{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1660687393066,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "xAgfGYA4acPE",
    "outputId": "527d048f-6a89-4e80-87ff-bfdb1c9d6222"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1856,
     "status": "ok",
     "timestamp": 1660687061284,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "7kSdyTofacUc",
    "outputId": "08ee5c9b-0706-46a5-86a1-2c7e56a6a74d"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/2D Klein Gordon/stan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32419,
     "status": "ok",
     "timestamp": 1660687093700,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "RHuSaD0gagsN",
    "outputId": "c232cd79-e56c-4a76-97c7-d59dafa084ef"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1660687406024,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "T7Wci76Yf-U8"
   },
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1]).reshape(-1,1)\n",
    "b_value = np.array([0.0,0.25,0.5,1.0]).reshape(-1,1)\n",
    "\n",
    "\n",
    "LR_tune, B_value = np.meshgrid(lr_tune,b_value)\n",
    "\n",
    "LR_tune = LR_tune.flatten('F').reshape(-1,1)\n",
    "B_value = B_value.flatten('F').reshape(-1,1)\n",
    "\n",
    "\n",
    "lrb_tune = np.hstack((LR_tune,B_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    y = xt[:,0]*np.cos(xt[:,1])\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.1\n",
    "\n",
    "x = np.linspace(-5,5,500).reshape(-1,1)\n",
    "t = np.linspace(0,10,1000).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "\n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        self.beta = Parameter(beta_init*torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = (xt - lbxt)/(ubxt - lbxt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) + self.beta[:,i]*z*self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,2) + (g[:,0]*torch.cos(g[:,1])).reshape(-1,1) - (torch.pow(g[:,0],2)*torch.pow(torch.cos(g[:,1]),2)).reshape(-1,1)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC, y_BC, xt_coll, f_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC, y_BC, xt_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    nan_flag = 0\n",
    "    for i in range(max_iter):\n",
    "        train_step(xt_BC, y_BC, xt_coll,f_hat,i)\n",
    "        loss_np = PINN.loss(xt_BC, y_BC, xt_coll,f_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "        if(np.isnan(loss_np)):\n",
    "            nan_flag =1\n",
    "            print(\"NAN BREAK!\")\n",
    "            break\n",
    "            \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))\n",
    "    \n",
    "    return nan_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_stan_tune0\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 58.700226 Test MSE 8.644311399021719 Test RE 1.405313641281015\n",
      "1 Train Loss 57.910076 Test MSE 8.487540787907289 Test RE 1.3925121636877191\n",
      "2 Train Loss 56.02439 Test MSE 9.022194644527383 Test RE 1.4357015076399968\n",
      "3 Train Loss 47.836292 Test MSE 7.362302639044134 Test RE 1.296925093305639\n",
      "4 Train Loss 39.00753 Test MSE 7.831202463887157 Test RE 1.3375877611665088\n",
      "5 Train Loss 37.789215 Test MSE 7.090911292843102 Test RE 1.272796834340069\n",
      "6 Train Loss 36.23677 Test MSE 7.130935289388107 Test RE 1.27638387211384\n",
      "7 Train Loss 35.662083 Test MSE 7.429628414718186 Test RE 1.3028415694241036\n",
      "8 Train Loss 34.298237 Test MSE 6.592262871489154 Test RE 1.2272281788188046\n",
      "9 Train Loss 32.232666 Test MSE 6.02188159427068 Test RE 1.1729355956590273\n",
      "10 Train Loss 30.794323 Test MSE 6.482751298070124 Test RE 1.2169920485198882\n",
      "11 Train Loss 29.502466 Test MSE 6.429890665024981 Test RE 1.2120201898209495\n",
      "12 Train Loss 27.78714 Test MSE 6.37364480104487 Test RE 1.2067074353192482\n",
      "13 Train Loss 26.915243 Test MSE 6.360040204924144 Test RE 1.2054188839802027\n",
      "14 Train Loss 26.023691 Test MSE 6.199045880357698 Test RE 1.1900644598980892\n",
      "15 Train Loss 24.947681 Test MSE 6.438207218399048 Test RE 1.2128037625024257\n",
      "16 Train Loss 24.252644 Test MSE 5.992614876052358 Test RE 1.1700818542067652\n",
      "17 Train Loss 23.800213 Test MSE 5.709437051217969 Test RE 1.1421015075796013\n",
      "18 Train Loss 23.432953 Test MSE 5.7081080004838025 Test RE 1.1419685698504383\n",
      "19 Train Loss 23.296206 Test MSE 5.58678684669353 Test RE 1.1297675885402458\n",
      "20 Train Loss 23.148079 Test MSE 5.657394214149711 Test RE 1.1368843319425008\n",
      "21 Train Loss 23.009422 Test MSE 5.776991410083234 Test RE 1.1488383410298963\n",
      "22 Train Loss 22.809732 Test MSE 5.679634450794485 Test RE 1.1391167886876963\n",
      "23 Train Loss 22.619883 Test MSE 5.6500453687570005 Test RE 1.1361456966442756\n",
      "24 Train Loss 22.109112 Test MSE 5.647173078859166 Test RE 1.135856871117932\n",
      "25 Train Loss 21.271294 Test MSE 5.459743651925458 Test RE 1.116848296914002\n",
      "26 Train Loss 20.37304 Test MSE 5.295017238761261 Test RE 1.0998709954069015\n",
      "27 Train Loss 18.923899 Test MSE 5.810815561904033 Test RE 1.1521966435385345\n",
      "28 Train Loss 17.973133 Test MSE 6.180968602474087 Test RE 1.1883279964905435\n",
      "29 Train Loss 16.512077 Test MSE 6.140994228450594 Test RE 1.1844791077404218\n",
      "30 Train Loss 15.539611 Test MSE 6.272450133910291 Test RE 1.1970896307970895\n",
      "31 Train Loss 15.036697 Test MSE 6.205972273148665 Test RE 1.190729122883252\n",
      "32 Train Loss 14.644691 Test MSE 6.263593771004334 Test RE 1.1962442191211435\n",
      "33 Train Loss 14.1876545 Test MSE 6.105965691186469 Test RE 1.181096112704418\n",
      "34 Train Loss 13.985941 Test MSE 6.159712835247538 Test RE 1.1862829629363774\n",
      "35 Train Loss 13.702702 Test MSE 6.170371191184684 Test RE 1.1873088517738895\n",
      "36 Train Loss 13.425901 Test MSE 6.181402847671324 Test RE 1.1883697388690733\n",
      "37 Train Loss 13.085168 Test MSE 6.037567977346168 Test RE 1.174462290465001\n",
      "38 Train Loss 12.816246 Test MSE 6.145605774737574 Test RE 1.1849237633568879\n",
      "39 Train Loss 12.694761 Test MSE 6.082242513002994 Test RE 1.1787994553475123\n",
      "40 Train Loss 12.506746 Test MSE 6.027744871024836 Test RE 1.1735064780892832\n",
      "41 Train Loss 12.387957 Test MSE 6.010603374849439 Test RE 1.171836701194045\n",
      "42 Train Loss 12.310641 Test MSE 6.074433209347203 Test RE 1.1780424516879637\n",
      "43 Train Loss 12.240107 Test MSE 6.026993421082029 Test RE 1.1734333281070053\n",
      "44 Train Loss 12.174799 Test MSE 6.028353847582576 Test RE 1.1735657556385106\n",
      "45 Train Loss 12.070475 Test MSE 5.962022861851552 Test RE 1.1670914266915253\n",
      "46 Train Loss 12.00528 Test MSE 5.959254697132344 Test RE 1.1668204552044372\n",
      "47 Train Loss 11.869072 Test MSE 5.9103997468273315 Test RE 1.1620277190622883\n",
      "48 Train Loss 11.80611 Test MSE 5.913173346295458 Test RE 1.1623003420296392\n",
      "49 Train Loss 11.686171 Test MSE 5.9350892507878905 Test RE 1.1644522580156198\n",
      "50 Train Loss 11.52272 Test MSE 5.914109965153906 Test RE 1.1623923898397261\n",
      "51 Train Loss 11.396839 Test MSE 5.909371902427708 Test RE 1.1619266738144147\n",
      "52 Train Loss 11.228313 Test MSE 5.857495761660795 Test RE 1.1568153741547427\n",
      "53 Train Loss 10.938021 Test MSE 5.8981091961990435 Test RE 1.160818884329201\n",
      "54 Train Loss 10.561962 Test MSE 5.818885194245332 Test RE 1.1529964088565634\n",
      "55 Train Loss 10.271087 Test MSE 5.788846626061465 Test RE 1.1500165275150693\n",
      "56 Train Loss 9.358723 Test MSE 5.179022124798671 Test RE 1.0877571419445737\n",
      "57 Train Loss 8.899893 Test MSE 5.01712577599889 Test RE 1.0706204992568973\n",
      "58 Train Loss 8.224155 Test MSE 4.906653568532736 Test RE 1.0587678816636625\n",
      "59 Train Loss 7.5981593 Test MSE 4.836807681630511 Test RE 1.0512051262110036\n",
      "60 Train Loss 7.0122137 Test MSE 4.556567565698553 Test RE 1.020297840638666\n",
      "61 Train Loss 6.7421074 Test MSE 4.268533950741367 Test RE 0.9875234795579821\n",
      "62 Train Loss 6.569286 Test MSE 4.109684357954484 Test RE 0.9689743792629437\n",
      "63 Train Loss 6.248896 Test MSE 3.6706140124050717 Test RE 0.9157510374919678\n",
      "64 Train Loss 6.0460224 Test MSE 3.522592052618231 Test RE 0.8970966517451148\n",
      "65 Train Loss 5.704466 Test MSE 3.1897848761180825 Test RE 0.8536675193959183\n",
      "66 Train Loss 5.477751 Test MSE 2.8878846800899427 Test RE 0.8122654555241151\n",
      "67 Train Loss 5.333053 Test MSE 2.801501434653871 Test RE 0.8000248644206648\n",
      "68 Train Loss 5.1884837 Test MSE 2.5326918544244417 Test RE 0.760675164497838\n",
      "69 Train Loss 4.94005 Test MSE 2.3107189800593235 Test RE 0.7265769666392374\n",
      "70 Train Loss 4.7655783 Test MSE 2.154051374880716 Test RE 0.7015135901440746\n",
      "71 Train Loss 4.630517 Test MSE 2.2141285169167624 Test RE 0.7112290271132453\n",
      "72 Train Loss 4.541644 Test MSE 2.203202002900055 Test RE 0.7094719327972095\n",
      "73 Train Loss 4.45714 Test MSE 2.169118582671103 Test RE 0.703962796313901\n",
      "74 Train Loss 4.398596 Test MSE 2.1620080192972755 Test RE 0.7028080228886603\n",
      "75 Train Loss 4.336364 Test MSE 2.1567748386514114 Test RE 0.701956927604273\n",
      "76 Train Loss 4.302906 Test MSE 2.1622522872548458 Test RE 0.702847724090056\n",
      "77 Train Loss 4.2618117 Test MSE 2.188168719273018 Test RE 0.7070472914948884\n",
      "78 Train Loss 4.194568 Test MSE 2.1582373643013475 Test RE 0.7021948884731894\n",
      "79 Train Loss 4.1818275 Test MSE 2.147306435980468 Test RE 0.7004144111243615\n",
      "80 Train Loss 4.1600366 Test MSE 2.135812960943409 Test RE 0.6985374091918798\n",
      "81 Train Loss 4.1389084 Test MSE 2.149898830060794 Test RE 0.7008370807640734\n",
      "82 Train Loss 4.115944 Test MSE 2.1295775495701066 Test RE 0.6975169893611805\n",
      "83 Train Loss 4.0968013 Test MSE 2.129903923649334 Test RE 0.6975704372254129\n",
      "84 Train Loss 4.0762525 Test MSE 2.1473599141592645 Test RE 0.7004231329009255\n",
      "85 Train Loss 4.0639606 Test MSE 2.141711857567275 Test RE 0.699501388433867\n",
      "86 Train Loss 4.056933 Test MSE 2.145287614995497 Test RE 0.700085081366219\n",
      "87 Train Loss 4.0491962 Test MSE 2.150727435449146 Test RE 0.7009721246623488\n",
      "88 Train Loss 4.032995 Test MSE 2.147008964258889 Test RE 0.7003658943654966\n",
      "89 Train Loss 4.0175056 Test MSE 2.143412376635236 Test RE 0.6997790353591038\n",
      "90 Train Loss 4.003615 Test MSE 2.151379821261084 Test RE 0.7010784304609328\n",
      "91 Train Loss 3.9833791 Test MSE 2.1502488411609453 Test RE 0.7008941278146348\n",
      "92 Train Loss 3.967246 Test MSE 2.1535071172020137 Test RE 0.701424959881357\n",
      "93 Train Loss 3.95919 Test MSE 2.144414909761692 Test RE 0.6999426692116474\n",
      "94 Train Loss 3.9451108 Test MSE 2.1346529143814594 Test RE 0.6983476814403853\n",
      "95 Train Loss 3.9313006 Test MSE 2.1544911637643773 Test RE 0.7015851998875788\n",
      "96 Train Loss 3.9185255 Test MSE 2.161327460499531 Test RE 0.7026973989166738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 Train Loss 3.9114406 Test MSE 2.148736721644375 Test RE 0.7006476395798695\n",
      "98 Train Loss 3.903901 Test MSE 2.1467923582502837 Test RE 0.7003305644507407\n",
      "99 Train Loss 3.889979 Test MSE 2.147132654097697 Test RE 0.7003860682209369\n",
      "Training time: 69.24\n",
      "KG_stan_tune0\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.67988 Test MSE 8.558332307589257 Test RE 1.3983073260597167\n",
      "1 Train Loss 57.365524 Test MSE 8.667949375866227 Test RE 1.4072337533344996\n",
      "2 Train Loss 56.94241 Test MSE 8.661739582142426 Test RE 1.4067295858192677\n",
      "3 Train Loss 49.324898 Test MSE 8.985387268325049 Test RE 1.4327699364175226\n",
      "4 Train Loss 44.611694 Test MSE 8.249390358468554 Test RE 1.372837038301794\n",
      "5 Train Loss 44.405342 Test MSE 8.426014320308743 Test RE 1.3874557999135195\n",
      "6 Train Loss 44.15439 Test MSE 8.326863421749657 Test RE 1.3792683829424028\n",
      "7 Train Loss 43.89135 Test MSE 8.355836499427848 Test RE 1.381665861258794\n",
      "8 Train Loss 43.631332 Test MSE 8.485507461890355 Test RE 1.3923453544268838\n",
      "9 Train Loss 43.254032 Test MSE 8.577774290761674 Test RE 1.3998946940473906\n",
      "10 Train Loss 42.739918 Test MSE 8.718618507743663 Test RE 1.4113408039651232\n",
      "11 Train Loss 42.53441 Test MSE 8.621815582978371 Test RE 1.4034838673271506\n",
      "12 Train Loss 42.42536 Test MSE 8.734752238895089 Test RE 1.41264603763236\n",
      "13 Train Loss 42.066856 Test MSE 8.885657391418647 Test RE 1.4247965086172478\n",
      "14 Train Loss 41.87393 Test MSE 8.713363241690052 Test RE 1.4109153874029885\n",
      "15 Train Loss 41.721054 Test MSE 8.759124394022106 Test RE 1.4146154836065794\n",
      "16 Train Loss 41.60919 Test MSE 8.916231943682824 Test RE 1.4272456862244491\n",
      "17 Train Loss 41.497902 Test MSE 8.925663864895384 Test RE 1.4280003834310095\n",
      "18 Train Loss 41.358665 Test MSE 8.904903199931804 Test RE 1.426338686498117\n",
      "19 Train Loss 40.927536 Test MSE 9.010565608865946 Test RE 1.4347759452838487\n",
      "20 Train Loss 40.576744 Test MSE 9.106460680101065 Test RE 1.442390550855184\n",
      "21 Train Loss 40.10674 Test MSE 8.885641772408581 Test RE 1.4247952563789605\n",
      "22 Train Loss 39.61355 Test MSE 9.010296341695886 Test RE 1.4347545070655634\n",
      "23 Train Loss 38.507835 Test MSE 8.841608246117321 Test RE 1.4212605269274439\n",
      "24 Train Loss 36.288834 Test MSE 8.82951112517654 Test RE 1.420287907186396\n",
      "25 Train Loss 34.573875 Test MSE 8.675566021658733 Test RE 1.4078518953548458\n",
      "26 Train Loss 33.05572 Test MSE 8.839098857118508 Test RE 1.421058824447285\n",
      "27 Train Loss 32.181824 Test MSE 8.779971960318148 Test RE 1.4162979441797365\n",
      "28 Train Loss 31.769735 Test MSE 8.529699553046077 Test RE 1.395966278037232\n",
      "29 Train Loss 31.302856 Test MSE 8.418681361709337 Test RE 1.3868519337143137\n",
      "30 Train Loss 30.7949 Test MSE 8.255947208609976 Test RE 1.3733825148999863\n",
      "31 Train Loss 29.654873 Test MSE 7.932321512378597 Test RE 1.3461957484123381\n",
      "32 Train Loss 28.734879 Test MSE 7.961909996448218 Test RE 1.3487041449838837\n",
      "33 Train Loss 28.371765 Test MSE 7.892560544306039 Test RE 1.3428175892000638\n",
      "34 Train Loss 27.742725 Test MSE 7.8604524540474126 Test RE 1.3400834164700355\n",
      "35 Train Loss 27.465775 Test MSE 7.888435127840532 Test RE 1.342466600072749\n",
      "36 Train Loss 26.639633 Test MSE 7.612140251302151 Test RE 1.3187468977355263\n",
      "37 Train Loss 25.984737 Test MSE 7.738601161162598 Test RE 1.329655983873813\n",
      "38 Train Loss 25.227512 Test MSE 7.524562103405977 Test RE 1.311138818960708\n",
      "39 Train Loss 24.47044 Test MSE 7.667371801269433 Test RE 1.3235224792245714\n",
      "40 Train Loss 23.455309 Test MSE 7.256997766252762 Test RE 1.287616564396312\n",
      "41 Train Loss 21.634243 Test MSE 7.37983576019789 Test RE 1.2984684706861254\n",
      "42 Train Loss 21.028746 Test MSE 7.248856531638523 Test RE 1.286894107910117\n",
      "43 Train Loss 20.203684 Test MSE 7.41534824157593 Test RE 1.301588898992518\n",
      "44 Train Loss 19.389935 Test MSE 7.201752313614258 Test RE 1.2827060723074135\n",
      "45 Train Loss 18.641418 Test MSE 7.301921773973327 Test RE 1.2915958718884715\n",
      "46 Train Loss 17.935118 Test MSE 7.3023295691057735 Test RE 1.2916319376785688\n",
      "47 Train Loss 17.62357 Test MSE 7.1392746787399135 Test RE 1.2771299980728972\n",
      "48 Train Loss 17.142647 Test MSE 7.0000135544625355 Test RE 1.2646125888095556\n",
      "49 Train Loss 16.91634 Test MSE 6.980884768451937 Test RE 1.2628835169838237\n",
      "50 Train Loss 16.35365 Test MSE 6.526628846153571 Test RE 1.2211036188993674\n",
      "51 Train Loss 15.079726 Test MSE 6.367615892243155 Test RE 1.2061365806099205\n",
      "52 Train Loss 14.807022 Test MSE 6.178529791652316 Test RE 1.1880935354136983\n",
      "53 Train Loss 14.434397 Test MSE 6.051110712784937 Test RE 1.1757787578613643\n",
      "54 Train Loss 13.979841 Test MSE 6.04467396419373 Test RE 1.175153235843822\n",
      "55 Train Loss 13.502979 Test MSE 5.849928132424229 Test RE 1.1560678551132684\n",
      "56 Train Loss 13.373842 Test MSE 5.893218161704614 Test RE 1.1603374772757231\n",
      "57 Train Loss 13.180208 Test MSE 5.882708573455872 Test RE 1.1593023797761566\n",
      "58 Train Loss 13.004126 Test MSE 5.774644035831942 Test RE 1.1486049126457334\n",
      "59 Train Loss 12.895021 Test MSE 5.766982470736182 Test RE 1.1478426983777048\n",
      "60 Train Loss 12.719281 Test MSE 5.832447213552852 Test RE 1.1543392656419698\n",
      "61 Train Loss 12.570948 Test MSE 5.865064764558905 Test RE 1.1575625460278065\n",
      "62 Train Loss 12.483439 Test MSE 5.90090740337099 Test RE 1.1610942121040033\n",
      "63 Train Loss 12.329742 Test MSE 5.871793228106268 Test RE 1.1582263396253119\n",
      "64 Train Loss 12.248649 Test MSE 5.92629601445394 Test RE 1.1635893308683625\n",
      "65 Train Loss 12.180623 Test MSE 5.879048424907975 Test RE 1.1589416718561638\n",
      "66 Train Loss 12.14061 Test MSE 5.817197423304351 Test RE 1.152829183099517\n",
      "67 Train Loss 12.061005 Test MSE 5.827313412100432 Test RE 1.1538311210308454\n",
      "68 Train Loss 11.96158 Test MSE 5.843038811050464 Test RE 1.1553869177502298\n",
      "69 Train Loss 11.904962 Test MSE 5.804054997512141 Test RE 1.1515261897528035\n",
      "70 Train Loss 11.847082 Test MSE 5.79959205717094 Test RE 1.1510833802864444\n",
      "71 Train Loss 11.809764 Test MSE 5.8121835158981305 Test RE 1.1523322578281407\n",
      "72 Train Loss 11.7403 Test MSE 5.792162401947838 Test RE 1.1503458376035967\n",
      "73 Train Loss 11.64843 Test MSE 5.832342040271903 Test RE 1.1543288578156516\n",
      "74 Train Loss 11.594916 Test MSE 5.8456644369733315 Test RE 1.1556464807294349\n",
      "75 Train Loss 11.507862 Test MSE 5.829289088513865 Test RE 1.1540267003300337\n",
      "76 Train Loss 11.261224 Test MSE 5.801781248017451 Test RE 1.1513006113793498\n",
      "77 Train Loss 11.171988 Test MSE 5.842860399439984 Test RE 1.1553692782974605\n",
      "78 Train Loss 11.094736 Test MSE 5.859744335809636 Test RE 1.157037391861921\n",
      "79 Train Loss 10.992953 Test MSE 5.794894634250105 Test RE 1.1506171215625478\n",
      "80 Train Loss 10.886298 Test MSE 5.781828813987812 Test RE 1.1493192342655092\n",
      "81 Train Loss 10.779274 Test MSE 5.739066850781283 Test RE 1.1450612081176346\n",
      "82 Train Loss 10.5808325 Test MSE 5.75663412461702 Test RE 1.146812384256698\n",
      "83 Train Loss 10.513832 Test MSE 5.851890501905017 Test RE 1.1562617414314333\n",
      "84 Train Loss 10.328146 Test MSE 5.911398827479974 Test RE 1.1621259281855567\n",
      "85 Train Loss 10.213356 Test MSE 5.848705034643505 Test RE 1.1559469939751226\n",
      "86 Train Loss 10.036113 Test MSE 5.807870497902341 Test RE 1.1519046257587906\n",
      "87 Train Loss 9.875107 Test MSE 5.778176443381196 Test RE 1.148956165497866\n",
      "88 Train Loss 9.704494 Test MSE 5.823537401663098 Test RE 1.1534572279454511\n",
      "89 Train Loss 9.523241 Test MSE 5.737160875057846 Test RE 1.1448710517600755\n",
      "90 Train Loss 9.205952 Test MSE 5.565498516513238 Test RE 1.1276130566784077\n",
      "91 Train Loss 8.478275 Test MSE 5.48180451560668 Test RE 1.1191024136624026\n",
      "92 Train Loss 7.8292446 Test MSE 5.206464391900857 Test RE 1.0906352030173805\n",
      "93 Train Loss 7.300297 Test MSE 5.017422784533356 Test RE 1.0706521885879723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 Train Loss 6.1673527 Test MSE 4.597209431699773 Test RE 1.0248379635276157\n",
      "95 Train Loss 5.2581654 Test MSE 4.09413780543741 Test RE 0.967139872838781\n",
      "96 Train Loss 4.8376303 Test MSE 3.9350032828371684 Test RE 0.948157773088217\n",
      "97 Train Loss 4.2011375 Test MSE 3.674093960724093 Test RE 0.9161850263726089\n",
      "98 Train Loss 3.4738383 Test MSE 3.1430948421643388 Test RE 0.8473967680023649\n",
      "99 Train Loss 3.1987507 Test MSE 3.1155565592629197 Test RE 0.8436763598333138\n",
      "Training time: 68.21\n",
      "KG_stan_tune0\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.935265 Test MSE 8.294996384195635 Test RE 1.3766266120748323\n",
      "1 Train Loss 56.113956 Test MSE 8.517300256689701 Test RE 1.3949512777778315\n",
      "2 Train Loss 52.19748 Test MSE 8.622154708547633 Test RE 1.4035114689721122\n",
      "3 Train Loss 47.143684 Test MSE 8.894528189724545 Test RE 1.4255075381441153\n",
      "4 Train Loss 45.218445 Test MSE 7.786195487851319 Test RE 1.3337385741778407\n",
      "5 Train Loss 44.195404 Test MSE 8.122504356110003 Test RE 1.362238143867159\n",
      "6 Train Loss 44.034267 Test MSE 8.10370995757416 Test RE 1.3606612118779802\n",
      "7 Train Loss 43.5295 Test MSE 8.077106924462928 Test RE 1.358425971970304\n",
      "8 Train Loss 43.135353 Test MSE 8.09552819259308 Test RE 1.3599741548576727\n",
      "9 Train Loss 42.611507 Test MSE 8.152496296652869 Test RE 1.3647508245786826\n",
      "10 Train Loss 42.530396 Test MSE 8.138574197991552 Test RE 1.363585027405927\n",
      "11 Train Loss 42.43573 Test MSE 8.133110472914904 Test RE 1.3631272380957518\n",
      "12 Train Loss 42.376415 Test MSE 8.17940769190851 Test RE 1.3670014903994672\n",
      "13 Train Loss 42.341293 Test MSE 8.239850214321809 Test RE 1.3720429885941092\n",
      "14 Train Loss 42.049576 Test MSE 8.176055712925642 Test RE 1.366721358268596\n",
      "15 Train Loss 41.95295 Test MSE 8.190171800874118 Test RE 1.3679006823485642\n",
      "16 Train Loss 41.834305 Test MSE 8.198263157594992 Test RE 1.3685762139698567\n",
      "17 Train Loss 41.779526 Test MSE 8.267634248534643 Test RE 1.374354244706612\n",
      "18 Train Loss 41.593674 Test MSE 8.322009196390917 Test RE 1.3788662954290256\n",
      "19 Train Loss 41.541485 Test MSE 8.243493220526759 Test RE 1.3723462592024092\n",
      "20 Train Loss 40.870678 Test MSE 7.9591368529325415 Test RE 1.3484692468320958\n",
      "21 Train Loss 40.645042 Test MSE 7.975882479880287 Test RE 1.3498870574909818\n",
      "22 Train Loss 39.951485 Test MSE 7.999061390203468 Test RE 1.3518471046539149\n",
      "23 Train Loss 38.776436 Test MSE 7.102525041022042 Test RE 1.2738387239971214\n",
      "24 Train Loss 36.547268 Test MSE 6.665919186953206 Test RE 1.2340651340951572\n",
      "25 Train Loss 32.848812 Test MSE 6.451894729826184 Test RE 1.2140922773945422\n",
      "26 Train Loss 31.563984 Test MSE 6.369702774294344 Test RE 1.2063342101957837\n",
      "27 Train Loss 30.545523 Test MSE 6.422412817213198 Test RE 1.2113152058916206\n",
      "28 Train Loss 30.125912 Test MSE 6.477425973565884 Test RE 1.216492090340662\n",
      "29 Train Loss 29.2903 Test MSE 6.46419926804694 Test RE 1.2152494358492911\n",
      "30 Train Loss 28.94291 Test MSE 6.307504617269446 Test RE 1.200430023414954\n",
      "31 Train Loss 28.415077 Test MSE 6.077825491636881 Test RE 1.1783713461406713\n",
      "32 Train Loss 28.156326 Test MSE 6.1798560905971325 Test RE 1.1882210481634967\n",
      "33 Train Loss 27.43821 Test MSE 6.307344513381068 Test RE 1.2004147880131772\n",
      "34 Train Loss 27.260885 Test MSE 6.257482570352349 Test RE 1.1956605068989214\n",
      "35 Train Loss 27.024914 Test MSE 6.236130252863418 Test RE 1.1936187961374505\n",
      "36 Train Loss 26.858112 Test MSE 6.199244453134446 Test RE 1.1900835202919344\n",
      "37 Train Loss 26.647669 Test MSE 5.982395551253623 Test RE 1.1690837466255515\n",
      "38 Train Loss 26.436699 Test MSE 6.122667285836456 Test RE 1.1827103305622664\n",
      "39 Train Loss 26.193035 Test MSE 6.228248021986169 Test RE 1.192864213296219\n",
      "40 Train Loss 25.75155 Test MSE 6.242705650147399 Test RE 1.1942479082379036\n",
      "41 Train Loss 25.642485 Test MSE 6.229300226411446 Test RE 1.1929649706836185\n",
      "42 Train Loss 25.553965 Test MSE 6.210682428792304 Test RE 1.1911809018695674\n",
      "43 Train Loss 25.509651 Test MSE 6.28278671605067 Test RE 1.1980755869564266\n",
      "44 Train Loss 25.345867 Test MSE 6.332380383756147 Test RE 1.202794843921497\n",
      "45 Train Loss 25.13657 Test MSE 6.256109563567935 Test RE 1.1955293247476881\n",
      "46 Train Loss 24.975224 Test MSE 6.2629122733540346 Test RE 1.1961791398846386\n",
      "47 Train Loss 24.857895 Test MSE 6.206742374048467 Test RE 1.1908029995526301\n",
      "48 Train Loss 24.758472 Test MSE 6.160249744635993 Test RE 1.1863346627962927\n",
      "49 Train Loss 24.561066 Test MSE 6.038156345742578 Test RE 1.1745195154654315\n",
      "50 Train Loss 24.34911 Test MSE 6.081862628684208 Test RE 1.1787626420817134\n",
      "51 Train Loss 24.207306 Test MSE 6.042760664747136 Test RE 1.1749672375585207\n",
      "52 Train Loss 23.888874 Test MSE 5.987345736615943 Test RE 1.1695673308797145\n",
      "53 Train Loss 23.46587 Test MSE 5.667580202382294 Test RE 1.1379073367194878\n",
      "54 Train Loss 23.348186 Test MSE 5.590723390774711 Test RE 1.1301655450836925\n",
      "55 Train Loss 23.1488 Test MSE 5.723077169469396 Test RE 1.1434649612958883\n",
      "56 Train Loss 22.939873 Test MSE 5.686087569525149 Test RE 1.1397637290102098\n",
      "57 Train Loss 22.80923 Test MSE 5.521839533616989 Test RE 1.1231815248434616\n",
      "58 Train Loss 22.537914 Test MSE 5.528093737935827 Test RE 1.12381741970742\n",
      "59 Train Loss 22.331116 Test MSE 5.557466567091051 Test RE 1.1267990953557632\n",
      "60 Train Loss 22.186035 Test MSE 5.533823234441037 Test RE 1.1243996493849882\n",
      "61 Train Loss 21.712154 Test MSE 4.830470732985269 Test RE 1.0505162817664535\n",
      "62 Train Loss 19.793804 Test MSE 4.285117819873487 Test RE 0.9894399553845327\n",
      "63 Train Loss 17.114094 Test MSE 4.087857824178019 Test RE 0.9663978422295648\n",
      "64 Train Loss 15.624187 Test MSE 4.301886754485796 Test RE 0.9913740507916596\n",
      "65 Train Loss 15.136635 Test MSE 4.056290612436321 Test RE 0.9626592572126865\n",
      "66 Train Loss 14.642828 Test MSE 4.000932429542572 Test RE 0.9560677495956987\n",
      "67 Train Loss 14.348407 Test MSE 4.061855387943722 Test RE 0.9633193611269051\n",
      "68 Train Loss 14.081964 Test MSE 4.09493759416174 Test RE 0.9672343334834232\n",
      "69 Train Loss 13.672578 Test MSE 4.140847233418041 Test RE 0.9726412060494903\n",
      "70 Train Loss 13.320955 Test MSE 4.115347701526145 Test RE 0.9696417961603426\n",
      "71 Train Loss 13.052951 Test MSE 4.116745383356757 Test RE 0.9698064402886996\n",
      "72 Train Loss 12.695686 Test MSE 4.080515558021504 Test RE 0.9655295709432241\n",
      "73 Train Loss 12.486668 Test MSE 4.09705991777352 Test RE 0.9674849500443119\n",
      "74 Train Loss 11.965188 Test MSE 4.019904651214145 Test RE 0.9583318814191519\n",
      "75 Train Loss 11.5685005 Test MSE 3.767686771744708 Test RE 0.9277809596063783\n",
      "76 Train Loss 11.027374 Test MSE 3.572347804200612 Test RE 0.9034100714875425\n",
      "77 Train Loss 10.522983 Test MSE 3.5145371028696593 Test RE 0.8960703898403887\n",
      "78 Train Loss 10.031698 Test MSE 3.474537113905304 Test RE 0.8909565763321369\n",
      "79 Train Loss 9.692117 Test MSE 3.4104584609344384 Test RE 0.8827026743750782\n",
      "80 Train Loss 9.314556 Test MSE 3.448009922353955 Test RE 0.8875489483537087\n",
      "81 Train Loss 8.9596815 Test MSE 3.4271315987963873 Test RE 0.8848577335342087\n",
      "82 Train Loss 8.692472 Test MSE 3.3786135991842374 Test RE 0.8785719290931876\n",
      "83 Train Loss 8.341583 Test MSE 3.2882835034814293 Test RE 0.8667476785560787\n",
      "84 Train Loss 8.026581 Test MSE 3.3471820800569216 Test RE 0.8744756665460242\n",
      "85 Train Loss 7.8238926 Test MSE 3.2927600369186223 Test RE 0.867337455157182\n",
      "86 Train Loss 7.6629615 Test MSE 3.217830044441315 Test RE 0.8574121066210585\n",
      "87 Train Loss 7.421333 Test MSE 3.2486461070007184 Test RE 0.8615078958758866\n",
      "88 Train Loss 7.2056475 Test MSE 3.2068982429326716 Test RE 0.8559544421299323\n",
      "89 Train Loss 7.051074 Test MSE 3.1822491816710974 Test RE 0.8526585514371785\n",
      "90 Train Loss 6.9078026 Test MSE 3.1148073214521363 Test RE 0.8435749089007838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 Train Loss 6.8284016 Test MSE 3.1198199516849563 Test RE 0.8442534146300705\n",
      "92 Train Loss 6.7430315 Test MSE 3.124723592532712 Test RE 0.8449166404126269\n",
      "93 Train Loss 6.5699534 Test MSE 3.0020195926702424 Test RE 0.8281610890976165\n",
      "94 Train Loss 6.506839 Test MSE 3.046282979449123 Test RE 0.8342441736922716\n",
      "95 Train Loss 6.302414 Test MSE 2.9724999832244086 Test RE 0.8240792723726023\n",
      "96 Train Loss 6.186656 Test MSE 2.82306910422307 Test RE 0.8030985001645619\n",
      "97 Train Loss 6.1136637 Test MSE 2.7614061690093914 Test RE 0.7942792291402417\n",
      "98 Train Loss 5.948027 Test MSE 2.6331814102187305 Test RE 0.7756190200308102\n",
      "99 Train Loss 5.689459 Test MSE 2.5320196742391956 Test RE 0.7605742156393626\n",
      "Training time: 74.48\n",
      "KG_stan_tune0\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.588745 Test MSE 8.546582447082272 Test RE 1.397347118011628\n",
      "1 Train Loss 56.327553 Test MSE 8.551359434983917 Test RE 1.3977375768786722\n",
      "2 Train Loss 55.77166 Test MSE 8.72805554787832 Test RE 1.4121044156345846\n",
      "3 Train Loss 51.561737 Test MSE 9.419828536085557 Test RE 1.4669981261426925\n",
      "4 Train Loss 45.855515 Test MSE 8.469918070648513 Test RE 1.3910657730285896\n",
      "5 Train Loss 43.935417 Test MSE 8.590475429043018 Test RE 1.400930724988142\n",
      "6 Train Loss 43.456436 Test MSE 8.66695103037447 Test RE 1.4071527107563777\n",
      "7 Train Loss 43.06929 Test MSE 8.636903365115197 Test RE 1.4047113467771228\n",
      "8 Train Loss 42.521973 Test MSE 8.515941193888484 Test RE 1.3948399806550984\n",
      "9 Train Loss 42.295227 Test MSE 8.382674804679073 Test RE 1.3838829847075458\n",
      "10 Train Loss 42.071182 Test MSE 8.43329554992006 Test RE 1.3880551463157782\n",
      "11 Train Loss 41.876442 Test MSE 8.372918754282091 Test RE 1.3830774445281713\n",
      "12 Train Loss 41.85402 Test MSE 8.35236988985013 Test RE 1.3813792237097013\n",
      "13 Train Loss 41.845245 Test MSE 8.323114041221716 Test RE 1.3789578227695298\n",
      "14 Train Loss 41.706726 Test MSE 8.378059518851945 Test RE 1.383501967010425\n",
      "15 Train Loss 41.556976 Test MSE 8.456558262674122 Test RE 1.3899682591191806\n",
      "16 Train Loss 41.42144 Test MSE 8.605256972311876 Test RE 1.4021354905438432\n",
      "17 Train Loss 41.247093 Test MSE 8.65039738415967 Test RE 1.405808256334497\n",
      "18 Train Loss 41.030205 Test MSE 8.68895940442394 Test RE 1.4089382006989593\n",
      "19 Train Loss 40.7093 Test MSE 8.69545632775493 Test RE 1.4094648490905926\n",
      "20 Train Loss 39.875294 Test MSE 8.786870352757097 Test RE 1.416854225038518\n",
      "21 Train Loss 39.36566 Test MSE 8.737650991073663 Test RE 1.4128804215613404\n",
      "22 Train Loss 36.90029 Test MSE 8.804755142985668 Test RE 1.418295424143656\n",
      "23 Train Loss 34.706726 Test MSE 8.724690133737445 Test RE 1.4118321456921312\n",
      "24 Train Loss 33.034378 Test MSE 8.341953871583073 Test RE 1.3805176143648745\n",
      "25 Train Loss 31.57055 Test MSE 8.327621822749345 Test RE 1.3793311925893592\n",
      "26 Train Loss 30.906488 Test MSE 8.156749826864852 Test RE 1.3651068046163162\n",
      "27 Train Loss 30.328175 Test MSE 8.447399502181781 Test RE 1.3892153620943222\n",
      "28 Train Loss 29.41198 Test MSE 7.966893788835526 Test RE 1.3491261925779434\n",
      "29 Train Loss 27.429924 Test MSE 7.9442122584104755 Test RE 1.3472043609223434\n",
      "30 Train Loss 25.062716 Test MSE 7.985319235056701 Test RE 1.3506853884591263\n",
      "31 Train Loss 22.560364 Test MSE 7.758778739365937 Test RE 1.3313883235568975\n",
      "32 Train Loss 21.459648 Test MSE 7.404503052816482 Test RE 1.3006367426079624\n",
      "33 Train Loss 20.807121 Test MSE 7.494304778303312 Test RE 1.3085000265254896\n",
      "34 Train Loss 20.20921 Test MSE 7.661255833548367 Test RE 1.3229945124188038\n",
      "35 Train Loss 19.76478 Test MSE 7.739117351174859 Test RE 1.3297003293362015\n",
      "36 Train Loss 19.49545 Test MSE 7.648409026622163 Test RE 1.3218848127511342\n",
      "37 Train Loss 19.077242 Test MSE 7.635811673663318 Test RE 1.3207957554095413\n",
      "38 Train Loss 18.528519 Test MSE 7.813875487233382 Test RE 1.3361071976154468\n",
      "39 Train Loss 16.628798 Test MSE 6.985659766846964 Test RE 1.2633153559360328\n",
      "40 Train Loss 14.902767 Test MSE 6.85294776253516 Test RE 1.2512577227659054\n",
      "41 Train Loss 14.01421 Test MSE 6.736853955353371 Test RE 1.2406138538375702\n",
      "42 Train Loss 13.633469 Test MSE 6.859315021717884 Test RE 1.2518388765082475\n",
      "43 Train Loss 13.279483 Test MSE 6.846982806103887 Test RE 1.250713043096063\n",
      "44 Train Loss 12.971526 Test MSE 6.622988214831348 Test RE 1.2300847982829606\n",
      "45 Train Loss 12.748112 Test MSE 6.635372901871594 Test RE 1.231234362467144\n",
      "46 Train Loss 12.477879 Test MSE 6.589859424905208 Test RE 1.2270044433334135\n",
      "47 Train Loss 12.196135 Test MSE 6.355401855086866 Test RE 1.2049792504183645\n",
      "48 Train Loss 11.788331 Test MSE 6.168827574247514 Test RE 1.187160330345135\n",
      "49 Train Loss 11.391012 Test MSE 6.039681879091247 Test RE 1.1746678766065752\n",
      "50 Train Loss 10.593292 Test MSE 5.929516309499541 Test RE 1.1639054298323137\n",
      "51 Train Loss 9.539889 Test MSE 5.959491629524095 Test RE 1.166843650622942\n",
      "52 Train Loss 8.3704815 Test MSE 5.513909139324095 Test RE 1.1223746856799806\n",
      "53 Train Loss 7.0551734 Test MSE 5.5480450537063914 Test RE 1.1258435650065615\n",
      "54 Train Loss 5.5965104 Test MSE 5.299707537407429 Test RE 1.1003580175752212\n",
      "55 Train Loss 4.2076187 Test MSE 4.980087331266647 Test RE 1.0666613025941452\n",
      "56 Train Loss 3.3598487 Test MSE 4.793283644346687 Test RE 1.0464648009499484\n",
      "57 Train Loss 3.0256033 Test MSE 4.959740896923689 Test RE 1.0644801193059548\n",
      "58 Train Loss 2.6380372 Test MSE 5.022717724354437 Test RE 1.0712169749624336\n",
      "59 Train Loss 2.4392292 Test MSE 5.049090711979806 Test RE 1.0740256341083956\n",
      "60 Train Loss 2.24095 Test MSE 5.051978255198659 Test RE 1.0743327044639743\n",
      "61 Train Loss 2.149731 Test MSE 5.143180757444152 Test RE 1.0839867014486673\n",
      "62 Train Loss 2.0081816 Test MSE 5.203946347083866 Test RE 1.09037143472437\n",
      "63 Train Loss 1.8850443 Test MSE 5.295545515945761 Test RE 1.0999258604087483\n",
      "64 Train Loss 1.7840271 Test MSE 5.319324217946646 Test RE 1.1023926047733086\n",
      "65 Train Loss 1.6754909 Test MSE 5.336814738065498 Test RE 1.1042035111397137\n",
      "66 Train Loss 1.5987442 Test MSE 5.417736411069357 Test RE 1.1125434879736529\n",
      "67 Train Loss 1.5128386 Test MSE 5.426790918241753 Test RE 1.1134727808405758\n",
      "68 Train Loss 1.4494305 Test MSE 5.531736886602444 Test RE 1.1241876702675906\n",
      "69 Train Loss 1.4162707 Test MSE 5.561674395991295 Test RE 1.1272255919076097\n",
      "70 Train Loss 1.3707097 Test MSE 5.604594519476908 Test RE 1.131566701860984\n",
      "71 Train Loss 1.3286912 Test MSE 5.679243201914825 Test RE 1.1390775532539037\n",
      "72 Train Loss 1.2819799 Test MSE 5.719487488289025 Test RE 1.1431062977329736\n",
      "73 Train Loss 1.2454642 Test MSE 5.787408648457 Test RE 1.1498736837995964\n",
      "74 Train Loss 1.2194865 Test MSE 5.815687571870821 Test RE 1.1526795651971333\n",
      "75 Train Loss 1.1985571 Test MSE 5.8198848193041695 Test RE 1.1530954411083723\n",
      "76 Train Loss 1.1783881 Test MSE 5.844876373258703 Test RE 1.1555685807948504\n",
      "77 Train Loss 1.1509186 Test MSE 5.891844808241742 Test RE 1.1602022670815737\n",
      "78 Train Loss 1.1199821 Test MSE 5.903449474877118 Test RE 1.161344280991592\n",
      "79 Train Loss 1.0919619 Test MSE 5.934234713764795 Test RE 1.1643684257980902\n",
      "80 Train Loss 1.0636512 Test MSE 5.9626586898649405 Test RE 1.1671536580563469\n",
      "81 Train Loss 1.0440574 Test MSE 5.958018920162771 Test RE 1.1666994665338033\n",
      "82 Train Loss 1.020638 Test MSE 5.9882155785411495 Test RE 1.1696522851980737\n",
      "83 Train Loss 1.0049618 Test MSE 6.011622701347649 Test RE 1.171936061731444\n",
      "84 Train Loss 0.9935085 Test MSE 6.038758925304748 Test RE 1.1745781197610496\n",
      "85 Train Loss 0.98365307 Test MSE 6.087292897171843 Test RE 1.179288761286869\n",
      "86 Train Loss 0.96678174 Test MSE 6.105461822929406 Test RE 1.1810473792896157\n",
      "87 Train Loss 0.95477486 Test MSE 6.107944862980423 Test RE 1.1812875159021976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 Train Loss 0.9454146 Test MSE 6.144603111832836 Test RE 1.184827098552059\n",
      "89 Train Loss 0.9322938 Test MSE 6.158020918065085 Test RE 1.1861200307977182\n",
      "90 Train Loss 0.9222169 Test MSE 6.171647648396795 Test RE 1.1874316539950243\n",
      "91 Train Loss 0.91090405 Test MSE 6.219137066745958 Test RE 1.1919914068567554\n",
      "92 Train Loss 0.9031901 Test MSE 6.245146094983522 Test RE 1.194481317557562\n",
      "93 Train Loss 0.89591014 Test MSE 6.246753284199899 Test RE 1.1946350076367829\n",
      "94 Train Loss 0.8887078 Test MSE 6.225235148803022 Test RE 1.1925756583664082\n",
      "95 Train Loss 0.8815945 Test MSE 6.22579877095965 Test RE 1.1926296440259885\n",
      "96 Train Loss 0.8723711 Test MSE 6.239588555773837 Test RE 1.1939497163602\n",
      "97 Train Loss 0.8656387 Test MSE 6.24525513707982 Test RE 1.194491745510434\n",
      "98 Train Loss 0.8594803 Test MSE 6.250041667478823 Test RE 1.1949494030312033\n",
      "99 Train Loss 0.85336137 Test MSE 6.244871053422523 Test RE 1.194455014279908\n",
      "Training time: 85.42\n",
      "KG_stan_tune0\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.53786 Test MSE 8.426799278975224 Test RE 1.387520425372813\n",
      "1 Train Loss 56.835327 Test MSE 8.60035934113605 Test RE 1.4017364251882196\n",
      "2 Train Loss 55.795563 Test MSE 8.547850809124917 Test RE 1.397450801343784\n",
      "3 Train Loss 50.76889 Test MSE 8.303012072519264 Test RE 1.3772915879755556\n",
      "4 Train Loss 48.007366 Test MSE 8.065467304060666 Test RE 1.3574468303494829\n",
      "5 Train Loss 45.37683 Test MSE 8.204669770577892 Test RE 1.3691108531789915\n",
      "6 Train Loss 44.480377 Test MSE 8.180106864788986 Test RE 1.3670599145532565\n",
      "7 Train Loss 44.263466 Test MSE 8.118240588232736 Test RE 1.3618805552822995\n",
      "8 Train Loss 43.95575 Test MSE 8.243880240806135 Test RE 1.3723784736765816\n",
      "9 Train Loss 43.785904 Test MSE 8.354103132419715 Test RE 1.3815225447735549\n",
      "10 Train Loss 43.679153 Test MSE 8.340719416759013 Test RE 1.3804154650538931\n",
      "11 Train Loss 43.573746 Test MSE 8.27534640785552 Test RE 1.3749951032614496\n",
      "12 Train Loss 42.520203 Test MSE 8.381545951855664 Test RE 1.3837898012757701\n",
      "13 Train Loss 41.722855 Test MSE 8.522546528940785 Test RE 1.3953808251327422\n",
      "14 Train Loss 40.653946 Test MSE 8.77909459992033 Test RE 1.416227178875618\n",
      "15 Train Loss 40.164787 Test MSE 8.693579945957962 Test RE 1.4093127675450228\n",
      "16 Train Loss 39.784492 Test MSE 8.484645164369038 Test RE 1.3922746075412937\n",
      "17 Train Loss 39.52793 Test MSE 8.470327530097395 Test RE 1.3910993966207168\n",
      "18 Train Loss 39.260933 Test MSE 8.393791432716217 Test RE 1.3848002942621322\n",
      "19 Train Loss 39.1407 Test MSE 8.379001619792323 Test RE 1.3835797512432744\n",
      "20 Train Loss 38.896477 Test MSE 8.324109181304163 Test RE 1.3790402567707454\n",
      "21 Train Loss 38.47045 Test MSE 8.43547372676558 Test RE 1.3882343902639005\n",
      "22 Train Loss 38.182873 Test MSE 8.344445450066267 Test RE 1.3807237657794307\n",
      "23 Train Loss 37.655743 Test MSE 8.339700898442624 Test RE 1.3803311784779904\n",
      "24 Train Loss 37.083782 Test MSE 8.412390786845013 Test RE 1.3863336977908116\n",
      "25 Train Loss 36.65229 Test MSE 8.370881448807962 Test RE 1.3829091685209134\n",
      "26 Train Loss 36.392056 Test MSE 8.296175725322005 Test RE 1.376724469542302\n",
      "27 Train Loss 36.145493 Test MSE 8.050243923105725 Test RE 1.356165150702066\n",
      "28 Train Loss 35.54417 Test MSE 7.726392470965675 Test RE 1.3286067137749664\n",
      "29 Train Loss 35.27209 Test MSE 7.8566380413897585 Test RE 1.3397582283557332\n",
      "30 Train Loss 34.7708 Test MSE 7.412815773547629 Test RE 1.3013666225974476\n",
      "31 Train Loss 33.807076 Test MSE 6.511744518906986 Test RE 1.2197104279758968\n",
      "32 Train Loss 31.38431 Test MSE 5.731525999775992 Test RE 1.1443086838435421\n",
      "33 Train Loss 28.172297 Test MSE 4.5674658334672475 Test RE 1.0215172714972398\n",
      "34 Train Loss 23.974632 Test MSE 2.815200738628481 Test RE 0.8019785343403042\n",
      "35 Train Loss 20.105896 Test MSE 2.627176155207011 Test RE 0.7747340736556413\n",
      "36 Train Loss 18.210274 Test MSE 2.2934606179237598 Test RE 0.7238585421445066\n",
      "37 Train Loss 16.638945 Test MSE 1.8263133402158886 Test RE 0.6459452455597253\n",
      "38 Train Loss 14.40793 Test MSE 1.5844355965422838 Test RE 0.6016519875337354\n",
      "39 Train Loss 13.269814 Test MSE 1.6864446053106417 Test RE 0.620717658387352\n",
      "40 Train Loss 12.088453 Test MSE 1.728995834254387 Test RE 0.6284996406853797\n",
      "41 Train Loss 10.63476 Test MSE 1.9490780038533617 Test RE 0.6673023748255947\n",
      "42 Train Loss 9.613413 Test MSE 1.857679354225089 Test RE 0.6514685241562903\n",
      "43 Train Loss 8.604558 Test MSE 2.1471449110705163 Test RE 0.7003880673057941\n",
      "44 Train Loss 8.087067 Test MSE 1.9329491539993284 Test RE 0.6645356363227402\n",
      "45 Train Loss 7.4740953 Test MSE 1.8239202577287423 Test RE 0.6455219044681736\n",
      "46 Train Loss 7.0958033 Test MSE 1.9320153009652403 Test RE 0.6643750905600421\n",
      "47 Train Loss 6.9905457 Test MSE 1.9258153345000135 Test RE 0.6633082218835011\n",
      "48 Train Loss 6.8860016 Test MSE 1.8641996531064746 Test RE 0.6526108226584256\n",
      "49 Train Loss 6.486626 Test MSE 1.821944947572137 Test RE 0.6451722588650811\n",
      "50 Train Loss 6.3021326 Test MSE 1.8693039229165445 Test RE 0.653503652096172\n",
      "51 Train Loss 6.0353656 Test MSE 1.8776754247161378 Test RE 0.6549653447310746\n",
      "52 Train Loss 5.945922 Test MSE 1.8928534058076878 Test RE 0.6576071865870603\n",
      "53 Train Loss 5.8753633 Test MSE 1.8912188153338088 Test RE 0.6573231839792611\n",
      "54 Train Loss 5.808908 Test MSE 1.9280141093124123 Test RE 0.6636867756644579\n",
      "55 Train Loss 5.705521 Test MSE 1.9629106180944083 Test RE 0.6696661121632164\n",
      "56 Train Loss 5.661873 Test MSE 1.9651643383819084 Test RE 0.6700504412121496\n",
      "57 Train Loss 5.589367 Test MSE 1.982117405943019 Test RE 0.672934428180006\n",
      "58 Train Loss 5.552648 Test MSE 1.9840854961345222 Test RE 0.6732684313654393\n",
      "59 Train Loss 5.523422 Test MSE 1.9887000831037716 Test RE 0.67405092066651\n",
      "60 Train Loss 5.4758096 Test MSE 1.9877726368447575 Test RE 0.6738937278065774\n",
      "61 Train Loss 5.444031 Test MSE 1.9626066402757667 Test RE 0.6696142576560034\n",
      "62 Train Loss 5.388246 Test MSE 1.9459593469304968 Test RE 0.6667682965835788\n",
      "63 Train Loss 5.341585 Test MSE 1.971358289439572 Test RE 0.6711055678566337\n",
      "64 Train Loss 5.324275 Test MSE 1.953036259330429 Test RE 0.6679796216050279\n",
      "65 Train Loss 5.3065434 Test MSE 1.94534951538663 Test RE 0.6666638113069326\n",
      "66 Train Loss 5.283535 Test MSE 1.9489173500373629 Test RE 0.6672748728780274\n",
      "67 Train Loss 5.2732887 Test MSE 1.9444659033237945 Test RE 0.66651238887929\n",
      "68 Train Loss 5.2666583 Test MSE 1.9505323130393262 Test RE 0.6675512830300411\n",
      "69 Train Loss 5.239322 Test MSE 1.961580737182168 Test RE 0.6694392228017226\n",
      "70 Train Loss 5.2255516 Test MSE 1.9657250534254511 Test RE 0.670146026237512\n",
      "71 Train Loss 5.2170277 Test MSE 1.9780452354004583 Test RE 0.6722428161058545\n",
      "72 Train Loss 5.2101765 Test MSE 1.9779611695453962 Test RE 0.6722285309756192\n",
      "73 Train Loss 5.186552 Test MSE 1.9891082775151259 Test RE 0.6741200939178662\n",
      "74 Train Loss 5.151111 Test MSE 2.009158758542815 Test RE 0.6775091856628992\n",
      "75 Train Loss 5.1364393 Test MSE 2.0213618384083456 Test RE 0.6795635735288211\n",
      "76 Train Loss 5.1326923 Test MSE 2.0250419743358914 Test RE 0.6801819064312549\n",
      "77 Train Loss 5.1233754 Test MSE 2.034996897462355 Test RE 0.6818517131480991\n",
      "78 Train Loss 5.109401 Test MSE 2.031345686404892 Test RE 0.6812397460660439\n",
      "79 Train Loss 5.096635 Test MSE 2.0390911519045156 Test RE 0.6825372846254063\n",
      "80 Train Loss 5.0812445 Test MSE 2.0470736509617464 Test RE 0.683871955570463\n",
      "81 Train Loss 5.072821 Test MSE 2.0573012477148294 Test RE 0.6855782087933124\n",
      "82 Train Loss 5.056712 Test MSE 2.0678049298291152 Test RE 0.6873261121579909\n",
      "83 Train Loss 5.033775 Test MSE 2.065786346318201 Test RE 0.686990547641774\n",
      "84 Train Loss 5.0161276 Test MSE 2.066512092646388 Test RE 0.6871112128514208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 Train Loss 5.006655 Test MSE 2.075627307291201 Test RE 0.6886249409406517\n",
      "86 Train Loss 4.988309 Test MSE 2.0793388130211232 Test RE 0.6892403437828628\n",
      "87 Train Loss 4.967614 Test MSE 2.0894960168132357 Test RE 0.6909217018289933\n",
      "88 Train Loss 4.961775 Test MSE 2.0929578911730493 Test RE 0.6914938240553998\n",
      "89 Train Loss 4.95212 Test MSE 2.1024468825053018 Test RE 0.6930595886052583\n",
      "90 Train Loss 4.945063 Test MSE 2.1070843892938806 Test RE 0.6938235313604033\n",
      "91 Train Loss 4.932679 Test MSE 2.103530470994897 Test RE 0.6932381649726042\n",
      "92 Train Loss 4.905778 Test MSE 2.0991964035752875 Test RE 0.692523630478089\n",
      "93 Train Loss 4.895193 Test MSE 2.0971313108019185 Test RE 0.6921829102295503\n",
      "94 Train Loss 4.8900127 Test MSE 2.104559958172718 Test RE 0.6934077827919916\n",
      "95 Train Loss 4.886206 Test MSE 2.1077607532822626 Test RE 0.6939348794393874\n",
      "96 Train Loss 4.8791747 Test MSE 2.105664263600469 Test RE 0.6935896815192064\n",
      "97 Train Loss 4.875231 Test MSE 2.105978670376922 Test RE 0.6936414611785003\n",
      "98 Train Loss 4.8629603 Test MSE 2.1112019495951517 Test RE 0.6945011183430468\n",
      "99 Train Loss 4.8524404 Test MSE 2.1085025765449257 Test RE 0.6940569833711917\n",
      "Training time: 81.05\n",
      "KG_stan_tune0\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.861958 Test MSE 8.637519177258635 Test RE 1.404761423919938\n",
      "1 Train Loss 57.175514 Test MSE 8.428317883181347 Test RE 1.387645443150163\n",
      "2 Train Loss 54.2814 Test MSE 8.875195885117773 Test RE 1.4239575213131286\n",
      "3 Train Loss 46.46489 Test MSE 8.882036643183516 Test RE 1.4245061893500985\n",
      "4 Train Loss 46.3059 Test MSE 8.632358937793178 Test RE 1.4043417439066763\n",
      "5 Train Loss 45.825016 Test MSE 8.75772493434565 Test RE 1.4145024713738992\n",
      "6 Train Loss 45.748764 Test MSE 8.642377042329615 Test RE 1.4051563974120473\n",
      "7 Train Loss 45.226017 Test MSE 8.659772756019134 Test RE 1.4065698633089292\n",
      "8 Train Loss 45.105145 Test MSE 8.675686932978403 Test RE 1.4078617059330278\n",
      "9 Train Loss 44.75573 Test MSE 8.4733319704016 Test RE 1.3913460874675825\n",
      "10 Train Loss 44.6847 Test MSE 8.511922806022953 Test RE 1.394510852653565\n",
      "11 Train Loss 44.587135 Test MSE 8.472618706663694 Test RE 1.3912875262310005\n",
      "12 Train Loss 44.34089 Test MSE 8.46265255708733 Test RE 1.3904690154511048\n",
      "13 Train Loss 44.3099 Test MSE 8.465902124557285 Test RE 1.3907359523941574\n",
      "14 Train Loss 44.28042 Test MSE 8.45028664316957 Test RE 1.3894527439041693\n",
      "15 Train Loss 44.190666 Test MSE 8.462908436287302 Test RE 1.3904900366030102\n",
      "16 Train Loss 44.163963 Test MSE 8.413275554633973 Test RE 1.3864065992514105\n",
      "17 Train Loss 43.965 Test MSE 8.40405455643296 Test RE 1.3856466361761381\n",
      "18 Train Loss 43.289604 Test MSE 8.506083350456777 Test RE 1.3940324307125003\n",
      "19 Train Loss 41.269455 Test MSE 8.241631769619401 Test RE 1.3721913067236833\n",
      "20 Train Loss 39.527287 Test MSE 7.843262053308138 Test RE 1.3386172680628865\n",
      "21 Train Loss 37.212605 Test MSE 7.354528451383319 Test RE 1.2962401715759804\n",
      "22 Train Loss 35.386337 Test MSE 7.228034521987754 Test RE 1.2850445064263936\n",
      "23 Train Loss 34.481724 Test MSE 7.176059248171392 Test RE 1.2804159284425258\n",
      "24 Train Loss 33.828217 Test MSE 7.1987601698124175 Test RE 1.282439578849191\n",
      "25 Train Loss 33.111595 Test MSE 6.995991118924615 Test RE 1.2642491928280462\n",
      "26 Train Loss 32.815033 Test MSE 7.086707477654068 Test RE 1.2724194924372345\n",
      "27 Train Loss 32.22021 Test MSE 6.956362790977139 Test RE 1.260663479984246\n",
      "28 Train Loss 31.904072 Test MSE 6.979298640934069 Test RE 1.2627400388891175\n",
      "29 Train Loss 31.26588 Test MSE 7.081937487542952 Test RE 1.271991194100057\n",
      "30 Train Loss 30.227203 Test MSE 7.144282837154133 Test RE 1.277577869063008\n",
      "31 Train Loss 29.511562 Test MSE 7.027590146281146 Test RE 1.2671011144458675\n",
      "32 Train Loss 27.651327 Test MSE 6.783497261897528 Test RE 1.2449012049533206\n",
      "33 Train Loss 24.54935 Test MSE 6.82388601499811 Test RE 1.2486017583699227\n",
      "34 Train Loss 21.640663 Test MSE 6.704538427885458 Test RE 1.2376347715754958\n",
      "35 Train Loss 19.52682 Test MSE 6.22053013579782 Test RE 1.1921249007276309\n",
      "36 Train Loss 18.135838 Test MSE 6.501541302948034 Test RE 1.2187544746458092\n",
      "37 Train Loss 17.268553 Test MSE 6.272684794020524 Test RE 1.1971120228888144\n",
      "38 Train Loss 15.390446 Test MSE 5.7408467405444865 Test RE 1.1452387565570838\n",
      "39 Train Loss 13.844499 Test MSE 5.0928152196064325 Test RE 1.0786660746258818\n",
      "40 Train Loss 10.583578 Test MSE 4.716278287789899 Test RE 1.0380249009140405\n",
      "41 Train Loss 8.6177 Test MSE 4.23625813543619 Test RE 0.9837828972503462\n",
      "42 Train Loss 7.2586746 Test MSE 3.898901005268638 Test RE 0.9437982429364116\n",
      "43 Train Loss 6.364386 Test MSE 3.692340691844354 Test RE 0.9184572433354447\n",
      "44 Train Loss 5.5919957 Test MSE 3.7463619387801943 Test RE 0.9251516475386135\n",
      "45 Train Loss 5.300426 Test MSE 3.6901703221891733 Test RE 0.9181872676054761\n",
      "46 Train Loss 4.9957085 Test MSE 3.6021228463069135 Test RE 0.9071671602032241\n",
      "47 Train Loss 4.616677 Test MSE 3.308500967077932 Test RE 0.869408122389183\n",
      "48 Train Loss 4.4502277 Test MSE 3.2251080864822153 Test RE 0.8583812001891135\n",
      "49 Train Loss 4.2547464 Test MSE 3.1653497440602245 Test RE 0.85039150215876\n",
      "50 Train Loss 3.991687 Test MSE 3.021338000935834 Test RE 0.8308214811228884\n",
      "51 Train Loss 3.7092874 Test MSE 2.6448989845820914 Test RE 0.7773428445268107\n",
      "52 Train Loss 2.9346337 Test MSE 1.9775368519201697 Test RE 0.6721564229591838\n",
      "53 Train Loss 2.1703851 Test MSE 1.8966978192952357 Test RE 0.6582746528505616\n",
      "54 Train Loss 1.8713531 Test MSE 1.9558567248869128 Test RE 0.6684617769670155\n",
      "55 Train Loss 1.5666839 Test MSE 1.8961259327347697 Test RE 0.6581754048826833\n",
      "56 Train Loss 1.3656993 Test MSE 1.8212092301746745 Test RE 0.6450419825952253\n",
      "57 Train Loss 1.2310047 Test MSE 1.7451198987006815 Test RE 0.6314234336461035\n",
      "58 Train Loss 1.0991447 Test MSE 1.8060158768274726 Test RE 0.6423457311016394\n",
      "59 Train Loss 1.0057459 Test MSE 1.7478565949034848 Test RE 0.6319183386602116\n",
      "60 Train Loss 0.9331357 Test MSE 1.7516652408029312 Test RE 0.6326064510377412\n",
      "61 Train Loss 0.87395906 Test MSE 1.7616095459420282 Test RE 0.6343995814646236\n",
      "62 Train Loss 0.8193332 Test MSE 1.6985755290521187 Test RE 0.6229461294764224\n",
      "63 Train Loss 0.7626282 Test MSE 1.7054007210501707 Test RE 0.6241964313816885\n",
      "64 Train Loss 0.7415648 Test MSE 1.695291790626589 Test RE 0.6223436888682199\n",
      "65 Train Loss 0.7106971 Test MSE 1.6726007704522914 Test RE 0.6181647075049012\n",
      "66 Train Loss 0.681996 Test MSE 1.6874589809868472 Test RE 0.620904307341201\n",
      "67 Train Loss 0.6601 Test MSE 1.7006192115718057 Test RE 0.6233207732241958\n",
      "68 Train Loss 0.6390109 Test MSE 1.6721111826901658 Test RE 0.6180742292415684\n",
      "69 Train Loss 0.6256533 Test MSE 1.6432689436175862 Test RE 0.6127204620920857\n",
      "70 Train Loss 0.6054002 Test MSE 1.629748265411474 Test RE 0.610194549481567\n",
      "71 Train Loss 0.58529085 Test MSE 1.6435218900277193 Test RE 0.6127676179390277\n",
      "72 Train Loss 0.5734317 Test MSE 1.644801869191713 Test RE 0.6130061840141141\n",
      "73 Train Loss 0.5587274 Test MSE 1.6379058637955053 Test RE 0.6117197877043441\n",
      "74 Train Loss 0.53843707 Test MSE 1.6394666370466429 Test RE 0.6120111745790923\n",
      "75 Train Loss 0.520983 Test MSE 1.6271984448262005 Test RE 0.609717023075199\n",
      "76 Train Loss 0.5050687 Test MSE 1.615167727609925 Test RE 0.6074588652149213\n",
      "77 Train Loss 0.49244523 Test MSE 1.6113193303125724 Test RE 0.6067347493262333\n",
      "78 Train Loss 0.48634756 Test MSE 1.6122322567073717 Test RE 0.6069066040674465\n",
      "79 Train Loss 0.47379583 Test MSE 1.5988583281865842 Test RE 0.6043841299237139\n",
      "80 Train Loss 0.45815215 Test MSE 1.5728828333704046 Test RE 0.5994545301191055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 Train Loss 0.43311304 Test MSE 1.5716298224693381 Test RE 0.5992157098150669\n",
      "82 Train Loss 0.42443088 Test MSE 1.5596815078636843 Test RE 0.5969335955933059\n",
      "83 Train Loss 0.40945736 Test MSE 1.520052944482594 Test RE 0.589301325265502\n",
      "84 Train Loss 0.3913009 Test MSE 1.479017320172525 Test RE 0.5812924606674831\n",
      "85 Train Loss 0.37134796 Test MSE 1.351512926544463 Test RE 0.5556715505565073\n",
      "86 Train Loss 0.36035684 Test MSE 1.291133140057801 Test RE 0.543117222290071\n",
      "87 Train Loss 0.3392502 Test MSE 1.103456578170445 Test RE 0.5020947545804195\n",
      "88 Train Loss 0.30153567 Test MSE 0.9368035059226025 Test RE 0.46262842566366985\n",
      "89 Train Loss 0.2775956 Test MSE 0.8158529429612621 Test RE 0.4317317641339262\n",
      "90 Train Loss 0.25524053 Test MSE 0.769746266067173 Test RE 0.41935502917056466\n",
      "91 Train Loss 0.22589925 Test MSE 0.6877407281419549 Test RE 0.39638793965000546\n",
      "92 Train Loss 0.20509152 Test MSE 0.6452371555628311 Test RE 0.3839438754745038\n",
      "93 Train Loss 0.188286 Test MSE 0.5619746916305403 Test RE 0.3583161962222764\n",
      "94 Train Loss 0.17977431 Test MSE 0.5120306780281128 Test RE 0.3420235823041972\n",
      "95 Train Loss 0.16991168 Test MSE 0.5112148622409504 Test RE 0.34175100149782134\n",
      "96 Train Loss 0.15966254 Test MSE 0.43649248674720853 Test RE 0.3157885990853523\n",
      "97 Train Loss 0.14921641 Test MSE 0.35852122322580166 Test RE 0.28619727545035517\n",
      "98 Train Loss 0.13851216 Test MSE 0.35938907037543105 Test RE 0.28654345490782823\n",
      "99 Train Loss 0.13282777 Test MSE 0.3926255465439385 Test RE 0.2995003520754003\n",
      "Training time: 79.71\n",
      "KG_stan_tune0\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.057434 Test MSE 8.494815350132374 Test RE 1.3931087880228112\n",
      "1 Train Loss 58.36418 Test MSE 8.886047767834024 Test RE 1.4248278062928337\n",
      "2 Train Loss 57.76976 Test MSE 8.497997108343347 Test RE 1.3933696601056813\n",
      "3 Train Loss 51.716427 Test MSE 8.334835973884378 Test RE 1.3799285149570089\n",
      "4 Train Loss 47.928574 Test MSE 8.581405119933686 Test RE 1.4001909387707028\n",
      "5 Train Loss 46.18857 Test MSE 8.583801319789915 Test RE 1.400386413934551\n",
      "6 Train Loss 45.94462 Test MSE 8.483047587894877 Test RE 1.3921435254614172\n",
      "7 Train Loss 45.905994 Test MSE 8.4333920594605 Test RE 1.3880630886545846\n",
      "8 Train Loss 45.781 Test MSE 8.422621667102383 Test RE 1.387176448958995\n",
      "9 Train Loss 45.483 Test MSE 8.370361040682724 Test RE 1.3828661809121479\n",
      "10 Train Loss 45.029892 Test MSE 8.39633509947394 Test RE 1.3850101043151708\n",
      "11 Train Loss 44.678665 Test MSE 8.347537061999063 Test RE 1.3809795207474973\n",
      "12 Train Loss 43.297268 Test MSE 8.114904132188803 Test RE 1.3616006718815974\n",
      "13 Train Loss 42.442215 Test MSE 7.700176044973083 Test RE 1.3263507504329872\n",
      "14 Train Loss 41.779823 Test MSE 7.8178810918543 Test RE 1.3364496161416186\n",
      "15 Train Loss 40.54975 Test MSE 7.940360409112142 Test RE 1.3468777169977246\n",
      "16 Train Loss 40.172592 Test MSE 7.842375811008571 Test RE 1.338541638002839\n",
      "17 Train Loss 40.06517 Test MSE 7.845956710450038 Test RE 1.3388471982113554\n",
      "18 Train Loss 39.867836 Test MSE 7.898387076881587 Test RE 1.3433131525182684\n",
      "19 Train Loss 39.75395 Test MSE 7.803502820943788 Test RE 1.3352200836278225\n",
      "20 Train Loss 39.567486 Test MSE 7.627462718155062 Test RE 1.3200734824275757\n",
      "21 Train Loss 39.145443 Test MSE 7.648242292232723 Test RE 1.3218704042082854\n",
      "22 Train Loss 39.0308 Test MSE 7.671885126887691 Test RE 1.3239119613878227\n",
      "23 Train Loss 38.701893 Test MSE 7.807038554090293 Test RE 1.3355225405739468\n",
      "24 Train Loss 38.509735 Test MSE 7.722055234691866 Test RE 1.328233752514044\n",
      "25 Train Loss 38.16582 Test MSE 7.764906972823528 Test RE 1.3319140150530295\n",
      "26 Train Loss 37.867897 Test MSE 7.952087869589106 Test RE 1.3478719808872535\n",
      "27 Train Loss 37.028934 Test MSE 7.8132638084671475 Test RE 1.336054900621572\n",
      "28 Train Loss 36.281906 Test MSE 7.755774246632862 Test RE 1.3311305166259078\n",
      "29 Train Loss 35.428886 Test MSE 7.971375973605235 Test RE 1.349505649286861\n",
      "30 Train Loss 34.62667 Test MSE 8.060542928256767 Test RE 1.3570323720977593\n",
      "31 Train Loss 33.817337 Test MSE 8.043473420530413 Test RE 1.3555947424563957\n",
      "32 Train Loss 33.283375 Test MSE 8.024555923138992 Test RE 1.3539996880089415\n",
      "33 Train Loss 33.075863 Test MSE 8.235346787616828 Test RE 1.3716679975832204\n",
      "34 Train Loss 32.899757 Test MSE 8.175747264383986 Test RE 1.3666955776721421\n",
      "35 Train Loss 32.85919 Test MSE 8.182153809920838 Test RE 1.3672309466465769\n",
      "36 Train Loss 32.67105 Test MSE 8.334071916791357 Test RE 1.379865264262146\n",
      "37 Train Loss 32.515778 Test MSE 8.30742559972832 Test RE 1.3776575940865665\n",
      "38 Train Loss 32.33548 Test MSE 8.452912878468526 Test RE 1.3896686387325383\n",
      "39 Train Loss 32.09159 Test MSE 8.288221074838038 Test RE 1.376064286542156\n",
      "40 Train Loss 31.49879 Test MSE 8.362973583096831 Test RE 1.3822558057881456\n",
      "41 Train Loss 31.093914 Test MSE 8.510129029266212 Test RE 1.3943639074208645\n",
      "42 Train Loss 30.773182 Test MSE 8.568552191083569 Test RE 1.3991419673047907\n",
      "43 Train Loss 30.298618 Test MSE 8.621198704080872 Test RE 1.4034336577709796\n",
      "44 Train Loss 29.883657 Test MSE 8.491354402278674 Test RE 1.392824969725336\n",
      "45 Train Loss 29.354965 Test MSE 8.490368987236812 Test RE 1.3927441492559014\n",
      "46 Train Loss 28.993109 Test MSE 8.276550707541173 Test RE 1.3750951501868582\n",
      "47 Train Loss 28.53709 Test MSE 8.338785694516408 Test RE 1.3802554372020317\n",
      "48 Train Loss 27.852322 Test MSE 8.116510189456768 Test RE 1.3617354054797974\n",
      "49 Train Loss 26.633768 Test MSE 7.962519041280652 Test RE 1.348755728434484\n",
      "50 Train Loss 26.241352 Test MSE 7.766771640498963 Test RE 1.3320739286189698\n",
      "51 Train Loss 24.88682 Test MSE 7.813688333111684 Test RE 1.336091196626769\n",
      "52 Train Loss 24.145155 Test MSE 7.953906961896881 Test RE 1.3480261393539534\n",
      "53 Train Loss 23.378874 Test MSE 7.667513958307421 Test RE 1.3235347485632807\n",
      "54 Train Loss 22.108047 Test MSE 7.492679551629368 Test RE 1.3083581371497353\n",
      "55 Train Loss 21.237507 Test MSE 7.313953482586913 Test RE 1.2926595445346603\n",
      "56 Train Loss 20.084429 Test MSE 6.850513349224916 Test RE 1.2510354571710405\n",
      "57 Train Loss 19.465246 Test MSE 6.778480285710539 Test RE 1.2444407643662165\n",
      "58 Train Loss 18.556013 Test MSE 6.356857447210295 Test RE 1.205117232085695\n",
      "59 Train Loss 18.07404 Test MSE 6.177017661643597 Test RE 1.1879481398354714\n",
      "60 Train Loss 17.628456 Test MSE 6.164601753813506 Test RE 1.1867536415727469\n",
      "61 Train Loss 16.981739 Test MSE 5.869789279538962 Test RE 1.1580286807509488\n",
      "62 Train Loss 16.641567 Test MSE 5.9026694437390335 Test RE 1.1612675534248533\n",
      "63 Train Loss 16.084375 Test MSE 5.810084143577327 Test RE 1.1521241266729592\n",
      "64 Train Loss 15.70327 Test MSE 5.583407634528691 Test RE 1.1294258624324436\n",
      "65 Train Loss 15.433381 Test MSE 5.6063872328206115 Test RE 1.1317476616545177\n",
      "66 Train Loss 15.104008 Test MSE 5.5636612929931 Test RE 1.1274269234666685\n",
      "67 Train Loss 14.728054 Test MSE 5.610994299520844 Test RE 1.1322125747996126\n",
      "68 Train Loss 14.25856 Test MSE 5.6876095220028215 Test RE 1.1399162548154649\n",
      "69 Train Loss 13.991203 Test MSE 5.517792303308553 Test RE 1.1227698316438632\n",
      "70 Train Loss 13.548346 Test MSE 5.234237444559792 Test RE 1.093540243691756\n",
      "71 Train Loss 12.975391 Test MSE 4.859520936205364 Test RE 1.0536704221826192\n",
      "72 Train Loss 12.131971 Test MSE 4.365999369443949 Test RE 0.9987341373986951\n",
      "73 Train Loss 11.195373 Test MSE 4.076738136125964 Test RE 0.9650825616184114\n",
      "74 Train Loss 10.226953 Test MSE 4.073197053826699 Test RE 0.9646633319442476\n",
      "75 Train Loss 9.8617325 Test MSE 3.8582343916757607 Test RE 0.9388633029265373\n",
      "76 Train Loss 9.691544 Test MSE 3.8243530770037317 Test RE 0.9347318708683954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 Train Loss 9.598218 Test MSE 3.8142523504289105 Test RE 0.933496666742071\n",
      "78 Train Loss 9.430183 Test MSE 3.737105679946146 Test RE 0.9240080395143995\n",
      "79 Train Loss 9.301788 Test MSE 3.618383032992204 Test RE 0.9092123567569984\n",
      "80 Train Loss 9.190503 Test MSE 3.5852804679998163 Test RE 0.9050438630824184\n",
      "81 Train Loss 9.132055 Test MSE 3.604092718858711 Test RE 0.9074151749877889\n",
      "82 Train Loss 9.051478 Test MSE 3.5770956013879216 Test RE 0.9040102067269217\n",
      "83 Train Loss 9.00051 Test MSE 3.5516723174853984 Test RE 0.9007919687010605\n",
      "84 Train Loss 8.931043 Test MSE 3.526990411151052 Test RE 0.8976565408468978\n",
      "85 Train Loss 8.889365 Test MSE 3.520566866254984 Test RE 0.8968387381011802\n",
      "86 Train Loss 8.859829 Test MSE 3.5176101223267144 Test RE 0.8964620545173\n",
      "87 Train Loss 8.809282 Test MSE 3.4854597048834166 Test RE 0.8923558876486758\n",
      "88 Train Loss 8.7899 Test MSE 3.491952271009627 Test RE 0.8931866222653382\n",
      "89 Train Loss 8.754984 Test MSE 3.441445846892706 Test RE 0.8867037196859102\n",
      "90 Train Loss 8.708915 Test MSE 3.3994343555850723 Test RE 0.8812748775190671\n",
      "91 Train Loss 8.690657 Test MSE 3.418004718085195 Test RE 0.8836787045470222\n",
      "92 Train Loss 8.659629 Test MSE 3.4179508122202202 Test RE 0.8836717362048641\n",
      "93 Train Loss 8.629968 Test MSE 3.423464278015792 Test RE 0.8843841704907847\n",
      "94 Train Loss 8.589375 Test MSE 3.422871340341576 Test RE 0.8843075803239009\n",
      "95 Train Loss 8.564765 Test MSE 3.4227324798067063 Test RE 0.8842896426544984\n",
      "96 Train Loss 8.510949 Test MSE 3.4315092266822917 Test RE 0.8854226872854338\n",
      "97 Train Loss 8.480139 Test MSE 3.4286120279320187 Test RE 0.885048830329662\n",
      "98 Train Loss 8.367233 Test MSE 3.4261394369392595 Test RE 0.8847296401686401\n",
      "99 Train Loss 8.295969 Test MSE 3.4626603108884124 Test RE 0.8894325209534396\n",
      "Training time: 81.55\n",
      "KG_stan_tune0\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.748863 Test MSE 8.434721611635728 Test RE 1.388172500712877\n",
      "1 Train Loss 55.539818 Test MSE 8.543434313443232 Test RE 1.3970897379029312\n",
      "2 Train Loss 55.220818 Test MSE 8.554137293708099 Test RE 1.3979645818527522\n",
      "3 Train Loss 54.975 Test MSE 8.632201388564654 Test RE 1.404328928523913\n",
      "4 Train Loss 48.202263 Test MSE 8.700880590926184 Test RE 1.4099043956803077\n",
      "5 Train Loss 46.23896 Test MSE 7.48991912029424 Test RE 1.3081171041866546\n",
      "6 Train Loss 43.957672 Test MSE 7.471960848376543 Test RE 1.3065479536824212\n",
      "7 Train Loss 38.841263 Test MSE 7.409624796871903 Test RE 1.3010864943941083\n",
      "8 Train Loss 38.110184 Test MSE 7.398143373725601 Test RE 1.3000780684394457\n",
      "9 Train Loss 37.214893 Test MSE 7.1581644369170485 Test RE 1.2788184567158465\n",
      "10 Train Loss 36.24559 Test MSE 6.6634746954692385 Test RE 1.2338388383480354\n",
      "11 Train Loss 35.838543 Test MSE 6.896764626574998 Test RE 1.2552515391917807\n",
      "12 Train Loss 35.54546 Test MSE 6.967489669244246 Test RE 1.2616713086977227\n",
      "13 Train Loss 34.092415 Test MSE 6.436747542658324 Test RE 1.212666270765775\n",
      "14 Train Loss 33.379406 Test MSE 6.248347500610044 Test RE 1.1947874376393144\n",
      "15 Train Loss 30.473833 Test MSE 6.397077463283295 Test RE 1.2089236261198708\n",
      "16 Train Loss 29.847507 Test MSE 6.060510305670122 Test RE 1.1766916111879089\n",
      "17 Train Loss 28.711823 Test MSE 6.235145984071509 Test RE 1.193524596045104\n",
      "18 Train Loss 27.774406 Test MSE 6.008547572456699 Test RE 1.1716362828190614\n",
      "19 Train Loss 27.2305 Test MSE 5.771957987780219 Test RE 1.1483377475339476\n",
      "20 Train Loss 26.59475 Test MSE 5.599508649538742 Test RE 1.1310531671856665\n",
      "21 Train Loss 26.182816 Test MSE 5.661230034055193 Test RE 1.137269681137362\n",
      "22 Train Loss 25.513111 Test MSE 5.328141314468157 Test RE 1.103305867164215\n",
      "23 Train Loss 24.852137 Test MSE 5.2350219504065825 Test RE 1.0936221903536478\n",
      "24 Train Loss 24.118343 Test MSE 5.690094194593146 Test RE 1.1401652178816324\n",
      "25 Train Loss 23.191906 Test MSE 5.536362152121463 Test RE 1.1246575570433237\n",
      "26 Train Loss 22.500908 Test MSE 5.563698259048911 Test RE 1.127430668883145\n",
      "27 Train Loss 22.069412 Test MSE 5.492124380029759 Test RE 1.1201553110091866\n",
      "28 Train Loss 21.617466 Test MSE 5.375293536659278 Test RE 1.1081770529751154\n",
      "29 Train Loss 21.417389 Test MSE 5.529365712793027 Test RE 1.1239467034489414\n",
      "30 Train Loss 21.183046 Test MSE 5.5772528385658 Test RE 1.1288031869139805\n",
      "31 Train Loss 21.003021 Test MSE 5.5858964938709885 Test RE 1.1296775607775342\n",
      "32 Train Loss 20.832706 Test MSE 5.536328765329997 Test RE 1.124654165938939\n",
      "33 Train Loss 20.493706 Test MSE 5.460756536069833 Test RE 1.1169518901907354\n",
      "34 Train Loss 20.223263 Test MSE 5.313044792168841 Test RE 1.1017417291712643\n",
      "35 Train Loss 19.863121 Test MSE 5.045702461862139 Test RE 1.0736652050328284\n",
      "36 Train Loss 19.580078 Test MSE 5.296512994767434 Test RE 1.1000263322460866\n",
      "37 Train Loss 18.401405 Test MSE 4.950913919562092 Test RE 1.0635324562653812\n",
      "38 Train Loss 17.555023 Test MSE 4.837244630208637 Test RE 1.0512526071366801\n",
      "39 Train Loss 16.892712 Test MSE 4.9826885879449145 Test RE 1.0669398416461529\n",
      "40 Train Loss 16.570213 Test MSE 4.949041973145002 Test RE 1.0633313758156884\n",
      "41 Train Loss 16.150059 Test MSE 4.959815411067557 Test RE 1.064488115542904\n",
      "42 Train Loss 15.653606 Test MSE 5.028484554259495 Test RE 1.0718317570646307\n",
      "43 Train Loss 15.007865 Test MSE 5.046344047932676 Test RE 1.0737334637885654\n",
      "44 Train Loss 14.046843 Test MSE 5.041490926608668 Test RE 1.073217029298471\n",
      "45 Train Loss 13.090944 Test MSE 4.922501674261587 Test RE 1.0604763717623693\n",
      "46 Train Loss 12.664963 Test MSE 5.028760018626469 Test RE 1.0718611145589076\n",
      "47 Train Loss 11.794616 Test MSE 4.690193459810233 Test RE 1.0351503627481575\n",
      "48 Train Loss 10.944724 Test MSE 4.874778387762184 Test RE 1.0553232318611732\n",
      "49 Train Loss 10.207664 Test MSE 4.674210261314842 Test RE 1.033385069544636\n",
      "50 Train Loss 9.710772 Test MSE 4.408511736054965 Test RE 1.00358476747266\n",
      "51 Train Loss 9.250092 Test MSE 4.300434301993778 Test RE 0.9912066771072502\n",
      "52 Train Loss 8.983763 Test MSE 4.302861374280894 Test RE 0.9914863454788716\n",
      "53 Train Loss 8.681236 Test MSE 4.011179887100555 Test RE 0.9572913391622704\n",
      "54 Train Loss 8.171375 Test MSE 3.7999702170939718 Test RE 0.9317473294557368\n",
      "55 Train Loss 7.4530144 Test MSE 3.3684070505008137 Test RE 0.8772438740406808\n",
      "56 Train Loss 6.746791 Test MSE 3.01906514425647 Test RE 0.8305089220149703\n",
      "57 Train Loss 6.0867305 Test MSE 2.7248206608184424 Test RE 0.7890000343256239\n",
      "58 Train Loss 5.7947545 Test MSE 2.536007671796939 Test RE 0.7611729421727786\n",
      "59 Train Loss 5.41659 Test MSE 2.3774849675807577 Test RE 0.7369990874291273\n",
      "60 Train Loss 5.125406 Test MSE 2.2085144530642595 Test RE 0.7103267715736473\n",
      "61 Train Loss 5.001152 Test MSE 2.1923611809850825 Test RE 0.7077243074328144\n",
      "62 Train Loss 4.893806 Test MSE 2.199867014949298 Test RE 0.7089347654365403\n",
      "63 Train Loss 4.8108726 Test MSE 2.2137641592848594 Test RE 0.7111705046778793\n",
      "64 Train Loss 4.716909 Test MSE 2.2008881401645493 Test RE 0.709099281558197\n",
      "65 Train Loss 4.645794 Test MSE 2.1734164163063703 Test RE 0.7046598577429902\n",
      "66 Train Loss 4.5360723 Test MSE 2.1861867746505683 Test RE 0.7067270131672377\n",
      "67 Train Loss 4.374071 Test MSE 2.1805035735785583 Test RE 0.7058078132470424\n",
      "68 Train Loss 4.212422 Test MSE 2.159992303413935 Test RE 0.7024803202074501\n",
      "69 Train Loss 3.9520967 Test MSE 2.279251328913186 Test RE 0.721612701112713\n",
      "70 Train Loss 3.6610346 Test MSE 2.2640548101975457 Test RE 0.7192030632521863\n",
      "71 Train Loss 3.367817 Test MSE 2.280191612116792 Test RE 0.7217615329525664\n",
      "72 Train Loss 3.1509957 Test MSE 2.280617464191031 Test RE 0.721828928450097\n",
      "73 Train Loss 2.919221 Test MSE 2.2617037145385033 Test RE 0.718829539960941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Train Loss 2.6809103 Test MSE 2.233493717875978 Test RE 0.7143325299981323\n",
      "75 Train Loss 2.59698 Test MSE 2.2261282807419223 Test RE 0.7131537229793791\n",
      "76 Train Loss 2.5327756 Test MSE 2.228354969957044 Test RE 0.7135103005456694\n",
      "77 Train Loss 2.4389389 Test MSE 2.2227740945611623 Test RE 0.7126162534837421\n",
      "78 Train Loss 2.3352532 Test MSE 2.201584949908124 Test RE 0.7092115244697412\n",
      "79 Train Loss 2.2325864 Test MSE 2.1794820382860163 Test RE 0.7056424633560839\n",
      "80 Train Loss 2.116065 Test MSE 2.1457979108861314 Test RE 0.7001683404349568\n",
      "81 Train Loss 2.012326 Test MSE 2.1693887930950706 Test RE 0.7040066418103158\n",
      "82 Train Loss 1.9535513 Test MSE 2.1691887791208466 Test RE 0.703974186951937\n",
      "83 Train Loss 1.8665247 Test MSE 2.153300139497406 Test RE 0.7013912514214394\n",
      "84 Train Loss 1.7594006 Test MSE 2.139273184401909 Test RE 0.6991030292588583\n",
      "85 Train Loss 1.6787479 Test MSE 2.0848331888067295 Test RE 0.6901503559238837\n",
      "86 Train Loss 1.6351094 Test MSE 2.043323371590706 Test RE 0.6832452349310562\n",
      "87 Train Loss 1.5720241 Test MSE 2.008613725362382 Test RE 0.6774172840072713\n",
      "88 Train Loss 1.4882662 Test MSE 1.9296748127085561 Test RE 0.6639725488950031\n",
      "89 Train Loss 1.4392315 Test MSE 1.9169309059994215 Test RE 0.6617764221272374\n",
      "90 Train Loss 1.3684698 Test MSE 1.828188297742583 Test RE 0.64627673555879\n",
      "91 Train Loss 1.3083625 Test MSE 1.6872124398877006 Test RE 0.6208589480098644\n",
      "92 Train Loss 1.2269077 Test MSE 1.5100621940473575 Test RE 0.587361501848793\n",
      "93 Train Loss 1.1159033 Test MSE 1.2945546246684358 Test RE 0.5438363726600979\n",
      "94 Train Loss 1.0025076 Test MSE 1.0316548144741127 Test RE 0.4854843838627165\n",
      "95 Train Loss 0.90936077 Test MSE 0.7885282077059848 Test RE 0.4244403628854823\n",
      "96 Train Loss 0.8097844 Test MSE 0.6713003726720399 Test RE 0.3916214800636679\n",
      "97 Train Loss 0.70050645 Test MSE 0.5564814943809101 Test RE 0.3565606588552258\n",
      "98 Train Loss 0.64772254 Test MSE 0.5244555542530932 Test RE 0.3461484608547839\n",
      "99 Train Loss 0.5548418 Test MSE 0.4299147382060458 Test RE 0.31340016958949524\n",
      "Training time: 80.72\n",
      "KG_stan_tune0\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 58.082497 Test MSE 8.50461641310565 Test RE 1.3939122198979748\n",
      "1 Train Loss 56.602123 Test MSE 8.517175234005709 Test RE 1.3949410397219024\n",
      "2 Train Loss 52.489777 Test MSE 8.331735829040399 Test RE 1.3796718586678545\n",
      "3 Train Loss 48.03673 Test MSE 8.056319369964449 Test RE 1.3566767970221374\n",
      "4 Train Loss 44.04258 Test MSE 8.362088431164922 Test RE 1.3821826536514712\n",
      "5 Train Loss 43.108925 Test MSE 8.30483717970158 Test RE 1.3774429527228635\n",
      "6 Train Loss 42.78945 Test MSE 8.157612777192462 Test RE 1.365179014027756\n",
      "7 Train Loss 42.507195 Test MSE 8.371479739176692 Test RE 1.3829585878358408\n",
      "8 Train Loss 42.0366 Test MSE 8.242244486968525 Test RE 1.3722423129938939\n",
      "9 Train Loss 41.792046 Test MSE 8.274483770119822 Test RE 1.3749234353507342\n",
      "10 Train Loss 41.328167 Test MSE 8.305786740492671 Test RE 1.3775216977004034\n",
      "11 Train Loss 40.96357 Test MSE 8.378595806043013 Test RE 1.3835462459099213\n",
      "12 Train Loss 40.760464 Test MSE 8.275352692892925 Test RE 1.3749956254084146\n",
      "13 Train Loss 40.178463 Test MSE 8.26011946407006 Test RE 1.373729499854486\n",
      "14 Train Loss 39.17618 Test MSE 8.155687750710316 Test RE 1.3650179276362104\n",
      "15 Train Loss 38.80672 Test MSE 8.041803795911852 Test RE 1.3554540413126486\n",
      "16 Train Loss 38.19583 Test MSE 7.84703731681016 Test RE 1.33893939327688\n",
      "17 Train Loss 36.720203 Test MSE 6.968871671402039 Test RE 1.2617964287983596\n",
      "18 Train Loss 34.57231 Test MSE 7.04696089993103 Test RE 1.268846222841887\n",
      "19 Train Loss 32.12197 Test MSE 6.998329233075692 Test RE 1.2644604360917375\n",
      "20 Train Loss 30.781387 Test MSE 6.695321299810704 Test RE 1.2367837538924387\n",
      "21 Train Loss 27.009033 Test MSE 6.0767651934595435 Test RE 1.178268556130604\n",
      "22 Train Loss 25.094784 Test MSE 5.456482785788429 Test RE 1.1165147247747136\n",
      "23 Train Loss 24.50125 Test MSE 5.585051137392684 Test RE 1.1295920761664875\n",
      "24 Train Loss 23.855186 Test MSE 5.733637618343011 Test RE 1.144519458508609\n",
      "25 Train Loss 23.478338 Test MSE 5.6526034955514595 Test RE 1.1364028694328332\n",
      "26 Train Loss 23.034664 Test MSE 5.501105576505494 Test RE 1.121070824270796\n",
      "27 Train Loss 22.91015 Test MSE 5.518674774982052 Test RE 1.1228596114783804\n",
      "28 Train Loss 22.73048 Test MSE 5.60624409572722 Test RE 1.1317332141950396\n",
      "29 Train Loss 22.610264 Test MSE 5.730033824276507 Test RE 1.144159716488958\n",
      "30 Train Loss 22.587606 Test MSE 5.759845463386378 Test RE 1.1471322143450142\n",
      "31 Train Loss 22.484642 Test MSE 5.76774172833122 Test RE 1.147918256055238\n",
      "32 Train Loss 22.320316 Test MSE 5.598525097826386 Test RE 1.1309538282790224\n",
      "33 Train Loss 21.310808 Test MSE 5.086724196450944 Test RE 1.0780208376185607\n",
      "34 Train Loss 19.751328 Test MSE 4.824351054804488 Test RE 1.0498506262467486\n",
      "35 Train Loss 18.792843 Test MSE 4.824511046623828 Test RE 1.0498680344035403\n",
      "36 Train Loss 18.02298 Test MSE 4.7716352813225456 Test RE 1.0440990024287653\n",
      "37 Train Loss 17.622284 Test MSE 4.5324297029853415 Test RE 1.0175918002661057\n",
      "38 Train Loss 17.257376 Test MSE 4.447774948294465 Test RE 1.0080439384403999\n",
      "39 Train Loss 16.938368 Test MSE 4.278906199257021 Test RE 0.9887225591788004\n",
      "40 Train Loss 16.658829 Test MSE 4.163950715122834 Test RE 0.975350813516216\n",
      "41 Train Loss 15.632267 Test MSE 3.8138824970667073 Test RE 0.9334514068563784\n",
      "42 Train Loss 15.420901 Test MSE 3.956367995619635 Test RE 0.9507282533933251\n",
      "43 Train Loss 15.307152 Test MSE 3.885329352860017 Test RE 0.9421541812223349\n",
      "44 Train Loss 15.107916 Test MSE 3.719538838662808 Test RE 0.921833760263098\n",
      "45 Train Loss 14.882677 Test MSE 3.888748550222374 Test RE 0.9425686509336281\n",
      "46 Train Loss 14.228021 Test MSE 3.6189295492627123 Test RE 0.9092810173410809\n",
      "47 Train Loss 12.812515 Test MSE 3.6627134431109294 Test RE 0.9147649828703017\n",
      "48 Train Loss 11.439121 Test MSE 3.91624672738077 Test RE 0.9458953331730524\n",
      "49 Train Loss 10.446086 Test MSE 3.661705855604817 Test RE 0.9146391514096168\n",
      "50 Train Loss 9.876354 Test MSE 3.8176213351804202 Test RE 0.933908836887455\n",
      "51 Train Loss 9.351623 Test MSE 3.69660161435763 Test RE 0.9189870355588284\n",
      "52 Train Loss 9.04826 Test MSE 3.874988104542385 Test RE 0.9408995202709992\n",
      "53 Train Loss 8.656123 Test MSE 3.965212145627547 Test RE 0.9517902993751182\n",
      "54 Train Loss 8.450281 Test MSE 3.918292254759461 Test RE 0.946142330151217\n",
      "55 Train Loss 8.026697 Test MSE 3.902202607780058 Test RE 0.9441977641417971\n",
      "56 Train Loss 7.716414 Test MSE 3.9745540575757707 Test RE 0.9529108334042689\n",
      "57 Train Loss 7.5990057 Test MSE 3.902115298252121 Test RE 0.9441872011430912\n",
      "58 Train Loss 7.521144 Test MSE 3.8928465404993555 Test RE 0.9430651628621309\n",
      "59 Train Loss 7.4327326 Test MSE 3.9248285173173536 Test RE 0.9469311505595283\n",
      "60 Train Loss 7.3524294 Test MSE 3.916951988143214 Test RE 0.9459805005385244\n",
      "61 Train Loss 7.304552 Test MSE 3.9196136933694827 Test RE 0.9463018592941772\n",
      "62 Train Loss 7.245865 Test MSE 3.9279148105519677 Test RE 0.9473033875741282\n",
      "63 Train Loss 7.197111 Test MSE 3.9405855921720896 Test RE 0.9488300767394412\n",
      "64 Train Loss 7.1796575 Test MSE 3.930947964282099 Test RE 0.9476690729898166\n",
      "65 Train Loss 7.1388264 Test MSE 3.934287138564348 Test RE 0.9480714899764756\n",
      "66 Train Loss 7.097204 Test MSE 3.96026215950772 Test RE 0.9511960285172963\n",
      "67 Train Loss 7.0686007 Test MSE 3.9378273618927886 Test RE 0.9484979497106096\n",
      "68 Train Loss 7.024904 Test MSE 3.9465372348574808 Test RE 0.949546336645051\n",
      "69 Train Loss 6.979314 Test MSE 3.938092869597249 Test RE 0.9485299253719769\n",
      "70 Train Loss 6.96455 Test MSE 3.921159768086985 Test RE 0.9464884732373996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 Train Loss 6.9377685 Test MSE 3.9105674618713056 Test RE 0.9452092247485635\n",
      "72 Train Loss 6.911028 Test MSE 3.8787491571586163 Test RE 0.9413560267482635\n",
      "73 Train Loss 6.8985567 Test MSE 3.8677556950339538 Test RE 0.9400210467535326\n",
      "74 Train Loss 6.862487 Test MSE 3.8828181338471617 Test RE 0.9418496590440628\n",
      "75 Train Loss 6.845206 Test MSE 3.885665316541467 Test RE 0.9421949142871797\n",
      "76 Train Loss 6.822875 Test MSE 3.8461477409311544 Test RE 0.9373915657470704\n",
      "77 Train Loss 6.8025346 Test MSE 3.836609294589073 Test RE 0.9362284786506572\n",
      "78 Train Loss 6.781458 Test MSE 3.8355288407449533 Test RE 0.9360966405080959\n",
      "79 Train Loss 6.75961 Test MSE 3.8206087104583957 Test RE 0.9342741678543922\n",
      "80 Train Loss 6.747315 Test MSE 3.825016132838246 Test RE 0.9348128979789448\n",
      "81 Train Loss 6.723632 Test MSE 3.8099724363375866 Test RE 0.9329727885921179\n",
      "82 Train Loss 6.6370196 Test MSE 3.730377351526571 Test RE 0.9231758673857816\n",
      "83 Train Loss 6.5596395 Test MSE 3.798146377152464 Test RE 0.9315237011305958\n",
      "84 Train Loss 6.466363 Test MSE 3.7000895183323186 Test RE 0.9194204854042314\n",
      "85 Train Loss 5.253708 Test MSE 2.9106259296425634 Test RE 0.8154573607909997\n",
      "86 Train Loss 3.9223638 Test MSE 2.4492435585479786 Test RE 0.7480386668463044\n",
      "87 Train Loss 3.0934987 Test MSE 2.2408190547515527 Test RE 0.7155029928638947\n",
      "88 Train Loss 2.9560108 Test MSE 2.189361788515563 Test RE 0.7072400191890564\n",
      "89 Train Loss 2.8762825 Test MSE 2.203358322388763 Test RE 0.709497101238986\n",
      "90 Train Loss 2.8470714 Test MSE 2.193310597783093 Test RE 0.707877533238389\n",
      "91 Train Loss 2.7978854 Test MSE 2.1862154076324165 Test RE 0.7067316412337223\n",
      "92 Train Loss 2.7521646 Test MSE 2.179094253805879 Test RE 0.7055796848234277\n",
      "93 Train Loss 2.7285955 Test MSE 2.1632182179203596 Test RE 0.7030046961442169\n",
      "94 Train Loss 2.7075672 Test MSE 2.1600437155784213 Test RE 0.7024886803804951\n",
      "95 Train Loss 2.694249 Test MSE 2.1624419529583294 Test RE 0.702878549166679\n",
      "96 Train Loss 2.682703 Test MSE 2.1473914111225922 Test RE 0.700428269701862\n",
      "97 Train Loss 2.6669161 Test MSE 2.1429261324777973 Test RE 0.6996996566144975\n",
      "98 Train Loss 2.651488 Test MSE 2.151083600161484 Test RE 0.7010301634439644\n",
      "99 Train Loss 2.6428306 Test MSE 2.159368814266397 Test RE 0.7023789262194661\n",
      "Training time: 80.92\n",
      "KG_stan_tune0\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.7457 Test MSE 8.469422367395643 Test RE 1.3910250662642336\n",
      "1 Train Loss 56.35211 Test MSE 8.408608633970804 Test RE 1.3860220197205764\n",
      "2 Train Loss 55.485657 Test MSE 8.455811219169686 Test RE 1.3899068635927643\n",
      "3 Train Loss 47.593773 Test MSE 8.850674964407379 Test RE 1.4219890633308292\n",
      "4 Train Loss 44.061188 Test MSE 8.310698541170558 Test RE 1.3779289506311099\n",
      "5 Train Loss 43.67662 Test MSE 8.505837352950076 Test RE 1.3940122727286484\n",
      "6 Train Loss 43.598076 Test MSE 8.514936288027592 Test RE 1.3947576806372401\n",
      "7 Train Loss 43.540863 Test MSE 8.473542193543567 Test RE 1.3913633469903373\n",
      "8 Train Loss 43.354294 Test MSE 8.479293353939829 Test RE 1.391835439787237\n",
      "9 Train Loss 43.280266 Test MSE 8.519676176013997 Test RE 1.3951458265490069\n",
      "10 Train Loss 43.198044 Test MSE 8.472378622747105 Test RE 1.391267814018267\n",
      "11 Train Loss 43.135708 Test MSE 8.425961418322837 Test RE 1.3874514443974004\n",
      "12 Train Loss 42.974785 Test MSE 8.5230491274282 Test RE 1.3954219692878587\n",
      "13 Train Loss 42.788033 Test MSE 8.413176636342364 Test RE 1.3863984489552215\n",
      "14 Train Loss 42.57775 Test MSE 8.384376865692808 Test RE 1.3840234729035608\n",
      "15 Train Loss 42.352146 Test MSE 8.357707002569047 Test RE 1.3818204996194219\n",
      "16 Train Loss 41.510155 Test MSE 8.568016018179776 Test RE 1.3990981913126148\n",
      "17 Train Loss 40.439728 Test MSE 7.9738277076005755 Test RE 1.3497131651863044\n",
      "18 Train Loss 39.26014 Test MSE 7.88738694013272 Test RE 1.3423774059732119\n",
      "19 Train Loss 38.961426 Test MSE 7.969888634107534 Test RE 1.3493797446314382\n",
      "20 Train Loss 38.732796 Test MSE 7.818811402424565 Test RE 1.336529131051364\n",
      "21 Train Loss 38.57299 Test MSE 7.978640911531647 Test RE 1.3501204642208398\n",
      "22 Train Loss 38.01525 Test MSE 8.038029223719148 Test RE 1.3551359000251468\n",
      "23 Train Loss 37.743214 Test MSE 7.913367244039041 Test RE 1.3445864202759439\n",
      "24 Train Loss 37.30843 Test MSE 8.17679598412196 Test RE 1.3667832292728004\n",
      "25 Train Loss 36.53933 Test MSE 7.900061338903035 Test RE 1.3434555194976776\n",
      "26 Train Loss 35.82364 Test MSE 7.638609637916468 Test RE 1.3210377205727313\n",
      "27 Train Loss 35.26193 Test MSE 7.97081644312713 Test RE 1.3494582858959914\n",
      "28 Train Loss 34.764984 Test MSE 8.075503240013946 Test RE 1.3582911096507644\n",
      "29 Train Loss 33.907238 Test MSE 8.207505499365372 Test RE 1.3693474313571123\n",
      "30 Train Loss 32.504272 Test MSE 8.188519662415962 Test RE 1.3677627075073937\n",
      "31 Train Loss 31.202381 Test MSE 8.306667022851478 Test RE 1.377594693550141\n",
      "32 Train Loss 29.109138 Test MSE 8.109573296307136 Test RE 1.3611533676344652\n",
      "33 Train Loss 28.62441 Test MSE 8.229298584840866 Test RE 1.3711642149147811\n",
      "34 Train Loss 27.397123 Test MSE 8.242169013978252 Test RE 1.3722360302715118\n",
      "35 Train Loss 26.615667 Test MSE 8.345651915321364 Test RE 1.3808235767886337\n",
      "36 Train Loss 25.922548 Test MSE 8.466445301864352 Test RE 1.3907805669007836\n",
      "37 Train Loss 25.407286 Test MSE 8.505036115303586 Test RE 1.3939466142066892\n",
      "38 Train Loss 25.037418 Test MSE 8.12159405092043 Test RE 1.3621618073616213\n",
      "39 Train Loss 24.077677 Test MSE 8.307129255161781 Test RE 1.3776330217940662\n",
      "40 Train Loss 23.472488 Test MSE 8.202133157760377 Test RE 1.368899194897537\n",
      "41 Train Loss 22.64354 Test MSE 7.987698589742276 Test RE 1.3508866027218849\n",
      "42 Train Loss 21.44432 Test MSE 8.07980468203257 Test RE 1.3586528104924895\n",
      "43 Train Loss 20.28674 Test MSE 7.918713726031371 Test RE 1.3450405628068056\n",
      "44 Train Loss 19.614035 Test MSE 8.062670994154171 Test RE 1.3572114954991112\n",
      "45 Train Loss 18.863338 Test MSE 8.068703603733097 Test RE 1.3577191434075901\n",
      "46 Train Loss 18.422066 Test MSE 8.079323360501627 Test RE 1.3586123417797\n",
      "47 Train Loss 17.873035 Test MSE 8.092958061281996 Test RE 1.3597582585296328\n",
      "48 Train Loss 17.460972 Test MSE 7.872477169007331 Test RE 1.3411080370735295\n",
      "49 Train Loss 17.077488 Test MSE 7.975120535569035 Test RE 1.3498225778968804\n",
      "50 Train Loss 16.56581 Test MSE 8.024732113817612 Test RE 1.3540145524336322\n",
      "51 Train Loss 16.236763 Test MSE 7.9349696866067285 Test RE 1.346420440729337\n",
      "52 Train Loss 16.118649 Test MSE 7.816134675809537 Test RE 1.336300334809109\n",
      "53 Train Loss 15.885249 Test MSE 7.882206178779353 Test RE 1.3419364691064612\n",
      "54 Train Loss 15.76488 Test MSE 7.89298769824934 Test RE 1.342853926081139\n",
      "55 Train Loss 15.688976 Test MSE 7.869691132484559 Test RE 1.3408707098306247\n",
      "56 Train Loss 15.318966 Test MSE 7.926725237643052 Test RE 1.3457207922175258\n",
      "57 Train Loss 15.253398 Test MSE 7.860307708412358 Test RE 1.3400710779870249\n",
      "58 Train Loss 15.109488 Test MSE 7.851524683442763 Test RE 1.3393221780776148\n",
      "59 Train Loss 14.906502 Test MSE 7.806386657462443 Test RE 1.3354667805818676\n",
      "60 Train Loss 14.768795 Test MSE 7.716444637268869 Test RE 1.3277511388338767\n",
      "61 Train Loss 14.468697 Test MSE 7.7044992876193374 Test RE 1.32672303617469\n",
      "62 Train Loss 14.272508 Test MSE 7.6611655269388095 Test RE 1.3229867150352184\n",
      "63 Train Loss 13.592926 Test MSE 7.467896137852214 Test RE 1.3061925274578816\n",
      "64 Train Loss 13.070574 Test MSE 6.942792881643061 Test RE 1.25943327962188\n",
      "65 Train Loss 12.138296 Test MSE 6.133570520809366 Test RE 1.183762946369316\n",
      "66 Train Loss 11.499159 Test MSE 6.024766836149636 Test RE 1.1732165541585318\n",
      "67 Train Loss 10.875843 Test MSE 5.93387260417033 Test RE 1.1643329001211498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 Train Loss 10.467618 Test MSE 6.083781650089727 Test RE 1.1789485959966215\n",
      "69 Train Loss 10.108831 Test MSE 6.090336441029798 Test RE 1.1795835366986902\n",
      "70 Train Loss 9.798773 Test MSE 5.722060416141337 Test RE 1.143363383646969\n",
      "71 Train Loss 9.500877 Test MSE 5.735125991907409 Test RE 1.1446679996341733\n",
      "72 Train Loss 9.320808 Test MSE 5.864022523614751 Test RE 1.1574596901573257\n",
      "73 Train Loss 9.070702 Test MSE 5.889362501605712 Test RE 1.1599578375958284\n",
      "74 Train Loss 8.848812 Test MSE 5.826771642746872 Test RE 1.153777483545931\n",
      "75 Train Loss 8.753656 Test MSE 5.81509841753746 Test RE 1.1526211780028088\n",
      "76 Train Loss 8.544842 Test MSE 5.809942098702224 Test RE 1.1521100430277065\n",
      "77 Train Loss 8.463029 Test MSE 5.770803627955921 Test RE 1.148222911177911\n",
      "78 Train Loss 8.280347 Test MSE 5.650154876893249 Test RE 1.1361567068739975\n",
      "79 Train Loss 8.12121 Test MSE 5.6380388389036495 Test RE 1.1349378813945898\n",
      "80 Train Loss 7.960012 Test MSE 5.665918284124164 Test RE 1.1377404888262628\n",
      "81 Train Loss 7.83146 Test MSE 5.6443435315982775 Test RE 1.1355722717841041\n",
      "82 Train Loss 7.749134 Test MSE 5.652231690253517 Test RE 1.136365494835806\n",
      "83 Train Loss 7.649452 Test MSE 5.6584640266527275 Test RE 1.136991819200227\n",
      "84 Train Loss 7.5126457 Test MSE 5.724929722631599 Test RE 1.143650015434575\n",
      "85 Train Loss 7.382903 Test MSE 5.728033119336856 Test RE 1.143959951014611\n",
      "86 Train Loss 7.276534 Test MSE 5.683095964743591 Test RE 1.1394638592680766\n",
      "87 Train Loss 7.212644 Test MSE 5.650005808031119 Test RE 1.1361417190808925\n",
      "88 Train Loss 7.10151 Test MSE 5.631081020148878 Test RE 1.1342373603354061\n",
      "89 Train Loss 6.9879436 Test MSE 5.579770524506632 Test RE 1.1290579405836838\n",
      "90 Train Loss 6.9201937 Test MSE 5.536205103732901 Test RE 1.1246416055119068\n",
      "91 Train Loss 6.754834 Test MSE 5.449182679361094 Test RE 1.1157675947446435\n",
      "92 Train Loss 6.3332453 Test MSE 5.190008036301445 Test RE 1.0889102238331654\n",
      "93 Train Loss 5.622614 Test MSE 4.970514238489109 Test RE 1.0656356017521025\n",
      "94 Train Loss 5.209918 Test MSE 4.780131391352217 Test RE 1.0450281215137454\n",
      "95 Train Loss 4.8645277 Test MSE 4.841246893074266 Test RE 1.0516874124515683\n",
      "96 Train Loss 4.6796184 Test MSE 5.011090594613983 Test RE 1.069976372171713\n",
      "97 Train Loss 4.5724974 Test MSE 4.985344267416987 Test RE 1.0672241332230823\n",
      "98 Train Loss 4.4127207 Test MSE 4.969560108027115 Test RE 1.0655333181513997\n",
      "99 Train Loss 4.2146096 Test MSE 4.978373937566506 Test RE 1.066477794970845\n",
      "Training time: 81.31\n",
      "KG_stan_tune1\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 55.052696 Test MSE 9.941112968428472 Test RE 1.5070427248834821\n",
      "1 Train Loss 44.72351 Test MSE 9.33183625526582 Test RE 1.4601303059320536\n",
      "2 Train Loss 43.484398 Test MSE 9.306314454065102 Test RE 1.458132271003185\n",
      "3 Train Loss 43.296684 Test MSE 9.38448712142977 Test RE 1.464243590366786\n",
      "4 Train Loss 43.225574 Test MSE 9.341789639454769 Test RE 1.4609087896228479\n",
      "5 Train Loss 43.17795 Test MSE 9.368630036849257 Test RE 1.4630059920485463\n",
      "6 Train Loss 42.988758 Test MSE 9.40206044612613 Test RE 1.4656139152851544\n",
      "7 Train Loss 42.724686 Test MSE 9.323648476260436 Test RE 1.4594896041733247\n",
      "8 Train Loss 42.514637 Test MSE 9.160657976850072 Test RE 1.4466763927000277\n",
      "9 Train Loss 41.313133 Test MSE 9.451278489955424 Test RE 1.4694450166557949\n",
      "10 Train Loss 40.720932 Test MSE 9.132768226913319 Test RE 1.4444725008312427\n",
      "11 Train Loss 39.98534 Test MSE 9.18991401147884 Test RE 1.4489846480930437\n",
      "12 Train Loss 39.564514 Test MSE 9.219475141226352 Test RE 1.4513132462044698\n",
      "13 Train Loss 39.435467 Test MSE 9.225091992749418 Test RE 1.4517552762372548\n",
      "14 Train Loss 38.629395 Test MSE 9.024652709098202 Test RE 1.4358970701839742\n",
      "15 Train Loss 37.20945 Test MSE 8.883519580338715 Test RE 1.4246251015475415\n",
      "16 Train Loss 36.75944 Test MSE 8.837855669713012 Test RE 1.420958887531547\n",
      "17 Train Loss 36.591393 Test MSE 8.988837934058509 Test RE 1.4330450239237114\n",
      "18 Train Loss 36.27255 Test MSE 9.021290338650884 Test RE 1.4356295547562514\n",
      "19 Train Loss 36.104946 Test MSE 9.068572430471896 Test RE 1.4393868253993674\n",
      "20 Train Loss 35.894394 Test MSE 9.218853033370065 Test RE 1.4512642798267739\n",
      "21 Train Loss 35.55863 Test MSE 9.34096476082361 Test RE 1.4608442891849096\n",
      "22 Train Loss 35.43799 Test MSE 9.358058974733517 Test RE 1.462180370146588\n",
      "23 Train Loss 35.098522 Test MSE 9.427077094413503 Test RE 1.467562445152708\n",
      "24 Train Loss 34.893803 Test MSE 9.461479647163108 Test RE 1.4702378192897076\n",
      "25 Train Loss 34.82979 Test MSE 9.507235807357807 Test RE 1.473788601122762\n",
      "26 Train Loss 34.590897 Test MSE 9.719440345696066 Test RE 1.490145547796789\n",
      "27 Train Loss 34.370422 Test MSE 9.571177886986971 Test RE 1.4787363687916009\n",
      "28 Train Loss 34.29195 Test MSE 9.691304112071919 Test RE 1.4879871174328831\n",
      "29 Train Loss 33.987915 Test MSE 9.700160242716324 Test RE 1.4886668401506689\n",
      "30 Train Loss 33.76886 Test MSE 9.403301926546234 Test RE 1.465710674443924\n",
      "31 Train Loss 33.495174 Test MSE 9.448338205294982 Test RE 1.469216427331535\n",
      "32 Train Loss 33.29728 Test MSE 9.251659763160308 Test RE 1.4538442619626215\n",
      "33 Train Loss 32.974884 Test MSE 8.950966858369346 Test RE 1.4300230404233112\n",
      "34 Train Loss 32.877243 Test MSE 8.906027665155591 Test RE 1.426428738999836\n",
      "35 Train Loss 32.502113 Test MSE 8.704617083514604 Test RE 1.4102070967581082\n",
      "36 Train Loss 32.001945 Test MSE 8.344080311618612 Test RE 1.3806935564113632\n",
      "37 Train Loss 31.179663 Test MSE 8.55795016186114 Test RE 1.398276107177511\n",
      "38 Train Loss 30.12353 Test MSE 8.087371105942598 Test RE 1.3592888244744208\n",
      "39 Train Loss 29.411427 Test MSE 8.27355082467421 Test RE 1.3748459220730749\n",
      "40 Train Loss 28.450954 Test MSE 8.408221111476186 Test RE 1.385990080970503\n",
      "41 Train Loss 27.823254 Test MSE 9.203969481051484 Test RE 1.4500922960169171\n",
      "42 Train Loss 27.225113 Test MSE 9.095856653031253 Test RE 1.441550509691502\n",
      "43 Train Loss 26.718788 Test MSE 9.077742643310115 Test RE 1.4401144012376208\n",
      "44 Train Loss 26.143064 Test MSE 9.238883196004169 Test RE 1.4528400337033403\n",
      "45 Train Loss 25.599041 Test MSE 9.266340864611246 Test RE 1.454997329350283\n",
      "46 Train Loss 25.341038 Test MSE 9.294747871243525 Test RE 1.4572258514168344\n",
      "47 Train Loss 24.993032 Test MSE 9.439076023621507 Test RE 1.4684961162135373\n",
      "48 Train Loss 24.662527 Test MSE 9.44196932135161 Test RE 1.4687211631847705\n",
      "49 Train Loss 24.461918 Test MSE 9.35103848944909 Test RE 1.461631797959648\n",
      "50 Train Loss 24.314182 Test MSE 9.305362758468894 Test RE 1.4580577122964409\n",
      "51 Train Loss 24.082518 Test MSE 9.419430719572539 Test RE 1.4669671488144622\n",
      "52 Train Loss 23.932365 Test MSE 9.44100134162366 Test RE 1.4686458754612557\n",
      "53 Train Loss 23.879387 Test MSE 9.494265078476209 Test RE 1.4727829125480567\n",
      "54 Train Loss 23.765995 Test MSE 9.55399901224562 Test RE 1.47740871423945\n",
      "55 Train Loss 23.677338 Test MSE 9.494203804722439 Test RE 1.4727781600431291\n",
      "56 Train Loss 23.576569 Test MSE 9.493044942895501 Test RE 1.4726882737025346\n",
      "57 Train Loss 23.512428 Test MSE 9.409165883608933 Test RE 1.466167616324204\n",
      "58 Train Loss 23.33554 Test MSE 9.117698837157798 Test RE 1.4432802935403168\n",
      "59 Train Loss 23.198345 Test MSE 9.097426661982059 Test RE 1.4416749152112296\n",
      "60 Train Loss 22.953442 Test MSE 8.916116823376369 Test RE 1.4272364723832114\n",
      "61 Train Loss 22.64222 Test MSE 8.77061450955081 Test RE 1.4155430174339\n",
      "62 Train Loss 22.41274 Test MSE 8.654000184628384 Test RE 1.4061009781116456\n",
      "63 Train Loss 21.982605 Test MSE 8.39412785337545 Test RE 1.3848280451756316\n",
      "64 Train Loss 21.499065 Test MSE 7.5314690271889155 Test RE 1.3117404392657013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Train Loss 20.728691 Test MSE 7.319364151009882 Test RE 1.2931375937287222\n",
      "66 Train Loss 19.877548 Test MSE 7.405253354852143 Test RE 1.3007026380278555\n",
      "67 Train Loss 19.157265 Test MSE 7.192295349049563 Test RE 1.281863604374081\n",
      "68 Train Loss 18.745075 Test MSE 7.213235948869866 Test RE 1.2837283416584815\n",
      "69 Train Loss 17.634605 Test MSE 6.707239839506609 Test RE 1.2378840821193424\n",
      "70 Train Loss 16.53506 Test MSE 6.228193672137359 Test RE 1.192859008611784\n",
      "71 Train Loss 15.44784 Test MSE 5.879065557373808 Test RE 1.1589433605235038\n",
      "72 Train Loss 14.287949 Test MSE 5.337892913352973 Test RE 1.1043150444112726\n",
      "73 Train Loss 13.234175 Test MSE 5.531738243483019 Test RE 1.1241878081436631\n",
      "74 Train Loss 12.773235 Test MSE 5.521862777413893 Test RE 1.1231838888179684\n",
      "75 Train Loss 12.2848835 Test MSE 5.412453327753078 Test RE 1.1120009095712626\n",
      "76 Train Loss 11.922899 Test MSE 5.297658168994948 Test RE 1.1001452457389698\n",
      "77 Train Loss 11.723588 Test MSE 5.274543655680149 Test RE 1.097742568949834\n",
      "78 Train Loss 11.489428 Test MSE 5.289489080931554 Test RE 1.0992966962116846\n",
      "79 Train Loss 10.962555 Test MSE 5.314632031462198 Test RE 1.101906286148118\n",
      "80 Train Loss 10.383904 Test MSE 5.196612772598514 Test RE 1.0896028699893918\n",
      "81 Train Loss 9.777133 Test MSE 5.096494729271631 Test RE 1.07905566716465\n",
      "82 Train Loss 8.921869 Test MSE 4.909102759352148 Test RE 1.0590320944337377\n",
      "83 Train Loss 7.8918753 Test MSE 4.686544375559392 Test RE 1.0347475983502779\n",
      "84 Train Loss 7.064704 Test MSE 4.618556337011941 Test RE 1.0272145989372234\n",
      "85 Train Loss 6.6003046 Test MSE 4.592770196136752 Test RE 1.0243430332853751\n",
      "86 Train Loss 6.335848 Test MSE 4.623837038898146 Test RE 1.0278016724767773\n",
      "87 Train Loss 6.132901 Test MSE 4.577157061652736 Test RE 1.0226004225905576\n",
      "88 Train Loss 6.0095925 Test MSE 4.514105398967524 Test RE 1.0155326898411217\n",
      "89 Train Loss 5.9165773 Test MSE 4.56007901903443 Test RE 1.0206909038628769\n",
      "90 Train Loss 5.822825 Test MSE 4.561874361759792 Test RE 1.020891811528088\n",
      "91 Train Loss 5.754063 Test MSE 4.523399053464423 Test RE 1.0165775432903572\n",
      "92 Train Loss 5.7202654 Test MSE 4.519640707523739 Test RE 1.0161551348336244\n",
      "93 Train Loss 5.617067 Test MSE 4.482699568239381 Test RE 1.0119938585676231\n",
      "94 Train Loss 5.526314 Test MSE 4.501884213503162 Test RE 1.014157065677958\n",
      "95 Train Loss 5.4555235 Test MSE 4.501063961367763 Test RE 1.0140646707656744\n",
      "96 Train Loss 5.413611 Test MSE 4.511567405135956 Test RE 1.0152471650409929\n",
      "97 Train Loss 5.356197 Test MSE 4.528585197245855 Test RE 1.0171601369293175\n",
      "98 Train Loss 5.271658 Test MSE 4.485566916413288 Test RE 1.0123174665658803\n",
      "99 Train Loss 5.0831795 Test MSE 4.456744912896394 Test RE 1.009059903081334\n",
      "Training time: 80.70\n",
      "KG_stan_tune1\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.82816 Test MSE 8.647147788143142 Test RE 1.4055441795633037\n",
      "1 Train Loss 57.578876 Test MSE 8.390923468139096 Test RE 1.3845636969194683\n",
      "2 Train Loss 57.009327 Test MSE 8.611199218721303 Test RE 1.4026195200590494\n",
      "3 Train Loss 56.513836 Test MSE 8.98473041205928 Test RE 1.4327175657693605\n",
      "4 Train Loss 54.752556 Test MSE 8.588770714474617 Test RE 1.4007917160632528\n",
      "5 Train Loss 54.234608 Test MSE 8.962408130354373 Test RE 1.4309366879562149\n",
      "6 Train Loss 53.88244 Test MSE 9.380595002382925 Test RE 1.4639399189291509\n",
      "7 Train Loss 48.421997 Test MSE 8.82285951580661 Test RE 1.4197528277169575\n",
      "8 Train Loss 46.89686 Test MSE 8.613932439534942 Test RE 1.4028421002486493\n",
      "9 Train Loss 45.459087 Test MSE 8.688512740710076 Test RE 1.4089019863706398\n",
      "10 Train Loss 45.243717 Test MSE 8.598879793778229 Test RE 1.4016158473991942\n",
      "11 Train Loss 44.752304 Test MSE 8.63804265585277 Test RE 1.4048039911998964\n",
      "12 Train Loss 44.32596 Test MSE 8.515268877244228 Test RE 1.3947849196452051\n",
      "13 Train Loss 44.261772 Test MSE 8.455373565450492 Test RE 1.3898708939049573\n",
      "14 Train Loss 44.077705 Test MSE 8.423916593772764 Test RE 1.3872830798166038\n",
      "15 Train Loss 43.987408 Test MSE 8.521165475899771 Test RE 1.3952677619184974\n",
      "16 Train Loss 43.721004 Test MSE 8.453183386128952 Test RE 1.3896908744405239\n",
      "17 Train Loss 43.128845 Test MSE 8.275633444470142 Test RE 1.3750189494243645\n",
      "18 Train Loss 40.766922 Test MSE 7.549170970210141 Test RE 1.3132810899792884\n",
      "19 Train Loss 37.1519 Test MSE 7.387686726146795 Test RE 1.2991589685686715\n",
      "20 Train Loss 36.079315 Test MSE 7.414009177214831 Test RE 1.3014713731568093\n",
      "21 Train Loss 35.10113 Test MSE 6.976492767245397 Test RE 1.2624861849268547\n",
      "22 Train Loss 34.535988 Test MSE 7.103317589802849 Test RE 1.273909793874343\n",
      "23 Train Loss 34.4052 Test MSE 7.121142739991014 Test RE 1.2755071746235145\n",
      "24 Train Loss 34.052464 Test MSE 7.123749203468272 Test RE 1.2757405822963102\n",
      "25 Train Loss 33.959614 Test MSE 7.086629756687718 Test RE 1.2724125150119623\n",
      "26 Train Loss 33.8035 Test MSE 7.116235935178366 Test RE 1.275067656454007\n",
      "27 Train Loss 33.69767 Test MSE 7.099909020362237 Test RE 1.2736041105811162\n",
      "28 Train Loss 33.551514 Test MSE 7.061536349797104 Test RE 1.270157742212863\n",
      "29 Train Loss 33.45982 Test MSE 7.037306373591998 Test RE 1.2679767481793918\n",
      "30 Train Loss 33.30114 Test MSE 7.079679221549343 Test RE 1.2717883736506825\n",
      "31 Train Loss 33.00056 Test MSE 6.97979402126496 Test RE 1.2627848518073594\n",
      "32 Train Loss 32.73789 Test MSE 7.118061772258769 Test RE 1.2752312202057976\n",
      "33 Train Loss 32.645725 Test MSE 7.054572093556043 Test RE 1.2695312577212141\n",
      "34 Train Loss 32.415916 Test MSE 7.032110174209195 Test RE 1.2675085380200093\n",
      "35 Train Loss 32.09217 Test MSE 7.006618782198363 Test RE 1.2652090936963611\n",
      "36 Train Loss 32.03541 Test MSE 7.008442851075421 Test RE 1.2653737721539637\n",
      "37 Train Loss 31.812408 Test MSE 6.934649096593987 Test RE 1.2586944153386934\n",
      "38 Train Loss 31.555672 Test MSE 6.93411711281434 Test RE 1.2586461347519144\n",
      "39 Train Loss 31.095097 Test MSE 6.688828764699373 Test RE 1.2361839462658943\n",
      "40 Train Loss 29.814388 Test MSE 6.691793107169596 Test RE 1.2364578407538727\n",
      "41 Train Loss 29.075878 Test MSE 6.860587631189953 Test RE 1.2519549980248617\n",
      "42 Train Loss 28.505005 Test MSE 6.8754444328594735 Test RE 1.253309837380986\n",
      "43 Train Loss 27.763004 Test MSE 6.688127805799833 Test RE 1.2361191713350388\n",
      "44 Train Loss 27.134365 Test MSE 6.883954592393743 Test RE 1.2540852467641659\n",
      "45 Train Loss 26.479702 Test MSE 6.849387677288015 Test RE 1.2509326682784372\n",
      "46 Train Loss 26.048767 Test MSE 6.6179700055268444 Test RE 1.2296186950299226\n",
      "47 Train Loss 24.627949 Test MSE 6.590177693862231 Test RE 1.2270340731543399\n",
      "48 Train Loss 23.071404 Test MSE 6.516034148434006 Test RE 1.2201121056268514\n",
      "49 Train Loss 22.447453 Test MSE 6.459539476688751 Test RE 1.2148113437146482\n",
      "50 Train Loss 21.423126 Test MSE 6.199559925234541 Test RE 1.1901138008667687\n",
      "51 Train Loss 20.396881 Test MSE 5.9375377579729465 Test RE 1.164692429275034\n",
      "52 Train Loss 19.469955 Test MSE 5.342021533957549 Test RE 1.1047420309261773\n",
      "53 Train Loss 17.16198 Test MSE 4.607933464399477 Test RE 1.0260326006290572\n",
      "54 Train Loss 16.345688 Test MSE 4.390027723818769 Test RE 1.0014786419245219\n",
      "55 Train Loss 15.650609 Test MSE 4.324544425062312 Test RE 0.993981363456623\n",
      "56 Train Loss 14.842704 Test MSE 4.307608374663468 Test RE 0.9920331082337275\n",
      "57 Train Loss 14.362226 Test MSE 4.331949392937168 Test RE 0.9948320024154866\n",
      "58 Train Loss 13.996759 Test MSE 4.264367875053912 Test RE 0.9870414520125532\n",
      "59 Train Loss 13.507845 Test MSE 4.069767320090742 Test RE 0.9642571110947458\n",
      "60 Train Loss 13.31105 Test MSE 4.0163960186166525 Test RE 0.9579135669582075\n",
      "61 Train Loss 13.191665 Test MSE 4.035402750727582 Test RE 0.9601774519602839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 Train Loss 12.997577 Test MSE 4.031101445159094 Test RE 0.959665592549786\n",
      "63 Train Loss 12.852034 Test MSE 3.9948791560055943 Test RE 0.9553442269695058\n",
      "64 Train Loss 12.762026 Test MSE 4.046802439000174 Test RE 0.9615327075588515\n",
      "65 Train Loss 12.671584 Test MSE 4.098959470681243 Test RE 0.9677092054761419\n",
      "66 Train Loss 12.507747 Test MSE 4.182864391369608 Test RE 0.9775634440194632\n",
      "67 Train Loss 12.472767 Test MSE 4.200062601731778 Test RE 0.9795710510401652\n",
      "68 Train Loss 12.384529 Test MSE 4.173019973682179 Test RE 0.9764124131815547\n",
      "69 Train Loss 12.123583 Test MSE 4.16412988729027 Test RE 0.9753717976550011\n",
      "70 Train Loss 11.917758 Test MSE 4.277107638414953 Test RE 0.9885147415144497\n",
      "71 Train Loss 11.804214 Test MSE 4.357244824736714 Test RE 0.997732322082746\n",
      "72 Train Loss 11.541499 Test MSE 4.30767425217928 Test RE 0.992040693931083\n",
      "73 Train Loss 11.094439 Test MSE 4.122242356520781 Test RE 0.9704537017882848\n",
      "74 Train Loss 10.611125 Test MSE 4.140565379023624 Test RE 0.9726081031785276\n",
      "75 Train Loss 10.2911215 Test MSE 4.142680152895995 Test RE 0.9728564489299367\n",
      "76 Train Loss 9.863724 Test MSE 4.079903295919265 Test RE 0.9654571316480883\n",
      "77 Train Loss 9.366508 Test MSE 3.8500303623265286 Test RE 0.9378645869028741\n",
      "78 Train Loss 9.071295 Test MSE 3.6325432634054966 Test RE 0.9109896817348485\n",
      "79 Train Loss 8.804954 Test MSE 3.5851371094556583 Test RE 0.9050257686726817\n",
      "80 Train Loss 8.60859 Test MSE 3.4744604902113965 Test RE 0.8909467521802954\n",
      "81 Train Loss 8.244034 Test MSE 3.1441978936231467 Test RE 0.8475454495238551\n",
      "82 Train Loss 7.7535205 Test MSE 2.769493823022308 Test RE 0.7954415280746729\n",
      "83 Train Loss 7.4030743 Test MSE 2.7139452236724124 Test RE 0.7874239123661955\n",
      "84 Train Loss 6.896443 Test MSE 2.390043343241062 Test RE 0.7389430158476513\n",
      "85 Train Loss 6.4917026 Test MSE 2.2809509882364365 Test RE 0.721881707687921\n",
      "86 Train Loss 6.3266315 Test MSE 2.280969580052671 Test RE 0.7218846496767609\n",
      "87 Train Loss 6.0831103 Test MSE 2.273955654610571 Test RE 0.7207739063574541\n",
      "88 Train Loss 5.792171 Test MSE 2.241974950013541 Test RE 0.7156875101925094\n",
      "89 Train Loss 5.4693465 Test MSE 2.2052718492286796 Test RE 0.7098051190262147\n",
      "90 Train Loss 5.280319 Test MSE 2.2053127993123924 Test RE 0.7098117092441325\n",
      "91 Train Loss 5.0231156 Test MSE 2.1875987231125196 Test RE 0.7069551961078618\n",
      "92 Train Loss 4.808686 Test MSE 2.218130855404048 Test RE 0.7118715584869378\n",
      "93 Train Loss 4.5905275 Test MSE 2.2322940747216 Test RE 0.7141406648446693\n",
      "94 Train Loss 4.119131 Test MSE 1.969693240022818 Test RE 0.6708220932620392\n",
      "95 Train Loss 3.5687323 Test MSE 1.8711504191813784 Test RE 0.6538263375066857\n",
      "96 Train Loss 3.2252011 Test MSE 1.8566301657495254 Test RE 0.6512845285160129\n",
      "97 Train Loss 3.0392485 Test MSE 1.78833938847707 Test RE 0.6391945028127437\n",
      "98 Train Loss 2.8903613 Test MSE 1.7660832203638839 Test RE 0.635204611616671\n",
      "99 Train Loss 2.76156 Test MSE 1.7219802590647069 Test RE 0.627223244213734\n",
      "Training time: 81.32\n",
      "KG_stan_tune1\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.825542 Test MSE 8.445946203625633 Test RE 1.3890958559953055\n",
      "1 Train Loss 54.951523 Test MSE 8.737310535461846 Test RE 1.4128528954130324\n",
      "2 Train Loss 45.349976 Test MSE 7.449107285365181 Test RE 1.3045483351555378\n",
      "3 Train Loss 44.350292 Test MSE 7.945503707740135 Test RE 1.3473138604805468\n",
      "4 Train Loss 43.404617 Test MSE 8.051621893917448 Test RE 1.3562812140194564\n",
      "5 Train Loss 43.281326 Test MSE 7.884152326952689 Test RE 1.3421021236176909\n",
      "6 Train Loss 42.338623 Test MSE 7.616566695812822 Test RE 1.3191302663688595\n",
      "7 Train Loss 39.617844 Test MSE 7.398067059198102 Test RE 1.3000713630341596\n",
      "8 Train Loss 35.77847 Test MSE 7.366825233053033 Test RE 1.2973233766584036\n",
      "9 Train Loss 35.035122 Test MSE 7.581025707767956 Test RE 1.3160489558954434\n",
      "10 Train Loss 33.710865 Test MSE 7.365646792242994 Test RE 1.297219608759267\n",
      "11 Train Loss 31.765446 Test MSE 6.893055631740566 Test RE 1.254913964412689\n",
      "12 Train Loss 29.838383 Test MSE 6.776634498671565 Test RE 1.244271321591059\n",
      "13 Train Loss 28.820314 Test MSE 6.688591403924835 Test RE 1.2361620123674182\n",
      "14 Train Loss 28.064106 Test MSE 6.578487804012176 Test RE 1.225945311940457\n",
      "15 Train Loss 27.54467 Test MSE 6.54664031353519 Test RE 1.2229742149952505\n",
      "16 Train Loss 27.03068 Test MSE 6.5951243405867865 Test RE 1.2274944981834075\n",
      "17 Train Loss 26.760715 Test MSE 6.437332469042042 Test RE 1.2127213688085314\n",
      "18 Train Loss 26.346577 Test MSE 6.608246096290267 Test RE 1.228715011887084\n",
      "19 Train Loss 26.159248 Test MSE 6.698796192232601 Test RE 1.237104659553086\n",
      "20 Train Loss 26.060127 Test MSE 6.741069443311545 Test RE 1.2410019411358477\n",
      "21 Train Loss 25.805756 Test MSE 6.733832286347274 Test RE 1.240335597480673\n",
      "22 Train Loss 25.569105 Test MSE 6.709495849332683 Test RE 1.2380922485131678\n",
      "23 Train Loss 25.283466 Test MSE 6.800171307387279 Test RE 1.2464302686873816\n",
      "24 Train Loss 24.865814 Test MSE 6.753751596518368 Test RE 1.2421687575797327\n",
      "25 Train Loss 24.659103 Test MSE 6.866842031696875 Test RE 1.2525255354639813\n",
      "26 Train Loss 24.352333 Test MSE 6.847022129409228 Test RE 1.2507166346123313\n",
      "27 Train Loss 24.135433 Test MSE 6.835099588010375 Test RE 1.249627240012894\n",
      "28 Train Loss 23.517387 Test MSE 6.712676380257525 Test RE 1.2383856628188972\n",
      "29 Train Loss 23.214802 Test MSE 6.7355115829871774 Test RE 1.2404902465326473\n",
      "30 Train Loss 22.8707 Test MSE 6.682477037416385 Test RE 1.235596865290545\n",
      "31 Train Loss 22.50715 Test MSE 6.6311259133722595 Test RE 1.2308402719436997\n",
      "32 Train Loss 21.927189 Test MSE 6.62499911357889 Test RE 1.2302715257969763\n",
      "33 Train Loss 21.413532 Test MSE 6.598804849593845 Test RE 1.227836961357103\n",
      "34 Train Loss 20.376549 Test MSE 6.391160701274716 Test RE 1.2083644201269423\n",
      "35 Train Loss 19.741993 Test MSE 6.223437878239529 Test RE 1.1924034933156882\n",
      "36 Train Loss 19.484583 Test MSE 6.1492677418279955 Test RE 1.185276739596144\n",
      "37 Train Loss 19.416012 Test MSE 6.139604942947379 Test RE 1.1843451169994288\n",
      "38 Train Loss 19.234377 Test MSE 6.103296657488159 Test RE 1.180837944705087\n",
      "39 Train Loss 19.02713 Test MSE 5.998963186780113 Test RE 1.1707014565963187\n",
      "40 Train Loss 18.900566 Test MSE 5.880120455014327 Test RE 1.1590473321298196\n",
      "41 Train Loss 18.601515 Test MSE 5.84528854565578 Test RE 1.155609324605748\n",
      "42 Train Loss 18.473015 Test MSE 5.784739664373783 Test RE 1.1496085091194828\n",
      "43 Train Loss 18.296947 Test MSE 5.67973259654671 Test RE 1.139126630781592\n",
      "44 Train Loss 18.166258 Test MSE 5.642486660278502 Test RE 1.1353854666204877\n",
      "45 Train Loss 17.955585 Test MSE 5.556281384524637 Test RE 1.1266789386409042\n",
      "46 Train Loss 17.708246 Test MSE 5.453384030093571 Test RE 1.1161976434380534\n",
      "47 Train Loss 17.48975 Test MSE 5.530027886112907 Test RE 1.1240140009725639\n",
      "48 Train Loss 15.986578 Test MSE 4.979946676493542 Test RE 1.0666462393981733\n",
      "49 Train Loss 12.242948 Test MSE 3.3321791900583086 Test RE 0.8725136584534444\n",
      "50 Train Loss 9.714277 Test MSE 2.5477630314670137 Test RE 0.7629350654864706\n",
      "51 Train Loss 7.964528 Test MSE 2.4107753463880424 Test RE 0.7421410101723649\n",
      "52 Train Loss 7.4284544 Test MSE 2.392684211805843 Test RE 0.7393511491609653\n",
      "53 Train Loss 7.045322 Test MSE 2.4461719260249044 Test RE 0.7475694565187915\n",
      "54 Train Loss 6.573905 Test MSE 2.433306508612587 Test RE 0.7456009782730598\n",
      "55 Train Loss 6.198297 Test MSE 2.3032828657903877 Test RE 0.7254069275359225\n",
      "56 Train Loss 5.9121704 Test MSE 2.304187585964841 Test RE 0.725549381998939\n",
      "57 Train Loss 5.745415 Test MSE 2.321852569168506 Test RE 0.7283252728387831\n",
      "58 Train Loss 5.511331 Test MSE 2.3146598415537136 Test RE 0.7271962802426076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 Train Loss 5.4244943 Test MSE 2.2826116249045936 Test RE 0.722144441329979\n",
      "60 Train Loss 5.317872 Test MSE 2.2739479824233264 Test RE 0.7207726904328993\n",
      "61 Train Loss 5.2206225 Test MSE 2.3135588168796706 Test RE 0.7270233053049495\n",
      "62 Train Loss 5.175731 Test MSE 2.2991727873508907 Test RE 0.7247594146586416\n",
      "63 Train Loss 5.137951 Test MSE 2.3203048986433155 Test RE 0.7280824935437081\n",
      "64 Train Loss 5.0471554 Test MSE 2.314088173102012 Test RE 0.7271064742081808\n",
      "65 Train Loss 5.0212884 Test MSE 2.2772980123079636 Test RE 0.7213034240758921\n",
      "66 Train Loss 4.9749417 Test MSE 2.2780091629281216 Test RE 0.7214160389674504\n",
      "67 Train Loss 4.925152 Test MSE 2.2873625269498246 Test RE 0.7228955665175074\n",
      "68 Train Loss 4.8987694 Test MSE 2.2812209155061427 Test RE 0.7219244200905465\n",
      "69 Train Loss 4.8538027 Test MSE 2.285077026049879 Test RE 0.7225343226475183\n",
      "70 Train Loss 4.8239365 Test MSE 2.261464045035427 Test RE 0.7187914522835233\n",
      "71 Train Loss 4.780975 Test MSE 2.268500813683797 Test RE 0.7199088789974697\n",
      "72 Train Loss 4.7132797 Test MSE 2.276332903123878 Test RE 0.7211505652216966\n",
      "73 Train Loss 4.690881 Test MSE 2.254563476994027 Test RE 0.717693964381171\n",
      "74 Train Loss 4.659503 Test MSE 2.266509237556768 Test RE 0.7195927962019546\n",
      "75 Train Loss 4.6161313 Test MSE 2.2492149024142623 Test RE 0.7168421544698086\n",
      "76 Train Loss 4.580945 Test MSE 2.2446700232005643 Test RE 0.7161175441914376\n",
      "77 Train Loss 4.5408545 Test MSE 2.244278332314304 Test RE 0.7160550608530712\n",
      "78 Train Loss 4.513608 Test MSE 2.2503860818556167 Test RE 0.717028762146068\n",
      "79 Train Loss 4.483795 Test MSE 2.2412017280617915 Test RE 0.7155640848582583\n",
      "80 Train Loss 4.467206 Test MSE 2.222219494039392 Test RE 0.7125273461128704\n",
      "81 Train Loss 4.424984 Test MSE 2.22223056717658 Test RE 0.7125291213432753\n",
      "82 Train Loss 4.3752413 Test MSE 2.2001094055245725 Test RE 0.7089738210638193\n",
      "83 Train Loss 4.3521166 Test MSE 2.2060191016616355 Test RE 0.7099253669399432\n",
      "84 Train Loss 4.3232555 Test MSE 2.216088313144255 Test RE 0.7115437233134808\n",
      "85 Train Loss 4.2977047 Test MSE 2.2043531865986856 Test RE 0.7096572598493335\n",
      "86 Train Loss 4.271356 Test MSE 2.19830463634988 Test RE 0.7086829726619929\n",
      "87 Train Loss 4.2471404 Test MSE 2.201234351525204 Test RE 0.7091550519012791\n",
      "88 Train Loss 4.2354064 Test MSE 2.1930178761247667 Test RE 0.7078302946029336\n",
      "89 Train Loss 4.2084904 Test MSE 2.185099329806861 Test RE 0.7065512225512487\n",
      "90 Train Loss 4.1896715 Test MSE 2.1915575338801463 Test RE 0.7075945813804978\n",
      "91 Train Loss 4.155336 Test MSE 2.1798835916881276 Test RE 0.7057074650575504\n",
      "92 Train Loss 4.1345487 Test MSE 2.19551878056167 Test RE 0.7082337823139259\n",
      "93 Train Loss 4.1053715 Test MSE 2.1931903957516363 Test RE 0.7078581357386848\n",
      "94 Train Loss 4.066914 Test MSE 2.1648915426918562 Test RE 0.7032765429146429\n",
      "95 Train Loss 4.021804 Test MSE 2.168053234469507 Test RE 0.7037899017536866\n",
      "96 Train Loss 3.9673505 Test MSE 2.1625372838124686 Test RE 0.7028940421314464\n",
      "97 Train Loss 3.9351907 Test MSE 2.165636487578322 Test RE 0.7033975321634804\n",
      "98 Train Loss 3.8643222 Test MSE 2.1389802236325206 Test RE 0.6990551586140107\n",
      "99 Train Loss 3.6418996 Test MSE 1.9922779751630777 Test RE 0.674656994380481\n",
      "Training time: 82.06\n",
      "KG_stan_tune1\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.501587 Test MSE 8.54033423628177 Test RE 1.396836240375083\n",
      "1 Train Loss 56.208473 Test MSE 8.41388375723717 Test RE 1.3864567105819283\n",
      "2 Train Loss 53.622887 Test MSE 9.08085136331824 Test RE 1.4403609674495723\n",
      "3 Train Loss 47.206467 Test MSE 8.510897661725052 Test RE 1.3944268752769315\n",
      "4 Train Loss 45.974365 Test MSE 8.753291759008722 Test RE 1.4141444142710247\n",
      "5 Train Loss 44.76989 Test MSE 8.62724330686571 Test RE 1.4039255680520555\n",
      "6 Train Loss 44.36885 Test MSE 8.74553392821086 Test RE 1.4135176143633708\n",
      "7 Train Loss 44.2022 Test MSE 8.70206172156033 Test RE 1.4100000885670545\n",
      "8 Train Loss 43.98324 Test MSE 8.62426743948099 Test RE 1.40368341325815\n",
      "9 Train Loss 43.54477 Test MSE 8.440333464689543 Test RE 1.388634218663673\n",
      "10 Train Loss 43.269005 Test MSE 8.569227589358878 Test RE 1.3991971084435628\n",
      "11 Train Loss 42.97521 Test MSE 8.43340988262265 Test RE 1.388064555422657\n",
      "12 Train Loss 42.65899 Test MSE 8.351176699692036 Test RE 1.3812805506991663\n",
      "13 Train Loss 42.617104 Test MSE 8.353653009749568 Test RE 1.381485325757729\n",
      "14 Train Loss 42.5158 Test MSE 8.432632899126821 Test RE 1.3880006116497396\n",
      "15 Train Loss 42.4994 Test MSE 8.448038485032498 Test RE 1.3892679029979482\n",
      "16 Train Loss 42.418556 Test MSE 8.413709695460872 Test RE 1.3864423693827328\n",
      "17 Train Loss 42.26802 Test MSE 8.435684318263682 Test RE 1.3882517187830108\n",
      "18 Train Loss 42.17771 Test MSE 8.439864386603327 Test RE 1.3885956309150407\n",
      "19 Train Loss 41.765114 Test MSE 8.26277024220659 Test RE 1.3739499058691493\n",
      "20 Train Loss 40.981277 Test MSE 8.320492833393677 Test RE 1.3787406672884854\n",
      "21 Train Loss 39.321102 Test MSE 8.133164250666598 Test RE 1.3631317447231492\n",
      "22 Train Loss 37.428852 Test MSE 8.036698481510617 Test RE 1.3550237200905735\n",
      "23 Train Loss 34.925865 Test MSE 7.38079228280725 Test RE 1.2985526171527553\n",
      "24 Train Loss 33.084312 Test MSE 7.418154208153434 Test RE 1.3018351362153173\n",
      "25 Train Loss 31.718388 Test MSE 6.944877332684597 Test RE 1.2596223267417679\n",
      "26 Train Loss 31.073875 Test MSE 7.166532099136973 Test RE 1.2795656870713488\n",
      "27 Train Loss 30.699596 Test MSE 7.204410311562159 Test RE 1.2829427588409368\n",
      "28 Train Loss 30.49981 Test MSE 7.200716661842925 Test RE 1.2826138388813941\n",
      "29 Train Loss 30.220612 Test MSE 7.169949652223292 Test RE 1.279870748318766\n",
      "30 Train Loss 29.92229 Test MSE 7.249266395772479 Test RE 1.2869304891159778\n",
      "31 Train Loss 29.56248 Test MSE 7.227717332447188 Test RE 1.2850163101617529\n",
      "32 Train Loss 29.20475 Test MSE 7.226772001333281 Test RE 1.2849322721752654\n",
      "33 Train Loss 28.622934 Test MSE 7.203312681191818 Test RE 1.2828450235291438\n",
      "34 Train Loss 27.967434 Test MSE 7.197651204245031 Test RE 1.2823407954422255\n",
      "35 Train Loss 26.13176 Test MSE 6.959800098908849 Test RE 1.2609749037516351\n",
      "36 Train Loss 24.758863 Test MSE 7.059562426518212 Test RE 1.269980205127053\n",
      "37 Train Loss 22.889835 Test MSE 6.975495454896761 Test RE 1.2623959434469811\n",
      "38 Train Loss 21.652945 Test MSE 6.529492389953888 Test RE 1.2213714677631098\n",
      "39 Train Loss 19.388954 Test MSE 6.333867050570837 Test RE 1.2029360270257181\n",
      "40 Train Loss 18.532894 Test MSE 6.349932117903911 Test RE 1.204460609844554\n",
      "41 Train Loss 17.859274 Test MSE 6.100022718010457 Test RE 1.1805211887967382\n",
      "42 Train Loss 17.171505 Test MSE 5.7803323230217565 Test RE 1.149170487457807\n",
      "43 Train Loss 16.570103 Test MSE 5.615950352225639 Test RE 1.1327124921368403\n",
      "44 Train Loss 14.260016 Test MSE 4.5743649419245775 Test RE 1.0222884758583155\n",
      "45 Train Loss 12.996763 Test MSE 4.46414897375096 Test RE 1.009897738841284\n",
      "46 Train Loss 12.707648 Test MSE 4.3994058699592244 Test RE 1.0025477698556615\n",
      "47 Train Loss 12.063041 Test MSE 4.253013475694946 Test RE 0.9857265170347475\n",
      "48 Train Loss 11.600981 Test MSE 4.259983598496811 Test RE 0.9865339236186269\n",
      "49 Train Loss 11.2053795 Test MSE 4.328639132956456 Test RE 0.9944518292390897\n",
      "50 Train Loss 10.808548 Test MSE 4.2984405786269635 Test RE 0.9909768839197165\n",
      "51 Train Loss 10.36273 Test MSE 4.313648455858068 Test RE 0.9927283735650314\n",
      "52 Train Loss 9.137934 Test MSE 4.343083606251934 Test RE 0.9961096677790954\n",
      "53 Train Loss 7.6478014 Test MSE 3.943214888712469 Test RE 0.949146570261984\n",
      "54 Train Loss 6.950299 Test MSE 3.6054022493816236 Test RE 0.907580012582318\n",
      "55 Train Loss 6.537465 Test MSE 3.673022599865814 Test RE 0.916051437472479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 Train Loss 5.9477777 Test MSE 3.4643556544295118 Test RE 0.8896502306073659\n",
      "57 Train Loss 5.70161 Test MSE 3.307334224538139 Test RE 0.8692548105273235\n",
      "58 Train Loss 5.145414 Test MSE 3.1256220019492464 Test RE 0.8450380953972404\n",
      "59 Train Loss 4.54461 Test MSE 2.4119339972591733 Test RE 0.7423193301963172\n",
      "60 Train Loss 4.1407123 Test MSE 2.04745536192952 Test RE 0.6839357122550664\n",
      "61 Train Loss 3.8525777 Test MSE 2.007200902817886 Test RE 0.6771790005696681\n",
      "62 Train Loss 3.291857 Test MSE 1.97321881604348 Test RE 0.671422180850255\n",
      "63 Train Loss 2.8038447 Test MSE 1.8445111078966616 Test RE 0.6491554353208391\n",
      "64 Train Loss 2.241232 Test MSE 1.6000163697439962 Test RE 0.604602965839051\n",
      "65 Train Loss 1.9136872 Test MSE 1.708322794822498 Test RE 0.62473095894702\n",
      "66 Train Loss 1.720945 Test MSE 1.7737934018964343 Test RE 0.6365896565427834\n",
      "67 Train Loss 1.4639852 Test MSE 1.7550490215166659 Test RE 0.633217175244256\n",
      "68 Train Loss 1.2391243 Test MSE 1.739237133876615 Test RE 0.6303582772507156\n",
      "69 Train Loss 1.1436342 Test MSE 1.7184127901558088 Test RE 0.6265731904354217\n",
      "70 Train Loss 1.1029963 Test MSE 1.7206234518645749 Test RE 0.6269760901849398\n",
      "71 Train Loss 1.0561186 Test MSE 1.703796811589997 Test RE 0.623902837608319\n",
      "72 Train Loss 0.99430037 Test MSE 1.7202236180702184 Test RE 0.6269032384537909\n",
      "73 Train Loss 0.97057885 Test MSE 1.7275832270082676 Test RE 0.6282428429119894\n",
      "74 Train Loss 0.92121387 Test MSE 1.7242908822124736 Test RE 0.6276439199707955\n",
      "75 Train Loss 0.899205 Test MSE 1.7137380472397834 Test RE 0.6257203501393444\n",
      "76 Train Loss 0.8577356 Test MSE 1.72573982727516 Test RE 0.6279075734525693\n",
      "77 Train Loss 0.82548624 Test MSE 1.7489191501778696 Test RE 0.6321103870668597\n",
      "78 Train Loss 0.79271334 Test MSE 1.7830884064761034 Test RE 0.6382554007979148\n",
      "79 Train Loss 0.75972897 Test MSE 1.816703192554257 Test RE 0.6442435066464968\n",
      "80 Train Loss 0.72993654 Test MSE 1.824201832009375 Test RE 0.6455717299335685\n",
      "81 Train Loss 0.7035912 Test MSE 1.805468637025888 Test RE 0.6422484053285844\n",
      "82 Train Loss 0.6811081 Test MSE 1.8334089838110674 Test RE 0.6471988513581578\n",
      "83 Train Loss 0.66895473 Test MSE 1.8378148656237756 Test RE 0.647976029451943\n",
      "84 Train Loss 0.6439582 Test MSE 1.833115776856302 Test RE 0.6471470978231961\n",
      "85 Train Loss 0.63045913 Test MSE 1.8419287530426236 Test RE 0.6487008604406322\n",
      "86 Train Loss 0.61678374 Test MSE 1.834961641450863 Test RE 0.647472839756225\n",
      "87 Train Loss 0.6044368 Test MSE 1.8167303990706516 Test RE 0.6442483306474606\n",
      "88 Train Loss 0.5928162 Test MSE 1.8107811215400456 Test RE 0.6431926002233229\n",
      "89 Train Loss 0.5744637 Test MSE 1.8130179820467476 Test RE 0.6435897459815243\n",
      "90 Train Loss 0.55810493 Test MSE 1.8223040993467348 Test RE 0.6452358456775988\n",
      "91 Train Loss 0.5432838 Test MSE 1.8341037640758617 Test RE 0.6473214694976441\n",
      "92 Train Loss 0.5334274 Test MSE 1.8125174527042818 Test RE 0.6435009002579725\n",
      "93 Train Loss 0.52043885 Test MSE 1.763388292080171 Test RE 0.6347197861032274\n",
      "94 Train Loss 0.51098055 Test MSE 1.733768952455739 Test RE 0.6293665703396345\n",
      "95 Train Loss 0.50309634 Test MSE 1.7254460432568242 Test RE 0.6278541247638747\n",
      "96 Train Loss 0.4884252 Test MSE 1.703210233255709 Test RE 0.6237954306133145\n",
      "97 Train Loss 0.48039523 Test MSE 1.6770456800593705 Test RE 0.6189855439035928\n",
      "98 Train Loss 0.47424895 Test MSE 1.659244088275697 Test RE 0.6156915593065596\n",
      "99 Train Loss 0.46678182 Test MSE 1.6352665713771601 Test RE 0.611226731798255\n",
      "Training time: 81.96\n",
      "KG_stan_tune1\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.513626 Test MSE 8.435917923740542 Test RE 1.3882709407540665\n",
      "1 Train Loss 56.692883 Test MSE 8.6237671436639 Test RE 1.403642698662393\n",
      "2 Train Loss 47.028465 Test MSE 8.18365986922647 Test RE 1.3673567714717096\n",
      "3 Train Loss 45.709675 Test MSE 8.022576449767168 Test RE 1.3538326774191811\n",
      "4 Train Loss 45.089287 Test MSE 8.17030046317566 Test RE 1.3662402456308451\n",
      "5 Train Loss 44.874954 Test MSE 8.184409401850987 Test RE 1.3674193874076197\n",
      "6 Train Loss 44.56629 Test MSE 8.16944503835273 Test RE 1.3661687215529976\n",
      "7 Train Loss 43.782803 Test MSE 8.327331085623628 Test RE 1.3793071145095004\n",
      "8 Train Loss 43.673668 Test MSE 8.22320404450393 Test RE 1.370656385279551\n",
      "9 Train Loss 43.370483 Test MSE 8.27339320932848 Test RE 1.374832826254122\n",
      "10 Train Loss 43.111683 Test MSE 8.357417142272514 Test RE 1.3817965374027197\n",
      "11 Train Loss 42.82817 Test MSE 8.20683657525851 Test RE 1.3692916282771166\n",
      "12 Train Loss 41.799873 Test MSE 8.060286018492262 Test RE 1.357010745909036\n",
      "13 Train Loss 41.24762 Test MSE 7.859711861813418 Test RE 1.3400202853236596\n",
      "14 Train Loss 40.420517 Test MSE 7.688588467284749 Test RE 1.3253523980126216\n",
      "15 Train Loss 39.775536 Test MSE 7.481276457483253 Test RE 1.3073621642364024\n",
      "16 Train Loss 38.66362 Test MSE 7.023035276763587 Test RE 1.266690417776869\n",
      "17 Train Loss 36.29182 Test MSE 5.806258055961714 Test RE 1.1517447127351588\n",
      "18 Train Loss 32.23772 Test MSE 4.5660808850574215 Test RE 1.0213623873630444\n",
      "19 Train Loss 27.84665 Test MSE 4.264966294776165 Test RE 0.9871107054597562\n",
      "20 Train Loss 22.183554 Test MSE 4.318936243182117 Test RE 0.9933366439020924\n",
      "21 Train Loss 20.899952 Test MSE 4.37562633092982 Test RE 0.9998346278007432\n",
      "22 Train Loss 20.109734 Test MSE 4.19283578126493 Test RE 0.9787279407574268\n",
      "23 Train Loss 18.954998 Test MSE 4.1961175468457075 Test RE 0.9791108948696973\n",
      "24 Train Loss 17.703253 Test MSE 3.656597354530216 Test RE 0.9140009152901551\n",
      "25 Train Loss 17.067547 Test MSE 3.7892605594893918 Test RE 0.9304334065697087\n",
      "26 Train Loss 16.514584 Test MSE 3.8721533720057693 Test RE 0.9405553016069657\n",
      "27 Train Loss 16.026133 Test MSE 3.7199393717405385 Test RE 0.9218833920843866\n",
      "28 Train Loss 15.421848 Test MSE 3.3216521871929543 Test RE 0.8711343479475953\n",
      "29 Train Loss 13.368666 Test MSE 2.6413450750714578 Test RE 0.7768204172458458\n",
      "30 Train Loss 11.086527 Test MSE 2.381281966380929 Test RE 0.7375873704844106\n",
      "31 Train Loss 9.206214 Test MSE 2.6053614409248333 Test RE 0.7715108728978911\n",
      "32 Train Loss 7.7663016 Test MSE 2.2365353066659175 Test RE 0.7148187562631866\n",
      "33 Train Loss 7.154377 Test MSE 2.284660852392125 Test RE 0.7224685232365807\n",
      "34 Train Loss 6.2552586 Test MSE 2.193086401014471 Test RE 0.7078413532483058\n",
      "35 Train Loss 5.8258457 Test MSE 2.17924000524108 Test RE 0.7056032812171951\n",
      "36 Train Loss 5.505386 Test MSE 2.15467316792351 Test RE 0.7016148330394554\n",
      "37 Train Loss 5.2865214 Test MSE 2.1659238687854914 Test RE 0.7034442012437688\n",
      "38 Train Loss 5.130243 Test MSE 2.162955982188536 Test RE 0.7029620840450727\n",
      "39 Train Loss 5.02377 Test MSE 2.1241740171371077 Test RE 0.6966314969337283\n",
      "40 Train Loss 4.9307976 Test MSE 2.153609137897231 Test RE 0.7014415744107393\n",
      "41 Train Loss 4.8782835 Test MSE 2.1442059593980645 Test RE 0.6999085674066601\n",
      "42 Train Loss 4.806161 Test MSE 2.12236360771952 Test RE 0.6963345680919432\n",
      "43 Train Loss 4.7196445 Test MSE 2.1394427878398448 Test RE 0.6991307414575858\n",
      "44 Train Loss 4.648356 Test MSE 2.1277092982923964 Test RE 0.6972109608395436\n",
      "45 Train Loss 4.6317315 Test MSE 2.1332131121815103 Test RE 0.6981121274246735\n",
      "46 Train Loss 4.5816555 Test MSE 2.1554589608688155 Test RE 0.7017427581785384\n",
      "47 Train Loss 4.5567174 Test MSE 2.150423418615702 Test RE 0.700922579830759\n",
      "48 Train Loss 4.5276523 Test MSE 2.1313350746748285 Test RE 0.6978047578887849\n",
      "49 Train Loss 4.4751687 Test MSE 2.1382812549829904 Test RE 0.6989409318534054\n",
      "50 Train Loss 4.459592 Test MSE 2.1427941143841287 Test RE 0.6996781032729841\n",
      "51 Train Loss 4.4440756 Test MSE 2.140607179352411 Test RE 0.6993209664949199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 4.4071617 Test MSE 2.141027775677024 Test RE 0.6993896660172791\n",
      "53 Train Loss 4.3914185 Test MSE 2.1523201170450457 Test RE 0.7012316226287613\n",
      "54 Train Loss 4.3480296 Test MSE 2.1431391648838503 Test RE 0.6997344349941008\n",
      "55 Train Loss 4.317974 Test MSE 2.128504720626616 Test RE 0.6973412712511438\n",
      "56 Train Loss 4.2549405 Test MSE 2.1395386399671676 Test RE 0.6991464026425113\n",
      "57 Train Loss 4.2156343 Test MSE 2.1064571080838177 Test RE 0.6937202476801432\n",
      "58 Train Loss 4.1675763 Test MSE 2.106240883310614 Test RE 0.6936846420767463\n",
      "59 Train Loss 4.1275096 Test MSE 2.0893907554744593 Test RE 0.6909042985272644\n",
      "60 Train Loss 4.065456 Test MSE 2.1077263448083157 Test RE 0.6939292152913974\n",
      "61 Train Loss 3.9975457 Test MSE 2.1305360047176425 Test RE 0.6976739368139737\n",
      "62 Train Loss 3.9164393 Test MSE 2.0705394389910863 Test RE 0.6877804293331365\n",
      "63 Train Loss 3.746822 Test MSE 2.0053283460251152 Test RE 0.6768630501278722\n",
      "64 Train Loss 2.5951445 Test MSE 1.169661660810841 Test RE 0.5169376779783643\n",
      "65 Train Loss 1.8375157 Test MSE 0.8098156170649063 Test RE 0.43013138666813\n",
      "66 Train Loss 1.4825251 Test MSE 0.6349253854861575 Test RE 0.3808635454556093\n",
      "67 Train Loss 1.0651532 Test MSE 0.3785420517590468 Test RE 0.29407975382082135\n",
      "68 Train Loss 0.74524844 Test MSE 0.2029610709431553 Test RE 0.21533490505536626\n",
      "69 Train Loss 0.5318677 Test MSE 0.09384439979997847 Test RE 0.1464239912668403\n",
      "70 Train Loss 0.4645731 Test MSE 0.06466726705918216 Test RE 0.12154869878762482\n",
      "71 Train Loss 0.35427532 Test MSE 0.044799887108685946 Test RE 0.1011687816878978\n",
      "72 Train Loss 0.31874394 Test MSE 0.03384447484322411 Test RE 0.08793301213102425\n",
      "73 Train Loss 0.2710324 Test MSE 0.03279729649546576 Test RE 0.0865619603548399\n",
      "74 Train Loss 0.213154 Test MSE 0.02155411335044505 Test RE 0.07017350054765534\n",
      "75 Train Loss 0.17827477 Test MSE 0.017601401875659426 Test RE 0.06341349499517036\n",
      "76 Train Loss 0.15437175 Test MSE 0.014051732541131727 Test RE 0.056659533923074566\n",
      "77 Train Loss 0.142519 Test MSE 0.014789057313339647 Test RE 0.058127053158889545\n",
      "78 Train Loss 0.12571615 Test MSE 0.014899869295406546 Test RE 0.058344414994850574\n",
      "79 Train Loss 0.11339632 Test MSE 0.016807995940550106 Test RE 0.0619677928039325\n",
      "80 Train Loss 0.1028533 Test MSE 0.016080969136422558 Test RE 0.060612775274234684\n",
      "81 Train Loss 0.098653704 Test MSE 0.017087371733686026 Test RE 0.06248067231441268\n",
      "82 Train Loss 0.0929144 Test MSE 0.01609948860632932 Test RE 0.06064766724687282\n",
      "83 Train Loss 0.08894468 Test MSE 0.014852448851161543 Test RE 0.058251497302816285\n",
      "84 Train Loss 0.077747695 Test MSE 0.013756757120790808 Test RE 0.05606167832724475\n",
      "85 Train Loss 0.07253738 Test MSE 0.012761757922945573 Test RE 0.05399621418917978\n",
      "86 Train Loss 0.06751069 Test MSE 0.01280820814445158 Test RE 0.05409439259028909\n",
      "87 Train Loss 0.062191673 Test MSE 0.012988237984631775 Test RE 0.054473236458974374\n",
      "88 Train Loss 0.060895965 Test MSE 0.012611238258521465 Test RE 0.053676838145066685\n",
      "89 Train Loss 0.05842328 Test MSE 0.012155057052445765 Test RE 0.05269708120489577\n",
      "90 Train Loss 0.056418464 Test MSE 0.011612221635714735 Test RE 0.05150693632580697\n",
      "91 Train Loss 0.053450648 Test MSE 0.010969134547294045 Test RE 0.05006039154085021\n",
      "92 Train Loss 0.050849065 Test MSE 0.010045747932126694 Test RE 0.04790702459801415\n",
      "93 Train Loss 0.04776123 Test MSE 0.009271137336839784 Test RE 0.04602296215445073\n",
      "94 Train Loss 0.045358397 Test MSE 0.008334744171623385 Test RE 0.04363693083799157\n",
      "95 Train Loss 0.04357989 Test MSE 0.00809851767750373 Test RE 0.043014098723065906\n",
      "96 Train Loss 0.042005252 Test MSE 0.007773644083414392 Test RE 0.04214250883750028\n",
      "97 Train Loss 0.038989667 Test MSE 0.007678045868824779 Test RE 0.04188257852479635\n",
      "98 Train Loss 0.03696912 Test MSE 0.0074270953291139755 Test RE 0.04119244394735848\n",
      "99 Train Loss 0.03545232 Test MSE 0.007550205426637347 Test RE 0.041532439808532474\n",
      "Training time: 80.16\n",
      "KG_stan_tune1\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 58.852234 Test MSE 8.363151291275132 Test RE 1.3822704917640043\n",
      "1 Train Loss 57.88437 Test MSE 8.586076427822462 Test RE 1.4005719855232102\n",
      "2 Train Loss 56.933704 Test MSE 8.252966539617638 Test RE 1.3731345743474939\n",
      "3 Train Loss 53.49852 Test MSE 9.435404144292562 Test RE 1.4682104598092878\n",
      "4 Train Loss 45.653786 Test MSE 8.703330396871463 Test RE 1.4101028669180067\n",
      "5 Train Loss 45.60185 Test MSE 8.643063170790528 Test RE 1.4052121748131445\n",
      "6 Train Loss 45.3173 Test MSE 8.636115548252763 Test RE 1.4046472798033383\n",
      "7 Train Loss 45.003 Test MSE 8.355471185207008 Test RE 1.3816356579569153\n",
      "8 Train Loss 44.253456 Test MSE 8.49229817279443 Test RE 1.3929023702526615\n",
      "9 Train Loss 44.139755 Test MSE 8.383053488297977 Test RE 1.3839142425047677\n",
      "10 Train Loss 43.944057 Test MSE 8.405442319523502 Test RE 1.3857610374968115\n",
      "11 Train Loss 43.901283 Test MSE 8.432214451154005 Test RE 1.3879661732213984\n",
      "12 Train Loss 43.801514 Test MSE 8.483393085469018 Test RE 1.3921718747845029\n",
      "13 Train Loss 43.71291 Test MSE 8.410179147831604 Test RE 1.3861514504775798\n",
      "14 Train Loss 43.622868 Test MSE 8.477559679147488 Test RE 1.3916931453017884\n",
      "15 Train Loss 43.292564 Test MSE 8.632373171243549 Test RE 1.4043429016794478\n",
      "16 Train Loss 42.987938 Test MSE 8.595889529705927 Test RE 1.401372119957448\n",
      "17 Train Loss 42.67737 Test MSE 8.653183595923819 Test RE 1.40603463692612\n",
      "18 Train Loss 42.267334 Test MSE 8.741832334446084 Test RE 1.41321844327821\n",
      "19 Train Loss 41.98557 Test MSE 8.797197580251975 Test RE 1.4176865964369536\n",
      "20 Train Loss 41.45513 Test MSE 9.017097699655894 Test RE 1.4352959120216364\n",
      "21 Train Loss 41.126694 Test MSE 9.080345114930026 Test RE 1.4403208175477578\n",
      "22 Train Loss 39.28127 Test MSE 8.400023786901858 Test RE 1.3853143030109982\n",
      "23 Train Loss 36.58123 Test MSE 9.31484726871599 Test RE 1.4588005872206535\n",
      "24 Train Loss 33.61569 Test MSE 8.258430242923295 Test RE 1.3735890266093693\n",
      "25 Train Loss 32.315422 Test MSE 7.696304114419124 Test RE 1.326017239633209\n",
      "26 Train Loss 31.627047 Test MSE 7.880031312594856 Test RE 1.3417513221101085\n",
      "27 Train Loss 31.16743 Test MSE 7.815786251417668 Test RE 1.3362705499576601\n",
      "28 Train Loss 30.605312 Test MSE 7.9137548127803115 Test RE 1.3446193464166036\n",
      "29 Train Loss 29.760733 Test MSE 7.890662904384002 Test RE 1.3426561499917786\n",
      "30 Train Loss 28.764488 Test MSE 7.8979768904802725 Test RE 1.3432782709698865\n",
      "31 Train Loss 27.382792 Test MSE 8.130169508494845 Test RE 1.362880759752971\n",
      "32 Train Loss 26.07079 Test MSE 8.441025206681902 Test RE 1.3886911214462745\n",
      "33 Train Loss 25.423363 Test MSE 8.481907420958754 Test RE 1.3920499665523223\n",
      "34 Train Loss 24.48444 Test MSE 8.187662718585122 Test RE 1.3676911361776738\n",
      "35 Train Loss 23.272408 Test MSE 7.892592468465248 Test RE 1.3428203049397103\n",
      "36 Train Loss 22.33458 Test MSE 7.733559480095042 Test RE 1.3292227793787108\n",
      "37 Train Loss 21.466728 Test MSE 7.668050693649127 Test RE 1.323581072277057\n",
      "38 Train Loss 20.754189 Test MSE 7.497434641142191 Test RE 1.3087732338624418\n",
      "39 Train Loss 20.413036 Test MSE 7.579444413412972 Test RE 1.3159116941714815\n",
      "40 Train Loss 20.082987 Test MSE 7.608239871995234 Test RE 1.3184089985381187\n",
      "41 Train Loss 19.797316 Test MSE 7.691799074132801 Test RE 1.3256290899811831\n",
      "42 Train Loss 19.465866 Test MSE 7.911003100598919 Test RE 1.3443855555541775\n",
      "43 Train Loss 19.27792 Test MSE 7.848479752800813 Test RE 1.3390624489949987\n",
      "44 Train Loss 18.86462 Test MSE 7.803708938155242 Test RE 1.3352377173770074\n",
      "45 Train Loss 17.65059 Test MSE 7.619842730097948 Test RE 1.3194139277322745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 15.996981 Test MSE 6.961241601458496 Test RE 1.2611054825328512\n",
      "47 Train Loss 15.289131 Test MSE 6.897703097398606 Test RE 1.255336939878765\n",
      "48 Train Loss 14.754126 Test MSE 6.77503509118608 Test RE 1.2441244777333427\n",
      "49 Train Loss 14.375242 Test MSE 6.685540723311816 Test RE 1.2358800721679266\n",
      "50 Train Loss 13.976091 Test MSE 6.655957260130207 Test RE 1.2331426609343838\n",
      "51 Train Loss 13.667709 Test MSE 6.608412922658891 Test RE 1.2287305213556208\n",
      "52 Train Loss 13.296766 Test MSE 6.827487433467124 Test RE 1.2489312000013344\n",
      "53 Train Loss 12.868771 Test MSE 6.67925129433119 Test RE 1.2352986076885173\n",
      "54 Train Loss 12.180496 Test MSE 6.900243146091238 Test RE 1.255568054745079\n",
      "55 Train Loss 11.648466 Test MSE 6.435777412080627 Test RE 1.2125748823003226\n",
      "56 Train Loss 11.064948 Test MSE 6.4142571723153745 Test RE 1.2105458536841116\n",
      "57 Train Loss 10.318421 Test MSE 6.191448455669101 Test RE 1.189334976907576\n",
      "58 Train Loss 9.216521 Test MSE 6.192589577071249 Test RE 1.1894445726732548\n",
      "59 Train Loss 8.146653 Test MSE 5.832992599651719 Test RE 1.154393234914996\n",
      "60 Train Loss 6.451843 Test MSE 5.680892575126445 Test RE 1.1392429474399803\n",
      "61 Train Loss 4.8000994 Test MSE 5.310793372814857 Test RE 1.1015082711840882\n",
      "62 Train Loss 3.7739036 Test MSE 5.230935807617794 Test RE 1.0931952992337628\n",
      "63 Train Loss 3.0796 Test MSE 5.294045040050289 Test RE 1.0997700191302904\n",
      "64 Train Loss 2.7181997 Test MSE 5.233789417969933 Test RE 1.0934934416889865\n",
      "65 Train Loss 2.5077498 Test MSE 5.234512980459171 Test RE 1.093569025881381\n",
      "66 Train Loss 2.2175753 Test MSE 5.3603892547260585 Test RE 1.106639644082245\n",
      "67 Train Loss 2.1347642 Test MSE 5.424134675685375 Test RE 1.1132002426279832\n",
      "68 Train Loss 2.0272403 Test MSE 5.475829045485442 Test RE 1.118492305589897\n",
      "69 Train Loss 1.9265059 Test MSE 5.59318383276794 Test RE 1.1304142070811232\n",
      "70 Train Loss 1.8146127 Test MSE 5.528217495344263 Test RE 1.1238299990846539\n",
      "71 Train Loss 1.7352958 Test MSE 5.5542790098302515 Test RE 1.1264759038651737\n",
      "72 Train Loss 1.6857547 Test MSE 5.5234868115150135 Test RE 1.1233490463843452\n",
      "73 Train Loss 1.6378762 Test MSE 5.531950268392771 Test RE 1.1242093523241856\n",
      "74 Train Loss 1.6001089 Test MSE 5.5600684493128 Test RE 1.1270628356255326\n",
      "75 Train Loss 1.5705167 Test MSE 5.529682634438969 Test RE 1.1239789131049682\n",
      "76 Train Loss 1.5197384 Test MSE 5.608872132612932 Test RE 1.131998444187227\n",
      "77 Train Loss 1.4907107 Test MSE 5.626770013973015 Test RE 1.1338031061963554\n",
      "78 Train Loss 1.4654301 Test MSE 5.611881773070677 Test RE 1.1323021105334383\n",
      "79 Train Loss 1.442371 Test MSE 5.597086474427713 Test RE 1.1308085113297683\n",
      "80 Train Loss 1.4172089 Test MSE 5.639000011549222 Test RE 1.1350346193550962\n",
      "81 Train Loss 1.3797233 Test MSE 5.732023458314346 Test RE 1.1443583419777061\n",
      "82 Train Loss 1.3526665 Test MSE 5.738316151257688 Test RE 1.1449863157146072\n",
      "83 Train Loss 1.3276834 Test MSE 5.765308884158846 Test RE 1.147676133494498\n",
      "84 Train Loss 1.3099736 Test MSE 5.787008561686479 Test RE 1.149833937409826\n",
      "85 Train Loss 1.2923245 Test MSE 5.825289053422007 Test RE 1.1536306881066334\n",
      "86 Train Loss 1.2814112 Test MSE 5.831204025503385 Test RE 1.1542162351878051\n",
      "87 Train Loss 1.2662472 Test MSE 5.872894063025126 Test RE 1.1583349057988088\n",
      "88 Train Loss 1.2542124 Test MSE 5.910992020340231 Test RE 1.1620859402510182\n",
      "89 Train Loss 1.2392048 Test MSE 5.914589029156016 Test RE 1.16243946785122\n",
      "90 Train Loss 1.2288327 Test MSE 5.941665395149706 Test RE 1.1650971923901494\n",
      "91 Train Loss 1.2095175 Test MSE 5.917297376455351 Test RE 1.1627055835062823\n",
      "92 Train Loss 1.1979042 Test MSE 5.928385908911076 Test RE 1.1637944813143188\n",
      "93 Train Loss 1.1865127 Test MSE 5.983446885102256 Test RE 1.169186468295255\n",
      "94 Train Loss 1.177183 Test MSE 5.9995060830730536 Test RE 1.1707544286751834\n",
      "95 Train Loss 1.1674976 Test MSE 5.976696465008207 Test RE 1.1685267543141247\n",
      "96 Train Loss 1.1504581 Test MSE 6.022506951802548 Test RE 1.1729964973104046\n",
      "97 Train Loss 1.1395823 Test MSE 6.052112347049299 Test RE 1.1758760665717176\n",
      "98 Train Loss 1.1286632 Test MSE 6.05197142146541 Test RE 1.1758623761462572\n",
      "99 Train Loss 1.1146082 Test MSE 6.0390874225362055 Test RE 1.1746100667569535\n",
      "Training time: 80.28\n",
      "KG_stan_tune1\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 59.235073 Test MSE 8.488111480582036 Test RE 1.3925589783748586\n",
      "1 Train Loss 58.880108 Test MSE 8.62722709672807 Test RE 1.4039242491001855\n",
      "2 Train Loss 58.20116 Test MSE 8.509476369297415 Test RE 1.3943104380227986\n",
      "3 Train Loss 55.841034 Test MSE 9.491790103102801 Test RE 1.4725909367083252\n",
      "4 Train Loss 48.629135 Test MSE 8.931539797122122 Test RE 1.428470345839035\n",
      "5 Train Loss 48.201202 Test MSE 8.800802450041262 Test RE 1.417977032800155\n",
      "6 Train Loss 47.266987 Test MSE 8.738684800379316 Test RE 1.4129640027049957\n",
      "7 Train Loss 46.750217 Test MSE 8.522842577592094 Test RE 1.3954050606721156\n",
      "8 Train Loss 46.30313 Test MSE 8.518362406511775 Test RE 1.3950382537571626\n",
      "9 Train Loss 45.815193 Test MSE 8.461728422884157 Test RE 1.3903930927395605\n",
      "10 Train Loss 45.328575 Test MSE 8.368300227332934 Test RE 1.3826959370896943\n",
      "11 Train Loss 44.861897 Test MSE 8.482826861336942 Test RE 1.392125413748367\n",
      "12 Train Loss 44.070827 Test MSE 8.717500324302222 Test RE 1.411250297165276\n",
      "13 Train Loss 43.69258 Test MSE 8.784685446234159 Test RE 1.416678059556465\n",
      "14 Train Loss 43.097916 Test MSE 8.787772042187715 Test RE 1.4169269204155217\n",
      "15 Train Loss 42.882744 Test MSE 8.817094454950555 Test RE 1.4192889022211728\n",
      "16 Train Loss 42.368637 Test MSE 8.851792598936933 Test RE 1.4220788425801862\n",
      "17 Train Loss 42.039444 Test MSE 8.8561666250428 Test RE 1.4224301523114324\n",
      "18 Train Loss 41.413166 Test MSE 8.4266257180705 Test RE 1.3875061364042265\n",
      "19 Train Loss 39.689896 Test MSE 7.8642683164349 Test RE 1.340408649240568\n",
      "20 Train Loss 36.726273 Test MSE 7.930482608272286 Test RE 1.3460396989901062\n",
      "21 Train Loss 32.749916 Test MSE 8.29609505860621 Test RE 1.3767177763311678\n",
      "22 Train Loss 30.761631 Test MSE 8.45711669519785 Test RE 1.3900141519425329\n",
      "23 Train Loss 28.980839 Test MSE 8.27460856699843 Test RE 1.3749338037018515\n",
      "24 Train Loss 27.774082 Test MSE 8.272870716002139 Test RE 1.3747894128504456\n",
      "25 Train Loss 25.954132 Test MSE 8.190302806265539 Test RE 1.3679116223906094\n",
      "26 Train Loss 23.774899 Test MSE 7.412309383523869 Test RE 1.3013221718549792\n",
      "27 Train Loss 21.742153 Test MSE 7.081562808939314 Test RE 1.271957545526551\n",
      "28 Train Loss 20.152754 Test MSE 6.6821537282982355 Test RE 1.2355669748350553\n",
      "29 Train Loss 18.65567 Test MSE 6.563451873261218 Test RE 1.224543487215469\n",
      "30 Train Loss 17.413673 Test MSE 6.32355563343717 Test RE 1.2019564494995314\n",
      "31 Train Loss 16.656116 Test MSE 6.1620187254652246 Test RE 1.186504984838834\n",
      "32 Train Loss 15.1656685 Test MSE 5.927034267342818 Test RE 1.1636618041663473\n",
      "33 Train Loss 13.857325 Test MSE 5.693778127182696 Test RE 1.1405342462344332\n",
      "34 Train Loss 12.678521 Test MSE 5.914301902180051 Test RE 1.1624112518772671\n",
      "35 Train Loss 12.065519 Test MSE 5.95057086729456 Test RE 1.1659699995055388\n",
      "36 Train Loss 11.542478 Test MSE 5.899783317943331 Test RE 1.1609836162958274\n",
      "37 Train Loss 11.353025 Test MSE 6.005416131165406 Test RE 1.1713309354500725\n",
      "38 Train Loss 11.045107 Test MSE 6.061047090128117 Test RE 1.176743720313338\n",
      "39 Train Loss 10.646344 Test MSE 6.091270225344553 Test RE 1.1796739614558596\n",
      "40 Train Loss 10.47069 Test MSE 5.963980245937798 Test RE 1.167282994114915\n",
      "41 Train Loss 9.476695 Test MSE 5.384065288710476 Test RE 1.1090808819293303\n",
      "42 Train Loss 7.271306 Test MSE 4.705394416367037 Test RE 1.0368264713039388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Train Loss 5.597945 Test MSE 4.737272975625511 Test RE 1.0403327385952765\n",
      "44 Train Loss 4.7285466 Test MSE 4.699831281901642 Test RE 1.0362133759460463\n",
      "45 Train Loss 4.502361 Test MSE 4.566697197742241 Test RE 1.0214313148931555\n",
      "46 Train Loss 4.127495 Test MSE 4.50282871605733 Test RE 1.014263445990937\n",
      "47 Train Loss 3.9369798 Test MSE 4.617478563807831 Test RE 1.0270947380018969\n",
      "48 Train Loss 3.7520947 Test MSE 4.6601748365971405 Test RE 1.0318324112518276\n",
      "49 Train Loss 3.659985 Test MSE 4.703164357002262 Test RE 1.036580747098951\n",
      "50 Train Loss 3.5303807 Test MSE 4.7971340691558595 Test RE 1.0468850269858396\n",
      "51 Train Loss 3.4218533 Test MSE 4.762748265105455 Test RE 1.0431262489939603\n",
      "52 Train Loss 3.2987912 Test MSE 4.785095459855399 Test RE 1.0455706008574517\n",
      "53 Train Loss 3.2507234 Test MSE 4.759983606800952 Test RE 1.0428234504715146\n",
      "54 Train Loss 3.1786036 Test MSE 4.74760394300775 Test RE 1.0414664911205787\n",
      "55 Train Loss 3.1132934 Test MSE 4.800773721977403 Test RE 1.0472820948527994\n",
      "56 Train Loss 3.0054414 Test MSE 4.878704069842135 Test RE 1.0557480747400874\n",
      "57 Train Loss 2.965974 Test MSE 4.858035910576026 Test RE 1.0535094138072791\n",
      "58 Train Loss 2.9010148 Test MSE 4.8709727654806745 Test RE 1.054911218696456\n",
      "59 Train Loss 2.8216531 Test MSE 4.950727938165048 Test RE 1.063512480245516\n",
      "60 Train Loss 2.7721987 Test MSE 4.964361267608009 Test RE 1.0649758254257946\n",
      "61 Train Loss 2.7202575 Test MSE 4.980684307506468 Test RE 1.0667252324340764\n",
      "62 Train Loss 2.6649015 Test MSE 4.914966674321025 Test RE 1.0596644116902088\n",
      "63 Train Loss 2.6203105 Test MSE 4.9784443528657585 Test RE 1.0664853372013483\n",
      "64 Train Loss 2.5815763 Test MSE 5.0203992227703385 Test RE 1.070969707938159\n",
      "65 Train Loss 2.5466897 Test MSE 4.98510499060846 Test RE 1.0671985216469255\n",
      "66 Train Loss 2.4773104 Test MSE 5.02115999732114 Test RE 1.0710508504527199\n",
      "67 Train Loss 2.446623 Test MSE 5.043629105177001 Test RE 1.0734445896003861\n",
      "68 Train Loss 2.4218612 Test MSE 4.992824567282563 Test RE 1.0680244956212352\n",
      "69 Train Loss 2.3672519 Test MSE 5.020406936069607 Test RE 1.0709705306522825\n",
      "70 Train Loss 2.3456857 Test MSE 5.054990758488183 Test RE 1.0746529699435807\n",
      "71 Train Loss 2.3119948 Test MSE 5.1172367886679995 Test RE 1.081249244453833\n",
      "72 Train Loss 2.2968023 Test MSE 5.1065258860074545 Test RE 1.080117068791906\n",
      "73 Train Loss 2.255605 Test MSE 5.100907898502394 Test RE 1.0795227553374989\n",
      "74 Train Loss 2.2251675 Test MSE 5.1262096029264175 Test RE 1.0821967870278966\n",
      "75 Train Loss 2.2007847 Test MSE 5.146024882549713 Test RE 1.0842863766729154\n",
      "76 Train Loss 2.1694481 Test MSE 5.146970808332354 Test RE 1.0843860271151569\n",
      "77 Train Loss 2.1431665 Test MSE 5.133684452144659 Test RE 1.0829855092727654\n",
      "78 Train Loss 2.125837 Test MSE 5.152901225291446 Test RE 1.0850105701869506\n",
      "79 Train Loss 2.1107287 Test MSE 5.154106090943447 Test RE 1.0851374128626774\n",
      "80 Train Loss 2.0828302 Test MSE 5.143543809938121 Test RE 1.0840249595956408\n",
      "81 Train Loss 2.0629852 Test MSE 5.181769845081517 Test RE 1.088045657417415\n",
      "82 Train Loss 2.032758 Test MSE 5.189270492923861 Test RE 1.0888328494771682\n",
      "83 Train Loss 2.007687 Test MSE 5.180005862833622 Test RE 1.0878604449657223\n",
      "84 Train Loss 1.9866866 Test MSE 5.228020231723927 Test RE 1.0928905986763782\n",
      "85 Train Loss 1.9691938 Test MSE 5.217043252832691 Test RE 1.091742655450737\n",
      "86 Train Loss 1.9386594 Test MSE 5.2019447679854744 Test RE 1.0901617213235377\n",
      "87 Train Loss 1.9129405 Test MSE 5.216461156658717 Test RE 1.0916817476798517\n",
      "88 Train Loss 1.8769916 Test MSE 5.262373030518142 Test RE 1.0964753570318129\n",
      "89 Train Loss 1.8541677 Test MSE 5.279939815068233 Test RE 1.098303952074756\n",
      "90 Train Loss 1.8217567 Test MSE 5.299177601120248 Test RE 1.1003030018770854\n",
      "91 Train Loss 1.8035203 Test MSE 5.339579563408455 Test RE 1.1044894995708627\n",
      "92 Train Loss 1.7689017 Test MSE 5.330313675816238 Test RE 1.1035307612340979\n",
      "93 Train Loss 1.7412977 Test MSE 5.378349516721268 Test RE 1.1084920204980144\n",
      "94 Train Loss 1.7106385 Test MSE 5.455627804024524 Test RE 1.1164272474414638\n",
      "95 Train Loss 1.6617151 Test MSE 5.460704417897909 Test RE 1.1169465600108273\n",
      "96 Train Loss 1.6216116 Test MSE 5.480883919352516 Test RE 1.1190084405241243\n",
      "97 Train Loss 1.5926154 Test MSE 5.525688034919117 Test RE 1.1235728629684736\n",
      "98 Train Loss 1.5650878 Test MSE 5.572252172395084 Test RE 1.1282970207115919\n",
      "99 Train Loss 1.5405953 Test MSE 5.563316657982203 Test RE 1.1273920043022125\n",
      "Training time: 80.27\n",
      "KG_stan_tune1\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.75693 Test MSE 8.402791653030208 Test RE 1.385542519550813\n",
      "1 Train Loss 55.29153 Test MSE 8.604820893417294 Test RE 1.4020999628749269\n",
      "2 Train Loss 54.65149 Test MSE 8.442537710501458 Test RE 1.3888155320772337\n",
      "3 Train Loss 47.203606 Test MSE 7.964406154357909 Test RE 1.3489155461863669\n",
      "4 Train Loss 45.607788 Test MSE 8.012129979005424 Test RE 1.3529509544143248\n",
      "5 Train Loss 44.443115 Test MSE 8.043780082009782 Test RE 1.3556205835765944\n",
      "6 Train Loss 44.293774 Test MSE 8.215351179324834 Test RE 1.3700017650926888\n",
      "7 Train Loss 43.48639 Test MSE 8.021654024970806 Test RE 1.3537548442730438\n",
      "8 Train Loss 43.2637 Test MSE 7.979651151404378 Test RE 1.3502059363187053\n",
      "9 Train Loss 43.10893 Test MSE 7.939153222099325 Test RE 1.3467753290073115\n",
      "10 Train Loss 42.809345 Test MSE 7.877498707287636 Test RE 1.3415356884746619\n",
      "11 Train Loss 42.69288 Test MSE 7.885840167372667 Test RE 1.3422457746339669\n",
      "12 Train Loss 42.625458 Test MSE 7.881377780577535 Test RE 1.3418659503365682\n",
      "13 Train Loss 41.905304 Test MSE 7.801892436606354 Test RE 1.3350823039342732\n",
      "14 Train Loss 41.61563 Test MSE 7.540606966041856 Test RE 1.3125359660245632\n",
      "15 Train Loss 40.292156 Test MSE 7.31549559637597 Test RE 1.2927958130416786\n",
      "16 Train Loss 36.976555 Test MSE 6.989323139076981 Test RE 1.2636465621471022\n",
      "17 Train Loss 35.050602 Test MSE 7.046429874629978 Test RE 1.2687984148470006\n",
      "18 Train Loss 34.633263 Test MSE 6.900037005947839 Test RE 1.2555492999775701\n",
      "19 Train Loss 33.990555 Test MSE 6.6017743728409 Test RE 1.2281131992806436\n",
      "20 Train Loss 33.26352 Test MSE 6.600378420334963 Test RE 1.227983349467687\n",
      "21 Train Loss 32.039017 Test MSE 5.938070342495874 Test RE 1.1647446633220315\n",
      "22 Train Loss 30.92939 Test MSE 6.123715456896071 Test RE 1.182811563377161\n",
      "23 Train Loss 30.730455 Test MSE 6.1657078648424015 Test RE 1.1868601060667898\n",
      "24 Train Loss 30.340408 Test MSE 6.403166847390762 Test RE 1.2094988770303852\n",
      "25 Train Loss 29.185152 Test MSE 6.269524017419456 Test RE 1.1968103753028558\n",
      "26 Train Loss 28.864876 Test MSE 6.316360015825403 Test RE 1.2012723975763218\n",
      "27 Train Loss 28.117321 Test MSE 6.075010662521865 Test RE 1.178098444417159\n",
      "28 Train Loss 27.551273 Test MSE 5.553771797335434 Test RE 1.1264244682335434\n",
      "29 Train Loss 27.030947 Test MSE 5.920639837156579 Test RE 1.163033921666554\n",
      "30 Train Loss 26.802475 Test MSE 5.875327863086198 Test RE 1.15857489510574\n",
      "31 Train Loss 26.185024 Test MSE 5.635892898816127 Test RE 1.1347218718423353\n",
      "32 Train Loss 25.76728 Test MSE 5.801101227795163 Test RE 1.1512331380805059\n",
      "33 Train Loss 24.65388 Test MSE 5.638005347606552 Test RE 1.1349345104885615\n",
      "34 Train Loss 24.24179 Test MSE 5.462680586314641 Test RE 1.1171486470206018\n",
      "35 Train Loss 23.463352 Test MSE 5.52026013465136 Test RE 1.1230208828512669\n",
      "36 Train Loss 22.99675 Test MSE 5.338145425958509 Test RE 1.1043411642844105\n",
      "37 Train Loss 22.17492 Test MSE 5.014672623692235 Test RE 1.0703587242495702\n",
      "38 Train Loss 20.572851 Test MSE 4.406456492848925 Test RE 1.00335080515711\n",
      "39 Train Loss 18.952173 Test MSE 3.8695255471321026 Test RE 0.9402360949718098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Train Loss 18.453785 Test MSE 3.9121310031869503 Test RE 0.9453981648443641\n",
      "41 Train Loss 16.458185 Test MSE 2.49805499226632 Test RE 0.755455796176075\n",
      "42 Train Loss 12.10364 Test MSE 2.5195965021319804 Test RE 0.7587060700452902\n",
      "43 Train Loss 10.125104 Test MSE 2.003310596467679 Test RE 0.6765224366205106\n",
      "44 Train Loss 9.4258175 Test MSE 2.248688251800513 Test RE 0.7167582257482671\n",
      "45 Train Loss 8.610478 Test MSE 2.1498720594019938 Test RE 0.7008327173194993\n",
      "46 Train Loss 7.7281847 Test MSE 2.0467523058912374 Test RE 0.683818277114226\n",
      "47 Train Loss 7.3238535 Test MSE 2.0700360738821644 Test RE 0.6876968217215009\n",
      "48 Train Loss 7.003806 Test MSE 2.0426888739382165 Test RE 0.6831391452236916\n",
      "49 Train Loss 6.4960966 Test MSE 2.0640926806006137 Test RE 0.686708870177024\n",
      "50 Train Loss 6.201475 Test MSE 2.0065097072936133 Test RE 0.6770623945548154\n",
      "51 Train Loss 6.0269527 Test MSE 2.014750844325266 Test RE 0.6784513851951107\n",
      "52 Train Loss 5.791404 Test MSE 2.0554736944637892 Test RE 0.685273632819824\n",
      "53 Train Loss 5.727171 Test MSE 2.0392767017030264 Test RE 0.6825683381108285\n",
      "54 Train Loss 5.6494694 Test MSE 1.9988260525856714 Test RE 0.6757647921603196\n",
      "55 Train Loss 5.535586 Test MSE 2.013010733684185 Test RE 0.6781583376699549\n",
      "56 Train Loss 5.474046 Test MSE 1.9763946031784445 Test RE 0.6719622721579248\n",
      "57 Train Loss 5.4523993 Test MSE 1.9775807514421249 Test RE 0.672163883548821\n",
      "58 Train Loss 5.385186 Test MSE 1.9959168340347027 Test RE 0.6752728375629714\n",
      "59 Train Loss 5.32932 Test MSE 2.0045792376161193 Test RE 0.6767366141840697\n",
      "60 Train Loss 5.2974625 Test MSE 1.9977273576757006 Test RE 0.6755790427822039\n",
      "61 Train Loss 5.241935 Test MSE 1.9763761840636638 Test RE 0.6719591409565351\n",
      "62 Train Loss 5.224762 Test MSE 1.9934389354930058 Test RE 0.6748535372183642\n",
      "63 Train Loss 5.196998 Test MSE 1.9835046442618531 Test RE 0.6731698726450531\n",
      "64 Train Loss 5.144947 Test MSE 1.9805506773240076 Test RE 0.6726684212205447\n",
      "65 Train Loss 5.0998874 Test MSE 1.9974906032486532 Test RE 0.6755390095244748\n",
      "66 Train Loss 5.081209 Test MSE 2.0120968707393585 Test RE 0.6780043856520505\n",
      "67 Train Loss 5.0465856 Test MSE 2.0267242650006536 Test RE 0.6804643761620699\n",
      "68 Train Loss 5.0218825 Test MSE 2.028523247475388 Test RE 0.6807663096767126\n",
      "69 Train Loss 4.9827747 Test MSE 2.030134772450381 Test RE 0.6810366674630057\n",
      "70 Train Loss 4.9695945 Test MSE 2.034398423920148 Test RE 0.6817514426716779\n",
      "71 Train Loss 4.9559216 Test MSE 2.042190195849687 Test RE 0.6830557533470316\n",
      "72 Train Loss 4.9371185 Test MSE 2.0428481045919864 Test RE 0.6831657705640344\n",
      "73 Train Loss 4.930393 Test MSE 2.0420247607814876 Test RE 0.6830280860749081\n",
      "74 Train Loss 4.9200997 Test MSE 2.035114465427443 Test RE 0.6818714091881056\n",
      "75 Train Loss 4.9149528 Test MSE 2.033670164553196 Test RE 0.6816294075017659\n",
      "76 Train Loss 4.9096212 Test MSE 2.037371363717701 Test RE 0.6822493948062001\n",
      "77 Train Loss 4.902368 Test MSE 2.040637120686936 Test RE 0.6827959737499987\n",
      "78 Train Loss 4.8961973 Test MSE 2.0414622484293337 Test RE 0.6829340034257125\n",
      "79 Train Loss 4.8920064 Test MSE 2.038141673746295 Test RE 0.682378358502721\n",
      "80 Train Loss 4.885633 Test MSE 2.04147622041895 Test RE 0.6829363404590045\n",
      "81 Train Loss 4.872491 Test MSE 2.044111755202891 Test RE 0.6833770318374004\n",
      "82 Train Loss 4.8582826 Test MSE 2.0452479400002357 Test RE 0.683566927211105\n",
      "83 Train Loss 4.853937 Test MSE 2.0462510116794257 Test RE 0.6837345309923162\n",
      "84 Train Loss 4.8460155 Test MSE 2.045237558129104 Test RE 0.6835651922838584\n",
      "85 Train Loss 4.8401165 Test MSE 2.0505798106598587 Test RE 0.6844573615874214\n",
      "86 Train Loss 4.8373303 Test MSE 2.0476627602531483 Test RE 0.6839703512344762\n",
      "87 Train Loss 4.8343115 Test MSE 2.0403915890246065 Test RE 0.6827548951398017\n",
      "88 Train Loss 4.8315306 Test MSE 2.037932005854846 Test RE 0.6823432587564225\n",
      "89 Train Loss 4.826212 Test MSE 2.0403130385260853 Test RE 0.6827417527474674\n",
      "90 Train Loss 4.818446 Test MSE 2.0458030390504525 Test RE 0.6836596840846738\n",
      "91 Train Loss 4.816104 Test MSE 2.0475819478134007 Test RE 0.6839568544177075\n",
      "92 Train Loss 4.8133993 Test MSE 2.051088639940451 Test RE 0.6845422766789433\n",
      "93 Train Loss 4.809974 Test MSE 2.0494607855412244 Test RE 0.6842705779522954\n",
      "94 Train Loss 4.801178 Test MSE 2.0422299875641365 Test RE 0.6830624079248343\n",
      "95 Train Loss 4.7953715 Test MSE 2.0468626542037844 Test RE 0.6838367105064148\n",
      "96 Train Loss 4.7871428 Test MSE 2.0586974251525163 Test RE 0.6858108014885127\n",
      "97 Train Loss 4.7719646 Test MSE 2.062463062618932 Test RE 0.6864377355278601\n",
      "98 Train Loss 4.767999 Test MSE 2.0667430003288465 Test RE 0.6871495999546227\n",
      "99 Train Loss 4.765129 Test MSE 2.0668203022360268 Test RE 0.6871624504827013\n",
      "Training time: 81.00\n",
      "KG_stan_tune1\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 54.189404 Test MSE 8.32915988526295 Test RE 1.3794585638664387\n",
      "1 Train Loss 40.923866 Test MSE 9.415518672951155 Test RE 1.466662489221318\n",
      "2 Train Loss 40.30374 Test MSE 9.213626681014322 Test RE 1.4508528461179704\n",
      "3 Train Loss 40.02752 Test MSE 9.40620554365743 Test RE 1.465936953156424\n",
      "4 Train Loss 39.966896 Test MSE 9.382361332370225 Test RE 1.4640777395719307\n",
      "5 Train Loss 39.79518 Test MSE 9.221343767940853 Test RE 1.451460316686166\n",
      "6 Train Loss 39.563004 Test MSE 9.09466064293869 Test RE 1.4414557321623689\n",
      "7 Train Loss 38.658707 Test MSE 9.182082975668473 Test RE 1.4483671521629746\n",
      "8 Train Loss 37.300854 Test MSE 9.003146404440647 Test RE 1.4341851339723826\n",
      "9 Train Loss 36.536938 Test MSE 9.192736432757014 Test RE 1.4492071382676546\n",
      "10 Train Loss 35.675083 Test MSE 9.115586003761665 Test RE 1.4431130590473724\n",
      "11 Train Loss 34.805138 Test MSE 9.315991482486295 Test RE 1.458890182273342\n",
      "12 Train Loss 34.546684 Test MSE 9.283147131711525 Test RE 1.4563161884649873\n",
      "13 Train Loss 34.28456 Test MSE 9.095692750409093 Test RE 1.4415375216365045\n",
      "14 Train Loss 33.88465 Test MSE 8.809040971720979 Test RE 1.4186405689920583\n",
      "15 Train Loss 33.59478 Test MSE 8.967365168779168 Test RE 1.4313323532458357\n",
      "16 Train Loss 33.33486 Test MSE 8.984223582009855 Test RE 1.432677155288348\n",
      "17 Train Loss 32.51294 Test MSE 8.8619830649506 Test RE 1.4228971783884345\n",
      "18 Train Loss 31.228182 Test MSE 8.86393028292557 Test RE 1.4230534943484026\n",
      "19 Train Loss 29.483532 Test MSE 8.724476737468763 Test RE 1.4118148796603562\n",
      "20 Train Loss 28.424809 Test MSE 8.533944961927213 Test RE 1.3963136355468424\n",
      "21 Train Loss 27.723984 Test MSE 8.71964058489609 Test RE 1.4114235267563222\n",
      "22 Train Loss 26.887741 Test MSE 8.883237294145212 Test RE 1.424602466645449\n",
      "23 Train Loss 26.285149 Test MSE 8.73962044716944 Test RE 1.4130396433693728\n",
      "24 Train Loss 25.484673 Test MSE 8.456302813373513 Test RE 1.3899472654069593\n",
      "25 Train Loss 24.46632 Test MSE 8.456685299933255 Test RE 1.38997869936504\n",
      "26 Train Loss 22.591291 Test MSE 7.565120897658411 Test RE 1.3146677114881642\n",
      "27 Train Loss 20.404207 Test MSE 6.487241483678075 Test RE 1.2174134416928657\n",
      "28 Train Loss 16.461517 Test MSE 6.064812435201726 Test RE 1.1771091817729575\n",
      "29 Train Loss 14.061927 Test MSE 5.421502220728944 Test RE 1.112930079246074\n",
      "30 Train Loss 12.807953 Test MSE 5.389146878645097 Test RE 1.109604144998548\n",
      "31 Train Loss 12.08012 Test MSE 5.271974217435761 Test RE 1.0974751595291192\n",
      "32 Train Loss 11.458164 Test MSE 5.192123949375656 Test RE 1.0891321699821581\n",
      "33 Train Loss 10.966969 Test MSE 5.233012257031209 Test RE 1.0934122527194485\n",
      "34 Train Loss 10.502472 Test MSE 5.196701546488304 Test RE 1.0896121768086824\n",
      "35 Train Loss 10.258306 Test MSE 5.184374405664971 Test RE 1.0883190702571977\n",
      "36 Train Loss 9.877195 Test MSE 5.05513340076331 Test RE 1.0746681321733993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Train Loss 9.618191 Test MSE 4.9302801712090885 Test RE 1.0613139190729157\n",
      "38 Train Loss 9.223697 Test MSE 4.990594147905285 Test RE 1.0677859123705713\n",
      "39 Train Loss 8.946978 Test MSE 4.983480350737783 Test RE 1.0670246081028367\n",
      "40 Train Loss 8.785891 Test MSE 4.908229761504566 Test RE 1.0589379251027085\n",
      "41 Train Loss 8.5254 Test MSE 4.739951740332285 Test RE 1.0406268331923518\n",
      "42 Train Loss 6.8842936 Test MSE 4.091752967898931 Test RE 0.9668581520514726\n",
      "43 Train Loss 5.966736 Test MSE 3.9651075832845133 Test RE 0.9517777499734436\n",
      "44 Train Loss 5.5193367 Test MSE 4.009892994999875 Test RE 0.9571377647126205\n",
      "45 Train Loss 5.1263027 Test MSE 4.171584320777196 Test RE 0.9762444401174226\n",
      "46 Train Loss 4.888036 Test MSE 4.285519261861144 Test RE 0.9894863010693795\n",
      "47 Train Loss 4.5903883 Test MSE 4.260936103766311 Test RE 0.9866442088132034\n",
      "48 Train Loss 4.482148 Test MSE 4.3020755460596884 Test RE 0.9913958041553164\n",
      "49 Train Loss 4.366915 Test MSE 4.3420484836682 Test RE 0.9959909552293084\n",
      "50 Train Loss 4.246081 Test MSE 4.363436796952948 Test RE 0.9984409966922941\n",
      "51 Train Loss 4.174733 Test MSE 4.401725830174318 Test RE 1.0028120742255162\n",
      "52 Train Loss 4.0513287 Test MSE 4.431732140032768 Test RE 1.0062243247173235\n",
      "53 Train Loss 3.9792156 Test MSE 4.443111329532939 Test RE 1.0075153184401997\n",
      "54 Train Loss 3.903663 Test MSE 4.473257516077759 Test RE 1.0109274993774047\n",
      "55 Train Loss 3.8580616 Test MSE 4.460467138415335 Test RE 1.0094811931360856\n",
      "56 Train Loss 3.8331573 Test MSE 4.434368810253551 Test RE 1.006523608059764\n",
      "57 Train Loss 3.7965274 Test MSE 4.43003326755257 Test RE 1.0060314418198946\n",
      "58 Train Loss 3.7389946 Test MSE 4.509980906000654 Test RE 1.015068642785869\n",
      "59 Train Loss 3.7095914 Test MSE 4.508262877513013 Test RE 1.0148752846547842\n",
      "60 Train Loss 3.6877584 Test MSE 4.518457154694933 Test RE 1.0160220764659211\n",
      "61 Train Loss 3.669148 Test MSE 4.564781854456685 Test RE 1.0212170903995934\n",
      "62 Train Loss 3.6489062 Test MSE 4.580663975438021 Test RE 1.0229920941918107\n",
      "63 Train Loss 3.6256642 Test MSE 4.570469891770449 Test RE 1.0218531462626355\n",
      "64 Train Loss 3.603199 Test MSE 4.5899112165865565 Test RE 1.0240241591029313\n",
      "65 Train Loss 3.5752764 Test MSE 4.6379283805934035 Test RE 1.0293666159156947\n",
      "66 Train Loss 3.566783 Test MSE 4.639497329385759 Test RE 1.02954071163412\n",
      "67 Train Loss 3.5467396 Test MSE 4.614924697916527 Test RE 1.0268106625072522\n",
      "68 Train Loss 3.5352647 Test MSE 4.6218066918809315 Test RE 1.0275759916003917\n",
      "69 Train Loss 3.5215135 Test MSE 4.620287680551176 Test RE 1.0274071152333568\n",
      "70 Train Loss 3.5096245 Test MSE 4.601404126593528 Test RE 1.0253054104061416\n",
      "71 Train Loss 3.4999037 Test MSE 4.600996145112429 Test RE 1.0252599552710304\n",
      "72 Train Loss 3.4903686 Test MSE 4.599623694620002 Test RE 1.0251070293137408\n",
      "73 Train Loss 3.4835048 Test MSE 4.604429187315583 Test RE 1.0256423837995956\n",
      "74 Train Loss 3.4718106 Test MSE 4.635453392268386 Test RE 1.0290919231947788\n",
      "75 Train Loss 3.462337 Test MSE 4.64372510615857 Test RE 1.0300096931691314\n",
      "76 Train Loss 3.454574 Test MSE 4.641014857829156 Test RE 1.0297090735778882\n",
      "77 Train Loss 3.443257 Test MSE 4.643547287581673 Test RE 1.0299899722977377\n",
      "78 Train Loss 3.4359848 Test MSE 4.633018299939966 Test RE 1.0288215868516497\n",
      "79 Train Loss 3.4275632 Test MSE 4.638475767863343 Test RE 1.0294273591517766\n",
      "80 Train Loss 3.4202118 Test MSE 4.638452445556598 Test RE 1.0294247711625295\n",
      "81 Train Loss 3.412839 Test MSE 4.6303725144706345 Test RE 1.0285277794716723\n",
      "82 Train Loss 3.4057317 Test MSE 4.653711876060853 Test RE 1.0311166649428969\n",
      "83 Train Loss 3.4001017 Test MSE 4.667932420811468 Test RE 1.0326908767259133\n",
      "84 Train Loss 3.3942635 Test MSE 4.668974111518408 Test RE 1.0328060973829045\n",
      "85 Train Loss 3.3901248 Test MSE 4.676292578107875 Test RE 1.0336152255882756\n",
      "86 Train Loss 3.3866026 Test MSE 4.6716699465673175 Test RE 1.0331042220908202\n",
      "87 Train Loss 3.3837996 Test MSE 4.658124674893268 Test RE 1.0316054180508722\n",
      "88 Train Loss 3.378714 Test MSE 4.656460995087961 Test RE 1.031421179275431\n",
      "89 Train Loss 3.373521 Test MSE 4.676241229428092 Test RE 1.033609550694965\n",
      "90 Train Loss 3.3698785 Test MSE 4.671097129828353 Test RE 1.0330408831199975\n",
      "91 Train Loss 3.3651948 Test MSE 4.655399207701818 Test RE 1.0313035778999982\n",
      "92 Train Loss 3.356266 Test MSE 4.672719965062577 Test RE 1.0332203173635457\n",
      "93 Train Loss 3.349744 Test MSE 4.705725282570217 Test RE 1.0368629235943578\n",
      "94 Train Loss 3.3434696 Test MSE 4.705385482282918 Test RE 1.036825486997578\n",
      "95 Train Loss 3.3376265 Test MSE 4.693415994639424 Test RE 1.035505916877382\n",
      "96 Train Loss 3.332506 Test MSE 4.687546639546997 Test RE 1.0348582379526052\n",
      "97 Train Loss 3.326901 Test MSE 4.687021559307992 Test RE 1.034800275987587\n",
      "98 Train Loss 3.322401 Test MSE 4.688273321997847 Test RE 1.0349384488001645\n",
      "99 Train Loss 3.3122141 Test MSE 4.689283143524571 Test RE 1.035049902077494\n",
      "Training time: 79.85\n",
      "KG_stan_tune1\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.82176 Test MSE 8.548628447167925 Test RE 1.397514366222018\n",
      "1 Train Loss 56.340916 Test MSE 8.674108038402618 Test RE 1.4077335912158568\n",
      "2 Train Loss 47.16543 Test MSE 8.592350703543108 Test RE 1.4010836260894088\n",
      "3 Train Loss 44.50258 Test MSE 8.679021636451768 Test RE 1.4081322522485267\n",
      "4 Train Loss 43.989487 Test MSE 8.64314119325545 Test RE 1.4052185173486564\n",
      "5 Train Loss 43.61876 Test MSE 8.437451870920741 Test RE 1.3883971533083421\n",
      "6 Train Loss 43.517464 Test MSE 8.43375744418051 Test RE 1.38809315790466\n",
      "7 Train Loss 43.425232 Test MSE 8.426941519222416 Test RE 1.387532135656215\n",
      "8 Train Loss 43.17099 Test MSE 8.387707957338499 Test RE 1.3842983801075655\n",
      "9 Train Loss 43.062874 Test MSE 8.427525975513229 Test RE 1.3875802514419358\n",
      "10 Train Loss 43.04988 Test MSE 8.394093484069346 Test RE 1.3848252101206662\n",
      "11 Train Loss 42.960945 Test MSE 8.36139650898168 Test RE 1.3821254680194583\n",
      "12 Train Loss 42.843117 Test MSE 8.454613256676948 Test RE 1.389808403774688\n",
      "13 Train Loss 42.673416 Test MSE 8.530019658379857 Test RE 1.3959924719293058\n",
      "14 Train Loss 42.57395 Test MSE 8.43772017709864 Test RE 1.388419228253356\n",
      "15 Train Loss 42.195522 Test MSE 8.512117849763769 Test RE 1.3945268295991633\n",
      "16 Train Loss 41.97683 Test MSE 8.439950244497137 Test RE 1.388602693919111\n",
      "17 Train Loss 41.434807 Test MSE 8.491205106559862 Test RE 1.3928127252876874\n",
      "18 Train Loss 40.55706 Test MSE 8.290124746359632 Test RE 1.3762223074231887\n",
      "19 Train Loss 39.60686 Test MSE 8.155479745755562 Test RE 1.365000520624604\n",
      "20 Train Loss 38.385216 Test MSE 8.003328621533877 Test RE 1.3522076391527795\n",
      "21 Train Loss 37.283104 Test MSE 7.916638205667355 Test RE 1.3448642815239606\n",
      "22 Train Loss 36.32621 Test MSE 7.775240438879544 Test RE 1.3327999697941824\n",
      "23 Train Loss 34.421272 Test MSE 7.748461010663219 Test RE 1.330502779974522\n",
      "24 Train Loss 32.665546 Test MSE 7.005399171072881 Test RE 1.2650989742301042\n",
      "25 Train Loss 31.553387 Test MSE 7.166916572280096 Test RE 1.2796000099514195\n",
      "26 Train Loss 30.850647 Test MSE 7.185589256719005 Test RE 1.281265860538565\n",
      "27 Train Loss 30.405582 Test MSE 7.150231961999421 Test RE 1.2781096851196347\n",
      "28 Train Loss 29.646664 Test MSE 6.94824293583201 Test RE 1.2599275067448978\n",
      "29 Train Loss 29.172817 Test MSE 7.187367948700337 Test RE 1.2814244304356124\n",
      "30 Train Loss 28.4763 Test MSE 7.230733705568646 Test RE 1.2852844227731544\n",
      "31 Train Loss 27.92664 Test MSE 7.224420247737015 Test RE 1.2847231822817797\n",
      "32 Train Loss 27.348278 Test MSE 7.15352396794883 Test RE 1.2784038756107314\n",
      "33 Train Loss 26.624254 Test MSE 6.96832143569561 Test RE 1.2617466144821272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 25.960087 Test MSE 6.749923883466024 Test RE 1.2418167058814598\n",
      "35 Train Loss 24.083324 Test MSE 6.595931524718425 Test RE 1.2275696130496787\n",
      "36 Train Loss 23.472038 Test MSE 6.51893331059948 Test RE 1.2203835060984003\n",
      "37 Train Loss 22.594685 Test MSE 6.357374818381666 Test RE 1.2051662720581577\n",
      "38 Train Loss 21.712337 Test MSE 6.060753830191493 Test RE 1.1767152519680113\n",
      "39 Train Loss 19.35125 Test MSE 5.409960362937878 Test RE 1.1117447874153132\n",
      "40 Train Loss 18.814741 Test MSE 5.190510203282444 Test RE 1.0889629021266793\n",
      "41 Train Loss 18.041636 Test MSE 4.871252644338895 Test RE 1.054941525076786\n",
      "42 Train Loss 17.416235 Test MSE 4.428612984499188 Test RE 1.0058701604182114\n",
      "43 Train Loss 16.51396 Test MSE 4.246926291600625 Test RE 0.9850208471196922\n",
      "44 Train Loss 15.491924 Test MSE 4.3211729541405575 Test RE 0.9935938275285994\n",
      "45 Train Loss 14.424856 Test MSE 4.017963241352993 Test RE 0.9581004406495173\n",
      "46 Train Loss 13.236803 Test MSE 3.756685446482409 Test RE 0.9264254486009297\n",
      "47 Train Loss 12.647247 Test MSE 3.7909527132413596 Test RE 0.9306411331989662\n",
      "48 Train Loss 11.973224 Test MSE 3.7788791398918606 Test RE 0.9291579803542988\n",
      "49 Train Loss 11.56941 Test MSE 3.6160696367066736 Test RE 0.9089216599496236\n",
      "50 Train Loss 10.681059 Test MSE 3.4947664847417697 Test RE 0.8935464656461446\n",
      "51 Train Loss 9.9798155 Test MSE 3.3645964743474113 Test RE 0.8767475340088267\n",
      "52 Train Loss 9.681727 Test MSE 3.252084267735961 Test RE 0.8619636579439502\n",
      "53 Train Loss 9.1165085 Test MSE 3.157826518633835 Test RE 0.8493803195993301\n",
      "54 Train Loss 7.971332 Test MSE 2.370967433780109 Test RE 0.7359882055480458\n",
      "55 Train Loss 7.2778463 Test MSE 2.350964163336314 Test RE 0.7328769534852211\n",
      "56 Train Loss 6.428077 Test MSE 2.207989318310181 Test RE 0.7102423167378658\n",
      "57 Train Loss 5.7997785 Test MSE 2.019146625844009 Test RE 0.6791911042360521\n",
      "58 Train Loss 5.578581 Test MSE 2.01436778930331 Test RE 0.6783868867573023\n",
      "59 Train Loss 5.266713 Test MSE 1.9500030706901728 Test RE 0.6674607127853752\n",
      "60 Train Loss 4.974973 Test MSE 2.0202439494709976 Test RE 0.6793756354644664\n",
      "61 Train Loss 4.6393147 Test MSE 1.931431123944326 Test RE 0.6642746405264689\n",
      "62 Train Loss 4.259679 Test MSE 1.8538122827459633 Test RE 0.6507901003519819\n",
      "63 Train Loss 3.931961 Test MSE 1.8164616786850447 Test RE 0.6442006821184799\n",
      "64 Train Loss 3.6239567 Test MSE 1.6799775680041171 Test RE 0.6195263770457192\n",
      "65 Train Loss 3.2130275 Test MSE 1.557810363510427 Test RE 0.5965754185802287\n",
      "66 Train Loss 3.053856 Test MSE 1.5113172692527639 Test RE 0.5876055413818368\n",
      "67 Train Loss 2.860718 Test MSE 1.476567741981933 Test RE 0.5808108870627996\n",
      "68 Train Loss 2.666133 Test MSE 1.4422929176878458 Test RE 0.5740302717854947\n",
      "69 Train Loss 2.3809364 Test MSE 1.3652168158691322 Test RE 0.558481607156954\n",
      "70 Train Loss 2.244093 Test MSE 1.255790107186398 Test RE 0.5356320913365109\n",
      "71 Train Loss 2.1480045 Test MSE 1.195563501997487 Test RE 0.5226300590267688\n",
      "72 Train Loss 2.0935683 Test MSE 1.1500991187493557 Test RE 0.5125965697728346\n",
      "73 Train Loss 1.9494674 Test MSE 1.1321612147577162 Test RE 0.5085834185942738\n",
      "74 Train Loss 1.8296003 Test MSE 1.1419520863032344 Test RE 0.5107777861439136\n",
      "75 Train Loss 1.7530892 Test MSE 1.0558394742491155 Test RE 0.4911419245196215\n",
      "76 Train Loss 1.7001799 Test MSE 0.9922741283513596 Test RE 0.47612818883189056\n",
      "77 Train Loss 1.5630263 Test MSE 0.785096799312875 Test RE 0.42351584545085635\n",
      "78 Train Loss 1.3586124 Test MSE 0.6112436551798979 Test RE 0.37369324057419323\n",
      "79 Train Loss 1.297534 Test MSE 0.5317575972570585 Test RE 0.34854985948211004\n",
      "80 Train Loss 1.1477897 Test MSE 0.49202434377463167 Test RE 0.33527514242573253\n",
      "81 Train Loss 0.8825749 Test MSE 0.43587538005823667 Test RE 0.31556529148053164\n",
      "82 Train Loss 0.7304177 Test MSE 0.2812767599722676 Test RE 0.2534982617326759\n",
      "83 Train Loss 0.6729185 Test MSE 0.22718394177635665 Test RE 0.22782263759205057\n",
      "84 Train Loss 0.63088155 Test MSE 0.22268225528722577 Test RE 0.22555417269087055\n",
      "85 Train Loss 0.59655505 Test MSE 0.23083977997846578 Test RE 0.22964837999474877\n",
      "86 Train Loss 0.5611448 Test MSE 0.21541583056121766 Test RE 0.22184358158087997\n",
      "87 Train Loss 0.5211051 Test MSE 0.18466157918938025 Test RE 0.20539805790176194\n",
      "88 Train Loss 0.46717876 Test MSE 0.18779216677331387 Test RE 0.2071318083368309\n",
      "89 Train Loss 0.4405657 Test MSE 0.1694839050931561 Test RE 0.19677607393856344\n",
      "90 Train Loss 0.42666185 Test MSE 0.14590851061848825 Test RE 0.18257796933176604\n",
      "91 Train Loss 0.39907146 Test MSE 0.10773311905576853 Test RE 0.15688545336535237\n",
      "92 Train Loss 0.38231042 Test MSE 0.10368046940864938 Test RE 0.15390634963666658\n",
      "93 Train Loss 0.36947748 Test MSE 0.1105350359116742 Test RE 0.15891249217661432\n",
      "94 Train Loss 0.34149763 Test MSE 0.08229922389417735 Test RE 0.13712161830318337\n",
      "95 Train Loss 0.30768856 Test MSE 0.04843072240478413 Test RE 0.10518856582768683\n",
      "96 Train Loss 0.30105758 Test MSE 0.041134758104899985 Test RE 0.09694212473315039\n",
      "97 Train Loss 0.2950418 Test MSE 0.03738198576976739 Test RE 0.09241431402994565\n",
      "98 Train Loss 0.2734149 Test MSE 0.03808133655370506 Test RE 0.09327476242800337\n",
      "99 Train Loss 0.26337457 Test MSE 0.04469852730557955 Test RE 0.1010542696299362\n",
      "Training time: 81.45\n",
      "KG_stan_tune2\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 52.156662 Test MSE 9.255324846636107 Test RE 1.454132206671941\n",
      "1 Train Loss 44.32074 Test MSE 9.578075208339179 Test RE 1.4792690870848664\n",
      "2 Train Loss 43.235916 Test MSE 9.400798748688446 Test RE 1.4655155738964365\n",
      "3 Train Loss 42.974693 Test MSE 9.315227044247761 Test RE 1.4588303252885972\n",
      "4 Train Loss 42.689354 Test MSE 9.430849472291433 Test RE 1.4678560486901984\n",
      "5 Train Loss 42.526062 Test MSE 9.4381302715056 Test RE 1.468422546083577\n",
      "6 Train Loss 42.305763 Test MSE 9.334538987241137 Test RE 1.4603417356581962\n",
      "7 Train Loss 42.173332 Test MSE 9.520236440320387 Test RE 1.4747959201479874\n",
      "8 Train Loss 41.481598 Test MSE 9.557696567944731 Test RE 1.4776945773925605\n",
      "9 Train Loss 41.12758 Test MSE 9.539769115599464 Test RE 1.476308064801305\n",
      "10 Train Loss 40.79957 Test MSE 9.565131762060133 Test RE 1.4782692352098084\n",
      "11 Train Loss 40.431854 Test MSE 9.586140568575557 Test RE 1.4798917762597041\n",
      "12 Train Loss 39.535603 Test MSE 8.732017443997076 Test RE 1.4124248751132926\n",
      "13 Train Loss 36.88797 Test MSE 9.14982690373343 Test RE 1.4458209032728722\n",
      "14 Train Loss 35.713516 Test MSE 9.052014888244251 Test RE 1.4380721975016417\n",
      "15 Train Loss 33.89821 Test MSE 8.720503137452477 Test RE 1.4114933344997507\n",
      "16 Train Loss 32.781586 Test MSE 8.670471970358507 Test RE 1.4074385089071693\n",
      "17 Train Loss 32.19616 Test MSE 8.780874945194922 Test RE 1.416370772586806\n",
      "18 Train Loss 31.598131 Test MSE 8.81686018369541 Test RE 1.4192700467579076\n",
      "19 Train Loss 30.849281 Test MSE 8.784979346451305 Test RE 1.416701757531167\n",
      "20 Train Loss 29.793789 Test MSE 9.340986701047088 Test RE 1.4608460048123728\n",
      "21 Train Loss 28.884083 Test MSE 9.412312133524535 Test RE 1.4664127254147\n",
      "22 Train Loss 28.155302 Test MSE 9.33310386063989 Test RE 1.460229472169133\n",
      "23 Train Loss 27.030466 Test MSE 9.297505905700193 Test RE 1.4574420370016126\n",
      "24 Train Loss 26.463373 Test MSE 9.340867873303365 Test RE 1.4608367129895545\n",
      "25 Train Loss 25.815138 Test MSE 9.421486052926 Test RE 1.4671271872574398\n",
      "26 Train Loss 25.423985 Test MSE 9.338452345085472 Test RE 1.460647816170363\n",
      "27 Train Loss 25.12917 Test MSE 9.222094937583805 Test RE 1.4515194333806734\n",
      "28 Train Loss 24.855228 Test MSE 9.261498157706338 Test RE 1.4546170796618867\n",
      "29 Train Loss 24.572144 Test MSE 9.415476723224632 Test RE 1.466659221947311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 24.334581 Test MSE 9.354844636410842 Test RE 1.461929231204819\n",
      "31 Train Loss 23.97539 Test MSE 9.31802376706336 Test RE 1.4590493021234971\n",
      "32 Train Loss 23.765553 Test MSE 9.28174153612624 Test RE 1.4562059311854385\n",
      "33 Train Loss 23.4883 Test MSE 9.225556150152874 Test RE 1.4517917980672903\n",
      "34 Train Loss 23.271658 Test MSE 9.229308354926427 Test RE 1.4520870033777975\n",
      "35 Train Loss 23.093678 Test MSE 9.084822954834362 Test RE 1.440675910389702\n",
      "36 Train Loss 22.70934 Test MSE 8.955216477888573 Test RE 1.430362463683245\n",
      "37 Train Loss 22.169884 Test MSE 8.757047286037912 Test RE 1.4144477451889539\n",
      "38 Train Loss 21.173908 Test MSE 8.178301412396175 Test RE 1.3669090425757726\n",
      "39 Train Loss 19.63174 Test MSE 7.237359413012294 Test RE 1.2858731575384144\n",
      "40 Train Loss 17.962246 Test MSE 6.85090214767134 Test RE 1.251070957703351\n",
      "41 Train Loss 16.451885 Test MSE 6.729508224744853 Test RE 1.2399372991139552\n",
      "42 Train Loss 15.819124 Test MSE 6.375376337903949 Test RE 1.2068713381233234\n",
      "43 Train Loss 14.969439 Test MSE 5.951988808568652 Test RE 1.1661089087418808\n",
      "44 Train Loss 14.44412 Test MSE 5.628970055635298 Test RE 1.134024740480835\n",
      "45 Train Loss 13.908832 Test MSE 5.564155127757728 Test RE 1.1274769579876383\n",
      "46 Train Loss 13.42243 Test MSE 5.47393467949763 Test RE 1.1182988173483572\n",
      "47 Train Loss 12.723148 Test MSE 5.498843631961482 Test RE 1.1208403196276557\n",
      "48 Train Loss 12.479132 Test MSE 5.511683508836246 Test RE 1.122148145544944\n",
      "49 Train Loss 12.1768055 Test MSE 5.490096679150634 Test RE 1.1199485103765006\n",
      "50 Train Loss 12.034605 Test MSE 5.442853043844681 Test RE 1.115119382463898\n",
      "51 Train Loss 11.793009 Test MSE 5.432834569399887 Test RE 1.114092628611771\n",
      "52 Train Loss 11.590677 Test MSE 5.489071269724725 Test RE 1.1198439166457892\n",
      "53 Train Loss 11.332105 Test MSE 5.506365982317528 Test RE 1.1216067054912289\n",
      "54 Train Loss 11.086189 Test MSE 5.44141144524093 Test RE 1.1149716969586598\n",
      "55 Train Loss 10.946641 Test MSE 5.4089266104308935 Test RE 1.1116385644681235\n",
      "56 Train Loss 10.158779 Test MSE 5.220946569653801 Test RE 1.09215099217329\n",
      "57 Train Loss 9.607559 Test MSE 5.0685898081369025 Test RE 1.0760975268268613\n",
      "58 Train Loss 8.747152 Test MSE 5.091088335419647 Test RE 1.0784831807608566\n",
      "59 Train Loss 7.414772 Test MSE 4.5794781184297735 Test RE 1.0228596678803414\n",
      "60 Train Loss 6.914334 Test MSE 4.583690618758887 Test RE 1.0233300060012087\n",
      "61 Train Loss 6.561203 Test MSE 4.605960195035615 Test RE 1.0258128865735587\n",
      "62 Train Loss 6.20504 Test MSE 4.562387326525277 Test RE 1.0209492075419309\n",
      "63 Train Loss 6.017043 Test MSE 4.604591957644042 Test RE 1.02566051228692\n",
      "64 Train Loss 5.842169 Test MSE 4.616425013500935 Test RE 1.0269775574137447\n",
      "65 Train Loss 5.748227 Test MSE 4.6061614647839075 Test RE 1.0258352991474051\n",
      "66 Train Loss 5.645509 Test MSE 4.630589333141438 Test RE 1.0285518597605519\n",
      "67 Train Loss 5.5583305 Test MSE 4.583655595251771 Test RE 1.0233260964142414\n",
      "68 Train Loss 5.4302087 Test MSE 4.56497656038326 Test RE 1.0212388696330716\n",
      "69 Train Loss 5.3223343 Test MSE 4.548109108083207 Test RE 1.0193503999697604\n",
      "70 Train Loss 5.187396 Test MSE 4.54691984248284 Test RE 1.0192171184680057\n",
      "71 Train Loss 4.9768124 Test MSE 4.613811844205623 Test RE 1.0266868512831244\n",
      "72 Train Loss 4.672517 Test MSE 4.6461074360257575 Test RE 1.0302738677449623\n",
      "73 Train Loss 4.2508345 Test MSE 4.525315903993215 Test RE 1.0167929146054828\n",
      "74 Train Loss 3.6115935 Test MSE 4.0059604335227945 Test RE 0.9566683099899294\n",
      "75 Train Loss 3.041483 Test MSE 3.6014118375111956 Test RE 0.9070776247140915\n",
      "76 Train Loss 2.7444782 Test MSE 3.2704885914992174 Test RE 0.864399246303703\n",
      "77 Train Loss 2.3625107 Test MSE 2.909633219678551 Test RE 0.8153182873232042\n",
      "78 Train Loss 2.1088333 Test MSE 2.8226554243201534 Test RE 0.8030396567801239\n",
      "79 Train Loss 1.9493768 Test MSE 2.7706594205621946 Test RE 0.79560889930097\n",
      "80 Train Loss 1.7003548 Test MSE 2.805101872293469 Test RE 0.8005387879049064\n",
      "81 Train Loss 1.5771598 Test MSE 2.7736944468029607 Test RE 0.7960445416171751\n",
      "82 Train Loss 1.4556485 Test MSE 2.592337993358016 Test RE 0.7695801773811699\n",
      "83 Train Loss 1.3753316 Test MSE 2.6236144962894414 Test RE 0.7742087426155072\n",
      "84 Train Loss 1.3269132 Test MSE 2.643805294331752 Test RE 0.7771821086722667\n",
      "85 Train Loss 1.2379894 Test MSE 2.5218702424924366 Test RE 0.7590483295290743\n",
      "86 Train Loss 1.2101314 Test MSE 2.5046418129811507 Test RE 0.7564511257488983\n",
      "87 Train Loss 1.1761907 Test MSE 2.4833183086916466 Test RE 0.7532241838492073\n",
      "88 Train Loss 1.1308084 Test MSE 2.5027581968777204 Test RE 0.7561666276806517\n",
      "89 Train Loss 1.0950733 Test MSE 2.5405529089961223 Test RE 0.7618547545356592\n",
      "90 Train Loss 1.0627142 Test MSE 2.522866196933755 Test RE 0.7591981990421837\n",
      "91 Train Loss 1.0417796 Test MSE 2.518583779715281 Test RE 0.7585535781943353\n",
      "92 Train Loss 1.0153456 Test MSE 2.504838296676531 Test RE 0.7564807961386872\n",
      "93 Train Loss 0.98433846 Test MSE 2.498658023437064 Test RE 0.7555469742935824\n",
      "94 Train Loss 0.95978856 Test MSE 2.542099185283703 Test RE 0.762086566032735\n",
      "95 Train Loss 0.9431317 Test MSE 2.5528635356765426 Test RE 0.7636983640810623\n",
      "96 Train Loss 0.92158586 Test MSE 2.555228483740256 Test RE 0.7640520235786803\n",
      "97 Train Loss 0.9049761 Test MSE 2.5955505852664853 Test RE 0.7700568863517029\n",
      "98 Train Loss 0.8897626 Test MSE 2.6404657345924107 Test RE 0.7766910993263023\n",
      "99 Train Loss 0.8763924 Test MSE 2.645771822353667 Test RE 0.7774710986174641\n",
      "Training time: 78.82\n",
      "KG_stan_tune2\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.16234 Test MSE 8.477008027520725 Test RE 1.3916478644481907\n",
      "1 Train Loss 55.032906 Test MSE 9.470898462895471 Test RE 1.4709694413493277\n",
      "2 Train Loss 52.61853 Test MSE 9.495098765802853 Test RE 1.4728475733451853\n",
      "3 Train Loss 48.838272 Test MSE 9.112771955498589 Test RE 1.4428902920602427\n",
      "4 Train Loss 47.284683 Test MSE 8.81918809291471 Test RE 1.4194573988142398\n",
      "5 Train Loss 46.674618 Test MSE 8.66799808454267 Test RE 1.4072377072337616\n",
      "6 Train Loss 45.839256 Test MSE 8.616601786781397 Test RE 1.403059444804241\n",
      "7 Train Loss 45.337303 Test MSE 8.64035952509878 Test RE 1.4049923746727637\n",
      "8 Train Loss 44.987896 Test MSE 8.672262748917696 Test RE 1.4075838458961636\n",
      "9 Train Loss 44.849342 Test MSE 8.625448214231662 Test RE 1.4037795012573187\n",
      "10 Train Loss 44.74212 Test MSE 8.687888084672206 Test RE 1.4088513393279536\n",
      "11 Train Loss 44.37069 Test MSE 8.45690880413381 Test RE 1.3899970673197601\n",
      "12 Train Loss 44.190205 Test MSE 8.54887221056271 Test RE 1.397534291080129\n",
      "13 Train Loss 44.13462 Test MSE 8.471339481168615 Test RE 1.391182491546907\n",
      "14 Train Loss 44.06127 Test MSE 8.48161372973348 Test RE 1.3920258660535123\n",
      "15 Train Loss 43.973213 Test MSE 8.459900597704383 Test RE 1.3902429146296786\n",
      "16 Train Loss 43.77877 Test MSE 8.519250327074372 Test RE 1.3951109585104262\n",
      "17 Train Loss 43.578423 Test MSE 8.477036010025524 Test RE 1.3916501613529941\n",
      "18 Train Loss 43.31422 Test MSE 8.323060103250432 Test RE 1.3789533545916595\n",
      "19 Train Loss 43.153206 Test MSE 8.28980519777622 Test RE 1.3761957834479688\n",
      "20 Train Loss 42.228928 Test MSE 8.170610579012935 Test RE 1.3662661742193476\n",
      "21 Train Loss 40.436066 Test MSE 7.955363656154907 Test RE 1.348149573789839\n",
      "22 Train Loss 39.37874 Test MSE 7.736766942467064 Test RE 1.329498395677469\n",
      "23 Train Loss 38.84329 Test MSE 7.7756841939043015 Test RE 1.3328380025887778\n",
      "24 Train Loss 38.642357 Test MSE 7.865038629414723 Test RE 1.34047429481979\n",
      "25 Train Loss 38.116936 Test MSE 7.7763338038312915 Test RE 1.3328936765779182\n",
      "26 Train Loss 37.782497 Test MSE 7.842986235167781 Test RE 1.33859373077897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Train Loss 37.487583 Test MSE 7.9355491931385895 Test RE 1.3464696057057262\n",
      "28 Train Loss 37.195942 Test MSE 7.946958393164552 Test RE 1.3474371898633286\n",
      "29 Train Loss 37.014824 Test MSE 8.008567644281104 Test RE 1.352650148010537\n",
      "30 Train Loss 36.750576 Test MSE 8.03873692692305 Test RE 1.355195554754125\n",
      "31 Train Loss 36.66885 Test MSE 8.138781540437455 Test RE 1.3636023969873292\n",
      "32 Train Loss 36.549347 Test MSE 8.122270190041345 Test RE 1.3622185075434445\n",
      "33 Train Loss 36.35221 Test MSE 8.11421084698226 Test RE 1.3615425074381018\n",
      "34 Train Loss 36.08596 Test MSE 8.22428012854331 Test RE 1.3707460640229177\n",
      "35 Train Loss 35.913586 Test MSE 8.216076405285401 Test RE 1.3700622335314825\n",
      "36 Train Loss 35.424362 Test MSE 8.32019705602251 Test RE 1.378716161293321\n",
      "37 Train Loss 34.86779 Test MSE 8.143644912262607 Test RE 1.3640097500437123\n",
      "38 Train Loss 33.68371 Test MSE 7.432308701321906 Test RE 1.3030765525031887\n",
      "39 Train Loss 31.902142 Test MSE 7.453881619907983 Test RE 1.3049663283647135\n",
      "40 Train Loss 31.103188 Test MSE 7.531453911541198 Test RE 1.3117391229344346\n",
      "41 Train Loss 30.41735 Test MSE 7.268326145952716 Test RE 1.2886211755130532\n",
      "42 Train Loss 29.569195 Test MSE 7.277675907667588 Test RE 1.2894497313961237\n",
      "43 Train Loss 28.538069 Test MSE 7.142585855335059 Test RE 1.2774261284877948\n",
      "44 Train Loss 26.98009 Test MSE 6.794759094542704 Test RE 1.2459341570158315\n",
      "45 Train Loss 25.490772 Test MSE 6.918510968718132 Test RE 1.2572289624463433\n",
      "46 Train Loss 24.600637 Test MSE 6.854769075929972 Test RE 1.2514239856013663\n",
      "47 Train Loss 23.41606 Test MSE 6.562075260970373 Test RE 1.2244150631752366\n",
      "48 Train Loss 22.296083 Test MSE 6.41250074871135 Test RE 1.210380099737\n",
      "49 Train Loss 21.675516 Test MSE 6.141062353114248 Test RE 1.1844856776877324\n",
      "50 Train Loss 20.803139 Test MSE 5.946967612591227 Test RE 1.165616930600614\n",
      "51 Train Loss 19.889797 Test MSE 6.114702243141218 Test RE 1.1819407800062744\n",
      "52 Train Loss 18.781443 Test MSE 5.997515234874318 Test RE 1.17056016370526\n",
      "53 Train Loss 17.911795 Test MSE 5.768091921241753 Test RE 1.147953103899718\n",
      "54 Train Loss 16.874004 Test MSE 5.5182511471163105 Test RE 1.122816513835469\n",
      "55 Train Loss 15.642633 Test MSE 5.397631193120214 Test RE 1.1104772449854439\n",
      "56 Train Loss 14.378159 Test MSE 5.157626509276082 Test RE 1.08550794128003\n",
      "57 Train Loss 13.312975 Test MSE 4.789269851311974 Test RE 1.0460265655858365\n",
      "58 Train Loss 12.046671 Test MSE 4.68205593180737 Test RE 1.0342519752882704\n",
      "59 Train Loss 10.984806 Test MSE 4.569233473203941 Test RE 1.0217149193744681\n",
      "60 Train Loss 10.114347 Test MSE 4.491666915378081 Test RE 1.0130055666011053\n",
      "61 Train Loss 9.575576 Test MSE 4.602435535984052 Test RE 1.02542031559003\n",
      "62 Train Loss 9.090223 Test MSE 4.432031164238858 Test RE 1.006258270852273\n",
      "63 Train Loss 8.852879 Test MSE 4.259629082356789 Test RE 0.9864928730526786\n",
      "64 Train Loss 8.422603 Test MSE 4.094127979192343 Test RE 0.9671387122331107\n",
      "65 Train Loss 7.9270964 Test MSE 3.833331848686395 Test RE 0.9358285038886299\n",
      "66 Train Loss 7.6657467 Test MSE 3.567522698903974 Test RE 0.9027997555445207\n",
      "67 Train Loss 7.2219906 Test MSE 3.1417156360926124 Test RE 0.8472108265869577\n",
      "68 Train Loss 6.322806 Test MSE 2.504395504696175 Test RE 0.7564139298593651\n",
      "69 Train Loss 4.762146 Test MSE 2.5989576675562205 Test RE 0.7705621330550779\n",
      "70 Train Loss 4.061412 Test MSE 2.581435938270633 Test RE 0.7679602410282148\n",
      "71 Train Loss 3.528596 Test MSE 2.30164621291652 Test RE 0.7251491540920652\n",
      "72 Train Loss 3.2519052 Test MSE 2.360694695250489 Test RE 0.7343920592693238\n",
      "73 Train Loss 2.7692595 Test MSE 2.2363509767725147 Test RE 0.714789298829684\n",
      "74 Train Loss 2.607996 Test MSE 2.1873604162683105 Test RE 0.7069166888513899\n",
      "75 Train Loss 2.3701909 Test MSE 2.0806386861804795 Test RE 0.6894557451985031\n",
      "76 Train Loss 2.1663332 Test MSE 1.995777316075496 Test RE 0.675249235794335\n",
      "77 Train Loss 2.006709 Test MSE 2.0191372473721465 Test RE 0.6791895268909559\n",
      "78 Train Loss 1.9026539 Test MSE 2.02146524016437 Test RE 0.6795809546742672\n",
      "79 Train Loss 1.7924811 Test MSE 1.9829526280448107 Test RE 0.6730761933724492\n",
      "80 Train Loss 1.713088 Test MSE 1.9556440352824913 Test RE 0.6684254300468868\n",
      "81 Train Loss 1.6686336 Test MSE 1.9598092219992431 Test RE 0.6691368672578069\n",
      "82 Train Loss 1.6338243 Test MSE 1.947429799682175 Test RE 0.6670201687847823\n",
      "83 Train Loss 1.5617337 Test MSE 1.9678608426057553 Test RE 0.6705099891582297\n",
      "84 Train Loss 1.5091928 Test MSE 1.9856219835895776 Test RE 0.6735290724274255\n",
      "85 Train Loss 1.4484035 Test MSE 1.9633063842767104 Test RE 0.6697336185082567\n",
      "86 Train Loss 1.4296598 Test MSE 1.9661302239441059 Test RE 0.6702150871223379\n",
      "87 Train Loss 1.3888066 Test MSE 1.9669905997689294 Test RE 0.6703617136736466\n",
      "88 Train Loss 1.3534098 Test MSE 1.9447156460761683 Test RE 0.6665551901682509\n",
      "89 Train Loss 1.307044 Test MSE 1.957068629003015 Test RE 0.6686688438026153\n",
      "90 Train Loss 1.2775675 Test MSE 1.9919303549826457 Test RE 0.6745981334634534\n",
      "91 Train Loss 1.2581239 Test MSE 1.986282241667178 Test RE 0.6736410439034368\n",
      "92 Train Loss 1.2377163 Test MSE 1.970624970858566 Test RE 0.6709807351560816\n",
      "93 Train Loss 1.22458 Test MSE 1.994692473622793 Test RE 0.6750656886108227\n",
      "94 Train Loss 1.2100013 Test MSE 2.0198707049859608 Test RE 0.6793128744987907\n",
      "95 Train Loss 1.1908447 Test MSE 2.011045872940785 Test RE 0.6778272882658\n",
      "96 Train Loss 1.177838 Test MSE 1.9988600738554192 Test RE 0.6757705431055865\n",
      "97 Train Loss 1.1572205 Test MSE 2.016306081134925 Test RE 0.6787131915183711\n",
      "98 Train Loss 1.1354601 Test MSE 2.040850677365234 Test RE 0.6828317007844276\n",
      "99 Train Loss 1.1196873 Test MSE 2.0280396133646703 Test RE 0.6806851517615308\n",
      "Training time: 79.67\n",
      "KG_stan_tune2\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.554455 Test MSE 8.387479275844427 Test RE 1.3842795093039366\n",
      "1 Train Loss 53.52873 Test MSE 9.000864740424584 Test RE 1.4340033899565647\n",
      "2 Train Loss 43.975273 Test MSE 8.002708038256833 Test RE 1.3521552126090581\n",
      "3 Train Loss 43.80433 Test MSE 8.23063519673344 Test RE 1.3712755634073408\n",
      "4 Train Loss 43.367214 Test MSE 8.211993639593093 Test RE 1.3697217828172952\n",
      "5 Train Loss 43.04867 Test MSE 8.146700116619234 Test RE 1.3642655898912774\n",
      "6 Train Loss 42.295723 Test MSE 8.134105633030348 Test RE 1.3632106310590428\n",
      "7 Train Loss 42.20375 Test MSE 8.23169675084913 Test RE 1.3713639913505846\n",
      "8 Train Loss 41.502697 Test MSE 8.308817316156112 Test RE 1.3777729865381225\n",
      "9 Train Loss 41.42665 Test MSE 8.296542983909097 Test RE 1.376754941913228\n",
      "10 Train Loss 41.224987 Test MSE 8.33013398621472 Test RE 1.3795392258199375\n",
      "11 Train Loss 41.126366 Test MSE 8.328538425946896 Test RE 1.3794071004908441\n",
      "12 Train Loss 40.90967 Test MSE 8.352266574130814 Test RE 1.3813706801088208\n",
      "13 Train Loss 39.19371 Test MSE 7.676109407138455 Test RE 1.324276396297111\n",
      "14 Train Loss 33.804688 Test MSE 7.8528190644598235 Test RE 1.3394325720348363\n",
      "15 Train Loss 30.777657 Test MSE 7.143838600747729 Test RE 1.2775381481114956\n",
      "16 Train Loss 30.418634 Test MSE 7.016222316878976 Test RE 1.2660758683249085\n",
      "17 Train Loss 29.807446 Test MSE 6.960536349995189 Test RE 1.2610415988849726\n",
      "18 Train Loss 29.276205 Test MSE 7.1207604029099905 Test RE 1.275472932911629\n",
      "19 Train Loss 28.07713 Test MSE 6.83616590393665 Test RE 1.2497247108284588\n",
      "20 Train Loss 27.743317 Test MSE 6.796418286676405 Test RE 1.246086268219519\n",
      "21 Train Loss 27.094511 Test MSE 6.822865839903624 Test RE 1.2485084215215516\n",
      "22 Train Loss 26.61451 Test MSE 6.645143415048991 Test RE 1.2321405185012102\n",
      "23 Train Loss 26.346241 Test MSE 6.584756947837165 Test RE 1.226529321330422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Train Loss 25.7191 Test MSE 6.38477089357061 Test RE 1.2077602147640316\n",
      "25 Train Loss 24.916016 Test MSE 6.326093878245544 Test RE 1.202197655065355\n",
      "26 Train Loss 24.352512 Test MSE 6.154027894845177 Test RE 1.1857354126787922\n",
      "27 Train Loss 24.076889 Test MSE 6.163231073894395 Test RE 1.186621698757857\n",
      "28 Train Loss 23.745811 Test MSE 6.196041787922066 Test RE 1.189776068995694\n",
      "29 Train Loss 23.548073 Test MSE 6.1904911470053605 Test RE 1.1892430271239751\n",
      "30 Train Loss 22.950314 Test MSE 6.319612788712043 Test RE 1.2015816709031517\n",
      "31 Train Loss 22.618792 Test MSE 6.097559021966702 Test RE 1.1802827684461772\n",
      "32 Train Loss 22.448877 Test MSE 6.1037594922372564 Test RE 1.1808827174323149\n",
      "33 Train Loss 21.956854 Test MSE 5.873286025050943 Test RE 1.1583735592902697\n",
      "34 Train Loss 21.681793 Test MSE 5.808630752724162 Test RE 1.1519800159030271\n",
      "35 Train Loss 21.51667 Test MSE 5.806272412336628 Test RE 1.1517461366185384\n",
      "36 Train Loss 21.398064 Test MSE 5.938247936440214 Test RE 1.1647620806007417\n",
      "37 Train Loss 21.097841 Test MSE 5.947174126416361 Test RE 1.1656371689756089\n",
      "38 Train Loss 20.873732 Test MSE 5.786960523707545 Test RE 1.1498291650120929\n",
      "39 Train Loss 20.626575 Test MSE 5.956767012793088 Test RE 1.1665768858225127\n",
      "40 Train Loss 20.456987 Test MSE 6.009685897358989 Test RE 1.1717472613524964\n",
      "41 Train Loss 20.268656 Test MSE 6.043074041262171 Test RE 1.1749977039616222\n",
      "42 Train Loss 20.051071 Test MSE 6.207093268632681 Test RE 1.1908366597557383\n",
      "43 Train Loss 19.93214 Test MSE 6.428340355114696 Test RE 1.2118740660153466\n",
      "44 Train Loss 19.696474 Test MSE 6.449471617066493 Test RE 1.2138642700508318\n",
      "45 Train Loss 19.515745 Test MSE 6.252232422019815 Test RE 1.1951588105527904\n",
      "46 Train Loss 19.368324 Test MSE 6.292101389553304 Test RE 1.1989633737171124\n",
      "47 Train Loss 19.06596 Test MSE 6.367162338556854 Test RE 1.2060936243886897\n",
      "48 Train Loss 18.84808 Test MSE 6.208318052664899 Test RE 1.1909541419427403\n",
      "49 Train Loss 18.544075 Test MSE 6.125954198219907 Test RE 1.1830277529739592\n",
      "50 Train Loss 18.346638 Test MSE 6.223035686023328 Test RE 1.192364962911641\n",
      "51 Train Loss 18.177118 Test MSE 6.31508465965969 Test RE 1.2011511151052319\n",
      "52 Train Loss 17.868021 Test MSE 6.303413381999513 Test RE 1.200040642938703\n",
      "53 Train Loss 17.587885 Test MSE 5.97596670584666 Test RE 1.1684554131358333\n",
      "54 Train Loss 17.22512 Test MSE 5.842683265918215 Test RE 1.1553517649421576\n",
      "55 Train Loss 17.014008 Test MSE 5.899306028918113 Test RE 1.160936653897702\n",
      "56 Train Loss 16.598045 Test MSE 5.788991352835805 Test RE 1.1500309031889255\n",
      "57 Train Loss 16.291794 Test MSE 5.750135858052904 Test RE 1.1461649228501731\n",
      "58 Train Loss 15.84233 Test MSE 5.516712004828979 Test RE 1.1226599157708794\n",
      "59 Train Loss 15.57106 Test MSE 5.527215083523203 Test RE 1.1237281044369296\n",
      "60 Train Loss 15.040047 Test MSE 5.475009693039259 Test RE 1.1184086220340865\n",
      "61 Train Loss 14.682438 Test MSE 5.175256040825359 Test RE 1.0873615721197638\n",
      "62 Train Loss 14.024868 Test MSE 4.822011375524534 Test RE 1.04959602084874\n",
      "63 Train Loss 13.425432 Test MSE 4.6974257374139885 Test RE 1.0359481561684811\n",
      "64 Train Loss 12.855898 Test MSE 4.4135828521198315 Test RE 1.0041618139258794\n",
      "65 Train Loss 11.940495 Test MSE 3.879898319296075 Test RE 0.9414954648180429\n",
      "66 Train Loss 11.083603 Test MSE 3.4158873462140225 Test RE 0.8834049532728088\n",
      "67 Train Loss 10.789604 Test MSE 3.37951417270469 Test RE 0.8786890134939167\n",
      "68 Train Loss 10.110849 Test MSE 3.113145231407589 Test RE 0.8433498091745142\n",
      "69 Train Loss 9.591231 Test MSE 2.9330439791925476 Test RE 0.8185917205877093\n",
      "70 Train Loss 8.912842 Test MSE 2.6541720268099707 Test RE 0.7787043381026396\n",
      "71 Train Loss 8.456666 Test MSE 2.5096863223980934 Test RE 0.7572125131378235\n",
      "72 Train Loss 8.028137 Test MSE 2.601368956247905 Test RE 0.7709195103626864\n",
      "73 Train Loss 7.3334064 Test MSE 2.5107393161064513 Test RE 0.757371349002548\n",
      "74 Train Loss 7.0499353 Test MSE 2.4428756645782306 Test RE 0.7470656049609392\n",
      "75 Train Loss 6.7742605 Test MSE 2.4146185775283286 Test RE 0.7427323310530398\n",
      "76 Train Loss 6.3918724 Test MSE 2.2673484040778034 Test RE 0.719725997137039\n",
      "77 Train Loss 6.110127 Test MSE 2.2630891313083943 Test RE 0.7190496673879296\n",
      "78 Train Loss 6.0066977 Test MSE 2.3164219716685226 Test RE 0.727473031636527\n",
      "79 Train Loss 5.8626266 Test MSE 2.354599361119808 Test RE 0.733443343149266\n",
      "80 Train Loss 5.6275516 Test MSE 2.3053778423759304 Test RE 0.7257367535291607\n",
      "81 Train Loss 5.5242724 Test MSE 2.274314136132215 Test RE 0.7208307179192017\n",
      "82 Train Loss 5.4110503 Test MSE 2.3052259370964143 Test RE 0.7257128431188017\n",
      "83 Train Loss 5.2622437 Test MSE 2.3177047970004168 Test RE 0.7276744396003884\n",
      "84 Train Loss 5.211029 Test MSE 2.311525898988932 Test RE 0.7267038183979716\n",
      "85 Train Loss 5.14664 Test MSE 2.3112922810016854 Test RE 0.7266670947399732\n",
      "86 Train Loss 5.083704 Test MSE 2.2518035901228672 Test RE 0.717254553222814\n",
      "87 Train Loss 4.9975066 Test MSE 2.2556992175916974 Test RE 0.7178747114642294\n",
      "88 Train Loss 4.9774103 Test MSE 2.267909044433175 Test RE 0.719814973868107\n",
      "89 Train Loss 4.907218 Test MSE 2.236147306420524 Test RE 0.7147567492199912\n",
      "90 Train Loss 4.8449855 Test MSE 2.254816882389766 Test RE 0.7177342964487486\n",
      "91 Train Loss 4.7940006 Test MSE 2.2317616199856154 Test RE 0.7140554900774492\n",
      "92 Train Loss 4.74164 Test MSE 2.2338111536393965 Test RE 0.7143832905249837\n",
      "93 Train Loss 4.7233615 Test MSE 2.2421407969872575 Test RE 0.7157139806962736\n",
      "94 Train Loss 4.683317 Test MSE 2.2336255030317838 Test RE 0.7143536039403634\n",
      "95 Train Loss 4.649667 Test MSE 2.221631594720048 Test RE 0.712433088535765\n",
      "96 Train Loss 4.608836 Test MSE 2.210858391134039 Test RE 0.710703613217121\n",
      "97 Train Loss 4.5901575 Test MSE 2.206082626132605 Test RE 0.7099355883629301\n",
      "98 Train Loss 4.5644827 Test MSE 2.2104511475938575 Test RE 0.7106381538493494\n",
      "99 Train Loss 4.505556 Test MSE 2.21205121874924 Test RE 0.7108953108364207\n",
      "Training time: 78.85\n",
      "KG_stan_tune2\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.33827 Test MSE 8.406746193965162 Test RE 1.3858685147873953\n",
      "1 Train Loss 54.799324 Test MSE 8.845368899558519 Test RE 1.4215627513600584\n",
      "2 Train Loss 45.846596 Test MSE 8.473037399098686 Test RE 1.3913219025192443\n",
      "3 Train Loss 43.941475 Test MSE 8.720653745919943 Test RE 1.4115055231273301\n",
      "4 Train Loss 43.855812 Test MSE 8.62566217525593 Test RE 1.4037969120764362\n",
      "5 Train Loss 43.247887 Test MSE 8.690327463445517 Test RE 1.4090491135633143\n",
      "6 Train Loss 42.709755 Test MSE 8.451702639442388 Test RE 1.3895691528247103\n",
      "7 Train Loss 42.583412 Test MSE 8.428183338299666 Test RE 1.3876343673139375\n",
      "8 Train Loss 42.248158 Test MSE 8.377708578954463 Test RE 1.3834729906632237\n",
      "9 Train Loss 42.0849 Test MSE 8.342935702210504 Test RE 1.3805988540010403\n",
      "10 Train Loss 41.859047 Test MSE 8.322967866253519 Test RE 1.3789457137199654\n",
      "11 Train Loss 41.434494 Test MSE 8.197695469963014 Test RE 1.36852882971144\n",
      "12 Train Loss 40.94024 Test MSE 8.337116540573572 Test RE 1.3801172891436397\n",
      "13 Train Loss 40.10871 Test MSE 8.588117111188167 Test RE 1.4007384151009346\n",
      "14 Train Loss 39.4065 Test MSE 8.219650803625033 Test RE 1.3703602234369912\n",
      "15 Train Loss 37.891724 Test MSE 8.17259991974078 Test RE 1.3664324900350278\n",
      "16 Train Loss 37.059456 Test MSE 8.025977911119782 Test RE 1.3541196501608774\n",
      "17 Train Loss 36.59519 Test MSE 8.117488333461454 Test RE 1.361817456334425\n",
      "18 Train Loss 36.366558 Test MSE 7.9922080698019595 Test RE 1.3512678725323581\n",
      "19 Train Loss 36.014755 Test MSE 7.975874725983956 Test RE 1.349886401332439\n",
      "20 Train Loss 35.777752 Test MSE 8.17923289820079 Test RE 1.3669868839301154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Train Loss 35.599148 Test MSE 8.379878261163595 Test RE 1.3836521269022435\n",
      "22 Train Loss 35.448036 Test MSE 8.320162618866167 Test RE 1.3787133080488119\n",
      "23 Train Loss 35.283024 Test MSE 8.38391411090118 Test RE 1.3839852785128786\n",
      "24 Train Loss 35.16416 Test MSE 8.311249400634 Test RE 1.3779746166254352\n",
      "25 Train Loss 34.92061 Test MSE 8.289914811530869 Test RE 1.376204881942125\n",
      "26 Train Loss 34.702297 Test MSE 8.326986059717909 Test RE 1.3792785398310643\n",
      "27 Train Loss 34.20278 Test MSE 8.189271947759673 Test RE 1.3678255347490378\n",
      "28 Train Loss 33.777122 Test MSE 8.115516744343038 Test RE 1.3616520660425864\n",
      "29 Train Loss 32.79066 Test MSE 7.726839232499952 Test RE 1.328645125090202\n",
      "30 Train Loss 31.0 Test MSE 6.777556044709317 Test RE 1.2443559221642633\n",
      "31 Train Loss 29.528667 Test MSE 6.732738621772256 Test RE 1.240234869831856\n",
      "32 Train Loss 28.850643 Test MSE 6.666003308647745 Test RE 1.2340729208174246\n",
      "33 Train Loss 28.3278 Test MSE 6.402403942358245 Test RE 1.2094268220388102\n",
      "34 Train Loss 27.879383 Test MSE 6.202868400866146 Test RE 1.1904313183500344\n",
      "35 Train Loss 27.601154 Test MSE 6.085322948093713 Test RE 1.1790979271320658\n",
      "36 Train Loss 27.349854 Test MSE 6.037702191763219 Test RE 1.1744753444708727\n",
      "37 Train Loss 27.043854 Test MSE 6.0506574171918635 Test RE 1.1757347175738466\n",
      "38 Train Loss 26.532003 Test MSE 5.8146778952632845 Test RE 1.1525795010089352\n",
      "39 Train Loss 26.132301 Test MSE 5.575908664923474 Test RE 1.1286671522955287\n",
      "40 Train Loss 25.71456 Test MSE 5.487736124794198 Test RE 1.1197077146559584\n",
      "41 Train Loss 24.89468 Test MSE 5.051678268325161 Test RE 1.0743008070094213\n",
      "42 Train Loss 23.458609 Test MSE 4.692482513382373 Test RE 1.0354029350157399\n",
      "43 Train Loss 20.670044 Test MSE 4.297139297594677 Test RE 0.9908268717222357\n",
      "44 Train Loss 17.741446 Test MSE 3.6126221650859303 Test RE 0.9084882848842499\n",
      "45 Train Loss 16.130938 Test MSE 3.5724343248731936 Test RE 0.9034210115160641\n",
      "46 Train Loss 15.093113 Test MSE 3.364131709462039 Test RE 0.8766869776326053\n",
      "47 Train Loss 14.037666 Test MSE 3.0397369850568823 Test RE 0.8333473603355077\n",
      "48 Train Loss 13.35207 Test MSE 2.909640396732705 Test RE 0.8153192928760439\n",
      "49 Train Loss 12.761887 Test MSE 2.8564042930764257 Test RE 0.8078261338420522\n",
      "50 Train Loss 12.199065 Test MSE 2.5846534031758015 Test RE 0.7684386793361153\n",
      "51 Train Loss 11.801085 Test MSE 2.4685089556407256 Test RE 0.7509748863967788\n",
      "52 Train Loss 11.47559 Test MSE 2.435455134562559 Test RE 0.7459300909665398\n",
      "53 Train Loss 10.954481 Test MSE 2.5790450599995296 Test RE 0.7676045233511924\n",
      "54 Train Loss 10.665672 Test MSE 2.6727864573556452 Test RE 0.7814301998432766\n",
      "55 Train Loss 10.25025 Test MSE 2.535138486442698 Test RE 0.7610424896746854\n",
      "56 Train Loss 9.546964 Test MSE 2.260972160653481 Test RE 0.7187132769267902\n",
      "57 Train Loss 8.697858 Test MSE 2.254340719585998 Test RE 0.7176585083831395\n",
      "58 Train Loss 8.100615 Test MSE 2.0431091486967263 Test RE 0.6832094181313146\n",
      "59 Train Loss 7.221963 Test MSE 1.8148274938897386 Test RE 0.6439108384475261\n",
      "60 Train Loss 6.7806168 Test MSE 1.6273795113740415 Test RE 0.6097509452700849\n",
      "61 Train Loss 6.093685 Test MSE 1.7562631380644464 Test RE 0.6334361624424403\n",
      "62 Train Loss 5.4190707 Test MSE 1.7514989775284842 Test RE 0.6325764276881067\n",
      "63 Train Loss 4.889988 Test MSE 1.6979284208175003 Test RE 0.6228274559278559\n",
      "64 Train Loss 4.555837 Test MSE 1.7082773231424735 Test RE 0.6247226444307615\n",
      "65 Train Loss 4.1248345 Test MSE 1.840443203370217 Test RE 0.648439213041559\n",
      "66 Train Loss 3.8118 Test MSE 1.855224804141077 Test RE 0.6510379895012779\n",
      "67 Train Loss 3.4688823 Test MSE 1.9122971181453574 Test RE 0.6609760836907884\n",
      "68 Train Loss 3.3073602 Test MSE 1.9105707005406396 Test RE 0.660677652447287\n",
      "69 Train Loss 3.1855848 Test MSE 1.8179951469435756 Test RE 0.6444725438670746\n",
      "70 Train Loss 3.0500348 Test MSE 1.8060449287106985 Test RE 0.6423508975230321\n",
      "71 Train Loss 2.953063 Test MSE 1.804720842278428 Test RE 0.6421153873092021\n",
      "72 Train Loss 2.7834108 Test MSE 1.8883228537033747 Test RE 0.6568197224056594\n",
      "73 Train Loss 2.7125854 Test MSE 1.961387686179524 Test RE 0.6694062802134824\n",
      "74 Train Loss 2.584282 Test MSE 2.0116993482111454 Test RE 0.677937406935748\n",
      "75 Train Loss 2.5195951 Test MSE 2.041060779292414 Test RE 0.6828668480310413\n",
      "76 Train Loss 2.3946018 Test MSE 2.1157283464843184 Test RE 0.6952452216133458\n",
      "77 Train Loss 2.3124754 Test MSE 2.163411974804402 Test RE 0.7030361790866946\n",
      "78 Train Loss 2.230412 Test MSE 2.1232918251402335 Test RE 0.6964868226866406\n",
      "79 Train Loss 2.170044 Test MSE 2.1194027847429067 Test RE 0.6958486845845916\n",
      "80 Train Loss 2.0878627 Test MSE 2.172783186510053 Test RE 0.7045571981420111\n",
      "81 Train Loss 1.9956557 Test MSE 2.1424933002863074 Test RE 0.6996289897293\n",
      "82 Train Loss 1.940964 Test MSE 2.1399590578732983 Test RE 0.6992150901677475\n",
      "83 Train Loss 1.8611324 Test MSE 2.2270380227056954 Test RE 0.713299428777975\n",
      "84 Train Loss 1.7837642 Test MSE 2.3038587795475447 Test RE 0.7254976123848428\n",
      "85 Train Loss 1.7448112 Test MSE 2.3412792075802797 Test RE 0.7313658275127548\n",
      "86 Train Loss 1.6837243 Test MSE 2.41583956911606 Test RE 0.7429200947276311\n",
      "87 Train Loss 1.6575474 Test MSE 2.409811210835826 Test RE 0.7419925940025327\n",
      "88 Train Loss 1.613819 Test MSE 2.3768365444262254 Test RE 0.7368985778847441\n",
      "89 Train Loss 1.5600401 Test MSE 2.425486540584106 Test RE 0.7444019374217045\n",
      "90 Train Loss 1.507929 Test MSE 2.4398606966640175 Test RE 0.7466044529147304\n",
      "91 Train Loss 1.4746457 Test MSE 2.44800229953666 Test RE 0.7478490925177059\n",
      "92 Train Loss 1.4429833 Test MSE 2.4719358563648584 Test RE 0.7514959750131082\n",
      "93 Train Loss 1.4044033 Test MSE 2.4705939109878523 Test RE 0.7512919641664676\n",
      "94 Train Loss 1.376675 Test MSE 2.4426656280416545 Test RE 0.747033488212745\n",
      "95 Train Loss 1.3410918 Test MSE 2.442922390242242 Test RE 0.7470727496081351\n",
      "96 Train Loss 1.3059542 Test MSE 2.4287135405557776 Test RE 0.7448969693508188\n",
      "97 Train Loss 1.268047 Test MSE 2.4553259006691466 Test RE 0.748966913828586\n",
      "98 Train Loss 1.2556767 Test MSE 2.488861042475215 Test RE 0.7540643085564892\n",
      "99 Train Loss 1.2340809 Test MSE 2.471437310314055 Test RE 0.7514201894214577\n",
      "Training time: 79.86\n",
      "KG_stan_tune2\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.3468 Test MSE 8.382115889121534 Test RE 1.3838368486804857\n",
      "1 Train Loss 53.741802 Test MSE 7.559849999893345 Test RE 1.3142096430301442\n",
      "2 Train Loss 45.84638 Test MSE 8.206444490633439 Test RE 1.36925891868175\n",
      "3 Train Loss 44.991894 Test MSE 8.106353575305631 Test RE 1.3608831333689522\n",
      "4 Train Loss 44.609383 Test MSE 8.282294138212729 Test RE 1.3755721842963755\n",
      "5 Train Loss 44.364048 Test MSE 8.195045894292752 Test RE 1.368307650860428\n",
      "6 Train Loss 43.732437 Test MSE 8.422446451167357 Test RE 1.3871620201568806\n",
      "7 Train Loss 43.532364 Test MSE 8.373956596006144 Test RE 1.3831631596201048\n",
      "8 Train Loss 43.394756 Test MSE 8.42872393235661 Test RE 1.3876788688888095\n",
      "9 Train Loss 43.02054 Test MSE 8.343743511326018 Test RE 1.3806656909864747\n",
      "10 Train Loss 42.844322 Test MSE 8.282657221394 Test RE 1.3756023354623916\n",
      "11 Train Loss 42.47808 Test MSE 8.23685764154698 Test RE 1.3717938146858375\n",
      "12 Train Loss 42.162186 Test MSE 8.522131309824385 Test RE 1.3953468331886434\n",
      "13 Train Loss 40.781742 Test MSE 8.47897250619802 Test RE 1.3918091067271767\n",
      "14 Train Loss 40.241596 Test MSE 8.749658467512726 Test RE 1.4138508942848789\n",
      "15 Train Loss 39.55948 Test MSE 8.570991135185528 Test RE 1.399341078320271\n",
      "16 Train Loss 38.956917 Test MSE 8.562042796103917 Test RE 1.3986104132060857\n",
      "17 Train Loss 38.372093 Test MSE 8.476478319015222 Test RE 1.3916043833505907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Train Loss 37.979637 Test MSE 8.279228386188256 Test RE 1.3753175716574035\n",
      "19 Train Loss 37.717323 Test MSE 8.367228104689675 Test RE 1.3826073607321008\n",
      "20 Train Loss 36.904213 Test MSE 8.123476051156679 Test RE 1.3623196236924178\n",
      "21 Train Loss 34.520374 Test MSE 7.778262295794233 Test RE 1.3330589418212266\n",
      "22 Train Loss 33.527763 Test MSE 7.742208927317626 Test RE 1.3299658931701808\n",
      "23 Train Loss 32.326504 Test MSE 7.504110827614148 Test RE 1.3093558111246923\n",
      "24 Train Loss 30.689491 Test MSE 6.077164576980755 Test RE 1.1783072751939674\n",
      "25 Train Loss 23.361416 Test MSE 4.835282401598493 Test RE 1.051039365163626\n",
      "26 Train Loss 18.510498 Test MSE 4.131545900616771 Test RE 0.9715481995812925\n",
      "27 Train Loss 15.685494 Test MSE 3.9183421869104627 Test RE 0.9461483586411972\n",
      "28 Train Loss 13.425764 Test MSE 3.42486846944873 Test RE 0.8845655244147678\n",
      "29 Train Loss 11.230871 Test MSE 4.0527101692097105 Test RE 0.962234299032456\n",
      "30 Train Loss 10.237804 Test MSE 3.796620946403568 Test RE 0.9313366207156584\n",
      "31 Train Loss 9.593891 Test MSE 3.841931014532132 Test RE 0.9368775699238606\n",
      "32 Train Loss 9.264983 Test MSE 3.936122626239993 Test RE 0.9482926190600951\n",
      "33 Train Loss 8.823447 Test MSE 3.9152420266570775 Test RE 0.9457739921606564\n",
      "34 Train Loss 8.515187 Test MSE 3.8848648939186945 Test RE 0.94209786617511\n",
      "35 Train Loss 8.247525 Test MSE 3.898700598497444 Test RE 0.9437739866153525\n",
      "36 Train Loss 7.740415 Test MSE 3.8041630348876816 Test RE 0.9322612242394422\n",
      "37 Train Loss 7.4363365 Test MSE 3.8635014445069333 Test RE 0.939503927055446\n",
      "38 Train Loss 7.181706 Test MSE 3.7572290389646072 Test RE 0.926492473069708\n",
      "39 Train Loss 6.73518 Test MSE 3.4962851642086865 Test RE 0.8937405935346644\n",
      "40 Train Loss 6.469561 Test MSE 3.3899850119167025 Test RE 0.8800491935821915\n",
      "41 Train Loss 6.1683674 Test MSE 3.2300813489443403 Test RE 0.8590427765493379\n",
      "42 Train Loss 5.9562683 Test MSE 3.184960773564707 Test RE 0.8530217489065349\n",
      "43 Train Loss 5.4888644 Test MSE 3.02164773327538 Test RE 0.8308640658463201\n",
      "44 Train Loss 5.1855392 Test MSE 2.7968458344877636 Test RE 0.7993598380641396\n",
      "45 Train Loss 4.8649487 Test MSE 2.4974616909694918 Test RE 0.7553660784714306\n",
      "46 Train Loss 4.7739735 Test MSE 2.4078854191689794 Test RE 0.7416960544350871\n",
      "47 Train Loss 4.644039 Test MSE 2.2268655772299693 Test RE 0.7132718119076463\n",
      "48 Train Loss 4.539791 Test MSE 2.1570382747428862 Test RE 0.7019997960436912\n",
      "49 Train Loss 4.3152933 Test MSE 1.9816235784599614 Test RE 0.6728505950491391\n",
      "50 Train Loss 4.238557 Test MSE 1.9822098418416156 Test RE 0.6729501191207103\n",
      "51 Train Loss 4.1192226 Test MSE 1.832353292243795 Test RE 0.6470124933883339\n",
      "52 Train Loss 4.0336375 Test MSE 1.7735473538722095 Test RE 0.6365455034133516\n",
      "53 Train Loss 3.982273 Test MSE 1.7907452487136999 Test RE 0.639624313784002\n",
      "54 Train Loss 3.9457028 Test MSE 1.7820976681886356 Test RE 0.638078059079389\n",
      "55 Train Loss 3.9079287 Test MSE 1.7754588002658092 Test RE 0.6368884305274957\n",
      "56 Train Loss 3.8693185 Test MSE 1.7592611048791253 Test RE 0.6339765743061486\n",
      "57 Train Loss 3.8146958 Test MSE 1.7588896050399585 Test RE 0.6339096329551055\n",
      "58 Train Loss 3.7814152 Test MSE 1.7557578016871414 Test RE 0.6333450253691449\n",
      "59 Train Loss 3.7416825 Test MSE 1.7520663458037842 Test RE 0.6326788755744284\n",
      "60 Train Loss 3.6717556 Test MSE 1.7438762633566147 Test RE 0.6311984059987638\n",
      "61 Train Loss 3.6464417 Test MSE 1.7272343510825383 Test RE 0.6281794046166347\n",
      "62 Train Loss 3.601066 Test MSE 1.6917022316707147 Test RE 0.6216844739924531\n",
      "63 Train Loss 3.5351772 Test MSE 1.6622169138925837 Test RE 0.6162428719618445\n",
      "64 Train Loss 3.4985693 Test MSE 1.629667164651416 Test RE 0.610179366812419\n",
      "65 Train Loss 3.2701874 Test MSE 1.5767634769411119 Test RE 0.6001935668207881\n",
      "66 Train Loss 3.1178079 Test MSE 1.5339746943209043 Test RE 0.5919937993670654\n",
      "67 Train Loss 2.171808 Test MSE 1.0278250387171217 Test RE 0.48458242273292024\n",
      "68 Train Loss 1.1669631 Test MSE 0.7989102757912117 Test RE 0.42722539883148514\n",
      "69 Train Loss 0.94305277 Test MSE 0.6329299322953463 Test RE 0.3802645825964446\n",
      "70 Train Loss 0.6761465 Test MSE 0.4673468887259426 Test RE 0.3267591353460992\n",
      "71 Train Loss 0.5364888 Test MSE 0.3599072993735882 Test RE 0.2867499743138228\n",
      "72 Train Loss 0.44995335 Test MSE 0.2665811895206972 Test RE 0.24678730253704956\n",
      "73 Train Loss 0.40351522 Test MSE 0.270268066837233 Test RE 0.2484880041803438\n",
      "74 Train Loss 0.35014507 Test MSE 0.24564755325193788 Test RE 0.2368995750312001\n",
      "75 Train Loss 0.32403344 Test MSE 0.23317201975375998 Test RE 0.23080556585767467\n",
      "76 Train Loss 0.29252714 Test MSE 0.18708848366110337 Test RE 0.20674336840449678\n",
      "77 Train Loss 0.26653287 Test MSE 0.13199924903928645 Test RE 0.1736575983442334\n",
      "78 Train Loss 0.23804703 Test MSE 0.11753304188013189 Test RE 0.16386569656330663\n",
      "79 Train Loss 0.22002105 Test MSE 0.13622611042599375 Test RE 0.17641610879109712\n",
      "80 Train Loss 0.19101015 Test MSE 0.12595035571921576 Test RE 0.16963199099146004\n",
      "81 Train Loss 0.16469912 Test MSE 0.08262936829176398 Test RE 0.13739637560060375\n",
      "82 Train Loss 0.14264177 Test MSE 0.05591272788574836 Test RE 0.11302210741420497\n",
      "83 Train Loss 0.12684461 Test MSE 0.055766340122331136 Test RE 0.11287405617708961\n",
      "84 Train Loss 0.119683966 Test MSE 0.046006619436086985 Test RE 0.10252227188085003\n",
      "85 Train Loss 0.10841608 Test MSE 0.029823751362524884 Test RE 0.08254470034559579\n",
      "86 Train Loss 0.09296994 Test MSE 0.023949286823396383 Test RE 0.07396978440733522\n",
      "87 Train Loss 0.081735395 Test MSE 0.018767551630171114 Test RE 0.06548048235401342\n",
      "88 Train Loss 0.07634728 Test MSE 0.015059562840803266 Test RE 0.058656243045012886\n",
      "89 Train Loss 0.070087485 Test MSE 0.013721871148590902 Test RE 0.05599054936772868\n",
      "90 Train Loss 0.06292326 Test MSE 0.012749441039858112 Test RE 0.053970150945814026\n",
      "91 Train Loss 0.05717422 Test MSE 0.01282849099906382 Test RE 0.05413720711435267\n",
      "92 Train Loss 0.05182239 Test MSE 0.012788251126106076 Test RE 0.054052232764756056\n",
      "93 Train Loss 0.047471978 Test MSE 0.012326460164910298 Test RE 0.053067331371676685\n",
      "94 Train Loss 0.044255454 Test MSE 0.012079788957933298 Test RE 0.05253366904308441\n",
      "95 Train Loss 0.03952925 Test MSE 0.012070015742318559 Test RE 0.052512413424908186\n",
      "96 Train Loss 0.03652626 Test MSE 0.013236852713090485 Test RE 0.0549921156994106\n",
      "97 Train Loss 0.033483967 Test MSE 0.011278928167630771 Test RE 0.05076237997841672\n",
      "98 Train Loss 0.031180043 Test MSE 0.009189643651713599 Test RE 0.04582024381396716\n",
      "99 Train Loss 0.028336946 Test MSE 0.006313797069915857 Test RE 0.03797986090728589\n",
      "Training time: 79.39\n",
      "KG_stan_tune2\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 56.443756 Test MSE 8.678718427727537 Test RE 1.408107654907332\n",
      "1 Train Loss 50.271572 Test MSE 7.982733933662786 Test RE 1.3504667239703056\n",
      "2 Train Loss 44.31331 Test MSE 8.272054108138006 Test RE 1.374721559043088\n",
      "3 Train Loss 43.295467 Test MSE 7.847542261135391 Test RE 1.3389824718901957\n",
      "4 Train Loss 42.4327 Test MSE 8.0202093951385 Test RE 1.3536329390721036\n",
      "5 Train Loss 41.968956 Test MSE 8.211827288356226 Test RE 1.3697079094464264\n",
      "6 Train Loss 41.706535 Test MSE 8.136332423981722 Test RE 1.3633972144099462\n",
      "7 Train Loss 40.685295 Test MSE 8.287814825876943 Test RE 1.3760305620835473\n",
      "8 Train Loss 39.728584 Test MSE 8.222218965078913 Test RE 1.370574285538672\n",
      "9 Train Loss 38.584686 Test MSE 8.208824671546655 Test RE 1.3694574728587092\n",
      "10 Train Loss 37.83412 Test MSE 7.532815161828516 Test RE 1.3118576607760497\n",
      "11 Train Loss 36.604847 Test MSE 7.504084549541906 Test RE 1.3093535185561587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 35.93236 Test MSE 7.289948525317856 Test RE 1.2905364971309714\n",
      "13 Train Loss 34.870094 Test MSE 7.034237927363871 Test RE 1.2677002828338813\n",
      "14 Train Loss 29.647299 Test MSE 6.019885559773523 Test RE 1.1727411868256192\n",
      "15 Train Loss 28.728489 Test MSE 6.230718639251439 Test RE 1.193100782127739\n",
      "16 Train Loss 28.328512 Test MSE 6.408408029858337 Test RE 1.2099937811757653\n",
      "17 Train Loss 27.3606 Test MSE 6.406959981130115 Test RE 1.2098570678971194\n",
      "18 Train Loss 26.861538 Test MSE 6.546480744944134 Test RE 1.2229593104448093\n",
      "19 Train Loss 26.135641 Test MSE 6.356321391147282 Test RE 1.2050664189265274\n",
      "20 Train Loss 25.126411 Test MSE 6.49227949499236 Test RE 1.2178860734253125\n",
      "21 Train Loss 24.459774 Test MSE 6.308705445074368 Test RE 1.2005442873937402\n",
      "22 Train Loss 23.660192 Test MSE 6.349387787757011 Test RE 1.204408984231909\n",
      "23 Train Loss 23.246708 Test MSE 6.362481305072461 Test RE 1.205650192731786\n",
      "24 Train Loss 22.564281 Test MSE 6.171410000539981 Test RE 1.1874087919231473\n",
      "25 Train Loss 21.883753 Test MSE 6.166737538537436 Test RE 1.1869592047947983\n",
      "26 Train Loss 21.299545 Test MSE 5.939801832415198 Test RE 1.1649144656763317\n",
      "27 Train Loss 20.346916 Test MSE 5.809964064384334 Test RE 1.1521122209202406\n",
      "28 Train Loss 20.070065 Test MSE 5.880430589556315 Test RE 1.1590778974793405\n",
      "29 Train Loss 19.291012 Test MSE 5.689216654663436 Test RE 1.1400772949887634\n",
      "30 Train Loss 18.024628 Test MSE 5.379531890815429 Test RE 1.1086138590117773\n",
      "31 Train Loss 17.004333 Test MSE 5.639580621167973 Test RE 1.1350930512626716\n",
      "32 Train Loss 16.447584 Test MSE 5.657647817141945 Test RE 1.136909813111611\n",
      "33 Train Loss 15.714405 Test MSE 5.694838008654041 Test RE 1.140640394984708\n",
      "34 Train Loss 14.626769 Test MSE 5.752127382813177 Test RE 1.14636338931003\n",
      "35 Train Loss 13.789478 Test MSE 5.499842588533112 Test RE 1.120942124664394\n",
      "36 Train Loss 13.0846615 Test MSE 5.387557283326954 Test RE 1.1094404872176393\n",
      "37 Train Loss 12.678141 Test MSE 5.351452299379461 Test RE 1.1057167526415426\n",
      "38 Train Loss 12.24133 Test MSE 5.547218107563805 Test RE 1.1257596573707123\n",
      "39 Train Loss 11.866201 Test MSE 5.502635896562318 Test RE 1.121226745462207\n",
      "40 Train Loss 11.49248 Test MSE 5.382714614952004 Test RE 1.1089417583931116\n",
      "41 Train Loss 11.026033 Test MSE 5.127792835187685 Test RE 1.0823638926210832\n",
      "42 Train Loss 10.638746 Test MSE 5.059486927459529 Test RE 1.0751307895508886\n",
      "43 Train Loss 10.290697 Test MSE 4.9729167366206655 Test RE 1.0658931081314602\n",
      "44 Train Loss 10.084848 Test MSE 4.840644494216786 Test RE 1.0516219794114152\n",
      "45 Train Loss 9.88139 Test MSE 4.805324369228633 Test RE 1.0477783359610522\n",
      "46 Train Loss 9.67753 Test MSE 4.6570720823811245 Test RE 1.0314888559616222\n",
      "47 Train Loss 9.525613 Test MSE 4.607438128809654 Test RE 1.025977451816006\n",
      "48 Train Loss 9.41081 Test MSE 4.556616439045263 Test RE 1.020303312436865\n",
      "49 Train Loss 9.270367 Test MSE 4.4699473277961 Test RE 1.01055338949756\n",
      "50 Train Loss 9.096356 Test MSE 4.416140925603819 Test RE 1.0044527734141144\n",
      "51 Train Loss 9.03385 Test MSE 4.3738275396097075 Test RE 0.9996290939423577\n",
      "52 Train Loss 8.886012 Test MSE 4.275030162145545 Test RE 0.9882746417177886\n",
      "53 Train Loss 8.812984 Test MSE 4.240737321295737 Test RE 0.9843028587478457\n",
      "54 Train Loss 8.741761 Test MSE 4.199933501323968 Test RE 0.9795559960271841\n",
      "55 Train Loss 8.640274 Test MSE 4.154319892544407 Test RE 0.9742222136481609\n",
      "56 Train Loss 8.583382 Test MSE 4.162997576005874 Test RE 0.9752391769620931\n",
      "57 Train Loss 8.48998 Test MSE 4.087754380202699 Test RE 0.9663856147168584\n",
      "58 Train Loss 8.4383135 Test MSE 4.0332242107240015 Test RE 0.9599182377614506\n",
      "59 Train Loss 8.392536 Test MSE 4.023291320504381 Test RE 0.9587354817713516\n",
      "60 Train Loss 8.312884 Test MSE 4.02763923986072 Test RE 0.9592533884580158\n",
      "61 Train Loss 8.243282 Test MSE 4.020219403063841 Test RE 0.9583693985811605\n",
      "62 Train Loss 8.202311 Test MSE 3.9864836230960257 Test RE 0.9543398358476518\n",
      "63 Train Loss 8.149628 Test MSE 3.9181020083481006 Test RE 0.9461193606588715\n",
      "64 Train Loss 8.11567 Test MSE 3.9397806750388953 Test RE 0.9487331661950732\n",
      "65 Train Loss 8.092482 Test MSE 3.9466105896009616 Test RE 0.9495551612677697\n",
      "66 Train Loss 8.030036 Test MSE 3.909180069077093 Test RE 0.9450415390081256\n",
      "67 Train Loss 7.9784865 Test MSE 3.9402377468320307 Test RE 0.9487881980139565\n",
      "68 Train Loss 7.9458084 Test MSE 3.9340293824157206 Test RE 0.9480404328560977\n",
      "69 Train Loss 7.9041743 Test MSE 3.9253109621110047 Test RE 0.9469893477474414\n",
      "70 Train Loss 7.8770294 Test MSE 3.9127053326079113 Test RE 0.9454675579773679\n",
      "71 Train Loss 7.8558903 Test MSE 3.904733035268548 Test RE 0.9445038523966574\n",
      "72 Train Loss 7.823948 Test MSE 3.9169868903564264 Test RE 0.945984715134424\n",
      "73 Train Loss 7.785858 Test MSE 3.9163309200117853 Test RE 0.945905500687295\n",
      "74 Train Loss 7.7346845 Test MSE 3.899383439269258 Test RE 0.9438566319898276\n",
      "75 Train Loss 7.7006726 Test MSE 3.876020594163268 Test RE 0.9410248631442502\n",
      "76 Train Loss 7.6726437 Test MSE 3.8744543432755765 Test RE 0.9408347158119941\n",
      "77 Train Loss 7.644957 Test MSE 3.844532529654898 Test RE 0.93719471365963\n",
      "78 Train Loss 7.6227407 Test MSE 3.842928594311124 Test RE 0.9369991948898277\n",
      "79 Train Loss 7.569277 Test MSE 3.845918183907972 Test RE 0.937363591258985\n",
      "80 Train Loss 7.532442 Test MSE 3.8349034288571473 Test RE 0.9360203185902185\n",
      "81 Train Loss 7.4808025 Test MSE 3.8070150669086673 Test RE 0.9326106231327085\n",
      "82 Train Loss 7.4431486 Test MSE 3.799059494986025 Test RE 0.9316356688778373\n",
      "83 Train Loss 7.3642135 Test MSE 3.764296140134867 Test RE 0.9273633994832998\n",
      "84 Train Loss 6.8290205 Test MSE 3.567905843403225 Test RE 0.9028482336486067\n",
      "85 Train Loss 5.912185 Test MSE 3.2421246373235584 Test RE 0.8606427477695375\n",
      "86 Train Loss 5.469747 Test MSE 2.9686479014343052 Test RE 0.8235451344614829\n",
      "87 Train Loss 5.300076 Test MSE 2.74824005939102 Test RE 0.7923834445792615\n",
      "88 Train Loss 5.124996 Test MSE 2.507668067122593 Test RE 0.7569079819483431\n",
      "89 Train Loss 5.047753 Test MSE 2.4742362859337272 Test RE 0.751845571775399\n",
      "90 Train Loss 4.9294915 Test MSE 2.4010896758996925 Test RE 0.7406486754145419\n",
      "91 Train Loss 4.853336 Test MSE 2.3592004289335087 Test RE 0.7341595957007468\n",
      "92 Train Loss 4.799887 Test MSE 2.291324861233022 Test RE 0.723521421506784\n",
      "93 Train Loss 4.7107234 Test MSE 2.267642622822973 Test RE 0.7197726926537574\n",
      "94 Train Loss 4.6498976 Test MSE 2.2471426157393513 Test RE 0.716511851490928\n",
      "95 Train Loss 4.599625 Test MSE 2.231464191953056 Test RE 0.714007907218661\n",
      "96 Train Loss 4.5374627 Test MSE 2.205349682695704 Test RE 0.7098176449435709\n",
      "97 Train Loss 4.518018 Test MSE 2.2081936655834715 Test RE 0.7102751820967921\n",
      "98 Train Loss 4.499788 Test MSE 2.2063843422448706 Test RE 0.7099841340701221\n",
      "99 Train Loss 4.486513 Test MSE 2.197117585984796 Test RE 0.7084916079251309\n",
      "Training time: 79.41\n",
      "KG_stan_tune2\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.958538 Test MSE 8.19227126773494 Test RE 1.368075994796322\n",
      "1 Train Loss 58.09694 Test MSE 8.4647111057994 Test RE 1.39063812165838\n",
      "2 Train Loss 53.04574 Test MSE 9.180702752427706 Test RE 1.4482582909634472\n",
      "3 Train Loss 47.5813 Test MSE 8.552183885007944 Test RE 1.3978049542947204\n",
      "4 Train Loss 46.63977 Test MSE 8.635193637804381 Test RE 1.4045723043379479\n",
      "5 Train Loss 46.35627 Test MSE 8.564555346086113 Test RE 1.3988156107790715\n",
      "6 Train Loss 45.627403 Test MSE 8.407919620913052 Test RE 1.3859652322735956\n",
      "7 Train Loss 45.35147 Test MSE 8.368611613379503 Test RE 1.382721662040079\n",
      "8 Train Loss 45.188194 Test MSE 8.312981672310245 Test RE 1.3781182112835852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Train Loss 44.771873 Test MSE 8.4244610890461 Test RE 1.3873279138831314\n",
      "10 Train Loss 44.67955 Test MSE 8.420772110662437 Test RE 1.3870241328451838\n",
      "11 Train Loss 44.137802 Test MSE 8.675482283747957 Test RE 1.4078451009358661\n",
      "12 Train Loss 44.03206 Test MSE 8.707814643698267 Test RE 1.4104660862111127\n",
      "13 Train Loss 43.80581 Test MSE 8.908210989153082 Test RE 1.4266035736940994\n",
      "14 Train Loss 43.21237 Test MSE 8.87346155352166 Test RE 1.423818384373877\n",
      "15 Train Loss 42.608032 Test MSE 8.893265719894986 Test RE 1.4254063678467803\n",
      "16 Train Loss 41.989983 Test MSE 9.00483051889833 Test RE 1.4343192659118809\n",
      "17 Train Loss 41.37687 Test MSE 9.109866823274796 Test RE 1.4426602785561307\n",
      "18 Train Loss 40.81047 Test MSE 9.056218783830936 Test RE 1.4384060902147817\n",
      "19 Train Loss 40.303192 Test MSE 8.89398566028956 Test RE 1.4254640624489274\n",
      "20 Train Loss 39.977837 Test MSE 8.959642202323378 Test RE 1.430715867098188\n",
      "21 Train Loss 38.89848 Test MSE 8.973376060282126 Test RE 1.4318119892392207\n",
      "22 Train Loss 36.789253 Test MSE 8.431449911864652 Test RE 1.3879032491382657\n",
      "23 Train Loss 33.50465 Test MSE 8.247121802649168 Test RE 1.3726482624373981\n",
      "24 Train Loss 32.384403 Test MSE 8.648234418008762 Test RE 1.4056324895090673\n",
      "25 Train Loss 31.213348 Test MSE 8.72415958440403 Test RE 1.4117892182081717\n",
      "26 Train Loss 30.190458 Test MSE 8.672227809897155 Test RE 1.4075810104394977\n",
      "27 Train Loss 29.253548 Test MSE 8.317246335927768 Test RE 1.3784716619015815\n",
      "28 Train Loss 28.645195 Test MSE 8.215075347312125 Test RE 1.3699787658618579\n",
      "29 Train Loss 28.180689 Test MSE 8.058573141746201 Test RE 1.3568665503031543\n",
      "30 Train Loss 27.38949 Test MSE 8.090743345999687 Test RE 1.3595721903805893\n",
      "31 Train Loss 26.628616 Test MSE 7.916796682693099 Test RE 1.3448777423528635\n",
      "32 Train Loss 25.981092 Test MSE 7.760507588143371 Test RE 1.331536648502371\n",
      "33 Train Loss 24.926674 Test MSE 7.72106641872471 Test RE 1.3281487090411472\n",
      "34 Train Loss 24.071 Test MSE 7.377768129571779 Test RE 1.2982865600488527\n",
      "35 Train Loss 23.173422 Test MSE 7.362507205827691 Test RE 1.2969431111707654\n",
      "36 Train Loss 21.552055 Test MSE 7.631428101338334 Test RE 1.3204165792878573\n",
      "37 Train Loss 20.668812 Test MSE 7.011776136415942 Test RE 1.265674648578352\n",
      "38 Train Loss 20.195004 Test MSE 7.26206843263646 Test RE 1.2880663326148833\n",
      "39 Train Loss 19.462032 Test MSE 6.9646166090356525 Test RE 1.2614111553597145\n",
      "40 Train Loss 18.684925 Test MSE 6.8185985893364425 Test RE 1.2481179308035688\n",
      "41 Train Loss 17.762749 Test MSE 6.531292232683748 Test RE 1.2215397905789258\n",
      "42 Train Loss 17.353096 Test MSE 6.41221221732558 Test RE 1.2103528688180727\n",
      "43 Train Loss 16.984041 Test MSE 6.299555796541672 Test RE 1.1996733841594585\n",
      "44 Train Loss 16.76847 Test MSE 5.909422493052891 Test RE 1.161931647479299\n",
      "45 Train Loss 16.552332 Test MSE 5.78241665638156 Test RE 1.149377658807277\n",
      "46 Train Loss 16.3398 Test MSE 5.6812096535805745 Test RE 1.1392747403622654\n",
      "47 Train Loss 16.15335 Test MSE 5.599062167460442 Test RE 1.1310080734937618\n",
      "48 Train Loss 15.920048 Test MSE 5.392791042608594 Test RE 1.1099792411120535\n",
      "49 Train Loss 15.707865 Test MSE 5.309326568429006 Test RE 1.1013561461976407\n",
      "50 Train Loss 15.430544 Test MSE 5.445582006745265 Test RE 1.115398899295624\n",
      "51 Train Loss 15.09156 Test MSE 5.477931196196012 Test RE 1.118706977538262\n",
      "52 Train Loss 14.829719 Test MSE 5.604984954181806 Test RE 1.1316061155255839\n",
      "53 Train Loss 14.529276 Test MSE 5.556917050796303 Test RE 1.1267433856395275\n",
      "54 Train Loss 14.274225 Test MSE 5.52555469855719 Test RE 1.1235593068266208\n",
      "55 Train Loss 13.949472 Test MSE 5.615638158984773 Test RE 1.1326810076973075\n",
      "56 Train Loss 13.685359 Test MSE 5.605590974125157 Test RE 1.1316672894041793\n",
      "57 Train Loss 13.299682 Test MSE 5.490679725819852 Test RE 1.1200079779005827\n",
      "58 Train Loss 12.961468 Test MSE 5.647330814934028 Test RE 1.1358727343074309\n",
      "59 Train Loss 12.686729 Test MSE 5.5482149654731625 Test RE 1.1258608046470822\n",
      "60 Train Loss 12.295257 Test MSE 5.720414354669038 Test RE 1.1431989165102192\n",
      "61 Train Loss 12.013142 Test MSE 5.798486581793606 Test RE 1.1509736695545714\n",
      "62 Train Loss 11.665309 Test MSE 5.597833092073675 Test RE 1.130883930339192\n",
      "63 Train Loss 11.349342 Test MSE 5.573282393677263 Test RE 1.1284013180266832\n",
      "64 Train Loss 11.133076 Test MSE 5.570681848197958 Test RE 1.1281380260265215\n",
      "65 Train Loss 10.958768 Test MSE 5.557720858688839 Test RE 1.1268248743920584\n",
      "66 Train Loss 10.731461 Test MSE 5.6396454441723884 Test RE 1.1350995747912263\n",
      "67 Train Loss 10.512765 Test MSE 5.705061143000344 Test RE 1.1416637508180476\n",
      "68 Train Loss 10.3266735 Test MSE 5.795362496313468 Test RE 1.150663569278103\n",
      "69 Train Loss 10.0477705 Test MSE 5.753376812710357 Test RE 1.14648788437304\n",
      "70 Train Loss 9.888761 Test MSE 5.679484631767482 Test RE 1.1391017646138881\n",
      "71 Train Loss 9.759367 Test MSE 5.664549370245527 Test RE 1.137603038659164\n",
      "72 Train Loss 9.636573 Test MSE 5.644544485503675 Test RE 1.1355924863272584\n",
      "73 Train Loss 9.480316 Test MSE 5.698766419180496 Test RE 1.141033745176621\n",
      "74 Train Loss 9.319371 Test MSE 5.748515952596879 Test RE 1.1460034649611477\n",
      "75 Train Loss 9.193768 Test MSE 5.858711963460469 Test RE 1.1569354636925266\n",
      "76 Train Loss 9.062159 Test MSE 5.898598151588963 Test RE 1.1608669994851344\n",
      "77 Train Loss 8.972048 Test MSE 5.921013619838463 Test RE 1.1630706334991687\n",
      "78 Train Loss 8.873577 Test MSE 5.941932870104764 Test RE 1.1651234165875188\n",
      "79 Train Loss 8.774992 Test MSE 5.908743812473507 Test RE 1.1618649232699951\n",
      "80 Train Loss 8.594212 Test MSE 5.950449232809836 Test RE 1.1659580827593976\n",
      "81 Train Loss 8.378515 Test MSE 5.937955069264903 Test RE 1.1647333579210795\n",
      "82 Train Loss 8.300276 Test MSE 5.870460938785142 Test RE 1.1580949334207427\n",
      "83 Train Loss 8.151819 Test MSE 5.912369215301408 Test RE 1.1622213088733064\n",
      "84 Train Loss 7.9424276 Test MSE 5.862308553995272 Test RE 1.1572905233677477\n",
      "85 Train Loss 7.784895 Test MSE 5.770251574551499 Test RE 1.148167988539012\n",
      "86 Train Loss 7.627022 Test MSE 5.827854675197129 Test RE 1.1538847059043582\n",
      "87 Train Loss 7.4445186 Test MSE 5.7717294853494066 Test RE 1.1483150168969365\n",
      "88 Train Loss 7.244109 Test MSE 5.675951048049137 Test RE 1.1387473541367972\n",
      "89 Train Loss 6.979861 Test MSE 5.664472379907249 Test RE 1.1375953077052388\n",
      "90 Train Loss 6.6871557 Test MSE 5.639977584062753 Test RE 1.1351329994365615\n",
      "91 Train Loss 6.4136453 Test MSE 5.561916440691361 Test RE 1.1272501201335037\n",
      "92 Train Loss 6.0843816 Test MSE 5.746198067584682 Test RE 1.1457723990568027\n",
      "93 Train Loss 5.7203064 Test MSE 5.779027789307108 Test RE 1.1490408049280343\n",
      "94 Train Loss 5.4154286 Test MSE 5.762174317419227 Test RE 1.1473640984741733\n",
      "95 Train Loss 4.865221 Test MSE 5.446051929676272 Test RE 1.1154470245659813\n",
      "96 Train Loss 4.251979 Test MSE 5.294437580450322 Test RE 1.0998107909935664\n",
      "97 Train Loss 3.914833 Test MSE 5.168324433063986 Test RE 1.086633135756737\n",
      "98 Train Loss 3.5110974 Test MSE 5.0736757471894665 Test RE 1.0766372819073275\n",
      "99 Train Loss 3.224185 Test MSE 5.051528090795616 Test RE 1.074284838351909\n",
      "Training time: 79.55\n",
      "KG_stan_tune2\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.918377 Test MSE 8.415722209680856 Test RE 1.386608174256695\n",
      "1 Train Loss 55.190907 Test MSE 8.416022514975316 Test RE 1.386632913788907\n",
      "2 Train Loss 52.823246 Test MSE 9.44183426271351 Test RE 1.4687106587983094\n",
      "3 Train Loss 47.399513 Test MSE 7.297436936368708 Test RE 1.2911991621152337\n",
      "4 Train Loss 43.900368 Test MSE 8.094416206391333 Test RE 1.3598807499313208\n",
      "5 Train Loss 43.043983 Test MSE 8.081414179498443 Test RE 1.358788125605434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Train Loss 42.753677 Test MSE 8.236900097777824 Test RE 1.3717973500826086\n",
      "7 Train Loss 42.472042 Test MSE 8.255150409406212 Test RE 1.3733162392521705\n",
      "8 Train Loss 41.927456 Test MSE 8.231116956879534 Test RE 1.3713156949544951\n",
      "9 Train Loss 40.965866 Test MSE 8.248777787933077 Test RE 1.3727860663453597\n",
      "10 Train Loss 39.738007 Test MSE 7.836172071449438 Test RE 1.3380121041739759\n",
      "11 Train Loss 36.45652 Test MSE 7.554897826583887 Test RE 1.313779127868811\n",
      "12 Train Loss 33.938423 Test MSE 6.098977542989917 Test RE 1.1804200494919195\n",
      "13 Train Loss 31.244509 Test MSE 5.795954047864516 Test RE 1.150722293771242\n",
      "14 Train Loss 25.242619 Test MSE 4.367428758886147 Test RE 0.9988976123657798\n",
      "15 Train Loss 19.989557 Test MSE 3.936419777020205 Test RE 0.9483284132413679\n",
      "16 Train Loss 16.543228 Test MSE 3.761674149057596 Test RE 0.9270403693558702\n",
      "17 Train Loss 14.830858 Test MSE 3.4170542380469264 Test RE 0.8835558291507658\n",
      "18 Train Loss 13.655321 Test MSE 3.4127472130266674 Test RE 0.8829988147293506\n",
      "19 Train Loss 12.410812 Test MSE 3.761538784388742 Test RE 0.9270236893303561\n",
      "20 Train Loss 11.602504 Test MSE 3.8025881924704183 Test RE 0.9320682361254861\n",
      "21 Train Loss 10.742975 Test MSE 3.860101789203138 Test RE 0.9390904818303397\n",
      "22 Train Loss 9.847608 Test MSE 3.7601441398628785 Test RE 0.9268518197249371\n",
      "23 Train Loss 9.308319 Test MSE 3.7747041682564406 Test RE 0.9286445635294037\n",
      "24 Train Loss 8.898382 Test MSE 3.723786451693352 Test RE 0.9223599647234217\n",
      "25 Train Loss 8.516369 Test MSE 3.785796833530891 Test RE 0.9300080593147542\n",
      "26 Train Loss 8.332114 Test MSE 3.8518613501503873 Test RE 0.9380875740430206\n",
      "27 Train Loss 8.182002 Test MSE 3.85064120932885 Test RE 0.9379389848940046\n",
      "28 Train Loss 8.099334 Test MSE 3.841309674575234 Test RE 0.9368018081513857\n",
      "29 Train Loss 8.019716 Test MSE 3.844517688310832 Test RE 0.937192904695534\n",
      "30 Train Loss 7.9373875 Test MSE 3.8680000031727246 Test RE 0.9400507346635254\n",
      "31 Train Loss 7.8505197 Test MSE 3.820612193176447 Test RE 0.9342745936782614\n",
      "32 Train Loss 7.7608557 Test MSE 3.8211546612244436 Test RE 0.9343409176207123\n",
      "33 Train Loss 7.7142587 Test MSE 3.8161974883715857 Test RE 0.9337346620530373\n",
      "34 Train Loss 7.631262 Test MSE 3.775568837288752 Test RE 0.9287509194425587\n",
      "35 Train Loss 7.5754538 Test MSE 3.7946884309019744 Test RE 0.931099561028628\n",
      "36 Train Loss 7.484781 Test MSE 3.787370656266502 Test RE 0.9302013496319403\n",
      "37 Train Loss 7.3485703 Test MSE 3.6871780816668207 Test RE 0.9178149278369352\n",
      "38 Train Loss 6.552907 Test MSE 3.6509221881452767 Test RE 0.9132913592503094\n",
      "39 Train Loss 5.044077 Test MSE 3.1984255883066113 Test RE 0.8548229745479818\n",
      "40 Train Loss 3.1235728 Test MSE 2.174067046870214 Test RE 0.7047653227910817\n",
      "41 Train Loss 2.4806664 Test MSE 2.111675094868577 Test RE 0.6945789369318552\n",
      "42 Train Loss 1.7573427 Test MSE 1.351484897921867 Test RE 0.5556657885735389\n",
      "43 Train Loss 1.3384343 Test MSE 1.2835438465037372 Test RE 0.5415186454737582\n",
      "44 Train Loss 1.0747007 Test MSE 1.15879412311193 Test RE 0.5145305931101855\n",
      "45 Train Loss 0.9161087 Test MSE 1.0228244592971052 Test RE 0.4834021890729696\n",
      "46 Train Loss 0.75129575 Test MSE 0.8012115638604229 Test RE 0.42784027496224625\n",
      "47 Train Loss 0.6693108 Test MSE 0.7939091158733937 Test RE 0.42588608895244484\n",
      "48 Train Loss 0.5382361 Test MSE 0.7572602177896245 Test RE 0.4159399461847436\n",
      "49 Train Loss 0.43167117 Test MSE 0.7502733655669108 Test RE 0.4140166671903743\n",
      "50 Train Loss 0.36905694 Test MSE 0.7951784072260282 Test RE 0.42622640349614654\n",
      "51 Train Loss 0.32710811 Test MSE 0.8026010422798001 Test RE 0.42821109918725303\n",
      "52 Train Loss 0.29557645 Test MSE 0.857599869287554 Test RE 0.442639751465354\n",
      "53 Train Loss 0.26880816 Test MSE 0.8427293435026179 Test RE 0.43878534926138707\n",
      "54 Train Loss 0.23765512 Test MSE 0.8995394749301673 Test RE 0.45333387598097197\n",
      "55 Train Loss 0.21913826 Test MSE 0.8873946613376702 Test RE 0.4502632130180387\n",
      "56 Train Loss 0.1968942 Test MSE 0.901682467321206 Test RE 0.4538735483138844\n",
      "57 Train Loss 0.1803817 Test MSE 0.9424626526532709 Test RE 0.46402367030321784\n",
      "58 Train Loss 0.15746689 Test MSE 0.9131097600348613 Test RE 0.45674053127407943\n",
      "59 Train Loss 0.14088863 Test MSE 0.9361692139603079 Test RE 0.4624717806587047\n",
      "60 Train Loss 0.1258241 Test MSE 0.9479871214798453 Test RE 0.46538167565549393\n",
      "61 Train Loss 0.117750496 Test MSE 0.9162553259095909 Test RE 0.45752656614756354\n",
      "62 Train Loss 0.10961643 Test MSE 0.9443404583640467 Test RE 0.4644857112657279\n",
      "63 Train Loss 0.100113764 Test MSE 0.9388827771673917 Test RE 0.46314155184640243\n",
      "64 Train Loss 0.092971265 Test MSE 0.9257919120071372 Test RE 0.45990142099227527\n",
      "65 Train Loss 0.08791578 Test MSE 0.9181259033907739 Test RE 0.4579933588112282\n",
      "66 Train Loss 0.08516836 Test MSE 0.911979944944426 Test RE 0.4564578751842967\n",
      "67 Train Loss 0.07637719 Test MSE 0.8837228091264708 Test RE 0.44933070021075716\n",
      "68 Train Loss 0.072535336 Test MSE 0.8606640139373118 Test RE 0.44342980690492395\n",
      "69 Train Loss 0.06625514 Test MSE 0.859789322898414 Test RE 0.4432044212325426\n",
      "70 Train Loss 0.062385734 Test MSE 0.8637991753696079 Test RE 0.4442367189264262\n",
      "71 Train Loss 0.060155895 Test MSE 0.8559281477450648 Test RE 0.4422081216383043\n",
      "72 Train Loss 0.05579551 Test MSE 0.8678113745883219 Test RE 0.4452672254166497\n",
      "73 Train Loss 0.05186535 Test MSE 0.857920633984952 Test RE 0.4427225231267937\n",
      "74 Train Loss 0.048952617 Test MSE 0.8473781413790819 Test RE 0.4399939336348133\n",
      "75 Train Loss 0.046261318 Test MSE 0.8512016808866785 Test RE 0.4409854866492105\n",
      "76 Train Loss 0.044471305 Test MSE 0.8421856598932846 Test RE 0.43864378608143645\n",
      "77 Train Loss 0.04111387 Test MSE 0.8295838308080719 Test RE 0.43534965000994386\n",
      "78 Train Loss 0.039246224 Test MSE 0.8257513255694815 Test RE 0.4343428733443419\n",
      "79 Train Loss 0.036216605 Test MSE 0.8254010291169833 Test RE 0.43425073609770637\n",
      "80 Train Loss 0.033350155 Test MSE 0.8198278311222017 Test RE 0.43278219874309887\n",
      "81 Train Loss 0.031128943 Test MSE 0.821150131739943 Test RE 0.4331310754096666\n",
      "82 Train Loss 0.028736278 Test MSE 0.8247491913144875 Test RE 0.4340792334326001\n",
      "83 Train Loss 0.02605747 Test MSE 0.8081211207822947 Test RE 0.42968113744290026\n",
      "84 Train Loss 0.024973359 Test MSE 0.7994052004315091 Test RE 0.42735771133638023\n",
      "85 Train Loss 0.023090739 Test MSE 0.7858977461849344 Test RE 0.42373182341726046\n",
      "86 Train Loss 0.02157091 Test MSE 0.7589838985809988 Test RE 0.41641305976059595\n",
      "87 Train Loss 0.020692712 Test MSE 0.7564197976376612 Test RE 0.41570907352927183\n",
      "88 Train Loss 0.019743407 Test MSE 0.7617946282629822 Test RE 0.41718339424901996\n",
      "89 Train Loss 0.018925954 Test MSE 0.7567829900541337 Test RE 0.4158088622077048\n",
      "90 Train Loss 0.017975675 Test MSE 0.7382677356007902 Test RE 0.4106908288769188\n",
      "91 Train Loss 0.017497255 Test MSE 0.7290438425650898 Test RE 0.4081171859392924\n",
      "92 Train Loss 0.01702417 Test MSE 0.7237262286011079 Test RE 0.4066260674550024\n",
      "93 Train Loss 0.015915034 Test MSE 0.7210150241413936 Test RE 0.4058637067781051\n",
      "94 Train Loss 0.015251335 Test MSE 0.7188528662181319 Test RE 0.40525470400119784\n",
      "95 Train Loss 0.014889045 Test MSE 0.7147642229693768 Test RE 0.40410057026076557\n",
      "96 Train Loss 0.014484816 Test MSE 0.7122512986634 Test RE 0.40338958877884207\n",
      "97 Train Loss 0.013995568 Test MSE 0.7080279098749935 Test RE 0.40219183447396323\n",
      "98 Train Loss 0.013451653 Test MSE 0.696074946175171 Test RE 0.3987824723200723\n",
      "99 Train Loss 0.01294718 Test MSE 0.6916536323146671 Test RE 0.3975139658311346\n",
      "Training time: 79.47\n",
      "KG_stan_tune2\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.14604 Test MSE 7.441372301922689 Test RE 1.3038708525912222\n",
      "1 Train Loss 42.721035 Test MSE 8.721806356806932 Test RE 1.4115987995562806\n",
      "2 Train Loss 40.42357 Test MSE 9.318930394262408 Test RE 1.4591202818526667\n",
      "3 Train Loss 39.779465 Test MSE 9.346511491377422 Test RE 1.461277954621321\n",
      "4 Train Loss 39.10187 Test MSE 9.100140196691836 Test RE 1.4418899069553754\n",
      "5 Train Loss 38.293663 Test MSE 8.996288037850768 Test RE 1.4336387671294153\n",
      "6 Train Loss 37.541737 Test MSE 8.823464907878952 Test RE 1.4198015359822034\n",
      "7 Train Loss 36.495552 Test MSE 8.821508229017718 Test RE 1.4196441006823912\n",
      "8 Train Loss 35.32294 Test MSE 8.985704406385988 Test RE 1.43279522090758\n",
      "9 Train Loss 34.914867 Test MSE 9.086377592714422 Test RE 1.4407991727550913\n",
      "10 Train Loss 34.694862 Test MSE 8.965976898481195 Test RE 1.43122155408311\n",
      "11 Train Loss 34.271454 Test MSE 8.755853514136959 Test RE 1.414351332239022\n",
      "12 Train Loss 33.58927 Test MSE 7.751377900977892 Test RE 1.3307531887649957\n",
      "13 Train Loss 31.318539 Test MSE 7.358641112039315 Test RE 1.296602550409862\n",
      "14 Train Loss 29.050316 Test MSE 7.3708528740338615 Test RE 1.2976779689450602\n",
      "15 Train Loss 27.48832 Test MSE 7.440329947428442 Test RE 1.3037795291642165\n",
      "16 Train Loss 26.562073 Test MSE 7.157196586864605 Test RE 1.2787319997504183\n",
      "17 Train Loss 25.07396 Test MSE 7.385953612933937 Test RE 1.2990065716326742\n",
      "18 Train Loss 24.470665 Test MSE 7.451331805987088 Test RE 1.304743108699531\n",
      "19 Train Loss 23.99286 Test MSE 7.4686324147550325 Test RE 1.3062569161201962\n",
      "20 Train Loss 23.612642 Test MSE 7.478825428534219 Test RE 1.3071479865470077\n",
      "21 Train Loss 23.022783 Test MSE 7.699374673578301 Test RE 1.326281730763791\n",
      "22 Train Loss 22.520699 Test MSE 7.764275168583181 Test RE 1.3318598272795106\n",
      "23 Train Loss 22.145014 Test MSE 7.6214620816687715 Test RE 1.3195541197013283\n",
      "24 Train Loss 21.68134 Test MSE 7.630324749593379 Test RE 1.3203211229341876\n",
      "25 Train Loss 21.03355 Test MSE 7.388656406038843 Test RE 1.299244227123866\n",
      "26 Train Loss 20.165966 Test MSE 7.40646108379239 Test RE 1.3008087000421347\n",
      "27 Train Loss 19.322948 Test MSE 7.4082481108494385 Test RE 1.300965619798767\n",
      "28 Train Loss 18.548445 Test MSE 6.875971392253172 Test RE 1.2533578656025979\n",
      "29 Train Loss 17.096218 Test MSE 6.392505041216738 Test RE 1.2084914993239841\n",
      "30 Train Loss 14.143647 Test MSE 5.407122225523402 Test RE 1.1114531310814881\n",
      "31 Train Loss 13.441225 Test MSE 5.310609645029872 Test RE 1.1014892175878597\n",
      "32 Train Loss 12.769781 Test MSE 5.449771485354112 Test RE 1.115827874692953\n",
      "33 Train Loss 12.268586 Test MSE 5.446315661846959 Test RE 1.1154740327278074\n",
      "34 Train Loss 12.039803 Test MSE 5.407222439660281 Test RE 1.1114634307192146\n",
      "35 Train Loss 11.682074 Test MSE 5.506056804310859 Test RE 1.121575216393472\n",
      "36 Train Loss 11.490846 Test MSE 5.469884841654986 Test RE 1.1178850595017422\n",
      "37 Train Loss 11.200317 Test MSE 5.40348211694105 Test RE 1.111078949487469\n",
      "38 Train Loss 10.973077 Test MSE 5.437911199222968 Test RE 1.1146130305452653\n",
      "39 Train Loss 10.738581 Test MSE 5.491125825589058 Test RE 1.1200534754689508\n",
      "40 Train Loss 10.448545 Test MSE 5.574135736784797 Test RE 1.1284877012891295\n",
      "41 Train Loss 10.307121 Test MSE 5.529088947789856 Test RE 1.1239185742726727\n",
      "42 Train Loss 10.011296 Test MSE 5.47248583761253 Test RE 1.118150811801441\n",
      "43 Train Loss 9.876468 Test MSE 5.451915158661574 Test RE 1.1160473091465228\n",
      "44 Train Loss 9.587397 Test MSE 5.509173366073464 Test RE 1.1218925908838624\n",
      "45 Train Loss 9.329925 Test MSE 5.4661803072102755 Test RE 1.1175064459440247\n",
      "46 Train Loss 9.24874 Test MSE 5.469111377660772 Test RE 1.117806019957362\n",
      "47 Train Loss 9.123804 Test MSE 5.421787765988496 Test RE 1.1129593873336727\n",
      "48 Train Loss 9.073568 Test MSE 5.4098176139704846 Test RE 1.1117301198894298\n",
      "49 Train Loss 8.976957 Test MSE 5.422814240394031 Test RE 1.1130647372945937\n",
      "50 Train Loss 8.635638 Test MSE 5.379687141224876 Test RE 1.1086298558974979\n",
      "51 Train Loss 8.536539 Test MSE 5.362095442308864 Test RE 1.1068157492592552\n",
      "52 Train Loss 8.334342 Test MSE 5.4528280541344225 Test RE 1.1161407434590773\n",
      "53 Train Loss 8.100451 Test MSE 5.322920986072743 Test RE 1.1027652442652054\n",
      "54 Train Loss 7.840971 Test MSE 5.260326394134736 Test RE 1.0962621162960713\n",
      "55 Train Loss 6.710636 Test MSE 4.8616965691002685 Test RE 1.0539062626634537\n",
      "56 Train Loss 5.837903 Test MSE 4.639071987261255 Test RE 1.0294935171818351\n",
      "57 Train Loss 5.344284 Test MSE 4.672923289871332 Test RE 1.033242796459206\n",
      "58 Train Loss 4.9591646 Test MSE 4.475941302849854 Test RE 1.0112307132010006\n",
      "59 Train Loss 4.74872 Test MSE 4.486480816674286 Test RE 1.0124205873191214\n",
      "60 Train Loss 4.561345 Test MSE 4.413619064937247 Test RE 1.004165933419617\n",
      "61 Train Loss 4.3957343 Test MSE 4.41567937386376 Test RE 1.0044002819914835\n",
      "62 Train Loss 4.285301 Test MSE 4.427083712754577 Test RE 1.005696473799066\n",
      "63 Train Loss 4.1673193 Test MSE 4.466080500922734 Test RE 1.0101161941371757\n",
      "64 Train Loss 4.0915527 Test MSE 4.470986078984073 Test RE 1.010670801681574\n",
      "65 Train Loss 4.036991 Test MSE 4.492171568915804 Test RE 1.0130624722548565\n",
      "66 Train Loss 3.968484 Test MSE 4.5277968704405 Test RE 1.0170716005028515\n",
      "67 Train Loss 3.908512 Test MSE 4.56068963428276 Test RE 1.020759239144409\n",
      "68 Train Loss 3.8835523 Test MSE 4.565497870807468 Test RE 1.0212971796005974\n",
      "69 Train Loss 3.8331218 Test MSE 4.55729658898869 Test RE 1.020379458120317\n",
      "70 Train Loss 3.8101554 Test MSE 4.602940995351406 Test RE 1.0254766220901432\n",
      "71 Train Loss 3.78937 Test MSE 4.634078936861079 Test RE 1.0289393441800583\n",
      "72 Train Loss 3.765567 Test MSE 4.631571117664484 Test RE 1.0286608915386253\n",
      "73 Train Loss 3.7307134 Test MSE 4.608474591966217 Test RE 1.0260928443619117\n",
      "74 Train Loss 3.7100387 Test MSE 4.610377236331243 Test RE 1.026304637685979\n",
      "75 Train Loss 3.690329 Test MSE 4.612082419876679 Test RE 1.0264944134792346\n",
      "76 Train Loss 3.6674058 Test MSE 4.6182969635205104 Test RE 1.027185754861469\n",
      "77 Train Loss 3.65091 Test MSE 4.602777851317244 Test RE 1.0254584487227587\n",
      "78 Train Loss 3.628056 Test MSE 4.609136336105666 Test RE 1.0261665115308634\n",
      "79 Train Loss 3.613065 Test MSE 4.627754180625855 Test RE 1.028236937870817\n",
      "80 Train Loss 3.6030588 Test MSE 4.646879288560895 Test RE 1.0303594433029073\n",
      "81 Train Loss 3.589898 Test MSE 4.6753517959070585 Test RE 1.033511248377387\n",
      "82 Train Loss 3.5738783 Test MSE 4.670080278680799 Test RE 1.0329284356635922\n",
      "83 Train Loss 3.563324 Test MSE 4.644196711450905 Test RE 1.0300619944659222\n",
      "84 Train Loss 3.5450764 Test MSE 4.642913182368482 Test RE 1.0299196441338352\n",
      "85 Train Loss 3.533502 Test MSE 4.637391596419566 Test RE 1.029307045817608\n",
      "86 Train Loss 3.5218306 Test MSE 4.618135080691091 Test RE 1.0271677519921387\n",
      "87 Train Loss 3.51648 Test MSE 4.624830614019299 Test RE 1.027912094114641\n",
      "88 Train Loss 3.5096912 Test MSE 4.6245557392064995 Test RE 1.027881546904763\n",
      "89 Train Loss 3.5033472 Test MSE 4.616062970856715 Test RE 1.0269372863209159\n",
      "90 Train Loss 3.4948506 Test MSE 4.625236183208038 Test RE 1.0279571639095844\n",
      "91 Train Loss 3.4867086 Test MSE 4.621856297038609 Test RE 1.0275815059950555\n",
      "92 Train Loss 3.4782305 Test MSE 4.611295527956104 Test RE 1.0264068419071013\n",
      "93 Train Loss 3.4697843 Test MSE 4.624840408242874 Test RE 1.0279131825432102\n",
      "94 Train Loss 3.4631746 Test MSE 4.6169356963073485 Test RE 1.027034359514513\n",
      "95 Train Loss 3.4578013 Test MSE 4.6049850048249 Test RE 1.0257042864556307\n",
      "96 Train Loss 3.4507895 Test MSE 4.629166442392067 Test RE 1.028393820549329\n",
      "97 Train Loss 3.4413345 Test MSE 4.636105106480046 Test RE 1.0291642624249768\n",
      "98 Train Loss 3.434527 Test MSE 4.62070805753284 Test RE 1.0274538535003526\n",
      "99 Train Loss 3.4289827 Test MSE 4.631815712541146 Test RE 1.0286880531492049\n",
      "Training time: 79.27\n",
      "KG_stan_tune2\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.862053 Test MSE 8.791348041639731 Test RE 1.4172151854331672\n",
      "1 Train Loss 51.268806 Test MSE 8.423461623265714 Test RE 1.3872456161616784\n",
      "2 Train Loss 47.386917 Test MSE 9.187404644222442 Test RE 1.4487868071300505\n",
      "3 Train Loss 46.13346 Test MSE 8.977517627574866 Test RE 1.432142370000932\n",
      "4 Train Loss 44.65039 Test MSE 8.527441155576433 Test RE 1.3957814617140667\n",
      "5 Train Loss 44.407555 Test MSE 8.672231810187427 Test RE 1.407581335081107\n",
      "6 Train Loss 43.911545 Test MSE 8.59053085171465 Test RE 1.4009352441325693\n",
      "7 Train Loss 43.526695 Test MSE 8.530849992534057 Test RE 1.396060415033062\n",
      "8 Train Loss 43.404007 Test MSE 8.444037978533736 Test RE 1.3889389252476074\n",
      "9 Train Loss 43.1819 Test MSE 8.291517875644228 Test RE 1.3763379374720015\n",
      "10 Train Loss 43.05699 Test MSE 8.429711297285007 Test RE 1.3877601448526844\n",
      "11 Train Loss 42.88956 Test MSE 8.324048507878581 Test RE 1.3790352309327225\n",
      "12 Train Loss 42.681633 Test MSE 8.535563205892277 Test RE 1.3964460168204869\n",
      "13 Train Loss 42.321 Test MSE 8.393738328265089 Test RE 1.3847959136924906\n",
      "14 Train Loss 40.91674 Test MSE 8.590104720563753 Test RE 1.40090049717911\n",
      "15 Train Loss 39.27965 Test MSE 7.9187806285024775 Test RE 1.3450462446858609\n",
      "16 Train Loss 38.648697 Test MSE 8.017447435925398 Test RE 1.3533998403638716\n",
      "17 Train Loss 38.27459 Test MSE 8.036226460174326 Test RE 1.354983927039966\n",
      "18 Train Loss 37.779167 Test MSE 8.041649564264288 Test RE 1.3554410433014026\n",
      "19 Train Loss 37.290894 Test MSE 7.713014110768013 Test RE 1.3274559645638402\n",
      "20 Train Loss 36.176933 Test MSE 7.789186459202997 Test RE 1.333994719226327\n",
      "21 Train Loss 35.42426 Test MSE 7.873162383040229 Test RE 1.3411664002819395\n",
      "22 Train Loss 34.483788 Test MSE 7.594902377610427 Test RE 1.317252884500906\n",
      "23 Train Loss 32.76847 Test MSE 7.849394721884702 Test RE 1.339140500100097\n",
      "24 Train Loss 30.355389 Test MSE 7.396083885597728 Test RE 1.2998970985948788\n",
      "25 Train Loss 28.591633 Test MSE 7.236599327517359 Test RE 1.2858056329660879\n",
      "26 Train Loss 26.649078 Test MSE 6.948497465775377 Test RE 1.259950583538776\n",
      "27 Train Loss 25.002914 Test MSE 6.681776864134989 Test RE 1.2355321322155495\n",
      "28 Train Loss 22.808449 Test MSE 5.774036001940629 Test RE 1.1485444405979939\n",
      "29 Train Loss 18.816574 Test MSE 5.53050697823874 Test RE 1.1240626892075474\n",
      "30 Train Loss 16.610521 Test MSE 4.95511207869389 Test RE 1.0639832752920575\n",
      "31 Train Loss 14.624907 Test MSE 4.753102064365898 Test RE 1.0420693691574365\n",
      "32 Train Loss 13.577901 Test MSE 4.606061278146791 Test RE 1.0258241428355277\n",
      "33 Train Loss 11.985096 Test MSE 4.331917847310276 Test RE 0.9948283801829242\n",
      "34 Train Loss 9.647826 Test MSE 4.221384351137393 Test RE 0.9820543150056111\n",
      "35 Train Loss 8.890533 Test MSE 3.6300354186687205 Test RE 0.9106751617188871\n",
      "36 Train Loss 8.49346 Test MSE 3.7816755335519447 Test RE 0.929501708068151\n",
      "37 Train Loss 8.087688 Test MSE 3.6813028599949007 Test RE 0.9170834041860725\n",
      "38 Train Loss 7.4943542 Test MSE 3.584159661646678 Test RE 0.9049023876511173\n",
      "39 Train Loss 7.1936297 Test MSE 3.6131226638888125 Test RE 0.908551214458766\n",
      "40 Train Loss 6.747652 Test MSE 3.372599106387042 Test RE 0.8777895788551264\n",
      "41 Train Loss 6.434578 Test MSE 3.367058538946677 Test RE 0.8770682581035159\n",
      "42 Train Loss 5.883354 Test MSE 3.203062164430046 Test RE 0.8554423443483024\n",
      "43 Train Loss 5.3932743 Test MSE 3.167923738743712 Test RE 0.8507371919830948\n",
      "44 Train Loss 4.628461 Test MSE 3.022072787636612 Test RE 0.8309225025019157\n",
      "45 Train Loss 3.8702805 Test MSE 2.84279297165748 Test RE 0.8058991112024153\n",
      "46 Train Loss 3.2695627 Test MSE 2.570335199773052 Test RE 0.7663072636668778\n",
      "47 Train Loss 2.867375 Test MSE 2.324341822238471 Test RE 0.728715586220683\n",
      "48 Train Loss 2.6314492 Test MSE 2.3839767188890675 Test RE 0.7380045939477802\n",
      "49 Train Loss 2.3745182 Test MSE 2.3708090272059383 Test RE 0.735963619103717\n",
      "50 Train Loss 2.1907213 Test MSE 2.312544101212653 Test RE 0.7268638533729616\n",
      "51 Train Loss 2.0367818 Test MSE 2.2827912196353815 Test RE 0.7221728497513166\n",
      "52 Train Loss 1.9142227 Test MSE 2.2033672758206975 Test RE 0.7094985427720052\n",
      "53 Train Loss 1.7785399 Test MSE 2.3398160367845895 Test RE 0.7311372600785404\n",
      "54 Train Loss 1.7131121 Test MSE 2.3990396142181547 Test RE 0.7403324232308649\n",
      "55 Train Loss 1.6314338 Test MSE 2.387427878537145 Test RE 0.7385385862769434\n",
      "56 Train Loss 1.5607505 Test MSE 2.4121376068633062 Test RE 0.7423506619316546\n",
      "57 Train Loss 1.4809718 Test MSE 2.4000217684535152 Test RE 0.7404839518292524\n",
      "58 Train Loss 1.4153538 Test MSE 2.4041403956202534 Test RE 0.7411190439911872\n",
      "59 Train Loss 1.3525428 Test MSE 2.4473421014920853 Test RE 0.7477482425713391\n",
      "60 Train Loss 1.2531433 Test MSE 2.5101645249570863 Test RE 0.7572846503828181\n",
      "61 Train Loss 1.1901 Test MSE 2.5138651764078856 Test RE 0.757842664486012\n",
      "62 Train Loss 1.1541315 Test MSE 2.5247658538531943 Test RE 0.7594839741513697\n",
      "63 Train Loss 1.1108372 Test MSE 2.5475213262560805 Test RE 0.7628988749631613\n",
      "64 Train Loss 1.0865356 Test MSE 2.599581598869783 Test RE 0.770654621862853\n",
      "65 Train Loss 1.0449934 Test MSE 2.5970118173205243 Test RE 0.7702736175314309\n",
      "66 Train Loss 1.0151459 Test MSE 2.5625715907305504 Test RE 0.7651490860834547\n",
      "67 Train Loss 1.0042586 Test MSE 2.5803151362139087 Test RE 0.7677935073020822\n",
      "68 Train Loss 0.98673475 Test MSE 2.6032586948294103 Test RE 0.7711994729297917\n",
      "69 Train Loss 0.9722513 Test MSE 2.60060283001819 Test RE 0.7708059806865706\n",
      "70 Train Loss 0.94757736 Test MSE 2.6069292016008583 Test RE 0.7717429640166809\n",
      "71 Train Loss 0.93593705 Test MSE 2.597611411621752 Test RE 0.7703625322243761\n",
      "72 Train Loss 0.91960984 Test MSE 2.645582319936022 Test RE 0.7774432550804955\n",
      "73 Train Loss 0.90434813 Test MSE 2.668839419687241 Test RE 0.7808529981059513\n",
      "74 Train Loss 0.89566135 Test MSE 2.64738390738367 Test RE 0.7777079215075758\n",
      "75 Train Loss 0.88188434 Test MSE 2.6615739693586478 Test RE 0.7797894056316133\n",
      "76 Train Loss 0.8712488 Test MSE 2.6654357420920842 Test RE 0.7803549127272263\n",
      "77 Train Loss 0.85755336 Test MSE 2.686504938232549 Test RE 0.7834330375300271\n",
      "78 Train Loss 0.8457383 Test MSE 2.699730396326658 Test RE 0.7853590604508972\n",
      "79 Train Loss 0.8381008 Test MSE 2.702714157121143 Test RE 0.7857929327498728\n",
      "80 Train Loss 0.8249271 Test MSE 2.7408719138671507 Test RE 0.7913205252373398\n",
      "81 Train Loss 0.81149304 Test MSE 2.7552165348378126 Test RE 0.793388549610682\n",
      "82 Train Loss 0.7930556 Test MSE 2.780859005914573 Test RE 0.7970719853508373\n",
      "83 Train Loss 0.7782327 Test MSE 2.7704033736960394 Test RE 0.7955721358737282\n",
      "84 Train Loss 0.76006407 Test MSE 2.7730230719878977 Test RE 0.7959481941982844\n",
      "85 Train Loss 0.7493841 Test MSE 2.781034714501701 Test RE 0.7970971664513276\n",
      "86 Train Loss 0.7263181 Test MSE 2.7744464115569896 Test RE 0.7961524404654614\n",
      "87 Train Loss 0.7083934 Test MSE 2.786883313957652 Test RE 0.7979348858752676\n",
      "88 Train Loss 0.69994706 Test MSE 2.797862972386335 Test RE 0.7995051777298703\n",
      "89 Train Loss 0.6893055 Test MSE 2.8009439297218424 Test RE 0.7999452571083175\n",
      "90 Train Loss 0.67971957 Test MSE 2.8099825973801194 Test RE 0.8012349322548272\n",
      "91 Train Loss 0.66981757 Test MSE 2.8446668128809507 Test RE 0.8061646736653918\n",
      "92 Train Loss 0.66032964 Test MSE 2.8513947703544202 Test RE 0.8071174457799017\n",
      "93 Train Loss 0.65006363 Test MSE 2.843240335735021 Test RE 0.8059625199932097\n",
      "94 Train Loss 0.6398009 Test MSE 2.866615280254242 Test RE 0.809268741889329\n",
      "95 Train Loss 0.6337235 Test MSE 2.8639105978214605 Test RE 0.8088868749012811\n",
      "96 Train Loss 0.6286475 Test MSE 2.8564851909349196 Test RE 0.8078375732138723\n",
      "97 Train Loss 0.6234036 Test MSE 2.8656882461248845 Test RE 0.8091378766818691\n",
      "98 Train Loss 0.6175649 Test MSE 2.8869917437988493 Test RE 0.8121398692458875\n",
      "99 Train Loss 0.6123821 Test MSE 2.9129471156624915 Test RE 0.8157824542666706\n",
      "Training time: 79.56\n",
      "KG_stan_tune3\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.366604 Test MSE 7.998200455795127 Test RE 1.3517743534304723\n",
      "1 Train Loss 48.637444 Test MSE 9.31996219427902 Test RE 1.459201057145352\n",
      "2 Train Loss 45.002693 Test MSE 8.68754210964881 Test RE 1.4088232869276978\n",
      "3 Train Loss 43.977825 Test MSE 8.390672296075904 Test RE 1.384542974151336\n",
      "4 Train Loss 43.640297 Test MSE 8.671803797174544 Test RE 1.4075465994689231\n",
      "5 Train Loss 43.236343 Test MSE 8.790687809369292 Test RE 1.4171619678399456\n",
      "6 Train Loss 42.75566 Test MSE 8.683092188393514 Test RE 1.4084624279177353\n",
      "7 Train Loss 42.52025 Test MSE 8.834283046169942 Test RE 1.4206716535855362\n",
      "8 Train Loss 42.136524 Test MSE 8.889281681992346 Test RE 1.42508705268584\n",
      "9 Train Loss 42.02324 Test MSE 8.950711287264744 Test RE 1.4300026250211182\n",
      "10 Train Loss 41.891506 Test MSE 8.957659876701998 Test RE 1.4305575850179328\n",
      "11 Train Loss 41.51416 Test MSE 8.882893380839066 Test RE 1.4245748897345725\n",
      "12 Train Loss 41.05889 Test MSE 8.868244599628627 Test RE 1.4233997716982834\n",
      "13 Train Loss 40.485634 Test MSE 8.819133261300962 Test RE 1.4194529862050533\n",
      "14 Train Loss 39.10501 Test MSE 8.662772412156219 Test RE 1.406813452877081\n",
      "15 Train Loss 38.065586 Test MSE 8.21844977319644 Test RE 1.3702601033411599\n",
      "16 Train Loss 36.659904 Test MSE 8.166163026844416 Test RE 1.3658942701143129\n",
      "17 Train Loss 32.820908 Test MSE 6.406406660167115 Test RE 1.2098048236397723\n",
      "18 Train Loss 29.313643 Test MSE 6.321525839076918 Test RE 1.2017635263739397\n",
      "19 Train Loss 27.617367 Test MSE 6.2959410264809925 Test RE 1.1993291403871944\n",
      "20 Train Loss 25.70401 Test MSE 6.313653309987649 Test RE 1.201014983542569\n",
      "21 Train Loss 24.507687 Test MSE 6.135438012583141 Test RE 1.1839431431496208\n",
      "22 Train Loss 22.506102 Test MSE 6.038624374205254 Test RE 1.1745650341535807\n",
      "23 Train Loss 21.304945 Test MSE 6.149813822007087 Test RE 1.1853293671440324\n",
      "24 Train Loss 20.051838 Test MSE 6.127356013202883 Test RE 1.1831631025957157\n",
      "25 Train Loss 18.411812 Test MSE 5.678889449247135 Test RE 1.1390420768722918\n",
      "26 Train Loss 16.994835 Test MSE 5.613779413761365 Test RE 1.1324935366033717\n",
      "27 Train Loss 15.710614 Test MSE 5.785469447602723 Test RE 1.1496810221969849\n",
      "28 Train Loss 14.179442 Test MSE 5.416533601604593 Test RE 1.1124199814003062\n",
      "29 Train Loss 12.884941 Test MSE 5.622766759345632 Test RE 1.133399703344809\n",
      "30 Train Loss 11.985975 Test MSE 5.659439098415352 Test RE 1.1370897787220415\n",
      "31 Train Loss 11.262085 Test MSE 5.584644409444995 Test RE 1.1295509444901233\n",
      "32 Train Loss 10.63361 Test MSE 5.5085373427592454 Test RE 1.1218278288594983\n",
      "33 Train Loss 9.769108 Test MSE 4.847332713293718 Test RE 1.052348230881306\n",
      "34 Train Loss 8.742517 Test MSE 4.516558993060919 Test RE 1.0158086433575202\n",
      "35 Train Loss 8.1301565 Test MSE 4.29520864801512 Test RE 0.9906042638121954\n",
      "36 Train Loss 7.073101 Test MSE 4.164935774746783 Test RE 0.9754661753391015\n",
      "37 Train Loss 6.8271027 Test MSE 4.184464887700299 Test RE 0.9777504494925454\n",
      "38 Train Loss 6.3122473 Test MSE 3.88927011083074 Test RE 0.9426318576684091\n",
      "39 Train Loss 5.492555 Test MSE 3.368374238259635 Test RE 0.8772396013374067\n",
      "40 Train Loss 5.051785 Test MSE 3.350121095637374 Test RE 0.8748595019069273\n",
      "41 Train Loss 4.2477484 Test MSE 3.1405830680713063 Test RE 0.8470581058299306\n",
      "42 Train Loss 3.612112 Test MSE 3.068900348863322 Test RE 0.837335402527493\n",
      "43 Train Loss 3.2672992 Test MSE 2.9513463980884453 Test RE 0.821141786115031\n",
      "44 Train Loss 3.0591323 Test MSE 3.029704982922094 Test RE 0.8319710814566775\n",
      "45 Train Loss 2.7138171 Test MSE 2.9069835073312764 Test RE 0.8149469602801179\n",
      "46 Train Loss 2.4552274 Test MSE 2.828807774055478 Test RE 0.8039143458309752\n",
      "47 Train Loss 2.19683 Test MSE 2.7580824752989304 Test RE 0.79380107859504\n",
      "48 Train Loss 2.0402107 Test MSE 2.7800673961911184 Test RE 0.7969585285300291\n",
      "49 Train Loss 1.7735224 Test MSE 2.660489290526475 Test RE 0.7796304945391331\n",
      "50 Train Loss 1.6235307 Test MSE 2.5799168556858247 Test RE 0.7677342492292247\n",
      "51 Train Loss 1.4401301 Test MSE 2.4840982659088247 Test RE 0.7533424603735253\n",
      "52 Train Loss 1.304101 Test MSE 2.629059252725933 Test RE 0.775011679418105\n",
      "53 Train Loss 1.1945615 Test MSE 2.651049505591457 Test RE 0.7782461469303168\n",
      "54 Train Loss 1.105362 Test MSE 2.6624721631475157 Test RE 0.7799209711879584\n",
      "55 Train Loss 1.0405245 Test MSE 2.72943599703986 Test RE 0.7896679608040464\n",
      "56 Train Loss 0.9579442 Test MSE 2.7938093020717236 Test RE 0.7989257881761076\n",
      "57 Train Loss 0.90541375 Test MSE 2.797647091452454 Test RE 0.7994743325355872\n",
      "58 Train Loss 0.8624041 Test MSE 2.822758795521188 Test RE 0.8030543610924339\n",
      "59 Train Loss 0.8297805 Test MSE 2.86476416303752 Test RE 0.8090074069918258\n",
      "60 Train Loss 0.7964543 Test MSE 2.8997231534585635 Test RE 0.813928636249096\n",
      "61 Train Loss 0.7686951 Test MSE 2.909196348852853 Test RE 0.815257076490496\n",
      "62 Train Loss 0.74736273 Test MSE 2.942500477492856 Test RE 0.819910279363497\n",
      "63 Train Loss 0.7324969 Test MSE 2.947431981277828 Test RE 0.820597058848845\n",
      "64 Train Loss 0.7179658 Test MSE 2.9516073201280846 Test RE 0.8211780829818753\n",
      "65 Train Loss 0.7000903 Test MSE 3.0048365579553518 Test RE 0.8285495532547852\n",
      "66 Train Loss 0.6793386 Test MSE 2.9966104548762122 Test RE 0.8274146487400815\n",
      "67 Train Loss 0.6567891 Test MSE 2.993971550505196 Test RE 0.8270502455110617\n",
      "68 Train Loss 0.6384115 Test MSE 2.985976834634798 Test RE 0.8259452831735272\n",
      "69 Train Loss 0.6191046 Test MSE 3.011966516894193 Test RE 0.8295319734209137\n",
      "70 Train Loss 0.60137296 Test MSE 3.0421074101624916 Test RE 0.8336722243873025\n",
      "71 Train Loss 0.5873803 Test MSE 3.0420456785203376 Test RE 0.833663765741769\n",
      "72 Train Loss 0.57651174 Test MSE 3.0668057880569624 Test RE 0.8370496080939009\n",
      "73 Train Loss 0.56059176 Test MSE 3.0644268592771544 Test RE 0.8367248943932662\n",
      "74 Train Loss 0.5503871 Test MSE 3.0545048686006067 Test RE 0.8353692236738405\n",
      "75 Train Loss 0.53553975 Test MSE 3.08146402723472 Test RE 0.8390476229621907\n",
      "76 Train Loss 0.525158 Test MSE 3.0905370164605084 Test RE 0.8402819509584353\n",
      "77 Train Loss 0.5177773 Test MSE 3.0885969197661747 Test RE 0.8400181644138071\n",
      "78 Train Loss 0.5106682 Test MSE 3.0944566981827024 Test RE 0.840814640606059\n",
      "79 Train Loss 0.5004212 Test MSE 3.1131282552707797 Test RE 0.8433475097570131\n",
      "80 Train Loss 0.48913106 Test MSE 3.141908156684314 Test RE 0.8472367842244193\n",
      "81 Train Loss 0.47654355 Test MSE 3.149180757423083 Test RE 0.8482167704447757\n",
      "82 Train Loss 0.47130156 Test MSE 3.135891116203438 Test RE 0.8464251276086298\n",
      "83 Train Loss 0.46153444 Test MSE 3.150787575950823 Test RE 0.848433137290362\n",
      "84 Train Loss 0.45268396 Test MSE 3.2033484172134683 Test RE 0.8554805682835285\n",
      "85 Train Loss 0.44532403 Test MSE 3.2022352317601164 Test RE 0.8553319126975594\n",
      "86 Train Loss 0.4357494 Test MSE 3.1944284479661222 Test RE 0.854288662353524\n",
      "87 Train Loss 0.4269373 Test MSE 3.2128731358298293 Test RE 0.8567514515475052\n",
      "88 Train Loss 0.42244664 Test MSE 3.2100413761915205 Test RE 0.8563738068514124\n",
      "89 Train Loss 0.419516 Test MSE 3.2192192505095343 Test RE 0.8575971682238394\n",
      "90 Train Loss 0.41496664 Test MSE 3.222225293777144 Test RE 0.8579974784324315\n",
      "91 Train Loss 0.40950316 Test MSE 3.224585773484373 Test RE 0.85831168905957\n",
      "92 Train Loss 0.40252036 Test MSE 3.242396599400472 Test RE 0.8606788440500697\n",
      "93 Train Loss 0.39897826 Test MSE 3.247657468191982 Test RE 0.8613767974242119\n",
      "94 Train Loss 0.39560416 Test MSE 3.2444919422399012 Test RE 0.8609568985592785\n",
      "95 Train Loss 0.3896124 Test MSE 3.2518092752469934 Test RE 0.8619272138479159\n",
      "96 Train Loss 0.38239932 Test MSE 3.2788304921638844 Test RE 0.865500938034248\n",
      "97 Train Loss 0.37849832 Test MSE 3.29053392582455 Test RE 0.8670442184874183\n",
      "98 Train Loss 0.37418455 Test MSE 3.2883307134592115 Test RE 0.866753900494019\n",
      "99 Train Loss 0.36918288 Test MSE 3.2999885954564614 Test RE 0.8682889612452386\n",
      "Training time: 79.76\n",
      "KG_stan_tune3\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.326965 Test MSE 8.718683329587998 Test RE 1.4113460505270514\n",
      "1 Train Loss 50.328392 Test MSE 8.742877301071717 Test RE 1.413302906233017\n",
      "2 Train Loss 45.767986 Test MSE 7.773601183485508 Test RE 1.3326594651548467\n",
      "3 Train Loss 42.07973 Test MSE 8.159514306873374 Test RE 1.3653381155459643\n",
      "4 Train Loss 39.37345 Test MSE 8.001996387016673 Test RE 1.3520950901903153\n",
      "5 Train Loss 34.56125 Test MSE 6.905242688028993 Test RE 1.2560228306408547\n",
      "6 Train Loss 33.296024 Test MSE 6.708651493487418 Test RE 1.2380143422634424\n",
      "7 Train Loss 31.700369 Test MSE 5.661294543779067 Test RE 1.1372761607136792\n",
      "8 Train Loss 26.975616 Test MSE 5.066211894709284 Test RE 1.0758450732799287\n",
      "9 Train Loss 22.661987 Test MSE 4.499512775898627 Test RE 1.0138899189799346\n",
      "10 Train Loss 19.679535 Test MSE 5.16764278865571 Test RE 1.0865614759921005\n",
      "11 Train Loss 17.05537 Test MSE 5.700782158027325 Test RE 1.1412355276786657\n",
      "12 Train Loss 14.996389 Test MSE 5.59138427231521 Test RE 1.1302323417594136\n",
      "13 Train Loss 13.846488 Test MSE 5.972373720256477 Test RE 1.168104099708585\n",
      "14 Train Loss 12.928699 Test MSE 5.958245857228095 Test RE 1.1667216857341316\n",
      "15 Train Loss 12.49571 Test MSE 5.937894609800667 Test RE 1.1647274283263598\n",
      "16 Train Loss 12.250479 Test MSE 5.952591238316548 Test RE 1.1661679210269824\n",
      "17 Train Loss 11.993805 Test MSE 5.9179032718018005 Test RE 1.1627651089809103\n",
      "18 Train Loss 11.811217 Test MSE 5.922963145290233 Test RE 1.1632620913590186\n",
      "19 Train Loss 11.695168 Test MSE 5.9420711467472005 Test RE 1.1651369734906587\n",
      "20 Train Loss 11.556845 Test MSE 5.980553352994058 Test RE 1.1689037309570867\n",
      "21 Train Loss 11.4738455 Test MSE 5.961601288678496 Test RE 1.1670501635879393\n",
      "22 Train Loss 11.375534 Test MSE 5.976942481344329 Test RE 1.168550803863418\n",
      "23 Train Loss 11.312165 Test MSE 5.9510051726816275 Test RE 1.1660125481806025\n",
      "24 Train Loss 11.235884 Test MSE 5.945285552226549 Test RE 1.1654520754319746\n",
      "25 Train Loss 11.189108 Test MSE 5.934234914271484 Test RE 1.164368445469006\n",
      "26 Train Loss 11.132719 Test MSE 5.923251625675763 Test RE 1.163290419596282\n",
      "27 Train Loss 11.091419 Test MSE 5.930356318527903 Test RE 1.163987869646484\n",
      "28 Train Loss 11.027005 Test MSE 5.911353893755441 Test RE 1.162121511401384\n",
      "29 Train Loss 10.995631 Test MSE 5.9099854144792126 Test RE 1.161986987966906\n",
      "30 Train Loss 10.944593 Test MSE 5.87566327328467 Test RE 1.1586079649444507\n",
      "31 Train Loss 10.86259 Test MSE 5.806223853557055 Test RE 1.1517413204904157\n",
      "32 Train Loss 10.772567 Test MSE 5.838949589235562 Test RE 1.1549825510791591\n",
      "33 Train Loss 10.672366 Test MSE 5.8055152658769105 Test RE 1.1516710394754317\n",
      "34 Train Loss 10.575523 Test MSE 5.775505202022963 Test RE 1.148690554534385\n",
      "35 Train Loss 10.2578125 Test MSE 5.297407823795185 Test RE 1.1001192512970526\n",
      "36 Train Loss 9.198571 Test MSE 4.604660739121786 Test RE 1.0256681727031849\n",
      "37 Train Loss 8.774023 Test MSE 4.589045278299275 Test RE 1.02392755771872\n",
      "38 Train Loss 8.324232 Test MSE 4.26776483768194 Test RE 0.9874345085635727\n",
      "39 Train Loss 7.8494973 Test MSE 4.293829228859083 Test RE 0.9904451832717928\n",
      "40 Train Loss 7.6108637 Test MSE 4.236998649416231 Test RE 0.9838688779828552\n",
      "41 Train Loss 7.5100217 Test MSE 4.2471174949977035 Test RE 0.9850430204751316\n",
      "42 Train Loss 7.430806 Test MSE 4.239132322521967 Test RE 0.9841165757659338\n",
      "43 Train Loss 7.3488555 Test MSE 4.217957495176752 Test RE 0.9816556256578477\n",
      "44 Train Loss 7.230411 Test MSE 4.199864813557966 Test RE 0.9795479859255811\n",
      "45 Train Loss 7.052472 Test MSE 4.186406334714907 Test RE 0.9779772443889694\n",
      "46 Train Loss 6.812389 Test MSE 4.147452927609463 Test RE 0.9734167007349281\n",
      "47 Train Loss 6.5244827 Test MSE 4.167162074395491 Test RE 0.9757268504118125\n",
      "48 Train Loss 6.2030554 Test MSE 4.1551794288624695 Test RE 0.9743229926067875\n",
      "49 Train Loss 5.442054 Test MSE 4.011435433681398 Test RE 0.9573218325132676\n",
      "50 Train Loss 4.7517843 Test MSE 3.711885586107783 Test RE 0.920884898092572\n",
      "51 Train Loss 4.0779905 Test MSE 3.5591457182415653 Test RE 0.9017391903413337\n",
      "52 Train Loss 3.5823627 Test MSE 3.3561942670610962 Test RE 0.8756521248894014\n",
      "53 Train Loss 3.2305508 Test MSE 3.307784438526945 Test RE 0.8693139725792403\n",
      "54 Train Loss 2.9875603 Test MSE 3.271280017280188 Test RE 0.8645038279965632\n",
      "55 Train Loss 2.7261553 Test MSE 3.0699696137600774 Test RE 0.8374812618380986\n",
      "56 Train Loss 2.5156918 Test MSE 2.9870601798756873 Test RE 0.8260951006029099\n",
      "57 Train Loss 2.3247025 Test MSE 2.8382402952568535 Test RE 0.8052535369316789\n",
      "58 Train Loss 2.0807261 Test MSE 2.5853414329446482 Test RE 0.7685409509802824\n",
      "59 Train Loss 1.8400654 Test MSE 2.189585797656454 Test RE 0.7072761996361762\n",
      "60 Train Loss 1.6882033 Test MSE 1.9400458114921804 Test RE 0.6657544115657132\n",
      "61 Train Loss 1.5377355 Test MSE 1.6535028923633215 Test RE 0.6146254506762092\n",
      "62 Train Loss 1.3753982 Test MSE 1.3731908636982564 Test RE 0.5601102404442753\n",
      "63 Train Loss 1.1335201 Test MSE 0.8916199300600498 Test RE 0.45133388872381064\n",
      "64 Train Loss 0.7842381 Test MSE 0.3954539973434322 Test RE 0.3005772074080074\n",
      "65 Train Loss 0.5659765 Test MSE 0.25640657011981954 Test RE 0.24203191382271727\n",
      "66 Train Loss 0.44173828 Test MSE 0.23493702982780876 Test RE 0.2316774675170968\n",
      "67 Train Loss 0.33641303 Test MSE 0.1877536768846588 Test RE 0.20711058037794258\n",
      "68 Train Loss 0.27960572 Test MSE 0.14545533142146294 Test RE 0.18229421314994065\n",
      "69 Train Loss 0.21722934 Test MSE 0.09607259164475089 Test RE 0.14815210055684794\n",
      "70 Train Loss 0.18518597 Test MSE 0.06802294513591821 Test RE 0.12466248389283463\n",
      "71 Train Loss 0.13624212 Test MSE 0.039991382809748094 Test RE 0.09558533595804752\n",
      "72 Train Loss 0.104337856 Test MSE 0.03281546470114669 Test RE 0.08658593272345838\n",
      "73 Train Loss 0.08152464 Test MSE 0.026760117014405307 Test RE 0.07819015325362663\n",
      "74 Train Loss 0.06574698 Test MSE 0.019311217551204546 Test RE 0.0664221437983636\n",
      "75 Train Loss 0.050136384 Test MSE 0.01770398276767712 Test RE 0.06359801332643697\n",
      "76 Train Loss 0.04036844 Test MSE 0.015148419446538197 Test RE 0.05882903455212544\n",
      "77 Train Loss 0.03664417 Test MSE 0.014104800029264855 Test RE 0.0567664227230122\n",
      "78 Train Loss 0.030864257 Test MSE 0.012128405814180393 Test RE 0.05263927756180967\n",
      "79 Train Loss 0.027237885 Test MSE 0.00996698130135499 Test RE 0.04771884046062871\n",
      "80 Train Loss 0.024417415 Test MSE 0.007958557608124455 Test RE 0.04264079002047922\n",
      "81 Train Loss 0.021957852 Test MSE 0.006953133086680499 Test RE 0.03985642409219119\n",
      "82 Train Loss 0.01881524 Test MSE 0.005522266651011276 Test RE 0.03551949208992209\n",
      "83 Train Loss 0.017204218 Test MSE 0.0051694626186127935 Test RE 0.034366140387835184\n",
      "84 Train Loss 0.015728544 Test MSE 0.005155017901532599 Test RE 0.034318093185586075\n",
      "85 Train Loss 0.01379337 Test MSE 0.003418622905843917 Test RE 0.02794690118742286\n",
      "86 Train Loss 0.012237439 Test MSE 0.0024160823096849365 Test RE 0.023494376442459927\n",
      "87 Train Loss 0.011113677 Test MSE 0.002648057102320231 Test RE 0.02459641053888301\n",
      "88 Train Loss 0.010493368 Test MSE 0.0023420165173168067 Test RE 0.023131459567932038\n",
      "89 Train Loss 0.009726709 Test MSE 0.0020748536698914554 Test RE 0.021772174022463862\n",
      "90 Train Loss 0.00876924 Test MSE 0.0022182815278917883 Test RE 0.02251211982223413\n",
      "91 Train Loss 0.008204904 Test MSE 0.0022612448365299277 Test RE 0.02272907984971641\n",
      "92 Train Loss 0.007545018 Test MSE 0.002035394550374511 Test RE 0.021564150986105837\n",
      "93 Train Loss 0.007110739 Test MSE 0.0016958997605901708 Test RE 0.019683764014901434\n",
      "94 Train Loss 0.0062420256 Test MSE 0.0014765653996640852 Test RE 0.018366838361498463\n",
      "95 Train Loss 0.0057044798 Test MSE 0.0015535080740564432 Test RE 0.018839302416586576\n",
      "96 Train Loss 0.005335209 Test MSE 0.001494416545039167 Test RE 0.018477529053589452\n",
      "97 Train Loss 0.0050576706 Test MSE 0.0016140515505857864 Test RE 0.019202897375988206\n",
      "98 Train Loss 0.004767644 Test MSE 0.0015545173617848762 Test RE 0.01884542120983544\n",
      "99 Train Loss 0.0044891736 Test MSE 0.001328118830945242 Test RE 0.017419132694163626\n",
      "Training time: 79.14\n",
      "KG_stan_tune3\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 51.767353 Test MSE 9.08464948280428 Test RE 1.4406621556820354\n",
      "1 Train Loss 45.396774 Test MSE 8.525373215260013 Test RE 1.395612210017295\n",
      "2 Train Loss 43.847553 Test MSE 8.140854915031676 Test RE 1.363776076457202\n",
      "3 Train Loss 42.65889 Test MSE 8.30003375956068 Test RE 1.377044546705202\n",
      "4 Train Loss 42.104042 Test MSE 8.29477491248131 Test RE 1.3766082343759924\n",
      "5 Train Loss 41.388817 Test MSE 8.217504249743541 Test RE 1.3701812776278635\n",
      "6 Train Loss 40.139137 Test MSE 8.350861771111054 Test RE 1.3812545059368193\n",
      "7 Train Loss 33.48001 Test MSE 6.931456326248902 Test RE 1.2584046252702514\n",
      "8 Train Loss 26.93243 Test MSE 6.304516380785118 Test RE 1.2001456325207331\n",
      "9 Train Loss 24.968521 Test MSE 6.370638666284175 Test RE 1.2064228294843808\n",
      "10 Train Loss 23.110706 Test MSE 6.001656938864607 Test RE 1.170964270807076\n",
      "11 Train Loss 22.653143 Test MSE 6.130443296753962 Test RE 1.1834611348938109\n",
      "12 Train Loss 21.306591 Test MSE 5.783842722837045 Test RE 1.149519380510784\n",
      "13 Train Loss 20.22456 Test MSE 6.0589512753307595 Test RE 1.1765402529834847\n",
      "14 Train Loss 18.914032 Test MSE 5.718236691424788 Test RE 1.1429812977260059\n",
      "15 Train Loss 17.444904 Test MSE 5.859119748159005 Test RE 1.1569757261574816\n",
      "16 Train Loss 15.371574 Test MSE 5.4166545848108205 Test RE 1.1124324047871441\n",
      "17 Train Loss 13.117353 Test MSE 5.178569971603279 Test RE 1.087709657729311\n",
      "18 Train Loss 10.8290205 Test MSE 4.176751484596112 Test RE 0.976848869208725\n",
      "19 Train Loss 7.9699383 Test MSE 2.863106319707578 Test RE 0.8087732862137994\n",
      "20 Train Loss 6.824844 Test MSE 2.9746465627493035 Test RE 0.8243767715244569\n",
      "21 Train Loss 5.584818 Test MSE 2.520219492634648 Test RE 0.7587998623373311\n",
      "22 Train Loss 4.9751706 Test MSE 2.1740899346651004 Test RE 0.7047690325390674\n",
      "23 Train Loss 4.3487806 Test MSE 2.0727493092353235 Test RE 0.6881473627388117\n",
      "24 Train Loss 3.9873438 Test MSE 1.955770866237585 Test RE 0.6684471046614097\n",
      "25 Train Loss 3.787102 Test MSE 1.8315699207852647 Test RE 0.6468741725451673\n",
      "26 Train Loss 3.6397243 Test MSE 1.8308839012260232 Test RE 0.646753016947681\n",
      "27 Train Loss 3.4795039 Test MSE 1.8059009359418663 Test RE 0.6423252902619689\n",
      "28 Train Loss 3.349752 Test MSE 1.7986031998330776 Test RE 0.6410261421221511\n",
      "29 Train Loss 3.2920394 Test MSE 1.7731817633415852 Test RE 0.6364798928161\n",
      "30 Train Loss 3.1975255 Test MSE 1.753665652794715 Test RE 0.6329675681087629\n",
      "31 Train Loss 3.1072938 Test MSE 1.7030206784504556 Test RE 0.6237607177196425\n",
      "32 Train Loss 3.0554466 Test MSE 1.673741964160346 Test RE 0.61837555440846\n",
      "33 Train Loss 2.3601108 Test MSE 1.0622095406602035 Test RE 0.492621269663751\n",
      "34 Train Loss 1.7199235 Test MSE 1.051580118858391 Test RE 0.49015026712295146\n",
      "35 Train Loss 1.4985557 Test MSE 1.0175283759489475 Test RE 0.48214906058947493\n",
      "36 Train Loss 1.3907423 Test MSE 1.0527700559487159 Test RE 0.49042750851852024\n",
      "37 Train Loss 1.3493779 Test MSE 1.0637415832472685 Test RE 0.49297639960584905\n",
      "38 Train Loss 1.2842615 Test MSE 1.134917445772832 Test RE 0.5092021119663883\n",
      "39 Train Loss 1.242994 Test MSE 1.1399003681278161 Test RE 0.5103187287018492\n",
      "40 Train Loss 1.1846343 Test MSE 1.1113133753731514 Test RE 0.5038790837592991\n",
      "41 Train Loss 1.1316388 Test MSE 1.137677550193679 Test RE 0.5098209224065008\n",
      "42 Train Loss 1.0401409 Test MSE 0.9989064955102342 Test RE 0.4777167608051932\n",
      "43 Train Loss 0.91619825 Test MSE 0.5744075498271686 Test RE 0.36225812090463766\n",
      "44 Train Loss 0.5404399 Test MSE 0.5213947551871722 Test RE 0.34513689634731903\n",
      "45 Train Loss 0.37419343 Test MSE 0.4834650668613568 Test RE 0.33234611768894223\n",
      "46 Train Loss 0.26297992 Test MSE 0.3998746065764347 Test RE 0.3022525497505442\n",
      "47 Train Loss 0.197297 Test MSE 0.3347346991153828 Test RE 0.2765402985979297\n",
      "48 Train Loss 0.16479672 Test MSE 0.2843419312433199 Test RE 0.25487574878954083\n",
      "49 Train Loss 0.11703644 Test MSE 0.21360402826192407 Test RE 0.22090867947227788\n",
      "50 Train Loss 0.095565066 Test MSE 0.1709360049947964 Test RE 0.19761724257220323\n",
      "51 Train Loss 0.07862839 Test MSE 0.13092849159877787 Test RE 0.17295182238824805\n",
      "52 Train Loss 0.06090164 Test MSE 0.11333717072425792 Test RE 0.16091415306609144\n",
      "53 Train Loss 0.051069237 Test MSE 0.11844643255613219 Test RE 0.16450119331490168\n",
      "54 Train Loss 0.043581393 Test MSE 0.12208745055126606 Test RE 0.1670104217286521\n",
      "55 Train Loss 0.034363557 Test MSE 0.10786935831504794 Test RE 0.1569846206643228\n",
      "56 Train Loss 0.030415943 Test MSE 0.09988557033422414 Test RE 0.15106346329161705\n",
      "57 Train Loss 0.025930844 Test MSE 0.07739022877760474 Test RE 0.1329692213312894\n",
      "58 Train Loss 0.022225376 Test MSE 0.06696820475542871 Test RE 0.12369222127001284\n",
      "59 Train Loss 0.019903388 Test MSE 0.06783249960648505 Test RE 0.12448785124971311\n",
      "60 Train Loss 0.017603884 Test MSE 0.06093583348286233 Test RE 0.11798979272131996\n",
      "61 Train Loss 0.016027803 Test MSE 0.05496464285900396 Test RE 0.1120597799951842\n",
      "62 Train Loss 0.0143428035 Test MSE 0.04481084537298952 Test RE 0.1011811541126353\n",
      "63 Train Loss 0.012305086 Test MSE 0.03951008827848283 Test RE 0.09500841223609525\n",
      "64 Train Loss 0.0114735775 Test MSE 0.03673439531717977 Test RE 0.09161034273764751\n",
      "65 Train Loss 0.010038944 Test MSE 0.03065740455144961 Test RE 0.08369042102413148\n",
      "66 Train Loss 0.009330219 Test MSE 0.029629628569976595 Test RE 0.08227562004960014\n",
      "67 Train Loss 0.008478525 Test MSE 0.025775844311376563 Test RE 0.07673871281361863\n",
      "68 Train Loss 0.00782007 Test MSE 0.022738933822722504 Test RE 0.07207640370832331\n",
      "69 Train Loss 0.007251667 Test MSE 0.02172300719989372 Test RE 0.07044789703339363\n",
      "70 Train Loss 0.006521158 Test MSE 0.020641511235182892 Test RE 0.06867185918785405\n",
      "71 Train Loss 0.0058456794 Test MSE 0.01793953327881849 Test RE 0.0640196993579732\n",
      "72 Train Loss 0.0051843924 Test MSE 0.015430333569194543 Test RE 0.05937391926519402\n",
      "73 Train Loss 0.004511944 Test MSE 0.01247211083609304 Test RE 0.05337993505983664\n",
      "74 Train Loss 0.0041279066 Test MSE 0.011434875676836568 Test RE 0.051112106951170334\n",
      "75 Train Loss 0.0036688268 Test MSE 0.011383293556320083 Test RE 0.0509966946412572\n",
      "76 Train Loss 0.003415094 Test MSE 0.011106410378897726 Test RE 0.05037266388875087\n",
      "77 Train Loss 0.0032560106 Test MSE 0.011322271463791896 Test RE 0.05085982271042446\n",
      "78 Train Loss 0.0030172465 Test MSE 0.010510961905300101 Test RE 0.049003747262896295\n",
      "79 Train Loss 0.0029172495 Test MSE 0.010070030059224598 Test RE 0.0479648889977927\n",
      "80 Train Loss 0.0028501162 Test MSE 0.01026253148969491 Test RE 0.04842117363008683\n",
      "81 Train Loss 0.0026928529 Test MSE 0.010234645546873263 Test RE 0.048355342475910015\n",
      "82 Train Loss 0.0025183628 Test MSE 0.009272010847621115 Test RE 0.04602513020596829\n",
      "83 Train Loss 0.0023401123 Test MSE 0.009161703551906483 Test RE 0.045750535084789636\n",
      "84 Train Loss 0.0022323143 Test MSE 0.00982078013491773 Test RE 0.04736756441867728\n",
      "85 Train Loss 0.0021037105 Test MSE 0.010116623156155082 Test RE 0.04807572548891645\n",
      "86 Train Loss 0.0020030607 Test MSE 0.009612164021885599 Test RE 0.04686176553451655\n",
      "87 Train Loss 0.0018661151 Test MSE 0.008852050653041652 Test RE 0.044970737044909746\n",
      "88 Train Loss 0.0018085418 Test MSE 0.008634333800253628 Test RE 0.04441426479112229\n",
      "89 Train Loss 0.0017265268 Test MSE 0.008233605758448287 Test RE 0.043371365376506384\n",
      "90 Train Loss 0.0016387141 Test MSE 0.008094600613379854 Test RE 0.043003695006724484\n",
      "91 Train Loss 0.0015940613 Test MSE 0.007895345564705976 Test RE 0.04247111197437621\n",
      "92 Train Loss 0.0015340486 Test MSE 0.00743486776166859 Test RE 0.0412139921946143\n",
      "93 Train Loss 0.001483463 Test MSE 0.00729950468330649 Test RE 0.04083708706779281\n",
      "94 Train Loss 0.0014454292 Test MSE 0.007283846541489755 Test RE 0.04079326380799326\n",
      "95 Train Loss 0.0013957549 Test MSE 0.0070464445011195476 Test RE 0.04012297046744963\n",
      "96 Train Loss 0.0013477823 Test MSE 0.0068522537868383705 Test RE 0.0395662399138732\n",
      "97 Train Loss 0.0013105822 Test MSE 0.006968284719003631 Test RE 0.03989982619945573\n",
      "98 Train Loss 0.0012671414 Test MSE 0.007063517277033756 Test RE 0.0401715478782945\n",
      "99 Train Loss 0.001217347 Test MSE 0.006979173093144941 Test RE 0.039930986999734235\n",
      "Training time: 78.98\n",
      "KG_stan_tune3\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.97663 Test MSE 8.651864244669865 Test RE 1.4059274437609581\n",
      "1 Train Loss 45.998035 Test MSE 8.509051402233139 Test RE 1.3942756213439642\n",
      "2 Train Loss 42.80857 Test MSE 8.400408201982021 Test RE 1.3853460011126826\n",
      "3 Train Loss 42.06922 Test MSE 8.6903376053578 Test RE 1.409049935767564\n",
      "4 Train Loss 41.174866 Test MSE 8.850612993933241 Test RE 1.4219840850952095\n",
      "5 Train Loss 40.530632 Test MSE 8.50741497048833 Test RE 1.3941415437312183\n",
      "6 Train Loss 40.40707 Test MSE 8.718788987698966 Test RE 1.411354602260163\n",
      "7 Train Loss 40.05771 Test MSE 9.07848179375664 Test RE 1.4401730303251117\n",
      "8 Train Loss 39.83804 Test MSE 8.938005622693511 Test RE 1.428987309839795\n",
      "9 Train Loss 39.295906 Test MSE 8.902882639433242 Test RE 1.4261768561533015\n",
      "10 Train Loss 38.720284 Test MSE 9.191630260048617 Test RE 1.449119943250984\n",
      "11 Train Loss 38.00836 Test MSE 9.15653146656786 Test RE 1.4463505210510323\n",
      "12 Train Loss 36.67764 Test MSE 9.501770609889604 Test RE 1.4733649394108495\n",
      "13 Train Loss 34.800297 Test MSE 9.260610346378446 Test RE 1.454547357871215\n",
      "14 Train Loss 33.74812 Test MSE 9.14272564397103 Test RE 1.4452597373190545\n",
      "15 Train Loss 30.839376 Test MSE 9.65097867815537 Test RE 1.4848881395023996\n",
      "16 Train Loss 27.629847 Test MSE 9.520288971811189 Test RE 1.474799989013395\n",
      "17 Train Loss 24.845585 Test MSE 9.163549264364784 Test RE 1.4469046747412382\n",
      "18 Train Loss 23.364727 Test MSE 9.113960175699308 Test RE 1.4429843586909397\n",
      "19 Train Loss 22.104465 Test MSE 9.315109874839537 Test RE 1.4588211504814446\n",
      "20 Train Loss 21.154165 Test MSE 9.398246834753207 Test RE 1.4653166480629327\n",
      "21 Train Loss 19.276112 Test MSE 9.573520129896693 Test RE 1.4789172946892708\n",
      "22 Train Loss 17.641743 Test MSE 9.109210788263676 Test RE 1.442608331984905\n",
      "23 Train Loss 16.478008 Test MSE 8.856849386029186 Test RE 1.4224849819650267\n",
      "24 Train Loss 15.1116295 Test MSE 8.383761724043397 Test RE 1.383972700728603\n",
      "25 Train Loss 13.309526 Test MSE 7.733475126537583 Test RE 1.329215530131056\n",
      "26 Train Loss 10.681 Test MSE 6.909524278914523 Test RE 1.2564121683356622\n",
      "27 Train Loss 9.279506 Test MSE 6.580868489071031 Test RE 1.2261671201865276\n",
      "28 Train Loss 8.468143 Test MSE 6.451400877733716 Test RE 1.214045810929205\n",
      "29 Train Loss 7.688415 Test MSE 6.100324963841096 Test RE 1.1805504348507363\n",
      "30 Train Loss 7.202318 Test MSE 6.1584473643245055 Test RE 1.1861610998116414\n",
      "31 Train Loss 6.9255323 Test MSE 5.945737956762631 Test RE 1.165496416933398\n",
      "32 Train Loss 6.6183906 Test MSE 6.031149651900232 Test RE 1.1738378597616896\n",
      "33 Train Loss 6.3084474 Test MSE 6.062207368986393 Test RE 1.1768563481731162\n",
      "34 Train Loss 6.0942044 Test MSE 6.122855099328557 Test RE 1.1827284703078647\n",
      "35 Train Loss 5.777773 Test MSE 6.169811043675208 Test RE 1.1872549584852903\n",
      "36 Train Loss 5.476051 Test MSE 6.252646088003739 Test RE 1.195198347500118\n",
      "37 Train Loss 5.0529366 Test MSE 6.267445787475062 Test RE 1.196611998735038\n",
      "38 Train Loss 4.570179 Test MSE 6.3425199390940525 Test RE 1.203757430341936\n",
      "39 Train Loss 3.7372608 Test MSE 6.233623175097202 Test RE 1.193378839958825\n",
      "40 Train Loss 3.0661697 Test MSE 6.112797722503414 Test RE 1.1817566986049457\n",
      "41 Train Loss 2.4173799 Test MSE 5.905888408009041 Test RE 1.1615841533382962\n",
      "42 Train Loss 1.9816942 Test MSE 5.728653252046162 Test RE 1.1440218734729337\n",
      "43 Train Loss 1.7849112 Test MSE 5.649451448398383 Test RE 1.136085980504906\n",
      "44 Train Loss 1.6127213 Test MSE 5.7335120618103765 Test RE 1.1445069269631032\n",
      "45 Train Loss 1.5032313 Test MSE 5.749278510371568 Test RE 1.1460794728282215\n",
      "46 Train Loss 1.412729 Test MSE 5.9031202577764095 Test RE 1.1613118982525437\n",
      "47 Train Loss 1.3196071 Test MSE 5.9387290984006915 Test RE 1.1648092685810938\n",
      "48 Train Loss 1.2597591 Test MSE 5.943427471897902 Test RE 1.1652699418087038\n",
      "49 Train Loss 1.1974577 Test MSE 5.973977783050605 Test RE 1.1682609541369948\n",
      "50 Train Loss 1.1645244 Test MSE 5.978870022959077 Test RE 1.1687392153078657\n",
      "51 Train Loss 1.1368873 Test MSE 5.985042291858545 Test RE 1.169342331938906\n",
      "52 Train Loss 1.099821 Test MSE 5.977151951766181 Test RE 1.1685712804437098\n",
      "53 Train Loss 1.07166 Test MSE 5.997986153818933 Test RE 1.1706061184144232\n",
      "54 Train Loss 1.0467403 Test MSE 6.072183116401144 Test RE 1.1778242461012445\n",
      "55 Train Loss 1.0235467 Test MSE 6.11527667984274 Test RE 1.1819962965458437\n",
      "56 Train Loss 0.99932516 Test MSE 6.152659541797706 Test RE 1.185603580739248\n",
      "57 Train Loss 0.97784305 Test MSE 6.17906377852868 Test RE 1.1881448755115875\n",
      "58 Train Loss 0.9580243 Test MSE 6.189323529959165 Test RE 1.189130867532727\n",
      "59 Train Loss 0.9421551 Test MSE 6.179044525332972 Test RE 1.1881430244541737\n",
      "60 Train Loss 0.92471486 Test MSE 6.15125135469664 Test RE 1.1854678957400675\n",
      "61 Train Loss 0.9111562 Test MSE 6.146645995809925 Test RE 1.185024040738796\n",
      "62 Train Loss 0.8967459 Test MSE 6.142160111997469 Test RE 1.184591540606604\n",
      "63 Train Loss 0.8854877 Test MSE 6.17975868056718 Test RE 1.188211683454812\n",
      "64 Train Loss 0.87285745 Test MSE 6.217737523044738 Test RE 1.191857277482156\n",
      "65 Train Loss 0.86033916 Test MSE 6.173971971076157 Test RE 1.1876552340395419\n",
      "66 Train Loss 0.8460814 Test MSE 6.228713838891163 Test RE 1.192908820216562\n",
      "67 Train Loss 0.8335291 Test MSE 6.257202850828877 Test RE 1.1956337826275265\n",
      "68 Train Loss 0.8195052 Test MSE 6.300965998925942 Test RE 1.1998076545471184\n",
      "69 Train Loss 0.80819786 Test MSE 6.300333215369039 Test RE 1.199747406831313\n",
      "70 Train Loss 0.7968582 Test MSE 6.30836381711824 Test RE 1.2005117811175066\n",
      "71 Train Loss 0.7888313 Test MSE 6.341022623828464 Test RE 1.2036153329750867\n",
      "72 Train Loss 0.7802665 Test MSE 6.326621447689286 Test RE 1.2022477831173266\n",
      "73 Train Loss 0.772316 Test MSE 6.3338834469931165 Test RE 1.202937584039321\n",
      "74 Train Loss 0.7614749 Test MSE 6.369463009196746 Test RE 1.2063115058741087\n",
      "75 Train Loss 0.75194484 Test MSE 6.386033948876711 Test RE 1.2078796703042098\n",
      "76 Train Loss 0.7443135 Test MSE 6.384861958193621 Test RE 1.2077688277462602\n",
      "77 Train Loss 0.73508406 Test MSE 6.387304534217626 Test RE 1.2079998260914058\n",
      "78 Train Loss 0.7253271 Test MSE 6.424060346211713 Test RE 1.2114705640891141\n",
      "79 Train Loss 0.71763813 Test MSE 6.441926078767085 Test RE 1.213153983967443\n",
      "80 Train Loss 0.7093942 Test MSE 6.454038534915239 Test RE 1.2142939670638664\n",
      "81 Train Loss 0.7017776 Test MSE 6.468204060565758 Test RE 1.2156258218555218\n",
      "82 Train Loss 0.69661707 Test MSE 6.467671014932985 Test RE 1.2155757308735406\n",
      "83 Train Loss 0.69016147 Test MSE 6.481560792240301 Test RE 1.2168802979231959\n",
      "84 Train Loss 0.6831745 Test MSE 6.542168534364556 Test RE 1.2225564583616073\n",
      "85 Train Loss 0.6766402 Test MSE 6.570530874198829 Test RE 1.225203674001308\n",
      "86 Train Loss 0.6691383 Test MSE 6.579064956189811 Test RE 1.2259990888500707\n",
      "87 Train Loss 0.66221976 Test MSE 6.5905428995010364 Test RE 1.2270680717485491\n",
      "88 Train Loss 0.65522254 Test MSE 6.609714763036207 Test RE 1.2288515437744831\n",
      "89 Train Loss 0.6483234 Test MSE 6.65311513654145 Test RE 1.2328793541008816\n",
      "90 Train Loss 0.64321566 Test MSE 6.676102347031748 Test RE 1.2350073812751352\n",
      "91 Train Loss 0.63848245 Test MSE 6.667039077993947 Test RE 1.2341687927510636\n",
      "92 Train Loss 0.63341665 Test MSE 6.6690351319930805 Test RE 1.2343535286711564\n",
      "93 Train Loss 0.6279058 Test MSE 6.689741309390735 Test RE 1.2362682685489716\n",
      "94 Train Loss 0.62348866 Test MSE 6.699370180866471 Test RE 1.2371576592848903\n",
      "95 Train Loss 0.61767656 Test MSE 6.721492509092545 Test RE 1.2391986161446502\n",
      "96 Train Loss 0.6124152 Test MSE 6.752447092159654 Test RE 1.2420487877533537\n",
      "97 Train Loss 0.605079 Test MSE 6.773233385652722 Test RE 1.243959039844783\n",
      "98 Train Loss 0.6002039 Test MSE 6.785261167431471 Test RE 1.245063049597005\n",
      "99 Train Loss 0.5956503 Test MSE 6.802330869343211 Test RE 1.246628170298524\n",
      "Training time: 78.68\n",
      "KG_stan_tune3\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 51.04229 Test MSE 8.776939812361855 Test RE 1.4160533650530354\n",
      "1 Train Loss 44.970665 Test MSE 8.124473475413545 Test RE 1.362403255928335\n",
      "2 Train Loss 43.942047 Test MSE 8.168309616972357 Test RE 1.366073780521552\n",
      "3 Train Loss 43.671207 Test MSE 8.318935313732856 Test RE 1.3786116174687817\n",
      "4 Train Loss 42.84475 Test MSE 8.366635010680472 Test RE 1.3825583582031702\n",
      "5 Train Loss 42.40103 Test MSE 8.121187352929253 Test RE 1.3621277010394626\n",
      "6 Train Loss 41.9609 Test MSE 8.273121141438773 Test RE 1.3748102205993784\n",
      "7 Train Loss 40.98369 Test MSE 8.121700253472556 Test RE 1.362170713531181\n",
      "8 Train Loss 39.805298 Test MSE 7.964059646767976 Test RE 1.3488862022183494\n",
      "9 Train Loss 37.805885 Test MSE 7.939019395129618 Test RE 1.3467639779465839\n",
      "10 Train Loss 33.34597 Test MSE 7.246828038404043 Test RE 1.2867140354648534\n",
      "11 Train Loss 26.357464 Test MSE 5.8948252537630825 Test RE 1.1604956796347317\n",
      "12 Train Loss 24.37763 Test MSE 6.252922927985416 Test RE 1.1952248063002466\n",
      "13 Train Loss 23.1418 Test MSE 5.857941820812879 Test RE 1.1568594201329683\n",
      "14 Train Loss 22.42023 Test MSE 5.977936351428681 Test RE 1.1686479554935019\n",
      "15 Train Loss 21.47128 Test MSE 5.961462645041083 Test RE 1.1670365929873041\n",
      "16 Train Loss 20.411297 Test MSE 5.862996922190877 Test RE 1.157358467471801\n",
      "17 Train Loss 19.038145 Test MSE 5.836505220050932 Test RE 1.1547407696383383\n",
      "18 Train Loss 17.726685 Test MSE 5.9969205362743265 Test RE 1.1705021273584737\n",
      "19 Train Loss 16.486837 Test MSE 5.71819388756549 Test RE 1.1429770198248932\n",
      "20 Train Loss 14.97361 Test MSE 5.919586115784888 Test RE 1.162930422022488\n",
      "21 Train Loss 13.586082 Test MSE 6.174825354613026 Test RE 1.1877373117043173\n",
      "22 Train Loss 12.460136 Test MSE 5.7974635060152275 Test RE 1.1508721270907434\n",
      "23 Train Loss 11.331161 Test MSE 5.689830071442267 Test RE 1.1401387554440803\n",
      "24 Train Loss 10.643745 Test MSE 5.626155672064074 Test RE 1.13374120907097\n",
      "25 Train Loss 9.958359 Test MSE 5.378303845868685 Test RE 1.108487314046437\n",
      "26 Train Loss 9.428406 Test MSE 5.149780001693861 Test RE 1.0846819132390666\n",
      "27 Train Loss 8.899236 Test MSE 4.996752573595977 Test RE 1.0684445366326383\n",
      "28 Train Loss 8.019978 Test MSE 4.53859614176118 Test RE 1.0182837894547863\n",
      "29 Train Loss 7.361803 Test MSE 3.999872108705227 Test RE 0.9559410534131942\n",
      "30 Train Loss 6.469146 Test MSE 3.729576758392645 Test RE 0.9230767985986044\n",
      "31 Train Loss 5.9139214 Test MSE 3.439642411905371 Test RE 0.8864713577463479\n",
      "32 Train Loss 5.33652 Test MSE 3.0636841108320776 Test RE 0.8366234865598692\n",
      "33 Train Loss 5.045863 Test MSE 2.802446732990564 Test RE 0.8001598274764569\n",
      "34 Train Loss 4.7813377 Test MSE 2.562389729530137 Test RE 0.765121934959032\n",
      "35 Train Loss 4.580208 Test MSE 2.2910817118881024 Test RE 0.7234830313967561\n",
      "36 Train Loss 4.1155276 Test MSE 2.038685395502746 Test RE 0.6824693725923958\n",
      "37 Train Loss 3.3815057 Test MSE 1.829750873424001 Test RE 0.646552867021731\n",
      "38 Train Loss 2.8551853 Test MSE 1.4507889421864 Test RE 0.5757184913368921\n",
      "39 Train Loss 2.5456345 Test MSE 1.4669350754318133 Test RE 0.5789132727705517\n",
      "40 Train Loss 2.1311562 Test MSE 1.265439715700535 Test RE 0.5376860766510515\n",
      "41 Train Loss 1.8176416 Test MSE 1.1989557782871767 Test RE 0.5233709856821814\n",
      "42 Train Loss 1.5768062 Test MSE 1.038977860708599 Test RE 0.48720440580026375\n",
      "43 Train Loss 1.4476734 Test MSE 1.059548636258872 Test RE 0.49200385850072087\n",
      "44 Train Loss 1.2444814 Test MSE 0.9336438287071152 Test RE 0.4618475836125256\n",
      "45 Train Loss 1.135187 Test MSE 0.8606521490285517 Test RE 0.4434267503856271\n",
      "46 Train Loss 0.9240083 Test MSE 0.7544805316496219 Test RE 0.4151758459242933\n",
      "47 Train Loss 0.81390965 Test MSE 0.6666499911695023 Test RE 0.39026265890819073\n",
      "48 Train Loss 0.74932986 Test MSE 0.6282829764589488 Test RE 0.37886606433736775\n",
      "49 Train Loss 0.6644573 Test MSE 0.5621622102685693 Test RE 0.3583759723670002\n",
      "50 Train Loss 0.5758849 Test MSE 0.4690726854143601 Test RE 0.3273618998044885\n",
      "51 Train Loss 0.50685936 Test MSE 0.39438367554226017 Test RE 0.30017016598165\n",
      "52 Train Loss 0.44956592 Test MSE 0.30459548238531814 Test RE 0.26379696167417277\n",
      "53 Train Loss 0.38233727 Test MSE 0.22456278250833073 Test RE 0.2265045605531776\n",
      "54 Train Loss 0.32335 Test MSE 0.18794579861759494 Test RE 0.2072165177700511\n",
      "55 Train Loss 0.27608112 Test MSE 0.12441124686369284 Test RE 0.16859235671496106\n",
      "56 Train Loss 0.22579299 Test MSE 0.09413720299724375 Test RE 0.14665224155512774\n",
      "57 Train Loss 0.19311331 Test MSE 0.06328188786019927 Test RE 0.12023966945354446\n",
      "58 Train Loss 0.15316142 Test MSE 0.04231115921252077 Test RE 0.09831856297666967\n",
      "59 Train Loss 0.13028044 Test MSE 0.03621346839248852 Test RE 0.09095846470399516\n",
      "60 Train Loss 0.111170806 Test MSE 0.026198414813300614 Test RE 0.07736518482746986\n",
      "61 Train Loss 0.09917527 Test MSE 0.023335060336569166 Test RE 0.07301507310251322\n",
      "62 Train Loss 0.08528819 Test MSE 0.022109331116211862 Test RE 0.07107156229577101\n",
      "63 Train Loss 0.07514484 Test MSE 0.021336750216707275 Test RE 0.06981877052373739\n",
      "64 Train Loss 0.069435805 Test MSE 0.021248581562882406 Test RE 0.06967436710091265\n",
      "65 Train Loss 0.06521827 Test MSE 0.01846015261555652 Test RE 0.06494200665655746\n",
      "66 Train Loss 0.05876478 Test MSE 0.015615340096270618 Test RE 0.05972879924268638\n",
      "67 Train Loss 0.05349464 Test MSE 0.015233891469125328 Test RE 0.058994766819255834\n",
      "68 Train Loss 0.045288987 Test MSE 0.012334404508837625 Test RE 0.05308442943635092\n",
      "69 Train Loss 0.042322543 Test MSE 0.01203100362770441 Test RE 0.05242748071321349\n",
      "70 Train Loss 0.03942773 Test MSE 0.011372219572438483 Test RE 0.050971883105545714\n",
      "71 Train Loss 0.03538907 Test MSE 0.010445961045451013 Test RE 0.04885199019463027\n",
      "72 Train Loss 0.032531753 Test MSE 0.011033321962551535 Test RE 0.050206645565663094\n",
      "73 Train Loss 0.03096664 Test MSE 0.011718887659074358 Test RE 0.05174295839171441\n",
      "74 Train Loss 0.02795415 Test MSE 0.011776519145580495 Test RE 0.051870033862177756\n",
      "75 Train Loss 0.026012763 Test MSE 0.011927247839068613 Test RE 0.05220092299767867\n",
      "76 Train Loss 0.024523031 Test MSE 0.012434132124684758 Test RE 0.05329859971657996\n",
      "77 Train Loss 0.0231146 Test MSE 0.011864791699445478 Test RE 0.05206407049708365\n",
      "78 Train Loss 0.021257998 Test MSE 0.010158323764497528 Test RE 0.048174707396612705\n",
      "79 Train Loss 0.01992547 Test MSE 0.010060154089408635 Test RE 0.04794136295105093\n",
      "80 Train Loss 0.018704213 Test MSE 0.00909888873781973 Test RE 0.045593427065422854\n",
      "81 Train Loss 0.017491065 Test MSE 0.007610046411950924 Test RE 0.0416967026897481\n",
      "82 Train Loss 0.016587801 Test MSE 0.00755646068885647 Test RE 0.04154964083152514\n",
      "83 Train Loss 0.015668035 Test MSE 0.00732248716612511 Test RE 0.04090132430765152\n",
      "84 Train Loss 0.014600356 Test MSE 0.006813919870030011 Test RE 0.03945541096403469\n",
      "85 Train Loss 0.013502757 Test MSE 0.006659601475930641 Test RE 0.03900606864528764\n",
      "86 Train Loss 0.012674395 Test MSE 0.00611184135508585 Test RE 0.03736750459965129\n",
      "87 Train Loss 0.011623323 Test MSE 0.005649544764545957 Test RE 0.03592648987027338\n",
      "88 Train Loss 0.010860232 Test MSE 0.005389120456574279 Test RE 0.03508867797636418\n",
      "89 Train Loss 0.010009375 Test MSE 0.004898899879106863 Test RE 0.03345471558831342\n",
      "90 Train Loss 0.009244982 Test MSE 0.00459885355376321 Test RE 0.032414016609462644\n",
      "91 Train Loss 0.008664711 Test MSE 0.004042036715864276 Test RE 0.030388424698984083\n",
      "92 Train Loss 0.007864179 Test MSE 0.0032852182235834906 Test RE 0.027396190152018805\n",
      "93 Train Loss 0.0075996644 Test MSE 0.0031007292945943246 Test RE 0.02661582831438319\n",
      "94 Train Loss 0.007372218 Test MSE 0.0029468070578123648 Test RE 0.025946806374216116\n",
      "95 Train Loss 0.007058945 Test MSE 0.0030739849202104756 Test RE 0.0265007964673806\n",
      "96 Train Loss 0.006818548 Test MSE 0.003299767572977523 Test RE 0.02745678831788624\n",
      "97 Train Loss 0.0064838696 Test MSE 0.0032461754352247694 Test RE 0.027232910186974206\n",
      "98 Train Loss 0.0062936796 Test MSE 0.003018157286233308 Test RE 0.026259049058596884\n",
      "99 Train Loss 0.0061233244 Test MSE 0.0028272541442879214 Test RE 0.025415021705967978\n",
      "Training time: 78.86\n",
      "KG_stan_tune3\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.644974 Test MSE 8.470013923827342 Test RE 1.3910736442794067\n",
      "1 Train Loss 55.766006 Test MSE 8.788010943316415 Test RE 1.4169461803108834\n",
      "2 Train Loss 49.395523 Test MSE 8.811707371504655 Test RE 1.4188552561934864\n",
      "3 Train Loss 45.70508 Test MSE 8.420913077133974 Test RE 1.3870357424147755\n",
      "4 Train Loss 44.80648 Test MSE 8.54426924341293 Test RE 1.3971580034008553\n",
      "5 Train Loss 44.24665 Test MSE 8.781705503909055 Test RE 1.416437756303045\n",
      "6 Train Loss 43.89301 Test MSE 8.485850149046833 Test RE 1.3923734690714864\n",
      "7 Train Loss 43.56285 Test MSE 8.36450034363548 Test RE 1.382381973668981\n",
      "8 Train Loss 43.05913 Test MSE 8.67063110146102 Test RE 1.407451424364067\n",
      "9 Train Loss 42.4579 Test MSE 8.232245442483395 Test RE 1.3714096953794053\n",
      "10 Train Loss 41.8285 Test MSE 8.506200992090053 Test RE 1.3940420706183305\n",
      "11 Train Loss 40.99566 Test MSE 8.60057378114542 Test RE 1.401753900417251\n",
      "12 Train Loss 40.345444 Test MSE 8.654330285081192 Test RE 1.406127795198168\n",
      "13 Train Loss 39.854084 Test MSE 8.751959997180537 Test RE 1.414036833303706\n",
      "14 Train Loss 38.901634 Test MSE 8.776803752247593 Test RE 1.4160423891814073\n",
      "15 Train Loss 38.204876 Test MSE 8.634571059001832 Test RE 1.4045216701111896\n",
      "16 Train Loss 37.063 Test MSE 8.345615641155192 Test RE 1.3808205759278975\n",
      "17 Train Loss 36.238365 Test MSE 8.654872642188387 Test RE 1.4061718547285087\n",
      "18 Train Loss 34.62473 Test MSE 8.531565739767625 Test RE 1.3961189792689046\n",
      "19 Train Loss 32.85811 Test MSE 8.652573724433394 Test RE 1.4059850877896847\n",
      "20 Train Loss 31.66803 Test MSE 8.941296222068985 Test RE 1.4292503322766157\n",
      "21 Train Loss 30.129917 Test MSE 9.042403725896696 Test RE 1.437308543425469\n",
      "22 Train Loss 29.374168 Test MSE 9.018113101163681 Test RE 1.435376722979613\n",
      "23 Train Loss 27.843443 Test MSE 9.038713224507688 Test RE 1.4370152071251328\n",
      "24 Train Loss 26.489914 Test MSE 9.352346582456159 Test RE 1.4617340263632739\n",
      "25 Train Loss 24.614689 Test MSE 9.586053263867038 Test RE 1.4798850372695227\n",
      "26 Train Loss 23.447792 Test MSE 9.560360353921274 Test RE 1.4779004841106846\n",
      "27 Train Loss 22.208443 Test MSE 9.733574185421414 Test RE 1.491228625954851\n",
      "28 Train Loss 20.751007 Test MSE 9.54500292218225 Test RE 1.4767129829543442\n",
      "29 Train Loss 19.879967 Test MSE 9.81162312788055 Test RE 1.4971954182662486\n",
      "30 Train Loss 18.79565 Test MSE 9.850456843854063 Test RE 1.5001553895313315\n",
      "31 Train Loss 17.747993 Test MSE 9.855374217973315 Test RE 1.500529783582354\n",
      "32 Train Loss 17.022419 Test MSE 9.773039425995185 Test RE 1.4942486965749273\n",
      "33 Train Loss 16.165998 Test MSE 9.357327993071566 Test RE 1.4621232617273667\n",
      "34 Train Loss 15.373981 Test MSE 9.194014336168221 Test RE 1.449307863574134\n",
      "35 Train Loss 14.712166 Test MSE 9.121306040387205 Test RE 1.4435657652696654\n",
      "36 Train Loss 13.402943 Test MSE 9.051995208073443 Test RE 1.438070634229696\n",
      "37 Train Loss 11.634157 Test MSE 8.834453996985529 Test RE 1.4206853991154051\n",
      "38 Train Loss 10.368736 Test MSE 8.434079158652606 Test RE 1.388119632782663\n",
      "39 Train Loss 9.420673 Test MSE 8.286339919173313 Test RE 1.375908116840457\n",
      "40 Train Loss 8.654494 Test MSE 8.22451850712196 Test RE 1.370765929234561\n",
      "41 Train Loss 7.688644 Test MSE 7.764329667472188 Test RE 1.3318645015570159\n",
      "42 Train Loss 6.426695 Test MSE 7.279062718253599 Test RE 1.2895725822470652\n",
      "43 Train Loss 5.3031864 Test MSE 7.207087563419574 Test RE 1.2831811157427824\n",
      "44 Train Loss 4.707613 Test MSE 7.022491733233986 Test RE 1.2666413994624575\n",
      "45 Train Loss 4.266062 Test MSE 7.021505272745455 Test RE 1.2665524327805606\n",
      "46 Train Loss 4.064708 Test MSE 6.913678548890826 Test RE 1.2567898130791264\n",
      "47 Train Loss 3.811099 Test MSE 6.894370836618775 Test RE 1.2550336783926312\n",
      "48 Train Loss 3.7036707 Test MSE 6.96008623991061 Test RE 1.261000824964062\n",
      "49 Train Loss 3.5475802 Test MSE 7.014129377764104 Test RE 1.2658870190248641\n",
      "50 Train Loss 3.4189348 Test MSE 6.989455882603207 Test RE 1.2636585618859026\n",
      "51 Train Loss 3.2977333 Test MSE 7.048199985166352 Test RE 1.2689577701839008\n",
      "52 Train Loss 3.2084043 Test MSE 7.111426439341659 Test RE 1.2746367074846432\n",
      "53 Train Loss 3.1158938 Test MSE 7.099123151465303 Test RE 1.2735336228077883\n",
      "54 Train Loss 3.019133 Test MSE 7.032960392734077 Test RE 1.2675851598761165\n",
      "55 Train Loss 2.942381 Test MSE 7.083860471518739 Test RE 1.2721638765521666\n",
      "56 Train Loss 2.8523152 Test MSE 7.1379670325094455 Test RE 1.2770130316595152\n",
      "57 Train Loss 2.7622073 Test MSE 7.128561352785458 Test RE 1.2761713960154426\n",
      "58 Train Loss 2.6565182 Test MSE 7.088692617057578 Test RE 1.2725976960115395\n",
      "59 Train Loss 2.5870018 Test MSE 7.041968815811738 Test RE 1.2683967163557077\n",
      "60 Train Loss 2.5060852 Test MSE 7.002578322671339 Test RE 1.264844241298421\n",
      "61 Train Loss 2.4508493 Test MSE 7.030957029260637 Test RE 1.267404608974762\n",
      "62 Train Loss 2.3621614 Test MSE 7.084991717292803 Test RE 1.2722654505854745\n",
      "63 Train Loss 2.2635539 Test MSE 7.106595279994477 Test RE 1.2742036706453488\n",
      "64 Train Loss 2.1837068 Test MSE 7.088212477066312 Test RE 1.2725545967105343\n",
      "65 Train Loss 2.098029 Test MSE 7.0649805667722045 Test RE 1.2704674599100927\n",
      "66 Train Loss 2.019947 Test MSE 7.094408285494157 Test RE 1.2731106453836964\n",
      "67 Train Loss 1.9463965 Test MSE 7.144988801556519 Test RE 1.2776409896195082\n",
      "68 Train Loss 1.8691907 Test MSE 7.098488543163464 Test RE 1.2734766993642228\n",
      "69 Train Loss 1.7660412 Test MSE 7.072121165205146 Test RE 1.2711093305264534\n",
      "70 Train Loss 1.7003052 Test MSE 6.9427051474785335 Test RE 1.2594253220407214\n",
      "71 Train Loss 1.6245033 Test MSE 6.838756366479373 Test RE 1.249961470619544\n",
      "72 Train Loss 1.5374985 Test MSE 6.845831412123649 Test RE 1.2506078782332872\n",
      "73 Train Loss 1.4636303 Test MSE 6.662321945675563 Test RE 1.2337321095729\n",
      "74 Train Loss 1.415249 Test MSE 6.499803391368442 Test RE 1.2185915725753906\n",
      "75 Train Loss 1.3629464 Test MSE 6.357263831062759 Test RE 1.2051557520903262\n",
      "76 Train Loss 1.3179119 Test MSE 6.227281646842818 Test RE 1.1927716672832902\n",
      "77 Train Loss 1.2800956 Test MSE 6.234945496043628 Test RE 1.1935054072950189\n",
      "78 Train Loss 1.2510302 Test MSE 6.236780587206855 Test RE 1.1936810327351364\n",
      "79 Train Loss 1.2165427 Test MSE 6.164311445812886 Test RE 1.1867256975021552\n",
      "80 Train Loss 1.1736624 Test MSE 6.149080035806465 Test RE 1.1852586492081176\n",
      "81 Train Loss 1.1459193 Test MSE 6.079019053606809 Test RE 1.1784870446074907\n",
      "82 Train Loss 1.1180111 Test MSE 6.070565082511491 Test RE 1.1776673102445736\n",
      "83 Train Loss 1.1020067 Test MSE 6.059559783267068 Test RE 1.1765993321932493\n",
      "84 Train Loss 1.0781103 Test MSE 6.021331640075602 Test RE 1.1728820346939315\n",
      "85 Train Loss 1.065759 Test MSE 6.019568299864899 Test RE 1.1727102835251884\n",
      "86 Train Loss 1.047943 Test MSE 6.020491336910699 Test RE 1.1728001914296422\n",
      "87 Train Loss 1.0341637 Test MSE 6.021131523120242 Test RE 1.1728625443597334\n",
      "88 Train Loss 1.0256132 Test MSE 6.011319540127202 Test RE 1.1719065114699163\n",
      "89 Train Loss 1.0150702 Test MSE 5.9937693176864695 Test RE 1.170194553436278\n",
      "90 Train Loss 1.0037026 Test MSE 5.990423120287549 Test RE 1.1698678601294603\n",
      "91 Train Loss 0.99669087 Test MSE 5.996635242806177 Test RE 1.1704742846864653\n",
      "92 Train Loss 0.98513746 Test MSE 6.017115139708009 Test RE 1.172471301329085\n",
      "93 Train Loss 0.9772042 Test MSE 6.031259008879341 Test RE 1.1738485017443818\n",
      "94 Train Loss 0.96497285 Test MSE 6.021911729112559 Test RE 1.1729385304713393\n",
      "95 Train Loss 0.9538955 Test MSE 6.031316231529403 Test RE 1.173854070280124\n",
      "96 Train Loss 0.94523466 Test MSE 6.072756494958909 Test RE 1.1778798540442827\n",
      "97 Train Loss 0.939206 Test MSE 6.07548732724848 Test RE 1.1781446621926621\n",
      "98 Train Loss 0.933025 Test MSE 6.102159449857392 Test RE 1.1807279287124843\n",
      "99 Train Loss 0.92661756 Test MSE 6.118364200786842 Test RE 1.1822946459084842\n",
      "Training time: 73.65\n",
      "KG_stan_tune3\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.939484 Test MSE 8.787424892530078 Test RE 1.4168989331992583\n",
      "1 Train Loss 51.46005 Test MSE 8.639781833167453 Test RE 1.4049454051963637\n",
      "2 Train Loss 47.195976 Test MSE 8.713072816902429 Test RE 1.4108918736227807\n",
      "3 Train Loss 46.21206 Test MSE 8.542248927188927 Test RE 1.396992812687644\n",
      "4 Train Loss 45.54837 Test MSE 8.62747918662944 Test RE 1.4039447604728539\n",
      "5 Train Loss 45.35186 Test MSE 8.371894189457855 Test RE 1.3829928207611766\n",
      "6 Train Loss 44.73336 Test MSE 8.290267768157992 Test RE 1.3762341787126116\n",
      "7 Train Loss 44.54497 Test MSE 8.213534621562562 Test RE 1.3698502910488737\n",
      "8 Train Loss 44.203037 Test MSE 8.216744803642548 Test RE 1.3701179613921477\n",
      "9 Train Loss 43.632282 Test MSE 8.544973433947442 Test RE 1.397215576795506\n",
      "10 Train Loss 43.283806 Test MSE 8.519827708334239 Test RE 1.3951582336370094\n",
      "11 Train Loss 42.18376 Test MSE 8.4452262289152 Test RE 1.3890366479931977\n",
      "12 Train Loss 41.42 Test MSE 8.393131787810093 Test RE 1.38474587937614\n",
      "13 Train Loss 38.524185 Test MSE 8.835456848790894 Test RE 1.420766032083075\n",
      "14 Train Loss 35.090954 Test MSE 9.05509968811292 Test RE 1.4383172140586968\n",
      "15 Train Loss 33.61898 Test MSE 8.715641747280069 Test RE 1.4110998493824205\n",
      "16 Train Loss 31.05439 Test MSE 7.793752260936246 Test RE 1.3343856370158333\n",
      "17 Train Loss 29.250858 Test MSE 7.42661571262087 Test RE 1.3025773925842297\n",
      "18 Train Loss 27.292797 Test MSE 6.819154247390225 Test RE 1.2481687852894778\n",
      "19 Train Loss 25.995771 Test MSE 6.649240798766321 Test RE 1.2325203277987964\n",
      "20 Train Loss 23.465944 Test MSE 5.881887989731008 Test RE 1.1592215209481151\n",
      "21 Train Loss 19.75558 Test MSE 5.746438582922233 Test RE 1.1457963777770346\n",
      "22 Train Loss 18.246218 Test MSE 5.516724293719229 Test RE 1.1226611661748156\n",
      "23 Train Loss 16.810726 Test MSE 5.4064557673942435 Test RE 1.1113846325558494\n",
      "24 Train Loss 15.450087 Test MSE 5.279712481408751 Test RE 1.0982803074733936\n",
      "25 Train Loss 14.262145 Test MSE 5.516482610776918 Test RE 1.1226365744958462\n",
      "26 Train Loss 13.2013 Test MSE 5.382988902309761 Test RE 1.1089700122437975\n",
      "27 Train Loss 12.016733 Test MSE 5.439892303943112 Test RE 1.1148160463702357\n",
      "28 Train Loss 10.688285 Test MSE 5.195736452768688 Test RE 1.089510994675493\n",
      "29 Train Loss 9.293579 Test MSE 4.976054625704589 Test RE 1.066229342083939\n",
      "30 Train Loss 7.8846035 Test MSE 4.986792831201581 Test RE 1.0673791706551896\n",
      "31 Train Loss 7.2451534 Test MSE 4.932738100689427 Test RE 1.061578438495187\n",
      "32 Train Loss 6.3013663 Test MSE 4.653696874243232 Test RE 1.0311150029753073\n",
      "33 Train Loss 5.817386 Test MSE 4.682136017511456 Test RE 1.0342608205951889\n",
      "34 Train Loss 5.370825 Test MSE 4.539880762654327 Test RE 1.0184278886476164\n",
      "35 Train Loss 4.958017 Test MSE 4.732049499459123 Test RE 1.0397590275077482\n",
      "36 Train Loss 4.724581 Test MSE 4.72896669572074 Test RE 1.0394202847239697\n",
      "37 Train Loss 4.4611206 Test MSE 4.653937310015345 Test RE 1.031141639189103\n",
      "38 Train Loss 4.2421885 Test MSE 4.772717120637711 Test RE 1.044217356333332\n",
      "39 Train Loss 3.9218733 Test MSE 4.927299758580029 Test RE 1.0609930821748705\n",
      "40 Train Loss 3.7523005 Test MSE 4.910060967180967 Test RE 1.059135445634563\n",
      "41 Train Loss 3.5533738 Test MSE 4.992296340435216 Test RE 1.0679679971275455\n",
      "42 Train Loss 3.413172 Test MSE 5.0542168719234 Test RE 1.0745707055668643\n",
      "43 Train Loss 3.1745305 Test MSE 5.025504297510247 Test RE 1.071514086081029\n",
      "44 Train Loss 2.954812 Test MSE 4.999494550992819 Test RE 1.0687376519033538\n",
      "45 Train Loss 2.7809637 Test MSE 4.933642020519232 Test RE 1.0616757006876305\n",
      "46 Train Loss 2.6546276 Test MSE 4.84191303606419 Test RE 1.0517597646900758\n",
      "47 Train Loss 2.548234 Test MSE 4.838368933808614 Test RE 1.0513747694947213\n",
      "48 Train Loss 2.399657 Test MSE 4.922652806642456 Test RE 1.0604926511970305\n",
      "49 Train Loss 2.320244 Test MSE 4.954221695976632 Test RE 1.0638876775673318\n",
      "50 Train Loss 2.2088628 Test MSE 4.996100724907268 Test RE 1.068374842678855\n",
      "51 Train Loss 2.1125834 Test MSE 5.003273377729208 Test RE 1.0691414738827048\n",
      "52 Train Loss 2.0400126 Test MSE 5.089680270128164 Test RE 1.0783340299655346\n",
      "53 Train Loss 2.000747 Test MSE 5.10461259753383 Test RE 1.0799147033095868\n",
      "54 Train Loss 1.9348848 Test MSE 5.113233210289095 Test RE 1.0808261925898621\n",
      "55 Train Loss 1.8840705 Test MSE 5.182512065126998 Test RE 1.0881235787073547\n",
      "56 Train Loss 1.841006 Test MSE 5.17905250392141 Test RE 1.0877603322243665\n",
      "57 Train Loss 1.7650889 Test MSE 5.175958600238278 Test RE 1.0874353762153208\n",
      "58 Train Loss 1.7179313 Test MSE 5.244686509080785 Test RE 1.0946312121208381\n",
      "59 Train Loss 1.6758995 Test MSE 5.342037608948548 Test RE 1.1047436930970174\n",
      "60 Train Loss 1.6343719 Test MSE 5.408575537980591 Test RE 1.111602487808589\n",
      "61 Train Loss 1.5845125 Test MSE 5.389061474819397 Test RE 1.1095953528078193\n",
      "62 Train Loss 1.5539644 Test MSE 5.475157083831109 Test RE 1.118423676073463\n",
      "63 Train Loss 1.5218759 Test MSE 5.49764897003728 Test RE 1.1207185578465766\n",
      "64 Train Loss 1.4908694 Test MSE 5.478351902146518 Test RE 1.1187499351466528\n",
      "65 Train Loss 1.4598669 Test MSE 5.490916889490009 Test RE 1.1200321663752002\n",
      "66 Train Loss 1.4298979 Test MSE 5.571386712044483 Test RE 1.1282093959752868\n",
      "67 Train Loss 1.4032743 Test MSE 5.601499730959019 Test RE 1.1312542400769687\n",
      "68 Train Loss 1.3880041 Test MSE 5.6018563054746044 Test RE 1.131290245614129\n",
      "69 Train Loss 1.3633833 Test MSE 5.6251154434298085 Test RE 1.1336363946420531\n",
      "70 Train Loss 1.3450601 Test MSE 5.632770933392713 Test RE 1.1344075424855364\n",
      "71 Train Loss 1.3229468 Test MSE 5.637944624226567 Test RE 1.1349283986421852\n",
      "72 Train Loss 1.2973143 Test MSE 5.699568549934753 Test RE 1.1411140455422415\n",
      "73 Train Loss 1.277454 Test MSE 5.670090191627206 Test RE 1.1381592801346898\n",
      "74 Train Loss 1.258873 Test MSE 5.633641250940356 Test RE 1.1344951775650005\n",
      "75 Train Loss 1.2365601 Test MSE 5.68052181049858 Test RE 1.1392057703701843\n",
      "76 Train Loss 1.215093 Test MSE 5.715710383465922 Test RE 1.1427287861650701\n",
      "77 Train Loss 1.1952696 Test MSE 5.757291281676371 Test RE 1.1468778404183086\n",
      "78 Train Loss 1.1823907 Test MSE 5.786558743884981 Test RE 1.1497892488786674\n",
      "79 Train Loss 1.1674334 Test MSE 5.802802926223439 Test RE 1.151401977400702\n",
      "80 Train Loss 1.1559818 Test MSE 5.827741318292451 Test RE 1.1538734838130433\n",
      "81 Train Loss 1.1422198 Test MSE 5.884300798133873 Test RE 1.1594592586144137\n",
      "82 Train Loss 1.1292204 Test MSE 5.9061403853726935 Test RE 1.161608932827045\n",
      "83 Train Loss 1.1170965 Test MSE 5.909168365440935 Test RE 1.1619066634736894\n",
      "84 Train Loss 1.1005018 Test MSE 5.901775075610579 Test RE 1.161179572889667\n",
      "85 Train Loss 1.080224 Test MSE 5.917222223092871 Test RE 1.1626981999402666\n",
      "86 Train Loss 1.0628614 Test MSE 5.919143173877207 Test RE 1.1628869122022152\n",
      "87 Train Loss 1.0467296 Test MSE 5.929588011067115 Test RE 1.1639124669654608\n",
      "88 Train Loss 1.0287045 Test MSE 5.9627833806955035 Test RE 1.167165861723012\n",
      "89 Train Loss 1.0182317 Test MSE 5.960984491189457 Test RE 1.166989789521024\n",
      "90 Train Loss 1.0022588 Test MSE 5.9636365022758575 Test RE 1.167249354507123\n",
      "91 Train Loss 0.9868608 Test MSE 5.9794007874848685 Test RE 1.1687910906243153\n",
      "92 Train Loss 0.9747321 Test MSE 5.948655905928384 Test RE 1.1657823732074928\n",
      "93 Train Loss 0.9645988 Test MSE 5.9474207612815295 Test RE 1.1656613387560262\n",
      "94 Train Loss 0.9544883 Test MSE 5.977860738950763 Test RE 1.16864056459454\n",
      "95 Train Loss 0.9488132 Test MSE 5.983618400588956 Test RE 1.1692032255384415\n",
      "96 Train Loss 0.94081956 Test MSE 6.001958211072658 Test RE 1.1709936605712614\n",
      "97 Train Loss 0.9311348 Test MSE 6.037745364122796 Test RE 1.174479543483976\n",
      "98 Train Loss 0.92113394 Test MSE 6.0625014793785965 Test RE 1.1768848956528588\n",
      "99 Train Loss 0.91552204 Test MSE 6.059487613783261 Test RE 1.176592325511054\n",
      "Training time: 73.26\n",
      "KG_stan_tune3\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.202694 Test MSE 9.148007438201715 Test RE 1.445677143608586\n",
      "1 Train Loss 52.76852 Test MSE 7.934576437786207 Test RE 1.34638707671968\n",
      "2 Train Loss 44.061714 Test MSE 8.342622624385557 Test RE 1.3805729495138874\n",
      "3 Train Loss 42.429497 Test MSE 7.917205957987285 Test RE 1.344912505031637\n",
      "4 Train Loss 40.33432 Test MSE 7.942499422529581 Test RE 1.3470591190602392\n",
      "5 Train Loss 37.34469 Test MSE 7.571955944093201 Test RE 1.3152614750402132\n",
      "6 Train Loss 35.272205 Test MSE 7.302766470141915 Test RE 1.2916705765051246\n",
      "7 Train Loss 27.582245 Test MSE 5.466000954357843 Test RE 1.117488112336136\n",
      "8 Train Loss 24.564474 Test MSE 5.012409766181412 Test RE 1.0701171987542946\n",
      "9 Train Loss 22.746546 Test MSE 5.356652222737764 Test RE 1.1062538261326904\n",
      "10 Train Loss 20.94194 Test MSE 5.347788574006629 Test RE 1.1053381884788214\n",
      "11 Train Loss 18.892033 Test MSE 5.538228273562142 Test RE 1.1248470831886923\n",
      "12 Train Loss 17.534399 Test MSE 5.136950110250943 Test RE 1.0833299108600458\n",
      "13 Train Loss 15.83019 Test MSE 5.523584954424125 Test RE 1.12335902633518\n",
      "14 Train Loss 15.134722 Test MSE 5.618383388353245 Test RE 1.1329578319114808\n",
      "15 Train Loss 14.311641 Test MSE 5.693619149162234 Test RE 1.1405183234904852\n",
      "16 Train Loss 13.837303 Test MSE 5.889195882229728 Test RE 1.1599414289592382\n",
      "17 Train Loss 13.240869 Test MSE 5.856162081593906 Test RE 1.156683670309042\n",
      "18 Train Loss 12.839018 Test MSE 5.770344939008837 Test RE 1.148177277358241\n",
      "19 Train Loss 12.512861 Test MSE 5.831317438686196 Test RE 1.1542274595164195\n",
      "20 Train Loss 12.300318 Test MSE 5.794305293944021 Test RE 1.1505586112417312\n",
      "21 Train Loss 12.0663185 Test MSE 5.822414674433158 Test RE 1.1533460343381883\n",
      "22 Train Loss 11.823113 Test MSE 5.853931849041326 Test RE 1.1564633964169426\n",
      "23 Train Loss 11.333548 Test MSE 5.8532628747438435 Test RE 1.1563973154979992\n",
      "24 Train Loss 10.471796 Test MSE 5.660893300690443 Test RE 1.1372358578923392\n",
      "25 Train Loss 9.832849 Test MSE 5.666616859403501 Test RE 1.1378106251080584\n",
      "26 Train Loss 9.442163 Test MSE 5.226567718719456 Test RE 1.0927387679629932\n",
      "27 Train Loss 8.973497 Test MSE 4.829029618023809 Test RE 1.05035956539799\n",
      "28 Train Loss 8.60016 Test MSE 4.645001397413049 Test RE 1.0301512284688579\n",
      "29 Train Loss 8.395471 Test MSE 4.494577217223354 Test RE 1.0133336936225723\n",
      "30 Train Loss 8.140539 Test MSE 4.2596349006006005 Test RE 0.9864935467796603\n",
      "31 Train Loss 7.9591827 Test MSE 4.066416400533728 Test RE 0.9638600597232582\n",
      "32 Train Loss 7.7882223 Test MSE 3.948430324320658 Test RE 0.9497740502763237\n",
      "33 Train Loss 7.6580086 Test MSE 3.863465362567363 Test RE 0.9394995399465563\n",
      "34 Train Loss 7.588109 Test MSE 3.8946317633455894 Test RE 0.9432813784876765\n",
      "35 Train Loss 7.5197535 Test MSE 3.8655192433429537 Test RE 0.9397492333534512\n",
      "36 Train Loss 7.452523 Test MSE 3.838406034836367 Test RE 0.9364476777350893\n",
      "37 Train Loss 7.4013762 Test MSE 3.8233999726428483 Test RE 0.934615386783552\n",
      "38 Train Loss 7.349227 Test MSE 3.7667093195981813 Test RE 0.927660604549033\n",
      "39 Train Loss 7.2765703 Test MSE 3.7471535294068308 Test RE 0.9252493827152053\n",
      "40 Train Loss 7.1805305 Test MSE 3.7600629710911257 Test RE 0.9268418158757482\n",
      "41 Train Loss 7.0705724 Test MSE 3.7429875492623177 Test RE 0.9247349065303274\n",
      "42 Train Loss 6.9288235 Test MSE 3.7344134337610924 Test RE 0.9236751474949063\n",
      "43 Train Loss 6.6026573 Test MSE 3.773582847920167 Test RE 0.9285066208811157\n",
      "44 Train Loss 6.276694 Test MSE 3.728594322415099 Test RE 0.9229552132761183\n",
      "45 Train Loss 5.3329883 Test MSE 3.316816236438695 Test RE 0.8704999803176439\n",
      "46 Train Loss 4.1976595 Test MSE 3.0324262977181475 Test RE 0.8323446404426029\n",
      "47 Train Loss 3.146162 Test MSE 2.378505903654901 Test RE 0.7371573109733001\n",
      "48 Train Loss 2.3518775 Test MSE 1.5475511464852019 Test RE 0.5946077507326858\n",
      "49 Train Loss 1.7385813 Test MSE 1.0123797564446904 Test RE 0.4809276940510713\n",
      "50 Train Loss 1.2418875 Test MSE 0.5942535947533938 Test RE 0.3684630723474305\n",
      "51 Train Loss 0.88046986 Test MSE 0.4537461476329706 Test RE 0.3219693536117286\n",
      "52 Train Loss 0.68022853 Test MSE 0.27158862505837794 Test RE 0.24909433370668072\n",
      "53 Train Loss 0.45041743 Test MSE 0.1047997911211287 Test RE 0.154734896514288\n",
      "54 Train Loss 0.3570036 Test MSE 0.07956237629619639 Test RE 0.1348223625376054\n",
      "55 Train Loss 0.25930265 Test MSE 0.063734051646462 Test RE 0.12066847502033377\n",
      "56 Train Loss 0.18103632 Test MSE 0.06098072282328237 Test RE 0.11803324423903494\n",
      "57 Train Loss 0.1529758 Test MSE 0.046583909604516444 Test RE 0.10316349039189161\n",
      "58 Train Loss 0.11516836 Test MSE 0.028658774515310147 Test RE 0.0809164587670737\n",
      "59 Train Loss 0.09581762 Test MSE 0.026277551583847644 Test RE 0.07748194407478182\n",
      "60 Train Loss 0.078118466 Test MSE 0.016492224331207606 Test RE 0.06138293879464972\n",
      "61 Train Loss 0.06291344 Test MSE 0.016361335309185054 Test RE 0.0611388735547457\n",
      "62 Train Loss 0.05330892 Test MSE 0.01421315597504818 Test RE 0.0569840511651144\n",
      "63 Train Loss 0.045977402 Test MSE 0.011588728770388364 Test RE 0.05145480770684913\n",
      "64 Train Loss 0.039584935 Test MSE 0.01106657348345889 Test RE 0.05028224344106977\n",
      "65 Train Loss 0.034389462 Test MSE 0.009786043157612022 Test RE 0.04728371855543807\n",
      "66 Train Loss 0.029225793 Test MSE 0.008627294912027787 Test RE 0.044396157384475145\n",
      "67 Train Loss 0.02696741 Test MSE 0.006849924909924742 Test RE 0.03955951564940352\n",
      "68 Train Loss 0.025039058 Test MSE 0.005720176868237533 Test RE 0.03615037352250872\n",
      "69 Train Loss 0.022204084 Test MSE 0.005256130169495154 Test RE 0.034653022162789024\n",
      "70 Train Loss 0.018473579 Test MSE 0.004289989638034064 Test RE 0.03130662000491729\n",
      "71 Train Loss 0.016614364 Test MSE 0.003745976257075381 Test RE 0.029254357912870458\n",
      "72 Train Loss 0.014314208 Test MSE 0.0032846086221434917 Test RE 0.027393648230805975\n",
      "73 Train Loss 0.013472642 Test MSE 0.003521090534450287 Test RE 0.028362640233824836\n",
      "74 Train Loss 0.012389762 Test MSE 0.003259124889832836 Test RE 0.027287174096460684\n",
      "75 Train Loss 0.011633644 Test MSE 0.0030755966542646155 Test RE 0.026507742929390937\n",
      "76 Train Loss 0.010730893 Test MSE 0.002659735401563717 Test RE 0.024650587664069492\n",
      "77 Train Loss 0.009509912 Test MSE 0.002136483437063067 Test RE 0.022093159373723095\n",
      "78 Train Loss 0.008885281 Test MSE 0.0020977135621098606 Test RE 0.021891783942144444\n",
      "79 Train Loss 0.008276633 Test MSE 0.002049195940221588 Test RE 0.02163713743684087\n",
      "80 Train Loss 0.00776048 Test MSE 0.0019848121223294372 Test RE 0.021294515443357514\n",
      "81 Train Loss 0.0074952496 Test MSE 0.001985499642220017 Test RE 0.021298203232029946\n",
      "82 Train Loss 0.006555709 Test MSE 0.0016180820262416038 Test RE 0.019226858368242776\n",
      "83 Train Loss 0.0059134914 Test MSE 0.00153907534612372 Test RE 0.018751585782539104\n",
      "84 Train Loss 0.005661842 Test MSE 0.0015692124950001394 Test RE 0.018934286273628476\n",
      "85 Train Loss 0.0053763343 Test MSE 0.0015132357134803466 Test RE 0.01859350870690385\n",
      "86 Train Loss 0.005143312 Test MSE 0.0013561910313586742 Test RE 0.01760226254097954\n",
      "87 Train Loss 0.004777867 Test MSE 0.0012911003725236654 Test RE 0.017174656647942158\n",
      "88 Train Loss 0.004579718 Test MSE 0.0013387965437615076 Test RE 0.01748901505224267\n",
      "89 Train Loss 0.0043311953 Test MSE 0.0013087982432409655 Test RE 0.017291967554203296\n",
      "90 Train Loss 0.0041262507 Test MSE 0.0013677011881928938 Test RE 0.017676800983416965\n",
      "91 Train Loss 0.003978337 Test MSE 0.0012887787211769987 Test RE 0.017159208001640707\n",
      "92 Train Loss 0.0038001589 Test MSE 0.001019255867457717 Test RE 0.015259829119054621\n",
      "93 Train Loss 0.003479407 Test MSE 0.000898941003731507 Test RE 0.014330906269641919\n",
      "94 Train Loss 0.0032454468 Test MSE 0.0009096542244702673 Test RE 0.014416048364272032\n",
      "95 Train Loss 0.0030266999 Test MSE 0.0007028413888599123 Test RE 0.012671753741994137\n",
      "96 Train Loss 0.0028438168 Test MSE 0.0006609456632535343 Test RE 0.012288275482487395\n",
      "97 Train Loss 0.002710028 Test MSE 0.0006545360192204228 Test RE 0.0122285463977468\n",
      "98 Train Loss 0.0026046978 Test MSE 0.000574820371707136 Test RE 0.011459723414628331\n",
      "99 Train Loss 0.0024830995 Test MSE 0.0005759489837682789 Test RE 0.011470968005478425\n",
      "Training time: 73.31\n",
      "KG_stan_tune3\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.829372 Test MSE 7.641313213849876 Test RE 1.3212714810338049\n",
      "1 Train Loss 51.884903 Test MSE 8.592174812631225 Test RE 1.4010692854772577\n",
      "2 Train Loss 48.617737 Test MSE 8.2850143082866 Test RE 1.3757980566843457\n",
      "3 Train Loss 44.62744 Test MSE 8.664109013490485 Test RE 1.4069219791157588\n",
      "4 Train Loss 43.50879 Test MSE 8.526807440839397 Test RE 1.3957295971687824\n",
      "5 Train Loss 42.63637 Test MSE 8.59141252997905 Test RE 1.4010071338961287\n",
      "6 Train Loss 41.7985 Test MSE 8.527678923344535 Test RE 1.3958009206304942\n",
      "7 Train Loss 40.922333 Test MSE 8.526170062927461 Test RE 1.3956774308774962\n",
      "8 Train Loss 39.42581 Test MSE 8.56638581535726 Test RE 1.3989650845165769\n",
      "9 Train Loss 35.536224 Test MSE 7.334982593364245 Test RE 1.294516540846456\n",
      "10 Train Loss 33.558716 Test MSE 6.9193334002480285 Test RE 1.257303686185095\n",
      "11 Train Loss 32.30529 Test MSE 7.219432845242207 Test RE 1.284279649263594\n",
      "12 Train Loss 30.552776 Test MSE 7.580465496193688 Test RE 1.3160003292645184\n",
      "13 Train Loss 27.396759 Test MSE 7.382559542866957 Test RE 1.2987080708447485\n",
      "14 Train Loss 25.045212 Test MSE 7.317415505425648 Test RE 1.2929654452641033\n",
      "15 Train Loss 22.361443 Test MSE 7.185210901427838 Test RE 1.2812321277379568\n",
      "16 Train Loss 19.864033 Test MSE 7.171097331044747 Test RE 1.2799731773348557\n",
      "17 Train Loss 16.641111 Test MSE 6.898170865511264 Test RE 1.2553795045287506\n",
      "18 Train Loss 14.949911 Test MSE 6.93731278808458 Test RE 1.258936132811144\n",
      "19 Train Loss 13.880098 Test MSE 7.010215164732472 Test RE 1.2655337575816903\n",
      "20 Train Loss 12.265097 Test MSE 6.811734794632259 Test RE 1.247489577182259\n",
      "21 Train Loss 10.536606 Test MSE 6.546085388149499 Test RE 1.2229223812463592\n",
      "22 Train Loss 8.305944 Test MSE 6.061007593096362 Test RE 1.1767398861606644\n",
      "23 Train Loss 5.5625453 Test MSE 5.314550123775931 Test RE 1.101897794973038\n",
      "24 Train Loss 3.9972677 Test MSE 5.331012185703334 Test RE 1.1036030648491149\n",
      "25 Train Loss 3.1958833 Test MSE 5.387159420721622 Test RE 1.1093995212465082\n",
      "26 Train Loss 2.7220588 Test MSE 5.348925462784387 Test RE 1.1054556744063269\n",
      "27 Train Loss 2.2980447 Test MSE 5.282165778789892 Test RE 1.0985354440253368\n",
      "28 Train Loss 2.0618265 Test MSE 5.399438017843733 Test RE 1.1106630922383132\n",
      "29 Train Loss 1.8605772 Test MSE 5.515009008380745 Test RE 1.1224866211146656\n",
      "30 Train Loss 1.6432154 Test MSE 5.540917729279052 Test RE 1.1251201722600714\n",
      "31 Train Loss 1.5395893 Test MSE 5.599747779285024 Test RE 1.131077318016236\n",
      "32 Train Loss 1.4635084 Test MSE 5.599997901418002 Test RE 1.1311025784675481\n",
      "33 Train Loss 1.3923261 Test MSE 5.617389291533672 Test RE 1.132857596708264\n",
      "34 Train Loss 1.334801 Test MSE 5.6438075505160565 Test RE 1.135518354114004\n",
      "35 Train Loss 1.2826083 Test MSE 5.702514574054131 Test RE 1.141408920073011\n",
      "36 Train Loss 1.230129 Test MSE 5.725486015731029 Test RE 1.1437055784884702\n",
      "37 Train Loss 1.1850313 Test MSE 5.778436522808698 Test RE 1.148982022833847\n",
      "38 Train Loss 1.1459103 Test MSE 5.8655809555605645 Test RE 1.1576134841033012\n",
      "39 Train Loss 1.1226001 Test MSE 5.882097433867429 Test RE 1.1592421597285103\n",
      "40 Train Loss 1.0927038 Test MSE 5.902930279706342 Test RE 1.1612932110533476\n",
      "41 Train Loss 1.0710392 Test MSE 5.883841889611724 Test RE 1.1594140454168154\n",
      "42 Train Loss 1.0441574 Test MSE 5.903403864238338 Test RE 1.161339794652119\n",
      "43 Train Loss 1.013866 Test MSE 5.948620686336758 Test RE 1.1657789221388368\n",
      "44 Train Loss 0.98899144 Test MSE 6.002886064159301 Test RE 1.171084170039677\n",
      "45 Train Loss 0.97105145 Test MSE 6.030014199811514 Test RE 1.1737273584921128\n",
      "46 Train Loss 0.9576686 Test MSE 6.042999251663265 Test RE 1.1749904330033079\n",
      "47 Train Loss 0.9441892 Test MSE 6.063868823554807 Test RE 1.1770176062169897\n",
      "48 Train Loss 0.92649186 Test MSE 6.06672582091026 Test RE 1.1772948500270346\n",
      "49 Train Loss 0.9102323 Test MSE 6.083369050022993 Test RE 1.1789086173661334\n",
      "50 Train Loss 0.8928201 Test MSE 6.086580876179129 Test RE 1.1792197895021947\n",
      "51 Train Loss 0.8768745 Test MSE 6.1403802550897995 Test RE 1.1844198944624362\n",
      "52 Train Loss 0.86118406 Test MSE 6.2118034809178315 Test RE 1.191288403391546\n",
      "53 Train Loss 0.8456859 Test MSE 6.244288089050078 Test RE 1.1943992612496814\n",
      "54 Train Loss 0.83874947 Test MSE 6.2526971854866975 Test RE 1.1952032311527\n",
      "55 Train Loss 0.8285199 Test MSE 6.2471264253039935 Test RE 1.1946706870328494\n",
      "56 Train Loss 0.8209923 Test MSE 6.25962008156535 Test RE 1.1958647039936434\n",
      "57 Train Loss 0.81263614 Test MSE 6.269347031462885 Test RE 1.1967934824635091\n",
      "58 Train Loss 0.80291784 Test MSE 6.26387846196331 Test RE 1.1962714044764442\n",
      "59 Train Loss 0.79502225 Test MSE 6.275787623561254 Test RE 1.1974080664045212\n",
      "60 Train Loss 0.7874977 Test MSE 6.296088797507651 Test RE 1.1993432149359982\n",
      "61 Train Loss 0.778671 Test MSE 6.305810048491287 Test RE 1.2002687593329433\n",
      "62 Train Loss 0.76981294 Test MSE 6.320896629081057 Test RE 1.201703716411939\n",
      "63 Train Loss 0.76298016 Test MSE 6.316058257395417 Test RE 1.201243702378349\n",
      "64 Train Loss 0.75276804 Test MSE 6.32660337996275 Test RE 1.2022460664111931\n",
      "65 Train Loss 0.74569184 Test MSE 6.346718899490029 Test RE 1.2041558282606457\n",
      "66 Train Loss 0.74020696 Test MSE 6.359237538595934 Test RE 1.2053428168762546\n",
      "67 Train Loss 0.7301055 Test MSE 6.398694997592546 Test RE 1.2090764577727886\n",
      "68 Train Loss 0.7231939 Test MSE 6.418000839663436 Test RE 1.2108990683901404\n",
      "69 Train Loss 0.71708155 Test MSE 6.422518874875058 Test RE 1.2113252074853977\n",
      "70 Train Loss 0.7111435 Test MSE 6.414314050436404 Test RE 1.2105512209011635\n",
      "71 Train Loss 0.70379007 Test MSE 6.4353017634347465 Test RE 1.2125300726199306\n",
      "72 Train Loss 0.6976999 Test MSE 6.4476666571334516 Test RE 1.2136944011208073\n",
      "73 Train Loss 0.6898107 Test MSE 6.481325415417149 Test RE 1.2168582023178096\n",
      "74 Train Loss 0.6833302 Test MSE 6.507112408204296 Test RE 1.2192765320500845\n",
      "75 Train Loss 0.677475 Test MSE 6.52153475728247 Test RE 1.2206269850393183\n",
      "76 Train Loss 0.6723173 Test MSE 6.5384410160816415 Test RE 1.222208121962587\n",
      "77 Train Loss 0.6662277 Test MSE 6.528381582656702 Test RE 1.2212675725470523\n",
      "78 Train Loss 0.6610838 Test MSE 6.519049933448675 Test RE 1.220394422298818\n",
      "79 Train Loss 0.65396774 Test MSE 6.557671310842476 Test RE 1.22400412854867\n",
      "80 Train Loss 0.64635515 Test MSE 6.585358999949879 Test RE 1.2265853915617795\n",
      "81 Train Loss 0.63986516 Test MSE 6.578395544429634 Test RE 1.2259367153144065\n",
      "82 Train Loss 0.6347723 Test MSE 6.59585840403286 Test RE 1.2275628087810087\n",
      "83 Train Loss 0.630804 Test MSE 6.607092129281566 Test RE 1.2286077248345357\n",
      "84 Train Loss 0.6273588 Test MSE 6.6112926662780716 Test RE 1.228998213728907\n",
      "85 Train Loss 0.62433153 Test MSE 6.620881575320523 Test RE 1.229889150091377\n",
      "86 Train Loss 0.621017 Test MSE 6.638099675897269 Test RE 1.2314873213500366\n",
      "87 Train Loss 0.61483085 Test MSE 6.652171579682492 Test RE 1.232791926407619\n",
      "88 Train Loss 0.6104054 Test MSE 6.647889422605695 Test RE 1.2323950741589016\n",
      "89 Train Loss 0.6073655 Test MSE 6.672291530529803 Test RE 1.234654850855875\n",
      "90 Train Loss 0.6031945 Test MSE 6.693469385240509 Test RE 1.2366126959136814\n",
      "91 Train Loss 0.59890616 Test MSE 6.699730878075348 Test RE 1.237190963408735\n",
      "92 Train Loss 0.59321296 Test MSE 6.729427392137655 Test RE 1.239929852235054\n",
      "93 Train Loss 0.5887883 Test MSE 6.7382865161775936 Test RE 1.2407457522240841\n",
      "94 Train Loss 0.5852592 Test MSE 6.731567023338381 Test RE 1.2401269553165475\n",
      "95 Train Loss 0.58170474 Test MSE 6.7438668214545565 Test RE 1.2412594070807774\n",
      "96 Train Loss 0.5770607 Test MSE 6.764418236753209 Test RE 1.243149289631486\n",
      "97 Train Loss 0.57368004 Test MSE 6.771473812962692 Test RE 1.2437974494784374\n",
      "98 Train Loss 0.5699656 Test MSE 6.782340529155684 Test RE 1.2447950591613859\n",
      "99 Train Loss 0.56566423 Test MSE 6.797922615084701 Test RE 1.2462241657986204\n",
      "Training time: 73.53\n",
      "KG_stan_tune3\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.07481 Test MSE 8.819394921279674 Test RE 1.4194740433357411\n",
      "1 Train Loss 46.166283 Test MSE 9.071429853419316 Test RE 1.4396135762491082\n",
      "2 Train Loss 43.914986 Test MSE 8.505325975997774 Test RE 1.3939703675973405\n",
      "3 Train Loss 42.228607 Test MSE 8.60779756475889 Test RE 1.402342456585627\n",
      "4 Train Loss 41.63797 Test MSE 8.507463463317643 Test RE 1.3941455170751673\n",
      "5 Train Loss 40.643948 Test MSE 8.407719719972187 Test RE 1.3859487562953974\n",
      "6 Train Loss 39.15442 Test MSE 8.820432424245213 Test RE 1.4195575334863264\n",
      "7 Train Loss 38.057617 Test MSE 8.35045834924522 Test RE 1.3812211420149152\n",
      "8 Train Loss 36.277397 Test MSE 8.489078333136256 Test RE 1.3926382869978335\n",
      "9 Train Loss 33.948742 Test MSE 8.360348626513638 Test RE 1.3820388586579324\n",
      "10 Train Loss 31.453812 Test MSE 8.260908893961355 Test RE 1.3737951428046167\n",
      "11 Train Loss 30.311604 Test MSE 8.005014488720995 Test RE 1.3523500500520569\n",
      "12 Train Loss 27.382069 Test MSE 7.805174497013154 Test RE 1.3353630922219581\n",
      "13 Train Loss 25.138313 Test MSE 7.609208091277225 Test RE 1.3184928857726224\n",
      "14 Train Loss 23.669552 Test MSE 7.454133779467744 Test RE 1.3049884012234416\n",
      "15 Train Loss 21.662066 Test MSE 6.9501518572696 Test RE 1.2601005675806525\n",
      "16 Train Loss 19.333675 Test MSE 6.017282670460202 Test RE 1.1724876234059658\n",
      "17 Train Loss 16.576986 Test MSE 5.772739609673093 Test RE 1.1484154971937166\n",
      "18 Train Loss 13.906047 Test MSE 4.758516736485547 Test RE 1.042662756154263\n",
      "19 Train Loss 11.634085 Test MSE 4.211283517443252 Test RE 0.9808786925760755\n",
      "20 Train Loss 10.363621 Test MSE 3.813997286621418 Test RE 0.9334654541776036\n",
      "21 Train Loss 9.227331 Test MSE 3.5330685438121257 Test RE 0.8984296825748325\n",
      "22 Train Loss 8.194799 Test MSE 3.3607001596019233 Test RE 0.876239735535995\n",
      "23 Train Loss 7.6788616 Test MSE 3.273905495711426 Test RE 0.8648506770756812\n",
      "24 Train Loss 7.276739 Test MSE 3.3249853063438946 Test RE 0.8715713091908627\n",
      "25 Train Loss 6.8014708 Test MSE 3.311402206801931 Test RE 0.8697892328499142\n",
      "26 Train Loss 6.3302994 Test MSE 3.325685421543682 Test RE 0.8716630642133956\n",
      "27 Train Loss 5.754839 Test MSE 3.206777866062402 Test RE 0.8559383770608265\n",
      "28 Train Loss 5.206099 Test MSE 3.0600222451798063 Test RE 0.8361233503369305\n",
      "29 Train Loss 3.9384902 Test MSE 2.868223049245402 Test RE 0.8094956531900499\n",
      "30 Train Loss 3.1428428 Test MSE 2.4605613335247463 Test RE 0.7497649907683318\n",
      "31 Train Loss 2.5409024 Test MSE 2.3921935564978205 Test RE 0.739275337826647\n",
      "32 Train Loss 2.0443408 Test MSE 2.513658288597006 Test RE 0.7578114791151094\n",
      "33 Train Loss 1.7899816 Test MSE 2.4582471122766942 Test RE 0.7494123211919337\n",
      "34 Train Loss 1.6106521 Test MSE 2.5034853283077725 Test RE 0.7562764650176823\n",
      "35 Train Loss 1.4924158 Test MSE 2.5053469373319093 Test RE 0.7565575989720097\n",
      "36 Train Loss 1.3734689 Test MSE 2.526632542634773 Test RE 0.7597646849865353\n",
      "37 Train Loss 1.2846838 Test MSE 2.5603732449102528 Test RE 0.7648208175576753\n",
      "38 Train Loss 1.2091864 Test MSE 2.6027380759669367 Test RE 0.7711223539963328\n",
      "39 Train Loss 1.1455979 Test MSE 2.663971944558197 Test RE 0.780140606591328\n",
      "40 Train Loss 1.0626236 Test MSE 2.701229591794824 Test RE 0.7855770902463828\n",
      "41 Train Loss 1.0077376 Test MSE 2.7342560242884892 Test RE 0.7903649073861791\n",
      "42 Train Loss 0.96048325 Test MSE 2.750202929117672 Test RE 0.7926663652526756\n",
      "43 Train Loss 0.90205175 Test MSE 2.7583980722172075 Test RE 0.7938464931194852\n",
      "44 Train Loss 0.8697543 Test MSE 2.7662264311363214 Test RE 0.7949721668157894\n",
      "45 Train Loss 0.82411754 Test MSE 2.809818478480496 Test RE 0.8012115335840213\n",
      "46 Train Loss 0.79775417 Test MSE 2.8818377525782943 Test RE 0.8114146105768502\n",
      "47 Train Loss 0.7630729 Test MSE 2.891783758354779 Test RE 0.8128136107733701\n",
      "48 Train Loss 0.72761065 Test MSE 2.8793191450664835 Test RE 0.8110599615963553\n",
      "49 Train Loss 0.68897444 Test MSE 2.895126135362794 Test RE 0.8132832076023895\n",
      "50 Train Loss 0.65220785 Test MSE 2.9287984226398374 Test RE 0.817999053716029\n",
      "51 Train Loss 0.61848164 Test MSE 2.950881994891139 Test RE 0.8210771790134005\n",
      "52 Train Loss 0.59645027 Test MSE 2.9706948461805625 Test RE 0.8238290113226325\n",
      "53 Train Loss 0.556221 Test MSE 3.006014706543068 Test RE 0.8287119678823842\n",
      "54 Train Loss 0.527533 Test MSE 2.9814268519294744 Test RE 0.8253157623060353\n",
      "55 Train Loss 0.5016499 Test MSE 2.9884648982654616 Test RE 0.8262893207580742\n",
      "56 Train Loss 0.4875406 Test MSE 3.0151104003719826 Test RE 0.829964792255779\n",
      "57 Train Loss 0.47489345 Test MSE 3.0392187294778945 Test RE 0.8332763171283312\n",
      "58 Train Loss 0.4627221 Test MSE 3.0433283388874632 Test RE 0.8338395018897102\n",
      "59 Train Loss 0.45154342 Test MSE 3.061828239167755 Test RE 0.8363700496886034\n",
      "60 Train Loss 0.4377239 Test MSE 3.0967040951788527 Test RE 0.8411199125019974\n",
      "61 Train Loss 0.43102482 Test MSE 3.1132653242478487 Test RE 0.8433660755690539\n",
      "62 Train Loss 0.42039695 Test MSE 3.159054034891524 Test RE 0.8495453899161629\n",
      "63 Train Loss 0.40942678 Test MSE 3.1809832266105276 Test RE 0.8524889332329314\n",
      "64 Train Loss 0.4024852 Test MSE 3.1988477672603266 Test RE 0.8548793892355975\n",
      "65 Train Loss 0.39635733 Test MSE 3.2087206764180567 Test RE 0.856197620797004\n",
      "66 Train Loss 0.3920559 Test MSE 3.221289238854274 Test RE 0.8578728454496068\n",
      "67 Train Loss 0.38669538 Test MSE 3.2561279433936643 Test RE 0.86249937878794\n",
      "68 Train Loss 0.38040712 Test MSE 3.2726952489443466 Test RE 0.8646908099864259\n",
      "69 Train Loss 0.37564588 Test MSE 3.265977774618154 Test RE 0.8638029298812112\n",
      "70 Train Loss 0.37063414 Test MSE 3.2685604054211614 Test RE 0.8641443962589244\n",
      "71 Train Loss 0.36483312 Test MSE 3.282132912513501 Test RE 0.86593669227291\n",
      "72 Train Loss 0.3601582 Test MSE 3.2956704681082503 Test RE 0.8677206850910566\n",
      "73 Train Loss 0.3543046 Test MSE 3.3102702279782528 Test RE 0.8696405545727555\n",
      "74 Train Loss 0.34964955 Test MSE 3.327261134470618 Test RE 0.8718695371554152\n",
      "75 Train Loss 0.34531033 Test MSE 3.337076079644458 Test RE 0.8731545355234032\n",
      "76 Train Loss 0.34268352 Test MSE 3.350823127972632 Test RE 0.874951162397546\n",
      "77 Train Loss 0.33894727 Test MSE 3.3696309331739793 Test RE 0.8774032291979303\n",
      "78 Train Loss 0.33502504 Test MSE 3.3727134096382216 Test RE 0.8778044536370736\n",
      "79 Train Loss 0.3323258 Test MSE 3.370753283403972 Test RE 0.8775493389276452\n",
      "80 Train Loss 0.32942322 Test MSE 3.3732445352056755 Test RE 0.8778735680233913\n",
      "81 Train Loss 0.32694906 Test MSE 3.385255709243762 Test RE 0.8794351095094869\n",
      "82 Train Loss 0.32461786 Test MSE 3.3923354272173816 Test RE 0.8803542277735342\n",
      "83 Train Loss 0.3223613 Test MSE 3.396411776966567 Test RE 0.8808830012989121\n",
      "84 Train Loss 0.3191172 Test MSE 3.4103948768047228 Test RE 0.8826944458416429\n",
      "85 Train Loss 0.3153 Test MSE 3.418594585131664 Test RE 0.88375495231486\n",
      "86 Train Loss 0.3107499 Test MSE 3.4281826932760273 Test RE 0.8849934151896287\n",
      "87 Train Loss 0.30753577 Test MSE 3.439514428859457 Test RE 0.8864548655727058\n",
      "88 Train Loss 0.30546337 Test MSE 3.4410511240293933 Test RE 0.8866528671833099\n",
      "89 Train Loss 0.30235472 Test MSE 3.4453708275127153 Test RE 0.8872092198904303\n",
      "90 Train Loss 0.30024636 Test MSE 3.455181118373332 Test RE 0.8884714343213943\n",
      "91 Train Loss 0.29838753 Test MSE 3.4667758354844276 Test RE 0.8899609288931284\n",
      "92 Train Loss 0.2955338 Test MSE 3.4818338882010065 Test RE 0.8918916216653063\n",
      "93 Train Loss 0.2926863 Test MSE 3.493944134561541 Test RE 0.8934413296761003\n",
      "94 Train Loss 0.29169604 Test MSE 3.4960282165147527 Test RE 0.8937077517049663\n",
      "95 Train Loss 0.29025456 Test MSE 3.4999317347399765 Test RE 0.8942065507730489\n",
      "96 Train Loss 0.28821316 Test MSE 3.511024780968785 Test RE 0.8956225251171038\n",
      "97 Train Loss 0.28650573 Test MSE 3.5109855742533758 Test RE 0.8956175245093501\n",
      "98 Train Loss 0.28547913 Test MSE 3.5075408201649467 Test RE 0.895178055422796\n",
      "99 Train Loss 0.2844094 Test MSE 3.5149135567083736 Test RE 0.8961183791054768\n",
      "Training time: 73.55\n",
      "KG_stan_tune4\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.79895 Test MSE 8.608749623848272 Test RE 1.402420006966948\n",
      "1 Train Loss 57.74518 Test MSE 8.302017630252367 Test RE 1.377209107186092\n",
      "2 Train Loss 56.37274 Test MSE 8.409747170457429 Test RE 1.3861158511316911\n",
      "3 Train Loss 50.65202 Test MSE 7.7001415525539985 Test RE 1.3263477797803103\n",
      "4 Train Loss 40.801773 Test MSE 7.959110648648977 Test RE 1.348467027012268\n",
      "5 Train Loss 37.81787 Test MSE 7.663061462435 Test RE 1.3231504069891458\n",
      "6 Train Loss 35.861504 Test MSE 7.432915677350655 Test RE 1.3031297607400265\n",
      "7 Train Loss 33.56617 Test MSE 6.776840520743495 Test RE 1.2442902355082435\n",
      "8 Train Loss 32.1264 Test MSE 6.336771143261512 Test RE 1.2032117698973321\n",
      "9 Train Loss 30.351496 Test MSE 6.670088097091887 Test RE 1.2344509700446387\n",
      "10 Train Loss 27.991726 Test MSE 6.325559213180668 Test RE 1.2021468506762985\n",
      "11 Train Loss 26.930481 Test MSE 6.1058123160400415 Test RE 1.1810812786932243\n",
      "12 Train Loss 26.426067 Test MSE 6.141795995473476 Test RE 1.184556427898786\n",
      "13 Train Loss 25.604193 Test MSE 6.315161146538423 Test RE 1.2011583891186812\n",
      "14 Train Loss 25.232376 Test MSE 6.235137708910183 Test RE 1.1935238040338279\n",
      "15 Train Loss 24.302248 Test MSE 6.2278320054345615 Test RE 1.19282437387895\n",
      "16 Train Loss 23.761217 Test MSE 5.815202084225309 Test RE 1.152631451937896\n",
      "17 Train Loss 23.441326 Test MSE 5.964163219633653 Test RE 1.167300899979505\n",
      "18 Train Loss 23.207386 Test MSE 5.9178433593202495 Test RE 1.1627592230854957\n",
      "19 Train Loss 22.997406 Test MSE 5.758213901198747 Test RE 1.146969731678013\n",
      "20 Train Loss 22.926699 Test MSE 5.778717993631609 Test RE 1.1490100062663886\n",
      "21 Train Loss 22.611816 Test MSE 5.831786195186029 Test RE 1.1542738504698193\n",
      "22 Train Loss 22.40384 Test MSE 5.876559759962678 Test RE 1.1586963496034224\n",
      "23 Train Loss 22.193687 Test MSE 5.817314949314621 Test RE 1.1528408284606972\n",
      "24 Train Loss 21.331276 Test MSE 5.766535536774242 Test RE 1.1477982193258554\n",
      "25 Train Loss 20.73243 Test MSE 5.557409376538139 Test RE 1.1267932975314938\n",
      "26 Train Loss 19.158842 Test MSE 4.860093106536563 Test RE 1.0537324510551491\n",
      "27 Train Loss 18.316181 Test MSE 4.871249300481879 Test RE 1.054941162995974\n",
      "28 Train Loss 17.561024 Test MSE 5.032115497239035 Test RE 1.0722186586916969\n",
      "29 Train Loss 16.78203 Test MSE 4.756391644928174 Test RE 1.0424299103558814\n",
      "30 Train Loss 15.514175 Test MSE 4.683308874465453 Test RE 1.034390351650588\n",
      "31 Train Loss 12.609506 Test MSE 4.148613763887703 Test RE 0.9735529166707223\n",
      "32 Train Loss 10.412012 Test MSE 4.278084913384701 Test RE 0.9886276677743109\n",
      "33 Train Loss 8.767794 Test MSE 4.181542043965002 Test RE 0.9774089110794401\n",
      "34 Train Loss 8.210726 Test MSE 4.300524965826608 Test RE 0.9912171256011135\n",
      "35 Train Loss 7.5928993 Test MSE 3.978879842269597 Test RE 0.9534292520820828\n",
      "36 Train Loss 6.851572 Test MSE 3.812979910191067 Test RE 0.9333409458179466\n",
      "37 Train Loss 6.2737436 Test MSE 3.7622611481801806 Test RE 0.9271126976111053\n",
      "38 Train Loss 6.045314 Test MSE 3.663920143589519 Test RE 0.9149156575623908\n",
      "39 Train Loss 5.6957994 Test MSE 3.528782496820251 Test RE 0.8978845643091659\n",
      "40 Train Loss 5.4704657 Test MSE 3.3934845172991204 Test RE 0.8805033169013763\n",
      "41 Train Loss 5.3120914 Test MSE 3.260600237785741 Test RE 0.8630914973397991\n",
      "42 Train Loss 5.1728706 Test MSE 3.233334807080803 Test RE 0.8594752975900817\n",
      "43 Train Loss 5.0339413 Test MSE 3.1443095368418894 Test RE 0.8475604965827991\n",
      "44 Train Loss 4.961838 Test MSE 3.111513086787556 Test RE 0.8431287065257578\n",
      "45 Train Loss 4.84723 Test MSE 3.0297244585240963 Test RE 0.8319737554978324\n",
      "46 Train Loss 4.7332234 Test MSE 2.7625208435664694 Test RE 0.7944395231109519\n",
      "47 Train Loss 4.636654 Test MSE 2.665931870967646 Test RE 0.7804275347351736\n",
      "48 Train Loss 4.5311565 Test MSE 2.5832807094055563 Test RE 0.7682345956710807\n",
      "49 Train Loss 4.385617 Test MSE 2.425188230038549 Test RE 0.7443561590237108\n",
      "50 Train Loss 4.3237247 Test MSE 2.368867316144996 Test RE 0.7356621774018438\n",
      "51 Train Loss 4.251882 Test MSE 2.2993486551412534 Test RE 0.7247871331929228\n",
      "52 Train Loss 4.119747 Test MSE 2.2005676761500688 Test RE 0.7090476548828487\n",
      "53 Train Loss 4.0323257 Test MSE 2.150443117607857 Test RE 0.7009257902303155\n",
      "54 Train Loss 3.9760637 Test MSE 2.150867393455567 Test RE 0.7009949320770618\n",
      "55 Train Loss 3.9460194 Test MSE 2.169365686158356 Test RE 0.7040028924869376\n",
      "56 Train Loss 3.9224858 Test MSE 2.15368955614986 Test RE 0.7014546706077607\n",
      "57 Train Loss 3.9016314 Test MSE 2.1757286895176455 Test RE 0.7050345979364052\n",
      "58 Train Loss 3.8628213 Test MSE 2.1791130262807155 Test RE 0.705582724033028\n",
      "59 Train Loss 3.8263173 Test MSE 2.1848052137577496 Test RE 0.7065036697822537\n",
      "60 Train Loss 3.7917504 Test MSE 2.1741431371721736 Test RE 0.7047776557449098\n",
      "61 Train Loss 3.7728176 Test MSE 2.170878752368207 Test RE 0.7042483599346744\n",
      "62 Train Loss 3.74723 Test MSE 2.1692442592169408 Test RE 0.703983189466192\n",
      "63 Train Loss 3.706923 Test MSE 2.177740315300517 Test RE 0.7053604515480746\n",
      "64 Train Loss 3.4874206 Test MSE 2.1514956932068685 Test RE 0.7010973100254085\n",
      "65 Train Loss 3.2662644 Test MSE 2.1516137177658132 Test RE 0.7011165398026924\n",
      "66 Train Loss 2.8743482 Test MSE 2.0901202833323276 Test RE 0.691024905441592\n",
      "67 Train Loss 2.312715 Test MSE 1.8926906641667143 Test RE 0.6575789164704349\n",
      "68 Train Loss 1.9263473 Test MSE 1.5914021731203658 Test RE 0.6029732332258385\n",
      "69 Train Loss 1.6566713 Test MSE 1.3441190461785495 Test RE 0.5541494771755536\n",
      "70 Train Loss 1.3281496 Test MSE 0.9215131987160134 Test RE 0.4588374317817595\n",
      "71 Train Loss 0.88141334 Test MSE 0.3733711491897735 Test RE 0.29206427550545283\n",
      "72 Train Loss 0.7300264 Test MSE 0.23452920770419924 Test RE 0.23147629821797194\n",
      "73 Train Loss 0.55404127 Test MSE 0.20556812804357533 Test RE 0.21671349233002837\n",
      "74 Train Loss 0.45220542 Test MSE 0.11179218564918988 Test RE 0.1598136181070041\n",
      "75 Train Loss 0.37564188 Test MSE 0.11141852368722313 Test RE 0.15954630848574294\n",
      "76 Train Loss 0.3225144 Test MSE 0.09280821701141394 Test RE 0.1456133773264269\n",
      "77 Train Loss 0.29118901 Test MSE 0.0779646512662186 Test RE 0.13346178546899762\n",
      "78 Train Loss 0.2536646 Test MSE 0.09068671936041008 Test RE 0.14393947222659056\n",
      "79 Train Loss 0.21235684 Test MSE 0.0928561214482853 Test RE 0.14565095280824478\n",
      "80 Train Loss 0.17018673 Test MSE 0.080922050763457 Test RE 0.13596949997499053\n",
      "81 Train Loss 0.15263738 Test MSE 0.07664495707480135 Test RE 0.13232742238955322\n",
      "82 Train Loss 0.13934217 Test MSE 0.05962731518072396 Test RE 0.11671607858707671\n",
      "83 Train Loss 0.1288829 Test MSE 0.056244700787268315 Test RE 0.11335713622077954\n",
      "84 Train Loss 0.11693868 Test MSE 0.046514844428306314 Test RE 0.1030869870719637\n",
      "85 Train Loss 0.10941166 Test MSE 0.03380297031610238 Test RE 0.087879078103383\n",
      "86 Train Loss 0.103282444 Test MSE 0.026745043090008264 Test RE 0.07816812796716692\n",
      "87 Train Loss 0.09572992 Test MSE 0.027856904687355202 Test RE 0.07977641010630283\n",
      "88 Train Loss 0.08512986 Test MSE 0.02386032659724234 Test RE 0.07383227528420701\n",
      "89 Train Loss 0.08091258 Test MSE 0.02420438780665054 Test RE 0.07436269342967489\n",
      "90 Train Loss 0.07839844 Test MSE 0.024109318822070933 Test RE 0.07421651040319001\n",
      "91 Train Loss 0.076160066 Test MSE 0.022949292366811588 Test RE 0.07240902666603183\n",
      "92 Train Loss 0.073408276 Test MSE 0.019955146046975673 Test RE 0.06752047915835649\n",
      "93 Train Loss 0.0667346 Test MSE 0.019454138619813283 Test RE 0.06666748368812576\n",
      "94 Train Loss 0.06507878 Test MSE 0.017821576852276064 Test RE 0.06380888035054663\n",
      "95 Train Loss 0.06279503 Test MSE 0.018187166521691167 Test RE 0.06446004166457886\n",
      "96 Train Loss 0.059175022 Test MSE 0.018903121956547468 Test RE 0.0657165610046609\n",
      "97 Train Loss 0.055845313 Test MSE 0.01831437520176937 Test RE 0.06468507914880628\n",
      "98 Train Loss 0.0519761 Test MSE 0.017156319013014454 Test RE 0.0626065996843242\n",
      "99 Train Loss 0.049371112 Test MSE 0.017766896611719978 Test RE 0.06371091580520429\n",
      "Training time: 77.08\n",
      "KG_stan_tune4\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.576332 Test MSE 8.704337378209521 Test RE 1.4101844394963843\n",
      "1 Train Loss 57.31993 Test MSE 8.711330251844275 Test RE 1.4107507813887996\n",
      "2 Train Loss 55.78058 Test MSE 9.753150361998355 Test RE 1.4927274531615087\n",
      "3 Train Loss 48.085846 Test MSE 8.513450526144252 Test RE 1.3946359904605\n",
      "4 Train Loss 45.173874 Test MSE 8.395727833330518 Test RE 1.3849600178820511\n",
      "5 Train Loss 44.458565 Test MSE 8.384982132831801 Test RE 1.384073428244504\n",
      "6 Train Loss 44.345665 Test MSE 8.521346258005046 Test RE 1.3952825625995946\n",
      "7 Train Loss 44.165916 Test MSE 8.455616370975 Test RE 1.389890849611592\n",
      "8 Train Loss 44.072098 Test MSE 8.496278524426769 Test RE 1.3932287596241946\n",
      "9 Train Loss 43.8354 Test MSE 8.580470859694218 Test RE 1.4001147170849826\n",
      "10 Train Loss 43.73382 Test MSE 8.476159484310346 Test RE 1.3915782111639527\n",
      "11 Train Loss 43.41484 Test MSE 8.475197015348481 Test RE 1.3914992019816832\n",
      "12 Train Loss 43.139145 Test MSE 8.597258612713615 Test RE 1.4014837150612365\n",
      "13 Train Loss 42.684174 Test MSE 8.382788790473054 Test RE 1.3838923935459075\n",
      "14 Train Loss 42.282074 Test MSE 8.320533439395367 Test RE 1.3787440315770367\n",
      "15 Train Loss 41.73037 Test MSE 8.489063912639418 Test RE 1.3926371041518426\n",
      "16 Train Loss 40.907703 Test MSE 8.435987324118932 Test RE 1.3882766512369868\n",
      "17 Train Loss 39.619926 Test MSE 7.98382476485377 Test RE 1.3505589906620903\n",
      "18 Train Loss 38.90656 Test MSE 7.881998481881004 Test RE 1.341918788911845\n",
      "19 Train Loss 38.273415 Test MSE 7.9129273398163225 Test RE 1.3445490469652974\n",
      "20 Train Loss 37.157623 Test MSE 8.361437419209153 Test RE 1.3821288492129025\n",
      "21 Train Loss 36.313293 Test MSE 8.17943221236275 Test RE 1.367003539415339\n",
      "22 Train Loss 34.707542 Test MSE 8.554768988244502 Test RE 1.398016198412989\n",
      "23 Train Loss 32.334 Test MSE 8.243828322577986 Test RE 1.37237415219393\n",
      "24 Train Loss 31.410263 Test MSE 8.013795701896806 Test RE 1.3530915864472972\n",
      "25 Train Loss 30.529612 Test MSE 7.830161813762702 Test RE 1.3374988854719818\n",
      "26 Train Loss 28.285343 Test MSE 7.56628620488367 Test RE 1.3147689612112343\n",
      "27 Train Loss 26.233442 Test MSE 7.227052941199398 Test RE 1.284957247723973\n",
      "28 Train Loss 24.252594 Test MSE 6.840334798447792 Test RE 1.2501057121459007\n",
      "29 Train Loss 22.811987 Test MSE 6.515185593961502 Test RE 1.2200326581232421\n",
      "30 Train Loss 21.371 Test MSE 6.591485680189129 Test RE 1.2271558349821248\n",
      "31 Train Loss 18.48803 Test MSE 6.20474251027273 Test RE 1.1906111408044777\n",
      "32 Train Loss 16.57042 Test MSE 6.299575427391211 Test RE 1.1996752533856478\n",
      "33 Train Loss 15.210253 Test MSE 5.75168768730391 Test RE 1.1463195741757706\n",
      "34 Train Loss 14.102909 Test MSE 5.167715111386965 Test RE 1.0865690793445273\n",
      "35 Train Loss 12.349255 Test MSE 4.467407195535635 Test RE 1.0102662156385704\n",
      "36 Train Loss 10.651207 Test MSE 4.5458198372335 Test RE 1.0190938248939754\n",
      "37 Train Loss 8.067414 Test MSE 3.681238718544381 Test RE 0.9170754147162764\n",
      "38 Train Loss 6.664043 Test MSE 3.135017096656775 Test RE 0.8463071637454319\n",
      "39 Train Loss 5.143838 Test MSE 2.26632812422707 Test RE 0.7195640448408601\n",
      "40 Train Loss 3.875476 Test MSE 2.1116755255877537 Test RE 0.6945790077686176\n",
      "41 Train Loss 2.3585882 Test MSE 1.972137783370802 Test RE 0.671238235525025\n",
      "42 Train Loss 2.0713494 Test MSE 2.0189220699051043 Test RE 0.6791533356473686\n",
      "43 Train Loss 1.7637259 Test MSE 1.8564784883492098 Test RE 0.6512579246280604\n",
      "44 Train Loss 1.5884241 Test MSE 1.6886763887802079 Test RE 0.6211282409201908\n",
      "45 Train Loss 1.4694357 Test MSE 1.5915711940287625 Test RE 0.60300525290616\n",
      "46 Train Loss 1.3150247 Test MSE 1.6588102786324965 Test RE 0.6156110677147234\n",
      "47 Train Loss 1.202091 Test MSE 1.6877526958311384 Test RE 0.6209583415070776\n",
      "48 Train Loss 1.0252647 Test MSE 1.6918994834699699 Test RE 0.6217207170157145\n",
      "49 Train Loss 0.98575413 Test MSE 1.6752739982363118 Test RE 0.6186584999728992\n",
      "50 Train Loss 0.90077597 Test MSE 1.67690217676863 Test RE 0.6189590603188557\n",
      "51 Train Loss 0.86809117 Test MSE 1.6963597760529439 Test RE 0.6225396873825374\n",
      "52 Train Loss 0.82681775 Test MSE 1.6968306499401393 Test RE 0.6226260833662415\n",
      "53 Train Loss 0.7984944 Test MSE 1.647019845202619 Test RE 0.6134193568669559\n",
      "54 Train Loss 0.72549945 Test MSE 1.658680870023371 Test RE 0.6155870544424239\n",
      "55 Train Loss 0.6654263 Test MSE 1.620555099561775 Test RE 0.6084711075979438\n",
      "56 Train Loss 0.6376922 Test MSE 1.6109889577529766 Test RE 0.6066725460174232\n",
      "57 Train Loss 0.60213494 Test MSE 1.57685233551457 Test RE 0.600210478549643\n",
      "58 Train Loss 0.5733029 Test MSE 1.4804647678603449 Test RE 0.581576833493819\n",
      "59 Train Loss 0.54130554 Test MSE 1.3908197390649122 Test RE 0.5636940921082677\n",
      "60 Train Loss 0.5069459 Test MSE 1.3879325095730208 Test RE 0.5631086964289155\n",
      "61 Train Loss 0.44654828 Test MSE 1.1600798892249955 Test RE 0.5148159684738685\n",
      "62 Train Loss 0.40453753 Test MSE 1.0030493057972756 Test RE 0.4787063640221266\n",
      "63 Train Loss 0.34910607 Test MSE 0.8537784624376177 Test RE 0.44165246406099434\n",
      "64 Train Loss 0.30194426 Test MSE 0.712709339459803 Test RE 0.40351927558510087\n",
      "65 Train Loss 0.2613208 Test MSE 0.617144572546667 Test RE 0.375492716436008\n",
      "66 Train Loss 0.23627432 Test MSE 0.5691167007853987 Test RE 0.36058588745838166\n",
      "67 Train Loss 0.22142641 Test MSE 0.4280454696462856 Test RE 0.3127180956622093\n",
      "68 Train Loss 0.21079125 Test MSE 0.3959257023017061 Test RE 0.3007564210518767\n",
      "69 Train Loss 0.19274947 Test MSE 0.3666473977898091 Test RE 0.28942254878117835\n",
      "70 Train Loss 0.17794757 Test MSE 0.31616906879494877 Test RE 0.26876192950928607\n",
      "71 Train Loss 0.15822223 Test MSE 0.31630343869608646 Test RE 0.26881903452250805\n",
      "72 Train Loss 0.15231659 Test MSE 0.25523424447731974 Test RE 0.24147797854914502\n",
      "73 Train Loss 0.14542833 Test MSE 0.19772569541012736 Test RE 0.2125394811779159\n",
      "74 Train Loss 0.13705201 Test MSE 0.21145376368771346 Test RE 0.2197939682824778\n",
      "75 Train Loss 0.13313779 Test MSE 0.17522757920702267 Test RE 0.2000825855359517\n",
      "76 Train Loss 0.12027402 Test MSE 0.1629356955584224 Test RE 0.19293729249408115\n",
      "77 Train Loss 0.11211384 Test MSE 0.11581569192768842 Test RE 0.16266411825118243\n",
      "78 Train Loss 0.108547896 Test MSE 0.11973552208106557 Test RE 0.1653939298416629\n",
      "79 Train Loss 0.10499507 Test MSE 0.13193797666431037 Test RE 0.1736172888400751\n",
      "80 Train Loss 0.098820224 Test MSE 0.12215884751678598 Test RE 0.16705924859200952\n",
      "81 Train Loss 0.09476805 Test MSE 0.1261401254075743 Test RE 0.16975973534534253\n",
      "82 Train Loss 0.09042448 Test MSE 0.11747886032885378 Test RE 0.16382792198962295\n",
      "83 Train Loss 0.08566498 Test MSE 0.12158755041780171 Test RE 0.16666814997862572\n",
      "84 Train Loss 0.08170341 Test MSE 0.10312469761211823 Test RE 0.15349329332199496\n",
      "85 Train Loss 0.08002924 Test MSE 0.08192313298564363 Test RE 0.13680795042806365\n",
      "86 Train Loss 0.0777227 Test MSE 0.06845667735480407 Test RE 0.12505929277830982\n",
      "87 Train Loss 0.07063843 Test MSE 0.06320742961187918 Test RE 0.12016891089589563\n",
      "88 Train Loss 0.06760519 Test MSE 0.07566461132760081 Test RE 0.13147841594476506\n",
      "89 Train Loss 0.06552499 Test MSE 0.07790987150842722 Test RE 0.13341489056961087\n",
      "90 Train Loss 0.06337795 Test MSE 0.0745328895638538 Test RE 0.13049144479247887\n",
      "91 Train Loss 0.059322238 Test MSE 0.05566753400444285 Test RE 0.11277401741097347\n",
      "92 Train Loss 0.054323122 Test MSE 0.037238780574358143 Test RE 0.09223713097549976\n",
      "93 Train Loss 0.051120535 Test MSE 0.029273278472537217 Test RE 0.08177936656798951\n",
      "94 Train Loss 0.048198488 Test MSE 0.026769264966165378 Test RE 0.07820351677200182\n",
      "95 Train Loss 0.046557434 Test MSE 0.022908284220562538 Test RE 0.07234430380696942\n",
      "96 Train Loss 0.043882184 Test MSE 0.022371969938695956 Test RE 0.07149244893236122\n",
      "97 Train Loss 0.04232607 Test MSE 0.021682940223775603 Test RE 0.07038289827574348\n",
      "98 Train Loss 0.039921787 Test MSE 0.02204540893703163 Test RE 0.07096874738991037\n",
      "99 Train Loss 0.038202576 Test MSE 0.020427045228547627 Test RE 0.06831417619626222\n",
      "Training time: 78.26\n",
      "KG_stan_tune4\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.295284 Test MSE 8.515566338644685 Test RE 1.39480928123955\n",
      "1 Train Loss 54.03299 Test MSE 8.434677038602524 Test RE 1.388168832830073\n",
      "2 Train Loss 48.568726 Test MSE 8.320971438511055 Test RE 1.3787803201590079\n",
      "3 Train Loss 43.10228 Test MSE 8.01326324262843 Test RE 1.353046634083223\n",
      "4 Train Loss 39.29531 Test MSE 7.75992441655072 Test RE 1.3314866176939668\n",
      "5 Train Loss 36.880836 Test MSE 7.344318229363836 Test RE 1.2953400801090245\n",
      "6 Train Loss 35.232567 Test MSE 7.12482579809325 Test RE 1.2758369784162975\n",
      "7 Train Loss 32.367386 Test MSE 6.801074082588167 Test RE 1.246513002558452\n",
      "8 Train Loss 30.679916 Test MSE 6.47502170314398 Test RE 1.2162663025496576\n",
      "9 Train Loss 29.559612 Test MSE 6.132985488959299 Test RE 1.1837064902204117\n",
      "10 Train Loss 28.679811 Test MSE 6.285632499197924 Test RE 1.1983468899209846\n",
      "11 Train Loss 27.594736 Test MSE 6.228798283193671 Test RE 1.1929169064775842\n",
      "12 Train Loss 26.82523 Test MSE 6.458985114124363 Test RE 1.2147592145819361\n",
      "13 Train Loss 26.25891 Test MSE 6.368243095214099 Test RE 1.2061959806924658\n",
      "14 Train Loss 25.480122 Test MSE 6.609113882545291 Test RE 1.2287956858647469\n",
      "15 Train Loss 24.800121 Test MSE 6.315168836834495 Test RE 1.2011591204745897\n",
      "16 Train Loss 24.320404 Test MSE 6.421628698678463 Test RE 1.211241258317391\n",
      "17 Train Loss 23.984901 Test MSE 6.361770650886061 Test RE 1.2055828586020638\n",
      "18 Train Loss 23.6011 Test MSE 6.199982418225912 Test RE 1.1901543526300868\n",
      "19 Train Loss 23.462845 Test MSE 6.194454254937392 Test RE 1.1896236386360852\n",
      "20 Train Loss 23.166624 Test MSE 6.087332944385153 Test RE 1.17929264044561\n",
      "21 Train Loss 23.021847 Test MSE 6.029147473709894 Test RE 1.1736430024141502\n",
      "22 Train Loss 22.745153 Test MSE 5.985662476780421 Test RE 1.1694029154453724\n",
      "23 Train Loss 22.674442 Test MSE 5.957952440423009 Test RE 1.1666929574832015\n",
      "24 Train Loss 22.49965 Test MSE 5.999772645651437 Test RE 1.1707804371372499\n",
      "25 Train Loss 22.397722 Test MSE 6.006320539427748 Test RE 1.1714191326266876\n",
      "26 Train Loss 22.016705 Test MSE 5.932504194003008 Test RE 1.1641986389941927\n",
      "27 Train Loss 21.732475 Test MSE 5.9772182755180605 Test RE 1.1685777637837094\n",
      "28 Train Loss 21.383835 Test MSE 5.971550905141414 Test RE 1.1680236319699266\n",
      "29 Train Loss 21.00793 Test MSE 6.027791718247609 Test RE 1.1735110382866507\n",
      "30 Train Loss 20.909012 Test MSE 5.999238200050591 Test RE 1.170728290795535\n",
      "31 Train Loss 20.613644 Test MSE 6.041653974011294 Test RE 1.1748596389814152\n",
      "32 Train Loss 20.361506 Test MSE 5.84069432975232 Test RE 1.1551550987530175\n",
      "33 Train Loss 20.21743 Test MSE 5.895845463636671 Test RE 1.1605960980422285\n",
      "34 Train Loss 19.983885 Test MSE 6.062356377885823 Test RE 1.176870811633451\n",
      "35 Train Loss 19.647432 Test MSE 6.0273183895255205 Test RE 1.1734649627576075\n",
      "36 Train Loss 19.324284 Test MSE 6.042640480709385 Test RE 1.174955553080447\n",
      "37 Train Loss 19.041702 Test MSE 5.833551382125521 Test RE 1.154448527224107\n",
      "38 Train Loss 18.579151 Test MSE 5.946672022294151 Test RE 1.1655879621112348\n",
      "39 Train Loss 17.942043 Test MSE 5.799417776948339 Test RE 1.1510660848824827\n",
      "40 Train Loss 16.62472 Test MSE 5.5586015072595805 Test RE 1.126914146364624\n",
      "41 Train Loss 14.344724 Test MSE 3.8249534198356483 Test RE 0.9348052345911366\n",
      "42 Train Loss 11.354694 Test MSE 3.39031348079046 Test RE 0.8800918282493865\n",
      "43 Train Loss 9.798771 Test MSE 3.0567709824867313 Test RE 0.8356790432519867\n",
      "44 Train Loss 8.979783 Test MSE 2.985282710273157 Test RE 0.8258492773944982\n",
      "45 Train Loss 7.9343824 Test MSE 2.971225302987645 Test RE 0.8239025608157662\n",
      "46 Train Loss 7.018036 Test MSE 2.745491716381533 Test RE 0.7919871389105699\n",
      "47 Train Loss 6.4359884 Test MSE 2.281100460980998 Test RE 0.7219053600752344\n",
      "48 Train Loss 6.0285864 Test MSE 2.300579506629507 Test RE 0.7249810981152339\n",
      "49 Train Loss 5.6026807 Test MSE 2.2466015736034217 Test RE 0.716425589400362\n",
      "50 Train Loss 5.259625 Test MSE 2.2283089581845075 Test RE 0.7135029341153734\n",
      "51 Train Loss 5.11806 Test MSE 2.1996043480273246 Test RE 0.7088924403163577\n",
      "52 Train Loss 4.9925566 Test MSE 2.168831935787913 Test RE 0.7039162807821909\n",
      "53 Train Loss 4.906369 Test MSE 2.1669670046643295 Test RE 0.7036135745921529\n",
      "54 Train Loss 4.8272047 Test MSE 2.172783060534301 Test RE 0.704557177717257\n",
      "55 Train Loss 4.7163763 Test MSE 2.183385786453384 Test RE 0.7062741313487505\n",
      "56 Train Loss 4.643537 Test MSE 2.180086023821486 Test RE 0.7057402316125625\n",
      "57 Train Loss 4.5741735 Test MSE 2.1817311989440404 Test RE 0.7060064704893462\n",
      "58 Train Loss 4.4926586 Test MSE 2.1824246557540934 Test RE 0.7061186626095384\n",
      "59 Train Loss 4.4622936 Test MSE 2.1712506629176933 Test RE 0.7043086825522786\n",
      "60 Train Loss 4.3952975 Test MSE 2.184445120926065 Test RE 0.7064454455092272\n",
      "61 Train Loss 4.3704705 Test MSE 2.1720116651015138 Test RE 0.7044320984017035\n",
      "62 Train Loss 4.3559394 Test MSE 2.1609415905062335 Test RE 0.7026346685000664\n",
      "63 Train Loss 4.331941 Test MSE 2.173816586686812 Test RE 0.7047247258977257\n",
      "64 Train Loss 4.309332 Test MSE 2.1708003988911604 Test RE 0.7042356506100382\n",
      "65 Train Loss 4.2823462 Test MSE 2.1748957600930234 Test RE 0.7048996315964094\n",
      "66 Train Loss 4.2502837 Test MSE 2.177516918999302 Test RE 0.7053242720834996\n",
      "67 Train Loss 4.2321835 Test MSE 2.1708041093992985 Test RE 0.7042362524781322\n",
      "68 Train Loss 4.217433 Test MSE 2.1687267116131648 Test RE 0.7038992047914397\n",
      "69 Train Loss 4.1993504 Test MSE 2.1505570991549456 Test RE 0.7009443658314757\n",
      "70 Train Loss 4.180924 Test MSE 2.1590814901577193 Test RE 0.7023321956398562\n",
      "71 Train Loss 4.165706 Test MSE 2.15420524330009 Test RE 0.7015386449921163\n",
      "72 Train Loss 4.1593122 Test MSE 2.154875943120762 Test RE 0.701647846570509\n",
      "73 Train Loss 4.149844 Test MSE 2.157576944455014 Test RE 0.7020874445632257\n",
      "74 Train Loss 4.1340275 Test MSE 2.1570457357617556 Test RE 0.7020010101225641\n",
      "75 Train Loss 4.122187 Test MSE 2.1504612403487156 Test RE 0.7009287437308271\n",
      "76 Train Loss 4.1165814 Test MSE 2.148680366674507 Test RE 0.7006384515683473\n",
      "77 Train Loss 4.1032443 Test MSE 2.1496755384555333 Test RE 0.7008006848420517\n",
      "78 Train Loss 4.097232 Test MSE 2.1494203297407863 Test RE 0.7007590842033851\n",
      "79 Train Loss 4.094371 Test MSE 2.1485696653986266 Test RE 0.7006204026833774\n",
      "80 Train Loss 4.0896797 Test MSE 2.1445349368099174 Test RE 0.6999622575097384\n",
      "81 Train Loss 4.0818405 Test MSE 2.1377842865692624 Test RE 0.6988597049918437\n",
      "82 Train Loss 4.0672984 Test MSE 2.132761097154863 Test RE 0.698038160625947\n",
      "83 Train Loss 4.058328 Test MSE 2.123839652797766 Test RE 0.6965766667043413\n",
      "84 Train Loss 4.054 Test MSE 2.119303916930339 Test RE 0.6958324541067977\n",
      "85 Train Loss 4.0340104 Test MSE 2.1157389423796054 Test RE 0.6952469625590478\n",
      "86 Train Loss 4.0139847 Test MSE 2.1094508434049324 Test RE 0.6942130365963273\n",
      "87 Train Loss 3.9845777 Test MSE 2.0919062645548046 Test RE 0.6913200784000157\n",
      "88 Train Loss 3.9457157 Test MSE 2.0922740728275095 Test RE 0.6913808512157845\n",
      "89 Train Loss 3.9146726 Test MSE 2.0977102611897007 Test RE 0.6922784483363503\n",
      "90 Train Loss 3.8623884 Test MSE 2.0856818696339436 Test RE 0.6902908126718628\n",
      "91 Train Loss 3.717433 Test MSE 2.0724001750176284 Test RE 0.6880894044734027\n",
      "92 Train Loss 3.3196578 Test MSE 1.9625700837859246 Test RE 0.6696080213424458\n",
      "93 Train Loss 2.4824965 Test MSE 1.7180070939283862 Test RE 0.6264992229387664\n",
      "94 Train Loss 1.931437 Test MSE 1.527035364216107 Test RE 0.5906532632772525\n",
      "95 Train Loss 1.5492654 Test MSE 1.1857903172816835 Test RE 0.5204895447919621\n",
      "96 Train Loss 1.3488464 Test MSE 0.887816067779001 Test RE 0.4503701109437656\n",
      "97 Train Loss 1.1358209 Test MSE 0.7794918325859691 Test RE 0.42200135439536113\n",
      "98 Train Loss 0.9329576 Test MSE 0.5049006328058158 Test RE 0.3396338887842559\n",
      "99 Train Loss 0.7597575 Test MSE 0.2184228688654622 Test RE 0.22338659778213596\n",
      "Training time: 79.37\n",
      "KG_stan_tune4\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.446087 Test MSE 8.627160357121083 Test RE 1.4039188187612839\n",
      "1 Train Loss 55.895603 Test MSE 8.71432225914962 Test RE 1.410993029940302\n",
      "2 Train Loss 54.19937 Test MSE 9.157311898243467 Test RE 1.4464121575841307\n",
      "3 Train Loss 45.889637 Test MSE 8.981796983453354 Test RE 1.4324836623801476\n",
      "4 Train Loss 43.40356 Test MSE 8.502276048960233 Test RE 1.3937204130905203\n",
      "5 Train Loss 42.875763 Test MSE 8.562382080167051 Test RE 1.3986381239717391\n",
      "6 Train Loss 42.280838 Test MSE 8.498531819628354 Test RE 1.3934134962444973\n",
      "7 Train Loss 41.648396 Test MSE 8.358285504697688 Test RE 1.3818683220824324\n",
      "8 Train Loss 40.629784 Test MSE 8.553455256292047 Test RE 1.3979088495723058\n",
      "9 Train Loss 40.18245 Test MSE 8.521958200868708 Test RE 1.3953326613664214\n",
      "10 Train Loss 39.773773 Test MSE 8.446653779406729 Test RE 1.389154041897548\n",
      "11 Train Loss 38.826828 Test MSE 8.200360769413628 Test RE 1.3687512850783385\n",
      "12 Train Loss 37.677956 Test MSE 8.789320569167787 Test RE 1.4170517559769795\n",
      "13 Train Loss 37.007812 Test MSE 9.060712774126136 Test RE 1.4387629378919804\n",
      "14 Train Loss 36.188835 Test MSE 9.1394100143427 Test RE 1.444997650238924\n",
      "15 Train Loss 35.807076 Test MSE 9.129435741315033 Test RE 1.4442089376438902\n",
      "16 Train Loss 34.80059 Test MSE 9.457087968612903 Test RE 1.4698965639277348\n",
      "17 Train Loss 33.795174 Test MSE 9.471575040533821 Test RE 1.4710219816263213\n",
      "18 Train Loss 32.564713 Test MSE 9.572052815307403 Test RE 1.4788039549746674\n",
      "19 Train Loss 30.553173 Test MSE 9.304786932373863 Test RE 1.4580125984900447\n",
      "20 Train Loss 29.294392 Test MSE 9.131750135639514 Test RE 1.4443919860410586\n",
      "21 Train Loss 27.430164 Test MSE 8.744521455729995 Test RE 1.4134357903649182\n",
      "22 Train Loss 23.642736 Test MSE 7.511787758158296 Test RE 1.3100253950589362\n",
      "23 Train Loss 20.030905 Test MSE 7.0360178824227795 Test RE 1.267860663164277\n",
      "24 Train Loss 17.51298 Test MSE 6.667199463228981 Test RE 1.23418363751642\n",
      "25 Train Loss 16.387213 Test MSE 6.597558429266869 Test RE 1.2277209954165804\n",
      "26 Train Loss 15.765919 Test MSE 6.7640156030242 Test RE 1.243112291528683\n",
      "27 Train Loss 15.16777 Test MSE 6.744834622293918 Test RE 1.2413484693971086\n",
      "28 Train Loss 14.790054 Test MSE 6.541372474180112 Test RE 1.2224820749119625\n",
      "29 Train Loss 14.328619 Test MSE 6.794547559066839 Test RE 1.245914762558835\n",
      "30 Train Loss 14.107797 Test MSE 6.771749349611211 Test RE 1.2438227547741456\n",
      "31 Train Loss 13.9276285 Test MSE 6.900965779575632 Test RE 1.2556337982084247\n",
      "32 Train Loss 13.679403 Test MSE 6.988663365618836 Test RE 1.2635869183073645\n",
      "33 Train Loss 13.471593 Test MSE 7.070590874319558 Test RE 1.2709717994933598\n",
      "34 Train Loss 13.27453 Test MSE 6.997277029692036 Test RE 1.2643653762911735\n",
      "35 Train Loss 13.092319 Test MSE 6.942277047996748 Test RE 1.259386492245426\n",
      "36 Train Loss 12.892988 Test MSE 6.948774337789112 Test RE 1.2599756854821829\n",
      "37 Train Loss 12.721756 Test MSE 6.859812948710788 Test RE 1.2518843120257759\n",
      "38 Train Loss 12.588096 Test MSE 6.897610684655928 Test RE 1.2553285305926205\n",
      "39 Train Loss 12.366012 Test MSE 6.810029252240234 Test RE 1.2473333923321497\n",
      "40 Train Loss 12.206813 Test MSE 6.711487108585804 Test RE 1.2382759567834765\n",
      "41 Train Loss 12.020168 Test MSE 6.830516316316132 Test RE 1.2492082013779235\n",
      "42 Train Loss 11.78146 Test MSE 6.78403862609707 Test RE 1.2449508792933124\n",
      "43 Train Loss 11.446564 Test MSE 6.781518287939238 Test RE 1.2447196019632238\n",
      "44 Train Loss 10.848471 Test MSE 6.588530260535557 Test RE 1.226880694651717\n",
      "45 Train Loss 10.614782 Test MSE 6.551894392637456 Test RE 1.2234648723584287\n",
      "46 Train Loss 10.13693 Test MSE 6.439907888207549 Test RE 1.2129639346187944\n",
      "47 Train Loss 9.604496 Test MSE 6.214514997000339 Test RE 1.1915483798418562\n",
      "48 Train Loss 9.238967 Test MSE 6.0997143974356876 Test RE 1.1804913541889297\n",
      "49 Train Loss 8.674642 Test MSE 5.844672019797459 Test RE 1.1555483796401795\n",
      "50 Train Loss 8.194167 Test MSE 5.7777468008789725 Test RE 1.148913448770248\n",
      "51 Train Loss 8.007248 Test MSE 5.823867493779491 Test RE 1.15348991784817\n",
      "52 Train Loss 7.8721876 Test MSE 5.848270301492818 Test RE 1.1559040325149104\n",
      "53 Train Loss 7.7717514 Test MSE 5.9253361184838855 Test RE 1.1634950924150218\n",
      "54 Train Loss 7.640481 Test MSE 5.93088066224941 Test RE 1.1640393266086215\n",
      "55 Train Loss 7.586294 Test MSE 5.938632565154484 Test RE 1.164799801633285\n",
      "56 Train Loss 7.4999294 Test MSE 5.939881502460587 Test RE 1.1649222780983421\n",
      "57 Train Loss 7.442742 Test MSE 5.903702183570885 Test RE 1.1613691375315531\n",
      "58 Train Loss 7.3806763 Test MSE 5.884309605888332 Test RE 1.1594601263665039\n",
      "59 Train Loss 7.278233 Test MSE 5.813480278460208 Test RE 1.1524607997080931\n",
      "60 Train Loss 7.1356087 Test MSE 5.778933874781888 Test RE 1.1490314684043137\n",
      "61 Train Loss 6.9573393 Test MSE 5.638841635829055 Test RE 1.1350186800762265\n",
      "62 Train Loss 6.6174183 Test MSE 5.479191781918099 Test RE 1.1188356889871043\n",
      "63 Train Loss 6.0312066 Test MSE 4.951618770301454 Test RE 1.0636081599608358\n",
      "64 Train Loss 5.457292 Test MSE 4.516107049891483 Test RE 1.0157578193492878\n",
      "65 Train Loss 5.0568743 Test MSE 4.408549566144861 Test RE 1.0035890734179307\n",
      "66 Train Loss 4.729155 Test MSE 4.417374107810228 Test RE 1.0045930074835396\n",
      "67 Train Loss 4.488561 Test MSE 4.347618505143633 Test RE 0.9966295838643008\n",
      "68 Train Loss 4.289113 Test MSE 4.489600694744008 Test RE 1.0127725424464953\n",
      "69 Train Loss 4.147168 Test MSE 4.468040741461137 Test RE 1.0103378486155963\n",
      "70 Train Loss 4.006429 Test MSE 4.558192197408712 Test RE 1.02047971663131\n",
      "71 Train Loss 3.9123132 Test MSE 4.5353037447447 Test RE 1.0179143797697654\n",
      "72 Train Loss 3.8060114 Test MSE 4.587292055923342 Test RE 1.0237319457680134\n",
      "73 Train Loss 3.6114397 Test MSE 4.591137705667855 Test RE 1.0241609668209766\n",
      "74 Train Loss 3.4766202 Test MSE 4.514634982976428 Test RE 1.015592258022723\n",
      "75 Train Loss 3.3450804 Test MSE 4.540390629778614 Test RE 1.0184850760879298\n",
      "76 Train Loss 3.2035778 Test MSE 4.524409407018482 Test RE 1.0166910691338968\n",
      "77 Train Loss 3.10814 Test MSE 4.502469840511337 Test RE 1.0142230267762842\n",
      "78 Train Loss 3.055365 Test MSE 4.435588263074101 Test RE 1.0066619957009948\n",
      "79 Train Loss 2.985859 Test MSE 4.422202939486899 Test RE 1.005141940563195\n",
      "80 Train Loss 2.8951347 Test MSE 4.3999929786624605 Test RE 1.0026146635342865\n",
      "81 Train Loss 2.8126922 Test MSE 4.491095190426273 Test RE 1.0129410939898735\n",
      "82 Train Loss 2.7662945 Test MSE 4.4784854947899015 Test RE 1.0115180716983923\n",
      "83 Train Loss 2.7088728 Test MSE 4.4930829992231365 Test RE 1.013165238700485\n",
      "84 Train Loss 2.664583 Test MSE 4.517267529915001 Test RE 1.0158883179102658\n",
      "85 Train Loss 2.6232398 Test MSE 4.491113069953524 Test RE 1.0129431103009408\n",
      "86 Train Loss 2.58546 Test MSE 4.4888376451108805 Test RE 1.0126864737058363\n",
      "87 Train Loss 2.5550249 Test MSE 4.455082664864529 Test RE 1.008871709197933\n",
      "88 Train Loss 2.5113168 Test MSE 4.500587131440855 Test RE 1.0140109557780854\n",
      "89 Train Loss 2.46975 Test MSE 4.511120799118909 Test RE 1.0151969134683587\n",
      "90 Train Loss 2.4305177 Test MSE 4.5533824009819615 Test RE 1.0199411703203056\n",
      "91 Train Loss 2.3916488 Test MSE 4.551318577620027 Test RE 1.019709999642722\n",
      "92 Train Loss 2.3695602 Test MSE 4.564527739341503 Test RE 1.0211886651299393\n",
      "93 Train Loss 2.3297646 Test MSE 4.50477281810039 Test RE 1.0144823771309612\n",
      "94 Train Loss 2.304635 Test MSE 4.472414227827798 Test RE 1.0108322060189847\n",
      "95 Train Loss 2.2790284 Test MSE 4.469462077740232 Test RE 1.0104985360102658\n",
      "96 Train Loss 2.258581 Test MSE 4.466292666645562 Test RE 1.010140187153782\n",
      "97 Train Loss 2.2341883 Test MSE 4.414580337031235 Test RE 1.004275279527936\n",
      "98 Train Loss 2.2150145 Test MSE 4.395688977714129 Test RE 1.0021241729496633\n",
      "99 Train Loss 2.1793976 Test MSE 4.296175329375234 Test RE 0.9907157304349166\n",
      "Training time: 78.05\n",
      "KG_stan_tune4\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.19728 Test MSE 8.583577330943909 Test RE 1.4003681427181385\n",
      "1 Train Loss 56.559834 Test MSE 8.68561276983069 Test RE 1.4086668416548993\n",
      "2 Train Loss 51.83307 Test MSE 8.231821049235641 Test RE 1.3713743450901066\n",
      "3 Train Loss 45.398552 Test MSE 7.979178302550671 Test RE 1.3501659312623777\n",
      "4 Train Loss 44.430542 Test MSE 8.382684380248707 Test RE 1.3838837751154052\n",
      "5 Train Loss 43.81755 Test MSE 8.396199265670784 Test RE 1.3849989010968295\n",
      "6 Train Loss 43.309418 Test MSE 8.34553370198589 Test RE 1.3808137973046335\n",
      "7 Train Loss 42.71424 Test MSE 8.11912810148145 Test RE 1.3619549959194193\n",
      "8 Train Loss 42.282536 Test MSE 8.356149884376727 Test RE 1.381691770647133\n",
      "9 Train Loss 42.006096 Test MSE 8.087134109324742 Test RE 1.359268907667711\n",
      "10 Train Loss 41.43892 Test MSE 7.850815820937349 Test RE 1.3392617174191683\n",
      "11 Train Loss 40.831818 Test MSE 7.804785288702943 Test RE 1.335329797585676\n",
      "12 Train Loss 40.36798 Test MSE 7.503411114393117 Test RE 1.3092947649227482\n",
      "13 Train Loss 37.205383 Test MSE 6.722838205443004 Test RE 1.2393226586542112\n",
      "14 Train Loss 35.875248 Test MSE 6.7810029107949115 Test RE 1.2446723033941391\n",
      "15 Train Loss 33.956318 Test MSE 6.587132019876868 Test RE 1.2267505013135653\n",
      "16 Train Loss 32.9522 Test MSE 6.381884190569394 Test RE 1.207487155694285\n",
      "17 Train Loss 28.875114 Test MSE 4.881286153477889 Test RE 1.0560274183108103\n",
      "18 Train Loss 26.565279 Test MSE 3.9543530076084132 Test RE 0.950486118433277\n",
      "19 Train Loss 23.046967 Test MSE 3.0897607490752894 Test RE 0.8401764151835837\n",
      "20 Train Loss 20.607546 Test MSE 3.1473892563873362 Test RE 0.8479754700057729\n",
      "21 Train Loss 17.761002 Test MSE 3.5421162958102346 Test RE 0.8995793307227125\n",
      "22 Train Loss 16.642595 Test MSE 3.420499407226376 Test RE 0.884001129726093\n",
      "23 Train Loss 15.844065 Test MSE 3.258807106045587 Test RE 0.8628541407979514\n",
      "24 Train Loss 15.445545 Test MSE 2.83932750446755 Test RE 0.8054077513651979\n",
      "25 Train Loss 15.258774 Test MSE 2.9524734723328594 Test RE 0.8212985619205054\n",
      "26 Train Loss 15.046976 Test MSE 2.7467369823970054 Test RE 0.7921667283912506\n",
      "27 Train Loss 14.706963 Test MSE 2.6909716544556046 Test RE 0.784084054332347\n",
      "28 Train Loss 14.371811 Test MSE 2.9696567721520064 Test RE 0.8236850601146752\n",
      "29 Train Loss 14.235918 Test MSE 3.1184615796581676 Test RE 0.8440696003238902\n",
      "30 Train Loss 13.992363 Test MSE 3.285448667142574 Test RE 0.8663739854717135\n",
      "31 Train Loss 13.775914 Test MSE 3.3732414670126785 Test RE 0.8778731687807456\n",
      "32 Train Loss 13.406363 Test MSE 3.3828995238225374 Test RE 0.8791290066560759\n",
      "33 Train Loss 13.24387 Test MSE 3.525341928537108 Test RE 0.8974467381572656\n",
      "34 Train Loss 13.043545 Test MSE 3.646141102697125 Test RE 0.9126931604541155\n",
      "35 Train Loss 12.886772 Test MSE 3.64723190767621 Test RE 0.9128296740676132\n",
      "36 Train Loss 12.683422 Test MSE 3.635092050583122 Test RE 0.9113092253023369\n",
      "37 Train Loss 12.381327 Test MSE 3.6132288776746284 Test RE 0.9085645685521477\n",
      "38 Train Loss 12.144001 Test MSE 3.6511219370787575 Test RE 0.9133163428668281\n",
      "39 Train Loss 11.960825 Test MSE 3.519673098551643 Test RE 0.896724890472436\n",
      "40 Train Loss 11.700008 Test MSE 3.68477745192374 Test RE 0.9175160959774035\n",
      "41 Train Loss 11.513827 Test MSE 3.6194482864544857 Test RE 0.9093461831551277\n",
      "42 Train Loss 11.379322 Test MSE 3.465775241009127 Test RE 0.8898324876130458\n",
      "43 Train Loss 11.12995 Test MSE 3.5498648573532505 Test RE 0.9005627312291901\n",
      "44 Train Loss 10.7291355 Test MSE 3.5800959774110215 Test RE 0.9043892575439517\n",
      "45 Train Loss 10.554253 Test MSE 3.540877022780336 Test RE 0.8994219499597575\n",
      "46 Train Loss 10.358065 Test MSE 3.570910239471405 Test RE 0.903228280518793\n",
      "47 Train Loss 10.241793 Test MSE 3.576619432843168 Test RE 0.9039500356274014\n",
      "48 Train Loss 10.127976 Test MSE 3.5897304256154174 Test RE 0.9056053474576969\n",
      "49 Train Loss 9.9945345 Test MSE 3.656649553418086 Test RE 0.914007439068466\n",
      "50 Train Loss 9.847452 Test MSE 3.6187597788772616 Test RE 0.9092596891006213\n",
      "51 Train Loss 9.760199 Test MSE 3.618572055281163 Test RE 0.9092361048172273\n",
      "52 Train Loss 9.681204 Test MSE 3.627778809435729 Test RE 0.9103920573936242\n",
      "53 Train Loss 9.607807 Test MSE 3.709828681190575 Test RE 0.9206297130776862\n",
      "54 Train Loss 9.436141 Test MSE 3.687546473877206 Test RE 0.9178607769141279\n",
      "55 Train Loss 9.380718 Test MSE 3.738250190023566 Test RE 0.9241495200673516\n",
      "56 Train Loss 9.316821 Test MSE 3.7280967441202124 Test RE 0.9228936273587478\n",
      "57 Train Loss 9.270171 Test MSE 3.753810103889374 Test RE 0.9260708407296109\n",
      "58 Train Loss 9.243052 Test MSE 3.763564897824293 Test RE 0.9272733215157667\n",
      "59 Train Loss 9.201221 Test MSE 3.803777693400644 Test RE 0.9322140064912975\n",
      "60 Train Loss 9.155916 Test MSE 3.768460829936043 Test RE 0.9278762594034622\n",
      "61 Train Loss 9.128287 Test MSE 3.7768798524781815 Test RE 0.9289121535418495\n",
      "62 Train Loss 9.105051 Test MSE 3.778569586360026 Test RE 0.9291199227697144\n",
      "63 Train Loss 9.047714 Test MSE 3.790590057755742 Test RE 0.9305966179794869\n",
      "64 Train Loss 9.024862 Test MSE 3.8314983935788534 Test RE 0.9356046770937289\n",
      "65 Train Loss 8.970463 Test MSE 3.8351085704064256 Test RE 0.9360453536522539\n",
      "66 Train Loss 8.945796 Test MSE 3.8399043917103977 Test RE 0.9366304353560472\n",
      "67 Train Loss 8.914213 Test MSE 3.821315506266437 Test RE 0.9343605821640241\n",
      "68 Train Loss 8.855006 Test MSE 3.778267429726049 Test RE 0.929082773081898\n",
      "69 Train Loss 8.820254 Test MSE 3.7583385760345256 Test RE 0.9266292629555638\n",
      "70 Train Loss 8.751369 Test MSE 3.7447954543090303 Test RE 0.9249582082448813\n",
      "71 Train Loss 8.681823 Test MSE 3.705640989647579 Test RE 0.9201099583681583\n",
      "72 Train Loss 8.624506 Test MSE 3.708741400090779 Test RE 0.9204947935536236\n",
      "73 Train Loss 8.58 Test MSE 3.6760413527503055 Test RE 0.9164277984790175\n",
      "74 Train Loss 8.5248785 Test MSE 3.4944450161958827 Test RE 0.8935053679518914\n",
      "75 Train Loss 8.004522 Test MSE 2.8521275540525517 Test RE 0.8072211502053428\n",
      "76 Train Loss 5.930809 Test MSE 2.182556448727297 Test RE 0.7061399829499269\n",
      "77 Train Loss 5.336705 Test MSE 1.973871260566405 Test RE 0.6715331745006545\n",
      "78 Train Loss 4.857917 Test MSE 1.8246699118872858 Test RE 0.645654549649389\n",
      "79 Train Loss 4.5761685 Test MSE 1.7928662644444275 Test RE 0.6400029973946841\n",
      "80 Train Loss 4.272649 Test MSE 1.73964997139206 Test RE 0.63043308594096\n",
      "81 Train Loss 4.120387 Test MSE 1.7071184778228872 Test RE 0.6245107117070218\n",
      "82 Train Loss 4.0592175 Test MSE 1.6910326929275903 Test RE 0.6215614372586385\n",
      "83 Train Loss 4.0349708 Test MSE 1.690972980529838 Test RE 0.6215504631208904\n",
      "84 Train Loss 3.9988523 Test MSE 1.6607284086784657 Test RE 0.6159668892765381\n",
      "85 Train Loss 3.873268 Test MSE 1.6145679997806412 Test RE 0.6073460769872202\n",
      "86 Train Loss 3.7946372 Test MSE 1.5603159007478693 Test RE 0.5970549831726525\n",
      "87 Train Loss 3.742331 Test MSE 1.5115399787334225 Test RE 0.5876488349069141\n",
      "88 Train Loss 3.6841016 Test MSE 1.4909952870863117 Test RE 0.5836415412127359\n",
      "89 Train Loss 2.987842 Test MSE 0.794757489133655 Test RE 0.4261135796625342\n",
      "90 Train Loss 2.256915 Test MSE 0.5396080202570532 Test RE 0.3511132819299797\n",
      "91 Train Loss 1.6060778 Test MSE 0.18353763690472824 Test RE 0.20477202645536224\n",
      "92 Train Loss 0.9102502 Test MSE 0.08621535823336123 Test RE 0.140346109710399\n",
      "93 Train Loss 0.6627612 Test MSE 0.04621643541947826 Test RE 0.10275578547066402\n",
      "94 Train Loss 0.5095299 Test MSE 0.03122217974678929 Test RE 0.08445778163977419\n",
      "95 Train Loss 0.41193646 Test MSE 0.029033715742088524 Test RE 0.08144405162606255\n",
      "96 Train Loss 0.3693116 Test MSE 0.028074521626912242 Test RE 0.08008740885049367\n",
      "97 Train Loss 0.34970722 Test MSE 0.028545243197632953 Test RE 0.08075602503421159\n",
      "98 Train Loss 0.32045174 Test MSE 0.024892410705870748 Test RE 0.07541218759924184\n",
      "99 Train Loss 0.2866094 Test MSE 0.024976192563312023 Test RE 0.075538990619472\n",
      "Training time: 78.58\n",
      "KG_stan_tune4\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.90146 Test MSE 8.72449536222314 Test RE 1.4118163866098337\n",
      "1 Train Loss 57.79598 Test MSE 8.679964727535394 Test RE 1.4082087563150625\n",
      "2 Train Loss 57.227974 Test MSE 8.585109524789793 Test RE 1.4004931220609877\n",
      "3 Train Loss 54.28125 Test MSE 9.596823559346157 Test RE 1.480716157452114\n",
      "4 Train Loss 46.91561 Test MSE 8.770382793767155 Test RE 1.4155243182979564\n",
      "5 Train Loss 45.95656 Test MSE 8.655984989959842 Test RE 1.4062622143409207\n",
      "6 Train Loss 45.055588 Test MSE 8.315187207492201 Test RE 1.3783010149239114\n",
      "7 Train Loss 44.54066 Test MSE 8.508744531519026 Test RE 1.3942504795159836\n",
      "8 Train Loss 44.312748 Test MSE 8.418295716786677 Test RE 1.3868201687318418\n",
      "9 Train Loss 44.205242 Test MSE 8.454731498955146 Test RE 1.389818122346807\n",
      "10 Train Loss 44.125557 Test MSE 8.472125741503318 Test RE 1.391247050772416\n",
      "11 Train Loss 43.849525 Test MSE 8.479056512539206 Test RE 1.391816001460059\n",
      "12 Train Loss 43.580578 Test MSE 8.4651495165463 Test RE 1.3906741336850184\n",
      "13 Train Loss 40.578674 Test MSE 6.979413818355869 Test RE 1.262750458169731\n",
      "14 Train Loss 37.02625 Test MSE 7.041056540050382 Test RE 1.2683145543148913\n",
      "15 Train Loss 35.279175 Test MSE 7.300870932795616 Test RE 1.291502929851801\n",
      "16 Train Loss 33.778896 Test MSE 7.121438870091473 Test RE 1.275533695096059\n",
      "17 Train Loss 33.11968 Test MSE 7.093577415148583 Test RE 1.2730360922418262\n",
      "18 Train Loss 32.801693 Test MSE 7.1815882552532795 Test RE 1.2809091006264224\n",
      "19 Train Loss 32.643654 Test MSE 7.118411079858334 Test RE 1.2752625097973953\n",
      "20 Train Loss 32.353905 Test MSE 7.213425293726171 Test RE 1.2837451902521653\n",
      "21 Train Loss 32.042595 Test MSE 6.992909955827119 Test RE 1.2639707628755172\n",
      "22 Train Loss 31.592735 Test MSE 7.207051731528051 Test RE 1.283177925906161\n",
      "23 Train Loss 30.797142 Test MSE 7.560706446800837 Test RE 1.3142840835883758\n",
      "24 Train Loss 30.154282 Test MSE 7.35983354136144 Test RE 1.2967075999867572\n",
      "25 Train Loss 29.422771 Test MSE 7.215141557919379 Test RE 1.2838978995945742\n",
      "26 Train Loss 28.080307 Test MSE 6.970702262188444 Test RE 1.26196214294538\n",
      "27 Train Loss 24.024271 Test MSE 5.729118619964861 Test RE 1.1440683399147837\n",
      "28 Train Loss 20.211897 Test MSE 5.625556671498997 Test RE 1.1336808543864219\n",
      "29 Train Loss 18.745937 Test MSE 5.445214145768047 Test RE 1.1153612248415274\n",
      "30 Train Loss 17.708452 Test MSE 5.185316379086407 Test RE 1.0884179366772662\n",
      "31 Train Loss 16.391409 Test MSE 5.176736762847939 Test RE 1.0875171166051774\n",
      "32 Train Loss 15.772643 Test MSE 5.083664311608668 Test RE 1.0776965507388165\n",
      "33 Train Loss 15.38819 Test MSE 4.724150700319613 Test RE 1.038890875365171\n",
      "34 Train Loss 14.414471 Test MSE 4.305449475040871 Test RE 0.9917844820669813\n",
      "35 Train Loss 13.293567 Test MSE 3.8810838065984803 Test RE 0.9416392889060299\n",
      "36 Train Loss 11.741378 Test MSE 3.587126773237874 Test RE 0.9052768674692534\n",
      "37 Train Loss 9.861182 Test MSE 3.376989754583899 Test RE 0.8783607721045514\n",
      "38 Train Loss 7.6920204 Test MSE 2.30886641956889 Test RE 0.7262856508869961\n",
      "39 Train Loss 6.4722977 Test MSE 2.0427288077543553 Test RE 0.6831458227505636\n",
      "40 Train Loss 5.6273026 Test MSE 1.0829754677920713 Test RE 0.49741327285718656\n",
      "41 Train Loss 3.863922 Test MSE 0.5947271071020728 Test RE 0.3686098422404273\n",
      "42 Train Loss 2.6412861 Test MSE 0.480501551343059 Test RE 0.3313259541821736\n",
      "43 Train Loss 1.6737523 Test MSE 0.42032231582448454 Test RE 0.30988409360054714\n",
      "44 Train Loss 1.2332366 Test MSE 0.2804353671706698 Test RE 0.25311882875303343\n",
      "45 Train Loss 0.90611756 Test MSE 0.16450912686541175 Test RE 0.1938666290897587\n",
      "46 Train Loss 0.7260846 Test MSE 0.24416742815999576 Test RE 0.23618478918027225\n",
      "47 Train Loss 0.62990284 Test MSE 0.2812592000515695 Test RE 0.2534903487453919\n",
      "48 Train Loss 0.53850603 Test MSE 0.26087862530918327 Test RE 0.24413346151308615\n",
      "49 Train Loss 0.44395804 Test MSE 0.16692736882311582 Test RE 0.19528632568357196\n",
      "50 Train Loss 0.3877605 Test MSE 0.10567730400121439 Test RE 0.1553813616159278\n",
      "51 Train Loss 0.32472372 Test MSE 0.11004396091373438 Test RE 0.15855909825416464\n",
      "52 Train Loss 0.26857027 Test MSE 0.11686835502421832 Test RE 0.16340168319592926\n",
      "53 Train Loss 0.21302713 Test MSE 0.09412146511681499 Test RE 0.14663998236407683\n",
      "54 Train Loss 0.18964237 Test MSE 0.0879911714996361 Test RE 0.14178412593163134\n",
      "55 Train Loss 0.16032586 Test MSE 0.03368801509186012 Test RE 0.08772952375383035\n",
      "56 Train Loss 0.13199988 Test MSE 0.024721915796853757 Test RE 0.07515348453736984\n",
      "57 Train Loss 0.12203075 Test MSE 0.023004456537319393 Test RE 0.07249600072918261\n",
      "58 Train Loss 0.112771586 Test MSE 0.01911756514776738 Test RE 0.06608826486404858\n",
      "59 Train Loss 0.09638514 Test MSE 0.014796228827770938 Test RE 0.05814114494540931\n",
      "60 Train Loss 0.08746795 Test MSE 0.01436822537079804 Test RE 0.05729406362403801\n",
      "61 Train Loss 0.08423964 Test MSE 0.014477295873192575 Test RE 0.05751111470676978\n",
      "62 Train Loss 0.07820888 Test MSE 0.013188680599635847 Test RE 0.05489195967832099\n",
      "63 Train Loss 0.06979522 Test MSE 0.012579130991702586 Test RE 0.05360846599754777\n",
      "64 Train Loss 0.065866426 Test MSE 0.01183700793209586 Test RE 0.0520030755850159\n",
      "65 Train Loss 0.06310351 Test MSE 0.010881523343896086 Test RE 0.049860072919706656\n",
      "66 Train Loss 0.05916805 Test MSE 0.011345174994931045 Test RE 0.05091123823406059\n",
      "67 Train Loss 0.053943913 Test MSE 0.009322208665164382 Test RE 0.046149549953838326\n",
      "68 Train Loss 0.051355116 Test MSE 0.008167948595621458 Test RE 0.04319809132080929\n",
      "69 Train Loss 0.04710511 Test MSE 0.007646879274918496 Test RE 0.04179748755991526\n",
      "70 Train Loss 0.046304002 Test MSE 0.00736207884903086 Test RE 0.04101174916873415\n",
      "71 Train Loss 0.041373488 Test MSE 0.007672919135294906 Test RE 0.04186859341203007\n",
      "72 Train Loss 0.03680885 Test MSE 0.006903909245211557 Test RE 0.039715094215834815\n",
      "73 Train Loss 0.03628357 Test MSE 0.006708272265618125 Test RE 0.03914834443580414\n",
      "74 Train Loss 0.034786303 Test MSE 0.006551361819747148 Test RE 0.038687783868116304\n",
      "75 Train Loss 0.031338207 Test MSE 0.006379435791504758 Test RE 0.03817677123926666\n",
      "76 Train Loss 0.03014861 Test MSE 0.005692053276651868 Test RE 0.03606139628583724\n",
      "77 Train Loss 0.027960753 Test MSE 0.005550335302143172 Test RE 0.035609647150607424\n",
      "78 Train Loss 0.026520265 Test MSE 0.005673811921678612 Test RE 0.03600356683787865\n",
      "79 Train Loss 0.025146127 Test MSE 0.005604321644298165 Test RE 0.035782409908268906\n",
      "80 Train Loss 0.02476462 Test MSE 0.005468724710275571 Test RE 0.035346880470731916\n",
      "81 Train Loss 0.02394667 Test MSE 0.005360784549888491 Test RE 0.03499630855139112\n",
      "82 Train Loss 0.022346891 Test MSE 0.004725852747299156 Test RE 0.03285853170632677\n",
      "83 Train Loss 0.019963212 Test MSE 0.003962420166787561 Test RE 0.030087653776302656\n",
      "84 Train Loss 0.018059205 Test MSE 0.0033455309978209988 Test RE 0.027646527448618917\n",
      "85 Train Loss 0.017519698 Test MSE 0.003344777307970402 Test RE 0.027643413132709703\n",
      "86 Train Loss 0.01735955 Test MSE 0.003163067265403016 Test RE 0.026882043165055453\n",
      "87 Train Loss 0.016949458 Test MSE 0.003091907432488406 Test RE 0.026577939096933297\n",
      "88 Train Loss 0.015675854 Test MSE 0.002837552795665858 Test RE 0.025461268437240624\n",
      "89 Train Loss 0.013778253 Test MSE 0.0024885538708710265 Test RE 0.023844135632329806\n",
      "90 Train Loss 0.013196636 Test MSE 0.0024597569006827883 Test RE 0.023705774784589594\n",
      "91 Train Loss 0.012891792 Test MSE 0.002460376586277768 Test RE 0.023708760689831854\n",
      "92 Train Loss 0.011865348 Test MSE 0.0021402891196239714 Test RE 0.022112827708337463\n",
      "93 Train Loss 0.010356846 Test MSE 0.0021902435090545183 Test RE 0.022369396178166728\n",
      "94 Train Loss 0.009426715 Test MSE 0.001846796481156386 Test RE 0.020540810663955404\n",
      "95 Train Loss 0.009212481 Test MSE 0.0018129882358167047 Test RE 0.020351927800966937\n",
      "96 Train Loss 0.009138125 Test MSE 0.0017759536513804904 Test RE 0.0201429870717784\n",
      "97 Train Loss 0.008924371 Test MSE 0.0018871436671809578 Test RE 0.020763977150306433\n",
      "98 Train Loss 0.00863701 Test MSE 0.0018811965483008528 Test RE 0.020731233675555724\n",
      "99 Train Loss 0.007693164 Test MSE 0.001589081802053673 Test RE 0.019053781796600295\n",
      "Training time: 78.45\n",
      "KG_stan_tune4\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.948166 Test MSE 8.605041047787783 Test RE 1.4021178991262533\n",
      "1 Train Loss 58.15104 Test MSE 8.460947861715526 Test RE 1.3903289621132517\n",
      "2 Train Loss 56.65529 Test MSE 8.849237098533049 Test RE 1.421873551654907\n",
      "3 Train Loss 52.93936 Test MSE 8.992663799977423 Test RE 1.4333499607184292\n",
      "4 Train Loss 48.07988 Test MSE 8.697313931533465 Test RE 1.409615392507358\n",
      "5 Train Loss 46.87549 Test MSE 8.636927550493004 Test RE 1.4047133135382064\n",
      "6 Train Loss 46.02808 Test MSE 8.601903251762234 Test RE 1.4018622372943865\n",
      "7 Train Loss 45.86656 Test MSE 8.27305683639187 Test RE 1.374804877548914\n",
      "8 Train Loss 45.473793 Test MSE 8.428032881202085 Test RE 1.3876219814673791\n",
      "9 Train Loss 45.131996 Test MSE 8.46746518597402 Test RE 1.3908643324148444\n",
      "10 Train Loss 45.02318 Test MSE 8.413184752614628 Test RE 1.3863991176910064\n",
      "11 Train Loss 44.593246 Test MSE 8.47753009303041 Test RE 1.3916907168416053\n",
      "12 Train Loss 44.258503 Test MSE 8.486616972668283 Test RE 1.3924363785459357\n",
      "13 Train Loss 44.12494 Test MSE 8.39662719210089 Test RE 1.3850341950474128\n",
      "14 Train Loss 43.934258 Test MSE 8.565963485892562 Test RE 1.398930599059687\n",
      "15 Train Loss 43.68654 Test MSE 8.518576828408914 Test RE 1.3950558114080538\n",
      "16 Train Loss 43.40851 Test MSE 8.492816862733598 Test RE 1.3929449072314273\n",
      "17 Train Loss 43.201683 Test MSE 8.66009796634666 Test RE 1.406596274322491\n",
      "18 Train Loss 43.048492 Test MSE 8.6847319168051 Test RE 1.4085954097396327\n",
      "19 Train Loss 42.97503 Test MSE 8.704463577589632 Test RE 1.4101946622019923\n",
      "20 Train Loss 41.44699 Test MSE 9.21068016745183 Test RE 1.4506208365318805\n",
      "21 Train Loss 37.717266 Test MSE 8.9611461667911 Test RE 1.4308359419565675\n",
      "22 Train Loss 35.568058 Test MSE 8.783646054090479 Test RE 1.4165942473578153\n",
      "23 Train Loss 34.226036 Test MSE 8.805702217628074 Test RE 1.4183717008538508\n",
      "24 Train Loss 33.63609 Test MSE 8.615409360154656 Test RE 1.4029623587737923\n",
      "25 Train Loss 32.866573 Test MSE 8.08549144424289 Test RE 1.3591308527686559\n",
      "26 Train Loss 32.443874 Test MSE 8.335445545681896 Test RE 1.3799789748658038\n",
      "27 Train Loss 31.917755 Test MSE 8.561924958492343 Test RE 1.3986007887810739\n",
      "28 Train Loss 31.47569 Test MSE 8.538209417240706 Test RE 1.39666246445535\n",
      "29 Train Loss 31.252728 Test MSE 8.601976802320703 Test RE 1.401868230591859\n",
      "30 Train Loss 31.091673 Test MSE 8.62493407575735 Test RE 1.4037376629789697\n",
      "31 Train Loss 30.656357 Test MSE 8.486489459932486 Test RE 1.3924259177204052\n",
      "32 Train Loss 30.477777 Test MSE 8.50309020707232 Test RE 1.3937871412001939\n",
      "33 Train Loss 30.127472 Test MSE 8.460747899723845 Test RE 1.390312532831596\n",
      "34 Train Loss 29.522057 Test MSE 8.870415817992818 Test RE 1.423574007002086\n",
      "35 Train Loss 28.782387 Test MSE 8.826145033438761 Test RE 1.420017151815062\n",
      "36 Train Loss 28.346087 Test MSE 9.14775315638496 Test RE 1.4456570511475995\n",
      "37 Train Loss 28.050957 Test MSE 9.069101675920887 Test RE 1.4394288263768242\n",
      "38 Train Loss 27.433674 Test MSE 9.037284608188505 Test RE 1.4369016387193834\n",
      "39 Train Loss 27.12698 Test MSE 9.149164186154096 Test RE 1.4457685422670388\n",
      "40 Train Loss 26.676521 Test MSE 9.2848370655149 Test RE 1.4564487386618628\n",
      "41 Train Loss 26.536549 Test MSE 9.240254439187384 Test RE 1.452947845601966\n",
      "42 Train Loss 26.222527 Test MSE 9.154856831337518 Test RE 1.446218253701673\n",
      "43 Train Loss 25.631695 Test MSE 8.98425894460533 Test RE 1.4326799748493468\n",
      "44 Train Loss 25.268435 Test MSE 9.06657269571402 Test RE 1.4392281151621837\n",
      "45 Train Loss 25.073788 Test MSE 9.10611238899099 Test RE 1.4423629673280944\n",
      "46 Train Loss 24.90273 Test MSE 9.095694462235539 Test RE 1.441537657286532\n",
      "47 Train Loss 24.712334 Test MSE 9.04258474965175 Test RE 1.4373229304012882\n",
      "48 Train Loss 24.49858 Test MSE 8.987443274934655 Test RE 1.43293384788174\n",
      "49 Train Loss 24.266573 Test MSE 9.076813173511287 Test RE 1.440040672714986\n",
      "50 Train Loss 24.108284 Test MSE 8.99997901201735 Test RE 1.4339328318033409\n",
      "51 Train Loss 23.973278 Test MSE 9.030950984655231 Test RE 1.4363980367238245\n",
      "52 Train Loss 23.824867 Test MSE 9.073384280611785 Test RE 1.4397686492879902\n",
      "53 Train Loss 23.6792 Test MSE 9.10945765854481 Test RE 1.4426278800401575\n",
      "54 Train Loss 23.605701 Test MSE 9.03368639409334 Test RE 1.4366155575182304\n",
      "55 Train Loss 23.556622 Test MSE 9.044843107213685 Test RE 1.4375024026736005\n",
      "56 Train Loss 23.35745 Test MSE 9.062340548087912 Test RE 1.4388921703116575\n",
      "57 Train Loss 23.275438 Test MSE 9.054157284226855 Test RE 1.4382423661250456\n",
      "58 Train Loss 23.214203 Test MSE 8.994549193379509 Test RE 1.4335002102432988\n",
      "59 Train Loss 23.067596 Test MSE 8.975838799751855 Test RE 1.4320084558739068\n",
      "60 Train Loss 23.018875 Test MSE 8.972311215493193 Test RE 1.4317270322085789\n",
      "61 Train Loss 22.985493 Test MSE 8.986696074164897 Test RE 1.4328742808004165\n",
      "62 Train Loss 22.893019 Test MSE 9.005052741053046 Test RE 1.434336963943549\n",
      "63 Train Loss 22.825222 Test MSE 9.000802138352626 Test RE 1.4339984031168505\n",
      "64 Train Loss 22.639183 Test MSE 9.027597145739213 Test RE 1.4361312932218637\n",
      "65 Train Loss 22.599869 Test MSE 9.030379010585502 Test RE 1.4363525489650422\n",
      "66 Train Loss 22.571964 Test MSE 9.033993014935133 Test RE 1.4366399380708972\n",
      "67 Train Loss 22.492817 Test MSE 9.038695062666633 Test RE 1.4370137633988938\n",
      "68 Train Loss 22.446613 Test MSE 9.065689942627172 Test RE 1.4391580493263856\n",
      "69 Train Loss 22.405731 Test MSE 9.026935763721461 Test RE 1.4360786851582528\n",
      "70 Train Loss 22.370428 Test MSE 9.030405787866613 Test RE 1.4363546785316648\n",
      "71 Train Loss 22.338024 Test MSE 8.990570757401263 Test RE 1.4331831449034764\n",
      "72 Train Loss 22.273537 Test MSE 9.024165086356197 Test RE 1.435858277249362\n",
      "73 Train Loss 22.200047 Test MSE 9.015383993524548 Test RE 1.435159516012435\n",
      "74 Train Loss 22.129513 Test MSE 8.996584838774428 Test RE 1.433662415872043\n",
      "75 Train Loss 22.044445 Test MSE 9.008631559631365 Test RE 1.4346219551593955\n",
      "76 Train Loss 22.025702 Test MSE 9.022960049994495 Test RE 1.4357624058205942\n",
      "77 Train Loss 22.016495 Test MSE 9.022064154640972 Test RE 1.4356911251770024\n",
      "78 Train Loss 22.004562 Test MSE 9.020751197364527 Test RE 1.4355866551986234\n",
      "79 Train Loss 21.93148 Test MSE 9.034475899860636 Test RE 1.436678333191318\n",
      "80 Train Loss 21.861288 Test MSE 9.029847293905576 Test RE 1.4363102614901593\n",
      "81 Train Loss 21.78297 Test MSE 9.046571594428034 Test RE 1.4376397508728744\n",
      "82 Train Loss 21.741678 Test MSE 9.087831051236641 Test RE 1.4409144033889139\n",
      "83 Train Loss 21.720861 Test MSE 9.078417134987353 Test RE 1.4401679017153057\n",
      "84 Train Loss 21.675987 Test MSE 9.012314512463526 Test RE 1.434915179776632\n",
      "85 Train Loss 21.576168 Test MSE 9.086641469851282 Test RE 1.4408200936994584\n",
      "86 Train Loss 21.501534 Test MSE 9.12599330633256 Test RE 1.4439366281464643\n",
      "87 Train Loss 21.46511 Test MSE 9.123501009738556 Test RE 1.4437394460998458\n",
      "88 Train Loss 21.411972 Test MSE 9.045057300398332 Test RE 1.4375194234992277\n",
      "89 Train Loss 21.375422 Test MSE 9.041744505324855 Test RE 1.437256150242291\n",
      "90 Train Loss 21.339184 Test MSE 9.078531546149911 Test RE 1.4401769765772736\n",
      "91 Train Loss 21.29972 Test MSE 9.038084183979535 Test RE 1.43696520241151\n",
      "92 Train Loss 21.274557 Test MSE 9.062439103071206 Test RE 1.4388999944277072\n",
      "93 Train Loss 21.20443 Test MSE 9.045287722391508 Test RE 1.4375377337193984\n",
      "94 Train Loss 21.063108 Test MSE 8.936920786345244 Test RE 1.4289005866667503\n",
      "95 Train Loss 20.915981 Test MSE 8.982826484360347 Test RE 1.4325657562515488\n",
      "96 Train Loss 20.784935 Test MSE 8.920536941474891 Test RE 1.4275902010423942\n",
      "97 Train Loss 20.66555 Test MSE 8.912942903199033 Test RE 1.4269824190808826\n",
      "98 Train Loss 20.319576 Test MSE 8.557191339863683 Test RE 1.3982141141669224\n",
      "99 Train Loss 19.722298 Test MSE 7.786575291348558 Test RE 1.333771103055291\n",
      "Training time: 79.49\n",
      "KG_stan_tune4\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.712597 Test MSE 8.506192090831632 Test RE 1.3940413412250336\n",
      "1 Train Loss 55.4969 Test MSE 8.443390845430123 Test RE 1.3888857015659146\n",
      "2 Train Loss 55.003254 Test MSE 8.663697739607798 Test RE 1.4068885863496388\n",
      "3 Train Loss 49.675213 Test MSE 7.749492717472441 Test RE 1.3305913551822695\n",
      "4 Train Loss 46.402836 Test MSE 8.045281892639132 Test RE 1.355747127960118\n",
      "5 Train Loss 44.544426 Test MSE 8.093732591180203 Test RE 1.3598233242460571\n",
      "6 Train Loss 44.14476 Test MSE 8.183207676235268 Test RE 1.367318993894201\n",
      "7 Train Loss 43.388065 Test MSE 8.195268971121408 Test RE 1.3683262740419289\n",
      "8 Train Loss 43.18387 Test MSE 7.988810804663126 Test RE 1.3509806488304807\n",
      "9 Train Loss 42.975777 Test MSE 8.211336330652118 Test RE 1.3696669637057062\n",
      "10 Train Loss 42.463844 Test MSE 8.059025762402136 Test RE 1.3569046548902737\n",
      "11 Train Loss 42.043396 Test MSE 8.14747827414824 Test RE 1.364330744381778\n",
      "12 Train Loss 40.50558 Test MSE 7.883672456789209 Test RE 1.3420612793684377\n",
      "13 Train Loss 39.826412 Test MSE 7.6185536846833415 Test RE 1.319302320677504\n",
      "14 Train Loss 39.099068 Test MSE 7.5525973221621 Test RE 1.3135790864600527\n",
      "15 Train Loss 38.978786 Test MSE 7.583509031322559 Test RE 1.3162644879290484\n",
      "16 Train Loss 38.42435 Test MSE 7.34779619775395 Test RE 1.2956467538175145\n",
      "17 Train Loss 38.313942 Test MSE 7.410565358958963 Test RE 1.3011690703564192\n",
      "18 Train Loss 37.842533 Test MSE 7.493128252610264 Test RE 1.3083973122396768\n",
      "19 Train Loss 36.574673 Test MSE 6.677824953837418 Test RE 1.2351667028967979\n",
      "20 Train Loss 33.213997 Test MSE 6.428041574102731 Test RE 1.211845902512232\n",
      "21 Train Loss 32.521244 Test MSE 6.296186908915607 Test RE 1.199352559530461\n",
      "22 Train Loss 31.42513 Test MSE 5.837238643628782 Test RE 1.1548133205459783\n",
      "23 Train Loss 28.985798 Test MSE 4.466063494323921 Test RE 1.0101142709007696\n",
      "24 Train Loss 26.618477 Test MSE 4.0123597610915 Test RE 0.9574321206951978\n",
      "25 Train Loss 24.69973 Test MSE 3.151186768464129 Test RE 0.848486882174989\n",
      "26 Train Loss 22.808912 Test MSE 2.7789728240330267 Test RE 0.7968016232517242\n",
      "27 Train Loss 20.389282 Test MSE 2.4801234191066817 Test RE 0.7527395011980423\n",
      "28 Train Loss 18.088968 Test MSE 2.2261325725929884 Test RE 0.7131544104393328\n",
      "29 Train Loss 15.976534 Test MSE 1.523537356272773 Test RE 0.5899763652723946\n",
      "30 Train Loss 12.623225 Test MSE 0.616953689564308 Test RE 0.3754346419459284\n",
      "31 Train Loss 9.370018 Test MSE 0.41830926279046465 Test RE 0.3091411377859866\n",
      "32 Train Loss 7.6468225 Test MSE 0.32136584454052963 Test RE 0.27096170652171697\n",
      "33 Train Loss 5.6811666 Test MSE 0.2770168451802138 Test RE 0.2515713323071076\n",
      "34 Train Loss 5.0237265 Test MSE 0.22464718173947754 Test RE 0.22654712106716784\n",
      "35 Train Loss 4.414483 Test MSE 0.18443575031964465 Test RE 0.2052724253756812\n",
      "36 Train Loss 3.970626 Test MSE 0.14081646574657986 Test RE 0.17936379339434158\n",
      "37 Train Loss 3.7678561 Test MSE 0.14735377136008038 Test RE 0.18347998167803753\n",
      "38 Train Loss 3.505498 Test MSE 0.13061845185888496 Test RE 0.17274692535128455\n",
      "39 Train Loss 3.1948013 Test MSE 0.13543270743572133 Test RE 0.1759016205475876\n",
      "40 Train Loss 3.0697455 Test MSE 0.14517199964708286 Test RE 0.18211658157409152\n",
      "41 Train Loss 2.7021644 Test MSE 0.11040032622050022 Test RE 0.15881562886639564\n",
      "42 Train Loss 2.5150747 Test MSE 0.12032560823851912 Test RE 0.1658009799681146\n",
      "43 Train Loss 2.3677766 Test MSE 0.11419619972348918 Test RE 0.16152281916204136\n",
      "44 Train Loss 2.1604939 Test MSE 0.10611449225609378 Test RE 0.15570243714950818\n",
      "45 Train Loss 1.9511024 Test MSE 0.09021848243996956 Test RE 0.14356739460235\n",
      "46 Train Loss 1.7654922 Test MSE 0.07342921836289332 Test RE 0.12952169311762884\n",
      "47 Train Loss 1.7070909 Test MSE 0.08166331208182019 Test RE 0.13659083352720786\n",
      "48 Train Loss 1.6392231 Test MSE 0.08760391770070879 Test RE 0.14147178217429848\n",
      "49 Train Loss 1.5445628 Test MSE 0.07598877326357163 Test RE 0.1317597545138233\n",
      "50 Train Loss 1.4726571 Test MSE 0.08093208538684755 Test RE 0.13597793006553383\n",
      "51 Train Loss 1.2943124 Test MSE 0.07806629627134944 Test RE 0.13354875632701835\n",
      "52 Train Loss 1.1835223 Test MSE 0.060283495929506346 Test RE 0.11735653415046228\n",
      "53 Train Loss 1.0156724 Test MSE 0.05604400661806628 Test RE 0.11315471317760523\n",
      "54 Train Loss 0.97611046 Test MSE 0.052625478389455194 Test RE 0.10964935685439922\n",
      "55 Train Loss 0.9431978 Test MSE 0.04763636767226365 Test RE 0.10432235433093365\n",
      "56 Train Loss 0.92174315 Test MSE 0.045001782850894 Test RE 0.1013964896888077\n",
      "57 Train Loss 0.84678614 Test MSE 0.04508620977371668 Test RE 0.10149155905873834\n",
      "58 Train Loss 0.7998466 Test MSE 0.04489196825416532 Test RE 0.1012726988621944\n",
      "59 Train Loss 0.7583328 Test MSE 0.04622511424839056 Test RE 0.10276543309937732\n",
      "60 Train Loss 0.7277046 Test MSE 0.054667535658373984 Test RE 0.11175650429331307\n",
      "61 Train Loss 0.6840399 Test MSE 0.05847246119198908 Test RE 0.11558028138452882\n",
      "62 Train Loss 0.64556533 Test MSE 0.05474845974525828 Test RE 0.11183919000942062\n",
      "63 Train Loss 0.60945386 Test MSE 0.05846296046144527 Test RE 0.11557089113742668\n",
      "64 Train Loss 0.57486516 Test MSE 0.05697359893782586 Test RE 0.1140892925930539\n",
      "65 Train Loss 0.5410567 Test MSE 0.043078707063869716 Test RE 0.09920633149946938\n",
      "66 Train Loss 0.5289921 Test MSE 0.0449657299413764 Test RE 0.10135586495459513\n",
      "67 Train Loss 0.4922953 Test MSE 0.04031372581301594 Test RE 0.09596978660679804\n",
      "68 Train Loss 0.45824596 Test MSE 0.03734456108442612 Test RE 0.09236804250881396\n",
      "69 Train Loss 0.44779724 Test MSE 0.036293362124013274 Test RE 0.09105874517694877\n",
      "70 Train Loss 0.41863292 Test MSE 0.033904164772785524 Test RE 0.08801051965823711\n",
      "71 Train Loss 0.39978555 Test MSE 0.028736179177628746 Test RE 0.08102565896527428\n",
      "72 Train Loss 0.38946998 Test MSE 0.02635146058425822 Test RE 0.07759083154022471\n",
      "73 Train Loss 0.36809382 Test MSE 0.023919952566174053 Test RE 0.07392446962322699\n",
      "74 Train Loss 0.3440696 Test MSE 0.02499870045105594 Test RE 0.07557301983029455\n",
      "75 Train Loss 0.33314833 Test MSE 0.024599086049955244 Test RE 0.07496655367426569\n",
      "76 Train Loss 0.32568586 Test MSE 0.023651497364015596 Test RE 0.07350846953644773\n",
      "77 Train Loss 0.3223967 Test MSE 0.02303735024798326 Test RE 0.07254781266026368\n",
      "78 Train Loss 0.31693053 Test MSE 0.024658531297019046 Test RE 0.07505707972567023\n",
      "79 Train Loss 0.31103796 Test MSE 0.023401594708539798 Test RE 0.07311909156282358\n",
      "80 Train Loss 0.30805224 Test MSE 0.022582300340276945 Test RE 0.07182773138571012\n",
      "81 Train Loss 0.30378804 Test MSE 0.023065709304431418 Test RE 0.07259245222859383\n",
      "82 Train Loss 0.29830557 Test MSE 0.022976298001181266 Test RE 0.07245161788705029\n",
      "83 Train Loss 0.28796953 Test MSE 0.022960760212439743 Test RE 0.07242711593469217\n",
      "84 Train Loss 0.28039527 Test MSE 0.023201230783862253 Test RE 0.07280539665299347\n",
      "85 Train Loss 0.2709928 Test MSE 0.02357761283814115 Test RE 0.073393563775198\n",
      "86 Train Loss 0.25486827 Test MSE 0.02435183261175166 Test RE 0.07458884551758199\n",
      "87 Train Loss 0.24162957 Test MSE 0.021739340615848108 Test RE 0.0704743767602383\n",
      "88 Train Loss 0.23437649 Test MSE 0.021330964599969356 Test RE 0.0698093039454133\n",
      "89 Train Loss 0.23213354 Test MSE 0.021460101435291007 Test RE 0.07002029650616545\n",
      "90 Train Loss 0.225775 Test MSE 0.021126679941338856 Test RE 0.06947422115449241\n",
      "91 Train Loss 0.22013439 Test MSE 0.019126668414805502 Test RE 0.06610399771278884\n",
      "92 Train Loss 0.21845165 Test MSE 0.01895363350892925 Test RE 0.06580430394425343\n",
      "93 Train Loss 0.21307673 Test MSE 0.018998743844682264 Test RE 0.06588256572147583\n",
      "94 Train Loss 0.20626302 Test MSE 0.017418744551924725 Test RE 0.0630836023367816\n",
      "95 Train Loss 0.19948304 Test MSE 0.016273205120179268 Test RE 0.06097398921509518\n",
      "96 Train Loss 0.1935045 Test MSE 0.017311756390566153 Test RE 0.06288957015017695\n",
      "97 Train Loss 0.18684271 Test MSE 0.01492541271043762 Test RE 0.0583944046087892\n",
      "98 Train Loss 0.18383494 Test MSE 0.015019330828895311 Test RE 0.05857783981019359\n",
      "99 Train Loss 0.17984173 Test MSE 0.014262581370478864 Test RE 0.05708304448504042\n",
      "Training time: 61.05\n",
      "KG_stan_tune4\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.406754 Test MSE 8.559895135681888 Test RE 1.3984349919493675\n",
      "1 Train Loss 55.5313 Test MSE 8.686450511792057 Test RE 1.4087347741600567\n",
      "2 Train Loss 48.884933 Test MSE 7.377227452972954 Test RE 1.2982389869881172\n",
      "3 Train Loss 44.393913 Test MSE 6.3683116574990954 Test RE 1.2062024737965107\n",
      "4 Train Loss 39.81617 Test MSE 7.667529778097747 Test RE 1.323536113936172\n",
      "5 Train Loss 37.826233 Test MSE 7.375982715094647 Test RE 1.2981294583459138\n",
      "6 Train Loss 36.974403 Test MSE 7.636572861488192 Test RE 1.3208615865638973\n",
      "7 Train Loss 36.16893 Test MSE 7.596834966664655 Test RE 1.3174204670751024\n",
      "8 Train Loss 35.723106 Test MSE 7.7206071653842665 Test RE 1.3281092089404767\n",
      "9 Train Loss 34.381565 Test MSE 7.144884355296973 Test RE 1.2776316512346768\n",
      "10 Train Loss 33.063507 Test MSE 7.102842390045412 Test RE 1.2738671819720777\n",
      "11 Train Loss 31.856812 Test MSE 6.707888225507059 Test RE 1.237943913535228\n",
      "12 Train Loss 29.708378 Test MSE 6.824356340495275 Test RE 1.2486447865743078\n",
      "13 Train Loss 27.930107 Test MSE 6.601850362244389 Test RE 1.2281202673289902\n",
      "14 Train Loss 26.770924 Test MSE 6.536732026390956 Test RE 1.2220483837635612\n",
      "15 Train Loss 25.874577 Test MSE 6.220506671388775 Test RE 1.1921226523233894\n",
      "16 Train Loss 25.281204 Test MSE 6.242893185141625 Test RE 1.194265846100519\n",
      "17 Train Loss 24.594177 Test MSE 6.236367350889074 Test RE 1.1936414866489182\n",
      "18 Train Loss 24.304382 Test MSE 6.195317519708324 Test RE 1.189706529263621\n",
      "19 Train Loss 24.01944 Test MSE 6.194914870391402 Test RE 1.1896678676208972\n",
      "20 Train Loss 23.707537 Test MSE 6.249161805133558 Test RE 1.1948652893527916\n",
      "21 Train Loss 23.198658 Test MSE 6.078306565719378 Test RE 1.1784179806399564\n",
      "22 Train Loss 22.618734 Test MSE 5.2786316797028 Test RE 1.0981678880955639\n",
      "23 Train Loss 20.780611 Test MSE 4.36258016683898 Test RE 0.9983429848902926\n",
      "24 Train Loss 18.679852 Test MSE 4.5535268433119365 Test RE 1.019957347471463\n",
      "25 Train Loss 17.629074 Test MSE 4.378288690498022 Test RE 1.0001387573466771\n",
      "26 Train Loss 16.935066 Test MSE 4.351504639560272 Test RE 0.9970749048402102\n",
      "27 Train Loss 16.46809 Test MSE 4.051266487358091 Test RE 0.9620628971961054\n",
      "28 Train Loss 16.207993 Test MSE 4.043812117632758 Test RE 0.9611773871295067\n",
      "29 Train Loss 15.882963 Test MSE 3.920190606795284 Test RE 0.9463714980651331\n",
      "30 Train Loss 15.730357 Test MSE 3.9533034342576516 Test RE 0.9503599699705978\n",
      "31 Train Loss 15.355925 Test MSE 3.785446020516598 Test RE 0.9299649684538936\n",
      "32 Train Loss 15.111948 Test MSE 3.744950099348506 Test RE 0.9249773065806458\n",
      "33 Train Loss 14.623203 Test MSE 3.5492104160759173 Test RE 0.900479715028054\n",
      "34 Train Loss 14.030755 Test MSE 3.535770878086221 Test RE 0.8987732073640211\n",
      "35 Train Loss 12.839051 Test MSE 3.757813516403893 Test RE 0.9265645332082592\n",
      "36 Train Loss 11.938276 Test MSE 3.674518362379716 Test RE 0.9162379399913425\n",
      "37 Train Loss 10.933096 Test MSE 3.9840500790536875 Test RE 0.954048503588378\n",
      "38 Train Loss 10.25302 Test MSE 3.9503599643410636 Test RE 0.950006104283136\n",
      "39 Train Loss 9.754871 Test MSE 3.989225995464432 Test RE 0.954668033013531\n",
      "40 Train Loss 9.424693 Test MSE 4.060390430164014 Test RE 0.9631456290113803\n",
      "41 Train Loss 8.992921 Test MSE 3.98380520007414 Test RE 0.954019182921039\n",
      "42 Train Loss 8.759732 Test MSE 3.9314345685045793 Test RE 0.9477277262086592\n",
      "43 Train Loss 8.541068 Test MSE 3.8605009370803867 Test RE 0.9391390331773641\n",
      "44 Train Loss 8.3643 Test MSE 3.9497889718877817 Test RE 0.9499374439681288\n",
      "45 Train Loss 8.245134 Test MSE 3.923641478208203 Test RE 0.9467879431165441\n",
      "46 Train Loss 8.15911 Test MSE 3.958637379892759 Test RE 0.951000884559152\n",
      "47 Train Loss 8.008723 Test MSE 3.9436654597814997 Test RE 0.9492007957836743\n",
      "48 Train Loss 7.9239054 Test MSE 3.944411289660613 Test RE 0.9492905484330143\n",
      "49 Train Loss 7.8640275 Test MSE 3.9283988315043183 Test RE 0.9473617519462667\n",
      "50 Train Loss 7.813282 Test MSE 3.9554495880328484 Test RE 0.9506178988054753\n",
      "51 Train Loss 7.7332573 Test MSE 3.9591389757441644 Test RE 0.9510611329404647\n",
      "52 Train Loss 7.6600575 Test MSE 3.936120195320661 Test RE 0.9482923262309034\n",
      "53 Train Loss 7.5927753 Test MSE 3.957556979351288 Test RE 0.9508711010142218\n",
      "54 Train Loss 7.515934 Test MSE 3.9377712041617885 Test RE 0.9484911863767036\n",
      "55 Train Loss 7.4318223 Test MSE 3.9047972729152 Test RE 0.9445116214879948\n",
      "56 Train Loss 7.3865767 Test MSE 3.917514643298283 Test RE 0.9460484413371222\n",
      "57 Train Loss 7.3447747 Test MSE 3.9085626394564614 Test RE 0.9449669044722002\n",
      "58 Train Loss 7.287078 Test MSE 3.8984229705368385 Test RE 0.9437403827638483\n",
      "59 Train Loss 7.2190504 Test MSE 3.8923956750140776 Test RE 0.9430105488618077\n",
      "60 Train Loss 7.1485863 Test MSE 3.897987432239632 Test RE 0.9436876631688427\n",
      "61 Train Loss 7.0991735 Test MSE 3.8888661624103644 Test RE 0.9425829044552625\n",
      "62 Train Loss 7.043609 Test MSE 3.8700600971947696 Test RE 0.940301036513184\n",
      "63 Train Loss 6.98427 Test MSE 3.854080344122313 Test RE 0.93835774354987\n",
      "64 Train Loss 6.911781 Test MSE 3.8503853237514636 Test RE 0.9379078200784539\n",
      "65 Train Loss 6.8145165 Test MSE 3.8618108572996475 Test RE 0.9392983509563734\n",
      "66 Train Loss 6.732681 Test MSE 3.864849419393551 Test RE 0.9396678091288597\n",
      "67 Train Loss 6.641504 Test MSE 3.8537557126682014 Test RE 0.938318223505342\n",
      "68 Train Loss 6.444214 Test MSE 3.8110578318600883 Test RE 0.9331056730674393\n",
      "69 Train Loss 6.3527727 Test MSE 3.8322430456857224 Test RE 0.9356955901093164\n",
      "70 Train Loss 6.256418 Test MSE 3.7499740075841306 Test RE 0.9255975342904511\n",
      "71 Train Loss 6.1719418 Test MSE 3.726922977323485 Test RE 0.9227483324202088\n",
      "72 Train Loss 6.0055904 Test MSE 3.7402877092861884 Test RE 0.9244013378759658\n",
      "73 Train Loss 5.839733 Test MSE 3.733731870596555 Test RE 0.9235908542458332\n",
      "74 Train Loss 5.7167883 Test MSE 3.7085475398610295 Test RE 0.9204707355721028\n",
      "75 Train Loss 5.633198 Test MSE 3.6549980401590947 Test RE 0.9138010115915512\n",
      "76 Train Loss 5.4347715 Test MSE 3.7105529681104557 Test RE 0.9207195780787548\n",
      "77 Train Loss 5.3044415 Test MSE 3.670719042389385 Test RE 0.9157641389279623\n",
      "78 Train Loss 5.193925 Test MSE 3.652685211020128 Test RE 0.9135118459022769\n",
      "79 Train Loss 5.0855684 Test MSE 3.626997730880009 Test RE 0.9102940461820853\n",
      "80 Train Loss 4.961854 Test MSE 3.469933378223525 Test RE 0.8903661252824494\n",
      "81 Train Loss 3.7369592 Test MSE 2.9084319886040526 Test RE 0.8151499694128053\n",
      "82 Train Loss 2.756065 Test MSE 2.4918267785256245 Test RE 0.7545134477109573\n",
      "83 Train Loss 2.372984 Test MSE 2.218453426605364 Test RE 0.7119233184891501\n",
      "84 Train Loss 2.1254497 Test MSE 1.7272805465190821 Test RE 0.628187804990266\n",
      "85 Train Loss 1.7757778 Test MSE 1.8384918051190418 Test RE 0.6480953559928856\n",
      "86 Train Loss 1.6687163 Test MSE 1.8091497530073541 Test RE 0.6429028024689969\n",
      "87 Train Loss 1.5832211 Test MSE 1.9032349487739553 Test RE 0.6594080767180436\n",
      "88 Train Loss 1.5311444 Test MSE 1.8631787710551782 Test RE 0.6524321052363349\n",
      "89 Train Loss 1.4586653 Test MSE 1.8719836462344197 Test RE 0.6539718963970251\n",
      "90 Train Loss 1.4128926 Test MSE 1.8433403725993927 Test RE 0.6489493889028096\n",
      "91 Train Loss 1.3718654 Test MSE 1.7954077022877268 Test RE 0.6404564477902059\n",
      "92 Train Loss 1.3338928 Test MSE 1.7442942534197463 Test RE 0.6312740475048053\n",
      "93 Train Loss 1.3108777 Test MSE 1.7320169806128103 Test RE 0.6290485028134938\n",
      "94 Train Loss 1.2834045 Test MSE 1.700831770033022 Test RE 0.6233597260843506\n",
      "95 Train Loss 1.2405806 Test MSE 1.688062160003805 Test RE 0.6210152679608005\n",
      "96 Train Loss 1.1861895 Test MSE 1.6722395178257388 Test RE 0.618097947496345\n",
      "97 Train Loss 1.1456822 Test MSE 1.627178108718509 Test RE 0.6097132130574899\n",
      "98 Train Loss 1.1031353 Test MSE 1.5878109200030373 Test RE 0.6022924962695151\n",
      "99 Train Loss 1.0744839 Test MSE 1.5435442300175566 Test RE 0.5938374731839494\n",
      "Training time: 49.33\n",
      "KG_stan_tune4\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.70604 Test MSE 8.47923744065616 Test RE 1.3918308508306574\n",
      "1 Train Loss 56.221172 Test MSE 8.566103586120088 Test RE 1.3989420390859122\n",
      "2 Train Loss 53.44834 Test MSE 7.880393064562321 Test RE 1.3417821199325313\n",
      "3 Train Loss 45.287 Test MSE 8.124596130115972 Test RE 1.3624135399507862\n",
      "4 Train Loss 43.978676 Test MSE 8.21438101755337 Test RE 1.3699208700370717\n",
      "5 Train Loss 43.67949 Test MSE 8.482387132162527 Test RE 1.3920893310779152\n",
      "6 Train Loss 43.53454 Test MSE 8.54102998565301 Test RE 1.3968931367515398\n",
      "7 Train Loss 43.436104 Test MSE 8.51151637604747 Test RE 1.394477559484071\n",
      "8 Train Loss 43.41012 Test MSE 8.494685233416794 Test RE 1.393098118724739\n",
      "9 Train Loss 43.346813 Test MSE 8.471778169622755 Test RE 1.3912185122846643\n",
      "10 Train Loss 43.151352 Test MSE 8.436594274958823 Test RE 1.388326592073285\n",
      "11 Train Loss 42.995018 Test MSE 8.499747438752069 Test RE 1.3935131487233994\n",
      "12 Train Loss 42.919117 Test MSE 8.44747660310062 Test RE 1.389221701887797\n",
      "13 Train Loss 40.997322 Test MSE 8.221887179717989 Test RE 1.3705466323544497\n",
      "14 Train Loss 40.42167 Test MSE 7.878131902544092 Test RE 1.341589603873238\n",
      "15 Train Loss 39.542835 Test MSE 7.895152750520189 Test RE 1.3430380863578661\n",
      "16 Train Loss 39.425797 Test MSE 7.909287805261356 Test RE 1.344239800125973\n",
      "17 Train Loss 39.146996 Test MSE 7.7935508752455736 Test RE 1.3343683970587443\n",
      "18 Train Loss 38.97575 Test MSE 7.898912037585606 Test RE 1.343357792955256\n",
      "19 Train Loss 38.81392 Test MSE 7.903423936446226 Test RE 1.3437414045958014\n",
      "20 Train Loss 38.596893 Test MSE 7.965113573372578 Test RE 1.3489754519281947\n",
      "21 Train Loss 36.632782 Test MSE 7.102957534373642 Test RE 1.2738775072741484\n",
      "22 Train Loss 35.61312 Test MSE 7.340323926132571 Test RE 1.2949877884066776\n",
      "23 Train Loss 34.48703 Test MSE 7.197201690466498 Test RE 1.282300751903009\n",
      "24 Train Loss 33.73152 Test MSE 6.996243154383666 Test RE 1.264271965352377\n",
      "25 Train Loss 33.3245 Test MSE 7.160158393249166 Test RE 1.2789965561876413\n",
      "26 Train Loss 33.106632 Test MSE 7.144901960097675 Test RE 1.2776332252585254\n",
      "27 Train Loss 33.010086 Test MSE 7.131462638701073 Test RE 1.2764310670249464\n",
      "28 Train Loss 32.796253 Test MSE 7.095992653947285 Test RE 1.2732527970374148\n",
      "29 Train Loss 32.67919 Test MSE 7.03354628650318 Test RE 1.2676379580392487\n",
      "30 Train Loss 32.576164 Test MSE 7.0871232198313985 Test RE 1.2724568151779945\n",
      "31 Train Loss 32.34434 Test MSE 7.082258716855583 Test RE 1.2720200418711896\n",
      "32 Train Loss 32.21814 Test MSE 7.115977382822622 Test RE 1.2750444928922704\n",
      "33 Train Loss 31.782818 Test MSE 7.032257618581622 Test RE 1.2675218260670313\n",
      "34 Train Loss 31.448578 Test MSE 7.124104204173406 Test RE 1.2757723691511844\n",
      "35 Train Loss 31.173573 Test MSE 7.159064158594731 Test RE 1.2788988226074889\n",
      "36 Train Loss 30.536911 Test MSE 6.990449711197128 Test RE 1.2637483983047473\n",
      "37 Train Loss 29.44527 Test MSE 6.764106236187958 Test RE 1.2431206199262719\n",
      "38 Train Loss 28.770794 Test MSE 6.916833397224845 Test RE 1.257076529405196\n",
      "39 Train Loss 27.598623 Test MSE 6.800180468339321 Test RE 1.246431108260648\n",
      "40 Train Loss 26.086836 Test MSE 6.570831499264745 Test RE 1.2252317023851127\n",
      "41 Train Loss 25.460218 Test MSE 6.65202966024006 Test RE 1.2327787759593867\n",
      "42 Train Loss 24.877277 Test MSE 6.45180866912127 Test RE 1.2140841800843694\n",
      "43 Train Loss 23.00081 Test MSE 6.480588809736063 Test RE 1.2167890520995754\n",
      "44 Train Loss 21.425283 Test MSE 6.472898756733858 Test RE 1.2160668993678905\n",
      "45 Train Loss 20.038347 Test MSE 6.111103648363405 Test RE 1.181592933805402\n",
      "46 Train Loss 19.320004 Test MSE 5.640911079949817 Test RE 1.1352269358155318\n",
      "47 Train Loss 18.608234 Test MSE 5.267239755499223 Test RE 1.0969822586510953\n",
      "48 Train Loss 17.69475 Test MSE 5.215955765339687 Test RE 1.091628863183461\n",
      "49 Train Loss 16.738642 Test MSE 5.155355648050614 Test RE 1.085268944787829\n",
      "50 Train Loss 16.03748 Test MSE 4.740127865075802 Test RE 1.0406461665570788\n",
      "51 Train Loss 14.749637 Test MSE 4.611510173381899 Test RE 1.0264307300930318\n",
      "52 Train Loss 14.070416 Test MSE 4.626130154622917 Test RE 1.0280565015307899\n",
      "53 Train Loss 13.332836 Test MSE 4.357720951703143 Test RE 0.9977868329383716\n",
      "54 Train Loss 12.741268 Test MSE 4.431557651451746 Test RE 1.0062045157151882\n",
      "55 Train Loss 11.931852 Test MSE 4.352803457025035 Test RE 0.9972236949471907\n",
      "56 Train Loss 11.171691 Test MSE 4.390505966153326 Test RE 1.001533190149564\n",
      "57 Train Loss 10.889874 Test MSE 4.225043857872679 Test RE 0.9824798929141106\n",
      "58 Train Loss 10.447525 Test MSE 4.211457870267263 Test RE 0.9808989972170821\n",
      "59 Train Loss 10.078169 Test MSE 4.058557353872816 Test RE 0.9629281968758228\n",
      "60 Train Loss 9.648357 Test MSE 4.010128223193913 Test RE 0.9571658380909304\n",
      "61 Train Loss 8.945793 Test MSE 3.827914762302787 Test RE 0.9351670354461321\n",
      "62 Train Loss 8.499566 Test MSE 3.7868474449777914 Test RE 0.9301370954697644\n",
      "63 Train Loss 8.205751 Test MSE 3.514403781240484 Test RE 0.8960533937618561\n",
      "64 Train Loss 7.6238747 Test MSE 3.4281172120327965 Test RE 0.8849849630808887\n",
      "65 Train Loss 7.132885 Test MSE 3.642275204090768 Test RE 0.9122091809709394\n",
      "66 Train Loss 6.735922 Test MSE 3.4886129598911437 Test RE 0.8927594484108764\n",
      "67 Train Loss 6.484142 Test MSE 3.5577691892418777 Test RE 0.9015647959381513\n",
      "68 Train Loss 6.0636444 Test MSE 3.5676255652885795 Test RE 0.9028127711698277\n",
      "69 Train Loss 5.9676056 Test MSE 3.5335468459912067 Test RE 0.8984904946319469\n",
      "70 Train Loss 5.8075686 Test MSE 3.405763932508242 Test RE 0.8820949408626222\n",
      "71 Train Loss 5.65549 Test MSE 3.3530473964165153 Test RE 0.8752415094756807\n",
      "72 Train Loss 5.555733 Test MSE 3.2045233847413814 Test RE 0.8556374462753618\n",
      "73 Train Loss 5.4015365 Test MSE 3.146407677906118 Test RE 0.8478432303441019\n",
      "74 Train Loss 5.2179255 Test MSE 3.01472789283691 Test RE 0.829912144456174\n",
      "75 Train Loss 4.716339 Test MSE 2.3580487194851605 Test RE 0.7339803735899227\n",
      "76 Train Loss 4.189067 Test MSE 2.1530915425320405 Test RE 0.7013572776090111\n",
      "77 Train Loss 4.053832 Test MSE 2.1268920229734776 Test RE 0.6970770449800907\n",
      "78 Train Loss 3.6439178 Test MSE 1.97033740521389 Test RE 0.6709317765642171\n",
      "79 Train Loss 2.8769643 Test MSE 1.7377036867196312 Test RE 0.6300803294523895\n",
      "80 Train Loss 2.4408398 Test MSE 1.6587181450137465 Test RE 0.6155939713464021\n",
      "81 Train Loss 2.1490924 Test MSE 1.4795440048762298 Test RE 0.5813959518815626\n",
      "82 Train Loss 1.889121 Test MSE 1.464815608055653 Test RE 0.5784949068412927\n",
      "83 Train Loss 1.565548 Test MSE 1.0904365741025392 Test RE 0.4991237839535149\n",
      "84 Train Loss 1.3626118 Test MSE 0.9456505424406836 Test RE 0.4648077902503847\n",
      "85 Train Loss 1.2140633 Test MSE 0.7522597881362147 Test RE 0.41456437983399796\n",
      "86 Train Loss 1.1022025 Test MSE 0.6245382658267831 Test RE 0.3777353126174718\n",
      "87 Train Loss 0.9170004 Test MSE 0.45007441493922645 Test RE 0.32066401283126184\n",
      "88 Train Loss 0.7337871 Test MSE 0.3313825243963272 Test RE 0.2751521186967735\n",
      "89 Train Loss 0.5499254 Test MSE 0.21050327232602364 Test RE 0.21929942148297782\n",
      "90 Train Loss 0.449555 Test MSE 0.18456305203468718 Test RE 0.20534325498482234\n",
      "91 Train Loss 0.38857546 Test MSE 0.13115740721519326 Test RE 0.17310295100148343\n",
      "92 Train Loss 0.3023489 Test MSE 0.09284489929251996 Test RE 0.14564215119644844\n",
      "93 Train Loss 0.2538169 Test MSE 0.0751878439554455 Test RE 0.13106353456889316\n",
      "94 Train Loss 0.23449422 Test MSE 0.08083792065479971 Test RE 0.13589880167087942\n",
      "95 Train Loss 0.21823134 Test MSE 0.07106109614340719 Test RE 0.12741601302784394\n",
      "96 Train Loss 0.15679798 Test MSE 0.034924364291267065 Test RE 0.08932485401455344\n",
      "97 Train Loss 0.13165414 Test MSE 0.020036577822502684 Test RE 0.06765810567856535\n",
      "98 Train Loss 0.11752017 Test MSE 0.013872263361205615 Test RE 0.056296542469080516\n",
      "99 Train Loss 0.1098893 Test MSE 0.013116278855469031 Test RE 0.05474108245466265\n",
      "Training time: 50.62\n",
      "KG_stan_tune5\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.969765 Test MSE 7.894772768246497 Test RE 1.3430057667294595\n",
      "1 Train Loss 45.176704 Test MSE 9.639440376907368 Test RE 1.4840002393626164\n",
      "2 Train Loss 43.503845 Test MSE 9.43989261289041 Test RE 1.468559635790707\n",
      "3 Train Loss 43.28602 Test MSE 9.307778590114635 Test RE 1.4582469683987282\n",
      "4 Train Loss 43.238316 Test MSE 9.336787298251345 Test RE 1.4605175935515378\n",
      "5 Train Loss 43.180984 Test MSE 9.36905336051212 Test RE 1.4630390448031634\n",
      "6 Train Loss 43.091393 Test MSE 9.398771987295776 Test RE 1.4653575867628597\n",
      "7 Train Loss 42.850014 Test MSE 9.392831537397967 Test RE 1.4648944273605808\n",
      "8 Train Loss 42.51114 Test MSE 9.181026965589123 Test RE 1.4482838630937267\n",
      "9 Train Loss 41.460117 Test MSE 9.154359439979086 Test RE 1.4461789660183226\n",
      "10 Train Loss 40.948845 Test MSE 9.070327422095568 Test RE 1.4395260970232542\n",
      "11 Train Loss 40.192955 Test MSE 9.318955826614218 Test RE 1.4591222728984978\n",
      "12 Train Loss 39.864105 Test MSE 9.140216429627763 Test RE 1.4450613984725076\n",
      "13 Train Loss 39.404045 Test MSE 9.033445889023533 Test RE 1.436596433784598\n",
      "14 Train Loss 39.116615 Test MSE 9.036525807188866 Test RE 1.4368413138909164\n",
      "15 Train Loss 38.882244 Test MSE 9.017974425833035 Test RE 1.4353656867403985\n",
      "16 Train Loss 38.652695 Test MSE 9.079102867095326 Test RE 1.4402222917432286\n",
      "17 Train Loss 38.53664 Test MSE 9.141458907152218 Test RE 1.4451596125197668\n",
      "18 Train Loss 38.487206 Test MSE 9.14297377406434 Test RE 1.445279349085519\n",
      "19 Train Loss 38.338287 Test MSE 9.068632688006165 Test RE 1.4393916075057878\n",
      "20 Train Loss 38.287437 Test MSE 8.988077156125618 Test RE 1.4329843791491512\n",
      "21 Train Loss 38.260704 Test MSE 8.959221379888369 Test RE 1.4306822672963628\n",
      "22 Train Loss 38.09049 Test MSE 8.90152652649458 Test RE 1.4260682323164113\n",
      "23 Train Loss 38.052002 Test MSE 8.915104681597251 Test RE 1.4271554614067152\n",
      "24 Train Loss 37.96582 Test MSE 8.947872276935014 Test RE 1.4297758210237237\n",
      "25 Train Loss 37.6672 Test MSE 8.947916729127305 Test RE 1.4297793725155656\n",
      "26 Train Loss 37.546684 Test MSE 8.918626081983865 Test RE 1.4274372915031472\n",
      "27 Train Loss 37.48988 Test MSE 8.854702517401401 Test RE 1.4223125688792044\n",
      "28 Train Loss 37.33278 Test MSE 8.961011589333294 Test RE 1.4308251978517965\n",
      "29 Train Loss 37.248573 Test MSE 8.944469260491545 Test RE 1.429503912061562\n",
      "30 Train Loss 37.20965 Test MSE 8.972762209576299 Test RE 1.4317630147046605\n",
      "31 Train Loss 37.18252 Test MSE 8.814717039449823 Test RE 1.4190975428714983\n",
      "32 Train Loss 37.162132 Test MSE 8.816904194596974 Test RE 1.419273589020973\n",
      "33 Train Loss 37.062492 Test MSE 8.7168953018807 Test RE 1.4112013236719756\n",
      "34 Train Loss 36.99398 Test MSE 8.726899623839135 Test RE 1.4120109045725528\n",
      "35 Train Loss 36.917984 Test MSE 8.773315866841102 Test RE 1.4157609949228676\n",
      "36 Train Loss 36.89962 Test MSE 8.758953206162229 Test RE 1.414601659954265\n",
      "37 Train Loss 36.818787 Test MSE 8.796579573730526 Test RE 1.4176367990473981\n",
      "38 Train Loss 36.550056 Test MSE 9.295877436907654 Test RE 1.4573143950924143\n",
      "39 Train Loss 36.38794 Test MSE 9.42210054350243 Test RE 1.4671750311499197\n",
      "40 Train Loss 36.334763 Test MSE 9.438928809588642 Test RE 1.4684846646647902\n",
      "41 Train Loss 36.295258 Test MSE 9.453051014833608 Test RE 1.4695828025512783\n",
      "42 Train Loss 36.2603 Test MSE 9.44923249934045 Test RE 1.469285957040604\n",
      "43 Train Loss 36.211517 Test MSE 9.412779130358361 Test RE 1.4664491033841107\n",
      "44 Train Loss 36.084908 Test MSE 9.55149260792805 Test RE 1.477214909191518\n",
      "45 Train Loss 35.986362 Test MSE 9.710916278363841 Test RE 1.4894919665859119\n",
      "46 Train Loss 35.863422 Test MSE 9.836208241174436 Test RE 1.4990700158390442\n",
      "47 Train Loss 35.799747 Test MSE 9.72088209023321 Test RE 1.490256064938769\n",
      "48 Train Loss 35.74128 Test MSE 9.720890660843883 Test RE 1.4902567218956992\n",
      "49 Train Loss 35.67134 Test MSE 9.742173293687973 Test RE 1.4918871921323278\n",
      "50 Train Loss 35.655525 Test MSE 9.690869603082314 Test RE 1.4879537601561659\n",
      "51 Train Loss 35.611378 Test MSE 9.504753202082863 Test RE 1.473596164839667\n",
      "52 Train Loss 35.50934 Test MSE 9.693937591485804 Test RE 1.4881892737798184\n",
      "53 Train Loss 35.419083 Test MSE 9.730815809874597 Test RE 1.4910173130311997\n",
      "54 Train Loss 35.38116 Test MSE 9.810210265614087 Test RE 1.4970876171898522\n",
      "55 Train Loss 35.335762 Test MSE 9.728228971808965 Test RE 1.4908191139907139\n",
      "56 Train Loss 35.245903 Test MSE 9.708975701809635 Test RE 1.4893431331739195\n",
      "57 Train Loss 35.112938 Test MSE 9.738512623073925 Test RE 1.4916068737390944\n",
      "58 Train Loss 35.080486 Test MSE 9.699514367212187 Test RE 1.4886172786265617\n",
      "59 Train Loss 34.8761 Test MSE 9.750465723669272 Test RE 1.492521996001773\n",
      "60 Train Loss 34.74642 Test MSE 9.786880778628516 Test RE 1.4953064588733085\n",
      "61 Train Loss 34.715893 Test MSE 9.822462222968786 Test RE 1.4980221807626748\n",
      "62 Train Loss 34.64206 Test MSE 9.832630654197093 Test RE 1.4987973731203692\n",
      "63 Train Loss 34.57079 Test MSE 9.91560220552964 Test RE 1.505107805410925\n",
      "64 Train Loss 34.441727 Test MSE 9.909506318486622 Test RE 1.504645081233758\n",
      "65 Train Loss 34.304413 Test MSE 9.805940691601942 Test RE 1.4967618024605076\n",
      "66 Train Loss 34.21872 Test MSE 9.743627969633197 Test RE 1.4919985703299536\n",
      "67 Train Loss 34.17527 Test MSE 9.698422859709092 Test RE 1.4885335175957755\n",
      "68 Train Loss 34.14921 Test MSE 9.67995971988481 Test RE 1.4871159626304935\n",
      "69 Train Loss 34.10472 Test MSE 9.77333643076615 Test RE 1.4942714016721248\n",
      "70 Train Loss 33.95375 Test MSE 9.753251185857227 Test RE 1.4927351687276347\n",
      "71 Train Loss 33.86542 Test MSE 9.787861276862378 Test RE 1.4953813606042874\n",
      "72 Train Loss 33.750534 Test MSE 9.891108547792612 Test RE 1.5032476869170142\n",
      "73 Train Loss 33.322044 Test MSE 9.674662996898345 Test RE 1.4867090436273753\n",
      "74 Train Loss 33.058083 Test MSE 9.62372561203163 Test RE 1.4827900950819408\n",
      "75 Train Loss 32.824444 Test MSE 9.618194418613296 Test RE 1.4823639203372394\n",
      "76 Train Loss 32.56808 Test MSE 9.705741264694105 Test RE 1.4890950334711017\n",
      "77 Train Loss 32.313557 Test MSE 9.735419079025203 Test RE 1.4913699423793578\n",
      "78 Train Loss 32.140762 Test MSE 9.64868255589813 Test RE 1.48471148967044\n",
      "79 Train Loss 31.899845 Test MSE 9.495194684597477 Test RE 1.4728550126257343\n",
      "80 Train Loss 31.700249 Test MSE 9.522603595068158 Test RE 1.474979258723891\n",
      "81 Train Loss 31.553728 Test MSE 9.573238632656844 Test RE 1.4788955516840288\n",
      "82 Train Loss 31.400894 Test MSE 9.555438495118848 Test RE 1.4775200092289922\n",
      "83 Train Loss 31.136395 Test MSE 9.808877171352966 Test RE 1.4969858952765809\n",
      "84 Train Loss 31.021992 Test MSE 9.836459530424827 Test RE 1.4990891643648496\n",
      "85 Train Loss 30.70763 Test MSE 9.895728752063894 Test RE 1.5035987345518225\n",
      "86 Train Loss 30.274387 Test MSE 9.785277331102606 Test RE 1.495183961025952\n",
      "87 Train Loss 29.746687 Test MSE 9.768351441158046 Test RE 1.4938902689057243\n",
      "88 Train Loss 29.472683 Test MSE 9.982227311383062 Test RE 1.5101559144879342\n",
      "89 Train Loss 28.843353 Test MSE 9.775888694633881 Test RE 1.494466500141258\n",
      "90 Train Loss 28.527115 Test MSE 9.775071836212966 Test RE 1.494404061160722\n",
      "91 Train Loss 28.340612 Test MSE 9.882417679207204 Test RE 1.502587123993315\n",
      "92 Train Loss 27.835773 Test MSE 9.525580031107898 Test RE 1.4752097544270175\n",
      "93 Train Loss 27.654818 Test MSE 9.421207004701447 Test RE 1.4671054602036626\n",
      "94 Train Loss 24.570522 Test MSE 8.541252923198646 Test RE 1.3969113674506366\n",
      "95 Train Loss 23.945515 Test MSE 8.373950331588356 Test RE 1.38316264225932\n",
      "96 Train Loss 23.633953 Test MSE 8.332181975829965 Test RE 1.3797087974248605\n",
      "97 Train Loss 23.39087 Test MSE 8.306834288376525 Test RE 1.3776085633091628\n",
      "98 Train Loss 23.087631 Test MSE 8.098956791561926 Test RE 1.3602621108923783\n",
      "99 Train Loss 22.54042 Test MSE 8.12366000800374 Test RE 1.3623350485304027\n",
      "Training time: 49.56\n",
      "KG_stan_tune5\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.832237 Test MSE 8.628498540121633 Test RE 1.4040276974289263\n",
      "1 Train Loss 57.360306 Test MSE 8.74424747202011 Test RE 1.4134136472769896\n",
      "2 Train Loss 57.109676 Test MSE 8.682123970681003 Test RE 1.408383899655118\n",
      "3 Train Loss 56.322155 Test MSE 8.949341373452857 Test RE 1.4298931892877\n",
      "4 Train Loss 54.5297 Test MSE 9.046862199377705 Test RE 1.437662841491679\n",
      "5 Train Loss 53.252686 Test MSE 9.176717254608155 Test RE 1.4479439001708048\n",
      "6 Train Loss 48.906162 Test MSE 8.7982171712284 Test RE 1.4177687486546524\n",
      "7 Train Loss 47.539253 Test MSE 8.68704859655863 Test RE 1.4087832708564407\n",
      "8 Train Loss 47.002007 Test MSE 8.60017427843679 Test RE 1.4017213438112843\n",
      "9 Train Loss 45.96983 Test MSE 8.600308125076367 Test RE 1.4017322514368427\n",
      "10 Train Loss 45.677628 Test MSE 8.438970546397416 Test RE 1.3885220980114292\n",
      "11 Train Loss 45.289085 Test MSE 8.596722484743974 Test RE 1.401440015879506\n",
      "12 Train Loss 44.9942 Test MSE 8.777699742584854 Test RE 1.4161146665134865\n",
      "13 Train Loss 44.762413 Test MSE 8.467318975830535 Test RE 1.390852324136864\n",
      "14 Train Loss 44.44423 Test MSE 8.612104719419532 Test RE 1.4026932635375127\n",
      "15 Train Loss 44.363365 Test MSE 8.507720678522759 Test RE 1.3941665922591078\n",
      "16 Train Loss 44.1158 Test MSE 8.46462148284023 Test RE 1.3906307597158434\n",
      "17 Train Loss 44.042706 Test MSE 8.389670249097522 Test RE 1.3844602979080807\n",
      "18 Train Loss 43.99059 Test MSE 8.240371589732195 Test RE 1.37208639582495\n",
      "19 Train Loss 43.659958 Test MSE 8.34463813771543 Test RE 1.3807397073349421\n",
      "20 Train Loss 43.469513 Test MSE 8.35830356709663 Test RE 1.3818698152022488\n",
      "21 Train Loss 43.35269 Test MSE 8.378251167615002 Test RE 1.383517790777479\n",
      "22 Train Loss 42.927532 Test MSE 8.318853675102176 Test RE 1.3786048528867425\n",
      "23 Train Loss 42.63616 Test MSE 8.30276470957528 Test RE 1.3772710717197407\n",
      "24 Train Loss 42.485786 Test MSE 8.370017232739439 Test RE 1.3828377803893153\n",
      "25 Train Loss 41.891907 Test MSE 8.426758917456747 Test RE 1.3875171024920556\n",
      "26 Train Loss 41.36589 Test MSE 8.442263368271819 Test RE 1.3887929669517938\n",
      "27 Train Loss 40.78991 Test MSE 8.436930395074224 Test RE 1.3883542477736395\n",
      "28 Train Loss 39.898663 Test MSE 7.999714879520973 Test RE 1.3519023236075254\n",
      "29 Train Loss 38.624283 Test MSE 7.976994298354338 Test RE 1.3499811396864536\n",
      "30 Train Loss 38.126984 Test MSE 7.986868662230388 Test RE 1.3508164218639247\n",
      "31 Train Loss 37.96181 Test MSE 7.877922362329783 Test RE 1.3415717621535332\n",
      "32 Train Loss 37.788895 Test MSE 7.8830724625242725 Test RE 1.3420102089823653\n",
      "33 Train Loss 37.6071 Test MSE 7.910806594140974 Test RE 1.3443688584248232\n",
      "34 Train Loss 37.546944 Test MSE 7.988337825075423 Test RE 1.3509406556610328\n",
      "35 Train Loss 37.302536 Test MSE 8.171637559531376 Test RE 1.366352035896551\n",
      "36 Train Loss 37.154087 Test MSE 8.120087227619848 Test RE 1.3620354385509057\n",
      "37 Train Loss 36.869507 Test MSE 8.007783237719568 Test RE 1.3525839031037825\n",
      "38 Train Loss 36.654636 Test MSE 8.19256175496461 Test RE 1.3681002496744803\n",
      "39 Train Loss 36.388496 Test MSE 8.228697990633078 Test RE 1.371114178553665\n",
      "40 Train Loss 36.033813 Test MSE 8.059526683867515 Test RE 1.3569468245101801\n",
      "41 Train Loss 35.6035 Test MSE 8.104891881395755 Test RE 1.3607604342880453\n",
      "42 Train Loss 35.31506 Test MSE 8.153009252812186 Test RE 1.364793759055703\n",
      "43 Train Loss 35.008316 Test MSE 8.11130550977455 Test RE 1.3612987317747436\n",
      "44 Train Loss 34.354065 Test MSE 8.410094334476687 Test RE 1.386144461063367\n",
      "45 Train Loss 34.140503 Test MSE 8.39037890287919 Test RE 1.3845187675665778\n",
      "46 Train Loss 34.02252 Test MSE 8.426670503348278 Test RE 1.387509823512641\n",
      "47 Train Loss 33.969543 Test MSE 8.487696718244313 Test RE 1.3925249550191043\n",
      "48 Train Loss 33.855186 Test MSE 8.429436069871791 Test RE 1.3877374897024048\n",
      "49 Train Loss 33.715084 Test MSE 8.385921276064472 Test RE 1.384150936268881\n",
      "50 Train Loss 33.495655 Test MSE 8.338822847121834 Test RE 1.380258511991959\n",
      "51 Train Loss 33.406338 Test MSE 8.276308458890421 Test RE 1.3750750260195503\n",
      "52 Train Loss 33.299225 Test MSE 8.159795228768397 Test RE 1.3653616187874003\n",
      "53 Train Loss 32.9257 Test MSE 8.371943355377999 Test RE 1.3829968817307263\n",
      "54 Train Loss 32.73881 Test MSE 8.274269561356437 Test RE 1.3749056383157063\n",
      "55 Train Loss 32.62516 Test MSE 8.276691307103976 Test RE 1.3751068299893914\n",
      "56 Train Loss 32.503128 Test MSE 8.251011690783443 Test RE 1.372971940130995\n",
      "57 Train Loss 32.3653 Test MSE 8.31368812927911 Test RE 1.3781767679224197\n",
      "58 Train Loss 32.142506 Test MSE 8.339855882197018 Test RE 1.3803440043525066\n",
      "59 Train Loss 32.030838 Test MSE 8.392673166387036 Test RE 1.3847080458940995\n",
      "60 Train Loss 31.851906 Test MSE 8.349987153851563 Test RE 1.3811821720450113\n",
      "61 Train Loss 31.706764 Test MSE 8.352847637769612 Test RE 1.3814187299589433\n",
      "62 Train Loss 31.105202 Test MSE 8.017031851235835 Test RE 1.3533647631434795\n",
      "63 Train Loss 29.922352 Test MSE 7.191989196028878 Test RE 1.2818363216658546\n",
      "64 Train Loss 28.681564 Test MSE 6.876558682292593 Test RE 1.2534113903216066\n",
      "65 Train Loss 28.201874 Test MSE 6.900402528817584 Test RE 1.2555825552996156\n",
      "66 Train Loss 27.861612 Test MSE 7.04965291016526 Test RE 1.2690885557365832\n",
      "67 Train Loss 27.436573 Test MSE 7.25290325563434 Test RE 1.2872532665330887\n",
      "68 Train Loss 27.133553 Test MSE 7.201673603858557 Test RE 1.2826990627802144\n",
      "69 Train Loss 26.675625 Test MSE 7.250983020356646 Test RE 1.2870828525157678\n",
      "70 Train Loss 26.456684 Test MSE 7.182689895330847 Test RE 1.2810073411994003\n",
      "71 Train Loss 25.952639 Test MSE 6.96622092135978 Test RE 1.2615564311910157\n",
      "72 Train Loss 25.659805 Test MSE 6.984192670431773 Test RE 1.2631826911045803\n",
      "73 Train Loss 25.570705 Test MSE 7.0543256986682925 Test RE 1.2695090870821597\n",
      "74 Train Loss 25.323112 Test MSE 6.871368233741353 Test RE 1.252938261555993\n",
      "75 Train Loss 24.950794 Test MSE 6.6972257049094726 Test RE 1.2369596356551182\n",
      "76 Train Loss 24.766857 Test MSE 6.568377924975695 Test RE 1.225002927861882\n",
      "77 Train Loss 24.236002 Test MSE 6.038781789887952 Test RE 1.174580343414458\n",
      "78 Train Loss 23.63737 Test MSE 5.9944629584845295 Test RE 1.1702622630158874\n",
      "79 Train Loss 22.700682 Test MSE 6.17771614362967 Test RE 1.1880153030658542\n",
      "80 Train Loss 21.890884 Test MSE 6.180869898601187 Test RE 1.1883185082491905\n",
      "81 Train Loss 20.400164 Test MSE 5.589226756910952 Test RE 1.1300142625820353\n",
      "82 Train Loss 19.49499 Test MSE 5.3161267579478615 Test RE 1.1020612293981986\n",
      "83 Train Loss 18.987152 Test MSE 5.1346699036073415 Test RE 1.083089448115641\n",
      "84 Train Loss 16.919624 Test MSE 4.447014480272256 Test RE 1.007957758501102\n",
      "85 Train Loss 15.912762 Test MSE 4.479853203074439 Test RE 1.0116725163246725\n",
      "86 Train Loss 15.373972 Test MSE 4.131455726545454 Test RE 0.9715375971413369\n",
      "87 Train Loss 14.820869 Test MSE 3.9336877310787766 Test RE 0.9479992656096883\n",
      "88 Train Loss 14.358827 Test MSE 3.7492068856461276 Test RE 0.9255028559687287\n",
      "89 Train Loss 13.904178 Test MSE 3.6794354617659155 Test RE 0.9168507722585018\n",
      "90 Train Loss 13.410679 Test MSE 3.6654970158212716 Test RE 0.9151125163699486\n",
      "91 Train Loss 12.505671 Test MSE 3.7088712144654963 Test RE 0.9205109031171583\n",
      "92 Train Loss 11.825985 Test MSE 3.6070798113452662 Test RE 0.9077911325267751\n",
      "93 Train Loss 11.164994 Test MSE 3.391705921039891 Test RE 0.8802725415504529\n",
      "94 Train Loss 10.752473 Test MSE 3.5010837527231007 Test RE 0.894353704682066\n",
      "95 Train Loss 10.394946 Test MSE 3.4153124653546305 Test RE 0.8833306132966233\n",
      "96 Train Loss 9.681917 Test MSE 3.258651021912827 Test RE 0.8628334768788309\n",
      "97 Train Loss 9.027745 Test MSE 3.1513755445188267 Test RE 0.8485122966646821\n",
      "98 Train Loss 8.65259 Test MSE 3.0862399165658125 Test RE 0.8396975814058875\n",
      "99 Train Loss 8.233057 Test MSE 2.9157419527397455 Test RE 0.8161737130740611\n",
      "Training time: 50.02\n",
      "KG_stan_tune5\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.208656 Test MSE 8.636155017068969 Test RE 1.404650489562499\n",
      "1 Train Loss 52.50699 Test MSE 8.226807621435297 Test RE 1.3709566772764847\n",
      "2 Train Loss 45.82057 Test MSE 7.929711397127316 Test RE 1.3459742486192174\n",
      "3 Train Loss 42.347088 Test MSE 7.58507359109327 Test RE 1.3164002607124712\n",
      "4 Train Loss 36.86614 Test MSE 7.337362109964107 Test RE 1.294726498660244\n",
      "5 Train Loss 35.685375 Test MSE 7.31305053007673 Test RE 1.2925797486889277\n",
      "6 Train Loss 34.369762 Test MSE 7.21942723993051 Test RE 1.284279150693326\n",
      "7 Train Loss 33.253227 Test MSE 7.1186503066684 Test RE 1.2752839383448393\n",
      "8 Train Loss 32.079086 Test MSE 6.898159220960854 Test RE 1.2553784449481475\n",
      "9 Train Loss 30.65636 Test MSE 6.858743909378027 Test RE 1.2517867608443745\n",
      "10 Train Loss 29.072659 Test MSE 6.406732640661006 Test RE 1.2098356028096096\n",
      "11 Train Loss 27.984707 Test MSE 6.457164820303128 Test RE 1.214588028670463\n",
      "12 Train Loss 26.875378 Test MSE 6.287795136890783 Test RE 1.198553024090935\n",
      "13 Train Loss 25.341892 Test MSE 6.107939685260761 Test RE 1.181287015211947\n",
      "14 Train Loss 24.630064 Test MSE 6.268475850076335 Test RE 1.196710327038931\n",
      "15 Train Loss 24.02936 Test MSE 6.078085683949734 Test RE 1.1783965689679\n",
      "16 Train Loss 23.765385 Test MSE 6.02573649196634 Test RE 1.1733109620017907\n",
      "17 Train Loss 23.50167 Test MSE 5.980803901640073 Test RE 1.168928215662979\n",
      "18 Train Loss 23.208494 Test MSE 5.8370162704121755 Test RE 1.1547913236726168\n",
      "19 Train Loss 22.863047 Test MSE 5.535474103952103 Test RE 1.124567354297274\n",
      "20 Train Loss 22.572327 Test MSE 5.673739682285927 Test RE 1.1385255030133956\n",
      "21 Train Loss 22.320618 Test MSE 5.631731026235972 Test RE 1.1343028220035263\n",
      "22 Train Loss 21.917852 Test MSE 5.640012759867564 Test RE 1.1351365392692971\n",
      "23 Train Loss 20.242786 Test MSE 5.716784092147168 Test RE 1.142836113174264\n",
      "24 Train Loss 18.396698 Test MSE 5.653142363068636 Test RE 1.1364570352698218\n",
      "25 Train Loss 17.084915 Test MSE 5.693750545261262 Test RE 1.1405314837309277\n",
      "26 Train Loss 16.60247 Test MSE 5.753625125869236 Test RE 1.1465126250571436\n",
      "27 Train Loss 15.790533 Test MSE 6.054410050860132 Test RE 1.1760992579448133\n",
      "28 Train Loss 15.054525 Test MSE 6.074917162153195 Test RE 1.1780893783373736\n",
      "29 Train Loss 14.588702 Test MSE 5.857440831777614 Test RE 1.1568099500037985\n",
      "30 Train Loss 14.287699 Test MSE 5.914856372946825 Test RE 1.162465739115436\n",
      "31 Train Loss 13.944045 Test MSE 5.854210450967228 Test RE 1.1564909154506795\n",
      "32 Train Loss 13.660612 Test MSE 5.835349033970219 Test RE 1.1546263894330593\n",
      "33 Train Loss 13.414003 Test MSE 5.841596303417327 Test RE 1.15524429013992\n",
      "34 Train Loss 13.206422 Test MSE 5.829346552696752 Test RE 1.1540323884196895\n",
      "35 Train Loss 12.963964 Test MSE 5.818454461707117 Test RE 1.1529537338213893\n",
      "36 Train Loss 12.662036 Test MSE 5.8887802776369975 Test RE 1.1599004993060016\n",
      "37 Train Loss 12.524141 Test MSE 5.904228612467556 Test RE 1.1614209156045534\n",
      "38 Train Loss 12.06636 Test MSE 5.820189621313574 Test RE 1.153125635967612\n",
      "39 Train Loss 11.452074 Test MSE 5.865248294029672 Test RE 1.157580657096314\n",
      "40 Train Loss 11.139526 Test MSE 5.817940206431272 Test RE 1.152902781661686\n",
      "41 Train Loss 10.571983 Test MSE 5.703432093408061 Test RE 1.1415007412020217\n",
      "42 Train Loss 9.934044 Test MSE 5.681635031495548 Test RE 1.1393173908955196\n",
      "43 Train Loss 9.544245 Test MSE 5.720567455353319 Test RE 1.1432142146472475\n",
      "44 Train Loss 9.343281 Test MSE 5.722059818730591 Test RE 1.1433633239606371\n",
      "45 Train Loss 9.010081 Test MSE 5.718307895338789 Test RE 1.1429884139484592\n",
      "46 Train Loss 8.81812 Test MSE 5.529757953301251 Test RE 1.1239865678412604\n",
      "47 Train Loss 8.601409 Test MSE 5.415744006370062 Test RE 1.1123388969287749\n",
      "48 Train Loss 8.4366 Test MSE 5.360060392581588 Test RE 1.1066056971568232\n",
      "49 Train Loss 8.320026 Test MSE 5.307222092647424 Test RE 1.101137850428061\n",
      "50 Train Loss 8.120094 Test MSE 4.754710585614924 Test RE 1.04224568021835\n",
      "51 Train Loss 7.167807 Test MSE 3.865924799558728 Test RE 0.9397985295958085\n",
      "52 Train Loss 6.5034075 Test MSE 3.726686721315146 Test RE 0.9227190846608537\n",
      "53 Train Loss 6.135953 Test MSE 3.682860306137347 Test RE 0.9172773785788493\n",
      "54 Train Loss 5.8711033 Test MSE 3.5729029756173576 Test RE 0.9034802673352277\n",
      "55 Train Loss 5.705358 Test MSE 3.345948958252064 Test RE 0.8743145706867308\n",
      "56 Train Loss 5.6580915 Test MSE 3.2585194190815625 Test RE 0.8628160536453839\n",
      "57 Train Loss 5.4448304 Test MSE 2.792203393477909 Test RE 0.7986961400373517\n",
      "58 Train Loss 5.2656474 Test MSE 2.5934550247251362 Test RE 0.7697459645229521\n",
      "59 Train Loss 5.1204295 Test MSE 2.427293940676224 Test RE 0.7446792388119922\n",
      "60 Train Loss 4.924263 Test MSE 2.278990126450473 Test RE 0.7215713514790125\n",
      "61 Train Loss 4.726245 Test MSE 2.2245589534987604 Test RE 0.7129023069025187\n",
      "62 Train Loss 4.596955 Test MSE 2.2070625978645575 Test RE 0.7100932523496084\n",
      "63 Train Loss 4.4683027 Test MSE 2.2418264115042197 Test RE 0.7156638014269937\n",
      "64 Train Loss 4.405072 Test MSE 2.250172238827279 Test RE 0.7169946934931607\n",
      "65 Train Loss 4.339158 Test MSE 2.236867899041873 Test RE 0.7148719041902157\n",
      "66 Train Loss 4.290861 Test MSE 2.185528727510435 Test RE 0.7066206419512617\n",
      "67 Train Loss 4.267549 Test MSE 2.19138005583087 Test RE 0.7075659293723612\n",
      "68 Train Loss 4.243274 Test MSE 2.1707983159733346 Test RE 0.7042353127472519\n",
      "69 Train Loss 4.227204 Test MSE 2.1681926635501285 Test RE 0.7038125320101211\n",
      "70 Train Loss 4.2074924 Test MSE 2.1570139706578115 Test RE 0.7019958411971257\n",
      "71 Train Loss 4.189212 Test MSE 2.1491452755366454 Test RE 0.7007142458587815\n",
      "72 Train Loss 4.1786356 Test MSE 2.1472186813728955 Test RE 0.7004000989566282\n",
      "73 Train Loss 4.163297 Test MSE 2.1474392960587396 Test RE 0.7004360791249181\n",
      "74 Train Loss 4.1474586 Test MSE 2.146048608055552 Test RE 0.7002092401612547\n",
      "75 Train Loss 4.13592 Test MSE 2.148418637604559 Test RE 0.7005957781587165\n",
      "76 Train Loss 4.125919 Test MSE 2.1505178389512545 Test RE 0.7009379676418653\n",
      "77 Train Loss 4.1092215 Test MSE 2.1424330286298514 Test RE 0.6996191488362912\n",
      "78 Train Loss 4.0977607 Test MSE 2.141229513657024 Test RE 0.6994226151776278\n",
      "79 Train Loss 4.087771 Test MSE 2.1530652899736107 Test RE 0.7013530017854633\n",
      "80 Train Loss 4.0693345 Test MSE 2.139319339216253 Test RE 0.699110570791356\n",
      "81 Train Loss 4.050212 Test MSE 2.141282130886595 Test RE 0.6994312087109209\n",
      "82 Train Loss 4.039179 Test MSE 2.14376794236637 Test RE 0.6998370753165499\n",
      "83 Train Loss 4.0259614 Test MSE 2.1387529681351296 Test RE 0.6990180221445227\n",
      "84 Train Loss 4.0019546 Test MSE 2.1406558489498164 Test RE 0.6993289164534099\n",
      "85 Train Loss 3.9804113 Test MSE 2.129131520893975 Test RE 0.6974439399267205\n",
      "86 Train Loss 3.9627223 Test MSE 2.127709342819267 Test RE 0.6972109681348592\n",
      "87 Train Loss 3.934351 Test MSE 2.133413187340055 Test RE 0.6981448648054087\n",
      "88 Train Loss 3.8904989 Test MSE 2.1188936371195948 Test RE 0.6957650971261465\n",
      "89 Train Loss 3.839479 Test MSE 2.0959813475905973 Test RE 0.6919931047491319\n",
      "90 Train Loss 3.6881485 Test MSE 2.02367929775662 Test RE 0.6799530163778417\n",
      "91 Train Loss 3.1944127 Test MSE 1.768779489484371 Test RE 0.635689308309499\n",
      "92 Train Loss 2.5562727 Test MSE 1.4787585707487894 Test RE 0.5812416108004318\n",
      "93 Train Loss 2.0686703 Test MSE 1.3021516187200708 Test RE 0.5454297693197642\n",
      "94 Train Loss 1.5828525 Test MSE 1.105596567374574 Test RE 0.5025813876446259\n",
      "95 Train Loss 1.1397804 Test MSE 0.7542734463426719 Test RE 0.4151188645216623\n",
      "96 Train Loss 0.86479175 Test MSE 0.4235932955644505 Test RE 0.311087527446792\n",
      "97 Train Loss 0.5355534 Test MSE 0.12129825155002445 Test RE 0.16646975128456762\n",
      "98 Train Loss 0.37684155 Test MSE 0.10178190376504614 Test RE 0.15249069548963462\n",
      "99 Train Loss 0.23803608 Test MSE 0.09399583679328823 Test RE 0.1465420860635311\n",
      "Training time: 50.26\n",
      "KG_stan_tune5\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.422825 Test MSE 8.549129620062393 Test RE 1.3975553310422364\n",
      "1 Train Loss 56.147705 Test MSE 8.477049984647278 Test RE 1.391651308438873\n",
      "2 Train Loss 52.97927 Test MSE 8.929267177466773 Test RE 1.428288597988508\n",
      "3 Train Loss 47.319862 Test MSE 8.789074252732533 Test RE 1.4170318997446443\n",
      "4 Train Loss 44.13391 Test MSE 8.88879701245074 Test RE 1.4250482022067892\n",
      "5 Train Loss 43.161938 Test MSE 8.496149069335642 Test RE 1.3932181454922223\n",
      "6 Train Loss 42.882027 Test MSE 8.298005107926041 Test RE 1.3768762513422947\n",
      "7 Train Loss 42.71676 Test MSE 8.288635820891546 Test RE 1.376098715528033\n",
      "8 Train Loss 42.51467 Test MSE 8.42368749309178 Test RE 1.3872642150963916\n",
      "9 Train Loss 42.373924 Test MSE 8.355429237182642 Test RE 1.3816321897528068\n",
      "10 Train Loss 42.309395 Test MSE 8.303079699393782 Test RE 1.3772971968880159\n",
      "11 Train Loss 42.04547 Test MSE 8.245783941694068 Test RE 1.3725369213512704\n",
      "12 Train Loss 41.663517 Test MSE 8.3625734221924 Test RE 1.3822227355324115\n",
      "13 Train Loss 41.282654 Test MSE 8.267263027906072 Test RE 1.3743233897873988\n",
      "14 Train Loss 40.90892 Test MSE 8.248610154032285 Test RE 1.372772117208993\n",
      "15 Train Loss 40.43358 Test MSE 8.214923442310427 Test RE 1.3699660996610017\n",
      "16 Train Loss 40.135895 Test MSE 8.274331938612905 Test RE 1.3749108208082121\n",
      "17 Train Loss 39.788643 Test MSE 8.341078322092203 Test RE 1.3804451647187566\n",
      "18 Train Loss 39.328888 Test MSE 8.26375156300372 Test RE 1.3740314914359568\n",
      "19 Train Loss 38.32047 Test MSE 8.09153756607278 Test RE 1.3596389192941247\n",
      "20 Train Loss 37.33099 Test MSE 7.938729267264298 Test RE 1.3467393692821865\n",
      "21 Train Loss 36.747406 Test MSE 7.945881838345218 Test RE 1.347345919778661\n",
      "22 Train Loss 35.282276 Test MSE 7.968078340342792 Test RE 1.3492264857479204\n",
      "23 Train Loss 34.740818 Test MSE 7.821370819970143 Test RE 1.3367478635441408\n",
      "24 Train Loss 33.770702 Test MSE 7.811692437675905 Test RE 1.3359205429916536\n",
      "25 Train Loss 33.333794 Test MSE 7.713844884122656 Test RE 1.3275274531760974\n",
      "26 Train Loss 33.07053 Test MSE 7.668538462278972 Test RE 1.3236231684423978\n",
      "27 Train Loss 32.598408 Test MSE 7.637923990213171 Test RE 1.3209784305416583\n",
      "28 Train Loss 32.209953 Test MSE 7.644506617816934 Test RE 1.3215475404448283\n",
      "29 Train Loss 31.403149 Test MSE 7.2905425636588435 Test RE 1.2905890772376822\n",
      "30 Train Loss 30.579496 Test MSE 7.210108530388653 Test RE 1.2834500205949932\n",
      "31 Train Loss 30.15176 Test MSE 7.237841549059456 Test RE 1.2859159877642687\n",
      "32 Train Loss 29.88306 Test MSE 7.263734223705305 Test RE 1.2882140540515088\n",
      "33 Train Loss 29.469616 Test MSE 7.359998062228394 Test RE 1.29672209313155\n",
      "34 Train Loss 28.978046 Test MSE 7.444960951332498 Test RE 1.3041852147260569\n",
      "35 Train Loss 28.8036 Test MSE 7.391746390120322 Test RE 1.2995158749113231\n",
      "36 Train Loss 28.597054 Test MSE 7.311320284268566 Test RE 1.2924268293986463\n",
      "37 Train Loss 28.198795 Test MSE 6.976257649826523 Test RE 1.2624649109856334\n",
      "38 Train Loss 27.87729 Test MSE 7.017317882759849 Test RE 1.2661747117850095\n",
      "39 Train Loss 27.434227 Test MSE 6.870627295439106 Test RE 1.25287070769015\n",
      "40 Train Loss 27.01252 Test MSE 7.065248799549777 Test RE 1.2704915772999328\n",
      "41 Train Loss 26.770811 Test MSE 7.461531095766307 Test RE 1.3056357613651566\n",
      "42 Train Loss 26.606396 Test MSE 7.374349212343891 Test RE 1.2979857069612777\n",
      "43 Train Loss 26.236404 Test MSE 7.2690346525589495 Test RE 1.288683980507568\n",
      "44 Train Loss 26.025286 Test MSE 6.899484076468254 Test RE 1.2554989927017612\n",
      "45 Train Loss 25.862423 Test MSE 6.954517286998634 Test RE 1.2604962436090232\n",
      "46 Train Loss 25.665874 Test MSE 7.030350774035032 Test RE 1.267349965828164\n",
      "47 Train Loss 25.435604 Test MSE 6.9311945280150775 Test RE 1.258380860335174\n",
      "48 Train Loss 24.814236 Test MSE 6.166389257015259 Test RE 1.1869256861155066\n",
      "49 Train Loss 24.219599 Test MSE 6.210826352000497 Test RE 1.1911947037009845\n",
      "50 Train Loss 22.913975 Test MSE 6.295613815895053 Test RE 1.1992979744115215\n",
      "51 Train Loss 22.421871 Test MSE 6.200404910493611 Test RE 1.190194902942288\n",
      "52 Train Loss 22.203308 Test MSE 6.418987085521448 Test RE 1.210992103460137\n",
      "53 Train Loss 21.690384 Test MSE 6.185401252818883 Test RE 1.1887540218273989\n",
      "54 Train Loss 21.136282 Test MSE 5.973157313333889 Test RE 1.168180726549767\n",
      "55 Train Loss 20.604939 Test MSE 5.602273002977861 Test RE 1.1313323206896908\n",
      "56 Train Loss 19.959019 Test MSE 5.07180322353277 Test RE 1.0764385882060539\n",
      "57 Train Loss 19.250998 Test MSE 5.64084537753416 Test RE 1.135220324528088\n",
      "58 Train Loss 19.00164 Test MSE 5.628448678668316 Test RE 1.1339722203869695\n",
      "59 Train Loss 18.420218 Test MSE 5.593779545712088 Test RE 1.1304744039623618\n",
      "60 Train Loss 17.924736 Test MSE 5.396719236335647 Test RE 1.1103834306805629\n",
      "61 Train Loss 16.899998 Test MSE 5.878635531296506 Test RE 1.1589009741122558\n",
      "62 Train Loss 16.280771 Test MSE 6.291236428484102 Test RE 1.1988809614814875\n",
      "63 Train Loss 15.785537 Test MSE 6.39768553719581 Test RE 1.2089810818451798\n",
      "64 Train Loss 15.297975 Test MSE 6.146893790704005 Test RE 1.1850479269319691\n",
      "65 Train Loss 15.0654745 Test MSE 6.432140437342063 Test RE 1.2122322098330554\n",
      "66 Train Loss 14.882074 Test MSE 6.3746386599691665 Test RE 1.2068015141581478\n",
      "67 Train Loss 14.384583 Test MSE 6.089114309840054 Test RE 1.1794651788564672\n",
      "68 Train Loss 13.755062 Test MSE 5.777781602228478 Test RE 1.1489169089148037\n",
      "69 Train Loss 12.578084 Test MSE 5.293145880480097 Test RE 1.0996766207249078\n",
      "70 Train Loss 11.888144 Test MSE 4.597312671435283 Test RE 1.0248494708787448\n",
      "71 Train Loss 10.631214 Test MSE 4.800645763862711 Test RE 1.0472681378176285\n",
      "72 Train Loss 9.903599 Test MSE 4.721295569070061 Test RE 1.0385768910860673\n",
      "73 Train Loss 9.360144 Test MSE 4.613174856667238 Test RE 1.0266159761232514\n",
      "74 Train Loss 8.778263 Test MSE 4.270167986024577 Test RE 0.9877124781493961\n",
      "75 Train Loss 8.5431385 Test MSE 4.322054411960265 Test RE 0.9936951618653045\n",
      "76 Train Loss 8.325215 Test MSE 4.258720686990768 Test RE 0.9863876792296359\n",
      "77 Train Loss 7.8709292 Test MSE 4.094200737890304 Test RE 0.9671473059362354\n",
      "78 Train Loss 7.697604 Test MSE 3.9038224552334158 Test RE 0.9443937172747839\n",
      "79 Train Loss 7.4717803 Test MSE 3.8081145544812953 Test RE 0.9327452850329132\n",
      "80 Train Loss 7.250596 Test MSE 3.7060601133628013 Test RE 0.9201619910666152\n",
      "81 Train Loss 7.150038 Test MSE 3.6291291616404524 Test RE 0.9105614772520055\n",
      "82 Train Loss 6.838639 Test MSE 3.640119217728704 Test RE 0.9119391572124144\n",
      "83 Train Loss 6.6829348 Test MSE 3.572513825647893 Test RE 0.90343106380313\n",
      "84 Train Loss 6.4957857 Test MSE 3.6048850331325317 Test RE 0.9075149113905938\n",
      "85 Train Loss 6.344844 Test MSE 3.6281202639306285 Test RE 0.9104349004336968\n",
      "86 Train Loss 6.032271 Test MSE 3.632198768065603 Test RE 0.9109464834687483\n",
      "87 Train Loss 5.8364816 Test MSE 3.6323983661210377 Test RE 0.9109715124746591\n",
      "88 Train Loss 5.7556667 Test MSE 3.6499093550495836 Test RE 0.9131646685363322\n",
      "89 Train Loss 5.6520734 Test MSE 3.7232261741091603 Test RE 0.9222905733848702\n",
      "90 Train Loss 5.5920606 Test MSE 3.635276314959975 Test RE 0.9113323223376018\n",
      "91 Train Loss 5.3902073 Test MSE 3.7144474743871863 Test RE 0.9212026338148721\n",
      "92 Train Loss 5.267869 Test MSE 3.7956085861613045 Test RE 0.9312124430533705\n",
      "93 Train Loss 5.13075 Test MSE 3.791604721098501 Test RE 0.9307211604755952\n",
      "94 Train Loss 5.0249987 Test MSE 3.7947513930172425 Test RE 0.9311072854776549\n",
      "95 Train Loss 4.939746 Test MSE 3.7748518198473486 Test RE 0.9286627258144795\n",
      "96 Train Loss 4.6981063 Test MSE 3.9654207464435087 Test RE 0.9518153348101224\n",
      "97 Train Loss 4.626571 Test MSE 4.030519113797629 Test RE 0.9595962735853916\n",
      "98 Train Loss 4.5266323 Test MSE 3.9646430311155836 Test RE 0.9517219931799454\n",
      "99 Train Loss 4.39805 Test MSE 4.028226682133293 Test RE 0.9593233407813502\n",
      "Training time: 50.58\n",
      "KG_stan_tune5\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.479633 Test MSE 8.41973874025602 Test RE 1.386939024636071\n",
      "1 Train Loss 55.9675 Test MSE 8.878156509300842 Test RE 1.424195006299671\n",
      "2 Train Loss 48.236824 Test MSE 7.819039001799007 Test RE 1.3365485835592215\n",
      "3 Train Loss 43.97647 Test MSE 8.343206313227894 Test RE 1.3806212443348698\n",
      "4 Train Loss 43.874752 Test MSE 8.344164570048608 Test RE 1.3807005275078377\n",
      "5 Train Loss 43.630386 Test MSE 8.317799895092632 Test RE 1.3785175336297346\n",
      "6 Train Loss 42.05044 Test MSE 8.377687317973487 Test RE 1.3834712351705776\n",
      "7 Train Loss 40.78202 Test MSE 8.806188642303445 Test RE 1.418410875552782\n",
      "8 Train Loss 40.210464 Test MSE 8.778108211849556 Test RE 1.4161476154980885\n",
      "9 Train Loss 39.843918 Test MSE 8.67922021798796 Test RE 1.4081483616372348\n",
      "10 Train Loss 39.3651 Test MSE 8.450827404441231 Test RE 1.389497200988544\n",
      "11 Train Loss 38.46962 Test MSE 8.28377773872973 Test RE 1.3756953813349158\n",
      "12 Train Loss 37.707645 Test MSE 8.122459968888357 Test RE 1.3622344217362503\n",
      "13 Train Loss 36.270657 Test MSE 7.828014801228365 Test RE 1.337315503326411\n",
      "14 Train Loss 35.19146 Test MSE 6.959903897194322 Test RE 1.2609843067907431\n",
      "15 Train Loss 33.759327 Test MSE 6.543180323205602 Test RE 1.2226509928537255\n",
      "16 Train Loss 32.414265 Test MSE 5.626875913651496 Test RE 1.1338137756229685\n",
      "17 Train Loss 30.269258 Test MSE 4.931458587103591 Test RE 1.0614407470040172\n",
      "18 Train Loss 25.76932 Test MSE 3.1885801459655823 Test RE 0.8535062959646671\n",
      "19 Train Loss 14.056059 Test MSE 2.605688289568941 Test RE 0.7715592652956813\n",
      "20 Train Loss 11.580385 Test MSE 2.5597484437362694 Test RE 0.7647274932538863\n",
      "21 Train Loss 10.223448 Test MSE 2.5515674037174496 Test RE 0.7635044681841127\n",
      "22 Train Loss 7.670568 Test MSE 1.7202974536819544 Test RE 0.6269166923114586\n",
      "23 Train Loss 5.2560263 Test MSE 0.39162457894494584 Test RE 0.2991183322760137\n",
      "24 Train Loss 2.7903588 Test MSE 0.23639424201790007 Test RE 0.23239485409904725\n",
      "25 Train Loss 1.6288285 Test MSE 0.19363510077088755 Test RE 0.21032945825199845\n",
      "26 Train Loss 0.9851463 Test MSE 0.1610283929215303 Test RE 0.19180471971917243\n",
      "27 Train Loss 0.75077647 Test MSE 0.1385925968803892 Test RE 0.17794183977110825\n",
      "28 Train Loss 0.5725236 Test MSE 0.11129961265131909 Test RE 0.15946114813361656\n",
      "29 Train Loss 0.47662786 Test MSE 0.06669313277936371 Test RE 0.12343792690398937\n",
      "30 Train Loss 0.41958535 Test MSE 0.06470587282061965 Test RE 0.12158497509980681\n",
      "31 Train Loss 0.36666977 Test MSE 0.06120301427058785 Test RE 0.1182481803039505\n",
      "32 Train Loss 0.3362822 Test MSE 0.054107756941785316 Test RE 0.11118285593883347\n",
      "33 Train Loss 0.2883876 Test MSE 0.04174552772925299 Test RE 0.09765917205906757\n",
      "34 Train Loss 0.24394652 Test MSE 0.03675496262293488 Test RE 0.09163598511249489\n",
      "35 Train Loss 0.23537123 Test MSE 0.0379742919722956 Test RE 0.09314357501184899\n",
      "36 Train Loss 0.19609751 Test MSE 0.02864196349496751 Test RE 0.08089272279441573\n",
      "37 Train Loss 0.17858946 Test MSE 0.027427166801748355 Test RE 0.07915867828260195\n",
      "38 Train Loss 0.16597958 Test MSE 0.022886793877547027 Test RE 0.07231036262048637\n",
      "39 Train Loss 0.15085462 Test MSE 0.025448546166184974 Test RE 0.07624994744864352\n",
      "40 Train Loss 0.13424735 Test MSE 0.029301976735043585 Test RE 0.08181944323393431\n",
      "41 Train Loss 0.1261475 Test MSE 0.03317825614973845 Test RE 0.08706324261773828\n",
      "42 Train Loss 0.11644706 Test MSE 0.02920161562469755 Test RE 0.08167920468399699\n",
      "43 Train Loss 0.11238571 Test MSE 0.027899456012425876 Test RE 0.07983731595136606\n",
      "44 Train Loss 0.10455861 Test MSE 0.024802824534093985 Test RE 0.07527636349733535\n",
      "45 Train Loss 0.09475166 Test MSE 0.025651766867929283 Test RE 0.0765537910447374\n",
      "46 Train Loss 0.085174404 Test MSE 0.023134364255655675 Test RE 0.07270040746474195\n",
      "47 Train Loss 0.079491615 Test MSE 0.018856644631708382 Test RE 0.06563572224953794\n",
      "48 Train Loss 0.076286204 Test MSE 0.017728049179240184 Test RE 0.0636412255284217\n",
      "49 Train Loss 0.072472185 Test MSE 0.015880183009034942 Test RE 0.06023318271119164\n",
      "50 Train Loss 0.066821285 Test MSE 0.0143784817865691 Test RE 0.057314508978048614\n",
      "51 Train Loss 0.0657954 Test MSE 0.014029852645146381 Test RE 0.05661540457226089\n",
      "52 Train Loss 0.062541574 Test MSE 0.011481262813394838 Test RE 0.05121567364930253\n",
      "53 Train Loss 0.061024897 Test MSE 0.011289807110134019 Test RE 0.05078685517255222\n",
      "54 Train Loss 0.05734939 Test MSE 0.010508975959617809 Test RE 0.04899911764961885\n",
      "55 Train Loss 0.055301398 Test MSE 0.009435591975915588 Test RE 0.04642935350501582\n",
      "56 Train Loss 0.053392515 Test MSE 0.007942517025016003 Test RE 0.04259779679469906\n",
      "57 Train Loss 0.051101297 Test MSE 0.007162786668087988 Test RE 0.04045284482744601\n",
      "58 Train Loss 0.047671847 Test MSE 0.007126770394065437 Test RE 0.04035101317160323\n",
      "59 Train Loss 0.04520402 Test MSE 0.007527592482912491 Test RE 0.0414701981255194\n",
      "60 Train Loss 0.043686308 Test MSE 0.008073370600372432 Test RE 0.04294726427877274\n",
      "61 Train Loss 0.042034283 Test MSE 0.007349848169927552 Test RE 0.040977668438568926\n",
      "62 Train Loss 0.03954142 Test MSE 0.007128790660963378 Test RE 0.040356732034096114\n",
      "63 Train Loss 0.035887223 Test MSE 0.005383588140546509 Test RE 0.035070662838027455\n",
      "64 Train Loss 0.033318646 Test MSE 0.0054878320677251916 Test RE 0.0354085764424707\n",
      "65 Train Loss 0.031387623 Test MSE 0.005480492615596993 Test RE 0.03538489072307349\n",
      "66 Train Loss 0.029531121 Test MSE 0.005212444399816115 Test RE 0.03450871422381013\n",
      "67 Train Loss 0.026112271 Test MSE 0.006049169054007316 Test RE 0.03717542319864301\n",
      "68 Train Loss 0.022267016 Test MSE 0.005879181223647497 Test RE 0.03664936750314146\n",
      "69 Train Loss 0.020979093 Test MSE 0.005272532599373694 Test RE 0.03470704965087338\n",
      "70 Train Loss 0.019504087 Test MSE 0.0044550303295040426 Test RE 0.03190313728961062\n",
      "71 Train Loss 0.01887908 Test MSE 0.003757049041885801 Test RE 0.029297562696562095\n",
      "72 Train Loss 0.017934982 Test MSE 0.0033330239545522884 Test RE 0.027594801715674393\n",
      "73 Train Loss 0.015929537 Test MSE 0.0028936943716206033 Test RE 0.025711913008243575\n",
      "74 Train Loss 0.014795142 Test MSE 0.002813870986126165 Test RE 0.025354797773303822\n",
      "75 Train Loss 0.014486459 Test MSE 0.002772716832006096 Test RE 0.025168702058370813\n",
      "76 Train Loss 0.013752987 Test MSE 0.0026696574283125198 Test RE 0.0246965238335508\n",
      "77 Train Loss 0.013159906 Test MSE 0.002574464914321414 Test RE 0.02425222278176293\n",
      "78 Train Loss 0.012813434 Test MSE 0.0025894443901905762 Test RE 0.024322675999656828\n",
      "79 Train Loss 0.011835542 Test MSE 0.002217551875848977 Test RE 0.02250841709898402\n",
      "80 Train Loss 0.011426348 Test MSE 0.0021454502442581373 Test RE 0.022139473253484542\n",
      "81 Train Loss 0.010740223 Test MSE 0.002103256251825142 Test RE 0.02192068667731525\n",
      "82 Train Loss 0.0102442615 Test MSE 0.0020988148769305833 Test RE 0.02189752986068297\n",
      "83 Train Loss 0.009811359 Test MSE 0.0017895922849525318 Test RE 0.02022018429874323\n",
      "84 Train Loss 0.009358609 Test MSE 0.0017086204786811968 Test RE 0.01975744874351641\n",
      "85 Train Loss 0.008896829 Test MSE 0.001739685862321569 Test RE 0.0199362502894376\n",
      "86 Train Loss 0.00868084 Test MSE 0.0016654699757823865 Test RE 0.01950637029131752\n",
      "87 Train Loss 0.0083766645 Test MSE 0.001436319490632095 Test RE 0.018114801823096213\n",
      "88 Train Loss 0.0081107635 Test MSE 0.0013635348362067525 Test RE 0.017649856520550344\n",
      "89 Train Loss 0.008003772 Test MSE 0.0013443053360134571 Test RE 0.01752495944110929\n",
      "90 Train Loss 0.007639317 Test MSE 0.001411398764015998 Test RE 0.017956964607363225\n",
      "91 Train Loss 0.0074073253 Test MSE 0.0013907549715772602 Test RE 0.017825157292289933\n",
      "92 Train Loss 0.0071873013 Test MSE 0.0013764737692956973 Test RE 0.0177334008113386\n",
      "93 Train Loss 0.006986865 Test MSE 0.0013871295958377103 Test RE 0.017801909105755395\n",
      "94 Train Loss 0.006864395 Test MSE 0.0013568544239518086 Test RE 0.017606567164247605\n",
      "95 Train Loss 0.0067360136 Test MSE 0.001272316002439021 Test RE 0.01704926083467126\n",
      "96 Train Loss 0.006588326 Test MSE 0.0011922054930236577 Test RE 0.016503787364145057\n",
      "97 Train Loss 0.006471632 Test MSE 0.0012097844419581762 Test RE 0.016625015459819217\n",
      "98 Train Loss 0.006301215 Test MSE 0.0011384263184067906 Test RE 0.01612725763582536\n",
      "99 Train Loss 0.005959414 Test MSE 0.0010461108683111602 Test RE 0.015459552460124204\n",
      "Training time: 50.92\n",
      "KG_stan_tune5\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.551514 Test MSE 8.546842743498134 Test RE 1.3973683967905675\n",
      "1 Train Loss 57.712303 Test MSE 8.6532132475701 Test RE 1.4060370459357947\n",
      "2 Train Loss 55.28648 Test MSE 8.22466560020358 Test RE 1.3707781870514177\n",
      "3 Train Loss 46.326073 Test MSE 8.653890039234804 Test RE 1.4060920298775827\n",
      "4 Train Loss 45.191433 Test MSE 8.643141207823273 Test RE 1.405218518532889\n",
      "5 Train Loss 44.248177 Test MSE 8.400429928564494 Test RE 1.385347792621735\n",
      "6 Train Loss 44.159325 Test MSE 8.398902607636145 Test RE 1.385221848659492\n",
      "7 Train Loss 43.989403 Test MSE 8.525188352013746 Test RE 1.3955970787851615\n",
      "8 Train Loss 43.87845 Test MSE 8.39361381180699 Test RE 1.3847856423142855\n",
      "9 Train Loss 43.54406 Test MSE 8.6219440010317 Test RE 1.4034943194177385\n",
      "10 Train Loss 43.35592 Test MSE 8.61135759255552 Test RE 1.402632418216689\n",
      "11 Train Loss 43.061203 Test MSE 8.729592182651333 Test RE 1.4122287155567548\n",
      "12 Train Loss 42.672234 Test MSE 8.612474418382496 Test RE 1.4027233705030326\n",
      "13 Train Loss 42.378906 Test MSE 8.688496699326233 Test RE 1.408900685759784\n",
      "14 Train Loss 41.67894 Test MSE 8.727397547827502 Test RE 1.4120511860071479\n",
      "15 Train Loss 41.021805 Test MSE 8.997944389097201 Test RE 1.4337707382300882\n",
      "16 Train Loss 37.26912 Test MSE 8.96707935595335 Test RE 1.4313095429555984\n",
      "17 Train Loss 35.028572 Test MSE 8.744429608035084 Test RE 1.4134283673652255\n",
      "18 Train Loss 33.389603 Test MSE 8.319314029873224 Test RE 1.3786429974777101\n",
      "19 Train Loss 32.455006 Test MSE 8.18458543044414 Test RE 1.367434092415944\n",
      "20 Train Loss 31.784904 Test MSE 8.415873876563996 Test RE 1.3866206688226501\n",
      "21 Train Loss 31.318344 Test MSE 8.151206612397942 Test RE 1.364642871922129\n",
      "22 Train Loss 30.903484 Test MSE 8.055765709657077 Test RE 1.3566301782770473\n",
      "23 Train Loss 29.753271 Test MSE 8.036237727964048 Test RE 1.3549848769676893\n",
      "24 Train Loss 28.43229 Test MSE 8.07406730831568 Test RE 1.3581703431850776\n",
      "25 Train Loss 27.180382 Test MSE 7.822924103084078 Test RE 1.3368805925026646\n",
      "26 Train Loss 25.037878 Test MSE 7.071289791286548 Test RE 1.2710346147389482\n",
      "27 Train Loss 22.782568 Test MSE 7.051443362036042 Test RE 1.2692497053528555\n",
      "28 Train Loss 18.362309 Test MSE 6.291706677837572 Test RE 1.1989257668602697\n",
      "29 Train Loss 16.66306 Test MSE 5.907101962038251 Test RE 1.1617034895520388\n",
      "30 Train Loss 14.631485 Test MSE 5.5084450971670345 Test RE 1.1218184357938592\n",
      "31 Train Loss 13.770227 Test MSE 5.791290021781647 Test RE 1.1502592053052496\n",
      "32 Train Loss 13.013773 Test MSE 5.370362399238663 Test RE 1.1076686317016982\n",
      "33 Train Loss 12.147909 Test MSE 4.976908622430213 Test RE 1.0663208319660882\n",
      "34 Train Loss 10.737606 Test MSE 4.280587932914478 Test RE 0.9889168383451774\n",
      "35 Train Loss 8.636299 Test MSE 3.689416334955572 Test RE 0.9180934593548672\n",
      "36 Train Loss 6.9874096 Test MSE 3.5544266032666596 Test RE 0.901141178519832\n",
      "37 Train Loss 5.864871 Test MSE 3.471246155409363 Test RE 0.8905345351158782\n",
      "38 Train Loss 4.967968 Test MSE 3.3058846390939967 Test RE 0.8690642949739417\n",
      "39 Train Loss 4.372862 Test MSE 3.00203633198662 Test RE 0.8281633980151187\n",
      "40 Train Loss 3.8644233 Test MSE 2.4106532879760767 Test RE 0.7421222225030987\n",
      "41 Train Loss 3.608687 Test MSE 2.0928319640605246 Test RE 0.6914730211690151\n",
      "42 Train Loss 3.461811 Test MSE 1.9874943128287346 Test RE 0.6738465475176568\n",
      "43 Train Loss 3.2836914 Test MSE 1.936177211298492 Test RE 0.6650902976393991\n",
      "44 Train Loss 3.0364332 Test MSE 1.736447641050005 Test RE 0.6298525711934242\n",
      "45 Train Loss 2.6587174 Test MSE 1.3472073893924932 Test RE 0.5547857384685176\n",
      "46 Train Loss 2.2329576 Test MSE 0.9499547248388852 Test RE 0.46586438891159637\n",
      "47 Train Loss 1.5009795 Test MSE 0.5181905708785064 Test RE 0.3440747582243902\n",
      "48 Train Loss 0.8402752 Test MSE 0.2742586807258869 Test RE 0.25031579326364783\n",
      "49 Train Loss 0.5142668 Test MSE 0.2404480295882509 Test RE 0.2343789862687946\n",
      "50 Train Loss 0.31741187 Test MSE 0.14346489409177468 Test RE 0.18104264306376563\n",
      "51 Train Loss 0.2657436 Test MSE 0.10880256103350673 Test RE 0.15766221341267062\n",
      "52 Train Loss 0.19779712 Test MSE 0.11614167256632575 Test RE 0.16289287867532737\n",
      "53 Train Loss 0.16075619 Test MSE 0.08976783879359111 Test RE 0.14320838430548016\n",
      "54 Train Loss 0.13766165 Test MSE 0.06231743157843719 Test RE 0.11931988690227396\n",
      "55 Train Loss 0.11975156 Test MSE 0.047240119314774856 Test RE 0.10388756168825651\n",
      "56 Train Loss 0.09659581 Test MSE 0.025852061869731463 Test RE 0.07685208485238651\n",
      "57 Train Loss 0.08876211 Test MSE 0.023952205520403558 Test RE 0.07397429161484785\n",
      "58 Train Loss 0.07687627 Test MSE 0.020302791668997986 Test RE 0.06810608865856581\n",
      "59 Train Loss 0.068401754 Test MSE 0.019598514933881775 Test RE 0.06691440835704786\n",
      "60 Train Loss 0.06192962 Test MSE 0.017826474932860253 Test RE 0.06381764836161538\n",
      "61 Train Loss 0.057104763 Test MSE 0.015827610489922768 Test RE 0.060133396854854373\n",
      "62 Train Loss 0.051373374 Test MSE 0.015081495634638684 Test RE 0.058698941071055326\n",
      "63 Train Loss 0.047662307 Test MSE 0.012169533990110863 Test RE 0.05272845355207045\n",
      "64 Train Loss 0.04353652 Test MSE 0.010085199310248833 Test RE 0.04800100198042053\n",
      "65 Train Loss 0.04124584 Test MSE 0.01002237884573145 Test RE 0.04785126990200714\n",
      "66 Train Loss 0.037003018 Test MSE 0.008415273000993475 Test RE 0.04384723025794429\n",
      "67 Train Loss 0.033430897 Test MSE 0.007219492344002987 Test RE 0.04061265579576987\n",
      "68 Train Loss 0.030559547 Test MSE 0.005420967303622553 Test RE 0.035192203006557926\n",
      "69 Train Loss 0.029409328 Test MSE 0.006152637573839258 Test RE 0.03749201023942571\n",
      "70 Train Loss 0.027133543 Test MSE 0.005823248962337314 Test RE 0.0364746169129808\n",
      "71 Train Loss 0.024539936 Test MSE 0.0043073370978100115 Test RE 0.03136985353923575\n",
      "72 Train Loss 0.02338871 Test MSE 0.004209349188492779 Test RE 0.031010983323738524\n",
      "73 Train Loss 0.020747675 Test MSE 0.0038565194190058293 Test RE 0.029682865319234007\n",
      "74 Train Loss 0.019865613 Test MSE 0.003932408435790043 Test RE 0.029973493886964766\n",
      "75 Train Loss 0.018579043 Test MSE 0.00388151885401985 Test RE 0.029778917755798447\n",
      "76 Train Loss 0.016235428 Test MSE 0.003221172084944599 Test RE 0.027127828029737747\n",
      "77 Train Loss 0.014886417 Test MSE 0.004277152433457555 Test RE 0.03125974453201716\n",
      "78 Train Loss 0.014137606 Test MSE 0.004157528887552134 Test RE 0.030819507760604648\n",
      "79 Train Loss 0.012710312 Test MSE 0.004517906474739013 Test RE 0.03212748122402858\n",
      "80 Train Loss 0.01182696 Test MSE 0.004221792697055865 Test RE 0.031056786208611364\n",
      "81 Train Loss 0.01027151 Test MSE 0.0038190209542473064 Test RE 0.029538203685531114\n",
      "82 Train Loss 0.009421544 Test MSE 0.003281314709268784 Test RE 0.027379909162579274\n",
      "83 Train Loss 0.009112734 Test MSE 0.002806549562461629 Test RE 0.02532179090755457\n",
      "84 Train Loss 0.007868543 Test MSE 0.0025764130269645036 Test RE 0.024261396945896747\n",
      "85 Train Loss 0.0073765786 Test MSE 0.002568827850247242 Test RE 0.024225656824107728\n",
      "86 Train Loss 0.0069846767 Test MSE 0.0026374699419344306 Test RE 0.02454719201065956\n",
      "87 Train Loss 0.0065948535 Test MSE 0.0024268359587387724 Test RE 0.023546603507324505\n",
      "88 Train Loss 0.006057332 Test MSE 0.00257645965770175 Test RE 0.024261616499534976\n",
      "89 Train Loss 0.005824331 Test MSE 0.0024813242856170175 Test RE 0.02380947522278375\n",
      "90 Train Loss 0.005358975 Test MSE 0.0025735681397820076 Test RE 0.024247998472842456\n",
      "91 Train Loss 0.005004555 Test MSE 0.00242596997098205 Test RE 0.023542401968757575\n",
      "92 Train Loss 0.0048011434 Test MSE 0.0022824919932884474 Test RE 0.02283561391183592\n",
      "93 Train Loss 0.0044766613 Test MSE 0.0017563879434413158 Test RE 0.02003172197582431\n",
      "94 Train Loss 0.004335123 Test MSE 0.0017304007233251862 Test RE 0.01988297673123117\n",
      "95 Train Loss 0.0037988843 Test MSE 0.0017446136562050956 Test RE 0.019964465803343077\n",
      "96 Train Loss 0.0036178902 Test MSE 0.0015580862304914362 Test RE 0.018867041513916473\n",
      "97 Train Loss 0.003525317 Test MSE 0.0014106024572548002 Test RE 0.017951898261069195\n",
      "98 Train Loss 0.0032914102 Test MSE 0.0010818519696143012 Test RE 0.015721427610282907\n",
      "99 Train Loss 0.0030571832 Test MSE 0.0012021335093173747 Test RE 0.01657236202320762\n",
      "Training time: 49.25\n",
      "KG_stan_tune5\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.96312 Test MSE 8.527677892380925 Test RE 1.3958008362570085\n",
      "1 Train Loss 58.228252 Test MSE 8.605425529034665 Test RE 1.402149222743046\n",
      "2 Train Loss 56.69836 Test MSE 9.41237224055476 Test RE 1.4664174076634422\n",
      "3 Train Loss 50.10212 Test MSE 8.449833711405814 Test RE 1.389415506367641\n",
      "4 Train Loss 47.204224 Test MSE 8.661431963307036 Test RE 1.4067046058279515\n",
      "5 Train Loss 45.69387 Test MSE 8.363184105125375 Test RE 1.3822732035152834\n",
      "6 Train Loss 45.007645 Test MSE 8.4912148124901 Test RE 1.3928135213195298\n",
      "7 Train Loss 44.512833 Test MSE 8.498000513873786 Test RE 1.3933699392986638\n",
      "8 Train Loss 43.855698 Test MSE 8.77330328271983 Test RE 1.4157599795647797\n",
      "9 Train Loss 43.594376 Test MSE 8.714487492866494 Test RE 1.4110064069139052\n",
      "10 Train Loss 43.208282 Test MSE 8.87022094063614 Test RE 1.4235583694114178\n",
      "11 Train Loss 42.92237 Test MSE 8.874233859400801 Test RE 1.4238803443754462\n",
      "12 Train Loss 41.889366 Test MSE 8.954174963586354 Test RE 1.430279283880462\n",
      "13 Train Loss 40.63813 Test MSE 9.234167963792752 Test RE 1.4524692447091905\n",
      "14 Train Loss 38.60915 Test MSE 8.724569239230181 Test RE 1.4118223640643457\n",
      "15 Train Loss 34.725853 Test MSE 8.749109274220025 Test RE 1.4138065217179012\n",
      "16 Train Loss 31.387909 Test MSE 8.107823615288224 Test RE 1.3610065218882283\n",
      "17 Train Loss 30.070518 Test MSE 8.187742655628536 Test RE 1.3676978126201849\n",
      "18 Train Loss 29.197803 Test MSE 7.9313089465830835 Test RE 1.3461098243061314\n",
      "19 Train Loss 27.866013 Test MSE 7.407119384890352 Test RE 1.3008665079991801\n",
      "20 Train Loss 24.392822 Test MSE 6.52651529250106 Test RE 1.221092996158101\n",
      "21 Train Loss 21.965694 Test MSE 6.111213690640878 Test RE 1.1816035721941143\n",
      "22 Train Loss 19.11454 Test MSE 5.835759408597483 Test RE 1.1546669886363925\n",
      "23 Train Loss 15.543577 Test MSE 5.32313292611057 Test RE 1.102787198168124\n",
      "24 Train Loss 13.258268 Test MSE 4.9205361890052375 Test RE 1.060264634020482\n",
      "25 Train Loss 10.816487 Test MSE 4.7797953227367875 Test RE 1.0449913853554507\n",
      "26 Train Loss 8.78837 Test MSE 4.60468989134795 Test RE 1.0256714194639027\n",
      "27 Train Loss 7.354779 Test MSE 3.8606499203937967 Test RE 0.9391571544908054\n",
      "28 Train Loss 6.14378 Test MSE 3.9060285531677823 Test RE 0.9446605238206348\n",
      "29 Train Loss 5.462591 Test MSE 3.689954884616468 Test RE 0.918160464652472\n",
      "30 Train Loss 4.6414957 Test MSE 3.030860469865204 Test RE 0.8321297173774946\n",
      "31 Train Loss 3.7238595 Test MSE 2.270555423207 Test RE 0.7202348204439722\n",
      "32 Train Loss 3.0868075 Test MSE 2.2019491593753306 Test RE 0.7092701846794267\n",
      "33 Train Loss 2.7063842 Test MSE 2.2756161141340576 Test RE 0.7210370155991419\n",
      "34 Train Loss 2.4853878 Test MSE 2.2432845565739816 Test RE 0.715896507225818\n",
      "35 Train Loss 2.1911373 Test MSE 2.3023788036759827 Test RE 0.7252645487390305\n",
      "36 Train Loss 2.040986 Test MSE 2.376518519259912 Test RE 0.7368492770329346\n",
      "37 Train Loss 1.8261033 Test MSE 2.4498852955864296 Test RE 0.7481366588725635\n",
      "38 Train Loss 1.6904235 Test MSE 2.4468060572270165 Test RE 0.7476663479911609\n",
      "39 Train Loss 1.5737836 Test MSE 2.52901795992819 Test RE 0.7601232508294564\n",
      "40 Train Loss 1.4683927 Test MSE 2.556843034437345 Test RE 0.7642933730177709\n",
      "41 Train Loss 1.4079556 Test MSE 2.605445800721141 Test RE 0.7715233632902464\n",
      "42 Train Loss 1.3379794 Test MSE 2.6518967972066854 Test RE 0.7783705031059976\n",
      "43 Train Loss 1.2703371 Test MSE 2.7417052789446954 Test RE 0.791440817026216\n",
      "44 Train Loss 1.2280855 Test MSE 2.813810179385433 Test RE 0.8017804425320438\n",
      "45 Train Loss 1.1907912 Test MSE 2.7927811438108203 Test RE 0.7987787670934983\n",
      "46 Train Loss 1.144445 Test MSE 2.7767970465337233 Test RE 0.796489637020507\n",
      "47 Train Loss 1.1051235 Test MSE 2.87650112130644 Test RE 0.8106629674401274\n",
      "48 Train Loss 1.0622649 Test MSE 2.9018330794865594 Test RE 0.81422470191505\n",
      "49 Train Loss 1.0295471 Test MSE 2.9495198151243045 Test RE 0.8208876452017032\n",
      "50 Train Loss 0.9967557 Test MSE 3.0232647073679217 Test RE 0.8310863462212527\n",
      "51 Train Loss 0.9538577 Test MSE 3.022691838272443 Test RE 0.83100760249791\n",
      "52 Train Loss 0.9213952 Test MSE 3.10799333946189 Test RE 0.8426516974886162\n",
      "53 Train Loss 0.8989425 Test MSE 3.083757179873191 Test RE 0.8393597645977491\n",
      "54 Train Loss 0.86937284 Test MSE 3.1148016927691073 Test RE 0.843574146699879\n",
      "55 Train Loss 0.83982754 Test MSE 3.183217885411466 Test RE 0.852788319823013\n",
      "56 Train Loss 0.8147392 Test MSE 3.1979121189947795 Test RE 0.8547543559464482\n",
      "57 Train Loss 0.7782337 Test MSE 3.2231120515352942 Test RE 0.8581155309447047\n",
      "58 Train Loss 0.75247824 Test MSE 3.267161844062549 Test RE 0.8639595001396755\n",
      "59 Train Loss 0.708243 Test MSE 3.2992495254276224 Test RE 0.8681917241997803\n",
      "60 Train Loss 0.6918969 Test MSE 3.321949889066092 Test RE 0.8711733846230219\n",
      "61 Train Loss 0.662041 Test MSE 3.322463936390922 Test RE 0.8712407858541875\n",
      "62 Train Loss 0.6454575 Test MSE 3.3218411810890864 Test RE 0.8711591303033887\n",
      "63 Train Loss 0.6279557 Test MSE 3.323747809340348 Test RE 0.8714091028713792\n",
      "64 Train Loss 0.60343564 Test MSE 3.288926457382174 Test RE 0.866832411451213\n",
      "65 Train Loss 0.59270996 Test MSE 3.329129644893934 Test RE 0.8721143133543326\n",
      "66 Train Loss 0.5685859 Test MSE 3.339052475732656 Test RE 0.8734130618095686\n",
      "67 Train Loss 0.5595949 Test MSE 3.3621699079937746 Test RE 0.8764313192992663\n",
      "68 Train Loss 0.548797 Test MSE 3.3936867227968817 Test RE 0.8805295495183835\n",
      "69 Train Loss 0.5302395 Test MSE 3.44019947361777 Test RE 0.8865431383562341\n",
      "70 Train Loss 0.520222 Test MSE 3.4295558369204513 Test RE 0.8851706375736769\n",
      "71 Train Loss 0.51394093 Test MSE 3.4118052192754744 Test RE 0.882876942712591\n",
      "72 Train Loss 0.5030848 Test MSE 3.4167608425339395 Test RE 0.8835178963492264\n",
      "73 Train Loss 0.49112844 Test MSE 3.4414305658153754 Test RE 0.8867017510651976\n",
      "74 Train Loss 0.4878176 Test MSE 3.459090853415828 Test RE 0.888973970320015\n",
      "75 Train Loss 0.47598946 Test MSE 3.4677433286132002 Test RE 0.8900851034950629\n",
      "76 Train Loss 0.47129577 Test MSE 3.4940467667178563 Test RE 0.8934544516856847\n",
      "77 Train Loss 0.46435574 Test MSE 3.478065587896388 Test RE 0.8914088551939126\n",
      "78 Train Loss 0.45594478 Test MSE 3.480657197526168 Test RE 0.8917409009142275\n",
      "79 Train Loss 0.44994226 Test MSE 3.4630979598992724 Test RE 0.8894887272990145\n",
      "80 Train Loss 0.44067192 Test MSE 3.4441620990210517 Test RE 0.8870535778436699\n",
      "81 Train Loss 0.43760937 Test MSE 3.464084755444782 Test RE 0.8896154463531099\n",
      "82 Train Loss 0.4345938 Test MSE 3.472396697492214 Test RE 0.8906821064096667\n",
      "83 Train Loss 0.42710668 Test MSE 3.47231845532797 Test RE 0.8906720716563971\n",
      "84 Train Loss 0.4221697 Test MSE 3.455832103856501 Test RE 0.8885551281634372\n",
      "85 Train Loss 0.41565186 Test MSE 3.456202612343647 Test RE 0.8886027590064304\n",
      "86 Train Loss 0.41150552 Test MSE 3.4612470344849724 Test RE 0.8892509925663861\n",
      "87 Train Loss 0.40820497 Test MSE 3.4852175059278006 Test RE 0.8923248829266238\n",
      "88 Train Loss 0.4034215 Test MSE 3.4627364141304633 Test RE 0.8894422949884933\n",
      "89 Train Loss 0.399809 Test MSE 3.473567883154752 Test RE 0.8908323003907512\n",
      "90 Train Loss 0.39583483 Test MSE 3.4819939465447822 Test RE 0.8919121213588329\n",
      "91 Train Loss 0.39049694 Test MSE 3.492869543377507 Test RE 0.8933039265049081\n",
      "92 Train Loss 0.38722408 Test MSE 3.503685540437379 Test RE 0.8946859569931588\n",
      "93 Train Loss 0.38428825 Test MSE 3.492274610710028 Test RE 0.8932278460338788\n",
      "94 Train Loss 0.38231426 Test MSE 3.4903668568463115 Test RE 0.8929838372071658\n",
      "95 Train Loss 0.38033336 Test MSE 3.4856965720448563 Test RE 0.892386208787495\n",
      "96 Train Loss 0.3776254 Test MSE 3.491555859073516 Test RE 0.8931359228485117\n",
      "97 Train Loss 0.37074107 Test MSE 3.4890834792176006 Test RE 0.8928196509063153\n",
      "98 Train Loss 0.36764634 Test MSE 3.505393108858128 Test RE 0.8949039490722842\n",
      "99 Train Loss 0.36558878 Test MSE 3.4922796932035003 Test RE 0.8932284960147008\n",
      "Training time: 57.08\n",
      "KG_stan_tune5\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.660145 Test MSE 8.543763286178722 Test RE 1.3971166357517144\n",
      "1 Train Loss 55.313717 Test MSE 8.5776212392956 Test RE 1.3998822049748318\n",
      "2 Train Loss 54.741955 Test MSE 8.243803261333126 Test RE 1.3723720661830705\n",
      "3 Train Loss 48.802902 Test MSE 8.124545852060134 Test RE 1.3624093243806263\n",
      "4 Train Loss 46.8975 Test MSE 7.685242987224354 Test RE 1.3250640211231925\n",
      "5 Train Loss 43.994473 Test MSE 7.968420516964974 Test RE 1.3492554556441345\n",
      "6 Train Loss 43.68857 Test MSE 8.124966413558807 Test RE 1.3624445860126577\n",
      "7 Train Loss 43.385887 Test MSE 8.090381847965984 Test RE 1.35954181689434\n",
      "8 Train Loss 43.336254 Test MSE 8.09003634252535 Test RE 1.359512786490184\n",
      "9 Train Loss 43.166702 Test MSE 8.073970651677742 Test RE 1.358162213665779\n",
      "10 Train Loss 43.122925 Test MSE 8.124397263733389 Test RE 1.3623968658967223\n",
      "11 Train Loss 43.003437 Test MSE 8.06810066857472 Test RE 1.3576684145705704\n",
      "12 Train Loss 42.677315 Test MSE 8.04649056878179 Test RE 1.3558489638988638\n",
      "13 Train Loss 42.25643 Test MSE 8.066697737695725 Test RE 1.3575503695790312\n",
      "14 Train Loss 41.7808 Test MSE 8.017742254466436 Test RE 1.3534247238259427\n",
      "15 Train Loss 40.939835 Test MSE 8.169390887013684 Test RE 1.366164193706376\n",
      "16 Train Loss 40.676163 Test MSE 8.02795992498994 Test RE 1.3542868396474728\n",
      "17 Train Loss 39.46456 Test MSE 7.817560297622818 Test RE 1.3364221963253928\n",
      "18 Train Loss 37.298515 Test MSE 6.904544419689205 Test RE 1.255959323593431\n",
      "19 Train Loss 36.082558 Test MSE 6.485460351670888 Test RE 1.2172463041730397\n",
      "20 Train Loss 32.573505 Test MSE 5.660470760561217 Test RE 1.1371934143478268\n",
      "21 Train Loss 29.767155 Test MSE 5.8503007068358395 Test RE 1.156104668765791\n",
      "22 Train Loss 27.601622 Test MSE 5.709632828476096 Test RE 1.1421210888082658\n",
      "23 Train Loss 26.379354 Test MSE 5.667870711570706 Test RE 1.1379364998092947\n",
      "24 Train Loss 25.427586 Test MSE 5.689742288940681 Test RE 1.1401299603995114\n",
      "25 Train Loss 24.658484 Test MSE 5.746225497523556 Test RE 1.1457751337719133\n",
      "26 Train Loss 24.143467 Test MSE 5.539874786683444 Test RE 1.125014279063942\n",
      "27 Train Loss 23.378973 Test MSE 5.494518868961785 Test RE 1.1203994703746876\n",
      "28 Train Loss 22.981014 Test MSE 5.100086529356723 Test RE 1.0794358372438688\n",
      "29 Train Loss 22.399296 Test MSE 5.080372840171867 Test RE 1.0773476113171827\n",
      "30 Train Loss 22.223158 Test MSE 5.050509088635568 Test RE 1.074176479676796\n",
      "31 Train Loss 21.81757 Test MSE 4.916080524553648 Test RE 1.0597844776708853\n",
      "32 Train Loss 21.463583 Test MSE 4.9158758249129795 Test RE 1.0597624133699668\n",
      "33 Train Loss 21.231808 Test MSE 4.723097977582352 Test RE 1.0387751164648078\n",
      "34 Train Loss 21.05576 Test MSE 4.594136789926245 Test RE 1.0244954202599046\n",
      "35 Train Loss 20.803068 Test MSE 4.636453837845615 Test RE 1.029202968957877\n",
      "36 Train Loss 20.49052 Test MSE 4.451280519370473 Test RE 1.0084411115991994\n",
      "37 Train Loss 20.34208 Test MSE 4.151502676183982 Test RE 0.9738918274124273\n",
      "38 Train Loss 20.238712 Test MSE 3.973721876905187 Test RE 0.9528110693203106\n",
      "39 Train Loss 20.040602 Test MSE 4.063349635893385 Test RE 0.9634965345469846\n",
      "40 Train Loss 19.619226 Test MSE 3.5857162315563573 Test RE 0.9050988620083351\n",
      "41 Train Loss 19.14787 Test MSE 3.514078408836217 Test RE 0.8960119133552675\n",
      "42 Train Loss 18.493614 Test MSE 3.4035112534780088 Test RE 0.8818031699849618\n",
      "43 Train Loss 18.13832 Test MSE 3.458058353823167 Test RE 0.8888412860679281\n",
      "44 Train Loss 16.855604 Test MSE 2.435066805336368 Test RE 0.7458706199464137\n",
      "45 Train Loss 14.340258 Test MSE 1.852301784226189 Test RE 0.6505249122808043\n",
      "46 Train Loss 12.585973 Test MSE 1.7248038512707367 Test RE 0.6277372737001073\n",
      "47 Train Loss 11.397534 Test MSE 1.738027765428108 Test RE 0.6301390811548006\n",
      "48 Train Loss 10.629693 Test MSE 1.7949796387591936 Test RE 0.6403800939933284\n",
      "49 Train Loss 10.081271 Test MSE 1.6108296644373465 Test RE 0.6066425516248781\n",
      "50 Train Loss 9.5058 Test MSE 1.3512786169205375 Test RE 0.5556233805268038\n",
      "51 Train Loss 8.98138 Test MSE 1.259884945247855 Test RE 0.5365046661361302\n",
      "52 Train Loss 8.860915 Test MSE 1.2838195430389516 Test RE 0.5415767996220174\n",
      "53 Train Loss 8.618298 Test MSE 1.2341456401348077 Test RE 0.5309960212667615\n",
      "54 Train Loss 8.427852 Test MSE 1.19963735852955 Test RE 0.523519727048354\n",
      "55 Train Loss 7.7946825 Test MSE 1.2054311368788824 Test RE 0.5247824018955578\n",
      "56 Train Loss 7.6729393 Test MSE 1.2219766346520078 Test RE 0.5283716547389464\n",
      "57 Train Loss 7.4831767 Test MSE 1.1336402502693588 Test RE 0.5089155123887925\n",
      "58 Train Loss 7.0508833 Test MSE 1.1036995234763844 Test RE 0.5021500240186643\n",
      "59 Train Loss 6.5224037 Test MSE 0.962507552044046 Test RE 0.46893228406370907\n",
      "60 Train Loss 5.7056518 Test MSE 0.8892564913871721 Test RE 0.4507353109266287\n",
      "61 Train Loss 5.355897 Test MSE 0.864748586864933 Test RE 0.444480784695422\n",
      "62 Train Loss 4.7584863 Test MSE 0.7686602420107101 Test RE 0.41905909372846667\n",
      "63 Train Loss 3.6203582 Test MSE 0.5413839497929867 Test RE 0.3516905901020451\n",
      "64 Train Loss 3.2045004 Test MSE 0.4937750242707738 Test RE 0.3358710869852349\n",
      "65 Train Loss 2.8837533 Test MSE 0.41198082739465514 Test RE 0.30679378891910514\n",
      "66 Train Loss 2.447673 Test MSE 0.34138153289353657 Test RE 0.27927243543108327\n",
      "67 Train Loss 2.0476797 Test MSE 0.2730225468685162 Test RE 0.2497510467411042\n",
      "68 Train Loss 1.747611 Test MSE 0.21197185451151318 Test RE 0.22006306628799913\n",
      "69 Train Loss 1.6424787 Test MSE 0.22885834978081684 Test RE 0.228660654007942\n",
      "70 Train Loss 1.4847361 Test MSE 0.2053897061106562 Test RE 0.21661942416320448\n",
      "71 Train Loss 1.4356977 Test MSE 0.16989770239983312 Test RE 0.19701614325261507\n",
      "72 Train Loss 1.3477844 Test MSE 0.160988044968914 Test RE 0.1917806885143715\n",
      "73 Train Loss 1.1982757 Test MSE 0.12746346537626946 Test RE 0.17064788933507158\n",
      "74 Train Loss 1.0813843 Test MSE 0.11369687797618608 Test RE 0.16116930384313613\n",
      "75 Train Loss 1.0554817 Test MSE 0.099683164581695 Test RE 0.15091032996486684\n",
      "76 Train Loss 0.9686203 Test MSE 0.09226556075703836 Test RE 0.14518704732363721\n",
      "77 Train Loss 0.92323625 Test MSE 0.08297515141038508 Test RE 0.13768356009858884\n",
      "78 Train Loss 0.8522294 Test MSE 0.07934363790637 Test RE 0.13463690349694926\n",
      "79 Train Loss 0.8136759 Test MSE 0.07302102880854713 Test RE 0.12916118892779468\n",
      "80 Train Loss 0.7834799 Test MSE 0.06829843541295787 Test RE 0.12491466791788701\n",
      "81 Train Loss 0.7373041 Test MSE 0.05706122743521165 Test RE 0.11417699665469747\n",
      "82 Train Loss 0.6873731 Test MSE 0.05269196290758104 Test RE 0.10971859787486003\n",
      "83 Train Loss 0.6709915 Test MSE 0.05508715079686117 Test RE 0.1121845927005161\n",
      "84 Train Loss 0.61883575 Test MSE 0.04792520267556394 Test RE 0.10463814678104208\n",
      "85 Train Loss 0.5884583 Test MSE 0.04192863934623289 Test RE 0.09787312266519424\n",
      "86 Train Loss 0.56342936 Test MSE 0.04189836748465797 Test RE 0.09783778480740325\n",
      "87 Train Loss 0.5111141 Test MSE 0.04313704803695464 Test RE 0.09927348573936129\n",
      "88 Train Loss 0.4365768 Test MSE 0.039533828180047074 Test RE 0.09503695117067679\n",
      "89 Train Loss 0.40450916 Test MSE 0.030134863472069562 Test RE 0.0829741236842195\n",
      "90 Train Loss 0.37482613 Test MSE 0.02855328213434311 Test RE 0.08076739552542807\n",
      "91 Train Loss 0.3524656 Test MSE 0.02463251477580301 Test RE 0.07501747397175279\n",
      "92 Train Loss 0.33100927 Test MSE 0.021805574164118914 Test RE 0.07058165273941594\n",
      "93 Train Loss 0.28553686 Test MSE 0.024631084700349158 Test RE 0.0750152963174158\n",
      "94 Train Loss 0.2639856 Test MSE 0.022368602120469164 Test RE 0.07148706758607634\n",
      "95 Train Loss 0.24486032 Test MSE 0.02154165893451034 Test RE 0.07015322376254232\n",
      "96 Train Loss 0.23240869 Test MSE 0.022087708900853577 Test RE 0.0710368009427842\n",
      "97 Train Loss 0.22684115 Test MSE 0.022372997086849533 Test RE 0.07149409010419955\n",
      "98 Train Loss 0.2048192 Test MSE 0.017997368076987187 Test RE 0.06412281204720087\n",
      "99 Train Loss 0.17395255 Test MSE 0.016113758152585648 Test RE 0.06067453838040062\n",
      "Training time: 71.77\n",
      "KG_stan_tune5\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 50.140976 Test MSE 9.217629801710274 Test RE 1.4511679939168391\n",
      "1 Train Loss 41.09967 Test MSE 9.463182401679559 Test RE 1.4703701105145337\n",
      "2 Train Loss 40.251064 Test MSE 9.27626607560699 Test RE 1.4557763472376666\n",
      "3 Train Loss 40.01671 Test MSE 9.395443708696552 Test RE 1.4650981087082433\n",
      "4 Train Loss 39.819786 Test MSE 9.224701520858025 Test RE 1.4517245515774018\n",
      "5 Train Loss 39.60634 Test MSE 8.991069617119214 Test RE 1.4332229058620019\n",
      "6 Train Loss 39.221375 Test MSE 9.090072330276438 Test RE 1.4410920746142661\n",
      "7 Train Loss 38.683655 Test MSE 8.959609011564382 Test RE 1.4307132170710755\n",
      "8 Train Loss 37.875816 Test MSE 9.071616226991523 Test RE 1.4396283646866015\n",
      "9 Train Loss 37.098515 Test MSE 8.88841030187402 Test RE 1.4250172032310426\n",
      "10 Train Loss 36.04834 Test MSE 8.988383067464769 Test RE 1.4330087649233765\n",
      "11 Train Loss 35.796658 Test MSE 8.84479672106973 Test RE 1.4215167724534514\n",
      "12 Train Loss 35.54281 Test MSE 8.84989570809051 Test RE 1.4219264625486208\n",
      "13 Train Loss 35.41185 Test MSE 8.939076212430484 Test RE 1.4290728889613615\n",
      "14 Train Loss 35.091877 Test MSE 8.840460878448557 Test RE 1.4211683060757943\n",
      "15 Train Loss 34.927986 Test MSE 8.822610244591495 Test RE 1.4197327715202317\n",
      "16 Train Loss 34.84825 Test MSE 8.7960348162911 Test RE 1.4175929024315093\n",
      "17 Train Loss 34.76664 Test MSE 8.647561677068142 Test RE 1.4055778167939148\n",
      "18 Train Loss 34.30783 Test MSE 7.619907601490629 Test RE 1.3194195441235748\n",
      "19 Train Loss 32.90949 Test MSE 7.684642706173555 Test RE 1.3250122708820522\n",
      "20 Train Loss 32.374573 Test MSE 7.7575148626797965 Test RE 1.3312798799956556\n",
      "21 Train Loss 31.959911 Test MSE 7.7076999081072595 Test RE 1.3269985827000856\n",
      "22 Train Loss 31.521126 Test MSE 7.641599596847469 Test RE 1.321296240268998\n",
      "23 Train Loss 31.36059 Test MSE 7.738793950646136 Test RE 1.3296725464339285\n",
      "24 Train Loss 31.139683 Test MSE 7.87034301806189 Test RE 1.340926244168723\n",
      "25 Train Loss 30.962757 Test MSE 7.915791846588023 Test RE 1.3447923906222206\n",
      "26 Train Loss 30.75585 Test MSE 7.871737995069921 Test RE 1.3410450749742129\n",
      "27 Train Loss 30.614403 Test MSE 7.813785831825451 Test RE 1.336099532431912\n",
      "28 Train Loss 30.543694 Test MSE 7.734349701205693 Test RE 1.3292906881516982\n",
      "29 Train Loss 30.485554 Test MSE 7.732105284405946 Test RE 1.3290978019400748\n",
      "30 Train Loss 30.265755 Test MSE 7.736001854774128 Test RE 1.3294326571062813\n",
      "31 Train Loss 30.076717 Test MSE 7.766816392698651 Test RE 1.332077766323704\n",
      "32 Train Loss 29.792784 Test MSE 7.644615814443838 Test RE 1.3215569791192645\n",
      "33 Train Loss 29.47319 Test MSE 7.47547960617685 Test RE 1.3068555626728664\n",
      "34 Train Loss 29.183285 Test MSE 7.479383108316079 Test RE 1.3071967212328242\n",
      "35 Train Loss 28.88884 Test MSE 7.377409835076673 Test RE 1.298255034622252\n",
      "36 Train Loss 28.629166 Test MSE 7.502828084852125 Test RE 1.309243896568119\n",
      "37 Train Loss 28.432777 Test MSE 7.428160894231498 Test RE 1.3027128926579272\n",
      "38 Train Loss 28.235975 Test MSE 7.2771207974498955 Test RE 1.2894005535830424\n",
      "39 Train Loss 28.114962 Test MSE 7.264544284997424 Test RE 1.2882858837204234\n",
      "40 Train Loss 27.003105 Test MSE 6.939978592641637 Test RE 1.2591779955780344\n",
      "41 Train Loss 26.224918 Test MSE 7.279836143938645 Test RE 1.289641091209266\n",
      "42 Train Loss 24.966516 Test MSE 7.522042595783468 Test RE 1.310919291181068\n",
      "43 Train Loss 24.0436 Test MSE 8.048700602922677 Test RE 1.3560351485933806\n",
      "44 Train Loss 23.798195 Test MSE 7.989258538010202 Test RE 1.3510185061929618\n",
      "45 Train Loss 23.547972 Test MSE 7.938249507587998 Test RE 1.3466986750486394\n",
      "46 Train Loss 23.334124 Test MSE 8.047648740449409 Test RE 1.3559465374522477\n",
      "47 Train Loss 23.051567 Test MSE 8.255872002919553 Test RE 1.3733762596264933\n",
      "48 Train Loss 22.558517 Test MSE 8.201810189554852 Test RE 1.368872243660569\n",
      "49 Train Loss 22.398987 Test MSE 8.283996305608028 Test RE 1.3757135300269214\n",
      "50 Train Loss 22.182474 Test MSE 8.343180242522124 Test RE 1.3806190872625757\n",
      "51 Train Loss 21.865206 Test MSE 8.293868810987423 Test RE 1.3765330436169312\n",
      "52 Train Loss 21.596157 Test MSE 8.195267819369938 Test RE 1.368326177890609\n",
      "53 Train Loss 21.280014 Test MSE 8.019189013682757 Test RE 1.3535468274872566\n",
      "54 Train Loss 20.92165 Test MSE 7.943062118636127 Test RE 1.3471068352423023\n",
      "55 Train Loss 20.738625 Test MSE 8.005541579023756 Test RE 1.3523945720741568\n",
      "56 Train Loss 20.364786 Test MSE 8.154212097687989 Test RE 1.3648944319841878\n",
      "57 Train Loss 20.231583 Test MSE 8.12768064130764 Test RE 1.36267213625272\n",
      "58 Train Loss 19.946232 Test MSE 8.019998797666895 Test RE 1.3536151668711671\n",
      "59 Train Loss 19.790329 Test MSE 8.026822906406982 Test RE 1.354190930858397\n",
      "60 Train Loss 19.549442 Test MSE 7.914080000147167 Test RE 1.3446469722872099\n",
      "61 Train Loss 19.392124 Test MSE 7.938507386080087 Test RE 1.3467205490022671\n",
      "62 Train Loss 19.092815 Test MSE 8.048146939345989 Test RE 1.3559885075130695\n",
      "63 Train Loss 18.810183 Test MSE 8.074268638470107 Test RE 1.3581872763446565\n",
      "64 Train Loss 18.543854 Test MSE 8.082939801460578 Test RE 1.3589163766227441\n",
      "65 Train Loss 17.96132 Test MSE 7.801622354673689 Test RE 1.33505919513519\n",
      "66 Train Loss 17.552404 Test MSE 7.887527285868886 Test RE 1.3423893488453327\n",
      "67 Train Loss 17.365877 Test MSE 7.89718888277579 Test RE 1.3432112576039539\n",
      "68 Train Loss 17.172737 Test MSE 7.743445303815462 Test RE 1.3300720820464158\n",
      "69 Train Loss 16.99326 Test MSE 7.81735085952747 Test RE 1.3364042943468077\n",
      "70 Train Loss 16.87735 Test MSE 7.815995662642796 Test RE 1.3362884514310112\n",
      "71 Train Loss 16.715744 Test MSE 7.785244401516351 Test RE 1.3336571133878048\n",
      "72 Train Loss 16.561762 Test MSE 7.789256901487691 Test RE 1.334000751269842\n",
      "73 Train Loss 16.396769 Test MSE 7.9032836217909015 Test RE 1.343729476382764\n",
      "74 Train Loss 16.302399 Test MSE 7.856851715868198 Test RE 1.3397764467204323\n",
      "75 Train Loss 16.141203 Test MSE 7.823468967787553 Test RE 1.3369271483911602\n",
      "76 Train Loss 16.058352 Test MSE 7.899798581438516 Test RE 1.3434331775254988\n",
      "77 Train Loss 15.950151 Test MSE 8.00982499596914 Test RE 1.3527563274344145\n",
      "78 Train Loss 15.817816 Test MSE 8.051835506304048 Test RE 1.356299205211125\n",
      "79 Train Loss 15.712257 Test MSE 8.030680709550488 Test RE 1.3545163133002156\n",
      "80 Train Loss 15.665478 Test MSE 8.028279578294098 Test RE 1.3543138015380356\n",
      "81 Train Loss 15.520632 Test MSE 8.05637962129376 Test RE 1.356681870146965\n",
      "82 Train Loss 15.413916 Test MSE 7.926459701896596 Test RE 1.3456982520160548\n",
      "83 Train Loss 15.311441 Test MSE 7.874922301685275 Test RE 1.3413162899799835\n",
      "84 Train Loss 15.041922 Test MSE 7.751621688429653 Test RE 1.3307741152623342\n",
      "85 Train Loss 14.886168 Test MSE 7.803891186763973 Test RE 1.3352533089244043\n",
      "86 Train Loss 14.80157 Test MSE 7.827966943792901 Test RE 1.3373114154069428\n",
      "87 Train Loss 14.680141 Test MSE 7.763615332997054 Test RE 1.331803232995914\n",
      "88 Train Loss 14.490156 Test MSE 7.531865632246616 Test RE 1.3117749767538025\n",
      "89 Train Loss 13.768541 Test MSE 6.285224033306746 Test RE 1.1983079525679965\n",
      "90 Train Loss 13.349096 Test MSE 5.939297660472185 Test RE 1.1648650255039474\n",
      "91 Train Loss 12.8840885 Test MSE 5.7573499517676865 Test RE 1.1468836840740237\n",
      "92 Train Loss 11.653693 Test MSE 5.352019894772797 Test RE 1.1057753893498137\n",
      "93 Train Loss 11.037104 Test MSE 5.371982091246364 Test RE 1.1078356545806\n",
      "94 Train Loss 10.541667 Test MSE 5.397243131163995 Test RE 1.110437325463123\n",
      "95 Train Loss 10.309945 Test MSE 5.430180098564277 Test RE 1.1138204237731109\n",
      "96 Train Loss 10.167498 Test MSE 5.382866158489868 Test RE 1.1089573687111913\n",
      "97 Train Loss 9.940899 Test MSE 5.445222556905094 Test RE 1.1153620862817064\n",
      "98 Train Loss 9.838053 Test MSE 5.47975571909086 Test RE 1.1188932647050402\n",
      "99 Train Loss 9.794431 Test MSE 5.484334712076373 Test RE 1.1193606518309889\n",
      "Training time: 97.28\n",
      "KG_stan_tune5\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.595432 Test MSE 8.482552165977365 Test RE 1.3921028732973317\n",
      "1 Train Loss 56.07772 Test MSE 8.385333738710402 Test RE 1.3841024469856622\n",
      "2 Train Loss 53.298035 Test MSE 8.912099779124826 Test RE 1.4269149244442672\n",
      "3 Train Loss 47.769814 Test MSE 8.352668617767755 Test RE 1.3814039264500446\n",
      "4 Train Loss 46.109154 Test MSE 8.846946278825952 Test RE 1.4216894981174528\n",
      "5 Train Loss 44.198593 Test MSE 8.81915509912619 Test RE 1.4194547436196494\n",
      "6 Train Loss 43.65763 Test MSE 8.456343870850693 Test RE 1.3899506396746582\n",
      "7 Train Loss 43.568043 Test MSE 8.455769723173484 Test RE 1.3899034531783643\n",
      "8 Train Loss 43.2911 Test MSE 8.432004308907935 Test RE 1.3879488781117906\n",
      "9 Train Loss 43.035503 Test MSE 8.451188716605879 Test RE 1.3895269044040435\n",
      "10 Train Loss 42.68116 Test MSE 8.496980784732779 Test RE 1.393286337129186\n",
      "11 Train Loss 41.503845 Test MSE 8.149104294488364 Test RE 1.3644668796860102\n",
      "12 Train Loss 38.57547 Test MSE 7.510354646525556 Test RE 1.3099004246626853\n",
      "13 Train Loss 35.985447 Test MSE 7.572548871593705 Test RE 1.3153129702838786\n",
      "14 Train Loss 34.92423 Test MSE 7.468298755031702 Test RE 1.3062277374054758\n",
      "15 Train Loss 34.261993 Test MSE 7.337510150023772 Test RE 1.2947395599224822\n",
      "16 Train Loss 33.695805 Test MSE 7.254507540890024 Test RE 1.2873956238194408\n",
      "17 Train Loss 33.23153 Test MSE 7.114500539781211 Test RE 1.2749121752782062\n",
      "18 Train Loss 32.973587 Test MSE 7.1186045951137595 Test RE 1.275279843797242\n",
      "19 Train Loss 32.84337 Test MSE 7.088447849295783 Test RE 1.272575724853\n",
      "20 Train Loss 32.562363 Test MSE 7.136855508222994 Test RE 1.2769135995484469\n",
      "21 Train Loss 32.160873 Test MSE 7.061879905701499 Test RE 1.2701886395178417\n",
      "22 Train Loss 31.837543 Test MSE 7.054641533016599 Test RE 1.2695375058215654\n",
      "23 Train Loss 31.118746 Test MSE 7.051362311013605 Test RE 1.2692424107979197\n",
      "24 Train Loss 30.75973 Test MSE 7.018925674788401 Test RE 1.2663197550229943\n",
      "25 Train Loss 30.286442 Test MSE 6.990607153916633 Test RE 1.2637626296398201\n",
      "26 Train Loss 29.257793 Test MSE 6.89193632106787 Test RE 1.2548120723277059\n",
      "27 Train Loss 28.191597 Test MSE 6.656364326562132 Test RE 1.2331803687567708\n",
      "28 Train Loss 27.88359 Test MSE 6.651368114345412 Test RE 1.2327174743674432\n",
      "29 Train Loss 27.437752 Test MSE 6.551817641517572 Test RE 1.223457706295572\n",
      "30 Train Loss 27.046175 Test MSE 6.31499416745076 Test RE 1.2011425091076158\n",
      "31 Train Loss 26.514366 Test MSE 6.1641153245416955 Test RE 1.1867068191565662\n",
      "32 Train Loss 25.984144 Test MSE 6.354361334444433 Test RE 1.2048806054282024\n",
      "33 Train Loss 24.847054 Test MSE 6.205329168597324 Test RE 1.1906674256081073\n",
      "34 Train Loss 24.256172 Test MSE 6.30009956037031 Test RE 1.1997251596287966\n",
      "35 Train Loss 23.234566 Test MSE 6.243958525001362 Test RE 1.1943677415436191\n",
      "36 Train Loss 22.438583 Test MSE 5.878979270032744 Test RE 1.1589348555572825\n",
      "37 Train Loss 22.089663 Test MSE 5.949516252215905 Test RE 1.1658666729459994\n",
      "38 Train Loss 21.528614 Test MSE 6.018660677318939 Test RE 1.1726218703396745\n",
      "39 Train Loss 20.401602 Test MSE 5.630815356301589 Test RE 1.1342106044235405\n",
      "40 Train Loss 19.721466 Test MSE 5.665068526368387 Test RE 1.1376551681414002\n",
      "41 Train Loss 19.314177 Test MSE 5.762391592576581 Test RE 1.1473857301839505\n",
      "42 Train Loss 18.95117 Test MSE 5.755839044449802 Test RE 1.146733185262254\n",
      "43 Train Loss 18.575943 Test MSE 5.500345448755559 Test RE 1.1209933683421156\n",
      "44 Train Loss 17.959072 Test MSE 5.386354003571098 Test RE 1.109316586741411\n",
      "45 Train Loss 16.75335 Test MSE 5.180501934679877 Test RE 1.0879125340978608\n",
      "46 Train Loss 16.129711 Test MSE 5.293513283395269 Test RE 1.0997147849276925\n",
      "47 Train Loss 15.735955 Test MSE 5.443352386272784 Test RE 1.1151705333626054\n",
      "48 Train Loss 15.2738 Test MSE 5.4291205285499595 Test RE 1.1137117507385987\n",
      "49 Train Loss 14.32947 Test MSE 5.08402819046237 Test RE 1.0777351197654463\n",
      "50 Train Loss 13.529659 Test MSE 5.123615108740353 Test RE 1.0819228898556275\n",
      "51 Train Loss 13.230861 Test MSE 5.230515020571818 Test RE 1.0931513289300914\n",
      "52 Train Loss 12.993429 Test MSE 5.067524030749455 Test RE 1.0759843848337771\n",
      "53 Train Loss 12.795535 Test MSE 5.199128694056134 Test RE 1.089866601735127\n",
      "54 Train Loss 12.127241 Test MSE 5.072837659247355 Test RE 1.0765483568326866\n",
      "55 Train Loss 11.697068 Test MSE 4.9998487369791045 Test RE 1.0687755082497787\n",
      "56 Train Loss 11.498219 Test MSE 5.1687861764460195 Test RE 1.086681675129557\n",
      "57 Train Loss 11.272022 Test MSE 4.98171860272918 Test RE 1.066835985442203\n",
      "58 Train Loss 10.48378 Test MSE 4.327660350392304 Test RE 0.994339391229043\n",
      "59 Train Loss 9.73918 Test MSE 4.333670263186795 Test RE 0.9950295816868254\n",
      "60 Train Loss 9.330886 Test MSE 4.087746922683157 Test RE 0.9663847332007224\n",
      "61 Train Loss 8.99044 Test MSE 4.110516741781811 Test RE 0.9690725033152762\n",
      "62 Train Loss 8.80676 Test MSE 4.058109528688699 Test RE 0.9628750701912011\n",
      "63 Train Loss 8.717525 Test MSE 4.049608201994374 Test RE 0.9618659787612698\n",
      "64 Train Loss 8.487217 Test MSE 3.9396631925694616 Test RE 0.9487190206936709\n",
      "65 Train Loss 8.341191 Test MSE 3.869724511648397 Test RE 0.9402602673429272\n",
      "66 Train Loss 8.191979 Test MSE 3.7103548446896424 Test RE 0.9206949970326063\n",
      "67 Train Loss 7.85477 Test MSE 3.6409337124385903 Test RE 0.9120411769581857\n",
      "68 Train Loss 7.6279526 Test MSE 3.4206812784901235 Test RE 0.8840246310114901\n",
      "69 Train Loss 7.518288 Test MSE 3.4267849977387366 Test RE 0.8848129876042434\n",
      "70 Train Loss 7.271814 Test MSE 3.5574048218071557 Test RE 0.9015186280664162\n",
      "71 Train Loss 6.919355 Test MSE 3.4956256383637743 Test RE 0.8936562936574111\n",
      "72 Train Loss 6.6805677 Test MSE 3.497609473774409 Test RE 0.8939098413368425\n",
      "73 Train Loss 6.3572316 Test MSE 3.5593891732135687 Test RE 0.901770030485667\n",
      "74 Train Loss 6.0106196 Test MSE 3.6456295050430714 Test RE 0.9126291272685092\n",
      "75 Train Loss 5.598601 Test MSE 3.6068869186519734 Test RE 0.9077668596208898\n",
      "76 Train Loss 5.2573724 Test MSE 3.368614650697155 Test RE 0.8772709065803682\n",
      "77 Train Loss 4.9812026 Test MSE 3.4337645054125394 Test RE 0.8857136011122695\n",
      "78 Train Loss 4.59474 Test MSE 3.4453952156813146 Test RE 0.8872123599544223\n",
      "79 Train Loss 4.453203 Test MSE 3.511590076266769 Test RE 0.8956946224186734\n",
      "80 Train Loss 4.395633 Test MSE 3.492253620310088 Test RE 0.893225161646196\n",
      "81 Train Loss 4.2015157 Test MSE 3.3065337982779384 Test RE 0.8691496175785526\n",
      "82 Train Loss 4.1336637 Test MSE 3.3439271284105954 Test RE 0.8740503732298339\n",
      "83 Train Loss 4.0215387 Test MSE 3.219862731832813 Test RE 0.8576828753695184\n",
      "84 Train Loss 3.8984427 Test MSE 3.3511251181833783 Test RE 0.8749905886404121\n",
      "85 Train Loss 3.7760851 Test MSE 3.4713111471774925 Test RE 0.8905428717679796\n",
      "86 Train Loss 3.6807995 Test MSE 3.4522829169025537 Test RE 0.8880987318021552\n",
      "87 Train Loss 3.590904 Test MSE 3.4136580988186447 Test RE 0.883116646107209\n",
      "88 Train Loss 3.4320774 Test MSE 3.580880877440374 Test RE 0.9044883912342753\n",
      "89 Train Loss 3.402089 Test MSE 3.574055309656736 Test RE 0.9036259509910266\n",
      "90 Train Loss 3.2917721 Test MSE 3.5576949856773776 Test RE 0.9015553940254979\n",
      "91 Train Loss 3.1796427 Test MSE 3.397002955878236 Test RE 0.8809596611430887\n",
      "92 Train Loss 3.0768127 Test MSE 3.427858553515904 Test RE 0.8849515754803579\n",
      "93 Train Loss 2.990629 Test MSE 3.2791981340406644 Test RE 0.8655494592174895\n",
      "94 Train Loss 2.8812447 Test MSE 3.235847103684385 Test RE 0.8598091383037395\n",
      "95 Train Loss 2.764414 Test MSE 3.187550670087621 Test RE 0.8533685018624748\n",
      "96 Train Loss 2.5871801 Test MSE 3.1461220301929043 Test RE 0.8478047435995896\n",
      "97 Train Loss 2.5100782 Test MSE 3.1974504655704137 Test RE 0.8546926571719089\n",
      "98 Train Loss 2.4203696 Test MSE 3.1303996663914466 Test RE 0.8456836895911067\n",
      "99 Train Loss 2.3530207 Test MSE 3.1312002919135162 Test RE 0.845791827964994\n",
      "Training time: 98.02\n",
      "KG_stan_tune6\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 51.864502 Test MSE 9.199446983781515 Test RE 1.449735990823975\n",
      "1 Train Loss 43.879417 Test MSE 9.252921591440991 Test RE 1.4539434030521678\n",
      "2 Train Loss 43.267593 Test MSE 9.397864658091995 Test RE 1.4652868544467785\n",
      "3 Train Loss 42.859642 Test MSE 9.450945807371658 Test RE 1.4694191543839676\n",
      "4 Train Loss 42.71438 Test MSE 9.445102958475621 Test RE 1.4689648653828873\n",
      "5 Train Loss 42.486298 Test MSE 9.387014382407646 Test RE 1.4644407389447516\n",
      "6 Train Loss 42.098 Test MSE 9.49936143258817 Test RE 1.473178141468474\n",
      "7 Train Loss 41.566143 Test MSE 9.234749757324144 Test RE 1.4525149999902602\n",
      "8 Train Loss 41.08007 Test MSE 9.488888288827757 Test RE 1.4723658204761536\n",
      "9 Train Loss 40.699654 Test MSE 9.284821145909056 Test RE 1.4564474900616111\n",
      "10 Train Loss 39.81311 Test MSE 8.954680644204783 Test RE 1.430319670309394\n",
      "11 Train Loss 38.05577 Test MSE 9.043039363444004 Test RE 1.4373590604809978\n",
      "12 Train Loss 37.111034 Test MSE 9.168945737408135 Test RE 1.4473306577645473\n",
      "13 Train Loss 36.91558 Test MSE 9.315392992429697 Test RE 1.4588433195592092\n",
      "14 Train Loss 36.661476 Test MSE 9.282977550424432 Test RE 1.4563028866666843\n",
      "15 Train Loss 36.51906 Test MSE 9.367986557288262 Test RE 1.4629557482767517\n",
      "16 Train Loss 36.25336 Test MSE 9.28764423431844 Test RE 1.4566688926857232\n",
      "17 Train Loss 36.028393 Test MSE 9.136066338371574 Test RE 1.4447332980592809\n",
      "18 Train Loss 35.940468 Test MSE 9.165021856345334 Test RE 1.4470209296204672\n",
      "19 Train Loss 35.781452 Test MSE 9.259288366049391 Test RE 1.4544435336332813\n",
      "20 Train Loss 35.655853 Test MSE 9.170377345313366 Test RE 1.4474436439898808\n",
      "21 Train Loss 35.436012 Test MSE 9.059075885208145 Test RE 1.4386329701099982\n",
      "22 Train Loss 35.285583 Test MSE 9.118151736197241 Test RE 1.443316138776776\n",
      "23 Train Loss 35.149277 Test MSE 9.19398405781742 Test RE 1.4493054770927543\n",
      "24 Train Loss 35.00917 Test MSE 9.233412880846483 Test RE 1.4524098588943544\n",
      "25 Train Loss 34.911034 Test MSE 9.341912500702204 Test RE 1.4609183963734305\n",
      "26 Train Loss 34.647892 Test MSE 9.486180433296173 Test RE 1.4721557200781306\n",
      "27 Train Loss 34.559578 Test MSE 9.622415247339255 Test RE 1.4826891434334255\n",
      "28 Train Loss 34.30635 Test MSE 9.539466816331878 Test RE 1.4762846737539488\n",
      "29 Train Loss 34.077682 Test MSE 9.735220962813683 Test RE 1.4913547675798058\n",
      "30 Train Loss 33.723145 Test MSE 9.699145380226685 Test RE 1.4885889635168859\n",
      "31 Train Loss 33.394753 Test MSE 9.527435505999424 Test RE 1.4753534244906001\n",
      "32 Train Loss 32.884666 Test MSE 9.308570509565513 Test RE 1.458309001974463\n",
      "33 Train Loss 31.004349 Test MSE 8.911408063314065 Test RE 1.4268595481137156\n",
      "34 Train Loss 29.914059 Test MSE 9.072572032635662 Test RE 1.4397042039107915\n",
      "35 Train Loss 29.148214 Test MSE 9.33537087144711 Test RE 1.4604068062611404\n",
      "36 Train Loss 28.921955 Test MSE 9.382919642355928 Test RE 1.4641212998779665\n",
      "37 Train Loss 28.44255 Test MSE 9.277857306785132 Test RE 1.4559012022903828\n",
      "38 Train Loss 28.234348 Test MSE 9.38098962162261 Test RE 1.4639707108342555\n",
      "39 Train Loss 27.966438 Test MSE 9.554461957795892 Test RE 1.4774445082302219\n",
      "40 Train Loss 27.834621 Test MSE 9.423970638015122 Test RE 1.4673206260642842\n",
      "41 Train Loss 27.576118 Test MSE 9.424719308310195 Test RE 1.4673789092228\n",
      "42 Train Loss 27.430035 Test MSE 9.49455118313112 Test RE 1.4728051031478075\n",
      "43 Train Loss 26.942297 Test MSE 9.356123425063359 Test RE 1.4620291491991575\n",
      "44 Train Loss 26.518251 Test MSE 9.375165140815735 Test RE 1.4635161642669166\n",
      "45 Train Loss 26.153822 Test MSE 9.353427798970051 Test RE 1.4618185188100783\n",
      "46 Train Loss 25.910275 Test MSE 9.225018042588593 Test RE 1.4517494574469711\n",
      "47 Train Loss 24.427612 Test MSE 7.111263537587112 Test RE 1.2746221083218063\n",
      "48 Train Loss 19.800602 Test MSE 6.067761754058159 Test RE 1.1773953611377082\n",
      "49 Train Loss 17.060055 Test MSE 5.9053667438255495 Test RE 1.1615328511303467\n",
      "50 Train Loss 14.901489 Test MSE 5.557064749250002 Test RE 1.126758359513391\n",
      "51 Train Loss 14.375717 Test MSE 5.609577901141801 Test RE 1.1320696620476878\n",
      "52 Train Loss 14.0020075 Test MSE 5.610501294028695 Test RE 1.1321628332342535\n",
      "53 Train Loss 13.773924 Test MSE 5.55426504072959 Test RE 1.126474487311814\n",
      "54 Train Loss 13.643885 Test MSE 5.562426159989755 Test RE 1.1273017721119873\n",
      "55 Train Loss 13.544958 Test MSE 5.554243666875278 Test RE 1.1264723198671058\n",
      "56 Train Loss 13.413737 Test MSE 5.479361296616627 Test RE 1.1188529960677085\n",
      "57 Train Loss 13.370788 Test MSE 5.4563540217812045 Test RE 1.116501550742657\n",
      "58 Train Loss 13.285875 Test MSE 5.436124483365785 Test RE 1.114429903208772\n",
      "59 Train Loss 13.241642 Test MSE 5.449322074554498 Test RE 1.1157818658430962\n",
      "60 Train Loss 13.173476 Test MSE 5.42093112049957 Test RE 1.1128714597586238\n",
      "61 Train Loss 13.159671 Test MSE 5.431970826127964 Test RE 1.1140040626660748\n",
      "62 Train Loss 13.12595 Test MSE 5.4466274950703015 Test RE 1.1155059659562436\n",
      "63 Train Loss 13.11237 Test MSE 5.443594488316785 Test RE 1.1151953326080375\n",
      "64 Train Loss 13.067192 Test MSE 5.424123611483122 Test RE 1.1131991072691056\n",
      "65 Train Loss 13.015243 Test MSE 5.399091460096007 Test RE 1.1106274482439837\n",
      "66 Train Loss 12.970839 Test MSE 5.430373230655135 Test RE 1.1138402309020368\n",
      "67 Train Loss 12.962874 Test MSE 5.442463268108096 Test RE 1.1150794535647546\n",
      "68 Train Loss 12.943312 Test MSE 5.4464515486879845 Test RE 1.1154879483091378\n",
      "69 Train Loss 12.888263 Test MSE 5.463350552623637 Test RE 1.1172171508436697\n",
      "70 Train Loss 12.858315 Test MSE 5.458322113791031 Test RE 1.1167028921201498\n",
      "71 Train Loss 12.843934 Test MSE 5.460273638986002 Test RE 1.1169025028273032\n",
      "72 Train Loss 12.834097 Test MSE 5.453453565577702 Test RE 1.1162047596704403\n",
      "73 Train Loss 12.81351 Test MSE 5.430294438503973 Test RE 1.1138321502248472\n",
      "74 Train Loss 12.793553 Test MSE 5.470948418492292 Test RE 1.1179937362746757\n",
      "75 Train Loss 12.776478 Test MSE 5.4598290477576645 Test RE 1.1168570311900883\n",
      "76 Train Loss 12.753822 Test MSE 5.493854076548232 Test RE 1.1203316886801595\n",
      "77 Train Loss 12.708182 Test MSE 5.489217637714568 Test RE 1.1198588470595428\n",
      "78 Train Loss 12.673868 Test MSE 5.477378205881605 Test RE 1.1186505100768742\n",
      "79 Train Loss 12.652058 Test MSE 5.45631942954072 Test RE 1.116498011533947\n",
      "80 Train Loss 12.618165 Test MSE 5.429947805151255 Test RE 1.1137965998934114\n",
      "81 Train Loss 12.596965 Test MSE 5.416447467505406 Test RE 1.1124111364746592\n",
      "82 Train Loss 12.579676 Test MSE 5.382418195577682 Test RE 1.1089112239535903\n",
      "83 Train Loss 12.562902 Test MSE 5.396585239912076 Test RE 1.1103696456080425\n",
      "84 Train Loss 12.532524 Test MSE 5.380988199485353 Test RE 1.1087639068929516\n",
      "85 Train Loss 12.514576 Test MSE 5.378591708139073 Test RE 1.1085169783620374\n",
      "86 Train Loss 12.50056 Test MSE 5.377633455127045 Test RE 1.1084182269501837\n",
      "87 Train Loss 12.467269 Test MSE 5.383572303842296 Test RE 1.10903010499968\n",
      "88 Train Loss 12.431421 Test MSE 5.365518904036808 Test RE 1.1071690194305221\n",
      "89 Train Loss 12.4026165 Test MSE 5.354554921551961 Test RE 1.10603723799962\n",
      "90 Train Loss 12.378214 Test MSE 5.344200902099398 Test RE 1.1049673570562388\n",
      "91 Train Loss 12.329042 Test MSE 5.345864763277208 Test RE 1.1051393536974299\n",
      "92 Train Loss 12.297466 Test MSE 5.346766525638187 Test RE 1.1052325594830195\n",
      "93 Train Loss 12.267484 Test MSE 5.3718289165456286 Test RE 1.107819860260959\n",
      "94 Train Loss 12.21792 Test MSE 5.38133989858909 Test RE 1.1088001404699732\n",
      "95 Train Loss 12.168184 Test MSE 5.37812504328165 Test RE 1.1084688879726734\n",
      "96 Train Loss 12.138306 Test MSE 5.368531322239492 Test RE 1.1074797804362928\n",
      "97 Train Loss 12.091831 Test MSE 5.394741557780483 Test RE 1.1101799568083746\n",
      "98 Train Loss 12.05324 Test MSE 5.388301220159115 Test RE 1.109517082704983\n",
      "99 Train Loss 11.9898205 Test MSE 5.4227409779063755 Test RE 1.1130572184894687\n",
      "Training time: 97.96\n",
      "KG_stan_tune6\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.816742 Test MSE 8.551398549282013 Test RE 1.397740773531914\n",
      "1 Train Loss 53.570236 Test MSE 8.867773871532664 Test RE 1.423361994032793\n",
      "2 Train Loss 52.231537 Test MSE 9.295724831098287 Test RE 1.457302433039503\n",
      "3 Train Loss 47.650574 Test MSE 9.012351934721014 Test RE 1.4349181589064393\n",
      "4 Train Loss 45.768883 Test MSE 8.539318174988919 Test RE 1.3967531456499265\n",
      "5 Train Loss 45.133698 Test MSE 8.66586345829142 Test RE 1.4070644197292121\n",
      "6 Train Loss 44.861877 Test MSE 8.586162823299226 Test RE 1.4005790319769111\n",
      "7 Train Loss 44.709724 Test MSE 8.657711499513704 Test RE 1.4064024528057302\n",
      "8 Train Loss 44.45417 Test MSE 8.53528402102234 Test RE 1.3964231788554804\n",
      "9 Train Loss 44.146366 Test MSE 8.512015154870458 Test RE 1.3945184174026655\n",
      "10 Train Loss 44.020653 Test MSE 8.462379090445392 Test RE 1.3904465490930842\n",
      "11 Train Loss 43.924454 Test MSE 8.441165963509041 Test RE 1.3887026998349468\n",
      "12 Train Loss 43.736465 Test MSE 8.472177217529113 Test RE 1.391251277324433\n",
      "13 Train Loss 43.501854 Test MSE 8.51371149386132 Test RE 1.394657365588033\n",
      "14 Train Loss 43.161583 Test MSE 8.581985221094241 Test RE 1.4002382642757145\n",
      "15 Train Loss 42.853752 Test MSE 8.278193871351606 Test RE 1.3752316439105912\n",
      "16 Train Loss 42.50003 Test MSE 8.454378640441384 Test RE 1.3897891199903138\n",
      "17 Train Loss 41.100666 Test MSE 8.218080014318934 Test RE 1.3702292780912222\n",
      "18 Train Loss 40.155495 Test MSE 8.171929541242253 Test RE 1.3663764463184849\n",
      "19 Train Loss 39.32381 Test MSE 7.837856317024436 Test RE 1.338155887380151\n",
      "20 Train Loss 38.86164 Test MSE 8.01487614435717 Test RE 1.3531827971784431\n",
      "21 Train Loss 38.408497 Test MSE 8.139744185978664 Test RE 1.3636830372495157\n",
      "22 Train Loss 38.04172 Test MSE 7.984183902960021 Test RE 1.3505893665632442\n",
      "23 Train Loss 37.76885 Test MSE 8.038813979854535 Test RE 1.3552020496513308\n",
      "24 Train Loss 37.411945 Test MSE 8.190965227709153 Test RE 1.3679669387624254\n",
      "25 Train Loss 37.14518 Test MSE 8.035269120447737 Test RE 1.3549032163616643\n",
      "26 Train Loss 36.863968 Test MSE 7.976868593962295 Test RE 1.3499705028964153\n",
      "27 Train Loss 36.433903 Test MSE 7.984751640852307 Test RE 1.350637384440782\n",
      "28 Train Loss 34.820923 Test MSE 8.30130608012511 Test RE 1.3771500869359843\n",
      "29 Train Loss 34.105614 Test MSE 8.687854283607535 Test RE 1.4088485986894295\n",
      "30 Train Loss 33.111473 Test MSE 8.443578898248985 Test RE 1.3889011682440393\n",
      "31 Train Loss 32.654152 Test MSE 8.358541443140632 Test RE 1.381889478964373\n",
      "32 Train Loss 32.180717 Test MSE 8.360953298946523 Test RE 1.3820888365790982\n",
      "33 Train Loss 31.868233 Test MSE 8.224887655208844 Test RE 1.3707966915182161\n",
      "34 Train Loss 31.678429 Test MSE 8.14412636440288 Test RE 1.3640500695637046\n",
      "35 Train Loss 31.235142 Test MSE 8.105311447460158 Test RE 1.3607956550855422\n",
      "36 Train Loss 30.990776 Test MSE 7.8694929498219786 Test RE 1.3408538261311242\n",
      "37 Train Loss 30.876404 Test MSE 7.881172895061976 Test RE 1.3418485085458371\n",
      "38 Train Loss 30.5572 Test MSE 7.892076930440128 Test RE 1.3427764482325537\n",
      "39 Train Loss 30.249815 Test MSE 7.7041423529413855 Test RE 1.32669230355166\n",
      "40 Train Loss 30.165646 Test MSE 7.847265804496068 Test RE 1.338958886553401\n",
      "41 Train Loss 30.032377 Test MSE 7.913323590333346 Test RE 1.3445827115980187\n",
      "42 Train Loss 29.818794 Test MSE 7.954791522429073 Test RE 1.3481010948176357\n",
      "43 Train Loss 29.689323 Test MSE 7.927497459503433 Test RE 1.3457863407053434\n",
      "44 Train Loss 29.529318 Test MSE 7.916632553493997 Test RE 1.3448638014333447\n",
      "45 Train Loss 29.232445 Test MSE 7.945060487478621 Test RE 1.3472762816717314\n",
      "46 Train Loss 29.088413 Test MSE 7.855474216988085 Test RE 1.3396589937302952\n",
      "47 Train Loss 28.832043 Test MSE 7.771643485508833 Test RE 1.3324916466009804\n",
      "48 Train Loss 28.621681 Test MSE 7.540492611293188 Test RE 1.3125260135571928\n",
      "49 Train Loss 28.259144 Test MSE 7.481668070694231 Test RE 1.3073963812311977\n",
      "50 Train Loss 27.930458 Test MSE 7.532677434289742 Test RE 1.3118456679321502\n",
      "51 Train Loss 27.64999 Test MSE 7.539418843223591 Test RE 1.3124325582106389\n",
      "52 Train Loss 26.778076 Test MSE 7.277150209822966 Test RE 1.289403159303962\n",
      "53 Train Loss 26.079466 Test MSE 7.1594725952346066 Test RE 1.2789353037505728\n",
      "54 Train Loss 24.670383 Test MSE 6.828679204832013 Test RE 1.2490401987733868\n",
      "55 Train Loss 22.48943 Test MSE 6.433061280527846 Test RE 1.212318980001669\n",
      "56 Train Loss 21.30782 Test MSE 6.314937740704901 Test RE 1.2011371427753037\n",
      "57 Train Loss 20.09893 Test MSE 6.144412181545034 Test RE 1.1848086904358508\n",
      "58 Train Loss 19.759426 Test MSE 6.1336613366075765 Test RE 1.183771709941738\n",
      "59 Train Loss 19.250298 Test MSE 6.18584207189467 Test RE 1.188796380931654\n",
      "60 Train Loss 18.700153 Test MSE 6.215738404690635 Test RE 1.1916656599284607\n",
      "61 Train Loss 18.534435 Test MSE 6.263482110411549 Test RE 1.1962335563978883\n",
      "62 Train Loss 18.38881 Test MSE 6.257475502273426 Test RE 1.195659831625349\n",
      "63 Train Loss 18.087826 Test MSE 6.231525527594991 Test RE 1.1931780338866254\n",
      "64 Train Loss 17.797764 Test MSE 6.101114625676045 Test RE 1.180626841063651\n",
      "65 Train Loss 17.635221 Test MSE 6.055185987317945 Test RE 1.1761746202879082\n",
      "66 Train Loss 17.485426 Test MSE 6.001843626807337 Test RE 1.170982482711971\n",
      "67 Train Loss 17.353645 Test MSE 5.926830736394889 Test RE 1.1636418242562718\n",
      "68 Train Loss 17.168766 Test MSE 5.896791071387478 Test RE 1.1606891656668519\n",
      "69 Train Loss 17.006824 Test MSE 5.927153527978105 Test RE 1.163673511399819\n",
      "70 Train Loss 16.74746 Test MSE 5.9882309923704105 Test RE 1.1696537905554534\n",
      "71 Train Loss 16.503387 Test MSE 5.851724834739863 Test RE 1.1562453744163153\n",
      "72 Train Loss 16.413376 Test MSE 5.903170765701173 Test RE 1.1613168664156464\n",
      "73 Train Loss 16.176613 Test MSE 5.8886899604899146 Test RE 1.1598916044839218\n",
      "74 Train Loss 15.847807 Test MSE 5.9205414487800665 Test RE 1.1630242580577277\n",
      "75 Train Loss 15.70125 Test MSE 5.872573705719245 Test RE 1.158303312677397\n",
      "76 Train Loss 15.566385 Test MSE 5.8040910399257175 Test RE 1.1515297651598904\n",
      "77 Train Loss 15.415932 Test MSE 5.789943072934447 Test RE 1.150125432829487\n",
      "78 Train Loss 15.246128 Test MSE 5.699408975415824 Test RE 1.14109807117525\n",
      "79 Train Loss 15.103289 Test MSE 5.735034774752234 Test RE 1.144658896628078\n",
      "80 Train Loss 14.982154 Test MSE 5.839240228932922 Test RE 1.1550112959412977\n",
      "81 Train Loss 14.783297 Test MSE 5.7325269647807895 Test RE 1.144408601643996\n",
      "82 Train Loss 14.621212 Test MSE 5.6610736957231955 Test RE 1.1372539778298272\n",
      "83 Train Loss 14.538555 Test MSE 5.62821363838782 Test RE 1.1339485431762006\n",
      "84 Train Loss 14.411207 Test MSE 5.568016913875584 Test RE 1.1278681512185358\n",
      "85 Train Loss 14.26902 Test MSE 5.513671120273885 Test RE 1.1223504606308399\n",
      "86 Train Loss 14.150774 Test MSE 5.571810239349635 Test RE 1.1282522774363362\n",
      "87 Train Loss 14.065855 Test MSE 5.542357295588233 Test RE 1.1252663195217156\n",
      "88 Train Loss 14.004686 Test MSE 5.570082635893125 Test RE 1.128077350117851\n",
      "89 Train Loss 13.889432 Test MSE 5.58159265696043 Test RE 1.129242278378266\n",
      "90 Train Loss 13.79531 Test MSE 5.56705597091933 Test RE 1.12777082179782\n",
      "91 Train Loss 13.716398 Test MSE 5.540127030004457 Test RE 1.125039891024381\n",
      "92 Train Loss 13.644019 Test MSE 5.565755863312106 Test RE 1.1276391266032462\n",
      "93 Train Loss 13.585798 Test MSE 5.503172427011502 Test RE 1.1212814063226957\n",
      "94 Train Loss 13.504061 Test MSE 5.527585415583437 Test RE 1.1237657495771394\n",
      "95 Train Loss 13.430314 Test MSE 5.579622905620775 Test RE 1.1290430052582168\n",
      "96 Train Loss 13.358494 Test MSE 5.5441792660960685 Test RE 1.1254512619092552\n",
      "97 Train Loss 13.300829 Test MSE 5.520412779499336 Test RE 1.1230364094897523\n",
      "98 Train Loss 13.1723 Test MSE 5.4982464789523675 Test RE 1.1207794585278872\n",
      "99 Train Loss 13.017437 Test MSE 5.489839689366259 Test RE 1.1199222978422567\n",
      "Training time: 100.68\n",
      "KG_stan_tune6\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.86338 Test MSE 8.741111643227235 Test RE 1.4131601880362956\n",
      "1 Train Loss 51.618866 Test MSE 7.709984373003836 Test RE 1.3271952209401694\n",
      "2 Train Loss 46.280674 Test MSE 8.612408341470198 Test RE 1.402717989482294\n",
      "3 Train Loss 43.603256 Test MSE 8.55471372700827 Test RE 1.398011683023488\n",
      "4 Train Loss 37.874695 Test MSE 7.747796287952474 Test RE 1.3304457083584844\n",
      "5 Train Loss 34.03215 Test MSE 7.369196919997484 Test RE 1.2975321909859214\n",
      "6 Train Loss 31.105034 Test MSE 6.233703347317902 Test RE 1.193386514109269\n",
      "7 Train Loss 29.714962 Test MSE 6.485044954618011 Test RE 1.2172073209246\n",
      "8 Train Loss 26.65147 Test MSE 6.473410105375474 Test RE 1.2161149320886224\n",
      "9 Train Loss 25.408081 Test MSE 6.133001772471673 Test RE 1.1837080616318003\n",
      "10 Train Loss 24.076956 Test MSE 6.507057841423368 Test RE 1.2192714197874768\n",
      "11 Train Loss 23.228895 Test MSE 6.2945251474246735 Test RE 1.1991942756794576\n",
      "12 Train Loss 22.563911 Test MSE 6.139289272329439 Test RE 1.1843146697830271\n",
      "13 Train Loss 21.939463 Test MSE 5.861030102898089 Test RE 1.1571643256421469\n",
      "14 Train Loss 20.284992 Test MSE 6.038712743341942 Test RE 1.1745736284055064\n",
      "15 Train Loss 18.62698 Test MSE 5.823563576884182 Test RE 1.15345982018123\n",
      "16 Train Loss 16.907297 Test MSE 5.773236893022189 Test RE 1.1484649603294963\n",
      "17 Train Loss 15.256478 Test MSE 5.7513011823435045 Test RE 1.146281058033276\n",
      "18 Train Loss 14.175833 Test MSE 5.842204863422218 Test RE 1.1553044635176457\n",
      "19 Train Loss 13.329433 Test MSE 6.034459689730256 Test RE 1.1741599305928037\n",
      "20 Train Loss 12.586893 Test MSE 6.1063388371883915 Test RE 1.1811322015543664\n",
      "21 Train Loss 11.814838 Test MSE 6.196769488287578 Test RE 1.18984593416851\n",
      "22 Train Loss 10.910752 Test MSE 6.158192907956963 Test RE 1.186136594498474\n",
      "23 Train Loss 10.110548 Test MSE 6.006423634280928 Test RE 1.1714291859334063\n",
      "24 Train Loss 9.314555 Test MSE 5.820496022082071 Test RE 1.1531559884092053\n",
      "25 Train Loss 8.417601 Test MSE 5.718009168471831 Test RE 1.1429585584550603\n",
      "26 Train Loss 8.101852 Test MSE 5.5879894020173735 Test RE 1.1298891731794483\n",
      "27 Train Loss 7.80865 Test MSE 5.363199315413554 Test RE 1.1069296712582313\n",
      "28 Train Loss 7.6204567 Test MSE 5.153694972914544 Test RE 1.0850941339271118\n",
      "29 Train Loss 7.3644524 Test MSE 4.839623011193383 Test RE 1.051511015811734\n",
      "30 Train Loss 7.1375837 Test MSE 4.655482003402571 Test RE 1.0313127486626934\n",
      "31 Train Loss 6.696786 Test MSE 4.218816961717867 Test RE 0.9817556334449852\n",
      "32 Train Loss 6.126419 Test MSE 3.942355887768877 Test RE 0.9490431822613187\n",
      "33 Train Loss 4.660281 Test MSE 3.340255449616459 Test RE 0.8735703816620495\n",
      "34 Train Loss 3.8273144 Test MSE 3.0917690253497665 Test RE 0.8404494188898722\n",
      "35 Train Loss 2.6007154 Test MSE 2.3518424184958273 Test RE 0.7330138319783549\n",
      "36 Train Loss 1.9405391 Test MSE 1.093980420918084 Test RE 0.49993418570877085\n",
      "37 Train Loss 1.3054994 Test MSE 0.7230892730000312 Test RE 0.4064470911007444\n",
      "38 Train Loss 0.9964917 Test MSE 0.5663400525008068 Test RE 0.3597051855045828\n",
      "39 Train Loss 0.70123607 Test MSE 0.3946325210127281 Test RE 0.300264850690644\n",
      "40 Train Loss 0.5077618 Test MSE 0.23735182100610874 Test RE 0.2328650675898799\n",
      "41 Train Loss 0.39518943 Test MSE 0.15274867239616013 Test RE 0.18680856417194389\n",
      "42 Train Loss 0.26119193 Test MSE 0.11464821446586562 Test RE 0.16184217562939576\n",
      "43 Train Loss 0.19929424 Test MSE 0.08742318941647052 Test RE 0.14132577755757866\n",
      "44 Train Loss 0.15668899 Test MSE 0.0565166733160739 Test RE 0.11363087620498433\n",
      "45 Train Loss 0.12277503 Test MSE 0.04382444500002885 Test RE 0.10006133035243994\n",
      "46 Train Loss 0.10158002 Test MSE 0.03296269479339961 Test RE 0.08677995386696179\n",
      "47 Train Loss 0.08224306 Test MSE 0.0308238747371177 Test RE 0.08391733355333239\n",
      "48 Train Loss 0.0700514 Test MSE 0.0229499395888315 Test RE 0.07241004770810429\n",
      "49 Train Loss 0.061115112 Test MSE 0.0194071531835451 Test RE 0.0665869277074616\n",
      "50 Train Loss 0.05066847 Test MSE 0.014428742769728808 Test RE 0.05741459501620367\n",
      "51 Train Loss 0.039380018 Test MSE 0.011741165680642639 Test RE 0.051792117640065284\n",
      "52 Train Loss 0.03510522 Test MSE 0.011826103652172364 Test RE 0.051979117387561856\n",
      "53 Train Loss 0.030405307 Test MSE 0.010524433601161717 Test RE 0.04903514078286559\n",
      "54 Train Loss 0.025925122 Test MSE 0.008671202758232044 Test RE 0.044508989141959505\n",
      "55 Train Loss 0.021923695 Test MSE 0.008001240180234948 Test RE 0.042754980616873446\n",
      "56 Train Loss 0.020051803 Test MSE 0.00624894853682557 Test RE 0.03778431335561317\n",
      "57 Train Loss 0.016399913 Test MSE 0.005557981691930697 Test RE 0.035634167428568654\n",
      "58 Train Loss 0.0149321 Test MSE 0.004745000538587614 Test RE 0.032925031058559436\n",
      "59 Train Loss 0.012711935 Test MSE 0.005862341255535812 Test RE 0.03659684175681108\n",
      "60 Train Loss 0.011035645 Test MSE 0.006069091663792904 Test RE 0.03723659049601476\n",
      "61 Train Loss 0.009409613 Test MSE 0.005200749117711314 Test RE 0.034469978483257877\n",
      "62 Train Loss 0.008563321 Test MSE 0.004300530771089481 Test RE 0.03134505888291572\n",
      "63 Train Loss 0.007981821 Test MSE 0.0035909697511481006 Test RE 0.028642698642639044\n",
      "64 Train Loss 0.00694702 Test MSE 0.002575224683804054 Test RE 0.02425580114466624\n",
      "65 Train Loss 0.0056308904 Test MSE 0.002233789698512915 Test RE 0.022590674714934353\n",
      "66 Train Loss 0.0052804765 Test MSE 0.001984328900535803 Test RE 0.02129192310723508\n",
      "67 Train Loss 0.004783176 Test MSE 0.0017970294984202553 Test RE 0.020262156403875305\n",
      "68 Train Loss 0.0045005498 Test MSE 0.001793095481144985 Test RE 0.020239965519704108\n",
      "69 Train Loss 0.004067763 Test MSE 0.002140860549773646 Test RE 0.022115779434119506\n",
      "70 Train Loss 0.003624879 Test MSE 0.0021107189306761327 Test RE 0.02195954123760631\n",
      "71 Train Loss 0.0030435831 Test MSE 0.002161840925651423 Test RE 0.022223882250846684\n",
      "72 Train Loss 0.0028968225 Test MSE 0.0021466901337387875 Test RE 0.022145869704577752\n",
      "73 Train Loss 0.002538164 Test MSE 0.001836848943849049 Test RE 0.020485415720294053\n",
      "74 Train Loss 0.0022827974 Test MSE 0.0014773770764992832 Test RE 0.018371885848407807\n",
      "75 Train Loss 0.0021982421 Test MSE 0.0013453740106792033 Test RE 0.01753192391526262\n",
      "76 Train Loss 0.0021240765 Test MSE 0.001211468277841711 Test RE 0.016636581182860925\n",
      "77 Train Loss 0.0019668918 Test MSE 0.0010247087887692093 Test RE 0.015300593982189862\n",
      "78 Train Loss 0.0019291397 Test MSE 0.0010615535635125648 Test RE 0.015573241433093386\n",
      "79 Train Loss 0.0018687345 Test MSE 0.0009853235614395621 Test RE 0.015003669682289833\n",
      "80 Train Loss 0.001755338 Test MSE 0.0009648186321412998 Test RE 0.014846733096126637\n",
      "81 Train Loss 0.0016721381 Test MSE 0.0008732051942385792 Test RE 0.01412427665209313\n",
      "82 Train Loss 0.0016199201 Test MSE 0.0008210255586014846 Test RE 0.013695768255798263\n",
      "83 Train Loss 0.0014992156 Test MSE 0.000882935528783014 Test RE 0.014202753733738178\n",
      "84 Train Loss 0.0013988758 Test MSE 0.0009305827447176776 Test RE 0.01458094117889291\n",
      "85 Train Loss 0.0013186868 Test MSE 0.0009467810912577305 Test RE 0.014707296508797542\n",
      "86 Train Loss 0.0012192935 Test MSE 0.0008520548346534257 Test RE 0.013952172361833843\n",
      "87 Train Loss 0.0010857779 Test MSE 0.0007234583149056327 Test RE 0.012856265022655173\n",
      "88 Train Loss 0.0010629051 Test MSE 0.0007458819408271895 Test RE 0.013053984911687683\n",
      "89 Train Loss 0.0010349229 Test MSE 0.0007363801817111443 Test RE 0.012970571323415335\n",
      "90 Train Loss 0.00095919264 Test MSE 0.0007142536413294069 Test RE 0.012774217072133718\n",
      "91 Train Loss 0.00090028765 Test MSE 0.0007055077650311407 Test RE 0.012695767465614006\n",
      "92 Train Loss 0.00085708 Test MSE 0.0007026652554851514 Test RE 0.01267016585983866\n",
      "93 Train Loss 0.00084691145 Test MSE 0.0007002687807788888 Test RE 0.012648541291620602\n",
      "94 Train Loss 0.0008164221 Test MSE 0.0006881611307106002 Test RE 0.012538717844590553\n",
      "95 Train Loss 0.00077167724 Test MSE 0.0006930275365904837 Test RE 0.012582974191367153\n",
      "96 Train Loss 0.00074527226 Test MSE 0.0006799314937825837 Test RE 0.012463517825359342\n",
      "97 Train Loss 0.00072834955 Test MSE 0.0006355781556376745 Test RE 0.012050152454154172\n",
      "98 Train Loss 0.00071865105 Test MSE 0.0006091738953457537 Test RE 0.011797193490098857\n",
      "99 Train Loss 0.0006968528 Test MSE 0.0005404511881017915 Test RE 0.011111848159137712\n",
      "Training time: 94.26\n",
      "KG_stan_tune6\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.22517 Test MSE 8.558689997568216 Test RE 1.3983365464308248\n",
      "1 Train Loss 51.752228 Test MSE 9.760788965382963 Test RE 1.493311885927575\n",
      "2 Train Loss 47.857384 Test MSE 8.761687440052707 Test RE 1.4148224369069886\n",
      "3 Train Loss 46.23365 Test MSE 8.666737981761472 Test RE 1.4071354155291045\n",
      "4 Train Loss 44.48398 Test MSE 8.834683725663536 Test RE 1.420703870548785\n",
      "5 Train Loss 44.085266 Test MSE 8.794013180639489 Test RE 1.4174299869191076\n",
      "6 Train Loss 43.13775 Test MSE 8.509282569617234 Test RE 1.3942945605208366\n",
      "7 Train Loss 42.548645 Test MSE 8.425822391789545 Test RE 1.3874399980264447\n",
      "8 Train Loss 42.42443 Test MSE 8.442943586116145 Test RE 1.3888489153798877\n",
      "9 Train Loss 42.258793 Test MSE 8.302487497946354 Test RE 1.3772480794540614\n",
      "10 Train Loss 42.13305 Test MSE 8.219287625321885 Test RE 1.3703299490001504\n",
      "11 Train Loss 41.99302 Test MSE 8.266787932073104 Test RE 1.3742839000134381\n",
      "12 Train Loss 41.925713 Test MSE 8.384897026009131 Test RE 1.3840664041155994\n",
      "13 Train Loss 41.870155 Test MSE 8.388219579174924 Test RE 1.384340598225036\n",
      "14 Train Loss 41.77576 Test MSE 8.16618100145588 Test RE 1.3658957733542807\n",
      "15 Train Loss 41.55457 Test MSE 8.22251722604086 Test RE 1.3705991441017569\n",
      "16 Train Loss 41.412308 Test MSE 8.410657991417175 Test RE 1.3861909110093626\n",
      "17 Train Loss 40.99065 Test MSE 8.347490373430782 Test RE 1.3809756587672317\n",
      "18 Train Loss 40.85775 Test MSE 8.214150828229938 Test RE 1.3699016754460995\n",
      "19 Train Loss 40.70816 Test MSE 8.273864965830793 Test RE 1.3748720228125042\n",
      "20 Train Loss 40.367767 Test MSE 8.253029932114728 Test RE 1.373139847982249\n",
      "21 Train Loss 39.15264 Test MSE 8.134214737638262 Test RE 1.3632197735554263\n",
      "22 Train Loss 38.17746 Test MSE 7.827318481170604 Test RE 1.3372560233470565\n",
      "23 Train Loss 37.573235 Test MSE 7.829712880513039 Test RE 1.337460542948411\n",
      "24 Train Loss 37.108173 Test MSE 7.889016848843419 Test RE 1.3425160982689994\n",
      "25 Train Loss 36.4171 Test MSE 8.046647748779753 Test RE 1.3558622063984878\n",
      "26 Train Loss 35.6958 Test MSE 8.018851107637182 Test RE 1.3535183098607615\n",
      "27 Train Loss 35.184395 Test MSE 8.05247451510172 Test RE 1.3563530233702843\n",
      "28 Train Loss 34.642586 Test MSE 8.036105446498484 Test RE 1.354973724975363\n",
      "29 Train Loss 34.12625 Test MSE 8.082844816475797 Test RE 1.3589083920878025\n",
      "30 Train Loss 33.174244 Test MSE 8.178572764885505 Test RE 1.366931719111892\n",
      "31 Train Loss 31.908237 Test MSE 8.333904689278837 Test RE 1.379851420333535\n",
      "32 Train Loss 30.980019 Test MSE 8.53569117134333 Test RE 1.3964564845641114\n",
      "33 Train Loss 30.60653 Test MSE 8.291074656902778 Test RE 1.3763011512689276\n",
      "34 Train Loss 30.335775 Test MSE 8.335034934082655 Test RE 1.379944984939944\n",
      "35 Train Loss 30.107922 Test MSE 8.21333401018816 Test RE 1.3698335620010091\n",
      "36 Train Loss 29.721975 Test MSE 8.103077572114783 Test RE 1.3606081201979006\n",
      "37 Train Loss 29.35371 Test MSE 7.797216750572562 Test RE 1.3346821855471405\n",
      "38 Train Loss 29.102047 Test MSE 7.89196858308173 Test RE 1.342767230964292\n",
      "39 Train Loss 28.754112 Test MSE 7.8973376492633145 Test RE 1.3432239091868592\n",
      "40 Train Loss 28.263784 Test MSE 7.739788990277487 Test RE 1.3297580270890472\n",
      "41 Train Loss 27.94664 Test MSE 7.735892784218006 Test RE 1.329423285180507\n",
      "42 Train Loss 27.671574 Test MSE 7.734105704474765 Test RE 1.3292697203164596\n",
      "43 Train Loss 27.375248 Test MSE 7.665676188045333 Test RE 1.3233761248828637\n",
      "44 Train Loss 26.943546 Test MSE 7.731132275725716 Test RE 1.3290141724279312\n",
      "45 Train Loss 26.643686 Test MSE 7.68218838353845 Test RE 1.3248006626504958\n",
      "46 Train Loss 25.944584 Test MSE 7.842879843292694 Test RE 1.338584651585426\n",
      "47 Train Loss 25.404966 Test MSE 7.976290122108169 Test RE 1.3499215529802318\n",
      "48 Train Loss 24.770144 Test MSE 8.032213581370836 Test RE 1.3546455801016208\n",
      "49 Train Loss 23.98427 Test MSE 7.867714912512408 Test RE 1.3407023409702958\n",
      "50 Train Loss 23.327057 Test MSE 7.804698458770295 Test RE 1.3353223696479053\n",
      "51 Train Loss 21.966568 Test MSE 7.444561621422386 Test RE 1.3041502375682332\n",
      "52 Train Loss 21.40514 Test MSE 7.075639463469122 Test RE 1.2714254722875393\n",
      "53 Train Loss 20.652248 Test MSE 6.628232511875493 Test RE 1.2305717124487314\n",
      "54 Train Loss 19.527134 Test MSE 6.074261407743487 Test RE 1.1780257924370903\n",
      "55 Train Loss 18.630234 Test MSE 6.00196355848413 Test RE 1.1709941822163072\n",
      "56 Train Loss 17.773571 Test MSE 5.96191399732564 Test RE 1.1670807712950428\n",
      "57 Train Loss 16.772394 Test MSE 5.8636537511812925 Test RE 1.1574232948386043\n",
      "58 Train Loss 16.142805 Test MSE 5.873042024247202 Test RE 1.1583494972052704\n",
      "59 Train Loss 15.696729 Test MSE 5.821527916816603 Test RE 1.1532582033108947\n",
      "60 Train Loss 15.444105 Test MSE 5.848352227459379 Test RE 1.155912128774025\n",
      "61 Train Loss 15.056646 Test MSE 5.8608757515336585 Test RE 1.1571490884683615\n",
      "62 Train Loss 14.869964 Test MSE 5.8609962096328685 Test RE 1.1571609798024736\n",
      "63 Train Loss 14.658588 Test MSE 5.832885469829858 Test RE 1.1543826339663963\n",
      "64 Train Loss 14.54491 Test MSE 5.783641271196568 Test RE 1.1494993614168596\n",
      "65 Train Loss 14.257484 Test MSE 5.693280304677004 Test RE 1.1404843851391404\n",
      "66 Train Loss 14.158623 Test MSE 5.700466166955391 Test RE 1.141203898226329\n",
      "67 Train Loss 13.982536 Test MSE 5.713032068958306 Test RE 1.1424610201741712\n",
      "68 Train Loss 13.86028 Test MSE 5.742196592854085 Test RE 1.1453733893376294\n",
      "69 Train Loss 13.764622 Test MSE 5.762178836656718 Test RE 1.147364548409349\n",
      "70 Train Loss 13.647022 Test MSE 5.777561346362792 Test RE 1.1488950096706354\n",
      "71 Train Loss 13.537622 Test MSE 5.768593665362632 Test RE 1.1480030308256226\n",
      "72 Train Loss 13.457373 Test MSE 5.80218814709673 Test RE 1.1513409830277512\n",
      "73 Train Loss 13.389069 Test MSE 5.807611233671495 Test RE 1.1518789148721664\n",
      "74 Train Loss 13.292959 Test MSE 5.787713219340181 Test RE 1.14990394029755\n",
      "75 Train Loss 13.220383 Test MSE 5.783955739953432 Test RE 1.149530611342707\n",
      "76 Train Loss 13.115561 Test MSE 5.8150949923226225 Test RE 1.152620838543744\n",
      "77 Train Loss 13.037731 Test MSE 5.795297485771797 Test RE 1.1506571153701934\n",
      "78 Train Loss 12.980139 Test MSE 5.799999335514192 Test RE 1.1511237971896615\n",
      "79 Train Loss 12.895734 Test MSE 5.85932641497965 Test RE 1.1569961307913434\n",
      "80 Train Loss 12.805426 Test MSE 5.833768852300388 Test RE 1.1544700454869008\n",
      "81 Train Loss 12.735243 Test MSE 5.806869065571139 Test RE 1.1518053118824465\n",
      "82 Train Loss 12.645439 Test MSE 5.821584353428185 Test RE 1.1532637934092727\n",
      "83 Train Loss 12.572813 Test MSE 5.83117804379481 Test RE 1.154213663802622\n",
      "84 Train Loss 12.493198 Test MSE 5.852078451008991 Test RE 1.1562803095004424\n",
      "85 Train Loss 12.428732 Test MSE 5.891186254227487 Test RE 1.1601374251486347\n",
      "86 Train Loss 12.356615 Test MSE 5.931851518667586 Test RE 1.1641345965078822\n",
      "87 Train Loss 12.307224 Test MSE 5.954310491772829 Test RE 1.1663363177302593\n",
      "88 Train Loss 12.255735 Test MSE 5.953248223449421 Test RE 1.1662322739967215\n",
      "89 Train Loss 12.182843 Test MSE 6.002043080250953 Test RE 1.1710019396124465\n",
      "90 Train Loss 12.089398 Test MSE 6.050063023243528 Test RE 1.175676966265458\n",
      "91 Train Loss 12.000792 Test MSE 5.972333701620072 Test RE 1.1681001861882876\n",
      "92 Train Loss 11.944107 Test MSE 5.947090274865398 Test RE 1.165628951557813\n",
      "93 Train Loss 11.75906 Test MSE 5.7537173923607865 Test RE 1.1465218178939225\n",
      "94 Train Loss 11.403292 Test MSE 5.693317012032128 Test RE 1.1404880617627757\n",
      "95 Train Loss 10.194332 Test MSE 4.862460679868331 Test RE 1.0539890804074925\n",
      "96 Train Loss 9.1668215 Test MSE 4.659757850483345 Test RE 1.0317862467378833\n",
      "97 Train Loss 8.763767 Test MSE 4.44734823502272 Test RE 1.0079955821218556\n",
      "98 Train Loss 8.532787 Test MSE 4.339736770965947 Test RE 0.9957257864398498\n",
      "99 Train Loss 8.275102 Test MSE 4.335536451926185 Test RE 0.9952438011615982\n",
      "Training time: 96.65\n",
      "KG_stan_tune6\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.764954 Test MSE 8.559530021096908 Test RE 1.3984051671414457\n",
      "1 Train Loss 51.396145 Test MSE 8.369689337178459 Test RE 1.3828106937777842\n",
      "2 Train Loss 45.76683 Test MSE 8.14004491443899 Test RE 1.3637082281217976\n",
      "3 Train Loss 45.09812 Test MSE 8.356873238184498 Test RE 1.3817515727323473\n",
      "4 Train Loss 44.728485 Test MSE 8.20043370538848 Test RE 1.3687573720658595\n",
      "5 Train Loss 44.44046 Test MSE 8.139010181986748 Test RE 1.3636215505899594\n",
      "6 Train Loss 44.308437 Test MSE 8.22834172757779 Test RE 1.3710844969069298\n",
      "7 Train Loss 43.74849 Test MSE 8.340442109478982 Test RE 1.3803925172468383\n",
      "8 Train Loss 43.5293 Test MSE 8.398757335362893 Test RE 1.38520986880888\n",
      "9 Train Loss 43.376747 Test MSE 8.468911492530403 Test RE 1.3909831123723861\n",
      "10 Train Loss 43.19081 Test MSE 8.344913455037261 Test RE 1.3807624847410211\n",
      "11 Train Loss 42.744423 Test MSE 8.185876554173827 Test RE 1.3675419449759636\n",
      "12 Train Loss 42.3797 Test MSE 8.403363228164972 Test RE 1.385589642472463\n",
      "13 Train Loss 40.870895 Test MSE 8.92484861406714 Test RE 1.4279351667088958\n",
      "14 Train Loss 40.18174 Test MSE 8.671340243681133 Test RE 1.4075089785841375\n",
      "15 Train Loss 39.976665 Test MSE 8.729295605269245 Test RE 1.4122047259680082\n",
      "16 Train Loss 39.54135 Test MSE 8.595044239286686 Test RE 1.4013032151893212\n",
      "17 Train Loss 38.435474 Test MSE 8.371120075303374 Test RE 1.382928879492728\n",
      "18 Train Loss 37.497047 Test MSE 8.295678184164132 Test RE 1.3766831862221582\n",
      "19 Train Loss 36.2336 Test MSE 7.852340282202026 Test RE 1.339391739161895\n",
      "20 Train Loss 35.177414 Test MSE 7.757303916788466 Test RE 1.3312617794869874\n",
      "21 Train Loss 34.035988 Test MSE 7.682939922054808 Test RE 1.3248654628301746\n",
      "22 Train Loss 33.148262 Test MSE 7.824346337937203 Test RE 1.3370021117541326\n",
      "23 Train Loss 32.01645 Test MSE 7.956672062694396 Test RE 1.3482604332849628\n",
      "24 Train Loss 30.498459 Test MSE 6.9700601023130675 Test RE 1.261904013930078\n",
      "25 Train Loss 27.26662 Test MSE 6.570508322805875 Test RE 1.2252015714259048\n",
      "26 Train Loss 24.282356 Test MSE 6.624808282620883 Test RE 1.2302538068825644\n",
      "27 Train Loss 21.764147 Test MSE 6.334413301666982 Test RE 1.2029878982562838\n",
      "28 Train Loss 20.042152 Test MSE 5.687766905213222 Test RE 1.1399320261547254\n",
      "29 Train Loss 17.823252 Test MSE 4.62713078028828 Test RE 1.0281676791312813\n",
      "30 Train Loss 14.809572 Test MSE 2.815167989943277 Test RE 0.80197386969622\n",
      "31 Train Loss 11.642933 Test MSE 2.12479391900333 Test RE 0.6967331391861332\n",
      "32 Train Loss 9.563716 Test MSE 2.1409386379213746 Test RE 0.699375106964204\n",
      "33 Train Loss 8.736605 Test MSE 1.9254714647461708 Test RE 0.6632489997416633\n",
      "34 Train Loss 7.966917 Test MSE 1.905699915960234 Test RE 0.6598349534218975\n",
      "35 Train Loss 7.148591 Test MSE 1.9727795507719779 Test RE 0.6713474428485737\n",
      "36 Train Loss 6.681818 Test MSE 2.1047334649085774 Test RE 0.69343636559405\n",
      "37 Train Loss 5.9129705 Test MSE 2.079506653643527 Test RE 0.6892681603640838\n",
      "38 Train Loss 5.6507907 Test MSE 2.080780477698414 Test RE 0.6894792373386437\n",
      "39 Train Loss 5.4619083 Test MSE 2.0540842959205228 Test RE 0.6850419881287865\n",
      "40 Train Loss 5.2689652 Test MSE 2.070161642086366 Test RE 0.6877176792192348\n",
      "41 Train Loss 5.2043047 Test MSE 2.077327235325646 Test RE 0.6889068733605146\n",
      "42 Train Loss 5.121402 Test MSE 2.053129306970575 Test RE 0.6848827240745409\n",
      "43 Train Loss 5.049083 Test MSE 2.0911998639472733 Test RE 0.6912033451205744\n",
      "44 Train Loss 4.9999866 Test MSE 2.082073612490549 Test RE 0.6896934480926453\n",
      "45 Train Loss 4.977107 Test MSE 2.114544493500963 Test RE 0.6950506826263267\n",
      "46 Train Loss 4.911045 Test MSE 2.0983262813444665 Test RE 0.6923800892017887\n",
      "47 Train Loss 4.885624 Test MSE 2.1084496601053724 Test RE 0.694048274049408\n",
      "48 Train Loss 4.8640866 Test MSE 2.1225806351024046 Test RE 0.6963701698628164\n",
      "49 Train Loss 4.8499203 Test MSE 2.111425743989771 Test RE 0.6945379270762633\n",
      "50 Train Loss 4.81703 Test MSE 2.117151290944438 Test RE 0.6954789777699671\n",
      "51 Train Loss 4.785381 Test MSE 2.12398360037711 Test RE 0.6966002722590063\n",
      "52 Train Loss 4.768868 Test MSE 2.1284270997098447 Test RE 0.6973285560427299\n",
      "53 Train Loss 4.751152 Test MSE 2.1134361723412365 Test RE 0.694868506193238\n",
      "54 Train Loss 4.722526 Test MSE 2.1421493697387994 Test RE 0.6995728323917353\n",
      "55 Train Loss 4.6954894 Test MSE 2.117087259991547 Test RE 0.695468460685391\n",
      "56 Train Loss 4.6769915 Test MSE 2.092681930893445 Test RE 0.6914482351975445\n",
      "57 Train Loss 4.6320605 Test MSE 2.0921453503791496 Test RE 0.6913595830640783\n",
      "58 Train Loss 4.615989 Test MSE 2.0956532450784247 Test RE 0.6919389407265466\n",
      "59 Train Loss 4.5367594 Test MSE 2.033256629981929 Test RE 0.6815601013623835\n",
      "60 Train Loss 3.5980923 Test MSE 1.7425937596758838 Test RE 0.6309662613258428\n",
      "61 Train Loss 2.0303326 Test MSE 1.2553814818319293 Test RE 0.535544938770267\n",
      "62 Train Loss 1.3143069 Test MSE 0.6570252154127942 Test RE 0.38743520303746154\n",
      "63 Train Loss 0.8734353 Test MSE 0.3687389285663485 Test RE 0.2902468766561075\n",
      "64 Train Loss 0.5967926 Test MSE 0.2545284589040055 Test RE 0.24114387436485038\n",
      "65 Train Loss 0.4104406 Test MSE 0.13852895669372714 Test RE 0.1779009806182954\n",
      "66 Train Loss 0.33460262 Test MSE 0.059713465860011694 Test RE 0.1168003649587672\n",
      "67 Train Loss 0.242773 Test MSE 0.042466741244421936 Test RE 0.09849916031938277\n",
      "68 Train Loss 0.18238124 Test MSE 0.03768303078972303 Test RE 0.09278568383569635\n",
      "69 Train Loss 0.14112976 Test MSE 0.0408097356402872 Test RE 0.09655837560001318\n",
      "70 Train Loss 0.1109845 Test MSE 0.024665020654869363 Test RE 0.07506695541944791\n",
      "71 Train Loss 0.09424804 Test MSE 0.022904118755228124 Test RE 0.0723377262434409\n",
      "72 Train Loss 0.08043982 Test MSE 0.020727558198758052 Test RE 0.06881484434957892\n",
      "73 Train Loss 0.07538425 Test MSE 0.017127171005714436 Test RE 0.0625533938254433\n",
      "74 Train Loss 0.07004805 Test MSE 0.01444942493330004 Test RE 0.057455729328578634\n",
      "75 Train Loss 0.06689056 Test MSE 0.012576394027707473 Test RE 0.053602633622350286\n",
      "76 Train Loss 0.055786535 Test MSE 0.011865935027985934 Test RE 0.05206657896521662\n",
      "77 Train Loss 0.05208791 Test MSE 0.011723937750046248 Test RE 0.0517541061434928\n",
      "78 Train Loss 0.050483502 Test MSE 0.011759255200567243 Test RE 0.05183200013473003\n",
      "79 Train Loss 0.047059495 Test MSE 0.011376785769728037 Test RE 0.05098211524687723\n",
      "80 Train Loss 0.04495847 Test MSE 0.010669813409979368 Test RE 0.04937265394540816\n",
      "81 Train Loss 0.04394681 Test MSE 0.00990510424302671 Test RE 0.04757048568752716\n",
      "82 Train Loss 0.040306196 Test MSE 0.008955809997132875 Test RE 0.045233531531129474\n",
      "83 Train Loss 0.038731813 Test MSE 0.008613591024638316 Test RE 0.044360883191325966\n",
      "84 Train Loss 0.03769184 Test MSE 0.008500266829779035 Test RE 0.04406810135874025\n",
      "85 Train Loss 0.03497287 Test MSE 0.007783509271420461 Test RE 0.04216924095640023\n",
      "86 Train Loss 0.03309437 Test MSE 0.007892648009940308 Test RE 0.04246385593110401\n",
      "87 Train Loss 0.030446447 Test MSE 0.006308736532717265 Test RE 0.03796463734021323\n",
      "88 Train Loss 0.029275777 Test MSE 0.005940368668809052 Test RE 0.03683958758670014\n",
      "89 Train Loss 0.027920837 Test MSE 0.006624389971610616 Test RE 0.03890281301791346\n",
      "90 Train Loss 0.0259498 Test MSE 0.006929108676989614 Test RE 0.03978750871323766\n",
      "91 Train Loss 0.02429736 Test MSE 0.006068131036744255 Test RE 0.037233643441201794\n",
      "92 Train Loss 0.023544455 Test MSE 0.005247401022080474 Test RE 0.0346242351061043\n",
      "93 Train Loss 0.022508543 Test MSE 0.004665602370411129 Test RE 0.03264840143510429\n",
      "94 Train Loss 0.021195678 Test MSE 0.005183800733961462 Test RE 0.034413766661803846\n",
      "95 Train Loss 0.020527022 Test MSE 0.005080378248743467 Test RE 0.03406874096983965\n",
      "96 Train Loss 0.020068916 Test MSE 0.00533641371145818 Test RE 0.034916669002351124\n",
      "97 Train Loss 0.019542187 Test MSE 0.00586078604495012 Test RE 0.036591987077724986\n",
      "98 Train Loss 0.018176755 Test MSE 0.00534087557348215 Test RE 0.03493126314891806\n",
      "99 Train Loss 0.016519427 Test MSE 0.004830759432428285 Test RE 0.033221234405640475\n",
      "Training time: 95.59\n",
      "KG_stan_tune6\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.5457 Test MSE 8.515418128629497 Test RE 1.3947971431388042\n",
      "1 Train Loss 53.203773 Test MSE 8.428813227774413 Test RE 1.3876862195291428\n",
      "2 Train Loss 45.705544 Test MSE 8.404920474209575 Test RE 1.3857180198839014\n",
      "3 Train Loss 43.739876 Test MSE 7.873220992642961 Test RE 1.3411713922457655\n",
      "4 Train Loss 42.66263 Test MSE 8.11750070411503 Test RE 1.3618184940054923\n",
      "5 Train Loss 42.08654 Test MSE 8.177426635935516 Test RE 1.3668359362074245\n",
      "6 Train Loss 41.240997 Test MSE 7.9155460490015095 Test RE 1.3447715115177408\n",
      "7 Train Loss 40.38356 Test MSE 8.077337723559891 Test RE 1.3584453799867442\n",
      "8 Train Loss 38.87809 Test MSE 8.102816342554043 Test RE 1.360586188165096\n",
      "9 Train Loss 37.687782 Test MSE 7.941062049943207 Test RE 1.346937223334744\n",
      "10 Train Loss 37.07994 Test MSE 7.482603270638455 Test RE 1.307478090203404\n",
      "11 Train Loss 36.19384 Test MSE 7.377080579013452 Test RE 1.2982260635388487\n",
      "12 Train Loss 33.915165 Test MSE 6.850980474548811 Test RE 1.2510781094768992\n",
      "13 Train Loss 32.31311 Test MSE 5.987817690350985 Test RE 1.1696134256617252\n",
      "14 Train Loss 28.514154 Test MSE 5.10553741854315 Test RE 1.080012524893021\n",
      "15 Train Loss 26.50773 Test MSE 4.628112495592932 Test RE 1.0282767439558789\n",
      "16 Train Loss 24.536957 Test MSE 4.9405252285996575 Test RE 1.062416045006034\n",
      "17 Train Loss 22.576885 Test MSE 4.7481105407371755 Test RE 1.0415220549894395\n",
      "18 Train Loss 21.077763 Test MSE 4.654135204903516 Test RE 1.0311635620768207\n",
      "19 Train Loss 20.097841 Test MSE 4.606497545846608 Test RE 1.025872722664967\n",
      "20 Train Loss 19.170254 Test MSE 4.3934909733673875 Test RE 1.0018735923555466\n",
      "21 Train Loss 18.523209 Test MSE 4.4041588584281275 Test RE 1.003089185197568\n",
      "22 Train Loss 17.864815 Test MSE 4.0748061621217815 Test RE 0.9648538572829517\n",
      "23 Train Loss 17.30189 Test MSE 3.8242382740963543 Test RE 0.9347178409475727\n",
      "24 Train Loss 16.645994 Test MSE 3.286495857176789 Test RE 0.8665120466641114\n",
      "25 Train Loss 16.007992 Test MSE 3.621138544709166 Test RE 0.9095584876787752\n",
      "26 Train Loss 15.353394 Test MSE 3.114722274137631 Test RE 0.8435633922541803\n",
      "27 Train Loss 14.513401 Test MSE 2.899209437462995 Test RE 0.8138565351107914\n",
      "28 Train Loss 13.584372 Test MSE 2.3100523106394433 Test RE 0.7264721461067816\n",
      "29 Train Loss 9.386127 Test MSE 1.1722707159942511 Test RE 0.5175138991608137\n",
      "30 Train Loss 6.2337623 Test MSE 0.8683329375194054 Test RE 0.4454010102474548\n",
      "31 Train Loss 5.4370127 Test MSE 0.6580321869769219 Test RE 0.38773198530305086\n",
      "32 Train Loss 4.112916 Test MSE 0.4971812180953963 Test RE 0.3370275608490147\n",
      "33 Train Loss 3.312221 Test MSE 0.4161056043961399 Test RE 0.30832578286542045\n",
      "34 Train Loss 2.9356666 Test MSE 0.3187119240144166 Test RE 0.26984055183314726\n",
      "35 Train Loss 2.2004058 Test MSE 0.2591594166505336 Test RE 0.24332770339766638\n",
      "36 Train Loss 1.8828986 Test MSE 0.14745208748623945 Test RE 0.18354118144543893\n",
      "37 Train Loss 1.5344284 Test MSE 0.11173430076848194 Test RE 0.15977223779957006\n",
      "38 Train Loss 1.3525676 Test MSE 0.11432905975129876 Test RE 0.16161675262090697\n",
      "39 Train Loss 1.1550033 Test MSE 0.08046983233094994 Test RE 0.1355890470700406\n",
      "40 Train Loss 0.970739 Test MSE 0.07425074577465511 Test RE 0.13024422333108313\n",
      "41 Train Loss 0.78156203 Test MSE 0.060594628381454047 Test RE 0.1176589920121604\n",
      "42 Train Loss 0.6916141 Test MSE 0.07238521546035785 Test RE 0.12859763924056639\n",
      "43 Train Loss 0.62697625 Test MSE 0.06295601735336391 Test RE 0.11992968237535467\n",
      "44 Train Loss 0.58478516 Test MSE 0.06117716578677179 Test RE 0.11822320719597641\n",
      "45 Train Loss 0.5109584 Test MSE 0.0634902790682706 Test RE 0.12043748510223927\n",
      "46 Train Loss 0.46552107 Test MSE 0.06007707375586585 Test RE 0.11715543628923653\n",
      "47 Train Loss 0.417125 Test MSE 0.06129629621929189 Test RE 0.11833825937150172\n",
      "48 Train Loss 0.39826643 Test MSE 0.05416723862560294 Test RE 0.11124395186399687\n",
      "49 Train Loss 0.38260305 Test MSE 0.05516056437729156 Test RE 0.112259320930058\n",
      "50 Train Loss 0.35911322 Test MSE 0.04863991600143842 Test RE 0.10541549888202599\n",
      "51 Train Loss 0.3340649 Test MSE 0.04114632600608859 Test RE 0.09695575478886921\n",
      "52 Train Loss 0.3217549 Test MSE 0.04405867377940512 Test RE 0.10032837321386696\n",
      "53 Train Loss 0.2858132 Test MSE 0.04009408235091147 Test RE 0.0957079908301028\n",
      "54 Train Loss 0.27233347 Test MSE 0.040546126725847294 Test RE 0.09624601280616742\n",
      "55 Train Loss 0.24608918 Test MSE 0.0379392618549664 Test RE 0.093100604056973\n",
      "56 Train Loss 0.23003685 Test MSE 0.045160347526715744 Test RE 0.10157496888112454\n",
      "57 Train Loss 0.21092373 Test MSE 0.03805225910509936 Test RE 0.09323914511141945\n",
      "58 Train Loss 0.20184848 Test MSE 0.037379050584729706 Test RE 0.09241068583268641\n",
      "59 Train Loss 0.1712634 Test MSE 0.0271987798810017 Test RE 0.07882841084856014\n",
      "60 Train Loss 0.1657885 Test MSE 0.026264414857078085 Test RE 0.07746257418847424\n",
      "61 Train Loss 0.15593131 Test MSE 0.02958254166391995 Test RE 0.08221021854157179\n",
      "62 Train Loss 0.14619546 Test MSE 0.028747281279207407 Test RE 0.08104130941453372\n",
      "63 Train Loss 0.14069192 Test MSE 0.02767313267869024 Test RE 0.07951283218025056\n",
      "64 Train Loss 0.13465087 Test MSE 0.02742180841452908 Test RE 0.07915094537362086\n",
      "65 Train Loss 0.12898102 Test MSE 0.024461665585556194 Test RE 0.0747568636347843\n",
      "66 Train Loss 0.123219736 Test MSE 0.025470709413898125 Test RE 0.07628314342528432\n",
      "67 Train Loss 0.11723798 Test MSE 0.022676613605732355 Test RE 0.07197756664232932\n",
      "68 Train Loss 0.10953225 Test MSE 0.020867970407210105 Test RE 0.06904753301422978\n",
      "69 Train Loss 0.10500923 Test MSE 0.01858779503314468 Test RE 0.06516614009358801\n",
      "70 Train Loss 0.09849393 Test MSE 0.016417315830994365 Test RE 0.06124337796627025\n",
      "71 Train Loss 0.09478925 Test MSE 0.016833746649010415 Test RE 0.06201524354882606\n",
      "72 Train Loss 0.09306904 Test MSE 0.015821481724177838 Test RE 0.06012175330364498\n",
      "73 Train Loss 0.08683334 Test MSE 0.015219533028715848 Test RE 0.05896695801747528\n",
      "74 Train Loss 0.08289495 Test MSE 0.014087942042201257 Test RE 0.05673248910716265\n",
      "75 Train Loss 0.078253016 Test MSE 0.012381346861016931 Test RE 0.053185348031623954\n",
      "76 Train Loss 0.07432051 Test MSE 0.012083783105958224 Test RE 0.05254235337976243\n",
      "77 Train Loss 0.07249303 Test MSE 0.010963858390818896 Test RE 0.05004835056228887\n",
      "78 Train Loss 0.069142975 Test MSE 0.007991551532905128 Test RE 0.04272908691821491\n",
      "79 Train Loss 0.06246242 Test MSE 0.007050836468123667 Test RE 0.04013547261034946\n",
      "80 Train Loss 0.058250893 Test MSE 0.0070300733510992525 Test RE 0.04007633410097138\n",
      "81 Train Loss 0.053334575 Test MSE 0.006208838555498005 Test RE 0.03766285549339665\n",
      "82 Train Loss 0.051824406 Test MSE 0.005175127998841138 Test RE 0.03438496671003775\n",
      "83 Train Loss 0.051089674 Test MSE 0.0054219318900472135 Test RE 0.035195333851059926\n",
      "84 Train Loss 0.049922332 Test MSE 0.006122504146156552 Test RE 0.03740008629157116\n",
      "85 Train Loss 0.047985125 Test MSE 0.005772242799573019 Test RE 0.03631452397326315\n",
      "86 Train Loss 0.043204915 Test MSE 0.006097406684673022 Test RE 0.03732335207395224\n",
      "87 Train Loss 0.041458037 Test MSE 0.005876347777014539 Test RE 0.036640534934641276\n",
      "88 Train Loss 0.03921963 Test MSE 0.0054655076698202415 Test RE 0.03533648233601681\n",
      "89 Train Loss 0.037827767 Test MSE 0.0055437965230192 Test RE 0.035588665333954085\n",
      "90 Train Loss 0.03631604 Test MSE 0.005269905705170432 Test RE 0.034698402657743925\n",
      "91 Train Loss 0.03504375 Test MSE 0.0047680415477653944 Test RE 0.033004873750090945\n",
      "92 Train Loss 0.03329048 Test MSE 0.004525755505592325 Test RE 0.03215537690571772\n",
      "93 Train Loss 0.03119816 Test MSE 0.00537809533917368 Test RE 0.03505276721330177\n",
      "94 Train Loss 0.02861059 Test MSE 0.005238361085930319 Test RE 0.034594397878614055\n",
      "95 Train Loss 0.027610566 Test MSE 0.005088309054224527 Test RE 0.03409532237574261\n",
      "96 Train Loss 0.026974387 Test MSE 0.0056384316062647755 Test RE 0.035891137171796844\n",
      "97 Train Loss 0.026635159 Test MSE 0.005741464484511657 Test RE 0.03621757779366371\n",
      "98 Train Loss 0.026221555 Test MSE 0.0056632552178184975 Test RE 0.0359700570955019\n",
      "99 Train Loss 0.025301568 Test MSE 0.006119300122683543 Test RE 0.03739029892082835\n",
      "Training time: 93.55\n",
      "KG_stan_tune6\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.03296 Test MSE 8.348110029924355 Test RE 1.3810269145708287\n",
      "1 Train Loss 56.03665 Test MSE 8.344433637259057 Test RE 1.380722788468864\n",
      "2 Train Loss 47.74968 Test MSE 8.18317218205883 Test RE 1.367316028558592\n",
      "3 Train Loss 46.688965 Test MSE 8.67203680093199 Test RE 1.4075655091128187\n",
      "4 Train Loss 46.250034 Test MSE 8.543984501644562 Test RE 1.3971347227349629\n",
      "5 Train Loss 45.79045 Test MSE 8.397726180122483 Test RE 1.385124831808597\n",
      "6 Train Loss 45.639565 Test MSE 8.191256406643353 Test RE 1.3679912533336793\n",
      "7 Train Loss 45.151634 Test MSE 8.41268397291319 Test RE 1.3863578556191272\n",
      "8 Train Loss 44.8266 Test MSE 8.334688032195006 Test RE 1.3799162681736132\n",
      "9 Train Loss 44.554775 Test MSE 8.314928333363227 Test RE 1.3782795596491872\n",
      "10 Train Loss 44.23018 Test MSE 8.379975606199126 Test RE 1.3836601634912071\n",
      "11 Train Loss 43.986656 Test MSE 8.43422312132625 Test RE 1.3881314797523885\n",
      "12 Train Loss 43.692497 Test MSE 8.385531450717497 Test RE 1.3841187642884847\n",
      "13 Train Loss 43.503677 Test MSE 8.153439647978356 Test RE 1.3648297821280762\n",
      "14 Train Loss 43.225918 Test MSE 8.302267307346455 Test RE 1.3772298163075285\n",
      "15 Train Loss 42.082462 Test MSE 8.386614504821479 Test RE 1.3842081460477562\n",
      "16 Train Loss 41.14185 Test MSE 8.530386007891854 Test RE 1.3960224493320708\n",
      "17 Train Loss 40.078445 Test MSE 8.515503832023986 Test RE 1.394804162086506\n",
      "18 Train Loss 39.044533 Test MSE 8.75481158500852 Test RE 1.4142671772396493\n",
      "19 Train Loss 38.06292 Test MSE 8.943449744356283 Test RE 1.4294224402719338\n",
      "20 Train Loss 37.019154 Test MSE 8.786675550090889 Test RE 1.416838519303748\n",
      "21 Train Loss 36.43296 Test MSE 8.693389845146651 Test RE 1.4092973588775473\n",
      "22 Train Loss 35.75567 Test MSE 8.680994506708855 Test RE 1.4082922878204565\n",
      "23 Train Loss 33.506657 Test MSE 8.239580157399775 Test RE 1.3720205044024798\n",
      "24 Train Loss 31.593256 Test MSE 7.695044980068968 Test RE 1.3259087653496349\n",
      "25 Train Loss 30.544472 Test MSE 8.001923508791025 Test RE 1.3520889330695993\n",
      "26 Train Loss 29.898945 Test MSE 7.917460713798238 Test RE 1.3449341428115271\n",
      "27 Train Loss 29.126392 Test MSE 8.009568808873736 Test RE 1.352734693910235\n",
      "28 Train Loss 28.886612 Test MSE 7.823841935283852 Test RE 1.3369590156121254\n",
      "29 Train Loss 28.499659 Test MSE 7.794823509839597 Test RE 1.3344773393169933\n",
      "30 Train Loss 28.281096 Test MSE 7.779666762262322 Test RE 1.3331792869578414\n",
      "31 Train Loss 27.964647 Test MSE 8.075685353167348 Test RE 1.3583064251843777\n",
      "32 Train Loss 27.316227 Test MSE 7.670649048236402 Test RE 1.3238053040796345\n",
      "33 Train Loss 26.864199 Test MSE 7.485158574266336 Test RE 1.307701322559682\n",
      "34 Train Loss 26.412878 Test MSE 7.4356072742724235 Test RE 1.3033656831377538\n",
      "35 Train Loss 26.02433 Test MSE 7.25932612935303 Test RE 1.287823109758139\n",
      "36 Train Loss 25.557251 Test MSE 7.140733813743422 Test RE 1.2772605022180208\n",
      "37 Train Loss 25.259247 Test MSE 7.070035337546633 Test RE 1.2709218683451655\n",
      "38 Train Loss 24.685629 Test MSE 6.47435620595456 Test RE 1.216203797538707\n",
      "39 Train Loss 23.019596 Test MSE 6.173931817565369 Test RE 1.1876513719710862\n",
      "40 Train Loss 22.180069 Test MSE 6.189956122521358 Test RE 1.1891916347650966\n",
      "41 Train Loss 21.3252 Test MSE 5.954205066531051 Test RE 1.1663259922834466\n",
      "42 Train Loss 20.863594 Test MSE 5.9183604130608165 Test RE 1.1628100182686005\n",
      "43 Train Loss 20.47429 Test MSE 6.144815217016899 Test RE 1.1848475478631504\n",
      "44 Train Loss 19.95729 Test MSE 6.048474331138579 Test RE 1.1755225950349986\n",
      "45 Train Loss 19.62187 Test MSE 5.95843964761325 Test RE 1.1667406592384009\n",
      "46 Train Loss 19.351934 Test MSE 6.011579475402018 Test RE 1.1719318483818992\n",
      "47 Train Loss 19.103973 Test MSE 6.065400701653016 Test RE 1.1771662682086819\n",
      "48 Train Loss 18.635841 Test MSE 5.944562761536097 Test RE 1.1653812290859742\n",
      "49 Train Loss 18.107407 Test MSE 5.960974895977683 Test RE 1.166988850287019\n",
      "50 Train Loss 17.734634 Test MSE 6.033552598244186 Test RE 1.1740716782422145\n",
      "51 Train Loss 17.269363 Test MSE 6.129935685472044 Test RE 1.1834121375676174\n",
      "52 Train Loss 16.93108 Test MSE 6.041935785117736 Test RE 1.1748870391466195\n",
      "53 Train Loss 16.658354 Test MSE 6.134344026679473 Test RE 1.1838375863134087\n",
      "54 Train Loss 16.508455 Test MSE 6.0450847045898115 Test RE 1.1751931614633848\n",
      "55 Train Loss 16.250128 Test MSE 6.081787092276323 Test RE 1.1787553219745652\n",
      "56 Train Loss 16.014442 Test MSE 6.088221930891556 Test RE 1.1793787485146916\n",
      "57 Train Loss 15.795286 Test MSE 6.072095256105114 Test RE 1.1778157249187236\n",
      "58 Train Loss 15.635666 Test MSE 6.031436945231463 Test RE 1.1738658172650316\n",
      "59 Train Loss 15.369202 Test MSE 6.032025923330347 Test RE 1.1739231306702715\n",
      "60 Train Loss 15.247444 Test MSE 6.102629695745924 Test RE 1.1807734225874038\n",
      "61 Train Loss 15.020228 Test MSE 6.060583815735924 Test RE 1.1766987474199349\n",
      "62 Train Loss 14.927155 Test MSE 6.075276145572959 Test RE 1.1781241860800085\n",
      "63 Train Loss 14.761554 Test MSE 6.074253996489976 Test RE 1.1780250737776625\n",
      "64 Train Loss 14.641273 Test MSE 6.052736956143846 Test RE 1.1759367432325274\n",
      "65 Train Loss 14.535492 Test MSE 6.035755133043941 Test RE 1.1742859548008735\n",
      "66 Train Loss 14.392883 Test MSE 5.996243231808149 Test RE 1.1704360260403281\n",
      "67 Train Loss 14.300188 Test MSE 6.002272819533769 Test RE 1.1710243505288525\n",
      "68 Train Loss 14.217525 Test MSE 6.028168352100376 Test RE 1.173547699895112\n",
      "69 Train Loss 14.080732 Test MSE 6.04513737055694 Test RE 1.1751982807092376\n",
      "70 Train Loss 13.937145 Test MSE 5.894004917676318 Test RE 1.1604149283345395\n",
      "71 Train Loss 13.39322 Test MSE 5.158418480478532 Test RE 1.085591279810688\n",
      "72 Train Loss 12.432991 Test MSE 4.641501845534428 Test RE 1.0297630965147127\n",
      "73 Train Loss 11.45167 Test MSE 4.172608746115066 Test RE 0.9763643020298873\n",
      "74 Train Loss 10.809679 Test MSE 3.8180618851238903 Test RE 0.9339627214375583\n",
      "75 Train Loss 10.259335 Test MSE 3.44903114290849 Test RE 0.8876803743279863\n",
      "76 Train Loss 9.917968 Test MSE 3.29672971634624 Test RE 0.8678601192022498\n",
      "77 Train Loss 9.50387 Test MSE 3.2763382952046474 Test RE 0.8651719474316901\n",
      "78 Train Loss 9.376171 Test MSE 3.2435428750398443 Test RE 0.8608309673301978\n",
      "79 Train Loss 9.276669 Test MSE 3.263901698922449 Test RE 0.863528340543528\n",
      "80 Train Loss 9.192591 Test MSE 3.3172706612198626 Test RE 0.8705596102740032\n",
      "81 Train Loss 9.111051 Test MSE 3.2891478338692974 Test RE 0.8668615840532231\n",
      "82 Train Loss 9.034357 Test MSE 3.304977409879253 Test RE 0.8689450387529831\n",
      "83 Train Loss 8.958431 Test MSE 3.2460499556374987 Test RE 0.8611635906102096\n",
      "84 Train Loss 8.906679 Test MSE 3.2352293794273628 Test RE 0.8597270654655427\n",
      "85 Train Loss 8.841296 Test MSE 3.2699037022820363 Test RE 0.864321948922812\n",
      "86 Train Loss 8.734885 Test MSE 3.3374550626440356 Test RE 0.8732041150538719\n",
      "87 Train Loss 8.660784 Test MSE 3.3311899557477744 Test RE 0.8723841359297544\n",
      "88 Train Loss 8.59132 Test MSE 3.313722026389121 Test RE 0.8700938471356259\n",
      "89 Train Loss 8.51972 Test MSE 3.291922243388187 Test RE 0.8672271076177843\n",
      "90 Train Loss 8.473858 Test MSE 3.3195471441535926 Test RE 0.8708582705897702\n",
      "91 Train Loss 8.369336 Test MSE 3.259606409081071 Test RE 0.8629599524686453\n",
      "92 Train Loss 8.233093 Test MSE 3.2226039265407227 Test RE 0.8580478871381969\n",
      "93 Train Loss 8.062917 Test MSE 3.3624504027493023 Test RE 0.8764678774251637\n",
      "94 Train Loss 7.7535524 Test MSE 3.366491661157146 Test RE 0.8769944234139534\n",
      "95 Train Loss 7.356405 Test MSE 3.316389867550777 Test RE 0.8704440281619324\n",
      "96 Train Loss 7.099084 Test MSE 3.2234890564832632 Test RE 0.8581657160354161\n",
      "97 Train Loss 6.725976 Test MSE 3.179109979296933 Test RE 0.8522378854181178\n",
      "98 Train Loss 6.483323 Test MSE 3.123675091941051 Test RE 0.8447748726851545\n",
      "99 Train Loss 6.004076 Test MSE 2.8762410096115594 Test RE 0.8106263139370252\n",
      "Training time: 95.74\n",
      "KG_stan_tune6\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.436966 Test MSE 8.740005799987866 Test RE 1.4130707953404587\n",
      "1 Train Loss 53.880356 Test MSE 9.728653889461338 Test RE 1.4908516722519691\n",
      "2 Train Loss 46.688988 Test MSE 8.170404907262098 Test RE 1.3662489781896372\n",
      "3 Train Loss 43.473686 Test MSE 8.037313909633234 Test RE 1.3550756010801284\n",
      "4 Train Loss 43.037403 Test MSE 8.094067936300618 Test RE 1.3598514945239812\n",
      "5 Train Loss 42.71643 Test MSE 8.275834180214254 Test RE 1.3750356257174892\n",
      "6 Train Loss 42.31195 Test MSE 8.312011199858876 Test RE 1.3780377669347854\n",
      "7 Train Loss 41.65441 Test MSE 8.202251842232924 Test RE 1.368909098814486\n",
      "8 Train Loss 40.905678 Test MSE 8.32749518050188 Test RE 1.3793207044650144\n",
      "9 Train Loss 39.917755 Test MSE 8.09768731636097 Test RE 1.3601554992179294\n",
      "10 Train Loss 37.79322 Test MSE 7.874576086466757 Test RE 1.3412868046594408\n",
      "11 Train Loss 36.2014 Test MSE 7.538419139114173 Test RE 1.3123455430344553\n",
      "12 Train Loss 34.37042 Test MSE 6.937822084275185 Test RE 1.2589823437597432\n",
      "13 Train Loss 32.149345 Test MSE 6.51907833738433 Test RE 1.2203970809658966\n",
      "14 Train Loss 27.451305 Test MSE 5.967990008104253 Test RE 1.1676753278035044\n",
      "15 Train Loss 20.610523 Test MSE 4.923991194734552 Test RE 1.060636806628103\n",
      "16 Train Loss 15.954474 Test MSE 4.084461201252958 Test RE 0.9659962662269602\n",
      "17 Train Loss 12.1418495 Test MSE 4.375434203655482 Test RE 0.9998126769306271\n",
      "18 Train Loss 10.615227 Test MSE 4.366829990173475 Test RE 0.9988291362472383\n",
      "19 Train Loss 9.600185 Test MSE 4.130442716456421 Test RE 0.9714184820171491\n",
      "20 Train Loss 8.926048 Test MSE 3.9411345914434013 Test RE 0.9488961695658396\n",
      "21 Train Loss 8.20024 Test MSE 3.856009213806836 Test RE 0.9385925263305612\n",
      "22 Train Loss 7.6611366 Test MSE 3.830451065410523 Test RE 0.9354767960399778\n",
      "23 Train Loss 6.754018 Test MSE 3.5627348990586776 Test RE 0.9021937501875689\n",
      "24 Train Loss 5.8300858 Test MSE 2.9748580136073084 Test RE 0.8244060711528867\n",
      "25 Train Loss 5.344595 Test MSE 2.5066276931236158 Test RE 0.7567509537740701\n",
      "26 Train Loss 5.1414557 Test MSE 2.321267890705383 Test RE 0.7282335652690949\n",
      "27 Train Loss 5.015625 Test MSE 2.233964528639818 Test RE 0.7144078151264949\n",
      "28 Train Loss 4.8701696 Test MSE 2.1627568413508986 Test RE 0.7029297228500948\n",
      "29 Train Loss 4.750515 Test MSE 2.142228959551263 Test RE 0.6995858282999933\n",
      "30 Train Loss 4.665584 Test MSE 2.1580271769929693 Test RE 0.7021606948183048\n",
      "31 Train Loss 4.5996194 Test MSE 2.159062843909997 Test RE 0.7023291628945806\n",
      "32 Train Loss 4.4174404 Test MSE 2.111217095840603 Test RE 0.6945036095934787\n",
      "33 Train Loss 4.2654047 Test MSE 2.0785702863761615 Test RE 0.68911295989546\n",
      "34 Train Loss 3.0136735 Test MSE 1.8863383766619972 Test RE 0.6564744990528747\n",
      "35 Train Loss 2.3669138 Test MSE 1.7494709331051894 Test RE 0.6322100944242552\n",
      "36 Train Loss 2.0360878 Test MSE 1.6511383057487512 Test RE 0.6141858218504803\n",
      "37 Train Loss 1.7707436 Test MSE 1.5203373834175387 Test RE 0.5893564590031803\n",
      "38 Train Loss 1.2911643 Test MSE 0.9659147205559246 Test RE 0.46976153462847564\n",
      "39 Train Loss 1.0750955 Test MSE 0.6800526633313981 Test RE 0.3941661570420692\n",
      "40 Train Loss 0.8282882 Test MSE 0.32677257569301466 Test RE 0.2732315595204586\n",
      "41 Train Loss 0.63270015 Test MSE 0.06852240173859263 Test RE 0.12511931229264214\n",
      "42 Train Loss 0.45838436 Test MSE 0.052263225955916814 Test RE 0.10927131432414074\n",
      "43 Train Loss 0.34299406 Test MSE 0.0479871658930826 Test RE 0.1047057690498897\n",
      "44 Train Loss 0.24942708 Test MSE 0.04213978577746512 Test RE 0.098119250479175\n",
      "45 Train Loss 0.19916853 Test MSE 0.03923003548756071 Test RE 0.09467109727219461\n",
      "46 Train Loss 0.15618514 Test MSE 0.03078221002930423 Test RE 0.08386059874091543\n",
      "47 Train Loss 0.12984076 Test MSE 0.022223718328246433 Test RE 0.07125517684731396\n",
      "48 Train Loss 0.11491095 Test MSE 0.0240068555107768 Test RE 0.07405863439005385\n",
      "49 Train Loss 0.10037173 Test MSE 0.02156897465104367 Test RE 0.07019768826925661\n",
      "50 Train Loss 0.088796504 Test MSE 0.019398834561723248 Test RE 0.06657265537101727\n",
      "51 Train Loss 0.07437879 Test MSE 0.015267730776899816 Test RE 0.059060253522958316\n",
      "52 Train Loss 0.060457785 Test MSE 0.013954135033112576 Test RE 0.056462424251127026\n",
      "53 Train Loss 0.053708732 Test MSE 0.011501708459559862 Test RE 0.051261255385031165\n",
      "54 Train Loss 0.046923183 Test MSE 0.010404365183899889 Test RE 0.048754628757609775\n",
      "55 Train Loss 0.04348155 Test MSE 0.009972364864020268 Test RE 0.04773172614183016\n",
      "56 Train Loss 0.036644764 Test MSE 0.009377716307680613 Test RE 0.046286741196968365\n",
      "57 Train Loss 0.03411432 Test MSE 0.009384324063169778 Test RE 0.0463030456787664\n",
      "58 Train Loss 0.027562637 Test MSE 0.007116640590621266 Test RE 0.040322326041335586\n",
      "59 Train Loss 0.024502518 Test MSE 0.006798651919157438 Test RE 0.03941118230288107\n",
      "60 Train Loss 0.023256324 Test MSE 0.0061907174594455355 Test RE 0.037607853988378716\n",
      "61 Train Loss 0.020745382 Test MSE 0.0059942754732615075 Test RE 0.0370063633822397\n",
      "62 Train Loss 0.019624094 Test MSE 0.004972054454397199 Test RE 0.03370357723250279\n",
      "63 Train Loss 0.016977135 Test MSE 0.004883644943042372 Test RE 0.03340258679606681\n",
      "64 Train Loss 0.015245363 Test MSE 0.0034513575668120473 Test RE 0.02808038370556015\n",
      "65 Train Loss 0.012468573 Test MSE 0.003648854464425578 Test RE 0.028872629049851762\n",
      "66 Train Loss 0.010536591 Test MSE 0.0027705774814239647 Test RE 0.025158990452221894\n",
      "67 Train Loss 0.009694208 Test MSE 0.002405423049874033 Test RE 0.023442492968339983\n",
      "68 Train Loss 0.008949959 Test MSE 0.0018057362869723056 Test RE 0.020311183182949936\n",
      "69 Train Loss 0.0073606204 Test MSE 0.0012072714407637577 Test RE 0.016607739488658336\n",
      "70 Train Loss 0.0068118935 Test MSE 0.001417681436455582 Test RE 0.017996886867294504\n",
      "71 Train Loss 0.006441659 Test MSE 0.0012341358312166163 Test RE 0.01679150182756114\n",
      "72 Train Loss 0.0059799952 Test MSE 0.001086577027806287 Test RE 0.01575572237901736\n",
      "73 Train Loss 0.005731741 Test MSE 0.0010695210170232382 Test RE 0.01563157439584122\n",
      "74 Train Loss 0.005345874 Test MSE 0.0009407343062061003 Test RE 0.014660255903780561\n",
      "75 Train Loss 0.004883123 Test MSE 0.0007761553152504892 Test RE 0.013316263436905047\n",
      "76 Train Loss 0.004511454 Test MSE 0.0007345883197763044 Test RE 0.012954780819119018\n",
      "77 Train Loss 0.003878034 Test MSE 0.0008416722711279844 Test RE 0.01386690595136986\n",
      "78 Train Loss 0.0031634942 Test MSE 0.0006078032906477364 Test RE 0.01178391452807105\n",
      "79 Train Loss 0.003031075 Test MSE 0.0005642650881673594 Test RE 0.011354019888774183\n",
      "80 Train Loss 0.0027469594 Test MSE 0.00042200327119021737 Test RE 0.009818970811099127\n",
      "81 Train Loss 0.002622895 Test MSE 0.00040018085868255554 Test RE 0.009561724276778536\n",
      "82 Train Loss 0.0022977723 Test MSE 0.00033577123996453604 Test RE 0.008758501476529984\n",
      "83 Train Loss 0.0022392015 Test MSE 0.0003370749939017351 Test RE 0.008775489035850452\n",
      "84 Train Loss 0.002190461 Test MSE 0.00036036888582546584 Test RE 0.009073643328568925\n",
      "85 Train Loss 0.0021270819 Test MSE 0.0003541097636637968 Test RE 0.008994499687040022\n",
      "86 Train Loss 0.0020192447 Test MSE 0.0003851392606541982 Test RE 0.009380304930770852\n",
      "87 Train Loss 0.0019469694 Test MSE 0.00035121744437574776 Test RE 0.008957691460723293\n",
      "88 Train Loss 0.0018720351 Test MSE 0.0003800353439577192 Test RE 0.009317943110770322\n",
      "89 Train Loss 0.0017331474 Test MSE 0.00037445491295537176 Test RE 0.009249277868435074\n",
      "90 Train Loss 0.0016368141 Test MSE 0.00034071313878593037 Test RE 0.008822720089766648\n",
      "91 Train Loss 0.0015847827 Test MSE 0.00034446592001541895 Test RE 0.008871175904273158\n",
      "92 Train Loss 0.0015581304 Test MSE 0.0003294589301399699 Test RE 0.008675783426329136\n",
      "93 Train Loss 0.0014887124 Test MSE 0.00030327338233447816 Test RE 0.00832386844406156\n",
      "94 Train Loss 0.0013647228 Test MSE 0.0002704705771671518 Test RE 0.007860824025836028\n",
      "95 Train Loss 0.0012842003 Test MSE 0.00030155699576611884 Test RE 0.008300280406591278\n",
      "96 Train Loss 0.0012564508 Test MSE 0.00032497642120787293 Test RE 0.00861656138167183\n",
      "97 Train Loss 0.0012425038 Test MSE 0.00032637966662789065 Test RE 0.008635144462227984\n",
      "98 Train Loss 0.0012237632 Test MSE 0.00034248622958465535 Test RE 0.008845647271639893\n",
      "99 Train Loss 0.0011443832 Test MSE 0.0003707857288079308 Test RE 0.009203850704801717\n",
      "Training time: 92.48\n",
      "KG_stan_tune6\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.055626 Test MSE 7.465561349215642 Test RE 1.3059883252423496\n",
      "1 Train Loss 54.10619 Test MSE 8.463763920480968 Test RE 1.3905603145811205\n",
      "2 Train Loss 49.56267 Test MSE 8.66555488744151 Test RE 1.407039368392374\n",
      "3 Train Loss 42.710022 Test MSE 7.319478365963343 Test RE 1.2931476830664619\n",
      "4 Train Loss 37.7397 Test MSE 8.083444773047978 Test RE 1.3589588242630486\n",
      "5 Train Loss 34.95 Test MSE 7.649632099318407 Test RE 1.321990501175138\n",
      "6 Train Loss 33.61165 Test MSE 7.589177744925363 Test RE 1.3167563534041848\n",
      "7 Train Loss 33.356667 Test MSE 7.433511046296723 Test RE 1.3031819493757169\n",
      "8 Train Loss 32.68675 Test MSE 7.4831345996493175 Test RE 1.307524510458713\n",
      "9 Train Loss 32.034252 Test MSE 7.446147411643762 Test RE 1.304289130808507\n",
      "10 Train Loss 31.456367 Test MSE 7.642471037960562 Test RE 1.3213715778358621\n",
      "11 Train Loss 31.037315 Test MSE 7.915225098109492 Test RE 1.3447442480801541\n",
      "12 Train Loss 30.576302 Test MSE 7.746911721152349 Test RE 1.330369757620239\n",
      "13 Train Loss 30.11401 Test MSE 7.695363276413924 Test RE 1.3259361873823021\n",
      "14 Train Loss 29.672977 Test MSE 7.898864915121701 Test RE 1.3433537859209193\n",
      "15 Train Loss 29.24418 Test MSE 8.062778637412237 Test RE 1.3572205554111274\n",
      "16 Train Loss 28.375072 Test MSE 8.51784345717876 Test RE 1.394995759368972\n",
      "17 Train Loss 27.53669 Test MSE 8.653817285574618 Test RE 1.406086119324279\n",
      "18 Train Loss 26.927078 Test MSE 8.786348372236757 Test RE 1.4168121405841136\n",
      "19 Train Loss 25.806004 Test MSE 8.823174859996536 Test RE 1.4197781996955172\n",
      "20 Train Loss 25.195902 Test MSE 8.955762659073375 Test RE 1.4304060821237055\n",
      "21 Train Loss 24.075836 Test MSE 9.206827302466372 Test RE 1.4503174044981386\n",
      "22 Train Loss 23.377361 Test MSE 9.059991114348161 Test RE 1.4387056400809044\n",
      "23 Train Loss 22.902428 Test MSE 9.16155451862356 Test RE 1.4467471831437673\n",
      "24 Train Loss 22.29184 Test MSE 9.014519845332064 Test RE 1.4350907324629554\n",
      "25 Train Loss 21.467987 Test MSE 8.994596239370402 Test RE 1.4335039591999281\n",
      "26 Train Loss 20.665096 Test MSE 8.773887390506136 Test RE 1.4158071079175316\n",
      "27 Train Loss 19.371418 Test MSE 8.585214858637793 Test RE 1.4005017136157445\n",
      "28 Train Loss 17.679523 Test MSE 8.24410403865912 Test RE 1.3723971016322583\n",
      "29 Train Loss 16.695766 Test MSE 8.24248112195444 Test RE 1.3722620114031234\n",
      "30 Train Loss 15.108475 Test MSE 8.110135502720563 Test RE 1.3612005486551224\n",
      "31 Train Loss 13.73247 Test MSE 7.890354822758196 Test RE 1.3426299385230929\n",
      "32 Train Loss 12.910864 Test MSE 7.755073823242307 Test RE 1.3310704081202156\n",
      "33 Train Loss 12.024282 Test MSE 7.7181838541885215 Test RE 1.327900761960076\n",
      "34 Train Loss 11.189416 Test MSE 7.273622861207597 Test RE 1.28909062447962\n",
      "35 Train Loss 10.467413 Test MSE 7.176265673763967 Test RE 1.2804343444496182\n",
      "36 Train Loss 10.048735 Test MSE 7.065648331564059 Test RE 1.270527499239664\n",
      "37 Train Loss 9.579916 Test MSE 6.9857702808711455 Test RE 1.2633253488011509\n",
      "38 Train Loss 9.323774 Test MSE 6.869628933881189 Test RE 1.2527796779093325\n",
      "39 Train Loss 9.028191 Test MSE 6.765707441089748 Test RE 1.2432677474976699\n",
      "40 Train Loss 7.5053988 Test MSE 5.7455839316302875 Test RE 1.145711169107905\n",
      "41 Train Loss 5.574546 Test MSE 5.241179301904811 Test RE 1.0942651520649003\n",
      "42 Train Loss 4.730263 Test MSE 5.565800618637837 Test RE 1.127643660376933\n",
      "43 Train Loss 4.128181 Test MSE 5.838468354328034 Test RE 1.1549349543868515\n",
      "44 Train Loss 3.7976525 Test MSE 5.750457468553731 Test RE 1.1461969754424781\n",
      "45 Train Loss 3.47056 Test MSE 5.738656968281273 Test RE 1.1450203174168299\n",
      "46 Train Loss 3.2929323 Test MSE 5.683834228146934 Test RE 1.1395378679733559\n",
      "47 Train Loss 3.0034623 Test MSE 5.548492810360004 Test RE 1.1258889948626387\n",
      "48 Train Loss 2.8470879 Test MSE 5.482847591540043 Test RE 1.1192088798149114\n",
      "49 Train Loss 2.6319578 Test MSE 5.372365012031675 Test RE 1.107875137748294\n",
      "50 Train Loss 2.5101233 Test MSE 5.310793139749595 Test RE 1.101508247014129\n",
      "51 Train Loss 2.3797429 Test MSE 5.275966603962388 Test RE 1.097890631575642\n",
      "52 Train Loss 2.3069549 Test MSE 5.320248708208666 Test RE 1.1024883976699629\n",
      "53 Train Loss 2.2502515 Test MSE 5.279173387692886 Test RE 1.0982242351845528\n",
      "54 Train Loss 2.1818354 Test MSE 5.187578854204922 Test RE 1.0886553619147268\n",
      "55 Train Loss 2.095842 Test MSE 5.217210242049213 Test RE 1.091760127779699\n",
      "56 Train Loss 2.062393 Test MSE 5.1653785228785285 Test RE 1.0863234048227828\n",
      "57 Train Loss 2.0145702 Test MSE 5.143998772137339 Test RE 1.0840729011989667\n",
      "58 Train Loss 1.9944652 Test MSE 5.082737742054914 Test RE 1.07759833356165\n",
      "59 Train Loss 1.9524466 Test MSE 5.051300035746213 Test RE 1.0742605883781708\n",
      "60 Train Loss 1.9278432 Test MSE 5.045149030600102 Test RE 1.0736063216376694\n",
      "61 Train Loss 1.8811982 Test MSE 5.053059597335256 Test RE 1.074447675174987\n",
      "62 Train Loss 1.8377128 Test MSE 5.105679392476965 Test RE 1.0800275411927955\n",
      "63 Train Loss 1.8034207 Test MSE 5.102353635494273 Test RE 1.0796757276554647\n",
      "64 Train Loss 1.7733122 Test MSE 5.157130753175364 Test RE 1.085455769984209\n",
      "65 Train Loss 1.7330709 Test MSE 5.225796745466582 Test RE 1.0926581698077151\n",
      "66 Train Loss 1.6797447 Test MSE 5.237745702720021 Test RE 1.0939066560772408\n",
      "67 Train Loss 1.656514 Test MSE 5.231799843132111 Test RE 1.093285581412274\n",
      "68 Train Loss 1.6160508 Test MSE 5.255129703299978 Test RE 1.0957204823208\n",
      "69 Train Loss 1.5913308 Test MSE 5.2587312302635185 Test RE 1.0960958860869046\n",
      "70 Train Loss 1.569232 Test MSE 5.275803086435457 Test RE 1.097873618034294\n",
      "71 Train Loss 1.5304686 Test MSE 5.259976287890571 Test RE 1.0962256342824281\n",
      "72 Train Loss 1.4990093 Test MSE 5.270562754566138 Test RE 1.097328236472473\n",
      "73 Train Loss 1.4714411 Test MSE 5.266911686998919 Test RE 1.0969480955082376\n",
      "74 Train Loss 1.442629 Test MSE 5.272710474157788 Test RE 1.097551790713284\n",
      "75 Train Loss 1.4072102 Test MSE 5.325939381130779 Test RE 1.1030778648576214\n",
      "76 Train Loss 1.3564314 Test MSE 5.40572188529484 Test RE 1.1113091993142796\n",
      "77 Train Loss 1.3153945 Test MSE 5.412741077721542 Test RE 1.1120304686228175\n",
      "78 Train Loss 1.2863567 Test MSE 5.472031848912959 Test RE 1.1181044308352335\n",
      "79 Train Loss 1.2536652 Test MSE 5.555855407374495 Test RE 1.126635748902184\n",
      "80 Train Loss 1.2235535 Test MSE 5.558708752859999 Test RE 1.1269250174444412\n",
      "81 Train Loss 1.2092259 Test MSE 5.604174595398923 Test RE 1.131524309766141\n",
      "82 Train Loss 1.1872463 Test MSE 5.601515328847525 Test RE 1.1312558151163394\n",
      "83 Train Loss 1.1644711 Test MSE 5.675670967459944 Test RE 1.1387192579673773\n",
      "84 Train Loss 1.1500913 Test MSE 5.695552310325189 Test RE 1.140711927817764\n",
      "85 Train Loss 1.1386775 Test MSE 5.719678641440935 Test RE 1.143125399667067\n",
      "86 Train Loss 1.1232698 Test MSE 5.701185055106461 Test RE 1.1412758548060906\n",
      "87 Train Loss 1.107686 Test MSE 5.706131456300335 Test RE 1.1417708382409628\n",
      "88 Train Loss 1.0986362 Test MSE 5.726525039021806 Test RE 1.1438093498384136\n",
      "89 Train Loss 1.0852729 Test MSE 5.756211400402814 Test RE 1.1467702768156516\n",
      "90 Train Loss 1.0754303 Test MSE 5.757361977548909 Test RE 1.1468848818616504\n",
      "91 Train Loss 1.0633008 Test MSE 5.821937551640721 Test RE 1.1532987774022576\n",
      "92 Train Loss 1.0529187 Test MSE 5.824191511240358 Test RE 1.1535220052605593\n",
      "93 Train Loss 1.0387372 Test MSE 5.824727308384707 Test RE 1.1535750632327548\n",
      "94 Train Loss 1.0303197 Test MSE 5.845462048297601 Test RE 1.1556264751519825\n",
      "95 Train Loss 1.0182108 Test MSE 5.872940565735797 Test RE 1.1583394917496006\n",
      "96 Train Loss 1.0049833 Test MSE 5.9058019684890555 Test RE 1.1615756527421879\n",
      "97 Train Loss 0.9943359 Test MSE 5.914935665341922 Test RE 1.1624735308839893\n",
      "98 Train Loss 0.98432255 Test MSE 5.9025093432891405 Test RE 1.1612518045573086\n",
      "99 Train Loss 0.97459376 Test MSE 5.92679013358787 Test RE 1.1636378383819106\n",
      "Training time: 94.68\n",
      "KG_stan_tune6\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.600994 Test MSE 8.857523035081094 Test RE 1.4225390778064049\n",
      "1 Train Loss 47.782528 Test MSE 8.725742670930957 Test RE 1.4119173040763677\n",
      "2 Train Loss 44.9783 Test MSE 8.401895382980404 Test RE 1.3854686242651613\n",
      "3 Train Loss 43.91752 Test MSE 8.54370333519142 Test RE 1.3971117340084303\n",
      "4 Train Loss 43.481125 Test MSE 8.546566558273646 Test RE 1.3973458191186845\n",
      "5 Train Loss 43.32154 Test MSE 8.481461019916825 Test RE 1.3920133344187073\n",
      "6 Train Loss 42.917152 Test MSE 8.393995126696693 Test RE 1.3848170967866582\n",
      "7 Train Loss 42.591194 Test MSE 8.367503561284696 Test RE 1.3826301188771315\n",
      "8 Train Loss 42.14422 Test MSE 8.45128270652157 Test RE 1.3895346311959689\n",
      "9 Train Loss 41.109676 Test MSE 8.384760307100956 Test RE 1.3840551202072588\n",
      "10 Train Loss 39.358673 Test MSE 7.910044621248641 Test RE 1.3443041117214725\n",
      "11 Train Loss 38.575203 Test MSE 7.798550113731173 Test RE 1.3347962993416702\n",
      "12 Train Loss 37.985924 Test MSE 7.803365429113018 Test RE 1.3352083293462225\n",
      "13 Train Loss 37.45981 Test MSE 7.841264801945129 Test RE 1.3384468207815836\n",
      "14 Train Loss 36.58164 Test MSE 7.715487187059649 Test RE 1.3276687631348363\n",
      "15 Train Loss 34.99694 Test MSE 7.295879757725717 Test RE 1.2910613921661023\n",
      "16 Train Loss 34.051876 Test MSE 7.305520690285089 Test RE 1.2919141287101772\n",
      "17 Train Loss 33.219738 Test MSE 7.295873531767882 Test RE 1.2910608413006972\n",
      "18 Train Loss 32.86377 Test MSE 7.2357003581284705 Test RE 1.2857257656311671\n",
      "19 Train Loss 32.220146 Test MSE 7.174347776901556 Test RE 1.280263231420717\n",
      "20 Train Loss 31.488201 Test MSE 7.095550505745459 Test RE 1.2732131285067418\n",
      "21 Train Loss 30.662487 Test MSE 7.059078807526835 Test RE 1.2699367040551799\n",
      "22 Train Loss 30.10097 Test MSE 7.048233295631086 Test RE 1.2689607687880262\n",
      "23 Train Loss 29.039953 Test MSE 6.998158597803335 Test RE 1.2644450207791025\n",
      "24 Train Loss 28.233803 Test MSE 6.754542200164133 Test RE 1.2422414604616514\n",
      "25 Train Loss 26.556463 Test MSE 6.6376986618037295 Test RE 1.2314501231114885\n",
      "26 Train Loss 24.971949 Test MSE 6.580825567236192 Test RE 1.2261631215176192\n",
      "27 Train Loss 23.14312 Test MSE 6.513348063171453 Test RE 1.2198605981231274\n",
      "28 Train Loss 21.214695 Test MSE 6.703474642260419 Test RE 1.2375365820937323\n",
      "29 Train Loss 19.092321 Test MSE 6.550135403112845 Test RE 1.223300629299411\n",
      "30 Train Loss 15.775323 Test MSE 5.714056131698827 Test RE 1.1425634088292043\n",
      "31 Train Loss 13.304667 Test MSE 5.907586743058496 Test RE 1.161751157617738\n",
      "32 Train Loss 12.128992 Test MSE 5.281117683896724 Test RE 1.0984264521310245\n",
      "33 Train Loss 10.917319 Test MSE 4.599801022357536 Test RE 1.0251267894256886\n",
      "34 Train Loss 8.258142 Test MSE 2.649284176684782 Test RE 0.7779869874529586\n",
      "35 Train Loss 5.2925353 Test MSE 1.0018240884863858 Test RE 0.47841390654402993\n",
      "36 Train Loss 3.5319948 Test MSE 0.6617989296305126 Test RE 0.3888401396973643\n",
      "37 Train Loss 2.5770607 Test MSE 0.4685987637014575 Test RE 0.3271964850149949\n",
      "38 Train Loss 1.4326293 Test MSE 0.2669677875303577 Test RE 0.24696618409100024\n",
      "39 Train Loss 0.9311033 Test MSE 0.21921459625015285 Test RE 0.22379109138727635\n",
      "40 Train Loss 0.6281536 Test MSE 0.1143242014545185 Test RE 0.16161331871489854\n",
      "41 Train Loss 0.45035022 Test MSE 0.07818064546042493 Test RE 0.13364652965950685\n",
      "42 Train Loss 0.33474243 Test MSE 0.06754820088116688 Test RE 0.12422670136653599\n",
      "43 Train Loss 0.28547603 Test MSE 0.05497613564952981 Test RE 0.1120714949104084\n",
      "44 Train Loss 0.20342824 Test MSE 0.04625594266779338 Test RE 0.10279969551152296\n",
      "45 Train Loss 0.17370416 Test MSE 0.039075300409602234 Test RE 0.09448420713877584\n",
      "46 Train Loss 0.15219116 Test MSE 0.03277194124760377 Test RE 0.0865284938110531\n",
      "47 Train Loss 0.12484415 Test MSE 0.026727358635040537 Test RE 0.07814228038632218\n",
      "48 Train Loss 0.1150434 Test MSE 0.02495390348421 Test RE 0.075505277107327\n",
      "49 Train Loss 0.094849914 Test MSE 0.02154373801698686 Test RE 0.07015660908257604\n",
      "50 Train Loss 0.08449198 Test MSE 0.018518863247079156 Test RE 0.06504519538877761\n",
      "51 Train Loss 0.07508918 Test MSE 0.015700559075806777 Test RE 0.05989155911887028\n",
      "52 Train Loss 0.0670227 Test MSE 0.01632473245418709 Test RE 0.061070446672343855\n",
      "53 Train Loss 0.055728033 Test MSE 0.014538530210738448 Test RE 0.057632613190570406\n",
      "54 Train Loss 0.050947785 Test MSE 0.015626046796871115 Test RE 0.05974927234112319\n",
      "55 Train Loss 0.04613184 Test MSE 0.01466809008006173 Test RE 0.057888839652508406\n",
      "56 Train Loss 0.03833825 Test MSE 0.01120626209415595 Test RE 0.05059859387921889\n",
      "57 Train Loss 0.03604072 Test MSE 0.01105167023417611 Test RE 0.05024837472499405\n",
      "58 Train Loss 0.031229112 Test MSE 0.00873288818415023 Test RE 0.044667023181075606\n",
      "59 Train Loss 0.028577816 Test MSE 0.007439648565196585 Test RE 0.04122724087240041\n",
      "60 Train Loss 0.02701379 Test MSE 0.007727324392265837 Test RE 0.042016767004901076\n",
      "61 Train Loss 0.024242152 Test MSE 0.007816758299351084 Test RE 0.04225921272097439\n",
      "62 Train Loss 0.023418015 Test MSE 0.007735188764299073 Test RE 0.042038142544438946\n",
      "63 Train Loss 0.02130688 Test MSE 0.006525041309163457 Test RE 0.038609990344740414\n",
      "64 Train Loss 0.020256115 Test MSE 0.00599079090799481 Test RE 0.03699560563221389\n",
      "65 Train Loss 0.017690437 Test MSE 0.0061795313900867375 Test RE 0.03757386162219904\n",
      "66 Train Loss 0.016007219 Test MSE 0.006404495382517752 Test RE 0.03825168041838002\n",
      "67 Train Loss 0.014973638 Test MSE 0.006497734450676019 Test RE 0.038529115537310664\n",
      "68 Train Loss 0.014039541 Test MSE 0.0073456492295241455 Test RE 0.04096596157297168\n",
      "69 Train Loss 0.01337965 Test MSE 0.0074129068021871955 Test RE 0.04115307865881376\n",
      "70 Train Loss 0.012203803 Test MSE 0.006786952221453865 Test RE 0.03937725664600162\n",
      "71 Train Loss 0.011625531 Test MSE 0.005983941778318451 Test RE 0.03697445148338822\n",
      "72 Train Loss 0.0110614505 Test MSE 0.006211261608688436 Test RE 0.037670203904812176\n",
      "73 Train Loss 0.009693588 Test MSE 0.004715032643990907 Test RE 0.03282089443079899\n",
      "74 Train Loss 0.009069027 Test MSE 0.0045042738916162665 Test RE 0.032078972976134636\n",
      "75 Train Loss 0.008833568 Test MSE 0.0043834028100438426 Test RE 0.03164563037293668\n",
      "76 Train Loss 0.008197306 Test MSE 0.004264072542460068 Test RE 0.031211910473128057\n",
      "77 Train Loss 0.007861994 Test MSE 0.00439515835637967 Test RE 0.03168803607987809\n",
      "78 Train Loss 0.0071191126 Test MSE 0.003935763331260525 Test RE 0.029986276956444725\n",
      "79 Train Loss 0.0066827927 Test MSE 0.0034041115209558753 Test RE 0.027887523546951325\n",
      "80 Train Loss 0.0062380997 Test MSE 0.0029665760035738667 Test RE 0.026033694248550163\n",
      "81 Train Loss 0.00581683 Test MSE 0.0027408164368519583 Test RE 0.02502349894018462\n",
      "82 Train Loss 0.0053379126 Test MSE 0.0024589208440113607 Test RE 0.02370174571660278\n",
      "83 Train Loss 0.005097945 Test MSE 0.002481357217633089 Test RE 0.023809633221362106\n",
      "84 Train Loss 0.00475465 Test MSE 0.002440224308233566 Test RE 0.023611465031823573\n",
      "85 Train Loss 0.0046685208 Test MSE 0.0025306787531852383 Test RE 0.024045099011559243\n",
      "86 Train Loss 0.0045945817 Test MSE 0.0024532911212759253 Test RE 0.023674597482172606\n",
      "87 Train Loss 0.0041334373 Test MSE 0.002137356612479481 Test RE 0.022097673621911836\n",
      "88 Train Loss 0.0037865196 Test MSE 0.0019593963472098568 Test RE 0.02115773665724476\n",
      "89 Train Loss 0.0036953741 Test MSE 0.0019193735487815907 Test RE 0.020940536924744773\n",
      "90 Train Loss 0.00360586 Test MSE 0.0018459798083347448 Test RE 0.020536268480526185\n",
      "91 Train Loss 0.0034492451 Test MSE 0.001780858924590496 Test RE 0.020170785860745395\n",
      "92 Train Loss 0.0033312687 Test MSE 0.0016024524240550214 Test RE 0.019133773670965047\n",
      "93 Train Loss 0.003249566 Test MSE 0.0015198358219050024 Test RE 0.018634013187078663\n",
      "94 Train Loss 0.0032070961 Test MSE 0.0014314517326691368 Test RE 0.018084079790649056\n",
      "95 Train Loss 0.0031450468 Test MSE 0.0014826005794610622 Test RE 0.018404335561437044\n",
      "96 Train Loss 0.002933047 Test MSE 0.0012229497190310564 Test RE 0.01671523016394336\n",
      "97 Train Loss 0.0027255486 Test MSE 0.0011283198908874756 Test RE 0.016055512847557886\n",
      "98 Train Loss 0.0026759873 Test MSE 0.0010273759653869358 Test RE 0.01532049371670302\n",
      "99 Train Loss 0.0026183303 Test MSE 0.0009970548929944905 Test RE 0.015092722771248852\n",
      "Training time: 96.90\n",
      "KG_stan_tune7\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.308235 Test MSE 8.107442243601 Test RE 1.360974512345221\n",
      "1 Train Loss 45.563965 Test MSE 9.522182909576149 Test RE 1.4749466778639304\n",
      "2 Train Loss 44.16809 Test MSE 8.649738497651866 Test RE 1.4057547162663204\n",
      "3 Train Loss 43.64161 Test MSE 8.596766963409301 Test RE 1.4014436413368196\n",
      "4 Train Loss 43.054436 Test MSE 8.873099123474804 Test RE 1.4237893066667149\n",
      "5 Train Loss 42.633102 Test MSE 8.469420790020811 Test RE 1.391024936729542\n",
      "6 Train Loss 42.35328 Test MSE 8.609325907421237 Test RE 1.4024669463090573\n",
      "7 Train Loss 42.25398 Test MSE 8.922775565211243 Test RE 1.4277693178856832\n",
      "8 Train Loss 41.87535 Test MSE 8.887094558924414 Test RE 1.4249117273547791\n",
      "9 Train Loss 41.545845 Test MSE 8.995789051415164 Test RE 1.433599007607754\n",
      "10 Train Loss 40.699875 Test MSE 8.874793452362516 Test RE 1.4239252373133027\n",
      "11 Train Loss 39.672993 Test MSE 8.692175357392026 Test RE 1.4091989143008385\n",
      "12 Train Loss 38.58616 Test MSE 8.752389263090729 Test RE 1.4140715106997221\n",
      "13 Train Loss 36.94514 Test MSE 9.665794545607003 Test RE 1.4860274783031167\n",
      "14 Train Loss 34.399704 Test MSE 9.457788711045097 Test RE 1.4699510204272974\n",
      "15 Train Loss 31.63222 Test MSE 9.007674726764785 Test RE 1.434545765458435\n",
      "16 Train Loss 28.883842 Test MSE 8.315228381980983 Test RE 1.378304427400865\n",
      "17 Train Loss 26.575064 Test MSE 8.58172645297069 Test RE 1.4002171537896078\n",
      "18 Train Loss 24.936176 Test MSE 8.458466482045578 Test RE 1.3901250731956636\n",
      "19 Train Loss 23.81977 Test MSE 8.317708559284204 Test RE 1.3785099650202108\n",
      "20 Train Loss 22.181225 Test MSE 8.179910455450464 Test RE 1.3670435024849472\n",
      "21 Train Loss 21.310682 Test MSE 8.57357454801382 Test RE 1.399551952609412\n",
      "22 Train Loss 19.843136 Test MSE 8.36368309641539 Test RE 1.382314439723419\n",
      "23 Train Loss 17.73824 Test MSE 7.862238497311996 Test RE 1.3402356539544742\n",
      "24 Train Loss 15.602604 Test MSE 7.956828784350937 Test RE 1.3482737114850947\n",
      "25 Train Loss 13.342304 Test MSE 7.328648403412497 Test RE 1.2939574744437872\n",
      "26 Train Loss 10.742213 Test MSE 6.482242700855872 Test RE 1.2169443086886351\n",
      "27 Train Loss 9.034911 Test MSE 5.942890141892545 Test RE 1.1652172660875413\n",
      "28 Train Loss 8.160106 Test MSE 5.344688629505348 Test RE 1.1050177771823935\n",
      "29 Train Loss 6.2458997 Test MSE 4.524028306417496 Test RE 1.0166482492095565\n",
      "30 Train Loss 4.765047 Test MSE 4.534086304602245 Test RE 1.0177777480165977\n",
      "31 Train Loss 4.0078025 Test MSE 4.3447149657618525 Test RE 0.9962967307690811\n",
      "32 Train Loss 3.590448 Test MSE 4.437113892608134 Test RE 1.0068351025295883\n",
      "33 Train Loss 3.2980409 Test MSE 4.414241181735179 Test RE 1.004236701475681\n",
      "34 Train Loss 2.99604 Test MSE 4.228211726883218 Test RE 0.982848147603163\n",
      "35 Train Loss 2.7449188 Test MSE 4.146343969388387 Test RE 0.9732865545174979\n",
      "36 Train Loss 2.5177898 Test MSE 3.9845765350721742 Test RE 0.954111535926746\n",
      "37 Train Loss 2.3397245 Test MSE 3.904138008559773 Test RE 0.944431885065511\n",
      "38 Train Loss 2.1606038 Test MSE 3.785577769184985 Test RE 0.929981151564092\n",
      "39 Train Loss 1.9664083 Test MSE 3.898379961966876 Test RE 0.9437351769361926\n",
      "40 Train Loss 1.7878506 Test MSE 3.8139615963943596 Test RE 0.9334610866244243\n",
      "41 Train Loss 1.6416159 Test MSE 3.7264081212509166 Test RE 0.9226845936477682\n",
      "42 Train Loss 1.5181247 Test MSE 3.683992698611703 Test RE 0.9174183882942645\n",
      "43 Train Loss 1.3942828 Test MSE 3.5460994985984318 Test RE 0.9000849888960497\n",
      "44 Train Loss 1.3204327 Test MSE 3.514907232196777 Test RE 0.8961175728959445\n",
      "45 Train Loss 1.2373418 Test MSE 3.4233620551039143 Test RE 0.8843709667601992\n",
      "46 Train Loss 1.1759125 Test MSE 3.3815918727254677 Test RE 0.8789590777065829\n",
      "47 Train Loss 1.0699846 Test MSE 3.353327401567498 Test RE 0.8752780533991478\n",
      "48 Train Loss 1.0018072 Test MSE 3.4038857626304706 Test RE 0.8818516837475234\n",
      "49 Train Loss 0.93900526 Test MSE 3.4423048061587838 Test RE 0.8868143701059715\n",
      "50 Train Loss 0.88388973 Test MSE 3.39125795383071 Test RE 0.8802144076402008\n",
      "51 Train Loss 0.8424393 Test MSE 3.417773604211398 Test RE 0.88364882836517\n",
      "52 Train Loss 0.7954548 Test MSE 3.359961411912424 Test RE 0.8761434229185868\n",
      "53 Train Loss 0.7603054 Test MSE 3.360685655160907 Test RE 0.876237844653044\n",
      "54 Train Loss 0.73196775 Test MSE 3.3519249395861004 Test RE 0.875095000505437\n",
      "55 Train Loss 0.70067155 Test MSE 3.3247970581456823 Test RE 0.871546636292218\n",
      "56 Train Loss 0.6657852 Test MSE 3.2683627897219516 Test RE 0.8641182729723506\n",
      "57 Train Loss 0.6418124 Test MSE 3.287409016792104 Test RE 0.8666324193780367\n",
      "58 Train Loss 0.60952973 Test MSE 3.252249440986853 Test RE 0.8619855472186545\n",
      "59 Train Loss 0.5802828 Test MSE 3.2815556027520496 Test RE 0.8658605320893414\n",
      "60 Train Loss 0.55102676 Test MSE 3.2883830037373443 Test RE 0.8667607919271354\n",
      "61 Train Loss 0.5256887 Test MSE 3.282542458767117 Test RE 0.8659907166033158\n",
      "62 Train Loss 0.5041339 Test MSE 3.3271545623025522 Test RE 0.8718555740537627\n",
      "63 Train Loss 0.48008296 Test MSE 3.3409106070555166 Test RE 0.8736560484742844\n",
      "64 Train Loss 0.46470326 Test MSE 3.3464626942550484 Test RE 0.8743816891094246\n",
      "65 Train Loss 0.44985378 Test MSE 3.327804348177045 Test RE 0.8719407056232034\n",
      "66 Train Loss 0.43968588 Test MSE 3.3452986135049225 Test RE 0.8742295972564961\n",
      "67 Train Loss 0.42989498 Test MSE 3.3549746388300226 Test RE 0.8754930061065145\n",
      "68 Train Loss 0.4186014 Test MSE 3.382043426869749 Test RE 0.8790177607736531\n",
      "69 Train Loss 0.40896657 Test MSE 3.3717421424076934 Test RE 0.8776780503547349\n",
      "70 Train Loss 0.4036204 Test MSE 3.358715696258024 Test RE 0.8759809914759764\n",
      "71 Train Loss 0.39553988 Test MSE 3.3532053728185387 Test RE 0.8752621274180578\n",
      "72 Train Loss 0.38732427 Test MSE 3.3709736224075026 Test RE 0.8775780202298465\n",
      "73 Train Loss 0.38105333 Test MSE 3.3823087159657375 Test RE 0.8790522353833643\n",
      "74 Train Loss 0.37303025 Test MSE 3.3933589500553056 Test RE 0.8804870263603563\n",
      "75 Train Loss 0.36758867 Test MSE 3.3928733141396106 Test RE 0.8804240192589262\n",
      "76 Train Loss 0.36141127 Test MSE 3.401503511520531 Test RE 0.881543042389692\n",
      "77 Train Loss 0.3565175 Test MSE 3.4119957217125534 Test RE 0.8829015906409902\n",
      "78 Train Loss 0.35106537 Test MSE 3.414379490560691 Test RE 0.8832099535480091\n",
      "79 Train Loss 0.34667468 Test MSE 3.4333708033195416 Test RE 0.8856628234171283\n",
      "80 Train Loss 0.34303695 Test MSE 3.427455561599021 Test RE 0.8848995548370843\n",
      "81 Train Loss 0.33735695 Test MSE 3.4551721683203884 Test RE 0.8884702836043621\n",
      "82 Train Loss 0.33376378 Test MSE 3.4774678058400803 Test RE 0.8913322477948789\n",
      "83 Train Loss 0.32969567 Test MSE 3.4930148343418206 Test RE 0.8933225054466108\n",
      "84 Train Loss 0.32455587 Test MSE 3.526423639936075 Test RE 0.8975844133005046\n",
      "85 Train Loss 0.32137567 Test MSE 3.5300212073685926 Test RE 0.8980421429490234\n",
      "86 Train Loss 0.31840897 Test MSE 3.5568504518312727 Test RE 0.9014483810243565\n",
      "87 Train Loss 0.3146561 Test MSE 3.5615978754731827 Test RE 0.9020497740764678\n",
      "88 Train Loss 0.3109721 Test MSE 3.5745323829831346 Test RE 0.9036862580394559\n",
      "89 Train Loss 0.30815375 Test MSE 3.586550825987645 Test RE 0.9052041891551379\n",
      "90 Train Loss 0.30514327 Test MSE 3.6066423583664413 Test RE 0.9077360841224211\n",
      "91 Train Loss 0.3027608 Test MSE 3.621800405431676 Test RE 0.9096416070519941\n",
      "92 Train Loss 0.30032378 Test MSE 3.641041122379639 Test RE 0.9120546297664912\n",
      "93 Train Loss 0.29746473 Test MSE 3.6651963845371536 Test RE 0.9150749884315988\n",
      "94 Train Loss 0.29553628 Test MSE 3.6785497448787745 Test RE 0.9167404130611653\n",
      "95 Train Loss 0.29314178 Test MSE 3.6645861684966334 Test RE 0.9149988101561122\n",
      "96 Train Loss 0.29108962 Test MSE 3.6747768327442665 Test RE 0.9162701641043546\n",
      "97 Train Loss 0.28801563 Test MSE 3.676624494587111 Test RE 0.9165004834880295\n",
      "98 Train Loss 0.28521672 Test MSE 3.67011114771557 Test RE 0.9156883075736977\n",
      "99 Train Loss 0.2831185 Test MSE 3.668104441877334 Test RE 0.9154379380014643\n",
      "Training time: 92.99\n",
      "KG_stan_tune7\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.126812 Test MSE 8.356611039422821 Test RE 1.3817298961804363\n",
      "1 Train Loss 50.16197 Test MSE 8.623754200689913 Test RE 1.4036416453339906\n",
      "2 Train Loss 43.4198 Test MSE 8.200421795175686 Test RE 1.3687563780819993\n",
      "3 Train Loss 40.56903 Test MSE 8.069333718513263 Test RE 1.3577721570166892\n",
      "4 Train Loss 38.51416 Test MSE 7.912830642293456 Test RE 1.34454083161377\n",
      "5 Train Loss 34.746513 Test MSE 7.633424944415693 Test RE 1.3205893184013888\n",
      "6 Train Loss 31.494427 Test MSE 5.699869692714768 Test RE 1.1411441911325588\n",
      "7 Train Loss 26.646587 Test MSE 5.3771462282869 Test RE 1.1083680131016738\n",
      "8 Train Loss 23.367815 Test MSE 5.193890625128657 Test RE 1.089317448662475\n",
      "9 Train Loss 20.485268 Test MSE 6.010740852778826 Test RE 1.1718501025742414\n",
      "10 Train Loss 17.419212 Test MSE 5.943811268243982 Test RE 1.1653075648072433\n",
      "11 Train Loss 15.045524 Test MSE 5.816029372499334 Test RE 1.1527134374440775\n",
      "12 Train Loss 13.181067 Test MSE 5.972627417290671 Test RE 1.1681289090568117\n",
      "13 Train Loss 12.68691 Test MSE 6.016775235482697 Test RE 1.172438184663669\n",
      "14 Train Loss 12.21118 Test MSE 6.039678308926406 Test RE 1.1746675294228446\n",
      "15 Train Loss 11.746048 Test MSE 6.082654908655844 Test RE 1.1788394178720156\n",
      "16 Train Loss 11.549371 Test MSE 6.010227110390141 Test RE 1.1718000220641895\n",
      "17 Train Loss 11.382408 Test MSE 5.9525606566658755 Test RE 1.1661649254084048\n",
      "18 Train Loss 11.295884 Test MSE 5.962090776976453 Test RE 1.1670980740104073\n",
      "19 Train Loss 11.187192 Test MSE 6.0182508994147 Test RE 1.1725819509342257\n",
      "20 Train Loss 11.101738 Test MSE 5.968227025777718 Test RE 1.1676985145834229\n",
      "21 Train Loss 11.035306 Test MSE 5.954687569995332 Test RE 1.1663732483759968\n",
      "22 Train Loss 10.964363 Test MSE 5.948139807702363 Test RE 1.1657318011728508\n",
      "23 Train Loss 10.875278 Test MSE 5.904176690203082 Test RE 1.1614158087785411\n",
      "24 Train Loss 10.816446 Test MSE 5.9072628985323385 Test RE 1.1617193145043236\n",
      "25 Train Loss 10.712657 Test MSE 5.899197326533265 Test RE 1.160925957964684\n",
      "26 Train Loss 10.474163 Test MSE 5.865261555793147 Test RE 1.1575819657836393\n",
      "27 Train Loss 10.14114 Test MSE 5.740445970520676 Test RE 1.145198781149701\n",
      "28 Train Loss 9.971624 Test MSE 5.80488176085619 Test RE 1.151608201875596\n",
      "29 Train Loss 9.692796 Test MSE 5.810401946291463 Test RE 1.152155635955668\n",
      "30 Train Loss 9.329515 Test MSE 5.6310389222290995 Test RE 1.1342331205524516\n",
      "31 Train Loss 8.347009 Test MSE 4.5005180147839825 Test RE 1.0140031695366103\n",
      "32 Train Loss 7.3663883 Test MSE 4.445783595994328 Test RE 1.007818253083848\n",
      "33 Train Loss 6.7651696 Test MSE 4.327988485532345 Test RE 0.9943770872916254\n",
      "34 Train Loss 6.2865906 Test MSE 4.104300883940703 Test RE 0.9683395181184471\n",
      "35 Train Loss 5.9561734 Test MSE 3.9296035649312233 Test RE 0.9475070058944339\n",
      "36 Train Loss 5.7188773 Test MSE 3.7245318513510566 Test RE 0.9224522756559034\n",
      "37 Train Loss 5.467434 Test MSE 3.528113664576129 Test RE 0.8977994694347864\n",
      "38 Train Loss 5.2762947 Test MSE 3.3555201407608846 Test RE 0.8755641785839738\n",
      "39 Train Loss 4.9995317 Test MSE 2.9634045441826355 Test RE 0.8228175221098176\n",
      "40 Train Loss 4.826397 Test MSE 2.80479043624331 Test RE 0.8004943468168592\n",
      "41 Train Loss 4.615678 Test MSE 2.505449891769687 Test RE 0.7565731437576225\n",
      "42 Train Loss 4.4628205 Test MSE 2.3418197384676622 Test RE 0.7314502478168122\n",
      "43 Train Loss 4.328873 Test MSE 2.2331592339673407 Test RE 0.7142790394328826\n",
      "44 Train Loss 4.183593 Test MSE 2.1665023674037975 Test RE 0.7035381367544694\n",
      "45 Train Loss 4.0407305 Test MSE 2.128759848746531 Test RE 0.6973830625694428\n",
      "46 Train Loss 3.695393 Test MSE 2.046683139561794 Test RE 0.6838067228094658\n",
      "47 Train Loss 3.233395 Test MSE 1.9934546270803208 Test RE 0.6748561933073408\n",
      "48 Train Loss 2.7763734 Test MSE 1.9844335360986982 Test RE 0.6733274797396255\n",
      "49 Train Loss 2.3062956 Test MSE 1.8733260827821931 Test RE 0.6542063424725606\n",
      "50 Train Loss 1.8475164 Test MSE 1.574829765918946 Test RE 0.5998254212538277\n",
      "51 Train Loss 1.5896347 Test MSE 1.4405179258658845 Test RE 0.5736769410918602\n",
      "52 Train Loss 1.3564119 Test MSE 1.3143815644124655 Test RE 0.5479851502739257\n",
      "53 Train Loss 1.1216806 Test MSE 1.2252691584945599 Test RE 0.5290830046703323\n",
      "54 Train Loss 1.0300211 Test MSE 1.13208025804685 Test RE 0.5085652347984077\n",
      "55 Train Loss 0.915843 Test MSE 1.0282128499502787 Test RE 0.4846738336133894\n",
      "56 Train Loss 0.78043693 Test MSE 0.8356808769356016 Test RE 0.43694652762071906\n",
      "57 Train Loss 0.64872545 Test MSE 0.5772416463147028 Test RE 0.3631507024815204\n",
      "58 Train Loss 0.48855236 Test MSE 0.4628184834919521 Test RE 0.3251721988469198\n",
      "59 Train Loss 0.39390612 Test MSE 0.29678281623620995 Test RE 0.260391879355285\n",
      "60 Train Loss 0.30689248 Test MSE 0.21954527749987146 Test RE 0.22395982018506008\n",
      "61 Train Loss 0.24769197 Test MSE 0.1283098163524167 Test RE 0.1712134986698403\n",
      "62 Train Loss 0.21166328 Test MSE 0.10271667414276214 Test RE 0.15318933636618695\n",
      "63 Train Loss 0.16770357 Test MSE 0.06761408586903 Test RE 0.12428727055854359\n",
      "64 Train Loss 0.14330298 Test MSE 0.0584962016713855 Test RE 0.11560374245297596\n",
      "65 Train Loss 0.12079537 Test MSE 0.0475154737270722 Test RE 0.10418989300384124\n",
      "66 Train Loss 0.10231798 Test MSE 0.034961951925798165 Test RE 0.08937290939271476\n",
      "67 Train Loss 0.086492956 Test MSE 0.025966620000329777 Test RE 0.07702217378864752\n",
      "68 Train Loss 0.07407723 Test MSE 0.017683405586572856 Test RE 0.06356104287917512\n",
      "69 Train Loss 0.06386419 Test MSE 0.015212350613148705 Test RE 0.058953042505882264\n",
      "70 Train Loss 0.053088125 Test MSE 0.008596516879349852 Test RE 0.04431689457595904\n",
      "71 Train Loss 0.045685247 Test MSE 0.00817749268412949 Test RE 0.043223322015841024\n",
      "72 Train Loss 0.04123526 Test MSE 0.009292913135469498 Test RE 0.04607697920395471\n",
      "73 Train Loss 0.038556848 Test MSE 0.008601560692566543 Test RE 0.04432989364081875\n",
      "74 Train Loss 0.035483878 Test MSE 0.009121656065762259 Test RE 0.045650433585575204\n",
      "75 Train Loss 0.03382028 Test MSE 0.009019921628617813 Test RE 0.04539514862529658\n",
      "76 Train Loss 0.030297251 Test MSE 0.007676034277216605 Test RE 0.04187709170146173\n",
      "77 Train Loss 0.028051779 Test MSE 0.00807900833104013 Test RE 0.04296225695444335\n",
      "78 Train Loss 0.026391845 Test MSE 0.007849187079232982 Test RE 0.04234678075507522\n",
      "79 Train Loss 0.023410872 Test MSE 0.008041247973173866 Test RE 0.04286173903505192\n",
      "80 Train Loss 0.021447157 Test MSE 0.009140917250408283 Test RE 0.04569860563588033\n",
      "81 Train Loss 0.020138498 Test MSE 0.008817725858535037 Test RE 0.044883462883413536\n",
      "82 Train Loss 0.018739562 Test MSE 0.009482906436243806 Test RE 0.04654561715723402\n",
      "83 Train Loss 0.017044779 Test MSE 0.009167626167688549 Test RE 0.0457653204935579\n",
      "84 Train Loss 0.01600781 Test MSE 0.00827349856412794 Test RE 0.043476308144011475\n",
      "85 Train Loss 0.014874018 Test MSE 0.0069762612428003285 Test RE 0.039922656128218735\n",
      "86 Train Loss 0.013710298 Test MSE 0.006428621904730577 Test RE 0.03832366208475887\n",
      "87 Train Loss 0.012348171 Test MSE 0.005701203583081017 Test RE 0.03609037004136165\n",
      "88 Train Loss 0.011377063 Test MSE 0.0059212423012361135 Test RE 0.036780233057660365\n",
      "89 Train Loss 0.010608764 Test MSE 0.005562745649865133 Test RE 0.03564943585897881\n",
      "90 Train Loss 0.00968887 Test MSE 0.004813497602622292 Test RE 0.03316182630351605\n",
      "91 Train Loss 0.009262485 Test MSE 0.004766222451899276 Test RE 0.03299857716517331\n",
      "92 Train Loss 0.008824465 Test MSE 0.004505334057963853 Test RE 0.03208274795158013\n",
      "93 Train Loss 0.008096825 Test MSE 0.003985682651119965 Test RE 0.03017584347987347\n",
      "94 Train Loss 0.007695714 Test MSE 0.0038884375053320572 Test RE 0.029805445801630533\n",
      "95 Train Loss 0.0073726126 Test MSE 0.003613951803988492 Test RE 0.028734208484593064\n",
      "96 Train Loss 0.006853331 Test MSE 0.0031330430412123047 Test RE 0.026754155126319182\n",
      "97 Train Loss 0.0061380453 Test MSE 0.0031508659973168043 Test RE 0.02683014544953158\n",
      "98 Train Loss 0.0058045136 Test MSE 0.0030743555301089446 Test RE 0.02650239393154095\n",
      "99 Train Loss 0.005594946 Test MSE 0.0029969928970738154 Test RE 0.02616681820341945\n",
      "Training time: 92.38\n",
      "KG_stan_tune7\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.237534 Test MSE 8.96325571390659 Test RE 1.4310043488856143\n",
      "1 Train Loss 47.16771 Test MSE 8.204538941599477 Test RE 1.3690999374387292\n",
      "2 Train Loss 44.32666 Test MSE 8.378647797529071 Test RE 1.3835505385453124\n",
      "3 Train Loss 42.41851 Test MSE 8.087999397150304 Test RE 1.3593416236238396\n",
      "4 Train Loss 41.89627 Test MSE 8.284888294071958 Test RE 1.3757875937711628\n",
      "5 Train Loss 40.7344 Test MSE 8.222145856706367 Test RE 1.3705681922517727\n",
      "6 Train Loss 37.453247 Test MSE 7.790618457191235 Test RE 1.334117337292661\n",
      "7 Train Loss 31.095995 Test MSE 6.619623858877737 Test RE 1.2297723283919513\n",
      "8 Train Loss 27.198074 Test MSE 6.76554640478256 Test RE 1.243252951377677\n",
      "9 Train Loss 24.05516 Test MSE 6.538638050059021 Test RE 1.222226537263165\n",
      "10 Train Loss 22.65625 Test MSE 6.442112564605127 Test RE 1.2131715434983439\n",
      "11 Train Loss 21.553715 Test MSE 6.323675405350559 Test RE 1.201967832331473\n",
      "12 Train Loss 19.643566 Test MSE 6.195643928284694 Test RE 1.1897378694894034\n",
      "13 Train Loss 17.455471 Test MSE 6.405326394741108 Test RE 1.2097028190769301\n",
      "14 Train Loss 16.219795 Test MSE 6.581609919476281 Test RE 1.2262361910076092\n",
      "15 Train Loss 15.372753 Test MSE 6.423432584598539 Test RE 1.2114113699614917\n",
      "16 Train Loss 14.515203 Test MSE 6.350923863621239 Test RE 1.2045546637645301\n",
      "17 Train Loss 13.4472065 Test MSE 5.8442619196166 Test RE 1.155507838536164\n",
      "18 Train Loss 12.360466 Test MSE 5.644796295319936 Test RE 1.1356178161078063\n",
      "19 Train Loss 10.129994 Test MSE 4.340330961031841 Test RE 0.9957939507262226\n",
      "20 Train Loss 8.466608 Test MSE 3.8170291996839314 Test RE 0.933836406705239\n",
      "21 Train Loss 5.9733133 Test MSE 3.144054460448559 Test RE 0.8475261174835402\n",
      "22 Train Loss 4.870371 Test MSE 2.9686205246653743 Test RE 0.8235413371002638\n",
      "23 Train Loss 3.863227 Test MSE 2.67884132372883 Test RE 0.7823148157516047\n",
      "24 Train Loss 2.9101865 Test MSE 2.28355579242538 Test RE 0.7222937779116595\n",
      "25 Train Loss 2.4176066 Test MSE 2.1097832207744736 Test RE 0.6942677265681818\n",
      "26 Train Loss 1.9615779 Test MSE 1.6170029748288226 Test RE 0.6078038822271037\n",
      "27 Train Loss 1.5673813 Test MSE 1.2412923532809834 Test RE 0.5325312526496959\n",
      "28 Train Loss 1.1650845 Test MSE 0.575669297932169 Test RE 0.3626557721606699\n",
      "29 Train Loss 0.78086776 Test MSE 0.2161944544103804 Test RE 0.22224414847085458\n",
      "30 Train Loss 0.58493745 Test MSE 0.15620912858469357 Test RE 0.18891274784043272\n",
      "31 Train Loss 0.41891667 Test MSE 0.10058316803985168 Test RE 0.1515900567196828\n",
      "32 Train Loss 0.308004 Test MSE 0.07065835610959931 Test RE 0.12705443371881892\n",
      "33 Train Loss 0.23525128 Test MSE 0.05975122993060557 Test RE 0.11683729264337352\n",
      "34 Train Loss 0.19347245 Test MSE 0.05737003489239441 Test RE 0.11448553481998004\n",
      "35 Train Loss 0.15904501 Test MSE 0.051159887288483315 Test RE 0.10811173816845192\n",
      "36 Train Loss 0.13613424 Test MSE 0.04267471414900181 Test RE 0.09874005633051564\n",
      "37 Train Loss 0.11642317 Test MSE 0.037670902519854416 Test RE 0.09277075111463813\n",
      "38 Train Loss 0.09644035 Test MSE 0.03491606001440206 Test RE 0.08931423360049913\n",
      "39 Train Loss 0.085118294 Test MSE 0.02702341179207127 Test RE 0.07857387106782751\n",
      "40 Train Loss 0.07581567 Test MSE 0.02459632278431165 Test RE 0.07496234298286927\n",
      "41 Train Loss 0.06486317 Test MSE 0.02830558334180645 Test RE 0.0804163051797683\n",
      "42 Train Loss 0.057332337 Test MSE 0.02728402294366531 Test RE 0.07895184135745063\n",
      "43 Train Loss 0.05047168 Test MSE 0.029368607057035968 Test RE 0.08191241580468997\n",
      "44 Train Loss 0.044288386 Test MSE 0.029374912172521583 Test RE 0.0819212081781821\n",
      "45 Train Loss 0.038370967 Test MSE 0.02708515400042811 Test RE 0.0786635813620055\n",
      "46 Train Loss 0.035328828 Test MSE 0.02646525764773777 Test RE 0.07775818652912628\n",
      "47 Train Loss 0.031829596 Test MSE 0.029203815047058265 Test RE 0.08168228060433193\n",
      "48 Train Loss 0.027505085 Test MSE 0.028907430163981795 Test RE 0.08126673333502125\n",
      "49 Train Loss 0.02485856 Test MSE 0.025928652651954605 Test RE 0.0769658438264569\n",
      "50 Train Loss 0.021412035 Test MSE 0.025932451960836305 Test RE 0.07697148249783\n",
      "51 Train Loss 0.01946022 Test MSE 0.024349299530564042 Test RE 0.0745849660453871\n",
      "52 Train Loss 0.018006064 Test MSE 0.022469255791317182 Test RE 0.07164772490906236\n",
      "53 Train Loss 0.016738893 Test MSE 0.021992733342114573 Test RE 0.07088390984458755\n",
      "54 Train Loss 0.015531882 Test MSE 0.021169020293227973 Test RE 0.06954380356508665\n",
      "55 Train Loss 0.014862824 Test MSE 0.020745840834321166 Test RE 0.06884518654912705\n",
      "56 Train Loss 0.013580836 Test MSE 0.019006497106718267 Test RE 0.06589600747047862\n",
      "57 Train Loss 0.013125602 Test MSE 0.018648767847757264 Test RE 0.06527293355371865\n",
      "58 Train Loss 0.012479873 Test MSE 0.018192214950844065 Test RE 0.06446898751585996\n",
      "59 Train Loss 0.011336935 Test MSE 0.017754178888802832 Test RE 0.06368810926669338\n",
      "60 Train Loss 0.010397894 Test MSE 0.01653683748957737 Test RE 0.061465906296287176\n",
      "61 Train Loss 0.009642747 Test MSE 0.01608132475645983 Test RE 0.06061344547632424\n",
      "62 Train Loss 0.009008245 Test MSE 0.015482430255882135 Test RE 0.059474065448408296\n",
      "63 Train Loss 0.00880983 Test MSE 0.014548221929000151 Test RE 0.057651819602276874\n",
      "64 Train Loss 0.008120182 Test MSE 0.01337334293587626 Test RE 0.05527491087712831\n",
      "65 Train Loss 0.0073212627 Test MSE 0.012613535487947206 Test RE 0.05368172673707829\n",
      "66 Train Loss 0.0069137816 Test MSE 0.012211675471385757 Test RE 0.052819670471010084\n",
      "67 Train Loss 0.006296361 Test MSE 0.011071182294578673 Test RE 0.05029271268162467\n",
      "68 Train Loss 0.005968565 Test MSE 0.010749887076837831 Test RE 0.04955757094627359\n",
      "69 Train Loss 0.005688032 Test MSE 0.010698992663243772 Test RE 0.04944011874091763\n",
      "70 Train Loss 0.0053191315 Test MSE 0.010087400897689084 Test RE 0.04800624097635353\n",
      "71 Train Loss 0.004959556 Test MSE 0.009609725693260254 Test RE 0.046855821418738314\n",
      "72 Train Loss 0.004625897 Test MSE 0.008933800177149205 Test RE 0.04517791432143847\n",
      "73 Train Loss 0.004431262 Test MSE 0.009219276994508195 Test RE 0.04589406137387845\n",
      "74 Train Loss 0.0042541963 Test MSE 0.00853834653839977 Test RE 0.044166699749330886\n",
      "75 Train Loss 0.0039183865 Test MSE 0.008005578890053811 Test RE 0.04276657108969942\n",
      "76 Train Loss 0.0037001662 Test MSE 0.007621156529082626 Test RE 0.0417271286733324\n",
      "77 Train Loss 0.003602593 Test MSE 0.0075173862045082186 Test RE 0.04144207492718032\n",
      "78 Train Loss 0.0034442728 Test MSE 0.007230470143208586 Test RE 0.040643521416602796\n",
      "79 Train Loss 0.0033345283 Test MSE 0.007381611772285714 Test RE 0.04106611891382861\n",
      "80 Train Loss 0.0032296672 Test MSE 0.007413203224161935 Test RE 0.04115390145041379\n",
      "81 Train Loss 0.0031109143 Test MSE 0.0071253977871363556 Test RE 0.040347127207534576\n",
      "82 Train Loss 0.0030137708 Test MSE 0.007381812125348645 Test RE 0.04106667622211926\n",
      "83 Train Loss 0.0028819079 Test MSE 0.007280099177756419 Test RE 0.04078276888177739\n",
      "84 Train Loss 0.0027337866 Test MSE 0.007020764510954624 Test RE 0.04004979186245255\n",
      "85 Train Loss 0.002628121 Test MSE 0.006658896949232366 Test RE 0.039004005342873856\n",
      "86 Train Loss 0.0024826226 Test MSE 0.006204871450826709 Test RE 0.03765082132929054\n",
      "87 Train Loss 0.002394008 Test MSE 0.005782528706068071 Test RE 0.03634686508885303\n",
      "88 Train Loss 0.0022967667 Test MSE 0.005609945830092194 Test RE 0.035800360025117425\n",
      "89 Train Loss 0.0022193198 Test MSE 0.0054186759975763995 Test RE 0.03518476479253424\n",
      "90 Train Loss 0.0021688526 Test MSE 0.005321930565619976 Test RE 0.03486925450025596\n",
      "91 Train Loss 0.0021179842 Test MSE 0.005199753572231713 Test RE 0.034466679143789265\n",
      "92 Train Loss 0.0020304034 Test MSE 0.004959224171149546 Test RE 0.033660063452263696\n",
      "93 Train Loss 0.0019426594 Test MSE 0.005035744544946128 Test RE 0.03391875521951117\n",
      "94 Train Loss 0.001901807 Test MSE 0.004960017340512685 Test RE 0.03366275510954141\n",
      "95 Train Loss 0.0018425571 Test MSE 0.004668995736274709 Test RE 0.03266027212456741\n",
      "96 Train Loss 0.0017901247 Test MSE 0.0045252772607041036 Test RE 0.03215367790199386\n",
      "97 Train Loss 0.0017513789 Test MSE 0.00443470849239092 Test RE 0.03183029026612257\n",
      "98 Train Loss 0.0017161635 Test MSE 0.0042902952091994516 Test RE 0.03130773495283341\n",
      "99 Train Loss 0.0016738139 Test MSE 0.004129859139935382 Test RE 0.03071677947777873\n",
      "Training time: 97.81\n",
      "KG_stan_tune7\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.684185 Test MSE 8.508021119599118 Test RE 1.3941912087944617\n",
      "1 Train Loss 44.8673 Test MSE 8.48581953259787 Test RE 1.3923709572683698\n",
      "2 Train Loss 42.276688 Test MSE 8.53746137306387 Test RE 1.396601281363157\n",
      "3 Train Loss 41.32908 Test MSE 8.606642964468183 Test RE 1.402248402369366\n",
      "4 Train Loss 40.63563 Test MSE 8.778550384925158 Test RE 1.41618328232095\n",
      "5 Train Loss 40.341896 Test MSE 8.818063160759115 Test RE 1.419366866433163\n",
      "6 Train Loss 39.974915 Test MSE 8.888821580737103 Test RE 1.4250501715941017\n",
      "7 Train Loss 39.68322 Test MSE 9.04144590103808 Test RE 1.437232417300555\n",
      "8 Train Loss 38.946327 Test MSE 8.972759227001607 Test RE 1.431762776743351\n",
      "9 Train Loss 38.242584 Test MSE 9.204813416887431 Test RE 1.4501587758550374\n",
      "10 Train Loss 37.573853 Test MSE 9.199826359296521 Test RE 1.4497658833093017\n",
      "11 Train Loss 35.588764 Test MSE 8.925325505840245 Test RE 1.4279733164561041\n",
      "12 Train Loss 31.717293 Test MSE 8.62806818902984 Test RE 1.4039926836670371\n",
      "13 Train Loss 29.7651 Test MSE 8.088363765907156 Test RE 1.3593722428174706\n",
      "14 Train Loss 27.802464 Test MSE 7.964586310902302 Test RE 1.3489308024769497\n",
      "15 Train Loss 25.466099 Test MSE 7.785762262558499 Test RE 1.3337014689367235\n",
      "16 Train Loss 23.799746 Test MSE 7.613958189847182 Test RE 1.318904360526351\n",
      "17 Train Loss 19.380655 Test MSE 6.314019646532467 Test RE 1.2010498262299767\n",
      "18 Train Loss 16.89243 Test MSE 5.9249527650441545 Test RE 1.1634574542919396\n",
      "19 Train Loss 14.771856 Test MSE 5.030131598815767 Test RE 1.0720072781493608\n",
      "20 Train Loss 12.971056 Test MSE 4.2517873006749465 Test RE 0.9855844106943195\n",
      "21 Train Loss 9.813889 Test MSE 3.5702944048452587 Test RE 0.9031503923618107\n",
      "22 Train Loss 8.779569 Test MSE 3.498659581551829 Test RE 0.894044023159647\n",
      "23 Train Loss 8.34468 Test MSE 3.44692155951691 Test RE 0.8874088600777676\n",
      "24 Train Loss 7.866303 Test MSE 3.469250806895559 Test RE 0.8902785489211349\n",
      "25 Train Loss 7.4400783 Test MSE 3.4856707752341567 Test RE 0.8923829066124181\n",
      "26 Train Loss 7.149211 Test MSE 3.4768038349468466 Test RE 0.8912471503972567\n",
      "27 Train Loss 6.929044 Test MSE 3.4559007609105117 Test RE 0.8885639545867983\n",
      "28 Train Loss 6.701885 Test MSE 3.4386252340763375 Test RE 0.8863402735265231\n",
      "29 Train Loss 6.496731 Test MSE 3.4457907973250053 Test RE 0.8872632909548283\n",
      "30 Train Loss 6.3211374 Test MSE 3.451250369182722 Test RE 0.8879659105763403\n",
      "31 Train Loss 6.1488934 Test MSE 3.470198924866743 Test RE 0.8904001935464132\n",
      "32 Train Loss 6.025595 Test MSE 3.431382113330864 Test RE 0.8854062877830451\n",
      "33 Train Loss 5.8406086 Test MSE 3.3741262349054644 Test RE 0.8779882899597137\n",
      "34 Train Loss 5.6682997 Test MSE 3.331971421170152 Test RE 0.8724864564321412\n",
      "35 Train Loss 5.5189238 Test MSE 3.4109205636813966 Test RE 0.88276247359548\n",
      "36 Train Loss 5.3455496 Test MSE 3.4686749002120214 Test RE 0.8902046513168653\n",
      "37 Train Loss 5.233099 Test MSE 3.496945135640615 Test RE 0.893824942407679\n",
      "38 Train Loss 5.1058264 Test MSE 3.519448165734123 Test RE 0.8966962363796859\n",
      "39 Train Loss 4.8980656 Test MSE 3.500271939273483 Test RE 0.894250009582143\n",
      "40 Train Loss 4.691544 Test MSE 3.4561433743446752 Test RE 0.8885951438170473\n",
      "41 Train Loss 4.3624983 Test MSE 3.3501855132711595 Test RE 0.8748679129623025\n",
      "42 Train Loss 3.8997643 Test MSE 3.3312835340518183 Test RE 0.8723963891569321\n",
      "43 Train Loss 3.6424494 Test MSE 3.244844585590032 Test RE 0.8610036859270742\n",
      "44 Train Loss 3.288392 Test MSE 3.2505119108680307 Test RE 0.8617552564656309\n",
      "45 Train Loss 2.9028563 Test MSE 3.25951888471831 Test RE 0.8629483666331986\n",
      "46 Train Loss 2.5786068 Test MSE 3.1561818937963353 Test RE 0.8491591082866831\n",
      "47 Train Loss 2.1140585 Test MSE 2.9497299944106943 Test RE 0.8209168924210408\n",
      "48 Train Loss 1.8060557 Test MSE 2.8598326472746782 Test RE 0.8083107787513967\n",
      "49 Train Loss 1.5329182 Test MSE 2.82119674688461 Test RE 0.8028321346024938\n",
      "50 Train Loss 1.3947972 Test MSE 2.7740535275999183 Test RE 0.796096067670818\n",
      "51 Train Loss 1.2432798 Test MSE 2.668085013260347 Test RE 0.7807426276297577\n",
      "52 Train Loss 1.123694 Test MSE 2.581710432054368 Test RE 0.7680010699919889\n",
      "53 Train Loss 1.0395526 Test MSE 2.5816972464820345 Test RE 0.7679991087831595\n",
      "54 Train Loss 0.9431066 Test MSE 2.6450449973412273 Test RE 0.7773643009997698\n",
      "55 Train Loss 0.91085726 Test MSE 2.686723944891959 Test RE 0.7834649700147469\n",
      "56 Train Loss 0.8693386 Test MSE 2.6822257444437696 Test RE 0.7828088440295585\n",
      "57 Train Loss 0.848397 Test MSE 2.702084986714485 Test RE 0.7857014642469871\n",
      "58 Train Loss 0.8219549 Test MSE 2.734958943082501 Test RE 0.7904664938216451\n",
      "59 Train Loss 0.80012566 Test MSE 2.7028020947450093 Test RE 0.7858057162329328\n",
      "60 Train Loss 0.78349763 Test MSE 2.7032981157417013 Test RE 0.7858778188581939\n",
      "61 Train Loss 0.76667374 Test MSE 2.7143075604370943 Test RE 0.787476474795978\n",
      "62 Train Loss 0.75426567 Test MSE 2.7182403249062785 Test RE 0.7880467562482546\n",
      "63 Train Loss 0.7399169 Test MSE 2.7234650471045985 Test RE 0.7888037439154559\n",
      "64 Train Loss 0.72376496 Test MSE 2.747230152094359 Test RE 0.7922378409684104\n",
      "65 Train Loss 0.71375257 Test MSE 2.7663332033858095 Test RE 0.7949875090427525\n",
      "66 Train Loss 0.7001481 Test MSE 2.7813748121895587 Test RE 0.7971459041773172\n",
      "67 Train Loss 0.68434083 Test MSE 2.831322993391815 Test RE 0.8042716644968756\n",
      "68 Train Loss 0.67449397 Test MSE 2.81624567898138 Test RE 0.8021273588933844\n",
      "69 Train Loss 0.6620703 Test MSE 2.833341121212905 Test RE 0.8045582502897638\n",
      "70 Train Loss 0.6483862 Test MSE 2.833742316423932 Test RE 0.8046152101610942\n",
      "71 Train Loss 0.63460016 Test MSE 2.855867258935848 Test RE 0.8077501903547002\n",
      "72 Train Loss 0.62879515 Test MSE 2.865778387042782 Test RE 0.8091506023957459\n",
      "73 Train Loss 0.6220673 Test MSE 2.875697423420072 Test RE 0.8105497094225211\n",
      "74 Train Loss 0.61132157 Test MSE 2.8833104646376992 Test RE 0.811621913616683\n",
      "75 Train Loss 0.5998299 Test MSE 2.920880584882485 Test RE 0.8168925987492291\n",
      "76 Train Loss 0.5901337 Test MSE 2.9243310982947115 Test RE 0.817374964739025\n",
      "77 Train Loss 0.58235705 Test MSE 2.940062107343578 Test RE 0.8195704902764224\n",
      "78 Train Loss 0.5774311 Test MSE 2.9402183335531284 Test RE 0.8195922647637682\n",
      "79 Train Loss 0.57159615 Test MSE 2.935830042731286 Test RE 0.8189804135682561\n",
      "80 Train Loss 0.565249 Test MSE 2.9458636554190285 Test RE 0.8203787103273485\n",
      "81 Train Loss 0.5568022 Test MSE 2.980055424975347 Test RE 0.8251259219159468\n",
      "82 Train Loss 0.5497374 Test MSE 2.9994786592005958 Test RE 0.8278105338084707\n",
      "83 Train Loss 0.5420529 Test MSE 3.016067483226975 Test RE 0.8300965091650208\n",
      "84 Train Loss 0.53413725 Test MSE 3.013984827317627 Test RE 0.8298098604151734\n",
      "85 Train Loss 0.526807 Test MSE 3.027182521563847 Test RE 0.8316246695267512\n",
      "86 Train Loss 0.5231433 Test MSE 3.0405950411168297 Test RE 0.8334649705599395\n",
      "87 Train Loss 0.514352 Test MSE 3.070497385303705 Test RE 0.8375532462286768\n",
      "88 Train Loss 0.50740665 Test MSE 3.072689072310788 Test RE 0.837852111019389\n",
      "89 Train Loss 0.49987608 Test MSE 3.096847940401852 Test RE 0.8411394477356933\n",
      "90 Train Loss 0.49457037 Test MSE 3.112217050363305 Test RE 0.8432240778636622\n",
      "91 Train Loss 0.48687872 Test MSE 3.1268726339096986 Test RE 0.8452071379037934\n",
      "92 Train Loss 0.48013195 Test MSE 3.1388420966079256 Test RE 0.8468232914039064\n",
      "93 Train Loss 0.4758414 Test MSE 3.1499897897920612 Test RE 0.848325717946977\n",
      "94 Train Loss 0.4722212 Test MSE 3.15705109248888 Test RE 0.8492760275901273\n",
      "95 Train Loss 0.46629128 Test MSE 3.1541364376571215 Test RE 0.84888390247219\n",
      "96 Train Loss 0.4609279 Test MSE 3.1534334718924266 Test RE 0.8487893013688524\n",
      "97 Train Loss 0.4573827 Test MSE 3.1616553831193133 Test RE 0.8498951003997929\n",
      "98 Train Loss 0.45244882 Test MSE 3.18041675761439 Test RE 0.8524130243052813\n",
      "99 Train Loss 0.44677517 Test MSE 3.15866572872542 Test RE 0.8494931758914145\n",
      "Training time: 90.84\n",
      "KG_stan_tune7\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 52.417767 Test MSE 9.171276853840476 Test RE 1.4475146310346503\n",
      "1 Train Loss 44.69709 Test MSE 8.300266233584653 Test RE 1.3770638312560044\n",
      "2 Train Loss 44.208923 Test MSE 8.139403359759157 Test RE 1.3636544869788338\n",
      "3 Train Loss 43.5407 Test MSE 8.349038260853373 Test RE 1.3811036910064036\n",
      "4 Train Loss 43.061966 Test MSE 8.445847243429352 Test RE 1.3890877180319616\n",
      "5 Train Loss 42.262306 Test MSE 8.33583415715585 Test RE 1.3800111428771087\n",
      "6 Train Loss 40.829903 Test MSE 7.930742106230702 Test RE 1.3460617210859716\n",
      "7 Train Loss 39.200844 Test MSE 7.735940433680897 Test RE 1.329427379485439\n",
      "8 Train Loss 36.474514 Test MSE 7.3819839832069185 Test RE 1.2986574448700559\n",
      "9 Train Loss 29.758018 Test MSE 5.723832818960523 Test RE 1.1435404478017317\n",
      "10 Train Loss 25.68676 Test MSE 5.160412784277996 Test RE 1.0858011105571925\n",
      "11 Train Loss 22.23507 Test MSE 5.38055304804034 Test RE 1.1087190740524855\n",
      "12 Train Loss 19.324732 Test MSE 5.6673139694776005 Test RE 1.137880609975223\n",
      "13 Train Loss 17.868938 Test MSE 5.320329646309422 Test RE 1.1024967838359605\n",
      "14 Train Loss 16.860184 Test MSE 5.305602523788087 Test RE 1.1009698242350134\n",
      "15 Train Loss 16.347141 Test MSE 5.46010585660716 Test RE 1.1168853426984489\n",
      "16 Train Loss 15.78091 Test MSE 5.4814731640267835 Test RE 1.1190685906798876\n",
      "17 Train Loss 15.173027 Test MSE 5.732998958060466 Test RE 1.1444557136815354\n",
      "18 Train Loss 14.608169 Test MSE 5.6836553425899785 Test RE 1.1395199356708\n",
      "19 Train Loss 14.314486 Test MSE 5.628044445027523 Test RE 1.1339314988688367\n",
      "20 Train Loss 14.0793 Test MSE 5.630971432424623 Test RE 1.134226323458526\n",
      "21 Train Loss 13.826227 Test MSE 5.657393518370992 Test RE 1.1368842620322281\n",
      "22 Train Loss 13.599493 Test MSE 5.586601283059096 Test RE 1.129748825919942\n",
      "23 Train Loss 13.363964 Test MSE 5.639643983410886 Test RE 1.1350994277864288\n",
      "24 Train Loss 13.112679 Test MSE 5.682189902977502 Test RE 1.1393730227067607\n",
      "25 Train Loss 12.922673 Test MSE 5.6688792397492005 Test RE 1.1380377362379441\n",
      "26 Train Loss 12.762899 Test MSE 5.653447649724434 Test RE 1.1364877209010678\n",
      "27 Train Loss 12.554468 Test MSE 5.538232554093902 Test RE 1.1248475178893311\n",
      "28 Train Loss 11.340819 Test MSE 4.787567021749825 Test RE 1.045840591171216\n",
      "29 Train Loss 10.764561 Test MSE 4.749850765857996 Test RE 1.0417129010940163\n",
      "30 Train Loss 10.124643 Test MSE 4.65948430168192 Test RE 1.03175596104037\n",
      "31 Train Loss 9.764981 Test MSE 4.536038605827572 Test RE 1.0179968434157582\n",
      "32 Train Loss 9.470736 Test MSE 4.433422706440094 Test RE 1.0064162278819102\n",
      "33 Train Loss 9.25194 Test MSE 4.3117637902539645 Test RE 0.9925114846086257\n",
      "34 Train Loss 9.158084 Test MSE 4.2799049166861565 Test RE 0.9888379387634431\n",
      "35 Train Loss 9.0266905 Test MSE 4.243339614517112 Test RE 0.9846048170667977\n",
      "36 Train Loss 8.882432 Test MSE 4.208143355924238 Test RE 0.9805129261888984\n",
      "37 Train Loss 8.46161 Test MSE 3.814497959688637 Test RE 0.9335267213521787\n",
      "38 Train Loss 7.305313 Test MSE 3.2120076476695365 Test RE 0.8566360473360517\n",
      "39 Train Loss 6.288885 Test MSE 3.100190779755137 Test RE 0.8415933020619532\n",
      "40 Train Loss 5.6675396 Test MSE 2.8490555195232226 Test RE 0.8067863030058419\n",
      "41 Train Loss 5.052926 Test MSE 2.3300101663180386 Test RE 0.7296036000635454\n",
      "42 Train Loss 4.7629395 Test MSE 2.1570195427431744 Test RE 0.7019967479085047\n",
      "43 Train Loss 4.524691 Test MSE 2.179752514619356 Test RE 0.7056862475354615\n",
      "44 Train Loss 4.4288354 Test MSE 2.1660165368229856 Test RE 0.7034592493480264\n",
      "45 Train Loss 4.38332 Test MSE 2.148008396061181 Test RE 0.7005288854195574\n",
      "46 Train Loss 4.3478394 Test MSE 2.131376438504423 Test RE 0.697811529169706\n",
      "47 Train Loss 4.3153715 Test MSE 2.1320791442444307 Test RE 0.6979265524353547\n",
      "48 Train Loss 4.2936597 Test MSE 2.1187095453878255 Test RE 0.6957348720639861\n",
      "49 Train Loss 4.263092 Test MSE 2.139862905293484 Test RE 0.69919938143497\n",
      "50 Train Loss 4.230173 Test MSE 2.1161095592687618 Test RE 0.6953078535740426\n",
      "51 Train Loss 4.17379 Test MSE 2.0992895798518822 Test RE 0.6925389997063365\n",
      "52 Train Loss 4.0905156 Test MSE 2.0621637594082145 Test RE 0.686387926036416\n",
      "53 Train Loss 3.9414158 Test MSE 2.0835052561585328 Test RE 0.6899305255849602\n",
      "54 Train Loss 3.7361584 Test MSE 1.9812514928094231 Test RE 0.672787422152048\n",
      "55 Train Loss 3.3267121 Test MSE 2.127935030177855 Test RE 0.697247943939363\n",
      "56 Train Loss 2.922367 Test MSE 2.0014513735301995 Test RE 0.6762084318914741\n",
      "57 Train Loss 2.4204187 Test MSE 1.855239884410416 Test RE 0.6510406354901251\n",
      "58 Train Loss 1.9645432 Test MSE 1.5885510259495792 Test RE 0.602432849355769\n",
      "59 Train Loss 1.544616 Test MSE 1.325286510955484 Test RE 0.5502536716185163\n",
      "60 Train Loss 1.2958782 Test MSE 0.9835164601995892 Test RE 0.47402241290000025\n",
      "61 Train Loss 0.94031686 Test MSE 0.4483626438504615 Test RE 0.32005364010733733\n",
      "62 Train Loss 0.6491459 Test MSE 0.21767308942664793 Test RE 0.22300285897722857\n",
      "63 Train Loss 0.45169583 Test MSE 0.1629028158373521 Test RE 0.19291782455488626\n",
      "64 Train Loss 0.31160513 Test MSE 0.15661424935355212 Test RE 0.18915755722440464\n",
      "65 Train Loss 0.24453185 Test MSE 0.1377315538317023 Test RE 0.17738822326189002\n",
      "66 Train Loss 0.16030495 Test MSE 0.07386273886616704 Test RE 0.12990347354372703\n",
      "67 Train Loss 0.12496935 Test MSE 0.04698748698398655 Test RE 0.1036094025692163\n",
      "68 Train Loss 0.09995644 Test MSE 0.03658106901615577 Test RE 0.09141895585718281\n",
      "69 Train Loss 0.07645047 Test MSE 0.02575736859068098 Test RE 0.07671120533096962\n",
      "70 Train Loss 0.05964262 Test MSE 0.020644019692733787 Test RE 0.06867603173143835\n",
      "71 Train Loss 0.05147899 Test MSE 0.018228215306244338 Test RE 0.06453274444156529\n",
      "72 Train Loss 0.045106936 Test MSE 0.013391140708645359 Test RE 0.055311679664703226\n",
      "73 Train Loss 0.041445035 Test MSE 0.01165846462182102 Test RE 0.05160939165473093\n",
      "74 Train Loss 0.030687932 Test MSE 0.010293954427712498 Test RE 0.048495247586307376\n",
      "75 Train Loss 0.023357224 Test MSE 0.007449901163575044 Test RE 0.041255638774075044\n",
      "76 Train Loss 0.020254401 Test MSE 0.0055267914640905955 Test RE 0.03553404102097497\n",
      "77 Train Loss 0.01767896 Test MSE 0.004836602046171035 Test RE 0.03324131822373753\n",
      "78 Train Loss 0.0161407 Test MSE 0.004306100296256584 Test RE 0.03136534947231162\n",
      "79 Train Loss 0.014822133 Test MSE 0.004179922613056585 Test RE 0.030902397952342498\n",
      "80 Train Loss 0.013237516 Test MSE 0.003634398176883578 Test RE 0.028815377484333052\n",
      "81 Train Loss 0.011724626 Test MSE 0.003282561655289766 Test RE 0.02738511104488632\n",
      "82 Train Loss 0.0105749555 Test MSE 0.003031917317400808 Test RE 0.02631883958759621\n",
      "83 Train Loss 0.010054914 Test MSE 0.0026629095149323366 Test RE 0.024665292215094604\n",
      "84 Train Loss 0.009057869 Test MSE 0.0019067641461748522 Test RE 0.020871638726321844\n",
      "85 Train Loss 0.008345315 Test MSE 0.001881818001186906 Test RE 0.02073465767215308\n",
      "86 Train Loss 0.007828834 Test MSE 0.002089429266348639 Test RE 0.02184851363453056\n",
      "87 Train Loss 0.0072626253 Test MSE 0.0017157398383811186 Test RE 0.01979856792917813\n",
      "88 Train Loss 0.0064913263 Test MSE 0.0016024039886896732 Test RE 0.019133484502217385\n",
      "89 Train Loss 0.006203618 Test MSE 0.0016859074874003492 Test RE 0.01962568979158297\n",
      "90 Train Loss 0.005823776 Test MSE 0.0015959859348503708 Test RE 0.019095128712169018\n",
      "91 Train Loss 0.005288517 Test MSE 0.0015241765999476759 Test RE 0.018660604362940533\n",
      "92 Train Loss 0.0049707396 Test MSE 0.0012915566276507082 Test RE 0.01717769101039646\n",
      "93 Train Loss 0.0045824694 Test MSE 0.0009395887893186408 Test RE 0.01465132740716309\n",
      "94 Train Loss 0.0041874466 Test MSE 0.0007643199340544734 Test RE 0.013214345375385354\n",
      "95 Train Loss 0.003960586 Test MSE 0.0008224699613374883 Test RE 0.013707810214806429\n",
      "96 Train Loss 0.003643926 Test MSE 0.0007728050494299048 Test RE 0.013287492604275012\n",
      "97 Train Loss 0.003428372 Test MSE 0.0007898992595009701 Test RE 0.013433646430864525\n",
      "98 Train Loss 0.0032557119 Test MSE 0.0006859720085570577 Test RE 0.012518758384491124\n",
      "99 Train Loss 0.0030746693 Test MSE 0.0006647589584735657 Test RE 0.012323672816628732\n",
      "Training time: 90.75\n",
      "KG_stan_tune7\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.917522 Test MSE 8.11939100424912 Test RE 1.3619770462451972\n",
      "1 Train Loss 56.97924 Test MSE 8.813595650199318 Test RE 1.4190072727392602\n",
      "2 Train Loss 53.385414 Test MSE 9.204669581911144 Test RE 1.450147445676003\n",
      "3 Train Loss 45.88541 Test MSE 8.475126093731324 Test RE 1.3914933798409146\n",
      "4 Train Loss 45.0908 Test MSE 8.604875022467885 Test RE 1.4021043728575056\n",
      "5 Train Loss 44.273026 Test MSE 8.455163848847778 Test RE 1.3898536574808522\n",
      "6 Train Loss 43.86843 Test MSE 8.69688593188388 Test RE 1.4095807081024179\n",
      "7 Train Loss 43.52069 Test MSE 8.535497610309724 Test RE 1.3964406509844103\n",
      "8 Train Loss 43.1054 Test MSE 8.59071835253609 Test RE 1.400950532773066\n",
      "9 Train Loss 42.650185 Test MSE 8.437088389201556 Test RE 1.3883672472166015\n",
      "10 Train Loss 42.089325 Test MSE 8.649266237774222 Test RE 1.4057163399262496\n",
      "11 Train Loss 41.306362 Test MSE 8.241462135363454 Test RE 1.372177185014803\n",
      "12 Train Loss 39.874016 Test MSE 8.41598262979815 Test RE 1.386629628022688\n",
      "13 Train Loss 38.76248 Test MSE 8.55993674571304 Test RE 1.398438390872598\n",
      "14 Train Loss 38.129604 Test MSE 8.394712348537393 Test RE 1.384876258117869\n",
      "15 Train Loss 37.506172 Test MSE 8.431818597238562 Test RE 1.3879335935060795\n",
      "16 Train Loss 37.103317 Test MSE 8.354814597934404 Test RE 1.3815813712392295\n",
      "17 Train Loss 36.418884 Test MSE 8.295930539584921 Test RE 1.376704125488062\n",
      "18 Train Loss 36.09977 Test MSE 8.267592844856082 Test RE 1.3743508033719507\n",
      "19 Train Loss 34.824806 Test MSE 8.176529259279278 Test RE 1.366760937043944\n",
      "20 Train Loss 34.11892 Test MSE 8.165057061338846 Test RE 1.3658017736081358\n",
      "21 Train Loss 32.201904 Test MSE 8.26803923653639 Test RE 1.3743879054943604\n",
      "22 Train Loss 29.519793 Test MSE 7.803701055121521 Test RE 1.3352370429716256\n",
      "23 Train Loss 27.204193 Test MSE 7.467850488216652 Test RE 1.3061885352154299\n",
      "24 Train Loss 24.987978 Test MSE 7.342327351059074 Test RE 1.2951644995327298\n",
      "25 Train Loss 23.113155 Test MSE 7.4197801133518 Test RE 1.301977795998783\n",
      "26 Train Loss 20.968218 Test MSE 7.547663516004037 Test RE 1.3131499623395722\n",
      "27 Train Loss 18.914688 Test MSE 7.448600322420617 Test RE 1.3045039426603804\n",
      "28 Train Loss 17.166918 Test MSE 7.30954198772652 Test RE 1.2922696445235922\n",
      "29 Train Loss 15.969574 Test MSE 7.282036282896007 Test RE 1.2898359565331883\n",
      "30 Train Loss 15.087086 Test MSE 7.239622098301939 Test RE 1.2860741492771914\n",
      "31 Train Loss 13.578453 Test MSE 6.696374130069879 Test RE 1.2368809913599614\n",
      "32 Train Loss 12.759388 Test MSE 6.480537876259027 Test RE 1.2167842704801242\n",
      "33 Train Loss 12.019011 Test MSE 6.402318690667986 Test RE 1.2094187699051915\n",
      "34 Train Loss 11.191495 Test MSE 6.241327405747488 Test RE 1.1941160698619133\n",
      "35 Train Loss 10.507455 Test MSE 6.238048223508696 Test RE 1.1938023354255884\n",
      "36 Train Loss 10.040249 Test MSE 6.284642428017359 Test RE 1.1982525083735236\n",
      "37 Train Loss 9.539572 Test MSE 6.306435423092646 Test RE 1.2003282757932823\n",
      "38 Train Loss 8.636124 Test MSE 6.215923156074314 Test RE 1.1916833698310716\n",
      "39 Train Loss 8.089562 Test MSE 6.317272000236913 Test RE 1.2013591169966737\n",
      "40 Train Loss 7.554774 Test MSE 6.232972524473454 Test RE 1.1933165573241984\n",
      "41 Train Loss 6.989112 Test MSE 6.070701074664756 Test RE 1.1776805011596079\n",
      "42 Train Loss 6.0325003 Test MSE 6.306036269075321 Test RE 1.2002902889272735\n",
      "43 Train Loss 5.445222 Test MSE 6.249295204674494 Test RE 1.194878042553574\n",
      "44 Train Loss 5.0434036 Test MSE 6.218711809790177 Test RE 1.1919506527057209\n",
      "45 Train Loss 4.781679 Test MSE 6.06532670053782 Test RE 1.1771590871594317\n",
      "46 Train Loss 4.4504037 Test MSE 5.995680221958058 Test RE 1.1703810764281262\n",
      "47 Train Loss 4.1937656 Test MSE 5.859545468281362 Test RE 1.157017757974729\n",
      "48 Train Loss 3.9747896 Test MSE 5.872038281986058 Test RE 1.1582505081276684\n",
      "49 Train Loss 3.7388673 Test MSE 5.762433315262777 Test RE 1.147389884008569\n",
      "50 Train Loss 3.4490867 Test MSE 5.68639503291957 Test RE 1.1397945437737476\n",
      "51 Train Loss 3.2369294 Test MSE 5.677512656500965 Test RE 1.1389039935423673\n",
      "52 Train Loss 2.9643466 Test MSE 5.610050748632886 Test RE 1.132117373749791\n",
      "53 Train Loss 2.7097504 Test MSE 5.681228620397689 Test RE 1.1392766421049332\n",
      "54 Train Loss 2.5244133 Test MSE 5.756451358613366 Test RE 1.146794179175784\n",
      "55 Train Loss 2.3339465 Test MSE 5.610716158996535 Test RE 1.1321845122063274\n",
      "56 Train Loss 2.1779366 Test MSE 5.543775980000983 Test RE 1.1254103282491965\n",
      "57 Train Loss 2.0701993 Test MSE 5.493839292762898 Test RE 1.1203301812908022\n",
      "58 Train Loss 1.9859529 Test MSE 5.456151986686056 Test RE 1.1164808799261863\n",
      "59 Train Loss 1.9029704 Test MSE 5.504898505796811 Test RE 1.1214572383846007\n",
      "60 Train Loss 1.8535991 Test MSE 5.475117060037367 Test RE 1.1184195881870653\n",
      "61 Train Loss 1.7996901 Test MSE 5.470154593554441 Test RE 1.117912623875507\n",
      "62 Train Loss 1.7585855 Test MSE 5.531709755395291 Test RE 1.1241849133933401\n",
      "63 Train Loss 1.7260437 Test MSE 5.5134352052724545 Test RE 1.1223264492111247\n",
      "64 Train Loss 1.6786363 Test MSE 5.557816745127487 Test RE 1.1268345948117149\n",
      "65 Train Loss 1.6422346 Test MSE 5.5492945897050605 Test RE 1.1259703396496517\n",
      "66 Train Loss 1.598395 Test MSE 5.545758219889259 Test RE 1.1256115118713437\n",
      "67 Train Loss 1.560252 Test MSE 5.556924051794831 Test RE 1.1267440954149506\n",
      "68 Train Loss 1.5262469 Test MSE 5.595275480368641 Test RE 1.1306255542514903\n",
      "69 Train Loss 1.4818556 Test MSE 5.658723319148701 Test RE 1.1370178695619524\n",
      "70 Train Loss 1.4566538 Test MSE 5.64932269822238 Test RE 1.1360730348141022\n",
      "71 Train Loss 1.4213539 Test MSE 5.610232329245633 Test RE 1.132135695233164\n",
      "72 Train Loss 1.3854389 Test MSE 5.700095061455609 Test RE 1.1411667509191177\n",
      "73 Train Loss 1.3524189 Test MSE 5.770409407557206 Test RE 1.1481836912829173\n",
      "74 Train Loss 1.3185238 Test MSE 5.78320049838572 Test RE 1.1494555587591107\n",
      "75 Train Loss 1.2866614 Test MSE 5.847266472180731 Test RE 1.1558048253916393\n",
      "76 Train Loss 1.2563772 Test MSE 5.828807401965172 Test RE 1.1539790195053408\n",
      "77 Train Loss 1.2348322 Test MSE 5.849366565749863 Test RE 1.156012365135693\n",
      "78 Train Loss 1.219831 Test MSE 5.823783744547621 Test RE 1.1534816240260668\n",
      "79 Train Loss 1.1969464 Test MSE 5.857994536540573 Test RE 1.1568646254210058\n",
      "80 Train Loss 1.1809852 Test MSE 5.833754713412126 Test RE 1.1544686464828195\n",
      "81 Train Loss 1.1621704 Test MSE 5.85341352322416 Test RE 1.1564121968027552\n",
      "82 Train Loss 1.1427836 Test MSE 5.861388751027532 Test RE 1.1571997296978218\n",
      "83 Train Loss 1.1075412 Test MSE 5.933460997925351 Test RE 1.1642925171338507\n",
      "84 Train Loss 1.0845283 Test MSE 5.9304744260351105 Test RE 1.1639994604357928\n",
      "85 Train Loss 1.057136 Test MSE 5.947965548939458 Test RE 1.1657147252065871\n",
      "86 Train Loss 1.0373287 Test MSE 6.050969908050869 Test RE 1.1757650780440319\n",
      "87 Train Loss 1.0202029 Test MSE 6.057918776363465 Test RE 1.1764400022719699\n",
      "88 Train Loss 1.001908 Test MSE 6.064661860417007 Test RE 1.1770945692796877\n",
      "89 Train Loss 0.97942436 Test MSE 6.117389705020396 Test RE 1.182200487815775\n",
      "90 Train Loss 0.9554684 Test MSE 6.093416547435184 Test RE 1.1798817783141038\n",
      "91 Train Loss 0.9398685 Test MSE 6.108379336319769 Test RE 1.1813295291174957\n",
      "92 Train Loss 0.92616904 Test MSE 6.15383794716269 Test RE 1.185717113327903\n",
      "93 Train Loss 0.9110117 Test MSE 6.161291109191014 Test RE 1.1864349310251598\n",
      "94 Train Loss 0.89367646 Test MSE 6.216024944956256 Test RE 1.1916931269997344\n",
      "95 Train Loss 0.87645996 Test MSE 6.215850370463261 Test RE 1.1916763927776246\n",
      "96 Train Loss 0.86190903 Test MSE 6.263477600832376 Test RE 1.1962331257659484\n",
      "97 Train Loss 0.8551259 Test MSE 6.249329439905418 Test RE 1.194881315472227\n",
      "98 Train Loss 0.8442192 Test MSE 6.259100234374189 Test RE 1.195815046042616\n",
      "99 Train Loss 0.83570373 Test MSE 6.281371945043352 Test RE 1.197940686782873\n",
      "Training time: 90.50\n",
      "KG_stan_tune7\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.918056 Test MSE 8.044940779398702 Test RE 1.3557183863818671\n",
      "1 Train Loss 51.302505 Test MSE 8.430075336099021 Test RE 1.387790109882642\n",
      "2 Train Loss 46.737595 Test MSE 8.533829671223582 Test RE 1.3963042036530375\n",
      "3 Train Loss 45.66651 Test MSE 8.557951374179174 Test RE 1.3982762062173064\n",
      "4 Train Loss 44.70316 Test MSE 8.273271565055746 Test RE 1.3748227190858908\n",
      "5 Train Loss 44.067047 Test MSE 8.67097501141679 Test RE 1.4074793365051703\n",
      "6 Train Loss 43.367546 Test MSE 8.551968911656596 Test RE 1.397787386109333\n",
      "7 Train Loss 42.552963 Test MSE 8.412668672181121 Test RE 1.3863565948859407\n",
      "8 Train Loss 41.101654 Test MSE 8.363590424525526 Test RE 1.382306781491699\n",
      "9 Train Loss 38.238815 Test MSE 8.275701810728238 Test RE 1.3750246290322683\n",
      "10 Train Loss 36.48591 Test MSE 8.186940973405344 Test RE 1.3676308536358979\n",
      "11 Train Loss 34.41392 Test MSE 8.346689934264372 Test RE 1.3809094464413836\n",
      "12 Train Loss 33.372246 Test MSE 8.422793104782336 Test RE 1.3871905664815058\n",
      "13 Train Loss 31.683302 Test MSE 8.598730892981497 Test RE 1.4016037119452232\n",
      "14 Train Loss 29.447765 Test MSE 8.46717881715001 Test RE 1.390840812769817\n",
      "15 Train Loss 26.89885 Test MSE 8.0257045934343 Test RE 1.3540965932820963\n",
      "16 Train Loss 25.307045 Test MSE 7.715529442591845 Test RE 1.3276723987622434\n",
      "17 Train Loss 24.170273 Test MSE 7.434012131987326 Test RE 1.303225871744216\n",
      "18 Train Loss 22.749018 Test MSE 6.692086884921059 Test RE 1.2364849814478385\n",
      "19 Train Loss 20.73711 Test MSE 5.7347182167949 Test RE 1.1446273051995406\n",
      "20 Train Loss 17.397572 Test MSE 4.881508907213089 Test RE 1.0560515135349877\n",
      "21 Train Loss 12.6602545 Test MSE 3.9537335312592954 Test RE 0.950411665453076\n",
      "22 Train Loss 8.736659 Test MSE 3.19274372090527 Test RE 0.8540633586625296\n",
      "23 Train Loss 5.5779543 Test MSE 2.8956153447876956 Test RE 0.8133519177354815\n",
      "24 Train Loss 3.9829686 Test MSE 2.854280664263797 Test RE 0.8075257838823504\n",
      "25 Train Loss 2.631183 Test MSE 2.7852015247463635 Test RE 0.797694086270688\n",
      "26 Train Loss 1.9186146 Test MSE 2.9370095788066757 Test RE 0.8191449189923584\n",
      "27 Train Loss 1.4538397 Test MSE 3.022744337476026 Test RE 0.8310148190866669\n",
      "28 Train Loss 1.2753872 Test MSE 3.042062181727574 Test RE 0.8336660270666613\n",
      "29 Train Loss 1.0774086 Test MSE 3.0974489424214116 Test RE 0.8412210632996764\n",
      "30 Train Loss 0.9429684 Test MSE 3.1143785337144645 Test RE 0.8435168431861545\n",
      "31 Train Loss 0.8621445 Test MSE 3.121178205748441 Test RE 0.8444371729666273\n",
      "32 Train Loss 0.7901207 Test MSE 3.1257379002701704 Test RE 0.8450537622930513\n",
      "33 Train Loss 0.7524276 Test MSE 3.1421149704438798 Test RE 0.847264668130076\n",
      "34 Train Loss 0.7172354 Test MSE 3.176895862391448 Test RE 0.8519410597369522\n",
      "35 Train Loss 0.6849346 Test MSE 3.118526024671424 Test RE 0.8440783218992828\n",
      "36 Train Loss 0.65415186 Test MSE 3.117302588486096 Test RE 0.843912734494073\n",
      "37 Train Loss 0.63172686 Test MSE 3.115103288457053 Test RE 0.8436149859236695\n",
      "38 Train Loss 0.6088971 Test MSE 3.133671792880604 Test RE 0.8461255598885205\n",
      "39 Train Loss 0.5926867 Test MSE 3.1396970465588394 Test RE 0.8469386113556753\n",
      "40 Train Loss 0.56974256 Test MSE 3.1413565390932487 Test RE 0.8471624072526248\n",
      "41 Train Loss 0.5476181 Test MSE 3.1787210943523534 Test RE 0.8521857587818991\n",
      "42 Train Loss 0.52777404 Test MSE 3.2240672861292494 Test RE 0.8582426814909564\n",
      "43 Train Loss 0.5190301 Test MSE 3.2148229803606987 Test RE 0.8570113869204804\n",
      "44 Train Loss 0.5012691 Test MSE 3.2479032843694724 Test RE 0.8614093957427343\n",
      "45 Train Loss 0.48472625 Test MSE 3.290029876531434 Test RE 0.8669778083283196\n",
      "46 Train Loss 0.47285944 Test MSE 3.3219668115229197 Test RE 0.8711756035570378\n",
      "47 Train Loss 0.46240392 Test MSE 3.303206314571425 Test RE 0.8687121792617044\n",
      "48 Train Loss 0.4499187 Test MSE 3.3419380742448888 Test RE 0.8737903807005096\n",
      "49 Train Loss 0.44369185 Test MSE 3.3503772458167504 Test RE 0.8748929471359989\n",
      "50 Train Loss 0.43445045 Test MSE 3.353100143546349 Test RE 0.8752483937052367\n",
      "51 Train Loss 0.42645273 Test MSE 3.3312163790695597 Test RE 0.8723875958406779\n",
      "52 Train Loss 0.41675246 Test MSE 3.3573983011692268 Test RE 0.8758091808282803\n",
      "53 Train Loss 0.4108545 Test MSE 3.39266404163113 Test RE 0.8803968665527718\n",
      "54 Train Loss 0.40406168 Test MSE 3.3865121092162247 Test RE 0.8795982906457707\n",
      "55 Train Loss 0.398089 Test MSE 3.405653988348655 Test RE 0.8820807029454379\n",
      "56 Train Loss 0.39360714 Test MSE 3.425274618941414 Test RE 0.8846179724418437\n",
      "57 Train Loss 0.38726094 Test MSE 3.440539767386602 Test RE 0.8865869843087769\n",
      "58 Train Loss 0.38188207 Test MSE 3.4390122722094296 Test RE 0.8863901536107023\n",
      "59 Train Loss 0.37457588 Test MSE 3.4598816153177117 Test RE 0.8890755760029277\n",
      "60 Train Loss 0.36898097 Test MSE 3.4724133193839077 Test RE 0.8906842381942929\n",
      "61 Train Loss 0.36567542 Test MSE 3.481696494988367 Test RE 0.8918740244639407\n",
      "62 Train Loss 0.36220723 Test MSE 3.488595398646258 Test RE 0.8927572013878895\n",
      "63 Train Loss 0.35823202 Test MSE 3.5055609925710494 Test RE 0.8949253786230075\n",
      "64 Train Loss 0.35394308 Test MSE 3.5180669607627695 Test RE 0.896520265207615\n",
      "65 Train Loss 0.3501622 Test MSE 3.52643900041953 Test RE 0.8975863681585879\n",
      "66 Train Loss 0.34629965 Test MSE 3.5350895774489315 Test RE 0.8986866117841174\n",
      "67 Train Loss 0.34329492 Test MSE 3.5505470705242996 Test RE 0.9006492621629629\n",
      "68 Train Loss 0.33986706 Test MSE 3.558056146664941 Test RE 0.9016011537624421\n",
      "69 Train Loss 0.33624232 Test MSE 3.58940377480233 Test RE 0.9055641433256528\n",
      "70 Train Loss 0.33376908 Test MSE 3.581327252273596 Test RE 0.9045447639938429\n",
      "71 Train Loss 0.33018392 Test MSE 3.6005907940944137 Test RE 0.9069742218546817\n",
      "72 Train Loss 0.32558662 Test MSE 3.6079493335328436 Test RE 0.9079005419394595\n",
      "73 Train Loss 0.32304302 Test MSE 3.61592946089789 Test RE 0.9089040427469188\n",
      "74 Train Loss 0.32069862 Test MSE 3.6202270496466262 Test RE 0.9094440056949268\n",
      "75 Train Loss 0.31815296 Test MSE 3.63317214834027 Test RE 0.9110685359770397\n",
      "76 Train Loss 0.31517497 Test MSE 3.636287485627553 Test RE 0.9114590593942912\n",
      "77 Train Loss 0.31238747 Test MSE 3.6641758186748277 Test RE 0.9149475792540364\n",
      "78 Train Loss 0.31059504 Test MSE 3.6718336650474117 Test RE 0.9159031653655271\n",
      "79 Train Loss 0.30878806 Test MSE 3.6677993610583246 Test RE 0.9153998681526349\n",
      "80 Train Loss 0.306786 Test MSE 3.686994102278794 Test RE 0.9177920294127948\n",
      "81 Train Loss 0.3040644 Test MSE 3.7131846287588814 Test RE 0.9210460243026709\n",
      "82 Train Loss 0.30240378 Test MSE 3.718961978356609 Test RE 0.9217622742606939\n",
      "83 Train Loss 0.30092603 Test MSE 3.7286354882803288 Test RE 0.9229603082451292\n",
      "84 Train Loss 0.29838628 Test MSE 3.7203755053875636 Test RE 0.9219374322906522\n",
      "85 Train Loss 0.29748705 Test MSE 3.733600194432417 Test RE 0.9235745681308425\n",
      "86 Train Loss 0.29628175 Test MSE 3.739313813941652 Test RE 0.9242809823257934\n",
      "87 Train Loss 0.2944853 Test MSE 3.744275742848588 Test RE 0.9248940220874741\n",
      "88 Train Loss 0.29338175 Test MSE 3.7558585949892223 Test RE 0.9263234892498798\n",
      "89 Train Loss 0.29224113 Test MSE 3.760379418888361 Test RE 0.9268808166694247\n",
      "90 Train Loss 0.29127005 Test MSE 3.7705131489596377 Test RE 0.9281288875961256\n",
      "91 Train Loss 0.29007205 Test MSE 3.783673544840894 Test RE 0.9297472222128355\n",
      "92 Train Loss 0.28877982 Test MSE 3.797712321472471 Test RE 0.9314704719148253\n",
      "93 Train Loss 0.2877392 Test MSE 3.794530973722247 Test RE 0.931080243259268\n",
      "94 Train Loss 0.28688407 Test MSE 3.7952163323141415 Test RE 0.931164324142703\n",
      "95 Train Loss 0.28564656 Test MSE 3.8127636919122394 Test RE 0.9333144824954815\n",
      "96 Train Loss 0.284422 Test MSE 3.82579852268601 Test RE 0.9349084989775845\n",
      "97 Train Loss 0.28306162 Test MSE 3.833820292036241 Test RE 0.9358881236485921\n",
      "98 Train Loss 0.28221214 Test MSE 3.8458366175041823 Test RE 0.9373536511381971\n",
      "99 Train Loss 0.28108054 Test MSE 3.851943585673445 Test RE 0.9380975878653741\n",
      "Training time: 90.42\n",
      "KG_stan_tune7\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.897717 Test MSE 9.139042280399142 Test RE 1.4449685794329996\n",
      "1 Train Loss 44.702354 Test MSE 8.512560837083544 Test RE 1.3945631160837015\n",
      "2 Train Loss 42.315212 Test MSE 8.119890803999757 Test RE 1.362018964740837\n",
      "3 Train Loss 40.52249 Test MSE 8.055791834045882 Test RE 1.356632378012416\n",
      "4 Train Loss 38.09407 Test MSE 7.430532434456997 Test RE 1.3029208303644852\n",
      "5 Train Loss 35.14582 Test MSE 7.0918938245842185 Test RE 1.2728850120030601\n",
      "6 Train Loss 30.676655 Test MSE 5.815500477210754 Test RE 1.1526610238017043\n",
      "7 Train Loss 24.657106 Test MSE 5.123385700591289 Test RE 1.0818986682171283\n",
      "8 Train Loss 20.686155 Test MSE 5.213493572060731 Test RE 1.0913711809253868\n",
      "9 Train Loss 15.741943 Test MSE 3.9850703042779627 Test RE 0.9541706509038402\n",
      "10 Train Loss 11.45594 Test MSE 3.8704955229427007 Test RE 0.9403539323024032\n",
      "11 Train Loss 9.892484 Test MSE 3.9738649934169055 Test RE 0.9528282272610284\n",
      "12 Train Loss 9.076915 Test MSE 3.8918273937266745 Test RE 0.9429417076063447\n",
      "13 Train Loss 8.644967 Test MSE 3.903133538399383 Test RE 0.9443103838953341\n",
      "14 Train Loss 8.294007 Test MSE 3.8267076963859568 Test RE 0.93501957954303\n",
      "15 Train Loss 8.02364 Test MSE 3.8198689560292918 Test RE 0.9341837153945919\n",
      "16 Train Loss 7.8494296 Test MSE 3.768321423834443 Test RE 0.9278590968516645\n",
      "17 Train Loss 7.7124133 Test MSE 3.7718214957894265 Test RE 0.9282899013783288\n",
      "18 Train Loss 7.5142174 Test MSE 3.7495402084418434 Test RE 0.9255439959154582\n",
      "19 Train Loss 7.2438793 Test MSE 3.6337226303053054 Test RE 0.9111375538740257\n",
      "20 Train Loss 6.523097 Test MSE 2.934483281816691 Test RE 0.8187925455180045\n",
      "21 Train Loss 5.382407 Test MSE 2.5580558420216937 Test RE 0.7644746181885247\n",
      "22 Train Loss 4.38112 Test MSE 2.1444914807688344 Test RE 0.6999551655892032\n",
      "23 Train Loss 2.8663228 Test MSE 1.6733717395179801 Test RE 0.6183071595976697\n",
      "24 Train Loss 1.8166233 Test MSE 1.2859507550274638 Test RE 0.5420261370527337\n",
      "25 Train Loss 1.2290539 Test MSE 0.9385371996754718 Test RE 0.46305630902901407\n",
      "26 Train Loss 0.63369226 Test MSE 0.2569420695232595 Test RE 0.24228452112749796\n",
      "27 Train Loss 0.39272913 Test MSE 0.1656456765431441 Test RE 0.19453516281196537\n",
      "28 Train Loss 0.26781383 Test MSE 0.13900189018066525 Test RE 0.1782043960433954\n",
      "29 Train Loss 0.18945202 Test MSE 0.09335704721261201 Test RE 0.14604329194273227\n",
      "30 Train Loss 0.1512574 Test MSE 0.0691156236323881 Test RE 0.1256597454980646\n",
      "31 Train Loss 0.11911614 Test MSE 0.04550656777573388 Test RE 0.10196358597371535\n",
      "32 Train Loss 0.097459085 Test MSE 0.03718185693309264 Test RE 0.09216660662839474\n",
      "33 Train Loss 0.079250224 Test MSE 0.02459462437904546 Test RE 0.07495975481883523\n",
      "34 Train Loss 0.070458174 Test MSE 0.016384112613343306 Test RE 0.06118141575447258\n",
      "35 Train Loss 0.059983283 Test MSE 0.012706700427439686 Test RE 0.053879611534094866\n",
      "36 Train Loss 0.048555184 Test MSE 0.011884389277828998 Test RE 0.052107050970131144\n",
      "37 Train Loss 0.04215107 Test MSE 0.01102841899163742 Test RE 0.05019548894950248\n",
      "38 Train Loss 0.037041783 Test MSE 0.009301639961155813 Test RE 0.04609860920314525\n",
      "39 Train Loss 0.032298896 Test MSE 0.007421676520104893 Test RE 0.041177414201167835\n",
      "40 Train Loss 0.027418062 Test MSE 0.007068934319242189 Test RE 0.040186948793744376\n",
      "41 Train Loss 0.025071857 Test MSE 0.005708886670764046 Test RE 0.03611468000654233\n",
      "42 Train Loss 0.021461168 Test MSE 0.005670075810236662 Test RE 0.035991711008775795\n",
      "43 Train Loss 0.018987488 Test MSE 0.0046258983654548546 Test RE 0.032509186625646606\n",
      "44 Train Loss 0.016309248 Test MSE 0.003886592747473876 Test RE 0.029798374792618914\n",
      "45 Train Loss 0.014345961 Test MSE 0.0032853007416277086 Test RE 0.0273965342183305\n",
      "46 Train Loss 0.01293917 Test MSE 0.003015649589688558 Test RE 0.02624813786276225\n",
      "47 Train Loss 0.01086033 Test MSE 0.0023978401200212365 Test RE 0.023405513382308563\n",
      "48 Train Loss 0.009889958 Test MSE 0.0021711493188845796 Test RE 0.022271676338875227\n",
      "49 Train Loss 0.008916767 Test MSE 0.002010264907541975 Test RE 0.021430618537949534\n",
      "50 Train Loss 0.007852551 Test MSE 0.0016523861787649241 Test RE 0.019429598985466312\n",
      "51 Train Loss 0.0072196997 Test MSE 0.001665960607598784 Test RE 0.01950924327650772\n",
      "52 Train Loss 0.0060405564 Test MSE 0.0014515465214745894 Test RE 0.018210570013096276\n",
      "53 Train Loss 0.005680156 Test MSE 0.0014899276855392324 Test RE 0.018449757208136762\n",
      "54 Train Loss 0.005063105 Test MSE 0.0015303702311934315 Test RE 0.01869848046137825\n",
      "55 Train Loss 0.0046824664 Test MSE 0.001856743930292547 Test RE 0.020596056129458244\n",
      "56 Train Loss 0.004167575 Test MSE 0.0015370372789836767 Test RE 0.018739166101082862\n",
      "57 Train Loss 0.0038317053 Test MSE 0.0014859444931087592 Test RE 0.018425078790416972\n",
      "58 Train Loss 0.0033045304 Test MSE 0.0012557260663959408 Test RE 0.016937742066466595\n",
      "59 Train Loss 0.0031106572 Test MSE 0.0011158970100280977 Test RE 0.015966882055229992\n",
      "60 Train Loss 0.0028732785 Test MSE 0.0010081843881880256 Test RE 0.015176724282466473\n",
      "61 Train Loss 0.0027401354 Test MSE 0.0009751046724145926 Test RE 0.01492566462753324\n",
      "62 Train Loss 0.00254999 Test MSE 0.000936588002031554 Test RE 0.014627912548917649\n",
      "63 Train Loss 0.0023655128 Test MSE 0.0008565896334857426 Test RE 0.013989251157406141\n",
      "64 Train Loss 0.0022066997 Test MSE 0.0008156881441201612 Test RE 0.013651178180043534\n",
      "65 Train Loss 0.002064945 Test MSE 0.0008137406333695649 Test RE 0.01363487188437911\n",
      "66 Train Loss 0.0019126 Test MSE 0.0006969295916506598 Test RE 0.012618348355043734\n",
      "67 Train Loss 0.0018537684 Test MSE 0.0006902941302021742 Test RE 0.012558135089426239\n",
      "68 Train Loss 0.0017150997 Test MSE 0.0006018262525640581 Test RE 0.011725830835470283\n",
      "69 Train Loss 0.0016645868 Test MSE 0.0006258708406379938 Test RE 0.011957776156511305\n",
      "70 Train Loss 0.0016160394 Test MSE 0.000615893649372581 Test RE 0.011862082037904969\n",
      "71 Train Loss 0.0014602073 Test MSE 0.0005541981212164758 Test RE 0.01125228140713807\n",
      "72 Train Loss 0.001411903 Test MSE 0.0005076378729171884 Test RE 0.010769240309855491\n",
      "73 Train Loss 0.0013630169 Test MSE 0.0005012234514736716 Test RE 0.010700984910634717\n",
      "74 Train Loss 0.0012682298 Test MSE 0.0004898264725378582 Test RE 0.010578624134956187\n",
      "75 Train Loss 0.0012386157 Test MSE 0.00046733228948480515 Test RE 0.010332869743871688\n",
      "76 Train Loss 0.0012073038 Test MSE 0.00043717649591318227 Test RE 0.009993933669312616\n",
      "77 Train Loss 0.0011638288 Test MSE 0.00041453641382292646 Test RE 0.009731715480386932\n",
      "78 Train Loss 0.001094021 Test MSE 0.0003852685482354006 Test RE 0.009381879238169064\n",
      "79 Train Loss 0.0010583967 Test MSE 0.0003771707747766969 Test RE 0.009282759039056536\n",
      "80 Train Loss 0.0010275746 Test MSE 0.00036557411911603954 Test RE 0.009138939059807913\n",
      "81 Train Loss 0.0009500374 Test MSE 0.0003177333433989423 Test RE 0.008519997290153094\n",
      "82 Train Loss 0.0009207013 Test MSE 0.0003395486023108196 Test RE 0.008807629427684852\n",
      "83 Train Loss 0.0008793288 Test MSE 0.00029565397042514107 Test RE 0.008218639254037674\n",
      "84 Train Loss 0.0008541359 Test MSE 0.000258814978709498 Test RE 0.007689582555056124\n",
      "85 Train Loss 0.00081831147 Test MSE 0.00023536498113223454 Test RE 0.007332954387503655\n",
      "86 Train Loss 0.0007906916 Test MSE 0.000219784954006382 Test RE 0.007086096125650032\n",
      "87 Train Loss 0.0007774204 Test MSE 0.00023136042322159664 Test RE 0.007270304410314396\n",
      "88 Train Loss 0.0007637679 Test MSE 0.00023037689080803052 Test RE 0.007254834617408543\n",
      "89 Train Loss 0.0007433209 Test MSE 0.0002279523744124808 Test RE 0.007216558232556732\n",
      "90 Train Loss 0.0007033805 Test MSE 0.00021826638756827066 Test RE 0.0070615736108809056\n",
      "91 Train Loss 0.00068326306 Test MSE 0.00022414293525931098 Test RE 0.007156004215703769\n",
      "92 Train Loss 0.00066077785 Test MSE 0.00020633959534048366 Test RE 0.0068659296231798825\n",
      "93 Train Loss 0.0006218636 Test MSE 0.00018167811697430611 Test RE 0.006442573327240602\n",
      "94 Train Loss 0.0005974389 Test MSE 0.00018912561727292665 Test RE 0.006573296760257304\n",
      "95 Train Loss 0.0005721195 Test MSE 0.00017574281265065575 Test RE 0.0063364621737571555\n",
      "96 Train Loss 0.000555327 Test MSE 0.0001635226262313593 Test RE 0.006112191984304698\n",
      "97 Train Loss 0.00053524866 Test MSE 0.00016041396172380954 Test RE 0.006053814965173342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 Train Loss 0.0005244581 Test MSE 0.00017466820800955506 Test RE 0.0063170598652141224\n",
      "99 Train Loss 0.0005112335 Test MSE 0.00017324005853962973 Test RE 0.006291181593635949\n",
      "Training time: 91.03\n",
      "KG_stan_tune7\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 57.24431 Test MSE 7.604454928812077 Test RE 1.3180810170332964\n",
      "1 Train Loss 52.235905 Test MSE 8.10638484083528 Test RE 1.3608857577727937\n",
      "2 Train Loss 45.213028 Test MSE 8.945661628509542 Test RE 1.429599190936968\n",
      "3 Train Loss 43.623238 Test MSE 8.442339050114754 Test RE 1.3887991919515985\n",
      "4 Train Loss 42.76602 Test MSE 8.401368585749156 Test RE 1.3854251892756217\n",
      "5 Train Loss 41.316208 Test MSE 8.634522106289003 Test RE 1.4045176887180808\n",
      "6 Train Loss 40.089836 Test MSE 8.681607981490647 Test RE 1.408342048048979\n",
      "7 Train Loss 38.102783 Test MSE 9.040071099392085 Test RE 1.4371231435940983\n",
      "8 Train Loss 34.64393 Test MSE 9.185006961478873 Test RE 1.4485977462401747\n",
      "9 Train Loss 29.359821 Test MSE 8.472092237114767 Test RE 1.391244299814199\n",
      "10 Train Loss 24.283575 Test MSE 7.545220434742815 Test RE 1.312937420292015\n",
      "11 Train Loss 19.612066 Test MSE 7.5295297410159705 Test RE 1.3115715476548944\n",
      "12 Train Loss 17.885445 Test MSE 7.0012684799458675 Test RE 1.2647259402646114\n",
      "13 Train Loss 15.69912 Test MSE 6.181917635733119 Test RE 1.1884192216348255\n",
      "14 Train Loss 12.3716 Test MSE 5.945438863938135 Test RE 1.1654671021534837\n",
      "15 Train Loss 9.939894 Test MSE 5.114407877759441 Test RE 1.0809503350266008\n",
      "16 Train Loss 7.1047215 Test MSE 4.6378959898587375 Test RE 1.0293630214230236\n",
      "17 Train Loss 5.623102 Test MSE 4.576042616604715 Test RE 1.0224759237652516\n",
      "18 Train Loss 4.606526 Test MSE 4.198487848050138 Test RE 0.9793873957134653\n",
      "19 Train Loss 3.7720375 Test MSE 3.9981065171992602 Test RE 0.955730048204365\n",
      "20 Train Loss 3.3024573 Test MSE 3.880890691038526 Test RE 0.9416158614989267\n",
      "21 Train Loss 2.83193 Test MSE 3.8276448633587865 Test RE 0.9351340664460063\n",
      "22 Train Loss 2.4194844 Test MSE 3.725469703065293 Test RE 0.9225684068945446\n",
      "23 Train Loss 2.2071257 Test MSE 3.7412798282014075 Test RE 0.9245239294137275\n",
      "24 Train Loss 2.0014038 Test MSE 3.66539278989907 Test RE 0.9150995059755136\n",
      "25 Train Loss 1.8228378 Test MSE 3.5942785853738024 Test RE 0.9061788632238236\n",
      "26 Train Loss 1.6634309 Test MSE 3.504631628771977 Test RE 0.8948067433485327\n",
      "27 Train Loss 1.5045066 Test MSE 3.4052675493390447 Test RE 0.8820306567480577\n",
      "28 Train Loss 1.3779172 Test MSE 3.3156351320499713 Test RE 0.8703449758163028\n",
      "29 Train Loss 1.2426543 Test MSE 3.2302041037656526 Test RE 0.8590590997668168\n",
      "30 Train Loss 1.1309215 Test MSE 3.147218890162886 Test RE 0.8479525195025933\n",
      "31 Train Loss 1.0403405 Test MSE 3.0542838554522667 Test RE 0.8353390009487243\n",
      "32 Train Loss 0.96366525 Test MSE 2.9909280081740874 Test RE 0.8266297668216791\n",
      "33 Train Loss 0.8978874 Test MSE 2.9461364552882556 Test RE 0.8204166947777704\n",
      "34 Train Loss 0.8345306 Test MSE 2.9169375794912114 Test RE 0.8163410356841492\n",
      "35 Train Loss 0.7569299 Test MSE 2.9182697079234656 Test RE 0.816527420710259\n",
      "36 Train Loss 0.63742226 Test MSE 2.9416319677582696 Test RE 0.819789267894126\n",
      "37 Train Loss 0.5704395 Test MSE 2.9571900256881727 Test RE 0.8219543091622523\n",
      "38 Train Loss 0.51931894 Test MSE 3.0182902724144487 Test RE 0.8304023361605248\n",
      "39 Train Loss 0.49646616 Test MSE 3.0642151016546237 Test RE 0.836695984266918\n",
      "40 Train Loss 0.47249356 Test MSE 3.0976800210469118 Test RE 0.8412524414733472\n",
      "41 Train Loss 0.446956 Test MSE 3.142745649654773 Test RE 0.8473496945225689\n",
      "42 Train Loss 0.4308533 Test MSE 3.143692794252513 Test RE 0.8474773698606449\n",
      "43 Train Loss 0.4076853 Test MSE 3.1867062674185274 Test RE 0.8532554629740602\n",
      "44 Train Loss 0.39709753 Test MSE 3.2480042636508064 Test RE 0.8614227865087163\n",
      "45 Train Loss 0.38594753 Test MSE 3.2633636985090324 Test RE 0.8634571684015374\n",
      "46 Train Loss 0.37929085 Test MSE 3.278246573906329 Test RE 0.8654238672153401\n",
      "47 Train Loss 0.36884087 Test MSE 3.301892664626267 Test RE 0.868539423296791\n",
      "48 Train Loss 0.3621322 Test MSE 3.3173191407477174 Test RE 0.870565971552444\n",
      "49 Train Loss 0.3547246 Test MSE 3.33586442765787 Test RE 0.8729960052033233\n",
      "50 Train Loss 0.34752703 Test MSE 3.354323822970857 Test RE 0.8754080855885598\n",
      "51 Train Loss 0.34064224 Test MSE 3.3288462003078627 Test RE 0.872077186331843\n",
      "52 Train Loss 0.33458573 Test MSE 3.355336354637796 Test RE 0.8755402003715642\n",
      "53 Train Loss 0.32903907 Test MSE 3.3796306124127717 Test RE 0.8787041507896513\n",
      "54 Train Loss 0.32462028 Test MSE 3.382018750208995 Test RE 0.8790145539457228\n",
      "55 Train Loss 0.3190868 Test MSE 3.425822782218888 Test RE 0.8846887544581424\n",
      "56 Train Loss 0.31560385 Test MSE 3.4400649557041962 Test RE 0.8865258054806288\n",
      "57 Train Loss 0.31222403 Test MSE 3.4682151366815215 Test RE 0.8901456522454053\n",
      "58 Train Loss 0.30795994 Test MSE 3.495947859219923 Test RE 0.8936974805707635\n",
      "59 Train Loss 0.30336022 Test MSE 3.5169725246612766 Test RE 0.8963808050330405\n",
      "60 Train Loss 0.30067748 Test MSE 3.5445251139628446 Test RE 0.8998851584485037\n",
      "61 Train Loss 0.29725325 Test MSE 3.544022619521171 Test RE 0.8998213694636467\n",
      "62 Train Loss 0.29285645 Test MSE 3.5697083396387557 Test RE 0.9030762630766076\n",
      "63 Train Loss 0.28921366 Test MSE 3.5761215462609424 Test RE 0.9038871158415254\n",
      "64 Train Loss 0.28463435 Test MSE 3.6079295787653374 Test RE 0.9078980564016902\n",
      "65 Train Loss 0.2819719 Test MSE 3.622370452513298 Test RE 0.9097131899780753\n",
      "66 Train Loss 0.27968442 Test MSE 3.6280816409679866 Test RE 0.9104300544274766\n",
      "67 Train Loss 0.27792704 Test MSE 3.6431732668533434 Test RE 0.9123216341162025\n",
      "68 Train Loss 0.27567828 Test MSE 3.64997926522047 Test RE 0.9131734138483556\n",
      "69 Train Loss 0.27255714 Test MSE 3.6410418880279134 Test RE 0.912054725661181\n",
      "70 Train Loss 0.27051073 Test MSE 3.660847119023331 Test RE 0.9145318953677346\n",
      "71 Train Loss 0.26766548 Test MSE 3.680422871208537 Test RE 0.9169737865620193\n",
      "72 Train Loss 0.26620632 Test MSE 3.6966133074931427 Test RE 0.9189884890332034\n",
      "73 Train Loss 0.2636183 Test MSE 3.707179997328762 Test RE 0.9203010061923602\n",
      "74 Train Loss 0.2616426 Test MSE 3.71486416929759 Test RE 0.9212543036374544\n",
      "75 Train Loss 0.25876173 Test MSE 3.732903997382258 Test RE 0.923488455554039\n",
      "76 Train Loss 0.2564562 Test MSE 3.742582094022533 Test RE 0.9246848196996087\n",
      "77 Train Loss 0.25491238 Test MSE 3.753880572656552 Test RE 0.9260795330665155\n",
      "78 Train Loss 0.25305778 Test MSE 3.7545397638317057 Test RE 0.9261608404824657\n",
      "79 Train Loss 0.25152326 Test MSE 3.7611575809126307 Test RE 0.9269767147241199\n",
      "80 Train Loss 0.25000668 Test MSE 3.7815270237927203 Test RE 0.9294834567098702\n",
      "81 Train Loss 0.24894577 Test MSE 3.787240728213472 Test RE 0.9301853939336718\n",
      "82 Train Loss 0.24629009 Test MSE 3.8164410159587874 Test RE 0.9337644543426745\n",
      "83 Train Loss 0.24493663 Test MSE 3.8309204213980452 Test RE 0.935534107591354\n",
      "84 Train Loss 0.24266961 Test MSE 3.8342433670167626 Test RE 0.9359397614271653\n",
      "85 Train Loss 0.24106449 Test MSE 3.835127928340089 Test RE 0.9360477160209667\n",
      "86 Train Loss 0.23991477 Test MSE 3.8495896557470175 Test RE 0.937810907466088\n",
      "87 Train Loss 0.2388701 Test MSE 3.858342043775916 Test RE 0.9388764008738167\n",
      "88 Train Loss 0.23715168 Test MSE 3.8630289316574404 Test RE 0.9394464738283455\n",
      "89 Train Loss 0.2358283 Test MSE 3.8850278029742658 Test RE 0.9421176190711409\n",
      "90 Train Loss 0.23466206 Test MSE 3.8830690619160593 Test RE 0.9418800921843473\n",
      "91 Train Loss 0.23369455 Test MSE 3.8820878015602442 Test RE 0.9417610770476397\n",
      "92 Train Loss 0.23302859 Test MSE 3.899257664577656 Test RE 0.9438414098097133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Train Loss 0.23188242 Test MSE 3.920077766904152 Test RE 0.9463578776527612\n",
      "94 Train Loss 0.23032877 Test MSE 3.9340638490444566 Test RE 0.9480445858100897\n",
      "95 Train Loss 0.22849417 Test MSE 3.958189071681408 Test RE 0.9509470335068945\n",
      "96 Train Loss 0.22716029 Test MSE 3.977456014566454 Test RE 0.9532586462201992\n",
      "97 Train Loss 0.22560005 Test MSE 3.9955994931580667 Test RE 0.9554303545961685\n",
      "98 Train Loss 0.2246746 Test MSE 4.000849458378865 Test RE 0.9560578360984787\n",
      "99 Train Loss 0.2235108 Test MSE 4.011095405363679 Test RE 0.957281258081\n",
      "Training time: 90.67\n",
      "KG_stan_tune7\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 54.898018 Test MSE 7.916579884359022 Test RE 1.3448593277552738\n",
      "1 Train Loss 46.081085 Test MSE 9.025881127044975 Test RE 1.4359947925987664\n",
      "2 Train Loss 43.36744 Test MSE 8.58311041309329 Test RE 1.4003300545323971\n",
      "3 Train Loss 42.333603 Test MSE 8.104096779980582 Test RE 1.3606936863844847\n",
      "4 Train Loss 41.780952 Test MSE 8.51346563098801 Test RE 1.394637227664459\n",
      "5 Train Loss 40.79419 Test MSE 8.294166639701045 Test RE 1.3765577587043405\n",
      "6 Train Loss 39.697514 Test MSE 8.544589382954607 Test RE 1.3971841777476852\n",
      "7 Train Loss 37.917015 Test MSE 8.178431916870224 Test RE 1.3669199486933774\n",
      "8 Train Loss 35.9122 Test MSE 8.45217709713089 Test RE 1.389608155765531\n",
      "9 Train Loss 32.91901 Test MSE 8.326402615249451 Test RE 1.3792302182339409\n",
      "10 Train Loss 28.542624 Test MSE 7.3647330815264995 Test RE 1.2971391460210593\n",
      "11 Train Loss 25.610647 Test MSE 6.945987567032327 Test RE 1.2597230067119372\n",
      "12 Train Loss 21.709202 Test MSE 6.646500255310911 Test RE 1.2322663045398259\n",
      "13 Train Loss 18.161049 Test MSE 6.301908133934568 Test RE 1.1998973502020407\n",
      "14 Train Loss 15.588047 Test MSE 5.1298023756099775 Test RE 1.0825759566619866\n",
      "15 Train Loss 14.2832775 Test MSE 4.989693610415546 Test RE 1.0676895686688874\n",
      "16 Train Loss 13.056714 Test MSE 4.151062838693037 Test RE 0.9738402357939825\n",
      "17 Train Loss 10.991715 Test MSE 3.280167881254442 Test RE 0.8656774329012498\n",
      "18 Train Loss 8.934556 Test MSE 2.9633033747298883 Test RE 0.8228034766584338\n",
      "19 Train Loss 7.153615 Test MSE 2.8982375531654427 Test RE 0.8137201115954347\n",
      "20 Train Loss 5.856676 Test MSE 2.8946815116068527 Test RE 0.8132207545516265\n",
      "21 Train Loss 4.5307035 Test MSE 2.6518389748091975 Test RE 0.7783620171999832\n",
      "22 Train Loss 3.6057794 Test MSE 2.551032485579969 Test RE 0.7634244323216615\n",
      "23 Train Loss 3.2029335 Test MSE 2.5524857522648983 Test RE 0.7636418543530585\n",
      "24 Train Loss 2.829069 Test MSE 2.712717611734055 Test RE 0.7872458025937239\n",
      "25 Train Loss 2.233431 Test MSE 2.7779857024730745 Test RE 0.7966600943540987\n",
      "26 Train Loss 2.0202777 Test MSE 2.6497040944325394 Test RE 0.7780486413899266\n",
      "27 Train Loss 1.6814737 Test MSE 2.802171215963089 Test RE 0.8001204934414321\n",
      "28 Train Loss 1.4921588 Test MSE 2.849495534928586 Test RE 0.8068486016683413\n",
      "29 Train Loss 1.2996885 Test MSE 2.7569777996017466 Test RE 0.7936420948464916\n",
      "30 Train Loss 1.1751598 Test MSE 2.7454167155051103 Test RE 0.7919763211516139\n",
      "31 Train Loss 1.0738766 Test MSE 2.8016202784016375 Test RE 0.8000418333473454\n",
      "32 Train Loss 0.974185 Test MSE 2.8483710406037575 Test RE 0.8066893829239051\n",
      "33 Train Loss 0.9048046 Test MSE 2.8334909382867406 Test RE 0.8045795211082585\n",
      "34 Train Loss 0.8527686 Test MSE 2.885387189744283 Test RE 0.8119141492662593\n",
      "35 Train Loss 0.8200361 Test MSE 2.905380484876056 Test RE 0.8147222327540895\n",
      "36 Train Loss 0.78135467 Test MSE 2.9030156305661534 Test RE 0.8143905908889862\n",
      "37 Train Loss 0.7469652 Test MSE 2.861220692196881 Test RE 0.8085069153271504\n",
      "38 Train Loss 0.715999 Test MSE 2.900301848839371 Test RE 0.8140098497338697\n",
      "39 Train Loss 0.6778929 Test MSE 2.9477153098102002 Test RE 0.8206364987705692\n",
      "40 Train Loss 0.64947766 Test MSE 2.960044904219758 Test RE 0.8223509718074571\n",
      "41 Train Loss 0.6233253 Test MSE 2.9470181446015333 Test RE 0.8205394485150661\n",
      "42 Train Loss 0.60550916 Test MSE 2.9479433916762985 Test RE 0.8206682468642359\n",
      "43 Train Loss 0.58114076 Test MSE 2.976215272164632 Test RE 0.824594114513694\n",
      "44 Train Loss 0.5637876 Test MSE 2.9644919534921237 Test RE 0.8229684730439568\n",
      "45 Train Loss 0.5499703 Test MSE 2.9849858582154494 Test RE 0.8258082157638404\n",
      "46 Train Loss 0.5310482 Test MSE 3.022613450681555 Test RE 0.8309968271510032\n",
      "47 Train Loss 0.51517063 Test MSE 3.038694944344299 Test RE 0.8332045097672025\n",
      "48 Train Loss 0.50584507 Test MSE 3.0283322721730466 Test RE 0.8317825837244003\n",
      "49 Train Loss 0.49383023 Test MSE 3.067420708136462 Test RE 0.8371335215935434\n",
      "50 Train Loss 0.48139244 Test MSE 3.0619065117255118 Test RE 0.8363807400996138\n",
      "51 Train Loss 0.46222624 Test MSE 3.1329429027670908 Test RE 0.8460271500257087\n",
      "52 Train Loss 0.45224625 Test MSE 3.1486772485783687 Test RE 0.8481489588849459\n",
      "53 Train Loss 0.44396102 Test MSE 3.1696018437537057 Test RE 0.8509624873898226\n",
      "54 Train Loss 0.4298853 Test MSE 3.180941600890498 Test RE 0.85248335546354\n",
      "55 Train Loss 0.41443232 Test MSE 3.2300321294142877 Test RE 0.8590362315372683\n",
      "56 Train Loss 0.40906605 Test MSE 3.226633676826173 Test RE 0.858584198539475\n",
      "57 Train Loss 0.40190566 Test MSE 3.2402560289446267 Test RE 0.8603946949924504\n",
      "58 Train Loss 0.38862008 Test MSE 3.268605369099272 Test RE 0.8641503400035749\n",
      "59 Train Loss 0.3824727 Test MSE 3.280060811049245 Test RE 0.8656633042011166\n",
      "60 Train Loss 0.37217212 Test MSE 3.2878186860167284 Test RE 0.8666864165486536\n",
      "61 Train Loss 0.36365578 Test MSE 3.3020481511972597 Test RE 0.8685598728753541\n",
      "62 Train Loss 0.3563103 Test MSE 3.324709085607913 Test RE 0.8715351058626576\n",
      "63 Train Loss 0.34852654 Test MSE 3.3214747813692864 Test RE 0.8711110844688535\n",
      "64 Train Loss 0.3415566 Test MSE 3.3341983162717153 Test RE 0.8727779672290072\n",
      "65 Train Loss 0.33696705 Test MSE 3.345681864697473 Test RE 0.8742796734946444\n",
      "66 Train Loss 0.33337447 Test MSE 3.348765260453253 Test RE 0.8746824507947145\n",
      "67 Train Loss 0.3264156 Test MSE 3.3383651203965043 Test RE 0.8733231596543893\n",
      "68 Train Loss 0.3225229 Test MSE 3.358108817881218 Test RE 0.8759018484364219\n",
      "69 Train Loss 0.31766593 Test MSE 3.3829341091587444 Test RE 0.8791335005664533\n",
      "70 Train Loss 0.31401977 Test MSE 3.3943340024847095 Test RE 0.8806135174512563\n",
      "71 Train Loss 0.31008822 Test MSE 3.4190176768858525 Test RE 0.8838096382180163\n",
      "72 Train Loss 0.3066023 Test MSE 3.4243805821627524 Test RE 0.8845025170835943\n",
      "73 Train Loss 0.30325606 Test MSE 3.4256346466256002 Test RE 0.8846644619393154\n",
      "74 Train Loss 0.2998814 Test MSE 3.442354296987219 Test RE 0.8868207450527829\n",
      "75 Train Loss 0.294414 Test MSE 3.442810137959694 Test RE 0.8868794600794832\n",
      "76 Train Loss 0.29026806 Test MSE 3.4422138404186375 Test RE 0.8868026526284323\n",
      "77 Train Loss 0.28785363 Test MSE 3.450918593532949 Test RE 0.8879232285747414\n",
      "78 Train Loss 0.2852864 Test MSE 3.457721552112588 Test RE 0.8887980001362699\n",
      "79 Train Loss 0.28158653 Test MSE 3.4872400117376574 Test RE 0.8925837578041494\n",
      "80 Train Loss 0.27929205 Test MSE 3.494344595337631 Test RE 0.8934925294009741\n",
      "81 Train Loss 0.27691495 Test MSE 3.5025418262862202 Test RE 0.8945399181294793\n",
      "82 Train Loss 0.27505422 Test MSE 3.5060663421276494 Test RE 0.8949898809732311\n",
      "83 Train Loss 0.27334893 Test MSE 3.511260271946027 Test RE 0.8956525601496661\n",
      "84 Train Loss 0.27230176 Test MSE 3.5193409550940604 Test RE 0.8966825785411479\n",
      "85 Train Loss 0.2708955 Test MSE 3.530898490346237 Test RE 0.8981537270014391\n",
      "86 Train Loss 0.26841125 Test MSE 3.538618987488249 Test RE 0.8991351212477263\n",
      "87 Train Loss 0.26605457 Test MSE 3.5476935151930022 Test RE 0.900287265962867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 Train Loss 0.26291558 Test MSE 3.56659486611029 Test RE 0.9026823489068576\n",
      "89 Train Loss 0.26116988 Test MSE 3.5574487973304625 Test RE 0.9015242001945414\n",
      "90 Train Loss 0.2592922 Test MSE 3.572126837934766 Test RE 0.903382131005825\n",
      "91 Train Loss 0.25815567 Test MSE 3.5757513539447445 Test RE 0.9038403304176115\n",
      "92 Train Loss 0.25491366 Test MSE 3.5997270117673907 Test RE 0.9068654236962004\n",
      "93 Train Loss 0.25303027 Test MSE 3.602133176020424 Test RE 0.9071684609320655\n",
      "94 Train Loss 0.25168973 Test MSE 3.6139736386710575 Test RE 0.9086582006761182\n",
      "95 Train Loss 0.25042477 Test MSE 3.622609348081134 Test RE 0.9097431873056383\n",
      "96 Train Loss 0.24916784 Test MSE 3.630914488693169 Test RE 0.9107854221824849\n",
      "97 Train Loss 0.2480515 Test MSE 3.6354481377983596 Test RE 0.911353859332663\n",
      "98 Train Loss 0.24673489 Test MSE 3.639267869098142 Test RE 0.9118325091184623\n",
      "99 Train Loss 0.245582 Test MSE 3.639853908620163 Test RE 0.9119059233869447\n",
      "Training time: 68.15\n",
      "KG_stan_tune8\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 58.67046 Test MSE 8.644525829583607 Test RE 1.405331071259591\n",
      "1 Train Loss 57.579586 Test MSE 8.542056421978716 Test RE 1.3969770715220273\n",
      "2 Train Loss 50.210648 Test MSE 8.314018418970655 Test RE 1.3782041440430726\n",
      "3 Train Loss 43.908955 Test MSE 7.387425897569546 Test RE 1.2991360344088378\n",
      "4 Train Loss 37.798088 Test MSE 7.4605663438201715 Test RE 1.3055513513865467\n",
      "5 Train Loss 36.00007 Test MSE 7.377003622651959 Test RE 1.298219292092222\n",
      "6 Train Loss 34.47018 Test MSE 7.191994111397643 Test RE 1.2818367597016311\n",
      "7 Train Loss 33.47155 Test MSE 6.624122537936805 Test RE 1.2301901324481568\n",
      "8 Train Loss 32.291363 Test MSE 6.436650752899347 Test RE 1.2126571532637656\n",
      "9 Train Loss 30.940876 Test MSE 6.330221580871621 Test RE 1.2025898010968743\n",
      "10 Train Loss 29.496956 Test MSE 6.186897744918636 Test RE 1.1888978163317765\n",
      "11 Train Loss 27.872957 Test MSE 6.614993581174159 Test RE 1.229342154140258\n",
      "12 Train Loss 26.048172 Test MSE 6.304016575467401 Test RE 1.2000980593984012\n",
      "13 Train Loss 23.766903 Test MSE 5.452413955409286 Test RE 1.1160983616684141\n",
      "14 Train Loss 21.42823 Test MSE 4.382777655107153 Test RE 1.0006513363042995\n",
      "15 Train Loss 19.731428 Test MSE 4.324777178216561 Test RE 0.9940081118446639\n",
      "16 Train Loss 17.944286 Test MSE 3.8110740297885215 Test RE 0.9331076560290628\n",
      "17 Train Loss 15.472974 Test MSE 3.2655285097005 Test RE 0.8637435158671365\n",
      "18 Train Loss 13.475895 Test MSE 3.3145131473223297 Test RE 0.8701977044253225\n",
      "19 Train Loss 12.810694 Test MSE 3.402770662548907 Test RE 0.8817072262801001\n",
      "20 Train Loss 12.396532 Test MSE 3.6154695937497485 Test RE 0.9088462445508033\n",
      "21 Train Loss 11.910339 Test MSE 3.6967715047802767 Test RE 0.919008152968596\n",
      "22 Train Loss 11.368612 Test MSE 3.835366626897963 Test RE 0.9360768453965148\n",
      "23 Train Loss 10.4728775 Test MSE 4.073472998012777 Test RE 0.9646960075951189\n",
      "24 Train Loss 9.919607 Test MSE 4.005000395116711 Test RE 0.9565536691481363\n",
      "25 Train Loss 9.083383 Test MSE 4.009090316943842 Test RE 0.9570419626634987\n",
      "26 Train Loss 8.798786 Test MSE 3.962026583513159 Test RE 0.9514078991138673\n",
      "27 Train Loss 8.51698 Test MSE 3.9612501005596483 Test RE 0.95131466548723\n",
      "28 Train Loss 8.052047 Test MSE 3.965001088501375 Test RE 0.9517649684733787\n",
      "29 Train Loss 6.870068 Test MSE 3.711204217480142 Test RE 0.9208003735480812\n",
      "30 Train Loss 6.098211 Test MSE 3.367653809898345 Test RE 0.8771457842553674\n",
      "31 Train Loss 5.299912 Test MSE 2.932639144015342 Test RE 0.8185352253284087\n",
      "32 Train Loss 4.967138 Test MSE 2.6238393533436075 Test RE 0.7742419187104638\n",
      "33 Train Loss 4.771019 Test MSE 2.4538016797945095 Test RE 0.7487344053398326\n",
      "34 Train Loss 4.5676537 Test MSE 2.2466159781480703 Test RE 0.7164278861511454\n",
      "35 Train Loss 4.3382225 Test MSE 2.0189957825083633 Test RE 0.6791657337741176\n",
      "36 Train Loss 4.22319 Test MSE 1.9085693503454961 Test RE 0.6603315271251462\n",
      "37 Train Loss 4.0720243 Test MSE 1.8079939833438254 Test RE 0.6426974114377181\n",
      "38 Train Loss 3.9640996 Test MSE 1.7576990852875154 Test RE 0.6336950630117637\n",
      "39 Train Loss 3.8832963 Test MSE 1.7280342081281368 Test RE 0.6283248381433835\n",
      "40 Train Loss 3.8176892 Test MSE 1.711678602773411 Test RE 0.62534426474678\n",
      "41 Train Loss 3.7749007 Test MSE 1.6949080790971685 Test RE 0.6222732543966956\n",
      "42 Train Loss 3.7404084 Test MSE 1.6679775501838852 Test RE 0.617309784659202\n",
      "43 Train Loss 3.6989067 Test MSE 1.6531194208286377 Test RE 0.6145541762222695\n",
      "44 Train Loss 3.6715846 Test MSE 1.6373272423148744 Test RE 0.6116117273197675\n",
      "45 Train Loss 3.6280253 Test MSE 1.6015214498219 Test RE 0.6048872635503141\n",
      "46 Train Loss 3.5827017 Test MSE 1.5757693233312275 Test RE 0.6000043251582674\n",
      "47 Train Loss 3.4125853 Test MSE 1.2202771957167884 Test RE 0.5280041158881886\n",
      "48 Train Loss 2.5610857 Test MSE 0.6691944209105263 Test RE 0.3910067151830964\n",
      "49 Train Loss 1.9012804 Test MSE 0.4121664374140082 Test RE 0.30686289115032733\n",
      "50 Train Loss 1.2534741 Test MSE 0.14335487064315175 Test RE 0.18097320880775974\n",
      "51 Train Loss 0.55031246 Test MSE 0.045076291812016375 Test RE 0.10148039550381097\n",
      "52 Train Loss 0.33537617 Test MSE 0.03161055638002225 Test RE 0.08498144868366947\n",
      "53 Train Loss 0.24493368 Test MSE 0.02199534593568931 Test RE 0.07088811999311688\n",
      "54 Train Loss 0.17959216 Test MSE 0.01829000942173089 Test RE 0.06464203572087544\n",
      "55 Train Loss 0.13686787 Test MSE 0.016889139426365447 Test RE 0.062117192786372614\n",
      "56 Train Loss 0.11649821 Test MSE 0.015834757244096772 Test RE 0.060146971554054816\n",
      "57 Train Loss 0.100774 Test MSE 0.017991660984784736 Test RE 0.0641126443433627\n",
      "58 Train Loss 0.091091625 Test MSE 0.020899713705101387 Test RE 0.06910002886043204\n",
      "59 Train Loss 0.08586365 Test MSE 0.021110729164241962 Test RE 0.06944798946389737\n",
      "60 Train Loss 0.07976924 Test MSE 0.01835273336455931 Test RE 0.06475278287750616\n",
      "61 Train Loss 0.06849133 Test MSE 0.01469526291691161 Test RE 0.05794243477490978\n",
      "62 Train Loss 0.064223826 Test MSE 0.01454564931013611 Test RE 0.05764672197877382\n",
      "63 Train Loss 0.060336176 Test MSE 0.012818923234287143 Test RE 0.054117015001418856\n",
      "64 Train Loss 0.05835996 Test MSE 0.012143175154643167 Test RE 0.052671318494649455\n",
      "65 Train Loss 0.054584548 Test MSE 0.012150837860950184 Test RE 0.05268793446154821\n",
      "66 Train Loss 0.05218719 Test MSE 0.011537937932469973 Test RE 0.05134192636036233\n",
      "67 Train Loss 0.049188025 Test MSE 0.011679253373982828 Test RE 0.05165538471774788\n",
      "68 Train Loss 0.047894757 Test MSE 0.01194830345107989 Test RE 0.052246978791246186\n",
      "69 Train Loss 0.04569473 Test MSE 0.010857762683342686 Test RE 0.04980560647859893\n",
      "70 Train Loss 0.043727815 Test MSE 0.009847239344062553 Test RE 0.047431330496518216\n",
      "71 Train Loss 0.041456558 Test MSE 0.009656333244948008 Test RE 0.04696931027723151\n",
      "72 Train Loss 0.037467487 Test MSE 0.00878978993965924 Test RE 0.04481230760593103\n",
      "73 Train Loss 0.036067557 Test MSE 0.008220935033221513 Test RE 0.043337980353152845\n",
      "74 Train Loss 0.03492245 Test MSE 0.008627100140043515 Test RE 0.04439565623222745\n",
      "75 Train Loss 0.033417337 Test MSE 0.0086302147569276 Test RE 0.044403669526393054\n",
      "76 Train Loss 0.03201992 Test MSE 0.00784314837052594 Test RE 0.0423304880438675\n",
      "77 Train Loss 0.028777871 Test MSE 0.008309896489682693 Test RE 0.043571836704398924\n",
      "78 Train Loss 0.027885472 Test MSE 0.009412382031402988 Test RE 0.04637221420577405\n",
      "79 Train Loss 0.026463136 Test MSE 0.009991342635597955 Test RE 0.047777122156477544\n",
      "80 Train Loss 0.025740929 Test MSE 0.009510651014046075 Test RE 0.0466136577582752\n",
      "81 Train Loss 0.024605932 Test MSE 0.009420990905111313 Test RE 0.04639341613387466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 Train Loss 0.02382452 Test MSE 0.010245244590762608 Test RE 0.0483803744993157\n",
      "83 Train Loss 0.022802439 Test MSE 0.008980550011942192 Test RE 0.04529596622187026\n",
      "84 Train Loss 0.021281734 Test MSE 0.007829686124106247 Test RE 0.042294143697342336\n",
      "85 Train Loss 0.020475062 Test MSE 0.008165388363619725 Test RE 0.04319132059970924\n",
      "86 Train Loss 0.019853251 Test MSE 0.007761507418075751 Test RE 0.04210959831890774\n",
      "87 Train Loss 0.018980723 Test MSE 0.007292862690090006 Test RE 0.04081850352020978\n",
      "88 Train Loss 0.018443605 Test MSE 0.007091380590431039 Test RE 0.04025070184110433\n",
      "89 Train Loss 0.018125236 Test MSE 0.0068411314742789445 Test RE 0.03953411567991629\n",
      "90 Train Loss 0.01777869 Test MSE 0.006876430349811207 Test RE 0.03963597853147683\n",
      "91 Train Loss 0.016977388 Test MSE 0.006298307053194637 Test RE 0.037933243162801306\n",
      "92 Train Loss 0.016245954 Test MSE 0.0055910437662365425 Test RE 0.03573999654833207\n",
      "93 Train Loss 0.015516795 Test MSE 0.005057709061629519 Test RE 0.03399264682030262\n",
      "94 Train Loss 0.014356214 Test MSE 0.004476929077557931 Test RE 0.03198145127134743\n",
      "95 Train Loss 0.013725524 Test MSE 0.004626740949180429 Test RE 0.03251214718186912\n",
      "96 Train Loss 0.013008971 Test MSE 0.004411492735356361 Test RE 0.031746864946497165\n",
      "97 Train Loss 0.0125424 Test MSE 0.0036487505800678584 Test RE 0.028872218039231488\n",
      "98 Train Loss 0.012058227 Test MSE 0.0030952370684568667 Test RE 0.026592245969306906\n",
      "99 Train Loss 0.011611282 Test MSE 0.002837114457779279 Test RE 0.02545930176552557\n",
      "Training time: 48.66\n",
      "KG_stan_tune8\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.638157 Test MSE 8.600205375716587 Test RE 1.401723878043732\n",
      "1 Train Loss 56.891315 Test MSE 8.659066894649866 Test RE 1.4065125371186094\n",
      "2 Train Loss 52.79693 Test MSE 9.269656996071976 Test RE 1.4552576549141347\n",
      "3 Train Loss 49.5025 Test MSE 8.999621666157738 Test RE 1.4339043642343516\n",
      "4 Train Loss 47.43274 Test MSE 8.705322934972646 Test RE 1.4102642719645326\n",
      "5 Train Loss 46.081505 Test MSE 8.739374200644008 Test RE 1.4130197364091328\n",
      "6 Train Loss 45.731842 Test MSE 8.739618976118583 Test RE 1.413039524448118\n",
      "7 Train Loss 45.3092 Test MSE 8.593933435981127 Test RE 1.401212661697369\n",
      "8 Train Loss 44.483948 Test MSE 8.594232340632221 Test RE 1.40123702919702\n",
      "9 Train Loss 44.151924 Test MSE 8.436523875372336 Test RE 1.3883207995805618\n",
      "10 Train Loss 43.74756 Test MSE 8.354961812208137 Test RE 1.3815935431192785\n",
      "11 Train Loss 43.585762 Test MSE 8.244855339266842 Test RE 1.3724596347639122\n",
      "12 Train Loss 43.370193 Test MSE 8.147825955849948 Test RE 1.364359854479312\n",
      "13 Train Loss 42.82843 Test MSE 8.05651617887162 Test RE 1.3566933681407134\n",
      "14 Train Loss 40.15152 Test MSE 8.329772857967912 Test RE 1.379509322580544\n",
      "15 Train Loss 39.153103 Test MSE 8.075787303635103 Test RE 1.3583149990411034\n",
      "16 Train Loss 38.28419 Test MSE 7.943138395280037 Test RE 1.3471133033109246\n",
      "17 Train Loss 37.985603 Test MSE 8.006049880013487 Test RE 1.3524375056209563\n",
      "18 Train Loss 37.78618 Test MSE 8.108142535608557 Test RE 1.361033289143429\n",
      "19 Train Loss 36.964287 Test MSE 8.481937745094937 Test RE 1.3920524549474989\n",
      "20 Train Loss 36.536594 Test MSE 8.594778947266882 Test RE 1.4012815889231485\n",
      "21 Train Loss 36.33276 Test MSE 8.505067108553535 Test RE 1.3939491540487243\n",
      "22 Train Loss 35.776802 Test MSE 8.327023060713454 Test RE 1.3792816042424878\n",
      "23 Train Loss 35.337788 Test MSE 8.133241020749482 Test RE 1.363138178104232\n",
      "24 Train Loss 34.064526 Test MSE 7.752874879601311 Test RE 1.3308816828811547\n",
      "25 Train Loss 32.36885 Test MSE 7.291201053066339 Test RE 1.2906473595973726\n",
      "26 Train Loss 29.746616 Test MSE 7.213267758050156 Test RE 1.2837311721704414\n",
      "27 Train Loss 29.020535 Test MSE 7.196784262911645 Test RE 1.2822635655455958\n",
      "28 Train Loss 28.22385 Test MSE 6.865366063412292 Test RE 1.2523909184662416\n",
      "29 Train Loss 26.814142 Test MSE 6.686761963614024 Test RE 1.2359929454339604\n",
      "30 Train Loss 23.849224 Test MSE 6.564037683816185 Test RE 1.2245981333458813\n",
      "31 Train Loss 21.793629 Test MSE 6.328090529092543 Test RE 1.2023873597741646\n",
      "32 Train Loss 21.315786 Test MSE 6.343009767638733 Test RE 1.203803912132461\n",
      "33 Train Loss 20.882866 Test MSE 6.28006919641768 Test RE 1.1978164546467394\n",
      "34 Train Loss 20.478348 Test MSE 6.278768021175661 Test RE 1.197692359688121\n",
      "35 Train Loss 19.90565 Test MSE 6.195080046956462 Test RE 1.1896837277211727\n",
      "36 Train Loss 19.37621 Test MSE 6.146741450523842 Test RE 1.1850332421546341\n",
      "37 Train Loss 19.095436 Test MSE 6.101270920653371 Test RE 1.180641963289254\n",
      "38 Train Loss 18.70925 Test MSE 5.961351832350041 Test RE 1.1670257463986329\n",
      "39 Train Loss 18.421244 Test MSE 6.018739690292778 Test RE 1.1726295674040252\n",
      "40 Train Loss 18.094803 Test MSE 6.08854869622966 Test RE 1.1794103977325605\n",
      "41 Train Loss 17.699524 Test MSE 6.0653248795187675 Test RE 1.1771589104476574\n",
      "42 Train Loss 17.47157 Test MSE 6.130116487486647 Test RE 1.1834295897671077\n",
      "43 Train Loss 17.17264 Test MSE 6.306873783687835 Test RE 1.2003699925031805\n",
      "44 Train Loss 16.923248 Test MSE 6.304539512289144 Test RE 1.2001478342080942\n",
      "45 Train Loss 16.554455 Test MSE 6.43716524823181 Test RE 1.2127056174419646\n",
      "46 Train Loss 16.435978 Test MSE 6.49311882051849 Test RE 1.217964795377635\n",
      "47 Train Loss 16.060062 Test MSE 6.56366147165757 Test RE 1.224563039450108\n",
      "48 Train Loss 15.840172 Test MSE 6.6011698866391235 Test RE 1.228056972391035\n",
      "49 Train Loss 15.688588 Test MSE 6.522367571453875 Test RE 1.2207049209115455\n",
      "50 Train Loss 15.538485 Test MSE 6.6051771560833465 Test RE 1.2284296645531867\n",
      "51 Train Loss 15.303818 Test MSE 6.787982525199966 Test RE 1.2453127026505209\n",
      "52 Train Loss 15.049345 Test MSE 6.753369966438964 Test RE 1.2421336618516992\n",
      "53 Train Loss 14.74215 Test MSE 6.782702524421799 Test RE 1.2448282780704263\n",
      "54 Train Loss 14.595217 Test MSE 6.843937717146237 Test RE 1.2504348945943693\n",
      "55 Train Loss 14.457773 Test MSE 6.876717242117252 Test RE 1.2534258408304895\n",
      "56 Train Loss 14.175959 Test MSE 6.952862355251086 Test RE 1.2603462576875901\n",
      "57 Train Loss 13.966288 Test MSE 6.857210529446989 Test RE 1.251646824726625\n",
      "58 Train Loss 13.661827 Test MSE 6.992973426583342 Test RE 1.26397649904248\n",
      "59 Train Loss 13.322704 Test MSE 7.197671143521128 Test RE 1.2823425716417616\n",
      "60 Train Loss 12.970446 Test MSE 7.21348990896528 Test RE 1.2837509399004452\n",
      "61 Train Loss 12.204683 Test MSE 7.034578615822406 Test RE 1.2677309816551607\n",
      "62 Train Loss 9.978519 Test MSE 5.876966136935436 Test RE 1.1587364121054675\n",
      "63 Train Loss 8.686957 Test MSE 5.153551711489392 Test RE 1.085079052202913\n",
      "64 Train Loss 7.4849515 Test MSE 5.303859729152397 Test RE 1.1007889850286396\n",
      "65 Train Loss 6.902807 Test MSE 4.932129749446772 Test RE 1.0615129746024983\n",
      "66 Train Loss 6.045875 Test MSE 3.6615284929820042 Test RE 0.9146169998811123\n",
      "67 Train Loss 4.769404 Test MSE 3.6735046076601225 Test RE 0.9161115418464559\n",
      "68 Train Loss 3.8857765 Test MSE 3.485533534165613 Test RE 0.8923653385750026\n",
      "69 Train Loss 3.678662 Test MSE 3.461631772404771 Test RE 0.8893004139261993\n",
      "70 Train Loss 3.5574315 Test MSE 3.557120924539644 Test RE 0.9014826546821073\n",
      "71 Train Loss 3.41609 Test MSE 3.6293002847051894 Test RE 0.9105829446932171\n",
      "72 Train Loss 3.3355117 Test MSE 3.6228585933932203 Test RE 0.9097744831621246\n",
      "73 Train Loss 3.2333236 Test MSE 3.7079831363981373 Test RE 0.9204006897343631\n",
      "74 Train Loss 3.14125 Test MSE 3.788154949377683 Test RE 0.930297658233818\n",
      "75 Train Loss 3.0447075 Test MSE 3.81702788912471 Test RE 0.9338362463910318\n",
      "76 Train Loss 2.947295 Test MSE 3.958158446814778 Test RE 0.9509433547182016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 Train Loss 2.8699536 Test MSE 4.026083096835172 Test RE 0.9590680590882896\n",
      "78 Train Loss 2.8261137 Test MSE 4.034855576939901 Test RE 0.9601123529136039\n",
      "79 Train Loss 2.774665 Test MSE 4.091080476491566 Test RE 0.966778695823004\n",
      "80 Train Loss 2.709128 Test MSE 4.089839029158193 Test RE 0.9666319991366636\n",
      "81 Train Loss 2.6733382 Test MSE 4.094398839661001 Test RE 0.9671707038212615\n",
      "82 Train Loss 2.6366758 Test MSE 4.132325057731223 Test RE 0.9716398060917487\n",
      "83 Train Loss 2.6023233 Test MSE 4.151854353491857 Test RE 0.9739330761396682\n",
      "84 Train Loss 2.563333 Test MSE 4.17503527597084 Test RE 0.9766481571588609\n",
      "85 Train Loss 2.5388176 Test MSE 4.226835596999402 Test RE 0.9826881938375903\n",
      "86 Train Loss 2.5003684 Test MSE 4.203020092949473 Test RE 0.9799158748247485\n",
      "87 Train Loss 2.4557834 Test MSE 4.128370295288024 Test RE 0.9711747501761673\n",
      "88 Train Loss 2.418454 Test MSE 4.083123002421088 Test RE 0.9658380077798031\n",
      "89 Train Loss 2.3868933 Test MSE 4.076123408980144 Test RE 0.9650097969724103\n",
      "90 Train Loss 2.3564365 Test MSE 4.077393764640434 Test RE 0.9651601616736158\n",
      "91 Train Loss 2.3329175 Test MSE 4.052962128210422 Test RE 0.9622642098593126\n",
      "92 Train Loss 2.304935 Test MSE 4.083338600942608 Test RE 0.9658635067052157\n",
      "93 Train Loss 2.285533 Test MSE 4.1127081541827755 Test RE 0.9693307864789064\n",
      "94 Train Loss 2.2612307 Test MSE 4.081786130766384 Test RE 0.9656798803903591\n",
      "95 Train Loss 2.2522619 Test MSE 4.064202435710334 Test RE 0.9635976366713697\n",
      "96 Train Loss 2.2337327 Test MSE 4.05549701040056 Test RE 0.9625650817960322\n",
      "97 Train Loss 2.2134504 Test MSE 4.067162812582203 Test RE 0.9639485164477664\n",
      "98 Train Loss 2.1913385 Test MSE 4.090816084105804 Test RE 0.966747455536083\n",
      "99 Train Loss 2.1694508 Test MSE 4.076150226141031 Test RE 0.9650129714077527\n",
      "Training time: 49.07\n",
      "KG_stan_tune8\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.552166 Test MSE 8.57946829343709 Test RE 1.4000329180322209\n",
      "1 Train Loss 52.59637 Test MSE 8.710021449643962 Test RE 1.4106448008422139\n",
      "2 Train Loss 45.623146 Test MSE 8.27550135290442 Test RE 1.3750079756945637\n",
      "3 Train Loss 45.51893 Test MSE 8.06729655666258 Test RE 1.357600756481464\n",
      "4 Train Loss 44.695778 Test MSE 8.110262633868471 Test RE 1.3612112174232376\n",
      "5 Train Loss 42.05198 Test MSE 7.432024417740812 Test RE 1.3030516311210123\n",
      "6 Train Loss 38.75216 Test MSE 7.481721911213552 Test RE 1.3074010854477456\n",
      "7 Train Loss 36.975285 Test MSE 7.423813866098401 Test RE 1.3023316570858576\n",
      "8 Train Loss 36.129086 Test MSE 7.576330358923637 Test RE 1.315641341789134\n",
      "9 Train Loss 34.281567 Test MSE 7.230366925753925 Test RE 1.2852518242582622\n",
      "10 Train Loss 33.85281 Test MSE 7.2351814470595786 Test RE 1.2856796616425774\n",
      "11 Train Loss 33.32554 Test MSE 7.1964123467936805 Test RE 1.2822304326468248\n",
      "12 Train Loss 32.42519 Test MSE 7.038800967751465 Test RE 1.2681113884757358\n",
      "13 Train Loss 31.366531 Test MSE 6.982473421319701 Test RE 1.263027207179052\n",
      "14 Train Loss 30.060844 Test MSE 6.873876861044427 Test RE 1.253166954605067\n",
      "15 Train Loss 29.392124 Test MSE 6.578929167929645 Test RE 1.2259864368133944\n",
      "16 Train Loss 28.270576 Test MSE 6.465631999697427 Test RE 1.2153841029435615\n",
      "17 Train Loss 27.58771 Test MSE 6.33833245329835 Test RE 1.2033599897768932\n",
      "18 Train Loss 27.008896 Test MSE 6.35826567015156 Test RE 1.2052507083961383\n",
      "19 Train Loss 26.590668 Test MSE 6.4420369483139 Test RE 1.2131644234891068\n",
      "20 Train Loss 26.162235 Test MSE 6.419148509402594 Test RE 1.211007330303079\n",
      "21 Train Loss 25.989037 Test MSE 6.257167881826376 Test RE 1.1956304416635086\n",
      "22 Train Loss 25.69289 Test MSE 6.329579251434695 Test RE 1.2025287859794473\n",
      "23 Train Loss 25.409067 Test MSE 6.325043742486664 Test RE 1.202097868121925\n",
      "24 Train Loss 25.167725 Test MSE 6.261235044458956 Test RE 1.1960189587685122\n",
      "25 Train Loss 24.802937 Test MSE 6.460164854944612 Test RE 1.2148701480779491\n",
      "26 Train Loss 24.32975 Test MSE 6.448037280397165 Test RE 1.2137292832681048\n",
      "27 Train Loss 23.828335 Test MSE 6.240481034505674 Test RE 1.1940351015276949\n",
      "28 Train Loss 23.660656 Test MSE 6.17249714508563 Test RE 1.1875133732219505\n",
      "29 Train Loss 23.54538 Test MSE 6.1514328302221095 Test RE 1.1854853825740628\n",
      "30 Train Loss 23.449358 Test MSE 6.072040584996387 Test RE 1.1778104225779515\n",
      "31 Train Loss 23.191322 Test MSE 6.124942990778404 Test RE 1.1829301081173178\n",
      "32 Train Loss 23.088451 Test MSE 6.038287561178049 Test RE 1.1745322771631754\n",
      "33 Train Loss 23.00541 Test MSE 5.895726812692101 Test RE 1.160584419775136\n",
      "34 Train Loss 22.763096 Test MSE 5.789547847502499 Test RE 1.150086177989444\n",
      "35 Train Loss 22.618587 Test MSE 5.885071126308518 Test RE 1.1595351499509752\n",
      "36 Train Loss 22.460539 Test MSE 5.927695005849546 Test RE 1.1637266641537372\n",
      "37 Train Loss 22.148224 Test MSE 5.783476021152796 Test RE 1.1494829395670472\n",
      "38 Train Loss 21.953934 Test MSE 5.692387474842932 Test RE 1.1403949552890162\n",
      "39 Train Loss 21.772451 Test MSE 5.616387585163995 Test RE 1.132756585259188\n",
      "40 Train Loss 21.551819 Test MSE 5.575644317893864 Test RE 1.128640397611821\n",
      "41 Train Loss 20.870323 Test MSE 5.6907370637744785 Test RE 1.1402296242300416\n",
      "42 Train Loss 20.229433 Test MSE 5.534606744614225 Test RE 1.1244792460169564\n",
      "43 Train Loss 19.345835 Test MSE 5.123666126562913 Test RE 1.081928276405109\n",
      "44 Train Loss 17.571995 Test MSE 4.616101183308134 Test RE 1.0269415368814259\n",
      "45 Train Loss 13.841338 Test MSE 4.159872256357867 Test RE 0.9748730337719657\n",
      "46 Train Loss 11.7080765 Test MSE 3.9206839541972016 Test RE 0.9464310455818616\n",
      "47 Train Loss 10.013321 Test MSE 4.138051623665468 Test RE 0.9723128210374676\n",
      "48 Train Loss 8.875887 Test MSE 4.0617357055889105 Test RE 0.9633051689452736\n",
      "49 Train Loss 7.9554205 Test MSE 3.6483621609762475 Test RE 0.9129711030826149\n",
      "50 Train Loss 7.420618 Test MSE 3.5218709923807574 Test RE 0.8970048310317155\n",
      "51 Train Loss 6.9823904 Test MSE 3.36763942752363 Test RE 0.8771439112224594\n",
      "52 Train Loss 6.743204 Test MSE 3.2245467221619992 Test RE 0.858306491755125\n",
      "53 Train Loss 6.390938 Test MSE 3.2503945308336823 Test RE 0.8617396967972492\n",
      "54 Train Loss 5.9781094 Test MSE 3.005117815636265 Test RE 0.8285883291529901\n",
      "55 Train Loss 5.8032637 Test MSE 2.828109816460766 Test RE 0.8038151639878657\n",
      "56 Train Loss 5.6172304 Test MSE 2.7460819030132675 Test RE 0.792072259383156\n",
      "57 Train Loss 5.462526 Test MSE 2.5160313043633766 Test RE 0.7581691001919088\n",
      "58 Train Loss 5.280158 Test MSE 2.2476864717308507 Test RE 0.7165985517488209\n",
      "59 Train Loss 5.109174 Test MSE 2.2278469228660405 Test RE 0.7134289585913063\n",
      "60 Train Loss 4.946029 Test MSE 2.1811458222280997 Test RE 0.7059117504168985\n",
      "61 Train Loss 4.8283873 Test MSE 2.1379062193134093 Test RE 0.6988796351286418\n",
      "62 Train Loss 4.7357154 Test MSE 2.136669636339529 Test RE 0.6986774869580733\n",
      "63 Train Loss 4.657508 Test MSE 2.131885156882109 Test RE 0.6978948012662904\n",
      "64 Train Loss 4.585345 Test MSE 2.0982964049364106 Test RE 0.6923751600580489\n",
      "65 Train Loss 4.531345 Test MSE 2.097317077014302 Test RE 0.6922135667147787\n",
      "66 Train Loss 4.466258 Test MSE 2.118485184818708 Test RE 0.6956980336958294\n",
      "67 Train Loss 4.423066 Test MSE 2.098891759405761 Test RE 0.6924733776906861\n",
      "68 Train Loss 4.3763566 Test MSE 2.0907156500224358 Test RE 0.6911233169829336\n",
      "69 Train Loss 4.3497896 Test MSE 2.105989102181604 Test RE 0.6936431791264036\n",
      "70 Train Loss 4.3246326 Test MSE 2.1019652765362924 Test RE 0.6929802047324725\n",
      "71 Train Loss 4.3028026 Test MSE 2.0923045587545457 Test RE 0.6913858881537461\n",
      "72 Train Loss 4.2848 Test MSE 2.1047699722877202 Test RE 0.6934423795228813\n",
      "73 Train Loss 4.270724 Test MSE 2.1003190031375567 Test RE 0.6927087781883348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Train Loss 4.2578654 Test MSE 2.0905569360632468 Test RE 0.691097083621222\n",
      "75 Train Loss 4.243489 Test MSE 2.098447758617108 Test RE 0.6924001307054238\n",
      "76 Train Loss 4.2327824 Test MSE 2.100639292805506 Test RE 0.6927615937383549\n",
      "77 Train Loss 4.223204 Test MSE 2.1085647996420627 Test RE 0.694067224301643\n",
      "78 Train Loss 4.213922 Test MSE 2.1044824545361713 Test RE 0.6933950147738233\n",
      "79 Train Loss 4.2044387 Test MSE 2.099328329063076 Test RE 0.6925453912057241\n",
      "80 Train Loss 4.1934786 Test MSE 2.1001211331619754 Test RE 0.6926761475505109\n",
      "81 Train Loss 4.185828 Test MSE 2.0862254723707814 Test RE 0.6903807639566575\n",
      "82 Train Loss 4.1809144 Test MSE 2.085652505913208 Test RE 0.6902859534509319\n",
      "83 Train Loss 4.176771 Test MSE 2.0930364080054122 Test RE 0.6915067945493824\n",
      "84 Train Loss 4.172719 Test MSE 2.0893089864562167 Test RE 0.6908907790075707\n",
      "85 Train Loss 4.166425 Test MSE 2.0844693506986784 Test RE 0.6900901319315068\n",
      "86 Train Loss 4.1601715 Test MSE 2.0869737240535002 Test RE 0.6905045598416423\n",
      "87 Train Loss 4.1556344 Test MSE 2.0890223869438493 Test RE 0.6908433911504974\n",
      "88 Train Loss 4.147195 Test MSE 2.091134573005323 Test RE 0.6911925547435951\n",
      "89 Train Loss 4.141079 Test MSE 2.0870174241009294 Test RE 0.6905117891909403\n",
      "90 Train Loss 4.132527 Test MSE 2.0902359779572253 Test RE 0.6910440303602768\n",
      "91 Train Loss 4.125927 Test MSE 2.083751625042034 Test RE 0.6899713155921452\n",
      "92 Train Loss 4.1200533 Test MSE 2.082574452513903 Test RE 0.6897763955230655\n",
      "93 Train Loss 4.114273 Test MSE 2.0846199769715685 Test RE 0.6901150648543041\n",
      "94 Train Loss 4.10964 Test MSE 2.086368989142687 Test RE 0.6904045100751827\n",
      "95 Train Loss 4.105274 Test MSE 2.0923750725870986 Test RE 0.6913975384313771\n",
      "96 Train Loss 4.1016498 Test MSE 2.0903467934215736 Test RE 0.6910623482322727\n",
      "97 Train Loss 4.097079 Test MSE 2.0900629912735065 Test RE 0.6910154345725827\n",
      "98 Train Loss 4.090292 Test MSE 2.0906808261508707 Test RE 0.6911175611332927\n",
      "99 Train Loss 4.08405 Test MSE 2.0904784174498334 Test RE 0.6910841051432541\n",
      "Training time: 48.27\n",
      "KG_stan_tune8\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.382732 Test MSE 8.659649201965381 Test RE 1.4065598290947938\n",
      "1 Train Loss 55.64983 Test MSE 8.604038571135426 Test RE 1.4020362242458146\n",
      "2 Train Loss 45.378708 Test MSE 9.042334928841218 Test RE 1.4373030756988177\n",
      "3 Train Loss 43.98049 Test MSE 8.670080270407471 Test RE 1.4074067171071734\n",
      "4 Train Loss 43.831806 Test MSE 8.54530167034603 Test RE 1.397242412022579\n",
      "5 Train Loss 43.683483 Test MSE 8.647020260533953 Test RE 1.4055338150850902\n",
      "6 Train Loss 43.35591 Test MSE 8.553712263744046 Test RE 1.3979298510437597\n",
      "7 Train Loss 42.82167 Test MSE 8.470562363987915 Test RE 1.3911186801146584\n",
      "8 Train Loss 42.378174 Test MSE 8.350437802016485 Test RE 1.3812194426899793\n",
      "9 Train Loss 42.09316 Test MSE 8.345453123995616 Test RE 1.3808071312558665\n",
      "10 Train Loss 41.964165 Test MSE 8.441253213605028 Test RE 1.388709876813298\n",
      "11 Train Loss 41.87409 Test MSE 8.446384555346736 Test RE 1.3891319031500007\n",
      "12 Train Loss 41.677063 Test MSE 8.382520778134857 Test RE 1.383870270645635\n",
      "13 Train Loss 41.58407 Test MSE 8.437808914972106 Test RE 1.3884265291025948\n",
      "14 Train Loss 41.385952 Test MSE 8.60833754142068 Test RE 1.4023864411425109\n",
      "15 Train Loss 41.068047 Test MSE 8.624546891948672 Test RE 1.4037061548775895\n",
      "16 Train Loss 40.805843 Test MSE 8.747458976254915 Test RE 1.4136731760259016\n",
      "17 Train Loss 40.326977 Test MSE 8.900068376015703 Test RE 1.4259514261015622\n",
      "18 Train Loss 38.913864 Test MSE 8.818568578226266 Test RE 1.4194075421753607\n",
      "19 Train Loss 35.903397 Test MSE 9.457007547885006 Test RE 1.4698903140967454\n",
      "20 Train Loss 34.398605 Test MSE 9.431363652260972 Test RE 1.4678960626832942\n",
      "21 Train Loss 33.69461 Test MSE 9.012029636217123 Test RE 1.4348925010030438\n",
      "22 Train Loss 33.14396 Test MSE 8.726202432101118 Test RE 1.4119545006925012\n",
      "23 Train Loss 32.749176 Test MSE 8.26304212146517 Test RE 1.373972509995732\n",
      "24 Train Loss 32.192238 Test MSE 8.031362506188485 Test RE 1.3545738106096967\n",
      "25 Train Loss 31.903278 Test MSE 8.145766279967736 Test RE 1.3641873964078428\n",
      "26 Train Loss 31.683743 Test MSE 8.27082805772055 Test RE 1.374619677431965\n",
      "27 Train Loss 31.516148 Test MSE 8.391069704354429 Test RE 1.384575761889047\n",
      "28 Train Loss 31.355782 Test MSE 8.479254536228563 Test RE 1.3918322539127892\n",
      "29 Train Loss 31.037035 Test MSE 8.369674368340238 Test RE 1.3828094572277772\n",
      "30 Train Loss 30.806265 Test MSE 8.20485453800943 Test RE 1.3691262691359236\n",
      "31 Train Loss 30.5013 Test MSE 8.270411033692952 Test RE 1.3745850220953753\n",
      "32 Train Loss 30.226887 Test MSE 8.262541989570748 Test RE 1.3739309285864607\n",
      "33 Train Loss 29.812614 Test MSE 8.218723906408998 Test RE 1.3702829562320453\n",
      "34 Train Loss 29.438828 Test MSE 8.323361900541586 Test RE 1.378978355048785\n",
      "35 Train Loss 28.689453 Test MSE 8.812641224629997 Test RE 1.4189304384059622\n",
      "36 Train Loss 28.172268 Test MSE 8.60429968925258 Test RE 1.402057498806503\n",
      "37 Train Loss 27.917097 Test MSE 8.601408275911439 Test RE 1.4018219033173807\n",
      "38 Train Loss 27.664536 Test MSE 8.562709599740002 Test RE 1.39866487336089\n",
      "39 Train Loss 27.476757 Test MSE 8.414709278985873 Test RE 1.3865247244818377\n",
      "40 Train Loss 27.389309 Test MSE 8.369140021422448 Test RE 1.3827653150226775\n",
      "41 Train Loss 26.579533 Test MSE 7.73843157947851 Test RE 1.3296414149270728\n",
      "42 Train Loss 24.824621 Test MSE 7.21708467315791 Test RE 1.2840707717142326\n",
      "43 Train Loss 23.943638 Test MSE 6.839413804853686 Test RE 1.2500215511988184\n",
      "44 Train Loss 23.111187 Test MSE 6.665949600540041 Test RE 1.2340679493336297\n",
      "45 Train Loss 22.58736 Test MSE 6.826872736804473 Test RE 1.2488749764543414\n",
      "46 Train Loss 22.381739 Test MSE 6.790111458782331 Test RE 1.2455079727606848\n",
      "47 Train Loss 22.00893 Test MSE 6.972391394412605 Test RE 1.2621150322615373\n",
      "48 Train Loss 21.37487 Test MSE 7.1670195495996145 Test RE 1.2796092028382366\n",
      "49 Train Loss 21.13285 Test MSE 7.0456881305054155 Test RE 1.2687316329053349\n",
      "50 Train Loss 21.021954 Test MSE 6.997872618171979 Test RE 1.2644191847530832\n",
      "51 Train Loss 20.716118 Test MSE 6.938662899779853 Test RE 1.2590586313750027\n",
      "52 Train Loss 20.505526 Test MSE 6.915211398943705 Test RE 1.2569291284630377\n",
      "53 Train Loss 20.257355 Test MSE 6.764918374264242 Test RE 1.2431952458451472\n",
      "54 Train Loss 19.932491 Test MSE 6.710163066148007 Test RE 1.2381538071943041\n",
      "55 Train Loss 19.784954 Test MSE 6.7607333303546415 Test RE 1.2428106416768954\n",
      "56 Train Loss 19.719028 Test MSE 6.7843922778799195 Test RE 1.2449833285012624\n",
      "57 Train Loss 19.61459 Test MSE 6.8206803937938485 Test RE 1.2483084493640628\n",
      "58 Train Loss 19.432663 Test MSE 6.667130360581611 Test RE 1.234177241609251\n",
      "59 Train Loss 19.341347 Test MSE 6.473345976976905 Test RE 1.216108908393619\n",
      "60 Train Loss 19.183933 Test MSE 6.236133591084614 Test RE 1.1936191156114566\n",
      "61 Train Loss 18.935993 Test MSE 5.991090232054242 Test RE 1.1699329983402906\n",
      "62 Train Loss 18.4794 Test MSE 5.712490552709613 Test RE 1.142406874156848\n",
      "63 Train Loss 18.012619 Test MSE 5.957087785302228 Test RE 1.1666082955416055\n",
      "64 Train Loss 16.930288 Test MSE 5.02333343606082 Test RE 1.071282630714545\n",
      "65 Train Loss 15.556223 Test MSE 4.8483657475591295 Test RE 1.0524603599564528\n",
      "66 Train Loss 15.032172 Test MSE 4.676755724107554 Test RE 1.0336664096081372\n",
      "67 Train Loss 14.631081 Test MSE 4.481105332963642 Test RE 1.0118138889139199\n",
      "68 Train Loss 14.179171 Test MSE 4.679341641711064 Test RE 1.0339521425961848\n",
      "69 Train Loss 13.644582 Test MSE 4.940465676799057 Test RE 1.0624096419439915\n",
      "70 Train Loss 13.1653805 Test MSE 5.1476407148919145 Test RE 1.084456594221888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 Train Loss 12.737855 Test MSE 5.226255995537859 Test RE 1.0927061808902832\n",
      "72 Train Loss 12.323206 Test MSE 5.046811969221615 Test RE 1.0737832434999126\n",
      "73 Train Loss 12.108025 Test MSE 5.145649524921974 Test RE 1.0842468313351656\n",
      "74 Train Loss 11.940736 Test MSE 5.247354175160371 Test RE 1.0949095642512372\n",
      "75 Train Loss 11.65609 Test MSE 5.088303779742465 Test RE 1.0781882038313808\n",
      "76 Train Loss 11.405496 Test MSE 5.078153114969371 Test RE 1.0771122273215223\n",
      "77 Train Loss 11.267319 Test MSE 5.138679909512656 Test RE 1.0835122939385264\n",
      "78 Train Loss 11.123666 Test MSE 5.189056704664329 Test RE 1.0888104203055053\n",
      "79 Train Loss 10.97563 Test MSE 5.15415361593593 Test RE 1.0851424157698355\n",
      "80 Train Loss 10.754122 Test MSE 5.381514590919171 Test RE 1.1088181375963222\n",
      "81 Train Loss 10.556279 Test MSE 5.4125413707720025 Test RE 1.1120099538542387\n",
      "82 Train Loss 10.317446 Test MSE 5.361342065385034 Test RE 1.1067379924620746\n",
      "83 Train Loss 10.159027 Test MSE 5.382289815416513 Test RE 1.1088979991310859\n",
      "84 Train Loss 9.956828 Test MSE 5.331924463060915 Test RE 1.1036974886643525\n",
      "85 Train Loss 9.741711 Test MSE 5.265122044593331 Test RE 1.096761713835488\n",
      "86 Train Loss 9.618607 Test MSE 5.369658317285191 Test RE 1.1075960188126992\n",
      "87 Train Loss 9.360196 Test MSE 5.277640656318097 Test RE 1.098064796877159\n",
      "88 Train Loss 9.115709 Test MSE 5.09501996615731 Test RE 1.0788995337122447\n",
      "89 Train Loss 8.374154 Test MSE 4.740783483932391 Test RE 1.0407181312465725\n",
      "90 Train Loss 7.564494 Test MSE 4.709198694284529 Test RE 1.0372455200352697\n",
      "91 Train Loss 6.7092595 Test MSE 4.486303356318429 Test RE 1.0124005642429386\n",
      "92 Train Loss 5.7919455 Test MSE 4.591872412769173 Test RE 1.0242429103698747\n",
      "93 Train Loss 5.177567 Test MSE 4.634029601741072 Test RE 1.0289338670419017\n",
      "94 Train Loss 4.8642797 Test MSE 4.625648485048663 Test RE 1.0280029798602937\n",
      "95 Train Loss 4.608356 Test MSE 4.679987747125044 Test RE 1.0340235221907625\n",
      "96 Train Loss 4.3275747 Test MSE 4.68676285835287 Test RE 1.0347717176045645\n",
      "97 Train Loss 4.084914 Test MSE 4.581579328988414 Test RE 1.0230943012817642\n",
      "98 Train Loss 3.9432633 Test MSE 4.558576787402159 Test RE 1.0205227663747671\n",
      "99 Train Loss 3.8021076 Test MSE 4.584803222745426 Test RE 1.0234541954433278\n",
      "Training time: 71.11\n",
      "KG_stan_tune8\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.217606 Test MSE 8.55450879314712 Test RE 1.3979949377730259\n",
      "1 Train Loss 56.410812 Test MSE 8.584110223031962 Test RE 1.4004116113963465\n",
      "2 Train Loss 52.347923 Test MSE 8.712637567754522 Test RE 1.4108566336352437\n",
      "3 Train Loss 47.116608 Test MSE 8.236650047681856 Test RE 1.371776527888684\n",
      "4 Train Loss 45.364723 Test MSE 8.128158752467142 Test RE 1.3627122152865097\n",
      "5 Train Loss 44.646645 Test MSE 8.232877105542887 Test RE 1.3714623087419078\n",
      "6 Train Loss 44.413086 Test MSE 8.018509255160147 Test RE 1.3534894585632242\n",
      "7 Train Loss 44.02301 Test MSE 8.000574338609699 Test RE 1.3519749432915145\n",
      "8 Train Loss 43.699303 Test MSE 8.08249921607387 Test RE 1.3588793401687451\n",
      "9 Train Loss 43.03273 Test MSE 8.005620380607207 Test RE 1.3524012281242455\n",
      "10 Train Loss 42.772835 Test MSE 8.03243761751671 Test RE 1.3546644719958354\n",
      "11 Train Loss 41.866364 Test MSE 7.934771345095941 Test RE 1.3464036131456332\n",
      "12 Train Loss 41.603535 Test MSE 8.036704574856204 Test RE 1.3550242337732912\n",
      "13 Train Loss 41.063416 Test MSE 7.912994590052067 Test RE 1.344554760467038\n",
      "14 Train Loss 40.71205 Test MSE 7.9420451424762035 Test RE 1.3470205952400676\n",
      "15 Train Loss 40.135777 Test MSE 8.042432541043576 Test RE 1.3555070280861459\n",
      "16 Train Loss 39.197525 Test MSE 8.055878272677772 Test RE 1.3566396563243799\n",
      "17 Train Loss 36.982674 Test MSE 7.614777775778208 Test RE 1.3189753437353249\n",
      "18 Train Loss 36.25679 Test MSE 7.5917620040455756 Test RE 1.3169805245921697\n",
      "19 Train Loss 35.29075 Test MSE 7.1997976381159825 Test RE 1.282531986600636\n",
      "20 Train Loss 34.842064 Test MSE 7.184765300240933 Test RE 1.2811923983955267\n",
      "21 Train Loss 34.10338 Test MSE 6.953384180117452 Test RE 1.2603935524306993\n",
      "22 Train Loss 32.049263 Test MSE 6.323023292393613 Test RE 1.201905855794457\n",
      "23 Train Loss 31.323086 Test MSE 6.11285756770527 Test RE 1.1817624833779978\n",
      "24 Train Loss 30.055958 Test MSE 5.879757686678774 Test RE 1.1590115784271553\n",
      "25 Train Loss 28.865349 Test MSE 6.166476712835574 Test RE 1.186934102969127\n",
      "26 Train Loss 26.772171 Test MSE 5.635660295980392 Test RE 1.1346984556549398\n",
      "27 Train Loss 26.444387 Test MSE 5.604067228777767 Test RE 1.131513470656678\n",
      "28 Train Loss 26.140461 Test MSE 5.841563105997846 Test RE 1.15524100754542\n",
      "29 Train Loss 25.914982 Test MSE 5.661356280260981 Test RE 1.1372823617015606\n",
      "30 Train Loss 25.52399 Test MSE 5.580871325850502 Test RE 1.1291693078163747\n",
      "31 Train Loss 24.92937 Test MSE 5.742757669581039 Test RE 1.1454293458557032\n",
      "32 Train Loss 24.52948 Test MSE 5.568742783213199 Test RE 1.1279416655630918\n",
      "33 Train Loss 24.20887 Test MSE 5.679977057569165 Test RE 1.1391511450575522\n",
      "34 Train Loss 23.830135 Test MSE 5.707362805700207 Test RE 1.1418940252905576\n",
      "35 Train Loss 23.589893 Test MSE 5.5759106950221184 Test RE 1.1286673577602868\n",
      "36 Train Loss 22.924374 Test MSE 5.51054770241093 Test RE 1.122032517648253\n",
      "37 Train Loss 21.688309 Test MSE 5.553809454037036 Test RE 1.1264282870219025\n",
      "38 Train Loss 19.638554 Test MSE 5.307765959873879 Test RE 1.1011942695336066\n",
      "39 Train Loss 18.163212 Test MSE 5.644477886193869 Test RE 1.135585786947079\n",
      "40 Train Loss 17.04578 Test MSE 5.66984883201031 Test RE 1.1381350557747623\n",
      "41 Train Loss 16.34883 Test MSE 5.894535338464234 Test RE 1.160467141928006\n",
      "42 Train Loss 15.73591 Test MSE 5.958091554576491 Test RE 1.1667065781488049\n",
      "43 Train Loss 15.158586 Test MSE 6.001469457528621 Test RE 1.1709459812194993\n",
      "44 Train Loss 14.71907 Test MSE 6.09971399332111 Test RE 1.1804913150843306\n",
      "45 Train Loss 14.387331 Test MSE 6.123295023495081 Test RE 1.1827709587779003\n",
      "46 Train Loss 14.107677 Test MSE 6.080819607073439 Test RE 1.1786615605790471\n",
      "47 Train Loss 13.682653 Test MSE 5.998218839866584 Test RE 1.170628824457952\n",
      "48 Train Loss 13.289936 Test MSE 5.932236448640185 Test RE 1.164172367432143\n",
      "49 Train Loss 12.830486 Test MSE 6.034719947595232 Test RE 1.1741852502632963\n",
      "50 Train Loss 12.349992 Test MSE 5.91172943610929 Test RE 1.1621584250191854\n",
      "51 Train Loss 12.023937 Test MSE 5.946422359133888 Test RE 1.1655634940198794\n",
      "52 Train Loss 11.73419 Test MSE 5.8730642197554515 Test RE 1.1583516860310468\n",
      "53 Train Loss 11.434867 Test MSE 5.669902242883956 Test RE 1.1381404164683457\n",
      "54 Train Loss 11.047457 Test MSE 5.563844586274014 Test RE 1.127445494697638\n",
      "55 Train Loss 10.832216 Test MSE 5.492421209259803 Test RE 1.12018558074846\n",
      "56 Train Loss 10.677836 Test MSE 5.42884491548442 Test RE 1.113683481205448\n",
      "57 Train Loss 10.535906 Test MSE 5.3834112382389465 Test RE 1.1090135149058753\n",
      "58 Train Loss 10.417006 Test MSE 5.303710200091455 Test RE 1.1007734679230057\n",
      "59 Train Loss 10.286786 Test MSE 5.24735520639582 Test RE 1.0949096718396962\n",
      "60 Train Loss 10.159122 Test MSE 5.3008067963334335 Test RE 1.1004721291227233\n",
      "61 Train Loss 10.055258 Test MSE 5.293430081660363 Test RE 1.099706142412538\n",
      "62 Train Loss 9.920378 Test MSE 5.203256634531571 Test RE 1.0902991753528324\n",
      "63 Train Loss 9.821249 Test MSE 5.14936504523676 Test RE 1.0846382118740647\n",
      "64 Train Loss 9.66523 Test MSE 5.171249635835749 Test RE 1.0869406021962522\n",
      "65 Train Loss 9.516564 Test MSE 5.130750122356866 Test RE 1.0826759566601267\n",
      "66 Train Loss 9.188197 Test MSE 4.435494687027275 Test RE 1.0066513770478096\n",
      "67 Train Loss 8.428901 Test MSE 3.576070343533104 Test RE 0.9038806449133072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 Train Loss 7.2705736 Test MSE 3.502859202936718 Test RE 0.8945804457899484\n",
      "69 Train Loss 6.8466167 Test MSE 3.5099476865012162 Test RE 0.8954851372997963\n",
      "70 Train Loss 6.636693 Test MSE 3.401215748613473 Test RE 0.8815057528862275\n",
      "71 Train Loss 6.5294724 Test MSE 3.343238198700526 Test RE 0.8739603308537413\n",
      "72 Train Loss 6.460799 Test MSE 3.329068489876204 Test RE 0.8721063030908526\n",
      "73 Train Loss 6.3003235 Test MSE 3.2930740912279286 Test RE 0.8673788162900458\n",
      "74 Train Loss 6.1527452 Test MSE 3.323283523028517 Test RE 0.871348238228289\n",
      "75 Train Loss 6.05404 Test MSE 3.2940076973836376 Test RE 0.8675017611119404\n",
      "76 Train Loss 5.9950037 Test MSE 3.242085615251188 Test RE 0.8606375684244473\n",
      "77 Train Loss 5.951179 Test MSE 3.2304957838677297 Test RE 0.8590978844351583\n",
      "78 Train Loss 5.8611517 Test MSE 3.168056895950011 Test RE 0.8507550712956593\n",
      "79 Train Loss 5.7976274 Test MSE 3.1258546153440303 Test RE 0.8450695393023098\n",
      "80 Train Loss 5.746908 Test MSE 3.0848999059359494 Test RE 0.8395152679954606\n",
      "81 Train Loss 5.692801 Test MSE 3.0413578162959447 Test RE 0.8335695070926202\n",
      "82 Train Loss 5.64817 Test MSE 3.014138881376991 Test RE 0.8298310672147007\n",
      "83 Train Loss 5.5539246 Test MSE 2.9521046935714192 Test RE 0.8212472681616294\n",
      "84 Train Loss 5.5012546 Test MSE 2.9091694794178125 Test RE 0.8152533116109534\n",
      "85 Train Loss 5.4589477 Test MSE 2.872097167795534 Test RE 0.8100421629641942\n",
      "86 Train Loss 5.406099 Test MSE 2.826113818741751 Test RE 0.8035314592300998\n",
      "87 Train Loss 5.35555 Test MSE 2.767165200760176 Test RE 0.7951070495584085\n",
      "88 Train Loss 5.3173695 Test MSE 2.7199306743829643 Test RE 0.7882917433057146\n",
      "89 Train Loss 5.2768273 Test MSE 2.653076858060151 Test RE 0.778543666405739\n",
      "90 Train Loss 5.2166014 Test MSE 2.5398438278476325 Test RE 0.76174842836115\n",
      "91 Train Loss 5.144553 Test MSE 2.440480611955024 Test RE 0.7466992948297251\n",
      "92 Train Loss 5.0915294 Test MSE 2.371907973742198 Test RE 0.7361341707926156\n",
      "93 Train Loss 5.013729 Test MSE 2.3762973726773446 Test RE 0.7368149925345814\n",
      "94 Train Loss 4.9628315 Test MSE 2.324303011707602 Test RE 0.7287095023571688\n",
      "95 Train Loss 4.9120827 Test MSE 2.3227587754637673 Test RE 0.7284673896485917\n",
      "96 Train Loss 4.8576765 Test MSE 2.3113887370864545 Test RE 0.7266822574115672\n",
      "97 Train Loss 4.812337 Test MSE 2.217498028969065 Test RE 0.7117700037759138\n",
      "98 Train Loss 4.692583 Test MSE 2.0727529474303212 Test RE 0.68814796667417\n",
      "99 Train Loss 4.498357 Test MSE 1.659816489831696 Test RE 0.6157977499568159\n",
      "Training time: 81.21\n",
      "KG_stan_tune8\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.857975 Test MSE 8.612236043373825 Test RE 1.4027039581661664\n",
      "1 Train Loss 56.72253 Test MSE 8.47348304406531 Test RE 1.3913584907827579\n",
      "2 Train Loss 49.803165 Test MSE 8.675824972876667 Test RE 1.4078729062169437\n",
      "3 Train Loss 46.391888 Test MSE 8.791691972153494 Test RE 1.417242906937164\n",
      "4 Train Loss 45.72384 Test MSE 8.733284838308974 Test RE 1.412527373437056\n",
      "5 Train Loss 45.122086 Test MSE 8.658240178872767 Test RE 1.406445392824972\n",
      "6 Train Loss 44.606865 Test MSE 8.574222751225129 Test RE 1.399604858017687\n",
      "7 Train Loss 44.491325 Test MSE 8.50697745315062 Test RE 1.3941056944784693\n",
      "8 Train Loss 44.37023 Test MSE 8.44039059672605 Test RE 1.388638918440462\n",
      "9 Train Loss 44.310112 Test MSE 8.42840263182579 Test RE 1.387652419677169\n",
      "10 Train Loss 43.953674 Test MSE 8.497164188883966 Test RE 1.393301373830198\n",
      "11 Train Loss 43.57753 Test MSE 8.399645459908232 Test RE 1.3852831062126232\n",
      "12 Train Loss 42.331406 Test MSE 8.347832588066346 Test RE 1.381003965792287\n",
      "13 Train Loss 40.36824 Test MSE 7.680096993398755 Test RE 1.3246203192703538\n",
      "14 Train Loss 34.996964 Test MSE 7.216205980902587 Test RE 1.2839926004415656\n",
      "15 Train Loss 32.669987 Test MSE 7.062614504204129 Test RE 1.2702547022674877\n",
      "16 Train Loss 32.093395 Test MSE 7.1756125484814435 Test RE 1.2803760757685385\n",
      "17 Train Loss 31.720331 Test MSE 7.157485198040536 Test RE 1.2787577816764297\n",
      "18 Train Loss 31.492388 Test MSE 7.2019220540775715 Test RE 1.282721188478494\n",
      "19 Train Loss 31.173393 Test MSE 7.165990031283886 Test RE 1.2795172937528125\n",
      "20 Train Loss 30.785542 Test MSE 7.195738103209763 Test RE 1.282170364111871\n",
      "21 Train Loss 30.317688 Test MSE 7.119883612378237 Test RE 1.2753944049907937\n",
      "22 Train Loss 29.609406 Test MSE 7.186689291852851 Test RE 1.281363930681027\n",
      "23 Train Loss 28.537083 Test MSE 7.319722585238486 Test RE 1.2931692562537676\n",
      "24 Train Loss 26.663532 Test MSE 7.2485473072073345 Test RE 1.286866659212469\n",
      "25 Train Loss 24.974304 Test MSE 7.317226050191348 Test RE 1.2929487070689871\n",
      "26 Train Loss 21.22255 Test MSE 6.39818426673053 Test RE 1.2090282037940947\n",
      "27 Train Loss 18.933474 Test MSE 6.370280911156592 Test RE 1.2063889545437785\n",
      "28 Train Loss 16.822706 Test MSE 6.0361390237550845 Test RE 1.1743232981235046\n",
      "29 Train Loss 14.305451 Test MSE 5.6908703149029325 Test RE 1.1402429736426938\n",
      "30 Train Loss 12.088646 Test MSE 5.165240164209027 Test RE 1.0863088557179323\n",
      "31 Train Loss 10.059973 Test MSE 4.11863722938209 Test RE 0.970029251459973\n",
      "32 Train Loss 8.302185 Test MSE 4.103201953760645 Test RE 0.9682098725598518\n",
      "33 Train Loss 7.04684 Test MSE 4.194218986348158 Test RE 0.9788893672834802\n",
      "34 Train Loss 6.39048 Test MSE 4.186368091828152 Test RE 0.9779727774601255\n",
      "35 Train Loss 5.6994104 Test MSE 4.133078662765559 Test RE 0.9717284001953396\n",
      "36 Train Loss 5.286805 Test MSE 4.0159218206252225 Test RE 0.9578570169945528\n",
      "37 Train Loss 4.947897 Test MSE 4.079388673758478 Test RE 0.9653962403391895\n",
      "38 Train Loss 4.78759 Test MSE 4.096010581724343 Test RE 0.9673610463343381\n",
      "39 Train Loss 4.634721 Test MSE 4.10531471180309 Test RE 0.9684591083962117\n",
      "40 Train Loss 4.5066338 Test MSE 4.109687319144064 Test RE 0.9689747283549985\n",
      "41 Train Loss 4.3398767 Test MSE 4.067318691497893 Test RE 0.9639669885149985\n",
      "42 Train Loss 4.2144423 Test MSE 4.053297391779337 Test RE 0.9623040085857305\n",
      "43 Train Loss 4.1344166 Test MSE 4.063270375369751 Test RE 0.9634871374215704\n",
      "44 Train Loss 4.0577745 Test MSE 4.012154947475774 Test RE 0.9574076839985101\n",
      "45 Train Loss 3.9938815 Test MSE 4.026736004103987 Test RE 0.9591458216564188\n",
      "46 Train Loss 3.9435892 Test MSE 4.029492858165258 Test RE 0.9594740990282294\n",
      "47 Train Loss 3.8303223 Test MSE 3.9456194635388004 Test RE 0.9494359212336836\n",
      "48 Train Loss 3.7791724 Test MSE 3.952094557765632 Test RE 0.9502146540737834\n",
      "49 Train Loss 3.727468 Test MSE 3.993275835311996 Test RE 0.9551524969037638\n",
      "50 Train Loss 3.6847975 Test MSE 3.9609434949879225 Test RE 0.9512778483191919\n",
      "51 Train Loss 3.6530178 Test MSE 3.9278667702878933 Test RE 0.9472975945711936\n",
      "52 Train Loss 3.6096063 Test MSE 3.9361565923933832 Test RE 0.948296710622545\n",
      "53 Train Loss 3.5503848 Test MSE 3.9239925581464163 Test RE 0.9468303005565853\n",
      "54 Train Loss 3.5018556 Test MSE 3.897466830612549 Test RE 0.9436246432455964\n",
      "55 Train Loss 3.416679 Test MSE 3.8615516134744516 Test RE 0.9392668228218649\n",
      "56 Train Loss 3.2429347 Test MSE 3.7152897665439912 Test RE 0.9213070743509695\n",
      "57 Train Loss 3.111941 Test MSE 3.533045319469297 Test RE 0.8984267296922341\n",
      "58 Train Loss 2.9326549 Test MSE 3.3298806687472964 Test RE 0.872212678661002\n",
      "59 Train Loss 2.8262105 Test MSE 3.2611023409329496 Test RE 0.863157948950454\n",
      "60 Train Loss 2.7563121 Test MSE 3.2191157437599505 Test RE 0.8575833810596288\n",
      "61 Train Loss 2.5938058 Test MSE 3.0364186241586975 Test RE 0.832892369915927\n",
      "62 Train Loss 2.2691922 Test MSE 2.8932290744547977 Test RE 0.8130167078830947\n",
      "63 Train Loss 1.9627177 Test MSE 2.6435604125892813 Test RE 0.777146114698612\n",
      "64 Train Loss 1.7430601 Test MSE 2.5219549595351656 Test RE 0.7590610787555511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Train Loss 1.6585515 Test MSE 2.46875085365378 Test RE 0.7510116808516492\n",
      "66 Train Loss 1.6036882 Test MSE 2.485812632263311 Test RE 0.7536023700223177\n",
      "67 Train Loss 1.558806 Test MSE 2.484177146133598 Test RE 0.7533544211223591\n",
      "68 Train Loss 1.5298737 Test MSE 2.4663152254631275 Test RE 0.7506411216673874\n",
      "69 Train Loss 1.5019246 Test MSE 2.4903154862238814 Test RE 0.754284606901512\n",
      "70 Train Loss 1.4783992 Test MSE 2.49325467323948 Test RE 0.7547295966575722\n",
      "71 Train Loss 1.4517186 Test MSE 2.4724010903298375 Test RE 0.7515666898341514\n",
      "72 Train Loss 1.4213907 Test MSE 2.4875060816697596 Test RE 0.7538590205426173\n",
      "73 Train Loss 1.3961432 Test MSE 2.4750559278897404 Test RE 0.7519700936634489\n",
      "74 Train Loss 1.3775175 Test MSE 2.4829460337293496 Test RE 0.7531677237060584\n",
      "75 Train Loss 1.3342595 Test MSE 2.4663887495661214 Test RE 0.7506523103839099\n",
      "76 Train Loss 1.3092929 Test MSE 2.4602101239252665 Test RE 0.7497114797959283\n",
      "77 Train Loss 1.294227 Test MSE 2.4788164740746224 Test RE 0.7525411403454344\n",
      "78 Train Loss 1.2736038 Test MSE 2.5168516829470486 Test RE 0.7582926946397468\n",
      "79 Train Loss 1.2600971 Test MSE 2.5243696778813995 Test RE 0.7594243842480983\n",
      "80 Train Loss 1.2403791 Test MSE 2.5406737170929317 Test RE 0.7618728681377205\n",
      "81 Train Loss 1.2182449 Test MSE 2.549919050570767 Test RE 0.7632578103232862\n",
      "82 Train Loss 1.2105281 Test MSE 2.560210848109415 Test RE 0.7647965620270074\n",
      "83 Train Loss 1.1895257 Test MSE 2.574140842115324 Test RE 0.7668743517070001\n",
      "84 Train Loss 1.1675308 Test MSE 2.590723565427255 Test RE 0.7693405046930831\n",
      "85 Train Loss 1.1554642 Test MSE 2.569140554128611 Test RE 0.7661291600419793\n",
      "86 Train Loss 1.1453688 Test MSE 2.5594922255235453 Test RE 0.7646892195681746\n",
      "87 Train Loss 1.1367023 Test MSE 2.5558798546476478 Test RE 0.7641494022573898\n",
      "88 Train Loss 1.1291138 Test MSE 2.5540398264108295 Test RE 0.7638742896327073\n",
      "89 Train Loss 1.1165274 Test MSE 2.5650236260185784 Test RE 0.7655150707782931\n",
      "90 Train Loss 1.1062568 Test MSE 2.570299128176294 Test RE 0.7663018865426039\n",
      "91 Train Loss 1.0946487 Test MSE 2.5719790546324166 Test RE 0.7665522699551733\n",
      "92 Train Loss 1.0833356 Test MSE 2.561454372920126 Test RE 0.7649822748649727\n",
      "93 Train Loss 1.0702616 Test MSE 2.578429338316904 Test RE 0.7675128888605056\n",
      "94 Train Loss 1.0611254 Test MSE 2.587582782262602 Test RE 0.7688740202478327\n",
      "95 Train Loss 1.0487814 Test MSE 2.586864456122895 Test RE 0.7687672911710904\n",
      "96 Train Loss 1.0295522 Test MSE 2.5887025648114896 Test RE 0.7690403682752918\n",
      "97 Train Loss 1.0222777 Test MSE 2.577067781848097 Test RE 0.7673102170020997\n",
      "98 Train Loss 1.0115619 Test MSE 2.5650043344049513 Test RE 0.7655121920428715\n",
      "99 Train Loss 0.9950499 Test MSE 2.5908880539971464 Test RE 0.7693649275439921\n",
      "Training time: 81.05\n",
      "KG_stan_tune8\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.96483 Test MSE 8.53586246535805 Test RE 1.396470496518899\n",
      "1 Train Loss 58.85521 Test MSE 8.48282880846898 Test RE 1.3921255735212754\n",
      "2 Train Loss 58.694366 Test MSE 8.589749706730434 Test RE 1.4008715485102385\n",
      "3 Train Loss 56.517757 Test MSE 8.686806457321634 Test RE 1.4087636367954814\n",
      "4 Train Loss 55.568264 Test MSE 8.720736019752492 Test RE 1.4115121814409455\n",
      "5 Train Loss 54.6096 Test MSE 8.877994321415182 Test RE 1.424181997504909\n",
      "6 Train Loss 46.546608 Test MSE 8.704975229299006 Test RE 1.4102361074846577\n",
      "7 Train Loss 46.084194 Test MSE 8.53386985768052 Test RE 1.3963074913008378\n",
      "8 Train Loss 45.952507 Test MSE 8.494336428286296 Test RE 1.39306951703168\n",
      "9 Train Loss 45.575115 Test MSE 8.550866702761809 Test RE 1.3976973072426786\n",
      "10 Train Loss 44.848648 Test MSE 8.561957369047553 Test RE 1.398603435930249\n",
      "11 Train Loss 44.4056 Test MSE 8.614489221235809 Test RE 1.4028874375086542\n",
      "12 Train Loss 44.089615 Test MSE 8.616694803680522 Test RE 1.4030670178527502\n",
      "13 Train Loss 43.849205 Test MSE 8.511793201935966 Test RE 1.394500236075035\n",
      "14 Train Loss 43.41706 Test MSE 8.624713843445841 Test RE 1.403719741081767\n",
      "15 Train Loss 42.750336 Test MSE 8.801792993150343 Test RE 1.4180568282430905\n",
      "16 Train Loss 41.90614 Test MSE 9.066883849863489 Test RE 1.439252811261415\n",
      "17 Train Loss 40.814545 Test MSE 9.527702500648257 Test RE 1.4753740968273246\n",
      "18 Train Loss 40.345146 Test MSE 9.631652171704248 Test RE 1.483400617735551\n",
      "19 Train Loss 38.908676 Test MSE 9.736069007539466 Test RE 1.4914197228596016\n",
      "20 Train Loss 37.339706 Test MSE 9.587299476429305 Test RE 1.479981228649744\n",
      "21 Train Loss 35.37009 Test MSE 9.339619618340448 Test RE 1.4607391012030504\n",
      "22 Train Loss 33.45002 Test MSE 9.079895609953434 Test RE 1.4402851669540937\n",
      "23 Train Loss 30.31818 Test MSE 8.466549569472848 Test RE 1.3907891308796445\n",
      "24 Train Loss 27.505491 Test MSE 8.43930293820039 Test RE 1.3885494431014789\n",
      "25 Train Loss 25.887638 Test MSE 8.568131363857544 Test RE 1.3991076088595509\n",
      "26 Train Loss 25.355938 Test MSE 8.409494563022095 Test RE 1.3860950332763784\n",
      "27 Train Loss 24.771387 Test MSE 7.933871785319063 Test RE 1.3463272905390637\n",
      "28 Train Loss 22.013742 Test MSE 7.1502175536982175 Test RE 1.278108397371301\n",
      "29 Train Loss 20.234957 Test MSE 7.628274881916418 Test RE 1.3201437605361983\n",
      "30 Train Loss 19.52976 Test MSE 7.712210215973342 Test RE 1.327386785204647\n",
      "31 Train Loss 19.063324 Test MSE 7.768509664516406 Test RE 1.3322229639635026\n",
      "32 Train Loss 18.681244 Test MSE 7.965210783501838 Test RE 1.3489836836801175\n",
      "33 Train Loss 18.1945 Test MSE 8.096078119283995 Test RE 1.3600203453821467\n",
      "34 Train Loss 17.63579 Test MSE 8.350754154945431 Test RE 1.3812456059096934\n",
      "35 Train Loss 16.798927 Test MSE 8.127261836270627 Test RE 1.3626370277555024\n",
      "36 Train Loss 15.550888 Test MSE 7.442512846355147 Test RE 1.3039707713698099\n",
      "37 Train Loss 14.331522 Test MSE 6.815768300093051 Test RE 1.2478588672028699\n",
      "38 Train Loss 13.224876 Test MSE 6.616631395203317 Test RE 1.229494331855194\n",
      "39 Train Loss 11.766554 Test MSE 6.715197058657712 Test RE 1.238618154214582\n",
      "40 Train Loss 10.89313 Test MSE 6.326149995759343 Test RE 1.2022029872810298\n",
      "41 Train Loss 10.163712 Test MSE 6.497318182748329 Test RE 1.218358585234317\n",
      "42 Train Loss 9.163964 Test MSE 6.595554528525014 Test RE 1.2275345311448331\n",
      "43 Train Loss 8.357384 Test MSE 6.371902893591628 Test RE 1.2065425283957218\n",
      "44 Train Loss 7.3183775 Test MSE 6.213056090838299 Test RE 1.1914085089661894\n",
      "45 Train Loss 6.2093096 Test MSE 6.093537447124464 Test RE 1.1798934832937094\n",
      "46 Train Loss 5.3599606 Test MSE 6.040131544273012 Test RE 1.1747116038610643\n",
      "47 Train Loss 4.815846 Test MSE 5.964724179864654 Test RE 1.167355794015941\n",
      "48 Train Loss 4.4032583 Test MSE 5.999565403146454 Test RE 1.1707602165738877\n",
      "49 Train Loss 3.9838557 Test MSE 6.031313679176544 Test RE 1.1738538219023242\n",
      "50 Train Loss 3.640297 Test MSE 6.024172885766235 Test RE 1.173158722078368\n",
      "51 Train Loss 3.3997593 Test MSE 6.108560492133021 Test RE 1.1813470462945674\n",
      "52 Train Loss 3.1779964 Test MSE 6.155430536333066 Test RE 1.1858705328760595\n",
      "53 Train Loss 2.9855118 Test MSE 5.984642290032998 Test RE 1.1693032556166278\n",
      "54 Train Loss 2.7932591 Test MSE 5.910555680102543 Test RE 1.1620430477710693\n",
      "55 Train Loss 2.6627614 Test MSE 5.887661855424374 Test RE 1.1597903474559788\n",
      "56 Train Loss 2.5123215 Test MSE 5.73515050691916 Test RE 1.1446704460947665\n",
      "57 Train Loss 2.4196012 Test MSE 5.714485536463964 Test RE 1.1426063391875905\n",
      "58 Train Loss 2.329155 Test MSE 5.786463069179635 Test RE 1.1497797435571817\n",
      "59 Train Loss 2.2585807 Test MSE 5.756322931220579 Test RE 1.1467813865194416\n",
      "60 Train Loss 2.217265 Test MSE 5.694492671721584 Test RE 1.140605810047765\n",
      "61 Train Loss 2.1702147 Test MSE 5.663196968738108 Test RE 1.1374672301594004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 Train Loss 2.1243255 Test MSE 5.591854881201847 Test RE 1.1302799047748084\n",
      "63 Train Loss 2.0821033 Test MSE 5.637697364718963 Test RE 1.1349035114773989\n",
      "64 Train Loss 2.0284524 Test MSE 5.6658340181546265 Test RE 1.137732028312271\n",
      "65 Train Loss 1.9817526 Test MSE 5.634462316217525 Test RE 1.134577847069379\n",
      "66 Train Loss 1.9321775 Test MSE 5.63027909477064 Test RE 1.1341565937733131\n",
      "67 Train Loss 1.9021561 Test MSE 5.671495594444934 Test RE 1.1383003249063819\n",
      "68 Train Loss 1.8400886 Test MSE 5.723762399915631 Test RE 1.1435334134179236\n",
      "69 Train Loss 1.817588 Test MSE 5.7502958862272155 Test RE 1.1461808718128117\n",
      "70 Train Loss 1.7954949 Test MSE 5.762771018955078 Test RE 1.1474235045385022\n",
      "71 Train Loss 1.7753907 Test MSE 5.742685876665392 Test RE 1.145422186057732\n",
      "72 Train Loss 1.7556612 Test MSE 5.773955294282324 Test RE 1.1485364135735563\n",
      "73 Train Loss 1.7343683 Test MSE 5.834916013916273 Test RE 1.154583548323279\n",
      "74 Train Loss 1.7103214 Test MSE 5.868790907477143 Test RE 1.1579301940257982\n",
      "75 Train Loss 1.6757178 Test MSE 5.937015867338201 Test RE 1.1646412417749792\n",
      "76 Train Loss 1.6570005 Test MSE 5.950819969299159 Test RE 1.1659944040905004\n",
      "77 Train Loss 1.6457419 Test MSE 5.931907892420639 Test RE 1.1641401282107695\n",
      "78 Train Loss 1.6115133 Test MSE 5.946953585998084 Test RE 1.1656155559803754\n",
      "79 Train Loss 1.5906459 Test MSE 5.9258979622782855 Test RE 1.163550252745933\n",
      "80 Train Loss 1.5574154 Test MSE 5.939113424791492 Test RE 1.1648469584379852\n",
      "81 Train Loss 1.5464948 Test MSE 5.944593260014202 Test RE 1.1653842185664236\n",
      "82 Train Loss 1.5192935 Test MSE 5.937652867358415 Test RE 1.1647037190036633\n",
      "83 Train Loss 1.4968168 Test MSE 5.934712641024977 Test RE 1.1644153124005303\n",
      "84 Train Loss 1.4834088 Test MSE 5.955791678825786 Test RE 1.166481376913215\n",
      "85 Train Loss 1.4665008 Test MSE 5.959175270077972 Test RE 1.1668126792806632\n",
      "86 Train Loss 1.4417483 Test MSE 5.886272551589558 Test RE 1.159653502280233\n",
      "87 Train Loss 1.4282975 Test MSE 5.891500576062698 Test RE 1.1601683740649427\n",
      "88 Train Loss 1.4144759 Test MSE 5.895655473530748 Test RE 1.160577398132828\n",
      "89 Train Loss 1.3983978 Test MSE 5.869029030708063 Test RE 1.1579536850043048\n",
      "90 Train Loss 1.3907708 Test MSE 5.873559383863021 Test RE 1.1584005159150945\n",
      "91 Train Loss 1.3814168 Test MSE 5.896487891328249 Test RE 1.1606593272064925\n",
      "92 Train Loss 1.3684725 Test MSE 5.9327283412586596 Test RE 1.1642206321910444\n",
      "93 Train Loss 1.35768 Test MSE 5.956539856709713 Test RE 1.1665546424174777\n",
      "94 Train Loss 1.3476871 Test MSE 5.949421627287915 Test RE 1.1658574015629193\n",
      "95 Train Loss 1.3396738 Test MSE 5.959749585650093 Test RE 1.1668689037174513\n",
      "96 Train Loss 1.329549 Test MSE 5.961948263657962 Test RE 1.167084125211261\n",
      "97 Train Loss 1.3190746 Test MSE 5.941496586174444 Test RE 1.1650806414530774\n",
      "98 Train Loss 1.3121281 Test MSE 5.93410160990188 Test RE 1.1643553674332068\n",
      "99 Train Loss 1.3007169 Test MSE 5.932502846543819 Test RE 1.1641985067810332\n",
      "Training time: 80.20\n",
      "KG_stan_tune8\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.650482 Test MSE 8.459730275244675 Test RE 1.3902289197380189\n",
      "1 Train Loss 55.149277 Test MSE 8.765446273321821 Test RE 1.4151258893771694\n",
      "2 Train Loss 54.751167 Test MSE 8.32030157189219 Test RE 1.3787248207796976\n",
      "3 Train Loss 48.63719 Test MSE 7.694510926230715 Test RE 1.3258627539907912\n",
      "4 Train Loss 44.908543 Test MSE 7.703918920836557 Test RE 1.326673065342558\n",
      "5 Train Loss 43.460747 Test MSE 7.55419811089597 Test RE 1.313718286996209\n",
      "6 Train Loss 41.154495 Test MSE 7.521556852738936 Test RE 1.3108769635685966\n",
      "7 Train Loss 39.85981 Test MSE 7.5239832020450255 Test RE 1.3110883818299086\n",
      "8 Train Loss 38.81595 Test MSE 7.238941027030449 Test RE 1.2860136538020452\n",
      "9 Train Loss 37.776073 Test MSE 7.340995140595605 Test RE 1.295046995239509\n",
      "10 Train Loss 36.2414 Test MSE 7.047423132817246 Test RE 1.2688878360168956\n",
      "11 Train Loss 34.79322 Test MSE 6.573254890589367 Test RE 1.2254576206847645\n",
      "12 Train Loss 31.453247 Test MSE 6.298066051368836 Test RE 1.1995315238946374\n",
      "13 Train Loss 30.078537 Test MSE 6.412401827474576 Test RE 1.2103707638505115\n",
      "14 Train Loss 28.838692 Test MSE 6.250710923402243 Test RE 1.1950133790493738\n",
      "15 Train Loss 28.005829 Test MSE 6.064968092041068 Test RE 1.1771242872622958\n",
      "16 Train Loss 27.091152 Test MSE 6.036839196215838 Test RE 1.1743914049868116\n",
      "17 Train Loss 26.456491 Test MSE 5.964400828485145 Test RE 1.167324152048031\n",
      "18 Train Loss 25.88116 Test MSE 5.963496757837494 Test RE 1.1672356784924136\n",
      "19 Train Loss 25.397816 Test MSE 5.731226990080126 Test RE 1.1442788345630697\n",
      "20 Train Loss 24.440693 Test MSE 5.516810131277289 Test RE 1.1226699001728413\n",
      "21 Train Loss 23.827675 Test MSE 5.532765361837869 Test RE 1.1242921713914353\n",
      "22 Train Loss 23.075024 Test MSE 5.348167652611797 Test RE 1.1053773637965996\n",
      "23 Train Loss 22.113724 Test MSE 5.8432636646234 Test RE 1.1554091485094011\n",
      "24 Train Loss 20.857328 Test MSE 5.729853461122275 Test RE 1.1441417091014197\n",
      "25 Train Loss 18.867558 Test MSE 5.279286390428597 Test RE 1.098235989077613\n",
      "26 Train Loss 17.42183 Test MSE 5.561837556118658 Test RE 1.1272421262198677\n",
      "27 Train Loss 16.11471 Test MSE 5.796448529915977 Test RE 1.1507713796835863\n",
      "28 Train Loss 15.693121 Test MSE 5.820247395828756 Test RE 1.1531313592441341\n",
      "29 Train Loss 15.292479 Test MSE 5.873986522258101 Test RE 1.1584426358895026\n",
      "30 Train Loss 14.983643 Test MSE 5.80990789403611 Test RE 1.1521066516344116\n",
      "31 Train Loss 14.734217 Test MSE 5.797272926791989 Test RE 1.1508532107044345\n",
      "32 Train Loss 14.271747 Test MSE 5.650458661030751 Test RE 1.1361872495541234\n",
      "33 Train Loss 14.001292 Test MSE 5.71998102314551 Test RE 1.1431556160183851\n",
      "34 Train Loss 13.454548 Test MSE 5.863839220454747 Test RE 1.1574415995313114\n",
      "35 Train Loss 13.184938 Test MSE 5.788411138041574 Test RE 1.1499732695163603\n",
      "36 Train Loss 12.994302 Test MSE 5.900187629871086 Test RE 1.1610233966959704\n",
      "37 Train Loss 12.889158 Test MSE 5.896716661324452 Test RE 1.1606818424273657\n",
      "38 Train Loss 12.79955 Test MSE 5.908046381057464 Test RE 1.1617963515873218\n",
      "39 Train Loss 12.704899 Test MSE 5.946783211214907 Test RE 1.1655988589507835\n",
      "40 Train Loss 12.57283 Test MSE 5.965894342676632 Test RE 1.1674702946456774\n",
      "41 Train Loss 12.468931 Test MSE 5.930309256079216 Test RE 1.1639832510177597\n",
      "42 Train Loss 12.320585 Test MSE 5.812424219159133 Test RE 1.152356118676632\n",
      "43 Train Loss 12.129608 Test MSE 5.817942021101321 Test RE 1.1529029614622603\n",
      "44 Train Loss 11.786187 Test MSE 5.8568521707480565 Test RE 1.1567518200059381\n",
      "45 Train Loss 11.597248 Test MSE 5.84533116408862 Test RE 1.1556135374147678\n",
      "46 Train Loss 11.359977 Test MSE 5.872195192266716 Test RE 1.1582659831798972\n",
      "47 Train Loss 11.135031 Test MSE 5.80877753261398 Test RE 1.1519945706611823\n",
      "48 Train Loss 10.954542 Test MSE 5.822985135478767 Test RE 1.1534025334804343\n",
      "49 Train Loss 10.76564 Test MSE 5.816939802129492 Test RE 1.1528036556440096\n",
      "50 Train Loss 10.636238 Test MSE 5.778420494967332 Test RE 1.1489804293479366\n",
      "51 Train Loss 10.553787 Test MSE 5.813898150419855 Test RE 1.1525022183055633\n",
      "52 Train Loss 10.455805 Test MSE 5.845225338158481 Test RE 1.1556030765505698\n",
      "53 Train Loss 10.347199 Test MSE 5.82731411305384 Test RE 1.1538311904266179\n",
      "54 Train Loss 10.27977 Test MSE 5.840202086222335 Test RE 1.1551064204989936\n",
      "55 Train Loss 10.190757 Test MSE 5.8309234166254695 Test RE 1.1541884632887442\n",
      "56 Train Loss 10.112139 Test MSE 5.820874788961786 Test RE 1.1531935084236802\n",
      "57 Train Loss 9.954743 Test MSE 5.788776929139601 Test RE 1.1500096044733572\n",
      "58 Train Loss 9.876816 Test MSE 5.770127048645913 Test RE 1.1481555993538888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 Train Loss 9.696739 Test MSE 5.711483570261994 Test RE 1.1423061795157976\n",
      "60 Train Loss 9.55226 Test MSE 5.645510325847856 Test RE 1.1356896380217978\n",
      "61 Train Loss 9.48038 Test MSE 5.645462418599235 Test RE 1.1356848193359634\n",
      "62 Train Loss 9.384026 Test MSE 5.672784891224597 Test RE 1.1384297020275262\n",
      "63 Train Loss 9.278043 Test MSE 5.600274082767358 Test RE 1.131130470048078\n",
      "64 Train Loss 9.193625 Test MSE 5.518807811348533 Test RE 1.12287314554848\n",
      "65 Train Loss 9.113219 Test MSE 5.476530645570807 Test RE 1.1185639576772621\n",
      "66 Train Loss 9.005071 Test MSE 5.4330282644295975 Test RE 1.1141124886202682\n",
      "67 Train Loss 8.909456 Test MSE 5.417277319522975 Test RE 1.1124963492710402\n",
      "68 Train Loss 8.811522 Test MSE 5.346702563767936 Test RE 1.105225948669489\n",
      "69 Train Loss 8.705981 Test MSE 5.169277862473386 Test RE 1.086733359748694\n",
      "70 Train Loss 8.638117 Test MSE 5.142579850626487 Test RE 1.0839233754586872\n",
      "71 Train Loss 8.571845 Test MSE 5.129396666094627 Test RE 1.0825331460409278\n",
      "72 Train Loss 8.488586 Test MSE 5.113927710833606 Test RE 1.0808995912460124\n",
      "73 Train Loss 8.392729 Test MSE 5.10849147076109 Test RE 1.0803249260934285\n",
      "74 Train Loss 8.326805 Test MSE 5.0452136986420095 Test RE 1.0736132022863585\n",
      "75 Train Loss 8.207039 Test MSE 4.840262613205144 Test RE 1.0515804970853886\n",
      "76 Train Loss 7.245723 Test MSE 3.9951254729502343 Test RE 0.9553736789046807\n",
      "77 Train Loss 5.695789 Test MSE 3.3254981217384727 Test RE 0.8716385182025428\n",
      "78 Train Loss 4.5141096 Test MSE 3.0911485954219824 Test RE 0.8403650875361792\n",
      "79 Train Loss 3.751722 Test MSE 3.183211036381738 Test RE 0.8527874023904171\n",
      "80 Train Loss 3.3227797 Test MSE 3.029853135217886 Test RE 0.8319914228627965\n",
      "81 Train Loss 2.9665058 Test MSE 2.7503618416964986 Test RE 0.792689265896723\n",
      "82 Train Loss 2.6956542 Test MSE 2.380986725218981 Test RE 0.7375416445045223\n",
      "83 Train Loss 2.5129795 Test MSE 2.145248631489788 Test RE 0.7000787204720991\n",
      "84 Train Loss 2.3525615 Test MSE 1.8893498300397678 Test RE 0.6569983059097492\n",
      "85 Train Loss 2.231773 Test MSE 1.6172960100595097 Test RE 0.6078589532087625\n",
      "86 Train Loss 2.1084566 Test MSE 1.3718087313536687 Test RE 0.5598282907913741\n",
      "87 Train Loss 1.9528788 Test MSE 1.1643919729412862 Test RE 0.5157718812945026\n",
      "88 Train Loss 1.6464478 Test MSE 0.569975626329155 Test RE 0.36085788761154053\n",
      "89 Train Loss 1.3236698 Test MSE 0.38448506296297036 Test RE 0.2963792512014191\n",
      "90 Train Loss 1.0340947 Test MSE 0.2390207746919258 Test RE 0.23368233584264853\n",
      "91 Train Loss 0.8974053 Test MSE 0.17640228708789607 Test RE 0.2007521319261399\n",
      "92 Train Loss 0.76512605 Test MSE 0.12928899156172516 Test RE 0.1718655508207987\n",
      "93 Train Loss 0.6212726 Test MSE 0.1083117747648292 Test RE 0.15730622038420647\n",
      "94 Train Loss 0.5307176 Test MSE 0.07743331174441508 Test RE 0.13300622801528514\n",
      "95 Train Loss 0.40963987 Test MSE 0.032348563854055455 Test RE 0.08596775044821553\n",
      "96 Train Loss 0.32990938 Test MSE 0.02664836521127879 Test RE 0.07802671913652819\n",
      "97 Train Loss 0.26195818 Test MSE 0.02415358715824509 Test RE 0.07428461549355488\n",
      "98 Train Loss 0.21806665 Test MSE 0.02380830447161807 Test RE 0.07375174395256681\n",
      "99 Train Loss 0.18151858 Test MSE 0.029575669340546024 Test RE 0.08220066885464743\n",
      "Training time: 81.25\n",
      "KG_stan_tune8\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 57.153744 Test MSE 8.566089260708571 Test RE 1.3989408693341943\n",
      "1 Train Loss 55.476974 Test MSE 8.494421349661824 Test RE 1.3930764805587854\n",
      "2 Train Loss 48.90445 Test MSE 8.205658450683906 Test RE 1.3691933410746333\n",
      "3 Train Loss 46.464703 Test MSE 8.643960500847717 Test RE 1.405285118072382\n",
      "4 Train Loss 43.106934 Test MSE 8.258409382196383 Test RE 1.3735872917709784\n",
      "5 Train Loss 42.514008 Test MSE 8.181073054054405 Test RE 1.3671406469713172\n",
      "6 Train Loss 41.98278 Test MSE 8.11751292725573 Test RE 1.361819519302157\n",
      "7 Train Loss 41.4206 Test MSE 8.380929880294731 Test RE 1.3837389437601044\n",
      "8 Train Loss 40.739006 Test MSE 8.362553151670847 Test RE 1.3822210603068965\n",
      "9 Train Loss 40.176666 Test MSE 8.209649075358502 Test RE 1.3695262377344164\n",
      "10 Train Loss 39.555717 Test MSE 8.093667720527291 Test RE 1.359817874794728\n",
      "11 Train Loss 39.370667 Test MSE 8.104994721673068 Test RE 1.3607690673789337\n",
      "12 Train Loss 38.88002 Test MSE 8.022308416421627 Test RE 1.3538100615341824\n",
      "13 Train Loss 38.432564 Test MSE 7.814309706669886 Test RE 1.33614432104131\n",
      "14 Train Loss 38.111732 Test MSE 7.5453594474804495 Test RE 1.3129495149807031\n",
      "15 Train Loss 37.729134 Test MSE 7.368219404848772 Test RE 1.2974461300860223\n",
      "16 Train Loss 35.774673 Test MSE 7.467704027345099 Test RE 1.3061757265464848\n",
      "17 Train Loss 29.712193 Test MSE 5.601695799556873 Test RE 1.1312740384793978\n",
      "18 Train Loss 23.18858 Test MSE 2.9983807331590357 Test RE 0.8276590144892929\n",
      "19 Train Loss 17.735365 Test MSE 2.61412071481133 Test RE 0.7728067016529059\n",
      "20 Train Loss 13.660976 Test MSE 2.1933333667262236 Test RE 0.7078812074971749\n",
      "21 Train Loss 10.912385 Test MSE 1.7523582636014785 Test RE 0.6327315797805565\n",
      "22 Train Loss 9.238514 Test MSE 1.7282958492244742 Test RE 0.6283724035724806\n",
      "23 Train Loss 8.697111 Test MSE 1.5498348213722366 Test RE 0.5950463114260276\n",
      "24 Train Loss 8.032707 Test MSE 1.6623199167025218 Test RE 0.6162619650668357\n",
      "25 Train Loss 7.704254 Test MSE 1.7041720201070651 Test RE 0.6239715314720325\n",
      "26 Train Loss 7.011141 Test MSE 1.7623445257234256 Test RE 0.6345319099486707\n",
      "27 Train Loss 6.720813 Test MSE 1.7779450493837337 Test RE 0.6373342052587171\n",
      "28 Train Loss 6.3938904 Test MSE 1.767250370873261 Test RE 0.6354144706225103\n",
      "29 Train Loss 6.048034 Test MSE 1.7985658980043409 Test RE 0.6410194948607234\n",
      "30 Train Loss 5.8075743 Test MSE 1.790993677707018 Test RE 0.6396686795903065\n",
      "31 Train Loss 5.5224676 Test MSE 1.778512983099425 Test RE 0.637435989811148\n",
      "32 Train Loss 5.3917513 Test MSE 1.801321796517124 Test RE 0.641510416118839\n",
      "33 Train Loss 5.2961707 Test MSE 1.7901562464855645 Test RE 0.639519114250404\n",
      "34 Train Loss 5.2176137 Test MSE 1.7712715810973116 Test RE 0.6361369724726623\n",
      "35 Train Loss 5.127013 Test MSE 1.7446607171031754 Test RE 0.6313403570918659\n",
      "36 Train Loss 5.0803556 Test MSE 1.7352585505682765 Test RE 0.6296368779755791\n",
      "37 Train Loss 5.034231 Test MSE 1.7222971470024084 Test RE 0.6272809540323973\n",
      "38 Train Loss 4.9964447 Test MSE 1.7114549121417606 Test RE 0.6253034018698869\n",
      "39 Train Loss 4.93897 Test MSE 1.6766436418600505 Test RE 0.6189113447470713\n",
      "40 Train Loss 4.913547 Test MSE 1.6547064304528283 Test RE 0.6148490942473172\n",
      "41 Train Loss 4.866968 Test MSE 1.6232900073114467 Test RE 0.6089843301461183\n",
      "42 Train Loss 4.8345327 Test MSE 1.607295253488281 Test RE 0.6059766520727567\n",
      "43 Train Loss 4.793633 Test MSE 1.6132650156941288 Test RE 0.6071009581694873\n",
      "44 Train Loss 4.7293677 Test MSE 1.5885965546907288 Test RE 0.6024414823213734\n",
      "45 Train Loss 4.673229 Test MSE 1.5292810287877854 Test RE 0.5910874122960352\n",
      "46 Train Loss 4.593539 Test MSE 1.4320289707763962 Test RE 0.5719841077326634\n",
      "47 Train Loss 4.3100553 Test MSE 1.0205096976341625 Test RE 0.4828548836949952\n",
      "48 Train Loss 3.8083231 Test MSE 0.7637574007850995 Test RE 0.4177204873944707\n",
      "49 Train Loss 3.5295842 Test MSE 0.7134533794463488 Test RE 0.4037298496174892\n",
      "50 Train Loss 1.8895979 Test MSE 0.11036856715822561 Test RE 0.15879278383316728\n",
      "51 Train Loss 1.1568776 Test MSE 0.0748489681106816 Test RE 0.1307678456572955\n",
      "52 Train Loss 0.84192413 Test MSE 0.07512186436102387 Test RE 0.13100601585079583\n",
      "53 Train Loss 0.5910572 Test MSE 0.032712811673569576 Test RE 0.08645039799624109\n",
      "54 Train Loss 0.48904046 Test MSE 0.026938628198877566 Test RE 0.07845051490967858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 Train Loss 0.37523216 Test MSE 0.01649695273815339 Test RE 0.06139173756877867\n",
      "56 Train Loss 0.31241012 Test MSE 0.01470813275419165 Test RE 0.05796780167420133\n",
      "57 Train Loss 0.27325398 Test MSE 0.014920631182833686 Test RE 0.058385050200005235\n",
      "58 Train Loss 0.2523022 Test MSE 0.01401465152030163 Test RE 0.05658472530934698\n",
      "59 Train Loss 0.21315107 Test MSE 0.013341588036038552 Test RE 0.055209246949185165\n",
      "60 Train Loss 0.1862089 Test MSE 0.011166355020354297 Test RE 0.050508419175457356\n",
      "61 Train Loss 0.16336352 Test MSE 0.009572827007735336 Test RE 0.04676577821092319\n",
      "62 Train Loss 0.14786829 Test MSE 0.007937056522444745 Test RE 0.04258315122509217\n",
      "63 Train Loss 0.13091311 Test MSE 0.008345371616195875 Test RE 0.043664742209248035\n",
      "64 Train Loss 0.11576849 Test MSE 0.006961389071416245 Test RE 0.03988007935702231\n",
      "65 Train Loss 0.1068134 Test MSE 0.006122676280923004 Test RE 0.037400612041306534\n",
      "66 Train Loss 0.09326887 Test MSE 0.00568649613100636 Test RE 0.03604378863551459\n",
      "67 Train Loss 0.08098157 Test MSE 0.00530497932858386 Test RE 0.03481367801238091\n",
      "68 Train Loss 0.06958433 Test MSE 0.004157419028351321 Test RE 0.03081910056814121\n",
      "69 Train Loss 0.056450173 Test MSE 0.0033659606425544835 Test RE 0.02773081139324352\n",
      "70 Train Loss 0.0535514 Test MSE 0.0036871373338145585 Test RE 0.02902369604958145\n",
      "71 Train Loss 0.04851126 Test MSE 0.0035543643133862384 Test RE 0.028496336478276024\n",
      "72 Train Loss 0.044714715 Test MSE 0.0034247518845700133 Test RE 0.027971941863892586\n",
      "73 Train Loss 0.041097593 Test MSE 0.002769210055311117 Test RE 0.025152781041597752\n",
      "74 Train Loss 0.03968007 Test MSE 0.0024996307701307253 Test RE 0.023897143492843588\n",
      "75 Train Loss 0.03627073 Test MSE 0.002769427793121029 Test RE 0.025153769880236956\n",
      "76 Train Loss 0.03441293 Test MSE 0.0024810923388423134 Test RE 0.023808362377501748\n",
      "77 Train Loss 0.03362932 Test MSE 0.002295815334121235 Test RE 0.022902164851078592\n",
      "78 Train Loss 0.029692397 Test MSE 0.0019455676551265086 Test RE 0.021082942730886033\n",
      "79 Train Loss 0.027167404 Test MSE 0.001776657114906527 Test RE 0.020146976042377564\n",
      "80 Train Loss 0.026457427 Test MSE 0.0017001640949450862 Test RE 0.0197084958574774\n",
      "81 Train Loss 0.025624894 Test MSE 0.0017030240251690871 Test RE 0.019725065210841105\n",
      "82 Train Loss 0.023434168 Test MSE 0.001643914973724865 Test RE 0.01937973061541578\n",
      "83 Train Loss 0.022270624 Test MSE 0.0014270206448495232 Test RE 0.018056068278735765\n",
      "84 Train Loss 0.021544352 Test MSE 0.0013210453442033276 Test RE 0.017372684101853716\n",
      "85 Train Loss 0.021251563 Test MSE 0.0013340506655247946 Test RE 0.017457989268690233\n",
      "86 Train Loss 0.020758554 Test MSE 0.001266850604907369 Test RE 0.017012602775215855\n",
      "87 Train Loss 0.018453224 Test MSE 0.0010578597707562544 Test RE 0.015546123416543097\n",
      "88 Train Loss 0.016707389 Test MSE 0.001124839787596227 Test RE 0.016030733530032072\n",
      "89 Train Loss 0.015861906 Test MSE 0.0011562300657359172 Test RE 0.0162528747818726\n",
      "90 Train Loss 0.015449088 Test MSE 0.0011095098773761744 Test RE 0.01592112113685954\n",
      "91 Train Loss 0.015243044 Test MSE 0.0010752514946553726 Test RE 0.015673395322752717\n",
      "92 Train Loss 0.0150476545 Test MSE 0.0011306118802228528 Test RE 0.016071811592142243\n",
      "93 Train Loss 0.014488136 Test MSE 0.0011797168642126337 Test RE 0.016417119301073625\n",
      "94 Train Loss 0.013460264 Test MSE 0.0009797629215364347 Test RE 0.014961273433223801\n",
      "95 Train Loss 0.012840149 Test MSE 0.0009220201381100647 Test RE 0.014513704067682542\n",
      "96 Train Loss 0.012221737 Test MSE 0.0009840160712669204 Test RE 0.014993711703219772\n",
      "97 Train Loss 0.012031162 Test MSE 0.0009506064247353946 Test RE 0.01473697792132119\n",
      "98 Train Loss 0.011864258 Test MSE 0.0009521013174017442 Test RE 0.01474856081485915\n",
      "99 Train Loss 0.011385614 Test MSE 0.000925463606758942 Test RE 0.014540780975808713\n",
      "Training time: 80.96\n",
      "KG_stan_tune8\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.886272 Test MSE 8.228624151795652 Test RE 1.3711080268086282\n",
      "1 Train Loss 56.48783 Test MSE 8.637583413998165 Test RE 1.4047666474756872\n",
      "2 Train Loss 54.167778 Test MSE 8.885961669081583 Test RE 1.4248209035506403\n",
      "3 Train Loss 48.021973 Test MSE 8.946802310822664 Test RE 1.4296903338059253\n",
      "4 Train Loss 46.598484 Test MSE 8.75945551523619 Test RE 1.4146422217112464\n",
      "5 Train Loss 45.154373 Test MSE 8.532574297748356 Test RE 1.396201497845821\n",
      "6 Train Loss 44.696205 Test MSE 8.553400575693699 Test RE 1.3979043812836311\n",
      "7 Train Loss 44.52845 Test MSE 8.63511972317955 Test RE 1.4045662929697353\n",
      "8 Train Loss 43.90679 Test MSE 8.558644746215592 Test RE 1.398332849795954\n",
      "9 Train Loss 43.44404 Test MSE 8.454809744384304 Test RE 1.3898245534596012\n",
      "10 Train Loss 43.414337 Test MSE 8.456412413586579 Test RE 1.3899562727726011\n",
      "11 Train Loss 43.33367 Test MSE 8.51027831586388 Test RE 1.3943761374898826\n",
      "12 Train Loss 42.65325 Test MSE 8.471891169680857 Test RE 1.391227790575795\n",
      "13 Train Loss 42.434223 Test MSE 8.056855418655358 Test RE 1.3567219313254548\n",
      "14 Train Loss 41.93027 Test MSE 8.16094386472207 Test RE 1.3654577148421043\n",
      "15 Train Loss 41.28238 Test MSE 7.933122713776644 Test RE 1.3462637327142937\n",
      "16 Train Loss 40.578526 Test MSE 7.8983855080002145 Test RE 1.343313019105012\n",
      "17 Train Loss 40.30269 Test MSE 7.909872831256036 Test RE 1.3442895138741553\n",
      "18 Train Loss 40.098698 Test MSE 7.857398575738405 Test RE 1.3398230720897089\n",
      "19 Train Loss 40.05034 Test MSE 7.950378946015113 Test RE 1.3477271425752215\n",
      "20 Train Loss 40.00869 Test MSE 7.975522882154674 Test RE 1.3498566268904566\n",
      "21 Train Loss 39.89321 Test MSE 8.028310079996004 Test RE 1.3543163742459379\n",
      "22 Train Loss 39.826157 Test MSE 8.03777839160537 Test RE 1.3551147558961179\n",
      "23 Train Loss 39.72518 Test MSE 8.024118947820488 Test RE 1.3539628216386685\n",
      "24 Train Loss 39.704018 Test MSE 8.082990229313488 Test RE 1.3589206156205569\n",
      "25 Train Loss 39.541466 Test MSE 8.1530847379822 Test RE 1.364800077057271\n",
      "26 Train Loss 39.36332 Test MSE 7.931446243779606 Test RE 1.3461214753656536\n",
      "27 Train Loss 39.23873 Test MSE 7.917268347663085 Test RE 1.3449178041542258\n",
      "28 Train Loss 39.15555 Test MSE 7.929161652802434 Test RE 1.3459275915284037\n",
      "29 Train Loss 39.039734 Test MSE 7.960996913656035 Test RE 1.3486268071430882\n",
      "30 Train Loss 38.89109 Test MSE 8.014748578593048 Test RE 1.3531720284228643\n",
      "31 Train Loss 38.771465 Test MSE 8.044456834921235 Test RE 1.3556776090591243\n",
      "32 Train Loss 38.38777 Test MSE 8.1086301380386 Test RE 1.361074213014655\n",
      "33 Train Loss 35.744198 Test MSE 7.965438759946351 Test RE 1.3490029885241301\n",
      "34 Train Loss 34.840508 Test MSE 7.991348041556235 Test RE 1.3511951667298363\n",
      "35 Train Loss 33.986267 Test MSE 7.8501321390830014 Test RE 1.3392034018956374\n",
      "36 Train Loss 33.456657 Test MSE 7.91130002862897 Test RE 1.344410785098644\n",
      "37 Train Loss 32.98918 Test MSE 7.7144053141368945 Test RE 1.3275756763856665\n",
      "38 Train Loss 32.24941 Test MSE 7.86419975950995 Test RE 1.340402806707497\n",
      "39 Train Loss 31.272528 Test MSE 7.838321747545401 Test RE 1.3381956182275137\n",
      "40 Train Loss 30.265087 Test MSE 7.934246105160544 Test RE 1.34635905000579\n",
      "41 Train Loss 29.823242 Test MSE 7.814732670557136 Test RE 1.3361804811866107\n",
      "42 Train Loss 28.918932 Test MSE 7.751462166446048 Test RE 1.3307604220748104\n",
      "43 Train Loss 27.343252 Test MSE 7.914174051200445 Test RE 1.344654962166533\n",
      "44 Train Loss 26.9245 Test MSE 7.858834960031616 Test RE 1.3399455307414534\n",
      "45 Train Loss 26.290092 Test MSE 7.623978996268278 Test RE 1.3197719867483193\n",
      "46 Train Loss 25.701092 Test MSE 7.688001724182081 Test RE 1.3253018259070826\n",
      "47 Train Loss 25.156029 Test MSE 7.554483119356796 Test RE 1.3137430690637375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 Train Loss 24.67389 Test MSE 7.564230271372549 Test RE 1.3145903226334346\n",
      "49 Train Loss 24.421385 Test MSE 7.629607795283269 Test RE 1.3202590920123016\n",
      "50 Train Loss 23.553493 Test MSE 7.361524155761867 Test RE 1.2968565236444969\n",
      "51 Train Loss 23.10592 Test MSE 7.3112360246790065 Test RE 1.2924193820660375\n",
      "52 Train Loss 22.928654 Test MSE 7.405040854186897 Test RE 1.3006839754551154\n",
      "53 Train Loss 22.55824 Test MSE 7.4975645540090845 Test RE 1.3087845727906573\n",
      "54 Train Loss 22.398903 Test MSE 7.601173262860506 Test RE 1.3177965805813365\n",
      "55 Train Loss 22.311615 Test MSE 7.645635535715732 Test RE 1.3216451179387498\n",
      "56 Train Loss 22.21651 Test MSE 7.60623663961133 Test RE 1.3182354200550526\n",
      "57 Train Loss 21.984596 Test MSE 7.480757786911643 Test RE 1.3073168442941343\n",
      "58 Train Loss 21.81872 Test MSE 7.538031316200392 Test RE 1.3123117850137653\n",
      "59 Train Loss 21.581116 Test MSE 7.4744949226618305 Test RE 1.306769489164821\n",
      "60 Train Loss 21.30949 Test MSE 7.492260605374438 Test RE 1.3083215588201687\n",
      "61 Train Loss 21.158882 Test MSE 7.628328140949701 Test RE 1.3201483690131377\n",
      "62 Train Loss 21.019238 Test MSE 7.67461987357654 Test RE 1.324147903480325\n",
      "63 Train Loss 20.666176 Test MSE 7.507403682139924 Test RE 1.3096430567045128\n",
      "64 Train Loss 20.418022 Test MSE 7.580769554851845 Test RE 1.3160267219235204\n",
      "65 Train Loss 20.199957 Test MSE 7.620858110774343 Test RE 1.3195018339283862\n",
      "66 Train Loss 20.021309 Test MSE 7.506652674721139 Test RE 1.3095775496203093\n",
      "67 Train Loss 19.692003 Test MSE 7.305071574398353 Test RE 1.2918744170933192\n",
      "68 Train Loss 19.470453 Test MSE 7.233278345036746 Test RE 1.2855105614962516\n",
      "69 Train Loss 19.081722 Test MSE 7.036896988996416 Test RE 1.2679398663335375\n",
      "70 Train Loss 18.784708 Test MSE 7.072507248371437 Test RE 1.2711440264264464\n",
      "71 Train Loss 18.199543 Test MSE 6.901861157964093 Test RE 1.255715252814742\n",
      "72 Train Loss 17.589754 Test MSE 6.821803606541208 Test RE 1.2484112293040774\n",
      "73 Train Loss 17.049046 Test MSE 6.731046766001999 Test RE 1.2400790320313182\n",
      "74 Train Loss 16.507105 Test MSE 6.505921906761711 Test RE 1.2191649912638634\n",
      "75 Train Loss 15.773411 Test MSE 6.365586863211838 Test RE 1.2059443987033742\n",
      "76 Train Loss 14.594015 Test MSE 6.2848869040253454 Test RE 1.198275814483959\n",
      "77 Train Loss 13.891787 Test MSE 5.855447242855441 Test RE 1.156613072234906\n",
      "78 Train Loss 13.168989 Test MSE 5.413610964510809 Test RE 1.1121198227723692\n",
      "79 Train Loss 12.808237 Test MSE 5.261919805734006 Test RE 1.0964281387422128\n",
      "80 Train Loss 12.320176 Test MSE 5.025487538793221 Test RE 1.071512299472635\n",
      "81 Train Loss 11.60962 Test MSE 4.499342933558169 Test RE 1.0138707832345293\n",
      "82 Train Loss 11.18848 Test MSE 4.356632458930001 Test RE 0.9976622091270809\n",
      "83 Train Loss 10.638046 Test MSE 4.100317240290745 Test RE 0.9678694677779281\n",
      "84 Train Loss 10.168035 Test MSE 3.923373557016608 Test RE 0.9467556174204066\n",
      "85 Train Loss 9.693195 Test MSE 3.8317646233571674 Test RE 0.9356371815441341\n",
      "86 Train Loss 9.34873 Test MSE 3.9328352113299623 Test RE 0.9478965335241759\n",
      "87 Train Loss 9.199551 Test MSE 3.8808051407641693 Test RE 0.9416054829614146\n",
      "88 Train Loss 8.884205 Test MSE 3.90899411541303 Test RE 0.9450190616569087\n",
      "89 Train Loss 8.542106 Test MSE 3.903703199449653 Test RE 0.9443792922753935\n",
      "90 Train Loss 8.414857 Test MSE 3.8831818529671147 Test RE 0.9418937714252298\n",
      "91 Train Loss 8.279844 Test MSE 3.9229242587843394 Test RE 0.9467014054268074\n",
      "92 Train Loss 8.200609 Test MSE 3.932285495423658 Test RE 0.9478302846243777\n",
      "93 Train Loss 8.049885 Test MSE 3.8230633501554494 Test RE 0.934574242843126\n",
      "94 Train Loss 7.9944677 Test MSE 3.8157987136037077 Test RE 0.9336858753285598\n",
      "95 Train Loss 7.909767 Test MSE 3.8181623390150303 Test RE 0.9339750077198753\n",
      "96 Train Loss 7.8121433 Test MSE 3.7859898726566352 Test RE 0.9300317697332088\n",
      "97 Train Loss 7.7302365 Test MSE 3.7906493713653977 Test RE 0.9306038987494701\n",
      "98 Train Loss 7.6824784 Test MSE 3.7859504435014624 Test RE 0.9300269268171322\n",
      "99 Train Loss 7.619281 Test MSE 3.7544424408141333 Test RE 0.9261488367007046\n",
      "Training time: 80.45\n",
      "KG_stan_tune9\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 50.3859 Test MSE 9.586360163840885 Test RE 1.479908726530976\n",
      "1 Train Loss 44.25175 Test MSE 9.410127289982942 Test RE 1.4662425191850954\n",
      "2 Train Loss 43.378952 Test MSE 9.414500416705497 Test RE 1.4665831798029239\n",
      "3 Train Loss 43.206146 Test MSE 9.358025062328615 Test RE 1.4621777207671702\n",
      "4 Train Loss 43.108467 Test MSE 9.349945444368103 Test RE 1.4615463702214175\n",
      "5 Train Loss 42.81505 Test MSE 9.335884663938062 Test RE 1.460446994044635\n",
      "6 Train Loss 41.936333 Test MSE 9.261592587779852 Test RE 1.4546244952681577\n",
      "7 Train Loss 40.663143 Test MSE 9.248798544217763 Test RE 1.4536194326608456\n",
      "8 Train Loss 39.438957 Test MSE 9.175067417617038 Test RE 1.4478137349536682\n",
      "9 Train Loss 38.58496 Test MSE 9.194700027328274 Test RE 1.449361907380549\n",
      "10 Train Loss 36.931038 Test MSE 9.54132261244105 Test RE 1.4764282640706632\n",
      "11 Train Loss 36.08455 Test MSE 9.118466909102924 Test RE 1.4433410829882565\n",
      "12 Train Loss 35.300137 Test MSE 9.243608533300032 Test RE 1.453211522413502\n",
      "13 Train Loss 34.585674 Test MSE 9.55916631193427 Test RE 1.4778081899780071\n",
      "14 Train Loss 34.100452 Test MSE 9.481901693072635 Test RE 1.4718236748262548\n",
      "15 Train Loss 32.930096 Test MSE 9.20562487760881 Test RE 1.4502226946386052\n",
      "16 Train Loss 30.96262 Test MSE 9.219114624107691 Test RE 1.4512848699478553\n",
      "17 Train Loss 29.854317 Test MSE 9.161958749640746 Test RE 1.446779099868897\n",
      "18 Train Loss 28.810692 Test MSE 8.928684935690255 Test RE 1.428242030737743\n",
      "19 Train Loss 27.76969 Test MSE 9.295599355692191 Test RE 1.4572925975379705\n",
      "20 Train Loss 26.619324 Test MSE 9.28126770872976 Test RE 1.4561687614868133\n",
      "21 Train Loss 25.60993 Test MSE 9.270739788932547 Test RE 1.4553426470873398\n",
      "22 Train Loss 25.12328 Test MSE 9.154673184147324 Test RE 1.4462037479996415\n",
      "23 Train Loss 24.79489 Test MSE 9.21502816124172 Test RE 1.450963186178965\n",
      "24 Train Loss 24.529396 Test MSE 9.265524103580896 Test RE 1.4549332041835485\n",
      "25 Train Loss 24.034712 Test MSE 9.397364983890363 Test RE 1.4652479000779843\n",
      "26 Train Loss 23.810953 Test MSE 9.307809223068212 Test RE 1.458249368024724\n",
      "27 Train Loss 23.520208 Test MSE 9.29296432910177 Test RE 1.457086033293535\n",
      "28 Train Loss 23.279669 Test MSE 9.293393449841828 Test RE 1.4571196747989117\n",
      "29 Train Loss 22.915718 Test MSE 9.355350120451753 Test RE 1.4619687279544549\n",
      "30 Train Loss 22.410707 Test MSE 9.30512065304281 Test RE 1.4580387444179717\n",
      "31 Train Loss 21.607042 Test MSE 9.039336946542614 Test RE 1.4370647873344544\n",
      "32 Train Loss 20.474407 Test MSE 8.426303807665084 Test RE 1.3874796336886903\n",
      "33 Train Loss 19.057503 Test MSE 8.193590912890208 Test RE 1.3681861780471634\n",
      "34 Train Loss 16.696701 Test MSE 7.362244727311607 Test RE 1.2969199925015493\n",
      "35 Train Loss 13.490601 Test MSE 6.533244107559293 Test RE 1.2217223053579367\n",
      "36 Train Loss 11.441056 Test MSE 6.483753250904827 Test RE 1.2170860920413031\n",
      "37 Train Loss 10.655079 Test MSE 6.276840862208803 Test RE 1.197508540131397\n",
      "38 Train Loss 9.936361 Test MSE 6.071753478821672 Test RE 1.1777825768613743\n",
      "39 Train Loss 9.543521 Test MSE 6.165897768169145 Test RE 1.1868783835259233\n",
      "40 Train Loss 9.400626 Test MSE 6.246577146727193 Test RE 1.1946181651696015\n",
      "41 Train Loss 9.248957 Test MSE 6.2110038478775955 Test RE 1.191211724836834\n",
      "42 Train Loss 9.13624 Test MSE 6.247358385574349 Test RE 1.194692866315319\n",
      "43 Train Loss 9.046722 Test MSE 6.189444961712661 Test RE 1.189142532582827\n",
      "44 Train Loss 8.92617 Test MSE 6.175940421300962 Test RE 1.1878445492736753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 Train Loss 8.8338785 Test MSE 6.1641906027061175 Test RE 1.186714065357652\n",
      "46 Train Loss 8.693564 Test MSE 5.946859392842892 Test RE 1.1656063249144077\n",
      "47 Train Loss 7.8534145 Test MSE 5.229365544295846 Test RE 1.0930312049502027\n",
      "48 Train Loss 6.8525915 Test MSE 5.053969382962589 Test RE 1.0745443960861203\n",
      "49 Train Loss 5.9830723 Test MSE 4.838265748239377 Test RE 1.0513635583527043\n",
      "50 Train Loss 5.648261 Test MSE 4.899883665644987 Test RE 1.0580372177034798\n",
      "51 Train Loss 5.452341 Test MSE 4.852173154266153 Test RE 1.0528735257994533\n",
      "52 Train Loss 5.2794294 Test MSE 4.74357198387716 Test RE 1.0410241582825965\n",
      "53 Train Loss 5.173273 Test MSE 4.7599038077444416 Test RE 1.042814709193907\n",
      "54 Train Loss 4.9984837 Test MSE 4.727378472032938 Test RE 1.039245725390474\n",
      "55 Train Loss 4.5115337 Test MSE 4.677083732475362 Test RE 1.0337026575230563\n",
      "56 Train Loss 3.6347113 Test MSE 4.644076058806977 Test RE 1.0300486142714618\n",
      "57 Train Loss 2.6808417 Test MSE 4.00289304453952 Test RE 0.9563019763934264\n",
      "58 Train Loss 2.0360048 Test MSE 3.639256760156697 Test RE 0.911831117423478\n",
      "59 Train Loss 1.7068474 Test MSE 3.3821152826492415 Test RE 0.8790270986447165\n",
      "60 Train Loss 1.4781698 Test MSE 3.0191667989303372 Test RE 0.830522903893287\n",
      "61 Train Loss 1.2989553 Test MSE 2.7933442525453267 Test RE 0.7988592919550151\n",
      "62 Train Loss 1.1486216 Test MSE 2.7475804309762806 Test RE 0.7922883455356887\n",
      "63 Train Loss 1.0546192 Test MSE 2.7025537433055065 Test RE 0.7857696128747845\n",
      "64 Train Loss 0.9874475 Test MSE 2.6103012871673448 Test RE 0.7722419308280701\n",
      "65 Train Loss 0.94506073 Test MSE 2.6360812174341834 Test RE 0.7760459801220074\n",
      "66 Train Loss 0.8950902 Test MSE 2.615098910184735 Test RE 0.772951278992044\n",
      "67 Train Loss 0.8703136 Test MSE 2.6116632150049135 Test RE 0.7724433636353704\n",
      "68 Train Loss 0.84632176 Test MSE 2.62551937546131 Test RE 0.7744897493177549\n",
      "69 Train Loss 0.823775 Test MSE 2.62031464035034 Test RE 0.773721708193037\n",
      "70 Train Loss 0.8123765 Test MSE 2.6280113243577223 Test RE 0.774857206355139\n",
      "71 Train Loss 0.79970807 Test MSE 2.631276481804085 Test RE 0.775338415356418\n",
      "72 Train Loss 0.7902777 Test MSE 2.6209047611634055 Test RE 0.7738088281847126\n",
      "73 Train Loss 0.78043365 Test MSE 2.6040193329105024 Test RE 0.771312131891649\n",
      "74 Train Loss 0.76747066 Test MSE 2.5782670629289406 Test RE 0.7674887364802844\n",
      "75 Train Loss 0.75850886 Test MSE 2.6066207576683076 Test RE 0.7716973075262713\n",
      "76 Train Loss 0.7496073 Test MSE 2.6200208539218557 Test RE 0.7736783326179156\n",
      "77 Train Loss 0.74007374 Test MSE 2.6157187588040944 Test RE 0.7730428786623216\n",
      "78 Train Loss 0.7330567 Test MSE 2.633026682954862 Test RE 0.7755962317847526\n",
      "79 Train Loss 0.7290053 Test MSE 2.624932640062509 Test RE 0.7744032053092027\n",
      "80 Train Loss 0.7226862 Test MSE 2.6182983781483817 Test RE 0.7734239718017427\n",
      "81 Train Loss 0.71563816 Test MSE 2.6287316232355136 Test RE 0.7749633875067479\n",
      "82 Train Loss 0.70936453 Test MSE 2.6256925092112007 Test RE 0.7745152848566105\n",
      "83 Train Loss 0.70405954 Test MSE 2.614518383752497 Test RE 0.7728654804105651\n",
      "84 Train Loss 0.700349 Test MSE 2.605037127104501 Test RE 0.7714628527994665\n",
      "85 Train Loss 0.6955407 Test MSE 2.60366346052833 Test RE 0.7712594252813255\n",
      "86 Train Loss 0.69051737 Test MSE 2.6140396686452925 Test RE 0.7727947218110102\n",
      "87 Train Loss 0.6865531 Test MSE 2.6157695601282365 Test RE 0.7730503854730301\n",
      "88 Train Loss 0.6823764 Test MSE 2.619315182623611 Test RE 0.7735741350960406\n",
      "89 Train Loss 0.67944354 Test MSE 2.6258611525149997 Test RE 0.7745401572890779\n",
      "90 Train Loss 0.6769531 Test MSE 2.6224777129165333 Test RE 0.774040996366408\n",
      "91 Train Loss 0.6732586 Test MSE 2.62379645778435 Test RE 0.7742355898786695\n",
      "92 Train Loss 0.6681614 Test MSE 2.640584564665105 Test RE 0.7767085760199436\n",
      "93 Train Loss 0.664037 Test MSE 2.6475878063745593 Test RE 0.777737870093192\n",
      "94 Train Loss 0.65870446 Test MSE 2.6514402211530337 Test RE 0.7783034943462834\n",
      "95 Train Loss 0.6542376 Test MSE 2.6619757858696587 Test RE 0.7798482656213954\n",
      "96 Train Loss 0.6499601 Test MSE 2.6696268360647064 Test RE 0.7809681813367837\n",
      "97 Train Loss 0.64720047 Test MSE 2.6765379557153333 Test RE 0.7819784116462799\n",
      "98 Train Loss 0.6445714 Test MSE 2.6730587798026693 Test RE 0.7814700076557319\n",
      "99 Train Loss 0.64228135 Test MSE 2.6719428232603457 Test RE 0.7813068654132957\n",
      "Training time: 80.41\n",
      "KG_stan_tune9\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.820145 Test MSE 8.584965733319871 Test RE 1.4004813936254166\n",
      "1 Train Loss 57.23097 Test MSE 8.620884450383384 Test RE 1.4034080790637478\n",
      "2 Train Loss 55.104527 Test MSE 9.01073320460711 Test RE 1.4347892885760605\n",
      "3 Train Loss 53.712273 Test MSE 9.016109515921979 Test RE 1.4352172628275242\n",
      "4 Train Loss 48.595688 Test MSE 9.465957531166996 Test RE 1.4705856917094744\n",
      "5 Train Loss 47.28496 Test MSE 8.762399875733792 Test RE 1.414879957190839\n",
      "6 Train Loss 47.004562 Test MSE 8.70011239423658 Test RE 1.40984215440568\n",
      "7 Train Loss 45.793472 Test MSE 8.675681422016998 Test RE 1.4078612587826866\n",
      "8 Train Loss 44.660088 Test MSE 8.5879969521289 Test RE 1.4007286159798475\n",
      "9 Train Loss 44.289436 Test MSE 8.42964442447695 Test RE 1.3877546402986982\n",
      "10 Train Loss 44.165764 Test MSE 8.357612056635862 Test RE 1.3818126506598083\n",
      "11 Train Loss 43.94297 Test MSE 8.416993580552509 Test RE 1.3867129083854937\n",
      "12 Train Loss 43.83212 Test MSE 8.39908453653319 Test RE 1.385236851245554\n",
      "13 Train Loss 43.624405 Test MSE 8.378187374606046 Test RE 1.3835125236322805\n",
      "14 Train Loss 43.42727 Test MSE 8.409795283260033 Test RE 1.3861198161630766\n",
      "15 Train Loss 43.24447 Test MSE 8.46873601677347 Test RE 1.3909687017200192\n",
      "16 Train Loss 42.844437 Test MSE 8.61688779372582 Test RE 1.403082730168049\n",
      "17 Train Loss 42.512276 Test MSE 8.64079749493899 Test RE 1.405027982941521\n",
      "18 Train Loss 42.117752 Test MSE 8.670896379030113 Test RE 1.4074729546559435\n",
      "19 Train Loss 41.901443 Test MSE 8.680683659329357 Test RE 1.408267073665223\n",
      "20 Train Loss 41.390823 Test MSE 8.744117781754621 Test RE 1.4134031657191748\n",
      "21 Train Loss 40.828636 Test MSE 8.82751696379287 Test RE 1.4201275108068454\n",
      "22 Train Loss 40.2383 Test MSE 8.697193370215771 Test RE 1.4096056224979363\n",
      "23 Train Loss 39.034218 Test MSE 8.78043474570588 Test RE 1.4163352696609264\n",
      "24 Train Loss 36.718254 Test MSE 8.11804579648774 Test RE 1.3618642164784478\n",
      "25 Train Loss 34.456264 Test MSE 7.189431838721376 Test RE 1.2816084010685074\n",
      "26 Train Loss 32.324974 Test MSE 7.360729335060416 Test RE 1.2967865112248944\n",
      "27 Train Loss 29.991837 Test MSE 6.947833871728474 Test RE 1.2598904183250832\n",
      "28 Train Loss 26.584145 Test MSE 6.9211952823134775 Test RE 1.2574728349738418\n",
      "29 Train Loss 23.920177 Test MSE 6.854000856260342 Test RE 1.2513538595732692\n",
      "30 Train Loss 22.561174 Test MSE 6.756542071872387 Test RE 1.2424253470683808\n",
      "31 Train Loss 21.18547 Test MSE 6.60767023146419 Test RE 1.2286614735380224\n",
      "32 Train Loss 20.183456 Test MSE 6.5890474440293625 Test RE 1.2269288472720608\n",
      "33 Train Loss 18.691324 Test MSE 6.1979482293881745 Test RE 1.1899590942286509\n",
      "34 Train Loss 17.11569 Test MSE 6.055699046498758 Test RE 1.1762244481880244\n",
      "35 Train Loss 15.812444 Test MSE 5.986715643803211 Test RE 1.1695057881368245\n",
      "36 Train Loss 14.608379 Test MSE 5.707302031240837 Test RE 1.1418879455844697\n",
      "37 Train Loss 12.48051 Test MSE 5.286525649642816 Test RE 1.0989887130981322\n",
      "38 Train Loss 10.833912 Test MSE 4.622780414599472 Test RE 1.0276842308085672\n",
      "39 Train Loss 9.339242 Test MSE 3.924656450685204 Test RE 0.9469103933418473\n",
      "40 Train Loss 8.417624 Test MSE 3.7310916417404267 Test RE 0.9232642477106812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 Train Loss 7.321745 Test MSE 3.6936799106842724 Test RE 0.9186237913106449\n",
      "42 Train Loss 6.7848177 Test MSE 3.8781939785638997 Test RE 0.9412886545881495\n",
      "43 Train Loss 6.2303414 Test MSE 3.614224267631374 Test RE 0.9086897078389604\n",
      "44 Train Loss 5.659212 Test MSE 3.5475707361282214 Test RE 0.900271687195358\n",
      "45 Train Loss 5.2715435 Test MSE 3.577529662801232 Test RE 0.9040650534641406\n",
      "46 Train Loss 4.7875967 Test MSE 3.541735911947781 Test RE 0.8995310270224598\n",
      "47 Train Loss 4.4855847 Test MSE 3.4909200726679206 Test RE 0.8930546024352921\n",
      "48 Train Loss 4.261375 Test MSE 3.493431498514187 Test RE 0.8933757838322998\n",
      "49 Train Loss 3.9017277 Test MSE 3.6491958443541352 Test RE 0.9130754081547725\n",
      "50 Train Loss 3.6267931 Test MSE 3.6481419337590073 Test RE 0.912943547687776\n",
      "51 Train Loss 3.3912008 Test MSE 3.4949101814446055 Test RE 0.8935648357377742\n",
      "52 Train Loss 3.1491678 Test MSE 3.360536800592012 Test RE 0.8762184388733409\n",
      "53 Train Loss 2.87209 Test MSE 3.0229032376333484 Test RE 0.8310366612663895\n",
      "54 Train Loss 2.64306 Test MSE 2.817745577664227 Test RE 0.8023409321675914\n",
      "55 Train Loss 2.442357 Test MSE 3.003321932199791 Test RE 0.8283407065086847\n",
      "56 Train Loss 2.2644298 Test MSE 2.9894222659251364 Test RE 0.8264216628392457\n",
      "57 Train Loss 2.1179116 Test MSE 2.858658456251889 Test RE 0.8081448234633231\n",
      "58 Train Loss 2.0322604 Test MSE 2.613887705939956 Test RE 0.7727722589377821\n",
      "59 Train Loss 1.9417417 Test MSE 2.4883359928756494 Test RE 0.7539847657375932\n",
      "60 Train Loss 1.8827583 Test MSE 2.4967391578280282 Test RE 0.7552568042215801\n",
      "61 Train Loss 1.8030001 Test MSE 2.440005006478259 Test RE 0.7466265321992064\n",
      "62 Train Loss 1.7211888 Test MSE 2.4325211811470715 Test RE 0.7454806506085008\n",
      "63 Train Loss 1.6667875 Test MSE 2.421081620744595 Test RE 0.7437256770258823\n",
      "64 Train Loss 1.6145321 Test MSE 2.460447949550881 Test RE 0.7497477157847086\n",
      "65 Train Loss 1.5677795 Test MSE 2.4661379277771056 Test RE 0.7506141402571355\n",
      "66 Train Loss 1.540287 Test MSE 2.4316018077834243 Test RE 0.7453397597849486\n",
      "67 Train Loss 1.5119176 Test MSE 2.4065913910479937 Test RE 0.7414967292247661\n",
      "68 Train Loss 1.4772798 Test MSE 2.4141802831798853 Test RE 0.7426649187171889\n",
      "69 Train Loss 1.4537195 Test MSE 2.4391705223148192 Test RE 0.7464988477691861\n",
      "70 Train Loss 1.4335258 Test MSE 2.4499906734253556 Test RE 0.7481527486414875\n",
      "71 Train Loss 1.4201232 Test MSE 2.4338104976375114 Test RE 0.7456781891079862\n",
      "72 Train Loss 1.4035863 Test MSE 2.439339229432438 Test RE 0.7465246634081822\n",
      "73 Train Loss 1.380524 Test MSE 2.466424813010957 Test RE 0.7506577983689717\n",
      "74 Train Loss 1.3561826 Test MSE 2.479826423626591 Test RE 0.7526944294647021\n",
      "75 Train Loss 1.3408393 Test MSE 2.514415933634972 Test RE 0.7579256769859982\n",
      "76 Train Loss 1.3220719 Test MSE 2.5328592903182323 Test RE 0.7607003081450783\n",
      "77 Train Loss 1.3119495 Test MSE 2.5205500921369373 Test RE 0.7588496299530595\n",
      "78 Train Loss 1.2910249 Test MSE 2.503668578908306 Test RE 0.7563041435462539\n",
      "79 Train Loss 1.2717524 Test MSE 2.5389916297542308 Test RE 0.7616206222705145\n",
      "80 Train Loss 1.2408276 Test MSE 2.565672201952647 Test RE 0.7656118463529638\n",
      "81 Train Loss 1.219239 Test MSE 2.569063941122715 Test RE 0.7661177367869633\n",
      "82 Train Loss 1.1987573 Test MSE 2.587188861335409 Test RE 0.7688154932130693\n",
      "83 Train Loss 1.1710303 Test MSE 2.5951986869396393 Test RE 0.7700046833785066\n",
      "84 Train Loss 1.1553347 Test MSE 2.6100712160908213 Test RE 0.7722078975062535\n",
      "85 Train Loss 1.1409644 Test MSE 2.5980635977131197 Test RE 0.7704295807564002\n",
      "86 Train Loss 1.1260698 Test MSE 2.5823182094406247 Test RE 0.7680914647568003\n",
      "87 Train Loss 1.1090204 Test MSE 2.6030835837070225 Test RE 0.771173534693874\n",
      "88 Train Loss 1.0931644 Test MSE 2.620607795069584 Test RE 0.7737649880768667\n",
      "89 Train Loss 1.0759094 Test MSE 2.6467210340043383 Test RE 0.777610551014615\n",
      "90 Train Loss 1.0619072 Test MSE 2.6931721398330457 Test RE 0.7844045729296364\n",
      "91 Train Loss 1.0503936 Test MSE 2.6853975072248963 Test RE 0.7832715475110483\n",
      "92 Train Loss 1.0389916 Test MSE 2.6724048863535885 Test RE 0.7813744187788804\n",
      "93 Train Loss 1.022951 Test MSE 2.6935068728221983 Test RE 0.7844533180368418\n",
      "94 Train Loss 1.0174339 Test MSE 2.6957217699677027 Test RE 0.7847757835912822\n",
      "95 Train Loss 1.0133427 Test MSE 2.702626628707101 Test RE 0.7857802085470824\n",
      "96 Train Loss 0.9998587 Test MSE 2.715313755212908 Test RE 0.7876224201760499\n",
      "97 Train Loss 0.98546165 Test MSE 2.717536315329868 Test RE 0.7879446997110363\n",
      "98 Train Loss 0.9702674 Test MSE 2.7261050149315103 Test RE 0.7891859614344809\n",
      "99 Train Loss 0.96160686 Test MSE 2.7396889090921794 Test RE 0.7911497334192649\n",
      "Training time: 80.46\n",
      "KG_stan_tune9\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.897114 Test MSE 8.381068907209347 Test RE 1.3837504207776272\n",
      "1 Train Loss 52.158493 Test MSE 7.5945560726282455 Test RE 1.3172228527497294\n",
      "2 Train Loss 44.176495 Test MSE 7.871148706219756 Test RE 1.340994877819446\n",
      "3 Train Loss 43.286674 Test MSE 8.099384052550683 Test RE 1.360297990776941\n",
      "4 Train Loss 43.00184 Test MSE 8.045660874504941 Test RE 1.35577905956502\n",
      "5 Train Loss 42.55448 Test MSE 7.8782144483438215 Test RE 1.3415966323349369\n",
      "6 Train Loss 41.7181 Test MSE 7.606273169709967 Test RE 1.3182385855634626\n",
      "7 Train Loss 36.805218 Test MSE 7.615168201534739 Test RE 1.3190091566292113\n",
      "8 Train Loss 33.38427 Test MSE 7.007451973102456 Test RE 1.265284317524318\n",
      "9 Train Loss 32.40841 Test MSE 6.615846056054431 Test RE 1.2294213643111789\n",
      "10 Train Loss 30.896078 Test MSE 6.663450262829968 Test RE 1.233836576317468\n",
      "11 Train Loss 28.74773 Test MSE 6.101216781735164 Test RE 1.1806367251330314\n",
      "12 Train Loss 27.86182 Test MSE 6.263937081483864 Test RE 1.1962770020221618\n",
      "13 Train Loss 27.52861 Test MSE 5.970309010389411 Test RE 1.1679021695669864\n",
      "14 Train Loss 26.621077 Test MSE 6.215425535094322 Test RE 1.1916356682668525\n",
      "15 Train Loss 25.306206 Test MSE 6.283273693956463 Test RE 1.1981220173910103\n",
      "16 Train Loss 24.50217 Test MSE 5.8699656108558615 Test RE 1.1580460744919365\n",
      "17 Train Loss 23.806873 Test MSE 5.715850604444352 Test RE 1.1427428031074096\n",
      "18 Train Loss 23.518875 Test MSE 5.580500113493699 Test RE 1.1291317537727594\n",
      "19 Train Loss 23.356956 Test MSE 5.489011815302358 Test RE 1.1198378518808934\n",
      "20 Train Loss 23.194782 Test MSE 5.348676329935986 Test RE 1.1054299301208834\n",
      "21 Train Loss 23.111929 Test MSE 5.326302645546026 Test RE 1.103115482832063\n",
      "22 Train Loss 23.02399 Test MSE 5.509169379337223 Test RE 1.121892184952667\n",
      "23 Train Loss 22.957344 Test MSE 5.458720036087725 Test RE 1.1167435962845333\n",
      "24 Train Loss 22.782372 Test MSE 5.530277324648053 Test RE 1.1240393506859918\n",
      "25 Train Loss 22.612507 Test MSE 5.580325312763263 Test RE 1.1291140694615924\n",
      "26 Train Loss 22.134651 Test MSE 5.501180864865624 Test RE 1.1210784957555535\n",
      "27 Train Loss 21.067102 Test MSE 5.3968397590337025 Test RE 1.1103958294782317\n",
      "28 Train Loss 20.030254 Test MSE 5.449428333387306 Test RE 1.1157927443614835\n",
      "29 Train Loss 19.490097 Test MSE 5.407179310157753 Test RE 1.1114589980404248\n",
      "30 Train Loss 18.983608 Test MSE 5.462917192166888 Test RE 1.1171728403668377\n",
      "31 Train Loss 18.272018 Test MSE 5.8150482734641225 Test RE 1.152616208418347\n",
      "32 Train Loss 17.822876 Test MSE 6.084194133331953 Test RE 1.1789885619524\n",
      "33 Train Loss 17.042326 Test MSE 6.196432371873881 Test RE 1.189813568752105\n",
      "34 Train Loss 16.468391 Test MSE 6.019367823494723 Test RE 1.1726907553259318\n",
      "35 Train Loss 15.5188465 Test MSE 6.218580084245816 Test RE 1.1919380286137193\n",
      "36 Train Loss 15.002102 Test MSE 6.114837904285287 Test RE 1.181953891237429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Train Loss 14.481726 Test MSE 5.934009817448427 Test RE 1.1643463619041299\n",
      "38 Train Loss 14.058939 Test MSE 6.095616272890508 Test RE 1.1800947279596428\n",
      "39 Train Loss 13.695701 Test MSE 6.02844579818451 Test RE 1.1735747058153652\n",
      "40 Train Loss 13.450113 Test MSE 6.040350277486086 Test RE 1.174732873771783\n",
      "41 Train Loss 13.183443 Test MSE 6.0905131985392424 Test RE 1.179600653875825\n",
      "42 Train Loss 12.901009 Test MSE 6.047717484659759 Test RE 1.1754490460768967\n",
      "43 Train Loss 12.6082535 Test MSE 6.087360635291253 Test RE 1.1792953227076888\n",
      "44 Train Loss 12.399891 Test MSE 6.076189186529507 Test RE 1.1782127117038463\n",
      "45 Train Loss 12.239225 Test MSE 6.042936804364535 Test RE 1.1749843619146745\n",
      "46 Train Loss 12.047835 Test MSE 6.006745553186869 Test RE 1.1714605773380269\n",
      "47 Train Loss 11.914167 Test MSE 5.984412106812046 Test RE 1.169280768342976\n",
      "48 Train Loss 11.738323 Test MSE 5.909197923380294 Test RE 1.1619095694260695\n",
      "49 Train Loss 11.4610815 Test MSE 5.94303506306909 Test RE 1.1652314732850195\n",
      "50 Train Loss 11.360414 Test MSE 5.931742278993598 Test RE 1.1641238772350813\n",
      "51 Train Loss 11.289003 Test MSE 5.940358441176767 Test RE 1.1649690454777226\n",
      "52 Train Loss 11.141791 Test MSE 5.868608793335675 Test RE 1.1579122280509975\n",
      "53 Train Loss 11.073579 Test MSE 5.880476552654512 Test RE 1.1590824273097933\n",
      "54 Train Loss 10.977787 Test MSE 5.873861854697912 Test RE 1.1584303426213125\n",
      "55 Train Loss 10.890723 Test MSE 5.8114733669962035 Test RE 1.1522618580822248\n",
      "56 Train Loss 10.781909 Test MSE 5.797699345275667 Test RE 1.1508955354374073\n",
      "57 Train Loss 10.646311 Test MSE 5.824462340219074 Test RE 1.153548824738791\n",
      "58 Train Loss 10.55715 Test MSE 5.80151381816424 Test RE 1.1512740767955338\n",
      "59 Train Loss 10.382863 Test MSE 5.685900875611366 Test RE 1.1397450176647186\n",
      "60 Train Loss 10.141914 Test MSE 5.653045558399296 Test RE 1.1364473048569452\n",
      "61 Train Loss 9.844904 Test MSE 5.62032457658055 Test RE 1.1331535371810713\n",
      "62 Train Loss 9.408862 Test MSE 5.242820395353504 Test RE 1.0944364542393077\n",
      "63 Train Loss 8.747358 Test MSE 4.938877190377736 Test RE 1.0622388322394134\n",
      "64 Train Loss 8.511261 Test MSE 4.969576150173131 Test RE 1.0655350379643118\n",
      "65 Train Loss 8.3688965 Test MSE 4.976334618150197 Test RE 1.0662593389372834\n",
      "66 Train Loss 8.2157 Test MSE 4.8656978011947984 Test RE 1.0543398619446511\n",
      "67 Train Loss 8.098248 Test MSE 4.774730909221472 Test RE 1.044437630358456\n",
      "68 Train Loss 7.9060316 Test MSE 4.628358760804212 Test RE 1.0283041012663716\n",
      "69 Train Loss 7.8201694 Test MSE 4.589507200916332 Test RE 1.023979089504408\n",
      "70 Train Loss 7.7281346 Test MSE 4.45823276815708 Test RE 1.009228323064154\n",
      "71 Train Loss 7.571445 Test MSE 4.357422109748226 Test RE 0.9977526194488721\n",
      "72 Train Loss 7.371759 Test MSE 4.355400857533305 Test RE 0.9975211817357784\n",
      "73 Train Loss 6.8313723 Test MSE 3.927810475535076 Test RE 0.9472908061440234\n",
      "74 Train Loss 6.401737 Test MSE 3.4232602784869113 Test RE 0.8843578204799165\n",
      "75 Train Loss 6.136655 Test MSE 3.263206351376629 Test RE 0.8634363518209028\n",
      "76 Train Loss 5.8227463 Test MSE 2.92032090613497 Test RE 0.8168143313711936\n",
      "77 Train Loss 5.5215263 Test MSE 2.4916083417516615 Test RE 0.7544803761714449\n",
      "78 Train Loss 5.2331266 Test MSE 2.3275893446821945 Test RE 0.7292244817201229\n",
      "79 Train Loss 5.06322 Test MSE 2.2453627276016834 Test RE 0.7162280324824879\n",
      "80 Train Loss 4.892765 Test MSE 2.2163028202604016 Test RE 0.7115781595536512\n",
      "81 Train Loss 4.781889 Test MSE 2.222440525990525 Test RE 0.7125627808199201\n",
      "82 Train Loss 4.6893244 Test MSE 2.1888651452125245 Test RE 0.7071597981075578\n",
      "83 Train Loss 4.569826 Test MSE 2.183467034040092 Test RE 0.7062872720715813\n",
      "84 Train Loss 4.531941 Test MSE 2.153775299343572 Test RE 0.7014686337077154\n",
      "85 Train Loss 4.4908166 Test MSE 2.1609112655131293 Test RE 0.7026297383653689\n",
      "86 Train Loss 4.4654055 Test MSE 2.1447141296863266 Test RE 0.6999915005936647\n",
      "87 Train Loss 4.439374 Test MSE 2.1434103773079443 Test RE 0.699778708989884\n",
      "88 Train Loss 4.4133086 Test MSE 2.1576954091345395 Test RE 0.7021067188288985\n",
      "89 Train Loss 4.373926 Test MSE 2.1274400473311426 Test RE 0.6971668451652748\n",
      "90 Train Loss 4.3463883 Test MSE 2.1217313515969702 Test RE 0.6962308406754891\n",
      "91 Train Loss 4.3239694 Test MSE 2.111683464308644 Test RE 0.6945803133820107\n",
      "92 Train Loss 4.279944 Test MSE 2.1249757371386195 Test RE 0.6967629481970634\n",
      "93 Train Loss 4.2497225 Test MSE 2.136038464214193 Test RE 0.6985742846851358\n",
      "94 Train Loss 4.2309785 Test MSE 2.1447546453350053 Test RE 0.6999981123083413\n",
      "95 Train Loss 4.198868 Test MSE 2.150256701122091 Test RE 0.7008954088281325\n",
      "96 Train Loss 4.170771 Test MSE 2.138042666050934 Test RE 0.6989019369311705\n",
      "97 Train Loss 4.153151 Test MSE 2.1468748287356783 Test RE 0.7003440161585144\n",
      "98 Train Loss 4.1374426 Test MSE 2.1492944778257383 Test RE 0.7007385686340252\n",
      "99 Train Loss 4.1173286 Test MSE 2.1572860076033993 Test RE 0.7020401067388213\n",
      "Training time: 81.12\n",
      "KG_stan_tune9\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.4912 Test MSE 8.55372523426449 Test RE 1.3979309109269014\n",
      "1 Train Loss 54.493202 Test MSE 7.910364136013824 Test RE 1.3443312620534704\n",
      "2 Train Loss 46.229744 Test MSE 8.719093195765893 Test RE 1.4113792238968883\n",
      "3 Train Loss 44.54931 Test MSE 8.77081637613754 Test RE 1.4155593075805466\n",
      "4 Train Loss 43.808517 Test MSE 8.648286482279412 Test RE 1.4056367206108549\n",
      "5 Train Loss 43.234165 Test MSE 8.50610595934429 Test RE 1.3940342833572585\n",
      "6 Train Loss 42.85843 Test MSE 8.374980038175822 Test RE 1.3832476802549567\n",
      "7 Train Loss 42.20554 Test MSE 8.307850392008014 Test RE 1.377692816239449\n",
      "8 Train Loss 41.659615 Test MSE 8.500517192164429 Test RE 1.3935762469051192\n",
      "9 Train Loss 41.25073 Test MSE 8.6257344122575 Test RE 1.403802790226158\n",
      "10 Train Loss 40.953217 Test MSE 8.815030852468325 Test RE 1.419122803314799\n",
      "11 Train Loss 40.41655 Test MSE 8.897745234266093 Test RE 1.4257653093576894\n",
      "12 Train Loss 39.83448 Test MSE 9.007768475906005 Test RE 1.434553230597203\n",
      "13 Train Loss 39.1287 Test MSE 9.103889182388091 Test RE 1.442186884139004\n",
      "14 Train Loss 38.638924 Test MSE 8.982516228992617 Test RE 1.4325410165410508\n",
      "15 Train Loss 36.867317 Test MSE 8.694738225873975 Test RE 1.4094066485650245\n",
      "16 Train Loss 35.040905 Test MSE 8.409666065528851 Test RE 1.3861091671555927\n",
      "17 Train Loss 34.046185 Test MSE 8.548500015312017 Test RE 1.397503868278461\n",
      "18 Train Loss 31.749397 Test MSE 8.048701200866203 Test RE 1.3560351989637736\n",
      "19 Train Loss 28.940697 Test MSE 7.354944404546379 Test RE 1.2962768270583576\n",
      "20 Train Loss 27.713024 Test MSE 7.288235773323103 Test RE 1.2903848843454173\n",
      "21 Train Loss 26.783634 Test MSE 7.021963819965818 Test RE 1.266593788913841\n",
      "22 Train Loss 25.891417 Test MSE 7.197940128237709 Test RE 1.2823665326788647\n",
      "23 Train Loss 23.6155 Test MSE 6.488878850751104 Test RE 1.2175670683865072\n",
      "24 Train Loss 20.889212 Test MSE 6.256512359899398 Test RE 1.1955678108923409\n",
      "25 Train Loss 18.836878 Test MSE 6.738276890841167 Test RE 1.2407448660492744\n",
      "26 Train Loss 17.89804 Test MSE 6.665346850687608 Test RE 1.2340121545006\n",
      "27 Train Loss 17.3198 Test MSE 6.272166998576438 Test RE 1.1970626124717145\n",
      "28 Train Loss 16.713213 Test MSE 6.421880534086146 Test RE 1.2112650085573888\n",
      "29 Train Loss 16.274435 Test MSE 6.321056244149712 Test RE 1.2017188890070292\n",
      "30 Train Loss 15.726745 Test MSE 6.052870325062448 Test RE 1.175949698739185\n",
      "31 Train Loss 15.281435 Test MSE 6.161915082395426 Test RE 1.1864950064907038\n",
      "32 Train Loss 14.615896 Test MSE 6.32865880812458 Test RE 1.2024413473223954\n",
      "33 Train Loss 14.014456 Test MSE 6.233439699895941 Test RE 1.1933612773770126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 13.536148 Test MSE 6.0520920692881095 Test RE 1.175874096668263\n",
      "35 Train Loss 12.660892 Test MSE 5.878043928697209 Test RE 1.1588426590427918\n",
      "36 Train Loss 11.747122 Test MSE 5.582917553702494 Test RE 1.1293762939482337\n",
      "37 Train Loss 9.866881 Test MSE 4.555928284678765 Test RE 1.0202262648402192\n",
      "38 Train Loss 8.246862 Test MSE 4.598730595691917 Test RE 1.0250075030812287\n",
      "39 Train Loss 6.81867 Test MSE 4.457888187020195 Test RE 1.0091893201922788\n",
      "40 Train Loss 5.4882574 Test MSE 4.166173726297884 Test RE 0.9756111343745645\n",
      "41 Train Loss 4.4731555 Test MSE 3.879467316797415 Test RE 0.9414431698692636\n",
      "42 Train Loss 3.8253803 Test MSE 3.8601227411803114 Test RE 0.9390930304387332\n",
      "43 Train Loss 3.3316011 Test MSE 3.516046799709103 Test RE 0.8962628261913491\n",
      "44 Train Loss 2.9301863 Test MSE 3.5182576471085594 Test RE 0.8965445614843418\n",
      "45 Train Loss 2.591824 Test MSE 3.6250813831657696 Test RE 0.9100535345349099\n",
      "46 Train Loss 2.3763802 Test MSE 3.42510157923535 Test RE 0.8845956273769549\n",
      "47 Train Loss 2.1585443 Test MSE 3.3992786377395934 Test RE 0.881254693014469\n",
      "48 Train Loss 1.9518579 Test MSE 3.136916337002091 Test RE 0.8465634777137935\n",
      "49 Train Loss 1.7483082 Test MSE 2.9153734513183203 Test RE 0.8161221360343781\n",
      "50 Train Loss 1.543768 Test MSE 2.87262473368846 Test RE 0.810116556511696\n",
      "51 Train Loss 1.3812575 Test MSE 2.8439381296921113 Test RE 0.8060614144248857\n",
      "52 Train Loss 1.2872463 Test MSE 2.831860668895729 Test RE 0.8043480274984153\n",
      "53 Train Loss 1.2142519 Test MSE 2.875436989424552 Test RE 0.8105130053733963\n",
      "54 Train Loss 1.1525768 Test MSE 2.9178506329645595 Test RE 0.816468790337601\n",
      "55 Train Loss 1.099287 Test MSE 2.8835015949877176 Test RE 0.8116488137739256\n",
      "56 Train Loss 1.0564537 Test MSE 2.9073374942678836 Test RE 0.8149965773136543\n",
      "57 Train Loss 0.99661964 Test MSE 2.94155787020454 Test RE 0.8197789428836347\n",
      "58 Train Loss 0.9378318 Test MSE 2.9523060390877722 Test RE 0.8212752738817949\n",
      "59 Train Loss 0.8739479 Test MSE 2.956824060063049 Test RE 0.8219034473090917\n",
      "60 Train Loss 0.81388557 Test MSE 2.9251563603038444 Test RE 0.8174902904151118\n",
      "61 Train Loss 0.76935077 Test MSE 2.962302109708909 Test RE 0.8226644571522115\n",
      "62 Train Loss 0.7242503 Test MSE 2.9920932382071532 Test RE 0.8267907737118477\n",
      "63 Train Loss 0.701309 Test MSE 3.0198705070385796 Test RE 0.8306196874910072\n",
      "64 Train Loss 0.6756218 Test MSE 3.064772090949444 Test RE 0.8367720248702794\n",
      "65 Train Loss 0.6505317 Test MSE 3.091227921058897 Test RE 0.840375870270506\n",
      "66 Train Loss 0.6288724 Test MSE 3.1026803302925425 Test RE 0.8419311471736569\n",
      "67 Train Loss 0.6102898 Test MSE 3.1089995212706785 Test RE 0.8427880864872477\n",
      "68 Train Loss 0.5943037 Test MSE 3.125348534873837 Test RE 0.8450011275311209\n",
      "69 Train Loss 0.5762897 Test MSE 3.170196247761127 Test RE 0.8510422752978298\n",
      "70 Train Loss 0.5642555 Test MSE 3.194745577412055 Test RE 0.8543310663971507\n",
      "71 Train Loss 0.5546278 Test MSE 3.210006974167975 Test RE 0.8563692179587244\n",
      "72 Train Loss 0.5366455 Test MSE 3.277268222090242 Test RE 0.8652947200975968\n",
      "73 Train Loss 0.524333 Test MSE 3.303302708671019 Test RE 0.8687248545398198\n",
      "74 Train Loss 0.5154863 Test MSE 3.3054038944458957 Test RE 0.8690011026299067\n",
      "75 Train Loss 0.5052427 Test MSE 3.32317003208075 Test RE 0.87133335972319\n",
      "76 Train Loss 0.4971985 Test MSE 3.313443345715549 Test RE 0.8700572593597471\n",
      "77 Train Loss 0.48737884 Test MSE 3.300328593458392 Test RE 0.8683336900222824\n",
      "78 Train Loss 0.47825965 Test MSE 3.3124074084920934 Test RE 0.8699212384492429\n",
      "79 Train Loss 0.4680228 Test MSE 3.3196582092255484 Test RE 0.8708728390117975\n",
      "80 Train Loss 0.45990455 Test MSE 3.3194730720497807 Test RE 0.8708485544054122\n",
      "81 Train Loss 0.45283616 Test MSE 3.3374030886507464 Test RE 0.8731973158489904\n",
      "82 Train Loss 0.44772825 Test MSE 3.33831938398339 Test RE 0.8733171772641801\n",
      "83 Train Loss 0.44351587 Test MSE 3.323659253741119 Test RE 0.8713974941883927\n",
      "84 Train Loss 0.43817884 Test MSE 3.321225705354025 Test RE 0.871078421727168\n",
      "85 Train Loss 0.430152 Test MSE 3.333850874450805 Test RE 0.8727324919096592\n",
      "86 Train Loss 0.42164114 Test MSE 3.3616277698978014 Test RE 0.876360655713668\n",
      "87 Train Loss 0.41580054 Test MSE 3.385259672426403 Test RE 0.8794356242949625\n",
      "88 Train Loss 0.40902436 Test MSE 3.3928540294684213 Test RE 0.8804215171448959\n",
      "89 Train Loss 0.4031725 Test MSE 3.374516074474915 Test RE 0.8780390089706901\n",
      "90 Train Loss 0.39776173 Test MSE 3.383331293535583 Test RE 0.879185107815046\n",
      "91 Train Loss 0.39273435 Test MSE 3.398570908406813 Test RE 0.8811629496876079\n",
      "92 Train Loss 0.38865215 Test MSE 3.4065845371129644 Test RE 0.8822012030093301\n",
      "93 Train Loss 0.38546088 Test MSE 3.4285889714096682 Test RE 0.8850458544632943\n",
      "94 Train Loss 0.3820738 Test MSE 3.4424132890036776 Test RE 0.8868283437941298\n",
      "95 Train Loss 0.37835938 Test MSE 3.4364479850454055 Test RE 0.8860596251657266\n",
      "96 Train Loss 0.37174213 Test MSE 3.4358956705512 Test RE 0.885988417447589\n",
      "97 Train Loss 0.36761484 Test MSE 3.4556403338362904 Test RE 0.8885304741012958\n",
      "98 Train Loss 0.36337423 Test MSE 3.4717656782862423 Test RE 0.8906011733969917\n",
      "99 Train Loss 0.3586811 Test MSE 3.480608809996798 Test RE 0.8917347024743142\n",
      "Training time: 81.10\n",
      "KG_stan_tune9\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.07142 Test MSE 8.551698467498454 Test RE 1.3977652843906838\n",
      "1 Train Loss 50.90712 Test MSE 9.08067810517815 Test RE 1.4403472266975963\n",
      "2 Train Loss 46.67517 Test MSE 7.871302169544425 Test RE 1.3410079504049683\n",
      "3 Train Loss 45.906883 Test MSE 8.322353950666356 Test RE 1.3788948561477312\n",
      "4 Train Loss 45.123642 Test MSE 8.13383558188718 Test RE 1.3631880016722684\n",
      "5 Train Loss 44.657543 Test MSE 8.242848485049576 Test RE 1.3722925915643296\n",
      "6 Train Loss 44.00582 Test MSE 8.231669406941013 Test RE 1.3713617136620808\n",
      "7 Train Loss 43.61393 Test MSE 8.28249448815914 Test RE 1.375588821845233\n",
      "8 Train Loss 43.313866 Test MSE 8.36436653293672 Test RE 1.382370916329627\n",
      "9 Train Loss 42.98066 Test MSE 8.05936615745858 Test RE 1.3569333108825166\n",
      "10 Train Loss 42.69226 Test MSE 8.130324358774526 Test RE 1.3628937386620639\n",
      "11 Train Loss 41.88109 Test MSE 7.790971042157351 Test RE 1.3341475264488032\n",
      "12 Train Loss 41.3722 Test MSE 7.721792245986954 Test RE 1.3282111346074164\n",
      "13 Train Loss 40.483498 Test MSE 7.760292471969871 Test RE 1.331518193713788\n",
      "14 Train Loss 39.929836 Test MSE 7.646613579370346 Test RE 1.321729648863555\n",
      "15 Train Loss 37.914024 Test MSE 7.312728656686007 Test RE 1.2925513028575457\n",
      "16 Train Loss 34.692955 Test MSE 6.614294420692736 Test RE 1.229277185810809\n",
      "17 Train Loss 27.775517 Test MSE 6.0678198105847345 Test RE 1.1774009938013106\n",
      "18 Train Loss 25.394577 Test MSE 6.377861738117363 Test RE 1.20710656078624\n",
      "19 Train Loss 23.775806 Test MSE 6.075305803964675 Test RE 1.1781270617703572\n",
      "20 Train Loss 23.02055 Test MSE 5.898729029861027 Test RE 1.1608798780895355\n",
      "21 Train Loss 22.639645 Test MSE 5.977181059250523 Test RE 1.1685741257895466\n",
      "22 Train Loss 22.157978 Test MSE 6.0240747322005905 Test RE 1.1731491647347403\n",
      "23 Train Loss 21.729485 Test MSE 6.164602864973648 Test RE 1.1867537485280162\n",
      "24 Train Loss 20.87711 Test MSE 5.70751016425218 Test RE 1.141908766491502\n",
      "25 Train Loss 19.67416 Test MSE 5.607903117459252 Test RE 1.1319006552733475\n",
      "26 Train Loss 18.288881 Test MSE 5.166162946164358 Test RE 1.0864058871637774\n",
      "27 Train Loss 17.288193 Test MSE 4.785267153160644 Test RE 1.0455893586715386\n",
      "28 Train Loss 16.897676 Test MSE 4.579682054340213 Test RE 1.0228824429094965\n",
      "29 Train Loss 16.56674 Test MSE 4.405316684466897 Test RE 1.0032210294944928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 16.106049 Test MSE 4.078317378751032 Test RE 0.9652694698640096\n",
      "31 Train Loss 15.611848 Test MSE 3.959900221926694 Test RE 0.9511525615140869\n",
      "32 Train Loss 14.737133 Test MSE 3.881950908396222 Test RE 0.9417444723497648\n",
      "33 Train Loss 13.603746 Test MSE 3.7394027365189455 Test RE 0.9242919721707974\n",
      "34 Train Loss 11.993738 Test MSE 3.4261515972987353 Test RE 0.8847312102478964\n",
      "35 Train Loss 10.759099 Test MSE 3.1477586373006914 Test RE 0.8480252281924009\n",
      "36 Train Loss 9.328689 Test MSE 2.603907507725997 Test RE 0.771295570369548\n",
      "37 Train Loss 7.803826 Test MSE 2.236307904850545 Test RE 0.7147824154072105\n",
      "38 Train Loss 6.293677 Test MSE 2.1248514082312973 Test RE 0.6967425646600539\n",
      "39 Train Loss 5.4075327 Test MSE 1.7987134565726357 Test RE 0.6410457896934681\n",
      "40 Train Loss 4.29401 Test MSE 1.3718737567546293 Test RE 0.559841558904803\n",
      "41 Train Loss 3.3862567 Test MSE 1.099442663543237 Test RE 0.5011807169892459\n",
      "42 Train Loss 2.4702017 Test MSE 0.849594261224262 Test RE 0.4405689086959393\n",
      "43 Train Loss 1.8907894 Test MSE 0.662523483773227 Test RE 0.38905293746024927\n",
      "44 Train Loss 1.3962234 Test MSE 0.4497479227111801 Test RE 0.32054768395518046\n",
      "45 Train Loss 1.0859958 Test MSE 0.2665199661541736 Test RE 0.2467589621708369\n",
      "46 Train Loss 1.0144932 Test MSE 0.2721499389863009 Test RE 0.2493516124293289\n",
      "47 Train Loss 0.86528456 Test MSE 0.23915989949400362 Test RE 0.23375033470025705\n",
      "48 Train Loss 0.6832705 Test MSE 0.23214478988297774 Test RE 0.23029660240739194\n",
      "49 Train Loss 0.61125934 Test MSE 0.22903843371814842 Test RE 0.22875060050445165\n",
      "50 Train Loss 0.5228794 Test MSE 0.19301562720082605 Test RE 0.20999274782340216\n",
      "51 Train Loss 0.456767 Test MSE 0.20752455149789464 Test RE 0.2177422981001225\n",
      "52 Train Loss 0.3931555 Test MSE 0.22068365820552086 Test RE 0.22453970489724853\n",
      "53 Train Loss 0.3539817 Test MSE 0.20942837363521538 Test RE 0.21873879752914505\n",
      "54 Train Loss 0.32705522 Test MSE 0.2092037628021789 Test RE 0.2186214679549356\n",
      "55 Train Loss 0.29528013 Test MSE 0.1847878349452292 Test RE 0.20546826269488075\n",
      "56 Train Loss 0.2642298 Test MSE 0.1502530346204327 Test RE 0.18527622198453106\n",
      "57 Train Loss 0.2343049 Test MSE 0.12780413533290713 Test RE 0.17087578136988435\n",
      "58 Train Loss 0.20675373 Test MSE 0.10329683896520149 Test RE 0.1536213495806806\n",
      "59 Train Loss 0.1875446 Test MSE 0.09997920613641006 Test RE 0.15113425247114778\n",
      "60 Train Loss 0.1726973 Test MSE 0.0932377887021675 Test RE 0.1459499809832557\n",
      "61 Train Loss 0.1506429 Test MSE 0.07601773484433161 Test RE 0.13178486090179145\n",
      "62 Train Loss 0.14260137 Test MSE 0.06963604654828523 Test RE 0.1261319510925504\n",
      "63 Train Loss 0.135221 Test MSE 0.0629456758503053 Test RE 0.11991983181486711\n",
      "64 Train Loss 0.12566441 Test MSE 0.05691693535034581 Test RE 0.11403254423140242\n",
      "65 Train Loss 0.120279886 Test MSE 0.053544412455562546 Test RE 0.11060254974765074\n",
      "66 Train Loss 0.11334455 Test MSE 0.046853755016581226 Test RE 0.10346185517874515\n",
      "67 Train Loss 0.1075802 Test MSE 0.04245153834504716 Test RE 0.0984815276164127\n",
      "68 Train Loss 0.101867914 Test MSE 0.0382535583900331 Test RE 0.09348544082161714\n",
      "69 Train Loss 0.09515432 Test MSE 0.03525633348052178 Test RE 0.08974838307420273\n",
      "70 Train Loss 0.090673804 Test MSE 0.03464155312332344 Test RE 0.08896245062032342\n",
      "71 Train Loss 0.08605271 Test MSE 0.03368146744611093 Test RE 0.0877209977282427\n",
      "72 Train Loss 0.08267067 Test MSE 0.0343386991260833 Test RE 0.08857271955026758\n",
      "73 Train Loss 0.077192344 Test MSE 0.0332868590936187 Test RE 0.08720561899037185\n",
      "74 Train Loss 0.074191585 Test MSE 0.03105082507825041 Test RE 0.08422570068433184\n",
      "75 Train Loss 0.068720825 Test MSE 0.027771374154620252 Test RE 0.07965384508179359\n",
      "76 Train Loss 0.06634049 Test MSE 0.027577721356961443 Test RE 0.07937564180666133\n",
      "77 Train Loss 0.064512104 Test MSE 0.028062015935857387 Test RE 0.08006956954472338\n",
      "78 Train Loss 0.060861263 Test MSE 0.02635189859718743 Test RE 0.07759147639340219\n",
      "79 Train Loss 0.058395814 Test MSE 0.024797544294011983 Test RE 0.07526835032875302\n",
      "80 Train Loss 0.05611403 Test MSE 0.024383674676815625 Test RE 0.07463759517471347\n",
      "81 Train Loss 0.05343117 Test MSE 0.024018715783768754 Test RE 0.07407692598102558\n",
      "82 Train Loss 0.051306535 Test MSE 0.02316007273548054 Test RE 0.07274079106857734\n",
      "83 Train Loss 0.048318516 Test MSE 0.022453555782744973 Test RE 0.07162268922318375\n",
      "84 Train Loss 0.046611898 Test MSE 0.022842659957938116 Test RE 0.07224060886327605\n",
      "85 Train Loss 0.044517018 Test MSE 0.024106184488697974 Test RE 0.07421168598554445\n",
      "86 Train Loss 0.043507233 Test MSE 0.02417298742885956 Test RE 0.07431444237531183\n",
      "87 Train Loss 0.0423528 Test MSE 0.02263081781525842 Test RE 0.07190484997664436\n",
      "88 Train Loss 0.040582303 Test MSE 0.021702037747681393 Test RE 0.0704138867678922\n",
      "89 Train Loss 0.03963552 Test MSE 0.021550533777772125 Test RE 0.07016767331712236\n",
      "90 Train Loss 0.038829662 Test MSE 0.020748406388966172 Test RE 0.06884944332110429\n",
      "91 Train Loss 0.038024835 Test MSE 0.020406760935731436 Test RE 0.06828024938712059\n",
      "92 Train Loss 0.037413474 Test MSE 0.02023348992719626 Test RE 0.06798975231305418\n",
      "93 Train Loss 0.036496386 Test MSE 0.02040409034333181 Test RE 0.06827578139041289\n",
      "94 Train Loss 0.03552975 Test MSE 0.020369282658994486 Test RE 0.06821752012492172\n",
      "95 Train Loss 0.03469123 Test MSE 0.019942128338551274 Test RE 0.0674984521257699\n",
      "96 Train Loss 0.034033354 Test MSE 0.02007280814836196 Test RE 0.06771924805860469\n",
      "97 Train Loss 0.033623718 Test MSE 0.020334114087359054 Test RE 0.06815860422628536\n",
      "98 Train Loss 0.033066705 Test MSE 0.019792784219440106 Test RE 0.0672452333970464\n",
      "99 Train Loss 0.032294434 Test MSE 0.019448856036061883 Test RE 0.0666584316174136\n",
      "Training time: 80.71\n",
      "KG_stan_tune9\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 58.018044 Test MSE 8.510837492623644 Test RE 1.3944219462104757\n",
      "1 Train Loss 55.080063 Test MSE 9.25260869136851 Test RE 1.4539188193118944\n",
      "2 Train Loss 46.171494 Test MSE 8.6363847346139 Test RE 1.4046691709499683\n",
      "3 Train Loss 45.68667 Test MSE 8.763011501666059 Test RE 1.41492933648102\n",
      "4 Train Loss 44.50269 Test MSE 8.506271240277028 Test RE 1.394047826932221\n",
      "5 Train Loss 44.329098 Test MSE 8.40101243541713 Test RE 1.385395823532083\n",
      "6 Train Loss 44.123833 Test MSE 8.357642165721312 Test RE 1.3818151397127474\n",
      "7 Train Loss 43.96363 Test MSE 8.474305259583806 Test RE 1.3914259936494462\n",
      "8 Train Loss 43.87779 Test MSE 8.382848613300819 Test RE 1.3838973315331735\n",
      "9 Train Loss 43.66622 Test MSE 8.362607702174785 Test RE 1.382225568543261\n",
      "10 Train Loss 43.511993 Test MSE 8.572064701148255 Test RE 1.3994287133375476\n",
      "11 Train Loss 43.05739 Test MSE 8.612751889328479 Test RE 1.4027459663231674\n",
      "12 Train Loss 42.52934 Test MSE 8.696148173587085 Test RE 1.4095209193501081\n",
      "13 Train Loss 42.030205 Test MSE 8.750198762073598 Test RE 1.4138945465119093\n",
      "14 Train Loss 41.466736 Test MSE 9.018952628865108 Test RE 1.435443533545382\n",
      "15 Train Loss 40.42426 Test MSE 8.952716842086053 Test RE 1.430162823911029\n",
      "16 Train Loss 35.915817 Test MSE 8.926210416477879 Test RE 1.4280441036479985\n",
      "17 Train Loss 32.54925 Test MSE 8.583123462872074 Test RE 1.4003311190643446\n",
      "18 Train Loss 30.46907 Test MSE 8.191531795700405 Test RE 1.3680142489912595\n",
      "19 Train Loss 28.01522 Test MSE 8.02138436329498 Test RE 1.3537320896848462\n",
      "20 Train Loss 26.112045 Test MSE 7.654113046770465 Test RE 1.3223776376183647\n",
      "21 Train Loss 24.578724 Test MSE 7.07406625378945 Test RE 1.2712841189818989\n",
      "22 Train Loss 23.380348 Test MSE 7.185796670598398 Test RE 1.281284352439191\n",
      "23 Train Loss 22.159874 Test MSE 7.06229057339184 Test RE 1.2702255714579616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Train Loss 21.414211 Test MSE 7.268944741952845 Test RE 1.2886760106242483\n",
      "25 Train Loss 20.514435 Test MSE 7.707366903159356 Test RE 1.326969916439579\n",
      "26 Train Loss 20.022102 Test MSE 7.848761982095462 Test RE 1.3390865249475992\n",
      "27 Train Loss 19.664032 Test MSE 7.77685154849365 Test RE 1.3329380475577222\n",
      "28 Train Loss 19.298435 Test MSE 8.021616631519363 Test RE 1.353751688962127\n",
      "29 Train Loss 18.956734 Test MSE 8.016458900426535 Test RE 1.3533164020227293\n",
      "30 Train Loss 18.75875 Test MSE 8.039934020775018 Test RE 1.355296455921169\n",
      "31 Train Loss 18.552427 Test MSE 8.184299319080298 Test RE 1.3674101912754593\n",
      "32 Train Loss 18.086369 Test MSE 8.297503749915448 Test RE 1.3768346559011928\n",
      "33 Train Loss 17.056526 Test MSE 8.227277776173658 Test RE 1.370995851194169\n",
      "34 Train Loss 15.39376 Test MSE 7.8527945445919904 Test RE 1.3394304808918334\n",
      "35 Train Loss 13.091629 Test MSE 6.8574971491789505 Test RE 1.2516729828070283\n",
      "36 Train Loss 10.115644 Test MSE 6.7944691634269985 Test RE 1.2459075748420743\n",
      "37 Train Loss 7.831615 Test MSE 6.2813882904636005 Test RE 1.197942245425745\n",
      "38 Train Loss 6.3253336 Test MSE 5.989067048005402 Test RE 1.1697354391686776\n",
      "39 Train Loss 5.6426992 Test MSE 6.0279958198354775 Test RE 1.173530905714891\n",
      "40 Train Loss 4.982427 Test MSE 6.434897759562522 Test RE 1.2124920111155013\n",
      "41 Train Loss 4.6203012 Test MSE 6.481895532169368 Test RE 1.21691172038289\n",
      "42 Train Loss 4.2922306 Test MSE 6.355246177054371 Test RE 1.2049644921110256\n",
      "43 Train Loss 3.9530678 Test MSE 6.251075814778977 Test RE 1.1950482585789917\n",
      "44 Train Loss 3.6201987 Test MSE 6.124989451757275 Test RE 1.1829345946885903\n",
      "45 Train Loss 3.436174 Test MSE 6.123467299495919 Test RE 1.1827875970108064\n",
      "46 Train Loss 3.295604 Test MSE 6.065930269138227 Test RE 1.1772176560233238\n",
      "47 Train Loss 3.1884851 Test MSE 6.075660017835524 Test RE 1.1781614059563015\n",
      "48 Train Loss 3.0923138 Test MSE 6.030810494983368 Test RE 1.1738048543771875\n",
      "49 Train Loss 2.9648914 Test MSE 5.982624996632821 Test RE 1.169106165595454\n",
      "50 Train Loss 2.8575382 Test MSE 5.9989116087308805 Test RE 1.1706964238410509\n",
      "51 Train Loss 2.7726717 Test MSE 5.8842297161944765 Test RE 1.1594522555001543\n",
      "52 Train Loss 2.6625729 Test MSE 5.7738005434584325 Test RE 1.1485210222050632\n",
      "53 Train Loss 2.5561063 Test MSE 5.739674366604789 Test RE 1.145121812429481\n",
      "54 Train Loss 2.4348922 Test MSE 5.58328723578174 Test RE 1.1294136850847927\n",
      "55 Train Loss 2.3600454 Test MSE 5.445990805695591 Test RE 1.1154407649163702\n",
      "56 Train Loss 2.312946 Test MSE 5.458222910427663 Test RE 1.1166927442043777\n",
      "57 Train Loss 2.2391908 Test MSE 5.343046230781649 Test RE 1.1048479806460332\n",
      "58 Train Loss 2.1902928 Test MSE 5.2222298685384745 Test RE 1.092285208260073\n",
      "59 Train Loss 2.1529398 Test MSE 5.18518627904096 Test RE 1.0884042823405877\n",
      "60 Train Loss 2.1015456 Test MSE 5.175167072455415 Test RE 1.0873522256061205\n",
      "61 Train Loss 2.0736206 Test MSE 5.163144052258689 Test RE 1.086088415238958\n",
      "62 Train Loss 2.0377774 Test MSE 5.163994481181252 Test RE 1.0861778571527416\n",
      "63 Train Loss 2.0027685 Test MSE 5.196983107429441 Test RE 1.089641694385533\n",
      "64 Train Loss 1.9648284 Test MSE 5.239581251091672 Test RE 1.0940983170330398\n",
      "65 Train Loss 1.9373215 Test MSE 5.216384523335935 Test RE 1.0916737288808531\n",
      "66 Train Loss 1.9116759 Test MSE 5.228479459167878 Test RE 1.0929385971837509\n",
      "67 Train Loss 1.8834729 Test MSE 5.269912128073148 Test RE 1.0972605043449717\n",
      "68 Train Loss 1.8593556 Test MSE 5.28203629179736 Test RE 1.0985219791958938\n",
      "69 Train Loss 1.828065 Test MSE 5.355466504539067 Test RE 1.106131382315598\n",
      "70 Train Loss 1.8044809 Test MSE 5.429347199700232 Test RE 1.1137349997793384\n",
      "71 Train Loss 1.7801539 Test MSE 5.436136971380975 Test RE 1.1144311832576022\n",
      "72 Train Loss 1.7541095 Test MSE 5.397334136744989 Test RE 1.110446687239637\n",
      "73 Train Loss 1.732821 Test MSE 5.389949081197145 Test RE 1.109686727100536\n",
      "74 Train Loss 1.6995869 Test MSE 5.464897050250074 Test RE 1.1173752636540648\n",
      "75 Train Loss 1.6810467 Test MSE 5.5111653373081575 Test RE 1.1220953958827584\n",
      "76 Train Loss 1.6449493 Test MSE 5.568935510972711 Test RE 1.1279611837737271\n",
      "77 Train Loss 1.6078318 Test MSE 5.618865005440624 Test RE 1.133006390377535\n",
      "78 Train Loss 1.5798234 Test MSE 5.645012472791682 Test RE 1.1356395611474093\n",
      "79 Train Loss 1.5509393 Test MSE 5.688176563021831 Test RE 1.1399730768566407\n",
      "80 Train Loss 1.5291096 Test MSE 5.681625953650756 Test RE 1.1393164807217295\n",
      "81 Train Loss 1.4914601 Test MSE 5.731752647020494 Test RE 1.1443313088692457\n",
      "82 Train Loss 1.467113 Test MSE 5.792189160771828 Test RE 1.1503484948034564\n",
      "83 Train Loss 1.4281709 Test MSE 5.830435624584303 Test RE 1.1541401848531234\n",
      "84 Train Loss 1.3809466 Test MSE 5.925889506245297 Test RE 1.163549422574464\n",
      "85 Train Loss 1.3445174 Test MSE 5.986172168513683 Test RE 1.1694527029428545\n",
      "86 Train Loss 1.3039579 Test MSE 6.035613335041483 Test RE 1.1742721609691977\n",
      "87 Train Loss 1.2647468 Test MSE 6.063535431884683 Test RE 1.1769852495425037\n",
      "88 Train Loss 1.2358913 Test MSE 6.110511134701663 Test RE 1.1815356506232526\n",
      "89 Train Loss 1.201053 Test MSE 6.099896472372839 Test RE 1.1805089727421259\n",
      "90 Train Loss 1.1600564 Test MSE 6.04469644983004 Test RE 1.1751554215732634\n",
      "91 Train Loss 1.137903 Test MSE 6.082464701418652 Test RE 1.1788209863199175\n",
      "92 Train Loss 1.1167403 Test MSE 6.104806965892838 Test RE 1.180984039451524\n",
      "93 Train Loss 1.091886 Test MSE 6.084863568205533 Test RE 1.1790534213514143\n",
      "94 Train Loss 1.0682448 Test MSE 6.130909363285056 Test RE 1.1835061203146215\n",
      "95 Train Loss 1.0528164 Test MSE 6.1858831112360155 Test RE 1.1888003243995746\n",
      "96 Train Loss 1.0371556 Test MSE 6.2313441509957865 Test RE 1.193160669266369\n",
      "97 Train Loss 1.0264406 Test MSE 6.230544255761566 Test RE 1.1930840859369793\n",
      "98 Train Loss 1.0070201 Test MSE 6.198240139126651 Test RE 1.1899871161276125\n",
      "99 Train Loss 0.99145085 Test MSE 6.198550432579287 Test RE 1.190016902049216\n",
      "Training time: 81.55\n",
      "KG_stan_tune9\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.984344 Test MSE 8.468727364922167 Test RE 1.3909679911973736\n",
      "1 Train Loss 57.894783 Test MSE 8.699069458764162 Test RE 1.4097576486892573\n",
      "2 Train Loss 49.707806 Test MSE 8.22686630946633 Test RE 1.3709615673023752\n",
      "3 Train Loss 47.12561 Test MSE 8.636760702511959 Test RE 1.4046997453618577\n",
      "4 Train Loss 46.731575 Test MSE 8.549196524305149 Test RE 1.3975607995637325\n",
      "5 Train Loss 46.441948 Test MSE 8.553768204271632 Test RE 1.3979344222055627\n",
      "6 Train Loss 45.853912 Test MSE 8.582231400239793 Test RE 1.4002583474486965\n",
      "7 Train Loss 45.62445 Test MSE 8.431212748191603 Test RE 1.3878837292128337\n",
      "8 Train Loss 45.5085 Test MSE 8.275114884460892 Test RE 1.374975868673261\n",
      "9 Train Loss 45.00081 Test MSE 8.302863784842382 Test RE 1.3772792890483665\n",
      "10 Train Loss 44.906776 Test MSE 8.396515282630101 Test RE 1.3850249652128197\n",
      "11 Train Loss 44.819946 Test MSE 8.4067183779828 Test RE 1.3858662220260127\n",
      "12 Train Loss 44.69484 Test MSE 8.400525296961284 Test RE 1.3853556563872889\n",
      "13 Train Loss 44.52904 Test MSE 8.406988020704794 Test RE 1.3858884474490127\n",
      "14 Train Loss 44.27517 Test MSE 8.445250448687064 Test RE 1.3890386397768213\n",
      "15 Train Loss 43.779816 Test MSE 8.697844058715091 Test RE 1.4096583519804942\n",
      "16 Train Loss 43.665367 Test MSE 8.700213316881035 Test RE 1.40985033157509\n",
      "17 Train Loss 43.19044 Test MSE 8.679581294988896 Test RE 1.408177652557758\n",
      "18 Train Loss 42.71399 Test MSE 8.896325908869688 Test RE 1.4256515892204091\n",
      "19 Train Loss 41.537796 Test MSE 9.04896757424927 Test RE 1.437830117342389\n",
      "20 Train Loss 40.04873 Test MSE 8.736686891729565 Test RE 1.4128024718546193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Train Loss 37.76969 Test MSE 8.362510024411376 Test RE 1.3822174961153098\n",
      "22 Train Loss 34.55396 Test MSE 8.917866689769182 Test RE 1.4273765193712304\n",
      "23 Train Loss 31.928965 Test MSE 8.237570882295003 Test RE 1.3718532061497521\n",
      "24 Train Loss 30.985706 Test MSE 8.190124327129205 Test RE 1.3678967178735968\n",
      "25 Train Loss 30.188244 Test MSE 8.248181682542736 Test RE 1.3727364626355882\n",
      "26 Train Loss 29.176247 Test MSE 7.9941584172905475 Test RE 1.3514327381812345\n",
      "27 Train Loss 28.423977 Test MSE 8.05430656020517 Test RE 1.3565073087759367\n",
      "28 Train Loss 27.332779 Test MSE 7.796154565949291 Test RE 1.3345912731597909\n",
      "29 Train Loss 25.750534 Test MSE 7.545185607517283 Test RE 1.3129343901605026\n",
      "30 Train Loss 24.361336 Test MSE 7.571866574918975 Test RE 1.3152537132294198\n",
      "31 Train Loss 23.276138 Test MSE 7.828943307058379 Test RE 1.3373948126056132\n",
      "32 Train Loss 22.352133 Test MSE 7.789613045161237 Test RE 1.3340312477923966\n",
      "33 Train Loss 21.733381 Test MSE 7.781914068051979 Test RE 1.333371830243151\n",
      "34 Train Loss 20.866924 Test MSE 7.694985068764023 Test RE 1.3259036037762333\n",
      "35 Train Loss 20.205225 Test MSE 7.7682491577254424 Test RE 1.3322006266006285\n",
      "36 Train Loss 19.69204 Test MSE 7.684350592594693 Test RE 1.3249870870335902\n",
      "37 Train Loss 19.21302 Test MSE 7.623238280624601 Test RE 1.3197078732780005\n",
      "38 Train Loss 17.26159 Test MSE 7.0283543225390215 Test RE 1.2671700045096357\n",
      "39 Train Loss 15.98074 Test MSE 6.453520016866345 Test RE 1.214245187839673\n",
      "40 Train Loss 15.585718 Test MSE 6.4046413165581315 Test RE 1.2096381257952196\n",
      "41 Train Loss 15.28905 Test MSE 6.488241505284307 Test RE 1.2175072714689252\n",
      "42 Train Loss 14.914082 Test MSE 6.538297658192798 Test RE 1.2221947231924468\n",
      "43 Train Loss 14.479101 Test MSE 6.426493255955433 Test RE 1.2116999454597035\n",
      "44 Train Loss 14.206982 Test MSE 6.41718085409651 Test RE 1.210821711632124\n",
      "45 Train Loss 13.979446 Test MSE 6.434528585558376 Test RE 1.212457229914019\n",
      "46 Train Loss 13.694899 Test MSE 6.245217583317317 Test RE 1.1944881541658234\n",
      "47 Train Loss 13.439285 Test MSE 6.255023967039434 Test RE 1.195425592645531\n",
      "48 Train Loss 13.094065 Test MSE 6.385044949034542 Test RE 1.2077861350154968\n",
      "49 Train Loss 12.743555 Test MSE 6.418763973610751 Test RE 1.2109710573740275\n",
      "50 Train Loss 12.154676 Test MSE 6.313172253411105 Test RE 1.2009692281665871\n",
      "51 Train Loss 11.542196 Test MSE 6.06359902433396 Test RE 1.1769914214515644\n",
      "52 Train Loss 10.988011 Test MSE 6.097528453611433 Test RE 1.1802798099386778\n",
      "53 Train Loss 10.390237 Test MSE 6.077961358209941 Test RE 1.1783845170010459\n",
      "54 Train Loss 9.920149 Test MSE 6.02134941185906 Test RE 1.1728837655560902\n",
      "55 Train Loss 9.306364 Test MSE 6.076798904938961 Test RE 1.1782718244090244\n",
      "56 Train Loss 8.385572 Test MSE 6.065186352278105 Test RE 1.177145467679955\n",
      "57 Train Loss 5.481159 Test MSE 4.563098347774003 Test RE 1.0210287589092553\n",
      "58 Train Loss 3.9781852 Test MSE 4.784426596612606 Test RE 1.0454975230903623\n",
      "59 Train Loss 3.2383041 Test MSE 5.065388298383719 Test RE 1.0757576215426572\n",
      "60 Train Loss 2.9783955 Test MSE 5.131494379193907 Test RE 1.0827544792683608\n",
      "61 Train Loss 2.6723044 Test MSE 5.182608919634163 Test RE 1.0881337464772731\n",
      "62 Train Loss 2.5034435 Test MSE 5.17809192719394 Test RE 1.0876594522165712\n",
      "63 Train Loss 2.4289706 Test MSE 5.1140107344475565 Test RE 1.080908365306894\n",
      "64 Train Loss 2.3613052 Test MSE 5.114935157284226 Test RE 1.0810060548971119\n",
      "65 Train Loss 2.2858295 Test MSE 5.112698924038627 Test RE 1.0807697228733455\n",
      "66 Train Loss 2.2213612 Test MSE 5.108903094252666 Test RE 1.0803684495252681\n",
      "67 Train Loss 2.177934 Test MSE 5.127979058163394 Test RE 1.082383546222682\n",
      "68 Train Loss 2.1236749 Test MSE 5.148819775405852 Test RE 1.0845807838080315\n",
      "69 Train Loss 2.0849187 Test MSE 5.131922915015411 Test RE 1.0827996892363674\n",
      "70 Train Loss 2.042481 Test MSE 5.171450817654879 Test RE 1.0869617451091134\n",
      "71 Train Loss 2.0163026 Test MSE 5.251368049675676 Test RE 1.0953282504437012\n",
      "72 Train Loss 1.9824734 Test MSE 5.301476690498669 Test RE 1.1005416634971148\n",
      "73 Train Loss 1.9656188 Test MSE 5.25900232566657 Test RE 1.0961241384079987\n",
      "74 Train Loss 1.9277251 Test MSE 5.251248498753406 Test RE 1.0953157824309312\n",
      "75 Train Loss 1.9087154 Test MSE 5.25755034745485 Test RE 1.0959728113941385\n",
      "76 Train Loss 1.8846412 Test MSE 5.230085445415613 Test RE 1.0931064384849685\n",
      "77 Train Loss 1.8664454 Test MSE 5.235245232130331 Test RE 1.0936455124377227\n",
      "78 Train Loss 1.841766 Test MSE 5.260357633119933 Test RE 1.0962653714234736\n",
      "79 Train Loss 1.8209203 Test MSE 5.256462516736126 Test RE 1.0958594226018854\n",
      "80 Train Loss 1.8063208 Test MSE 5.233527197162188 Test RE 1.0934660485038372\n",
      "81 Train Loss 1.792494 Test MSE 5.233191975042501 Test RE 1.0934310281568829\n",
      "82 Train Loss 1.7733353 Test MSE 5.262005803264702 Test RE 1.0964370983739393\n",
      "83 Train Loss 1.7560183 Test MSE 5.282853474934924 Test RE 1.0986069520046955\n",
      "84 Train Loss 1.7431705 Test MSE 5.271205350031473 Test RE 1.0973951284430272\n",
      "85 Train Loss 1.7313321 Test MSE 5.283961654151273 Test RE 1.0987221728373007\n",
      "86 Train Loss 1.7105098 Test MSE 5.322121719925941 Test RE 1.102682447994202\n",
      "87 Train Loss 1.6956522 Test MSE 5.345462896075539 Test RE 1.1050978143370076\n",
      "88 Train Loss 1.6798843 Test MSE 5.379872370942978 Test RE 1.1086489415267085\n",
      "89 Train Loss 1.6636934 Test MSE 5.413308389676614 Test RE 1.112088743315867\n",
      "90 Train Loss 1.6486671 Test MSE 5.433186603327891 Test RE 1.114128723218191\n",
      "91 Train Loss 1.6309469 Test MSE 5.462569659111709 Test RE 1.1171373043471813\n",
      "92 Train Loss 1.6160152 Test MSE 5.465043955439719 Test RE 1.1173902819719193\n",
      "93 Train Loss 1.5909258 Test MSE 5.4834352758264915 Test RE 1.1192688599471985\n",
      "94 Train Loss 1.5731142 Test MSE 5.5307145799915824 Test RE 1.1240837862964423\n",
      "95 Train Loss 1.553518 Test MSE 5.520155487171476 Test RE 1.123010238256687\n",
      "96 Train Loss 1.5375694 Test MSE 5.491769952286192 Test RE 1.1201191664777386\n",
      "97 Train Loss 1.5168151 Test MSE 5.528714797605894 Test RE 1.123880546176225\n",
      "98 Train Loss 1.4916548 Test MSE 5.569022810996192 Test RE 1.1279700248396478\n",
      "99 Train Loss 1.4611387 Test MSE 5.591728499735658 Test RE 1.1302671319792217\n",
      "Training time: 80.88\n",
      "KG_stan_tune9\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.498287 Test MSE 8.49468449952427 Test RE 1.393098058546858\n",
      "1 Train Loss 54.672062 Test MSE 8.376299231669334 Test RE 1.3833566177974566\n",
      "2 Train Loss 47.313904 Test MSE 7.890663036172801 Test RE 1.3426561612042107\n",
      "3 Train Loss 45.71911 Test MSE 8.15668245746387 Test RE 1.365101167161475\n",
      "4 Train Loss 44.832397 Test MSE 8.124283521455359 Test RE 1.36238732902522\n",
      "5 Train Loss 43.686954 Test MSE 8.304426664799198 Test RE 1.3774089082355967\n",
      "6 Train Loss 43.489983 Test MSE 8.028899088007652 Test RE 1.3543660539765523\n",
      "7 Train Loss 43.436714 Test MSE 8.057760178949641 Test RE 1.3567981070547344\n",
      "8 Train Loss 43.29823 Test MSE 8.12809423839997 Test RE 1.3627068072793265\n",
      "9 Train Loss 43.254868 Test MSE 8.1041916202431 Test RE 1.360701648293897\n",
      "10 Train Loss 43.0527 Test MSE 8.065509660604919 Test RE 1.3574503947233185\n",
      "11 Train Loss 42.765427 Test MSE 8.122271934624095 Test RE 1.3622186538389212\n",
      "12 Train Loss 42.528076 Test MSE 8.16631661887264 Test RE 1.3659071151606432\n",
      "13 Train Loss 41.540417 Test MSE 7.785505950676137 Test RE 1.333679515636844\n",
      "14 Train Loss 39.392776 Test MSE 7.414068196224052 Test RE 1.3014765533094281\n",
      "15 Train Loss 38.017204 Test MSE 7.643210839753597 Test RE 1.321435531588629\n",
      "16 Train Loss 33.703415 Test MSE 7.205090926669422 Test RE 1.2830033584988982\n",
      "17 Train Loss 33.280647 Test MSE 6.985851104219886 Test RE 1.2633326569351009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Train Loss 32.48204 Test MSE 6.981968413013801 Test RE 1.2629815320489737\n",
      "19 Train Loss 31.608765 Test MSE 6.925322432988986 Test RE 1.2578476984334703\n",
      "20 Train Loss 30.463547 Test MSE 6.761038474806489 Test RE 1.2428386883749667\n",
      "21 Train Loss 29.870407 Test MSE 6.5609194683823535 Test RE 1.2243072289826893\n",
      "22 Train Loss 28.894455 Test MSE 6.4968114087453745 Test RE 1.2183110698995352\n",
      "23 Train Loss 28.176018 Test MSE 6.671715037465537 Test RE 1.2346015119594775\n",
      "24 Train Loss 27.85939 Test MSE 6.556078996148448 Test RE 1.2238555149636001\n",
      "25 Train Loss 27.275005 Test MSE 6.333260730014621 Test RE 1.2028784490649764\n",
      "26 Train Loss 26.9105 Test MSE 6.394622711771332 Test RE 1.2086916536401862\n",
      "27 Train Loss 26.654385 Test MSE 6.421662205165853 Test RE 1.2112444182935367\n",
      "28 Train Loss 26.503775 Test MSE 6.456294120300465 Test RE 1.2145061368896257\n",
      "29 Train Loss 26.18407 Test MSE 6.369505424997574 Test RE 1.2063155224280404\n",
      "30 Train Loss 25.975163 Test MSE 6.292425922738748 Test RE 1.1989942933067423\n",
      "31 Train Loss 25.872715 Test MSE 6.29733382444994 Test RE 1.1994617917899488\n",
      "32 Train Loss 25.829407 Test MSE 6.261884034184539 Test RE 1.196080942059156\n",
      "33 Train Loss 25.587036 Test MSE 6.165156489996198 Test RE 1.1868070367798842\n",
      "34 Train Loss 25.506111 Test MSE 6.137621906699717 Test RE 1.1841538352318535\n",
      "35 Train Loss 25.397717 Test MSE 6.223597679749887 Test RE 1.1924188021096167\n",
      "36 Train Loss 25.310734 Test MSE 6.229916740855191 Test RE 1.1930240031521018\n",
      "37 Train Loss 25.161507 Test MSE 6.1203788739179 Test RE 1.1824892846327721\n",
      "38 Train Loss 24.949436 Test MSE 6.142892544322849 Test RE 1.1846621678172953\n",
      "39 Train Loss 24.774925 Test MSE 6.1239098132862555 Test RE 1.182830333449294\n",
      "40 Train Loss 24.745771 Test MSE 6.120673048441127 Test RE 1.1825177023213553\n",
      "41 Train Loss 24.672035 Test MSE 6.202893660723575 Test RE 1.1904337422362774\n",
      "42 Train Loss 24.344517 Test MSE 6.159060617982926 Test RE 1.1862201568663566\n",
      "43 Train Loss 23.893482 Test MSE 5.899719769527679 Test RE 1.1609773636197451\n",
      "44 Train Loss 23.651482 Test MSE 5.776568807505981 Test RE 1.148796319942398\n",
      "45 Train Loss 23.30729 Test MSE 5.701181900621218 Test RE 1.1412755390701244\n",
      "46 Train Loss 23.142025 Test MSE 5.823810610400496 Test RE 1.1534842846014954\n",
      "47 Train Loss 22.934158 Test MSE 5.840131213485465 Test RE 1.1550994116831548\n",
      "48 Train Loss 22.45417 Test MSE 5.931563954344175 Test RE 1.164106378704907\n",
      "49 Train Loss 22.207289 Test MSE 5.950606136722343 Test RE 1.1659734548911376\n",
      "50 Train Loss 21.912312 Test MSE 5.677283099154674 Test RE 1.1388809688097927\n",
      "51 Train Loss 21.519144 Test MSE 5.462415558349274 Test RE 1.1171215468433675\n",
      "52 Train Loss 21.351847 Test MSE 5.374220886180773 Test RE 1.1080664779948701\n",
      "53 Train Loss 20.850769 Test MSE 5.299196684655521 Test RE 1.1003049830950993\n",
      "54 Train Loss 20.524952 Test MSE 5.389592034792244 Test RE 1.109649972002088\n",
      "55 Train Loss 20.223473 Test MSE 5.274785851147806 Test RE 1.0977677716251983\n",
      "56 Train Loss 19.881836 Test MSE 5.132841101523291 Test RE 1.0828965503560253\n",
      "57 Train Loss 19.710047 Test MSE 5.081510208972204 Test RE 1.0774682002016598\n",
      "58 Train Loss 19.209517 Test MSE 5.040729107888503 Test RE 1.0731359394259827\n",
      "59 Train Loss 18.874788 Test MSE 4.9472187625950195 Test RE 1.0631354939079913\n",
      "60 Train Loss 18.318165 Test MSE 4.704735146226019 Test RE 1.0367538341753537\n",
      "61 Train Loss 17.778044 Test MSE 4.418277935106515 Test RE 1.004695775793359\n",
      "62 Train Loss 17.52632 Test MSE 4.273676882440567 Test RE 0.9881182079825247\n",
      "63 Train Loss 17.35876 Test MSE 4.15910868582485 Test RE 0.9747835576488567\n",
      "64 Train Loss 16.979328 Test MSE 4.0174807765771146 Test RE 0.9580429160327127\n",
      "65 Train Loss 16.13481 Test MSE 3.984032002779192 Test RE 0.9540463392503489\n",
      "66 Train Loss 15.592648 Test MSE 3.6042872726657826 Test RE 0.9074396664074392\n",
      "67 Train Loss 15.080294 Test MSE 3.6090910505339098 Test RE 0.9080441808042562\n",
      "68 Train Loss 14.345369 Test MSE 3.5916043860023836 Test RE 0.9058416948880341\n",
      "69 Train Loss 13.740394 Test MSE 3.400384664811145 Test RE 0.8813980487643276\n",
      "70 Train Loss 12.947112 Test MSE 3.21593598519928 Test RE 0.8571597271683922\n",
      "71 Train Loss 11.85938 Test MSE 3.099628065322651 Test RE 0.8415169199579744\n",
      "72 Train Loss 11.183886 Test MSE 2.9338729597844875 Test RE 0.8187073937095423\n",
      "73 Train Loss 10.656351 Test MSE 2.579542087959055 Test RE 0.7676784853257589\n",
      "74 Train Loss 9.483576 Test MSE 2.251068026118474 Test RE 0.7171373960858733\n",
      "75 Train Loss 8.59319 Test MSE 2.135483073826272 Test RE 0.698483460790234\n",
      "76 Train Loss 8.182112 Test MSE 2.0298530329571105 Test RE 0.6809894091268364\n",
      "77 Train Loss 7.586912 Test MSE 1.8769280549689304 Test RE 0.6548349840744\n",
      "78 Train Loss 6.9701767 Test MSE 1.8563059220110916 Test RE 0.651227655543958\n",
      "79 Train Loss 6.6384134 Test MSE 1.8113479536339092 Test RE 0.643293262218584\n",
      "80 Train Loss 6.4511905 Test MSE 1.8994190322475735 Test RE 0.6587467004936918\n",
      "81 Train Loss 6.2315917 Test MSE 1.853750154989979 Test RE 0.6507791951304317\n",
      "82 Train Loss 5.9790688 Test MSE 1.8250682082738736 Test RE 0.645725013857841\n",
      "83 Train Loss 5.768906 Test MSE 1.816983321790208 Test RE 0.6442931747721278\n",
      "84 Train Loss 5.5793467 Test MSE 1.8889584400488502 Test RE 0.6569302518428357\n",
      "85 Train Loss 5.430979 Test MSE 1.898473454337998 Test RE 0.6585827098576\n",
      "86 Train Loss 5.348214 Test MSE 1.8761960674604474 Test RE 0.6547072813182503\n",
      "87 Train Loss 5.093315 Test MSE 1.9474110608266482 Test RE 0.6670169596255494\n",
      "88 Train Loss 4.9513664 Test MSE 1.9723167626739648 Test RE 0.6712686935962213\n",
      "89 Train Loss 4.775249 Test MSE 1.9744054106236006 Test RE 0.6716240302791101\n",
      "90 Train Loss 4.651741 Test MSE 2.007590295935885 Test RE 0.6772446830966543\n",
      "91 Train Loss 4.5383253 Test MSE 1.973266615710524 Test RE 0.6714303131369711\n",
      "92 Train Loss 4.43206 Test MSE 1.978774111554185 Test RE 0.6723666597420425\n",
      "93 Train Loss 4.3496265 Test MSE 1.980559292380519 Test RE 0.6726698842152127\n",
      "94 Train Loss 4.2853756 Test MSE 1.9413523404357236 Test RE 0.6659785508631604\n",
      "95 Train Loss 4.2023306 Test MSE 1.9335248922569046 Test RE 0.6646345965315726\n",
      "96 Train Loss 4.156901 Test MSE 1.9277802170505893 Test RE 0.6636465176838472\n",
      "97 Train Loss 4.1274796 Test MSE 1.9244466159402402 Test RE 0.6630724662458471\n",
      "98 Train Loss 4.0886946 Test MSE 1.9259505925506388 Test RE 0.6633315149272813\n",
      "99 Train Loss 4.055418 Test MSE 1.9144929210698014 Test RE 0.6613554590521074\n",
      "Training time: 80.99\n",
      "KG_stan_tune9\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 43.557358 Test MSE 9.480855713432083 Test RE 1.4717424917415074\n",
      "1 Train Loss 40.80346 Test MSE 9.37951335873101 Test RE 1.4638555155960906\n",
      "2 Train Loss 40.016632 Test MSE 9.35623222797884 Test RE 1.4620376501863857\n",
      "3 Train Loss 39.83538 Test MSE 9.240173054716886 Test RE 1.4529414470957225\n",
      "4 Train Loss 39.56472 Test MSE 9.083222614113536 Test RE 1.4405490133725523\n",
      "5 Train Loss 39.22501 Test MSE 9.124305240800908 Test RE 1.4438030770744477\n",
      "6 Train Loss 38.444134 Test MSE 8.912122401376985 Test RE 1.426916735465774\n",
      "7 Train Loss 37.314323 Test MSE 9.022426499810857 Test RE 1.4357199550829192\n",
      "8 Train Loss 35.98747 Test MSE 9.118568549204653 Test RE 1.4433491271544068\n",
      "9 Train Loss 35.144093 Test MSE 9.015071944876645 Test RE 1.4351346782760646\n",
      "10 Train Loss 34.87191 Test MSE 9.026829515379141 Test RE 1.4360702337062476\n",
      "11 Train Loss 34.69049 Test MSE 9.038166890361293 Test RE 1.436971777141192\n",
      "12 Train Loss 34.561226 Test MSE 9.04450318456016 Test RE 1.4374753903630237\n",
      "13 Train Loss 34.203133 Test MSE 8.995770398592013 Test RE 1.4335975213188659\n",
      "14 Train Loss 34.00532 Test MSE 9.004964963442902 Test RE 1.4343299732583603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Train Loss 33.853985 Test MSE 9.004208795359348 Test RE 1.434269749963688\n",
      "16 Train Loss 33.66024 Test MSE 9.207938246402591 Test RE 1.4504049033004685\n",
      "17 Train Loss 33.36435 Test MSE 9.187704699498036 Test RE 1.4488104652028249\n",
      "18 Train Loss 31.598179 Test MSE 8.592720595470015 Test RE 1.4011137833748062\n",
      "19 Train Loss 29.593143 Test MSE 8.82872346326721 Test RE 1.420224555341691\n",
      "20 Train Loss 28.604324 Test MSE 9.276187277198424 Test RE 1.4557701640869216\n",
      "21 Train Loss 28.296425 Test MSE 9.179527164564092 Test RE 1.4481655633464754\n",
      "22 Train Loss 27.89137 Test MSE 8.904214581763798 Test RE 1.426283535886121\n",
      "23 Train Loss 27.196363 Test MSE 8.628997119866414 Test RE 1.4040682612452031\n",
      "24 Train Loss 26.598408 Test MSE 8.776567336917235 Test RE 1.4160233175242802\n",
      "25 Train Loss 25.808208 Test MSE 8.505548848582908 Test RE 1.3939886311974121\n",
      "26 Train Loss 24.529552 Test MSE 8.173441286629 Test RE 1.3665028251471916\n",
      "27 Train Loss 23.06303 Test MSE 7.6718884201497595 Test RE 1.3239122455414891\n",
      "28 Train Loss 20.665527 Test MSE 6.657567964015837 Test RE 1.2332918586717234\n",
      "29 Train Loss 19.74675 Test MSE 6.751111359699149 Test RE 1.2419259340001427\n",
      "30 Train Loss 18.559198 Test MSE 6.96999205207202 Test RE 1.261897853790806\n",
      "31 Train Loss 17.886314 Test MSE 6.839911616286846 Test RE 1.2500670422098081\n",
      "32 Train Loss 17.325413 Test MSE 6.724185023368437 Test RE 1.2394467921178363\n",
      "33 Train Loss 16.875319 Test MSE 6.65601783972319 Test RE 1.2331482726824454\n",
      "34 Train Loss 16.067791 Test MSE 6.460903782421029 Test RE 1.2149396258145146\n",
      "35 Train Loss 14.831997 Test MSE 6.042064027119057 Test RE 1.1748995077552815\n",
      "36 Train Loss 13.0138855 Test MSE 5.744325555631775 Test RE 1.1455856975802852\n",
      "37 Train Loss 11.356286 Test MSE 5.6575687159896635 Test RE 1.136901865357218\n",
      "38 Train Loss 10.560842 Test MSE 5.587165384250319 Test RE 1.129805862080169\n",
      "39 Train Loss 10.23639 Test MSE 5.50031507912124 Test RE 1.1209902736087045\n",
      "40 Train Loss 9.868383 Test MSE 5.371688893872843 Test RE 1.1078054218908\n",
      "41 Train Loss 9.559606 Test MSE 5.3807594848655045 Test RE 1.108740343078947\n",
      "42 Train Loss 9.422899 Test MSE 5.361994658267893 Test RE 1.106805347552573\n",
      "43 Train Loss 9.30844 Test MSE 5.3721039599353215 Test RE 1.1078482206791842\n",
      "44 Train Loss 9.181377 Test MSE 5.354782061852528 Test RE 1.1060606968090043\n",
      "45 Train Loss 9.017915 Test MSE 5.323950372392251 Test RE 1.1028718696107964\n",
      "46 Train Loss 8.952469 Test MSE 5.346473740193937 Test RE 1.1052022981620442\n",
      "47 Train Loss 8.881483 Test MSE 5.3620437524454525 Test RE 1.106810414470515\n",
      "48 Train Loss 8.833328 Test MSE 5.366201035493898 Test RE 1.107239395737809\n",
      "49 Train Loss 8.707162 Test MSE 5.354263442597656 Test RE 1.1060071336333623\n",
      "50 Train Loss 8.642203 Test MSE 5.29531464022219 Test RE 1.09990188280851\n",
      "51 Train Loss 8.554367 Test MSE 5.278137710042831 Test RE 1.0981165041060608\n",
      "52 Train Loss 8.433764 Test MSE 5.221665530815455 Test RE 1.092226188031458\n",
      "53 Train Loss 8.274557 Test MSE 5.101581265943179 Test RE 1.0795940065246572\n",
      "54 Train Loss 8.114048 Test MSE 5.062175557860502 Test RE 1.0754164158847859\n",
      "55 Train Loss 7.8341904 Test MSE 4.997587224372691 Test RE 1.068533768670047\n",
      "56 Train Loss 7.0371776 Test MSE 4.360617202937799 Test RE 0.9981183550083923\n",
      "57 Train Loss 5.6202493 Test MSE 4.452168990777 Test RE 1.0085417485265558\n",
      "58 Train Loss 5.2377634 Test MSE 4.295450794465267 Test RE 0.9906321865448252\n",
      "59 Train Loss 4.8486547 Test MSE 4.369970521383559 Test RE 0.9991882400245802\n",
      "60 Train Loss 4.6623416 Test MSE 4.4885060504693906 Test RE 1.0126490689658507\n",
      "61 Train Loss 4.528069 Test MSE 4.4743626940352765 Test RE 1.0110523732288754\n",
      "62 Train Loss 4.326248 Test MSE 4.549323333833966 Test RE 1.0194864607893797\n",
      "63 Train Loss 4.203703 Test MSE 4.5944181007950595 Test RE 1.0245267860309133\n",
      "64 Train Loss 4.1293116 Test MSE 4.552437834237319 Test RE 1.0198353750681106\n",
      "65 Train Loss 4.069644 Test MSE 4.5569471202811815 Test RE 1.0203403343196338\n",
      "66 Train Loss 3.9880612 Test MSE 4.575967537489004 Test RE 1.0224675358513375\n",
      "67 Train Loss 3.9512246 Test MSE 4.588191571930046 Test RE 1.0238323119668817\n",
      "68 Train Loss 3.8956976 Test MSE 4.623946042931857 Test RE 1.0278137872925603\n",
      "69 Train Loss 3.8476362 Test MSE 4.607984926921854 Test RE 1.026038330103957\n",
      "70 Train Loss 3.8232596 Test MSE 4.567404137566177 Test RE 1.0215103723059102\n",
      "71 Train Loss 3.776425 Test MSE 4.560460955941638 Test RE 1.0207336477893352\n",
      "72 Train Loss 3.7489548 Test MSE 4.596671253486017 Test RE 1.0247779747870998\n",
      "73 Train Loss 3.7139487 Test MSE 4.5948551507549045 Test RE 1.024575514589429\n",
      "74 Train Loss 3.67702 Test MSE 4.580755901592372 Test RE 1.0230023589981636\n",
      "75 Train Loss 3.6601298 Test MSE 4.598312585072294 Test RE 1.0249609169908365\n",
      "76 Train Loss 3.6406708 Test MSE 4.579880410865139 Test RE 1.0229045943610011\n",
      "77 Train Loss 3.6189954 Test MSE 4.599751192947681 Test RE 1.0251212368375398\n",
      "78 Train Loss 3.6062465 Test MSE 4.6145347516218065 Test RE 1.0267672804915162\n",
      "79 Train Loss 3.5883079 Test MSE 4.614147998044103 Test RE 1.026724251859001\n",
      "80 Train Loss 3.5717015 Test MSE 4.622260932270337 Test RE 1.0276264864697753\n",
      "81 Train Loss 3.5582795 Test MSE 4.614431289496862 Test RE 1.0267557698923069\n",
      "82 Train Loss 3.5423393 Test MSE 4.596038613705618 Test RE 1.0247074522735662\n",
      "83 Train Loss 3.5288663 Test MSE 4.611334109154294 Test RE 1.026411135702925\n",
      "84 Train Loss 3.520453 Test MSE 4.615612974910592 Test RE 1.0268872297162297\n",
      "85 Train Loss 3.5123887 Test MSE 4.625629621952281 Test RE 1.0280008837932098\n",
      "86 Train Loss 3.503971 Test MSE 4.642420367003598 Test RE 1.0298649830111126\n",
      "87 Train Loss 3.495441 Test MSE 4.654431475046559 Test RE 1.0311963821498165\n",
      "88 Train Loss 3.4854808 Test MSE 4.660180574926684 Test RE 1.0318330465276262\n",
      "89 Train Loss 3.4755626 Test MSE 4.669196059089894 Test RE 1.0328306451824343\n",
      "90 Train Loss 3.4686065 Test MSE 4.691128706847047 Test RE 1.0352535645734675\n",
      "91 Train Loss 3.460682 Test MSE 4.683892264997544 Test RE 1.034454775625413\n",
      "92 Train Loss 3.452053 Test MSE 4.689383904536528 Test RE 1.0350610223396024\n",
      "93 Train Loss 3.4429538 Test MSE 4.689977968204921 Test RE 1.0351265824097151\n",
      "94 Train Loss 3.4379058 Test MSE 4.68852239050304 Test RE 1.0349659394274406\n",
      "95 Train Loss 3.4287958 Test MSE 4.698063801139896 Test RE 1.0360185115644438\n",
      "96 Train Loss 3.421252 Test MSE 4.7029168013355624 Test RE 1.0365534660180342\n",
      "97 Train Loss 3.4159892 Test MSE 4.7059727796048545 Test RE 1.0368901900739511\n",
      "98 Train Loss 3.4110203 Test MSE 4.714658237171252 Test RE 1.0378466038312746\n",
      "99 Train Loss 3.4028242 Test MSE 4.707611265376172 Test RE 1.0370706821898645\n",
      "Training time: 80.10\n",
      "KG_stan_tune9\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.74466 Test MSE 8.27079297013641 Test RE 1.3746167616335465\n",
      "1 Train Loss 55.856075 Test MSE 8.796960161876108 Test RE 1.4176674660765678\n",
      "2 Train Loss 50.85067 Test MSE 6.925777801812041 Test RE 1.2578890521188855\n",
      "3 Train Loss 47.54379 Test MSE 8.621139400073359 Test RE 1.4034288307517808\n",
      "4 Train Loss 46.06918 Test MSE 8.632990880084941 Test RE 1.4043931462351187\n",
      "5 Train Loss 44.937374 Test MSE 8.789139905305609 Test RE 1.4170371922028686\n",
      "6 Train Loss 44.195484 Test MSE 8.614189654079931 Test RE 1.4028630447302466\n",
      "7 Train Loss 43.58526 Test MSE 8.390467337750472 Test RE 1.3845260639841648\n",
      "8 Train Loss 43.522705 Test MSE 8.452100127460117 Test RE 1.3896018285243648\n",
      "9 Train Loss 43.256084 Test MSE 8.512141732990719 Test RE 1.3945287859734756\n",
      "10 Train Loss 43.109077 Test MSE 8.41657620088559 Test RE 1.3866785259815144\n",
      "11 Train Loss 42.85885 Test MSE 8.3675638117653 Test RE 1.3826350967046632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 41.858673 Test MSE 8.40217609283423 Test RE 1.385491768533739\n",
      "13 Train Loss 39.431435 Test MSE 7.892035717917829 Test RE 1.3427729422304555\n",
      "14 Train Loss 38.083477 Test MSE 7.891222536792088 Test RE 1.3427037619973339\n",
      "15 Train Loss 37.437843 Test MSE 7.809403137312899 Test RE 1.3357247757165152\n",
      "16 Train Loss 36.259647 Test MSE 7.6129061928031945 Test RE 1.3188132429116122\n",
      "17 Train Loss 34.844776 Test MSE 7.369000166776506 Test RE 1.2975148691973508\n",
      "18 Train Loss 34.316776 Test MSE 7.2848656076390705 Test RE 1.2900865052970965\n",
      "19 Train Loss 33.51749 Test MSE 7.296724645392625 Test RE 1.2911361446500975\n",
      "20 Train Loss 33.152084 Test MSE 7.238992943453087 Test RE 1.2860182653266048\n",
      "21 Train Loss 32.91569 Test MSE 7.1492880317142875 Test RE 1.2780253181882197\n",
      "22 Train Loss 32.578793 Test MSE 7.150853618299461 Test RE 1.2781652446925975\n",
      "23 Train Loss 32.38965 Test MSE 7.128855021091733 Test RE 1.2761976823314432\n",
      "24 Train Loss 32.314583 Test MSE 7.132217162414772 Test RE 1.2764985897818248\n",
      "25 Train Loss 32.054802 Test MSE 7.10624805614847 Test RE 1.2741725418638383\n",
      "26 Train Loss 31.752243 Test MSE 7.033557933243892 Test RE 1.2676390075698771\n",
      "27 Train Loss 31.450493 Test MSE 7.008799363246147 Test RE 1.2654059558660244\n",
      "28 Train Loss 31.217806 Test MSE 7.06723750463834 Test RE 1.270670371802729\n",
      "29 Train Loss 30.336416 Test MSE 6.991981550086667 Test RE 1.263886855269751\n",
      "30 Train Loss 29.847492 Test MSE 6.940667187141876 Test RE 1.2592404627401634\n",
      "31 Train Loss 29.68732 Test MSE 6.92407977299882 Test RE 1.2577348410792826\n",
      "32 Train Loss 29.341448 Test MSE 6.848288927602125 Test RE 1.2508323296009622\n",
      "33 Train Loss 28.953613 Test MSE 6.919907893673833 Test RE 1.2573558803538016\n",
      "34 Train Loss 28.47377 Test MSE 6.843648332565441 Test RE 1.250408458029781\n",
      "35 Train Loss 28.046017 Test MSE 6.79034588620717 Test RE 1.2455294730488855\n",
      "36 Train Loss 27.891743 Test MSE 6.820370669856071 Test RE 1.2482801064880258\n",
      "37 Train Loss 27.342175 Test MSE 6.665954934975102 Test RE 1.2340684431157927\n",
      "38 Train Loss 26.856625 Test MSE 6.597247574105383 Test RE 1.2276920719968085\n",
      "39 Train Loss 26.24095 Test MSE 6.640430829243308 Test RE 1.2317035378830126\n",
      "40 Train Loss 24.851738 Test MSE 6.355210578139325 Test RE 1.2049611173016583\n",
      "41 Train Loss 24.475624 Test MSE 6.173598953641593 Test RE 1.1876193557749228\n",
      "42 Train Loss 24.004534 Test MSE 6.092541949243865 Test RE 1.1797971000804488\n",
      "43 Train Loss 23.595732 Test MSE 6.008990882800446 Test RE 1.1716795036554677\n",
      "44 Train Loss 23.321716 Test MSE 6.090751502332135 Test RE 1.1796237307948896\n",
      "45 Train Loss 23.112988 Test MSE 6.129128545356795 Test RE 1.1833342239562232\n",
      "46 Train Loss 22.738579 Test MSE 6.118053360689716 Test RE 1.182264612615406\n",
      "47 Train Loss 22.123573 Test MSE 6.100439546099104 Test RE 1.1805615219239767\n",
      "48 Train Loss 21.332054 Test MSE 5.841243392666463 Test RE 1.1552093934895453\n",
      "49 Train Loss 20.983128 Test MSE 5.584252055132223 Test RE 1.1295112649746144\n",
      "50 Train Loss 20.795227 Test MSE 5.4685230535638505 Test RE 1.1177458959391722\n",
      "51 Train Loss 20.610512 Test MSE 5.514246725856324 Test RE 1.1224090435891445\n",
      "52 Train Loss 20.534063 Test MSE 5.593466225803716 Test RE 1.1304427433388249\n",
      "53 Train Loss 19.922932 Test MSE 5.532384430340883 Test RE 1.1242534669060746\n",
      "54 Train Loss 19.31438 Test MSE 5.504931632666616 Test RE 1.1214606126804207\n",
      "55 Train Loss 19.107075 Test MSE 5.490168477288728 Test RE 1.119955833558551\n",
      "56 Train Loss 18.682072 Test MSE 5.467976596681583 Test RE 1.1176900476606517\n",
      "57 Train Loss 18.091667 Test MSE 5.125530034169748 Test RE 1.0821250525928026\n",
      "58 Train Loss 17.62359 Test MSE 5.104981715970833 Test RE 1.0799537473324157\n",
      "59 Train Loss 17.270912 Test MSE 5.157351341465562 Test RE 1.0854789840816883\n",
      "60 Train Loss 17.12577 Test MSE 5.128308388993112 Test RE 1.0824183022683167\n",
      "61 Train Loss 16.848927 Test MSE 5.230320487022782 Test RE 1.093131000474469\n",
      "62 Train Loss 16.178381 Test MSE 5.417026277223128 Test RE 1.112470571849905\n",
      "63 Train Loss 15.580576 Test MSE 5.319140524766333 Test RE 1.1023735700478887\n",
      "64 Train Loss 15.101284 Test MSE 4.838511208108086 Test RE 1.051390227442558\n",
      "65 Train Loss 14.43022 Test MSE 4.713067771389029 Test RE 1.0376715329500552\n",
      "66 Train Loss 14.066116 Test MSE 4.819845772841018 Test RE 1.0493603035260275\n",
      "67 Train Loss 13.730919 Test MSE 4.852404970740039 Test RE 1.0528986764386936\n",
      "68 Train Loss 13.274461 Test MSE 4.45930523134713 Test RE 1.00934970469656\n",
      "69 Train Loss 12.866883 Test MSE 4.3984747317496975 Test RE 1.00244166917266\n",
      "70 Train Loss 12.247805 Test MSE 4.12751630070834 Test RE 0.9710742963882357\n",
      "71 Train Loss 11.691256 Test MSE 3.9004335709474613 Test RE 0.9439837170842819\n",
      "72 Train Loss 11.291654 Test MSE 3.7904761179965294 Test RE 0.9305826316673602\n",
      "73 Train Loss 10.576278 Test MSE 3.6671531616618345 Test RE 0.9153192262144252\n",
      "74 Train Loss 9.814202 Test MSE 3.3439676722308267 Test RE 0.8740556719747571\n",
      "75 Train Loss 9.483032 Test MSE 3.118500450967565 Test RE 0.8440748609287599\n",
      "76 Train Loss 9.097107 Test MSE 3.0740517206157607 Test RE 0.8380378719575521\n",
      "77 Train Loss 8.622135 Test MSE 2.8186670292938043 Test RE 0.8024721111378801\n",
      "78 Train Loss 8.200865 Test MSE 2.6043046731212276 Test RE 0.7713543897072315\n",
      "79 Train Loss 8.054328 Test MSE 2.517463904839376 Test RE 0.758384916037482\n",
      "80 Train Loss 7.810277 Test MSE 2.4722478430618344 Test RE 0.7515433972285985\n",
      "81 Train Loss 7.7301126 Test MSE 2.425826258217267 Test RE 0.7444540666761377\n",
      "82 Train Loss 7.620103 Test MSE 2.4417235528637207 Test RE 0.7468894182329714\n",
      "83 Train Loss 7.4926696 Test MSE 2.4039997699920255 Test RE 0.7410973684984771\n",
      "84 Train Loss 7.315443 Test MSE 2.2782653247456635 Test RE 0.7214565993944854\n",
      "85 Train Loss 7.196265 Test MSE 2.2600189033548816 Test RE 0.7185617511986384\n",
      "86 Train Loss 7.145862 Test MSE 2.229256279414926 Test RE 0.7136545837894738\n",
      "87 Train Loss 7.0320044 Test MSE 2.1780970593391746 Test RE 0.705418223089985\n",
      "88 Train Loss 6.8065863 Test MSE 2.1100448319866016 Test RE 0.6943107695191391\n",
      "89 Train Loss 6.666389 Test MSE 2.1063419704547837 Test RE 0.6937012882634738\n",
      "90 Train Loss 6.5429044 Test MSE 2.0995898860395696 Test RE 0.6925885322509705\n",
      "91 Train Loss 6.442724 Test MSE 2.0755975804247226 Test RE 0.6886200097242199\n",
      "92 Train Loss 6.276128 Test MSE 2.0747125101636152 Test RE 0.6884731744021239\n",
      "93 Train Loss 6.1986656 Test MSE 2.072258287290677 Test RE 0.6880658489087321\n",
      "94 Train Loss 6.141886 Test MSE 2.0785946857130915 Test RE 0.6891170044663988\n",
      "95 Train Loss 6.102264 Test MSE 2.0907055176369607 Test RE 0.6911216422606101\n",
      "96 Train Loss 6.070801 Test MSE 2.089379110535335 Test RE 0.6909023731933638\n",
      "97 Train Loss 6.0326657 Test MSE 2.0250100389548518 Test RE 0.6801765430969948\n",
      "98 Train Loss 5.9846954 Test MSE 2.0243591326975285 Test RE 0.6800672185152999\n",
      "99 Train Loss 5.9218783 Test MSE 2.039763901662951 Test RE 0.6826498688337065\n",
      "Training time: 80.98\n",
      "KG_stan_tune10\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 54.949646 Test MSE 8.625120380226853 Test RE 1.4037528237434516\n",
      "1 Train Loss 44.47586 Test MSE 9.536739497764211 Test RE 1.4760736249344144\n",
      "2 Train Loss 43.354702 Test MSE 9.464128634824228 Test RE 1.4704436205715357\n",
      "3 Train Loss 43.1238 Test MSE 9.360399069834926 Test RE 1.4623631766052736\n",
      "4 Train Loss 42.74859 Test MSE 9.332867666417615 Test RE 1.4602109949319888\n",
      "5 Train Loss 42.39148 Test MSE 9.441999147014279 Test RE 1.468723482909919\n",
      "6 Train Loss 42.09674 Test MSE 9.424299721482843 Test RE 1.4673462451352184\n",
      "7 Train Loss 41.453552 Test MSE 9.631997929297704 Test RE 1.483427243096167\n",
      "8 Train Loss 40.87362 Test MSE 9.647438810828184 Test RE 1.4846157946314065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Train Loss 40.621216 Test MSE 9.429010748635262 Test RE 1.4677129484734148\n",
      "10 Train Loss 39.83573 Test MSE 9.433788181140782 Test RE 1.468084727219576\n",
      "11 Train Loss 38.683884 Test MSE 9.055330674284667 Test RE 1.4383355589295312\n",
      "12 Train Loss 36.503784 Test MSE 8.958416649483617 Test RE 1.4306180128636639\n",
      "13 Train Loss 34.010773 Test MSE 8.812002561313184 Test RE 1.4188790216277047\n",
      "14 Train Loss 32.4367 Test MSE 8.76420879509715 Test RE 1.4150259943330485\n",
      "15 Train Loss 30.468533 Test MSE 7.689118301886941 Test RE 1.3253980634469344\n",
      "16 Train Loss 26.811506 Test MSE 6.908982501510408 Test RE 1.256362909585025\n",
      "17 Train Loss 25.512758 Test MSE 7.038875836344997 Test RE 1.2681181326260584\n",
      "18 Train Loss 24.596657 Test MSE 6.830109006008809 Test RE 1.249170955074836\n",
      "19 Train Loss 24.097637 Test MSE 6.773472722513471 Test RE 1.2439810177248078\n",
      "20 Train Loss 23.064869 Test MSE 6.228836066234898 Test RE 1.1929205245077605\n",
      "21 Train Loss 21.710457 Test MSE 5.7690233996121085 Test RE 1.1480457905571948\n",
      "22 Train Loss 21.225208 Test MSE 5.805861638635352 Test RE 1.1517053948691127\n",
      "23 Train Loss 20.826355 Test MSE 5.77118337463739 Test RE 1.1482606898561651\n",
      "24 Train Loss 19.822319 Test MSE 4.7584924054198 Test RE 1.0426600904991958\n",
      "25 Train Loss 17.008713 Test MSE 3.808572003087678 Test RE 0.9328013062228777\n",
      "26 Train Loss 14.86665 Test MSE 3.2726548485873646 Test RE 0.8646854728067378\n",
      "27 Train Loss 13.366304 Test MSE 2.880600811130251 Test RE 0.8112404543314868\n",
      "28 Train Loss 12.610647 Test MSE 3.082579693879539 Test RE 0.8391995008882643\n",
      "29 Train Loss 11.790351 Test MSE 3.371745148832059 Test RE 0.8776784416468287\n",
      "30 Train Loss 10.800431 Test MSE 3.4328195916442947 Test RE 0.8855917260448658\n",
      "31 Train Loss 9.889912 Test MSE 3.444204172523591 Test RE 0.8870589959012276\n",
      "32 Train Loss 9.373052 Test MSE 3.4765733147193107 Test RE 0.8912176040220186\n",
      "33 Train Loss 9.116715 Test MSE 3.494331788454233 Test RE 0.893490892060292\n",
      "34 Train Loss 8.790532 Test MSE 3.4057377160498263 Test RE 0.8820915458167093\n",
      "35 Train Loss 8.6331005 Test MSE 3.368902615859645 Test RE 0.8773084024186764\n",
      "36 Train Loss 8.409452 Test MSE 3.3926784126633347 Test RE 0.8803987311933856\n",
      "37 Train Loss 8.107066 Test MSE 3.358061544604686 Test RE 0.8758956832258425\n",
      "38 Train Loss 7.79642 Test MSE 3.3894005724674248 Test RE 0.8799733292886588\n",
      "39 Train Loss 7.5271187 Test MSE 3.4345387140649217 Test RE 0.8858134461197208\n",
      "40 Train Loss 7.3048196 Test MSE 3.3919462437686843 Test RE 0.880303727295464\n",
      "41 Train Loss 7.0202985 Test MSE 3.3535013447305855 Test RE 0.8753007542333723\n",
      "42 Train Loss 6.5760813 Test MSE 3.2806617827460665 Test RE 0.8657426038463731\n",
      "43 Train Loss 6.143778 Test MSE 3.2236533748699796 Test RE 0.8581875883927487\n",
      "44 Train Loss 5.5199604 Test MSE 3.179768703898843 Test RE 0.8523261744342094\n",
      "45 Train Loss 5.073044 Test MSE 3.1727525941734127 Test RE 0.8513853329981054\n",
      "46 Train Loss 4.4227934 Test MSE 3.02029833873612 Test RE 0.8306785232663524\n",
      "47 Train Loss 3.866599 Test MSE 3.0004082578009728 Test RE 0.8279388014154381\n",
      "48 Train Loss 3.0486383 Test MSE 2.9711937747509074 Test RE 0.8238981895107913\n",
      "49 Train Loss 2.367482 Test MSE 2.660033145343354 Test RE 0.779563657220829\n",
      "50 Train Loss 1.8049748 Test MSE 2.5958453263976784 Test RE 0.7701006075174596\n",
      "51 Train Loss 1.5368462 Test MSE 2.637341131052038 Test RE 0.7762314133497472\n",
      "52 Train Loss 1.3760071 Test MSE 2.551310937615146 Test RE 0.7634660960965373\n",
      "53 Train Loss 1.2607408 Test MSE 2.5554896834778065 Test RE 0.7640910739198662\n",
      "54 Train Loss 1.1646676 Test MSE 2.6196241695426603 Test RE 0.7736197609988621\n",
      "55 Train Loss 1.100593 Test MSE 2.6108541926942155 Test RE 0.7723237133843441\n",
      "56 Train Loss 1.0458188 Test MSE 2.5806275193318493 Test RE 0.7678399819492384\n",
      "57 Train Loss 0.9953363 Test MSE 2.5626651817550865 Test RE 0.7651630584605208\n",
      "58 Train Loss 0.9558579 Test MSE 2.5597736686321717 Test RE 0.7647312612264648\n",
      "59 Train Loss 0.923045 Test MSE 2.584827668098438 Test RE 0.7684645840956731\n",
      "60 Train Loss 0.8975252 Test MSE 2.626119045565377 Test RE 0.7745781912154694\n",
      "61 Train Loss 0.8737277 Test MSE 2.6383198629813642 Test RE 0.7763754318820139\n",
      "62 Train Loss 0.84694135 Test MSE 2.657617202996903 Test RE 0.7792095622562217\n",
      "63 Train Loss 0.81672364 Test MSE 2.6898924206232495 Test RE 0.7839268072466815\n",
      "64 Train Loss 0.79563886 Test MSE 2.7027818142666127 Test RE 0.785802768080388\n",
      "65 Train Loss 0.77299726 Test MSE 2.7845789381037447 Test RE 0.7976049254980653\n",
      "66 Train Loss 0.74968755 Test MSE 2.8266692558463773 Test RE 0.803610417348696\n",
      "67 Train Loss 0.73136115 Test MSE 2.819710419576303 Test RE 0.8026206235593536\n",
      "68 Train Loss 0.714787 Test MSE 2.8915355389406523 Test RE 0.8127787256531824\n",
      "69 Train Loss 0.6967027 Test MSE 2.9356252467992405 Test RE 0.8189518480893662\n",
      "70 Train Loss 0.68077505 Test MSE 2.9527207152020503 Test RE 0.8213329493525827\n",
      "71 Train Loss 0.6682532 Test MSE 3.009923578618132 Test RE 0.8292506007574963\n",
      "72 Train Loss 0.6544281 Test MSE 3.013835809438922 Test RE 0.8297893463713556\n",
      "73 Train Loss 0.63664687 Test MSE 3.0274887726718416 Test RE 0.8316667349677237\n",
      "74 Train Loss 0.6211931 Test MSE 3.023401547026789 Test RE 0.831105154413104\n",
      "75 Train Loss 0.6070428 Test MSE 3.0180269084952434 Test RE 0.8303661065793848\n",
      "76 Train Loss 0.5901785 Test MSE 3.0677691804904486 Test RE 0.8371810712504035\n",
      "77 Train Loss 0.5740906 Test MSE 3.068698527593159 Test RE 0.83730786907027\n",
      "78 Train Loss 0.5633687 Test MSE 3.0805686915053667 Test RE 0.8389257192363692\n",
      "79 Train Loss 0.55120397 Test MSE 3.125409601229437 Test RE 0.8450093827523714\n",
      "80 Train Loss 0.5400839 Test MSE 3.1299768775088115 Test RE 0.8456265790343804\n",
      "81 Train Loss 0.53194493 Test MSE 3.1306369082607257 Test RE 0.8457157346651508\n",
      "82 Train Loss 0.52419955 Test MSE 3.1447330779629157 Test RE 0.8476175782140523\n",
      "83 Train Loss 0.5179791 Test MSE 3.1392619268481905 Test RE 0.8468799221817049\n",
      "84 Train Loss 0.51105845 Test MSE 3.1480906046483113 Test RE 0.8480699440197962\n",
      "85 Train Loss 0.5066219 Test MSE 3.1620523822438362 Test RE 0.8499484580524737\n",
      "86 Train Loss 0.49987143 Test MSE 3.1554688117185012 Test RE 0.8490631768151834\n",
      "87 Train Loss 0.49392274 Test MSE 3.166559301983053 Test RE 0.8505539643853307\n",
      "88 Train Loss 0.48873115 Test MSE 3.1893866503198014 Test RE 0.8536142300592535\n",
      "89 Train Loss 0.48344707 Test MSE 3.209278175341311 Test RE 0.8562719975608669\n",
      "90 Train Loss 0.4779987 Test MSE 3.2355315588369455 Test RE 0.8597672149759081\n",
      "91 Train Loss 0.4732274 Test MSE 3.23284481739166 Test RE 0.8594101713326384\n",
      "92 Train Loss 0.4687995 Test MSE 3.239394182763408 Test RE 0.860280263109566\n",
      "93 Train Loss 0.46460703 Test MSE 3.2597030463898355 Test RE 0.8629727444285978\n",
      "94 Train Loss 0.4599768 Test MSE 3.271251884833326 Test RE 0.8645001106962767\n",
      "95 Train Loss 0.45440587 Test MSE 3.2778545767514125 Test RE 0.8653721240306853\n",
      "96 Train Loss 0.4487739 Test MSE 3.2909453752615425 Test RE 0.8670984245391429\n",
      "97 Train Loss 0.44483975 Test MSE 3.3219193327818894 Test RE 0.8711693779577148\n",
      "98 Train Loss 0.43967637 Test MSE 3.345879742344383 Test RE 0.8743055273943298\n",
      "99 Train Loss 0.43532696 Test MSE 3.3390664187381742 Test RE 0.8734148853793563\n",
      "Training time: 80.61\n",
      "KG_stan_tune10\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.734993 Test MSE 8.561651762076076 Test RE 1.398578475120702\n",
      "1 Train Loss 56.989933 Test MSE 8.627164972479191 Test RE 1.4039191942954676\n",
      "2 Train Loss 54.266266 Test MSE 8.931691929198683 Test RE 1.4284825114476292\n",
      "3 Train Loss 48.862137 Test MSE 8.912671379375984 Test RE 1.4269606831247013\n",
      "4 Train Loss 45.835644 Test MSE 8.701957316565528 Test RE 1.4099916301408688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Train Loss 45.143982 Test MSE 8.674417713009005 Test RE 1.4077587197623902\n",
      "6 Train Loss 44.850136 Test MSE 8.694676795958607 Test RE 1.4094016696983915\n",
      "7 Train Loss 44.670456 Test MSE 8.609485712182732 Test RE 1.4024799624184634\n",
      "8 Train Loss 44.40432 Test MSE 8.534861072324093 Test RE 1.3963885799668487\n",
      "9 Train Loss 44.10784 Test MSE 8.491648116146273 Test RE 1.3928490582541992\n",
      "10 Train Loss 43.940697 Test MSE 8.523946363297723 Test RE 1.3954954165762843\n",
      "11 Train Loss 43.605774 Test MSE 8.49495188272073 Test RE 1.3931199833211545\n",
      "12 Train Loss 43.21991 Test MSE 8.41485401974941 Test RE 1.386536649182837\n",
      "13 Train Loss 41.64778 Test MSE 8.532488080894794 Test RE 1.3961944439134455\n",
      "14 Train Loss 40.34925 Test MSE 7.915255491047292 Test RE 1.344746829856954\n",
      "15 Train Loss 39.83636 Test MSE 7.9656403881942195 Test RE 1.3490200619959063\n",
      "16 Train Loss 39.53737 Test MSE 7.914381099551959 Test RE 1.3446725512902105\n",
      "17 Train Loss 39.195637 Test MSE 7.773999235501544 Test RE 1.3326935845406835\n",
      "18 Train Loss 38.852676 Test MSE 7.72245146710944 Test RE 1.328267829097533\n",
      "19 Train Loss 38.69673 Test MSE 7.666786653754804 Test RE 1.3234719749131942\n",
      "20 Train Loss 38.472046 Test MSE 7.574062504797904 Test RE 1.3154444188847383\n",
      "21 Train Loss 38.310802 Test MSE 7.611692986684042 Test RE 1.318708154525832\n",
      "22 Train Loss 38.096497 Test MSE 7.61955428275608 Test RE 1.3193889544450603\n",
      "23 Train Loss 37.88654 Test MSE 7.636515552157972 Test RE 1.320856630293838\n",
      "24 Train Loss 37.584618 Test MSE 7.741647476764298 Test RE 1.329917668972692\n",
      "25 Train Loss 37.331615 Test MSE 7.717995092773309 Test RE 1.3278845238162067\n",
      "26 Train Loss 36.920456 Test MSE 7.730080610283962 Test RE 1.3289237764961548\n",
      "27 Train Loss 36.605324 Test MSE 8.048078152397828 Test RE 1.3559827127312907\n",
      "28 Train Loss 36.384563 Test MSE 8.150405772574029 Test RE 1.3645758335526346\n",
      "29 Train Loss 35.821144 Test MSE 8.192070441697881 Test RE 1.368059226127704\n",
      "30 Train Loss 35.357883 Test MSE 7.989387091941584 Test RE 1.3510293756648195\n",
      "31 Train Loss 34.9129 Test MSE 7.921614168025325 Test RE 1.3452868689053288\n",
      "32 Train Loss 34.451786 Test MSE 7.9802536685062115 Test RE 1.3502569101517827\n",
      "33 Train Loss 33.867477 Test MSE 7.974155000396804 Test RE 1.3497408649861504\n",
      "34 Train Loss 33.333805 Test MSE 7.829879356163244 Test RE 1.3374747614410558\n",
      "35 Train Loss 32.661133 Test MSE 8.07613852267198 Test RE 1.3583445355358723\n",
      "36 Train Loss 32.145355 Test MSE 8.176871577157227 Test RE 1.3667895470930236\n",
      "37 Train Loss 31.57029 Test MSE 8.005830220262064 Test RE 1.3524189522688992\n",
      "38 Train Loss 30.690819 Test MSE 7.709232477888765 Test RE 1.3271305038223442\n",
      "39 Train Loss 29.00946 Test MSE 7.806088152987487 Test RE 1.3354412472180595\n",
      "40 Train Loss 27.600098 Test MSE 7.57921556574429 Test RE 1.3158918282301193\n",
      "41 Train Loss 25.728165 Test MSE 7.107117029139056 Test RE 1.2742504442723221\n",
      "42 Train Loss 24.5498 Test MSE 6.823586020087445 Test RE 1.248574312257178\n",
      "43 Train Loss 24.024261 Test MSE 6.683957010648269 Test RE 1.2357336820007903\n",
      "44 Train Loss 23.634321 Test MSE 6.647983525583014 Test RE 1.232403796599058\n",
      "45 Train Loss 23.325756 Test MSE 6.616948481393851 Test RE 1.2295237917857893\n",
      "46 Train Loss 23.093174 Test MSE 6.708059691868776 Test RE 1.2379597355327978\n",
      "47 Train Loss 22.856344 Test MSE 6.813380118029234 Test RE 1.2476402289562007\n",
      "48 Train Loss 22.022585 Test MSE 6.432645576776057 Test RE 1.2122798094055727\n",
      "49 Train Loss 21.284817 Test MSE 6.075184922643572 Test RE 1.178115341021751\n",
      "50 Train Loss 20.658281 Test MSE 6.220430662233601 Test RE 1.1921153689526567\n",
      "51 Train Loss 19.716633 Test MSE 6.2620163250228025 Test RE 1.196093576412802\n",
      "52 Train Loss 19.004509 Test MSE 6.028332198306359 Test RE 1.1735636483574305\n",
      "53 Train Loss 17.988354 Test MSE 6.05314439029161 Test RE 1.1759763210900922\n",
      "54 Train Loss 16.826412 Test MSE 5.922334745256069 Test RE 1.1632003812563343\n",
      "55 Train Loss 16.211643 Test MSE 5.966029177539613 Test RE 1.1674834875383726\n",
      "56 Train Loss 15.486792 Test MSE 6.019771956514905 Test RE 1.172730121179307\n",
      "57 Train Loss 14.981647 Test MSE 6.082684570426317 Test RE 1.1788422921450212\n",
      "58 Train Loss 14.615425 Test MSE 6.025571984701347 Test RE 1.1732949457442754\n",
      "59 Train Loss 14.322203 Test MSE 5.960832531692221 Test RE 1.1669749147707085\n",
      "60 Train Loss 14.068118 Test MSE 6.013166024223048 Test RE 1.1720864836520368\n",
      "61 Train Loss 13.74835 Test MSE 5.940954998339688 Test RE 1.1650275396905223\n",
      "62 Train Loss 13.515213 Test MSE 5.907129634464812 Test RE 1.161706210608579\n",
      "63 Train Loss 13.29855 Test MSE 5.895807363681495 Test RE 1.1605923480515765\n",
      "64 Train Loss 13.106206 Test MSE 5.857106281577298 Test RE 1.156776913688294\n",
      "65 Train Loss 12.897535 Test MSE 5.888573110719107 Test RE 1.1598800965134384\n",
      "66 Train Loss 12.564461 Test MSE 5.951550485122257 Test RE 1.166065969961004\n",
      "67 Train Loss 12.194742 Test MSE 5.866894594354895 Test RE 1.1577431047547329\n",
      "68 Train Loss 11.478014 Test MSE 5.188855007406867 Test RE 1.088789259213783\n",
      "69 Train Loss 9.606268 Test MSE 4.715184717567035 Test RE 1.0379045497745418\n",
      "70 Train Loss 8.791186 Test MSE 4.546937517475199 Test RE 1.0192190994395096\n",
      "71 Train Loss 8.407948 Test MSE 4.55339139403015 Test RE 1.0199421775249242\n",
      "72 Train Loss 8.034583 Test MSE 4.62140137893225 Test RE 1.0275309335728262\n",
      "73 Train Loss 7.842676 Test MSE 4.616183875670421 Test RE 1.026950735102818\n",
      "74 Train Loss 7.642359 Test MSE 4.7857441916373435 Test RE 1.0456414742492786\n",
      "75 Train Loss 7.5153675 Test MSE 4.880655629165319 Test RE 1.0559592116492131\n",
      "76 Train Loss 7.410982 Test MSE 4.89474475194679 Test RE 1.0574822465377425\n",
      "77 Train Loss 7.274756 Test MSE 4.909850005653395 Test RE 1.0591126924311849\n",
      "78 Train Loss 7.154813 Test MSE 4.8345936138883445 Test RE 1.050964502030432\n",
      "79 Train Loss 7.050761 Test MSE 4.770215427170206 Test RE 1.0439436491259282\n",
      "80 Train Loss 6.920726 Test MSE 4.736560648049995 Test RE 1.0402545200124653\n",
      "81 Train Loss 6.7979145 Test MSE 4.635485813912868 Test RE 1.0290955220654083\n",
      "82 Train Loss 6.637624 Test MSE 4.505387777194065 Test RE 1.014551619676417\n",
      "83 Train Loss 6.4659033 Test MSE 4.444486024081698 Test RE 1.0076711685414552\n",
      "84 Train Loss 6.240916 Test MSE 4.160654951669014 Test RE 0.9749647424371831\n",
      "85 Train Loss 5.2635193 Test MSE 3.26496762870875 Test RE 0.8636693352065613\n",
      "86 Train Loss 4.3229055 Test MSE 2.8980412720706927 Test RE 0.8136925568184916\n",
      "87 Train Loss 3.6622205 Test MSE 2.593185775390088 Test RE 0.7697060064425899\n",
      "88 Train Loss 3.3935647 Test MSE 2.6832494710524406 Test RE 0.7829582173239915\n",
      "89 Train Loss 3.0608866 Test MSE 2.773851344276342 Test RE 0.7960670559231809\n",
      "90 Train Loss 2.7537603 Test MSE 2.694087088616064 Test RE 0.7845378041208587\n",
      "91 Train Loss 2.4909415 Test MSE 2.725821909249258 Test RE 0.7891449819363092\n",
      "92 Train Loss 2.245237 Test MSE 2.8014338939651235 Test RE 0.8000152205640941\n",
      "93 Train Loss 2.1326103 Test MSE 2.7384720195523333 Test RE 0.7909740111390762\n",
      "94 Train Loss 2.0275083 Test MSE 2.6768578273076997 Test RE 0.7820251371571842\n",
      "95 Train Loss 1.9072794 Test MSE 2.743012674887889 Test RE 0.7916294958016429\n",
      "96 Train Loss 1.8392793 Test MSE 2.775450458164907 Test RE 0.7962964875527382\n",
      "97 Train Loss 1.7725284 Test MSE 2.738708827941941 Test RE 0.7910082099972827\n",
      "98 Train Loss 1.7055619 Test MSE 2.723538803197285 Test RE 0.7888144249205636\n",
      "99 Train Loss 1.6755533 Test MSE 2.7435881542521474 Test RE 0.7917125327032555\n",
      "Training time: 80.68\n",
      "KG_stan_tune10\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.04792 Test MSE 8.595312288704193 Test RE 1.4013250658960545\n",
      "1 Train Loss 48.85851 Test MSE 8.331892806867337 Test RE 1.3796848557716141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Train Loss 45.015594 Test MSE 8.192806755637934 Test RE 1.3681207062170402\n",
      "3 Train Loss 40.46525 Test MSE 7.90838987847991 Test RE 1.344163493433966\n",
      "4 Train Loss 33.45095 Test MSE 6.756765948683233 Test RE 1.2424459306684954\n",
      "5 Train Loss 31.180374 Test MSE 6.684648796312329 Test RE 1.235797629204979\n",
      "6 Train Loss 27.406265 Test MSE 6.095205991698881 Test RE 1.180055012630059\n",
      "7 Train Loss 25.232384 Test MSE 6.168952967703928 Test RE 1.187172395958809\n",
      "8 Train Loss 23.925377 Test MSE 6.01685612751786 Test RE 1.1724460660111005\n",
      "9 Train Loss 22.864614 Test MSE 5.9630543080856695 Test RE 1.167192377327283\n",
      "10 Train Loss 22.267117 Test MSE 5.741851106558498 Test RE 1.1453389324224719\n",
      "11 Train Loss 21.245058 Test MSE 5.498287043725592 Test RE 1.120783592944277\n",
      "12 Train Loss 20.308273 Test MSE 5.7508258412021025 Test RE 1.1462336873785268\n",
      "13 Train Loss 17.44723 Test MSE 5.202816572812124 Test RE 1.090253068740319\n",
      "14 Train Loss 14.019939 Test MSE 4.365396079885344 Test RE 0.9986651329576175\n",
      "15 Train Loss 12.352269 Test MSE 3.9679614381851978 Test RE 0.9521202056278745\n",
      "16 Train Loss 9.994571 Test MSE 3.4805597902669048 Test RE 0.8917284230056135\n",
      "17 Train Loss 7.464197 Test MSE 2.62346411761726 Test RE 0.7741865544946523\n",
      "18 Train Loss 5.825246 Test MSE 2.3327042236329962 Test RE 0.7300252776374239\n",
      "19 Train Loss 4.823074 Test MSE 2.038027832066463 Test RE 0.6823593009012784\n",
      "20 Train Loss 4.231303 Test MSE 1.841245519839855 Test RE 0.6485805368194973\n",
      "21 Train Loss 3.9860282 Test MSE 1.8739454346713322 Test RE 0.6543144791320736\n",
      "22 Train Loss 3.856298 Test MSE 1.8631899430489898 Test RE 0.6524340612903189\n",
      "23 Train Loss 3.7470126 Test MSE 1.8200548499443914 Test RE 0.64483751906267\n",
      "24 Train Loss 3.6234586 Test MSE 1.7883332831862817 Test RE 0.6391934117246467\n",
      "25 Train Loss 3.530828 Test MSE 1.7892403986859688 Test RE 0.6393555036422435\n",
      "26 Train Loss 3.4398508 Test MSE 1.751789454441997 Test RE 0.6326288802538286\n",
      "27 Train Loss 3.3086705 Test MSE 1.7335896178882018 Test RE 0.629334019837347\n",
      "28 Train Loss 3.233901 Test MSE 1.6866194169851059 Test RE 0.6207498283978928\n",
      "29 Train Loss 3.1677349 Test MSE 1.676171321812549 Test RE 0.6188241631842449\n",
      "30 Train Loss 3.0891016 Test MSE 1.6027599383378164 Test RE 0.6051211040502374\n",
      "31 Train Loss 3.0440166 Test MSE 1.5578831234827328 Test RE 0.5965893504120864\n",
      "32 Train Loss 2.9075692 Test MSE 1.415271608378061 Test RE 0.5686276286386613\n",
      "33 Train Loss 2.6357834 Test MSE 1.3186329020956529 Test RE 0.5488706576510738\n",
      "34 Train Loss 2.2831445 Test MSE 1.0551896054371255 Test RE 0.4909907524165841\n",
      "35 Train Loss 1.705369 Test MSE 0.7904439877774359 Test RE 0.4249556526932917\n",
      "36 Train Loss 1.4856285 Test MSE 0.8626955827410976 Test RE 0.4439528490926184\n",
      "37 Train Loss 1.300739 Test MSE 0.8730040456278433 Test RE 0.44659739800390497\n",
      "38 Train Loss 1.1780088 Test MSE 0.8917525675491532 Test RE 0.4513674577174811\n",
      "39 Train Loss 1.0890961 Test MSE 0.8767505249279954 Test RE 0.4475546539670299\n",
      "40 Train Loss 0.8317498 Test MSE 0.4501493690803947 Test RE 0.3206907129660467\n",
      "41 Train Loss 0.5810249 Test MSE 0.3304303986581491 Test RE 0.27475655187450365\n",
      "42 Train Loss 0.39769903 Test MSE 0.3293465210565832 Test RE 0.2743055535887807\n",
      "43 Train Loss 0.31013116 Test MSE 0.29899406994524586 Test RE 0.26136013616384185\n",
      "44 Train Loss 0.26126367 Test MSE 0.2916100560536334 Test RE 0.2581126611718991\n",
      "45 Train Loss 0.21596211 Test MSE 0.2701229416076564 Test RE 0.2484212802025683\n",
      "46 Train Loss 0.17198642 Test MSE 0.23574229569411267 Test RE 0.23207417459647992\n",
      "47 Train Loss 0.15125139 Test MSE 0.248886320001085 Test RE 0.23845617508383357\n",
      "48 Train Loss 0.1270088 Test MSE 0.22143654731790333 Test RE 0.22492240101367642\n",
      "49 Train Loss 0.113673106 Test MSE 0.19474347033605494 Test RE 0.21093056342677893\n",
      "50 Train Loss 0.10335261 Test MSE 0.1893369674121401 Test RE 0.20798200886742801\n",
      "51 Train Loss 0.09251051 Test MSE 0.1808270135947007 Test RE 0.20325428737336668\n",
      "52 Train Loss 0.08810607 Test MSE 0.17735375738153575 Test RE 0.20129280750522788\n",
      "53 Train Loss 0.07995199 Test MSE 0.16209645967948422 Test RE 0.19243976818751798\n",
      "54 Train Loss 0.06947457 Test MSE 0.12852388907170317 Test RE 0.17135626586165914\n",
      "55 Train Loss 0.06060985 Test MSE 0.09813206327709278 Test RE 0.14973162068394802\n",
      "56 Train Loss 0.05216367 Test MSE 0.06944973857780662 Test RE 0.12596310802976482\n",
      "57 Train Loss 0.048021704 Test MSE 0.06442451306174164 Test RE 0.12132034387986805\n",
      "58 Train Loss 0.04107483 Test MSE 0.05158350806311292 Test RE 0.10855841587592402\n",
      "59 Train Loss 0.03526835 Test MSE 0.03902498912681992 Test RE 0.09442336112188586\n",
      "60 Train Loss 0.029948553 Test MSE 0.02833339387469688 Test RE 0.08045580041320363\n",
      "61 Train Loss 0.027942615 Test MSE 0.022955815627952583 Test RE 0.07241931694909681\n",
      "62 Train Loss 0.026096106 Test MSE 0.018637567999172204 Test RE 0.06525333020050371\n",
      "63 Train Loss 0.02363149 Test MSE 0.015720602671077537 Test RE 0.05992977620666816\n",
      "64 Train Loss 0.021717515 Test MSE 0.014390008481343494 Test RE 0.057337477832131174\n",
      "65 Train Loss 0.0202918 Test MSE 0.014298252593895035 Test RE 0.05715438327021323\n",
      "66 Train Loss 0.018663699 Test MSE 0.013880037755287724 Test RE 0.056312315317088094\n",
      "67 Train Loss 0.016204448 Test MSE 0.010163681141041974 Test RE 0.04818740909986639\n",
      "68 Train Loss 0.014801852 Test MSE 0.00798001085059442 Test RE 0.042698223013056785\n",
      "69 Train Loss 0.013106942 Test MSE 0.007021969119132527 Test RE 0.04005322754509713\n",
      "70 Train Loss 0.012218944 Test MSE 0.006548570426135685 Test RE 0.0386795409759126\n",
      "71 Train Loss 0.011468954 Test MSE 0.00500657317281784 Test RE 0.033820369197971926\n",
      "72 Train Loss 0.00963954 Test MSE 0.0029123868304508503 Test RE 0.025794825220899684\n",
      "73 Train Loss 0.008378242 Test MSE 0.0025310878647744318 Test RE 0.02404704250816448\n",
      "74 Train Loss 0.0073905517 Test MSE 0.002043714929763972 Test RE 0.021608181498253127\n",
      "75 Train Loss 0.0067233862 Test MSE 0.001974285379779426 Test RE 0.021237971076026\n",
      "76 Train Loss 0.0061544594 Test MSE 0.0020126007140078956 Test RE 0.021443065465858085\n",
      "77 Train Loss 0.0057296515 Test MSE 0.0017108622983657883 Test RE 0.019770406014862192\n",
      "78 Train Loss 0.005341146 Test MSE 0.0015570650371044493 Test RE 0.018860857627672468\n",
      "79 Train Loss 0.0050967946 Test MSE 0.0015781559336991795 Test RE 0.01898816585879272\n",
      "80 Train Loss 0.0048055993 Test MSE 0.0014556952575695914 Test RE 0.018236575704654326\n",
      "81 Train Loss 0.0043721832 Test MSE 0.0013557039003198655 Test RE 0.017599100973635175\n",
      "82 Train Loss 0.004080786 Test MSE 0.0013855211573799873 Test RE 0.017791585059423548\n",
      "83 Train Loss 0.0038388646 Test MSE 0.0013937123681962062 Test RE 0.01784409954523258\n",
      "84 Train Loss 0.0036361162 Test MSE 0.001345964456849747 Test RE 0.017535770623220197\n",
      "85 Train Loss 0.0033795785 Test MSE 0.0013323937850079778 Test RE 0.017447144557159868\n",
      "86 Train Loss 0.0031990935 Test MSE 0.0013649983428339189 Test RE 0.017659325935589533\n",
      "87 Train Loss 0.0030331903 Test MSE 0.0014060215199865112 Test RE 0.017922725125205163\n",
      "88 Train Loss 0.0029091793 Test MSE 0.0012544243677670057 Test RE 0.016928960870896823\n",
      "89 Train Loss 0.0027938322 Test MSE 0.0011578118494972392 Test RE 0.01626398837747867\n",
      "90 Train Loss 0.0025703656 Test MSE 0.0010378965536454814 Test RE 0.015398736774038515\n",
      "91 Train Loss 0.0024232413 Test MSE 0.0009529928420397634 Test RE 0.014755464296930525\n",
      "92 Train Loss 0.0022344235 Test MSE 0.0008968775071923685 Test RE 0.01431444870168691\n",
      "93 Train Loss 0.002117876 Test MSE 0.0009076246824757256 Test RE 0.01439995746266277\n",
      "94 Train Loss 0.0020608094 Test MSE 0.0008960461747761162 Test RE 0.014307812999482495\n",
      "95 Train Loss 0.0020033265 Test MSE 0.0008468775175129741 Test RE 0.013909719175473227\n",
      "96 Train Loss 0.0019398945 Test MSE 0.0008124805927578072 Test RE 0.013624311303056321\n",
      "97 Train Loss 0.0018371955 Test MSE 0.0007877711985376186 Test RE 0.013415538489492871\n",
      "98 Train Loss 0.0017396836 Test MSE 0.0008542756601921238 Test RE 0.01397034324438307\n",
      "99 Train Loss 0.0016716288 Test MSE 0.0008370085892522704 Test RE 0.013828434521307791\n",
      "Training time: 82.21\n",
      "KG_stan_tune10\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.86203 Test MSE 8.809584495156871 Test RE 1.4186843338301038\n",
      "1 Train Loss 46.38889 Test MSE 8.859685000057217 Test RE 1.422712675549619\n",
      "2 Train Loss 44.798973 Test MSE 8.71204076951769 Test RE 1.41080831237982\n",
      "3 Train Loss 43.00756 Test MSE 8.633066514399825 Test RE 1.4043992982212765\n",
      "4 Train Loss 42.428436 Test MSE 8.467014662901484 Test RE 1.390827330502584\n",
      "5 Train Loss 42.00116 Test MSE 8.360370260446828 Test RE 1.3820406467961028\n",
      "6 Train Loss 41.79815 Test MSE 8.442928587591533 Test RE 1.3888476817642843\n",
      "7 Train Loss 41.543182 Test MSE 8.441362575199408 Test RE 1.3887188725767543\n",
      "8 Train Loss 40.818985 Test MSE 8.680585877854458 Test RE 1.4082591420998822\n",
      "9 Train Loss 40.361694 Test MSE 8.681006501973265 Test RE 1.4082932607984087\n",
      "10 Train Loss 39.63716 Test MSE 8.811740033877582 Test RE 1.418857885827825\n",
      "11 Train Loss 38.847794 Test MSE 8.873252211600956 Test RE 1.423801588976076\n",
      "12 Train Loss 36.930824 Test MSE 8.70568009870429 Test RE 1.4102932019701984\n",
      "13 Train Loss 34.638046 Test MSE 9.190798906821232 Test RE 1.4490544076631813\n",
      "14 Train Loss 31.21577 Test MSE 7.927280300259156 Test RE 1.3457679079056082\n",
      "15 Train Loss 29.662043 Test MSE 7.934007966269096 Test RE 1.346338845007531\n",
      "16 Train Loss 28.835964 Test MSE 7.721361036340192 Test RE 1.3281740483046494\n",
      "17 Train Loss 27.929752 Test MSE 7.858343249939436 Test RE 1.339903611357089\n",
      "18 Train Loss 26.781034 Test MSE 7.633491533277489 Test RE 1.320595078355045\n",
      "19 Train Loss 25.441944 Test MSE 7.523895719289968 Test RE 1.31108075967326\n",
      "20 Train Loss 23.04884 Test MSE 7.036721734618597 Test RE 1.2679240771727536\n",
      "21 Train Loss 19.204002 Test MSE 6.23529671361435 Test RE 1.193539022197272\n",
      "22 Train Loss 16.167673 Test MSE 5.973284756231616 Test RE 1.1681931885974708\n",
      "23 Train Loss 14.755699 Test MSE 6.116282999057099 Test RE 1.1820935461648485\n",
      "24 Train Loss 14.128481 Test MSE 6.073951904155216 Test RE 1.1779957799112941\n",
      "25 Train Loss 13.716238 Test MSE 5.954445565754803 Test RE 1.1663495468688407\n",
      "26 Train Loss 13.240896 Test MSE 5.793804698399785 Test RE 1.1505089092562892\n",
      "27 Train Loss 12.960985 Test MSE 5.7432572992216535 Test RE 1.1454791719182262\n",
      "28 Train Loss 12.778792 Test MSE 5.68647112426731 Test RE 1.139802169713587\n",
      "29 Train Loss 12.524904 Test MSE 5.898661002590484 Test RE 1.1608731841291227\n",
      "30 Train Loss 12.036869 Test MSE 5.875963733492674 Test RE 1.1586375880800628\n",
      "31 Train Loss 10.583462 Test MSE 4.955982909645162 Test RE 1.064076765494474\n",
      "32 Train Loss 8.985664 Test MSE 4.474514161820323 Test RE 1.0110694863439689\n",
      "33 Train Loss 7.969219 Test MSE 4.175393027730857 Test RE 0.9766899999325792\n",
      "34 Train Loss 7.2340546 Test MSE 4.10751611136253 Test RE 0.9687187327945816\n",
      "35 Train Loss 6.905548 Test MSE 3.999312675980402 Test RE 0.9558742008496424\n",
      "36 Train Loss 6.676567 Test MSE 3.94955660975646 Test RE 0.9499095016227159\n",
      "37 Train Loss 6.5020294 Test MSE 3.9770390518764205 Test RE 0.9532086791425688\n",
      "38 Train Loss 6.302696 Test MSE 3.818032709689158 Test RE 0.9339591530275512\n",
      "39 Train Loss 6.140426 Test MSE 3.6370441775764815 Test RE 0.9115538893352799\n",
      "40 Train Loss 6.0554047 Test MSE 3.5504991849902163 Test RE 0.90064318870224\n",
      "41 Train Loss 5.968911 Test MSE 3.6043603074341024 Test RE 0.9074488602237274\n",
      "42 Train Loss 5.8924437 Test MSE 3.6115270269071176 Test RE 0.9083505738848269\n",
      "43 Train Loss 5.8164816 Test MSE 3.586885127168919 Test RE 0.9052463750592528\n",
      "44 Train Loss 5.7561693 Test MSE 3.5702683108907753 Test RE 0.9031470919605523\n",
      "45 Train Loss 5.6830616 Test MSE 3.437319165268772 Test RE 0.8861719313477443\n",
      "46 Train Loss 5.595765 Test MSE 3.399322441829897 Test RE 0.8812603710479441\n",
      "47 Train Loss 5.5416536 Test MSE 3.4423873426643423 Test RE 0.8868250016631062\n",
      "48 Train Loss 5.4516535 Test MSE 3.419637905879619 Test RE 0.8838897985969068\n",
      "49 Train Loss 5.3472185 Test MSE 3.4024893902815667 Test RE 0.8816707846652551\n",
      "50 Train Loss 5.2358036 Test MSE 3.418744999280294 Test RE 0.8837743941912346\n",
      "51 Train Loss 5.0904913 Test MSE 3.4208367421910246 Test RE 0.8840447194336704\n",
      "52 Train Loss 4.9362125 Test MSE 3.4983322186645918 Test RE 0.8940021951863133\n",
      "53 Train Loss 4.5924635 Test MSE 3.4425100399861543 Test RE 0.8868408061139446\n",
      "54 Train Loss 4.193498 Test MSE 3.347526667837677 Test RE 0.8745206784197408\n",
      "55 Train Loss 3.8654456 Test MSE 3.219016238754919 Test RE 0.8575701267213444\n",
      "56 Train Loss 3.4467869 Test MSE 3.0930984058802578 Test RE 0.8406300852027406\n",
      "57 Train Loss 2.9476037 Test MSE 2.970410769236057 Test RE 0.8237896204670243\n",
      "58 Train Loss 2.5177677 Test MSE 2.869390062429511 Test RE 0.8096603189098652\n",
      "59 Train Loss 2.1939256 Test MSE 2.8115946268174117 Test RE 0.8014647253339976\n",
      "60 Train Loss 1.8947381 Test MSE 2.646273502613662 Test RE 0.7775448055433257\n",
      "61 Train Loss 1.6641607 Test MSE 2.5648000631250762 Test RE 0.7654817095858757\n",
      "62 Train Loss 1.4313351 Test MSE 2.506967514106014 Test RE 0.7568022480165525\n",
      "63 Train Loss 1.3265454 Test MSE 2.4703534615913387 Test RE 0.751255403707429\n",
      "64 Train Loss 1.2821528 Test MSE 2.469499478995162 Test RE 0.7511255408142958\n",
      "65 Train Loss 1.2146751 Test MSE 2.4923588031953616 Test RE 0.7545939906979348\n",
      "66 Train Loss 1.1684628 Test MSE 2.5085846296232646 Test RE 0.7570462957269863\n",
      "67 Train Loss 1.1401095 Test MSE 2.5075493200173025 Test RE 0.7568900605780721\n",
      "68 Train Loss 1.1202188 Test MSE 2.51896664777068 Test RE 0.7586112325989938\n",
      "69 Train Loss 1.0937382 Test MSE 2.5155033054898244 Test RE 0.7580895436629121\n",
      "70 Train Loss 1.0786252 Test MSE 2.5121328726403207 Test RE 0.757581504906318\n",
      "71 Train Loss 1.061883 Test MSE 2.5266098139578688 Test RE 0.7597612676940337\n",
      "72 Train Loss 1.0489647 Test MSE 2.511967132374217 Test RE 0.7575565134274302\n",
      "73 Train Loss 1.0352077 Test MSE 2.498594159546266 Test RE 0.7555373186149476\n",
      "74 Train Loss 1.0235542 Test MSE 2.495777949400037 Test RE 0.7551114087589347\n",
      "75 Train Loss 1.0088271 Test MSE 2.4934259113601773 Test RE 0.7547555138372707\n",
      "76 Train Loss 0.99796116 Test MSE 2.50221805545322 Test RE 0.756085025918368\n",
      "77 Train Loss 0.98723876 Test MSE 2.502518935612743 Test RE 0.7561304824173413\n",
      "78 Train Loss 0.97236776 Test MSE 2.495930970101657 Test RE 0.7551345570335121\n",
      "79 Train Loss 0.96150523 Test MSE 2.5177373056313908 Test RE 0.7584260958548279\n",
      "80 Train Loss 0.9520059 Test MSE 2.535032237317197 Test RE 0.761026541641339\n",
      "81 Train Loss 0.941897 Test MSE 2.535474534961977 Test RE 0.7610929284827559\n",
      "82 Train Loss 0.9239615 Test MSE 2.5665685049897773 Test RE 0.7657455657543172\n",
      "83 Train Loss 0.9139029 Test MSE 2.578988054372318 Test RE 0.7675960399749646\n",
      "84 Train Loss 0.9028744 Test MSE 2.5675657401019087 Test RE 0.7658943157684858\n",
      "85 Train Loss 0.8918253 Test MSE 2.5651139608834868 Test RE 0.7655285505940264\n",
      "86 Train Loss 0.8840525 Test MSE 2.589959038304467 Test RE 0.769226979442818\n",
      "87 Train Loss 0.87763715 Test MSE 2.597372801744119 Test RE 0.7703271496551941\n",
      "88 Train Loss 0.8720084 Test MSE 2.59886603674667 Test RE 0.7705485491757985\n",
      "89 Train Loss 0.8621571 Test MSE 2.6167286775206913 Test RE 0.7731920986666703\n",
      "90 Train Loss 0.8548465 Test MSE 2.6215506051276893 Test RE 0.7739041633881625\n",
      "91 Train Loss 0.84915316 Test MSE 2.6181047140694447 Test RE 0.7733953678786368\n",
      "92 Train Loss 0.84215164 Test MSE 2.6242883854376413 Test RE 0.77430816602028\n",
      "93 Train Loss 0.8295784 Test MSE 2.640556696500781 Test RE 0.7767044774010944\n",
      "94 Train Loss 0.8218661 Test MSE 2.646101548391953 Test RE 0.7775195427948227\n",
      "95 Train Loss 0.8121627 Test MSE 2.6704078191952068 Test RE 0.7810824067345151\n",
      "96 Train Loss 0.8052677 Test MSE 2.6777774005759274 Test RE 0.7821594490459906\n",
      "97 Train Loss 0.7990331 Test MSE 2.665850717680564 Test RE 0.7804156561979804\n",
      "98 Train Loss 0.79025406 Test MSE 2.672592494073937 Test RE 0.7814018452555959\n",
      "99 Train Loss 0.7840367 Test MSE 2.6989468477825684 Test RE 0.7852450839579965\n",
      "Training time: 80.00\n",
      "KG_stan_tune10\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.948166 Test MSE 8.48597148608031 Test RE 1.3923834236346317\n",
      "1 Train Loss 50.37663 Test MSE 7.63376972150513 Test RE 1.3206191414365116\n",
      "2 Train Loss 45.286457 Test MSE 8.151433764230125 Test RE 1.3646618862217181\n",
      "3 Train Loss 44.821766 Test MSE 8.170437659814956 Test RE 1.36625171661555\n",
      "4 Train Loss 44.517082 Test MSE 8.142793651951653 Test RE 1.3639384577832188\n",
      "5 Train Loss 44.414474 Test MSE 8.188142670415912 Test RE 1.3677312218692725\n",
      "6 Train Loss 43.99621 Test MSE 8.300853697829673 Test RE 1.3771125623103817\n",
      "7 Train Loss 43.502594 Test MSE 8.343565562777064 Test RE 1.3806509680527026\n",
      "8 Train Loss 43.025936 Test MSE 8.38315340070293 Test RE 1.3839224894871125\n",
      "9 Train Loss 41.717983 Test MSE 8.403645553214487 Test RE 1.3856129178782868\n",
      "10 Train Loss 39.39563 Test MSE 8.644345802856398 Test RE 1.405316437809729\n",
      "11 Train Loss 38.509865 Test MSE 8.362989441520087 Test RE 1.3822571163499335\n",
      "12 Train Loss 37.437004 Test MSE 8.045089071864414 Test RE 1.3557308813088893\n",
      "13 Train Loss 35.901234 Test MSE 8.181267911976335 Test RE 1.367156928246245\n",
      "14 Train Loss 35.16327 Test MSE 8.071727429381673 Test RE 1.3579735288453523\n",
      "15 Train Loss 34.052574 Test MSE 7.832368839691228 Test RE 1.3376873673202698\n",
      "16 Train Loss 32.87421 Test MSE 7.695859779833059 Test RE 1.3259789612714883\n",
      "17 Train Loss 30.925714 Test MSE 7.264632926843835 Test RE 1.2882937435177215\n",
      "18 Train Loss 28.265404 Test MSE 6.504117846688212 Test RE 1.2189959453230756\n",
      "19 Train Loss 23.204971 Test MSE 4.909245757412055 Test RE 1.0590475186812527\n",
      "20 Train Loss 20.441185 Test MSE 3.6671711604387105 Test RE 0.915321472453617\n",
      "21 Train Loss 17.205421 Test MSE 3.0448598387524943 Test RE 0.8340492828142265\n",
      "22 Train Loss 12.825738 Test MSE 2.2726538121874094 Test RE 0.7205675548429233\n",
      "23 Train Loss 10.403572 Test MSE 1.0212802789166904 Test RE 0.48303714983329304\n",
      "24 Train Loss 6.607412 Test MSE 0.5889802910209601 Test RE 0.366824590523547\n",
      "25 Train Loss 4.599162 Test MSE 0.35713378025734527 Test RE 0.28564296055269395\n",
      "26 Train Loss 3.0981722 Test MSE 0.21523907090106645 Test RE 0.22175254592358426\n",
      "27 Train Loss 2.2568035 Test MSE 0.24458620993163746 Test RE 0.23638724761300461\n",
      "28 Train Loss 1.7678925 Test MSE 0.16943181824465847 Test RE 0.19674583439119336\n",
      "29 Train Loss 1.3492746 Test MSE 0.09388641849692238 Test RE 0.1464567681655324\n",
      "30 Train Loss 0.9910778 Test MSE 0.06800108120996128 Test RE 0.12464244778322774\n",
      "31 Train Loss 0.7466757 Test MSE 0.04098220203405047 Test RE 0.09676219360102221\n",
      "32 Train Loss 0.61333686 Test MSE 0.0441017452321861 Test RE 0.10037740139401094\n",
      "33 Train Loss 0.55402774 Test MSE 0.05091531407592136 Test RE 0.10785301093798727\n",
      "34 Train Loss 0.40125275 Test MSE 0.027766691036360203 Test RE 0.0796471287396046\n",
      "35 Train Loss 0.3238728 Test MSE 0.024501040820204153 Test RE 0.07481700642115381\n",
      "36 Train Loss 0.280701 Test MSE 0.0240542991984802 Test RE 0.07413177767370907\n",
      "37 Train Loss 0.2421639 Test MSE 0.026237907150889788 Test RE 0.07742347425946593\n",
      "38 Train Loss 0.20935667 Test MSE 0.01921449665721347 Test RE 0.06625559620657337\n",
      "39 Train Loss 0.1826607 Test MSE 0.021392126680291074 Test RE 0.0699093140975525\n",
      "40 Train Loss 0.16155197 Test MSE 0.021680834832044842 Test RE 0.07037948113840461\n",
      "41 Train Loss 0.150485 Test MSE 0.019299512521230362 Test RE 0.06640201065477924\n",
      "42 Train Loss 0.12825125 Test MSE 0.017368953406743895 Test RE 0.06299337618321563\n",
      "43 Train Loss 0.11584099 Test MSE 0.0158452403229053 Test RE 0.06016687779925553\n",
      "44 Train Loss 0.10804066 Test MSE 0.014693592083696529 Test RE 0.05793914068969525\n",
      "45 Train Loss 0.09904852 Test MSE 0.013347986928625299 Test RE 0.05522248509184176\n",
      "46 Train Loss 0.08695619 Test MSE 0.01086389636689676 Test RE 0.0498196723919195\n",
      "47 Train Loss 0.07818079 Test MSE 0.010287940161756408 Test RE 0.04848107878789638\n",
      "48 Train Loss 0.072851926 Test MSE 0.010319075102078114 Test RE 0.0485543838013181\n",
      "49 Train Loss 0.06572829 Test MSE 0.009127794132655794 Test RE 0.04566579035251215\n",
      "50 Train Loss 0.060047574 Test MSE 0.009940648340878952 Test RE 0.04765576171209984\n",
      "51 Train Loss 0.05383538 Test MSE 0.0083270546242905 Test RE 0.04361679670626104\n",
      "52 Train Loss 0.049014363 Test MSE 0.006214699022220956 Test RE 0.037680626115836655\n",
      "53 Train Loss 0.04478373 Test MSE 0.005716793119949939 Test RE 0.03613967963465267\n",
      "54 Train Loss 0.03966022 Test MSE 0.005399644255733939 Test RE 0.03512292160703732\n",
      "55 Train Loss 0.035609297 Test MSE 0.005620513766907778 Test RE 0.03583406426628316\n",
      "56 Train Loss 0.030931301 Test MSE 0.005823760662221576 Test RE 0.0364762194245152\n",
      "57 Train Loss 0.029249737 Test MSE 0.005315303948428246 Test RE 0.0348475389619588\n",
      "58 Train Loss 0.023593988 Test MSE 0.003733068510008237 Test RE 0.029203912625038405\n",
      "59 Train Loss 0.02038068 Test MSE 0.003687987379780789 Test RE 0.029027041470665566\n",
      "60 Train Loss 0.01835435 Test MSE 0.0038675136458137557 Test RE 0.029725145399432218\n",
      "61 Train Loss 0.016958062 Test MSE 0.0038225962087044154 Test RE 0.029552026847378968\n",
      "62 Train Loss 0.016204495 Test MSE 0.0037683619370135193 Test RE 0.029341638662113673\n",
      "63 Train Loss 0.015174523 Test MSE 0.0033654101753361337 Test RE 0.027728543760257622\n",
      "64 Train Loss 0.01383948 Test MSE 0.003299856868114522 Test RE 0.027457159819974448\n",
      "65 Train Loss 0.012603847 Test MSE 0.0025399859692267148 Test RE 0.024089274421927067\n",
      "66 Train Loss 0.011954793 Test MSE 0.002112848404259102 Test RE 0.02197061577571381\n",
      "67 Train Loss 0.010814366 Test MSE 0.0018922671209273027 Test RE 0.02079214436686807\n",
      "68 Train Loss 0.0086969705 Test MSE 0.0011357616399729337 Test RE 0.0161083722976432\n",
      "69 Train Loss 0.007922672 Test MSE 0.001106705478075506 Test RE 0.015900987278006574\n",
      "70 Train Loss 0.00759817 Test MSE 0.0011421097213698231 Test RE 0.01615332661152594\n",
      "71 Train Loss 0.0071278294 Test MSE 0.0009754453423254551 Test RE 0.014928271671141064\n",
      "72 Train Loss 0.0064046057 Test MSE 0.0009723208083857919 Test RE 0.01490434347050666\n",
      "73 Train Loss 0.0061175735 Test MSE 0.000910325205033351 Test RE 0.014421364178189889\n",
      "74 Train Loss 0.005566405 Test MSE 0.0007297822344875916 Test RE 0.012912332585093158\n",
      "75 Train Loss 0.0052529 Test MSE 0.0008471768098915298 Test RE 0.013912176853886732\n",
      "76 Train Loss 0.0050642747 Test MSE 0.0007931309251358762 Test RE 0.0134610985016955\n",
      "77 Train Loss 0.0048741857 Test MSE 0.0006522812095967845 Test RE 0.012207465180777886\n",
      "78 Train Loss 0.0047358763 Test MSE 0.0006645612569944163 Test RE 0.012321840130141983\n",
      "79 Train Loss 0.0045863744 Test MSE 0.0006921952137837425 Test RE 0.012575415874945687\n",
      "80 Train Loss 0.004370285 Test MSE 0.000666538016929376 Test RE 0.012340152387747197\n",
      "81 Train Loss 0.0040260814 Test MSE 0.0006857041182631967 Test RE 0.01251631369191822\n",
      "82 Train Loss 0.003861702 Test MSE 0.0006639842807447854 Test RE 0.012316490019214945\n",
      "83 Train Loss 0.0036565694 Test MSE 0.0006773973426512564 Test RE 0.01244026995230405\n",
      "84 Train Loss 0.0035491793 Test MSE 0.000694815297872 Test RE 0.012599193507400094\n",
      "85 Train Loss 0.0034610396 Test MSE 0.0006350989207084938 Test RE 0.012045608604670239\n",
      "86 Train Loss 0.0034175327 Test MSE 0.0006441080634151859 Test RE 0.012130743736036462\n",
      "87 Train Loss 0.0033799715 Test MSE 0.0006680273670560785 Test RE 0.012353931460995041\n",
      "88 Train Loss 0.003360367 Test MSE 0.0006381476457502893 Test RE 0.012074485824226641\n",
      "89 Train Loss 0.0033285194 Test MSE 0.0006723076920761296 Test RE 0.012393446614652047\n",
      "90 Train Loss 0.003201948 Test MSE 0.0007454350029500419 Test RE 0.013050073304341355\n",
      "91 Train Loss 0.0028986554 Test MSE 0.0006948407532268326 Test RE 0.012599424298233942\n",
      "92 Train Loss 0.0028242553 Test MSE 0.0007019690953459474 Test RE 0.012663887870323451\n",
      "93 Train Loss 0.002738393 Test MSE 0.0007431970475773171 Test RE 0.013030469023087464\n",
      "94 Train Loss 0.0025888053 Test MSE 0.0007960273426123463 Test RE 0.01348565524814967\n",
      "95 Train Loss 0.0023654476 Test MSE 0.0006942104812603212 Test RE 0.012593708696858542\n",
      "96 Train Loss 0.0021808841 Test MSE 0.0005693882287162625 Test RE 0.011405446784534477\n",
      "97 Train Loss 0.002054214 Test MSE 0.0005251597945414222 Test RE 0.01095352225961967\n",
      "98 Train Loss 0.0019103568 Test MSE 0.00045058117970381013 Test RE 0.010145993602838375\n",
      "99 Train Loss 0.0018142844 Test MSE 0.0003910855189972554 Test RE 0.009452439969722611\n",
      "Training time: 80.08\n",
      "KG_stan_tune10\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.900238 Test MSE 8.658752677842127 Test RE 1.4064870174007091\n",
      "1 Train Loss 46.603317 Test MSE 8.287690175103615 Test RE 1.3760202141255977\n",
      "2 Train Loss 43.625572 Test MSE 8.1025954796062 Test RE 1.3605676449135045\n",
      "3 Train Loss 42.94106 Test MSE 8.238686180356094 Test RE 1.3719460717200846\n",
      "4 Train Loss 42.346275 Test MSE 8.249244110325323 Test RE 1.3728248691748075\n",
      "5 Train Loss 41.94075 Test MSE 8.277562551089348 Test RE 1.3751792032351648\n",
      "6 Train Loss 41.34223 Test MSE 8.340295770319743 Test RE 1.3803804071953663\n",
      "7 Train Loss 40.17363 Test MSE 8.294666186787236 Test RE 1.3765992122399013\n",
      "8 Train Loss 38.676468 Test MSE 8.276912880536939 Test RE 1.3751252362033333\n",
      "9 Train Loss 37.58946 Test MSE 8.598613313399738 Test RE 1.40159412910424\n",
      "10 Train Loss 36.222298 Test MSE 8.503571577740967 Test RE 1.3938265926664557\n",
      "11 Train Loss 34.858044 Test MSE 8.149147401345331 Test RE 1.3644704885366707\n",
      "12 Train Loss 29.368359 Test MSE 6.726792107030206 Test RE 1.2396870463879817\n",
      "13 Train Loss 25.06361 Test MSE 6.501613762669802 Test RE 1.2187612661403155\n",
      "14 Train Loss 23.515945 Test MSE 6.527073382010142 Test RE 1.2211452035453778\n",
      "15 Train Loss 22.607382 Test MSE 6.572757264556246 Test RE 1.2254112333799456\n",
      "16 Train Loss 21.426874 Test MSE 6.525261821877631 Test RE 1.2209757300805024\n",
      "17 Train Loss 20.671816 Test MSE 6.210773855794645 Test RE 1.1911896694808202\n",
      "18 Train Loss 19.723213 Test MSE 6.345233921715681 Test RE 1.20401494843928\n",
      "19 Train Loss 18.623266 Test MSE 6.303065114315453 Test RE 1.2000074909682443\n",
      "20 Train Loss 17.988913 Test MSE 6.318030512278355 Test RE 1.201431238159475\n",
      "21 Train Loss 17.303478 Test MSE 6.298126828381134 Test RE 1.1995373116845482\n",
      "22 Train Loss 16.89735 Test MSE 6.12364977122559 Test RE 1.1828052196811254\n",
      "23 Train Loss 16.651163 Test MSE 6.157707607925413 Test RE 1.1860898564799889\n",
      "24 Train Loss 16.50214 Test MSE 6.123861848245179 Test RE 1.1828257012275316\n",
      "25 Train Loss 16.304333 Test MSE 6.030384207833081 Test RE 1.1737633685131084\n",
      "26 Train Loss 16.075409 Test MSE 5.776551224796627 Test RE 1.1487945715890207\n",
      "27 Train Loss 15.6668825 Test MSE 5.48667190617744 Test RE 1.1195991387746478\n",
      "28 Train Loss 14.999819 Test MSE 5.212393945396209 Test RE 1.0912560792068704\n",
      "29 Train Loss 13.897693 Test MSE 5.1068207202540625 Test RE 1.0801482495704646\n",
      "30 Train Loss 13.028517 Test MSE 5.002726925620399 Test RE 1.0690830870505104\n",
      "31 Train Loss 12.395325 Test MSE 4.912488546366941 Test RE 1.0593972364209165\n",
      "32 Train Loss 11.213438 Test MSE 4.522825591092535 Test RE 1.016513101988561\n",
      "33 Train Loss 10.29426 Test MSE 4.026182642743501 Test RE 0.959079915613436\n",
      "34 Train Loss 8.171178 Test MSE 3.0028557889283993 Test RE 0.8282764209543559\n",
      "35 Train Loss 5.832421 Test MSE 2.092256866543701 Test RE 0.6913780083474055\n",
      "36 Train Loss 4.6187572 Test MSE 1.5442791620047573 Test RE 0.5939788290999135\n",
      "37 Train Loss 3.4334755 Test MSE 1.0854450506816828 Test RE 0.4979800926230002\n",
      "38 Train Loss 2.7169476 Test MSE 0.9441256101842477 Test RE 0.4644328703726832\n",
      "39 Train Loss 2.2304194 Test MSE 0.8222366870658717 Test RE 0.4334175426942708\n",
      "40 Train Loss 1.9345073 Test MSE 0.590483513814052 Test RE 0.3672924055785513\n",
      "41 Train Loss 1.533945 Test MSE 0.4410872768492715 Test RE 0.3174463410344462\n",
      "42 Train Loss 1.3126206 Test MSE 0.3983321054250045 Test RE 0.301669022591226\n",
      "43 Train Loss 1.0896418 Test MSE 0.3360679194678718 Test RE 0.27709046977841656\n",
      "44 Train Loss 0.9564485 Test MSE 0.38264261391624127 Test RE 0.29566827504562243\n",
      "45 Train Loss 0.8410927 Test MSE 0.36435571938276057 Test RE 0.2885166333566074\n",
      "46 Train Loss 0.740645 Test MSE 0.27065651419132325 Test RE 0.24866651185775354\n",
      "47 Train Loss 0.64565843 Test MSE 0.22592158966194983 Test RE 0.2271888053699546\n",
      "48 Train Loss 0.5433785 Test MSE 0.2128763658225726 Test RE 0.22053208525842055\n",
      "49 Train Loss 0.49244145 Test MSE 0.19033223317506728 Test RE 0.2085279298869273\n",
      "50 Train Loss 0.41971305 Test MSE 0.16183491118675578 Test RE 0.19228445125133928\n",
      "51 Train Loss 0.3725154 Test MSE 0.12795914727885088 Test RE 0.17097937645509467\n",
      "52 Train Loss 0.3315374 Test MSE 0.11065134868994073 Test RE 0.1589960796719507\n",
      "53 Train Loss 0.29196 Test MSE 0.0978712805968653 Test RE 0.14953253493980811\n",
      "54 Train Loss 0.26100844 Test MSE 0.10031198004064129 Test RE 0.15138556350401006\n",
      "55 Train Loss 0.23694214 Test MSE 0.0914789371943723 Test RE 0.14456681579835387\n",
      "56 Train Loss 0.21635047 Test MSE 0.072380639691632 Test RE 0.12859357458211554\n",
      "57 Train Loss 0.20366693 Test MSE 0.0622516619016946 Test RE 0.11925690531046307\n",
      "58 Train Loss 0.1853218 Test MSE 0.051345880397220996 Test RE 0.10830808140393168\n",
      "59 Train Loss 0.16745973 Test MSE 0.045405583923179504 Test RE 0.10185038918769547\n",
      "60 Train Loss 0.15874173 Test MSE 0.042325468134068 Test RE 0.09833518641252897\n",
      "61 Train Loss 0.14566343 Test MSE 0.03821267897751685 Test RE 0.09343547617000979\n",
      "62 Train Loss 0.13406886 Test MSE 0.03192009447799224 Test RE 0.08539651434798522\n",
      "63 Train Loss 0.12453017 Test MSE 0.02820392587526377 Test RE 0.08027177060381754\n",
      "64 Train Loss 0.118366286 Test MSE 0.028654585904884945 Test RE 0.08091054539650311\n",
      "65 Train Loss 0.113802515 Test MSE 0.028464869937074155 Test RE 0.08064225475971074\n",
      "66 Train Loss 0.10553737 Test MSE 0.027905923575133024 Test RE 0.07984656923081548\n",
      "67 Train Loss 0.10087498 Test MSE 0.028222316693963363 Test RE 0.0802979375815911\n",
      "68 Train Loss 0.095416225 Test MSE 0.027312565007352355 Test RE 0.07899312668144257\n",
      "69 Train Loss 0.08944974 Test MSE 0.025628843835637485 Test RE 0.07651957825052035\n",
      "70 Train Loss 0.08368091 Test MSE 0.023430716955989347 Test RE 0.07316457415135244\n",
      "71 Train Loss 0.07875987 Test MSE 0.02180040676466355 Test RE 0.0705732891622537\n",
      "72 Train Loss 0.073347405 Test MSE 0.022352594169275014 Test RE 0.07146148336997606\n",
      "73 Train Loss 0.07057489 Test MSE 0.023001242151282804 Test RE 0.07249093566118371\n",
      "74 Train Loss 0.067370385 Test MSE 0.02110004771323259 Test RE 0.06943041785023056\n",
      "75 Train Loss 0.06425181 Test MSE 0.01981120464708789 Test RE 0.06727651747200793\n",
      "76 Train Loss 0.061515186 Test MSE 0.019651772867585748 Test RE 0.0670052648674151\n",
      "77 Train Loss 0.057752952 Test MSE 0.01815387251935138 Test RE 0.06440101334177419\n",
      "78 Train Loss 0.05397623 Test MSE 0.01715822307692776 Test RE 0.06261007372965387\n",
      "79 Train Loss 0.051593244 Test MSE 0.017087046847946596 Test RE 0.06248007833260467\n",
      "80 Train Loss 0.047857556 Test MSE 0.01712459411010994 Test RE 0.0625486878635201\n",
      "81 Train Loss 0.045515664 Test MSE 0.015289193099699934 Test RE 0.05910175036002639\n",
      "82 Train Loss 0.043949425 Test MSE 0.014131387785967911 Test RE 0.056819900306648664\n",
      "83 Train Loss 0.04243998 Test MSE 0.014775810207232162 Test RE 0.058101014049883055\n",
      "84 Train Loss 0.03950915 Test MSE 0.014946418795383722 Test RE 0.05843548241873299\n",
      "85 Train Loss 0.036802486 Test MSE 0.013744495967177077 Test RE 0.05603668936819499\n",
      "86 Train Loss 0.0351083 Test MSE 0.013860993118591097 Test RE 0.05627366932305512\n",
      "87 Train Loss 0.033513136 Test MSE 0.013160606384583134 Test RE 0.054833505398715225\n",
      "88 Train Loss 0.031533808 Test MSE 0.012625947503053785 Test RE 0.053708132282578334\n",
      "89 Train Loss 0.030036312 Test MSE 0.013165679418792913 Test RE 0.05484407274792855\n",
      "90 Train Loss 0.02932347 Test MSE 0.012535480461130307 Test RE 0.053515372462617505\n",
      "91 Train Loss 0.028179752 Test MSE 0.011956604318177204 Test RE 0.052265124460614175\n",
      "92 Train Loss 0.027343377 Test MSE 0.012724852275773803 Test RE 0.05391808200532288\n",
      "93 Train Loss 0.026650438 Test MSE 0.012368209429532944 Test RE 0.053157123949109195\n",
      "94 Train Loss 0.025710467 Test MSE 0.011675300078034042 Test RE 0.05164664159435899\n",
      "95 Train Loss 0.023877498 Test MSE 0.011900104139854378 Test RE 0.05214149045965362\n",
      "96 Train Loss 0.022271313 Test MSE 0.011241107070415318 Test RE 0.05067719896423513\n",
      "97 Train Loss 0.021456711 Test MSE 0.010221888728059946 Test RE 0.04832519718759796\n",
      "98 Train Loss 0.020862829 Test MSE 0.010334024877079344 Test RE 0.04858954268873601\n",
      "99 Train Loss 0.020458506 Test MSE 0.009720812797558352 Test RE 0.047125866657977446\n",
      "Training time: 79.93\n",
      "KG_stan_tune10\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.827835 Test MSE 8.647437652685872 Test RE 1.4055677372736972\n",
      "1 Train Loss 53.89746 Test MSE 8.014553589844237 Test RE 1.3531555678362983\n",
      "2 Train Loss 46.865417 Test MSE 8.525690036624619 Test RE 1.39563814176514\n",
      "3 Train Loss 46.367348 Test MSE 8.619858468734892 Test RE 1.4033245659517528\n",
      "4 Train Loss 45.88649 Test MSE 8.494706990859012 Test RE 1.3930999027951068\n",
      "5 Train Loss 45.434708 Test MSE 8.414892417782498 Test RE 1.3865398126494444\n",
      "6 Train Loss 45.125057 Test MSE 8.267783875678695 Test RE 1.3743666811402981\n",
      "7 Train Loss 44.81492 Test MSE 8.372481692888709 Test RE 1.3830413461459041\n",
      "8 Train Loss 44.216408 Test MSE 8.525728417329962 Test RE 1.395641283183358\n",
      "9 Train Loss 43.73534 Test MSE 8.539194769442128 Test RE 1.3967430530579368\n",
      "10 Train Loss 43.30509 Test MSE 8.371121186582393 Test RE 1.382928971285689\n",
      "11 Train Loss 42.971184 Test MSE 8.541618929965045 Test RE 1.3969412971073256\n",
      "12 Train Loss 42.43473 Test MSE 9.043726459103066 Test RE 1.4374136651538474\n",
      "13 Train Loss 41.362904 Test MSE 9.129673018396012 Test RE 1.4442277052580237\n",
      "14 Train Loss 39.175873 Test MSE 9.003519928051857 Test RE 1.4342148844857099\n",
      "15 Train Loss 37.541294 Test MSE 8.975974242266929 Test RE 1.4320192601062198\n",
      "16 Train Loss 33.902847 Test MSE 9.020667482183237 Test RE 1.4355799938533929\n",
      "17 Train Loss 31.012554 Test MSE 8.83734203986723 Test RE 1.4209175959826703\n",
      "18 Train Loss 28.710289 Test MSE 8.934619786274862 Test RE 1.4287166244222986\n",
      "19 Train Loss 26.888668 Test MSE 8.64408268220963 Test RE 1.4052950498069636\n",
      "20 Train Loss 24.364403 Test MSE 8.304842174134658 Test RE 1.377443366911936\n",
      "21 Train Loss 22.982077 Test MSE 8.25045992753638 Test RE 1.3729260325411456\n",
      "22 Train Loss 21.699444 Test MSE 7.761553054745848 Test RE 1.3316263353043924\n",
      "23 Train Loss 20.505512 Test MSE 7.701647329029385 Test RE 1.326477458283146\n",
      "24 Train Loss 19.421398 Test MSE 7.848454138995906 Test RE 1.3390602639532205\n",
      "25 Train Loss 18.429733 Test MSE 7.956333172866511 Test RE 1.3482317204884655\n",
      "26 Train Loss 17.336567 Test MSE 8.089916118540724 Test RE 1.359502684764762\n",
      "27 Train Loss 16.06678 Test MSE 7.795892728007053 Test RE 1.3345688614974853\n",
      "28 Train Loss 13.553913 Test MSE 6.249548175455216 Test RE 1.1949022265745313\n",
      "29 Train Loss 12.273817 Test MSE 6.042136603522871 Test RE 1.174906564096018\n",
      "30 Train Loss 11.468966 Test MSE 5.810612567009363 Test RE 1.1521765179574939\n",
      "31 Train Loss 11.0842085 Test MSE 5.959560064112837 Test RE 1.1668503502074932\n",
      "32 Train Loss 10.692678 Test MSE 5.93868640635814 Test RE 1.1648050818118871\n",
      "33 Train Loss 10.382444 Test MSE 5.698376551506135 Test RE 1.1409947139417438\n",
      "34 Train Loss 10.042734 Test MSE 5.63286108272481 Test RE 1.1344166202266974\n",
      "35 Train Loss 9.623514 Test MSE 5.610886824919554 Test RE 1.1322017313847688\n",
      "36 Train Loss 7.4696355 Test MSE 4.520931030461546 Test RE 1.0163001767512136\n",
      "37 Train Loss 5.053443 Test MSE 4.464223898345775 Test RE 1.009906213677344\n",
      "38 Train Loss 4.4159026 Test MSE 4.329263416094074 Test RE 0.9945235373564473\n",
      "39 Train Loss 3.834296 Test MSE 4.53962146707183 Test RE 1.0183988044450587\n",
      "40 Train Loss 3.4179788 Test MSE 4.6501357156365275 Test RE 1.0307204062802742\n",
      "41 Train Loss 3.0951185 Test MSE 4.729888722349491 Test RE 1.039521609868835\n",
      "42 Train Loss 2.8516116 Test MSE 4.9032862437236515 Test RE 1.0584045151454513\n",
      "43 Train Loss 2.6833007 Test MSE 4.9249262466175265 Test RE 1.0607375077997532\n",
      "44 Train Loss 2.4927285 Test MSE 4.9864114872212575 Test RE 1.067338358211484\n",
      "45 Train Loss 2.3688407 Test MSE 5.029741617799019 Test RE 1.0719657215237155\n",
      "46 Train Loss 2.284314 Test MSE 5.084907821766126 Test RE 1.0778283498293562\n",
      "47 Train Loss 2.1963427 Test MSE 5.117933361290206 Test RE 1.0813228332893179\n",
      "48 Train Loss 2.1263394 Test MSE 5.091601327935545 Test RE 1.078537514905901\n",
      "49 Train Loss 2.0672057 Test MSE 5.123474293687137 Test RE 1.081908022220874\n",
      "50 Train Loss 2.0037606 Test MSE 5.174591089898844 Test RE 1.0872917141933223\n",
      "51 Train Loss 1.9455937 Test MSE 5.203031836174346 Test RE 1.0902756227848889\n",
      "52 Train Loss 1.8773683 Test MSE 5.239122461167648 Test RE 1.0940504150874077\n",
      "53 Train Loss 1.8228849 Test MSE 5.2991247267881825 Test RE 1.1002975125412116\n",
      "54 Train Loss 1.7643218 Test MSE 5.286394545113905 Test RE 1.0989750856894738\n",
      "55 Train Loss 1.7261654 Test MSE 5.353272465261175 Test RE 1.1059047779374198\n",
      "56 Train Loss 1.6801369 Test MSE 5.4481169371721885 Test RE 1.115658479413414\n",
      "57 Train Loss 1.6410302 Test MSE 5.442343112404824 Test RE 1.1150671444421336\n",
      "58 Train Loss 1.595073 Test MSE 5.43008985219599 Test RE 1.1138111682176792\n",
      "59 Train Loss 1.5510244 Test MSE 5.46553102644432 Test RE 1.1174400744608401\n",
      "60 Train Loss 1.5130134 Test MSE 5.51892402407677 Test RE 1.1228849679808979\n",
      "61 Train Loss 1.4626619 Test MSE 5.54165877164263 Test RE 1.1251954065333036\n",
      "62 Train Loss 1.4261543 Test MSE 5.545698692812196 Test RE 1.1256054708089354\n",
      "63 Train Loss 1.3806256 Test MSE 5.607844043546204 Test RE 1.1318946935104943\n",
      "64 Train Loss 1.340428 Test MSE 5.671294823493023 Test RE 1.1382801768115292\n",
      "65 Train Loss 1.3016304 Test MSE 5.701929298404364 Test RE 1.1413503445112536\n",
      "66 Train Loss 1.2604895 Test MSE 5.820509179660811 Test RE 1.153157291797446\n",
      "67 Train Loss 1.234699 Test MSE 5.862180991533607 Test RE 1.157277932113828\n",
      "68 Train Loss 1.1953394 Test MSE 5.857965911755785 Test RE 1.1568617989382242\n",
      "69 Train Loss 1.163857 Test MSE 5.930602117128683 Test RE 1.164011991605585\n",
      "70 Train Loss 1.127429 Test MSE 5.987786249308783 Test RE 1.169610354934187\n",
      "71 Train Loss 1.1034722 Test MSE 5.940188308716485 Test RE 1.1649523629432463\n",
      "72 Train Loss 1.0684904 Test MSE 5.927885868548937 Test RE 1.1637453991109474\n",
      "73 Train Loss 1.045167 Test MSE 5.960568534419377 Test RE 1.1669490726081826\n",
      "74 Train Loss 1.0259386 Test MSE 6.018040966438737 Test RE 1.1725614993304796\n",
      "75 Train Loss 1.004866 Test MSE 6.050164513222921 Test RE 1.175686827231387\n",
      "76 Train Loss 0.98962057 Test MSE 6.026553553908277 Test RE 1.1733905070697557\n",
      "77 Train Loss 0.9724245 Test MSE 6.046635423853539 Test RE 1.1753438853907885\n",
      "78 Train Loss 0.9579285 Test MSE 6.065101389329876 Test RE 1.177137222747823\n",
      "79 Train Loss 0.9457675 Test MSE 6.059542912832269 Test RE 1.17659769430561\n",
      "80 Train Loss 0.9353064 Test MSE 6.061909907419532 Test RE 1.1768274747111562\n",
      "81 Train Loss 0.92651045 Test MSE 6.04911223674362 Test RE 1.175584581962676\n",
      "82 Train Loss 0.9197098 Test MSE 6.05227917415639 Test RE 1.1758922730331485\n",
      "83 Train Loss 0.90927595 Test MSE 6.075861768889906 Test RE 1.178180967068342\n",
      "84 Train Loss 0.8990218 Test MSE 6.095828237406789 Test RE 1.1801152456581399\n",
      "85 Train Loss 0.88906586 Test MSE 6.119645118260382 Test RE 1.1824183997882804\n",
      "86 Train Loss 0.8823101 Test MSE 6.120733205751505 Test RE 1.1825235135212908\n",
      "87 Train Loss 0.8740165 Test MSE 6.117754817463099 Test RE 1.1822357667246235\n",
      "88 Train Loss 0.8662679 Test MSE 6.127780022818476 Test RE 1.1832040390006409\n",
      "89 Train Loss 0.8600955 Test MSE 6.147898123531943 Test RE 1.1851447346827293\n",
      "90 Train Loss 0.85328597 Test MSE 6.179219291134539 Test RE 1.1881598268334868\n",
      "91 Train Loss 0.84757596 Test MSE 6.183244561596438 Test RE 1.1885467596968258\n",
      "92 Train Loss 0.8407577 Test MSE 6.198563118223183 Test RE 1.1900181197631867\n",
      "93 Train Loss 0.8353195 Test MSE 6.207130669242742 Test RE 1.1908402474213766\n",
      "94 Train Loss 0.8284911 Test MSE 6.1965288697660155 Test RE 1.189822833281073\n",
      "95 Train Loss 0.82420737 Test MSE 6.21010560254365 Test RE 1.191125584247577\n",
      "96 Train Loss 0.81961745 Test MSE 6.232640295828673 Test RE 1.1932847539411302\n",
      "97 Train Loss 0.81461257 Test MSE 6.2354473546580325 Test RE 1.1935534397050758\n",
      "98 Train Loss 0.81006104 Test MSE 6.240848671818854 Test RE 1.1940702723253611\n",
      "99 Train Loss 0.80549383 Test MSE 6.23472814610017 Test RE 1.1934846043390241\n",
      "Training time: 79.91\n",
      "KG_stan_tune10\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.464115 Test MSE 8.580824019352702 Test RE 1.4001435301277434\n",
      "1 Train Loss 54.243095 Test MSE 8.369745265826449 Test RE 1.3828153139375188\n",
      "2 Train Loss 46.495174 Test MSE 8.029998793182395 Test RE 1.3544588034522231\n",
      "3 Train Loss 44.215847 Test MSE 7.997662008626588 Test RE 1.3517288512373473\n",
      "4 Train Loss 43.052055 Test MSE 8.127452810196358 Test RE 1.3626530372442505\n",
      "5 Train Loss 42.5186 Test MSE 8.17269140733794 Test RE 1.3664401382300069\n",
      "6 Train Loss 41.622845 Test MSE 8.188157865068742 Test RE 1.3677324909111221\n",
      "7 Train Loss 40.485336 Test MSE 8.228325558082297 Test RE 1.3710831497487648\n",
      "8 Train Loss 33.766243 Test MSE 6.716762681311889 Test RE 1.2387625353554903\n",
      "9 Train Loss 29.751003 Test MSE 6.352990486792819 Test RE 1.2047506319538273\n",
      "10 Train Loss 26.747694 Test MSE 6.082188180532567 Test RE 1.178794190247556\n",
      "11 Train Loss 25.52586 Test MSE 6.080313269227265 Test RE 1.1786124871466293\n",
      "12 Train Loss 24.575304 Test MSE 5.6497633484343766 Test RE 1.1361173411043226\n",
      "13 Train Loss 23.806301 Test MSE 5.49307124152163 Test RE 1.1202518661985175\n",
      "14 Train Loss 23.433327 Test MSE 5.637494326958131 Test RE 1.1348830749119412\n",
      "15 Train Loss 22.92341 Test MSE 5.392359679018273 Test RE 1.1099348471978447\n",
      "16 Train Loss 21.745718 Test MSE 5.034297308043441 Test RE 1.0724510783107581\n",
      "17 Train Loss 18.747213 Test MSE 5.00952042007437 Test RE 1.0698087259025912\n",
      "18 Train Loss 16.162033 Test MSE 4.66340169032298 Test RE 1.0321895862722257\n",
      "19 Train Loss 14.427141 Test MSE 4.964055769577414 Test RE 1.0649430565553144\n",
      "20 Train Loss 12.661015 Test MSE 4.860413545028387 Test RE 1.053767188133693\n",
      "21 Train Loss 11.10376 Test MSE 4.254923953127952 Test RE 0.9859478891086001\n",
      "22 Train Loss 10.364544 Test MSE 4.167430078639653 Test RE 0.9757582260492433\n",
      "23 Train Loss 9.634693 Test MSE 4.062946563151394 Test RE 0.9634487453021017\n",
      "24 Train Loss 9.301293 Test MSE 3.955200835639872 Test RE 0.9505880068564344\n",
      "25 Train Loss 8.793469 Test MSE 3.933823046029219 Test RE 0.9480155705859942\n",
      "26 Train Loss 8.555626 Test MSE 3.963230394594043 Test RE 0.9515524246947934\n",
      "27 Train Loss 8.365819 Test MSE 3.894085419702416 Test RE 0.9432152138421941\n",
      "28 Train Loss 8.257449 Test MSE 3.886785046077221 Test RE 0.9423306603427538\n",
      "29 Train Loss 8.161689 Test MSE 3.878125408825137 Test RE 0.9412803331629189\n",
      "30 Train Loss 8.077827 Test MSE 3.8581960775879525 Test RE 0.9388586412371891\n",
      "31 Train Loss 8.001745 Test MSE 3.845585296134187 Test RE 0.9373230231011789\n",
      "32 Train Loss 7.9422526 Test MSE 3.845734376478316 Test RE 0.9373411913478604\n",
      "33 Train Loss 7.887706 Test MSE 3.831370013973799 Test RE 0.9355890026039155\n",
      "34 Train Loss 7.803953 Test MSE 3.812323926814351 Test RE 0.9332606565828837\n",
      "35 Train Loss 7.747003 Test MSE 3.780804588385901 Test RE 0.929394666674916\n",
      "36 Train Loss 7.623004 Test MSE 3.7612561020662674 Test RE 0.9269888554301805\n",
      "37 Train Loss 7.530642 Test MSE 3.7814503440951315 Test RE 0.9294740328883245\n",
      "38 Train Loss 7.412036 Test MSE 3.7629507046135586 Test RE 0.9271976554608736\n",
      "39 Train Loss 7.1903086 Test MSE 3.6292187152447597 Test RE 0.9105727118423926\n",
      "40 Train Loss 6.2917233 Test MSE 3.0851209532594566 Test RE 0.8395453450294855\n",
      "41 Train Loss 5.3451633 Test MSE 2.7652996580858136 Test RE 0.7948389852924858\n",
      "42 Train Loss 4.7025785 Test MSE 2.5136481454569934 Test RE 0.7578099501491946\n",
      "43 Train Loss 3.4776695 Test MSE 2.0390166800396945 Test RE 0.682524820668496\n",
      "44 Train Loss 2.1531742 Test MSE 1.654512929629173 Test RE 0.6148131430712163\n",
      "45 Train Loss 1.6629508 Test MSE 1.2363287205658358 Test RE 0.5314654532397074\n",
      "46 Train Loss 1.3273218 Test MSE 0.8233354153338828 Test RE 0.43370702693544555\n",
      "47 Train Loss 0.9931353 Test MSE 0.37116295816497064 Test RE 0.29119933172235035\n",
      "48 Train Loss 0.6490978 Test MSE 0.12240394448389198 Test RE 0.16722675671118875\n",
      "49 Train Loss 0.44100916 Test MSE 0.08030018194339172 Test RE 0.13544604396947932\n",
      "50 Train Loss 0.33535987 Test MSE 0.0572589595686953 Test RE 0.11437465220497327\n",
      "51 Train Loss 0.27829447 Test MSE 0.043403541404321774 Test RE 0.09957966097257355\n",
      "52 Train Loss 0.23329955 Test MSE 0.03783846490339825 Test RE 0.09297684705787342\n",
      "53 Train Loss 0.19712754 Test MSE 0.037328469668618504 Test RE 0.0923481401096115\n",
      "54 Train Loss 0.17076927 Test MSE 0.02799198618862324 Test RE 0.07996959892296755\n",
      "55 Train Loss 0.15499575 Test MSE 0.023506901608963203 Test RE 0.07328342442155532\n",
      "56 Train Loss 0.1356938 Test MSE 0.023645753115760462 Test RE 0.0734995424792609\n",
      "57 Train Loss 0.12105429 Test MSE 0.020619704364460912 Test RE 0.06863557516621656\n",
      "58 Train Loss 0.108336955 Test MSE 0.01807940292353653 Test RE 0.06426878684533643\n",
      "59 Train Loss 0.099093586 Test MSE 0.016342509944284923 Test RE 0.06110369021403958\n",
      "60 Train Loss 0.09119095 Test MSE 0.014061716831069456 Test RE 0.05667965972463287\n",
      "61 Train Loss 0.08636508 Test MSE 0.01284720830233268 Test RE 0.05417668694017548\n",
      "62 Train Loss 0.07723023 Test MSE 0.011308142427491528 Test RE 0.050828078876667265\n",
      "63 Train Loss 0.06659725 Test MSE 0.008869164740642999 Test RE 0.04501418807849365\n",
      "64 Train Loss 0.061569452 Test MSE 0.010039980862731022 Test RE 0.047893271376210786\n",
      "65 Train Loss 0.05318965 Test MSE 0.008798019404105044 Test RE 0.04483328051978755\n",
      "66 Train Loss 0.04293704 Test MSE 0.006424711912540491 Test RE 0.0383120057754306\n",
      "67 Train Loss 0.040219054 Test MSE 0.0057376582861863555 Test RE 0.03620557091472314\n",
      "68 Train Loss 0.03821154 Test MSE 0.005982326509925758 Test RE 0.03696946081871146\n",
      "69 Train Loss 0.032855906 Test MSE 0.005587980166988398 Test RE 0.03573020338319557\n",
      "70 Train Loss 0.030119505 Test MSE 0.005396008963863024 Test RE 0.0351110964234726\n",
      "71 Train Loss 0.027704637 Test MSE 0.004841717181218056 Test RE 0.03325889139778931\n",
      "72 Train Loss 0.023926724 Test MSE 0.003933622969500309 Test RE 0.02997812222210811\n",
      "73 Train Loss 0.021288686 Test MSE 0.003950673294255979 Test RE 0.030043022193314627\n",
      "74 Train Loss 0.018669443 Test MSE 0.003329422391117344 Test RE 0.02757988863784089\n",
      "75 Train Loss 0.01683473 Test MSE 0.0027259754809835983 Test RE 0.024955658436399006\n",
      "76 Train Loss 0.014361987 Test MSE 0.0028354850586376225 Test RE 0.025451989878235097\n",
      "77 Train Loss 0.0133372005 Test MSE 0.002427001977055866 Test RE 0.023547408897697075\n",
      "78 Train Loss 0.0127439685 Test MSE 0.0020659643109614133 Test RE 0.02172548436533432\n",
      "79 Train Loss 0.011644754 Test MSE 0.002330423821644014 Test RE 0.02307413959860238\n",
      "80 Train Loss 0.010623757 Test MSE 0.0022835702502084147 Test RE 0.022841007085508472\n",
      "81 Train Loss 0.009974638 Test MSE 0.00243243483954155 Test RE 0.0235737496923657\n",
      "82 Train Loss 0.0090751 Test MSE 0.0027304279857724256 Test RE 0.02497603093308077\n",
      "83 Train Loss 0.008664374 Test MSE 0.0023081840419964016 Test RE 0.022963774702103524\n",
      "84 Train Loss 0.008203212 Test MSE 0.001996860195245086 Test RE 0.02135904792831973\n",
      "85 Train Loss 0.007836896 Test MSE 0.0018445648575702734 Test RE 0.020528396406568263\n",
      "86 Train Loss 0.007490635 Test MSE 0.0015173797240710966 Test RE 0.018618950552056604\n",
      "87 Train Loss 0.0069846264 Test MSE 0.0013286982476008336 Test RE 0.0174229319908854\n",
      "88 Train Loss 0.0066207554 Test MSE 0.0012959760508152358 Test RE 0.01720705505579759\n",
      "89 Train Loss 0.006106056 Test MSE 0.001090559073697096 Test RE 0.015784566460588966\n",
      "90 Train Loss 0.005828049 Test MSE 0.0010399988471324051 Test RE 0.01541432420783504\n",
      "91 Train Loss 0.0054688696 Test MSE 0.001036285668496177 Test RE 0.01538678219688697\n",
      "92 Train Loss 0.0053305198 Test MSE 0.0010608045965838314 Test RE 0.0155677467028903\n",
      "93 Train Loss 0.005174358 Test MSE 0.0010734900500842717 Test RE 0.015660552219030868\n",
      "94 Train Loss 0.0048834416 Test MSE 0.0011021040504213583 Test RE 0.015867896516411375\n",
      "95 Train Loss 0.0046144035 Test MSE 0.001131448813523511 Test RE 0.016077759055725397\n",
      "96 Train Loss 0.004475044 Test MSE 0.0011369887391787224 Test RE 0.016117071849552595\n",
      "97 Train Loss 0.004267508 Test MSE 0.0010447654453997481 Test RE 0.0154496078506591\n",
      "98 Train Loss 0.00410621 Test MSE 0.000917114902813634 Test RE 0.014475045435503977\n",
      "99 Train Loss 0.0038363377 Test MSE 0.0008765636788359532 Test RE 0.014151412680178485\n",
      "Training time: 79.11\n",
      "KG_stan_tune10\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 62.258827 Test MSE 6.359749372010682 Test RE 1.205391322873468\n",
      "1 Train Loss 58.010357 Test MSE 8.187820829907709 Test RE 1.3677043418028862\n",
      "2 Train Loss 43.958496 Test MSE 7.5877307650324495 Test RE 1.3166308186717848\n",
      "3 Train Loss 40.920105 Test MSE 7.570021316836391 Test RE 1.3150934403031578\n",
      "4 Train Loss 36.043793 Test MSE 7.573031981177454 Test RE 1.3153549264453899\n",
      "5 Train Loss 34.581757 Test MSE 7.7135143151972505 Test RE 1.3274990079563762\n",
      "6 Train Loss 33.61121 Test MSE 7.615906511235296 Test RE 1.3190730957062506\n",
      "7 Train Loss 33.26657 Test MSE 7.471922809911754 Test RE 1.3065446279729729\n",
      "8 Train Loss 32.286163 Test MSE 7.436048247188947 Test RE 1.3034043309861532\n",
      "9 Train Loss 31.789673 Test MSE 7.6185999009319305 Test RE 1.3193063222973702\n",
      "10 Train Loss 31.154358 Test MSE 7.761623922356958 Test RE 1.3316324145620613\n",
      "11 Train Loss 30.423897 Test MSE 7.663803833950693 Test RE 1.3232144966085073\n",
      "12 Train Loss 30.01202 Test MSE 7.5537143268399385 Test RE 1.3136762199145748\n",
      "13 Train Loss 29.618214 Test MSE 7.600252218178849 Test RE 1.317716738545099\n",
      "14 Train Loss 29.026224 Test MSE 7.560423863492756 Test RE 1.3142595225095257\n",
      "15 Train Loss 27.745354 Test MSE 7.489632338735756 Test RE 1.3080920606950746\n",
      "16 Train Loss 25.25286 Test MSE 7.370799996991059 Test RE 1.2976733142939807\n",
      "17 Train Loss 21.433765 Test MSE 6.088246522764228 Test RE 1.1793811304172448\n",
      "18 Train Loss 19.337513 Test MSE 6.001145636288959 Test RE 1.1709143904318717\n",
      "19 Train Loss 18.717293 Test MSE 6.001618890522075 Test RE 1.1709605590554097\n",
      "20 Train Loss 18.245659 Test MSE 5.914046241945947 Test RE 1.1623861275642566\n",
      "21 Train Loss 17.65914 Test MSE 5.827950560657902 Test RE 1.15389419827486\n",
      "22 Train Loss 17.076086 Test MSE 5.804580009748083 Test RE 1.1515782698647983\n",
      "23 Train Loss 16.172264 Test MSE 5.632446545511153 Test RE 1.134374877092066\n",
      "24 Train Loss 14.294056 Test MSE 5.623674069963989 Test RE 1.1334911444581102\n",
      "25 Train Loss 13.228666 Test MSE 5.406481582907572 Test RE 1.1113872859513254\n",
      "26 Train Loss 12.303954 Test MSE 5.058089544928673 Test RE 1.074982308810192\n",
      "27 Train Loss 11.548843 Test MSE 4.998591454471596 Test RE 1.0686411204603992\n",
      "28 Train Loss 10.624092 Test MSE 4.960351154117033 Test RE 1.0645456052539564\n",
      "29 Train Loss 8.774762 Test MSE 3.4507667714671597 Test RE 0.8879036964099148\n",
      "30 Train Loss 6.205577 Test MSE 2.279610976231045 Test RE 0.7216696311739632\n",
      "31 Train Loss 4.115886 Test MSE 1.796594450959053 Test RE 0.6406680808584508\n",
      "32 Train Loss 3.1387348 Test MSE 1.8697418068891192 Test RE 0.6535801891470951\n",
      "33 Train Loss 2.4678042 Test MSE 1.790668309016065 Test RE 0.6396105728485018\n",
      "34 Train Loss 2.1138892 Test MSE 1.5682032479916328 Test RE 0.5985621279050377\n",
      "35 Train Loss 1.8809944 Test MSE 1.4971371764312928 Test RE 0.5848424094463178\n",
      "36 Train Loss 1.513707 Test MSE 1.4274430373588562 Test RE 0.5710675115962395\n",
      "37 Train Loss 1.2394171 Test MSE 1.1405917026494234 Test RE 0.5104734560306454\n",
      "38 Train Loss 1.0314246 Test MSE 0.9112640973426351 Test RE 0.45627869447823494\n",
      "39 Train Loss 0.8155977 Test MSE 0.7200165564369545 Test RE 0.40558258767320227\n",
      "40 Train Loss 0.67184967 Test MSE 0.508677991664731 Test RE 0.3409019883119245\n",
      "41 Train Loss 0.5255638 Test MSE 0.4443782457851627 Test RE 0.31862837992986637\n",
      "42 Train Loss 0.43872365 Test MSE 0.40816646077001234 Test RE 0.3053702454154258\n",
      "43 Train Loss 0.37636223 Test MSE 0.3261775622812227 Test RE 0.27298268533392384\n",
      "44 Train Loss 0.32493624 Test MSE 0.2573465705416259 Test RE 0.24247515902938457\n",
      "45 Train Loss 0.2728524 Test MSE 0.17911678466280573 Test RE 0.2022908329177285\n",
      "46 Train Loss 0.23927175 Test MSE 0.13034042553142267 Test RE 0.172562978224191\n",
      "47 Train Loss 0.21181485 Test MSE 0.10257741128481408 Test RE 0.15308545439730992\n",
      "48 Train Loss 0.16244996 Test MSE 0.05517761510810585 Test RE 0.11227666987843699\n",
      "49 Train Loss 0.13571823 Test MSE 0.03498733666822944 Test RE 0.08940534889481391\n",
      "50 Train Loss 0.107699715 Test MSE 0.022809948235635997 Test RE 0.07218886442176758\n",
      "51 Train Loss 0.08907249 Test MSE 0.017499566458428435 Test RE 0.06322978498648965\n",
      "52 Train Loss 0.06860475 Test MSE 0.01464200332011412 Test RE 0.057837339958805384\n",
      "53 Train Loss 0.06087075 Test MSE 0.010711965352991938 Test RE 0.04947008310491905\n",
      "54 Train Loss 0.052963275 Test MSE 0.009272198861755412 Test RE 0.046025596843210545\n",
      "55 Train Loss 0.0468381 Test MSE 0.007613565353585916 Test RE 0.04170634200710948\n",
      "56 Train Loss 0.04196857 Test MSE 0.006584942535187181 Test RE 0.03878680930355003\n",
      "57 Train Loss 0.037352607 Test MSE 0.005751058834681017 Test RE 0.036247826093444645\n",
      "58 Train Loss 0.033768617 Test MSE 0.006047928318540413 Test RE 0.037171610507094804\n",
      "59 Train Loss 0.030682707 Test MSE 0.006176458326404947 Test RE 0.03756451777222447\n",
      "60 Train Loss 0.028107196 Test MSE 0.005157188135892209 Test RE 0.03432531629026969\n",
      "61 Train Loss 0.025611859 Test MSE 0.004047058366215994 Test RE 0.030407295467337787\n",
      "62 Train Loss 0.023635078 Test MSE 0.003867722010741152 Test RE 0.02972594611985757\n",
      "63 Train Loss 0.021180293 Test MSE 0.0037999244789208523 Test RE 0.029464260324361634\n",
      "64 Train Loss 0.019770209 Test MSE 0.004396792425790949 Test RE 0.031693926156448005\n",
      "65 Train Loss 0.018464556 Test MSE 0.004753640893996143 Test RE 0.03295499465694856\n",
      "66 Train Loss 0.017188426 Test MSE 0.00402394424277514 Test RE 0.03032033793796377\n",
      "67 Train Loss 0.016179748 Test MSE 0.003478804159639301 Test RE 0.02819181589627578\n",
      "68 Train Loss 0.014922659 Test MSE 0.0034419530905367333 Test RE 0.02804210001007263\n",
      "69 Train Loss 0.013170897 Test MSE 0.0033401293696907045 Test RE 0.02762419966447598\n",
      "70 Train Loss 0.012136452 Test MSE 0.0034268943755781946 Test RE 0.027980689981424597\n",
      "71 Train Loss 0.011452181 Test MSE 0.0034566653353712076 Test RE 0.028101967519456407\n",
      "72 Train Loss 0.010902165 Test MSE 0.0030031867940440685 Test RE 0.026193843780045002\n",
      "73 Train Loss 0.010205833 Test MSE 0.0027534634488178113 Test RE 0.025081165745151988\n",
      "74 Train Loss 0.009742307 Test MSE 0.002873488870223761 Test RE 0.025621987793126348\n",
      "75 Train Loss 0.008658269 Test MSE 0.0025704727557469896 Test RE 0.0242334118278223\n",
      "76 Train Loss 0.007971209 Test MSE 0.0021044525842518493 Test RE 0.02192692003575901\n",
      "77 Train Loss 0.007521992 Test MSE 0.0020804782698222494 Test RE 0.021801664509024928\n",
      "78 Train Loss 0.0071961144 Test MSE 0.0020051662731392886 Test RE 0.021403424047329027\n",
      "79 Train Loss 0.006690932 Test MSE 0.002050799448802188 Test RE 0.021645601378766564\n",
      "80 Train Loss 0.006328113 Test MSE 0.002026724353548781 Test RE 0.02151817342284463\n",
      "81 Train Loss 0.0059279418 Test MSE 0.0018903428351763657 Test RE 0.02078156969598091\n",
      "82 Train Loss 0.005730263 Test MSE 0.0019087401822847612 Test RE 0.020882450874234265\n",
      "83 Train Loss 0.0055074454 Test MSE 0.0020701939575782664 Test RE 0.02174771227529658\n",
      "84 Train Loss 0.00518437 Test MSE 0.002043050067586995 Test RE 0.021604666421126125\n",
      "85 Train Loss 0.004842481 Test MSE 0.001776776601945284 Test RE 0.02014765351188288\n",
      "86 Train Loss 0.004588428 Test MSE 0.0016604056880138442 Test RE 0.019476690656068316\n",
      "87 Train Loss 0.0044639413 Test MSE 0.0017438325560004725 Test RE 0.019959996047495487\n",
      "88 Train Loss 0.004263477 Test MSE 0.001649731006774642 Test RE 0.019413982276572466\n",
      "89 Train Loss 0.004150777 Test MSE 0.0015447218832716613 Test RE 0.018785952062773427\n",
      "90 Train Loss 0.003954291 Test MSE 0.0014024722816304402 Test RE 0.017900089547631455\n",
      "91 Train Loss 0.0036809575 Test MSE 0.0012233541327310628 Test RE 0.016717993691018083\n",
      "92 Train Loss 0.003497451 Test MSE 0.0011832768829827403 Test RE 0.01644187152282983\n",
      "93 Train Loss 0.0033451484 Test MSE 0.0011516764603324155 Test RE 0.016220838687825683\n",
      "94 Train Loss 0.0032070372 Test MSE 0.0010676034605593841 Test RE 0.015617555094922197\n",
      "95 Train Loss 0.0030627311 Test MSE 0.001056305013830188 Test RE 0.015534694997012597\n",
      "96 Train Loss 0.0029094508 Test MSE 0.0010824964323538386 Test RE 0.015726109565921638\n",
      "97 Train Loss 0.0027903498 Test MSE 0.001022823095173472 Test RE 0.015286509240130185\n",
      "98 Train Loss 0.0026583471 Test MSE 0.0009518244208523918 Test RE 0.014746416020766578\n",
      "99 Train Loss 0.002586159 Test MSE 0.0009561913717211468 Test RE 0.01478020543555591\n",
      "Training time: 80.10\n",
      "KG_stan_tune10\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.61917 Test MSE 8.819043996914878 Test RE 1.4194458025671461\n",
      "1 Train Loss 50.371666 Test MSE 8.924673232040794 Test RE 1.4279211364768891\n",
      "2 Train Loss 45.921394 Test MSE 8.788717994764822 Test RE 1.4170031803365426\n",
      "3 Train Loss 44.860043 Test MSE 8.684830504119835 Test RE 1.4086034047615985\n",
      "4 Train Loss 43.49671 Test MSE 8.530187301922478 Test RE 1.3960061898328375\n",
      "5 Train Loss 43.31552 Test MSE 8.41828262522697 Test RE 1.3868190903873219\n",
      "6 Train Loss 42.923958 Test MSE 8.449130352737185 Test RE 1.389357678142168\n",
      "7 Train Loss 42.6146 Test MSE 8.410350916686303 Test RE 1.3861656057308271\n",
      "8 Train Loss 42.11267 Test MSE 8.433427655564437 Test RE 1.3880660180562698\n",
      "9 Train Loss 40.803017 Test MSE 8.396489931104247 Test RE 1.3850228743143016\n",
      "10 Train Loss 38.225693 Test MSE 7.94173951036795 Test RE 1.3469946764308787\n",
      "11 Train Loss 35.50932 Test MSE 7.550418102549 Test RE 1.3133895633259827\n",
      "12 Train Loss 33.989956 Test MSE 7.562601028999633 Test RE 1.3144487416978434\n",
      "13 Train Loss 33.136055 Test MSE 7.449795189368478 Test RE 1.3046085694407106\n",
      "14 Train Loss 31.781555 Test MSE 7.355458609771081 Test RE 1.2963221394788693\n",
      "15 Train Loss 30.516273 Test MSE 7.44984132135703 Test RE 1.3046126087527248\n",
      "16 Train Loss 29.089111 Test MSE 7.456951218427621 Test RE 1.3052350011581388\n",
      "17 Train Loss 27.390238 Test MSE 7.339721295547961 Test RE 1.2949346289498247\n",
      "18 Train Loss 23.06768 Test MSE 7.064053719737107 Test RE 1.2703841215619196\n",
      "19 Train Loss 18.889744 Test MSE 6.707548275466842 Test RE 1.2379125441682146\n",
      "20 Train Loss 15.904395 Test MSE 6.029424307161968 Test RE 1.1736699465149376\n",
      "21 Train Loss 11.990039 Test MSE 5.509505782249429 Test RE 1.1219264371249125\n",
      "22 Train Loss 9.453556 Test MSE 5.094691783305042 Test RE 1.0788647858574223\n",
      "23 Train Loss 7.64457 Test MSE 4.970808917218273 Test RE 1.0656671895794123\n",
      "24 Train Loss 6.744725 Test MSE 4.817224656831327 Test RE 1.049074934526205\n",
      "25 Train Loss 5.9461875 Test MSE 4.476068058420836 Test RE 1.011245031777843\n",
      "26 Train Loss 5.162637 Test MSE 3.9226326190902405 Test RE 0.9466662147346521\n",
      "27 Train Loss 4.3010755 Test MSE 3.5698557608244683 Test RE 0.9030949104262412\n",
      "28 Train Loss 3.466352 Test MSE 3.0469565382733355 Test RE 0.834336397801303\n",
      "29 Train Loss 2.8716857 Test MSE 2.581861794602536 Test RE 0.7680235831471648\n",
      "30 Train Loss 2.343816 Test MSE 2.4944350962990836 Test RE 0.7549082376134574\n",
      "31 Train Loss 1.8547819 Test MSE 2.3459428017317836 Test RE 0.7320938689578745\n",
      "32 Train Loss 1.5620278 Test MSE 2.174896683859545 Test RE 0.7048997812961383\n",
      "33 Train Loss 1.2917956 Test MSE 1.8335809577254065 Test RE 0.6472292042992941\n",
      "34 Train Loss 0.9432988 Test MSE 1.5632562925140034 Test RE 0.5976172889355753\n",
      "35 Train Loss 0.77898026 Test MSE 1.4801252023675426 Test RE 0.5815101332407778\n",
      "36 Train Loss 0.5994234 Test MSE 1.4317387843395761 Test RE 0.5719261513494364\n",
      "37 Train Loss 0.5148266 Test MSE 1.3903402729763923 Test RE 0.5635969208174633\n",
      "38 Train Loss 0.42745003 Test MSE 1.3358422961782705 Test RE 0.5524406853688725\n",
      "39 Train Loss 0.34772095 Test MSE 1.2048771459605643 Test RE 0.5246617985337105\n",
      "40 Train Loss 0.30407387 Test MSE 1.064713421205293 Test RE 0.49320154065972693\n",
      "41 Train Loss 0.24213667 Test MSE 0.8182615315718016 Test RE 0.43236858101931674\n",
      "42 Train Loss 0.1979017 Test MSE 0.6795704266196004 Test RE 0.39402637735209\n",
      "43 Train Loss 0.1539812 Test MSE 0.4956702842636494 Test RE 0.3365150577625108\n",
      "44 Train Loss 0.123359695 Test MSE 0.31160101171773497 Test RE 0.26681330952595106\n",
      "45 Train Loss 0.10769544 Test MSE 0.24338885050656717 Test RE 0.23580792682445795\n",
      "46 Train Loss 0.09349387 Test MSE 0.20971127364456674 Test RE 0.21888648602832955\n",
      "47 Train Loss 0.08517103 Test MSE 0.180594044029764 Test RE 0.2031233132357909\n",
      "48 Train Loss 0.0782519 Test MSE 0.1622767966460211 Test RE 0.19254678581507698\n",
      "49 Train Loss 0.067340605 Test MSE 0.12432735880855811 Test RE 0.168535507876358\n",
      "50 Train Loss 0.061980497 Test MSE 0.13022557408863228 Test RE 0.17248693322571212\n",
      "51 Train Loss 0.05558189 Test MSE 0.1383120353707365 Test RE 0.1777616392272285\n",
      "52 Train Loss 0.0500914 Test MSE 0.11219389296398496 Test RE 0.1601004929490733\n",
      "53 Train Loss 0.046794645 Test MSE 0.09949130920600158 Test RE 0.15076503510647413\n",
      "54 Train Loss 0.041887555 Test MSE 0.08001583848806199 Test RE 0.13520602365081058\n",
      "55 Train Loss 0.037358828 Test MSE 0.060814623012218474 Test RE 0.11787238464978891\n",
      "56 Train Loss 0.034892615 Test MSE 0.05498782223261567 Test RE 0.11208340610809857\n",
      "57 Train Loss 0.0323687 Test MSE 0.050949742746599164 Test RE 0.10788946959838275\n",
      "58 Train Loss 0.028696228 Test MSE 0.04888814749552833 Test RE 0.10568414804692994\n",
      "59 Train Loss 0.02675592 Test MSE 0.04704963967728156 Test RE 0.10367790458693017\n",
      "60 Train Loss 0.025344135 Test MSE 0.042504706249754325 Test RE 0.09854317930498611\n",
      "61 Train Loss 0.023828175 Test MSE 0.04051615629519857 Test RE 0.096210435207004\n",
      "62 Train Loss 0.022117447 Test MSE 0.035395497854644305 Test RE 0.0899253367677475\n",
      "63 Train Loss 0.020360855 Test MSE 0.028028693153731254 Test RE 0.08002201534581208\n",
      "64 Train Loss 0.019044917 Test MSE 0.02620644436774433 Test RE 0.07737703975031195\n",
      "65 Train Loss 0.017215738 Test MSE 0.026676754273142946 Test RE 0.07806826982272529\n",
      "66 Train Loss 0.01605073 Test MSE 0.027171657126239063 Test RE 0.07878909700897015\n",
      "67 Train Loss 0.014609782 Test MSE 0.02923345745582711 Test RE 0.08172372459808465\n",
      "68 Train Loss 0.013447143 Test MSE 0.027655581272886195 Test RE 0.07948761307421519\n",
      "69 Train Loss 0.01233284 Test MSE 0.025646710868808247 Test RE 0.0765462462433126\n",
      "70 Train Loss 0.011390312 Test MSE 0.024165780831643547 Test RE 0.07430336401404745\n",
      "71 Train Loss 0.010855806 Test MSE 0.022061784846920753 Test RE 0.07099510122329981\n",
      "72 Train Loss 0.010239528 Test MSE 0.02162526594507987 Test RE 0.07028923049457396\n",
      "73 Train Loss 0.009635898 Test MSE 0.022031653464213364 Test RE 0.07094660307394438\n",
      "74 Train Loss 0.009009436 Test MSE 0.02163688194399419 Test RE 0.07030810586964996\n",
      "75 Train Loss 0.008345257 Test MSE 0.021513963608455863 Test RE 0.07010811253648133\n",
      "76 Train Loss 0.007861504 Test MSE 0.02171811167959748 Test RE 0.07043995847913748\n",
      "77 Train Loss 0.007517296 Test MSE 0.021134230488651956 Test RE 0.06948663487814201\n",
      "78 Train Loss 0.007163643 Test MSE 0.021027543515768524 Test RE 0.0693110264462914\n",
      "79 Train Loss 0.0067565143 Test MSE 0.020634713355024852 Test RE 0.0686605503862655\n",
      "80 Train Loss 0.006158594 Test MSE 0.01906036158666043 Test RE 0.06598931616693374\n",
      "81 Train Loss 0.005529052 Test MSE 0.016363493513269576 Test RE 0.061142905799457865\n",
      "82 Train Loss 0.0051908367 Test MSE 0.014540626306359997 Test RE 0.05763676763783962\n",
      "83 Train Loss 0.005047827 Test MSE 0.014308509860503091 Test RE 0.05717488027292067\n",
      "84 Train Loss 0.004655414 Test MSE 0.014394452746045169 Test RE 0.05734633131046861\n",
      "85 Train Loss 0.0042826724 Test MSE 0.013426403862917706 Test RE 0.05538445845085624\n",
      "86 Train Loss 0.0040299175 Test MSE 0.012817279948796816 Test RE 0.05411354620165652\n",
      "87 Train Loss 0.003863612 Test MSE 0.012634722313447085 Test RE 0.05372679214248576\n",
      "88 Train Loss 0.0037309942 Test MSE 0.012064352066007021 Test RE 0.05250009164274511\n",
      "89 Train Loss 0.0035508487 Test MSE 0.010628827703525098 Test RE 0.04927773569140263\n",
      "90 Train Loss 0.0033942163 Test MSE 0.00931269298251525 Test RE 0.04612599026914346\n",
      "91 Train Loss 0.003211911 Test MSE 0.008464092011951498 Test RE 0.04397423046844485\n",
      "92 Train Loss 0.003001466 Test MSE 0.008570744333734115 Test RE 0.04425041320081322\n",
      "93 Train Loss 0.0028432 Test MSE 0.008392057529408962 Test RE 0.0437867071382801\n",
      "94 Train Loss 0.0027519118 Test MSE 0.007818374693690719 Test RE 0.04226358179692196\n",
      "95 Train Loss 0.0026748825 Test MSE 0.00764440049430938 Test RE 0.04179071256089298\n",
      "96 Train Loss 0.002569897 Test MSE 0.00766328475335885 Test RE 0.04184229933044652\n",
      "97 Train Loss 0.0024502063 Test MSE 0.007599501570327093 Test RE 0.041667804210024494\n",
      "98 Train Loss 0.0023457927 Test MSE 0.007220865506054785 Test RE 0.04061651791678693\n",
      "99 Train Loss 0.0022313232 Test MSE 0.006661461219431068 Test RE 0.039011514633248465\n",
      "Training time: 79.61\n",
      "KG_stan_tune11\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.728638 Test MSE 8.58125364671314 Test RE 1.4001785810994445\n",
      "1 Train Loss 45.461708 Test MSE 8.925817638630676 Test RE 1.4280126843651764\n",
      "2 Train Loss 44.027584 Test MSE 8.57996816076035 Test RE 1.4000737026408923\n",
      "3 Train Loss 43.5027 Test MSE 8.811010834052817 Test RE 1.4187991770867938\n",
      "4 Train Loss 42.980316 Test MSE 8.736750699612358 Test RE 1.4128076310053965\n",
      "5 Train Loss 42.36007 Test MSE 8.719704840956474 Test RE 1.4114287272199997\n",
      "6 Train Loss 42.097046 Test MSE 8.87609769948374 Test RE 1.424029864095576\n",
      "7 Train Loss 41.82144 Test MSE 8.746219608229678 Test RE 1.4135730256050152\n",
      "8 Train Loss 41.453598 Test MSE 8.95993692305752 Test RE 1.430739398069273\n",
      "9 Train Loss 40.784714 Test MSE 8.850688556139561 Test RE 1.4219901551846803\n",
      "10 Train Loss 39.12553 Test MSE 8.704311852146777 Test RE 1.410182371763867\n",
      "11 Train Loss 37.16152 Test MSE 8.815304236786176 Test RE 1.4191448090750758\n",
      "12 Train Loss 33.733166 Test MSE 8.358278213669779 Test RE 1.381867719372541\n",
      "13 Train Loss 30.433113 Test MSE 7.490977753717484 Test RE 1.3082095462769068\n",
      "14 Train Loss 28.227577 Test MSE 7.056003272340885 Test RE 1.269660027690313\n",
      "15 Train Loss 25.377584 Test MSE 6.837971716775172 Test RE 1.2498897609416495\n",
      "16 Train Loss 22.858385 Test MSE 6.7087534131207 Test RE 1.238023746350736\n",
      "17 Train Loss 20.630981 Test MSE 6.478809125766127 Test RE 1.2166219647618401\n",
      "18 Train Loss 19.235012 Test MSE 6.363154145993421 Test RE 1.2057139406079382\n",
      "19 Train Loss 17.85693 Test MSE 6.392289322878292 Test RE 1.2084711085713822\n",
      "20 Train Loss 16.00906 Test MSE 6.259527630725808 Test RE 1.1958558728583155\n",
      "21 Train Loss 14.4956255 Test MSE 6.291710255297283 Test RE 1.1989261077143685\n",
      "22 Train Loss 12.529577 Test MSE 6.435406859094426 Test RE 1.2125399735641504\n",
      "23 Train Loss 11.432165 Test MSE 6.601961973185371 Test RE 1.2281306485911996\n",
      "24 Train Loss 10.130938 Test MSE 6.759016736544351 Test RE 1.2426528528403242\n",
      "25 Train Loss 9.233497 Test MSE 6.48964301138447 Test RE 1.2176387594638567\n",
      "26 Train Loss 8.305176 Test MSE 6.337449707447299 Test RE 1.2032761902890756\n",
      "27 Train Loss 7.578018 Test MSE 6.3506807326583266 Test RE 1.2045316066987752\n",
      "28 Train Loss 6.893053 Test MSE 6.362215769399566 Test RE 1.2056250337992735\n",
      "29 Train Loss 6.191781 Test MSE 6.263819635142045 Test RE 1.196265787109365\n",
      "30 Train Loss 5.6649504 Test MSE 6.065191254176918 Test RE 1.1771459433658178\n",
      "31 Train Loss 5.0295644 Test MSE 5.973995160326296 Test RE 1.1682626532710265\n",
      "32 Train Loss 4.6074615 Test MSE 6.038137762736313 Test RE 1.174517708115716\n",
      "33 Train Loss 4.198742 Test MSE 6.05011219311114 Test RE 1.1756817437167926\n",
      "34 Train Loss 3.7906833 Test MSE 5.794758742841306 Test RE 1.1506036303855565\n",
      "35 Train Loss 3.4448004 Test MSE 5.583555397386634 Test RE 1.12944080725647\n",
      "36 Train Loss 3.0526252 Test MSE 5.6892250937875355 Test RE 1.1400781405577398\n",
      "37 Train Loss 2.800423 Test MSE 5.763608948420762 Test RE 1.1475069214410167\n",
      "38 Train Loss 2.5599494 Test MSE 5.762742474667676 Test RE 1.1474206628129906\n",
      "39 Train Loss 2.4071524 Test MSE 5.84908182178217 Test RE 1.1559842277681784\n",
      "40 Train Loss 2.2118983 Test MSE 5.805521843260613 Test RE 1.151671691870597\n",
      "41 Train Loss 2.064176 Test MSE 5.6738367612203255 Test RE 1.138535243182669\n",
      "42 Train Loss 1.9060673 Test MSE 5.639802038998572 Test RE 1.1351153337151245\n",
      "43 Train Loss 1.8315604 Test MSE 5.717651082935626 Test RE 1.1429227694834039\n",
      "44 Train Loss 1.7535119 Test MSE 5.792582545865405 Test RE 1.150387557949912\n",
      "45 Train Loss 1.6757832 Test MSE 5.753939064771106 Test RE 1.1465439035986633\n",
      "46 Train Loss 1.6100017 Test MSE 5.788056479428026 Test RE 1.1499380392810583\n",
      "47 Train Loss 1.5640244 Test MSE 5.827146212802528 Test RE 1.1538145678507141\n",
      "48 Train Loss 1.516082 Test MSE 5.7636606423030665 Test RE 1.1475120674315984\n",
      "49 Train Loss 1.4667826 Test MSE 5.799397679934603 Test RE 1.151064090457193\n",
      "50 Train Loss 1.4098037 Test MSE 5.829586457651422 Test RE 1.1540561350984024\n",
      "51 Train Loss 1.3641001 Test MSE 5.790771123022923 Test RE 1.1502076726206472\n",
      "52 Train Loss 1.3178089 Test MSE 5.816022744722327 Test RE 1.1527127806446267\n",
      "53 Train Loss 1.2719723 Test MSE 5.780949108638334 Test RE 1.1492317964692356\n",
      "54 Train Loss 1.2375588 Test MSE 5.800906321736926 Test RE 1.1512137982871653\n",
      "55 Train Loss 1.1981261 Test MSE 5.820296418443835 Test RE 1.1531362155150007\n",
      "56 Train Loss 1.1611592 Test MSE 5.87625591412343 Test RE 1.1586663941847648\n",
      "57 Train Loss 1.1391438 Test MSE 5.913528409082527 Test RE 1.1623352372863636\n",
      "58 Train Loss 1.11626 Test MSE 5.9157160420440675 Test RE 1.162550212811932\n",
      "59 Train Loss 1.0929402 Test MSE 5.99092318036432 Test RE 1.169916687398601\n",
      "60 Train Loss 1.0747527 Test MSE 5.995099404870548 Test RE 1.1703243861305568\n",
      "61 Train Loss 1.0551203 Test MSE 6.021852309170144 Test RE 1.1729327435954269\n",
      "62 Train Loss 1.038319 Test MSE 6.03782141586497 Test RE 1.1744869403621794\n",
      "63 Train Loss 1.0200418 Test MSE 6.055009806757108 Test RE 1.1761575092848766\n",
      "64 Train Loss 1.0010905 Test MSE 6.0888710111432 Test RE 1.1794416150676348\n",
      "65 Train Loss 0.97894335 Test MSE 6.12179406944902 Test RE 1.182625988328739\n",
      "66 Train Loss 0.96605873 Test MSE 6.1649577718324045 Test RE 1.1867879097702156\n",
      "67 Train Loss 0.9523007 Test MSE 6.18075920936518 Test RE 1.1883078677844288\n",
      "68 Train Loss 0.9341819 Test MSE 6.201369673450236 Test RE 1.1902874945800392\n",
      "69 Train Loss 0.9200801 Test MSE 6.263829974493169 Test RE 1.1962667744148454\n",
      "70 Train Loss 0.9047729 Test MSE 6.283686323781944 Test RE 1.1981613577720476\n",
      "71 Train Loss 0.88985324 Test MSE 6.303914954653221 Test RE 1.2000883865626848\n",
      "72 Train Loss 0.873408 Test MSE 6.363878192855932 Test RE 1.2057825361930243\n",
      "73 Train Loss 0.8560934 Test MSE 6.390403587007335 Test RE 1.2082928449404045\n",
      "74 Train Loss 0.84474796 Test MSE 6.400513703876229 Test RE 1.2092482739573027\n",
      "75 Train Loss 0.8326309 Test MSE 6.436760093562391 Test RE 1.212667453043821\n",
      "76 Train Loss 0.8222697 Test MSE 6.419625109633821 Test RE 1.2110522860834314\n",
      "77 Train Loss 0.81294245 Test MSE 6.412259188458651 Test RE 1.2103573018857583\n",
      "78 Train Loss 0.80327415 Test MSE 6.398432422833977 Test RE 1.2090516498849213\n",
      "79 Train Loss 0.7927664 Test MSE 6.414148390952327 Test RE 1.2105355886305922\n",
      "80 Train Loss 0.78484136 Test MSE 6.446688435341603 Test RE 1.2136023284834956\n",
      "81 Train Loss 0.7784403 Test MSE 6.439538267034713 Test RE 1.212929124836324\n",
      "82 Train Loss 0.77005935 Test MSE 6.456229994904199 Test RE 1.214500105497683\n",
      "83 Train Loss 0.76160496 Test MSE 6.482249688736359 Test RE 1.2169449646235855\n",
      "84 Train Loss 0.7558559 Test MSE 6.484865600228804 Test RE 1.2171904888913159\n",
      "85 Train Loss 0.74934167 Test MSE 6.502201860331296 Test RE 1.218816385874367\n",
      "86 Train Loss 0.74326384 Test MSE 6.524978222222353 Test RE 1.2209491968878086\n",
      "87 Train Loss 0.73813957 Test MSE 6.537423017423468 Test RE 1.2221129727781053\n",
      "88 Train Loss 0.73194873 Test MSE 6.544375245053619 Test RE 1.2227626286039837\n",
      "89 Train Loss 0.7230645 Test MSE 6.541279713857387 Test RE 1.2224734071412267\n",
      "90 Train Loss 0.71693575 Test MSE 6.554128194810406 Test RE 1.2236734185758271\n",
      "91 Train Loss 0.7096292 Test MSE 6.594749238667766 Test RE 1.2274595904193413\n",
      "92 Train Loss 0.7045548 Test MSE 6.618922551915433 Test RE 1.2297071833959317\n",
      "93 Train Loss 0.69848776 Test MSE 6.6284076638906075 Test RE 1.2305879713602066\n",
      "94 Train Loss 0.6925114 Test MSE 6.63458703462527 Test RE 1.2311614490511764\n",
      "95 Train Loss 0.686787 Test MSE 6.650162323183707 Test RE 1.2326057329045286\n",
      "96 Train Loss 0.6813376 Test MSE 6.653492590433664 Test RE 1.2329143263282651\n",
      "97 Train Loss 0.6768628 Test MSE 6.662183826815784 Test RE 1.2337193210468569\n",
      "98 Train Loss 0.67048675 Test MSE 6.716120741016884 Test RE 1.2387033378948837\n",
      "99 Train Loss 0.66588366 Test MSE 6.709947569207894 Test RE 1.238133925375005\n",
      "Training time: 78.85\n",
      "KG_stan_tune11\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.50747 Test MSE 8.823868150613661 Test RE 1.419833978912445\n",
      "1 Train Loss 51.361042 Test MSE 8.9938841246068 Test RE 1.43344721182008\n",
      "2 Train Loss 44.42406 Test MSE 8.025961357196483 Test RE 1.3541182536952612\n",
      "3 Train Loss 39.70713 Test MSE 7.851574324479162 Test RE 1.3393264119836765\n",
      "4 Train Loss 34.472652 Test MSE 6.765562993666664 Test RE 1.2432544755832065\n",
      "5 Train Loss 30.966751 Test MSE 5.912915596870571 Test RE 1.1622750099877854\n",
      "6 Train Loss 25.330948 Test MSE 4.354504469586996 Test RE 0.9974185262047829\n",
      "7 Train Loss 21.302921 Test MSE 3.9231876960172474 Test RE 0.9467331919456617\n",
      "8 Train Loss 13.393854 Test MSE 3.669969768987767 Test RE 0.9156706704927557\n",
      "9 Train Loss 10.519822 Test MSE 3.7066860747146433 Test RE 0.9202396964339016\n",
      "10 Train Loss 8.74141 Test MSE 3.6927052347689435 Test RE 0.9185025816254166\n",
      "11 Train Loss 8.130432 Test MSE 3.739923731596215 Test RE 0.9243563587626447\n",
      "12 Train Loss 7.7010317 Test MSE 3.785708618547773 Test RE 0.9299972239309783\n",
      "13 Train Loss 7.369062 Test MSE 3.686438923767017 Test RE 0.9177229273771554\n",
      "14 Train Loss 7.2163143 Test MSE 3.7505911128551452 Test RE 0.9256736905009825\n",
      "15 Train Loss 7.0753613 Test MSE 3.7357708808050267 Test RE 0.9238430086864658\n",
      "16 Train Loss 6.981653 Test MSE 3.749082249768475 Test RE 0.9254874724725765\n",
      "17 Train Loss 6.8496237 Test MSE 3.7570038665411096 Test RE 0.9264647100987625\n",
      "18 Train Loss 6.7431383 Test MSE 3.7150119018532375 Test RE 0.921272621655746\n",
      "19 Train Loss 6.6471334 Test MSE 3.6708456160009804 Test RE 0.9157799274661066\n",
      "20 Train Loss 6.5537467 Test MSE 3.614619386263869 Test RE 0.9087393769236404\n",
      "21 Train Loss 6.4617543 Test MSE 3.5327317077781646 Test RE 0.8983868542655953\n",
      "22 Train Loss 6.030512 Test MSE 2.7841367947540525 Test RE 0.7975415999969104\n",
      "23 Train Loss 5.113073 Test MSE 2.6943738334820666 Test RE 0.7845795541078634\n",
      "24 Train Loss 4.4539127 Test MSE 2.1416926373967193 Test RE 0.6994982496908784\n",
      "25 Train Loss 3.8518426 Test MSE 2.1647153608669116 Test RE 0.703247925530513\n",
      "26 Train Loss 3.5595748 Test MSE 2.168065114187054 Test RE 0.7037918299383036\n",
      "27 Train Loss 3.4915113 Test MSE 2.168286152403998 Test RE 0.703827705458218\n",
      "28 Train Loss 3.4388716 Test MSE 2.152760556367766 Test RE 0.7013033671103924\n",
      "29 Train Loss 3.3901565 Test MSE 2.1574983795940277 Test RE 0.7020746617271904\n",
      "30 Train Loss 3.3129022 Test MSE 2.142620577768802 Test RE 0.6996497705863589\n",
      "31 Train Loss 3.2201385 Test MSE 2.1400338218400434 Test RE 0.6992273043353435\n",
      "32 Train Loss 3.004801 Test MSE 2.0616489360686447 Test RE 0.6863022416235621\n",
      "33 Train Loss 2.755825 Test MSE 2.0181803929987434 Test RE 0.6790285763458004\n",
      "34 Train Loss 2.50529 Test MSE 2.0087743482794584 Test RE 0.6774443689971998\n",
      "35 Train Loss 2.3469574 Test MSE 1.9999580052859698 Test RE 0.6759561108380359\n",
      "36 Train Loss 2.2132652 Test MSE 2.0021860141343852 Test RE 0.676332522988698\n",
      "37 Train Loss 2.0855966 Test MSE 1.9819728188050356 Test RE 0.6729098838626114\n",
      "38 Train Loss 1.9465914 Test MSE 1.9181149511159459 Test RE 0.6619807727840284\n",
      "39 Train Loss 1.6864166 Test MSE 1.7945432622450581 Test RE 0.640302248035299\n",
      "40 Train Loss 1.4934735 Test MSE 1.7264181855603433 Test RE 0.6280309710957872\n",
      "41 Train Loss 1.2925919 Test MSE 1.5409432553989924 Test RE 0.5933369344290484\n",
      "42 Train Loss 1.0978833 Test MSE 1.2759795664864917 Test RE 0.5399206277910436\n",
      "43 Train Loss 0.90624326 Test MSE 1.0140202474494022 Test RE 0.4813171912713408\n",
      "44 Train Loss 0.6447115 Test MSE 0.5818356770313765 Test RE 0.3645929227853004\n",
      "45 Train Loss 0.41417384 Test MSE 0.39256657448062365 Test RE 0.29947785886636025\n",
      "46 Train Loss 0.2975881 Test MSE 0.28628327600487485 Test RE 0.255744350904852\n",
      "47 Train Loss 0.21126345 Test MSE 0.14115180512773556 Test RE 0.17957723426177294\n",
      "48 Train Loss 0.15938526 Test MSE 0.08797803728169824 Test RE 0.1417735436591379\n",
      "49 Train Loss 0.12466855 Test MSE 0.06067175903122646 Test RE 0.11773385201762201\n",
      "50 Train Loss 0.094115816 Test MSE 0.03543680838293002 Test RE 0.08997779795786333\n",
      "51 Train Loss 0.07436894 Test MSE 0.024263171246480603 Test RE 0.07445293830812488\n",
      "52 Train Loss 0.061655752 Test MSE 0.01636026521977254 Test RE 0.06113687417236572\n",
      "53 Train Loss 0.052163467 Test MSE 0.013433619161794638 Test RE 0.05539933815175773\n",
      "54 Train Loss 0.044870965 Test MSE 0.010581876027348 Test RE 0.04916877574253791\n",
      "55 Train Loss 0.039735742 Test MSE 0.008064351770610087 Test RE 0.04292326920171879\n",
      "56 Train Loss 0.03364923 Test MSE 0.007203984199888522 Test RE 0.04056901245601288\n",
      "57 Train Loss 0.02995342 Test MSE 0.00583810706599414 Test RE 0.03652112002391661\n",
      "58 Train Loss 0.026149247 Test MSE 0.004732251850717105 Test RE 0.032880770445435366\n",
      "59 Train Loss 0.022917558 Test MSE 0.004136867000201026 Test RE 0.03074282971963466\n",
      "60 Train Loss 0.020731535 Test MSE 0.0034249352884337145 Test RE 0.027972690836913783\n",
      "61 Train Loss 0.018542629 Test MSE 0.002703110454809274 Test RE 0.02485077609591894\n",
      "62 Train Loss 0.017046742 Test MSE 0.0028148825438166075 Test RE 0.02535935475835824\n",
      "63 Train Loss 0.015953666 Test MSE 0.0026908038783171467 Test RE 0.024794141920959592\n",
      "64 Train Loss 0.014041218 Test MSE 0.0024680919346786907 Test RE 0.023745905038233536\n",
      "65 Train Loss 0.012816226 Test MSE 0.0024338454727765245 Test RE 0.02358058422179277\n",
      "66 Train Loss 0.011315699 Test MSE 0.0017059343459207845 Test RE 0.019741912231526455\n",
      "67 Train Loss 0.00978726 Test MSE 0.0017094678445235408 Test RE 0.019762347348036297\n",
      "68 Train Loss 0.009079241 Test MSE 0.0017115962124303783 Test RE 0.019774646047303123\n",
      "69 Train Loss 0.008245726 Test MSE 0.0014214074190035033 Test RE 0.018020521261765374\n",
      "70 Train Loss 0.0076425127 Test MSE 0.0013865615517248769 Test RE 0.01779826369829772\n",
      "71 Train Loss 0.00696336 Test MSE 0.0015160815016133711 Test RE 0.018610983952899535\n",
      "72 Train Loss 0.0064335642 Test MSE 0.0017552212979282935 Test RE 0.02002506803564897\n",
      "73 Train Loss 0.005635419 Test MSE 0.001905751955466037 Test RE 0.020866098218536345\n",
      "74 Train Loss 0.005301133 Test MSE 0.0019589243311640037 Test RE 0.02115518806804939\n",
      "75 Train Loss 0.0049052765 Test MSE 0.002052486489909855 Test RE 0.021654502666620848\n",
      "76 Train Loss 0.0045563774 Test MSE 0.0020978112704504045 Test RE 0.021892293779381462\n",
      "77 Train Loss 0.0042712456 Test MSE 0.002231839694658459 Test RE 0.022580812210675698\n",
      "78 Train Loss 0.003942293 Test MSE 0.002279069746350959 Test RE 0.02281848823841854\n",
      "79 Train Loss 0.0035840906 Test MSE 0.0018552661130119008 Test RE 0.02058785810442045\n",
      "80 Train Loss 0.003227116 Test MSE 0.0014524179252444992 Test RE 0.01821603534893878\n",
      "81 Train Loss 0.0030133585 Test MSE 0.0014309011797780321 Test RE 0.018080601783081605\n",
      "82 Train Loss 0.0028199493 Test MSE 0.0014210627271533504 Test RE 0.018018336137587933\n",
      "83 Train Loss 0.0026705672 Test MSE 0.0014176653029894383 Test RE 0.017996784463121196\n",
      "84 Train Loss 0.0024946718 Test MSE 0.0013688667770706527 Test RE 0.017684331683427697\n",
      "85 Train Loss 0.002248262 Test MSE 0.0013165924595068407 Test RE 0.017343380089587898\n",
      "86 Train Loss 0.0020384097 Test MSE 0.001233532264632306 Test RE 0.016787395298692727\n",
      "87 Train Loss 0.0019267072 Test MSE 0.001258134908106346 Test RE 0.01695397999953418\n",
      "88 Train Loss 0.0018454351 Test MSE 0.0012668337463841214 Test RE 0.017012489577845763\n",
      "89 Train Loss 0.0017801299 Test MSE 0.0012547427301899618 Test RE 0.016931108949022316\n",
      "90 Train Loss 0.0017185141 Test MSE 0.0012622617724524002 Test RE 0.01698176298757318\n",
      "91 Train Loss 0.0016296946 Test MSE 0.0012536731400633952 Test RE 0.016923891051900227\n",
      "92 Train Loss 0.0015591783 Test MSE 0.0012409023563651985 Test RE 0.016837471162053082\n",
      "93 Train Loss 0.0014792258 Test MSE 0.001181064494272222 Test RE 0.01642649353714443\n",
      "94 Train Loss 0.001419595 Test MSE 0.0011036488901002659 Test RE 0.015879013784313074\n",
      "95 Train Loss 0.0013352379 Test MSE 0.0010817832803689525 Test RE 0.015720928507739103\n",
      "96 Train Loss 0.0012743949 Test MSE 0.0010534655657446906 Test RE 0.015513801579752452\n",
      "97 Train Loss 0.0012172012 Test MSE 0.0010012527678643951 Test RE 0.01512446165249365\n",
      "98 Train Loss 0.0011589634 Test MSE 0.0009670392681699687 Test RE 0.014863808969545035\n",
      "99 Train Loss 0.0011230765 Test MSE 0.0009857233868338364 Test RE 0.015006713474172062\n",
      "Training time: 79.62\n",
      "KG_stan_tune11\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 50.156815 Test MSE 7.523939939651097 Test RE 1.3110846124897826\n",
      "1 Train Loss 43.834633 Test MSE 8.24555555790881 Test RE 1.3725179136165133\n",
      "2 Train Loss 41.98637 Test MSE 8.124797416597172 Test RE 1.3624304167114567\n",
      "3 Train Loss 39.946457 Test MSE 7.750803298762771 Test RE 1.330703864121617\n",
      "4 Train Loss 31.35876 Test MSE 6.708794139622926 Test RE 1.238027504150228\n",
      "5 Train Loss 26.72007 Test MSE 6.290210171672767 Test RE 1.1987831738727774\n",
      "6 Train Loss 24.029484 Test MSE 5.819495582968469 Test RE 1.1530568807104582\n",
      "7 Train Loss 22.717112 Test MSE 5.874409382705971 Test RE 1.1584843325085041\n",
      "8 Train Loss 21.566643 Test MSE 5.745118192918359 Test RE 1.1456647323258116\n",
      "9 Train Loss 19.294147 Test MSE 6.030686348262932 Test RE 1.1737927726865778\n",
      "10 Train Loss 15.781265 Test MSE 5.710396929902807 Test RE 1.1421975094104382\n",
      "11 Train Loss 13.048699 Test MSE 6.0309446173935894 Test RE 1.1738179067406327\n",
      "12 Train Loss 11.861322 Test MSE 6.001655376671936 Test RE 1.1709641184098343\n",
      "13 Train Loss 11.224995 Test MSE 6.019602602039477 Test RE 1.1727136248325352\n",
      "14 Train Loss 10.802007 Test MSE 5.948940580402602 Test RE 1.1658102672829844\n",
      "15 Train Loss 10.341187 Test MSE 5.8304431708495095 Test RE 1.1541409317480094\n",
      "16 Train Loss 9.791921 Test MSE 5.568877699125743 Test RE 1.1279553290023392\n",
      "17 Train Loss 8.2670555 Test MSE 4.690011394134296 Test RE 1.0351302711270842\n",
      "18 Train Loss 6.9635653 Test MSE 4.657547631956941 Test RE 1.031541519046668\n",
      "19 Train Loss 6.133651 Test MSE 4.502531715263437 Test RE 1.0142299956827932\n",
      "20 Train Loss 5.265807 Test MSE 3.9893511179423204 Test RE 0.9546830045259698\n",
      "21 Train Loss 4.6401854 Test MSE 3.8933069399691167 Test RE 0.9431209284644437\n",
      "22 Train Loss 3.6107488 Test MSE 3.2314128722506297 Test RE 0.8592198181620939\n",
      "23 Train Loss 2.490072 Test MSE 2.8078766748813178 Test RE 0.8009346359234726\n",
      "24 Train Loss 1.9556007 Test MSE 2.430503006708395 Test RE 0.7451713373342553\n",
      "25 Train Loss 1.6285186 Test MSE 1.9906861484184348 Test RE 0.6743874156207093\n",
      "26 Train Loss 1.4418287 Test MSE 1.6194055598421437 Test RE 0.6082552600185209\n",
      "27 Train Loss 1.1954457 Test MSE 1.0417692464163801 Test RE 0.4878584443711781\n",
      "28 Train Loss 0.8923943 Test MSE 0.8110420847020224 Test RE 0.430456980929634\n",
      "29 Train Loss 0.69099927 Test MSE 0.7740600575570797 Test RE 0.42052845657854415\n",
      "30 Train Loss 0.48882878 Test MSE 0.5344449508360513 Test RE 0.34942948609471347\n",
      "31 Train Loss 0.3694169 Test MSE 0.5008403030273071 Test RE 0.33826549153689844\n",
      "32 Train Loss 0.29405624 Test MSE 0.4810277728164699 Test RE 0.3315073304153262\n",
      "33 Train Loss 0.24547565 Test MSE 0.456653986295187 Test RE 0.3229993786133109\n",
      "34 Train Loss 0.20814164 Test MSE 0.4357878080620534 Test RE 0.31553358967775696\n",
      "35 Train Loss 0.18362208 Test MSE 0.41653142895035966 Test RE 0.3084835061873509\n",
      "36 Train Loss 0.17147699 Test MSE 0.40883431047521385 Test RE 0.3056199696002163\n",
      "37 Train Loss 0.15945268 Test MSE 0.3957144739344612 Test RE 0.3006761828117035\n",
      "38 Train Loss 0.15198675 Test MSE 0.38173619638085793 Test RE 0.29531787260870135\n",
      "39 Train Loss 0.14487909 Test MSE 0.37425938972474765 Test RE 0.2924114759007588\n",
      "40 Train Loss 0.1388894 Test MSE 0.3643214608666276 Test RE 0.28850306916156027\n",
      "41 Train Loss 0.13356693 Test MSE 0.3549374127638122 Test RE 0.2847632559219608\n",
      "42 Train Loss 0.12920259 Test MSE 0.3393339557798997 Test RE 0.27843364975759444\n",
      "43 Train Loss 0.12564045 Test MSE 0.32357894675762505 Test RE 0.27189310152797386\n",
      "44 Train Loss 0.123009205 Test MSE 0.3213958767019594 Test RE 0.27097436713226647\n",
      "45 Train Loss 0.12005152 Test MSE 0.3171284302851646 Test RE 0.2691693769385038\n",
      "46 Train Loss 0.11828077 Test MSE 0.31554411700251067 Test RE 0.26849617559952826\n",
      "47 Train Loss 0.11554624 Test MSE 0.3069230269742766 Test RE 0.26480293636633306\n",
      "48 Train Loss 0.114192314 Test MSE 0.2918930768808145 Test RE 0.25823788583589524\n",
      "49 Train Loss 0.111292884 Test MSE 0.271118161967373 Test RE 0.2488784916679619\n",
      "50 Train Loss 0.10921804 Test MSE 0.2608084371182659 Test RE 0.2441006178129111\n",
      "51 Train Loss 0.106706545 Test MSE 0.23481676846341407 Test RE 0.23161816350952846\n",
      "52 Train Loss 0.10314123 Test MSE 0.1938261420262785 Test RE 0.2104331886646117\n",
      "53 Train Loss 0.081713215 Test MSE 0.09363890349407143 Test RE 0.1462635870251509\n",
      "54 Train Loss 0.06158891 Test MSE 0.04280796680325042 Test RE 0.09889409508404498\n",
      "55 Train Loss 0.050474588 Test MSE 0.029134334790134258 Test RE 0.08158505554219742\n",
      "56 Train Loss 0.039435256 Test MSE 0.019337006746193434 Test RE 0.0664664807775494\n",
      "57 Train Loss 0.030203192 Test MSE 0.018623116690209704 Test RE 0.06522802703586922\n",
      "58 Train Loss 0.02635436 Test MSE 0.01768733039981002 Test RE 0.0635680961410776\n",
      "59 Train Loss 0.022396836 Test MSE 0.013882179254975521 Test RE 0.0563166592589671\n",
      "60 Train Loss 0.019134304 Test MSE 0.011705313734368988 Test RE 0.05171298291353469\n",
      "61 Train Loss 0.01654352 Test MSE 0.010932042794561489 Test RE 0.04997568111925465\n",
      "62 Train Loss 0.014405392 Test MSE 0.010160842480936004 Test RE 0.04818067939109906\n",
      "63 Train Loss 0.012638686 Test MSE 0.008510250786307011 Test RE 0.04409397377547755\n",
      "64 Train Loss 0.011255974 Test MSE 0.007529013910933036 Test RE 0.04147411332943805\n",
      "65 Train Loss 0.010199812 Test MSE 0.007515264165242656 Test RE 0.041436225293087846\n",
      "66 Train Loss 0.00897118 Test MSE 0.007137789394671697 Test RE 0.040382195325811394\n",
      "67 Train Loss 0.008096305 Test MSE 0.0071475345274919794 Test RE 0.040409752571238765\n",
      "68 Train Loss 0.007302851 Test MSE 0.0064311822430865705 Test RE 0.03833129294061085\n",
      "69 Train Loss 0.0068724044 Test MSE 0.00625578166575956 Test RE 0.03780496599353538\n",
      "70 Train Loss 0.006284407 Test MSE 0.005785405656442877 Test RE 0.036355905694562506\n",
      "71 Train Loss 0.0059459913 Test MSE 0.005042031552730373 Test RE 0.033939921996251336\n",
      "72 Train Loss 0.0055957055 Test MSE 0.004732245078892836 Test RE 0.03288074691933342\n",
      "73 Train Loss 0.004882011 Test MSE 0.004324264050999892 Test RE 0.031431431653099945\n",
      "74 Train Loss 0.004673519 Test MSE 0.004276090510074598 Test RE 0.03125586373575583\n",
      "75 Train Loss 0.004493733 Test MSE 0.004096370098613255 Test RE 0.030591984739771923\n",
      "76 Train Loss 0.004341348 Test MSE 0.004056916282055475 Test RE 0.030444306330350192\n",
      "77 Train Loss 0.0041042767 Test MSE 0.004014865690537473 Test RE 0.03028611527121319\n",
      "78 Train Loss 0.0037835701 Test MSE 0.003741017468059939 Test RE 0.029234988565753715\n",
      "79 Train Loss 0.0035350858 Test MSE 0.003672251569676106 Test RE 0.028965049354794683\n",
      "80 Train Loss 0.0033949774 Test MSE 0.0037611798459126046 Test RE 0.029313664328641756\n",
      "81 Train Loss 0.003237173 Test MSE 0.0035811540434305665 Test RE 0.028603525276343585\n",
      "82 Train Loss 0.002908295 Test MSE 0.003096815361332282 Test RE 0.026599024933649983\n",
      "83 Train Loss 0.0026356308 Test MSE 0.0028589437699025944 Test RE 0.025557058503277632\n",
      "84 Train Loss 0.002517931 Test MSE 0.002606246323498144 Test RE 0.024401458768712414\n",
      "85 Train Loss 0.002380153 Test MSE 0.0023323593778736256 Test RE 0.0230837198355981\n",
      "86 Train Loss 0.002225296 Test MSE 0.0021741728582208904 Test RE 0.022287178695408666\n",
      "87 Train Loss 0.0021191738 Test MSE 0.002054986019166732 Test RE 0.021667684140529924\n",
      "88 Train Loss 0.001991725 Test MSE 0.0019397840215967122 Test RE 0.021051582533874895\n",
      "89 Train Loss 0.0019145878 Test MSE 0.0018726640748702075 Test RE 0.020684165299385965\n",
      "90 Train Loss 0.0018385953 Test MSE 0.0018622502217622871 Test RE 0.020626572974350842\n",
      "91 Train Loss 0.0017093344 Test MSE 0.0017023256089111541 Test RE 0.019721020136095745\n",
      "92 Train Loss 0.0016289015 Test MSE 0.0016505461518807113 Test RE 0.01941877798515141\n",
      "93 Train Loss 0.0015095754 Test MSE 0.0016568489566817861 Test RE 0.01945581910234065\n",
      "94 Train Loss 0.001401064 Test MSE 0.0015838047625550352 Test RE 0.01902211848866158\n",
      "95 Train Loss 0.0013229853 Test MSE 0.0015306256233124018 Test RE 0.018700040621537937\n",
      "96 Train Loss 0.0012665064 Test MSE 0.0014147434898921763 Test RE 0.017978229180023626\n",
      "97 Train Loss 0.0012183685 Test MSE 0.0013673271731420827 Test RE 0.017674383846644416\n",
      "98 Train Loss 0.0011360417 Test MSE 0.0012676900230497129 Test RE 0.0170182381368528\n",
      "99 Train Loss 0.0010844539 Test MSE 0.001147194115043512 Test RE 0.016189242017662517\n",
      "Training time: 79.97\n",
      "KG_stan_tune11\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.280434 Test MSE 8.673996334680956 Test RE 1.4077245269070648\n",
      "1 Train Loss 44.71263 Test MSE 8.497386899634975 Test RE 1.3933196329314246\n",
      "2 Train Loss 42.63181 Test MSE 8.637644100077143 Test RE 1.404771582283601\n",
      "3 Train Loss 41.294205 Test MSE 8.702046812984245 Test RE 1.4099988807439383\n",
      "4 Train Loss 40.564865 Test MSE 8.700856421211542 Test RE 1.409902437429632\n",
      "5 Train Loss 40.353455 Test MSE 8.661473931837678 Test RE 1.406708013881844\n",
      "6 Train Loss 39.893562 Test MSE 8.930796929266982 Test RE 1.4284109391302158\n",
      "7 Train Loss 39.339027 Test MSE 8.9150728906162 Test RE 1.4271529168088501\n",
      "8 Train Loss 38.481216 Test MSE 8.973783070859099 Test RE 1.4318444606308087\n",
      "9 Train Loss 37.416573 Test MSE 9.289837361443825 Test RE 1.4568408669458843\n",
      "10 Train Loss 35.69552 Test MSE 9.337052227556901 Test RE 1.4605383143388229\n",
      "11 Train Loss 33.196007 Test MSE 9.225728948521718 Test RE 1.4518053943251101\n",
      "12 Train Loss 28.941946 Test MSE 8.87231819387882 Test RE 1.423726650786396\n",
      "13 Train Loss 25.974504 Test MSE 9.071162982077759 Test RE 1.4395924001810414\n",
      "14 Train Loss 24.390896 Test MSE 8.984406578033006 Test RE 1.4326917460253474\n",
      "15 Train Loss 22.386177 Test MSE 8.689108918704711 Test RE 1.4089503227187383\n",
      "16 Train Loss 19.723907 Test MSE 8.423819361307844 Test RE 1.3872750734848032\n",
      "17 Train Loss 17.830208 Test MSE 7.945276446750405 Test RE 1.347294592094163\n",
      "18 Train Loss 15.807593 Test MSE 7.632771891915132 Test RE 1.320532827860844\n",
      "19 Train Loss 13.363638 Test MSE 7.334543760256012 Test RE 1.294477816472748\n",
      "20 Train Loss 10.621586 Test MSE 6.846145661280812 Test RE 1.2506365816834635\n",
      "21 Train Loss 9.42144 Test MSE 6.4425643117779305 Test RE 1.213214079017704\n",
      "22 Train Loss 8.642359 Test MSE 6.2080513292672155 Test RE 1.1909285586249716\n",
      "23 Train Loss 8.232093 Test MSE 6.035784354306263 Test RE 1.1742887973678464\n",
      "24 Train Loss 7.948607 Test MSE 5.937498370108172 Test RE 1.1646885661565283\n",
      "25 Train Loss 7.743895 Test MSE 5.972320080247288 Test RE 1.1680988541179482\n",
      "26 Train Loss 7.527663 Test MSE 6.056203978258153 Test RE 1.1762734846985674\n",
      "27 Train Loss 7.255488 Test MSE 6.089931645565661 Test RE 1.1795443354161148\n",
      "28 Train Loss 7.065733 Test MSE 6.102288406574191 Test RE 1.1807404047870556\n",
      "29 Train Loss 6.862249 Test MSE 6.132832614533485 Test RE 1.1836917372442282\n",
      "30 Train Loss 6.667306 Test MSE 6.147976376385485 Test RE 1.1851522771517478\n",
      "31 Train Loss 6.5212398 Test MSE 6.232693208233258 Test RE 1.1932898191645893\n",
      "32 Train Loss 6.3860598 Test MSE 6.291159777447012 Test RE 1.1988736580086334\n",
      "33 Train Loss 6.2575836 Test MSE 6.283815928229979 Test RE 1.1981737140731679\n",
      "34 Train Loss 6.128256 Test MSE 6.243586322527513 Test RE 1.1943321428724105\n",
      "35 Train Loss 5.984474 Test MSE 6.27589964364061 Test RE 1.197418752963413\n",
      "36 Train Loss 5.853222 Test MSE 6.31232071574994 Test RE 1.2008882304546526\n",
      "37 Train Loss 5.727717 Test MSE 6.363671546800423 Test RE 1.205762959119098\n",
      "38 Train Loss 5.5781126 Test MSE 6.3906703947395345 Test RE 1.2083180685827382\n",
      "39 Train Loss 5.4308677 Test MSE 6.362297274294421 Test RE 1.2056327562681795\n",
      "40 Train Loss 5.1368723 Test MSE 6.305950480929803 Test RE 1.2002821244461492\n",
      "41 Train Loss 4.7812796 Test MSE 6.131881739622275 Test RE 1.183599969991021\n",
      "42 Train Loss 4.3383684 Test MSE 6.000351366547089 Test RE 1.1708369008405632\n",
      "43 Train Loss 3.6236377 Test MSE 5.812784511679996 Test RE 1.1523918334525576\n",
      "44 Train Loss 2.8877099 Test MSE 5.627175668723006 Test RE 1.133843975498386\n",
      "45 Train Loss 2.3485236 Test MSE 5.709580223480871 Test RE 1.1421158274005176\n",
      "46 Train Loss 2.0092382 Test MSE 5.697895075879288 Test RE 1.140946509620302\n",
      "47 Train Loss 1.8325218 Test MSE 5.548073859710517 Test RE 1.125846487748894\n",
      "48 Train Loss 1.7119303 Test MSE 5.496414489945154 Test RE 1.1205927238373279\n",
      "49 Train Loss 1.6305429 Test MSE 5.457661389610431 Test RE 1.1166353022163475\n",
      "50 Train Loss 1.5604279 Test MSE 5.447148691265164 Test RE 1.1155593369236254\n",
      "51 Train Loss 1.5174166 Test MSE 5.4873604103777796 Test RE 1.1196693839562104\n",
      "52 Train Loss 1.4656619 Test MSE 5.518713222196743 Test RE 1.122863522811365\n",
      "53 Train Loss 1.4366083 Test MSE 5.526807662746453 Test RE 1.1236866876829747\n",
      "54 Train Loss 1.4113489 Test MSE 5.5617939722766625 Test RE 1.1272377095465587\n",
      "55 Train Loss 1.385349 Test MSE 5.565950342476636 Test RE 1.1276588274673274\n",
      "56 Train Loss 1.3601929 Test MSE 5.562939781551392 Test RE 1.1273538171292663\n",
      "57 Train Loss 1.3336722 Test MSE 5.578141891013211 Test RE 1.1288931528232202\n",
      "58 Train Loss 1.3131148 Test MSE 5.5724314807295 Test RE 1.1283151741821935\n",
      "59 Train Loss 1.2922564 Test MSE 5.537756811434795 Test RE 1.1247992037894077\n",
      "60 Train Loss 1.2735379 Test MSE 5.518405576500116 Test RE 1.1228322248501204\n",
      "61 Train Loss 1.244361 Test MSE 5.505523023914961 Test RE 1.1215208499571514\n",
      "62 Train Loss 1.2282115 Test MSE 5.50326461531587 Test RE 1.1212907980508344\n",
      "63 Train Loss 1.2100981 Test MSE 5.5127228131548724 Test RE 1.1222539388510007\n",
      "64 Train Loss 1.1912359 Test MSE 5.514755697469454 Test RE 1.1224608422470752\n",
      "65 Train Loss 1.1615741 Test MSE 5.491340201776951 Test RE 1.1200753389682085\n",
      "66 Train Loss 1.1411148 Test MSE 5.5025854205493765 Test RE 1.121221602909931\n",
      "67 Train Loss 1.1251733 Test MSE 5.515570961083844 Test RE 1.1225438076326135\n",
      "68 Train Loss 1.1093462 Test MSE 5.502811454532215 Test RE 1.1212446313195426\n",
      "69 Train Loss 1.0944488 Test MSE 5.488940756447772 Test RE 1.119830603340055\n",
      "70 Train Loss 1.0748857 Test MSE 5.46103261437583 Test RE 1.1169801245833775\n",
      "71 Train Loss 1.0602804 Test MSE 5.4378717877102485 Test RE 1.114608991433222\n",
      "72 Train Loss 1.0431973 Test MSE 5.432847446590984 Test RE 1.114093948951549\n",
      "73 Train Loss 1.0289243 Test MSE 5.4249851535478 Test RE 1.1132875113916463\n",
      "74 Train Loss 1.016554 Test MSE 5.398949339237941 Test RE 1.1106128305656349\n",
      "75 Train Loss 1.002184 Test MSE 5.379885218588743 Test RE 1.108650265305359\n",
      "76 Train Loss 0.98763466 Test MSE 5.3671412622640995 Test RE 1.1073363927116857\n",
      "77 Train Loss 0.977987 Test MSE 5.3386185804241135 Test RE 1.1043901056613852\n",
      "78 Train Loss 0.96626335 Test MSE 5.347097414566159 Test RE 1.105266758054917\n",
      "79 Train Loss 0.9538584 Test MSE 5.349651161438466 Test RE 1.1055306614754639\n",
      "80 Train Loss 0.9401573 Test MSE 5.329813797594466 Test RE 1.1034790153180245\n",
      "81 Train Loss 0.9279011 Test MSE 5.333550098962434 Test RE 1.1038657274998136\n",
      "82 Train Loss 0.9149648 Test MSE 5.311298280545477 Test RE 1.1015606312350483\n",
      "83 Train Loss 0.9045478 Test MSE 5.309100147247436 Test RE 1.1013326617674168\n",
      "84 Train Loss 0.8954072 Test MSE 5.33149667273665 Test RE 1.10365321191394\n",
      "85 Train Loss 0.8861202 Test MSE 5.353300394218546 Test RE 1.1059076627828408\n",
      "86 Train Loss 0.87592566 Test MSE 5.332269289986291 Test RE 1.1037331773224621\n",
      "87 Train Loss 0.8675592 Test MSE 5.337015389375216 Test RE 1.1042242686335648\n",
      "88 Train Loss 0.8610116 Test MSE 5.362605719521021 Test RE 1.1068684123855368\n",
      "89 Train Loss 0.8547777 Test MSE 5.35976770165648 Test RE 1.1065754831439907\n",
      "90 Train Loss 0.8483099 Test MSE 5.365357012520019 Test RE 1.1071523162348793\n",
      "91 Train Loss 0.84212214 Test MSE 5.366129998465706 Test RE 1.1072320669724534\n",
      "92 Train Loss 0.83582777 Test MSE 5.3655922014111255 Test RE 1.10717658182163\n",
      "93 Train Loss 0.8299535 Test MSE 5.383847861660906 Test RE 1.1090584874554927\n",
      "94 Train Loss 0.82409257 Test MSE 5.3801759459674505 Test RE 1.1086802204640758\n",
      "95 Train Loss 0.8188326 Test MSE 5.378429101277283 Test RE 1.1085002217611228\n",
      "96 Train Loss 0.8143542 Test MSE 5.386216606489401 Test RE 1.1093024382252175\n",
      "97 Train Loss 0.8076476 Test MSE 5.3907656322861826 Test RE 1.1097707799901293\n",
      "98 Train Loss 0.8028636 Test MSE 5.412374682925393 Test RE 1.1119928306620968\n",
      "99 Train Loss 0.7967161 Test MSE 5.408772562848299 Test RE 1.111622734483248\n",
      "Training time: 80.30\n",
      "KG_stan_tune11\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 49.327415 Test MSE 8.477836401856647 Test RE 1.3917158587930187\n",
      "1 Train Loss 44.691235 Test MSE 7.981594497605299 Test RE 1.3503703393603133\n",
      "2 Train Loss 43.892616 Test MSE 8.282294798712682 Test RE 1.3755722391462353\n",
      "3 Train Loss 43.10388 Test MSE 8.43669324158711 Test RE 1.388334735027323\n",
      "4 Train Loss 42.207664 Test MSE 8.15092412061209 Test RE 1.364619224886767\n",
      "5 Train Loss 41.304268 Test MSE 8.153637660370192 Test RE 1.36484635498447\n",
      "6 Train Loss 39.705536 Test MSE 7.81183260090387 Test RE 1.335932527980641\n",
      "7 Train Loss 37.38073 Test MSE 7.693825316650549 Test RE 1.3258036830202578\n",
      "8 Train Loss 34.202656 Test MSE 6.8877944371463995 Test RE 1.254434960091056\n",
      "9 Train Loss 26.168667 Test MSE 4.510644531724337 Test RE 1.0151433216922983\n",
      "10 Train Loss 19.202713 Test MSE 4.386283150786351 Test RE 1.001051433922946\n",
      "11 Train Loss 15.840358 Test MSE 3.499391925715825 Test RE 0.894137589516685\n",
      "12 Train Loss 14.0506525 Test MSE 3.326187216408446 Test RE 0.8717288220191026\n",
      "13 Train Loss 12.417227 Test MSE 3.323581797944583 Test RE 0.871387340442913\n",
      "14 Train Loss 11.012123 Test MSE 3.7328613226190726 Test RE 0.9234831768536217\n",
      "15 Train Loss 9.857702 Test MSE 3.8395772183637296 Test RE 0.9365905324039686\n",
      "16 Train Loss 9.152391 Test MSE 3.8650605173101016 Test RE 0.9396934710870208\n",
      "17 Train Loss 8.645228 Test MSE 3.8566646409188916 Test RE 0.9386722918103225\n",
      "18 Train Loss 8.418443 Test MSE 3.8239772532187053 Test RE 0.9346859411263477\n",
      "19 Train Loss 8.134644 Test MSE 3.7740498117053023 Test RE 0.9285640683483045\n",
      "20 Train Loss 7.818823 Test MSE 3.7607380141129467 Test RE 0.9269250099640405\n",
      "21 Train Loss 7.3987036 Test MSE 3.649427137034197 Test RE 0.9131043438876021\n",
      "22 Train Loss 6.661792 Test MSE 3.2103520836541763 Test RE 0.8564152510670896\n",
      "23 Train Loss 5.74288 Test MSE 2.8881783877229497 Test RE 0.8123067595450931\n",
      "24 Train Loss 5.1848593 Test MSE 2.262258718303428 Test RE 0.7189177320230778\n",
      "25 Train Loss 4.559979 Test MSE 1.851820513264016 Test RE 0.6504403960610284\n",
      "26 Train Loss 4.2808533 Test MSE 1.8242189118563092 Test RE 0.6455747521431533\n",
      "27 Train Loss 4.103444 Test MSE 1.7795326436848298 Test RE 0.6376186916601405\n",
      "28 Train Loss 4.0072412 Test MSE 1.7854001668744979 Test RE 0.6386690133878806\n",
      "29 Train Loss 3.9175982 Test MSE 1.7613255028513988 Test RE 0.6343484338983035\n",
      "30 Train Loss 3.8281002 Test MSE 1.7295471980466137 Test RE 0.6285998446061273\n",
      "31 Train Loss 3.7591689 Test MSE 1.7105814330456703 Test RE 0.6251438127524213\n",
      "32 Train Loss 3.6649723 Test MSE 1.6991256276554128 Test RE 0.6230469945981835\n",
      "33 Train Loss 3.5875869 Test MSE 1.6522105377516556 Test RE 0.6143852124201554\n",
      "34 Train Loss 3.4983552 Test MSE 1.6480518866181924 Test RE 0.6136115145514637\n",
      "35 Train Loss 3.4259398 Test MSE 1.5850215016739975 Test RE 0.6017632190679233\n",
      "36 Train Loss 3.144153 Test MSE 1.2807723998839815 Test RE 0.5409337020643991\n",
      "37 Train Loss 1.9710989 Test MSE 0.7038772283817726 Test RE 0.4010112143519934\n",
      "38 Train Loss 1.126329 Test MSE 0.3006460824243618 Test RE 0.2620811796289976\n",
      "39 Train Loss 0.65276515 Test MSE 0.2091271919015371 Test RE 0.21858145535067489\n",
      "40 Train Loss 0.36129037 Test MSE 0.09682461551002731 Test RE 0.1487308126272387\n",
      "41 Train Loss 0.28202534 Test MSE 0.09951499979639922 Test RE 0.15078298391087355\n",
      "42 Train Loss 0.22632673 Test MSE 0.09614285222301305 Test RE 0.1482062645469561\n",
      "43 Train Loss 0.17614385 Test MSE 0.06607996809226042 Test RE 0.1228691835870151\n",
      "44 Train Loss 0.14605856 Test MSE 0.045763631015312604 Test RE 0.10225117278881085\n",
      "45 Train Loss 0.11921043 Test MSE 0.02844604945636883 Test RE 0.08061559071804067\n",
      "46 Train Loss 0.09521326 Test MSE 0.02092699364618037 Test RE 0.06914511153516707\n",
      "47 Train Loss 0.07899047 Test MSE 0.01644036208076399 Test RE 0.06128634891273738\n",
      "48 Train Loss 0.06497695 Test MSE 0.014923135625134193 Test RE 0.058389949987832125\n",
      "49 Train Loss 0.05670554 Test MSE 0.015400087003461871 Test RE 0.059315698291941533\n",
      "50 Train Loss 0.050526924 Test MSE 0.013774782151647048 Test RE 0.05609839419998943\n",
      "51 Train Loss 0.042857666 Test MSE 0.013573015726813784 Test RE 0.0556860273593882\n",
      "52 Train Loss 0.037664544 Test MSE 0.010482736966686309 Test RE 0.048937908496521874\n",
      "53 Train Loss 0.032359347 Test MSE 0.007615247238129689 Test RE 0.04171094834955796\n",
      "54 Train Loss 0.029767632 Test MSE 0.008560320255995728 Test RE 0.04422349546367329\n",
      "55 Train Loss 0.026506785 Test MSE 0.007834311138205916 Test RE 0.0423066334785028\n",
      "56 Train Loss 0.0247126 Test MSE 0.007549354493590513 Test RE 0.041530099321129915\n",
      "57 Train Loss 0.022658912 Test MSE 0.007779177767758179 Test RE 0.04215750578436695\n",
      "58 Train Loss 0.020158306 Test MSE 0.006739020569720481 Test RE 0.039237962814491024\n",
      "59 Train Loss 0.018397339 Test MSE 0.006735547540823285 Test RE 0.03922785065208617\n",
      "60 Train Loss 0.016476605 Test MSE 0.005890168878338206 Test RE 0.036683598683218875\n",
      "61 Train Loss 0.014546967 Test MSE 0.005315552813338885 Test RE 0.03484835474109822\n",
      "62 Train Loss 0.013031539 Test MSE 0.005087002669524094 Test RE 0.034090945237254144\n",
      "63 Train Loss 0.011856782 Test MSE 0.004971455729322588 Test RE 0.03370154791197753\n",
      "64 Train Loss 0.010975948 Test MSE 0.004906039373171386 Test RE 0.03347908460887905\n",
      "65 Train Loss 0.009961874 Test MSE 0.005229871369002122 Test RE 0.03456635325414035\n",
      "66 Train Loss 0.009178683 Test MSE 0.00544151304327917 Test RE 0.03525883004900463\n",
      "67 Train Loss 0.008450559 Test MSE 0.004863936863288021 Test RE 0.033335120145295535\n",
      "68 Train Loss 0.007977386 Test MSE 0.004468253275067692 Test RE 0.0319504479536354\n",
      "69 Train Loss 0.0074235033 Test MSE 0.00391831916781594 Test RE 0.029919750292157665\n",
      "70 Train Loss 0.0069433902 Test MSE 0.003926672636560344 Test RE 0.029951626285604518\n",
      "71 Train Loss 0.0063392557 Test MSE 0.003922702796043192 Test RE 0.029936482007181315\n",
      "72 Train Loss 0.005832077 Test MSE 0.0033319315195140986 Test RE 0.027590279096093257\n",
      "73 Train Loss 0.0053977994 Test MSE 0.0030792986284349367 Test RE 0.026523691293127854\n",
      "74 Train Loss 0.0050617764 Test MSE 0.0032242214635144592 Test RE 0.02714066550732748\n",
      "75 Train Loss 0.00475335 Test MSE 0.003056387162318416 Test RE 0.026424832536345897\n",
      "76 Train Loss 0.004423709 Test MSE 0.002717633872825688 Test RE 0.02491744646013047\n",
      "77 Train Loss 0.0041040266 Test MSE 0.00225924008697052 Test RE 0.022719002166854897\n",
      "78 Train Loss 0.0039189733 Test MSE 0.002043456595897127 Test RE 0.021606815774146353\n",
      "79 Train Loss 0.0037217787 Test MSE 0.0018388371820409737 Test RE 0.020496499612173247\n",
      "80 Train Loss 0.0035317629 Test MSE 0.0016821539864344311 Test RE 0.01960383032011914\n",
      "81 Train Loss 0.0033845147 Test MSE 0.0015493534007491301 Test RE 0.018814093809689462\n",
      "82 Train Loss 0.0032368817 Test MSE 0.0013323094351875735 Test RE 0.01744659228544452\n",
      "83 Train Loss 0.0031233104 Test MSE 0.001289274318837921 Test RE 0.01716250695661667\n",
      "84 Train Loss 0.0029846008 Test MSE 0.0013593862473118433 Test RE 0.017622986001132157\n",
      "85 Train Loss 0.002802299 Test MSE 0.0013825076836212161 Test RE 0.01777222640196158\n",
      "86 Train Loss 0.0026805215 Test MSE 0.0013950868414171454 Test RE 0.01785289626455517\n",
      "87 Train Loss 0.002569525 Test MSE 0.0013742894669179302 Test RE 0.017719324811618885\n",
      "88 Train Loss 0.0024035426 Test MSE 0.0013548193851365645 Test RE 0.01759335885991562\n",
      "89 Train Loss 0.002289309 Test MSE 0.0012992387460178142 Test RE 0.017228701322161265\n",
      "90 Train Loss 0.002182445 Test MSE 0.001200547231228197 Test RE 0.016561424364242298\n",
      "91 Train Loss 0.0020802103 Test MSE 0.001137892247584804 Test RE 0.016123474295609574\n",
      "92 Train Loss 0.0020075575 Test MSE 0.001120592645790657 Test RE 0.01600044068782602\n",
      "93 Train Loss 0.001961512 Test MSE 0.001127397311099237 Test RE 0.01604894754595804\n",
      "94 Train Loss 0.0019151588 Test MSE 0.001074749122962643 Test RE 0.015669733486388303\n",
      "95 Train Loss 0.0018635137 Test MSE 0.0010298874915581372 Test RE 0.01533920854709277\n",
      "96 Train Loss 0.001793084 Test MSE 0.0010298122480363046 Test RE 0.015338648196003717\n",
      "97 Train Loss 0.0017137411 Test MSE 0.0010078954788871033 Test RE 0.01517454957562557\n",
      "98 Train Loss 0.0016576804 Test MSE 0.000933955747151981 Test RE 0.014607342412384238\n",
      "99 Train Loss 0.001617918 Test MSE 0.0008712938487860708 Test RE 0.01410880997753394\n",
      "Training time: 76.80\n",
      "KG_stan_tune11\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.404057 Test MSE 8.367725595405865 Test RE 1.382648462999999\n",
      "1 Train Loss 54.618122 Test MSE 9.019423772876385 Test RE 1.435481026357466\n",
      "2 Train Loss 48.754448 Test MSE 8.681236271686059 Test RE 1.408311898095643\n",
      "3 Train Loss 45.17116 Test MSE 8.653098810740586 Test RE 1.4060277486407269\n",
      "4 Train Loss 44.062645 Test MSE 8.597507992199104 Test RE 1.4015040412354907\n",
      "5 Train Loss 43.338192 Test MSE 8.476358824138295 Test RE 1.3915945744314668\n",
      "6 Train Loss 42.8749 Test MSE 8.351213810262493 Test RE 1.381283619730879\n",
      "7 Train Loss 41.696716 Test MSE 8.006407914755615 Test RE 1.3524677461395214\n",
      "8 Train Loss 40.465103 Test MSE 8.023940865841324 Test RE 1.3539477970784415\n",
      "9 Train Loss 39.69943 Test MSE 8.149571791262714 Test RE 1.3645060174055472\n",
      "10 Train Loss 38.473656 Test MSE 8.08174333042048 Test RE 1.3588157966170011\n",
      "11 Train Loss 37.042114 Test MSE 7.74281756151147 Test RE 1.3300181680970775\n",
      "12 Train Loss 35.916885 Test MSE 7.520823679091836 Test RE 1.3108130722834967\n",
      "13 Train Loss 34.844563 Test MSE 7.434810531209578 Test RE 1.3032958518954887\n",
      "14 Train Loss 34.227413 Test MSE 7.53973593248113 Test RE 1.3124601567496348\n",
      "15 Train Loss 33.50867 Test MSE 7.62552576750391 Test RE 1.319905859219499\n",
      "16 Train Loss 32.907604 Test MSE 7.5902121606045005 Test RE 1.3168460882248314\n",
      "17 Train Loss 32.54252 Test MSE 7.5771213862141025 Test RE 1.3157100215452597\n",
      "18 Train Loss 32.166832 Test MSE 7.492594950187042 Test RE 1.3083507506535437\n",
      "19 Train Loss 31.8127 Test MSE 7.53344215985979 Test RE 1.311912256238548\n",
      "20 Train Loss 31.457897 Test MSE 7.59480598039016 Test RE 1.3172445249517597\n",
      "21 Train Loss 31.02454 Test MSE 7.576948495704699 Test RE 1.3156950108926733\n",
      "22 Train Loss 30.415829 Test MSE 7.530024549202604 Test RE 1.311614642356677\n",
      "23 Train Loss 29.753277 Test MSE 7.39483399525428 Test RE 1.2997872568526738\n",
      "24 Train Loss 28.359589 Test MSE 7.6947395202001125 Test RE 1.325882448678452\n",
      "25 Train Loss 27.157 Test MSE 7.754385672821539 Test RE 1.3310113502051575\n",
      "26 Train Loss 25.672596 Test MSE 7.741082308786122 Test RE 1.3298691237114448\n",
      "27 Train Loss 24.204136 Test MSE 7.473203105981754 Test RE 1.3066565598240603\n",
      "28 Train Loss 22.805023 Test MSE 7.448914723425928 Test RE 1.3045314735390308\n",
      "29 Train Loss 20.790699 Test MSE 7.673356046415129 Test RE 1.3240388711754327\n",
      "30 Train Loss 19.011892 Test MSE 7.4729900110250504 Test RE 1.3066379303352031\n",
      "31 Train Loss 16.978626 Test MSE 7.046992375837247 Test RE 1.2688490565485504\n",
      "32 Train Loss 15.130001 Test MSE 6.99488352621738 Test RE 1.264149112039715\n",
      "33 Train Loss 13.21925 Test MSE 6.58548107451028 Test RE 1.2265967602797614\n",
      "34 Train Loss 11.824727 Test MSE 6.171515868523451 Test RE 1.187418976632576\n",
      "35 Train Loss 10.489713 Test MSE 5.93896049728013 Test RE 1.1648319613937745\n",
      "36 Train Loss 8.624517 Test MSE 5.802328675073209 Test RE 1.15135492558139\n",
      "37 Train Loss 7.793464 Test MSE 5.768698516731783 Test RE 1.1480134639701283\n",
      "38 Train Loss 7.098977 Test MSE 6.034824560484342 Test RE 1.1741954275689634\n",
      "39 Train Loss 6.4599648 Test MSE 6.237445302113297 Test RE 1.1937446421907192\n",
      "40 Train Loss 6.062115 Test MSE 6.351594600382551 Test RE 1.2046182700823163\n",
      "41 Train Loss 5.5560923 Test MSE 6.348821039726813 Test RE 1.2043552301004046\n",
      "42 Train Loss 5.1421447 Test MSE 6.4343323945558915 Test RE 1.2124387456529364\n",
      "43 Train Loss 4.792411 Test MSE 6.539275136346859 Test RE 1.2222860790817662\n",
      "44 Train Loss 4.385511 Test MSE 6.718550106418804 Test RE 1.2389273504661855\n",
      "45 Train Loss 3.9717162 Test MSE 6.868432238888299 Test RE 1.2526705555332827\n",
      "46 Train Loss 3.6022785 Test MSE 6.716021098180687 Test RE 1.2386941489317636\n",
      "47 Train Loss 3.344842 Test MSE 6.7632271804704045 Test RE 1.2430398400156253\n",
      "48 Train Loss 3.1505258 Test MSE 6.799192240128084 Test RE 1.24634053690416\n",
      "49 Train Loss 2.8961759 Test MSE 6.944536456684961 Test RE 1.2595914132880004\n",
      "50 Train Loss 2.7690558 Test MSE 6.99051828355654 Test RE 1.2637545966181922\n",
      "51 Train Loss 2.661431 Test MSE 6.916236157977963 Test RE 1.2570222566185143\n",
      "52 Train Loss 2.5836785 Test MSE 6.894044720292813 Test RE 1.2550039953496115\n",
      "53 Train Loss 2.4778295 Test MSE 6.869674578665537 Test RE 1.2527838399072948\n",
      "54 Train Loss 2.368263 Test MSE 6.8842918231989385 Test RE 1.2541159639190043\n",
      "55 Train Loss 2.2787504 Test MSE 6.90271675987094 Test RE 1.2557930839276106\n",
      "56 Train Loss 2.2095442 Test MSE 6.827462809939684 Test RE 1.248928947846373\n",
      "57 Train Loss 2.1370173 Test MSE 6.80436625343266 Test RE 1.2468146635324997\n",
      "58 Train Loss 2.0779314 Test MSE 6.822985083964912 Test RE 1.2485193316411225\n",
      "59 Train Loss 2.0145783 Test MSE 6.762107468655018 Test RE 1.2429369376606103\n",
      "60 Train Loss 1.9518745 Test MSE 6.751346859280538 Test RE 1.2419475949142829\n",
      "61 Train Loss 1.890913 Test MSE 6.711593108295208 Test RE 1.2382857352700622\n",
      "62 Train Loss 1.8199325 Test MSE 6.5905944427953 Test RE 1.2270728700639546\n",
      "63 Train Loss 1.7743559 Test MSE 6.597002709784109 Test RE 1.2276692881940128\n",
      "64 Train Loss 1.728402 Test MSE 6.662293167370856 Test RE 1.2337294449795941\n",
      "65 Train Loss 1.6880891 Test MSE 6.623429985650988 Test RE 1.2301258225525518\n",
      "66 Train Loss 1.6445085 Test MSE 6.553406849933385 Test RE 1.2236060782054614\n",
      "67 Train Loss 1.5975922 Test MSE 6.536519193927634 Test RE 1.2220284889840363\n",
      "68 Train Loss 1.5607606 Test MSE 6.4732932322463554 Test RE 1.2161039539645195\n",
      "69 Train Loss 1.5144125 Test MSE 6.464779874068189 Test RE 1.2153040106904769\n",
      "70 Train Loss 1.4769142 Test MSE 6.4093976082299005 Test RE 1.210087200434413\n",
      "71 Train Loss 1.4457294 Test MSE 6.329370078273905 Test RE 1.2025089158731355\n",
      "72 Train Loss 1.4145446 Test MSE 6.327993558233993 Test RE 1.202378147122992\n",
      "73 Train Loss 1.3847338 Test MSE 6.225172663108913 Test RE 1.1925696731222362\n",
      "74 Train Loss 1.3624567 Test MSE 6.170512249282427 Test RE 1.187322422964804\n",
      "75 Train Loss 1.3355887 Test MSE 6.143321294978357 Test RE 1.1847035095642693\n",
      "76 Train Loss 1.3172544 Test MSE 6.110009988426614 Test RE 1.181487198511953\n",
      "77 Train Loss 1.2931975 Test MSE 6.124700955743173 Test RE 1.1829067353806764\n",
      "78 Train Loss 1.2728535 Test MSE 6.094380473172907 Test RE 1.1799750981642907\n",
      "79 Train Loss 1.2549268 Test MSE 6.03013416981155 Test RE 1.1737390343660161\n",
      "80 Train Loss 1.2409481 Test MSE 6.023192926903928 Test RE 1.1730632986845013\n",
      "81 Train Loss 1.2188579 Test MSE 5.991119422546751 Test RE 1.1699358484792053\n",
      "82 Train Loss 1.2042177 Test MSE 5.9786511438766405 Test RE 1.1687178220590282\n",
      "83 Train Loss 1.187547 Test MSE 5.990949213428133 Test RE 1.1699192292841982\n",
      "84 Train Loss 1.1754082 Test MSE 5.988174191132442 Test RE 1.1696482431791968\n",
      "85 Train Loss 1.1588145 Test MSE 5.982518951491329 Test RE 1.169095804041937\n",
      "86 Train Loss 1.1469488 Test MSE 5.979269555817621 Test RE 1.1687782646530742\n",
      "87 Train Loss 1.1283836 Test MSE 5.994995554908141 Test RE 1.170314249628921\n",
      "88 Train Loss 1.1129863 Test MSE 6.006886420534698 Test RE 1.1714743135264225\n",
      "89 Train Loss 1.1059363 Test MSE 5.999297409238269 Test RE 1.1707340680040523\n",
      "90 Train Loss 1.093442 Test MSE 5.993032624034524 Test RE 1.1701226369723323\n",
      "91 Train Loss 1.0784683 Test MSE 6.01032050386589 Test RE 1.17180912638336\n",
      "92 Train Loss 1.0659485 Test MSE 6.020635418887573 Test RE 1.1728142250316869\n",
      "93 Train Loss 1.0510026 Test MSE 6.056333573918871 Test RE 1.1762860700675937\n",
      "94 Train Loss 1.0341941 Test MSE 6.055576525828468 Test RE 1.1762125492696967\n",
      "95 Train Loss 1.0224781 Test MSE 6.039706457424844 Test RE 1.1746702667448425\n",
      "96 Train Loss 1.0133688 Test MSE 6.05182592058335 Test RE 1.1758482410794058\n",
      "97 Train Loss 1.0005666 Test MSE 6.076900082311293 Test RE 1.178281633352247\n",
      "98 Train Loss 0.9902899 Test MSE 6.068043931948173 Test RE 1.1774227378780675\n",
      "99 Train Loss 0.98158026 Test MSE 6.046861372469424 Test RE 1.1753658451109152\n",
      "Training time: 78.43\n",
      "KG_stan_tune11\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.990723 Test MSE 8.394089134123726 Test RE 1.3848248513019825\n",
      "1 Train Loss 47.585266 Test MSE 8.345802383187781 Test RE 1.380836024506506\n",
      "2 Train Loss 46.001884 Test MSE 8.633128493203657 Test RE 1.4044043394677581\n",
      "3 Train Loss 44.75128 Test MSE 8.370966893040565 Test RE 1.382916226398382\n",
      "4 Train Loss 44.15567 Test MSE 8.198500509053941 Test RE 1.368596024947118\n",
      "5 Train Loss 43.50506 Test MSE 8.472013673602413 Test RE 1.3912378491471695\n",
      "6 Train Loss 42.84219 Test MSE 8.559297766244448 Test RE 1.3983861948037002\n",
      "7 Train Loss 41.911644 Test MSE 8.540218992880883 Test RE 1.3968268158784867\n",
      "8 Train Loss 40.449345 Test MSE 8.988482208986307 Test RE 1.4330166679175254\n",
      "9 Train Loss 38.97764 Test MSE 9.59698524680786 Test RE 1.4807286309662473\n",
      "10 Train Loss 37.6946 Test MSE 9.2442822547057 Test RE 1.4532644801878944\n",
      "11 Train Loss 35.2347 Test MSE 9.202036581196356 Test RE 1.4499400231108344\n",
      "12 Train Loss 33.00627 Test MSE 8.692893518769568 Test RE 1.409257128228242\n",
      "13 Train Loss 30.79741 Test MSE 8.010689217278163 Test RE 1.3528293033928052\n",
      "14 Train Loss 27.019127 Test MSE 7.056439256648745 Test RE 1.2696992526790511\n",
      "15 Train Loss 22.52303 Test MSE 7.164110139583307 Test RE 1.2793494515074462\n",
      "16 Train Loss 20.437542 Test MSE 7.036567032328007 Test RE 1.26791013944404\n",
      "17 Train Loss 17.73489 Test MSE 6.220375844883381 Test RE 1.192110116201424\n",
      "18 Train Loss 15.16638 Test MSE 5.991990638679452 Test RE 1.1700209102065147\n",
      "19 Train Loss 11.678654 Test MSE 4.555381831412285 Test RE 1.0201650783312997\n",
      "20 Train Loss 8.325282 Test MSE 4.229886043856635 Test RE 0.9830427258983573\n",
      "21 Train Loss 7.0858955 Test MSE 3.9705955014740657 Test RE 0.952436177549895\n",
      "22 Train Loss 5.953194 Test MSE 3.572411937055464 Test RE 0.9034181807213195\n",
      "23 Train Loss 4.734865 Test MSE 2.927455551186505 Test RE 0.8178115035056862\n",
      "24 Train Loss 3.6257935 Test MSE 2.5914707939870336 Test RE 0.7694514450803649\n",
      "25 Train Loss 3.117538 Test MSE 2.3431581304347415 Test RE 0.7316592364263018\n",
      "26 Train Loss 2.641789 Test MSE 2.0070481200800026 Test RE 0.6771532275564953\n",
      "27 Train Loss 2.1269073 Test MSE 1.5107408559709088 Test RE 0.5874934749260329\n",
      "28 Train Loss 1.6485097 Test MSE 1.3533759074343612 Test RE 0.5560543989047005\n",
      "29 Train Loss 1.2946311 Test MSE 1.122766599701937 Test RE 0.5064689235456961\n",
      "30 Train Loss 0.9914708 Test MSE 1.0389769518559526 Test RE 0.48720419270760473\n",
      "31 Train Loss 0.8725905 Test MSE 0.9146680116754824 Test RE 0.45713008646788056\n",
      "32 Train Loss 0.77686834 Test MSE 0.8254475055861292 Test RE 0.434262961765065\n",
      "33 Train Loss 0.67096186 Test MSE 0.7776483163541676 Test RE 0.42150203750968784\n",
      "34 Train Loss 0.5881748 Test MSE 0.6934048648920941 Test RE 0.3980168904771032\n",
      "35 Train Loss 0.52398354 Test MSE 0.6270514484102776 Test RE 0.3784945652912623\n",
      "36 Train Loss 0.46350294 Test MSE 0.5558960491352027 Test RE 0.35637305003405284\n",
      "37 Train Loss 0.39455822 Test MSE 0.35750534968140374 Test RE 0.28579151636564265\n",
      "38 Train Loss 0.32787552 Test MSE 0.24230661938903528 Test RE 0.23528308151208818\n",
      "39 Train Loss 0.26489758 Test MSE 0.169393336961405 Test RE 0.19672349070689651\n",
      "40 Train Loss 0.22075525 Test MSE 0.10966131883941921 Test RE 0.15828318935877028\n",
      "41 Train Loss 0.18977922 Test MSE 0.08562183310063244 Test RE 0.13986218896425562\n",
      "42 Train Loss 0.15601313 Test MSE 0.0629849547337625 Test RE 0.11995724171188965\n",
      "43 Train Loss 0.13122275 Test MSE 0.045357073898679115 Test RE 0.1017959676298588\n",
      "44 Train Loss 0.11605363 Test MSE 0.03105138517452389 Test RE 0.08422646031452252\n",
      "45 Train Loss 0.101113044 Test MSE 0.03343421035337484 Test RE 0.08739842283108767\n",
      "46 Train Loss 0.091197774 Test MSE 0.03536650727450904 Test RE 0.08988850268050548\n",
      "47 Train Loss 0.08178693 Test MSE 0.03052311189630129 Test RE 0.08350691977912926\n",
      "48 Train Loss 0.0737863 Test MSE 0.026718069520375108 Test RE 0.07812870000052724\n",
      "49 Train Loss 0.06590906 Test MSE 0.021908703265517953 Test RE 0.07074836323636945\n",
      "50 Train Loss 0.059873447 Test MSE 0.017749558921348118 Test RE 0.06367982231245342\n",
      "51 Train Loss 0.053723067 Test MSE 0.016164551428769512 Test RE 0.06077009131541945\n",
      "52 Train Loss 0.0482559 Test MSE 0.015125797645732037 Test RE 0.05878509214876775\n",
      "53 Train Loss 0.0431881 Test MSE 0.014117237044160843 Test RE 0.05679144432136248\n",
      "54 Train Loss 0.03885302 Test MSE 0.012644837252028654 Test RE 0.05374829378166319\n",
      "55 Train Loss 0.034948677 Test MSE 0.010561520078967716 Test RE 0.04912146093469763\n",
      "56 Train Loss 0.032417856 Test MSE 0.010314335628852022 Test RE 0.04854323218990061\n",
      "57 Train Loss 0.02921056 Test MSE 0.008354788270689285 Test RE 0.04368937022377952\n",
      "58 Train Loss 0.026186459 Test MSE 0.00649995219938665 Test RE 0.038535690183221394\n",
      "59 Train Loss 0.023002835 Test MSE 0.0054614320897073566 Test RE 0.03532330482979334\n",
      "60 Train Loss 0.02084504 Test MSE 0.005432151433842906 Test RE 0.03522848724881894\n",
      "61 Train Loss 0.019433085 Test MSE 0.00533829425816675 Test RE 0.03492282075956981\n",
      "62 Train Loss 0.017031012 Test MSE 0.004117083291322589 Test RE 0.030669231016388916\n",
      "63 Train Loss 0.015483963 Test MSE 0.0035688815637975506 Test RE 0.028554471613684906\n",
      "64 Train Loss 0.013824406 Test MSE 0.003390972354429703 Test RE 0.02783365147594889\n",
      "65 Train Loss 0.011952978 Test MSE 0.002940166285806405 Test RE 0.025917553693771498\n",
      "66 Train Loss 0.010913793 Test MSE 0.002794226612242447 Test RE 0.02526613850591709\n",
      "67 Train Loss 0.009950589 Test MSE 0.002788761940945302 Test RE 0.025241419910469003\n",
      "68 Train Loss 0.00915914 Test MSE 0.003035759498376747 Test RE 0.02633551051196108\n",
      "69 Train Loss 0.008220964 Test MSE 0.0031815725094176107 Test RE 0.026960563990365647\n",
      "70 Train Loss 0.0075791483 Test MSE 0.0030518753100344026 Test RE 0.0264053211054795\n",
      "71 Train Loss 0.0072143506 Test MSE 0.0031201007741308096 Test RE 0.026698838658061688\n",
      "72 Train Loss 0.006876195 Test MSE 0.0031309920474306956 Test RE 0.026745396614487167\n",
      "73 Train Loss 0.006490347 Test MSE 0.0029984245671716217 Test RE 0.026173067430491595\n",
      "74 Train Loss 0.0062309057 Test MSE 0.002650686768976938 Test RE 0.024608620304070756\n",
      "75 Train Loss 0.005846294 Test MSE 0.001954077414551889 Test RE 0.021128999987204265\n",
      "76 Train Loss 0.0055614472 Test MSE 0.001845731670433622 Test RE 0.02053488818433001\n",
      "77 Train Loss 0.0052961195 Test MSE 0.001737047801561011 Test RE 0.01992112888335451\n",
      "78 Train Loss 0.005078369 Test MSE 0.0016515967068878356 Test RE 0.019424956924552688\n",
      "79 Train Loss 0.004894047 Test MSE 0.0016258597451557573 Test RE 0.01927301234141064\n",
      "80 Train Loss 0.0047508753 Test MSE 0.0015606681435792072 Test RE 0.018882667381244517\n",
      "81 Train Loss 0.004501863 Test MSE 0.0015156846397121955 Test RE 0.01860854791173551\n",
      "82 Train Loss 0.0042971214 Test MSE 0.0015216209638583972 Test RE 0.018644953380811218\n",
      "83 Train Loss 0.004142438 Test MSE 0.0015268072525191651 Test RE 0.018676701055272575\n",
      "84 Train Loss 0.0039352723 Test MSE 0.0014637154290866941 Test RE 0.01828674402160195\n",
      "85 Train Loss 0.0037358361 Test MSE 0.0014644209335453661 Test RE 0.018291150556150222\n",
      "86 Train Loss 0.0036046403 Test MSE 0.0014734670672609464 Test RE 0.01834755833024854\n",
      "87 Train Loss 0.0034845439 Test MSE 0.0013766441616155248 Test RE 0.017734498377403627\n",
      "88 Train Loss 0.0033719353 Test MSE 0.001387481029418086 Test RE 0.017804164047351096\n",
      "89 Train Loss 0.0032454976 Test MSE 0.0013948682900268784 Test RE 0.017851497811066097\n",
      "90 Train Loss 0.0030755396 Test MSE 0.0012969289870581847 Test RE 0.01721338010063863\n",
      "91 Train Loss 0.0029096557 Test MSE 0.0012984612496477659 Test RE 0.017223545511733204\n",
      "92 Train Loss 0.0027849828 Test MSE 0.0013427135292908103 Test RE 0.01751458061924088\n",
      "93 Train Loss 0.0025612493 Test MSE 0.0011988972388207017 Test RE 0.016550039714280342\n",
      "94 Train Loss 0.002451989 Test MSE 0.001077015883874171 Test RE 0.015686249354928915\n",
      "95 Train Loss 0.0023530736 Test MSE 0.0011151374372004716 Test RE 0.015961446932553268\n",
      "96 Train Loss 0.0022824532 Test MSE 0.0011323818336603203 Test RE 0.01608438674472379\n",
      "97 Train Loss 0.0021331902 Test MSE 0.0010212508480183522 Test RE 0.015274755783446992\n",
      "98 Train Loss 0.0020379256 Test MSE 0.0009830225742652621 Test RE 0.014986140704184225\n",
      "99 Train Loss 0.001968868 Test MSE 0.0009320241300922182 Test RE 0.014592229064646496\n",
      "Training time: 79.19\n",
      "KG_stan_tune11\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 52.78699 Test MSE 8.46115065241873 Test RE 1.3903456236092877\n",
      "1 Train Loss 43.85454 Test MSE 8.178581227890131 Test RE 1.3669324263469318\n",
      "2 Train Loss 42.178482 Test MSE 8.062910037835701 Test RE 1.3572316147888641\n",
      "3 Train Loss 39.80381 Test MSE 7.913865585019883 Test RE 1.3446287569921578\n",
      "4 Train Loss 34.50261 Test MSE 6.656553505127738 Test RE 1.2331978925598783\n",
      "5 Train Loss 28.577312 Test MSE 3.9840519670564367 Test RE 0.9540487296455247\n",
      "6 Train Loss 16.987219 Test MSE 3.0753049684043656 Test RE 0.8382086826956362\n",
      "7 Train Loss 12.016539 Test MSE 3.7059855400204156 Test RE 0.9201527332701537\n",
      "8 Train Loss 10.288636 Test MSE 3.79638412618056 Test RE 0.9313075734669505\n",
      "9 Train Loss 9.253648 Test MSE 3.7423140459692266 Test RE 0.9246517056091518\n",
      "10 Train Loss 8.677831 Test MSE 3.81172684550714 Test RE 0.9331875706747252\n",
      "11 Train Loss 8.330285 Test MSE 3.77032389580962 Test RE 0.9281055945438499\n",
      "12 Train Loss 8.039854 Test MSE 3.7105393261423893 Test RE 0.9207178855495368\n",
      "13 Train Loss 7.84393 Test MSE 3.7330292025957488 Test RE 0.9235039427725404\n",
      "14 Train Loss 7.686829 Test MSE 3.677894056364891 Test RE 0.9166587065478717\n",
      "15 Train Loss 7.559888 Test MSE 3.695203034611169 Test RE 0.9188131734036875\n",
      "16 Train Loss 7.41228 Test MSE 3.644483809199796 Test RE 0.9124857120424578\n",
      "17 Train Loss 7.111064 Test MSE 3.329396713534982 Test RE 0.8721492939255835\n",
      "18 Train Loss 6.1874504 Test MSE 2.6372556088298285 Test RE 0.7762188276487888\n",
      "19 Train Loss 5.1671715 Test MSE 2.2759956600263256 Test RE 0.7210971433213891\n",
      "20 Train Loss 4.43347 Test MSE 2.120068505457823 Test RE 0.6959579617158526\n",
      "21 Train Loss 4.1617093 Test MSE 2.100968585127607 Test RE 0.6928158896223237\n",
      "22 Train Loss 3.9476237 Test MSE 2.1011794251123765 Test RE 0.6928506520714355\n",
      "23 Train Loss 3.6881132 Test MSE 2.022803019998823 Test RE 0.6798057864735306\n",
      "24 Train Loss 2.8675816 Test MSE 1.6815776391089148 Test RE 0.6198213364402985\n",
      "25 Train Loss 2.019037 Test MSE 1.5770654140193894 Test RE 0.6002510301055115\n",
      "26 Train Loss 1.3374248 Test MSE 1.1976435925618758 Test RE 0.5230845080838197\n",
      "27 Train Loss 0.97908455 Test MSE 0.7677046347366533 Test RE 0.4187985231690611\n",
      "28 Train Loss 0.5938603 Test MSE 0.35713664959858327 Test RE 0.28564410802952916\n",
      "29 Train Loss 0.36687136 Test MSE 0.16054001838028534 Test RE 0.19151364163089768\n",
      "30 Train Loss 0.22585368 Test MSE 0.11330852620247091 Test RE 0.16089381728301744\n",
      "31 Train Loss 0.15706192 Test MSE 0.08099900485497441 Test RE 0.1360341357747652\n",
      "32 Train Loss 0.11633307 Test MSE 0.06813549779986963 Test RE 0.12476557627853996\n",
      "33 Train Loss 0.09458519 Test MSE 0.061530806052982626 Test RE 0.11856441490373815\n",
      "34 Train Loss 0.076656476 Test MSE 0.05169145552864991 Test RE 0.10867194519854474\n",
      "35 Train Loss 0.06337017 Test MSE 0.04470474510486824 Test RE 0.10106129797464956\n",
      "36 Train Loss 0.05542273 Test MSE 0.03773415104120384 Test RE 0.09284859836027125\n",
      "37 Train Loss 0.045349292 Test MSE 0.02682563023253069 Test RE 0.07828580599719309\n",
      "38 Train Loss 0.03916724 Test MSE 0.025512663802146694 Test RE 0.07634594292860318\n",
      "39 Train Loss 0.034122355 Test MSE 0.021652666781315402 Test RE 0.0703337472647608\n",
      "40 Train Loss 0.02640683 Test MSE 0.01499874840493487 Test RE 0.0585376886445652\n",
      "41 Train Loss 0.021972777 Test MSE 0.012580482767750365 Test RE 0.053611346351270045\n",
      "42 Train Loss 0.019191174 Test MSE 0.009261925338374364 Test RE 0.04600009177682308\n",
      "43 Train Loss 0.014989867 Test MSE 0.006402418455253516 Test RE 0.03824547755654727\n",
      "44 Train Loss 0.012465262 Test MSE 0.004265614652210734 Test RE 0.031217553885618223\n",
      "45 Train Loss 0.011010644 Test MSE 0.003471524819417402 Test RE 0.02816230499595643\n",
      "46 Train Loss 0.009508886 Test MSE 0.002635517224360876 Test RE 0.02453810326087284\n",
      "47 Train Loss 0.008713541 Test MSE 0.002325315387268024 Test RE 0.0230488357474711\n",
      "48 Train Loss 0.0074737775 Test MSE 0.0021499884906427294 Test RE 0.02216287657121715\n",
      "49 Train Loss 0.006713804 Test MSE 0.0016559917391965032 Test RE 0.019450785443114432\n",
      "50 Train Loss 0.0060826316 Test MSE 0.0014210607658322176 Test RE 0.018018323703317803\n",
      "51 Train Loss 0.0055997684 Test MSE 0.0015164163914332448 Test RE 0.018613039345340848\n",
      "52 Train Loss 0.004915001 Test MSE 0.0013484234566429822 Test RE 0.017551781736826432\n",
      "53 Train Loss 0.0045131384 Test MSE 0.0011465851492145622 Test RE 0.016184944574131437\n",
      "54 Train Loss 0.0041674557 Test MSE 0.0009872746239847489 Test RE 0.015018516897125148\n",
      "55 Train Loss 0.0037569439 Test MSE 0.0007851733415981462 Test RE 0.013393399808784486\n",
      "56 Train Loss 0.0034015614 Test MSE 0.000646789193158188 Test RE 0.012155964909449191\n",
      "57 Train Loss 0.0032058705 Test MSE 0.0005513091521763745 Test RE 0.01122291468197572\n",
      "58 Train Loss 0.0030118139 Test MSE 0.0004983551982887108 Test RE 0.010670322767386112\n",
      "59 Train Loss 0.0029146343 Test MSE 0.000490875948181035 Test RE 0.010589950664565867\n",
      "60 Train Loss 0.0027381177 Test MSE 0.0004374932912787436 Test RE 0.009997554013212073\n",
      "61 Train Loss 0.0026019996 Test MSE 0.00042755325509820455 Test RE 0.009883327095609\n",
      "62 Train Loss 0.002478275 Test MSE 0.0004455046630997366 Test RE 0.010088676291813094\n",
      "63 Train Loss 0.0023530666 Test MSE 0.00046624466646763026 Test RE 0.01032083888965089\n",
      "64 Train Loss 0.0022268253 Test MSE 0.00041024009000351585 Test RE 0.009681153578379663\n",
      "65 Train Loss 0.0020308336 Test MSE 0.0003604142143343057 Test RE 0.009074213968551011\n",
      "66 Train Loss 0.0018930597 Test MSE 0.0003452667055975252 Test RE 0.00888148140257649\n",
      "67 Train Loss 0.0017414247 Test MSE 0.00030037485217039453 Test RE 0.008283995328537005\n",
      "68 Train Loss 0.001563154 Test MSE 0.0002758276034486191 Test RE 0.007938289321486209\n",
      "69 Train Loss 0.0014430129 Test MSE 0.00028591613683727387 Test RE 0.008082159071481534\n",
      "70 Train Loss 0.0013448936 Test MSE 0.0003117395945181681 Test RE 0.008439253711105328\n",
      "71 Train Loss 0.0012583348 Test MSE 0.00029753176196713253 Test RE 0.00824469752746113\n",
      "72 Train Loss 0.0011732178 Test MSE 0.00024406069031188078 Test RE 0.007467186148567969\n",
      "73 Train Loss 0.0011221321 Test MSE 0.00023847474621728766 Test RE 0.007381238833084266\n",
      "74 Train Loss 0.0010479271 Test MSE 0.00024512339190919095 Test RE 0.007483425493014035\n",
      "75 Train Loss 0.0010067734 Test MSE 0.00025736397968702376 Test RE 0.007667997137072776\n",
      "76 Train Loss 0.0009676815 Test MSE 0.00026900509167631194 Test RE 0.007839499025090995\n",
      "77 Train Loss 0.0009130263 Test MSE 0.000261603160238298 Test RE 0.007730891057785333\n",
      "78 Train Loss 0.00086524535 Test MSE 0.00024971993233938 Test RE 0.007553264004309749\n",
      "79 Train Loss 0.0008352692 Test MSE 0.00024888534299010633 Test RE 0.007540631553432816\n",
      "80 Train Loss 0.0008001325 Test MSE 0.0002631898392306972 Test RE 0.007754300367840131\n",
      "81 Train Loss 0.00077649526 Test MSE 0.00025520900126521 Test RE 0.007635826542094604\n",
      "82 Train Loss 0.0007417828 Test MSE 0.0002341282726885393 Test RE 0.007313663771905812\n",
      "83 Train Loss 0.00071612315 Test MSE 0.00021889559622851977 Test RE 0.007071744681562764\n",
      "84 Train Loss 0.0006928638 Test MSE 0.0002061356174547312 Test RE 0.006862535112072714\n",
      "85 Train Loss 0.00066845305 Test MSE 0.00019454706365053796 Test RE 0.006666845648551229\n",
      "86 Train Loss 0.0006539712 Test MSE 0.00018138646457798244 Test RE 0.006437400038666557\n",
      "87 Train Loss 0.0006413829 Test MSE 0.00016899273063892626 Test RE 0.006213582543265285\n",
      "88 Train Loss 0.00062921934 Test MSE 0.00017436956269423204 Test RE 0.006311657143531777\n",
      "89 Train Loss 0.0006137185 Test MSE 0.00017795956453469145 Test RE 0.006376299785230007\n",
      "90 Train Loss 0.00059682684 Test MSE 0.00015143690396879247 Test RE 0.005881985118013164\n",
      "91 Train Loss 0.00057398883 Test MSE 0.0001422066873523632 Test RE 0.005699910943066104\n",
      "92 Train Loss 0.00054397417 Test MSE 0.00015041054504388374 Test RE 0.005862018744174636\n",
      "93 Train Loss 0.00052979204 Test MSE 0.00014175962824632178 Test RE 0.0056909444063938455\n",
      "94 Train Loss 0.0005173238 Test MSE 0.00013433493403330413 Test RE 0.0055399078841444314\n",
      "95 Train Loss 0.00050160236 Test MSE 0.0001296402281806178 Test RE 0.005442243303630607\n",
      "96 Train Loss 0.0004892577 Test MSE 0.00012696112743496417 Test RE 0.005385715963233026\n",
      "97 Train Loss 0.0004663773 Test MSE 0.00011444811309321737 Test RE 0.005113430749188011\n",
      "98 Train Loss 0.000449649 Test MSE 0.00010632117450386489 Test RE 0.004928536112004606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.0004382133 Test MSE 0.00010171777035534772 Test RE 0.0048206597153769935\n",
      "Training time: 78.86\n",
      "KG_stan_tune11\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 57.068817 Test MSE 7.881236675000107 Test RE 1.3418539381210315\n",
      "1 Train Loss 52.337708 Test MSE 8.319464963824506 Test RE 1.3786555035022743\n",
      "2 Train Loss 46.172974 Test MSE 8.333542727776228 Test RE 1.3798214548770456\n",
      "3 Train Loss 43.827763 Test MSE 8.558926225745706 Test RE 1.398355844022785\n",
      "4 Train Loss 42.733185 Test MSE 8.432659138371942 Test RE 1.388002771121187\n",
      "5 Train Loss 41.327637 Test MSE 8.86732919650228 Test RE 1.4233263063009034\n",
      "6 Train Loss 39.35533 Test MSE 9.59188252523511 Test RE 1.4803349265710761\n",
      "7 Train Loss 37.880623 Test MSE 9.844064889429934 Test RE 1.4996685856654013\n",
      "8 Train Loss 35.99794 Test MSE 9.952607978222684 Test RE 1.507913777551566\n",
      "9 Train Loss 31.783758 Test MSE 8.64863058850801 Test RE 1.40566468473649\n",
      "10 Train Loss 29.235676 Test MSE 9.124258949213035 Test RE 1.443799414547821\n",
      "11 Train Loss 26.4033 Test MSE 8.643904817709872 Test RE 1.4052805917437994\n",
      "12 Train Loss 23.036022 Test MSE 8.207026833903333 Test RE 1.3693075002917034\n",
      "13 Train Loss 17.900476 Test MSE 6.714137480186809 Test RE 1.2385204307305722\n",
      "14 Train Loss 11.610149 Test MSE 5.428715786978518 Test RE 1.1136702362941118\n",
      "15 Train Loss 7.542674 Test MSE 5.130235658273264 Test RE 1.0826216749426445\n",
      "16 Train Loss 4.5211396 Test MSE 4.475721261184889 Test RE 1.0112058563486042\n",
      "17 Train Loss 3.1771727 Test MSE 4.330005735533122 Test RE 0.9946087969537328\n",
      "18 Train Loss 2.5577974 Test MSE 4.160602238688706 Test RE 0.9749585663109908\n",
      "19 Train Loss 2.192691 Test MSE 4.161393676518726 Test RE 0.9750512911566482\n",
      "20 Train Loss 1.8687547 Test MSE 4.12310874908493 Test RE 0.9705556790162747\n",
      "21 Train Loss 1.71384 Test MSE 4.116163474852804 Test RE 0.9697378960254304\n",
      "22 Train Loss 1.5599642 Test MSE 4.218339455580388 Test RE 0.9817000719439077\n",
      "23 Train Loss 1.42066 Test MSE 4.281840359718503 Test RE 0.9890614978398097\n",
      "24 Train Loss 1.275089 Test MSE 4.286783268755862 Test RE 0.9896322139937759\n",
      "25 Train Loss 1.1730014 Test MSE 4.3805711393415105 Test RE 1.000399414909639\n",
      "26 Train Loss 1.0558143 Test MSE 4.51280434335587 Test RE 1.0153863308612578\n",
      "27 Train Loss 0.9681202 Test MSE 4.530467722452628 Test RE 1.0173715308368179\n",
      "28 Train Loss 0.88337684 Test MSE 4.526894928522946 Test RE 1.016970294589159\n",
      "29 Train Loss 0.8185743 Test MSE 4.5962115770613865 Test RE 1.0247267335706853\n",
      "30 Train Loss 0.7633503 Test MSE 4.582915921851593 Test RE 1.0232435250237146\n",
      "31 Train Loss 0.7273887 Test MSE 4.532770507016129 Test RE 1.0176300571052657\n",
      "32 Train Loss 0.70025957 Test MSE 4.585186188238147 Test RE 1.023496938766951\n",
      "33 Train Loss 0.66708547 Test MSE 4.543301085634088 Test RE 1.0188114556017849\n",
      "34 Train Loss 0.6407108 Test MSE 4.515471700021859 Test RE 1.0156863657399313\n",
      "35 Train Loss 0.6115304 Test MSE 4.516138304660195 Test RE 1.0157613342372689\n",
      "36 Train Loss 0.58368665 Test MSE 4.499567247024755 Test RE 1.0138960560397965\n",
      "37 Train Loss 0.56413203 Test MSE 4.476249205128693 Test RE 1.0112654941404149\n",
      "38 Train Loss 0.5412321 Test MSE 4.356492456246042 Test RE 0.9976461787974127\n",
      "39 Train Loss 0.5230742 Test MSE 4.3155767818866835 Test RE 0.9929502379673033\n",
      "40 Train Loss 0.50248104 Test MSE 4.294547341271027 Test RE 0.9905280022669273\n",
      "41 Train Loss 0.48640952 Test MSE 4.1915719688431725 Test RE 0.9785804246350501\n",
      "42 Train Loss 0.47286397 Test MSE 4.1433936084197605 Test RE 0.9729402183618151\n",
      "43 Train Loss 0.4577628 Test MSE 4.100669965165557 Test RE 0.9679110967879795\n",
      "44 Train Loss 0.4414218 Test MSE 4.041904855151373 Test RE 0.9609506909174695\n",
      "45 Train Loss 0.42505056 Test MSE 4.095035021850098 Test RE 0.9672458397448174\n",
      "46 Train Loss 0.41302395 Test MSE 4.067116371515974 Test RE 0.9639430129891206\n",
      "47 Train Loss 0.40350643 Test MSE 4.0289837214708575 Test RE 0.9594134811142352\n",
      "48 Train Loss 0.39192852 Test MSE 4.0431894460469 Test RE 0.961103382592244\n",
      "49 Train Loss 0.38293523 Test MSE 4.0749412788288515 Test RE 0.964869853969679\n",
      "50 Train Loss 0.3745304 Test MSE 4.10726786470828 Test RE 0.9686894590423413\n",
      "51 Train Loss 0.3661554 Test MSE 4.110025246628074 Test RE 0.9690145655050909\n",
      "52 Train Loss 0.35589164 Test MSE 4.116242220565427 Test RE 0.969747171936959\n",
      "53 Train Loss 0.3486071 Test MSE 4.118802629584655 Test RE 0.9700487289491249\n",
      "54 Train Loss 0.3418629 Test MSE 4.102266775619958 Test RE 0.9680995318654791\n",
      "55 Train Loss 0.3328578 Test MSE 4.0851956045313225 Test RE 0.9660831074164163\n",
      "56 Train Loss 0.32594952 Test MSE 4.0550428245852865 Test RE 0.9625111801846731\n",
      "57 Train Loss 0.3193027 Test MSE 4.025318094332248 Test RE 0.9589769377299223\n",
      "58 Train Loss 0.31388646 Test MSE 4.033446197527427 Test RE 0.9599446541268712\n",
      "59 Train Loss 0.3093804 Test MSE 4.034827781582562 Test RE 0.9601090458916565\n",
      "60 Train Loss 0.30408025 Test MSE 4.052851234662153 Test RE 0.9622510454601453\n",
      "61 Train Loss 0.29962167 Test MSE 4.105498004497071 Test RE 0.9684807278712247\n",
      "62 Train Loss 0.29340863 Test MSE 4.144686171234858 Test RE 0.9730919645393842\n",
      "63 Train Loss 0.29006317 Test MSE 4.172241573677639 Test RE 0.9763213430599412\n",
      "64 Train Loss 0.2870872 Test MSE 4.1905644048199315 Test RE 0.9784628026907743\n",
      "65 Train Loss 0.28443053 Test MSE 4.209151244054468 Test RE 0.9806303399851757\n",
      "66 Train Loss 0.28175277 Test MSE 4.242166329833488 Test RE 0.9844686858915833\n",
      "67 Train Loss 0.27931136 Test MSE 4.261422199174024 Test RE 0.9867004862988955\n",
      "68 Train Loss 0.27665338 Test MSE 4.261586772063235 Test RE 0.9867195389266885\n",
      "69 Train Loss 0.27456695 Test MSE 4.278222717921855 Test RE 0.9886435903522679\n",
      "70 Train Loss 0.27154344 Test MSE 4.3082922035255145 Test RE 0.9921118472800343\n",
      "71 Train Loss 0.2687474 Test MSE 4.317515814578547 Test RE 0.9931732842537415\n",
      "72 Train Loss 0.2660223 Test MSE 4.338769807046501 Test RE 0.9956148483116246\n",
      "73 Train Loss 0.26366448 Test MSE 4.337941882876864 Test RE 0.9955198521537375\n",
      "74 Train Loss 0.26114148 Test MSE 4.335386754130949 Test RE 0.9952266190792328\n",
      "75 Train Loss 0.25931185 Test MSE 4.341252028799701 Test RE 0.9958996045421524\n",
      "76 Train Loss 0.2571505 Test MSE 4.33005541896386 Test RE 0.9946145031165583\n",
      "77 Train Loss 0.2550083 Test MSE 4.334970818957016 Test RE 0.9951788771233935\n",
      "78 Train Loss 0.25244036 Test MSE 4.35567074816148 Test RE 0.9975520878976432\n",
      "79 Train Loss 0.2502383 Test MSE 4.360470973657711 Test RE 0.9981016193783965\n",
      "80 Train Loss 0.24876106 Test MSE 4.351837414343177 Test RE 0.9971130290143996\n",
      "81 Train Loss 0.24658409 Test MSE 4.3534625725842835 Test RE 0.9972991935057272\n",
      "82 Train Loss 0.24482998 Test MSE 4.376300166112934 Test RE 0.9999116108155873\n",
      "83 Train Loss 0.24315926 Test MSE 4.379014529267396 Test RE 1.0002216561059678\n",
      "84 Train Loss 0.24148642 Test MSE 4.379114572976978 Test RE 1.000233081657617\n",
      "85 Train Loss 0.23986325 Test MSE 4.392768323994462 Test RE 1.0017911939733213\n",
      "86 Train Loss 0.23810586 Test MSE 4.406795821738546 Test RE 1.003389437032954\n",
      "87 Train Loss 0.2365962 Test MSE 4.431141433315036 Test RE 1.0061572625329367\n",
      "88 Train Loss 0.23529619 Test MSE 4.427777321264328 Test RE 1.0057752539122853\n",
      "89 Train Loss 0.23418844 Test MSE 4.429274203422072 Test RE 1.0059452488897405\n",
      "90 Train Loss 0.2327194 Test MSE 4.471646060899323 Test RE 1.0107453937095756\n",
      "91 Train Loss 0.23146613 Test MSE 4.493336260442876 Test RE 1.0131937927966834\n",
      "92 Train Loss 0.2302819 Test MSE 4.490106561066168 Test RE 1.012829597976066\n",
      "93 Train Loss 0.22937644 Test MSE 4.504074729986135 Test RE 1.0144037687796597\n",
      "94 Train Loss 0.2286159 Test MSE 4.514247685284932 Test RE 1.0155486947031318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 Train Loss 0.22746459 Test MSE 4.522740063935262 Test RE 1.0165034907527073\n",
      "96 Train Loss 0.22616182 Test MSE 4.534069851567619 Test RE 1.0177759013879057\n",
      "97 Train Loss 0.22473611 Test MSE 4.539734982349021 Test RE 1.0184115371256075\n",
      "98 Train Loss 0.22348294 Test MSE 4.547006241338405 Test RE 1.019226801811604\n",
      "99 Train Loss 0.2223227 Test MSE 4.559103276091309 Test RE 1.0205816968486745\n",
      "Training time: 75.93\n",
      "KG_stan_tune11\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 51.126713 Test MSE 8.619113829616694 Test RE 1.403263950517061\n",
      "1 Train Loss 43.48253 Test MSE 8.659768566418187 Test RE 1.4065695230594033\n",
      "2 Train Loss 42.319126 Test MSE 8.929797803149395 Test RE 1.4283310357013752\n",
      "3 Train Loss 41.12026 Test MSE 8.727475391841773 Test RE 1.412057483387722\n",
      "4 Train Loss 40.721054 Test MSE 8.726916078225711 Test RE 1.4120122357304283\n",
      "5 Train Loss 40.078087 Test MSE 9.029253441529745 Test RE 1.4362630308860485\n",
      "6 Train Loss 39.310738 Test MSE 8.890457757477492 Test RE 1.425181320961689\n",
      "7 Train Loss 37.79741 Test MSE 7.997510776343186 Test RE 1.3517160708768554\n",
      "8 Train Loss 35.498173 Test MSE 7.950566880187593 Test RE 1.347743071532206\n",
      "9 Train Loss 31.256966 Test MSE 8.185669647393409 Test RE 1.3675246618244858\n",
      "10 Train Loss 27.303621 Test MSE 8.108902388397183 Test RE 1.3610970621165335\n",
      "11 Train Loss 24.571613 Test MSE 7.890472725133046 Test RE 1.3426399696731806\n",
      "12 Train Loss 21.439396 Test MSE 7.585644667352977 Test RE 1.3164498153264557\n",
      "13 Train Loss 17.546024 Test MSE 5.440677897493479 Test RE 1.1148965406732645\n",
      "14 Train Loss 14.385548 Test MSE 4.137198407592274 Test RE 0.9722125763124206\n",
      "15 Train Loss 10.250336 Test MSE 3.768393054018507 Test RE 0.9278679154202767\n",
      "16 Train Loss 8.929756 Test MSE 3.4926669973898576 Test RE 0.893278025487574\n",
      "17 Train Loss 7.899967 Test MSE 3.5498441225876642 Test RE 0.9005601011312645\n",
      "18 Train Loss 7.1834335 Test MSE 3.4855260044580367 Test RE 0.8923643746976487\n",
      "19 Train Loss 6.9207106 Test MSE 3.4236437743402477 Test RE 0.884407354846512\n",
      "20 Train Loss 6.65128 Test MSE 3.375942040157654 Test RE 0.8782245053834317\n",
      "21 Train Loss 6.4772425 Test MSE 3.3542250302706513 Test RE 0.8753951940834575\n",
      "22 Train Loss 6.3291197 Test MSE 3.379089276875137 Test RE 0.8786337743361502\n",
      "23 Train Loss 6.1636105 Test MSE 3.345712527526462 Test RE 0.8742836798269525\n",
      "24 Train Loss 6.036406 Test MSE 3.3501563675682453 Test RE 0.8748641073975603\n",
      "25 Train Loss 5.852266 Test MSE 3.351391816439452 Test RE 0.8750254058753832\n",
      "26 Train Loss 5.5976973 Test MSE 3.293597765048446 Test RE 0.8674477800469242\n",
      "27 Train Loss 5.3658857 Test MSE 3.2764412656143924 Test RE 0.8651855428546811\n",
      "28 Train Loss 5.0791216 Test MSE 3.321931294046235 Test RE 0.8711709463699482\n",
      "29 Train Loss 4.7349167 Test MSE 3.1450992082862332 Test RE 0.8476669193596895\n",
      "30 Train Loss 4.282669 Test MSE 2.896197079224389 Test RE 0.8134336155788294\n",
      "31 Train Loss 3.6781492 Test MSE 2.6669834220977653 Test RE 0.7805814356198354\n",
      "32 Train Loss 2.60732 Test MSE 2.078425711363501 Test RE 0.6890889938434025\n",
      "33 Train Loss 2.116575 Test MSE 2.2126126534753077 Test RE 0.7109855203191302\n",
      "34 Train Loss 1.8890731 Test MSE 2.2288239252210484 Test RE 0.7135853753908866\n",
      "35 Train Loss 1.6712615 Test MSE 2.236365595776052 Test RE 0.714791635111046\n",
      "36 Train Loss 1.5150492 Test MSE 2.332794779841877 Test RE 0.7300394473892695\n",
      "37 Train Loss 1.3933686 Test MSE 2.450649918236606 Test RE 0.7482533985436857\n",
      "38 Train Loss 1.2826741 Test MSE 2.45115305952609 Test RE 0.7483302063030104\n",
      "39 Train Loss 1.2113482 Test MSE 2.4885263238292565 Test RE 0.7540136010507917\n",
      "40 Train Loss 1.1501303 Test MSE 2.5105684298051463 Test RE 0.7573455744049988\n",
      "41 Train Loss 1.107141 Test MSE 2.5203531147628095 Test RE 0.758819977868702\n",
      "42 Train Loss 1.0614796 Test MSE 2.527311794799776 Test RE 0.7598668045306974\n",
      "43 Train Loss 1.023478 Test MSE 2.5126426493095915 Test RE 0.7576583674381747\n",
      "44 Train Loss 0.9847531 Test MSE 2.524084109176531 Test RE 0.7593814281839796\n",
      "45 Train Loss 0.95190895 Test MSE 2.5374073434706017 Test RE 0.7613829662306074\n",
      "46 Train Loss 0.92124003 Test MSE 2.5353781251224516 Test RE 0.7610784583029874\n",
      "47 Train Loss 0.8913491 Test MSE 2.565577059558144 Test RE 0.7655976506931329\n",
      "48 Train Loss 0.86097914 Test MSE 2.5982112703646223 Test RE 0.7704514758636747\n",
      "49 Train Loss 0.84125197 Test MSE 2.575564304081434 Test RE 0.7670863575118765\n",
      "50 Train Loss 0.8197501 Test MSE 2.580600470370489 Test RE 0.7678359578643462\n",
      "51 Train Loss 0.8066365 Test MSE 2.5875064403344936 Test RE 0.768862678048749\n",
      "52 Train Loss 0.7914206 Test MSE 2.5792562879510013 Test RE 0.7676359567320565\n",
      "53 Train Loss 0.7748011 Test MSE 2.5899682496090395 Test RE 0.7692283473365933\n",
      "54 Train Loss 0.75100845 Test MSE 2.626379914171118 Test RE 0.7746166620752212\n",
      "55 Train Loss 0.73175585 Test MSE 2.6481782482597693 Test RE 0.7778245874088122\n",
      "56 Train Loss 0.7063497 Test MSE 2.6521069586192225 Test RE 0.7784013452194117\n",
      "57 Train Loss 0.6917957 Test MSE 2.665981000263019 Test RE 0.7804347257813222\n",
      "58 Train Loss 0.68281215 Test MSE 2.6642102269238106 Test RE 0.7801754961465546\n",
      "59 Train Loss 0.6739556 Test MSE 2.6662439655327206 Test RE 0.7804732148342475\n",
      "60 Train Loss 0.66683894 Test MSE 2.666332470777006 Test RE 0.7804861685249449\n",
      "61 Train Loss 0.66270924 Test MSE 2.657853375197682 Test RE 0.7792441841627747\n",
      "62 Train Loss 0.65555525 Test MSE 2.672678647038913 Test RE 0.7814144396828115\n",
      "63 Train Loss 0.649225 Test MSE 2.6928104029917446 Test RE 0.7843518920116678\n",
      "64 Train Loss 0.64182764 Test MSE 2.6996969367591097 Test RE 0.785354193695315\n",
      "65 Train Loss 0.63543046 Test MSE 2.7164902325890474 Test RE 0.7877930302221152\n",
      "66 Train Loss 0.6283644 Test MSE 2.7003718442577074 Test RE 0.7854523544007884\n",
      "67 Train Loss 0.62387925 Test MSE 2.693867629988989 Test RE 0.7845058494939017\n",
      "68 Train Loss 0.6196015 Test MSE 2.711694456760913 Test RE 0.7870973259482011\n",
      "69 Train Loss 0.61100566 Test MSE 2.722080040034323 Test RE 0.7886031469415157\n",
      "70 Train Loss 0.6050466 Test MSE 2.722104295818053 Test RE 0.7886066604577402\n",
      "71 Train Loss 0.5998316 Test MSE 2.744961191733333 Test RE 0.791910615460233\n",
      "72 Train Loss 0.5950922 Test MSE 2.7496045459113434 Test RE 0.7925801272446983\n",
      "73 Train Loss 0.5905467 Test MSE 2.738060440332764 Test RE 0.7909145691040851\n",
      "74 Train Loss 0.583994 Test MSE 2.759670291883115 Test RE 0.7940295397047692\n",
      "75 Train Loss 0.57751536 Test MSE 2.770640457601033 Test RE 0.7956061766410933\n",
      "76 Train Loss 0.57153547 Test MSE 2.782714048995782 Test RE 0.7973377946503664\n",
      "77 Train Loss 0.5673302 Test MSE 2.792561374306979 Test RE 0.7987473377300861\n",
      "78 Train Loss 0.5635788 Test MSE 2.7882706249835216 Test RE 0.7981334672313014\n",
      "79 Train Loss 0.55853987 Test MSE 2.7951531972784904 Test RE 0.799117917154168\n",
      "80 Train Loss 0.55390227 Test MSE 2.8003382291062433 Test RE 0.7998587588519666\n",
      "81 Train Loss 0.5498637 Test MSE 2.8147971745618827 Test RE 0.8019210497506664\n",
      "82 Train Loss 0.54466695 Test MSE 2.8343990089937563 Test RE 0.8047084356845544\n",
      "83 Train Loss 0.54038566 Test MSE 2.8442520373313362 Test RE 0.8061058988409187\n",
      "84 Train Loss 0.53637534 Test MSE 2.8498260269433477 Test RE 0.8068953905271505\n",
      "85 Train Loss 0.5332899 Test MSE 2.8577528892136757 Test RE 0.8080168110945996\n",
      "86 Train Loss 0.52997476 Test MSE 2.856376379312256 Test RE 0.8078221866551402\n",
      "87 Train Loss 0.52723926 Test MSE 2.867260794570187 Test RE 0.809359853723657\n",
      "88 Train Loss 0.52372736 Test MSE 2.8831855072999786 Test RE 0.8116043263305325\n",
      "89 Train Loss 0.51949835 Test MSE 2.900931146591628 Test RE 0.8140981555054144\n",
      "90 Train Loss 0.5145943 Test MSE 2.901258392990884 Test RE 0.8141440723444773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 Train Loss 0.5125889 Test MSE 2.8996971390719644 Test RE 0.8139249852278474\n",
      "92 Train Loss 0.5096734 Test MSE 2.903295793030797 Test RE 0.8144298872965161\n",
      "93 Train Loss 0.5074476 Test MSE 2.909935995859926 Test RE 0.8153607071949386\n",
      "94 Train Loss 0.5053205 Test MSE 2.9075935015336336 Test RE 0.8150324590186292\n",
      "95 Train Loss 0.50381786 Test MSE 2.9081046907403154 Test RE 0.8151041020260107\n",
      "96 Train Loss 0.50165707 Test MSE 2.91895847795027 Test RE 0.8166237734276666\n",
      "97 Train Loss 0.49906045 Test MSE 2.9150133650105254 Test RE 0.8160717336611549\n",
      "98 Train Loss 0.49658418 Test MSE 2.92974757738289 Test RE 0.8181315901142268\n",
      "99 Train Loss 0.49447194 Test MSE 2.9520828200994793 Test RE 0.8212442256607331\n",
      "Training time: 75.99\n",
      "KG_stan_tune12\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 59.192734 Test MSE 8.607674256369547 Test RE 1.4023324121342093\n",
      "1 Train Loss 57.4388 Test MSE 8.6319707394973 Test RE 1.4043101668369027\n",
      "2 Train Loss 49.936295 Test MSE 7.646539451114096 Test RE 1.3217232422529324\n",
      "3 Train Loss 38.548912 Test MSE 6.9795214436295945 Test RE 1.2627601941836233\n",
      "4 Train Loss 36.015106 Test MSE 7.247582444707739 Test RE 1.2867810082088311\n",
      "5 Train Loss 33.94593 Test MSE 6.4184123459818085 Test RE 1.210937887692516\n",
      "6 Train Loss 30.820591 Test MSE 6.260383996360493 Test RE 1.1959376725491182\n",
      "7 Train Loss 28.97901 Test MSE 6.424771284227729 Test RE 1.2115375977566973\n",
      "8 Train Loss 27.558075 Test MSE 6.279177899122817 Test RE 1.1977314517259787\n",
      "9 Train Loss 26.13866 Test MSE 6.250813555979297 Test RE 1.195023189677378\n",
      "10 Train Loss 24.937572 Test MSE 5.98553830355237 Test RE 1.1693907856862547\n",
      "11 Train Loss 24.026552 Test MSE 5.695764262221203 Test RE 1.1407331526080422\n",
      "12 Train Loss 23.368816 Test MSE 5.455798990538637 Test RE 1.116444762913232\n",
      "13 Train Loss 23.044132 Test MSE 5.556936399989805 Test RE 1.1267453472988989\n",
      "14 Train Loss 22.741505 Test MSE 5.481532283565895 Test RE 1.1190746254299402\n",
      "15 Train Loss 21.153095 Test MSE 5.4667785356493335 Test RE 1.1175675952118043\n",
      "16 Train Loss 18.996376 Test MSE 5.556818435127251 Test RE 1.1267333877355834\n",
      "17 Train Loss 17.245674 Test MSE 5.577104247358842 Test RE 1.1287881498204493\n",
      "18 Train Loss 16.229399 Test MSE 5.625155642255521 Test RE 1.1336404452940698\n",
      "19 Train Loss 14.60388 Test MSE 5.79181947797909 Test RE 1.1503117840868213\n",
      "20 Train Loss 13.608645 Test MSE 5.940679289209434 Test RE 1.1650005059512878\n",
      "21 Train Loss 12.95259 Test MSE 5.924063503551598 Test RE 1.1633701407911339\n",
      "22 Train Loss 12.4743595 Test MSE 5.824894305976497 Test RE 1.1535915998761488\n",
      "23 Train Loss 12.159367 Test MSE 5.809853848364627 Test RE 1.1521012929847094\n",
      "24 Train Loss 11.795798 Test MSE 5.6926653081428435 Test RE 1.1404227850730084\n",
      "25 Train Loss 11.322262 Test MSE 5.549148501161828 Test RE 1.1259555186263137\n",
      "26 Train Loss 10.449619 Test MSE 4.997922600454205 Test RE 1.0685696214366158\n",
      "27 Train Loss 9.43844 Test MSE 4.798058728445114 Test RE 1.0469859169452258\n",
      "28 Train Loss 9.085705 Test MSE 4.834448648455393 Test RE 1.050948745311427\n",
      "29 Train Loss 7.896266 Test MSE 5.006112106834093 Test RE 1.0694447326111813\n",
      "30 Train Loss 6.952159 Test MSE 4.55852994121037 Test RE 1.0205175226627174\n",
      "31 Train Loss 6.119602 Test MSE 3.882186528210528 Test RE 0.9417730520891807\n",
      "32 Train Loss 5.546151 Test MSE 3.598750302989926 Test RE 0.906742386101067\n",
      "33 Train Loss 5.370801 Test MSE 3.4646878524633995 Test RE 0.8896928839897583\n",
      "34 Train Loss 5.169609 Test MSE 3.402797869848668 Test RE 0.8817107511760206\n",
      "35 Train Loss 5.0094204 Test MSE 3.3111409884900995 Test RE 0.869754925728372\n",
      "36 Train Loss 4.886155 Test MSE 3.202837255984204 Test RE 0.85541231065308\n",
      "37 Train Loss 4.718654 Test MSE 2.775834639687345 Test RE 0.7963515978520751\n",
      "38 Train Loss 4.5970325 Test MSE 2.655519394083736 Test RE 0.7789019642568392\n",
      "39 Train Loss 4.3747168 Test MSE 2.387689286712749 Test RE 0.7385790178103447\n",
      "40 Train Loss 4.3056536 Test MSE 2.267682347484402 Test RE 0.7197789971307091\n",
      "41 Train Loss 4.188235 Test MSE 2.1992515212940034 Test RE 0.7088355832195411\n",
      "42 Train Loss 4.11028 Test MSE 2.1574198420357718 Test RE 0.7020618831008026\n",
      "43 Train Loss 4.0372663 Test MSE 2.1725132687011284 Test RE 0.7045134343548876\n",
      "44 Train Loss 3.9892862 Test MSE 2.1619988385865962 Test RE 0.7028065306916118\n",
      "45 Train Loss 3.949444 Test MSE 2.16797829782746 Test RE 0.7037777387433793\n",
      "46 Train Loss 3.9112594 Test MSE 2.1487782457410622 Test RE 0.7006544095157762\n",
      "47 Train Loss 3.883122 Test MSE 2.1493176502824856 Test RE 0.7007423461039285\n",
      "48 Train Loss 3.868081 Test MSE 2.135331385444606 Test RE 0.6984586528887675\n",
      "49 Train Loss 3.8518183 Test MSE 2.1434940122310855 Test RE 0.6997923613842782\n",
      "50 Train Loss 3.832362 Test MSE 2.1432497858188007 Test RE 0.6997524936157401\n",
      "51 Train Loss 3.8149471 Test MSE 2.1425727610071252 Test RE 0.6996419635174498\n",
      "52 Train Loss 3.791626 Test MSE 2.143539543465785 Test RE 0.6997997936982633\n",
      "53 Train Loss 3.7619176 Test MSE 2.1588480928338565 Test RE 0.7022942334587325\n",
      "54 Train Loss 3.746377 Test MSE 2.159870245347593 Test RE 0.7024604718494869\n",
      "55 Train Loss 3.6965933 Test MSE 2.1363607121579826 Test RE 0.6986269770033969\n",
      "56 Train Loss 3.6301506 Test MSE 2.1443891390073753 Test RE 0.6999384633780009\n",
      "57 Train Loss 3.2943954 Test MSE 1.8726197838425114 Test RE 0.6540830033455599\n",
      "58 Train Loss 1.6730282 Test MSE 0.950541616296555 Test RE 0.4660082745132156\n",
      "59 Train Loss 1.0793948 Test MSE 0.6867546273029934 Test RE 0.39610366195831404\n",
      "60 Train Loss 0.8153437 Test MSE 0.5540844313447811 Test RE 0.35579188147230245\n",
      "61 Train Loss 0.5554151 Test MSE 0.4090553824270945 Test RE 0.30570258848806053\n",
      "62 Train Loss 0.3905028 Test MSE 0.19530329276436456 Test RE 0.211233523312946\n",
      "63 Train Loss 0.29347613 Test MSE 0.10329934193324261 Test RE 0.1536232107557324\n",
      "64 Train Loss 0.22042905 Test MSE 0.06198281477613532 Test RE 0.1189991084365666\n",
      "65 Train Loss 0.17512757 Test MSE 0.05425899153156717 Test RE 0.11133812905878983\n",
      "66 Train Loss 0.12780802 Test MSE 0.029771446320129374 Test RE 0.08247228492951703\n",
      "67 Train Loss 0.11094666 Test MSE 0.03533333232536172 Test RE 0.08984633360052172\n",
      "68 Train Loss 0.09218563 Test MSE 0.027661038492278064 Test RE 0.07949545525156843\n",
      "69 Train Loss 0.08124261 Test MSE 0.024658676120717007 Test RE 0.07505730013676759\n",
      "70 Train Loss 0.06898711 Test MSE 0.020045566185788472 Test RE 0.06767327961324823\n",
      "71 Train Loss 0.058356304 Test MSE 0.014502183067606795 Test RE 0.0575605257196581\n",
      "72 Train Loss 0.04598323 Test MSE 0.010325606871689428 Test RE 0.04856974835068719\n",
      "73 Train Loss 0.040160734 Test MSE 0.010474619705485529 Test RE 0.04891895740018398\n",
      "74 Train Loss 0.036109142 Test MSE 0.008110795928641366 Test RE 0.043046693445970445\n",
      "75 Train Loss 0.030036492 Test MSE 0.006780067999646604 Test RE 0.039357280776372024\n",
      "76 Train Loss 0.024504406 Test MSE 0.007339922988106843 Test RE 0.040949991118027364\n",
      "77 Train Loss 0.023036007 Test MSE 0.006863353431670271 Test RE 0.03959827269605817\n",
      "78 Train Loss 0.019651394 Test MSE 0.0050798651937991645 Test RE 0.034067020667092385\n",
      "79 Train Loss 0.018302776 Test MSE 0.004290854687426113 Test RE 0.031309776237193776\n",
      "80 Train Loss 0.016753048 Test MSE 0.003651485638183913 Test RE 0.02888303714016493\n",
      "81 Train Loss 0.014997236 Test MSE 0.003491254048823486 Test RE 0.028242217054763482\n",
      "82 Train Loss 0.013133248 Test MSE 0.0040037838726223116 Test RE 0.030244288575286066\n",
      "83 Train Loss 0.012317019 Test MSE 0.003654563579072789 Test RE 0.028895207741882235\n",
      "84 Train Loss 0.011079889 Test MSE 0.0034198180072372007 Test RE 0.027951785677902106\n",
      "85 Train Loss 0.009314427 Test MSE 0.0024222808051602416 Test RE 0.023524494725529553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 0.008928563 Test MSE 0.002286622787817915 Test RE 0.02285626822064223\n",
      "87 Train Loss 0.008556384 Test MSE 0.0021812738606789036 Test RE 0.022323544777695006\n",
      "88 Train Loss 0.0076508923 Test MSE 0.0019822928391344348 Test RE 0.021280996796339095\n",
      "89 Train Loss 0.006852127 Test MSE 0.001384654879948708 Test RE 0.017786022221794314\n",
      "90 Train Loss 0.0064099864 Test MSE 0.001349506687044081 Test RE 0.017558830266964517\n",
      "91 Train Loss 0.0061018346 Test MSE 0.0012011658656056992 Test RE 0.01656569081318725\n",
      "92 Train Loss 0.0058274204 Test MSE 0.001159305880223593 Test RE 0.016274478451776684\n",
      "93 Train Loss 0.005254831 Test MSE 0.000920148104841173 Test RE 0.014498962555508588\n",
      "94 Train Loss 0.004968714 Test MSE 0.0009172421609044079 Test RE 0.014476049673219374\n",
      "95 Train Loss 0.0046577468 Test MSE 0.0009312474840318035 Test RE 0.014586148020845565\n",
      "96 Train Loss 0.0043158727 Test MSE 0.0007834843337942011 Test RE 0.013378986599519941\n",
      "97 Train Loss 0.0040542306 Test MSE 0.0007760059361793065 Test RE 0.013314981949332226\n",
      "98 Train Loss 0.003944899 Test MSE 0.0007608816581755563 Test RE 0.01318458965740937\n",
      "99 Train Loss 0.0036054337 Test MSE 0.0006361805458254719 Test RE 0.012055861566704717\n",
      "Training time: 76.89\n",
      "KG_stan_tune12\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.55753 Test MSE 8.674079227434884 Test RE 1.4077312533270174\n",
      "1 Train Loss 56.80223 Test MSE 8.972428519556042 Test RE 1.4317363913828653\n",
      "2 Train Loss 48.670902 Test MSE 8.86771878502908 Test RE 1.4233575730722177\n",
      "3 Train Loss 45.220345 Test MSE 8.165337373466073 Test RE 1.3658252178726298\n",
      "4 Train Loss 44.64549 Test MSE 8.41036143073867 Test RE 1.3861664721758398\n",
      "5 Train Loss 44.291496 Test MSE 8.539670009496549 Test RE 1.3967819196622897\n",
      "6 Train Loss 44.114365 Test MSE 8.53626487310101 Test RE 1.396503413164406\n",
      "7 Train Loss 44.02026 Test MSE 8.494180785204279 Test RE 1.3930567542556735\n",
      "8 Train Loss 43.78056 Test MSE 8.559867081209298 Test RE 1.3984327003098274\n",
      "9 Train Loss 43.252335 Test MSE 8.331161303895243 Test RE 1.379624289358394\n",
      "10 Train Loss 43.122883 Test MSE 8.35771819190634 Test RE 1.3818214246129914\n",
      "11 Train Loss 42.79619 Test MSE 8.463535149791202 Test RE 1.3905415214298114\n",
      "12 Train Loss 42.63587 Test MSE 8.584854733199345 Test RE 1.400472339768313\n",
      "13 Train Loss 42.44915 Test MSE 8.649698223643844 Test RE 1.4057514435984453\n",
      "14 Train Loss 41.877136 Test MSE 8.714957846614643 Test RE 1.4110444850681123\n",
      "15 Train Loss 41.625046 Test MSE 8.797367994572577 Test RE 1.4177003276806794\n",
      "16 Train Loss 41.464935 Test MSE 8.868367222650026 Test RE 1.4234096124833084\n",
      "17 Train Loss 41.2762 Test MSE 8.804421845099528 Test RE 1.4182685795958652\n",
      "18 Train Loss 40.72911 Test MSE 8.911468852973684 Test RE 1.4268644148058092\n",
      "19 Train Loss 38.662186 Test MSE 9.121153704462804 Test RE 1.443553710644895\n",
      "20 Train Loss 33.23786 Test MSE 9.025963560285838 Test RE 1.4360013500435567\n",
      "21 Train Loss 30.673092 Test MSE 8.385474422800597 Test RE 1.3841140577564934\n",
      "22 Train Loss 30.101418 Test MSE 8.290988813389966 Test RE 1.3762940263281798\n",
      "23 Train Loss 29.481514 Test MSE 8.166423241639098 Test RE 1.3659160320522339\n",
      "24 Train Loss 29.097137 Test MSE 7.958469075265396 Test RE 1.3484126768451115\n",
      "25 Train Loss 27.971897 Test MSE 7.3841133948860085 Test RE 1.2988447371304936\n",
      "26 Train Loss 27.464699 Test MSE 7.23797719695443 Test RE 1.2859280376950664\n",
      "27 Train Loss 26.655188 Test MSE 6.521369815743147 Test RE 1.2206115489974687\n",
      "28 Train Loss 24.351467 Test MSE 6.341079189437586 Test RE 1.2036207014374514\n",
      "29 Train Loss 21.784618 Test MSE 5.834857978073905 Test RE 1.1545778063901244\n",
      "30 Train Loss 20.733643 Test MSE 5.588668586092289 Test RE 1.129957836464293\n",
      "31 Train Loss 19.42748 Test MSE 5.478820193720576 Test RE 1.118797749706773\n",
      "32 Train Loss 18.88306 Test MSE 5.226872845194512 Test RE 1.0927706644847839\n",
      "33 Train Loss 18.607506 Test MSE 5.4391206933163 Test RE 1.1147369791418889\n",
      "34 Train Loss 18.252731 Test MSE 5.493295276514756 Test RE 1.1202747107101891\n",
      "35 Train Loss 18.022797 Test MSE 5.505737376515899 Test RE 1.1215426824488373\n",
      "36 Train Loss 17.870483 Test MSE 5.552590710657975 Test RE 1.1263046869640803\n",
      "37 Train Loss 17.525589 Test MSE 5.533475027407694 Test RE 1.1243642732978942\n",
      "38 Train Loss 17.266447 Test MSE 5.576686255801695 Test RE 1.128745848947418\n",
      "39 Train Loss 16.800207 Test MSE 5.597150517523086 Test RE 1.1308149807912022\n",
      "40 Train Loss 16.166555 Test MSE 5.926861760616291 Test RE 1.1636448698160282\n",
      "41 Train Loss 15.732132 Test MSE 5.913655927309879 Test RE 1.1623477694092992\n",
      "42 Train Loss 15.171226 Test MSE 5.869842303625506 Test RE 1.158033911200578\n",
      "43 Train Loss 14.63116 Test MSE 5.742582338590101 Test RE 1.1454118602845975\n",
      "44 Train Loss 14.052738 Test MSE 5.869021166202321 Test RE 1.157952909174401\n",
      "45 Train Loss 13.569056 Test MSE 5.60852280219347 Test RE 1.131963192211484\n",
      "46 Train Loss 12.120926 Test MSE 4.642137247327175 Test RE 1.0298335791890454\n",
      "47 Train Loss 10.789537 Test MSE 4.442353778668829 Test RE 1.0074294240545376\n",
      "48 Train Loss 9.79808 Test MSE 4.163163265768413 Test RE 0.9752585843166391\n",
      "49 Train Loss 9.347313 Test MSE 4.1546736538217965 Test RE 0.9742636927310173\n",
      "50 Train Loss 8.927264 Test MSE 3.904080946808667 Test RE 0.9444249832687559\n",
      "51 Train Loss 8.583799 Test MSE 3.842405341643902 Test RE 0.9369354018728122\n",
      "52 Train Loss 8.3230915 Test MSE 3.686779275766788 Test RE 0.9177652909739662\n",
      "53 Train Loss 8.061299 Test MSE 3.592303324024154 Test RE 0.9059298304863708\n",
      "54 Train Loss 7.7591267 Test MSE 3.41807023828211 Test RE 0.8836871741850186\n",
      "55 Train Loss 7.6253395 Test MSE 3.412254709623178 Test RE 0.8829350983763349\n",
      "56 Train Loss 7.5348024 Test MSE 3.339693620048295 Test RE 0.8734969114862768\n",
      "57 Train Loss 7.447916 Test MSE 3.3561937197804794 Test RE 0.8756520534949265\n",
      "58 Train Loss 7.363653 Test MSE 3.2844009497107316 Test RE 0.8662358327264821\n",
      "59 Train Loss 7.222574 Test MSE 3.281258077051308 Test RE 0.8658212791202844\n",
      "60 Train Loss 7.0757027 Test MSE 3.2937190947082335 Test RE 0.8674637574343117\n",
      "61 Train Loss 7.026222 Test MSE 3.2949927500728706 Test RE 0.8676314619421897\n",
      "62 Train Loss 6.8732214 Test MSE 3.286418415907224 Test RE 0.8665018375856266\n",
      "63 Train Loss 6.723654 Test MSE 3.248528341470319 Test RE 0.8614922806241114\n",
      "64 Train Loss 6.6257744 Test MSE 3.1925823025187827 Test RE 0.8540417685688821\n",
      "65 Train Loss 6.211357 Test MSE 2.9700329779504813 Test RE 0.8237372320163684\n",
      "66 Train Loss 3.9756358 Test MSE 2.2238848321862674 Test RE 0.712794281207802\n",
      "67 Train Loss 3.3638542 Test MSE 2.22530103042004 Test RE 0.7130212033329273\n",
      "68 Train Loss 3.0371974 Test MSE 2.2408685168914912 Test RE 0.7155108895554615\n",
      "69 Train Loss 2.828599 Test MSE 2.260595353106316 Test RE 0.7186533850192213\n",
      "70 Train Loss 2.5061133 Test MSE 2.345101878597988 Test RE 0.7319626445627566\n",
      "71 Train Loss 2.3648872 Test MSE 2.417801192172113 Test RE 0.7432216531368278\n",
      "72 Train Loss 2.2041578 Test MSE 2.4708189088092314 Test RE 0.7513261735940003\n",
      "73 Train Loss 2.1140435 Test MSE 2.5017818180048694 Test RE 0.7560191150001015\n",
      "74 Train Loss 2.0771105 Test MSE 2.4920880577829303 Test RE 0.7545530037401912\n",
      "75 Train Loss 2.03035 Test MSE 2.455595033311421 Test RE 0.7490079605020833\n",
      "76 Train Loss 1.9569303 Test MSE 2.498069236969466 Test RE 0.7554579500974755\n",
      "77 Train Loss 1.8964868 Test MSE 2.525841966363938 Test RE 0.7596458115622908\n",
      "78 Train Loss 1.8451355 Test MSE 2.5544243083640015 Test RE 0.763931783807915\n",
      "79 Train Loss 1.8088645 Test MSE 2.5447533126226705 Test RE 0.7624842977820736\n",
      "80 Train Loss 1.7834376 Test MSE 2.5346038819102104 Test RE 0.7609622419450041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 Train Loss 1.7251539 Test MSE 2.5042993391696733 Test RE 0.7563994070649452\n",
      "82 Train Loss 1.7147496 Test MSE 2.4953407446461737 Test RE 0.7550452665051389\n",
      "83 Train Loss 1.6685246 Test MSE 2.516957849929891 Test RE 0.7583086877948229\n",
      "84 Train Loss 1.6420993 Test MSE 2.509764847121687 Test RE 0.7572243591278318\n",
      "85 Train Loss 1.62954 Test MSE 2.487341207403876 Test RE 0.7538340368826532\n",
      "86 Train Loss 1.5875957 Test MSE 2.4816639714113573 Test RE 0.7529732505632648\n",
      "87 Train Loss 1.5444027 Test MSE 2.508518131618599 Test RE 0.7570362617019956\n",
      "88 Train Loss 1.5331726 Test MSE 2.5240411023129368 Test RE 0.7593749587576055\n",
      "89 Train Loss 1.4919174 Test MSE 2.501395325532884 Test RE 0.7559607152266893\n",
      "90 Train Loss 1.4438494 Test MSE 2.5479621527794794 Test RE 0.7629648786326564\n",
      "91 Train Loss 1.4304556 Test MSE 2.539354854299363 Test RE 0.7616750985058133\n",
      "92 Train Loss 1.4080741 Test MSE 2.5369116103701153 Test RE 0.7613085869283401\n",
      "93 Train Loss 1.3675499 Test MSE 2.5591004196328995 Test RE 0.764630688191392\n",
      "94 Train Loss 1.3275732 Test MSE 2.5673207005112353 Test RE 0.7658577677446773\n",
      "95 Train Loss 1.2876776 Test MSE 2.5802297858894496 Test RE 0.7677808088595622\n",
      "96 Train Loss 1.2699183 Test MSE 2.593178693487455 Test RE 0.7697049554213388\n",
      "97 Train Loss 1.2504752 Test MSE 2.6043778980162995 Test RE 0.7713652336664294\n",
      "98 Train Loss 1.2311456 Test MSE 2.6108200034030458 Test RE 0.772318656555274\n",
      "99 Train Loss 1.2189008 Test MSE 2.575037003174914 Test RE 0.767007829859516\n",
      "Training time: 80.01\n",
      "KG_stan_tune12\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.201492 Test MSE 8.510484077943516 Test RE 1.3943929940478574\n",
      "1 Train Loss 52.073936 Test MSE 8.672712854143361 Test RE 1.4076203734232022\n",
      "2 Train Loss 45.943268 Test MSE 7.642333623649169 Test RE 1.3213596984201101\n",
      "3 Train Loss 38.529583 Test MSE 7.453420273350997 Test RE 1.3049259432962903\n",
      "4 Train Loss 36.63984 Test MSE 7.333192301584752 Test RE 1.294358551122249\n",
      "5 Train Loss 35.124535 Test MSE 7.316989955068282 Test RE 1.2929278479794633\n",
      "6 Train Loss 32.395172 Test MSE 7.246689960588491 Test RE 1.2867017771700093\n",
      "7 Train Loss 31.046211 Test MSE 6.418087572920952 Test RE 1.2109072504446872\n",
      "8 Train Loss 30.054436 Test MSE 6.356619406458944 Test RE 1.2050946682875172\n",
      "9 Train Loss 29.180752 Test MSE 6.295096488725435 Test RE 1.199248698662494\n",
      "10 Train Loss 28.18787 Test MSE 6.22262083637653 Test RE 1.1923252186089586\n",
      "11 Train Loss 27.370922 Test MSE 6.236508390413627 Test RE 1.1936549840638768\n",
      "12 Train Loss 26.797894 Test MSE 6.086736351738204 Test RE 1.1792348503950818\n",
      "13 Train Loss 25.788082 Test MSE 6.1492839907607895 Test RE 1.1852783055931186\n",
      "14 Train Loss 25.270195 Test MSE 5.812285980215708 Test RE 1.152342415148339\n",
      "15 Train Loss 24.504078 Test MSE 5.648715863753492 Test RE 1.1360120162789515\n",
      "16 Train Loss 24.111897 Test MSE 5.471374341511156 Test RE 1.118037254323405\n",
      "17 Train Loss 23.767677 Test MSE 5.486832201364141 Test RE 1.1196154934105063\n",
      "18 Train Loss 23.501564 Test MSE 5.296710959290186 Test RE 1.1000468895592945\n",
      "19 Train Loss 23.137976 Test MSE 5.223755830603295 Test RE 1.0924447822438592\n",
      "20 Train Loss 22.982227 Test MSE 5.291584839441452 Test RE 1.0995144518598872\n",
      "21 Train Loss 22.769299 Test MSE 5.391869910807174 Test RE 1.1098844404018402\n",
      "22 Train Loss 22.56762 Test MSE 5.4861616341065575 Test RE 1.1195470750222931\n",
      "23 Train Loss 22.415306 Test MSE 5.411969967167463 Test RE 1.1119512546939656\n",
      "24 Train Loss 22.309925 Test MSE 5.4732306117495835 Test RE 1.1182268961896684\n",
      "25 Train Loss 22.207188 Test MSE 5.488670379742375 Test RE 1.1198030224413689\n",
      "26 Train Loss 22.07587 Test MSE 5.551907945746973 Test RE 1.1262354377612647\n",
      "27 Train Loss 21.733467 Test MSE 5.674249723457285 Test RE 1.1385766757727998\n",
      "28 Train Loss 21.590988 Test MSE 5.712078240707477 Test RE 1.142365645505275\n",
      "29 Train Loss 21.45212 Test MSE 5.602377906569431 Test RE 1.1313429128429173\n",
      "30 Train Loss 21.21867 Test MSE 5.5081944272044465 Test RE 1.1217929104977347\n",
      "31 Train Loss 20.752712 Test MSE 4.9767230770848805 Test RE 1.0663009548972011\n",
      "32 Train Loss 19.701115 Test MSE 5.097959976092252 Test RE 1.0792107707549816\n",
      "33 Train Loss 17.60461 Test MSE 4.667726135600255 Test RE 1.0326680581426508\n",
      "34 Train Loss 16.018229 Test MSE 4.398391035824108 Test RE 1.0024321316980136\n",
      "35 Train Loss 14.553555 Test MSE 4.494846568705529 Test RE 1.0133640567501827\n",
      "36 Train Loss 13.393864 Test MSE 3.975759538521171 Test RE 0.9530553312205793\n",
      "37 Train Loss 12.569046 Test MSE 3.9920508694861288 Test RE 0.9550059857487724\n",
      "38 Train Loss 11.670732 Test MSE 3.9347924466068056 Test RE 0.9481323717512812\n",
      "39 Train Loss 11.083935 Test MSE 4.173172652048457 Test RE 0.9764302750285448\n",
      "40 Train Loss 10.722046 Test MSE 3.8570854826346466 Test RE 0.9387235046741099\n",
      "41 Train Loss 10.609177 Test MSE 4.004799223374464 Test RE 0.956529644932691\n",
      "42 Train Loss 10.28433 Test MSE 3.9016067052710155 Test RE 0.9441256675139001\n",
      "43 Train Loss 9.8782835 Test MSE 3.8818924920361373 Test RE 0.9417373865451699\n",
      "44 Train Loss 9.663723 Test MSE 3.8814132481322243 Test RE 0.941679253066074\n",
      "45 Train Loss 9.475032 Test MSE 3.8064267001875187 Test RE 0.9325385537755848\n",
      "46 Train Loss 9.284976 Test MSE 3.6218492547393626 Test RE 0.9096477414613958\n",
      "47 Train Loss 8.910873 Test MSE 3.3522619545435988 Test RE 0.8751389920471634\n",
      "48 Train Loss 8.50139 Test MSE 3.000092917817748 Test RE 0.8278952924917271\n",
      "49 Train Loss 8.155361 Test MSE 2.531544532767243 Test RE 0.7605028502168986\n",
      "50 Train Loss 7.4072866 Test MSE 2.3324164786792387 Test RE 0.7299802510185497\n",
      "51 Train Loss 7.221041 Test MSE 2.3691642497484797 Test RE 0.7357082829761961\n",
      "52 Train Loss 6.993356 Test MSE 2.2400543854929387 Test RE 0.715380901384506\n",
      "53 Train Loss 6.682006 Test MSE 2.2413837090522426 Test RE 0.7155931354376843\n",
      "54 Train Loss 6.487705 Test MSE 2.2199897446923886 Test RE 0.7121697855469034\n",
      "55 Train Loss 6.249057 Test MSE 2.188899512045459 Test RE 0.7071653495567413\n",
      "56 Train Loss 5.9987006 Test MSE 2.216131674307744 Test RE 0.7115506845010408\n",
      "57 Train Loss 5.8206015 Test MSE 2.216658961907714 Test RE 0.7116353296379246\n",
      "58 Train Loss 5.711367 Test MSE 2.17752569387767 Test RE 0.7053256932270987\n",
      "59 Train Loss 5.5495257 Test MSE 2.1557465945679706 Test RE 0.7017895784000647\n",
      "60 Train Loss 5.4249873 Test MSE 2.167094660555207 Test RE 0.7036342992027987\n",
      "61 Train Loss 5.33934 Test MSE 2.1789695946145016 Test RE 0.7055595025273246\n",
      "62 Train Loss 5.2847557 Test MSE 2.199359476599136 Test RE 0.7088529804162433\n",
      "63 Train Loss 5.2326326 Test MSE 2.2041387070410416 Test RE 0.7096227348288778\n",
      "64 Train Loss 5.117482 Test MSE 2.1988810536899157 Test RE 0.7087758784341915\n",
      "65 Train Loss 5.0538063 Test MSE 2.209729354567321 Test RE 0.710522119721174\n",
      "66 Train Loss 4.853462 Test MSE 2.1836894268570606 Test RE 0.7063232399186298\n",
      "67 Train Loss 4.7862024 Test MSE 2.1863233099302852 Test RE 0.7067490816531066\n",
      "68 Train Loss 4.757551 Test MSE 2.1762450698435325 Test RE 0.7051182582747101\n",
      "69 Train Loss 4.7064157 Test MSE 2.160868037505077 Test RE 0.7026227104423867\n",
      "70 Train Loss 4.67673 Test MSE 2.1386649367410486 Test RE 0.6990036361529871\n",
      "71 Train Loss 4.642926 Test MSE 2.1455273178373298 Test RE 0.700124192135098\n",
      "72 Train Loss 4.615474 Test MSE 2.128894889208448 Test RE 0.6974051818886983\n",
      "73 Train Loss 4.55669 Test MSE 2.1253769474323816 Test RE 0.6968287219535143\n",
      "74 Train Loss 4.5020547 Test MSE 2.161034152507841 Test RE 0.7026497167029337\n",
      "75 Train Loss 4.4694576 Test MSE 2.1476880802091785 Test RE 0.7004766512492377\n",
      "76 Train Loss 4.446972 Test MSE 2.1531495546188713 Test RE 0.7013667260984093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 Train Loss 4.401215 Test MSE 2.1790627320755376 Test RE 0.7055745815166403\n",
      "78 Train Loss 4.379165 Test MSE 2.165100613121053 Test RE 0.7033105009157828\n",
      "79 Train Loss 4.3632274 Test MSE 2.1621473047006576 Test RE 0.7028306614083865\n",
      "80 Train Loss 4.33792 Test MSE 2.1679787757798996 Test RE 0.703777816320786\n",
      "81 Train Loss 4.30921 Test MSE 2.1397578675968623 Test RE 0.6991822207108892\n",
      "82 Train Loss 4.2754345 Test MSE 2.1724820937811895 Test RE 0.7045083795575198\n",
      "83 Train Loss 4.250199 Test MSE 2.1613611269093655 Test RE 0.7027028717584638\n",
      "84 Train Loss 4.2351966 Test MSE 2.1726344282009333 Test RE 0.7045330791843297\n",
      "85 Train Loss 4.221264 Test MSE 2.1745089941709455 Test RE 0.7048369519768392\n",
      "86 Train Loss 4.19487 Test MSE 2.1618079393058056 Test RE 0.7027755019462218\n",
      "87 Train Loss 4.164416 Test MSE 2.164468093260206 Test RE 0.7032077596499051\n",
      "88 Train Loss 4.1545696 Test MSE 2.183125871834517 Test RE 0.7062320919537214\n",
      "89 Train Loss 4.137211 Test MSE 2.1512499424351232 Test RE 0.7010572680848505\n",
      "90 Train Loss 4.128178 Test MSE 2.1443619357424852 Test RE 0.6999340237286236\n",
      "91 Train Loss 4.118449 Test MSE 2.159509584783369 Test RE 0.7024018200930221\n",
      "92 Train Loss 4.110204 Test MSE 2.1552845126617655 Test RE 0.7017143604578638\n",
      "93 Train Loss 4.097572 Test MSE 2.153715035461388 Test RE 0.7014588198894351\n",
      "94 Train Loss 4.076789 Test MSE 2.154276767090302 Test RE 0.7015502911169557\n",
      "95 Train Loss 4.0662346 Test MSE 2.154444926832684 Test RE 0.701577671585409\n",
      "96 Train Loss 4.0487146 Test MSE 2.1657389046821827 Test RE 0.7034141644761548\n",
      "97 Train Loss 4.0243177 Test MSE 2.17692588679063 Test RE 0.7052285443190588\n",
      "98 Train Loss 3.9888048 Test MSE 2.1714319484223026 Test RE 0.7043380845674571\n",
      "99 Train Loss 3.4155428 Test MSE 1.6546201930864475 Test RE 0.6148330721734033\n",
      "Training time: 78.59\n",
      "KG_stan_tune12\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.31354 Test MSE 8.627204378973731 Test RE 1.403922400648369\n",
      "1 Train Loss 54.455017 Test MSE 8.600584112464807 Test RE 1.401754742335666\n",
      "2 Train Loss 45.352318 Test MSE 8.924847074078684 Test RE 1.4279350435133173\n",
      "3 Train Loss 43.724014 Test MSE 8.750758401061246 Test RE 1.413939760219774\n",
      "4 Train Loss 42.987385 Test MSE 8.395915384314934 Test RE 1.3849754870092827\n",
      "5 Train Loss 42.178665 Test MSE 8.406931380028405 Test RE 1.3858837788452816\n",
      "6 Train Loss 41.90847 Test MSE 8.373883741679203 Test RE 1.3831571427725693\n",
      "7 Train Loss 41.704216 Test MSE 8.405497427080421 Test RE 1.3857655801358055\n",
      "8 Train Loss 41.299248 Test MSE 8.547421507349684 Test RE 1.3974157085668977\n",
      "9 Train Loss 41.12432 Test MSE 8.723347127471767 Test RE 1.4117234786585895\n",
      "10 Train Loss 40.36923 Test MSE 8.70733664768093 Test RE 1.4104273734885886\n",
      "11 Train Loss 39.745472 Test MSE 8.839550673926928 Test RE 1.4210951431981218\n",
      "12 Train Loss 39.129208 Test MSE 8.982799535513411 Test RE 1.4325636073720003\n",
      "13 Train Loss 38.076054 Test MSE 8.71418737312814 Test RE 1.4109821097581594\n",
      "14 Train Loss 34.716812 Test MSE 8.764965004898308 Test RE 1.4150870399716036\n",
      "15 Train Loss 31.651104 Test MSE 8.24347148383124 Test RE 1.372344449878883\n",
      "16 Train Loss 30.953688 Test MSE 7.801712306951036 Test RE 1.3350668916926096\n",
      "17 Train Loss 30.469696 Test MSE 7.7100099796919785 Test RE 1.327197424903516\n",
      "18 Train Loss 29.38867 Test MSE 7.8319485088806955 Test RE 1.337651472767118\n",
      "19 Train Loss 28.020485 Test MSE 8.534687768647046 Test RE 1.396374402787986\n",
      "20 Train Loss 27.351042 Test MSE 8.503711317232028 Test RE 1.3938380450201362\n",
      "21 Train Loss 26.7896 Test MSE 8.500769729867233 Test RE 1.3935969472885388\n",
      "22 Train Loss 26.094053 Test MSE 8.282977923690837 Test RE 1.375628966683896\n",
      "23 Train Loss 25.471386 Test MSE 8.271820415281578 Test RE 1.3747021403550121\n",
      "24 Train Loss 24.331615 Test MSE 8.014059426904694 Test RE 1.3531138506256466\n",
      "25 Train Loss 22.017868 Test MSE 7.427086600760391 Test RE 1.3026186872025514\n",
      "26 Train Loss 20.5755 Test MSE 6.646902947615597 Test RE 1.2323036337072926\n",
      "27 Train Loss 20.105846 Test MSE 6.842806560098356 Test RE 1.2503315552047258\n",
      "28 Train Loss 19.648552 Test MSE 6.956796692617269 Test RE 1.2607027961785355\n",
      "29 Train Loss 19.104607 Test MSE 6.701086439187352 Test RE 1.2373161179235677\n",
      "30 Train Loss 18.57031 Test MSE 6.637806679759905 Test RE 1.2314601430137952\n",
      "31 Train Loss 17.295872 Test MSE 6.694911165656173 Test RE 1.2367458725866094\n",
      "32 Train Loss 16.552769 Test MSE 6.979601220534766 Test RE 1.2627674109257176\n",
      "33 Train Loss 15.704348 Test MSE 7.167521128205786 Test RE 1.2796539783105894\n",
      "34 Train Loss 14.78269 Test MSE 7.395373490382791 Test RE 1.2998346694182856\n",
      "35 Train Loss 14.311802 Test MSE 7.242399987699457 Test RE 1.2863208630597798\n",
      "36 Train Loss 14.048196 Test MSE 7.126898417829313 Test RE 1.276022536119398\n",
      "37 Train Loss 13.691399 Test MSE 7.242998509997195 Test RE 1.286374013660017\n",
      "38 Train Loss 13.339131 Test MSE 7.199051765712527 Test RE 1.282465552095118\n",
      "39 Train Loss 13.19277 Test MSE 7.323556772714475 Test RE 1.2935079032568388\n",
      "40 Train Loss 12.893829 Test MSE 7.430740462062248 Test RE 1.302939068734718\n",
      "41 Train Loss 12.625158 Test MSE 7.361148346477062 Test RE 1.2968234206530092\n",
      "42 Train Loss 12.217342 Test MSE 7.420342672572448 Test RE 1.3020271522950864\n",
      "43 Train Loss 11.7003 Test MSE 6.996146085672462 Test RE 1.2642631948112988\n",
      "44 Train Loss 10.871929 Test MSE 6.554628245077526 Test RE 1.2237200980525489\n",
      "45 Train Loss 10.166375 Test MSE 6.510453267363812 Test RE 1.2195894902569677\n",
      "46 Train Loss 9.497349 Test MSE 6.4889755615394185 Test RE 1.217576141712961\n",
      "47 Train Loss 9.085667 Test MSE 6.5386268670928835 Test RE 1.2222254920819124\n",
      "48 Train Loss 8.70889 Test MSE 6.351735980025712 Test RE 1.204631676759235\n",
      "49 Train Loss 8.308292 Test MSE 6.398683144034924 Test RE 1.2090753378675492\n",
      "50 Train Loss 7.9167056 Test MSE 6.163251755673849 Test RE 1.1866236897125515\n",
      "51 Train Loss 6.752981 Test MSE 5.8447835154828 Test RE 1.1555594014771324\n",
      "52 Train Loss 5.3715153 Test MSE 5.16378548585468 Test RE 1.0861558772306414\n",
      "53 Train Loss 4.814558 Test MSE 5.026737846430709 Test RE 1.0716455837244985\n",
      "54 Train Loss 4.4197106 Test MSE 5.2342844114372875 Test RE 1.093545149855833\n",
      "55 Train Loss 4.0489674 Test MSE 5.290535222619287 Test RE 1.0994053988885508\n",
      "56 Train Loss 3.8182921 Test MSE 5.365035691366608 Test RE 1.1071191631022075\n",
      "57 Train Loss 3.586446 Test MSE 5.4533757796470335 Test RE 1.1161967990877917\n",
      "58 Train Loss 3.4846325 Test MSE 5.449367934580865 Test RE 1.1157865608929969\n",
      "59 Train Loss 3.3475478 Test MSE 5.547246843200915 Test RE 1.1257625731907202\n",
      "60 Train Loss 3.1824384 Test MSE 5.620658507158185 Test RE 1.1331871997382483\n",
      "61 Train Loss 3.089163 Test MSE 5.6689301356211494 Test RE 1.1380428449455422\n",
      "62 Train Loss 2.9816866 Test MSE 5.660838802430978 Test RE 1.137230383710021\n",
      "63 Train Loss 2.9120457 Test MSE 5.719591215905921 Test RE 1.143116663273135\n",
      "64 Train Loss 2.824786 Test MSE 5.67672977866663 Test RE 1.1388254685363721\n",
      "65 Train Loss 2.7497826 Test MSE 5.712845773144256 Test RE 1.142442392811475\n",
      "66 Train Loss 2.674926 Test MSE 5.74108480954057 Test RE 1.1452625024456973\n",
      "67 Train Loss 2.5715718 Test MSE 5.798712533037347 Test RE 1.150996094492099\n",
      "68 Train Loss 2.466648 Test MSE 5.863632436866175 Test RE 1.1574211912263948\n",
      "69 Train Loss 2.3919282 Test MSE 5.9982328753640175 Test RE 1.1706301940602197\n",
      "70 Train Loss 2.3166838 Test MSE 6.0089059488550385 Test RE 1.1716712230875157\n",
      "71 Train Loss 2.210639 Test MSE 6.125822444041609 Test RE 1.1830150308997684\n",
      "72 Train Loss 2.1317108 Test MSE 6.201399477539779 Test RE 1.1902903548669046\n",
      "73 Train Loss 2.0832052 Test MSE 6.111958335050617 Test RE 1.1816755585243106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Train Loss 2.0142767 Test MSE 6.126203710562049 Test RE 1.1830518453039274\n",
      "75 Train Loss 1.9637549 Test MSE 6.153370374189513 Test RE 1.1856720666584677\n",
      "76 Train Loss 1.9272916 Test MSE 6.16484978649797 Test RE 1.1867775158425296\n",
      "77 Train Loss 1.8711768 Test MSE 6.114789971591008 Test RE 1.1819492587069815\n",
      "78 Train Loss 1.8158854 Test MSE 6.139078859368714 Test RE 1.18429437449474\n",
      "79 Train Loss 1.7741617 Test MSE 6.0812117031869235 Test RE 1.1786995604867245\n",
      "80 Train Loss 1.7420582 Test MSE 6.082477413017321 Test RE 1.1788222181142793\n",
      "81 Train Loss 1.6934294 Test MSE 6.111159986921281 Test RE 1.1815983803738366\n",
      "82 Train Loss 1.6675148 Test MSE 6.113207039393505 Test RE 1.181796263539164\n",
      "83 Train Loss 1.63769 Test MSE 6.127125620088887 Test RE 1.1831408584831289\n",
      "84 Train Loss 1.602138 Test MSE 6.123724581805096 Test RE 1.1828124446267854\n",
      "85 Train Loss 1.5774392 Test MSE 6.168443381699288 Test RE 1.1871233617924715\n",
      "86 Train Loss 1.5585116 Test MSE 6.155322007890764 Test RE 1.1858600785911606\n",
      "87 Train Loss 1.5378796 Test MSE 6.132159149401683 Test RE 1.183626743052457\n",
      "88 Train Loss 1.5085676 Test MSE 6.151063434680508 Test RE 1.1854497876483399\n",
      "89 Train Loss 1.4722192 Test MSE 6.148746313014336 Test RE 1.1852264856006804\n",
      "90 Train Loss 1.4529144 Test MSE 6.146007552104643 Test RE 1.1849624957281546\n",
      "91 Train Loss 1.4253976 Test MSE 6.129490067631068 Test RE 1.1833691225040754\n",
      "92 Train Loss 1.3978652 Test MSE 6.115752685406517 Test RE 1.182042298214669\n",
      "93 Train Loss 1.374979 Test MSE 6.170405041823809 Test RE 1.187312108555945\n",
      "94 Train Loss 1.3568332 Test MSE 6.188109010140464 Test RE 1.189014191303497\n",
      "95 Train Loss 1.3406609 Test MSE 6.168070199545434 Test RE 1.1870874516019865\n",
      "96 Train Loss 1.3196203 Test MSE 6.140550717071048 Test RE 1.1844363345811464\n",
      "97 Train Loss 1.2964792 Test MSE 6.128991145962944 Test RE 1.18332096021774\n",
      "98 Train Loss 1.2810683 Test MSE 6.1376037558066345 Test RE 1.1841520842714752\n",
      "99 Train Loss 1.2556149 Test MSE 6.125611740168599 Test RE 1.1829946852241808\n",
      "Training time: 79.31\n",
      "KG_stan_tune12\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.02083 Test MSE 8.546626262474627 Test RE 1.3973506998663714\n",
      "1 Train Loss 54.94657 Test MSE 8.666451180879813 Test RE 1.4071121327774265\n",
      "2 Train Loss 48.20095 Test MSE 8.121047911678918 Test RE 1.3621160070840834\n",
      "3 Train Loss 46.720608 Test MSE 8.049008719568398 Test RE 1.3560611039011679\n",
      "4 Train Loss 45.99063 Test MSE 8.108153700653094 Test RE 1.3610342262256272\n",
      "5 Train Loss 44.84143 Test MSE 8.076936980245447 Test RE 1.3584116810951612\n",
      "6 Train Loss 44.485874 Test MSE 8.22324759944787 Test RE 1.370660015177499\n",
      "7 Train Loss 44.212486 Test MSE 8.114214627976327 Test RE 1.361542824658324\n",
      "8 Train Loss 43.964508 Test MSE 8.022526085447158 Test RE 1.353828427851125\n",
      "9 Train Loss 43.496456 Test MSE 8.217191665809652 Test RE 1.3701552173598102\n",
      "10 Train Loss 42.166725 Test MSE 7.506282832893832 Test RE 1.3095452887351497\n",
      "11 Train Loss 41.236366 Test MSE 7.291269864842175 Test RE 1.2906534499195712\n",
      "12 Train Loss 37.527493 Test MSE 7.111904257670606 Test RE 1.274679528327737\n",
      "13 Train Loss 36.92598 Test MSE 7.267331221146213 Test RE 1.2885329760414435\n",
      "14 Train Loss 35.679504 Test MSE 6.919614306275853 Test RE 1.2573292074730082\n",
      "15 Train Loss 35.039436 Test MSE 6.914891646500814 Test RE 1.256900068555667\n",
      "16 Train Loss 34.708805 Test MSE 7.091908875770375 Test RE 1.2728863627296485\n",
      "17 Train Loss 34.142525 Test MSE 6.959344822082363 Test RE 1.2609336596043028\n",
      "18 Train Loss 33.717945 Test MSE 6.743459453522894 Test RE 1.241221916948858\n",
      "19 Train Loss 33.544098 Test MSE 6.696274947922923 Test RE 1.2368718314053262\n",
      "20 Train Loss 32.693504 Test MSE 6.718350929032374 Test RE 1.238908985779113\n",
      "21 Train Loss 32.47641 Test MSE 6.579691380247188 Test RE 1.226057454062182\n",
      "22 Train Loss 31.949062 Test MSE 6.360238324251726 Test RE 1.2054376586192976\n",
      "23 Train Loss 31.739994 Test MSE 6.1989529784524615 Test RE 1.1900555424233648\n",
      "24 Train Loss 31.058077 Test MSE 6.226855304971898 Test RE 1.1927308358870836\n",
      "25 Train Loss 30.3997 Test MSE 5.870419859542073 Test RE 1.1580908814606847\n",
      "26 Train Loss 29.6413 Test MSE 6.02542328656345 Test RE 1.1732804684589273\n",
      "27 Train Loss 29.170872 Test MSE 5.952800578198889 Test RE 1.1661884266605202\n",
      "28 Train Loss 28.629164 Test MSE 5.670557723730807 Test RE 1.1382062031126075\n",
      "29 Train Loss 28.19199 Test MSE 5.875098164784313 Test RE 1.1585522474090235\n",
      "30 Train Loss 27.829401 Test MSE 5.683185575884456 Test RE 1.13947284277412\n",
      "31 Train Loss 27.505028 Test MSE 5.724518581053719 Test RE 1.1436089485100032\n",
      "32 Train Loss 27.248024 Test MSE 5.695059670618198 Test RE 1.1406625935204437\n",
      "33 Train Loss 26.995659 Test MSE 5.455770876236085 Test RE 1.1164418863312375\n",
      "34 Train Loss 26.56989 Test MSE 5.385093556410646 Test RE 1.109186784954357\n",
      "35 Train Loss 26.405985 Test MSE 5.262445548146836 Test RE 1.0964829119427266\n",
      "36 Train Loss 26.310566 Test MSE 5.1971602475815475 Test RE 1.089660264548909\n",
      "37 Train Loss 25.949055 Test MSE 5.113062259031433 Test RE 1.0808081247515973\n",
      "38 Train Loss 25.650984 Test MSE 4.793255743003037 Test RE 1.0464617552490592\n",
      "39 Train Loss 25.417225 Test MSE 4.7612075148823925 Test RE 1.0429575095483152\n",
      "40 Train Loss 25.173183 Test MSE 5.0556987858122096 Test RE 1.0747282279471548\n",
      "41 Train Loss 24.744486 Test MSE 5.22354725468986 Test RE 1.0924229722712777\n",
      "42 Train Loss 24.638287 Test MSE 5.313350242591411 Test RE 1.101773398642655\n",
      "43 Train Loss 24.217415 Test MSE 5.218312908495811 Test RE 1.0918754943839482\n",
      "44 Train Loss 24.078243 Test MSE 5.346643531403979 Test RE 1.1052198473126462\n",
      "45 Train Loss 23.785809 Test MSE 5.336624268988517 Test RE 1.1041838066427008\n",
      "46 Train Loss 23.499043 Test MSE 5.237708764894971 Test RE 1.0939027988258379\n",
      "47 Train Loss 23.136509 Test MSE 4.88094126038356 Test RE 1.0559901102134863\n",
      "48 Train Loss 22.779846 Test MSE 4.618523794528573 Test RE 1.0272109800387574\n",
      "49 Train Loss 22.26721 Test MSE 4.429812986732327 Test RE 1.006006429345639\n",
      "50 Train Loss 21.767345 Test MSE 3.997508522091869 Test RE 0.9556585714612463\n",
      "51 Train Loss 20.942322 Test MSE 3.684846593051825 Test RE 0.9175247040685508\n",
      "52 Train Loss 20.061495 Test MSE 3.1322820387171406 Test RE 0.8459379146910961\n",
      "53 Train Loss 19.304516 Test MSE 3.333597705967876 Test RE 0.8726993541713357\n",
      "54 Train Loss 18.183994 Test MSE 2.765041213825612 Test RE 0.7948018416916431\n",
      "55 Train Loss 17.449184 Test MSE 2.3473838659041477 Test RE 0.732318689503166\n",
      "56 Train Loss 16.661926 Test MSE 2.3743273867035217 Test RE 0.7365095138992074\n",
      "57 Train Loss 16.2052 Test MSE 2.199812478743524 Test RE 0.7089259778935644\n",
      "58 Train Loss 15.37682 Test MSE 2.1255800721735154 Test RE 0.6968620195227369\n",
      "59 Train Loss 15.103464 Test MSE 2.1297051516520074 Test RE 0.6975378862960668\n",
      "60 Train Loss 14.777541 Test MSE 2.055789790471804 Test RE 0.6853263223612079\n",
      "61 Train Loss 14.238091 Test MSE 2.0025621854773736 Test RE 0.6763960547891458\n",
      "62 Train Loss 13.750048 Test MSE 2.0473910928107872 Test RE 0.6839249778841832\n",
      "63 Train Loss 13.320355 Test MSE 1.8655309588482116 Test RE 0.6528438099012162\n",
      "64 Train Loss 12.814963 Test MSE 1.8035385553701984 Test RE 0.6419050254148219\n",
      "65 Train Loss 12.3532505 Test MSE 1.6909367790752594 Test RE 0.621543809806039\n",
      "66 Train Loss 12.127495 Test MSE 1.590885713814755 Test RE 0.6028753835394628\n",
      "67 Train Loss 11.789578 Test MSE 1.472806537766219 Test RE 0.580070676768532\n",
      "68 Train Loss 11.672641 Test MSE 1.3025476983234554 Test RE 0.5455127155674174\n",
      "69 Train Loss 11.456945 Test MSE 1.3950421582558652 Test RE 0.5645491090933786\n",
      "70 Train Loss 11.254217 Test MSE 1.5498223337036967 Test RE 0.5950439141524703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 Train Loss 10.93964 Test MSE 1.6632743273410002 Test RE 0.6164388511676291\n",
      "72 Train Loss 10.592049 Test MSE 1.9822805497744866 Test RE 0.6729621215047454\n",
      "73 Train Loss 10.484095 Test MSE 2.075169400466696 Test RE 0.6885489775314421\n",
      "74 Train Loss 10.302353 Test MSE 2.037072440553197 Test RE 0.682199343148269\n",
      "75 Train Loss 10.126852 Test MSE 2.0717799999399054 Test RE 0.6879864398443986\n",
      "76 Train Loss 10.028324 Test MSE 2.119319236865507 Test RE 0.6958349691044663\n",
      "77 Train Loss 9.959988 Test MSE 2.164549109719003 Test RE 0.7032209201278904\n",
      "78 Train Loss 9.89406 Test MSE 2.1798940665902036 Test RE 0.705709160608574\n",
      "79 Train Loss 9.731108 Test MSE 2.2187150752350893 Test RE 0.7119653000485715\n",
      "80 Train Loss 9.501879 Test MSE 2.198860408405602 Test RE 0.7087725510796157\n",
      "81 Train Loss 9.390396 Test MSE 2.224756165213993 Test RE 0.7129339063282604\n",
      "82 Train Loss 9.280794 Test MSE 2.2205199354895315 Test RE 0.7122548227245713\n",
      "83 Train Loss 9.221792 Test MSE 2.1639602022193793 Test RE 0.703125251186056\n",
      "84 Train Loss 9.146708 Test MSE 2.15914765212914 Test RE 0.7023429565413992\n",
      "85 Train Loss 9.039074 Test MSE 2.0944177300160765 Test RE 0.6917349406070873\n",
      "86 Train Loss 8.955519 Test MSE 2.116405468127964 Test RE 0.69535646650162\n",
      "87 Train Loss 8.715944 Test MSE 2.2118278874314843 Test RE 0.7108594235132222\n",
      "88 Train Loss 8.643423 Test MSE 2.2168778123631516 Test RE 0.711670458603357\n",
      "89 Train Loss 8.563779 Test MSE 2.266112856383175 Test RE 0.7195298700280254\n",
      "90 Train Loss 8.427702 Test MSE 2.2825288598806237 Test RE 0.722131349123855\n",
      "91 Train Loss 8.322325 Test MSE 2.317094025723533 Test RE 0.7275785533746252\n",
      "92 Train Loss 8.029883 Test MSE 2.3059183944695145 Test RE 0.725821831888336\n",
      "93 Train Loss 7.9340925 Test MSE 2.2360901568239075 Test RE 0.7147476155817969\n",
      "94 Train Loss 7.8044844 Test MSE 2.1786103489396567 Test RE 0.7055013375009624\n",
      "95 Train Loss 7.589362 Test MSE 2.2192531535209516 Test RE 0.7120516270061416\n",
      "96 Train Loss 7.3244324 Test MSE 2.189322976510646 Test RE 0.7072337503474012\n",
      "97 Train Loss 7.1305866 Test MSE 2.238727371867823 Test RE 0.7151689733067795\n",
      "98 Train Loss 6.947255 Test MSE 2.276983227028254 Test RE 0.7212535703576359\n",
      "99 Train Loss 6.6585846 Test MSE 2.1702079338145253 Test RE 0.7041395423954725\n",
      "Training time: 75.12\n",
      "KG_stan_tune12\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.883476 Test MSE 8.647636532075353 Test RE 1.405583900260784\n",
      "1 Train Loss 56.13698 Test MSE 8.869452441857597 Test RE 1.423496700904399\n",
      "2 Train Loss 46.57837 Test MSE 8.910058496608267 Test RE 1.426751500370986\n",
      "3 Train Loss 45.881058 Test MSE 8.762832451667139 Test RE 1.4149148811542047\n",
      "4 Train Loss 45.079178 Test MSE 8.582256138948223 Test RE 1.4002603656043722\n",
      "5 Train Loss 44.637196 Test MSE 8.526307855124516 Test RE 1.3956887086658338\n",
      "6 Train Loss 44.439095 Test MSE 8.423342768701424 Test RE 1.3872358291487932\n",
      "7 Train Loss 44.363014 Test MSE 8.54902349816739 Test RE 1.3975466569615433\n",
      "8 Train Loss 44.22198 Test MSE 8.45188719202747 Test RE 1.3895843241570613\n",
      "9 Train Loss 44.055534 Test MSE 8.585232538966347 Test RE 1.4005031557064842\n",
      "10 Train Loss 43.29084 Test MSE 8.342812025606424 Test RE 1.3805886208878564\n",
      "11 Train Loss 40.876545 Test MSE 7.980214329546306 Test RE 1.350253582076629\n",
      "12 Train Loss 37.586174 Test MSE 7.727564486963036 Test RE 1.3287074780891108\n",
      "13 Train Loss 34.196564 Test MSE 7.190354374989697 Test RE 1.281690625389709\n",
      "14 Train Loss 33.68656 Test MSE 7.249881457985651 Test RE 1.2869850826074278\n",
      "15 Train Loss 33.41241 Test MSE 7.119575770695944 Test RE 1.2753668326437864\n",
      "16 Train Loss 33.204643 Test MSE 7.126359704745424 Test RE 1.2759743087569573\n",
      "17 Train Loss 32.980305 Test MSE 7.109942090482109 Test RE 1.2745036748014085\n",
      "18 Train Loss 32.49076 Test MSE 7.031029777364005 Test RE 1.2674111657665774\n",
      "19 Train Loss 32.323105 Test MSE 7.075461383308217 Test RE 1.2714094725267766\n",
      "20 Train Loss 31.943111 Test MSE 7.031088835754457 Test RE 1.2674164886786319\n",
      "21 Train Loss 31.642296 Test MSE 7.095222656694972 Test RE 1.273183713837876\n",
      "22 Train Loss 31.32605 Test MSE 7.100770988814834 Test RE 1.2736814195468604\n",
      "23 Train Loss 30.85772 Test MSE 7.232127811064992 Test RE 1.2854083200007642\n",
      "24 Train Loss 30.300724 Test MSE 7.012576686654182 Test RE 1.2657468989755793\n",
      "25 Train Loss 28.746635 Test MSE 6.891759214191245 Test RE 1.254795949335249\n",
      "26 Train Loss 27.07083 Test MSE 6.660097444579291 Test RE 1.2335261252645828\n",
      "27 Train Loss 24.620138 Test MSE 6.4488809479116505 Test RE 1.2138086834352082\n",
      "28 Train Loss 22.58096 Test MSE 6.330795455437715 Test RE 1.2026443110418183\n",
      "29 Train Loss 20.720459 Test MSE 6.135193774953236 Test RE 1.183919577892795\n",
      "30 Train Loss 18.677195 Test MSE 5.700863364115663 Test RE 1.1412436559442687\n",
      "31 Train Loss 16.65686 Test MSE 4.43162758310671 Test RE 1.0062124548276803\n",
      "32 Train Loss 14.175643 Test MSE 3.1239795546266382 Test RE 0.8448160415250386\n",
      "33 Train Loss 10.029706 Test MSE 2.3847100395895233 Test RE 0.738118091791431\n",
      "34 Train Loss 6.7561193 Test MSE 0.7979950858412037 Test RE 0.4269806251425267\n",
      "35 Train Loss 5.149957 Test MSE 0.6276039535864361 Test RE 0.3786612774187002\n",
      "36 Train Loss 3.887667 Test MSE 0.566043269028416 Test RE 0.35961092363573305\n",
      "37 Train Loss 3.1542277 Test MSE 0.478747877136576 Test RE 0.330720785585436\n",
      "38 Train Loss 2.7591093 Test MSE 0.39789065085673647 Test RE 0.3015018127626477\n",
      "39 Train Loss 2.3456917 Test MSE 0.35498657692603425 Test RE 0.28478297723286167\n",
      "40 Train Loss 2.0749085 Test MSE 0.30101097131755344 Test RE 0.2622401730742394\n",
      "41 Train Loss 1.7178359 Test MSE 0.2894328479242663 Test RE 0.257147300346504\n",
      "42 Train Loss 1.3852717 Test MSE 0.23178156608741474 Test RE 0.23011636585762998\n",
      "43 Train Loss 0.94248885 Test MSE 0.18590374009768568 Test RE 0.20608772442254486\n",
      "44 Train Loss 0.72399503 Test MSE 0.13629500605917794 Test RE 0.17646071390801052\n",
      "45 Train Loss 0.6143691 Test MSE 0.11337347975517513 Test RE 0.16093992646882951\n",
      "46 Train Loss 0.5718654 Test MSE 0.11676450189466037 Test RE 0.16332906495883204\n",
      "47 Train Loss 0.49558145 Test MSE 0.12262143246563796 Test RE 0.16737525547396542\n",
      "48 Train Loss 0.42055568 Test MSE 0.10509530759809883 Test RE 0.1549529051624734\n",
      "49 Train Loss 0.36462185 Test MSE 0.10750092203625795 Test RE 0.15671629468573975\n",
      "50 Train Loss 0.28952417 Test MSE 0.09316575470372153 Test RE 0.1458935907993649\n",
      "51 Train Loss 0.25777343 Test MSE 0.08861740048942582 Test RE 0.1422877668694037\n",
      "52 Train Loss 0.22208196 Test MSE 0.07602703575115745 Test RE 0.13179292271279444\n",
      "53 Train Loss 0.21200503 Test MSE 0.07466173709416206 Test RE 0.13060418857742734\n",
      "54 Train Loss 0.16139916 Test MSE 0.04702794515275866 Test RE 0.1036539989608779\n",
      "55 Train Loss 0.14848575 Test MSE 0.04390953296161711 Test RE 0.10015842098318935\n",
      "56 Train Loss 0.13447154 Test MSE 0.03943549416781449 Test RE 0.09491868304867428\n",
      "57 Train Loss 0.11858207 Test MSE 0.038498823319662534 Test RE 0.09378465566856879\n",
      "58 Train Loss 0.110460296 Test MSE 0.03616353795897677 Test RE 0.09089573718406674\n",
      "59 Train Loss 0.101945445 Test MSE 0.03676221343808524 Test RE 0.09164502338618578\n",
      "60 Train Loss 0.09585374 Test MSE 0.036656580563659814 Test RE 0.09151326185005548\n",
      "61 Train Loss 0.08925538 Test MSE 0.033357849804051626 Test RE 0.08729856094650221\n",
      "62 Train Loss 0.084239714 Test MSE 0.03310941429168156 Test RE 0.08697287156818793\n",
      "63 Train Loss 0.08044557 Test MSE 0.03251257789007778 Test RE 0.08618541220530383\n",
      "64 Train Loss 0.078388125 Test MSE 0.032674820868353195 Test RE 0.08640018411713649\n",
      "65 Train Loss 0.07484237 Test MSE 0.03135376891624456 Test RE 0.08463557262114767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 Train Loss 0.07241639 Test MSE 0.02892584253980319 Test RE 0.08129261034028952\n",
      "67 Train Loss 0.066816 Test MSE 0.026002402195164247 Test RE 0.07707522408221334\n",
      "68 Train Loss 0.06528406 Test MSE 0.025436277098979946 Test RE 0.07623156469886463\n",
      "69 Train Loss 0.063518226 Test MSE 0.025094512452105203 Test RE 0.07571770490332272\n",
      "70 Train Loss 0.061472222 Test MSE 0.025320353416379386 Test RE 0.07605765687413542\n",
      "71 Train Loss 0.05694511 Test MSE 0.0243285259895257 Test RE 0.07455314327246892\n",
      "72 Train Loss 0.054820336 Test MSE 0.022055854121267284 Test RE 0.07098555800700936\n",
      "73 Train Loss 0.053954758 Test MSE 0.021205997492774527 Test RE 0.0696045152343571\n",
      "74 Train Loss 0.051813293 Test MSE 0.01982583326636551 Test RE 0.06730135142249874\n",
      "75 Train Loss 0.04884684 Test MSE 0.01989459708006728 Test RE 0.06741796421826855\n",
      "76 Train Loss 0.0472564 Test MSE 0.020418712098236508 Test RE 0.06830024052921498\n",
      "77 Train Loss 0.046603058 Test MSE 0.020797321011769704 Test RE 0.0689305522493913\n",
      "78 Train Loss 0.045186244 Test MSE 0.020028740077392942 Test RE 0.06764487141121453\n",
      "79 Train Loss 0.042611174 Test MSE 0.018378708961534818 Test RE 0.06479859069875224\n",
      "80 Train Loss 0.04192001 Test MSE 0.01836577139094395 Test RE 0.06477577941395553\n",
      "81 Train Loss 0.041499484 Test MSE 0.018117025750706714 Test RE 0.0643356230356779\n",
      "82 Train Loss 0.04046176 Test MSE 0.017299289394868456 Test RE 0.06286692122911348\n",
      "83 Train Loss 0.039248094 Test MSE 0.016640166139146928 Test RE 0.061657638808351685\n",
      "84 Train Loss 0.037779506 Test MSE 0.015271773338012159 Test RE 0.05906807193702074\n",
      "85 Train Loss 0.037114948 Test MSE 0.015431155454217728 Test RE 0.0593755004975441\n",
      "86 Train Loss 0.036371015 Test MSE 0.014694844708138043 Test RE 0.05794161028448971\n",
      "87 Train Loss 0.035480667 Test MSE 0.013653892822056049 Test RE 0.05585168822260382\n",
      "88 Train Loss 0.034975115 Test MSE 0.01354729236134696 Test RE 0.05563323469390642\n",
      "89 Train Loss 0.03395639 Test MSE 0.014038757962028045 Test RE 0.05663336976942484\n",
      "90 Train Loss 0.03367743 Test MSE 0.014236676618249733 Test RE 0.05703118170729558\n",
      "91 Train Loss 0.032952964 Test MSE 0.014368537833633092 Test RE 0.05729468660174617\n",
      "92 Train Loss 0.031913254 Test MSE 0.01444066084604286 Test RE 0.05743830221969643\n",
      "93 Train Loss 0.030781595 Test MSE 0.013584073299973336 Test RE 0.05570870570058002\n",
      "94 Train Loss 0.030077599 Test MSE 0.012817754388035292 Test RE 0.05411454771493302\n",
      "95 Train Loss 0.029917352 Test MSE 0.012732825607281792 Test RE 0.0539349717659858\n",
      "96 Train Loss 0.029766161 Test MSE 0.012358620716001887 Test RE 0.0531365143667183\n",
      "97 Train Loss 0.029450614 Test MSE 0.012016115855371396 Test RE 0.05239503246380483\n",
      "98 Train Loss 0.029217174 Test MSE 0.011860986981719336 Test RE 0.05205572205827691\n",
      "99 Train Loss 0.028883915 Test MSE 0.011084646576617854 Test RE 0.05032328527511908\n",
      "Training time: 74.99\n",
      "KG_stan_tune12\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.79499 Test MSE 8.589081679774969 Test RE 1.4008170743880033\n",
      "1 Train Loss 56.582497 Test MSE 8.342882871181024 Test RE 1.3805944827235412\n",
      "2 Train Loss 47.057682 Test MSE 8.126682988027584 Test RE 1.3625885013200136\n",
      "3 Train Loss 46.01922 Test MSE 8.500578794935942 Test RE 1.3935812964804362\n",
      "4 Train Loss 45.842102 Test MSE 8.437201504333231 Test RE 1.388376554030183\n",
      "5 Train Loss 45.543266 Test MSE 8.450507646135058 Test RE 1.3894709131794887\n",
      "6 Train Loss 45.22204 Test MSE 8.397891694928441 Test RE 1.3851384817855799\n",
      "7 Train Loss 45.03839 Test MSE 8.313425599003796 Test RE 1.3781550076652944\n",
      "8 Train Loss 44.367573 Test MSE 8.078436273315855 Test RE 1.3585377538080985\n",
      "9 Train Loss 42.883812 Test MSE 7.89178803584639 Test RE 1.3427518714063271\n",
      "10 Train Loss 41.034904 Test MSE 7.765262963670833 Test RE 1.331944546247161\n",
      "11 Train Loss 40.3955 Test MSE 7.712030396770255 Test RE 1.3273713103265923\n",
      "12 Train Loss 40.10714 Test MSE 7.66931666160941 Test RE 1.323690327037075\n",
      "13 Train Loss 39.623497 Test MSE 7.580934999160134 Test RE 1.3160410824670772\n",
      "14 Train Loss 39.399788 Test MSE 7.735424696562656 Test RE 1.3293830638344013\n",
      "15 Train Loss 39.081764 Test MSE 7.85484109943247 Test RE 1.3396050072557502\n",
      "16 Train Loss 38.45479 Test MSE 7.876374137537904 Test RE 1.341439928109854\n",
      "17 Train Loss 37.05167 Test MSE 8.254767559466261 Test RE 1.3732843936703356\n",
      "18 Train Loss 35.514038 Test MSE 8.487320208575618 Test RE 1.392494068846954\n",
      "19 Train Loss 33.092148 Test MSE 8.572519009843175 Test RE 1.3994657968309054\n",
      "20 Train Loss 31.684607 Test MSE 8.61363771775247 Test RE 1.4028181012410088\n",
      "21 Train Loss 30.36199 Test MSE 8.439018569797526 Test RE 1.388526048816628\n",
      "22 Train Loss 28.739336 Test MSE 8.112642990862009 Test RE 1.3614109600872768\n",
      "23 Train Loss 28.025589 Test MSE 8.217976254460483 Test RE 1.3702206279415239\n",
      "24 Train Loss 26.331335 Test MSE 7.815293362781422 Test RE 1.3362284145325067\n",
      "25 Train Loss 25.502645 Test MSE 7.449127625271086 Test RE 1.3045501161993096\n",
      "26 Train Loss 25.039326 Test MSE 7.39364985846583 Test RE 1.2996831850419281\n",
      "27 Train Loss 24.737314 Test MSE 7.461952236154742 Test RE 1.3056726068990143\n",
      "28 Train Loss 24.488108 Test MSE 7.427141093328622 Test RE 1.3026234658534082\n",
      "29 Train Loss 24.116234 Test MSE 7.300593288809538 Test RE 1.2914783724096877\n",
      "30 Train Loss 23.87946 Test MSE 7.263489408002261 Test RE 1.2881923449913353\n",
      "31 Train Loss 23.468609 Test MSE 7.013230194632105 Test RE 1.2658058756159118\n",
      "32 Train Loss 23.26632 Test MSE 6.952495460087846 Test RE 1.2603130036820613\n",
      "33 Train Loss 22.860624 Test MSE 6.885625307685894 Test RE 1.2542374189103402\n",
      "34 Train Loss 22.559727 Test MSE 6.8311780064851435 Test RE 1.2492687069627235\n",
      "35 Train Loss 22.049234 Test MSE 6.10727706241746 Test RE 1.1812229372223582\n",
      "36 Train Loss 20.245884 Test MSE 5.4157527792280895 Test RE 1.1123397978564455\n",
      "37 Train Loss 19.327148 Test MSE 5.333980117864071 Test RE 1.103910226337493\n",
      "38 Train Loss 18.863678 Test MSE 5.528723458192044 Test RE 1.1238814264405208\n",
      "39 Train Loss 18.489498 Test MSE 5.460647023595014 Test RE 1.116940690206062\n",
      "40 Train Loss 18.219807 Test MSE 5.4674540121009905 Test RE 1.117636636537661\n",
      "41 Train Loss 18.095108 Test MSE 5.438049456226617 Test RE 1.1146271997798016\n",
      "42 Train Loss 17.93887 Test MSE 5.49969728050227 Test RE 1.1209273166979785\n",
      "43 Train Loss 17.841331 Test MSE 5.598006047612187 Test RE 1.1309014005928752\n",
      "44 Train Loss 17.614872 Test MSE 5.585902340410546 Test RE 1.1296781519720565\n",
      "45 Train Loss 16.859615 Test MSE 5.993463263796665 Test RE 1.1701646768137466\n",
      "46 Train Loss 15.572778 Test MSE 6.092624603947786 Test RE 1.1798051029346002\n",
      "47 Train Loss 15.229292 Test MSE 5.9752292102296956 Test RE 1.168383311216891\n",
      "48 Train Loss 14.922373 Test MSE 5.927508236013484 Test RE 1.163708330657314\n",
      "49 Train Loss 14.784117 Test MSE 5.922867187058072 Test RE 1.163252668286208\n",
      "50 Train Loss 14.58934 Test MSE 5.866364655002223 Test RE 1.1576908158072388\n",
      "51 Train Loss 14.438428 Test MSE 5.81820725261031 Test RE 1.1529292407467626\n",
      "52 Train Loss 14.264513 Test MSE 5.893748216726568 Test RE 1.1603896583473392\n",
      "53 Train Loss 14.067386 Test MSE 5.846176970436449 Test RE 1.1556971417378499\n",
      "54 Train Loss 13.957524 Test MSE 5.874271346659685 Test RE 1.1584707214775103\n",
      "55 Train Loss 13.751537 Test MSE 5.8321355573774305 Test RE 1.1543084242341077\n",
      "56 Train Loss 13.621705 Test MSE 5.814846889829457 Test RE 1.1525962498522104\n",
      "57 Train Loss 13.427546 Test MSE 5.910743647832058 Test RE 1.1620615252940414\n",
      "58 Train Loss 13.327032 Test MSE 5.720375236037211 Test RE 1.1431950076627824\n",
      "59 Train Loss 13.194104 Test MSE 5.656854423785836 Test RE 1.136830093734682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 Train Loss 12.965857 Test MSE 5.673526635524016 Test RE 1.138504127213447\n",
      "61 Train Loss 12.627472 Test MSE 5.652478473954312 Test RE 1.1363903021541053\n",
      "62 Train Loss 12.48534 Test MSE 5.552989955480245 Test RE 1.1263451782640135\n",
      "63 Train Loss 12.114443 Test MSE 5.238617507655405 Test RE 1.0939976908081281\n",
      "64 Train Loss 11.873699 Test MSE 4.885715628776063 Test RE 1.0565064505296196\n",
      "65 Train Loss 11.599295 Test MSE 4.552369746664142 Test RE 1.0198277485635985\n",
      "66 Train Loss 11.181719 Test MSE 4.147520781548431 Test RE 0.9734246634397988\n",
      "67 Train Loss 10.750836 Test MSE 3.8287153582980507 Test RE 0.9352648239141998\n",
      "68 Train Loss 10.481269 Test MSE 3.7964005789468716 Test RE 0.9313095915147507\n",
      "69 Train Loss 10.186094 Test MSE 3.851763559636141 Test RE 0.9380756659497395\n",
      "70 Train Loss 9.970621 Test MSE 3.996754121771373 Test RE 0.9555683923977407\n",
      "71 Train Loss 9.659283 Test MSE 4.058703341609294 Test RE 0.9629455151531664\n",
      "72 Train Loss 9.512873 Test MSE 4.1630815081054235 Test RE 0.9752490080342499\n",
      "73 Train Loss 9.35947 Test MSE 4.230325855879331 Test RE 0.9830938316216588\n",
      "74 Train Loss 9.24697 Test MSE 4.330541192151072 Test RE 0.9946702926458287\n",
      "75 Train Loss 9.196138 Test MSE 4.327708566789681 Test RE 0.9943449304033073\n",
      "76 Train Loss 9.018985 Test MSE 4.355695901938503 Test RE 0.9975549682997685\n",
      "77 Train Loss 8.928893 Test MSE 4.301557673354282 Test RE 0.9913361315306022\n",
      "78 Train Loss 8.873348 Test MSE 4.237986257790582 Test RE 0.9839835370384431\n",
      "79 Train Loss 8.7730875 Test MSE 4.166669523032102 Test RE 0.9756691840930904\n",
      "80 Train Loss 8.674519 Test MSE 4.107942697521158 Test RE 0.9687690346391823\n",
      "81 Train Loss 8.58219 Test MSE 4.118938963496858 Test RE 0.9700647833046949\n",
      "82 Train Loss 8.505267 Test MSE 4.130283853455846 Test RE 0.9713998007341295\n",
      "83 Train Loss 8.256687 Test MSE 3.914737294136967 Test RE 0.9457130280780988\n",
      "84 Train Loss 8.119143 Test MSE 3.6451445013182764 Test RE 0.912568418514652\n",
      "85 Train Loss 5.743557 Test MSE 1.324435746854632 Test RE 0.5500770263346096\n",
      "86 Train Loss 4.2782784 Test MSE 0.9315374628608643 Test RE 0.46132630919626877\n",
      "87 Train Loss 3.5838017 Test MSE 0.6717189054168523 Test RE 0.3917435423178427\n",
      "88 Train Loss 2.97819 Test MSE 0.7041719414530487 Test RE 0.40109515717156785\n",
      "89 Train Loss 2.380749 Test MSE 0.546058714892683 Test RE 0.35320572281376644\n",
      "90 Train Loss 1.981783 Test MSE 0.5693413593952711 Test RE 0.36065705100984724\n",
      "91 Train Loss 1.4106597 Test MSE 0.6801853900730216 Test RE 0.39420462012006907\n",
      "92 Train Loss 1.0561466 Test MSE 0.6955957630626053 Test RE 0.39864518629533585\n",
      "93 Train Loss 0.89120984 Test MSE 0.6786294831552906 Test RE 0.393753495427193\n",
      "94 Train Loss 0.8070145 Test MSE 0.7005196149897481 Test RE 0.4000536253735335\n",
      "95 Train Loss 0.7260035 Test MSE 0.7615980767885736 Test RE 0.4171295718026692\n",
      "96 Train Loss 0.63708514 Test MSE 0.6621298594094955 Test RE 0.3889373464873942\n",
      "97 Train Loss 0.5205007 Test MSE 0.6800447572073288 Test RE 0.3941638657962827\n",
      "98 Train Loss 0.46485543 Test MSE 0.7181995625753916 Test RE 0.40507051154173557\n",
      "99 Train Loss 0.43093905 Test MSE 0.671012406383283 Test RE 0.39153747453836224\n",
      "Training time: 75.65\n",
      "KG_stan_tune12\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.5639 Test MSE 8.55913394323675 Test RE 1.3983728123431998\n",
      "1 Train Loss 55.244186 Test MSE 8.591744168021354 Test RE 1.4010341738489787\n",
      "2 Train Loss 49.655098 Test MSE 9.255509987520735 Test RE 1.4541467506226526\n",
      "3 Train Loss 43.23497 Test MSE 7.7664574482397395 Test RE 1.3320469848919463\n",
      "4 Train Loss 40.579178 Test MSE 7.366075034438868 Test RE 1.297257318692629\n",
      "5 Train Loss 38.518684 Test MSE 7.158337499075927 Test RE 1.2788339155494073\n",
      "6 Train Loss 37.572163 Test MSE 7.3359235447978115 Test RE 1.2945995702277346\n",
      "7 Train Loss 36.602264 Test MSE 6.995728998210475 Test RE 1.2642255086209238\n",
      "8 Train Loss 32.61218 Test MSE 6.208013586239331 Test RE 1.1909249383812162\n",
      "9 Train Loss 30.565971 Test MSE 6.449856716169693 Test RE 1.2139005095361541\n",
      "10 Train Loss 29.283691 Test MSE 6.1321157342589805 Test RE 1.183622553058879\n",
      "11 Train Loss 27.429554 Test MSE 6.26810912667226 Test RE 1.196675321073034\n",
      "12 Train Loss 26.2709 Test MSE 5.657066209772553 Test RE 1.1368513743273623\n",
      "13 Train Loss 24.700523 Test MSE 5.290495225332491 Test RE 1.0994012430409565\n",
      "14 Train Loss 23.859888 Test MSE 5.170228764785196 Test RE 1.0868333088879008\n",
      "15 Train Loss 23.169918 Test MSE 4.839100943923154 Test RE 1.0514542991739175\n",
      "16 Train Loss 20.063087 Test MSE 4.392036313780706 Test RE 1.001707721333219\n",
      "17 Train Loss 15.377258 Test MSE 3.9558532607162364 Test RE 0.9506664051357239\n",
      "18 Train Loss 13.848497 Test MSE 3.9603776335386325 Test RE 0.9512098959879988\n",
      "19 Train Loss 12.987628 Test MSE 4.04530539362642 Test RE 0.9613548398146727\n",
      "20 Train Loss 12.506413 Test MSE 4.09139988471803 Test RE 0.9668164353692372\n",
      "21 Train Loss 12.110425 Test MSE 4.073572839378046 Test RE 0.9647078299364402\n",
      "22 Train Loss 11.657362 Test MSE 4.0442683227101215 Test RE 0.9612316035007126\n",
      "23 Train Loss 11.243708 Test MSE 4.087240785472972 Test RE 0.9663249033698159\n",
      "24 Train Loss 10.911391 Test MSE 4.127422512552832 Test RE 0.9710632636293245\n",
      "25 Train Loss 10.544581 Test MSE 4.153244353151388 Test RE 0.9740960940638342\n",
      "26 Train Loss 10.292405 Test MSE 4.178545982297737 Test RE 0.9770586931368463\n",
      "27 Train Loss 10.14186 Test MSE 4.300086177246474 Test RE 0.9911665566759917\n",
      "28 Train Loss 9.803286 Test MSE 4.291877269673132 Test RE 0.9902200312874756\n",
      "29 Train Loss 9.702091 Test MSE 4.294184151298786 Test RE 0.9904861168928245\n",
      "30 Train Loss 9.593709 Test MSE 4.345217515265251 Test RE 0.9963543495028202\n",
      "31 Train Loss 9.527803 Test MSE 4.280725770903218 Test RE 0.9889327601312573\n",
      "32 Train Loss 9.392824 Test MSE 4.261159222119879 Test RE 0.98667004064268\n",
      "33 Train Loss 9.309835 Test MSE 4.281371415237575 Test RE 0.9890073356581752\n",
      "34 Train Loss 9.222505 Test MSE 4.3055273507545575 Test RE 0.9917934515805661\n",
      "35 Train Loss 9.138028 Test MSE 4.269516100683677 Test RE 0.9876370830053328\n",
      "36 Train Loss 9.096234 Test MSE 4.275668560992018 Test RE 0.9883484294824604\n",
      "37 Train Loss 9.04791 Test MSE 4.258293902316537 Test RE 0.9863382529203347\n",
      "38 Train Loss 9.014199 Test MSE 4.248275084963859 Test RE 0.9851772524843182\n",
      "39 Train Loss 8.9856 Test MSE 4.265369736673598 Test RE 0.9871573919246714\n",
      "40 Train Loss 8.951265 Test MSE 4.270790985112264 Test RE 0.9877845270163763\n",
      "41 Train Loss 8.913341 Test MSE 4.2448614372096225 Test RE 0.9847813595744359\n",
      "42 Train Loss 8.870643 Test MSE 4.241736785627984 Test RE 0.9844188430174743\n",
      "43 Train Loss 8.834322 Test MSE 4.199004292463466 Test RE 0.9794476297327148\n",
      "44 Train Loss 8.793715 Test MSE 4.220908723140226 Test RE 0.9819989888796535\n",
      "45 Train Loss 8.760766 Test MSE 4.157860458536692 Test RE 0.9746372711684033\n",
      "46 Train Loss 8.654491 Test MSE 4.188160016774085 Test RE 0.978182059860624\n",
      "47 Train Loss 7.9755764 Test MSE 3.7180501270968986 Test RE 0.9216492640143864\n",
      "48 Train Loss 7.1110363 Test MSE 3.204556451257772 Test RE 0.8556418607971579\n",
      "49 Train Loss 6.3283997 Test MSE 2.453621292892165 Test RE 0.74870688388945\n",
      "50 Train Loss 5.233614 Test MSE 2.090162043116864 Test RE 0.6910318086105758\n",
      "51 Train Loss 4.9188995 Test MSE 2.1444050014809717 Test RE 0.6999410521653299\n",
      "52 Train Loss 4.826043 Test MSE 2.1440765014677807 Test RE 0.6998874383537793\n",
      "53 Train Loss 4.784042 Test MSE 2.139030551965975 Test RE 0.6990633826438047\n",
      "54 Train Loss 4.7395773 Test MSE 2.1477063814467363 Test RE 0.7004796357520635\n",
      "55 Train Loss 4.697263 Test MSE 2.158746177502522 Test RE 0.7022776562399643\n",
      "56 Train Loss 4.668184 Test MSE 2.14094812602902 Test RE 0.6993766566907655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 Train Loss 4.6375613 Test MSE 2.1380666244622537 Test RE 0.6989058527868816\n",
      "58 Train Loss 4.609656 Test MSE 2.1554995184895804 Test RE 0.7017493602255491\n",
      "59 Train Loss 4.5901113 Test MSE 2.1576144301069022 Test RE 0.7020935435557314\n",
      "60 Train Loss 4.5628843 Test MSE 2.1462931537600505 Test RE 0.7002491340116301\n",
      "61 Train Loss 4.547235 Test MSE 2.134296161740951 Test RE 0.6982893235247322\n",
      "62 Train Loss 4.526745 Test MSE 2.1262503047153896 Test RE 0.696971877249713\n",
      "63 Train Loss 4.495285 Test MSE 2.1398204949032977 Test RE 0.6991924526112966\n",
      "64 Train Loss 4.4654326 Test MSE 2.137954553915621 Test RE 0.698887535353153\n",
      "65 Train Loss 4.428748 Test MSE 2.119588162042664 Test RE 0.6958791157349505\n",
      "66 Train Loss 4.361742 Test MSE 2.1355641437956963 Test RE 0.6984967190305088\n",
      "67 Train Loss 4.245982 Test MSE 2.096856000260845 Test RE 0.6921374739935601\n",
      "68 Train Loss 4.0684195 Test MSE 2.080364299602439 Test RE 0.6894102823218154\n",
      "69 Train Loss 3.6215525 Test MSE 1.678032527371371 Test RE 0.619167636255629\n",
      "70 Train Loss 2.1577613 Test MSE 0.8873904215032133 Test RE 0.4502621373727546\n",
      "71 Train Loss 1.324517 Test MSE 0.46860167837041405 Test RE 0.3271975025891206\n",
      "72 Train Loss 0.9219081 Test MSE 0.50963933260582 Test RE 0.341223968376302\n",
      "73 Train Loss 0.7390813 Test MSE 0.35440407891926623 Test RE 0.2845492308974731\n",
      "74 Train Loss 0.48281774 Test MSE 0.09200847439019266 Test RE 0.14498463351252192\n",
      "75 Train Loss 0.33874187 Test MSE 0.0698396658463574 Test RE 0.1263162245650899\n",
      "76 Train Loss 0.26212916 Test MSE 0.07572945506567544 Test RE 0.1315347416564992\n",
      "77 Train Loss 0.22696105 Test MSE 0.07156814691481281 Test RE 0.12786978838535218\n",
      "78 Train Loss 0.18907854 Test MSE 0.03769900429737388 Test RE 0.09280534727264915\n",
      "79 Train Loss 0.16753834 Test MSE 0.029911263149265108 Test RE 0.0826657170280901\n",
      "80 Train Loss 0.13739564 Test MSE 0.022098341674968453 Test RE 0.07105389704322419\n",
      "81 Train Loss 0.12225725 Test MSE 0.021449177819639516 Test RE 0.07000247338058468\n",
      "82 Train Loss 0.11742829 Test MSE 0.020923592468199755 Test RE 0.06913949237192096\n",
      "83 Train Loss 0.11032896 Test MSE 0.017989489859960996 Test RE 0.06410877586358836\n",
      "84 Train Loss 0.09990528 Test MSE 0.01357238418727954 Test RE 0.05568473183532845\n",
      "85 Train Loss 0.088169485 Test MSE 0.011520136179558401 Test RE 0.05130230363464006\n",
      "86 Train Loss 0.07769918 Test MSE 0.009063626490477419 Test RE 0.04550499388205902\n",
      "87 Train Loss 0.07086963 Test MSE 0.007586740511155924 Test RE 0.04163280528834429\n",
      "88 Train Loss 0.06729584 Test MSE 0.006116632889349292 Test RE 0.03738214933515128\n",
      "89 Train Loss 0.059797883 Test MSE 0.005663342266522404 Test RE 0.03597033353852779\n",
      "90 Train Loss 0.056714397 Test MSE 0.004960396914247861 Test RE 0.03366404313459965\n",
      "91 Train Loss 0.050268937 Test MSE 0.0059877284833711655 Test RE 0.03698614855567441\n",
      "92 Train Loss 0.0431752 Test MSE 0.005090576732186798 Test RE 0.034102919064336205\n",
      "93 Train Loss 0.039312176 Test MSE 0.0044311203037434325 Test RE 0.031817410479480085\n",
      "94 Train Loss 0.035742417 Test MSE 0.004286360368102311 Test RE 0.031293374726412145\n",
      "95 Train Loss 0.02927909 Test MSE 0.003839679430158784 Test RE 0.02961798738968044\n",
      "96 Train Loss 0.027735384 Test MSE 0.003931226751388011 Test RE 0.02996899004764629\n",
      "97 Train Loss 0.026504058 Test MSE 0.0033553050079209975 Test RE 0.027686882831002752\n",
      "98 Train Loss 0.023883877 Test MSE 0.0030415387994199216 Test RE 0.026360566593406833\n",
      "99 Train Loss 0.02200412 Test MSE 0.00290147823022333 Test RE 0.025746471510396284\n",
      "Training time: 76.61\n",
      "KG_stan_tune12\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 56.828926 Test MSE 8.709169406672418 Test RE 1.4105758021956274\n",
      "1 Train Loss 53.661137 Test MSE 8.571613844933944 Test RE 1.3993919106855401\n",
      "2 Train Loss 46.81704 Test MSE 8.193099320422244 Test RE 1.3681451337653745\n",
      "3 Train Loss 43.63712 Test MSE 8.206745344618948 Test RE 1.3692840174457674\n",
      "4 Train Loss 42.63704 Test MSE 8.144368043783476 Test RE 1.3640703087100225\n",
      "5 Train Loss 42.42077 Test MSE 8.147157392155156 Test RE 1.364303877573157\n",
      "6 Train Loss 39.970318 Test MSE 7.1128241739258105 Test RE 1.2747619647933937\n",
      "7 Train Loss 35.16706 Test MSE 7.15037802254051 Test RE 1.2781227392722712\n",
      "8 Train Loss 33.98123 Test MSE 7.0043840360153125 Test RE 1.265007309728462\n",
      "9 Train Loss 32.14643 Test MSE 6.683880210030506 Test RE 1.2357265825099768\n",
      "10 Train Loss 30.182384 Test MSE 6.594110927105363 Test RE 1.227400185536725\n",
      "11 Train Loss 28.280624 Test MSE 6.388299228304553 Test RE 1.2080938832559232\n",
      "12 Train Loss 27.057217 Test MSE 6.076665830666687 Test RE 1.178258923001025\n",
      "13 Train Loss 25.817997 Test MSE 5.999445046109537 Test RE 1.170748473228509\n",
      "14 Train Loss 25.193249 Test MSE 5.969929945535887 Test RE 1.167865092952409\n",
      "15 Train Loss 24.387741 Test MSE 5.66262806961398 Test RE 1.137410096320807\n",
      "16 Train Loss 23.617998 Test MSE 5.6543157386456375 Test RE 1.1365749716011264\n",
      "17 Train Loss 23.114075 Test MSE 5.300708875416321 Test RE 1.1004619646570166\n",
      "18 Train Loss 22.589355 Test MSE 5.2864255156063225 Test RE 1.0989783048731174\n",
      "19 Train Loss 22.237492 Test MSE 5.387765769431659 Test RE 1.1094619534105483\n",
      "20 Train Loss 21.663315 Test MSE 5.354292436642163 Test RE 1.1060101282167434\n",
      "21 Train Loss 20.76928 Test MSE 5.176547502310672 Test RE 1.0874972367112925\n",
      "22 Train Loss 18.65823 Test MSE 5.637779177416282 Test RE 1.1349117461496958\n",
      "23 Train Loss 17.352974 Test MSE 5.099939552076815 Test RE 1.0794202832248017\n",
      "24 Train Loss 16.605913 Test MSE 5.110249972506116 Test RE 1.0805108508246517\n",
      "25 Train Loss 15.501085 Test MSE 5.416819855619038 Test RE 1.11244937570502\n",
      "26 Train Loss 14.944662 Test MSE 5.22239466612752 Test RE 1.0923024427129135\n",
      "27 Train Loss 14.408621 Test MSE 5.553754109342549 Test RE 1.1264226744792654\n",
      "28 Train Loss 13.848738 Test MSE 5.586794299435602 Test RE 1.1297683420917826\n",
      "29 Train Loss 13.314834 Test MSE 5.818173674305381 Test RE 1.1529259138228678\n",
      "30 Train Loss 12.835533 Test MSE 5.880796436294228 Test RE 1.1591139525152874\n",
      "31 Train Loss 12.410763 Test MSE 5.9319297717217445 Test RE 1.1641422751211203\n",
      "32 Train Loss 12.16217 Test MSE 6.027287431905758 Test RE 1.173461949167946\n",
      "33 Train Loss 11.997281 Test MSE 5.98974148075284 Test RE 1.169801299650041\n",
      "34 Train Loss 11.905674 Test MSE 5.958758112087397 Test RE 1.1667718385829773\n",
      "35 Train Loss 11.823478 Test MSE 5.993524205760055 Test RE 1.1701706259577123\n",
      "36 Train Loss 11.746237 Test MSE 5.956755484380524 Test RE 1.1665757569562911\n",
      "37 Train Loss 11.675555 Test MSE 5.9283522097918935 Test RE 1.1637911735923467\n",
      "38 Train Loss 11.614952 Test MSE 5.935872031008191 Test RE 1.1645290454154131\n",
      "39 Train Loss 11.5169115 Test MSE 5.935926174651053 Test RE 1.1645343564885486\n",
      "40 Train Loss 11.469439 Test MSE 5.940508411785854 Test RE 1.1649837508205376\n",
      "41 Train Loss 11.364044 Test MSE 5.897577073791269 Test RE 1.1607665191006302\n",
      "42 Train Loss 11.201724 Test MSE 5.88881072001133 Test RE 1.1599034973869193\n",
      "43 Train Loss 11.120447 Test MSE 5.852095477332734 Test RE 1.156281991568509\n",
      "44 Train Loss 11.005647 Test MSE 5.772976892244159 Test RE 1.1484390991747613\n",
      "45 Train Loss 10.871985 Test MSE 5.659460628259788 Test RE 1.1370919415991698\n",
      "46 Train Loss 10.617094 Test MSE 5.5889742902420165 Test RE 1.1299887407906613\n",
      "47 Train Loss 10.359865 Test MSE 5.5991254663915955 Test RE 1.1310144666536963\n",
      "48 Train Loss 9.975869 Test MSE 5.553684063204762 Test RE 1.1264155710132944\n",
      "49 Train Loss 9.691838 Test MSE 5.566033033753005 Test RE 1.1276672040423668\n",
      "50 Train Loss 9.551168 Test MSE 5.342716385711128 Test RE 1.1048138770402534\n",
      "51 Train Loss 9.426624 Test MSE 5.268592711601053 Test RE 1.097123136379731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 9.269577 Test MSE 5.115792961293031 Test RE 1.0810966965596316\n",
      "53 Train Loss 9.126363 Test MSE 4.79314349611052 Test RE 1.0464495023280653\n",
      "54 Train Loss 8.389492 Test MSE 3.7229327498361307 Test RE 0.922254230202848\n",
      "55 Train Loss 7.0037193 Test MSE 3.4435436073112737 Test RE 0.8869739271331327\n",
      "56 Train Loss 6.371483 Test MSE 3.0329159242253256 Test RE 0.8324118344169565\n",
      "57 Train Loss 5.556143 Test MSE 2.885988659863793 Test RE 0.8119987681790306\n",
      "58 Train Loss 5.2869415 Test MSE 2.5757983508229163 Test RE 0.7671212100650929\n",
      "59 Train Loss 4.987953 Test MSE 2.3037658830196097 Test RE 0.725482985427406\n",
      "60 Train Loss 4.7524467 Test MSE 2.1644466989923 Test RE 0.7032042842804995\n",
      "61 Train Loss 4.662002 Test MSE 2.150765886836299 Test RE 0.7009783907353141\n",
      "62 Train Loss 4.558893 Test MSE 2.1435639569197646 Test RE 0.6998037788081868\n",
      "63 Train Loss 4.512641 Test MSE 2.131398548495667 Test RE 0.6978151485600933\n",
      "64 Train Loss 4.4259133 Test MSE 2.132611306362067 Test RE 0.6980136474431115\n",
      "65 Train Loss 4.353944 Test MSE 2.118570371455261 Test RE 0.6957120209496026\n",
      "66 Train Loss 4.2941327 Test MSE 2.131724840422229 Test RE 0.6978685601418498\n",
      "67 Train Loss 4.2483444 Test MSE 2.143953926558789 Test RE 0.6998674321028009\n",
      "68 Train Loss 4.222412 Test MSE 2.131866279602465 Test RE 0.6978917114224387\n",
      "69 Train Loss 4.188398 Test MSE 2.1211179640726567 Test RE 0.6961301940546731\n",
      "70 Train Loss 4.160622 Test MSE 2.11196126597706 Test RE 0.6946259994963213\n",
      "71 Train Loss 4.085882 Test MSE 2.106688423920248 Test RE 0.693758336296711\n",
      "72 Train Loss 3.7236974 Test MSE 1.8605325088351228 Test RE 0.6519686178000725\n",
      "73 Train Loss 2.7804122 Test MSE 1.4556514750218477 Test RE 0.5766824869317038\n",
      "74 Train Loss 1.5237756 Test MSE 0.5089108832070491 Test RE 0.3409800181322973\n",
      "75 Train Loss 0.78228974 Test MSE 0.21567272177733426 Test RE 0.22197582043925881\n",
      "76 Train Loss 0.48524407 Test MSE 0.09771015318660678 Test RE 0.14940939506338863\n",
      "77 Train Loss 0.32317233 Test MSE 0.05381207306490056 Test RE 0.11087864803921471\n",
      "78 Train Loss 0.24908866 Test MSE 0.05471054602801782 Test RE 0.11180045856565203\n",
      "79 Train Loss 0.18509825 Test MSE 0.03469502661225113 Test RE 0.08903108637421575\n",
      "80 Train Loss 0.13193284 Test MSE 0.02742856942228959 Test RE 0.07916070233724651\n",
      "81 Train Loss 0.0930474 Test MSE 0.028287355874893 Test RE 0.0803904088473285\n",
      "82 Train Loss 0.069052845 Test MSE 0.020682875599626296 Test RE 0.06874063191771493\n",
      "83 Train Loss 0.061627902 Test MSE 0.020996860682793533 Test RE 0.06926043958140968\n",
      "84 Train Loss 0.05831129 Test MSE 0.017679780053757758 Test RE 0.06355452675708524\n",
      "85 Train Loss 0.049905285 Test MSE 0.014168725797366798 Test RE 0.05689491567594376\n",
      "86 Train Loss 0.046869367 Test MSE 0.013490040074782909 Test RE 0.05551555427063468\n",
      "87 Train Loss 0.0426465 Test MSE 0.013716885752492037 Test RE 0.055980377270146674\n",
      "88 Train Loss 0.03892965 Test MSE 0.014000990512159115 Test RE 0.056557140147540715\n",
      "89 Train Loss 0.035852212 Test MSE 0.012655029517629483 Test RE 0.05376995110032049\n",
      "90 Train Loss 0.03334732 Test MSE 0.011214255643317841 Test RE 0.050616636927077234\n",
      "91 Train Loss 0.03009606 Test MSE 0.009803496903229078 Test RE 0.04732586584275582\n",
      "92 Train Loss 0.027976919 Test MSE 0.00854857775995467 Test RE 0.044193153583305035\n",
      "93 Train Loss 0.025895506 Test MSE 0.010275581845588496 Test RE 0.04845195125954353\n",
      "94 Train Loss 0.024551466 Test MSE 0.011326848843283102 Test RE 0.050870102502128325\n",
      "95 Train Loss 0.023050172 Test MSE 0.010440801663725024 Test RE 0.04883992442135191\n",
      "96 Train Loss 0.022537176 Test MSE 0.009710811790722808 Test RE 0.04710161830500682\n",
      "97 Train Loss 0.020665703 Test MSE 0.00850978070358254 Test RE 0.04409275594405925\n",
      "98 Train Loss 0.01918162 Test MSE 0.006861863416141219 Test RE 0.03959397412361309\n",
      "99 Train Loss 0.018103464 Test MSE 0.005957447041681454 Test RE 0.0368925059065253\n",
      "Training time: 77.44\n",
      "KG_stan_tune12\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.581528 Test MSE 8.639301196237735 Test RE 1.404906325619432\n",
      "1 Train Loss 50.312286 Test MSE 9.262426082072997 Test RE 1.454689948046788\n",
      "2 Train Loss 45.116264 Test MSE 8.37286549256644 Test RE 1.383073045512912\n",
      "3 Train Loss 43.707264 Test MSE 8.469489678030046 Test RE 1.3910305938309075\n",
      "4 Train Loss 43.549194 Test MSE 8.4970059159295 Test RE 1.3932883975626515\n",
      "5 Train Loss 43.41197 Test MSE 8.46387963582882 Test RE 1.390569820317696\n",
      "6 Train Loss 43.277878 Test MSE 8.461908903572104 Test RE 1.390407920547267\n",
      "7 Train Loss 43.202152 Test MSE 8.501149230667838 Test RE 1.3936280541924748\n",
      "8 Train Loss 43.115025 Test MSE 8.526729598667838 Test RE 1.3957232262690373\n",
      "9 Train Loss 42.805676 Test MSE 8.46289895140066 Test RE 1.3904892574002\n",
      "10 Train Loss 42.59707 Test MSE 8.34983209001609 Test RE 1.3811693473307054\n",
      "11 Train Loss 41.675385 Test MSE 8.3088954138339 Test RE 1.3777794616243968\n",
      "12 Train Loss 41.054802 Test MSE 8.138931450009537 Test RE 1.3636149551392787\n",
      "13 Train Loss 39.4599 Test MSE 8.370105598684152 Test RE 1.3828450799826688\n",
      "14 Train Loss 38.106956 Test MSE 7.70796583283208 Test RE 1.3270214740096526\n",
      "15 Train Loss 36.25174 Test MSE 7.797157017247577 Test RE 1.3346770731358801\n",
      "16 Train Loss 35.424873 Test MSE 7.499381736116226 Test RE 1.3089431680118904\n",
      "17 Train Loss 34.481422 Test MSE 7.405507819682515 Test RE 1.3007249856922074\n",
      "18 Train Loss 34.045296 Test MSE 7.236661774783178 Test RE 1.2858111807979695\n",
      "19 Train Loss 33.716583 Test MSE 7.272382629146509 Test RE 1.2889807177859103\n",
      "20 Train Loss 33.311985 Test MSE 7.240837240647829 Test RE 1.2861820760147407\n",
      "21 Train Loss 32.851727 Test MSE 7.185961768546905 Test RE 1.2812990714893326\n",
      "22 Train Loss 32.71403 Test MSE 7.119523285628852 Test RE 1.2753621316728785\n",
      "23 Train Loss 32.338417 Test MSE 7.109041059963787 Test RE 1.2744229144325459\n",
      "24 Train Loss 31.880745 Test MSE 7.025608142313478 Test RE 1.266922420435361\n",
      "25 Train Loss 31.53202 Test MSE 7.079233537787185 Test RE 1.2717483418688604\n",
      "26 Train Loss 31.114681 Test MSE 7.033849940331202 Test RE 1.2676653211181583\n",
      "27 Train Loss 30.375393 Test MSE 7.084861148511116 Test RE 1.2722537272891146\n",
      "28 Train Loss 29.04179 Test MSE 6.716083191582581 Test RE 1.2386998751314517\n",
      "29 Train Loss 27.935404 Test MSE 6.75022375249405 Test RE 1.2418442897653135\n",
      "30 Train Loss 27.053719 Test MSE 7.049565938875927 Test RE 1.2690807273647617\n",
      "31 Train Loss 24.507421 Test MSE 7.056226524700124 Test RE 1.2696801135904734\n",
      "32 Train Loss 22.976204 Test MSE 6.605170258256732 Test RE 1.2284290231247401\n",
      "33 Train Loss 21.014418 Test MSE 6.848656752466132 Test RE 1.2508659205503718\n",
      "34 Train Loss 19.642794 Test MSE 6.494827182982431 Test RE 1.218125010256863\n",
      "35 Train Loss 18.603642 Test MSE 6.7792382369367585 Test RE 1.2445103374119293\n",
      "36 Train Loss 17.857319 Test MSE 6.515325549834806 Test RE 1.2200457621105865\n",
      "37 Train Loss 16.930048 Test MSE 6.459607398231458 Test RE 1.2148177305200818\n",
      "38 Train Loss 16.539995 Test MSE 6.3544576892824916 Test RE 1.204889740542607\n",
      "39 Train Loss 15.923868 Test MSE 6.307065111586186 Test RE 1.200388199822212\n",
      "40 Train Loss 15.55499 Test MSE 6.388394363393679 Test RE 1.2081028787402657\n",
      "41 Train Loss 15.079823 Test MSE 6.17248201962071 Test RE 1.187511918243321\n",
      "42 Train Loss 14.781518 Test MSE 6.1379917030404885 Test RE 1.184189507774586\n",
      "43 Train Loss 14.449116 Test MSE 6.1234110089076585 Test RE 1.1827821605514133\n",
      "44 Train Loss 14.27228 Test MSE 6.046653173596094 Test RE 1.1753456104853748\n",
      "45 Train Loss 14.024313 Test MSE 5.906948890309613 Test RE 1.161688437745378\n",
      "46 Train Loss 13.865927 Test MSE 5.926024520538412 Test RE 1.1635626775387884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 Train Loss 13.5919285 Test MSE 5.902360979729378 Test RE 1.1612372100413038\n",
      "48 Train Loss 13.284539 Test MSE 6.078992958271883 Test RE 1.1784845151659094\n",
      "49 Train Loss 12.976088 Test MSE 5.904619145581587 Test RE 1.1614593258573174\n",
      "50 Train Loss 12.564552 Test MSE 5.902448924201522 Test RE 1.1612458611567995\n",
      "51 Train Loss 12.407733 Test MSE 5.924297074629041 Test RE 1.1633930749594403\n",
      "52 Train Loss 11.462634 Test MSE 5.253137231723752 Test RE 1.0955127425486915\n",
      "53 Train Loss 10.882965 Test MSE 5.23407469631662 Test RE 1.093523242825935\n",
      "54 Train Loss 10.403946 Test MSE 5.278603960402518 Test RE 1.0981650047266087\n",
      "55 Train Loss 10.078189 Test MSE 5.2781461205770395 Test RE 1.0981173790114964\n",
      "56 Train Loss 9.662893 Test MSE 5.258472744907706 Test RE 1.09606894724896\n",
      "57 Train Loss 9.315596 Test MSE 5.102869186913425 Test RE 1.0797302725119562\n",
      "58 Train Loss 8.813439 Test MSE 4.343867896073612 Test RE 0.9961996042709979\n",
      "59 Train Loss 8.669627 Test MSE 4.1500374828944775 Test RE 0.9737199540202461\n",
      "60 Train Loss 8.257315 Test MSE 3.3225343689008855 Test RE 0.8712500204691146\n",
      "61 Train Loss 7.6639905 Test MSE 2.876578843816064 Test RE 0.8106739193452421\n",
      "62 Train Loss 7.3750253 Test MSE 2.645787066365764 Test RE 0.7774733383725444\n",
      "63 Train Loss 6.9530783 Test MSE 2.6440671064448535 Test RE 0.7772205893147988\n",
      "64 Train Loss 6.47136 Test MSE 2.429184827349818 Test RE 0.7449692386962453\n",
      "65 Train Loss 6.2275763 Test MSE 2.271678321566014 Test RE 0.7204128937301327\n",
      "66 Train Loss 5.7393565 Test MSE 1.508474357405438 Test RE 0.5870526141041345\n",
      "67 Train Loss 5.138267 Test MSE 1.2153655076584051 Test RE 0.5269404205148067\n",
      "68 Train Loss 4.464279 Test MSE 0.9839588061527594 Test RE 0.47412899897823707\n",
      "69 Train Loss 4.0209107 Test MSE 0.880714107947769 Test RE 0.44856515788271206\n",
      "70 Train Loss 3.2537036 Test MSE 0.5857764893164482 Test RE 0.36582554537733236\n",
      "71 Train Loss 2.5226657 Test MSE 0.4840251126577876 Test RE 0.3325385567989893\n",
      "72 Train Loss 2.0996473 Test MSE 0.41353205799459375 Test RE 0.30737083127066694\n",
      "73 Train Loss 1.8800778 Test MSE 0.35441003450259195 Test RE 0.28455162174119675\n",
      "74 Train Loss 1.7536398 Test MSE 0.285163599686438 Test RE 0.2552437428509344\n",
      "75 Train Loss 1.4963243 Test MSE 0.16721922110959217 Test RE 0.19545696837300958\n",
      "76 Train Loss 1.2961262 Test MSE 0.11851065437513233 Test RE 0.16454578365836742\n",
      "77 Train Loss 1.1365135 Test MSE 0.11127920465189726 Test RE 0.15944652799194606\n",
      "78 Train Loss 1.0632521 Test MSE 0.13108553027036296 Test RE 0.17305551252041132\n",
      "79 Train Loss 0.87322736 Test MSE 0.1219410976390232 Test RE 0.16691028944229674\n",
      "80 Train Loss 0.8127164 Test MSE 0.11047394429323398 Test RE 0.15886857142769703\n",
      "81 Train Loss 0.75191987 Test MSE 0.09868670883875029 Test RE 0.1501541684174979\n",
      "82 Train Loss 0.7308626 Test MSE 0.09669883289753801 Test RE 0.1486341748573801\n",
      "83 Train Loss 0.6485834 Test MSE 0.09134071609797378 Test RE 0.1444575571089881\n",
      "84 Train Loss 0.6285733 Test MSE 0.09038791773405376 Test RE 0.14370214511397641\n",
      "85 Train Loss 0.5962522 Test MSE 0.08820121631945224 Test RE 0.14195325238600398\n",
      "86 Train Loss 0.564251 Test MSE 0.08224990249377177 Test RE 0.13708052408938343\n",
      "87 Train Loss 0.5333397 Test MSE 0.07023910487410842 Test RE 0.12667693427971627\n",
      "88 Train Loss 0.4937392 Test MSE 0.059916158433855046 Test RE 0.1169984317593568\n",
      "89 Train Loss 0.41712433 Test MSE 0.07536738596407212 Test RE 0.1312199254030092\n",
      "90 Train Loss 0.37320065 Test MSE 0.07689843628647648 Test RE 0.1325460575426591\n",
      "91 Train Loss 0.3447511 Test MSE 0.07334257100557787 Test RE 0.12944525198586604\n",
      "92 Train Loss 0.32810843 Test MSE 0.07634674106855034 Test RE 0.13206973670888345\n",
      "93 Train Loss 0.29298985 Test MSE 0.05680448142497168 Test RE 0.11391983834357448\n",
      "94 Train Loss 0.2659829 Test MSE 0.05334300539404255 Test RE 0.11039433827512024\n",
      "95 Train Loss 0.24235645 Test MSE 0.04715844939655396 Test RE 0.10379772111404197\n",
      "96 Train Loss 0.21542671 Test MSE 0.030904085706010893 Test RE 0.08402644892910582\n",
      "97 Train Loss 0.20423706 Test MSE 0.03547901380297847 Test RE 0.09003136402205394\n",
      "98 Train Loss 0.19956025 Test MSE 0.03671959382854805 Test RE 0.0915918844772964\n",
      "99 Train Loss 0.19480278 Test MSE 0.03969664580145616 Test RE 0.09523245198493493\n",
      "Training time: 76.21\n",
      "KG_stan_tune13\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 52.304413 Test MSE 9.639920052443287 Test RE 1.4840371621364976\n",
      "1 Train Loss 43.946342 Test MSE 9.421181723569465 Test RE 1.4671034917663046\n",
      "2 Train Loss 43.329575 Test MSE 9.37465228442843 Test RE 1.4634761338319018\n",
      "3 Train Loss 43.209824 Test MSE 9.360786385910908 Test RE 1.4623934312399316\n",
      "4 Train Loss 42.982677 Test MSE 9.471748176787887 Test RE 1.4710354263844834\n",
      "5 Train Loss 42.740593 Test MSE 9.292948688325698 Test RE 1.4570848070989026\n",
      "6 Train Loss 42.302277 Test MSE 8.928622065950242 Test RE 1.4282370023733277\n",
      "7 Train Loss 40.388416 Test MSE 9.158221339244427 Test RE 1.446483979636108\n",
      "8 Train Loss 39.47276 Test MSE 9.482810440911013 Test RE 1.4718942031116575\n",
      "9 Train Loss 38.57425 Test MSE 9.346023223492509 Test RE 1.4612397850638648\n",
      "10 Train Loss 37.051598 Test MSE 9.14554252525077 Test RE 1.445482363028607\n",
      "11 Train Loss 36.539593 Test MSE 9.21858414220014 Test RE 1.4512431147754257\n",
      "12 Train Loss 35.917206 Test MSE 9.004601399976242 Test RE 1.434301018384963\n",
      "13 Train Loss 35.47775 Test MSE 9.374623747221078 Test RE 1.4634739063597564\n",
      "14 Train Loss 34.929356 Test MSE 9.493654163722072 Test RE 1.4727355281914156\n",
      "15 Train Loss 34.75015 Test MSE 9.652897118661324 Test RE 1.4850357166599435\n",
      "16 Train Loss 34.477646 Test MSE 9.776361157451035 Test RE 1.4945026130382006\n",
      "17 Train Loss 34.283306 Test MSE 9.663024386278014 Test RE 1.4858145197176387\n",
      "18 Train Loss 34.029015 Test MSE 9.80326491037302 Test RE 1.4965575752214542\n",
      "19 Train Loss 33.40409 Test MSE 9.75358329670321 Test RE 1.4927605832950483\n",
      "20 Train Loss 32.644 Test MSE 9.557163606832685 Test RE 1.4776533768418356\n",
      "21 Train Loss 31.753296 Test MSE 9.190049745908155 Test RE 1.4489953487578067\n",
      "22 Train Loss 30.596973 Test MSE 9.288019464112196 Test RE 1.4566983178033233\n",
      "23 Train Loss 29.354439 Test MSE 9.244917921485277 Test RE 1.4533144449145414\n",
      "24 Train Loss 27.97962 Test MSE 9.802412726838178 Test RE 1.4964925270230576\n",
      "25 Train Loss 27.269714 Test MSE 9.556698703561457 Test RE 1.4776174365633503\n",
      "26 Train Loss 26.763681 Test MSE 9.529579366776275 Test RE 1.4755194069538309\n",
      "27 Train Loss 26.143536 Test MSE 9.456619903982272 Test RE 1.4698601882956308\n",
      "28 Train Loss 25.590443 Test MSE 9.440006672181886 Test RE 1.468568507838963\n",
      "29 Train Loss 25.313387 Test MSE 9.441592301747168 Test RE 1.4686918397364017\n",
      "30 Train Loss 24.948597 Test MSE 9.467047720663542 Test RE 1.4706703725730754\n",
      "31 Train Loss 24.363453 Test MSE 8.831383671474004 Test RE 1.420438505211067\n",
      "32 Train Loss 23.374466 Test MSE 7.951831958959099 Test RE 1.3478502923981024\n",
      "33 Train Loss 20.418413 Test MSE 6.1815159643724 Test RE 1.1883806121168505\n",
      "34 Train Loss 14.621401 Test MSE 5.42141681606193 Test RE 1.1129213132442088\n",
      "35 Train Loss 13.651468 Test MSE 5.361733130803804 Test RE 1.1067783554028348\n",
      "36 Train Loss 13.152815 Test MSE 5.331049433743559 Test RE 1.103606920306401\n",
      "37 Train Loss 12.823147 Test MSE 5.4329405810013665 Test RE 1.1141034982753046\n",
      "38 Train Loss 12.634045 Test MSE 5.464752035384648 Test RE 1.117360438388653\n",
      "39 Train Loss 12.480147 Test MSE 5.453656744332266 Test RE 1.1162255526393234\n",
      "40 Train Loss 12.110028 Test MSE 5.551396687495659 Test RE 1.1261835807760117\n",
      "41 Train Loss 11.844748 Test MSE 5.5227833318681405 Test RE 1.12327750838842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Train Loss 11.247315 Test MSE 5.269222723744917 Test RE 1.0971887307685035\n",
      "43 Train Loss 10.206619 Test MSE 4.965542028294493 Test RE 1.0651024687899284\n",
      "44 Train Loss 8.362173 Test MSE 4.295695331316927 Test RE 0.9906603841240801\n",
      "45 Train Loss 7.519228 Test MSE 4.206018407435679 Test RE 0.9802653345104231\n",
      "46 Train Loss 6.830676 Test MSE 4.507895536741165 Test RE 1.0148339369478039\n",
      "47 Train Loss 6.477396 Test MSE 4.486365483157765 Test RE 1.0124075741377732\n",
      "48 Train Loss 6.25165 Test MSE 4.478132384676084 Test RE 1.0114781938978936\n",
      "49 Train Loss 6.103779 Test MSE 4.555426407196707 Test RE 1.0201700696304974\n",
      "50 Train Loss 5.9463687 Test MSE 4.503197792034686 Test RE 1.0143050123735167\n",
      "51 Train Loss 5.828282 Test MSE 4.552409188733308 Test RE 1.01983216648566\n",
      "52 Train Loss 5.7623954 Test MSE 4.5851160841888206 Test RE 1.023489114487719\n",
      "53 Train Loss 5.7219014 Test MSE 4.617033122940243 Test RE 1.027045195703084\n",
      "54 Train Loss 5.6887174 Test MSE 4.60254974941289 Test RE 1.0254330388582593\n",
      "55 Train Loss 5.6685615 Test MSE 4.581236935705551 Test RE 1.0230560713247667\n",
      "56 Train Loss 5.6319547 Test MSE 4.602467952149339 Test RE 1.025423926736308\n",
      "57 Train Loss 5.602392 Test MSE 4.596800645155381 Test RE 1.024792397919891\n",
      "58 Train Loss 5.566161 Test MSE 4.590464395884199 Test RE 1.0240858652963185\n",
      "59 Train Loss 5.547209 Test MSE 4.604227268496118 Test RE 1.0256198947177337\n",
      "60 Train Loss 5.521101 Test MSE 4.591071609016617 Test RE 1.0241535945901465\n",
      "61 Train Loss 5.4956884 Test MSE 4.580760098262659 Test RE 1.0230028276110645\n",
      "62 Train Loss 5.4753428 Test MSE 4.593645578349811 Test RE 1.0244406485491289\n",
      "63 Train Loss 5.444584 Test MSE 4.64046354110747 Test RE 1.0296479110187715\n",
      "64 Train Loss 5.430193 Test MSE 4.636251455670227 Test RE 1.0291805062508053\n",
      "65 Train Loss 5.4083567 Test MSE 4.659766044126303 Test RE 1.031787153875622\n",
      "66 Train Loss 5.3955517 Test MSE 4.677024403571263 Test RE 1.0336961012324455\n",
      "67 Train Loss 5.3759785 Test MSE 4.663413687953898 Test RE 1.0321909140392236\n",
      "68 Train Loss 5.360134 Test MSE 4.696736504825623 Test RE 1.035872153325458\n",
      "69 Train Loss 5.34128 Test MSE 4.703689708402995 Test RE 1.036638639392272\n",
      "70 Train Loss 5.3224554 Test MSE 4.684741607425918 Test RE 1.0345485615682868\n",
      "71 Train Loss 5.281229 Test MSE 4.726482612588792 Test RE 1.0391472498595224\n",
      "72 Train Loss 5.2604284 Test MSE 4.7000358641911895 Test RE 1.036235928734143\n",
      "73 Train Loss 5.240017 Test MSE 4.717557692927268 Test RE 1.038165686111114\n",
      "74 Train Loss 5.206172 Test MSE 4.735102936400746 Test RE 1.0400944346749383\n",
      "75 Train Loss 5.1547937 Test MSE 4.711494819749759 Test RE 1.0374983608862358\n",
      "76 Train Loss 5.120425 Test MSE 4.716604488790405 Test RE 1.038060797746869\n",
      "77 Train Loss 5.0314875 Test MSE 4.703303121844077 Test RE 1.036596038920744\n",
      "78 Train Loss 4.905507 Test MSE 4.636735706842961 Test RE 1.0292342532119756\n",
      "79 Train Loss 4.6263113 Test MSE 4.475664171285627 Test RE 1.0111994071283337\n",
      "80 Train Loss 3.704729 Test MSE 3.9262382069430988 Test RE 0.94710119100486\n",
      "81 Train Loss 2.8143568 Test MSE 3.5438893500245525 Test RE 0.8998044508543139\n",
      "82 Train Loss 2.3863225 Test MSE 3.4580669968146953 Test RE 0.8888423968419693\n",
      "83 Train Loss 2.0668826 Test MSE 3.5130052395303144 Test RE 0.8958750857440907\n",
      "84 Train Loss 1.9142845 Test MSE 3.3579538580127073 Test RE 0.8758816389660817\n",
      "85 Train Loss 1.8125913 Test MSE 3.2160258906746186 Test RE 0.8571717085657947\n",
      "86 Train Loss 1.6715691 Test MSE 3.106027002578365 Test RE 0.8423850947181726\n",
      "87 Train Loss 1.5515745 Test MSE 2.9959682566307757 Test RE 0.8273259831100883\n",
      "88 Train Loss 1.5143459 Test MSE 2.9873438266007666 Test RE 0.8261343220436236\n",
      "89 Train Loss 1.4604712 Test MSE 2.936573606756825 Test RE 0.819084119472675\n",
      "90 Train Loss 1.3861487 Test MSE 2.8569708159565237 Test RE 0.8079062396763875\n",
      "91 Train Loss 1.3229892 Test MSE 2.851148616685386 Test RE 0.8070826068283393\n",
      "92 Train Loss 1.2727535 Test MSE 2.8466927858899513 Test RE 0.8064516979949617\n",
      "93 Train Loss 1.2183925 Test MSE 2.8060224873178337 Test RE 0.8006701427737505\n",
      "94 Train Loss 1.1859579 Test MSE 2.7304692572751073 Test RE 0.7898174157277422\n",
      "95 Train Loss 1.1603891 Test MSE 2.72261032191366 Test RE 0.7886799561441087\n",
      "96 Train Loss 1.1262484 Test MSE 2.6646119089862093 Test RE 0.7802343073259248\n",
      "97 Train Loss 1.1038321 Test MSE 2.6992800378942152 Test RE 0.7852935524602651\n",
      "98 Train Loss 1.0859337 Test MSE 2.693626595373976 Test RE 0.7844707517605757\n",
      "99 Train Loss 1.0657539 Test MSE 2.733563339539488 Test RE 0.7902647872089383\n",
      "Training time: 76.67\n",
      "KG_stan_tune13\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.390804 Test MSE 8.881845066020478 Test RE 1.4244908266389869\n",
      "1 Train Loss 56.379242 Test MSE 8.9047298696304 Test RE 1.4263248048807677\n",
      "2 Train Loss 53.931747 Test MSE 9.06967086448688 Test RE 1.439473995876739\n",
      "3 Train Loss 52.625725 Test MSE 9.129097492547197 Test RE 1.4441821831744808\n",
      "4 Train Loss 47.174973 Test MSE 8.593173162940941 Test RE 1.4011506803136342\n",
      "5 Train Loss 45.2827 Test MSE 8.628754962457663 Test RE 1.4040485597716383\n",
      "6 Train Loss 44.81977 Test MSE 8.579326929454544 Test RE 1.4000213838067026\n",
      "7 Train Loss 44.345352 Test MSE 8.455069889275906 Test RE 1.3898459349565013\n",
      "8 Train Loss 44.253345 Test MSE 8.486069984897636 Test RE 1.3923915044844637\n",
      "9 Train Loss 44.062233 Test MSE 8.51236711076157 Test RE 1.3945472474675757\n",
      "10 Train Loss 43.920612 Test MSE 8.480693068130297 Test RE 1.391950313240889\n",
      "11 Train Loss 43.78262 Test MSE 8.498394189925339 Test RE 1.3934022133625732\n",
      "12 Train Loss 42.7986 Test MSE 8.187811238451578 Test RE 1.367703540717939\n",
      "13 Train Loss 39.592407 Test MSE 7.631788257054506 Test RE 1.3204477366257605\n",
      "14 Train Loss 36.31382 Test MSE 7.3206046211110225 Test RE 1.2932471681760074\n",
      "15 Train Loss 35.089855 Test MSE 7.176913975873891 Test RE 1.2804921802083378\n",
      "16 Train Loss 34.61273 Test MSE 7.10200034808688 Test RE 1.2737916712574617\n",
      "17 Train Loss 34.186123 Test MSE 7.156520231648255 Test RE 1.2786715782235294\n",
      "18 Train Loss 34.006554 Test MSE 7.106721211956954 Test RE 1.2742149603172424\n",
      "19 Train Loss 33.885014 Test MSE 7.1675053428092355 Test RE 1.2796525691862732\n",
      "20 Train Loss 33.56552 Test MSE 6.948187255555804 Test RE 1.2599224584720634\n",
      "21 Train Loss 33.432858 Test MSE 7.093937074640939 Test RE 1.2730683646542085\n",
      "22 Train Loss 33.258446 Test MSE 7.049514574175507 Test RE 1.2690761039545626\n",
      "23 Train Loss 32.98063 Test MSE 7.014233756179942 Test RE 1.265896437926555\n",
      "24 Train Loss 32.617455 Test MSE 7.025379829132891 Test RE 1.2669018344994856\n",
      "25 Train Loss 32.306778 Test MSE 7.060080121994964 Test RE 1.2700267696954448\n",
      "26 Train Loss 31.923946 Test MSE 6.992652941404853 Test RE 1.2639475349416232\n",
      "27 Train Loss 31.758104 Test MSE 7.028747623264247 Test RE 1.2672054588910504\n",
      "28 Train Loss 31.486557 Test MSE 6.991023325270814 Test RE 1.2638002468285627\n",
      "29 Train Loss 31.055805 Test MSE 6.95599682087296 Test RE 1.2606303181705827\n",
      "30 Train Loss 30.410746 Test MSE 6.983776975886438 Test RE 1.263145098644518\n",
      "31 Train Loss 29.972631 Test MSE 6.785359328911815 Test RE 1.245072055646075\n",
      "32 Train Loss 29.327007 Test MSE 6.748741194761623 Test RE 1.2417079085856806\n",
      "33 Train Loss 28.889996 Test MSE 6.931145302831178 Test RE 1.2583763918312965\n",
      "34 Train Loss 28.658228 Test MSE 6.873169751809293 Test RE 1.2531024968954956\n",
      "35 Train Loss 28.245348 Test MSE 6.744959916297317 Test RE 1.2413599991680928\n",
      "36 Train Loss 27.706135 Test MSE 6.905336578654643 Test RE 1.2560313696867555\n",
      "37 Train Loss 27.288652 Test MSE 6.683364823178968 Test RE 1.2356789388142182\n",
      "38 Train Loss 27.084753 Test MSE 6.599683910909019 Test RE 1.227918741926069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Train Loss 26.835173 Test MSE 6.6477046573148195 Test RE 1.2323779480153965\n",
      "40 Train Loss 26.506737 Test MSE 6.489275325811272 Test RE 1.2176042649203125\n",
      "41 Train Loss 26.199203 Test MSE 6.422747396242785 Test RE 1.2113467575373533\n",
      "42 Train Loss 25.313286 Test MSE 6.602585983285351 Test RE 1.2281886879909845\n",
      "43 Train Loss 24.716526 Test MSE 6.635227567565335 Test RE 1.2312208785549061\n",
      "44 Train Loss 24.130106 Test MSE 6.7478246536768 Test RE 1.24162358804918\n",
      "45 Train Loss 23.80823 Test MSE 6.87001712613822 Test RE 1.2528150737440502\n",
      "46 Train Loss 23.320387 Test MSE 6.954508906065672 Test RE 1.2604954840927791\n",
      "47 Train Loss 22.90006 Test MSE 6.99439691792037 Test RE 1.2641051401749235\n",
      "48 Train Loss 21.891356 Test MSE 7.136320064752811 Test RE 1.2768656983493463\n",
      "49 Train Loss 21.177933 Test MSE 7.196538765102575 Test RE 1.2822416949733302\n",
      "50 Train Loss 20.93609 Test MSE 7.139776828314232 Test RE 1.2771749115296072\n",
      "51 Train Loss 20.740273 Test MSE 7.094959912164243 Test RE 1.2731601398663035\n",
      "52 Train Loss 20.506767 Test MSE 7.114756030807294 Test RE 1.2749350669551216\n",
      "53 Train Loss 20.374594 Test MSE 7.071526814519134 Test RE 1.2710559165252926\n",
      "54 Train Loss 20.178244 Test MSE 6.890453238107956 Test RE 1.254677052904749\n",
      "55 Train Loss 19.980814 Test MSE 6.785014134900501 Test RE 1.2450403847453309\n",
      "56 Train Loss 19.47762 Test MSE 6.770444694418735 Test RE 1.2437029306415543\n",
      "57 Train Loss 19.19778 Test MSE 6.749540659049926 Test RE 1.2417814535404628\n",
      "58 Train Loss 18.825333 Test MSE 6.839718208986371 Test RE 1.2500493684579572\n",
      "59 Train Loss 18.400877 Test MSE 6.698576388249662 Test RE 1.2370843631629356\n",
      "60 Train Loss 18.189974 Test MSE 6.730395714282611 Test RE 1.240019058067565\n",
      "61 Train Loss 18.099033 Test MSE 6.759052167893693 Test RE 1.2426561098828317\n",
      "62 Train Loss 17.95379 Test MSE 6.809825536811703 Test RE 1.247314735807526\n",
      "63 Train Loss 17.842352 Test MSE 6.734975111884735 Test RE 1.2404408441662749\n",
      "64 Train Loss 17.602598 Test MSE 6.653260192640512 Test RE 1.2328927940978813\n",
      "65 Train Loss 17.110804 Test MSE 6.545064762161008 Test RE 1.2228270422044092\n",
      "66 Train Loss 16.878386 Test MSE 6.472932098093795 Test RE 1.216070031293285\n",
      "67 Train Loss 16.662195 Test MSE 6.479401520671234 Test RE 1.2166775848739022\n",
      "68 Train Loss 16.544834 Test MSE 6.381735283645769 Test RE 1.2074730686127009\n",
      "69 Train Loss 16.4407 Test MSE 6.39683511916525 Test RE 1.208900726732891\n",
      "70 Train Loss 16.329128 Test MSE 6.354572179329434 Test RE 1.2049005949119602\n",
      "71 Train Loss 16.154423 Test MSE 6.436813993594661 Test RE 1.2126725303402457\n",
      "72 Train Loss 16.067934 Test MSE 6.320761701490772 Test RE 1.2016908903951964\n",
      "73 Train Loss 15.982509 Test MSE 6.334308161019872 Test RE 1.2029779144231394\n",
      "74 Train Loss 15.834425 Test MSE 6.317295231695874 Test RE 1.2013613259643552\n",
      "75 Train Loss 15.698234 Test MSE 6.238094075240452 Test RE 1.1938067228398814\n",
      "76 Train Loss 15.420007 Test MSE 6.224379076837073 Test RE 1.1924936561877688\n",
      "77 Train Loss 15.1854515 Test MSE 6.2865280000949895 Test RE 1.1984322498665803\n",
      "78 Train Loss 14.885521 Test MSE 6.283503981578187 Test RE 1.1981439733136148\n",
      "79 Train Loss 14.716667 Test MSE 6.23018292574914 Test RE 1.1930494899755137\n",
      "80 Train Loss 14.556195 Test MSE 6.241495156701379 Test RE 1.1941321171504782\n",
      "81 Train Loss 14.410247 Test MSE 6.263387250695024 Test RE 1.1962244979537433\n",
      "82 Train Loss 14.232782 Test MSE 6.326714307025054 Test RE 1.2022566061140745\n",
      "83 Train Loss 14.07931 Test MSE 6.3223433785274645 Test RE 1.201841233667612\n",
      "84 Train Loss 13.867653 Test MSE 6.117938066289157 Test RE 1.1822534727050487\n",
      "85 Train Loss 13.6992035 Test MSE 5.969490427961173 Test RE 1.1678221019386317\n",
      "86 Train Loss 13.323144 Test MSE 5.693145332455413 Test RE 1.1404708661645544\n",
      "87 Train Loss 12.847532 Test MSE 5.680658528274505 Test RE 1.1392194793873585\n",
      "88 Train Loss 12.598035 Test MSE 5.715248077032353 Test RE 1.1426825713013737\n",
      "89 Train Loss 12.354594 Test MSE 5.848178335071329 Test RE 1.1558949439494115\n",
      "90 Train Loss 12.012182 Test MSE 5.850285530574397 Test RE 1.1561031692396155\n",
      "91 Train Loss 11.753988 Test MSE 5.784802437383999 Test RE 1.1496147465817632\n",
      "92 Train Loss 11.598432 Test MSE 5.8135158636863 Test RE 1.1524643268994998\n",
      "93 Train Loss 11.499135 Test MSE 5.763520335632552 Test RE 1.1474981002163684\n",
      "94 Train Loss 11.433208 Test MSE 5.739925971264094 Test RE 1.1451469109636188\n",
      "95 Train Loss 11.373714 Test MSE 5.69449125885236 Test RE 1.1406056685490364\n",
      "96 Train Loss 11.311725 Test MSE 5.677279016633245 Test RE 1.1388805593263551\n",
      "97 Train Loss 11.247997 Test MSE 5.680359550333357 Test RE 1.1391894999426848\n",
      "98 Train Loss 11.181526 Test MSE 5.589126192543914 Test RE 1.1300040966248133\n",
      "99 Train Loss 11.098342 Test MSE 5.510893364994662 Test RE 1.1220677082135189\n",
      "Training time: 77.44\n",
      "KG_stan_tune13\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 56.288208 Test MSE 8.5743561856361 Test RE 1.3996157484930491\n",
      "1 Train Loss 48.507076 Test MSE 7.263124020675545 Test RE 1.2881599435482813\n",
      "2 Train Loss 43.20618 Test MSE 7.394032432965508 Test RE 1.299716809788966\n",
      "3 Train Loss 36.105145 Test MSE 7.239586730596952 Test RE 1.2860710078461857\n",
      "4 Train Loss 35.322502 Test MSE 7.461642746113014 Test RE 1.3056455297450134\n",
      "5 Train Loss 34.085712 Test MSE 7.223356632004108 Test RE 1.2846286070743627\n",
      "6 Train Loss 32.864952 Test MSE 7.01851439190943 Test RE 1.2662826536709952\n",
      "7 Train Loss 31.984533 Test MSE 6.842119159650311 Test RE 1.25026875202231\n",
      "8 Train Loss 31.370712 Test MSE 6.618868037104157 Test RE 1.2297021193245108\n",
      "9 Train Loss 30.234035 Test MSE 6.241589398968289 Test RE 1.194141132401638\n",
      "10 Train Loss 28.468172 Test MSE 6.411731788993564 Test RE 1.2103075257537401\n",
      "11 Train Loss 27.25448 Test MSE 6.334608327811515 Test RE 1.2030064171209938\n",
      "12 Train Loss 26.6888 Test MSE 6.276168211515953 Test RE 1.1974443735746596\n",
      "13 Train Loss 26.24838 Test MSE 6.322987230438689 Test RE 1.2019024283884052\n",
      "14 Train Loss 25.581371 Test MSE 6.547622490910475 Test RE 1.2230659515576625\n",
      "15 Train Loss 25.002153 Test MSE 6.346527192387229 Test RE 1.204137641936968\n",
      "16 Train Loss 24.518314 Test MSE 6.395570535658411 Test RE 1.2087812276795347\n",
      "17 Train Loss 24.002678 Test MSE 6.491297769082116 Test RE 1.2177939890104723\n",
      "18 Train Loss 23.178232 Test MSE 6.218961078167731 Test RE 1.1919745413049283\n",
      "19 Train Loss 22.688326 Test MSE 6.318030342627389 Test RE 1.201431222029134\n",
      "20 Train Loss 22.398798 Test MSE 6.187395288468594 Test RE 1.1889456203017488\n",
      "21 Train Loss 21.861744 Test MSE 6.308751258528523 Test RE 1.2005486465274242\n",
      "22 Train Loss 21.703896 Test MSE 6.194193656131562 Test RE 1.1895986148206303\n",
      "23 Train Loss 21.52437 Test MSE 6.27226475956895 Test RE 1.1970719414303592\n",
      "24 Train Loss 21.320244 Test MSE 6.414629920543503 Test RE 1.2105810270685422\n",
      "25 Train Loss 21.285257 Test MSE 6.399724089406509 Test RE 1.2091736807738789\n",
      "26 Train Loss 21.167404 Test MSE 6.338180435028909 Test RE 1.2033455590254782\n",
      "27 Train Loss 21.040562 Test MSE 6.319633190239755 Test RE 1.201583610427201\n",
      "28 Train Loss 20.95361 Test MSE 6.4079299064039175 Test RE 1.2099486422586603\n",
      "29 Train Loss 20.776146 Test MSE 6.359001593440282 Test RE 1.2053204559064983\n",
      "30 Train Loss 20.662441 Test MSE 6.346757400489859 Test RE 1.2041594806307725\n",
      "31 Train Loss 20.473797 Test MSE 6.398829487329443 Test RE 1.2090891640762083\n",
      "32 Train Loss 20.336594 Test MSE 6.365003595379575 Test RE 1.2058891481268217\n",
      "33 Train Loss 20.236767 Test MSE 6.333377087743781 Test RE 1.2028894989465375\n",
      "34 Train Loss 20.144192 Test MSE 6.3564651261099 Test RE 1.205080043882444\n",
      "35 Train Loss 20.088827 Test MSE 6.328780531425579 Test RE 1.2024529109435917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 Train Loss 19.95429 Test MSE 6.277859470368475 Test RE 1.1976057022639066\n",
      "37 Train Loss 19.808395 Test MSE 6.41593346062925 Test RE 1.2107040240889215\n",
      "38 Train Loss 19.7347 Test MSE 6.45704109269435 Test RE 1.2145763920778947\n",
      "39 Train Loss 19.675732 Test MSE 6.397165029675371 Test RE 1.2089319002668213\n",
      "40 Train Loss 19.374537 Test MSE 6.472471093387056 Test RE 1.2160267260351891\n",
      "41 Train Loss 19.180698 Test MSE 6.541599452095902 Test RE 1.2225032840716277\n",
      "42 Train Loss 18.543653 Test MSE 6.500363898954997 Test RE 1.21864411378746\n",
      "43 Train Loss 18.103733 Test MSE 6.45755015352917 Test RE 1.2146242685802613\n",
      "44 Train Loss 17.840134 Test MSE 6.439994775458031 Test RE 1.2129721172471457\n",
      "45 Train Loss 17.611176 Test MSE 6.37482831287325 Test RE 1.206819465897982\n",
      "46 Train Loss 17.42094 Test MSE 6.246465500164935 Test RE 1.1946074892742922\n",
      "47 Train Loss 17.151007 Test MSE 6.3385658798799325 Test RE 1.2033821480988767\n",
      "48 Train Loss 16.876053 Test MSE 6.30148701926103 Test RE 1.1998572589462002\n",
      "49 Train Loss 16.577768 Test MSE 6.180023361014811 Test RE 1.188237128868549\n",
      "50 Train Loss 16.028412 Test MSE 6.098677730685411 Test RE 1.1803910357103289\n",
      "51 Train Loss 15.488651 Test MSE 6.182598403496412 Test RE 1.1884846556369406\n",
      "52 Train Loss 15.17713 Test MSE 6.112316796082262 Test RE 1.1817102101372656\n",
      "53 Train Loss 14.6857395 Test MSE 5.944965876918716 Test RE 1.1654207420960043\n",
      "54 Train Loss 13.877722 Test MSE 5.253289958561431 Test RE 1.0955286676019829\n",
      "55 Train Loss 12.187632 Test MSE 3.9729287058229716 Test RE 0.9527159720882347\n",
      "56 Train Loss 9.557606 Test MSE 2.7808359094301798 Test RE 0.7970686752946902\n",
      "57 Train Loss 8.000331 Test MSE 2.620930940575163 Test RE 0.7738126928442851\n",
      "58 Train Loss 7.001758 Test MSE 2.3270393471900563 Test RE 0.7291383206168631\n",
      "59 Train Loss 6.3026295 Test MSE 2.3112297418502212 Test RE 0.7266572635621305\n",
      "60 Train Loss 5.5988703 Test MSE 2.155234699558643 Test RE 0.7017062513725981\n",
      "61 Train Loss 5.2348175 Test MSE 2.1727640331533804 Test RE 0.7045540927550734\n",
      "62 Train Loss 5.030191 Test MSE 2.1472757413267187 Test RE 0.7004094050725237\n",
      "63 Train Loss 4.8757315 Test MSE 2.1635973358598193 Test RE 0.7030662964980874\n",
      "64 Train Loss 4.7306786 Test MSE 2.1880206441892542 Test RE 0.7070233678693317\n",
      "65 Train Loss 4.6562243 Test MSE 2.177150611312551 Test RE 0.7052649438259514\n",
      "66 Train Loss 4.5828533 Test MSE 2.1688476933107834 Test RE 0.7039188379090395\n",
      "67 Train Loss 4.5177345 Test MSE 2.169643829784059 Test RE 0.7040480226469052\n",
      "68 Train Loss 4.4850903 Test MSE 2.160408133639836 Test RE 0.7025479358401875\n",
      "69 Train Loss 4.449435 Test MSE 2.1467054564397308 Test RE 0.7003163896727947\n",
      "70 Train Loss 4.415884 Test MSE 2.171399397417773 Test RE 0.7043328053326828\n",
      "71 Train Loss 4.3966727 Test MSE 2.158884361861269 Test RE 0.702300132767236\n",
      "72 Train Loss 4.3618593 Test MSE 2.1510447411907174 Test RE 0.7010238314181767\n",
      "73 Train Loss 4.338012 Test MSE 2.147316011064059 Test RE 0.700415972736376\n",
      "74 Train Loss 4.317782 Test MSE 2.1400251961150123 Test RE 0.6992258951640311\n",
      "75 Train Loss 4.302927 Test MSE 2.158762498613862 Test RE 0.7022803110055582\n",
      "76 Train Loss 4.283786 Test MSE 2.149899824656626 Test RE 0.7008372428762505\n",
      "77 Train Loss 4.2586336 Test MSE 2.161402541340375 Test RE 0.7027096040670617\n",
      "78 Train Loss 4.241252 Test MSE 2.152246217716416 Test RE 0.7012195842264496\n",
      "79 Train Loss 4.2288485 Test MSE 2.1485058282810465 Test RE 0.7006099943824586\n",
      "80 Train Loss 4.2091713 Test MSE 2.149017437391547 Test RE 0.7006934051686262\n",
      "81 Train Loss 4.1878185 Test MSE 2.1628985954076274 Test RE 0.7029527586128824\n",
      "82 Train Loss 4.171319 Test MSE 2.1591912950701375 Test RE 0.7023500547491778\n",
      "83 Train Loss 4.1535196 Test MSE 2.1576685320305984 Test RE 0.7021023459563548\n",
      "84 Train Loss 4.139394 Test MSE 2.151362833054301 Test RE 0.7010756624492731\n",
      "85 Train Loss 4.1198263 Test MSE 2.1504655623955506 Test RE 0.7009294481018892\n",
      "86 Train Loss 4.1111226 Test MSE 2.1468644655200877 Test RE 0.7003423258352852\n",
      "87 Train Loss 4.0936437 Test MSE 2.151874891499679 Test RE 0.7011590910437909\n",
      "88 Train Loss 4.0779934 Test MSE 2.142021790615347 Test RE 0.6995519999934634\n",
      "89 Train Loss 4.0620384 Test MSE 2.1390841493473354 Test RE 0.6990721407543367\n",
      "90 Train Loss 4.0491395 Test MSE 2.1344582452681826 Test RE 0.6983158378974521\n",
      "91 Train Loss 4.0390325 Test MSE 2.14083583509626 Test RE 0.6993583155908675\n",
      "92 Train Loss 4.0193353 Test MSE 2.1412128027618427 Test RE 0.6994198859043905\n",
      "93 Train Loss 3.9994946 Test MSE 2.127202781498896 Test RE 0.6971279678102575\n",
      "94 Train Loss 3.968863 Test MSE 2.129458277055211 Test RE 0.69749745596348\n",
      "95 Train Loss 3.9158916 Test MSE 2.1220978287639443 Test RE 0.6962909664989032\n",
      "96 Train Loss 3.8661075 Test MSE 2.117652956439965 Test RE 0.6955613708284722\n",
      "97 Train Loss 3.7754295 Test MSE 2.1336477364245727 Test RE 0.6981832410420047\n",
      "98 Train Loss 3.588133 Test MSE 2.033706103780523 Test RE 0.6816354303874893\n",
      "99 Train Loss 3.1928165 Test MSE 1.7768198458282305 Test RE 0.6371324993026923\n",
      "Training time: 76.22\n",
      "KG_stan_tune13\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.38683 Test MSE 8.629962784524713 Test RE 1.4041468231654188\n",
      "1 Train Loss 51.262497 Test MSE 8.947760780768935 Test RE 1.4297669130390052\n",
      "2 Train Loss 44.83716 Test MSE 8.388322528810656 Test RE 1.3843490932889582\n",
      "3 Train Loss 44.016575 Test MSE 8.70171386620876 Test RE 1.4099719066836185\n",
      "4 Train Loss 43.130287 Test MSE 8.37232454156157 Test RE 1.3830283662547012\n",
      "5 Train Loss 42.747818 Test MSE 8.48799986827129 Test RE 1.3925498227907973\n",
      "6 Train Loss 42.609123 Test MSE 8.317635114588468 Test RE 1.3785038789408703\n",
      "7 Train Loss 42.51377 Test MSE 8.339129386334672 Test RE 1.3802838812483416\n",
      "8 Train Loss 42.181465 Test MSE 8.3226296763038 Test RE 1.3789176978531212\n",
      "9 Train Loss 41.974533 Test MSE 8.30821349932075 Test RE 1.3777229229967176\n",
      "10 Train Loss 41.83835 Test MSE 8.327956465261403 Test RE 1.379358906276894\n",
      "11 Train Loss 41.534775 Test MSE 8.467692053751966 Test RE 1.390882964920561\n",
      "12 Train Loss 41.386444 Test MSE 8.457147308031631 Test RE 1.3900166677073738\n",
      "13 Train Loss 41.217194 Test MSE 8.570811285487308 Test RE 1.3993263966815357\n",
      "14 Train Loss 40.576355 Test MSE 8.416152546893334 Test RE 1.3866436258468058\n",
      "15 Train Loss 40.418564 Test MSE 8.477519952376108 Test RE 1.3916898844848624\n",
      "16 Train Loss 40.283157 Test MSE 8.392152589713433 Test RE 1.384665100227529\n",
      "17 Train Loss 40.183987 Test MSE 8.541070328600984 Test RE 1.3968964358103586\n",
      "18 Train Loss 40.11461 Test MSE 8.605579759091954 Test RE 1.4021617876409287\n",
      "19 Train Loss 39.903496 Test MSE 8.789029861184462 Test RE 1.4170283211926078\n",
      "20 Train Loss 39.633545 Test MSE 9.009700247157282 Test RE 1.434707046724687\n",
      "21 Train Loss 39.490566 Test MSE 9.010686447847256 Test RE 1.4347855660052269\n",
      "22 Train Loss 38.379486 Test MSE 9.077942544501717 Test RE 1.440130257547462\n",
      "23 Train Loss 37.6492 Test MSE 9.105639798685052 Test RE 1.442325538864049\n",
      "24 Train Loss 36.668022 Test MSE 9.5094716717956 Test RE 1.4739618900720914\n",
      "25 Train Loss 35.989662 Test MSE 9.506411402632544 Test RE 1.4737247011284986\n",
      "26 Train Loss 32.282707 Test MSE 8.795791995043679 Test RE 1.4175733354300275\n",
      "27 Train Loss 30.270788 Test MSE 8.912080876734386 Test RE 1.4269134112140527\n",
      "28 Train Loss 29.0059 Test MSE 8.885923485633624 Test RE 1.4248178422819058\n",
      "29 Train Loss 28.343685 Test MSE 8.691769324759843 Test RE 1.4091660003637019\n",
      "30 Train Loss 27.72842 Test MSE 8.35940743180028 Test RE 1.3819610626031753\n",
      "31 Train Loss 26.967117 Test MSE 8.236627543616539 Test RE 1.3717746539126447\n",
      "32 Train Loss 26.153908 Test MSE 8.021557439122263 Test RE 1.353746694211128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 Train Loss 23.2252 Test MSE 8.138220926286268 Test RE 1.363555432465597\n",
      "34 Train Loss 21.750076 Test MSE 7.702753491494505 Test RE 1.326572713676598\n",
      "35 Train Loss 20.69115 Test MSE 7.5195340982937315 Test RE 1.3107006861999617\n",
      "36 Train Loss 19.996717 Test MSE 7.288550446007878 Test RE 1.2904127405033294\n",
      "37 Train Loss 19.448765 Test MSE 7.33098082382592 Test RE 1.2941633659375336\n",
      "38 Train Loss 19.177668 Test MSE 7.430108743355875 Test RE 1.3028836833742992\n",
      "39 Train Loss 18.837776 Test MSE 7.538225136094431 Test RE 1.3123286561625755\n",
      "40 Train Loss 18.55634 Test MSE 7.385885949167244 Test RE 1.2990006214274936\n",
      "41 Train Loss 18.373554 Test MSE 7.318071961690412 Test RE 1.2930234408932069\n",
      "42 Train Loss 17.969963 Test MSE 7.46612764189808 Test RE 1.3060378565215798\n",
      "43 Train Loss 17.716106 Test MSE 7.603365503978815 Test RE 1.317986598587899\n",
      "44 Train Loss 17.409492 Test MSE 7.526171110494689 Test RE 1.3112789944858299\n",
      "45 Train Loss 16.883087 Test MSE 7.462552025004521 Test RE 1.3057250805754759\n",
      "46 Train Loss 16.228188 Test MSE 7.195143036553136 Test RE 1.2821173471318543\n",
      "47 Train Loss 15.496685 Test MSE 6.952016398412356 Test RE 1.260269582002489\n",
      "48 Train Loss 14.807613 Test MSE 7.182276779883363 Test RE 1.2809705018301483\n",
      "49 Train Loss 13.788863 Test MSE 7.140807047187452 Test RE 1.2772670518211928\n",
      "50 Train Loss 12.792701 Test MSE 7.324764448709642 Test RE 1.2936145504842587\n",
      "51 Train Loss 12.1416645 Test MSE 7.063563174436656 Test RE 1.2703400114939254\n",
      "52 Train Loss 11.275616 Test MSE 6.941265756417706 Test RE 1.25929476057504\n",
      "53 Train Loss 10.637797 Test MSE 6.864445463861452 Test RE 1.2523069470392492\n",
      "54 Train Loss 10.312376 Test MSE 6.771188449243784 Test RE 1.243771241121509\n",
      "55 Train Loss 9.885668 Test MSE 6.8541165714122885 Test RE 1.25136442274607\n",
      "56 Train Loss 9.552677 Test MSE 6.913896018661542 Test RE 1.256809579086565\n",
      "57 Train Loss 9.300163 Test MSE 6.9650400189615835 Test RE 1.2614494981656865\n",
      "58 Train Loss 8.856033 Test MSE 6.881748967879958 Test RE 1.2538843257149745\n",
      "59 Train Loss 8.560645 Test MSE 6.898196998841055 Test RE 1.2553818824935885\n",
      "60 Train Loss 8.290434 Test MSE 7.000900981146704 Test RE 1.2646927468965097\n",
      "61 Train Loss 8.108182 Test MSE 7.1204594482124595 Test RE 1.2754459790748898\n",
      "62 Train Loss 7.8434043 Test MSE 7.030622224201838 Test RE 1.267374432533309\n",
      "63 Train Loss 7.613065 Test MSE 7.317154037511926 Test RE 1.2929423447583799\n",
      "64 Train Loss 7.375009 Test MSE 7.366821103986715 Test RE 1.2973230130869302\n",
      "65 Train Loss 6.873687 Test MSE 7.122290627575304 Test RE 1.2756099727210197\n",
      "66 Train Loss 5.866816 Test MSE 6.495204950530943 Test RE 1.218160435480259\n",
      "67 Train Loss 5.3495975 Test MSE 6.256410525784154 Test RE 1.1955580810237931\n",
      "68 Train Loss 4.8263164 Test MSE 6.439130407565486 Test RE 1.2128907127295823\n",
      "69 Train Loss 4.457084 Test MSE 6.511499366071863 Test RE 1.2196874680545615\n",
      "70 Train Loss 4.274158 Test MSE 6.542062475400428 Test RE 1.2225465485284694\n",
      "71 Train Loss 4.093276 Test MSE 6.613149057106418 Test RE 1.2291707473765217\n",
      "72 Train Loss 3.8619914 Test MSE 6.604825322983943 Test RE 1.2283969471890896\n",
      "73 Train Loss 3.7077646 Test MSE 6.767412803602853 Test RE 1.243424426502782\n",
      "74 Train Loss 3.62704 Test MSE 6.677006916408948 Test RE 1.2350910462611207\n",
      "75 Train Loss 3.4993172 Test MSE 6.732728956530746 Test RE 1.2402339796165567\n",
      "76 Train Loss 3.4228172 Test MSE 6.703763721649632 Test RE 1.2375632654543478\n",
      "77 Train Loss 3.33869 Test MSE 6.76117596567342 Test RE 1.2428513253463893\n",
      "78 Train Loss 3.2718651 Test MSE 6.712578709940686 Test RE 1.2383766534496696\n",
      "79 Train Loss 3.1896055 Test MSE 6.659254696618992 Test RE 1.233448079521095\n",
      "80 Train Loss 3.1433053 Test MSE 6.682650855507445 Test RE 1.2356129347577998\n",
      "81 Train Loss 3.0712795 Test MSE 6.684655413313629 Test RE 1.2357982408506125\n",
      "82 Train Loss 3.029076 Test MSE 6.731322518626612 Test RE 1.2401044330987545\n",
      "83 Train Loss 3.0039172 Test MSE 6.672616898735139 Test RE 1.2346849538972342\n",
      "84 Train Loss 2.9683502 Test MSE 6.760634491442794 Test RE 1.242801556974511\n",
      "85 Train Loss 2.9317994 Test MSE 6.724475272928423 Test RE 1.2394735422000196\n",
      "86 Train Loss 2.8809857 Test MSE 6.7883585061305 Test RE 1.245347190610949\n",
      "87 Train Loss 2.8367803 Test MSE 6.805620636410907 Test RE 1.2469295832002103\n",
      "88 Train Loss 2.7986488 Test MSE 6.8290479702341065 Test RE 1.2490739239330457\n",
      "89 Train Loss 2.767057 Test MSE 6.851970533075242 Test RE 1.2511685049908923\n",
      "90 Train Loss 2.7389448 Test MSE 6.869682283356491 Test RE 1.2527845424376334\n",
      "91 Train Loss 2.6941817 Test MSE 6.841357188957024 Test RE 1.2501991321683998\n",
      "92 Train Loss 2.6690958 Test MSE 6.847529573124917 Test RE 1.2507629800546058\n",
      "93 Train Loss 2.6449733 Test MSE 6.836861117062552 Test RE 1.2497882554342352\n",
      "94 Train Loss 2.6124668 Test MSE 6.866764957314936 Test RE 1.2525185061845872\n",
      "95 Train Loss 2.5856354 Test MSE 6.884505434151927 Test RE 1.254135420591893\n",
      "96 Train Loss 2.545198 Test MSE 6.865949077301279 Test RE 1.2524440944944613\n",
      "97 Train Loss 2.5232308 Test MSE 6.8842795868688365 Test RE 1.2541148493683627\n",
      "98 Train Loss 2.4957812 Test MSE 6.868780483457274 Test RE 1.252702311702167\n",
      "99 Train Loss 2.4667087 Test MSE 6.878549512120188 Test RE 1.2535928145134227\n",
      "Training time: 76.16\n",
      "KG_stan_tune13\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 56.558487 Test MSE 8.936657688029554 Test RE 1.4288795534656313\n",
      "1 Train Loss 51.258087 Test MSE 9.005695486624884 Test RE 1.4343881517215973\n",
      "2 Train Loss 46.347702 Test MSE 8.023143967063017 Test RE 1.3538805616542273\n",
      "3 Train Loss 44.403915 Test MSE 8.2435271796402 Test RE 1.372349085893295\n",
      "4 Train Loss 44.059074 Test MSE 8.215928004040846 Test RE 1.3700498602374274\n",
      "5 Train Loss 43.38282 Test MSE 8.372397285150917 Test RE 1.3830343745161167\n",
      "6 Train Loss 41.684677 Test MSE 8.462993409055022 Test RE 1.390497017269952\n",
      "7 Train Loss 41.076355 Test MSE 8.822462409897698 Test RE 1.4197208767049236\n",
      "8 Train Loss 40.778496 Test MSE 8.72921361313359 Test RE 1.412198093705876\n",
      "9 Train Loss 40.369457 Test MSE 8.705927617451803 Test RE 1.4103132504627827\n",
      "10 Train Loss 40.001633 Test MSE 8.785222443615135 Test RE 1.4167213588178162\n",
      "11 Train Loss 39.65512 Test MSE 8.568676152961979 Test RE 1.3991520880133579\n",
      "12 Train Loss 39.303593 Test MSE 8.312667594183388 Test RE 1.3780921772508008\n",
      "13 Train Loss 39.098183 Test MSE 8.277263742881344 Test RE 1.375154382006736\n",
      "14 Train Loss 38.925518 Test MSE 8.350568500542444 Test RE 1.3812302518620907\n",
      "15 Train Loss 38.579815 Test MSE 8.201301998045809 Test RE 1.3688298347281986\n",
      "16 Train Loss 37.300644 Test MSE 8.002397214439984 Test RE 1.3521289536150312\n",
      "17 Train Loss 36.47141 Test MSE 7.882795018001032 Test RE 1.34198659276797\n",
      "18 Train Loss 35.496563 Test MSE 7.764321457017235 Test RE 1.3318637973612355\n",
      "19 Train Loss 34.18578 Test MSE 7.532026778805661 Test RE 1.3117890095913092\n",
      "20 Train Loss 30.932657 Test MSE 5.447967193463267 Test RE 1.1156431471446238\n",
      "21 Train Loss 24.023827 Test MSE 3.752943256770798 Test RE 0.9259639082839916\n",
      "22 Train Loss 20.643799 Test MSE 2.8217919104949334 Test RE 0.8029168134315566\n",
      "23 Train Loss 16.325842 Test MSE 2.3493706938307097 Test RE 0.7326285415683342\n",
      "24 Train Loss 11.915745 Test MSE 1.2602696432441636 Test RE 0.5365865690583407\n",
      "25 Train Loss 9.730422 Test MSE 0.6019169888933089 Test RE 0.37083128062201204\n",
      "26 Train Loss 5.6127396 Test MSE 0.3191677475828085 Test RE 0.2700334466178762\n",
      "27 Train Loss 3.2341769 Test MSE 0.22508787210161485 Test RE 0.22676922093370858\n",
      "28 Train Loss 2.497613 Test MSE 0.21177198736009253 Test RE 0.21995929366425077\n",
      "29 Train Loss 1.9694123 Test MSE 0.1780289880941266 Test RE 0.2016756298483779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 1.7134628 Test MSE 0.1643691679957108 Test RE 0.1937841439161659\n",
      "31 Train Loss 1.2033408 Test MSE 0.07635054692405407 Test RE 0.13207302848049915\n",
      "32 Train Loss 0.97690344 Test MSE 0.08360827871728779 Test RE 0.13820784698062322\n",
      "33 Train Loss 0.86648047 Test MSE 0.0600126240415156 Test RE 0.11709257819655775\n",
      "34 Train Loss 0.7369219 Test MSE 0.061735752150219064 Test RE 0.11876170724656623\n",
      "35 Train Loss 0.61952335 Test MSE 0.04843302791989558 Test RE 0.10519106951677008\n",
      "36 Train Loss 0.56027627 Test MSE 0.039659659330537174 Test RE 0.09518807628156846\n",
      "37 Train Loss 0.4982636 Test MSE 0.028354138912558807 Test RE 0.08048524893662601\n",
      "38 Train Loss 0.4534026 Test MSE 0.024962263517328765 Test RE 0.07551792390141028\n",
      "39 Train Loss 0.3449606 Test MSE 0.016845942829896064 Test RE 0.0620377047453187\n",
      "40 Train Loss 0.31969982 Test MSE 0.016873914068337055 Test RE 0.06208918751863238\n",
      "41 Train Loss 0.30402443 Test MSE 0.015317480273882616 Test RE 0.05915639840240068\n",
      "42 Train Loss 0.2724471 Test MSE 0.015167892387676025 Test RE 0.058866834086763783\n",
      "43 Train Loss 0.26151332 Test MSE 0.014834212602384657 Test RE 0.058215724916580856\n",
      "44 Train Loss 0.24783224 Test MSE 0.012193468789428223 Test RE 0.05278028072241713\n",
      "45 Train Loss 0.20688394 Test MSE 0.011596612280162056 Test RE 0.051472306412859645\n",
      "46 Train Loss 0.19017254 Test MSE 0.012830540062202026 Test RE 0.05414153054281361\n",
      "47 Train Loss 0.1372122 Test MSE 0.010411899211933697 Test RE 0.048772277708868744\n",
      "48 Train Loss 0.12137238 Test MSE 0.009032347270164205 Test RE 0.04542640553313051\n",
      "49 Train Loss 0.10480954 Test MSE 0.006788472969393415 Test RE 0.03938166801695664\n",
      "50 Train Loss 0.100765735 Test MSE 0.007345574248538469 Test RE 0.04096575249165563\n",
      "51 Train Loss 0.09684574 Test MSE 0.007374511025708196 Test RE 0.041046362370657084\n",
      "52 Train Loss 0.08969965 Test MSE 0.0066126499874388685 Test RE 0.03886832524290587\n",
      "53 Train Loss 0.08831795 Test MSE 0.006074232690973691 Test RE 0.037252358407541826\n",
      "54 Train Loss 0.08267778 Test MSE 0.005611027015596791 Test RE 0.03580380969884977\n",
      "55 Train Loss 0.078412816 Test MSE 0.005530699452146617 Test RE 0.03554660184124145\n",
      "56 Train Loss 0.073216155 Test MSE 0.0049285900276137325 Test RE 0.033555939851591665\n",
      "57 Train Loss 0.07078389 Test MSE 0.005264953450311724 Test RE 0.034682095371506134\n",
      "58 Train Loss 0.06990703 Test MSE 0.005153754859363746 Test RE 0.03431388875264066\n",
      "59 Train Loss 0.06604946 Test MSE 0.004400534502932454 Test RE 0.031707410519673934\n",
      "60 Train Loss 0.061362784 Test MSE 0.004238787757637754 Test RE 0.03111923383256201\n",
      "61 Train Loss 0.0587449 Test MSE 0.004091159885040488 Test RE 0.030572523425827735\n",
      "62 Train Loss 0.05813376 Test MSE 0.003919603633174322 Test RE 0.029924653891397836\n",
      "63 Train Loss 0.056673758 Test MSE 0.0037197015177884425 Test RE 0.029151580535930983\n",
      "64 Train Loss 0.0554434 Test MSE 0.0037252973359941455 Test RE 0.029173499719429025\n",
      "65 Train Loss 0.05479975 Test MSE 0.003718493871969426 Test RE 0.02914684794622431\n",
      "66 Train Loss 0.052098814 Test MSE 0.003720806389474165 Test RE 0.0291559096957263\n",
      "67 Train Loss 0.05050478 Test MSE 0.0036827948445460803 Test RE 0.029006599829909652\n",
      "68 Train Loss 0.049438402 Test MSE 0.003788124240124959 Test RE 0.0294184757760044\n",
      "69 Train Loss 0.04773526 Test MSE 0.003747916710471807 Test RE 0.029261933957771404\n",
      "70 Train Loss 0.047308035 Test MSE 0.0033823178475713765 Test RE 0.027798109985531155\n",
      "71 Train Loss 0.04658075 Test MSE 0.003468454057984488 Test RE 0.028149846658904944\n",
      "72 Train Loss 0.042321336 Test MSE 0.00317922235061692 Test RE 0.02695060455806736\n",
      "73 Train Loss 0.040147036 Test MSE 0.002929846894343334 Test RE 0.025872031018193766\n",
      "74 Train Loss 0.0371631 Test MSE 0.002518995111839735 Test RE 0.023989529074486756\n",
      "75 Train Loss 0.036327913 Test MSE 0.002548505157367323 Test RE 0.02412963867433887\n",
      "76 Train Loss 0.03564031 Test MSE 0.0023126334571051178 Test RE 0.022985897325685987\n",
      "77 Train Loss 0.034848448 Test MSE 0.0024914329381584637 Test RE 0.02385792456971191\n",
      "78 Train Loss 0.033622243 Test MSE 0.0026245229558962383 Test RE 0.024486868453655622\n",
      "79 Train Loss 0.032003075 Test MSE 0.002662113466005973 Test RE 0.024661605224061234\n",
      "80 Train Loss 0.031189483 Test MSE 0.002329644842738361 Test RE 0.023070282838699024\n",
      "81 Train Loss 0.030851066 Test MSE 0.0024354536302717885 Test RE 0.02358837334227126\n",
      "82 Train Loss 0.030557642 Test MSE 0.002487839107292777 Test RE 0.02384071112465712\n",
      "83 Train Loss 0.030119477 Test MSE 0.0027714950873905446 Test RE 0.025163156393928743\n",
      "84 Train Loss 0.029310718 Test MSE 0.002630798377304746 Test RE 0.024516125898630226\n",
      "85 Train Loss 0.028252792 Test MSE 0.002876486296071517 Test RE 0.02563534785719269\n",
      "86 Train Loss 0.0276382 Test MSE 0.0028578845249107605 Test RE 0.025552323591304396\n",
      "87 Train Loss 0.02697545 Test MSE 0.0025416368456369722 Test RE 0.024097101621672425\n",
      "88 Train Loss 0.026334874 Test MSE 0.0023553896247312535 Test RE 0.02319740683152724\n",
      "89 Train Loss 0.02537946 Test MSE 0.002437146683464587 Test RE 0.02359657087723517\n",
      "90 Train Loss 0.024795119 Test MSE 0.00261825121603215 Test RE 0.024457593204420956\n",
      "91 Train Loss 0.024452295 Test MSE 0.002576486113366262 Test RE 0.024261741061069837\n",
      "92 Train Loss 0.024103746 Test MSE 0.0025886493429512466 Test RE 0.024318941769827757\n",
      "93 Train Loss 0.023597844 Test MSE 0.0024303533312279232 Test RE 0.02356366114711204\n",
      "94 Train Loss 0.023142863 Test MSE 0.0023070003020429298 Test RE 0.02295788552186947\n",
      "95 Train Loss 0.022923362 Test MSE 0.002271960568739956 Test RE 0.022782871208983667\n",
      "96 Train Loss 0.022811607 Test MSE 0.002212362792019596 Test RE 0.022482066763833644\n",
      "97 Train Loss 0.022693135 Test MSE 0.002346929269702605 Test RE 0.02315570781740418\n",
      "98 Train Loss 0.022067437 Test MSE 0.0020748881037553697 Test RE 0.021772354685075837\n",
      "99 Train Loss 0.021337057 Test MSE 0.002561570664697163 Test RE 0.02419141271693013\n",
      "Training time: 75.66\n",
      "KG_stan_tune13\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 58.034554 Test MSE 8.45932997877212 Test RE 1.390196028008743\n",
      "1 Train Loss 56.76934 Test MSE 8.513431696216667 Test RE 1.3946344481417219\n",
      "2 Train Loss 47.228783 Test MSE 8.326355682589126 Test RE 1.3792263311390243\n",
      "3 Train Loss 45.318115 Test MSE 8.740965489995473 Test RE 1.4131483738185928\n",
      "4 Train Loss 44.40492 Test MSE 8.441029513619661 Test RE 1.3886914757282083\n",
      "5 Train Loss 44.07242 Test MSE 8.422861369546885 Test RE 1.3871961878973678\n",
      "6 Train Loss 43.7276 Test MSE 8.570043878568612 Test RE 1.3992637493567324\n",
      "7 Train Loss 43.481995 Test MSE 8.56742260763421 Test RE 1.3990497405396998\n",
      "8 Train Loss 43.082127 Test MSE 8.6470418509653 Test RE 1.4055355697972043\n",
      "9 Train Loss 42.51101 Test MSE 8.727521373124263 Test RE 1.4120612031420385\n",
      "10 Train Loss 41.770798 Test MSE 8.6606471423916 Test RE 1.4066408729364854\n",
      "11 Train Loss 40.960316 Test MSE 8.880141266232918 Test RE 1.4243541904133077\n",
      "12 Train Loss 39.921165 Test MSE 9.01704039219493 Test RE 1.4352913510587924\n",
      "13 Train Loss 38.064182 Test MSE 8.447956657248154 Test RE 1.38926117475033\n",
      "14 Train Loss 33.651703 Test MSE 8.390858034967456 Test RE 1.3845582984331757\n",
      "15 Train Loss 31.778019 Test MSE 8.154922112063621 Test RE 1.3649538536402386\n",
      "16 Train Loss 30.959263 Test MSE 8.057947319871394 Test RE 1.3568138627342585\n",
      "17 Train Loss 30.505203 Test MSE 8.10732542622317 Test RE 1.3609647074004714\n",
      "18 Train Loss 29.9684 Test MSE 8.350372354658603 Test RE 1.381214029959387\n",
      "19 Train Loss 29.249186 Test MSE 8.282830044210922 Test RE 1.3756166867885489\n",
      "20 Train Loss 27.533497 Test MSE 8.160128231422116 Test RE 1.3653894788249938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Train Loss 24.805992 Test MSE 7.656525309091695 Test RE 1.3225860007844599\n",
      "22 Train Loss 22.510702 Test MSE 7.426096990727707 Test RE 1.3025319016610422\n",
      "23 Train Loss 20.46108 Test MSE 7.09065747883952 Test RE 1.2727740547185336\n",
      "24 Train Loss 17.411076 Test MSE 6.906946600063862 Test RE 1.2561777868463175\n",
      "25 Train Loss 14.51718 Test MSE 6.746281666786266 Test RE 1.2414816224121423\n",
      "26 Train Loss 11.031489 Test MSE 6.53481945115884 Test RE 1.2218695917883928\n",
      "27 Train Loss 9.182946 Test MSE 6.356856964009986 Test RE 1.2051171862837375\n",
      "28 Train Loss 7.383812 Test MSE 6.069371025586478 Test RE 1.1775514832215965\n",
      "29 Train Loss 6.1386986 Test MSE 6.0097436552117065 Test RE 1.1717528920496987\n",
      "30 Train Loss 5.51868 Test MSE 5.949912411087666 Test RE 1.1659054879284179\n",
      "31 Train Loss 5.139295 Test MSE 5.76843089572767 Test RE 1.1479868343864854\n",
      "32 Train Loss 4.7654333 Test MSE 5.268868076634714 Test RE 1.0971518067874237\n",
      "33 Train Loss 4.4039073 Test MSE 5.007774894644346 Test RE 1.0696223267190217\n",
      "34 Train Loss 4.067176 Test MSE 4.836510201077275 Test RE 1.0511727993219189\n",
      "35 Train Loss 3.6704888 Test MSE 4.810348784952201 Test RE 1.0483259679350565\n",
      "36 Train Loss 3.210057 Test MSE 4.937479872359102 Test RE 1.0620885561338995\n",
      "37 Train Loss 2.8772948 Test MSE 4.955973268104498 Test RE 1.0640757304480886\n",
      "38 Train Loss 2.47706 Test MSE 5.027439837306622 Test RE 1.0717204095043953\n",
      "39 Train Loss 2.264511 Test MSE 5.243839716218268 Test RE 1.094542840459952\n",
      "40 Train Loss 1.9421208 Test MSE 5.5200379702239974 Test RE 1.122998284477678\n",
      "41 Train Loss 1.7089146 Test MSE 5.648739944077743 Test RE 1.1360144376707517\n",
      "42 Train Loss 1.5337167 Test MSE 5.782131825192125 Test RE 1.1493493503458903\n",
      "43 Train Loss 1.4419103 Test MSE 5.86167781431075 Test RE 1.157228263876612\n",
      "44 Train Loss 1.3580645 Test MSE 5.887099555284999 Test RE 1.159734963344115\n",
      "45 Train Loss 1.3061816 Test MSE 5.890797404679726 Test RE 1.1600991369043023\n",
      "46 Train Loss 1.2413617 Test MSE 5.963854712297038 Test RE 1.1672707091936803\n",
      "47 Train Loss 1.1882662 Test MSE 6.05394726546736 Test RE 1.176054307903953\n",
      "48 Train Loss 1.1514479 Test MSE 6.073851872994498 Test RE 1.1779860797381443\n",
      "49 Train Loss 1.114337 Test MSE 6.094714575163805 Test RE 1.180007441618093\n",
      "50 Train Loss 1.0794297 Test MSE 6.103419314989741 Test RE 1.1808498102518972\n",
      "51 Train Loss 1.0404135 Test MSE 6.1788132451898194 Test RE 1.188120788292978\n",
      "52 Train Loss 1.0028558 Test MSE 6.197579067506332 Test RE 1.1899236555589745\n",
      "53 Train Loss 0.9655075 Test MSE 6.25574546809937 Test RE 1.1954945353039705\n",
      "54 Train Loss 0.9428023 Test MSE 6.305517265411723 Test RE 1.200240894359197\n",
      "55 Train Loss 0.9148632 Test MSE 6.302247850725147 Test RE 1.1999296911831263\n",
      "56 Train Loss 0.88740647 Test MSE 6.351252741585114 Test RE 1.2045858518534778\n",
      "57 Train Loss 0.8672391 Test MSE 6.336374330750082 Test RE 1.20317409637653\n",
      "58 Train Loss 0.84795403 Test MSE 6.3976205675876034 Test RE 1.2089749431231236\n",
      "59 Train Loss 0.83299494 Test MSE 6.411731592662611 Test RE 1.2103075072235798\n",
      "60 Train Loss 0.81714857 Test MSE 6.414991747141022 Test RE 1.2106151688852056\n",
      "61 Train Loss 0.80004627 Test MSE 6.399813650842059 Test RE 1.209182141681747\n",
      "62 Train Loss 0.785393 Test MSE 6.410012010678021 Test RE 1.2101451982968676\n",
      "63 Train Loss 0.77125156 Test MSE 6.453418200736381 Test RE 1.2142356093280111\n",
      "64 Train Loss 0.7589245 Test MSE 6.494954831310061 Test RE 1.2181369806182\n",
      "65 Train Loss 0.7440164 Test MSE 6.481494163703082 Test RE 1.2168740433214735\n",
      "66 Train Loss 0.7292788 Test MSE 6.543466353488445 Test RE 1.222677716203093\n",
      "67 Train Loss 0.71672577 Test MSE 6.573931791403438 Test RE 1.225520716663891\n",
      "68 Train Loss 0.70401853 Test MSE 6.6029785264556295 Test RE 1.2282251971645788\n",
      "69 Train Loss 0.6903591 Test MSE 6.615293403200861 Test RE 1.2293700135535177\n",
      "70 Train Loss 0.67984384 Test MSE 6.665375750274549 Test RE 1.2340148297104347\n",
      "71 Train Loss 0.6709666 Test MSE 6.656518377212685 Test RE 1.2331946386441748\n",
      "72 Train Loss 0.6628476 Test MSE 6.698290551778707 Test RE 1.237057968927772\n",
      "73 Train Loss 0.654422 Test MSE 6.711954786681916 Test RE 1.2383190995657143\n",
      "74 Train Loss 0.64575684 Test MSE 6.71848569806141 Test RE 1.2389214118733667\n",
      "75 Train Loss 0.64016706 Test MSE 6.748830684646022 Test RE 1.2417161412268225\n",
      "76 Train Loss 0.633187 Test MSE 6.7502895657122775 Test RE 1.2418503436068626\n",
      "77 Train Loss 0.6247463 Test MSE 6.775142037758501 Test RE 1.2441342971897507\n",
      "78 Train Loss 0.616707 Test MSE 6.793207049093315 Test RE 1.245791851979702\n",
      "79 Train Loss 0.61086756 Test MSE 6.811502100516575 Test RE 1.2474682693971018\n",
      "80 Train Loss 0.60494226 Test MSE 6.822979820518654 Test RE 1.2485188500692304\n",
      "81 Train Loss 0.60076517 Test MSE 6.837843640266786 Test RE 1.2498780555505862\n",
      "82 Train Loss 0.5966768 Test MSE 6.849476522354414 Test RE 1.2509407813274278\n",
      "83 Train Loss 0.59224683 Test MSE 6.873682253973458 Test RE 1.2531492152069423\n",
      "84 Train Loss 0.5891966 Test MSE 6.874764603242111 Test RE 1.2532478735167978\n",
      "85 Train Loss 0.58529127 Test MSE 6.873638967448159 Test RE 1.2531452693916862\n",
      "86 Train Loss 0.58306354 Test MSE 6.879492027547015 Test RE 1.2536786967254565\n",
      "87 Train Loss 0.5792197 Test MSE 6.903471275655722 Test RE 1.2558617155871497\n",
      "88 Train Loss 0.5757996 Test MSE 6.916403221142668 Test RE 1.2570374383476621\n",
      "89 Train Loss 0.5724516 Test MSE 6.914511972671935 Test RE 1.2568655619692548\n",
      "90 Train Loss 0.5683521 Test MSE 6.946170701587207 Test RE 1.2597396132267973\n",
      "91 Train Loss 0.5651949 Test MSE 6.952774816329663 Test RE 1.2603383235668164\n",
      "92 Train Loss 0.56277156 Test MSE 6.967176073842546 Test RE 1.261642915489287\n",
      "93 Train Loss 0.5594392 Test MSE 6.9812635739511295 Test RE 1.2629177806013603\n",
      "94 Train Loss 0.5562873 Test MSE 6.980031357877912 Test RE 1.2628063211036598\n",
      "95 Train Loss 0.55430126 Test MSE 6.978047814562513 Test RE 1.26262688000335\n",
      "96 Train Loss 0.5523592 Test MSE 6.99598920692262 Test RE 1.264249020068597\n",
      "97 Train Loss 0.5506622 Test MSE 6.998992995560154 Test RE 1.2645203990823661\n",
      "98 Train Loss 0.54846543 Test MSE 7.00671467070256 Test RE 1.2652177511241578\n",
      "99 Train Loss 0.54629195 Test MSE 7.007998857148668 Test RE 1.2653336899859202\n",
      "Training time: 75.60\n",
      "KG_stan_tune13\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.888668 Test MSE 8.529867748692816 Test RE 1.3959800413762595\n",
      "1 Train Loss 56.582237 Test MSE 8.290761395396 Test RE 1.3762751506439899\n",
      "2 Train Loss 48.395092 Test MSE 8.639419954601147 Test RE 1.4049159817130685\n",
      "3 Train Loss 46.53614 Test MSE 8.535736501925443 Test RE 1.396460192647032\n",
      "4 Train Loss 46.01371 Test MSE 8.520862660008014 Test RE 1.3952429699457034\n",
      "5 Train Loss 45.56996 Test MSE 8.453165432327612 Test RE 1.3896893986505172\n",
      "6 Train Loss 44.623497 Test MSE 8.390833790193971 Test RE 1.3845562981415234\n",
      "7 Train Loss 44.28295 Test MSE 8.326719725349605 Test RE 1.379256481897173\n",
      "8 Train Loss 43.45625 Test MSE 8.661362551050203 Test RE 1.4066989691885694\n",
      "9 Train Loss 42.40748 Test MSE 8.701219759923905 Test RE 1.4099318751518233\n",
      "10 Train Loss 39.34182 Test MSE 8.570333537155564 Test RE 1.3992873959880372\n",
      "11 Train Loss 36.31491 Test MSE 8.443945724603639 Test RE 1.3889313379164734\n",
      "12 Train Loss 31.70736 Test MSE 8.03396883040733 Test RE 1.3547935847854944\n",
      "13 Train Loss 30.467567 Test MSE 8.295768716524227 Test RE 1.3766906982082276\n",
      "14 Train Loss 29.392437 Test MSE 8.183861200943312 Test RE 1.367373590999744\n",
      "15 Train Loss 28.438946 Test MSE 7.796530598982695 Test RE 1.3346234585371617\n",
      "16 Train Loss 26.508568 Test MSE 7.540275476581026 Test RE 1.3125071157858832\n",
      "17 Train Loss 24.56759 Test MSE 7.756481956264542 Test RE 1.3311912476611472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Train Loss 22.491352 Test MSE 7.147131572901344 Test RE 1.2778325565590005\n",
      "19 Train Loss 21.310322 Test MSE 7.288832254460762 Test RE 1.2904376868699408\n",
      "20 Train Loss 20.391315 Test MSE 7.247317065536372 Test RE 1.286757449456218\n",
      "21 Train Loss 19.777641 Test MSE 7.331839164030619 Test RE 1.2942391266005244\n",
      "22 Train Loss 19.459953 Test MSE 7.478494597952995 Test RE 1.3071190749675932\n",
      "23 Train Loss 19.001404 Test MSE 7.601195881199977 Test RE 1.3177985412226223\n",
      "24 Train Loss 18.219444 Test MSE 7.85242319833767 Test RE 1.3393988107411923\n",
      "25 Train Loss 16.300169 Test MSE 7.663894591961914 Test RE 1.323222331618588\n",
      "26 Train Loss 11.838415 Test MSE 7.294807125058938 Test RE 1.2909664834249341\n",
      "27 Train Loss 9.277076 Test MSE 6.370135829119766 Test RE 1.206375216816532\n",
      "28 Train Loss 8.00301 Test MSE 6.059891977755808 Test RE 1.1766315832536272\n",
      "29 Train Loss 6.4142933 Test MSE 5.9643631909880845 Test RE 1.1673204689262966\n",
      "30 Train Loss 4.28625 Test MSE 4.986525920136941 Test RE 1.0673506052893607\n",
      "31 Train Loss 3.4408333 Test MSE 4.531142278482284 Test RE 1.0174472678908126\n",
      "32 Train Loss 2.8700507 Test MSE 4.664312241091717 Test RE 1.032290351251322\n",
      "33 Train Loss 2.4190478 Test MSE 4.144270759273755 Test RE 0.9730431979797481\n",
      "34 Train Loss 2.1346843 Test MSE 3.9806447497167414 Test RE 0.9536406844318199\n",
      "35 Train Loss 1.7993085 Test MSE 3.5842333228146197 Test RE 0.9049116863195034\n",
      "36 Train Loss 1.5841051 Test MSE 3.1621158959491096 Test RE 0.8499569941388913\n",
      "37 Train Loss 1.4293299 Test MSE 3.0419374544801614 Test RE 0.8336489363682382\n",
      "38 Train Loss 1.3344765 Test MSE 2.9565389195250398 Test RE 0.8218638163339761\n",
      "39 Train Loss 1.2365973 Test MSE 2.8988232407389507 Test RE 0.8138023273686019\n",
      "40 Train Loss 1.1996282 Test MSE 2.8679562343558707 Test RE 0.8094580008678993\n",
      "41 Train Loss 1.1595616 Test MSE 2.8593846926528155 Test RE 0.8082474707236166\n",
      "42 Train Loss 1.1172602 Test MSE 2.8230472610759785 Test RE 0.8030953932210275\n",
      "43 Train Loss 1.0826643 Test MSE 2.792533082996688 Test RE 0.7987432916836467\n",
      "44 Train Loss 1.0443465 Test MSE 2.817641809093984 Test RE 0.8023261582045729\n",
      "45 Train Loss 1.0086625 Test MSE 2.795574497599479 Test RE 0.7991781385313302\n",
      "46 Train Loss 0.97699213 Test MSE 2.7852505366710023 Test RE 0.7977011048562549\n",
      "47 Train Loss 0.9503006 Test MSE 2.7987793150927267 Test RE 0.7996360920686486\n",
      "48 Train Loss 0.9204546 Test MSE 2.7477904587984385 Test RE 0.792318626617542\n",
      "49 Train Loss 0.8968105 Test MSE 2.7531875563122665 Test RE 0.7930963648073909\n",
      "50 Train Loss 0.8709966 Test MSE 2.7834970006111366 Test RE 0.7974499572724413\n",
      "51 Train Loss 0.8528688 Test MSE 2.781976377777905 Test RE 0.7972321042853783\n",
      "52 Train Loss 0.82484376 Test MSE 2.795661715803882 Test RE 0.7991906050813453\n",
      "53 Train Loss 0.8079295 Test MSE 2.799405162101441 Test RE 0.799725492093827\n",
      "54 Train Loss 0.7913474 Test MSE 2.7907965828687122 Test RE 0.7984949090362824\n",
      "55 Train Loss 0.77769107 Test MSE 2.7701784545279926 Test RE 0.7955398403862493\n",
      "56 Train Loss 0.7636732 Test MSE 2.7685175583952946 Test RE 0.7953013165551402\n",
      "57 Train Loss 0.75240016 Test MSE 2.763354989487824 Test RE 0.7945594549610505\n",
      "58 Train Loss 0.73929846 Test MSE 2.736766548459322 Test RE 0.7907276705889908\n",
      "59 Train Loss 0.7303042 Test MSE 2.7530984811974677 Test RE 0.7930835350019906\n",
      "60 Train Loss 0.7198123 Test MSE 2.771779659450693 Test RE 0.7957697241844575\n",
      "61 Train Loss 0.7122737 Test MSE 2.782537080563962 Test RE 0.7973124406506147\n",
      "62 Train Loss 0.70151055 Test MSE 2.779980735409964 Test RE 0.7969461069630269\n",
      "63 Train Loss 0.68841004 Test MSE 2.770337418397509 Test RE 0.7955626656805915\n",
      "64 Train Loss 0.68044853 Test MSE 2.7815761432940636 Test RE 0.797174754543052\n",
      "65 Train Loss 0.6727784 Test MSE 2.796232440435356 Test RE 0.7992721769118435\n",
      "66 Train Loss 0.6663111 Test MSE 2.7811158317281675 Test RE 0.797108791232483\n",
      "67 Train Loss 0.65820086 Test MSE 2.8070483734800513 Test RE 0.8008164925199579\n",
      "68 Train Loss 0.64913446 Test MSE 2.8038039982140903 Test RE 0.800353568472721\n",
      "69 Train Loss 0.6413576 Test MSE 2.8207665868203757 Test RE 0.8027709266261116\n",
      "70 Train Loss 0.6341067 Test MSE 2.8229830429175093 Test RE 0.8030862588361313\n",
      "71 Train Loss 0.62284136 Test MSE 2.8482160523769964 Test RE 0.8066674354570817\n",
      "72 Train Loss 0.6113229 Test MSE 2.8802790678087824 Test RE 0.8111951480735052\n",
      "73 Train Loss 0.600262 Test MSE 2.8899324361762537 Test RE 0.812553387169563\n",
      "74 Train Loss 0.5899768 Test MSE 2.8933253262708 Test RE 0.8130302314724355\n",
      "75 Train Loss 0.5818124 Test MSE 2.905291262943826 Test RE 0.8147097229209893\n",
      "76 Train Loss 0.5736673 Test MSE 2.910554138729479 Test RE 0.8154473040556234\n",
      "77 Train Loss 0.56523615 Test MSE 2.938428969037792 Test RE 0.8193428321798434\n",
      "78 Train Loss 0.5516943 Test MSE 2.933041771175294 Test RE 0.8185914124666938\n",
      "79 Train Loss 0.542169 Test MSE 2.97299113572343 Test RE 0.8241473517465827\n",
      "80 Train Loss 0.5334671 Test MSE 2.977682409704994 Test RE 0.8247973329999221\n",
      "81 Train Loss 0.5268167 Test MSE 2.99121108430893 Test RE 0.8266688840492171\n",
      "82 Train Loss 0.51895285 Test MSE 3.0230384916215067 Test RE 0.8310552526265227\n",
      "83 Train Loss 0.5099034 Test MSE 3.0765781817703846 Test RE 0.8383821789946717\n",
      "84 Train Loss 0.5024412 Test MSE 3.0798875516472233 Test RE 0.838832967314097\n",
      "85 Train Loss 0.49295124 Test MSE 3.078167171864504 Test RE 0.838598654723894\n",
      "86 Train Loss 0.4843039 Test MSE 3.103107127848493 Test RE 0.8419890522365695\n",
      "87 Train Loss 0.47716033 Test MSE 3.1139056847708124 Test RE 0.8434528061424178\n",
      "88 Train Loss 0.46928728 Test MSE 3.129028134558901 Test RE 0.8454984082695989\n",
      "89 Train Loss 0.46319827 Test MSE 3.138391151505679 Test RE 0.8467624593326479\n",
      "90 Train Loss 0.45656818 Test MSE 3.1702766766456953 Test RE 0.8510530708356192\n",
      "91 Train Loss 0.45127696 Test MSE 3.1774775560233732 Test RE 0.8520190519072897\n",
      "92 Train Loss 0.44398326 Test MSE 3.178672179914095 Test RE 0.8521792020021748\n",
      "93 Train Loss 0.43844607 Test MSE 3.2046785320118922 Test RE 0.855658158904303\n",
      "94 Train Loss 0.4310534 Test MSE 3.2262604471888845 Test RE 0.8585345402317242\n",
      "95 Train Loss 0.42458966 Test MSE 3.2309878247663226 Test RE 0.8591633070867605\n",
      "96 Train Loss 0.41744965 Test MSE 3.2421130766038857 Test RE 0.8606412133346331\n",
      "97 Train Loss 0.4127673 Test MSE 3.2737034209743796 Test RE 0.8648239861448943\n",
      "98 Train Loss 0.4066001 Test MSE 3.266542393686286 Test RE 0.8638775933605235\n",
      "99 Train Loss 0.40086967 Test MSE 3.27024256216103 Test RE 0.8643667325724533\n",
      "Training time: 76.84\n",
      "KG_stan_tune13\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.582024 Test MSE 8.560710461716925 Test RE 1.3985015905051932\n",
      "1 Train Loss 54.348732 Test MSE 7.888832181618696 Test RE 1.342500385273476\n",
      "2 Train Loss 47.037918 Test MSE 7.788689021081599 Test RE 1.3339521223244946\n",
      "3 Train Loss 44.755913 Test MSE 8.180595154071616 Test RE 1.3671007154104375\n",
      "4 Train Loss 43.864887 Test MSE 8.158035712367523 Test RE 1.3652144027350646\n",
      "5 Train Loss 43.62716 Test MSE 8.030101714675428 Test RE 1.354467483557863\n",
      "6 Train Loss 43.55535 Test MSE 8.079031846497543 Test RE 1.3585878311815531\n",
      "7 Train Loss 43.35064 Test MSE 8.093571808799924 Test RE 1.3598098177016917\n",
      "8 Train Loss 43.29165 Test MSE 8.11649345798787 Test RE 1.36173400193044\n",
      "9 Train Loss 43.25126 Test MSE 8.1353123312958 Test RE 1.3633117437673203\n",
      "10 Train Loss 42.760414 Test MSE 7.954049934325777 Test RE 1.3480382547650458\n",
      "11 Train Loss 42.118694 Test MSE 8.107971925437978 Test RE 1.3610189697514026\n",
      "12 Train Loss 41.81266 Test MSE 8.18057186511223 Test RE 1.3670987694410368\n",
      "13 Train Loss 40.96705 Test MSE 8.114309225048808 Test RE 1.3615507611990614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Train Loss 40.270123 Test MSE 7.8884890284993965 Test RE 1.3424711865154\n",
      "15 Train Loss 39.46447 Test MSE 7.906182693785388 Test RE 1.3439759063163992\n",
      "16 Train Loss 38.079117 Test MSE 7.8013115231477945 Test RE 1.335032599216971\n",
      "17 Train Loss 37.25612 Test MSE 7.328685025486862 Test RE 1.2939607074647377\n",
      "18 Train Loss 35.70682 Test MSE 6.568790070698691 Test RE 1.2250413598616443\n",
      "19 Train Loss 34.825657 Test MSE 5.976833666318136 Test RE 1.1685401666132293\n",
      "20 Train Loss 32.950035 Test MSE 5.607081308449976 Test RE 1.1318177151602304\n",
      "21 Train Loss 30.283684 Test MSE 5.817278448697924 Test RE 1.152837211717615\n",
      "22 Train Loss 25.955093 Test MSE 3.7754570427647742 Test RE 0.9287371691919322\n",
      "23 Train Loss 22.210926 Test MSE 3.5756905392642024 Test RE 0.9038326443414242\n",
      "24 Train Loss 16.920746 Test MSE 3.003097513757476 Test RE 0.8283097577113092\n",
      "25 Train Loss 13.358459 Test MSE 2.012343033415213 Test RE 0.6780458583743325\n",
      "26 Train Loss 11.024813 Test MSE 1.6595220948747722 Test RE 0.6157431367533488\n",
      "27 Train Loss 10.270741 Test MSE 2.148166060460692 Test RE 0.700554594453004\n",
      "28 Train Loss 9.326587 Test MSE 1.8944595070070944 Test RE 0.6578861198995416\n",
      "29 Train Loss 8.944684 Test MSE 1.8991254981995296 Test RE 0.658695797545603\n",
      "30 Train Loss 8.589877 Test MSE 1.8183503242195507 Test RE 0.6445354953067531\n",
      "31 Train Loss 8.322269 Test MSE 1.7868823468372423 Test RE 0.6389340593002502\n",
      "32 Train Loss 8.197102 Test MSE 1.7715452431791272 Test RE 0.6361861122676195\n",
      "33 Train Loss 7.951915 Test MSE 1.8215894997374535 Test RE 0.6451093216537482\n",
      "34 Train Loss 7.478115 Test MSE 1.8953799813636991 Test RE 0.6580459263669665\n",
      "35 Train Loss 7.2467766 Test MSE 2.008913402500356 Test RE 0.677467816097874\n",
      "36 Train Loss 6.5609384 Test MSE 2.025222382113896 Test RE 0.680212203920157\n",
      "37 Train Loss 6.233154 Test MSE 1.9873982527004086 Test RE 0.6738302630514417\n",
      "38 Train Loss 5.953794 Test MSE 2.025409435274796 Test RE 0.6802436160026406\n",
      "39 Train Loss 5.7133126 Test MSE 2.016701072901875 Test RE 0.6787796677833421\n",
      "40 Train Loss 5.5325336 Test MSE 2.0159893031410543 Test RE 0.6786598737581083\n",
      "41 Train Loss 5.4202023 Test MSE 2.0636350155880625 Test RE 0.6866327350185093\n",
      "42 Train Loss 5.2790947 Test MSE 2.034636400008731 Test RE 0.6817913158340622\n",
      "43 Train Loss 5.1799984 Test MSE 2.055392428945253 Test RE 0.6852600861449858\n",
      "44 Train Loss 5.125059 Test MSE 2.0507203423654783 Test RE 0.6844808150301991\n",
      "45 Train Loss 5.0308733 Test MSE 2.086353517117015 Test RE 0.6904019501310494\n",
      "46 Train Loss 4.990945 Test MSE 2.0942041590673695 Test RE 0.6916996710780504\n",
      "47 Train Loss 4.9512844 Test MSE 2.0862990878695284 Test RE 0.6903929443936732\n",
      "48 Train Loss 4.905853 Test MSE 2.0917358388067857 Test RE 0.6912919172096168\n",
      "49 Train Loss 4.8744326 Test MSE 2.096195254102759 Test RE 0.6920284147138958\n",
      "50 Train Loss 4.81999 Test MSE 2.118836884308164 Test RE 0.695755779317769\n",
      "51 Train Loss 4.76964 Test MSE 2.1288635932258417 Test RE 0.697400055740675\n",
      "52 Train Loss 4.7377462 Test MSE 2.1339214821183896 Test RE 0.6982280278459758\n",
      "53 Train Loss 4.7090535 Test MSE 2.1585085570242573 Test RE 0.7022390041402689\n",
      "54 Train Loss 4.6757107 Test MSE 2.142893357351132 Test RE 0.6996943057925042\n",
      "55 Train Loss 4.6640415 Test MSE 2.147668675642716 Test RE 0.7004734868054432\n",
      "56 Train Loss 4.648158 Test MSE 2.17320865648069 Test RE 0.7046261772418858\n",
      "57 Train Loss 4.6341386 Test MSE 2.160752124764207 Test RE 0.7026038652341263\n",
      "58 Train Loss 4.605588 Test MSE 2.1468109591422606 Test RE 0.7003335984528205\n",
      "59 Train Loss 4.5929823 Test MSE 2.1474409431371657 Test RE 0.7004363477408775\n",
      "60 Train Loss 4.5730166 Test MSE 2.1452911649173627 Test RE 0.7000856606000458\n",
      "61 Train Loss 4.5532107 Test MSE 2.150485313438975 Test RE 0.7009326669528256\n",
      "62 Train Loss 4.5180407 Test MSE 2.1145202849781186 Test RE 0.6950467039447386\n",
      "63 Train Loss 4.4451714 Test MSE 2.1041195970019766 Test RE 0.6933352341728664\n",
      "64 Train Loss 4.1727643 Test MSE 2.036740792209736 Test RE 0.6821438076928141\n",
      "65 Train Loss 3.4781203 Test MSE 1.8586249170327327 Test RE 0.6516343025072318\n",
      "66 Train Loss 3.078504 Test MSE 1.5838023208146654 Test RE 0.6015317397685971\n",
      "67 Train Loss 2.6992183 Test MSE 1.1695516795766552 Test RE 0.5169133740355036\n",
      "68 Train Loss 1.6420344 Test MSE 0.5125873590401206 Test RE 0.3422094562370547\n",
      "69 Train Loss 1.0207427 Test MSE 0.18400105952776027 Test RE 0.20503038262937573\n",
      "70 Train Loss 0.6282965 Test MSE 0.07881628610889577 Test RE 0.13418873030737719\n",
      "71 Train Loss 0.4636916 Test MSE 0.06480312149030523 Test RE 0.12167630790498704\n",
      "72 Train Loss 0.34751508 Test MSE 0.0498666066734118 Test RE 0.10673650263051868\n",
      "73 Train Loss 0.24220741 Test MSE 0.032251712858397896 Test RE 0.08583896105854762\n",
      "74 Train Loss 0.20091188 Test MSE 0.024287264861802167 Test RE 0.07448989545877356\n",
      "75 Train Loss 0.16682906 Test MSE 0.016996518522916986 Test RE 0.062314346695187116\n",
      "76 Train Loss 0.1469398 Test MSE 0.018043991709662886 Test RE 0.06420581598147959\n",
      "77 Train Loss 0.13096616 Test MSE 0.015600267207396013 Test RE 0.059699965323420374\n",
      "78 Train Loss 0.11581444 Test MSE 0.016705167756986654 Test RE 0.06177794830215414\n",
      "79 Train Loss 0.10632399 Test MSE 0.015107117944370385 Test RE 0.05874878242071944\n",
      "80 Train Loss 0.098290876 Test MSE 0.016183889458957483 Test RE 0.06080643078959726\n",
      "81 Train Loss 0.08251941 Test MSE 0.014482570986448976 Test RE 0.057521591456562465\n",
      "82 Train Loss 0.07480137 Test MSE 0.010979964708890995 Test RE 0.05008509852071142\n",
      "83 Train Loss 0.06727082 Test MSE 0.008037256545377024 Test RE 0.04285110009119025\n",
      "84 Train Loss 0.06094598 Test MSE 0.005437696497553249 Test RE 0.035246463034551874\n",
      "85 Train Loss 0.054274656 Test MSE 0.005887478715569928 Test RE 0.03667522064484231\n",
      "86 Train Loss 0.0471919 Test MSE 0.005150150233690591 Test RE 0.03430188678875253\n",
      "87 Train Loss 0.044921603 Test MSE 0.004910506621383794 Test RE 0.033494323515383305\n",
      "88 Train Loss 0.043045096 Test MSE 0.004810790887592306 Test RE 0.033152501251028955\n",
      "89 Train Loss 0.03638537 Test MSE 0.00411923183224235 Test RE 0.030677232494440727\n",
      "90 Train Loss 0.030857906 Test MSE 0.002046778952221558 Test RE 0.02162437337403029\n",
      "91 Train Loss 0.029230118 Test MSE 0.0018299376868443227 Test RE 0.02044684058314556\n",
      "92 Train Loss 0.027155165 Test MSE 0.001617535567636816 Test RE 0.019223611447117372\n",
      "93 Train Loss 0.024723478 Test MSE 0.0015686148732611531 Test RE 0.01893068044628247\n",
      "94 Train Loss 0.023832047 Test MSE 0.001573361727427005 Test RE 0.018959302289771992\n",
      "95 Train Loss 0.022690292 Test MSE 0.0016385271984006302 Test RE 0.019347946938037063\n",
      "96 Train Loss 0.02009029 Test MSE 0.0015033490276247926 Test RE 0.018532669069715662\n",
      "97 Train Loss 0.018039782 Test MSE 0.0018814711940062763 Test RE 0.02073274695084388\n",
      "98 Train Loss 0.017614307 Test MSE 0.0020405010852287326 Test RE 0.021591184837399986\n",
      "99 Train Loss 0.015719447 Test MSE 0.0017462748908994381 Test RE 0.019973968701516152\n",
      "Training time: 76.80\n",
      "KG_stan_tune13\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 42.71725 Test MSE 10.382271086390828 Test RE 1.5401188715948988\n",
      "1 Train Loss 40.38633 Test MSE 9.227463974918226 Test RE 1.4519419039861594\n",
      "2 Train Loss 39.86827 Test MSE 9.237161934508505 Test RE 1.4527046908246617\n",
      "3 Train Loss 39.434353 Test MSE 8.999527596432644 Test RE 1.4338968701781107\n",
      "4 Train Loss 38.438995 Test MSE 8.952895407964862 Test RE 1.4301770864534842\n",
      "5 Train Loss 37.603912 Test MSE 8.981529864381862 Test RE 1.4324623611554852\n",
      "6 Train Loss 36.76898 Test MSE 8.735743748343095 Test RE 1.412726212324717\n",
      "7 Train Loss 36.40468 Test MSE 8.84718664186527 Test RE 1.4217088109558567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 35.993874 Test MSE 8.824847350316158 Test RE 1.4199127574264219\n",
      "9 Train Loss 35.15723 Test MSE 8.71306924472948 Test RE 1.4108915844050498\n",
      "10 Train Loss 35.028225 Test MSE 8.73732600010881 Test RE 1.4128541457555415\n",
      "11 Train Loss 34.946156 Test MSE 8.848333144397527 Test RE 1.4218009272417347\n",
      "12 Train Loss 34.842705 Test MSE 8.950475817893846 Test RE 1.4299838151175095\n",
      "13 Train Loss 34.684113 Test MSE 8.934245646193213 Test RE 1.4286867101246885\n",
      "14 Train Loss 34.53055 Test MSE 8.991665605047753 Test RE 1.433270406850894\n",
      "15 Train Loss 34.509865 Test MSE 8.985276048702545 Test RE 1.4327610690966257\n",
      "16 Train Loss 34.352383 Test MSE 8.8691211520516 Test RE 1.4234701155907774\n",
      "17 Train Loss 34.12969 Test MSE 8.782581664785944 Test RE 1.4165084143542015\n",
      "18 Train Loss 33.968975 Test MSE 8.845764017530382 Test RE 1.4215945012353413\n",
      "19 Train Loss 33.847343 Test MSE 8.920931408055582 Test RE 1.427621764747784\n",
      "20 Train Loss 33.700256 Test MSE 9.00723583969749 Test RE 1.434510816857806\n",
      "21 Train Loss 33.5858 Test MSE 9.203890642785561 Test RE 1.4500860854896498\n",
      "22 Train Loss 33.475975 Test MSE 9.146166645992697 Test RE 1.4455316843308372\n",
      "23 Train Loss 33.212944 Test MSE 8.971016603434236 Test RE 1.4316237367531106\n",
      "24 Train Loss 32.5804 Test MSE 8.948727063614138 Test RE 1.4298441123505081\n",
      "25 Train Loss 31.19564 Test MSE 8.458500328393502 Test RE 1.3901278544687181\n",
      "26 Train Loss 29.973637 Test MSE 8.453440498713714 Test RE 1.389712008744579\n",
      "27 Train Loss 29.118876 Test MSE 8.558585663541724 Test RE 1.398328023249885\n",
      "28 Train Loss 27.946083 Test MSE 8.70151783351558 Test RE 1.4099560246314653\n",
      "29 Train Loss 27.809755 Test MSE 8.903774355351983 Test RE 1.4262482775576975\n",
      "30 Train Loss 27.187622 Test MSE 8.564568539156886 Test RE 1.3988166881652\n",
      "31 Train Loss 26.66774 Test MSE 7.965818974654107 Test RE 1.3490351841552781\n",
      "32 Train Loss 25.947422 Test MSE 7.835382199046626 Test RE 1.3379446678377267\n",
      "33 Train Loss 25.399202 Test MSE 7.762648553049978 Test RE 1.3317203076647115\n",
      "34 Train Loss 24.651455 Test MSE 7.465476597533056 Test RE 1.3059809122015233\n",
      "35 Train Loss 23.798527 Test MSE 7.671232848991595 Test RE 1.3238556794668461\n",
      "36 Train Loss 23.19347 Test MSE 7.720954580130786 Test RE 1.3281390899798686\n",
      "37 Train Loss 22.86434 Test MSE 7.447539266969141 Test RE 1.3044110258534223\n",
      "38 Train Loss 22.559818 Test MSE 7.322629359129111 Test RE 1.293425999421035\n",
      "39 Train Loss 22.007692 Test MSE 7.405396473727544 Test RE 1.300715207091359\n",
      "40 Train Loss 21.438599 Test MSE 7.5842301821457205 Test RE 1.316327071269397\n",
      "41 Train Loss 21.281378 Test MSE 7.601907436158378 Test RE 1.3178602199477498\n",
      "42 Train Loss 21.14605 Test MSE 7.486181327325911 Test RE 1.307790660002027\n",
      "43 Train Loss 20.644148 Test MSE 7.607602232023841 Test RE 1.3183537500243387\n",
      "44 Train Loss 20.503777 Test MSE 7.60733888587918 Test RE 1.318330931640085\n",
      "45 Train Loss 20.231941 Test MSE 7.201116448850956 Test RE 1.2826494440340508\n",
      "46 Train Loss 20.102156 Test MSE 6.959699427538225 Test RE 1.2609657839113284\n",
      "47 Train Loss 19.977798 Test MSE 7.338904531700925 Test RE 1.2948625768124056\n",
      "48 Train Loss 19.80788 Test MSE 7.366149748156001 Test RE 1.2972638976828057\n",
      "49 Train Loss 19.488016 Test MSE 7.497435622201463 Test RE 1.3087733194906688\n",
      "50 Train Loss 19.371574 Test MSE 7.570596531898825 Test RE 1.3151434036489762\n",
      "51 Train Loss 19.19276 Test MSE 7.474507558880065 Test RE 1.306770593762365\n",
      "52 Train Loss 19.08664 Test MSE 7.514304407253428 Test RE 1.3102448233922623\n",
      "53 Train Loss 18.735865 Test MSE 7.2900230078259405 Test RE 1.2905430899175478\n",
      "54 Train Loss 18.54233 Test MSE 7.173222853393286 Test RE 1.2801628561176188\n",
      "55 Train Loss 17.974638 Test MSE 5.916773361819528 Test RE 1.1626540998479886\n",
      "56 Train Loss 16.324844 Test MSE 5.688855857652917 Test RE 1.1400411438781213\n",
      "57 Train Loss 14.836644 Test MSE 5.666649078927857 Test RE 1.137813859812817\n",
      "58 Train Loss 14.1668825 Test MSE 5.34240903830702 Test RE 1.1047820985837344\n",
      "59 Train Loss 13.936602 Test MSE 5.34867995805864 Test RE 1.105430305039316\n",
      "60 Train Loss 13.6862545 Test MSE 5.4591406953516435 Test RE 1.116786624639727\n",
      "61 Train Loss 13.584677 Test MSE 5.406104648552338 Test RE 1.1113485428847352\n",
      "62 Train Loss 13.5089245 Test MSE 5.409757527935422 Test RE 1.1117239459622095\n",
      "63 Train Loss 13.41828 Test MSE 5.423449106564706 Test RE 1.1131298904083653\n",
      "64 Train Loss 13.194227 Test MSE 5.349046453839984 Test RE 1.1054681768700043\n",
      "65 Train Loss 12.957756 Test MSE 5.325790546577439 Test RE 1.103062451872553\n",
      "66 Train Loss 12.873206 Test MSE 5.275767207722012 Test RE 1.0978698849192345\n",
      "67 Train Loss 12.645311 Test MSE 5.26187937993813 Test RE 1.0964239269652472\n",
      "68 Train Loss 12.511979 Test MSE 5.352114417006701 Test RE 1.1057851538780268\n",
      "69 Train Loss 12.431897 Test MSE 5.292402573684018 Test RE 1.0995994052256055\n",
      "70 Train Loss 12.292789 Test MSE 5.348685814963911 Test RE 1.10543091027265\n",
      "71 Train Loss 12.222275 Test MSE 5.379687342669028 Test RE 1.1086298766540021\n",
      "72 Train Loss 12.114571 Test MSE 5.379949629606686 Test RE 1.1086569019784007\n",
      "73 Train Loss 12.007271 Test MSE 5.3381344831003625 Test RE 1.1043400323693038\n",
      "74 Train Loss 11.948097 Test MSE 5.300224313009969 Test RE 1.1004116643389528\n",
      "75 Train Loss 11.763921 Test MSE 5.259862610330343 Test RE 1.0962137885133556\n",
      "76 Train Loss 11.60487 Test MSE 5.345507404133684 Test RE 1.1051024150288795\n",
      "77 Train Loss 11.427387 Test MSE 5.352522947538152 Test RE 1.1058273557389342\n",
      "78 Train Loss 11.244905 Test MSE 5.388859620799403 Test RE 1.1095745719741859\n",
      "79 Train Loss 11.140654 Test MSE 5.3699477884736355 Test RE 1.1076258729296689\n",
      "80 Train Loss 10.898291 Test MSE 5.315746819508463 Test RE 1.1020218470692729\n",
      "81 Train Loss 10.789589 Test MSE 5.311206266032806 Test RE 1.1015510893115577\n",
      "82 Train Loss 10.748905 Test MSE 5.35843303784003 Test RE 1.1064376974885082\n",
      "83 Train Loss 10.54741 Test MSE 5.358901895143414 Test RE 1.1064861025020885\n",
      "84 Train Loss 10.463967 Test MSE 5.299564774899865 Test RE 1.100343196858547\n",
      "85 Train Loss 10.411236 Test MSE 5.334323339417874 Test RE 1.1039457420012184\n",
      "86 Train Loss 10.342886 Test MSE 5.388916167242232 Test RE 1.1095803934591495\n",
      "87 Train Loss 10.279405 Test MSE 5.290771625667941 Test RE 1.0994299616098775\n",
      "88 Train Loss 10.249799 Test MSE 5.298681632306573 Test RE 1.1002515100433448\n",
      "89 Train Loss 10.212303 Test MSE 5.289381651054789 Test RE 1.099285532760315\n",
      "90 Train Loss 10.175262 Test MSE 5.289872275363864 Test RE 1.0993365144945157\n",
      "91 Train Loss 10.1573925 Test MSE 5.281833460900711 Test RE 1.0985008872983013\n",
      "92 Train Loss 10.087128 Test MSE 5.309144070930261 Test RE 1.1013372175758518\n",
      "93 Train Loss 10.06092 Test MSE 5.291745562187375 Test RE 1.0995311496588833\n",
      "94 Train Loss 10.002662 Test MSE 5.3486633824630605 Test RE 1.105428592169971\n",
      "95 Train Loss 9.957962 Test MSE 5.331782956282646 Test RE 1.1036828427599383\n",
      "96 Train Loss 9.935997 Test MSE 5.337265078026926 Test RE 1.104250098523871\n",
      "97 Train Loss 9.908877 Test MSE 5.367527231529465 Test RE 1.1073762081468954\n",
      "98 Train Loss 9.871767 Test MSE 5.3723862495990975 Test RE 1.1078773275240845\n",
      "99 Train Loss 9.828394 Test MSE 5.38482539854437 Test RE 1.1091591678980006\n",
      "Training time: 76.23\n",
      "KG_stan_tune13\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.435223 Test MSE 8.611024715570242 Test RE 1.402605308172889\n",
      "1 Train Loss 52.386383 Test MSE 10.276608705264607 Test RE 1.5322617858681464\n",
      "2 Train Loss 46.316414 Test MSE 8.481607307565266 Test RE 1.3920253390414221\n",
      "3 Train Loss 43.811176 Test MSE 8.624410560704394 Test RE 1.4036950603954466\n",
      "4 Train Loss 43.520596 Test MSE 8.454099121645273 Test RE 1.3897661451858276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Train Loss 43.240845 Test MSE 8.476765807381133 Test RE 1.391627981988078\n",
      "6 Train Loss 42.956863 Test MSE 8.44829993973282 Test RE 1.3892894007582612\n",
      "7 Train Loss 42.530067 Test MSE 8.340806697886288 Test RE 1.3804226876864187\n",
      "8 Train Loss 41.53849 Test MSE 8.346447313611515 Test RE 1.3808893762345824\n",
      "9 Train Loss 39.104492 Test MSE 7.7132607790334164 Test RE 1.3274771909377037\n",
      "10 Train Loss 35.43282 Test MSE 7.5146338103447485 Test RE 1.3102735415504536\n",
      "11 Train Loss 34.017143 Test MSE 7.300975123393855 Test RE 1.2915121453265055\n",
      "12 Train Loss 33.383137 Test MSE 7.203043760412367 Test RE 1.282821077122901\n",
      "13 Train Loss 32.563183 Test MSE 7.158050554433338 Test RE 1.2788082840240478\n",
      "14 Train Loss 31.934006 Test MSE 7.201505902616183 Test RE 1.2826841279546064\n",
      "15 Train Loss 31.030151 Test MSE 7.166061981490623 Test RE 1.2795237172408664\n",
      "16 Train Loss 29.798218 Test MSE 7.050295192581041 Test RE 1.2691463667174032\n",
      "17 Train Loss 29.132442 Test MSE 7.006029148795056 Test RE 1.2651558565171637\n",
      "18 Train Loss 28.455143 Test MSE 6.966458968024991 Test RE 1.2615779856851486\n",
      "19 Train Loss 27.97843 Test MSE 6.910101016622387 Test RE 1.2564646035775457\n",
      "20 Train Loss 27.71428 Test MSE 6.729298143880449 Test RE 1.2399179448666684\n",
      "21 Train Loss 27.081703 Test MSE 6.541510422898761 Test RE 1.2224949650926842\n",
      "22 Train Loss 26.408741 Test MSE 6.703793448319968 Test RE 1.2375660093304717\n",
      "23 Train Loss 26.024609 Test MSE 6.784413298121468 Test RE 1.2449852571802766\n",
      "24 Train Loss 25.60701 Test MSE 6.734289612056473 Test RE 1.2403777152304207\n",
      "25 Train Loss 23.92826 Test MSE 6.851764740144302 Test RE 1.2511497159749565\n",
      "26 Train Loss 23.192066 Test MSE 6.755326361974224 Test RE 1.2423135667578784\n",
      "27 Train Loss 22.74303 Test MSE 6.734258234992088 Test RE 1.240374825582142\n",
      "28 Train Loss 21.69044 Test MSE 6.34368548759656 Test RE 1.2038680309574301\n",
      "29 Train Loss 21.02206 Test MSE 6.331828387539506 Test RE 1.2027424187170264\n",
      "30 Train Loss 20.04443 Test MSE 6.341361628689006 Test RE 1.2036475064917962\n",
      "31 Train Loss 19.07472 Test MSE 6.3375449360217315 Test RE 1.2032852306642332\n",
      "32 Train Loss 18.471539 Test MSE 6.41400805973921 Test RE 1.2105223462758412\n",
      "33 Train Loss 17.90234 Test MSE 6.428853184303415 Test RE 1.211922404463946\n",
      "34 Train Loss 17.52835 Test MSE 6.374822294439779 Test RE 1.2068188962226887\n",
      "35 Train Loss 17.300858 Test MSE 6.442714504813105 Test RE 1.2132282205329497\n",
      "36 Train Loss 17.042267 Test MSE 6.430153785856756 Test RE 1.2120449884150941\n",
      "37 Train Loss 16.80386 Test MSE 6.333924241291973 Test RE 1.202941457880441\n",
      "38 Train Loss 16.527946 Test MSE 6.356319587615827 Test RE 1.2050662479648024\n",
      "39 Train Loss 15.910935 Test MSE 6.131226970586874 Test RE 1.183536775254634\n",
      "40 Train Loss 15.736923 Test MSE 6.045377598556321 Test RE 1.1752216311072405\n",
      "41 Train Loss 15.465789 Test MSE 5.91290294222901 Test RE 1.1622737662543623\n",
      "42 Train Loss 15.209309 Test MSE 5.912482113859035 Test RE 1.1622324053118283\n",
      "43 Train Loss 14.823059 Test MSE 6.016689842661046 Test RE 1.1724298647450986\n",
      "44 Train Loss 13.984981 Test MSE 5.5638774015413865 Test RE 1.1274488195003198\n",
      "45 Train Loss 13.642279 Test MSE 5.751503235122737 Test RE 1.1463011932367762\n",
      "46 Train Loss 12.569162 Test MSE 5.57587736066832 Test RE 1.1286639840106596\n",
      "47 Train Loss 11.206139 Test MSE 5.172179681418324 Test RE 1.087038340550447\n",
      "48 Train Loss 10.23824 Test MSE 4.875138519026748 Test RE 1.0553622129020297\n",
      "49 Train Loss 9.550839 Test MSE 4.750574119511143 Test RE 1.0417922191803373\n",
      "50 Train Loss 8.767269 Test MSE 4.151741931482262 Test RE 0.973919890193642\n",
      "51 Train Loss 8.166064 Test MSE 3.8260779525269224 Test RE 0.934942640420424\n",
      "52 Train Loss 7.2402983 Test MSE 3.3027640294997602 Test RE 0.8686540189086974\n",
      "53 Train Loss 5.6340237 Test MSE 2.6983643604614036 Test RE 0.7851603434994652\n",
      "54 Train Loss 4.3768983 Test MSE 1.3642254687962834 Test RE 0.5582788006707894\n",
      "55 Train Loss 3.202014 Test MSE 1.0758525314426464 Test RE 0.4957747832316184\n",
      "56 Train Loss 2.3605702 Test MSE 1.2050083712247799 Test RE 0.5246903686700337\n",
      "57 Train Loss 1.7055746 Test MSE 1.1080844663969114 Test RE 0.5031465436650696\n",
      "58 Train Loss 1.3937389 Test MSE 0.8181822803530044 Test RE 0.43234764237964\n",
      "59 Train Loss 1.1929767 Test MSE 0.7583901011605922 Test RE 0.41625013576276076\n",
      "60 Train Loss 1.0436579 Test MSE 0.680825422129413 Test RE 0.39439004329505933\n",
      "61 Train Loss 0.8791355 Test MSE 0.5261644346793164 Test RE 0.34671194545532663\n",
      "62 Train Loss 0.7197458 Test MSE 0.406252565447633 Test RE 0.3046534625950049\n",
      "63 Train Loss 0.62747586 Test MSE 0.37327066276387105 Test RE 0.292024970821401\n",
      "64 Train Loss 0.55710316 Test MSE 0.3614005087652869 Test RE 0.2873442031064399\n",
      "65 Train Loss 0.46964937 Test MSE 0.31077160801421816 Test RE 0.26645797787807324\n",
      "66 Train Loss 0.4347662 Test MSE 0.29237311542843203 Test RE 0.2584501437214298\n",
      "67 Train Loss 0.37750885 Test MSE 0.2328231212285754 Test RE 0.23063282243017844\n",
      "68 Train Loss 0.31860134 Test MSE 0.15095928403476 Test RE 0.18571114771041888\n",
      "69 Train Loss 0.29394278 Test MSE 0.11199780864303778 Test RE 0.15996052577127445\n",
      "70 Train Loss 0.27916443 Test MSE 0.09878577450435015 Test RE 0.15022951489334876\n",
      "71 Train Loss 0.26131105 Test MSE 0.09387682589605581 Test RE 0.14644928605453555\n",
      "72 Train Loss 0.24115255 Test MSE 0.08754991125323217 Test RE 0.14142816787894427\n",
      "73 Train Loss 0.22562066 Test MSE 0.08070449646251732 Test RE 0.13578660385739955\n",
      "74 Train Loss 0.20562221 Test MSE 0.06436839216015271 Test RE 0.12126749062444342\n",
      "75 Train Loss 0.1855949 Test MSE 0.053874185817483884 Test RE 0.11094262059646309\n",
      "76 Train Loss 0.17394298 Test MSE 0.04486482315959591 Test RE 0.10124207564836901\n",
      "77 Train Loss 0.15751421 Test MSE 0.031510072560351696 Test RE 0.08484627141199652\n",
      "78 Train Loss 0.14611697 Test MSE 0.026892035787036587 Test RE 0.07838264247520824\n",
      "79 Train Loss 0.13987376 Test MSE 0.02840217302035968 Test RE 0.08055339421128152\n",
      "80 Train Loss 0.13195524 Test MSE 0.026410144226421496 Test RE 0.07767717932323465\n",
      "81 Train Loss 0.1246783 Test MSE 0.018906714162640156 Test RE 0.06572280484674485\n",
      "82 Train Loss 0.117565304 Test MSE 0.018679149177472383 Test RE 0.06532608107301721\n",
      "83 Train Loss 0.10702187 Test MSE 0.01948277551405606 Test RE 0.06671653360127751\n",
      "84 Train Loss 0.10192907 Test MSE 0.019275608813320903 Test RE 0.0663608762984143\n",
      "85 Train Loss 0.0964917 Test MSE 0.016034469667071175 Test RE 0.060525078374005295\n",
      "86 Train Loss 0.09093469 Test MSE 0.013970303244500005 Test RE 0.056495125386871625\n",
      "87 Train Loss 0.08544772 Test MSE 0.014250712165021894 Test RE 0.05705928751626261\n",
      "88 Train Loss 0.076505154 Test MSE 0.011803582605717254 Test RE 0.05192960057277726\n",
      "89 Train Loss 0.0704094 Test MSE 0.008920392950827406 Test RE 0.0451440016564592\n",
      "90 Train Loss 0.06926931 Test MSE 0.008541959442711055 Test RE 0.04417604307960729\n",
      "91 Train Loss 0.06373196 Test MSE 0.007861266309810733 Test RE 0.04237935227362794\n",
      "92 Train Loss 0.058578737 Test MSE 0.007205276765431044 Test RE 0.040572651814053576\n",
      "93 Train Loss 0.05655301 Test MSE 0.007329804609558691 Test RE 0.040921755780304526\n",
      "94 Train Loss 0.055005565 Test MSE 0.0075786432420078325 Test RE 0.04161058217246145\n",
      "95 Train Loss 0.053671166 Test MSE 0.00659301185478651 Test RE 0.03881056709138134\n",
      "96 Train Loss 0.05263471 Test MSE 0.006345965254479126 Test RE 0.03807648984132765\n",
      "97 Train Loss 0.04934884 Test MSE 0.006665365463993223 Test RE 0.03902294517215807\n",
      "98 Train Loss 0.047702987 Test MSE 0.006331807228236969 Test RE 0.038033991266508124\n",
      "99 Train Loss 0.046725854 Test MSE 0.006905576368715943 Test RE 0.03971988903339103\n",
      "Training time: 74.29\n",
      "KG_stan_tune14\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 51.6547 Test MSE 9.5658778011755 Test RE 1.478326883405173\n",
      "1 Train Loss 43.477768 Test MSE 9.48053742296239 Test RE 1.4717177869282065\n",
      "2 Train Loss 43.14387 Test MSE 9.38160635197282 Test RE 1.4640188326405232\n",
      "3 Train Loss 42.6653 Test MSE 9.361727559493852 Test RE 1.4624669470437288\n",
      "4 Train Loss 42.33011 Test MSE 9.470878308651889 Test RE 1.4709678762236795\n",
      "5 Train Loss 41.757244 Test MSE 9.476947571140593 Test RE 1.4714391239806568\n",
      "6 Train Loss 40.66385 Test MSE 9.565790855570397 Test RE 1.4783201650297062\n",
      "7 Train Loss 39.433876 Test MSE 9.328597277228285 Test RE 1.4598768863311646\n",
      "8 Train Loss 38.605415 Test MSE 9.581361186548019 Test RE 1.479522813906007\n",
      "9 Train Loss 38.083397 Test MSE 9.549226436315426 Test RE 1.4770396579916896\n",
      "10 Train Loss 37.691826 Test MSE 9.48988277406153 Test RE 1.472442974282766\n",
      "11 Train Loss 37.325596 Test MSE 9.469211766297903 Test RE 1.4708384511567474\n",
      "12 Train Loss 37.015167 Test MSE 9.45537897029035 Test RE 1.4697637448046936\n",
      "13 Train Loss 36.516586 Test MSE 9.322046472948289 Test RE 1.4593642129367934\n",
      "14 Train Loss 36.197838 Test MSE 9.353478278384918 Test RE 1.461822463441153\n",
      "15 Train Loss 35.596077 Test MSE 9.26283319114514 Test RE 1.454721916505295\n",
      "16 Train Loss 34.46879 Test MSE 8.527353416012302 Test RE 1.395774281038771\n",
      "17 Train Loss 30.75726 Test MSE 6.3796118900317 Test RE 1.207272170753463\n",
      "18 Train Loss 24.812637 Test MSE 5.3720782968301615 Test RE 1.1078455745223381\n",
      "19 Train Loss 22.573103 Test MSE 5.0342354344215785 Test RE 1.072444487854105\n",
      "20 Train Loss 21.529713 Test MSE 5.308401335513538 Test RE 1.101260177778343\n",
      "21 Train Loss 21.10984 Test MSE 5.39303443071966 Test RE 1.1100042886895114\n",
      "22 Train Loss 20.726677 Test MSE 5.412091196717084 Test RE 1.1119637086243959\n",
      "23 Train Loss 20.379436 Test MSE 5.512785620048051 Test RE 1.1222603317973618\n",
      "24 Train Loss 19.983433 Test MSE 5.57294850537864 Test RE 1.1283675169726006\n",
      "25 Train Loss 19.766672 Test MSE 5.75079822841904 Test RE 1.1462309355354858\n",
      "26 Train Loss 19.337505 Test MSE 5.934649567893059 Test RE 1.1644091247786363\n",
      "27 Train Loss 19.079132 Test MSE 5.89639896537287 Test RE 1.1606505751213032\n",
      "28 Train Loss 18.678766 Test MSE 5.945682897273794 Test RE 1.1654910204808473\n",
      "29 Train Loss 18.364525 Test MSE 6.027795467262421 Test RE 1.1735114032220848\n",
      "30 Train Loss 17.960936 Test MSE 5.925574944842154 Test RE 1.1635185400718544\n",
      "31 Train Loss 17.538961 Test MSE 5.700306371662649 Test RE 1.1411879030178986\n",
      "32 Train Loss 17.026646 Test MSE 5.815629210327166 Test RE 1.1526737815020236\n",
      "33 Train Loss 16.662033 Test MSE 5.889277723885993 Test RE 1.159949488735123\n",
      "34 Train Loss 16.267986 Test MSE 5.740283703183488 Test RE 1.1451825951537906\n",
      "35 Train Loss 15.780563 Test MSE 5.822556745829298 Test RE 1.1533601055174965\n",
      "36 Train Loss 15.3345 Test MSE 5.550481054209716 Test RE 1.126090702014694\n",
      "37 Train Loss 14.924063 Test MSE 5.587289224142098 Test RE 1.1298183831217683\n",
      "38 Train Loss 14.520533 Test MSE 5.458275365723805 Test RE 1.116698110081589\n",
      "39 Train Loss 14.083971 Test MSE 5.263615873303961 Test RE 1.0966048296126365\n",
      "40 Train Loss 11.395695 Test MSE 4.3695962750841115 Test RE 0.9991454536366694\n",
      "41 Train Loss 9.325476 Test MSE 4.004669257295232 Test RE 0.9565141238779141\n",
      "42 Train Loss 8.466479 Test MSE 3.8360631778179877 Test RE 0.9361618432141933\n",
      "43 Train Loss 8.118841 Test MSE 3.455080141772 Test RE 0.8884584515748716\n",
      "44 Train Loss 7.8787394 Test MSE 3.3351395479578136 Test RE 0.8729011495103722\n",
      "45 Train Loss 7.6344204 Test MSE 3.305896224416103 Test RE 0.8690658177707219\n",
      "46 Train Loss 7.39752 Test MSE 3.296057564562769 Test RE 0.8677716431193869\n",
      "47 Train Loss 7.249985 Test MSE 3.2821762583677683 Test RE 0.8659424102987703\n",
      "48 Train Loss 7.08545 Test MSE 3.2862717908916976 Test RE 0.866482507688083\n",
      "49 Train Loss 6.746372 Test MSE 3.2088781702263183 Test RE 0.8562186329359374\n",
      "50 Train Loss 6.433144 Test MSE 3.230838647086215 Test RE 0.8591434726776912\n",
      "51 Train Loss 5.8083653 Test MSE 3.163909442576227 Test RE 0.8501980070313494\n",
      "52 Train Loss 5.4965963 Test MSE 3.1338225076347577 Test RE 0.8461459069575319\n",
      "53 Train Loss 5.0974636 Test MSE 3.079776619596645 Test RE 0.8388178605451783\n",
      "54 Train Loss 4.546168 Test MSE 2.943614758043243 Test RE 0.8200655084973796\n",
      "55 Train Loss 3.9669094 Test MSE 2.7452666178490945 Test RE 0.791954671357328\n",
      "56 Train Loss 3.5522206 Test MSE 2.767765135746362 Test RE 0.7951932364410712\n",
      "57 Train Loss 3.2705798 Test MSE 2.780461396483001 Test RE 0.7970150003207367\n",
      "58 Train Loss 2.969895 Test MSE 2.661952391452773 Test RE 0.7798448388179636\n",
      "59 Train Loss 2.616487 Test MSE 2.5011983075084125 Test RE 0.7559309436791866\n",
      "60 Train Loss 2.2731845 Test MSE 2.499851403536167 Test RE 0.7557273805518283\n",
      "61 Train Loss 1.9205111 Test MSE 2.4812853069528575 Test RE 0.7529158021962182\n",
      "62 Train Loss 1.683692 Test MSE 2.5163649602453457 Test RE 0.7582193696764917\n",
      "63 Train Loss 1.4915843 Test MSE 2.5393735506386514 Test RE 0.7616779024679758\n",
      "64 Train Loss 1.3873203 Test MSE 2.495719746085088 Test RE 0.7551026038403332\n",
      "65 Train Loss 1.3154646 Test MSE 2.532890905218158 Test RE 0.7607050556233851\n",
      "66 Train Loss 1.2567807 Test MSE 2.51342664250073 Test RE 0.7577765602647333\n",
      "67 Train Loss 1.2114127 Test MSE 2.5162977294258138 Test RE 0.7582092407701321\n",
      "68 Train Loss 1.1717091 Test MSE 2.570827041609128 Test RE 0.7663805778289704\n",
      "69 Train Loss 1.1217915 Test MSE 2.5861576286446577 Test RE 0.7686622561028914\n",
      "70 Train Loss 1.0977128 Test MSE 2.5559965825941204 Test RE 0.7641668515463234\n",
      "71 Train Loss 1.0686393 Test MSE 2.5824969882697175 Test RE 0.7681180525172819\n",
      "72 Train Loss 1.0358413 Test MSE 2.617853313808986 Test RE 0.7733582348213495\n",
      "73 Train Loss 1.016679 Test MSE 2.6208065868669004 Test RE 0.7737943353176154\n",
      "74 Train Loss 0.9918921 Test MSE 2.599115368453194 Test RE 0.7705855109841884\n",
      "75 Train Loss 0.9670552 Test MSE 2.599276830341236 Test RE 0.7706094457161295\n",
      "76 Train Loss 0.9505681 Test MSE 2.604092318371315 Test RE 0.7713229409851557\n",
      "77 Train Loss 0.93117446 Test MSE 2.5926296072943744 Test RE 0.7696234614734646\n",
      "78 Train Loss 0.90296733 Test MSE 2.5642207939614434 Test RE 0.7653952613289762\n",
      "79 Train Loss 0.8859664 Test MSE 2.5992901697449793 Test RE 0.7706114230848378\n",
      "80 Train Loss 0.84973276 Test MSE 2.635739227328484 Test RE 0.7759956386049396\n",
      "81 Train Loss 0.83014417 Test MSE 2.6398154725627117 Test RE 0.7765954563829984\n",
      "82 Train Loss 0.8088087 Test MSE 2.6688423895254365 Test RE 0.7808534325656638\n",
      "83 Train Loss 0.79103553 Test MSE 2.672500949133113 Test RE 0.7813884623701737\n",
      "84 Train Loss 0.77120805 Test MSE 2.665349653553004 Test RE 0.7803423106307299\n",
      "85 Train Loss 0.75388825 Test MSE 2.64632894381569 Test RE 0.7775529505428553\n",
      "86 Train Loss 0.7398598 Test MSE 2.6598727468376775 Test RE 0.7795401532410109\n",
      "87 Train Loss 0.7249247 Test MSE 2.6991294764413 Test RE 0.7852716509559106\n",
      "88 Train Loss 0.70656216 Test MSE 2.701572186970075 Test RE 0.7856269057801517\n",
      "89 Train Loss 0.6964315 Test MSE 2.711903949670409 Test RE 0.7871277291014577\n",
      "90 Train Loss 0.6870859 Test MSE 2.74800762836915 Test RE 0.7923499361549536\n",
      "91 Train Loss 0.6795307 Test MSE 2.7677959740090046 Test RE 0.7951976664248973\n",
      "92 Train Loss 0.6669099 Test MSE 2.7889279027431324 Test RE 0.7982275335067371\n",
      "93 Train Loss 0.65765065 Test MSE 2.7907202709560126 Test RE 0.7984839918861897\n",
      "94 Train Loss 0.6489807 Test MSE 2.7893593608530614 Test RE 0.7982892755875409\n",
      "95 Train Loss 0.6412838 Test MSE 2.781364722042087 Test RE 0.7971444582508299\n",
      "96 Train Loss 0.63391614 Test MSE 2.7951387793108244 Test RE 0.7991158561452829\n",
      "97 Train Loss 0.629377 Test MSE 2.8152860390316397 Test RE 0.8019906841975374\n",
      "98 Train Loss 0.6228754 Test MSE 2.8269536813970926 Test RE 0.8036508468375013\n",
      "99 Train Loss 0.6156658 Test MSE 2.84867420933117 Test RE 0.8067323121074513\n",
      "Training time: 73.72\n",
      "KG_stan_tune14\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.438984 Test MSE 8.48437417830547 Test RE 1.3922523738461587\n",
      "1 Train Loss 55.349236 Test MSE 8.654310522450384 Test RE 1.4061261897128543\n",
      "2 Train Loss 53.721886 Test MSE 8.993321509763655 Test RE 1.4334023762807382\n",
      "3 Train Loss 50.305653 Test MSE 9.079878312889546 Test RE 1.4402837950927043\n",
      "4 Train Loss 46.338364 Test MSE 8.758596944338823 Test RE 1.4145728908947883\n",
      "5 Train Loss 45.142433 Test MSE 8.689156620632415 Test RE 1.4089541901782685\n",
      "6 Train Loss 44.615894 Test MSE 8.625994094625433 Test RE 1.4038239211856567\n",
      "7 Train Loss 44.457745 Test MSE 8.427583273970649 Test RE 1.38758496848897\n",
      "8 Train Loss 44.17007 Test MSE 8.500343443142139 Test RE 1.3935620046100794\n",
      "9 Train Loss 43.97715 Test MSE 8.493696838933019 Test RE 1.3930170697798165\n",
      "10 Train Loss 43.828148 Test MSE 8.582633343296958 Test RE 1.4002911371455153\n",
      "11 Train Loss 43.37815 Test MSE 8.39266400698511 Test RE 1.38470729028854\n",
      "12 Train Loss 43.03293 Test MSE 8.381424886031395 Test RE 1.3837798072806986\n",
      "13 Train Loss 42.487038 Test MSE 8.301835926393997 Test RE 1.3771940358149515\n",
      "14 Train Loss 41.804672 Test MSE 8.359773048751697 Test RE 1.3819912838162325\n",
      "15 Train Loss 40.33597 Test MSE 8.632687272325676 Test RE 1.4043684509463672\n",
      "16 Train Loss 38.84762 Test MSE 8.109057632248602 Test RE 1.3611100910647578\n",
      "17 Train Loss 38.02507 Test MSE 8.18119377161439 Test RE 1.3671507335011135\n",
      "18 Train Loss 37.53517 Test MSE 8.260290268101418 Test RE 1.3737437028768897\n",
      "19 Train Loss 37.062725 Test MSE 8.244350188757712 Test RE 1.3724175897992392\n",
      "20 Train Loss 36.407516 Test MSE 8.01463767808097 Test RE 1.353162666432994\n",
      "21 Train Loss 34.988354 Test MSE 7.749825024500185 Test RE 1.3306198835088632\n",
      "22 Train Loss 33.130527 Test MSE 8.067331543362073 Test RE 1.3576037003374306\n",
      "23 Train Loss 31.513523 Test MSE 8.465795000248121 Test RE 1.3907271534441326\n",
      "24 Train Loss 30.517136 Test MSE 8.300561004816638 Test RE 1.3770882831944606\n",
      "25 Train Loss 29.08432 Test MSE 7.862492607682336 Test RE 1.340257312228178\n",
      "26 Train Loss 27.99485 Test MSE 7.496147925235634 Test RE 1.3086609226734758\n",
      "27 Train Loss 27.088633 Test MSE 7.277176899869836 Test RE 1.2894055238421542\n",
      "28 Train Loss 26.271076 Test MSE 7.353745352889631 Test RE 1.296171158942805\n",
      "29 Train Loss 25.595688 Test MSE 7.397545480257483 Test RE 1.3000255333741328\n",
      "30 Train Loss 24.874674 Test MSE 7.202637499351002 Test RE 1.2827849002219678\n",
      "31 Train Loss 23.874086 Test MSE 7.37295068852919 Test RE 1.2978626215239675\n",
      "32 Train Loss 23.08305 Test MSE 7.501712674329752 Test RE 1.309146573353343\n",
      "33 Train Loss 22.287176 Test MSE 7.552624937830086 Test RE 1.313581487973679\n",
      "34 Train Loss 21.738556 Test MSE 7.592045532065911 Test RE 1.31700511686696\n",
      "35 Train Loss 21.29464 Test MSE 7.732969461996664 Test RE 1.3291720730734362\n",
      "36 Train Loss 20.687435 Test MSE 7.637853965093428 Test RE 1.3209723751079492\n",
      "37 Train Loss 20.253338 Test MSE 7.545106591151216 Test RE 1.312927515341154\n",
      "38 Train Loss 19.6712 Test MSE 7.199370750787593 Test RE 1.2824939643674715\n",
      "39 Train Loss 18.748833 Test MSE 6.746459414388908 Test RE 1.241497977268009\n",
      "40 Train Loss 17.754662 Test MSE 6.315830017340239 Test RE 1.2012219978282417\n",
      "41 Train Loss 15.355844 Test MSE 6.090693888055608 Test RE 1.1796181515713307\n",
      "42 Train Loss 12.5403805 Test MSE 5.235989354193052 Test RE 1.0937232334233302\n",
      "43 Train Loss 9.960768 Test MSE 3.6507191835259736 Test RE 0.9132659677283217\n",
      "44 Train Loss 8.3868685 Test MSE 3.578497141592534 Test RE 0.9041872892974292\n",
      "45 Train Loss 7.2319045 Test MSE 3.7263122753568547 Test RE 0.9226727275161473\n",
      "46 Train Loss 6.461737 Test MSE 3.841759610613538 Test RE 0.9368566707617935\n",
      "47 Train Loss 5.9246235 Test MSE 3.7024996247322304 Test RE 0.9197198755220671\n",
      "48 Train Loss 5.5131946 Test MSE 3.631638484378173 Test RE 0.910876221876339\n",
      "49 Train Loss 5.0789495 Test MSE 3.9496936164168104 Test RE 0.9499259772442457\n",
      "50 Train Loss 4.7029295 Test MSE 3.908458639502801 Test RE 0.9449543324377865\n",
      "51 Train Loss 4.384831 Test MSE 3.9951289863105317 Test RE 0.9553740989880094\n",
      "52 Train Loss 4.154344 Test MSE 3.8784978749651495 Test RE 0.9413255336912375\n",
      "53 Train Loss 3.9570155 Test MSE 3.63228766270772 Test RE 0.9109576306789295\n",
      "54 Train Loss 3.7750638 Test MSE 3.438400041740799 Test RE 0.8863112502554988\n",
      "55 Train Loss 3.3685617 Test MSE 3.096170675642705 Test RE 0.8410474662651707\n",
      "56 Train Loss 2.9118772 Test MSE 2.814654425489627 Test RE 0.8019007152593767\n",
      "57 Train Loss 2.754284 Test MSE 2.721271089024567 Test RE 0.7884859592200458\n",
      "58 Train Loss 2.6177602 Test MSE 2.6183575353353867 Test RE 0.773432709027508\n",
      "59 Train Loss 2.4843583 Test MSE 2.592569815700318 Test RE 0.7696145868392378\n",
      "60 Train Loss 2.396407 Test MSE 2.5884169898430347 Test RE 0.7689979484277807\n",
      "61 Train Loss 2.2895374 Test MSE 2.557756770484265 Test RE 0.7644299281394282\n",
      "62 Train Loss 2.1437583 Test MSE 2.509955977298251 Test RE 0.7572531916438128\n",
      "63 Train Loss 2.0487008 Test MSE 2.480101705554365 Test RE 0.75273620606277\n",
      "64 Train Loss 1.9797378 Test MSE 2.4736860276181543 Test RE 0.7517619636971108\n",
      "65 Train Loss 1.885275 Test MSE 2.464988429727105 Test RE 0.7504391844997589\n",
      "66 Train Loss 1.833339 Test MSE 2.485098736833059 Test RE 0.7534941494925307\n",
      "67 Train Loss 1.7566645 Test MSE 2.5180130904167983 Test RE 0.7584676324857936\n",
      "68 Train Loss 1.7046429 Test MSE 2.537764982342711 Test RE 0.7614366215003686\n",
      "69 Train Loss 1.6685042 Test MSE 2.5616050766605225 Test RE 0.7650047784855155\n",
      "70 Train Loss 1.6061559 Test MSE 2.4908920588738948 Test RE 0.7543719200767568\n",
      "71 Train Loss 1.539283 Test MSE 2.527866355230124 Test RE 0.7599501676023478\n",
      "72 Train Loss 1.5134137 Test MSE 2.5265397797799687 Test RE 0.7597507378480285\n",
      "73 Train Loss 1.4623487 Test MSE 2.5004202109360723 Test RE 0.7558133534372856\n",
      "74 Train Loss 1.4309033 Test MSE 2.5301338836534515 Test RE 0.7602909337073227\n",
      "75 Train Loss 1.4002832 Test MSE 2.5367162248939312 Test RE 0.7612792694889133\n",
      "76 Train Loss 1.3674636 Test MSE 2.525587149200963 Test RE 0.7596074925234432\n",
      "77 Train Loss 1.3342197 Test MSE 2.549428810475218 Test RE 0.7631844359218167\n",
      "78 Train Loss 1.281204 Test MSE 2.580375758614722 Test RE 0.7678025265904054\n",
      "79 Train Loss 1.2584617 Test MSE 2.5814204625995414 Test RE 0.7679579390694995\n",
      "80 Train Loss 1.2289736 Test MSE 2.6044754370758434 Test RE 0.7713796781015229\n",
      "81 Train Loss 1.2124429 Test MSE 2.6292034153281953 Test RE 0.7750329277351192\n",
      "82 Train Loss 1.1748866 Test MSE 2.6220435087797145 Test RE 0.7739769146558411\n",
      "83 Train Loss 1.143236 Test MSE 2.6588975591439863 Test RE 0.7793972389501674\n",
      "84 Train Loss 1.1280198 Test MSE 2.664417779017685 Test RE 0.7802058848716288\n",
      "85 Train Loss 1.1134157 Test MSE 2.6721115327572242 Test RE 0.7813315313242521\n",
      "86 Train Loss 1.0850656 Test MSE 2.6479114729434943 Test RE 0.7777854077148719\n",
      "87 Train Loss 1.0715305 Test MSE 2.6535761243358555 Test RE 0.7786169176405352\n",
      "88 Train Loss 1.0540293 Test MSE 2.653383856106125 Test RE 0.7785887092905176\n",
      "89 Train Loss 1.0398142 Test MSE 2.6693334189550217 Test RE 0.7809252622815447\n",
      "90 Train Loss 1.0129994 Test MSE 2.6997649701116355 Test RE 0.7853640892397701\n",
      "91 Train Loss 0.9942202 Test MSE 2.6954803051947755 Test RE 0.7847406353144598\n",
      "92 Train Loss 0.97009796 Test MSE 2.67840700652069 Test RE 0.7822513953174591\n",
      "93 Train Loss 0.96213806 Test MSE 2.690453866295624 Test RE 0.7840086152301239\n",
      "94 Train Loss 0.9528154 Test MSE 2.7108626796090483 Test RE 0.7869766007347703\n",
      "95 Train Loss 0.94096136 Test MSE 2.73115157433714 Test RE 0.789916093314865\n",
      "96 Train Loss 0.9285117 Test MSE 2.7165346863262645 Test RE 0.7877994760765222\n",
      "97 Train Loss 0.9119493 Test MSE 2.7242340600851285 Test RE 0.7889151015963777\n",
      "98 Train Loss 0.9092016 Test MSE 2.731789803632219 Test RE 0.790008383714755\n",
      "99 Train Loss 0.898986 Test MSE 2.71468906822008 Test RE 0.7875318144804969\n",
      "Training time: 76.69\n",
      "KG_stan_tune14\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 52.924 Test MSE 8.97816035174353 Test RE 1.4321936345084596\n",
      "1 Train Loss 44.43945 Test MSE 8.297106379679038 Test RE 1.3768016869698299\n",
      "2 Train Loss 42.337696 Test MSE 7.937660859375497 Test RE 1.3466487429783784\n",
      "3 Train Loss 39.556084 Test MSE 7.20220921681314 Test RE 1.2827467612388594\n",
      "4 Train Loss 34.27795 Test MSE 7.224321204245438 Test RE 1.2847143757684933\n",
      "5 Train Loss 30.407722 Test MSE 6.846111913609092 Test RE 1.2506334992099888\n",
      "6 Train Loss 26.046368 Test MSE 6.421764835048808 Test RE 1.2112540972031582\n",
      "7 Train Loss 24.67392 Test MSE 6.07773744050166 Test RE 1.1783628104143113\n",
      "8 Train Loss 23.570337 Test MSE 5.991914469636342 Test RE 1.1700134736414611\n",
      "9 Train Loss 23.201557 Test MSE 6.00845479757059 Test RE 1.171627237468169\n",
      "10 Train Loss 22.746313 Test MSE 5.999169337566537 Test RE 1.170721571651627\n",
      "11 Train Loss 22.420319 Test MSE 5.978700451412525 Test RE 1.1687226414134062\n",
      "12 Train Loss 22.191223 Test MSE 6.008102584877013 Test RE 1.1715928968559177\n",
      "13 Train Loss 21.795319 Test MSE 5.813990010519898 Test RE 1.1525113230876007\n",
      "14 Train Loss 21.109425 Test MSE 5.477426445376281 Test RE 1.1186554360665066\n",
      "15 Train Loss 19.273558 Test MSE 5.748562370812017 Test RE 1.146008091836018\n",
      "16 Train Loss 16.851223 Test MSE 5.747022204986038 Test RE 1.1458545612117756\n",
      "17 Train Loss 15.006512 Test MSE 6.038144489571869 Test RE 1.1745183623559463\n",
      "18 Train Loss 13.296335 Test MSE 6.017754089394167 Test RE 1.1725335512832453\n",
      "19 Train Loss 12.499534 Test MSE 6.01639153009095 Test RE 1.1724007993527736\n",
      "20 Train Loss 11.860195 Test MSE 6.068850018091638 Test RE 1.1775009403965981\n",
      "21 Train Loss 11.463535 Test MSE 6.061541903332393 Test RE 1.1767917529749263\n",
      "22 Train Loss 11.186321 Test MSE 6.015380909384058 Test RE 1.1723023265156822\n",
      "23 Train Loss 10.9739485 Test MSE 6.025874357446025 Test RE 1.1733243842742036\n",
      "24 Train Loss 10.753195 Test MSE 6.029990348031828 Test RE 1.173725037144839\n",
      "25 Train Loss 10.438113 Test MSE 5.93913259240661 Test RE 1.1648488381225917\n",
      "26 Train Loss 10.142079 Test MSE 6.080449920071538 Test RE 1.1786257313233188\n",
      "27 Train Loss 9.230058 Test MSE 5.786930351384307 Test RE 1.1498261674918646\n",
      "28 Train Loss 8.471743 Test MSE 5.743909329110508 Test RE 1.145544192987369\n",
      "29 Train Loss 7.8645945 Test MSE 5.716064912535192 Test RE 1.142764225704841\n",
      "30 Train Loss 6.8338594 Test MSE 5.379536526359824 Test RE 1.1086143366581374\n",
      "31 Train Loss 5.5470905 Test MSE 4.524918843064237 Test RE 1.0167483058307352\n",
      "32 Train Loss 4.150346 Test MSE 4.025123328059845 Test RE 0.9589537372500513\n",
      "33 Train Loss 3.4939852 Test MSE 3.2960314935741004 Test RE 0.8677682111845726\n",
      "34 Train Loss 2.9702547 Test MSE 2.5945374583484218 Test RE 0.7699065826916229\n",
      "35 Train Loss 2.6966224 Test MSE 2.479199617676988 Test RE 0.752599297168596\n",
      "36 Train Loss 2.237337 Test MSE 2.041629187561907 Test RE 0.6829619260776207\n",
      "37 Train Loss 1.8061805 Test MSE 1.582786092353437 Test RE 0.6013387258567275\n",
      "38 Train Loss 1.5945822 Test MSE 1.3895660096543894 Test RE 0.5634399688819587\n",
      "39 Train Loss 1.1773176 Test MSE 0.9249431115189758 Test RE 0.4596905452750603\n",
      "40 Train Loss 0.9304206 Test MSE 0.7082616010607687 Test RE 0.40225820257274614\n",
      "41 Train Loss 0.77069885 Test MSE 0.5279646954381204 Test RE 0.3473045728570391\n",
      "42 Train Loss 0.57456887 Test MSE 0.21899679985610535 Test RE 0.22367989211960204\n",
      "43 Train Loss 0.3868807 Test MSE 0.14567520203935877 Test RE 0.18243193930147802\n",
      "44 Train Loss 0.2746949 Test MSE 0.0771383377752358 Test RE 0.13275264974710815\n",
      "45 Train Loss 0.21186729 Test MSE 0.04171317363540498 Test RE 0.09762132026225481\n",
      "46 Train Loss 0.16729179 Test MSE 0.03626229957518748 Test RE 0.09101976942456332\n",
      "47 Train Loss 0.14369062 Test MSE 0.027138406539119763 Test RE 0.07874087422879024\n",
      "48 Train Loss 0.1205642 Test MSE 0.027087916345019607 Test RE 0.07866759260703\n",
      "49 Train Loss 0.10747169 Test MSE 0.020807229298416646 Test RE 0.06894697028569542\n",
      "50 Train Loss 0.09338234 Test MSE 0.018078453951848077 Test RE 0.06426710011763406\n",
      "51 Train Loss 0.081528544 Test MSE 0.017502270425030057 Test RE 0.06323466981101633\n",
      "52 Train Loss 0.07293124 Test MSE 0.01706886436205981 Test RE 0.0624468266674097\n",
      "53 Train Loss 0.06466894 Test MSE 0.016746013842921376 Test RE 0.06185342933923835\n",
      "54 Train Loss 0.057392128 Test MSE 0.015243625426240257 Test RE 0.05901361167017748\n",
      "55 Train Loss 0.052344464 Test MSE 0.014161319297973003 Test RE 0.056880043229117015\n",
      "56 Train Loss 0.04286748 Test MSE 0.01107119281602758 Test RE 0.05029273657934703\n",
      "57 Train Loss 0.037835963 Test MSE 0.009434987371556527 Test RE 0.04642786595451098\n",
      "58 Train Loss 0.0336069 Test MSE 0.009548726732511338 Test RE 0.046706873020847244\n",
      "59 Train Loss 0.03029513 Test MSE 0.008779053337499874 Test RE 0.044784930448135155\n",
      "60 Train Loss 0.026483716 Test MSE 0.00889534922977265 Test RE 0.04508058693810595\n",
      "61 Train Loss 0.0237711 Test MSE 0.007764958486971309 Test RE 0.042118959063325294\n",
      "62 Train Loss 0.022440571 Test MSE 0.0076034572620729355 Test RE 0.04167864725970115\n",
      "63 Train Loss 0.020308139 Test MSE 0.007205985758234571 Test RE 0.040574647921316154\n",
      "64 Train Loss 0.0187718 Test MSE 0.005501589608416685 Test RE 0.03545293184598662\n",
      "65 Train Loss 0.017057056 Test MSE 0.005014742984451964 Test RE 0.03384795227804033\n",
      "66 Train Loss 0.014269723 Test MSE 0.0040921953831945385 Test RE 0.030576392229482302\n",
      "67 Train Loss 0.012622859 Test MSE 0.005159319658768706 Test RE 0.03433240907383253\n",
      "68 Train Loss 0.011339928 Test MSE 0.004862067040799495 Test RE 0.033328712090401336\n",
      "69 Train Loss 0.010349517 Test MSE 0.004723900711518209 Test RE 0.032851744819616883\n",
      "70 Train Loss 0.009906853 Test MSE 0.004583843713599917 Test RE 0.03236107658451508\n",
      "71 Train Loss 0.0092266 Test MSE 0.004242407373407976 Test RE 0.03113251777595824\n",
      "72 Train Loss 0.008629244 Test MSE 0.0038856481487235953 Test RE 0.02979475346928108\n",
      "73 Train Loss 0.008130921 Test MSE 0.003631416042802395 Test RE 0.028803553112095214\n",
      "74 Train Loss 0.007648367 Test MSE 0.003571086313169022 Test RE 0.02856329030550979\n",
      "75 Train Loss 0.0070975255 Test MSE 0.003593813791045913 Test RE 0.028654038873902648\n",
      "76 Train Loss 0.0063977125 Test MSE 0.0034145641581371593 Test RE 0.027930306331628782\n",
      "77 Train Loss 0.00613638 Test MSE 0.0033184202907809543 Test RE 0.027534281959171465\n",
      "78 Train Loss 0.0056621395 Test MSE 0.003089759295663603 Test RE 0.026568704834443024\n",
      "79 Train Loss 0.005027933 Test MSE 0.0026437581072537605 Test RE 0.024576436876259832\n",
      "80 Train Loss 0.0046031745 Test MSE 0.0020660033231256762 Test RE 0.021725689488472012\n",
      "81 Train Loss 0.0041291756 Test MSE 0.0019082990364932013 Test RE 0.020880037571013067\n",
      "82 Train Loss 0.0038715324 Test MSE 0.0015300994269763695 Test RE 0.018696826008329982\n",
      "83 Train Loss 0.0036856523 Test MSE 0.0014349496442248712 Test RE 0.01810616153947574\n",
      "84 Train Loss 0.0033876277 Test MSE 0.0015017015247734743 Test RE 0.018522511416952287\n",
      "85 Train Loss 0.0031206822 Test MSE 0.001552858486607692 Test RE 0.01883536325008086\n",
      "86 Train Loss 0.0029250619 Test MSE 0.0015093661189699036 Test RE 0.018569720147698716\n",
      "87 Train Loss 0.0026940918 Test MSE 0.0013870554589146661 Test RE 0.0178014333764493\n",
      "88 Train Loss 0.0024939068 Test MSE 0.001342862228881175 Test RE 0.01751555042359747\n",
      "89 Train Loss 0.0022704 Test MSE 0.0010524049019953953 Test RE 0.015505989710332476\n",
      "90 Train Loss 0.0021869403 Test MSE 0.0010195561507032804 Test RE 0.01526207680470186\n",
      "91 Train Loss 0.002019598 Test MSE 0.0008316242947424867 Test RE 0.013783885103223698\n",
      "92 Train Loss 0.0019170194 Test MSE 0.000804841363522004 Test RE 0.013560109743956359\n",
      "93 Train Loss 0.0018129231 Test MSE 0.000737384879135919 Test RE 0.012979416657661396\n",
      "94 Train Loss 0.0016634808 Test MSE 0.0006955390817785912 Test RE 0.012605754042219794\n",
      "95 Train Loss 0.0015806482 Test MSE 0.0005638438798883558 Test RE 0.011349781366761777\n",
      "96 Train Loss 0.0015211464 Test MSE 0.0005145291209537618 Test RE 0.010842090801162222\n",
      "97 Train Loss 0.0014474979 Test MSE 0.0005192270958926847 Test RE 0.010891475886913147\n",
      "98 Train Loss 0.0013411387 Test MSE 0.0005139592339869899 Test RE 0.01083608484559967\n",
      "99 Train Loss 0.0012998735 Test MSE 0.0005218555279913017 Test RE 0.010919008508873635\n",
      "Training time: 75.83\n",
      "KG_stan_tune14\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.181797 Test MSE 8.947431058803216 Test RE 1.4297405695821517\n",
      "1 Train Loss 47.39603 Test MSE 8.523304874288298 Test RE 1.3954429049943593\n",
      "2 Train Loss 44.780964 Test MSE 8.679275563283422 Test RE 1.4081528513414325\n",
      "3 Train Loss 43.64949 Test MSE 8.686615893923785 Test RE 1.4087481846118146\n",
      "4 Train Loss 42.430916 Test MSE 8.481642871360899 Test RE 1.3920282574536393\n",
      "5 Train Loss 42.132652 Test MSE 8.39490007774231 Test RE 1.38489174288105\n",
      "6 Train Loss 41.8025 Test MSE 8.302889199539363 Test RE 1.377281396942095\n",
      "7 Train Loss 41.27646 Test MSE 8.607017277405834 Test RE 1.4022788947468348\n",
      "8 Train Loss 40.629032 Test MSE 8.720255309605665 Test RE 1.4114732777533854\n",
      "9 Train Loss 40.20047 Test MSE 8.720316031077296 Test RE 1.4114781919779322\n",
      "10 Train Loss 39.898647 Test MSE 8.676506006494394 Test RE 1.407928162631535\n",
      "11 Train Loss 39.12562 Test MSE 8.482799444042282 Test RE 1.39212316400638\n",
      "12 Train Loss 37.45809 Test MSE 8.082057484206697 Test RE 1.3588422063259904\n",
      "13 Train Loss 35.09029 Test MSE 8.565375253688062 Test RE 1.3988825653411618\n",
      "14 Train Loss 32.397907 Test MSE 8.421847374912929 Test RE 1.38711268588032\n",
      "15 Train Loss 30.033566 Test MSE 8.242563905220312 Test RE 1.3722689025348118\n",
      "16 Train Loss 28.969551 Test MSE 8.02104517250991 Test RE 1.3537034675490829\n",
      "17 Train Loss 28.058449 Test MSE 7.91909068838184 Test RE 1.345072577072983\n",
      "18 Train Loss 27.229246 Test MSE 7.709905427158614 Test RE 1.327188426061501\n",
      "19 Train Loss 26.33704 Test MSE 7.802351420541692 Test RE 1.3351215746831753\n",
      "20 Train Loss 25.82493 Test MSE 7.851164095239155 Test RE 1.3392914229477042\n",
      "21 Train Loss 25.035774 Test MSE 7.868518882144978 Test RE 1.3407708396669125\n",
      "22 Train Loss 24.113758 Test MSE 7.782708081909326 Test RE 1.333439852627893\n",
      "23 Train Loss 22.824987 Test MSE 7.633969190210199 Test RE 1.3206363950660336\n",
      "24 Train Loss 20.934723 Test MSE 7.785871148981024 Test RE 1.3337107950289566\n",
      "25 Train Loss 19.858572 Test MSE 7.939912247737011 Test RE 1.3468397069417495\n",
      "26 Train Loss 18.737934 Test MSE 8.159238453457595 Test RE 1.365315035963527\n",
      "27 Train Loss 17.909672 Test MSE 8.330150760312547 Test RE 1.3795406147840477\n",
      "28 Train Loss 17.375961 Test MSE 8.150051598148227 Test RE 1.364546184531082\n",
      "29 Train Loss 16.964228 Test MSE 8.19382244986808 Test RE 1.3682055092206546\n",
      "30 Train Loss 16.296848 Test MSE 8.327400275754716 Test RE 1.3793128446912863\n",
      "31 Train Loss 15.676241 Test MSE 8.452433765215556 Test RE 1.3896292547884208\n",
      "32 Train Loss 15.091667 Test MSE 8.282623183423329 Test RE 1.375599508908135\n",
      "33 Train Loss 13.843085 Test MSE 7.341122540069747 Test RE 1.2950582326526392\n",
      "34 Train Loss 12.719139 Test MSE 7.385747235754459 Test RE 1.2989884231850162\n",
      "35 Train Loss 12.123188 Test MSE 7.257124977084012 Test RE 1.287627849921053\n",
      "36 Train Loss 11.77096 Test MSE 7.389840711707353 Test RE 1.2993483489401239\n",
      "37 Train Loss 11.302667 Test MSE 7.370251496322554 Test RE 1.2976250299881449\n",
      "38 Train Loss 10.943463 Test MSE 7.341496616586378 Test RE 1.2950912279267652\n",
      "39 Train Loss 10.668095 Test MSE 7.306669141277737 Test RE 1.2920156712162099\n",
      "40 Train Loss 10.248668 Test MSE 7.234258266363661 Test RE 1.285597635191875\n",
      "41 Train Loss 10.024137 Test MSE 7.316362562725925 Test RE 1.2928724160036649\n",
      "42 Train Loss 9.807162 Test MSE 7.158602234963999 Test RE 1.2788575628070467\n",
      "43 Train Loss 9.570348 Test MSE 7.194017582055837 Test RE 1.2820170696837114\n",
      "44 Train Loss 9.39395 Test MSE 7.179419560162361 Test RE 1.2807156816410301\n",
      "45 Train Loss 9.251884 Test MSE 7.138504851881294 Test RE 1.2770611398538294\n",
      "46 Train Loss 9.076378 Test MSE 7.122671232945654 Test RE 1.2756440556829127\n",
      "47 Train Loss 8.909252 Test MSE 6.994867317891398 Test RE 1.2641476474154159\n",
      "48 Train Loss 8.784126 Test MSE 6.997960927792292 Test RE 1.2644271628938657\n",
      "49 Train Loss 8.645304 Test MSE 7.056585927311659 Test RE 1.2697124481914497\n",
      "50 Train Loss 8.492334 Test MSE 7.08840894673795 Test RE 1.272572232796649\n",
      "51 Train Loss 8.292481 Test MSE 7.024561424120219 Test RE 1.266828039983394\n",
      "52 Train Loss 8.153686 Test MSE 7.044344352594202 Test RE 1.268610638702177\n",
      "53 Train Loss 8.062098 Test MSE 6.972830949325695 Test RE 1.2621548148905342\n",
      "54 Train Loss 7.9277644 Test MSE 6.989134951659917 Test RE 1.2636295502005508\n",
      "55 Train Loss 7.7629585 Test MSE 6.869380939268979 Test RE 1.2527570649401774\n",
      "56 Train Loss 7.5976005 Test MSE 6.81036935782622 Test RE 1.2473645390234556\n",
      "57 Train Loss 7.4680853 Test MSE 6.75595226676773 Test RE 1.2423711177897963\n",
      "58 Train Loss 7.3848476 Test MSE 6.655925136420009 Test RE 1.2331396851666823\n",
      "59 Train Loss 7.270034 Test MSE 6.717065469860756 Test RE 1.2387904564613281\n",
      "60 Train Loss 7.113076 Test MSE 6.591919435004199 Test RE 1.2271962110082275\n",
      "61 Train Loss 7.0333076 Test MSE 6.558210826447022 Test RE 1.2240544784148102\n",
      "62 Train Loss 6.9142065 Test MSE 6.630598951437254 Test RE 1.2307913647998587\n",
      "63 Train Loss 6.8390255 Test MSE 6.523999613585766 Test RE 1.2208576351851153\n",
      "64 Train Loss 6.758581 Test MSE 6.511589236361836 Test RE 1.2196958849553436\n",
      "65 Train Loss 6.691496 Test MSE 6.491407868842877 Test RE 1.217804316549209\n",
      "66 Train Loss 6.62041 Test MSE 6.4404699562502765 Test RE 1.213016866539648\n",
      "67 Train Loss 6.5500674 Test MSE 6.387550113327413 Test RE 1.208023048459221\n",
      "68 Train Loss 6.458182 Test MSE 6.346988665473463 Test RE 1.2041814191868097\n",
      "69 Train Loss 6.339016 Test MSE 6.294272686038676 Test RE 1.199170226741883\n",
      "70 Train Loss 6.245364 Test MSE 6.364923057459149 Test RE 1.205881518900065\n",
      "71 Train Loss 6.1563015 Test MSE 6.350537378288582 Test RE 1.2045180116330614\n",
      "72 Train Loss 5.9988756 Test MSE 6.305046653498518 Test RE 1.2001961035688806\n",
      "73 Train Loss 5.8801227 Test MSE 6.182229212161677 Test RE 1.1884491701696456\n",
      "74 Train Loss 5.717138 Test MSE 6.193618442060716 Test RE 1.1895433784342144\n",
      "75 Train Loss 5.5375967 Test MSE 6.132125947076082 Test RE 1.183623538698758\n",
      "76 Train Loss 5.2787457 Test MSE 5.975595096767569 Test RE 1.1684190829978138\n",
      "77 Train Loss 4.049951 Test MSE 5.093966592002845 Test RE 1.0787879989549154\n",
      "78 Train Loss 3.520518 Test MSE 4.968707444653942 Test RE 1.0654419036008034\n",
      "79 Train Loss 3.0045922 Test MSE 5.0649345350560955 Test RE 1.0757094366591082\n",
      "80 Train Loss 2.7611818 Test MSE 5.035932893781358 Test RE 1.0726252777206768\n",
      "81 Train Loss 2.5588915 Test MSE 5.13247484147105 Test RE 1.0828579139736725\n",
      "82 Train Loss 2.3716445 Test MSE 5.225628814183432 Test RE 1.092640613349668\n",
      "83 Train Loss 2.291266 Test MSE 5.199309523396576 Test RE 1.0898855547325177\n",
      "84 Train Loss 2.1865344 Test MSE 5.154796125552012 Test RE 1.0852100498337198\n",
      "85 Train Loss 2.0877278 Test MSE 5.1361144523018645 Test RE 1.0832417914455688\n",
      "86 Train Loss 2.0293329 Test MSE 5.205681970107541 Test RE 1.0905532502036088\n",
      "87 Train Loss 1.9712383 Test MSE 5.243936290772147 Test RE 1.0945529193816539\n",
      "88 Train Loss 1.9218119 Test MSE 5.303496120049972 Test RE 1.1007512517763065\n",
      "89 Train Loss 1.8836023 Test MSE 5.306624231132026 Test RE 1.1010758267861511\n",
      "90 Train Loss 1.840636 Test MSE 5.312565117213844 Test RE 1.1016919940510415\n",
      "91 Train Loss 1.8121982 Test MSE 5.364484454930046 Test RE 1.1070622855589516\n",
      "92 Train Loss 1.7812967 Test MSE 5.423464911115386 Test RE 1.1131315123010577\n",
      "93 Train Loss 1.7438021 Test MSE 5.456894034054936 Test RE 1.1165567991394436\n",
      "94 Train Loss 1.711941 Test MSE 5.456560552676232 Test RE 1.1165226811423377\n",
      "95 Train Loss 1.6805342 Test MSE 5.463459989960148 Test RE 1.1172283403743288\n",
      "96 Train Loss 1.6354972 Test MSE 5.507774413837489 Test RE 1.121750139948704\n",
      "97 Train Loss 1.6066512 Test MSE 5.529835565516164 Test RE 1.12399445559889\n",
      "98 Train Loss 1.5777004 Test MSE 5.574910325135927 Test RE 1.1285661065437054\n",
      "99 Train Loss 1.5581657 Test MSE 5.583646871218142 Test RE 1.1294500588755196\n",
      "Training time: 79.32\n",
      "KG_stan_tune14\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.152 Test MSE 8.471941796834294 Test RE 1.3912319474869363\n",
      "1 Train Loss 46.649406 Test MSE 8.096330839120315 Test RE 1.3600415717976944\n",
      "2 Train Loss 44.922062 Test MSE 8.196221791305097 Test RE 1.3684058157264671\n",
      "3 Train Loss 44.538208 Test MSE 8.152036857243948 Test RE 1.364712368311814\n",
      "4 Train Loss 43.859688 Test MSE 8.264837492385668 Test RE 1.3741217683605065\n",
      "5 Train Loss 43.41038 Test MSE 8.410271089306283 Test RE 1.3861590272757638\n",
      "6 Train Loss 43.10087 Test MSE 8.296694029254487 Test RE 1.3767674743306249\n",
      "7 Train Loss 42.807827 Test MSE 8.34686420668521 Test RE 1.3809238625259586\n",
      "8 Train Loss 42.232418 Test MSE 8.268412141689696 Test RE 1.374418898970515\n",
      "9 Train Loss 40.776108 Test MSE 8.406446398023993 Test RE 1.3858438035941265\n",
      "10 Train Loss 39.01442 Test MSE 8.80172135213099 Test RE 1.4180510571892002\n",
      "11 Train Loss 36.454098 Test MSE 7.489921295658027 Test RE 1.3081172941506798\n",
      "12 Train Loss 33.764626 Test MSE 7.79601039227741 Test RE 1.334578932857129\n",
      "13 Train Loss 31.13414 Test MSE 7.2327670013127365 Test RE 1.2854651222538946\n",
      "14 Train Loss 30.523018 Test MSE 7.046002196637005 Test RE 1.268759909859141\n",
      "15 Train Loss 29.532724 Test MSE 6.668642287720324 Test RE 1.2343171728981035\n",
      "16 Train Loss 28.718107 Test MSE 6.232577020934164 Test RE 1.1932786967041504\n",
      "17 Train Loss 27.563942 Test MSE 6.27427080602399 Test RE 1.1972633547427693\n",
      "18 Train Loss 24.410042 Test MSE 6.0532515617356575 Test RE 1.1759867314251617\n",
      "19 Train Loss 22.433804 Test MSE 6.353923384139923 Test RE 1.2048390837950567\n",
      "20 Train Loss 20.3835 Test MSE 6.466583777476624 Test RE 1.215473555375634\n",
      "21 Train Loss 18.239054 Test MSE 5.85796762931085 Test RE 1.1568619685340984\n",
      "22 Train Loss 15.402743 Test MSE 5.702225621699355 Test RE 1.1413800015170799\n",
      "23 Train Loss 14.684643 Test MSE 5.433433198633382 Test RE 1.1141540063361473\n",
      "24 Train Loss 12.684843 Test MSE 4.619768683084847 Test RE 1.0273494092308721\n",
      "25 Train Loss 11.488843 Test MSE 4.247592907110871 Test RE 0.9850981506051639\n",
      "26 Train Loss 10.563272 Test MSE 4.0370911964650125 Test RE 0.9603783040288251\n",
      "27 Train Loss 9.924061 Test MSE 3.9286859558876155 Test RE 0.9473963723731075\n",
      "28 Train Loss 9.383159 Test MSE 3.9309988319630143 Test RE 0.9476752045352487\n",
      "29 Train Loss 9.122005 Test MSE 3.97977055990327 Test RE 0.9535359641164327\n",
      "30 Train Loss 8.899101 Test MSE 3.9987233041429033 Test RE 0.9558037654852571\n",
      "31 Train Loss 8.718261 Test MSE 3.9275579629440673 Test RE 0.9472603557567143\n",
      "32 Train Loss 8.54081 Test MSE 3.9358688266726705 Test RE 0.9482620458083104\n",
      "33 Train Loss 8.390485 Test MSE 3.86073006695138 Test RE 0.9391669028264309\n",
      "34 Train Loss 8.289062 Test MSE 3.840743847442542 Test RE 0.9367328098868384\n",
      "35 Train Loss 8.171435 Test MSE 3.7571488136636506 Test RE 0.9264825816665636\n",
      "36 Train Loss 8.043194 Test MSE 3.6442033025411282 Test RE 0.912450595513359\n",
      "37 Train Loss 6.5772142 Test MSE 2.725463835561135 Test RE 0.7890931477842477\n",
      "38 Train Loss 5.761923 Test MSE 2.438931263051833 Test RE 0.7464622346782555\n",
      "39 Train Loss 5.3219566 Test MSE 2.336770347954835 Test RE 0.730661252205914\n",
      "40 Train Loss 5.0481296 Test MSE 2.1294746528101314 Test RE 0.6975001378721984\n",
      "41 Train Loss 4.860607 Test MSE 2.1862349058494166 Test RE 0.7067347927932914\n",
      "42 Train Loss 4.6695805 Test MSE 2.1685512397904074 Test RE 0.7038707279496293\n",
      "43 Train Loss 4.599727 Test MSE 2.1630675726348834 Test RE 0.7029802172945782\n",
      "44 Train Loss 4.52069 Test MSE 2.159905479638275 Test RE 0.7024662014981943\n",
      "45 Train Loss 4.4742956 Test MSE 2.165684740537308 Test RE 0.7034053683870124\n",
      "46 Train Loss 4.4188294 Test MSE 2.1489233450276934 Test RE 0.7006780654558429\n",
      "47 Train Loss 4.3785863 Test MSE 2.1346057813616754 Test RE 0.698339971658491\n",
      "48 Train Loss 4.3465323 Test MSE 2.137312352658316 Test RE 0.6987825611471036\n",
      "49 Train Loss 4.2998323 Test MSE 2.128417061076683 Test RE 0.6973269115809997\n",
      "50 Train Loss 4.258686 Test MSE 2.110543392630172 Test RE 0.694392790425485\n",
      "51 Train Loss 4.224115 Test MSE 2.1132782720816543 Test RE 0.6948425480005137\n",
      "52 Train Loss 4.138277 Test MSE 2.061677414931053 Test RE 0.6863069817709441\n",
      "53 Train Loss 3.7564993 Test MSE 2.0979936731380806 Test RE 0.692325212029369\n",
      "54 Train Loss 2.671093 Test MSE 1.886023487986183 Test RE 0.6564197037372934\n",
      "55 Train Loss 2.0030005 Test MSE 1.4148363292836426 Test RE 0.5685401787273464\n",
      "56 Train Loss 1.4109951 Test MSE 0.9176133016487165 Test RE 0.4578654891092615\n",
      "57 Train Loss 1.0431956 Test MSE 0.6195315192663963 Test RE 0.3762181673083659\n",
      "58 Train Loss 0.8219846 Test MSE 0.3857766070023862 Test RE 0.29687662544433324\n",
      "59 Train Loss 0.63523275 Test MSE 0.2901517933713479 Test RE 0.257466476656523\n",
      "60 Train Loss 0.4521024 Test MSE 0.21633118591225378 Test RE 0.22231441616838005\n",
      "61 Train Loss 0.34531623 Test MSE 0.12378255926921995 Test RE 0.16816584316590777\n",
      "62 Train Loss 0.28422797 Test MSE 0.07343901944603734 Test RE 0.12953033688746438\n",
      "63 Train Loss 0.2372391 Test MSE 0.047744835800577624 Test RE 0.10444105792810365\n",
      "64 Train Loss 0.18176773 Test MSE 0.03206947595409962 Test RE 0.085596102844893\n",
      "65 Train Loss 0.14627276 Test MSE 0.026950521348513733 Test RE 0.07846783057899194\n",
      "66 Train Loss 0.12183164 Test MSE 0.016424512247120406 Test RE 0.06125679929987577\n",
      "67 Train Loss 0.10859547 Test MSE 0.01318711980373436 Test RE 0.054888711526242036\n",
      "68 Train Loss 0.09578008 Test MSE 0.011549615547466204 Test RE 0.051367901522782665\n",
      "69 Train Loss 0.08265065 Test MSE 0.010567559199278763 Test RE 0.04913550285365731\n",
      "70 Train Loss 0.075671576 Test MSE 0.010796509288233625 Test RE 0.04966492015891961\n",
      "71 Train Loss 0.06706638 Test MSE 0.008661276702368851 Test RE 0.04448350679361758\n",
      "72 Train Loss 0.06342027 Test MSE 0.009418948343794347 Test RE 0.04638838659213305\n",
      "73 Train Loss 0.05912962 Test MSE 0.007508233421361158 Test RE 0.041416838372732974\n",
      "74 Train Loss 0.05291805 Test MSE 0.006405218632676064 Test RE 0.03825384021015541\n",
      "75 Train Loss 0.049245294 Test MSE 0.005741389911744268 Test RE 0.03621734258766517\n",
      "76 Train Loss 0.044793878 Test MSE 0.005707180841893058 Test RE 0.0361092840274288\n",
      "77 Train Loss 0.042646516 Test MSE 0.005681327772889006 Test RE 0.036027405123521004\n",
      "78 Train Loss 0.03994111 Test MSE 0.006164672703846802 Test RE 0.03752866125047344\n",
      "79 Train Loss 0.03782927 Test MSE 0.0060279142786717815 Test RE 0.037110054668763444\n",
      "80 Train Loss 0.03392729 Test MSE 0.005476305444256638 Test RE 0.03537137086992427\n",
      "81 Train Loss 0.030832939 Test MSE 0.005652767976940381 Test RE 0.03593673690790462\n",
      "82 Train Loss 0.029518588 Test MSE 0.005588308757912221 Test RE 0.03573125389228793\n",
      "83 Train Loss 0.02797171 Test MSE 0.005392413519259789 Test RE 0.03509939693975023\n",
      "84 Train Loss 0.026339376 Test MSE 0.004817215133512922 Test RE 0.03317462950093096\n",
      "85 Train Loss 0.024919394 Test MSE 0.004728081870636423 Test RE 0.032866280263946314\n",
      "86 Train Loss 0.023217399 Test MSE 0.004456707696976578 Test RE 0.03190914266383573\n",
      "87 Train Loss 0.020801269 Test MSE 0.003623226394728759 Test RE 0.028771055581206673\n",
      "88 Train Loss 0.019833505 Test MSE 0.003081289742546756 Test RE 0.026532265187378022\n",
      "89 Train Loss 0.018700227 Test MSE 0.0032105669785704094 Test RE 0.02708313456425008\n",
      "90 Train Loss 0.01727731 Test MSE 0.0031854658530647358 Test RE 0.026977054994022975\n",
      "91 Train Loss 0.01605381 Test MSE 0.0027239414732782674 Test RE 0.02494634627013382\n",
      "92 Train Loss 0.0135970805 Test MSE 0.0031122902958416435 Test RE 0.026665400416648357\n",
      "93 Train Loss 0.012678885 Test MSE 0.0031528328994560838 Test RE 0.026838518391673918\n",
      "94 Train Loss 0.0120287845 Test MSE 0.002839011737455133 Test RE 0.025467813114585427\n",
      "95 Train Loss 0.011107633 Test MSE 0.0025875422674195778 Test RE 0.024313741029801564\n",
      "96 Train Loss 0.010041542 Test MSE 0.0021499439804865328 Test RE 0.022162647156453323\n",
      "97 Train Loss 0.009400174 Test MSE 0.0018135794873699177 Test RE 0.020355246114838584\n",
      "98 Train Loss 0.008965661 Test MSE 0.0018711603931591569 Test RE 0.020675859312337626\n",
      "99 Train Loss 0.008530967 Test MSE 0.0015684205017522505 Test RE 0.01892950753284794\n",
      "Training time: 77.28\n",
      "KG_stan_tune14\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.595184 Test MSE 8.579512653815694 Test RE 1.4000365374820454\n",
      "1 Train Loss 46.16095 Test MSE 8.187606276864377 Test RE 1.3676864220744633\n",
      "2 Train Loss 43.55165 Test MSE 8.386357197488369 Test RE 1.384186911636765\n",
      "3 Train Loss 42.48991 Test MSE 8.281983190339723 Test RE 1.3755463620270585\n",
      "4 Train Loss 42.278694 Test MSE 8.146804951971117 Test RE 1.3642743678505131\n",
      "5 Train Loss 41.87567 Test MSE 8.097370204579882 Test RE 1.3601288665795683\n",
      "6 Train Loss 41.273643 Test MSE 8.260031452812282 Test RE 1.3737221813172842\n",
      "7 Train Loss 40.406685 Test MSE 8.158172356415296 Test RE 1.3652258361025749\n",
      "8 Train Loss 39.4888 Test MSE 8.352288873167703 Test RE 1.3813725241121768\n",
      "9 Train Loss 38.8006 Test MSE 8.314223369969332 Test RE 1.378221131170158\n",
      "10 Train Loss 38.30506 Test MSE 8.29783027910136 Test RE 1.37686174671609\n",
      "11 Train Loss 36.035267 Test MSE 7.8780785965689795 Test RE 1.3415850650521126\n",
      "12 Train Loss 35.320034 Test MSE 7.804179077180649 Test RE 1.3352779378612436\n",
      "13 Train Loss 34.66379 Test MSE 7.357701786028264 Test RE 1.2965197925098224\n",
      "14 Train Loss 33.093567 Test MSE 7.038276890809975 Test RE 1.2680641787086184\n",
      "15 Train Loss 31.79044 Test MSE 6.230618634917753 Test RE 1.1930912073311215\n",
      "16 Train Loss 28.358648 Test MSE 5.143800159683104 Test RE 1.0840519726891278\n",
      "17 Train Loss 23.639488 Test MSE 5.000259731541492 Test RE 1.0688194347682414\n",
      "18 Train Loss 20.08475 Test MSE 4.540652249762618 Test RE 1.0185144185204222\n",
      "19 Train Loss 18.670086 Test MSE 3.5829792534332094 Test RE 0.9047533649690022\n",
      "20 Train Loss 15.265218 Test MSE 1.5212331055549908 Test RE 0.589530046096901\n",
      "21 Train Loss 11.883677 Test MSE 1.1724210301332147 Test RE 0.5175470771467569\n",
      "22 Train Loss 8.9879265 Test MSE 0.6890310518207378 Test RE 0.396759612467132\n",
      "23 Train Loss 5.13506 Test MSE 0.37847061270031457 Test RE 0.2940520029117696\n",
      "24 Train Loss 3.8126407 Test MSE 0.2884205049670049 Test RE 0.25669719717177747\n",
      "25 Train Loss 2.906507 Test MSE 0.18106206778706305 Test RE 0.20338634799791624\n",
      "26 Train Loss 2.4783735 Test MSE 0.15038671055960182 Test RE 0.1853586212081794\n",
      "27 Train Loss 2.1113198 Test MSE 0.13812718007367317 Test RE 0.17764280948344036\n",
      "28 Train Loss 1.8445077 Test MSE 0.13686246985943498 Test RE 0.17682767913517444\n",
      "29 Train Loss 1.6567411 Test MSE 0.14036763614195402 Test RE 0.17907771878416978\n",
      "30 Train Loss 1.2997266 Test MSE 0.13684810689540908 Test RE 0.17681840034518176\n",
      "31 Train Loss 1.1862477 Test MSE 0.11883286257272047 Test RE 0.16476931635702205\n",
      "32 Train Loss 0.96541196 Test MSE 0.08457764262294347 Test RE 0.13900673680817158\n",
      "33 Train Loss 0.8623551 Test MSE 0.0801818443311201 Test RE 0.13534620440116818\n",
      "34 Train Loss 0.80446416 Test MSE 0.07955520283976211 Test RE 0.13481628451310587\n",
      "35 Train Loss 0.6006796 Test MSE 0.06930658248186802 Test RE 0.12583321777218845\n",
      "36 Train Loss 0.55509216 Test MSE 0.05578901782312381 Test RE 0.11289700428421769\n",
      "37 Train Loss 0.5253252 Test MSE 0.05378563201856975 Test RE 0.11085140408143225\n",
      "38 Train Loss 0.49693143 Test MSE 0.04680013174062609 Test RE 0.10340263311741668\n",
      "39 Train Loss 0.4528004 Test MSE 0.0466563099662728 Test RE 0.10324362722718694\n",
      "40 Train Loss 0.42478633 Test MSE 0.04460054356751048 Test RE 0.10094344822249904\n",
      "41 Train Loss 0.36975932 Test MSE 0.047570444379364495 Test RE 0.10425014422713469\n",
      "42 Train Loss 0.34997657 Test MSE 0.05150433141438667 Test RE 0.10847506954400822\n",
      "43 Train Loss 0.31606233 Test MSE 0.041091844865210995 Test RE 0.09689154480532511\n",
      "44 Train Loss 0.29793853 Test MSE 0.04406515292706122 Test RE 0.10033574995029348\n",
      "45 Train Loss 0.26422334 Test MSE 0.039337787206609 Test RE 0.0948010229565666\n",
      "46 Train Loss 0.24179289 Test MSE 0.030969545863486953 Test RE 0.08411539307426553\n",
      "47 Train Loss 0.22523451 Test MSE 0.031105132984454466 Test RE 0.08429932389970929\n",
      "48 Train Loss 0.21049553 Test MSE 0.02870571691636317 Test RE 0.08098270128386326\n",
      "49 Train Loss 0.2002763 Test MSE 0.030308790486519403 Test RE 0.08321322677979145\n",
      "50 Train Loss 0.17952657 Test MSE 0.024260916764687158 Test RE 0.07444947922415993\n",
      "51 Train Loss 0.1706239 Test MSE 0.0242771694541703 Test RE 0.07447441236453493\n",
      "52 Train Loss 0.1612736 Test MSE 0.02262199454358631 Test RE 0.07189083152884936\n",
      "53 Train Loss 0.14802316 Test MSE 0.022846665608819344 Test RE 0.0722469425821667\n",
      "54 Train Loss 0.13650462 Test MSE 0.020983471012134262 Test RE 0.06923835241363596\n",
      "55 Train Loss 0.13327177 Test MSE 0.0207971537179327 Test RE 0.0689302750098431\n",
      "56 Train Loss 0.12555927 Test MSE 0.02156008005207335 Test RE 0.07018321273948398\n",
      "57 Train Loss 0.12110901 Test MSE 0.01921163181915491 Test RE 0.06625065674256769\n",
      "58 Train Loss 0.11506409 Test MSE 0.01757431065590586 Test RE 0.06336467472234715\n",
      "59 Train Loss 0.10033297 Test MSE 0.013553138986359526 Test RE 0.05564523825766046\n",
      "60 Train Loss 0.09133725 Test MSE 0.013923527064057493 Test RE 0.0564004659549125\n",
      "61 Train Loss 0.08827922 Test MSE 0.012881030202101153 Test RE 0.054247953554618075\n",
      "62 Train Loss 0.080277525 Test MSE 0.011763568407994562 Test RE 0.051841505059475025\n",
      "63 Train Loss 0.07457661 Test MSE 0.009866553973070543 Test RE 0.04747782422614585\n",
      "64 Train Loss 0.0711731 Test MSE 0.00922358833926016 Test RE 0.045904791173706515\n",
      "65 Train Loss 0.06880908 Test MSE 0.008667231653975283 Test RE 0.04449879620321137\n",
      "66 Train Loss 0.061868936 Test MSE 0.007423139093744958 Test RE 0.04118147137299442\n",
      "67 Train Loss 0.057537973 Test MSE 0.007376569879267326 Test RE 0.04105209173707947\n",
      "68 Train Loss 0.054945458 Test MSE 0.007113941254039698 Test RE 0.040314678201643764\n",
      "69 Train Loss 0.053203866 Test MSE 0.0071936564990971895 Test RE 0.04053992196363783\n",
      "70 Train Loss 0.051828343 Test MSE 0.007069588171908521 Test RE 0.040188807329617236\n",
      "71 Train Loss 0.048686642 Test MSE 0.006710210654612206 Test RE 0.039154000082739775\n",
      "72 Train Loss 0.046986766 Test MSE 0.006413281234199408 Test RE 0.03827790874637875\n",
      "73 Train Loss 0.04515985 Test MSE 0.006577241942316173 Test RE 0.03876412354752009\n",
      "74 Train Loss 0.04257449 Test MSE 0.005957763569924567 Test RE 0.03689348597104708\n",
      "75 Train Loss 0.041051403 Test MSE 0.0062404933600987205 Test RE 0.03775874255882744\n",
      "76 Train Loss 0.037926577 Test MSE 0.0057225540393751875 Test RE 0.03615788436528337\n",
      "77 Train Loss 0.03648069 Test MSE 0.005696165355230785 Test RE 0.0360744197517171\n",
      "78 Train Loss 0.035856336 Test MSE 0.005381214575114525 Test RE 0.035062930848876496\n",
      "79 Train Loss 0.034936506 Test MSE 0.0051087695611318085 Test RE 0.0341638036426715\n",
      "80 Train Loss 0.03253812 Test MSE 0.003851110361945251 Test RE 0.029662041795175252\n",
      "81 Train Loss 0.030253619 Test MSE 0.003948504792830664 Test RE 0.030034775842131763\n",
      "82 Train Loss 0.029028658 Test MSE 0.0038762354267814366 Test RE 0.02975864369200678\n",
      "83 Train Loss 0.028429877 Test MSE 0.004077438134447517 Test RE 0.030521210240532726\n",
      "84 Train Loss 0.027851405 Test MSE 0.003944587800755707 Test RE 0.030019874610353443\n",
      "85 Train Loss 0.027611073 Test MSE 0.00397471082894515 Test RE 0.03013428069320398\n",
      "86 Train Loss 0.027254608 Test MSE 0.003705196290103363 Test RE 0.029094685735352305\n",
      "87 Train Loss 0.026889158 Test MSE 0.0036990191349791234 Test RE 0.02907042287017579\n",
      "88 Train Loss 0.02607029 Test MSE 0.003906529059067623 Test RE 0.02987470254929817\n",
      "89 Train Loss 0.024978407 Test MSE 0.0037515025415663806 Test RE 0.029275928834811515\n",
      "90 Train Loss 0.024029246 Test MSE 0.004248129377557067 Test RE 0.03115350590290721\n",
      "91 Train Loss 0.02318816 Test MSE 0.004102392445258533 Test RE 0.030614464138328645\n",
      "92 Train Loss 0.02255725 Test MSE 0.004182678132528697 Test RE 0.03091258212776139\n",
      "93 Train Loss 0.022323009 Test MSE 0.004228499317243931 Test RE 0.031081444384723354\n",
      "94 Train Loss 0.022196759 Test MSE 0.004094828931010828 Test RE 0.030586229423478408\n",
      "95 Train Loss 0.021915004 Test MSE 0.004219253019036711 Test RE 0.03104744348284501\n",
      "96 Train Loss 0.020457348 Test MSE 0.003370441083768548 Test RE 0.027749261542368328\n",
      "97 Train Loss 0.018692605 Test MSE 0.0030038703381954266 Test RE 0.02619682455201467\n",
      "98 Train Loss 0.01766056 Test MSE 0.003023354869570298 Test RE 0.026281649750620008\n",
      "99 Train Loss 0.016776387 Test MSE 0.0032079785305732912 Test RE 0.027072214776345346\n",
      "Training time: 75.78\n",
      "KG_stan_tune14\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.648354 Test MSE 8.375325629679617 Test RE 1.3832762196492194\n",
      "1 Train Loss 55.611122 Test MSE 9.326317793344026 Test RE 1.4596985117561943\n",
      "2 Train Loss 47.45307 Test MSE 9.076874983656666 Test RE 1.4400455758109354\n",
      "3 Train Loss 46.44953 Test MSE 8.65266069775744 Test RE 1.405992154062291\n",
      "4 Train Loss 45.762756 Test MSE 8.476773925756838 Test RE 1.3916286483835136\n",
      "5 Train Loss 45.25702 Test MSE 8.08778860393557 Test RE 1.35932390961054\n",
      "6 Train Loss 45.11631 Test MSE 8.3534426058852 Test RE 1.3814679278791562\n",
      "7 Train Loss 44.176796 Test MSE 8.217815409676104 Test RE 1.3702072186839986\n",
      "8 Train Loss 43.184967 Test MSE 8.342636608567734 Test RE 1.3805741065946047\n",
      "9 Train Loss 40.31112 Test MSE 8.05389549346799 Test RE 1.3564726923788504\n",
      "10 Train Loss 39.319016 Test MSE 7.992975778416009 Test RE 1.3513327704345295\n",
      "11 Train Loss 38.794632 Test MSE 7.9632920918394685 Test RE 1.3488211996163122\n",
      "12 Train Loss 37.972183 Test MSE 7.946842593873122 Test RE 1.3474273727211892\n",
      "13 Train Loss 37.192173 Test MSE 7.741400048567037 Test RE 1.3298964162766986\n",
      "14 Train Loss 36.350986 Test MSE 7.890658873111933 Test RE 1.3426558070159733\n",
      "15 Train Loss 35.083202 Test MSE 7.494630910862948 Test RE 1.3085284974666218\n",
      "16 Train Loss 31.838224 Test MSE 7.370549858764164 Test RE 1.2976512949435695\n",
      "17 Train Loss 29.011555 Test MSE 7.411156074683435 Test RE 1.3012209291334644\n",
      "18 Train Loss 26.583248 Test MSE 6.982626045305185 Test RE 1.2630410108257772\n",
      "19 Train Loss 24.115059 Test MSE 5.915271831621035 Test RE 1.1625065641130305\n",
      "20 Train Loss 21.611633 Test MSE 5.6495215060954145 Test RE 1.136093024668521\n",
      "21 Train Loss 20.111717 Test MSE 5.761682166657759 Test RE 1.1473150989002718\n",
      "22 Train Loss 19.14939 Test MSE 5.447453756154999 Test RE 1.1155905746629282\n",
      "23 Train Loss 18.70134 Test MSE 5.587493915066189 Test RE 1.1298390784394403\n",
      "24 Train Loss 18.328632 Test MSE 5.656431070986953 Test RE 1.1367875533782454\n",
      "25 Train Loss 17.864996 Test MSE 5.968201450534063 Test RE 1.1676960126506135\n",
      "26 Train Loss 17.567131 Test MSE 6.09569822487055 Test RE 1.1801026607731766\n",
      "27 Train Loss 17.191778 Test MSE 6.017666735959755 Test RE 1.1725250410315096\n",
      "28 Train Loss 16.881636 Test MSE 5.8946806726980725 Test RE 1.16048144793804\n",
      "29 Train Loss 16.44843 Test MSE 5.887540438265688 Test RE 1.1597783886191668\n",
      "30 Train Loss 16.223654 Test MSE 5.98345795735513 Test RE 1.1691875500732412\n",
      "31 Train Loss 15.80781 Test MSE 5.816208092021373 Test RE 1.1527311480502997\n",
      "32 Train Loss 15.019197 Test MSE 5.807411675048356 Test RE 1.151859124519842\n",
      "33 Train Loss 14.667718 Test MSE 5.78080915587419 Test RE 1.149217885333106\n",
      "34 Train Loss 14.390858 Test MSE 5.80095239795399 Test RE 1.1512183702857963\n",
      "35 Train Loss 14.10306 Test MSE 5.790774096980997 Test RE 1.1502079679758672\n",
      "36 Train Loss 12.994385 Test MSE 5.256819430776466 Test RE 1.0958966264223013\n",
      "37 Train Loss 11.875373 Test MSE 3.864608877052293 Test RE 0.9396385669272453\n",
      "38 Train Loss 10.538652 Test MSE 3.331407349878023 Test RE 0.8724126014479213\n",
      "39 Train Loss 9.784689 Test MSE 3.3475425566638704 Test RE 0.8745227538461605\n",
      "40 Train Loss 9.419174 Test MSE 3.313525520728323 Test RE 0.8700680482152757\n",
      "41 Train Loss 9.239021 Test MSE 3.2617945559385784 Test RE 0.8632495528191655\n",
      "42 Train Loss 9.04084 Test MSE 3.3168389181202897 Test RE 0.8705029567215532\n",
      "43 Train Loss 8.88374 Test MSE 3.2875037265650335 Test RE 0.8666449030647445\n",
      "44 Train Loss 8.775112 Test MSE 3.2864066169909494 Test RE 0.8665002821245569\n",
      "45 Train Loss 8.693148 Test MSE 3.288994555366546 Test RE 0.8668413853877273\n",
      "46 Train Loss 8.572667 Test MSE 3.298418471281675 Test RE 0.8680823720928942\n",
      "47 Train Loss 8.476876 Test MSE 3.2932705801219435 Test RE 0.8674046929872257\n",
      "48 Train Loss 8.395802 Test MSE 3.2786888309273534 Test RE 0.8654822409320747\n",
      "49 Train Loss 8.25322 Test MSE 3.2515118746231098 Test RE 0.8618877983209465\n",
      "50 Train Loss 7.975839 Test MSE 3.1826046261850847 Test RE 0.8527061693835709\n",
      "51 Train Loss 7.725093 Test MSE 3.163172666484131 Test RE 0.8500990089328992\n",
      "52 Train Loss 7.4026546 Test MSE 3.0547400849698807 Test RE 0.8354013874354975\n",
      "53 Train Loss 6.8846374 Test MSE 2.994077453124568 Test RE 0.8270648725727021\n",
      "54 Train Loss 4.8933926 Test MSE 1.895624753505 Test RE 0.658088415501637\n",
      "55 Train Loss 3.814655 Test MSE 1.7672109825915185 Test RE 0.6354073895591645\n",
      "56 Train Loss 3.3137102 Test MSE 1.6371322977794533 Test RE 0.6115753161766126\n",
      "57 Train Loss 2.9913347 Test MSE 1.5561227253656218 Test RE 0.5962521840320367\n",
      "58 Train Loss 2.791816 Test MSE 1.496571518326965 Test RE 0.584731914527084\n",
      "59 Train Loss 2.6616678 Test MSE 1.5161184971595894 Test RE 0.5885381685271843\n",
      "60 Train Loss 2.4833138 Test MSE 1.6007024994525356 Test RE 0.6047325868857216\n",
      "61 Train Loss 2.375359 Test MSE 1.5864291080743471 Test RE 0.6020303630097323\n",
      "62 Train Loss 2.2627134 Test MSE 1.601026534997026 Test RE 0.604793792805368\n",
      "63 Train Loss 2.1880136 Test MSE 1.5377163550273405 Test RE 0.592715353269801\n",
      "64 Train Loss 2.070978 Test MSE 1.488666023774782 Test RE 0.5831854746517043\n",
      "65 Train Loss 1.9791591 Test MSE 1.532048204068183 Test RE 0.5916219455851062\n",
      "66 Train Loss 1.9042106 Test MSE 1.4765288083587111 Test RE 0.5808032297028755\n",
      "67 Train Loss 1.8216084 Test MSE 1.4424662913445174 Test RE 0.5740647719676066\n",
      "68 Train Loss 1.7627728 Test MSE 1.383091803155412 Test RE 0.5621258587354607\n",
      "69 Train Loss 1.6608521 Test MSE 1.3311981637594805 Test RE 0.5514795534078203\n",
      "70 Train Loss 1.615968 Test MSE 1.2570029327826233 Test RE 0.535890682135996\n",
      "71 Train Loss 1.5587448 Test MSE 1.2297329969016682 Test RE 0.5300458926554159\n",
      "72 Train Loss 1.504799 Test MSE 1.2010071475960555 Test RE 0.5238185286003185\n",
      "73 Train Loss 1.440638 Test MSE 1.1733357379372755 Test RE 0.5177489295693406\n",
      "74 Train Loss 1.2923336 Test MSE 1.0980006484832165 Test RE 0.5008519380107862\n",
      "75 Train Loss 1.1723684 Test MSE 1.0332236438981042 Test RE 0.4858533797902939\n",
      "76 Train Loss 1.1150341 Test MSE 1.0340274261919724 Test RE 0.48604232456809043\n",
      "77 Train Loss 1.058041 Test MSE 1.0326063749950716 Test RE 0.48570822874295994\n",
      "78 Train Loss 1.0141001 Test MSE 1.0160721560171422 Test RE 0.481803926992261\n",
      "79 Train Loss 0.9661364 Test MSE 0.975962444473607 Test RE 0.47219851107577415\n",
      "80 Train Loss 0.92774904 Test MSE 0.9380708997212377 Test RE 0.46294126299669114\n",
      "81 Train Loss 0.89343035 Test MSE 0.9551005270896485 Test RE 0.4671244533734656\n",
      "82 Train Loss 0.838982 Test MSE 0.9062024806211592 Test RE 0.4550097298308213\n",
      "83 Train Loss 0.7897856 Test MSE 0.8577376487426837 Test RE 0.44267530663313825\n",
      "84 Train Loss 0.75856924 Test MSE 0.859752235474356 Test RE 0.4431948622120137\n",
      "85 Train Loss 0.72206503 Test MSE 0.8780515176551833 Test RE 0.4478865896148515\n",
      "86 Train Loss 0.69231516 Test MSE 0.82857912919055 Test RE 0.43508594609400875\n",
      "87 Train Loss 0.6692894 Test MSE 0.7767626651544122 Test RE 0.42126194817537144\n",
      "88 Train Loss 0.65113693 Test MSE 0.7616064201294809 Test RE 0.4171318566329456\n",
      "89 Train Loss 0.62352127 Test MSE 0.6916629106162954 Test RE 0.39751663208049354\n",
      "90 Train Loss 0.60336846 Test MSE 0.6404420805159479 Test RE 0.38251457706252867\n",
      "91 Train Loss 0.5475528 Test MSE 0.4024863069175978 Test RE 0.3032379940948822\n",
      "92 Train Loss 0.51762784 Test MSE 0.404946031534125 Test RE 0.3041631756887845\n",
      "93 Train Loss 0.45410803 Test MSE 0.23710147571488324 Test RE 0.23274222873185824\n",
      "94 Train Loss 0.37909132 Test MSE 0.10285516030760761 Test RE 0.15329256915734096\n",
      "95 Train Loss 0.31520417 Test MSE 0.07442522681155181 Test RE 0.13039716329261022\n",
      "96 Train Loss 0.262788 Test MSE 0.058830342713544356 Test RE 0.1159334471891386\n",
      "97 Train Loss 0.2098091 Test MSE 0.045083928706656104 Test RE 0.10148899162202384\n",
      "98 Train Loss 0.17382944 Test MSE 0.04539300924278036 Test RE 0.1018362849226872\n",
      "99 Train Loss 0.15018874 Test MSE 0.031232163156719468 Test RE 0.08447128340792884\n",
      "Training time: 76.60\n",
      "KG_stan_tune14\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.370728 Test MSE 8.619980722378681 Test RE 1.403334517445384\n",
      "1 Train Loss 53.70762 Test MSE 7.75459674164621 Test RE 1.3310294646697638\n",
      "2 Train Loss 46.025406 Test MSE 8.16647238239208 Test RE 1.365920141687466\n",
      "3 Train Loss 43.24572 Test MSE 8.125699713703405 Test RE 1.3625060667757563\n",
      "4 Train Loss 42.730793 Test MSE 8.17918563417985 Test RE 1.3669829343305107\n",
      "5 Train Loss 42.09782 Test MSE 8.172561160808971 Test RE 1.366429249846654\n",
      "6 Train Loss 41.17115 Test MSE 8.171040244813687 Test RE 1.3663020974913425\n",
      "7 Train Loss 39.465805 Test MSE 7.388900730732096 Test RE 1.2992657083516854\n",
      "8 Train Loss 37.467583 Test MSE 7.485618217511569 Test RE 1.3077414731354116\n",
      "9 Train Loss 34.01188 Test MSE 5.879303672762769 Test RE 1.158966830193315\n",
      "10 Train Loss 28.274094 Test MSE 5.176218200274229 Test RE 1.0874626460164327\n",
      "11 Train Loss 25.285435 Test MSE 4.959894681268261 Test RE 1.064496622094299\n",
      "12 Train Loss 22.56874 Test MSE 5.230637440297047 Test RE 1.0931641214086307\n",
      "13 Train Loss 19.745243 Test MSE 4.146205595807587 Test RE 0.9732703139124814\n",
      "14 Train Loss 17.99198 Test MSE 3.935453435364428 Test RE 0.9482120047344461\n",
      "15 Train Loss 16.696468 Test MSE 3.696600878686576 Test RE 0.9189869441137302\n",
      "16 Train Loss 15.173019 Test MSE 3.2782239892697325 Test RE 0.8654208861526342\n",
      "17 Train Loss 12.707675 Test MSE 3.3756475059447033 Test RE 0.8781861941798453\n",
      "18 Train Loss 11.8980255 Test MSE 3.2659973016765034 Test RE 0.8638055121867511\n",
      "19 Train Loss 10.645414 Test MSE 3.761370450491635 Test RE 0.927002946322617\n",
      "20 Train Loss 9.781626 Test MSE 3.812331578692649 Test RE 0.9332615931760903\n",
      "21 Train Loss 8.999892 Test MSE 3.864606846379538 Test RE 0.9396383200589661\n",
      "22 Train Loss 8.497043 Test MSE 3.8776329525891846 Test RE 0.941220567936511\n",
      "23 Train Loss 8.045214 Test MSE 3.870157911365249 Test RE 0.9403129192982609\n",
      "24 Train Loss 7.7419906 Test MSE 3.931670344574046 Test RE 0.9477561443552933\n",
      "25 Train Loss 7.530568 Test MSE 3.921771188706998 Test RE 0.9465622626321277\n",
      "26 Train Loss 7.1833296 Test MSE 3.710116137723596 Test RE 0.9206653799402316\n",
      "27 Train Loss 6.438642 Test MSE 3.5617767584324955 Test RE 0.9020724267330306\n",
      "28 Train Loss 5.2538958 Test MSE 3.1952997213857137 Test RE 0.8544051570990412\n",
      "29 Train Loss 4.4811964 Test MSE 3.0017494146803405 Test RE 0.8281238215305653\n",
      "30 Train Loss 4.244692 Test MSE 2.737600143073526 Test RE 0.7908480857086138\n",
      "31 Train Loss 4.045833 Test MSE 2.5301148457988685 Test RE 0.7602880733180843\n",
      "32 Train Loss 3.900457 Test MSE 2.3371801246702577 Test RE 0.7307253138804732\n",
      "33 Train Loss 3.752897 Test MSE 2.13112559312562 Test RE 0.6977704646386403\n",
      "34 Train Loss 3.650152 Test MSE 1.9904459054961603 Test RE 0.6743467206844217\n",
      "35 Train Loss 3.5224586 Test MSE 1.86171061238375 Test RE 0.6521750009155184\n",
      "36 Train Loss 3.4695263 Test MSE 1.8110965000318933 Test RE 0.6432486092787999\n",
      "37 Train Loss 3.408688 Test MSE 1.8297946154540183 Test RE 0.6465605952229594\n",
      "38 Train Loss 3.3686528 Test MSE 1.7770420043489932 Test RE 0.6371723288863735\n",
      "39 Train Loss 3.3384154 Test MSE 1.776301605725188 Test RE 0.6370395771945213\n",
      "40 Train Loss 3.2991362 Test MSE 1.7653932019122407 Test RE 0.635080510521735\n",
      "41 Train Loss 3.2746058 Test MSE 1.7524831300194117 Test RE 0.6327541224078655\n",
      "42 Train Loss 3.2402442 Test MSE 1.742067500581504 Test RE 0.6308709789902679\n",
      "43 Train Loss 3.2140472 Test MSE 1.7227288828332457 Test RE 0.6273595707491949\n",
      "44 Train Loss 3.1811888 Test MSE 1.7200296990519406 Test RE 0.6268679023830779\n",
      "45 Train Loss 3.1082664 Test MSE 1.6905852840233067 Test RE 0.6214792062883553\n",
      "46 Train Loss 3.0459182 Test MSE 1.653253118368372 Test RE 0.6145790270343606\n",
      "47 Train Loss 2.9783123 Test MSE 1.5767306336520066 Test RE 0.6001873159043464\n",
      "48 Train Loss 2.7644897 Test MSE 1.2507256218263583 Test RE 0.5345509228290007\n",
      "49 Train Loss 1.8833812 Test MSE 0.6617261749310357 Test RE 0.3888187655882531\n",
      "50 Train Loss 1.4980913 Test MSE 0.6493789291269422 Test RE 0.3851741710739381\n",
      "51 Train Loss 1.3088255 Test MSE 0.5396570064210922 Test RE 0.3511292187784376\n",
      "52 Train Loss 0.88689214 Test MSE 0.1770549585010672 Test RE 0.20112317078387493\n",
      "53 Train Loss 0.48259395 Test MSE 0.07097188951652163 Test RE 0.12733601199505531\n",
      "54 Train Loss 0.2530907 Test MSE 0.05832656778004271 Test RE 0.11543600036180837\n",
      "55 Train Loss 0.1444235 Test MSE 0.03307553209463742 Test RE 0.08692835875628865\n",
      "56 Train Loss 0.10350984 Test MSE 0.023483501491059815 Test RE 0.07324694007802894\n",
      "57 Train Loss 0.07421067 Test MSE 0.011268340793915487 Test RE 0.050738549413105606\n",
      "58 Train Loss 0.060221255 Test MSE 0.00952932104052482 Test RE 0.04665938814722793\n",
      "59 Train Loss 0.04434831 Test MSE 0.0054655791067613636 Test RE 0.035336713268083145\n",
      "60 Train Loss 0.040163618 Test MSE 0.005126554436416061 Test RE 0.03422321825298629\n",
      "61 Train Loss 0.03319957 Test MSE 0.004304749531439073 Test RE 0.03136042964570912\n",
      "62 Train Loss 0.025334328 Test MSE 0.0036940510665390753 Test RE 0.029050894399138254\n",
      "63 Train Loss 0.020830575 Test MSE 0.0028275854751232555 Test RE 0.025416510877659858\n",
      "64 Train Loss 0.015519181 Test MSE 0.002461019778341651 Test RE 0.02371185946144221\n",
      "65 Train Loss 0.013555344 Test MSE 0.0024800807276872017 Test RE 0.023803508213047095\n",
      "66 Train Loss 0.011486748 Test MSE 0.002290834025784935 Test RE 0.022877305557624072\n",
      "67 Train Loss 0.010091465 Test MSE 0.0018562931151918179 Test RE 0.020593555629353475\n",
      "68 Train Loss 0.00859043 Test MSE 0.001669975005326581 Test RE 0.019532734449839603\n",
      "69 Train Loss 0.0077570835 Test MSE 0.0017066714491847292 Test RE 0.01974617683186746\n",
      "70 Train Loss 0.007185149 Test MSE 0.001656397688405436 Test RE 0.019453169376236992\n",
      "71 Train Loss 0.0061467467 Test MSE 0.0013332106894422457 Test RE 0.01745249225015125\n",
      "72 Train Loss 0.005632818 Test MSE 0.0011336899244864618 Test RE 0.01609367414473829\n",
      "73 Train Loss 0.005154076 Test MSE 0.0011985502731382935 Test RE 0.016547644716961803\n",
      "74 Train Loss 0.004799328 Test MSE 0.0012062835440810706 Test RE 0.01660094313452927\n",
      "75 Train Loss 0.0044638617 Test MSE 0.0011641095560346662 Test RE 0.016308160892139194\n",
      "76 Train Loss 0.004013393 Test MSE 0.001057939309969317 Test RE 0.015546707852786234\n",
      "77 Train Loss 0.0036007848 Test MSE 0.0010042884594139892 Test RE 0.015147372176977928\n",
      "78 Train Loss 0.0034531725 Test MSE 0.000920419736596654 Test RE 0.014501102476254567\n",
      "79 Train Loss 0.0032379322 Test MSE 0.000878273589077209 Test RE 0.014165208515541261\n",
      "80 Train Loss 0.0030690602 Test MSE 0.0007766993383447179 Test RE 0.0133209294397732\n",
      "81 Train Loss 0.0029110385 Test MSE 0.0006867907896075835 Test RE 0.012526227395750303\n",
      "82 Train Loss 0.0025221189 Test MSE 0.00044524966491893083 Test RE 0.010085788597760338\n",
      "83 Train Loss 0.0024077843 Test MSE 0.00047420014343304526 Test RE 0.010408518076384751\n",
      "84 Train Loss 0.0022731144 Test MSE 0.0004710779212788882 Test RE 0.010374195675020795\n",
      "85 Train Loss 0.0020164063 Test MSE 0.0003975314638143412 Test RE 0.009530020047384829\n",
      "86 Train Loss 0.0018661224 Test MSE 0.00038663217367303725 Test RE 0.009398467756707468\n",
      "87 Train Loss 0.0017373424 Test MSE 0.00044075462714508946 Test RE 0.010034748688625722\n",
      "88 Train Loss 0.00168076 Test MSE 0.0004635143049370432 Test RE 0.010290574738444865\n",
      "89 Train Loss 0.0016161011 Test MSE 0.0004656890451005397 Test RE 0.010314687411165644\n",
      "90 Train Loss 0.0015095338 Test MSE 0.0004644964443471986 Test RE 0.01030147130706528\n",
      "91 Train Loss 0.0013956815 Test MSE 0.0004516185205239669 Test RE 0.010157666086186415\n",
      "92 Train Loss 0.001352546 Test MSE 0.00042171657115394563 Test RE 0.009815634844565192\n",
      "93 Train Loss 0.0013037553 Test MSE 0.00039084595555361314 Test RE 0.009449544431732055\n",
      "94 Train Loss 0.0012205992 Test MSE 0.00036350656859602474 Test RE 0.00911305920521154\n",
      "95 Train Loss 0.0011638692 Test MSE 0.00034295267944151666 Test RE 0.008851668896207981\n",
      "96 Train Loss 0.0011276865 Test MSE 0.00032330999925371865 Test RE 0.008594440881768795\n",
      "97 Train Loss 0.0010936655 Test MSE 0.00032713374847657685 Test RE 0.008645114214527667\n",
      "98 Train Loss 0.0010642321 Test MSE 0.0003101732716719344 Test RE 0.008418025670067317\n",
      "99 Train Loss 0.0010180317 Test MSE 0.00027932677294481063 Test RE 0.00798848349586225\n",
      "Training time: 76.11\n",
      "KG_stan_tune14\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.69419 Test MSE 7.9111909817998605 Test RE 1.3444015196025936\n",
      "1 Train Loss 54.957268 Test MSE 7.7230279032504905 Test RE 1.32831740191113\n",
      "2 Train Loss 44.89978 Test MSE 7.991905680616033 Test RE 1.3512423093429728\n",
      "3 Train Loss 38.504997 Test MSE 8.082287967962454 Test RE 1.3588615818886458\n",
      "4 Train Loss 35.839523 Test MSE 8.144212900877973 Test RE 1.3640573164902638\n",
      "5 Train Loss 33.45039 Test MSE 7.969562256333027 Test RE 1.3493521148810645\n",
      "6 Train Loss 31.991463 Test MSE 7.933993862378264 Test RE 1.3463376483472422\n",
      "7 Train Loss 31.144215 Test MSE 8.350733403547707 Test RE 1.381243889729682\n",
      "8 Train Loss 30.352205 Test MSE 8.42705279064456 Test RE 1.3875412962848963\n",
      "9 Train Loss 29.623463 Test MSE 8.056075794714722 Test RE 1.3566562879427282\n",
      "10 Train Loss 29.04335 Test MSE 8.070427956005044 Test RE 1.3578642138634511\n",
      "11 Train Loss 28.280025 Test MSE 8.636376875160089 Test RE 1.404668531797399\n",
      "12 Train Loss 27.198965 Test MSE 8.651694905293983 Test RE 1.4059136848741967\n",
      "13 Train Loss 26.01397 Test MSE 8.711558305129723 Test RE 1.41076924723935\n",
      "14 Train Loss 25.380016 Test MSE 8.867509348854647 Test RE 1.4233407646724288\n",
      "15 Train Loss 25.04723 Test MSE 8.91557244961263 Test RE 1.4271929017366431\n",
      "16 Train Loss 24.002571 Test MSE 9.048392709095985 Test RE 1.437784445195158\n",
      "17 Train Loss 22.800589 Test MSE 8.997309789162143 Test RE 1.433720177411903\n",
      "18 Train Loss 21.661835 Test MSE 9.122680572137876 Test RE 1.4436745299697151\n",
      "19 Train Loss 20.244795 Test MSE 8.822751126543789 Test RE 1.4197441068235364\n",
      "20 Train Loss 17.770458 Test MSE 7.7581206836039165 Test RE 1.331331861943216\n",
      "21 Train Loss 16.412445 Test MSE 7.646619298176616 Test RE 1.321730143115965\n",
      "22 Train Loss 15.310265 Test MSE 7.567002840257682 Test RE 1.314831223436824\n",
      "23 Train Loss 14.786501 Test MSE 7.258153861365403 Test RE 1.2877191238832444\n",
      "24 Train Loss 14.304092 Test MSE 7.142363383282455 Test RE 1.2774062341643948\n",
      "25 Train Loss 13.888251 Test MSE 6.848346088008297 Test RE 1.2508375497322666\n",
      "26 Train Loss 13.044441 Test MSE 6.713552058684721 Test RE 1.2384664347930001\n",
      "27 Train Loss 10.692814 Test MSE 6.021372102328391 Test RE 1.1728859754642207\n",
      "28 Train Loss 9.245145 Test MSE 5.9770776325759805 Test RE 1.1685640154835824\n",
      "29 Train Loss 8.574545 Test MSE 5.920694424255636 Test RE 1.1630392831226894\n",
      "30 Train Loss 8.2499275 Test MSE 5.825401866419688 Test RE 1.1536418587030495\n",
      "31 Train Loss 7.8336353 Test MSE 5.710330825311778 Test RE 1.1421908982484934\n",
      "32 Train Loss 7.1517296 Test MSE 5.731886715092222 Test RE 1.1443446919829565\n",
      "33 Train Loss 4.9669523 Test MSE 5.123635452130946 Test RE 1.0819250377490213\n",
      "34 Train Loss 4.1799893 Test MSE 4.9767536159093835 Test RE 1.0663042264804568\n",
      "35 Train Loss 3.7496195 Test MSE 4.882063580852375 Test RE 1.056111510075877\n",
      "36 Train Loss 3.4211411 Test MSE 5.0084558396548395 Test RE 1.0696950465640176\n",
      "37 Train Loss 3.1019638 Test MSE 5.069444188841926 Test RE 1.076188218543636\n",
      "38 Train Loss 2.9396737 Test MSE 5.1304834893778235 Test RE 1.0826478242370556\n",
      "39 Train Loss 2.782521 Test MSE 5.260476023861461 Test RE 1.0962777077463088\n",
      "40 Train Loss 2.4989588 Test MSE 5.192281223115336 Test RE 1.0891486652155085\n",
      "41 Train Loss 2.3016365 Test MSE 5.231389626332551 Test RE 1.0932427192121486\n",
      "42 Train Loss 2.1712136 Test MSE 5.218201467329842 Test RE 1.091863835392817\n",
      "43 Train Loss 2.0838773 Test MSE 5.23664236353718 Test RE 1.0937914334497312\n",
      "44 Train Loss 2.0330129 Test MSE 5.231864580545742 Test RE 1.0932923454575432\n",
      "45 Train Loss 1.9679215 Test MSE 5.270003549464208 Test RE 1.0972700218325668\n",
      "46 Train Loss 1.8880682 Test MSE 5.295308714070608 Test RE 1.0999012673411066\n",
      "47 Train Loss 1.8240443 Test MSE 5.405609127379132 Test RE 1.1112976088583575\n",
      "48 Train Loss 1.7549591 Test MSE 5.513945201321276 Test RE 1.1223783559441745\n",
      "49 Train Loss 1.6819618 Test MSE 5.5119526837751565 Test RE 1.122175546471563\n",
      "50 Train Loss 1.5968382 Test MSE 5.632893843340088 Test RE 1.1344199190948818\n",
      "51 Train Loss 1.5240085 Test MSE 5.7710652513264895 Test RE 1.1482489386225183\n",
      "52 Train Loss 1.4409151 Test MSE 5.960467014235408 Test RE 1.166939134849033\n",
      "53 Train Loss 1.3553843 Test MSE 6.048263068642266 Test RE 1.1755020653945558\n",
      "54 Train Loss 1.3044446 Test MSE 6.1468934820308325 Test RE 1.185047897177713\n",
      "55 Train Loss 1.2532717 Test MSE 6.173466938834224 Test RE 1.1876066578186883\n",
      "56 Train Loss 1.1956477 Test MSE 6.283157206391474 Test RE 1.1981109111611976\n",
      "57 Train Loss 1.1515003 Test MSE 6.312495873469741 Test RE 1.2009048917900385\n",
      "58 Train Loss 1.1165925 Test MSE 6.315714915307678 Test RE 1.2012110520204007\n",
      "59 Train Loss 1.0922223 Test MSE 6.309201317990149 Test RE 1.2005914686818637\n",
      "60 Train Loss 1.067329 Test MSE 6.320066216903214 Test RE 1.2016247764896275\n",
      "61 Train Loss 1.0513806 Test MSE 6.326467692550137 Test RE 1.2022331739851193\n",
      "62 Train Loss 1.0336863 Test MSE 6.3552520090996305 Test RE 1.2049650449932934\n",
      "63 Train Loss 1.0182579 Test MSE 6.332433197384426 Test RE 1.2027998597152016\n",
      "64 Train Loss 1.0021273 Test MSE 6.3515166517306705 Test RE 1.2046108783433762\n",
      "65 Train Loss 0.99191475 Test MSE 6.397379656215482 Test RE 1.2089521800855776\n",
      "66 Train Loss 0.97663903 Test MSE 6.392419027367507 Test RE 1.2084833689154342\n",
      "67 Train Loss 0.9631419 Test MSE 6.430629475098331 Test RE 1.2120898198544172\n",
      "68 Train Loss 0.9484348 Test MSE 6.439771154349731 Test RE 1.2129510575620546\n",
      "69 Train Loss 0.93880975 Test MSE 6.432246169660403 Test RE 1.2122421732034483\n",
      "70 Train Loss 0.9255922 Test MSE 6.431637177047382 Test RE 1.212184785474188\n",
      "71 Train Loss 0.91591966 Test MSE 6.44522441692019 Test RE 1.2134645184227992\n",
      "72 Train Loss 0.9004277 Test MSE 6.440499559148076 Test RE 1.2130196542844327\n",
      "73 Train Loss 0.88997734 Test MSE 6.431882267839012 Test RE 1.2122078816540718\n",
      "74 Train Loss 0.876336 Test MSE 6.413886888716092 Test RE 1.2105109118558497\n",
      "75 Train Loss 0.86681914 Test MSE 6.433738501051998 Test RE 1.21238278987796\n",
      "76 Train Loss 0.856375 Test MSE 6.434799994903545 Test RE 1.2124828004549246\n",
      "77 Train Loss 0.848748 Test MSE 6.450426403993998 Test RE 1.213954117631731\n",
      "78 Train Loss 0.8420458 Test MSE 6.460251358463578 Test RE 1.2148782817861017\n",
      "79 Train Loss 0.83083326 Test MSE 6.456646410525637 Test RE 1.2145392714398846\n",
      "80 Train Loss 0.8204587 Test MSE 6.466475413000312 Test RE 1.2154633711182545\n",
      "81 Train Loss 0.81287044 Test MSE 6.468995288327687 Test RE 1.2157001707379014\n",
      "82 Train Loss 0.8044311 Test MSE 6.498506373606537 Test RE 1.2184699832230153\n",
      "83 Train Loss 0.7930583 Test MSE 6.4881678817195025 Test RE 1.2175003637821726\n",
      "84 Train Loss 0.7848234 Test MSE 6.507364345702327 Test RE 1.2193001353387918\n",
      "85 Train Loss 0.77710575 Test MSE 6.507239320266702 Test RE 1.2192884221278275\n",
      "86 Train Loss 0.76947033 Test MSE 6.511035056107698 Test RE 1.219643981669283\n",
      "87 Train Loss 0.7638364 Test MSE 6.500898946441597 Test RE 1.2186942662915012\n",
      "88 Train Loss 0.75501716 Test MSE 6.493741258753474 Test RE 1.2180231717689385\n",
      "89 Train Loss 0.7471681 Test MSE 6.489778038547313 Test RE 1.217651426836434\n",
      "90 Train Loss 0.741269 Test MSE 6.494894446934635 Test RE 1.2181313180221058\n",
      "91 Train Loss 0.73414665 Test MSE 6.509345180849468 Test RE 1.2194856980846345\n",
      "92 Train Loss 0.72608185 Test MSE 6.54048930424245 Test RE 1.2223995466759834\n",
      "93 Train Loss 0.71644807 Test MSE 6.538120089145056 Test RE 1.2221781267144316\n",
      "94 Train Loss 0.70895064 Test MSE 6.575453021679085 Test RE 1.225662503302234\n",
      "95 Train Loss 0.698987 Test MSE 6.593644531256924 Test RE 1.2273567782844133\n",
      "96 Train Loss 0.6914842 Test MSE 6.613127848547037 Test RE 1.2291687763819572\n",
      "97 Train Loss 0.6818738 Test MSE 6.615881723511904 Test RE 1.2294246783449967\n",
      "98 Train Loss 0.67377436 Test MSE 6.63578784165892 Test RE 1.2312728591835516\n",
      "99 Train Loss 0.6666177 Test MSE 6.669044294567678 Test RE 1.23435437660884\n",
      "Training time: 75.47\n",
      "KG_stan_tune14\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.713272 Test MSE 8.884429260348156 Test RE 1.4246980410952694\n",
      "1 Train Loss 50.39247 Test MSE 8.670160058511195 Test RE 1.4074131930596023\n",
      "2 Train Loss 46.204 Test MSE 8.694913389834134 Test RE 1.4094208454275545\n",
      "3 Train Loss 44.9712 Test MSE 8.732383418265327 Test RE 1.4124544734133073\n",
      "4 Train Loss 44.12836 Test MSE 8.550616823893732 Test RE 1.3976768848934151\n",
      "5 Train Loss 43.66027 Test MSE 8.626092998135242 Test RE 1.4038319691111165\n",
      "6 Train Loss 43.43374 Test MSE 8.393073374687713 Test RE 1.3847410607057498\n",
      "7 Train Loss 43.28993 Test MSE 8.471065291615508 Test RE 1.3911599773510652\n",
      "8 Train Loss 43.084335 Test MSE 8.435907156977935 Test RE 1.3882700548286369\n",
      "9 Train Loss 42.883957 Test MSE 8.369393304034542 Test RE 1.382786238783076\n",
      "10 Train Loss 42.64196 Test MSE 8.420070252866298 Test RE 1.3869663285266542\n",
      "11 Train Loss 42.16987 Test MSE 8.435393394507518 Test RE 1.388227780067935\n",
      "12 Train Loss 41.622845 Test MSE 8.258788776530409 Test RE 1.373618842958778\n",
      "13 Train Loss 40.7047 Test MSE 8.643788818717116 Test RE 1.405271162459031\n",
      "14 Train Loss 39.48266 Test MSE 8.72756590378521 Test RE 1.4120648055358784\n",
      "15 Train Loss 37.806847 Test MSE 8.243599979985309 Test RE 1.3723551456335195\n",
      "16 Train Loss 36.882973 Test MSE 8.66653225003533 Test RE 1.4071187140829213\n",
      "17 Train Loss 36.32322 Test MSE 8.587227713141091 Test RE 1.4006658819571158\n",
      "18 Train Loss 34.858345 Test MSE 9.078797236971425 Test RE 1.4401980504151817\n",
      "19 Train Loss 33.72636 Test MSE 8.664187541888506 Test RE 1.4069283550211547\n",
      "20 Train Loss 32.28058 Test MSE 8.566698342068182 Test RE 1.3989906034447657\n",
      "21 Train Loss 29.586168 Test MSE 7.907404858045799 Test RE 1.3440797804557905\n",
      "22 Train Loss 23.34377 Test MSE 5.910724817058364 Test RE 1.1620596742126605\n",
      "23 Train Loss 18.830364 Test MSE 5.357361912492325 Test RE 1.106327106137769\n",
      "24 Train Loss 14.7987175 Test MSE 4.702196429290433 Test RE 1.0364740756345612\n",
      "25 Train Loss 13.403637 Test MSE 4.641066870318017 Test RE 1.0297148436069985\n",
      "26 Train Loss 12.491716 Test MSE 4.5369894655124865 Test RE 1.0181035357876498\n",
      "27 Train Loss 11.061434 Test MSE 4.210456601458708 Test RE 0.9807823865345937\n",
      "28 Train Loss 8.902146 Test MSE 4.011778162718345 Test RE 0.957362727473106\n",
      "29 Train Loss 6.1761613 Test MSE 4.161462459942562 Test RE 0.9750593494051943\n",
      "30 Train Loss 5.065097 Test MSE 3.868436221623426 Test RE 0.9401037408571535\n",
      "31 Train Loss 4.2152505 Test MSE 3.485181565221739 Test RE 0.8923202819413257\n",
      "32 Train Loss 3.7925313 Test MSE 3.580790395912553 Test RE 0.9044769638772479\n",
      "33 Train Loss 3.2351875 Test MSE 3.643090553806743 Test RE 0.9123112775774627\n",
      "34 Train Loss 2.9872575 Test MSE 3.6393268601213533 Test RE 0.9118398993019646\n",
      "35 Train Loss 2.6394503 Test MSE 3.573482374439373 Test RE 0.9035535206792997\n",
      "36 Train Loss 2.4167848 Test MSE 3.574920569885985 Test RE 0.9037353259466072\n",
      "37 Train Loss 2.2405713 Test MSE 3.716742252392849 Test RE 0.9214871484242296\n",
      "38 Train Loss 2.0376375 Test MSE 3.699557798242408 Test RE 0.9193544205285862\n",
      "39 Train Loss 1.8921204 Test MSE 3.5979597628521116 Test RE 0.9066427882461551\n",
      "40 Train Loss 1.7356704 Test MSE 3.248280197290532 Test RE 0.8614593767434264\n",
      "41 Train Loss 1.541497 Test MSE 3.047247483463485 Test RE 0.8343762310520157\n",
      "42 Train Loss 1.4389852 Test MSE 2.912407704972983 Test RE 0.815706918712478\n",
      "43 Train Loss 1.3724638 Test MSE 2.7358676852060992 Test RE 0.7905978066777736\n",
      "44 Train Loss 1.2993872 Test MSE 2.5941068839670063 Test RE 0.7698426954264374\n",
      "45 Train Loss 1.2113974 Test MSE 2.560221255000419 Test RE 0.7647981164197595\n",
      "46 Train Loss 1.1545422 Test MSE 2.5386618621069363 Test RE 0.7615711605091006\n",
      "47 Train Loss 1.1122131 Test MSE 2.4695029095437446 Test RE 0.7511260625337347\n",
      "48 Train Loss 1.072352 Test MSE 2.4362322309368913 Test RE 0.7460490858372346\n",
      "49 Train Loss 1.0336943 Test MSE 2.483454946516348 Test RE 0.7532449056185362\n",
      "50 Train Loss 1.0000943 Test MSE 2.4747605256304834 Test RE 0.7519252178506511\n",
      "51 Train Loss 0.9615959 Test MSE 2.4710909233713094 Test RE 0.7513675295255916\n",
      "52 Train Loss 0.9328114 Test MSE 2.5096416494855283 Test RE 0.7572057738416363\n",
      "53 Train Loss 0.9061299 Test MSE 2.5026221484537445 Test RE 0.7561460750207533\n",
      "54 Train Loss 0.8861412 Test MSE 2.522401286790533 Test RE 0.7591282438447836\n",
      "55 Train Loss 0.86341476 Test MSE 2.5362862911761366 Test RE 0.7612147542915462\n",
      "56 Train Loss 0.8497394 Test MSE 2.533851453309649 Test RE 0.7608492830209708\n",
      "57 Train Loss 0.8309506 Test MSE 2.52958969365069 Test RE 0.7602091663001337\n",
      "58 Train Loss 0.81886643 Test MSE 2.547645728435203 Test RE 0.7629175019169211\n",
      "59 Train Loss 0.802461 Test MSE 2.558545873567825 Test RE 0.7645478376104625\n",
      "60 Train Loss 0.79429096 Test MSE 2.569884658428748 Test RE 0.7662400996184869\n",
      "61 Train Loss 0.7857158 Test MSE 2.5894373661027617 Test RE 0.7691495062984842\n",
      "62 Train Loss 0.7738508 Test MSE 2.572080678984542 Test RE 0.7665674138592764\n",
      "63 Train Loss 0.7602621 Test MSE 2.589923575074872 Test RE 0.7692217130725859\n",
      "64 Train Loss 0.748328 Test MSE 2.6039258387097273 Test RE 0.7712982852474048\n",
      "65 Train Loss 0.7352632 Test MSE 2.6274166802652035 Test RE 0.7747695373402758\n",
      "66 Train Loss 0.7278838 Test MSE 2.628118865036017 Test RE 0.774873060133303\n",
      "67 Train Loss 0.7177296 Test MSE 2.6383418279448443 Test RE 0.7763786636778915\n",
      "68 Train Loss 0.7127039 Test MSE 2.654703505539383 Test RE 0.7787822991525905\n",
      "69 Train Loss 0.7056681 Test MSE 2.6671118724285994 Test RE 0.7806002330250922\n",
      "70 Train Loss 0.7005634 Test MSE 2.668681150946006 Test RE 0.7808298445110853\n",
      "71 Train Loss 0.6950663 Test MSE 2.6882869616838465 Test RE 0.7836928294601019\n",
      "72 Train Loss 0.6901133 Test MSE 2.6969626150178456 Test RE 0.7849563795868435\n",
      "73 Train Loss 0.68035305 Test MSE 2.7209076622249833 Test RE 0.7884333061606137\n",
      "74 Train Loss 0.6743284 Test MSE 2.703648257263892 Test RE 0.7859287121622854\n",
      "75 Train Loss 0.66717124 Test MSE 2.720092101024176 Test RE 0.7883151353358121\n",
      "76 Train Loss 0.6609595 Test MSE 2.7228164489494926 Test RE 0.788709810799291\n",
      "77 Train Loss 0.6536708 Test MSE 2.737394464796516 Test RE 0.790818376598726\n",
      "78 Train Loss 0.64766115 Test MSE 2.734652254971522 Test RE 0.7904221725946329\n",
      "79 Train Loss 0.64239997 Test MSE 2.7602783249957947 Test RE 0.7941170084258578\n",
      "80 Train Loss 0.6369727 Test MSE 2.7611528326418524 Test RE 0.7942427940021844\n",
      "81 Train Loss 0.6321882 Test MSE 2.7519534417077676 Test RE 0.7929185924081964\n",
      "82 Train Loss 0.6286413 Test MSE 2.76216805783815 Test RE 0.7943887948286994\n",
      "83 Train Loss 0.62377924 Test MSE 2.7819826118336124 Test RE 0.7972329975328198\n",
      "84 Train Loss 0.62132883 Test MSE 2.7710355571394776 Test RE 0.7956629022307644\n",
      "85 Train Loss 0.6162997 Test MSE 2.787587942014156 Test RE 0.7980357533515369\n",
      "86 Train Loss 0.61273193 Test MSE 2.8006222326002628 Test RE 0.799899317688859\n",
      "87 Train Loss 0.60666007 Test MSE 2.80539052851426 Test RE 0.8005799761695687\n",
      "88 Train Loss 0.60301405 Test MSE 2.8025507897689326 Test RE 0.8001746825814562\n",
      "89 Train Loss 0.5995537 Test MSE 2.825769509799617 Test RE 0.8034825101233921\n",
      "90 Train Loss 0.5935473 Test MSE 2.8375030233987037 Test RE 0.8051489423115039\n",
      "91 Train Loss 0.588645 Test MSE 2.8570842591537167 Test RE 0.8079222794897021\n",
      "92 Train Loss 0.5845751 Test MSE 2.8753719779543605 Test RE 0.8105038427765253\n",
      "93 Train Loss 0.5786683 Test MSE 2.8911870612311477 Test RE 0.8127297475585024\n",
      "94 Train Loss 0.57363546 Test MSE 2.9071383963448136 Test RE 0.8149686708693078\n",
      "95 Train Loss 0.5671617 Test MSE 2.945110529483438 Test RE 0.8202738365025299\n",
      "96 Train Loss 0.5625003 Test MSE 2.9567926076808524 Test RE 0.8218990759143835\n",
      "97 Train Loss 0.55819535 Test MSE 2.9651581481323848 Test RE 0.8230609385314961\n",
      "98 Train Loss 0.5538634 Test MSE 2.9772192322828848 Test RE 0.8247331820417083\n",
      "99 Train Loss 0.54912615 Test MSE 2.9985173641031015 Test RE 0.827677871758324\n",
      "Training time: 75.83\n",
      "KG_stan_tune15\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.40087 Test MSE 8.287276633763607 Test RE 1.3759858831883927\n",
      "1 Train Loss 45.104355 Test MSE 8.766352389062982 Test RE 1.4151990308161595\n",
      "2 Train Loss 43.71845 Test MSE 8.8050772992712 Test RE 1.418321370839436\n",
      "3 Train Loss 43.304955 Test MSE 8.765618312127033 Test RE 1.4151397765978015\n",
      "4 Train Loss 42.67481 Test MSE 8.670782168424873 Test RE 1.4074636852067242\n",
      "5 Train Loss 42.33654 Test MSE 8.884323044057993 Test RE 1.4246895247016793\n",
      "6 Train Loss 41.910927 Test MSE 8.996645447616286 Test RE 1.4336672450641113\n",
      "7 Train Loss 41.27797 Test MSE 9.180906103584867 Test RE 1.4482743302240835\n",
      "8 Train Loss 40.185467 Test MSE 8.882848355184796 Test RE 1.4245712792838439\n",
      "9 Train Loss 38.64453 Test MSE 8.878529917464437 Test RE 1.424224956236329\n",
      "10 Train Loss 35.42579 Test MSE 9.013793574358862 Test RE 1.4350329209680224\n",
      "11 Train Loss 32.119743 Test MSE 9.22902128595928 Test RE 1.4520644203010544\n",
      "12 Train Loss 28.505144 Test MSE 9.445240947954927 Test RE 1.4689755958618154\n",
      "13 Train Loss 26.41941 Test MSE 8.949061722806638 Test RE 1.429870848332003\n",
      "14 Train Loss 24.02007 Test MSE 8.897784547301118 Test RE 1.4257684590938386\n",
      "15 Train Loss 22.213211 Test MSE 8.444648549847798 Test RE 1.388989140022655\n",
      "16 Train Loss 20.022152 Test MSE 8.57720590874548 Test RE 1.3998483132425967\n",
      "17 Train Loss 17.149218 Test MSE 7.700852994322259 Test RE 1.326409051213329\n",
      "18 Train Loss 14.781463 Test MSE 7.500569707348865 Test RE 1.3090468382414702\n",
      "19 Train Loss 12.253882 Test MSE 7.635779308146042 Test RE 1.3207929562124836\n",
      "20 Train Loss 10.750572 Test MSE 7.508645029623021 Test RE 1.3097513268191483\n",
      "21 Train Loss 9.496252 Test MSE 7.357790074370421 Test RE 1.2965275712458322\n",
      "22 Train Loss 8.19645 Test MSE 7.280391236742496 Test RE 1.2896902583078953\n",
      "23 Train Loss 6.911496 Test MSE 7.247959147931526 Test RE 1.2868144488946927\n",
      "24 Train Loss 5.701144 Test MSE 6.968286690400512 Test RE 1.261743468831233\n",
      "25 Train Loss 4.8894873 Test MSE 7.1886539547182435 Test RE 1.2815390652945433\n",
      "26 Train Loss 4.375444 Test MSE 7.123770760608091 Test RE 1.2757425125507673\n",
      "27 Train Loss 4.0022144 Test MSE 6.934587048966733 Test RE 1.258688784255165\n",
      "28 Train Loss 3.42076 Test MSE 6.930114373760204 Test RE 1.258282803759556\n",
      "29 Train Loss 3.047056 Test MSE 6.662871167737619 Test RE 1.233782961132961\n",
      "30 Train Loss 2.6758335 Test MSE 6.504118044997487 Test RE 1.2189959639065489\n",
      "31 Train Loss 2.473343 Test MSE 6.301294524718679 Test RE 1.1998389324990366\n",
      "32 Train Loss 2.324535 Test MSE 6.119010713539875 Test RE 1.1823571093668659\n",
      "33 Train Loss 2.1345332 Test MSE 5.763602482377815 Test RE 1.147506277761754\n",
      "34 Train Loss 1.9829504 Test MSE 5.614657689626878 Test RE 1.1325821224532824\n",
      "35 Train Loss 1.8296441 Test MSE 5.47361056206492 Test RE 1.1182657090333632\n",
      "36 Train Loss 1.664483 Test MSE 5.467087373244758 Test RE 1.1175991624329822\n",
      "37 Train Loss 1.5487887 Test MSE 5.518185862191693 Test RE 1.12280987194782\n",
      "38 Train Loss 1.4559476 Test MSE 5.466227187112908 Test RE 1.1175112379997294\n",
      "39 Train Loss 1.3892549 Test MSE 5.551707472431351 Test RE 1.1262151040135886\n",
      "40 Train Loss 1.3418818 Test MSE 5.604757399272406 Test RE 1.1315831444433402\n",
      "41 Train Loss 1.302438 Test MSE 5.650654575935419 Test RE 1.1362069465469324\n",
      "42 Train Loss 1.2573719 Test MSE 5.683128171843933 Test RE 1.139467088034147\n",
      "43 Train Loss 1.2291112 Test MSE 5.7098769407607 Test RE 1.1421455039341313\n",
      "44 Train Loss 1.1970742 Test MSE 5.7236068913804505 Test RE 1.1435178790192624\n",
      "45 Train Loss 1.169068 Test MSE 5.742607465074665 Test RE 1.1454143661382576\n",
      "46 Train Loss 1.1428179 Test MSE 5.761338898185888 Test RE 1.1472809211241015\n",
      "47 Train Loss 1.120821 Test MSE 5.790789853674025 Test RE 1.1502095328324164\n",
      "48 Train Loss 1.0983465 Test MSE 5.769731129599577 Test RE 1.1481162081529581\n",
      "49 Train Loss 1.0749497 Test MSE 5.778660044267565 Test RE 1.1490042450779945\n",
      "50 Train Loss 1.0555598 Test MSE 5.726836870379435 Test RE 1.1438404918280616\n",
      "51 Train Loss 1.0369886 Test MSE 5.719388494523992 Test RE 1.1430964051607695\n",
      "52 Train Loss 1.011651 Test MSE 5.770637971059545 Test RE 1.1482064305955564\n",
      "53 Train Loss 0.9908691 Test MSE 5.7978725157659206 Test RE 1.1509127232600271\n",
      "54 Train Loss 0.9690925 Test MSE 5.849000178005703 Test RE 1.15597615989957\n",
      "55 Train Loss 0.9490402 Test MSE 5.910797457928053 Test RE 1.1620668148568813\n",
      "56 Train Loss 0.9308871 Test MSE 5.938057601196094 Test RE 1.16474341372679\n",
      "57 Train Loss 0.91227466 Test MSE 5.9608104288733905 Test RE 1.1669727511921397\n",
      "58 Train Loss 0.8962308 Test MSE 5.979883625587126 Test RE 1.1688382797574797\n",
      "59 Train Loss 0.87996346 Test MSE 6.027578584888178 Test RE 1.1734902913387997\n",
      "60 Train Loss 0.8667969 Test MSE 6.029505477617622 Test RE 1.1736778466890554\n",
      "61 Train Loss 0.85446596 Test MSE 6.0714491692609265 Test RE 1.1777530619122938\n",
      "62 Train Loss 0.8403919 Test MSE 6.076535837680169 Test RE 1.1782463201839786\n",
      "63 Train Loss 0.82643867 Test MSE 6.101065593863763 Test RE 1.1806220969805197\n",
      "64 Train Loss 0.81623936 Test MSE 6.122962298557118 Test RE 1.1827388238947627\n",
      "65 Train Loss 0.8061565 Test MSE 6.15513009037265 Test RE 1.1858415914107305\n",
      "66 Train Loss 0.7987778 Test MSE 6.202360198248305 Test RE 1.1903825511777117\n",
      "67 Train Loss 0.7900846 Test MSE 6.190100597954609 Test RE 1.1892055127289094\n",
      "68 Train Loss 0.7805007 Test MSE 6.225472671422288 Test RE 1.1925984093939088\n",
      "69 Train Loss 0.773213 Test MSE 6.224138358605316 Test RE 1.1924705970411322\n",
      "70 Train Loss 0.7654418 Test MSE 6.248594172740305 Test RE 1.1948110213031344\n",
      "71 Train Loss 0.759194 Test MSE 6.268688117055091 Test RE 1.1967305887374062\n",
      "72 Train Loss 0.7503364 Test MSE 6.285085911502178 Test RE 1.1982947857051065\n",
      "73 Train Loss 0.7439231 Test MSE 6.293860743690406 Test RE 1.1991309849496519\n",
      "74 Train Loss 0.7377831 Test MSE 6.3070723514486495 Test RE 1.2003888887831489\n",
      "75 Train Loss 0.73146915 Test MSE 6.322694649035204 Test RE 1.2018746204588129\n",
      "76 Train Loss 0.72618455 Test MSE 6.344874234652194 Test RE 1.203980822452439\n",
      "77 Train Loss 0.7203175 Test MSE 6.348216023184666 Test RE 1.2042978436823162\n",
      "78 Train Loss 0.71492314 Test MSE 6.366688423008413 Test RE 1.2060487380541307\n",
      "79 Train Loss 0.70866454 Test MSE 6.381352069130324 Test RE 1.207436814511505\n",
      "80 Train Loss 0.7023565 Test MSE 6.408537370554141 Test RE 1.2100059917471884\n",
      "81 Train Loss 0.69745964 Test MSE 6.436311033930918 Test RE 1.2126251515218003\n",
      "82 Train Loss 0.6927564 Test MSE 6.460582042151126 Test RE 1.214909374638916\n",
      "83 Train Loss 0.6879615 Test MSE 6.467178651074452 Test RE 1.2155294609761662\n",
      "84 Train Loss 0.68243337 Test MSE 6.480066878555788 Test RE 1.2167400524675795\n",
      "85 Train Loss 0.67710733 Test MSE 6.502574888639838 Test RE 1.2188513468386675\n",
      "86 Train Loss 0.6723372 Test MSE 6.521384013154837 Test RE 1.2206128776688774\n",
      "87 Train Loss 0.66701454 Test MSE 6.5360090118247465 Test RE 1.2219807977578923\n",
      "88 Train Loss 0.6599729 Test MSE 6.568326294740408 Test RE 1.224998113331232\n",
      "89 Train Loss 0.6530057 Test MSE 6.580698306879106 Test RE 1.2261512656562614\n",
      "90 Train Loss 0.6468797 Test MSE 6.603028122991653 Test RE 1.2282298099011346\n",
      "91 Train Loss 0.64171684 Test MSE 6.6047056152184 Test RE 1.22838581522777\n",
      "92 Train Loss 0.6373277 Test MSE 6.619849513869654 Test RE 1.2297932889409062\n",
      "93 Train Loss 0.63294005 Test MSE 6.6298291369382625 Test RE 1.230719915105261\n",
      "94 Train Loss 0.6275781 Test MSE 6.6592904539552125 Test RE 1.233451391059735\n",
      "95 Train Loss 0.6235182 Test MSE 6.670515342345496 Test RE 1.2344905051200856\n",
      "96 Train Loss 0.6182218 Test MSE 6.688219020441808 Test RE 1.2361276005835882\n",
      "97 Train Loss 0.61186194 Test MSE 6.736247464241021 Test RE 1.240558008912305\n",
      "98 Train Loss 0.60629267 Test MSE 6.76401285813965 Test RE 1.2431120392968533\n",
      "99 Train Loss 0.6012854 Test MSE 6.796821347526564 Test RE 1.246123217177281\n",
      "Training time: 75.40\n",
      "KG_stan_tune15\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.00568 Test MSE 8.467892557354759 Test RE 1.390899431945633\n",
      "1 Train Loss 52.10414 Test MSE 9.130562943230583 Test RE 1.4442980923781445\n",
      "2 Train Loss 42.207657 Test MSE 8.624553778998019 Test RE 1.4037067153355327\n",
      "3 Train Loss 38.25198 Test MSE 8.034133017113602 Test RE 1.354807428376663\n",
      "4 Train Loss 32.62168 Test MSE 6.583226678099583 Test RE 1.2263867929290442\n",
      "5 Train Loss 28.299606 Test MSE 5.581641993541323 Test RE 1.1292472691428497\n",
      "6 Train Loss 23.454718 Test MSE 4.988638097479947 Test RE 1.0675766339033352\n",
      "7 Train Loss 21.379562 Test MSE 6.047621808054925 Test RE 1.1754397480715766\n",
      "8 Train Loss 17.66736 Test MSE 5.714768121989437 Test RE 1.1426345902015351\n",
      "9 Train Loss 15.610744 Test MSE 5.957825291894526 Test RE 1.1666805082327525\n",
      "10 Train Loss 14.327797 Test MSE 5.972715019803471 Test RE 1.1681374756930116\n",
      "11 Train Loss 13.122326 Test MSE 6.015712923917677 Test RE 1.1723346782524644\n",
      "12 Train Loss 12.613693 Test MSE 5.923782589514659 Test RE 1.16334255745439\n",
      "13 Train Loss 11.902977 Test MSE 5.930074231531306 Test RE 1.1639601858338042\n",
      "14 Train Loss 11.633534 Test MSE 5.960440971473467 Test RE 1.1669365855226792\n",
      "15 Train Loss 11.39904 Test MSE 5.927092822858968 Test RE 1.163667552289794\n",
      "16 Train Loss 11.232042 Test MSE 5.905830605766478 Test RE 1.1615784689832396\n",
      "17 Train Loss 11.123257 Test MSE 5.864552936864925 Test RE 1.1575120363131854\n",
      "18 Train Loss 11.037039 Test MSE 5.871427993645004 Test RE 1.15819031734599\n",
      "19 Train Loss 10.940607 Test MSE 5.811466094629977 Test RE 1.1522611371228135\n",
      "20 Train Loss 10.817959 Test MSE 5.74437826123005 Test RE 1.1455909530833452\n",
      "21 Train Loss 9.985386 Test MSE 4.698477196636691 Test RE 1.0360640916144728\n",
      "22 Train Loss 8.59922 Test MSE 4.348209464189369 Test RE 0.9966973160324226\n",
      "23 Train Loss 7.992652 Test MSE 4.310426292225556 Test RE 0.9923575354152364\n",
      "24 Train Loss 7.775681 Test MSE 4.293770164320188 Test RE 0.990438371125092\n",
      "25 Train Loss 7.674912 Test MSE 4.286527602672911 Test RE 0.9896027024523172\n",
      "26 Train Loss 7.6049814 Test MSE 4.2779759162417905 Test RE 0.9886150735551983\n",
      "27 Train Loss 7.5318675 Test MSE 4.247812320930426 Test RE 0.985123593410227\n",
      "28 Train Loss 7.442456 Test MSE 4.231802006673281 Test RE 0.983265339469379\n",
      "29 Train Loss 7.330777 Test MSE 4.228319542887127 Test RE 0.9828606784425649\n",
      "30 Train Loss 7.138254 Test MSE 4.1582533030421445 Test RE 0.9746833130999641\n",
      "31 Train Loss 6.425149 Test MSE 4.0621314884847255 Test RE 0.963352100903646\n",
      "32 Train Loss 5.4859877 Test MSE 3.969483832895111 Test RE 0.9523028389246162\n",
      "33 Train Loss 4.779431 Test MSE 3.642699680167736 Test RE 0.9122623345180959\n",
      "34 Train Loss 4.381918 Test MSE 3.4545558623413646 Test RE 0.8883910409586644\n",
      "35 Train Loss 4.1369734 Test MSE 3.2497104623519206 Test RE 0.8616490124235118\n",
      "36 Train Loss 3.6887064 Test MSE 2.553529583166697 Test RE 0.7637979828421662\n",
      "37 Train Loss 3.10177 Test MSE 2.34248994970438 Test RE 0.7315549081152525\n",
      "38 Train Loss 2.591837 Test MSE 2.1179953499327437 Test RE 0.6956175996030411\n",
      "39 Train Loss 2.227492 Test MSE 2.032722585011022 Test RE 0.6814705879082502\n",
      "40 Train Loss 1.9103634 Test MSE 1.8844074460633307 Test RE 0.6561384163880722\n",
      "41 Train Loss 1.5313557 Test MSE 1.5672089879015667 Test RE 0.598372349955259\n",
      "42 Train Loss 1.2563466 Test MSE 1.21924241854263 Test RE 0.5277801985332815\n",
      "43 Train Loss 0.9195511 Test MSE 0.7925847203939527 Test RE 0.4255307100879184\n",
      "44 Train Loss 0.68288946 Test MSE 0.40547138298379704 Test RE 0.3043604128021731\n",
      "45 Train Loss 0.42494035 Test MSE 0.3193228417052009 Test RE 0.2700990477229094\n",
      "46 Train Loss 0.261376 Test MSE 0.20003135033910868 Test RE 0.21377508788180533\n",
      "47 Train Loss 0.21608064 Test MSE 0.1885455157602698 Test RE 0.20754685854448213\n",
      "48 Train Loss 0.16471808 Test MSE 0.13638950773586553 Test RE 0.17652187881868237\n",
      "49 Train Loss 0.12726858 Test MSE 0.07302648951521253 Test RE 0.12916601834605285\n",
      "50 Train Loss 0.09549199 Test MSE 0.045161391271371296 Test RE 0.10157614267322473\n",
      "51 Train Loss 0.07674446 Test MSE 0.031224115766982252 Test RE 0.0844604001218494\n",
      "52 Train Loss 0.06256443 Test MSE 0.02603715033476216 Test RE 0.07712670637349472\n",
      "53 Train Loss 0.05392178 Test MSE 0.023727441573080148 Test RE 0.07362639163522862\n",
      "54 Train Loss 0.04603004 Test MSE 0.021873200952322484 Test RE 0.07069101732939968\n",
      "55 Train Loss 0.038710706 Test MSE 0.014418531898243806 Test RE 0.057394275962200994\n",
      "56 Train Loss 0.0337548 Test MSE 0.012932056156450556 Test RE 0.05435529425967139\n",
      "57 Train Loss 0.029615488 Test MSE 0.009672308816073465 Test RE 0.047008147558544724\n",
      "58 Train Loss 0.024697868 Test MSE 0.007269816129216733 Test RE 0.04075395612967306\n",
      "59 Train Loss 0.021161173 Test MSE 0.006702712120505416 Test RE 0.03913211703849089\n",
      "60 Train Loss 0.017684408 Test MSE 0.005407591590404481 Test RE 0.03514875951097312\n",
      "61 Train Loss 0.01451143 Test MSE 0.006793391328149747 Test RE 0.039395931762414994\n",
      "62 Train Loss 0.013361264 Test MSE 0.006874419259872486 Test RE 0.03963018211221805\n",
      "63 Train Loss 0.011736867 Test MSE 0.006787489840025893 Test RE 0.039378816221240814\n",
      "64 Train Loss 0.0110203065 Test MSE 0.0058158651113518105 Test RE 0.03645148476054718\n",
      "65 Train Loss 0.009848233 Test MSE 0.005550779732464234 Test RE 0.03561107280232569\n",
      "66 Train Loss 0.009137444 Test MSE 0.005572333225423832 Test RE 0.035680144122119506\n",
      "67 Train Loss 0.008622021 Test MSE 0.005179223686273296 Test RE 0.03439857045309599\n",
      "68 Train Loss 0.007864086 Test MSE 0.004289556949800242 Test RE 0.03130504117270095\n",
      "69 Train Loss 0.0072815726 Test MSE 0.0035362410036634297 Test RE 0.02842359380225884\n",
      "70 Train Loss 0.0066334917 Test MSE 0.0030400288714452195 Test RE 0.026354022620005354\n",
      "71 Train Loss 0.0059077498 Test MSE 0.002825363054439714 Test RE 0.02540652050184873\n",
      "72 Train Loss 0.005590931 Test MSE 0.0027399250096192674 Test RE 0.025019429269161075\n",
      "73 Train Loss 0.0052317535 Test MSE 0.0026368067670343026 Test RE 0.024544105699646573\n",
      "74 Train Loss 0.004753922 Test MSE 0.002274052100694094 Test RE 0.02279335557700548\n",
      "75 Train Loss 0.0044518276 Test MSE 0.0020476266059918646 Test RE 0.02162885067339809\n",
      "76 Train Loss 0.00409606 Test MSE 0.0020869144130088377 Test RE 0.02183536115513667\n",
      "77 Train Loss 0.0036596202 Test MSE 0.0017264452130154615 Test RE 0.01986023855426926\n",
      "78 Train Loss 0.003483857 Test MSE 0.0014080241636808958 Test RE 0.01793548455320833\n",
      "79 Train Loss 0.0033397353 Test MSE 0.0014293923431480209 Test RE 0.018071066578946405\n",
      "80 Train Loss 0.003090171 Test MSE 0.0014157879717257012 Test RE 0.017984864470919314\n",
      "81 Train Loss 0.0028684542 Test MSE 0.0012617317044219896 Test RE 0.01697819699394767\n",
      "82 Train Loss 0.0027259209 Test MSE 0.001185866390096779 Test RE 0.016459852553140118\n",
      "83 Train Loss 0.0025826164 Test MSE 0.0012167385316372615 Test RE 0.016672728994580898\n",
      "84 Train Loss 0.0024700868 Test MSE 0.0011196609064198766 Test RE 0.01599378735986466\n",
      "85 Train Loss 0.0023521788 Test MSE 0.0010544108977450335 Test RE 0.015520760708247604\n",
      "86 Train Loss 0.0022118895 Test MSE 0.0009851435424807476 Test RE 0.015002299031836787\n",
      "87 Train Loss 0.0021521547 Test MSE 0.0009174533012025376 Test RE 0.014477715700851636\n",
      "88 Train Loss 0.0020395808 Test MSE 0.0008798333571226217 Test RE 0.01417778127130439\n",
      "89 Train Loss 0.0019292315 Test MSE 0.0008099174758886279 Test RE 0.013602804151447349\n",
      "90 Train Loss 0.0018197924 Test MSE 0.0007115728307936594 Test RE 0.01275022178013813\n",
      "91 Train Loss 0.0017164075 Test MSE 0.0006424912156353989 Test RE 0.012115508800148774\n",
      "92 Train Loss 0.001625338 Test MSE 0.0005277561412336606 Test RE 0.010980565531032134\n",
      "93 Train Loss 0.0015273973 Test MSE 0.0004963986302317865 Test RE 0.01064935605094456\n",
      "94 Train Loss 0.0014847387 Test MSE 0.00047010510653222094 Test RE 0.010363478354425602\n",
      "95 Train Loss 0.0014049022 Test MSE 0.00047388444863014626 Test RE 0.010405052807359753\n",
      "96 Train Loss 0.001333263 Test MSE 0.0004158121791312481 Test RE 0.009746678999814561\n",
      "97 Train Loss 0.0012824633 Test MSE 0.0004478231393404286 Test RE 0.010114893754136966\n",
      "98 Train Loss 0.0012280103 Test MSE 0.00043179075853520913 Test RE 0.00993218343433176\n",
      "99 Train Loss 0.0011477601 Test MSE 0.0003672437731021939 Test RE 0.009159785014558266\n",
      "Training time: 76.45\n",
      "KG_stan_tune15\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 51.66794 Test MSE 9.489812590989311 Test RE 1.4724375294967176\n",
      "1 Train Loss 44.419594 Test MSE 8.45054101064767 Test RE 1.3894736561492604\n",
      "2 Train Loss 42.636055 Test MSE 8.290386014163596 Test RE 1.3762439934507291\n",
      "3 Train Loss 41.772713 Test MSE 8.233293094922997 Test RE 1.371496956808545\n",
      "4 Train Loss 37.38929 Test MSE 7.3121007492459125 Test RE 1.2924958092080012\n",
      "5 Train Loss 29.405743 Test MSE 5.80505708093146 Test RE 1.151625592282543\n",
      "6 Train Loss 24.498947 Test MSE 6.331485254772737 Test RE 1.2027098289262121\n",
      "7 Train Loss 22.767693 Test MSE 6.346421695132812 Test RE 1.2041276338065978\n",
      "8 Train Loss 20.930408 Test MSE 6.557246431248466 Test RE 1.223964475539502\n",
      "9 Train Loss 19.891052 Test MSE 6.616989848311316 Test RE 1.229527635062631\n",
      "10 Train Loss 18.434473 Test MSE 6.436132298937341 Test RE 1.2126083142331545\n",
      "11 Train Loss 16.119568 Test MSE 6.177244942326985 Test RE 1.1879699946524944\n",
      "12 Train Loss 13.212784 Test MSE 5.484989400015431 Test RE 1.119427461215143\n",
      "13 Train Loss 11.559554 Test MSE 5.0758858604959265 Test RE 1.0768717501143124\n",
      "14 Train Loss 8.699482 Test MSE 3.104364574383859 Test RE 0.8421596311010586\n",
      "15 Train Loss 4.8230124 Test MSE 1.1962817360325708 Test RE 0.5227870202992246\n",
      "16 Train Loss 2.7511735 Test MSE 0.717273700834675 Test RE 0.4048093304882771\n",
      "17 Train Loss 1.6508312 Test MSE 0.4468863658040496 Test RE 0.3195263016469578\n",
      "18 Train Loss 1.042858 Test MSE 0.2675790554900565 Test RE 0.247248757884053\n",
      "19 Train Loss 0.64335924 Test MSE 0.13838149195524568 Test RE 0.1778062671825117\n",
      "20 Train Loss 0.3719731 Test MSE 0.08004347795704639 Test RE 0.13522937340323637\n",
      "21 Train Loss 0.2506832 Test MSE 0.06230074642989374 Test RE 0.11930391221216172\n",
      "22 Train Loss 0.15776253 Test MSE 0.04401405053048618 Test RE 0.10027755334403754\n",
      "23 Train Loss 0.11994267 Test MSE 0.03690673503786 Test RE 0.09182498662318894\n",
      "24 Train Loss 0.09085301 Test MSE 0.022816729238013967 Test RE 0.07219959387368773\n",
      "25 Train Loss 0.069295414 Test MSE 0.02282539766302581 Test RE 0.07221330743725321\n",
      "26 Train Loss 0.05017659 Test MSE 0.015600746279553088 Test RE 0.059700881986295834\n",
      "27 Train Loss 0.043087985 Test MSE 0.01603634937537743 Test RE 0.06052862592377891\n",
      "28 Train Loss 0.035821203 Test MSE 0.011700175603661692 Test RE 0.05170163177692625\n",
      "29 Train Loss 0.030772787 Test MSE 0.010590452988226593 Test RE 0.04918869816675081\n",
      "30 Train Loss 0.024402838 Test MSE 0.007780322047830598 Test RE 0.0421606062547106\n",
      "31 Train Loss 0.020792995 Test MSE 0.006482249025789049 Test RE 0.038483176784975565\n",
      "32 Train Loss 0.016958738 Test MSE 0.00619296975169134 Test RE 0.037614694566686806\n",
      "33 Train Loss 0.015064854 Test MSE 0.005540666068199859 Test RE 0.03557861586330939\n",
      "34 Train Loss 0.012985959 Test MSE 0.004498051903458962 Test RE 0.032056809141280514\n",
      "35 Train Loss 0.010120537 Test MSE 0.0026945688921489307 Test RE 0.024811482028235764\n",
      "36 Train Loss 0.009236504 Test MSE 0.00268708464696741 Test RE 0.024777000754026033\n",
      "37 Train Loss 0.008326318 Test MSE 0.003109646022927583 Test RE 0.02665407024295321\n",
      "38 Train Loss 0.007166344 Test MSE 0.002372462891857595 Test RE 0.023281329337851833\n",
      "39 Train Loss 0.006638136 Test MSE 0.0021284365391420644 Test RE 0.0220515140440483\n",
      "40 Train Loss 0.0061128857 Test MSE 0.0019894780827027425 Test RE 0.02131953066730411\n",
      "41 Train Loss 0.0054825237 Test MSE 0.0019445086703935785 Test RE 0.02107720416061294\n",
      "42 Train Loss 0.0052127657 Test MSE 0.0017027980935527276 Test RE 0.01972375675493686\n",
      "43 Train Loss 0.0049559856 Test MSE 0.0015423373354264283 Test RE 0.01877144676477606\n",
      "44 Train Loss 0.0046395175 Test MSE 0.0015500045638604971 Test RE 0.01881804699329117\n",
      "45 Train Loss 0.0044203396 Test MSE 0.0015641405333343245 Test RE 0.01890366209122765\n",
      "46 Train Loss 0.0040556765 Test MSE 0.001278034089518551 Test RE 0.017087529577876518\n",
      "47 Train Loss 0.0038862803 Test MSE 0.0011241566833142965 Test RE 0.016025865136372625\n",
      "48 Train Loss 0.0037559061 Test MSE 0.0009725040962742261 Test RE 0.014905748180193306\n",
      "49 Train Loss 0.0033324237 Test MSE 0.000948057771723764 Test RE 0.014717209144797338\n",
      "50 Train Loss 0.0030084036 Test MSE 0.00103093101995591 Test RE 0.015346977768087482\n",
      "51 Train Loss 0.0028898572 Test MSE 0.0009213542905967034 Test RE 0.014508462501516755\n",
      "52 Train Loss 0.0027322294 Test MSE 0.0008713134704725835 Test RE 0.014108968843046552\n",
      "53 Train Loss 0.0025947704 Test MSE 0.0007655683582490235 Test RE 0.013225132989795942\n",
      "54 Train Loss 0.002455973 Test MSE 0.0006916926018628406 Test RE 0.012570849459591357\n",
      "55 Train Loss 0.0023759992 Test MSE 0.000680707277986423 Test RE 0.012470626073685997\n",
      "56 Train Loss 0.0021814725 Test MSE 0.000639339019609856 Test RE 0.012085751648914074\n",
      "57 Train Loss 0.0020276706 Test MSE 0.0005842968554458533 Test RE 0.011553799715537529\n",
      "58 Train Loss 0.0018348609 Test MSE 0.0005457359629592647 Test RE 0.011166044318011279\n",
      "59 Train Loss 0.0017011358 Test MSE 0.0005482646472080055 Test RE 0.01119188352457\n",
      "60 Train Loss 0.0016253723 Test MSE 0.0005535064333856137 Test RE 0.01124525729804735\n",
      "61 Train Loss 0.0015153368 Test MSE 0.0005292769116600906 Test RE 0.010996374827706695\n",
      "62 Train Loss 0.0013509064 Test MSE 0.0005374547625004042 Test RE 0.01108100161280509\n",
      "63 Train Loss 0.0012650699 Test MSE 0.000549661675443598 Test RE 0.011206133421906161\n",
      "64 Train Loss 0.0012271345 Test MSE 0.0005005189492919145 Test RE 0.010693461800782393\n",
      "65 Train Loss 0.0011437486 Test MSE 0.0004972316009651043 Test RE 0.010658287263904007\n",
      "66 Train Loss 0.0011129053 Test MSE 0.0004712390197305097 Test RE 0.010375969398564961\n",
      "67 Train Loss 0.0010734054 Test MSE 0.00042714069363248983 Test RE 0.009878557556416435\n",
      "68 Train Loss 0.001060168 Test MSE 0.00039910640988188785 Test RE 0.009548879474062534\n",
      "69 Train Loss 0.0010115646 Test MSE 0.0004002611074634635 Test RE 0.009562682941137471\n",
      "70 Train Loss 0.00095716445 Test MSE 0.0003855944668882141 Test RE 0.009385846708465501\n",
      "71 Train Loss 0.0009003351 Test MSE 0.00037328278716307914 Test RE 0.00923479039076798\n",
      "72 Train Loss 0.00088016095 Test MSE 0.00035415189418685274 Test RE 0.00899503473541305\n",
      "73 Train Loss 0.0008451356 Test MSE 0.00031996544073651355 Test RE 0.008549871681271942\n",
      "74 Train Loss 0.00081139564 Test MSE 0.0003196107705588912 Test RE 0.008545131754845519\n",
      "75 Train Loss 0.000780402 Test MSE 0.0003280460482641274 Test RE 0.008657160426276544\n",
      "76 Train Loss 0.00075605593 Test MSE 0.00032683106017410737 Test RE 0.008641113739879306\n",
      "77 Train Loss 0.0007390035 Test MSE 0.0003273191036854079 Test RE 0.008647563044766798\n",
      "78 Train Loss 0.0007284912 Test MSE 0.00033330839410585563 Test RE 0.008726321025680335\n",
      "79 Train Loss 0.0007123355 Test MSE 0.00033159609934455263 Test RE 0.008703877436193214\n",
      "80 Train Loss 0.00069682836 Test MSE 0.000345012390685532 Test RE 0.00887820986031327\n",
      "81 Train Loss 0.00066498877 Test MSE 0.00034567377660653896 Test RE 0.00888671551366202\n",
      "82 Train Loss 0.00064314797 Test MSE 0.0003227479153392397 Test RE 0.008586966788124307\n",
      "83 Train Loss 0.0006220862 Test MSE 0.0003120962335537819 Test RE 0.008444079705356237\n",
      "84 Train Loss 0.0005908116 Test MSE 0.0003153583534702851 Test RE 0.008488094968468732\n",
      "85 Train Loss 0.00056454126 Test MSE 0.00029235417866128074 Test RE 0.008172646476910092\n",
      "86 Train Loss 0.00054753496 Test MSE 0.0002892276174544546 Test RE 0.008128828112353796\n",
      "87 Train Loss 0.00053404295 Test MSE 0.00028032112716237464 Test RE 0.008002689662829241\n",
      "88 Train Loss 0.0005163739 Test MSE 0.0002794278708775463 Test RE 0.007989929018064739\n",
      "89 Train Loss 0.00048257876 Test MSE 0.0002766716851242511 Test RE 0.007950426334001098\n",
      "90 Train Loss 0.00047049974 Test MSE 0.00026716039595975284 Test RE 0.00781257320022817\n",
      "91 Train Loss 0.00046359227 Test MSE 0.0002822621738092163 Test RE 0.008030348649345733\n",
      "92 Train Loss 0.00045207812 Test MSE 0.0002853976213739373 Test RE 0.008074827155520825\n",
      "93 Train Loss 0.0004409361 Test MSE 0.00028072377775937 Test RE 0.008008435094001945\n",
      "94 Train Loss 0.00043403057 Test MSE 0.00027313478797690634 Test RE 0.007899444809801748\n",
      "95 Train Loss 0.0004167378 Test MSE 0.00024239402117231124 Test RE 0.007441646090127663\n",
      "96 Train Loss 0.00039991713 Test MSE 0.00024362408825189904 Test RE 0.007460504105260518\n",
      "97 Train Loss 0.00038424868 Test MSE 0.00023696714512590962 Test RE 0.007357870306576061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 Train Loss 0.00037667798 Test MSE 0.0002363581721024685 Test RE 0.007348409866493211\n",
      "99 Train Loss 0.0003663064 Test MSE 0.00024907019820212013 Test RE 0.007543431369395321\n",
      "Training time: 76.48\n",
      "KG_stan_tune15\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 54.01173 Test MSE 8.822203276027754 Test RE 1.4197000264904684\n",
      "1 Train Loss 45.14762 Test MSE 8.656175125145753 Test RE 1.4062776590568944\n",
      "2 Train Loss 42.817474 Test MSE 8.590771081007569 Test RE 1.4009548321729435\n",
      "3 Train Loss 41.320515 Test MSE 8.44969992438006 Test RE 1.389404506949767\n",
      "4 Train Loss 40.322517 Test MSE 8.692461611530996 Test RE 1.409222118256361\n",
      "5 Train Loss 40.01001 Test MSE 8.819402685169331 Test RE 1.419474668131292\n",
      "6 Train Loss 39.197666 Test MSE 8.651750524258656 Test RE 1.4059182039504448\n",
      "7 Train Loss 38.220387 Test MSE 8.626474473506454 Test RE 1.403863009896387\n",
      "8 Train Loss 34.532223 Test MSE 7.425236421114072 Test RE 1.3024564278385926\n",
      "9 Train Loss 31.563118 Test MSE 7.203423254142158 Test RE 1.282854869513971\n",
      "10 Train Loss 29.41029 Test MSE 7.001127669533573 Test RE 1.2647132220352622\n",
      "11 Train Loss 26.292433 Test MSE 7.275684697841213 Test RE 1.2892733192655792\n",
      "12 Train Loss 22.733198 Test MSE 7.23888709429035 Test RE 1.2860088631586983\n",
      "13 Train Loss 17.7647 Test MSE 6.786567225890022 Test RE 1.2451828715790734\n",
      "14 Train Loss 13.2580185 Test MSE 6.809138642729842 Test RE 1.2472518270948154\n",
      "15 Train Loss 10.149378 Test MSE 6.330427278475814 Test RE 1.2026093397361026\n",
      "16 Train Loss 7.9412947 Test MSE 6.101533418539404 Test RE 1.1806673606769635\n",
      "17 Train Loss 6.440472 Test MSE 5.978091270201233 Test RE 1.1686630982052368\n",
      "18 Train Loss 5.1618934 Test MSE 5.824207847935251 Test RE 1.153523623057965\n",
      "19 Train Loss 4.134152 Test MSE 5.74946213983407 Test RE 1.1460977753227672\n",
      "20 Train Loss 3.5029836 Test MSE 5.5308307194114015 Test RE 1.1240955885465433\n",
      "21 Train Loss 3.0720549 Test MSE 5.661301417575488 Test RE 1.13727685113902\n",
      "22 Train Loss 2.723588 Test MSE 5.844208680139295 Test RE 1.155502575358854\n",
      "23 Train Loss 2.449264 Test MSE 5.723839195036256 Test RE 1.1435410847262106\n",
      "24 Train Loss 2.1704412 Test MSE 5.747141413259317 Test RE 1.1458664451605816\n",
      "25 Train Loss 1.9759682 Test MSE 5.661484802546633 Test RE 1.1372952707371144\n",
      "26 Train Loss 1.8207278 Test MSE 5.581724989237771 Test RE 1.1292556647292449\n",
      "27 Train Loss 1.7048763 Test MSE 5.565430567332221 Test RE 1.1276061731425175\n",
      "28 Train Loss 1.5830667 Test MSE 5.7110278074367695 Test RE 1.142260601946351\n",
      "29 Train Loss 1.4977531 Test MSE 5.684285494064763 Test RE 1.139583103669436\n",
      "30 Train Loss 1.4310417 Test MSE 5.67790104443128 Test RE 1.1389429480130173\n",
      "31 Train Loss 1.3517108 Test MSE 5.709231376676476 Test RE 1.1420809360839057\n",
      "32 Train Loss 1.2942519 Test MSE 5.724839395297142 Test RE 1.1436409932046154\n",
      "33 Train Loss 1.206669 Test MSE 5.788871893586274 Test RE 1.1500190373448602\n",
      "34 Train Loss 1.1456047 Test MSE 5.864398367803451 Test RE 1.1574967822324451\n",
      "35 Train Loss 1.0951953 Test MSE 5.956025048636964 Test RE 1.1665042302034865\n",
      "36 Train Loss 1.0587717 Test MSE 6.020124231008887 Test RE 1.1727644345112103\n",
      "37 Train Loss 1.0267922 Test MSE 6.06935541810436 Test RE 1.1775499691746345\n",
      "38 Train Loss 0.9998839 Test MSE 6.139278435611276 Test RE 1.184313624540704\n",
      "39 Train Loss 0.9711026 Test MSE 6.2061402795558775 Test RE 1.1907452403229681\n",
      "40 Train Loss 0.9352704 Test MSE 6.264172101026074 Test RE 1.1962994436457468\n",
      "41 Train Loss 0.9116589 Test MSE 6.296725786106489 Test RE 1.1994038834443759\n",
      "42 Train Loss 0.8884509 Test MSE 6.333737686297539 Test RE 1.2029237424499362\n",
      "43 Train Loss 0.8580768 Test MSE 6.370201207235158 Test RE 1.2063814074487162\n",
      "44 Train Loss 0.83987033 Test MSE 6.436277574405528 Test RE 1.2126219995676322\n",
      "45 Train Loss 0.8238931 Test MSE 6.4431977495037005 Test RE 1.2132737196080856\n",
      "46 Train Loss 0.8082979 Test MSE 6.467157497917962 Test RE 1.2155274730686632\n",
      "47 Train Loss 0.79457307 Test MSE 6.495423420530413 Test RE 1.2181809220756696\n",
      "48 Train Loss 0.77959764 Test MSE 6.561996855770678 Test RE 1.2244077483555733\n",
      "49 Train Loss 0.7663751 Test MSE 6.547964392522603 Test RE 1.2230978839699507\n",
      "50 Train Loss 0.75358605 Test MSE 6.610448230434937 Test RE 1.228919723535216\n",
      "51 Train Loss 0.74205685 Test MSE 6.662971758855132 Test RE 1.2337922744706562\n",
      "52 Train Loss 0.7305656 Test MSE 6.692420309795848 Test RE 1.2365157842244665\n",
      "53 Train Loss 0.7185966 Test MSE 6.670642186449491 Test RE 1.2345022423764727\n",
      "54 Train Loss 0.7081768 Test MSE 6.736045642623777 Test RE 1.2405394248786634\n",
      "55 Train Loss 0.69905853 Test MSE 6.751398538584324 Test RE 1.2419523482520654\n",
      "56 Train Loss 0.6900569 Test MSE 6.73903459782624 Test RE 1.2408146238404487\n",
      "57 Train Loss 0.68056494 Test MSE 6.753930454456988 Test RE 1.2421852054953328\n",
      "58 Train Loss 0.67324615 Test MSE 6.764926458147526 Test RE 1.2431959886362425\n",
      "59 Train Loss 0.6656436 Test MSE 6.793075890178761 Test RE 1.2457798254438857\n",
      "60 Train Loss 0.6541927 Test MSE 6.842772951222127 Test RE 1.2503284846597884\n",
      "61 Train Loss 0.6473199 Test MSE 6.861022171237347 Test RE 1.251994645938368\n",
      "62 Train Loss 0.641474 Test MSE 6.887078935774206 Test RE 1.2543698032942063\n",
      "63 Train Loss 0.6331997 Test MSE 6.872402172006715 Test RE 1.2530325231382715\n",
      "64 Train Loss 0.62741673 Test MSE 6.8913133704284935 Test RE 1.2547553608600601\n",
      "65 Train Loss 0.6209365 Test MSE 6.907240042153394 Test RE 1.2562044709616624\n",
      "66 Train Loss 0.6140947 Test MSE 6.9111427450362495 Test RE 1.2565593088176497\n",
      "67 Train Loss 0.608861 Test MSE 6.940073883421002 Test RE 1.2591866402474001\n",
      "68 Train Loss 0.60291564 Test MSE 6.927650313301715 Test RE 1.2580590873542423\n",
      "69 Train Loss 0.5998211 Test MSE 6.936639950198332 Test RE 1.2588750803191981\n",
      "70 Train Loss 0.5957592 Test MSE 6.95686410447103 Test RE 1.2607089043135298\n",
      "71 Train Loss 0.59150684 Test MSE 6.9696600955266055 Test RE 1.2618678035241175\n",
      "72 Train Loss 0.5877044 Test MSE 6.965581099592528 Test RE 1.2614984952018202\n",
      "73 Train Loss 0.5843091 Test MSE 6.978922612123491 Test RE 1.2627060216436077\n",
      "74 Train Loss 0.5811371 Test MSE 6.9917084202064474 Test RE 1.2638621692323095\n",
      "75 Train Loss 0.5776006 Test MSE 7.004503760799883 Test RE 1.265018120963231\n",
      "76 Train Loss 0.5733048 Test MSE 7.0071493652029275 Test RE 1.2652569973825043\n",
      "77 Train Loss 0.568772 Test MSE 7.014879402667289 Test RE 1.2659546982304992\n",
      "78 Train Loss 0.5655905 Test MSE 7.008518635707595 Test RE 1.2653806135899779\n",
      "79 Train Loss 0.5619978 Test MSE 7.032862836783972 Test RE 1.2675763683504613\n",
      "80 Train Loss 0.55805254 Test MSE 7.024669331114343 Test RE 1.2668377700628\n",
      "81 Train Loss 0.5547217 Test MSE 7.047077222675179 Test RE 1.2688566950913829\n",
      "82 Train Loss 0.5515752 Test MSE 7.0584609869459545 Test RE 1.2698811295091592\n",
      "83 Train Loss 0.54837835 Test MSE 7.070292297798072 Test RE 1.270944963946528\n",
      "84 Train Loss 0.5458877 Test MSE 7.0737373973059094 Test RE 1.271254569153778\n",
      "85 Train Loss 0.5433967 Test MSE 7.081740594547776 Test RE 1.271973511940532\n",
      "86 Train Loss 0.5414178 Test MSE 7.090008594473432 Test RE 1.2727158159667902\n",
      "87 Train Loss 0.5391028 Test MSE 7.09000462987325 Test RE 1.2727154601273019\n",
      "88 Train Loss 0.53694063 Test MSE 7.104406795163273 Test RE 1.2740074592378767\n",
      "89 Train Loss 0.5351241 Test MSE 7.1034836909374 Test RE 1.2739246880855644\n",
      "90 Train Loss 0.5332228 Test MSE 7.1227736039519325 Test RE 1.2756532227841406\n",
      "91 Train Loss 0.5312643 Test MSE 7.119590366263882 Test RE 1.2753681399333152\n",
      "92 Train Loss 0.52992964 Test MSE 7.124481765964863 Test RE 1.2758061752624874\n",
      "93 Train Loss 0.5282829 Test MSE 7.125519988310847 Test RE 1.2758991309518437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 Train Loss 0.52654856 Test MSE 7.130011327732876 Test RE 1.27630117833585\n",
      "95 Train Loss 0.52373195 Test MSE 7.144025049191952 Test RE 1.2775548193620165\n",
      "96 Train Loss 0.5220908 Test MSE 7.148762722069307 Test RE 1.2779783644666716\n",
      "97 Train Loss 0.5203426 Test MSE 7.1571979407104935 Test RE 1.2787321206920432\n",
      "98 Train Loss 0.51856524 Test MSE 7.1566864783337785 Test RE 1.27868642997203\n",
      "99 Train Loss 0.5167396 Test MSE 7.1643841755469495 Test RE 1.2793739196130736\n",
      "Training time: 75.82\n",
      "KG_stan_tune15\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 49.622284 Test MSE 9.064890510030398 Test RE 1.439094593856997\n",
      "1 Train Loss 44.306145 Test MSE 8.11921808812723 Test RE 1.361962543369137\n",
      "2 Train Loss 43.58379 Test MSE 8.413279492009504 Test RE 1.386406923667433\n",
      "3 Train Loss 42.729004 Test MSE 8.230807370918098 Test RE 1.3712899059830788\n",
      "4 Train Loss 41.687286 Test MSE 8.10910350754479 Test RE 1.3611139411570308\n",
      "5 Train Loss 40.128265 Test MSE 7.820434550928847 Test RE 1.3366678524356954\n",
      "6 Train Loss 38.693775 Test MSE 7.5075300684598 Test RE 1.3096540805069263\n",
      "7 Train Loss 34.977192 Test MSE 6.789233018049664 Test RE 1.2454274041035047\n",
      "8 Train Loss 30.492517 Test MSE 5.515911296271963 Test RE 1.1225784400639076\n",
      "9 Train Loss 21.06461 Test MSE 4.699792209217844 Test RE 1.0362090685869825\n",
      "10 Train Loss 17.106342 Test MSE 4.017928037563648 Test RE 0.9580962433936019\n",
      "11 Train Loss 14.424236 Test MSE 3.5409888373793468 Test RE 0.8994361509204375\n",
      "12 Train Loss 13.244628 Test MSE 3.4982780418024593 Test RE 0.8939952726846514\n",
      "13 Train Loss 12.300005 Test MSE 3.6311914350985464 Test RE 0.9108201563988734\n",
      "14 Train Loss 11.244621 Test MSE 3.8047495545542205 Test RE 0.9323330887288442\n",
      "15 Train Loss 10.373017 Test MSE 3.797962269404929 Test RE 0.9315011239585097\n",
      "16 Train Loss 9.667413 Test MSE 3.6801771259022145 Test RE 0.9169431724486886\n",
      "17 Train Loss 9.129277 Test MSE 3.706960131087444 Test RE 0.9202737150811244\n",
      "18 Train Loss 8.896562 Test MSE 3.655520723783341 Test RE 0.9138663483912846\n",
      "19 Train Loss 8.666008 Test MSE 3.7100669214014883 Test RE 0.920659273404414\n",
      "20 Train Loss 8.543841 Test MSE 3.6971184138156183 Test RE 0.9190512723164288\n",
      "21 Train Loss 8.441726 Test MSE 3.681490505135926 Test RE 0.9171067768965497\n",
      "22 Train Loss 8.26721 Test MSE 3.650680329915296 Test RE 0.9132611078948227\n",
      "23 Train Loss 8.1389675 Test MSE 3.6578074510694227 Test RE 0.9141521402879257\n",
      "24 Train Loss 8.000921 Test MSE 3.6969174585096853 Test RE 0.9190262946556326\n",
      "25 Train Loss 7.7467966 Test MSE 3.6658410291345467 Test RE 0.9151554578184582\n",
      "26 Train Loss 7.105891 Test MSE 3.244718119637003 Test RE 0.8609869072016515\n",
      "27 Train Loss 5.312563 Test MSE 2.639508815651188 Test RE 0.7765503480632651\n",
      "28 Train Loss 4.6648216 Test MSE 2.4501989438798897 Test RE 0.7481845477016592\n",
      "29 Train Loss 3.842802 Test MSE 2.0064500822584592 Test RE 0.6770523347557423\n",
      "30 Train Loss 2.5152287 Test MSE 1.3370536809169358 Test RE 0.5526911140941762\n",
      "31 Train Loss 1.3676268 Test MSE 0.674228396294864 Test RE 0.3924746222190014\n",
      "32 Train Loss 0.80595315 Test MSE 0.3505212453339058 Test RE 0.2829861842811428\n",
      "33 Train Loss 0.48941386 Test MSE 0.16195114564035307 Test RE 0.19235349094829665\n",
      "34 Train Loss 0.29800943 Test MSE 0.10641401063187149 Test RE 0.1559220248701997\n",
      "35 Train Loss 0.2027794 Test MSE 0.07312423011325514 Test RE 0.12925242906124873\n",
      "36 Train Loss 0.15138493 Test MSE 0.07771012355628276 Test RE 0.13324375401323946\n",
      "37 Train Loss 0.124678075 Test MSE 0.06252158071663719 Test RE 0.11951517042312926\n",
      "38 Train Loss 0.09819322 Test MSE 0.05472935744151868 Test RE 0.1118196773822909\n",
      "39 Train Loss 0.07258496 Test MSE 0.04805879314162314 Test RE 0.10478388357783316\n",
      "40 Train Loss 0.064098604 Test MSE 0.045520124741918216 Test RE 0.10197877294581273\n",
      "41 Train Loss 0.055648014 Test MSE 0.04105030188975581 Test RE 0.09684255478146671\n",
      "42 Train Loss 0.04523462 Test MSE 0.03863224412507034 Test RE 0.09394702429321923\n",
      "43 Train Loss 0.03682643 Test MSE 0.032218866295123945 Test RE 0.08579523883635976\n",
      "44 Train Loss 0.033419076 Test MSE 0.030258127465193463 Test RE 0.0831436496596565\n",
      "45 Train Loss 0.030133028 Test MSE 0.026797213094670338 Test RE 0.0782443298418296\n",
      "46 Train Loss 0.02733592 Test MSE 0.02266507147776059 Test RE 0.07195924644602028\n",
      "47 Train Loss 0.02453688 Test MSE 0.021993417834258143 Test RE 0.07088501291579567\n",
      "48 Train Loss 0.02062055 Test MSE 0.016033990859270555 Test RE 0.060524174692854434\n",
      "49 Train Loss 0.018765656 Test MSE 0.013790634803948019 Test RE 0.05613066522289948\n",
      "50 Train Loss 0.017819945 Test MSE 0.012527643952535248 Test RE 0.05349864238033081\n",
      "51 Train Loss 0.016292974 Test MSE 0.010272598461403083 Test RE 0.04844491704576588\n",
      "52 Train Loss 0.014027984 Test MSE 0.008085079923721827 Test RE 0.042978397569962516\n",
      "53 Train Loss 0.012849866 Test MSE 0.007311455566621145 Test RE 0.04087050301108377\n",
      "54 Train Loss 0.0116869025 Test MSE 0.006161738526212239 Test RE 0.03751972899488105\n",
      "55 Train Loss 0.010450333 Test MSE 0.005464113758235142 Test RE 0.03533197597759472\n",
      "56 Train Loss 0.009419877 Test MSE 0.004417156778810781 Test RE 0.031767238769234964\n",
      "57 Train Loss 0.0087087825 Test MSE 0.0030750824890222093 Test RE 0.026505527110596495\n",
      "58 Train Loss 0.008108532 Test MSE 0.002702657067745171 Test RE 0.02484869192416732\n",
      "59 Train Loss 0.00753005 Test MSE 0.002582275234371543 Test RE 0.02428898268790801\n",
      "60 Train Loss 0.0069572586 Test MSE 0.0027295173762169594 Test RE 0.02497186577854882\n",
      "61 Train Loss 0.0064343098 Test MSE 0.00267728612280644 Test RE 0.02473178450649076\n",
      "62 Train Loss 0.005690176 Test MSE 0.0023147422648937734 Test RE 0.02299637494677929\n",
      "63 Train Loss 0.0052579064 Test MSE 0.0016441004387513732 Test RE 0.019380823786577333\n",
      "64 Train Loss 0.004680626 Test MSE 0.00127112983195647 Test RE 0.01704131153370158\n",
      "65 Train Loss 0.0044127 Test MSE 0.0011911767811646518 Test RE 0.016496665560977904\n",
      "66 Train Loss 0.004139087 Test MSE 0.0012749653038087775 Test RE 0.01706700215882345\n",
      "67 Train Loss 0.0038898783 Test MSE 0.0011352799508653414 Test RE 0.016104956065719263\n",
      "68 Train Loss 0.003579595 Test MSE 0.0010140004061981636 Test RE 0.015220437103414312\n",
      "69 Train Loss 0.003354548 Test MSE 0.0008647945540537448 Test RE 0.014056090131016016\n",
      "70 Train Loss 0.0031715762 Test MSE 0.0007363424854402266 Test RE 0.012970239328855824\n",
      "71 Train Loss 0.0028594302 Test MSE 0.0007102884598251045 Test RE 0.01273870966905287\n",
      "72 Train Loss 0.0026251562 Test MSE 0.0005632206182542249 Test RE 0.01134350672279814\n",
      "73 Train Loss 0.002409947 Test MSE 0.00044909278354776275 Test RE 0.010129222208334555\n",
      "74 Train Loss 0.0021843053 Test MSE 0.00034761933432393395 Test RE 0.008911688999541544\n",
      "75 Train Loss 0.0020729583 Test MSE 0.0003381564800767002 Test RE 0.008789555593649015\n",
      "76 Train Loss 0.0019570026 Test MSE 0.00033335034605796256 Test RE 0.008726870178791318\n",
      "77 Train Loss 0.001851197 Test MSE 0.0002711681849841563 Test RE 0.00787095496301794\n",
      "78 Train Loss 0.0016933852 Test MSE 0.0002494677583624155 Test RE 0.007549449295343919\n",
      "79 Train Loss 0.0016018717 Test MSE 0.0002010936296438036 Test RE 0.006778088215176043\n",
      "80 Train Loss 0.0015187426 Test MSE 0.000205071112510584 Test RE 0.0068447927677938334\n",
      "81 Train Loss 0.0014527269 Test MSE 0.00021357320256661344 Test RE 0.006985241737504938\n",
      "82 Train Loss 0.0013918686 Test MSE 0.00021791185155634938 Test RE 0.007055836127296239\n",
      "83 Train Loss 0.0013396557 Test MSE 0.0002203787732898091 Test RE 0.007095662344947898\n",
      "84 Train Loss 0.0012896323 Test MSE 0.0002155003145301956 Test RE 0.0070166855537737\n",
      "85 Train Loss 0.0012331408 Test MSE 0.00019989774455242976 Test RE 0.006757903832017356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 0.0011799069 Test MSE 0.00016371853668388178 Test RE 0.006115852284676926\n",
      "87 Train Loss 0.0011454084 Test MSE 0.00016458682454951863 Test RE 0.006132048673213063\n",
      "88 Train Loss 0.0010921624 Test MSE 0.0001547964052458171 Test RE 0.005946870698291296\n",
      "89 Train Loss 0.0010361213 Test MSE 0.0001532954859552456 Test RE 0.005917969785718568\n",
      "90 Train Loss 0.0009710439 Test MSE 0.00015318003384867903 Test RE 0.005915740852603393\n",
      "91 Train Loss 0.0009399385 Test MSE 0.00016283084177010198 Test RE 0.006099249430083854\n",
      "92 Train Loss 0.00090965215 Test MSE 0.0001519848206768038 Test RE 0.005892616370855843\n",
      "93 Train Loss 0.0008852746 Test MSE 0.00015269773370144512 Test RE 0.005906420407861343\n",
      "94 Train Loss 0.00085688144 Test MSE 0.00014102923273070491 Test RE 0.005676264598461876\n",
      "95 Train Loss 0.00082861376 Test MSE 0.00014859984521204927 Test RE 0.005826627292677406\n",
      "96 Train Loss 0.0007947773 Test MSE 0.00014043815622379144 Test RE 0.005664357033547316\n",
      "97 Train Loss 0.0007733335 Test MSE 0.00012279681857709795 Test RE 0.005296654170774651\n",
      "98 Train Loss 0.00073676294 Test MSE 0.00014263706669948942 Test RE 0.005708529633030832\n",
      "99 Train Loss 0.00070441474 Test MSE 0.00012996300567164051 Test RE 0.005449014124728042\n",
      "Training time: 76.51\n",
      "KG_stan_tune15\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 60.92297 Test MSE 8.124625466873827 Test RE 1.362415999689055\n",
      "1 Train Loss 54.49434 Test MSE 9.26566504512751 Test RE 1.454944269923269\n",
      "2 Train Loss 46.721703 Test MSE 8.500864072953057 Test RE 1.3936046804630504\n",
      "3 Train Loss 44.830116 Test MSE 8.56136670735804 Test RE 1.3985551925391166\n",
      "4 Train Loss 43.822227 Test MSE 8.5246844473403 Test RE 1.3955558328763698\n",
      "5 Train Loss 43.475105 Test MSE 8.421355896566327 Test RE 1.387072211043538\n",
      "6 Train Loss 42.7885 Test MSE 8.496159742685519 Test RE 1.3932190206122288\n",
      "7 Train Loss 41.93715 Test MSE 8.640575533296392 Test RE 1.4050099369034121\n",
      "8 Train Loss 40.49642 Test MSE 8.566897936754291 Test RE 1.3990069008240356\n",
      "9 Train Loss 39.02068 Test MSE 8.228912717033985 Test RE 1.3711320679264722\n",
      "10 Train Loss 37.82853 Test MSE 8.427166102022772 Test RE 1.3875506247946374\n",
      "11 Train Loss 37.342022 Test MSE 8.238501110503115 Test RE 1.3719306622677672\n",
      "12 Train Loss 36.647648 Test MSE 8.289021212451345 Test RE 1.3761307069604793\n",
      "13 Train Loss 36.095634 Test MSE 8.25067176598076 Test RE 1.372943658022069\n",
      "14 Train Loss 35.16406 Test MSE 8.171403668096975 Test RE 1.3663324816565319\n",
      "15 Train Loss 33.79399 Test MSE 8.469036709454553 Test RE 1.3909933955110882\n",
      "16 Train Loss 32.34545 Test MSE 9.08758285709058 Test RE 1.4408947271339492\n",
      "17 Train Loss 30.506664 Test MSE 9.224856044809616 Test RE 1.451736710522296\n",
      "18 Train Loss 27.998474 Test MSE 9.878616349295461 Test RE 1.5022981067233168\n",
      "19 Train Loss 26.06812 Test MSE 9.585069063645257 Test RE 1.479809065410796\n",
      "20 Train Loss 23.123856 Test MSE 8.607303145552505 Test RE 1.402302181765285\n",
      "21 Train Loss 20.382677 Test MSE 8.212357239015716 Test RE 1.3697521058154971\n",
      "22 Train Loss 18.530365 Test MSE 7.812776045855849 Test RE 1.3360131966797808\n",
      "23 Train Loss 16.624418 Test MSE 7.263868256631044 Test RE 1.2882259392813935\n",
      "24 Train Loss 14.845432 Test MSE 7.348779455621728 Test RE 1.295733440506557\n",
      "25 Train Loss 12.721661 Test MSE 7.0677938132981 Test RE 1.270720382221986\n",
      "26 Train Loss 10.394365 Test MSE 6.209735366062994 Test RE 1.1910900772251805\n",
      "27 Train Loss 8.774731 Test MSE 5.901305380418098 Test RE 1.1611333654937637\n",
      "28 Train Loss 7.46806 Test MSE 5.646108654924401 Test RE 1.1357498184208914\n",
      "29 Train Loss 6.481222 Test MSE 5.442192345154459 Test RE 1.1150516991855413\n",
      "30 Train Loss 5.929954 Test MSE 5.492326971284343 Test RE 1.1201759707358572\n",
      "31 Train Loss 5.176522 Test MSE 5.532909469688854 Test RE 1.1243068130997962\n",
      "32 Train Loss 4.5980396 Test MSE 5.803234482844466 Test RE 1.1514447917022474\n",
      "33 Train Loss 4.0428576 Test MSE 5.843313279156219 Test RE 1.155414053727334\n",
      "34 Train Loss 3.6264591 Test MSE 5.796230395912684 Test RE 1.1507497263618744\n",
      "35 Train Loss 3.3231688 Test MSE 5.872286044825405 Test RE 1.1582749432891704\n",
      "36 Train Loss 3.0477538 Test MSE 5.933402822470851 Test RE 1.1642868093848318\n",
      "37 Train Loss 2.8453875 Test MSE 5.790101612805608 Test RE 1.1501411790542293\n",
      "38 Train Loss 2.6714456 Test MSE 5.729717463818363 Test RE 1.1441281309957942\n",
      "39 Train Loss 2.4851906 Test MSE 5.899639544152027 Test RE 1.160969470010778\n",
      "40 Train Loss 2.3358488 Test MSE 5.869423519169129 Test RE 1.1579926004440713\n",
      "41 Train Loss 2.229242 Test MSE 5.818756116996894 Test RE 1.152983620631303\n",
      "42 Train Loss 2.1172092 Test MSE 5.858798995568064 Test RE 1.156944056891718\n",
      "43 Train Loss 2.0063677 Test MSE 5.824991722385898 Test RE 1.1536012462556207\n",
      "44 Train Loss 1.9041224 Test MSE 5.908997371759116 Test RE 1.1618898522979586\n",
      "45 Train Loss 1.8450966 Test MSE 5.901489018876563 Test RE 1.1611514315883618\n",
      "46 Train Loss 1.7744921 Test MSE 5.816269945858414 Test RE 1.1527372775296691\n",
      "47 Train Loss 1.7168307 Test MSE 5.859591567100036 Test RE 1.1570223092703211\n",
      "48 Train Loss 1.6553906 Test MSE 5.895971776251308 Test RE 1.1606085302831526\n",
      "49 Train Loss 1.6020786 Test MSE 5.8503208469171675 Test RE 1.1561066587508517\n",
      "50 Train Loss 1.5580857 Test MSE 5.874832507176514 Test RE 1.1585260536596385\n",
      "51 Train Loss 1.5183306 Test MSE 5.875159832566003 Test RE 1.1585583277465417\n",
      "52 Train Loss 1.482725 Test MSE 5.869477600424436 Test RE 1.1579979353418688\n",
      "53 Train Loss 1.4451371 Test MSE 5.8555483081380055 Test RE 1.1566230537886386\n",
      "54 Train Loss 1.4055891 Test MSE 5.85661455108655 Test RE 1.1567283543493123\n",
      "55 Train Loss 1.3756156 Test MSE 5.8455697960920014 Test RE 1.1556371257754083\n",
      "56 Train Loss 1.3565046 Test MSE 5.842445197216409 Test RE 1.1553282264510047\n",
      "57 Train Loss 1.3366545 Test MSE 5.8017098201965425 Test RE 1.15129352431906\n",
      "58 Train Loss 1.3137314 Test MSE 5.8525177141412 Test RE 1.1563237044911268\n",
      "59 Train Loss 1.2900614 Test MSE 5.839581119099313 Test RE 1.1550450097663119\n",
      "60 Train Loss 1.2658964 Test MSE 5.834896871930494 Test RE 1.1545816544622591\n",
      "61 Train Loss 1.2401088 Test MSE 5.880054329200597 Test RE 1.1590408149875218\n",
      "62 Train Loss 1.2121426 Test MSE 5.865104392565791 Test RE 1.1575664566256345\n",
      "63 Train Loss 1.1834261 Test MSE 5.881037720743221 Test RE 1.1591377310379514\n",
      "64 Train Loss 1.1699369 Test MSE 5.911761468409343 Test RE 1.1621615735527369\n",
      "65 Train Loss 1.1500677 Test MSE 5.914870886323468 Test RE 1.1624671652948477\n",
      "66 Train Loss 1.1331128 Test MSE 5.939776795340177 Test RE 1.1649120105370498\n",
      "67 Train Loss 1.1103762 Test MSE 5.951851672844736 Test RE 1.1660954749035752\n",
      "68 Train Loss 1.0865513 Test MSE 6.03015315648167 Test RE 1.1737408822003836\n",
      "69 Train Loss 1.0541391 Test MSE 6.012031004040351 Test RE 1.1719758593492298\n",
      "70 Train Loss 1.0127097 Test MSE 6.1381290829201 Test RE 1.1842027599024483\n",
      "71 Train Loss 0.9849147 Test MSE 6.158617404752494 Test RE 1.1861774752011602\n",
      "72 Train Loss 0.95372635 Test MSE 6.105213493188961 Test RE 1.1810233604536953\n",
      "73 Train Loss 0.92796135 Test MSE 6.204558938776852 Test RE 1.1905935281570257\n",
      "74 Train Loss 0.90824974 Test MSE 6.188256755885432 Test RE 1.1890283855216837\n",
      "75 Train Loss 0.8949741 Test MSE 6.241862931407863 Test RE 1.194167298233584\n",
      "76 Train Loss 0.88385713 Test MSE 6.2390204773019615 Test RE 1.1938953640128565\n",
      "77 Train Loss 0.87089086 Test MSE 6.274679511823766 Test RE 1.1973023489560912\n",
      "78 Train Loss 0.86030936 Test MSE 6.269266234551042 Test RE 1.196785770533657\n",
      "79 Train Loss 0.8512084 Test MSE 6.275042646418171 Test RE 1.1973369942006566\n",
      "80 Train Loss 0.842074 Test MSE 6.297243055883124 Test RE 1.199453147352227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 Train Loss 0.83425665 Test MSE 6.300128719251299 Test RE 1.1997279359819586\n",
      "82 Train Loss 0.8258591 Test MSE 6.330912901291797 Test RE 1.202655466427756\n",
      "83 Train Loss 0.8162587 Test MSE 6.374064030353234 Test RE 1.2067471205245608\n",
      "84 Train Loss 0.80902064 Test MSE 6.3892828375924955 Test RE 1.2081868850538082\n",
      "85 Train Loss 0.80089384 Test MSE 6.385829115220812 Test RE 1.2078602986257365\n",
      "86 Train Loss 0.79491377 Test MSE 6.396110093789473 Test RE 1.2088322156235538\n",
      "87 Train Loss 0.78800803 Test MSE 6.392904929499855 Test RE 1.2085292978106683\n",
      "88 Train Loss 0.7804957 Test MSE 6.414135306233831 Test RE 1.2105343538972715\n",
      "89 Train Loss 0.77361226 Test MSE 6.425280424152644 Test RE 1.2115856017956055\n",
      "90 Train Loss 0.7661477 Test MSE 6.430413852282674 Test RE 1.2120694986392329\n",
      "91 Train Loss 0.75891495 Test MSE 6.453636260856824 Test RE 1.2142561235824985\n",
      "92 Train Loss 0.7531326 Test MSE 6.488227817020344 Test RE 1.2175059871787455\n",
      "93 Train Loss 0.7472135 Test MSE 6.506066130956015 Test RE 1.2191785044996997\n",
      "94 Train Loss 0.7420654 Test MSE 6.524861040940937 Test RE 1.2209382334003511\n",
      "95 Train Loss 0.73622483 Test MSE 6.5264573610055585 Test RE 1.2210875767346245\n",
      "96 Train Loss 0.73252046 Test MSE 6.534770106250247 Test RE 1.2218649785655185\n",
      "97 Train Loss 0.7267359 Test MSE 6.560181557945113 Test RE 1.2242383777728296\n",
      "98 Train Loss 0.723124 Test MSE 6.5712052579688 Test RE 1.2252665483936733\n",
      "99 Train Loss 0.7189126 Test MSE 6.575431801488631 Test RE 1.2256605255820179\n",
      "Training time: 76.27\n",
      "KG_stan_tune15\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 56.038994 Test MSE 8.268155515609223 Test RE 1.3743975699374587\n",
      "1 Train Loss 49.78236 Test MSE 8.793150578028952 Test RE 1.4173604675332256\n",
      "2 Train Loss 46.506638 Test MSE 8.470514487226502 Test RE 1.3911147487138618\n",
      "3 Train Loss 45.552673 Test MSE 8.512577932046153 Test RE 1.3945645163669307\n",
      "4 Train Loss 44.910156 Test MSE 8.411805320480042 Test RE 1.3862854555078743\n",
      "5 Train Loss 44.517982 Test MSE 8.279150298694296 Test RE 1.3753110858261886\n",
      "6 Train Loss 43.51362 Test MSE 8.276081804339364 Test RE 1.3750561970242265\n",
      "7 Train Loss 42.389297 Test MSE 8.527093384296865 Test RE 1.395752999620616\n",
      "8 Train Loss 39.666267 Test MSE 8.478572567232044 Test RE 1.391776281685071\n",
      "9 Train Loss 34.691074 Test MSE 7.9790361650516095 Test RE 1.350153905584033\n",
      "10 Train Loss 29.9679 Test MSE 7.516881581471542 Test RE 1.310469490874205\n",
      "11 Train Loss 25.692928 Test MSE 7.360336993625762 Test RE 1.2967519501211602\n",
      "12 Train Loss 22.514887 Test MSE 6.183361886272313 Test RE 1.1885580357510466\n",
      "13 Train Loss 17.164677 Test MSE 5.528465773695651 Test RE 1.12385523502435\n",
      "14 Train Loss 12.574645 Test MSE 4.579990635565669 Test RE 1.022916903489634\n",
      "15 Train Loss 9.167916 Test MSE 4.019804276783561 Test RE 0.9583199168794766\n",
      "16 Train Loss 7.2416053 Test MSE 3.0546846378886428 Test RE 0.8353938056482585\n",
      "17 Train Loss 3.886744 Test MSE 2.1684716175682968 Test RE 0.7038578058971422\n",
      "18 Train Loss 2.8294516 Test MSE 2.625252616208641 Test RE 0.7744504032826904\n",
      "19 Train Loss 2.1185772 Test MSE 2.389005706624568 Test RE 0.7387825924870194\n",
      "20 Train Loss 1.6910233 Test MSE 2.343484659394685 Test RE 0.7317102145493255\n",
      "21 Train Loss 1.4371558 Test MSE 2.3962129902630327 Test RE 0.7398961532090553\n",
      "22 Train Loss 1.2952623 Test MSE 2.464704397159218 Test RE 0.7503959479258014\n",
      "23 Train Loss 1.1829083 Test MSE 2.508497709587148 Test RE 0.7570331801516539\n",
      "24 Train Loss 1.073909 Test MSE 2.5334269331882866 Test RE 0.7607855442095827\n",
      "25 Train Loss 1.0118817 Test MSE 2.649820273246023 Test RE 0.778065698346845\n",
      "26 Train Loss 0.9333544 Test MSE 2.6906739284129184 Test RE 0.7840406780486266\n",
      "27 Train Loss 0.87670225 Test MSE 2.732522113819883 Test RE 0.7901142652910906\n",
      "28 Train Loss 0.8192902 Test MSE 2.769195786090948 Test RE 0.7953987265113456\n",
      "29 Train Loss 0.75649524 Test MSE 2.860398812415856 Test RE 0.8083907860096998\n",
      "30 Train Loss 0.70903665 Test MSE 2.905329929415948 Test RE 0.8147151443818897\n",
      "31 Train Loss 0.6768913 Test MSE 2.9510609200085676 Test RE 0.8211020714191328\n",
      "32 Train Loss 0.64582896 Test MSE 2.973937764274597 Test RE 0.824278549467179\n",
      "33 Train Loss 0.6237935 Test MSE 2.991525771516382 Test RE 0.8267123673196457\n",
      "34 Train Loss 0.5950173 Test MSE 3.0113887369116075 Test RE 0.8294524058105404\n",
      "35 Train Loss 0.5718521 Test MSE 3.078625017705612 Test RE 0.8386610188855741\n",
      "36 Train Loss 0.5470362 Test MSE 3.081484614235083 Test RE 0.8390504257605874\n",
      "37 Train Loss 0.5250602 Test MSE 3.1089688097880246 Test RE 0.8427839238401577\n",
      "38 Train Loss 0.50921434 Test MSE 3.1236085721515843 Test RE 0.8447658777442286\n",
      "39 Train Loss 0.49448085 Test MSE 3.126777409748189 Test RE 0.8451942680553547\n",
      "40 Train Loss 0.48003882 Test MSE 3.1765888023767377 Test RE 0.8518998869432757\n",
      "41 Train Loss 0.469465 Test MSE 3.204064278145028 Test RE 0.8555761512215435\n",
      "42 Train Loss 0.45936105 Test MSE 3.2273955428047105 Test RE 0.8586855561071336\n",
      "43 Train Loss 0.44807136 Test MSE 3.2576264263438452 Test RE 0.8626978187715273\n",
      "44 Train Loss 0.43746588 Test MSE 3.282192003948362 Test RE 0.8659444873885707\n",
      "45 Train Loss 0.42663726 Test MSE 3.281880304263168 Test RE 0.8659033683692787\n",
      "46 Train Loss 0.41799995 Test MSE 3.2931374511660465 Test RE 0.8673871605911841\n",
      "47 Train Loss 0.4106859 Test MSE 3.3209510682819405 Test RE 0.871042405600245\n",
      "48 Train Loss 0.40022123 Test MSE 3.338717585583986 Test RE 0.8733692612453939\n",
      "49 Train Loss 0.3923083 Test MSE 3.3322036483316757 Test RE 0.8725168605829215\n",
      "50 Train Loss 0.38580844 Test MSE 3.337685599344691 Test RE 0.8732342730808261\n",
      "51 Train Loss 0.3762665 Test MSE 3.353770414679863 Test RE 0.8753358686378876\n",
      "52 Train Loss 0.36864418 Test MSE 3.3947239063890975 Test RE 0.8806640936156557\n",
      "53 Train Loss 0.36258048 Test MSE 3.4202648902042068 Test RE 0.8839708246680527\n",
      "54 Train Loss 0.35817486 Test MSE 3.4335240737815003 Test RE 0.8856825918084447\n",
      "55 Train Loss 0.35366467 Test MSE 3.4513576653430973 Test RE 0.8879797134857303\n",
      "56 Train Loss 0.34740123 Test MSE 3.4985883244242135 Test RE 0.8940349186251889\n",
      "57 Train Loss 0.34205586 Test MSE 3.4997237856500796 Test RE 0.8941799856548349\n",
      "58 Train Loss 0.33763126 Test MSE 3.504022509333818 Test RE 0.8947289794173562\n",
      "59 Train Loss 0.33362463 Test MSE 3.5347196976239297 Test RE 0.8986395953316542\n",
      "60 Train Loss 0.33089295 Test MSE 3.535602108716966 Test RE 0.8987517569925678\n",
      "61 Train Loss 0.32822266 Test MSE 3.5363112464058646 Test RE 0.8988418840444262\n",
      "62 Train Loss 0.3246234 Test MSE 3.553020026176529 Test RE 0.900962858624541\n",
      "63 Train Loss 0.32211614 Test MSE 3.5646757969121605 Test RE 0.9024394641604541\n",
      "64 Train Loss 0.31957468 Test MSE 3.5784677251655386 Test RE 0.9041835729308939\n",
      "65 Train Loss 0.3173626 Test MSE 3.5700972107942084 Test RE 0.9031254506730317\n",
      "66 Train Loss 0.3152886 Test MSE 3.566845760055475 Test RE 0.9027140981749252\n",
      "67 Train Loss 0.312749 Test MSE 3.565187850165801 Test RE 0.9025042779747667\n",
      "68 Train Loss 0.31009048 Test MSE 3.571479688877185 Test RE 0.9033002960931618\n",
      "69 Train Loss 0.30784133 Test MSE 3.573146819240946 Test RE 0.903511097187726\n",
      "70 Train Loss 0.30490693 Test MSE 3.5753544385277514 Test RE 0.903790165000316\n",
      "71 Train Loss 0.30234966 Test MSE 3.5872576718970683 Test RE 0.9052933846506374\n",
      "72 Train Loss 0.30000898 Test MSE 3.5809354691603232 Test RE 0.9044952858211726\n",
      "73 Train Loss 0.29693425 Test MSE 3.6063250810307723 Test RE 0.9076961563458533\n",
      "74 Train Loss 0.2951604 Test MSE 3.61805336398187 Test RE 0.9091709368792957\n",
      "75 Train Loss 0.29271606 Test MSE 3.6288065090988284 Test RE 0.9105209990143617\n",
      "76 Train Loss 0.2905587 Test MSE 3.630422365782035 Test RE 0.9107236975724257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 Train Loss 0.2890402 Test MSE 3.626048123970645 Test RE 0.9101748734988832\n",
      "78 Train Loss 0.2878827 Test MSE 3.6203080570283435 Test RE 0.9094541806459157\n",
      "79 Train Loss 0.28619027 Test MSE 3.626387229831252 Test RE 0.9102174320098951\n",
      "80 Train Loss 0.28317532 Test MSE 3.6444407738323554 Test RE 0.9124803245478377\n",
      "81 Train Loss 0.28089264 Test MSE 3.6339558704771093 Test RE 0.9111667953009511\n",
      "82 Train Loss 0.27948388 Test MSE 3.6457165059136645 Test RE 0.9126400168905612\n",
      "83 Train Loss 0.27753785 Test MSE 3.658276491286307 Test RE 0.9142107492195535\n",
      "84 Train Loss 0.27556688 Test MSE 3.6729071483390783 Test RE 0.9160370405602317\n",
      "85 Train Loss 0.27367586 Test MSE 3.6812317865058857 Test RE 0.9170745512562352\n",
      "86 Train Loss 0.2723574 Test MSE 3.696556155435094 Test RE 0.9189813849243731\n",
      "87 Train Loss 0.27105933 Test MSE 3.696343753990414 Test RE 0.9189549825420507\n",
      "88 Train Loss 0.27008888 Test MSE 3.703405751953836 Test RE 0.9198324119591879\n",
      "89 Train Loss 0.268466 Test MSE 3.7185592011627433 Test RE 0.9217123577951212\n",
      "90 Train Loss 0.2669726 Test MSE 3.7202092968178406 Test RE 0.9219168381848619\n",
      "91 Train Loss 0.26588893 Test MSE 3.7215230247303346 Test RE 0.9220796033522979\n",
      "92 Train Loss 0.26455057 Test MSE 3.737675081077456 Test RE 0.924078429707871\n",
      "93 Train Loss 0.2634117 Test MSE 3.74594991262088 Test RE 0.9251007718934298\n",
      "94 Train Loss 0.2623145 Test MSE 3.7601654620018703 Test RE 0.9268544476076154\n",
      "95 Train Loss 0.2609911 Test MSE 3.7749781298648757 Test RE 0.92867826263944\n",
      "96 Train Loss 0.25985286 Test MSE 3.7623748481810284 Test RE 0.9271267067287531\n",
      "97 Train Loss 0.2585406 Test MSE 3.7793057268046226 Test RE 0.9292104238744657\n",
      "98 Train Loss 0.25692973 Test MSE 3.7859446490872073 Test RE 0.9300262151116534\n",
      "99 Train Loss 0.2560438 Test MSE 3.787522994289455 Test RE 0.9302200570179476\n",
      "Training time: 74.08\n",
      "KG_stan_tune15\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 48.282703 Test MSE 8.167364886100186 Test RE 1.3659947795131997\n",
      "1 Train Loss 42.219063 Test MSE 8.032910606161325 Test RE 1.3547043559956142\n",
      "2 Train Loss 39.243126 Test MSE 8.002587042732419 Test RE 1.3521449907349967\n",
      "3 Train Loss 29.374977 Test MSE 5.96002345658933 Test RE 1.1668957142240648\n",
      "4 Train Loss 24.556246 Test MSE 5.306156377678151 Test RE 1.101027288067292\n",
      "5 Train Loss 22.570152 Test MSE 5.075637773453954 Test RE 1.0768454334083357\n",
      "6 Train Loss 19.958101 Test MSE 5.366034700396959 Test RE 1.1072222351619918\n",
      "7 Train Loss 15.705603 Test MSE 5.730541425981582 Test RE 1.1442103937257018\n",
      "8 Train Loss 14.02087 Test MSE 5.722358843606595 Test RE 1.143393198657899\n",
      "9 Train Loss 13.1309805 Test MSE 5.722267355573626 Test RE 1.1433840584400603\n",
      "10 Train Loss 12.441226 Test MSE 5.75712038867217 Test RE 1.1468608189715515\n",
      "11 Train Loss 11.831654 Test MSE 5.540222906811515 Test RE 1.1250496258883393\n",
      "12 Train Loss 10.630849 Test MSE 5.459633332801924 Test RE 1.1168370133853707\n",
      "13 Train Loss 9.560443 Test MSE 5.11485989557465 Test RE 1.0809981018478023\n",
      "14 Train Loss 8.881435 Test MSE 4.695463194834021 Test RE 1.035731728610376\n",
      "15 Train Loss 8.345093 Test MSE 4.185043525064501 Test RE 0.9778180499385678\n",
      "16 Train Loss 7.784176 Test MSE 3.6319224782818846 Test RE 0.9109118364120514\n",
      "17 Train Loss 6.876338 Test MSE 2.769161572616969 Test RE 0.7953938129119129\n",
      "18 Train Loss 6.1340313 Test MSE 2.718094872254765 Test RE 0.7880256718315136\n",
      "19 Train Loss 5.8751183 Test MSE 2.6977766482316894 Test RE 0.7850748336491492\n",
      "20 Train Loss 5.7225294 Test MSE 2.694189801864891 Test RE 0.7845527594018119\n",
      "21 Train Loss 5.535641 Test MSE 2.6441587312761765 Test RE 0.7772340557068392\n",
      "22 Train Loss 5.070725 Test MSE 2.3054222625355045 Test RE 0.7257437452652923\n",
      "23 Train Loss 4.5385947 Test MSE 2.145875513014646 Test RE 0.7001810010079828\n",
      "24 Train Loss 4.4022274 Test MSE 2.1266972648969533 Test RE 0.6970451288106193\n",
      "25 Train Loss 4.3304243 Test MSE 2.1260553563553586 Test RE 0.6969399250757993\n",
      "26 Train Loss 4.2381835 Test MSE 2.1346004296100904 Test RE 0.6983390962405508\n",
      "27 Train Loss 4.044245 Test MSE 2.0816222572847707 Test RE 0.6896186876233232\n",
      "28 Train Loss 3.284956 Test MSE 1.6142206245149253 Test RE 0.6072807380377051\n",
      "29 Train Loss 2.0736737 Test MSE 1.4932589876200446 Test RE 0.5840844294588404\n",
      "30 Train Loss 1.3247151 Test MSE 0.9249944509153094 Test RE 0.4597033027664803\n",
      "31 Train Loss 0.83531946 Test MSE 0.5603336435145565 Test RE 0.35779264593862825\n",
      "32 Train Loss 0.54133856 Test MSE 0.3253371203111292 Test RE 0.27263076952149023\n",
      "33 Train Loss 0.33268425 Test MSE 0.18666682912006657 Test RE 0.20651026091560262\n",
      "34 Train Loss 0.24442774 Test MSE 0.12447506470219827 Test RE 0.1686355916340806\n",
      "35 Train Loss 0.17500535 Test MSE 0.08046827674112007 Test RE 0.13558773650460323\n",
      "36 Train Loss 0.123223625 Test MSE 0.061023933097964105 Test RE 0.11807505536797729\n",
      "37 Train Loss 0.08368499 Test MSE 0.034140415689450414 Test RE 0.08831662467602598\n",
      "38 Train Loss 0.061203133 Test MSE 0.015642916757763935 Test RE 0.05978151645237502\n",
      "39 Train Loss 0.047054667 Test MSE 0.016882845456201494 Test RE 0.062105617294587925\n",
      "40 Train Loss 0.03718846 Test MSE 0.014334325197505748 Test RE 0.057226434336685054\n",
      "41 Train Loss 0.03042451 Test MSE 0.012688089823620062 Test RE 0.053840140251336134\n",
      "42 Train Loss 0.025903206 Test MSE 0.009194118749952233 Test RE 0.04583139904167915\n",
      "43 Train Loss 0.021365628 Test MSE 0.009298494390187114 Test RE 0.046090813873029754\n",
      "44 Train Loss 0.018186808 Test MSE 0.007611361420906507 Test RE 0.04170030510988999\n",
      "45 Train Loss 0.015058912 Test MSE 0.005881932784947542 Test RE 0.03665794277758363\n",
      "46 Train Loss 0.011923887 Test MSE 0.005797496538096992 Test RE 0.03639387585194973\n",
      "47 Train Loss 0.010252141 Test MSE 0.005231171455840739 Test RE 0.034570649389289124\n",
      "48 Train Loss 0.008366577 Test MSE 0.004572351211508824 Test RE 0.03232048367090054\n",
      "49 Train Loss 0.007143642 Test MSE 0.004421065787321557 Test RE 0.03178129203379386\n",
      "50 Train Loss 0.006298217 Test MSE 0.00455105182322744 Test RE 0.03224511652681926\n",
      "51 Train Loss 0.0056354823 Test MSE 0.004162792382253849 Test RE 0.030839010572245328\n",
      "52 Train Loss 0.005142181 Test MSE 0.0037395662767372422 Test RE 0.029229317691820546\n",
      "53 Train Loss 0.0044691474 Test MSE 0.003070414098056749 Test RE 0.026485399981936237\n",
      "54 Train Loss 0.0042016516 Test MSE 0.0029954851779607555 Test RE 0.026160235409196198\n",
      "55 Train Loss 0.003922616 Test MSE 0.0026350920652019223 Test RE 0.02453612394917901\n",
      "56 Train Loss 0.003541865 Test MSE 0.0022935898142826855 Test RE 0.022891061697527\n",
      "57 Train Loss 0.0032601391 Test MSE 0.0017577533369000163 Test RE 0.02003950666505114\n",
      "58 Train Loss 0.002867639 Test MSE 0.0015393276907873738 Test RE 0.018753122961559506\n",
      "59 Train Loss 0.0026324263 Test MSE 0.0014257594585343322 Test RE 0.018048087630398217\n",
      "60 Train Loss 0.0024045592 Test MSE 0.0011924092542613862 Test RE 0.016505197644707467\n",
      "61 Train Loss 0.0022576961 Test MSE 0.0012535775998602494 Test RE 0.016923246169775804\n",
      "62 Train Loss 0.0020564992 Test MSE 0.001176559460337792 Test RE 0.016395135125301184\n",
      "63 Train Loss 0.0018916797 Test MSE 0.0011715965694549762 Test RE 0.01636052010777327\n",
      "64 Train Loss 0.0017898398 Test MSE 0.0010766800649353342 Test RE 0.015683803638768867\n",
      "65 Train Loss 0.0016588507 Test MSE 0.0009433264726518684 Test RE 0.014680439966889676\n",
      "66 Train Loss 0.0015715885 Test MSE 0.0008220769474587806 Test RE 0.013704534713177135\n",
      "67 Train Loss 0.0014508992 Test MSE 0.0007815913689324862 Test RE 0.013362814439881968\n",
      "68 Train Loss 0.0013631679 Test MSE 0.0007278603957659248 Test RE 0.012895319441574562\n",
      "69 Train Loss 0.0012821108 Test MSE 0.0006607037571136529 Test RE 0.012286026522023161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Train Loss 0.0012330469 Test MSE 0.0006773059360783852 Test RE 0.012439430592054792\n",
      "71 Train Loss 0.00116956 Test MSE 0.0006266992502879872 Test RE 0.011965687262751401\n",
      "72 Train Loss 0.0011119207 Test MSE 0.0005367927414121952 Test RE 0.011074174882748838\n",
      "73 Train Loss 0.0010434155 Test MSE 0.000496692542760263 Test RE 0.010652508271562193\n",
      "74 Train Loss 0.00097604154 Test MSE 0.0004365759072922628 Test RE 0.009987066527816682\n",
      "75 Train Loss 0.00092273875 Test MSE 0.0004762670689483839 Test RE 0.010431177537416188\n",
      "76 Train Loss 0.00086573395 Test MSE 0.0004809729999236546 Test RE 0.010482585393528577\n",
      "77 Train Loss 0.00082599756 Test MSE 0.00046570989625584485 Test RE 0.010314918327851343\n",
      "78 Train Loss 0.00078953465 Test MSE 0.00045381209148719 Test RE 0.010182304768785328\n",
      "79 Train Loss 0.0007612161 Test MSE 0.0004680919057439715 Test RE 0.01034126401612666\n",
      "80 Train Loss 0.0007264745 Test MSE 0.00042644335754346904 Test RE 0.009870490555720214\n",
      "81 Train Loss 0.00069754967 Test MSE 0.0003718976472631669 Test RE 0.009217640704961763\n",
      "82 Train Loss 0.0006779216 Test MSE 0.0003730076158029205 Test RE 0.009231385976735262\n",
      "83 Train Loss 0.0006255695 Test MSE 0.0003529585005871833 Test RE 0.008979866561111282\n",
      "84 Train Loss 0.0005943706 Test MSE 0.00032510720835609983 Test RE 0.008618295079958491\n",
      "85 Train Loss 0.0005757774 Test MSE 0.0003450178997930778 Test RE 0.008878280743010537\n",
      "86 Train Loss 0.0005612796 Test MSE 0.0003399437899667594 Test RE 0.00881275336905799\n",
      "87 Train Loss 0.0005386928 Test MSE 0.00033479338011307356 Test RE 0.008745738573326901\n",
      "88 Train Loss 0.00052445673 Test MSE 0.00034739935246284924 Test RE 0.008908868787912444\n",
      "89 Train Loss 0.0005058144 Test MSE 0.00036658647814472674 Test RE 0.009151584226256112\n",
      "90 Train Loss 0.00048538746 Test MSE 0.00035940463931736236 Test RE 0.009061495929464604\n",
      "91 Train Loss 0.0004624559 Test MSE 0.00035078353749682045 Test RE 0.00895215642078799\n",
      "92 Train Loss 0.00044740873 Test MSE 0.0003329948416635179 Test RE 0.008722215513913025\n",
      "93 Train Loss 0.00042915874 Test MSE 0.00030612403375157213 Test RE 0.008362897501256022\n",
      "94 Train Loss 0.0004149821 Test MSE 0.00030141177977154206 Test RE 0.008298281649084919\n",
      "95 Train Loss 0.00040070052 Test MSE 0.000295110174725269 Test RE 0.008211077512779498\n",
      "96 Train Loss 0.0003919735 Test MSE 0.0002765415656785159 Test RE 0.007948556560575021\n",
      "97 Train Loss 0.00037787942 Test MSE 0.0002537425171798092 Test RE 0.0076138564103980936\n",
      "98 Train Loss 0.0003650715 Test MSE 0.00024085524222699207 Test RE 0.007417987751271075\n",
      "99 Train Loss 0.0003572207 Test MSE 0.00023770481516401627 Test RE 0.00736931379800573\n",
      "Training time: 73.93\n",
      "KG_stan_tune15\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 54.43496 Test MSE 7.738969389230106 Test RE 1.3296876181975712\n",
      "1 Train Loss 46.99151 Test MSE 7.920155147919481 Test RE 1.3451629742713076\n",
      "2 Train Loss 43.41517 Test MSE 8.766303709708405 Test RE 1.4151951015267583\n",
      "3 Train Loss 41.962227 Test MSE 8.51601243110354 Test RE 1.394845814673066\n",
      "4 Train Loss 40.511787 Test MSE 8.974381023259209 Test RE 1.4318921640666455\n",
      "5 Train Loss 39.13751 Test MSE 9.3219538053254 Test RE 1.4593569593713334\n",
      "6 Train Loss 37.69592 Test MSE 9.865941979361581 Test RE 1.5013340651737426\n",
      "7 Train Loss 35.484615 Test MSE 9.82790121781169 Test RE 1.4984368734909876\n",
      "8 Train Loss 31.19763 Test MSE 9.828919167568918 Test RE 1.4985144736785696\n",
      "9 Train Loss 23.034252 Test MSE 8.653434916603336 Test RE 1.4060550550191104\n",
      "10 Train Loss 18.015162 Test MSE 8.714077494991397 Test RE 1.4109732141166451\n",
      "11 Train Loss 13.704849 Test MSE 8.252833275819796 Test RE 1.3731234880389434\n",
      "12 Train Loss 9.568631 Test MSE 7.574653600548769 Test RE 1.315495747906391\n",
      "13 Train Loss 7.348348 Test MSE 6.888875457763258 Test RE 1.2545333963076883\n",
      "14 Train Loss 6.1901054 Test MSE 6.586092789246869 Test RE 1.226653727256225\n",
      "15 Train Loss 5.2399664 Test MSE 6.654364971461124 Test RE 1.2329951512332495\n",
      "16 Train Loss 4.3483005 Test MSE 6.68011206055643 Test RE 1.235378202617464\n",
      "17 Train Loss 3.817158 Test MSE 6.757982266176797 Test RE 1.242557754929386\n",
      "18 Train Loss 3.2889717 Test MSE 6.857211005146355 Test RE 1.251646868141334\n",
      "19 Train Loss 2.9228365 Test MSE 6.801381499826703 Test RE 1.2465411742303243\n",
      "20 Train Loss 2.6508985 Test MSE 6.880534923124859 Test RE 1.2537737187428142\n",
      "21 Train Loss 2.4482489 Test MSE 6.850840820708939 Test RE 1.251065358108463\n",
      "22 Train Loss 2.2725816 Test MSE 6.823501956069544 Test RE 1.2485666212501108\n",
      "23 Train Loss 2.159834 Test MSE 6.730892330289588 Test RE 1.24006480589429\n",
      "24 Train Loss 2.0304253 Test MSE 6.835079621539429 Test RE 1.2496254148263055\n",
      "25 Train Loss 1.9197302 Test MSE 6.808235171109689 Test RE 1.2471690784484848\n",
      "26 Train Loss 1.8544203 Test MSE 6.8638642343189185 Test RE 1.2522539279566278\n",
      "27 Train Loss 1.800145 Test MSE 6.917194358250333 Test RE 1.2571093297986244\n",
      "28 Train Loss 1.7357612 Test MSE 6.941072086572774 Test RE 1.2592771925167943\n",
      "29 Train Loss 1.6746666 Test MSE 6.983163706210393 Test RE 1.2630896368510638\n",
      "30 Train Loss 1.6245549 Test MSE 7.045133509606551 Test RE 1.2686816960564484\n",
      "31 Train Loss 1.575399 Test MSE 7.054283528578497 Test RE 1.2695052925740455\n",
      "32 Train Loss 1.5200348 Test MSE 7.054406585272201 Test RE 1.2695163653103505\n",
      "33 Train Loss 1.4790514 Test MSE 7.103075919373375 Test RE 1.2738881230887051\n",
      "34 Train Loss 1.4440242 Test MSE 7.111744546090059 Test RE 1.2746652155489264\n",
      "35 Train Loss 1.4116637 Test MSE 7.119606981396786 Test RE 1.2753696281087366\n",
      "36 Train Loss 1.3822238 Test MSE 7.15246730644671 Test RE 1.2783094543120057\n",
      "37 Train Loss 1.3604378 Test MSE 7.131219572842483 Test RE 1.2764093141621273\n",
      "38 Train Loss 1.3417698 Test MSE 7.147161538429073 Test RE 1.277835235318051\n",
      "39 Train Loss 1.3241416 Test MSE 7.137553236652628 Test RE 1.2769760161929453\n",
      "40 Train Loss 1.3076289 Test MSE 7.172421087003831 Test RE 1.2800913108544822\n",
      "41 Train Loss 1.2930942 Test MSE 7.161955381788475 Test RE 1.2791570413222664\n",
      "42 Train Loss 1.2811129 Test MSE 7.183771541747808 Test RE 1.2811037914750154\n",
      "43 Train Loss 1.2692114 Test MSE 7.188944830603647 Test RE 1.2815649926129165\n",
      "44 Train Loss 1.2590256 Test MSE 7.226424078187229 Test RE 1.2849013411413686\n",
      "45 Train Loss 1.2491529 Test MSE 7.246914875501699 Test RE 1.2867217446430652\n",
      "46 Train Loss 1.2399474 Test MSE 7.230065550257902 Test RE 1.285225038104364\n",
      "47 Train Loss 1.2306252 Test MSE 7.223780019428309 Test RE 1.2846662549197496\n",
      "48 Train Loss 1.2226038 Test MSE 7.2380745611300945 Test RE 1.285936686720816\n",
      "49 Train Loss 1.2148901 Test MSE 7.239220541982388 Test RE 1.2860384817826458\n",
      "50 Train Loss 1.206172 Test MSE 7.250817310028567 Test RE 1.2870681452588528\n",
      "51 Train Loss 1.1968627 Test MSE 7.2400604369402055 Test RE 1.286113082763688\n",
      "52 Train Loss 1.1873655 Test MSE 7.258366277637606 Test RE 1.287737966863147\n",
      "53 Train Loss 1.17707 Test MSE 7.266124979133452 Test RE 1.2884260353321177\n",
      "54 Train Loss 1.1676514 Test MSE 7.254364076859332 Test RE 1.2873828940871068\n",
      "55 Train Loss 1.1574565 Test MSE 7.25226610769283 Test RE 1.2871967244317186\n",
      "56 Train Loss 1.1450101 Test MSE 7.2443583602609865 Test RE 1.2864947643368134\n",
      "57 Train Loss 1.1316764 Test MSE 7.19369883869883 Test RE 1.281988668380386\n",
      "58 Train Loss 1.1111931 Test MSE 7.146088681477343 Test RE 1.2777393241049466\n",
      "59 Train Loss 1.0838001 Test MSE 7.044697688441246 Test RE 1.2686424542957537\n",
      "60 Train Loss 1.0440115 Test MSE 6.911748310878398 Test RE 1.2566143585219016\n",
      "61 Train Loss 1.0037829 Test MSE 6.786482117800904 Test RE 1.2451750638418533\n",
      "62 Train Loss 0.97349906 Test MSE 6.741270573954328 Test RE 1.241020454641636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 Train Loss 0.94873834 Test MSE 6.618336859625688 Test RE 1.2296527752997604\n",
      "64 Train Loss 0.91441 Test MSE 6.563079621266128 Test RE 1.2245087611880292\n",
      "65 Train Loss 0.8891958 Test MSE 6.517820813862958 Test RE 1.2202793686167044\n",
      "66 Train Loss 0.8612207 Test MSE 6.547203278562015 Test RE 1.2230267974557225\n",
      "67 Train Loss 0.8404155 Test MSE 6.511851224915316 Test RE 1.2197204214498059\n",
      "68 Train Loss 0.8236215 Test MSE 6.527049956721888 Test RE 1.2211430122337141\n",
      "69 Train Loss 0.8048458 Test MSE 6.546295467575734 Test RE 1.222942004330673\n",
      "70 Train Loss 0.7937174 Test MSE 6.536980844242659 Test RE 1.222071641911425\n",
      "71 Train Loss 0.7842182 Test MSE 6.540688441299833 Test RE 1.2224181556197875\n",
      "72 Train Loss 0.7729696 Test MSE 6.556580702175196 Test RE 1.223902342033683\n",
      "73 Train Loss 0.7638818 Test MSE 6.607622046044309 Test RE 1.2286569936173504\n",
      "74 Train Loss 0.75351214 Test MSE 6.600986584280938 Test RE 1.2280399218298768\n",
      "75 Train Loss 0.7459973 Test MSE 6.613263125723939 Test RE 1.229181348166102\n",
      "76 Train Loss 0.73714393 Test MSE 6.627860529337779 Test RE 1.2305371815530397\n",
      "77 Train Loss 0.7308669 Test MSE 6.641492262599834 Test RE 1.2318019741904127\n",
      "78 Train Loss 0.7222563 Test MSE 6.639218269053772 Test RE 1.2315910765909734\n",
      "79 Train Loss 0.7159409 Test MSE 6.652307352933249 Test RE 1.2328045072100897\n",
      "80 Train Loss 0.71111506 Test MSE 6.665299157024335 Test RE 1.2340077395266482\n",
      "81 Train Loss 0.7053571 Test MSE 6.677511517694128 Test RE 1.2351377151325695\n",
      "82 Train Loss 0.70061684 Test MSE 6.681924106815593 Test RE 1.2355457455151704\n",
      "83 Train Loss 0.6954325 Test MSE 6.690987042814248 Test RE 1.2363833693385404\n",
      "84 Train Loss 0.6907565 Test MSE 6.712268550648465 Test RE 1.2383480430988738\n",
      "85 Train Loss 0.6859956 Test MSE 6.720104257848199 Test RE 1.239070638031456\n",
      "86 Train Loss 0.6814319 Test MSE 6.737583675820331 Test RE 1.2406810422324075\n",
      "87 Train Loss 0.67767596 Test MSE 6.748838722328051 Test RE 1.2417168806524361\n",
      "88 Train Loss 0.6743283 Test MSE 6.774041628157037 Test RE 1.244033257764072\n",
      "89 Train Loss 0.6699603 Test MSE 6.810672756123761 Test RE 1.2473923234241862\n",
      "90 Train Loss 0.6659612 Test MSE 6.840581167221833 Test RE 1.250128224511717\n",
      "91 Train Loss 0.66131574 Test MSE 6.8626069226313176 Test RE 1.2521392297666067\n",
      "92 Train Loss 0.65736663 Test MSE 6.856373668864541 Test RE 1.2515704463037751\n",
      "93 Train Loss 0.6528572 Test MSE 6.889126945243532 Test RE 1.2545562952964502\n",
      "94 Train Loss 0.6492274 Test MSE 6.903821548713945 Test RE 1.2558935755693585\n",
      "95 Train Loss 0.6451729 Test MSE 6.914190681335905 Test RE 1.25683636072495\n",
      "96 Train Loss 0.64183176 Test MSE 6.934820832834552 Test RE 1.2587100009945495\n",
      "97 Train Loss 0.63744557 Test MSE 6.962305790002121 Test RE 1.2612018735789088\n",
      "98 Train Loss 0.63460535 Test MSE 6.9829851610977 Test RE 1.2630734894476396\n",
      "99 Train Loss 0.63076997 Test MSE 7.005236579038041 Test RE 1.2650842929674802\n",
      "Training time: 74.97\n",
      "KG_stan_tune15\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 52.90426 Test MSE 9.042952119570053 Test RE 1.4373521269119778\n",
      "1 Train Loss 44.40361 Test MSE 8.457976181666107 Test RE 1.3900847828705984\n",
      "2 Train Loss 42.77291 Test MSE 8.712801565280229 Test RE 1.4108699118134334\n",
      "3 Train Loss 41.87474 Test MSE 8.386267934663042 Test RE 1.3841795451032164\n",
      "4 Train Loss 40.598385 Test MSE 8.937840815094688 Test RE 1.428974135253491\n",
      "5 Train Loss 39.462975 Test MSE 8.823697963602084 Test RE 1.4198202865916392\n",
      "6 Train Loss 38.013332 Test MSE 8.62634076884393 Test RE 1.4038521303790437\n",
      "7 Train Loss 33.305332 Test MSE 8.999766567840688 Test RE 1.4339159077373425\n",
      "8 Train Loss 29.858011 Test MSE 8.218744094157863 Test RE 1.3702846391521386\n",
      "9 Train Loss 24.692806 Test MSE 7.057663452335281 Test RE 1.2698093856287285\n",
      "10 Train Loss 21.578417 Test MSE 6.5613388633806755 Test RE 1.2243463591781858\n",
      "11 Train Loss 19.428465 Test MSE 6.3605782239751445 Test RE 1.2054698682969796\n",
      "12 Train Loss 16.70084 Test MSE 5.821397803745512 Test RE 1.1532453153880684\n",
      "13 Train Loss 14.101196 Test MSE 5.9661420574889235 Test RE 1.1674945321418786\n",
      "14 Train Loss 11.783589 Test MSE 5.858340918636203 Test RE 1.156898827507352\n",
      "15 Train Loss 10.418142 Test MSE 5.866738312308535 Test RE 1.1577276847004254\n",
      "16 Train Loss 9.451651 Test MSE 6.041350902385765 Test RE 1.174830170967557\n",
      "17 Train Loss 8.425161 Test MSE 5.937581327356302 Test RE 1.1646967024973633\n",
      "18 Train Loss 7.0883393 Test MSE 5.785273837177774 Test RE 1.1496615863070982\n",
      "19 Train Loss 5.9566846 Test MSE 5.582328694668607 Test RE 1.129316731813896\n",
      "20 Train Loss 4.6721663 Test MSE 5.338836261033076 Test RE 1.1044126210234169\n",
      "21 Train Loss 3.6751876 Test MSE 5.110028378212898 Test RE 1.0804874236307487\n",
      "22 Train Loss 2.917377 Test MSE 5.140713806123746 Test RE 1.0837267005568252\n",
      "23 Train Loss 2.5279527 Test MSE 4.919389733936619 Test RE 1.060141109212514\n",
      "24 Train Loss 2.3093793 Test MSE 4.937792987728966 Test RE 1.0621222323196762\n",
      "25 Train Loss 2.1333578 Test MSE 4.987298743088421 Test RE 1.0674333122782105\n",
      "26 Train Loss 2.0094025 Test MSE 4.995618608067997 Test RE 1.0683232930847384\n",
      "27 Train Loss 1.8944523 Test MSE 5.083459313350302 Test RE 1.0776748215165808\n",
      "28 Train Loss 1.8048131 Test MSE 5.1145088397878595 Test RE 1.0809610043359774\n",
      "29 Train Loss 1.7137605 Test MSE 5.111293071980161 Test RE 1.080621121633074\n",
      "30 Train Loss 1.6411598 Test MSE 5.215075512531035 Test RE 1.0915367468043526\n",
      "31 Train Loss 1.5664697 Test MSE 5.115460275820107 Test RE 1.0810615435524595\n",
      "32 Train Loss 1.4941136 Test MSE 5.214393819461606 Test RE 1.0914654038917413\n",
      "33 Train Loss 1.416691 Test MSE 5.257904733487086 Test RE 1.0960097478841027\n",
      "34 Train Loss 1.3577374 Test MSE 5.321889922938232 Test RE 1.1026584348969442\n",
      "35 Train Loss 1.2995548 Test MSE 5.410178319827642 Test RE 1.1117671822185364\n",
      "36 Train Loss 1.2243507 Test MSE 5.492477154630806 Test RE 1.120191285795099\n",
      "37 Train Loss 1.1740752 Test MSE 5.601064338860039 Test RE 1.1312102742862795\n",
      "38 Train Loss 1.1292256 Test MSE 5.650693116775636 Test RE 1.1362108213454294\n",
      "39 Train Loss 1.0782224 Test MSE 5.703727897346285 Test RE 1.1415303423291323\n",
      "40 Train Loss 1.0446862 Test MSE 5.7562834073626945 Test RE 1.146777449518088\n",
      "41 Train Loss 1.0203485 Test MSE 5.813019292260753 Test RE 1.152415105990137\n",
      "42 Train Loss 0.9918793 Test MSE 5.834860275607072 Test RE 1.1545780337033298\n",
      "43 Train Loss 0.97063327 Test MSE 5.833857287865416 Test RE 1.1544787959042078\n",
      "44 Train Loss 0.94968694 Test MSE 5.857054199259292 Test RE 1.1567717705549685\n",
      "45 Train Loss 0.933178 Test MSE 5.888133014594015 Test RE 1.1598367525433126\n",
      "46 Train Loss 0.9148563 Test MSE 5.909856595565254 Test RE 1.1619743240847635\n",
      "47 Train Loss 0.8995534 Test MSE 5.965183378697776 Test RE 1.1674007280385092\n",
      "48 Train Loss 0.88622445 Test MSE 5.988902269058437 Test RE 1.1697193474219871\n",
      "49 Train Loss 0.8752626 Test MSE 6.018977324816 Test RE 1.1726527163132696\n",
      "50 Train Loss 0.86187583 Test MSE 6.044199322677861 Test RE 1.1751070970887425\n",
      "51 Train Loss 0.8496599 Test MSE 6.044105380387164 Test RE 1.1750979649708584\n",
      "52 Train Loss 0.8367485 Test MSE 6.082479557600126 Test RE 1.178822425931051\n",
      "53 Train Loss 0.8278904 Test MSE 6.0476237521017895 Test RE 1.1754399369978887\n",
      "54 Train Loss 0.81807005 Test MSE 6.064706496031294 Test RE 1.1770989009509094\n",
      "55 Train Loss 0.809384 Test MSE 6.088203994973404 Test RE 1.1793770112869328\n",
      "56 Train Loss 0.79880786 Test MSE 6.089949994541654 Test RE 1.1795461123994737\n",
      "57 Train Loss 0.7884622 Test MSE 6.099032503111781 Test RE 1.180425368078778\n",
      "58 Train Loss 0.78251815 Test MSE 6.1083262239730765 Test RE 1.181324393277329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 Train Loss 0.7758379 Test MSE 6.124977942326201 Test RE 1.1829334832654042\n",
      "60 Train Loss 0.7683622 Test MSE 6.138029795760846 Test RE 1.1841931823420966\n",
      "61 Train Loss 0.76233214 Test MSE 6.1403642027647685 Test RE 1.1844183462923916\n",
      "62 Train Loss 0.75645 Test MSE 6.146894283943197 Test RE 1.1850479744772897\n",
      "63 Train Loss 0.74890864 Test MSE 6.1577522954813375 Test RE 1.1860941603024502\n",
      "64 Train Loss 0.7426872 Test MSE 6.165885010537367 Test RE 1.1868771556621323\n",
      "65 Train Loss 0.73600316 Test MSE 6.164092248440711 Test RE 1.1867045978652224\n",
      "66 Train Loss 0.7295078 Test MSE 6.199446194236217 Test RE 1.190102884491002\n",
      "67 Train Loss 0.7236073 Test MSE 6.185058981432041 Test RE 1.188721131308267\n",
      "68 Train Loss 0.71846557 Test MSE 6.2097392749783324 Test RE 1.191090452109879\n",
      "69 Train Loss 0.7133561 Test MSE 6.227140911679388 Test RE 1.1927581890215468\n",
      "70 Train Loss 0.7072849 Test MSE 6.216930266135749 Test RE 1.1917799047843662\n",
      "71 Train Loss 0.70250565 Test MSE 6.2188791122408364 Test RE 1.1919666861649127\n",
      "72 Train Loss 0.6972267 Test MSE 6.262638848656405 Test RE 1.1961530283509647\n",
      "73 Train Loss 0.69301313 Test MSE 6.278882904042417 Test RE 1.197703316750233\n",
      "74 Train Loss 0.68834203 Test MSE 6.302763860556177 Test RE 1.1999788135644023\n",
      "75 Train Loss 0.68485326 Test MSE 6.329426309158219 Test RE 1.2025142574781231\n",
      "76 Train Loss 0.68145484 Test MSE 6.33505996726693 Test RE 1.2030493018149584\n",
      "77 Train Loss 0.67760473 Test MSE 6.3297341078936 Test RE 1.2025434961365649\n",
      "78 Train Loss 0.6731354 Test MSE 6.356268071388744 Test RE 1.205061364589178\n",
      "79 Train Loss 0.66964495 Test MSE 6.3446484560999625 Test RE 1.2039594007933767\n",
      "80 Train Loss 0.66612965 Test MSE 6.368922673834168 Test RE 1.206260337778131\n",
      "81 Train Loss 0.6625009 Test MSE 6.371154702695243 Test RE 1.2064716900094485\n",
      "82 Train Loss 0.6593475 Test MSE 6.395974365666 Test RE 1.2088193895936503\n",
      "83 Train Loss 0.65715694 Test MSE 6.3968217869882125 Test RE 1.208899466946871\n",
      "84 Train Loss 0.6551878 Test MSE 6.3972378640555165 Test RE 1.2089387823430662\n",
      "85 Train Loss 0.6518811 Test MSE 6.426220631512698 Test RE 1.2116742438435406\n",
      "86 Train Loss 0.6495 Test MSE 6.4139101807541214 Test RE 1.2105131098397781\n",
      "87 Train Loss 0.6468559 Test MSE 6.422952317280878 Test RE 1.2113660817019032\n",
      "88 Train Loss 0.64471084 Test MSE 6.427707377036097 Test RE 1.211814399868287\n",
      "89 Train Loss 0.64201266 Test MSE 6.44132100832521 Test RE 1.2130970087052628\n",
      "90 Train Loss 0.6392503 Test MSE 6.443276366107941 Test RE 1.2132811214582697\n",
      "91 Train Loss 0.6355353 Test MSE 6.448243416706675 Test RE 1.2137486838752005\n",
      "92 Train Loss 0.63265014 Test MSE 6.465785141207867 Test RE 1.21539849632809\n",
      "93 Train Loss 0.63018477 Test MSE 6.4735425048125075 Test RE 1.2161273685098029\n",
      "94 Train Loss 0.6276227 Test MSE 6.48246050191548 Test RE 1.2169647529658527\n",
      "95 Train Loss 0.6251227 Test MSE 6.496424904275919 Test RE 1.218274829839015\n",
      "96 Train Loss 0.622543 Test MSE 6.4995466629464715 Test RE 1.2185675064489345\n",
      "97 Train Loss 0.62025726 Test MSE 6.503638842270928 Test RE 1.218951057207022\n",
      "98 Train Loss 0.6180297 Test MSE 6.511391311343242 Test RE 1.2196773479932888\n",
      "99 Train Loss 0.61455613 Test MSE 6.5347818304459295 Test RE 1.2218660746543972\n",
      "Training time: 75.38\n",
      "KG_stan_tune16\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 58.46186 Test MSE 8.738097925839115 Test RE 1.412916555832768\n",
      "1 Train Loss 53.89193 Test MSE 7.571588218989185 Test RE 1.3152295374181182\n",
      "2 Train Loss 47.34904 Test MSE 7.4325760392049265 Test RE 1.3030999879260428\n",
      "3 Train Loss 40.28306 Test MSE 7.17365943723798 Test RE 1.280201812799237\n",
      "4 Train Loss 37.856388 Test MSE 7.588647510350908 Test RE 1.3167103535631122\n",
      "5 Train Loss 35.009796 Test MSE 7.3235977104980865 Test RE 1.2935115185270067\n",
      "6 Train Loss 31.138624 Test MSE 6.419556893270917 Test RE 1.2110458516109892\n",
      "7 Train Loss 29.222588 Test MSE 6.252430624364722 Test RE 1.1951777542984368\n",
      "8 Train Loss 26.81792 Test MSE 6.403712377958788 Test RE 1.209550398767371\n",
      "9 Train Loss 26.04634 Test MSE 6.077761288455013 Test RE 1.1783651222543707\n",
      "10 Train Loss 25.167255 Test MSE 6.426777436921266 Test RE 1.211726735984524\n",
      "11 Train Loss 24.151697 Test MSE 5.817895667286773 Test RE 1.1528983686392036\n",
      "12 Train Loss 23.529112 Test MSE 5.68104552136461 Test RE 1.139258283212317\n",
      "13 Train Loss 22.856565 Test MSE 5.7731303251677675 Test RE 1.148454360555594\n",
      "14 Train Loss 20.671768 Test MSE 5.80914125167512 Test RE 1.1520306364101744\n",
      "15 Train Loss 18.707256 Test MSE 5.78928115199204 Test RE 1.1500596883255905\n",
      "16 Train Loss 16.294065 Test MSE 6.066652421273587 Test RE 1.1772877281232126\n",
      "17 Train Loss 15.224238 Test MSE 5.741777941460159 Test RE 1.1453316352023757\n",
      "18 Train Loss 14.672668 Test MSE 5.82721683409749 Test RE 1.153821559577802\n",
      "19 Train Loss 14.027093 Test MSE 5.871086340465195 Test RE 1.1581566198228581\n",
      "20 Train Loss 13.342474 Test MSE 5.857299422180564 Test RE 1.1567959861396373\n",
      "21 Train Loss 13.082254 Test MSE 5.977773937637978 Test RE 1.168632079962006\n",
      "22 Train Loss 12.815231 Test MSE 5.930981470656869 Test RE 1.164049219275393\n",
      "23 Train Loss 12.510963 Test MSE 5.919638057537077 Test RE 1.162935524111562\n",
      "24 Train Loss 12.339473 Test MSE 5.937090477613054 Test RE 1.1646485597552658\n",
      "25 Train Loss 12.232062 Test MSE 5.877232619483905 Test RE 1.1587626824228945\n",
      "26 Train Loss 12.15641 Test MSE 5.896878283572364 Test RE 1.1606977487981358\n",
      "27 Train Loss 12.083381 Test MSE 5.881273566032074 Test RE 1.1591609730613193\n",
      "28 Train Loss 12.0068245 Test MSE 5.877941372438793 Test RE 1.15883254963505\n",
      "29 Train Loss 11.973703 Test MSE 5.8973813278800575 Test RE 1.1607472554960563\n",
      "30 Train Loss 11.920364 Test MSE 5.900316560863834 Test RE 1.16103608197742\n",
      "31 Train Loss 11.877888 Test MSE 5.903905255628535 Test RE 1.1613891114043082\n",
      "32 Train Loss 11.830008 Test MSE 5.89763431077713 Test RE 1.1607721518049434\n",
      "33 Train Loss 11.773499 Test MSE 5.86228671482148 Test RE 1.1572883677073815\n",
      "34 Train Loss 11.728765 Test MSE 5.908546382730911 Test RE 1.1618455123244391\n",
      "35 Train Loss 11.686421 Test MSE 5.905009035802274 Test RE 1.161497671612269\n",
      "36 Train Loss 11.585001 Test MSE 5.804142370780762 Test RE 1.151534857161063\n",
      "37 Train Loss 11.544682 Test MSE 5.811615659607829 Test RE 1.1522759644314329\n",
      "38 Train Loss 11.374178 Test MSE 5.765641129834722 Test RE 1.1477092024025908\n",
      "39 Train Loss 11.071049 Test MSE 5.5426868450532325 Test RE 1.1252997732834953\n",
      "40 Train Loss 10.395383 Test MSE 4.907054170652101 Test RE 1.0588111021595108\n",
      "41 Train Loss 8.073226 Test MSE 3.7369272694305518 Test RE 0.9239859830444411\n",
      "42 Train Loss 6.7975225 Test MSE 3.000563649975936 Test RE 0.827960240755405\n",
      "43 Train Loss 6.296482 Test MSE 2.6640041790022875 Test RE 0.7801453264838836\n",
      "44 Train Loss 5.882495 Test MSE 2.3729299201861807 Test RE 0.7362927369537241\n",
      "45 Train Loss 5.4273376 Test MSE 2.2714730141091133 Test RE 0.7203803386188509\n",
      "46 Train Loss 5.1943736 Test MSE 2.3051678210122546 Test RE 0.725703695240104\n",
      "47 Train Loss 5.051993 Test MSE 2.230766942562675 Test RE 0.7138963480739654\n",
      "48 Train Loss 4.8868876 Test MSE 2.210214073941256 Test RE 0.7106000444117156\n",
      "49 Train Loss 4.7903776 Test MSE 2.222730942340277 Test RE 0.7126093361988726\n",
      "50 Train Loss 4.7194653 Test MSE 2.1937912617373945 Test RE 0.7079550946597312\n",
      "51 Train Loss 4.6822543 Test MSE 2.1782493578677253 Test RE 0.7054428850486824\n",
      "52 Train Loss 4.6354566 Test MSE 2.1824344195008067 Test RE 0.7061202421270817\n",
      "53 Train Loss 4.6050797 Test MSE 2.175229757453699 Test RE 0.7049537550129477\n",
      "54 Train Loss 4.568096 Test MSE 2.182067726250512 Test RE 0.7060609183733783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 Train Loss 4.5458164 Test MSE 2.1712212897899623 Test RE 0.7043039185194531\n",
      "56 Train Loss 4.531172 Test MSE 2.169456018592064 Test RE 0.7040175496821304\n",
      "57 Train Loss 4.516406 Test MSE 2.172168035394054 Test RE 0.7044574551418594\n",
      "58 Train Loss 4.4976897 Test MSE 2.1614267075045417 Test RE 0.7027135324764767\n",
      "59 Train Loss 4.4840927 Test MSE 2.1604596056657823 Test RE 0.7025563049417555\n",
      "60 Train Loss 4.474361 Test MSE 2.1560247670630566 Test RE 0.7018348555818331\n",
      "61 Train Loss 4.457976 Test MSE 2.1600335939085586 Test RE 0.7024870344955572\n",
      "62 Train Loss 4.448816 Test MSE 2.1437058946779572 Test RE 0.6998269474509959\n",
      "63 Train Loss 4.429816 Test MSE 2.1418778956553037 Test RE 0.6995285026373365\n",
      "64 Train Loss 4.418583 Test MSE 2.1368026738939854 Test RE 0.6986992378398702\n",
      "65 Train Loss 4.3860483 Test MSE 2.1354375497885707 Test RE 0.6984760156464954\n",
      "66 Train Loss 4.373334 Test MSE 2.1381653542148538 Test RE 0.6989219893292554\n",
      "67 Train Loss 4.3470807 Test MSE 2.146979538405729 Test RE 0.7003610949131136\n",
      "68 Train Loss 4.258975 Test MSE 2.1304691734083008 Test RE 0.6976629943027365\n",
      "69 Train Loss 4.125775 Test MSE 2.158057722190414 Test RE 0.7021656640701741\n",
      "70 Train Loss 3.9671226 Test MSE 2.0688477748598446 Test RE 0.6874994080673913\n",
      "71 Train Loss 3.0480971 Test MSE 1.3680198183733108 Test RE 0.5590546379875104\n",
      "72 Train Loss 1.9500148 Test MSE 0.9107549579857164 Test RE 0.4561512111835041\n",
      "73 Train Loss 1.3554925 Test MSE 0.5752116894094659 Test RE 0.36251160313360004\n",
      "74 Train Loss 0.96454227 Test MSE 0.26819451100624664 Test RE 0.24753294158193037\n",
      "75 Train Loss 0.69411033 Test MSE 0.09724134850117151 Test RE 0.14905053756319678\n",
      "76 Train Loss 0.4617608 Test MSE 0.07155019286412719 Test RE 0.1278537482560315\n",
      "77 Train Loss 0.34631923 Test MSE 0.03728499587447757 Test RE 0.09229434881218342\n",
      "78 Train Loss 0.2961101 Test MSE 0.04399379872047227 Test RE 0.10025448076162168\n",
      "79 Train Loss 0.2385621 Test MSE 0.04726734690925327 Test RE 0.10391749600024673\n",
      "80 Train Loss 0.19990408 Test MSE 0.04939007106900474 Test RE 0.10622528031747658\n",
      "81 Train Loss 0.15750189 Test MSE 0.035418190043923346 Test RE 0.08995415788811327\n",
      "82 Train Loss 0.13528942 Test MSE 0.029242829762536407 Test RE 0.08173682394551708\n",
      "83 Train Loss 0.119299576 Test MSE 0.025363719057887868 Test RE 0.07612276019256224\n",
      "84 Train Loss 0.1079965 Test MSE 0.022245364943442047 Test RE 0.07128987081614106\n",
      "85 Train Loss 0.086430416 Test MSE 0.020333697418197634 Test RE 0.06815790589898595\n",
      "86 Train Loss 0.07246411 Test MSE 0.01603657386018409 Test RE 0.060529049577224533\n",
      "87 Train Loss 0.062839516 Test MSE 0.012372789979960047 Test RE 0.053166966374094835\n",
      "88 Train Loss 0.05020177 Test MSE 0.006938421801937588 Test RE 0.03981423809734971\n",
      "89 Train Loss 0.0435924 Test MSE 0.007675572758476896 Test RE 0.04187583276016446\n",
      "90 Train Loss 0.039510153 Test MSE 0.006682250401130702 Test RE 0.03907234105452151\n",
      "91 Train Loss 0.034037624 Test MSE 0.007537560618239694 Test RE 0.04149764672794225\n",
      "92 Train Loss 0.032087263 Test MSE 0.008192280756349377 Test RE 0.043262386611657135\n",
      "93 Train Loss 0.02929091 Test MSE 0.00853308918482758 Test RE 0.04415310017767859\n",
      "94 Train Loss 0.026547227 Test MSE 0.008638993580033796 Test RE 0.0444262479262542\n",
      "95 Train Loss 0.025114384 Test MSE 0.009356425455597905 Test RE 0.04623416740841119\n",
      "96 Train Loss 0.022419121 Test MSE 0.00845975494175384 Test RE 0.04396296264657107\n",
      "97 Train Loss 0.021316089 Test MSE 0.007274321553930831 Test RE 0.040766582682965034\n",
      "98 Train Loss 0.019178621 Test MSE 0.0057211637360153455 Test RE 0.036153491791490064\n",
      "99 Train Loss 0.017190704 Test MSE 0.004578403715140668 Test RE 0.032341868199580445\n",
      "Training time: 75.19\n",
      "KG_stan_tune16\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 57.5009 Test MSE 8.66253373687782 Test RE 1.4067940725973418\n",
      "1 Train Loss 47.849476 Test MSE 8.441258822923926 Test RE 1.3887103382208086\n",
      "2 Train Loss 44.701492 Test MSE 8.34918527661154 Test RE 1.3811158506771388\n",
      "3 Train Loss 44.299633 Test MSE 8.636233362565308 Test RE 1.4046568609042585\n",
      "4 Train Loss 44.139847 Test MSE 8.511311336333097 Test RE 1.3944607631231272\n",
      "5 Train Loss 43.905823 Test MSE 8.439609241907156 Test RE 1.3885746415085876\n",
      "6 Train Loss 43.52821 Test MSE 8.557216716978228 Test RE 1.3982161874297496\n",
      "7 Train Loss 43.20302 Test MSE 8.486018500897693 Test RE 1.3923872807393738\n",
      "8 Train Loss 43.13613 Test MSE 8.497069734459444 Test RE 1.393293629843955\n",
      "9 Train Loss 42.85904 Test MSE 8.356981948789846 Test RE 1.3817605599789604\n",
      "10 Train Loss 42.776466 Test MSE 8.17928548246744 Test RE 1.3669912781005817\n",
      "11 Train Loss 42.57122 Test MSE 8.295389255694136 Test RE 1.3766592119055745\n",
      "12 Train Loss 41.671318 Test MSE 8.193756090639692 Test RE 1.368199968873262\n",
      "13 Train Loss 40.9859 Test MSE 8.152521842333947 Test RE 1.3647529627864616\n",
      "14 Train Loss 39.64812 Test MSE 7.907184010002668 Test RE 1.3440610107413713\n",
      "15 Train Loss 38.22254 Test MSE 7.90223545847312 Test RE 1.3436403681895692\n",
      "16 Train Loss 36.725132 Test MSE 7.955351619220901 Test RE 1.3481485538745792\n",
      "17 Train Loss 34.059635 Test MSE 8.088761758006351 Test RE 1.3594056867112574\n",
      "18 Train Loss 32.73446 Test MSE 8.681326155525683 Test RE 1.4083191887711395\n",
      "19 Train Loss 31.409939 Test MSE 8.829678420685923 Test RE 1.4203013624423015\n",
      "20 Train Loss 30.531837 Test MSE 8.497151649376198 Test RE 1.3933003457625126\n",
      "21 Train Loss 29.97371 Test MSE 8.173549507533794 Test RE 1.3665118717456464\n",
      "22 Train Loss 29.682417 Test MSE 7.79585136008601 Test RE 1.3345653206321573\n",
      "23 Train Loss 29.39308 Test MSE 7.638431794427965 Test RE 1.321022342163879\n",
      "24 Train Loss 28.999454 Test MSE 7.481766740014527 Test RE 1.3074050022690311\n",
      "25 Train Loss 28.559378 Test MSE 7.414048464979725 Test RE 1.3014748214822949\n",
      "26 Train Loss 28.154156 Test MSE 7.314246635769937 Test RE 1.2926854500496352\n",
      "27 Train Loss 27.52393 Test MSE 6.996073917141435 Test RE 1.2642566740603178\n",
      "28 Train Loss 26.28402 Test MSE 6.421994900463207 Test RE 1.2112757941343864\n",
      "29 Train Loss 24.068014 Test MSE 5.673323585925828 Test RE 1.1384837540937975\n",
      "30 Train Loss 20.741596 Test MSE 5.4707233878219474 Test RE 1.1179707434178854\n",
      "31 Train Loss 19.751753 Test MSE 5.529610339558809 Test RE 1.1239715656501696\n",
      "32 Train Loss 18.590893 Test MSE 5.249256817997046 Test RE 1.0951080483791054\n",
      "33 Train Loss 18.008432 Test MSE 5.272931511049832 Test RE 1.0975747956644775\n",
      "34 Train Loss 17.731583 Test MSE 5.345642463132418 Test RE 1.1051163756383826\n",
      "35 Train Loss 17.151022 Test MSE 4.762033709126333 Test RE 1.0430479958493601\n",
      "36 Train Loss 16.033539 Test MSE 4.30307227380184 Test RE 0.9915106434302715\n",
      "37 Train Loss 14.95936 Test MSE 4.156733228591078 Test RE 0.9745051461485984\n",
      "38 Train Loss 14.363129 Test MSE 4.067422624553469 Test RE 0.9639793046625846\n",
      "39 Train Loss 14.052692 Test MSE 4.024447430821877 Test RE 0.9588732202892952\n",
      "40 Train Loss 13.693832 Test MSE 4.023972117093826 Test RE 0.9588165939982426\n",
      "41 Train Loss 13.451979 Test MSE 4.127921364195718 Test RE 0.971121944545422\n",
      "42 Train Loss 13.208357 Test MSE 4.043570226293427 Test RE 0.9611486390131555\n",
      "43 Train Loss 13.024021 Test MSE 4.095058751182624 Test RE 0.9672486421707789\n",
      "44 Train Loss 12.783626 Test MSE 4.303313651996637 Test RE 0.9915384521304103\n",
      "45 Train Loss 12.628792 Test MSE 4.282896194405596 Test RE 0.9891834338511031\n",
      "46 Train Loss 12.51706 Test MSE 4.35049184840025 Test RE 0.9969588659642179\n",
      "47 Train Loss 12.200383 Test MSE 4.533768965637004 Test RE 1.0177421304558343\n",
      "48 Train Loss 11.693571 Test MSE 4.503512062529746 Test RE 1.0143404050646398\n",
      "49 Train Loss 11.324493 Test MSE 4.655819491244963 Test RE 1.0313501292396663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Train Loss 10.863319 Test MSE 4.538763160379746 Test RE 1.0183025255112552\n",
      "51 Train Loss 10.206739 Test MSE 4.483596692228057 Test RE 1.0120951188164826\n",
      "52 Train Loss 9.04974 Test MSE 4.3141685855632455 Test RE 0.9927882222009936\n",
      "53 Train Loss 8.375549 Test MSE 3.8428053805245357 Test RE 0.9369841735146672\n",
      "54 Train Loss 6.7246203 Test MSE 3.3792127921496258 Test RE 0.8786498324647194\n",
      "55 Train Loss 4.5838566 Test MSE 3.1867951231713865 Test RE 0.853267358662223\n",
      "56 Train Loss 3.6897953 Test MSE 3.124088224117843 Test RE 0.8448307351120842\n",
      "57 Train Loss 3.0269592 Test MSE 3.016405816463312 Test RE 0.8301430667046346\n",
      "58 Train Loss 2.3925862 Test MSE 2.769822876568007 Test RE 0.7954887813089717\n",
      "59 Train Loss 2.0284986 Test MSE 2.5068449367445407 Test RE 0.756783745990464\n",
      "60 Train Loss 1.7581365 Test MSE 2.4855926145051153 Test RE 0.7535690188415252\n",
      "61 Train Loss 1.5604869 Test MSE 2.4124934258472273 Test RE 0.7424054126882387\n",
      "62 Train Loss 1.4070938 Test MSE 2.4386569478155966 Test RE 0.7464202548723133\n",
      "63 Train Loss 1.3251402 Test MSE 2.4682454015010284 Test RE 0.7509347958346555\n",
      "64 Train Loss 1.2841486 Test MSE 2.486281113194905 Test RE 0.7536733793380052\n",
      "65 Train Loss 1.2326826 Test MSE 2.5179213318147338 Test RE 0.7584538127475287\n",
      "66 Train Loss 1.1992743 Test MSE 2.5117821394273934 Test RE 0.757528617920701\n",
      "67 Train Loss 1.1673152 Test MSE 2.5669254144095865 Test RE 0.7657988065511873\n",
      "68 Train Loss 1.1463568 Test MSE 2.563506102975348 Test RE 0.765288589700573\n",
      "69 Train Loss 1.1203257 Test MSE 2.5825274718375764 Test RE 0.7681225859029528\n",
      "70 Train Loss 1.1028436 Test MSE 2.5604344220944566 Test RE 0.7648299547615264\n",
      "71 Train Loss 1.0840372 Test MSE 2.5781099926786655 Test RE 0.7674653580867679\n",
      "72 Train Loss 1.0689411 Test MSE 2.5318369929469253 Test RE 0.760546778019464\n",
      "73 Train Loss 1.0473468 Test MSE 2.5278297214299066 Test RE 0.7599446609893454\n",
      "74 Train Loss 1.0361564 Test MSE 2.5433992454734518 Test RE 0.7622814112559873\n",
      "75 Train Loss 1.0179778 Test MSE 2.5320450772724716 Test RE 0.7605780309421909\n",
      "76 Train Loss 1.0068187 Test MSE 2.5447090671501957 Test RE 0.7624776691189948\n",
      "77 Train Loss 0.9896058 Test MSE 2.5405708936429634 Test RE 0.7618574511267056\n",
      "78 Train Loss 0.97783965 Test MSE 2.544371863973086 Test RE 0.7624271489212464\n",
      "79 Train Loss 0.96510386 Test MSE 2.562697990026561 Test RE 0.7651679564076223\n",
      "80 Train Loss 0.9474344 Test MSE 2.6031118964893047 Test RE 0.7711777285678537\n",
      "81 Train Loss 0.93884546 Test MSE 2.619415370028507 Test RE 0.7735889293530497\n",
      "82 Train Loss 0.9309061 Test MSE 2.6284102300869936 Test RE 0.7749160118952116\n",
      "83 Train Loss 0.9145123 Test MSE 2.62719322065087 Test RE 0.7747365898857279\n",
      "84 Train Loss 0.904436 Test MSE 2.6695603807794313 Test RE 0.7809584609171413\n",
      "85 Train Loss 0.89398164 Test MSE 2.7085916687544884 Test RE 0.7866468889267927\n",
      "86 Train Loss 0.8794025 Test MSE 2.7233409720709605 Test RE 0.7887857756353259\n",
      "87 Train Loss 0.8688069 Test MSE 2.722076372746491 Test RE 0.7886026157235397\n",
      "88 Train Loss 0.84748524 Test MSE 2.7351649631501056 Test RE 0.7904962655471364\n",
      "89 Train Loss 0.8355055 Test MSE 2.7192796809087416 Test RE 0.7881974020243123\n",
      "90 Train Loss 0.8063115 Test MSE 2.7087203748424034 Test RE 0.7866655785362477\n",
      "91 Train Loss 0.7994049 Test MSE 2.7305493877615943 Test RE 0.7898290049425387\n",
      "92 Train Loss 0.7747484 Test MSE 2.790035754150822 Test RE 0.7983860585251538\n",
      "93 Train Loss 0.75845945 Test MSE 2.7983641219557356 Test RE 0.7995767776865454\n",
      "94 Train Loss 0.7476506 Test MSE 2.805936732525383 Test RE 0.8006579080488289\n",
      "95 Train Loss 0.7258594 Test MSE 2.794673746647361 Test RE 0.7990493781522022\n",
      "96 Train Loss 0.7205014 Test MSE 2.7883713302272057 Test RE 0.7981478803766499\n",
      "97 Train Loss 0.7045723 Test MSE 2.80104309794293 Test RE 0.7999594181283075\n",
      "98 Train Loss 0.69832695 Test MSE 2.784807420437128 Test RE 0.7976376476618835\n",
      "99 Train Loss 0.6896628 Test MSE 2.785504139980521 Test RE 0.7977374202671641\n",
      "Training time: 76.82\n",
      "KG_stan_tune16\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 55.961395 Test MSE 8.702914568795954 Test RE 1.4100691805394234\n",
      "1 Train Loss 50.97726 Test MSE 8.25890895481476 Test RE 1.373628837072917\n",
      "2 Train Loss 48.52746 Test MSE 8.516023567358507 Test RE 1.3948467266816897\n",
      "3 Train Loss 44.51867 Test MSE 8.121874148986649 Test RE 1.3621852963218026\n",
      "4 Train Loss 41.71535 Test MSE 7.543342599096276 Test RE 1.312774029829763\n",
      "5 Train Loss 37.529633 Test MSE 7.695957405241205 Test RE 1.325987371561597\n",
      "6 Train Loss 36.546368 Test MSE 7.4864792529292306 Test RE 1.3078166826448128\n",
      "7 Train Loss 34.20842 Test MSE 7.302158945479387 Test RE 1.2916168476849963\n",
      "8 Train Loss 32.32946 Test MSE 6.58300544971439 Test RE 1.2263661864800735\n",
      "9 Train Loss 30.447548 Test MSE 6.221460094725116 Test RE 1.1922140077440992\n",
      "10 Train Loss 29.574917 Test MSE 6.359146732314948 Test RE 1.2053342110419396\n",
      "11 Train Loss 27.755405 Test MSE 6.164923216192285 Test RE 1.1867845836911985\n",
      "12 Train Loss 26.278524 Test MSE 6.375305097536989 Test RE 1.2068645951333703\n",
      "13 Train Loss 25.52248 Test MSE 6.239000296277346 Test RE 1.193893433096674\n",
      "14 Train Loss 24.78543 Test MSE 6.439788809001827 Test RE 1.2129527202154116\n",
      "15 Train Loss 24.402164 Test MSE 6.497866751085777 Test RE 1.2184100171342227\n",
      "16 Train Loss 24.154694 Test MSE 6.441133156311056 Test RE 1.213079319447295\n",
      "17 Train Loss 23.957602 Test MSE 6.39488311357836 Test RE 1.2087162635586084\n",
      "18 Train Loss 23.580894 Test MSE 6.309034539320216 Test RE 1.2005756002413552\n",
      "19 Train Loss 23.304 Test MSE 6.251114468106111 Test RE 1.1950519533446005\n",
      "20 Train Loss 23.064022 Test MSE 6.141441328573066 Test RE 1.1845222254421852\n",
      "21 Train Loss 23.014507 Test MSE 6.083050389358559 Test RE 1.1788777400085384\n",
      "22 Train Loss 22.881956 Test MSE 6.049947558367411 Test RE 1.175665747370511\n",
      "23 Train Loss 22.76878 Test MSE 6.120511638264888 Test RE 1.1825021099471487\n",
      "24 Train Loss 22.711845 Test MSE 6.10709901355221 Test RE 1.1812057186702674\n",
      "25 Train Loss 22.183033 Test MSE 6.276713189907073 Test RE 1.1974963612780156\n",
      "26 Train Loss 21.914839 Test MSE 6.038177614811985 Test RE 1.1745215840533965\n",
      "27 Train Loss 21.616974 Test MSE 6.121833134440266 Test RE 1.1826297616670496\n",
      "28 Train Loss 21.424603 Test MSE 6.075797712427759 Test RE 1.1781747564017482\n",
      "29 Train Loss 21.332699 Test MSE 6.090567538669966 Test RE 1.179605916117993\n",
      "30 Train Loss 20.98248 Test MSE 6.087574757467386 Test RE 1.1793160633106723\n",
      "31 Train Loss 20.45912 Test MSE 6.044629797192191 Test RE 1.175148942552745\n",
      "32 Train Loss 20.042194 Test MSE 5.790878880360334 Test RE 1.1502183743680523\n",
      "33 Train Loss 19.444267 Test MSE 5.538500046612008 Test RE 1.1248746822110733\n",
      "34 Train Loss 18.660988 Test MSE 5.129120025421026 Test RE 1.0825039538419092\n",
      "35 Train Loss 17.702175 Test MSE 4.872785401409695 Test RE 1.055107482585421\n",
      "36 Train Loss 15.941108 Test MSE 3.817842317594988 Test RE 0.9339358660798757\n",
      "37 Train Loss 12.78016 Test MSE 3.3422897393347655 Test RE 0.8738363530498939\n",
      "38 Train Loss 11.295927 Test MSE 3.1287226982280285 Test RE 0.8454571411056628\n",
      "39 Train Loss 10.364445 Test MSE 2.4667696108426966 Test RE 0.7507102662436868\n",
      "40 Train Loss 9.689229 Test MSE 2.6608010974639265 Test RE 0.7796761791948703\n",
      "41 Train Loss 9.090726 Test MSE 2.6270847088827125 Test RE 0.774720590128905\n",
      "42 Train Loss 8.469767 Test MSE 2.3811617339055875 Test RE 0.7375687496163198\n",
      "43 Train Loss 7.921029 Test MSE 2.4140722065770346 Test RE 0.7426482949380203\n",
      "44 Train Loss 7.3662415 Test MSE 2.337613145177541 Test RE 0.7307930032271354\n",
      "45 Train Loss 6.8312554 Test MSE 2.3036316987340166 Test RE 0.725461857014489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 6.4621572 Test MSE 2.311973400050577 Test RE 0.7267741582960775\n",
      "47 Train Loss 6.0936394 Test MSE 2.2288763673458916 Test RE 0.7135937703369377\n",
      "48 Train Loss 5.751052 Test MSE 2.3148242075406507 Test RE 0.7272220992010375\n",
      "49 Train Loss 5.509165 Test MSE 2.2950013856618656 Test RE 0.7241016487027898\n",
      "50 Train Loss 5.3179474 Test MSE 2.2816888543093916 Test RE 0.7219984591993586\n",
      "51 Train Loss 5.216239 Test MSE 2.30126251181185 Test RE 0.725088707763029\n",
      "52 Train Loss 5.018298 Test MSE 2.308391408757819 Test RE 0.7262109364558867\n",
      "53 Train Loss 4.8046145 Test MSE 2.2603264045721034 Test RE 0.7186106337759798\n",
      "54 Train Loss 4.6417384 Test MSE 2.2810237184133175 Test RE 0.7218932165204304\n",
      "55 Train Loss 4.5645647 Test MSE 2.289232449685449 Test RE 0.7231909903268005\n",
      "56 Train Loss 4.3592067 Test MSE 2.1756547644979665 Test RE 0.7050226203080584\n",
      "57 Train Loss 4.18023 Test MSE 2.1577608270635755 Test RE 0.7021173621335988\n",
      "58 Train Loss 4.0241957 Test MSE 2.103521151848365 Test RE 0.6932366293648997\n",
      "59 Train Loss 3.8429554 Test MSE 2.055422500128965 Test RE 0.6852650989362856\n",
      "60 Train Loss 3.7117567 Test MSE 2.0424866239963704 Test RE 0.6831053250285782\n",
      "61 Train Loss 3.273968 Test MSE 1.904998433893315 Test RE 0.6597135006723175\n",
      "62 Train Loss 2.792105 Test MSE 1.6418739343459479 Test RE 0.6124603305383463\n",
      "63 Train Loss 2.3403141 Test MSE 1.3929522863492523 Test RE 0.5641260833387423\n",
      "64 Train Loss 2.1362681 Test MSE 1.0661978745957688 Test RE 0.49354523863126076\n",
      "65 Train Loss 1.7871487 Test MSE 0.699189192528999 Test RE 0.3996735551624819\n",
      "66 Train Loss 1.6515348 Test MSE 0.6640463644599455 Test RE 0.3894998205817911\n",
      "67 Train Loss 1.4844273 Test MSE 0.5609495071104483 Test RE 0.3579892171727053\n",
      "68 Train Loss 1.3283658 Test MSE 0.512818219382239 Test RE 0.34228651012592604\n",
      "69 Train Loss 1.2199712 Test MSE 0.4185694067199152 Test RE 0.30923724932118046\n",
      "70 Train Loss 1.1657448 Test MSE 0.4102798806089519 Test RE 0.3061598035248854\n",
      "71 Train Loss 1.118103 Test MSE 0.4363092558938472 Test RE 0.3157223112454978\n",
      "72 Train Loss 1.0282996 Test MSE 0.3976957063987278 Test RE 0.30142794408996415\n",
      "73 Train Loss 0.96855086 Test MSE 0.3170524405639803 Test RE 0.26913712607514384\n",
      "74 Train Loss 0.92607045 Test MSE 0.27691692832413506 Test RE 0.25152595874221895\n",
      "75 Train Loss 0.8918034 Test MSE 0.2840900540696561 Test RE 0.254762836131582\n",
      "76 Train Loss 0.8718819 Test MSE 0.27076866701318947 Test RE 0.2487180268981589\n",
      "77 Train Loss 0.8348204 Test MSE 0.2341799241670481 Test RE 0.23130386556840274\n",
      "78 Train Loss 0.79073685 Test MSE 0.16749048287256302 Test RE 0.19561543854388683\n",
      "79 Train Loss 0.7629608 Test MSE 0.13263399394185937 Test RE 0.17407463132016968\n",
      "80 Train Loss 0.73159504 Test MSE 0.12058836243219735 Test RE 0.1659819104710986\n",
      "81 Train Loss 0.69777715 Test MSE 0.1002706325806864 Test RE 0.15135436058253723\n",
      "82 Train Loss 0.6662693 Test MSE 0.08925801317896469 Test RE 0.14280113788138496\n",
      "83 Train Loss 0.6459315 Test MSE 0.08000190350150911 Test RE 0.1351942498808028\n",
      "84 Train Loss 0.62282413 Test MSE 0.07973043585326442 Test RE 0.13496468001847586\n",
      "85 Train Loss 0.60581285 Test MSE 0.07434846595133138 Test RE 0.13032990128304434\n",
      "86 Train Loss 0.574019 Test MSE 0.05942737906592877 Test RE 0.11652023416710143\n",
      "87 Train Loss 0.55492574 Test MSE 0.06223624659366333 Test RE 0.11924213867052731\n",
      "88 Train Loss 0.53889495 Test MSE 0.0604320151058699 Test RE 0.11750100962782771\n",
      "89 Train Loss 0.52108836 Test MSE 0.06471935873026018 Test RE 0.12159764472692172\n",
      "90 Train Loss 0.50454193 Test MSE 0.07173778822185642 Test RE 0.128021246539516\n",
      "91 Train Loss 0.4927147 Test MSE 0.061655112642565346 Test RE 0.1186841183725884\n",
      "92 Train Loss 0.47650018 Test MSE 0.05572604440933938 Test RE 0.11283326846809383\n",
      "93 Train Loss 0.45216617 Test MSE 0.05009230270761313 Test RE 0.1069777744018534\n",
      "94 Train Loss 0.44069436 Test MSE 0.04711332827197286 Test RE 0.10374805248852682\n",
      "95 Train Loss 0.417303 Test MSE 0.04827381231545613 Test RE 0.10501802802806882\n",
      "96 Train Loss 0.4091979 Test MSE 0.04797243250903776 Test RE 0.10468969403579813\n",
      "97 Train Loss 0.3869446 Test MSE 0.052070956539513914 Test RE 0.10907013184937725\n",
      "98 Train Loss 0.37420222 Test MSE 0.043812195206962536 Test RE 0.1000473448215716\n",
      "99 Train Loss 0.3503385 Test MSE 0.04343007900612041 Test RE 0.09961009859926884\n",
      "Training time: 79.81\n",
      "KG_stan_tune16\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 56.23603 Test MSE 8.519454584076597 Test RE 1.3951276829558397\n",
      "1 Train Loss 54.67836 Test MSE 8.522714165218845 Test RE 1.3953945484545778\n",
      "2 Train Loss 47.481827 Test MSE 9.809996548019637 Test RE 1.4970713099090631\n",
      "3 Train Loss 44.658405 Test MSE 8.879508209525246 Test RE 1.4243034190900727\n",
      "4 Train Loss 44.09675 Test MSE 8.696372889488298 Test RE 1.4095391308450802\n",
      "5 Train Loss 43.37747 Test MSE 8.619917483640148 Test RE 1.4033293697965525\n",
      "6 Train Loss 42.680832 Test MSE 8.433599154573944 Test RE 1.3880801315784779\n",
      "7 Train Loss 42.128452 Test MSE 8.360810781296577 Test RE 1.3820770572469248\n",
      "8 Train Loss 41.654808 Test MSE 8.519624460699768 Test RE 1.3951415922029584\n",
      "9 Train Loss 41.425232 Test MSE 8.47280855813135 Test RE 1.3913031138850822\n",
      "10 Train Loss 41.25185 Test MSE 8.666401114497669 Test RE 1.4071080683043204\n",
      "11 Train Loss 40.882645 Test MSE 8.727937108770883 Test RE 1.412094834522671\n",
      "12 Train Loss 40.623207 Test MSE 8.715290749989256 Test RE 1.4110714351115456\n",
      "13 Train Loss 40.394478 Test MSE 8.97541445257104 Test RE 1.4319746052251254\n",
      "14 Train Loss 39.889477 Test MSE 9.033825587362337 Test RE 1.436626625339092\n",
      "15 Train Loss 39.395496 Test MSE 9.037094097761742 Test RE 1.4368864933411556\n",
      "16 Train Loss 38.79117 Test MSE 9.048739875794507 Test RE 1.4378120272258752\n",
      "17 Train Loss 36.227367 Test MSE 7.964888081661178 Test RE 1.348956357100898\n",
      "18 Train Loss 33.36637 Test MSE 8.620572519927515 Test RE 1.4033826889959191\n",
      "19 Train Loss 31.805975 Test MSE 8.48939217756173 Test RE 1.392664029941079\n",
      "20 Train Loss 31.033302 Test MSE 8.24402950625683 Test RE 1.3723908979087491\n",
      "21 Train Loss 30.598541 Test MSE 8.072477191853956 Test RE 1.3580365967547168\n",
      "22 Train Loss 28.795624 Test MSE 7.659293450274907 Test RE 1.3228250631384686\n",
      "23 Train Loss 27.20087 Test MSE 7.5799166479394655 Test RE 1.3159526872326412\n",
      "24 Train Loss 25.949768 Test MSE 7.360565258071016 Test RE 1.296772057900862\n",
      "25 Train Loss 25.469166 Test MSE 7.388579938747062 Test RE 1.2992375039837578\n",
      "26 Train Loss 24.293121 Test MSE 7.034965834950173 Test RE 1.2677658723683565\n",
      "27 Train Loss 23.252556 Test MSE 6.814414271579608 Test RE 1.2477349104941626\n",
      "28 Train Loss 22.636688 Test MSE 6.661328992913464 Test RE 1.2336401684025238\n",
      "29 Train Loss 21.738424 Test MSE 6.613114005190894 Test RE 1.2291674898628984\n",
      "30 Train Loss 20.88297 Test MSE 6.671736805493732 Test RE 1.2346035260456945\n",
      "31 Train Loss 18.625788 Test MSE 6.359346271859567 Test RE 1.2053531215941744\n",
      "32 Train Loss 16.05218 Test MSE 5.483593021304957 Test RE 1.1192849591918492\n",
      "33 Train Loss 12.471794 Test MSE 4.696906450024496 Test RE 1.0358908939878833\n",
      "34 Train Loss 10.196944 Test MSE 4.160225504994932 Test RE 0.9749144250982744\n",
      "35 Train Loss 8.738983 Test MSE 3.6748972050158213 Test RE 0.9162851708139923\n",
      "36 Train Loss 7.8966646 Test MSE 3.3732130365887794 Test RE 0.8778694693184994\n",
      "37 Train Loss 6.8123827 Test MSE 3.42427615196529 Test RE 0.8844890300492924\n",
      "38 Train Loss 6.2172694 Test MSE 3.7229403767217932 Test RE 0.9222551748779786\n",
      "39 Train Loss 5.7469535 Test MSE 3.682698664446885 Test RE 0.9172572485873872\n",
      "40 Train Loss 5.393745 Test MSE 3.785750248545245 Test RE 0.9300023373297562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 Train Loss 5.1011496 Test MSE 3.8227627013212024 Test RE 0.9345374942785314\n",
      "42 Train Loss 4.95516 Test MSE 3.905313616827529 Test RE 0.9445740673296816\n",
      "43 Train Loss 4.8022385 Test MSE 3.898970990476418 Test RE 0.9438067134797313\n",
      "44 Train Loss 4.5583 Test MSE 4.043415085971221 Test RE 0.9611302005625428\n",
      "45 Train Loss 4.3018966 Test MSE 4.031959215493511 Test RE 0.9597676898179609\n",
      "46 Train Loss 4.063777 Test MSE 3.917413280102532 Test RE 0.9460362020575801\n",
      "47 Train Loss 3.7860532 Test MSE 3.740473741543321 Test RE 0.9244243262584765\n",
      "48 Train Loss 3.241072 Test MSE 3.3387021462039 Test RE 0.8733672418629183\n",
      "49 Train Loss 2.6069243 Test MSE 3.1663997118810108 Test RE 0.8505325307579539\n",
      "50 Train Loss 1.9415082 Test MSE 2.9972835619978797 Test RE 0.8275075716323377\n",
      "51 Train Loss 1.6452237 Test MSE 2.8927523926361065 Test RE 0.8129497297356237\n",
      "52 Train Loss 1.3951772 Test MSE 2.7654439764296512 Test RE 0.7948597259650254\n",
      "53 Train Loss 1.2180022 Test MSE 2.8127454288813665 Test RE 0.8016287306447444\n",
      "54 Train Loss 1.1105015 Test MSE 2.7695664406421256 Test RE 0.7954519564589776\n",
      "55 Train Loss 1.0147141 Test MSE 2.72657125488859 Test RE 0.7892534449495492\n",
      "56 Train Loss 0.8953397 Test MSE 2.8010546916120584 Test RE 0.7999610736642794\n",
      "57 Train Loss 0.8380483 Test MSE 2.821739072915193 Test RE 0.8029092961551062\n",
      "58 Train Loss 0.7821077 Test MSE 2.766985469833816 Test RE 0.7950812275281449\n",
      "59 Train Loss 0.7412442 Test MSE 2.757160543796483 Test RE 0.7936683973945706\n",
      "60 Train Loss 0.6880677 Test MSE 2.778763201419793 Test RE 0.796771570638945\n",
      "61 Train Loss 0.6654287 Test MSE 2.8262951216671843 Test RE 0.8035572331863465\n",
      "62 Train Loss 0.6329884 Test MSE 2.8535858723553544 Test RE 0.8074274935258209\n",
      "63 Train Loss 0.60645676 Test MSE 2.925874838801335 Test RE 0.8175906804560874\n",
      "64 Train Loss 0.58673763 Test MSE 2.9855752165325598 Test RE 0.8258897359020109\n",
      "65 Train Loss 0.57255626 Test MSE 2.9804535013167848 Test RE 0.8251810303104352\n",
      "66 Train Loss 0.5602108 Test MSE 3.038413373529603 Test RE 0.8331659057756985\n",
      "67 Train Loss 0.54635006 Test MSE 3.0397499515675657 Test RE 0.833349137725456\n",
      "68 Train Loss 0.53111374 Test MSE 3.0768195731011776 Test RE 0.8384150684920942\n",
      "69 Train Loss 0.5180826 Test MSE 3.0763217922200767 Test RE 0.8383472445812328\n",
      "70 Train Loss 0.50877845 Test MSE 3.0875313912389664 Test RE 0.8398732538685612\n",
      "71 Train Loss 0.49516502 Test MSE 3.1230851072607413 Test RE 0.8446950904167057\n",
      "72 Train Loss 0.48258436 Test MSE 3.1382159056238503 Test RE 0.8467388176483733\n",
      "73 Train Loss 0.47163224 Test MSE 3.166205810736069 Test RE 0.8505064882852089\n",
      "74 Train Loss 0.4579884 Test MSE 3.2429925598809195 Test RE 0.8607579378614488\n",
      "75 Train Loss 0.45267934 Test MSE 3.25333195956003 Test RE 0.8621289922014478\n",
      "76 Train Loss 0.4453682 Test MSE 3.271825215907677 Test RE 0.8645758650373488\n",
      "77 Train Loss 0.43717772 Test MSE 3.317077641001767 Test RE 0.8705342825170275\n",
      "78 Train Loss 0.43410763 Test MSE 3.3295267678403957 Test RE 0.8721663278919051\n",
      "79 Train Loss 0.42586794 Test MSE 3.365808565133979 Test RE 0.8769054432744184\n",
      "80 Train Loss 0.4145255 Test MSE 3.3778768888126827 Test RE 0.8784761370884611\n",
      "81 Train Loss 0.41102085 Test MSE 3.4232923242358164 Test RE 0.8843619597857286\n",
      "82 Train Loss 0.40544218 Test MSE 3.44560095565121 Test RE 0.8872388492695641\n",
      "83 Train Loss 0.40000242 Test MSE 3.452392292372119 Test RE 0.8881128000938899\n",
      "84 Train Loss 0.3946927 Test MSE 3.4760742133027107 Test RE 0.8911536295428617\n",
      "85 Train Loss 0.38707122 Test MSE 3.495492090408676 Test RE 0.8936392227346598\n",
      "86 Train Loss 0.38535193 Test MSE 3.5166729429347816 Test RE 0.89634262659602\n",
      "87 Train Loss 0.3800129 Test MSE 3.516301043129367 Test RE 0.8962952297428723\n",
      "88 Train Loss 0.3766985 Test MSE 3.506354761242294 Test RE 0.8950266924387656\n",
      "89 Train Loss 0.3694736 Test MSE 3.5372211424756133 Test RE 0.8989575130203341\n",
      "90 Train Loss 0.36689276 Test MSE 3.5627646221912084 Test RE 0.9021975135841219\n",
      "91 Train Loss 0.36046717 Test MSE 3.577280346346189 Test RE 0.9040335509690368\n",
      "92 Train Loss 0.35867164 Test MSE 3.570122500243608 Test RE 0.9031286493961467\n",
      "93 Train Loss 0.35334715 Test MSE 3.5642833302449253 Test RE 0.9023897840242753\n",
      "94 Train Loss 0.35114515 Test MSE 3.5713633319470595 Test RE 0.9032855814489986\n",
      "95 Train Loss 0.34838894 Test MSE 3.5615951470686635 Test RE 0.9020494285634095\n",
      "96 Train Loss 0.34629887 Test MSE 3.558575439916752 Test RE 0.9016669450672735\n",
      "97 Train Loss 0.3436489 Test MSE 3.5790277093282645 Test RE 0.9042543167118919\n",
      "98 Train Loss 0.34226125 Test MSE 3.5800636191266744 Test RE 0.9043851704257481\n",
      "99 Train Loss 0.33965397 Test MSE 3.5912726601930713 Test RE 0.9057998614932858\n",
      "Training time: 78.80\n",
      "KG_stan_tune16\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.013363 Test MSE 8.44914233313064 Test RE 1.3893586631574915\n",
      "1 Train Loss 52.95912 Test MSE 8.30905741759913 Test RE 1.3777928932757377\n",
      "2 Train Loss 49.068996 Test MSE 8.345328474906678 Test RE 1.3807968192337954\n",
      "3 Train Loss 44.332077 Test MSE 8.141433873668413 Test RE 1.3638245698837943\n",
      "4 Train Loss 43.599007 Test MSE 8.277445655590046 Test RE 1.3751694930803862\n",
      "5 Train Loss 41.91698 Test MSE 8.238442805901887 Test RE 1.371925807621842\n",
      "6 Train Loss 40.776077 Test MSE 8.613960612631343 Test RE 1.4028443943445048\n",
      "7 Train Loss 40.30751 Test MSE 8.858748523400184 Test RE 1.4226374825591526\n",
      "8 Train Loss 39.57913 Test MSE 8.323148899355104 Test RE 1.3789607103813752\n",
      "9 Train Loss 39.241093 Test MSE 8.448165240886583 Test RE 1.389278325368737\n",
      "10 Train Loss 39.04673 Test MSE 8.288919173384693 Test RE 1.3761222367490107\n",
      "11 Train Loss 38.709743 Test MSE 8.413675841083982 Test RE 1.3864395800548721\n",
      "12 Train Loss 38.12603 Test MSE 8.200414024331144 Test RE 1.3687557295546546\n",
      "13 Train Loss 37.527905 Test MSE 8.125558760887069 Test RE 1.3624942493380583\n",
      "14 Train Loss 36.46868 Test MSE 8.122881605628804 Test RE 1.3622697780587099\n",
      "15 Train Loss 36.028133 Test MSE 8.27075292547581 Test RE 1.3746134338916658\n",
      "16 Train Loss 35.446747 Test MSE 8.04165114549157 Test RE 1.3554411765613907\n",
      "17 Train Loss 33.75891 Test MSE 8.020990580662215 Test RE 1.353698860836511\n",
      "18 Train Loss 32.340775 Test MSE 7.386684677165574 Test RE 1.2990708581007973\n",
      "19 Train Loss 31.670174 Test MSE 7.362130734929427 Test RE 1.2969099521146037\n",
      "20 Train Loss 31.044062 Test MSE 5.705268969189354 Test RE 1.1416845451145268\n",
      "21 Train Loss 28.120113 Test MSE 3.359556695053113 Test RE 0.8760906543523083\n",
      "22 Train Loss 22.173672 Test MSE 3.2068330658648914 Test RE 0.855945743867635\n",
      "23 Train Loss 18.72101 Test MSE 2.7210968443927572 Test RE 0.7884607151997869\n",
      "24 Train Loss 16.331074 Test MSE 2.2173388242105427 Test RE 0.7117444526358312\n",
      "25 Train Loss 14.031689 Test MSE 2.1979827369297165 Test RE 0.7086310842690162\n",
      "26 Train Loss 11.819416 Test MSE 2.5414513168922146 Test RE 0.7619894488033672\n",
      "27 Train Loss 10.570631 Test MSE 2.2129660780152474 Test RE 0.7110423015403013\n",
      "28 Train Loss 8.956688 Test MSE 1.8620924173524325 Test RE 0.6522418724499167\n",
      "29 Train Loss 7.9542384 Test MSE 1.9876182949136403 Test RE 0.6738675648349048\n",
      "30 Train Loss 7.247984 Test MSE 2.0995915126959175 Test RE 0.6925888005422502\n",
      "31 Train Loss 6.9709005 Test MSE 1.9976397437497388 Test RE 0.6755642282528351\n",
      "32 Train Loss 6.633921 Test MSE 1.9981727497835833 Test RE 0.6756543485548825\n",
      "33 Train Loss 6.3839397 Test MSE 1.8881682467994187 Test RE 0.6567928332160778\n",
      "34 Train Loss 6.2311306 Test MSE 1.9116054084090017 Test RE 0.6608565298462875\n",
      "35 Train Loss 6.0592184 Test MSE 2.015607383521715 Test RE 0.6785955862648284\n",
      "36 Train Loss 5.82078 Test MSE 1.9863396294782378 Test RE 0.6736507752761765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Train Loss 5.6751256 Test MSE 2.0601838537874677 Test RE 0.6860583426905539\n",
      "38 Train Loss 5.5485806 Test MSE 2.033977450527439 Test RE 0.6816809023923036\n",
      "39 Train Loss 5.481941 Test MSE 2.030682252753784 Test RE 0.6811284911764478\n",
      "40 Train Loss 5.373828 Test MSE 2.003600052642644 Test RE 0.6765713098516645\n",
      "41 Train Loss 5.3258314 Test MSE 2.011726843952619 Test RE 0.6779420399163175\n",
      "42 Train Loss 5.2753916 Test MSE 2.027671578168127 Test RE 0.6806233858427359\n",
      "43 Train Loss 5.237927 Test MSE 2.043825734218755 Test RE 0.6833292196254283\n",
      "44 Train Loss 5.2163744 Test MSE 2.0444660777665487 Test RE 0.6834362569285215\n",
      "45 Train Loss 5.162918 Test MSE 2.050472202708313 Test RE 0.6844394022715946\n",
      "46 Train Loss 5.125929 Test MSE 2.0753257468243187 Test RE 0.6885749151963542\n",
      "47 Train Loss 5.083234 Test MSE 2.0837432385266292 Test RE 0.6899699271203092\n",
      "48 Train Loss 5.062294 Test MSE 2.0771361355888165 Test RE 0.6888751852981284\n",
      "49 Train Loss 5.032578 Test MSE 2.088947454580613 Test RE 0.6908310009069871\n",
      "50 Train Loss 4.9978533 Test MSE 2.102001068612816 Test RE 0.6929861047097957\n",
      "51 Train Loss 4.9890943 Test MSE 2.10126430870431 Test RE 0.6928646468444097\n",
      "52 Train Loss 4.9685 Test MSE 2.104741012936854 Test RE 0.693437608999139\n",
      "53 Train Loss 4.9314427 Test MSE 2.108551282598434 Test RE 0.6940649996244624\n",
      "54 Train Loss 4.9226832 Test MSE 2.1134115305504486 Test RE 0.6948644552418796\n",
      "55 Train Loss 4.916689 Test MSE 2.11567615257137 Test RE 0.6952366458922616\n",
      "56 Train Loss 4.896632 Test MSE 2.1265567213783605 Test RE 0.6970220961968081\n",
      "57 Train Loss 4.8842535 Test MSE 2.1119133128810423 Test RE 0.6946181135429029\n",
      "58 Train Loss 4.8729086 Test MSE 2.1142876619693367 Test RE 0.6950084710879274\n",
      "59 Train Loss 4.860554 Test MSE 2.123530750629068 Test RE 0.6965260080147129\n",
      "60 Train Loss 4.842705 Test MSE 2.1254942498117075 Test RE 0.6968479511399809\n",
      "61 Train Loss 4.8332896 Test MSE 2.1297429602270084 Test RE 0.6975440779504423\n",
      "62 Train Loss 4.829562 Test MSE 2.128950193212005 Test RE 0.6974142403556929\n",
      "63 Train Loss 4.8210993 Test MSE 2.1419305879344486 Test RE 0.6995371071251343\n",
      "64 Train Loss 4.811955 Test MSE 2.1431375355108826 Test RE 0.6997341689991045\n",
      "65 Train Loss 4.808101 Test MSE 2.1391096910657095 Test RE 0.6990763143747264\n",
      "66 Train Loss 4.80626 Test MSE 2.135344025756949 Test RE 0.6984607201843935\n",
      "67 Train Loss 4.801269 Test MSE 2.1334953168124837 Test RE 0.698158302829965\n",
      "68 Train Loss 4.796088 Test MSE 2.134921200045124 Test RE 0.6983915646364518\n",
      "69 Train Loss 4.7900095 Test MSE 2.1462487190594293 Test RE 0.7002418853462689\n",
      "70 Train Loss 4.786215 Test MSE 2.1394956704042873 Test RE 0.6991393819312258\n",
      "71 Train Loss 4.7762933 Test MSE 2.136713321305572 Test RE 0.6986846292756707\n",
      "72 Train Loss 4.772889 Test MSE 2.130163629670717 Test RE 0.6976129644302219\n",
      "73 Train Loss 4.7612185 Test MSE 2.1377816560357497 Test RE 0.6988592750199207\n",
      "74 Train Loss 4.7559676 Test MSE 2.1350035889903114 Test RE 0.6984050403537799\n",
      "75 Train Loss 4.751539 Test MSE 2.1256730172244707 Test RE 0.6968772551679915\n",
      "76 Train Loss 4.738494 Test MSE 2.1310466258575476 Test RE 0.6977575368370236\n",
      "77 Train Loss 4.7318444 Test MSE 2.1270925257743203 Test RE 0.6971099010453312\n",
      "78 Train Loss 4.7284803 Test MSE 2.1233148686572174 Test RE 0.6964906020687754\n",
      "79 Train Loss 4.7183375 Test MSE 2.1166708080700714 Test RE 0.6954000545722183\n",
      "80 Train Loss 4.7096233 Test MSE 2.1248881409745652 Test RE 0.6967485870000271\n",
      "81 Train Loss 4.7049184 Test MSE 2.12878386880791 Test RE 0.6973869970519364\n",
      "82 Train Loss 4.702033 Test MSE 2.1275929804946987 Test RE 0.697191902984234\n",
      "83 Train Loss 4.6955547 Test MSE 2.112950629464224 Test RE 0.6947886817257967\n",
      "84 Train Loss 4.6829576 Test MSE 2.1230864289775946 Test RE 0.696453134622947\n",
      "85 Train Loss 4.658472 Test MSE 2.113773803277937 Test RE 0.6949240081616634\n",
      "86 Train Loss 4.634093 Test MSE 2.1312798249206333 Test RE 0.69779571337212\n",
      "87 Train Loss 4.6118183 Test MSE 2.102726050868012 Test RE 0.6931056002048717\n",
      "88 Train Loss 4.5875926 Test MSE 2.1035165747467404 Test RE 0.6932358751494676\n",
      "89 Train Loss 4.559115 Test MSE 2.093613377004878 Test RE 0.691602098790137\n",
      "90 Train Loss 4.539801 Test MSE 2.088930888284701 Test RE 0.6908282616007754\n",
      "91 Train Loss 4.4723654 Test MSE 2.034650745311875 Test RE 0.6817937193312833\n",
      "92 Train Loss 3.011754 Test MSE 1.4485413667596432 Test RE 0.5752723643219277\n",
      "93 Train Loss 2.0758793 Test MSE 1.2868710849320433 Test RE 0.5422200611357273\n",
      "94 Train Loss 1.5401862 Test MSE 0.8227850755638211 Test RE 0.4335620519225541\n",
      "95 Train Loss 0.94460833 Test MSE 0.31008894789024605 Test RE 0.26616515795065604\n",
      "96 Train Loss 0.61932623 Test MSE 0.09147205734378418 Test RE 0.14456137948249764\n",
      "97 Train Loss 0.42097035 Test MSE 0.04598345807439779 Test RE 0.10249646196063185\n",
      "98 Train Loss 0.28264198 Test MSE 0.03845627646785263 Test RE 0.09373281843611625\n",
      "99 Train Loss 0.19687177 Test MSE 0.031979762929178125 Test RE 0.08547629322710973\n",
      "Training time: 80.24\n",
      "KG_stan_tune16\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 57.823112 Test MSE 8.613334779855085 Test RE 1.402793432772444\n",
      "1 Train Loss 54.63833 Test MSE 8.493124160548879 Test RE 1.392970107648541\n",
      "2 Train Loss 46.224113 Test MSE 8.763495697050566 Test RE 1.414968426512485\n",
      "3 Train Loss 45.37951 Test MSE 8.627436102206435 Test RE 1.403941254916703\n",
      "4 Train Loss 45.04618 Test MSE 8.558639219054541 Test RE 1.3983323982751612\n",
      "5 Train Loss 44.530304 Test MSE 8.477665606903628 Test RE 1.391701839930738\n",
      "6 Train Loss 44.34097 Test MSE 8.49913013411163 Test RE 1.3934625449990738\n",
      "7 Train Loss 44.1291 Test MSE 8.387321548889517 Test RE 1.3842664935210631\n",
      "8 Train Loss 43.80081 Test MSE 8.432023943461303 Test RE 1.3879504940822915\n",
      "9 Train Loss 41.224777 Test MSE 8.318822092721692 Test RE 1.378602235959818\n",
      "10 Train Loss 38.13475 Test MSE 7.674600096050219 Test RE 1.3241461973119861\n",
      "11 Train Loss 35.414314 Test MSE 7.163819253588628 Test RE 1.2793234783853045\n",
      "12 Train Loss 34.33118 Test MSE 7.184747980158145 Test RE 1.2811908541299268\n",
      "13 Train Loss 33.783203 Test MSE 7.239995337656406 Test RE 1.2861073006828954\n",
      "14 Train Loss 33.338814 Test MSE 7.148655697597164 Test RE 1.277968798092943\n",
      "15 Train Loss 32.80596 Test MSE 7.081740549284941 Test RE 1.2719735078756325\n",
      "16 Train Loss 32.165863 Test MSE 7.033490708093859 Test RE 1.2676329496524683\n",
      "17 Train Loss 31.578053 Test MSE 7.066588451165806 Test RE 1.27061202142513\n",
      "18 Train Loss 30.014034 Test MSE 6.795699755349636 Test RE 1.246020397076244\n",
      "19 Train Loss 27.256756 Test MSE 6.432074679197622 Test RE 1.2122260132686875\n",
      "20 Train Loss 23.125553 Test MSE 6.3468158329935 Test RE 1.204165023767752\n",
      "21 Train Loss 20.197187 Test MSE 5.619366988433919 Test RE 1.1330569999967737\n",
      "22 Train Loss 17.87105 Test MSE 4.880160586114705 Test RE 1.0559056575198795\n",
      "23 Train Loss 16.04553 Test MSE 4.719779822746492 Test RE 1.0384101629655451\n",
      "24 Train Loss 13.219337 Test MSE 4.618614867845626 Test RE 1.0272211078473652\n",
      "25 Train Loss 9.905266 Test MSE 4.436249991432652 Test RE 1.0067370829169155\n",
      "26 Train Loss 7.168571 Test MSE 3.8747133314487514 Test RE 0.9408661603679114\n",
      "27 Train Loss 6.3227687 Test MSE 3.4225692686978353 Test RE 0.8842685589714236\n",
      "28 Train Loss 5.0219398 Test MSE 3.457038100790302 Test RE 0.8887101561356302\n",
      "29 Train Loss 4.6750693 Test MSE 3.063529000447808 Test RE 0.8366023077065108\n",
      "30 Train Loss 4.2492085 Test MSE 2.6053026953930845 Test RE 0.771502174858676\n",
      "31 Train Loss 3.5711355 Test MSE 1.8599372308545812 Test RE 0.6518643106706111\n",
      "32 Train Loss 3.2100623 Test MSE 1.8791916682419612 Test RE 0.6552297372211889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 Train Loss 2.850442 Test MSE 1.6933503864556492 Test RE 0.6219872408679578\n",
      "34 Train Loss 2.3298538 Test MSE 1.6291080915097238 Test RE 0.6100746938566682\n",
      "35 Train Loss 2.0021286 Test MSE 1.5073346572375508 Test RE 0.5868308037756769\n",
      "36 Train Loss 1.6491524 Test MSE 0.833556103722092 Test RE 0.436390691540282\n",
      "37 Train Loss 1.3500351 Test MSE 0.814218298341355 Test RE 0.4312990379510558\n",
      "38 Train Loss 1.0715535 Test MSE 0.769331573362233 Test RE 0.4192420523965793\n",
      "39 Train Loss 0.95140904 Test MSE 0.7331073615731981 Test RE 0.40925298010692246\n",
      "40 Train Loss 0.72511065 Test MSE 0.32928587208189064 Test RE 0.2742802958200204\n",
      "41 Train Loss 0.5656844 Test MSE 0.21353300531699232 Test RE 0.22087195055496509\n",
      "42 Train Loss 0.48060817 Test MSE 0.17374611467319168 Test RE 0.19923498942663864\n",
      "43 Train Loss 0.41711345 Test MSE 0.15617399181744568 Test RE 0.18889150018154374\n",
      "44 Train Loss 0.35856405 Test MSE 0.16228347656836814 Test RE 0.19255074874868208\n",
      "45 Train Loss 0.32006836 Test MSE 0.1388577825537957 Test RE 0.1781119970407448\n",
      "46 Train Loss 0.2668441 Test MSE 0.10339881368167116 Test RE 0.15369715843109913\n",
      "47 Train Loss 0.2506618 Test MSE 0.0951515541105115 Test RE 0.14744023122064415\n",
      "48 Train Loss 0.23061264 Test MSE 0.09181099936357515 Test RE 0.14482896185596866\n",
      "49 Train Loss 0.21660998 Test MSE 0.08705161683398985 Test RE 0.141025121050846\n",
      "50 Train Loss 0.20577753 Test MSE 0.0778938166139406 Test RE 0.13340114345188678\n",
      "51 Train Loss 0.18204878 Test MSE 0.06121852160065795 Test RE 0.11826315993726035\n",
      "52 Train Loss 0.17260599 Test MSE 0.053529051034022855 Test RE 0.1105866831596397\n",
      "53 Train Loss 0.15524623 Test MSE 0.04353118230071855 Test RE 0.09972597514185222\n",
      "54 Train Loss 0.13942958 Test MSE 0.047725566058234414 Test RE 0.1044199796758768\n",
      "55 Train Loss 0.12839013 Test MSE 0.048557943419274996 Test RE 0.10532663334566529\n",
      "56 Train Loss 0.11791306 Test MSE 0.03911589824416905 Test RE 0.09453327724647718\n",
      "57 Train Loss 0.1126741 Test MSE 0.037640353430049095 Test RE 0.09273312742342273\n",
      "58 Train Loss 0.106626645 Test MSE 0.03662261062277972 Test RE 0.09147084899273107\n",
      "59 Train Loss 0.100683905 Test MSE 0.03506598683883536 Test RE 0.08950578235554013\n",
      "60 Train Loss 0.09641611 Test MSE 0.033369215290764594 Test RE 0.08731343160125676\n",
      "61 Train Loss 0.08956113 Test MSE 0.02627226556725348 Test RE 0.0774741505130357\n",
      "62 Train Loss 0.07901225 Test MSE 0.024884672901552374 Test RE 0.07540046575132668\n",
      "63 Train Loss 0.0728705 Test MSE 0.024725697238640352 Test RE 0.07515923202196405\n",
      "64 Train Loss 0.06818007 Test MSE 0.02021973509290635 Test RE 0.06796663848616866\n",
      "65 Train Loss 0.06422081 Test MSE 0.017109081589250053 Test RE 0.06252035120177718\n",
      "66 Train Loss 0.061443213 Test MSE 0.015499027869293311 Test RE 0.0595059358690845\n",
      "67 Train Loss 0.05813044 Test MSE 0.015839239011686528 Test RE 0.06015548275736251\n",
      "68 Train Loss 0.051423114 Test MSE 0.014592093392028903 Test RE 0.05773868127322738\n",
      "69 Train Loss 0.048118375 Test MSE 0.013998888625348071 Test RE 0.056552894691880115\n",
      "70 Train Loss 0.04550415 Test MSE 0.012770822228682966 Test RE 0.054015386756135174\n",
      "71 Train Loss 0.040248472 Test MSE 0.011449672160162282 Test RE 0.0511451652443008\n",
      "72 Train Loss 0.0332354 Test MSE 0.009022353458816345 Test RE 0.04540126762821879\n",
      "73 Train Loss 0.030577717 Test MSE 0.009385901162112999 Test RE 0.04630693628485106\n",
      "74 Train Loss 0.028820071 Test MSE 0.008811087175861716 Test RE 0.04486656378853523\n",
      "75 Train Loss 0.027147433 Test MSE 0.007980646569406353 Test RE 0.04269992373273841\n",
      "76 Train Loss 0.025229365 Test MSE 0.007190353453788515 Test RE 0.04053061372285593\n",
      "77 Train Loss 0.022524232 Test MSE 0.009246317226515354 Test RE 0.04596131596683102\n",
      "78 Train Loss 0.021091823 Test MSE 0.00807011692361172 Test RE 0.04293860924456223\n",
      "79 Train Loss 0.020355973 Test MSE 0.008031845494982003 Test RE 0.04283667299780316\n",
      "80 Train Loss 0.019353166 Test MSE 0.008201740976719602 Test RE 0.04328735851127223\n",
      "81 Train Loss 0.018681701 Test MSE 0.007664064293370961 Test RE 0.04184442745944843\n",
      "82 Train Loss 0.016645677 Test MSE 0.00509373792348833 Test RE 0.0341135061869169\n",
      "83 Train Loss 0.015770804 Test MSE 0.005345991825839787 Test RE 0.03494799021691233\n",
      "84 Train Loss 0.015433554 Test MSE 0.00549843278423624 Test RE 0.03544275890144798\n",
      "85 Train Loss 0.015003061 Test MSE 0.005453783054110895 Test RE 0.03529856004842426\n",
      "86 Train Loss 0.014508806 Test MSE 0.0049513354351855545 Test RE 0.033633280932851894\n",
      "87 Train Loss 0.013839602 Test MSE 0.005167542650792878 Test RE 0.03435975790515203\n",
      "88 Train Loss 0.012835998 Test MSE 0.0048773171874557444 Test RE 0.033380939858365814\n",
      "89 Train Loss 0.012218706 Test MSE 0.004717049573483745 Test RE 0.032827913507571284\n",
      "90 Train Loss 0.012080576 Test MSE 0.005195150606260934 Test RE 0.034451420336359125\n",
      "91 Train Loss 0.011215705 Test MSE 0.004417967304017016 Test RE 0.03177015319677172\n",
      "92 Train Loss 0.010645122 Test MSE 0.0039392743837008545 Test RE 0.029999649193536385\n",
      "93 Train Loss 0.010381733 Test MSE 0.0037687644401428843 Test RE 0.02934320562757955\n",
      "94 Train Loss 0.009990706 Test MSE 0.0036125915321022144 Test RE 0.028728800275413788\n",
      "95 Train Loss 0.009432503 Test MSE 0.003767133196433429 Test RE 0.029336854593844476\n",
      "96 Train Loss 0.009094359 Test MSE 0.0036680707030950243 Test RE 0.028948556272543165\n",
      "97 Train Loss 0.008545885 Test MSE 0.002834284459910922 Test RE 0.02544660087752376\n",
      "98 Train Loss 0.007953651 Test MSE 0.0019727678304464267 Test RE 0.021229807143661728\n",
      "99 Train Loss 0.007129943 Test MSE 0.0011858477119262606 Test RE 0.016459722925913196\n",
      "Training time: 79.10\n",
      "KG_stan_tune16\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.921387 Test MSE 8.592390621276314 Test RE 1.4010868806130752\n",
      "1 Train Loss 58.294334 Test MSE 8.677854979610306 Test RE 1.4080376066533258\n",
      "2 Train Loss 56.74569 Test MSE 8.874701507605321 Test RE 1.4239178612092835\n",
      "3 Train Loss 53.76654 Test MSE 8.581539129113098 Test RE 1.400201871578533\n",
      "4 Train Loss 49.581512 Test MSE 8.838221503706983 Test RE 1.4209882967969345\n",
      "5 Train Loss 46.784462 Test MSE 8.537126904087348 Test RE 1.3965739240284698\n",
      "6 Train Loss 46.210995 Test MSE 8.466877907490646 Test RE 1.3908160984486326\n",
      "7 Train Loss 46.002113 Test MSE 8.450634111683595 Test RE 1.3894813101610155\n",
      "8 Train Loss 45.700897 Test MSE 8.518264539986268 Test RE 1.395030240013883\n",
      "9 Train Loss 45.214886 Test MSE 8.301308825685584 Test RE 1.3771503146741562\n",
      "10 Train Loss 45.09756 Test MSE 8.138349354052824 Test RE 1.3635661914318065\n",
      "11 Train Loss 44.963158 Test MSE 8.287962371986858 Test RE 1.3760428106108866\n",
      "12 Train Loss 44.639328 Test MSE 8.256981024799593 Test RE 1.3734685002265294\n",
      "13 Train Loss 44.38031 Test MSE 8.425253063437506 Test RE 1.3873931229420444\n",
      "14 Train Loss 43.80478 Test MSE 8.507301088281643 Test RE 1.3941322125508704\n",
      "15 Train Loss 43.299545 Test MSE 8.449991286467041 Test RE 1.3894284614280763\n",
      "16 Train Loss 42.709602 Test MSE 8.41028544803425 Test RE 1.386160210559375\n",
      "17 Train Loss 42.14392 Test MSE 8.348749220031246 Test RE 1.3810797841330087\n",
      "18 Train Loss 40.634666 Test MSE 7.850210132134107 Test RE 1.3392100545416108\n",
      "19 Train Loss 38.72618 Test MSE 7.615317093012175 Test RE 1.3190220511744755\n",
      "20 Train Loss 38.092873 Test MSE 7.373652365831336 Test RE 1.2979243782829066\n",
      "21 Train Loss 37.29432 Test MSE 7.563157222352888 Test RE 1.314497076537207\n",
      "22 Train Loss 36.47175 Test MSE 7.631613473323062 Test RE 1.3204326160474482\n",
      "23 Train Loss 35.529663 Test MSE 7.2678065878368345 Test RE 1.2885751177590643\n",
      "24 Train Loss 33.17011 Test MSE 6.8747085979568405 Test RE 1.2532427687130943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Train Loss 28.448528 Test MSE 7.278737305570257 Test RE 1.2895437565602443\n",
      "26 Train Loss 25.86747 Test MSE 7.582602409214543 Test RE 1.3161858046869719\n",
      "27 Train Loss 23.549507 Test MSE 6.665595412428558 Test RE 1.234035163456983\n",
      "28 Train Loss 21.049835 Test MSE 6.047961886325066 Test RE 1.1754727970873153\n",
      "29 Train Loss 18.740372 Test MSE 5.381164229838617 Test RE 1.1087820424564194\n",
      "30 Train Loss 17.649824 Test MSE 5.161269334820686 Test RE 1.085891220106495\n",
      "31 Train Loss 14.886374 Test MSE 4.290820409374679 Test RE 0.9900981046099708\n",
      "32 Train Loss 12.481905 Test MSE 4.081304331101432 Test RE 0.9656228859817517\n",
      "33 Train Loss 9.058175 Test MSE 3.316120789583299 Test RE 0.870408715356397\n",
      "34 Train Loss 7.16328 Test MSE 3.0842858418527146 Test RE 0.8394317090720487\n",
      "35 Train Loss 5.075219 Test MSE 2.2013562521284378 Test RE 0.7091746875279381\n",
      "36 Train Loss 3.3524582 Test MSE 2.075062940445753 Test RE 0.68853131538812\n",
      "37 Train Loss 2.404568 Test MSE 1.8731921600680224 Test RE 0.6541829576876793\n",
      "38 Train Loss 1.8860972 Test MSE 1.857766381184733 Test RE 0.6514837836952535\n",
      "39 Train Loss 1.4046903 Test MSE 1.6901499492349235 Test RE 0.6213991840201294\n",
      "40 Train Loss 1.1937954 Test MSE 1.6343797185858182 Test RE 0.6110609662718554\n",
      "41 Train Loss 1.045113 Test MSE 1.6283011001248513 Test RE 0.6099235725133387\n",
      "42 Train Loss 0.91641 Test MSE 1.596923999739428 Test RE 0.6040184217174767\n",
      "43 Train Loss 0.8288975 Test MSE 1.5986724944438464 Test RE 0.6043490054143408\n",
      "44 Train Loss 0.7882382 Test MSE 1.607283480462566 Test RE 0.6059744327568731\n",
      "45 Train Loss 0.7126716 Test MSE 1.5402361514427938 Test RE 0.5932007843684055\n",
      "46 Train Loss 0.65008074 Test MSE 1.4925328548566061 Test RE 0.5839423997048393\n",
      "47 Train Loss 0.5593932 Test MSE 1.4627489208668207 Test RE 0.5780866677406314\n",
      "48 Train Loss 0.50298154 Test MSE 1.344475996046359 Test RE 0.5542230534158962\n",
      "49 Train Loss 0.42771736 Test MSE 1.0450891679609113 Test RE 0.48863518232767705\n",
      "50 Train Loss 0.3601381 Test MSE 0.9398136345983292 Test RE 0.46337108633149465\n",
      "51 Train Loss 0.31006372 Test MSE 0.8616553870079415 Test RE 0.4436851201533265\n",
      "52 Train Loss 0.26919636 Test MSE 0.7559277821688264 Test RE 0.4155738519457564\n",
      "53 Train Loss 0.23546706 Test MSE 0.679596063619636 Test RE 0.3940338096641686\n",
      "54 Train Loss 0.2144367 Test MSE 0.4895253719062815 Test RE 0.3344226340967969\n",
      "55 Train Loss 0.19029346 Test MSE 0.5521757551765158 Test RE 0.3551785477642608\n",
      "56 Train Loss 0.1700583 Test MSE 0.5036245180073449 Test RE 0.3392044121630492\n",
      "57 Train Loss 0.16430563 Test MSE 0.46757493190045496 Test RE 0.32683884712397515\n",
      "58 Train Loss 0.13895862 Test MSE 0.39700096846634064 Test RE 0.3011645455169424\n",
      "59 Train Loss 0.13364196 Test MSE 0.40235457704397154 Test RE 0.3031883666032965\n",
      "60 Train Loss 0.11625112 Test MSE 0.34913938479520373 Test RE 0.2824278249597081\n",
      "61 Train Loss 0.10959299 Test MSE 0.2963687917518989 Test RE 0.2602101871660758\n",
      "62 Train Loss 0.1030762 Test MSE 0.2791989065693076 Test RE 0.2525602023506887\n",
      "63 Train Loss 0.086019784 Test MSE 0.19580812425306018 Test RE 0.2115063515659325\n",
      "64 Train Loss 0.08169318 Test MSE 0.1849840867412248 Test RE 0.205577341344419\n",
      "65 Train Loss 0.07736927 Test MSE 0.1612227445846366 Test RE 0.19192043324157065\n",
      "66 Train Loss 0.07277183 Test MSE 0.14596348943359194 Test RE 0.18261236408698958\n",
      "67 Train Loss 0.06220676 Test MSE 0.11986298092012623 Test RE 0.16548193760547072\n",
      "68 Train Loss 0.05832485 Test MSE 0.1259616554352501 Test RE 0.16963960014162072\n",
      "69 Train Loss 0.05351945 Test MSE 0.07510751044907824 Test RE 0.13099349926413262\n",
      "70 Train Loss 0.049280915 Test MSE 0.06745863214427429 Test RE 0.12414431190561419\n",
      "71 Train Loss 0.048150256 Test MSE 0.06246574768845272 Test RE 0.11946179377921803\n",
      "72 Train Loss 0.044894543 Test MSE 0.05433535896933653 Test RE 0.11141645356992436\n",
      "73 Train Loss 0.04209286 Test MSE 0.04968731690372151 Test RE 0.10654445031071076\n",
      "74 Train Loss 0.040049184 Test MSE 0.04607935798378558 Test RE 0.10260328604785474\n",
      "75 Train Loss 0.037300386 Test MSE 0.045160323535153236 Test RE 0.10157494190012602\n",
      "76 Train Loss 0.03509857 Test MSE 0.03886281924354337 Test RE 0.09422696687567353\n",
      "77 Train Loss 0.03355987 Test MSE 0.03672338209805571 Test RE 0.09159660900932778\n",
      "78 Train Loss 0.03136644 Test MSE 0.027452302782400965 Test RE 0.07919494297137382\n",
      "79 Train Loss 0.02732478 Test MSE 0.023492615728335064 Test RE 0.07326115272066651\n",
      "80 Train Loss 0.02578219 Test MSE 0.023540884678738386 Test RE 0.07333637687671835\n",
      "81 Train Loss 0.024683055 Test MSE 0.02464948530739294 Test RE 0.07504331110665782\n",
      "82 Train Loss 0.022853354 Test MSE 0.022773701622552506 Test RE 0.07213148502466324\n",
      "83 Train Loss 0.022221986 Test MSE 0.02327930817307345 Test RE 0.07292779707658772\n",
      "84 Train Loss 0.020959819 Test MSE 0.021560714483055576 Test RE 0.07018424534411556\n",
      "85 Train Loss 0.020282805 Test MSE 0.02081193067277907 Test RE 0.06895475909807866\n",
      "86 Train Loss 0.019448586 Test MSE 0.018318417938679 Test RE 0.06469221808541946\n",
      "87 Train Loss 0.018638052 Test MSE 0.019173352263648632 Test RE 0.06618462096131845\n",
      "88 Train Loss 0.018083211 Test MSE 0.018205563871292404 Test RE 0.06449263591647234\n",
      "89 Train Loss 0.01677284 Test MSE 0.01849034491123201 Test RE 0.06499509254491768\n",
      "90 Train Loss 0.015704835 Test MSE 0.020136212202631253 Test RE 0.06782611625512115\n",
      "91 Train Loss 0.014854007 Test MSE 0.01854200294728418 Test RE 0.06508582035649149\n",
      "92 Train Loss 0.013702884 Test MSE 0.016319316855715898 Test RE 0.06106031601774917\n",
      "93 Train Loss 0.013191084 Test MSE 0.017125294356206924 Test RE 0.0625499666975328\n",
      "94 Train Loss 0.01288006 Test MSE 0.01798606359458794 Test RE 0.06410267051706861\n",
      "95 Train Loss 0.0126146935 Test MSE 0.018374519020845904 Test RE 0.06479120395226699\n",
      "96 Train Loss 0.01192184 Test MSE 0.02048675641660695 Test RE 0.06841394941263797\n",
      "97 Train Loss 0.011431262 Test MSE 0.020230821170184633 Test RE 0.06798526830875205\n",
      "98 Train Loss 0.011128722 Test MSE 0.01869342876397144 Test RE 0.06535104610770189\n",
      "99 Train Loss 0.011009755 Test MSE 0.018383151409730493 Test RE 0.06480642168920975\n",
      "Training time: 79.26\n",
      "KG_stan_tune16\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 55.57404 Test MSE 8.496988452484965 Test RE 1.3932869657861298\n",
      "1 Train Loss 55.25634 Test MSE 8.525802094350427 Test RE 1.3956473135460559\n",
      "2 Train Loss 54.38451 Test MSE 8.47560910556719 Test RE 1.3915330310619518\n",
      "3 Train Loss 48.137863 Test MSE 8.330272150594222 Test RE 1.3795506663556545\n",
      "4 Train Loss 44.281006 Test MSE 8.141698870896672 Test RE 1.3638467654082933\n",
      "5 Train Loss 42.70946 Test MSE 7.930004308477847 Test RE 1.345999107499605\n",
      "6 Train Loss 41.662468 Test MSE 8.178616952480409 Test RE 1.3669354117698422\n",
      "7 Train Loss 41.116177 Test MSE 7.920222070254037 Test RE 1.345168657320109\n",
      "8 Train Loss 40.170166 Test MSE 7.860796850474116 Test RE 1.340112773233382\n",
      "9 Train Loss 39.588806 Test MSE 7.966061178930477 Test RE 1.34905569300741\n",
      "10 Train Loss 39.19639 Test MSE 7.778328514420226 Test RE 1.3330646161698316\n",
      "11 Train Loss 38.48361 Test MSE 7.7176907336335 Test RE 1.3278583409946902\n",
      "12 Train Loss 36.96525 Test MSE 7.734233801066886 Test RE 1.3292807283258306\n",
      "13 Train Loss 35.48091 Test MSE 7.503722568063046 Test RE 1.3093219379259207\n",
      "14 Train Loss 34.00205 Test MSE 6.877408165343891 Test RE 1.2534888068682088\n",
      "15 Train Loss 32.511654 Test MSE 6.8613340265482705 Test RE 1.25202309918726\n",
      "16 Train Loss 30.597115 Test MSE 6.6602092433192475 Test RE 1.233536478422995\n",
      "17 Train Loss 29.589684 Test MSE 6.809083815474996 Test RE 1.2472468056423953\n",
      "18 Train Loss 28.652803 Test MSE 6.417329375159172 Test RE 1.210835723352448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Train Loss 27.404198 Test MSE 5.647849052425311 Test RE 1.135924850816228\n",
      "20 Train Loss 26.673573 Test MSE 5.794407344649842 Test RE 1.150568743155346\n",
      "21 Train Loss 26.11428 Test MSE 5.490107954024288 Test RE 1.119949660380973\n",
      "22 Train Loss 22.33846 Test MSE 3.3843544039820728 Test RE 0.8793180293941907\n",
      "23 Train Loss 17.407446 Test MSE 2.752287541494782 Test RE 0.7929667229268442\n",
      "24 Train Loss 16.166447 Test MSE 2.5976128758078727 Test RE 0.7703627493380605\n",
      "25 Train Loss 14.491692 Test MSE 2.324843218667302 Test RE 0.7287941795856767\n",
      "26 Train Loss 12.249399 Test MSE 1.8828557104715091 Test RE 0.6558682086300122\n",
      "27 Train Loss 12.134503 Test MSE 1.8282319149044195 Test RE 0.6462844449913661\n",
      "28 Train Loss 11.7587385 Test MSE 1.843464144551527 Test RE 0.6489711755423335\n",
      "29 Train Loss 11.155207 Test MSE 2.007127893336618 Test RE 0.6771666846781496\n",
      "30 Train Loss 10.7793 Test MSE 1.9762930880575384 Test RE 0.6719450146711983\n",
      "31 Train Loss 10.179426 Test MSE 1.7049020054139594 Test RE 0.6241051568565181\n",
      "32 Train Loss 9.772193 Test MSE 1.6600839219057537 Test RE 0.6158473570782897\n",
      "33 Train Loss 9.523028 Test MSE 1.7539095210745672 Test RE 0.6330115774516316\n",
      "34 Train Loss 9.39328 Test MSE 1.7828603910491692 Test RE 0.6382145905021339\n",
      "35 Train Loss 9.13051 Test MSE 1.6814157286442724 Test RE 0.6197914960172217\n",
      "36 Train Loss 8.945654 Test MSE 1.67951602889961 Test RE 0.6194412701680585\n",
      "37 Train Loss 8.833055 Test MSE 1.6509431754849455 Test RE 0.614149528772526\n",
      "38 Train Loss 8.791109 Test MSE 1.698087613837325 Test RE 0.6228566525236698\n",
      "39 Train Loss 8.712783 Test MSE 1.7111631762357788 Test RE 0.6252501047517927\n",
      "40 Train Loss 8.553324 Test MSE 1.851291281856863 Test RE 0.6503474448052965\n",
      "41 Train Loss 8.451859 Test MSE 1.8594877864223465 Test RE 0.6517855460538886\n",
      "42 Train Loss 8.400728 Test MSE 1.8371148744740182 Test RE 0.6478526163997111\n",
      "43 Train Loss 8.25223 Test MSE 1.8076062052622883 Test RE 0.642628484954467\n",
      "44 Train Loss 8.184342 Test MSE 1.822489673639306 Test RE 0.6452686986293624\n",
      "45 Train Loss 8.062304 Test MSE 1.9020682696917508 Test RE 0.6592059378428845\n",
      "46 Train Loss 7.947264 Test MSE 1.8738765652607623 Test RE 0.6543024556585778\n",
      "47 Train Loss 7.863839 Test MSE 1.8721560741370178 Test RE 0.654002014289924\n",
      "48 Train Loss 7.7704167 Test MSE 1.867889458818741 Test RE 0.6532563588740455\n",
      "49 Train Loss 7.604357 Test MSE 1.9065728116281637 Test RE 0.6599860530593608\n",
      "50 Train Loss 7.4251785 Test MSE 2.0455630485814993 Test RE 0.6836195832985521\n",
      "51 Train Loss 7.314107 Test MSE 2.0922749776208427 Test RE 0.691381000707843\n",
      "52 Train Loss 7.2660036 Test MSE 2.1451756771412143 Test RE 0.700066816439046\n",
      "53 Train Loss 7.1822634 Test MSE 2.1358520780071717 Test RE 0.6985438059615796\n",
      "54 Train Loss 7.02141 Test MSE 2.1837237432016923 Test RE 0.7063287897775519\n",
      "55 Train Loss 6.806138 Test MSE 2.1478663911371 Test RE 0.7005057290400105\n",
      "56 Train Loss 6.7354646 Test MSE 2.1456254847118275 Test RE 0.7001402087611712\n",
      "57 Train Loss 6.634741 Test MSE 2.1549753464241537 Test RE 0.701664029708492\n",
      "58 Train Loss 6.5563765 Test MSE 2.1652938627780833 Test RE 0.7033418877898112\n",
      "59 Train Loss 6.4882092 Test MSE 2.1559508526538993 Test RE 0.7018228250722383\n",
      "60 Train Loss 6.330926 Test MSE 2.2261101004732464 Test RE 0.7131508108936572\n",
      "61 Train Loss 6.153489 Test MSE 2.2341765709516204 Test RE 0.7144417192212738\n",
      "62 Train Loss 6.1004095 Test MSE 2.215726900158443 Test RE 0.7114856995366857\n",
      "63 Train Loss 6.0340023 Test MSE 2.218160498078763 Test RE 0.7118763151284355\n",
      "64 Train Loss 5.932579 Test MSE 2.2466853587378512 Test RE 0.7164389485236218\n",
      "65 Train Loss 5.697175 Test MSE 2.209447092902698 Test RE 0.7104767386973135\n",
      "66 Train Loss 5.5363092 Test MSE 2.1433269782809923 Test RE 0.6997650948374711\n",
      "67 Train Loss 5.4421725 Test MSE 2.1573330377248627 Test RE 0.7020477591436093\n",
      "68 Train Loss 5.381904 Test MSE 2.1203824501359603 Test RE 0.6960094893456468\n",
      "69 Train Loss 5.213531 Test MSE 1.8324507306756483 Test RE 0.6470296961420057\n",
      "70 Train Loss 4.9628897 Test MSE 1.2809731100659703 Test RE 0.5409760853358471\n",
      "71 Train Loss 4.513059 Test MSE 0.8595634094306905 Test RE 0.4431461904409775\n",
      "72 Train Loss 2.6615024 Test MSE 0.20067161048046453 Test RE 0.21411694009150498\n",
      "73 Train Loss 1.2966985 Test MSE 0.11695225922091633 Test RE 0.16346032878523659\n",
      "74 Train Loss 1.0427841 Test MSE 0.07689823858515217 Test RE 0.13254588715851856\n",
      "75 Train Loss 0.9490567 Test MSE 0.0788895855998145 Test RE 0.1342511138596483\n",
      "76 Train Loss 0.852484 Test MSE 0.06613946554185395 Test RE 0.12292448596126798\n",
      "77 Train Loss 0.75931966 Test MSE 0.05290251085029233 Test RE 0.10993758757324085\n",
      "78 Train Loss 0.69296074 Test MSE 0.0500367510563097 Test RE 0.10691843953170707\n",
      "79 Train Loss 0.6715579 Test MSE 0.05336817237465078 Test RE 0.11042037697064434\n",
      "80 Train Loss 0.64955753 Test MSE 0.045588097036691755 Test RE 0.10205488373754429\n",
      "81 Train Loss 0.5962364 Test MSE 0.04933486846093133 Test RE 0.10616590044810258\n",
      "82 Train Loss 0.57583755 Test MSE 0.04987409832063074 Test RE 0.10674452004182604\n",
      "83 Train Loss 0.5030199 Test MSE 0.05061470204426078 Test RE 0.10753414900866563\n",
      "84 Train Loss 0.46887648 Test MSE 0.045730158988461514 Test RE 0.10221377212831198\n",
      "85 Train Loss 0.45445085 Test MSE 0.04680048594733451 Test RE 0.10340302441799275\n",
      "86 Train Loss 0.44589165 Test MSE 0.04524978082801799 Test RE 0.10167549613871948\n",
      "87 Train Loss 0.42118454 Test MSE 0.04289797559782172 Test RE 0.09899800873420864\n",
      "88 Train Loss 0.3751512 Test MSE 0.03969498874917234 Test RE 0.09523046432583032\n",
      "89 Train Loss 0.36316878 Test MSE 0.03851522713438957 Test RE 0.09380463371130597\n",
      "90 Train Loss 0.3435752 Test MSE 0.042478597836360946 Test RE 0.0985129097007964\n",
      "91 Train Loss 0.30843204 Test MSE 0.04199675101633409 Test RE 0.09795258621144048\n",
      "92 Train Loss 0.27294797 Test MSE 0.043387927327875796 Test RE 0.09956174786860268\n",
      "93 Train Loss 0.25949505 Test MSE 0.03891499880640931 Test RE 0.0942902030583882\n",
      "94 Train Loss 0.25367427 Test MSE 0.0363349706751235 Test RE 0.09111092740709403\n",
      "95 Train Loss 0.24024662 Test MSE 0.03647349258575879 Test RE 0.09128443592486704\n",
      "96 Train Loss 0.21954542 Test MSE 0.029623298274209484 Test RE 0.08226683059026668\n",
      "97 Train Loss 0.20678249 Test MSE 0.025976465219246934 Test RE 0.0770367738463147\n",
      "98 Train Loss 0.20203903 Test MSE 0.024093582217918994 Test RE 0.0741922851959841\n",
      "99 Train Loss 0.19166888 Test MSE 0.021271988225058002 Test RE 0.06971273190883492\n",
      "Training time: 80.96\n",
      "KG_stan_tune16\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 56.88012 Test MSE 8.857108423872022 Test RE 1.4225057836480484\n",
      "1 Train Loss 54.88465 Test MSE 8.671087829709087 Test RE 1.4074884928513987\n",
      "2 Train Loss 48.194855 Test MSE 8.13883874350987 Test RE 1.3636071889890076\n",
      "3 Train Loss 43.77214 Test MSE 8.220303069788839 Test RE 1.3704145944738815\n",
      "4 Train Loss 42.717293 Test MSE 8.14473044420165 Test RE 1.364100656930326\n",
      "5 Train Loss 41.976402 Test MSE 8.320576977461338 Test RE 1.3787476387838653\n",
      "6 Train Loss 41.619247 Test MSE 8.163628279768641 Test RE 1.3656822693741495\n",
      "7 Train Loss 41.157204 Test MSE 8.336163232964081 Test RE 1.3800383821306614\n",
      "8 Train Loss 40.67897 Test MSE 8.25473247744888 Test RE 1.3732814754998472\n",
      "9 Train Loss 39.367104 Test MSE 7.978945718678994 Test RE 1.3501462532268582\n",
      "10 Train Loss 38.992275 Test MSE 8.143447240474641 Test RE 1.3639931955472195\n",
      "11 Train Loss 38.37468 Test MSE 8.11597166444537 Test RE 1.3616902296146778\n",
      "12 Train Loss 37.286545 Test MSE 7.78706986282201 Test RE 1.3338134602303546\n",
      "13 Train Loss 35.572163 Test MSE 7.525685213048068 Test RE 1.3112366650337135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Train Loss 32.650963 Test MSE 6.231512233173065 Test RE 1.1931767611147657\n",
      "15 Train Loss 28.893599 Test MSE 5.14666600461476 Test RE 1.0843539179583108\n",
      "16 Train Loss 22.440304 Test MSE 3.0904569203925853 Test RE 0.8402710622818179\n",
      "17 Train Loss 17.102015 Test MSE 2.022266869719802 Test RE 0.6797156881759683\n",
      "18 Train Loss 13.068436 Test MSE 1.666418226562771 Test RE 0.617021168423231\n",
      "19 Train Loss 7.662684 Test MSE 0.2755205096244719 Test RE 0.25089096782398757\n",
      "20 Train Loss 3.42541 Test MSE 0.24094857265599676 Test RE 0.23462281397990706\n",
      "21 Train Loss 2.2339377 Test MSE 0.1532576934263675 Test RE 0.18711956654844278\n",
      "22 Train Loss 1.6823406 Test MSE 0.1009502640539993 Test RE 0.15186643210504577\n",
      "23 Train Loss 1.3211713 Test MSE 0.08293093043615389 Test RE 0.13764686650730895\n",
      "24 Train Loss 1.088443 Test MSE 0.07015119349065442 Test RE 0.12659763492564902\n",
      "25 Train Loss 0.93834835 Test MSE 0.05379647018923285 Test RE 0.11086257217477608\n",
      "26 Train Loss 0.78350246 Test MSE 0.048215201964383565 Test RE 0.10495425625817066\n",
      "27 Train Loss 0.66594917 Test MSE 0.034774717213696245 Test RE 0.0891332749602079\n",
      "28 Train Loss 0.5399729 Test MSE 0.03847101675416291 Test RE 0.09375078060427498\n",
      "29 Train Loss 0.47475654 Test MSE 0.026139782716715524 Test RE 0.07727856462915342\n",
      "30 Train Loss 0.40334815 Test MSE 0.027600707172510338 Test RE 0.07940871440567833\n",
      "31 Train Loss 0.33661634 Test MSE 0.022640556072720842 Test RE 0.07192031898521248\n",
      "32 Train Loss 0.26658082 Test MSE 0.023306308251116684 Test RE 0.07297007680383287\n",
      "33 Train Loss 0.21555017 Test MSE 0.01502655688904478 Test RE 0.05859192952225482\n",
      "34 Train Loss 0.19126195 Test MSE 0.011375894466871287 Test RE 0.05098011813644925\n",
      "35 Train Loss 0.15486926 Test MSE 0.01254221310611284 Test RE 0.05352974174187572\n",
      "36 Train Loss 0.12759763 Test MSE 0.007972560943577994 Test RE 0.04267828744695498\n",
      "37 Train Loss 0.11285962 Test MSE 0.009757628016682104 Test RE 0.047215021215940664\n",
      "38 Train Loss 0.10118308 Test MSE 0.008228564180117352 Test RE 0.043358084826959006\n",
      "39 Train Loss 0.094738886 Test MSE 0.006756665439888098 Test RE 0.03928929788225892\n",
      "40 Train Loss 0.08468518 Test MSE 0.007121691845908927 Test RE 0.04033663351064668\n",
      "41 Train Loss 0.08066769 Test MSE 0.006420150829800737 Test RE 0.038298403978524\n",
      "42 Train Loss 0.07123093 Test MSE 0.006175293995660411 Test RE 0.037560976941696654\n",
      "43 Train Loss 0.06972673 Test MSE 0.005954793584268021 Test RE 0.03688428899788681\n",
      "44 Train Loss 0.05629328 Test MSE 0.005125511927972653 Test RE 0.03421973835157909\n",
      "45 Train Loss 0.053548716 Test MSE 0.005129399123158449 Test RE 0.03423271204017816\n",
      "46 Train Loss 0.04874901 Test MSE 0.005565417722935357 Test RE 0.03565799696054189\n",
      "47 Train Loss 0.04645956 Test MSE 0.004885135960798228 Test RE 0.03340768545186408\n",
      "48 Train Loss 0.044428438 Test MSE 0.005089189378927177 Test RE 0.034098271651829055\n",
      "49 Train Loss 0.04292343 Test MSE 0.005009831565023825 Test RE 0.033831372942374864\n",
      "50 Train Loss 0.04005535 Test MSE 0.004474202433721686 Test RE 0.03197171074307789\n",
      "51 Train Loss 0.038955655 Test MSE 0.004134655163674864 Test RE 0.03073461006872909\n",
      "52 Train Loss 0.03812956 Test MSE 0.004180654901825502 Test RE 0.03090510475938285\n",
      "53 Train Loss 0.03681042 Test MSE 0.003521193439380318 Test RE 0.028363054684142984\n",
      "54 Train Loss 0.034982428 Test MSE 0.0034558838699673654 Test RE 0.028098790764607768\n",
      "55 Train Loss 0.034559127 Test MSE 0.0034781090958702393 Test RE 0.028188999398452673\n",
      "56 Train Loss 0.033235632 Test MSE 0.0032130116105526635 Test RE 0.027093443599831027\n",
      "57 Train Loss 0.032774575 Test MSE 0.003198925419315508 Test RE 0.027033988066345847\n",
      "58 Train Loss 0.03211543 Test MSE 0.003268970490273744 Test RE 0.027328359388267026\n",
      "59 Train Loss 0.03102367 Test MSE 0.0033217934815623954 Test RE 0.027548272772132846\n",
      "60 Train Loss 0.02955772 Test MSE 0.0032820696863369585 Test RE 0.02738305881698427\n",
      "61 Train Loss 0.029070675 Test MSE 0.003203523136610501 Test RE 0.027053408651237534\n",
      "62 Train Loss 0.02814286 Test MSE 0.0030877014181915543 Test RE 0.02655985556160592\n",
      "63 Train Loss 0.024616165 Test MSE 0.0025867976221580296 Test RE 0.024310242262836443\n",
      "64 Train Loss 0.02352883 Test MSE 0.002476017898323845 Test RE 0.023784002954498812\n",
      "65 Train Loss 0.023217563 Test MSE 0.0023552721429029623 Test RE 0.023196828305638965\n",
      "66 Train Loss 0.022712989 Test MSE 0.002305366506469596 Test RE 0.02294975480449442\n",
      "67 Train Loss 0.020805124 Test MSE 0.002136720101312791 Test RE 0.02209438300038599\n",
      "68 Train Loss 0.019659905 Test MSE 0.002109332158756901 Test RE 0.021952326189136284\n",
      "69 Train Loss 0.019031547 Test MSE 0.0018588519667880733 Test RE 0.020607744580657845\n",
      "70 Train Loss 0.018784732 Test MSE 0.0017650092399578254 Test RE 0.020080825025257817\n",
      "71 Train Loss 0.018374791 Test MSE 0.0015979540888656617 Test RE 0.01910689904613021\n",
      "72 Train Loss 0.018237213 Test MSE 0.0015947000962271245 Test RE 0.019087434972227955\n",
      "73 Train Loss 0.018059246 Test MSE 0.0016791575031298688 Test RE 0.0195863620222907\n",
      "74 Train Loss 0.017853217 Test MSE 0.0016685665489060996 Test RE 0.019524495761147103\n",
      "75 Train Loss 0.017334262 Test MSE 0.0017418253240312014 Test RE 0.019948505300389895\n",
      "76 Train Loss 0.01691478 Test MSE 0.0018066128287759064 Test RE 0.020316112319400777\n",
      "77 Train Loss 0.016800443 Test MSE 0.0018261412939045258 Test RE 0.020425620040101237\n",
      "78 Train Loss 0.016158706 Test MSE 0.001745692166591614 Test RE 0.019970635810369945\n",
      "79 Train Loss 0.01578833 Test MSE 0.0018363360375374597 Test RE 0.02048255543267088\n",
      "80 Train Loss 0.015169108 Test MSE 0.0018223120333488406 Test RE 0.020404193421310068\n",
      "81 Train Loss 0.014463242 Test MSE 0.0018174948221342012 Test RE 0.02037720672778845\n",
      "82 Train Loss 0.014339331 Test MSE 0.001781629814148635 Test RE 0.020175151104282245\n",
      "83 Train Loss 0.014257342 Test MSE 0.00181990363269875 Test RE 0.020390705687292923\n",
      "84 Train Loss 0.013898085 Test MSE 0.0016249280920829987 Test RE 0.01926748962205537\n",
      "85 Train Loss 0.012884489 Test MSE 0.0013566865349875215 Test RE 0.017605477865455816\n",
      "86 Train Loss 0.012346776 Test MSE 0.001299582755104567 Test RE 0.017230982056766507\n",
      "87 Train Loss 0.011960561 Test MSE 0.001168999788309693 Test RE 0.016342378940994003\n",
      "88 Train Loss 0.011849344 Test MSE 0.0011111273978835611 Test RE 0.01593272236784767\n",
      "89 Train Loss 0.011756198 Test MSE 0.001027908990258374 Test RE 0.015324467503097993\n",
      "90 Train Loss 0.011475565 Test MSE 0.0009831999099816865 Test RE 0.014987492381258015\n",
      "91 Train Loss 0.011280792 Test MSE 0.0009114821725769749 Test RE 0.014430525603219018\n",
      "92 Train Loss 0.011053276 Test MSE 0.0008554071714095908 Test RE 0.013979592231504252\n",
      "93 Train Loss 0.010708054 Test MSE 0.0008072083514057195 Test RE 0.013580034820514503\n",
      "94 Train Loss 0.010228125 Test MSE 0.0008128404266663302 Test RE 0.013627327957573116\n",
      "95 Train Loss 0.009927338 Test MSE 0.0009410954925475539 Test RE 0.014663069969350125\n",
      "96 Train Loss 0.0096919555 Test MSE 0.0009638041896879647 Test RE 0.014838925868489639\n",
      "97 Train Loss 0.009536289 Test MSE 0.0009783680499394925 Test RE 0.014950619586294123\n",
      "98 Train Loss 0.00946181 Test MSE 0.0009635374787369847 Test RE 0.014836872558330083\n",
      "99 Train Loss 0.009313786 Test MSE 0.0009348579108162983 Test RE 0.014614395761928366\n",
      "Training time: 79.93\n",
      "KG_stan_tune16\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 56.553772 Test MSE 8.616690826529416 Test RE 1.4030666940505088\n",
      "1 Train Loss 55.28233 Test MSE 8.97976459757485 Test RE 1.432321583216869\n",
      "2 Train Loss 46.86612 Test MSE 8.58905417527951 Test RE 1.4008148314941093\n",
      "3 Train Loss 44.35663 Test MSE 8.598410736918652 Test RE 1.4015776187863225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 43.767612 Test MSE 8.593651386526727 Test RE 1.4011896678894464\n",
      "5 Train Loss 43.552456 Test MSE 8.469764144804259 Test RE 1.391053132885877\n",
      "6 Train Loss 43.45212 Test MSE 8.516386885752214 Test RE 1.3948764804783533\n",
      "7 Train Loss 43.384987 Test MSE 8.475801894511605 Test RE 1.3915488571020218\n",
      "8 Train Loss 43.37257 Test MSE 8.462720863129768 Test RE 1.3904746270039419\n",
      "9 Train Loss 43.1859 Test MSE 8.546077401369308 Test RE 1.397305830479328\n",
      "10 Train Loss 43.02613 Test MSE 8.40806243005947 Test RE 1.3859770025854121\n",
      "11 Train Loss 42.871902 Test MSE 8.47921964937009 Test RE 1.3918293906478294\n",
      "12 Train Loss 42.715836 Test MSE 8.360197627619668 Test RE 1.3820263778816697\n",
      "13 Train Loss 42.676323 Test MSE 8.378563635018578 Test RE 1.3835435897283945\n",
      "14 Train Loss 42.6098 Test MSE 8.333471122275094 Test RE 1.3798155268448615\n",
      "15 Train Loss 42.424183 Test MSE 8.340286747390428 Test RE 1.3803796605145195\n",
      "16 Train Loss 42.33089 Test MSE 8.385286015368434 Test RE 1.3840985083178385\n",
      "17 Train Loss 42.2333 Test MSE 8.331017635222135 Test RE 1.3796123936791282\n",
      "18 Train Loss 42.139755 Test MSE 8.335276759301339 Test RE 1.3799650030370472\n",
      "19 Train Loss 42.04036 Test MSE 8.386795542571134 Test RE 1.3842230860795968\n",
      "20 Train Loss 41.86474 Test MSE 8.128561201206983 Test RE 1.3627459507881277\n",
      "21 Train Loss 41.20549 Test MSE 7.9097993425037405 Test RE 1.3442832691221434\n",
      "22 Train Loss 40.31997 Test MSE 7.725440739801524 Test RE 1.3285248828712906\n",
      "23 Train Loss 40.12729 Test MSE 8.023522984813807 Test RE 1.3539125403091814\n",
      "24 Train Loss 39.965282 Test MSE 7.977950376525765 Test RE 1.3500620378781711\n",
      "25 Train Loss 39.89119 Test MSE 8.037296501418233 Test RE 1.3550741335836218\n",
      "26 Train Loss 39.829086 Test MSE 7.996080660639798 Test RE 1.3515952084697251\n",
      "27 Train Loss 39.74209 Test MSE 8.008116307523263 Test RE 1.3526120319977173\n",
      "28 Train Loss 39.629166 Test MSE 7.97319207516568 Test RE 1.3496593680267086\n",
      "29 Train Loss 39.561035 Test MSE 8.067081259762796 Test RE 1.357582640797846\n",
      "30 Train Loss 39.455795 Test MSE 8.02191009651438 Test RE 1.3537764517448327\n",
      "31 Train Loss 39.368164 Test MSE 7.964822222945608 Test RE 1.348950780078611\n",
      "32 Train Loss 39.27956 Test MSE 7.999583411311967 Test RE 1.351891214904894\n",
      "33 Train Loss 39.1394 Test MSE 7.895500632831933 Test RE 1.3430676750220996\n",
      "34 Train Loss 38.84993 Test MSE 7.95607467025908 Test RE 1.348209818172504\n",
      "35 Train Loss 38.667393 Test MSE 8.013480695675682 Test RE 1.3530649925290095\n",
      "36 Train Loss 38.569405 Test MSE 7.984977280446645 Test RE 1.3506564680098292\n",
      "37 Train Loss 38.375217 Test MSE 8.053253150426452 Test RE 1.35641859817254\n",
      "38 Train Loss 37.978817 Test MSE 8.228577733157229 Test RE 1.371104159512206\n",
      "39 Train Loss 37.64074 Test MSE 8.215157386474946 Test RE 1.3699856064339573\n",
      "40 Train Loss 37.5272 Test MSE 8.256570964104096 Test RE 1.3734343949985144\n",
      "41 Train Loss 37.450172 Test MSE 8.308827686921568 Test RE 1.3777738463810751\n",
      "42 Train Loss 37.412666 Test MSE 8.39952655607275 Test RE 1.3852733012715537\n",
      "43 Train Loss 37.29624 Test MSE 8.38531183996252 Test RE 1.38410063965567\n",
      "44 Train Loss 37.043907 Test MSE 8.345688299386318 Test RE 1.3808265867344391\n",
      "45 Train Loss 36.88498 Test MSE 8.259794863245233 Test RE 1.373702507623225\n",
      "46 Train Loss 36.840042 Test MSE 8.187038796539259 Test RE 1.3676390243028744\n",
      "47 Train Loss 36.77251 Test MSE 8.194914774005378 Test RE 1.368296704392747\n",
      "48 Train Loss 36.709984 Test MSE 8.135179182151099 Test RE 1.3633005871867245\n",
      "49 Train Loss 36.64444 Test MSE 8.170016100173976 Test RE 1.3662164697881127\n",
      "50 Train Loss 36.560688 Test MSE 8.164369707962415 Test RE 1.36574428422308\n",
      "51 Train Loss 36.430305 Test MSE 8.128523723164435 Test RE 1.3627428092044982\n",
      "52 Train Loss 35.9253 Test MSE 8.12952125723245 Test RE 1.3628264246752193\n",
      "53 Train Loss 35.0482 Test MSE 8.18409473886529 Test RE 1.3673931008191953\n",
      "54 Train Loss 34.64286 Test MSE 8.1136693285322 Test RE 1.361497074018639\n",
      "55 Train Loss 33.67646 Test MSE 8.20865375844966 Test RE 1.3694432162844996\n",
      "56 Train Loss 33.301422 Test MSE 8.232105875038014 Test RE 1.3713980700603865\n",
      "57 Train Loss 33.13536 Test MSE 8.139158671973224 Test RE 1.3636339896468925\n",
      "58 Train Loss 32.812763 Test MSE 8.142518635670282 Test RE 1.3639154246286296\n",
      "59 Train Loss 32.648632 Test MSE 8.008969086543006 Test RE 1.352684049461736\n",
      "60 Train Loss 32.41769 Test MSE 7.816980873946651 Test RE 1.3363726687885777\n",
      "61 Train Loss 32.35741 Test MSE 7.699632566124226 Test RE 1.3263039426525833\n",
      "62 Train Loss 32.254898 Test MSE 7.806252274504541 Test RE 1.3354552858432402\n",
      "63 Train Loss 32.073524 Test MSE 7.698724905544133 Test RE 1.326225765591809\n",
      "64 Train Loss 31.995472 Test MSE 7.68098615419657 Test RE 1.3246969958001555\n",
      "65 Train Loss 31.844063 Test MSE 7.721980687613448 Test RE 1.328227341255534\n",
      "66 Train Loss 31.478443 Test MSE 7.561463816726228 Test RE 1.314349909071672\n",
      "67 Train Loss 31.324017 Test MSE 7.498652363467331 Test RE 1.3088795140605658\n",
      "68 Train Loss 31.213009 Test MSE 7.457974264471648 Test RE 1.3053245330371404\n",
      "69 Train Loss 31.162598 Test MSE 7.454664389676866 Test RE 1.305034847119561\n",
      "70 Train Loss 31.047714 Test MSE 7.33129776225802 Test RE 1.2941913407532393\n",
      "71 Train Loss 30.96066 Test MSE 7.299766299006411 Test RE 1.2914052228963195\n",
      "72 Train Loss 30.87886 Test MSE 7.322423867291002 Test RE 1.2934078508614297\n",
      "73 Train Loss 30.826248 Test MSE 7.391599963729107 Test RE 1.299503003503661\n",
      "74 Train Loss 30.697708 Test MSE 7.433111339312099 Test RE 1.3031469122360297\n",
      "75 Train Loss 30.622963 Test MSE 7.373205693491629 Test RE 1.2978850656281924\n",
      "76 Train Loss 30.49023 Test MSE 7.4438867643959465 Test RE 1.304091124960746\n",
      "77 Train Loss 30.419739 Test MSE 7.437923207580164 Test RE 1.3035686438969034\n",
      "78 Train Loss 30.303253 Test MSE 7.441097048275471 Test RE 1.3038467375145923\n",
      "79 Train Loss 30.241852 Test MSE 7.4604721220290005 Test RE 1.3055431072553694\n",
      "80 Train Loss 30.189598 Test MSE 7.467202905984187 Test RE 1.306131900255525\n",
      "81 Train Loss 30.158762 Test MSE 7.480016806918051 Test RE 1.3072520968685815\n",
      "82 Train Loss 30.06708 Test MSE 7.483671627348735 Test RE 1.307571426912837\n",
      "83 Train Loss 29.889872 Test MSE 7.60063570377522 Test RE 1.31774998211391\n",
      "84 Train Loss 29.751926 Test MSE 7.684162591437436 Test RE 1.3249708787264398\n",
      "85 Train Loss 29.479504 Test MSE 7.680278833693488 Test RE 1.3246360005777473\n",
      "86 Train Loss 29.392097 Test MSE 7.538168228503301 Test RE 1.3123237026355723\n",
      "87 Train Loss 29.28875 Test MSE 7.4938689791212765 Test RE 1.3084619808662603\n",
      "88 Train Loss 29.091383 Test MSE 7.547334664219388 Test RE 1.3131213550486174\n",
      "89 Train Loss 28.876339 Test MSE 7.448013691149871 Test RE 1.3044525720779525\n",
      "90 Train Loss 28.66158 Test MSE 7.434463442974455 Test RE 1.3032654298736495\n",
      "91 Train Loss 28.546793 Test MSE 7.360840843635761 Test RE 1.2967963337752264\n",
      "92 Train Loss 28.519972 Test MSE 7.335440834389829 Test RE 1.294556976615406\n",
      "93 Train Loss 28.475576 Test MSE 7.225902709723075 Test RE 1.2848549890926213\n",
      "94 Train Loss 28.369837 Test MSE 7.2362374003545 Test RE 1.2857734787882429\n",
      "95 Train Loss 28.256695 Test MSE 7.219283468647685 Test RE 1.2842663627411701\n",
      "96 Train Loss 28.19585 Test MSE 7.323878503564083 Test RE 1.293536315464125\n",
      "97 Train Loss 28.173132 Test MSE 7.321322034238479 Test RE 1.2933105351937544\n",
      "98 Train Loss 28.12104 Test MSE 7.293413756363804 Test RE 1.2908431848813329\n",
      "99 Train Loss 28.06672 Test MSE 7.2008497515903755 Test RE 1.2826256920045727\n",
      "Training time: 85.07\n",
      "KG_stan_tune17\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 53.078156 Test MSE 9.66475090398727 Test RE 1.4859472509621288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Train Loss 43.84366 Test MSE 9.555012142850844 Test RE 1.477487046271077\n",
      "2 Train Loss 43.385277 Test MSE 9.366733236833571 Test RE 1.462857882332818\n",
      "3 Train Loss 43.18078 Test MSE 9.372815288749601 Test RE 1.4633327401909677\n",
      "4 Train Loss 42.861443 Test MSE 9.361985085270943 Test RE 1.4624870619394341\n",
      "5 Train Loss 42.442627 Test MSE 9.161280632014513 Test RE 1.446725557575703\n",
      "6 Train Loss 41.952793 Test MSE 8.979156362548261 Test RE 1.4322730739881728\n",
      "7 Train Loss 40.795853 Test MSE 8.709713433859624 Test RE 1.410619858038761\n",
      "8 Train Loss 40.000824 Test MSE 9.255625262788062 Test RE 1.4541558061276274\n",
      "9 Train Loss 39.323288 Test MSE 9.083539598587057 Test RE 1.4405741491479365\n",
      "10 Train Loss 38.938545 Test MSE 9.092450110327677 Test RE 1.44128054263792\n",
      "11 Train Loss 38.515312 Test MSE 8.97551683195804 Test RE 1.4319827722164655\n",
      "12 Train Loss 38.16513 Test MSE 8.723464931994998 Test RE 1.411733010942897\n",
      "13 Train Loss 37.881634 Test MSE 8.538484344233511 Test RE 1.3966849502659924\n",
      "14 Train Loss 37.675724 Test MSE 8.592480953821832 Test RE 1.401094245467477\n",
      "15 Train Loss 37.617805 Test MSE 8.622879640518661 Test RE 1.4035704698242544\n",
      "16 Train Loss 37.53306 Test MSE 8.46272994312149 Test RE 1.390475372951665\n",
      "17 Train Loss 37.32045 Test MSE 8.404022173449203 Test RE 1.3856439665471254\n",
      "18 Train Loss 37.27217 Test MSE 8.399058416621434 Test RE 1.3852346973029255\n",
      "19 Train Loss 37.02557 Test MSE 8.800634223961136 Test RE 1.4179634805213024\n",
      "20 Train Loss 36.883587 Test MSE 8.924552384131536 Test RE 1.4279114687913836\n",
      "21 Train Loss 36.78306 Test MSE 8.891497526207326 Test RE 1.425264658382986\n",
      "22 Train Loss 36.65588 Test MSE 8.84895718877171 Test RE 1.4218510638726631\n",
      "23 Train Loss 36.502113 Test MSE 8.939698107099137 Test RE 1.4291225986479557\n",
      "24 Train Loss 36.186745 Test MSE 9.000378543510033 Test RE 1.4339646593757132\n",
      "25 Train Loss 36.01307 Test MSE 8.924865035409162 Test RE 1.4279364803782912\n",
      "26 Train Loss 35.735733 Test MSE 8.83155273455042 Test RE 1.4204521011866924\n",
      "27 Train Loss 35.166283 Test MSE 8.5403247928295 Test RE 1.3968354681008572\n",
      "28 Train Loss 34.57206 Test MSE 8.720455214733404 Test RE 1.411489456128835\n",
      "29 Train Loss 34.07502 Test MSE 8.672304636216108 Test RE 1.407587245228905\n",
      "30 Train Loss 33.47712 Test MSE 8.37523058735904 Test RE 1.3832683709899132\n",
      "31 Train Loss 32.935513 Test MSE 8.017791634342935 Test RE 1.353428891572965\n",
      "32 Train Loss 32.183075 Test MSE 8.105421706464176 Test RE 1.3608049107115794\n",
      "33 Train Loss 30.530907 Test MSE 7.7177191522146895 Test RE 1.327860785755476\n",
      "34 Train Loss 28.807737 Test MSE 6.885888685160122 Test RE 1.2542614061816402\n",
      "35 Train Loss 27.619354 Test MSE 6.871654318094526 Test RE 1.2529643438651559\n",
      "36 Train Loss 26.960514 Test MSE 7.188587716657198 Test RE 1.2815331610697114\n",
      "37 Train Loss 26.438831 Test MSE 7.19128134292828 Test RE 1.2817732393865948\n",
      "38 Train Loss 25.38475 Test MSE 7.483747499288813 Test RE 1.3075780551920049\n",
      "39 Train Loss 24.770638 Test MSE 7.279443443923209 Test RE 1.2896063068476116\n",
      "40 Train Loss 24.202608 Test MSE 7.187496381020107 Test RE 1.2814358793817482\n",
      "41 Train Loss 23.726265 Test MSE 7.009367067675675 Test RE 1.2654572030185494\n",
      "42 Train Loss 23.25458 Test MSE 7.4498770835595405 Test RE 1.3046157400787697\n",
      "43 Train Loss 22.881735 Test MSE 7.356905871750817 Test RE 1.29644966554952\n",
      "44 Train Loss 22.76618 Test MSE 7.347537767456318 Test RE 1.2956239689367568\n",
      "45 Train Loss 22.531332 Test MSE 7.531272942134777 Test RE 1.3117233632896663\n",
      "46 Train Loss 22.390259 Test MSE 7.35048557873038 Test RE 1.2958838432015582\n",
      "47 Train Loss 21.842888 Test MSE 5.357448494913362 Test RE 1.1063360459941627\n",
      "48 Train Loss 16.342464 Test MSE 4.001254991576234 Test RE 0.956106288729707\n",
      "49 Train Loss 13.000906 Test MSE 3.6044811698511836 Test RE 0.9074640745105711\n",
      "50 Train Loss 11.290572 Test MSE 3.46834130613249 Test RE 0.8901618433065711\n",
      "51 Train Loss 10.964769 Test MSE 3.439817124576209 Test RE 0.8864938711057803\n",
      "52 Train Loss 10.734554 Test MSE 3.4339232032920894 Test RE 0.8857340683350697\n",
      "53 Train Loss 10.664272 Test MSE 3.464791899373176 Test RE 0.8897062429277343\n",
      "54 Train Loss 10.574387 Test MSE 3.424835908311219 Test RE 0.8845613195046536\n",
      "55 Train Loss 10.496454 Test MSE 3.405764012778361 Test RE 0.8820949512576273\n",
      "56 Train Loss 10.387506 Test MSE 3.4010162274677245 Test RE 0.8814798971878217\n",
      "57 Train Loss 10.334762 Test MSE 3.4008530600267775 Test RE 0.8814587519573118\n",
      "58 Train Loss 10.241628 Test MSE 3.361805581300505 Test RE 0.8763838327082065\n",
      "59 Train Loss 10.059578 Test MSE 3.3998850166677594 Test RE 0.8813332906382925\n",
      "60 Train Loss 10.042663 Test MSE 3.3921844208219776 Test RE 0.8803346335145179\n",
      "61 Train Loss 10.005416 Test MSE 3.4188718591831253 Test RE 0.8837907912161286\n",
      "62 Train Loss 9.989614 Test MSE 3.407399091665839 Test RE 0.8823066690629792\n",
      "63 Train Loss 9.980724 Test MSE 3.4296778957638527 Test RE 0.8851863891677708\n",
      "64 Train Loss 9.945812 Test MSE 3.440280925903968 Test RE 0.8865536334653933\n",
      "65 Train Loss 9.925862 Test MSE 3.443751668737691 Test RE 0.8870007225354881\n",
      "66 Train Loss 9.854575 Test MSE 3.4711963777769035 Test RE 0.8905281499651695\n",
      "67 Train Loss 9.77298 Test MSE 3.4398587352840035 Test RE 0.8864992329498175\n",
      "68 Train Loss 9.748128 Test MSE 3.4414719678502133 Test RE 0.88670708476955\n",
      "69 Train Loss 9.734737 Test MSE 3.4349834139121835 Test RE 0.8858707912811393\n",
      "70 Train Loss 9.730284 Test MSE 3.441667156992096 Test RE 0.8867322299897628\n",
      "71 Train Loss 9.71749 Test MSE 3.4511309687736453 Test RE 0.8879505502867865\n",
      "72 Train Loss 9.707986 Test MSE 3.4526329648943253 Test RE 0.8881437555306575\n",
      "73 Train Loss 9.684609 Test MSE 3.447540970213952 Test RE 0.8874885900396197\n",
      "74 Train Loss 9.649469 Test MSE 3.4763079626842783 Test RE 0.8911835919509143\n",
      "75 Train Loss 9.620748 Test MSE 3.452318597031867 Test RE 0.8881033211415114\n",
      "76 Train Loss 9.60307 Test MSE 3.447176603474738 Test RE 0.8874416899634385\n",
      "77 Train Loss 9.587032 Test MSE 3.4570642809876606 Test RE 0.8887135212364122\n",
      "78 Train Loss 9.576232 Test MSE 3.4562819096703685 Test RE 0.8886129527692163\n",
      "79 Train Loss 9.564023 Test MSE 3.4718407690042192 Test RE 0.8906108047382353\n",
      "80 Train Loss 9.508387 Test MSE 3.471679660032102 Test RE 0.8905901403320188\n",
      "81 Train Loss 9.486808 Test MSE 3.4616849381141805 Test RE 0.8893072430907313\n",
      "82 Train Loss 9.468826 Test MSE 3.4557742159402283 Test RE 0.8885476861322964\n",
      "83 Train Loss 9.43164 Test MSE 3.4751595185050492 Test RE 0.8910363726649166\n",
      "84 Train Loss 9.404825 Test MSE 3.466360433879912 Test RE 0.8899076081290442\n",
      "85 Train Loss 9.386461 Test MSE 3.484044340281049 Test RE 0.8921746867040711\n",
      "86 Train Loss 9.375029 Test MSE 3.487004207015198 Test RE 0.8925535793503087\n",
      "87 Train Loss 9.367073 Test MSE 3.4994198224982744 Test RE 0.8941411534947464\n",
      "88 Train Loss 9.355599 Test MSE 3.4840791258483854 Test RE 0.8921791405402085\n",
      "89 Train Loss 9.288019 Test MSE 3.4822157754154626 Test RE 0.8919405316189611\n",
      "90 Train Loss 9.232176 Test MSE 3.48553049552609 Test RE 0.8923649495990896\n",
      "91 Train Loss 9.193356 Test MSE 3.4680246274620434 Test RE 0.8901212040385349\n",
      "92 Train Loss 9.184395 Test MSE 3.471513028628233 Test RE 0.8905687670947628\n",
      "93 Train Loss 9.14901 Test MSE 3.4763993027799596 Test RE 0.8911952998117739\n",
      "94 Train Loss 9.124796 Test MSE 3.474445370814247 Test RE 0.8909448136645925\n",
      "95 Train Loss 9.106751 Test MSE 3.482927502776698 Test RE 0.8920316784759751\n",
      "96 Train Loss 9.095749 Test MSE 3.4889495982203638 Test RE 0.8928025213746494\n",
      "97 Train Loss 9.082718 Test MSE 3.5010245166771403 Test RE 0.8943461387103573\n",
      "98 Train Loss 9.015449 Test MSE 3.4749316586373493 Test RE 0.891007160371622\n",
      "99 Train Loss 8.977304 Test MSE 3.4563771020025595 Test RE 0.8886251896988381\n",
      "Training time: 82.78\n",
      "KG_stan_tune17\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.360886 Test MSE 8.7493204779619 Test RE 1.413823586279348\n",
      "1 Train Loss 56.412186 Test MSE 9.034385620706274 Test RE 1.4366711549980022\n",
      "2 Train Loss 54.366882 Test MSE 9.255469901747231 Test RE 1.4541436016519054\n",
      "3 Train Loss 51.152008 Test MSE 9.522910113486637 Test RE 1.475002997224977\n",
      "4 Train Loss 45.80995 Test MSE 8.948566277197045 Test RE 1.4298312669176954\n",
      "5 Train Loss 45.11017 Test MSE 8.59065660224491 Test RE 1.4009454977308713\n",
      "6 Train Loss 44.454 Test MSE 8.440749116510123 Test RE 1.3886684105138913\n",
      "7 Train Loss 44.245247 Test MSE 8.29217062055245 Test RE 1.3763921121064526\n",
      "8 Train Loss 43.977493 Test MSE 8.282269110026686 Test RE 1.3755701058805414\n",
      "9 Train Loss 43.630028 Test MSE 8.311576277379329 Test RE 1.3780017138407539\n",
      "10 Train Loss 43.24573 Test MSE 8.281669586489102 Test RE 1.3755203187044867\n",
      "11 Train Loss 42.783005 Test MSE 8.46481916846847 Test RE 1.3906469982511926\n",
      "12 Train Loss 41.96254 Test MSE 8.514752585007233 Test RE 1.3947426351588077\n",
      "13 Train Loss 40.4169 Test MSE 8.396598184159027 Test RE 1.3850318025971353\n",
      "14 Train Loss 39.13871 Test MSE 7.956041972540168 Test RE 1.3482070477465846\n",
      "15 Train Loss 38.67446 Test MSE 8.099067400894285 Test RE 1.3602713995683202\n",
      "16 Train Loss 38.284855 Test MSE 8.082199346660786 Test RE 1.3588541319924798\n",
      "17 Train Loss 38.05115 Test MSE 7.920840305469606 Test RE 1.3452211567575794\n",
      "18 Train Loss 37.980766 Test MSE 7.928202337146727 Test RE 1.345846170028743\n",
      "19 Train Loss 37.70456 Test MSE 7.943862493276981 Test RE 1.347174703463275\n",
      "20 Train Loss 37.32735 Test MSE 8.000678463174788 Test RE 1.3519837409939666\n",
      "21 Train Loss 36.844994 Test MSE 7.838981169284047 Test RE 1.3382519068535137\n",
      "22 Train Loss 36.558502 Test MSE 7.74890311950024 Test RE 1.3305407371021005\n",
      "23 Train Loss 35.91697 Test MSE 7.741558798099902 Test RE 1.329910052011268\n",
      "24 Train Loss 34.605194 Test MSE 8.255458742684082 Test RE 1.3733418859771096\n",
      "25 Train Loss 33.79316 Test MSE 8.49638723531459 Test RE 1.393237672859\n",
      "26 Train Loss 33.275436 Test MSE 8.306582363839778 Test RE 1.3775876735201995\n",
      "27 Train Loss 32.880196 Test MSE 8.462598857514905 Test RE 1.3904646038490953\n",
      "28 Train Loss 32.57996 Test MSE 8.298125506003098 Test RE 1.3768862400473838\n",
      "29 Train Loss 32.369205 Test MSE 8.315830557637783 Test RE 1.378354333808108\n",
      "30 Train Loss 32.078102 Test MSE 8.145265010901475 Test RE 1.3641454215070523\n",
      "31 Train Loss 31.766808 Test MSE 8.221010103121342 Test RE 1.3704735283085452\n",
      "32 Train Loss 31.63327 Test MSE 8.04404038225261 Test RE 1.3556425176367497\n",
      "33 Train Loss 31.51393 Test MSE 8.038854373048874 Test RE 1.3552054544366092\n",
      "34 Train Loss 31.2292 Test MSE 8.135933915538642 Test RE 1.3633638251673525\n",
      "35 Train Loss 30.614359 Test MSE 8.034909348567032 Test RE 1.3548728837413444\n",
      "36 Train Loss 29.828014 Test MSE 8.078987687777204 Test RE 1.3585841182625298\n",
      "37 Train Loss 29.589622 Test MSE 8.04670283268637 Test RE 1.3558668472167315\n",
      "38 Train Loss 29.245647 Test MSE 7.8298581050272436 Test RE 1.3374729464145367\n",
      "39 Train Loss 28.878023 Test MSE 7.486628671468952 Test RE 1.3078297335781912\n",
      "40 Train Loss 28.586718 Test MSE 7.589508430534754 Test RE 1.3167850408093673\n",
      "41 Train Loss 28.022022 Test MSE 7.446905419017856 Test RE 1.3043555165221292\n",
      "42 Train Loss 27.555431 Test MSE 7.315676271082063 Test RE 1.292811777377814\n",
      "43 Train Loss 26.690687 Test MSE 7.454708240030937 Test RE 1.3050386853980518\n",
      "44 Train Loss 26.242287 Test MSE 7.6541075598338235 Test RE 1.3223771636376718\n",
      "45 Train Loss 25.923447 Test MSE 7.491520436502869 Test RE 1.3082569319431256\n",
      "46 Train Loss 25.535572 Test MSE 7.522568082942899 Test RE 1.3109650805537778\n",
      "47 Train Loss 25.134455 Test MSE 7.512497295442199 Test RE 1.310087263813885\n",
      "48 Train Loss 24.607304 Test MSE 7.906656272420464 Test RE 1.3440161576468448\n",
      "49 Train Loss 24.262676 Test MSE 7.871351818067579 Test RE 1.3410121796263763\n",
      "50 Train Loss 23.691223 Test MSE 8.28717385210949 Test RE 1.375977350436931\n",
      "51 Train Loss 23.302677 Test MSE 8.22636718091062 Test RE 1.37091997817107\n",
      "52 Train Loss 22.733017 Test MSE 8.233525633702866 Test RE 1.3715163247560587\n",
      "53 Train Loss 22.056604 Test MSE 8.056200274413515 Test RE 1.3566667691942729\n",
      "54 Train Loss 21.846397 Test MSE 8.084063896918055 Test RE 1.3590108656736375\n",
      "55 Train Loss 21.588566 Test MSE 7.7982150980938325 Test RE 1.3347676284715035\n",
      "56 Train Loss 21.069506 Test MSE 7.865648713637792 Test RE 1.3405262835256815\n",
      "57 Train Loss 20.191635 Test MSE 7.668872672517247 Test RE 1.3236520112001777\n",
      "58 Train Loss 19.93481 Test MSE 7.779113263745271 Test RE 1.333131860383777\n",
      "59 Train Loss 19.651031 Test MSE 7.774579767012473 Test RE 1.332743343754292\n",
      "60 Train Loss 19.407352 Test MSE 7.823192425786852 Test RE 1.3369035195011407\n",
      "61 Train Loss 19.223701 Test MSE 7.833867550091248 Test RE 1.33781534329507\n",
      "62 Train Loss 18.922634 Test MSE 7.658367364227112 Test RE 1.3227450892560821\n",
      "63 Train Loss 18.717281 Test MSE 7.358733225964482 Test RE 1.2966106656837773\n",
      "64 Train Loss 18.499285 Test MSE 7.506580848329479 Test RE 1.3095712843474194\n",
      "65 Train Loss 18.197672 Test MSE 7.078850677724689 Test RE 1.2717139519712544\n",
      "66 Train Loss 17.799482 Test MSE 6.79222113065703 Test RE 1.2457014459524844\n",
      "67 Train Loss 17.271324 Test MSE 6.394476961411252 Test RE 1.2086778789223087\n",
      "68 Train Loss 16.810268 Test MSE 6.197393294491361 Test RE 1.1899058213886289\n",
      "69 Train Loss 16.507769 Test MSE 6.07395209495262 Test RE 1.1779957984131315\n",
      "70 Train Loss 16.155193 Test MSE 6.088496686616478 Test RE 1.1794053603408414\n",
      "71 Train Loss 15.874313 Test MSE 6.1376734562319255 Test RE 1.1841588080412753\n",
      "72 Train Loss 15.261985 Test MSE 5.960701268132089 Test RE 1.1669620657161182\n",
      "73 Train Loss 14.992237 Test MSE 5.995706113692042 Test RE 1.1703836035110973\n",
      "74 Train Loss 14.803659 Test MSE 5.94511478587801 Test RE 1.165435337680465\n",
      "75 Train Loss 11.897905 Test MSE 4.16778941126868 Test RE 0.9758002920472761\n",
      "76 Train Loss 10.751636 Test MSE 3.99935343396683 Test RE 0.9558790716126463\n",
      "77 Train Loss 10.236305 Test MSE 3.8084959476809193 Test RE 0.9327919923728443\n",
      "78 Train Loss 9.82809 Test MSE 3.6127011443659414 Test RE 0.9084982155322948\n",
      "79 Train Loss 9.610283 Test MSE 3.4901113879970507 Test RE 0.8929511567272689\n",
      "80 Train Loss 9.451312 Test MSE 3.4915992912896643 Test RE 0.8931414777863942\n",
      "81 Train Loss 9.321638 Test MSE 3.365880874561937 Test RE 0.8769148627332489\n",
      "82 Train Loss 9.254318 Test MSE 3.3829429929941113 Test RE 0.8791346549005177\n",
      "83 Train Loss 9.198967 Test MSE 3.362496996310384 Test RE 0.8764739500230048\n",
      "84 Train Loss 9.124963 Test MSE 3.3501633457800803 Test RE 0.8748650185466559\n",
      "85 Train Loss 8.985593 Test MSE 3.3173439397246303 Test RE 0.8705692255512555\n",
      "86 Train Loss 8.761456 Test MSE 3.3149416406848613 Test RE 0.870253951281731\n",
      "87 Train Loss 8.65784 Test MSE 3.3110589307813765 Test RE 0.8697441483953032\n",
      "88 Train Loss 8.53691 Test MSE 3.3362213350049306 Test RE 0.8730427052958162\n",
      "89 Train Loss 8.492472 Test MSE 3.382346146513894 Test RE 0.8790570994154143\n",
      "90 Train Loss 8.435599 Test MSE 3.4107390087408636 Test RE 0.8827389796415522\n",
      "91 Train Loss 8.398296 Test MSE 3.3976198686884747 Test RE 0.8810396508627177\n",
      "92 Train Loss 8.343139 Test MSE 3.3756911786874793 Test RE 0.8781918749678504\n",
      "93 Train Loss 8.277489 Test MSE 3.3727655076076557 Test RE 0.8778112332900468\n",
      "94 Train Loss 8.236205 Test MSE 3.4018467512403925 Test RE 0.8815875187444947\n",
      "95 Train Loss 8.187714 Test MSE 3.410510552301071 Test RE 0.8827094155527804\n",
      "96 Train Loss 8.13976 Test MSE 3.4103998830461637 Test RE 0.8826950937108857\n",
      "97 Train Loss 8.087379 Test MSE 3.3811132160407347 Test RE 0.8788968681699183\n",
      "98 Train Loss 8.037605 Test MSE 3.3609554727075532 Test RE 0.8762730189633713\n",
      "99 Train Loss 7.96749 Test MSE 3.389067247969825 Test RE 0.8799300585283286\n",
      "Training time: 82.14\n",
      "KG_stan_tune17\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.748165 Test MSE 8.696351348107212 Test RE 1.4095373850920654\n",
      "1 Train Loss 50.902042 Test MSE 8.03074353345427 Test RE 1.3545216114710175\n",
      "2 Train Loss 45.595253 Test MSE 8.433086481615371 Test RE 1.3880379406971015\n",
      "3 Train Loss 42.911514 Test MSE 8.03150291669275 Test RE 1.3545856514125731\n",
      "4 Train Loss 40.691185 Test MSE 7.193450397847859 Test RE 1.2819665308741603\n",
      "5 Train Loss 33.358437 Test MSE 7.201855425434639 Test RE 1.2827152549117962\n",
      "6 Train Loss 31.92109 Test MSE 6.73876912126071 Test RE 1.2407901833627935\n",
      "7 Train Loss 29.423965 Test MSE 6.380795008496999 Test RE 1.20738411171522\n",
      "8 Train Loss 27.60875 Test MSE 6.557524177300856 Test RE 1.2239903970680845\n",
      "9 Train Loss 25.135958 Test MSE 6.216074085849136 Test RE 1.191697837465755\n",
      "10 Train Loss 24.25985 Test MSE 6.035693623373813 Test RE 1.1742799712806558\n",
      "11 Train Loss 23.564234 Test MSE 5.913492404007494 Test RE 1.1623316987871601\n",
      "12 Train Loss 23.072563 Test MSE 6.032496607321543 Test RE 1.1739689308751302\n",
      "13 Train Loss 22.809155 Test MSE 6.003025794800646 Test RE 1.171097799766125\n",
      "14 Train Loss 22.555676 Test MSE 5.951672134029901 Test RE 1.1660778870174922\n",
      "15 Train Loss 22.235193 Test MSE 5.655829564852379 Test RE 1.1367271086510045\n",
      "16 Train Loss 21.666826 Test MSE 5.769390802361269 Test RE 1.1480823468714147\n",
      "17 Train Loss 20.685587 Test MSE 5.926701681480088 Test RE 1.1636291552160487\n",
      "18 Train Loss 19.749733 Test MSE 5.783136961319501 Test RE 1.149449244501584\n",
      "19 Train Loss 18.160023 Test MSE 3.7100984618533057 Test RE 0.9206631868038694\n",
      "20 Train Loss 13.299766 Test MSE 1.8983322837734802 Test RE 0.6585582232836256\n",
      "21 Train Loss 11.166199 Test MSE 2.0396592106518234 Test RE 0.6826323500850917\n",
      "22 Train Loss 9.91042 Test MSE 1.9696145956232236 Test RE 0.6708087010935783\n",
      "23 Train Loss 9.134207 Test MSE 2.0834952932868576 Test RE 0.6899288760336844\n",
      "24 Train Loss 8.316115 Test MSE 2.009708764443069 Test RE 0.6776019131662424\n",
      "25 Train Loss 7.8900447 Test MSE 2.0507243048113613 Test RE 0.6844814763141441\n",
      "26 Train Loss 7.4987955 Test MSE 2.04862003427258 Test RE 0.6841302092333109\n",
      "27 Train Loss 7.0146337 Test MSE 1.9403739540998217 Test RE 0.6658107125948881\n",
      "28 Train Loss 6.241902 Test MSE 2.118113502496895 Test RE 0.6956370018781374\n",
      "29 Train Loss 5.7948923 Test MSE 2.0708716484044305 Test RE 0.6878356028701431\n",
      "30 Train Loss 5.3316255 Test MSE 2.1027260520943543 Test RE 0.6931056004069868\n",
      "31 Train Loss 5.093128 Test MSE 2.109323216927181 Test RE 0.6941920355606522\n",
      "32 Train Loss 4.903115 Test MSE 2.127804697971248 Test RE 0.697226591018972\n",
      "33 Train Loss 4.783759 Test MSE 2.120425305824348 Test RE 0.6960165229388255\n",
      "34 Train Loss 4.677128 Test MSE 2.136170682492713 Test RE 0.6985959048154896\n",
      "35 Train Loss 4.6035223 Test MSE 2.1530101099671746 Test RE 0.7013440143870558\n",
      "36 Train Loss 4.5353136 Test MSE 2.136896532966332 Test RE 0.698714582855811\n",
      "37 Train Loss 4.4656863 Test MSE 2.1633071155870462 Test RE 0.7030191410195854\n",
      "38 Train Loss 4.4004726 Test MSE 2.164194101601014 Test RE 0.7031632500636367\n",
      "39 Train Loss 4.351773 Test MSE 2.1709850147126444 Test RE 0.7042655958503049\n",
      "40 Train Loss 4.325849 Test MSE 2.161744415401326 Test RE 0.7027651764748871\n",
      "41 Train Loss 4.281713 Test MSE 2.1662316742566774 Test RE 0.7034941836750022\n",
      "42 Train Loss 4.251112 Test MSE 2.150204443500034 Test RE 0.7008868918566713\n",
      "43 Train Loss 4.206876 Test MSE 2.1620196185978497 Test RE 0.7028099081893847\n",
      "44 Train Loss 4.172832 Test MSE 2.1568536809010985 Test RE 0.7019697577237161\n",
      "45 Train Loss 4.1459637 Test MSE 2.1442926228376353 Test RE 0.6999227115402232\n",
      "46 Train Loss 4.125053 Test MSE 2.136546320145167 Test RE 0.6986573248584939\n",
      "47 Train Loss 4.079317 Test MSE 2.109388653795808 Test RE 0.6942028033273862\n",
      "48 Train Loss 3.9964082 Test MSE 2.105542015686712 Test RE 0.6935695474637149\n",
      "49 Train Loss 3.8027983 Test MSE 2.007193272122578 Test RE 0.6771777133662978\n",
      "50 Train Loss 3.0878272 Test MSE 1.5450002405334866 Test RE 0.5941174877714348\n",
      "51 Train Loss 2.560708 Test MSE 1.1634996493579783 Test RE 0.5155742143437133\n",
      "52 Train Loss 1.3864053 Test MSE 0.5926434354749058 Test RE 0.3679635493588156\n",
      "53 Train Loss 0.9737278 Test MSE 0.3800101636063879 Test RE 0.29464947146346177\n",
      "54 Train Loss 0.6316047 Test MSE 0.09559142904744825 Test RE 0.14778063806488087\n",
      "55 Train Loss 0.4481348 Test MSE 0.07232403721773496 Test RE 0.1285432839377841\n",
      "56 Train Loss 0.305634 Test MSE 0.05947405229442861 Test RE 0.11656598166781033\n",
      "57 Train Loss 0.23244806 Test MSE 0.04654900216920793 Test RE 0.10312483060806242\n",
      "58 Train Loss 0.18951991 Test MSE 0.04176517520720587 Test RE 0.09768215093635516\n",
      "59 Train Loss 0.15706766 Test MSE 0.04965284039239991 Test RE 0.10650747992679942\n",
      "60 Train Loss 0.14476538 Test MSE 0.044974236772934176 Test RE 0.10136545199450249\n",
      "61 Train Loss 0.119416244 Test MSE 0.037047884129707234 Test RE 0.09200041049652649\n",
      "62 Train Loss 0.10043752 Test MSE 0.03112368386611292 Test RE 0.08432445791357161\n",
      "63 Train Loss 0.08910573 Test MSE 0.023067751361215593 Test RE 0.07259566554032826\n",
      "64 Train Loss 0.083605364 Test MSE 0.02086026648152226 Test RE 0.06903478653825793\n",
      "65 Train Loss 0.07687658 Test MSE 0.017578456497940834 Test RE 0.06337214825704235\n",
      "66 Train Loss 0.07187682 Test MSE 0.01535630738013059 Test RE 0.0592313264592937\n",
      "67 Train Loss 0.06704472 Test MSE 0.015048074137843414 Test RE 0.05863386481487579\n",
      "68 Train Loss 0.061187778 Test MSE 0.013271519382591157 Test RE 0.05506407944280822\n",
      "69 Train Loss 0.05579249 Test MSE 0.00875931481588266 Test RE 0.044734555668225574\n",
      "70 Train Loss 0.047998592 Test MSE 0.008694845959161422 Test RE 0.044569627708824784\n",
      "71 Train Loss 0.044119198 Test MSE 0.006724295179031708 Test RE 0.039195070059877476\n",
      "72 Train Loss 0.04209474 Test MSE 0.006650212261339229 Test RE 0.03897856207989691\n",
      "73 Train Loss 0.039302163 Test MSE 0.006881840518896534 Test RE 0.039651567665168135\n",
      "74 Train Loss 0.035621963 Test MSE 0.007191194485633552 Test RE 0.040532984019416504\n",
      "75 Train Loss 0.03354508 Test MSE 0.006460707117096063 Test RE 0.03841917963203801\n",
      "76 Train Loss 0.031741586 Test MSE 0.005582023620606019 Test RE 0.035711154876031374\n",
      "77 Train Loss 0.03041753 Test MSE 0.005194025472833733 Test RE 0.03444768949710803\n",
      "78 Train Loss 0.027749186 Test MSE 0.005104909327876674 Test RE 0.034150893961459226\n",
      "79 Train Loss 0.026591705 Test MSE 0.004401094964269247 Test RE 0.03170942961665857\n",
      "80 Train Loss 0.025518827 Test MSE 0.004297636695941075 Test RE 0.03133451015907948\n",
      "81 Train Loss 0.024530716 Test MSE 0.0036868533938883333 Test RE 0.029022578496310295\n",
      "82 Train Loss 0.02182392 Test MSE 0.003379932465175352 Test RE 0.02778830593687932\n",
      "83 Train Loss 0.019753482 Test MSE 0.003873183071777823 Test RE 0.02974692461100536\n",
      "84 Train Loss 0.018594218 Test MSE 0.00381444863013248 Test RE 0.02952051607770088\n",
      "85 Train Loss 0.018106692 Test MSE 0.0035942952059151334 Test RE 0.028655958007620316\n",
      "86 Train Loss 0.017192097 Test MSE 0.003405037005087249 Test RE 0.027891314213967563\n",
      "87 Train Loss 0.016432142 Test MSE 0.0028452603298539246 Test RE 0.02549582471328971\n",
      "88 Train Loss 0.015568331 Test MSE 0.002619333006192594 Test RE 0.024462645288642178\n",
      "89 Train Loss 0.0145579185 Test MSE 0.0026324156930933587 Test RE 0.02452366053637087\n",
      "90 Train Loss 0.014199856 Test MSE 0.0026883889563684774 Test RE 0.024783013395710655\n",
      "91 Train Loss 0.013720735 Test MSE 0.0025044857784989427 Test RE 0.023920339828705117\n",
      "92 Train Loss 0.01327975 Test MSE 0.0024842895377236965 Test RE 0.023823697470354045\n",
      "93 Train Loss 0.012930181 Test MSE 0.0024911589624779466 Test RE 0.02385661274013598\n",
      "94 Train Loss 0.0122181345 Test MSE 0.0022182248275054335 Test RE 0.022511832109869328\n",
      "95 Train Loss 0.011524788 Test MSE 0.001952982275677476 Test RE 0.02112307841213792\n",
      "96 Train Loss 0.0108149415 Test MSE 0.002103260997280071 Test RE 0.021920711406487433\n",
      "97 Train Loss 0.010187244 Test MSE 0.002057010051482918 Test RE 0.021678352169155937\n",
      "98 Train Loss 0.009729929 Test MSE 0.002031903749413987 Test RE 0.02154565126519437\n",
      "99 Train Loss 0.009427607 Test MSE 0.001981958402187651 Test RE 0.021279201538931758\n",
      "Training time: 78.12\n",
      "KG_stan_tune17\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.924145 Test MSE 7.537107462855791 Test RE 1.3122313647601018\n",
      "1 Train Loss 50.8804 Test MSE 9.18447826500062 Test RE 1.4485560544074212\n",
      "2 Train Loss 45.226124 Test MSE 8.801460436731777 Test RE 1.418030038908519\n",
      "3 Train Loss 43.794815 Test MSE 8.468209042503265 Test RE 1.3909254239440716\n",
      "4 Train Loss 42.697983 Test MSE 8.416492537361133 Test RE 1.3866716339449958\n",
      "5 Train Loss 42.582314 Test MSE 8.227032945389983 Test RE 1.3709754517075456\n",
      "6 Train Loss 42.278267 Test MSE 8.152241698485515 Test RE 1.364729514187423\n",
      "7 Train Loss 41.85695 Test MSE 8.273228248163479 Test RE 1.3748191199579585\n",
      "8 Train Loss 40.15271 Test MSE 7.879018646355686 Test RE 1.3416651048181059\n",
      "9 Train Loss 35.22445 Test MSE 7.0362666969601415 Test RE 1.2678830806297203\n",
      "10 Train Loss 32.750397 Test MSE 7.035474308227731 Test RE 1.267811687332906\n",
      "11 Train Loss 31.77024 Test MSE 7.094588676321381 Test RE 1.2731268310903372\n",
      "12 Train Loss 30.88441 Test MSE 6.885029780675535 Test RE 1.2541831792169253\n",
      "13 Train Loss 30.309052 Test MSE 7.182304561304436 Test RE 1.2809729792580982\n",
      "14 Train Loss 29.486557 Test MSE 6.878355930126537 Test RE 1.2535751745514485\n",
      "15 Train Loss 28.564022 Test MSE 6.802188016604513 Test RE 1.2466150802866836\n",
      "16 Train Loss 27.781057 Test MSE 6.648965690589267 Test RE 1.2324948301564218\n",
      "17 Train Loss 26.922544 Test MSE 6.564241316883286 Test RE 1.224617128265768\n",
      "18 Train Loss 25.081654 Test MSE 6.474251134023794 Test RE 1.2161939286501544\n",
      "19 Train Loss 23.38979 Test MSE 6.2848306727619905 Test RE 1.1982704539488653\n",
      "20 Train Loss 22.317118 Test MSE 6.175766286928113 Test RE 1.1878278031581395\n",
      "21 Train Loss 21.001472 Test MSE 5.998078925093794 Test RE 1.170615171303114\n",
      "22 Train Loss 20.019304 Test MSE 6.158086895875027 Test RE 1.1861263849002286\n",
      "23 Train Loss 18.98499 Test MSE 6.021201126761077 Test RE 1.1728693234233571\n",
      "24 Train Loss 17.905836 Test MSE 5.72021236274539 Test RE 1.1431787327462086\n",
      "25 Train Loss 16.718454 Test MSE 5.468459279581615 Test RE 1.1177393783370666\n",
      "26 Train Loss 15.624211 Test MSE 4.859621021974456 Test RE 1.0536812727245728\n",
      "27 Train Loss 13.980983 Test MSE 4.946152671060388 Test RE 1.0630209385516236\n",
      "28 Train Loss 11.790194 Test MSE 3.8459304236241305 Test RE 0.9373650828475497\n",
      "29 Train Loss 9.985349 Test MSE 3.840041529511121 Test RE 0.9366471605499678\n",
      "30 Train Loss 8.032728 Test MSE 3.267747413874571 Test RE 0.8640369199247837\n",
      "31 Train Loss 7.1699977 Test MSE 3.16993532548227 Test RE 0.8510072521570248\n",
      "32 Train Loss 6.8372874 Test MSE 3.0512162449668967 Test RE 0.8349194036647708\n",
      "33 Train Loss 6.04366 Test MSE 3.2157939253397307 Test RE 0.8571407949919158\n",
      "34 Train Loss 5.3814135 Test MSE 2.9150494593396954 Test RE 0.8160767860343193\n",
      "35 Train Loss 4.4289007 Test MSE 2.442886034259354 Test RE 0.7470671905561441\n",
      "36 Train Loss 4.0211635 Test MSE 2.290657187685742 Test RE 0.7234159996789037\n",
      "37 Train Loss 3.7284033 Test MSE 2.0909046254679167 Test RE 0.6911545508777855\n",
      "38 Train Loss 3.440619 Test MSE 1.8808665072079502 Test RE 0.6555216605801127\n",
      "39 Train Loss 3.2521646 Test MSE 1.8671629775278396 Test RE 0.6531293104894988\n",
      "40 Train Loss 3.0171318 Test MSE 1.872217628121569 Test RE 0.6540127655567524\n",
      "41 Train Loss 2.8883078 Test MSE 1.876970157143792 Test RE 0.654842328474822\n",
      "42 Train Loss 2.612436 Test MSE 1.8633271689404214 Test RE 0.6524580870740415\n",
      "43 Train Loss 2.31695 Test MSE 1.873832016224279 Test RE 0.6542946780072232\n",
      "44 Train Loss 2.2410507 Test MSE 1.78925029137949 Test RE 0.6393572711351168\n",
      "45 Train Loss 2.0964055 Test MSE 1.8466021041236615 Test RE 0.6495232826830458\n",
      "46 Train Loss 2.0280714 Test MSE 1.8505618537602684 Test RE 0.6502193103403199\n",
      "47 Train Loss 1.8163263 Test MSE 1.8701667970244165 Test RE 0.6536544639346251\n",
      "48 Train Loss 1.6897149 Test MSE 1.8249515750726804 Test RE 0.6457043806074243\n",
      "49 Train Loss 1.5940688 Test MSE 1.8452758594531138 Test RE 0.6492899943323412\n",
      "50 Train Loss 1.5543058 Test MSE 1.8232986576341932 Test RE 0.6454118967338788\n",
      "51 Train Loss 1.4659696 Test MSE 1.7632467522227604 Test RE 0.6346943124309709\n",
      "52 Train Loss 1.3587923 Test MSE 1.777430174826393 Test RE 0.6372419158689594\n",
      "53 Train Loss 1.321541 Test MSE 1.7787390432001517 Test RE 0.6374764995703567\n",
      "54 Train Loss 1.282269 Test MSE 1.8144679969338824 Test RE 0.6438470595341652\n",
      "55 Train Loss 1.233965 Test MSE 1.8828130643245053 Test RE 0.6558607809736425\n",
      "56 Train Loss 1.186759 Test MSE 1.886427074468947 Test RE 0.6564899329656434\n",
      "57 Train Loss 1.1447483 Test MSE 1.8584810060309025 Test RE 0.6516090744045153\n",
      "58 Train Loss 1.1145649 Test MSE 1.8838278451786328 Test RE 0.656037501998591\n",
      "59 Train Loss 1.069759 Test MSE 1.8812068604826075 Test RE 0.6555809680457526\n",
      "60 Train Loss 1.02877 Test MSE 1.8783803499775489 Test RE 0.6550882781958752\n",
      "61 Train Loss 1.0054622 Test MSE 1.9066913878140648 Test RE 0.6600065761182464\n",
      "62 Train Loss 0.99484926 Test MSE 1.9063951416029807 Test RE 0.659955300897711\n",
      "63 Train Loss 0.96498334 Test MSE 1.910548314209887 Test RE 0.6606737818258624\n",
      "64 Train Loss 0.9251658 Test MSE 1.8819854781801673 Test RE 0.6557166240833721\n",
      "65 Train Loss 0.88740635 Test MSE 1.902275299246361 Test RE 0.6592418123171202\n",
      "66 Train Loss 0.87074614 Test MSE 1.8958740949270758 Test RE 0.6581316949812817\n",
      "67 Train Loss 0.8508731 Test MSE 1.915954879540747 Test RE 0.6616079253037864\n",
      "68 Train Loss 0.82856256 Test MSE 1.90948354682881 Test RE 0.6604896561677079\n",
      "69 Train Loss 0.81054074 Test MSE 1.901997881958306 Test RE 0.6591937404780859\n",
      "70 Train Loss 0.8025588 Test MSE 1.9000208904862979 Test RE 0.6588510589107116\n",
      "71 Train Loss 0.78457355 Test MSE 1.9188251629677033 Test RE 0.6621033157730394\n",
      "72 Train Loss 0.77612686 Test MSE 1.9330249497482337 Test RE 0.664548665243434\n",
      "73 Train Loss 0.7643386 Test MSE 1.9713872468941118 Test RE 0.6711104968027596\n",
      "74 Train Loss 0.7489847 Test MSE 1.9618860384717671 Test RE 0.6694913166825148\n",
      "75 Train Loss 0.7380386 Test MSE 1.9545713163945921 Test RE 0.668242081000356\n",
      "76 Train Loss 0.73313785 Test MSE 1.956891610615963 Test RE 0.6686386023089963\n",
      "77 Train Loss 0.71429574 Test MSE 1.962395816009797 Test RE 0.6695782915273802\n",
      "78 Train Loss 0.68965626 Test MSE 1.9561769417380146 Test RE 0.6685164956900201\n",
      "79 Train Loss 0.6773926 Test MSE 1.9703748069900524 Test RE 0.670938144489065\n",
      "80 Train Loss 0.66494364 Test MSE 1.9695687774226833 Test RE 0.6708008986975139\n",
      "81 Train Loss 0.65742576 Test MSE 1.9756000340943358 Test RE 0.6718271842255787\n",
      "82 Train Loss 0.64856875 Test MSE 2.001601523342875 Test RE 0.6762337961512649\n",
      "83 Train Loss 0.64330053 Test MSE 1.996885949024108 Test RE 0.6754367566198916\n",
      "84 Train Loss 0.6357355 Test MSE 1.9899387714564059 Test RE 0.6742608087886192\n",
      "85 Train Loss 0.6295164 Test MSE 2.0060232857639693 Test RE 0.6769803222661789\n",
      "86 Train Loss 0.6253877 Test MSE 1.9965801710438018 Test RE 0.6753850406982932\n",
      "87 Train Loss 0.6181939 Test MSE 2.0074782466106305 Test RE 0.6772257833568038\n",
      "88 Train Loss 0.60594267 Test MSE 1.9931336933608939 Test RE 0.6748018673088638\n",
      "89 Train Loss 0.5983663 Test MSE 2.0078951100730955 Test RE 0.6772960944625639\n",
      "90 Train Loss 0.594316 Test MSE 2.0130445071001497 Test RE 0.6781640265684739\n",
      "91 Train Loss 0.5897569 Test MSE 2.0166676843696383 Test RE 0.6787740488170687\n",
      "92 Train Loss 0.5874674 Test MSE 2.025327613675287 Test RE 0.6802298757726711\n",
      "93 Train Loss 0.57726574 Test MSE 2.019230233259031 Test RE 0.6792051658262267\n",
      "94 Train Loss 0.5607001 Test MSE 2.0473930951870134 Test RE 0.6839253123280484\n",
      "95 Train Loss 0.5464462 Test MSE 2.067859276864603 Test RE 0.6873351444150073\n",
      "96 Train Loss 0.54079527 Test MSE 2.051030134146936 Test RE 0.6845325135770682\n",
      "97 Train Loss 0.53747606 Test MSE 2.0457637754030964 Test RE 0.6836531235553778\n",
      "98 Train Loss 0.53162724 Test MSE 2.0567678663842606 Test RE 0.6854893306277704\n",
      "99 Train Loss 0.52454 Test MSE 2.068267657648518 Test RE 0.6874030118494685\n",
      "Training time: 80.25\n",
      "KG_stan_tune17\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.902428 Test MSE 8.555018432635162 Test RE 1.3980365803050758\n",
      "1 Train Loss 55.006294 Test MSE 8.669609339273629 Test RE 1.4073684936639743\n",
      "2 Train Loss 46.482292 Test MSE 8.056361668596782 Test RE 1.3566803585429184\n",
      "3 Train Loss 45.233734 Test MSE 8.243461950481562 Test RE 1.372343656339212\n",
      "4 Train Loss 44.32514 Test MSE 8.20746265399351 Test RE 1.369343857172698\n",
      "5 Train Loss 44.167076 Test MSE 8.171186087615046 Test RE 1.3663142908247663\n",
      "6 Train Loss 44.028427 Test MSE 8.246076898598128 Test RE 1.3725613029381927\n",
      "7 Train Loss 43.69231 Test MSE 8.376930608539586 Test RE 1.3834087531671115\n",
      "8 Train Loss 43.614178 Test MSE 8.326811121918592 Test RE 1.3792640514424703\n",
      "9 Train Loss 43.223724 Test MSE 8.31343321016678 Test RE 1.378155638533994\n",
      "10 Train Loss 43.048424 Test MSE 8.396352855510466 Test RE 1.3850115687801254\n",
      "11 Train Loss 41.343887 Test MSE 8.517483543257944 Test RE 1.3949662869033397\n",
      "12 Train Loss 40.698948 Test MSE 8.762732642599254 Test RE 1.4149068231582123\n",
      "13 Train Loss 40.107582 Test MSE 8.775542102203277 Test RE 1.4159406087268447\n",
      "14 Train Loss 39.864967 Test MSE 8.64277406106284 Test RE 1.4051886725027614\n",
      "15 Train Loss 39.506817 Test MSE 8.734939554900453 Test RE 1.412661184587127\n",
      "16 Train Loss 38.87109 Test MSE 8.589667870417168 Test RE 1.4008648752985702\n",
      "17 Train Loss 37.601433 Test MSE 8.189385128290127 Test RE 1.3678349867910313\n",
      "18 Train Loss 35.09755 Test MSE 7.904472314704145 Test RE 1.3438305243602295\n",
      "19 Train Loss 31.120836 Test MSE 6.78611260038627 Test RE 1.245141164088952\n",
      "20 Train Loss 26.713102 Test MSE 4.975373843655171 Test RE 1.0661564033121802\n",
      "21 Train Loss 22.188349 Test MSE 4.38871812112688 Test RE 1.0013292536934257\n",
      "22 Train Loss 18.187696 Test MSE 4.330719661110643 Test RE 0.9946907884609537\n",
      "23 Train Loss 16.082485 Test MSE 4.090288746480478 Test RE 0.9666851429403284\n",
      "24 Train Loss 14.785246 Test MSE 4.118682512824193 Test RE 0.9700345840663982\n",
      "25 Train Loss 14.080568 Test MSE 4.305569119843981 Test RE 0.9917982623976305\n",
      "26 Train Loss 13.414731 Test MSE 4.4108865927846725 Test RE 1.0038550456627566\n",
      "27 Train Loss 12.997111 Test MSE 4.593823267284723 Test RE 1.0244604617894344\n",
      "28 Train Loss 12.528879 Test MSE 4.772665008326018 Test RE 1.0442116555210366\n",
      "29 Train Loss 11.837432 Test MSE 4.769175684789715 Test RE 1.043829871077058\n",
      "30 Train Loss 11.294395 Test MSE 4.452638282289247 Test RE 1.0085949010025324\n",
      "31 Train Loss 10.338057 Test MSE 4.109376913159574 Test RE 0.9689381341799707\n",
      "32 Train Loss 8.916826 Test MSE 4.249618936373 Test RE 0.9853330600920737\n",
      "33 Train Loss 7.851861 Test MSE 3.6224311704878245 Test RE 0.9097208142273834\n",
      "34 Train Loss 7.0887356 Test MSE 3.1988177231518966 Test RE 0.8548753746417124\n",
      "35 Train Loss 6.502266 Test MSE 2.7794765275292272 Test RE 0.7968738322303087\n",
      "36 Train Loss 5.862851 Test MSE 2.870030160347065 Test RE 0.8097506225933649\n",
      "37 Train Loss 4.9672675 Test MSE 2.6359304987470242 Test RE 0.7760237944809798\n",
      "38 Train Loss 4.434183 Test MSE 2.11631457259332 Test RE 0.69534153423146\n",
      "39 Train Loss 4.0165615 Test MSE 1.4765311951271072 Test RE 0.5808036991289459\n",
      "40 Train Loss 3.5343719 Test MSE 1.118931231185466 Test RE 0.5056031351023755\n",
      "41 Train Loss 2.9163394 Test MSE 0.7729177997834871 Test RE 0.4202180612577709\n",
      "42 Train Loss 2.5890963 Test MSE 0.6593343252279206 Test RE 0.388115424849714\n",
      "43 Train Loss 2.2200596 Test MSE 0.47137582425641683 Test RE 0.3281645863739843\n",
      "44 Train Loss 1.5281872 Test MSE 0.25465506418170364 Test RE 0.24120384072726342\n",
      "45 Train Loss 1.2122972 Test MSE 0.1929776103480042 Test RE 0.20997206644997365\n",
      "46 Train Loss 1.0795544 Test MSE 0.14170688325226902 Test RE 0.17992998068772312\n",
      "47 Train Loss 0.8990582 Test MSE 0.09872640826936419 Test RE 0.15018436719342113\n",
      "48 Train Loss 0.8034309 Test MSE 0.09381564271198278 Test RE 0.1464015549241434\n",
      "49 Train Loss 0.65854055 Test MSE 0.07189942536039569 Test RE 0.12816539194324916\n",
      "50 Train Loss 0.5728283 Test MSE 0.06527082664038426 Test RE 0.12211460718288812\n",
      "51 Train Loss 0.48168692 Test MSE 0.07315458213270497 Test RE 0.1292792509862602\n",
      "52 Train Loss 0.43738464 Test MSE 0.0674444902585673 Test RE 0.12413129854738361\n",
      "53 Train Loss 0.39014107 Test MSE 0.05561940007390841 Test RE 0.11272525082974542\n",
      "54 Train Loss 0.3632905 Test MSE 0.051543858585464224 Test RE 0.10851668633792118\n",
      "55 Train Loss 0.3481707 Test MSE 0.04256198336777137 Test RE 0.09860955276816531\n",
      "56 Train Loss 0.33086708 Test MSE 0.038202877714253326 Test RE 0.09342349265491531\n",
      "57 Train Loss 0.31017342 Test MSE 0.03387186406321325 Test RE 0.08796858558221089\n",
      "58 Train Loss 0.28533491 Test MSE 0.031185582260597488 Test RE 0.08440826797951989\n",
      "59 Train Loss 0.25370693 Test MSE 0.026328239621507363 Test RE 0.07755663740322172\n",
      "60 Train Loss 0.23930247 Test MSE 0.021014746272142896 Test RE 0.06928993208769274\n",
      "61 Train Loss 0.2243756 Test MSE 0.018507491787770537 Test RE 0.06502522190649702\n",
      "62 Train Loss 0.20586763 Test MSE 0.02102219549358672 Test RE 0.0693022118056619\n",
      "63 Train Loss 0.19751129 Test MSE 0.021087037809124163 Test RE 0.06940900978588345\n",
      "64 Train Loss 0.17872 Test MSE 0.025868023302731406 Test RE 0.07687580598006823\n",
      "65 Train Loss 0.16811906 Test MSE 0.02662936541603605 Test RE 0.07799889836747002\n",
      "66 Train Loss 0.16202925 Test MSE 0.025489209808512943 Test RE 0.07631084214503304\n",
      "67 Train Loss 0.15304282 Test MSE 0.02446627510933831 Test RE 0.07476390684505628\n",
      "68 Train Loss 0.14068761 Test MSE 0.023198363223341414 Test RE 0.0728008973155585\n",
      "69 Train Loss 0.13431059 Test MSE 0.023347629891178688 Test RE 0.07303473543418722\n",
      "70 Train Loss 0.13011223 Test MSE 0.0209986962889101 Test RE 0.0692634669889338\n",
      "71 Train Loss 0.1256894 Test MSE 0.020410123539571688 Test RE 0.06828587472795784\n",
      "72 Train Loss 0.121675596 Test MSE 0.020294295236924626 Test RE 0.0680918364483696\n",
      "73 Train Loss 0.11790486 Test MSE 0.020438741511096738 Test RE 0.06833373133879733\n",
      "74 Train Loss 0.11323485 Test MSE 0.018446634808645213 Test RE 0.06491822477637556\n",
      "75 Train Loss 0.10364556 Test MSE 0.01827664948066711 Test RE 0.06461842251401759\n",
      "76 Train Loss 0.101804435 Test MSE 0.01688395147167296 Test RE 0.062107651568040836\n",
      "77 Train Loss 0.095160276 Test MSE 0.017054246847130954 Test RE 0.06242008168554805\n",
      "78 Train Loss 0.081041455 Test MSE 0.011220654761066989 Test RE 0.05063107638863156\n",
      "79 Train Loss 0.07208815 Test MSE 0.008485465074426187 Test RE 0.04402971612469729\n",
      "80 Train Loss 0.06951798 Test MSE 0.008670873501584485 Test RE 0.04450814410234515\n",
      "81 Train Loss 0.0663118 Test MSE 0.007606459097783467 Test RE 0.04168687378753415\n",
      "82 Train Loss 0.06484959 Test MSE 0.007658289442034073 Test RE 0.041828659658218054\n",
      "83 Train Loss 0.06318803 Test MSE 0.0077978880601218895 Test RE 0.04220817344895497\n",
      "84 Train Loss 0.05979707 Test MSE 0.0064710913637087706 Test RE 0.03845004266671715\n",
      "85 Train Loss 0.05694835 Test MSE 0.00618922690940161 Test RE 0.037603326260907136\n",
      "86 Train Loss 0.05452642 Test MSE 0.006152853975743753 Test RE 0.03749266957219007\n",
      "87 Train Loss 0.052418444 Test MSE 0.0062638230215439 Test RE 0.037829255967787044\n",
      "88 Train Loss 0.05005383 Test MSE 0.006413602682721408 Test RE 0.03827886802311755\n",
      "89 Train Loss 0.04788415 Test MSE 0.005600369129929211 Test RE 0.03576978969805646\n",
      "90 Train Loss 0.045879696 Test MSE 0.00516204173490611 Test RE 0.03434146483254226\n",
      "91 Train Loss 0.044497013 Test MSE 0.005203935716558221 Test RE 0.034480537074989576\n",
      "92 Train Loss 0.043924738 Test MSE 0.0049060112748265374 Test RE 0.033478988736410434\n",
      "93 Train Loss 0.04277746 Test MSE 0.0045072364997756215 Test RE 0.03208952093649416\n",
      "94 Train Loss 0.04166698 Test MSE 0.0046250670592581245 Test RE 0.03250626543062504\n",
      "95 Train Loss 0.04083391 Test MSE 0.004442381444650431 Test RE 0.03185781482003405\n",
      "96 Train Loss 0.039710358 Test MSE 0.004243848815245909 Test RE 0.031137806271202512\n",
      "97 Train Loss 0.03886643 Test MSE 0.004101439568788035 Test RE 0.03061090846964524\n",
      "98 Train Loss 0.03825525 Test MSE 0.004372096836242444 Test RE 0.03160479273068158\n",
      "99 Train Loss 0.037832275 Test MSE 0.004391615534996469 Test RE 0.03167526205954611\n",
      "Training time: 80.11\n",
      "KG_stan_tune17\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.3315 Test MSE 8.090959711121037 Test RE 1.3595903693057356\n",
      "1 Train Loss 57.566013 Test MSE 8.628986001449999 Test RE 1.4040673566777075\n",
      "2 Train Loss 46.991898 Test MSE 8.676090683387242 Test RE 1.4078944651906267\n",
      "3 Train Loss 44.84926 Test MSE 8.644723406015617 Test RE 1.4053471310596202\n",
      "4 Train Loss 44.503788 Test MSE 8.440608224000972 Test RE 1.3886568206780543\n",
      "5 Train Loss 44.065586 Test MSE 8.327677642079113 Test RE 1.3793358153505342\n",
      "6 Train Loss 43.782135 Test MSE 8.445869549175528 Test RE 1.38908955234276\n",
      "7 Train Loss 43.50122 Test MSE 8.498412050625694 Test RE 1.3934036775878005\n",
      "8 Train Loss 43.019627 Test MSE 8.760134120963796 Test RE 1.4146970176811804\n",
      "9 Train Loss 42.205498 Test MSE 8.876342800581595 Test RE 1.4240495252623078\n",
      "10 Train Loss 41.859135 Test MSE 8.656941260564837 Test RE 1.4063398906585947\n",
      "11 Train Loss 41.43512 Test MSE 8.708372046021639 Test RE 1.4105112286793786\n",
      "12 Train Loss 40.906532 Test MSE 9.08271733735229 Test RE 1.4405089457614424\n",
      "13 Train Loss 38.202415 Test MSE 9.856102223807577 Test RE 1.500585203815012\n",
      "14 Train Loss 35.087048 Test MSE 9.628508875372797 Test RE 1.4831585435761478\n",
      "15 Train Loss 32.847336 Test MSE 8.84106767770122 Test RE 1.4212170789328025\n",
      "16 Train Loss 31.471027 Test MSE 8.378464451421928 Test RE 1.383535400661542\n",
      "17 Train Loss 30.431707 Test MSE 8.326911773671016 Test RE 1.3792723874622437\n",
      "18 Train Loss 27.519112 Test MSE 7.033731871117488 Test RE 1.2676546816478051\n",
      "19 Train Loss 24.56173 Test MSE 6.218587356721646 Test RE 1.191938725584559\n",
      "20 Train Loss 23.35598 Test MSE 6.136406487030678 Test RE 1.184036581746382\n",
      "21 Train Loss 21.969326 Test MSE 6.654220204058903 Test RE 1.232981739098764\n",
      "22 Train Loss 21.030281 Test MSE 6.859744883937976 Test RE 1.2518781012563798\n",
      "23 Train Loss 20.023539 Test MSE 7.136962701391915 Test RE 1.2769231889187975\n",
      "24 Train Loss 19.148426 Test MSE 7.057368343289866 Test RE 1.2697828374548512\n",
      "25 Train Loss 18.088799 Test MSE 7.091042866536264 Test RE 1.2728086428225323\n",
      "26 Train Loss 17.505306 Test MSE 7.169232846074904 Test RE 1.279806770034634\n",
      "27 Train Loss 16.741367 Test MSE 7.08903252528366 Test RE 1.2726282066616261\n",
      "28 Train Loss 16.311882 Test MSE 7.094565147092462 Test RE 1.2731247199237248\n",
      "29 Train Loss 15.97674 Test MSE 7.022842374262207 Test RE 1.266673021493187\n",
      "30 Train Loss 15.726614 Test MSE 7.087358058186737 Test RE 1.2724778970176245\n",
      "31 Train Loss 15.591975 Test MSE 7.034117563743794 Test RE 1.267689436907889\n",
      "32 Train Loss 15.444597 Test MSE 7.071535539026544 Test RE 1.2710567006086766\n",
      "33 Train Loss 15.33717 Test MSE 7.1081885229394635 Test RE 1.2743464958772273\n",
      "34 Train Loss 15.205416 Test MSE 6.999608226470228 Test RE 1.2645759752874508\n",
      "35 Train Loss 15.118685 Test MSE 7.010416594233913 Test RE 1.2655519391921481\n",
      "36 Train Loss 15.023739 Test MSE 7.022901500476958 Test RE 1.2666783536236452\n",
      "37 Train Loss 14.950459 Test MSE 7.0438380785994665 Test RE 1.2685650506329464\n",
      "38 Train Loss 14.854221 Test MSE 6.974889195589873 Test RE 1.2623410831202275\n",
      "39 Train Loss 14.790768 Test MSE 7.004647832143053 Test RE 1.265031130587388\n",
      "40 Train Loss 14.683446 Test MSE 7.007824925773151 Test RE 1.2653179877434368\n",
      "41 Train Loss 14.595095 Test MSE 6.9768436654606365 Test RE 1.2625179343024728\n",
      "42 Train Loss 14.545329 Test MSE 6.997629739682022 Test RE 1.264397242163975\n",
      "43 Train Loss 14.432303 Test MSE 6.983728129247677 Test RE 1.263140681228238\n",
      "44 Train Loss 14.351034 Test MSE 7.0275579910158195 Test RE 1.2670982155845016\n",
      "45 Train Loss 14.281607 Test MSE 7.046872498065499 Test RE 1.2688382641823637\n",
      "46 Train Loss 14.232885 Test MSE 7.078938917525878 Test RE 1.2717218780768962\n",
      "47 Train Loss 14.116618 Test MSE 7.143305124849449 Test RE 1.2774904462684546\n",
      "48 Train Loss 14.089741 Test MSE 7.165707134554629 Test RE 1.2794920373103411\n",
      "49 Train Loss 13.961758 Test MSE 7.189798814076009 Test RE 1.2816411096821\n",
      "50 Train Loss 13.909952 Test MSE 7.213583969130746 Test RE 1.2837593095962323\n",
      "51 Train Loss 13.79488 Test MSE 7.171768363699054 Test RE 1.2800330624310294\n",
      "52 Train Loss 13.674587 Test MSE 7.218061500323236 Test RE 1.284157667796863\n",
      "53 Train Loss 13.57729 Test MSE 7.177830952877836 Test RE 1.2805739802956544\n",
      "54 Train Loss 13.461979 Test MSE 7.253606363567327 Test RE 1.2873156592065946\n",
      "55 Train Loss 13.305059 Test MSE 7.296666420671764 Test RE 1.2911309932845716\n",
      "56 Train Loss 13.173847 Test MSE 7.244464712170367 Test RE 1.2865042075935962\n",
      "57 Train Loss 13.015529 Test MSE 7.357042283837225 Test RE 1.2964616849084114\n",
      "58 Train Loss 12.890214 Test MSE 7.426161187078708 Test RE 1.3025375316450387\n",
      "59 Train Loss 12.725119 Test MSE 7.40030267804047 Test RE 1.3002677822116118\n",
      "60 Train Loss 12.518588 Test MSE 7.37773361226201 Test RE 1.2982835229913718\n",
      "61 Train Loss 12.392642 Test MSE 7.339247369981369 Test RE 1.2948928213313862\n",
      "62 Train Loss 12.204453 Test MSE 7.273369358643794 Test RE 1.289068160390411\n",
      "63 Train Loss 11.972858 Test MSE 7.219569228731668 Test RE 1.2842917799750053\n",
      "64 Train Loss 11.666111 Test MSE 7.067130435272368 Test RE 1.2706607463736785\n",
      "65 Train Loss 11.305275 Test MSE 7.079117837515071 Test RE 1.2717379493433392\n",
      "66 Train Loss 11.012226 Test MSE 7.084916316564915 Test RE 1.2722586806413378\n",
      "67 Train Loss 10.2338915 Test MSE 7.120368001219383 Test RE 1.2754377888678563\n",
      "68 Train Loss 9.178484 Test MSE 6.460351668483617 Test RE 1.2148877136166125\n",
      "69 Train Loss 8.489584 Test MSE 6.345144736695005 Test RE 1.2040064869328393\n",
      "70 Train Loss 7.629018 Test MSE 6.218773942679856 Test RE 1.1919566072470866\n",
      "71 Train Loss 7.234441 Test MSE 6.407492078027505 Test RE 1.2099073060622163\n",
      "72 Train Loss 6.696758 Test MSE 6.1750946171933405 Test RE 1.1877632079611755\n",
      "73 Train Loss 6.2461843 Test MSE 6.188847950589651 Test RE 1.189085181039728\n",
      "74 Train Loss 5.7618375 Test MSE 6.204228447781666 Test RE 1.19056181875723\n",
      "75 Train Loss 5.111283 Test MSE 6.23600821157376 Test RE 1.1936071164992745\n",
      "76 Train Loss 4.525833 Test MSE 5.804108158991881 Test RE 1.1515314633672034\n",
      "77 Train Loss 4.0096135 Test MSE 5.875692906581766 Test RE 1.158610886600199\n",
      "78 Train Loss 3.4835873 Test MSE 5.954509125686537 Test RE 1.1663557718732451\n",
      "79 Train Loss 3.0597682 Test MSE 5.841890338077854 Test RE 1.155273364178136\n",
      "80 Train Loss 2.6617558 Test MSE 5.783827474968922 Test RE 1.1495178652784108\n",
      "81 Train Loss 2.271938 Test MSE 5.676836426423653 Test RE 1.1388361659463393\n",
      "82 Train Loss 2.100094 Test MSE 5.721858681246695 Test RE 1.1433432284661438\n",
      "83 Train Loss 2.0024567 Test MSE 5.669919804827147 Test RE 1.1381421791038375\n",
      "84 Train Loss 1.9018829 Test MSE 5.656701363658355 Test RE 1.136814713761726\n",
      "85 Train Loss 1.8490815 Test MSE 5.725746917155066 Test RE 1.1437316366269437\n",
      "86 Train Loss 1.7731335 Test MSE 5.777763810398852 Test RE 1.1489151399530253\n",
      "87 Train Loss 1.7314396 Test MSE 5.8245852321973395 Test RE 1.153560994201057\n",
      "88 Train Loss 1.6721596 Test MSE 5.846470470005637 Test RE 1.1557261514956632\n",
      "89 Train Loss 1.6216291 Test MSE 5.807993698159734 Test RE 1.1519168431622129\n",
      "90 Train Loss 1.590438 Test MSE 5.8248569217007 Test RE 1.1535878979844527\n",
      "91 Train Loss 1.546035 Test MSE 5.8614562740675415 Test RE 1.1572063951334317\n",
      "92 Train Loss 1.5128983 Test MSE 5.90390278187403 Test RE 1.1613888680914737\n",
      "93 Train Loss 1.4844906 Test MSE 5.907607392690751 Test RE 1.1617531880333936\n",
      "94 Train Loss 1.4526708 Test MSE 5.866948093083956 Test RE 1.1577483833260869\n",
      "95 Train Loss 1.4303838 Test MSE 5.894484318149806 Test RE 1.1604621196893403\n",
      "96 Train Loss 1.411438 Test MSE 5.877965031714835 Test RE 1.15883488183861\n",
      "97 Train Loss 1.3982738 Test MSE 5.8889196370096855 Test RE 1.1599142238840996\n",
      "98 Train Loss 1.3769398 Test MSE 5.918573125640285 Test RE 1.1628309144356752\n",
      "99 Train Loss 1.3582785 Test MSE 5.921991789898655 Test RE 1.1631667009938063\n",
      "Training time: 77.40\n",
      "KG_stan_tune17\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.02378 Test MSE 8.420420558827825 Test RE 1.3869951796826074\n",
      "1 Train Loss 58.41578 Test MSE 8.339000251047743 Test RE 1.380273194038872\n",
      "2 Train Loss 51.80819 Test MSE 9.661148120452141 Test RE 1.485670262690319\n",
      "3 Train Loss 46.75792 Test MSE 8.563595132480746 Test RE 1.3987371945989089\n",
      "4 Train Loss 46.47943 Test MSE 8.603482213145591 Test RE 1.4019908939826433\n",
      "5 Train Loss 45.798325 Test MSE 8.358032181295881 Test RE 1.381847381051138\n",
      "6 Train Loss 45.711372 Test MSE 8.455475154734252 Test RE 1.3898792433624607\n",
      "7 Train Loss 45.100357 Test MSE 8.335698520008583 Test RE 1.379999915354312\n",
      "8 Train Loss 45.014076 Test MSE 8.32995450318941 Test RE 1.3795243638016352\n",
      "9 Train Loss 44.813644 Test MSE 8.343590527005977 Test RE 1.380653033528234\n",
      "10 Train Loss 44.581516 Test MSE 8.426970201053402 Test RE 1.3875344969475711\n",
      "11 Train Loss 44.302002 Test MSE 8.641015239494719 Test RE 1.4050456858946778\n",
      "12 Train Loss 43.930782 Test MSE 8.728616083943352 Test RE 1.4121497592245775\n",
      "13 Train Loss 43.439087 Test MSE 8.721340810007108 Test RE 1.4115611253609042\n",
      "14 Train Loss 42.771698 Test MSE 9.114691071188457 Test RE 1.4430422177112956\n",
      "15 Train Loss 41.983932 Test MSE 9.242412317386831 Test RE 1.453117489277748\n",
      "16 Train Loss 41.200882 Test MSE 9.246787524822324 Test RE 1.4534613896576865\n",
      "17 Train Loss 39.80521 Test MSE 8.500499309808003 Test RE 1.3935747810860584\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 14.28\n",
      "KG_stan_tune18\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smartlab/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio5.py:493: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  narr = np.asanyarray(source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 50.86392 Test MSE 9.706792378330178 Test RE 1.4891756643924\n",
      "1 Train Loss 43.27896 Test MSE 9.429281037173023 Test RE 1.467733984781165\n",
      "2 Train Loss 43.115303 Test MSE 9.37645242402297 Test RE 1.463616636903256\n",
      "3 Train Loss 42.632107 Test MSE 9.455603265182408 Test RE 1.4697811771332414\n",
      "4 Train Loss 42.465893 Test MSE 9.448746574455727 Test RE 1.4692481776871782\n",
      "5 Train Loss 41.878384 Test MSE 9.380324305563715 Test RE 1.463918796242455\n",
      "6 Train Loss 41.411015 Test MSE 9.553600576048833 Test RE 1.477377907283859\n",
      "7 Train Loss 40.885178 Test MSE 9.52292645591754 Test RE 1.475004262863523\n",
      "8 Train Loss 40.231033 Test MSE 9.580834149088586 Test RE 1.4794821216362375\n",
      "9 Train Loss 39.61463 Test MSE 9.698157617924814 Test RE 1.48851316253437\n",
      "10 Train Loss 38.429924 Test MSE 8.984362412751212 Test RE 1.4326882246290316\n",
      "11 Train Loss 36.985146 Test MSE 8.291665946741256 Test RE 1.3763502268357524\n",
      "12 Train Loss 34.19919 Test MSE 8.998804950126258 Test RE 1.433839299318531\n",
      "13 Train Loss 32.516766 Test MSE 8.805148017135709 Test RE 1.4183270664428778\n",
      "14 Train Loss 32.057312 Test MSE 9.000180900596211 Test RE 1.433948914787408\n",
      "15 Train Loss 31.6213 Test MSE 9.055026813219806 Test RE 1.4383114263021992\n",
      "16 Train Loss 31.048595 Test MSE 9.397624273875028 Test RE 1.4652681143340833\n",
      "17 Train Loss 30.270031 Test MSE 9.37215480228263 Test RE 1.4632811799889627\n",
      "18 Train Loss 29.456444 Test MSE 9.010417392015379 Test RE 1.4347641447567991\n",
      "19 Train Loss 28.004074 Test MSE 8.212173150283192 Test RE 1.3697367535034388\n",
      "20 Train Loss 25.037207 Test MSE 7.707435779010124 Test RE 1.3269758455706882\n",
      "21 Train Loss 23.207027 Test MSE 7.396771113020146 Test RE 1.2999574889444083\n",
      "22 Train Loss 22.426556 Test MSE 7.118407351037234 Test RE 1.2752621757884206\n",
      "23 Train Loss 21.783436 Test MSE 6.398288526766703 Test RE 1.2090380544646517\n",
      "24 Train Loss 21.312399 Test MSE 6.473694137013722 Test RE 1.2161416113289303\n",
      "25 Train Loss 20.970444 Test MSE 6.484979754772326 Test RE 1.217201202082747\n",
      "26 Train Loss 20.469034 Test MSE 6.214133930280197 Test RE 1.1915118471121076\n",
      "27 Train Loss 19.426292 Test MSE 5.639363673371901 Test RE 1.1350712182292702\n",
      "28 Train Loss 17.116894 Test MSE 5.088323413908038 Test RE 1.0781902840241333\n",
      "29 Train Loss 16.0069 Test MSE 5.109249312178037 Test RE 1.0804050558749634\n",
      "30 Train Loss 15.314232 Test MSE 5.3567779269687765 Test RE 1.1062668062520737\n",
      "31 Train Loss 14.427685 Test MSE 5.482616555756015 Test RE 1.119185299000311\n",
      "32 Train Loss 13.752348 Test MSE 5.363230019691728 Test RE 1.1069328398359681\n",
      "33 Train Loss 13.277735 Test MSE 5.327827790615036 Test RE 1.1032734057696114\n",
      "34 Train Loss 12.800985 Test MSE 5.28758484933169 Test RE 1.0990988033804134\n",
      "35 Train Loss 11.319607 Test MSE 5.112256033816136 Test RE 1.080722910737849\n",
      "36 Train Loss 8.999352 Test MSE 4.542226119600722 Test RE 1.0186909207222095\n",
      "37 Train Loss 7.258796 Test MSE 4.2865185492453195 Test RE 0.9896016573988413\n",
      "38 Train Loss 6.747578 Test MSE 4.345579968100377 Test RE 0.9963959036858893\n",
      "39 Train Loss 6.482237 Test MSE 4.314646773894757 Test RE 0.9928432416768938\n",
      "40 Train Loss 6.271116 Test MSE 4.396060937390427 Test RE 1.002166571524694\n",
      "41 Train Loss 6.0642233 Test MSE 4.539563586795587 Test RE 1.0183923121204845\n",
      "42 Train Loss 5.882836 Test MSE 4.549599060348254 Test RE 1.0195173549651138\n",
      "43 Train Loss 5.76388 Test MSE 4.557148994316719 Test RE 1.0203629347508305\n",
      "44 Train Loss 5.7040296 Test MSE 4.547754532456432 Test RE 1.019310664351819\n",
      "45 Train Loss 5.63978 Test MSE 4.5782021803365645 Test RE 1.0227171629375755\n",
      "46 Train Loss 5.5794325 Test MSE 4.59315140465842 Test RE 1.0243855435976974\n",
      "47 Train Loss 5.5322404 Test MSE 4.614654701497946 Test RE 1.0267806252612928\n",
      "48 Train Loss 5.467253 Test MSE 4.625341844289481 Test RE 1.0279689054121812\n",
      "49 Train Loss 5.41442 Test MSE 4.683292843873849 Test RE 1.0343885813313625\n",
      "50 Train Loss 5.3591137 Test MSE 4.684639540984901 Test RE 1.0345372916548394\n",
      "51 Train Loss 5.297091 Test MSE 4.706142468071181 Test RE 1.0369088840537382\n",
      "52 Train Loss 5.191496 Test MSE 4.798535126446608 Test RE 1.0470378931345854\n",
      "53 Train Loss 5.0284233 Test MSE 4.8243030061047225 Test RE 1.0498453981774636\n",
      "54 Train Loss 4.617501 Test MSE 4.450041946324332 Test RE 1.0083008019880768\n",
      "55 Train Loss 3.082793 Test MSE 2.948989278720549 Test RE 0.8208138144780095\n",
      "56 Train Loss 1.6370764 Test MSE 2.489295970771033 Test RE 0.7541301920213345\n",
      "57 Train Loss 1.3624687 Test MSE 2.5490005894456185 Test RE 0.763120338162318\n",
      "58 Train Loss 1.2394457 Test MSE 2.504852443658307 Test RE 0.7564829323853541\n",
      "59 Train Loss 1.162889 Test MSE 2.5001682679992356 Test RE 0.7557752745111693\n",
      "60 Train Loss 1.0886893 Test MSE 2.542653285496244 Test RE 0.7621696173398079\n",
      "61 Train Loss 1.0475187 Test MSE 2.555161730239314 Test RE 0.7640420433595122\n",
      "62 Train Loss 1.0083593 Test MSE 2.573226716435344 Test RE 0.7667381738852408\n",
      "63 Train Loss 0.9747913 Test MSE 2.5818273138385517 Test RE 0.7680184546526074\n",
      "64 Train Loss 0.9411803 Test MSE 2.5818719069905534 Test RE 0.7680250872061521\n",
      "65 Train Loss 0.91525394 Test MSE 2.578052237916038 Test RE 0.7674567616676953\n",
      "66 Train Loss 0.8914763 Test MSE 2.5835596628320365 Test RE 0.7682760731394481\n",
      "67 Train Loss 0.87350094 Test MSE 2.6131536873234458 Test RE 0.772663748336831\n",
      "68 Train Loss 0.85222954 Test MSE 2.6370277619815177 Test RE 0.7761852960424848\n",
      "69 Train Loss 0.82593006 Test MSE 2.6769261585865975 Test RE 0.7820351183441181\n",
      "70 Train Loss 0.81271416 Test MSE 2.653913245636001 Test RE 0.7786663754286145\n",
      "71 Train Loss 0.79001755 Test MSE 2.6774387116701464 Test RE 0.7821099831895455\n",
      "72 Train Loss 0.7608106 Test MSE 2.6668657304153247 Test RE 0.7805642122364401\n",
      "73 Train Loss 0.7419757 Test MSE 2.6763950176245457 Test RE 0.7819575309422899\n",
      "74 Train Loss 0.72704726 Test MSE 2.7159953447249356 Test RE 0.7877212672237542\n",
      "75 Train Loss 0.7080076 Test MSE 2.7321351911674223 Test RE 0.7900583235790972\n",
      "76 Train Loss 0.68190765 Test MSE 2.7755610973022202 Test RE 0.7963123589724891\n",
      "77 Train Loss 0.6626043 Test MSE 2.80638375925169 Test RE 0.8007216837614495\n",
      "78 Train Loss 0.6460052 Test MSE 2.79604940229728 Test RE 0.7992460167680812\n",
      "79 Train Loss 0.62890476 Test MSE 2.818663993336834 Test RE 0.8024716789705768\n",
      "80 Train Loss 0.61523736 Test MSE 2.820205916171835 Test RE 0.8026911411404984\n",
      "81 Train Loss 0.60474324 Test MSE 2.8553468319189483 Test RE 0.807676588513838\n",
      "82 Train Loss 0.5918568 Test MSE 2.8672199662539963 Test RE 0.8093540912695198\n",
      "83 Train Loss 0.57817066 Test MSE 2.9024046213851236 Test RE 0.8143048823746295\n",
      "84 Train Loss 0.5708528 Test MSE 2.930805999802463 Test RE 0.8182793589237265\n",
      "85 Train Loss 0.5603273 Test MSE 2.950285443256785 Test RE 0.8209941801520902\n",
      "86 Train Loss 0.55495906 Test MSE 2.9671014214211797 Test RE 0.8233305987465968\n",
      "87 Train Loss 0.5501312 Test MSE 2.98112300963841 Test RE 0.8252737065666452\n",
      "88 Train Loss 0.54217327 Test MSE 2.991118318268387 Test RE 0.8266560652625066\n",
      "89 Train Loss 0.5350417 Test MSE 3.012417432544487 Test RE 0.8295940649064343\n",
      "90 Train Loss 0.5310208 Test MSE 3.0270853883874427 Test RE 0.8316113272533426\n",
      "91 Train Loss 0.5230308 Test MSE 3.0452191393121653 Test RE 0.8340984912425172\n",
      "92 Train Loss 0.51954466 Test MSE 3.0694050108468427 Test RE 0.8374042470525972\n",
      "93 Train Loss 0.514233 Test MSE 3.068147954727492 Test RE 0.8372327525887631\n",
      "94 Train Loss 0.5105273 Test MSE 3.100870032323239 Test RE 0.8416854936629473\n",
      "95 Train Loss 0.5045205 Test MSE 3.106748168027888 Test RE 0.8424828826263938\n",
      "96 Train Loss 0.4995981 Test MSE 3.1047373522915076 Test RE 0.84221019363546\n",
      "97 Train Loss 0.4965915 Test MSE 3.0979308558499588 Test RE 0.841286501014272\n",
      "98 Train Loss 0.4904751 Test MSE 3.1385754979957916 Test RE 0.8467873280293153\n",
      "99 Train Loss 0.48651794 Test MSE 3.1526900832894484 Test RE 0.8486892489197189\n",
      "Training time: 77.16\n",
      "KG_stan_tune18\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.567535 Test MSE 8.192823868820147 Test RE 1.3681221350855226\n",
      "1 Train Loss 52.973236 Test MSE 8.688344101375368 Test RE 1.4088883132913883\n",
      "2 Train Loss 48.20198 Test MSE 8.854726160648605 Test RE 1.422314467760909\n",
      "3 Train Loss 46.96645 Test MSE 8.860296778435409 Test RE 1.4227617952321112\n",
      "4 Train Loss 46.121544 Test MSE 8.615413870083175 Test RE 1.4029627259797404\n",
      "5 Train Loss 45.77269 Test MSE 8.693536967043663 Test RE 1.4093092838934143\n",
      "6 Train Loss 45.114975 Test MSE 8.664770258438953 Test RE 1.4069756662462125\n",
      "7 Train Loss 44.952095 Test MSE 8.683330154645642 Test RE 1.408481727737525\n",
      "8 Train Loss 44.5496 Test MSE 8.556024459254083 Test RE 1.3981187788812288\n",
      "9 Train Loss 44.22612 Test MSE 8.430944502555784 Test RE 1.387861650733393\n",
      "10 Train Loss 44.047832 Test MSE 8.483801585324523 Test RE 1.392205392927418\n",
      "11 Train Loss 43.830826 Test MSE 8.538645581351092 Test RE 1.3966981374069032\n",
      "12 Train Loss 43.519012 Test MSE 8.372137124058868 Test RE 1.3830128863738214\n",
      "13 Train Loss 43.371162 Test MSE 8.4752695815807 Test RE 1.3915051591079834\n",
      "14 Train Loss 42.766945 Test MSE 8.439644807772048 Test RE 1.3885775673434604\n",
      "15 Train Loss 42.073868 Test MSE 8.564924481679004 Test RE 1.398845755196694\n",
      "16 Train Loss 40.771694 Test MSE 8.355570877358296 Test RE 1.3816439003299146\n",
      "17 Train Loss 39.837227 Test MSE 7.997766582869156 Test RE 1.3517376885424588\n",
      "18 Train Loss 39.28885 Test MSE 8.328047156774419 Test RE 1.379366416871249\n",
      "19 Train Loss 38.9923 Test MSE 8.060774079061447 Test RE 1.357051829650357\n",
      "20 Train Loss 38.765633 Test MSE 8.218509522813614 Test RE 1.370265084351573\n",
      "21 Train Loss 38.406006 Test MSE 8.029695560205644 Test RE 1.3544332293230779\n",
      "22 Train Loss 37.939335 Test MSE 8.046902580931071 Test RE 1.3558836758698873\n",
      "23 Train Loss 37.75555 Test MSE 8.04362990136541 Test RE 1.35560792852381\n",
      "24 Train Loss 37.56955 Test MSE 7.952122973011116 Test RE 1.3478749558837275\n",
      "25 Train Loss 36.892574 Test MSE 7.913046154645112 Test RE 1.3445591413183904\n",
      "26 Train Loss 36.299095 Test MSE 8.258820061866864 Test RE 1.3736214446772697\n",
      "27 Train Loss 35.320442 Test MSE 8.164397472178063 Test RE 1.3657466064345882\n",
      "28 Train Loss 33.999004 Test MSE 8.338571089778528 Test RE 1.380237676147066\n",
      "29 Train Loss 32.865036 Test MSE 8.293426480520033 Test RE 1.376496336343347\n",
      "30 Train Loss 32.625275 Test MSE 8.420902229535836 Test RE 1.387034849043056\n",
      "31 Train Loss 32.31647 Test MSE 8.305676013281298 Test RE 1.3775125155693588\n",
      "32 Train Loss 31.773241 Test MSE 8.120935171401223 Test RE 1.3621065522777869\n",
      "33 Train Loss 31.408169 Test MSE 8.139492158976193 Test RE 1.363661925553575\n",
      "34 Train Loss 31.15174 Test MSE 8.188916933074237 Test RE 1.3677958859952792\n",
      "35 Train Loss 30.975769 Test MSE 8.244423463887838 Test RE 1.3724236887549925\n",
      "36 Train Loss 30.663807 Test MSE 8.10712040699944 Test RE 1.3609474991550146\n",
      "37 Train Loss 30.420124 Test MSE 8.226073965535221 Test RE 1.3708955458554928\n",
      "38 Train Loss 30.168018 Test MSE 8.23093859489078 Test RE 1.3713008371945532\n",
      "39 Train Loss 29.958693 Test MSE 8.170370500775075 Test RE 1.3662461014731362\n",
      "40 Train Loss 29.774372 Test MSE 8.295251846098596 Test RE 1.3766478099711357\n",
      "41 Train Loss 29.619076 Test MSE 8.26028660137593 Test RE 1.3737433979758849\n",
      "42 Train Loss 29.381948 Test MSE 8.352948459398629 Test RE 1.381427067023887\n",
      "43 Train Loss 29.161425 Test MSE 8.393291489204826 Test RE 1.3847590535286443\n",
      "44 Train Loss 29.004026 Test MSE 8.366965172801024 Test RE 1.3825856370252751\n",
      "45 Train Loss 28.730942 Test MSE 8.25431773752253 Test RE 1.3732469763919888\n",
      "46 Train Loss 28.563068 Test MSE 8.298331210513558 Test RE 1.3769033059470563\n",
      "47 Train Loss 28.100735 Test MSE 8.226726787961201 Test RE 1.3709499420112166\n",
      "48 Train Loss 27.904823 Test MSE 8.203039633555163 Test RE 1.3689748361776322\n",
      "49 Train Loss 27.34825 Test MSE 8.134018371414793 Test RE 1.3632033188672414\n",
      "50 Train Loss 27.079308 Test MSE 8.188117629960292 Test RE 1.3677291305134838\n",
      "51 Train Loss 26.736183 Test MSE 7.949725063134571 Test RE 1.3476717191902028\n",
      "52 Train Loss 26.504253 Test MSE 8.097442241155628 Test RE 1.3601349166183918\n",
      "53 Train Loss 26.289566 Test MSE 8.161741922100656 Test RE 1.3655244771543513\n",
      "54 Train Loss 26.001963 Test MSE 8.254529676462973 Test RE 1.3732646061131963\n",
      "55 Train Loss 25.618027 Test MSE 8.19325330823043 Test RE 1.3681579907241568\n",
      "56 Train Loss 25.071484 Test MSE 8.221093169326412 Test RE 1.3704804520165903\n",
      "57 Train Loss 24.539165 Test MSE 7.991385137368463 Test RE 1.351198302848033\n",
      "58 Train Loss 24.090443 Test MSE 7.52890502219182 Test RE 1.3115171365256868\n",
      "59 Train Loss 23.61097 Test MSE 7.705830456117572 Test RE 1.3268376455455797\n",
      "60 Train Loss 23.23682 Test MSE 7.712396354254767 Test RE 1.3274028036998156\n",
      "61 Train Loss 22.767746 Test MSE 7.061193574069075 Test RE 1.2701269143230935\n",
      "62 Train Loss 22.258705 Test MSE 6.810281963923364 Test RE 1.2473565356098846\n",
      "63 Train Loss 21.719261 Test MSE 7.100551956529844 Test RE 1.2736617752361585\n",
      "64 Train Loss 21.428621 Test MSE 7.05743261464824 Test RE 1.26978861938928\n",
      "65 Train Loss 21.266556 Test MSE 7.229742598688194 Test RE 1.2851963336565455\n",
      "66 Train Loss 20.927853 Test MSE 7.484312481829981 Test RE 1.3076274118031097\n",
      "67 Train Loss 20.649218 Test MSE 7.404259737695124 Test RE 1.300615372693976\n",
      "68 Train Loss 20.450893 Test MSE 7.499211868121257 Test RE 1.3089283435357935\n",
      "69 Train Loss 20.293373 Test MSE 7.297305272866991 Test RE 1.291187513876858\n",
      "70 Train Loss 20.024155 Test MSE 6.9136696282474945 Test RE 1.2567890022678336\n",
      "71 Train Loss 19.589424 Test MSE 6.355391346071041 Test RE 1.2049782541673377\n",
      "72 Train Loss 19.212332 Test MSE 6.137738004966295 Test RE 1.1841650348104193\n",
      "73 Train Loss 18.746464 Test MSE 6.171781609787999 Test RE 1.1874445410830607\n",
      "74 Train Loss 18.263954 Test MSE 6.289081504144214 Test RE 1.1986756187748637\n",
      "75 Train Loss 17.972855 Test MSE 6.1303084174910385 Test RE 1.1834481158317416\n",
      "76 Train Loss 17.828104 Test MSE 6.224558833993308 Test RE 1.1925108753929445\n",
      "77 Train Loss 17.745579 Test MSE 6.25252409676135 Test RE 1.1951866880810147\n",
      "78 Train Loss 17.635384 Test MSE 6.142707713167988 Test RE 1.1846443452587763\n",
      "79 Train Loss 17.566065 Test MSE 6.128096640231154 Test RE 1.1832346062012515\n",
      "80 Train Loss 17.479807 Test MSE 6.21374625182374 Test RE 1.1914746793680908\n",
      "81 Train Loss 17.43752 Test MSE 6.267621430151075 Test RE 1.1966287659052874\n",
      "82 Train Loss 17.359943 Test MSE 6.251028339414061 Test RE 1.1950437205233375\n",
      "83 Train Loss 17.300667 Test MSE 6.182334924687741 Test RE 1.1884593310212175\n",
      "84 Train Loss 17.2359 Test MSE 6.198981957196948 Test RE 1.190058324044334\n",
      "85 Train Loss 17.151646 Test MSE 6.119987126164613 Test RE 1.1824514401673436\n",
      "86 Train Loss 16.994476 Test MSE 6.082836560932186 Test RE 1.1788570201582032\n",
      "87 Train Loss 16.948473 Test MSE 6.075893015690178 Test RE 1.1781839966252536\n",
      "88 Train Loss 16.89804 Test MSE 6.113350375143937 Test RE 1.1818101181870002\n",
      "89 Train Loss 16.784256 Test MSE 6.1420065660775185 Test RE 1.1845767338992474\n",
      "90 Train Loss 16.689602 Test MSE 6.110532328958387 Test RE 1.181537699694733\n",
      "91 Train Loss 16.588417 Test MSE 6.116987781461643 Test RE 1.1821616508236092\n",
      "92 Train Loss 16.348854 Test MSE 6.178514066234113 Test RE 1.188092023461808\n",
      "93 Train Loss 16.17379 Test MSE 6.261031633749654 Test RE 1.1959995308889522\n",
      "94 Train Loss 16.05181 Test MSE 6.274084872237831 Test RE 1.1972456145650883\n",
      "95 Train Loss 15.871912 Test MSE 6.284871090259456 Test RE 1.1982743069576172\n",
      "96 Train Loss 15.65332 Test MSE 6.144015033396154 Test RE 1.184770399370081\n",
      "97 Train Loss 15.488507 Test MSE 6.162110999809705 Test RE 1.1865138685800807\n",
      "98 Train Loss 15.292414 Test MSE 6.2774235866821 Test RE 1.1975641255248712\n",
      "99 Train Loss 15.154269 Test MSE 6.144112832984076 Test RE 1.1847798288388498\n",
      "Training time: 80.33\n",
      "KG_stan_tune18\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.756973 Test MSE 8.84553695788851 Test RE 1.4215762558464127\n",
      "1 Train Loss 47.290253 Test MSE 8.246243966762332 Test RE 1.372575207134\n",
      "2 Train Loss 42.958847 Test MSE 7.963195508158288 Test RE 1.348813019926918\n",
      "3 Train Loss 35.986862 Test MSE 7.312212282343647 Test RE 1.2925056665333206\n",
      "4 Train Loss 32.21598 Test MSE 6.925013692189171 Test RE 1.2578196597943598\n",
      "5 Train Loss 28.568207 Test MSE 5.940070612106725 Test RE 1.1649408219267252\n",
      "6 Train Loss 26.114712 Test MSE 5.94116808218811 Test RE 1.165048432486866\n",
      "7 Train Loss 24.485342 Test MSE 6.327569628745037 Test RE 1.2023378711582666\n",
      "8 Train Loss 23.320284 Test MSE 6.006027652191055 Test RE 1.1713905712226464\n",
      "9 Train Loss 22.794088 Test MSE 6.089231383662294 Test RE 1.1794765174375763\n",
      "10 Train Loss 22.38329 Test MSE 6.060308978846147 Test RE 1.1766720665010444\n",
      "11 Train Loss 21.403217 Test MSE 6.067733374278249 Test RE 1.1773926077121746\n",
      "12 Train Loss 20.482626 Test MSE 6.346793600498988 Test RE 1.2041629147089394\n",
      "13 Train Loss 19.441044 Test MSE 6.223836020169463 Test RE 1.1924416344721278\n",
      "14 Train Loss 18.67231 Test MSE 6.151911283440865 Test RE 1.1855314847005178\n",
      "15 Train Loss 16.531193 Test MSE 5.48214052181464 Test RE 1.1191367107260193\n",
      "16 Train Loss 13.955488 Test MSE 5.332019536909457 Test RE 1.1037073286668544\n",
      "17 Train Loss 11.929603 Test MSE 5.506736447948664 Test RE 1.1216444354340502\n",
      "18 Train Loss 10.922139 Test MSE 5.332753629857951 Test RE 1.1037833032461222\n",
      "19 Train Loss 10.033022 Test MSE 5.428812492789892 Test RE 1.1136801555741407\n",
      "20 Train Loss 9.401098 Test MSE 5.342692432682379 Test RE 1.104811400428516\n",
      "21 Train Loss 8.688954 Test MSE 4.92551625637959 Test RE 1.0608010444610336\n",
      "22 Train Loss 7.9859266 Test MSE 4.491699768804952 Test RE 1.0130092713107455\n",
      "23 Train Loss 6.9011917 Test MSE 4.128220110977491 Test RE 0.9711570850291049\n",
      "24 Train Loss 5.942593 Test MSE 3.6016687103614156 Test RE 0.9071099730639485\n",
      "25 Train Loss 5.5086136 Test MSE 3.4998456129582673 Test RE 0.8941955489677348\n",
      "26 Train Loss 5.094928 Test MSE 3.0285767005353503 Test RE 0.8318161512351813\n",
      "27 Train Loss 4.7372503 Test MSE 2.5863441152586373 Test RE 0.7686899695407345\n",
      "28 Train Loss 4.3352537 Test MSE 2.1725993741062277 Test RE 0.7045273955615864\n",
      "29 Train Loss 4.0002074 Test MSE 2.0479065397528378 Test RE 0.6840110642344174\n",
      "30 Train Loss 3.8060617 Test MSE 1.9043955499669607 Test RE 0.6596091010750825\n",
      "31 Train Loss 3.6505988 Test MSE 1.8536217812726106 Test RE 0.6507566612440164\n",
      "32 Train Loss 3.5494947 Test MSE 1.8229475893632234 Test RE 0.6453497581079121\n",
      "33 Train Loss 3.4398642 Test MSE 1.7622381656782142 Test RE 0.6345127621997665\n",
      "34 Train Loss 3.362063 Test MSE 1.7661029408011357 Test RE 0.6352081580174216\n",
      "35 Train Loss 3.2610524 Test MSE 1.7024166643503345 Test RE 0.6236500926151157\n",
      "36 Train Loss 3.2021122 Test MSE 1.7234670849593872 Test RE 0.6274939704715858\n",
      "37 Train Loss 3.0640068 Test MSE 1.7182818322188176 Test RE 0.6265493148287445\n",
      "38 Train Loss 2.89641 Test MSE 1.6955018497893948 Test RE 0.6223822441616693\n",
      "39 Train Loss 2.3808746 Test MSE 1.6178579727641968 Test RE 0.6079645505734301\n",
      "40 Train Loss 1.7662356 Test MSE 1.6003880926176521 Test RE 0.6046731937767846\n",
      "41 Train Loss 1.4453139 Test MSE 1.533516565011406 Test RE 0.5919053917929058\n",
      "42 Train Loss 1.171957 Test MSE 1.3889504917707656 Test RE 0.5633151652423775\n",
      "43 Train Loss 0.8497902 Test MSE 0.9525813087813385 Test RE 0.4665079918308789\n",
      "44 Train Loss 0.6217922 Test MSE 0.5605050971676038 Test RE 0.3578473813315118\n",
      "45 Train Loss 0.4116027 Test MSE 0.2992414019320317 Test RE 0.26146821415840915\n",
      "46 Train Loss 0.36698213 Test MSE 0.19637829696539622 Test RE 0.21181406986947093\n",
      "47 Train Loss 0.28883526 Test MSE 0.07713463613390015 Test RE 0.13274946450481964\n",
      "48 Train Loss 0.2395049 Test MSE 0.024671391351197988 Test RE 0.07507664926701642\n",
      "49 Train Loss 0.18226051 Test MSE 0.017750164023634194 Test RE 0.06368090776133213\n",
      "50 Train Loss 0.14876162 Test MSE 0.020162179148416844 Test RE 0.06786983524319372\n",
      "51 Train Loss 0.12651862 Test MSE 0.02222174425718115 Test RE 0.07125201207748114\n",
      "52 Train Loss 0.107555404 Test MSE 0.01572742975649808 Test RE 0.05994278783538964\n",
      "53 Train Loss 0.095480226 Test MSE 0.014971434446378808 Test RE 0.05848436337527022\n",
      "54 Train Loss 0.08701064 Test MSE 0.014678682694356097 Test RE 0.057909738197646284\n",
      "55 Train Loss 0.07915197 Test MSE 0.012913941460160928 Test RE 0.054317211580308895\n",
      "56 Train Loss 0.0692531 Test MSE 0.011220238374568444 Test RE 0.05063013694736671\n",
      "57 Train Loss 0.06253091 Test MSE 0.00971586551060512 Test RE 0.04711387306949001\n",
      "58 Train Loss 0.057174698 Test MSE 0.008710856941486489 Test RE 0.044610644842052835\n",
      "59 Train Loss 0.052501988 Test MSE 0.008288188743710907 Test RE 0.043514888650050626\n",
      "60 Train Loss 0.046426635 Test MSE 0.008898243281218894 Test RE 0.04508791969844095\n",
      "61 Train Loss 0.040576257 Test MSE 0.009828695603994537 Test RE 0.04738664951007217\n",
      "62 Train Loss 0.037902225 Test MSE 0.011956431286128747 Test RE 0.05226474627739313\n",
      "63 Train Loss 0.03327209 Test MSE 0.012626961730571958 Test RE 0.05371028939481956\n",
      "64 Train Loss 0.029480502 Test MSE 0.01050007828418391 Test RE 0.048978370120601515\n",
      "65 Train Loss 0.026426088 Test MSE 0.010229333761971682 Test RE 0.048342792626856965\n",
      "66 Train Loss 0.024416339 Test MSE 0.010940215157156773 Test RE 0.049994357550261236\n",
      "67 Train Loss 0.021212459 Test MSE 0.011194401682631326 Test RE 0.05057181068367877\n",
      "68 Train Loss 0.019703083 Test MSE 0.010002520542638886 Test RE 0.04780384023458103\n",
      "69 Train Loss 0.018105034 Test MSE 0.007666689441770113 Test RE 0.041851593267478254\n",
      "70 Train Loss 0.016435103 Test MSE 0.007143403727467229 Test RE 0.04039807380766764\n",
      "71 Train Loss 0.014744714 Test MSE 0.006896842602684151 Test RE 0.03969476339908351\n",
      "72 Train Loss 0.013381029 Test MSE 0.006312964299342086 Test RE 0.03797735611078989\n",
      "73 Train Loss 0.01205384 Test MSE 0.00428504649597436 Test RE 0.03128857827435083\n",
      "74 Train Loss 0.010658482 Test MSE 0.004619945119648768 Test RE 0.03248826123227414\n",
      "75 Train Loss 0.009920637 Test MSE 0.004007299482367783 Test RE 0.0302575639903151\n",
      "76 Train Loss 0.008928847 Test MSE 0.00348532023588769 Test RE 0.02821820629838282\n",
      "77 Train Loss 0.008062022 Test MSE 0.0040453755757640176 Test RE 0.03040097304472099\n",
      "78 Train Loss 0.0073235394 Test MSE 0.0035854212387403175 Test RE 0.02862056175247081\n",
      "79 Train Loss 0.006424506 Test MSE 0.002888854792036488 Test RE 0.025690402975597677\n",
      "80 Train Loss 0.0060625626 Test MSE 0.0027739630663130557 Test RE 0.025174357626209422\n",
      "81 Train Loss 0.0057862056 Test MSE 0.002631401983048862 Test RE 0.024518938205690677\n",
      "82 Train Loss 0.005514904 Test MSE 0.0022842998005354518 Test RE 0.02284465539312718\n",
      "83 Train Loss 0.0053497097 Test MSE 0.0020665851054268323 Test RE 0.021728748227968147\n",
      "84 Train Loss 0.0047710896 Test MSE 0.0024122397079167353 Test RE 0.02347568596647406\n",
      "85 Train Loss 0.004408438 Test MSE 0.0022632143521000626 Test RE 0.022738976065438263\n",
      "86 Train Loss 0.0042736386 Test MSE 0.0023310423139838964 Test RE 0.023077201323189724\n",
      "87 Train Loss 0.0040916237 Test MSE 0.002479204575226359 Test RE 0.02379930324013511\n",
      "88 Train Loss 0.0036867722 Test MSE 0.0022777713533495827 Test RE 0.022811987431152602\n",
      "89 Train Loss 0.0035179239 Test MSE 0.0023724521112762453 Test RE 0.02328127644207191\n",
      "90 Train Loss 0.0034078248 Test MSE 0.0021732094948682876 Test RE 0.022282240488675442\n",
      "91 Train Loss 0.0032660007 Test MSE 0.0020299549600497862 Test RE 0.021535316620041642\n",
      "92 Train Loss 0.0031750284 Test MSE 0.0020452276967865323 Test RE 0.021616177255677937\n",
      "93 Train Loss 0.0029618056 Test MSE 0.002034089616464714 Test RE 0.021557237264254986\n",
      "94 Train Loss 0.0028906087 Test MSE 0.0020008927513801267 Test RE 0.02138060379869534\n",
      "95 Train Loss 0.0028335305 Test MSE 0.00173307858866017 Test RE 0.019898355640308125\n",
      "96 Train Loss 0.0027256473 Test MSE 0.001580650551626763 Test RE 0.019003167391212578\n",
      "97 Train Loss 0.0026225785 Test MSE 0.0015558498873357656 Test RE 0.018853496586388414\n",
      "98 Train Loss 0.0025113614 Test MSE 0.0014819055833993672 Test RE 0.01840002137181016\n",
      "99 Train Loss 0.0024340493 Test MSE 0.0014939426579901867 Test RE 0.018474599162315655\n",
      "Training time: 74.48\n",
      "KG_stan_tune18\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.700558 Test MSE 8.635555812770713 Test RE 1.4046017591257927\n",
      "1 Train Loss 52.03322 Test MSE 9.599393046729773 Test RE 1.4809143702683731\n",
      "2 Train Loss 46.075623 Test MSE 8.912253848818809 Test RE 1.4269272584284605\n",
      "3 Train Loss 44.33257 Test MSE 8.657413852317125 Test RE 1.4063782769397786\n",
      "4 Train Loss 43.16874 Test MSE 8.690517661327462 Test RE 1.4090645328148752\n",
      "5 Train Loss 42.43957 Test MSE 8.359594818772702 Test RE 1.3819765517422333\n",
      "6 Train Loss 42.15915 Test MSE 8.330787936520228 Test RE 1.3795933745524025\n",
      "7 Train Loss 41.687263 Test MSE 8.301441341957677 Test RE 1.3771613065611787\n",
      "8 Train Loss 41.21917 Test MSE 8.59264714385563 Test RE 1.401107794917012\n",
      "9 Train Loss 40.748386 Test MSE 8.511914476317203 Test RE 1.3945101703243092\n",
      "10 Train Loss 39.913284 Test MSE 8.397076642825729 Test RE 1.3850712632819897\n",
      "11 Train Loss 39.122295 Test MSE 8.198679111894476 Test RE 1.368610932173513\n",
      "12 Train Loss 37.542717 Test MSE 8.343262673703183 Test RE 1.3806259075503766\n",
      "13 Train Loss 35.97876 Test MSE 8.062992258600351 Test RE 1.3572385348919136\n",
      "14 Train Loss 34.921833 Test MSE 8.104255285754808 Test RE 1.3607069930340419\n",
      "15 Train Loss 33.66697 Test MSE 8.377853695830451 Test RE 1.3834849727229435\n",
      "16 Train Loss 31.829224 Test MSE 8.117382464776371 Test RE 1.3618085758600966\n",
      "17 Train Loss 29.897446 Test MSE 7.986894960757794 Test RE 1.35081864579266\n",
      "18 Train Loss 28.728767 Test MSE 7.803294753364511 Test RE 1.3352022827844785\n",
      "19 Train Loss 27.462101 Test MSE 7.827918402241532 Test RE 1.3373072690384238\n",
      "20 Train Loss 25.894777 Test MSE 7.706392242009538 Test RE 1.3268860105523947\n",
      "21 Train Loss 24.438477 Test MSE 7.444454989963402 Test RE 1.304140897599837\n",
      "22 Train Loss 23.030273 Test MSE 7.1822706958949185 Test RE 1.280969959285519\n",
      "23 Train Loss 21.959087 Test MSE 7.491055978820515 Test RE 1.3082163767977515\n",
      "24 Train Loss 20.663841 Test MSE 7.648997968055275 Test RE 1.3219357055412015\n",
      "25 Train Loss 19.930254 Test MSE 7.587079858822531 Test RE 1.3165743445042988\n",
      "26 Train Loss 19.102942 Test MSE 7.681198619510669 Test RE 1.3247153170294448\n",
      "27 Train Loss 18.126587 Test MSE 7.834858886512422 Test RE 1.337899987508928\n",
      "28 Train Loss 17.170834 Test MSE 7.839110740716798 Test RE 1.338262966868628\n",
      "29 Train Loss 16.343233 Test MSE 7.941764839120369 Test RE 1.3469968244280157\n",
      "30 Train Loss 15.711884 Test MSE 7.836923503881103 Test RE 1.3380762554954218\n",
      "31 Train Loss 15.113825 Test MSE 7.792492411614088 Test RE 1.3342777818565101\n",
      "32 Train Loss 14.51985 Test MSE 8.173544592464925 Test RE 1.3665114608775797\n",
      "33 Train Loss 13.956505 Test MSE 8.172424251476034 Test RE 1.3664178043709374\n",
      "34 Train Loss 13.613635 Test MSE 8.20245846642069 Test RE 1.3689263409057315\n",
      "35 Train Loss 13.216012 Test MSE 8.293086489526583 Test RE 1.3764681211566276\n",
      "36 Train Loss 12.978781 Test MSE 8.246486296161121 Test RE 1.3725953746722452\n",
      "37 Train Loss 12.431982 Test MSE 7.611341143097364 Test RE 1.3186776761309753\n",
      "38 Train Loss 10.21353 Test MSE 6.538155506970439 Test RE 1.2221814370568744\n",
      "39 Train Loss 8.483671 Test MSE 6.772992154023641 Test RE 1.2439368875786092\n",
      "40 Train Loss 7.592548 Test MSE 6.683698689018466 Test RE 1.235709802446915\n",
      "41 Train Loss 7.0813036 Test MSE 6.712347689684666 Test RE 1.2383553432672898\n",
      "42 Train Loss 6.660435 Test MSE 6.514289017773615 Test RE 1.2199487088750827\n",
      "43 Train Loss 6.491274 Test MSE 6.285727232523534 Test RE 1.198355920273809\n",
      "44 Train Loss 6.3645906 Test MSE 6.330296274620855 Test RE 1.2025968960835913\n",
      "45 Train Loss 6.193143 Test MSE 6.1920508889830055 Test RE 1.1893928371634244\n",
      "46 Train Loss 6.0282574 Test MSE 6.2287305445110865 Test RE 1.1929104199262703\n",
      "47 Train Loss 5.781313 Test MSE 6.166258707467676 Test RE 1.1869131217585531\n",
      "48 Train Loss 5.5557194 Test MSE 6.215661756361816 Test RE 1.1916583124938538\n",
      "49 Train Loss 5.2736473 Test MSE 6.120430950165722 Test RE 1.1824943153241154\n",
      "50 Train Loss 4.9010296 Test MSE 6.0698415282711045 Test RE 1.177597124721745\n",
      "51 Train Loss 4.436112 Test MSE 6.162281307504335 Test RE 1.18653026483174\n",
      "52 Train Loss 3.9361343 Test MSE 5.962170212983377 Test RE 1.1671058489089583\n",
      "53 Train Loss 3.4113004 Test MSE 5.806309509291321 Test RE 1.1517498159331625\n",
      "54 Train Loss 3.069222 Test MSE 5.502085964385974 Test RE 1.1211707164896967\n",
      "55 Train Loss 2.845533 Test MSE 5.548832543925242 Test RE 1.1259234633606972\n",
      "56 Train Loss 2.4860742 Test MSE 5.603292631561204 Test RE 1.1314352687510238\n",
      "57 Train Loss 2.0832143 Test MSE 5.548350636979686 Test RE 1.1258745700021267\n",
      "58 Train Loss 1.9316084 Test MSE 5.489830692495848 Test RE 1.119921380165195\n",
      "59 Train Loss 1.8162374 Test MSE 5.469455160408552 Test RE 1.117841151476889\n",
      "60 Train Loss 1.7533273 Test MSE 5.419996142029493 Test RE 1.1127754840211288\n",
      "61 Train Loss 1.6863633 Test MSE 5.435827685625306 Test RE 1.1143994803594626\n",
      "62 Train Loss 1.6135854 Test MSE 5.399795676975248 Test RE 1.1106998768275242\n",
      "63 Train Loss 1.577023 Test MSE 5.4524501294232035 Test RE 1.1161020640368544\n",
      "64 Train Loss 1.5288901 Test MSE 5.523285569604625 Test RE 1.123328582230543\n",
      "65 Train Loss 1.5021396 Test MSE 5.600472861437969 Test RE 1.1311505442991454\n",
      "66 Train Loss 1.4621835 Test MSE 5.650983495612663 Test RE 1.1362400148736889\n",
      "67 Train Loss 1.4278182 Test MSE 5.631920359733051 Test RE 1.134321888939966\n",
      "68 Train Loss 1.4009479 Test MSE 5.676153391085137 Test RE 1.1387676516641552\n",
      "69 Train Loss 1.3841481 Test MSE 5.676876915519086 Test RE 1.1388402272192493\n",
      "70 Train Loss 1.3594253 Test MSE 5.682714203242093 Test RE 1.1394255869300682\n",
      "71 Train Loss 1.3257427 Test MSE 5.691453155567303 Test RE 1.1403013621597713\n",
      "72 Train Loss 1.3134809 Test MSE 5.726953772526493 Test RE 1.1438521663990355\n",
      "73 Train Loss 1.2920307 Test MSE 5.71918801488625 Test RE 1.1430763707146314\n",
      "74 Train Loss 1.2717798 Test MSE 5.732138328237258 Test RE 1.1443698084080962\n",
      "75 Train Loss 1.2557461 Test MSE 5.759080389044995 Test RE 1.1470560256195586\n",
      "76 Train Loss 1.2368169 Test MSE 5.749523500758798 Test RE 1.1461038911497767\n",
      "77 Train Loss 1.2199541 Test MSE 5.769847663355997 Test RE 1.1481278025943602\n",
      "78 Train Loss 1.1956625 Test MSE 5.793306754370032 Test RE 1.1504594683981644\n",
      "79 Train Loss 1.1748035 Test MSE 5.827537022551114 Test RE 1.153853258695637\n",
      "80 Train Loss 1.1610209 Test MSE 5.8304122946168855 Test RE 1.1541378757563785\n",
      "81 Train Loss 1.1442833 Test MSE 5.839697693885024 Test RE 1.155056538714173\n",
      "82 Train Loss 1.1282518 Test MSE 5.863603779355989 Test RE 1.1574183628729413\n",
      "83 Train Loss 1.1116501 Test MSE 5.908247098825793 Test RE 1.1618160866380756\n",
      "84 Train Loss 1.0991403 Test MSE 5.951343661196618 Test RE 1.1660457086494902\n",
      "85 Train Loss 1.0865296 Test MSE 5.957281445160294 Test RE 1.166627258109302\n",
      "86 Train Loss 1.070363 Test MSE 5.956865598460175 Test RE 1.1665865393211634\n",
      "87 Train Loss 1.0572895 Test MSE 5.980096721021608 Test RE 1.1688591055709683\n",
      "88 Train Loss 1.0455456 Test MSE 5.966000616755009 Test RE 1.1674806930260324\n",
      "89 Train Loss 1.0341918 Test MSE 5.959607768070832 Test RE 1.1668550202895214\n",
      "90 Train Loss 1.0238738 Test MSE 6.0056866992526095 Test RE 1.1713573217315696\n",
      "91 Train Loss 1.0149897 Test MSE 5.9990374791665575 Test RE 1.170708705676954\n",
      "92 Train Loss 1.004765 Test MSE 5.996009711070437 Test RE 1.1704132347913057\n",
      "93 Train Loss 0.99141943 Test MSE 6.004657391484291 Test RE 1.1712569386350244\n",
      "94 Train Loss 0.9847892 Test MSE 6.003782803500646 Test RE 1.1711716378026535\n",
      "95 Train Loss 0.97062546 Test MSE 6.031420917557623 Test RE 1.173864257574437\n",
      "96 Train Loss 0.9591742 Test MSE 6.049277122976118 Test RE 1.1756006038502054\n",
      "97 Train Loss 0.9432642 Test MSE 6.083510250464327 Test RE 1.1789222990489125\n",
      "98 Train Loss 0.9365051 Test MSE 6.097652302566782 Test RE 1.1802917964083055\n",
      "99 Train Loss 0.9207877 Test MSE 6.128075070239811 Test RE 1.1832325237942523\n",
      "Training time: 52.10\n",
      "KG_stan_tune18\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 56.26909 Test MSE 8.118739976992565 Test RE 1.3619224422758764\n",
      "1 Train Loss 46.95785 Test MSE 8.325235051789296 Test RE 1.37913351409072\n",
      "2 Train Loss 45.422974 Test MSE 8.353192824204424 Test RE 1.3814472736425265\n",
      "3 Train Loss 44.98522 Test MSE 8.389072407902779 Test RE 1.3844109692622808\n",
      "4 Train Loss 44.506943 Test MSE 8.079486139040844 Test RE 1.358626028063104\n",
      "5 Train Loss 44.343956 Test MSE 8.104664461921498 Test RE 1.3607413430035489\n",
      "6 Train Loss 43.69471 Test MSE 8.320340680756582 Test RE 1.3787280610648134\n",
      "7 Train Loss 43.336937 Test MSE 8.427877294904144 Test RE 1.3876091732613323\n",
      "8 Train Loss 43.038807 Test MSE 8.290559451918561 Test RE 1.3762583891266198\n",
      "9 Train Loss 42.71486 Test MSE 8.054938639158483 Test RE 1.3565605351395091\n",
      "10 Train Loss 41.299236 Test MSE 7.882548189439989 Test RE 1.3419655822500072\n",
      "11 Train Loss 40.560234 Test MSE 7.5772955601302545 Test RE 1.3157251434522725\n",
      "12 Train Loss 39.25763 Test MSE 7.192134305743018 Test RE 1.2818492531343888\n",
      "13 Train Loss 37.95491 Test MSE 6.891173823660877 Test RE 1.2547426566096678\n",
      "14 Train Loss 34.349037 Test MSE 5.23088215550312 Test RE 1.0931896929338476\n",
      "15 Train Loss 30.833084 Test MSE 3.7781584105755073 Test RE 0.9290693689823677\n",
      "16 Train Loss 24.738441 Test MSE 4.051323748996882 Test RE 0.9620696961938542\n",
      "17 Train Loss 21.858438 Test MSE 3.778735928365377 Test RE 0.9291403736264119\n",
      "18 Train Loss 16.774555 Test MSE 2.514096543219272 Test RE 0.7578775381952793\n",
      "19 Train Loss 12.023787 Test MSE 2.1679100432711227 Test RE 0.703766660123392\n",
      "20 Train Loss 9.757377 Test MSE 2.1496156258302674 Test RE 0.7007909189260755\n",
      "21 Train Loss 8.205414 Test MSE 2.097184684897287 Test RE 0.6921917185481821\n",
      "22 Train Loss 7.325851 Test MSE 2.107655726429206 Test RE 0.6939175903081557\n",
      "23 Train Loss 6.6206193 Test MSE 2.0047945749011054 Test RE 0.6767729616401936\n",
      "24 Train Loss 5.8333945 Test MSE 2.0920539802674134 Test RE 0.6913444860508476\n",
      "25 Train Loss 4.8202443 Test MSE 2.1004140564489857 Test RE 0.6927244528354168\n",
      "26 Train Loss 4.042789 Test MSE 2.115040387947241 Test RE 0.6951321780900225\n",
      "27 Train Loss 3.025957 Test MSE 1.8275858375515235 Test RE 0.6461702399400423\n",
      "28 Train Loss 2.2606812 Test MSE 1.4671086144651113 Test RE 0.5789475145990904\n",
      "29 Train Loss 1.9540253 Test MSE 1.2821186502487174 Test RE 0.5412179215434912\n",
      "30 Train Loss 1.6705638 Test MSE 0.7938447775392244 Test RE 0.42586883171473117\n",
      "31 Train Loss 1.3999418 Test MSE 0.7183212005114445 Test RE 0.4051048124919778\n",
      "32 Train Loss 1.1753174 Test MSE 0.4725983096551593 Test RE 0.328589848579313\n",
      "33 Train Loss 1.0417714 Test MSE 0.271652385304207 Test RE 0.24912357164677107\n",
      "34 Train Loss 0.73755455 Test MSE 0.11085705544079243 Test RE 0.15914380213821605\n",
      "35 Train Loss 0.59607685 Test MSE 0.05658856606317001 Test RE 0.11370312603032198\n",
      "36 Train Loss 0.48982644 Test MSE 0.060697858362126586 Test RE 0.11775917223600832\n",
      "37 Train Loss 0.4255962 Test MSE 0.06243143054498966 Test RE 0.11942897458730067\n",
      "38 Train Loss 0.37714073 Test MSE 0.05729453051607778 Test RE 0.11441017313573781\n",
      "39 Train Loss 0.3294701 Test MSE 0.044098685680166554 Test RE 0.1003739194999709\n",
      "40 Train Loss 0.29449877 Test MSE 0.03267303244988883 Test RE 0.0863978195777922\n",
      "41 Train Loss 0.26983112 Test MSE 0.023987599093023993 Test RE 0.074028926415735\n",
      "42 Train Loss 0.24217139 Test MSE 0.02305006889054226 Test RE 0.0725678362820921\n",
      "43 Train Loss 0.2213848 Test MSE 0.027510576122479004 Test RE 0.07927895245177835\n",
      "44 Train Loss 0.19074416 Test MSE 0.02312130744607084 Test RE 0.07267988886870179\n",
      "45 Train Loss 0.17223065 Test MSE 0.023170290605029276 Test RE 0.07275683536088798\n",
      "46 Train Loss 0.16427517 Test MSE 0.0222834594211933 Test RE 0.07135088552055395\n",
      "47 Train Loss 0.14193505 Test MSE 0.02166447687191764 Test RE 0.07035292584218618\n",
      "48 Train Loss 0.12354254 Test MSE 0.01665946786009759 Test RE 0.06169338825988447\n",
      "49 Train Loss 0.11297231 Test MSE 0.015286620656318176 Test RE 0.05909677814529892\n",
      "50 Train Loss 0.10311307 Test MSE 0.01289115742533382 Test RE 0.05426927456647947\n",
      "51 Train Loss 0.09061983 Test MSE 0.011671827633967057 Test RE 0.0516389607035164\n",
      "52 Train Loss 0.08450547 Test MSE 0.010518860449274796 Test RE 0.049022155928487174\n",
      "53 Train Loss 0.07690836 Test MSE 0.009258260628042027 Test RE 0.04599099033818145\n",
      "54 Train Loss 0.07328452 Test MSE 0.008832688972791547 Test RE 0.04492152891776459\n",
      "55 Train Loss 0.0687738 Test MSE 0.009149388335573893 Test RE 0.04571977567406439\n",
      "56 Train Loss 0.06513167 Test MSE 0.00848625481262941 Test RE 0.04403176498940779\n",
      "57 Train Loss 0.061677597 Test MSE 0.008461899599811234 Test RE 0.043968534885236464\n",
      "58 Train Loss 0.059243355 Test MSE 0.0085705088559838 Test RE 0.044249805315493246\n",
      "59 Train Loss 0.057199605 Test MSE 0.00825901719762406 Test RE 0.04343824250046494\n",
      "60 Train Loss 0.053243257 Test MSE 0.007258250315052544 Test RE 0.04072152475197608\n",
      "61 Train Loss 0.050268777 Test MSE 0.007774000140744463 Test RE 0.042143473956124264\n",
      "62 Train Loss 0.04916471 Test MSE 0.008249934561025315 Test RE 0.04341435089866225\n",
      "63 Train Loss 0.04541453 Test MSE 0.008115953089159585 Test RE 0.043060376654880314\n",
      "64 Train Loss 0.042518817 Test MSE 0.00719085528196932 Test RE 0.04053202805174904\n",
      "65 Train Loss 0.040927578 Test MSE 0.006888825386474575 Test RE 0.03967168515462909\n",
      "66 Train Loss 0.039494555 Test MSE 0.006781025773215304 Test RE 0.03936006054437127\n",
      "67 Train Loss 0.03493564 Test MSE 0.006797675572333009 Test RE 0.039408352303292454\n",
      "68 Train Loss 0.03302533 Test MSE 0.0062808068764937065 Test RE 0.03788050675110962\n",
      "69 Train Loss 0.031144323 Test MSE 0.005463705452061243 Test RE 0.035330655861096696\n",
      "70 Train Loss 0.029372165 Test MSE 0.005302258709429256 Test RE 0.03480474989975972\n",
      "71 Train Loss 0.027329868 Test MSE 0.004881469754468304 Test RE 0.03339514716663119\n",
      "72 Train Loss 0.026158405 Test MSE 0.005461771022944666 Test RE 0.03532440088446544\n",
      "73 Train Loss 0.025210265 Test MSE 0.005399910594267032 Test RE 0.03512378781892317\n",
      "74 Train Loss 0.024228789 Test MSE 0.005763893221390778 Test RE 0.036288249897828674\n",
      "75 Train Loss 0.023337036 Test MSE 0.005302060383000819 Test RE 0.034804098972799416\n",
      "76 Train Loss 0.022728696 Test MSE 0.005614858352080101 Test RE 0.035816031439464664\n",
      "77 Train Loss 0.02170809 Test MSE 0.005847720903593036 Test RE 0.0365511780278143\n",
      "78 Train Loss 0.021092046 Test MSE 0.005759720435899117 Test RE 0.03627511203314394\n",
      "79 Train Loss 0.020217365 Test MSE 0.005122080471379576 Test RE 0.03420828162214833\n",
      "80 Train Loss 0.019227875 Test MSE 0.005030926761529177 Test RE 0.03390252600864396\n",
      "81 Train Loss 0.018504063 Test MSE 0.004725107150423774 Test RE 0.03285593956198104\n",
      "82 Train Loss 0.01800546 Test MSE 0.004635747055314074 Test RE 0.03254377478970474\n",
      "83 Train Loss 0.017677078 Test MSE 0.004649342909841146 Test RE 0.032591462517503916\n",
      "84 Train Loss 0.017391667 Test MSE 0.004948671289200438 Test RE 0.033624231250397915\n",
      "85 Train Loss 0.016736131 Test MSE 0.005007818896987065 Test RE 0.033824576490012616\n",
      "86 Train Loss 0.016284935 Test MSE 0.005156286545322612 Test RE 0.0343223157468204\n",
      "87 Train Loss 0.015758531 Test MSE 0.00516948881528654 Test RE 0.034366227464335555\n",
      "88 Train Loss 0.015538773 Test MSE 0.005621503240089531 Test RE 0.03583721836274806\n",
      "89 Train Loss 0.015363818 Test MSE 0.005783584952363689 Test RE 0.036350184526642876\n",
      "90 Train Loss 0.015136181 Test MSE 0.006017591855990277 Test RE 0.03707826674123018\n",
      "91 Train Loss 0.014912798 Test MSE 0.005794480399911688 Test RE 0.036384407692853594\n",
      "92 Train Loss 0.014318056 Test MSE 0.00531043063620539 Test RE 0.034831560394937136\n",
      "93 Train Loss 0.014004667 Test MSE 0.005413862956204783 Test RE 0.035169135204240316\n",
      "94 Train Loss 0.013785642 Test MSE 0.005103678299143768 Test RE 0.03414677603655445\n",
      "95 Train Loss 0.013410742 Test MSE 0.004922329633444194 Test RE 0.033534621364834566\n",
      "96 Train Loss 0.011552009 Test MSE 0.004468497382827649 Test RE 0.03195132069352722\n",
      "97 Train Loss 0.010727755 Test MSE 0.003807322303804109 Test RE 0.02949292740103056\n",
      "98 Train Loss 0.010399127 Test MSE 0.003650629511514096 Test RE 0.02887965098581231\n",
      "99 Train Loss 0.010135124 Test MSE 0.003390822474627219 Test RE 0.027833036350278798\n",
      "Training time: 45.17\n",
      "KG_stan_tune18\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.92712 Test MSE 8.432803408703982 Test RE 1.3880146444081836\n",
      "1 Train Loss 46.352528 Test MSE 8.238459115597035 Test RE 1.3719271656260872\n",
      "2 Train Loss 44.040817 Test MSE 8.590603308979748 Test RE 1.4009411522495452\n",
      "3 Train Loss 43.06539 Test MSE 7.990598668794041 Test RE 1.3511318124254283\n",
      "4 Train Loss 42.583054 Test MSE 8.210776836722399 Test RE 1.3696203005698186\n",
      "5 Train Loss 41.978188 Test MSE 8.077457760765121 Test RE 1.3584554738683323\n",
      "6 Train Loss 41.116417 Test MSE 8.245250237237494 Test RE 1.3724925022317267\n",
      "7 Train Loss 39.90058 Test MSE 8.288475075450709 Test RE 1.3760853717962103\n",
      "8 Train Loss 39.391808 Test MSE 8.270986178615741 Test RE 1.3746328172925448\n",
      "9 Train Loss 37.666466 Test MSE 8.127588687269414 Test RE 1.3626644278076143\n",
      "10 Train Loss 36.488754 Test MSE 7.920653005016554 Test RE 1.3452052517518023\n",
      "11 Train Loss 34.53985 Test MSE 6.950381462161454 Test RE 1.2601213817204724\n",
      "12 Train Loss 33.617706 Test MSE 6.751408053585222 Test RE 1.2419532234169273\n",
      "13 Train Loss 30.75909 Test MSE 5.975855022570113 Test RE 1.1684444946062318\n",
      "14 Train Loss 26.662941 Test MSE 4.830093676351753 Test RE 1.050475280393645\n",
      "15 Train Loss 23.603386 Test MSE 4.7832726690545275 Test RE 1.0453714368048856\n",
      "16 Train Loss 20.943838 Test MSE 3.8075316552772898 Test RE 0.9326738957294161\n",
      "17 Train Loss 18.766922 Test MSE 3.509450869441045 Test RE 0.8954217591418707\n",
      "18 Train Loss 14.906154 Test MSE 2.059057256212773 Test RE 0.6858707338618975\n",
      "19 Train Loss 12.855629 Test MSE 2.4126218773510693 Test RE 0.7424251768503595\n",
      "20 Train Loss 11.16733 Test MSE 2.125279170538735 Test RE 0.6968126931423541\n",
      "21 Train Loss 10.234982 Test MSE 1.8311390715520768 Test RE 0.6467980843679489\n",
      "22 Train Loss 8.884814 Test MSE 1.6463885533803073 Test RE 0.6133017858069755\n",
      "23 Train Loss 7.567994 Test MSE 1.3347940362186062 Test RE 0.5522238876582825\n",
      "24 Train Loss 5.4074645 Test MSE 0.6646991485921502 Test RE 0.38969122050497884\n",
      "25 Train Loss 3.5313103 Test MSE 0.4194807824588773 Test RE 0.3095737264703813\n",
      "26 Train Loss 2.6391335 Test MSE 0.26740131417587304 Test RE 0.24716662585877994\n",
      "27 Train Loss 2.1016595 Test MSE 0.14203368569038374 Test RE 0.18013733721209693\n",
      "28 Train Loss 1.8097439 Test MSE 0.12436913094187108 Test RE 0.1685638182037417\n",
      "29 Train Loss 1.5321585 Test MSE 0.10501866734784997 Test RE 0.15489639552588175\n",
      "30 Train Loss 1.1739401 Test MSE 0.09213513616439171 Test RE 0.14508439440553197\n",
      "31 Train Loss 1.0032914 Test MSE 0.09627917845318737 Test RE 0.14831130222634517\n",
      "32 Train Loss 0.81161547 Test MSE 0.10249819185598473 Test RE 0.15302632985679948\n",
      "33 Train Loss 0.7525743 Test MSE 0.08591245273436984 Test RE 0.14009934965141335\n",
      "34 Train Loss 0.6429528 Test MSE 0.07092385850718311 Test RE 0.12729291667693768\n",
      "35 Train Loss 0.5824285 Test MSE 0.06067388660585592 Test RE 0.11773591628413295\n",
      "36 Train Loss 0.514424 Test MSE 0.07171447364611744 Test RE 0.1280004415797329\n",
      "37 Train Loss 0.45745942 Test MSE 0.059724177532928316 Test RE 0.1168108405791718\n",
      "38 Train Loss 0.40822846 Test MSE 0.05253716552225639 Test RE 0.10955731479281139\n",
      "39 Train Loss 0.37668166 Test MSE 0.04622666238039623 Test RE 0.10276715395098146\n",
      "40 Train Loss 0.34494832 Test MSE 0.044055695278593224 Test RE 0.1003249819044376\n",
      "41 Train Loss 0.3133007 Test MSE 0.04564713559000936 Test RE 0.10212094509603277\n",
      "42 Train Loss 0.27538502 Test MSE 0.03995442786410198 Test RE 0.09554116185026243\n",
      "43 Train Loss 0.2510625 Test MSE 0.04341861207139989 Test RE 0.09959694759966112\n",
      "44 Train Loss 0.21254092 Test MSE 0.03930710715161748 Test RE 0.09476404746658866\n",
      "45 Train Loss 0.19054501 Test MSE 0.031020887211462334 Test RE 0.08418508749799054\n",
      "46 Train Loss 0.16622986 Test MSE 0.024897838057803243 Test RE 0.07542040830112225\n",
      "47 Train Loss 0.16000704 Test MSE 0.02274010228345209 Test RE 0.07207825554020861\n",
      "48 Train Loss 0.14237598 Test MSE 0.015034072088185173 Test RE 0.05860657941777213\n",
      "49 Train Loss 0.12929747 Test MSE 0.01396531608459453 Test RE 0.05648504058882724\n",
      "50 Train Loss 0.12666424 Test MSE 0.013633775723082928 Test RE 0.05581052823560183\n",
      "51 Train Loss 0.11866816 Test MSE 0.01266905269761588 Test RE 0.05379973439441168\n",
      "52 Train Loss 0.10989374 Test MSE 0.01029520745484776 Test RE 0.04849819902797742\n",
      "53 Train Loss 0.10684733 Test MSE 0.009724460795921036 Test RE 0.04713470845763274\n",
      "54 Train Loss 0.10440741 Test MSE 0.009117263125291463 Test RE 0.045639439760206235\n",
      "55 Train Loss 0.10206113 Test MSE 0.009493192069969156 Test RE 0.046570853166036805\n",
      "56 Train Loss 0.096290536 Test MSE 0.01048667754117295 Test RE 0.04894710577747443\n",
      "57 Train Loss 0.091703966 Test MSE 0.009957663872955486 Test RE 0.04769653075497673\n",
      "58 Train Loss 0.08884365 Test MSE 0.009111558772404126 Test RE 0.04562516002509873\n",
      "59 Train Loss 0.08696537 Test MSE 0.009078660041913746 Test RE 0.04554271709513527\n",
      "60 Train Loss 0.08257658 Test MSE 0.008111773304140613 Test RE 0.04304928699637347\n",
      "61 Train Loss 0.081238955 Test MSE 0.0077713934044534895 Test RE 0.04213640770119092\n",
      "62 Train Loss 0.07802379 Test MSE 0.007507454135143842 Test RE 0.04141468897173421\n",
      "63 Train Loss 0.07633677 Test MSE 0.007522045780404761 Test RE 0.04145491666327674\n",
      "64 Train Loss 0.07496613 Test MSE 0.006823390293319826 Test RE 0.039482820275136415\n",
      "65 Train Loss 0.073273934 Test MSE 0.006934488329123957 Test RE 0.03980295091780972\n",
      "66 Train Loss 0.07185141 Test MSE 0.006789172197912364 Test RE 0.03938369616647375\n",
      "67 Train Loss 0.06963161 Test MSE 0.006268508789328042 Test RE 0.037843402757232844\n",
      "68 Train Loss 0.06388943 Test MSE 0.006328806178893655 Test RE 0.038024976824943955\n",
      "69 Train Loss 0.0558622 Test MSE 0.007306645592565778 Test RE 0.040857057097346786\n",
      "70 Train Loss 0.05230347 Test MSE 0.006617477763830975 Test RE 0.038882511185480584\n",
      "71 Train Loss 0.050691 Test MSE 0.006788352301458261 Test RE 0.0393813180026234\n",
      "72 Train Loss 0.046899177 Test MSE 0.00609123323021649 Test RE 0.03730445286174621\n",
      "73 Train Loss 0.044733014 Test MSE 0.0063539564334193525 Test RE 0.03810045627524561\n",
      "74 Train Loss 0.043734357 Test MSE 0.0059449746130962045 Test RE 0.03685386685277471\n",
      "75 Train Loss 0.042346887 Test MSE 0.005682824815959705 Test RE 0.036032151463359835\n",
      "76 Train Loss 0.039351538 Test MSE 0.005584001135500684 Test RE 0.0357174799197872\n",
      "77 Train Loss 0.03798023 Test MSE 0.006098963877921431 Test RE 0.03732811770339085\n",
      "78 Train Loss 0.03739419 Test MSE 0.006292797574029478 Test RE 0.03791664837507285\n",
      "79 Train Loss 0.036585324 Test MSE 0.006027897299570542 Test RE 0.037110002403934375\n",
      "80 Train Loss 0.035509884 Test MSE 0.005310125392460059 Test RE 0.03483055932087487\n",
      "81 Train Loss 0.03400674 Test MSE 0.004937824114834119 Test RE 0.03358735994066179\n",
      "82 Train Loss 0.033327498 Test MSE 0.005017507929848735 Test RE 0.03385728225202647\n",
      "83 Train Loss 0.032104477 Test MSE 0.004942313264230292 Test RE 0.03360262419664903\n",
      "84 Train Loss 0.031344928 Test MSE 0.004365161054998993 Test RE 0.0315797142682502\n",
      "85 Train Loss 0.029445175 Test MSE 0.0036243111407657626 Test RE 0.028775362095561544\n",
      "86 Train Loss 0.027906347 Test MSE 0.003615124404983331 Test RE 0.028738869729486992\n",
      "87 Train Loss 0.026982034 Test MSE 0.003578203385716253 Test RE 0.02859173904715088\n",
      "88 Train Loss 0.025740068 Test MSE 0.0036872800929650482 Test RE 0.02902425791610711\n",
      "89 Train Loss 0.024040034 Test MSE 0.004445415612924236 Test RE 0.0318686924847155\n",
      "90 Train Loss 0.021995055 Test MSE 0.0042269515517726125 Test RE 0.031075755464639913\n",
      "91 Train Loss 0.020623345 Test MSE 0.0034752384398324346 Test RE 0.028177364107120677\n",
      "92 Train Loss 0.02011137 Test MSE 0.0036320910344213426 Test RE 0.028806229926503935\n",
      "93 Train Loss 0.01968677 Test MSE 0.0036440663235845416 Test RE 0.0288536790481154\n",
      "94 Train Loss 0.018543515 Test MSE 0.0033338486395050426 Test RE 0.027598215374044412\n",
      "95 Train Loss 0.017692806 Test MSE 0.0033103876391487545 Test RE 0.02750093668006607\n",
      "96 Train Loss 0.017251354 Test MSE 0.003309772274235904 Test RE 0.027498380499359047\n",
      "97 Train Loss 0.016844578 Test MSE 0.0031468481655931363 Test RE 0.02681303374173817\n",
      "98 Train Loss 0.016468456 Test MSE 0.002797432351018265 Test RE 0.025280627921626133\n",
      "99 Train Loss 0.01569957 Test MSE 0.002728207478878345 Test RE 0.024965873051371424\n",
      "Training time: 45.75\n",
      "KG_stan_tune18\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.66897 Test MSE 8.612160075739217 Test RE 1.4026977715999707\n",
      "1 Train Loss 49.02791 Test MSE 8.387245216924978 Test RE 1.3842601944886073\n",
      "2 Train Loss 46.23736 Test MSE 8.458827946031235 Test RE 1.390154775670838\n",
      "3 Train Loss 45.480434 Test MSE 8.323589420753098 Test RE 1.3789972021989347\n",
      "4 Train Loss 45.045395 Test MSE 8.189360675293898 Test RE 1.3678329446542765\n",
      "5 Train Loss 44.56836 Test MSE 8.499167670044493 Test RE 1.3934656220703714\n",
      "6 Train Loss 44.13772 Test MSE 8.47914302873039 Test RE 1.3918231021505618\n",
      "7 Train Loss 43.58789 Test MSE 8.597942523728307 Test RE 1.4015394578934364\n",
      "8 Train Loss 43.25404 Test MSE 8.623245548435003 Test RE 1.4036002494407642\n",
      "9 Train Loss 42.12596 Test MSE 8.566917869258 Test RE 1.399008528349788\n",
      "10 Train Loss 40.01003 Test MSE 8.985613149000931 Test RE 1.4327879452688965\n",
      "11 Train Loss 34.5552 Test MSE 8.823054069515509 Test RE 1.4197684811825464\n",
      "12 Train Loss 32.98707 Test MSE 9.218583216329362 Test RE 1.4512430418974434\n",
      "13 Train Loss 32.13618 Test MSE 8.688018170177413 Test RE 1.4088618867964762\n",
      "14 Train Loss 31.327984 Test MSE 8.400529559897455 Test RE 1.3853560078939966\n",
      "15 Train Loss 29.876507 Test MSE 7.947111330145353 Test RE 1.3474501553259621\n",
      "16 Train Loss 28.469559 Test MSE 7.6872689171419895 Test RE 1.3252386616618552\n",
      "17 Train Loss 26.53933 Test MSE 7.636699347436387 Test RE 1.3208725253542057\n",
      "18 Train Loss 25.494823 Test MSE 8.124521069529717 Test RE 1.3624072464813266\n",
      "19 Train Loss 24.99789 Test MSE 7.8618372740100435 Test RE 1.3402014562743103\n",
      "20 Train Loss 24.465315 Test MSE 7.956201232448914 Test RE 1.3482205415326678\n",
      "21 Train Loss 23.94542 Test MSE 7.777623725614894 Test RE 1.3330042207841135\n",
      "22 Train Loss 23.024038 Test MSE 7.212748345461865 Test RE 1.283684951916523\n",
      "23 Train Loss 22.305843 Test MSE 6.485161638467402 Test RE 1.2172182713341837\n",
      "24 Train Loss 21.698948 Test MSE 6.560694647195936 Test RE 1.224286252306851\n",
      "25 Train Loss 21.025087 Test MSE 5.892240954351149 Test RE 1.1602412703058467\n",
      "26 Train Loss 20.224548 Test MSE 5.68198254941562 Test RE 1.1393522336083697\n",
      "27 Train Loss 19.24316 Test MSE 5.788961638211503 Test RE 1.150027951657476\n",
      "28 Train Loss 18.633863 Test MSE 5.598265577791402 Test RE 1.1309276152520737\n",
      "29 Train Loss 18.413334 Test MSE 5.718904390828589 Test RE 1.143048026832843\n",
      "30 Train Loss 17.995903 Test MSE 5.81051235087088 Test RE 1.152166582070527\n",
      "31 Train Loss 17.518454 Test MSE 5.884962194735135 Test RE 1.159524418511196\n",
      "32 Train Loss 16.891443 Test MSE 6.093350094976029 Test RE 1.1798753446279413\n",
      "33 Train Loss 16.43378 Test MSE 6.055607939834718 Test RE 1.1762156001353161\n",
      "34 Train Loss 16.045591 Test MSE 6.00081124536471 Test RE 1.1708817676108783\n",
      "35 Train Loss 15.791667 Test MSE 5.995212283529215 Test RE 1.1703354037981684\n",
      "36 Train Loss 15.346434 Test MSE 5.897372735737411 Test RE 1.1607464099250244\n",
      "37 Train Loss 15.16529 Test MSE 5.815770802325539 Test RE 1.1526878133793064\n",
      "38 Train Loss 14.859535 Test MSE 5.7338329185937384 Test RE 1.1445389507619286\n",
      "39 Train Loss 14.714277 Test MSE 5.7162336893674395 Test RE 1.1427810966383658\n",
      "40 Train Loss 14.55332 Test MSE 5.824411856349867 Test RE 1.1535438255018846\n",
      "41 Train Loss 14.376509 Test MSE 5.953845232156402 Test RE 1.1662907490796657\n",
      "42 Train Loss 14.189542 Test MSE 5.938282143117221 Test RE 1.1647654353430272\n",
      "43 Train Loss 13.81641 Test MSE 5.807002211306447 Test RE 1.1518185166821737\n",
      "44 Train Loss 13.654627 Test MSE 5.744294523170532 Test RE 1.1455826031881386\n",
      "45 Train Loss 13.294006 Test MSE 5.609997321319457 Test RE 1.1321119828775437\n",
      "46 Train Loss 12.424959 Test MSE 4.192254924896353 Test RE 0.9786601441541398\n",
      "47 Train Loss 11.368261 Test MSE 3.986544137151292 Test RE 0.9543470791678146\n",
      "48 Train Loss 10.369408 Test MSE 3.668629975956679 Test RE 0.915503513642926\n",
      "49 Train Loss 9.972948 Test MSE 3.6676906293047176 Test RE 0.9153862995573012\n",
      "50 Train Loss 9.615381 Test MSE 3.5726483104745013 Test RE 0.9034480681637139\n",
      "51 Train Loss 9.23483 Test MSE 3.5292949277864905 Test RE 0.8979497549454589\n",
      "52 Train Loss 8.890976 Test MSE 3.3736370591926677 Test RE 0.8779246429463068\n",
      "53 Train Loss 8.514847 Test MSE 3.395939001877224 Test RE 0.880821690412509\n",
      "54 Train Loss 8.252006 Test MSE 3.3212614524313597 Test RE 0.8710831095181644\n",
      "55 Train Loss 7.8147583 Test MSE 3.1475225023063294 Test RE 0.8479934194975177\n",
      "56 Train Loss 6.051616 Test MSE 2.162261721823982 Test RE 0.7028492574583523\n",
      "57 Train Loss 4.638004 Test MSE 1.7659668452778339 Test RE 0.6351836830419904\n",
      "58 Train Loss 3.8512821 Test MSE 1.907972687529692 Test RE 0.6602283016211622\n",
      "59 Train Loss 3.4904065 Test MSE 1.9756173702779893 Test RE 0.6718301319107624\n",
      "60 Train Loss 3.2879322 Test MSE 1.9852545577487495 Test RE 0.673466753557793\n",
      "61 Train Loss 3.1316693 Test MSE 1.9858772725469014 Test RE 0.6735723684348555\n",
      "62 Train Loss 2.9708996 Test MSE 1.9665387643586736 Test RE 0.6702847151978351\n",
      "63 Train Loss 2.8330998 Test MSE 2.0729763843811893 Test RE 0.6881850558844815\n",
      "64 Train Loss 2.7334027 Test MSE 2.1331526671172973 Test RE 0.6981022367740274\n",
      "65 Train Loss 2.6146972 Test MSE 2.1211747174023636 Test RE 0.6961395069365649\n",
      "66 Train Loss 2.483088 Test MSE 2.2405797109868892 Test RE 0.7154647801057755\n",
      "67 Train Loss 2.3951015 Test MSE 2.2515978637642333 Test RE 0.717221788034388\n",
      "68 Train Loss 2.2802544 Test MSE 2.2685961227412417 Test RE 0.7199240020063785\n",
      "69 Train Loss 2.1633086 Test MSE 2.331266860963261 Test RE 0.7298003299646726\n",
      "70 Train Loss 2.0277045 Test MSE 2.3457128579913125 Test RE 0.7320579890276895\n",
      "71 Train Loss 1.9579364 Test MSE 2.3447850802972803 Test RE 0.7319132027120833\n",
      "72 Train Loss 1.872612 Test MSE 2.4016788731027203 Test RE 0.7407395427746001\n",
      "73 Train Loss 1.748636 Test MSE 2.437151359590849 Test RE 0.7461898052686198\n",
      "74 Train Loss 1.6970686 Test MSE 2.409075206539762 Test RE 0.7418792756979821\n",
      "75 Train Loss 1.6473706 Test MSE 2.3848065379711736 Test RE 0.7381330257833201\n",
      "76 Train Loss 1.5962709 Test MSE 2.3837393760215106 Test RE 0.7379678560708841\n",
      "77 Train Loss 1.5535947 Test MSE 2.3794768846065 Test RE 0.7373077610250683\n",
      "78 Train Loss 1.469311 Test MSE 2.385378479843724 Test RE 0.7382215327270364\n",
      "79 Train Loss 1.4361633 Test MSE 2.4080173445903026 Test RE 0.7417163725165618\n",
      "80 Train Loss 1.3733177 Test MSE 2.4323843870258943 Test RE 0.7454596890635463\n",
      "81 Train Loss 1.3362976 Test MSE 2.418500456347707 Test RE 0.74332912076213\n",
      "82 Train Loss 1.2931285 Test MSE 2.4166435744421504 Test RE 0.7430437084873625\n",
      "83 Train Loss 1.2677846 Test MSE 2.4431853339796517 Test RE 0.7471129540812834\n",
      "84 Train Loss 1.2332939 Test MSE 2.4438381567072875 Test RE 0.7472127622565793\n",
      "85 Train Loss 1.1981988 Test MSE 2.448368963476921 Test RE 0.747905097168514\n",
      "86 Train Loss 1.1744019 Test MSE 2.450548255562019 Test RE 0.7482378781239534\n",
      "87 Train Loss 1.1363951 Test MSE 2.446101249341588 Test RE 0.7475586567645263\n",
      "88 Train Loss 1.1215732 Test MSE 2.4514243950688477 Test RE 0.7483716241498048\n",
      "89 Train Loss 1.1055442 Test MSE 2.4530997824093816 Test RE 0.7486273118626793\n",
      "90 Train Loss 1.0912391 Test MSE 2.4717151086071554 Test RE 0.751462419378012\n",
      "91 Train Loss 1.0790453 Test MSE 2.4813502582682716 Test RE 0.752925656474481\n",
      "92 Train Loss 1.0720091 Test MSE 2.4839554184554684 Test RE 0.7533207996766523\n",
      "93 Train Loss 1.046589 Test MSE 2.4983863947817815 Test RE 0.7555059054909312\n",
      "94 Train Loss 1.0394332 Test MSE 2.528581554334474 Test RE 0.7600576648281909\n",
      "95 Train Loss 1.0146072 Test MSE 2.512141671042615 Test RE 0.7575828315680335\n",
      "96 Train Loss 1.0048943 Test MSE 2.502508552349788 Test RE 0.7561289137759095\n",
      "97 Train Loss 0.9980599 Test MSE 2.4874055952810785 Test RE 0.75384379377872\n",
      "98 Train Loss 0.9643131 Test MSE 2.4920332789030626 Test RE 0.7545447107355846\n",
      "99 Train Loss 0.94527304 Test MSE 2.512984145616947 Test RE 0.7577098528223086\n",
      "Training time: 44.55\n",
      "KG_stan_tune18\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.255775 Test MSE 8.528052286551187 Test RE 1.3958314761314796\n",
      "1 Train Loss 51.84326 Test MSE 9.213689212115492 Test RE 1.4508577694383582\n",
      "2 Train Loss 45.049988 Test MSE 8.138483537568506 Test RE 1.3635774324920809\n",
      "3 Train Loss 43.23147 Test MSE 8.18497301168103 Test RE 1.3674664694695602\n",
      "4 Train Loss 42.243927 Test MSE 8.086074350384504 Test RE 1.3591798436957077\n",
      "5 Train Loss 37.98597 Test MSE 6.237718915328099 Test RE 1.193770824442548\n",
      "6 Train Loss 31.16281 Test MSE 6.160431229799935 Test RE 1.1863521377822088\n",
      "7 Train Loss 26.763641 Test MSE 5.791436413977968 Test RE 1.150273743336211\n",
      "8 Train Loss 24.732756 Test MSE 5.597534142946614 Test RE 1.130853732825972\n",
      "9 Train Loss 23.847382 Test MSE 5.309369320708889 Test RE 1.1013605804126794\n",
      "10 Train Loss 22.942516 Test MSE 5.390362405883234 Test RE 1.1097292740818285\n",
      "11 Train Loss 21.951637 Test MSE 5.3217740344386275 Test RE 1.1026464291875897\n",
      "12 Train Loss 19.130192 Test MSE 4.690560828271904 Test RE 1.0351909020301016\n",
      "13 Train Loss 16.939611 Test MSE 5.231188428236206 Test RE 1.0932216960725445\n",
      "14 Train Loss 15.212715 Test MSE 5.674403120421881 Test RE 1.1385920657392405\n",
      "15 Train Loss 14.37023 Test MSE 5.885137644029555 Test RE 1.1595417029234065\n",
      "16 Train Loss 13.668879 Test MSE 5.917636262499319 Test RE 1.162738877342057\n",
      "17 Train Loss 13.185321 Test MSE 5.934134694288638 Test RE 1.164358613242947\n",
      "18 Train Loss 12.779761 Test MSE 5.949349948999285 Test RE 1.1658503784504\n",
      "19 Train Loss 12.612675 Test MSE 5.924298242880598 Test RE 1.163393189668045\n",
      "20 Train Loss 12.39502 Test MSE 5.952891159798484 Test RE 1.1661972993591674\n",
      "21 Train Loss 12.243077 Test MSE 5.9818508942149835 Test RE 1.1690305267925\n",
      "22 Train Loss 12.107146 Test MSE 5.906988346981172 Test RE 1.1616923176064913\n",
      "23 Train Loss 11.9977665 Test MSE 5.878944322764373 Test RE 1.1589314109399644\n",
      "24 Train Loss 11.768873 Test MSE 5.89754440230762 Test RE 1.1607633038805156\n",
      "25 Train Loss 11.360764 Test MSE 5.711453871571725 Test RE 1.1423032096183015\n",
      "26 Train Loss 9.372329 Test MSE 4.860452189978491 Test RE 1.0537713773553594\n",
      "27 Train Loss 7.1149077 Test MSE 4.330772353022811 Test RE 0.994696839649248\n",
      "28 Train Loss 6.2907076 Test MSE 3.9606055115829175 Test RE 0.9512372616527011\n",
      "29 Train Loss 5.358087 Test MSE 3.270170595088046 Test RE 0.8643572216134365\n",
      "30 Train Loss 4.9069138 Test MSE 3.1118172683204834 Test RE 0.8431699176515954\n",
      "31 Train Loss 4.597005 Test MSE 3.046298290991191 Test RE 0.8342462702717418\n",
      "32 Train Loss 4.3490705 Test MSE 2.8561718746909603 Test RE 0.8077932677898556\n",
      "33 Train Loss 4.0763607 Test MSE 2.644928960678274 Test RE 0.7773472495415175\n",
      "34 Train Loss 3.8127882 Test MSE 2.3309417686454936 Test RE 0.7297494433080514\n",
      "35 Train Loss 3.453145 Test MSE 2.0531521139070126 Test RE 0.6848865280320715\n",
      "36 Train Loss 2.3550239 Test MSE 1.3749276196062028 Test RE 0.5604643308361402\n",
      "37 Train Loss 1.8584812 Test MSE 1.3496768406950503 Test RE 0.555293970955549\n",
      "38 Train Loss 1.4182316 Test MSE 1.1945124248852956 Test RE 0.5224002739590022\n",
      "39 Train Loss 0.8661739 Test MSE 0.6487997227078038 Test RE 0.38500235681309203\n",
      "40 Train Loss 0.64105 Test MSE 0.49010010202372684 Test RE 0.33461889193111743\n",
      "41 Train Loss 0.46772963 Test MSE 0.32628994494121627 Test RE 0.2730297086147749\n",
      "42 Train Loss 0.35035765 Test MSE 0.23842702671500543 Test RE 0.2333919119511747\n",
      "43 Train Loss 0.26439247 Test MSE 0.1485137393203773 Test RE 0.18420074263242134\n",
      "44 Train Loss 0.19327296 Test MSE 0.12501671927668626 Test RE 0.16900210313693528\n",
      "45 Train Loss 0.15881947 Test MSE 0.08455501527558908 Test RE 0.13898814108936944\n",
      "46 Train Loss 0.10946432 Test MSE 0.04177043610204649 Test RE 0.09768830294385078\n",
      "47 Train Loss 0.09042165 Test MSE 0.03092043697909873 Test RE 0.08404867507967391\n",
      "48 Train Loss 0.07165964 Test MSE 0.025586101915326818 Test RE 0.07645574473369131\n",
      "49 Train Loss 0.05794848 Test MSE 0.020170516093013305 Test RE 0.06788386568535384\n",
      "50 Train Loss 0.04663423 Test MSE 0.01341636153831175 Test RE 0.05536374207902312\n",
      "51 Train Loss 0.035726305 Test MSE 0.0074656497952888265 Test RE 0.04129922169164868\n",
      "52 Train Loss 0.029947698 Test MSE 0.006420697956194197 Test RE 0.03830003584215082\n",
      "53 Train Loss 0.024176795 Test MSE 0.005910210976839585 Test RE 0.03674595614332331\n",
      "54 Train Loss 0.01991468 Test MSE 0.004786565001440324 Test RE 0.03306892222988401\n",
      "55 Train Loss 0.016334953 Test MSE 0.004103428448996044 Test RE 0.03061832952877328\n",
      "56 Train Loss 0.014824724 Test MSE 0.00302834202611112 Test RE 0.026303317186287582\n",
      "57 Train Loss 0.012435559 Test MSE 0.001882875742738689 Test RE 0.02074048417289197\n",
      "58 Train Loss 0.010213175 Test MSE 0.0017373581722142691 Test RE 0.019922908528571266\n",
      "59 Train Loss 0.00882803 Test MSE 0.001601973735932529 Test RE 0.019130915615971703\n",
      "60 Train Loss 0.007704816 Test MSE 0.0013466826581628917 Test RE 0.017540448508218193\n",
      "61 Train Loss 0.0063260756 Test MSE 0.0012967798546759024 Test RE 0.01721239039873222\n",
      "62 Train Loss 0.005457015 Test MSE 0.0013581820254736409 Test RE 0.017615178548823184\n",
      "63 Train Loss 0.004745302 Test MSE 0.001625177391470904 Test RE 0.019268967591810224\n",
      "64 Train Loss 0.0043167435 Test MSE 0.0014134115213054492 Test RE 0.017969764014543553\n",
      "65 Train Loss 0.003852915 Test MSE 0.0011386262090599525 Test RE 0.01612867342642813\n",
      "66 Train Loss 0.0033642522 Test MSE 0.0009301565898863094 Test RE 0.014577602168947993\n",
      "67 Train Loss 0.0027695398 Test MSE 0.001057078580257904 Test RE 0.015540382236508292\n",
      "68 Train Loss 0.0025722187 Test MSE 0.0009996510004070063 Test RE 0.015112359030690317\n",
      "69 Train Loss 0.0022994108 Test MSE 0.0008516590868527546 Test RE 0.01394893185277925\n",
      "70 Train Loss 0.0021679837 Test MSE 0.0008139229187618253 Test RE 0.01363639896726848\n",
      "71 Train Loss 0.0019128736 Test MSE 0.0007543505363364212 Test RE 0.013127881927521349\n",
      "72 Train Loss 0.0018631535 Test MSE 0.0007834412176895475 Test RE 0.013378618463427168\n",
      "73 Train Loss 0.001610732 Test MSE 0.0006759862304999605 Test RE 0.012427305797666996\n",
      "74 Train Loss 0.0014729926 Test MSE 0.0006554228691515303 Test RE 0.012236828000428489\n",
      "75 Train Loss 0.0012760367 Test MSE 0.0006701567232661037 Test RE 0.01237360504968077\n",
      "76 Train Loss 0.0011794198 Test MSE 0.000633536296499962 Test RE 0.012030780716177789\n",
      "77 Train Loss 0.0011035267 Test MSE 0.0005735390672294163 Test RE 0.01144694412974854\n",
      "78 Train Loss 0.0010620761 Test MSE 0.0005082324833131708 Test RE 0.01077554561973663\n",
      "79 Train Loss 0.0009303783 Test MSE 0.0003876127329560261 Test RE 0.009410378197280002\n",
      "80 Train Loss 0.00089655374 Test MSE 0.000355617668144317 Test RE 0.00901362996777842\n",
      "81 Train Loss 0.0008263779 Test MSE 0.0003001246451011051 Test RE 0.00828054439715604\n",
      "82 Train Loss 0.0008027252 Test MSE 0.0002865560257251064 Test RE 0.00809119807409664\n",
      "83 Train Loss 0.0007074283 Test MSE 0.0002610769035972852 Test RE 0.0077231111806367455\n",
      "84 Train Loss 0.00068533805 Test MSE 0.0002507358725088142 Test RE 0.007568612950124932\n",
      "85 Train Loss 0.00063203706 Test MSE 0.00021126947032385098 Test RE 0.006947466031208409\n",
      "86 Train Loss 0.00059212086 Test MSE 0.00018053204122511337 Test RE 0.006422220412375087\n",
      "87 Train Loss 0.0005831495 Test MSE 0.0001907050199765309 Test RE 0.006600686750789182\n",
      "88 Train Loss 0.00052827335 Test MSE 0.00021926133528076764 Test RE 0.007077650085267675\n",
      "89 Train Loss 0.00051037956 Test MSE 0.00022245964825683265 Test RE 0.007129083203298969\n",
      "90 Train Loss 0.0004993318 Test MSE 0.00022601436508480098 Test RE 0.00718581582346967\n",
      "91 Train Loss 0.0004504334 Test MSE 0.00022297786375554055 Test RE 0.007137381904725048\n",
      "92 Train Loss 0.00043356206 Test MSE 0.00022172575483480443 Test RE 0.007117314081309182\n",
      "93 Train Loss 0.00041594644 Test MSE 0.00023017816383158119 Test RE 0.007251704871207234\n",
      "94 Train Loss 0.0003750691 Test MSE 0.0002586939713257378 Test RE 0.007687784735897336\n",
      "95 Train Loss 0.00037020692 Test MSE 0.00025443252986310973 Test RE 0.007624201721809611\n",
      "96 Train Loss 0.00034771406 Test MSE 0.00024975974507037655 Test RE 0.007553866086971581\n",
      "97 Train Loss 0.00033488293 Test MSE 0.000249197565805865 Test RE 0.007545359873860466\n",
      "98 Train Loss 0.00032655292 Test MSE 0.00026229434741550754 Test RE 0.007741097295124456\n",
      "99 Train Loss 0.00030556283 Test MSE 0.0002419769419216652 Test RE 0.007435241038464321\n",
      "Training time: 44.27\n",
      "KG_stan_tune18\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.729748 Test MSE 7.342913342573242 Test RE 1.2952161820733894\n",
      "1 Train Loss 44.307476 Test MSE 8.089860846815462 Test RE 1.3594980405764825\n",
      "2 Train Loss 39.835567 Test MSE 8.087544557103374 Test RE 1.359303400840289\n",
      "3 Train Loss 35.44449 Test MSE 7.647893153440774 Test RE 1.3218402324717262\n",
      "4 Train Loss 33.294685 Test MSE 7.572142461404331 Test RE 1.3152776741256857\n",
      "5 Train Loss 32.47515 Test MSE 7.346108062509874 Test RE 1.2954979096925652\n",
      "6 Train Loss 31.61575 Test MSE 7.673887484904932 Test RE 1.324084720281815\n",
      "7 Train Loss 30.956734 Test MSE 7.804410981050416 Test RE 1.3352977768358236\n",
      "8 Train Loss 30.408602 Test MSE 7.5778426859598325 Test RE 1.3157726441872437\n",
      "9 Train Loss 29.777773 Test MSE 7.462669277470287 Test RE 1.3057353383856343\n",
      "10 Train Loss 29.245266 Test MSE 7.630896115045665 Test RE 1.3203705554143625\n",
      "11 Train Loss 27.935532 Test MSE 8.042893810348904 Test RE 1.3555458997096879\n",
      "12 Train Loss 26.5534 Test MSE 8.392414832039169 Test RE 1.3846867344242202\n",
      "13 Train Loss 25.424198 Test MSE 8.597364638088054 Test RE 1.40149235690768\n",
      "14 Train Loss 24.370728 Test MSE 8.828495238186234 Test RE 1.4202061986132108\n",
      "15 Train Loss 23.019691 Test MSE 8.938246773296296 Test RE 1.4290065870052695\n",
      "16 Train Loss 21.26655 Test MSE 8.521870356045772 Test RE 1.395325469764236\n",
      "17 Train Loss 19.684662 Test MSE 8.098371467630058 Test RE 1.3602129558978726\n",
      "18 Train Loss 16.681278 Test MSE 7.333256553135635 Test RE 1.294364221528719\n",
      "19 Train Loss 15.201852 Test MSE 7.154859730099113 Test RE 1.2785232268429882\n",
      "20 Train Loss 14.201326 Test MSE 7.029510101526301 Test RE 1.2672741902259472\n",
      "21 Train Loss 13.71961 Test MSE 7.217813493412295 Test RE 1.2841356062840823\n",
      "22 Train Loss 13.332497 Test MSE 7.115030256443616 Test RE 1.2749596367723919\n",
      "23 Train Loss 13.175137 Test MSE 7.057439845947028 Test RE 1.2697892699246127\n",
      "24 Train Loss 12.922655 Test MSE 7.04625764342012 Test RE 1.2687829085533675\n",
      "25 Train Loss 12.703672 Test MSE 7.03424028196449 Test RE 1.2677004950052388\n",
      "26 Train Loss 12.347713 Test MSE 7.122084794108748 Test RE 1.2755915400893407\n",
      "27 Train Loss 11.7340555 Test MSE 6.7443499157917755 Test RE 1.241303864857599\n",
      "28 Train Loss 10.574181 Test MSE 6.484830507775768 Test RE 1.2171871955109683\n",
      "29 Train Loss 8.9723835 Test MSE 5.071076230500637 Test RE 1.076361437007175\n",
      "30 Train Loss 8.458869 Test MSE 5.2119905878374375 Test RE 1.0912138553354078\n",
      "31 Train Loss 8.088655 Test MSE 5.445568672717503 Test RE 1.1153975337144082\n",
      "32 Train Loss 7.7083826 Test MSE 5.403813876206641 Test RE 1.1111130575931838\n",
      "33 Train Loss 7.3492155 Test MSE 5.419575511887876 Test RE 1.1127323035484085\n",
      "34 Train Loss 6.7330465 Test MSE 5.5330440245259895 Test RE 1.1243204840265675\n",
      "35 Train Loss 5.6955023 Test MSE 5.382056211082219 Test RE 1.1088739344487102\n",
      "36 Train Loss 4.156699 Test MSE 4.722818937456924 Test RE 1.0387444306499558\n",
      "37 Train Loss 3.365286 Test MSE 4.527004003482901 Test RE 1.0169825464005808\n",
      "38 Train Loss 3.0773716 Test MSE 4.633588824866245 Test RE 1.0288849311180444\n",
      "39 Train Loss 2.78878 Test MSE 4.928261835825105 Test RE 1.061096658933903\n",
      "40 Train Loss 2.5591776 Test MSE 4.913290086139224 Test RE 1.0594836604783853\n",
      "41 Train Loss 2.42027 Test MSE 4.989287738965195 Test RE 1.067646143805536\n",
      "42 Train Loss 2.2209055 Test MSE 4.772481101307927 Test RE 1.044191536813617\n",
      "43 Train Loss 2.001118 Test MSE 4.016690206027727 Test RE 0.9579486482787303\n",
      "44 Train Loss 1.6712284 Test MSE 3.556808963520516 Test RE 0.9014431236091048\n",
      "45 Train Loss 1.418841 Test MSE 3.218449130047426 Test RE 0.8574945823823374\n",
      "46 Train Loss 1.3054918 Test MSE 3.1886376471200664 Test RE 0.8535139917687355\n",
      "47 Train Loss 1.186971 Test MSE 2.9110569897430594 Test RE 0.8155177426687745\n",
      "48 Train Loss 1.1269697 Test MSE 2.976190486787764 Test RE 0.8245906809720019\n",
      "49 Train Loss 1.0734252 Test MSE 2.9324436553690063 Test RE 0.8185079432452691\n",
      "50 Train Loss 1.0329233 Test MSE 2.8555754652195895 Test RE 0.8077089240020889\n",
      "51 Train Loss 0.9908246 Test MSE 2.776721387542778 Test RE 0.7964787860271293\n",
      "52 Train Loss 0.9639998 Test MSE 2.713473484271478 Test RE 0.7873554741706382\n",
      "53 Train Loss 0.9244071 Test MSE 2.7022193637307286 Test RE 0.785721000809739\n",
      "54 Train Loss 0.8929744 Test MSE 2.669730400161186 Test RE 0.7809833294238863\n",
      "55 Train Loss 0.8743551 Test MSE 2.670538883293319 Test RE 0.7811015743321341\n",
      "56 Train Loss 0.85656196 Test MSE 2.682684863972486 Test RE 0.7828758382879204\n",
      "57 Train Loss 0.82975304 Test MSE 2.681709296925324 Test RE 0.7827334776760602\n",
      "58 Train Loss 0.80822253 Test MSE 2.6926985844789755 Test RE 0.7843356068004141\n",
      "59 Train Loss 0.79236144 Test MSE 2.683855080389687 Test RE 0.7830465691638709\n",
      "60 Train Loss 0.77487016 Test MSE 2.6841408284798347 Test RE 0.7830882532525265\n",
      "61 Train Loss 0.7580324 Test MSE 2.7081915867858455 Test RE 0.7865887895716441\n",
      "62 Train Loss 0.74269885 Test MSE 2.714653199591776 Test RE 0.7875266117153683\n",
      "63 Train Loss 0.72673774 Test MSE 2.730146240688736 Test RE 0.7897706963459735\n",
      "64 Train Loss 0.7153797 Test MSE 2.709094804251098 Test RE 0.7867199474832668\n",
      "65 Train Loss 0.70922065 Test MSE 2.713387227148335 Test RE 0.7873429596651113\n",
      "66 Train Loss 0.70161664 Test MSE 2.725222262342087 Test RE 0.7890581761229924\n",
      "67 Train Loss 0.691082 Test MSE 2.7467779082888826 Test RE 0.7921726299408566\n",
      "68 Train Loss 0.6839198 Test MSE 2.754266873018496 Test RE 0.7932518061388815\n",
      "69 Train Loss 0.67626613 Test MSE 2.772590760820376 Test RE 0.7958861480673421\n",
      "70 Train Loss 0.6703521 Test MSE 2.764021858625532 Test RE 0.7946553230664496\n",
      "71 Train Loss 0.65643585 Test MSE 2.80724740711916 Test RE 0.8008448829454661\n",
      "72 Train Loss 0.65274084 Test MSE 2.8254686482661064 Test RE 0.8034397353298143\n",
      "73 Train Loss 0.6424943 Test MSE 2.8324881805740896 Test RE 0.8044371402552978\n",
      "74 Train Loss 0.6375712 Test MSE 2.8355059195225043 Test RE 0.8048655507007465\n",
      "75 Train Loss 0.63203776 Test MSE 2.8495901297186457 Test RE 0.8068619940459971\n",
      "76 Train Loss 0.62421477 Test MSE 2.865881626648655 Test RE 0.8091651770811658\n",
      "77 Train Loss 0.61779517 Test MSE 2.9012874968581954 Test RE 0.8141481558624584\n",
      "78 Train Loss 0.6109743 Test MSE 2.912169778170729 Test RE 0.8156735987720131\n",
      "79 Train Loss 0.59769106 Test MSE 2.907347257122682 Test RE 0.8149979456939299\n",
      "80 Train Loss 0.5874653 Test MSE 2.944330060058905 Test RE 0.8201651409098976\n",
      "81 Train Loss 0.5773964 Test MSE 2.9890437787530924 Test RE 0.8263693450548416\n",
      "82 Train Loss 0.5719774 Test MSE 2.9927953983524826 Test RE 0.8268877802936173\n",
      "83 Train Loss 0.56559324 Test MSE 3.0143673184240676 Test RE 0.8298625124424202\n",
      "84 Train Loss 0.556797 Test MSE 3.038309318258493 Test RE 0.8331516391115198\n",
      "85 Train Loss 0.5502182 Test MSE 3.0606918867359223 Test RE 0.8362148320759925\n",
      "86 Train Loss 0.54005456 Test MSE 3.0644088235803078 Test RE 0.8367224321157446\n",
      "87 Train Loss 0.532576 Test MSE 3.076348551690369 Test RE 0.8383508907666637\n",
      "88 Train Loss 0.5270669 Test MSE 3.0973799920266902 Test RE 0.841211700296729\n",
      "89 Train Loss 0.519781 Test MSE 3.1488058530838434 Test RE 0.8481662795969568\n",
      "90 Train Loss 0.5155082 Test MSE 3.1782963762632086 Test RE 0.8521288253821058\n",
      "91 Train Loss 0.5071674 Test MSE 3.205446890166776 Test RE 0.8557607296480525\n",
      "92 Train Loss 0.5041372 Test MSE 3.2153822993722123 Test RE 0.8570859356463917\n",
      "93 Train Loss 0.50064784 Test MSE 3.252976946961254 Test RE 0.86208195196578\n",
      "94 Train Loss 0.4932222 Test MSE 3.2695887802260613 Test RE 0.8642803268103613\n",
      "95 Train Loss 0.48919424 Test MSE 3.255586300823529 Test RE 0.8624276393142806\n",
      "96 Train Loss 0.48271096 Test MSE 3.2332202985321303 Test RE 0.8594600782969686\n",
      "97 Train Loss 0.47929916 Test MSE 3.2476727806177466 Test RE 0.861378828080592\n",
      "98 Train Loss 0.47377902 Test MSE 3.262345963207455 Test RE 0.8633225160231236\n",
      "99 Train Loss 0.46966237 Test MSE 3.257592511704281 Test RE 0.8626933280537623\n",
      "Training time: 43.96\n",
      "KG_stan_tune18\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.732132 Test MSE 8.879647387863061 Test RE 1.4243145813865066\n",
      "1 Train Loss 48.118034 Test MSE 8.405776408079705 Test RE 1.3857885769341427\n",
      "2 Train Loss 44.372025 Test MSE 8.520413732583878 Test RE 1.3952062148008404\n",
      "3 Train Loss 43.674244 Test MSE 8.439665156565571 Test RE 1.3885792413393352\n",
      "4 Train Loss 43.246048 Test MSE 8.468832839481214 Test RE 1.3909766531410388\n",
      "5 Train Loss 42.76807 Test MSE 8.496545816672755 Test RE 1.3932506748847644\n",
      "6 Train Loss 42.002876 Test MSE 8.457460640057649 Test RE 1.3900424170935919\n",
      "7 Train Loss 41.376213 Test MSE 8.160024887558357 Test RE 1.365380832816804\n",
      "8 Train Loss 40.1565 Test MSE 7.9303427086594915 Test RE 1.346027826366933\n",
      "9 Train Loss 38.647087 Test MSE 7.762790724498562 Test RE 1.3317325027123854\n",
      "10 Train Loss 37.80924 Test MSE 7.907242033116342 Test RE 1.3440659421089507\n",
      "11 Train Loss 36.633408 Test MSE 8.030846951648273 Test RE 1.3545303330624385\n",
      "12 Train Loss 35.352425 Test MSE 8.227044754604432 Test RE 1.3709764356672192\n",
      "13 Train Loss 34.139275 Test MSE 8.674028539431212 Test RE 1.407727140199312\n",
      "14 Train Loss 32.996643 Test MSE 8.413883324836608 Test RE 1.3864566749560097\n",
      "15 Train Loss 30.648533 Test MSE 8.81553595807672 Test RE 1.4191634609500872\n",
      "16 Train Loss 28.357285 Test MSE 7.980862014672051 Test RE 1.3503083751799843\n",
      "17 Train Loss 23.982689 Test MSE 6.754411973704162 Test RE 1.2422294852986588\n",
      "18 Train Loss 19.624798 Test MSE 5.90407860452951 Test RE 1.1614061614787554\n",
      "19 Train Loss 15.437582 Test MSE 4.682882340513897 Test RE 1.034343246851172\n",
      "20 Train Loss 11.207057 Test MSE 3.4081116570221015 Test RE 0.8823989195278555\n",
      "21 Train Loss 9.9283285 Test MSE 3.2608620435802544 Test RE 0.8631261470673128\n",
      "22 Train Loss 8.708546 Test MSE 3.3701234419878228 Test RE 0.8774673479461402\n",
      "23 Train Loss 7.911283 Test MSE 3.151093026035736 Test RE 0.8484742615627907\n",
      "24 Train Loss 6.9760275 Test MSE 3.141750607959059 Test RE 0.8472155419184606\n",
      "25 Train Loss 6.442461 Test MSE 3.205936371743931 Test RE 0.8558260657986981\n",
      "26 Train Loss 6.003188 Test MSE 3.173245876371548 Test RE 0.8514515147903409\n",
      "27 Train Loss 5.7266436 Test MSE 3.1507812296060496 Test RE 0.8484322828290908\n",
      "28 Train Loss 5.31275 Test MSE 3.177684227900642 Test RE 0.8520467602876947\n",
      "29 Train Loss 5.0341253 Test MSE 3.1665487484240082 Test RE 0.850552547014281\n",
      "30 Train Loss 4.8435063 Test MSE 3.1722972483285328 Test RE 0.8513242364151224\n",
      "31 Train Loss 4.4896 Test MSE 3.1395567370540443 Test RE 0.8469196867806206\n",
      "32 Train Loss 4.240886 Test MSE 3.140721364082208 Test RE 0.8470767557851946\n",
      "33 Train Loss 4.0300655 Test MSE 3.1163753145419055 Test RE 0.843787209866636\n",
      "34 Train Loss 3.7949252 Test MSE 3.1916058456632626 Test RE 0.8539111535000039\n",
      "35 Train Loss 3.628958 Test MSE 3.182258708687366 Test RE 0.8526598277806304\n",
      "36 Train Loss 3.3810897 Test MSE 3.1012506597474183 Test RE 0.8417371499315893\n",
      "37 Train Loss 3.2456684 Test MSE 3.1204266323415846 Test RE 0.8443354974627431\n",
      "38 Train Loss 3.0037808 Test MSE 3.088864201183846 Test RE 0.8400545104302157\n",
      "39 Train Loss 2.7623394 Test MSE 3.069780498595379 Test RE 0.8374554663309943\n",
      "40 Train Loss 2.5255475 Test MSE 2.9943326664115975 Test RE 0.8271001210674679\n",
      "41 Train Loss 2.3655853 Test MSE 2.948653429413673 Test RE 0.8207670734467941\n",
      "42 Train Loss 2.1318429 Test MSE 2.9101321713858685 Test RE 0.8153881908097043\n",
      "43 Train Loss 1.9216048 Test MSE 2.8166985366253177 Test RE 0.8021918481009433\n",
      "44 Train Loss 1.6667501 Test MSE 2.853681963247168 Test RE 0.8074410879607273\n",
      "45 Train Loss 1.4352036 Test MSE 2.769057240545012 Test RE 0.7953788289783276\n",
      "46 Train Loss 1.2619052 Test MSE 2.6835866157540833 Test RE 0.7830074043127754\n",
      "47 Train Loss 1.1715183 Test MSE 2.672897360726193 Test RE 0.781446411827552\n",
      "48 Train Loss 1.0867 Test MSE 2.6959286809165346 Test RE 0.7848059008660087\n",
      "49 Train Loss 1.0381817 Test MSE 2.7093712987647947 Test RE 0.786760093401939\n",
      "50 Train Loss 0.98660207 Test MSE 2.7158080837019276 Test RE 0.7876941110591975\n",
      "51 Train Loss 0.944686 Test MSE 2.7621600223511202 Test RE 0.7943876393404447\n",
      "52 Train Loss 0.91454005 Test MSE 2.7339746352437193 Test RE 0.790324237136839\n",
      "53 Train Loss 0.8748845 Test MSE 2.7834384668627568 Test RE 0.7974415724995221\n",
      "54 Train Loss 0.85665023 Test MSE 2.7992545388023284 Test RE 0.7997039770030512\n",
      "55 Train Loss 0.83611727 Test MSE 2.825698698413587 Test RE 0.8034724427653789\n",
      "56 Train Loss 0.8143699 Test MSE 2.798540580895012 Test RE 0.7996019871017134\n",
      "57 Train Loss 0.7917453 Test MSE 2.8302944784978936 Test RE 0.8041255701578423\n",
      "58 Train Loss 0.77417004 Test MSE 2.8829638721365 Test RE 0.811573131058126\n",
      "59 Train Loss 0.7580129 Test MSE 2.8783567228536393 Test RE 0.8109244004927367\n",
      "60 Train Loss 0.74031556 Test MSE 2.8922112442936325 Test RE 0.8128736867642123\n",
      "61 Train Loss 0.712481 Test MSE 2.9195476516517194 Test RE 0.8167061844963616\n",
      "62 Train Loss 0.6866069 Test MSE 2.966711210598528 Test RE 0.8232764578480989\n",
      "63 Train Loss 0.66939986 Test MSE 3.0336671127207118 Test RE 0.8325149133508277\n",
      "64 Train Loss 0.6506824 Test MSE 3.042119371806925 Test RE 0.8336738633959854\n",
      "65 Train Loss 0.63587415 Test MSE 3.036402556935295 Test RE 0.8328901662860693\n",
      "66 Train Loss 0.6220836 Test MSE 3.038254804589478 Test RE 0.8331441648303222\n",
      "67 Train Loss 0.60654294 Test MSE 3.0235372794480275 Test RE 0.8311238099980613\n",
      "68 Train Loss 0.5948425 Test MSE 3.056783969129648 Test RE 0.8356808184346652\n",
      "69 Train Loss 0.57555836 Test MSE 3.0619335743508613 Test RE 0.8363844362622038\n",
      "70 Train Loss 0.5626954 Test MSE 3.072593415670473 Test RE 0.8378390692276704\n",
      "71 Train Loss 0.55340105 Test MSE 3.0592534425070417 Test RE 0.8360183095569388\n",
      "72 Train Loss 0.54728866 Test MSE 3.059273000297276 Test RE 0.8360209818828684\n",
      "73 Train Loss 0.5405755 Test MSE 3.064268836095677 Test RE 0.8367033204349832\n",
      "74 Train Loss 0.5331414 Test MSE 3.082141996810811 Test RE 0.839139919589833\n",
      "75 Train Loss 0.52922326 Test MSE 3.09354861411506 Test RE 0.840691260885943\n",
      "76 Train Loss 0.51986986 Test MSE 3.119764682155221 Test RE 0.8442459363626401\n",
      "77 Train Loss 0.51723605 Test MSE 3.1236170762161457 Test RE 0.8447670276864357\n",
      "78 Train Loss 0.5123153 Test MSE 3.1261566855319147 Test RE 0.8451103703995845\n",
      "79 Train Loss 0.50745803 Test MSE 3.1372534484222525 Test RE 0.8466089648289511\n",
      "80 Train Loss 0.5029797 Test MSE 3.1411689392303326 Test RE 0.8471371108683519\n",
      "81 Train Loss 0.5000933 Test MSE 3.1375760823013548 Test RE 0.8466524961720088\n",
      "82 Train Loss 0.4952789 Test MSE 3.147609136004122 Test RE 0.8480050896762166\n",
      "83 Train Loss 0.49289912 Test MSE 3.1491342583684028 Test RE 0.8482105082727028\n",
      "84 Train Loss 0.4868316 Test MSE 3.168415711824492 Test RE 0.8508032484262772\n",
      "85 Train Loss 0.48440206 Test MSE 3.166960841435706 Test RE 0.8506078904474005\n",
      "86 Train Loss 0.47856677 Test MSE 3.1875806296039677 Test RE 0.8533725122218626\n",
      "87 Train Loss 0.47487852 Test MSE 3.198387893433761 Test RE 0.8548179372980313\n",
      "88 Train Loss 0.46886557 Test MSE 3.2083522417947106 Test RE 0.8561484638376478\n",
      "89 Train Loss 0.46555033 Test MSE 3.2218900986995465 Test RE 0.8579528502663494\n",
      "90 Train Loss 0.46113232 Test MSE 3.222579651060553 Test RE 0.8580446553473579\n",
      "91 Train Loss 0.4585375 Test MSE 3.230959443038215 Test RE 0.8591595335360299\n",
      "92 Train Loss 0.45359105 Test MSE 3.237581969950279 Test RE 0.8600395963478319\n",
      "93 Train Loss 0.450353 Test MSE 3.2304244713173205 Test RE 0.859088402175562\n",
      "94 Train Loss 0.44595906 Test MSE 3.263769523169987 Test RE 0.8635108555402601\n",
      "95 Train Loss 0.44241846 Test MSE 3.267472691631768 Test RE 0.8640005990101554\n",
      "96 Train Loss 0.44062978 Test MSE 3.260706561478998 Test RE 0.8631055693389461\n",
      "97 Train Loss 0.4374623 Test MSE 3.2673998130507997 Test RE 0.8639909635067146\n",
      "98 Train Loss 0.43440545 Test MSE 3.277587442255815 Test RE 0.8653368608043047\n",
      "99 Train Loss 0.43136907 Test MSE 3.286419296130551 Test RE 0.8665019536260974\n",
      "Training time: 44.21\n",
      "KG_stan_tune19\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 53.682472 Test MSE 8.622629212067126 Test RE 1.4035500882031418\n",
      "1 Train Loss 44.81028 Test MSE 8.679376814384304 Test RE 1.4081610649653435\n",
      "2 Train Loss 43.432777 Test MSE 8.638144483326942 Test RE 1.4048122712713351\n",
      "3 Train Loss 42.76698 Test MSE 8.584220712904264 Test RE 1.4004206240253896\n",
      "4 Train Loss 42.30705 Test MSE 8.76330194417266 Test RE 1.4149527845968846\n",
      "5 Train Loss 41.775146 Test MSE 8.818517214412395 Test RE 1.4194034084948026\n",
      "6 Train Loss 40.731472 Test MSE 8.913413131935073 Test RE 1.4270200609291777\n",
      "7 Train Loss 38.800835 Test MSE 8.990025506761855 Test RE 1.4331396851557228\n",
      "8 Train Loss 36.54978 Test MSE 8.900937348036646 Test RE 1.426021036895321\n",
      "9 Train Loss 31.22285 Test MSE 8.459451301526494 Test RE 1.3902059969901475\n",
      "10 Train Loss 27.669472 Test MSE 7.643312447005528 Test RE 1.3214443150037116\n",
      "11 Train Loss 24.07372 Test MSE 7.196432775815153 Test RE 1.2822322526296994\n",
      "12 Train Loss 20.695244 Test MSE 7.23983180855989 Test RE 1.2860927760083132\n",
      "13 Train Loss 16.593782 Test MSE 6.33226605404104 Test RE 1.2027839857762017\n",
      "14 Train Loss 15.062374 Test MSE 6.266940787445075 Test RE 1.1965637892020882\n",
      "15 Train Loss 13.180629 Test MSE 6.515759193937129 Test RE 1.220086363063081\n",
      "16 Train Loss 11.526209 Test MSE 6.868801048436879 Test RE 1.2527041869825215\n",
      "17 Train Loss 10.246979 Test MSE 6.888623122687695 Test RE 1.2545104197217263\n",
      "18 Train Loss 8.835175 Test MSE 6.99283899680074 Test RE 1.26396434992563\n",
      "19 Train Loss 7.327348 Test MSE 6.837199211012748 Test RE 1.2498191570875807\n",
      "20 Train Loss 6.22635 Test MSE 6.803744128762415 Test RE 1.2467576639631546\n",
      "21 Train Loss 5.4502873 Test MSE 6.588325798834886 Test RE 1.2268616576245186\n",
      "22 Train Loss 4.841693 Test MSE 6.648533327855254 Test RE 1.2324547567433166\n",
      "23 Train Loss 3.999475 Test MSE 6.629778427361226 Test RE 1.2307152083922837\n",
      "24 Train Loss 3.4896169 Test MSE 6.491845662567601 Test RE 1.2178453814545172\n",
      "25 Train Loss 3.0517175 Test MSE 6.42468929154668 Test RE 1.2115298669341996\n",
      "26 Train Loss 2.6798735 Test MSE 6.147143352803432 Test RE 1.185071982988323\n",
      "27 Train Loss 2.4041486 Test MSE 6.126874145596935 Test RE 1.1831165785174753\n",
      "28 Train Loss 2.2355454 Test MSE 5.952561726419845 Test RE 1.16616503019604\n",
      "29 Train Loss 2.070018 Test MSE 5.984373579056561 Test RE 1.1692770044113447\n",
      "30 Train Loss 1.9439206 Test MSE 5.968242879574787 Test RE 1.1677000654998768\n",
      "31 Train Loss 1.8129432 Test MSE 5.81759013985002 Test RE 1.1528680959488549\n",
      "32 Train Loss 1.7070682 Test MSE 5.760579891232902 Test RE 1.1472053464275462\n",
      "33 Train Loss 1.6013926 Test MSE 5.747790605604107 Test RE 1.1459311613964294\n",
      "34 Train Loss 1.5186092 Test MSE 5.74367608514574 Test RE 1.1455209340911539\n",
      "35 Train Loss 1.439399 Test MSE 5.796569028314631 Test RE 1.1507833409204635\n",
      "36 Train Loss 1.3764299 Test MSE 5.884045387545558 Test RE 1.1594340949292876\n",
      "37 Train Loss 1.3098557 Test MSE 5.964713042318142 Test RE 1.167354704151169\n",
      "38 Train Loss 1.2680526 Test MSE 5.964374983275502 Test RE 1.1673216228945604\n",
      "39 Train Loss 1.2201232 Test MSE 5.957164915561977 Test RE 1.1666158479323745\n",
      "40 Train Loss 1.1925447 Test MSE 5.992575314777343 Test RE 1.1700779919523585\n",
      "41 Train Loss 1.165951 Test MSE 5.9995467966582 Test RE 1.1707584011296313\n",
      "42 Train Loss 1.1290323 Test MSE 6.001843501146553 Test RE 1.170982470453523\n",
      "43 Train Loss 1.0886471 Test MSE 6.010106079449736 Test RE 1.171788223444101\n",
      "44 Train Loss 1.0617545 Test MSE 6.015147481917261 Test RE 1.1722795806396271\n",
      "45 Train Loss 1.0293934 Test MSE 6.068049481670734 Test RE 1.1774232763026495\n",
      "46 Train Loss 1.0013831 Test MSE 6.093032606357336 Test RE 1.179844606046767\n",
      "47 Train Loss 0.9714259 Test MSE 6.11474258493079 Test RE 1.1819446789310049\n",
      "48 Train Loss 0.9455552 Test MSE 6.174637820990591 Test RE 1.187719275374624\n",
      "49 Train Loss 0.9162135 Test MSE 6.210127186077299 Test RE 1.1911276541541482\n",
      "50 Train Loss 0.8913066 Test MSE 6.2795523981985575 Test RE 1.1977671683947075\n",
      "51 Train Loss 0.86669695 Test MSE 6.329811222245585 Test RE 1.2025508213320963\n",
      "52 Train Loss 0.84333086 Test MSE 6.37786668689028 Test RE 1.2071070291011188\n",
      "53 Train Loss 0.8162969 Test MSE 6.418271019252505 Test RE 1.2109245558260118\n",
      "54 Train Loss 0.80037665 Test MSE 6.394167446967022 Test RE 1.2086486265071945\n",
      "55 Train Loss 0.7806181 Test MSE 6.404136322678066 Test RE 1.2095904360135292\n",
      "56 Train Loss 0.7639832 Test MSE 6.41454979045377 Test RE 1.2105734658942835\n",
      "57 Train Loss 0.7503109 Test MSE 6.43324014381905 Test RE 1.2123358333974381\n",
      "58 Train Loss 0.73542434 Test MSE 6.4421164530022015 Test RE 1.2131719096276163\n",
      "59 Train Loss 0.7217401 Test MSE 6.492802249879825 Test RE 1.217935104207372\n",
      "60 Train Loss 0.7084385 Test MSE 6.5110416147527195 Test RE 1.219644595950257\n",
      "61 Train Loss 0.69721425 Test MSE 6.547858351996031 Test RE 1.2230879802456032\n",
      "62 Train Loss 0.68552065 Test MSE 6.592826888264332 Test RE 1.2272806769130657\n",
      "63 Train Loss 0.6731765 Test MSE 6.6532748506521555 Test RE 1.232894152210029\n",
      "64 Train Loss 0.663969 Test MSE 6.675831523413294 Test RE 1.2349823312876929\n",
      "65 Train Loss 0.65452117 Test MSE 6.71338743206086 Test RE 1.2384512501488618\n",
      "66 Train Loss 0.6453392 Test MSE 6.716688031193456 Test RE 1.2387556515312954\n",
      "67 Train Loss 0.6372254 Test MSE 6.7417309435694355 Test RE 1.2410628293207806\n",
      "68 Train Loss 0.62962323 Test MSE 6.758056727124148 Test RE 1.2425646002989852\n",
      "69 Train Loss 0.6206895 Test MSE 6.798013100562596 Test RE 1.2462324598628771\n",
      "70 Train Loss 0.61492085 Test MSE 6.796967964150179 Test RE 1.2461366573858792\n",
      "71 Train Loss 0.61022353 Test MSE 6.8247820702183 Test RE 1.2486837336106507\n",
      "72 Train Loss 0.60504246 Test MSE 6.834793169357734 Test RE 1.2495992292003362\n",
      "73 Train Loss 0.6003498 Test MSE 6.826208989197158 Test RE 1.2488142635951074\n",
      "74 Train Loss 0.59578276 Test MSE 6.853995547282925 Test RE 1.2513533749358432\n",
      "75 Train Loss 0.5903118 Test MSE 6.849088886635442 Test RE 1.2509053832799673\n",
      "76 Train Loss 0.5854227 Test MSE 6.848641220460654 Test RE 1.2508645021359261\n",
      "77 Train Loss 0.5809169 Test MSE 6.850276440181854 Test RE 1.251013824910774\n",
      "78 Train Loss 0.57658994 Test MSE 6.860615060322738 Test RE 1.2519575007263357\n",
      "79 Train Loss 0.57219213 Test MSE 6.86069756323948 Test RE 1.2519650284650303\n",
      "80 Train Loss 0.5682251 Test MSE 6.871819979521264 Test RE 1.252979446968445\n",
      "81 Train Loss 0.564657 Test MSE 6.875318070269432 Test RE 1.2532983201469803\n",
      "82 Train Loss 0.5612846 Test MSE 6.885712267270961 Test RE 1.2542453388606927\n",
      "83 Train Loss 0.5573978 Test MSE 6.896321912406134 Test RE 1.2552112502599142\n",
      "84 Train Loss 0.55258465 Test MSE 6.908693822919971 Test RE 1.2563366619528777\n",
      "85 Train Loss 0.54868823 Test MSE 6.950385157814354 Test RE 1.260121716735942\n",
      "86 Train Loss 0.5452853 Test MSE 6.95053407749723 Test RE 1.2601352164138016\n",
      "87 Train Loss 0.5426452 Test MSE 6.962027047291163 Test RE 1.261176626601927\n",
      "88 Train Loss 0.5395583 Test MSE 6.971584965042646 Test RE 1.2620420418050085\n",
      "89 Train Loss 0.53729886 Test MSE 6.97440071843698 Test RE 1.2622968791509979\n",
      "90 Train Loss 0.53467155 Test MSE 6.967168199345247 Test RE 1.2616422025170273\n",
      "91 Train Loss 0.5322012 Test MSE 6.971787880300275 Test RE 1.2620604081968643\n",
      "92 Train Loss 0.5294883 Test MSE 6.987363442217942 Test RE 1.2634693963645731\n",
      "93 Train Loss 0.52724445 Test MSE 6.980173653205153 Test RE 1.262819192859795\n",
      "94 Train Loss 0.5251465 Test MSE 6.978786149650224 Test RE 1.2626936764122134\n",
      "95 Train Loss 0.52307206 Test MSE 6.982807200490075 Test RE 1.2630573947007226\n",
      "96 Train Loss 0.5209403 Test MSE 6.989157330657953 Test RE 1.2636315732506693\n",
      "97 Train Loss 0.518906 Test MSE 6.993665820056293 Test RE 1.2640390723830581\n",
      "98 Train Loss 0.51695985 Test MSE 6.985002695697395 Test RE 1.2632559408183965\n",
      "99 Train Loss 0.51535666 Test MSE 6.97429720177002 Test RE 1.2622875113747698\n",
      "Training time: 43.82\n",
      "KG_stan_tune19\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 55.10658 Test MSE 9.222148356603093 Test RE 1.4515236373404485\n",
      "1 Train Loss 45.94661 Test MSE 8.709102853647128 Test RE 1.4105704125733793\n",
      "2 Train Loss 40.3209 Test MSE 7.954973015485045 Test RE 1.3481164735733964\n",
      "3 Train Loss 34.256374 Test MSE 6.8282226482124475 Test RE 1.2489984434730033\n",
      "4 Train Loss 31.517342 Test MSE 6.24718346999906 Test RE 1.1946761414982174\n",
      "5 Train Loss 26.522585 Test MSE 5.009561033617221 Test RE 1.0698130625087756\n",
      "6 Train Loss 23.453352 Test MSE 5.266606543347047 Test RE 1.0969163186705013\n",
      "7 Train Loss 20.868393 Test MSE 6.041952453249825 Test RE 1.174888659749647\n",
      "8 Train Loss 17.680628 Test MSE 5.617863909786363 Test RE 1.1329054537739316\n",
      "9 Train Loss 15.116755 Test MSE 5.639758484749093 Test RE 1.1351109506541999\n",
      "10 Train Loss 13.991267 Test MSE 5.867451467631762 Test RE 1.1577980487193886\n",
      "11 Train Loss 12.910374 Test MSE 6.055143021880212 Test RE 1.1761704474229322\n",
      "12 Train Loss 12.3221855 Test MSE 5.979036887093869 Test RE 1.1687555243509231\n",
      "13 Train Loss 11.842344 Test MSE 5.8518104720723025 Test RE 1.1562538349480422\n",
      "14 Train Loss 11.6187315 Test MSE 5.863266031136824 Test RE 1.1573850282859681\n",
      "15 Train Loss 11.461344 Test MSE 5.885463268148346 Test RE 1.1595737811470102\n",
      "16 Train Loss 11.338392 Test MSE 5.91170858415348 Test RE 1.1621563754245827\n",
      "17 Train Loss 11.24087 Test MSE 5.90390643437419 Test RE 1.161389227343017\n",
      "18 Train Loss 11.133088 Test MSE 5.905170133147029 Test RE 1.1615135151879123\n",
      "19 Train Loss 11.039707 Test MSE 5.879093975355413 Test RE 1.1589461615461307\n",
      "20 Train Loss 10.953667 Test MSE 5.847594049479708 Test RE 1.1558372003588202\n",
      "21 Train Loss 10.832941 Test MSE 5.770060449871755 Test RE 1.1481489733320132\n",
      "22 Train Loss 10.713728 Test MSE 5.668871697498934 Test RE 1.1380369791775173\n",
      "23 Train Loss 10.254813 Test MSE 5.002741085487995 Test RE 1.069084600031778\n",
      "24 Train Loss 8.61315 Test MSE 4.417955251376513 Test RE 1.0046590867365814\n",
      "25 Train Loss 7.9271107 Test MSE 4.274633722573166 Test RE 0.9882288174493061\n",
      "26 Train Loss 7.7717433 Test MSE 4.282718746906059 Test RE 0.9891629418829239\n",
      "27 Train Loss 7.6693325 Test MSE 4.287347400296938 Test RE 0.9896973285966125\n",
      "28 Train Loss 7.6129665 Test MSE 4.28365370701108 Test RE 0.9892709080457056\n",
      "29 Train Loss 7.5680847 Test MSE 4.26679401873661 Test RE 0.9873221927862403\n",
      "30 Train Loss 7.504884 Test MSE 4.26462624339293 Test RE 0.9870713528566306\n",
      "31 Train Loss 7.4405947 Test MSE 4.274834983522312 Test RE 0.9882520813757204\n",
      "32 Train Loss 7.353123 Test MSE 4.234198381135113 Test RE 0.9835437006100274\n",
      "33 Train Loss 7.2255917 Test MSE 4.17213645509244 Test RE 0.9763090438961812\n",
      "34 Train Loss 7.01146 Test MSE 4.100790405253643 Test RE 0.9679253108606528\n",
      "35 Train Loss 6.700074 Test MSE 4.0641921798418075 Test RE 0.9635964208686302\n",
      "36 Train Loss 5.9592915 Test MSE 3.877384785412659 Test RE 0.9411904485581337\n",
      "37 Train Loss 5.159562 Test MSE 3.767894711733421 Test RE 0.9278065615356466\n",
      "38 Train Loss 4.495161 Test MSE 3.5296287054469637 Test RE 0.8979922150527342\n",
      "39 Train Loss 3.742361 Test MSE 3.4239116819998197 Test RE 0.8844419575804827\n",
      "40 Train Loss 3.1093276 Test MSE 3.1513070723785437 Test RE 0.8485030785045828\n",
      "41 Train Loss 2.548545 Test MSE 2.6682430689186853 Test RE 0.7807657526355009\n",
      "42 Train Loss 2.1579618 Test MSE 2.0982063832195905 Test RE 0.6923603076594622\n",
      "43 Train Loss 1.5426873 Test MSE 1.1189330252475014 Test RE 0.5056035404369486\n",
      "44 Train Loss 1.1251 Test MSE 0.6681265605961164 Test RE 0.39069461809640765\n",
      "45 Train Loss 0.6950553 Test MSE 0.3297876386680246 Test RE 0.27448919075151124\n",
      "46 Train Loss 0.41137397 Test MSE 0.23198018157223985 Test RE 0.2302149390258067\n",
      "47 Train Loss 0.27370918 Test MSE 0.08826181222158605 Test RE 0.14200200629699325\n",
      "48 Train Loss 0.19034164 Test MSE 0.056094348699853795 Test RE 0.11320552293873401\n",
      "49 Train Loss 0.13425219 Test MSE 0.024025264555139873 Test RE 0.07408702393534894\n",
      "50 Train Loss 0.092945755 Test MSE 0.015489249561260127 Test RE 0.059487161815016\n",
      "51 Train Loss 0.07175616 Test MSE 0.01151519673434211 Test RE 0.05129130410811471\n",
      "52 Train Loss 0.055176787 Test MSE 0.007238078821325424 Test RE 0.04066490053537652\n",
      "53 Train Loss 0.04495182 Test MSE 0.008030536886173155 Test RE 0.042833183218826926\n",
      "54 Train Loss 0.034962617 Test MSE 0.006841788815939121 Test RE 0.039536014985396745\n",
      "55 Train Loss 0.030544497 Test MSE 0.007192561665283745 Test RE 0.04053683687288733\n",
      "56 Train Loss 0.027278274 Test MSE 0.006762687939011665 Test RE 0.03930680408116531\n",
      "57 Train Loss 0.02395078 Test MSE 0.005043389849474061 Test RE 0.03394449330651165\n",
      "58 Train Loss 0.020818837 Test MSE 0.004732761727535212 Test RE 0.03288254176821936\n",
      "59 Train Loss 0.018991642 Test MSE 0.004898312437354393 Test RE 0.03345270970062157\n",
      "60 Train Loss 0.017500803 Test MSE 0.004226693991491163 Test RE 0.03107480868276244\n",
      "61 Train Loss 0.015340913 Test MSE 0.003530645579263035 Test RE 0.028401097451844107\n",
      "62 Train Loss 0.014255836 Test MSE 0.003052254067219955 Test RE 0.026406959589002826\n",
      "63 Train Loss 0.012792397 Test MSE 0.002727258597287026 Test RE 0.02496153105800563\n",
      "64 Train Loss 0.011852981 Test MSE 0.0025108882342642015 Test RE 0.023950895235840874\n",
      "65 Train Loss 0.010422733 Test MSE 0.0027417540504856962 Test RE 0.025027778753896397\n",
      "66 Train Loss 0.009018133 Test MSE 0.0022536343904107103 Test RE 0.022690799115086598\n",
      "67 Train Loss 0.008218906 Test MSE 0.0016869539136216756 Test RE 0.01963177958322291\n",
      "68 Train Loss 0.0074426737 Test MSE 0.0014447244788271388 Test RE 0.018167726192135174\n",
      "69 Train Loss 0.006873028 Test MSE 0.00128722328159696 Test RE 0.017148850067865373\n",
      "70 Train Loss 0.006489627 Test MSE 0.0014057783969906115 Test RE 0.017921175499204356\n",
      "71 Train Loss 0.0056077666 Test MSE 0.0013430128656666484 Test RE 0.017516532807406237\n",
      "72 Train Loss 0.0053151413 Test MSE 0.0014877438086283792 Test RE 0.01843623078849808\n",
      "73 Train Loss 0.0049522268 Test MSE 0.0014973987351989682 Test RE 0.018495956326220548\n",
      "74 Train Loss 0.0046844403 Test MSE 0.0013471017943546876 Test RE 0.01754317790582178\n",
      "75 Train Loss 0.0043733353 Test MSE 0.0013794503067631253 Test RE 0.01775256413589353\n",
      "76 Train Loss 0.004008211 Test MSE 0.0012913505209545962 Test RE 0.017176320347150942\n",
      "77 Train Loss 0.003890957 Test MSE 0.0013092508347591608 Test RE 0.01729495713698159\n",
      "78 Train Loss 0.0035270439 Test MSE 0.0013397725994181973 Test RE 0.017495389113334616\n",
      "79 Train Loss 0.0033913509 Test MSE 0.0011721804522678012 Test RE 0.016364596355891204\n",
      "80 Train Loss 0.003116153 Test MSE 0.0009895169817386563 Test RE 0.01503556270506876\n",
      "81 Train Loss 0.0029799333 Test MSE 0.0010146507088717206 Test RE 0.015225316936031132\n",
      "82 Train Loss 0.0026429794 Test MSE 0.0006916479841325671 Test RE 0.01257044401083115\n",
      "83 Train Loss 0.0024882474 Test MSE 0.0007882775902044119 Test RE 0.013419849655930034\n",
      "84 Train Loss 0.0024100994 Test MSE 0.0007691379342327082 Test RE 0.01325592920531284\n",
      "85 Train Loss 0.00224985 Test MSE 0.0007035283489493329 Test RE 0.012677944941877503\n",
      "86 Train Loss 0.002114774 Test MSE 0.0006902774800214294 Test RE 0.012557983634799298\n",
      "87 Train Loss 0.0020062255 Test MSE 0.0007160968804398588 Test RE 0.012790689347360556\n",
      "88 Train Loss 0.001954147 Test MSE 0.0007613896097601521 Test RE 0.013188989826467728\n",
      "89 Train Loss 0.0018539669 Test MSE 0.0007640444338762058 Test RE 0.013211963596195607\n",
      "90 Train Loss 0.0017589042 Test MSE 0.0007496844494562869 Test RE 0.01308721724027177\n",
      "91 Train Loss 0.0017177563 Test MSE 0.0007459015321852394 Test RE 0.01305415634874699\n",
      "92 Train Loss 0.0016386032 Test MSE 0.0006423447912083899 Test RE 0.012114128152852122\n",
      "93 Train Loss 0.0015427205 Test MSE 0.0006005038334596111 Test RE 0.011712940910616735\n",
      "94 Train Loss 0.0015100793 Test MSE 0.0005491455875309094 Test RE 0.011200871359415948\n",
      "95 Train Loss 0.0014691063 Test MSE 0.0005337575213970126 Test RE 0.011042821807481916\n",
      "96 Train Loss 0.0013994966 Test MSE 0.0005179164598419483 Test RE 0.01087772103806969\n",
      "97 Train Loss 0.0013502138 Test MSE 0.0004735860995754261 Test RE 0.010401776875388456\n",
      "98 Train Loss 0.0013294023 Test MSE 0.0004936449911497527 Test RE 0.010619777742445442\n",
      "99 Train Loss 0.001272437 Test MSE 0.00043623981781829106 Test RE 0.009983221613196057\n",
      "Training time: 43.69\n",
      "KG_stan_tune19\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 51.792137 Test MSE 9.356728753284978 Test RE 1.4620764440642642\n",
      "1 Train Loss 44.515274 Test MSE 8.284517672265492 Test RE 1.3757568207198028\n",
      "2 Train Loss 42.6326 Test MSE 8.100037323298066 Test RE 1.3603528483414968\n",
      "3 Train Loss 37.656128 Test MSE 6.924896268356592 Test RE 1.2578089956543437\n",
      "4 Train Loss 29.944687 Test MSE 6.641180167950842 Test RE 1.231773031649639\n",
      "5 Train Loss 26.81826 Test MSE 5.984167561363207 Test RE 1.1692568775073817\n",
      "6 Train Loss 24.272366 Test MSE 6.3902136681437725 Test RE 1.2082748899469646\n",
      "7 Train Loss 22.33413 Test MSE 6.127242358492816 Test RE 1.1831521294547171\n",
      "8 Train Loss 19.838583 Test MSE 6.651477385773888 Test RE 1.2327276001223095\n",
      "9 Train Loss 18.539465 Test MSE 6.403877794847528 Test RE 1.2095660208596712\n",
      "10 Train Loss 17.569088 Test MSE 6.330915553957769 Test RE 1.2026557183853288\n",
      "11 Train Loss 16.151392 Test MSE 6.106539228886523 Test RE 1.1811515820008234\n",
      "12 Train Loss 14.967077 Test MSE 5.939381483999831 Test RE 1.1648732455626762\n",
      "13 Train Loss 12.114895 Test MSE 4.41324635184125 Test RE 1.0041235335556848\n",
      "14 Train Loss 8.324102 Test MSE 2.920241372068314 Test RE 0.816803208448424\n",
      "15 Train Loss 5.9171715 Test MSE 2.3786034326438124 Test RE 0.737172424131127\n",
      "16 Train Loss 4.9563737 Test MSE 2.145901310088911 Test RE 0.7001852096787289\n",
      "17 Train Loss 4.6073537 Test MSE 2.175613711873571 Test RE 0.7050159687092321\n",
      "18 Train Loss 4.406615 Test MSE 2.1458831599159636 Test RE 0.7001822485664302\n",
      "19 Train Loss 4.2423997 Test MSE 2.1432201100457338 Test RE 0.6997476491575202\n",
      "20 Train Loss 4.134389 Test MSE 2.116792599094639 Test RE 0.6954200605803676\n",
      "21 Train Loss 4.0253654 Test MSE 2.080706551358244 Test RE 0.6894669892591568\n",
      "22 Train Loss 3.8778691 Test MSE 2.1107636836089925 Test RE 0.6944290285991832\n",
      "23 Train Loss 3.7227485 Test MSE 2.1028996694350415 Test RE 0.6931342138983141\n",
      "24 Train Loss 2.5982451 Test MSE 1.4241841448736305 Test RE 0.570415257532996\n",
      "25 Train Loss 1.6036434 Test MSE 1.244799240828631 Test RE 0.533282973242988\n",
      "26 Train Loss 1.1392885 Test MSE 0.70067357639659 Test RE 0.400097585195489\n",
      "27 Train Loss 0.7815543 Test MSE 0.3384237864335889 Test RE 0.2780599884567109\n",
      "28 Train Loss 0.51047707 Test MSE 0.1350245078934927 Test RE 0.17563633327585965\n",
      "29 Train Loss 0.3177815 Test MSE 0.09124592798591283 Test RE 0.14438258280423588\n",
      "30 Train Loss 0.22171357 Test MSE 0.06915670381377928 Test RE 0.12569708407683672\n",
      "31 Train Loss 0.13654603 Test MSE 0.04157318013828856 Test RE 0.09745736923061919\n",
      "32 Train Loss 0.097865924 Test MSE 0.021344365060872453 Test RE 0.0698312281760189\n",
      "33 Train Loss 0.078273565 Test MSE 0.017862936199004004 Test RE 0.06388287953245153\n",
      "34 Train Loss 0.06099262 Test MSE 0.015051293768622473 Test RE 0.05864013702278651\n",
      "35 Train Loss 0.050772887 Test MSE 0.011995046670805205 Test RE 0.0523490773085013\n",
      "36 Train Loss 0.04037396 Test MSE 0.012552171370099334 Test RE 0.05355098829248431\n",
      "37 Train Loss 0.033909414 Test MSE 0.00980749208155158 Test RE 0.047335508117131685\n",
      "38 Train Loss 0.028139625 Test MSE 0.008615880059259853 Test RE 0.04436677718210462\n",
      "39 Train Loss 0.022860603 Test MSE 0.008324172525984871 Test RE 0.04360924789214192\n",
      "40 Train Loss 0.020007383 Test MSE 0.007376258941701205 Test RE 0.041051226512983804\n",
      "41 Train Loss 0.016026635 Test MSE 0.006397905169704265 Test RE 0.03823199490204057\n",
      "42 Train Loss 0.014127154 Test MSE 0.006694175490202005 Test RE 0.03910718960298499\n",
      "43 Train Loss 0.011932028 Test MSE 0.005957327298560874 Test RE 0.036892135139823506\n",
      "44 Train Loss 0.010714864 Test MSE 0.004904134727688424 Test RE 0.03347258527484522\n",
      "45 Train Loss 0.008824793 Test MSE 0.003743096367901806 Test RE 0.029243110443359567\n",
      "46 Train Loss 0.008116138 Test MSE 0.0035555469284922103 Test RE 0.028501076762653232\n",
      "47 Train Loss 0.0068220464 Test MSE 0.0035294319703284877 Test RE 0.02839621579673184\n",
      "48 Train Loss 0.0065185884 Test MSE 0.003394568993047714 Test RE 0.02784840846075743\n",
      "49 Train Loss 0.0060664434 Test MSE 0.0032304019821503163 Test RE 0.02716666605984433\n",
      "50 Train Loss 0.0053698854 Test MSE 0.002975621870653352 Test RE 0.026073355812487882\n",
      "51 Train Loss 0.004620072 Test MSE 0.0020682338726279188 Test RE 0.021737414337225126\n",
      "52 Train Loss 0.004039665 Test MSE 0.002068262115389252 Test RE 0.021737562754316007\n",
      "53 Train Loss 0.003899142 Test MSE 0.0019112561093484796 Test RE 0.02089620901226223\n",
      "54 Train Loss 0.003383726 Test MSE 0.0014298888791406529 Test RE 0.01807420503002159\n",
      "55 Train Loss 0.0029279953 Test MSE 0.0014016887276848456 Test RE 0.01789508850570639\n",
      "56 Train Loss 0.0026502467 Test MSE 0.0013829490435489098 Test RE 0.017775063030906004\n",
      "57 Train Loss 0.0025166655 Test MSE 0.0014257323131246045 Test RE 0.018047915818434224\n",
      "58 Train Loss 0.002365236 Test MSE 0.001241383941463718 Test RE 0.01684073809461635\n",
      "59 Train Loss 0.0021560793 Test MSE 0.001355354021517437 Test RE 0.017596829847282974\n",
      "60 Train Loss 0.0020886508 Test MSE 0.0013042019772347166 Test RE 0.017261577696782597\n",
      "61 Train Loss 0.0018645914 Test MSE 0.0012238056637507014 Test RE 0.01672107865068857\n",
      "62 Train Loss 0.0017455538 Test MSE 0.0012533631785918461 Test RE 0.01692179876871621\n",
      "63 Train Loss 0.0016852282 Test MSE 0.0011819218287124375 Test RE 0.01643245444949319\n",
      "64 Train Loss 0.0015782033 Test MSE 0.0011389107226649473 Test RE 0.0161306883723173\n",
      "65 Train Loss 0.00150455 Test MSE 0.0011881698344800098 Test RE 0.016475830728142665\n",
      "66 Train Loss 0.0014701989 Test MSE 0.0012361668530518025 Test RE 0.016805313065472664\n",
      "67 Train Loss 0.0013892557 Test MSE 0.0011593959652174434 Test RE 0.016275110751602147\n",
      "68 Train Loss 0.0013673702 Test MSE 0.0011369928593240822 Test RE 0.016117101051521074\n",
      "69 Train Loss 0.0012803909 Test MSE 0.0009988069139691034 Test RE 0.015105977387899386\n",
      "70 Train Loss 0.0011654274 Test MSE 0.000897543979897342 Test RE 0.014319766271584359\n",
      "71 Train Loss 0.0011503551 Test MSE 0.0008451825048949099 Test RE 0.013895792156408016\n",
      "72 Train Loss 0.0011145624 Test MSE 0.0007552329828983648 Test RE 0.013135558244919356\n",
      "73 Train Loss 0.0010210291 Test MSE 0.000522864640852492 Test RE 0.010929560462280639\n",
      "74 Train Loss 0.0009247456 Test MSE 0.0005363541186185294 Test RE 0.011069649506547558\n",
      "75 Train Loss 0.00088659103 Test MSE 0.0005481532053865026 Test RE 0.011190746019828087\n",
      "76 Train Loss 0.0008773513 Test MSE 0.0005338164164953008 Test RE 0.011043431026190934\n",
      "77 Train Loss 0.0007444358 Test MSE 0.00048287778906668877 Test RE 0.01050332188502016\n",
      "78 Train Loss 0.00071404414 Test MSE 0.000450864782733549 Test RE 0.010149186126207783\n",
      "79 Train Loss 0.00070647715 Test MSE 0.0004863131972321583 Test RE 0.010540618327178836\n",
      "80 Train Loss 0.00068119133 Test MSE 0.0004914432559199981 Test RE 0.010596068326464068\n",
      "81 Train Loss 0.0006563922 Test MSE 0.0005141344436160818 Test RE 0.010837931708639345\n",
      "82 Train Loss 0.00063617626 Test MSE 0.0004603719143707918 Test RE 0.010255632991979454\n",
      "83 Train Loss 0.00062724686 Test MSE 0.0004610369843829584 Test RE 0.010263038148724226\n",
      "84 Train Loss 0.00062195986 Test MSE 0.0004351121165021754 Test RE 0.009970309704663878\n",
      "85 Train Loss 0.00058215915 Test MSE 0.0003844519566161125 Test RE 0.009371931335809104\n",
      "86 Train Loss 0.00054209615 Test MSE 0.0003373897624502185 Test RE 0.00877958545865535\n",
      "87 Train Loss 0.0005342873 Test MSE 0.0003155259254443308 Test RE 0.008490349828556499\n",
      "88 Train Loss 0.0005288928 Test MSE 0.00028236264812223777 Test RE 0.008031777767467609\n",
      "89 Train Loss 0.00050002005 Test MSE 0.0002436961727184457 Test RE 0.007461607745478814\n",
      "90 Train Loss 0.0004899208 Test MSE 0.00023257015074097364 Test RE 0.007289286957787103\n",
      "91 Train Loss 0.00048638156 Test MSE 0.0002419273136836849 Test RE 0.007434478534337676\n",
      "92 Train Loss 0.00046023633 Test MSE 0.00022617857460949448 Test RE 0.007188425757469576\n",
      "93 Train Loss 0.00045378975 Test MSE 0.000213876176833333 Test RE 0.006990194602467499\n",
      "94 Train Loss 0.00045061976 Test MSE 0.00020144402563993126 Test RE 0.006783990891678496\n",
      "95 Train Loss 0.00044003612 Test MSE 0.00017608457209654734 Test RE 0.006342620303299961\n",
      "96 Train Loss 0.00041542895 Test MSE 0.00015731404312498493 Test RE 0.005995036157504659\n",
      "97 Train Loss 0.0003993183 Test MSE 0.00015502230049966285 Test RE 0.005951208267126773\n",
      "98 Train Loss 0.0003974803 Test MSE 0.00016259499054404464 Test RE 0.0060948306212143385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Train Loss 0.0003943736 Test MSE 0.00014911534284386572 Test RE 0.005836724921540851\n",
      "Training time: 44.40\n",
      "KG_stan_tune19\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 53.736458 Test MSE 8.725304043712907 Test RE 1.4118818163725932\n",
      "1 Train Loss 43.857506 Test MSE 8.335229065002505 Test RE 1.3799610549643384\n",
      "2 Train Loss 42.028786 Test MSE 8.668005022725369 Test RE 1.407238270435914\n",
      "3 Train Loss 40.974705 Test MSE 8.648117363769195 Test RE 1.405622976827578\n",
      "4 Train Loss 40.402946 Test MSE 8.577749032679513 Test RE 1.3998926329835273\n",
      "5 Train Loss 40.019226 Test MSE 8.861875468458987 Test RE 1.4228885404115896\n",
      "6 Train Loss 39.464725 Test MSE 9.031813716800839 Test RE 1.4364666450668255\n",
      "7 Train Loss 38.68702 Test MSE 9.064465521245193 Test RE 1.4390608589635019\n",
      "8 Train Loss 37.614243 Test MSE 9.400871813616018 Test RE 1.4655212690285242\n",
      "9 Train Loss 35.91765 Test MSE 8.739284466561402 Test RE 1.4130124820936456\n",
      "10 Train Loss 32.505444 Test MSE 7.608903870232212 Test RE 1.3184665284113826\n",
      "11 Train Loss 26.31828 Test MSE 6.3730399129161235 Test RE 1.2066501729250954\n",
      "12 Train Loss 21.539827 Test MSE 6.181492965919489 Test RE 1.18837840141796\n",
      "13 Train Loss 18.412363 Test MSE 5.908499401354442 Test RE 1.161840893150248\n",
      "14 Train Loss 15.500973 Test MSE 5.845653520572758 Test RE 1.1556454016813702\n",
      "15 Train Loss 13.01399 Test MSE 5.756234128106524 Test RE 1.1467725407552056\n",
      "16 Train Loss 11.325229 Test MSE 5.731670104776336 Test RE 1.1443230691544344\n",
      "17 Train Loss 9.713255 Test MSE 5.890597476733789 Test RE 1.1600794504179452\n",
      "18 Train Loss 8.613298 Test MSE 5.60506484218953 Test RE 1.131614179903697\n",
      "19 Train Loss 8.1019 Test MSE 5.720422837853287 Test RE 1.1431997641728922\n",
      "20 Train Loss 7.650977 Test MSE 5.734745214438043 Test RE 1.1446299995083087\n",
      "21 Train Loss 7.4430075 Test MSE 5.781815459033301 Test RE 1.1493179069073804\n",
      "22 Train Loss 7.2329903 Test MSE 5.82102568618643 Test RE 1.1532084557106828\n",
      "23 Train Loss 6.9743695 Test MSE 5.827376055894317 Test RE 1.1538373228737497\n",
      "24 Train Loss 6.8337035 Test MSE 5.940808909027575 Test RE 1.165013215468387\n",
      "25 Train Loss 6.6407413 Test MSE 6.069072953938212 Test RE 1.177522567620659\n",
      "26 Train Loss 6.5127783 Test MSE 6.055012620400345 Test RE 1.176157782553405\n",
      "27 Train Loss 6.383235 Test MSE 6.16838646563272 Test RE 1.187117885001654\n",
      "28 Train Loss 6.2130256 Test MSE 6.32360890168098 Test RE 1.2019615119974418\n",
      "29 Train Loss 6.1021643 Test MSE 6.394884337806212 Test RE 1.2087163792561135\n",
      "30 Train Loss 5.955125 Test MSE 6.567088944637058 Test RE 1.22488272450418\n",
      "31 Train Loss 5.825864 Test MSE 6.664555321527936 Test RE 1.233938881074217\n",
      "32 Train Loss 5.7178264 Test MSE 6.69192268971235 Test RE 1.2364698123265736\n",
      "33 Train Loss 5.593016 Test MSE 6.777073951012416 Test RE 1.2443116652956374\n",
      "34 Train Loss 5.5081058 Test MSE 6.695628242199568 Test RE 1.2368121033167718\n",
      "35 Train Loss 5.3876905 Test MSE 6.692328823412538 Test RE 1.2365073325180298\n",
      "36 Train Loss 5.264259 Test MSE 6.747956305497028 Test RE 1.2416357001902407\n",
      "37 Train Loss 5.1123276 Test MSE 6.793392478197866 Test RE 1.2458088545890378\n",
      "38 Train Loss 4.9085226 Test MSE 6.705497638865155 Test RE 1.2377233019356686\n",
      "39 Train Loss 4.6647415 Test MSE 6.87508658238838 Test RE 1.2532772210638832\n",
      "40 Train Loss 4.099888 Test MSE 6.63285640003543 Test RE 1.2310008641086414\n",
      "41 Train Loss 2.9272945 Test MSE 6.207996185981917 Test RE 1.190923269375928\n",
      "42 Train Loss 2.1561902 Test MSE 5.933531002086061 Test RE 1.1642993853916945\n",
      "43 Train Loss 1.75784 Test MSE 5.933287414943531 Test RE 1.1642754863616724\n",
      "44 Train Loss 1.553329 Test MSE 5.879365278142972 Test RE 1.1589729022053383\n",
      "45 Train Loss 1.4132982 Test MSE 5.8946847564121345 Test RE 1.1604818499168623\n",
      "46 Train Loss 1.2911544 Test MSE 5.908701615871142 Test RE 1.1618607746014074\n",
      "47 Train Loss 1.2183231 Test MSE 5.935719275403316 Test RE 1.1645140611399545\n",
      "48 Train Loss 1.1352793 Test MSE 5.951791273242068 Test RE 1.1660895580993675\n",
      "49 Train Loss 1.0727186 Test MSE 6.016985315866769 Test RE 1.172458652780271\n",
      "50 Train Loss 1.0354731 Test MSE 6.012170272387386 Test RE 1.1719894336467807\n",
      "51 Train Loss 0.9946597 Test MSE 5.982895624169355 Test RE 1.1691326078965976\n",
      "52 Train Loss 0.9676054 Test MSE 5.990978634165551 Test RE 1.1699221019378434\n",
      "53 Train Loss 0.93871886 Test MSE 6.001491141196866 Test RE 1.1709480965665346\n",
      "54 Train Loss 0.9125181 Test MSE 6.02275970781728 Test RE 1.1730211115459437\n",
      "55 Train Loss 0.89234316 Test MSE 6.045407267952354 Test RE 1.1752245149695508\n",
      "56 Train Loss 0.868479 Test MSE 6.093881832296125 Test RE 1.1799268245246672\n",
      "57 Train Loss 0.8512472 Test MSE 6.105769918799065 Test RE 1.181077178118893\n",
      "58 Train Loss 0.8368795 Test MSE 6.143423729989832 Test RE 1.1847133865189243\n",
      "59 Train Loss 0.822536 Test MSE 6.155054097883491 Test RE 1.185834271067285\n",
      "60 Train Loss 0.8094351 Test MSE 6.164215750635744 Test RE 1.186716486062436\n",
      "61 Train Loss 0.800516 Test MSE 6.156788752116079 Test RE 1.1860013587561398\n",
      "62 Train Loss 0.79099107 Test MSE 6.1569275204958815 Test RE 1.1860147243730434\n",
      "63 Train Loss 0.78181064 Test MSE 6.179116699892817 Test RE 1.1881499635083472\n",
      "64 Train Loss 0.7728174 Test MSE 6.2107257481815505 Test RE 1.1911850560941442\n",
      "65 Train Loss 0.76574033 Test MSE 6.221611478815426 Test RE 1.1922285124690652\n",
      "66 Train Loss 0.7588031 Test MSE 6.226073111126705 Test RE 1.1926559203821252\n",
      "67 Train Loss 0.7515391 Test MSE 6.224029814038566 Test RE 1.1924601990742827\n",
      "68 Train Loss 0.74414104 Test MSE 6.236919118203763 Test RE 1.1936942896473284\n",
      "69 Train Loss 0.7378837 Test MSE 6.277377723743176 Test RE 1.1975597508072893\n",
      "70 Train Loss 0.73021144 Test MSE 6.28961788256212 Test RE 1.1987267335539784\n",
      "71 Train Loss 0.72332716 Test MSE 6.296628939144759 Test RE 1.1993946596769296\n",
      "72 Train Loss 0.713975 Test MSE 6.326954362776857 Test RE 1.2022794146258713\n",
      "73 Train Loss 0.7076164 Test MSE 6.34588561413174 Test RE 1.2040767765195743\n",
      "74 Train Loss 0.6998939 Test MSE 6.348865792101875 Test RE 1.2043594747988806\n",
      "75 Train Loss 0.6942799 Test MSE 6.358272626986397 Test RE 1.2052513677526566\n",
      "76 Train Loss 0.6865406 Test MSE 6.372068202918815 Test RE 1.2065581792494242\n",
      "77 Train Loss 0.67992234 Test MSE 6.376702077590103 Test RE 1.2069968141716594\n",
      "78 Train Loss 0.6738094 Test MSE 6.36694967103328 Test RE 1.2060734820495682\n",
      "79 Train Loss 0.66800016 Test MSE 6.383337733406356 Test RE 1.2076246569656317\n",
      "80 Train Loss 0.66019523 Test MSE 6.416468925356707 Test RE 1.210754544857139\n",
      "81 Train Loss 0.6554436 Test MSE 6.444688821721986 Test RE 1.213414098202345\n",
      "82 Train Loss 0.6493981 Test MSE 6.469974244819518 Test RE 1.2157921535342515\n",
      "83 Train Loss 0.6442354 Test MSE 6.511122694460923 Test RE 1.2196521898289292\n",
      "84 Train Loss 0.6372726 Test MSE 6.536582246217096 Test RE 1.2220343829090685\n",
      "85 Train Loss 0.6321651 Test MSE 6.549989125042596 Test RE 1.2232869698066355\n",
      "86 Train Loss 0.6276405 Test MSE 6.548876312653197 Test RE 1.2231830500371623\n",
      "87 Train Loss 0.62331086 Test MSE 6.5513163112546575 Test RE 1.2234108972922746\n",
      "88 Train Loss 0.6195228 Test MSE 6.563081689609324 Test RE 1.2245089541389236\n",
      "89 Train Loss 0.6147556 Test MSE 6.571626210550368 Test RE 1.2253057931620566\n",
      "90 Train Loss 0.60995024 Test MSE 6.583148300236379 Test RE 1.226379492416158\n",
      "91 Train Loss 0.60561585 Test MSE 6.5975110448686385 Test RE 1.2277165865943138\n",
      "92 Train Loss 0.60198796 Test MSE 6.609136791051723 Test RE 1.2287978154883226\n",
      "93 Train Loss 0.59812534 Test MSE 6.641555032549416 Test RE 1.231807795168746\n",
      "94 Train Loss 0.5946854 Test MSE 6.655218359817888 Test RE 1.2330742113672442\n",
      "95 Train Loss 0.5919136 Test MSE 6.653916041816928 Test RE 1.232953559179536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 0.5885901 Test MSE 6.666820119688872 Test RE 1.2341485263537435\n",
      "97 Train Loss 0.58522457 Test MSE 6.681229349957459 Test RE 1.2354815105597194\n",
      "98 Train Loss 0.5819085 Test MSE 6.704624279817507 Test RE 1.2376426955360569\n",
      "99 Train Loss 0.5789872 Test MSE 6.719866859297177 Test RE 1.2390487517510722\n",
      "Training time: 43.73\n",
      "KG_stan_tune19\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.180817 Test MSE 8.589629510729377 Test RE 1.4008617473080556\n",
      "1 Train Loss 44.65274 Test MSE 7.793986733011946 Test RE 1.3344057091073283\n",
      "2 Train Loss 43.83818 Test MSE 8.277133287864526 Test RE 1.3751435453039043\n",
      "3 Train Loss 43.298653 Test MSE 8.253885800447748 Test RE 1.3732110458607947\n",
      "4 Train Loss 42.492744 Test MSE 8.25928851704592 Test RE 1.3736604012685518\n",
      "5 Train Loss 41.623222 Test MSE 8.143048902723168 Test RE 1.363959835189442\n",
      "6 Train Loss 40.170235 Test MSE 8.05065394551353 Test RE 1.3561996869860318\n",
      "7 Train Loss 38.594917 Test MSE 8.327509913250145 Test RE 1.3793219245903512\n",
      "8 Train Loss 36.311005 Test MSE 8.220257584234691 Test RE 1.370410802998498\n",
      "9 Train Loss 33.20088 Test MSE 7.418317843489978 Test RE 1.3018494945752206\n",
      "10 Train Loss 30.06946 Test MSE 7.067589108105337 Test RE 1.2707019800903465\n",
      "11 Train Loss 23.595335 Test MSE 5.893468067507619 Test RE 1.160362079452919\n",
      "12 Train Loss 19.520504 Test MSE 5.487508500610795 Test RE 1.11968449240261\n",
      "13 Train Loss 17.377958 Test MSE 5.148283932511336 Test RE 1.0845243456286746\n",
      "14 Train Loss 15.534063 Test MSE 4.842162388731973 Test RE 1.0517868465195943\n",
      "15 Train Loss 14.051166 Test MSE 4.011358116139644 Test RE 0.9573126066228546\n",
      "16 Train Loss 7.7759624 Test MSE 1.41566491484981 Test RE 0.5687066344596512\n",
      "17 Train Loss 5.195843 Test MSE 1.0386850553012446 Test RE 0.4871357488335592\n",
      "18 Train Loss 3.1925201 Test MSE 0.4434937733416344 Test RE 0.3183111294861655\n",
      "19 Train Loss 1.8123676 Test MSE 0.1836853290892559 Test RE 0.2048543996043124\n",
      "20 Train Loss 0.99136955 Test MSE 0.12370293191086709 Test RE 0.16811174525373432\n",
      "21 Train Loss 0.5488069 Test MSE 0.04788134667550446 Test RE 0.10459025902430581\n",
      "22 Train Loss 0.35196275 Test MSE 0.039083642083346685 Test RE 0.09449429169811231\n",
      "23 Train Loss 0.2616454 Test MSE 0.030699310923241217 Test RE 0.0837476007538211\n",
      "24 Train Loss 0.19116516 Test MSE 0.02676886863092008 Test RE 0.07820293784454962\n",
      "25 Train Loss 0.13811265 Test MSE 0.02378002723422547 Test RE 0.07370793329018564\n",
      "26 Train Loss 0.10403357 Test MSE 0.028217261995943013 Test RE 0.08029074646390556\n",
      "27 Train Loss 0.08597784 Test MSE 0.02759102713232862 Test RE 0.07939478818722115\n",
      "28 Train Loss 0.07409173 Test MSE 0.02079457648134127 Test RE 0.06892600386934325\n",
      "29 Train Loss 0.06127979 Test MSE 0.019605663033046113 Test RE 0.06692660997596787\n",
      "30 Train Loss 0.05296126 Test MSE 0.018494241677762657 Test RE 0.06500194091253762\n",
      "31 Train Loss 0.04628271 Test MSE 0.013865545607636115 Test RE 0.056282909794826426\n",
      "32 Train Loss 0.04065598 Test MSE 0.012670066028914958 Test RE 0.0538018859311507\n",
      "33 Train Loss 0.035923522 Test MSE 0.012465937323948434 Test RE 0.05336672228168814\n",
      "34 Train Loss 0.031055324 Test MSE 0.012177040993458435 Test RE 0.052744714308327986\n",
      "35 Train Loss 0.026509762 Test MSE 0.010350039979143731 Test RE 0.04862717881010133\n",
      "36 Train Loss 0.023900567 Test MSE 0.00862869441092812 Test RE 0.04439975815705426\n",
      "37 Train Loss 0.021283485 Test MSE 0.00715000737522869 Test RE 0.04041674229079127\n",
      "38 Train Loss 0.018934965 Test MSE 0.006636560117136574 Test RE 0.038938532204413186\n",
      "39 Train Loss 0.017832948 Test MSE 0.006711186957566797 Test RE 0.039156848337258375\n",
      "40 Train Loss 0.016149104 Test MSE 0.005742425865600138 Test RE 0.03622060989784309\n",
      "41 Train Loss 0.0144302 Test MSE 0.005191047762051609 Test RE 0.034437813730935234\n",
      "42 Train Loss 0.013430177 Test MSE 0.005278742049678187 Test RE 0.03472748084607054\n",
      "43 Train Loss 0.012005357 Test MSE 0.004573881718273684 Test RE 0.032325892548937016\n",
      "44 Train Loss 0.0107451305 Test MSE 0.003652973186770854 Test RE 0.02888891975212773\n",
      "45 Train Loss 0.009928488 Test MSE 0.0033950691802942913 Test RE 0.027850460106444035\n",
      "46 Train Loss 0.008957397 Test MSE 0.0029159161564767068 Test RE 0.025810449996928213\n",
      "47 Train Loss 0.008274422 Test MSE 0.0027101490464331553 Test RE 0.02488310935626259\n",
      "48 Train Loss 0.0074755885 Test MSE 0.002405014809754106 Test RE 0.023440503594323297\n",
      "49 Train Loss 0.006985736 Test MSE 0.0022269004355335302 Test RE 0.022555811701180713\n",
      "50 Train Loss 0.006328888 Test MSE 0.002076443429092436 Test RE 0.021780513378382077\n",
      "51 Train Loss 0.005724292 Test MSE 0.0018219939736760012 Test RE 0.0204024127069855\n",
      "52 Train Loss 0.0052723577 Test MSE 0.0015046233859808016 Test RE 0.01854052228889713\n",
      "53 Train Loss 0.004832035 Test MSE 0.0012548820960675217 Test RE 0.016932049202861673\n",
      "54 Train Loss 0.0046607926 Test MSE 0.001287748709612774 Test RE 0.01715234968098218\n",
      "55 Train Loss 0.004314961 Test MSE 0.0012361131815909442 Test RE 0.016804948237904814\n",
      "56 Train Loss 0.004079142 Test MSE 0.0012156899822172965 Test RE 0.01666554341284227\n",
      "57 Train Loss 0.0036978046 Test MSE 0.0011165774444369786 Test RE 0.015971749332485956\n",
      "58 Train Loss 0.0034145368 Test MSE 0.0010248650233046501 Test RE 0.015301760357509556\n",
      "59 Train Loss 0.003178138 Test MSE 0.0009056855360903995 Test RE 0.014384566433358158\n",
      "60 Train Loss 0.0029477878 Test MSE 0.0009084363099520706 Test RE 0.014406394478818588\n",
      "61 Train Loss 0.002851946 Test MSE 0.0009764796855821692 Test RE 0.014936184398443051\n",
      "62 Train Loss 0.0026073463 Test MSE 0.0009016177320029883 Test RE 0.014352226594702243\n",
      "63 Train Loss 0.0024770605 Test MSE 0.0008374856993792058 Test RE 0.013832375189481367\n",
      "64 Train Loss 0.0023088893 Test MSE 0.0007476579568146624 Test RE 0.013069517062395316\n",
      "65 Train Loss 0.0022230342 Test MSE 0.0007237626065310103 Test RE 0.0128589684558915\n",
      "66 Train Loss 0.002056765 Test MSE 0.0007216221880047924 Test RE 0.012839940149226502\n",
      "67 Train Loss 0.0019498747 Test MSE 0.0006871393356942731 Test RE 0.012529405520598938\n",
      "68 Train Loss 0.0018741881 Test MSE 0.0006242345466685198 Test RE 0.011942134556643617\n",
      "69 Train Loss 0.0017859614 Test MSE 0.0005964841912416829 Test RE 0.011673673146742818\n",
      "70 Train Loss 0.0017261953 Test MSE 0.0006095842203337978 Test RE 0.011801165975170043\n",
      "71 Train Loss 0.0015354881 Test MSE 0.0005604956319869113 Test RE 0.011316032249910861\n",
      "72 Train Loss 0.0014346017 Test MSE 0.00048128414181286035 Test RE 0.010485975442570577\n",
      "73 Train Loss 0.0013853732 Test MSE 0.00045617163256026936 Test RE 0.0102087412809325\n",
      "74 Train Loss 0.0013117747 Test MSE 0.00042152648092393195 Test RE 0.009813422379226265\n",
      "75 Train Loss 0.0012256952 Test MSE 0.00043591550586543883 Test RE 0.009979510030791115\n",
      "76 Train Loss 0.0011693601 Test MSE 0.00040304742463422515 Test RE 0.009595909324914047\n",
      "77 Train Loss 0.0011373871 Test MSE 0.0003972540354149025 Test RE 0.009526694072097847\n",
      "78 Train Loss 0.0010605094 Test MSE 0.0003437735938958206 Test RE 0.0088622565373034\n",
      "79 Train Loss 0.0010165247 Test MSE 0.00031502184742266716 Test RE 0.008483565109620728\n",
      "80 Train Loss 0.0009928382 Test MSE 0.0003199407895316255 Test RE 0.008549542319610642\n",
      "81 Train Loss 0.0009674185 Test MSE 0.0003285528049670315 Test RE 0.008663844520089318\n",
      "82 Train Loss 0.00088353833 Test MSE 0.0002964786344184747 Test RE 0.008230093347241516\n",
      "83 Train Loss 0.0008443217 Test MSE 0.00028613677903472615 Test RE 0.008085276981251365\n",
      "84 Train Loss 0.00082399853 Test MSE 0.00027335263001807545 Test RE 0.007902594332082317\n",
      "85 Train Loss 0.00076057983 Test MSE 0.0002568877839931821 Test RE 0.007660899877685351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 0.00072368945 Test MSE 0.00023661954711418794 Test RE 0.007352471837348148\n",
      "87 Train Loss 0.00070377055 Test MSE 0.0002280849871656706 Test RE 0.007218657066825027\n",
      "88 Train Loss 0.0006760162 Test MSE 0.00021541847779886342 Test RE 0.007015353126167515\n",
      "89 Train Loss 0.00064031983 Test MSE 0.00021417267409491446 Test RE 0.006995038189494752\n",
      "90 Train Loss 0.0006205817 Test MSE 0.00017934679467782337 Test RE 0.006401103802492447\n",
      "91 Train Loss 0.0006068706 Test MSE 0.00017248005757589018 Test RE 0.006277366776433894\n",
      "92 Train Loss 0.0005928312 Test MSE 0.00017459386445273152 Test RE 0.006315715365584909\n",
      "93 Train Loss 0.00057591056 Test MSE 0.0001501477960507178 Test RE 0.005856896388014002\n",
      "94 Train Loss 0.00054416695 Test MSE 0.0001302533894903927 Test RE 0.005455098250932989\n",
      "95 Train Loss 0.0005258668 Test MSE 0.00012872018362338012 Test RE 0.005422897372948859\n",
      "96 Train Loss 0.00051246746 Test MSE 0.00012929453402552013 Test RE 0.0054349824109703945\n",
      "97 Train Loss 0.00049718353 Test MSE 0.00012892372733481211 Test RE 0.005427183261208343\n",
      "98 Train Loss 0.00047216937 Test MSE 0.00012464216555230386 Test RE 0.005336303884605149\n",
      "99 Train Loss 0.00043709244 Test MSE 0.00010895877960837874 Test RE 0.004989294912370635\n",
      "Training time: 42.37\n",
      "KG_stan_tune19\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 60.808468 Test MSE 8.493779471851385 Test RE 1.3930238459096942\n",
      "1 Train Loss 51.84256 Test MSE 9.47441380475422 Test RE 1.4712424080973698\n",
      "2 Train Loss 45.35906 Test MSE 8.844161505655508 Test RE 1.421465726306951\n",
      "3 Train Loss 44.206093 Test MSE 8.28032431322845 Test RE 1.3754085945021528\n",
      "4 Train Loss 43.7894 Test MSE 8.536319071208114 Test RE 1.3965078464688163\n",
      "5 Train Loss 43.278397 Test MSE 8.445315772440367 Test RE 1.3890440118520797\n",
      "6 Train Loss 43.024715 Test MSE 8.460297581665799 Test RE 1.3902755330782512\n",
      "7 Train Loss 42.63088 Test MSE 8.309522252732577 Test RE 1.3778314317978777\n",
      "8 Train Loss 42.35838 Test MSE 8.352244649897221 Test RE 1.3813688670971624\n",
      "9 Train Loss 41.134426 Test MSE 8.149276005083234 Test RE 1.364481255019601\n",
      "10 Train Loss 40.02937 Test MSE 8.057885007325654 Test RE 1.3568086165663467\n",
      "11 Train Loss 38.411453 Test MSE 7.849920335559557 Test RE 1.3391853353263488\n",
      "12 Train Loss 37.363308 Test MSE 7.685933322555543 Test RE 1.3251235324470678\n",
      "13 Train Loss 36.388527 Test MSE 7.540629451618717 Test RE 1.312537922969573\n",
      "14 Train Loss 35.247696 Test MSE 7.369784937798528 Test RE 1.2975839576040804\n",
      "15 Train Loss 34.46577 Test MSE 7.438145145539047 Test RE 1.303588092148645\n",
      "16 Train Loss 34.083435 Test MSE 7.303292094580426 Test RE 1.291717060355319\n",
      "17 Train Loss 33.74437 Test MSE 7.233922851763147 Test RE 1.285567831637752\n",
      "18 Train Loss 33.294052 Test MSE 7.223539702288934 Test RE 1.2846448859213657\n",
      "19 Train Loss 32.935677 Test MSE 7.2221619155742145 Test RE 1.2845223662747034\n",
      "20 Train Loss 32.503086 Test MSE 7.213713222816164 Test RE 1.2837708108055743\n",
      "21 Train Loss 32.07773 Test MSE 7.418384549757028 Test RE 1.301855347743463\n",
      "22 Train Loss 31.557768 Test MSE 7.285071697107298 Test RE 1.2901047534965684\n",
      "23 Train Loss 31.036976 Test MSE 7.242113240397488 Test RE 1.2862953982491787\n",
      "24 Train Loss 30.56467 Test MSE 7.29521801022578 Test RE 1.2910028402127631\n",
      "25 Train Loss 30.113415 Test MSE 7.229864791190246 Test RE 1.2852071943953585\n",
      "26 Train Loss 29.595001 Test MSE 7.059424669376786 Test RE 1.2699678141539568\n",
      "27 Train Loss 28.815666 Test MSE 7.054498054104612 Test RE 1.269524595683937\n",
      "28 Train Loss 28.01376 Test MSE 6.97254989125128 Test RE 1.2621293774190678\n",
      "29 Train Loss 26.956976 Test MSE 6.88551778461204 Test RE 1.2542276260459975\n",
      "30 Train Loss 26.022144 Test MSE 6.935050867522336 Test RE 1.2587308771330954\n",
      "31 Train Loss 24.341595 Test MSE 7.140599300717049 Test RE 1.2772484720129174\n",
      "32 Train Loss 22.020948 Test MSE 6.982831305984806 Test RE 1.2630595748122613\n",
      "33 Train Loss 19.527811 Test MSE 6.37124498031069 Test RE 1.2064802376751806\n",
      "34 Train Loss 16.191544 Test MSE 5.526474522239951 Test RE 1.12365282082742\n",
      "35 Train Loss 13.502677 Test MSE 4.407152079132372 Test RE 1.0034299945826985\n",
      "36 Train Loss 11.654255 Test MSE 4.340605566793893 Test RE 0.9958254513691553\n",
      "37 Train Loss 10.579192 Test MSE 4.161286354264243 Test RE 0.9750387177995422\n",
      "38 Train Loss 9.762009 Test MSE 4.087096857392497 Test RE 0.9663078891394115\n",
      "39 Train Loss 8.99843 Test MSE 3.7887858454903727 Test RE 0.9303751229559563\n",
      "40 Train Loss 8.448343 Test MSE 3.6689906713462364 Test RE 0.915548518151748\n",
      "41 Train Loss 7.848482 Test MSE 3.4987600780845236 Test RE 0.8940568634599267\n",
      "42 Train Loss 7.1323175 Test MSE 3.4588194736474724 Test RE 0.8889390978213869\n",
      "43 Train Loss 6.6221466 Test MSE 3.2641061072381867 Test RE 0.8635553802074702\n",
      "44 Train Loss 5.891575 Test MSE 2.671335119710768 Test RE 0.7812180106010752\n",
      "45 Train Loss 4.884098 Test MSE 2.6816535515089717 Test RE 0.782725342187546\n",
      "46 Train Loss 4.3239446 Test MSE 2.5352568661809487 Test RE 0.7610602581239253\n",
      "47 Train Loss 3.4348385 Test MSE 2.5406323786786786 Test RE 0.7618666700289018\n",
      "48 Train Loss 3.0272298 Test MSE 2.4801685340837776 Test RE 0.7527463475651738\n",
      "49 Train Loss 2.6969545 Test MSE 2.5786879729994157 Test RE 0.7675513813783646\n",
      "50 Train Loss 2.479978 Test MSE 2.4348340987328196 Test RE 0.7458349796171131\n",
      "51 Train Loss 2.3355 Test MSE 2.3801552580884406 Test RE 0.7374128543740757\n",
      "52 Train Loss 2.0975196 Test MSE 2.381845949133084 Test RE 0.7376747103990842\n",
      "53 Train Loss 1.957034 Test MSE 2.3299488725957356 Test RE 0.7295940034499319\n",
      "54 Train Loss 1.7599186 Test MSE 2.429806792183191 Test RE 0.7450646029946874\n",
      "55 Train Loss 1.6129544 Test MSE 2.4428507827848343 Test RE 0.7470618003507332\n",
      "56 Train Loss 1.4283049 Test MSE 2.5283743147407525 Test RE 0.7600265174703088\n",
      "57 Train Loss 1.3041489 Test MSE 2.577085959491035 Test RE 0.7673129231526034\n",
      "58 Train Loss 1.1968368 Test MSE 2.647666812914029 Test RE 0.7777494742256753\n",
      "59 Train Loss 1.1364747 Test MSE 2.6231513193717966 Test RE 0.7741403996009986\n",
      "60 Train Loss 1.0446754 Test MSE 2.611603071687413 Test RE 0.7724344693848273\n",
      "61 Train Loss 0.9868203 Test MSE 2.6545425071463655 Test RE 0.7787586835963756\n",
      "62 Train Loss 0.92255694 Test MSE 2.722114552466266 Test RE 0.7886081461564122\n",
      "63 Train Loss 0.8611457 Test MSE 2.7532788977972773 Test RE 0.7931095208306177\n",
      "64 Train Loss 0.8254331 Test MSE 2.78736307447294 Test RE 0.7980035649577486\n",
      "65 Train Loss 0.77581286 Test MSE 2.8395009223656262 Test RE 0.8054323469756883\n",
      "66 Train Loss 0.7491914 Test MSE 2.8482540664763847 Test RE 0.80667281858694\n",
      "67 Train Loss 0.7009983 Test MSE 2.9232782308675698 Test RE 0.8172278088729504\n",
      "68 Train Loss 0.6635514 Test MSE 2.9432010079516586 Test RE 0.8200078728808118\n",
      "69 Train Loss 0.6393998 Test MSE 2.9806794351615706 Test RE 0.8252123062202361\n",
      "70 Train Loss 0.61281693 Test MSE 2.982729040442731 Test RE 0.8254959779266606\n",
      "71 Train Loss 0.5924251 Test MSE 2.964866706648602 Test RE 0.8230204887504554\n",
      "72 Train Loss 0.5684285 Test MSE 2.956647754498598 Test RE 0.8218789432621156\n",
      "73 Train Loss 0.55353975 Test MSE 3.0003419779752813 Test RE 0.8279296566694928\n",
      "74 Train Loss 0.5384354 Test MSE 3.013568304793261 Test RE 0.8297525199738953\n",
      "75 Train Loss 0.52465045 Test MSE 3.0107824169031026 Test RE 0.8293688996692413\n",
      "76 Train Loss 0.5127339 Test MSE 3.033773299122537 Test RE 0.8325294833392721\n",
      "77 Train Loss 0.5037744 Test MSE 3.050270132781902 Test RE 0.8347899489486903\n",
      "78 Train Loss 0.49305528 Test MSE 3.0791882284896865 Test RE 0.8387377286710144\n",
      "79 Train Loss 0.48091578 Test MSE 3.0963862947455487 Test RE 0.8410767512694507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Train Loss 0.47198805 Test MSE 3.111598515309726 Test RE 0.8431402807571698\n",
      "81 Train Loss 0.46321285 Test MSE 3.1181732137882783 Test RE 0.8440305736298874\n",
      "82 Train Loss 0.4576016 Test MSE 3.145567589806759 Test RE 0.8477300360872542\n",
      "83 Train Loss 0.45161748 Test MSE 3.1735127733489166 Test RE 0.8514873211958822\n",
      "84 Train Loss 0.44633555 Test MSE 3.1936663055546073 Test RE 0.8541867460840671\n",
      "85 Train Loss 0.44192794 Test MSE 3.199892892015132 Test RE 0.8550190305551792\n",
      "86 Train Loss 0.43655363 Test MSE 3.198888218063475 Test RE 0.8548847943769308\n",
      "87 Train Loss 0.4307018 Test MSE 3.220702345256465 Test RE 0.8577946930426027\n",
      "88 Train Loss 0.42829737 Test MSE 3.19662929150161 Test RE 0.8545828983933369\n",
      "89 Train Loss 0.42243132 Test MSE 3.216907636501187 Test RE 0.8572892069635163\n",
      "90 Train Loss 0.42043605 Test MSE 3.2115854436066043 Test RE 0.8565797449941455\n",
      "91 Train Loss 0.41188675 Test MSE 3.249754892462366 Test RE 0.8616549026451762\n",
      "92 Train Loss 0.40735477 Test MSE 3.266282896788082 Test RE 0.8638432790946732\n",
      "93 Train Loss 0.40381408 Test MSE 3.284537829942692 Test RE 0.866253883099773\n",
      "94 Train Loss 0.39999163 Test MSE 3.302419457529699 Test RE 0.8686087051001629\n",
      "95 Train Loss 0.3969285 Test MSE 3.3134584698398806 Test RE 0.8700592450341315\n",
      "96 Train Loss 0.39544022 Test MSE 3.3154703520092927 Test RE 0.8703233483970134\n",
      "97 Train Loss 0.39149463 Test MSE 3.333224763669716 Test RE 0.8726505367022293\n",
      "98 Train Loss 0.3874316 Test MSE 3.3328069294623237 Test RE 0.8725958397197748\n",
      "99 Train Loss 0.38470846 Test MSE 3.3638344110578977 Test RE 0.8766482390485545\n",
      "Training time: 43.09\n",
      "KG_stan_tune19\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 55.92901 Test MSE 8.087721199180214 Test RE 1.3593182452014556\n",
      "1 Train Loss 50.111397 Test MSE 8.878260491638947 Test RE 1.4242033464710173\n",
      "2 Train Loss 47.110695 Test MSE 8.694873347795875 Test RE 1.4094176000732959\n",
      "3 Train Loss 46.036392 Test MSE 8.524691054837213 Test RE 1.3955563737250734\n",
      "4 Train Loss 45.157436 Test MSE 8.34225757856423 Test RE 1.3805427445098912\n",
      "5 Train Loss 44.634132 Test MSE 8.389514147987233 Test RE 1.3844474179742727\n",
      "6 Train Loss 43.68347 Test MSE 8.581806508251514 Test RE 1.4002236847899057\n",
      "7 Train Loss 43.142822 Test MSE 8.472845920776443 Test RE 1.3913061815046794\n",
      "8 Train Loss 42.577618 Test MSE 8.308825584492801 Test RE 1.3777736720681844\n",
      "9 Train Loss 41.470306 Test MSE 8.188446231595165 Test RE 1.3677565747649953\n",
      "10 Train Loss 36.561333 Test MSE 8.798695623790495 Test RE 1.4178072977069907\n",
      "11 Train Loss 31.981817 Test MSE 8.388333085549082 Test RE 1.3843499643931998\n",
      "12 Train Loss 28.260223 Test MSE 8.293344632951264 Test RE 1.3764895440267584\n",
      "13 Train Loss 23.018764 Test MSE 7.019447085357365 Test RE 1.2663667893037864\n",
      "14 Train Loss 21.003933 Test MSE 6.9608422013852795 Test RE 1.2610693041557868\n",
      "15 Train Loss 19.639477 Test MSE 6.090348646024274 Test RE 1.179584718636952\n",
      "16 Train Loss 17.455322 Test MSE 5.810273230202509 Test RE 1.1521428742061344\n",
      "17 Train Loss 15.844784 Test MSE 4.912529463427522 Test RE 1.059401648373253\n",
      "18 Train Loss 14.616873 Test MSE 4.903319597272331 Test RE 1.0584081149237157\n",
      "19 Train Loss 13.638533 Test MSE 5.472571441230345 Test RE 1.1181595571306457\n",
      "20 Train Loss 12.302999 Test MSE 5.7791028996443785 Test RE 1.1490482719765684\n",
      "21 Train Loss 10.892954 Test MSE 5.939672552428861 Test RE 1.16490178840612\n",
      "22 Train Loss 10.143818 Test MSE 5.843055167874852 Test RE 1.155388534926523\n",
      "23 Train Loss 9.155577 Test MSE 5.649155331136817 Test RE 1.1360562060143249\n",
      "24 Train Loss 8.071754 Test MSE 5.604650135874248 Test RE 1.1315723163177447\n",
      "25 Train Loss 5.0536766 Test MSE 4.820278966446498 Test RE 1.0494074591800902\n",
      "26 Train Loss 3.1912556 Test MSE 4.802039500505838 Test RE 1.0474201496641689\n",
      "27 Train Loss 2.6383476 Test MSE 5.034616523677678 Test RE 1.0724850788577596\n",
      "28 Train Loss 2.280302 Test MSE 5.064012571980821 Test RE 1.0756115272478464\n",
      "29 Train Loss 2.0999756 Test MSE 5.10897009385862 Test RE 1.080375533631362\n",
      "30 Train Loss 1.9808782 Test MSE 5.089392338382597 Test RE 1.0783035279522069\n",
      "31 Train Loss 1.8591924 Test MSE 5.146735890804376 Test RE 1.0843612801133633\n",
      "32 Train Loss 1.7657071 Test MSE 5.225445442731664 Test RE 1.0926214423694496\n",
      "33 Train Loss 1.6689737 Test MSE 5.272035173889471 Test RE 1.0974815042111703\n",
      "34 Train Loss 1.6018271 Test MSE 5.356252665574614 Test RE 1.1062125671648755\n",
      "35 Train Loss 1.5526464 Test MSE 5.371395735893936 Test RE 1.1077751924382029\n",
      "36 Train Loss 1.509918 Test MSE 5.396441669140708 Test RE 1.110354875370964\n",
      "37 Train Loss 1.455398 Test MSE 5.470959297571743 Test RE 1.1179948478494617\n",
      "38 Train Loss 1.4011445 Test MSE 5.568916006770628 Test RE 1.1279592085306946\n",
      "39 Train Loss 1.3336542 Test MSE 5.603484190396679 Test RE 1.1314546086806327\n",
      "40 Train Loss 1.2703687 Test MSE 5.634252652035601 Test RE 1.134556737464259\n",
      "41 Train Loss 1.2115854 Test MSE 5.755519250069749 Test RE 1.1467013285755832\n",
      "42 Train Loss 1.1726335 Test MSE 5.734897925994576 Test RE 1.144645239685394\n",
      "43 Train Loss 1.1385138 Test MSE 5.773278670276664 Test RE 1.1484691156783058\n",
      "44 Train Loss 1.1021861 Test MSE 5.7774605211819345 Test RE 1.1488849848482605\n",
      "45 Train Loss 1.0767174 Test MSE 5.794347923239194 Test RE 1.1505628436224875\n",
      "46 Train Loss 1.0405095 Test MSE 5.847127725411132 Test RE 1.155791112562073\n",
      "47 Train Loss 1.0081841 Test MSE 5.958755649707455 Test RE 1.1667715975062447\n",
      "48 Train Loss 0.9471631 Test MSE 6.01861698247711 Test RE 1.172617613776388\n",
      "49 Train Loss 0.90351933 Test MSE 6.126500562567116 Test RE 1.1830805080022908\n",
      "50 Train Loss 0.87568295 Test MSE 6.160613845495714 Test RE 1.1863697213658488\n",
      "51 Train Loss 0.8487906 Test MSE 6.189941104590426 Test RE 1.1891901921693568\n",
      "52 Train Loss 0.8254825 Test MSE 6.208707016576916 Test RE 1.1909914492232845\n",
      "53 Train Loss 0.80540025 Test MSE 6.240127807416814 Test RE 1.194001308338596\n",
      "54 Train Loss 0.78418154 Test MSE 6.347464961496434 Test RE 1.2042266009329392\n",
      "55 Train Loss 0.76663345 Test MSE 6.3518049100218485 Test RE 1.2046382131637559\n",
      "56 Train Loss 0.75102735 Test MSE 6.346069116452431 Test RE 1.2040941853809166\n",
      "57 Train Loss 0.73693347 Test MSE 6.373039425944918 Test RE 1.2066501268243404\n",
      "58 Train Loss 0.7251371 Test MSE 6.410991900869183 Test RE 1.2102376914226916\n",
      "59 Train Loss 0.7145344 Test MSE 6.402675626233676 Test RE 1.209452482578451\n",
      "60 Train Loss 0.70375496 Test MSE 6.442457072316371 Test RE 1.2132039817210603\n",
      "61 Train Loss 0.69409496 Test MSE 6.473202142915262 Test RE 1.2160953976948259\n",
      "62 Train Loss 0.68226457 Test MSE 6.499160027421052 Test RE 1.2185312617291566\n",
      "63 Train Loss 0.6731744 Test MSE 6.54701004904016 Test RE 1.2230087495490862\n",
      "64 Train Loss 0.6650413 Test MSE 6.54922292260926 Test RE 1.2232154190874658\n",
      "65 Train Loss 0.65718246 Test MSE 6.557913624345789 Test RE 1.2240267425205047\n",
      "66 Train Loss 0.646145 Test MSE 6.5742869319584125 Test RE 1.2255538190935578\n",
      "67 Train Loss 0.63883567 Test MSE 6.613567115606061 Test RE 1.229209598546601\n",
      "68 Train Loss 0.6294903 Test MSE 6.642588561583122 Test RE 1.2319036356450344\n",
      "69 Train Loss 0.62085927 Test MSE 6.665780494087417 Test RE 1.2340522958866889\n",
      "70 Train Loss 0.61381066 Test MSE 6.680319155062343 Test RE 1.2353973518512886\n",
      "71 Train Loss 0.60690606 Test MSE 6.709995540126301 Test RE 1.2381383512155015\n",
      "72 Train Loss 0.5993046 Test MSE 6.74781316289597 Test RE 1.241622530876585\n",
      "73 Train Loss 0.5924486 Test MSE 6.788474332462677 Test RE 1.2453578149306543\n",
      "74 Train Loss 0.5861851 Test MSE 6.807395475961287 Test RE 1.2470921661437149\n",
      "75 Train Loss 0.5811847 Test MSE 6.814107401603656 Test RE 1.2477068158790232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 Train Loss 0.57554096 Test MSE 6.861152182717804 Test RE 1.2520065080853104\n",
      "77 Train Loss 0.5694175 Test MSE 6.863567231521556 Test RE 1.2522268348403949\n",
      "78 Train Loss 0.56341517 Test MSE 6.873383102409281 Test RE 1.253121945570891\n",
      "79 Train Loss 0.5574827 Test MSE 6.894862644646105 Test RE 1.2550784413336626\n",
      "80 Train Loss 0.5517772 Test MSE 6.904476152814164 Test RE 1.2559531145936096\n",
      "81 Train Loss 0.5470417 Test MSE 6.933563227788862 Test RE 1.2585958645331314\n",
      "82 Train Loss 0.5419636 Test MSE 6.938262186417485 Test RE 1.2590222750258597\n",
      "83 Train Loss 0.5388056 Test MSE 6.95229705666263 Test RE 1.260295020772029\n",
      "84 Train Loss 0.53575635 Test MSE 6.974256629412294 Test RE 1.2622838397463987\n",
      "85 Train Loss 0.5313823 Test MSE 6.988148707821071 Test RE 1.2635403910388676\n",
      "86 Train Loss 0.52801144 Test MSE 6.981787654273547 Test RE 1.2629651830471726\n",
      "87 Train Loss 0.52419496 Test MSE 6.988263750356408 Test RE 1.2635507915253141\n",
      "88 Train Loss 0.520798 Test MSE 7.006584011650686 Test RE 1.2652059543741672\n",
      "89 Train Loss 0.51780283 Test MSE 7.02399843912583 Test RE 1.2667772738626009\n",
      "90 Train Loss 0.5149816 Test MSE 7.019685683690978 Test RE 1.2663883116854227\n",
      "91 Train Loss 0.5119622 Test MSE 7.030822020418365 Test RE 1.267392440528158\n",
      "92 Train Loss 0.5091814 Test MSE 7.046775296527105 Test RE 1.268829513246641\n",
      "93 Train Loss 0.5066476 Test MSE 7.048733217842298 Test RE 1.269005770875663\n",
      "94 Train Loss 0.50350845 Test MSE 7.050601044193391 Test RE 1.269173895086231\n",
      "95 Train Loss 0.50032747 Test MSE 7.071986252693997 Test RE 1.271097206202959\n",
      "96 Train Loss 0.49802098 Test MSE 7.07627246624545 Test RE 1.2714823433207965\n",
      "97 Train Loss 0.49533582 Test MSE 7.095662706340362 Test RE 1.2732231950058532\n",
      "98 Train Loss 0.4929807 Test MSE 7.113851238756778 Test RE 1.2748539968674433\n",
      "99 Train Loss 0.49030802 Test MSE 7.116608406307086 Test RE 1.2751010251955126\n",
      "Training time: 41.53\n",
      "KG_stan_tune19\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 51.9204 Test MSE 8.221521842188878 Test RE 1.3705161820653846\n",
      "1 Train Loss 42.501686 Test MSE 8.133340388202534 Test RE 1.3631465051140217\n",
      "2 Train Loss 38.304554 Test MSE 7.538707908760962 Test RE 1.3123706784058642\n",
      "3 Train Loss 27.620808 Test MSE 5.147998758002083 Test RE 1.0844943081457858\n",
      "4 Train Loss 23.674267 Test MSE 5.077269303750165 Test RE 1.077018491934533\n",
      "5 Train Loss 21.308071 Test MSE 5.31284693661544 Test RE 1.1017212147809736\n",
      "6 Train Loss 18.404547 Test MSE 5.347171583601729 Test RE 1.1052744235488163\n",
      "7 Train Loss 15.896456 Test MSE 5.593400606409371 Test RE 1.1304361124606968\n",
      "8 Train Loss 14.422147 Test MSE 5.739741436186999 Test RE 1.1451285029324845\n",
      "9 Train Loss 13.415741 Test MSE 5.8555278807478714 Test RE 1.156621036316515\n",
      "10 Train Loss 12.763238 Test MSE 5.8852070962659315 Test RE 1.1595485449491767\n",
      "11 Train Loss 12.2356415 Test MSE 5.8905489646347435 Test RE 1.160074673482729\n",
      "12 Train Loss 11.659405 Test MSE 5.783802415317576 Test RE 1.1495153750115203\n",
      "13 Train Loss 10.074026 Test MSE 5.226679837311846 Test RE 1.0927504884344457\n",
      "14 Train Loss 9.33949 Test MSE 5.1401337700680365 Test RE 1.083665559408232\n",
      "15 Train Loss 8.683723 Test MSE 4.523985843300237 Test RE 1.016643478002107\n",
      "16 Train Loss 8.161074 Test MSE 4.000313701655074 Test RE 0.9559938207477072\n",
      "17 Train Loss 7.8225603 Test MSE 3.7760100818109903 Test RE 0.9288051886534698\n",
      "18 Train Loss 7.62957 Test MSE 3.7752625931658232 Test RE 0.9287132522338812\n",
      "19 Train Loss 7.504319 Test MSE 3.6491004366635993 Test RE 0.9130634719653902\n",
      "20 Train Loss 7.2801733 Test MSE 3.45059946936872 Test RE 0.8878821722151479\n",
      "21 Train Loss 6.2531157 Test MSE 2.63625654396572 Test RE 0.7760717872152814\n",
      "22 Train Loss 5.27928 Test MSE 2.3100754955934177 Test RE 0.7264757917344006\n",
      "23 Train Loss 4.6021953 Test MSE 2.0970527448208904 Test RE 0.6921699442940225\n",
      "24 Train Loss 4.343752 Test MSE 2.0878369629070055 Test RE 0.690647352424996\n",
      "25 Train Loss 4.272732 Test MSE 2.1012839377870254 Test RE 0.6928678830545438\n",
      "26 Train Loss 4.1804614 Test MSE 2.0920462094544523 Test RE 0.6913432020701922\n",
      "27 Train Loss 4.0504513 Test MSE 2.062725479022832 Test RE 0.6864814034111597\n",
      "28 Train Loss 3.8575954 Test MSE 1.9908927020039253 Test RE 0.6744224019307401\n",
      "29 Train Loss 3.0109034 Test MSE 1.6568677799889515 Test RE 0.6152505159483062\n",
      "30 Train Loss 1.9828019 Test MSE 1.4542986504919626 Test RE 0.5764144517694136\n",
      "31 Train Loss 1.5126579 Test MSE 1.297809008000731 Test RE 0.5445195192343354\n",
      "32 Train Loss 1.2089096 Test MSE 1.1309747777150638 Test RE 0.5083168662850946\n",
      "33 Train Loss 0.96983415 Test MSE 0.9586841349571136 Test RE 0.4679999756474464\n",
      "34 Train Loss 0.75149333 Test MSE 0.6402022242963757 Test RE 0.3824429413165956\n",
      "35 Train Loss 0.5345288 Test MSE 0.31658142474906265 Test RE 0.26893713556349536\n",
      "36 Train Loss 0.37593496 Test MSE 0.17084682340704185 Test RE 0.197565684918339\n",
      "37 Train Loss 0.23498298 Test MSE 0.04809678313489023 Test RE 0.10482529070022092\n",
      "38 Train Loss 0.15453166 Test MSE 0.026055476788865706 Test RE 0.07715384471995841\n",
      "39 Train Loss 0.10273809 Test MSE 0.01506250407409004 Test RE 0.05866197074353599\n",
      "40 Train Loss 0.06901325 Test MSE 0.013967346600943743 Test RE 0.05648914681989904\n",
      "41 Train Loss 0.052248925 Test MSE 0.0086490555637821 Test RE 0.04445211240308167\n",
      "42 Train Loss 0.039598215 Test MSE 0.004041730522440538 Test RE 0.030387273681233007\n",
      "43 Train Loss 0.030181104 Test MSE 0.004246679373651886 Test RE 0.031148188673070825\n",
      "44 Train Loss 0.02438929 Test MSE 0.004358187433021616 Test RE 0.031554478885996995\n",
      "45 Train Loss 0.020668946 Test MSE 0.003484939575797903 Test RE 0.028216665286721777\n",
      "46 Train Loss 0.016789692 Test MSE 0.00273103082822643 Test RE 0.024978787969866557\n",
      "47 Train Loss 0.01411351 Test MSE 0.0020224316457768837 Test RE 0.02149537303714726\n",
      "48 Train Loss 0.012095917 Test MSE 0.0020139105985598656 Test RE 0.02145004235185708\n",
      "49 Train Loss 0.010722384 Test MSE 0.001681335524968449 Test RE 0.019599060563009876\n",
      "50 Train Loss 0.008964028 Test MSE 0.0014498745616724658 Test RE 0.018200079094166228\n",
      "51 Train Loss 0.007920332 Test MSE 0.0019652575373417082 Test RE 0.021189357854700854\n",
      "52 Train Loss 0.007154788 Test MSE 0.002020381589924786 Test RE 0.021484475786751205\n",
      "53 Train Loss 0.0064646658 Test MSE 0.0018142199954158129 Test RE 0.020358840263334586\n",
      "54 Train Loss 0.0058230525 Test MSE 0.0017394725138933336 Test RE 0.019935027799168392\n",
      "55 Train Loss 0.0052438 Test MSE 0.001598087634895429 Test RE 0.019107697441158086\n",
      "56 Train Loss 0.0047676507 Test MSE 0.0015240265915406688 Test RE 0.018659686058456405\n",
      "57 Train Loss 0.004356111 Test MSE 0.001487868363813401 Test RE 0.01843700252085651\n",
      "58 Train Loss 0.0039184806 Test MSE 0.0015384678186885158 Test RE 0.01874788446041621\n",
      "59 Train Loss 0.003763001 Test MSE 0.0017818741641653494 Test RE 0.020176534564934918\n",
      "60 Train Loss 0.0033344124 Test MSE 0.0019047214567772348 Test RE 0.02086045598520607\n",
      "61 Train Loss 0.003137004 Test MSE 0.0019901452927970865 Test RE 0.021323105326851024\n",
      "62 Train Loss 0.0029606188 Test MSE 0.0020216264720120986 Test RE 0.021491093724806478\n",
      "63 Train Loss 0.0026661844 Test MSE 0.0019726455013986902 Test RE 0.02122914891558434\n",
      "64 Train Loss 0.0025120166 Test MSE 0.0019360732068909674 Test RE 0.021031437013235458\n",
      "65 Train Loss 0.0022903369 Test MSE 0.0016489741430011332 Test RE 0.01940952839120876\n",
      "66 Train Loss 0.0021593752 Test MSE 0.0016320508174396376 Test RE 0.019309672096078652\n",
      "67 Train Loss 0.0020798182 Test MSE 0.0015116146750648422 Test RE 0.018583546984498284\n",
      "68 Train Loss 0.0019179824 Test MSE 0.001273310904744228 Test RE 0.01705592546601807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 Train Loss 0.0018204184 Test MSE 0.0012265147855314031 Test RE 0.016739576030515388\n",
      "70 Train Loss 0.0016593256 Test MSE 0.001134435831548561 Test RE 0.016098967660641374\n",
      "71 Train Loss 0.0016026039 Test MSE 0.0011032511723387233 Test RE 0.015876152396539264\n",
      "72 Train Loss 0.001404254 Test MSE 0.0010867818857427628 Test RE 0.01575720756256763\n",
      "73 Train Loss 0.0013730002 Test MSE 0.001021482562116543 Test RE 0.01527648854848051\n",
      "74 Train Loss 0.0012904893 Test MSE 0.0010038524654956626 Test RE 0.015144083839343807\n",
      "75 Train Loss 0.0012329813 Test MSE 0.0010320133597995923 Test RE 0.015355031792917683\n",
      "76 Train Loss 0.0011984578 Test MSE 0.0009432103601331025 Test RE 0.014679536443365542\n",
      "77 Train Loss 0.0011543055 Test MSE 0.0008670105445165997 Test RE 0.014074087604042029\n",
      "78 Train Loss 0.0010545107 Test MSE 0.0007701476847820736 Test RE 0.013264627769609488\n",
      "79 Train Loss 0.0010000562 Test MSE 0.0007120822912656986 Test RE 0.012754785312825086\n",
      "80 Train Loss 0.0009522224 Test MSE 0.0005825725633120385 Test RE 0.011536739170603355\n",
      "81 Train Loss 0.00088837266 Test MSE 0.0005146178262274666 Test RE 0.01084302535388703\n",
      "82 Train Loss 0.0008681558 Test MSE 0.000459135579932397 Test RE 0.01024185291985181\n",
      "83 Train Loss 0.00081906084 Test MSE 0.0003884433764134972 Test RE 0.009420455892324405\n",
      "84 Train Loss 0.0007841163 Test MSE 0.0003958159966597103 Test RE 0.00950943537281227\n",
      "85 Train Loss 0.0007592474 Test MSE 0.00039690014094736814 Test RE 0.009522449690386998\n",
      "86 Train Loss 0.0007170583 Test MSE 0.000358443508749502 Test RE 0.009049371557339307\n",
      "87 Train Loss 0.0007027156 Test MSE 0.00034340466007879165 Test RE 0.008857499825500435\n",
      "88 Train Loss 0.00067429355 Test MSE 0.00030088916244011115 Test RE 0.008291084340225059\n",
      "89 Train Loss 0.00064126804 Test MSE 0.00026228219951881425 Test RE 0.0077409180325135685\n",
      "90 Train Loss 0.0006300874 Test MSE 0.0002767057696900627 Test RE 0.007950916045270158\n",
      "91 Train Loss 0.0006143709 Test MSE 0.0003199751579349661 Test RE 0.008550001508057155\n",
      "92 Train Loss 0.0005666069 Test MSE 0.0002666110281100683 Test RE 0.007804536482777576\n",
      "93 Train Loss 0.0005517942 Test MSE 0.0002364791515604291 Test RE 0.007350290260356155\n",
      "94 Train Loss 0.00053261407 Test MSE 0.00023787267461701847 Test RE 0.007371915324347173\n",
      "95 Train Loss 0.0004832416 Test MSE 0.00020388875061432612 Test RE 0.0068250320098589765\n",
      "96 Train Loss 0.0004709516 Test MSE 0.00020499703606557192 Test RE 0.006843556407134322\n",
      "97 Train Loss 0.00045825634 Test MSE 0.00019149144365903045 Test RE 0.006614282606396289\n",
      "98 Train Loss 0.0004268153 Test MSE 0.00018691759024156706 Test RE 0.0065348127390065834\n",
      "99 Train Loss 0.0004115564 Test MSE 0.00018202962194540363 Test RE 0.006448802757290074\n",
      "Training time: 42.51\n",
      "KG_stan_tune19\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 54.627914 Test MSE 7.793256793282591 Test RE 1.3343432212829174\n",
      "1 Train Loss 48.84294 Test MSE 8.08529931103623 Test RE 1.3591147043550351\n",
      "2 Train Loss 44.133194 Test MSE 8.478814754044539 Test RE 1.3917961592913344\n",
      "3 Train Loss 43.45788 Test MSE 8.384116375083877 Test RE 1.3840019729207167\n",
      "4 Train Loss 41.909275 Test MSE 8.826519941668726 Test RE 1.420047310534501\n",
      "5 Train Loss 40.901245 Test MSE 8.680620958474156 Test RE 1.4082619876770228\n",
      "6 Train Loss 38.406357 Test MSE 8.2201802572463 Test RE 1.3704043573373745\n",
      "7 Train Loss 36.19526 Test MSE 8.355930527065603 Test RE 1.381673635131082\n",
      "8 Train Loss 32.789436 Test MSE 8.080473886298465 Test RE 1.3587090740698229\n",
      "9 Train Loss 30.11725 Test MSE 8.451064601321606 Test RE 1.3895167009778904\n",
      "10 Train Loss 28.07777 Test MSE 8.885353931055818 Test RE 1.4247721787934646\n",
      "11 Train Loss 25.714725 Test MSE 8.624998896164232 Test RE 1.4037429378410564\n",
      "12 Train Loss 23.027388 Test MSE 7.774502810054275 Test RE 1.332736747633944\n",
      "13 Train Loss 18.269659 Test MSE 4.842445067229416 Test RE 1.0518175469755497\n",
      "14 Train Loss 11.526159 Test MSE 4.58199830750351 Test RE 1.023141080427215\n",
      "15 Train Loss 8.202243 Test MSE 4.342818598210924 Test RE 0.9960792768031657\n",
      "16 Train Loss 5.6371984 Test MSE 3.996265871585471 Test RE 0.9555100236964503\n",
      "17 Train Loss 2.9402437 Test MSE 3.1906655982020813 Test RE 0.8537853630712351\n",
      "18 Train Loss 2.1530569 Test MSE 2.877376044012681 Test RE 0.8107862445539785\n",
      "19 Train Loss 1.5238081 Test MSE 2.8955053782616984 Test RE 0.8133364732921856\n",
      "20 Train Loss 1.2349557 Test MSE 2.9916514991086247 Test RE 0.8267297396358616\n",
      "21 Train Loss 1.0487504 Test MSE 3.0178664749174278 Test RE 0.8303440358060143\n",
      "22 Train Loss 0.8903951 Test MSE 3.0506488654713406 Test RE 0.8348417726258337\n",
      "23 Train Loss 0.75534904 Test MSE 3.059435107091833 Test RE 0.8360431314076526\n",
      "24 Train Loss 0.70005286 Test MSE 3.0671487405304405 Test RE 0.8370964092655914\n",
      "25 Train Loss 0.65957713 Test MSE 3.060332981030959 Test RE 0.8361658021370548\n",
      "26 Train Loss 0.6181376 Test MSE 3.0324705650877366 Test RE 0.8323507157054022\n",
      "27 Train Loss 0.5812906 Test MSE 3.0670209069238754 Test RE 0.8370789646978336\n",
      "28 Train Loss 0.54058367 Test MSE 3.04799053461212 Test RE 0.8344779534145877\n",
      "29 Train Loss 0.52154833 Test MSE 3.087848218096466 Test RE 0.8399163445361593\n",
      "30 Train Loss 0.48471418 Test MSE 3.1312863203139067 Test RE 0.845803446771118\n",
      "31 Train Loss 0.45696348 Test MSE 3.157148269936333 Test RE 0.8492890983069198\n",
      "32 Train Loss 0.43737364 Test MSE 3.1781712580368855 Test RE 0.8521120525761887\n",
      "33 Train Loss 0.42274645 Test MSE 3.210029932226006 Test RE 0.8563722803413304\n",
      "34 Train Loss 0.41025043 Test MSE 3.242139098040478 Test RE 0.8606446671123541\n",
      "35 Train Loss 0.39816207 Test MSE 3.2491396535905084 Test RE 0.8615733351576719\n",
      "36 Train Loss 0.38286775 Test MSE 3.2620748884706026 Test RE 0.8632866476958388\n",
      "37 Train Loss 0.3709542 Test MSE 3.299679517741034 Test RE 0.8682482982179466\n",
      "38 Train Loss 0.36326885 Test MSE 3.317679974225668 Test RE 0.8706133171336601\n",
      "39 Train Loss 0.35401556 Test MSE 3.3268752265143933 Test RE 0.8718189743750754\n",
      "40 Train Loss 0.34690666 Test MSE 3.32222970453719 Test RE 0.8712100743182466\n",
      "41 Train Loss 0.33963317 Test MSE 3.3357528818430975 Test RE 0.8729814093066874\n",
      "42 Train Loss 0.33109045 Test MSE 3.3346166328158744 Test RE 0.8728327159238443\n",
      "43 Train Loss 0.32200164 Test MSE 3.3604173248639797 Test RE 0.8762028628251377\n",
      "44 Train Loss 0.31884316 Test MSE 3.366285715675364 Test RE 0.8769675978905936\n",
      "45 Train Loss 0.31204116 Test MSE 3.3999209951298757 Test RE 0.8813379538743089\n",
      "46 Train Loss 0.30831227 Test MSE 3.4173860444883286 Test RE 0.8835987260991985\n",
      "47 Train Loss 0.3044898 Test MSE 3.4501526438122307 Test RE 0.8878246834666919\n",
      "48 Train Loss 0.30079228 Test MSE 3.454944601521431 Test RE 0.8884410246184414\n",
      "49 Train Loss 0.2969761 Test MSE 3.467927912409604 Test RE 0.8901087922582877\n",
      "50 Train Loss 0.2930583 Test MSE 3.483075916934986 Test RE 0.8920506838558321\n",
      "51 Train Loss 0.28986582 Test MSE 3.494756519997944 Test RE 0.8935451917458694\n",
      "52 Train Loss 0.28741494 Test MSE 3.4936579744288343 Test RE 0.8934047417235271\n",
      "53 Train Loss 0.28513634 Test MSE 3.5124226954657556 Test RE 0.8958008034251841\n",
      "54 Train Loss 0.28198308 Test MSE 3.528270835305227 Test RE 0.8978194668383747\n",
      "55 Train Loss 0.27956522 Test MSE 3.547215111856467 Test RE 0.9002265624450873\n",
      "56 Train Loss 0.27575085 Test MSE 3.555406665530029 Test RE 0.9012654058130862\n",
      "57 Train Loss 0.27384642 Test MSE 3.560148690629996 Test RE 0.9018662370926281\n",
      "58 Train Loss 0.27192864 Test MSE 3.591342082564459 Test RE 0.9058086163939086\n",
      "59 Train Loss 0.26944432 Test MSE 3.58779026124175 Test RE 0.905360585247873\n",
      "60 Train Loss 0.2664382 Test MSE 3.6148212440524334 Test RE 0.9087647507653214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 Train Loss 0.26466894 Test MSE 3.62431448462446 Test RE 0.9099572669521909\n",
      "62 Train Loss 0.26319638 Test MSE 3.627551927618727 Test RE 0.9103635889223425\n",
      "63 Train Loss 0.2612522 Test MSE 3.6348878479400892 Test RE 0.9112836283761302\n",
      "64 Train Loss 0.25989777 Test MSE 3.6483052665116 Test RE 0.9129639843808024\n",
      "65 Train Loss 0.25810558 Test MSE 3.65937681132878 Test RE 0.9143482249932976\n",
      "66 Train Loss 0.2559958 Test MSE 3.669324723424145 Test RE 0.9155901963612504\n",
      "67 Train Loss 0.2543368 Test MSE 3.68704592923715 Test RE 0.9177984799522876\n",
      "68 Train Loss 0.25282988 Test MSE 3.7019853081367535 Test RE 0.9196559938648916\n",
      "69 Train Loss 0.2514402 Test MSE 3.7238414878532384 Test RE 0.9223667807645113\n",
      "70 Train Loss 0.24995215 Test MSE 3.7405270041565553 Test RE 0.9244309079221207\n",
      "71 Train Loss 0.24868126 Test MSE 3.7413665654152917 Test RE 0.924534646356687\n",
      "72 Train Loss 0.2472467 Test MSE 3.752267008592186 Test RE 0.9258804791492746\n",
      "73 Train Loss 0.2458246 Test MSE 3.767313627532342 Test RE 0.9277350156773226\n",
      "74 Train Loss 0.24411286 Test MSE 3.7854626164882137 Test RE 0.9299670070056552\n",
      "75 Train Loss 0.2430369 Test MSE 3.7957149397728243 Test RE 0.9312254893291401\n",
      "76 Train Loss 0.24174733 Test MSE 3.8115741658576527 Test RE 0.9331688809595705\n",
      "77 Train Loss 0.24054752 Test MSE 3.8141638087186123 Test RE 0.9334858318701866\n",
      "78 Train Loss 0.23867685 Test MSE 3.820546939321156 Test RE 0.9342666152082716\n",
      "79 Train Loss 0.23731145 Test MSE 3.827279249061472 Test RE 0.9350894036622744\n",
      "80 Train Loss 0.23609665 Test MSE 3.838917752290041 Test RE 0.9365100969589583\n",
      "81 Train Loss 0.23452722 Test MSE 3.8444632541985904 Test RE 0.9371862698653048\n",
      "82 Train Loss 0.23358932 Test MSE 3.8513260835443446 Test RE 0.9380223919983186\n",
      "83 Train Loss 0.23187315 Test MSE 3.8694656459602377 Test RE 0.9402288174049349\n",
      "84 Train Loss 0.23100206 Test MSE 3.8849419942433796 Test RE 0.9421072147229959\n",
      "85 Train Loss 0.2300018 Test MSE 3.892421983601387 Test RE 0.9430137357466352\n",
      "86 Train Loss 0.22856769 Test MSE 3.914430313086663 Test RE 0.9456759474710915\n",
      "87 Train Loss 0.22788478 Test MSE 3.9239450227589674 Test RE 0.9468245655710025\n",
      "88 Train Loss 0.22683081 Test MSE 3.93478760982106 Test RE 0.9481317890122151\n",
      "89 Train Loss 0.22583166 Test MSE 3.9558854532461347 Test RE 0.9506702733649515\n",
      "90 Train Loss 0.22505227 Test MSE 3.9588581230470923 Test RE 0.9510273992393888\n",
      "91 Train Loss 0.22390032 Test MSE 3.9746497149673226 Test RE 0.9529223004034509\n",
      "92 Train Loss 0.22272989 Test MSE 3.987691991385008 Test RE 0.9544844628835103\n",
      "93 Train Loss 0.2214373 Test MSE 4.000538964722552 Test RE 0.9560207370204086\n",
      "94 Train Loss 0.2202914 Test MSE 4.022834500031764 Test RE 0.958681050909412\n",
      "95 Train Loss 0.21938987 Test MSE 4.035494358273183 Test RE 0.9601883503768683\n",
      "96 Train Loss 0.2179855 Test MSE 4.066954310031446 Test RE 0.9639238077860182\n",
      "97 Train Loss 0.21733135 Test MSE 4.067903871554649 Test RE 0.9640363307539175\n",
      "98 Train Loss 0.21650779 Test MSE 4.083383142222278 Test RE 0.9658687745366963\n",
      "99 Train Loss 0.21554354 Test MSE 4.079953112007522 Test RE 0.9654630258013781\n",
      "Training time: 42.46\n",
      "KG_stan_tune19\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 52.213593 Test MSE 8.69482139832875 Test RE 1.4094133896265353\n",
      "1 Train Loss 42.954853 Test MSE 8.850366767053034 Test RE 1.4219643049319355\n",
      "2 Train Loss 41.81389 Test MSE 8.73147617828993 Test RE 1.4123810989183194\n",
      "3 Train Loss 40.951267 Test MSE 8.554214393782589 Test RE 1.3979708818995502\n",
      "4 Train Loss 40.154724 Test MSE 8.987459525474794 Test RE 1.432935143352419\n",
      "5 Train Loss 39.344948 Test MSE 8.835895401062636 Test RE 1.4208012918579869\n",
      "6 Train Loss 38.203926 Test MSE 8.683637003105297 Test RE 1.4085066137330373\n",
      "7 Train Loss 35.820274 Test MSE 8.165136075725192 Test RE 1.3658083821184699\n",
      "8 Train Loss 32.96894 Test MSE 8.354963704560719 Test RE 1.381593699580913\n",
      "9 Train Loss 30.848625 Test MSE 8.353920264004191 Test RE 1.3815074241665126\n",
      "10 Train Loss 27.991344 Test MSE 7.50708650884834 Test RE 1.3096153914686959\n",
      "11 Train Loss 25.608295 Test MSE 7.295361854584168 Test RE 1.291015567903668\n",
      "12 Train Loss 21.373983 Test MSE 5.238010852491726 Test RE 1.093934344079475\n",
      "13 Train Loss 18.951078 Test MSE 5.325074277683035 Test RE 1.1029882735996148\n",
      "14 Train Loss 16.928915 Test MSE 4.996791566469078 Test RE 1.0684487055043546\n",
      "15 Train Loss 14.523138 Test MSE 5.151728064010714 Test RE 1.0848870509506416\n",
      "16 Train Loss 12.3967 Test MSE 5.181394720221557 Test RE 1.0880062731554527\n",
      "17 Train Loss 9.540232 Test MSE 4.927241389640863 Test RE 1.0609867978784904\n",
      "18 Train Loss 6.4348135 Test MSE 4.652326067804498 Test RE 1.0309631276784368\n",
      "19 Train Loss 5.1028385 Test MSE 4.90346763526418 Test RE 1.058424092204634\n",
      "20 Train Loss 4.363312 Test MSE 4.8362829827310785 Test RE 1.051148107080985\n",
      "21 Train Loss 3.744616 Test MSE 4.818680279115039 Test RE 1.0492334222053532\n",
      "22 Train Loss 3.3623376 Test MSE 5.0151726383627135 Test RE 1.0704120858311237\n",
      "23 Train Loss 3.0354078 Test MSE 5.018166282395779 Test RE 1.0707315119936827\n",
      "24 Train Loss 2.7879815 Test MSE 5.076655110912248 Test RE 1.0769533469706887\n",
      "25 Train Loss 2.6021984 Test MSE 5.1861852576428715 Test RE 1.0885091233400566\n",
      "26 Train Loss 2.325551 Test MSE 5.230117962078014 Test RE 1.0931098365286676\n",
      "27 Train Loss 2.2148347 Test MSE 5.277650594324507 Test RE 1.0980658307264266\n",
      "28 Train Loss 2.0886328 Test MSE 5.309582754622411 Test RE 1.1013827172543948\n",
      "29 Train Loss 1.9587679 Test MSE 5.388590288929717 Test RE 1.1095468437024223\n",
      "30 Train Loss 1.8696407 Test MSE 5.465668045850958 Test RE 1.1174540813355256\n",
      "31 Train Loss 1.7440801 Test MSE 5.46403930022666 Test RE 1.117287570669133\n",
      "32 Train Loss 1.6627865 Test MSE 5.372670531382669 Test RE 1.1079066390033518\n",
      "33 Train Loss 1.5868163 Test MSE 5.47539555242428 Test RE 1.118448032088503\n",
      "34 Train Loss 1.5472795 Test MSE 5.48939180609725 Test RE 1.119876613020921\n",
      "35 Train Loss 1.4971743 Test MSE 5.547089451779127 Test RE 1.125746602508882\n",
      "36 Train Loss 1.4545958 Test MSE 5.587541532861124 Test RE 1.1298438927919694\n",
      "37 Train Loss 1.4132568 Test MSE 5.613021918917707 Test RE 1.1324171275666135\n",
      "38 Train Loss 1.3765726 Test MSE 5.643230149275538 Test RE 1.1354602668678773\n",
      "39 Train Loss 1.3535694 Test MSE 5.672416353381115 Test RE 1.1383927218449703\n",
      "40 Train Loss 1.321541 Test MSE 5.698626829452295 Test RE 1.1410197704359482\n",
      "41 Train Loss 1.2894754 Test MSE 5.683361272537875 Test RE 1.1394904561368349\n",
      "42 Train Loss 1.253926 Test MSE 5.729188741130535 Test RE 1.1440753412674751\n",
      "43 Train Loss 1.2338507 Test MSE 5.72849509817058 Test RE 1.1440060815639228\n",
      "44 Train Loss 1.2055666 Test MSE 5.764100283981758 Test RE 1.1475558316764805\n",
      "45 Train Loss 1.1776468 Test MSE 5.731832019200719 Test RE 1.1443392320789538\n",
      "46 Train Loss 1.148553 Test MSE 5.806267350587069 Test RE 1.151745634588031\n",
      "47 Train Loss 1.1219226 Test MSE 5.816840333510009 Test RE 1.1527937992347743\n",
      "48 Train Loss 1.1019986 Test MSE 5.83094384990316 Test RE 1.154190485595593\n",
      "49 Train Loss 1.0816358 Test MSE 5.869478124987629 Test RE 1.1579979870877926\n",
      "50 Train Loss 1.0543485 Test MSE 5.8841671738005035 Test RE 1.1594460936815354\n",
      "51 Train Loss 1.0313096 Test MSE 5.917531326253512 Test RE 1.1627285679897967\n",
      "52 Train Loss 1.0111297 Test MSE 5.9277857917878 Test RE 1.1637355756794188\n",
      "53 Train Loss 0.98966664 Test MSE 5.977404960800551 Test RE 1.1685960126209198\n",
      "54 Train Loss 0.97047114 Test MSE 6.011535748126912 Test RE 1.1719275861510043\n",
      "55 Train Loss 0.952844 Test MSE 6.034402017649621 Test RE 1.174154319783264\n",
      "56 Train Loss 0.9383896 Test MSE 6.0510034830061645 Test RE 1.1757683400173826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 Train Loss 0.927692 Test MSE 6.072863528915484 Test RE 1.1778902342221922\n",
      "58 Train Loss 0.9149302 Test MSE 6.098621182399971 Test RE 1.1803855632745897\n",
      "59 Train Loss 0.90252936 Test MSE 6.142146359817378 Test RE 1.1845902144668565\n",
      "60 Train Loss 0.8865953 Test MSE 6.150890213852782 Test RE 1.1854330957347117\n",
      "61 Train Loss 0.87016714 Test MSE 6.134917886322398 Test RE 1.1838929582263733\n",
      "62 Train Loss 0.8568356 Test MSE 6.161889403581725 Test RE 1.1864925342222967\n",
      "63 Train Loss 0.8459983 Test MSE 6.177979055935741 Test RE 1.1880405826766836\n",
      "64 Train Loss 0.83392334 Test MSE 6.231117094599881 Test RE 1.1931389310007023\n",
      "65 Train Loss 0.8212979 Test MSE 6.237404847289504 Test RE 1.193740770989841\n",
      "66 Train Loss 0.81256443 Test MSE 6.229062061370888 Test RE 1.1929421651311432\n",
      "67 Train Loss 0.8002411 Test MSE 6.279149235066546 Test RE 1.1977287179380955\n",
      "68 Train Loss 0.79111236 Test MSE 6.282500032139358 Test RE 1.1980482525163882\n",
      "69 Train Loss 0.78350395 Test MSE 6.316490765011846 Test RE 1.2012848307320856\n",
      "70 Train Loss 0.77153903 Test MSE 6.324466191802693 Test RE 1.2020429840512585\n",
      "71 Train Loss 0.75842494 Test MSE 6.374223643597979 Test RE 1.206762229536393\n",
      "72 Train Loss 0.7472756 Test MSE 6.379910865729846 Test RE 1.2073004593717651\n",
      "73 Train Loss 0.73694396 Test MSE 6.443393639306868 Test RE 1.2132921627905668\n",
      "74 Train Loss 0.7260974 Test MSE 6.424297963409918 Test RE 1.211492969200814\n",
      "75 Train Loss 0.7184245 Test MSE 6.430436363179656 Test RE 1.2120716201782478\n",
      "76 Train Loss 0.7099861 Test MSE 6.442490049147229 Test RE 1.213207086714299\n",
      "77 Train Loss 0.7027783 Test MSE 6.445825154582755 Test RE 1.2135210685757298\n",
      "78 Train Loss 0.69589067 Test MSE 6.477231398946194 Test RE 1.216473819173661\n",
      "79 Train Loss 0.6889296 Test MSE 6.4767354754074535 Test RE 1.2164272491569488\n",
      "80 Train Loss 0.68247527 Test MSE 6.490005129935679 Test RE 1.2176727307803032\n",
      "81 Train Loss 0.6758952 Test MSE 6.507709434030496 Test RE 1.2193324649153054\n",
      "82 Train Loss 0.6705071 Test MSE 6.553527412465091 Test RE 1.2236173334480782\n",
      "83 Train Loss 0.6655859 Test MSE 6.590946172470392 Test RE 1.2271056131030973\n",
      "84 Train Loss 0.65892625 Test MSE 6.583402451972935 Test RE 1.2264031652437508\n",
      "85 Train Loss 0.65275455 Test MSE 6.6107792409844555 Test RE 1.2289504915169494\n",
      "86 Train Loss 0.6470142 Test MSE 6.6258040411288395 Test RE 1.2303462616082963\n",
      "87 Train Loss 0.6432034 Test MSE 6.6342386572022125 Test RE 1.2311291249229883\n",
      "88 Train Loss 0.6389529 Test MSE 6.642578483113095 Test RE 1.231902701091549\n",
      "89 Train Loss 0.6343779 Test MSE 6.65730681014414 Test RE 1.2332676695005316\n",
      "90 Train Loss 0.6298913 Test MSE 6.7102995992495345 Test RE 1.2381664036184064\n",
      "91 Train Loss 0.625032 Test MSE 6.710976572749505 Test RE 1.2382288587064185\n",
      "92 Train Loss 0.6203028 Test MSE 6.711061970526662 Test RE 1.2382367369678462\n",
      "93 Train Loss 0.6155536 Test MSE 6.72522765990259 Test RE 1.2395428812655935\n",
      "94 Train Loss 0.61040634 Test MSE 6.737954862553276 Test RE 1.2407152175408138\n",
      "95 Train Loss 0.6049744 Test MSE 6.751620687910912 Test RE 1.2419727808044267\n",
      "96 Train Loss 0.6003862 Test MSE 6.755290896140559 Test RE 1.2423103056464389\n",
      "97 Train Loss 0.59668165 Test MSE 6.771265581434419 Test RE 1.2437783251458268\n",
      "98 Train Loss 0.59242475 Test MSE 6.789441512909837 Test RE 1.2454465272664788\n",
      "99 Train Loss 0.58889586 Test MSE 6.784867269497185 Test RE 1.2450269098767373\n",
      "Training time: 43.88\n"
     ]
    }
   ],
   "source": [
    "nan_tune = []\n",
    "for tune_reps in range(20):\n",
    "    \n",
    "    max_reps = 10 #10\n",
    "    max_iter = 100 #100\n",
    "    label = \"KG_stan_tune\"+str(tune_reps)\n",
    "\n",
    "    train_loss_full = []\n",
    "    test_mse_full = []\n",
    "    test_re_full = []\n",
    "    beta_full = []\n",
    "    elapsed_time= np.zeros((max_reps,1))\n",
    "    time_threshold = np.empty((max_reps,1))\n",
    "    time_threshold[:] = np.nan\n",
    "    epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "    \n",
    "    beta_init = lrb_tune[tune_reps,1]\n",
    "\n",
    "    N_I = 200  #Total number of data points for 'y'\n",
    "    N_B = 400\n",
    "    N_f = 10000 #Total number of collocation points\n",
    "    \n",
    "    for reps in range(max_reps):\n",
    "        print(label)\n",
    "        print(reps)\n",
    "        train_loss = []\n",
    "        test_mse_loss = []\n",
    "        test_re_loss = []\n",
    "        beta_val = []\n",
    "      \n",
    "        torch.manual_seed(reps*36)\n",
    "\n",
    "        layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "        #layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "        PINN = Sequentialmodel(layers,beta_init)\n",
    "    \n",
    "        PINN.to(device)\n",
    "\n",
    "        'Neural Network Summary'\n",
    "        print(PINN)\n",
    "\n",
    "        params = list(PINN.parameters())\n",
    "      \n",
    "\n",
    "        optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lrb_tune[tune_reps,0], \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-8, \n",
    "                                tolerance_change = 1e-8, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "        nan_flag = train_model(max_iter,reps)\n",
    "    \n",
    "        \n",
    "      \n",
    "        torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "        train_loss_full.append(train_loss)\n",
    "        test_mse_full.append(test_mse_loss)\n",
    "        test_re_full.append(test_re_loss)\n",
    "        #elapsed_time[reps] = time.time() - start_time\n",
    "        beta_full.append(beta_val)\n",
    "        \n",
    "        if(nan_flag == 1):\n",
    "            nan_tune.append(tune_reps)\n",
    "            break\n",
    "\n",
    "\n",
    "      #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "      \n",
    "    mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label}\n",
    "    savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_O3sPdAnSq_2"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "jQ4afiEWSq_2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0.7464338405153359\n",
      "1   0.7088968006531634\n",
      "2   0.698321253106821\n",
      "3   0.6710382757272744\n",
      "4   0.34801528958135347\n",
      "5   0.6235461617123761\n",
      "6   0.5308507424773917\n",
      "7   0.5845655022100533\n",
      "8   0.6277262044572863\n",
      "9   0.7934249883767227\n",
      "10   0.3782206980277623\n",
      "11   0.5431666081727968\n",
      "12   0.38807631804346154\n",
      "13   0.7125802670146782\n",
      "14   0.493512693155249\n",
      "15   0.7197849631318884\n",
      "16   0.33691845060768677\n",
      "17   [[1.38699518 1.38027319 1.48567026 1.39873719 1.40199089 1.38184738\n",
      "  1.38987924 1.37999992 1.37952436 1.38065303 1.3875345  1.40504569\n",
      "  1.41214976 1.41156113 1.44304222 1.45311749 1.45346139 1.39357478\n",
      "         nan]]\n",
      "18   0.578231548565742\n",
      "19   0.6890833507252422\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(20):\n",
    "    label = \"KG_stan_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0. ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrb_tune[4]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
