{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1660687393066,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "xAgfGYA4acPE",
    "outputId": "527d048f-6a89-4e80-87ff-bfdb1c9d6222"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1856,
     "status": "ok",
     "timestamp": 1660687061284,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "7kSdyTofacUc",
    "outputId": "08ee5c9b-0706-46a5-86a1-2c7e56a6a74d"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/2D Klein Gordon/stan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32419,
     "status": "ok",
     "timestamp": 1660687093700,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "RHuSaD0gagsN",
    "outputId": "c232cd79-e56c-4a76-97c7-d59dafa084ef"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1660687406024,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "T7Wci76Yf-U8"
   },
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1]).reshape(-1,1)\n",
    "n_value = np.array([1.0,3.0,5.0,8.0,10.0]).reshape(-1,1)\n",
    "r_value = np.array([2,6,8]).reshape(-1,1)\n",
    "\n",
    "LR_tune,N_value,R_value = np.meshgrid(lr_tune,n_value,r_value)\n",
    "\n",
    "LR_tune = LR_tune.flatten('F').reshape(-1,1)\n",
    "N_value = N_value.flatten('F').reshape(-1,1)\n",
    "R_value = R_value.flatten('F').reshape(-1,1)\n",
    "\n",
    "\n",
    "lrnr_tune = np.hstack((LR_tune,N_value,R_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    y = xt[:,0]*np.cos(xt[:,1])\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "loss_thresh = 0.01\n",
    "\n",
    "x = np.linspace(-5,5,500).reshape(-1,1)\n",
    "t = np.linspace(0,10,1000).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    x01 = np.array([[0.0,1.0],[0.0,0.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state=seed)\n",
    "    samples = sampling(N_I)\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "\n",
    "    x01 = np.array([[0.0,0.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state=seed+1)\n",
    "    samples = sampling(int(N_B/2))\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x01 = np.array([[1.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state=seed+2)\n",
    "    samples = sampling(int(N_B/2))\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "\n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,n_val,rowdy_terms):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        self.omega1.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        self.omega.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = (xt - lbxt)/(ubxt - lbxt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,2) + (g[:,0]*torch.cos(g[:,1])).reshape(-1,1) - (torch.pow(g[:,0],2)*torch.pow(torch.cos(g[:,1]),2)).reshape(-1,1)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred1 = self.forward(xt_test_tensor[:250000])\n",
    "        y_pred1 = y_pred1.cpu().detach().numpy()\n",
    "        \n",
    "        y_pred2 = self.forward(xt_test_tensor[250000:])\n",
    "          \n",
    "        y_pred2 = y_pred2.cpu().detach().numpy()\n",
    "        \n",
    "        y_pred = np.vstack((y_pred1.reshape(-1,1),y_pred2.reshape(-1,1)))\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    alpha_val.append(PINN.alpha.cpu().detach().numpy())\n",
    "    omega_val.append(PINN.omega.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC, y_BC, xt_coll, f_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC, y_BC, xt_coll,f_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    nan_flag = 0\n",
    "    for i in range(max_iter):\n",
    "        train_step(xt_BC, y_BC, xt_coll,f_hat,i)\n",
    "\n",
    "        loss_np = PINN.loss(xt_BC, y_BC, xt_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "        \n",
    "        if(np.isnan(loss_np)):\n",
    "            nan_flag =1\n",
    "            print(\"NAN BREAK!\")\n",
    "            break\n",
    "            \n",
    "        \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))\n",
    "    \n",
    "    return nan_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "KG_rowdy_tune59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 73.00385 Test MSE 4.393381403517718 Test RE 1.0018610993489605\n",
      "1 Train Loss 71.54026 Test MSE 4.362517252240187 Test RE 0.9983357861028312\n",
      "2 Train Loss 60.534836 Test MSE 5.465802256994762 Test RE 1.1174678009639851\n",
      "3 Train Loss 46.386303 Test MSE 6.458548185782875 Test RE 1.2147181267255671\n",
      "4 Train Loss 41.74831 Test MSE 6.290730918606965 Test RE 1.1988327946108663\n",
      "5 Train Loss 35.93466 Test MSE 6.490571166065434 Test RE 1.217725830255439\n",
      "6 Train Loss 33.37262 Test MSE 6.102979528393753 Test RE 1.1808072659626228\n",
      "7 Train Loss 30.520113 Test MSE 5.996774671593982 Test RE 1.1704878920558843\n",
      "8 Train Loss 27.476185 Test MSE 6.035347121149822 Test RE 1.1742462637660782\n",
      "9 Train Loss 24.639435 Test MSE 6.2365804804014955 Test RE 1.1936618829822507\n",
      "10 Train Loss 22.72869 Test MSE 6.5623824849893255 Test RE 1.224443725244691\n",
      "11 Train Loss 21.65263 Test MSE 6.605541460728858 Test RE 1.2284635407424518\n",
      "12 Train Loss 20.319286 Test MSE 6.3826284126780655 Test RE 1.2075575590746392\n",
      "13 Train Loss 19.439774 Test MSE 6.411837747369051 Test RE 1.2103175263037995\n",
      "14 Train Loss 18.42841 Test MSE 6.453315561146617 Test RE 1.2142259532716009\n",
      "15 Train Loss 17.354027 Test MSE 6.336443820386755 Test RE 1.203180693832521\n",
      "16 Train Loss 16.599628 Test MSE 6.306663811681149 Test RE 1.2003500106387446\n",
      "17 Train Loss 15.966928 Test MSE 6.244592563278616 Test RE 1.194428380610884\n",
      "18 Train Loss 15.342306 Test MSE 6.316591895314305 Test RE 1.2012944472910678\n",
      "19 Train Loss 14.728507 Test MSE 6.194170326039302 Test RE 1.1895963745393998\n",
      "20 Train Loss 14.235331 Test MSE 6.449516397336348 Test RE 1.2138684841228096\n",
      "21 Train Loss 13.913748 Test MSE 6.485996997575835 Test RE 1.2172966642628817\n",
      "22 Train Loss 13.372129 Test MSE 6.443384937287979 Test RE 1.2132913434944417\n",
      "23 Train Loss 13.107087 Test MSE 6.441661035438998 Test RE 1.2131290270156843\n",
      "24 Train Loss 12.730906 Test MSE 6.4234225449934055 Test RE 1.2114104232638805\n",
      "25 Train Loss 12.199769 Test MSE 6.248346713691393 Test RE 1.1947873624033787\n",
      "26 Train Loss 11.683905 Test MSE 6.066977246459631 Test RE 1.1773192453060046\n",
      "27 Train Loss 11.289522 Test MSE 5.98719092076218 Test RE 1.1695522099276832\n",
      "28 Train Loss 10.86384 Test MSE 5.916514948523431 Test RE 1.162628710286793\n",
      "29 Train Loss 10.157885 Test MSE 5.716216535189958 Test RE 1.1427793819180156\n",
      "30 Train Loss 9.315731 Test MSE 5.503145530401054 Test RE 1.1212786662026613\n",
      "31 Train Loss 8.798664 Test MSE 5.48968776232427 Test RE 1.1199068012459277\n",
      "32 Train Loss 8.117579 Test MSE 5.401126710603213 Test RE 1.1108367605063048\n",
      "33 Train Loss 7.2839603 Test MSE 4.962438025931868 Test RE 1.064769514463189\n",
      "34 Train Loss 6.557929 Test MSE 4.951506531503421 Test RE 1.0635961054405383\n",
      "35 Train Loss 5.7785378 Test MSE 4.938083122310337 Test RE 1.062153435922525\n",
      "36 Train Loss 5.5616155 Test MSE 4.909881515400655 Test RE 1.0591160909382347\n",
      "37 Train Loss 5.0883646 Test MSE 4.842282289221594 Test RE 1.0517998684886118\n",
      "38 Train Loss 4.869617 Test MSE 4.84038015996075 Test RE 1.0515932659302951\n",
      "39 Train Loss 4.427195 Test MSE 4.804674439941046 Test RE 1.047707476555662\n",
      "40 Train Loss 4.0657883 Test MSE 4.681820382013194 Test RE 1.0342259588429754\n",
      "41 Train Loss 3.8912244 Test MSE 4.743294714524227 Test RE 1.0409937330762553\n",
      "42 Train Loss 3.6973784 Test MSE 4.726948047217225 Test RE 1.0391984129809717\n",
      "43 Train Loss 3.5692375 Test MSE 4.586817204009664 Test RE 1.0236789587717174\n",
      "44 Train Loss 3.4758344 Test MSE 4.575286005035135 Test RE 1.0223913912161877\n",
      "45 Train Loss 3.3346193 Test MSE 4.52695026004119 Test RE 1.0169765097034207\n",
      "46 Train Loss 3.2607322 Test MSE 4.5617896339997355 Test RE 1.0208823309647022\n",
      "47 Train Loss 3.1855252 Test MSE 4.614701639198842 Test RE 1.0267858471687197\n",
      "48 Train Loss 3.0237935 Test MSE 4.662228727753268 Test RE 1.0320597673148286\n",
      "49 Train Loss 2.9612076 Test MSE 4.6536936900340065 Test RE 1.0311146502142061\n",
      "50 Train Loss 2.8947093 Test MSE 4.633384436445549 Test RE 1.028862238719867\n",
      "51 Train Loss 2.8659763 Test MSE 4.655160144307106 Test RE 1.0312770978830805\n",
      "52 Train Loss 2.8089764 Test MSE 4.649441864805952 Test RE 1.030643506063446\n",
      "53 Train Loss 2.7579248 Test MSE 4.6625735114410976 Test RE 1.032097928333398\n",
      "54 Train Loss 2.6715918 Test MSE 4.708512066392174 Test RE 1.0371698991373026\n",
      "55 Train Loss 2.6347153 Test MSE 4.734753476564649 Test RE 1.0400560534673897\n",
      "56 Train Loss 2.5834978 Test MSE 4.7867954399640125 Test RE 1.0457563120308109\n",
      "57 Train Loss 2.5428324 Test MSE 4.7723649721451755 Test RE 1.044178832538417\n",
      "58 Train Loss 2.47809 Test MSE 4.759342173888632 Test RE 1.0427531851224983\n",
      "59 Train Loss 2.4364552 Test MSE 4.795159818649189 Test RE 1.0466695831440482\n",
      "60 Train Loss 2.3847673 Test MSE 4.713232232844996 Test RE 1.037689637451271\n",
      "61 Train Loss 2.350831 Test MSE 4.7470390410852925 Test RE 1.041404528925345\n",
      "62 Train Loss 2.3044426 Test MSE 4.799325536012304 Test RE 1.0471241230638755\n",
      "63 Train Loss 2.2610028 Test MSE 4.831511526969436 Test RE 1.0506294500473006\n",
      "64 Train Loss 2.2424295 Test MSE 4.829610937229166 Test RE 1.0504227847051224\n",
      "65 Train Loss 2.209286 Test MSE 4.815448291415629 Test RE 1.0488814919951737\n",
      "66 Train Loss 2.1902485 Test MSE 4.817678818723345 Test RE 1.0491243860944652\n",
      "67 Train Loss 2.1836433 Test MSE 4.82786307650243 Test RE 1.050232690834254\n",
      "68 Train Loss 2.1518478 Test MSE 4.841208111843994 Test RE 1.0516832001262837\n",
      "69 Train Loss 2.1305058 Test MSE 4.832206796119732 Test RE 1.0507050417087924\n",
      "70 Train Loss 2.1136718 Test MSE 4.810031052855268 Test RE 1.0482913454655247\n",
      "71 Train Loss 2.103331 Test MSE 4.825318967188283 Test RE 1.0499559370385505\n",
      "72 Train Loss 2.0802972 Test MSE 4.844862358102621 Test RE 1.0520800416138907\n",
      "73 Train Loss 2.041852 Test MSE 4.8262981185522635 Test RE 1.050062459907453\n",
      "74 Train Loss 2.0298157 Test MSE 4.847624714758086 Test RE 1.0523799269309726\n",
      "75 Train Loss 2.0204587 Test MSE 4.848211510074192 Test RE 1.0524436192505733\n",
      "76 Train Loss 2.004751 Test MSE 4.883848306700487 Test RE 1.0563045326828986\n",
      "77 Train Loss 1.9721475 Test MSE 4.9396685474322135 Test RE 1.062323930176753\n",
      "78 Train Loss 1.9484968 Test MSE 4.9472289772935945 Test RE 1.063136591454262\n",
      "79 Train Loss 1.9401579 Test MSE 4.947281694659042 Test RE 1.0631422557979953\n",
      "80 Train Loss 1.92036 Test MSE 4.994305447912213 Test RE 1.0681828728590137\n",
      "81 Train Loss 1.9072347 Test MSE 5.006352257315934 Test RE 1.069470383713507\n",
      "82 Train Loss 1.8971429 Test MSE 5.003902159490954 Test RE 1.069208653455833\n",
      "83 Train Loss 1.887348 Test MSE 4.998225697678913 Test RE 1.0686020224562285\n",
      "84 Train Loss 1.8573663 Test MSE 5.039965896291984 Test RE 1.0730546951475715\n",
      "85 Train Loss 1.8394969 Test MSE 5.045799938594985 Test RE 1.0736755759248584\n",
      "86 Train Loss 1.8305334 Test MSE 5.045689372214846 Test RE 1.073663812371641\n",
      "87 Train Loss 1.8161036 Test MSE 5.0409798850454 Test RE 1.073162633444547\n",
      "88 Train Loss 1.7970169 Test MSE 5.066100273208637 Test RE 1.0758332214164945\n",
      "89 Train Loss 1.7759227 Test MSE 5.0753328602016134 Test RE 1.0768130877811057\n",
      "90 Train Loss 1.7575501 Test MSE 5.067150253418199 Test RE 1.0759447021420148\n",
      "91 Train Loss 1.7398744 Test MSE 5.062234925776707 Test RE 1.075422721972331\n",
      "92 Train Loss 1.7251825 Test MSE 5.107172050546905 Test RE 1.080185404024771\n",
      "93 Train Loss 1.7003822 Test MSE 5.1426731007982065 Test RE 1.083933202781318\n",
      "94 Train Loss 1.6874051 Test MSE 5.139660451388571 Test RE 1.083615664698986\n",
      "95 Train Loss 1.6796038 Test MSE 5.14715120760576 Test RE 1.084405030597455\n",
      "96 Train Loss 1.6659212 Test MSE 5.146149161153343 Test RE 1.084299469573389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 Train Loss 1.6512883 Test MSE 5.186483530986847 Test RE 1.0885404246310761\n",
      "98 Train Loss 1.6396675 Test MSE 5.167756416482515 Test RE 1.0865734217617262\n",
      "99 Train Loss 1.6212289 Test MSE 5.151867564454026 Test RE 1.0849017393423963\n",
      "100 Train Loss 1.6044358 Test MSE 5.198070456530347 Test RE 1.0897556796462657\n",
      "101 Train Loss 1.5910114 Test MSE 5.19235536418566 Test RE 1.089156441215695\n",
      "102 Train Loss 1.5769651 Test MSE 5.209723249111677 Test RE 1.0909764776456674\n",
      "103 Train Loss 1.5686076 Test MSE 5.207591311089674 Test RE 1.0907532285282415\n",
      "104 Train Loss 1.5577365 Test MSE 5.217481352476421 Test RE 1.091788493869601\n",
      "105 Train Loss 1.5446005 Test MSE 5.2204891825098345 Test RE 1.092103151541566\n",
      "106 Train Loss 1.5354238 Test MSE 5.235352818691663 Test RE 1.0936567498249212\n",
      "107 Train Loss 1.5258417 Test MSE 5.249231005258099 Test RE 1.095105355829102\n",
      "108 Train Loss 1.5184094 Test MSE 5.2306284526197375 Test RE 1.0931631822295438\n",
      "109 Train Loss 1.5032413 Test MSE 5.221372065753735 Test RE 1.0921954952642288\n",
      "110 Train Loss 1.4931273 Test MSE 5.211220054133739 Test RE 1.091133190556959\n",
      "111 Train Loss 1.4857298 Test MSE 5.203082578465343 Test RE 1.090280939199412\n",
      "112 Train Loss 1.4764417 Test MSE 5.2120405105774825 Test RE 1.0912190813862097\n",
      "113 Train Loss 1.467595 Test MSE 5.231596561214007 Test RE 1.0932643413652947\n",
      "114 Train Loss 1.458645 Test MSE 5.253034040554575 Test RE 1.0955019825217835\n",
      "115 Train Loss 1.439495 Test MSE 5.291992525006056 Test RE 1.0995568066127779\n",
      "116 Train Loss 1.4283088 Test MSE 5.3143241603713705 Test RE 1.1018743695449107\n",
      "117 Train Loss 1.4186792 Test MSE 5.322384274568808 Test RE 1.1027096468108595\n",
      "118 Train Loss 1.4080172 Test MSE 5.322575694152777 Test RE 1.102729476112269\n",
      "119 Train Loss 1.3971056 Test MSE 5.340678308175938 Test RE 1.1046031311425193\n",
      "120 Train Loss 1.387573 Test MSE 5.3594160499287264 Test RE 1.1065391816114374\n",
      "121 Train Loss 1.3747147 Test MSE 5.369181625884184 Test RE 1.1075468543049063\n",
      "122 Train Loss 1.3693179 Test MSE 5.377354865636099 Test RE 1.1083895156525874\n",
      "123 Train Loss 1.3652627 Test MSE 5.401897783905097 Test RE 1.1109160500737159\n",
      "124 Train Loss 1.3605082 Test MSE 5.396436321301954 Test RE 1.1103543251935817\n",
      "125 Train Loss 1.350662 Test MSE 5.391638526966815 Test RE 1.1098606256507768\n",
      "126 Train Loss 1.3425868 Test MSE 5.3901162166970495 Test RE 1.109703931957699\n",
      "127 Train Loss 1.3358494 Test MSE 5.415348025000639 Test RE 1.112298230906637\n",
      "128 Train Loss 1.3305702 Test MSE 5.413757228310866 Test RE 1.1121348461803842\n",
      "129 Train Loss 1.3227409 Test MSE 5.421705390535751 Test RE 1.1129509324765647\n",
      "130 Train Loss 1.317518 Test MSE 5.416196407609029 Test RE 1.1123853552718794\n",
      "131 Train Loss 1.3113592 Test MSE 5.421606351416003 Test RE 1.1129407672078797\n",
      "132 Train Loss 1.3069851 Test MSE 5.431745760259868 Test RE 1.1139809838520853\n",
      "133 Train Loss 1.3027573 Test MSE 5.441109077283633 Test RE 1.1149407181950244\n",
      "134 Train Loss 1.2965015 Test MSE 5.426328606388427 Test RE 1.1134253510946543\n",
      "135 Train Loss 1.2930996 Test MSE 5.454627526861789 Test RE 1.1163248955296332\n",
      "136 Train Loss 1.2882326 Test MSE 5.447443088996767 Test RE 1.1155894823923425\n",
      "137 Train Loss 1.2827756 Test MSE 5.454145363769436 Test RE 1.1162755555374637\n",
      "138 Train Loss 1.2775006 Test MSE 5.455808975263902 Test RE 1.1164457845224545\n",
      "139 Train Loss 1.2718987 Test MSE 5.446533678211866 Test RE 1.1154963587528826\n",
      "140 Train Loss 1.2626603 Test MSE 5.4487840903102684 Test RE 1.115726786709231\n",
      "141 Train Loss 1.2576066 Test MSE 5.448256740542793 Test RE 1.1156727937000812\n",
      "142 Train Loss 1.2543728 Test MSE 5.449243303260292 Test RE 1.1157738013629603\n",
      "143 Train Loss 1.2501026 Test MSE 5.460413353261033 Test RE 1.116916792058538\n",
      "144 Train Loss 1.2417072 Test MSE 5.466339616710572 Test RE 1.1175227304504205\n",
      "145 Train Loss 1.2350302 Test MSE 5.504871983030851 Test RE 1.1214545367740563\n",
      "146 Train Loss 1.2287042 Test MSE 5.502636817569295 Test RE 1.1212268392952016\n",
      "147 Train Loss 1.2227621 Test MSE 5.517152168698233 Test RE 1.122704701911204\n",
      "148 Train Loss 1.2149796 Test MSE 5.49660633579319 Test RE 1.120612280148621\n",
      "149 Train Loss 1.2092773 Test MSE 5.522998939955563 Test RE 1.1232994344116751\n",
      "Training time: 300.85\n",
      "1\n",
      "KG_rowdy_tune59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 60.049587 Test MSE 7.695879239329348 Test RE 1.325980637683683\n",
      "1 Train Loss 53.051727 Test MSE 9.140608686342548 Test RE 1.4450924058868186\n",
      "2 Train Loss 45.257584 Test MSE 9.999650454793116 Test RE 1.5114732653684506\n",
      "3 Train Loss 41.50872 Test MSE 9.246315456031695 Test RE 1.4534242879877295\n",
      "4 Train Loss 39.352013 Test MSE 9.280449714322204 Test RE 1.456104591150023\n",
      "5 Train Loss 36.707718 Test MSE 9.117771922197335 Test RE 1.4432860780034709\n",
      "6 Train Loss 33.481308 Test MSE 8.719363293110487 Test RE 1.4114010843598872\n",
      "7 Train Loss 31.568386 Test MSE 8.414595673957898 Test RE 1.3865153648767377\n",
      "8 Train Loss 29.183191 Test MSE 8.558573612531852 Test RE 1.3983270387840276\n",
      "9 Train Loss 27.254303 Test MSE 8.363205107261177 Test RE 1.3822749391383988\n",
      "10 Train Loss 26.378933 Test MSE 8.664301180703276 Test RE 1.4069375815727327\n",
      "11 Train Loss 25.3917 Test MSE 9.102817890666234 Test RE 1.4421020276401069\n",
      "12 Train Loss 24.50853 Test MSE 9.106452942566557 Test RE 1.4423899380732574\n",
      "13 Train Loss 23.564629 Test MSE 9.364546913556651 Test RE 1.4626871468794629\n",
      "14 Train Loss 22.677782 Test MSE 9.440021993495014 Test RE 1.4685696995960036\n",
      "15 Train Loss 21.976685 Test MSE 9.594662967331754 Test RE 1.4805494666939114\n",
      "16 Train Loss 21.632114 Test MSE 9.635643562435959 Test RE 1.4837079491307874\n",
      "17 Train Loss 21.282475 Test MSE 9.740426563051455 Test RE 1.4917534415920484\n",
      "18 Train Loss 20.945915 Test MSE 9.552328989311293 Test RE 1.477279584318949\n",
      "19 Train Loss 20.707277 Test MSE 9.654821969972266 Test RE 1.4851837722346317\n",
      "20 Train Loss 20.541794 Test MSE 9.577449105446231 Test RE 1.4792207376111544\n",
      "21 Train Loss 20.30789 Test MSE 9.669608585694876 Test RE 1.4863206362708445\n",
      "22 Train Loss 20.103199 Test MSE 9.654871589624085 Test RE 1.4851875886803003\n",
      "23 Train Loss 19.934582 Test MSE 9.688172638813567 Test RE 1.4877466973470992\n",
      "24 Train Loss 19.640947 Test MSE 9.729721704430846 Test RE 1.4909334877873095\n",
      "25 Train Loss 19.489809 Test MSE 9.8238860749097 Test RE 1.498130752546863\n",
      "26 Train Loss 19.23702 Test MSE 9.809985278867956 Test RE 1.497070450034728\n",
      "27 Train Loss 19.057621 Test MSE 9.733353962947138 Test RE 1.4912117563081513\n",
      "28 Train Loss 18.697216 Test MSE 9.592866057323175 Test RE 1.4804108198890316\n",
      "29 Train Loss 18.5343 Test MSE 9.543790562551752 Test RE 1.4766191975425644\n",
      "30 Train Loss 18.055733 Test MSE 9.384773790089554 Test RE 1.464265954377557\n",
      "31 Train Loss 16.610844 Test MSE 8.505255912682522 Test RE 1.393964626113315\n",
      "32 Train Loss 15.969614 Test MSE 8.284298044762703 Test RE 1.3757385845321615\n",
      "33 Train Loss 15.484968 Test MSE 8.06646451831721 Test RE 1.3575307451086338\n",
      "34 Train Loss 14.648865 Test MSE 7.7408257417536 Test RE 1.3298470852297248\n",
      "35 Train Loss 14.3189335 Test MSE 7.647004595551963 Test RE 1.3217634423244282\n",
      "36 Train Loss 14.0675 Test MSE 7.466478058252375 Test RE 1.3060685050502676\n",
      "37 Train Loss 13.708143 Test MSE 7.458797912385472 Test RE 1.3053966101259125\n",
      "38 Train Loss 13.470812 Test MSE 7.424302384256883 Test RE 1.3023745058296639\n",
      "39 Train Loss 13.276112 Test MSE 7.499988357030633 Test RE 1.3089961067922367\n",
      "40 Train Loss 13.069874 Test MSE 7.413609239066271 Test RE 1.3014362696750996\n",
      "41 Train Loss 12.638565 Test MSE 7.043872943512829 Test RE 1.2685681901398005\n",
      "42 Train Loss 12.06121 Test MSE 6.5621152401083735 Test RE 1.2244187930154378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Train Loss 11.4890785 Test MSE 6.382946378921964 Test RE 1.207587637416557\n",
      "44 Train Loss 11.026041 Test MSE 6.3061097547045755 Test RE 1.2002972825304217\n",
      "45 Train Loss 10.786207 Test MSE 6.338139410608116 Test RE 1.203341664640097\n",
      "46 Train Loss 10.537235 Test MSE 6.434292006235812 Test RE 1.212434940406488\n",
      "47 Train Loss 10.44037 Test MSE 6.390004410218121 Test RE 1.208255106323116\n",
      "48 Train Loss 10.204231 Test MSE 6.567244768671794 Test RE 1.224897256440447\n",
      "49 Train Loss 9.9995 Test MSE 6.581652199827676 Test RE 1.2262401296802452\n",
      "50 Train Loss 9.853762 Test MSE 6.6113738072957 Test RE 1.2290057555111862\n",
      "51 Train Loss 9.67365 Test MSE 6.75280772321833 Test RE 1.2420819546469788\n",
      "52 Train Loss 9.58766 Test MSE 6.686633033219424 Test RE 1.2359810295150737\n",
      "53 Train Loss 9.438211 Test MSE 6.631186848449948 Test RE 1.2308459271805532\n",
      "54 Train Loss 9.328964 Test MSE 6.690192847355411 Test RE 1.2363099900904098\n",
      "55 Train Loss 9.183089 Test MSE 6.574839348978284 Test RE 1.2256053077625293\n",
      "56 Train Loss 9.036741 Test MSE 6.58017629362987 Test RE 1.226102632527207\n",
      "57 Train Loss 8.960098 Test MSE 6.528720873601631 Test RE 1.2212993077971892\n",
      "58 Train Loss 8.866008 Test MSE 6.5384714434194375 Test RE 1.2222109657976867\n",
      "59 Train Loss 8.748966 Test MSE 6.575046198515004 Test RE 1.2256245868568716\n",
      "60 Train Loss 8.605257 Test MSE 6.638704784138518 Test RE 1.231543449322059\n",
      "61 Train Loss 8.499886 Test MSE 6.708156198221908 Test RE 1.2379686405332893\n",
      "62 Train Loss 8.373006 Test MSE 6.837190351154193 Test RE 1.249818347309761\n",
      "63 Train Loss 8.311163 Test MSE 6.840203357920702 Test RE 1.2500937013783051\n",
      "64 Train Loss 8.174293 Test MSE 6.849186345411276 Test RE 1.2509142830968394\n",
      "65 Train Loss 8.073017 Test MSE 6.889841855030819 Test RE 1.2546213885451332\n",
      "66 Train Loss 7.972022 Test MSE 6.907487614190222 Test RE 1.256226983449352\n",
      "67 Train Loss 7.9149017 Test MSE 6.951065402703411 Test RE 1.2601833802528046\n",
      "68 Train Loss 7.837032 Test MSE 6.870147041213113 Test RE 1.252826919332765\n",
      "69 Train Loss 7.7546334 Test MSE 6.881868598127634 Test RE 1.2538952242410066\n",
      "70 Train Loss 7.680151 Test MSE 6.8548561477269665 Test RE 1.2514319335999058\n",
      "71 Train Loss 7.5826597 Test MSE 6.810703342116734 Test RE 1.2473951243728858\n",
      "72 Train Loss 7.527261 Test MSE 6.820704366450748 Test RE 1.2483106430780428\n",
      "73 Train Loss 7.429037 Test MSE 6.778070168291263 Test RE 1.2444031176863484\n",
      "74 Train Loss 7.3744044 Test MSE 6.813843101386624 Test RE 1.2476826181110277\n",
      "75 Train Loss 7.250117 Test MSE 6.688092352644605 Test RE 1.2361158950532292\n",
      "76 Train Loss 7.150033 Test MSE 6.648299083230746 Test RE 1.232433045304838\n",
      "77 Train Loss 7.017976 Test MSE 6.537570918512311 Test RE 1.2221267970951621\n",
      "78 Train Loss 6.9302797 Test MSE 6.375703123256361 Test RE 1.2069022682834378\n",
      "79 Train Loss 6.848269 Test MSE 6.383584086838889 Test RE 1.2076479597910137\n",
      "80 Train Loss 6.745187 Test MSE 6.320831401272716 Test RE 1.2016975159702519\n",
      "81 Train Loss 6.5469184 Test MSE 6.232576963102562 Test RE 1.1932786911679796\n",
      "82 Train Loss 6.378606 Test MSE 6.19182916932288 Test RE 1.189371542592282\n",
      "83 Train Loss 6.2549276 Test MSE 6.051656055634612 Test RE 1.1758317388860677\n",
      "84 Train Loss 6.0455046 Test MSE 6.0121704618490766 Test RE 1.1719894521132481\n",
      "85 Train Loss 5.7730255 Test MSE 5.822340539508414 Test RE 1.1533386917236188\n",
      "86 Train Loss 5.5671515 Test MSE 5.722904737050413 Test RE 1.1434477352557144\n",
      "87 Train Loss 5.443206 Test MSE 5.644703102491961 Test RE 1.1356084418215562\n",
      "88 Train Loss 5.2602787 Test MSE 5.744046706286184 Test RE 1.1455578919052902\n",
      "89 Train Loss 5.053199 Test MSE 5.742036893450724 Test RE 1.1453574619206772\n",
      "90 Train Loss 4.89348 Test MSE 5.6979449074220865 Test RE 1.1409514987434568\n",
      "91 Train Loss 4.6943693 Test MSE 5.694177271097985 Test RE 1.1405742222676079\n",
      "92 Train Loss 4.523624 Test MSE 5.6053804256480175 Test RE 1.1316460362425638\n",
      "93 Train Loss 4.4320045 Test MSE 5.590314306171151 Test RE 1.1301241960712811\n",
      "94 Train Loss 4.3256207 Test MSE 5.562416500393713 Test RE 1.1273007932869077\n",
      "95 Train Loss 4.246553 Test MSE 5.560568165312559 Test RE 1.1271134823651028\n",
      "96 Train Loss 4.1503124 Test MSE 5.545819393977247 Test RE 1.1256177200456858\n",
      "97 Train Loss 4.067971 Test MSE 5.574825267060842 Test RE 1.1285574970754642\n",
      "98 Train Loss 3.982808 Test MSE 5.506329525159803 Test RE 1.1216029924561361\n",
      "99 Train Loss 3.842998 Test MSE 5.563594651336444 Test RE 1.1274201712742744\n",
      "100 Train Loss 3.7939365 Test MSE 5.590023642682413 Test RE 1.1300948157812394\n",
      "101 Train Loss 3.6966846 Test MSE 5.725025230439824 Test RE 1.1436595550320978\n",
      "102 Train Loss 3.642797 Test MSE 5.654299142216091 Test RE 1.1365733035743344\n",
      "103 Train Loss 3.6143134 Test MSE 5.697662940046097 Test RE 1.1409232679439674\n",
      "104 Train Loss 3.5785134 Test MSE 5.692780826291838 Test RE 1.1404343560027703\n",
      "105 Train Loss 3.5545034 Test MSE 5.747628417096429 Test RE 1.145914993603546\n",
      "106 Train Loss 3.5100417 Test MSE 5.706480515811028 Test RE 1.1418057603136775\n",
      "107 Train Loss 3.4824975 Test MSE 5.697312564125601 Test RE 1.1408881870528838\n",
      "108 Train Loss 3.4381757 Test MSE 5.709918624977498 Test RE 1.1421496729691558\n",
      "109 Train Loss 3.40239 Test MSE 5.699399191350048 Test RE 1.1410970917242726\n",
      "110 Train Loss 3.3749084 Test MSE 5.6640455855735174 Test RE 1.137552450370552\n",
      "111 Train Loss 3.3473964 Test MSE 5.662803950591617 Test RE 1.1374277601373164\n",
      "112 Train Loss 3.3209877 Test MSE 5.684918076845783 Test RE 1.1396465118668926\n",
      "113 Train Loss 3.2702355 Test MSE 5.741875164450703 Test RE 1.1453413318587515\n",
      "114 Train Loss 3.2306933 Test MSE 5.657185926088892 Test RE 1.1368634034369463\n",
      "115 Train Loss 3.1420848 Test MSE 5.6921168525397325 Test RE 1.1403678471574277\n",
      "116 Train Loss 3.127856 Test MSE 5.7191604951791195 Test RE 1.1430736205720657\n",
      "117 Train Loss 3.0736115 Test MSE 5.7910991081920695 Test RE 1.1502402456328062\n",
      "118 Train Loss 3.031022 Test MSE 5.804620654851493 Test RE 1.1515823016755273\n",
      "119 Train Loss 3.0026393 Test MSE 5.808819069772657 Test RE 1.1519986894706449\n",
      "120 Train Loss 2.9662652 Test MSE 5.817285162050373 Test RE 1.1528378769256111\n",
      "121 Train Loss 2.9339595 Test MSE 5.811723150980511 Test RE 1.152286620603456\n",
      "122 Train Loss 2.8844361 Test MSE 5.857807330008676 Test RE 1.156846140055122\n",
      "123 Train Loss 2.8493063 Test MSE 5.882623068898058 Test RE 1.1592939545757308\n",
      "124 Train Loss 2.7904167 Test MSE 5.874754853466082 Test RE 1.1585183969184565\n",
      "125 Train Loss 2.738546 Test MSE 5.795603248360961 Test RE 1.1506874695719553\n",
      "126 Train Loss 2.7012694 Test MSE 5.815679068844705 Test RE 1.1526787225394157\n",
      "127 Train Loss 2.658856 Test MSE 5.779632474741099 Test RE 1.1491009179858753\n",
      "128 Train Loss 2.6312804 Test MSE 5.8029494246379905 Test RE 1.1514165115406456\n",
      "129 Train Loss 2.5913303 Test MSE 5.725578915612389 Test RE 1.143714857148943\n",
      "130 Train Loss 2.5696332 Test MSE 5.754039279159327 Test RE 1.1465538880366528\n",
      "131 Train Loss 2.5464268 Test MSE 5.769994242567539 Test RE 1.1481423862202242\n",
      "132 Train Loss 2.4984403 Test MSE 5.786371136628741 Test RE 1.1497706099462548\n",
      "133 Train Loss 2.4570718 Test MSE 5.802443337841672 Test RE 1.1513663017803637\n",
      "134 Train Loss 2.4268935 Test MSE 5.829781085173649 Test RE 1.1540753996905846\n",
      "135 Train Loss 2.4094422 Test MSE 5.816354774438046 Test RE 1.1527456836654149\n",
      "136 Train Loss 2.3694897 Test MSE 5.781456534153966 Test RE 1.149282232542098\n",
      "137 Train Loss 2.3277378 Test MSE 5.820866360884272 Test RE 1.153192673565678\n",
      "138 Train Loss 2.2987828 Test MSE 5.808319136025567 Test RE 1.151949115245081\n",
      "139 Train Loss 2.2767148 Test MSE 5.8216364486363545 Test RE 1.1532689534635927\n",
      "140 Train Loss 2.2597892 Test MSE 5.816613216827148 Test RE 1.1527712937812638\n",
      "141 Train Loss 2.229402 Test MSE 5.776800459081348 Test RE 1.1488193541880054\n",
      "142 Train Loss 2.1979122 Test MSE 5.8449728316862695 Test RE 1.1555781159724363\n",
      "143 Train Loss 2.1802719 Test MSE 5.863771795667218 Test RE 1.1574349451470987\n",
      "144 Train Loss 2.1638327 Test MSE 5.847789155477707 Test RE 1.1558564825531354\n",
      "145 Train Loss 2.152039 Test MSE 5.847035116026061 Test RE 1.155781959561398\n",
      "146 Train Loss 2.1392317 Test MSE 5.860122818308654 Test RE 1.157074757940315\n",
      "147 Train Loss 2.1281853 Test MSE 5.852605130915655 Test RE 1.156332340236968\n",
      "148 Train Loss 2.1090095 Test MSE 5.852368100759403 Test RE 1.1563089243047187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 Train Loss 2.0814805 Test MSE 5.84498043116324 Test RE 1.1555788671980345\n",
      "Training time: 297.56\n",
      "2\n",
      "KG_rowdy_tune59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 64.40421 Test MSE 6.2783499628037776 Test RE 1.19765248612924\n",
      "1 Train Loss 52.03505 Test MSE 8.947479480561444 Test RE 1.4297444383159847\n",
      "2 Train Loss 40.687622 Test MSE 7.511993917262707 Test RE 1.3100433715924789\n",
      "3 Train Loss 32.432495 Test MSE 6.934488941075372 Test RE 1.2586798804993684\n",
      "4 Train Loss 28.295506 Test MSE 6.204198528376671 Test RE 1.1905589480582803\n",
      "5 Train Loss 24.022717 Test MSE 6.0062125060943385 Test RE 1.17140859765091\n",
      "6 Train Loss 21.638012 Test MSE 6.255167362175223 Test RE 1.1954392950097155\n",
      "7 Train Loss 19.528267 Test MSE 6.096534465801511 Test RE 1.1801836044377272\n",
      "8 Train Loss 17.719624 Test MSE 6.220449392113382 Test RE 1.192117163696618\n",
      "9 Train Loss 16.1148 Test MSE 6.259050733324752 Test RE 1.1958103173903714\n",
      "10 Train Loss 15.225207 Test MSE 6.217587727139661 Test RE 1.1918429204580565\n",
      "11 Train Loss 14.272743 Test MSE 5.938626121010442 Test RE 1.1647991696578546\n",
      "12 Train Loss 13.600172 Test MSE 6.067617928879278 Test RE 1.177381407054738\n",
      "13 Train Loss 12.914529 Test MSE 6.055317824390855 Test RE 1.1761874244012311\n",
      "14 Train Loss 12.456947 Test MSE 5.981197319857049 Test RE 1.1689666611712652\n",
      "15 Train Loss 11.991346 Test MSE 5.976756227249793 Test RE 1.16853259647158\n",
      "16 Train Loss 11.67179 Test MSE 5.9823339748179185 Test RE 1.1690777299559094\n",
      "17 Train Loss 11.320686 Test MSE 6.015396365226862 Test RE 1.17230383256402\n",
      "18 Train Loss 10.964418 Test MSE 5.992298975390944 Test RE 1.1700510133709459\n",
      "19 Train Loss 10.703174 Test MSE 5.967225243645324 Test RE 1.1676005098833149\n",
      "20 Train Loss 10.499722 Test MSE 5.9500386999547255 Test RE 1.1659178612283674\n",
      "21 Train Loss 10.307808 Test MSE 5.882640179040318 Test RE 1.1592956405302643\n",
      "22 Train Loss 10.080828 Test MSE 5.8026711250788985 Test RE 1.1513889012233693\n",
      "23 Train Loss 9.880788 Test MSE 5.767725065842122 Test RE 1.147916597937543\n",
      "24 Train Loss 9.536968 Test MSE 5.5712912283600255 Test RE 1.128199728180077\n",
      "25 Train Loss 9.4594 Test MSE 5.509072079961728 Test RE 1.1218822778429527\n",
      "26 Train Loss 9.160971 Test MSE 5.277518859799412 Test RE 1.098052126325119\n",
      "27 Train Loss 8.932912 Test MSE 5.259194188926879 Test RE 1.0961441330780684\n",
      "28 Train Loss 8.537677 Test MSE 5.195543831720559 Test RE 1.089490798819069\n",
      "29 Train Loss 8.410009 Test MSE 5.217172929271139 Test RE 1.0917562237127452\n",
      "30 Train Loss 8.069059 Test MSE 5.0234692808288735 Test RE 1.0712971158326925\n",
      "31 Train Loss 7.949045 Test MSE 4.956500315739609 Test RE 1.0641323090107209\n",
      "32 Train Loss 7.810032 Test MSE 4.944077281012496 Test RE 1.0627978950369226\n",
      "33 Train Loss 7.7510366 Test MSE 4.929844456666742 Test RE 1.0612670211168396\n",
      "34 Train Loss 7.6591725 Test MSE 4.878837499675491 Test RE 1.0557625117016767\n",
      "35 Train Loss 7.512841 Test MSE 4.896789856286792 Test RE 1.0577031401481145\n",
      "36 Train Loss 7.40333 Test MSE 4.811701444152018 Test RE 1.048473351020544\n",
      "37 Train Loss 7.2286644 Test MSE 4.66860922568498 Test RE 1.0327657390870733\n",
      "38 Train Loss 7.123514 Test MSE 4.617224817438349 Test RE 1.0270665164153865\n",
      "39 Train Loss 6.9404154 Test MSE 4.490102607990485 Test RE 1.0128291521299728\n",
      "40 Train Loss 6.740674 Test MSE 4.383293601956825 Test RE 1.0007102336237292\n",
      "41 Train Loss 6.4771223 Test MSE 4.117071787901959 Test RE 0.9698448860664056\n",
      "42 Train Loss 6.4177065 Test MSE 4.143812425740374 Test RE 0.9729893898812506\n",
      "43 Train Loss 6.22725 Test MSE 3.890496903127924 Test RE 0.9427805131090999\n",
      "44 Train Loss 6.099528 Test MSE 3.6719343328664156 Test RE 0.9159157205832377\n",
      "45 Train Loss 5.991621 Test MSE 3.4997232058997096 Test RE 0.8941799115916759\n",
      "46 Train Loss 5.8090863 Test MSE 3.4044895351068583 Test RE 0.8819298905681271\n",
      "47 Train Loss 5.6266584 Test MSE 3.311290463951926 Test RE 0.8697745572621017\n",
      "48 Train Loss 5.4982862 Test MSE 3.2771805964796035 Test RE 0.8652831521574832\n",
      "49 Train Loss 5.462076 Test MSE 3.2899492195427062 Test RE 0.8669671810315283\n",
      "50 Train Loss 5.3935165 Test MSE 3.241576573890453 Test RE 0.8605700012209788\n",
      "51 Train Loss 5.2915707 Test MSE 3.138875706656958 Test RE 0.8468278251930046\n",
      "52 Train Loss 5.236711 Test MSE 3.113286821691286 Test RE 0.8433689873323186\n",
      "53 Train Loss 5.218496 Test MSE 3.107516802149203 Test RE 0.8425870946524749\n",
      "54 Train Loss 5.199414 Test MSE 3.1109742042804567 Test RE 0.8430556926941754\n",
      "55 Train Loss 5.1638975 Test MSE 3.0887244343541584 Test RE 0.8400355045632935\n",
      "56 Train Loss 5.1212893 Test MSE 3.058876353771373 Test RE 0.8359667834561226\n",
      "57 Train Loss 5.0833454 Test MSE 3.030065359522013 Test RE 0.8320205605307082\n",
      "58 Train Loss 4.991469 Test MSE 2.9737170629288663 Test RE 0.8242479632924147\n",
      "59 Train Loss 4.9641953 Test MSE 2.9769934320543423 Test RE 0.8247019064691783\n",
      "60 Train Loss 4.945507 Test MSE 2.9452940923387048 Test RE 0.820299399118921\n",
      "61 Train Loss 4.864407 Test MSE 2.844776448090939 Test RE 0.8061802085570887\n",
      "62 Train Loss 4.84196 Test MSE 2.831333316599679 Test RE 0.8042731307117904\n",
      "63 Train Loss 4.8187704 Test MSE 2.800084477445185 Test RE 0.7998225185712962\n",
      "64 Train Loss 4.7983885 Test MSE 2.7561064347932733 Test RE 0.793516666480089\n",
      "65 Train Loss 4.774586 Test MSE 2.778112674722395 Test RE 0.7966783004536138\n",
      "66 Train Loss 4.7400017 Test MSE 2.7384821291913632 Test RE 0.7909754711602663\n",
      "67 Train Loss 4.720326 Test MSE 2.7574236670409284 Test RE 0.7937062674457138\n",
      "68 Train Loss 4.70917 Test MSE 2.73077565087517 Test RE 0.7898617282964331\n",
      "69 Train Loss 4.684254 Test MSE 2.668558368596103 Test RE 0.7808118818507819\n",
      "70 Train Loss 4.628838 Test MSE 2.5982563323287615 Test RE 0.7704581569805337\n",
      "71 Train Loss 4.6012096 Test MSE 2.6072308134029436 Test RE 0.7717876065895998\n",
      "72 Train Loss 4.5800056 Test MSE 2.5322354176217012 Test RE 0.7606066177096164\n",
      "73 Train Loss 4.562757 Test MSE 2.5312990087453375 Test RE 0.7604659703114494\n",
      "74 Train Loss 4.5439873 Test MSE 2.509386232359555 Test RE 0.7571672408017324\n",
      "75 Train Loss 4.502578 Test MSE 2.5082102317782113 Test RE 0.7569898003082838\n",
      "76 Train Loss 4.4857144 Test MSE 2.514689910359374 Test RE 0.7579669685510156\n",
      "77 Train Loss 4.4680376 Test MSE 2.5224559875257033 Test RE 0.759136475018808\n",
      "78 Train Loss 4.4550247 Test MSE 2.5187533170297196 Test RE 0.7585791086081728\n",
      "79 Train Loss 4.4387393 Test MSE 2.480057838258682 Test RE 0.7527295489471233\n",
      "80 Train Loss 4.426284 Test MSE 2.475949011601773 Test RE 0.752105749521659\n",
      "81 Train Loss 4.3925824 Test MSE 2.4238841704784053 Test RE 0.7441560064589977\n",
      "82 Train Loss 4.3613634 Test MSE 2.34933275438874 Test RE 0.732622626020326\n",
      "83 Train Loss 4.3444195 Test MSE 2.3233677162419735 Test RE 0.7285628718902747\n",
      "84 Train Loss 4.3196573 Test MSE 2.2805200678552304 Test RE 0.7218135150271042\n",
      "85 Train Loss 4.289961 Test MSE 2.2570106844348543 Test RE 0.7180833678469605\n",
      "86 Train Loss 4.273995 Test MSE 2.2253537589970973 Test RE 0.7130296508126701\n",
      "87 Train Loss 4.246992 Test MSE 2.204845993600419 Test RE 0.709736581195079\n",
      "88 Train Loss 4.2340894 Test MSE 2.199795417033706 Test RE 0.708923228679055\n",
      "89 Train Loss 4.208123 Test MSE 2.1757172197173924 Test RE 0.7050327395666768\n",
      "90 Train Loss 4.1878853 Test MSE 2.166228995681355 Test RE 0.7034937487347402\n",
      "91 Train Loss 4.1604633 Test MSE 2.1591444430960993 Test RE 0.7023424346126209\n",
      "92 Train Loss 4.1395764 Test MSE 2.174728322159119 Test RE 0.7048724971443123\n",
      "93 Train Loss 4.112381 Test MSE 2.193388620515018 Test RE 0.7078901238053373\n",
      "94 Train Loss 4.086855 Test MSE 2.1793523699805197 Test RE 0.705621471941178\n",
      "95 Train Loss 4.071008 Test MSE 2.1947816754708964 Test RE 0.7081148840938458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 4.06304 Test MSE 2.1834695866825897 Test RE 0.7062876849237907\n",
      "97 Train Loss 4.051591 Test MSE 2.180735864082628 Test RE 0.705845407335042\n",
      "98 Train Loss 4.0371704 Test MSE 2.166154501702963 Test RE 0.7034816524838883\n",
      "99 Train Loss 4.022995 Test MSE 2.17481829088687 Test RE 0.7048870773162987\n",
      "100 Train Loss 4.0041337 Test MSE 2.1634327813909193 Test RE 0.703039559799218\n",
      "101 Train Loss 3.9822774 Test MSE 2.1663872551473604 Test RE 0.7035194460437162\n",
      "102 Train Loss 3.9569607 Test MSE 2.177455994079799 Test RE 0.7053144048524558\n",
      "103 Train Loss 3.944087 Test MSE 2.1742848162059873 Test RE 0.7048006189502608\n",
      "104 Train Loss 3.9214354 Test MSE 2.1696949847151465 Test RE 0.7040563224690463\n",
      "105 Train Loss 3.9064045 Test MSE 2.1825333205664053 Test RE 0.7061362415203719\n",
      "106 Train Loss 3.88657 Test MSE 2.174883703494307 Test RE 0.7048976777777648\n",
      "107 Train Loss 3.8706748 Test MSE 2.174434094581253 Test RE 0.7048248130403594\n",
      "108 Train Loss 3.854051 Test MSE 2.172508263776434 Test RE 0.7045126228434534\n",
      "109 Train Loss 3.8134346 Test MSE 2.1603995995532292 Test RE 0.7025465482294955\n",
      "110 Train Loss 3.7706785 Test MSE 2.1435645994421635 Test RE 0.6998038836894916\n",
      "111 Train Loss 3.7257862 Test MSE 2.1182821355762744 Test RE 0.6956646928103895\n",
      "112 Train Loss 3.7038107 Test MSE 2.1217855577902296 Test RE 0.6962397343043717\n",
      "113 Train Loss 3.6804936 Test MSE 2.083033585855673 Test RE 0.6898524268716365\n",
      "114 Train Loss 3.6421251 Test MSE 2.0675716665130275 Test RE 0.6872873433922246\n",
      "115 Train Loss 3.5843515 Test MSE 1.9539991745255205 Test RE 0.6681442699732144\n",
      "116 Train Loss 3.5063996 Test MSE 1.7828819234566307 Test RE 0.6382184444929416\n",
      "117 Train Loss 3.4260874 Test MSE 1.6920923159252732 Test RE 0.6217561459870322\n",
      "118 Train Loss 3.2792134 Test MSE 1.5242388710689763 Test RE 0.5901121773403887\n",
      "119 Train Loss 3.1370778 Test MSE 1.423147899426143 Test RE 0.5702077008854556\n",
      "120 Train Loss 3.0240133 Test MSE 1.3720859455150785 Test RE 0.5598848527912796\n",
      "121 Train Loss 2.8747652 Test MSE 1.3624648326878739 Test RE 0.5579184338629051\n",
      "122 Train Loss 2.63819 Test MSE 1.3152439048461895 Test RE 0.5481648820514667\n",
      "123 Train Loss 2.4589171 Test MSE 1.1546720310245016 Test RE 0.5136146271183791\n",
      "124 Train Loss 2.3125374 Test MSE 1.103088652542974 Test RE 0.5020110408517685\n",
      "125 Train Loss 2.1085207 Test MSE 0.8607665180507726 Test RE 0.4434562121137055\n",
      "126 Train Loss 2.0293086 Test MSE 0.8642203177385415 Test RE 0.4443449987857211\n",
      "127 Train Loss 1.9787805 Test MSE 0.8328459497302088 Test RE 0.4362047588689738\n",
      "128 Train Loss 1.908675 Test MSE 0.8109610391648661 Test RE 0.4304354731130372\n",
      "129 Train Loss 1.8278275 Test MSE 0.7935833903920066 Test RE 0.42579871359661636\n",
      "130 Train Loss 1.7865496 Test MSE 0.8033163926920993 Test RE 0.42840188685472524\n",
      "131 Train Loss 1.6584849 Test MSE 0.8755811969332037 Test RE 0.44725610108193825\n",
      "132 Train Loss 1.5547422 Test MSE 0.8059946214134759 Test RE 0.4291154310609012\n",
      "133 Train Loss 1.4765121 Test MSE 0.7769800257331111 Test RE 0.4213208846692062\n",
      "134 Train Loss 1.4096997 Test MSE 0.7261630430658158 Test RE 0.40731005510709895\n",
      "135 Train Loss 1.3150619 Test MSE 0.5732901984046392 Test RE 0.3619056127765394\n",
      "136 Train Loss 1.2296001 Test MSE 0.5436948844969248 Test RE 0.352440398563683\n",
      "137 Train Loss 1.1985477 Test MSE 0.5796358214533802 Test RE 0.3639030275449841\n",
      "138 Train Loss 1.1477162 Test MSE 0.5981083266100884 Test RE 0.3696561913253836\n",
      "139 Train Loss 1.107648 Test MSE 0.5556906986636319 Test RE 0.3563072210597119\n",
      "140 Train Loss 1.0360116 Test MSE 0.41518074636998337 Test RE 0.30798294176955193\n",
      "141 Train Loss 0.94142056 Test MSE 0.42644832214068407 Test RE 0.3121341346888801\n",
      "142 Train Loss 0.91984177 Test MSE 0.4339203596637569 Test RE 0.3148567977836729\n",
      "143 Train Loss 0.8657924 Test MSE 0.4746914818733529 Test RE 0.32931671877374263\n",
      "144 Train Loss 0.82660216 Test MSE 0.5107960631420905 Test RE 0.34161098763390363\n",
      "145 Train Loss 0.7999071 Test MSE 0.5064556761095306 Test RE 0.34015650584639906\n",
      "146 Train Loss 0.7472937 Test MSE 0.5060424543846535 Test RE 0.3400177091584943\n",
      "147 Train Loss 0.73076093 Test MSE 0.5181111192989396 Test RE 0.34404837957865725\n",
      "148 Train Loss 0.7137551 Test MSE 0.4863141926070039 Test RE 0.33332395972343504\n",
      "149 Train Loss 0.669281 Test MSE 0.472135260312206 Test RE 0.3284288338249216\n",
      "Training time: 292.88\n",
      "3\n",
      "KG_rowdy_tune59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 63.21176 Test MSE 5.7971149419513335 Test RE 1.150837529314053\n",
      "1 Train Loss 51.51638 Test MSE 8.217232113675836 Test RE 1.3701585895451587\n",
      "2 Train Loss 42.80893 Test MSE 9.191699228432006 Test RE 1.4491253798965795\n",
      "3 Train Loss 39.37726 Test MSE 8.840722923388087 Test RE 1.421189368733516\n",
      "4 Train Loss 36.23013 Test MSE 8.676501930050655 Test RE 1.407927831891222\n",
      "5 Train Loss 32.978325 Test MSE 8.68582622240198 Test RE 1.4086841508373409\n",
      "6 Train Loss 31.031963 Test MSE 8.561743339116994 Test RE 1.3985859548301849\n",
      "7 Train Loss 29.840012 Test MSE 8.830177877359272 Test RE 1.4203415320231454\n",
      "8 Train Loss 27.668375 Test MSE 9.011494318266282 Test RE 1.4348498837929717\n",
      "9 Train Loss 26.250885 Test MSE 9.083601714942171 Test RE 1.4405790747092477\n",
      "10 Train Loss 24.927156 Test MSE 9.322869901369069 Test RE 1.4594286652776676\n",
      "11 Train Loss 23.786678 Test MSE 9.32565348228918 Test RE 1.4596465238683716\n",
      "12 Train Loss 22.698906 Test MSE 9.233979521853048 Test RE 1.4524544243420872\n",
      "13 Train Loss 21.784576 Test MSE 9.037485584765156 Test RE 1.4369176159724706\n",
      "14 Train Loss 21.071667 Test MSE 8.962792160793885 Test RE 1.4309673447479323\n",
      "15 Train Loss 20.091597 Test MSE 8.722779622910915 Test RE 1.4116775574925768\n",
      "16 Train Loss 19.218456 Test MSE 8.524844721703056 Test RE 1.3955689518822327\n",
      "17 Train Loss 18.180237 Test MSE 8.245451146060473 Test RE 1.372509223626803\n",
      "18 Train Loss 17.32529 Test MSE 8.315231818569076 Test RE 1.3783047122195053\n",
      "19 Train Loss 16.04618 Test MSE 8.173575816593655 Test RE 1.3665140710113182\n",
      "20 Train Loss 15.16173 Test MSE 7.809787278758913 Test RE 1.3357576271987643\n",
      "21 Train Loss 14.400447 Test MSE 7.542225810400777 Test RE 1.3126768484115405\n",
      "22 Train Loss 13.824711 Test MSE 7.340075192231602 Test RE 1.2949658472705412\n",
      "23 Train Loss 13.285378 Test MSE 7.190212649446288 Test RE 1.2816779939402698\n",
      "24 Train Loss 12.889215 Test MSE 7.092534188795664 Test RE 1.2729424784307748\n",
      "25 Train Loss 12.342968 Test MSE 6.851253219780739 Test RE 1.2511030126418048\n",
      "26 Train Loss 11.786926 Test MSE 6.691242703292785 Test RE 1.2364069900197958\n",
      "27 Train Loss 11.270551 Test MSE 6.5787441676137846 Test RE 1.225969199245794\n",
      "28 Train Loss 11.08292 Test MSE 6.616992907208628 Test RE 1.229527919255174\n",
      "29 Train Loss 10.717829 Test MSE 6.443520751125673 Test RE 1.2133041303205354\n",
      "30 Train Loss 10.329362 Test MSE 6.458659502729483 Test RE 1.214728594877722\n",
      "31 Train Loss 10.11216 Test MSE 6.420851484216062 Test RE 1.2111679573875387\n",
      "32 Train Loss 9.778872 Test MSE 6.419847858089395 Test RE 1.2110732964759183\n",
      "33 Train Loss 9.472404 Test MSE 6.482050165073497 Test RE 1.2169262356948225\n",
      "34 Train Loss 9.24176 Test MSE 6.308571779661788 Test RE 1.2005315690873537\n",
      "35 Train Loss 9.039035 Test MSE 6.304745206940123 Test RE 1.200167412321282\n",
      "36 Train Loss 8.72513 Test MSE 6.386610598207125 Test RE 1.207934203938515\n",
      "37 Train Loss 8.486869 Test MSE 6.34145591457683 Test RE 1.2036564546135546\n",
      "38 Train Loss 8.385214 Test MSE 6.353501421561671 Test RE 1.2047990765887724\n",
      "39 Train Loss 8.2333145 Test MSE 6.3044767051457695 Test RE 1.200141856131132\n",
      "40 Train Loss 8.022374 Test MSE 6.343068578072733 Test RE 1.2038094927691791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 Train Loss 7.891968 Test MSE 6.340684173474707 Test RE 1.2035832112263338\n",
      "42 Train Loss 7.735135 Test MSE 6.266625832817789 Test RE 1.196533721259043\n",
      "43 Train Loss 7.620984 Test MSE 6.28260053492881 Test RE 1.1980578352230429\n",
      "44 Train Loss 7.4410458 Test MSE 6.270502653040554 Test RE 1.1969037791688693\n",
      "45 Train Loss 7.350931 Test MSE 6.173740392258753 Test RE 1.1876329600176483\n",
      "46 Train Loss 7.1861353 Test MSE 6.119657902716139 Test RE 1.1824196348736107\n",
      "47 Train Loss 6.970748 Test MSE 6.051317235508882 Test RE 1.1757988221909976\n",
      "48 Train Loss 6.8622084 Test MSE 6.040374040897942 Test RE 1.1747351845345995\n",
      "49 Train Loss 6.5364037 Test MSE 6.048927583366407 Test RE 1.175566639055404\n",
      "50 Train Loss 6.094576 Test MSE 6.016011694024452 Test RE 1.1723637898650563\n",
      "51 Train Loss 5.9149847 Test MSE 5.99884948162782 Test RE 1.1706903617275848\n",
      "52 Train Loss 5.8125887 Test MSE 5.9360105188384855 Test RE 1.1645426299535677\n",
      "53 Train Loss 5.5040336 Test MSE 5.847615484463755 Test RE 1.1558393187795788\n",
      "54 Train Loss 5.269295 Test MSE 5.827850844632897 Test RE 1.153884326688467\n",
      "55 Train Loss 5.0624285 Test MSE 5.885172554931575 Test RE 1.159545142145154\n",
      "56 Train Loss 4.866467 Test MSE 5.8134351804839 Test RE 1.152456329601707\n",
      "57 Train Loss 4.574984 Test MSE 5.757701911300389 Test RE 1.146918739306029\n",
      "58 Train Loss 4.2602644 Test MSE 5.603656697230915 Test RE 1.1314720248224295\n",
      "59 Train Loss 4.07127 Test MSE 5.702349405131998 Test RE 1.1413923899402303\n",
      "60 Train Loss 3.858036 Test MSE 5.561528274475754 Test RE 1.1272107840474221\n",
      "61 Train Loss 3.629736 Test MSE 5.446087036714208 Test RE 1.1154506198289722\n",
      "62 Train Loss 3.4401927 Test MSE 5.502226685663124 Test RE 1.1211850539216601\n",
      "63 Train Loss 3.3136344 Test MSE 5.461829591431187 Test RE 1.117061627031434\n",
      "64 Train Loss 3.173966 Test MSE 5.38045294158208 Test RE 1.1087087600146002\n",
      "65 Train Loss 3.0476499 Test MSE 5.292854077065191 Test RE 1.0996463085227568\n",
      "66 Train Loss 2.9660728 Test MSE 5.280486357628039 Test RE 1.0983607949878667\n",
      "67 Train Loss 2.8623083 Test MSE 5.315454720535105 Test RE 1.1019915687393151\n",
      "68 Train Loss 2.7722304 Test MSE 5.264144441145403 Test RE 1.096659888293864\n",
      "69 Train Loss 2.6905434 Test MSE 5.199912359574133 Test RE 1.0899487365257203\n",
      "70 Train Loss 2.6576412 Test MSE 5.186393930007917 Test RE 1.0885310218528432\n",
      "71 Train Loss 2.6119246 Test MSE 5.112005611627773 Test RE 1.0806964409846835\n",
      "72 Train Loss 2.5561411 Test MSE 5.0869240659318296 Test RE 1.078042016410687\n",
      "73 Train Loss 2.5131042 Test MSE 5.126452470510989 Test RE 1.0822224226755834\n",
      "74 Train Loss 2.4679744 Test MSE 5.08663114049796 Test RE 1.078010976978264\n",
      "75 Train Loss 2.4257038 Test MSE 5.090826921051603 Test RE 1.0784554917285936\n",
      "76 Train Loss 2.4012144 Test MSE 5.089262271311937 Test RE 1.0782897490304872\n",
      "77 Train Loss 2.3692858 Test MSE 5.086465745493924 Test RE 1.0779934507340416\n",
      "78 Train Loss 2.3310726 Test MSE 5.085714917962161 Test RE 1.0779138849732997\n",
      "79 Train Loss 2.293697 Test MSE 5.147029918128288 Test RE 1.0843922538507587\n",
      "80 Train Loss 2.2624571 Test MSE 5.187079433255526 Test RE 1.088602956891488\n",
      "81 Train Loss 2.2345204 Test MSE 5.225207848950192 Test RE 1.092596602093722\n",
      "82 Train Loss 2.211292 Test MSE 5.202854160070277 Test RE 1.0902570069484954\n",
      "83 Train Loss 2.1607652 Test MSE 5.277795197032953 Test RE 1.0980808736136662\n",
      "84 Train Loss 2.1247003 Test MSE 5.29674433147064 Test RE 1.100050355002827\n",
      "85 Train Loss 2.1080768 Test MSE 5.322279268245794 Test RE 1.1026987689739252\n",
      "86 Train Loss 2.0706406 Test MSE 5.28849528940842 Test RE 1.0991934231885507\n",
      "87 Train Loss 2.0333242 Test MSE 5.325870120588828 Test RE 1.1030706924121942\n",
      "88 Train Loss 2.0154479 Test MSE 5.302177818841183 Test RE 1.100614435244225\n",
      "89 Train Loss 1.9808934 Test MSE 5.298649290156571 Test RE 1.1002481521747136\n",
      "90 Train Loss 1.9579068 Test MSE 5.261747990299892 Test RE 1.0964102379739176\n",
      "91 Train Loss 1.9404271 Test MSE 5.272725191510338 Test RE 1.0975533224724665\n",
      "92 Train Loss 1.915924 Test MSE 5.2901361766102575 Test RE 1.099363936012752\n",
      "93 Train Loss 1.9015228 Test MSE 5.295361561952878 Test RE 1.0999067559075708\n",
      "94 Train Loss 1.8723834 Test MSE 5.306496746904589 Test RE 1.1010626008031092\n",
      "95 Train Loss 1.857171 Test MSE 5.332819913681368 Test RE 1.1037901629995723\n",
      "96 Train Loss 1.8350611 Test MSE 5.325456321242362 Test RE 1.1030278394334572\n",
      "97 Train Loss 1.8070111 Test MSE 5.351497199664528 Test RE 1.1057213912789143\n",
      "98 Train Loss 1.7866595 Test MSE 5.299835092180152 Test RE 1.1003712593504829\n",
      "99 Train Loss 1.7737142 Test MSE 5.30080859289598 Test RE 1.1004723156100749\n",
      "100 Train Loss 1.7528503 Test MSE 5.299845161775493 Test RE 1.1003723046932012\n",
      "101 Train Loss 1.735395 Test MSE 5.2913481944367575 Test RE 1.099489865888045\n",
      "102 Train Loss 1.723999 Test MSE 5.273634155173593 Test RE 1.0976479218551887\n",
      "103 Train Loss 1.7021431 Test MSE 5.311957552224226 Test RE 1.1016289954233929\n",
      "104 Train Loss 1.6815072 Test MSE 5.346874733542961 Test RE 1.1052437432792346\n",
      "105 Train Loss 1.6632522 Test MSE 5.37217008037476 Test RE 1.1078550384163621\n",
      "106 Train Loss 1.6511897 Test MSE 5.381949684984613 Test RE 1.1088629605204519\n",
      "107 Train Loss 1.6439409 Test MSE 5.398065281800135 Test RE 1.1105218975277094\n",
      "108 Train Loss 1.6317325 Test MSE 5.385068154521082 Test RE 1.1091841688927095\n",
      "109 Train Loss 1.6168975 Test MSE 5.378953641601076 Test RE 1.1085542746154222\n",
      "110 Train Loss 1.603453 Test MSE 5.395095638702957 Test RE 1.1102163892388344\n",
      "111 Train Loss 1.5867584 Test MSE 5.404670282996275 Test RE 1.1112010997694968\n",
      "112 Train Loss 1.5703251 Test MSE 5.411343291697458 Test RE 1.1118868740014574\n",
      "113 Train Loss 1.5618 Test MSE 5.412032099996239 Test RE 1.1119576376265246\n",
      "114 Train Loss 1.5526305 Test MSE 5.43685885746127 Test RE 1.114505175658522\n",
      "115 Train Loss 1.5320117 Test MSE 5.42569594610527 Test RE 1.1133604415966838\n",
      "116 Train Loss 1.5221813 Test MSE 5.444098313520852 Test RE 1.1152469391813395\n",
      "117 Train Loss 1.5159299 Test MSE 5.425245709140223 Test RE 1.1133142460089744\n",
      "118 Train Loss 1.5110555 Test MSE 5.452427186786932 Test RE 1.1160997158860202\n",
      "119 Train Loss 1.5053391 Test MSE 5.422433309361533 Test RE 1.1130256424328506\n",
      "120 Train Loss 1.4948602 Test MSE 5.430651079001982 Test RE 1.1138687256937476\n",
      "121 Train Loss 1.4869144 Test MSE 5.42671222532258 Test RE 1.113464707677032\n",
      "122 Train Loss 1.4787914 Test MSE 5.419717827412528 Test RE 1.1127469133680923\n",
      "123 Train Loss 1.4701424 Test MSE 5.435804964454423 Test RE 1.114397151322474\n",
      "124 Train Loss 1.4662054 Test MSE 5.44730443900123 Test RE 1.1155752851388367\n",
      "125 Train Loss 1.4631753 Test MSE 5.449660767895535 Test RE 1.1158165400659603\n",
      "126 Train Loss 1.45359 Test MSE 5.469807149421517 Test RE 1.1178771204593356\n",
      "127 Train Loss 1.4452314 Test MSE 5.4482997317375235 Test RE 1.1156771954760984\n",
      "128 Train Loss 1.4389477 Test MSE 5.460728128021011 Test RE 1.1169489848730487\n",
      "129 Train Loss 1.4333392 Test MSE 5.456939462706273 Test RE 1.1165614467983171\n",
      "130 Train Loss 1.4289565 Test MSE 5.454928153841953 Test RE 1.116355657736279\n",
      "131 Train Loss 1.4222858 Test MSE 5.457910461502699 Test RE 1.1166607819296104\n",
      "132 Train Loss 1.4121189 Test MSE 5.434006036358078 Test RE 1.1142127364798373\n",
      "133 Train Loss 1.4044851 Test MSE 5.4600050147427 Test RE 1.116875028858082\n",
      "134 Train Loss 1.393853 Test MSE 5.450060126374622 Test RE 1.1158574235862302\n",
      "135 Train Loss 1.3887591 Test MSE 5.447164789251315 Test RE 1.1155609853314903\n",
      "136 Train Loss 1.3838103 Test MSE 5.451647216675727 Test RE 1.1160198839575908\n",
      "137 Train Loss 1.379245 Test MSE 5.448075543691199 Test RE 1.1156542411530834\n",
      "138 Train Loss 1.3743563 Test MSE 5.443321727364478 Test RE 1.1151673928384533\n",
      "139 Train Loss 1.3697927 Test MSE 5.468423506185812 Test RE 1.117735722334842\n",
      "140 Train Loss 1.3639197 Test MSE 5.45497260717504 Test RE 1.1163602064331084\n",
      "141 Train Loss 1.3562531 Test MSE 5.466264391711109 Test RE 1.1175150410328292\n",
      "142 Train Loss 1.3479801 Test MSE 5.450081032970068 Test RE 1.1158595638155873\n",
      "143 Train Loss 1.3358229 Test MSE 5.475638884871843 Test RE 1.11847288432711\n",
      "144 Train Loss 1.3280675 Test MSE 5.45033004659942 Test RE 1.115885055277487\n",
      "145 Train Loss 1.3188583 Test MSE 5.471038489591347 Test RE 1.118002939296017\n",
      "146 Train Loss 1.3137466 Test MSE 5.4815751831759085 Test RE 1.1190790044765817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 Train Loss 1.3099279 Test MSE 5.47742846598352 Test RE 1.1186556424009124\n",
      "148 Train Loss 1.301672 Test MSE 5.471013715230156 Test RE 1.118000407981346\n",
      "149 Train Loss 1.292816 Test MSE 5.503107066325238 Test RE 1.1212747476234821\n",
      "Training time: 299.63\n",
      "4\n",
      "KG_rowdy_tune59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 58.72503 Test MSE 8.031256242538962 Test RE 1.3545648493386369\n",
      "1 Train Loss 49.764713 Test MSE 7.281513050555702 Test RE 1.28978961674694\n",
      "2 Train Loss 40.722664 Test MSE 6.624007003784209 Test RE 1.230179404265412\n",
      "3 Train Loss 33.85424 Test MSE 7.2262342656834635 Test RE 1.2848844661324035\n",
      "4 Train Loss 29.024065 Test MSE 7.1481593007888735 Test RE 1.277924426768292\n",
      "5 Train Loss 21.973015 Test MSE 5.3744175795421 Test RE 1.1080867551039224\n",
      "6 Train Loss 18.987629 Test MSE 5.038337762566052 Test RE 1.0728813588895891\n",
      "7 Train Loss 17.07465 Test MSE 4.62555910139237 Test RE 1.027993047511433\n",
      "8 Train Loss 15.645733 Test MSE 4.651473822307965 Test RE 1.0308686938498435\n",
      "9 Train Loss 12.469263 Test MSE 4.235808874318954 Test RE 0.9837307300891334\n",
      "10 Train Loss 11.108894 Test MSE 4.186101128958787 Test RE 0.9779415945140111\n",
      "11 Train Loss 10.422701 Test MSE 4.098909362484827 Test RE 0.967703290522422\n",
      "12 Train Loss 9.383135 Test MSE 4.034040335416506 Test RE 0.9600153527876316\n",
      "13 Train Loss 8.587788 Test MSE 3.833126666565762 Test RE 0.9358034580728664\n",
      "14 Train Loss 8.11057 Test MSE 3.7547396616047397 Test RE 0.9261854953052858\n",
      "15 Train Loss 7.727046 Test MSE 3.8345556447141473 Test RE 0.9359778741830407\n",
      "16 Train Loss 7.416309 Test MSE 3.818295815381094 Test RE 0.9339913326544209\n",
      "17 Train Loss 7.1845193 Test MSE 3.6466363948270306 Test RE 0.9127551485088946\n",
      "18 Train Loss 6.958497 Test MSE 3.7098469586012635 Test RE 0.9206319809326298\n",
      "19 Train Loss 6.6342053 Test MSE 3.618441170632589 Test RE 0.9092196610208401\n",
      "20 Train Loss 6.174821 Test MSE 3.4929374180879305 Test RE 0.8933126059660245\n",
      "21 Train Loss 5.741357 Test MSE 3.312160433238677 Test RE 0.8698888068976862\n",
      "22 Train Loss 5.577477 Test MSE 3.3832433209706325 Test RE 0.8791736775610935\n",
      "23 Train Loss 5.173029 Test MSE 3.309083120337536 Test RE 0.8694846081625239\n",
      "24 Train Loss 4.8218136 Test MSE 3.2514387760508447 Test RE 0.861878110039919\n",
      "25 Train Loss 4.660017 Test MSE 3.253842909499217 Test RE 0.8621966900981232\n",
      "26 Train Loss 4.434271 Test MSE 3.2209627992763825 Test RE 0.8578293767133452\n",
      "27 Train Loss 4.1677823 Test MSE 3.187023772356253 Test RE 0.8532979686291459\n",
      "28 Train Loss 4.059311 Test MSE 3.234904227674486 Test RE 0.8596838616067695\n",
      "29 Train Loss 3.7963471 Test MSE 2.981221766577298 Test RE 0.8252873760512266\n",
      "30 Train Loss 3.627274 Test MSE 2.8593876278778914 Test RE 0.8082478855659495\n",
      "31 Train Loss 3.456134 Test MSE 2.507214233001397 Test RE 0.756839486796066\n",
      "32 Train Loss 3.2674024 Test MSE 2.4275879496444897 Test RE 0.7447243375413853\n",
      "33 Train Loss 3.087851 Test MSE 2.406660227275128 Test RE 0.7415073337404465\n",
      "34 Train Loss 2.893655 Test MSE 2.320487851638381 Test RE 0.7281111971522882\n",
      "35 Train Loss 2.8400238 Test MSE 2.279403151805645 Test RE 0.7216367343340082\n",
      "36 Train Loss 2.7242641 Test MSE 2.282702658197037 Test RE 0.7221588411801266\n",
      "37 Train Loss 2.5760052 Test MSE 2.2067853226873377 Test RE 0.710048646134798\n",
      "38 Train Loss 2.4823933 Test MSE 2.121360405678891 Test RE 0.6961699764012804\n",
      "39 Train Loss 2.3700013 Test MSE 2.083108696519686 Test RE 0.6898648642147309\n",
      "40 Train Loss 2.2573743 Test MSE 2.0279243869503767 Test RE 0.6806658143622786\n",
      "41 Train Loss 2.184416 Test MSE 1.992176688505047 Test RE 0.6746398445094117\n",
      "42 Train Loss 2.0316591 Test MSE 1.852623670571307 Test RE 0.6505814327657525\n",
      "43 Train Loss 1.9975437 Test MSE 1.7795806041363738 Test RE 0.6376272838808092\n",
      "44 Train Loss 1.9575773 Test MSE 1.7509316238547032 Test RE 0.6324739658445064\n",
      "45 Train Loss 1.7971218 Test MSE 1.4386014797151252 Test RE 0.5732952079481644\n",
      "46 Train Loss 1.6944395 Test MSE 1.3022360508220665 Test RE 0.5454474519900355\n",
      "47 Train Loss 1.6366713 Test MSE 1.3158968703050127 Test RE 0.5483009360254253\n",
      "48 Train Loss 1.5839288 Test MSE 1.2963506039917678 Test RE 0.5442134831882991\n",
      "49 Train Loss 1.5279224 Test MSE 1.2608406077895418 Test RE 0.5367081054357138\n",
      "50 Train Loss 1.4957755 Test MSE 1.2396832045116082 Test RE 0.5321859673889924\n",
      "51 Train Loss 1.4239168 Test MSE 1.166557845429757 Test RE 0.5162513491893523\n",
      "52 Train Loss 1.3496082 Test MSE 1.115950590781497 Test RE 0.5049292661276448\n",
      "53 Train Loss 1.2701308 Test MSE 1.0405524307770888 Test RE 0.48757344496586663\n",
      "54 Train Loss 1.1555192 Test MSE 0.8694942914588762 Test RE 0.4456987620404109\n",
      "55 Train Loss 1.0809225 Test MSE 0.8743610314420884 Test RE 0.4469443557412991\n",
      "56 Train Loss 1.0367353 Test MSE 0.8066643895253547 Test RE 0.429293687926034\n",
      "57 Train Loss 1.0059465 Test MSE 0.8178916181899656 Test RE 0.4322708390395771\n",
      "58 Train Loss 0.95442086 Test MSE 0.830304472669745 Test RE 0.43553869846248466\n",
      "59 Train Loss 0.92160314 Test MSE 0.7657264326001887 Test RE 0.41825860034035467\n",
      "60 Train Loss 0.8905836 Test MSE 0.7317250655405589 Test RE 0.40886696864574446\n",
      "61 Train Loss 0.8479802 Test MSE 0.6728309810002188 Test RE 0.3920676870327427\n",
      "62 Train Loss 0.8001948 Test MSE 0.638379525991649 Test RE 0.3818981330210282\n",
      "63 Train Loss 0.7522948 Test MSE 0.5693027290734356 Test RE 0.36064481535011456\n",
      "64 Train Loss 0.7181462 Test MSE 0.5448125508299669 Test RE 0.3528024661015926\n",
      "65 Train Loss 0.64935094 Test MSE 0.44502896976545664 Test RE 0.31886158585410085\n",
      "66 Train Loss 0.5917589 Test MSE 0.3656659194412623 Test RE 0.28903491160831657\n",
      "67 Train Loss 0.56453145 Test MSE 0.34300565057680854 Test RE 0.27993596446225316\n",
      "68 Train Loss 0.5298376 Test MSE 0.2724101941636606 Test RE 0.24947081058365778\n",
      "69 Train Loss 0.4750875 Test MSE 0.25884232746999886 Test RE 0.24317879852985136\n",
      "70 Train Loss 0.45146278 Test MSE 0.2597142097859027 Test RE 0.24358801492775306\n",
      "71 Train Loss 0.43054998 Test MSE 0.1894746060125119 Test RE 0.20805759144487992\n",
      "72 Train Loss 0.41341537 Test MSE 0.16696138060143312 Test RE 0.19530621965592324\n",
      "73 Train Loss 0.39072824 Test MSE 0.15125443448802461 Test RE 0.1858926071149764\n",
      "74 Train Loss 0.3476296 Test MSE 0.17821473168178567 Test RE 0.20178080988035088\n",
      "75 Train Loss 0.31150797 Test MSE 0.17262681422808768 Test RE 0.19859220057655938\n",
      "76 Train Loss 0.29120034 Test MSE 0.15486679086181487 Test RE 0.18809931318392373\n",
      "77 Train Loss 0.27797872 Test MSE 0.14956540453626158 Test RE 0.1848517793050124\n",
      "78 Train Loss 0.27181703 Test MSE 0.14216759900438514 Test RE 0.18022223645432256\n",
      "79 Train Loss 0.2633455 Test MSE 0.1354522245865084 Test RE 0.17591429464544855\n",
      "80 Train Loss 0.25931886 Test MSE 0.14237631172574688 Test RE 0.18035447783180922\n",
      "81 Train Loss 0.25039306 Test MSE 0.1505116369286468 Test RE 0.1854355940087161\n",
      "82 Train Loss 0.2450364 Test MSE 0.14871455124715996 Test RE 0.18432523350716562\n",
      "83 Train Loss 0.23164989 Test MSE 0.1511941369382386 Test RE 0.185855550396288\n",
      "84 Train Loss 0.22094844 Test MSE 0.14874198745659503 Test RE 0.18434223571858638\n",
      "85 Train Loss 0.2100872 Test MSE 0.147499534327311 Test RE 0.1835707088294875\n",
      "86 Train Loss 0.20627503 Test MSE 0.14920405605646345 Test RE 0.18462834426997063\n",
      "87 Train Loss 0.20214249 Test MSE 0.13864242056147982 Test RE 0.17797382171321605\n",
      "88 Train Loss 0.19672674 Test MSE 0.13231305581911765 Test RE 0.1738638971768214\n",
      "89 Train Loss 0.188518 Test MSE 0.11333415934009647 Test RE 0.1609120152963392\n",
      "90 Train Loss 0.18151256 Test MSE 0.09992652391860948 Test RE 0.1510944285064497\n",
      "91 Train Loss 0.1761067 Test MSE 0.08796432105213162 Test RE 0.14176249161518165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 0.17347407 Test MSE 0.08660102999954783 Test RE 0.14065966831084784\n",
      "93 Train Loss 0.1706575 Test MSE 0.08608621109532213 Test RE 0.14024095390285984\n",
      "94 Train Loss 0.16704142 Test MSE 0.08523625262503456 Test RE 0.13954691318668538\n",
      "95 Train Loss 0.16181365 Test MSE 0.07617734907299638 Test RE 0.13192314250737067\n",
      "96 Train Loss 0.15661603 Test MSE 0.07851870916453942 Test RE 0.1339351708166181\n",
      "97 Train Loss 0.15027462 Test MSE 0.06940643335394857 Test RE 0.12592382990352954\n",
      "98 Train Loss 0.14245747 Test MSE 0.059639271810565074 Test RE 0.11672778011172233\n",
      "99 Train Loss 0.13465686 Test MSE 0.05022686367540949 Test RE 0.10712136311548417\n",
      "100 Train Loss 0.12939733 Test MSE 0.040417988244333604 Test RE 0.09609380865930715\n",
      "101 Train Loss 0.12728652 Test MSE 0.03763319815594279 Test RE 0.09272431291423779\n",
      "102 Train Loss 0.12446724 Test MSE 0.03838096633290982 Test RE 0.09364099349591831\n",
      "103 Train Loss 0.1212368 Test MSE 0.032143628698460616 Test RE 0.08569500563180447\n",
      "104 Train Loss 0.11533127 Test MSE 0.028263199951688668 Test RE 0.0803560769129579\n",
      "105 Train Loss 0.11298029 Test MSE 0.028223666042673998 Test RE 0.0802998571373926\n",
      "106 Train Loss 0.11060664 Test MSE 0.032662360828745934 Test RE 0.0863837088566982\n",
      "107 Train Loss 0.10648866 Test MSE 0.027896505608674498 Test RE 0.07983309438976649\n",
      "108 Train Loss 0.102473184 Test MSE 0.027726951813186365 Test RE 0.07959011351413169\n",
      "109 Train Loss 0.099674195 Test MSE 0.02995313606689849 Test RE 0.0827235588544861\n",
      "110 Train Loss 0.09795126 Test MSE 0.027438346451500374 Test RE 0.07917480966325134\n",
      "111 Train Loss 0.095769465 Test MSE 0.025786599975809624 Test RE 0.07675472178988087\n",
      "112 Train Loss 0.08855698 Test MSE 0.021998851655511575 Test RE 0.0708937690060175\n",
      "113 Train Loss 0.08476652 Test MSE 0.01899975366597257 Test RE 0.0658843165933768\n",
      "114 Train Loss 0.08224464 Test MSE 0.019902529194162317 Test RE 0.0674314028842762\n",
      "115 Train Loss 0.080169916 Test MSE 0.02019683749101775 Test RE 0.06792814357344985\n",
      "116 Train Loss 0.0719748 Test MSE 0.019272903847154053 Test RE 0.06635621988976691\n",
      "117 Train Loss 0.06874192 Test MSE 0.017544544079702167 Test RE 0.06331098986376221\n",
      "118 Train Loss 0.06663718 Test MSE 0.017943414832865597 Test RE 0.06402662491392394\n",
      "119 Train Loss 0.065393135 Test MSE 0.016477816952556817 Test RE 0.06135612129413251\n",
      "120 Train Loss 0.064374 Test MSE 0.017164553454991915 Test RE 0.06262162238726375\n",
      "121 Train Loss 0.061364777 Test MSE 0.015176927876978457 Test RE 0.05888436491596692\n",
      "122 Train Loss 0.05922983 Test MSE 0.014896442943053229 Test RE 0.0583377062105771\n",
      "123 Train Loss 0.05809734 Test MSE 0.013379631494467144 Test RE 0.05528790533423314\n",
      "124 Train Loss 0.05625298 Test MSE 0.011866354489417962 Test RE 0.052067499235246534\n",
      "125 Train Loss 0.053840607 Test MSE 0.011490974440737463 Test RE 0.051237329908206106\n",
      "126 Train Loss 0.0525031 Test MSE 0.011421355536284343 Test RE 0.05108188155669913\n",
      "127 Train Loss 0.05180461 Test MSE 0.010831098622490829 Test RE 0.04974441357506071\n",
      "128 Train Loss 0.05122407 Test MSE 0.010452818357942114 Test RE 0.04886802215196128\n",
      "129 Train Loss 0.048931118 Test MSE 0.009867319426682232 Test RE 0.04747966587051809\n",
      "130 Train Loss 0.046448722 Test MSE 0.009363138729177701 Test RE 0.04625075103646362\n",
      "131 Train Loss 0.044518843 Test MSE 0.008522836328207354 Test RE 0.04412656632455508\n",
      "132 Train Loss 0.04345148 Test MSE 0.00860721095711381 Test RE 0.044344451144698066\n",
      "133 Train Loss 0.043111667 Test MSE 0.008465924823081773 Test RE 0.04397899129195226\n",
      "134 Train Loss 0.04274913 Test MSE 0.008703125582222308 Test RE 0.04459084326063781\n",
      "135 Train Loss 0.04200227 Test MSE 0.008401099751246551 Test RE 0.04381029030156888\n",
      "136 Train Loss 0.04095207 Test MSE 0.008909859241965551 Test RE 0.045117339476876434\n",
      "137 Train Loss 0.040007476 Test MSE 0.0092396111611195 Test RE 0.04594464578946258\n",
      "138 Train Loss 0.03793655 Test MSE 0.008863987136786398 Test RE 0.0450010470632422\n",
      "139 Train Loss 0.036262825 Test MSE 0.008232180205219474 Test RE 0.04336761058983061\n",
      "140 Train Loss 0.03563944 Test MSE 0.008627406003565997 Test RE 0.04439644322271226\n",
      "141 Train Loss 0.03525882 Test MSE 0.008587261272605057 Test RE 0.04429303082854968\n",
      "142 Train Loss 0.034632973 Test MSE 0.008804968978838425 Test RE 0.04485098397755447\n",
      "143 Train Loss 0.03394867 Test MSE 0.008332108092782361 Test RE 0.043630029637158375\n",
      "144 Train Loss 0.033010863 Test MSE 0.0074047502703576875 Test RE 0.041130431754539856\n",
      "145 Train Loss 0.032733735 Test MSE 0.007774618578360542 Test RE 0.04214515022257475\n",
      "146 Train Loss 0.031698275 Test MSE 0.007453873742858476 Test RE 0.041266636869877145\n",
      "147 Train Loss 0.03123345 Test MSE 0.006925788951088507 Test RE 0.039777976502571574\n",
      "148 Train Loss 0.0309619 Test MSE 0.0070514947285639715 Test RE 0.04013734607439817\n",
      "149 Train Loss 0.030555304 Test MSE 0.006995639997010461 Test RE 0.039978066525973875\n",
      "Training time: 297.26\n",
      "5\n",
      "KG_rowdy_tune59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 68.56989 Test MSE 4.738632025629383 Test RE 1.0404819555424856\n",
      "1 Train Loss 50.326538 Test MSE 5.427230154136083 Test RE 1.1135178412938145\n",
      "2 Train Loss 33.719276 Test MSE 5.6774126512995835 Test RE 1.1388939630209336\n",
      "3 Train Loss 25.905819 Test MSE 5.534052927598245 Test RE 1.1244229844477973\n",
      "4 Train Loss 22.398434 Test MSE 5.618163889020835 Test RE 1.1329357004637397\n",
      "5 Train Loss 21.107166 Test MSE 5.690721593405499 Test RE 1.1402280743618265\n",
      "6 Train Loss 19.834126 Test MSE 5.619109706200334 Test RE 1.1330310612412906\n",
      "7 Train Loss 18.814518 Test MSE 5.468440211281146 Test RE 1.1177374295789424\n",
      "8 Train Loss 17.980055 Test MSE 5.651439112944726 Test RE 1.1362858193084504\n",
      "9 Train Loss 17.403566 Test MSE 5.728669842747157 Test RE 1.144023530067447\n",
      "10 Train Loss 17.075903 Test MSE 5.661735533397941 Test RE 1.137320454223802\n",
      "11 Train Loss 16.665617 Test MSE 5.7132487249996915 Test RE 1.1424826828160421\n",
      "12 Train Loss 16.392365 Test MSE 5.600962033357613 Test RE 1.1311999432530218\n",
      "13 Train Loss 16.125568 Test MSE 5.764339948051319 Test RE 1.1475796883955127\n",
      "14 Train Loss 15.632612 Test MSE 5.775863483656762 Test RE 1.148726183308989\n",
      "15 Train Loss 15.213764 Test MSE 5.851443655691483 Test RE 1.1562175949248992\n",
      "16 Train Loss 14.634167 Test MSE 5.879400607282182 Test RE 1.1589763843374699\n",
      "17 Train Loss 14.471926 Test MSE 5.840414366806793 Test RE 1.155127413303204\n",
      "18 Train Loss 14.194105 Test MSE 5.811411551474614 Test RE 1.1522557298723308\n",
      "19 Train Loss 13.744158 Test MSE 5.934591452331051 Test RE 1.1644034234768506\n",
      "20 Train Loss 13.649852 Test MSE 5.9941912932467005 Test RE 1.1702357449457723\n",
      "21 Train Loss 13.044053 Test MSE 5.881810301915814 Test RE 1.1592138654398143\n",
      "22 Train Loss 12.758947 Test MSE 5.8191815179348945 Test RE 1.153025766352794\n",
      "23 Train Loss 12.359298 Test MSE 5.743761382438632 Test RE 1.1455294399217764\n",
      "24 Train Loss 11.705075 Test MSE 5.543540896171816 Test RE 1.1253864664828577\n",
      "25 Train Loss 11.522446 Test MSE 5.581222346278251 Test RE 1.1292048179758094\n",
      "26 Train Loss 11.376112 Test MSE 5.682872003434166 Test RE 1.1394414068641572\n",
      "27 Train Loss 10.971218 Test MSE 5.660094753766062 Test RE 1.1371556436772925\n",
      "28 Train Loss 10.752567 Test MSE 5.705042408170782 Test RE 1.1416618762637865\n",
      "29 Train Loss 10.555392 Test MSE 5.7105006594435075 Test RE 1.1422078833902554\n",
      "30 Train Loss 10.091213 Test MSE 5.407414230871277 Test RE 1.1114831420432372\n",
      "31 Train Loss 9.856601 Test MSE 5.397422266614569 Test RE 1.110455753115471\n",
      "32 Train Loss 9.52043 Test MSE 5.218719116342668 Test RE 1.0919179908545844\n",
      "33 Train Loss 9.108535 Test MSE 5.1090404817620305 Test RE 1.0803829759441363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 8.832798 Test MSE 5.168833920881256 Test RE 1.0866866939948452\n",
      "35 Train Loss 8.593654 Test MSE 5.179885315025257 Test RE 1.0878477866831944\n",
      "36 Train Loss 8.521881 Test MSE 5.138878719937079 Test RE 1.083533253743313\n",
      "37 Train Loss 8.323948 Test MSE 5.133473997874661 Test RE 1.0829633106683498\n",
      "38 Train Loss 8.112629 Test MSE 5.114678193631378 Test RE 1.080978900813538\n",
      "39 Train Loss 7.7940264 Test MSE 5.057447101890575 Test RE 1.0749140382878044\n",
      "40 Train Loss 7.724372 Test MSE 5.081684428263103 Test RE 1.0774866705115829\n",
      "41 Train Loss 7.470355 Test MSE 5.077241148469814 Test RE 1.077015505703371\n",
      "42 Train Loss 7.3654385 Test MSE 5.004959823806822 Test RE 1.069321645681917\n",
      "43 Train Loss 7.19275 Test MSE 5.048029123228795 Test RE 1.0739127193744198\n",
      "44 Train Loss 7.0420218 Test MSE 5.113476896884442 Test RE 1.0808519473037776\n",
      "45 Train Loss 6.972274 Test MSE 5.0989529216074905 Test RE 1.07931586625645\n",
      "46 Train Loss 6.874194 Test MSE 5.025542615416499 Test RE 1.071518171053959\n",
      "47 Train Loss 6.7301846 Test MSE 4.9358505338522605 Test RE 1.0619133002731904\n",
      "48 Train Loss 6.6584096 Test MSE 4.881208551487622 Test RE 1.0560190239908944\n",
      "49 Train Loss 6.552806 Test MSE 4.882988651672035 Test RE 1.0562115632243219\n",
      "50 Train Loss 6.329117 Test MSE 4.733889278905635 Test RE 1.0399611324722182\n",
      "51 Train Loss 6.229927 Test MSE 4.721204535826761 Test RE 1.0385668784235282\n",
      "52 Train Loss 6.0688114 Test MSE 4.643157471061381 Test RE 1.0299467385898784\n",
      "53 Train Loss 5.817279 Test MSE 4.548776809705327 Test RE 1.0194252219365314\n",
      "54 Train Loss 5.1594515 Test MSE 4.090382594990286 Test RE 0.9666962327979594\n",
      "55 Train Loss 4.794892 Test MSE 3.884374293402805 Test RE 0.9420383778396401\n",
      "56 Train Loss 4.45893 Test MSE 3.7372667049116566 Test RE 0.9240279461979019\n",
      "57 Train Loss 4.061974 Test MSE 3.7656032388182914 Test RE 0.9275243924320072\n",
      "58 Train Loss 3.8258553 Test MSE 3.469972720940872 Test RE 0.8903711728323144\n",
      "59 Train Loss 3.7060513 Test MSE 3.30150387626331 Test RE 0.8684882877821658\n",
      "60 Train Loss 3.509975 Test MSE 3.303862611465534 Test RE 0.8687984749293752\n",
      "61 Train Loss 3.2411509 Test MSE 3.239324419525616 Test RE 0.8602709996089997\n",
      "62 Train Loss 3.1831381 Test MSE 3.284582039481155 Test RE 0.8662597129238577\n",
      "63 Train Loss 3.0470672 Test MSE 3.3259821068971056 Test RE 0.8717019440026849\n",
      "64 Train Loss 2.9296114 Test MSE 3.251968520477077 Test RE 0.8619483184247049\n",
      "65 Train Loss 2.845411 Test MSE 3.321599115222172 Test RE 0.8711273886094812\n",
      "66 Train Loss 2.7447958 Test MSE 3.342755337845908 Test RE 0.8738972159265969\n",
      "67 Train Loss 2.6949654 Test MSE 3.3548062381768875 Test RE 0.875471033445013\n",
      "68 Train Loss 2.6141055 Test MSE 3.3379953719003224 Test RE 0.8732747948328413\n",
      "69 Train Loss 2.550573 Test MSE 3.2862827447989926 Test RE 0.8664839517806225\n",
      "70 Train Loss 2.4576666 Test MSE 3.2550734252903775 Test RE 0.8623597044760994\n",
      "71 Train Loss 2.407835 Test MSE 3.2278379300055207 Test RE 0.8587444051818611\n",
      "72 Train Loss 2.349881 Test MSE 3.150435187648858 Test RE 0.8483856910145717\n",
      "73 Train Loss 2.323665 Test MSE 3.175348500688288 Test RE 0.8517335582030947\n",
      "74 Train Loss 2.2754886 Test MSE 3.1828848404493595 Test RE 0.8527437070611618\n",
      "75 Train Loss 2.2236466 Test MSE 3.2178155206564436 Test RE 0.8574101716395859\n",
      "76 Train Loss 2.210296 Test MSE 3.2395293515291046 Test RE 0.8602982111890151\n",
      "77 Train Loss 2.1850383 Test MSE 3.256936349489564 Test RE 0.8626064394587853\n",
      "78 Train Loss 2.1543624 Test MSE 3.2690452500306963 Test RE 0.8642084856689846\n",
      "79 Train Loss 2.1195111 Test MSE 3.2358732653825384 Test RE 0.8598126140584581\n",
      "80 Train Loss 2.1037302 Test MSE 3.2271725711925883 Test RE 0.8586558935189522\n",
      "81 Train Loss 2.0756335 Test MSE 3.2309697619452087 Test RE 0.8591609055093394\n",
      "82 Train Loss 2.0429661 Test MSE 3.2324984366204728 Test RE 0.8593641296651726\n",
      "83 Train Loss 2.0046408 Test MSE 3.2338173582408354 Test RE 0.8595394303436513\n",
      "84 Train Loss 1.9914638 Test MSE 3.248474823514031 Test RE 0.8614851842575011\n",
      "85 Train Loss 1.9779773 Test MSE 3.2862378706567172 Test RE 0.8664780358476537\n",
      "86 Train Loss 1.966302 Test MSE 3.3107291498886626 Test RE 0.8697008341339183\n",
      "87 Train Loss 1.9508101 Test MSE 3.330764514857437 Test RE 0.8723284261474504\n",
      "88 Train Loss 1.939924 Test MSE 3.323216172092811 Test RE 0.8713394086451213\n",
      "89 Train Loss 1.9223117 Test MSE 3.3555483790296754 Test RE 0.8755678627169193\n",
      "90 Train Loss 1.8897318 Test MSE 3.3723705122118894 Test RE 0.8777598301392764\n",
      "91 Train Loss 1.8494987 Test MSE 3.396732958036654 Test RE 0.8809246505857529\n",
      "92 Train Loss 1.8314538 Test MSE 3.3958653658978375 Test RE 0.8808121406945361\n",
      "93 Train Loss 1.8205571 Test MSE 3.396907538716343 Test RE 0.8809472885808646\n",
      "94 Train Loss 1.8103462 Test MSE 3.376507710237485 Test RE 0.8782980795905219\n",
      "95 Train Loss 1.7634084 Test MSE 3.3385106953393198 Test RE 0.873342200798557\n",
      "96 Train Loss 1.7422242 Test MSE 3.3388246479905868 Test RE 0.8733832642664597\n",
      "97 Train Loss 1.7303836 Test MSE 3.3460156181120397 Test RE 0.8743232799344371\n",
      "98 Train Loss 1.7194264 Test MSE 3.3379599359773753 Test RE 0.8732701595087882\n",
      "99 Train Loss 1.7009952 Test MSE 3.3422192120987284 Test RE 0.8738271333842369\n",
      "100 Train Loss 1.6736636 Test MSE 3.3431403297320306 Test RE 0.8739475387317049\n",
      "101 Train Loss 1.6490633 Test MSE 3.304246166700619 Test RE 0.8688489041650245\n",
      "102 Train Loss 1.6266632 Test MSE 3.287217415687345 Test RE 0.8666071639036419\n",
      "103 Train Loss 1.612627 Test MSE 3.2691935887588173 Test RE 0.8642280929432113\n",
      "104 Train Loss 1.6030902 Test MSE 3.2988767681788675 Test RE 0.86814267760638\n",
      "105 Train Loss 1.5819302 Test MSE 3.2984017401420465 Test RE 0.8680801704277749\n",
      "106 Train Loss 1.5695087 Test MSE 3.29836966232469 Test RE 0.8680759492644577\n",
      "107 Train Loss 1.5564855 Test MSE 3.317218186190119 Test RE 0.8705527246703291\n",
      "108 Train Loss 1.5352867 Test MSE 3.301526991829421 Test RE 0.868491328148624\n",
      "109 Train Loss 1.5046921 Test MSE 3.276939765365116 Test RE 0.86525135791723\n",
      "110 Train Loss 1.4809041 Test MSE 3.2875718567877357 Test RE 0.8666538831921075\n",
      "111 Train Loss 1.4642684 Test MSE 3.3045175976642818 Test RE 0.868884589710298\n",
      "112 Train Loss 1.4566588 Test MSE 3.2969870714697054 Test RE 0.8678939927540213\n",
      "113 Train Loss 1.445767 Test MSE 3.307151818590776 Test RE 0.8692308396458375\n",
      "114 Train Loss 1.4353479 Test MSE 3.3117241908465735 Test RE 0.8698315187804894\n",
      "115 Train Loss 1.4261734 Test MSE 3.312854739502767 Test RE 0.8699799766359373\n",
      "116 Train Loss 1.417165 Test MSE 3.308182545327475 Test RE 0.869366283937231\n",
      "117 Train Loss 1.4093844 Test MSE 3.3046705227245354 Test RE 0.8689046944134912\n",
      "118 Train Loss 1.3983274 Test MSE 3.3129017002875485 Test RE 0.8699861427375142\n",
      "119 Train Loss 1.3841512 Test MSE 3.3166326217056854 Test RE 0.8704758850976757\n",
      "120 Train Loss 1.3784391 Test MSE 3.315438752990564 Test RE 0.8703192009569226\n",
      "121 Train Loss 1.3706174 Test MSE 3.3040299326833504 Test RE 0.8688204744183807\n",
      "122 Train Loss 1.3624837 Test MSE 3.3115887899071486 Test RE 0.8698137369239928\n",
      "123 Train Loss 1.351548 Test MSE 3.2873994334616357 Test RE 0.866631156190085\n",
      "124 Train Loss 1.3387744 Test MSE 3.280708924991901 Test RE 0.8657488240706366\n",
      "125 Train Loss 1.3312591 Test MSE 3.2905712095404267 Test RE 0.8670491305380843\n",
      "126 Train Loss 1.3208177 Test MSE 3.3040676366423134 Test RE 0.8688254316794721\n",
      "127 Train Loss 1.3136543 Test MSE 3.291548869147351 Test RE 0.8671779251916844\n",
      "128 Train Loss 1.3063786 Test MSE 3.2712530070573385 Test RE 0.8645002589824272\n",
      "129 Train Loss 1.3023098 Test MSE 3.2645303514151083 Test RE 0.863611497629225\n",
      "130 Train Loss 1.2999853 Test MSE 3.259105817617499 Test RE 0.8628936857299176\n",
      "131 Train Loss 1.292359 Test MSE 3.2408121141351205 Test RE 0.8604685212916094\n",
      "132 Train Loss 1.2863637 Test MSE 3.241604986580922 Test RE 0.8605737726968232\n",
      "133 Train Loss 1.2732836 Test MSE 3.261626490665734 Test RE 0.8632273128929464\n",
      "134 Train Loss 1.2606839 Test MSE 3.276596111906423 Test RE 0.8652059871690333\n",
      "135 Train Loss 1.2559769 Test MSE 3.271609959967276 Test RE 0.8645474240083058\n",
      "136 Train Loss 1.2487464 Test MSE 3.2591065975480418 Test RE 0.8628937889786519\n",
      "137 Train Loss 1.2444614 Test MSE 3.263902355828215 Test RE 0.863528427442088\n",
      "138 Train Loss 1.2395822 Test MSE 3.2593773333254017 Test RE 0.8629296287651531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 Train Loss 1.2328887 Test MSE 3.243209328581417 Test RE 0.8607867048503254\n",
      "140 Train Loss 1.2247427 Test MSE 3.2330264630332763 Test RE 0.8594343150710527\n",
      "141 Train Loss 1.2139333 Test MSE 3.2305534828867737 Test RE 0.8591055564593889\n",
      "142 Train Loss 1.2087038 Test MSE 3.226184131161017 Test RE 0.8585243860091439\n",
      "143 Train Loss 1.2019928 Test MSE 3.1996463885300392 Test RE 0.8549860967606442\n",
      "144 Train Loss 1.1932812 Test MSE 3.216488503569689 Test RE 0.8572333567676497\n",
      "145 Train Loss 1.1802499 Test MSE 3.242047421417462 Test RE 0.8606324989801298\n",
      "146 Train Loss 1.175389 Test MSE 3.2258689903907647 Test RE 0.858482453708826\n",
      "147 Train Loss 1.169149 Test MSE 3.2341835262782452 Test RE 0.8595880921761649\n",
      "148 Train Loss 1.1639726 Test MSE 3.2365443555973568 Test RE 0.8599017680318868\n",
      "149 Train Loss 1.1558878 Test MSE 3.2454365902349904 Test RE 0.8610822251176621\n",
      "Training time: 299.20\n",
      "6\n",
      "KG_rowdy_tune59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 65.4246 Test MSE 7.884555250257007 Test RE 1.3421364175589499\n",
      "1 Train Loss 54.579327 Test MSE 8.02404376283579 Test RE 1.3539564783931881\n",
      "2 Train Loss 49.52804 Test MSE 8.506152719535551 Test RE 1.3940381150294974\n",
      "3 Train Loss 45.81601 Test MSE 9.363003157982812 Test RE 1.4625665791400928\n",
      "4 Train Loss 43.901672 Test MSE 9.258194405139847 Test RE 1.4543576117294033\n",
      "5 Train Loss 41.849873 Test MSE 8.920425985008965 Test RE 1.4275813226050815\n",
      "6 Train Loss 40.496223 Test MSE 8.997926355901095 Test RE 1.4337693014862756\n",
      "7 Train Loss 38.261093 Test MSE 9.410709342576252 Test RE 1.4662878648556612\n",
      "8 Train Loss 37.110126 Test MSE 9.55482339648902 Test RE 1.4774724533183077\n",
      "9 Train Loss 35.751286 Test MSE 9.63102130970462 Test RE 1.4833520364336321\n",
      "10 Train Loss 33.928524 Test MSE 9.988236215751689 Test RE 1.5106103730468943\n",
      "11 Train Loss 32.181293 Test MSE 9.402214970138727 Test RE 1.4656259590075862\n",
      "12 Train Loss 30.572187 Test MSE 9.028379978604171 Test RE 1.4361935593146642\n",
      "13 Train Loss 28.358425 Test MSE 8.701843230342568 Test RE 1.409982387326817\n",
      "14 Train Loss 25.844944 Test MSE 8.099698186705204 Test RE 1.360324370061661\n",
      "15 Train Loss 24.161905 Test MSE 8.231916103291027 Test RE 1.3713822627984646\n",
      "16 Train Loss 23.038776 Test MSE 8.257411477633621 Test RE 1.3735043005814966\n",
      "17 Train Loss 21.379421 Test MSE 8.022055557566965 Test RE 1.353788725682871\n",
      "18 Train Loss 20.567223 Test MSE 7.8144389049189655 Test RE 1.336155366597459\n",
      "19 Train Loss 19.30648 Test MSE 7.320348534992667 Test RE 1.2932245480810227\n",
      "20 Train Loss 18.525818 Test MSE 7.2977078133078495 Test RE 1.2912231262025062\n",
      "21 Train Loss 17.77713 Test MSE 7.368380022314887 Test RE 1.2974602713162655\n",
      "22 Train Loss 17.432579 Test MSE 7.389531087569453 Test RE 1.2993211282027484\n",
      "23 Train Loss 16.648386 Test MSE 6.6997584914293515 Test RE 1.237193512985536\n",
      "24 Train Loss 16.192146 Test MSE 7.033597293631486 Test RE 1.2676425544726917\n",
      "25 Train Loss 15.313021 Test MSE 6.577359067813414 Test RE 1.2258401336491587\n",
      "26 Train Loss 14.95756 Test MSE 6.3135323062214 Test RE 1.201003474513999\n",
      "27 Train Loss 13.840412 Test MSE 5.945694044508467 Test RE 1.1654921130379219\n",
      "28 Train Loss 12.234049 Test MSE 5.465602163335168 Test RE 1.1174473464856045\n",
      "29 Train Loss 11.515342 Test MSE 5.279829114218087 Test RE 1.098292438324337\n",
      "30 Train Loss 10.854484 Test MSE 5.0496428126176705 Test RE 1.074084353000823\n",
      "31 Train Loss 10.180408 Test MSE 5.080678589939661 Test RE 1.0773800295900624\n",
      "32 Train Loss 9.774109 Test MSE 4.7704077017563415 Test RE 1.0439646881978033\n",
      "33 Train Loss 9.358432 Test MSE 4.678424587035127 Test RE 1.033850820959437\n",
      "34 Train Loss 9.21266 Test MSE 4.750689410469962 Test RE 1.0418048606518833\n",
      "35 Train Loss 8.913363 Test MSE 4.799910148353298 Test RE 1.0471878969253667\n",
      "36 Train Loss 8.578809 Test MSE 4.724522406174386 Test RE 1.0389317455923965\n",
      "37 Train Loss 8.492824 Test MSE 4.723372038575752 Test RE 1.0388052538462478\n",
      "38 Train Loss 8.314072 Test MSE 4.63726955048082 Test RE 1.0292935011806503\n",
      "39 Train Loss 8.075534 Test MSE 4.65318779968511 Test RE 1.0310586038602843\n",
      "40 Train Loss 7.998459 Test MSE 4.638279327313396 Test RE 1.0294055606744577\n",
      "41 Train Loss 7.812936 Test MSE 4.46608499466723 Test RE 1.0101167023235982\n",
      "42 Train Loss 7.327731 Test MSE 4.432155705529379 Test RE 1.0062724088195651\n",
      "43 Train Loss 7.1940145 Test MSE 4.44286475928362 Test RE 1.0074873620452895\n",
      "44 Train Loss 6.9919257 Test MSE 4.363136881172551 Test RE 0.9984066827592213\n",
      "45 Train Loss 6.749042 Test MSE 4.122210056712382 Test RE 0.9704498997883875\n",
      "46 Train Loss 5.3909163 Test MSE 2.781318345017601 Test RE 0.7971378123510893\n",
      "47 Train Loss 4.5422454 Test MSE 2.4907287913010956 Test RE 0.7543471967070235\n",
      "48 Train Loss 3.970454 Test MSE 2.4784084707196006 Test RE 0.7524792051540504\n",
      "49 Train Loss 3.4031663 Test MSE 2.523588268504529 Test RE 0.7593068366341262\n",
      "50 Train Loss 3.043912 Test MSE 2.4243132016648836 Test RE 0.7442218619177416\n",
      "51 Train Loss 2.857677 Test MSE 2.307985282115354 Test RE 0.7261470507167427\n",
      "52 Train Loss 2.6614907 Test MSE 2.3337434166049675 Test RE 0.7301878684746963\n",
      "53 Train Loss 2.5892575 Test MSE 2.2934062931548613 Test RE 0.723849969143389\n",
      "54 Train Loss 2.5194817 Test MSE 2.3341494089784263 Test RE 0.730251379701275\n",
      "55 Train Loss 2.3770545 Test MSE 2.317694429120678 Test RE 0.7276728120312679\n",
      "56 Train Loss 2.311286 Test MSE 2.3935683610952747 Test RE 0.7394877397758647\n",
      "57 Train Loss 2.2463527 Test MSE 2.409184728736417 Test RE 0.7418961392903368\n",
      "58 Train Loss 2.2054033 Test MSE 2.4143271290050836 Test RE 0.7426875051796118\n",
      "59 Train Loss 2.1729283 Test MSE 2.398677599748334 Test RE 0.7402765631359414\n",
      "60 Train Loss 2.0996852 Test MSE 2.397840532386758 Test RE 0.740147384579411\n",
      "61 Train Loss 2.0791976 Test MSE 2.3907475842318338 Test RE 0.7390518748845387\n",
      "62 Train Loss 2.052997 Test MSE 2.38320435957701 Test RE 0.7378850351259835\n",
      "63 Train Loss 2.0221958 Test MSE 2.404401954929023 Test RE 0.7411593580496132\n",
      "64 Train Loss 1.9599509 Test MSE 2.391810035738016 Test RE 0.7392160744774677\n",
      "65 Train Loss 1.9101801 Test MSE 2.385635999891964 Test RE 0.738261380012431\n",
      "66 Train Loss 1.8823537 Test MSE 2.391349860323937 Test RE 0.7391449598359462\n",
      "67 Train Loss 1.8496464 Test MSE 2.4080369517021754 Test RE 0.7417193921971139\n",
      "68 Train Loss 1.8413153 Test MSE 2.4102982867229263 Test RE 0.7420675767312841\n",
      "69 Train Loss 1.8107984 Test MSE 2.432957918862884 Test RE 0.7455475698416468\n",
      "70 Train Loss 1.7785025 Test MSE 2.426500219642869 Test RE 0.7445574744281096\n",
      "71 Train Loss 1.7592354 Test MSE 2.404188688647445 Test RE 0.7411264875461631\n",
      "72 Train Loss 1.6953931 Test MSE 2.4142795032500275 Test RE 0.7426801799030954\n",
      "73 Train Loss 1.6907666 Test MSE 2.4226428193331535 Test RE 0.7439654286202803\n",
      "74 Train Loss 1.6720865 Test MSE 2.4244043899728487 Test RE 0.7442358583960311\n",
      "75 Train Loss 1.6522546 Test MSE 2.4045753400257777 Test RE 0.7411860806344406\n",
      "76 Train Loss 1.6433733 Test MSE 2.4079678261567086 Test RE 0.7417087461550148\n",
      "77 Train Loss 1.6097838 Test MSE 2.4324276370558024 Test RE 0.7454663165132827\n",
      "78 Train Loss 1.5905912 Test MSE 2.395194993377031 Test RE 0.7397389693531483\n",
      "79 Train Loss 1.5867276 Test MSE 2.4026513111518435 Test RE 0.7408894900519213\n",
      "80 Train Loss 1.5734158 Test MSE 2.3870603365002743 Test RE 0.7384817354655151\n",
      "81 Train Loss 1.5495119 Test MSE 2.345513024164963 Test RE 0.7320268059559122\n",
      "82 Train Loss 1.5450463 Test MSE 2.3333132370584213 Test RE 0.7301205675108594\n",
      "83 Train Loss 1.5387264 Test MSE 2.3288953782668225 Test RE 0.729429040592243\n",
      "84 Train Loss 1.51605 Test MSE 2.3399163511921546 Test RE 0.7311529328523497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 Train Loss 1.499988 Test MSE 2.3388453877196427 Test RE 0.730985591891253\n",
      "86 Train Loss 1.4956286 Test MSE 2.3374407051460633 Test RE 0.7307660483195548\n",
      "87 Train Loss 1.4929271 Test MSE 2.333831920839453 Test RE 0.7302017140639714\n",
      "88 Train Loss 1.4836771 Test MSE 2.3393346343137162 Test RE 0.7310620427572105\n",
      "89 Train Loss 1.464439 Test MSE 2.3408830167809227 Test RE 0.731303944105124\n",
      "90 Train Loss 1.4473536 Test MSE 2.359674319644923 Test RE 0.7342333270250153\n",
      "91 Train Loss 1.4386122 Test MSE 2.35784306303024 Test RE 0.7339483659618091\n",
      "92 Train Loss 1.4351989 Test MSE 2.3643887718526093 Test RE 0.7349664325784999\n",
      "93 Train Loss 1.424026 Test MSE 2.3505722142869203 Test RE 0.7328158588919464\n",
      "94 Train Loss 1.3868728 Test MSE 2.358758995818302 Test RE 0.7340909077006297\n",
      "95 Train Loss 1.3695124 Test MSE 2.3667379604278356 Test RE 0.7353314626681637\n",
      "96 Train Loss 1.3670641 Test MSE 2.3643481235364145 Test RE 0.7349601148196137\n",
      "97 Train Loss 1.3663654 Test MSE 2.360089353029438 Test RE 0.7342978948219132\n",
      "98 Train Loss 1.3630708 Test MSE 2.358886650191703 Test RE 0.7341107716729907\n",
      "99 Train Loss 1.3474126 Test MSE 2.3624770056071682 Test RE 0.7346692377654004\n",
      "100 Train Loss 1.330151 Test MSE 2.3972989652420806 Test RE 0.7400637964225109\n",
      "101 Train Loss 1.3236712 Test MSE 2.3831044191297046 Test RE 0.7378695632397149\n",
      "102 Train Loss 1.3200567 Test MSE 2.3807105137835656 Test RE 0.7374988632192129\n",
      "103 Train Loss 1.3189496 Test MSE 2.3782021859689144 Test RE 0.7371102446910567\n",
      "104 Train Loss 1.3128325 Test MSE 2.3831769896866954 Test RE 0.7378807979965949\n",
      "105 Train Loss 1.2868934 Test MSE 2.364709945482232 Test RE 0.7350163490355478\n",
      "106 Train Loss 1.274342 Test MSE 2.382989808308874 Test RE 0.7378518198180595\n",
      "107 Train Loss 1.267096 Test MSE 2.393685371357543 Test RE 0.7395058145879996\n",
      "108 Train Loss 1.260931 Test MSE 2.396660892746124 Test RE 0.7399653010353507\n",
      "109 Train Loss 1.2550484 Test MSE 2.392261296258138 Test RE 0.7392858047847961\n",
      "110 Train Loss 1.2509674 Test MSE 2.391260204131975 Test RE 0.7391311037405552\n",
      "111 Train Loss 1.247657 Test MSE 2.3990360821308534 Test RE 0.7403318782378396\n",
      "112 Train Loss 1.2412852 Test MSE 2.404088178107807 Test RE 0.7411109954589318\n",
      "113 Train Loss 1.2315612 Test MSE 2.400075822086257 Test RE 0.7404922904249152\n",
      "114 Train Loss 1.225325 Test MSE 2.410740697229454 Test RE 0.7421356768977416\n",
      "115 Train Loss 1.2221203 Test MSE 2.412321497006954 Test RE 0.742378958071939\n",
      "116 Train Loss 1.2200894 Test MSE 2.413503665225993 Test RE 0.7425608387454304\n",
      "117 Train Loss 1.2141875 Test MSE 2.4240671082225678 Test RE 0.7441840877621945\n",
      "118 Train Loss 1.2084308 Test MSE 2.426458713693142 Test RE 0.7445511064712874\n",
      "119 Train Loss 1.2036943 Test MSE 2.420470179030033 Test RE 0.7436317575119357\n",
      "120 Train Loss 1.1955774 Test MSE 2.4138092581966197 Test RE 0.7426078480359538\n",
      "121 Train Loss 1.1920136 Test MSE 2.4233724525098594 Test RE 0.7440774511169778\n",
      "122 Train Loss 1.1882418 Test MSE 2.438338400655834 Test RE 0.7463715030752394\n",
      "123 Train Loss 1.181565 Test MSE 2.451240586917122 Test RE 0.7483435671181623\n",
      "124 Train Loss 1.1760945 Test MSE 2.4408932175049034 Test RE 0.7467624133914224\n",
      "125 Train Loss 1.1721497 Test MSE 2.4354979834172656 Test RE 0.7459366528015434\n",
      "126 Train Loss 1.1645013 Test MSE 2.4374584448836503 Test RE 0.7462368143918441\n",
      "127 Train Loss 1.156822 Test MSE 2.421296407488105 Test RE 0.7437586661808381\n",
      "128 Train Loss 1.1440974 Test MSE 2.439448137655274 Test RE 0.7465413281192569\n",
      "129 Train Loss 1.1223037 Test MSE 2.436246123770863 Test RE 0.7460512130402932\n",
      "130 Train Loss 1.116082 Test MSE 2.4274950105080406 Test RE 0.7447100816831569\n",
      "131 Train Loss 1.1094675 Test MSE 2.439496868249033 Test RE 0.7465487845640048\n",
      "132 Train Loss 1.1048136 Test MSE 2.427076251966274 Test RE 0.7446458452672533\n",
      "133 Train Loss 1.1007607 Test MSE 2.427531829695432 Test RE 0.744715729380878\n",
      "134 Train Loss 1.0975146 Test MSE 2.42958202240798 Test RE 0.7450301410208037\n",
      "135 Train Loss 1.0937483 Test MSE 2.4293988635718007 Test RE 0.7450020577076677\n",
      "136 Train Loss 1.0835401 Test MSE 2.424842009915132 Test RE 0.7443030249460288\n",
      "137 Train Loss 1.0788658 Test MSE 2.4369077630154043 Test RE 0.7461525129964903\n",
      "138 Train Loss 1.0748574 Test MSE 2.434425575378842 Test RE 0.7457724078408472\n",
      "139 Train Loss 1.0659126 Test MSE 2.4259911631983675 Test RE 0.7444793698274055\n",
      "140 Train Loss 1.0563157 Test MSE 2.444999046945846 Test RE 0.7473902144766463\n",
      "141 Train Loss 1.0512322 Test MSE 2.440630097096979 Test RE 0.7467221630181339\n",
      "142 Train Loss 1.0481427 Test MSE 2.4459493591528454 Test RE 0.7475354466483821\n",
      "143 Train Loss 1.0425979 Test MSE 2.44199101020126 Test RE 0.7469303228605715\n",
      "144 Train Loss 1.0353557 Test MSE 2.4419913126777817 Test RE 0.7469303691197258\n",
      "145 Train Loss 1.0290234 Test MSE 2.4383070822912765 Test RE 0.7463667098090788\n",
      "146 Train Loss 1.0227814 Test MSE 2.422349589701711 Test RE 0.7439204035533905\n",
      "147 Train Loss 1.0168809 Test MSE 2.4303967772109214 Test RE 0.7451550526307502\n",
      "148 Train Loss 1.0107318 Test MSE 2.434371081004942 Test RE 0.7457640607736203\n",
      "149 Train Loss 1.0082991 Test MSE 2.437298275687037 Test RE 0.7462122957964827\n",
      "Training time: 295.87\n",
      "7\n",
      "KG_rowdy_tune59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 63.13749 Test MSE 5.5833673516995415 Test RE 1.129421788168652\n",
      "1 Train Loss 44.35419 Test MSE 7.670680675011823 Test RE 1.3238080331609439\n",
      "2 Train Loss 37.88482 Test MSE 8.15211155323246 Test RE 1.3647186206330226\n",
      "3 Train Loss 33.366436 Test MSE 7.592928145370979 Test RE 1.3170816688615545\n",
      "4 Train Loss 29.108242 Test MSE 6.956261199266422 Test RE 1.2606542744963338\n",
      "5 Train Loss 26.099945 Test MSE 6.938994670006702 Test RE 1.259088731783441\n",
      "6 Train Loss 24.779667 Test MSE 6.709614442238591 Test RE 1.2381031903418849\n",
      "7 Train Loss 22.478039 Test MSE 6.090349949568242 Test RE 1.1795848448727841\n",
      "8 Train Loss 20.5736 Test MSE 6.381523031350616 Test RE 1.2074529885678702\n",
      "9 Train Loss 18.606113 Test MSE 5.952412578992493 Test RE 1.1661504203850346\n",
      "10 Train Loss 16.007421 Test MSE 5.951939917959865 Test RE 1.1661041194274706\n",
      "11 Train Loss 14.604924 Test MSE 5.999908574030207 Test RE 1.1707936994219028\n",
      "12 Train Loss 13.334914 Test MSE 6.011095648152105 Test RE 1.171884687400769\n",
      "13 Train Loss 12.680145 Test MSE 6.017542733554185 Test RE 1.1725129602133877\n",
      "14 Train Loss 12.050397 Test MSE 5.973886556944318 Test RE 1.1682520340916984\n",
      "15 Train Loss 11.677662 Test MSE 5.953422497544792 Test RE 1.166249343886931\n",
      "16 Train Loss 11.150202 Test MSE 5.7823473673457295 Test RE 1.1493707724556796\n",
      "17 Train Loss 10.721353 Test MSE 5.834390795317424 Test RE 1.1545315833593575\n",
      "18 Train Loss 10.125614 Test MSE 5.74179332946637 Test RE 1.1453331699498603\n",
      "19 Train Loss 9.548366 Test MSE 5.424595667029252 Test RE 1.113247546465686\n",
      "20 Train Loss 9.228558 Test MSE 5.355310020591819 Test RE 1.1061152219055603\n",
      "21 Train Loss 8.750393 Test MSE 5.267245384539125 Test RE 1.0969828448172412\n",
      "22 Train Loss 8.359902 Test MSE 5.073992567206921 Test RE 1.0766708960891063\n",
      "23 Train Loss 7.947753 Test MSE 4.860101008495058 Test RE 1.0537333076793456\n",
      "24 Train Loss 7.467152 Test MSE 4.792780361541885 Test RE 1.046409861413229\n",
      "25 Train Loss 7.1432667 Test MSE 4.820436426438473 Test RE 1.0494245990947955\n",
      "26 Train Loss 6.911865 Test MSE 4.877746232122752 Test RE 1.0556444319537452\n",
      "27 Train Loss 6.6174545 Test MSE 4.811122926850411 Test RE 1.048410319449087\n",
      "28 Train Loss 6.311133 Test MSE 4.716987463506578 Test RE 1.038102940666702\n",
      "29 Train Loss 5.84517 Test MSE 4.371211396575977 Test RE 0.9993300922280839\n",
      "30 Train Loss 5.5512323 Test MSE 4.1193181257873315 Test RE 0.9701094311526247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 Train Loss 5.1700273 Test MSE 4.069235957668251 Test RE 0.9641941607244378\n",
      "32 Train Loss 5.0716195 Test MSE 4.127016761329668 Test RE 0.9710155316864867\n",
      "33 Train Loss 4.7140813 Test MSE 3.941451274191622 Test RE 0.9489342922185312\n",
      "34 Train Loss 4.543724 Test MSE 3.909466956644445 Test RE 0.9450762158059838\n",
      "35 Train Loss 4.2763333 Test MSE 3.7990842806652925 Test RE 0.931638707943855\n",
      "36 Train Loss 4.1979594 Test MSE 3.6790113428209286 Test RE 0.916797929235099\n",
      "37 Train Loss 4.014579 Test MSE 3.6257398536549816 Test RE 0.9101361831878846\n",
      "38 Train Loss 3.8523355 Test MSE 3.549746079288488 Test RE 0.9005476647410978\n",
      "39 Train Loss 3.673879 Test MSE 3.3967400095361477 Test RE 0.8809255649697476\n",
      "40 Train Loss 3.5532851 Test MSE 3.3392720940716525 Test RE 0.8734417846842918\n",
      "41 Train Loss 3.4643521 Test MSE 3.312063205828763 Test RE 0.8698760391501684\n",
      "42 Train Loss 3.3752923 Test MSE 3.3116887673544917 Test RE 0.869826866739658\n",
      "43 Train Loss 3.319842 Test MSE 3.2280904720063797 Test RE 0.8587779980686926\n",
      "44 Train Loss 3.186057 Test MSE 3.191221363021267 Test RE 0.8538597179655838\n",
      "45 Train Loss 3.0908217 Test MSE 3.2070018144738865 Test RE 0.8559682641782612\n",
      "46 Train Loss 2.986499 Test MSE 3.1711712211087124 Test RE 0.8511731315107394\n",
      "47 Train Loss 2.8574975 Test MSE 3.133803641109443 Test RE 0.8461433599311508\n",
      "48 Train Loss 2.7479239 Test MSE 3.0217817810892607 Test RE 0.8308824952408584\n",
      "49 Train Loss 2.5794487 Test MSE 2.8615914849188813 Test RE 0.808559301843289\n",
      "50 Train Loss 2.494697 Test MSE 2.849517082920454 Test RE 0.8068516523722332\n",
      "51 Train Loss 2.451261 Test MSE 2.8255536859847097 Test RE 0.8034518257432225\n",
      "52 Train Loss 2.3928633 Test MSE 2.7998978858153953 Test RE 0.799795868897897\n",
      "53 Train Loss 2.2912612 Test MSE 2.7473690337221193 Test RE 0.7922578658451606\n",
      "54 Train Loss 2.2189453 Test MSE 2.6816948970652086 Test RE 0.782731376167942\n",
      "55 Train Loss 2.1419284 Test MSE 2.5466201917653897 Test RE 0.7627639329534752\n",
      "56 Train Loss 2.049245 Test MSE 2.5017003401439037 Test RE 0.7560068039101735\n",
      "57 Train Loss 2.0033934 Test MSE 2.4864082102860308 Test RE 0.7536926427409883\n",
      "58 Train Loss 1.961911 Test MSE 2.397581632053229 Test RE 0.7401074257967165\n",
      "59 Train Loss 1.8788029 Test MSE 2.408019144796733 Test RE 0.7417166497658798\n",
      "60 Train Loss 1.8441756 Test MSE 2.4028057207800635 Test RE 0.7409132968007854\n",
      "61 Train Loss 1.795781 Test MSE 2.400382442972133 Test RE 0.740539589587042\n",
      "62 Train Loss 1.7477424 Test MSE 2.3683878839367423 Test RE 0.7355877287429252\n",
      "63 Train Loss 1.698211 Test MSE 2.3804160326116657 Test RE 0.737453249473934\n",
      "64 Train Loss 1.680078 Test MSE 2.3577813730386983 Test RE 0.7339387644821015\n",
      "65 Train Loss 1.6168545 Test MSE 2.2345313772342843 Test RE 0.7144984466864708\n",
      "66 Train Loss 1.5818188 Test MSE 2.2516150580161387 Test RE 0.7172245265492779\n",
      "67 Train Loss 1.5534447 Test MSE 2.248554679895358 Test RE 0.7167369377410403\n",
      "68 Train Loss 1.5188155 Test MSE 2.225728088700484 Test RE 0.7130896181219833\n",
      "69 Train Loss 1.4917058 Test MSE 2.19093165971277 Test RE 0.7074935352555495\n",
      "70 Train Loss 1.4633996 Test MSE 2.1138427419234667 Test RE 0.6949353401994599\n",
      "71 Train Loss 1.437435 Test MSE 2.0957817009355506 Test RE 0.691960147061111\n",
      "72 Train Loss 1.4161017 Test MSE 2.06360518120727 Test RE 0.6866277716077396\n",
      "73 Train Loss 1.3937818 Test MSE 1.998737402536809 Test RE 0.6757498065526395\n",
      "74 Train Loss 1.3796253 Test MSE 1.9581885930405751 Test RE 0.6688601446944852\n",
      "75 Train Loss 1.3694636 Test MSE 1.952291557902226 Test RE 0.6678522576596784\n",
      "76 Train Loss 1.3449659 Test MSE 1.9036672558718286 Test RE 0.6594829625344869\n",
      "77 Train Loss 1.330555 Test MSE 1.844974383718684 Test RE 0.6492369526224478\n",
      "78 Train Loss 1.3183963 Test MSE 1.8241644997952267 Test RE 0.6455651241005534\n",
      "79 Train Loss 1.2968031 Test MSE 1.7812052770903903 Test RE 0.6379182792614686\n",
      "80 Train Loss 1.2819542 Test MSE 1.7189164728798987 Test RE 0.6266650109138037\n",
      "81 Train Loss 1.2430567 Test MSE 1.6265705421826981 Test RE 0.6095993730517066\n",
      "82 Train Loss 1.1874772 Test MSE 1.5386157931907936 Test RE 0.5928886729048886\n",
      "83 Train Loss 1.156892 Test MSE 1.486861328558843 Test RE 0.5828318724373163\n",
      "84 Train Loss 1.1177223 Test MSE 1.3366582853626932 Test RE 0.552609386721889\n",
      "85 Train Loss 1.0844865 Test MSE 1.1383035209837202 Test RE 0.5099611594707759\n",
      "86 Train Loss 1.0556434 Test MSE 1.0246921789249182 Test RE 0.4838433439356435\n",
      "87 Train Loss 1.0337619 Test MSE 0.8922592052324659 Test RE 0.4514956588016618\n",
      "88 Train Loss 1.003529 Test MSE 0.8015965004105409 Test RE 0.427943039070016\n",
      "89 Train Loss 0.9523808 Test MSE 0.7425635122169482 Test RE 0.4118839442013642\n",
      "90 Train Loss 0.86606646 Test MSE 0.6729720063180986 Test RE 0.39210877355728385\n",
      "91 Train Loss 0.7731546 Test MSE 0.5820106300829596 Test RE 0.3646477336645915\n",
      "92 Train Loss 0.71676296 Test MSE 0.5418641510752062 Test RE 0.35184652826739093\n",
      "93 Train Loss 0.6918377 Test MSE 0.49969948870667014 Test RE 0.33788002124331884\n",
      "94 Train Loss 0.6556577 Test MSE 0.4778228359736643 Test RE 0.3304011201853052\n",
      "95 Train Loss 0.6040261 Test MSE 0.42225724883200927 Test RE 0.3105965426658182\n",
      "96 Train Loss 0.53444207 Test MSE 0.351854384696937 Test RE 0.2835238150213972\n",
      "97 Train Loss 0.47231466 Test MSE 0.3080717644467037 Test RE 0.26529801971668715\n",
      "98 Train Loss 0.4405255 Test MSE 0.3056508750546029 Test RE 0.2642535814328457\n",
      "99 Train Loss 0.4240344 Test MSE 0.28431132912728135 Test RE 0.25486203300186655\n",
      "100 Train Loss 0.39322555 Test MSE 0.24975759007401097 Test RE 0.2388731892085979\n",
      "101 Train Loss 0.38094717 Test MSE 0.24627755669447776 Test RE 0.23720316441340725\n",
      "102 Train Loss 0.34774274 Test MSE 0.20010759538253825 Test RE 0.21381582584099593\n",
      "103 Train Loss 0.328665 Test MSE 0.21026471737943034 Test RE 0.21917512462236416\n",
      "104 Train Loss 0.30983856 Test MSE 0.2024868871503138 Test RE 0.21508321139076494\n",
      "105 Train Loss 0.27961227 Test MSE 0.17332447880381677 Test RE 0.1989930972717695\n",
      "106 Train Loss 0.2683346 Test MSE 0.1709005809477495 Test RE 0.19759676483487898\n",
      "107 Train Loss 0.25565684 Test MSE 0.15132801639667648 Test RE 0.1859378179206485\n",
      "108 Train Loss 0.23645213 Test MSE 0.14853139183913566 Test RE 0.18421168946623878\n",
      "109 Train Loss 0.22545536 Test MSE 0.12991681140874556 Test RE 0.1722823300447331\n",
      "110 Train Loss 0.20800506 Test MSE 0.11404123277262981 Test RE 0.16141318680816258\n",
      "111 Train Loss 0.19527017 Test MSE 0.10094823866314563 Test RE 0.15186490862995494\n",
      "112 Train Loss 0.19053788 Test MSE 0.09538312318561619 Test RE 0.14761953386282498\n",
      "113 Train Loss 0.17859055 Test MSE 0.09674869834582889 Test RE 0.14867249359542045\n",
      "114 Train Loss 0.1673647 Test MSE 0.09413205536545731 Test RE 0.14664823186482198\n",
      "115 Train Loss 0.16383411 Test MSE 0.09097266206588403 Test RE 0.14416622014216793\n",
      "116 Train Loss 0.1413292 Test MSE 0.08730559139602082 Test RE 0.1412306928062618\n",
      "117 Train Loss 0.1326316 Test MSE 0.0864746542221412 Test RE 0.1405569994122675\n",
      "118 Train Loss 0.12525146 Test MSE 0.08068449324487378 Test RE 0.13576977494800974\n",
      "119 Train Loss 0.12003654 Test MSE 0.08024206772439468 Test RE 0.1353970231233686\n",
      "120 Train Loss 0.11123343 Test MSE 0.07119307970548094 Test RE 0.12753428461978825\n",
      "121 Train Loss 0.110230505 Test MSE 0.07004905132134334 Test RE 0.12650543644113907\n",
      "122 Train Loss 0.106720164 Test MSE 0.06689419119614498 Test RE 0.12362384977570699\n",
      "123 Train Loss 0.09672852 Test MSE 0.06566985036055163 Test RE 0.12248730340361944\n",
      "124 Train Loss 0.09386116 Test MSE 0.0620068458299877 Test RE 0.11902217448212873\n",
      "125 Train Loss 0.09192293 Test MSE 0.05969899203048035 Test RE 0.11678620859552596\n",
      "126 Train Loss 0.08612499 Test MSE 0.05430168737728237 Test RE 0.111381925862411\n",
      "127 Train Loss 0.08160672 Test MSE 0.048999863889194924 Test RE 0.10580483082196368\n",
      "128 Train Loss 0.079533085 Test MSE 0.047591278357948054 Test RE 0.10427297045406994\n",
      "129 Train Loss 0.07859258 Test MSE 0.046480939278889834 Test RE 0.10304940963950215\n",
      "130 Train Loss 0.07635088 Test MSE 0.04268916206512634 Test RE 0.09875676959215964\n",
      "131 Train Loss 0.07527438 Test MSE 0.04156914447110164 Test RE 0.09745263883651416\n",
      "132 Train Loss 0.07318364 Test MSE 0.040099556212849836 Test RE 0.09571452389455457\n",
      "133 Train Loss 0.07047258 Test MSE 0.04195684137661386 Test RE 0.09790603282914424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 Train Loss 0.06821494 Test MSE 0.04576869383788702 Test RE 0.10225682864715797\n",
      "135 Train Loss 0.06644804 Test MSE 0.04307419587960306 Test RE 0.0992011369406092\n",
      "136 Train Loss 0.063554026 Test MSE 0.04229296075140878 Test RE 0.09829741679428058\n",
      "137 Train Loss 0.061116852 Test MSE 0.040431719316646055 Test RE 0.0961101300924971\n",
      "138 Train Loss 0.05991358 Test MSE 0.04020490149610407 Test RE 0.09584016693119918\n",
      "139 Train Loss 0.059313595 Test MSE 0.04055256269754808 Test RE 0.0962536511687631\n",
      "140 Train Loss 0.058152825 Test MSE 0.03918230530899586 Test RE 0.09461348779522992\n",
      "141 Train Loss 0.05576764 Test MSE 0.03936399957786004 Test RE 0.09483260258985987\n",
      "142 Train Loss 0.051622394 Test MSE 0.03615759459618916 Test RE 0.09088826766406993\n",
      "143 Train Loss 0.050317243 Test MSE 0.035805974131178135 Test RE 0.09044525906488804\n",
      "144 Train Loss 0.049585357 Test MSE 0.035295807832884475 Test RE 0.08979861189623323\n",
      "145 Train Loss 0.04842109 Test MSE 0.0335183726572776 Test RE 0.0875083555819444\n",
      "146 Train Loss 0.04771275 Test MSE 0.03324007404727402 Test RE 0.08714431321328457\n",
      "147 Train Loss 0.04643647 Test MSE 0.0327446115668361 Test RE 0.08649240670039414\n",
      "148 Train Loss 0.044063188 Test MSE 0.03448292911772632 Test RE 0.08875853696247149\n",
      "149 Train Loss 0.038251504 Test MSE 0.032599499447584876 Test RE 0.08630054257074374\n",
      "Training time: 297.02\n",
      "8\n",
      "KG_rowdy_tune59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 70.6755 Test MSE 5.875078380853102 Test RE 1.158550296740573\n",
      "1 Train Loss 57.96507 Test MSE 5.9694698422922015 Test RE 1.1678200883312542\n",
      "2 Train Loss 42.595955 Test MSE 6.763983277519665 Test RE 1.243109321083138\n",
      "3 Train Loss 33.03251 Test MSE 7.716610551499321 Test RE 1.327765412999937\n",
      "4 Train Loss 27.956795 Test MSE 7.663152332583392 Test RE 1.3231582520598117\n",
      "5 Train Loss 24.9609 Test MSE 7.877068426714965 Test RE 1.34149904964752\n",
      "6 Train Loss 22.926777 Test MSE 7.957292380474572 Test RE 1.3483129887762693\n",
      "7 Train Loss 21.069653 Test MSE 8.279666853019156 Test RE 1.375353989492804\n",
      "8 Train Loss 18.905193 Test MSE 8.015087225324358 Test RE 1.3532006158725738\n",
      "9 Train Loss 17.508472 Test MSE 7.85674698015372 Test RE 1.3397675167497447\n",
      "10 Train Loss 16.774202 Test MSE 7.88697342312596 Test RE 1.3423422166787808\n",
      "11 Train Loss 16.189789 Test MSE 7.839856180551438 Test RE 1.338326594673039\n",
      "12 Train Loss 14.967381 Test MSE 7.825383239899547 Test RE 1.3370907002525314\n",
      "13 Train Loss 14.30378 Test MSE 7.944867517513992 Test RE 1.3472599202207725\n",
      "14 Train Loss 13.421599 Test MSE 8.087496309346594 Test RE 1.3592993462451504\n",
      "15 Train Loss 12.473362 Test MSE 7.937548899643238 Test RE 1.3466392457872634\n",
      "16 Train Loss 11.938677 Test MSE 7.901435916323462 Test RE 1.3435723922168514\n",
      "17 Train Loss 11.090488 Test MSE 7.833441573952868 Test RE 1.3377789701270708\n",
      "18 Train Loss 10.477731 Test MSE 7.586113718554129 Test RE 1.3164905154151856\n",
      "19 Train Loss 9.654582 Test MSE 7.604293813810776 Test RE 1.3180670539188062\n",
      "20 Train Loss 9.0271435 Test MSE 7.52841989834769 Test RE 1.3114748821419144\n",
      "21 Train Loss 8.265204 Test MSE 7.334593528284635 Test RE 1.2944822082591934\n",
      "22 Train Loss 7.881212 Test MSE 7.239727910081802 Test RE 1.2860835476474164\n",
      "23 Train Loss 7.7007895 Test MSE 7.1915500566449975 Test RE 1.2817971869153615\n",
      "24 Train Loss 7.481045 Test MSE 7.22806942369224 Test RE 1.2850476089426675\n",
      "25 Train Loss 6.942095 Test MSE 7.399674031174736 Test RE 1.300212552941831\n",
      "26 Train Loss 6.5916967 Test MSE 7.4027061750765 Test RE 1.3004789179032945\n",
      "27 Train Loss 6.410556 Test MSE 7.34512744745383 Test RE 1.29541144028982\n",
      "28 Train Loss 5.940442 Test MSE 7.040113794530811 Test RE 1.2682296424921307\n",
      "29 Train Loss 5.519804 Test MSE 7.076134530286711 Test RE 1.2714699509212979\n",
      "30 Train Loss 5.214921 Test MSE 7.056023938351796 Test RE 1.2696618870140521\n",
      "31 Train Loss 4.9937634 Test MSE 6.928826266137507 Test RE 1.2581658591533245\n",
      "32 Train Loss 4.717074 Test MSE 6.99800908407336 Test RE 1.2644315134472426\n",
      "33 Train Loss 4.5854487 Test MSE 6.935475212505233 Test RE 1.2587693864369383\n",
      "34 Train Loss 4.495101 Test MSE 6.897067068918372 Test RE 1.2552790620286176\n",
      "35 Train Loss 4.352935 Test MSE 6.899737535898932 Test RE 1.2555220534939828\n",
      "36 Train Loss 4.2420692 Test MSE 6.813413518503619 Test RE 1.2476432870363101\n",
      "37 Train Loss 4.1214166 Test MSE 6.750377283666655 Test RE 1.241858412313904\n",
      "38 Train Loss 3.9981017 Test MSE 6.650116950616841 Test RE 1.2326015280010452\n",
      "39 Train Loss 3.9259753 Test MSE 6.57375681836143 Test RE 1.2255044072069696\n",
      "40 Train Loss 3.780267 Test MSE 6.527341126694346 Test RE 1.2211702493633763\n",
      "41 Train Loss 3.7253566 Test MSE 6.427069682429774 Test RE 1.2117542861583046\n",
      "42 Train Loss 3.5715055 Test MSE 6.431098800372281 Test RE 1.2121340498951936\n",
      "43 Train Loss 3.5071304 Test MSE 6.359532163378121 Test RE 1.2053707384430759\n",
      "44 Train Loss 3.4569192 Test MSE 6.377620990084755 Test RE 1.2070837779724943\n",
      "45 Train Loss 3.2989047 Test MSE 6.365745451779252 Test RE 1.2059594207121478\n",
      "46 Train Loss 3.2607756 Test MSE 6.340229407683283 Test RE 1.203540048826884\n",
      "47 Train Loss 3.1610265 Test MSE 6.221164721207614 Test RE 1.1921857062988175\n",
      "48 Train Loss 3.10951 Test MSE 6.284771018537425 Test RE 1.1982647670761317\n",
      "49 Train Loss 3.0362535 Test MSE 6.184726366558992 Test RE 1.188689167858509\n",
      "50 Train Loss 2.9720683 Test MSE 6.232834484988188 Test RE 1.1933033432666424\n",
      "51 Train Loss 2.9143062 Test MSE 6.226055390148514 Test RE 1.1926542230807753\n",
      "52 Train Loss 2.870939 Test MSE 6.2110737814276895 Test RE 1.191218431114303\n",
      "53 Train Loss 2.8386374 Test MSE 6.2427777746719135 Test RE 1.1942548070345615\n",
      "54 Train Loss 2.7461662 Test MSE 6.17301413540241 Test RE 1.187563103504995\n",
      "55 Train Loss 2.7209005 Test MSE 6.156625089347272 Test RE 1.1859855952173892\n",
      "56 Train Loss 2.6862507 Test MSE 6.029775551830314 Test RE 1.1737041321424897\n",
      "57 Train Loss 2.6168592 Test MSE 6.027542379258972 Test RE 1.1734867669535451\n",
      "58 Train Loss 2.5801032 Test MSE 6.000918593327725 Test RE 1.1708922404624167\n",
      "59 Train Loss 2.549644 Test MSE 5.9782268496765445 Test RE 1.1686763504143576\n",
      "60 Train Loss 2.5074563 Test MSE 5.947000862513965 Test RE 1.165620189120017\n",
      "61 Train Loss 2.462854 Test MSE 5.850790238489569 Test RE 1.1561530370480457\n",
      "62 Train Loss 2.4474208 Test MSE 5.852510146595125 Test RE 1.1563229569038345\n",
      "63 Train Loss 2.4068272 Test MSE 5.817604500669408 Test RE 1.1528695188851472\n",
      "64 Train Loss 2.3851047 Test MSE 5.793073645505789 Test RE 1.1504363222910083\n",
      "65 Train Loss 2.3684916 Test MSE 5.760456249368465 Test RE 1.147193034874567\n",
      "66 Train Loss 2.3491921 Test MSE 5.743835446799506 Test RE 1.1455368255552207\n",
      "67 Train Loss 2.3202245 Test MSE 5.673180245606302 Test RE 1.138469371725737\n",
      "68 Train Loss 2.2873588 Test MSE 5.711817517655367 Test RE 1.142339574043722\n",
      "69 Train Loss 2.2531762 Test MSE 5.622043746670921 Test RE 1.1333268309733615\n",
      "70 Train Loss 2.2301757 Test MSE 5.605287219840154 Test RE 1.1316366277445244\n",
      "71 Train Loss 2.2109718 Test MSE 5.540948194726513 Test RE 1.1251232653616166\n",
      "72 Train Loss 2.1868472 Test MSE 5.538006568207633 Test RE 1.1248245681256697\n",
      "73 Train Loss 2.1705897 Test MSE 5.520280428717047 Test RE 1.1230229471234263\n",
      "74 Train Loss 2.1563983 Test MSE 5.5311630993706125 Test RE 1.1241293647776047\n",
      "75 Train Loss 2.1469078 Test MSE 5.5375925917627855 Test RE 1.1247825259600954\n",
      "76 Train Loss 2.1025944 Test MSE 5.472806995864976 Test RE 1.1181836212141019\n",
      "77 Train Loss 2.058825 Test MSE 5.436138175189422 Test RE 1.1144313066505187\n",
      "78 Train Loss 2.0236537 Test MSE 5.455562420848154 Test RE 1.116420557489276\n",
      "79 Train Loss 2.002058 Test MSE 5.455419949580237 Test RE 1.1164059798088701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Train Loss 1.986279 Test MSE 5.432040935085011 Test RE 1.1140112517152676\n",
      "81 Train Loss 1.9735628 Test MSE 5.4387788004024324 Test RE 1.1147019434546142\n",
      "82 Train Loss 1.9548281 Test MSE 5.419839003772733 Test RE 1.1127593529333424\n",
      "83 Train Loss 1.9181246 Test MSE 5.409774561537257 Test RE 1.1117256961929765\n",
      "84 Train Loss 1.8870658 Test MSE 5.435272167882057 Test RE 1.114342535535459\n",
      "85 Train Loss 1.8643885 Test MSE 5.426598418215566 Test RE 1.113453032019998\n",
      "86 Train Loss 1.855101 Test MSE 5.462390701262055 Test RE 1.11711900507233\n",
      "87 Train Loss 1.8475106 Test MSE 5.455945919025619 Test RE 1.1164597961316205\n",
      "88 Train Loss 1.8380234 Test MSE 5.461171603634997 Test RE 1.1169943386764973\n",
      "89 Train Loss 1.827446 Test MSE 5.47140200937853 Test RE 1.1180400811878661\n",
      "90 Train Loss 1.8188161 Test MSE 5.506755529700077 Test RE 1.1216463787739892\n",
      "91 Train Loss 1.8069053 Test MSE 5.506042810950249 Test RE 1.1215737911796588\n",
      "92 Train Loss 1.7950859 Test MSE 5.483265068092786 Test RE 1.1192514885654952\n",
      "93 Train Loss 1.7817016 Test MSE 5.460767709971674 Test RE 1.1169530329540427\n",
      "94 Train Loss 1.7753097 Test MSE 5.461849315901 Test RE 1.117063644068773\n",
      "95 Train Loss 1.7655709 Test MSE 5.4565106274034525 Test RE 1.1165175732702275\n",
      "96 Train Loss 1.7466255 Test MSE 5.413864968375304 Test RE 1.1121459125136899\n",
      "97 Train Loss 1.7362971 Test MSE 5.3868618706274685 Test RE 1.1093688829764579\n",
      "98 Train Loss 1.7298176 Test MSE 5.380528300668636 Test RE 1.1087165243225277\n",
      "99 Train Loss 1.722771 Test MSE 5.3635576507996054 Test RE 1.106966649694284\n",
      "100 Train Loss 1.7128795 Test MSE 5.326059725621962 Test RE 1.1030903273158839\n",
      "101 Train Loss 1.7046795 Test MSE 5.31017408902544 Test RE 1.101444046683572\n",
      "102 Train Loss 1.6772164 Test MSE 5.273695599603598 Test RE 1.0976543163217438\n",
      "103 Train Loss 1.66853 Test MSE 5.27339911014068 Test RE 1.097623460586251\n",
      "104 Train Loss 1.6623036 Test MSE 5.262545376434139 Test RE 1.0964933120020763\n",
      "105 Train Loss 1.6560044 Test MSE 5.24401154103028 Test RE 1.094560772746919\n",
      "106 Train Loss 1.6487924 Test MSE 5.237657998268973 Test RE 1.0938974974725815\n",
      "107 Train Loss 1.6373721 Test MSE 5.222561236719022 Test RE 1.0923198623091743\n",
      "108 Train Loss 1.6290132 Test MSE 5.246264814184367 Test RE 1.094795905669926\n",
      "109 Train Loss 1.62192 Test MSE 5.242329920334602 Test RE 1.0943852598195882\n",
      "110 Train Loss 1.6171033 Test MSE 5.240464430777567 Test RE 1.094190523322629\n",
      "111 Train Loss 1.6099666 Test MSE 5.228917482583188 Test RE 1.092984377479398\n",
      "112 Train Loss 1.5982089 Test MSE 5.2427600547228055 Test RE 1.0944301561811114\n",
      "113 Train Loss 1.5866294 Test MSE 5.205087082255775 Test RE 1.0904909360419415\n",
      "114 Train Loss 1.5751381 Test MSE 5.185825110683406 Test RE 1.0884713277313625\n",
      "115 Train Loss 1.5694429 Test MSE 5.164795069141172 Test RE 1.0862620504276552\n",
      "116 Train Loss 1.5633067 Test MSE 5.154626485359748 Test RE 1.0851921929920865\n",
      "117 Train Loss 1.5549842 Test MSE 5.135426487499303 Test RE 1.0831692407665396\n",
      "118 Train Loss 1.5435239 Test MSE 5.096642362985685 Test RE 1.079071295930166\n",
      "119 Train Loss 1.531504 Test MSE 5.065403145908158 Test RE 1.0757591981568206\n",
      "120 Train Loss 1.517737 Test MSE 5.032427517523726 Test RE 1.0722519000576205\n",
      "121 Train Loss 1.5045123 Test MSE 5.02082748821278 Test RE 1.0710153865300782\n",
      "122 Train Loss 1.4812647 Test MSE 4.96690850037192 Test RE 1.065249011972748\n",
      "123 Train Loss 1.4689165 Test MSE 4.947147667207584 Test RE 1.0631278548379384\n",
      "124 Train Loss 1.4499307 Test MSE 4.864834620140537 Test RE 1.0542463371721555\n",
      "125 Train Loss 1.4313694 Test MSE 4.8191564258873 Test RE 1.0492852597145426\n",
      "126 Train Loss 1.3960707 Test MSE 4.697310516058152 Test RE 1.0359354509028986\n",
      "127 Train Loss 1.3862737 Test MSE 4.643764008755391 Test RE 1.0300140075898798\n",
      "128 Train Loss 1.37583 Test MSE 4.629109199360293 Test RE 1.0283874621084668\n",
      "129 Train Loss 1.3528155 Test MSE 4.577371703300642 Test RE 1.0226243992712494\n",
      "130 Train Loss 1.3209814 Test MSE 4.531337871868915 Test RE 1.0174692274538835\n",
      "131 Train Loss 1.3003719 Test MSE 4.457837912768645 Test RE 1.009183629562695\n",
      "132 Train Loss 1.2847266 Test MSE 4.38293902008728 Test RE 1.0006697571106324\n",
      "133 Train Loss 1.2641551 Test MSE 4.412120602684302 Test RE 1.0039954573928491\n",
      "134 Train Loss 1.2503426 Test MSE 4.366462406801207 Test RE 0.9987870965170723\n",
      "135 Train Loss 1.2234905 Test MSE 4.300539741196983 Test RE 0.99121882836853\n",
      "136 Train Loss 1.2025071 Test MSE 4.253360049929786 Test RE 0.985766679199282\n",
      "137 Train Loss 1.1892653 Test MSE 4.240979669709271 Test RE 0.9843309836716758\n",
      "138 Train Loss 1.1696057 Test MSE 4.206327450576478 Test RE 0.980301347038643\n",
      "139 Train Loss 1.1529822 Test MSE 4.160949652710822 Test RE 0.9749992704190794\n",
      "140 Train Loss 1.1367642 Test MSE 4.083682658930803 Test RE 0.965904197190094\n",
      "141 Train Loss 1.1222823 Test MSE 4.043092593515774 Test RE 0.9610918711538143\n",
      "142 Train Loss 1.1055335 Test MSE 3.9931466321000277 Test RE 0.955137044706889\n",
      "143 Train Loss 1.0914092 Test MSE 3.9838024067200783 Test RE 0.9540188484526486\n",
      "144 Train Loss 1.0715969 Test MSE 3.9715859202703574 Test RE 0.9525549571983166\n",
      "145 Train Loss 1.0513042 Test MSE 3.9108632567412385 Test RE 0.9452449718307476\n",
      "146 Train Loss 1.0375376 Test MSE 3.8791630897814167 Test RE 0.9414062552572519\n",
      "147 Train Loss 1.0175849 Test MSE 3.838703004190219 Test RE 0.9364839025222178\n",
      "148 Train Loss 0.9929916 Test MSE 3.821095655231685 Test RE 0.9343337035805666\n",
      "149 Train Loss 0.9751237 Test MSE 3.8084985846371833 Test RE 0.9327923152997025\n",
      "Training time: 303.86\n",
      "9\n",
      "KG_rowdy_tune59\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 57.003246 Test MSE 7.596961703596502 Test RE 1.317431456199673\n",
      "1 Train Loss 49.049217 Test MSE 8.758106358196395 Test RE 1.4145332738431045\n",
      "2 Train Loss 41.838524 Test MSE 8.631498789683368 Test RE 1.4042717762421428\n",
      "3 Train Loss 34.583946 Test MSE 8.267946744703972 Test RE 1.3743802180603923\n",
      "4 Train Loss 31.122726 Test MSE 8.405434927456284 Test RE 1.3857604281510683\n",
      "5 Train Loss 28.373676 Test MSE 8.736439894004194 Test RE 1.4127825008136687\n",
      "6 Train Loss 27.099491 Test MSE 8.980219881141133 Test RE 1.4323578928665204\n",
      "7 Train Loss 26.424736 Test MSE 9.241365467963561 Test RE 1.4530351926742935\n",
      "8 Train Loss 25.561813 Test MSE 9.228062549425617 Test RE 1.4519889960863537\n",
      "9 Train Loss 24.616478 Test MSE 9.160150561955351 Test RE 1.4466363259648252\n",
      "10 Train Loss 24.176813 Test MSE 9.306280746629076 Test RE 1.4581296303259874\n",
      "11 Train Loss 23.55249 Test MSE 9.227127643380662 Test RE 1.4519154428531622\n",
      "12 Train Loss 22.999014 Test MSE 9.338702802349278 Test RE 1.4606674033240499\n",
      "13 Train Loss 22.280905 Test MSE 9.359258119401973 Test RE 1.4622740492756838\n",
      "14 Train Loss 21.856123 Test MSE 9.251360510259682 Test RE 1.4538207488502823\n",
      "15 Train Loss 21.724815 Test MSE 9.437147028085104 Test RE 1.468346055593894\n",
      "16 Train Loss 21.004116 Test MSE 9.567438201916481 Test RE 1.4784474519692092\n",
      "17 Train Loss 20.206076 Test MSE 9.296806850698355 Test RE 1.4573872453559962\n",
      "18 Train Loss 19.901075 Test MSE 9.390751296278903 Test RE 1.4647322024578153\n",
      "19 Train Loss 19.588902 Test MSE 9.47528957977451 Test RE 1.471310404260635\n",
      "20 Train Loss 18.996233 Test MSE 9.162470343706152 Test RE 1.4468194926107472\n",
      "21 Train Loss 18.323044 Test MSE 9.102144319896414 Test RE 1.4420486718686105\n",
      "22 Train Loss 17.713766 Test MSE 9.049332751889581 Test RE 1.4378591293875693\n",
      "23 Train Loss 17.238771 Test MSE 8.90686951171562 Test RE 1.4264961543389851\n",
      "24 Train Loss 16.386885 Test MSE 8.794094483060078 Test RE 1.4174365391166213\n",
      "25 Train Loss 16.081802 Test MSE 8.815106537678695 Test RE 1.4191288955440358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 Train Loss 15.370744 Test MSE 8.649550928630635 Test RE 1.405739474333529\n",
      "27 Train Loss 14.550465 Test MSE 8.547966195824872 Test RE 1.3974602333458017\n",
      "28 Train Loss 13.389114 Test MSE 8.346145313529297 Test RE 1.3808643936005405\n",
      "29 Train Loss 12.484092 Test MSE 7.902086824751139 Test RE 1.3436277318154015\n",
      "30 Train Loss 11.584527 Test MSE 7.7719950662282145 Test RE 1.3325217864983072\n",
      "31 Train Loss 11.258708 Test MSE 7.700475372098077 Test RE 1.3263765296422136\n",
      "32 Train Loss 10.247438 Test MSE 7.778508200638876 Test RE 1.3330800135624916\n",
      "33 Train Loss 9.92949 Test MSE 7.4248949431851665 Test RE 1.3024264782712076\n",
      "34 Train Loss 9.277732 Test MSE 7.1746578613183685 Test RE 1.2802908984226744\n",
      "35 Train Loss 8.722248 Test MSE 7.1601825053314485 Test RE 1.2789987097185092\n",
      "36 Train Loss 8.429539 Test MSE 7.12839201033122 Test RE 1.276156237888227\n",
      "37 Train Loss 7.8943205 Test MSE 6.97966564261539 Test RE 1.26277323861656\n",
      "38 Train Loss 7.7177963 Test MSE 6.958047745828939 Test RE 1.260816148303818\n",
      "39 Train Loss 7.5048437 Test MSE 6.706679184934421 Test RE 1.2378323440056775\n",
      "40 Train Loss 7.191942 Test MSE 6.730644085757049 Test RE 1.2400419380387817\n",
      "41 Train Loss 6.9631147 Test MSE 6.599367050140473 Test RE 1.227889264457776\n",
      "42 Train Loss 6.6771407 Test MSE 6.427978926352503 Test RE 1.2118399971673834\n",
      "43 Train Loss 6.5094986 Test MSE 6.410434329488807 Test RE 1.210185062392491\n",
      "44 Train Loss 6.1874905 Test MSE 6.276893515636997 Test RE 1.197513562785235\n",
      "45 Train Loss 5.8998365 Test MSE 6.119097794177195 Test RE 1.1823655224951584\n",
      "46 Train Loss 5.8399067 Test MSE 6.163050315286039 Test RE 1.1866042976855093\n",
      "47 Train Loss 5.6077743 Test MSE 6.043309930775936 Test RE 1.175020636572609\n",
      "48 Train Loss 5.4409027 Test MSE 5.909190985513156 Test RE 1.1619088873388648\n",
      "49 Train Loss 5.36175 Test MSE 5.848781076515131 Test RE 1.1559545084665088\n",
      "50 Train Loss 5.2312574 Test MSE 5.762032934307918 Test RE 1.1473500222858988\n",
      "51 Train Loss 5.0494876 Test MSE 5.7849369982804655 Test RE 1.149628117158632\n",
      "52 Train Loss 4.6424665 Test MSE 5.509518113406514 Test RE 1.1219276926498123\n",
      "53 Train Loss 4.411387 Test MSE 5.509395240652854 Test RE 1.1219151820172328\n",
      "54 Train Loss 3.7765734 Test MSE 5.192371686902538 Test RE 1.0891581531534391\n",
      "55 Train Loss 3.5661469 Test MSE 5.286575121462621 Test RE 1.0989938553075895\n",
      "56 Train Loss 3.3439806 Test MSE 5.3160405415331615 Test RE 1.1020522928022944\n",
      "57 Train Loss 3.1114707 Test MSE 5.218864028923625 Test RE 1.0919331508538381\n",
      "58 Train Loss 3.029327 Test MSE 5.280739006939642 Test RE 1.0983870706716503\n",
      "59 Train Loss 2.9333594 Test MSE 5.207015148224286 Test RE 1.0906928869180987\n",
      "60 Train Loss 2.86764 Test MSE 5.194578002024734 Test RE 1.0893895282391015\n",
      "61 Train Loss 2.8225245 Test MSE 5.190630339836373 Test RE 1.0889755043072267\n",
      "62 Train Loss 2.737249 Test MSE 5.180390259827892 Test RE 1.0879008080983819\n",
      "63 Train Loss 2.6015248 Test MSE 5.186651055309318 Test RE 1.088558004511887\n",
      "64 Train Loss 2.5592847 Test MSE 5.234580860528574 Test RE 1.0935761164455837\n",
      "65 Train Loss 2.391714 Test MSE 5.213783955773555 Test RE 1.091401574364871\n",
      "66 Train Loss 2.3467612 Test MSE 5.235785277856995 Test RE 1.0937019189028117\n",
      "67 Train Loss 2.3083649 Test MSE 5.280208097099435 Test RE 1.0983318549943513\n",
      "68 Train Loss 2.237463 Test MSE 5.259619752949176 Test RE 1.0961884811334222\n",
      "69 Train Loss 2.202142 Test MSE 5.259006287862927 Test RE 1.0961245513245539\n",
      "70 Train Loss 2.188155 Test MSE 5.266430954573073 Test RE 1.0968980329114106\n",
      "71 Train Loss 2.0996413 Test MSE 5.289073556982271 Test RE 1.0992535168923916\n",
      "72 Train Loss 2.0866525 Test MSE 5.299769958723562 Test RE 1.10036449770577\n",
      "73 Train Loss 2.0528374 Test MSE 5.330039198190825 Test RE 1.1035023484219513\n",
      "74 Train Loss 1.9992359 Test MSE 5.386537549894254 Test RE 1.109335487211565\n",
      "75 Train Loss 1.9806299 Test MSE 5.399026366615995 Test RE 1.1106207531524082\n",
      "76 Train Loss 1.9592332 Test MSE 5.405553114992469 Test RE 1.1112918512655354\n",
      "77 Train Loss 1.8964162 Test MSE 5.429655799030415 Test RE 1.1137666511895865\n",
      "78 Train Loss 1.8726695 Test MSE 5.464642963909611 Test RE 1.117349287584509\n",
      "79 Train Loss 1.8625941 Test MSE 5.468950507068735 Test RE 1.1177895800436213\n",
      "80 Train Loss 1.8137233 Test MSE 5.430039455693863 Test RE 1.1138059995815537\n",
      "81 Train Loss 1.793102 Test MSE 5.414136994374711 Test RE 1.112173852701054\n",
      "82 Train Loss 1.7875292 Test MSE 5.428947242392508 Test RE 1.113693976923413\n",
      "83 Train Loss 1.7835779 Test MSE 5.434544193029993 Test RE 1.1142679081311868\n",
      "84 Train Loss 1.7597103 Test MSE 5.411869434748574 Test RE 1.1119409268771872\n",
      "85 Train Loss 1.7074848 Test MSE 5.454646447515338 Test RE 1.116326831645177\n",
      "86 Train Loss 1.6953176 Test MSE 5.451927261206662 Test RE 1.116048547886029\n",
      "87 Train Loss 1.6886305 Test MSE 5.462812162211096 Test RE 1.1171621009419213\n",
      "88 Train Loss 1.6675302 Test MSE 5.474170795980241 Test RE 1.1183229358254092\n",
      "89 Train Loss 1.6329205 Test MSE 5.455951857622338 Test RE 1.1164604037441934\n",
      "90 Train Loss 1.6092573 Test MSE 5.4618404254551285 Test RE 1.1170627349263442\n",
      "91 Train Loss 1.5971014 Test MSE 5.483954618231529 Test RE 1.119321862306988\n",
      "92 Train Loss 1.5882092 Test MSE 5.50297510984847 Test RE 1.1212613042768078\n",
      "93 Train Loss 1.5752082 Test MSE 5.504304489239959 Test RE 1.1213967302627341\n",
      "94 Train Loss 1.5562596 Test MSE 5.503890813641975 Test RE 1.1213545902266775\n",
      "95 Train Loss 1.5339304 Test MSE 5.512685981302662 Test RE 1.122250189817931\n",
      "96 Train Loss 1.5278164 Test MSE 5.520209160932914 Test RE 1.1230156978888697\n",
      "97 Train Loss 1.5216823 Test MSE 5.516528868647048 Test RE 1.1226412813599533\n",
      "98 Train Loss 1.5171841 Test MSE 5.520159182745984 Test RE 1.1230106141670506\n",
      "99 Train Loss 1.5054098 Test MSE 5.496223434650442 Test RE 1.120573247773976\n",
      "100 Train Loss 1.489327 Test MSE 5.50782309176358 Test RE 1.1217550969735979\n",
      "101 Train Loss 1.4691247 Test MSE 5.526483771324076 Test RE 1.1236537610973039\n",
      "102 Train Loss 1.4550599 Test MSE 5.5076257701862685 Test RE 1.1217350029669533\n",
      "103 Train Loss 1.4473045 Test MSE 5.52015195386278 Test RE 1.123009878851731\n",
      "104 Train Loss 1.440645 Test MSE 5.520111988776689 Test RE 1.1230058136314167\n",
      "105 Train Loss 1.4249277 Test MSE 5.522005617525977 Test RE 1.1231984160419783\n",
      "106 Train Loss 1.4087728 Test MSE 5.523539652712122 Test RE 1.1233544197081569\n",
      "107 Train Loss 1.3986272 Test MSE 5.4890772317285625 Test RE 1.1198445248098654\n",
      "108 Train Loss 1.3907826 Test MSE 5.522903323415184 Test RE 1.1232897108473792\n",
      "109 Train Loss 1.3800943 Test MSE 5.510841581191867 Test RE 1.1220624363759444\n",
      "110 Train Loss 1.3693967 Test MSE 5.528252715231358 Test RE 1.1238335790001213\n",
      "111 Train Loss 1.3626331 Test MSE 5.525468011121211 Test RE 1.1235504933352334\n",
      "112 Train Loss 1.3537759 Test MSE 5.532871230772924 Test RE 1.124302927951464\n",
      "113 Train Loss 1.3473904 Test MSE 5.55361043013658 Test RE 1.1264081037439542\n",
      "114 Train Loss 1.3436837 Test MSE 5.544602512107213 Test RE 1.1254942199057185\n",
      "115 Train Loss 1.3391819 Test MSE 5.524544078953218 Test RE 1.1234565530717027\n",
      "116 Train Loss 1.3345568 Test MSE 5.5377071985883575 Test RE 1.1247941652316429\n",
      "117 Train Loss 1.3311135 Test MSE 5.534980008447727 Test RE 1.124517163829086\n",
      "118 Train Loss 1.32508 Test MSE 5.5502789307931115 Test RE 1.1260701982628534\n",
      "119 Train Loss 1.3209331 Test MSE 5.551839795666582 Test RE 1.1262285254284314\n",
      "120 Train Loss 1.312225 Test MSE 5.549379840585943 Test RE 1.1259789884601528\n",
      "121 Train Loss 1.3004984 Test MSE 5.58172110200628 Test RE 1.1292552715103963\n",
      "122 Train Loss 1.2875465 Test MSE 5.580806147263953 Test RE 1.1291627140543927\n",
      "123 Train Loss 1.2807826 Test MSE 5.590676588620562 Test RE 1.130160814542664\n",
      "124 Train Loss 1.2737186 Test MSE 5.607200289239391 Test RE 1.1318297235335206\n",
      "125 Train Loss 1.2712823 Test MSE 5.601273187825518 Test RE 1.1312313640184237\n",
      "126 Train Loss 1.266372 Test MSE 5.6284319614980145 Test RE 1.1339705363687005\n",
      "127 Train Loss 1.2562654 Test MSE 5.632664355850234 Test RE 1.1343968103839313\n",
      "128 Train Loss 1.2496208 Test MSE 5.637066778209789 Test RE 1.1348400392111353\n",
      "129 Train Loss 1.2402973 Test MSE 5.61425386005917 Test RE 1.132541391708999\n",
      "130 Train Loss 1.2342257 Test MSE 5.614966450988715 Test RE 1.1326132635139081\n",
      "131 Train Loss 1.2312806 Test MSE 5.617865853779972 Test RE 1.1329056497880048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 Train Loss 1.2256684 Test MSE 5.622876562036129 Test RE 1.133410769936631\n",
      "133 Train Loss 1.2217685 Test MSE 5.634176065505038 Test RE 1.1345490264096698\n",
      "134 Train Loss 1.2135237 Test MSE 5.637981550113017 Test RE 1.1349321152597958\n",
      "135 Train Loss 1.2060156 Test MSE 5.633828627516901 Test RE 1.134514044230931\n",
      "136 Train Loss 1.1995368 Test MSE 5.646836228598836 Test RE 1.1358229940449944\n",
      "137 Train Loss 1.1956426 Test MSE 5.650343880468657 Test RE 1.1361757095286795\n",
      "138 Train Loss 1.186632 Test MSE 5.688839953095179 Test RE 1.140039550248108\n",
      "139 Train Loss 1.1749626 Test MSE 5.730509559690347 Test RE 1.1442072123690354\n",
      "140 Train Loss 1.1666954 Test MSE 5.740608251601947 Test RE 1.145214968287774\n",
      "141 Train Loss 1.1627876 Test MSE 5.736004874697337 Test RE 1.1447557039380585\n",
      "142 Train Loss 1.1567016 Test MSE 5.718155188293615 Test RE 1.1429731521304651\n",
      "143 Train Loss 1.1506841 Test MSE 5.716024425213904 Test RE 1.1427601785548351\n",
      "144 Train Loss 1.1454893 Test MSE 5.723027085179958 Test RE 1.1434599578900555\n",
      "145 Train Loss 1.1439791 Test MSE 5.714404394618453 Test RE 1.1425982270385977\n",
      "146 Train Loss 1.142774 Test MSE 5.717940218920144 Test RE 1.142951667357525\n",
      "147 Train Loss 1.1384888 Test MSE 5.7174106993761855 Test RE 1.1428987436441869\n",
      "148 Train Loss 1.1305592 Test MSE 5.710000033441456 Test RE 1.1421578149695224\n",
      "149 Train Loss 1.1248803 Test MSE 5.697155267978809 Test RE 1.140872437648898\n",
      "Training time: 300.47\n",
      "0\n",
      "KG_rowdy_tune60\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 68.09002 Test MSE 5.203401248905077 Test RE 1.0903143266174835\n",
      "1 Train Loss 50.74724 Test MSE 8.636520798040294 Test RE 1.4046802359588493\n",
      "2 Train Loss 40.168736 Test MSE 8.928325207299732 Test RE 1.4282132591781174\n",
      "3 Train Loss 33.39792 Test MSE 8.871764907639495 Test RE 1.4236822576171875\n",
      "4 Train Loss 27.26669 Test MSE 9.258088632959671 Test RE 1.4543493038991726\n",
      "5 Train Loss 23.393349 Test MSE 9.542914202106086 Test RE 1.4765514005620282\n",
      "6 Train Loss 20.279278 Test MSE 9.42374838333284 Test RE 1.4673033233362252\n",
      "7 Train Loss 18.437813 Test MSE 9.455927070692665 Test RE 1.4698063431198138\n",
      "8 Train Loss 16.566515 Test MSE 9.296772341139603 Test RE 1.4573845404575159\n",
      "9 Train Loss 14.875662 Test MSE 9.210460121866339 Test RE 1.450603508570645\n",
      "10 Train Loss 13.615742 Test MSE 9.01584510161702 Test RE 1.435196217455532\n",
      "11 Train Loss 12.255512 Test MSE 8.639851906706733 Test RE 1.4049511026375332\n",
      "12 Train Loss 10.726578 Test MSE 8.349983164652881 Test RE 1.3811818421157158\n",
      "13 Train Loss 9.404049 Test MSE 8.020834554320915 Test RE 1.353685694525847\n",
      "14 Train Loss 7.823839 Test MSE 7.399511987278795 Test RE 1.300198316324094\n",
      "15 Train Loss 6.275052 Test MSE 6.809781912902766 Test RE 1.2473107406367758\n",
      "16 Train Loss 4.829072 Test MSE 6.336152970115981 Test RE 1.2031530798067103\n",
      "17 Train Loss 3.7734015 Test MSE 5.960467427547806 Test RE 1.1669391753081453\n",
      "18 Train Loss 3.1966062 Test MSE 5.7446495184931345 Test RE 1.1456180009363937\n",
      "19 Train Loss 2.6688404 Test MSE 5.328765771864884 Test RE 1.1033705189145537\n",
      "20 Train Loss 2.270832 Test MSE 4.855222119763471 Test RE 1.053204271510108\n",
      "21 Train Loss 1.9892538 Test MSE 4.589228643642741 Test RE 1.0239480141471746\n",
      "22 Train Loss 1.7493508 Test MSE 4.359550804744847 Test RE 0.9979963015646524\n",
      "23 Train Loss 1.5838282 Test MSE 4.314683761458407 Test RE 0.992847497271363\n",
      "24 Train Loss 1.4471372 Test MSE 4.302712551442915 Test RE 0.991469199087806\n",
      "25 Train Loss 1.3463451 Test MSE 4.2994044949377175 Test RE 0.9910879899381746\n",
      "26 Train Loss 1.2578027 Test MSE 4.297871800562364 Test RE 0.9909113177509273\n",
      "27 Train Loss 1.1916283 Test MSE 4.218440021934366 Test RE 0.9817117738718306\n",
      "28 Train Loss 1.1445223 Test MSE 4.18091114784014 Test RE 0.9773351743157155\n",
      "29 Train Loss 1.0755315 Test MSE 4.101004219065133 Test RE 0.9679505441793449\n",
      "30 Train Loss 1.0218153 Test MSE 3.987748272728581 Test RE 0.9544911985439574\n",
      "31 Train Loss 0.9823893 Test MSE 3.925365572218855 Test RE 0.946995935124982\n",
      "32 Train Loss 0.93976206 Test MSE 3.707489200874981 Test RE 0.9203393850142134\n",
      "33 Train Loss 0.89780736 Test MSE 3.503066215780975 Test RE 0.8946068794682319\n",
      "34 Train Loss 0.86776954 Test MSE 3.488520280938383 Test RE 0.8927475897493933\n",
      "35 Train Loss 0.8398491 Test MSE 3.3793646851336203 Test RE 0.8786695795557495\n",
      "36 Train Loss 0.813116 Test MSE 3.2924781449405836 Test RE 0.8673003281419828\n",
      "37 Train Loss 0.7928159 Test MSE 3.2761357959000663 Test RE 0.8651452103537276\n",
      "38 Train Loss 0.77434295 Test MSE 3.207205668568972 Test RE 0.8559954686940644\n",
      "39 Train Loss 0.7613102 Test MSE 3.1720674789919325 Test RE 0.8512934051701564\n",
      "40 Train Loss 0.74626756 Test MSE 3.1428494646608383 Test RE 0.8473636897511095\n",
      "41 Train Loss 0.7363887 Test MSE 3.086228736958099 Test RE 0.8396960605425854\n",
      "42 Train Loss 0.7247561 Test MSE 3.040379409065247 Test RE 0.8334354163204615\n",
      "43 Train Loss 0.7133447 Test MSE 3.0467500094293696 Test RE 0.8343081208223557\n",
      "44 Train Loss 0.704501 Test MSE 3.043293396654284 Test RE 0.8338347149763874\n",
      "45 Train Loss 0.6947087 Test MSE 3.0313596455556606 Test RE 0.8321982394735745\n",
      "46 Train Loss 0.68834496 Test MSE 3.042436660181682 Test RE 0.8337173377137385\n",
      "47 Train Loss 0.67733717 Test MSE 3.0642542391490224 Test RE 0.836701327573238\n",
      "48 Train Loss 0.6673267 Test MSE 3.086873070316337 Test RE 0.8397837105504529\n",
      "49 Train Loss 0.6584847 Test MSE 3.1019431584612764 Test RE 0.8418311232058121\n",
      "50 Train Loss 0.6483559 Test MSE 3.101079521010014 Test RE 0.8417139244918739\n",
      "51 Train Loss 0.6401813 Test MSE 3.1114335893112135 Test RE 0.8431179357157595\n",
      "52 Train Loss 0.6303619 Test MSE 3.11268530837338 Test RE 0.8432875103896589\n",
      "53 Train Loss 0.6171051 Test MSE 3.1187408841566464 Test RE 0.8441073989550151\n",
      "54 Train Loss 0.60976446 Test MSE 3.150981016944639 Test RE 0.8484591814501703\n",
      "55 Train Loss 0.60230666 Test MSE 3.1679824497688025 Test RE 0.8507450752885851\n",
      "56 Train Loss 0.59104574 Test MSE 3.17401042879063 Test RE 0.8515540817098601\n",
      "57 Train Loss 0.5830734 Test MSE 3.173465330253461 Test RE 0.8514809564278593\n",
      "58 Train Loss 0.5759513 Test MSE 3.170937025555269 Test RE 0.8511417007507376\n",
      "59 Train Loss 0.56874114 Test MSE 3.15872832290268 Test RE 0.8495015929047316\n",
      "60 Train Loss 0.56146604 Test MSE 3.1615475496400682 Test RE 0.8498806067380836\n",
      "61 Train Loss 0.55421454 Test MSE 3.1720446650819007 Test RE 0.851290343859796\n",
      "62 Train Loss 0.544267 Test MSE 3.180688044426163 Test RE 0.8524493785786657\n",
      "63 Train Loss 0.53597236 Test MSE 3.196199466115771 Test RE 0.8545254419698564\n",
      "64 Train Loss 0.5303076 Test MSE 3.2070452626149497 Test RE 0.8559740624450037\n",
      "65 Train Loss 0.52236784 Test MSE 3.1765341811124306 Test RE 0.851892562726669\n",
      "66 Train Loss 0.5155091 Test MSE 3.1721322549218707 Test RE 0.8513020971416896\n",
      "67 Train Loss 0.50837886 Test MSE 3.1892962818349644 Test RE 0.8536021367667973\n",
      "68 Train Loss 0.50162446 Test MSE 3.182706343849899 Test RE 0.8527197957364319\n",
      "69 Train Loss 0.49583578 Test MSE 3.1928075542573113 Test RE 0.8540718963748094\n",
      "70 Train Loss 0.49189353 Test MSE 3.181133475769341 Test RE 0.8525090660383474\n",
      "71 Train Loss 0.48681086 Test MSE 3.1669303516682152 Test RE 0.8506037958436896\n",
      "72 Train Loss 0.48094684 Test MSE 3.183145489687646 Test RE 0.8527786223123597\n",
      "73 Train Loss 0.4762162 Test MSE 3.1836245967720136 Test RE 0.8528427973410999\n",
      "74 Train Loss 0.47054517 Test MSE 3.200611145017518 Test RE 0.8551149846306433\n",
      "75 Train Loss 0.46456075 Test MSE 3.2040302120542727 Test RE 0.8555716029026341\n",
      "76 Train Loss 0.4595235 Test MSE 3.2274902756215718 Test RE 0.8586981583902327\n",
      "77 Train Loss 0.45523158 Test MSE 3.255503864909269 Test RE 0.8624167203192944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 Train Loss 0.44901007 Test MSE 3.267020658475479 Test RE 0.86394083256934\n",
      "79 Train Loss 0.4452309 Test MSE 3.2814650551976214 Test RE 0.8658485862161053\n",
      "80 Train Loss 0.44162682 Test MSE 3.2911011597112343 Test RE 0.8671189473429185\n",
      "81 Train Loss 0.43718925 Test MSE 3.306990079086158 Test RE 0.8692095840924086\n",
      "82 Train Loss 0.43382114 Test MSE 3.3136665515350954 Test RE 0.8700865640064449\n",
      "83 Train Loss 0.42822304 Test MSE 3.3314525856971984 Test RE 0.8724185244949361\n",
      "84 Train Loss 0.4231501 Test MSE 3.3707131336637945 Test RE 0.8775441125761583\n",
      "85 Train Loss 0.41917595 Test MSE 3.377954029232698 Test RE 0.8784861678908749\n",
      "86 Train Loss 0.41492432 Test MSE 3.377291979397533 Test RE 0.8784000758189239\n",
      "87 Train Loss 0.41170886 Test MSE 3.387831261114929 Test RE 0.8797695894251978\n",
      "88 Train Loss 0.40765145 Test MSE 3.389068310445313 Test RE 0.8799301964577317\n",
      "89 Train Loss 0.40438768 Test MSE 3.3961070471227113 Test RE 0.8808434835109749\n",
      "90 Train Loss 0.4010163 Test MSE 3.392077475889767 Test RE 0.8803207563106163\n",
      "91 Train Loss 0.39709342 Test MSE 3.3924356187713953 Test RE 0.8803672281693962\n",
      "92 Train Loss 0.39285445 Test MSE 3.3989924052700684 Test RE 0.8812175896987151\n",
      "93 Train Loss 0.3894749 Test MSE 3.412546606069142 Test RE 0.882972862278462\n",
      "94 Train Loss 0.385678 Test MSE 3.4348092234344936 Test RE 0.8858483294241144\n",
      "95 Train Loss 0.38271034 Test MSE 3.433361806289856 Test RE 0.8856616629919383\n",
      "96 Train Loss 0.3801307 Test MSE 3.4439312451938084 Test RE 0.8870238488211795\n",
      "97 Train Loss 0.37766942 Test MSE 3.4540186252497236 Test RE 0.8883219589701934\n",
      "98 Train Loss 0.3737809 Test MSE 3.452245147532927 Test RE 0.888093873709435\n",
      "99 Train Loss 0.3702053 Test MSE 3.468025003471943 Test RE 0.8901212522928597\n",
      "100 Train Loss 0.36714983 Test MSE 3.468478227398115 Test RE 0.8901794137923684\n",
      "101 Train Loss 0.36436388 Test MSE 3.4724895901272506 Test RE 0.8906940199756724\n",
      "102 Train Loss 0.36121768 Test MSE 3.4804562255597706 Test RE 0.8917151561339703\n",
      "103 Train Loss 0.35829118 Test MSE 3.477736199699004 Test RE 0.8913666440134991\n",
      "104 Train Loss 0.35528886 Test MSE 3.4715387100854396 Test RE 0.8905720612004153\n",
      "105 Train Loss 0.3530153 Test MSE 3.4731882460350203 Test RE 0.8907836181336154\n",
      "106 Train Loss 0.35007197 Test MSE 3.4823550979442564 Test RE 0.8919583745924381\n",
      "107 Train Loss 0.34787196 Test MSE 3.4773967543945377 Test RE 0.8913231419207636\n",
      "108 Train Loss 0.34581095 Test MSE 3.4808264938889155 Test RE 0.8917625874301304\n",
      "109 Train Loss 0.34379277 Test MSE 3.4876736195637337 Test RE 0.8926392485749689\n",
      "110 Train Loss 0.34174728 Test MSE 3.4828634741143514 Test RE 0.8920234790722266\n",
      "111 Train Loss 0.3403601 Test MSE 3.479510840501293 Test RE 0.8915940410581772\n",
      "112 Train Loss 0.33855304 Test MSE 3.483328161709456 Test RE 0.8920829844796443\n",
      "113 Train Loss 0.3365966 Test MSE 3.480863611652143 Test RE 0.8917673420687765\n",
      "114 Train Loss 0.33493495 Test MSE 3.471481348340438 Test RE 0.8905647035151394\n",
      "115 Train Loss 0.33327985 Test MSE 3.4682219654895765 Test RE 0.8901465285795669\n",
      "116 Train Loss 0.33169785 Test MSE 3.466411858149484 Test RE 0.8899142090985452\n",
      "117 Train Loss 0.33058128 Test MSE 3.4641220983918233 Test RE 0.889620241382001\n",
      "118 Train Loss 0.32962662 Test MSE 3.4562694613649083 Test RE 0.8886113525329332\n",
      "119 Train Loss 0.328563 Test MSE 3.4556900168666584 Test RE 0.8885368614454046\n",
      "120 Train Loss 0.32753634 Test MSE 3.4550241662729237 Test RE 0.8884512546207314\n",
      "121 Train Loss 0.32654503 Test MSE 3.4485698441796773 Test RE 0.8876210099001036\n",
      "122 Train Loss 0.32557875 Test MSE 3.4457803677722323 Test RE 0.8872619481910239\n",
      "123 Train Loss 0.324921 Test MSE 3.450483677482217 Test RE 0.8878672747436887\n",
      "124 Train Loss 0.32437003 Test MSE 3.4509452927630226 Test RE 0.8879266634312978\n",
      "125 Train Loss 0.32353795 Test MSE 3.444292480267645 Test RE 0.8870703677120638\n",
      "126 Train Loss 0.32258132 Test MSE 3.4430074331898832 Test RE 0.8869048716725505\n",
      "127 Train Loss 0.3216937 Test MSE 3.4442506834669246 Test RE 0.8870649853561693\n",
      "128 Train Loss 0.3209629 Test MSE 3.4474099524849184 Test RE 0.8874717261581808\n",
      "129 Train Loss 0.3201669 Test MSE 3.4475631600047136 Test RE 0.887491446155703\n",
      "130 Train Loss 0.31947014 Test MSE 3.447905883517551 Test RE 0.887535557983831\n",
      "131 Train Loss 0.3187819 Test MSE 3.4493425857051707 Test RE 0.8877204515853578\n",
      "132 Train Loss 0.31809688 Test MSE 3.443143703078029 Test RE 0.8869224227865363\n",
      "133 Train Loss 0.31744444 Test MSE 3.444764178101785 Test RE 0.8871311080307982\n",
      "134 Train Loss 0.31682456 Test MSE 3.4428492606398713 Test RE 0.8868844991321047\n",
      "135 Train Loss 0.31617492 Test MSE 3.4363493567896986 Test RE 0.8860469098354329\n",
      "136 Train Loss 0.31552067 Test MSE 3.4389435209553914 Test RE 0.886381293401087\n",
      "137 Train Loss 0.3148299 Test MSE 3.4358349000639765 Test RE 0.8859805822000956\n",
      "138 Train Loss 0.31414503 Test MSE 3.4332112552777523 Test RE 0.8856422448925664\n",
      "139 Train Loss 0.31343943 Test MSE 3.434785271046802 Test RE 0.8858452407198759\n",
      "140 Train Loss 0.31282437 Test MSE 3.433274301563086 Test RE 0.8856503766667547\n",
      "141 Train Loss 0.31231007 Test MSE 3.4396147144487914 Test RE 0.8864677886178707\n",
      "142 Train Loss 0.31183827 Test MSE 3.437802194648636 Test RE 0.886234193829215\n",
      "143 Train Loss 0.31135798 Test MSE 3.4312163725407667 Test RE 0.8853849043135091\n",
      "144 Train Loss 0.31078917 Test MSE 3.431660563893268 Test RE 0.885442211627904\n",
      "145 Train Loss 0.31022295 Test MSE 3.428724794762019 Test RE 0.8850633848096607\n",
      "146 Train Loss 0.30956653 Test MSE 3.424332380254956 Test RE 0.884496291890777\n",
      "147 Train Loss 0.3088787 Test MSE 3.429720272916492 Test RE 0.8851918578391731\n",
      "148 Train Loss 0.3082083 Test MSE 3.4333573494989187 Test RE 0.8856610881602752\n",
      "149 Train Loss 0.3076107 Test MSE 3.4292412216326795 Test RE 0.8851300354351953\n",
      "Training time: 230.63\n",
      "1\n",
      "KG_rowdy_tune60\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 59.69263 Test MSE 8.148394386614063 Test RE 1.364407445738187\n",
      "1 Train Loss 48.54406 Test MSE 8.877686486291303 Test RE 1.424157306283773\n",
      "2 Train Loss 43.249557 Test MSE 8.724251091741916 Test RE 1.411796622287212\n",
      "3 Train Loss 40.008793 Test MSE 9.242707950301517 Test RE 1.4531407292019562\n",
      "4 Train Loss 37.16341 Test MSE 9.407365633707224 Test RE 1.4660273491419762\n",
      "5 Train Loss 34.65056 Test MSE 9.465906762573988 Test RE 1.470581748121817\n",
      "6 Train Loss 31.572357 Test MSE 9.299861376459251 Test RE 1.4576266426761413\n",
      "7 Train Loss 29.197952 Test MSE 9.142624876673304 Test RE 1.445251772772966\n",
      "8 Train Loss 27.0513 Test MSE 9.06459815222528 Test RE 1.4390713870720542\n",
      "9 Train Loss 24.674295 Test MSE 9.038408689154352 Test RE 1.4369909987223892\n",
      "10 Train Loss 22.880178 Test MSE 8.861085768503113 Test RE 1.4228251407364592\n",
      "11 Train Loss 20.618464 Test MSE 8.79634967126813 Test RE 1.4176182736468326\n",
      "12 Train Loss 18.37735 Test MSE 8.759494550530674 Test RE 1.4146453737858293\n",
      "13 Train Loss 16.568525 Test MSE 8.759798519622748 Test RE 1.414669918851584\n",
      "14 Train Loss 14.915072 Test MSE 8.535138971138107 Test RE 1.3964113132936264\n",
      "15 Train Loss 13.266461 Test MSE 8.365312004018216 Test RE 1.382449042675961\n",
      "16 Train Loss 11.70936 Test MSE 8.185191126530539 Test RE 1.3674846896124817\n",
      "17 Train Loss 10.11853 Test MSE 8.073396318450522 Test RE 1.358113907101809\n",
      "18 Train Loss 8.965888 Test MSE 8.009186468535969 Test RE 1.3527024068280884\n",
      "19 Train Loss 7.5218353 Test MSE 7.673404367505405 Test RE 1.3240430400749799\n",
      "20 Train Loss 6.399188 Test MSE 7.6098294990176285 Test RE 1.3185467221868863\n",
      "21 Train Loss 5.478666 Test MSE 7.358463532047253 Test RE 1.2965869053976757\n",
      "22 Train Loss 4.63674 Test MSE 6.948445122717623 Test RE 1.2599458379235775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 Train Loss 3.9876323 Test MSE 6.762991080295965 Test RE 1.2430181429413885\n",
      "24 Train Loss 3.5179713 Test MSE 6.787032379798524 Test RE 1.245225543502588\n",
      "25 Train Loss 3.0591555 Test MSE 6.877208621370605 Test RE 1.253470622114205\n",
      "26 Train Loss 2.7439387 Test MSE 6.8064396285276345 Test RE 1.2470046090377824\n",
      "27 Train Loss 2.4406645 Test MSE 6.690469352055697 Test RE 1.2363355380827494\n",
      "28 Train Loss 2.283879 Test MSE 6.625461185978202 Test RE 1.2303144287916796\n",
      "29 Train Loss 2.1692476 Test MSE 6.54997859818507 Test RE 1.2232859867994443\n",
      "30 Train Loss 2.0594645 Test MSE 6.54225225626334 Test RE 1.2225642810292794\n",
      "31 Train Loss 1.9350758 Test MSE 6.506859592519964 Test RE 1.2192528460273426\n",
      "32 Train Loss 1.7817461 Test MSE 6.544004174005831 Test RE 1.2227279623276222\n",
      "33 Train Loss 1.6794565 Test MSE 6.596763285149624 Test RE 1.227647010126949\n",
      "34 Train Loss 1.6041222 Test MSE 6.597761605921418 Test RE 1.2277398995556503\n",
      "35 Train Loss 1.5239174 Test MSE 6.52114741928288 Test RE 1.2205907357320083\n",
      "36 Train Loss 1.4442196 Test MSE 6.348419834201961 Test RE 1.2043171756645397\n",
      "37 Train Loss 1.3937677 Test MSE 6.198960693534507 Test RE 1.190056282981756\n",
      "38 Train Loss 1.34189 Test MSE 6.120456956740495 Test RE 1.1824968276140517\n",
      "39 Train Loss 1.2938771 Test MSE 6.08222122896361 Test RE 1.178797392815812\n",
      "40 Train Loss 1.250294 Test MSE 6.028511672460878 Test RE 1.1735811177643072\n",
      "41 Train Loss 1.2132311 Test MSE 5.999246837724667 Test RE 1.1707291335996899\n",
      "42 Train Loss 1.1790025 Test MSE 5.951698513007365 Test RE 1.1660804711575055\n",
      "43 Train Loss 1.1530421 Test MSE 5.885798661624797 Test RE 1.1596068208520738\n",
      "44 Train Loss 1.12395 Test MSE 5.915170850054142 Test RE 1.1624966413031643\n",
      "45 Train Loss 1.0966494 Test MSE 5.9699703220234275 Test RE 1.1678690422626246\n",
      "46 Train Loss 1.0697548 Test MSE 5.962051611343192 Test RE 1.1670942406059919\n",
      "47 Train Loss 1.0454668 Test MSE 5.977678451397223 Test RE 1.1686227463261967\n",
      "48 Train Loss 1.027597 Test MSE 5.9768815100589165 Test RE 1.1685448436064383\n",
      "49 Train Loss 1.0119526 Test MSE 5.957545652822181 Test RE 1.166653128000251\n",
      "50 Train Loss 0.99728125 Test MSE 5.984912961980558 Test RE 1.1693296977994354\n",
      "51 Train Loss 0.9816742 Test MSE 6.009018633782197 Test RE 1.1716822092028394\n",
      "52 Train Loss 0.96790236 Test MSE 6.0047098356533954 Test RE 1.1712620534533087\n",
      "53 Train Loss 0.95842564 Test MSE 6.0199421911618805 Test RE 1.1727467030272762\n",
      "54 Train Loss 0.94538283 Test MSE 6.041322234243651 Test RE 1.174827383491808\n",
      "55 Train Loss 0.9322603 Test MSE 6.092737506490096 Test RE 1.1798160343793478\n",
      "56 Train Loss 0.91561997 Test MSE 6.150691681374819 Test RE 1.185413964449574\n",
      "57 Train Loss 0.9045338 Test MSE 6.181910445911897 Test RE 1.1884185305447197\n",
      "58 Train Loss 0.89397764 Test MSE 6.2055164239024805 Test RE 1.1906853905785422\n",
      "59 Train Loss 0.886009 Test MSE 6.216927671738787 Test RE 1.1917796561125658\n",
      "60 Train Loss 0.8760501 Test MSE 6.234463552314686 Test RE 1.1934592791000986\n",
      "61 Train Loss 0.8666619 Test MSE 6.25475800867828 Test RE 1.1954001781297097\n",
      "62 Train Loss 0.8599271 Test MSE 6.250320327181212 Test RE 1.194976041296295\n",
      "63 Train Loss 0.85301274 Test MSE 6.239377426791573 Test RE 1.1939295163487194\n",
      "64 Train Loss 0.84701496 Test MSE 6.236084880561523 Test RE 1.1936144539148956\n",
      "65 Train Loss 0.8414468 Test MSE 6.256683523228796 Test RE 1.1955841647294054\n",
      "66 Train Loss 0.83301944 Test MSE 6.268055881403166 Test RE 1.196670238405078\n",
      "67 Train Loss 0.82353455 Test MSE 6.2618897502274065 Test RE 1.1960814879690085\n",
      "68 Train Loss 0.817082 Test MSE 6.267036422571173 Test RE 1.1965729191026389\n",
      "69 Train Loss 0.8095228 Test MSE 6.269569213407328 Test RE 1.196814689101605\n",
      "70 Train Loss 0.803859 Test MSE 6.278574093952225 Test RE 1.1976738634682786\n",
      "71 Train Loss 0.79749584 Test MSE 6.26825317284717 Test RE 1.1966890712733578\n",
      "72 Train Loss 0.7915468 Test MSE 6.262733082753255 Test RE 1.1961620275906644\n",
      "73 Train Loss 0.7842822 Test MSE 6.2864161197284485 Test RE 1.198421585662432\n",
      "74 Train Loss 0.7792524 Test MSE 6.291000342385943 Test RE 1.1988584665564466\n",
      "75 Train Loss 0.77501035 Test MSE 6.286571707920447 Test RE 1.198436415979938\n",
      "76 Train Loss 0.7711952 Test MSE 6.283167533009109 Test RE 1.1981118957321524\n",
      "77 Train Loss 0.76359874 Test MSE 6.305675754761625 Test RE 1.2002559783083595\n",
      "78 Train Loss 0.7574236 Test MSE 6.331015382860822 Test RE 1.2026652003731082\n",
      "79 Train Loss 0.752149 Test MSE 6.329732158958609 Test RE 1.2025433110040433\n",
      "80 Train Loss 0.7474749 Test MSE 6.343807378326572 Test RE 1.203879596761609\n",
      "81 Train Loss 0.7429458 Test MSE 6.361821629705824 Test RE 1.2055876889450219\n",
      "82 Train Loss 0.73703164 Test MSE 6.362419521579672 Test RE 1.2056443389259157\n",
      "83 Train Loss 0.7328681 Test MSE 6.36156471652824 Test RE 1.2055633457215607\n",
      "84 Train Loss 0.7288963 Test MSE 6.363589806075731 Test RE 1.2057552151419093\n",
      "85 Train Loss 0.7257656 Test MSE 6.381070763212676 Test RE 1.2074102008048193\n",
      "86 Train Loss 0.7229345 Test MSE 6.40249348237034 Test RE 1.2094352791523115\n",
      "87 Train Loss 0.71921754 Test MSE 6.423080400516891 Test RE 1.2113781598636717\n",
      "88 Train Loss 0.71506864 Test MSE 6.420104509360505 Test RE 1.21109750424543\n",
      "89 Train Loss 0.7119746 Test MSE 6.4411484048317496 Test RE 1.2130807553479122\n",
      "90 Train Loss 0.7092019 Test MSE 6.468840598011902 Test RE 1.2156856353920575\n",
      "91 Train Loss 0.7061243 Test MSE 6.48346117132781 Test RE 1.2170586781360564\n",
      "92 Train Loss 0.7032888 Test MSE 6.498703847632599 Test RE 1.2184884962728977\n",
      "93 Train Loss 0.70068395 Test MSE 6.508534973366252 Test RE 1.2194098020338378\n",
      "94 Train Loss 0.697725 Test MSE 6.513889813720387 Test RE 1.219911328285325\n",
      "95 Train Loss 0.6938913 Test MSE 6.525203685485054 Test RE 1.2209702909667612\n",
      "96 Train Loss 0.69100505 Test MSE 6.518708060908484 Test RE 1.2203624218681144\n",
      "97 Train Loss 0.68845266 Test MSE 6.518315983154701 Test RE 1.2203257210258929\n",
      "98 Train Loss 0.6852519 Test MSE 6.5323585457743745 Test RE 1.221639502141608\n",
      "99 Train Loss 0.6824878 Test MSE 6.537878167277698 Test RE 1.2221555151421626\n",
      "100 Train Loss 0.6797771 Test MSE 6.545460403362149 Test RE 1.2228640008493021\n",
      "101 Train Loss 0.6767624 Test MSE 6.545785905320113 Test RE 1.2228944066308334\n",
      "102 Train Loss 0.6736977 Test MSE 6.552516258049186 Test RE 1.223522932851205\n",
      "103 Train Loss 0.67067844 Test MSE 6.570879310374361 Test RE 1.2252361599321273\n",
      "104 Train Loss 0.6675518 Test MSE 6.583987369918145 Test RE 1.2264576453770701\n",
      "105 Train Loss 0.66404164 Test MSE 6.588883974713883 Test RE 1.2269136275863246\n",
      "106 Train Loss 0.6612464 Test MSE 6.5887717016358085 Test RE 1.2269031743777967\n",
      "107 Train Loss 0.65772617 Test MSE 6.601056167862613 Test RE 1.2280463944374111\n",
      "108 Train Loss 0.655435 Test MSE 6.609619446707284 Test RE 1.2288426833285773\n",
      "109 Train Loss 0.6525168 Test MSE 6.617328676443283 Test RE 1.2295591141209654\n",
      "110 Train Loss 0.65009093 Test MSE 6.628929492275582 Test RE 1.230636410074912\n",
      "111 Train Loss 0.6473492 Test MSE 6.635013458781953 Test RE 1.231201013574515\n",
      "112 Train Loss 0.64400774 Test MSE 6.662749730866001 Test RE 1.2337717176748497\n",
      "113 Train Loss 0.64019585 Test MSE 6.682865861795197 Test RE 1.2356328117810886\n",
      "114 Train Loss 0.6381599 Test MSE 6.686472032314248 Test RE 1.2359661494355623\n",
      "115 Train Loss 0.6350007 Test MSE 6.710988145822411 Test RE 1.23822992636822\n",
      "116 Train Loss 0.63160956 Test MSE 6.728325900067774 Test RE 1.2398283704363182\n",
      "117 Train Loss 0.62851745 Test MSE 6.740954448491773 Test RE 1.2409913560644155\n",
      "118 Train Loss 0.6252121 Test MSE 6.746828185797933 Test RE 1.2415319078584142\n",
      "119 Train Loss 0.62192124 Test MSE 6.748285428198571 Test RE 1.2416659793958809\n",
      "120 Train Loss 0.6194369 Test MSE 6.750084963856023 Test RE 1.241831523168985\n",
      "121 Train Loss 0.61569726 Test MSE 6.756267897740049 Test RE 1.2424001385857204\n",
      "122 Train Loss 0.61333 Test MSE 6.770844300939355 Test RE 1.2437396331396955\n",
      "123 Train Loss 0.61089545 Test MSE 6.779933946146023 Test RE 1.244574193781947\n",
      "124 Train Loss 0.6081921 Test MSE 6.788988139496002 Test RE 1.2454049434506818\n",
      "125 Train Loss 0.6055304 Test MSE 6.80336642848046 Test RE 1.2467230574841457\n",
      "126 Train Loss 0.6028781 Test MSE 6.828499043005375 Test RE 1.2490237218793003\n",
      "127 Train Loss 0.60041535 Test MSE 6.8437120473218584 Test RE 1.2504142787032742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 Train Loss 0.5974333 Test MSE 6.8534606536685425 Test RE 1.2513045454622522\n",
      "129 Train Loss 0.59472454 Test MSE 6.870565304318165 Test RE 1.2528650555836234\n",
      "130 Train Loss 0.59073055 Test MSE 6.8708715595370995 Test RE 1.2528929784814622\n",
      "131 Train Loss 0.5883818 Test MSE 6.869954214554037 Test RE 1.2528093374583924\n",
      "132 Train Loss 0.5850567 Test MSE 6.874351390198318 Test RE 1.2532102092344453\n",
      "133 Train Loss 0.5820697 Test MSE 6.880573917249613 Test RE 1.2537772714999824\n",
      "134 Train Loss 0.5795944 Test MSE 6.897079956030591 Test RE 1.255280234767292\n",
      "135 Train Loss 0.57714254 Test MSE 6.907338692847455 Test RE 1.2562134416214126\n",
      "136 Train Loss 0.57462233 Test MSE 6.9126976711741355 Test RE 1.2567006564282253\n",
      "137 Train Loss 0.572636 Test MSE 6.927146630981469 Test RE 1.2580133522485673\n",
      "138 Train Loss 0.56977284 Test MSE 6.9420903077117995 Test RE 1.2593695540151928\n",
      "139 Train Loss 0.56717867 Test MSE 6.940359739680533 Test RE 1.2592125724408232\n",
      "140 Train Loss 0.5649495 Test MSE 6.945664642293308 Test RE 1.2596937235864325\n",
      "141 Train Loss 0.56252575 Test MSE 6.967873976702518 Test RE 1.2617061033677544\n",
      "142 Train Loss 0.5604659 Test MSE 6.9738315371659025 Test RE 1.2622453700371343\n",
      "143 Train Loss 0.55812967 Test MSE 6.977646788340372 Test RE 1.2625905980964167\n",
      "144 Train Loss 0.55567473 Test MSE 6.996171110727623 Test RE 1.264265455929599\n",
      "145 Train Loss 0.55330247 Test MSE 6.995932014368105 Test RE 1.2642438524091963\n",
      "146 Train Loss 0.55146724 Test MSE 7.00182974594215 Test RE 1.2647766334669228\n",
      "147 Train Loss 0.5497086 Test MSE 7.01216539249292 Test RE 1.2657097798133936\n",
      "148 Train Loss 0.548251 Test MSE 7.011352892679491 Test RE 1.265636448774122\n",
      "149 Train Loss 0.54637694 Test MSE 7.0146396090303345 Test RE 1.2659330606186323\n",
      "Training time: 230.82\n",
      "2\n",
      "KG_rowdy_tune60\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 48.715244 Test MSE 8.27037166878011 Test RE 1.3745817507655849\n",
      "1 Train Loss 40.705948 Test MSE 7.873462225420058 Test RE 1.341191938602943\n",
      "2 Train Loss 32.925858 Test MSE 6.9403859770252385 Test RE 1.2592149526029717\n",
      "3 Train Loss 26.295761 Test MSE 6.734072751855747 Test RE 1.2403577435079856\n",
      "4 Train Loss 20.339825 Test MSE 6.2940607201791625 Test RE 1.1991500349500355\n",
      "5 Train Loss 16.530293 Test MSE 6.230700774133681 Test RE 1.1930990716588117\n",
      "6 Train Loss 14.06142 Test MSE 6.0626624538818925 Test RE 1.176900520160712\n",
      "7 Train Loss 12.31267 Test MSE 5.895569423708774 Test RE 1.1605689285196232\n",
      "8 Train Loss 10.561622 Test MSE 5.8483588473184 Test RE 1.1559127829730942\n",
      "9 Train Loss 9.268694 Test MSE 5.808117801042515 Test RE 1.1519291499453068\n",
      "10 Train Loss 8.173218 Test MSE 5.639044018415901 Test RE 1.1350390482626695\n",
      "11 Train Loss 7.211262 Test MSE 5.443499925137591 Test RE 1.1151856462808973\n",
      "12 Train Loss 6.2434416 Test MSE 5.393840678785191 Test RE 1.110087257320306\n",
      "13 Train Loss 5.0968347 Test MSE 5.2648242048222 Test RE 1.0967306923439772\n",
      "14 Train Loss 4.455904 Test MSE 5.003396335439275 Test RE 1.0691546111200474\n",
      "15 Train Loss 3.823287 Test MSE 4.905681121382081 Test RE 1.0586629581333815\n",
      "16 Train Loss 3.2406716 Test MSE 4.574218376547956 Test RE 1.022272098361375\n",
      "17 Train Loss 2.955221 Test MSE 4.286017737294265 Test RE 0.9895438460528915\n",
      "18 Train Loss 2.6943762 Test MSE 3.929543953429119 Test RE 0.9474998190969424\n",
      "19 Train Loss 2.4657803 Test MSE 3.565365645527377 Test RE 0.9025267815679402\n",
      "20 Train Loss 2.206068 Test MSE 3.1062659127414705 Test RE 0.8424174914890837\n",
      "21 Train Loss 2.0524123 Test MSE 2.6905264314682196 Test RE 0.7840191880441733\n",
      "22 Train Loss 1.8343701 Test MSE 2.3062750402520655 Test RE 0.7258779594788439\n",
      "23 Train Loss 1.6276611 Test MSE 1.9572726105974363 Test RE 0.6687036899446934\n",
      "24 Train Loss 1.5247068 Test MSE 1.7165335547093459 Test RE 0.6262304902846673\n",
      "25 Train Loss 1.4083054 Test MSE 1.405931939889825 Test RE 0.566748277601683\n",
      "26 Train Loss 1.2881782 Test MSE 1.054152202300815 Test RE 0.4907493358039678\n",
      "27 Train Loss 0.9660101 Test MSE 0.5375946091303263 Test RE 0.3504576244592814\n",
      "28 Train Loss 0.6640618 Test MSE 0.317363823227652 Test RE 0.26926925574534166\n",
      "29 Train Loss 0.4276365 Test MSE 0.28156233665333846 Test RE 0.2536269158500698\n",
      "30 Train Loss 0.31832808 Test MSE 0.21846746304115894 Test RE 0.22340940041455976\n",
      "31 Train Loss 0.24561304 Test MSE 0.1351978937342233 Test RE 0.17574906497130638\n",
      "32 Train Loss 0.1749384 Test MSE 0.08359190824896577 Test RE 0.13819431579700783\n",
      "33 Train Loss 0.1345619 Test MSE 0.06127875903209162 Test RE 0.11832132956662958\n",
      "34 Train Loss 0.109159425 Test MSE 0.060912041727764765 Test RE 0.11796675653592321\n",
      "35 Train Loss 0.0918764 Test MSE 0.05112022199108323 Test RE 0.10806981943098963\n",
      "36 Train Loss 0.07982487 Test MSE 0.03604803021117916 Test RE 0.09075045882389805\n",
      "37 Train Loss 0.06175524 Test MSE 0.021883045877245773 Test RE 0.07070692422541336\n",
      "38 Train Loss 0.052755427 Test MSE 0.016748538838903634 Test RE 0.061858092352634\n",
      "39 Train Loss 0.04499728 Test MSE 0.013371362077318613 Test RE 0.05527081706769198\n",
      "40 Train Loss 0.03736335 Test MSE 0.010954125016777973 Test RE 0.05002612994142691\n",
      "41 Train Loss 0.031899452 Test MSE 0.009000394061494901 Test RE 0.04534598316969082\n",
      "42 Train Loss 0.027742783 Test MSE 0.009830416410140534 Test RE 0.04739079755128585\n",
      "43 Train Loss 0.02572463 Test MSE 0.009588584356721625 Test RE 0.046804251782584815\n",
      "44 Train Loss 0.023186492 Test MSE 0.00928856326514339 Test RE 0.046066193977538195\n",
      "45 Train Loss 0.021187296 Test MSE 0.009356589288210027 Test RE 0.046234572190733965\n",
      "46 Train Loss 0.019706652 Test MSE 0.009636515472816496 Test RE 0.04692108777178596\n",
      "47 Train Loss 0.018099299 Test MSE 0.010536326365853992 Test RE 0.04906283817544235\n",
      "48 Train Loss 0.016378878 Test MSE 0.010987726294561809 Test RE 0.05010279762625848\n",
      "49 Train Loss 0.015230292 Test MSE 0.011295184598049807 Test RE 0.050798948965832515\n",
      "50 Train Loss 0.014092598 Test MSE 0.010472357497848916 Test RE 0.04891367459193677\n",
      "51 Train Loss 0.013454284 Test MSE 0.00910835780066827 Test RE 0.045617145058598485\n",
      "52 Train Loss 0.012868061 Test MSE 0.008818849185191178 Test RE 0.04488632173757974\n",
      "53 Train Loss 0.011808215 Test MSE 0.007777495216515252 Test RE 0.04215294643363915\n",
      "54 Train Loss 0.010926656 Test MSE 0.007492624801757222 Test RE 0.041373765923817245\n",
      "55 Train Loss 0.010468717 Test MSE 0.007449552936940496 Test RE 0.04125467456798599\n",
      "56 Train Loss 0.010050572 Test MSE 0.007116011704439024 Test RE 0.040320544392143096\n",
      "57 Train Loss 0.009381757 Test MSE 0.007271021346167905 Test RE 0.040757334160309334\n",
      "58 Train Loss 0.008916691 Test MSE 0.007000610999491266 Test RE 0.03999226792689159\n",
      "59 Train Loss 0.008351427 Test MSE 0.006046719495151036 Test RE 0.03716789550293642\n",
      "60 Train Loss 0.007813572 Test MSE 0.00543611726650024 Test RE 0.03524134447461147\n",
      "61 Train Loss 0.007208395 Test MSE 0.005282998602073281 Test RE 0.03474147940421047\n",
      "62 Train Loss 0.006779036 Test MSE 0.004892546323139651 Test RE 0.03343301424966529\n",
      "63 Train Loss 0.0063857245 Test MSE 0.0045849856981875475 Test RE 0.0323651074319401\n",
      "64 Train Loss 0.0061443257 Test MSE 0.004619113002502555 Test RE 0.03248533530394229\n",
      "65 Train Loss 0.005860302 Test MSE 0.004362928124860046 Test RE 0.03157163617961408\n",
      "66 Train Loss 0.0055289795 Test MSE 0.004328203582868221 Test RE 0.03144574587350366\n",
      "67 Train Loss 0.005188992 Test MSE 0.004394179226112209 Test RE 0.0316845062362512\n",
      "68 Train Loss 0.004935371 Test MSE 0.00417430966018217 Test RE 0.03088164254744652\n",
      "69 Train Loss 0.004504078 Test MSE 0.004117682526028887 Test RE 0.030671462863265005\n",
      "70 Train Loss 0.0043433914 Test MSE 0.0042085748166949925 Test RE 0.031008130728911218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 Train Loss 0.0041777613 Test MSE 0.0041229398575005245 Test RE 0.030691036811598685\n",
      "72 Train Loss 0.0039961366 Test MSE 0.003994573318763173 Test RE 0.030209480622324366\n",
      "73 Train Loss 0.0039021086 Test MSE 0.003957296996063245 Test RE 0.03006819672259249\n",
      "74 Train Loss 0.0037382229 Test MSE 0.004134024639988307 Test RE 0.030732266507084643\n",
      "75 Train Loss 0.0035871137 Test MSE 0.00405620100838043 Test RE 0.030441622398852203\n",
      "76 Train Loss 0.0034236577 Test MSE 0.004101321374904872 Test RE 0.030610467399120548\n",
      "77 Train Loss 0.0032986607 Test MSE 0.004068476472019396 Test RE 0.030487651026396344\n",
      "78 Train Loss 0.0031395666 Test MSE 0.0037573337733217914 Test RE 0.029298672846970058\n",
      "79 Train Loss 0.0030107666 Test MSE 0.003738003470004165 Test RE 0.029223209423557397\n",
      "80 Train Loss 0.0028766317 Test MSE 0.003818272201908265 Test RE 0.029535307932467742\n",
      "81 Train Loss 0.0028027315 Test MSE 0.003764026683057468 Test RE 0.029324755986950425\n",
      "82 Train Loss 0.002763792 Test MSE 0.003891095591135732 Test RE 0.029815631370705923\n",
      "83 Train Loss 0.0027113622 Test MSE 0.0038034521735639 Test RE 0.029477933859381987\n",
      "84 Train Loss 0.0026234584 Test MSE 0.0036291245467454233 Test RE 0.028794463869327314\n",
      "85 Train Loss 0.0025276118 Test MSE 0.003884941081171229 Test RE 0.029792042485029452\n",
      "86 Train Loss 0.0024680821 Test MSE 0.003935823538328041 Test RE 0.029986506312067104\n",
      "87 Train Loss 0.0023522996 Test MSE 0.0037904013741030577 Test RE 0.029427316529666316\n",
      "88 Train Loss 0.0022117828 Test MSE 0.0038172301057544716 Test RE 0.029531277217852685\n",
      "89 Train Loss 0.002151524 Test MSE 0.003889439450576354 Test RE 0.029809285583179357\n",
      "90 Train Loss 0.0020510727 Test MSE 0.003942261829557461 Test RE 0.030011022524455935\n",
      "91 Train Loss 0.0019763329 Test MSE 0.0038033604231058845 Test RE 0.029477578309986256\n",
      "92 Train Loss 0.0018838069 Test MSE 0.0034642963037913497 Test RE 0.028132969508874034\n",
      "93 Train Loss 0.0018032627 Test MSE 0.003374232553899405 Test RE 0.027764864978537376\n",
      "94 Train Loss 0.0017634409 Test MSE 0.0033421719356043545 Test RE 0.027632644790223752\n",
      "95 Train Loss 0.0016810317 Test MSE 0.003093060967707382 Test RE 0.02658289651083658\n",
      "96 Train Loss 0.0016276055 Test MSE 0.003093730379845169 Test RE 0.026585772941508483\n",
      "97 Train Loss 0.0015696574 Test MSE 0.0030446374201278043 Test RE 0.02637399081875889\n",
      "98 Train Loss 0.001544014 Test MSE 0.0028916884586380766 Test RE 0.025702999696280045\n",
      "99 Train Loss 0.0015110843 Test MSE 0.0029109572285373254 Test RE 0.025788493497107535\n",
      "100 Train Loss 0.0014505413 Test MSE 0.0030396195174956183 Test RE 0.026352248214745442\n",
      "101 Train Loss 0.0014107386 Test MSE 0.0030828169267684944 Test RE 0.026538839485916243\n",
      "102 Train Loss 0.0013869576 Test MSE 0.0032101039603542538 Test RE 0.027081181570138783\n",
      "103 Train Loss 0.0013627134 Test MSE 0.003205147738294816 Test RE 0.02706026757508229\n",
      "104 Train Loss 0.0013259215 Test MSE 0.003137376816371507 Test RE 0.026772652546142202\n",
      "105 Train Loss 0.0012926336 Test MSE 0.0032034093313438893 Test RE 0.027052928110345938\n",
      "106 Train Loss 0.0012769136 Test MSE 0.0032242413688179004 Test RE 0.027140749286055893\n",
      "107 Train Loss 0.0012489809 Test MSE 0.0033190298576782637 Test RE 0.02753681075520287\n",
      "108 Train Loss 0.0012168464 Test MSE 0.0033942621703127096 Test RE 0.027847149874180938\n",
      "109 Train Loss 0.0011979301 Test MSE 0.003288159478881633 Test RE 0.02740845131039342\n",
      "110 Train Loss 0.001180508 Test MSE 0.003234267105108804 Test RE 0.02718291343642561\n",
      "111 Train Loss 0.0011665749 Test MSE 0.003303066960989173 Test RE 0.027470511703318868\n",
      "112 Train Loss 0.0011465454 Test MSE 0.003357153737215866 Test RE 0.027694509336275944\n",
      "113 Train Loss 0.0011279874 Test MSE 0.003484690799590357 Test RE 0.028215658130054132\n",
      "114 Train Loss 0.0011019893 Test MSE 0.003491311828248316 Test RE 0.02824245075478688\n",
      "115 Train Loss 0.0010838214 Test MSE 0.003482057575619503 Test RE 0.02820499546400106\n",
      "116 Train Loss 0.0010599336 Test MSE 0.003506449104572096 Test RE 0.02830360991375844\n",
      "117 Train Loss 0.0010444163 Test MSE 0.003480757404593982 Test RE 0.02819972921826697\n",
      "118 Train Loss 0.0010245506 Test MSE 0.003483961835985971 Test RE 0.028212706754334942\n",
      "119 Train Loss 0.0010025271 Test MSE 0.0035253509711380845 Test RE 0.028379794110071146\n",
      "120 Train Loss 0.0009744047 Test MSE 0.0035201184214992813 Test RE 0.0283587247433103\n",
      "121 Train Loss 0.0009516529 Test MSE 0.003489645268400048 Test RE 0.02823570925546129\n",
      "122 Train Loss 0.00092845014 Test MSE 0.00345462552380116 Test RE 0.028093674674750106\n",
      "123 Train Loss 0.00090321485 Test MSE 0.0034860940776037046 Test RE 0.0282213387527575\n",
      "124 Train Loss 0.000888617 Test MSE 0.0034842683309180733 Test RE 0.028213947706716102\n",
      "125 Train Loss 0.0008657476 Test MSE 0.003318821367553153 Test RE 0.027535945857397118\n",
      "126 Train Loss 0.0008480301 Test MSE 0.0032322047122513085 Test RE 0.027174245199576997\n",
      "127 Train Loss 0.0008357417 Test MSE 0.0032737409851151043 Test RE 0.027348292616407942\n",
      "128 Train Loss 0.0008260525 Test MSE 0.003213904947867761 Test RE 0.02709720983303436\n",
      "129 Train Loss 0.0008083667 Test MSE 0.0030820681117032828 Test RE 0.026535616153132335\n",
      "130 Train Loss 0.0007934291 Test MSE 0.0030368032899294956 Test RE 0.02634003761974894\n",
      "131 Train Loss 0.0007772002 Test MSE 0.0029516693157980835 Test RE 0.025968203782598065\n",
      "132 Train Loss 0.00076307537 Test MSE 0.0028965031693311003 Test RE 0.02572438876352916\n",
      "133 Train Loss 0.00073912786 Test MSE 0.0027947448873508847 Test RE 0.02526848158780318\n",
      "134 Train Loss 0.0007229663 Test MSE 0.0026633280322023423 Test RE 0.024667230404345316\n",
      "135 Train Loss 0.0006993691 Test MSE 0.0026529512051209586 Test RE 0.024619129420774266\n",
      "136 Train Loss 0.00068241527 Test MSE 0.002651674405037556 Test RE 0.024613204417439374\n",
      "137 Train Loss 0.00067009055 Test MSE 0.0025802882933635704 Test RE 0.02427963626691413\n",
      "138 Train Loss 0.0006531024 Test MSE 0.002471403411805766 Test RE 0.02376182982244647\n",
      "139 Train Loss 0.0006389868 Test MSE 0.002354903298887785 Test RE 0.023195011881511688\n",
      "140 Train Loss 0.00062927767 Test MSE 0.0022965481844708937 Test RE 0.02290581987508763\n",
      "141 Train Loss 0.0006215615 Test MSE 0.002266727756336173 Test RE 0.02275661916519759\n",
      "142 Train Loss 0.0006083805 Test MSE 0.0021903572699320684 Test RE 0.022369977101951273\n",
      "143 Train Loss 0.0005967574 Test MSE 0.0021754935920321786 Test RE 0.0222939470076565\n",
      "144 Train Loss 0.0005892491 Test MSE 0.00215625750116495 Test RE 0.022195164691227655\n",
      "145 Train Loss 0.00057690626 Test MSE 0.0020777730108025765 Test RE 0.021787485477302238\n",
      "146 Train Loss 0.0005681812 Test MSE 0.0020281579877193274 Test RE 0.021525782680406256\n",
      "147 Train Loss 0.0005594967 Test MSE 0.0020607014843499563 Test RE 0.021697795027912106\n",
      "148 Train Loss 0.00055205007 Test MSE 0.002121564577282152 Test RE 0.02201588703018564\n",
      "149 Train Loss 0.00054614287 Test MSE 0.0021485599952652044 Test RE 0.022155512618472144\n",
      "Training time: 230.61\n",
      "3\n",
      "KG_rowdy_tune60\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 57.023064 Test MSE 7.633103287148824 Test RE 1.3205614946113586\n",
      "1 Train Loss 49.49692 Test MSE 8.770937191125121 Test RE 1.415569056968967\n",
      "2 Train Loss 44.060036 Test MSE 9.010493276655838 Test RE 1.4347701864487257\n",
      "3 Train Loss 40.32853 Test MSE 8.741347248300436 Test RE 1.4131792328374382\n",
      "4 Train Loss 36.894577 Test MSE 9.07231939315607 Test RE 1.4396841584015518\n",
      "5 Train Loss 34.527916 Test MSE 9.172252958363604 Test RE 1.447591658912477\n",
      "6 Train Loss 32.477875 Test MSE 9.26833828524474 Test RE 1.4551541380157413\n",
      "7 Train Loss 30.56181 Test MSE 9.159667451231096 Test RE 1.4465981773157626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 29.012882 Test MSE 9.24818812465242 Test RE 1.453571462517523\n",
      "9 Train Loss 27.459759 Test MSE 9.206366376414024 Test RE 1.4502811000568319\n",
      "10 Train Loss 25.542028 Test MSE 9.297182295945964 Test RE 1.4574166728572784\n",
      "11 Train Loss 23.008915 Test MSE 9.410915067207528 Test RE 1.4663038918027693\n",
      "12 Train Loss 21.453495 Test MSE 9.263880275705734 Test RE 1.4548041361557549\n",
      "13 Train Loss 19.533203 Test MSE 8.986810152588 Test RE 1.4328833753285035\n",
      "14 Train Loss 17.976427 Test MSE 8.822929686245862 Test RE 1.4197584735328792\n",
      "15 Train Loss 16.310219 Test MSE 8.635279849221103 Test RE 1.4045793157537354\n",
      "16 Train Loss 14.751178 Test MSE 8.519471911459707 Test RE 1.3951291017027392\n",
      "17 Train Loss 13.268507 Test MSE 8.49869780070501 Test RE 1.393427103250271\n",
      "18 Train Loss 11.674837 Test MSE 8.31683545846994 Test RE 1.3784376127761648\n",
      "19 Train Loss 10.350647 Test MSE 8.244157225057682 Test RE 1.3724015285985578\n",
      "20 Train Loss 8.690638 Test MSE 8.19313986353234 Test RE 1.3681485188573885\n",
      "21 Train Loss 6.908306 Test MSE 7.759147100248438 Test RE 1.3314199281156445\n",
      "22 Train Loss 5.691698 Test MSE 7.489469909291697 Test RE 1.3080778761658083\n",
      "23 Train Loss 4.4864764 Test MSE 7.076831888900653 Test RE 1.2715326015587616\n",
      "24 Train Loss 3.5568342 Test MSE 6.576269195818867 Test RE 1.2257385682513589\n",
      "25 Train Loss 2.9517415 Test MSE 6.440195106498305 Test RE 1.212990983262168\n",
      "26 Train Loss 2.494502 Test MSE 6.564870174625881 Test RE 1.2246757863408062\n",
      "27 Train Loss 2.1832533 Test MSE 6.413494912668057 Test RE 1.2104739219196954\n",
      "28 Train Loss 1.9439318 Test MSE 6.09805203924815 Test RE 1.1803304832807417\n",
      "29 Train Loss 1.7494104 Test MSE 5.992067031500164 Test RE 1.1700283685720334\n",
      "30 Train Loss 1.6023015 Test MSE 5.781547384954916 Test RE 1.1492912625158196\n",
      "31 Train Loss 1.4638202 Test MSE 5.61601623272732 Test RE 1.1327191360211086\n",
      "32 Train Loss 1.3613217 Test MSE 5.605194458538028 Test RE 1.1316272640386784\n",
      "33 Train Loss 1.2846113 Test MSE 5.580787458956121 Test RE 1.1291608234531514\n",
      "34 Train Loss 1.2104964 Test MSE 5.597834385294733 Test RE 1.1308840609685622\n",
      "35 Train Loss 1.1505429 Test MSE 5.626073733804017 Test RE 1.1337329532453513\n",
      "36 Train Loss 1.0974497 Test MSE 5.679423966944074 Test RE 1.1390956809992292\n",
      "37 Train Loss 1.0612812 Test MSE 5.747794368610474 Test RE 1.145931536509742\n",
      "38 Train Loss 1.0362948 Test MSE 5.7532621383541285 Test RE 1.146476458612181\n",
      "39 Train Loss 1.0111026 Test MSE 5.7922648343859064 Test RE 1.150356009297658\n",
      "40 Train Loss 0.9896162 Test MSE 5.828274335873159 Test RE 1.1539262504645418\n",
      "41 Train Loss 0.965369 Test MSE 5.855594534951239 Test RE 1.1566276192784573\n",
      "42 Train Loss 0.94226557 Test MSE 5.920003502572517 Test RE 1.162971420094626\n",
      "43 Train Loss 0.92179203 Test MSE 5.970534489525508 Test RE 1.1679242232902922\n",
      "44 Train Loss 0.90642345 Test MSE 5.998958532469684 Test RE 1.1707010024504192\n",
      "45 Train Loss 0.89235425 Test MSE 6.0439069383300374 Test RE 1.1750786742109454\n",
      "46 Train Loss 0.8750284 Test MSE 6.049121222861931 Test RE 1.175585455143549\n",
      "47 Train Loss 0.86000437 Test MSE 6.064289452533364 Test RE 1.1770584282682688\n",
      "48 Train Loss 0.84762686 Test MSE 6.0795618136740535 Test RE 1.1785396535420276\n",
      "49 Train Loss 0.83429044 Test MSE 6.073193980864752 Test RE 1.1779222809516459\n",
      "50 Train Loss 0.82484895 Test MSE 6.101688324065094 Test RE 1.180682347953507\n",
      "51 Train Loss 0.8155663 Test MSE 6.10758049806588 Test RE 1.1812522809619908\n",
      "52 Train Loss 0.80471456 Test MSE 6.122055290647334 Test RE 1.1826512197951085\n",
      "53 Train Loss 0.7937582 Test MSE 6.1531208560628645 Test RE 1.1856480270140048\n",
      "54 Train Loss 0.78399587 Test MSE 6.169966998675055 Test RE 1.1872699635782744\n",
      "55 Train Loss 0.77597445 Test MSE 6.195043724742273 Test RE 1.1896802401140563\n",
      "56 Train Loss 0.76892364 Test MSE 6.201468539201732 Test RE 1.1902969826612877\n",
      "57 Train Loss 0.7628939 Test MSE 6.207840947658125 Test RE 1.1909083790568662\n",
      "58 Train Loss 0.75681466 Test MSE 6.211500019161018 Test RE 1.1912593043635296\n",
      "59 Train Loss 0.7509858 Test MSE 6.232142969546211 Test RE 1.1932371446069348\n",
      "60 Train Loss 0.7454572 Test MSE 6.250611482148884 Test RE 1.1950038734025537\n",
      "61 Train Loss 0.7388674 Test MSE 6.2784615981762855 Test RE 1.1976631338143715\n",
      "62 Train Loss 0.73422354 Test MSE 6.296699617746552 Test RE 1.1994013911597974\n",
      "63 Train Loss 0.727528 Test MSE 6.2953822436319795 Test RE 1.199275917253308\n",
      "64 Train Loss 0.72310543 Test MSE 6.296538222071082 Test RE 1.199386019659655\n",
      "65 Train Loss 0.7181468 Test MSE 6.297047577909841 Test RE 1.199434530595036\n",
      "66 Train Loss 0.71210265 Test MSE 6.330974720595871 Test RE 1.2026613381830333\n",
      "67 Train Loss 0.70814985 Test MSE 6.343055631364944 Test RE 1.2038082642330616\n",
      "68 Train Loss 0.7035845 Test MSE 6.345253367583759 Test RE 1.2040167933750379\n",
      "69 Train Loss 0.69884425 Test MSE 6.374808960491127 Test RE 1.2068176340957721\n",
      "70 Train Loss 0.6939374 Test MSE 6.3851560597646815 Test RE 1.2077966437446104\n",
      "71 Train Loss 0.6887361 Test MSE 6.398591225007634 Test RE 1.2090666534690873\n",
      "72 Train Loss 0.68525994 Test MSE 6.418207931714023 Test RE 1.2109186045007239\n",
      "73 Train Loss 0.6801677 Test MSE 6.4149905687105555 Test RE 1.2106150576905288\n",
      "74 Train Loss 0.67530334 Test MSE 6.441790937400902 Test RE 1.2131412588798973\n",
      "75 Train Loss 0.6706172 Test MSE 6.479844899744935 Test RE 1.216719212187063\n",
      "76 Train Loss 0.6668897 Test MSE 6.486803994477005 Test RE 1.2173723907920218\n",
      "77 Train Loss 0.6619122 Test MSE 6.514252875888216 Test RE 1.2199453246755587\n",
      "78 Train Loss 0.6573224 Test MSE 6.527314113847259 Test RE 1.221167722506062\n",
      "79 Train Loss 0.65352243 Test MSE 6.547131930406784 Test RE 1.2230201334696036\n",
      "80 Train Loss 0.6490481 Test MSE 6.578693205827224 Test RE 1.2259644507938046\n",
      "81 Train Loss 0.64418316 Test MSE 6.567664281928818 Test RE 1.224936378815935\n",
      "82 Train Loss 0.64062583 Test MSE 6.5711910028830935 Test RE 1.2252652193917284\n",
      "83 Train Loss 0.6370136 Test MSE 6.5907043476437694 Test RE 1.2270831013637848\n",
      "84 Train Loss 0.6331196 Test MSE 6.603165131257893 Test RE 1.2282425522945302\n",
      "85 Train Loss 0.628999 Test MSE 6.61407197890141 Test RE 1.2292565150558579\n",
      "86 Train Loss 0.6264858 Test MSE 6.623615190697077 Test RE 1.230143020886161\n",
      "87 Train Loss 0.62343967 Test MSE 6.647536596395882 Test RE 1.232362370015911\n",
      "88 Train Loss 0.6187726 Test MSE 6.653599363247085 Test RE 1.232924218967462\n",
      "89 Train Loss 0.6150922 Test MSE 6.680593432725794 Test RE 1.2354227127968738\n",
      "90 Train Loss 0.6126284 Test MSE 6.702259753729283 Test RE 1.2374244359899362\n",
      "91 Train Loss 0.60961187 Test MSE 6.712084849057523 Test RE 1.2383310974075303\n",
      "92 Train Loss 0.6069085 Test MSE 6.729526488659425 Test RE 1.2399389817104225\n",
      "93 Train Loss 0.60446125 Test MSE 6.750734256655337 Test RE 1.241891247815515\n",
      "94 Train Loss 0.6021576 Test MSE 6.7554084624924045 Test RE 1.2423211159325744\n",
      "95 Train Loss 0.59959584 Test MSE 6.7593692766908475 Test RE 1.2426852598695963\n",
      "96 Train Loss 0.5965078 Test MSE 6.76981609986792 Test RE 1.2436451941805713\n",
      "97 Train Loss 0.59401506 Test MSE 6.783026115280419 Test RE 1.244857972004783\n",
      "98 Train Loss 0.59093785 Test MSE 6.807138491898113 Test RE 1.2470686266095559\n",
      "99 Train Loss 0.5883111 Test MSE 6.802762641424636 Test RE 1.2466677339943417\n",
      "100 Train Loss 0.585953 Test MSE 6.80674345804197 Test RE 1.2470324409585358\n",
      "101 Train Loss 0.5834445 Test MSE 6.822360301023085 Test RE 1.2484621666737648\n",
      "102 Train Loss 0.58125937 Test MSE 6.826400402265779 Test RE 1.248831772412594\n",
      "103 Train Loss 0.5789465 Test MSE 6.822636115798712 Test RE 1.2484874028689348\n",
      "104 Train Loss 0.57658815 Test MSE 6.835087260087004 Test RE 1.2496261130859485\n",
      "105 Train Loss 0.5745858 Test MSE 6.846808036672212 Test RE 1.2506970807511293\n",
      "106 Train Loss 0.57229793 Test MSE 6.84098094902877 Test RE 1.2501647543917371\n",
      "107 Train Loss 0.56983125 Test MSE 6.852829468780774 Test RE 1.2512469232809524\n",
      "108 Train Loss 0.5681087 Test MSE 6.859458667995572 Test RE 1.2518519843078502\n",
      "109 Train Loss 0.56651044 Test MSE 6.863031146983107 Test RE 1.252177930784329\n",
      "110 Train Loss 0.5653659 Test MSE 6.875423462862937 Test RE 1.2533079260919595\n",
      "111 Train Loss 0.5638885 Test MSE 6.873674433259531 Test RE 1.253148502304895\n",
      "112 Train Loss 0.56220424 Test MSE 6.878540076473376 Test RE 1.2535919547054732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 Train Loss 0.5608454 Test MSE 6.889076716222303 Test RE 1.254551721767021\n",
      "114 Train Loss 0.559477 Test MSE 6.88345828376998 Test RE 1.2540400384080241\n",
      "115 Train Loss 0.55796254 Test MSE 6.878241076395059 Test RE 1.2535647085048394\n",
      "116 Train Loss 0.55655015 Test MSE 6.878386701228755 Test RE 1.253577978553385\n",
      "117 Train Loss 0.55430245 Test MSE 6.887467518771434 Test RE 1.25440518984249\n",
      "118 Train Loss 0.5523423 Test MSE 6.89175870330072 Test RE 1.2547959028258342\n",
      "119 Train Loss 0.5504704 Test MSE 6.892458634042127 Test RE 1.254859620083367\n",
      "120 Train Loss 0.54853594 Test MSE 6.893042530587589 Test RE 1.2549127718481348\n",
      "121 Train Loss 0.5461856 Test MSE 6.888881911868628 Test RE 1.2545339839862493\n",
      "122 Train Loss 0.5441178 Test MSE 6.889009540468976 Test RE 1.2545456051518404\n",
      "123 Train Loss 0.54209626 Test MSE 6.893483556282125 Test RE 1.254952916669672\n",
      "124 Train Loss 0.53973365 Test MSE 6.888157023551454 Test RE 1.254467977559924\n",
      "125 Train Loss 0.5381128 Test MSE 6.892669850718898 Test RE 1.2548788472751653\n",
      "126 Train Loss 0.5355759 Test MSE 6.910315344766241 Test RE 1.2564840890841626\n",
      "127 Train Loss 0.53367984 Test MSE 6.914388844397927 Test RE 1.256854371275185\n",
      "128 Train Loss 0.5315857 Test MSE 6.921608770746557 Test RE 1.2575103966005137\n",
      "129 Train Loss 0.5294894 Test MSE 6.935680470696486 Test RE 1.2587880131934261\n",
      "130 Train Loss 0.5276896 Test MSE 6.948346241639178 Test RE 1.2599368729505318\n",
      "131 Train Loss 0.5261863 Test MSE 6.949665798970235 Test RE 1.2600565042953937\n",
      "132 Train Loss 0.5244461 Test MSE 6.951691304102116 Test RE 1.2602401149215121\n",
      "133 Train Loss 0.5224055 Test MSE 6.959981922422928 Test RE 1.2609913750142778\n",
      "134 Train Loss 0.5207881 Test MSE 6.9591229194923185 Test RE 1.2609135566576488\n",
      "135 Train Loss 0.51927996 Test MSE 6.961688701903997 Test RE 1.2611459804642668\n",
      "136 Train Loss 0.5174383 Test MSE 6.969301390504436 Test RE 1.2618353310551351\n",
      "137 Train Loss 0.5158165 Test MSE 6.9758001203308435 Test RE 1.2624235116828917\n",
      "138 Train Loss 0.51433283 Test MSE 6.986568164486221 Test RE 1.2633974924428324\n",
      "139 Train Loss 0.51306033 Test MSE 6.98845986730636 Test RE 1.2635685213933932\n",
      "140 Train Loss 0.51150346 Test MSE 6.990200871093866 Test RE 1.263725905182449\n",
      "141 Train Loss 0.51041424 Test MSE 6.99709347561518 Test RE 1.264348792630095\n",
      "142 Train Loss 0.5090023 Test MSE 7.000350998991738 Test RE 1.2646430695688866\n",
      "143 Train Loss 0.5079408 Test MSE 7.005745586109911 Test RE 1.265130253239309\n",
      "144 Train Loss 0.50676084 Test MSE 7.00617409974576 Test RE 1.2651689441443887\n",
      "145 Train Loss 0.5051446 Test MSE 6.999930582311246 Test RE 1.2646050939713558\n",
      "146 Train Loss 0.5037338 Test MSE 7.005278681450585 Test RE 1.2650880946250103\n",
      "147 Train Loss 0.5020712 Test MSE 7.014077115961608 Test RE 1.2658823029968975\n",
      "148 Train Loss 0.5005001 Test MSE 7.020759715729614 Test RE 1.2664851885014918\n",
      "149 Train Loss 0.49886143 Test MSE 7.018815784417829 Test RE 1.266309842046403\n",
      "Training time: 229.81\n",
      "4\n",
      "KG_rowdy_tune60\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 48.285797 Test MSE 8.498709336647721 Test RE 1.3934280489533757\n",
      "1 Train Loss 39.9734 Test MSE 7.722563880187292 Test RE 1.3282774966320028\n",
      "2 Train Loss 32.268356 Test MSE 7.483947519234339 Test RE 1.3075955290541206\n",
      "3 Train Loss 26.298626 Test MSE 7.381829646837207 Test RE 1.298643869175255\n",
      "4 Train Loss 21.979042 Test MSE 6.991918077578375 Test RE 1.2638811185375824\n",
      "5 Train Loss 19.45627 Test MSE 6.912355278338067 Test RE 1.2566695332220215\n",
      "6 Train Loss 17.230371 Test MSE 6.7848512308660345 Test RE 1.2450254383270078\n",
      "7 Train Loss 15.40786 Test MSE 6.595159958933293 Test RE 1.2274978128491425\n",
      "8 Train Loss 14.22261 Test MSE 6.618209916497297 Test RE 1.229640982554698\n",
      "9 Train Loss 12.539212 Test MSE 6.180352520342437 Test RE 1.1882687722866845\n",
      "10 Train Loss 11.2308445 Test MSE 5.999964436090618 Test RE 1.1707991497379642\n",
      "11 Train Loss 9.656686 Test MSE 5.812062943475349 Test RE 1.1523203053310827\n",
      "12 Train Loss 8.041245 Test MSE 5.492047379572781 Test RE 1.1201474586038886\n",
      "13 Train Loss 6.5967703 Test MSE 5.143612188757768 Test RE 1.0840321651433706\n",
      "14 Train Loss 5.764288 Test MSE 5.096546058691116 Test RE 1.079061101013253\n",
      "15 Train Loss 5.010275 Test MSE 4.937508041463085 Test RE 1.062091585821217\n",
      "16 Train Loss 4.2169576 Test MSE 4.755705978501112 Test RE 1.0423547709427852\n",
      "17 Train Loss 3.5578146 Test MSE 4.442594372669807 Test RE 1.0074567044340625\n",
      "18 Train Loss 3.137781 Test MSE 4.351516411441449 Test RE 0.9970762535046759\n",
      "19 Train Loss 2.8527586 Test MSE 4.2182464439873435 Test RE 0.981689248965828\n",
      "20 Train Loss 2.574513 Test MSE 3.924349621757904 Test RE 0.9468733779772297\n",
      "21 Train Loss 2.369588 Test MSE 3.7536282787491 Test RE 0.9260484121843569\n",
      "22 Train Loss 2.1281455 Test MSE 3.604474779020913 Test RE 0.9074632700325931\n",
      "23 Train Loss 1.9548035 Test MSE 3.4437175825688255 Test RE 0.8869963327690157\n",
      "24 Train Loss 1.8195655 Test MSE 3.1862315105167744 Test RE 0.8531919014194776\n",
      "25 Train Loss 1.6979322 Test MSE 2.891180029804296 Test RE 0.8127287592701065\n",
      "26 Train Loss 1.5881599 Test MSE 2.663084698670183 Test RE 0.780010681388984\n",
      "27 Train Loss 1.4916414 Test MSE 2.5086707887380975 Test RE 0.7570592962608139\n",
      "28 Train Loss 1.4222412 Test MSE 2.403917819948664 Test RE 0.741084736742053\n",
      "29 Train Loss 1.3193647 Test MSE 2.2377667748957664 Test RE 0.7150155238809283\n",
      "30 Train Loss 1.2299306 Test MSE 2.056274185464668 Test RE 0.6854070575336126\n",
      "31 Train Loss 1.1679225 Test MSE 1.899270893171139 Test RE 0.6587210115780385\n",
      "32 Train Loss 1.0576452 Test MSE 1.6982522084902119 Test RE 0.6228868383602341\n",
      "33 Train Loss 0.9729974 Test MSE 1.5924754937328993 Test RE 0.6031765364902659\n",
      "34 Train Loss 0.9013794 Test MSE 1.4816313871541258 Test RE 0.5818059322067106\n",
      "35 Train Loss 0.84023947 Test MSE 1.3604254747239546 Test RE 0.5575007271227774\n",
      "36 Train Loss 0.75320643 Test MSE 1.1665957519926915 Test RE 0.5162597367525426\n",
      "37 Train Loss 0.6400802 Test MSE 0.9495645486021903 Test RE 0.46576870651866875\n",
      "38 Train Loss 0.52181065 Test MSE 0.8161140061497326 Test RE 0.431800833110706\n",
      "39 Train Loss 0.43035793 Test MSE 0.712668686431897 Test RE 0.4035077670265658\n",
      "40 Train Loss 0.37342507 Test MSE 0.6869478626277148 Test RE 0.39615938479822455\n",
      "41 Train Loss 0.30694818 Test MSE 0.6573537568564595 Test RE 0.3875320582337785\n",
      "42 Train Loss 0.256078 Test MSE 0.6199244091271446 Test RE 0.3763374420115662\n",
      "43 Train Loss 0.22320315 Test MSE 0.6152052840910816 Test RE 0.37490228618651206\n",
      "44 Train Loss 0.19378954 Test MSE 0.5921325891281798 Test RE 0.3678049266960956\n",
      "45 Train Loss 0.17524977 Test MSE 0.5518247334627577 Test RE 0.35506563516180073\n",
      "46 Train Loss 0.16063423 Test MSE 0.5409090681598044 Test RE 0.35153631138546376\n",
      "47 Train Loss 0.1417698 Test MSE 0.519358893986401 Test RE 0.3444624188501536\n",
      "48 Train Loss 0.13437393 Test MSE 0.502716503339176 Test RE 0.3388984882801949\n",
      "49 Train Loss 0.12852508 Test MSE 0.5059451357741703 Test RE 0.33998501265074665\n",
      "50 Train Loss 0.12148853 Test MSE 0.5051914558698917 Test RE 0.33973168936371506\n",
      "51 Train Loss 0.11528465 Test MSE 0.48754777990030324 Test RE 0.33374644767944145\n",
      "52 Train Loss 0.11004616 Test MSE 0.49231532892623486 Test RE 0.3353742692974914\n",
      "53 Train Loss 0.10615502 Test MSE 0.4949861839208373 Test RE 0.3362827566141761\n",
      "54 Train Loss 0.10337694 Test MSE 0.48821674424134637 Test RE 0.3339753359534173\n",
      "55 Train Loss 0.10017332 Test MSE 0.4950324408116543 Test RE 0.33629846920562034\n",
      "56 Train Loss 0.09719245 Test MSE 0.4972627556355859 Test RE 0.3370551959151495\n",
      "57 Train Loss 0.094926216 Test MSE 0.4918050193068101 Test RE 0.3352004080761357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 Train Loss 0.092941225 Test MSE 0.489155453022383 Test RE 0.33429625389846085\n",
      "59 Train Loss 0.09121854 Test MSE 0.49008062075280656 Test RE 0.3346122413856033\n",
      "60 Train Loss 0.08975214 Test MSE 0.49525149283701125 Test RE 0.3363728670704178\n",
      "61 Train Loss 0.08829511 Test MSE 0.49542394574581466 Test RE 0.33643142664193154\n",
      "62 Train Loss 0.08701904 Test MSE 0.4991914269122228 Test RE 0.337708210394854\n",
      "63 Train Loss 0.08597152 Test MSE 0.5001692524774987 Test RE 0.33803880318147694\n",
      "64 Train Loss 0.0848778 Test MSE 0.4982955812355866 Test RE 0.3374050498461741\n",
      "65 Train Loss 0.08396213 Test MSE 0.4991330648094487 Test RE 0.33768846853198803\n",
      "66 Train Loss 0.083016805 Test MSE 0.5033239996573139 Test RE 0.33910319353893775\n",
      "67 Train Loss 0.082120106 Test MSE 0.5030003106149745 Test RE 0.33899413690632857\n",
      "68 Train Loss 0.081095956 Test MSE 0.5043124767977584 Test RE 0.3394360123038928\n",
      "69 Train Loss 0.080204196 Test MSE 0.5061958372851308 Test RE 0.34006923541945144\n",
      "70 Train Loss 0.07965173 Test MSE 0.5063985024507406 Test RE 0.3401373052116559\n",
      "71 Train Loss 0.079118274 Test MSE 0.5086754854244735 Test RE 0.34090114850427267\n",
      "72 Train Loss 0.07860465 Test MSE 0.5124665467678496 Test RE 0.34216912600103844\n",
      "73 Train Loss 0.078051716 Test MSE 0.5125978941623391 Test RE 0.34221297290583114\n",
      "74 Train Loss 0.0772538 Test MSE 0.5095889495321467 Test RE 0.3412071012153922\n",
      "75 Train Loss 0.07656021 Test MSE 0.5111166244171907 Test RE 0.34171816355611007\n",
      "76 Train Loss 0.07582524 Test MSE 0.5161274399627587 Test RE 0.34338912315709774\n",
      "77 Train Loss 0.07507497 Test MSE 0.5167371694507047 Test RE 0.3435918954359477\n",
      "78 Train Loss 0.0745284 Test MSE 0.5172839061052095 Test RE 0.3437736170448521\n",
      "79 Train Loss 0.07401932 Test MSE 0.5199948459697953 Test RE 0.3446732504563213\n",
      "80 Train Loss 0.07342753 Test MSE 0.5230026604363973 Test RE 0.34566866257248724\n",
      "81 Train Loss 0.07278636 Test MSE 0.523247752875933 Test RE 0.345749647679192\n",
      "82 Train Loss 0.071850255 Test MSE 0.5219149269022239 Test RE 0.3453090170816626\n",
      "83 Train Loss 0.07128971 Test MSE 0.5261406473706794 Test RE 0.34670410813610997\n",
      "84 Train Loss 0.07084314 Test MSE 0.5285787034366486 Test RE 0.347506466869312\n",
      "85 Train Loss 0.0703663 Test MSE 0.5294096349573398 Test RE 0.34777950159720966\n",
      "86 Train Loss 0.06978379 Test MSE 0.5364598312441397 Test RE 0.35008754852898066\n",
      "87 Train Loss 0.06908934 Test MSE 0.5433443726615079 Test RE 0.3523267737613091\n",
      "88 Train Loss 0.06849136 Test MSE 0.5452866503354116 Test RE 0.35295593824703114\n",
      "89 Train Loss 0.06807594 Test MSE 0.5461977979464314 Test RE 0.35325070131288777\n",
      "90 Train Loss 0.067587644 Test MSE 0.550581928483416 Test RE 0.3546655750964866\n",
      "91 Train Loss 0.067125216 Test MSE 0.5517065755777831 Test RE 0.355027619422397\n",
      "92 Train Loss 0.06666294 Test MSE 0.5494985297402175 Test RE 0.3543164595269084\n",
      "93 Train Loss 0.06603834 Test MSE 0.5517035245441223 Test RE 0.355026637738688\n",
      "94 Train Loss 0.06564598 Test MSE 0.5504013721684639 Test RE 0.3546074163040655\n",
      "95 Train Loss 0.06523291 Test MSE 0.5489390853216808 Test RE 0.354136048813611\n",
      "96 Train Loss 0.06488294 Test MSE 0.5489769184179434 Test RE 0.3541482522007819\n",
      "97 Train Loss 0.06459627 Test MSE 0.5475281860570391 Test RE 0.3536806505996563\n",
      "98 Train Loss 0.064165935 Test MSE 0.5463837084893588 Test RE 0.35331081455624946\n",
      "99 Train Loss 0.063909404 Test MSE 0.5474790709805777 Test RE 0.35366478708594407\n",
      "100 Train Loss 0.06361008 Test MSE 0.5479256341258671 Test RE 0.35380899485177064\n",
      "101 Train Loss 0.06326954 Test MSE 0.5455274560882281 Test RE 0.35303386463569536\n",
      "102 Train Loss 0.062824234 Test MSE 0.5459633479248519 Test RE 0.35317487848447005\n",
      "103 Train Loss 0.062452897 Test MSE 0.5496074452961787 Test RE 0.3543515721432545\n",
      "104 Train Loss 0.062048174 Test MSE 0.5495872046367244 Test RE 0.3543450471447343\n",
      "105 Train Loss 0.061835773 Test MSE 0.5482838556371833 Test RE 0.3539246321540432\n",
      "106 Train Loss 0.06156802 Test MSE 0.5477403092446208 Test RE 0.3537491553852347\n",
      "107 Train Loss 0.06129621 Test MSE 0.5476138835077862 Test RE 0.3537083280279702\n",
      "108 Train Loss 0.06079309 Test MSE 0.5495979113074623 Test RE 0.35434849867821094\n",
      "109 Train Loss 0.060399108 Test MSE 0.5505293298698039 Test RE 0.3546486336004611\n",
      "110 Train Loss 0.060002785 Test MSE 0.551263468364582 Test RE 0.354885019255982\n",
      "111 Train Loss 0.05962044 Test MSE 0.5511439951284183 Test RE 0.3548465607314684\n",
      "112 Train Loss 0.059276093 Test MSE 0.5496909777711821 Test RE 0.3543784993068986\n",
      "113 Train Loss 0.058932107 Test MSE 0.5507398871069575 Test RE 0.35471644715167944\n",
      "114 Train Loss 0.05858184 Test MSE 0.5516380286558392 Test RE 0.3550055634894514\n",
      "115 Train Loss 0.05839347 Test MSE 0.5514320093556033 Test RE 0.35493926564201694\n",
      "116 Train Loss 0.058162723 Test MSE 0.5526879342105911 Test RE 0.3553432352200731\n",
      "117 Train Loss 0.0578498 Test MSE 0.5543909808020248 Test RE 0.35589028951321433\n",
      "118 Train Loss 0.057575125 Test MSE 0.5550517046178148 Test RE 0.35610230159347095\n",
      "119 Train Loss 0.057290245 Test MSE 0.5555704113914205 Test RE 0.35626865505220184\n",
      "120 Train Loss 0.056977376 Test MSE 0.5550480148627913 Test RE 0.3561011179808193\n",
      "121 Train Loss 0.056746356 Test MSE 0.5561973945770392 Test RE 0.3564696300011107\n",
      "122 Train Loss 0.05653656 Test MSE 0.5577437368771585 Test RE 0.3569648152318895\n",
      "123 Train Loss 0.056353517 Test MSE 0.5570147282120664 Test RE 0.3567314504116977\n",
      "124 Train Loss 0.05616897 Test MSE 0.5566634687083006 Test RE 0.3566189533206389\n",
      "125 Train Loss 0.0559945 Test MSE 0.5561657044488622 Test RE 0.35645947467739814\n",
      "126 Train Loss 0.055771656 Test MSE 0.5563425231485758 Test RE 0.35651613377334124\n",
      "127 Train Loss 0.05556212 Test MSE 0.5578458439077045 Test RE 0.3569974887940104\n",
      "128 Train Loss 0.055376213 Test MSE 0.5581034733900686 Test RE 0.3570799152051205\n",
      "129 Train Loss 0.055171125 Test MSE 0.5608315419160229 Test RE 0.3579515734208935\n",
      "130 Train Loss 0.054921646 Test MSE 0.5633804785160378 Test RE 0.3587640825748654\n",
      "131 Train Loss 0.054670587 Test MSE 0.5648485499631585 Test RE 0.3592312168258858\n",
      "132 Train Loss 0.054340184 Test MSE 0.5671541592355204 Test RE 0.35996362851105984\n",
      "133 Train Loss 0.054041408 Test MSE 0.5683429479106393 Test RE 0.3603406835639011\n",
      "134 Train Loss 0.05378297 Test MSE 0.5710204148208472 Test RE 0.3611884697764179\n",
      "135 Train Loss 0.053521883 Test MSE 0.5715776400949186 Test RE 0.3613646581074428\n",
      "136 Train Loss 0.05323258 Test MSE 0.5733072822693244 Test RE 0.3619110050721641\n",
      "137 Train Loss 0.052873313 Test MSE 0.5755847842328912 Test RE 0.3626291505343585\n",
      "138 Train Loss 0.052578136 Test MSE 0.5732574841513993 Test RE 0.3618952867315406\n",
      "139 Train Loss 0.052208055 Test MSE 0.5746091377521775 Test RE 0.36232168244458884\n",
      "140 Train Loss 0.05199043 Test MSE 0.5779335798444643 Test RE 0.3633682897723725\n",
      "141 Train Loss 0.051753238 Test MSE 0.5780253700993303 Test RE 0.36339714459656736\n",
      "142 Train Loss 0.051588025 Test MSE 0.579932921097262 Test RE 0.3639962771384825\n",
      "143 Train Loss 0.051399484 Test MSE 0.5816359488077388 Test RE 0.36453034004072116\n",
      "144 Train Loss 0.051146634 Test MSE 0.5805636738313565 Test RE 0.36419417007132165\n",
      "145 Train Loss 0.05090091 Test MSE 0.5817377504082529 Test RE 0.36456223984718406\n",
      "146 Train Loss 0.05062197 Test MSE 0.5821706599688773 Test RE 0.3646978620655663\n",
      "147 Train Loss 0.050283913 Test MSE 0.5840070399170942 Test RE 0.36527260464510414\n",
      "148 Train Loss 0.05007931 Test MSE 0.5864434521780404 Test RE 0.36603374990964477\n",
      "149 Train Loss 0.049845256 Test MSE 0.5885670975859626 Test RE 0.36669589682422304\n",
      "Training time: 230.52\n",
      "5\n",
      "KG_rowdy_tune60\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 52.332333 Test MSE 8.454713765752594 Test RE 1.3898166648233359\n",
      "1 Train Loss 43.617023 Test MSE 8.733597739044788 Test RE 1.4125526775983124\n",
      "2 Train Loss 39.43078 Test MSE 8.77283882313378 Test RE 1.4157225038286767\n",
      "3 Train Loss 35.774437 Test MSE 9.102371284345526 Test RE 1.4420666506948432\n",
      "4 Train Loss 32.668343 Test MSE 9.569534850847573 Test RE 1.4786094397133691\n",
      "5 Train Loss 29.851343 Test MSE 9.35786233913404 Test RE 1.4621650080814002\n",
      "6 Train Loss 26.501797 Test MSE 9.139877234684155 Test RE 1.4450345849899777\n",
      "7 Train Loss 23.492329 Test MSE 9.022480480654934 Test RE 1.4357242500061926\n",
      "8 Train Loss 20.971436 Test MSE 8.583779816559355 Test RE 1.4003846598835383\n",
      "9 Train Loss 18.18172 Test MSE 8.624941383155386 Test RE 1.4037382576309156\n",
      "10 Train Loss 15.660386 Test MSE 8.523413790687457 Test RE 1.3954518209097901\n",
      "11 Train Loss 13.3107395 Test MSE 8.351527280791831 Test RE 1.381309543366303\n",
      "12 Train Loss 11.182609 Test MSE 8.061821963387775 Test RE 1.3571400337803818\n",
      "13 Train Loss 9.455943 Test MSE 7.836434714324163 Test RE 1.338034526882264\n",
      "14 Train Loss 8.014044 Test MSE 7.771592143532843 Test RE 1.3324872451595575\n",
      "15 Train Loss 6.2855825 Test MSE 7.467819505060055 Test RE 1.306185825608028\n",
      "16 Train Loss 5.168264 Test MSE 7.075801759501253 Test RE 1.2714400537347084\n",
      "17 Train Loss 4.2853384 Test MSE 6.855595485311093 Test RE 1.2514994190216244\n",
      "18 Train Loss 3.521955 Test MSE 6.684847025811417 Test RE 1.235815952510838\n",
      "19 Train Loss 2.9609003 Test MSE 6.69025110505477 Test RE 1.2363153729261933\n",
      "20 Train Loss 2.631765 Test MSE 6.548222649563202 Test RE 1.2231220037197248\n",
      "21 Train Loss 2.432247 Test MSE 6.5214742188080965 Test RE 1.2206213195733133\n",
      "22 Train Loss 2.201475 Test MSE 6.346344413255324 Test RE 1.2041203023108318\n",
      "23 Train Loss 2.0354567 Test MSE 6.240268920869255 Test RE 1.1940148087587397\n",
      "24 Train Loss 1.9043946 Test MSE 6.180849336547241 Test RE 1.1883165316431468\n",
      "25 Train Loss 1.7913749 Test MSE 6.141376960180523 Test RE 1.184516017942407\n",
      "26 Train Loss 1.6840067 Test MSE 6.2135204709389225 Test RE 1.1914530326319528\n",
      "27 Train Loss 1.5860839 Test MSE 6.235311305846615 Test RE 1.1935404187938767\n",
      "28 Train Loss 1.5304677 Test MSE 6.210785897473202 Test RE 1.191190824241602\n",
      "29 Train Loss 1.4617368 Test MSE 6.174029494777351 Test RE 1.1876607667959256\n",
      "30 Train Loss 1.3973246 Test MSE 6.015911743360772 Test RE 1.1723540509357175\n",
      "31 Train Loss 1.3339492 Test MSE 5.953752343374303 Test RE 1.166281651114772\n",
      "32 Train Loss 1.2727035 Test MSE 5.977658763955469 Test RE 1.1686208218992324\n",
      "33 Train Loss 1.2273088 Test MSE 6.034571978865198 Test RE 1.1741708549171286\n",
      "34 Train Loss 1.1908352 Test MSE 6.058625579146801 Test RE 1.1765086303640733\n",
      "35 Train Loss 1.1496534 Test MSE 6.01404201329692 Test RE 1.1721718544499322\n",
      "36 Train Loss 1.1177222 Test MSE 5.972492375834159 Test RE 1.1681157032505622\n",
      "37 Train Loss 1.0898402 Test MSE 5.944587043386779 Test RE 1.1653836092092253\n",
      "38 Train Loss 1.06682 Test MSE 5.9265269255319675 Test RE 1.1636119995849532\n",
      "39 Train Loss 1.0392876 Test MSE 5.91515075625013 Test RE 1.1624946668040246\n",
      "40 Train Loss 1.0179043 Test MSE 5.9281503464856735 Test RE 1.1637713595929737\n",
      "41 Train Loss 0.9928321 Test MSE 5.944665660864261 Test RE 1.1653913153136248\n",
      "42 Train Loss 0.97014916 Test MSE 5.958016520052049 Test RE 1.166699231538898\n",
      "43 Train Loss 0.94841295 Test MSE 5.993313749370978 Test RE 1.1701500811131427\n",
      "44 Train Loss 0.92760265 Test MSE 5.998687053459953 Test RE 1.1706745124902962\n",
      "45 Train Loss 0.91058147 Test MSE 6.007695723736955 Test RE 1.171553226786606\n",
      "46 Train Loss 0.8964723 Test MSE 6.0169101166606875 Test RE 1.1724513261681302\n",
      "47 Train Loss 0.87898296 Test MSE 6.036657489736475 Test RE 1.1743737304947093\n",
      "48 Train Loss 0.8664088 Test MSE 6.066878676450937 Test RE 1.1773096813308244\n",
      "49 Train Loss 0.8572087 Test MSE 6.067215367824345 Test RE 1.17734234924255\n",
      "50 Train Loss 0.8441677 Test MSE 6.080322342798749 Test RE 1.1786133665602534\n",
      "51 Train Loss 0.8287989 Test MSE 6.108809815046447 Test RE 1.1813711545834498\n",
      "52 Train Loss 0.81640744 Test MSE 6.143359110285709 Test RE 1.1847071557888633\n",
      "53 Train Loss 0.805634 Test MSE 6.170408689985166 Test RE 1.187312459546316\n",
      "54 Train Loss 0.79494655 Test MSE 6.208728643270587 Test RE 1.1909935235025777\n",
      "55 Train Loss 0.7864811 Test MSE 6.243892635118987 Test RE 1.1943614396954163\n",
      "56 Train Loss 0.77874535 Test MSE 6.220337680930084 Test RE 1.1921064592114192\n",
      "57 Train Loss 0.77055144 Test MSE 6.227373788316816 Test RE 1.192780491625857\n",
      "58 Train Loss 0.7627466 Test MSE 6.2545603960836464 Test RE 1.195381294265909\n",
      "59 Train Loss 0.7543994 Test MSE 6.249904687413171 Test RE 1.1949363083069393\n",
      "60 Train Loss 0.7471415 Test MSE 6.264079593049909 Test RE 1.1962906102638393\n",
      "61 Train Loss 0.7419115 Test MSE 6.27484859958623 Test RE 1.1973184810797262\n",
      "62 Train Loss 0.73571396 Test MSE 6.296850933589611 Test RE 1.1994158024667805\n",
      "63 Train Loss 0.7295978 Test MSE 6.330590762741769 Test RE 1.202624868422173\n",
      "64 Train Loss 0.7229078 Test MSE 6.3495165145754155 Test RE 1.2044211932003932\n",
      "65 Train Loss 0.71719855 Test MSE 6.351409829785282 Test RE 1.2046007485251327\n",
      "66 Train Loss 0.71179444 Test MSE 6.344759392947042 Test RE 1.203969926425885\n",
      "67 Train Loss 0.70518625 Test MSE 6.366818152667455 Test RE 1.2060610254070026\n",
      "68 Train Loss 0.69957244 Test MSE 6.395407702508214 Test RE 1.208765839614705\n",
      "69 Train Loss 0.6947741 Test MSE 6.386915526567895 Test RE 1.2079630399693528\n",
      "70 Train Loss 0.68843806 Test MSE 6.379284788265495 Test RE 1.207241220130743\n",
      "71 Train Loss 0.6830517 Test MSE 6.400336546618358 Test RE 1.2092315386919312\n",
      "72 Train Loss 0.6765164 Test MSE 6.426190165661565 Test RE 1.211671371647502\n",
      "73 Train Loss 0.67201424 Test MSE 6.43888752440408 Test RE 1.2128678374739084\n",
      "74 Train Loss 0.6678661 Test MSE 6.437706881512574 Test RE 1.2127566358546125\n",
      "75 Train Loss 0.66402197 Test MSE 6.4341164698641045 Test RE 1.2124184018439128\n",
      "76 Train Loss 0.6587644 Test MSE 6.441271634796143 Test RE 1.213092359426402\n",
      "77 Train Loss 0.65435225 Test MSE 6.457119443575191 Test RE 1.2145837609981258\n",
      "78 Train Loss 0.6502393 Test MSE 6.469883204103422 Test RE 1.2157835996379396\n",
      "79 Train Loss 0.64655286 Test MSE 6.483364028142366 Test RE 1.2170495603672749\n",
      "80 Train Loss 0.6421888 Test MSE 6.507874047359541 Test RE 1.2193478864018528\n",
      "81 Train Loss 0.638612 Test MSE 6.5250917235183294 Test RE 1.2209598159817583\n",
      "82 Train Loss 0.635669 Test MSE 6.5277049779091385 Test RE 1.2212042845147721\n",
      "83 Train Loss 0.6326302 Test MSE 6.519819342583305 Test RE 1.220466438537518\n",
      "84 Train Loss 0.6294339 Test MSE 6.537314013810369 Test RE 1.2221027841086103\n",
      "85 Train Loss 0.6264752 Test MSE 6.553549951581994 Test RE 1.2236194375996803\n",
      "86 Train Loss 0.622355 Test MSE 6.5654568712682035 Test RE 1.2247305092142342\n",
      "87 Train Loss 0.6188628 Test MSE 6.594904340680791 Test RE 1.227474024655361\n",
      "88 Train Loss 0.615546 Test MSE 6.5967742707682016 Test RE 1.227648032329475\n",
      "89 Train Loss 0.6118423 Test MSE 6.617087168636537 Test RE 1.2295366767562175\n",
      "90 Train Loss 0.6081188 Test MSE 6.631981168851232 Test RE 1.2309196437547296\n",
      "91 Train Loss 0.60362864 Test MSE 6.646304419855016 Test RE 1.2322481503833604\n",
      "92 Train Loss 0.5988985 Test MSE 6.6823087441717774 Test RE 1.2355813063957246\n",
      "93 Train Loss 0.59539515 Test MSE 6.698154768015465 Test RE 1.2370454304124348\n",
      "94 Train Loss 0.5922803 Test MSE 6.716325901898547 Test RE 1.238722257412412\n",
      "95 Train Loss 0.58807534 Test MSE 6.743862614104473 Test RE 1.2412590198835047\n",
      "96 Train Loss 0.5845559 Test MSE 6.743797636111644 Test RE 1.2412530400231048\n",
      "97 Train Loss 0.5812821 Test MSE 6.747208481855575 Test RE 1.241566897858441\n",
      "98 Train Loss 0.5773169 Test MSE 6.789858001322998 Test RE 1.2454847267334108\n",
      "99 Train Loss 0.5729238 Test MSE 6.797265821618206 Test RE 1.2461639612546966\n",
      "100 Train Loss 0.5693984 Test MSE 6.802148558367655 Test RE 1.2466114645894746\n",
      "101 Train Loss 0.5658326 Test MSE 6.821426742344298 Test RE 1.2483767451690533\n",
      "102 Train Loss 0.5631883 Test MSE 6.835494682990362 Test RE 1.2496633561154091\n",
      "103 Train Loss 0.55902135 Test MSE 6.8675903513537335 Test RE 1.2525937810957066\n",
      "104 Train Loss 0.5552691 Test MSE 6.8865932300763095 Test RE 1.2543255708040182\n",
      "105 Train Loss 0.55244243 Test MSE 6.888254788755522 Test RE 1.2544768800052535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 0.54945695 Test MSE 6.8908548425939005 Test RE 1.2547136162898807\n",
      "107 Train Loss 0.5463761 Test MSE 6.915549935799224 Test RE 1.256959894812937\n",
      "108 Train Loss 0.54322 Test MSE 6.934912654364428 Test RE 1.2587183340357464\n",
      "109 Train Loss 0.5396658 Test MSE 6.947134477250895 Test RE 1.2598270041305637\n",
      "110 Train Loss 0.5372237 Test MSE 6.948775606436815 Test RE 1.2599758004999622\n",
      "111 Train Loss 0.53406084 Test MSE 6.965587973811337 Test RE 1.26149911767785\n",
      "112 Train Loss 0.531113 Test MSE 7.0000521542016125 Test RE 1.2646160754919948\n",
      "113 Train Loss 0.5282713 Test MSE 7.0013770798402675 Test RE 1.264735749099348\n",
      "114 Train Loss 0.52499896 Test MSE 7.005798832021202 Test RE 1.2651350609278278\n",
      "115 Train Loss 0.52216685 Test MSE 7.021462590972599 Test RE 1.2665485832651573\n",
      "116 Train Loss 0.5200206 Test MSE 7.019333021645023 Test RE 1.266356500239546\n",
      "117 Train Loss 0.5179106 Test MSE 7.0256170255431964 Test RE 1.2669232213880401\n",
      "118 Train Loss 0.5152247 Test MSE 7.02821731604335 Test RE 1.2671576537259495\n",
      "119 Train Loss 0.5129917 Test MSE 7.03331900861022 Test RE 1.2676174770187318\n",
      "120 Train Loss 0.51080567 Test MSE 7.045006985148975 Test RE 1.2686703037965352\n",
      "121 Train Loss 0.50921625 Test MSE 7.04716283036654 Test RE 1.2688644020852906\n",
      "122 Train Loss 0.5074994 Test MSE 7.056228167430964 Test RE 1.2696802613849456\n",
      "123 Train Loss 0.505543 Test MSE 7.0600520699179725 Test RE 1.270024246570813\n",
      "124 Train Loss 0.5035924 Test MSE 7.07127019213484 Test RE 1.2710328533051618\n",
      "125 Train Loss 0.50179034 Test MSE 7.074511582845838 Test RE 1.271324133510115\n",
      "126 Train Loss 0.4999036 Test MSE 7.076014544228902 Test RE 1.271459171072985\n",
      "127 Train Loss 0.49827045 Test MSE 7.087472873232639 Test RE 1.2724882040329648\n",
      "128 Train Loss 0.49639508 Test MSE 7.084377333494964 Test RE 1.2722102863554403\n",
      "129 Train Loss 0.49493468 Test MSE 7.082958223310228 Test RE 1.2720828582900463\n",
      "130 Train Loss 0.49381065 Test MSE 7.0863606662759 Test RE 1.2723883570363232\n",
      "131 Train Loss 0.49249417 Test MSE 7.085838309006261 Test RE 1.2723414603577576\n",
      "132 Train Loss 0.4912523 Test MSE 7.089654956264008 Test RE 1.2726840750634656\n",
      "133 Train Loss 0.490211 Test MSE 7.094184679803192 Test RE 1.2730905819043155\n",
      "134 Train Loss 0.48938674 Test MSE 7.094498338811133 Test RE 1.2731187255130079\n",
      "135 Train Loss 0.4881813 Test MSE 7.103045038964214 Test RE 1.273885353990524\n",
      "136 Train Loss 0.48720604 Test MSE 7.1187901750495515 Test RE 1.2752964667748163\n",
      "137 Train Loss 0.48599038 Test MSE 7.125943594031286 Test RE 1.2759370559130367\n",
      "138 Train Loss 0.48474026 Test MSE 7.133531865194999 Test RE 1.2766162347494556\n",
      "139 Train Loss 0.4837368 Test MSE 7.142793766917209 Test RE 1.2774447204767536\n",
      "140 Train Loss 0.48262477 Test MSE 7.141366193887295 Test RE 1.2773170577709452\n",
      "141 Train Loss 0.48191047 Test MSE 7.141037378576504 Test RE 1.2772876511960232\n",
      "142 Train Loss 0.48082525 Test MSE 7.1364489328536465 Test RE 1.2768772271564368\n",
      "143 Train Loss 0.47974715 Test MSE 7.147245160347293 Test RE 1.2778427106437744\n",
      "144 Train Loss 0.47866696 Test MSE 7.161216753779517 Test RE 1.2790910784999758\n",
      "145 Train Loss 0.47774988 Test MSE 7.155236917473888 Test RE 1.2785569267673895\n",
      "146 Train Loss 0.47657865 Test MSE 7.165568268439059 Test RE 1.2794796394446029\n",
      "147 Train Loss 0.4757427 Test MSE 7.17439755108558 Test RE 1.2802676725176034\n",
      "148 Train Loss 0.47507495 Test MSE 7.1768466046151635 Test RE 1.2804861700643735\n",
      "149 Train Loss 0.47420532 Test MSE 7.189819257181726 Test RE 1.2816429317571503\n",
      "Training time: 230.75\n",
      "6\n",
      "KG_rowdy_tune60\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 52.354534 Test MSE 9.547073964010789 Test RE 1.4768731803111526\n",
      "1 Train Loss 42.406723 Test MSE 8.829554863484672 Test RE 1.4202914249866636\n",
      "2 Train Loss 37.59379 Test MSE 9.597413929907752 Test RE 1.4807617015730568\n",
      "3 Train Loss 34.640556 Test MSE 9.51485318821412 Test RE 1.4743788968459544\n",
      "4 Train Loss 32.42443 Test MSE 9.41098657980718 Test RE 1.4663094629402855\n",
      "5 Train Loss 30.468609 Test MSE 9.44045297821899 Test RE 1.468603223028634\n",
      "6 Train Loss 27.630264 Test MSE 9.117439011316034 Test RE 1.443259728911264\n",
      "7 Train Loss 24.36539 Test MSE 8.97753554082285 Test RE 1.4321437988095231\n",
      "8 Train Loss 21.166426 Test MSE 8.77677968902498 Test RE 1.4160404480096802\n",
      "9 Train Loss 18.788628 Test MSE 8.641983558527382 Test RE 1.405124408957203\n",
      "10 Train Loss 15.669107 Test MSE 8.081197624563554 Test RE 1.3587699199895105\n",
      "11 Train Loss 13.568338 Test MSE 7.935043650855737 Test RE 1.3464267159105041\n",
      "12 Train Loss 11.201616 Test MSE 8.052358153378279 Test RE 1.3563432233923223\n",
      "13 Train Loss 9.072154 Test MSE 7.958780751540162 Test RE 1.3484390804235726\n",
      "14 Train Loss 7.3962774 Test MSE 7.799605795952084 Test RE 1.3348866413293858\n",
      "15 Train Loss 6.0202055 Test MSE 7.527534992132652 Test RE 1.311397803127022\n",
      "16 Train Loss 4.811259 Test MSE 7.581016040023746 Test RE 1.3160481167458862\n",
      "17 Train Loss 3.9732893 Test MSE 7.39591474996077 Test RE 1.299882235311544\n",
      "18 Train Loss 3.4879425 Test MSE 7.124228789860655 Test RE 1.275783524398071\n",
      "19 Train Loss 3.094719 Test MSE 7.126474313863245 Test RE 1.27598456909379\n",
      "20 Train Loss 2.8297682 Test MSE 7.109976101175299 Test RE 1.2745067231174891\n",
      "21 Train Loss 2.6087177 Test MSE 7.027034016519472 Test RE 1.2670509773029937\n",
      "22 Train Loss 2.407731 Test MSE 7.000402332012344 Test RE 1.2646477063242254\n",
      "23 Train Loss 2.2255514 Test MSE 6.987774951815271 Test RE 1.2635066008217302\n",
      "24 Train Loss 2.061889 Test MSE 6.865453050373713 Test RE 1.2523988525905414\n",
      "25 Train Loss 1.88552 Test MSE 6.885697034067904 Test RE 1.2542439514817432\n",
      "26 Train Loss 1.7387049 Test MSE 6.874327497139186 Test RE 1.2532080313524927\n",
      "27 Train Loss 1.5980059 Test MSE 6.785178112197356 Test RE 1.2450554294540974\n",
      "28 Train Loss 1.5127847 Test MSE 6.942043213559318 Test RE 1.259365282316053\n",
      "29 Train Loss 1.4272432 Test MSE 7.016222178435356 Test RE 1.2660758558338467\n",
      "30 Train Loss 1.3561345 Test MSE 6.914112862141271 Test RE 1.2568292878603815\n",
      "31 Train Loss 1.3001946 Test MSE 6.815845802245144 Test RE 1.2478659618889367\n",
      "32 Train Loss 1.2481802 Test MSE 6.707238369167071 Test RE 1.2378839464368518\n",
      "33 Train Loss 1.2138541 Test MSE 6.702416424870113 Test RE 1.237438898840695\n",
      "34 Train Loss 1.1780816 Test MSE 6.683905937876716 Test RE 1.235728960810595\n",
      "35 Train Loss 1.1501222 Test MSE 6.601647892150092 Test RE 1.2281014347654498\n",
      "36 Train Loss 1.1271874 Test MSE 6.535381456704539 Test RE 1.221922132086421\n",
      "37 Train Loss 1.1076558 Test MSE 6.471804218028994 Test RE 1.2159640792395539\n",
      "38 Train Loss 1.0883675 Test MSE 6.425771489052812 Test RE 1.211631899836769\n",
      "39 Train Loss 1.0667648 Test MSE 6.404648931784861 Test RE 1.2096388449350894\n",
      "40 Train Loss 1.0453004 Test MSE 6.300529693146022 Test RE 1.1997661139264482\n",
      "41 Train Loss 1.028421 Test MSE 6.2645786792501115 Test RE 1.1963382661272581\n",
      "42 Train Loss 1.0057243 Test MSE 6.272500474282992 Test RE 1.1970944344875112\n",
      "43 Train Loss 0.98526394 Test MSE 6.2732244819946255 Test RE 1.1971635202211104\n",
      "44 Train Loss 0.966466 Test MSE 6.242284849082492 Test RE 1.1942076573203793\n",
      "45 Train Loss 0.9537178 Test MSE 6.224245177594873 Test RE 1.1924808296187523\n",
      "46 Train Loss 0.93912196 Test MSE 6.243399009984197 Test RE 1.194314227282106\n",
      "47 Train Loss 0.9211964 Test MSE 6.208884285855009 Test RE 1.1910084515304376\n",
      "48 Train Loss 0.9017701 Test MSE 6.168664822267039 Test RE 1.1871446698353394\n",
      "49 Train Loss 0.8861742 Test MSE 6.161512817553079 Test RE 1.1864562772149678\n",
      "50 Train Loss 0.8692065 Test MSE 6.136952483451671 Test RE 1.1840892563335015\n",
      "51 Train Loss 0.85596406 Test MSE 6.132176662988714 Test RE 1.1836284332837987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 0.8431007 Test MSE 6.165601356165632 Test RE 1.186849854896275\n",
      "53 Train Loss 0.8306887 Test MSE 6.161937573754697 Test RE 1.1864971718776616\n",
      "54 Train Loss 0.8196826 Test MSE 6.15648618399246 Test RE 1.185972216078921\n",
      "55 Train Loss 0.81004167 Test MSE 6.1629842101766945 Test RE 1.1865979338872945\n",
      "56 Train Loss 0.80040646 Test MSE 6.14635156168835 Test RE 1.184995658130527\n",
      "57 Train Loss 0.79090333 Test MSE 6.158797436684787 Test RE 1.1861948125553294\n",
      "58 Train Loss 0.7830551 Test MSE 6.173376182348478 Test RE 1.1875979282503664\n",
      "59 Train Loss 0.77657855 Test MSE 6.191593301384616 Test RE 1.1893488887627273\n",
      "60 Train Loss 0.7705871 Test MSE 6.189209583608606 Test RE 1.1891199214458341\n",
      "61 Train Loss 0.76514983 Test MSE 6.178293618108785 Test RE 1.1880708278318577\n",
      "62 Train Loss 0.7592511 Test MSE 6.1993989767538284 Test RE 1.19009835233061\n",
      "63 Train Loss 0.7543616 Test MSE 6.20904964132671 Test RE 1.1910243109380232\n",
      "64 Train Loss 0.7490483 Test MSE 6.2251457941471315 Test RE 1.192567099447153\n",
      "65 Train Loss 0.7427521 Test MSE 6.246888465206249 Test RE 1.194647933638622\n",
      "66 Train Loss 0.73756397 Test MSE 6.251383645280832 Test RE 1.1950776829362764\n",
      "67 Train Loss 0.7331461 Test MSE 6.278485706446814 Test RE 1.197665433227903\n",
      "68 Train Loss 0.7279927 Test MSE 6.28943363379273 Test RE 1.1987091756079207\n",
      "69 Train Loss 0.72226405 Test MSE 6.291574275481195 Test RE 1.1989131517273712\n",
      "70 Train Loss 0.7154423 Test MSE 6.295977170106099 Test RE 1.1993325829258423\n",
      "71 Train Loss 0.7100425 Test MSE 6.300197413819247 Test RE 1.1997344766870168\n",
      "72 Train Loss 0.70456696 Test MSE 6.330137771774539 Test RE 1.2025818402144863\n",
      "73 Train Loss 0.7004136 Test MSE 6.339904314653926 Test RE 1.2035091928853352\n",
      "74 Train Loss 0.696473 Test MSE 6.339047021615653 Test RE 1.2034278198170039\n",
      "75 Train Loss 0.69177455 Test MSE 6.360060937574568 Test RE 1.2054208487089748\n",
      "76 Train Loss 0.68733704 Test MSE 6.371310463865877 Test RE 1.2064864377516542\n",
      "77 Train Loss 0.6835103 Test MSE 6.385656326424358 Test RE 1.2078439572755895\n",
      "78 Train Loss 0.67884225 Test MSE 6.40588252540121 Test RE 1.2097553330460742\n",
      "79 Train Loss 0.67502004 Test MSE 6.407347499975225 Test RE 1.209893655867539\n",
      "80 Train Loss 0.6711489 Test MSE 6.427181600013508 Test RE 1.2117648365357006\n",
      "81 Train Loss 0.66688544 Test MSE 6.446142103422766 Test RE 1.2135509033414735\n",
      "82 Train Loss 0.66320896 Test MSE 6.455693219992802 Test RE 1.2144496173073833\n",
      "83 Train Loss 0.6601863 Test MSE 6.4591558367958815 Test RE 1.2147752686186237\n",
      "84 Train Loss 0.65583 Test MSE 6.46383294414494 Test RE 1.215215001482099\n",
      "85 Train Loss 0.65211695 Test MSE 6.487405447483759 Test RE 1.2174288265432847\n",
      "86 Train Loss 0.64874214 Test MSE 6.4975820331630985 Test RE 1.218383323222012\n",
      "87 Train Loss 0.64530504 Test MSE 6.495471036845206 Test RE 1.218185387156404\n",
      "88 Train Loss 0.6416764 Test MSE 6.525967425674539 Test RE 1.2210417428969815\n",
      "89 Train Loss 0.63692963 Test MSE 6.542104268140605 Test RE 1.2225504535269953\n",
      "90 Train Loss 0.63319397 Test MSE 6.549742872766699 Test RE 1.223263974346184\n",
      "91 Train Loss 0.62894654 Test MSE 6.582502102171061 Test RE 1.2263193005848638\n",
      "92 Train Loss 0.62439257 Test MSE 6.581040030505658 Test RE 1.226183101139235\n",
      "93 Train Loss 0.61946195 Test MSE 6.594944185764483 Test RE 1.2274777327251705\n",
      "94 Train Loss 0.61566246 Test MSE 6.612095524281698 Test RE 1.2290728346198627\n",
      "95 Train Loss 0.6117829 Test MSE 6.6207868982411044 Test RE 1.2298803564943541\n",
      "96 Train Loss 0.6076782 Test MSE 6.647402822304352 Test RE 1.2323499700100222\n",
      "97 Train Loss 0.60418975 Test MSE 6.654685542798475 Test RE 1.2330248503965788\n",
      "98 Train Loss 0.6000543 Test MSE 6.662746348205841 Test RE 1.2337714044835153\n",
      "99 Train Loss 0.59468806 Test MSE 6.684627818519012 Test RE 1.2357956901107663\n",
      "100 Train Loss 0.59079856 Test MSE 6.678265420809794 Test RE 1.2352074378045501\n",
      "101 Train Loss 0.5860334 Test MSE 6.690233810021409 Test RE 1.2363137749196984\n",
      "102 Train Loss 0.58365065 Test MSE 6.7137596345605415 Test RE 1.2384855806762471\n",
      "103 Train Loss 0.58084136 Test MSE 6.7254890006924235 Test RE 1.2395669652063144\n",
      "104 Train Loss 0.5769448 Test MSE 6.740220623662577 Test RE 1.2409238066496961\n",
      "105 Train Loss 0.5730562 Test MSE 6.7522144485524604 Test RE 1.2420273912732887\n",
      "106 Train Loss 0.56895924 Test MSE 6.749204549829387 Test RE 1.2417505344443587\n",
      "107 Train Loss 0.5649149 Test MSE 6.75541375938179 Test RE 1.242321602982046\n",
      "108 Train Loss 0.5611315 Test MSE 6.766794321840224 Test RE 1.2433676061990053\n",
      "109 Train Loss 0.55731434 Test MSE 6.778657098784626 Test RE 1.2444569945500443\n",
      "110 Train Loss 0.5542308 Test MSE 6.784227404252213 Test RE 1.2449682006787175\n",
      "111 Train Loss 0.55130696 Test MSE 6.78681204795574 Test RE 1.245205331055522\n",
      "112 Train Loss 0.54893017 Test MSE 6.789458209442641 Test RE 1.245448058660922\n",
      "113 Train Loss 0.5454695 Test MSE 6.806986556675555 Test RE 1.2470547092559696\n",
      "114 Train Loss 0.54270613 Test MSE 6.827121653824588 Test RE 1.2488977440828013\n",
      "115 Train Loss 0.53887403 Test MSE 6.848047067926082 Test RE 1.2508102417059908\n",
      "116 Train Loss 0.5361548 Test MSE 6.861419577379917 Test RE 1.2520309046142424\n",
      "117 Train Loss 0.53387594 Test MSE 6.886178369132038 Test RE 1.2542877888042256\n",
      "118 Train Loss 0.53146195 Test MSE 6.909282223288157 Test RE 1.2563901607208352\n",
      "119 Train Loss 0.5288808 Test MSE 6.926626394455482 Test RE 1.2579661122506935\n",
      "120 Train Loss 0.5255006 Test MSE 6.9453303913072615 Test RE 1.2596634126689967\n",
      "121 Train Loss 0.5213832 Test MSE 6.962284721354008 Test RE 1.261199965314651\n",
      "122 Train Loss 0.5177909 Test MSE 6.98084932858543 Test RE 1.2628803113385836\n",
      "123 Train Loss 0.5135952 Test MSE 7.012336575851604 Test RE 1.2657252291872154\n",
      "124 Train Loss 0.5106237 Test MSE 7.028932878299091 Test RE 1.2672221584979495\n",
      "125 Train Loss 0.5079697 Test MSE 7.0347807559411715 Test RE 1.2677491957845561\n",
      "126 Train Loss 0.50523144 Test MSE 7.028861474453844 Test RE 1.2672157219046383\n",
      "127 Train Loss 0.50277776 Test MSE 7.038645326179711 Test RE 1.2680973681943242\n",
      "128 Train Loss 0.5002602 Test MSE 7.034773271426393 Test RE 1.2677485213861315\n",
      "129 Train Loss 0.49763274 Test MSE 7.0440599521998095 Test RE 1.2685850297178936\n",
      "130 Train Loss 0.49568254 Test MSE 7.05045027416888 Test RE 1.2691603250089385\n",
      "131 Train Loss 0.49448335 Test MSE 7.043328214284719 Test RE 1.268519137613088\n",
      "132 Train Loss 0.49260116 Test MSE 7.050763847597586 Test RE 1.269188548066634\n",
      "133 Train Loss 0.49072516 Test MSE 7.065131411249837 Test RE 1.2704810227200392\n",
      "134 Train Loss 0.48928046 Test MSE 7.065034397736925 Test RE 1.2704723000054114\n",
      "135 Train Loss 0.48776424 Test MSE 7.077256307674408 Test RE 1.2715707297936103\n",
      "136 Train Loss 0.48640624 Test MSE 7.091748880277612 Test RE 1.2728720043084496\n",
      "137 Train Loss 0.48544484 Test MSE 7.0909553376336625 Test RE 1.2728007872863565\n",
      "138 Train Loss 0.48444486 Test MSE 7.091911064229018 Test RE 1.272886559126627\n",
      "139 Train Loss 0.48330894 Test MSE 7.1056265414653454 Test RE 1.2741168208804563\n",
      "140 Train Loss 0.48219472 Test MSE 7.107698438253962 Test RE 1.2743025642577346\n",
      "141 Train Loss 0.48103368 Test MSE 7.1028459530333246 Test RE 1.2738675014760557\n",
      "142 Train Loss 0.4798302 Test MSE 7.102386014753996 Test RE 1.2738262567471286\n",
      "143 Train Loss 0.4788061 Test MSE 7.1006526021109035 Test RE 1.2736708018566227\n",
      "144 Train Loss 0.47788665 Test MSE 7.10015419648958 Test RE 1.273626100625426\n",
      "145 Train Loss 0.47706807 Test MSE 7.107039022374867 Test RE 1.2742434512520673\n",
      "146 Train Loss 0.47615153 Test MSE 7.113102610475243 Test RE 1.274786915280051\n",
      "147 Train Loss 0.47483248 Test MSE 7.108114145196165 Test RE 1.274339828688802\n",
      "148 Train Loss 0.4739309 Test MSE 7.113690723602577 Test RE 1.2748396140434735\n",
      "149 Train Loss 0.4731595 Test MSE 7.123902763916694 Test RE 1.275754332235743\n",
      "Training time: 230.77\n",
      "7\n",
      "KG_rowdy_tune60\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 52.960495 Test MSE 8.509768111057738 Test RE 1.394334339322802\n",
      "1 Train Loss 43.19994 Test MSE 8.286247103699635 Test RE 1.3759004110305055\n",
      "2 Train Loss 37.35244 Test MSE 7.711488100116994 Test RE 1.3273246402775307\n",
      "3 Train Loss 29.359238 Test MSE 6.941975506158854 Test RE 1.2593591408563423\n",
      "4 Train Loss 23.499012 Test MSE 6.308940120346423 Test RE 1.2005666164943525\n",
      "5 Train Loss 19.390625 Test MSE 6.170298296902511 Test RE 1.1873018385586867\n",
      "6 Train Loss 15.201567 Test MSE 5.718341688952276 Test RE 1.1429917913157086\n",
      "7 Train Loss 13.149082 Test MSE 5.702804739461791 Test RE 1.1414379592948545\n",
      "8 Train Loss 11.331198 Test MSE 5.875160124278703 Test RE 1.1585583565088373\n",
      "9 Train Loss 10.067794 Test MSE 5.842691761861362 Test RE 1.1553526049499834\n",
      "10 Train Loss 8.865936 Test MSE 5.811277600527656 Test RE 1.1522424502556488\n",
      "11 Train Loss 7.620675 Test MSE 5.811631988996398 Test RE 1.152277583253964\n",
      "12 Train Loss 6.2892537 Test MSE 5.6311254951226974 Test RE 1.1342418394999858\n",
      "13 Train Loss 5.1552396 Test MSE 5.48128809261041 Test RE 1.119049698919308\n",
      "14 Train Loss 4.341198 Test MSE 5.340353626242299 Test RE 1.1045695539346383\n",
      "15 Train Loss 3.6927283 Test MSE 4.904607753163746 Test RE 1.058547133509878\n",
      "16 Train Loss 3.0719388 Test MSE 4.373212426882563 Test RE 0.9995588001101686\n",
      "17 Train Loss 2.6088617 Test MSE 3.9116986453929217 Test RE 0.9453459220182923\n",
      "18 Train Loss 2.3021803 Test MSE 3.599947445999633 Test RE 0.9068931898465927\n",
      "19 Train Loss 2.0573044 Test MSE 3.18085260034711 Test RE 0.8524714294331219\n",
      "20 Train Loss 1.9090192 Test MSE 2.7448448172159434 Test RE 0.7918938284847438\n",
      "21 Train Loss 1.7704502 Test MSE 2.466522328843273 Test RE 0.7506726377218836\n",
      "22 Train Loss 1.6151775 Test MSE 2.2824374820876927 Test RE 0.7221168942290046\n",
      "23 Train Loss 1.4795593 Test MSE 1.9726840237644223 Test RE 0.6713311884757535\n",
      "24 Train Loss 1.3787358 Test MSE 1.828756179326326 Test RE 0.6463771027256889\n",
      "25 Train Loss 1.267242 Test MSE 1.6633765469571071 Test RE 0.6164577930744395\n",
      "26 Train Loss 1.1927924 Test MSE 1.6053896191042092 Test RE 0.6056173178362467\n",
      "27 Train Loss 1.1219724 Test MSE 1.4244852064792353 Test RE 0.5704755450524377\n",
      "28 Train Loss 1.0496242 Test MSE 1.050327751758145 Test RE 0.48985831079436354\n",
      "29 Train Loss 0.7384345 Test MSE 0.7521329052803523 Test RE 0.4145294162938006\n",
      "30 Train Loss 0.53158915 Test MSE 0.7418916250653328 Test RE 0.4116975613844122\n",
      "31 Train Loss 0.41111702 Test MSE 0.6245800873171143 Test RE 0.37774795971224\n",
      "32 Train Loss 0.3418702 Test MSE 0.5590908612421853 Test RE 0.35739564569415033\n",
      "33 Train Loss 0.29165956 Test MSE 0.5332577568196013 Test RE 0.3490411661862732\n",
      "34 Train Loss 0.24254343 Test MSE 0.4955964512259528 Test RE 0.3364899938691928\n",
      "35 Train Loss 0.22348493 Test MSE 0.4777591705683722 Test RE 0.3303791080289456\n",
      "36 Train Loss 0.20522125 Test MSE 0.48151306912762976 Test RE 0.3316745127875242\n",
      "37 Train Loss 0.18879661 Test MSE 0.4717701464919127 Test RE 0.32830181821270565\n",
      "38 Train Loss 0.17596704 Test MSE 0.45720789741350815 Test RE 0.3231952147725441\n",
      "39 Train Loss 0.16865854 Test MSE 0.4433024322969208 Test RE 0.31824245596867606\n",
      "40 Train Loss 0.16337197 Test MSE 0.4234769057112354 Test RE 0.31104478607253305\n",
      "41 Train Loss 0.15663534 Test MSE 0.4037120807276147 Test RE 0.3036993993783733\n",
      "42 Train Loss 0.15078709 Test MSE 0.41152726685786717 Test RE 0.3066248637340255\n",
      "43 Train Loss 0.14365917 Test MSE 0.4046459005332307 Test RE 0.30405043755520017\n",
      "44 Train Loss 0.14034694 Test MSE 0.39845780942265946 Test RE 0.30171661856745496\n",
      "45 Train Loss 0.13589503 Test MSE 0.39750646268290396 Test RE 0.30135621823158004\n",
      "46 Train Loss 0.13194154 Test MSE 0.37357076772349745 Test RE 0.29214233945347307\n",
      "47 Train Loss 0.12939475 Test MSE 0.35620537334846014 Test RE 0.285271439450058\n",
      "48 Train Loss 0.12703992 Test MSE 0.3431612454901015 Test RE 0.2799994498211756\n",
      "49 Train Loss 0.12385981 Test MSE 0.3372848815257427 Test RE 0.27759171349601397\n",
      "50 Train Loss 0.12228636 Test MSE 0.3339828556164608 Test RE 0.2762295571265707\n",
      "51 Train Loss 0.12043428 Test MSE 0.3149809236385933 Test RE 0.26825645825108035\n",
      "52 Train Loss 0.117710344 Test MSE 0.3043007862541613 Test RE 0.2636693190120786\n",
      "53 Train Loss 0.11645633 Test MSE 0.30894639791476197 Test RE 0.2656743509721\n",
      "54 Train Loss 0.114658736 Test MSE 0.29805606074648083 Test RE 0.260949842419938\n",
      "55 Train Loss 0.11147362 Test MSE 0.2712824463938638 Test RE 0.2489538843823164\n",
      "56 Train Loss 0.10845293 Test MSE 0.24688624151984076 Test RE 0.23749611206821508\n",
      "57 Train Loss 0.10517516 Test MSE 0.19601359885742495 Test RE 0.21161729637195867\n",
      "58 Train Loss 0.09002651 Test MSE 0.06553443595486864 Test RE 0.12236095086364256\n",
      "59 Train Loss 0.06411102 Test MSE 0.033320322084803226 Test RE 0.08724944150632717\n",
      "60 Train Loss 0.04707879 Test MSE 0.024714082188209356 Test RE 0.07514157668938237\n",
      "61 Train Loss 0.035315096 Test MSE 0.01933907244850023 Test RE 0.06647003086929447\n",
      "62 Train Loss 0.029286683 Test MSE 0.015537625230977651 Test RE 0.05957998386771844\n",
      "63 Train Loss 0.025975727 Test MSE 0.012700090724239244 Test RE 0.05386559630775433\n",
      "64 Train Loss 0.023319663 Test MSE 0.011856655763679468 Test RE 0.052046216724972026\n",
      "65 Train Loss 0.020687642 Test MSE 0.011971014407511351 Test RE 0.0522966099186372\n",
      "66 Train Loss 0.018642131 Test MSE 0.010731400707290515 Test RE 0.04951494102050506\n",
      "67 Train Loss 0.016797757 Test MSE 0.01039712595328775 Test RE 0.048737664367664\n",
      "68 Train Loss 0.014759687 Test MSE 0.010136170341474845 Test RE 0.04812214866781377\n",
      "69 Train Loss 0.013301723 Test MSE 0.008535451848344866 Test RE 0.04415921236616525\n",
      "70 Train Loss 0.011736826 Test MSE 0.006941071501389296 Test RE 0.03982183965991689\n",
      "71 Train Loss 0.010854654 Test MSE 0.006368163434090819 Test RE 0.03814302746517605\n",
      "72 Train Loss 0.009716938 Test MSE 0.006194453847771423 Test RE 0.037619201328302376\n",
      "73 Train Loss 0.008979763 Test MSE 0.0060394091004497925 Test RE 0.03714542098926119\n",
      "74 Train Loss 0.00786376 Test MSE 0.005246386254825598 Test RE 0.03462088704496922\n",
      "75 Train Loss 0.0069919997 Test MSE 0.004298885252645604 Test RE 0.031339061506064914\n",
      "76 Train Loss 0.0063063656 Test MSE 0.003342456439971437 Test RE 0.027633820887828748\n",
      "77 Train Loss 0.005986535 Test MSE 0.0030639200120534237 Test RE 0.026457376154765577\n",
      "78 Train Loss 0.005525424 Test MSE 0.002994316212063753 Test RE 0.02615513049208559\n",
      "79 Train Loss 0.0052294815 Test MSE 0.003093479153099042 Test RE 0.026584693469155006\n",
      "80 Train Loss 0.005028667 Test MSE 0.003251096681207911 Test RE 0.027253545099816777\n",
      "81 Train Loss 0.004847696 Test MSE 0.0028971150953386506 Test RE 0.025727105934939397\n",
      "82 Train Loss 0.0045765527 Test MSE 0.0024432642148905373 Test RE 0.023626167432230352\n",
      "83 Train Loss 0.0043071997 Test MSE 0.0021910670440583985 Test RE 0.02237360124699681\n",
      "84 Train Loss 0.0040802946 Test MSE 0.0019259387668157878 Test RE 0.02097631990963465\n",
      "85 Train Loss 0.0038543078 Test MSE 0.0017410055454243573 Test RE 0.01994381043166193\n",
      "86 Train Loss 0.0037294643 Test MSE 0.0017436304896813312 Test RE 0.019958839583314868\n",
      "87 Train Loss 0.0035942686 Test MSE 0.0016892300605557257 Test RE 0.01964501934982225\n",
      "88 Train Loss 0.0033921173 Test MSE 0.0017142725624103637 Test RE 0.01979010039355229\n",
      "89 Train Loss 0.0032543056 Test MSE 0.0017666066896479052 Test RE 0.02008991020511676\n",
      "90 Train Loss 0.0031104994 Test MSE 0.0017061033647038253 Test RE 0.01974289019159375\n",
      "91 Train Loss 0.0029820336 Test MSE 0.0015973662618180347 Test RE 0.019103384369069075\n",
      "92 Train Loss 0.0028368058 Test MSE 0.001648465053327131 Test RE 0.019406531996966087\n",
      "93 Train Loss 0.0026791797 Test MSE 0.0018129550546603342 Test RE 0.020351741560489665\n",
      "94 Train Loss 0.0025702273 Test MSE 0.0017377673122212429 Test RE 0.019925254267989027\n",
      "95 Train Loss 0.0024508708 Test MSE 0.001713323670335494 Test RE 0.019784622481471798\n",
      "96 Train Loss 0.0022969428 Test MSE 0.0016936019868576961 Test RE 0.01967042473404291\n",
      "97 Train Loss 0.0022042193 Test MSE 0.0015597744919911478 Test RE 0.01887726042074594\n",
      "98 Train Loss 0.002146226 Test MSE 0.001519160073350526 Test RE 0.018629870204245665\n",
      "99 Train Loss 0.0020767774 Test MSE 0.0014563619865890728 Test RE 0.018240751531381095\n",
      "100 Train Loss 0.0019855688 Test MSE 0.0013725846666823183 Test RE 0.01770833102761198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 Train Loss 0.0019124964 Test MSE 0.0013634390026637654 Test RE 0.01764923626576851\n",
      "102 Train Loss 0.0018488942 Test MSE 0.001330372249880525 Test RE 0.017433903950573114\n",
      "103 Train Loss 0.0017982908 Test MSE 0.001283062994111734 Test RE 0.01712111521933265\n",
      "104 Train Loss 0.0017059577 Test MSE 0.0012372025549606082 Test RE 0.016812351618002614\n",
      "105 Train Loss 0.0015646548 Test MSE 0.0013145370029476633 Test RE 0.017329836609006354\n",
      "106 Train Loss 0.0014979467 Test MSE 0.0013168352508402172 Test RE 0.017344979152470436\n",
      "107 Train Loss 0.0014302213 Test MSE 0.0012256297443033217 Test RE 0.01673353538237313\n",
      "108 Train Loss 0.0013829824 Test MSE 0.0011842505234627414 Test RE 0.016448634597553552\n",
      "109 Train Loss 0.0012997823 Test MSE 0.0011050037987729406 Test RE 0.015888757831790654\n",
      "110 Train Loss 0.0012380914 Test MSE 0.0010976698976285569 Test RE 0.0158359432757882\n",
      "111 Train Loss 0.0011977638 Test MSE 0.0010768845301611643 Test RE 0.015685292772043714\n",
      "112 Train Loss 0.0011669464 Test MSE 0.0010379100696968305 Test RE 0.015398837039059445\n",
      "113 Train Loss 0.001127431 Test MSE 0.0010116291830295956 Test RE 0.015202630316965395\n",
      "114 Train Loss 0.0010870319 Test MSE 0.0009961769367846898 Test RE 0.015086076362889968\n",
      "115 Train Loss 0.0010188706 Test MSE 0.0009147408860293543 Test RE 0.01445629845627995\n",
      "116 Train Loss 0.00096737914 Test MSE 0.0008650507922310795 Test RE 0.01405817238288861\n",
      "117 Train Loss 0.00092213217 Test MSE 0.0008637017993411113 Test RE 0.014047206683549423\n",
      "118 Train Loss 0.0008771049 Test MSE 0.0008081744464224604 Test RE 0.013588158919325063\n",
      "119 Train Loss 0.00082099397 Test MSE 0.0006756687272335697 Test RE 0.01242438697075299\n",
      "120 Train Loss 0.0007884855 Test MSE 0.0006170575670264162 Test RE 0.011873285246430096\n",
      "121 Train Loss 0.00076161046 Test MSE 0.0005966465513122284 Test RE 0.01167526179692463\n",
      "122 Train Loss 0.0007324633 Test MSE 0.0005580750654442273 Test RE 0.011291571001180497\n",
      "123 Train Loss 0.0006974075 Test MSE 0.0005136648279876359 Test RE 0.010832980839326847\n",
      "124 Train Loss 0.0006675527 Test MSE 0.0005038132756931268 Test RE 0.010728595313571967\n",
      "125 Train Loss 0.00064512715 Test MSE 0.0005007333135746025 Test RE 0.01069575147521498\n",
      "126 Train Loss 0.0006282187 Test MSE 0.0004641248930440226 Test RE 0.01029735040274814\n",
      "127 Train Loss 0.00061675184 Test MSE 0.00046031919561888263 Test RE 0.010255045771480432\n",
      "128 Train Loss 0.0005881629 Test MSE 0.0004609954434667436 Test RE 0.010262575771923358\n",
      "129 Train Loss 0.00057108176 Test MSE 0.00045699779559079285 Test RE 0.010217981519460797\n",
      "130 Train Loss 0.0005602025 Test MSE 0.0004409861965175344 Test RE 0.010037384435563264\n",
      "131 Train Loss 0.0005493143 Test MSE 0.0004241018942830479 Test RE 0.009843355413049992\n",
      "132 Train Loss 0.0005399235 Test MSE 0.0004099780415253883 Test RE 0.009678061076109594\n",
      "133 Train Loss 0.00051486696 Test MSE 0.00037450755112316875 Test RE 0.0092499279439379\n",
      "134 Train Loss 0.0004982178 Test MSE 0.0003551186984456211 Test RE 0.009007304203666442\n",
      "135 Train Loss 0.0004777771 Test MSE 0.000328359365751426 Test RE 0.008661293675878387\n",
      "136 Train Loss 0.0004571262 Test MSE 0.00030833035153354343 Test RE 0.008392980214475494\n",
      "137 Train Loss 0.00044644528 Test MSE 0.00030476969969888925 Test RE 0.008344377701249591\n",
      "138 Train Loss 0.0004378872 Test MSE 0.00028598667310721857 Test RE 0.0080831559550507\n",
      "139 Train Loss 0.00042095824 Test MSE 0.0002629302698635522 Test RE 0.0077504756089463375\n",
      "140 Train Loss 0.00040548044 Test MSE 0.000256277749626605 Test RE 0.007651798257646803\n",
      "141 Train Loss 0.00039724674 Test MSE 0.00024158353677593294 Test RE 0.007429194487257736\n",
      "142 Train Loss 0.0003910369 Test MSE 0.00024069319966466248 Test RE 0.007415491994951165\n",
      "143 Train Loss 0.00038559898 Test MSE 0.00024964308841772076 Test RE 0.007552101768118168\n",
      "144 Train Loss 0.00037852756 Test MSE 0.00024230064252993362 Test RE 0.0074402125610692\n",
      "145 Train Loss 0.00036943305 Test MSE 0.0002231612200073668 Test RE 0.007140315861144562\n",
      "146 Train Loss 0.00036278542 Test MSE 0.00021189729606502905 Test RE 0.006957781204385367\n",
      "147 Train Loss 0.00035756585 Test MSE 0.00020366541491260423 Test RE 0.006821292983178796\n",
      "148 Train Loss 0.00035181764 Test MSE 0.0001935837511241203 Test RE 0.006650319504174597\n",
      "149 Train Loss 0.00034246017 Test MSE 0.00018305633195553404 Test RE 0.006466963923197184\n",
      "Training time: 230.08\n",
      "8\n",
      "KG_rowdy_tune60\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 70.55172 Test MSE 5.2838896221933 Test RE 1.0987146838182387\n",
      "1 Train Loss 56.055996 Test MSE 6.796396456622702 Test RE 1.2460842670072003\n",
      "2 Train Loss 40.57645 Test MSE 8.268565269691994 Test RE 1.3744316257820417\n",
      "3 Train Loss 28.56657 Test MSE 7.43357184122661 Test RE 1.303187278398083\n",
      "4 Train Loss 22.234974 Test MSE 6.873164937360495 Test RE 1.2531020580151038\n",
      "5 Train Loss 18.691141 Test MSE 7.100801412493764 Test RE 1.2736841481261316\n",
      "6 Train Loss 16.541706 Test MSE 6.928393158353532 Test RE 1.2581265357584257\n",
      "7 Train Loss 14.773008 Test MSE 6.920019692834329 Test RE 1.2573660373361093\n",
      "8 Train Loss 12.997778 Test MSE 6.990977120081331 Test RE 1.263796070456689\n",
      "9 Train Loss 11.324316 Test MSE 6.933565496709753 Test RE 1.2585960704629053\n",
      "10 Train Loss 9.758551 Test MSE 6.7503331872729655 Test RE 1.241854356128258\n",
      "11 Train Loss 8.264589 Test MSE 6.631176002105152 Test RE 1.230844920559485\n",
      "12 Train Loss 7.1057324 Test MSE 6.3704547284605235 Test RE 1.2064054129894988\n",
      "13 Train Loss 6.1345086 Test MSE 6.260103192415393 Test RE 1.1959108508890888\n",
      "14 Train Loss 4.8458996 Test MSE 6.009556539083672 Test RE 1.1717346503755588\n",
      "15 Train Loss 3.926274 Test MSE 5.677938599812027 Test RE 1.1389467146659578\n",
      "16 Train Loss 3.3111763 Test MSE 5.37066459244156 Test RE 1.107699795820425\n",
      "17 Train Loss 2.8261511 Test MSE 5.212438429708755 Test RE 1.091260735769041\n",
      "18 Train Loss 2.433555 Test MSE 4.8615918148118675 Test RE 1.0538949084176956\n",
      "19 Train Loss 2.1764326 Test MSE 4.647472630970728 Test RE 1.0304252225498955\n",
      "20 Train Loss 1.9197773 Test MSE 4.248084846763249 Test RE 0.9851551940674024\n",
      "21 Train Loss 1.7203851 Test MSE 3.8919657172890054 Test RE 0.9429584645027769\n",
      "22 Train Loss 1.5214548 Test MSE 3.6093409048860012 Test RE 0.9080756118295154\n",
      "23 Train Loss 1.3679678 Test MSE 3.418971428967281 Test RE 0.8838036606978236\n",
      "24 Train Loss 1.2640748 Test MSE 3.2726033337253533 Test RE 0.8646786672726728\n",
      "25 Train Loss 1.197684 Test MSE 3.207823121044182 Test RE 0.856077863017888\n",
      "26 Train Loss 1.1474144 Test MSE 3.1629079939637528 Test RE 0.8500634429714808\n",
      "27 Train Loss 1.0912926 Test MSE 3.0436861958420187 Test RE 0.8338885249427866\n",
      "28 Train Loss 1.0530771 Test MSE 2.9617964410646493 Test RE 0.8225942392339202\n",
      "29 Train Loss 1.0270296 Test MSE 2.924557263620517 Test RE 0.8174065716766228\n",
      "30 Train Loss 0.9985626 Test MSE 2.8975369814367946 Test RE 0.8136217580704577\n",
      "31 Train Loss 0.9752423 Test MSE 2.9022262608481295 Test RE 0.8142798613823045\n",
      "32 Train Loss 0.95182747 Test MSE 2.913660961024169 Test RE 0.8158824057634235\n",
      "33 Train Loss 0.92758524 Test MSE 2.8378781203353856 Test RE 0.8052021579238166\n",
      "34 Train Loss 0.8934214 Test MSE 2.7995124648397494 Test RE 0.799740818905762\n",
      "35 Train Loss 0.85580766 Test MSE 2.785531450852507 Test RE 0.7977413310226439\n",
      "36 Train Loss 0.8327223 Test MSE 2.761600445467743 Test RE 0.7943071690795601\n",
      "37 Train Loss 0.8096409 Test MSE 2.769667830198714 Test RE 0.7954665164604745\n",
      "38 Train Loss 0.79137415 Test MSE 2.766221981630547 Test RE 0.7949715274547755\n",
      "39 Train Loss 0.77676195 Test MSE 2.776728406272658 Test RE 0.7964797926578173\n",
      "40 Train Loss 0.75754005 Test MSE 2.8099542923778618 Test RE 0.8012308968181487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 Train Loss 0.74057746 Test MSE 2.8153588694387435 Test RE 0.8020010577314273\n",
      "42 Train Loss 0.7275343 Test MSE 2.814648566374954 Test RE 0.8018998806221559\n",
      "43 Train Loss 0.7114291 Test MSE 2.844085933017301 Test RE 0.8060823602057039\n",
      "44 Train Loss 0.6995616 Test MSE 2.8741808531257527 Test RE 0.8103359494988032\n",
      "45 Train Loss 0.6866008 Test MSE 2.9040098289286798 Test RE 0.8145300314888781\n",
      "46 Train Loss 0.67050445 Test MSE 2.9100460133850827 Test RE 0.8153761204410351\n",
      "47 Train Loss 0.66154456 Test MSE 2.8899368257856484 Test RE 0.8125540042757938\n",
      "48 Train Loss 0.651724 Test MSE 2.8676207688937696 Test RE 0.8094106582445707\n",
      "49 Train Loss 0.6423671 Test MSE 2.8646497653447853 Test RE 0.808991253916137\n",
      "50 Train Loss 0.6344291 Test MSE 2.8662404163662405 Test RE 0.8092158266014887\n",
      "51 Train Loss 0.6267071 Test MSE 2.857136509815558 Test RE 0.8079296671403602\n",
      "52 Train Loss 0.6186077 Test MSE 2.8737816181076257 Test RE 0.8102796681200107\n",
      "53 Train Loss 0.60876954 Test MSE 2.8888671488318356 Test RE 0.8124036115876931\n",
      "54 Train Loss 0.6020441 Test MSE 2.897105832405297 Test RE 0.8135612229874627\n",
      "55 Train Loss 0.5947692 Test MSE 2.9015369410676866 Test RE 0.8141831541482883\n",
      "56 Train Loss 0.58733064 Test MSE 2.9190471284940718 Test RE 0.8166361740137807\n",
      "57 Train Loss 0.58021224 Test MSE 2.937466013391985 Test RE 0.819208567328581\n",
      "58 Train Loss 0.5741551 Test MSE 2.946897225238156 Test RE 0.8205226145288703\n",
      "59 Train Loss 0.5668412 Test MSE 2.9674277544799796 Test RE 0.8233758740114643\n",
      "60 Train Loss 0.55819803 Test MSE 2.968769463081765 Test RE 0.8235619957535245\n",
      "61 Train Loss 0.55098855 Test MSE 2.9638264599325708 Test RE 0.8228760944901421\n",
      "62 Train Loss 0.54213387 Test MSE 2.9709579025896686 Test RE 0.8238654857360856\n",
      "63 Train Loss 0.536096 Test MSE 2.982138900224234 Test RE 0.8254143106902254\n",
      "64 Train Loss 0.5295644 Test MSE 3.00030030727968 Test RE 0.82792390723747\n",
      "65 Train Loss 0.52173054 Test MSE 3.010598260683802 Test RE 0.8293435348710928\n",
      "66 Train Loss 0.51504153 Test MSE 3.008433724321788 Test RE 0.8290453438035549\n",
      "67 Train Loss 0.50763685 Test MSE 3.0100434766831587 Test RE 0.8292671168831953\n",
      "68 Train Loss 0.5010486 Test MSE 3.02287168705951 Test RE 0.8310323244170268\n",
      "69 Train Loss 0.49353892 Test MSE 3.0482477608504044 Test RE 0.8345131643337099\n",
      "70 Train Loss 0.48791754 Test MSE 3.0425418245937346 Test RE 0.833731746663831\n",
      "71 Train Loss 0.4837778 Test MSE 3.036601109066432 Test RE 0.8329173974273725\n",
      "72 Train Loss 0.48023623 Test MSE 3.050123449488083 Test RE 0.8347698767573474\n",
      "73 Train Loss 0.47651443 Test MSE 3.0436482149073742 Test RE 0.8338833220469664\n",
      "74 Train Loss 0.47265422 Test MSE 3.0482643149561266 Test RE 0.8345154303241209\n",
      "75 Train Loss 0.46916825 Test MSE 3.060063089720444 Test RE 0.8361289305186197\n",
      "76 Train Loss 0.46535012 Test MSE 3.0603426488757752 Test RE 0.8361671228944498\n",
      "77 Train Loss 0.46267974 Test MSE 3.0696907294045124 Test RE 0.8374432214409695\n",
      "78 Train Loss 0.45898646 Test MSE 3.0836800028413323 Test RE 0.8393492612252677\n",
      "79 Train Loss 0.45586973 Test MSE 3.09687742429832 Test RE 0.8411434518085187\n",
      "80 Train Loss 0.45300168 Test MSE 3.1025475214877267 Test RE 0.8419131277430238\n",
      "81 Train Loss 0.45009834 Test MSE 3.107708870824355 Test RE 0.8426131334636369\n",
      "82 Train Loss 0.44698423 Test MSE 3.127849139319587 Test RE 0.8453391044101543\n",
      "83 Train Loss 0.4433643 Test MSE 3.1314639997467437 Test RE 0.8458274432584285\n",
      "84 Train Loss 0.43889973 Test MSE 3.142365978361011 Test RE 0.8472985093317007\n",
      "85 Train Loss 0.43428165 Test MSE 3.17057742937178 Test RE 0.8510934380475492\n",
      "86 Train Loss 0.43049255 Test MSE 3.1767715480522543 Test RE 0.8519243910247009\n",
      "87 Train Loss 0.42612782 Test MSE 3.1840830664495154 Test RE 0.8529042035267921\n",
      "88 Train Loss 0.4213837 Test MSE 3.215648937066191 Test RE 0.8571214721174183\n",
      "89 Train Loss 0.41667753 Test MSE 3.232468315866596 Test RE 0.8593601258340421\n",
      "90 Train Loss 0.4103881 Test MSE 3.2312739675063544 Test RE 0.8592013508543791\n",
      "91 Train Loss 0.40609786 Test MSE 3.254023119709082 Test RE 0.8622205656353742\n",
      "92 Train Loss 0.4021936 Test MSE 3.2734278927663163 Test RE 0.8647875918252985\n",
      "93 Train Loss 0.39778033 Test MSE 3.2873259785164177 Test RE 0.8666214739623855\n",
      "94 Train Loss 0.39368004 Test MSE 3.3032990025410354 Test RE 0.8687243672081371\n",
      "95 Train Loss 0.38941085 Test MSE 3.3204301404400387 Test RE 0.8709740866117158\n",
      "96 Train Loss 0.38515428 Test MSE 3.339830201881657 Test RE 0.8735147727938438\n",
      "97 Train Loss 0.38173565 Test MSE 3.352251925239821 Test RE 0.8751376829249222\n",
      "98 Train Loss 0.37867478 Test MSE 3.3589998979622666 Test RE 0.8760180517762499\n",
      "99 Train Loss 0.37557754 Test MSE 3.369749573805994 Test RE 0.877418675215529\n",
      "100 Train Loss 0.3711317 Test MSE 3.399135505062963 Test RE 0.8812361394205633\n",
      "101 Train Loss 0.36712846 Test MSE 3.418004623988168 Test RE 0.8836786923832677\n",
      "102 Train Loss 0.3642588 Test MSE 3.4168371698992392 Test RE 0.8835277647918414\n",
      "103 Train Loss 0.36140496 Test MSE 3.4219538497780286 Test RE 0.8841890543618633\n",
      "104 Train Loss 0.3588802 Test MSE 3.4183482599584143 Test RE 0.8837231124742664\n",
      "105 Train Loss 0.35600898 Test MSE 3.4318631167029796 Test RE 0.8854683427323705\n",
      "106 Train Loss 0.35359597 Test MSE 3.439815449525623 Test RE 0.8864936552625816\n",
      "107 Train Loss 0.35045832 Test MSE 3.4376809125021888 Test RE 0.886218560973222\n",
      "108 Train Loss 0.34780353 Test MSE 3.44096143833545 Test RE 0.8866413124878166\n",
      "109 Train Loss 0.34543365 Test MSE 3.4373845914938523 Test RE 0.8861803650435344\n",
      "110 Train Loss 0.34302258 Test MSE 3.448755331851825 Test RE 0.8876448807434492\n",
      "111 Train Loss 0.3411417 Test MSE 3.455733712591445 Test RE 0.8885424790122639\n",
      "112 Train Loss 0.33943927 Test MSE 3.4585437302133792 Test RE 0.8889036631872678\n",
      "113 Train Loss 0.33798236 Test MSE 3.464665310964087 Test RE 0.8896899897832655\n",
      "114 Train Loss 0.33608383 Test MSE 3.459106308960444 Test RE 0.8889759563276242\n",
      "115 Train Loss 0.33481622 Test MSE 3.4645311391074225 Test RE 0.8896727626483506\n",
      "116 Train Loss 0.3335837 Test MSE 3.4710581956799564 Test RE 0.8905104246251951\n",
      "117 Train Loss 0.3321129 Test MSE 3.4602202392607606 Test RE 0.8891190825364874\n",
      "118 Train Loss 0.33085904 Test MSE 3.4614620442244655 Test RE 0.8892786118973932\n",
      "119 Train Loss 0.32922 Test MSE 3.471917571929757 Test RE 0.8906206555841677\n",
      "120 Train Loss 0.3278823 Test MSE 3.469206197454567 Test RE 0.8902728250691744\n",
      "121 Train Loss 0.32657954 Test MSE 3.4698375336331972 Test RE 0.890353828595956\n",
      "122 Train Loss 0.32542235 Test MSE 3.4740937370491602 Test RE 0.8908997281656319\n",
      "123 Train Loss 0.32438573 Test MSE 3.474565362641314 Test RE 0.8909601981593244\n",
      "124 Train Loss 0.3232066 Test MSE 3.4772749438660937 Test RE 0.8913075306026684\n",
      "125 Train Loss 0.32166868 Test MSE 3.475721117036926 Test RE 0.8911083671303353\n",
      "126 Train Loss 0.32057458 Test MSE 3.479801184367509 Test RE 0.8916312393128764\n",
      "127 Train Loss 0.31929225 Test MSE 3.480508797954362 Test RE 0.8917218908004889\n",
      "128 Train Loss 0.31830713 Test MSE 3.486816536550468 Test RE 0.892529560423324\n",
      "129 Train Loss 0.31698188 Test MSE 3.490387668163634 Test RE 0.8929864994118937\n",
      "130 Train Loss 0.3156984 Test MSE 3.4912526796552967 Test RE 0.8930971455356489\n",
      "131 Train Loss 0.31452784 Test MSE 3.5035602038997355 Test RE 0.8946699541524762\n",
      "132 Train Loss 0.31297967 Test MSE 3.5141370552593147 Test RE 0.8960193900914719\n",
      "133 Train Loss 0.31203026 Test MSE 3.5121479802725064 Test RE 0.8957657713512884\n",
      "134 Train Loss 0.3105461 Test MSE 3.5164323261278954 Test RE 0.8963119614199389\n",
      "135 Train Loss 0.30924606 Test MSE 3.515984658802238 Test RE 0.8962549060989748\n",
      "136 Train Loss 0.30786505 Test MSE 3.519715765081253 Test RE 0.8967303256395763\n",
      "137 Train Loss 0.3066388 Test MSE 3.5268070267039726 Test RE 0.8976332038982442\n",
      "138 Train Loss 0.3053047 Test MSE 3.5380638578806614 Test RE 0.8990645914582597\n",
      "139 Train Loss 0.30439085 Test MSE 3.546038750509234 Test RE 0.9000772792029927\n",
      "140 Train Loss 0.3031519 Test MSE 3.547317870478136 Test RE 0.900239601599451\n",
      "141 Train Loss 0.3013738 Test MSE 3.5539720365587337 Test RE 0.9010835543342661\n",
      "142 Train Loss 0.30014172 Test MSE 3.562290390467219 Test RE 0.9021374668274408\n",
      "143 Train Loss 0.29874653 Test MSE 3.5633599693343654 Test RE 0.9022728901992705\n",
      "144 Train Loss 0.2975438 Test MSE 3.5661437027661904 Test RE 0.9026252538228217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 Train Loss 0.29663584 Test MSE 3.568890242303662 Test RE 0.902972774703312\n",
      "146 Train Loss 0.2954506 Test MSE 3.568998948374491 Test RE 0.9029865265797061\n",
      "147 Train Loss 0.2939503 Test MSE 3.5761280426908244 Test RE 0.9038879368478206\n",
      "148 Train Loss 0.29286045 Test MSE 3.577597175089619 Test RE 0.9040735838214559\n",
      "149 Train Loss 0.29122457 Test MSE 3.580543122959999 Test RE 0.904445733823839\n",
      "Training time: 232.68\n",
      "9\n",
      "KG_rowdy_tune60\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 57.815063 Test MSE 8.719853335666443 Test RE 1.4114407453336284\n",
      "1 Train Loss 50.147057 Test MSE 8.490158537490814 Test RE 1.392726888258812\n",
      "2 Train Loss 43.606834 Test MSE 8.457025223624736 Test RE 1.3900066347750675\n",
      "3 Train Loss 39.073753 Test MSE 8.465210026030473 Test RE 1.3906791039943989\n",
      "4 Train Loss 36.290844 Test MSE 8.740397181897452 Test RE 1.413102434001094\n",
      "5 Train Loss 33.877594 Test MSE 8.775698895523254 Test RE 1.4159532580329885\n",
      "6 Train Loss 31.880802 Test MSE 9.014238686391355 Test RE 1.4350683523615586\n",
      "7 Train Loss 29.334202 Test MSE 8.929947567414061 Test RE 1.4283430131310484\n",
      "8 Train Loss 26.853937 Test MSE 8.766239432228826 Test RE 1.4151899131746317\n",
      "9 Train Loss 24.971806 Test MSE 8.823214954140957 Test RE 1.419781425559699\n",
      "10 Train Loss 23.359314 Test MSE 8.851748576119462 Test RE 1.4220753063475833\n",
      "11 Train Loss 21.857565 Test MSE 8.79405201789665 Test RE 1.417433116834369\n",
      "12 Train Loss 20.446976 Test MSE 8.768306903973807 Test RE 1.4153567859077874\n",
      "13 Train Loss 19.020615 Test MSE 8.720741114675038 Test RE 1.411512593765328\n",
      "14 Train Loss 17.947666 Test MSE 8.70004644971558 Test RE 1.4098368112826536\n",
      "15 Train Loss 16.460363 Test MSE 8.778960513577712 Test RE 1.4162163635548763\n",
      "16 Train Loss 15.54254 Test MSE 8.665676399482606 Test RE 1.4070492334055447\n",
      "17 Train Loss 14.682154 Test MSE 8.595375732438423 Test RE 1.4013302376180354\n",
      "18 Train Loss 13.897392 Test MSE 8.591350264754585 Test RE 1.4010020570719501\n",
      "19 Train Loss 12.995851 Test MSE 8.400626079796549 Test RE 1.3853639665611885\n",
      "20 Train Loss 12.13223 Test MSE 8.20935889864261 Test RE 1.369502034011818\n",
      "21 Train Loss 11.101877 Test MSE 7.951604579584941 Test RE 1.3478310216471334\n",
      "22 Train Loss 10.169212 Test MSE 7.669312558494091 Test RE 1.3236899729471974\n",
      "23 Train Loss 9.050411 Test MSE 7.437863020305778 Test RE 1.3035633696825706\n",
      "24 Train Loss 8.06967 Test MSE 7.420827696793764 Test RE 1.3020697045338625\n",
      "25 Train Loss 7.1972723 Test MSE 7.126996655902095 Test RE 1.2760313305174273\n",
      "26 Train Loss 6.123017 Test MSE 6.577456125347933 Test RE 1.225849178052919\n",
      "27 Train Loss 5.2382298 Test MSE 6.141633281687182 Test RE 1.1845407366467315\n",
      "28 Train Loss 4.556799 Test MSE 5.95772274004562 Test RE 1.1666704671731194\n",
      "29 Train Loss 3.9451444 Test MSE 5.79543113837771 Test RE 1.1506703836653667\n",
      "30 Train Loss 3.4005382 Test MSE 5.579185282068314 Test RE 1.1289987275796112\n",
      "31 Train Loss 3.0956306 Test MSE 5.561800631548638 Test RE 1.1272383843809985\n",
      "32 Train Loss 2.7861705 Test MSE 5.487773994740385 Test RE 1.1197115781068223\n",
      "33 Train Loss 2.5919528 Test MSE 5.372071853352929 Test RE 1.1078449101258525\n",
      "34 Train Loss 2.4496114 Test MSE 5.261896117693178 Test RE 1.096425670796605\n",
      "35 Train Loss 2.35113 Test MSE 5.208327432473929 Test RE 1.0908303177577903\n",
      "36 Train Loss 2.2530313 Test MSE 5.1573582260600235 Test RE 1.0854797085892518\n",
      "37 Train Loss 2.1577551 Test MSE 5.18875694960187 Test RE 1.088778971318947\n",
      "38 Train Loss 2.0940387 Test MSE 5.260314401096208 Test RE 1.0962608666092355\n",
      "39 Train Loss 2.0309513 Test MSE 5.222577585071528 Test RE 1.0923215719699495\n",
      "40 Train Loss 1.9667177 Test MSE 5.2019984011206795 Test RE 1.0901673412063795\n",
      "41 Train Loss 1.9247575 Test MSE 5.191529101093455 Test RE 1.089069778659846\n",
      "42 Train Loss 1.867228 Test MSE 5.144237420053511 Test RE 1.084098047855269\n",
      "43 Train Loss 1.8243961 Test MSE 5.143752551853076 Test RE 1.0840469560205297\n",
      "44 Train Loss 1.7792231 Test MSE 5.17062868572477 Test RE 1.0868753417468975\n",
      "45 Train Loss 1.7377489 Test MSE 5.2100155857565875 Test RE 1.0910070865584556\n",
      "46 Train Loss 1.7025129 Test MSE 5.235467839754418 Test RE 1.0936687636160727\n",
      "47 Train Loss 1.6648111 Test MSE 5.244424337426859 Test RE 1.0946038525387805\n",
      "48 Train Loss 1.6244564 Test MSE 5.282469777534893 Test RE 1.0985670549786402\n",
      "49 Train Loss 1.5788994 Test MSE 5.2757796725071024 Test RE 1.0978711818589544\n",
      "50 Train Loss 1.5444525 Test MSE 5.308724909322151 Test RE 1.1012937409452432\n",
      "51 Train Loss 1.5170124 Test MSE 5.383970244799548 Test RE 1.1090710926860627\n",
      "52 Train Loss 1.4784634 Test MSE 5.407486341311677 Test RE 1.1114905530966763\n",
      "53 Train Loss 1.4560479 Test MSE 5.4247940392502585 Test RE 1.1132679014730413\n",
      "54 Train Loss 1.4326367 Test MSE 5.433272500272903 Test RE 1.1141375301930303\n",
      "55 Train Loss 1.4082141 Test MSE 5.45375220898988 Test RE 1.1162353221966013\n",
      "56 Train Loss 1.3857666 Test MSE 5.46909491629018 Test RE 1.117804337724937\n",
      "57 Train Loss 1.363245 Test MSE 5.4181305711060155 Test RE 1.1125839580309829\n",
      "58 Train Loss 1.3379378 Test MSE 5.4321614587045834 Test RE 1.11402361023071\n",
      "59 Train Loss 1.31854 Test MSE 5.464404275165342 Test RE 1.1173248851109663\n",
      "60 Train Loss 1.2995507 Test MSE 5.460112932759374 Test RE 1.1168860664250886\n",
      "61 Train Loss 1.2814904 Test MSE 5.478284936845374 Test RE 1.1187430975377701\n",
      "62 Train Loss 1.2600791 Test MSE 5.492917526247013 Test RE 1.1202361918134247\n",
      "63 Train Loss 1.2394667 Test MSE 5.508277311062291 Test RE 1.121801350484339\n",
      "64 Train Loss 1.2236404 Test MSE 5.54324936618813 Test RE 1.1253568745471363\n",
      "65 Train Loss 1.2072637 Test MSE 5.56500193844979 Test RE 1.127562750277539\n",
      "66 Train Loss 1.1908779 Test MSE 5.573918998247343 Test RE 1.128465761641167\n",
      "67 Train Loss 1.1776886 Test MSE 5.621491059175455 Test RE 1.1332711224987349\n",
      "68 Train Loss 1.1629076 Test MSE 5.644811788657842 Test RE 1.1356193745784366\n",
      "69 Train Loss 1.151935 Test MSE 5.6743870200606805 Test RE 1.1385904504366147\n",
      "70 Train Loss 1.1388048 Test MSE 5.716724951265835 Test RE 1.1428302017642238\n",
      "71 Train Loss 1.1224359 Test MSE 5.702290813867612 Test RE 1.1413865260593699\n",
      "72 Train Loss 1.1115108 Test MSE 5.6972881968638385 Test RE 1.140885747275312\n",
      "73 Train Loss 1.1000185 Test MSE 5.7078639660113915 Test RE 1.1419441587254173\n",
      "74 Train Loss 1.0883565 Test MSE 5.737979266147143 Test RE 1.1449527052884048\n",
      "75 Train Loss 1.0766174 Test MSE 5.75707140982624 Test RE 1.1468559404876018\n",
      "76 Train Loss 1.0637004 Test MSE 5.763379182635077 Test RE 1.1474840485796314\n",
      "77 Train Loss 1.0502222 Test MSE 5.772937219945976 Test RE 1.1484351530913526\n",
      "78 Train Loss 1.0384891 Test MSE 5.765432660742128 Test RE 1.147688453273969\n",
      "79 Train Loss 1.0271974 Test MSE 5.774799699677374 Test RE 1.148620393691107\n",
      "80 Train Loss 1.0174674 Test MSE 5.798403471723221 Test RE 1.1509654210362634\n",
      "81 Train Loss 1.0078921 Test MSE 5.809404108949659 Test RE 1.1520567001771465\n",
      "82 Train Loss 0.99580127 Test MSE 5.805767633217006 Test RE 1.1516960709313024\n",
      "83 Train Loss 0.9859917 Test MSE 5.787615949707623 Test RE 1.149894277482595\n",
      "84 Train Loss 0.9753548 Test MSE 5.811322170651805 Test RE 1.152246868861515\n",
      "85 Train Loss 0.96484923 Test MSE 5.8261511451001375 Test RE 1.1537160485594637\n",
      "86 Train Loss 0.95285815 Test MSE 5.816361408132118 Test RE 1.152746341032471\n",
      "87 Train Loss 0.9419945 Test MSE 5.832960544995399 Test RE 1.1543900629814974\n",
      "88 Train Loss 0.9311291 Test MSE 5.862146610113227 Test RE 1.1572745384180794\n",
      "89 Train Loss 0.91814375 Test MSE 5.855631576392264 Test RE 1.1566312775821306\n",
      "90 Train Loss 0.91035575 Test MSE 5.851175541970122 Test RE 1.1561911056197443\n",
      "91 Train Loss 0.9034455 Test MSE 5.85197491134427 Test RE 1.1562700805359707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 0.8939091 Test MSE 5.8676344013440405 Test RE 1.1578160973257938\n",
      "93 Train Loss 0.88537127 Test MSE 5.888337638959183 Test RE 1.1598569056883512\n",
      "94 Train Loss 0.8793661 Test MSE 5.897824791430476 Test RE 1.1607908968509177\n",
      "95 Train Loss 0.87371635 Test MSE 5.8914984423241 Test RE 1.1601681639744712\n",
      "96 Train Loss 0.86754555 Test MSE 5.88447557246905 Test RE 1.159476477501019\n",
      "97 Train Loss 0.8624681 Test MSE 5.894907516857419 Test RE 1.1605037770446125\n",
      "98 Train Loss 0.8580688 Test MSE 5.90098193787442 Test RE 1.1611015449853166\n",
      "99 Train Loss 0.8532551 Test MSE 5.921778179112262 Test RE 1.1631457226470658\n",
      "100 Train Loss 0.84744114 Test MSE 5.968700772844447 Test RE 1.1677448585618162\n",
      "101 Train Loss 0.8426331 Test MSE 5.977017687776855 Test RE 1.1685581556374236\n",
      "102 Train Loss 0.8377117 Test MSE 5.98005491064783 Test RE 1.1688550194730505\n",
      "103 Train Loss 0.8335285 Test MSE 5.98985835038912 Test RE 1.1698127119610715\n",
      "104 Train Loss 0.8288429 Test MSE 6.001212797812611 Test RE 1.1709209425286937\n",
      "105 Train Loss 0.8231043 Test MSE 6.026182143882404 Test RE 1.1733543491140093\n",
      "106 Train Loss 0.8174168 Test MSE 6.035675122824799 Test RE 1.1742781715835395\n",
      "107 Train Loss 0.81289196 Test MSE 6.0370717607994555 Test RE 1.174414026031436\n",
      "108 Train Loss 0.8090113 Test MSE 6.050214906385565 Test RE 1.1756917234994144\n",
      "109 Train Loss 0.8051536 Test MSE 6.054771139467524 Test RE 1.1761343290506547\n",
      "110 Train Loss 0.8014523 Test MSE 6.06143527211443 Test RE 1.176781402201825\n",
      "111 Train Loss 0.79726255 Test MSE 6.077267148872748 Test RE 1.178317219033323\n",
      "112 Train Loss 0.79384506 Test MSE 6.083648776092077 Test RE 1.1789357214000842\n",
      "113 Train Loss 0.79041195 Test MSE 6.107456486028813 Test RE 1.1812402884679654\n",
      "114 Train Loss 0.78808945 Test MSE 6.107202409215956 Test RE 1.1812157177739415\n",
      "115 Train Loss 0.7848238 Test MSE 6.108236862305202 Test RE 1.1813157521618818\n",
      "116 Train Loss 0.7826356 Test MSE 6.123253234451928 Test RE 1.1827669228012914\n",
      "117 Train Loss 0.7796386 Test MSE 6.120625305145134 Test RE 1.1825130902956567\n",
      "118 Train Loss 0.7768364 Test MSE 6.124892418978651 Test RE 1.1829252245593707\n",
      "119 Train Loss 0.7743057 Test MSE 6.131321224332659 Test RE 1.1835458723200472\n",
      "120 Train Loss 0.7703906 Test MSE 6.148535879788683 Test RE 1.18520620397303\n",
      "121 Train Loss 0.76761365 Test MSE 6.165813773462674 Test RE 1.1868702993957037\n",
      "122 Train Loss 0.76491636 Test MSE 6.152391399224991 Test RE 1.1855777452240501\n",
      "123 Train Loss 0.7622529 Test MSE 6.166318953106742 Test RE 1.186918919939287\n",
      "124 Train Loss 0.75974596 Test MSE 6.179666190741613 Test RE 1.1882027916915392\n",
      "125 Train Loss 0.7577473 Test MSE 6.170424685375141 Test RE 1.1873139984649241\n",
      "126 Train Loss 0.75589395 Test MSE 6.176808173713323 Test RE 1.1879279955748645\n",
      "127 Train Loss 0.75347304 Test MSE 6.186648143118427 Test RE 1.1888738338739662\n",
      "128 Train Loss 0.75077665 Test MSE 6.1899024132381255 Test RE 1.189186475538794\n",
      "129 Train Loss 0.7482933 Test MSE 6.199230381783068 Test RE 1.1900821696359782\n",
      "130 Train Loss 0.7465049 Test MSE 6.212789562246864 Test RE 1.191382954083643\n",
      "131 Train Loss 0.74457586 Test MSE 6.223459275692662 Test RE 1.1924055431775509\n",
      "132 Train Loss 0.7422954 Test MSE 6.229176197668484 Test RE 1.1929530943350046\n",
      "133 Train Loss 0.73945594 Test MSE 6.237864502554311 Test RE 1.1937847555583398\n",
      "134 Train Loss 0.7359992 Test MSE 6.244327641425454 Test RE 1.1944030440070144\n",
      "135 Train Loss 0.73326385 Test MSE 6.254622164237279 Test RE 1.1953871968640501\n",
      "136 Train Loss 0.7311749 Test MSE 6.267117050521557 Test RE 1.1965806162744077\n",
      "137 Train Loss 0.728846 Test MSE 6.2729439852496975 Test RE 1.1971367553392462\n",
      "138 Train Loss 0.72710973 Test MSE 6.270438222213013 Test RE 1.1968976299250726\n",
      "139 Train Loss 0.7248311 Test MSE 6.278590211609077 Test RE 1.1976754007348356\n",
      "140 Train Loss 0.72278774 Test MSE 6.276382655438973 Test RE 1.1974648305212385\n",
      "141 Train Loss 0.7205253 Test MSE 6.270317852904844 Test RE 1.196886141857894\n",
      "142 Train Loss 0.7184924 Test MSE 6.30204409836656 Test RE 1.1999102940976236\n",
      "143 Train Loss 0.716868 Test MSE 6.302377472641558 Test RE 1.19994203093793\n",
      "144 Train Loss 0.7150792 Test MSE 6.297665414181373 Test RE 1.1994933705492268\n",
      "145 Train Loss 0.71376586 Test MSE 6.323069811728132 Test RE 1.2019102770780064\n",
      "146 Train Loss 0.7124925 Test MSE 6.323016482629771 Test RE 1.2019052085805482\n",
      "147 Train Loss 0.71078664 Test MSE 6.319368885318689 Test RE 1.201558483353177\n",
      "148 Train Loss 0.70911586 Test MSE 6.325595063596648 Test RE 1.2021502572844853\n",
      "149 Train Loss 0.70752114 Test MSE 6.328657788913436 Test RE 1.2024412504976407\n",
      "Training time: 232.14\n",
      "0\n",
      "KG_rowdy_tune61\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.57\n",
      "0\n",
      "KG_rowdy_tune62\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.92\n",
      "0\n",
      "KG_rowdy_tune63\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 73.085205 Test MSE 4.39601962835828 Test RE 1.0021618629197675\n",
      "1 Train Loss 71.68392 Test MSE 4.361738822745772 Test RE 0.9982467126795606\n",
      "2 Train Loss 66.08638 Test MSE 4.764871178328203 Test RE 1.0433587008971068\n",
      "3 Train Loss 57.03982 Test MSE 6.092691534051345 Test RE 1.1798115832502263\n",
      "4 Train Loss 44.897415 Test MSE 6.526592369013609 Test RE 1.2211002065381849\n",
      "5 Train Loss 39.927425 Test MSE 6.653531606728072 Test RE 1.2329179412475844\n",
      "6 Train Loss 32.613373 Test MSE 6.420240778509617 Test RE 1.2111103571787765\n",
      "7 Train Loss 27.92749 Test MSE 6.261035699821585 Test RE 1.1959999192450264\n",
      "8 Train Loss 26.327696 Test MSE 6.059570079615699 Test RE 1.1766003318262428\n",
      "9 Train Loss 24.243801 Test MSE 5.960701917740198 Test RE 1.1669621293049444\n",
      "10 Train Loss 23.129875 Test MSE 6.014827207008139 Test RE 1.172248371368772\n",
      "11 Train Loss 21.802177 Test MSE 6.03255572273149 Test RE 1.1739746830113604\n",
      "12 Train Loss 20.331734 Test MSE 6.336705349256972 Test RE 1.2032055234727452\n",
      "13 Train Loss 19.024906 Test MSE 6.57931654887826 Test RE 1.226022530589892\n",
      "14 Train Loss 18.15768 Test MSE 6.601315553133807 Test RE 1.2280705219413919\n",
      "15 Train Loss 17.216965 Test MSE 6.640488066276832 Test RE 1.2317088461910566\n",
      "16 Train Loss 16.726133 Test MSE 6.686355565457492 Test RE 1.2359553851851008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 Train Loss 16.078588 Test MSE 6.7681412705429596 Test RE 1.2434913478831648\n",
      "18 Train Loss 15.6730175 Test MSE 6.759232128886694 Test RE 1.2426726527451601\n",
      "19 Train Loss 15.34626 Test MSE 6.737973015092 Test RE 1.240716888828046\n",
      "20 Train Loss 15.0042515 Test MSE 6.733678922159266 Test RE 1.240321472972014\n",
      "21 Train Loss 14.578209 Test MSE 6.820217332168379 Test RE 1.248266074298998\n",
      "22 Train Loss 14.134121 Test MSE 6.841338243754486 Test RE 1.250197401130865\n",
      "23 Train Loss 13.785486 Test MSE 6.8033052520625 Test RE 1.2467174521545563\n",
      "24 Train Loss 13.474031 Test MSE 6.709568695061841 Test RE 1.2380989695463\n",
      "25 Train Loss 13.166891 Test MSE 6.769227967902424 Test RE 1.2435911717840882\n",
      "26 Train Loss 12.906694 Test MSE 6.754039674117156 Test RE 1.2421952493134056\n",
      "27 Train Loss 12.630959 Test MSE 6.690634183027606 Test RE 1.236350767592257\n",
      "28 Train Loss 12.18788 Test MSE 6.655408547511818 Test RE 1.2330918301629468\n",
      "29 Train Loss 11.8706255 Test MSE 6.691131611781293 Test RE 1.2363967262393936\n",
      "30 Train Loss 11.46077 Test MSE 6.761203449998042 Test RE 1.2428538514524052\n",
      "31 Train Loss 11.073782 Test MSE 6.7964680890815545 Test RE 1.2460908337109937\n",
      "32 Train Loss 10.652843 Test MSE 6.637195964004739 Test RE 1.2314034910618026\n",
      "33 Train Loss 10.2881 Test MSE 6.481941073053419 Test RE 1.2169159953004616\n",
      "34 Train Loss 9.786419 Test MSE 6.4308537829407175 Test RE 1.2121109592220694\n",
      "35 Train Loss 9.383751 Test MSE 6.274273422828106 Test RE 1.197263604413484\n",
      "36 Train Loss 8.8850155 Test MSE 5.896877369451229 Test RE 1.1606976588337226\n",
      "37 Train Loss 8.249965 Test MSE 5.7887074219433865 Test RE 1.1500027002357127\n",
      "38 Train Loss 7.348342 Test MSE 5.546384104423795 Test RE 1.12567502734868\n",
      "39 Train Loss 6.6718144 Test MSE 5.33556866624615 Test RE 1.1040745955534215\n",
      "40 Train Loss 6.0013485 Test MSE 5.078539467713564 Test RE 1.077153200618357\n",
      "41 Train Loss 5.2923923 Test MSE 4.834241055351721 Test RE 1.0509261809954287\n",
      "42 Train Loss 4.7382774 Test MSE 4.914441450058744 Test RE 1.0596077911304553\n",
      "43 Train Loss 4.247447 Test MSE 4.889621089141761 Test RE 1.0569286322671334\n",
      "44 Train Loss 3.8788404 Test MSE 4.748051171036203 Test RE 1.0415155434470345\n",
      "45 Train Loss 3.6005154 Test MSE 4.729571643992062 Test RE 1.03948676599109\n",
      "46 Train Loss 3.3228803 Test MSE 4.955403315769216 Test RE 1.0640145426800924\n",
      "47 Train Loss 3.1440132 Test MSE 4.959172398899612 Test RE 1.0644191108582188\n",
      "48 Train Loss 2.9162402 Test MSE 4.98630200114065 Test RE 1.0673266404325468\n",
      "49 Train Loss 2.8194509 Test MSE 5.061463213928572 Test RE 1.0753407474986043\n",
      "50 Train Loss 2.7211041 Test MSE 5.103239152725468 Test RE 1.079769412849702\n",
      "51 Train Loss 2.6419528 Test MSE 5.127399180826793 Test RE 1.0823223459500524\n",
      "52 Train Loss 2.5522604 Test MSE 5.109737892142466 Test RE 1.0804567123525255\n",
      "53 Train Loss 2.5077136 Test MSE 5.073276597544061 Test RE 1.0765949311676444\n",
      "54 Train Loss 2.4617863 Test MSE 5.039981693404989 Test RE 1.0730563768209542\n",
      "55 Train Loss 2.3702545 Test MSE 5.007796264770793 Test RE 1.0696246089641768\n",
      "56 Train Loss 2.3066845 Test MSE 5.059015993282723 Test RE 1.0750807521041033\n",
      "57 Train Loss 2.2537181 Test MSE 5.043237525543092 Test RE 1.073402918495157\n",
      "58 Train Loss 2.1888285 Test MSE 5.0319804012562 Test RE 1.0722042657981108\n",
      "59 Train Loss 2.157918 Test MSE 5.084713695802151 Test RE 1.0778077755660886\n",
      "60 Train Loss 2.1331277 Test MSE 5.078161521451516 Test RE 1.077113118858342\n",
      "61 Train Loss 2.094156 Test MSE 5.0735079937429175 Test RE 1.0766194830651625\n",
      "62 Train Loss 2.0565877 Test MSE 5.087295119278633 Test RE 1.0780813332747496\n",
      "63 Train Loss 2.0326488 Test MSE 5.096021784234858 Test RE 1.0790055988442304\n",
      "64 Train Loss 1.9982846 Test MSE 5.095535721211608 Test RE 1.0789541393673816\n",
      "65 Train Loss 1.9700482 Test MSE 5.121826488393344 Test RE 1.0817340272878817\n",
      "66 Train Loss 1.9486636 Test MSE 5.128987427902889 Test RE 1.0824899613573666\n",
      "67 Train Loss 1.9204698 Test MSE 5.12151659137459 Test RE 1.0817013015384074\n",
      "68 Train Loss 1.9027004 Test MSE 5.1174756004755375 Test RE 1.0812744740928548\n",
      "69 Train Loss 1.877044 Test MSE 5.126670954820263 Test RE 1.0822454840519062\n",
      "70 Train Loss 1.8529123 Test MSE 5.160592513798303 Test RE 1.085820018813347\n",
      "71 Train Loss 1.8375047 Test MSE 5.167711124605694 Test RE 1.0865686602120872\n",
      "72 Train Loss 1.824002 Test MSE 5.182335741859539 Test RE 1.088105068076378\n",
      "73 Train Loss 1.8132813 Test MSE 5.1756662406832605 Test RE 1.0874046643572117\n",
      "74 Train Loss 1.7965965 Test MSE 5.163276194534944 Test RE 1.0861023134834853\n",
      "75 Train Loss 1.7800015 Test MSE 5.187653482221502 Test RE 1.0886631925328711\n",
      "76 Train Loss 1.7664087 Test MSE 5.200200547765749 Test RE 1.089978939535079\n",
      "77 Train Loss 1.7517469 Test MSE 5.220896669198445 Test RE 1.0921457729126325\n",
      "78 Train Loss 1.7441518 Test MSE 5.217759658539492 Test RE 1.091817612067164\n",
      "79 Train Loss 1.7310333 Test MSE 5.22184223088238 Test RE 1.0922446682277356\n",
      "80 Train Loss 1.7178183 Test MSE 5.239965492693328 Test RE 1.094138433825053\n",
      "81 Train Loss 1.704916 Test MSE 5.249541439071798 Test RE 1.0951377370203315\n",
      "82 Train Loss 1.6892257 Test MSE 5.254463299656915 Test RE 1.0956510058936864\n",
      "83 Train Loss 1.6800528 Test MSE 5.2641639314138455 Test RE 1.096661918460026\n",
      "84 Train Loss 1.6688654 Test MSE 5.2600790111093145 Test RE 1.0962363384443559\n",
      "85 Train Loss 1.6575867 Test MSE 5.261589259504397 Test RE 1.0963937001824722\n",
      "86 Train Loss 1.6446574 Test MSE 5.275569734267088 Test RE 1.097849337937207\n",
      "87 Train Loss 1.6323364 Test MSE 5.2848474816077635 Test RE 1.098814266378442\n",
      "88 Train Loss 1.6235194 Test MSE 5.2860943773304 Test RE 1.0989438846889035\n",
      "89 Train Loss 1.6107092 Test MSE 5.306607541229333 Test RE 1.1010740952839706\n",
      "90 Train Loss 1.6015887 Test MSE 5.306806486241975 Test RE 1.1010947347551454\n",
      "91 Train Loss 1.5953763 Test MSE 5.301811529243856 Test RE 1.1005764177922563\n",
      "92 Train Loss 1.5892907 Test MSE 5.305689654248086 Test RE 1.1009788644536276\n",
      "93 Train Loss 1.5815635 Test MSE 5.330781748763879 Test RE 1.1035792125625288\n",
      "94 Train Loss 1.5759467 Test MSE 5.339996470458663 Test RE 1.1045326172420133\n",
      "95 Train Loss 1.567056 Test MSE 5.333752544378865 Test RE 1.1038866770017584\n",
      "96 Train Loss 1.5598986 Test MSE 5.342673805625447 Test RE 1.1048094744892027\n",
      "97 Train Loss 1.5519028 Test MSE 5.3399857022024415 Test RE 1.1045315035805818\n",
      "98 Train Loss 1.5467272 Test MSE 5.340071902388338 Test RE 1.1045404184393492\n",
      "99 Train Loss 1.5399022 Test MSE 5.360547987280911 Test RE 1.1066560289406258\n",
      "100 Train Loss 1.5304548 Test MSE 5.3551133291751105 Test RE 1.1060949088548762\n",
      "101 Train Loss 1.5212299 Test MSE 5.3527753622795595 Test RE 1.1058534297827145\n",
      "102 Train Loss 1.5122802 Test MSE 5.372903806420205 Test RE 1.1079306907441004\n",
      "103 Train Loss 1.504304 Test MSE 5.380891479719455 Test RE 1.1087539421928414\n",
      "104 Train Loss 1.4974426 Test MSE 5.39794742877165 Test RE 1.110509774750719\n",
      "105 Train Loss 1.4907836 Test MSE 5.408958474288303 Test RE 1.1116418387814109\n",
      "106 Train Loss 1.479805 Test MSE 5.424246512012255 Test RE 1.1132117187059145\n",
      "107 Train Loss 1.4681878 Test MSE 5.438109741229166 Test RE 1.1146333780168596\n",
      "108 Train Loss 1.4636848 Test MSE 5.435490569156952 Test RE 1.1143649236862396\n",
      "109 Train Loss 1.4567628 Test MSE 5.446116259630101 Test RE 1.11545361249836\n",
      "110 Train Loss 1.4517498 Test MSE 5.447490474486537 Test RE 1.115594334452124\n",
      "111 Train Loss 1.4441545 Test MSE 5.441387890502932 Test RE 1.1149692837158012\n",
      "112 Train Loss 1.431982 Test MSE 5.449244387954677 Test RE 1.1157739124126462\n",
      "113 Train Loss 1.4259229 Test MSE 5.474561086904456 Test RE 1.1183628015447107\n",
      "114 Train Loss 1.4179736 Test MSE 5.483114239526574 Test RE 1.1192360947940772\n",
      "115 Train Loss 1.4104396 Test MSE 5.487366578557433 Test RE 1.119670013249664\n",
      "116 Train Loss 1.4055083 Test MSE 5.499241809493302 Test RE 1.120880899555277\n",
      "117 Train Loss 1.400923 Test MSE 5.504873215652726 Test RE 1.121454662329139\n",
      "118 Train Loss 1.3928857 Test MSE 5.52063848000937 Test RE 1.1230593667675703\n",
      "119 Train Loss 1.3866931 Test MSE 5.521079214216048 Test RE 1.1231041949882905\n",
      "120 Train Loss 1.3812366 Test MSE 5.533766748628419 Test RE 1.124393910785534\n",
      "121 Train Loss 1.3749119 Test MSE 5.560085055448432 Test RE 1.1270645187113173\n",
      "122 Train Loss 1.3693666 Test MSE 5.555225197017628 Test RE 1.1265718489622925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 Train Loss 1.3639361 Test MSE 5.535200988615512 Test RE 1.124539611381828\n",
      "124 Train Loss 1.3603494 Test MSE 5.544931651862532 Test RE 1.1255276253115978\n",
      "125 Train Loss 1.3540604 Test MSE 5.5464946583512855 Test RE 1.1256862461150754\n",
      "126 Train Loss 1.347738 Test MSE 5.539193977948571 Test RE 1.124945149064581\n",
      "127 Train Loss 1.3427289 Test MSE 5.555886658939198 Test RE 1.1266389175484053\n",
      "128 Train Loss 1.3399985 Test MSE 5.564311966573743 Test RE 1.1274928481723137\n",
      "129 Train Loss 1.3338088 Test MSE 5.583590408054782 Test RE 1.1294443482274543\n",
      "130 Train Loss 1.3275001 Test MSE 5.6093914697867735 Test RE 1.1320508500231115\n",
      "131 Train Loss 1.3223009 Test MSE 5.6173392474731685 Test RE 1.132852550509982\n",
      "132 Train Loss 1.3184001 Test MSE 5.610197656142657 Test RE 1.132132196740063\n",
      "133 Train Loss 1.3137269 Test MSE 5.608261103125884 Test RE 1.1319367826578357\n",
      "134 Train Loss 1.3069626 Test MSE 5.628714818299617 Test RE 1.1339990298506757\n",
      "135 Train Loss 1.3013976 Test MSE 5.649563329600819 Test RE 1.1360972299188918\n",
      "136 Train Loss 1.295374 Test MSE 5.6632605320031475 Test RE 1.1374736135616152\n",
      "137 Train Loss 1.2913183 Test MSE 5.673946325640737 Test RE 1.1385462359515024\n",
      "138 Train Loss 1.2855642 Test MSE 5.679364655045423 Test RE 1.1390897330277117\n",
      "139 Train Loss 1.2799423 Test MSE 5.683633887494528 Test RE 1.1395177848954112\n",
      "140 Train Loss 1.2746277 Test MSE 5.6847596988719955 Test RE 1.1396306368656983\n",
      "141 Train Loss 1.2706635 Test MSE 5.692046625611149 Test RE 1.1403608124478066\n",
      "142 Train Loss 1.2641921 Test MSE 5.704209721827232 Test RE 1.1415785569055756\n",
      "143 Train Loss 1.2594931 Test MSE 5.7022758821321675 Test RE 1.1413850316693637\n",
      "144 Train Loss 1.2513951 Test MSE 5.678200499518356 Test RE 1.1389729818019274\n",
      "145 Train Loss 1.2428902 Test MSE 5.675338060648964 Test RE 1.1386858616554734\n",
      "146 Train Loss 1.234673 Test MSE 5.688989134572109 Test RE 1.1400544980819636\n",
      "147 Train Loss 1.2256908 Test MSE 5.679077689738094 Test RE 1.1390609548646262\n",
      "148 Train Loss 1.2184185 Test MSE 5.693087523552301 Test RE 1.140465075908613\n",
      "149 Train Loss 1.2143475 Test MSE 5.69719305776699 Test RE 1.140876221401862\n",
      "Training time: 230.29\n",
      "1\n",
      "KG_rowdy_tune63\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 62.92884 Test MSE 7.66337903162594 Test RE 1.323177823410966\n",
      "1 Train Loss 48.01853 Test MSE 9.797423179818228 Test RE 1.4961116121169997\n",
      "2 Train Loss 42.80668 Test MSE 9.197368668459443 Test RE 1.4495722212669564\n",
      "3 Train Loss 39.499107 Test MSE 9.476729288325343 Test RE 1.4714221780325252\n",
      "4 Train Loss 33.795273 Test MSE 9.465277263261154 Test RE 1.4705328491830088\n",
      "5 Train Loss 30.647007 Test MSE 9.211144794338379 Test RE 1.4506574238919319\n",
      "6 Train Loss 27.955963 Test MSE 9.030160935257461 Test RE 1.4363352055653893\n",
      "7 Train Loss 25.908312 Test MSE 9.178410711985206 Test RE 1.4480774946849526\n",
      "8 Train Loss 23.732674 Test MSE 9.108663105245718 Test RE 1.4425649635757418\n",
      "9 Train Loss 22.618252 Test MSE 9.112332249834989 Test RE 1.442855480770663\n",
      "10 Train Loss 21.750862 Test MSE 9.132278392036001 Test RE 1.4444337632611934\n",
      "11 Train Loss 20.859293 Test MSE 9.242081972356816 Test RE 1.4530915201685182\n",
      "12 Train Loss 20.304356 Test MSE 9.19213229992018 Test RE 1.4491595176265726\n",
      "13 Train Loss 20.002647 Test MSE 9.173280144485906 Test RE 1.447672713395039\n",
      "14 Train Loss 19.60468 Test MSE 9.331685067555993 Test RE 1.4601184778927965\n",
      "15 Train Loss 19.047863 Test MSE 9.110373818173827 Test RE 1.4427004224594502\n",
      "16 Train Loss 18.780184 Test MSE 9.06579190557568 Test RE 1.4391661424989075\n",
      "17 Train Loss 18.3116 Test MSE 8.86790245096647 Test RE 1.4233723131060199\n",
      "18 Train Loss 17.628277 Test MSE 8.191765903176295 Test RE 1.3680337972322127\n",
      "19 Train Loss 17.161463 Test MSE 8.155003662346676 Test RE 1.3649606784813166\n",
      "20 Train Loss 16.806522 Test MSE 8.202788346263151 Test RE 1.3689538678153332\n",
      "21 Train Loss 15.059319 Test MSE 7.65121908916927 Test RE 1.322127623894278\n",
      "22 Train Loss 12.643404 Test MSE 6.744074313253863 Test RE 1.2412785021469743\n",
      "23 Train Loss 11.553268 Test MSE 6.798453631247381 Test RE 1.2462728389219386\n",
      "24 Train Loss 10.7902 Test MSE 6.389355536695068 Test RE 1.2081937585836444\n",
      "25 Train Loss 10.034906 Test MSE 6.198506644861679 Test RE 1.1900126987909985\n",
      "26 Train Loss 9.521558 Test MSE 6.2581202885389065 Test RE 1.195721431960686\n",
      "27 Train Loss 9.168434 Test MSE 6.307362832605459 Test RE 1.2004165312707276\n",
      "28 Train Loss 8.907541 Test MSE 6.316259636850642 Test RE 1.2012628522867521\n",
      "29 Train Loss 8.773384 Test MSE 6.221475775707816 Test RE 1.1922155102109764\n",
      "30 Train Loss 8.53883 Test MSE 6.2570966392268135 Test RE 1.195623635064673\n",
      "31 Train Loss 8.360575 Test MSE 6.234436448353273 Test RE 1.1934566848504784\n",
      "32 Train Loss 8.277252 Test MSE 6.242674039040822 Test RE 1.1942448845853548\n",
      "33 Train Loss 8.183991 Test MSE 6.202306309503871 Test RE 1.19037737989143\n",
      "34 Train Loss 8.077791 Test MSE 6.187286501818675 Test RE 1.188935168247737\n",
      "35 Train Loss 7.9675827 Test MSE 6.310358819945112 Test RE 1.2007015953975166\n",
      "36 Train Loss 7.8791847 Test MSE 6.381513036730281 Test RE 1.2074520430225153\n",
      "37 Train Loss 7.7636557 Test MSE 6.3790337109193445 Test RE 1.2072174624592873\n",
      "38 Train Loss 7.6692734 Test MSE 6.4129331810610415 Test RE 1.2104209105460155\n",
      "39 Train Loss 7.575868 Test MSE 6.421171434821878 Test RE 1.2111981332213309\n",
      "40 Train Loss 7.4963775 Test MSE 6.420830344653117 Test RE 1.211165963603505\n",
      "41 Train Loss 7.437997 Test MSE 6.431752362589095 Test RE 1.2121956400616114\n",
      "42 Train Loss 7.3670244 Test MSE 6.447862053592626 Test RE 1.2137127914784682\n",
      "43 Train Loss 7.282048 Test MSE 6.502620222602265 Test RE 1.2188555955605813\n",
      "44 Train Loss 7.198806 Test MSE 6.5338919673329805 Test RE 1.2217828790256349\n",
      "45 Train Loss 7.0981817 Test MSE 6.60178966351575 Test RE 1.2281146215247005\n",
      "46 Train Loss 7.0053673 Test MSE 6.561019241266097 Test RE 1.22431653805888\n",
      "47 Train Loss 6.8804545 Test MSE 6.5411731196209875 Test RE 1.2224634466169926\n",
      "48 Train Loss 6.731865 Test MSE 6.514322290838603 Test RE 1.2199518244400145\n",
      "49 Train Loss 6.5977116 Test MSE 6.474700491049255 Test RE 1.2162361339795726\n",
      "50 Train Loss 6.4035034 Test MSE 6.461023736718989 Test RE 1.2149509041556217\n",
      "51 Train Loss 6.275627 Test MSE 6.405312820340252 Test RE 1.2097015372531266\n",
      "52 Train Loss 5.8897147 Test MSE 6.281004971409725 Test RE 1.197905692909595\n",
      "53 Train Loss 5.118423 Test MSE 5.775071571795524 Test RE 1.148647431354773\n",
      "54 Train Loss 4.263315 Test MSE 5.6043646092246915 Test RE 1.1315434922021037\n",
      "55 Train Loss 3.776726 Test MSE 5.403220418749808 Test RE 1.1110520436084665\n",
      "56 Train Loss 3.4053857 Test MSE 5.345313344654389 Test RE 1.1050823554228018\n",
      "57 Train Loss 3.0908935 Test MSE 5.287768759275808 Test RE 1.0991179173471546\n",
      "58 Train Loss 2.8007333 Test MSE 5.347915095738253 Test RE 1.105351263834414\n",
      "59 Train Loss 2.5932577 Test MSE 5.37042341085866 Test RE 1.1076749236854295\n",
      "60 Train Loss 2.4943495 Test MSE 5.418952751927245 Test RE 1.1126683700325621\n",
      "61 Train Loss 2.4300263 Test MSE 5.437557702532569 Test RE 1.1145768017060627\n",
      "62 Train Loss 2.3476477 Test MSE 5.446897044621043 Test RE 1.1155335683957508\n",
      "63 Train Loss 2.2575707 Test MSE 5.497216248992145 Test RE 1.120674450988221\n",
      "64 Train Loss 2.2216237 Test MSE 5.509312229032471 Test RE 1.1219067298783016\n",
      "65 Train Loss 2.1942153 Test MSE 5.518401561057892 Test RE 1.1228318163382156\n",
      "66 Train Loss 2.154473 Test MSE 5.524589388570537 Test RE 1.1234611600837383\n",
      "67 Train Loss 2.1087055 Test MSE 5.485796205967644 Test RE 1.1195097884051424\n",
      "68 Train Loss 2.0608644 Test MSE 5.442485092792578 Test RE 1.1150816893384892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 Train Loss 2.013356 Test MSE 5.517894359803213 Test RE 1.1227802149110455\n",
      "70 Train Loss 1.9857417 Test MSE 5.520425233391486 Test RE 1.1230376762579266\n",
      "71 Train Loss 1.9462677 Test MSE 5.53954019671842 Test RE 1.124980304995343\n",
      "72 Train Loss 1.9159012 Test MSE 5.5895125792745635 Test RE 1.1300431555964368\n",
      "73 Train Loss 1.881675 Test MSE 5.64865758155463 Test RE 1.1360061557036785\n",
      "74 Train Loss 1.8586023 Test MSE 5.647147300774364 Test RE 1.1358542786484118\n",
      "75 Train Loss 1.8296196 Test MSE 5.6659557051135145 Test RE 1.1377442459669662\n",
      "76 Train Loss 1.7842839 Test MSE 5.705631682088003 Test RE 1.1417208358776338\n",
      "77 Train Loss 1.7455715 Test MSE 5.699446796916297 Test RE 1.1411018573546436\n",
      "78 Train Loss 1.7217548 Test MSE 5.693695278475241 Test RE 1.1405259483933743\n",
      "79 Train Loss 1.7037969 Test MSE 5.690046539732787 Test RE 1.140160443397577\n",
      "80 Train Loss 1.6680948 Test MSE 5.6882068372129 Test RE 1.1399761104928543\n",
      "81 Train Loss 1.6480918 Test MSE 5.673881741132569 Test RE 1.1385397561001163\n",
      "82 Train Loss 1.6225328 Test MSE 5.637175792614536 Test RE 1.1348510124103282\n",
      "83 Train Loss 1.5840029 Test MSE 5.666475649238869 Test RE 1.1377964480928608\n",
      "84 Train Loss 1.5612127 Test MSE 5.69381999189174 Test RE 1.1405384392364728\n",
      "85 Train Loss 1.5383388 Test MSE 5.70308233666607 Test RE 1.1414657400224923\n",
      "86 Train Loss 1.5126745 Test MSE 5.684648197389166 Test RE 1.1396194603924856\n",
      "87 Train Loss 1.4986428 Test MSE 5.70449313826653 Test RE 1.1416069164967215\n",
      "88 Train Loss 1.4871305 Test MSE 5.748421108449215 Test RE 1.1459940110280737\n",
      "89 Train Loss 1.4684238 Test MSE 5.7634072090852255 Test RE 1.14748683859781\n",
      "90 Train Loss 1.4532107 Test MSE 5.762390570288567 Test RE 1.1473856284068746\n",
      "91 Train Loss 1.4417511 Test MSE 5.784632711534613 Test RE 1.1495978816349766\n",
      "92 Train Loss 1.4307128 Test MSE 5.784940736640222 Test RE 1.1496284886166783\n",
      "93 Train Loss 1.4184744 Test MSE 5.776696288076469 Test RE 1.1488089960142276\n",
      "94 Train Loss 1.4082466 Test MSE 5.7972771373227205 Test RE 1.1508536286338638\n",
      "95 Train Loss 1.3953335 Test MSE 5.803403531296705 Test RE 1.1514615623964986\n",
      "96 Train Loss 1.3865527 Test MSE 5.819593177871243 Test RE 1.153066549246224\n",
      "97 Train Loss 1.3740292 Test MSE 5.8489579583656 Test RE 1.155971987820238\n",
      "98 Train Loss 1.3578441 Test MSE 5.880969388142332 Test RE 1.1591309969265757\n",
      "99 Train Loss 1.3465965 Test MSE 5.88969576417353 Test RE 1.159990656517981\n",
      "100 Train Loss 1.338265 Test MSE 5.8887472363186 Test RE 1.1598972452624086\n",
      "101 Train Loss 1.3278842 Test MSE 5.879638041703389 Test RE 1.1589997862220502\n",
      "102 Train Loss 1.3153636 Test MSE 5.85929039943819 Test RE 1.156992574929867\n",
      "103 Train Loss 1.2956612 Test MSE 5.904604963112733 Test RE 1.1614579309857596\n",
      "104 Train Loss 1.2833868 Test MSE 5.935216732784622 Test RE 1.164464763800752\n",
      "105 Train Loss 1.2751263 Test MSE 5.914143297423136 Test RE 1.162395665490815\n",
      "106 Train Loss 1.2668473 Test MSE 5.91408422505976 Test RE 1.1623898602856355\n",
      "107 Train Loss 1.2561098 Test MSE 5.931616794239192 Test RE 1.1641115637726498\n",
      "108 Train Loss 1.2489982 Test MSE 5.915495155281802 Test RE 1.1625285083937529\n",
      "109 Train Loss 1.240913 Test MSE 5.9014392013103105 Test RE 1.161146530633681\n",
      "110 Train Loss 1.2313937 Test MSE 5.909518311413288 Test RE 1.1619410675143511\n",
      "111 Train Loss 1.222594 Test MSE 5.926767246637497 Test RE 1.1636355916221495\n",
      "112 Train Loss 1.2169185 Test MSE 5.911133789389858 Test RE 1.162099875884068\n",
      "113 Train Loss 1.2069284 Test MSE 5.915683106046035 Test RE 1.1625469765338083\n",
      "114 Train Loss 1.1980976 Test MSE 5.927177639767672 Test RE 1.1636758783219983\n",
      "115 Train Loss 1.1908637 Test MSE 5.934420464433714 Test RE 1.1643866489163126\n",
      "116 Train Loss 1.1845403 Test MSE 5.9472577879822035 Test RE 1.1656453677172063\n",
      "117 Train Loss 1.1766574 Test MSE 5.919694129188495 Test RE 1.1629410318436466\n",
      "118 Train Loss 1.1697098 Test MSE 5.928675059121182 Test RE 1.1638228623374864\n",
      "119 Train Loss 1.165338 Test MSE 5.9637857938925505 Test RE 1.1672639646743062\n",
      "120 Train Loss 1.1610401 Test MSE 5.976380930834424 Test RE 1.1684959082612354\n",
      "121 Train Loss 1.1552162 Test MSE 5.984284629088815 Test RE 1.1692683144844092\n",
      "122 Train Loss 1.1490091 Test MSE 5.979447320440365 Test RE 1.1687956385046063\n",
      "123 Train Loss 1.1444387 Test MSE 5.996323048086419 Test RE 1.1704438158791541\n",
      "124 Train Loss 1.1399703 Test MSE 6.011043270793855 Test RE 1.1718795818125864\n",
      "125 Train Loss 1.1359017 Test MSE 6.0031045503227425 Test RE 1.1711054817351267\n",
      "126 Train Loss 1.1309501 Test MSE 5.999532296634259 Test RE 1.1707569863531757\n",
      "127 Train Loss 1.1261096 Test MSE 6.019885276901538 Test RE 1.1727411592723016\n",
      "128 Train Loss 1.1205885 Test MSE 6.015138127834472 Test RE 1.172278669140404\n",
      "129 Train Loss 1.1169336 Test MSE 5.999064483673772 Test RE 1.1707113406309964\n",
      "130 Train Loss 1.1148212 Test MSE 6.002830868484671 Test RE 1.1710787860519827\n",
      "131 Train Loss 1.1114597 Test MSE 5.998885036162313 Test RE 1.1706938310002593\n",
      "132 Train Loss 1.1080608 Test MSE 5.998483629520245 Test RE 1.1706546627099774\n",
      "133 Train Loss 1.1039182 Test MSE 6.002518511382848 Test RE 1.1710483171330435\n",
      "134 Train Loss 1.1010683 Test MSE 5.986755515084325 Test RE 1.169509682560677\n",
      "135 Train Loss 1.097969 Test MSE 5.990147665578899 Test RE 1.16984096308825\n",
      "136 Train Loss 1.0932685 Test MSE 6.012621546126982 Test RE 1.1720334176081713\n",
      "137 Train Loss 1.0887833 Test MSE 6.002531703018695 Test RE 1.1710496039291147\n",
      "138 Train Loss 1.0850948 Test MSE 5.992521046892437 Test RE 1.1700726939128494\n",
      "139 Train Loss 1.080003 Test MSE 6.011396450039371 Test RE 1.1719140082381363\n",
      "140 Train Loss 1.0728129 Test MSE 6.005768251637744 Test RE 1.1713652747487617\n",
      "141 Train Loss 1.0693011 Test MSE 6.012710822957262 Test RE 1.1720421188909058\n",
      "142 Train Loss 1.0652975 Test MSE 6.030971048101608 Test RE 1.1738204788753759\n",
      "143 Train Loss 1.0616643 Test MSE 6.024824824408198 Test RE 1.1732222002377108\n",
      "144 Train Loss 1.057974 Test MSE 6.020645170022399 Test RE 1.1728151747873357\n",
      "145 Train Loss 1.0550716 Test MSE 6.035455304580167 Test RE 1.1742567878848298\n",
      "146 Train Loss 1.0510986 Test MSE 6.046431343705962 Test RE 1.1753240506925868\n",
      "147 Train Loss 1.0478029 Test MSE 6.040366263008225 Test RE 1.1747344282102732\n",
      "148 Train Loss 1.0452743 Test MSE 6.05351845962632 Test RE 1.1760126567411007\n",
      "149 Train Loss 1.0414776 Test MSE 6.064549123609313 Test RE 1.1770836286449204\n",
      "Training time: 230.29\n",
      "2\n",
      "KG_rowdy_tune63\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 63.673256 Test MSE 6.300351784388835 Test RE 1.199749174842319\n",
      "1 Train Loss 46.29989 Test MSE 9.06518593404668 Test RE 1.4391180436515896\n",
      "2 Train Loss 36.34085 Test MSE 8.112000584108769 Test RE 1.3613570567594735\n",
      "3 Train Loss 31.106123 Test MSE 7.070889208767578 Test RE 1.2709986127171322\n",
      "4 Train Loss 25.499634 Test MSE 6.526405611615315 Test RE 1.2210827356195066\n",
      "5 Train Loss 21.035921 Test MSE 5.880639780545276 Test RE 1.159098513868872\n",
      "6 Train Loss 17.08918 Test MSE 5.859114713343303 Test RE 1.1569752290554371\n",
      "7 Train Loss 14.874001 Test MSE 5.680153569600669 Test RE 1.1391688451572743\n",
      "8 Train Loss 13.189657 Test MSE 5.260963390214853 Test RE 1.0963284898895822\n",
      "9 Train Loss 11.726586 Test MSE 5.129553606521247 Test RE 1.0825497066547118\n",
      "10 Train Loss 10.428989 Test MSE 4.931783733879641 Test RE 1.061475738512327\n",
      "11 Train Loss 9.443821 Test MSE 4.694523358676484 Test RE 1.035628068246959\n",
      "12 Train Loss 8.449316 Test MSE 4.266510573308639 Test RE 0.987289398068698\n",
      "13 Train Loss 7.7974906 Test MSE 4.22414871794495 Test RE 0.982375810732191\n",
      "14 Train Loss 7.401023 Test MSE 4.214689802492783 Test RE 0.9812753029045784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Train Loss 7.112463 Test MSE 4.106708620669007 Test RE 0.9686235086021038\n",
      "16 Train Loss 6.8130884 Test MSE 4.146247573868949 Test RE 0.9732752408145133\n",
      "17 Train Loss 6.635579 Test MSE 4.070406334442487 Test RE 0.9643328095191342\n",
      "18 Train Loss 6.524706 Test MSE 4.039407861459218 Test RE 0.9606538186999156\n",
      "19 Train Loss 6.3614388 Test MSE 4.051713940288803 Test RE 0.9621160245303055\n",
      "20 Train Loss 6.189805 Test MSE 3.853356910374078 Test RE 0.9382696717587373\n",
      "21 Train Loss 5.9969454 Test MSE 3.815977967106086 Test RE 0.933707805795849\n",
      "22 Train Loss 5.801978 Test MSE 3.8404077174089166 Test RE 0.9366918190094613\n",
      "23 Train Loss 5.707915 Test MSE 3.7514359152775127 Test RE 0.9257779363813545\n",
      "24 Train Loss 5.562497 Test MSE 3.758317638735677 Test RE 0.9266266818761282\n",
      "25 Train Loss 5.4039607 Test MSE 3.7417701432774617 Test RE 0.9245845093743864\n",
      "26 Train Loss 5.1925545 Test MSE 3.638618478420198 Test RE 0.9117511518276444\n",
      "27 Train Loss 4.9910245 Test MSE 3.5287580210453187 Test RE 0.8978814504223449\n",
      "28 Train Loss 4.7570376 Test MSE 3.4804042998508886 Test RE 0.891708504259718\n",
      "29 Train Loss 4.509788 Test MSE 3.4530324044203713 Test RE 0.888195129288644\n",
      "30 Train Loss 4.139789 Test MSE 3.463912716891565 Test RE 0.88959335537304\n",
      "31 Train Loss 3.826539 Test MSE 3.4082259939589825 Test RE 0.8824137209712278\n",
      "32 Train Loss 3.6026218 Test MSE 3.367812207110398 Test RE 0.877166412238667\n",
      "33 Train Loss 3.4699202 Test MSE 3.2827413711921456 Test RE 0.8660169544519006\n",
      "34 Train Loss 3.3330579 Test MSE 3.2501624664372515 Test RE 0.8617089339667272\n",
      "35 Train Loss 3.0870996 Test MSE 3.091551443009752 Test RE 0.8404198451786504\n",
      "36 Train Loss 2.9700193 Test MSE 2.998804191628771 Test RE 0.8277174571750854\n",
      "37 Train Loss 2.86938 Test MSE 2.960778090108024 Test RE 0.8224528112754249\n",
      "38 Train Loss 2.71223 Test MSE 2.8283746852171827 Test RE 0.8038528040640947\n",
      "39 Train Loss 2.5291862 Test MSE 2.7270273077074014 Test RE 0.7893194483976121\n",
      "40 Train Loss 2.3321815 Test MSE 2.5914275697485314 Test RE 0.7694450280504022\n",
      "41 Train Loss 2.1796043 Test MSE 2.4757275146781907 Test RE 0.7520721073030885\n",
      "42 Train Loss 2.0408635 Test MSE 2.369800272087511 Test RE 0.7358070299293686\n",
      "43 Train Loss 1.917145 Test MSE 2.2194959141509836 Test RE 0.7120905710478346\n",
      "44 Train Loss 1.8470672 Test MSE 2.134236906879051 Test RE 0.6982796300891706\n",
      "45 Train Loss 1.7802826 Test MSE 2.048301520749315 Test RE 0.6840770238719146\n",
      "46 Train Loss 1.7113856 Test MSE 1.994823746448351 Test RE 0.6750879016395459\n",
      "47 Train Loss 1.6266308 Test MSE 1.8661476955277911 Test RE 0.6529517146910082\n",
      "48 Train Loss 1.5775584 Test MSE 1.764423949642676 Test RE 0.6349061477401531\n",
      "49 Train Loss 1.5487927 Test MSE 1.723217702820065 Test RE 0.6274485702863034\n",
      "50 Train Loss 1.5193726 Test MSE 1.6659174305511557 Test RE 0.6169284471140545\n",
      "51 Train Loss 1.4746989 Test MSE 1.613355751140895 Test RE 0.607118030628633\n",
      "52 Train Loss 1.4326108 Test MSE 1.5798710469049895 Test RE 0.6007847225176665\n",
      "53 Train Loss 1.4029564 Test MSE 1.522649863367804 Test RE 0.5898045033517302\n",
      "54 Train Loss 1.3754632 Test MSE 1.4471676325059526 Test RE 0.5749995178489389\n",
      "55 Train Loss 1.34344 Test MSE 1.380361013435369 Test RE 0.5615706512051406\n",
      "56 Train Loss 1.2982626 Test MSE 1.2542559711287669 Test RE 0.5353048138635299\n",
      "57 Train Loss 1.2253138 Test MSE 0.9447706226956724 Test RE 0.4645914900848068\n",
      "58 Train Loss 1.0690391 Test MSE 0.783136771101195 Test RE 0.4229868522421971\n",
      "59 Train Loss 0.8872379 Test MSE 0.66292155588621 Test RE 0.38916979963372383\n",
      "60 Train Loss 0.7611972 Test MSE 0.6124507178543822 Test RE 0.3740620367885086\n",
      "61 Train Loss 0.6959689 Test MSE 0.582924143173164 Test RE 0.36493379361975203\n",
      "62 Train Loss 0.6140244 Test MSE 0.5444745276417875 Test RE 0.35269300283974364\n",
      "63 Train Loss 0.54109037 Test MSE 0.4943489753463086 Test RE 0.3360662341433001\n",
      "64 Train Loss 0.49441618 Test MSE 0.4640894161730212 Test RE 0.3256183658211262\n",
      "65 Train Loss 0.4479025 Test MSE 0.42224247274982535 Test RE 0.31059110825326136\n",
      "66 Train Loss 0.4195054 Test MSE 0.38962196956079087 Test RE 0.298352567103908\n",
      "67 Train Loss 0.3934654 Test MSE 0.36953183438820597 Test RE 0.2905587705675025\n",
      "68 Train Loss 0.35826352 Test MSE 0.37831143448229526 Test RE 0.2939901598058413\n",
      "69 Train Loss 0.33281636 Test MSE 0.34959329827336205 Test RE 0.2826113564685467\n",
      "70 Train Loss 0.31252778 Test MSE 0.2855862619868467 Test RE 0.2554328307328963\n",
      "71 Train Loss 0.29197448 Test MSE 0.2708649908177805 Test RE 0.2487622626965521\n",
      "72 Train Loss 0.27371046 Test MSE 0.27709831777153476 Test RE 0.2516083240314497\n",
      "73 Train Loss 0.25600183 Test MSE 0.24915111945557075 Test RE 0.23858299257814708\n",
      "74 Train Loss 0.24147639 Test MSE 0.2317997333878501 Test RE 0.23012538407100103\n",
      "75 Train Loss 0.23287167 Test MSE 0.22567088165526944 Test RE 0.22706271325286473\n",
      "76 Train Loss 0.22334744 Test MSE 0.19041300552229995 Test RE 0.20857217227164715\n",
      "77 Train Loss 0.20900576 Test MSE 0.1675995855385334 Test RE 0.19567913974966328\n",
      "78 Train Loss 0.19752467 Test MSE 0.15183301539402688 Test RE 0.1862478074613889\n",
      "79 Train Loss 0.18776564 Test MSE 0.12478023190003563 Test RE 0.16884218139631457\n",
      "80 Train Loss 0.17895085 Test MSE 0.10379225022224813 Test RE 0.1539892926567366\n",
      "81 Train Loss 0.1675118 Test MSE 0.08674040962667648 Test RE 0.1407728148296112\n",
      "82 Train Loss 0.14946197 Test MSE 0.08025395834083426 Test RE 0.13540705460982327\n",
      "83 Train Loss 0.13547643 Test MSE 0.06451051065459626 Test RE 0.12140128960715554\n",
      "84 Train Loss 0.12552287 Test MSE 0.04944117293936349 Test RE 0.10628021956943338\n",
      "85 Train Loss 0.11574018 Test MSE 0.03577871302402797 Test RE 0.09041082197101669\n",
      "86 Train Loss 0.10311722 Test MSE 0.02540612706077284 Test RE 0.07618637203836766\n",
      "87 Train Loss 0.09485855 Test MSE 0.02232896346818732 Test RE 0.07142369957882422\n",
      "88 Train Loss 0.088581935 Test MSE 0.023110825869267094 Test RE 0.0726634130228775\n",
      "89 Train Loss 0.08296543 Test MSE 0.023978260597150202 Test RE 0.07401451509182992\n",
      "90 Train Loss 0.07502204 Test MSE 0.027263130086524326 Test RE 0.07892160671334325\n",
      "91 Train Loss 0.0719867 Test MSE 0.02710113521189846 Test RE 0.07868678510572642\n",
      "92 Train Loss 0.067567445 Test MSE 0.024501277301582407 Test RE 0.07481736748308242\n",
      "93 Train Loss 0.06297462 Test MSE 0.02296709697602155 Test RE 0.07243710954650968\n",
      "94 Train Loss 0.059721038 Test MSE 0.02141365758882813 Test RE 0.06994448667568508\n",
      "95 Train Loss 0.057039917 Test MSE 0.020648638874321286 Test RE 0.06868371456944126\n",
      "96 Train Loss 0.054196283 Test MSE 0.019949662087204945 Test RE 0.06751120072377216\n",
      "97 Train Loss 0.05110676 Test MSE 0.017979075755479686 Test RE 0.06409021691203859\n",
      "98 Train Loss 0.04740169 Test MSE 0.015902782880318277 Test RE 0.06027602787865542\n",
      "99 Train Loss 0.044740435 Test MSE 0.012882021922632029 Test RE 0.05425004181048701\n",
      "100 Train Loss 0.043785267 Test MSE 0.012105861834822425 Test RE 0.0525903325162025\n",
      "101 Train Loss 0.042061366 Test MSE 0.011837681700818501 Test RE 0.052004555585174264\n",
      "102 Train Loss 0.04089866 Test MSE 0.011267022105870281 Test RE 0.05073558046331153\n",
      "103 Train Loss 0.039044093 Test MSE 0.010659220046485627 Test RE 0.04934813841111426\n",
      "104 Train Loss 0.038362727 Test MSE 0.010323013275486051 Test RE 0.04856364806874651\n",
      "105 Train Loss 0.03586706 Test MSE 0.00733315309448753 Test RE 0.04093110188459598\n",
      "106 Train Loss 0.031962086 Test MSE 0.005558484747501672 Test RE 0.035635780024816\n",
      "107 Train Loss 0.02919562 Test MSE 0.0038463351803464155 Test RE 0.02964364637707471\n",
      "108 Train Loss 0.028302204 Test MSE 0.0030443615704087057 Test RE 0.026372796025791734\n",
      "109 Train Loss 0.027444394 Test MSE 0.002756201689793786 Test RE 0.025093633898603522\n",
      "110 Train Loss 0.025555316 Test MSE 0.0022920632581448657 Test RE 0.022883442569861058\n",
      "111 Train Loss 0.024024744 Test MSE 0.0020956571724707065 Test RE 0.021881051047838287\n",
      "112 Train Loss 0.023057241 Test MSE 0.002045649666881359 Test RE 0.021618407058733566\n",
      "113 Train Loss 0.022617968 Test MSE 0.0020540432243501 Test RE 0.02166271317633015\n",
      "114 Train Loss 0.022310173 Test MSE 0.0021434921953006766 Test RE 0.022129368132646217\n",
      "115 Train Loss 0.021786712 Test MSE 0.0024191878411948687 Test RE 0.0235094709397302\n",
      "116 Train Loss 0.021110212 Test MSE 0.002532227864059343 Test RE 0.024052457279728632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 Train Loss 0.020324998 Test MSE 0.002465785610905804 Test RE 0.02373480769121876\n",
      "118 Train Loss 0.019662699 Test MSE 0.0026487608505634756 Test RE 0.024599678695522896\n",
      "119 Train Loss 0.019541584 Test MSE 0.0027847279992338297 Test RE 0.02522315745799815\n",
      "120 Train Loss 0.01923009 Test MSE 0.0028419060787154863 Test RE 0.02548079188526559\n",
      "121 Train Loss 0.0191087 Test MSE 0.0028202404594354987 Test RE 0.025383478089645986\n",
      "122 Train Loss 0.018884698 Test MSE 0.0029365577062317426 Test RE 0.02590164400358815\n",
      "123 Train Loss 0.018241627 Test MSE 0.0030692432307376457 Test RE 0.026480349548141695\n",
      "124 Train Loss 0.017813094 Test MSE 0.0029004050351797922 Test RE 0.025741709534099724\n",
      "125 Train Loss 0.017323032 Test MSE 0.0028102739115432418 Test RE 0.025338586606411764\n",
      "126 Train Loss 0.016668078 Test MSE 0.0028402653808187184 Test RE 0.02547343549906369\n",
      "127 Train Loss 0.016358929 Test MSE 0.0028756260156907144 Test RE 0.02563151414590345\n",
      "128 Train Loss 0.016152048 Test MSE 0.0029119737815770687 Test RE 0.025792995982216245\n",
      "129 Train Loss 0.015999949 Test MSE 0.0029091923853681533 Test RE 0.02578067484100665\n",
      "130 Train Loss 0.01582482 Test MSE 0.002878050277209236 Test RE 0.02564231603782529\n",
      "131 Train Loss 0.015640307 Test MSE 0.0027680086815413604 Test RE 0.0251473244007391\n",
      "132 Train Loss 0.015416711 Test MSE 0.002749624716830399 Test RE 0.02506367623503193\n",
      "133 Train Loss 0.015168984 Test MSE 0.0030747100282665155 Test RE 0.026503921858111602\n",
      "134 Train Loss 0.014839939 Test MSE 0.0032119211873688305 Test RE 0.027088845759919333\n",
      "135 Train Loss 0.01436566 Test MSE 0.0025717023567659097 Test RE 0.02423920723359276\n",
      "136 Train Loss 0.014233068 Test MSE 0.0025230351284891033 Test RE 0.02400875881966034\n",
      "137 Train Loss 0.014083666 Test MSE 0.00266506812598886 Test RE 0.024675287295030605\n",
      "138 Train Loss 0.013862085 Test MSE 0.0025650562364360092 Test RE 0.024207865950279458\n",
      "139 Train Loss 0.013658817 Test MSE 0.0027200916316642222 Test RE 0.02492871126568872\n",
      "140 Train Loss 0.013331605 Test MSE 0.0027298071014649978 Test RE 0.02497319106559228\n",
      "141 Train Loss 0.013069741 Test MSE 0.0025814230998242303 Test RE 0.02428497475165409\n",
      "142 Train Loss 0.012896979 Test MSE 0.002557576377542883 Test RE 0.02417254438199279\n",
      "143 Train Loss 0.012688561 Test MSE 0.0023334512636657106 Test RE 0.023089122484255827\n",
      "144 Train Loss 0.012406003 Test MSE 0.0022227109181670386 Test RE 0.02253458433724757\n",
      "145 Train Loss 0.011919381 Test MSE 0.002228336276109528 Test RE 0.022563082194812716\n",
      "146 Train Loss 0.011638617 Test MSE 0.0021632358364439587 Test RE 0.02223105098693835\n",
      "147 Train Loss 0.011459732 Test MSE 0.002232812399101027 Test RE 0.022585732381181552\n",
      "148 Train Loss 0.011166596 Test MSE 0.0022142280489535096 Test RE 0.022491542152751676\n",
      "149 Train Loss 0.01100681 Test MSE 0.0022280630287938425 Test RE 0.02256169876567674\n",
      "Training time: 229.58\n",
      "3\n",
      "KG_rowdy_tune63\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 65.4869 Test MSE 5.465000221582779 Test RE 1.1173858110211912\n",
      "1 Train Loss 51.892193 Test MSE 7.849759380170628 Test RE 1.3391716058748258\n",
      "2 Train Loss 41.21209 Test MSE 9.061846201758927 Test RE 1.4388529243376673\n",
      "3 Train Loss 35.390778 Test MSE 8.373454078277623 Test RE 1.3831216574682177\n",
      "4 Train Loss 32.217964 Test MSE 8.623554500716486 Test RE 1.4036253931997373\n",
      "5 Train Loss 29.381266 Test MSE 8.806353716980604 Test RE 1.4184241697615254\n",
      "6 Train Loss 26.338793 Test MSE 8.76787714633399 Test RE 1.4153221003150178\n",
      "7 Train Loss 23.370827 Test MSE 9.095183911290178 Test RE 1.4414971992024974\n",
      "8 Train Loss 22.000273 Test MSE 9.142523302724607 Test RE 1.4452437444255746\n",
      "9 Train Loss 20.28999 Test MSE 9.081135343433484 Test RE 1.4403834890535132\n",
      "10 Train Loss 18.567623 Test MSE 8.880477248677392 Test RE 1.4243811355632685\n",
      "11 Train Loss 16.902794 Test MSE 8.997927811313543 Test RE 1.4337694174421929\n",
      "12 Train Loss 15.50141 Test MSE 8.98805704463518 Test RE 1.432982775943746\n",
      "13 Train Loss 14.047465 Test MSE 8.79006485284688 Test RE 1.4171117530017303\n",
      "14 Train Loss 12.516191 Test MSE 8.581577811409977 Test RE 1.4002050273622813\n",
      "15 Train Loss 10.577994 Test MSE 8.179937627707726 Test RE 1.367045773024893\n",
      "16 Train Loss 9.105203 Test MSE 8.30368517761953 Test RE 1.3773474136925614\n",
      "17 Train Loss 7.89711 Test MSE 8.053339269881793 Test RE 1.356425850752113\n",
      "18 Train Loss 6.9821734 Test MSE 7.749960867131623 Test RE 1.3306315453279207\n",
      "19 Train Loss 6.422096 Test MSE 7.65244621486479 Test RE 1.3222336430602646\n",
      "20 Train Loss 5.607714 Test MSE 7.509304886881132 Test RE 1.3098088758129591\n",
      "21 Train Loss 4.8858232 Test MSE 7.408848228580951 Test RE 1.301018312197452\n",
      "22 Train Loss 4.4680886 Test MSE 7.459471829643833 Test RE 1.3054555813867297\n",
      "23 Train Loss 4.054236 Test MSE 7.452870166879907 Test RE 1.3048777867838954\n",
      "24 Train Loss 3.6775312 Test MSE 7.364394324282701 Test RE 1.297109313281016\n",
      "25 Train Loss 3.367331 Test MSE 7.303729939517866 Test RE 1.2917557801060602\n",
      "26 Train Loss 3.1533456 Test MSE 7.244686280526251 Test RE 1.286523880989351\n",
      "27 Train Loss 2.9673057 Test MSE 7.18932220333955 Test RE 1.2815986290750288\n",
      "28 Train Loss 2.827543 Test MSE 7.058002842820952 Test RE 1.269839916699393\n",
      "29 Train Loss 2.7306807 Test MSE 7.065517792460017 Test RE 1.2705157625751937\n",
      "30 Train Loss 2.630091 Test MSE 7.123883443141874 Test RE 1.2757526022444934\n",
      "31 Train Loss 2.5403242 Test MSE 7.068425386837338 Test RE 1.2707771563344081\n",
      "32 Train Loss 2.4721954 Test MSE 7.052614605471032 Test RE 1.2693551120463893\n",
      "33 Train Loss 2.408687 Test MSE 7.015230506393022 Test RE 1.2659863791635606\n",
      "34 Train Loss 2.351293 Test MSE 6.972418860380122 Test RE 1.2621175181501212\n",
      "35 Train Loss 2.3100462 Test MSE 6.95549424568832 Test RE 1.2605847766777205\n",
      "36 Train Loss 2.2523887 Test MSE 6.960290959778005 Test RE 1.2610193699945775\n",
      "37 Train Loss 2.1947618 Test MSE 7.058686426324064 Test RE 1.2699014086413096\n",
      "38 Train Loss 2.1300898 Test MSE 7.099435865858694 Test RE 1.2735616718992175\n",
      "39 Train Loss 2.0641968 Test MSE 7.029369136656392 Test RE 1.2672614836479368\n",
      "40 Train Loss 1.9889297 Test MSE 6.988157610282839 Test RE 1.2635411958740899\n",
      "41 Train Loss 1.9164307 Test MSE 6.941618441722558 Test RE 1.2593267525150293\n",
      "42 Train Loss 1.8786467 Test MSE 6.9208008848722 Test RE 1.2574370065429288\n",
      "43 Train Loss 1.8444071 Test MSE 6.955274000642606 Test RE 1.2605648183728297\n",
      "44 Train Loss 1.7998044 Test MSE 6.9768174563797425 Test RE 1.262515562924573\n",
      "45 Train Loss 1.7449652 Test MSE 6.927315584417331 Test RE 1.2580286936577767\n",
      "46 Train Loss 1.6842608 Test MSE 6.913373188759147 Test RE 1.2567620581193188\n",
      "47 Train Loss 1.6259137 Test MSE 6.930391094375597 Test RE 1.2583079252292197\n",
      "48 Train Loss 1.5890217 Test MSE 6.893527873063179 Test RE 1.2549569505796538\n",
      "49 Train Loss 1.5578274 Test MSE 6.891449550343771 Test RE 1.2547677584703125\n",
      "50 Train Loss 1.5144758 Test MSE 6.858955723981546 Test RE 1.2518060897967946\n",
      "51 Train Loss 1.4928862 Test MSE 6.870147340795843 Test RE 1.252826946648432\n",
      "52 Train Loss 1.4578459 Test MSE 6.869066121123436 Test RE 1.2527283581922006\n",
      "53 Train Loss 1.4179517 Test MSE 6.77505296874047 Test RE 1.2441261191926154\n",
      "54 Train Loss 1.394315 Test MSE 6.714691538098662 Test RE 1.2385715317014343\n",
      "55 Train Loss 1.3746923 Test MSE 6.634018666212704 Test RE 1.2311087126666862\n",
      "56 Train Loss 1.3503566 Test MSE 6.542540121445226 Test RE 1.2225911777159308\n",
      "57 Train Loss 1.3202624 Test MSE 6.483690430757957 Test RE 1.2170801959415214\n",
      "58 Train Loss 1.3033301 Test MSE 6.4523013033154175 Test RE 1.2141305304952135\n",
      "59 Train Loss 1.2882125 Test MSE 6.4112622224116835 Test RE 1.210263206185152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 Train Loss 1.2657781 Test MSE 6.379235430594761 Test RE 1.2072365498007709\n",
      "61 Train Loss 1.242435 Test MSE 6.35156550382439 Test RE 1.2046155109101784\n",
      "62 Train Loss 1.2189932 Test MSE 6.289608673338306 Test RE 1.1987258559691216\n",
      "63 Train Loss 1.2063628 Test MSE 6.259966199430884 Test RE 1.19589776545839\n",
      "64 Train Loss 1.1974404 Test MSE 6.251299668401738 Test RE 1.1950696559748208\n",
      "65 Train Loss 1.1871269 Test MSE 6.200169066689331 Test RE 1.190172267100993\n",
      "66 Train Loss 1.173898 Test MSE 6.1814789143608015 Test RE 1.1883770507265952\n",
      "67 Train Loss 1.1648961 Test MSE 6.1663525483251345 Test RE 1.1869221532091132\n",
      "68 Train Loss 1.1553 Test MSE 6.124901288645318 Test RE 1.1829260810763442\n",
      "69 Train Loss 1.1487502 Test MSE 6.124481229398307 Test RE 1.1828855165402508\n",
      "70 Train Loss 1.1401466 Test MSE 6.100218325184609 Test RE 1.1805401163133453\n",
      "71 Train Loss 1.1317734 Test MSE 6.077430330566897 Test RE 1.1783330385213115\n",
      "72 Train Loss 1.1219605 Test MSE 6.064979553680902 Test RE 1.1771253995326358\n",
      "73 Train Loss 1.1124984 Test MSE 6.0388961936875045 Test RE 1.174591469484451\n",
      "74 Train Loss 1.1021931 Test MSE 6.041049057498213 Test RE 1.1748008214962111\n",
      "75 Train Loss 1.0953046 Test MSE 6.020973680369674 Test RE 1.1728471710812538\n",
      "76 Train Loss 1.0881853 Test MSE 6.0134562871832 Test RE 1.1721147723426697\n",
      "77 Train Loss 1.0821743 Test MSE 6.019024285168134 Test RE 1.1726572908509445\n",
      "78 Train Loss 1.0723108 Test MSE 6.015987182243061 Test RE 1.172361401509144\n",
      "79 Train Loss 1.0665599 Test MSE 6.028515572763784 Test RE 1.1735814974037069\n",
      "80 Train Loss 1.061362 Test MSE 6.0173034856684895 Test RE 1.172489651360636\n",
      "81 Train Loss 1.0553765 Test MSE 6.0029519206636905 Test RE 1.1710905938912572\n",
      "82 Train Loss 1.0484629 Test MSE 6.0094071925842965 Test RE 1.1717200906027767\n",
      "83 Train Loss 1.0435877 Test MSE 5.998680273553115 Test RE 1.1706738509233312\n",
      "84 Train Loss 1.0377029 Test MSE 5.9740119890842545 Test RE 1.168264298769144\n",
      "85 Train Loss 1.0334235 Test MSE 5.98515456132086 Test RE 1.1693532993483924\n",
      "86 Train Loss 1.0264264 Test MSE 5.99149881174443 Test RE 1.1699728911389244\n",
      "87 Train Loss 1.021093 Test MSE 5.977086892276555 Test RE 1.168564920654082\n",
      "88 Train Loss 1.0154577 Test MSE 5.972753784828937 Test RE 1.1681412664988144\n",
      "89 Train Loss 1.0110673 Test MSE 5.974095212943667 Test RE 1.1682724362758417\n",
      "90 Train Loss 1.0034674 Test MSE 5.993248459513102 Test RE 1.170143707415406\n",
      "91 Train Loss 0.9975001 Test MSE 5.9830784571263536 Test RE 1.1691504716829828\n",
      "92 Train Loss 0.9914074 Test MSE 5.970585549218777 Test RE 1.1679292172925222\n",
      "93 Train Loss 0.9833517 Test MSE 5.975977512392364 Test RE 1.1684564696143696\n",
      "94 Train Loss 0.9785519 Test MSE 5.976133384021297 Test RE 1.1684717079603362\n",
      "95 Train Loss 0.9733622 Test MSE 5.978880270628591 Test RE 1.1687402169058305\n",
      "96 Train Loss 0.96919286 Test MSE 5.999258849173543 Test RE 1.170730305592315\n",
      "97 Train Loss 0.9633639 Test MSE 6.009077069610749 Test RE 1.1716879063106709\n",
      "98 Train Loss 0.9592452 Test MSE 6.0100238519476905 Test RE 1.1717802074834147\n",
      "99 Train Loss 0.9562592 Test MSE 6.031845704538694 Test RE 1.1739055938931557\n",
      "100 Train Loss 0.95214677 Test MSE 6.041954957777423 Test RE 1.1748889032587437\n",
      "101 Train Loss 0.94668174 Test MSE 6.042088743242628 Test RE 1.1749019108191672\n",
      "102 Train Loss 0.94322336 Test MSE 6.044834371480979 Test RE 1.1751688282391453\n",
      "103 Train Loss 0.9386328 Test MSE 6.049580504414458 Test RE 1.1756300826559578\n",
      "104 Train Loss 0.9345684 Test MSE 6.059905388946937 Test RE 1.1766328852588754\n",
      "105 Train Loss 0.93042845 Test MSE 6.061199386117768 Test RE 1.1767585042459674\n",
      "106 Train Loss 0.92729 Test MSE 6.048137690791605 Test RE 1.1754898815093202\n",
      "107 Train Loss 0.9226803 Test MSE 6.055749222685482 Test RE 1.1762293211461115\n",
      "108 Train Loss 0.91929805 Test MSE 6.068402225927207 Test RE 1.1774574984413833\n",
      "109 Train Loss 0.91573656 Test MSE 6.086263233419449 Test RE 1.1791890189002\n",
      "110 Train Loss 0.9133134 Test MSE 6.093660720076363 Test RE 1.1799054179226716\n",
      "111 Train Loss 0.9100776 Test MSE 6.099070173017678 Test RE 1.180429013447437\n",
      "112 Train Loss 0.9067277 Test MSE 6.104041891400044 Test RE 1.180910034730287\n",
      "113 Train Loss 0.9037693 Test MSE 6.094967154363101 Test RE 1.1800318924962456\n",
      "114 Train Loss 0.8997071 Test MSE 6.091208874383053 Test RE 1.1796680206330628\n",
      "115 Train Loss 0.896273 Test MSE 6.086935982809411 Test RE 1.179254188343415\n",
      "116 Train Loss 0.89343697 Test MSE 6.090513090090771 Test RE 1.1796006433737634\n",
      "117 Train Loss 0.8886313 Test MSE 6.10925234697982 Test RE 1.1814139440145524\n",
      "118 Train Loss 0.8860204 Test MSE 6.120324696651247 Test RE 1.1824840509552181\n",
      "119 Train Loss 0.88296217 Test MSE 6.1126983253846285 Test RE 1.1817470905912517\n",
      "120 Train Loss 0.87961197 Test MSE 6.1126374908206085 Test RE 1.1817412101073739\n",
      "121 Train Loss 0.87669367 Test MSE 6.119357181583672 Test RE 1.1823905823558305\n",
      "122 Train Loss 0.87422955 Test MSE 6.119300879566667 Test RE 1.1823851429668695\n",
      "123 Train Loss 0.8722752 Test MSE 6.134562535648637 Test RE 1.183858670623808\n",
      "124 Train Loss 0.8696712 Test MSE 6.142752959785648 Test RE 1.184648708241157\n",
      "125 Train Loss 0.86472 Test MSE 6.13583358194853 Test RE 1.1839813086472104\n",
      "126 Train Loss 0.8625469 Test MSE 6.119454506377477 Test RE 1.1823999849334752\n",
      "127 Train Loss 0.8587555 Test MSE 6.115743758094108 Test RE 1.1820414354864597\n",
      "128 Train Loss 0.8553265 Test MSE 6.1123065578926505 Test RE 1.1817092204488489\n",
      "129 Train Loss 0.85178083 Test MSE 6.104610242834641 Test RE 1.1809650111132906\n",
      "130 Train Loss 0.84820014 Test MSE 6.1210655500862075 Test RE 1.1825556174900838\n",
      "131 Train Loss 0.846115 Test MSE 6.1285932263797385 Test RE 1.1832825465363541\n",
      "132 Train Loss 0.843238 Test MSE 6.127285226627163 Test RE 1.183156268301588\n",
      "133 Train Loss 0.8402144 Test MSE 6.137503425348122 Test RE 1.1841424056565117\n",
      "134 Train Loss 0.83751756 Test MSE 6.142047643623078 Test RE 1.1845806950984803\n",
      "135 Train Loss 0.83496106 Test MSE 6.149865187431602 Test RE 1.1853343172791713\n",
      "136 Train Loss 0.8323331 Test MSE 6.166477703154762 Test RE 1.1869341982782977\n",
      "137 Train Loss 0.8287702 Test MSE 6.176951109567944 Test RE 1.1879417402562764\n",
      "138 Train Loss 0.82626855 Test MSE 6.174193185186664 Test RE 1.1876765107593001\n",
      "139 Train Loss 0.82400703 Test MSE 6.169509212984347 Test RE 1.1872259175337445\n",
      "140 Train Loss 0.8212403 Test MSE 6.170846762245239 Test RE 1.187354605816305\n",
      "141 Train Loss 0.81790584 Test MSE 6.185627157017589 Test RE 1.1887757295599994\n",
      "142 Train Loss 0.8154325 Test MSE 6.196213563577049 Test RE 1.189792561230096\n",
      "143 Train Loss 0.81347436 Test MSE 6.202881474605545 Test RE 1.1904325728809724\n",
      "144 Train Loss 0.81184953 Test MSE 6.193373022062281 Test RE 1.189519810577327\n",
      "145 Train Loss 0.8094859 Test MSE 6.185379978071694 Test RE 1.188751977460187\n",
      "146 Train Loss 0.8078819 Test MSE 6.191638055200836 Test RE 1.1893531871559528\n",
      "147 Train Loss 0.80590147 Test MSE 6.1978966203757 Test RE 1.189954139948677\n",
      "148 Train Loss 0.80436385 Test MSE 6.205740674459408 Test RE 1.1907069044567995\n",
      "149 Train Loss 0.80205905 Test MSE 6.21922593865576 Test RE 1.191999923647204\n",
      "Training time: 230.84\n",
      "4\n",
      "KG_rowdy_tune63\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 55.99172 Test MSE 7.400516487700649 Test RE 1.3002865657544418\n",
      "1 Train Loss 49.230953 Test MSE 7.261932387490125 Test RE 1.2880542674577558\n",
      "2 Train Loss 42.50447 Test MSE 7.8138539570804095 Test RE 1.3361053568763523\n",
      "3 Train Loss 33.72592 Test MSE 8.332896680833386 Test RE 1.379767969418393\n",
      "4 Train Loss 27.925594 Test MSE 6.962814418995471 Test RE 1.261247941084653\n",
      "5 Train Loss 23.4317 Test MSE 6.213585904961336 Test RE 1.1914593061575298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Train Loss 20.283096 Test MSE 5.672759141662862 Test RE 1.1384271182790038\n",
      "7 Train Loss 16.171167 Test MSE 5.621873737527453 Test RE 1.1333096950892307\n",
      "8 Train Loss 14.150501 Test MSE 5.821562684021985 Test RE 1.1532616470378267\n",
      "9 Train Loss 12.003571 Test MSE 5.998385373599636 Test RE 1.1706450749349888\n",
      "10 Train Loss 11.1442795 Test MSE 5.868099833187826 Test RE 1.1578620164951028\n",
      "11 Train Loss 10.23995 Test MSE 5.59220655641709 Test RE 1.1303154462174796\n",
      "12 Train Loss 8.850821 Test MSE 5.134173852302943 Test RE 1.0830371291817704\n",
      "13 Train Loss 7.889505 Test MSE 4.95212392893493 Test RE 1.0636624126372645\n",
      "14 Train Loss 7.038872 Test MSE 4.927514941317402 Test RE 1.0610162495194972\n",
      "15 Train Loss 6.298857 Test MSE 4.753266875782534 Test RE 1.0420874356157064\n",
      "16 Train Loss 5.767113 Test MSE 4.629110378052823 Test RE 1.0283875930356592\n",
      "17 Train Loss 4.936807 Test MSE 4.346206712177776 Test RE 0.9964677540166725\n",
      "18 Train Loss 4.4006186 Test MSE 4.224022823210005 Test RE 0.9823611714673265\n",
      "19 Train Loss 4.0080085 Test MSE 4.129014264563368 Test RE 0.9712504922085613\n",
      "20 Train Loss 3.7521138 Test MSE 4.031860063678305 Test RE 0.9597558886949099\n",
      "21 Train Loss 3.525359 Test MSE 3.9837713502912013 Test RE 0.9540151298349521\n",
      "22 Train Loss 3.2803252 Test MSE 3.897764820601758 Test RE 0.9436607160763488\n",
      "23 Train Loss 3.1058521 Test MSE 3.67428196091845 Test RE 0.916208466268477\n",
      "24 Train Loss 2.9522438 Test MSE 3.500248038914054 Test RE 0.8942469565431925\n",
      "25 Train Loss 2.810576 Test MSE 3.4196476475333544 Test RE 0.8838910575814048\n",
      "26 Train Loss 2.6603231 Test MSE 3.34573539185972 Test RE 0.8742866672144073\n",
      "27 Train Loss 2.5333154 Test MSE 3.2905900425018904 Test RE 0.8670516117303239\n",
      "28 Train Loss 2.412154 Test MSE 3.1371203055166017 Test RE 0.8465909998836021\n",
      "29 Train Loss 2.2757387 Test MSE 3.0503637597757494 Test RE 0.8348027606457294\n",
      "30 Train Loss 2.150261 Test MSE 3.0699038401208303 Test RE 0.8374722903347338\n",
      "31 Train Loss 2.0856915 Test MSE 2.9861846858865957 Test RE 0.8259740293398774\n",
      "32 Train Loss 2.016652 Test MSE 2.880455240890394 Test RE 0.8112199561841835\n",
      "33 Train Loss 1.9277837 Test MSE 2.8016091627731567 Test RE 0.8000402462342238\n",
      "34 Train Loss 1.8808895 Test MSE 2.738448599753136 Test RE 0.7909706288711569\n",
      "35 Train Loss 1.8123224 Test MSE 2.6562151188485696 Test RE 0.7790039906058677\n",
      "36 Train Loss 1.7677267 Test MSE 2.5780075425381916 Test RE 0.76745010898663\n",
      "37 Train Loss 1.711097 Test MSE 2.516723183625292 Test RE 0.7582733368560998\n",
      "38 Train Loss 1.6657435 Test MSE 2.44405095469997 Test RE 0.7472452934441024\n",
      "39 Train Loss 1.6397529 Test MSE 2.4035729155249212 Test RE 0.7410315709119146\n",
      "40 Train Loss 1.5516675 Test MSE 2.275708693981949 Test RE 0.7210516825761171\n",
      "41 Train Loss 1.498204 Test MSE 2.1794634540045825 Test RE 0.7056394548692377\n",
      "42 Train Loss 1.4470779 Test MSE 2.043785027722248 Test RE 0.6833224147211427\n",
      "43 Train Loss 1.4191939 Test MSE 1.9527554174678845 Test RE 0.6679315929561362\n",
      "44 Train Loss 1.3740778 Test MSE 1.8972161582350895 Test RE 0.6583645949788121\n",
      "45 Train Loss 1.3309474 Test MSE 1.8104167924658867 Test RE 0.6431278918082834\n",
      "46 Train Loss 1.2759367 Test MSE 1.7091865815197484 Test RE 0.6248888817049922\n",
      "47 Train Loss 1.231693 Test MSE 1.6198293251416862 Test RE 0.6083348387906928\n",
      "48 Train Loss 1.1969246 Test MSE 1.4982665717418933 Test RE 0.5850629616319297\n",
      "49 Train Loss 1.1371353 Test MSE 1.3361305942492403 Test RE 0.5525002953213792\n",
      "50 Train Loss 1.0580211 Test MSE 1.0458414995139251 Test RE 0.4888110283423011\n",
      "51 Train Loss 0.9204677 Test MSE 0.7943482695251826 Test RE 0.4260038628705312\n",
      "52 Train Loss 0.8646357 Test MSE 0.75690325757293 Test RE 0.41584190094809903\n",
      "53 Train Loss 0.7910673 Test MSE 0.7373129858665306 Test RE 0.41042518418330354\n",
      "54 Train Loss 0.70960903 Test MSE 0.5968041269045079 Test RE 0.36925294614883675\n",
      "55 Train Loss 0.6067935 Test MSE 0.37880623288083054 Test RE 0.2941823537417284\n",
      "56 Train Loss 0.5694729 Test MSE 0.3214058244755528 Test RE 0.27097856066894693\n",
      "57 Train Loss 0.5337149 Test MSE 0.2863556222759458 Test RE 0.25577666327326504\n",
      "58 Train Loss 0.4912819 Test MSE 0.2543559313705426 Test RE 0.24106213299387186\n",
      "59 Train Loss 0.4714496 Test MSE 0.24167551960785846 Test RE 0.23497647842943295\n",
      "60 Train Loss 0.44117752 Test MSE 0.19219447206951823 Test RE 0.2095455808833021\n",
      "61 Train Loss 0.40377823 Test MSE 0.16403811655610767 Test RE 0.19358889788819453\n",
      "62 Train Loss 0.37251663 Test MSE 0.13550059854694796 Test RE 0.17594570391734596\n",
      "63 Train Loss 0.35659173 Test MSE 0.10367972093153109 Test RE 0.15390579410489852\n",
      "64 Train Loss 0.34660354 Test MSE 0.10084243332689967 Test RE 0.15178530184111932\n",
      "65 Train Loss 0.32701695 Test MSE 0.1020270707088038 Test RE 0.1526742408463639\n",
      "66 Train Loss 0.30999017 Test MSE 0.08381648357389887 Test RE 0.13837982548058123\n",
      "67 Train Loss 0.29717344 Test MSE 0.0771526556106278 Test RE 0.1327649694473384\n",
      "68 Train Loss 0.28921047 Test MSE 0.07575262091118284 Test RE 0.13155485853510998\n",
      "69 Train Loss 0.26260975 Test MSE 0.060076032259439006 Test RE 0.1171544207812442\n",
      "70 Train Loss 0.23437406 Test MSE 0.050375976745998856 Test RE 0.10728025575287735\n",
      "71 Train Loss 0.22323988 Test MSE 0.0520296950291738 Test RE 0.10902690919163256\n",
      "72 Train Loss 0.21239854 Test MSE 0.05577450663112697 Test RE 0.11288232059991228\n",
      "73 Train Loss 0.20218894 Test MSE 0.054549819357663565 Test RE 0.11163611609808598\n",
      "74 Train Loss 0.19760846 Test MSE 0.0561590994321389 Test RE 0.11327084169695159\n",
      "75 Train Loss 0.19026934 Test MSE 0.05544195039971943 Test RE 0.11254528629321499\n",
      "76 Train Loss 0.17997397 Test MSE 0.051542536318091095 Test RE 0.10851529442627579\n",
      "77 Train Loss 0.16792203 Test MSE 0.05365080688505198 Test RE 0.11071238058569648\n",
      "78 Train Loss 0.15737022 Test MSE 0.051749333668531704 Test RE 0.10873276734349345\n",
      "79 Train Loss 0.1492384 Test MSE 0.045417176113312197 Test RE 0.10186338972228859\n",
      "80 Train Loss 0.13659257 Test MSE 0.03699644427650985 Test RE 0.09193651843371056\n",
      "81 Train Loss 0.13413876 Test MSE 0.03412900079124104 Test RE 0.08830185904500414\n",
      "82 Train Loss 0.13200311 Test MSE 0.03306360098888361 Test RE 0.08691267881217872\n",
      "83 Train Loss 0.12581034 Test MSE 0.030136389957438902 Test RE 0.08297622519003878\n",
      "84 Train Loss 0.120861664 Test MSE 0.025523784073426894 Test RE 0.07636257966851083\n",
      "85 Train Loss 0.11304706 Test MSE 0.01713933274929273 Test RE 0.06257559899092568\n",
      "86 Train Loss 0.11016126 Test MSE 0.018168145339796393 Test RE 0.06442632484214866\n",
      "87 Train Loss 0.108665824 Test MSE 0.01904967208243012 Test RE 0.06597080938260118\n",
      "88 Train Loss 0.105803445 Test MSE 0.018852716738304017 Test RE 0.0656288858384851\n",
      "89 Train Loss 0.103006735 Test MSE 0.019059633411506044 Test RE 0.06598805563892075\n",
      "90 Train Loss 0.10060185 Test MSE 0.019279621216001797 Test RE 0.06636778276516986\n",
      "91 Train Loss 0.09339386 Test MSE 0.01911664405461451 Test RE 0.06608667276324945\n",
      "92 Train Loss 0.08768686 Test MSE 0.019387224750785262 Test RE 0.06655273119425008\n",
      "93 Train Loss 0.08299235 Test MSE 0.020472275306555144 Test RE 0.06838976586098967\n",
      "94 Train Loss 0.07880826 Test MSE 0.021717723696163472 Test RE 0.07043932928863869\n",
      "95 Train Loss 0.076055855 Test MSE 0.021824818925821367 Test RE 0.07061279219732869\n",
      "96 Train Loss 0.074411616 Test MSE 0.021813348096318998 Test RE 0.0705942331943811\n",
      "97 Train Loss 0.07261623 Test MSE 0.022596760123397227 Test RE 0.0718507238885887\n",
      "98 Train Loss 0.0666047 Test MSE 0.024952698234742735 Test RE 0.07550345366928397\n",
      "99 Train Loss 0.059485752 Test MSE 0.023401880980560192 Test RE 0.07311953879486728\n",
      "100 Train Loss 0.054693375 Test MSE 0.023245786314310592 Test RE 0.07287527068698073\n",
      "101 Train Loss 0.0507938 Test MSE 0.021240205649942848 Test RE 0.06966063338525023\n",
      "102 Train Loss 0.049614504 Test MSE 0.020752349652588244 Test RE 0.06885598547672937\n",
      "103 Train Loss 0.04836225 Test MSE 0.01965806627190851 Test RE 0.06701599309714183\n",
      "104 Train Loss 0.044694863 Test MSE 0.018576713712977765 Test RE 0.06514671243906499\n",
      "105 Train Loss 0.04191819 Test MSE 0.01852506653345649 Test RE 0.0650560886111375\n",
      "106 Train Loss 0.039343234 Test MSE 0.017496322704012586 Test RE 0.06322392451559866\n",
      "107 Train Loss 0.038404442 Test MSE 0.017962395914902316 Test RE 0.06406048060436666\n",
      "108 Train Loss 0.037951853 Test MSE 0.017748388348440888 Test RE 0.06367772245453285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 Train Loss 0.036875844 Test MSE 0.015321212725233357 Test RE 0.05916360536223282\n",
      "110 Train Loss 0.03445239 Test MSE 0.012110716737189454 Test RE 0.052600876802108176\n",
      "111 Train Loss 0.03148061 Test MSE 0.010682544519666182 Test RE 0.04940210063112566\n",
      "112 Train Loss 0.030186672 Test MSE 0.010582642055863737 Test RE 0.049170555389293685\n",
      "113 Train Loss 0.029462831 Test MSE 0.0103660302269759 Test RE 0.048664727483907426\n",
      "114 Train Loss 0.027837949 Test MSE 0.007873292948459914 Test RE 0.042411757127352505\n",
      "115 Train Loss 0.025722014 Test MSE 0.006901220619505452 Test RE 0.03970736023372843\n",
      "116 Train Loss 0.02448319 Test MSE 0.007011331821906141 Test RE 0.04002287853929002\n",
      "117 Train Loss 0.023352789 Test MSE 0.005530145591132708 Test RE 0.03554482192443049\n",
      "118 Train Loss 0.022475049 Test MSE 0.005712853906857086 Test RE 0.03612722628636596\n",
      "119 Train Loss 0.021910772 Test MSE 0.005897209945061741 Test RE 0.03670551779346935\n",
      "120 Train Loss 0.02055347 Test MSE 0.005309797660986047 Test RE 0.03482948446427186\n",
      "121 Train Loss 0.019269845 Test MSE 0.005456147511106642 Test RE 0.035306210965436007\n",
      "122 Train Loss 0.0181832 Test MSE 0.005206087816959349 Test RE 0.03448766609342125\n",
      "123 Train Loss 0.017520053 Test MSE 0.0050179845639253895 Test RE 0.03385889033630508\n",
      "124 Train Loss 0.017076459 Test MSE 0.005251698319102698 Test RE 0.03463840975863029\n",
      "125 Train Loss 0.016607173 Test MSE 0.00541332856796942 Test RE 0.03516739943478587\n",
      "126 Train Loss 0.016285893 Test MSE 0.005507886051376284 Test RE 0.03547321357780212\n",
      "127 Train Loss 0.015395513 Test MSE 0.006073794342461296 Test RE 0.03725101422043717\n",
      "128 Train Loss 0.014506291 Test MSE 0.006065100457979842 Test RE 0.03722434456641668\n",
      "129 Train Loss 0.013739125 Test MSE 0.00501293403896155 Test RE 0.033841846818244765\n",
      "130 Train Loss 0.013488525 Test MSE 0.004886390846736345 Test RE 0.03341197603283388\n",
      "131 Train Loss 0.013371671 Test MSE 0.004799408269335076 Test RE 0.03311325762615459\n",
      "132 Train Loss 0.01332651 Test MSE 0.004613494799742456 Test RE 0.03246557342212771\n",
      "133 Train Loss 0.013262714 Test MSE 0.0044139612358430344 Test RE 0.03175574586238343\n",
      "134 Train Loss 0.012965466 Test MSE 0.0037988155300036257 Test RE 0.029459960667356757\n",
      "135 Train Loss 0.012306859 Test MSE 0.003362259471248597 Test RE 0.02771556096040803\n",
      "136 Train Loss 0.011837322 Test MSE 0.003224745273499343 Test RE 0.027142870066534774\n",
      "137 Train Loss 0.011602134 Test MSE 0.003104856369612186 Test RE 0.02663353527665765\n",
      "138 Train Loss 0.0114653185 Test MSE 0.0030314125114455238 Test RE 0.026316648488922997\n",
      "139 Train Loss 0.011194234 Test MSE 0.0028095721936750376 Test RE 0.025335422920306203\n",
      "140 Train Loss 0.010869551 Test MSE 0.0029782314269368106 Test RE 0.026084786192691826\n",
      "141 Train Loss 0.010460146 Test MSE 0.003113230420155252 Test RE 0.026669427498964747\n",
      "142 Train Loss 0.010267613 Test MSE 0.00291779627822921 Test RE 0.025818769675227175\n",
      "143 Train Loss 0.01011088 Test MSE 0.0029045784170914717 Test RE 0.025760222701445408\n",
      "144 Train Loss 0.009947924 Test MSE 0.002822350829074657 Test RE 0.025392973468632438\n",
      "145 Train Loss 0.009807888 Test MSE 0.0028821806275209395 Test RE 0.02566070935379296\n",
      "146 Train Loss 0.009657912 Test MSE 0.00284539257886133 Test RE 0.025496417235228074\n",
      "147 Train Loss 0.0095282225 Test MSE 0.0026982463727935105 Test RE 0.024828407302370528\n",
      "148 Train Loss 0.009224558 Test MSE 0.002543832130920439 Test RE 0.024107506057453175\n",
      "149 Train Loss 0.009075925 Test MSE 0.0026217214515375773 Test RE 0.024473795909398993\n",
      "Training time: 229.06\n",
      "5\n",
      "KG_rowdy_tune63\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 69.83956 Test MSE 4.643663289062069 Test RE 1.0300028374208856\n",
      "1 Train Loss 50.419315 Test MSE 5.916733096337671 Test RE 1.1626501437299872\n",
      "2 Train Loss 38.19156 Test MSE 5.722516028823607 Test RE 1.1434089022583542\n",
      "3 Train Loss 25.972185 Test MSE 5.486339674182746 Test RE 1.1195652409680585\n",
      "4 Train Loss 21.700956 Test MSE 6.107793323515398 Test RE 1.1812728618088355\n",
      "5 Train Loss 19.24081 Test MSE 5.96517776453299 Test RE 1.1674001786856072\n",
      "6 Train Loss 17.70511 Test MSE 5.959188261439207 Test RE 1.166813951140951\n",
      "7 Train Loss 16.910429 Test MSE 6.016660456796022 Test RE 1.1724270016335931\n",
      "8 Train Loss 15.835079 Test MSE 5.787801802401911 Test RE 1.1499127401134794\n",
      "9 Train Loss 14.452769 Test MSE 5.94521361908497 Test RE 1.1654450248973958\n",
      "10 Train Loss 13.809706 Test MSE 6.147842457115002 Test RE 1.1851393691977339\n",
      "11 Train Loss 13.362194 Test MSE 6.020367832009659 Test RE 1.1727881619036171\n",
      "12 Train Loss 13.026491 Test MSE 5.986140070116351 Test RE 1.1694495675829961\n",
      "13 Train Loss 12.779399 Test MSE 5.884575571304936 Test RE 1.1594863293394684\n",
      "14 Train Loss 12.609772 Test MSE 5.786631366036955 Test RE 1.1497964638669944\n",
      "15 Train Loss 12.386656 Test MSE 5.863832340774073 Test RE 1.1574409205537124\n",
      "16 Train Loss 12.233887 Test MSE 5.787133053450173 Test RE 1.149846305119625\n",
      "17 Train Loss 11.901518 Test MSE 5.779270816159257 Test RE 1.1490649651193527\n",
      "18 Train Loss 11.519404 Test MSE 5.786317755379494 Test RE 1.1497653064208146\n",
      "19 Train Loss 11.268475 Test MSE 5.702310978428987 Test RE 1.1413885441551725\n",
      "20 Train Loss 11.043635 Test MSE 5.668503938734981 Test RE 1.1380000644365331\n",
      "21 Train Loss 10.852409 Test MSE 5.728255314751834 Test RE 1.1439821384030033\n",
      "22 Train Loss 10.555164 Test MSE 5.7291954271494925 Test RE 1.1440760088408024\n",
      "23 Train Loss 10.094885 Test MSE 5.741341749183124 Test RE 1.1452881300104727\n",
      "24 Train Loss 9.836164 Test MSE 5.5166915199587505 Test RE 1.1226578314166469\n",
      "25 Train Loss 9.537279 Test MSE 5.279454213462848 Test RE 1.0982534448299297\n",
      "26 Train Loss 9.05903 Test MSE 5.3211432695794185 Test RE 1.1025810815022794\n",
      "27 Train Loss 8.505025 Test MSE 5.420323282883777 Test RE 1.1128090660403764\n",
      "28 Train Loss 8.028302 Test MSE 5.428474357075177 Test RE 1.1136454720314843\n",
      "29 Train Loss 7.4540863 Test MSE 5.32096610247555 Test RE 1.1025627261683704\n",
      "30 Train Loss 6.9188604 Test MSE 5.08499767130569 Test RE 1.0778378723179203\n",
      "31 Train Loss 6.4744434 Test MSE 5.069181353355807 Test RE 1.076160319615321\n",
      "32 Train Loss 6.160154 Test MSE 4.989097246703987 Test RE 1.067625762111791\n",
      "33 Train Loss 5.8398247 Test MSE 5.006110337286739 Test RE 1.0694445435989068\n",
      "34 Train Loss 5.6054745 Test MSE 5.150607083924282 Test RE 1.0847690126023484\n",
      "35 Train Loss 5.3285913 Test MSE 5.078107715043916 Test RE 1.077107412487958\n",
      "36 Train Loss 4.9993114 Test MSE 4.900642648410883 Test RE 1.0581191585182088\n",
      "37 Train Loss 4.7598805 Test MSE 4.810489408986032 Test RE 1.0483412910182237\n",
      "38 Train Loss 4.4605527 Test MSE 4.914815005421682 Test RE 1.0596480616938053\n",
      "39 Train Loss 4.2041287 Test MSE 4.94169841106694 Test RE 1.0625421787503966\n",
      "40 Train Loss 3.8407586 Test MSE 4.763411461673236 Test RE 1.0431988723648213\n",
      "41 Train Loss 3.4015558 Test MSE 4.61193998368237 Test RE 1.026478562603935\n",
      "42 Train Loss 3.0326986 Test MSE 4.433095971445031 Test RE 1.0063791416979602\n",
      "43 Train Loss 2.7871535 Test MSE 4.338877470144189 Test RE 0.9956272009275138\n",
      "44 Train Loss 2.6342306 Test MSE 4.415062571981573 Test RE 1.004330129975491\n",
      "45 Train Loss 2.4966688 Test MSE 4.516748443534684 Test RE 1.0158299475639976\n",
      "46 Train Loss 2.3982997 Test MSE 4.483971482815812 Test RE 1.012137419208752\n",
      "47 Train Loss 2.3099027 Test MSE 4.488208026843628 Test RE 1.0126154499450137\n",
      "48 Train Loss 2.2186463 Test MSE 4.5671713544359385 Test RE 1.0214843407347194\n",
      "49 Train Loss 2.152665 Test MSE 4.476692085158894 Test RE 1.0113155201995736\n",
      "50 Train Loss 2.0289571 Test MSE 4.508692029224744 Test RE 1.0149235876389968\n",
      "51 Train Loss 1.9791279 Test MSE 4.500625287133503 Test RE 1.0140152541293046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 1.8881508 Test MSE 4.519311712067686 Test RE 1.0161181499793321\n",
      "53 Train Loss 1.8159359 Test MSE 4.614434544473894 Test RE 1.0267561320242418\n",
      "54 Train Loss 1.748514 Test MSE 4.627950457680159 Test RE 1.0282587429591514\n",
      "55 Train Loss 1.7192708 Test MSE 4.648214153896311 Test RE 1.0305074235127156\n",
      "56 Train Loss 1.672803 Test MSE 4.6828795741845 Test RE 1.0343429413411946\n",
      "57 Train Loss 1.6139023 Test MSE 4.616773674818211 Test RE 1.0270163385686768\n",
      "58 Train Loss 1.572741 Test MSE 4.655381335126903 Test RE 1.031301598255791\n",
      "59 Train Loss 1.5611317 Test MSE 4.655420664224793 Test RE 1.0313059545128755\n",
      "60 Train Loss 1.547044 Test MSE 4.65487610336035 Test RE 1.0312456350136399\n",
      "61 Train Loss 1.5231795 Test MSE 4.611474341022583 Test RE 1.0264267422989255\n",
      "62 Train Loss 1.479674 Test MSE 4.605825457340527 Test RE 1.0257978824627003\n",
      "63 Train Loss 1.4586719 Test MSE 4.636320581503317 Test RE 1.0291881786878365\n",
      "64 Train Loss 1.443385 Test MSE 4.656787211502741 Test RE 1.0314573076384574\n",
      "65 Train Loss 1.4108334 Test MSE 4.639024619471538 Test RE 1.029488261286146\n",
      "66 Train Loss 1.3846688 Test MSE 4.591918968033579 Test RE 1.0242481025632069\n",
      "67 Train Loss 1.3500164 Test MSE 4.611548855708985 Test RE 1.0264350350435227\n",
      "68 Train Loss 1.2956195 Test MSE 4.702649088499508 Test RE 1.0365239627725924\n",
      "69 Train Loss 1.2785269 Test MSE 4.705092229953779 Test RE 1.0367931776121306\n",
      "70 Train Loss 1.2585694 Test MSE 4.71037088990038 Test RE 1.0373746055844277\n",
      "71 Train Loss 1.2198937 Test MSE 4.722694781149025 Test RE 1.0387307769907035\n",
      "72 Train Loss 1.1769574 Test MSE 4.731450175541616 Test RE 1.0396931816004047\n",
      "73 Train Loss 1.1557039 Test MSE 4.7676626058156915 Test RE 1.043664274082379\n",
      "74 Train Loss 1.1414003 Test MSE 4.8046852574624515 Test RE 1.0477086559895465\n",
      "75 Train Loss 1.1230073 Test MSE 4.7884148435199645 Test RE 1.0459331901014557\n",
      "76 Train Loss 1.1119666 Test MSE 4.764879619718014 Test RE 1.043359625097707\n",
      "77 Train Loss 1.1004748 Test MSE 4.767198500110728 Test RE 1.043613475360658\n",
      "78 Train Loss 1.075085 Test MSE 4.8245839902953 Test RE 1.0498759710564762\n",
      "79 Train Loss 1.0511347 Test MSE 4.847573901626894 Test RE 1.0523744113576177\n",
      "80 Train Loss 1.0373764 Test MSE 4.841440764639849 Test RE 1.0517084700683814\n",
      "81 Train Loss 1.0228794 Test MSE 4.832648191657723 Test RE 1.0507530286789646\n",
      "82 Train Loss 1.0133101 Test MSE 4.815538313255347 Test RE 1.0488912960460695\n",
      "83 Train Loss 0.9927385 Test MSE 4.82554157243506 Test RE 1.0499801554380508\n",
      "84 Train Loss 0.97755426 Test MSE 4.8245608961679185 Test RE 1.0498734583011304\n",
      "85 Train Loss 0.96419513 Test MSE 4.839977147740239 Test RE 1.0515494869558049\n",
      "86 Train Loss 0.95144606 Test MSE 4.8284016617667715 Test RE 1.0502912699683309\n",
      "87 Train Loss 0.9385023 Test MSE 4.8003760944730995 Test RE 1.0472387230118323\n",
      "88 Train Loss 0.9296639 Test MSE 4.818721348960905 Test RE 1.0492378935295132\n",
      "89 Train Loss 0.92020965 Test MSE 4.826667466422596 Test RE 1.0501026388296726\n",
      "90 Train Loss 0.9130313 Test MSE 4.816828940043315 Test RE 1.049031844872008\n",
      "91 Train Loss 0.9002063 Test MSE 4.81077001011529 Test RE 1.0483718660216659\n",
      "92 Train Loss 0.8891851 Test MSE 4.802418411860556 Test RE 1.047461472893503\n",
      "93 Train Loss 0.87742925 Test MSE 4.786322773335737 Test RE 1.045704679752084\n",
      "94 Train Loss 0.8681525 Test MSE 4.7772153345380435 Test RE 1.0447093199978674\n",
      "95 Train Loss 0.8596934 Test MSE 4.783065224581267 Test RE 1.0453487683419607\n",
      "96 Train Loss 0.85023916 Test MSE 4.788062930675136 Test RE 1.045894755243633\n",
      "97 Train Loss 0.8385319 Test MSE 4.779861687252825 Test RE 1.0449986398613607\n",
      "98 Train Loss 0.828703 Test MSE 4.7703673105775035 Test RE 1.0439602685489686\n",
      "99 Train Loss 0.82084876 Test MSE 4.757891625342898 Test RE 1.0425942682671787\n",
      "100 Train Loss 0.8158965 Test MSE 4.735189344811274 Test RE 1.0401039247006145\n",
      "101 Train Loss 0.8088241 Test MSE 4.717625563042874 Test RE 1.0381731539765113\n",
      "102 Train Loss 0.80260557 Test MSE 4.732609558671293 Test RE 1.0398205557517612\n",
      "103 Train Loss 0.79359525 Test MSE 4.745838446568279 Test RE 1.0412728274982448\n",
      "104 Train Loss 0.7842428 Test MSE 4.740566925306407 Test RE 1.0406943610129016\n",
      "105 Train Loss 0.7743733 Test MSE 4.744032755352601 Test RE 1.0410747175015955\n",
      "106 Train Loss 0.76420534 Test MSE 4.731049393504469 Test RE 1.03964914656249\n",
      "107 Train Loss 0.75464964 Test MSE 4.701687749834047 Test RE 1.036418011693278\n",
      "108 Train Loss 0.74770236 Test MSE 4.689195410851047 Test RE 1.035040219561307\n",
      "109 Train Loss 0.74219084 Test MSE 4.70576073187529 Test RE 1.036866829049805\n",
      "110 Train Loss 0.73333246 Test MSE 4.721011627390724 Test RE 1.0385456602833991\n",
      "111 Train Loss 0.72309256 Test MSE 4.723147856409165 Test RE 1.0387806015031855\n",
      "112 Train Loss 0.7125664 Test MSE 4.712840162629544 Test RE 1.0376464764482825\n",
      "113 Train Loss 0.7033233 Test MSE 4.693565074682302 Test RE 1.0355223624727452\n",
      "114 Train Loss 0.69626117 Test MSE 4.667584447371583 Test RE 1.0326523847704254\n",
      "115 Train Loss 0.6910355 Test MSE 4.665986857484906 Test RE 1.032475644936799\n",
      "116 Train Loss 0.68487847 Test MSE 4.6860848616383945 Test RE 1.0346968687994818\n",
      "117 Train Loss 0.67970157 Test MSE 4.6879502356595015 Test RE 1.0349027874583636\n",
      "118 Train Loss 0.6765188 Test MSE 4.689739391065858 Test RE 1.0351002538554008\n",
      "119 Train Loss 0.6724182 Test MSE 4.691526186592157 Test RE 1.0352974222069506\n",
      "120 Train Loss 0.6680466 Test MSE 4.682389860962134 Test RE 1.0342888566001542\n",
      "121 Train Loss 0.6637696 Test MSE 4.669436930676087 Test RE 1.032857285351774\n",
      "122 Train Loss 0.6589577 Test MSE 4.683562607479324 Test RE 1.0344183719492366\n",
      "123 Train Loss 0.65246755 Test MSE 4.688476383036865 Test RE 1.0349608614654202\n",
      "124 Train Loss 0.64774454 Test MSE 4.6728393903562555 Test RE 1.033233520792421\n",
      "125 Train Loss 0.6456281 Test MSE 4.666594883007882 Test RE 1.032542913781872\n",
      "126 Train Loss 0.6413563 Test MSE 4.682121683617013 Test RE 1.034259237450581\n",
      "127 Train Loss 0.6372379 Test MSE 4.692921296200468 Test RE 1.0354513429103205\n",
      "128 Train Loss 0.632857 Test MSE 4.671894478724158 Test RE 1.03312904858057\n",
      "129 Train Loss 0.6297132 Test MSE 4.671625340901556 Test RE 1.0330992899774478\n",
      "130 Train Loss 0.6266521 Test MSE 4.658800443863873 Test RE 1.031680244477632\n",
      "131 Train Loss 0.62279165 Test MSE 4.638180202286972 Test RE 1.0293945608627408\n",
      "132 Train Loss 0.6177145 Test MSE 4.639439617964245 Test RE 1.0295343083065036\n",
      "133 Train Loss 0.6144184 Test MSE 4.6347907021841035 Test RE 1.029018360445774\n",
      "134 Train Loss 0.6094233 Test MSE 4.627369692347979 Test RE 1.028194222414677\n",
      "135 Train Loss 0.6044476 Test MSE 4.638089834207675 Test RE 1.0293845326988529\n",
      "136 Train Loss 0.60017806 Test MSE 4.632015643863125 Test RE 1.0287102544581286\n",
      "137 Train Loss 0.59654826 Test MSE 4.619554336211164 Test RE 1.027325575603745\n",
      "138 Train Loss 0.5925194 Test MSE 4.629183393306644 Test RE 1.0283957034152906\n",
      "139 Train Loss 0.5897757 Test MSE 4.6454918946302675 Test RE 1.030205617362337\n",
      "140 Train Loss 0.58784753 Test MSE 4.624385007506345 Test RE 1.0278625728028479\n",
      "141 Train Loss 0.5860555 Test MSE 4.628154970603446 Test RE 1.0282814625064047\n",
      "142 Train Loss 0.58341235 Test MSE 4.642423749381223 Test RE 1.029865358180891\n",
      "143 Train Loss 0.5803826 Test MSE 4.645016095223399 Test RE 1.0301528582805752\n",
      "144 Train Loss 0.5777265 Test MSE 4.632031962604534 Test RE 1.0287120665463356\n",
      "145 Train Loss 0.5753564 Test MSE 4.613785325525262 Test RE 1.0266839007488933\n",
      "146 Train Loss 0.57277715 Test MSE 4.605714982545671 Test RE 1.0257855800544526\n",
      "147 Train Loss 0.5694187 Test MSE 4.619925346765659 Test RE 1.0273668286068725\n",
      "148 Train Loss 0.56642026 Test MSE 4.625959221586451 Test RE 1.0280375082862319\n",
      "149 Train Loss 0.56408036 Test MSE 4.624451110789698 Test RE 1.027869919168686\n",
      "Training time: 229.34\n",
      "6\n",
      "KG_rowdy_tune63\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 67.10001 Test MSE 6.254223434593938 Test RE 1.1953490935306492\n",
      "1 Train Loss 48.455776 Test MSE 8.7686023471279 Test RE 1.4153806305311132\n",
      "2 Train Loss 42.10957 Test MSE 9.605472790832616 Test RE 1.4813832621670513\n",
      "3 Train Loss 37.6369 Test MSE 9.577675242493836 Test RE 1.4792382007494163\n",
      "4 Train Loss 35.070183 Test MSE 9.488781746177704 Test RE 1.472357554481659\n",
      "5 Train Loss 32.46168 Test MSE 9.274382765824695 Test RE 1.4556285605644323\n",
      "6 Train Loss 29.944715 Test MSE 9.422286284265692 Test RE 1.4671894925147624\n",
      "7 Train Loss 28.255468 Test MSE 9.502760431966532 Test RE 1.4734416793799463\n",
      "8 Train Loss 25.772423 Test MSE 9.405927300610168 Test RE 1.465915271205105\n",
      "9 Train Loss 24.263435 Test MSE 9.116314026803638 Test RE 1.443170685544584\n",
      "10 Train Loss 22.87183 Test MSE 9.07374958210744 Test RE 1.4397976320980992\n",
      "11 Train Loss 21.5687 Test MSE 9.114093945923157 Test RE 1.442994948359353\n",
      "12 Train Loss 20.676945 Test MSE 9.269888227648746 Test RE 1.4552758055007111\n",
      "13 Train Loss 19.815409 Test MSE 9.118092355414316 Test RE 1.4433114390643593\n",
      "14 Train Loss 18.8274 Test MSE 9.047688288172738 Test RE 1.4377284780642283\n",
      "15 Train Loss 18.002033 Test MSE 8.94332558689364 Test RE 1.429412518257261\n",
      "16 Train Loss 17.31423 Test MSE 8.777792529232414 Test RE 1.4161221511728554\n",
      "17 Train Loss 16.721886 Test MSE 8.709645528333958 Test RE 1.410614359059351\n",
      "18 Train Loss 15.903742 Test MSE 8.576591509616946 Test RE 1.399798175645609\n",
      "19 Train Loss 15.337006 Test MSE 8.460981492501537 Test RE 1.3903317252675755\n",
      "20 Train Loss 14.534809 Test MSE 8.45413546913488 Test RE 1.389769132757625\n",
      "21 Train Loss 13.768287 Test MSE 8.27561958149633 Test RE 1.3750177977385263\n",
      "22 Train Loss 13.053416 Test MSE 8.148266074622184 Test RE 1.3643967030987174\n",
      "23 Train Loss 11.968979 Test MSE 7.927672893472779 Test RE 1.345801231617303\n",
      "24 Train Loss 10.919632 Test MSE 7.651247811924663 Test RE 1.3221301055323191\n",
      "25 Train Loss 9.844216 Test MSE 7.660297929236476 Test RE 1.3229118013208132\n",
      "26 Train Loss 8.646439 Test MSE 7.470674741221086 Test RE 1.306435504419082\n",
      "27 Train Loss 7.93364 Test MSE 7.3501384644943375 Test RE 1.2958532448801254\n",
      "28 Train Loss 7.248661 Test MSE 7.2146403592367605 Test RE 1.2838533059364965\n",
      "29 Train Loss 6.4424434 Test MSE 7.0397514284340375 Test RE 1.2681970031518763\n",
      "30 Train Loss 5.7210174 Test MSE 7.053875070678512 Test RE 1.2694685385245328\n",
      "31 Train Loss 5.253861 Test MSE 7.015411736220665 Test RE 1.2660027316562772\n",
      "32 Train Loss 4.7534885 Test MSE 6.7392755089255685 Test RE 1.2408368023394056\n",
      "33 Train Loss 4.396679 Test MSE 6.635110053402101 Test RE 1.231209975648377\n",
      "34 Train Loss 4.0380025 Test MSE 6.686400573618052 Test RE 1.2359595449986391\n",
      "35 Train Loss 3.831896 Test MSE 6.743836092786831 Test RE 1.241256579156358\n",
      "36 Train Loss 3.6211224 Test MSE 6.7831711338733705 Test RE 1.2448712792354766\n",
      "37 Train Loss 3.460415 Test MSE 6.705815768808732 Test RE 1.2377526623347959\n",
      "38 Train Loss 3.3445525 Test MSE 6.708775178992359 Test RE 1.2380257546704978\n",
      "39 Train Loss 3.2742074 Test MSE 6.707707692344729 Test RE 1.237927254683311\n",
      "40 Train Loss 3.2155442 Test MSE 6.7030208286082065 Test RE 1.237494691840439\n",
      "41 Train Loss 3.1510081 Test MSE 6.729923073050239 Test RE 1.2399755172082727\n",
      "42 Train Loss 3.0848632 Test MSE 6.748423951194197 Test RE 1.2416787232557998\n",
      "43 Train Loss 3.0477598 Test MSE 6.74274689672345 Test RE 1.241156337516832\n",
      "44 Train Loss 3.0018265 Test MSE 6.727627395809564 Test RE 1.239764012088719\n",
      "45 Train Loss 2.963813 Test MSE 6.725826796195245 Test RE 1.2395980941613025\n",
      "46 Train Loss 2.9206948 Test MSE 6.72371018530907 Test RE 1.2394030286804927\n",
      "47 Train Loss 2.8853755 Test MSE 6.719595835535274 Test RE 1.2390237650179308\n",
      "48 Train Loss 2.8627994 Test MSE 6.702299302075937 Test RE 1.2374280868495091\n",
      "49 Train Loss 2.819309 Test MSE 6.676628353525743 Test RE 1.2350560330987275\n",
      "50 Train Loss 2.7724643 Test MSE 6.676219030460206 Test RE 1.235018173819817\n",
      "51 Train Loss 2.7358654 Test MSE 6.7066782956799464 Test RE 1.2378322619421138\n",
      "52 Train Loss 2.708839 Test MSE 6.743024422732608 Test RE 1.2411818797495517\n",
      "53 Train Loss 2.6759088 Test MSE 6.768569733587334 Test RE 1.2435307074085762\n",
      "54 Train Loss 2.6415055 Test MSE 6.773585856712097 Test RE 1.2439914065027395\n",
      "55 Train Loss 2.5962362 Test MSE 6.765765517044879 Test RE 1.2432730835107622\n",
      "56 Train Loss 2.5707626 Test MSE 6.719286176780811 Test RE 1.2389952157580102\n",
      "57 Train Loss 2.542201 Test MSE 6.727831004054567 Test RE 1.2397827723625878\n",
      "58 Train Loss 2.5188274 Test MSE 6.755170643968247 Test RE 1.2422992483004214\n",
      "59 Train Loss 2.4952068 Test MSE 6.761550946940392 Test RE 1.2428857897284242\n",
      "60 Train Loss 2.4630709 Test MSE 6.76450570909872 Test RE 1.243157327339153\n",
      "61 Train Loss 2.438219 Test MSE 6.762865278100529 Test RE 1.243006581848323\n",
      "62 Train Loss 2.4159625 Test MSE 6.783291598874481 Test RE 1.2448823332654622\n",
      "63 Train Loss 2.4009285 Test MSE 6.819477008907811 Test RE 1.2481983238561258\n",
      "64 Train Loss 2.374798 Test MSE 6.820088840414485 Test RE 1.248254315681578\n",
      "65 Train Loss 2.3530076 Test MSE 6.820339410438053 Test RE 1.2482772458990445\n",
      "66 Train Loss 2.3301725 Test MSE 6.803134168179092 Test RE 1.2467017763472632\n",
      "67 Train Loss 2.2895389 Test MSE 6.771910467162686 Test RE 1.2438375515773323\n",
      "68 Train Loss 2.268134 Test MSE 6.782415985116398 Test RE 1.2448019835369337\n",
      "69 Train Loss 2.2468052 Test MSE 6.7753319229397775 Test RE 1.2441517315852202\n",
      "70 Train Loss 2.2234192 Test MSE 6.719469308850415 Test RE 1.2390120998589491\n",
      "71 Train Loss 2.1957576 Test MSE 6.7040603219942385 Test RE 1.2375906424358674\n",
      "72 Train Loss 2.1786122 Test MSE 6.700561168977475 Test RE 1.2372676229489412\n",
      "73 Train Loss 2.1586065 Test MSE 6.671744522541092 Test RE 1.2346042400645023\n",
      "74 Train Loss 2.1410103 Test MSE 6.669258038222968 Test RE 1.2343741570519413\n",
      "75 Train Loss 2.1225045 Test MSE 6.667859658744695 Test RE 1.2342447413080357\n",
      "76 Train Loss 2.0983078 Test MSE 6.620461599334634 Test RE 1.229850142287524\n",
      "77 Train Loss 2.0820146 Test MSE 6.611201341541568 Test RE 1.2289897253491526\n",
      "78 Train Loss 2.066363 Test MSE 6.5985239736191135 Test RE 1.227810829839268\n",
      "79 Train Loss 2.040015 Test MSE 6.60440306164521 Test RE 1.2283576794715647\n",
      "80 Train Loss 2.018201 Test MSE 6.590875624304129 Test RE 1.2270990457393065\n",
      "81 Train Loss 2.0049424 Test MSE 6.575467294022615 Test RE 1.2256638334818237\n",
      "82 Train Loss 1.9866191 Test MSE 6.529394815022054 Test RE 1.2213623418099864\n",
      "83 Train Loss 1.9670169 Test MSE 6.4591660442748795 Test RE 1.2147762284799783\n",
      "84 Train Loss 1.9481235 Test MSE 6.424011261376982 Test RE 1.2114659357899693\n",
      "85 Train Loss 1.9211547 Test MSE 6.3969837404156635 Test RE 1.2089147701849037\n",
      "86 Train Loss 1.9005287 Test MSE 6.423005146767384 Test RE 1.2113710635010284\n",
      "87 Train Loss 1.8844211 Test MSE 6.404310697650285 Test RE 1.2096069035629604\n",
      "88 Train Loss 1.8649033 Test MSE 6.333722278014177 Test RE 1.2029222792537886\n",
      "89 Train Loss 1.844568 Test MSE 6.312388130618574 Test RE 1.200894643112516\n",
      "90 Train Loss 1.8254496 Test MSE 6.2697035420665985 Test RE 1.196827510209881\n",
      "91 Train Loss 1.8127542 Test MSE 6.237032057293034 Test RE 1.1937050973981649\n",
      "92 Train Loss 1.8044759 Test MSE 6.241517036424925 Test RE 1.1941342101792354\n",
      "93 Train Loss 1.7952654 Test MSE 6.2363077985263535 Test RE 1.1936357874704968\n",
      "94 Train Loss 1.7805434 Test MSE 6.2130070878233585 Test RE 1.1914038105759586\n",
      "95 Train Loss 1.7676458 Test MSE 6.221128320896557 Test RE 1.19218221852796\n",
      "96 Train Loss 1.7576227 Test MSE 6.209042071019982 Test RE 1.1910235848669963\n",
      "97 Train Loss 1.7443355 Test MSE 6.126532003103142 Test RE 1.1830835437187843\n",
      "98 Train Loss 1.7302216 Test MSE 6.1243449628688404 Test RE 1.1828723571725706\n",
      "99 Train Loss 1.7155235 Test MSE 6.15843489868358 Test RE 1.186159899325142\n",
      "100 Train Loss 1.7025009 Test MSE 6.104541613013354 Test RE 1.180958372716879\n",
      "101 Train Loss 1.6811676 Test MSE 5.994044352302041 Test RE 1.170221401342836\n",
      "102 Train Loss 1.6670439 Test MSE 5.92615456814608 Test RE 1.1635754447583544\n",
      "103 Train Loss 1.6522393 Test MSE 5.920918290175479 Test RE 1.1630612706109105\n",
      "104 Train Loss 1.6427051 Test MSE 5.923049199929381 Test RE 1.1632705418367146\n",
      "105 Train Loss 1.6307187 Test MSE 5.904237332662341 Test RE 1.1614217732790728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 1.6212554 Test MSE 5.909422108142169 Test RE 1.161931609638041\n",
      "107 Train Loss 1.6080295 Test MSE 5.865511329117297 Test RE 1.1576066134497907\n",
      "108 Train Loss 1.5927055 Test MSE 5.867773244070139 Test RE 1.1578297956394008\n",
      "109 Train Loss 1.5796816 Test MSE 5.844596497989063 Test RE 1.1555409139188408\n",
      "110 Train Loss 1.5708983 Test MSE 5.831507019000276 Test RE 1.154246221745378\n",
      "111 Train Loss 1.5616773 Test MSE 5.840993813285793 Test RE 1.1551847138532598\n",
      "112 Train Loss 1.5543478 Test MSE 5.805223853979115 Test RE 1.151642134646184\n",
      "113 Train Loss 1.5455167 Test MSE 5.787111382403261 Test RE 1.1498441522058838\n",
      "114 Train Loss 1.538881 Test MSE 5.764693253676496 Test RE 1.1476148563549393\n",
      "115 Train Loss 1.5288949 Test MSE 5.672583129395143 Test RE 1.1384094567947023\n",
      "116 Train Loss 1.5226059 Test MSE 5.6689782060668525 Test RE 1.1380476700280093\n",
      "117 Train Loss 1.5166718 Test MSE 5.663776378006216 Test RE 1.137525416569172\n",
      "118 Train Loss 1.5046546 Test MSE 5.6217795929626275 Test RE 1.1333002057801744\n",
      "119 Train Loss 1.4962381 Test MSE 5.61841320989192 Test RE 1.1329608386928474\n",
      "120 Train Loss 1.48892 Test MSE 5.603226424567396 Test RE 1.131428584364357\n",
      "121 Train Loss 1.4843259 Test MSE 5.594145316825267 Test RE 1.1305113635992678\n",
      "122 Train Loss 1.4802556 Test MSE 5.596094042350342 Test RE 1.1307082537764188\n",
      "123 Train Loss 1.4744691 Test MSE 5.577986863553606 Test RE 1.1288774656412648\n",
      "124 Train Loss 1.4660714 Test MSE 5.549246429379079 Test RE 1.1259654536938437\n",
      "125 Train Loss 1.4614987 Test MSE 5.543179510854693 Test RE 1.1253497837216853\n",
      "126 Train Loss 1.4582294 Test MSE 5.5278421185115745 Test RE 1.1237918433041136\n",
      "127 Train Loss 1.4539847 Test MSE 5.496094476528855 Test RE 1.1205601016682454\n",
      "128 Train Loss 1.4491849 Test MSE 5.468912060517229 Test RE 1.1177856510237725\n",
      "129 Train Loss 1.4442204 Test MSE 5.457836930745678 Test RE 1.1166532598944137\n",
      "130 Train Loss 1.4384365 Test MSE 5.44599492503976 Test RE 1.1154411867756517\n",
      "131 Train Loss 1.4326198 Test MSE 5.426926286476319 Test RE 1.1134866682288032\n",
      "132 Train Loss 1.4266057 Test MSE 5.406305843143639 Test RE 1.1113692227688747\n",
      "133 Train Loss 1.4203037 Test MSE 5.364987850514073 Test RE 1.1071142269148504\n",
      "134 Train Loss 1.4155618 Test MSE 5.363587262977684 Test RE 1.106969705469056\n",
      "135 Train Loss 1.4100862 Test MSE 5.366313740732937 Test RE 1.1072510232397141\n",
      "136 Train Loss 1.4055021 Test MSE 5.339917880624562 Test RE 1.1045244893944566\n",
      "137 Train Loss 1.402436 Test MSE 5.325780089185269 Test RE 1.1030613689194952\n",
      "138 Train Loss 1.3950262 Test MSE 5.290486590186279 Test RE 1.0994003458192454\n",
      "139 Train Loss 1.3901685 Test MSE 5.276579736659912 Test RE 1.097954423970384\n",
      "140 Train Loss 1.3860607 Test MSE 5.275602948254313 Test RE 1.0978527938574518\n",
      "141 Train Loss 1.3806884 Test MSE 5.266714576757779 Test RE 1.0969275690840745\n",
      "142 Train Loss 1.3762825 Test MSE 5.267290779917711 Test RE 1.0969875719412512\n",
      "143 Train Loss 1.3675458 Test MSE 5.259462269664269 Test RE 1.0961720699988489\n",
      "144 Train Loss 1.3610238 Test MSE 5.232538264261019 Test RE 1.0933627323654362\n",
      "145 Train Loss 1.3568454 Test MSE 5.222619730395507 Test RE 1.0923259793868727\n",
      "146 Train Loss 1.3512564 Test MSE 5.202965919907524 Test RE 1.0902687165109368\n",
      "147 Train Loss 1.3466107 Test MSE 5.193240861278221 Test RE 1.0892493088720026\n",
      "148 Train Loss 1.3424178 Test MSE 5.178106338586672 Test RE 1.087660965773769\n",
      "149 Train Loss 1.337627 Test MSE 5.15616530101825 Test RE 1.0853541626452106\n",
      "Training time: 228.31\n",
      "7\n",
      "KG_rowdy_tune63\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 56.259132 Test MSE 6.119525682684441 Test RE 1.1824068612505945\n",
      "1 Train Loss 40.843975 Test MSE 8.129378029566121 Test RE 1.3628144193367744\n",
      "2 Train Loss 34.57744 Test MSE 7.605233920280456 Test RE 1.3181485266432873\n",
      "3 Train Loss 28.389282 Test MSE 7.013525833013188 Test RE 1.2658325549666367\n",
      "4 Train Loss 25.252602 Test MSE 6.953869707562491 Test RE 1.260437555822657\n",
      "5 Train Loss 22.237164 Test MSE 6.654953335382277 Test RE 1.233049659351612\n",
      "6 Train Loss 19.932602 Test MSE 6.595947803481693 Test RE 1.2275711278700432\n",
      "7 Train Loss 17.145792 Test MSE 5.960975188491044 Test RE 1.1669888789199045\n",
      "8 Train Loss 14.913802 Test MSE 5.910078174411274 Test RE 1.1619961068905214\n",
      "9 Train Loss 13.738609 Test MSE 6.02404579409073 Test RE 1.1731463469775165\n",
      "10 Train Loss 12.4345875 Test MSE 5.898238447944586 Test RE 1.160831603409171\n",
      "11 Train Loss 11.32436 Test MSE 5.792761483752876 Test RE 1.1504053260462734\n",
      "12 Train Loss 10.791563 Test MSE 5.9313654357644285 Test RE 1.1640868982879053\n",
      "13 Train Loss 10.406383 Test MSE 5.754956060161444 Test RE 1.1466452236103053\n",
      "14 Train Loss 10.113519 Test MSE 5.71865146369702 Test RE 1.1430227500459316\n",
      "15 Train Loss 9.758119 Test MSE 5.791737538092822 Test RE 1.1503036470281225\n",
      "16 Train Loss 9.088108 Test MSE 5.5773487967189785 Test RE 1.1288128975552536\n",
      "17 Train Loss 8.537727 Test MSE 5.504277506747284 Test RE 1.1213939816760417\n",
      "18 Train Loss 8.064878 Test MSE 5.369293587409516 Test RE 1.1075584018737343\n",
      "19 Train Loss 7.617676 Test MSE 5.341645145184173 Test RE 1.104703111219482\n",
      "20 Train Loss 6.7864914 Test MSE 5.306131564572726 Test RE 1.1010247137049696\n",
      "21 Train Loss 6.006624 Test MSE 5.146974146154204 Test RE 1.0843863787284573\n",
      "22 Train Loss 5.366999 Test MSE 4.977676343572967 Test RE 1.0664030723227182\n",
      "23 Train Loss 5.0279675 Test MSE 4.998421707746772 Test RE 1.068622975361733\n",
      "24 Train Loss 4.6848764 Test MSE 4.968216548219351 Test RE 1.0653892707424062\n",
      "25 Train Loss 4.4314623 Test MSE 4.934642635766284 Test RE 1.0617833569616968\n",
      "26 Train Loss 4.13474 Test MSE 4.857855992786365 Test RE 1.0534899052194884\n",
      "27 Train Loss 3.9313092 Test MSE 4.808748798391642 Test RE 1.0481516097926724\n",
      "28 Train Loss 3.7749014 Test MSE 4.815183251833361 Test RE 1.0488526266724725\n",
      "29 Train Loss 3.586329 Test MSE 4.703663010191227 Test RE 1.0366356974000368\n",
      "30 Train Loss 3.4460573 Test MSE 4.652212730352951 Test RE 1.0309505697188834\n",
      "31 Train Loss 3.3584676 Test MSE 4.671746154159788 Test RE 1.0331126484207367\n",
      "32 Train Loss 3.258604 Test MSE 4.62458712323106 Test RE 1.0278850346997856\n",
      "33 Train Loss 3.147296 Test MSE 4.483274299906909 Test RE 1.0120587308914888\n",
      "34 Train Loss 3.0272658 Test MSE 4.279966418860733 Test RE 0.9888450435316843\n",
      "35 Train Loss 2.91256 Test MSE 4.164281544249423 Test RE 0.9753895589374397\n",
      "36 Train Loss 2.7536507 Test MSE 4.026318906507332 Test RE 0.9590961452215996\n",
      "37 Train Loss 2.6373386 Test MSE 3.903740125669914 Test RE 0.9443837588387448\n",
      "38 Train Loss 2.5506728 Test MSE 3.797574846965345 Test RE 0.9314536124752374\n",
      "39 Train Loss 2.4513056 Test MSE 3.767537633759278 Test RE 0.9277625970458852\n",
      "40 Train Loss 2.3139932 Test MSE 3.576264213506462 Test RE 0.9039051456815759\n",
      "41 Train Loss 2.2029037 Test MSE 3.425653712916655 Test RE 0.8846669238548996\n",
      "42 Train Loss 2.128588 Test MSE 3.3561751940333675 Test RE 0.8756496367496127\n",
      "43 Train Loss 1.9953916 Test MSE 3.1565176737633833 Test RE 0.8492042772667634\n",
      "44 Train Loss 1.9015048 Test MSE 3.008132270483605 Test RE 0.8290038063816298\n",
      "45 Train Loss 1.8116276 Test MSE 2.9880256532155647 Test RE 0.8262285944581785\n",
      "46 Train Loss 1.729021 Test MSE 2.9458010932104437 Test RE 0.8203699989641455\n",
      "47 Train Loss 1.6576917 Test MSE 2.8887774993305677 Test RE 0.8123910059295051\n",
      "48 Train Loss 1.5807669 Test MSE 2.7781412052980876 Test RE 0.7966823912942055\n",
      "49 Train Loss 1.5559115 Test MSE 2.7283688381953786 Test RE 0.7895135729496098\n",
      "50 Train Loss 1.5191978 Test MSE 2.6740391246854713 Test RE 0.7816132966658671\n",
      "51 Train Loss 1.4871632 Test MSE 2.666755269582901 Test RE 0.780548046693402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 1.4560233 Test MSE 2.6204231015591857 Test RE 0.7737377211408911\n",
      "53 Train Loss 1.4320848 Test MSE 2.575655363296252 Test RE 0.7670999175817848\n",
      "54 Train Loss 1.3934432 Test MSE 2.5278790804631184 Test RE 0.7599520803875617\n",
      "55 Train Loss 1.3560746 Test MSE 2.484844164790114 Test RE 0.7534555547568692\n",
      "56 Train Loss 1.3255931 Test MSE 2.4077212326602537 Test RE 0.7416707669856281\n",
      "57 Train Loss 1.2925142 Test MSE 2.2804082070038754 Test RE 0.7217958121211768\n",
      "58 Train Loss 1.2294377 Test MSE 2.1820032607351525 Test RE 0.7060504886060952\n",
      "59 Train Loss 1.1952673 Test MSE 2.1089265429313904 Test RE 0.6941267584912473\n",
      "60 Train Loss 1.1636239 Test MSE 2.01232857409654 Test RE 0.6780434223834032\n",
      "61 Train Loss 1.1322081 Test MSE 1.920178066773919 Test RE 0.6623366888482567\n",
      "62 Train Loss 1.0588405 Test MSE 1.7095794817373065 Test RE 0.6249607009177521\n",
      "63 Train Loss 1.0004058 Test MSE 1.6242723043687406 Test RE 0.6091685587937418\n",
      "64 Train Loss 0.9417457 Test MSE 1.543420135976311 Test RE 0.5938136017678806\n",
      "65 Train Loss 0.882348 Test MSE 1.3918023994475517 Test RE 0.5638931912548134\n",
      "66 Train Loss 0.83613515 Test MSE 1.3189227938457417 Test RE 0.5489309869251527\n",
      "67 Train Loss 0.7574719 Test MSE 1.111755685780653 Test RE 0.5039793474635673\n",
      "68 Train Loss 0.7012128 Test MSE 0.9277593623681305 Test RE 0.46038984230363017\n",
      "69 Train Loss 0.6498496 Test MSE 0.8075777807962977 Test RE 0.4295366651648104\n",
      "70 Train Loss 0.59213793 Test MSE 0.7299323301135072 Test RE 0.4083657969326105\n",
      "71 Train Loss 0.54859775 Test MSE 0.6831475370969189 Test RE 0.3950620506979627\n",
      "72 Train Loss 0.50100857 Test MSE 0.6220336479884369 Test RE 0.3769771260565984\n",
      "73 Train Loss 0.4572035 Test MSE 0.5707327798507512 Test RE 0.36109748921053025\n",
      "74 Train Loss 0.41961223 Test MSE 0.5497238524521068 Test RE 0.35438909608434466\n",
      "75 Train Loss 0.38658175 Test MSE 0.5519300777316398 Test RE 0.3550995248576732\n",
      "76 Train Loss 0.3450177 Test MSE 0.47799791014566806 Test RE 0.330461644087252\n",
      "77 Train Loss 0.3077934 Test MSE 0.40579151172885936 Test RE 0.3044805387802193\n",
      "78 Train Loss 0.27727765 Test MSE 0.3711954548665262 Test RE 0.29121207923721726\n",
      "79 Train Loss 0.25327197 Test MSE 0.32240813063333057 Test RE 0.2714007559739795\n",
      "80 Train Loss 0.2238432 Test MSE 0.26671040305167487 Test RE 0.2468471049478015\n",
      "81 Train Loss 0.19682845 Test MSE 0.22812021492281392 Test RE 0.22829160758128605\n",
      "82 Train Loss 0.18197672 Test MSE 0.20387348442365386 Test RE 0.21581838238183182\n",
      "83 Train Loss 0.16761494 Test MSE 0.1953537634266072 Test RE 0.21126081524177678\n",
      "84 Train Loss 0.15517512 Test MSE 0.1842534990556386 Test RE 0.20517097973537451\n",
      "85 Train Loss 0.14351016 Test MSE 0.1496185964271314 Test RE 0.18488464700470722\n",
      "86 Train Loss 0.12868728 Test MSE 0.13494613734345595 Test RE 0.1755853547010829\n",
      "87 Train Loss 0.11499224 Test MSE 0.13585861004998104 Test RE 0.17617798714701968\n",
      "88 Train Loss 0.10886756 Test MSE 0.12358228956390666 Test RE 0.16802974904515747\n",
      "89 Train Loss 0.102978185 Test MSE 0.11289608378297986 Test RE 0.16060072401520173\n",
      "90 Train Loss 0.09309539 Test MSE 0.10248167271487232 Test RE 0.1530139981007452\n",
      "91 Train Loss 0.0870413 Test MSE 0.0884109403632794 Test RE 0.14212191975288765\n",
      "92 Train Loss 0.08146561 Test MSE 0.07823247853909114 Test RE 0.13369082555421605\n",
      "93 Train Loss 0.07584839 Test MSE 0.06973323647504219 Test RE 0.12621994058463512\n",
      "94 Train Loss 0.07180719 Test MSE 0.05695873816803975 Test RE 0.11407441232116257\n",
      "95 Train Loss 0.06737678 Test MSE 0.05042830894719747 Test RE 0.10733596439608058\n",
      "96 Train Loss 0.06344119 Test MSE 0.049022866678466906 Test RE 0.10582966273440271\n",
      "97 Train Loss 0.056944307 Test MSE 0.042239383298668796 Test RE 0.09823513463079833\n",
      "98 Train Loss 0.054003242 Test MSE 0.040387404441801486 Test RE 0.0960574452680685\n",
      "99 Train Loss 0.05045469 Test MSE 0.0418992243288579 Test RE 0.09783878522000738\n",
      "100 Train Loss 0.04622656 Test MSE 0.04043359965692009 Test RE 0.09611236494239091\n",
      "101 Train Loss 0.04259372 Test MSE 0.039249757045798826 Test RE 0.09469489060992362\n",
      "102 Train Loss 0.041308682 Test MSE 0.03839424645520194 Test RE 0.09365719236233343\n",
      "103 Train Loss 0.03975422 Test MSE 0.03597338850629337 Test RE 0.09065645536471768\n",
      "104 Train Loss 0.03809146 Test MSE 0.03653176925305926 Test RE 0.09135733310403155\n",
      "105 Train Loss 0.036127884 Test MSE 0.03987469645960787 Test RE 0.09544578524768309\n",
      "106 Train Loss 0.035108812 Test MSE 0.04055333118674793 Test RE 0.09625456318931139\n",
      "107 Train Loss 0.032382533 Test MSE 0.0403612099295921 Test RE 0.09602628968780214\n",
      "108 Train Loss 0.030627195 Test MSE 0.04093186282923979 Test RE 0.09670274793530276\n",
      "109 Train Loss 0.029297944 Test MSE 0.041692534800607604 Test RE 0.09759716674662619\n",
      "110 Train Loss 0.027543822 Test MSE 0.04070827699021222 Test RE 0.09643827216334702\n",
      "111 Train Loss 0.026548857 Test MSE 0.03939988947998683 Test RE 0.09487582428261744\n",
      "112 Train Loss 0.025287362 Test MSE 0.03944472439437452 Test RE 0.09492979067782713\n",
      "113 Train Loss 0.024148785 Test MSE 0.04008465899794195 Test RE 0.09569674299593398\n",
      "114 Train Loss 0.02337358 Test MSE 0.03898231739799125 Test RE 0.09437172356625444\n",
      "115 Train Loss 0.022691026 Test MSE 0.03846966671882502 Test RE 0.09374913562595302\n",
      "116 Train Loss 0.021341125 Test MSE 0.03595258609960017 Test RE 0.09063023952506667\n",
      "117 Train Loss 0.020076979 Test MSE 0.03334461087705735 Test RE 0.08728123587945058\n",
      "118 Train Loss 0.019348867 Test MSE 0.033108746015230846 Test RE 0.08697199383874983\n",
      "119 Train Loss 0.018792508 Test MSE 0.032267886351851134 Test RE 0.08586048149487764\n",
      "120 Train Loss 0.01811553 Test MSE 0.03153258214082898 Test RE 0.08487657145353338\n",
      "121 Train Loss 0.017637873 Test MSE 0.03166132348946227 Test RE 0.08504966215716954\n",
      "122 Train Loss 0.017064635 Test MSE 0.030480020875909036 Test RE 0.08344795348986586\n",
      "123 Train Loss 0.016662607 Test MSE 0.029281669722774812 Test RE 0.08179108684659472\n",
      "124 Train Loss 0.016389973 Test MSE 0.028913783630577672 Test RE 0.08127566351500316\n",
      "125 Train Loss 0.015976068 Test MSE 0.028039166170911678 Test RE 0.08003696419955353\n",
      "126 Train Loss 0.015465125 Test MSE 0.027738032039004813 Test RE 0.07960601479946727\n",
      "127 Train Loss 0.015026814 Test MSE 0.028709033973735504 Test RE 0.08098738008194746\n",
      "128 Train Loss 0.0145318415 Test MSE 0.028369002328093883 Test RE 0.08050634160618403\n",
      "129 Train Loss 0.013600992 Test MSE 0.026543737540352125 Test RE 0.07787339297943525\n",
      "130 Train Loss 0.013241963 Test MSE 0.027027601666825374 Test RE 0.0785799621180875\n",
      "131 Train Loss 0.012815724 Test MSE 0.027226116801185998 Test RE 0.07886801528650406\n",
      "132 Train Loss 0.012310304 Test MSE 0.026699400959448952 Test RE 0.07810140002540956\n",
      "133 Train Loss 0.011957392 Test MSE 0.026482886648962544 Test RE 0.0777840803061883\n",
      "134 Train Loss 0.011731494 Test MSE 0.0268001374234469 Test RE 0.07824859905263211\n",
      "135 Train Loss 0.01153794 Test MSE 0.02698747157936864 Test RE 0.0785216034039817\n",
      "136 Train Loss 0.011348718 Test MSE 0.02652621559676165 Test RE 0.07784768600331361\n",
      "137 Train Loss 0.011133744 Test MSE 0.025417562274699695 Test RE 0.07620351572679054\n",
      "138 Train Loss 0.010634741 Test MSE 0.02362966733962409 Test RE 0.07347453802448833\n",
      "139 Train Loss 0.010369872 Test MSE 0.023056683949769514 Test RE 0.0725782485307697\n",
      "140 Train Loss 0.010274081 Test MSE 0.0230087157225158 Test RE 0.07250271159413735\n",
      "141 Train Loss 0.010007615 Test MSE 0.02365607366148356 Test RE 0.07351558072157005\n",
      "142 Train Loss 0.009799322 Test MSE 0.02386516845075933 Test RE 0.07383976610639846\n",
      "143 Train Loss 0.009646899 Test MSE 0.024061312838567234 Test RE 0.07414258438457805\n",
      "144 Train Loss 0.009465769 Test MSE 0.02399497621797735 Test RE 0.07404030893585102\n",
      "145 Train Loss 0.009298372 Test MSE 0.023847700423499388 Test RE 0.07381273777934381\n",
      "146 Train Loss 0.0091494 Test MSE 0.023774405022998324 Test RE 0.07369921954770986\n",
      "147 Train Loss 0.00901787 Test MSE 0.023230309549217603 Test RE 0.07285100690807637\n",
      "148 Train Loss 0.008866379 Test MSE 0.02293264944392631 Test RE 0.07238276623951201\n",
      "149 Train Loss 0.008638963 Test MSE 0.023210726593232218 Test RE 0.07282029404033515\n",
      "Training time: 226.34\n",
      "8\n",
      "KG_rowdy_tune63\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 72.51949 Test MSE 5.367852794467872 Test RE 1.1074097911330718\n",
      "1 Train Loss 60.885754 Test MSE 6.731805638371177 Test RE 1.2401489346202386\n",
      "2 Train Loss 46.701576 Test MSE 6.287300386806013 Test RE 1.1985058695747302\n",
      "3 Train Loss 32.843384 Test MSE 7.969183508936459 Test RE 1.3493200510326215\n",
      "4 Train Loss 26.702568 Test MSE 7.75551176563908 Test RE 1.3311079915106852\n",
      "5 Train Loss 23.285828 Test MSE 7.8495909995125865 Test RE 1.3391572428991894\n",
      "6 Train Loss 20.533314 Test MSE 8.03467466581686 Test RE 1.3548530971076376\n",
      "7 Train Loss 18.7038 Test MSE 8.231889828965734 Test RE 1.371380074233131\n",
      "8 Train Loss 16.863138 Test MSE 8.299125787660552 Test RE 1.3769692246049567\n",
      "9 Train Loss 15.455873 Test MSE 8.175811005868855 Test RE 1.3667009053218888\n",
      "10 Train Loss 14.531721 Test MSE 8.39299589293648 Test RE 1.3847346689821685\n",
      "11 Train Loss 13.441913 Test MSE 8.257069552641953 Test RE 1.3734758630796473\n",
      "12 Train Loss 12.722637 Test MSE 8.034943597029256 Test RE 1.35487577128253\n",
      "13 Train Loss 11.640017 Test MSE 8.10070587364419 Test RE 1.3604089867002496\n",
      "14 Train Loss 10.557583 Test MSE 8.02279421492427 Test RE 1.353851051540445\n",
      "15 Train Loss 9.657323 Test MSE 7.960691005949817 Test RE 1.3486008958595603\n",
      "16 Train Loss 8.4458275 Test MSE 7.708277328506339 Test RE 1.3270482876516458\n",
      "17 Train Loss 7.487656 Test MSE 7.368994154528703 Test RE 1.2975143398865667\n",
      "18 Train Loss 6.775393 Test MSE 7.284863526874685 Test RE 1.2900863210544216\n",
      "19 Train Loss 6.210528 Test MSE 7.114455517666403 Test RE 1.274908141310339\n",
      "20 Train Loss 5.732062 Test MSE 7.063601020717633 Test RE 1.2703434147041346\n",
      "21 Train Loss 5.360736 Test MSE 6.994543519700087 Test RE 1.2641183878569184\n",
      "22 Train Loss 5.1087503 Test MSE 6.835696614924081 Test RE 1.249681814550829\n",
      "23 Train Loss 4.70926 Test MSE 6.796123309332376 Test RE 1.246059226681558\n",
      "24 Train Loss 4.524539 Test MSE 6.762450611975197 Test RE 1.2429684736942297\n",
      "25 Train Loss 4.3995037 Test MSE 6.648046845821188 Test RE 1.232409665740867\n",
      "26 Train Loss 4.2328625 Test MSE 6.585393124978597 Test RE 1.226588569612322\n",
      "27 Train Loss 4.1597 Test MSE 6.59839981047943 Test RE 1.2277992780463713\n",
      "28 Train Loss 4.03442 Test MSE 6.509807956481439 Test RE 1.2195290463953197\n",
      "29 Train Loss 3.9318242 Test MSE 6.582378218004837 Test RE 1.2263077607283983\n",
      "30 Train Loss 3.8606281 Test MSE 6.682533848713382 Test RE 1.2356021175129537\n",
      "31 Train Loss 3.7735505 Test MSE 6.573502315011665 Test RE 1.2254806842427486\n",
      "32 Train Loss 3.7084048 Test MSE 6.48549935221428 Test RE 1.2172499641442178\n",
      "33 Train Loss 3.5538538 Test MSE 6.456271957249551 Test RE 1.214504052320371\n",
      "34 Train Loss 3.4844635 Test MSE 6.436722525968896 Test RE 1.2126639142243112\n",
      "35 Train Loss 3.4264367 Test MSE 6.405478053441734 Test RE 1.2097171400389257\n",
      "36 Train Loss 3.3601978 Test MSE 6.340463966047835 Test RE 1.2035623112527738\n",
      "37 Train Loss 3.2886868 Test MSE 6.336882226747006 Test RE 1.2032223159915827\n",
      "38 Train Loss 3.2531838 Test MSE 6.337586147697858 Test RE 1.203289143008926\n",
      "39 Train Loss 3.1844583 Test MSE 6.332675503491836 Test RE 1.2028228716408689\n",
      "40 Train Loss 3.1310358 Test MSE 6.259600097621595 Test RE 1.1958627950828988\n",
      "41 Train Loss 3.0862274 Test MSE 6.167828210702658 Test RE 1.187064165166606\n",
      "42 Train Loss 3.0235033 Test MSE 6.126334924829897 Test RE 1.1830645148508305\n",
      "43 Train Loss 2.9594007 Test MSE 6.072825412279595 Test RE 1.177886537672499\n",
      "44 Train Loss 2.874569 Test MSE 5.891985030891379 Test RE 1.1602160730857498\n",
      "45 Train Loss 2.8272605 Test MSE 5.894322235869265 Test RE 1.160446164804256\n",
      "46 Train Loss 2.7828672 Test MSE 5.850826372772964 Test RE 1.1561566072236362\n",
      "47 Train Loss 2.725182 Test MSE 5.752377033589769 Test RE 1.1463882659674947\n",
      "48 Train Loss 2.6853375 Test MSE 5.697501624307602 Test RE 1.1409071165689022\n",
      "49 Train Loss 2.6209052 Test MSE 5.6355546318571506 Test RE 1.1346878182608129\n",
      "50 Train Loss 2.586238 Test MSE 5.589572361524755 Test RE 1.130049198729989\n",
      "51 Train Loss 2.5369852 Test MSE 5.537467203201808 Test RE 1.1247697915761206\n",
      "52 Train Loss 2.4960332 Test MSE 5.505390851586128 Test RE 1.1215073875747752\n",
      "53 Train Loss 2.4408903 Test MSE 5.411195388223173 Test RE 1.111871678785914\n",
      "54 Train Loss 2.4153879 Test MSE 5.364684106260314 Test RE 1.1070828862712285\n",
      "55 Train Loss 2.378377 Test MSE 5.348437340111348 Test RE 1.1054052334071531\n",
      "56 Train Loss 2.3389347 Test MSE 5.300368784468515 Test RE 1.1004266615339233\n",
      "57 Train Loss 2.3118055 Test MSE 5.255466366056477 Test RE 1.0957555796819367\n",
      "58 Train Loss 2.2894945 Test MSE 5.2607421880269545 Test RE 1.0963054415625149\n",
      "59 Train Loss 2.2689123 Test MSE 5.21952881063719 Test RE 1.0920026941560088\n",
      "60 Train Loss 2.2406886 Test MSE 5.150641520518621 Test RE 1.0847726389406993\n",
      "61 Train Loss 2.2164915 Test MSE 5.136341030837152 Test RE 1.0832656846662057\n",
      "62 Train Loss 2.199039 Test MSE 5.101028350770756 Test RE 1.0795355011270318\n",
      "63 Train Loss 2.1775737 Test MSE 5.04292996070354 Test RE 1.073370186938459\n",
      "64 Train Loss 2.1573308 Test MSE 5.04690623675779 Test RE 1.0737932718533258\n",
      "65 Train Loss 2.133243 Test MSE 5.030209631097333 Test RE 1.0720155931255901\n",
      "66 Train Loss 2.1122785 Test MSE 4.980037299902251 Test RE 1.0666559445902788\n",
      "67 Train Loss 2.087777 Test MSE 4.938144551843392 Test RE 1.0621600424725843\n",
      "68 Train Loss 2.0589318 Test MSE 4.915469525901955 Test RE 1.0597186175812725\n",
      "69 Train Loss 2.0363564 Test MSE 4.864939044636979 Test RE 1.0542576518992446\n",
      "70 Train Loss 2.0078788 Test MSE 4.852017050202133 Test RE 1.052856589145195\n",
      "71 Train Loss 1.9864879 Test MSE 4.849396765054217 Test RE 1.052572258214446\n",
      "72 Train Loss 1.9683245 Test MSE 4.83867705355164 Test RE 1.0514082460826903\n",
      "73 Train Loss 1.9493382 Test MSE 4.797299500862897 Test RE 1.0469030780223016\n",
      "74 Train Loss 1.9310523 Test MSE 4.758494236467765 Test RE 1.0426602911047962\n",
      "75 Train Loss 1.9153813 Test MSE 4.7386100165809 Test RE 1.0404795392286348\n",
      "76 Train Loss 1.886378 Test MSE 4.671344439375997 Test RE 1.033068229745951\n",
      "77 Train Loss 1.8578221 Test MSE 4.582254925225859 Test RE 1.0231697308587546\n",
      "78 Train Loss 1.839973 Test MSE 4.496703131889283 Test RE 1.013573316414434\n",
      "79 Train Loss 1.8289768 Test MSE 4.442016623694416 Test RE 1.0073911936137026\n",
      "80 Train Loss 1.8038566 Test MSE 4.385352849337525 Test RE 1.0009452701218295\n",
      "81 Train Loss 1.7716348 Test MSE 4.319948063298395 Test RE 0.9934529942118213\n",
      "82 Train Loss 1.7324117 Test MSE 4.270147616333503 Test RE 0.9877101223378557\n",
      "83 Train Loss 1.6761556 Test MSE 4.153052127034262 Test RE 0.9740735515813073\n",
      "84 Train Loss 1.64326 Test MSE 4.117475663221445 Test RE 0.9698924546816414\n",
      "85 Train Loss 1.5936365 Test MSE 4.060979638449146 Test RE 0.9632155081040731\n",
      "86 Train Loss 1.547304 Test MSE 4.009119742178463 Test RE 0.9570454748234144\n",
      "87 Train Loss 1.4999816 Test MSE 3.9222437466511124 Test RE 0.9466192894219959\n",
      "88 Train Loss 1.453501 Test MSE 3.830137680861556 Test RE 0.9354385277048306\n",
      "89 Train Loss 1.4335189 Test MSE 3.7868729267863874 Test RE 0.9301402249245292\n",
      "90 Train Loss 1.4144263 Test MSE 3.739290286098412 Test RE 0.9242780745232724\n",
      "91 Train Loss 1.3976858 Test MSE 3.7192617159201777 Test RE 0.9217994191969864\n",
      "92 Train Loss 1.3684382 Test MSE 3.6594447331602282 Test RE 0.9143567105799217\n",
      "93 Train Loss 1.3493961 Test MSE 3.635780619270103 Test RE 0.9113955325093007\n",
      "94 Train Loss 1.3271173 Test MSE 3.619099140957528 Test RE 0.9093023226331729\n",
      "95 Train Loss 1.2987713 Test MSE 3.548175455513085 Test RE 0.9003484141422232\n",
      "96 Train Loss 1.2693903 Test MSE 3.4794261410535205 Test RE 0.891583189247973\n",
      "97 Train Loss 1.2512467 Test MSE 3.476008457520814 Test RE 0.8911452006691915\n",
      "98 Train Loss 1.2229059 Test MSE 3.394327725754416 Test RE 0.88061270324498\n",
      "99 Train Loss 1.2016107 Test MSE 3.3220384926808815 Test RE 0.8711850025882035\n",
      "100 Train Loss 1.1768818 Test MSE 3.2721412027579238 Test RE 0.864617613601304\n",
      "101 Train Loss 1.1590053 Test MSE 3.244301757493102 Test RE 0.860931664520749\n",
      "102 Train Loss 1.137304 Test MSE 3.181671098708667 Test RE 0.8525811015361073\n",
      "103 Train Loss 1.1284318 Test MSE 3.151694034738871 Test RE 0.8485551725512043\n",
      "104 Train Loss 1.1134051 Test MSE 3.138932589886753 Test RE 0.8468354983358816\n",
      "105 Train Loss 1.0962706 Test MSE 3.1188445183951674 Test RE 0.8441214234771002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 1.0800112 Test MSE 3.0711175946227054 Test RE 0.8376378305866176\n",
      "107 Train Loss 1.063875 Test MSE 3.0482302446736833 Test RE 0.8345107666445768\n",
      "108 Train Loss 1.0507977 Test MSE 3.0587686413926938 Test RE 0.8359520648547435\n",
      "109 Train Loss 1.0245309 Test MSE 3.000752228095846 Test RE 0.827986257989277\n",
      "110 Train Loss 1.0052787 Test MSE 2.964778256069074 Test RE 0.8230082121138746\n",
      "111 Train Loss 0.99008375 Test MSE 2.9618371219281947 Test RE 0.8225998884623121\n",
      "112 Train Loss 0.97081345 Test MSE 2.9281003873924245 Test RE 0.8179015689944206\n",
      "113 Train Loss 0.9557805 Test MSE 2.939342494424216 Test RE 0.8194701846392587\n",
      "114 Train Loss 0.944563 Test MSE 2.9544405496408586 Test RE 0.8215721103162422\n",
      "115 Train Loss 0.92830753 Test MSE 2.910958551336816 Test RE 0.8155039540439201\n",
      "116 Train Loss 0.9136688 Test MSE 2.8572710213032955 Test RE 0.8079486852275396\n",
      "117 Train Loss 0.90338296 Test MSE 2.851611245036802 Test RE 0.8071480829225584\n",
      "118 Train Loss 0.89505726 Test MSE 2.854547187890321 Test RE 0.8075634850935717\n",
      "119 Train Loss 0.88575155 Test MSE 2.82389855120632 Test RE 0.8032164708344265\n",
      "120 Train Loss 0.8777253 Test MSE 2.829567743975635 Test RE 0.8040223258957168\n",
      "121 Train Loss 0.87169653 Test MSE 2.844940500862222 Test RE 0.8062034536508768\n",
      "122 Train Loss 0.8661963 Test MSE 2.8404963113225983 Test RE 0.8055735070311456\n",
      "123 Train Loss 0.85734 Test MSE 2.8368124990315486 Test RE 0.8050509672981919\n",
      "124 Train Loss 0.85133994 Test MSE 2.815474458032083 Test RE 0.80201752121387\n",
      "125 Train Loss 0.8439245 Test MSE 2.798161270762844 Test RE 0.7995477968185187\n",
      "126 Train Loss 0.83650315 Test MSE 2.813677565546936 Test RE 0.8017615485007908\n",
      "127 Train Loss 0.82334197 Test MSE 2.814503128292012 Test RE 0.8018791625315634\n",
      "128 Train Loss 0.8137138 Test MSE 2.798367387476134 Test RE 0.799577244215096\n",
      "129 Train Loss 0.8043016 Test MSE 2.801353292531032 Test RE 0.8000037116653776\n",
      "130 Train Loss 0.7980379 Test MSE 2.8100461492026776 Test RE 0.8012439927472986\n",
      "131 Train Loss 0.79117143 Test MSE 2.803114821480847 Test RE 0.8002551987298174\n",
      "132 Train Loss 0.7846712 Test MSE 2.7895458721050717 Test RE 0.7983159640532758\n",
      "133 Train Loss 0.7779963 Test MSE 2.774557256744544 Test RE 0.7961683443201537\n",
      "134 Train Loss 0.77251136 Test MSE 2.7671077560175132 Test RE 0.7950987965352632\n",
      "135 Train Loss 0.7644299 Test MSE 2.758205681494049 Test RE 0.7938188083256147\n",
      "136 Train Loss 0.7575675 Test MSE 2.7516128396725126 Test RE 0.7928695221660832\n",
      "137 Train Loss 0.7521142 Test MSE 2.7603834180474305 Test RE 0.7941321256306455\n",
      "138 Train Loss 0.7460704 Test MSE 2.7509095663303667 Test RE 0.7927681925705495\n",
      "139 Train Loss 0.7390739 Test MSE 2.725014365658712 Test RE 0.7890280784482567\n",
      "140 Train Loss 0.7331129 Test MSE 2.7169467790031967 Test RE 0.7878592275837464\n",
      "141 Train Loss 0.72904557 Test MSE 2.712810622121985 Test RE 0.7872592985450813\n",
      "142 Train Loss 0.724257 Test MSE 2.726920818324362 Test RE 0.7893040369344725\n",
      "143 Train Loss 0.72101974 Test MSE 2.730367563103088 Test RE 0.7898027075277136\n",
      "144 Train Loss 0.7172836 Test MSE 2.727878926056851 Test RE 0.7894426863373615\n",
      "145 Train Loss 0.7141716 Test MSE 2.7339715111135696 Test RE 0.7903237855824512\n",
      "146 Train Loss 0.7107631 Test MSE 2.7386681403893345 Test RE 0.7910023341795679\n",
      "147 Train Loss 0.7087406 Test MSE 2.726906543896947 Test RE 0.7893019710736211\n",
      "148 Train Loss 0.7063905 Test MSE 2.723140910991274 Test RE 0.7887568023569522\n",
      "149 Train Loss 0.70338607 Test MSE 2.728276283731044 Test RE 0.7895001815003797\n",
      "Training time: 228.96\n",
      "9\n",
      "KG_rowdy_tune63\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 58.43578 Test MSE 6.865645920046132 Test RE 1.2524164441506498\n",
      "1 Train Loss 49.12577 Test MSE 8.828949093799254 Test RE 1.4202427031507168\n",
      "2 Train Loss 40.81173 Test MSE 8.275344942768774 Test RE 1.3749949815452644\n",
      "3 Train Loss 35.068005 Test MSE 8.704037991991138 Test RE 1.4101601875976701\n",
      "4 Train Loss 32.391243 Test MSE 8.559744884983921 Test RE 1.3984227186240334\n",
      "5 Train Loss 29.940758 Test MSE 8.97403998729363 Test RE 1.4318649571002353\n",
      "6 Train Loss 27.70026 Test MSE 8.76113112659913 Test RE 1.414777519917218\n",
      "7 Train Loss 25.836763 Test MSE 9.011557546911792 Test RE 1.4348549175560923\n",
      "8 Train Loss 24.011211 Test MSE 8.982350537677503 Test RE 1.4325278041686191\n",
      "9 Train Loss 22.494701 Test MSE 8.980400156912317 Test RE 1.4323722699158163\n",
      "10 Train Loss 21.660103 Test MSE 9.15739980621777 Test RE 1.4464191001705053\n",
      "11 Train Loss 20.95137 Test MSE 9.03814498802022 Test RE 1.4369700360212607\n",
      "12 Train Loss 20.444633 Test MSE 9.194445675260305 Test RE 1.4493418604651092\n",
      "13 Train Loss 19.926912 Test MSE 9.23107932360822 Test RE 1.4522263137765876\n",
      "14 Train Loss 19.392883 Test MSE 9.205866363723999 Test RE 1.4502417159626684\n",
      "15 Train Loss 18.590206 Test MSE 9.20565976264653 Test RE 1.4502254424708345\n",
      "16 Train Loss 17.951038 Test MSE 8.90122635807251 Test RE 1.4260441878865873\n",
      "17 Train Loss 17.009169 Test MSE 8.548356085962055 Test RE 1.3974921034852446\n",
      "18 Train Loss 16.560883 Test MSE 8.38600272280413 Test RE 1.3841576579100405\n",
      "19 Train Loss 14.834026 Test MSE 7.91417944209716 Test RE 1.344655420135661\n",
      "20 Train Loss 13.19454 Test MSE 7.503370197194578 Test RE 1.3092911950299306\n",
      "21 Train Loss 11.925822 Test MSE 7.472033957564649 Test RE 1.3065543456074054\n",
      "22 Train Loss 11.30301 Test MSE 7.244678529100089 Test RE 1.2865231927333558\n",
      "23 Train Loss 10.584236 Test MSE 6.9493408644271275 Test RE 1.2600270467155401\n",
      "24 Train Loss 10.15867 Test MSE 6.807891590622403 Test RE 1.2471376085921113\n",
      "25 Train Loss 9.550661 Test MSE 6.615952886352056 Test RE 1.2294312903976488\n",
      "26 Train Loss 9.153103 Test MSE 6.588785122119461 Test RE 1.226904423899434\n",
      "27 Train Loss 8.72129 Test MSE 6.532574959750985 Test RE 1.2216597381460415\n",
      "28 Train Loss 8.346043 Test MSE 6.434402884173576 Test RE 1.2124453869098941\n",
      "29 Train Loss 7.9829683 Test MSE 6.4480426020067085 Test RE 1.2137297841175665\n",
      "30 Train Loss 7.6582375 Test MSE 6.487006695706705 Test RE 1.2173914110177853\n",
      "31 Train Loss 7.423504 Test MSE 6.40923954461627 Test RE 1.2100722792244445\n",
      "32 Train Loss 7.213892 Test MSE 6.339371690165476 Test RE 1.2034586375535687\n",
      "33 Train Loss 6.9940405 Test MSE 6.294811894522153 Test RE 1.1992215900164174\n",
      "34 Train Loss 6.775753 Test MSE 6.226101008485376 Test RE 1.1926585923642976\n",
      "35 Train Loss 6.568549 Test MSE 6.320352969668057 Test RE 1.2016520361184662\n",
      "36 Train Loss 6.2326384 Test MSE 6.372496633618433 Test RE 1.206598740481642\n",
      "37 Train Loss 6.055073 Test MSE 6.432218415674328 Test RE 1.2122395578970844\n",
      "38 Train Loss 5.7489376 Test MSE 6.362142759131598 Test RE 1.2056181161417696\n",
      "39 Train Loss 5.5583625 Test MSE 6.322521611655218 Test RE 1.201858174096157\n",
      "40 Train Loss 5.2251053 Test MSE 6.295847334832966 Test RE 1.1993202165788823\n",
      "41 Train Loss 4.7648325 Test MSE 6.1825451363442445 Test RE 1.1884795358373648\n",
      "42 Train Loss 4.4285293 Test MSE 6.171940771920294 Test RE 1.187459852301005\n",
      "43 Train Loss 4.1016808 Test MSE 6.227159787173822 Test RE 1.1927599967438882\n",
      "44 Train Loss 3.6853685 Test MSE 6.165031947880741 Test RE 1.1867950493951587\n",
      "45 Train Loss 3.2491784 Test MSE 6.029737218202432 Test RE 1.1737004012897767\n",
      "46 Train Loss 2.8053596 Test MSE 5.995819378014608 Test RE 1.1703946582624\n",
      "47 Train Loss 2.441232 Test MSE 5.837237511766598 Test RE 1.1548132085846834\n",
      "48 Train Loss 2.286755 Test MSE 5.745330243261817 Test RE 1.1456858751770256\n",
      "49 Train Loss 2.1987853 Test MSE 5.741892472360318 Test RE 1.1453430580761235\n",
      "50 Train Loss 2.0721061 Test MSE 5.731558043929372 Test RE 1.1443118826732885\n",
      "51 Train Loss 1.9393234 Test MSE 5.713410326709746 Test RE 1.1424988405100787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 1.8234473 Test MSE 5.62769464318881 Test RE 1.1338962594983368\n",
      "53 Train Loss 1.7672338 Test MSE 5.592816914008122 Test RE 1.130377128290768\n",
      "54 Train Loss 1.7179495 Test MSE 5.633524649635609 Test RE 1.1344834369964651\n",
      "55 Train Loss 1.6833946 Test MSE 5.628402395984984 Test RE 1.1339675580556525\n",
      "56 Train Loss 1.650557 Test MSE 5.649420681652849 Test RE 1.1360828869553656\n",
      "57 Train Loss 1.600826 Test MSE 5.644795385158566 Test RE 1.135617724554856\n",
      "58 Train Loss 1.5650697 Test MSE 5.6783745124020095 Test RE 1.1389904340259676\n",
      "59 Train Loss 1.5524687 Test MSE 5.6921897930117575 Test RE 1.1403751536397733\n",
      "60 Train Loss 1.5279957 Test MSE 5.664345749253339 Test RE 1.137582592024665\n",
      "61 Train Loss 1.5087923 Test MSE 5.699721848177577 Test RE 1.141129391405728\n",
      "62 Train Loss 1.4773127 Test MSE 5.731571682623509 Test RE 1.1443132441626394\n",
      "63 Train Loss 1.45437 Test MSE 5.76042450619827 Test RE 1.147189874049075\n",
      "64 Train Loss 1.4349649 Test MSE 5.80190251594326 Test RE 1.1513126434692893\n",
      "65 Train Loss 1.4051569 Test MSE 5.7830134430534725 Test RE 1.149436969266134\n",
      "66 Train Loss 1.3811151 Test MSE 5.755889107007021 Test RE 1.1467381722216206\n",
      "67 Train Loss 1.3619902 Test MSE 5.797294570678623 Test RE 1.1508553590346486\n",
      "68 Train Loss 1.3372644 Test MSE 5.807750066645427 Test RE 1.1518926828236706\n",
      "69 Train Loss 1.3166018 Test MSE 5.796396872929155 Test RE 1.1507662519304345\n",
      "70 Train Loss 1.298286 Test MSE 5.798885641298795 Test RE 1.151013274637236\n",
      "71 Train Loss 1.282412 Test MSE 5.812840686609153 Test RE 1.1523974018142502\n",
      "72 Train Loss 1.2690797 Test MSE 5.807069218708812 Test RE 1.1518251621199864\n",
      "73 Train Loss 1.2538357 Test MSE 5.788462711604622 Test RE 1.149978392518631\n",
      "74 Train Loss 1.2442575 Test MSE 5.794891301561407 Test RE 1.1506167906980997\n",
      "75 Train Loss 1.239032 Test MSE 5.808180939962002 Test RE 1.1519354111272149\n",
      "76 Train Loss 1.2288076 Test MSE 5.786140684353639 Test RE 1.1497477139130676\n",
      "77 Train Loss 1.2168837 Test MSE 5.78101842836277 Test RE 1.1492386867039643\n",
      "78 Train Loss 1.2056758 Test MSE 5.769641835207821 Test RE 1.1481073237931123\n",
      "79 Train Loss 1.1929615 Test MSE 5.748938104654945 Test RE 1.146045543546617\n",
      "80 Train Loss 1.1829736 Test MSE 5.768488565967405 Test RE 1.1479925729063423\n",
      "81 Train Loss 1.1755767 Test MSE 5.762263494628028 Test RE 1.1473729769223304\n",
      "82 Train Loss 1.1626648 Test MSE 5.740276389937812 Test RE 1.1451818656598522\n",
      "83 Train Loss 1.1524881 Test MSE 5.757122821665021 Test RE 1.146861061306581\n",
      "84 Train Loss 1.1487286 Test MSE 5.786652030467205 Test RE 1.1497985168634717\n",
      "85 Train Loss 1.1427078 Test MSE 5.774731896904496 Test RE 1.1486136506107991\n",
      "86 Train Loss 1.1332834 Test MSE 5.784797606539798 Test RE 1.1496142665644284\n",
      "87 Train Loss 1.125711 Test MSE 5.82985135714972 Test RE 1.1540823552617536\n",
      "88 Train Loss 1.1103511 Test MSE 5.819783327240419 Test RE 1.1530853867387516\n",
      "89 Train Loss 1.0983672 Test MSE 5.805113922650726 Test RE 1.1516312304888052\n",
      "90 Train Loss 1.0890155 Test MSE 5.824315759451372 Test RE 1.1535343093100454\n",
      "91 Train Loss 1.0829829 Test MSE 5.852494736383843 Test RE 1.156321434549122\n",
      "92 Train Loss 1.0733682 Test MSE 5.882002325035201 Test RE 1.1592327876792539\n",
      "93 Train Loss 1.0692704 Test MSE 5.874779165604048 Test RE 1.158520794127418\n",
      "94 Train Loss 1.0618273 Test MSE 5.880737101694209 Test RE 1.159108105030429\n",
      "95 Train Loss 1.0547564 Test MSE 5.8966037253942565 Test RE 1.1606707274867378\n",
      "96 Train Loss 1.0463767 Test MSE 5.878651045415519 Test RE 1.1589025033204943\n",
      "97 Train Loss 1.0407957 Test MSE 5.883812267459285 Test RE 1.1594111268830185\n",
      "98 Train Loss 1.037038 Test MSE 5.893512315113077 Test RE 1.16036643538957\n",
      "99 Train Loss 1.0322294 Test MSE 5.9004684836199885 Test RE 1.1610510291979927\n",
      "100 Train Loss 1.0274037 Test MSE 5.9154275785657 Test RE 1.1625218681986995\n",
      "101 Train Loss 1.0225434 Test MSE 5.9296763788597096 Test RE 1.163921139742734\n",
      "102 Train Loss 1.0163465 Test MSE 5.935951241815601 Test RE 1.164536815375558\n",
      "103 Train Loss 1.010834 Test MSE 5.929050685191105 Test RE 1.1638597302109446\n",
      "104 Train Loss 1.0042502 Test MSE 5.928122198555515 Test RE 1.1637685966912326\n",
      "105 Train Loss 1.0000426 Test MSE 5.926624875576465 Test RE 1.1636216152821097\n",
      "106 Train Loss 0.9967079 Test MSE 5.927176903767086 Test RE 1.1636758060729273\n",
      "107 Train Loss 0.9909395 Test MSE 5.916495691106016 Test RE 1.1626268181894361\n",
      "108 Train Loss 0.98581356 Test MSE 5.934778157545957 Test RE 1.1644217396897951\n",
      "109 Train Loss 0.9834445 Test MSE 5.948497812783199 Test RE 1.1657668820251619\n",
      "110 Train Loss 0.9787923 Test MSE 5.96076284370836 Test RE 1.166968093209602\n",
      "111 Train Loss 0.9746003 Test MSE 5.946847599895211 Test RE 1.1656051691832636\n",
      "112 Train Loss 0.9700898 Test MSE 5.947271928381495 Test RE 1.165646753455115\n",
      "113 Train Loss 0.9666662 Test MSE 5.953774618353656 Test RE 1.1662838328376508\n",
      "114 Train Loss 0.96329236 Test MSE 5.954364365143469 Test RE 1.166341594103291\n",
      "115 Train Loss 0.95906174 Test MSE 5.944627091548089 Test RE 1.1653875347461737\n",
      "116 Train Loss 0.9530202 Test MSE 5.948060750896395 Test RE 1.1657240542686065\n",
      "117 Train Loss 0.9479952 Test MSE 5.951892969979812 Test RE 1.1660995203940758\n",
      "118 Train Loss 0.9423094 Test MSE 5.930533420541277 Test RE 1.1640052499728206\n",
      "119 Train Loss 0.9405661 Test MSE 5.92549815951495 Test RE 1.1635110014412515\n",
      "120 Train Loss 0.9362056 Test MSE 5.943803510440909 Test RE 1.1653068043331005\n",
      "121 Train Loss 0.9324516 Test MSE 5.970905160127377 Test RE 1.1679604770341194\n",
      "122 Train Loss 0.9303923 Test MSE 5.979595829391715 Test RE 1.1688101528507968\n",
      "123 Train Loss 0.9278469 Test MSE 5.990149450313536 Test RE 1.1698411373623785\n",
      "124 Train Loss 0.9240862 Test MSE 5.993374578430248 Test RE 1.1701560193095237\n",
      "125 Train Loss 0.9181473 Test MSE 5.987770407290679 Test RE 1.169608807701211\n",
      "126 Train Loss 0.91197467 Test MSE 5.990979554088603 Test RE 1.1699221917594174\n",
      "127 Train Loss 0.90826434 Test MSE 5.982278815124431 Test RE 1.1690723402436192\n",
      "128 Train Loss 0.9055894 Test MSE 5.976709969507746 Test RE 1.1685280744715216\n",
      "129 Train Loss 0.90343237 Test MSE 5.985924830527265 Test RE 1.1694285428404971\n",
      "130 Train Loss 0.9002185 Test MSE 5.978930800287795 Test RE 1.1687451556165431\n",
      "131 Train Loss 0.8954349 Test MSE 5.967063197274345 Test RE 1.167584656056604\n",
      "132 Train Loss 0.8910732 Test MSE 5.983709055305915 Test RE 1.1692120825024828\n",
      "133 Train Loss 0.8870566 Test MSE 5.996291441805111 Test RE 1.1704407312033498\n",
      "134 Train Loss 0.88488096 Test MSE 5.981651538567191 Test RE 1.169011046636288\n",
      "135 Train Loss 0.8788206 Test MSE 5.998772631277005 Test RE 1.17068286293524\n",
      "136 Train Loss 0.87357265 Test MSE 6.020265978684089 Test RE 1.172778241174266\n",
      "137 Train Loss 0.86984307 Test MSE 6.0365308498554775 Test RE 1.174361412143889\n",
      "138 Train Loss 0.86466485 Test MSE 6.068740845178555 Test RE 1.1774903492808535\n",
      "139 Train Loss 0.8628185 Test MSE 6.067541322861347 Test RE 1.1773739745839629\n",
      "140 Train Loss 0.86026263 Test MSE 6.065602055563429 Test RE 1.177185807318779\n",
      "141 Train Loss 0.8570927 Test MSE 6.079715243826048 Test RE 1.1785545248750997\n",
      "142 Train Loss 0.85193205 Test MSE 6.08003719331454 Test RE 1.1785857294618398\n",
      "143 Train Loss 0.8448973 Test MSE 6.100078166360134 Test RE 1.1805265541704384\n",
      "144 Train Loss 0.8420636 Test MSE 6.098772243617877 Test RE 1.1804001821016403\n",
      "145 Train Loss 0.83919215 Test MSE 6.09002046569473 Test RE 1.1795529370642293\n",
      "146 Train Loss 0.83601785 Test MSE 6.110445654768562 Test RE 1.1815293199676886\n",
      "147 Train Loss 0.83319813 Test MSE 6.110926788511439 Test RE 1.1815758355957016\n",
      "148 Train Loss 0.8307161 Test MSE 6.097127505097287 Test RE 1.180241004116009\n",
      "149 Train Loss 0.82784694 Test MSE 6.113037852815139 Test RE 1.1817799099748005\n",
      "Training time: 228.84\n",
      "0\n",
      "KG_rowdy_tune64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 72.4315 Test MSE 4.382956464812173 Test RE 1.0006717485131105\n",
      "1 Train Loss 71.42203 Test MSE 4.360403265777983 Test RE 0.9980938702605658\n",
      "2 Train Loss 60.978344 Test MSE 5.482219679146732 Test RE 1.1191447903763065\n",
      "3 Train Loss 49.68264 Test MSE 7.140409664030282 Test RE 1.2772315116174116\n",
      "4 Train Loss 43.68783 Test MSE 7.47909970707243 Test RE 1.3071719555081325\n",
      "5 Train Loss 37.152065 Test MSE 8.398473563665306 Test RE 1.3851864673305028\n",
      "6 Train Loss 33.473553 Test MSE 8.646376989140391 Test RE 1.405481533693087\n",
      "7 Train Loss 30.081337 Test MSE 8.332133317227338 Test RE 1.3797047687802435\n",
      "8 Train Loss 28.058258 Test MSE 8.215731368321581 Test RE 1.370033465111307\n",
      "9 Train Loss 26.82583 Test MSE 8.31237615465001 Test RE 1.3780680192980819\n",
      "10 Train Loss 25.565079 Test MSE 8.403053266880665 Test RE 1.3855640882334106\n",
      "11 Train Loss 24.152308 Test MSE 8.51165729080808 Test RE 1.3944891027655195\n",
      "12 Train Loss 23.02649 Test MSE 8.58364045099898 Test RE 1.4003732915709062\n",
      "13 Train Loss 21.940947 Test MSE 8.406232073605787 Test RE 1.3858261372672358\n",
      "14 Train Loss 21.016605 Test MSE 8.5656168541074 Test RE 1.3989022940874896\n",
      "15 Train Loss 20.351244 Test MSE 8.62918702261533 Test RE 1.404083711184042\n",
      "16 Train Loss 19.486563 Test MSE 8.712245952719245 Test RE 1.4108249257353809\n",
      "17 Train Loss 18.37689 Test MSE 8.615388858656514 Test RE 1.4029606895061986\n",
      "18 Train Loss 17.6212 Test MSE 8.485225476865818 Test RE 1.3923222194639728\n",
      "19 Train Loss 16.972584 Test MSE 8.489389933413324 Test RE 1.392663845867537\n",
      "20 Train Loss 16.56464 Test MSE 8.576189384615622 Test RE 1.3997653595530644\n",
      "21 Train Loss 15.868911 Test MSE 8.50012665352113 Test RE 1.3935442340513307\n",
      "22 Train Loss 15.442893 Test MSE 8.38494918535763 Test RE 1.38407070899194\n",
      "23 Train Loss 15.049082 Test MSE 8.275989765490165 Test RE 1.3750485509578376\n",
      "24 Train Loss 14.727562 Test MSE 8.261200268816356 Test RE 1.3738193705158785\n",
      "25 Train Loss 14.114887 Test MSE 8.292210953041783 Test RE 1.3763954594358319\n",
      "26 Train Loss 13.714157 Test MSE 8.27442815221104 Test RE 1.3749188144887665\n",
      "27 Train Loss 13.374931 Test MSE 8.288573760068294 Test RE 1.376093563776836\n",
      "28 Train Loss 12.938297 Test MSE 8.287458606030626 Test RE 1.3760009900749555\n",
      "29 Train Loss 12.490248 Test MSE 8.08058994470106 Test RE 1.3587188314826135\n",
      "30 Train Loss 11.665507 Test MSE 7.641606599632627 Test RE 1.3212968456888097\n",
      "31 Train Loss 10.369358 Test MSE 7.109784306036799 Test RE 1.2744895327754593\n",
      "32 Train Loss 9.485605 Test MSE 7.041542051607824 Test RE 1.2683582814711956\n",
      "33 Train Loss 8.8648815 Test MSE 7.118485697052596 Test RE 1.2752691936106788\n",
      "34 Train Loss 8.199025 Test MSE 7.137731150188176 Test RE 1.2769919313038083\n",
      "35 Train Loss 7.8694 Test MSE 7.090173627524483 Test RE 1.2727306282867739\n",
      "36 Train Loss 7.607091 Test MSE 7.019448963233916 Test RE 1.2663669586960695\n",
      "37 Train Loss 7.276043 Test MSE 7.030573761607157 Test RE 1.2673700644733192\n",
      "38 Train Loss 6.907374 Test MSE 6.961997713858957 Test RE 1.2611739697120732\n",
      "39 Train Loss 6.5945196 Test MSE 6.895298051162837 Test RE 1.2551180694403772\n",
      "40 Train Loss 6.3211956 Test MSE 6.828402024561988 Test RE 1.2490148488629234\n",
      "41 Train Loss 6.076497 Test MSE 6.767333731839387 Test RE 1.2434171622755068\n",
      "42 Train Loss 5.8232284 Test MSE 6.711814624434153 Test RE 1.2383061699125733\n",
      "43 Train Loss 5.5895567 Test MSE 6.6736920089166425 Test RE 1.2347844177897263\n",
      "44 Train Loss 5.11444 Test MSE 6.458744991604817 Test RE 1.2147366341185069\n",
      "45 Train Loss 4.800278 Test MSE 6.339010047756169 Test RE 1.2034243101856792\n",
      "46 Train Loss 4.487014 Test MSE 6.241868421518842 Test RE 1.1941678234060864\n",
      "47 Train Loss 4.2299886 Test MSE 6.0742762634825205 Test RE 1.1780272329770896\n",
      "48 Train Loss 3.9124238 Test MSE 6.065234814838427 Test RE 1.177150170533747\n",
      "49 Train Loss 3.6771069 Test MSE 5.994182630004396 Test RE 1.1702348992904559\n",
      "50 Train Loss 3.473138 Test MSE 6.0633715553017336 Test RE 1.1769693444961584\n",
      "51 Train Loss 3.3640578 Test MSE 6.146835637956567 Test RE 1.1850423213400934\n",
      "52 Train Loss 3.254408 Test MSE 6.071018224073454 Test RE 1.1777112633229838\n",
      "53 Train Loss 3.1391711 Test MSE 5.997358608414076 Test RE 1.1705448788843982\n",
      "54 Train Loss 3.055902 Test MSE 5.908903523924872 Test RE 1.1618806255821243\n",
      "55 Train Loss 2.9440525 Test MSE 5.674537569500923 Test RE 1.1386055545366187\n",
      "56 Train Loss 2.8896065 Test MSE 5.648092803974133 Test RE 1.1359493628429986\n",
      "57 Train Loss 2.8012948 Test MSE 5.59681639440847 Test RE 1.1307812281646554\n",
      "58 Train Loss 2.6997728 Test MSE 5.552244172682622 Test RE 1.126269539997901\n",
      "59 Train Loss 2.608317 Test MSE 5.514741469406895 Test RE 1.122459394272381\n",
      "60 Train Loss 2.551335 Test MSE 5.488530053064702 Test RE 1.119788707568066\n",
      "61 Train Loss 2.4903283 Test MSE 5.52805849168346 Test RE 1.1238138370605433\n",
      "62 Train Loss 2.452807 Test MSE 5.500648641037926 Test RE 1.1210242638429035\n",
      "63 Train Loss 2.4134076 Test MSE 5.51336100699962 Test RE 1.1223188972075946\n",
      "64 Train Loss 2.3634524 Test MSE 5.590536474610412 Test RE 1.1301466523609054\n",
      "65 Train Loss 2.3324456 Test MSE 5.626891949917768 Test RE 1.1338153912731914\n",
      "66 Train Loss 2.2990904 Test MSE 5.639578709913603 Test RE 1.1350928589210876\n",
      "67 Train Loss 2.2711587 Test MSE 5.632227656131139 Test RE 1.1343528347145668\n",
      "68 Train Loss 2.2474167 Test MSE 5.613624645740995 Test RE 1.1324779254635418\n",
      "69 Train Loss 2.209608 Test MSE 5.618056863413137 Test RE 1.1329249092415814\n",
      "70 Train Loss 2.178867 Test MSE 5.628140662271493 Test RE 1.1339411916936204\n",
      "71 Train Loss 2.1582081 Test MSE 5.65270722041342 Test RE 1.1364132958398967\n",
      "72 Train Loss 2.137529 Test MSE 5.644971392466687 Test RE 1.1356354289575026\n",
      "73 Train Loss 2.099446 Test MSE 5.709055021375855 Test RE 1.1420632967933488\n",
      "74 Train Loss 2.071436 Test MSE 5.7578697046725615 Test RE 1.1469354511785592\n",
      "75 Train Loss 2.0535383 Test MSE 5.748365947144986 Test RE 1.1459885125899159\n",
      "76 Train Loss 2.027065 Test MSE 5.806882696065946 Test RE 1.1518066637010367\n",
      "77 Train Loss 2.010134 Test MSE 5.80912367895647 Test RE 1.1520288939559387\n",
      "78 Train Loss 1.9868573 Test MSE 5.773964443329647 Test RE 1.1485373235225687\n",
      "79 Train Loss 1.9751196 Test MSE 5.816895950329211 Test RE 1.1527993103514098\n",
      "80 Train Loss 1.9685979 Test MSE 5.814988543614261 Test RE 1.152610288796821\n",
      "81 Train Loss 1.9534842 Test MSE 5.789539256497652 Test RE 1.150085324693137\n",
      "82 Train Loss 1.9371111 Test MSE 5.773256225465386 Test RE 1.148466883220885\n",
      "83 Train Loss 1.9220487 Test MSE 5.814590066539991 Test RE 1.1525707963162455\n",
      "84 Train Loss 1.908411 Test MSE 5.828689244854792 Test RE 1.15396732315753\n",
      "85 Train Loss 1.8817704 Test MSE 5.828030125478792 Test RE 1.1539020748921123\n",
      "86 Train Loss 1.8557906 Test MSE 5.853497591782262 Test RE 1.156420501149996\n",
      "87 Train Loss 1.8453202 Test MSE 5.869479520178673 Test RE 1.1579981247174327\n",
      "88 Train Loss 1.8312038 Test MSE 5.879603221778429 Test RE 1.1589963543487742\n",
      "89 Train Loss 1.8193457 Test MSE 5.872595453684092 Test RE 1.158305457453918\n",
      "90 Train Loss 1.8025132 Test MSE 5.880837474169245 Test RE 1.1591179968221288\n",
      "91 Train Loss 1.7893662 Test MSE 5.908186202611351 Test RE 1.1618100992121374\n",
      "92 Train Loss 1.7694981 Test MSE 5.900656702118807 Test RE 1.1610695471800538\n",
      "93 Train Loss 1.7486639 Test MSE 5.921369654343346 Test RE 1.1631056010806498\n",
      "94 Train Loss 1.7300211 Test MSE 5.942378676601312 Test RE 1.1651671237327748\n",
      "95 Train Loss 1.7148856 Test MSE 5.973467297229521 Test RE 1.1682110382003246\n",
      "96 Train Loss 1.701396 Test MSE 5.985766348137442 Test RE 1.1694130619363614\n",
      "97 Train Loss 1.6864599 Test MSE 5.959631197107088 Test RE 1.1668573139187979\n",
      "98 Train Loss 1.6784059 Test MSE 5.961468374112467 Test RE 1.1670371537586064\n",
      "99 Train Loss 1.6654291 Test MSE 6.0100275985847045 Test RE 1.1717805727260928\n",
      "100 Train Loss 1.6491361 Test MSE 6.020660430841042 Test RE 1.1728166611818864\n",
      "101 Train Loss 1.6364334 Test MSE 6.0192851453781975 Test RE 1.1726827016400057\n",
      "102 Train Loss 1.627484 Test MSE 6.012418081404384 Test RE 1.172013586867969\n",
      "103 Train Loss 1.6078451 Test MSE 6.016838442345191 Test RE 1.1724443429412839\n",
      "104 Train Loss 1.587881 Test MSE 6.031834645638473 Test RE 1.1739045177622818\n",
      "105 Train Loss 1.5779538 Test MSE 6.043502405671241 Test RE 1.1750393481872585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 1.5672497 Test MSE 6.042752852446086 Test RE 1.1749664780380575\n",
      "107 Train Loss 1.5582557 Test MSE 6.052491902773607 Test RE 1.1759129382843714\n",
      "108 Train Loss 1.5530794 Test MSE 6.041156976592687 Test RE 1.1748113149447346\n",
      "109 Train Loss 1.5466135 Test MSE 6.0055614210511195 Test RE 1.1713451044522472\n",
      "110 Train Loss 1.535402 Test MSE 5.975297299681403 Test RE 1.1683899682295018\n",
      "111 Train Loss 1.5218732 Test MSE 5.9940167041547925 Test RE 1.1702187024563224\n",
      "112 Train Loss 1.5127538 Test MSE 5.9727766188939215 Test RE 1.1681434994209354\n",
      "113 Train Loss 1.5044323 Test MSE 5.993965290502373 Test RE 1.1702136836726245\n",
      "114 Train Loss 1.4927058 Test MSE 5.9981489789176035 Test RE 1.1706220073109879\n",
      "115 Train Loss 1.4829843 Test MSE 5.988934689884977 Test RE 1.169722513546181\n",
      "116 Train Loss 1.4773265 Test MSE 6.000549506124344 Test RE 1.1708562319762985\n",
      "117 Train Loss 1.4708377 Test MSE 6.0020326553203 Test RE 1.1710009226571236\n",
      "118 Train Loss 1.4648957 Test MSE 5.997680221667232 Test RE 1.1705762641761703\n",
      "119 Train Loss 1.4561961 Test MSE 5.975927867038308 Test RE 1.1684516161359644\n",
      "120 Train Loss 1.44833 Test MSE 5.975601725507233 Test RE 1.1684197310624538\n",
      "121 Train Loss 1.442098 Test MSE 5.996719700358851 Test RE 1.170482527229281\n",
      "122 Train Loss 1.4358397 Test MSE 5.994776360781716 Test RE 1.1702928544208584\n",
      "123 Train Loss 1.430558 Test MSE 5.992828058991212 Test RE 1.1701026664294054\n",
      "124 Train Loss 1.4234226 Test MSE 6.013375450272558 Test RE 1.1721068941399344\n",
      "125 Train Loss 1.4180918 Test MSE 6.014710824326638 Test RE 1.1722370302226248\n",
      "126 Train Loss 1.4130591 Test MSE 6.0271576519371175 Test RE 1.1734493155681318\n",
      "127 Train Loss 1.4097357 Test MSE 6.026037349671544 Test RE 1.1733402526318975\n",
      "128 Train Loss 1.4067652 Test MSE 6.02110340344571 Test RE 1.1728598056260418\n",
      "129 Train Loss 1.4028519 Test MSE 6.013839951061985 Test RE 1.1721521627306515\n",
      "130 Train Loss 1.3996022 Test MSE 6.023987054564106 Test RE 1.1731406273804703\n",
      "131 Train Loss 1.3967602 Test MSE 6.041805638346798 Test RE 1.1748743852072827\n",
      "132 Train Loss 1.3955474 Test MSE 6.045567272404087 Test RE 1.17524006726418\n",
      "133 Train Loss 1.39349 Test MSE 6.0471461994963365 Test RE 1.175393526580392\n",
      "134 Train Loss 1.3917055 Test MSE 6.037299265020817 Test RE 1.1744361544441835\n",
      "135 Train Loss 1.3871291 Test MSE 6.000385127820832 Test RE 1.1708401947217963\n",
      "136 Train Loss 1.3831009 Test MSE 6.024516229744805 Test RE 1.1731921533270757\n",
      "137 Train Loss 1.3779799 Test MSE 6.021327030324217 Test RE 1.172881585732145\n",
      "138 Train Loss 1.3740692 Test MSE 6.004526199704488 Test RE 1.171244143556831\n",
      "139 Train Loss 1.3668466 Test MSE 5.994631530891382 Test RE 1.1702787175791074\n",
      "140 Train Loss 1.3621753 Test MSE 5.9799328248386034 Test RE 1.1688430880325047\n",
      "141 Train Loss 1.3560199 Test MSE 6.009380372678993 Test RE 1.1717174759141789\n",
      "142 Train Loss 1.3486645 Test MSE 6.004989571628156 Test RE 1.1712893353974294\n",
      "143 Train Loss 1.346465 Test MSE 5.9819075070719965 Test RE 1.169036058692462\n",
      "144 Train Loss 1.3438721 Test MSE 5.97813116512634 Test RE 1.168666997748325\n",
      "145 Train Loss 1.341164 Test MSE 5.966222413005169 Test RE 1.1675023943675058\n",
      "146 Train Loss 1.3369515 Test MSE 5.9632868691269865 Test RE 1.1672151375449598\n",
      "147 Train Loss 1.3320338 Test MSE 5.973163269528986 Test RE 1.16818130898132\n",
      "148 Train Loss 1.3252658 Test MSE 5.9846837286324845 Test RE 1.169307303828957\n",
      "149 Train Loss 1.3212614 Test MSE 5.978320708473913 Test RE 1.168685524549848\n",
      "Training time: 229.41\n",
      "1\n",
      "KG_rowdy_tune64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 63.87248 Test MSE 6.4684506605809124 Test RE 1.2156489944770195\n",
      "1 Train Loss 50.573097 Test MSE 9.467794592449804 Test RE 1.4707283832949878\n",
      "2 Train Loss 44.534866 Test MSE 9.88131460556894 Test RE 1.5025032624043027\n",
      "3 Train Loss 41.27537 Test MSE 9.50955839150333 Test RE 1.4739686108057612\n",
      "4 Train Loss 38.15679 Test MSE 9.688366458219292 Test RE 1.4877615790357996\n",
      "5 Train Loss 34.434513 Test MSE 10.009478724208797 Test RE 1.5122158672316064\n",
      "6 Train Loss 31.552002 Test MSE 9.358983723552942 Test RE 1.462252613555828\n",
      "7 Train Loss 29.530628 Test MSE 9.457619595439686 Test RE 1.4699378782026384\n",
      "8 Train Loss 27.707132 Test MSE 9.497483748018585 Test RE 1.4730325369143897\n",
      "9 Train Loss 25.475182 Test MSE 9.759005050848339 Test RE 1.4931754183471206\n",
      "10 Train Loss 23.363228 Test MSE 9.573927652497435 Test RE 1.4789487713979612\n",
      "11 Train Loss 22.175396 Test MSE 9.617538104701048 Test RE 1.482313343658345\n",
      "12 Train Loss 21.574331 Test MSE 9.490588301034956 Test RE 1.4724977077790746\n",
      "13 Train Loss 21.174833 Test MSE 9.471043657610911 Test RE 1.470980716740555\n",
      "14 Train Loss 20.67256 Test MSE 9.254106874227856 Test RE 1.4540365238511612\n",
      "15 Train Loss 20.150892 Test MSE 8.875048293725289 Test RE 1.4239456813070102\n",
      "16 Train Loss 19.536077 Test MSE 8.045815519337072 Test RE 1.355792089148349\n",
      "17 Train Loss 17.326054 Test MSE 7.148227286181205 Test RE 1.2779305038563435\n",
      "18 Train Loss 16.316767 Test MSE 6.841948798493709 Test RE 1.2502531867747926\n",
      "19 Train Loss 15.484154 Test MSE 6.993287978386047 Test RE 1.2640049262644375\n",
      "20 Train Loss 14.922976 Test MSE 7.04094027290955 Test RE 1.268304082596987\n",
      "21 Train Loss 14.597868 Test MSE 7.043342798850944 Test RE 1.2685204509688783\n",
      "22 Train Loss 14.330019 Test MSE 7.1246392709940505 Test RE 1.27582027767617\n",
      "23 Train Loss 14.055345 Test MSE 7.144891758787689 Test RE 1.2776323131720257\n",
      "24 Train Loss 13.76342 Test MSE 7.161428241384016 Test RE 1.2791099656472473\n",
      "25 Train Loss 13.56774 Test MSE 7.110004257906222 Test RE 1.274509246748147\n",
      "26 Train Loss 13.392822 Test MSE 7.009569971620831 Test RE 1.2654755188235485\n",
      "27 Train Loss 13.160498 Test MSE 6.980950084605385 Test RE 1.2628894250100535\n",
      "28 Train Loss 13.003159 Test MSE 7.0588950492729445 Test RE 1.2699201747829931\n",
      "29 Train Loss 12.775494 Test MSE 7.07249499598118 Test RE 1.2711429253629276\n",
      "30 Train Loss 12.63324 Test MSE 7.017919678232952 Test RE 1.2662290033168029\n",
      "31 Train Loss 12.421765 Test MSE 7.092785509425813 Test RE 1.2729650312915244\n",
      "32 Train Loss 12.226113 Test MSE 7.173616565420391 Test RE 1.2801979873694769\n",
      "33 Train Loss 11.896637 Test MSE 7.1032408576513335 Test RE 1.2739029132793205\n",
      "34 Train Loss 11.629393 Test MSE 7.005035813228695 Test RE 1.2650661645653272\n",
      "35 Train Loss 11.404539 Test MSE 6.989431599011669 Test RE 1.2636563667082281\n",
      "36 Train Loss 11.190907 Test MSE 6.8448388096727815 Test RE 1.2505172098125534\n",
      "37 Train Loss 10.906736 Test MSE 6.695709093706259 Test RE 1.2368195707131506\n",
      "38 Train Loss 10.489601 Test MSE 6.693455414415729 Test RE 1.2366114053640938\n",
      "39 Train Loss 9.918749 Test MSE 6.347297431666379 Test RE 1.2042107091391125\n",
      "40 Train Loss 9.234209 Test MSE 6.1689005685439 Test RE 1.1871673540198624\n",
      "41 Train Loss 8.869551 Test MSE 6.341329900435968 Test RE 1.2036444953340457\n",
      "42 Train Loss 8.484137 Test MSE 6.293937572335921 Test RE 1.1991383037744539\n",
      "43 Train Loss 8.130266 Test MSE 6.240581760118513 Test RE 1.19404473775857\n",
      "44 Train Loss 7.971587 Test MSE 6.325781654517852 Test RE 1.202167987527058\n",
      "45 Train Loss 7.8481083 Test MSE 6.329815870460127 Test RE 1.2025512628707924\n",
      "46 Train Loss 7.6359262 Test MSE 6.383040003676789 Test RE 1.2075964938031836\n",
      "47 Train Loss 7.4103518 Test MSE 6.439738207212705 Test RE 1.2129479547098838\n",
      "48 Train Loss 7.279879 Test MSE 6.403926878954958 Test RE 1.2095706563599609\n",
      "49 Train Loss 7.1768003 Test MSE 6.445474625812674 Test RE 1.2134880720376113\n",
      "50 Train Loss 7.076972 Test MSE 6.4764611751713925 Test RE 1.2164014900522453\n",
      "51 Train Loss 6.975687 Test MSE 6.413264533059088 Test RE 1.2104521809643383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 6.888056 Test MSE 6.424141019798926 Test RE 1.2114781709112874\n",
      "53 Train Loss 6.7609177 Test MSE 6.432278761647079 Test RE 1.2122452443958178\n",
      "54 Train Loss 6.6060934 Test MSE 6.4314696982921955 Test RE 1.2121690028270198\n",
      "55 Train Loss 6.467515 Test MSE 6.355453667842458 Test RE 1.2049841622374413\n",
      "56 Train Loss 6.091935 Test MSE 6.0854648150297885 Test RE 1.179111671187786\n",
      "57 Train Loss 5.3022656 Test MSE 5.677380981306853 Test RE 1.1388907865023283\n",
      "58 Train Loss 4.4060245 Test MSE 5.429384687769735 Test RE 1.11373884478146\n",
      "59 Train Loss 3.7525432 Test MSE 5.351838213802826 Test RE 1.105756620730281\n",
      "60 Train Loss 3.389721 Test MSE 5.467651912779864 Test RE 1.1176568634153972\n",
      "61 Train Loss 3.1567814 Test MSE 5.583863543123476 Test RE 1.1294719726648272\n",
      "62 Train Loss 3.0040402 Test MSE 5.589300096674329 Test RE 1.1300216763720254\n",
      "63 Train Loss 2.825084 Test MSE 5.601331919068459 Test RE 1.1312372946745155\n",
      "64 Train Loss 2.716013 Test MSE 5.612148188266998 Test RE 1.132328987338859\n",
      "65 Train Loss 2.6441221 Test MSE 5.577539403585546 Test RE 1.1288321860791513\n",
      "66 Train Loss 2.551732 Test MSE 5.5680654845811395 Test RE 1.1278730704952962\n",
      "67 Train Loss 2.4885175 Test MSE 5.543630938051843 Test RE 1.1253956060836676\n",
      "68 Train Loss 2.4351788 Test MSE 5.532371291501819 Test RE 1.1242521319126075\n",
      "69 Train Loss 2.3837664 Test MSE 5.565720914916111 Test RE 1.1276355862718364\n",
      "70 Train Loss 2.3094847 Test MSE 5.596879331129924 Test RE 1.1307875860168786\n",
      "71 Train Loss 2.2766666 Test MSE 5.573599551661656 Test RE 1.128433424456162\n",
      "72 Train Loss 2.2510011 Test MSE 5.563307017655908 Test RE 1.1273910275079584\n",
      "73 Train Loss 2.2129927 Test MSE 5.574671786608062 Test RE 1.1285419618165524\n",
      "74 Train Loss 2.1790774 Test MSE 5.590002598369097 Test RE 1.1300926885906148\n",
      "75 Train Loss 2.160432 Test MSE 5.61542570310743 Test RE 1.1326595811909563\n",
      "76 Train Loss 2.143593 Test MSE 5.636481395927246 Test RE 1.1347811138403712\n",
      "77 Train Loss 2.1301322 Test MSE 5.623335953509775 Test RE 1.1334570690687213\n",
      "78 Train Loss 2.1126251 Test MSE 5.6412580504951455 Test RE 1.1352618489923738\n",
      "79 Train Loss 2.0862105 Test MSE 5.646974777524847 Test RE 1.1358369280501905\n",
      "80 Train Loss 2.0670161 Test MSE 5.6260502306497315 Test RE 1.1337305851348707\n",
      "81 Train Loss 2.0380201 Test MSE 5.627435965493251 Test RE 1.1338701993564282\n",
      "82 Train Loss 2.004212 Test MSE 5.623640430696592 Test RE 1.1334877543373238\n",
      "83 Train Loss 1.9765588 Test MSE 5.615088758202768 Test RE 1.1326255989409955\n",
      "84 Train Loss 1.958653 Test MSE 5.59759041183661 Test RE 1.1308594167327384\n",
      "85 Train Loss 1.9365847 Test MSE 5.5773840537309525 Test RE 1.128816465424899\n",
      "86 Train Loss 1.9150565 Test MSE 5.587883712253312 Test RE 1.1298784879153747\n",
      "87 Train Loss 1.900761 Test MSE 5.585896117778835 Test RE 1.129677522747571\n",
      "88 Train Loss 1.874458 Test MSE 5.594413194923144 Test RE 1.130538430791059\n",
      "89 Train Loss 1.847246 Test MSE 5.658857346717794 Test RE 1.1370313346874\n",
      "90 Train Loss 1.8292174 Test MSE 5.6615068717877595 Test RE 1.1372974874011148\n",
      "91 Train Loss 1.8104225 Test MSE 5.693281668957545 Test RE 1.140484521786247\n",
      "92 Train Loss 1.796864 Test MSE 5.718649481169463 Test RE 1.1430225519158035\n",
      "93 Train Loss 1.7657148 Test MSE 5.733976165486486 Test RE 1.1445532475357167\n",
      "94 Train Loss 1.7357047 Test MSE 5.736882935652801 Test RE 1.14484331952109\n",
      "95 Train Loss 1.7183355 Test MSE 5.741621340909799 Test RE 1.1453160162783051\n",
      "96 Train Loss 1.700326 Test MSE 5.72155392760158 Test RE 1.1433127800860285\n",
      "97 Train Loss 1.6832314 Test MSE 5.707781584092468 Test RE 1.14193591782382\n",
      "98 Train Loss 1.6591295 Test MSE 5.7069727206300245 Test RE 1.1418550017136844\n",
      "99 Train Loss 1.6405742 Test MSE 5.697449005496125 Test RE 1.1409018481794355\n",
      "100 Train Loss 1.6185771 Test MSE 5.679039395245705 Test RE 1.1390571144668553\n",
      "101 Train Loss 1.6005583 Test MSE 5.6882818495441345 Test RE 1.1399836270957244\n",
      "102 Train Loss 1.5920658 Test MSE 5.681051148663731 Test RE 1.1392588474522551\n",
      "103 Train Loss 1.5699315 Test MSE 5.660502869999105 Test RE 1.1371966397500124\n",
      "104 Train Loss 1.5554171 Test MSE 5.650155789957441 Test RE 1.1361567986753713\n",
      "105 Train Loss 1.5398543 Test MSE 5.633839013557976 Test RE 1.1345150899766228\n",
      "106 Train Loss 1.5224992 Test MSE 5.631969953409439 Test RE 1.1343268832461038\n",
      "107 Train Loss 1.5030578 Test MSE 5.627139718346713 Test RE 1.1338403535941588\n",
      "108 Train Loss 1.4914213 Test MSE 5.607454755100192 Test RE 1.1318554055800374\n",
      "109 Train Loss 1.4625463 Test MSE 5.640656886841964 Test RE 1.1352013574905242\n",
      "110 Train Loss 1.4404384 Test MSE 5.6593829686729045 Test RE 1.1370841399375646\n",
      "111 Train Loss 1.4117554 Test MSE 5.632280073512346 Test RE 1.1343581132358067\n",
      "112 Train Loss 1.4044093 Test MSE 5.655403900407819 Test RE 1.1366843321305873\n",
      "113 Train Loss 1.3995461 Test MSE 5.6708916405655945 Test RE 1.1382397148619101\n",
      "114 Train Loss 1.3936368 Test MSE 5.6635158577826425 Test RE 1.1374992545384017\n",
      "115 Train Loss 1.3874648 Test MSE 5.671617365100666 Test RE 1.1383125448605955\n",
      "116 Train Loss 1.3804142 Test MSE 5.691901224902695 Test RE 1.1403462473590238\n",
      "117 Train Loss 1.3694297 Test MSE 5.698557065779524 Test RE 1.1410127861241215\n",
      "118 Train Loss 1.3616254 Test MSE 5.691926350574483 Test RE 1.1403487642626722\n",
      "119 Train Loss 1.3538556 Test MSE 5.68429635321484 Test RE 1.1395841921877772\n",
      "120 Train Loss 1.3457916 Test MSE 5.670501384144987 Test RE 1.1382005487988283\n",
      "121 Train Loss 1.3358463 Test MSE 5.687204318653174 Test RE 1.1398756484666948\n",
      "122 Train Loss 1.3263826 Test MSE 5.696433380342511 Test RE 1.1408001552764422\n",
      "123 Train Loss 1.3164055 Test MSE 5.703137041970545 Test RE 1.141471214613023\n",
      "124 Train Loss 1.3060931 Test MSE 5.725340995332123 Test RE 1.1436910939810372\n",
      "125 Train Loss 1.299154 Test MSE 5.721127457915224 Test RE 1.1432701695177172\n",
      "126 Train Loss 1.2927389 Test MSE 5.705014661016408 Test RE 1.1416590999560416\n",
      "127 Train Loss 1.2877568 Test MSE 5.7128414537602845 Test RE 1.1424419609209169\n",
      "128 Train Loss 1.2823542 Test MSE 5.710742908652752 Test RE 1.1422321103397468\n",
      "129 Train Loss 1.2767193 Test MSE 5.705443084642293 Test RE 1.1417019661516536\n",
      "130 Train Loss 1.2701539 Test MSE 5.693764958815669 Test RE 1.1405329273402023\n",
      "131 Train Loss 1.2626691 Test MSE 5.674160509607126 Test RE 1.1385677250556856\n",
      "132 Train Loss 1.2578694 Test MSE 5.671683674631787 Test RE 1.1383191991133104\n",
      "133 Train Loss 1.2522882 Test MSE 5.680642642304146 Test RE 1.1392178864717268\n",
      "134 Train Loss 1.2424153 Test MSE 5.688446493195688 Test RE 1.1400001250219798\n",
      "135 Train Loss 1.2363896 Test MSE 5.688330330093455 Test RE 1.1399884850577735\n",
      "136 Train Loss 1.2287613 Test MSE 5.6776786174930605 Test RE 1.1389206392344904\n",
      "137 Train Loss 1.2199986 Test MSE 5.692279425159904 Test RE 1.1403841320712782\n",
      "138 Train Loss 1.2136505 Test MSE 5.695386789163461 Test RE 1.140695352310683\n",
      "139 Train Loss 1.2065326 Test MSE 5.70048918277663 Test RE 1.1412062020483003\n",
      "140 Train Loss 1.2015837 Test MSE 5.709591661063128 Test RE 1.142116971358275\n",
      "141 Train Loss 1.197192 Test MSE 5.728045184966651 Test RE 1.1439611558426652\n",
      "142 Train Loss 1.1941819 Test MSE 5.756947281382048 Test RE 1.1468435767178282\n",
      "143 Train Loss 1.1907291 Test MSE 5.76844156476549 Test RE 1.1479878960191467\n",
      "144 Train Loss 1.1869706 Test MSE 5.758436961644808 Test RE 1.146991946995705\n",
      "145 Train Loss 1.1821982 Test MSE 5.769339163270023 Test RE 1.1480772088885873\n",
      "146 Train Loss 1.1796013 Test MSE 5.780588969720166 Test RE 1.149195998753817\n",
      "147 Train Loss 1.1753473 Test MSE 5.7823643670059095 Test RE 1.1493724619856358\n",
      "148 Train Loss 1.1716359 Test MSE 5.795357528262049 Test RE 1.1506630760771162\n",
      "149 Train Loss 1.1667116 Test MSE 5.791542305744104 Test RE 1.1502842592041875\n",
      "Training time: 228.89\n",
      "2\n",
      "KG_rowdy_tune64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 64.83179 Test MSE 6.2696755782797355 Test RE 1.1968248411947913\n",
      "1 Train Loss 52.564217 Test MSE 8.365559625108062 Test RE 1.3824695034193981\n",
      "2 Train Loss 40.112137 Test MSE 8.145312329028469 Test RE 1.3641493838528118\n",
      "3 Train Loss 33.912506 Test MSE 7.349739400742858 Test RE 1.295818066285932\n",
      "4 Train Loss 28.98291 Test MSE 6.9496020227704145 Test RE 1.260050722592928\n",
      "5 Train Loss 23.83404 Test MSE 6.412838008059742 Test RE 1.2104119287107886\n",
      "6 Train Loss 18.946636 Test MSE 6.015377212986204 Test RE 1.1723019663309713\n",
      "7 Train Loss 17.19028 Test MSE 5.9175500492008 Test RE 1.1627304074129674\n",
      "8 Train Loss 15.553825 Test MSE 5.986424688194384 Test RE 1.1694773686808728\n",
      "9 Train Loss 13.835069 Test MSE 5.9470852256936935 Test RE 1.165628456739196\n",
      "10 Train Loss 13.02335 Test MSE 5.894415132924341 Test RE 1.1604553093337053\n",
      "11 Train Loss 12.278488 Test MSE 5.903350137504318 Test RE 1.161334509977577\n",
      "12 Train Loss 11.643589 Test MSE 5.88810457834925 Test RE 1.1598339518727507\n",
      "13 Train Loss 11.132104 Test MSE 6.089645775569408 Test RE 1.1795166503523422\n",
      "14 Train Loss 10.454069 Test MSE 6.06943996265521 Test RE 1.177558170629294\n",
      "15 Train Loss 9.795446 Test MSE 5.842385528835794 Test RE 1.1553223268029942\n",
      "16 Train Loss 9.451622 Test MSE 5.768742055552089 Test RE 1.1480177962348028\n",
      "17 Train Loss 8.954754 Test MSE 5.522177279604257 Test RE 1.1232158742889746\n",
      "18 Train Loss 8.543592 Test MSE 5.438723859057675 Test RE 1.1146963132037166\n",
      "19 Train Loss 8.237471 Test MSE 5.451165251603625 Test RE 1.1159705507495559\n",
      "20 Train Loss 7.9256134 Test MSE 5.475938689172832 Test RE 1.1185035034382773\n",
      "21 Train Loss 7.6013665 Test MSE 5.396903595082888 Test RE 1.1104023965690053\n",
      "22 Train Loss 7.276557 Test MSE 5.319047245019139 Test RE 1.1023639040522009\n",
      "23 Train Loss 6.940242 Test MSE 5.185056736804837 Test RE 1.088390686377243\n",
      "24 Train Loss 6.7281075 Test MSE 5.048288347612386 Test RE 1.073940292589841\n",
      "25 Train Loss 6.4462385 Test MSE 4.86410594337896 Test RE 1.0541673793415909\n",
      "26 Train Loss 6.103444 Test MSE 4.646000984588043 Test RE 1.0302620648794243\n",
      "27 Train Loss 5.942585 Test MSE 4.6288655977296 Test RE 1.028360402889528\n",
      "28 Train Loss 5.699314 Test MSE 4.556646864873092 Test RE 1.0203067188593178\n",
      "29 Train Loss 5.5513315 Test MSE 4.351950622641419 Test RE 0.9971259983333691\n",
      "30 Train Loss 5.456725 Test MSE 4.29370997617032 Test RE 0.9904314293396979\n",
      "31 Train Loss 5.3452816 Test MSE 4.236113310925835 Test RE 0.9837660808655134\n",
      "32 Train Loss 5.242112 Test MSE 4.179729643006843 Test RE 0.9771970695123745\n",
      "33 Train Loss 5.150728 Test MSE 4.101408708474239 Test RE 0.9679982783523673\n",
      "34 Train Loss 5.0575724 Test MSE 3.985186733523765 Test RE 0.954184589498312\n",
      "35 Train Loss 4.934169 Test MSE 3.889402060297526 Test RE 0.942647847650144\n",
      "36 Train Loss 4.870689 Test MSE 3.8646902208824416 Test RE 0.9396484558190094\n",
      "37 Train Loss 4.8130856 Test MSE 3.81565208167219 Test RE 0.9336679355092856\n",
      "38 Train Loss 4.768799 Test MSE 3.7963458948376054 Test RE 0.9313028841062726\n",
      "39 Train Loss 4.7039375 Test MSE 3.74207151584491 Test RE 0.9246217429277946\n",
      "40 Train Loss 4.6131573 Test MSE 3.569222935635214 Test RE 0.9030148614585068\n",
      "41 Train Loss 4.536577 Test MSE 3.460172396415982 Test RE 0.8891129357986566\n",
      "42 Train Loss 4.3938513 Test MSE 3.36795033140775 Test RE 0.8771843996953097\n",
      "43 Train Loss 4.2174244 Test MSE 3.3320527645532634 Test RE 0.8724971063684649\n",
      "44 Train Loss 4.061517 Test MSE 3.297987138952821 Test RE 0.86802561091533\n",
      "45 Train Loss 3.903851 Test MSE 3.217762112603268 Test RE 0.8574030561294267\n",
      "46 Train Loss 3.7336879 Test MSE 3.0998986255047702 Test RE 0.8415536463003108\n",
      "47 Train Loss 3.4810276 Test MSE 3.070395906365099 Test RE 0.8375394056833093\n",
      "48 Train Loss 3.192936 Test MSE 2.959884850605494 Test RE 0.8223287386946565\n",
      "49 Train Loss 2.9954271 Test MSE 2.855510646383177 Test RE 0.8076997568394002\n",
      "50 Train Loss 2.8561287 Test MSE 2.863576189170341 Test RE 0.8088396481013762\n",
      "51 Train Loss 2.6792471 Test MSE 2.883721702500454 Test RE 0.811679791144081\n",
      "52 Train Loss 2.5960069 Test MSE 2.828949075667096 Test RE 0.8039344237194781\n",
      "53 Train Loss 2.4722836 Test MSE 2.7197253252709643 Test RE 0.7882619855500425\n",
      "54 Train Loss 2.3562887 Test MSE 2.591471988153664 Test RE 0.7694516223644645\n",
      "55 Train Loss 2.2076423 Test MSE 2.4648878357960227 Test RE 0.7504238719739719\n",
      "56 Train Loss 2.092321 Test MSE 2.4943647982809694 Test RE 0.7548976001495\n",
      "57 Train Loss 1.9751217 Test MSE 2.398107155350714 Test RE 0.7401885330213875\n",
      "58 Train Loss 1.8772608 Test MSE 2.315850697155112 Test RE 0.7273833216369351\n",
      "59 Train Loss 1.8258085 Test MSE 2.2876964645168543 Test RE 0.7229483332245301\n",
      "60 Train Loss 1.783011 Test MSE 2.226339877418165 Test RE 0.7131876153145759\n",
      "61 Train Loss 1.7313364 Test MSE 2.1989477403342095 Test RE 0.7087866260656858\n",
      "62 Train Loss 1.6900781 Test MSE 2.164793551490437 Test RE 0.7032606262527994\n",
      "63 Train Loss 1.644055 Test MSE 2.1656078125475586 Test RE 0.703392875331007\n",
      "64 Train Loss 1.6016262 Test MSE 2.189895382885377 Test RE 0.7073261987102466\n",
      "65 Train Loss 1.55197 Test MSE 2.164905775701057 Test RE 0.7032788547452486\n",
      "66 Train Loss 1.5175552 Test MSE 2.160210669221024 Test RE 0.7025158281592793\n",
      "67 Train Loss 1.4864279 Test MSE 2.1400270648328767 Test RE 0.6992262004538095\n",
      "68 Train Loss 1.4470407 Test MSE 2.0772877729087105 Test RE 0.6889003298417765\n",
      "69 Train Loss 1.4127816 Test MSE 2.0426980090829896 Test RE 0.6831406727612656\n",
      "70 Train Loss 1.3816401 Test MSE 2.0099565757994506 Test RE 0.6776436884413778\n",
      "71 Train Loss 1.3452728 Test MSE 1.9825779865379338 Test RE 0.6730126078416567\n",
      "72 Train Loss 1.3127892 Test MSE 1.9769041778165959 Test RE 0.6720488927302372\n",
      "73 Train Loss 1.2551533 Test MSE 1.8861302315547133 Test RE 0.6564382792191694\n",
      "74 Train Loss 1.2201807 Test MSE 1.8271811754867227 Test RE 0.6460986988244559\n",
      "75 Train Loss 1.1724391 Test MSE 1.7455022725303462 Test RE 0.631492605561627\n",
      "76 Train Loss 1.100064 Test MSE 1.585510472210234 Test RE 0.6018560322549676\n",
      "77 Train Loss 1.0515648 Test MSE 1.5165259721825184 Test RE 0.588617251558315\n",
      "78 Train Loss 0.99555284 Test MSE 1.4482210123313166 Test RE 0.5752087481753495\n",
      "79 Train Loss 0.941279 Test MSE 1.3700626205808912 Test RE 0.5594718878010241\n",
      "80 Train Loss 0.9090983 Test MSE 1.345409424563207 Test RE 0.554415410082825\n",
      "81 Train Loss 0.8658629 Test MSE 1.359651872727105 Test RE 0.5573421939972029\n",
      "82 Train Loss 0.8263427 Test MSE 1.2964805901279237 Test RE 0.5442407668700823\n",
      "83 Train Loss 0.79466814 Test MSE 1.1999417916074402 Test RE 0.523586149876343\n",
      "84 Train Loss 0.7654853 Test MSE 1.160796195808911 Test RE 0.5149748838916127\n",
      "85 Train Loss 0.73322767 Test MSE 1.1177470535121474 Test RE 0.5053355214991311\n",
      "86 Train Loss 0.70267653 Test MSE 1.0672788112937843 Test RE 0.49379535918827766\n",
      "87 Train Loss 0.65910697 Test MSE 1.0106598454029387 Test RE 0.4805190013381996\n",
      "88 Train Loss 0.6092757 Test MSE 0.8599221280750834 Test RE 0.44323864913417005\n",
      "89 Train Loss 0.56770855 Test MSE 0.79776838292032 Test RE 0.42691997023849976\n",
      "90 Train Loss 0.54070336 Test MSE 0.795391352605794 Test RE 0.4262834704806529\n",
      "91 Train Loss 0.50123876 Test MSE 0.7444063450505991 Test RE 0.41239471728708366\n",
      "92 Train Loss 0.4743112 Test MSE 0.7086835563831726 Test RE 0.402378009799636\n",
      "93 Train Loss 0.4261175 Test MSE 0.6121133459392551 Test RE 0.37395899551019895\n",
      "94 Train Loss 0.385596 Test MSE 0.5260949600665988 Test RE 0.3466890548229192\n",
      "95 Train Loss 0.36288595 Test MSE 0.4944043140936818 Test RE 0.33608504369376485\n",
      "96 Train Loss 0.33110413 Test MSE 0.4443462718065583 Test RE 0.3186169167221546\n",
      "97 Train Loss 0.28836438 Test MSE 0.4024733639609615 Test RE 0.3032331183665729\n",
      "98 Train Loss 0.26919755 Test MSE 0.36714120104202885 Test RE 0.28961738134841236\n",
      "99 Train Loss 0.245534 Test MSE 0.3150349802825562 Test RE 0.2682794761874959\n",
      "100 Train Loss 0.2293552 Test MSE 0.3045250509176837 Test RE 0.26376646108830504\n",
      "101 Train Loss 0.21693179 Test MSE 0.3020138604600759 Test RE 0.26267666734135214\n",
      "102 Train Loss 0.20988166 Test MSE 0.2873346531662702 Test RE 0.2562135319139247\n",
      "103 Train Loss 0.19638114 Test MSE 0.29249574469795275 Test RE 0.2585043385636899\n",
      "104 Train Loss 0.18084343 Test MSE 0.30800364805253955 Test RE 0.2652686886555743\n",
      "105 Train Loss 0.17392956 Test MSE 0.30635873957422993 Test RE 0.2645594002169567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 0.1638572 Test MSE 0.2990985741410879 Test RE 0.26140580737841096\n",
      "107 Train Loss 0.14978307 Test MSE 0.2989926320910141 Test RE 0.261359507726245\n",
      "108 Train Loss 0.14091855 Test MSE 0.28732528717830974 Test RE 0.2562093560994447\n",
      "109 Train Loss 0.13517876 Test MSE 0.2767643695098694 Test RE 0.2514566639743854\n",
      "110 Train Loss 0.13099708 Test MSE 0.2765090580911886 Test RE 0.25134065451403365\n",
      "111 Train Loss 0.12683994 Test MSE 0.27358126331497223 Test RE 0.2500064628281933\n",
      "112 Train Loss 0.124195434 Test MSE 0.2684918845250615 Test RE 0.24767013556906073\n",
      "113 Train Loss 0.11545193 Test MSE 0.25621187261674994 Test RE 0.24194000518294875\n",
      "114 Train Loss 0.11183353 Test MSE 0.24583404532962863 Test RE 0.23698948333959527\n",
      "115 Train Loss 0.107895575 Test MSE 0.23755859996189405 Test RE 0.23296648057369052\n",
      "116 Train Loss 0.10439199 Test MSE 0.23994015711488895 Test RE 0.23413132868111594\n",
      "117 Train Loss 0.100422844 Test MSE 0.25202656593913597 Test RE 0.2399557831111489\n",
      "118 Train Loss 0.09709349 Test MSE 0.24916288835769473 Test RE 0.23858862736465145\n",
      "119 Train Loss 0.095106676 Test MSE 0.24466084015911985 Test RE 0.23642330910750184\n",
      "120 Train Loss 0.09028646 Test MSE 0.2399992571087477 Test RE 0.23416016151238503\n",
      "121 Train Loss 0.086020246 Test MSE 0.23754596689334154 Test RE 0.23296028605863534\n",
      "122 Train Loss 0.08321303 Test MSE 0.22947055846595066 Test RE 0.2289662896654296\n",
      "123 Train Loss 0.081627324 Test MSE 0.22477029231107082 Test RE 0.22660918845056266\n",
      "124 Train Loss 0.07897442 Test MSE 0.2181713440370764 Test RE 0.2232579403276861\n",
      "125 Train Loss 0.07802884 Test MSE 0.215397591117921 Test RE 0.22183418953882103\n",
      "126 Train Loss 0.07672661 Test MSE 0.21606007793349083 Test RE 0.2221750693915938\n",
      "127 Train Loss 0.0741339 Test MSE 0.21453333168098923 Test RE 0.22138869942503017\n",
      "128 Train Loss 0.06978139 Test MSE 0.21014698735502219 Test RE 0.21911375649071876\n",
      "129 Train Loss 0.066217154 Test MSE 0.19669206943242454 Test RE 0.2119832201715128\n",
      "130 Train Loss 0.06385705 Test MSE 0.1909946077654711 Test RE 0.2088904634358128\n",
      "131 Train Loss 0.062790625 Test MSE 0.19380683075975386 Test RE 0.21042270547443462\n",
      "132 Train Loss 0.061510988 Test MSE 0.19103618012985907 Test RE 0.20891319600943623\n",
      "133 Train Loss 0.060426738 Test MSE 0.1839812897361272 Test RE 0.2050193677014243\n",
      "134 Train Loss 0.058715064 Test MSE 0.1766409389266193 Test RE 0.20088788320530773\n",
      "135 Train Loss 0.056998722 Test MSE 0.1661070280714844 Test RE 0.19480588128703075\n",
      "136 Train Loss 0.05505375 Test MSE 0.1533532861645326 Test RE 0.18717791429906758\n",
      "137 Train Loss 0.05279817 Test MSE 0.15468463038100236 Test RE 0.18798865568654713\n",
      "138 Train Loss 0.051296707 Test MSE 0.15726190425425932 Test RE 0.18954827015892056\n",
      "139 Train Loss 0.050241403 Test MSE 0.15226809973676758 Test RE 0.18651446730616122\n",
      "140 Train Loss 0.04947444 Test MSE 0.15019792898805967 Test RE 0.18524224363698238\n",
      "141 Train Loss 0.04827161 Test MSE 0.14666318154628333 Test RE 0.18304952708720493\n",
      "142 Train Loss 0.04595664 Test MSE 0.13622816405468066 Test RE 0.1764174385355026\n",
      "143 Train Loss 0.043742202 Test MSE 0.1288140260810773 Test RE 0.17154957143360997\n",
      "144 Train Loss 0.04228394 Test MSE 0.12552778233521056 Test RE 0.16934718754729874\n",
      "145 Train Loss 0.041213777 Test MSE 0.11961790136781902 Test RE 0.16531267353800808\n",
      "146 Train Loss 0.03989081 Test MSE 0.11597214969893761 Test RE 0.16277395429985847\n",
      "147 Train Loss 0.03917492 Test MSE 0.11555501047455496 Test RE 0.16248095047105218\n",
      "148 Train Loss 0.038471237 Test MSE 0.11112472910271247 Test RE 0.15933581932937707\n",
      "149 Train Loss 0.037883483 Test MSE 0.10536358736616258 Test RE 0.15515055544068415\n",
      "Training time: 228.86\n",
      "3\n",
      "KG_rowdy_tune64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 63.024185 Test MSE 5.729206803587934 Test RE 1.1440771447336162\n",
      "1 Train Loss 49.53596 Test MSE 8.315132776301951 Test RE 1.378296503739396\n",
      "2 Train Loss 39.24128 Test MSE 8.974640251494142 Test RE 1.4319128442782896\n",
      "3 Train Loss 34.785458 Test MSE 8.403402795173625 Test RE 1.3855929044743158\n",
      "4 Train Loss 31.340528 Test MSE 8.661906390432373 Test RE 1.406743131194574\n",
      "5 Train Loss 29.809155 Test MSE 8.722739341832574 Test RE 1.4116742979834302\n",
      "6 Train Loss 28.114195 Test MSE 8.99925985929395 Test RE 1.4338755407085098\n",
      "7 Train Loss 26.607609 Test MSE 8.998396732973095 Test RE 1.433806776975938\n",
      "8 Train Loss 25.71762 Test MSE 8.826242892489805 Test RE 1.4200250239463967\n",
      "9 Train Loss 24.16983 Test MSE 8.781702881979577 Test RE 1.4164375448520812\n",
      "10 Train Loss 23.165764 Test MSE 8.787191373750238 Test RE 1.4168801065969097\n",
      "11 Train Loss 21.979282 Test MSE 8.830751384428853 Test RE 1.4203876558212836\n",
      "12 Train Loss 20.985224 Test MSE 8.62101672979812 Test RE 1.4034188460151138\n",
      "13 Train Loss 20.072424 Test MSE 8.501404910131733 Test RE 1.3936490113233846\n",
      "14 Train Loss 19.083292 Test MSE 8.403467715756493 Test RE 1.3855982566707674\n",
      "15 Train Loss 17.99331 Test MSE 8.437581355550595 Test RE 1.3884078067262522\n",
      "16 Train Loss 17.028318 Test MSE 8.51227276837185 Test RE 1.3945395195769241\n",
      "17 Train Loss 15.985775 Test MSE 8.703138949024165 Test RE 1.410087357760556\n",
      "18 Train Loss 14.843632 Test MSE 8.67968040107793 Test RE 1.4081856920343572\n",
      "19 Train Loss 13.967934 Test MSE 8.530364210322164 Test RE 1.3960206657131327\n",
      "20 Train Loss 12.470068 Test MSE 8.511867610069636 Test RE 1.394506331261486\n",
      "21 Train Loss 10.7984085 Test MSE 8.36426105325492 Test RE 1.3823622000387097\n",
      "22 Train Loss 9.95015 Test MSE 8.090847097016168 Test RE 1.3595809075366334\n",
      "23 Train Loss 9.132595 Test MSE 8.037802638082763 Test RE 1.3551167997901463\n",
      "24 Train Loss 8.429298 Test MSE 7.959688787858428 Test RE 1.348516001548405\n",
      "25 Train Loss 7.7816925 Test MSE 8.136424757354574 Test RE 1.3634049504941934\n",
      "26 Train Loss 7.3662605 Test MSE 7.9777138486915415 Test RE 1.350042024616513\n",
      "27 Train Loss 6.828679 Test MSE 7.846654373616906 Test RE 1.338906722093998\n",
      "28 Train Loss 6.1923666 Test MSE 7.5396157874734175 Test RE 1.312449699741243\n",
      "29 Train Loss 5.398436 Test MSE 7.257377583664812 Test RE 1.2876502596521195\n",
      "30 Train Loss 5.124432 Test MSE 7.220143990368217 Test RE 1.2843429012352148\n",
      "31 Train Loss 4.5851593 Test MSE 6.979396352082786 Test RE 1.262748878125997\n",
      "32 Train Loss 4.244869 Test MSE 6.963340633306541 Test RE 1.2612955995555974\n",
      "33 Train Loss 3.9294138 Test MSE 6.873728854967544 Test RE 1.253153463141167\n",
      "34 Train Loss 3.6956408 Test MSE 6.87445457340882 Test RE 1.2532196144684993\n",
      "35 Train Loss 3.5462549 Test MSE 6.896166452923451 Test RE 1.2551971024580995\n",
      "36 Train Loss 3.468142 Test MSE 6.914789169072564 Test RE 1.2568907550067063\n",
      "37 Train Loss 3.3943515 Test MSE 6.791435006022576 Test RE 1.2456293557693359\n",
      "38 Train Loss 3.3138065 Test MSE 6.817405685946436 Test RE 1.248008747866894\n",
      "39 Train Loss 3.238771 Test MSE 6.843457875385968 Test RE 1.2503910586169629\n",
      "40 Train Loss 3.1547318 Test MSE 6.758141804503302 Test RE 1.2425724216159095\n",
      "41 Train Loss 3.0383904 Test MSE 6.834913212131799 Test RE 1.2496102028096008\n",
      "42 Train Loss 2.9267788 Test MSE 6.762081602447111 Test RE 1.242934560436044\n",
      "43 Train Loss 2.8422766 Test MSE 6.639853517282978 Test RE 1.2316499952245592\n",
      "44 Train Loss 2.7420099 Test MSE 6.723968113815506 Test RE 1.23942680084627\n",
      "45 Train Loss 2.6423655 Test MSE 6.729582828948289 Test RE 1.23994417214799\n",
      "46 Train Loss 2.5695467 Test MSE 6.67859233449479 Test RE 1.2352376703011743\n",
      "47 Train Loss 2.505803 Test MSE 6.6397142972444545 Test RE 1.2316370829473406\n",
      "48 Train Loss 2.456625 Test MSE 6.583849399898933 Test RE 1.226444794860971\n",
      "49 Train Loss 2.3892708 Test MSE 6.517950611753389 Test RE 1.2202915190657395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Train Loss 2.3421578 Test MSE 6.506548073296015 Test RE 1.219223659501867\n",
      "51 Train Loss 2.2550836 Test MSE 6.407592445750402 Test RE 1.209916782091543\n",
      "52 Train Loss 2.194594 Test MSE 6.306155738004576 Test RE 1.2003016587252204\n",
      "53 Train Loss 2.1334538 Test MSE 6.231373827586071 Test RE 1.193163510459\n",
      "54 Train Loss 2.1058927 Test MSE 6.224816867134182 Test RE 1.19253559233643\n",
      "55 Train Loss 2.0633216 Test MSE 6.197580593886908 Test RE 1.1899238020900815\n",
      "56 Train Loss 2.0052116 Test MSE 6.276716336535005 Test RE 1.1974966614410874\n",
      "57 Train Loss 1.95078 Test MSE 6.322943409316896 Test RE 1.2018982635212285\n",
      "58 Train Loss 1.9173741 Test MSE 6.329777725524424 Test RE 1.202547639439191\n",
      "59 Train Loss 1.8679098 Test MSE 6.321426242197424 Test RE 1.2017540593266147\n",
      "60 Train Loss 1.829922 Test MSE 6.295202706206245 Test RE 1.1992588161117288\n",
      "61 Train Loss 1.7905593 Test MSE 6.2538341880262935 Test RE 1.1953118952456483\n",
      "62 Train Loss 1.7481372 Test MSE 6.200720834394083 Test RE 1.190225224044858\n",
      "63 Train Loss 1.7169417 Test MSE 6.269136801324361 Test RE 1.1967734162454786\n",
      "64 Train Loss 1.7032318 Test MSE 6.281401699107785 Test RE 1.1979435240262712\n",
      "65 Train Loss 1.6841621 Test MSE 6.199820303803157 Test RE 1.1901387927111942\n",
      "66 Train Loss 1.6622815 Test MSE 6.200902207566594 Test RE 1.190242631161875\n",
      "67 Train Loss 1.6467221 Test MSE 6.237940334788895 Test RE 1.193792011814905\n",
      "68 Train Loss 1.6351604 Test MSE 6.224729959165771 Test RE 1.1925272674965555\n",
      "69 Train Loss 1.6184636 Test MSE 6.197300366567975 Test RE 1.1898969002272408\n",
      "70 Train Loss 1.6063405 Test MSE 6.193505964681593 Test RE 1.1895325772095138\n",
      "71 Train Loss 1.5885608 Test MSE 6.180789809949646 Test RE 1.188310809402848\n",
      "72 Train Loss 1.583475 Test MSE 6.186352066910979 Test RE 1.1888453853943348\n",
      "73 Train Loss 1.5731333 Test MSE 6.167803527729404 Test RE 1.1870617899138143\n",
      "74 Train Loss 1.5633299 Test MSE 6.152361723902139 Test RE 1.1855748859744921\n",
      "75 Train Loss 1.5531454 Test MSE 6.176315999039902 Test RE 1.187880666946224\n",
      "76 Train Loss 1.5387253 Test MSE 6.159775907620955 Test RE 1.1862890363924372\n",
      "77 Train Loss 1.5262065 Test MSE 6.112454190710198 Test RE 1.1817234914942107\n",
      "78 Train Loss 1.5139855 Test MSE 6.057742572375061 Test RE 1.1764228928540696\n",
      "79 Train Loss 1.4975681 Test MSE 6.053825716609177 Test RE 1.1760425016584124\n",
      "80 Train Loss 1.4856248 Test MSE 6.045592492972394 Test RE 1.1752425186628779\n",
      "81 Train Loss 1.4729593 Test MSE 6.044198720496645 Test RE 1.1751070385510103\n",
      "82 Train Loss 1.4561591 Test MSE 6.046708024362413 Test RE 1.1753509414064123\n",
      "83 Train Loss 1.4408685 Test MSE 6.000814097019074 Test RE 1.1708820458190707\n",
      "84 Train Loss 1.4323575 Test MSE 5.998121342003617 Test RE 1.1706193104442455\n",
      "85 Train Loss 1.423975 Test MSE 5.998279962721272 Test RE 1.1706347888946582\n",
      "86 Train Loss 1.4101808 Test MSE 6.009584749794936 Test RE 1.1717374006141907\n",
      "87 Train Loss 1.400067 Test MSE 6.019238660830249 Test RE 1.1726781735499414\n",
      "88 Train Loss 1.392963 Test MSE 6.010451853565179 Test RE 1.1718219306868374\n",
      "89 Train Loss 1.3823162 Test MSE 5.978528601611276 Test RE 1.168705844602916\n",
      "90 Train Loss 1.3761804 Test MSE 5.987595054099245 Test RE 1.1695916814484664\n",
      "91 Train Loss 1.3698587 Test MSE 5.973172576092957 Test RE 1.1681822190309332\n",
      "92 Train Loss 1.3635207 Test MSE 5.936744098727471 Test RE 1.1646145855758423\n",
      "93 Train Loss 1.3570658 Test MSE 5.928094851555188 Test RE 1.1637659123996615\n",
      "94 Train Loss 1.3487772 Test MSE 5.940837057823354 Test RE 1.1650159755033198\n",
      "95 Train Loss 1.3405541 Test MSE 5.929177335821447 Test RE 1.1638721607659461\n",
      "96 Train Loss 1.3299803 Test MSE 5.899480810577799 Test RE 1.1609538515927575\n",
      "97 Train Loss 1.3213422 Test MSE 5.891087432777894 Test RE 1.1601276947702421\n",
      "98 Train Loss 1.3088634 Test MSE 5.886521069420655 Test RE 1.1596779822485712\n",
      "99 Train Loss 1.2980493 Test MSE 5.873078241651643 Test RE 1.1583530688081447\n",
      "100 Train Loss 1.289515 Test MSE 5.825707630669382 Test RE 1.1536721345378205\n",
      "101 Train Loss 1.2830188 Test MSE 5.8224368821030845 Test RE 1.1533482338640766\n",
      "102 Train Loss 1.2748066 Test MSE 5.8529601161854785 Test RE 1.1563674079302821\n",
      "103 Train Loss 1.2624851 Test MSE 5.847053913102031 Test RE 1.1557838173665425\n",
      "104 Train Loss 1.2556723 Test MSE 5.847280613241515 Test RE 1.155806222993107\n",
      "105 Train Loss 1.2469351 Test MSE 5.875780605523755 Test RE 1.1586195331182696\n",
      "106 Train Loss 1.2406371 Test MSE 5.8723362025063786 Test RE 1.1582798899369138\n",
      "107 Train Loss 1.2336304 Test MSE 5.86348849756169 Test RE 1.1574069850644741\n",
      "108 Train Loss 1.2268492 Test MSE 5.834417233507682 Test RE 1.154534199201538\n",
      "109 Train Loss 1.2220578 Test MSE 5.8203268086202655 Test RE 1.1531392260117836\n",
      "110 Train Loss 1.2191656 Test MSE 5.825119655039041 Test RE 1.1536139142957496\n",
      "111 Train Loss 1.2166677 Test MSE 5.819214875252995 Test RE 1.1530290710952245\n",
      "112 Train Loss 1.2133632 Test MSE 5.827049062070569 Test RE 1.1538049495579055\n",
      "113 Train Loss 1.2061577 Test MSE 5.8365155880788615 Test RE 1.1547417952845755\n",
      "114 Train Loss 1.1988392 Test MSE 5.828568137213815 Test RE 1.153955334614278\n",
      "115 Train Loss 1.193229 Test MSE 5.834150348356062 Test RE 1.1545077928316945\n",
      "116 Train Loss 1.18488 Test MSE 5.823703885926517 Test RE 1.1534737154419061\n",
      "117 Train Loss 1.1789377 Test MSE 5.815181517852196 Test RE 1.15262941370525\n",
      "118 Train Loss 1.1739866 Test MSE 5.835420092583598 Test RE 1.1546334195095767\n",
      "119 Train Loss 1.1685481 Test MSE 5.831465939318093 Test RE 1.154242156230983\n",
      "120 Train Loss 1.1637905 Test MSE 5.8114430599861695 Test RE 1.1522588535380227\n",
      "121 Train Loss 1.1600574 Test MSE 5.809495398545849 Test RE 1.1520657519125581\n",
      "122 Train Loss 1.1556925 Test MSE 5.801336248091827 Test RE 1.1512564578264244\n",
      "123 Train Loss 1.1483165 Test MSE 5.801340920389138 Test RE 1.151256921427493\n",
      "124 Train Loss 1.1377207 Test MSE 5.811640862231804 Test RE 1.1522784629058729\n",
      "125 Train Loss 1.1332557 Test MSE 5.798344585112799 Test RE 1.1509595766150558\n",
      "126 Train Loss 1.1276214 Test MSE 5.789769915477789 Test RE 1.150108234535713\n",
      "127 Train Loss 1.1208208 Test MSE 5.789588836387701 Test RE 1.1500902491767042\n",
      "128 Train Loss 1.1147077 Test MSE 5.798147974215151 Test RE 1.1509400630185027\n",
      "129 Train Loss 1.109837 Test MSE 5.7981660748202035 Test RE 1.1509418595141554\n",
      "130 Train Loss 1.1079931 Test MSE 5.794069354304495 Test RE 1.1505351860739406\n",
      "131 Train Loss 1.1039119 Test MSE 5.799689035732599 Test RE 1.1510930042343714\n",
      "132 Train Loss 1.0992645 Test MSE 5.809291851957732 Test RE 1.15204556934152\n",
      "133 Train Loss 1.0952133 Test MSE 5.808561228987091 Test RE 1.151973121834631\n",
      "134 Train Loss 1.0928627 Test MSE 5.813781672799158 Test RE 1.152490673436258\n",
      "135 Train Loss 1.0887296 Test MSE 5.814796082283407 Test RE 1.1525912144044959\n",
      "136 Train Loss 1.0831108 Test MSE 5.814349087224403 Test RE 1.1525469125517611\n",
      "137 Train Loss 1.0792644 Test MSE 5.832569891686641 Test RE 1.154351405609725\n",
      "138 Train Loss 1.0767022 Test MSE 5.841177810828872 Test RE 1.1552029084860636\n",
      "139 Train Loss 1.0742917 Test MSE 5.840210003319868 Test RE 1.155107203441686\n",
      "140 Train Loss 1.072185 Test MSE 5.843167880022776 Test RE 1.155399678557013\n",
      "141 Train Loss 1.0705998 Test MSE 5.8469269053301325 Test RE 1.1557712645214022\n",
      "142 Train Loss 1.0683596 Test MSE 5.852490261225833 Test RE 1.1563209924537123\n",
      "143 Train Loss 1.0659232 Test MSE 5.852255163761059 Test RE 1.1562977672237862\n",
      "144 Train Loss 1.0605898 Test MSE 5.858501643684019 Test RE 1.156914697302796\n",
      "145 Train Loss 1.0570257 Test MSE 5.872195449786597 Test RE 1.1582660085772576\n",
      "146 Train Loss 1.053665 Test MSE 5.870608356377504 Test RE 1.158109474229106\n",
      "147 Train Loss 1.0508091 Test MSE 5.886862022049057 Test RE 1.159711566561465\n",
      "148 Train Loss 1.0483572 Test MSE 5.901463169717661 Test RE 1.1611488886012749\n",
      "149 Train Loss 1.0448712 Test MSE 5.892008374774238 Test RE 1.1602183714555803\n",
      "Training time: 228.17\n",
      "4\n",
      "KG_rowdy_tune64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 59.86343 Test MSE 8.079030302059666 Test RE 1.3585877013235055\n",
      "1 Train Loss 50.158173 Test MSE 6.746103037556922 Test RE 1.2414651862192574\n",
      "2 Train Loss 39.544754 Test MSE 8.245954426934485 Test RE 1.3725511101827494\n",
      "3 Train Loss 31.277134 Test MSE 7.611666733248474 Test RE 1.3187058803504623\n",
      "4 Train Loss 26.166157 Test MSE 6.971791836024383 Test RE 1.2620607662371661\n",
      "5 Train Loss 22.826797 Test MSE 6.716517968994295 Test RE 1.238739969185857\n",
      "6 Train Loss 19.797195 Test MSE 6.785898904716929 Test RE 1.2451215590967484\n",
      "7 Train Loss 17.10366 Test MSE 6.711458479261021 Test RE 1.2382733157114025\n",
      "8 Train Loss 14.947581 Test MSE 6.517762633254571 Test RE 1.2202739222599748\n",
      "9 Train Loss 13.357607 Test MSE 6.344180970437595 Test RE 1.203915044976826\n",
      "10 Train Loss 10.84656 Test MSE 5.753810590433317 Test RE 1.14653110347258\n",
      "11 Train Loss 10.066097 Test MSE 5.651471000025229 Test RE 1.1362890249332087\n",
      "12 Train Loss 9.419121 Test MSE 5.753957094715301 Test RE 1.1465456999425394\n",
      "13 Train Loss 8.964521 Test MSE 5.797389411471061 Test RE 1.1508647727004977\n",
      "14 Train Loss 8.65096 Test MSE 5.794477677533809 Test RE 1.1505757259723564\n",
      "15 Train Loss 8.225728 Test MSE 5.746561047079365 Test RE 1.145808586925191\n",
      "16 Train Loss 7.9394836 Test MSE 5.665088628651167 Test RE 1.1376571866029157\n",
      "17 Train Loss 7.5448494 Test MSE 5.514930486686844 Test RE 1.1224786302061767\n",
      "18 Train Loss 7.324768 Test MSE 5.512980051820771 Test RE 1.122280122258743\n",
      "19 Train Loss 7.0542097 Test MSE 5.515889573279729 Test RE 1.1225762295690829\n",
      "20 Train Loss 6.8129787 Test MSE 5.435360625664408 Test RE 1.1143516033305363\n",
      "21 Train Loss 6.642949 Test MSE 5.351717549006116 Test RE 1.105744155232951\n",
      "22 Train Loss 6.471406 Test MSE 5.255188748207208 Test RE 1.09572663788081\n",
      "23 Train Loss 6.249997 Test MSE 5.170280333014534 Test RE 1.086838728950738\n",
      "24 Train Loss 6.0902653 Test MSE 5.120826783243457 Test RE 1.081628452855151\n",
      "25 Train Loss 6.009103 Test MSE 5.121642777141256 Test RE 1.0817146271290656\n",
      "26 Train Loss 5.7464437 Test MSE 4.939848162544521 Test RE 1.0623432439926181\n",
      "27 Train Loss 5.385524 Test MSE 4.5861885573010674 Test RE 1.0236088061548996\n",
      "28 Train Loss 4.8830748 Test MSE 4.251838697430098 Test RE 0.9855903676818131\n",
      "29 Train Loss 4.5005584 Test MSE 4.101644187626949 Test RE 0.9680260663831279\n",
      "30 Train Loss 4.3005457 Test MSE 4.113921510509027 Test RE 0.9694737648841852\n",
      "31 Train Loss 4.112166 Test MSE 4.136999697649021 Test RE 0.9721892283113575\n",
      "32 Train Loss 3.8417234 Test MSE 4.013482622280539 Test RE 0.9575660802887689\n",
      "33 Train Loss 3.603027 Test MSE 3.7696338235452975 Test RE 0.9280206563190508\n",
      "34 Train Loss 3.4352982 Test MSE 3.6913636812413406 Test RE 0.9183357212566122\n",
      "35 Train Loss 3.2544513 Test MSE 3.6657899105719216 Test RE 0.9151490770733168\n",
      "36 Train Loss 3.0909598 Test MSE 3.4196440035140387 Test RE 0.8838905866385948\n",
      "37 Train Loss 2.9357986 Test MSE 3.237983450000402 Test RE 0.8600929197910121\n",
      "38 Train Loss 2.8298955 Test MSE 3.1663503947994642 Test RE 0.8505259071555473\n",
      "39 Train Loss 2.7260742 Test MSE 2.9300288108738006 Test RE 0.8181708563779018\n",
      "40 Train Loss 2.6035779 Test MSE 2.81604938221283 Test RE 0.8020994036348102\n",
      "41 Train Loss 2.4927547 Test MSE 2.811720753522253 Test RE 0.8014827017823527\n",
      "42 Train Loss 2.3573937 Test MSE 2.6997811133056815 Test RE 0.7853664372711872\n",
      "43 Train Loss 2.2328176 Test MSE 2.581240060241157 Test RE 0.7679311042617006\n",
      "44 Train Loss 2.143149 Test MSE 2.4996336675588995 Test RE 0.7556944680709677\n",
      "45 Train Loss 2.0246446 Test MSE 2.4319998505616742 Test RE 0.7454007617482585\n",
      "46 Train Loss 1.9240396 Test MSE 2.356274574188014 Test RE 0.7337042060866867\n",
      "47 Train Loss 1.8562502 Test MSE 2.2785509680793052 Test RE 0.721501825208807\n",
      "48 Train Loss 1.8099039 Test MSE 2.245590964156558 Test RE 0.7162644331189543\n",
      "49 Train Loss 1.766752 Test MSE 2.2107580700424605 Test RE 0.710687488400762\n",
      "50 Train Loss 1.7013347 Test MSE 2.104743607782627 Test RE 0.6934380364538905\n",
      "51 Train Loss 1.6440443 Test MSE 2.015243636261539 Test RE 0.6785343520123922\n",
      "52 Train Loss 1.610557 Test MSE 2.0112956826063946 Test RE 0.6778693863980216\n",
      "53 Train Loss 1.5771083 Test MSE 1.967980186854329 Test RE 0.6705303209560532\n",
      "54 Train Loss 1.514864 Test MSE 1.877668091727879 Test RE 0.6549640657938818\n",
      "55 Train Loss 1.4903651 Test MSE 1.8766061358506256 Test RE 0.6547788250383964\n",
      "56 Train Loss 1.4570569 Test MSE 1.8153400686562746 Test RE 0.6440017642097039\n",
      "57 Train Loss 1.4226983 Test MSE 1.7800656223020739 Test RE 0.6377141694497475\n",
      "58 Train Loss 1.4015194 Test MSE 1.788035815563481 Test RE 0.6391402484653181\n",
      "59 Train Loss 1.3679329 Test MSE 1.7281529022752873 Test RE 0.6283464167671863\n",
      "60 Train Loss 1.3342893 Test MSE 1.6785545781752707 Test RE 0.6192639430376555\n",
      "61 Train Loss 1.3084985 Test MSE 1.6610702527261187 Test RE 0.6160302812733929\n",
      "62 Train Loss 1.274293 Test MSE 1.5744320763139654 Test RE 0.5997496799255523\n",
      "63 Train Loss 1.208531 Test MSE 1.3201228808844834 Test RE 0.5491806661259838\n",
      "64 Train Loss 1.1324977 Test MSE 1.2014703563868432 Test RE 0.5239195329768985\n",
      "65 Train Loss 1.041077 Test MSE 1.1308970911471639 Test RE 0.5082994078626436\n",
      "66 Train Loss 0.9864052 Test MSE 1.1260963643865622 Test RE 0.5072193795353818\n",
      "67 Train Loss 0.93472666 Test MSE 1.0884290206697158 Test RE 0.49866411518090425\n",
      "68 Train Loss 0.8948258 Test MSE 1.0432469656083525 Test RE 0.48820432822196913\n",
      "69 Train Loss 0.8527943 Test MSE 1.0140796242291956 Test RE 0.48133128302473205\n",
      "70 Train Loss 0.80197734 Test MSE 0.948645261501122 Test RE 0.4655431932318459\n",
      "71 Train Loss 0.75144345 Test MSE 0.8765521143742396 Test RE 0.4475040098050607\n",
      "72 Train Loss 0.7116929 Test MSE 0.8504221063556036 Test RE 0.440783501731376\n",
      "73 Train Loss 0.68623525 Test MSE 0.7993969306609526 Test RE 0.42735550084328067\n",
      "74 Train Loss 0.65531516 Test MSE 0.7407703605795548 Test RE 0.4113863323653348\n",
      "75 Train Loss 0.6139951 Test MSE 0.6691860152372004 Test RE 0.391004259480438\n",
      "76 Train Loss 0.5602411 Test MSE 0.5457235899731321 Test RE 0.35309732219412954\n",
      "77 Train Loss 0.52577513 Test MSE 0.4998840003784671 Test RE 0.3379423957855296\n",
      "78 Train Loss 0.48618746 Test MSE 0.5147786904756643 Test RE 0.3429401556751938\n",
      "79 Train Loss 0.45808282 Test MSE 0.5158304313203881 Test RE 0.3432903062698115\n",
      "80 Train Loss 0.43698686 Test MSE 0.48553521163565455 Test RE 0.333056892580765\n",
      "81 Train Loss 0.4098491 Test MSE 0.42518774124437353 Test RE 0.311672459133034\n",
      "82 Train Loss 0.36990404 Test MSE 0.3561423025860233 Test RE 0.2852461828354108\n",
      "83 Train Loss 0.34161982 Test MSE 0.3323731583712904 Test RE 0.2755630812735054\n",
      "84 Train Loss 0.3145103 Test MSE 0.2952631936536101 Test RE 0.2597243791099325\n",
      "85 Train Loss 0.2956286 Test MSE 0.2541520141714295 Test RE 0.240965483839878\n",
      "86 Train Loss 0.25916153 Test MSE 0.21078804466202733 Test RE 0.21944770730565424\n",
      "87 Train Loss 0.24062593 Test MSE 0.21396139073401457 Test RE 0.22109339387406107\n",
      "88 Train Loss 0.22952974 Test MSE 0.1892003292787036 Test RE 0.20790694850587293\n",
      "89 Train Loss 0.21887101 Test MSE 0.16305781469863212 Test RE 0.19300958151301995\n",
      "90 Train Loss 0.20556298 Test MSE 0.15610416381007186 Test RE 0.18884926718358444\n",
      "91 Train Loss 0.19775562 Test MSE 0.14841344452001062 Test RE 0.18413853459398485\n",
      "92 Train Loss 0.189331 Test MSE 0.13176948051852094 Test RE 0.17350639131595308\n",
      "93 Train Loss 0.17465143 Test MSE 0.1092496139389842 Test RE 0.15798578620813192\n",
      "94 Train Loss 0.16189 Test MSE 0.08958243250022924 Test RE 0.1430604167247747\n",
      "95 Train Loss 0.1522426 Test MSE 0.08945509664064673 Test RE 0.14295870482258374\n",
      "96 Train Loss 0.13807191 Test MSE 0.0885845774307962 Test RE 0.14226141339802414\n",
      "97 Train Loss 0.12743509 Test MSE 0.0751944991690744 Test RE 0.1310693349514727\n",
      "98 Train Loss 0.114892505 Test MSE 0.07197532502381139 Test RE 0.12823302213767535\n",
      "99 Train Loss 0.10839109 Test MSE 0.06684087255828837 Test RE 0.12357457218427753\n",
      "100 Train Loss 0.09891762 Test MSE 0.058402096295968986 Test RE 0.11551071664832459\n",
      "101 Train Loss 0.094109364 Test MSE 0.05488689065655326 Test RE 0.11198049285973721\n",
      "102 Train Loss 0.08883575 Test MSE 0.05034179439721337 Test RE 0.10724385235547201\n",
      "103 Train Loss 0.08134917 Test MSE 0.049767046529928374 Test RE 0.10662989811441088\n",
      "104 Train Loss 0.07236779 Test MSE 0.04142523469675409 Test RE 0.09728380512118795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 Train Loss 0.068535715 Test MSE 0.034684718232006764 Test RE 0.08901785919784519\n",
      "106 Train Loss 0.06382999 Test MSE 0.03422480779479069 Test RE 0.08842571276849255\n",
      "107 Train Loss 0.05746325 Test MSE 0.029509288623330143 Test RE 0.08210836993748101\n",
      "108 Train Loss 0.05428733 Test MSE 0.024959427687349517 Test RE 0.0755136341847536\n",
      "109 Train Loss 0.052130964 Test MSE 0.02193102179874769 Test RE 0.07078438996390295\n",
      "110 Train Loss 0.050518084 Test MSE 0.01757090071753673 Test RE 0.06335852710945315\n",
      "111 Train Loss 0.049665745 Test MSE 0.01572376301774893 Test RE 0.05993579981005207\n",
      "112 Train Loss 0.048021067 Test MSE 0.013882019441461241 Test RE 0.05631633509555708\n",
      "113 Train Loss 0.045991965 Test MSE 0.012965605646228591 Test RE 0.05442575525858039\n",
      "114 Train Loss 0.044499222 Test MSE 0.01187534163909232 Test RE 0.0520872125281042\n",
      "115 Train Loss 0.042780127 Test MSE 0.010466278941289611 Test RE 0.04889947684826972\n",
      "116 Train Loss 0.041302674 Test MSE 0.010385084838787155 Test RE 0.04870943417162095\n",
      "117 Train Loss 0.040311873 Test MSE 0.010427887441487657 Test RE 0.048809710036654276\n",
      "118 Train Loss 0.03880311 Test MSE 0.00899533578785155 Test RE 0.04533323902614866\n",
      "119 Train Loss 0.036794577 Test MSE 0.007160457934452053 Test RE 0.040446268367555556\n",
      "120 Train Loss 0.034505166 Test MSE 0.0075740349606344915 Test RE 0.04159792935170267\n",
      "121 Train Loss 0.033009198 Test MSE 0.008732836683387606 Test RE 0.0446668914726934\n",
      "122 Train Loss 0.031870227 Test MSE 0.008623314509350107 Test RE 0.04438591460425952\n",
      "123 Train Loss 0.030557532 Test MSE 0.007953739072574512 Test RE 0.04262787956093533\n",
      "124 Train Loss 0.029635668 Test MSE 0.008475164778953827 Test RE 0.04400298472022176\n",
      "125 Train Loss 0.02857612 Test MSE 0.00907320282484807 Test RE 0.045529027087353936\n",
      "126 Train Loss 0.027594386 Test MSE 0.008296538613514034 Test RE 0.04353680249637499\n",
      "127 Train Loss 0.026756639 Test MSE 0.007791340266673923 Test RE 0.04219044887788968\n",
      "128 Train Loss 0.025636392 Test MSE 0.007772872022614879 Test RE 0.04214041603606619\n",
      "129 Train Loss 0.024920097 Test MSE 0.007795081965859575 Test RE 0.04220057839439641\n",
      "130 Train Loss 0.024397405 Test MSE 0.007471234697503687 Test RE 0.04131466636161032\n",
      "131 Train Loss 0.023568993 Test MSE 0.006868165804612801 Test RE 0.03961215281061868\n",
      "132 Train Loss 0.022216987 Test MSE 0.006973158136988943 Test RE 0.03991377615646855\n",
      "133 Train Loss 0.020815287 Test MSE 0.007045009773082522 Test RE 0.0401188855363059\n",
      "134 Train Loss 0.019981777 Test MSE 0.0066099448812558005 Test RE 0.0388603742926573\n",
      "135 Train Loss 0.019322945 Test MSE 0.006996114366829007 Test RE 0.03997942194639945\n",
      "136 Train Loss 0.019010222 Test MSE 0.0075598268605639105 Test RE 0.0415588943470566\n",
      "137 Train Loss 0.018711284 Test MSE 0.007575276679737149 Test RE 0.04160133908158238\n",
      "138 Train Loss 0.018248543 Test MSE 0.007066328398329056 Test RE 0.040179540770213656\n",
      "139 Train Loss 0.017712403 Test MSE 0.006924531599437435 Test RE 0.03977436556560852\n",
      "140 Train Loss 0.017250339 Test MSE 0.0064020026968285735 Test RE 0.03824423574942615\n",
      "141 Train Loss 0.016682241 Test MSE 0.006118335045113229 Test RE 0.03738735038415325\n",
      "142 Train Loss 0.01610411 Test MSE 0.006720876971211647 Test RE 0.03918510664199502\n",
      "143 Train Loss 0.015769875 Test MSE 0.006644343551369533 Test RE 0.03896135929319509\n",
      "144 Train Loss 0.01531301 Test MSE 0.006500690089320409 Test RE 0.03853787745245394\n",
      "145 Train Loss 0.0150586385 Test MSE 0.006237517519982857 Test RE 0.03774973867299611\n",
      "146 Train Loss 0.014919783 Test MSE 0.006022649066675495 Test RE 0.03709384383844616\n",
      "147 Train Loss 0.014458739 Test MSE 0.006383429865582161 Test RE 0.038188720336200396\n",
      "148 Train Loss 0.014024702 Test MSE 0.006454839095793142 Test RE 0.03840172830864298\n",
      "149 Train Loss 0.013678917 Test MSE 0.0062325763843739425 Test RE 0.03773478372241471\n",
      "Training time: 229.07\n",
      "5\n",
      "KG_rowdy_tune64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 67.964645 Test MSE 4.70363577504128 Test RE 1.036632696231643\n",
      "1 Train Loss 47.39098 Test MSE 5.812609780917054 Test RE 1.1523745130257403\n",
      "2 Train Loss 34.696407 Test MSE 6.438261138479298 Test RE 1.2128088411164766\n",
      "3 Train Loss 28.839725 Test MSE 5.7646175584953845 Test RE 1.1476073217650014\n",
      "4 Train Loss 25.062164 Test MSE 5.5118064687513115 Test RE 1.1221606624529732\n",
      "5 Train Loss 22.752129 Test MSE 5.455178200453956 Test RE 1.1163812435683322\n",
      "6 Train Loss 21.257488 Test MSE 5.581984637078481 Test RE 1.1292819294937904\n",
      "7 Train Loss 19.458752 Test MSE 5.487750917468075 Test RE 1.1197092237901005\n",
      "8 Train Loss 18.35305 Test MSE 5.019320635745584 Test RE 1.0708546577171705\n",
      "9 Train Loss 17.65815 Test MSE 5.169669475473703 Test RE 1.0867745232209378\n",
      "10 Train Loss 17.079556 Test MSE 5.274486822942697 Test RE 1.0977366548947665\n",
      "11 Train Loss 16.320518 Test MSE 4.9497990988131 Test RE 1.06341270920244\n",
      "12 Train Loss 15.620231 Test MSE 4.968840545313924 Test RE 1.0654561739188322\n",
      "13 Train Loss 14.754846 Test MSE 4.930734555889992 Test RE 1.0613628243743443\n",
      "14 Train Loss 13.242107 Test MSE 4.87586894698104 Test RE 1.0554412708803\n",
      "15 Train Loss 12.2083 Test MSE 4.776894596410174 Test RE 1.044674248966691\n",
      "16 Train Loss 10.946989 Test MSE 4.572647942653352 Test RE 1.022096598588755\n",
      "17 Train Loss 10.096743 Test MSE 4.6806684037168775 Test RE 1.0340987135561783\n",
      "18 Train Loss 8.156451 Test MSE 4.590268102359949 Test RE 1.0240639695189717\n",
      "19 Train Loss 6.4499083 Test MSE 3.6290003365517967 Test RE 0.9105453157709972\n",
      "20 Train Loss 5.753644 Test MSE 3.2337443568437405 Test RE 0.8595297285073309\n",
      "21 Train Loss 5.025891 Test MSE 3.213236479771721 Test RE 0.856799895204609\n",
      "22 Train Loss 4.628064 Test MSE 3.273538921383065 Test RE 0.864802257698366\n",
      "23 Train Loss 4.277346 Test MSE 3.2891369707482396 Test RE 0.8668601525532451\n",
      "24 Train Loss 4.0077367 Test MSE 3.5172247780505193 Test RE 0.8964129507265567\n",
      "25 Train Loss 3.8025115 Test MSE 3.563087471852262 Test RE 0.9022383902057904\n",
      "26 Train Loss 3.7103164 Test MSE 3.5850504351543093 Test RE 0.9050148286517115\n",
      "27 Train Loss 3.5346 Test MSE 3.636460192999197 Test RE 0.9114807042491107\n",
      "28 Train Loss 3.3443165 Test MSE 3.58999189019136 Test RE 0.905638327567424\n",
      "29 Train Loss 3.2078257 Test MSE 3.55841374689146 Test RE 0.9016464600565187\n",
      "30 Train Loss 2.9963875 Test MSE 3.6306235911815206 Test RE 0.9107489368121127\n",
      "31 Train Loss 2.8362246 Test MSE 3.5449700038610175 Test RE 0.8999416310706434\n",
      "32 Train Loss 2.7078986 Test MSE 3.4279776560931468 Test RE 0.8849669493786969\n",
      "33 Train Loss 2.5300274 Test MSE 3.417577663651565 Test RE 0.8836234982602814\n",
      "34 Train Loss 2.3667493 Test MSE 3.421646082044474 Test RE 0.8841492918472023\n",
      "35 Train Loss 2.276057 Test MSE 3.4599427139009236 Test RE 0.8890834261296497\n",
      "36 Train Loss 2.2176206 Test MSE 3.5004817077011543 Test RE 0.8942768050156596\n",
      "37 Train Loss 2.127653 Test MSE 3.5015434075369862 Test RE 0.8944124122884147\n",
      "38 Train Loss 2.0767524 Test MSE 3.5392878371444794 Test RE 0.8992200919388224\n",
      "39 Train Loss 2.0435865 Test MSE 3.5957975429180284 Test RE 0.9063703205351606\n",
      "40 Train Loss 2.0112891 Test MSE 3.579416848112198 Test RE 0.9043034740374976\n",
      "41 Train Loss 1.9781739 Test MSE 3.5663368855349176 Test RE 0.9026497016996837\n",
      "42 Train Loss 1.9452894 Test MSE 3.6257816551585504 Test RE 0.9101414296965677\n",
      "43 Train Loss 1.8760217 Test MSE 3.6189044903673575 Test RE 0.9092778692254577\n",
      "44 Train Loss 1.8310437 Test MSE 3.5162994336328954 Test RE 0.8962950246147905\n",
      "45 Train Loss 1.8023826 Test MSE 3.554792871452209 Test RE 0.9011876066612543\n",
      "46 Train Loss 1.7819796 Test MSE 3.5513819964397872 Test RE 0.9007551516487897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 Train Loss 1.7431939 Test MSE 3.516108228061078 Test RE 0.896270655397133\n",
      "48 Train Loss 1.70214 Test MSE 3.5903343149084437 Test RE 0.9056815178535094\n",
      "49 Train Loss 1.6804119 Test MSE 3.588044968352409 Test RE 0.905392721698078\n",
      "50 Train Loss 1.6609013 Test MSE 3.5777999004671814 Test RE 0.9040991982287445\n",
      "51 Train Loss 1.6374483 Test MSE 3.611903218717658 Test RE 0.9083978814567099\n",
      "52 Train Loss 1.5942973 Test MSE 3.6098917024769195 Test RE 0.9081448968862965\n",
      "53 Train Loss 1.5574518 Test MSE 3.63627190759558 Test RE 0.9114571070247887\n",
      "54 Train Loss 1.5055764 Test MSE 3.636749081244236 Test RE 0.9115169085271271\n",
      "55 Train Loss 1.4813596 Test MSE 3.5942477827008474 Test RE 0.9061749802762018\n",
      "56 Train Loss 1.4639363 Test MSE 3.578810862193395 Test RE 0.9042269226898415\n",
      "57 Train Loss 1.4485208 Test MSE 3.5383332160096232 Test RE 0.8990988143774712\n",
      "58 Train Loss 1.4297696 Test MSE 3.4905135954506226 Test RE 0.8930026079883089\n",
      "59 Train Loss 1.4068972 Test MSE 3.523364858864246 Test RE 0.8971950514271573\n",
      "60 Train Loss 1.3840244 Test MSE 3.492886483209714 Test RE 0.8933060926894858\n",
      "61 Train Loss 1.372079 Test MSE 3.5004932406950173 Test RE 0.8942782781958205\n",
      "62 Train Loss 1.3557924 Test MSE 3.5137049487428573 Test RE 0.8959643000773396\n",
      "63 Train Loss 1.3364553 Test MSE 3.4954439439475165 Test RE 0.893633068277265\n",
      "64 Train Loss 1.317089 Test MSE 3.4811974791736047 Test RE 0.8918101080381624\n",
      "65 Train Loss 1.291157 Test MSE 3.4599286609381976 Test RE 0.8890816205695629\n",
      "66 Train Loss 1.269772 Test MSE 3.5240899566526607 Test RE 0.89728736668637\n",
      "67 Train Loss 1.2575027 Test MSE 3.534419664647379 Test RE 0.8986014554991598\n",
      "68 Train Loss 1.2457049 Test MSE 3.5193348146412267 Test RE 0.8966817962868062\n",
      "69 Train Loss 1.2274534 Test MSE 3.507390835842671 Test RE 0.8951589160718719\n",
      "70 Train Loss 1.2070403 Test MSE 3.5056939422337736 Test RE 0.8949423486456989\n",
      "71 Train Loss 1.1855496 Test MSE 3.48947923378717 Test RE 0.8928702841800479\n",
      "72 Train Loss 1.1716235 Test MSE 3.481605742500667 Test RE 0.8918624007750299\n",
      "73 Train Loss 1.1552215 Test MSE 3.457749367287771 Test RE 0.888801575036964\n",
      "74 Train Loss 1.1386117 Test MSE 3.460240936804662 Test RE 0.8891217416957972\n",
      "75 Train Loss 1.1205024 Test MSE 3.4796249825865466 Test RE 0.891608664890825\n",
      "76 Train Loss 1.1069076 Test MSE 3.4383334232971925 Test RE 0.8863026641454875\n",
      "77 Train Loss 1.0990099 Test MSE 3.417399519740649 Test RE 0.883600468176899\n",
      "78 Train Loss 1.0854511 Test MSE 3.4381017846506294 Test RE 0.8862728087792124\n",
      "79 Train Loss 1.0688868 Test MSE 3.4514795499683046 Test RE 0.8879953928399925\n",
      "80 Train Loss 1.0489734 Test MSE 3.4444039690698243 Test RE 0.8870847244504954\n",
      "81 Train Loss 1.0249844 Test MSE 3.454266430830599 Test RE 0.888353824344239\n",
      "82 Train Loss 1.0113196 Test MSE 3.473113483299407 Test RE 0.8907740307208686\n",
      "83 Train Loss 0.99783754 Test MSE 3.486173696026918 Test RE 0.892447281844696\n",
      "84 Train Loss 0.98713845 Test MSE 3.490495654836986 Test RE 0.8930003130487657\n",
      "85 Train Loss 0.9777885 Test MSE 3.4967829211493227 Test RE 0.8938042110215405\n",
      "86 Train Loss 0.96658814 Test MSE 3.4831706542132195 Test RE 0.8920628153570109\n",
      "87 Train Loss 0.9471201 Test MSE 3.466218585460169 Test RE 0.8898893997976015\n",
      "88 Train Loss 0.9384507 Test MSE 3.456470036807538 Test RE 0.8886371362618349\n",
      "89 Train Loss 0.9279886 Test MSE 3.4484265737832565 Test RE 0.8876025716575067\n",
      "90 Train Loss 0.92148 Test MSE 3.451785110020516 Test RE 0.8880346991591496\n",
      "91 Train Loss 0.912073 Test MSE 3.4515119215873464 Test RE 0.8879995571093663\n",
      "92 Train Loss 0.9001901 Test MSE 3.4560087737799563 Test RE 0.8885778403432399\n",
      "93 Train Loss 0.8939307 Test MSE 3.4432083185831344 Test RE 0.8869307449299627\n",
      "94 Train Loss 0.8811132 Test MSE 3.4116283793359297 Test RE 0.882854061874106\n",
      "95 Train Loss 0.87143975 Test MSE 3.416367099878643 Test RE 0.8834669872102224\n",
      "96 Train Loss 0.86250955 Test MSE 3.39420979079794 Test RE 0.880597404792482\n",
      "97 Train Loss 0.85600156 Test MSE 3.3821782996960805 Test RE 0.8790352878146871\n",
      "98 Train Loss 0.8497014 Test MSE 3.3745002652795852 Test RE 0.8780369522155652\n",
      "99 Train Loss 0.8383745 Test MSE 3.3478840688967817 Test RE 0.8745673615839997\n",
      "100 Train Loss 0.8269645 Test MSE 3.319578374632409 Test RE 0.870862367120957\n",
      "101 Train Loss 0.81458265 Test MSE 3.30861324488375 Test RE 0.8694228744489765\n",
      "102 Train Loss 0.8033932 Test MSE 3.3445446795666065 Test RE 0.8741310786218726\n",
      "103 Train Loss 0.79048485 Test MSE 3.383481682738761 Test RE 0.8792046475034588\n",
      "104 Train Loss 0.76955956 Test MSE 3.355082502695202 Test RE 0.8755070797301229\n",
      "105 Train Loss 0.74864197 Test MSE 3.3215817609088143 Test RE 0.8711251129228469\n",
      "106 Train Loss 0.73548156 Test MSE 3.2641344115277504 Test RE 0.8635591243058152\n",
      "107 Train Loss 0.72290057 Test MSE 3.233162557842775 Test RE 0.8594524038989415\n",
      "108 Train Loss 0.71649987 Test MSE 3.237420757272143 Test RE 0.8600181836061709\n",
      "109 Train Loss 0.7090723 Test MSE 3.24007573182396 Test RE 0.8603707572476024\n",
      "110 Train Loss 0.6987252 Test MSE 3.2424987256577524 Test RE 0.8606923984093598\n",
      "111 Train Loss 0.69286805 Test MSE 3.2626832728769655 Test RE 0.8633671464070416\n",
      "112 Train Loss 0.6846373 Test MSE 3.2513305399460743 Test RE 0.8618637645282549\n",
      "113 Train Loss 0.6780847 Test MSE 3.247804566573261 Test RE 0.8613963046689086\n",
      "114 Train Loss 0.6712364 Test MSE 3.2626694815324284 Test RE 0.8633653216809857\n",
      "115 Train Loss 0.6643286 Test MSE 3.2603653850368928 Test RE 0.8630604136364951\n",
      "116 Train Loss 0.655968 Test MSE 3.271317537339496 Test RE 0.8645087857106261\n",
      "117 Train Loss 0.6509651 Test MSE 3.268404620862433 Test RE 0.8641238027956192\n",
      "118 Train Loss 0.6451879 Test MSE 3.248544490145829 Test RE 0.861494421892486\n",
      "119 Train Loss 0.6381858 Test MSE 3.2629288215239356 Test RE 0.8633996341829487\n",
      "120 Train Loss 0.6269594 Test MSE 3.267543872157551 Test RE 0.8640100099047183\n",
      "121 Train Loss 0.6194103 Test MSE 3.276125997780157 Test RE 0.8651439166340259\n",
      "122 Train Loss 0.6148601 Test MSE 3.2887761711017873 Test RE 0.8668126064314362\n",
      "123 Train Loss 0.6087942 Test MSE 3.2958137125519946 Test RE 0.8677395423793497\n",
      "124 Train Loss 0.60250235 Test MSE 3.296149249753659 Test RE 0.8677837122738102\n",
      "125 Train Loss 0.59681493 Test MSE 3.307901736480261 Test RE 0.8693293858940586\n",
      "126 Train Loss 0.5907031 Test MSE 3.3067885819070533 Test RE 0.869183102920249\n",
      "127 Train Loss 0.58406013 Test MSE 3.306427870783752 Test RE 0.8691356955103007\n",
      "128 Train Loss 0.57908833 Test MSE 3.3289863745245047 Test RE 0.8720955472656676\n",
      "129 Train Loss 0.5732593 Test MSE 3.3332285650261086 Test RE 0.8726510343066488\n",
      "130 Train Loss 0.56403565 Test MSE 3.3371832264324004 Test RE 0.8731685530271498\n",
      "131 Train Loss 0.5590297 Test MSE 3.3529933377187273 Test RE 0.8752344540121925\n",
      "132 Train Loss 0.55191076 Test MSE 3.359940734418367 Test RE 0.8761407269831171\n",
      "133 Train Loss 0.5482813 Test MSE 3.347492112523754 Test RE 0.8745161647268624\n",
      "134 Train Loss 0.544681 Test MSE 3.3351645097881217 Test RE 0.8729044161157549\n",
      "135 Train Loss 0.54020447 Test MSE 3.335900802095561 Test RE 0.8730007647870713\n",
      "136 Train Loss 0.5362749 Test MSE 3.3586229164269135 Test RE 0.8759688925165722\n",
      "137 Train Loss 0.5296897 Test MSE 3.3650548184431823 Test RE 0.8768072496945051\n",
      "138 Train Loss 0.5255239 Test MSE 3.356095352187257 Test RE 0.8756392210389735\n",
      "139 Train Loss 0.52137184 Test MSE 3.353497473971559 Test RE 0.8753002490778758\n",
      "140 Train Loss 0.518322 Test MSE 3.346838765114348 Test RE 0.8744308186329529\n",
      "141 Train Loss 0.5162286 Test MSE 3.3521515252441008 Test RE 0.8751245776333944\n",
      "142 Train Loss 0.51324683 Test MSE 3.3586311845547763 Test RE 0.8759699707290614\n",
      "143 Train Loss 0.509814 Test MSE 3.3415404356658507 Test RE 0.8737383954312401\n",
      "144 Train Loss 0.5079892 Test MSE 3.343233988009714 Test RE 0.8739597804924333\n",
      "145 Train Loss 0.5069117 Test MSE 3.349441004715555 Test RE 0.8747706970268411\n",
      "146 Train Loss 0.50587755 Test MSE 3.3544145181364318 Test RE 0.875419920275487\n",
      "147 Train Loss 0.504727 Test MSE 3.3638093241027134 Test RE 0.8766449700891762\n",
      "148 Train Loss 0.5038887 Test MSE 3.363010584246903 Test RE 0.8765408838017356\n",
      "149 Train Loss 0.5027306 Test MSE 3.3608918545683624 Test RE 0.8762647256189415\n",
      "Training time: 229.83\n",
      "6\n",
      "KG_rowdy_tune64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.21436 Test MSE 7.037580496038035 Test RE 1.268001443530463\n",
      "1 Train Loss 47.751144 Test MSE 8.95747395291874 Test RE 1.4305427387264806\n",
      "2 Train Loss 41.292633 Test MSE 9.443266671861513 Test RE 1.4688220627236444\n",
      "3 Train Loss 36.801834 Test MSE 8.523564012795692 Test RE 1.3954641180243021\n",
      "4 Train Loss 32.732002 Test MSE 8.832642181272721 Test RE 1.4205397108749749\n",
      "5 Train Loss 30.042622 Test MSE 8.883301360849021 Test RE 1.4246076038165438\n",
      "6 Train Loss 28.046196 Test MSE 8.878916321856789 Test RE 1.424255947898029\n",
      "7 Train Loss 26.594042 Test MSE 8.689960285392917 Test RE 1.4090193461364395\n",
      "8 Train Loss 25.354134 Test MSE 8.863420374735341 Test RE 1.4230125623326553\n",
      "9 Train Loss 24.009104 Test MSE 8.82560756938202 Test RE 1.419973915510009\n",
      "10 Train Loss 23.232807 Test MSE 8.776438352225359 Test RE 1.416012912203193\n",
      "11 Train Loss 22.651524 Test MSE 8.695614467630772 Test RE 1.4094776656452637\n",
      "12 Train Loss 22.109734 Test MSE 8.799861036745247 Test RE 1.4179011909584642\n",
      "13 Train Loss 21.310978 Test MSE 8.995465496921486 Test RE 1.4335732260132041\n",
      "14 Train Loss 20.940126 Test MSE 8.92709902670061 Test RE 1.4281151832523074\n",
      "15 Train Loss 20.342085 Test MSE 8.860843437408292 Test RE 1.422805685043304\n",
      "16 Train Loss 19.521439 Test MSE 8.947468602768677 Test RE 1.4297435692182423\n",
      "17 Train Loss 19.203356 Test MSE 8.936642621870854 Test RE 1.4288783490032955\n",
      "18 Train Loss 18.338602 Test MSE 8.909795992385044 Test RE 1.4267304830536995\n",
      "19 Train Loss 17.696299 Test MSE 8.730705996590663 Test RE 1.4123188062405732\n",
      "20 Train Loss 17.252129 Test MSE 8.549050745613355 Test RE 1.3975488840899797\n",
      "21 Train Loss 16.882828 Test MSE 8.450119851394108 Test RE 1.3894390313259195\n",
      "22 Train Loss 16.48948 Test MSE 8.390739376726676 Test RE 1.3845485086219256\n",
      "23 Train Loss 15.917276 Test MSE 8.60947499593902 Test RE 1.4024790895834147\n",
      "24 Train Loss 15.478184 Test MSE 8.757677526462059 Test RE 1.4144986428305417\n",
      "25 Train Loss 14.69998 Test MSE 8.783320578788345 Test RE 1.4165680013826774\n",
      "26 Train Loss 13.659784 Test MSE 8.171079594277797 Test RE 1.3663053873534043\n",
      "27 Train Loss 13.087335 Test MSE 8.16357329069554 Test RE 1.3656776698427868\n",
      "28 Train Loss 11.821072 Test MSE 8.111336268170968 Test RE 1.361301312822042\n",
      "29 Train Loss 10.068207 Test MSE 7.34983977947678 Test RE 1.2958269150440775\n",
      "30 Train Loss 9.0392 Test MSE 6.84380056379022 Test RE 1.2504223650968336\n",
      "31 Train Loss 8.089142 Test MSE 6.769307049960219 Test RE 1.243598435940515\n",
      "32 Train Loss 7.222737 Test MSE 7.092447827429629 Test RE 1.2729347284937955\n",
      "33 Train Loss 6.4251986 Test MSE 7.128432150987757 Test RE 1.2761598309620257\n",
      "34 Train Loss 6.0117407 Test MSE 6.970878601349312 Test RE 1.2619781048907919\n",
      "35 Train Loss 5.5848327 Test MSE 6.806201534212877 Test RE 1.2469827982732256\n",
      "36 Train Loss 5.270401 Test MSE 6.808543867471823 Test RE 1.2471973524566393\n",
      "37 Train Loss 4.8616314 Test MSE 7.031792390836932 Test RE 1.2674798981325288\n",
      "38 Train Loss 4.5962243 Test MSE 6.911326369342293 Test RE 1.256576001664766\n",
      "39 Train Loss 4.460493 Test MSE 6.673659860325003 Test RE 1.2347814436767643\n",
      "40 Train Loss 4.3348265 Test MSE 6.6389539244103695 Test RE 1.2315665580609694\n",
      "41 Train Loss 4.17528 Test MSE 6.580629701271997 Test RE 1.2261448741558987\n",
      "42 Train Loss 4.041394 Test MSE 6.477757110590593 Test RE 1.2165231845148652\n",
      "43 Train Loss 3.898929 Test MSE 6.471226177358788 Test RE 1.2159097750329526\n",
      "44 Train Loss 3.7660904 Test MSE 6.387649036171682 Test RE 1.208032402641271\n",
      "45 Train Loss 3.663452 Test MSE 6.391574108563361 Test RE 1.2084035005541158\n",
      "46 Train Loss 3.5364468 Test MSE 6.460413179905165 Test RE 1.2148934973027214\n",
      "47 Train Loss 3.4690425 Test MSE 6.5304371514732065 Test RE 1.2214598255524765\n",
      "48 Train Loss 3.434678 Test MSE 6.573514642939316 Test RE 1.2254818333737147\n",
      "49 Train Loss 3.3942263 Test MSE 6.590782413793413 Test RE 1.2270903686727321\n",
      "50 Train Loss 3.3569715 Test MSE 6.557078107179929 Test RE 1.2239487658963921\n",
      "51 Train Loss 3.2865832 Test MSE 6.58529622587593 Test RE 1.2265795454153834\n",
      "52 Train Loss 3.2345603 Test MSE 6.654780109155071 Test RE 1.233033611310427\n",
      "53 Train Loss 3.1542616 Test MSE 6.664468800229053 Test RE 1.2339308713619337\n",
      "54 Train Loss 3.1085017 Test MSE 6.6508926398403565 Test RE 1.2326734130408008\n",
      "55 Train Loss 3.0579567 Test MSE 6.631669206313864 Test RE 1.2308906927277696\n",
      "56 Train Loss 3.0098379 Test MSE 6.544105406189804 Test RE 1.222737419759192\n",
      "57 Train Loss 2.9712546 Test MSE 6.499444304356597 Test RE 1.2185579110610416\n",
      "58 Train Loss 2.9417949 Test MSE 6.517097457230857 Test RE 1.220211652604589\n",
      "59 Train Loss 2.9232907 Test MSE 6.537943289111298 Test RE 1.2221616018883412\n",
      "60 Train Loss 2.903346 Test MSE 6.544061473389369 Test RE 1.2227333154266766\n",
      "61 Train Loss 2.8719122 Test MSE 6.517637777260448 Test RE 1.2202622342581328\n",
      "62 Train Loss 2.8137918 Test MSE 6.538330888998291 Test RE 1.2221978290822086\n",
      "63 Train Loss 2.7917793 Test MSE 6.536961606467059 Test RE 1.2220698436839348\n",
      "64 Train Loss 2.7611876 Test MSE 6.551394278410421 Test RE 1.2234181771715888\n",
      "65 Train Loss 2.7303615 Test MSE 6.540590160862395 Test RE 1.2224089715527384\n",
      "66 Train Loss 2.6788845 Test MSE 6.512282183446292 Test RE 1.2197607817257254\n",
      "67 Train Loss 2.6317463 Test MSE 6.457500426219212 Test RE 1.2146195918752936\n",
      "68 Train Loss 2.5913694 Test MSE 6.31706642725343 Test RE 1.201339569873556\n",
      "69 Train Loss 2.5547981 Test MSE 6.33333905096724 Test RE 1.202885886805089\n",
      "70 Train Loss 2.4922767 Test MSE 6.426814503390484 Test RE 1.2117302302993218\n",
      "71 Train Loss 2.4470289 Test MSE 6.432749811497801 Test RE 1.2122896312693152\n",
      "72 Train Loss 2.4129484 Test MSE 6.441768262834545 Test RE 1.2131391238000377\n",
      "73 Train Loss 2.3728602 Test MSE 6.428240490249986 Test RE 1.2118646526906784\n",
      "74 Train Loss 2.3393755 Test MSE 6.433478277854166 Test RE 1.2123582712161642\n",
      "75 Train Loss 2.3155377 Test MSE 6.418057486646456 Test RE 1.2109044122370274\n",
      "76 Train Loss 2.292175 Test MSE 6.425588730165319 Test RE 1.2116146693709051\n",
      "77 Train Loss 2.2518675 Test MSE 6.390859111078796 Test RE 1.208335909252424\n",
      "78 Train Loss 2.229088 Test MSE 6.3714808207254 Test RE 1.206502567233013\n",
      "79 Train Loss 2.2037768 Test MSE 6.390440025970275 Test RE 1.2082962898617486\n",
      "80 Train Loss 2.1895905 Test MSE 6.36777659979872 Test RE 1.2061518009091525\n",
      "81 Train Loss 2.1661963 Test MSE 6.291089499337244 Test RE 1.1988669617226686\n",
      "82 Train Loss 2.137203 Test MSE 6.275126657077786 Test RE 1.1973450091847497\n",
      "83 Train Loss 2.1111565 Test MSE 6.316724027731556 Test RE 1.2013070117492202\n",
      "84 Train Loss 2.09268 Test MSE 6.2923740028787645 Test RE 1.1989893467451926\n",
      "85 Train Loss 2.072722 Test MSE 6.220872131412382 Test RE 1.19215767091567\n",
      "86 Train Loss 2.0608752 Test MSE 6.214038446925095 Test RE 1.1915026929816113\n",
      "87 Train Loss 2.047871 Test MSE 6.197978533362649 Test RE 1.1899620032918277\n",
      "88 Train Loss 2.0322833 Test MSE 6.160181254031716 Test RE 1.186328067852326\n",
      "89 Train Loss 2.0192645 Test MSE 6.17613706714501 Test RE 1.1878634599835198\n",
      "90 Train Loss 2.0068655 Test MSE 6.135742849682798 Test RE 1.1839725546855506\n",
      "91 Train Loss 1.9940159 Test MSE 6.135564895158562 Test RE 1.1839553852241227\n",
      "92 Train Loss 1.9803417 Test MSE 6.136929405880282 Test RE 1.1840870299898802\n",
      "93 Train Loss 1.9623629 Test MSE 6.114080971485982 Test RE 1.1818807341587045\n",
      "94 Train Loss 1.9486308 Test MSE 6.120325169802161 Test RE 1.182484096663038\n",
      "95 Train Loss 1.9278455 Test MSE 6.112935302203174 Test RE 1.181769997328734\n",
      "96 Train Loss 1.9117352 Test MSE 6.110506262954785 Test RE 1.181535179619793\n",
      "97 Train Loss 1.8926424 Test MSE 6.137858497063103 Test RE 1.1841766581338358\n",
      "98 Train Loss 1.8772447 Test MSE 6.143178172730312 Test RE 1.1846897093404993\n",
      "99 Train Loss 1.8677154 Test MSE 6.133994042638019 Test RE 1.1838038149622352\n",
      "100 Train Loss 1.8548895 Test MSE 6.134226913207182 Test RE 1.1838262856762507\n",
      "101 Train Loss 1.8427777 Test MSE 6.12699455935157 Test RE 1.1831282045771945\n",
      "102 Train Loss 1.8313056 Test MSE 6.120639473629875 Test RE 1.182514458980076\n",
      "103 Train Loss 1.8159494 Test MSE 6.1724622449826265 Test RE 1.1875100160395446\n",
      "104 Train Loss 1.7980503 Test MSE 6.197799666305321 Test RE 1.189944832650113\n",
      "105 Train Loss 1.7741909 Test MSE 6.156990808836242 Test RE 1.1860208200035676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 1.7508962 Test MSE 6.150440301453021 Test RE 1.1853897401566083\n",
      "107 Train Loss 1.7302395 Test MSE 6.144310200920571 Test RE 1.184798858085098\n",
      "108 Train Loss 1.7139376 Test MSE 6.126879760002329 Test RE 1.1831171205960633\n",
      "109 Train Loss 1.7069106 Test MSE 6.125529045406607 Test RE 1.182986700079329\n",
      "110 Train Loss 1.6974492 Test MSE 6.108511491712249 Test RE 1.1813423081391123\n",
      "111 Train Loss 1.6804924 Test MSE 6.122716862975927 Test RE 1.1827151189390936\n",
      "112 Train Loss 1.6701274 Test MSE 6.133715224078104 Test RE 1.18377690996172\n",
      "113 Train Loss 1.6568365 Test MSE 6.102494266142935 Test RE 1.1807603206484845\n",
      "114 Train Loss 1.6456268 Test MSE 6.064257104970453 Test RE 1.1770552889868549\n",
      "115 Train Loss 1.6369543 Test MSE 6.078255836559871 Test RE 1.1784130631289855\n",
      "116 Train Loss 1.6258441 Test MSE 6.081061774572466 Test RE 1.1786850303330438\n",
      "117 Train Loss 1.6135542 Test MSE 6.047733267604182 Test RE 1.175450579881584\n",
      "118 Train Loss 1.6066196 Test MSE 6.022445127712367 Test RE 1.1729904765927928\n",
      "119 Train Loss 1.599967 Test MSE 6.027861865672254 Test RE 1.1735178665366535\n",
      "120 Train Loss 1.5931913 Test MSE 6.032549196509332 Test RE 1.1739740479884933\n",
      "121 Train Loss 1.5847455 Test MSE 5.9902339420898345 Test RE 1.169849387708047\n",
      "122 Train Loss 1.577698 Test MSE 5.974445143504015 Test RE 1.168306651351709\n",
      "123 Train Loss 1.5664536 Test MSE 5.9722777059560475 Test RE 1.1680947102133876\n",
      "124 Train Loss 1.5553236 Test MSE 5.943414082643401 Test RE 1.1652686292575976\n",
      "125 Train Loss 1.5452396 Test MSE 5.92671054283343 Test RE 1.163630025120238\n",
      "126 Train Loss 1.5413548 Test MSE 5.931724225057896 Test RE 1.1641221056616855\n",
      "127 Train Loss 1.5371468 Test MSE 5.943540865140725 Test RE 1.1652810577100798\n",
      "128 Train Loss 1.5323057 Test MSE 5.959028943373178 Test RE 1.1667983537326765\n",
      "129 Train Loss 1.5278214 Test MSE 5.976628911948877 Test RE 1.1685201505171376\n",
      "130 Train Loss 1.5216191 Test MSE 5.9882108193541566 Test RE 1.1696518204022621\n",
      "131 Train Loss 1.5157219 Test MSE 5.989948982663733 Test RE 1.1698215621190968\n",
      "132 Train Loss 1.5083193 Test MSE 6.002501410501683 Test RE 1.1710466490022133\n",
      "133 Train Loss 1.5036802 Test MSE 6.0004675935034495 Test RE 1.1708482403557088\n",
      "134 Train Loss 1.498151 Test MSE 6.00809400879251 Test RE 1.1715920606781784\n",
      "135 Train Loss 1.4921999 Test MSE 6.027144233915963 Test RE 1.1734480093656547\n",
      "136 Train Loss 1.4893155 Test MSE 6.012064273454542 Test RE 1.1719791020883574\n",
      "137 Train Loss 1.4847336 Test MSE 6.017282386629222 Test RE 1.1724875957532581\n",
      "138 Train Loss 1.4762653 Test MSE 6.022472087162792 Test RE 1.1729931020333357\n",
      "139 Train Loss 1.4671254 Test MSE 5.9721886035072735 Test RE 1.1680859965791253\n",
      "140 Train Loss 1.4608787 Test MSE 5.977846204220367 Test RE 1.1686391438617225\n",
      "141 Train Loss 1.4547642 Test MSE 5.989615038936503 Test RE 1.1697889524909726\n",
      "142 Train Loss 1.4508052 Test MSE 5.955927535617779 Test RE 1.1664946810650896\n",
      "143 Train Loss 1.4429222 Test MSE 5.965539578649937 Test RE 1.1674355821116922\n",
      "144 Train Loss 1.4373815 Test MSE 5.985125136373088 Test RE 1.1693504248861126\n",
      "145 Train Loss 1.4300784 Test MSE 5.972250938949721 Test RE 1.1680920925828058\n",
      "146 Train Loss 1.4243652 Test MSE 5.980412566710147 Test RE 1.1688899724826336\n",
      "147 Train Loss 1.4208987 Test MSE 5.97298514430413 Test RE 1.1681638907306988\n",
      "148 Train Loss 1.4119198 Test MSE 5.954287354326324 Test RE 1.166334051634931\n",
      "149 Train Loss 1.4056529 Test MSE 5.976456643558631 Test RE 1.1685033098751274\n",
      "Training time: 229.70\n",
      "7\n",
      "KG_rowdy_tune64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 58.555714 Test MSE 6.253515951524947 Test RE 1.195281482165971\n",
      "1 Train Loss 43.41038 Test MSE 7.51800653379679 Test RE 1.3105675475305771\n",
      "2 Train Loss 35.850155 Test MSE 7.717051190963685 Test RE 1.3278033219681624\n",
      "3 Train Loss 31.558426 Test MSE 8.138703180096913 Test RE 1.3635958325768667\n",
      "4 Train Loss 27.300264 Test MSE 7.235934244813481 Test RE 1.2857465453547763\n",
      "5 Train Loss 24.680878 Test MSE 6.997908890988133 Test RE 1.2644224617479427\n",
      "6 Train Loss 22.40794 Test MSE 6.850006348314185 Test RE 1.2509891622570821\n",
      "7 Train Loss 20.365807 Test MSE 6.6961872264356455 Test RE 1.2368637298419336\n",
      "8 Train Loss 19.29774 Test MSE 6.437210064984607 Test RE 1.2127098389766915\n",
      "9 Train Loss 17.472248 Test MSE 6.168356836776811 Test RE 1.187115033932967\n",
      "10 Train Loss 16.265955 Test MSE 6.0052624343718195 Test RE 1.1713159464004406\n",
      "11 Train Loss 15.422398 Test MSE 6.024818476948858 Test RE 1.1732215822129226\n",
      "12 Train Loss 13.919202 Test MSE 5.550475476945532 Test RE 1.126090136252298\n",
      "13 Train Loss 11.564678 Test MSE 5.5238666326219885 Test RE 1.12338766912014\n",
      "14 Train Loss 10.432962 Test MSE 5.471552487288302 Test RE 1.1180554555998927\n",
      "15 Train Loss 9.64646 Test MSE 5.467000911505658 Test RE 1.1175903250079826\n",
      "16 Train Loss 9.05364 Test MSE 5.320248452941984 Test RE 1.1024883712211466\n",
      "17 Train Loss 8.705058 Test MSE 5.326814231338232 Test RE 1.1031684581035932\n",
      "18 Train Loss 8.413815 Test MSE 5.298336149324499 Test RE 1.1002156403312742\n",
      "19 Train Loss 8.065934 Test MSE 5.165924198325763 Test RE 1.0863807834207413\n",
      "20 Train Loss 7.608566 Test MSE 5.21074041822473 Test RE 1.0910829759529979\n",
      "21 Train Loss 7.316044 Test MSE 5.076587765595812 Test RE 1.076946203684126\n",
      "22 Train Loss 6.949141 Test MSE 5.023192886896417 Test RE 1.0712676437607909\n",
      "23 Train Loss 6.687809 Test MSE 5.0325808578727695 Test RE 1.0722682359340518\n",
      "24 Train Loss 6.221756 Test MSE 4.980200637594155 Test RE 1.0666734367977662\n",
      "25 Train Loss 5.481273 Test MSE 4.784538739882417 Test RE 1.0455097758464056\n",
      "26 Train Loss 5.135347 Test MSE 4.721777913851322 Test RE 1.0386299421333802\n",
      "27 Train Loss 4.645591 Test MSE 4.571852927483293 Test RE 1.0220077422374736\n",
      "28 Train Loss 4.392411 Test MSE 4.457279945281679 Test RE 1.0091204701022451\n",
      "29 Train Loss 3.9955134 Test MSE 4.3258792053380635 Test RE 0.9941347489035016\n",
      "30 Train Loss 3.614867 Test MSE 4.161129058615 Test RE 0.9750202895078486\n",
      "31 Train Loss 3.3002808 Test MSE 3.905469767850834 Test RE 0.9445929511822115\n",
      "32 Train Loss 3.1517959 Test MSE 3.8148117856477097 Test RE 0.9335651220665451\n",
      "33 Train Loss 3.009433 Test MSE 3.74794998300616 Test RE 0.9253477078894632\n",
      "34 Train Loss 2.9205542 Test MSE 3.6632634763607745 Test RE 0.9148336658666555\n",
      "35 Train Loss 2.7556295 Test MSE 3.464690122502485 Test RE 0.8896931754499667\n",
      "36 Train Loss 2.6187465 Test MSE 3.350028109157479 Test RE 0.8748473604547732\n",
      "37 Train Loss 2.4820018 Test MSE 3.1948921286892698 Test RE 0.8543506613649023\n",
      "38 Train Loss 2.3942373 Test MSE 3.052830776194609 Test RE 0.8351402705366966\n",
      "39 Train Loss 2.3296547 Test MSE 3.0318840161057548 Test RE 0.8322702140047743\n",
      "40 Train Loss 2.2333412 Test MSE 2.9388408405995086 Test RE 0.8194002526910931\n",
      "41 Train Loss 2.1464207 Test MSE 2.840234821864667 Test RE 0.8055364265697091\n",
      "42 Train Loss 2.0925553 Test MSE 2.758957227399485 Test RE 0.7939269493981486\n",
      "43 Train Loss 2.0370412 Test MSE 2.6883213214722788 Test RE 0.7836978377486806\n",
      "44 Train Loss 1.9939371 Test MSE 2.64062224701014 Test RE 0.7767141179928324\n",
      "45 Train Loss 1.9317735 Test MSE 2.6167826245054466 Test RE 0.773200068764552\n",
      "46 Train Loss 1.8915528 Test MSE 2.4948694919909165 Test RE 0.754973966846302\n",
      "47 Train Loss 1.8124406 Test MSE 2.3095887592972284 Test RE 0.7263992529448892\n",
      "48 Train Loss 1.7023237 Test MSE 2.019058832344966 Test RE 0.6791763382921179\n",
      "49 Train Loss 1.6317327 Test MSE 1.892359316772751 Test RE 0.6575213538159931\n",
      "50 Train Loss 1.5698818 Test MSE 1.8574199619698948 Test RE 0.6514230395066725\n",
      "51 Train Loss 1.5013638 Test MSE 1.6825576881220758 Test RE 0.6200019307798716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 1.415579 Test MSE 1.46589659286 Test RE 0.5787083223975016\n",
      "53 Train Loss 1.2710243 Test MSE 1.3487260362829767 Test RE 0.5550983430244788\n",
      "54 Train Loss 1.1583253 Test MSE 1.3343517554119324 Test RE 0.5521323910471405\n",
      "55 Train Loss 1.0847489 Test MSE 1.2935410003338361 Test RE 0.5436234215345838\n",
      "56 Train Loss 1.0245875 Test MSE 1.2058267022135294 Test RE 0.5248684991817975\n",
      "57 Train Loss 0.97499686 Test MSE 1.1624879101876384 Test RE 0.5153500028131734\n",
      "58 Train Loss 0.8914273 Test MSE 1.0104253709865778 Test RE 0.48046325758399644\n",
      "59 Train Loss 0.8423593 Test MSE 0.9460931851623781 Test RE 0.46491656178144275\n",
      "60 Train Loss 0.7896614 Test MSE 0.8927972767436394 Test RE 0.45163177414551037\n",
      "61 Train Loss 0.7404534 Test MSE 0.8090095510316974 Test RE 0.4299172634692767\n",
      "62 Train Loss 0.6867349 Test MSE 0.7071851734888681 Test RE 0.4019524070407163\n",
      "63 Train Loss 0.6451823 Test MSE 0.6174907131316183 Test RE 0.375598003798753\n",
      "64 Train Loss 0.61465085 Test MSE 0.6110549142319894 Test RE 0.3736355412742611\n",
      "65 Train Loss 0.57547593 Test MSE 0.5432602175884231 Test RE 0.3522994879044443\n",
      "66 Train Loss 0.53929234 Test MSE 0.49252295157562365 Test RE 0.3354449800294517\n",
      "67 Train Loss 0.50344265 Test MSE 0.4763354850659814 Test RE 0.3298864886250984\n",
      "68 Train Loss 0.46958745 Test MSE 0.4695244586722959 Test RE 0.3275195062522471\n",
      "69 Train Loss 0.4477154 Test MSE 0.4452065887574263 Test RE 0.31892521117664774\n",
      "70 Train Loss 0.41671753 Test MSE 0.38642175051148886 Test RE 0.29712475871250793\n",
      "71 Train Loss 0.3934927 Test MSE 0.35364083594600326 Test RE 0.2842426638041441\n",
      "72 Train Loss 0.37697393 Test MSE 0.3396740009669772 Test RE 0.2785731234429835\n",
      "73 Train Loss 0.3595907 Test MSE 0.3140372784637706 Test RE 0.26785432470672743\n",
      "74 Train Loss 0.32528916 Test MSE 0.29707102388330786 Test RE 0.26051828276541034\n",
      "75 Train Loss 0.3027084 Test MSE 0.2899577706849124 Test RE 0.25738037915094003\n",
      "76 Train Loss 0.2830082 Test MSE 0.2131570349312295 Test RE 0.22067741880674574\n",
      "77 Train Loss 0.25591534 Test MSE 0.12556807265752504 Test RE 0.16937436282768664\n",
      "78 Train Loss 0.24482368 Test MSE 0.10083262329382311 Test RE 0.15177791876339364\n",
      "79 Train Loss 0.22517055 Test MSE 0.08258805404195355 Test RE 0.13736202257319058\n",
      "80 Train Loss 0.2123451 Test MSE 0.07515168327784011 Test RE 0.13103201407342607\n",
      "81 Train Loss 0.19901383 Test MSE 0.07490723867992052 Test RE 0.1308187377038468\n",
      "82 Train Loss 0.18234298 Test MSE 0.06720655342915073 Test RE 0.12391214422526989\n",
      "83 Train Loss 0.16573869 Test MSE 0.06019835053012355 Test RE 0.1172736267173685\n",
      "84 Train Loss 0.1504967 Test MSE 0.062171568209089104 Test RE 0.11918016197590106\n",
      "85 Train Loss 0.14249605 Test MSE 0.0654949726220926 Test RE 0.12232410383799061\n",
      "86 Train Loss 0.1379167 Test MSE 0.06623655302763541 Test RE 0.12301467457027823\n",
      "87 Train Loss 0.13265221 Test MSE 0.06824267113031891 Test RE 0.12486366236234299\n",
      "88 Train Loss 0.12450443 Test MSE 0.0760745645262463 Test RE 0.13183411185977426\n",
      "89 Train Loss 0.117143944 Test MSE 0.07923156346412652 Test RE 0.1345417812632554\n",
      "90 Train Loss 0.1121033 Test MSE 0.07885567394877992 Test RE 0.13422225601833304\n",
      "91 Train Loss 0.10809778 Test MSE 0.07679755262678035 Test RE 0.13245908490376032\n",
      "92 Train Loss 0.10234424 Test MSE 0.07300629221109797 Test RE 0.12914815506261504\n",
      "93 Train Loss 0.09349329 Test MSE 0.06947471824779382 Test RE 0.12598575918763655\n",
      "94 Train Loss 0.085496925 Test MSE 0.06614161384840489 Test RE 0.12292648232857993\n",
      "95 Train Loss 0.08276622 Test MSE 0.06336122736951734 Test RE 0.12031502093608544\n",
      "96 Train Loss 0.07987146 Test MSE 0.05950388487718797 Test RE 0.11659521314095186\n",
      "97 Train Loss 0.0748622 Test MSE 0.0575429679404038 Test RE 0.11465795440471883\n",
      "98 Train Loss 0.07233206 Test MSE 0.06021681540162983 Test RE 0.11729161123356525\n",
      "99 Train Loss 0.0697753 Test MSE 0.05868109718898187 Test RE 0.11578629917923912\n",
      "100 Train Loss 0.06406175 Test MSE 0.04879824158226582 Test RE 0.10558692609478129\n",
      "101 Train Loss 0.061402448 Test MSE 0.04593707427406917 Test RE 0.1024447545084116\n",
      "102 Train Loss 0.058935292 Test MSE 0.041170305463130885 Test RE 0.09698400284823888\n",
      "103 Train Loss 0.057301484 Test MSE 0.037434440022074765 Test RE 0.09247912899804746\n",
      "104 Train Loss 0.054498453 Test MSE 0.03632858829285507 Test RE 0.09110292505708675\n",
      "105 Train Loss 0.05079443 Test MSE 0.0364374841477719 Test RE 0.09123936454024574\n",
      "106 Train Loss 0.04828188 Test MSE 0.03280552864360354 Test RE 0.08657282323451691\n",
      "107 Train Loss 0.0463194 Test MSE 0.031248161257376016 Test RE 0.08449291506816929\n",
      "108 Train Loss 0.043717943 Test MSE 0.029882034700432623 Test RE 0.08262531784442251\n",
      "109 Train Loss 0.041798137 Test MSE 0.024702297432826786 Test RE 0.07512365915793105\n",
      "110 Train Loss 0.040096145 Test MSE 0.02283197424912588 Test RE 0.07222370994670578\n",
      "111 Train Loss 0.039159335 Test MSE 0.024554017616351995 Test RE 0.0748978483965722\n",
      "112 Train Loss 0.03871987 Test MSE 0.02437181403228969 Test RE 0.07461944045290023\n",
      "113 Train Loss 0.03829226 Test MSE 0.02369689950287883 Test RE 0.07357899026420092\n",
      "114 Train Loss 0.037674766 Test MSE 0.024037504591435187 Test RE 0.07410589391261808\n",
      "115 Train Loss 0.037094206 Test MSE 0.023124112268431304 Test RE 0.07268429709682576\n",
      "116 Train Loss 0.036372315 Test MSE 0.02243238786204922 Test RE 0.07158892038691424\n",
      "117 Train Loss 0.03535313 Test MSE 0.023423605606772195 Test RE 0.073153470386955\n",
      "118 Train Loss 0.0345525 Test MSE 0.022764003772204465 Test RE 0.07211612531624265\n",
      "119 Train Loss 0.033793725 Test MSE 0.022270063263457384 Test RE 0.071329435273624\n",
      "120 Train Loss 0.03307817 Test MSE 0.023218090457310967 Test RE 0.07283184465293958\n",
      "121 Train Loss 0.032358978 Test MSE 0.023251743696515788 Test RE 0.07288460825085105\n",
      "122 Train Loss 0.03189553 Test MSE 0.02242603413243079 Test RE 0.07157878127779503\n",
      "123 Train Loss 0.03105478 Test MSE 0.023795453926386132 Test RE 0.0737318374942045\n",
      "124 Train Loss 0.030065667 Test MSE 0.02515314870870856 Test RE 0.07580611491485227\n",
      "125 Train Loss 0.029177524 Test MSE 0.024220798045507454 Test RE 0.07438789759519279\n",
      "126 Train Loss 0.028571766 Test MSE 0.024070208669214468 Test RE 0.07415628893444641\n",
      "127 Train Loss 0.027988309 Test MSE 0.0239905180620498 Test RE 0.0740334304423578\n",
      "128 Train Loss 0.027422829 Test MSE 0.024341041034438 Test RE 0.07457231656671034\n",
      "129 Train Loss 0.026807506 Test MSE 0.025454443316637588 Test RE 0.07625878157540646\n",
      "130 Train Loss 0.026238522 Test MSE 0.023505626002473908 Test RE 0.07328143602509354\n",
      "131 Train Loss 0.02551014 Test MSE 0.022583965191439754 Test RE 0.07183037904065186\n",
      "132 Train Loss 0.024795497 Test MSE 0.02353876308965045 Test RE 0.07333307213340075\n",
      "133 Train Loss 0.024056148 Test MSE 0.021243300847535382 Test RE 0.06966570879680431\n",
      "134 Train Loss 0.023407709 Test MSE 0.020253589442189038 Test RE 0.06802351371163737\n",
      "135 Train Loss 0.022892557 Test MSE 0.021184413741418974 Test RE 0.06956908400747669\n",
      "136 Train Loss 0.022202019 Test MSE 0.01878798065427612 Test RE 0.06551611136265599\n",
      "137 Train Loss 0.021861523 Test MSE 0.018764705891778814 Test RE 0.06547551773767665\n",
      "138 Train Loss 0.021580113 Test MSE 0.01941878377294053 Test RE 0.06660687729029369\n",
      "139 Train Loss 0.02126625 Test MSE 0.018690719393631393 Test RE 0.065346310042308\n",
      "140 Train Loss 0.02084768 Test MSE 0.01931732547705794 Test RE 0.06643264726490077\n",
      "141 Train Loss 0.020403307 Test MSE 0.01883060930615016 Test RE 0.06559039505351853\n",
      "142 Train Loss 0.01999185 Test MSE 0.016572049781963114 Test RE 0.06153131192589731\n",
      "143 Train Loss 0.019413225 Test MSE 0.016096421001769307 Test RE 0.06064188905328609\n",
      "144 Train Loss 0.01901536 Test MSE 0.015583915089164247 Test RE 0.059668668524782746\n",
      "145 Train Loss 0.018156866 Test MSE 0.01473371783326951 Test RE 0.05801819781897465\n",
      "146 Train Loss 0.017592572 Test MSE 0.015213566975701255 Test RE 0.05895539936846437\n",
      "147 Train Loss 0.017117096 Test MSE 0.014915788613604139 Test RE 0.05837557484375205\n",
      "148 Train Loss 0.016772818 Test MSE 0.01484783132135989 Test RE 0.05824244159299317\n",
      "149 Train Loss 0.016201112 Test MSE 0.01618926295793711 Test RE 0.06081652466033147\n",
      "Training time: 228.74\n",
      "8\n",
      "KG_rowdy_tune64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 72.35293 Test MSE 5.5962982924255575 Test RE 1.1307288882704833\n",
      "1 Train Loss 58.38281 Test MSE 5.89099928497599 Test RE 1.1601190152955334\n",
      "2 Train Loss 47.727585 Test MSE 7.4635331898502315 Test RE 1.3058109151154165\n",
      "3 Train Loss 38.464516 Test MSE 8.732261917125674 Test RE 1.4124446470339003\n",
      "4 Train Loss 32.554146 Test MSE 8.479576759553284 Test RE 1.3918586994307143\n",
      "5 Train Loss 29.036572 Test MSE 8.803107405135282 Test RE 1.4181627067448022\n",
      "6 Train Loss 25.823421 Test MSE 9.080887130300528 Test RE 1.4403638040401305\n",
      "7 Train Loss 22.717133 Test MSE 8.875543093514986 Test RE 1.4239853745109443\n",
      "8 Train Loss 20.537851 Test MSE 8.37946228541692 Test RE 1.3836177843466824\n",
      "9 Train Loss 19.170597 Test MSE 8.629266769225028 Test RE 1.4040901990870576\n",
      "10 Train Loss 17.997564 Test MSE 8.719469733243182 Test RE 1.4114096990519913\n",
      "11 Train Loss 17.13013 Test MSE 8.524956265733952 Test RE 1.3955780820706496\n",
      "12 Train Loss 16.309376 Test MSE 8.389171325540943 Test RE 1.3844191312051617\n",
      "13 Train Loss 15.81642 Test MSE 8.171111278864819 Test RE 1.3663080363778985\n",
      "14 Train Loss 14.24647 Test MSE 7.742060019605333 Test RE 1.3299531033363814\n",
      "15 Train Loss 13.286093 Test MSE 7.950370887637717 Test RE 1.347726459557672\n",
      "16 Train Loss 12.530357 Test MSE 7.744068394406438 Test RE 1.3301255943200854\n",
      "17 Train Loss 11.400911 Test MSE 7.308153140550458 Test RE 1.2921468700521503\n",
      "18 Train Loss 10.280224 Test MSE 7.107387750398407 Test RE 1.2742747131424257\n",
      "19 Train Loss 9.666807 Test MSE 6.88311232273228 Test RE 1.2540085241294059\n",
      "20 Train Loss 8.463423 Test MSE 6.21505029683747 Test RE 1.1915996969534284\n",
      "21 Train Loss 7.313077 Test MSE 6.064343450745743 Test RE 1.1770636686933837\n",
      "22 Train Loss 6.7360187 Test MSE 6.004762093774701 Test RE 1.1712671501043523\n",
      "23 Train Loss 5.8196917 Test MSE 5.692686168455939 Test RE 1.1404248745647738\n",
      "24 Train Loss 5.016169 Test MSE 5.647370625694353 Test RE 1.1358767379579142\n",
      "25 Train Loss 4.624747 Test MSE 5.505389812031042 Test RE 1.1215072816904885\n",
      "26 Train Loss 4.243488 Test MSE 5.280242919133364 Test RE 1.0983354766400668\n",
      "27 Train Loss 3.8556154 Test MSE 5.255583984144677 Test RE 1.0957678411965535\n",
      "28 Train Loss 3.573586 Test MSE 5.298373132617838 Test RE 1.1002194801713305\n",
      "29 Train Loss 3.3706002 Test MSE 5.2030671882643365 Test RE 1.090279326726905\n",
      "30 Train Loss 3.237969 Test MSE 5.146022207197558 Test RE 1.0842860948196071\n",
      "31 Train Loss 3.140077 Test MSE 5.086508288029381 Test RE 1.07799795882286\n",
      "32 Train Loss 3.0642881 Test MSE 5.053072682740358 Test RE 1.0744490663691457\n",
      "33 Train Loss 3.0069985 Test MSE 5.039836145640953 Test RE 1.0730408825103177\n",
      "34 Train Loss 2.946605 Test MSE 5.043794055983784 Test RE 1.0734621428442606\n",
      "35 Train Loss 2.8707228 Test MSE 5.023197187706074 Test RE 1.0712681023652426\n",
      "36 Train Loss 2.797257 Test MSE 5.060828755247031 Test RE 1.0752733479516936\n",
      "37 Train Loss 2.730883 Test MSE 5.112550703724842 Test RE 1.080754056667407\n",
      "38 Train Loss 2.644527 Test MSE 5.044626381757316 Test RE 1.0735507104326136\n",
      "39 Train Loss 2.584849 Test MSE 4.9397193349941455 Test RE 1.062329391343145\n",
      "40 Train Loss 2.567884 Test MSE 4.953771967093317 Test RE 1.063839388259206\n",
      "41 Train Loss 2.5418649 Test MSE 4.922053023082525 Test RE 1.060428043204288\n",
      "42 Train Loss 2.504797 Test MSE 4.85184053688295 Test RE 1.0528374378417789\n",
      "43 Train Loss 2.4713311 Test MSE 4.783328320707745 Test RE 1.045377518047112\n",
      "44 Train Loss 2.4409046 Test MSE 4.734774011541806 Test RE 1.040058308865083\n",
      "45 Train Loss 2.4042685 Test MSE 4.698509401742074 Test RE 1.0360676423921689\n",
      "46 Train Loss 2.362726 Test MSE 4.6152352162771555 Test RE 1.026845206754585\n",
      "47 Train Loss 2.3328779 Test MSE 4.595827264111842 Test RE 1.024683891332089\n",
      "48 Train Loss 2.2957737 Test MSE 4.6140785110349345 Test RE 1.0267165208254343\n",
      "49 Train Loss 2.2397926 Test MSE 4.564889590188643 Test RE 1.021229141459761\n",
      "50 Train Loss 2.193092 Test MSE 4.470933108761923 Test RE 1.0106648146784267\n",
      "51 Train Loss 2.1414378 Test MSE 4.425612723968713 Test RE 1.0055293783431272\n",
      "52 Train Loss 2.0773737 Test MSE 4.32812870533294 Test RE 0.994393195262804\n",
      "53 Train Loss 2.0342603 Test MSE 4.229718710305839 Test RE 0.9830232812070469\n",
      "54 Train Loss 1.9970242 Test MSE 4.168525556683611 Test RE 0.975886464730632\n",
      "55 Train Loss 1.9489058 Test MSE 4.113251570175129 Test RE 0.969394823657411\n",
      "56 Train Loss 1.9072366 Test MSE 3.9859420482058456 Test RE 0.954275008785056\n",
      "57 Train Loss 1.8616619 Test MSE 3.8709603058603608 Test RE 0.9404103911358445\n",
      "58 Train Loss 1.8243892 Test MSE 3.794490646921062 Test RE 0.9310752956665513\n",
      "59 Train Loss 1.7722656 Test MSE 3.6963362668268855 Test RE 0.9189540518426661\n",
      "60 Train Loss 1.7297664 Test MSE 3.543065651142349 Test RE 0.8996998749323251\n",
      "61 Train Loss 1.6936332 Test MSE 3.4269669944114676 Test RE 0.8848364835168524\n",
      "62 Train Loss 1.5835124 Test MSE 3.3586232458372343 Test RE 0.8759689354736404\n",
      "63 Train Loss 1.5226136 Test MSE 3.3343731322857875 Test RE 0.8728008473265673\n",
      "64 Train Loss 1.4782778 Test MSE 3.2681866872947354 Test RE 0.8640949929105994\n",
      "65 Train Loss 1.4396777 Test MSE 3.222498831731709 Test RE 0.8580338957951568\n",
      "66 Train Loss 1.3953718 Test MSE 3.1787669932691878 Test RE 0.8521919112974726\n",
      "67 Train Loss 1.3506236 Test MSE 3.139980464482705 Test RE 0.8469768367262376\n",
      "68 Train Loss 1.3082685 Test MSE 3.066891640032698 Test RE 0.8370613241699564\n",
      "69 Train Loss 1.269435 Test MSE 3.081035218718103 Test RE 0.8389892410889722\n",
      "70 Train Loss 1.2375453 Test MSE 3.139693627459109 Test RE 0.8469381502015698\n",
      "71 Train Loss 1.2068019 Test MSE 3.0951952392289797 Test RE 0.840914971477992\n",
      "72 Train Loss 1.1827811 Test MSE 3.0238092123983877 Test RE 0.8311611842467223\n",
      "73 Train Loss 1.1556345 Test MSE 2.9641259626484606 Test RE 0.8229176703722976\n",
      "74 Train Loss 1.1347145 Test MSE 2.97349469190902 Test RE 0.8242171445758081\n",
      "75 Train Loss 1.1141652 Test MSE 2.9668378621347857 Test RE 0.8232940308621094\n",
      "76 Train Loss 1.0913432 Test MSE 2.9667808546885226 Test RE 0.8232861210743381\n",
      "77 Train Loss 1.0788032 Test MSE 2.956129283760718 Test RE 0.8218068787316002\n",
      "78 Train Loss 1.0547396 Test MSE 2.969047363416364 Test RE 0.8236005408142493\n",
      "79 Train Loss 1.0393099 Test MSE 2.954172620948225 Test RE 0.821534856608052\n",
      "80 Train Loss 1.0308661 Test MSE 2.93510128019679 Test RE 0.8188787593041444\n",
      "81 Train Loss 1.019087 Test MSE 2.935168824754522 Test RE 0.8188881815489228\n",
      "82 Train Loss 1.0130608 Test MSE 2.9195457274042895 Test RE 0.8167059153544902\n",
      "83 Train Loss 1.007181 Test MSE 2.888601178491689 Test RE 0.8123662128034332\n",
      "84 Train Loss 0.9947834 Test MSE 2.8952338436975733 Test RE 0.813298335883712\n",
      "85 Train Loss 0.9827187 Test MSE 2.904534551793226 Test RE 0.8146036165060717\n",
      "86 Train Loss 0.973056 Test MSE 2.906660766873408 Test RE 0.8149017203165917\n",
      "87 Train Loss 0.9561888 Test MSE 2.9295477950378865 Test RE 0.8181036950430994\n",
      "88 Train Loss 0.9453263 Test MSE 2.9237432121613174 Test RE 0.8172928010673928\n",
      "89 Train Loss 0.93013203 Test MSE 2.928941016468892 Test RE 0.8180189663526651\n",
      "90 Train Loss 0.9230217 Test MSE 2.936460359419752 Test RE 0.8190683255573659\n",
      "91 Train Loss 0.91534746 Test MSE 2.914012062880094 Test RE 0.815931561997033\n",
      "92 Train Loss 0.91195726 Test MSE 2.901960592764331 Test RE 0.8142425911797307\n",
      "93 Train Loss 0.90708363 Test MSE 2.8936688823619003 Test RE 0.8130785000156413\n",
      "94 Train Loss 0.9028539 Test MSE 2.8870755644438333 Test RE 0.8121516589563528\n",
      "95 Train Loss 0.89820045 Test MSE 2.882623951124168 Test RE 0.811525284656859\n",
      "96 Train Loss 0.8901712 Test MSE 2.87461947672339 Test RE 0.8103977790996848\n",
      "97 Train Loss 0.88247144 Test MSE 2.8701252545851035 Test RE 0.8097640374315939\n",
      "98 Train Loss 0.8759543 Test MSE 2.8842221555044314 Test RE 0.8117502192244304\n",
      "99 Train Loss 0.8691214 Test MSE 2.864989323436329 Test RE 0.8090391989371583\n",
      "100 Train Loss 0.86106694 Test MSE 2.8357478469878883 Test RE 0.8048998858308724\n",
      "101 Train Loss 0.8524303 Test MSE 2.8513164329292966 Test RE 0.8071063585854159\n",
      "102 Train Loss 0.8459297 Test MSE 2.8411422819182643 Test RE 0.805665101449724\n",
      "103 Train Loss 0.8401202 Test MSE 2.824117281332737 Test RE 0.8032475775181656\n",
      "104 Train Loss 0.8318012 Test MSE 2.8310705095919135 Test RE 0.8042358031532942\n",
      "105 Train Loss 0.82863736 Test MSE 2.822651215389722 Test RE 0.8030390580638798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 0.8247942 Test MSE 2.8112633745710114 Test RE 0.8014175110577477\n",
      "107 Train Loss 0.8191725 Test MSE 2.806809470147156 Test RE 0.8007824136986296\n",
      "108 Train Loss 0.81324327 Test MSE 2.78919701263017 Test RE 0.7982660439572071\n",
      "109 Train Loss 0.8070388 Test MSE 2.7996762828821278 Test RE 0.7997642176333031\n",
      "110 Train Loss 0.80339825 Test MSE 2.807126112284183 Test RE 0.8008275814071373\n",
      "111 Train Loss 0.798745 Test MSE 2.794852344557344 Test RE 0.7990749099820184\n",
      "112 Train Loss 0.7940091 Test MSE 2.7942487748858884 Test RE 0.7989886221637037\n",
      "113 Train Loss 0.7900163 Test MSE 2.7932207673995495 Test RE 0.7988416342054769\n",
      "114 Train Loss 0.78351426 Test MSE 2.7694112977010854 Test RE 0.7954296767110597\n",
      "115 Train Loss 0.7792149 Test MSE 2.770964442546267 Test RE 0.7956526924002703\n",
      "116 Train Loss 0.7762017 Test MSE 2.782180907313952 Test RE 0.7972614098030032\n",
      "117 Train Loss 0.77283823 Test MSE 2.775609399007492 Test RE 0.7963192878557275\n",
      "118 Train Loss 0.76670915 Test MSE 2.7640233271377186 Test RE 0.794655534164793\n",
      "119 Train Loss 0.75976807 Test MSE 2.748657406455339 Test RE 0.7924436078734518\n",
      "120 Train Loss 0.75451887 Test MSE 2.7502454363843487 Test RE 0.7926724909734401\n",
      "121 Train Loss 0.74798065 Test MSE 2.7657340877737244 Test RE 0.7949014176026007\n",
      "122 Train Loss 0.7439163 Test MSE 2.782323765224405 Test RE 0.7972818782126546\n",
      "123 Train Loss 0.74030256 Test MSE 2.7747351714422175 Test RE 0.7961938705152297\n",
      "124 Train Loss 0.73780507 Test MSE 2.7606858721653644 Test RE 0.7941756308102211\n",
      "125 Train Loss 0.7343294 Test MSE 2.768821956283446 Test RE 0.7953450369546108\n",
      "126 Train Loss 0.732093 Test MSE 2.775607138882221 Test RE 0.7963189636419329\n",
      "127 Train Loss 0.7286242 Test MSE 2.788722307665093 Test RE 0.7981981109683302\n",
      "128 Train Loss 0.7266904 Test MSE 2.793749972471141 Test RE 0.7989173050989831\n",
      "129 Train Loss 0.7239548 Test MSE 2.780826484966688 Test RE 0.7970673246304938\n",
      "130 Train Loss 0.7209382 Test MSE 2.7696572904930834 Test RE 0.7954650029232179\n",
      "131 Train Loss 0.7194676 Test MSE 2.7728665185257864 Test RE 0.7959257259026735\n",
      "132 Train Loss 0.7158978 Test MSE 2.7659854256974805 Test RE 0.7949375353794312\n",
      "133 Train Loss 0.71250147 Test MSE 2.755673482626328 Test RE 0.7934543379268274\n",
      "134 Train Loss 0.7098859 Test MSE 2.7574508021921167 Test RE 0.7937101727735092\n",
      "135 Train Loss 0.7086152 Test MSE 2.7536064473439175 Test RE 0.7931566963888684\n",
      "136 Train Loss 0.7072521 Test MSE 2.75981504410452 Test RE 0.794050363937453\n",
      "137 Train Loss 0.7063547 Test MSE 2.767827803371542 Test RE 0.7952022387565074\n",
      "138 Train Loss 0.7052306 Test MSE 2.7723082390996 Test RE 0.7958455973925651\n",
      "139 Train Loss 0.7045196 Test MSE 2.7703971437318753 Test RE 0.7955712413489938\n",
      "140 Train Loss 0.703117 Test MSE 2.7732284625349233 Test RE 0.7959776705502185\n",
      "141 Train Loss 0.7015744 Test MSE 2.7701181216431037 Test RE 0.7955311771402268\n",
      "142 Train Loss 0.7002253 Test MSE 2.7589851503793845 Test RE 0.7939309669939888\n",
      "143 Train Loss 0.6990446 Test MSE 2.7578510468361483 Test RE 0.7937677742941568\n",
      "144 Train Loss 0.69755214 Test MSE 2.7519011753821796 Test RE 0.7929110626408925\n",
      "145 Train Loss 0.6957488 Test MSE 2.748580245886071 Test RE 0.7924324850196398\n",
      "146 Train Loss 0.6944854 Test MSE 2.7510990056345244 Test RE 0.792795488791253\n",
      "147 Train Loss 0.69219947 Test MSE 2.747753038938506 Test RE 0.792313231636845\n",
      "148 Train Loss 0.6899061 Test MSE 2.7553751900401746 Test RE 0.7934113923541222\n",
      "149 Train Loss 0.68616086 Test MSE 2.76849512687607 Test RE 0.7952980946407886\n",
      "Training time: 228.92\n",
      "9\n",
      "KG_rowdy_tune64\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 62.561523 Test MSE 6.259890432696707 Test RE 1.1958905282354262\n",
      "1 Train Loss 47.71375 Test MSE 8.891392757003725 Test RE 1.4252562613563542\n",
      "2 Train Loss 41.054615 Test MSE 9.026771652972036 Test RE 1.4360656310595756\n",
      "3 Train Loss 34.15295 Test MSE 9.217092491767197 Test RE 1.4511256978834663\n",
      "4 Train Loss 30.098541 Test MSE 8.736286862199744 Test RE 1.41277012726078\n",
      "5 Train Loss 28.091492 Test MSE 8.510973077069904 Test RE 1.394433053294509\n",
      "6 Train Loss 26.512566 Test MSE 8.842390686647716 Test RE 1.4213234129549528\n",
      "7 Train Loss 25.108404 Test MSE 9.17655575452301 Test RE 1.4479311590082773\n",
      "8 Train Loss 23.88342 Test MSE 9.250404457618417 Test RE 1.4537456266519508\n",
      "9 Train Loss 23.33688 Test MSE 9.188435730862565 Test RE 1.4488681022764531\n",
      "10 Train Loss 22.263697 Test MSE 9.07669213983525 Test RE 1.4400310716582072\n",
      "11 Train Loss 21.692612 Test MSE 8.961609731646861 Test RE 1.430872950429976\n",
      "12 Train Loss 20.79426 Test MSE 8.989360180515364 Test RE 1.4330866528762862\n",
      "13 Train Loss 20.325237 Test MSE 8.866566445028344 Test RE 1.42326508901883\n",
      "14 Train Loss 19.790028 Test MSE 9.016108762312799 Test RE 1.4352172028463912\n",
      "15 Train Loss 19.250984 Test MSE 9.078253465647181 Test RE 1.4401549196949215\n",
      "16 Train Loss 18.66961 Test MSE 8.745785953170872 Test RE 1.413537981281886\n",
      "17 Train Loss 18.073305 Test MSE 8.860400266567328 Test RE 1.422770104125938\n",
      "18 Train Loss 17.251314 Test MSE 8.926240694637467 Test RE 1.4280465256450485\n",
      "19 Train Loss 16.682938 Test MSE 8.67280323368382 Test RE 1.4076277079074166\n",
      "20 Train Loss 15.761906 Test MSE 8.657982458691484 Test RE 1.4064244606233078\n",
      "21 Train Loss 15.190886 Test MSE 8.557845166239224 Test RE 1.3982675295790776\n",
      "22 Train Loss 14.519358 Test MSE 8.612400169666483 Test RE 1.402717324004164\n",
      "23 Train Loss 13.53517 Test MSE 8.291564471436686 Test RE 1.3763418047655265\n",
      "24 Train Loss 12.639322 Test MSE 8.055445275788996 Test RE 1.3566031966967609\n",
      "25 Train Loss 11.326214 Test MSE 7.678026813727959 Test RE 1.3244417807131754\n",
      "26 Train Loss 10.62633 Test MSE 7.0668010491314845 Test RE 1.2706311344314347\n",
      "27 Train Loss 9.108306 Test MSE 6.042746834816074 Test RE 1.1749658929971438\n",
      "28 Train Loss 7.8252993 Test MSE 5.839495641464294 Test RE 1.1550365561739167\n",
      "29 Train Loss 7.0958524 Test MSE 5.8260033396253235 Test RE 1.153701413972611\n",
      "30 Train Loss 5.777199 Test MSE 5.60711644297688 Test RE 1.1318212611956344\n",
      "31 Train Loss 5.25165 Test MSE 5.649110985477798 Test RE 1.136051747006114\n",
      "32 Train Loss 4.615719 Test MSE 5.913097459412198 Test RE 1.1622928837979762\n",
      "33 Train Loss 4.362441 Test MSE 6.0330214947365075 Test RE 1.1740200032713655\n",
      "34 Train Loss 4.0646496 Test MSE 5.962491877595102 Test RE 1.1671373317057365\n",
      "35 Train Loss 3.8137364 Test MSE 6.014760748246652 Test RE 1.1722418951735765\n",
      "36 Train Loss 3.562607 Test MSE 6.006655606199301 Test RE 1.1714518063868087\n",
      "37 Train Loss 3.3309565 Test MSE 5.874244903996758 Test RE 1.158468114083038\n",
      "38 Train Loss 3.1591065 Test MSE 5.860353739517006 Test RE 1.157097555284105\n",
      "39 Train Loss 3.0660799 Test MSE 5.920627188200579 Test RE 1.1630326793031305\n",
      "40 Train Loss 2.8957283 Test MSE 5.966821786646351 Test RE 1.16756103721877\n",
      "41 Train Loss 2.763269 Test MSE 6.007007385364385 Test RE 1.1714861088616004\n",
      "42 Train Loss 2.6458104 Test MSE 5.962715279734401 Test RE 1.1671591966021424\n",
      "43 Train Loss 2.58392 Test MSE 5.949735899440769 Test RE 1.1658881937726466\n",
      "44 Train Loss 2.498467 Test MSE 6.037077273552036 Test RE 1.1744145622394466\n",
      "45 Train Loss 2.4150715 Test MSE 6.074754915003215 Test RE 1.1780736461952548\n",
      "46 Train Loss 2.3525662 Test MSE 6.041306723920039 Test RE 1.1748258753811747\n",
      "47 Train Loss 2.2985175 Test MSE 6.018511107472691 Test RE 1.172607299825409\n",
      "48 Train Loss 2.2451146 Test MSE 5.945160947550449 Test RE 1.1654398622642461\n",
      "49 Train Loss 2.1821446 Test MSE 5.887609640388498 Test RE 1.1597852046140193\n",
      "50 Train Loss 2.1362243 Test MSE 5.8133307272788874 Test RE 1.1524459761450798\n",
      "51 Train Loss 2.090607 Test MSE 5.8564072090037795 Test RE 1.1567078783057814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 2.0617237 Test MSE 5.8979952721505295 Test RE 1.1608076734630492\n",
      "53 Train Loss 2.007977 Test MSE 5.907536924876104 Test RE 1.1617462591324852\n",
      "54 Train Loss 1.9531634 Test MSE 5.961240008640649 Test RE 1.1670148007470766\n",
      "55 Train Loss 1.9277267 Test MSE 5.963828871665708 Test RE 1.167268180372457\n",
      "56 Train Loss 1.8992323 Test MSE 5.9097876794325375 Test RE 1.1619675490464112\n",
      "57 Train Loss 1.874867 Test MSE 5.934900282395958 Test RE 1.1644337202638761\n",
      "58 Train Loss 1.8316433 Test MSE 5.93616036822957 Test RE 1.1645573287906184\n",
      "59 Train Loss 1.7908485 Test MSE 5.895757755118269 Test RE 1.1605874653072428\n",
      "60 Train Loss 1.7597227 Test MSE 5.939734971019347 Test RE 1.1649079092264187\n",
      "61 Train Loss 1.728278 Test MSE 5.878046088355815 Test RE 1.1588428719286024\n",
      "62 Train Loss 1.7061598 Test MSE 5.863370549008559 Test RE 1.1573953439428233\n",
      "63 Train Loss 1.6833932 Test MSE 5.90304834363147 Test RE 1.1613048244506488\n",
      "64 Train Loss 1.6530943 Test MSE 5.880091771917863 Test RE 1.1590445052228513\n",
      "65 Train Loss 1.6286138 Test MSE 5.889308864959284 Test RE 1.1599525554969554\n",
      "66 Train Loss 1.6153008 Test MSE 5.908565617344352 Test RE 1.16184740345211\n",
      "67 Train Loss 1.6060506 Test MSE 5.87395490541015 Test RE 1.158439518215175\n",
      "68 Train Loss 1.5973873 Test MSE 5.862831885152194 Test RE 1.1573421781609858\n",
      "69 Train Loss 1.5863059 Test MSE 5.860128642269167 Test RE 1.1570753329074477\n",
      "70 Train Loss 1.5735083 Test MSE 5.864245132436052 Test RE 1.1574816595726047\n",
      "71 Train Loss 1.5663539 Test MSE 5.871257245051539 Test RE 1.15817347639983\n",
      "72 Train Loss 1.5556309 Test MSE 5.8538791724485595 Test RE 1.1564581931885825\n",
      "73 Train Loss 1.538267 Test MSE 5.834689810056657 Test RE 1.154561168070887\n",
      "74 Train Loss 1.5203208 Test MSE 5.852450724520581 Test RE 1.1563170866634054\n",
      "75 Train Loss 1.5063862 Test MSE 5.862722714498349 Test RE 1.1573314027888644\n",
      "76 Train Loss 1.4944642 Test MSE 5.817819695038684 Test RE 1.1528908411265224\n",
      "77 Train Loss 1.482578 Test MSE 5.802517988941434 Test RE 1.1513737081848048\n",
      "78 Train Loss 1.4719459 Test MSE 5.799435113466031 Test RE 1.151067805353692\n",
      "79 Train Loss 1.461867 Test MSE 5.780194700227781 Test RE 1.1491568071894624\n",
      "80 Train Loss 1.452514 Test MSE 5.780842071406193 Test RE 1.1492211571124729\n",
      "81 Train Loss 1.4394923 Test MSE 5.799553001971401 Test RE 1.1510795045080842\n",
      "82 Train Loss 1.4228675 Test MSE 5.773328932742308 Test RE 1.1484741149834778\n",
      "83 Train Loss 1.4086045 Test MSE 5.788171667645684 Test RE 1.1499494816930853\n",
      "84 Train Loss 1.3982096 Test MSE 5.78998721277533 Test RE 1.1501298168325946\n",
      "85 Train Loss 1.3861881 Test MSE 5.783187692493627 Test RE 1.1494542861236545\n",
      "86 Train Loss 1.3763586 Test MSE 5.799217275381149 Test RE 1.1510461869756894\n",
      "87 Train Loss 1.3655691 Test MSE 5.789878086483715 Test RE 1.150118978294566\n",
      "88 Train Loss 1.3548865 Test MSE 5.797274545768714 Test RE 1.1508533714010631\n",
      "89 Train Loss 1.3435262 Test MSE 5.793067370086233 Test RE 1.150435699178565\n",
      "90 Train Loss 1.3345969 Test MSE 5.76822388148242 Test RE 1.1479662350446045\n",
      "91 Train Loss 1.3261721 Test MSE 5.797034158490872 Test RE 1.1508295107597493\n",
      "92 Train Loss 1.3184483 Test MSE 5.810619793550431 Test RE 1.1521772344265613\n",
      "93 Train Loss 1.3058766 Test MSE 5.793187019943535 Test RE 1.1504475796511797\n",
      "94 Train Loss 1.2988472 Test MSE 5.801201437715214 Test RE 1.1512430814066077\n",
      "95 Train Loss 1.293121 Test MSE 5.797081323730431 Test RE 1.1508341923812195\n",
      "96 Train Loss 1.2800044 Test MSE 5.771528648557601 Test RE 1.1482950379711363\n",
      "97 Train Loss 1.2657714 Test MSE 5.756468040039508 Test RE 1.1467958408026568\n",
      "98 Train Loss 1.2581302 Test MSE 5.762969826580691 Test RE 1.1474432966293526\n",
      "99 Train Loss 1.2458106 Test MSE 5.78303882023195 Test RE 1.1494394912588115\n",
      "100 Train Loss 1.2377559 Test MSE 5.771690068753495 Test RE 1.1483110958238505\n",
      "101 Train Loss 1.2300555 Test MSE 5.7602821927892105 Test RE 1.1471757030873684\n",
      "102 Train Loss 1.2197026 Test MSE 5.756368532738239 Test RE 1.1467859289042857\n",
      "103 Train Loss 1.201706 Test MSE 5.739533405037498 Test RE 1.1451077507296183\n",
      "104 Train Loss 1.1939039 Test MSE 5.737392000969768 Test RE 1.1448941125306102\n",
      "105 Train Loss 1.1840628 Test MSE 5.743401072712787 Test RE 1.14549350947097\n",
      "106 Train Loss 1.1769563 Test MSE 5.7496714605733 Test RE 1.146118638130821\n",
      "107 Train Loss 1.1692791 Test MSE 5.750026875382985 Test RE 1.146154061132431\n",
      "108 Train Loss 1.1627154 Test MSE 5.756080008729936 Test RE 1.1467571886128\n",
      "109 Train Loss 1.1566701 Test MSE 5.757396409063297 Test RE 1.1468883112903037\n",
      "110 Train Loss 1.149934 Test MSE 5.751941699742062 Test RE 1.1463448864172368\n",
      "111 Train Loss 1.1441067 Test MSE 5.783229308636423 Test RE 1.1494584218849508\n",
      "112 Train Loss 1.1374556 Test MSE 5.789567135908317 Test RE 1.1500880937962594\n",
      "113 Train Loss 1.1310669 Test MSE 5.783822381525309 Test RE 1.1495173591251975\n",
      "114 Train Loss 1.1226158 Test MSE 5.791757330922759 Test RE 1.1503056125647904\n",
      "115 Train Loss 1.1165649 Test MSE 5.7923440728272455 Test RE 1.1503638777315115\n",
      "116 Train Loss 1.1116598 Test MSE 5.79660657791541 Test RE 1.150787068244751\n",
      "117 Train Loss 1.1091232 Test MSE 5.789563042376374 Test RE 1.1500876872094565\n",
      "118 Train Loss 1.1058428 Test MSE 5.791657879799555 Test RE 1.1502957364883466\n",
      "119 Train Loss 1.104288 Test MSE 5.806208974710306 Test RE 1.1517398447814167\n",
      "120 Train Loss 1.1014338 Test MSE 5.804507416554644 Test RE 1.1515710689126761\n",
      "121 Train Loss 1.0974807 Test MSE 5.8029452809684985 Test RE 1.1514161004488048\n",
      "122 Train Loss 1.094233 Test MSE 5.825041645842041 Test RE 1.1536061897508711\n",
      "123 Train Loss 1.088403 Test MSE 5.827051614484389 Test RE 1.1538052022576288\n",
      "124 Train Loss 1.08317 Test MSE 5.834249326682206 Test RE 1.1545175860969838\n",
      "125 Train Loss 1.077683 Test MSE 5.825222124451446 Test RE 1.1536240608358284\n",
      "126 Train Loss 1.0733932 Test MSE 5.8085612888368425 Test RE 1.1519731277694318\n",
      "127 Train Loss 1.0696423 Test MSE 5.82787107869609 Test RE 1.1538863298066613\n",
      "128 Train Loss 1.0652509 Test MSE 5.83237546326385 Test RE 1.154332165326475\n",
      "129 Train Loss 1.061841 Test MSE 5.827009831355092 Test RE 1.1538010655447972\n",
      "130 Train Loss 1.0587883 Test MSE 5.8444366251301725 Test RE 1.155525109500786\n",
      "131 Train Loss 1.053155 Test MSE 5.8349857479910145 Test RE 1.1545904476149484\n",
      "132 Train Loss 1.0455124 Test MSE 5.824855724247466 Test RE 1.153587779409211\n",
      "133 Train Loss 1.0413488 Test MSE 5.853889246671529 Test RE 1.1564591882904918\n",
      "134 Train Loss 1.0375466 Test MSE 5.8643587584071 Test RE 1.157492873235872\n",
      "135 Train Loss 1.0346742 Test MSE 5.861206386277735 Test RE 1.1571817276432215\n",
      "136 Train Loss 1.029434 Test MSE 5.871647388625504 Test RE 1.1582119559293707\n",
      "137 Train Loss 1.0257627 Test MSE 5.856941023269061 Test RE 1.1567605943374881\n",
      "138 Train Loss 1.0230597 Test MSE 5.857457144081318 Test RE 1.156811560794469\n",
      "139 Train Loss 1.0208204 Test MSE 5.869697904379861 Test RE 1.1580196671848975\n",
      "140 Train Loss 1.0186892 Test MSE 5.868833694909205 Test RE 1.1579344150629745\n",
      "141 Train Loss 1.0145719 Test MSE 5.877407630151921 Test RE 1.1587799349577668\n",
      "142 Train Loss 1.0115176 Test MSE 5.889128058445768 Test RE 1.1599347496226216\n",
      "143 Train Loss 1.0073858 Test MSE 5.8899941656757 Test RE 1.16002004161562\n",
      "144 Train Loss 1.0043442 Test MSE 5.882569201925862 Test RE 1.15928864675663\n",
      "145 Train Loss 1.0017002 Test MSE 5.891892775127115 Test RE 1.160206989810846\n",
      "146 Train Loss 0.9980183 Test MSE 5.881706082558157 Test RE 1.1592035953823479\n",
      "147 Train Loss 0.99356675 Test MSE 5.884164800361968 Test RE 1.1594458598443385\n",
      "148 Train Loss 0.98856425 Test MSE 5.90640740521145 Test RE 1.1616351910180136\n",
      "149 Train Loss 0.983478 Test MSE 5.9098951744287085 Test RE 1.1619781166958787\n",
      "Training time: 228.69\n",
      "0\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 67.40691 Test MSE 5.2391068242291965 Test RE 1.094048782408281\n",
      "1 Train Loss 48.074234 Test MSE 8.613562607385157 Test RE 1.4028119849858327\n",
      "2 Train Loss 35.662468 Test MSE 8.93709038078412 Test RE 1.4289141446051796\n",
      "3 Train Loss 29.693394 Test MSE 9.356749765816437 Test RE 1.4620780857656983\n",
      "4 Train Loss 24.822521 Test MSE 9.669051086728624 Test RE 1.4862777889231604\n",
      "5 Train Loss 21.16857 Test MSE 9.67265825589872 Test RE 1.4865550010012387\n",
      "6 Train Loss 18.39309 Test MSE 9.503266690060528 Test RE 1.4734809275461416\n",
      "7 Train Loss 16.303469 Test MSE 9.09187287052151 Test RE 1.4412347916194468\n",
      "8 Train Loss 13.892609 Test MSE 8.939403762424522 Test RE 1.4290990711147065\n",
      "9 Train Loss 12.643314 Test MSE 8.634271273042481 Test RE 1.404497287919638\n",
      "10 Train Loss 10.861856 Test MSE 7.720319827902178 Test RE 1.3280844946208272\n",
      "11 Train Loss 8.100634 Test MSE 6.6330266353376865 Test RE 1.2310166611082252\n",
      "12 Train Loss 5.991326 Test MSE 6.1424576870556695 Test RE 1.1846202357741653\n",
      "13 Train Loss 4.805609 Test MSE 5.858178330572426 Test RE 1.156882773538484\n",
      "14 Train Loss 3.6761742 Test MSE 5.716847807596232 Test RE 1.1428424817997087\n",
      "15 Train Loss 3.1100142 Test MSE 5.4274789068911 Test RE 1.1135433596014115\n",
      "16 Train Loss 2.5565872 Test MSE 5.035240283713259 Test RE 1.0725515141670425\n",
      "17 Train Loss 2.2031589 Test MSE 4.641479058722769 Test RE 1.029760568771827\n",
      "18 Train Loss 1.9602723 Test MSE 4.189536534413365 Test RE 0.9783427956295189\n",
      "19 Train Loss 1.7350113 Test MSE 3.9323851759097326 Test RE 0.9478422979414235\n",
      "20 Train Loss 1.5384953 Test MSE 3.52870840781152 Test RE 0.8978751384340142\n",
      "21 Train Loss 1.3877512 Test MSE 3.2726487901383727 Test RE 0.8646846724389174\n",
      "22 Train Loss 1.2494184 Test MSE 3.1130793342722543 Test RE 0.8433408833733592\n",
      "23 Train Loss 1.1365713 Test MSE 2.924597627853924 Test RE 0.8174122125092055\n",
      "24 Train Loss 1.037979 Test MSE 2.839501951311824 Test RE 0.8054324929074028\n",
      "25 Train Loss 0.97028863 Test MSE 2.7515097072696935 Test RE 0.7928546633705464\n",
      "26 Train Loss 0.92851734 Test MSE 2.7276929417625215 Test RE 0.7894157741378874\n",
      "27 Train Loss 0.8956496 Test MSE 2.692239647667603 Test RE 0.7842687638526918\n",
      "28 Train Loss 0.8608632 Test MSE 2.6749309991394283 Test RE 0.7817436318597816\n",
      "29 Train Loss 0.82775927 Test MSE 2.668307762044064 Test RE 0.7807752176409862\n",
      "30 Train Loss 0.7974858 Test MSE 2.6118540058491697 Test RE 0.7724715779221847\n",
      "31 Train Loss 0.7789861 Test MSE 2.6016087889340755 Test RE 0.7709550469280073\n",
      "32 Train Loss 0.7589631 Test MSE 2.6128266054453637 Test RE 0.7726153906340542\n",
      "33 Train Loss 0.74016213 Test MSE 2.5767604485932263 Test RE 0.7672644620981426\n",
      "34 Train Loss 0.7252344 Test MSE 2.570772468364034 Test RE 0.7663724434627929\n",
      "35 Train Loss 0.7120329 Test MSE 2.556963020927745 Test RE 0.7643113060317221\n",
      "36 Train Loss 0.700389 Test MSE 2.586356896161787 Test RE 0.7686918688510115\n",
      "37 Train Loss 0.6895257 Test MSE 2.5681755815006753 Test RE 0.7659852669605596\n",
      "38 Train Loss 0.67881393 Test MSE 2.586794819395626 Test RE 0.7687569437409527\n",
      "39 Train Loss 0.6677023 Test MSE 2.584590990830267 Test RE 0.7684294014287085\n",
      "40 Train Loss 0.65849787 Test MSE 2.5847329820742027 Test RE 0.7684505089750185\n",
      "41 Train Loss 0.6520933 Test MSE 2.5880539627252466 Test RE 0.7689440203128504\n",
      "42 Train Loss 0.64379436 Test MSE 2.5977030659804843 Test RE 0.7703761228755315\n",
      "43 Train Loss 0.6366855 Test MSE 2.6016376738884253 Test RE 0.7709593267681623\n",
      "44 Train Loss 0.6286043 Test MSE 2.6037690362758408 Test RE 0.7712750619920914\n",
      "45 Train Loss 0.62066305 Test MSE 2.6183813112806034 Test RE 0.7734362205899522\n",
      "46 Train Loss 0.61483765 Test MSE 2.636186762377385 Test RE 0.7760615158552199\n",
      "47 Train Loss 0.6078351 Test MSE 2.6578654473412002 Test RE 0.7792459538497395\n",
      "48 Train Loss 0.599764 Test MSE 2.6569434993416814 Test RE 0.7791107915222548\n",
      "49 Train Loss 0.5921164 Test MSE 2.6842281902628824 Test RE 0.7831009968889097\n",
      "50 Train Loss 0.584622 Test MSE 2.6728422083595436 Test RE 0.7814383496322015\n",
      "51 Train Loss 0.578407 Test MSE 2.6973379394652213 Test RE 0.7850109971533691\n",
      "52 Train Loss 0.5717907 Test MSE 2.706622709410872 Test RE 0.7863609179286966\n",
      "53 Train Loss 0.56602395 Test MSE 2.729924751764318 Test RE 0.789738659781886\n",
      "54 Train Loss 0.5583951 Test MSE 2.749316110109256 Test RE 0.7925385549973943\n",
      "55 Train Loss 0.55403906 Test MSE 2.7570372750336976 Test RE 0.793650655298419\n",
      "56 Train Loss 0.54816306 Test MSE 2.753341629443342 Test RE 0.7931185560181527\n",
      "57 Train Loss 0.54309154 Test MSE 2.766304514891619 Test RE 0.7949833867892154\n",
      "58 Train Loss 0.53788084 Test MSE 2.7691814627342968 Test RE 0.7953966694530423\n",
      "59 Train Loss 0.53279126 Test MSE 2.7970871544714417 Test RE 0.7993943228648119\n",
      "60 Train Loss 0.5266942 Test MSE 2.799241010927581 Test RE 0.7997020446478191\n",
      "61 Train Loss 0.52013266 Test MSE 2.8136477283079686 Test RE 0.8017572974070214\n",
      "62 Train Loss 0.5130055 Test MSE 2.818958266470977 Test RE 0.8025135675556311\n",
      "63 Train Loss 0.50597423 Test MSE 2.837790264762144 Test RE 0.8051896940262007\n",
      "64 Train Loss 0.4997511 Test MSE 2.85989957483012 Test RE 0.8083202369880533\n",
      "65 Train Loss 0.4932903 Test MSE 2.8722353123926068 Test RE 0.8100616437818874\n",
      "66 Train Loss 0.48796907 Test MSE 2.890016008742185 Test RE 0.8125651360048876\n",
      "67 Train Loss 0.48175395 Test MSE 2.9128133608776947 Test RE 0.8157637247712708\n",
      "68 Train Loss 0.47668225 Test MSE 2.9349468694378826 Test RE 0.8188572191013288\n",
      "69 Train Loss 0.47067454 Test MSE 2.9662286955975508 Test RE 0.8232095050228672\n",
      "70 Train Loss 0.46466976 Test MSE 2.9679890791215326 Test RE 0.8234537460526508\n",
      "71 Train Loss 0.45675814 Test MSE 2.992181974376419 Test RE 0.8268030336409771\n",
      "72 Train Loss 0.4510182 Test MSE 3.0102678262935 Test RE 0.8292980204713732\n",
      "73 Train Loss 0.44519216 Test MSE 3.0205794528001415 Test RE 0.8307171800406221\n",
      "74 Train Loss 0.43958315 Test MSE 3.037925074383345 Test RE 0.8330989546243543\n",
      "75 Train Loss 0.4332916 Test MSE 3.0512546525229145 Test RE 0.8349246584730637\n",
      "76 Train Loss 0.42846245 Test MSE 3.0566544898371113 Test RE 0.8356631193581038\n",
      "77 Train Loss 0.4234976 Test MSE 3.0736350164932067 Test RE 0.8379810697786862\n",
      "78 Train Loss 0.41835076 Test MSE 3.0849167140336444 Test RE 0.8395175550446111\n",
      "79 Train Loss 0.41440874 Test MSE 3.101692679413324 Test RE 0.8417971339764185\n",
      "80 Train Loss 0.40933496 Test MSE 3.1214690815211106 Test RE 0.8444765203823297\n",
      "81 Train Loss 0.4046225 Test MSE 3.131468355524174 Test RE 0.8458280315191918\n",
      "82 Train Loss 0.39961365 Test MSE 3.1688463448907367 Test RE 0.8508610646342181\n",
      "83 Train Loss 0.39572468 Test MSE 3.179676587854662 Test RE 0.8523138286487959\n",
      "84 Train Loss 0.39166048 Test MSE 3.199102042304038 Test RE 0.8549133655593086\n",
      "85 Train Loss 0.38798594 Test MSE 3.219997074025998 Test RE 0.857700767715605\n",
      "86 Train Loss 0.38412732 Test MSE 3.2262341413454543 Test RE 0.8585310401235337\n",
      "87 Train Loss 0.37984565 Test MSE 3.2554540997791817 Test RE 0.862410128644691\n",
      "88 Train Loss 0.37605864 Test MSE 3.269948403638102 Test RE 0.8643278567773953\n",
      "89 Train Loss 0.37209654 Test MSE 3.263216649638133 Test RE 0.8634377142671248\n",
      "90 Train Loss 0.36848146 Test MSE 3.2692122612417127 Test RE 0.8642305610229992\n",
      "91 Train Loss 0.36494717 Test MSE 3.2746000562457755 Test RE 0.8649424114420736\n",
      "92 Train Loss 0.36143664 Test MSE 3.276417672190342 Test RE 0.8651824277788274\n",
      "93 Train Loss 0.3581579 Test MSE 3.286804190669026 Test RE 0.8665526930593673\n",
      "94 Train Loss 0.3556232 Test MSE 3.2826127012774573 Test RE 0.8659999821401995\n",
      "95 Train Loss 0.3526281 Test MSE 3.2900016040284825 Test RE 0.8669740831820101\n",
      "96 Train Loss 0.34931803 Test MSE 3.307247749321827 Test RE 0.8692434464673241\n",
      "97 Train Loss 0.34635764 Test MSE 3.321294813437675 Test RE 0.8710874843824379\n",
      "98 Train Loss 0.34407148 Test MSE 3.324875920503941 Test RE 0.8715569725344455\n",
      "99 Train Loss 0.34133437 Test MSE 3.328201843875733 Test RE 0.8719927793472723\n",
      "100 Train Loss 0.33813983 Test MSE 3.3374800248913568 Test RE 0.8732073805804355\n",
      "101 Train Loss 0.33520365 Test MSE 3.331588091348777 Test RE 0.8724362669714503\n",
      "102 Train Loss 0.33270806 Test MSE 3.3469502017247192 Test RE 0.8744453760709057\n",
      "103 Train Loss 0.3298294 Test MSE 3.3588187085051984 Test RE 0.8759944245984392\n",
      "104 Train Loss 0.32714954 Test MSE 3.3572475330304923 Test RE 0.875789515958243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 Train Loss 0.32470804 Test MSE 3.36281216732015 Test RE 0.8765150255551772\n",
      "106 Train Loss 0.32260233 Test MSE 3.3752716194610963 Test RE 0.8781372987442698\n",
      "107 Train Loss 0.32004654 Test MSE 3.374557417443138 Test RE 0.8780443876126729\n",
      "108 Train Loss 0.3177521 Test MSE 3.3719059462988437 Test RE 0.8776993695018841\n",
      "109 Train Loss 0.31538874 Test MSE 3.3787508095805614 Test RE 0.8785897689519279\n",
      "110 Train Loss 0.31328827 Test MSE 3.400188548786424 Test RE 0.8813726312320495\n",
      "111 Train Loss 0.31079143 Test MSE 3.4042366447868333 Test RE 0.8818971344571311\n",
      "112 Train Loss 0.30943906 Test MSE 3.4078997788304473 Test RE 0.8823714902631952\n",
      "113 Train Loss 0.3075626 Test MSE 3.417461831728305 Test RE 0.8836085238125027\n",
      "114 Train Loss 0.3057814 Test MSE 3.413000628836406 Test RE 0.8830315979523449\n",
      "115 Train Loss 0.30407497 Test MSE 3.415383224176008 Test RE 0.8833397637198978\n",
      "116 Train Loss 0.30205476 Test MSE 3.4187796488161344 Test RE 0.8837788727784004\n",
      "117 Train Loss 0.3000133 Test MSE 3.425793627000776 Test RE 0.8846849899101613\n",
      "118 Train Loss 0.2982234 Test MSE 3.442368404569269 Test RE 0.8868225622514969\n",
      "119 Train Loss 0.29664338 Test MSE 3.44053173189373 Test RE 0.8865859489817592\n",
      "120 Train Loss 0.29512355 Test MSE 3.437549474607786 Test RE 0.8862016187645012\n",
      "121 Train Loss 0.29339385 Test MSE 3.448091915393329 Test RE 0.887559501166038\n",
      "122 Train Loss 0.29147327 Test MSE 3.4491914454195847 Test RE 0.88770100269198\n",
      "123 Train Loss 0.28943598 Test MSE 3.4520792399954376 Test RE 0.8880725335044927\n",
      "124 Train Loss 0.28746164 Test MSE 3.442912295379651 Test RE 0.8868926180292012\n",
      "125 Train Loss 0.28579003 Test MSE 3.436731666433549 Test RE 0.886096196858109\n",
      "126 Train Loss 0.28457797 Test MSE 3.43354957737951 Test RE 0.8856858811476708\n",
      "127 Train Loss 0.28304523 Test MSE 3.4379137336660315 Test RE 0.8862485705856118\n",
      "128 Train Loss 0.28088072 Test MSE 3.4321709597849903 Test RE 0.8855080557369152\n",
      "129 Train Loss 0.27936992 Test MSE 3.428326372977334 Test RE 0.8850119606215151\n",
      "130 Train Loss 0.27739277 Test MSE 3.433506371583532 Test RE 0.8856803086514823\n",
      "131 Train Loss 0.2751546 Test MSE 3.4322778462952845 Test RE 0.8855218441131548\n",
      "132 Train Loss 0.27330524 Test MSE 3.4391118410299124 Test RE 0.8864029852286622\n",
      "133 Train Loss 0.2714068 Test MSE 3.4399652878672407 Test RE 0.8865129628816406\n",
      "134 Train Loss 0.2695795 Test MSE 3.4385767868216304 Test RE 0.8863340296207005\n",
      "135 Train Loss 0.26795503 Test MSE 3.4525500602579546 Test RE 0.8881330924109657\n",
      "136 Train Loss 0.26667854 Test MSE 3.4539883081224088 Test RE 0.8883180604056592\n",
      "137 Train Loss 0.26579016 Test MSE 3.4582143142138055 Test RE 0.8888613294646892\n",
      "138 Train Loss 0.26458395 Test MSE 3.459165187274628 Test RE 0.8889835220365464\n",
      "139 Train Loss 0.2635869 Test MSE 3.4571034118595074 Test RE 0.8887185509427862\n",
      "140 Train Loss 0.26280487 Test MSE 3.4615934348805095 Test RE 0.8892954894176387\n",
      "141 Train Loss 0.2619363 Test MSE 3.4647930673468785 Test RE 0.889706392886727\n",
      "142 Train Loss 0.26108074 Test MSE 3.4594122716417015 Test RE 0.88901527102752\n",
      "143 Train Loss 0.2600845 Test MSE 3.4672078465132894 Test RE 0.8900163782469068\n",
      "144 Train Loss 0.2589455 Test MSE 3.46634205003785 Test RE 0.8899052483134791\n",
      "145 Train Loss 0.25792384 Test MSE 3.473915963488599 Test RE 0.8908769336679986\n",
      "146 Train Loss 0.25688767 Test MSE 3.4708027031632587 Test RE 0.8904776503351114\n",
      "147 Train Loss 0.2558695 Test MSE 3.4662477712616937 Test RE 0.8898931462550295\n",
      "148 Train Loss 0.25473434 Test MSE 3.4696457275104873 Test RE 0.8903292197094951\n",
      "149 Train Loss 0.2539398 Test MSE 3.4689496874932106 Test RE 0.8902399114779423\n",
      "Training time: 227.67\n",
      "1\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 61.002213 Test MSE 8.238122040893307 Test RE 1.371899099293131\n",
      "1 Train Loss 53.947113 Test MSE 8.391510734656274 Test RE 1.384612147705408\n",
      "2 Train Loss 47.577328 Test MSE 8.768873037935725 Test RE 1.4154024770896798\n",
      "3 Train Loss 41.019493 Test MSE 8.729726568744043 Test RE 1.4122395856618373\n",
      "4 Train Loss 38.059128 Test MSE 8.817274329698444 Test RE 1.4193033793787406\n",
      "5 Train Loss 34.737938 Test MSE 8.660363215141748 Test RE 1.4066178153669189\n",
      "6 Train Loss 32.666283 Test MSE 8.808241377230633 Test RE 1.418576182702538\n",
      "7 Train Loss 30.586891 Test MSE 8.95438293135698 Test RE 1.43029589346583\n",
      "8 Train Loss 28.326647 Test MSE 8.885894656085206 Test RE 1.424815530935856\n",
      "9 Train Loss 26.393906 Test MSE 8.709097084948946 Test RE 1.410569945409513\n",
      "10 Train Loss 23.738699 Test MSE 8.907983019064593 Test RE 1.4265853194663958\n",
      "11 Train Loss 21.33896 Test MSE 8.81427079926355 Test RE 1.419061621901838\n",
      "12 Train Loss 18.859335 Test MSE 8.762223993848098 Test RE 1.4148657571424956\n",
      "13 Train Loss 16.893015 Test MSE 8.643069705276307 Test RE 1.4052127060100739\n",
      "14 Train Loss 15.293753 Test MSE 8.513960013467827 Test RE 1.3946777208215075\n",
      "15 Train Loss 13.600879 Test MSE 8.560577935206393 Test RE 1.3984907655126944\n",
      "16 Train Loss 11.878211 Test MSE 8.649956963582795 Test RE 1.40577246868587\n",
      "17 Train Loss 10.591463 Test MSE 8.558378093382725 Test RE 1.3983110664218876\n",
      "18 Train Loss 9.512264 Test MSE 8.344221628192315 Test RE 1.3807052481766222\n",
      "19 Train Loss 8.530454 Test MSE 8.119524988724041 Test RE 1.3619882837275694\n",
      "20 Train Loss 7.507374 Test MSE 8.121968436185261 Test RE 1.3621932031337318\n",
      "21 Train Loss 6.2380834 Test MSE 7.658374638576617 Test RE 1.3227457174648984\n",
      "22 Train Loss 5.260026 Test MSE 7.168448524930658 Test RE 1.2797367620583995\n",
      "23 Train Loss 4.1698365 Test MSE 7.091969188587041 Test RE 1.2728917753202467\n",
      "24 Train Loss 3.4102747 Test MSE 6.907549329539517 Test RE 1.2562325953532916\n",
      "25 Train Loss 2.886799 Test MSE 6.851843428551582 Test RE 1.2511569003062557\n",
      "26 Train Loss 2.4185247 Test MSE 6.770164337855008 Test RE 1.2436771801993483\n",
      "27 Train Loss 2.1235616 Test MSE 6.605302764918773 Test RE 1.228441344852015\n",
      "28 Train Loss 1.9053466 Test MSE 6.5469521257518375 Test RE 1.2230033393813473\n",
      "29 Train Loss 1.73485 Test MSE 6.500466998612532 Test RE 1.2186537779612314\n",
      "30 Train Loss 1.5763549 Test MSE 6.314135828269441 Test RE 1.2010608761966317\n",
      "31 Train Loss 1.4759754 Test MSE 6.25794074908421 Test RE 1.1957042797884903\n",
      "32 Train Loss 1.3987145 Test MSE 6.179472532342799 Test RE 1.1881841735942347\n",
      "33 Train Loss 1.3392962 Test MSE 6.000364210715746 Test RE 1.1708381539687267\n",
      "34 Train Loss 1.2607619 Test MSE 5.993658641613409 Test RE 1.1701837494556024\n",
      "35 Train Loss 1.1989751 Test MSE 5.950631849810144 Test RE 1.1659759740248814\n",
      "36 Train Loss 1.1470544 Test MSE 5.88320515623465 Test RE 1.159351309401129\n",
      "37 Train Loss 1.1053865 Test MSE 5.867939006972013 Test RE 1.1578461497028063\n",
      "38 Train Loss 1.0693136 Test MSE 5.927788348206105 Test RE 1.1637358266158313\n",
      "39 Train Loss 1.0355065 Test MSE 5.917635290722874 Test RE 1.1627387818713109\n",
      "40 Train Loss 1.0089566 Test MSE 5.901712724540335 Test RE 1.161173439058793\n",
      "41 Train Loss 0.9798312 Test MSE 5.91605063367168 Test RE 1.1625830891421283\n",
      "42 Train Loss 0.9531301 Test MSE 5.947504144760135 Test RE 1.1656695100760426\n",
      "43 Train Loss 0.92488444 Test MSE 5.973743678568576 Test RE 1.1682380633751843\n",
      "44 Train Loss 0.8999526 Test MSE 5.950094160981915 Test RE 1.165923295046093\n",
      "45 Train Loss 0.8849597 Test MSE 5.9652588466685 Test RE 1.1674081126468043\n",
      "46 Train Loss 0.8654001 Test MSE 6.016479011456804 Test RE 1.1724093229711177\n",
      "47 Train Loss 0.85540223 Test MSE 6.036905752672627 Test RE 1.1743978788312208\n",
      "48 Train Loss 0.8434977 Test MSE 6.019799924828003 Test RE 1.172732845472299\n",
      "49 Train Loss 0.8317445 Test MSE 6.048551077441935 Test RE 1.1755300528435766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Train Loss 0.8219153 Test MSE 6.0643475373686995 Test RE 1.1770640652915185\n",
      "51 Train Loss 0.8105713 Test MSE 6.048676077285382 Test RE 1.1755421995801691\n",
      "52 Train Loss 0.8025288 Test MSE 6.0367091804531405 Test RE 1.1743787584501564\n",
      "53 Train Loss 0.79561454 Test MSE 6.0650131418185635 Test RE 1.1771286590156131\n",
      "54 Train Loss 0.7863858 Test MSE 6.069368824130515 Test RE 1.1775512696633912\n",
      "55 Train Loss 0.7752361 Test MSE 6.081891241701703 Test RE 1.1787654149095852\n",
      "56 Train Loss 0.767826 Test MSE 6.094587077552282 Test RE 1.179995099045249\n",
      "57 Train Loss 0.7613646 Test MSE 6.117970416927293 Test RE 1.182256598480702\n",
      "58 Train Loss 0.75572264 Test MSE 6.096125383082224 Test RE 1.1801440081047536\n",
      "59 Train Loss 0.74998677 Test MSE 6.099757390753008 Test RE 1.1804955144779732\n",
      "60 Train Loss 0.74446523 Test MSE 6.094712685843071 Test RE 1.1800072587208732\n",
      "61 Train Loss 0.7383247 Test MSE 6.1038772086199575 Test RE 1.1808941045595307\n",
      "62 Train Loss 0.7322782 Test MSE 6.12934792828632 Test RE 1.1833554016003\n",
      "63 Train Loss 0.7252931 Test MSE 6.149673490195328 Test RE 1.185315843127584\n",
      "64 Train Loss 0.72037905 Test MSE 6.170113561935409 Test RE 1.1872840648792586\n",
      "65 Train Loss 0.71475834 Test MSE 6.182161894851136 Test RE 1.1884426997350421\n",
      "66 Train Loss 0.7104198 Test MSE 6.205116117172027 Test RE 1.1906469854700734\n",
      "67 Train Loss 0.70531106 Test MSE 6.20701668662564 Test RE 1.1908293135681742\n",
      "68 Train Loss 0.7012107 Test MSE 6.237664885834854 Test RE 1.1937656543656943\n",
      "69 Train Loss 0.69769275 Test MSE 6.251150636093004 Test RE 1.1950554105330011\n",
      "70 Train Loss 0.69425714 Test MSE 6.252365857418375 Test RE 1.195171564048708\n",
      "71 Train Loss 0.6903335 Test MSE 6.264635019890838 Test RE 1.1963436457638101\n",
      "72 Train Loss 0.68627834 Test MSE 6.3022685114460115 Test RE 1.1999316580521444\n",
      "73 Train Loss 0.68283546 Test MSE 6.305792518141264 Test RE 1.2002670909393558\n",
      "74 Train Loss 0.6785968 Test MSE 6.325124799778105 Test RE 1.2021055707156951\n",
      "75 Train Loss 0.6753931 Test MSE 6.325428964815086 Test RE 1.2021344740260103\n",
      "76 Train Loss 0.67248225 Test MSE 6.3461286287193985 Test RE 1.2040998312543936\n",
      "77 Train Loss 0.6695488 Test MSE 6.354570075533516 Test RE 1.2049003954598891\n",
      "78 Train Loss 0.66651565 Test MSE 6.370958647141956 Test RE 1.206453126867799\n",
      "79 Train Loss 0.6638601 Test MSE 6.374602136915418 Test RE 1.2067980570100603\n",
      "80 Train Loss 0.6605364 Test MSE 6.385414839317005 Test RE 1.2078211184720173\n",
      "81 Train Loss 0.6575904 Test MSE 6.392091377378114 Test RE 1.2084523974916845\n",
      "82 Train Loss 0.65466386 Test MSE 6.40518472398094 Test RE 1.2096894411118557\n",
      "83 Train Loss 0.6513586 Test MSE 6.429526376910423 Test RE 1.2119858555821086\n",
      "84 Train Loss 0.64916414 Test MSE 6.435040151205131 Test RE 1.2125054260740975\n",
      "85 Train Loss 0.64589953 Test MSE 6.457860299015534 Test RE 1.2146534364304902\n",
      "86 Train Loss 0.6429212 Test MSE 6.47970608777284 Test RE 1.2167061797688126\n",
      "87 Train Loss 0.63981855 Test MSE 6.498986941373379 Test RE 1.2185150356196717\n",
      "88 Train Loss 0.63655573 Test MSE 6.505317653396694 Test RE 1.2191083734881518\n",
      "89 Train Loss 0.63325757 Test MSE 6.5005310319098895 Test RE 1.218659780162888\n",
      "90 Train Loss 0.62973875 Test MSE 6.510475879774439 Test RE 1.2195916082227427\n",
      "91 Train Loss 0.6266395 Test MSE 6.524432630632166 Test RE 1.2208981504692058\n",
      "92 Train Loss 0.62335724 Test MSE 6.544464110038195 Test RE 1.2227709304211312\n",
      "93 Train Loss 0.62062657 Test MSE 6.546395282499113 Test RE 1.2229513277256951\n",
      "94 Train Loss 0.61719835 Test MSE 6.56067401470889 Test RE 1.2242843271989576\n",
      "95 Train Loss 0.6133831 Test MSE 6.579660321941559 Test RE 1.226054560361713\n",
      "96 Train Loss 0.6098588 Test MSE 6.6060985664347855 Test RE 1.2285153434313503\n",
      "97 Train Loss 0.6069121 Test MSE 6.633066457889475 Test RE 1.231020356416103\n",
      "98 Train Loss 0.60405517 Test MSE 6.648775353522576 Test RE 1.2324771889818016\n",
      "99 Train Loss 0.60053396 Test MSE 6.664478064227461 Test RE 1.233931728979397\n",
      "100 Train Loss 0.5978652 Test MSE 6.67784988933278 Test RE 1.235169008996842\n",
      "101 Train Loss 0.5948067 Test MSE 6.6928425780620415 Test RE 1.2365547935152823\n",
      "102 Train Loss 0.5923554 Test MSE 6.698822631398991 Test RE 1.23710710088603\n",
      "103 Train Loss 0.5901959 Test MSE 6.7045371008997705 Test RE 1.2376346490969892\n",
      "104 Train Loss 0.58686364 Test MSE 6.691991699203334 Test RE 1.236476187768755\n",
      "105 Train Loss 0.58386135 Test MSE 6.722121370929601 Test RE 1.239256584407695\n",
      "106 Train Loss 0.58050865 Test MSE 6.733283931148289 Test RE 1.240285094417073\n",
      "107 Train Loss 0.57834935 Test MSE 6.738715799868339 Test RE 1.240785274395747\n",
      "108 Train Loss 0.57541525 Test MSE 6.754322722318889 Test RE 1.2422212779914141\n",
      "109 Train Loss 0.57291114 Test MSE 6.758556552600634 Test RE 1.2426105494516346\n",
      "110 Train Loss 0.5703313 Test MSE 6.775166660767356 Test RE 1.2441365579764474\n",
      "111 Train Loss 0.5686248 Test MSE 6.783143836221928 Test RE 1.2448687743527462\n",
      "112 Train Loss 0.566721 Test MSE 6.797020757352531 Test RE 1.2461414968538091\n",
      "113 Train Loss 0.5651174 Test MSE 6.795599042188022 Test RE 1.2460111639491858\n",
      "114 Train Loss 0.563231 Test MSE 6.806261510054396 Test RE 1.2469882924301021\n",
      "115 Train Loss 0.5609542 Test MSE 6.801498735052502 Test RE 1.2465519174819923\n",
      "116 Train Loss 0.5590329 Test MSE 6.796898046265991 Test RE 1.2461302480969862\n",
      "117 Train Loss 0.55720556 Test MSE 6.804946323457161 Test RE 1.2468678076734936\n",
      "118 Train Loss 0.5547532 Test MSE 6.819254180718607 Test RE 1.2481779310867116\n",
      "119 Train Loss 0.5531935 Test MSE 6.827224597655109 Test RE 1.248907159898102\n",
      "120 Train Loss 0.5505461 Test MSE 6.844190530246389 Test RE 1.2504579897346193\n",
      "121 Train Loss 0.54878163 Test MSE 6.863000974625765 Test RE 1.2521751782686619\n",
      "122 Train Loss 0.5463129 Test MSE 6.878761028447095 Test RE 1.2536120884394688\n",
      "123 Train Loss 0.5443816 Test MSE 6.868231004857249 Test RE 1.252652204781385\n",
      "124 Train Loss 0.54247373 Test MSE 6.880606441298141 Test RE 1.2537802347603964\n",
      "125 Train Loss 0.54017967 Test MSE 6.872403090958542 Test RE 1.253032606913672\n",
      "126 Train Loss 0.5377408 Test MSE 6.884033439689922 Test RE 1.254092428751381\n",
      "127 Train Loss 0.53557837 Test MSE 6.895304549869958 Test RE 1.2551186609044993\n",
      "128 Train Loss 0.53309244 Test MSE 6.911618910778829 Test RE 1.2566025954500357\n",
      "129 Train Loss 0.5308375 Test MSE 6.921657507563396 Test RE 1.2575148238188103\n",
      "130 Train Loss 0.5284132 Test MSE 6.920787144200578 Test RE 1.2574357582742777\n",
      "131 Train Loss 0.52684325 Test MSE 6.925048148764231 Test RE 1.2578227890375306\n",
      "132 Train Loss 0.5249389 Test MSE 6.923833210626318 Test RE 1.257712447284199\n",
      "133 Train Loss 0.5231776 Test MSE 6.932583745237641 Test RE 1.2585069624644258\n",
      "134 Train Loss 0.52161497 Test MSE 6.937630750862024 Test RE 1.2589649833369159\n",
      "135 Train Loss 0.5197425 Test MSE 6.948278580745451 Test RE 1.2599307384935376\n",
      "136 Train Loss 0.5183069 Test MSE 6.959206016082877 Test RE 1.2609210847115415\n",
      "137 Train Loss 0.51677084 Test MSE 6.9648509967668275 Test RE 1.261432380994081\n",
      "138 Train Loss 0.5152001 Test MSE 6.961641527956561 Test RE 1.261141707554523\n",
      "139 Train Loss 0.51374084 Test MSE 6.96830667273028 Test RE 1.2617452779241363\n",
      "140 Train Loss 0.5124588 Test MSE 6.978753618186243 Test RE 1.262690733398855\n",
      "141 Train Loss 0.5109533 Test MSE 6.990844654784094 Test RE 1.2637840971722487\n",
      "142 Train Loss 0.50945926 Test MSE 6.992704183192995 Test RE 1.2639521660032311\n",
      "143 Train Loss 0.5078374 Test MSE 6.99144660906923 Test RE 1.2638385057533972\n",
      "144 Train Loss 0.50635046 Test MSE 7.001833721809865 Test RE 1.2647769925576213\n",
      "145 Train Loss 0.5046848 Test MSE 7.003239887267459 Test RE 1.2649039876067472\n",
      "146 Train Loss 0.5031573 Test MSE 7.008943758787829 Test RE 1.2654189907688576\n",
      "147 Train Loss 0.501831 Test MSE 7.013290119361122 Test RE 1.2658112834600823\n",
      "148 Train Loss 0.50106037 Test MSE 7.016801544075347 Test RE 1.2661281279603427\n",
      "149 Train Loss 0.49981552 Test MSE 7.020010834248979 Test RE 1.2664176407833774\n",
      "Training time: 228.23\n",
      "2\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 49.74455 Test MSE 8.173697932470889 Test RE 1.3665242790552026\n",
      "1 Train Loss 39.20481 Test MSE 7.619406378173488 Test RE 1.3193761489309612\n",
      "2 Train Loss 31.548424 Test MSE 7.008578668375595 Test RE 1.2653860329956717\n",
      "3 Train Loss 24.799221 Test MSE 6.657864191326537 Test RE 1.2333192959182364\n",
      "4 Train Loss 19.80518 Test MSE 6.435081535311187 Test RE 1.2125093249132104\n",
      "5 Train Loss 17.161255 Test MSE 6.2727144597662505 Test RE 1.1971148536686202\n",
      "6 Train Loss 14.697871 Test MSE 6.20724770590496 Test RE 1.190851474131289\n",
      "7 Train Loss 11.920761 Test MSE 5.939586418359227 Test RE 1.1648933419728658\n",
      "8 Train Loss 9.67892 Test MSE 5.77441318211214 Test RE 1.14858195344988\n",
      "9 Train Loss 8.689692 Test MSE 5.7583900846101415 Test RE 1.1469872783945687\n",
      "10 Train Loss 7.8950157 Test MSE 5.618761452486934 Test RE 1.1329959499506217\n",
      "11 Train Loss 7.157627 Test MSE 5.531125227891373 Test RE 1.1241255163542252\n",
      "12 Train Loss 6.559041 Test MSE 5.275492862129499 Test RE 1.0978413393382835\n",
      "13 Train Loss 6.0293865 Test MSE 5.154515239320924 Test RE 1.0851804827367906\n",
      "14 Train Loss 5.4626346 Test MSE 4.764130620006295 Test RE 1.0432776181181402\n",
      "15 Train Loss 4.9922404 Test MSE 4.476541464791421 Test RE 1.0112985069681892\n",
      "16 Train Loss 3.901273 Test MSE 3.7164261611741534 Test RE 0.9214479635454957\n",
      "17 Train Loss 3.0856156 Test MSE 3.533817176840704 Test RE 0.8985248630815427\n",
      "18 Train Loss 2.5851126 Test MSE 3.118973288822045 Test RE 0.8441388492823052\n",
      "19 Train Loss 2.288569 Test MSE 3.0666587933544354 Test RE 0.8370295475910425\n",
      "20 Train Loss 1.9338809 Test MSE 2.858672622740896 Test RE 0.8081468258992117\n",
      "21 Train Loss 1.6561401 Test MSE 2.671360152462294 Test RE 0.7812216709412527\n",
      "22 Train Loss 1.4803644 Test MSE 2.629665566269306 Test RE 0.775101040848064\n",
      "23 Train Loss 1.346147 Test MSE 2.4473328200234765 Test RE 0.7477468246640472\n",
      "24 Train Loss 1.2364936 Test MSE 2.2925144617595765 Test RE 0.7237092145591122\n",
      "25 Train Loss 1.1542822 Test MSE 2.1016261479256193 Test RE 0.6929243001710415\n",
      "26 Train Loss 1.0696981 Test MSE 1.9589769873836536 Test RE 0.668994777408047\n",
      "27 Train Loss 1.006829 Test MSE 1.976001867065041 Test RE 0.6718955048832347\n",
      "28 Train Loss 0.9231563 Test MSE 1.813968195998746 Test RE 0.6437583785748088\n",
      "29 Train Loss 0.84477484 Test MSE 1.7417852633594166 Test RE 0.6308198723354056\n",
      "30 Train Loss 0.739684 Test MSE 1.4215645193402593 Test RE 0.5698904089210853\n",
      "31 Train Loss 0.64900833 Test MSE 1.269701637115704 Test RE 0.538590762013712\n",
      "32 Train Loss 0.5683041 Test MSE 1.1572778985032888 Test RE 0.5141938640512397\n",
      "33 Train Loss 0.46238387 Test MSE 0.9506322218352363 Test RE 0.46603048391672547\n",
      "34 Train Loss 0.38875642 Test MSE 0.7716531506882262 Test RE 0.4198741398536409\n",
      "35 Train Loss 0.3123873 Test MSE 0.6836202152794865 Test RE 0.39519870121027045\n",
      "36 Train Loss 0.2237433 Test MSE 0.5186285956593348 Test RE 0.3442201501353243\n",
      "37 Train Loss 0.16031127 Test MSE 0.41764960800881246 Test RE 0.30889729082031564\n",
      "38 Train Loss 0.115544826 Test MSE 0.38765395790565665 Test RE 0.29759811188384366\n",
      "39 Train Loss 0.0791488 Test MSE 0.4027892532983548 Test RE 0.30335209434048466\n",
      "40 Train Loss 0.058906447 Test MSE 0.3968570846336853 Test RE 0.30110996550397295\n",
      "41 Train Loss 0.048448354 Test MSE 0.35828075884129956 Test RE 0.2861012814188487\n",
      "42 Train Loss 0.039351884 Test MSE 0.33068093087079276 Test RE 0.27486069229918175\n",
      "43 Train Loss 0.031111203 Test MSE 0.3051468065141865 Test RE 0.2640355927220907\n",
      "44 Train Loss 0.027114477 Test MSE 0.30004666925238527 Test RE 0.2618197870805154\n",
      "45 Train Loss 0.023405626 Test MSE 0.27406937804331566 Test RE 0.2502293901083938\n",
      "46 Train Loss 0.020152397 Test MSE 0.2618254039436193 Test RE 0.24457606391400205\n",
      "47 Train Loss 0.017860811 Test MSE 0.24488204031242922 Test RE 0.23653016122368883\n",
      "48 Train Loss 0.0155023085 Test MSE 0.249658148733141 Test RE 0.2388256306236799\n",
      "49 Train Loss 0.014501374 Test MSE 0.24191367948343326 Test RE 0.23509222906229077\n",
      "50 Train Loss 0.013601581 Test MSE 0.2372003773185162 Test RE 0.23279076529128645\n",
      "51 Train Loss 0.012746498 Test MSE 0.23184920002774853 Test RE 0.23014993742592807\n",
      "52 Train Loss 0.011949863 Test MSE 0.2266500705859691 Test RE 0.22755479409749596\n",
      "53 Train Loss 0.011173984 Test MSE 0.22040324671450637 Test RE 0.22439700396550638\n",
      "54 Train Loss 0.010638643 Test MSE 0.21729415693247492 Test RE 0.22280866906095648\n",
      "55 Train Loss 0.009525763 Test MSE 0.21084167736493176 Test RE 0.21947562355949912\n",
      "56 Train Loss 0.008941085 Test MSE 0.20798247431249686 Test RE 0.21798240034689126\n",
      "57 Train Loss 0.007955864 Test MSE 0.20091363834493714 Test RE 0.2142460232475144\n",
      "58 Train Loss 0.007434176 Test MSE 0.19487763677339084 Test RE 0.21100321009790476\n",
      "59 Train Loss 0.007112333 Test MSE 0.1949118482010297 Test RE 0.21102173044837552\n",
      "60 Train Loss 0.006743972 Test MSE 0.1909537797729334 Test RE 0.2088681354910371\n",
      "61 Train Loss 0.00642185 Test MSE 0.19012373698415536 Test RE 0.20841368441339103\n",
      "62 Train Loss 0.006033653 Test MSE 0.1899812663687499 Test RE 0.20833558161815952\n",
      "63 Train Loss 0.005740613 Test MSE 0.1863651349175441 Test RE 0.2063433106788716\n",
      "64 Train Loss 0.0053088656 Test MSE 0.18136673252126598 Test RE 0.20355739045882115\n",
      "65 Train Loss 0.0050046323 Test MSE 0.17193858767881978 Test RE 0.19819593270025948\n",
      "66 Train Loss 0.004776567 Test MSE 0.16559808938285064 Test RE 0.19450721749779992\n",
      "67 Train Loss 0.00448082 Test MSE 0.16018125589942478 Test RE 0.19129953196957528\n",
      "68 Train Loss 0.004175723 Test MSE 0.15370753479899663 Test RE 0.18739398163448803\n",
      "69 Train Loss 0.0038223276 Test MSE 0.14169516967260148 Test RE 0.17992254397162585\n",
      "70 Train Loss 0.003525597 Test MSE 0.13099140365402487 Test RE 0.17299336967759887\n",
      "71 Train Loss 0.0033770031 Test MSE 0.12506084798137504 Test RE 0.16903192789132987\n",
      "72 Train Loss 0.0032673047 Test MSE 0.12848546255562204 Test RE 0.17133064760267117\n",
      "73 Train Loss 0.0031175727 Test MSE 0.1262677472099758 Test RE 0.16984559052512213\n",
      "74 Train Loss 0.0030006752 Test MSE 0.12256685901755898 Test RE 0.16733800561816822\n",
      "75 Train Loss 0.0028763777 Test MSE 0.120457727260328 Test RE 0.16589198076914852\n",
      "76 Train Loss 0.0027936245 Test MSE 0.11759871012056582 Test RE 0.1639114678168184\n",
      "77 Train Loss 0.0026958676 Test MSE 0.11619033851011874 Test RE 0.1629270029704412\n",
      "78 Train Loss 0.0026147617 Test MSE 0.11291442536706679 Test RE 0.16061376942808647\n",
      "79 Train Loss 0.002570803 Test MSE 0.10858944850150734 Test RE 0.15750773054771106\n",
      "80 Train Loss 0.0025272418 Test MSE 0.10578510638400603 Test RE 0.15546059438747548\n",
      "81 Train Loss 0.0024731015 Test MSE 0.1045458446385789 Test RE 0.15454730923339502\n",
      "82 Train Loss 0.0023954369 Test MSE 0.09990011118221616 Test RE 0.15107445842791709\n",
      "83 Train Loss 0.0023193995 Test MSE 0.10135204433056125 Test RE 0.1521683448667131\n",
      "84 Train Loss 0.0022641195 Test MSE 0.09888398490152354 Test RE 0.15030417359385126\n",
      "85 Train Loss 0.0021945788 Test MSE 0.098259175145772 Test RE 0.14982856405870895\n",
      "86 Train Loss 0.0021135847 Test MSE 0.09602420474329254 Test RE 0.14811478750110013\n",
      "87 Train Loss 0.0020668784 Test MSE 0.0937655477209771 Test RE 0.14636246248889778\n",
      "88 Train Loss 0.0020309146 Test MSE 0.09554220463387805 Test RE 0.14774258364911352\n",
      "89 Train Loss 0.0019726516 Test MSE 0.09378196430769598 Test RE 0.1463752745875596\n",
      "90 Train Loss 0.0019186214 Test MSE 0.09209163986499173 Test RE 0.14505014374125455\n",
      "91 Train Loss 0.0018642 Test MSE 0.08875608891557266 Test RE 0.14239906527950585\n",
      "92 Train Loss 0.0018160009 Test MSE 0.08709006833818406 Test RE 0.14105626366230303\n",
      "93 Train Loss 0.0017657456 Test MSE 0.08405955583705607 Test RE 0.1385803346433141\n",
      "94 Train Loss 0.0017269426 Test MSE 0.08019786461272405 Test RE 0.13535972476872754\n",
      "95 Train Loss 0.001697928 Test MSE 0.07847195524295579 Test RE 0.1338952890674579\n",
      "96 Train Loss 0.0016787873 Test MSE 0.07785478233055701 Test RE 0.13336771415807624\n",
      "97 Train Loss 0.0016419295 Test MSE 0.07649773683304016 Test RE 0.13220027352156513\n",
      "98 Train Loss 0.0016132994 Test MSE 0.07769758834650636 Test RE 0.13323300698510232\n",
      "99 Train Loss 0.0015821436 Test MSE 0.07552788071839828 Test RE 0.1313595674343311\n",
      "100 Train Loss 0.0015449473 Test MSE 0.07366556118594714 Test RE 0.1297299680449028\n",
      "101 Train Loss 0.0014935138 Test MSE 0.06980825790887583 Test RE 0.1262878182276715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 Train Loss 0.0014625336 Test MSE 0.07063280107852592 Test RE 0.12703145573143973\n",
      "103 Train Loss 0.0014351162 Test MSE 0.06932275810252175 Test RE 0.12584790116569777\n",
      "104 Train Loss 0.0013939742 Test MSE 0.06877003638329965 Test RE 0.12534519414147927\n",
      "105 Train Loss 0.0013520024 Test MSE 0.0662682635469356 Test RE 0.1230441174704966\n",
      "106 Train Loss 0.0013235103 Test MSE 0.06431484636465179 Test RE 0.12121704105596674\n",
      "107 Train Loss 0.0012921905 Test MSE 0.06273469679049903 Test RE 0.11971869163312282\n",
      "108 Train Loss 0.0012458753 Test MSE 0.060179889186072005 Test RE 0.11725564287921036\n",
      "109 Train Loss 0.0012123175 Test MSE 0.05664667893172834 Test RE 0.1137614939988657\n",
      "110 Train Loss 0.0011745574 Test MSE 0.0551945300842036 Test RE 0.11229387804933076\n",
      "111 Train Loss 0.0011412677 Test MSE 0.05267247925126475 Test RE 0.10969831093749179\n",
      "112 Train Loss 0.0011218349 Test MSE 0.050712521205346264 Test RE 0.10763801036175268\n",
      "113 Train Loss 0.0011103405 Test MSE 0.05014717279446518 Test RE 0.10703634900212725\n",
      "114 Train Loss 0.001082766 Test MSE 0.04825107415629071 Test RE 0.10499329207103353\n",
      "115 Train Loss 0.0010496047 Test MSE 0.04649071040580128 Test RE 0.1030602404871931\n",
      "116 Train Loss 0.0010345953 Test MSE 0.04522336753143549 Test RE 0.1016458166904571\n",
      "117 Train Loss 0.0010150736 Test MSE 0.044328215066554696 Test RE 0.10063479874079821\n",
      "118 Train Loss 0.0009851228 Test MSE 0.04232435462318634 Test RE 0.098333892888498\n",
      "119 Train Loss 0.0009597326 Test MSE 0.041275086763561744 Test RE 0.0971073399503124\n",
      "120 Train Loss 0.0009336075 Test MSE 0.0389738001201403 Test RE 0.09436141332619517\n",
      "121 Train Loss 0.00090228743 Test MSE 0.03644790082595335 Test RE 0.09125240527569169\n",
      "122 Train Loss 0.00086200715 Test MSE 0.034823314770949125 Test RE 0.08919553495060353\n",
      "123 Train Loss 0.0008377153 Test MSE 0.03515928498589108 Test RE 0.08962477482083094\n",
      "124 Train Loss 0.00081934285 Test MSE 0.035741590147608436 Test RE 0.09036390607410767\n",
      "125 Train Loss 0.00080016826 Test MSE 0.03549345220030057 Test RE 0.09004968156024595\n",
      "126 Train Loss 0.0007843068 Test MSE 0.035118514509545014 Test RE 0.08957279559714174\n",
      "127 Train Loss 0.0007546125 Test MSE 0.03300921551434567 Test RE 0.08684116916890987\n",
      "128 Train Loss 0.00072800997 Test MSE 0.03133827896913077 Test RE 0.0846146634521684\n",
      "129 Train Loss 0.00070817117 Test MSE 0.02978699036166295 Test RE 0.08249381202164006\n",
      "130 Train Loss 0.0006928795 Test MSE 0.029577584979142185 Test RE 0.08220333091146086\n",
      "131 Train Loss 0.0006744068 Test MSE 0.027755519828477026 Test RE 0.07963110514965441\n",
      "132 Train Loss 0.00065696554 Test MSE 0.027106017311369735 Test RE 0.07869387225188582\n",
      "133 Train Loss 0.0006383888 Test MSE 0.025356621789998302 Test RE 0.07611210912400768\n",
      "134 Train Loss 0.0006209787 Test MSE 0.02407164562615232 Test RE 0.07415850241346152\n",
      "135 Train Loss 0.0006012859 Test MSE 0.02443728003058455 Test RE 0.07471959221193747\n",
      "136 Train Loss 0.00058866735 Test MSE 0.024461638767933207 Test RE 0.07475682265634136\n",
      "137 Train Loss 0.00057513197 Test MSE 0.024624903618925758 Test RE 0.07500588331849063\n",
      "138 Train Loss 0.0005474141 Test MSE 0.023972706057778348 Test RE 0.0740059419022122\n",
      "139 Train Loss 0.0005316891 Test MSE 0.023092533672719445 Test RE 0.0726346508195194\n",
      "140 Train Loss 0.00052252354 Test MSE 0.022537493915375798 Test RE 0.07175643789922258\n",
      "141 Train Loss 0.00051434943 Test MSE 0.022073129016749477 Test RE 0.07101335171812198\n",
      "142 Train Loss 0.00050880935 Test MSE 0.022102099176777978 Test RE 0.07105993762768\n",
      "143 Train Loss 0.00050166366 Test MSE 0.02168639449831299 Test RE 0.07038850434597209\n",
      "144 Train Loss 0.0004950849 Test MSE 0.02181873540039005 Test RE 0.07060295008459394\n",
      "145 Train Loss 0.00048817234 Test MSE 0.021188769479205782 Test RE 0.06957623570676469\n",
      "146 Train Loss 0.0004791645 Test MSE 0.021298671657070153 Test RE 0.06975644178542476\n",
      "147 Train Loss 0.00047149608 Test MSE 0.020852406445156287 Test RE 0.06902177934449762\n",
      "148 Train Loss 0.00046364553 Test MSE 0.020652499589887453 Test RE 0.0686901352321783\n",
      "149 Train Loss 0.00045392313 Test MSE 0.020453314260362867 Test RE 0.06835808785051384\n",
      "Training time: 228.91\n",
      "3\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 51.97021 Test MSE 8.57944974454247 Test RE 1.4000314045889513\n",
      "1 Train Loss 45.73004 Test MSE 8.599869369047275 Test RE 1.4016964953737023\n",
      "2 Train Loss 40.633682 Test MSE 8.83288347225228 Test RE 1.4205591139635656\n",
      "3 Train Loss 36.08079 Test MSE 8.75496592998339 Test RE 1.4142796437597873\n",
      "4 Train Loss 33.39473 Test MSE 8.867448778170326 Test RE 1.4233359035063462\n",
      "5 Train Loss 29.740606 Test MSE 8.921959948033175 Test RE 1.4277040612967284\n",
      "6 Train Loss 27.650558 Test MSE 9.09209099021257 Test RE 1.4412520795757653\n",
      "7 Train Loss 24.65171 Test MSE 9.009223247961284 Test RE 1.4346690674830274\n",
      "8 Train Loss 22.601704 Test MSE 9.101082448149038 Test RE 1.4419645534811214\n",
      "9 Train Loss 20.335136 Test MSE 9.09153387363905 Test RE 1.4412079226419265\n",
      "10 Train Loss 18.170033 Test MSE 8.70914908704724 Test RE 1.410574156666245\n",
      "11 Train Loss 16.827593 Test MSE 8.680968817553207 Test RE 1.4082902040807117\n",
      "12 Train Loss 15.778742 Test MSE 8.748047885537591 Test RE 1.41372076191608\n",
      "13 Train Loss 14.898188 Test MSE 8.918981009377049 Test RE 1.4274656945078086\n",
      "14 Train Loss 14.076765 Test MSE 8.960532884800944 Test RE 1.4307869794180754\n",
      "15 Train Loss 13.415913 Test MSE 8.909606377091434 Test RE 1.4267153013728266\n",
      "16 Train Loss 12.0638275 Test MSE 8.382813101459083 Test RE 1.3838944002625917\n",
      "17 Train Loss 9.2781725 Test MSE 7.1410265217846955 Test RE 1.2772866802410594\n",
      "18 Train Loss 8.238329 Test MSE 6.99705024109142 Test RE 1.2643448864651603\n",
      "19 Train Loss 7.685169 Test MSE 6.907009055866072 Test RE 1.2561834663034332\n",
      "20 Train Loss 7.3661394 Test MSE 6.7729707142185624 Test RE 1.243934918745271\n",
      "21 Train Loss 7.0029583 Test MSE 6.637044536155793 Test RE 1.2313894437256663\n",
      "22 Train Loss 6.526169 Test MSE 6.63437034280522 Test RE 1.231141343444591\n",
      "23 Train Loss 5.8829203 Test MSE 6.581921995916077 Test RE 1.226265262533672\n",
      "24 Train Loss 5.123294 Test MSE 6.507252279993272 Test RE 1.2192896362860839\n",
      "25 Train Loss 4.042918 Test MSE 6.523100739437631 Test RE 1.2207735276411105\n",
      "26 Train Loss 3.0927546 Test MSE 6.308397155596024 Test RE 1.200514953349136\n",
      "27 Train Loss 2.3640542 Test MSE 6.201638525301139 Test RE 1.1903132959388147\n",
      "28 Train Loss 1.8919895 Test MSE 5.956832930125554 Test RE 1.1665833404499575\n",
      "29 Train Loss 1.5976387 Test MSE 5.885876720712338 Test RE 1.159614510339553\n",
      "30 Train Loss 1.4179491 Test MSE 5.965299527947507 Test RE 1.1674120933268881\n",
      "31 Train Loss 1.292101 Test MSE 5.890932951536031 Test RE 1.1601124837294987\n",
      "32 Train Loss 1.2185056 Test MSE 5.875542372747929 Test RE 1.1585960448395285\n",
      "33 Train Loss 1.1517534 Test MSE 5.9264022067210425 Test RE 1.1635997558990387\n",
      "34 Train Loss 1.0974678 Test MSE 5.944262554744665 Test RE 1.1653518022138267\n",
      "35 Train Loss 1.0520029 Test MSE 5.979681970029313 Test RE 1.1688185716212345\n",
      "36 Train Loss 1.0108135 Test MSE 6.021177462599957 Test RE 1.1728670186509924\n",
      "37 Train Loss 0.9819057 Test MSE 6.048741426194735 Test RE 1.1755485497460711\n",
      "38 Train Loss 0.95807517 Test MSE 6.041944485368642 Test RE 1.174887885051699\n",
      "39 Train Loss 0.93865514 Test MSE 6.057757620899339 Test RE 1.1764243540764028\n",
      "40 Train Loss 0.914666 Test MSE 6.03532568059124 Test RE 1.1742441780104735\n",
      "41 Train Loss 0.89831835 Test MSE 6.016593668940481 Test RE 1.1724204943607395\n",
      "42 Train Loss 0.8842735 Test MSE 6.042606819328036 Test RE 1.1749522804480481\n",
      "43 Train Loss 0.8675595 Test MSE 6.044309179560813 Test RE 1.1751177761720537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 Train Loss 0.85562086 Test MSE 6.046307391424908 Test RE 1.1753120035167055\n",
      "45 Train Loss 0.8412024 Test MSE 6.095331376890875 Test RE 1.180067150092156\n",
      "46 Train Loss 0.8289027 Test MSE 6.108504033232256 Test RE 1.1813415869306254\n",
      "47 Train Loss 0.8201741 Test MSE 6.085827762440999 Test RE 1.179146832770408\n",
      "48 Train Loss 0.80888045 Test MSE 6.133645517643769 Test RE 1.1837701834428918\n",
      "49 Train Loss 0.80253154 Test MSE 6.1324009409875 Test RE 1.183650078076807\n",
      "50 Train Loss 0.79485506 Test MSE 6.141598608846843 Test RE 1.184537392955573\n",
      "51 Train Loss 0.7878764 Test MSE 6.154934395700945 Test RE 1.1858227400849188\n",
      "52 Train Loss 0.7807544 Test MSE 6.173010388305826 Test RE 1.187562743072131\n",
      "53 Train Loss 0.774071 Test MSE 6.193685738576755 Test RE 1.1895498408849081\n",
      "54 Train Loss 0.7678787 Test MSE 6.227867976027428 Test RE 1.1928278186200667\n",
      "55 Train Loss 0.76018524 Test MSE 6.290988974993827 Test RE 1.1988573834297815\n",
      "56 Train Loss 0.7537416 Test MSE 6.282421111370739 Test RE 1.1980407275513751\n",
      "57 Train Loss 0.7458992 Test MSE 6.2961398145997185 Test RE 1.199348074054193\n",
      "58 Train Loss 0.7405009 Test MSE 6.332184976896375 Test RE 1.2027762856414836\n",
      "59 Train Loss 0.7352948 Test MSE 6.341556189153514 Test RE 1.2036659710137283\n",
      "60 Train Loss 0.728621 Test MSE 6.349506263789489 Test RE 1.204420220979219\n",
      "61 Train Loss 0.7218023 Test MSE 6.378460642158364 Test RE 1.2071632352686887\n",
      "62 Train Loss 0.7156397 Test MSE 6.383172042092524 Test RE 1.207608983800365\n",
      "63 Train Loss 0.71020496 Test MSE 6.384348737928907 Test RE 1.2077202860629714\n",
      "64 Train Loss 0.7042936 Test MSE 6.385810627549138 Test RE 1.2078585501808285\n",
      "65 Train Loss 0.69788605 Test MSE 6.401907662366648 Test RE 1.2093799469923212\n",
      "66 Train Loss 0.6912026 Test MSE 6.420833744743605 Test RE 1.2111662842842508\n",
      "67 Train Loss 0.6868138 Test MSE 6.399128281522333 Test RE 1.2091173930362353\n",
      "68 Train Loss 0.6812165 Test MSE 6.410958852917671 Test RE 1.2102345720982006\n",
      "69 Train Loss 0.6766994 Test MSE 6.4194139634497045 Test RE 1.2110323697201497\n",
      "70 Train Loss 0.67174757 Test MSE 6.428890967822951 Test RE 1.2119259658010342\n",
      "71 Train Loss 0.6678707 Test MSE 6.423150550891031 Test RE 1.2113847749450515\n",
      "72 Train Loss 0.6647264 Test MSE 6.445919346914987 Test RE 1.2135299350869473\n",
      "73 Train Loss 0.66149455 Test MSE 6.458837886774292 Test RE 1.2147453697753483\n",
      "74 Train Loss 0.65815055 Test MSE 6.4679833348906115 Test RE 1.2156050802310403\n",
      "75 Train Loss 0.65480983 Test MSE 6.4737051931004155 Test RE 1.2161426498210997\n",
      "76 Train Loss 0.651301 Test MSE 6.4690449569021204 Test RE 1.2157048377670017\n",
      "77 Train Loss 0.6477766 Test MSE 6.474982354898305 Test RE 1.2162626069621998\n",
      "78 Train Loss 0.64407676 Test MSE 6.47865540917437 Test RE 1.2166075318554566\n",
      "79 Train Loss 0.6416004 Test MSE 6.485160005170567 Test RE 1.2172181180551298\n",
      "80 Train Loss 0.6383581 Test MSE 6.493333530646798 Test RE 1.2179849326354686\n",
      "81 Train Loss 0.63592255 Test MSE 6.5081144043736385 Test RE 1.2193704034411308\n",
      "82 Train Loss 0.63323843 Test MSE 6.527997753483684 Test RE 1.221231670462691\n",
      "83 Train Loss 0.63056505 Test MSE 6.525674115516967 Test RE 1.2210143026764795\n",
      "84 Train Loss 0.62766105 Test MSE 6.540786332470836 Test RE 1.2224273032422466\n",
      "85 Train Loss 0.62493825 Test MSE 6.547394580415381 Test RE 1.2230446650530822\n",
      "86 Train Loss 0.6224757 Test MSE 6.559169126078538 Test RE 1.2241439058622559\n",
      "87 Train Loss 0.62036777 Test MSE 6.566896429381897 Test RE 1.224864770556818\n",
      "88 Train Loss 0.6171699 Test MSE 6.5870203434489305 Test RE 1.226740102273876\n",
      "89 Train Loss 0.61410356 Test MSE 6.5940367500413855 Test RE 1.2273932820133282\n",
      "90 Train Loss 0.61173904 Test MSE 6.587456970402107 Test RE 1.226780759421525\n",
      "91 Train Loss 0.6085675 Test MSE 6.6129678389353845 Test RE 1.2291539059596108\n",
      "92 Train Loss 0.6065128 Test MSE 6.616987300522916 Test RE 1.2295273983555617\n",
      "93 Train Loss 0.6034313 Test MSE 6.641365862450138 Test RE 1.231790252374848\n",
      "94 Train Loss 0.60035205 Test MSE 6.63872209199983 Test RE 1.2315450547082007\n",
      "95 Train Loss 0.5973643 Test MSE 6.653458474719979 Test RE 1.2329111654465548\n",
      "96 Train Loss 0.5943562 Test MSE 6.659451289159345 Test RE 1.23346628613075\n",
      "97 Train Loss 0.59089184 Test MSE 6.666230236176346 Test RE 1.2340939261126327\n",
      "98 Train Loss 0.5883214 Test MSE 6.694563436882515 Test RE 1.2367137543329643\n",
      "99 Train Loss 0.58573747 Test MSE 6.711648023016468 Test RE 1.2382908011296725\n",
      "100 Train Loss 0.5831938 Test MSE 6.724644932773422 Test RE 1.2394891781830608\n",
      "101 Train Loss 0.5813407 Test MSE 6.730207352050939 Test RE 1.240001705864123\n",
      "102 Train Loss 0.57957125 Test MSE 6.737318116006623 Test RE 1.2406565914582945\n",
      "103 Train Loss 0.5781882 Test MSE 6.740371591865623 Test RE 1.2409377037458493\n",
      "104 Train Loss 0.5761597 Test MSE 6.751491927198468 Test RE 1.2419609378655274\n",
      "105 Train Loss 0.5736057 Test MSE 6.779871199978252 Test RE 1.2445684346962047\n",
      "106 Train Loss 0.5702683 Test MSE 6.785959248281075 Test RE 1.2451270952023323\n",
      "107 Train Loss 0.56747186 Test MSE 6.8024669338745785 Test RE 1.2466406381593806\n",
      "108 Train Loss 0.5641739 Test MSE 6.836359302297123 Test RE 1.2497423883544376\n",
      "109 Train Loss 0.56083 Test MSE 6.859400642491584 Test RE 1.251846689466126\n",
      "110 Train Loss 0.5581364 Test MSE 6.872572677847067 Test RE 1.2530480670509268\n",
      "111 Train Loss 0.5555543 Test MSE 6.87641758374404 Test RE 1.253398531023569\n",
      "112 Train Loss 0.55262846 Test MSE 6.89616879415602 Test RE 1.2551973155263387\n",
      "113 Train Loss 0.54932237 Test MSE 6.903452491723227 Test RE 1.2558600070236752\n",
      "114 Train Loss 0.54570097 Test MSE 6.9158965060581155 Test RE 1.2569913904613343\n",
      "115 Train Loss 0.54188913 Test MSE 6.921055229276014 Test RE 1.2574601121872546\n",
      "116 Train Loss 0.5388988 Test MSE 6.920261106114383 Test RE 1.2573879695144439\n",
      "117 Train Loss 0.53494585 Test MSE 6.930772337804463 Test RE 1.258342534750112\n",
      "118 Train Loss 0.5313906 Test MSE 6.953154139106127 Test RE 1.2603727032586949\n",
      "119 Train Loss 0.52864975 Test MSE 6.960173875925058 Test RE 1.2610087637118625\n",
      "120 Train Loss 0.52590907 Test MSE 6.97748764753684 Test RE 1.2625761999164797\n",
      "121 Train Loss 0.5223227 Test MSE 7.00238943250729 Test RE 1.2648271819928047\n",
      "122 Train Loss 0.52024055 Test MSE 7.014379088479453 Test RE 1.2659095523089443\n",
      "123 Train Loss 0.51714426 Test MSE 7.024641271194664 Test RE 1.2668352398795342\n",
      "124 Train Loss 0.5148145 Test MSE 7.028373900929018 Test RE 1.2671717694413762\n",
      "125 Train Loss 0.5120424 Test MSE 7.025218399318379 Test RE 1.266887278923276\n",
      "126 Train Loss 0.51017845 Test MSE 7.032378726022056 Test RE 1.2675327404612033\n",
      "127 Train Loss 0.5079086 Test MSE 7.037184480771101 Test RE 1.267965766851896\n",
      "128 Train Loss 0.5054818 Test MSE 7.04268928265612 Test RE 1.2684615998017272\n",
      "129 Train Loss 0.50306845 Test MSE 7.0579628024466325 Test RE 1.2698363147641973\n",
      "130 Train Loss 0.5013762 Test MSE 7.052322819503663 Test RE 1.2693288534273515\n",
      "131 Train Loss 0.49971598 Test MSE 7.057140863005179 Test RE 1.2697623728230665\n",
      "132 Train Loss 0.49832398 Test MSE 7.061689235589 Test RE 1.270171491913464\n",
      "133 Train Loss 0.4962715 Test MSE 7.061715784269123 Test RE 1.2701738795394146\n",
      "134 Train Loss 0.49429467 Test MSE 7.06111639934724 Test RE 1.2701199734314355\n",
      "135 Train Loss 0.49275243 Test MSE 7.072015834240018 Test RE 1.2710998646485385\n",
      "136 Train Loss 0.49134994 Test MSE 7.078250042047268 Test RE 1.2716599987937363\n",
      "137 Train Loss 0.48995695 Test MSE 7.089160601134711 Test RE 1.272639702744051\n",
      "138 Train Loss 0.48872674 Test MSE 7.088201350426337 Test RE 1.2725535979211742\n",
      "139 Train Loss 0.48731887 Test MSE 7.103434647392115 Test RE 1.2739202903918632\n",
      "140 Train Loss 0.48543477 Test MSE 7.121654130135519 Test RE 1.2755529727567643\n",
      "141 Train Loss 0.48399496 Test MSE 7.117662205493639 Test RE 1.2751954276557602\n",
      "142 Train Loss 0.4824852 Test MSE 7.131050361966861 Test RE 1.276394170636064\n",
      "143 Train Loss 0.4810843 Test MSE 7.131307706760594 Test RE 1.276417201635318\n",
      "144 Train Loss 0.47976115 Test MSE 7.1313094060564355 Test RE 1.2764173537119359\n",
      "145 Train Loss 0.47882187 Test MSE 7.13109046014994 Test RE 1.2763977592389055\n",
      "146 Train Loss 0.47780812 Test MSE 7.133759758151314 Test RE 1.2766366264382971\n",
      "147 Train Loss 0.47676623 Test MSE 7.140396717232547 Test RE 1.2772303536960654\n",
      "148 Train Loss 0.47585696 Test MSE 7.141970231823915 Test RE 1.2773710762615798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 Train Loss 0.47474352 Test MSE 7.157190610158292 Test RE 1.2787314658397504\n",
      "Training time: 228.30\n",
      "4\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 51.525475 Test MSE 8.828413080404701 Test RE 1.4201995903940907\n",
      "1 Train Loss 42.435913 Test MSE 7.67312794117077 Test RE 1.3240191912301131\n",
      "2 Train Loss 33.781902 Test MSE 7.421796178236869 Test RE 1.3021546673747253\n",
      "3 Train Loss 27.69935 Test MSE 7.205190669797158 Test RE 1.2830122390478245\n",
      "4 Train Loss 21.514359 Test MSE 6.945715963500677 Test RE 1.2596983774883062\n",
      "5 Train Loss 17.712828 Test MSE 6.340645027619823 Test RE 1.2035794959043624\n",
      "6 Train Loss 15.29693 Test MSE 6.2330428869579455 Test RE 1.1933232928328548\n",
      "7 Train Loss 13.576044 Test MSE 6.111221017298667 Test RE 1.1816042804987865\n",
      "8 Train Loss 11.861539 Test MSE 5.819897774271691 Test RE 1.153096724493365\n",
      "9 Train Loss 9.930842 Test MSE 5.4582718823918155 Test RE 1.1166977537574194\n",
      "10 Train Loss 6.8500805 Test MSE 4.513511061886813 Test RE 1.0154658340026992\n",
      "11 Train Loss 5.449051 Test MSE 4.371592237419078 Test RE 0.9993736244884894\n",
      "12 Train Loss 4.223064 Test MSE 4.087035566800133 Test RE 0.9663006436780196\n",
      "13 Train Loss 3.4804087 Test MSE 3.8408146169232293 Test RE 0.9367414399584802\n",
      "14 Train Loss 2.963363 Test MSE 3.557835122653624 Test RE 0.9015731499044066\n",
      "15 Train Loss 2.6448174 Test MSE 3.5039693169001844 Test RE 0.8947221882234706\n",
      "16 Train Loss 2.3475528 Test MSE 3.2250167738505637 Test RE 0.8583690484101563\n",
      "17 Train Loss 2.0965433 Test MSE 2.9637380113042298 Test RE 0.8228638159701529\n",
      "18 Train Loss 1.889253 Test MSE 2.666428162904325 Test RE 0.7805001738510873\n",
      "19 Train Loss 1.714185 Test MSE 2.4560485792692037 Test RE 0.7490771278207309\n",
      "20 Train Loss 1.5466648 Test MSE 2.139563820698444 Test RE 0.699150516839273\n",
      "21 Train Loss 1.43993 Test MSE 2.0371328314211565 Test RE 0.6822094552837766\n",
      "22 Train Loss 1.3411807 Test MSE 1.8546451382125937 Test RE 0.6509362729807454\n",
      "23 Train Loss 1.2562995 Test MSE 1.76201386638263 Test RE 0.6344723802305918\n",
      "24 Train Loss 1.1952342 Test MSE 1.5396509161144776 Test RE 0.5930880759895417\n",
      "25 Train Loss 1.0781944 Test MSE 1.2440404925395252 Test RE 0.5331204212395356\n",
      "26 Train Loss 0.7908327 Test MSE 1.0736877635124285 Test RE 0.4952757474714837\n",
      "27 Train Loss 0.65769935 Test MSE 0.9668343909798344 Test RE 0.46998511699755574\n",
      "28 Train Loss 0.51432383 Test MSE 0.7602124595111289 Test RE 0.41674994566701584\n",
      "29 Train Loss 0.38742056 Test MSE 0.47207420669191114 Test RE 0.3284075979426601\n",
      "30 Train Loss 0.31128153 Test MSE 0.47320176722004575 Test RE 0.32879956872367616\n",
      "31 Train Loss 0.26846516 Test MSE 0.4212041119875971 Test RE 0.3102089769449099\n",
      "32 Train Loss 0.22338934 Test MSE 0.39448524247333056 Test RE 0.3002088154007601\n",
      "33 Train Loss 0.20035164 Test MSE 0.35974868673504945 Test RE 0.28668678139962567\n",
      "34 Train Loss 0.18207437 Test MSE 0.32614357475439676 Test RE 0.27296846263880753\n",
      "35 Train Loss 0.16864796 Test MSE 0.28769123318152734 Test RE 0.25637246209730935\n",
      "36 Train Loss 0.15805177 Test MSE 0.25419485370465605 Test RE 0.2409857913985653\n",
      "37 Train Loss 0.14542383 Test MSE 0.23030866403562503 Test RE 0.22938404047370695\n",
      "38 Train Loss 0.1260032 Test MSE 0.13226283243098222 Test RE 0.1738308964169182\n",
      "39 Train Loss 0.10702208 Test MSE 0.08137440402599283 Test RE 0.1363490042692885\n",
      "40 Train Loss 0.090770036 Test MSE 0.06245080001346296 Test RE 0.11944749968228217\n",
      "41 Train Loss 0.06799605 Test MSE 0.05208242022930754 Test RE 0.10908213736483532\n",
      "42 Train Loss 0.056036912 Test MSE 0.05060628350771606 Test RE 0.10752520577900421\n",
      "43 Train Loss 0.04364323 Test MSE 0.04082289285839184 Test RE 0.09657393974427303\n",
      "44 Train Loss 0.03510942 Test MSE 0.03637596406382669 Test RE 0.09116230893759039\n",
      "45 Train Loss 0.029485567 Test MSE 0.02543682831198533 Test RE 0.07623239067670085\n",
      "46 Train Loss 0.024576887 Test MSE 0.02151992138478663 Test RE 0.07011781924482827\n",
      "47 Train Loss 0.021875408 Test MSE 0.019401101468132984 Test RE 0.06657654502660659\n",
      "48 Train Loss 0.019540131 Test MSE 0.017071902790188154 Test RE 0.06245238449912851\n",
      "49 Train Loss 0.016401578 Test MSE 0.016042735935148805 Test RE 0.06054067764445446\n",
      "50 Train Loss 0.013659126 Test MSE 0.012635482635533421 Test RE 0.053728408681858145\n",
      "51 Train Loss 0.012537133 Test MSE 0.0120196211880799 Test RE 0.05240267422719925\n",
      "52 Train Loss 0.0116100665 Test MSE 0.010719628039872352 Test RE 0.04948777388233308\n",
      "53 Train Loss 0.010536665 Test MSE 0.00973046249136718 Test RE 0.047149251399221985\n",
      "54 Train Loss 0.00969286 Test MSE 0.00886638603782495 Test RE 0.04500713607002332\n",
      "55 Train Loss 0.00856888 Test MSE 0.00795278159252447 Test RE 0.042625313687683374\n",
      "56 Train Loss 0.007807453 Test MSE 0.007555390142700154 Test RE 0.0415466974969626\n",
      "57 Train Loss 0.0070801205 Test MSE 0.00734783506527721 Test RE 0.04097205621486237\n",
      "58 Train Loss 0.0065746726 Test MSE 0.006946776350592856 Test RE 0.03983820103367764\n",
      "59 Train Loss 0.0057989107 Test MSE 0.0069234186065515275 Test RE 0.039771168933152856\n",
      "60 Train Loss 0.0053435066 Test MSE 0.00751119958779284 Test RE 0.04142501853297398\n",
      "61 Train Loss 0.004853076 Test MSE 0.006624842173193261 Test RE 0.038904140809112475\n",
      "62 Train Loss 0.004498023 Test MSE 0.006912231452608898 Test RE 0.03973902397033569\n",
      "63 Train Loss 0.004140076 Test MSE 0.006325617633639749 Test RE 0.038015396848011765\n",
      "64 Train Loss 0.0038316012 Test MSE 0.005762898870513718 Test RE 0.03628511965164996\n",
      "65 Train Loss 0.0034414313 Test MSE 0.005060853207727892 Test RE 0.03400321101463114\n",
      "66 Train Loss 0.0032668859 Test MSE 0.004888366812204706 Test RE 0.033418730940482866\n",
      "67 Train Loss 0.0031555411 Test MSE 0.004926067102721449 Test RE 0.033547350178642805\n",
      "68 Train Loss 0.0029145237 Test MSE 0.004946176596072135 Test RE 0.03361575496374013\n",
      "69 Train Loss 0.0027974753 Test MSE 0.004882475330391284 Test RE 0.03339858666624649\n",
      "70 Train Loss 0.0026468844 Test MSE 0.004653379925347794 Test RE 0.03260560899944024\n",
      "71 Train Loss 0.002531516 Test MSE 0.004401663740416953 Test RE 0.03171147853683638\n",
      "72 Train Loss 0.0024355357 Test MSE 0.004347838101946623 Test RE 0.031516990611513966\n",
      "73 Train Loss 0.002355758 Test MSE 0.004197991574385277 Test RE 0.030969118338242743\n",
      "74 Train Loss 0.0022498693 Test MSE 0.004193964609506289 Test RE 0.030954261058074223\n",
      "75 Train Loss 0.002154575 Test MSE 0.004309396816080897 Test RE 0.031377352991515235\n",
      "76 Train Loss 0.002033351 Test MSE 0.004019636700781806 Test RE 0.030304104971937026\n",
      "77 Train Loss 0.0019514859 Test MSE 0.003942943232855389 Test RE 0.030013616051601726\n",
      "78 Train Loss 0.0018934159 Test MSE 0.0038517731860053857 Test RE 0.029664594288772692\n",
      "79 Train Loss 0.0018078086 Test MSE 0.0035447227245077513 Test RE 0.028457660570034616\n",
      "80 Train Loss 0.0017540605 Test MSE 0.003544856815479933 Test RE 0.02845819881795719\n",
      "81 Train Loss 0.0016875626 Test MSE 0.00349189833218303 Test RE 0.028244822873593384\n",
      "82 Train Loss 0.0016234417 Test MSE 0.003555792070024449 Test RE 0.028502059266518918\n",
      "83 Train Loss 0.0015666151 Test MSE 0.00354178619987613 Test RE 0.028445870658384546\n",
      "84 Train Loss 0.0015045234 Test MSE 0.0032868166337377135 Test RE 0.027402854096441286\n",
      "85 Train Loss 0.0014208434 Test MSE 0.0029471868290342263 Test RE 0.02594847827412461\n",
      "86 Train Loss 0.0013552245 Test MSE 0.0029255638417563417 Test RE 0.025853113340768744\n",
      "87 Train Loss 0.0013236258 Test MSE 0.0029049179180620655 Test RE 0.025761728146265876\n",
      "88 Train Loss 0.001294599 Test MSE 0.002778996463162916 Test RE 0.02519718689628198\n",
      "89 Train Loss 0.0012521418 Test MSE 0.002646880394605446 Test RE 0.02459094502191453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 Train Loss 0.0011694297 Test MSE 0.0025460526923968703 Test RE 0.02411802572212762\n",
      "91 Train Loss 0.0011362403 Test MSE 0.0024305225292709427 Test RE 0.023564481368581996\n",
      "92 Train Loss 0.001110029 Test MSE 0.0024543371404879785 Test RE 0.023679644059087655\n",
      "93 Train Loss 0.001080101 Test MSE 0.0023792188799956183 Test RE 0.02331445452776233\n",
      "94 Train Loss 0.0010480946 Test MSE 0.00217171338324837 Test RE 0.022274569240574107\n",
      "95 Train Loss 0.0010277326 Test MSE 0.0021162269810748578 Test RE 0.0219881749537104\n",
      "96 Train Loss 0.0010011822 Test MSE 0.002088640353428603 Test RE 0.02184438853628177\n",
      "97 Train Loss 0.0009763304 Test MSE 0.0020363031501161193 Test RE 0.02156896356553916\n",
      "98 Train Loss 0.0009475779 Test MSE 0.0019456220250478023 Test RE 0.021083237315843186\n",
      "99 Train Loss 0.00092909305 Test MSE 0.0018256969631022344 Test RE 0.02042313494097263\n",
      "100 Train Loss 0.000909844 Test MSE 0.001768062924645473 Test RE 0.02009818867594229\n",
      "101 Train Loss 0.00089609146 Test MSE 0.0017683369359184817 Test RE 0.02009974600651936\n",
      "102 Train Loss 0.0008821133 Test MSE 0.0017982810756244885 Test RE 0.02026921116815806\n",
      "103 Train Loss 0.000858932 Test MSE 0.0017145306662662196 Test RE 0.019791590153431262\n",
      "104 Train Loss 0.00084835116 Test MSE 0.001649210647404178 Test RE 0.01941092024879509\n",
      "105 Train Loss 0.0008313177 Test MSE 0.0016483291349700122 Test RE 0.019405731931986258\n",
      "106 Train Loss 0.0008100396 Test MSE 0.0016746332079464602 Test RE 0.019559957633749056\n",
      "107 Train Loss 0.0007857207 Test MSE 0.0015742516273115836 Test RE 0.01896466326163191\n",
      "108 Train Loss 0.00076809525 Test MSE 0.0014968752411779734 Test RE 0.018492722929287688\n",
      "109 Train Loss 0.0007532212 Test MSE 0.0014578505598580227 Test RE 0.018250071247432685\n",
      "110 Train Loss 0.0007397619 Test MSE 0.001402238104989351 Test RE 0.017898595058972087\n",
      "111 Train Loss 0.0007197244 Test MSE 0.00137197711266915 Test RE 0.017704411430278982\n",
      "112 Train Loss 0.00070242526 Test MSE 0.0013169036820693321 Test RE 0.017345429824952734\n",
      "113 Train Loss 0.0006898332 Test MSE 0.001278335960220134 Test RE 0.017089547489616146\n",
      "114 Train Loss 0.0006763654 Test MSE 0.001147899553900112 Test RE 0.01619421884114682\n",
      "115 Train Loss 0.00066694315 Test MSE 0.0011198419286527457 Test RE 0.015995080212937617\n",
      "116 Train Loss 0.00066070457 Test MSE 0.0010467142358142657 Test RE 0.015464010136282102\n",
      "117 Train Loss 0.00064897456 Test MSE 0.0010144944922620646 Test RE 0.015224144838615755\n",
      "118 Train Loss 0.0006390752 Test MSE 0.0010115215608016428 Test RE 0.015201821629112941\n",
      "119 Train Loss 0.00062414765 Test MSE 0.0009253066912936373 Test RE 0.014539548204406028\n",
      "120 Train Loss 0.0006064228 Test MSE 0.0008370336888724359 Test RE 0.01382864185839871\n",
      "121 Train Loss 0.0005822115 Test MSE 0.0007902479007137732 Test RE 0.01343661073678398\n",
      "122 Train Loss 0.0005739027 Test MSE 0.0007566114602922848 Test RE 0.013147540517692102\n",
      "123 Train Loss 0.0005620493 Test MSE 0.0007732610771864111 Test RE 0.013291412462068533\n",
      "124 Train Loss 0.0005535742 Test MSE 0.0007401489661556177 Test RE 0.013003720573072869\n",
      "125 Train Loss 0.0005409551 Test MSE 0.0007066213631233485 Test RE 0.012705783236209802\n",
      "126 Train Loss 0.00052948645 Test MSE 0.0007212817750582854 Test RE 0.012836911280709372\n",
      "127 Train Loss 0.00052277313 Test MSE 0.0006891179949440458 Test RE 0.012547432142995061\n",
      "128 Train Loss 0.0005166782 Test MSE 0.0006580675124549942 Test RE 0.01226149105925945\n",
      "129 Train Loss 0.0005077516 Test MSE 0.0006433111655437466 Test RE 0.012123237266018353\n",
      "130 Train Loss 0.00050061935 Test MSE 0.0006157101308447173 Test RE 0.011860314627229765\n",
      "131 Train Loss 0.0004939984 Test MSE 0.0006128509855569538 Test RE 0.011832744980694013\n",
      "132 Train Loss 0.0004876327 Test MSE 0.0006407088051391346 Test RE 0.012098691598983871\n",
      "133 Train Loss 0.00047862 Test MSE 0.0006198758881480767 Test RE 0.011900369112137169\n",
      "134 Train Loss 0.0004637199 Test MSE 0.0005546818382092068 Test RE 0.01125719096236448\n",
      "135 Train Loss 0.00045164424 Test MSE 0.0005385259916901382 Test RE 0.011092039177516645\n",
      "136 Train Loss 0.00044606725 Test MSE 0.0005034227363560948 Test RE 0.010724436281849875\n",
      "137 Train Loss 0.0004422752 Test MSE 0.0004903540443560954 Test RE 0.010584319500896135\n",
      "138 Train Loss 0.0004369141 Test MSE 0.0004992290031156394 Test RE 0.010679673222767815\n",
      "139 Train Loss 0.0004304001 Test MSE 0.00047936023567381506 Test RE 0.01046499590853921\n",
      "140 Train Loss 0.00042270875 Test MSE 0.0004730895531631426 Test RE 0.01039632240834788\n",
      "141 Train Loss 0.00041213547 Test MSE 0.0004727929107741938 Test RE 0.010393062482730466\n",
      "142 Train Loss 0.00040231264 Test MSE 0.0004578769079131391 Test RE 0.010227804802789215\n",
      "143 Train Loss 0.00039485382 Test MSE 0.0004292539964787976 Test RE 0.009902964766990171\n",
      "144 Train Loss 0.0003906101 Test MSE 0.0004116876339097877 Test RE 0.009698218651813422\n",
      "145 Train Loss 0.00038416486 Test MSE 0.0003916592438546957 Test RE 0.009459370822487724\n",
      "146 Train Loss 0.00037845384 Test MSE 0.000383311778235068 Test RE 0.009358023735947449\n",
      "147 Train Loss 0.00037057718 Test MSE 0.00034936249882068493 Test RE 0.00893400524064427\n",
      "148 Train Loss 0.00036410298 Test MSE 0.0003516006456721922 Test RE 0.008962576843338187\n",
      "149 Train Loss 0.0003545185 Test MSE 0.00034302102900755335 Test RE 0.00885255090941696\n",
      "Training time: 227.52\n",
      "5\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 51.5384 Test MSE 8.644425614618257 Test RE 1.4053229253175485\n",
      "1 Train Loss 42.943592 Test MSE 8.799776574967895 Test RE 1.4178943863770304\n",
      "2 Train Loss 37.927242 Test MSE 9.642264440762931 Test RE 1.4842176069880293\n",
      "3 Train Loss 33.789764 Test MSE 9.484660614209858 Test RE 1.4720377853624433\n",
      "4 Train Loss 29.957632 Test MSE 9.50176033244404 Test RE 1.4733641425892525\n",
      "5 Train Loss 26.811722 Test MSE 9.393850641898212 Test RE 1.4649738943459016\n",
      "6 Train Loss 23.645971 Test MSE 9.314263479881918 Test RE 1.458754872845883\n",
      "7 Train Loss 20.32062 Test MSE 8.979230822202513 Test RE 1.432279012538103\n",
      "8 Train Loss 17.363102 Test MSE 8.568752333495695 Test RE 1.399158307639004\n",
      "9 Train Loss 15.225969 Test MSE 8.250341764068443 Test RE 1.372916200950936\n",
      "10 Train Loss 12.13943 Test MSE 7.951347714256313 Test RE 1.347809251584824\n",
      "11 Train Loss 10.180399 Test MSE 7.6694501472077325 Test RE 1.3237018465005583\n",
      "12 Train Loss 8.227289 Test MSE 7.137283206834982 Test RE 1.2769518605158692\n",
      "13 Train Loss 5.886281 Test MSE 6.537724133103972 Test RE 1.222141117900507\n",
      "14 Train Loss 3.861123 Test MSE 6.009681147065465 Test RE 1.1717467982547052\n",
      "15 Train Loss 2.6825297 Test MSE 5.560064439758599 Test RE 1.1270624292438145\n",
      "16 Train Loss 2.1166453 Test MSE 5.4140113191319985 Test RE 1.1121609445007126\n",
      "17 Train Loss 1.813855 Test MSE 5.3055504234965065 Test RE 1.1009644185351488\n",
      "18 Train Loss 1.6408458 Test MSE 5.418323802298538 Test RE 1.1126037973469052\n",
      "19 Train Loss 1.5121174 Test MSE 5.549084883024797 Test RE 1.1259490643569996\n",
      "20 Train Loss 1.4319685 Test MSE 5.449545639272257 Test RE 1.1158047537267697\n",
      "21 Train Loss 1.368191 Test MSE 5.458129705170072 Test RE 1.1166832097752313\n",
      "22 Train Loss 1.3258886 Test MSE 5.4958365797818765 Test RE 1.1205338109816103\n",
      "23 Train Loss 1.2892029 Test MSE 5.4991777149523475 Test RE 1.1208743675133566\n",
      "24 Train Loss 1.2576209 Test MSE 5.487152565842689 Test RE 1.1196481789187371\n",
      "25 Train Loss 1.2301843 Test MSE 5.5180626787342195 Test RE 1.1227973395343183\n",
      "26 Train Loss 1.2018418 Test MSE 5.496035379273643 Test RE 1.120554077189899\n",
      "27 Train Loss 1.1753299 Test MSE 5.543066991992849 Test RE 1.1253383621432242\n",
      "28 Train Loss 1.1536937 Test MSE 5.576444691679037 Test RE 1.1287214018617295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Train Loss 1.1365569 Test MSE 5.60454380534173 Test RE 1.131561582261671\n",
      "30 Train Loss 1.1182708 Test MSE 5.610227230305417 Test RE 1.1321351807541553\n",
      "31 Train Loss 1.0992998 Test MSE 5.625199296149132 Test RE 1.1336448440811013\n",
      "32 Train Loss 1.082783 Test MSE 5.669746654925542 Test RE 1.138124800488471\n",
      "33 Train Loss 1.0674946 Test MSE 5.706477969547984 Test RE 1.1418055055736385\n",
      "34 Train Loss 1.0491936 Test MSE 5.727725861795584 Test RE 1.1439292690136302\n",
      "35 Train Loss 1.0214225 Test MSE 5.808095623160664 Test RE 1.151926950663728\n",
      "36 Train Loss 1.0012062 Test MSE 5.816399998924206 Test RE 1.1527501651862218\n",
      "37 Train Loss 0.9883536 Test MSE 5.869109861818651 Test RE 1.1579616589263633\n",
      "38 Train Loss 0.97746146 Test MSE 5.868566636432809 Test RE 1.1579080691367885\n",
      "39 Train Loss 0.96540433 Test MSE 5.8608873942370145 Test RE 1.1571502378133955\n",
      "40 Train Loss 0.9535056 Test MSE 5.895790061807845 Test RE 1.1605906451094974\n",
      "41 Train Loss 0.9421982 Test MSE 5.899965025376262 Test RE 1.1610014947260099\n",
      "42 Train Loss 0.93054736 Test MSE 5.928008332861092 Test RE 1.1637574199685452\n",
      "43 Train Loss 0.92036986 Test MSE 5.928277356180752 Test RE 1.1637838263359876\n",
      "44 Train Loss 0.9056313 Test MSE 5.93188471497682 Test RE 1.164137853915613\n",
      "45 Train Loss 0.89698017 Test MSE 5.963378435004083 Test RE 1.1672240987663383\n",
      "46 Train Loss 0.887431 Test MSE 5.984191808294274 Test RE 1.1692592463299372\n",
      "47 Train Loss 0.87916315 Test MSE 5.996025323631478 Test RE 1.1704147585660374\n",
      "48 Train Loss 0.8704532 Test MSE 6.013557878850584 Test RE 1.1721246731871657\n",
      "49 Train Loss 0.86140186 Test MSE 6.040332668658251 Test RE 1.1747311614800235\n",
      "50 Train Loss 0.85494655 Test MSE 6.052751875615852 Test RE 1.1759381925227113\n",
      "51 Train Loss 0.848878 Test MSE 6.078021251852305 Test RE 1.1783903230240522\n",
      "52 Train Loss 0.8427277 Test MSE 6.096143558712211 Test RE 1.180145767406235\n",
      "53 Train Loss 0.8358876 Test MSE 6.120290177698904 Test RE 1.182480716314478\n",
      "54 Train Loss 0.8311339 Test MSE 6.119777961414533 Test RE 1.1824312334848663\n",
      "55 Train Loss 0.8254123 Test MSE 6.149110408031382 Test RE 1.1852615763856482\n",
      "56 Train Loss 0.8189755 Test MSE 6.19446026466822 Test RE 1.1896242157100145\n",
      "57 Train Loss 0.8112582 Test MSE 6.228488108583327 Test RE 1.192887204348353\n",
      "58 Train Loss 0.80653 Test MSE 6.253020953669752 Test RE 1.1952341749004787\n",
      "59 Train Loss 0.8013038 Test MSE 6.256446117416518 Test RE 1.195561481680048\n",
      "60 Train Loss 0.79816276 Test MSE 6.27026500685656 Test RE 1.1968810981872544\n",
      "61 Train Loss 0.7948071 Test MSE 6.284004460553106 Test RE 1.1981916882453951\n",
      "62 Train Loss 0.790223 Test MSE 6.288301258559556 Test RE 1.1986012605106144\n",
      "63 Train Loss 0.78621936 Test MSE 6.298951885248818 Test RE 1.1996158790200286\n",
      "64 Train Loss 0.78147644 Test MSE 6.320803366865208 Test RE 1.2016948510585432\n",
      "65 Train Loss 0.77682143 Test MSE 6.34817083753765 Test RE 1.2042935576692138\n",
      "66 Train Loss 0.7721152 Test MSE 6.354770406095949 Test RE 1.2049193878125322\n",
      "67 Train Loss 0.7670915 Test MSE 6.357707715386673 Test RE 1.2051978252544102\n",
      "68 Train Loss 0.76324767 Test MSE 6.375711837697062 Test RE 1.2069030930924396\n",
      "69 Train Loss 0.7594893 Test MSE 6.410887550944483 Test RE 1.2102278420321586\n",
      "70 Train Loss 0.7565459 Test MSE 6.419216198885173 Test RE 1.2110137152810376\n",
      "71 Train Loss 0.7521693 Test MSE 6.422230824746386 Test RE 1.2112980431982183\n",
      "72 Train Loss 0.748292 Test MSE 6.405902269292218 Test RE 1.2097571973683543\n",
      "73 Train Loss 0.7442937 Test MSE 6.410803505042825 Test RE 1.2102199090413865\n",
      "74 Train Loss 0.7408933 Test MSE 6.424733893641737 Test RE 1.2115340723264023\n",
      "75 Train Loss 0.73654854 Test MSE 6.4504458226714805 Test RE 1.2139559449036252\n",
      "76 Train Loss 0.7324917 Test MSE 6.475566416100876 Test RE 1.2163174608400393\n",
      "77 Train Loss 0.72880715 Test MSE 6.48511034365797 Test RE 1.2172134574909665\n",
      "78 Train Loss 0.7252392 Test MSE 6.485103527350535 Test RE 1.2172128178022887\n",
      "79 Train Loss 0.720535 Test MSE 6.526754860222641 Test RE 1.2211154071821593\n",
      "80 Train Loss 0.71661913 Test MSE 6.54753893033532 Test RE 1.223058147166024\n",
      "81 Train Loss 0.71078736 Test MSE 6.558377627852934 Test RE 1.224070044604667\n",
      "82 Train Loss 0.7062629 Test MSE 6.578767660975638 Test RE 1.2259713882739405\n",
      "83 Train Loss 0.702644 Test MSE 6.595046985701259 Test RE 1.2274872994582644\n",
      "84 Train Loss 0.69857013 Test MSE 6.613967426596458 Test RE 1.229246799247628\n",
      "85 Train Loss 0.6951431 Test MSE 6.638022622441982 Test RE 1.2314801739258299\n",
      "86 Train Loss 0.69223285 Test MSE 6.651721346102719 Test RE 1.232750206669375\n",
      "87 Train Loss 0.68845683 Test MSE 6.6911336721677275 Test RE 1.2363969165999331\n",
      "88 Train Loss 0.6842892 Test MSE 6.73440201248411 Test RE 1.2403880666120737\n",
      "89 Train Loss 0.68086165 Test MSE 6.741368588168591 Test RE 1.2410294764722591\n",
      "90 Train Loss 0.6780618 Test MSE 6.753707597796543 Test RE 1.2421647113895624\n",
      "91 Train Loss 0.67419785 Test MSE 6.781841750046643 Test RE 1.2447492866744931\n",
      "92 Train Loss 0.6704139 Test MSE 6.798191869801833 Test RE 1.2462488460157723\n",
      "93 Train Loss 0.6666979 Test MSE 6.805403815265099 Test RE 1.2469097199967776\n",
      "94 Train Loss 0.66332364 Test MSE 6.820785567283946 Test RE 1.2483180736568493\n",
      "95 Train Loss 0.65886605 Test MSE 6.818394295008336 Test RE 1.2480992330227365\n",
      "96 Train Loss 0.6544039 Test MSE 6.845981045251336 Test RE 1.2506215457730279\n",
      "97 Train Loss 0.6501292 Test MSE 6.846431245588508 Test RE 1.250662666321111\n",
      "98 Train Loss 0.644782 Test MSE 6.874809788954867 Test RE 1.2532519921163894\n",
      "99 Train Loss 0.6410349 Test MSE 6.892760928611789 Test RE 1.2548871380642328\n",
      "100 Train Loss 0.6372933 Test MSE 6.903290762493944 Test RE 1.2558452962350617\n",
      "101 Train Loss 0.6347193 Test MSE 6.911874025608824 Test RE 1.2566257864710897\n",
      "102 Train Loss 0.63112354 Test MSE 6.953258495294415 Test RE 1.2603821613546176\n",
      "103 Train Loss 0.6265729 Test MSE 6.951699362087941 Test RE 1.2602408453188785\n",
      "104 Train Loss 0.6233331 Test MSE 6.967512251068336 Test RE 1.2616733532516302\n",
      "105 Train Loss 0.61931586 Test MSE 6.982754941027146 Test RE 1.2630526683190042\n",
      "106 Train Loss 0.6154768 Test MSE 6.98423008201507 Test RE 1.2631860742873908\n",
      "107 Train Loss 0.61325943 Test MSE 6.987759041301873 Test RE 1.2635051623774267\n",
      "108 Train Loss 0.6111626 Test MSE 6.986592761520852 Test RE 1.2633997164105795\n",
      "109 Train Loss 0.6083211 Test MSE 6.990265036703633 Test RE 1.2637317052702217\n",
      "110 Train Loss 0.6062808 Test MSE 7.007322166808288 Test RE 1.2652725983837825\n",
      "111 Train Loss 0.60308665 Test MSE 7.019822464188933 Test RE 1.2664006495868536\n",
      "112 Train Loss 0.60010976 Test MSE 7.034472435448286 Test RE 1.2677214140132862\n",
      "113 Train Loss 0.5980431 Test MSE 7.050988838950715 Test RE 1.2692087979414688\n",
      "114 Train Loss 0.59590125 Test MSE 7.067802908456566 Test RE 1.270721199832108\n",
      "115 Train Loss 0.5925433 Test MSE 7.085419365418892 Test RE 1.2723038468001509\n",
      "116 Train Loss 0.5893239 Test MSE 7.1077636319530315 Test RE 1.2743084083652272\n",
      "117 Train Loss 0.5864791 Test MSE 7.111739708267697 Test RE 1.274664781998136\n",
      "118 Train Loss 0.5842327 Test MSE 7.115445810858974 Test RE 1.2749968683337212\n",
      "119 Train Loss 0.581289 Test MSE 7.1423602285658605 Test RE 1.2774059520550367\n",
      "120 Train Loss 0.57809234 Test MSE 7.1588135404464674 Test RE 1.2788764371355354\n",
      "121 Train Loss 0.5743489 Test MSE 7.177097072203138 Test RE 1.2805085139642733\n",
      "122 Train Loss 0.5706183 Test MSE 7.1955406249007 Test RE 1.2821527701855053\n",
      "123 Train Loss 0.56836116 Test MSE 7.201283058821022 Test RE 1.282664282076937\n",
      "124 Train Loss 0.5661082 Test MSE 7.213248062169942 Test RE 1.283729419550581\n",
      "125 Train Loss 0.5639311 Test MSE 7.204129827684679 Test RE 1.2829177846760518\n",
      "126 Train Loss 0.5612673 Test MSE 7.211025031997142 Test RE 1.2835315898685575\n",
      "127 Train Loss 0.5590762 Test MSE 7.231185937617176 Test RE 1.2853246149405864\n",
      "128 Train Loss 0.55662435 Test MSE 7.237712545972649 Test RE 1.2859045280031056\n",
      "129 Train Loss 0.5540642 Test MSE 7.254127124329851 Test RE 1.2873618687345765\n",
      "130 Train Loss 0.5509697 Test MSE 7.257439192564363 Test RE 1.2876557251626453\n",
      "131 Train Loss 0.54886866 Test MSE 7.267853593624799 Test RE 1.2885792847928237\n",
      "132 Train Loss 0.5467707 Test MSE 7.269016675032985 Test RE 1.2886823869421802\n",
      "133 Train Loss 0.54475844 Test MSE 7.280392006005614 Test RE 1.2896903264437334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 Train Loss 0.5424429 Test MSE 7.282286344945621 Test RE 1.2898581025539926\n",
      "135 Train Loss 0.5401191 Test MSE 7.301475395520248 Test RE 1.2915563925981806\n",
      "136 Train Loss 0.53793865 Test MSE 7.317947843817216 Test RE 1.2930124757099724\n",
      "137 Train Loss 0.53592515 Test MSE 7.309339535731857 Test RE 1.2922517484379563\n",
      "138 Train Loss 0.53369457 Test MSE 7.304146279343446 Test RE 1.2917925970281374\n",
      "139 Train Loss 0.53119725 Test MSE 7.317643274136012 Test RE 1.2929855681326308\n",
      "140 Train Loss 0.52876294 Test MSE 7.322069807918749 Test RE 1.2933765805665192\n",
      "141 Train Loss 0.5270198 Test MSE 7.328287755263185 Test RE 1.2939256357551157\n",
      "142 Train Loss 0.5253958 Test MSE 7.329202631503658 Test RE 1.2940064012024195\n",
      "143 Train Loss 0.5239351 Test MSE 7.331396443780168 Test RE 1.2942000508306246\n",
      "144 Train Loss 0.5221762 Test MSE 7.326026206124231 Test RE 1.2937259641328922\n",
      "145 Train Loss 0.520716 Test MSE 7.333337902786141 Test RE 1.2943714008619567\n",
      "146 Train Loss 0.5190825 Test MSE 7.338698268997611 Test RE 1.29484438038193\n",
      "147 Train Loss 0.51773614 Test MSE 7.348985552247732 Test RE 1.2957516098106978\n",
      "148 Train Loss 0.51636183 Test MSE 7.34879576314521 Test RE 1.295734878173309\n",
      "149 Train Loss 0.5148765 Test MSE 7.35834895605984 Test RE 1.296576811014345\n",
      "Training time: 228.34\n",
      "6\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 51.846325 Test MSE 9.609625270442224 Test RE 1.4817034311607247\n",
      "1 Train Loss 39.622414 Test MSE 9.080183324997492 Test RE 1.4403079859624506\n",
      "2 Train Loss 35.70738 Test MSE 8.957997697130148 Test RE 1.4305845600887765\n",
      "3 Train Loss 32.95685 Test MSE 9.381658018662788 Test RE 1.4640228639812203\n",
      "4 Train Loss 28.72744 Test MSE 9.023360254396717 Test RE 1.4357942463729665\n",
      "5 Train Loss 24.874685 Test MSE 8.847999256522609 Test RE 1.4217741014791387\n",
      "6 Train Loss 21.111038 Test MSE 8.778831921545432 Test RE 1.4162059913241922\n",
      "7 Train Loss 18.254108 Test MSE 8.718930012040293 Test RE 1.4113660163767685\n",
      "8 Train Loss 15.562992 Test MSE 8.655465729866448 Test RE 1.4062200338842146\n",
      "9 Train Loss 13.705402 Test MSE 8.484338471837724 Test RE 1.3922494441977402\n",
      "10 Train Loss 11.935743 Test MSE 8.53674901740549 Test RE 1.3965430147698743\n",
      "11 Train Loss 10.573991 Test MSE 8.221901079895007 Test RE 1.3705477908982449\n",
      "12 Train Loss 9.147118 Test MSE 7.931308914558952 Test RE 1.3461098215885468\n",
      "13 Train Loss 7.3412075 Test MSE 7.477432405273804 Test RE 1.3070262446795147\n",
      "14 Train Loss 6.1962643 Test MSE 7.3486556128535 Test RE 1.2957225225103657\n",
      "15 Train Loss 4.797039 Test MSE 7.143480291969855 Test RE 1.2775061093926725\n",
      "16 Train Loss 3.9240246 Test MSE 6.756633868377164 Test RE 1.2424337870303988\n",
      "17 Train Loss 3.1123154 Test MSE 6.5539253669215904 Test RE 1.2236544841722767\n",
      "18 Train Loss 2.605022 Test MSE 6.358145227010652 Test RE 1.2052392929508038\n",
      "19 Train Loss 2.2434676 Test MSE 6.293822624036186 Test RE 1.1991273535912856\n",
      "20 Train Loss 1.9950012 Test MSE 6.283411242901988 Test RE 1.1981351315355\n",
      "21 Train Loss 1.8118435 Test MSE 6.280693148911877 Test RE 1.1978759573351752\n",
      "22 Train Loss 1.6329672 Test MSE 6.28543076765486 Test RE 1.1983276598509054\n",
      "23 Train Loss 1.446883 Test MSE 6.11152534704731 Test RE 1.1816337012034153\n",
      "24 Train Loss 1.3428705 Test MSE 5.991224002523715 Test RE 1.1699460595367324\n",
      "25 Train Loss 1.2646458 Test MSE 5.868463428129839 Test RE 1.1578978872423291\n",
      "26 Train Loss 1.1904774 Test MSE 5.8263838120708735 Test RE 1.153739085117521\n",
      "27 Train Loss 1.1346791 Test MSE 5.725716431594669 Test RE 1.1437285918411007\n",
      "28 Train Loss 1.0798413 Test MSE 5.746861190324691 Test RE 1.1458385093618046\n",
      "29 Train Loss 1.042124 Test MSE 5.782927496272076 Test RE 1.149428427804493\n",
      "30 Train Loss 1.0088121 Test MSE 5.807229397970562 Test RE 1.151841047691944\n",
      "31 Train Loss 0.976351 Test MSE 5.843169596752988 Test RE 1.155399848285954\n",
      "32 Train Loss 0.94704866 Test MSE 5.8829251964352185 Test RE 1.1593237244697174\n",
      "33 Train Loss 0.9307618 Test MSE 5.951181697719126 Test RE 1.1660298418038182\n",
      "34 Train Loss 0.9130436 Test MSE 5.972776413141106 Test RE 1.1681434793005763\n",
      "35 Train Loss 0.89605826 Test MSE 6.01350613865508 Test RE 1.1721196307404633\n",
      "36 Train Loss 0.88098264 Test MSE 6.071209631190096 Test RE 1.1777298286222533\n",
      "37 Train Loss 0.86347824 Test MSE 6.096113553754246 Test RE 1.1801428630891555\n",
      "38 Train Loss 0.8514704 Test MSE 6.118006574159017 Test RE 1.1822600920463553\n",
      "39 Train Loss 0.84062064 Test MSE 6.0947081667633 Test RE 1.1800068212475914\n",
      "40 Train Loss 0.82851535 Test MSE 6.111036831429926 Test RE 1.1815864742003281\n",
      "41 Train Loss 0.81869495 Test MSE 6.132725356109452 Test RE 1.1836813862797244\n",
      "42 Train Loss 0.8093493 Test MSE 6.169051774391026 Test RE 1.1871819032530273\n",
      "43 Train Loss 0.8007078 Test MSE 6.176012176324626 Test RE 1.187851449726105\n",
      "44 Train Loss 0.7915709 Test MSE 6.179157514138241 Test RE 1.1881538874805344\n",
      "45 Train Loss 0.78023946 Test MSE 6.188530805012995 Test RE 1.189054713500387\n",
      "46 Train Loss 0.77291405 Test MSE 6.178906873574909 Test RE 1.188129790135636\n",
      "47 Train Loss 0.7652656 Test MSE 6.186305975652875 Test RE 1.1888409566549922\n",
      "48 Train Loss 0.7569616 Test MSE 6.19580292673843 Test RE 1.1897531354787148\n",
      "49 Train Loss 0.7492827 Test MSE 6.204720144347466 Test RE 1.1906089949343026\n",
      "50 Train Loss 0.7388333 Test MSE 6.230448875441173 Test RE 1.1930749537349423\n",
      "51 Train Loss 0.7329184 Test MSE 6.2254347480454735 Test RE 1.192594776944604\n",
      "52 Train Loss 0.72620076 Test MSE 6.246064516375632 Test RE 1.19456914551609\n",
      "53 Train Loss 0.7208918 Test MSE 6.243242098866383 Test RE 1.1942992192426074\n",
      "54 Train Loss 0.71586156 Test MSE 6.243816173565134 Test RE 1.1943541267084332\n",
      "55 Train Loss 0.710212 Test MSE 6.25847883371884 Test RE 1.195755684579343\n",
      "56 Train Loss 0.7064122 Test MSE 6.253677577295924 Test RE 1.195296928440062\n",
      "57 Train Loss 0.70242506 Test MSE 6.2608908612489484 Test RE 1.1959860854377042\n",
      "58 Train Loss 0.6981305 Test MSE 6.280982474673097 Test RE 1.1979035476324353\n",
      "59 Train Loss 0.69479215 Test MSE 6.2895270395321266 Test RE 1.1987180767195054\n",
      "60 Train Loss 0.6907907 Test MSE 6.310599809940212 Test RE 1.2007245223274496\n",
      "61 Train Loss 0.68628824 Test MSE 6.319863103439475 Test RE 1.2016054675043208\n",
      "62 Train Loss 0.68270004 Test MSE 6.343383111202347 Test RE 1.2038393389917768\n",
      "63 Train Loss 0.67951345 Test MSE 6.34761288674145 Test RE 1.2042406328715363\n",
      "64 Train Loss 0.6765079 Test MSE 6.337857350210701 Test RE 1.2033148887377052\n",
      "65 Train Loss 0.673068 Test MSE 6.3374309901314865 Test RE 1.203274413382107\n",
      "66 Train Loss 0.67069674 Test MSE 6.355036660729399 Test RE 1.204944629637893\n",
      "67 Train Loss 0.66757023 Test MSE 6.35393515785092 Test RE 1.2048402000676135\n",
      "68 Train Loss 0.6649855 Test MSE 6.356255778878152 Test RE 1.2050601993427954\n",
      "69 Train Loss 0.6619432 Test MSE 6.372959528919299 Test RE 1.2066425630818447\n",
      "70 Train Loss 0.6590949 Test MSE 6.387247826084989 Test RE 1.2079944636129107\n",
      "71 Train Loss 0.6564845 Test MSE 6.392427258671765 Test RE 1.2084841469769987\n",
      "72 Train Loss 0.65437126 Test MSE 6.3928813835765395 Test RE 1.2085270722211523\n",
      "73 Train Loss 0.6522877 Test MSE 6.389795898146333 Test RE 1.2082353928914376\n",
      "74 Train Loss 0.64927864 Test MSE 6.3911907944879776 Test RE 1.2083672649564723\n",
      "75 Train Loss 0.64600706 Test MSE 6.394388717044372 Test RE 1.2086695389609003\n",
      "76 Train Loss 0.64350516 Test MSE 6.403533881728276 Test RE 1.2095335412261063\n",
      "77 Train Loss 0.6410529 Test MSE 6.416707229636263 Test RE 1.2107770280417374\n",
      "78 Train Loss 0.63885534 Test MSE 6.43511139906624 Test RE 1.212512138400442\n",
      "79 Train Loss 0.6366615 Test MSE 6.449238711216097 Test RE 1.2138423520814765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Train Loss 0.63450146 Test MSE 6.45404778127699 Test RE 1.2142948368911233\n",
      "81 Train Loss 0.6318071 Test MSE 6.472782075678991 Test RE 1.216055938852873\n",
      "82 Train Loss 0.6290975 Test MSE 6.495433270512806 Test RE 1.2181818457303188\n",
      "83 Train Loss 0.6267871 Test MSE 6.503593482214803 Test RE 1.218946806372518\n",
      "84 Train Loss 0.62415713 Test MSE 6.499940433217849 Test RE 1.2186044188995393\n",
      "85 Train Loss 0.62175024 Test MSE 6.51452380581705 Test RE 1.219970693376295\n",
      "86 Train Loss 0.6197516 Test MSE 6.523530454027242 Test RE 1.2208137367055816\n",
      "87 Train Loss 0.6174805 Test MSE 6.532310909475991 Test RE 1.221635047817069\n",
      "88 Train Loss 0.6146227 Test MSE 6.548720799989785 Test RE 1.2231685268140817\n",
      "89 Train Loss 0.6117766 Test MSE 6.57070276086554 Test RE 1.2252196997077767\n",
      "90 Train Loss 0.6087176 Test MSE 6.58598540731374 Test RE 1.226643727322301\n",
      "91 Train Loss 0.6062984 Test MSE 6.589051465316379 Test RE 1.2269292216685368\n",
      "92 Train Loss 0.60362303 Test MSE 6.618962036951765 Test RE 1.229710851285986\n",
      "93 Train Loss 0.60117495 Test MSE 6.635188547896007 Test RE 1.2312172583397971\n",
      "94 Train Loss 0.59834146 Test MSE 6.6367814633048665 Test RE 1.2313650391627677\n",
      "95 Train Loss 0.5958394 Test MSE 6.648729827070365 Test RE 1.2324729693769183\n",
      "96 Train Loss 0.5926021 Test MSE 6.669060016836718 Test RE 1.2343558316029366\n",
      "97 Train Loss 0.5899431 Test MSE 6.673288955939829 Test RE 1.234747130254642\n",
      "98 Train Loss 0.58812463 Test MSE 6.687236399321884 Test RE 1.236036792425229\n",
      "99 Train Loss 0.584514 Test MSE 6.706075679151862 Test RE 1.237776649095922\n",
      "100 Train Loss 0.58177984 Test MSE 6.710072405983677 Test RE 1.2381454428963223\n",
      "101 Train Loss 0.57900393 Test MSE 6.717397307801477 Test RE 1.2388210555822528\n",
      "102 Train Loss 0.5763834 Test MSE 6.731234274894148 Test RE 1.2400963045473312\n",
      "103 Train Loss 0.57404435 Test MSE 6.745304403592117 Test RE 1.2413916989330485\n",
      "104 Train Loss 0.57200146 Test MSE 6.75265125345787 Test RE 1.242067564381499\n",
      "105 Train Loss 0.5691912 Test MSE 6.7760120150613306 Test RE 1.2442141725525424\n",
      "106 Train Loss 0.56714857 Test MSE 6.77304532252926 Test RE 1.2439417700688065\n",
      "107 Train Loss 0.5649829 Test MSE 6.76883360685319 Test RE 1.24355494674745\n",
      "108 Train Loss 0.56287056 Test MSE 6.764162853116728 Test RE 1.2431258225001118\n",
      "109 Train Loss 0.5599668 Test MSE 6.780463500813055 Test RE 1.2446227972941026\n",
      "110 Train Loss 0.5582467 Test MSE 6.780510368077508 Test RE 1.2446270987673704\n",
      "111 Train Loss 0.55618614 Test MSE 6.785644288056195 Test RE 1.2450981995041628\n",
      "112 Train Loss 0.55417 Test MSE 6.793775443534439 Test RE 1.2458439692158672\n",
      "113 Train Loss 0.5523295 Test MSE 6.80162607742981 Test RE 1.246563586832219\n",
      "114 Train Loss 0.55017996 Test MSE 6.799375566047743 Test RE 1.246357339266626\n",
      "115 Train Loss 0.54833674 Test MSE 6.799311821464454 Test RE 1.2463514969128202\n",
      "116 Train Loss 0.5467989 Test MSE 6.801669671134052 Test RE 1.2465675816296857\n",
      "117 Train Loss 0.54508543 Test MSE 6.811898326260616 Test RE 1.2475045515451546\n",
      "118 Train Loss 0.5432192 Test MSE 6.814538988494655 Test RE 1.247746328418773\n",
      "119 Train Loss 0.54115784 Test MSE 6.819503136658071 Test RE 1.248200714991311\n",
      "120 Train Loss 0.5393096 Test MSE 6.834616192759722 Test RE 1.2495830508576569\n",
      "121 Train Loss 0.53741443 Test MSE 6.842962164099656 Test RE 1.2503457712639696\n",
      "122 Train Loss 0.53573066 Test MSE 6.847512765724808 Test RE 1.2507614450421227\n",
      "123 Train Loss 0.5332656 Test MSE 6.850327060802197 Test RE 1.2510184471314563\n",
      "124 Train Loss 0.53164434 Test MSE 6.849368039709943 Test RE 1.250930875030142\n",
      "125 Train Loss 0.5295148 Test MSE 6.858299638111384 Test RE 1.251746218297281\n",
      "126 Train Loss 0.52722555 Test MSE 6.875604201020334 Test RE 1.253324399191965\n",
      "127 Train Loss 0.5251297 Test MSE 6.875791231735389 Test RE 1.253341445589462\n",
      "128 Train Loss 0.52329725 Test MSE 6.877873233127484 Test RE 1.2535311881979345\n",
      "129 Train Loss 0.5217771 Test MSE 6.877538870042066 Test RE 1.25350071804854\n",
      "130 Train Loss 0.52023995 Test MSE 6.8837603603918005 Test RE 1.2540675545203384\n",
      "131 Train Loss 0.5189484 Test MSE 6.888242436577091 Test RE 1.2544757552262142\n",
      "132 Train Loss 0.51757216 Test MSE 6.885674194215577 Test RE 1.2542418713168562\n",
      "133 Train Loss 0.5160935 Test MSE 6.89709537043018 Test RE 1.2552816374899258\n",
      "134 Train Loss 0.51497155 Test MSE 6.908633848604975 Test RE 1.2563312088168603\n",
      "135 Train Loss 0.5134749 Test MSE 6.922558467564878 Test RE 1.257596663586981\n",
      "136 Train Loss 0.5120913 Test MSE 6.9312303762595056 Test RE 1.2583841145135233\n",
      "137 Train Loss 0.5108901 Test MSE 6.9266626946029675 Test RE 1.2579694085375857\n",
      "138 Train Loss 0.50962096 Test MSE 6.936876588052133 Test RE 1.2588965528879605\n",
      "139 Train Loss 0.50843585 Test MSE 6.951911671343776 Test RE 1.2602600894446139\n",
      "140 Train Loss 0.5073073 Test MSE 6.951591469786381 Test RE 1.2602310656372628\n",
      "141 Train Loss 0.50549 Test MSE 6.958318168326748 Test RE 1.260840648691848\n",
      "142 Train Loss 0.5038353 Test MSE 6.959068035172291 Test RE 1.2609085844420103\n",
      "143 Train Loss 0.50253534 Test MSE 6.9734762188247945 Test RE 1.2622132137797395\n",
      "144 Train Loss 0.5006903 Test MSE 6.973721949510223 Test RE 1.2622354524578472\n",
      "145 Train Loss 0.4994689 Test MSE 6.986250297302999 Test RE 1.2633687517821341\n",
      "146 Train Loss 0.49831277 Test MSE 6.998880084384748 Test RE 1.264510199110704\n",
      "147 Train Loss 0.49713904 Test MSE 7.006437189064422 Test RE 1.2651926981437962\n",
      "148 Train Loss 0.49600866 Test MSE 7.001898235468265 Test RE 1.264782819260035\n",
      "149 Train Loss 0.49470213 Test MSE 7.0226518223671945 Test RE 1.2666558369567107\n",
      "Training time: 228.75\n",
      "7\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 53.69666 Test MSE 8.233208574289227 Test RE 1.3714899170925912\n",
      "1 Train Loss 42.67866 Test MSE 8.531912836209782 Test RE 1.3961473786868248\n",
      "2 Train Loss 35.892128 Test MSE 8.013105825056066 Test RE 1.353033343969318\n",
      "3 Train Loss 27.467407 Test MSE 6.848324423487348 Test RE 1.2508355712386723\n",
      "4 Train Loss 20.5666 Test MSE 6.425523719838239 Test RE 1.2116085401531407\n",
      "5 Train Loss 16.684639 Test MSE 6.33471106910542 Test RE 1.2030161728886997\n",
      "6 Train Loss 14.409945 Test MSE 6.4271124796551184 Test RE 1.2117583206279363\n",
      "7 Train Loss 12.203771 Test MSE 6.046802667307516 Test RE 1.1753601396543603\n",
      "8 Train Loss 10.900026 Test MSE 5.958519284288738 Test RE 1.1667484561653059\n",
      "9 Train Loss 9.548779 Test MSE 5.543489431197142 Test RE 1.1253812425545504\n",
      "10 Train Loss 8.416125 Test MSE 5.447573132430428 Test RE 1.1156027982011234\n",
      "11 Train Loss 7.2342377 Test MSE 5.175889687710582 Test RE 1.0874281371533712\n",
      "12 Train Loss 6.1777387 Test MSE 5.111269864391442 Test RE 1.0806186683752912\n",
      "13 Train Loss 4.7358484 Test MSE 4.775025218637953 Test RE 1.0444698188837118\n",
      "14 Train Loss 3.7210736 Test MSE 4.32587753673453 Test RE 0.9941345571717356\n",
      "15 Train Loss 2.8863218 Test MSE 3.4506273301693686 Test RE 0.8878857566732233\n",
      "16 Train Loss 2.36649 Test MSE 3.1096924686758025 Test RE 0.8428820034009809\n",
      "17 Train Loss 2.0201309 Test MSE 2.9065474640200812 Test RE 0.8148858375567366\n",
      "18 Train Loss 1.8045992 Test MSE 2.730075447693812 Test RE 0.7897604568587057\n",
      "19 Train Loss 1.6213832 Test MSE 2.4312825999382905 Test RE 0.7452908360453524\n",
      "20 Train Loss 1.503376 Test MSE 2.2748102790309606 Test RE 0.7209093384434658\n",
      "21 Train Loss 1.3748922 Test MSE 2.21577568351246 Test RE 0.7114935318349072\n",
      "22 Train Loss 1.300882 Test MSE 2.1002090936478304 Test RE 0.6926906532596239\n",
      "23 Train Loss 1.2326931 Test MSE 2.0387516055819725 Test RE 0.6824804547300458\n",
      "24 Train Loss 1.1326468 Test MSE 1.8791699254719267 Test RE 0.6552259466151146\n",
      "25 Train Loss 0.9944045 Test MSE 1.6737725353313053 Test RE 0.6183812017480361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 Train Loss 0.84976125 Test MSE 1.4874774776680828 Test RE 0.5829526214729827\n",
      "27 Train Loss 0.73380864 Test MSE 1.2447093612887454 Test RE 0.5332637203016579\n",
      "28 Train Loss 0.6011186 Test MSE 1.037214678681205 Test RE 0.48679082874289314\n",
      "29 Train Loss 0.49267223 Test MSE 0.8883306119720145 Test RE 0.4505006006742392\n",
      "30 Train Loss 0.40858355 Test MSE 0.7835448626285615 Test RE 0.42309704683089855\n",
      "31 Train Loss 0.35285974 Test MSE 0.7059005698028921 Test RE 0.4015871673101468\n",
      "32 Train Loss 0.29448834 Test MSE 0.6723207585048827 Test RE 0.3919190020749545\n",
      "33 Train Loss 0.2530142 Test MSE 0.6422197401690083 Test RE 0.38304507744126015\n",
      "34 Train Loss 0.22239298 Test MSE 0.6267963836692901 Test RE 0.3784175776390349\n",
      "35 Train Loss 0.20389862 Test MSE 0.6062525641685836 Test RE 0.3721644230460719\n",
      "36 Train Loss 0.18906341 Test MSE 0.5599077154895253 Test RE 0.3576566351103139\n",
      "37 Train Loss 0.17474292 Test MSE 0.5302979489643419 Test RE 0.3480711546922383\n",
      "38 Train Loss 0.16098449 Test MSE 0.5220353242140187 Test RE 0.34534884338083605\n",
      "39 Train Loss 0.15294023 Test MSE 0.502511633388002 Test RE 0.33882942630255086\n",
      "40 Train Loss 0.14651625 Test MSE 0.4995182457928675 Test RE 0.3378187404987874\n",
      "41 Train Loss 0.13991544 Test MSE 0.4972078437874427 Test RE 0.3370365851962561\n",
      "42 Train Loss 0.13293822 Test MSE 0.4794073437262527 Test RE 0.33094848816515826\n",
      "43 Train Loss 0.12845227 Test MSE 0.4854643140760393 Test RE 0.33303257530945257\n",
      "44 Train Loss 0.12497281 Test MSE 0.4778840953252492 Test RE 0.3304222990702184\n",
      "45 Train Loss 0.1216271 Test MSE 0.4807458053130203 Test RE 0.3314101551566858\n",
      "46 Train Loss 0.119640954 Test MSE 0.47943462948866156 Test RE 0.3309579060990404\n",
      "47 Train Loss 0.116944425 Test MSE 0.4635061763376839 Test RE 0.32541369264718323\n",
      "48 Train Loss 0.11495093 Test MSE 0.4640091598455598 Test RE 0.3255902095400382\n",
      "49 Train Loss 0.11256413 Test MSE 0.4704168495555697 Test RE 0.3278306047171462\n",
      "50 Train Loss 0.110241696 Test MSE 0.465751879622634 Test RE 0.3262010603317938\n",
      "51 Train Loss 0.108659 Test MSE 0.4750184805020842 Test RE 0.3294301267246315\n",
      "52 Train Loss 0.10691028 Test MSE 0.48070325982872103 Test RE 0.3313954901119058\n",
      "53 Train Loss 0.10566225 Test MSE 0.48578739163561324 Test RE 0.3331433738308776\n",
      "54 Train Loss 0.10402812 Test MSE 0.4926618623279293 Test RE 0.3354922810022377\n",
      "55 Train Loss 0.10107166 Test MSE 0.493414356927841 Test RE 0.33574839967294634\n",
      "56 Train Loss 0.09939875 Test MSE 0.4932487209494892 Test RE 0.3356920406697981\n",
      "57 Train Loss 0.097506255 Test MSE 0.49816075555563394 Test RE 0.3373594002914194\n",
      "58 Train Loss 0.09494473 Test MSE 0.5012685595601096 Test RE 0.33841008198959316\n",
      "59 Train Loss 0.09289736 Test MSE 0.5069796590276753 Test RE 0.3403324246184299\n",
      "60 Train Loss 0.09117873 Test MSE 0.5033906483043746 Test RE 0.3391256443071773\n",
      "61 Train Loss 0.08962924 Test MSE 0.4999023389114214 Test RE 0.3379485945345589\n",
      "62 Train Loss 0.088410035 Test MSE 0.505894523163933 Test RE 0.33996800689451084\n",
      "63 Train Loss 0.087669544 Test MSE 0.5078465862319849 Test RE 0.3406232818648501\n",
      "64 Train Loss 0.08675169 Test MSE 0.5094677188431106 Test RE 0.34116651239132695\n",
      "65 Train Loss 0.08560228 Test MSE 0.5089601983752391 Test RE 0.34099653878468345\n",
      "66 Train Loss 0.08443132 Test MSE 0.5093843493381159 Test RE 0.3411385969357415\n",
      "67 Train Loss 0.083525464 Test MSE 0.5093248839602497 Test RE 0.3411186841452562\n",
      "68 Train Loss 0.08220476 Test MSE 0.5123842393033717 Test RE 0.34214164693506527\n",
      "69 Train Loss 0.0814056 Test MSE 0.5136016283441097 Test RE 0.3425478580825024\n",
      "70 Train Loss 0.08060079 Test MSE 0.5141671422222807 Test RE 0.3427363916292179\n",
      "71 Train Loss 0.079690196 Test MSE 0.5138837243308745 Test RE 0.3426419174717654\n",
      "72 Train Loss 0.079133786 Test MSE 0.5165080964562202 Test RE 0.34351572871729646\n",
      "73 Train Loss 0.078519836 Test MSE 0.5172556686427018 Test RE 0.3437642339701162\n",
      "74 Train Loss 0.0778477 Test MSE 0.5165468518499866 Test RE 0.34352861606378754\n",
      "75 Train Loss 0.077290505 Test MSE 0.5189217747376232 Test RE 0.3443174296616011\n",
      "76 Train Loss 0.07611898 Test MSE 0.5222723647966123 Test RE 0.345427240757997\n",
      "77 Train Loss 0.075410336 Test MSE 0.5229587082321873 Test RE 0.3456541375805462\n",
      "78 Train Loss 0.07458478 Test MSE 0.5260341058635257 Test RE 0.34666900321828814\n",
      "79 Train Loss 0.074028835 Test MSE 0.5251343201517291 Test RE 0.3463723862163444\n",
      "80 Train Loss 0.07355013 Test MSE 0.5249497666584986 Test RE 0.3463115162172219\n",
      "81 Train Loss 0.07317206 Test MSE 0.5264871925793969 Test RE 0.3468182685516766\n",
      "82 Train Loss 0.07280172 Test MSE 0.5296657460756922 Test RE 0.3478636136169994\n",
      "83 Train Loss 0.072150536 Test MSE 0.5248710266582843 Test RE 0.34628554269250655\n",
      "84 Train Loss 0.07172725 Test MSE 0.5259632797461292 Test RE 0.34664566438362576\n",
      "85 Train Loss 0.07126302 Test MSE 0.5284945927467442 Test RE 0.34747881708759365\n",
      "86 Train Loss 0.07087455 Test MSE 0.5287878444115918 Test RE 0.34757520843341544\n",
      "87 Train Loss 0.07013778 Test MSE 0.5282737152798382 Test RE 0.347406197364664\n",
      "88 Train Loss 0.06940286 Test MSE 0.5315008721884875 Test RE 0.34846571184628355\n",
      "89 Train Loss 0.0683788 Test MSE 0.5296603744108934 Test RE 0.34786184966352535\n",
      "90 Train Loss 0.067622304 Test MSE 0.5361285467296414 Test RE 0.34997943559337324\n",
      "91 Train Loss 0.06709099 Test MSE 0.5377605344002462 Test RE 0.3505117035820497\n",
      "92 Train Loss 0.0664503 Test MSE 0.5402391027273059 Test RE 0.351318538969209\n",
      "93 Train Loss 0.065961376 Test MSE 0.5442855083395681 Test RE 0.3526317772278709\n",
      "94 Train Loss 0.06558942 Test MSE 0.5423290882828574 Test RE 0.3519974438303065\n",
      "95 Train Loss 0.065208696 Test MSE 0.5434705110119152 Test RE 0.3523676680276941\n",
      "96 Train Loss 0.06478196 Test MSE 0.5442376864987984 Test RE 0.3526162854768756\n",
      "97 Train Loss 0.064448185 Test MSE 0.5465865223968456 Test RE 0.35337638175507996\n",
      "98 Train Loss 0.06390812 Test MSE 0.549498838896848 Test RE 0.3543165591989378\n",
      "99 Train Loss 0.0632375 Test MSE 0.5527732140933485 Test RE 0.3553706489364655\n",
      "100 Train Loss 0.06273508 Test MSE 0.556416794450275 Test RE 0.356539930294873\n",
      "101 Train Loss 0.062343717 Test MSE 0.5590679340934005 Test RE 0.3573883175944451\n",
      "102 Train Loss 0.061973006 Test MSE 0.5616381861554753 Test RE 0.3582089018735268\n",
      "103 Train Loss 0.06154312 Test MSE 0.5639292346561086 Test RE 0.3589387656559397\n",
      "104 Train Loss 0.061039932 Test MSE 0.5670581364953223 Test RE 0.35993315517629987\n",
      "105 Train Loss 0.060553133 Test MSE 0.5702716594865573 Test RE 0.3609515863836789\n",
      "106 Train Loss 0.06005138 Test MSE 0.5753910338536827 Test RE 0.36256811222084767\n",
      "107 Train Loss 0.05954012 Test MSE 0.5764017311635861 Test RE 0.36288640518665544\n",
      "108 Train Loss 0.0592147 Test MSE 0.5768660160648065 Test RE 0.36303252616064435\n",
      "109 Train Loss 0.05884903 Test MSE 0.5786690767633199 Test RE 0.36359943335978817\n",
      "110 Train Loss 0.058570437 Test MSE 0.5788862538549814 Test RE 0.3636676572056823\n",
      "111 Train Loss 0.058308307 Test MSE 0.5807261698910633 Test RE 0.3642451343150536\n",
      "112 Train Loss 0.05800252 Test MSE 0.5825903342858071 Test RE 0.3648292898093662\n",
      "113 Train Loss 0.057570886 Test MSE 0.5849006436503253 Test RE 0.36555195418600744\n",
      "114 Train Loss 0.057106033 Test MSE 0.5838704997153806 Test RE 0.36522990198298266\n",
      "115 Train Loss 0.056884844 Test MSE 0.5852650800676658 Test RE 0.36566581942183257\n",
      "116 Train Loss 0.05671127 Test MSE 0.5845367542932648 Test RE 0.36543822447587615\n",
      "117 Train Loss 0.05628678 Test MSE 0.5870168553510219 Test RE 0.3662126534624396\n",
      "118 Train Loss 0.05608578 Test MSE 0.5841027815384849 Test RE 0.3653025446593797\n",
      "119 Train Loss 0.05581232 Test MSE 0.5856987319851001 Test RE 0.36580126430535903\n",
      "120 Train Loss 0.055512596 Test MSE 0.5859476644829468 Test RE 0.36587899210636554\n",
      "121 Train Loss 0.055305243 Test MSE 0.5860766346434874 Test RE 0.36591925583548635\n",
      "122 Train Loss 0.055066727 Test MSE 0.5881329527730833 Test RE 0.3665606289078612\n",
      "123 Train Loss 0.054786153 Test MSE 0.5900566540344688 Test RE 0.3671596239713544\n",
      "124 Train Loss 0.05456827 Test MSE 0.5916329111212053 Test RE 0.36764970569952676\n",
      "125 Train Loss 0.054397244 Test MSE 0.5929281619669465 Test RE 0.36805192998002556\n",
      "126 Train Loss 0.05416237 Test MSE 0.5918022392683033 Test RE 0.3677023134809795\n",
      "127 Train Loss 0.053902794 Test MSE 0.5928801737659579 Test RE 0.3680370356736779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 Train Loss 0.053711027 Test MSE 0.5949336297332524 Test RE 0.368673837698098\n",
      "129 Train Loss 0.05349253 Test MSE 0.5959716333390725 Test RE 0.36899531725315227\n",
      "130 Train Loss 0.05328792 Test MSE 0.5975001308066444 Test RE 0.3694681981833919\n",
      "131 Train Loss 0.053024508 Test MSE 0.5982638952820782 Test RE 0.36970426220259833\n",
      "132 Train Loss 0.052809484 Test MSE 0.6003943874006755 Test RE 0.37036195861146\n",
      "133 Train Loss 0.052548602 Test MSE 0.603613669126389 Test RE 0.3713535613976831\n",
      "134 Train Loss 0.052373044 Test MSE 0.6044978380892886 Test RE 0.37162543988615976\n",
      "135 Train Loss 0.05223153 Test MSE 0.6043640299745853 Test RE 0.3715843071901846\n",
      "136 Train Loss 0.05211013 Test MSE 0.6039910803094503 Test RE 0.37146963819745604\n",
      "137 Train Loss 0.051948067 Test MSE 0.6018573396475163 Test RE 0.3708129057010076\n",
      "138 Train Loss 0.05177777 Test MSE 0.6016784187215446 Test RE 0.37075778373465246\n",
      "139 Train Loss 0.05160932 Test MSE 0.602187727203663 Test RE 0.3709146699839307\n",
      "140 Train Loss 0.051369872 Test MSE 0.6038656336995624 Test RE 0.37143105979108715\n",
      "141 Train Loss 0.051157586 Test MSE 0.605492140279572 Test RE 0.37193094649431485\n",
      "142 Train Loss 0.050980322 Test MSE 0.6028866179866814 Test RE 0.3711298467981441\n",
      "143 Train Loss 0.05078784 Test MSE 0.6032673922883863 Test RE 0.3712470283690209\n",
      "144 Train Loss 0.050638333 Test MSE 0.604597774402673 Test RE 0.37165615740014235\n",
      "145 Train Loss 0.050440505 Test MSE 0.6036862290947886 Test RE 0.37137588080025385\n",
      "146 Train Loss 0.05034504 Test MSE 0.6039897250831227 Test RE 0.3714692214481594\n",
      "147 Train Loss 0.050225608 Test MSE 0.6062864112503679 Test RE 0.3721748118712871\n",
      "148 Train Loss 0.050115883 Test MSE 0.6059869398687393 Test RE 0.37208288380753524\n",
      "149 Train Loss 0.049973324 Test MSE 0.6071647903586024 Test RE 0.37244431507401693\n",
      "Training time: 229.43\n",
      "8\n",
      "KG_rowdy_tune65\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.21\n",
      "0\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smartlab/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 72.75146 Test MSE 4.351854387481989 Test RE 0.9971149734943676\n",
      "1 Train Loss 67.32043 Test MSE 4.118670801633607 Test RE 0.9700332049520904\n",
      "2 Train Loss 57.55945 Test MSE 4.871008708116014 Test RE 1.0549151107546884\n",
      "3 Train Loss 37.32808 Test MSE 7.927171233716656 Test RE 1.3457586500799716\n",
      "4 Train Loss 30.886162 Test MSE 8.017906512323304 Test RE 1.353438587423631\n",
      "5 Train Loss 26.614407 Test MSE 8.34394569515334 Test RE 1.3806824188845843\n",
      "6 Train Loss 23.226212 Test MSE 8.345761809338413 Test RE 1.3808326679747798\n",
      "7 Train Loss 19.823856 Test MSE 8.670531377234495 Test RE 1.4074433305236873\n",
      "8 Train Loss 17.315666 Test MSE 8.480090794656666 Test RE 1.391900886287921\n",
      "9 Train Loss 14.943077 Test MSE 7.927330328410243 Test RE 1.345772154391884\n",
      "10 Train Loss 13.38917 Test MSE 7.607562309504799 Test RE 1.3183502908482325\n",
      "11 Train Loss 11.352896 Test MSE 6.774468708340835 Test RE 1.2440724731695572\n",
      "12 Train Loss 9.208242 Test MSE 6.05094946750607 Test RE 1.1757630921393412\n",
      "13 Train Loss 7.2361326 Test MSE 5.879387164171622 Test RE 1.1589750593506536\n",
      "14 Train Loss 5.5805445 Test MSE 5.530308868970266 Test RE 1.1240425564030667\n",
      "15 Train Loss 4.586795 Test MSE 5.424970696513452 Test RE 1.1132860279915948\n",
      "16 Train Loss 3.9123042 Test MSE 5.420225290718914 Test RE 1.1127990069482683\n",
      "17 Train Loss 3.2276294 Test MSE 5.518615099434333 Test RE 1.1228535405060722\n",
      "18 Train Loss 2.8298788 Test MSE 5.4670962171990745 Test RE 1.117600066387068\n",
      "19 Train Loss 2.540866 Test MSE 5.403232160820169 Test RE 1.1110532508555497\n",
      "20 Train Loss 2.3551168 Test MSE 5.435567513071134 Test RE 1.1143728110419917\n",
      "21 Train Loss 2.214808 Test MSE 5.468199949563969 Test RE 1.1177128748198497\n",
      "22 Train Loss 2.1180513 Test MSE 5.4731357935645955 Test RE 1.1182172100726895\n",
      "23 Train Loss 2.0115058 Test MSE 5.493685212884547 Test RE 1.1203144708250248\n",
      "24 Train Loss 1.9325179 Test MSE 5.558509136992184 Test RE 1.1269047830568437\n",
      "25 Train Loss 1.8587986 Test MSE 5.573891009876243 Test RE 1.128462928449819\n",
      "26 Train Loss 1.7934878 Test MSE 5.64351682084602 Test RE 1.1354891067375597\n",
      "27 Train Loss 1.7329324 Test MSE 5.66493256125794 Test RE 1.1376415158494648\n",
      "28 Train Loss 1.6680257 Test MSE 5.666722419596772 Test RE 1.1378212228732791\n",
      "29 Train Loss 1.6286128 Test MSE 5.688663589010448 Test RE 1.14002187849149\n",
      "30 Train Loss 1.5927743 Test MSE 5.736486162719954 Test RE 1.1448037291458844\n",
      "31 Train Loss 1.5530294 Test MSE 5.699434970067271 Test RE 1.1411006734111075\n",
      "32 Train Loss 1.5303619 Test MSE 5.734687024580083 Test RE 1.1446241922733262\n",
      "33 Train Loss 1.5082335 Test MSE 5.780092891598567 Test RE 1.149146686890707\n",
      "34 Train Loss 1.4825758 Test MSE 5.791030446780943 Test RE 1.150233426775883\n",
      "35 Train Loss 1.4579353 Test MSE 5.818933058186102 Test RE 1.1530011509022033\n",
      "36 Train Loss 1.4230578 Test MSE 5.900965512454431 Test RE 1.1610999290175\n",
      "37 Train Loss 1.3964226 Test MSE 5.904330364388574 Test RE 1.161430923372534\n",
      "38 Train Loss 1.3676817 Test MSE 5.9332946245044855 Test RE 1.1642761937193267\n",
      "39 Train Loss 1.3411335 Test MSE 5.9894577435081295 Test RE 1.1697735922665469\n",
      "40 Train Loss 1.3085271 Test MSE 5.949320680573501 Test RE 1.1658475106877415\n",
      "41 Train Loss 1.2771965 Test MSE 5.936432252802937 Test RE 1.1645839976748356\n",
      "42 Train Loss 1.2485963 Test MSE 5.925214896464569 Test RE 1.1634831908162662\n",
      "43 Train Loss 1.224817 Test MSE 5.888173676869819 Test RE 1.1598407573373946\n",
      "44 Train Loss 1.1970327 Test MSE 5.874453464851806 Test RE 1.158488679190541\n",
      "45 Train Loss 1.1709334 Test MSE 5.86440662297543 Test RE 1.1574975969222936\n",
      "46 Train Loss 1.1522686 Test MSE 5.8148601501782755 Test RE 1.152597564058749\n",
      "47 Train Loss 1.1358441 Test MSE 5.820010046244513 Test RE 1.1531078466663638\n",
      "48 Train Loss 1.1223823 Test MSE 5.809047713288728 Test RE 1.1520213614144459\n",
      "49 Train Loss 1.1048949 Test MSE 5.817659392446467 Test RE 1.15287495779968\n",
      "50 Train Loss 1.0912521 Test MSE 5.829071399334861 Test RE 1.1540051521217907\n",
      "51 Train Loss 1.0718118 Test MSE 5.8568102429482645 Test RE 1.1567476795441247\n",
      "52 Train Loss 1.0536112 Test MSE 5.909595728483818 Test RE 1.161948678437461\n",
      "53 Train Loss 1.0259198 Test MSE 5.958701865335701 Test RE 1.1667663317911652\n",
      "54 Train Loss 0.9955917 Test MSE 5.9675602501040785 Test RE 1.1676332845990571\n",
      "55 Train Loss 0.9642191 Test MSE 6.018333501257965 Test RE 1.1725899978817353\n",
      "56 Train Loss 0.94022536 Test MSE 6.038130677529051 Test RE 1.1745170190204877\n",
      "57 Train Loss 0.91967565 Test MSE 6.079229734690405 Test RE 1.178507465893738\n",
      "58 Train Loss 0.90402937 Test MSE 6.080112285963166 Test RE 1.1785930076122835\n",
      "59 Train Loss 0.8905585 Test MSE 6.089278017703147 Test RE 1.1794810339066768\n",
      "60 Train Loss 0.8767612 Test MSE 6.10514830117189 Test RE 1.181017054900196\n",
      "61 Train Loss 0.86396194 Test MSE 6.124534236541933 Test RE 1.182890635442934\n",
      "62 Train Loss 0.85491914 Test MSE 6.1493816259372975 Test RE 1.185287715176202\n",
      "63 Train Loss 0.8460724 Test MSE 6.1618513944489335 Test RE 1.1864888748234592\n",
      "64 Train Loss 0.83862746 Test MSE 6.18888271082982 Test RE 1.1890885203387997\n",
      "65 Train Loss 0.83076435 Test MSE 6.179732228016924 Test RE 1.1882091403730728\n",
      "66 Train Loss 0.82444006 Test MSE 6.187230194222758 Test RE 1.1889297582644331\n",
      "67 Train Loss 0.8177476 Test MSE 6.213050943151903 Test RE 1.1914080154088675\n",
      "68 Train Loss 0.81087136 Test MSE 6.23512680489563 Test RE 1.1935227604156085\n",
      "69 Train Loss 0.80401886 Test MSE 6.245208486878669 Test RE 1.1944872842528043\n",
      "70 Train Loss 0.79607666 Test MSE 6.267103043835678 Test RE 1.1965792791254404\n",
      "71 Train Loss 0.7894892 Test MSE 6.286510951165393 Test RE 1.1984306248041525\n",
      "72 Train Loss 0.78376925 Test MSE 6.266686216886552 Test RE 1.1965394860360041\n",
      "73 Train Loss 0.7764921 Test MSE 6.2882487250147365 Test RE 1.1985962538401354\n",
      "74 Train Loss 0.7699859 Test MSE 6.300420834902297 Test RE 1.1997557493219984\n",
      "75 Train Loss 0.7648745 Test MSE 6.318389681390688 Test RE 1.2014653873186092\n",
      "76 Train Loss 0.7608803 Test MSE 6.299362514682223 Test RE 1.1996549799347376\n",
      "77 Train Loss 0.75605935 Test MSE 6.293414123086885 Test RE 1.1990884382420501\n",
      "78 Train Loss 0.75153196 Test MSE 6.304609603725354 Test RE 1.2001545055796823\n",
      "79 Train Loss 0.74753296 Test MSE 6.302326335571969 Test RE 1.1999371628033348\n",
      "80 Train Loss 0.743387 Test MSE 6.332483868738843 Test RE 1.202804672034113\n",
      "81 Train Loss 0.7390338 Test MSE 6.317266399163233 Test RE 1.2013585844169128\n",
      "82 Train Loss 0.73287344 Test MSE 6.341014412236841 Test RE 1.203614553637007\n",
      "83 Train Loss 0.7285664 Test MSE 6.355296199489573 Test RE 1.2049692342671856\n",
      "84 Train Loss 0.7237624 Test MSE 6.3493519824081766 Test RE 1.2044055882868148\n",
      "85 Train Loss 0.72087556 Test MSE 6.353921815751316 Test RE 1.2048389350951199\n",
      "86 Train Loss 0.7174523 Test MSE 6.365026611398768 Test RE 1.2058913283881736\n",
      "87 Train Loss 0.714045 Test MSE 6.368333345469261 Test RE 1.2062045277208784\n",
      "88 Train Loss 0.7105034 Test MSE 6.36724452719772 Test RE 1.206101408615837\n",
      "89 Train Loss 0.70656615 Test MSE 6.38877701172344 Test RE 1.208139059320261\n",
      "90 Train Loss 0.7031189 Test MSE 6.393987409340959 Test RE 1.2086316107062307\n",
      "91 Train Loss 0.70036834 Test MSE 6.394786933303701 Test RE 1.2087071738616364\n",
      "92 Train Loss 0.6974832 Test MSE 6.400220527475746 Test RE 1.2092205787493484\n",
      "93 Train Loss 0.69426996 Test MSE 6.407693315429773 Test RE 1.2099263054373706\n",
      "94 Train Loss 0.69193214 Test MSE 6.410585267821409 Test RE 1.2101993096517907\n",
      "95 Train Loss 0.68961525 Test MSE 6.417254529581135 Test RE 1.210828662318288\n",
      "96 Train Loss 0.68796086 Test MSE 6.427356829946309 Test RE 1.211781355131006\n",
      "97 Train Loss 0.6854619 Test MSE 6.423569064497419 Test RE 1.2114242394374983\n",
      "98 Train Loss 0.6834576 Test MSE 6.428886262777253 Test RE 1.211925522321115\n",
      "99 Train Loss 0.681426 Test MSE 6.43375304401322 Test RE 1.2123841601252843\n",
      "100 Train Loss 0.6789006 Test MSE 6.442161164611262 Test RE 1.2131761196395292\n",
      "101 Train Loss 0.67628616 Test MSE 6.453589812345891 Test RE 1.214251753914916\n",
      "102 Train Loss 0.6749334 Test MSE 6.458692586585437 Test RE 1.2147317060383565\n",
      "103 Train Loss 0.6724472 Test MSE 6.453023487599139 Test RE 1.2141984753580324\n",
      "104 Train Loss 0.66960585 Test MSE 6.486728036292519 Test RE 1.2173652632707168\n",
      "105 Train Loss 0.6673349 Test MSE 6.495949346643843 Test RE 1.2182302383517787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 0.6654406 Test MSE 6.504634313266727 Test RE 1.219044342214284\n",
      "107 Train Loss 0.6632243 Test MSE 6.507810337553721 Test RE 1.2193419178930407\n",
      "108 Train Loss 0.6609195 Test MSE 6.518579138228273 Test RE 1.2203503540495604\n",
      "109 Train Loss 0.6583769 Test MSE 6.508256039915624 Test RE 1.2193836718962936\n",
      "110 Train Loss 0.65597 Test MSE 6.530444574491687 Test RE 1.2214605197568666\n",
      "111 Train Loss 0.654308 Test MSE 6.533129822847932 Test RE 1.2217116196412128\n",
      "112 Train Loss 0.65253943 Test MSE 6.5485424978070625 Test RE 1.223151875080914\n",
      "113 Train Loss 0.6501285 Test MSE 6.554381466053356 Test RE 1.2236970615596423\n",
      "114 Train Loss 0.64802825 Test MSE 6.561817754611873 Test RE 1.2243910389340549\n",
      "115 Train Loss 0.64629626 Test MSE 6.583450425028779 Test RE 1.226407633617117\n",
      "116 Train Loss 0.6443669 Test MSE 6.579844426811911 Test RE 1.2260717133016732\n",
      "117 Train Loss 0.6431595 Test MSE 6.586647976639098 Test RE 1.2267054277374032\n",
      "118 Train Loss 0.6410765 Test MSE 6.5893945748035865 Test RE 1.2269611659914923\n",
      "119 Train Loss 0.6391579 Test MSE 6.594001760206981 Test RE 1.2273900255600896\n",
      "120 Train Loss 0.63636225 Test MSE 6.597632727567131 Test RE 1.2277279083774366\n",
      "121 Train Loss 0.63459367 Test MSE 6.605494505032894 Test RE 1.2284591744491373\n",
      "122 Train Loss 0.6327714 Test MSE 6.612913563521493 Test RE 1.2291488618572128\n",
      "123 Train Loss 0.6310039 Test MSE 6.6206975627988705 Test RE 1.2298720589703689\n",
      "124 Train Loss 0.62953097 Test MSE 6.642102578178362 Test RE 1.2318585707077552\n",
      "125 Train Loss 0.627862 Test MSE 6.662709148760569 Test RE 1.2337679602824678\n",
      "126 Train Loss 0.62642485 Test MSE 6.669058929891615 Test RE 1.2343557310132676\n",
      "127 Train Loss 0.62475944 Test MSE 6.674342501923228 Test RE 1.234844594304886\n",
      "128 Train Loss 0.62338835 Test MSE 6.675530400293707 Test RE 1.2349544781337756\n",
      "129 Train Loss 0.6217244 Test MSE 6.685759813252828 Test RE 1.2359003223380345\n",
      "130 Train Loss 0.6198223 Test MSE 6.687356174738247 Test RE 1.2360478617332133\n",
      "131 Train Loss 0.61833256 Test MSE 6.6956135251192395 Test RE 1.2368107440512617\n",
      "132 Train Loss 0.61677796 Test MSE 6.696702301451875 Test RE 1.2369112991028837\n",
      "133 Train Loss 0.6150286 Test MSE 6.706094658086304 Test RE 1.2377784006169592\n",
      "134 Train Loss 0.6137793 Test MSE 6.69857405576595 Test RE 1.2370841477828896\n",
      "135 Train Loss 0.61247814 Test MSE 6.709147391448405 Test RE 1.2380600979152103\n",
      "136 Train Loss 0.611518 Test MSE 6.716980829464482 Test RE 1.2387826515615608\n",
      "137 Train Loss 0.6102685 Test MSE 6.724546205719309 Test RE 1.239480079445095\n",
      "138 Train Loss 0.60942477 Test MSE 6.728238581574171 Test RE 1.239820325322386\n",
      "139 Train Loss 0.60818183 Test MSE 6.727066476756885 Test RE 1.239712328061805\n",
      "140 Train Loss 0.6068138 Test MSE 6.722612641380421 Test RE 1.2393018676586471\n",
      "141 Train Loss 0.60530126 Test MSE 6.726587470052653 Test RE 1.2396681898709643\n",
      "142 Train Loss 0.6033947 Test MSE 6.737625376578761 Test RE 1.240684881684566\n",
      "143 Train Loss 0.60209095 Test MSE 6.745653952677525 Test RE 1.2414238636572426\n",
      "144 Train Loss 0.60020673 Test MSE 6.758445668429662 Test RE 1.2426003559728427\n",
      "145 Train Loss 0.59867185 Test MSE 6.7699805314716 Test RE 1.2436602974957092\n",
      "146 Train Loss 0.5974943 Test MSE 6.7767406575952 Test RE 1.244281067578313\n",
      "147 Train Loss 0.59546006 Test MSE 6.790417261803065 Test RE 1.2455360191200444\n",
      "148 Train Loss 0.5930977 Test MSE 6.814295516236162 Test RE 1.247724038258671\n",
      "149 Train Loss 0.59128433 Test MSE 6.83541489775321 Test RE 1.2496560629359976\n",
      "Training time: 229.97\n",
      "1\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 68.75358 Test MSE 5.143993067904113 Test RE 1.0840723001289967\n",
      "1 Train Loss 46.176056 Test MSE 10.030869360373943 Test RE 1.5138308362485147\n",
      "2 Train Loss 40.5147 Test MSE 9.685804901712215 Test RE 1.4875648876067058\n",
      "3 Train Loss 36.5802 Test MSE 10.13982357446967 Test RE 1.5220301644343905\n",
      "4 Train Loss 33.661476 Test MSE 10.227621856719578 Test RE 1.5286054074655202\n",
      "5 Train Loss 30.731133 Test MSE 10.4120630337258 Test RE 1.5423269757578126\n",
      "6 Train Loss 28.641827 Test MSE 10.258020827319262 Test RE 1.5308754148116566\n",
      "7 Train Loss 24.859785 Test MSE 10.085109041710949 Test RE 1.517918169102576\n",
      "8 Train Loss 21.715305 Test MSE 10.031291408672091 Test RE 1.5138626830897397\n",
      "9 Train Loss 18.959211 Test MSE 9.88560712481253 Test RE 1.5028295764701023\n",
      "10 Train Loss 15.970627 Test MSE 9.711546895198806 Test RE 1.4895403288327882\n",
      "11 Train Loss 13.726007 Test MSE 8.961511815551736 Test RE 1.4308651334261773\n",
      "12 Train Loss 12.112068 Test MSE 7.873469937656485 Test RE 1.34119259546688\n",
      "13 Train Loss 9.035257 Test MSE 6.808985056554638 Test RE 1.2472377605786298\n",
      "14 Train Loss 6.7621217 Test MSE 6.544117572354402 Test RE 1.222738556355936\n",
      "15 Train Loss 5.374864 Test MSE 6.236609013678758 Test RE 1.1936646135688773\n",
      "16 Train Loss 3.977023 Test MSE 5.917636960386168 Test RE 1.1627389459049187\n",
      "17 Train Loss 3.2436094 Test MSE 5.69539067098189 Test RE 1.1406957410438499\n",
      "18 Train Loss 2.5262682 Test MSE 5.7560167966730456 Test RE 1.1467508918726965\n",
      "19 Train Loss 2.210457 Test MSE 5.703840191234324 Test RE 1.1415415793877572\n",
      "20 Train Loss 1.9980434 Test MSE 5.627494365630051 Test RE 1.1338760828532255\n",
      "21 Train Loss 1.8468788 Test MSE 5.663663687012603 Test RE 1.1375140999582622\n",
      "22 Train Loss 1.7437948 Test MSE 5.770079396966008 Test RE 1.1481508584135596\n",
      "23 Train Loss 1.6621642 Test MSE 5.859307338409515 Test RE 1.1569942473380042\n",
      "24 Train Loss 1.6037959 Test MSE 5.810393781339013 Test RE 1.15215482643342\n",
      "25 Train Loss 1.5418148 Test MSE 5.766447415628832 Test RE 1.1477894492697651\n",
      "26 Train Loss 1.4764237 Test MSE 5.710907783399995 Test RE 1.1422485989012379\n",
      "27 Train Loss 1.4072392 Test MSE 5.727283319346508 Test RE 1.143885076340024\n",
      "28 Train Loss 1.3599676 Test MSE 5.767187382937041 Test RE 1.1478630907480174\n",
      "29 Train Loss 1.3114152 Test MSE 5.762042741593692 Test RE 1.14735099871079\n",
      "30 Train Loss 1.2659812 Test MSE 5.80304031200926 Test RE 1.1514255284045334\n",
      "31 Train Loss 1.2334578 Test MSE 5.828636533294729 Test RE 1.1539621052129085\n",
      "32 Train Loss 1.1994463 Test MSE 5.800873828676682 Test RE 1.1512105740917018\n",
      "33 Train Loss 1.167918 Test MSE 5.793520521269742 Test RE 1.1504806935719407\n",
      "34 Train Loss 1.1459467 Test MSE 5.79155158507704 Test RE 1.1502851807088377\n",
      "35 Train Loss 1.1123903 Test MSE 5.831418903858893 Test RE 1.154237501276304\n",
      "36 Train Loss 1.0943192 Test MSE 5.832486207410571 Test RE 1.1543431244052125\n",
      "37 Train Loss 1.0757272 Test MSE 5.860495330305452 Test RE 1.1571115333964228\n",
      "38 Train Loss 1.0618815 Test MSE 5.924304627973798 Test RE 1.1633938166091302\n",
      "39 Train Loss 1.045797 Test MSE 5.94000638067709 Test RE 1.164934523515342\n",
      "40 Train Loss 1.0288897 Test MSE 5.942887344406368 Test RE 1.165216991837176\n",
      "41 Train Loss 1.0120625 Test MSE 5.966579802814047 Test RE 1.1675373618209701\n",
      "42 Train Loss 0.9989226 Test MSE 5.974658661341802 Test RE 1.1683275279415288\n",
      "43 Train Loss 0.98505265 Test MSE 5.981836262720187 Test RE 1.1690290970782837\n",
      "44 Train Loss 0.97240293 Test MSE 6.001119272789038 Test RE 1.170911818470015\n",
      "45 Train Loss 0.9615567 Test MSE 5.972695764772874 Test RE 1.1681355927519292\n",
      "46 Train Loss 0.9515319 Test MSE 5.988809423970172 Test RE 1.1697102803916621\n",
      "47 Train Loss 0.9426366 Test MSE 5.990670446625883 Test RE 1.1698920100218761\n",
      "48 Train Loss 0.93361 Test MSE 6.00642263435583 Test RE 1.1714290884260075\n",
      "49 Train Loss 0.92518556 Test MSE 6.037722288109524 Test RE 1.174477299075692\n",
      "50 Train Loss 0.9158867 Test MSE 6.051825172695049 Test RE 1.1758481684233857\n",
      "51 Train Loss 0.90524167 Test MSE 6.062962636226068 Test RE 1.1769296559064943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 0.89656425 Test MSE 6.092329420913553 Test RE 1.1797765222578762\n",
      "53 Train Loss 0.88698834 Test MSE 6.119967352929169 Test RE 1.182449529958292\n",
      "54 Train Loss 0.8772923 Test MSE 6.170476016608116 Test RE 1.1873189370362403\n",
      "55 Train Loss 0.8669716 Test MSE 6.184334783993237 Test RE 1.1886515366607304\n",
      "56 Train Loss 0.85778755 Test MSE 6.184264951592371 Test RE 1.188644825621643\n",
      "57 Train Loss 0.84818643 Test MSE 6.231147071370612 Test RE 1.1931418009844166\n",
      "58 Train Loss 0.84202534 Test MSE 6.213802551401024 Test RE 1.1914800770272584\n",
      "59 Train Loss 0.8317996 Test MSE 6.269403501293112 Test RE 1.1967988723846799\n",
      "60 Train Loss 0.82343125 Test MSE 6.2700169504593966 Test RE 1.196857423195119\n",
      "61 Train Loss 0.8177506 Test MSE 6.266479825341311 Test RE 1.1965197820283113\n",
      "62 Train Loss 0.81090593 Test MSE 6.258790743399243 Test RE 1.1957854812069626\n",
      "63 Train Loss 0.80567324 Test MSE 6.276177244335024 Test RE 1.1974452352703722\n",
      "64 Train Loss 0.8000729 Test MSE 6.303169806027942 Test RE 1.2000174567797406\n",
      "65 Train Loss 0.79443586 Test MSE 6.333398731177132 Test RE 1.2028915542983736\n",
      "66 Train Loss 0.7872368 Test MSE 6.365283540623465 Test RE 1.2059156665108892\n",
      "67 Train Loss 0.7782391 Test MSE 6.370700887094514 Test RE 1.2064287209206013\n",
      "68 Train Loss 0.7714585 Test MSE 6.421786338076821 Test RE 1.2112561251199103\n",
      "69 Train Loss 0.7660154 Test MSE 6.423228657825526 Test RE 1.2113921402763534\n",
      "70 Train Loss 0.7619113 Test MSE 6.4227602525068335 Test RE 1.2113479698990584\n",
      "71 Train Loss 0.7574277 Test MSE 6.444256689738109 Test RE 1.2133734163442955\n",
      "72 Train Loss 0.75210464 Test MSE 6.441054166293021 Test RE 1.2130718812024415\n",
      "73 Train Loss 0.745751 Test MSE 6.475926498714009 Test RE 1.2163512778572065\n",
      "74 Train Loss 0.73975474 Test MSE 6.47695265402262 Test RE 1.2164476436729679\n",
      "75 Train Loss 0.7355502 Test MSE 6.472031291335048 Test RE 1.215985411046906\n",
      "76 Train Loss 0.73020566 Test MSE 6.490324890175644 Test RE 1.217702727561582\n",
      "77 Train Loss 0.7262373 Test MSE 6.493818233081016 Test RE 1.2180303907381738\n",
      "78 Train Loss 0.72208786 Test MSE 6.49967689320146 Test RE 1.2185797144974635\n",
      "79 Train Loss 0.7183449 Test MSE 6.504418191048248 Test RE 1.2190240901337321\n",
      "80 Train Loss 0.71395844 Test MSE 6.503152058193182 Test RE 1.2189054383554783\n",
      "81 Train Loss 0.7108002 Test MSE 6.5322774576723335 Test RE 1.2216319198315333\n",
      "82 Train Loss 0.70733 Test MSE 6.5344664623354305 Test RE 1.221836590713353\n",
      "83 Train Loss 0.70369637 Test MSE 6.544833092410812 Test RE 1.2228054003603175\n",
      "84 Train Loss 0.70030594 Test MSE 6.55942434485176 Test RE 1.2241677214904878\n",
      "85 Train Loss 0.69592327 Test MSE 6.561360688461497 Test RE 1.2243483954574101\n",
      "86 Train Loss 0.6915411 Test MSE 6.576999211024139 Test RE 1.22580659945071\n",
      "87 Train Loss 0.68695706 Test MSE 6.589935767664808 Test RE 1.2270115506651416\n",
      "88 Train Loss 0.68339705 Test MSE 6.584183839321983 Test RE 1.2264759442886044\n",
      "89 Train Loss 0.6801481 Test MSE 6.600335102701063 Test RE 1.2279793198941489\n",
      "90 Train Loss 0.6775389 Test MSE 6.608959153017822 Test RE 1.2287813017814915\n",
      "91 Train Loss 0.6741103 Test MSE 6.622913135160589 Test RE 1.2300778260054623\n",
      "92 Train Loss 0.67224866 Test MSE 6.62401076087935 Test RE 1.2301797531403758\n",
      "93 Train Loss 0.66971457 Test MSE 6.62977627218764 Test RE 1.230715008355045\n",
      "94 Train Loss 0.6672981 Test MSE 6.628960650155202 Test RE 1.2306393022444624\n",
      "95 Train Loss 0.66525435 Test MSE 6.64106118767652 Test RE 1.2317619976657743\n",
      "96 Train Loss 0.6640205 Test MSE 6.645432964023179 Test RE 1.2321673622511982\n",
      "97 Train Loss 0.66253376 Test MSE 6.646369724689975 Test RE 1.2322542042412137\n",
      "98 Train Loss 0.6608916 Test MSE 6.639193886477593 Test RE 1.2315888150754155\n",
      "99 Train Loss 0.6590624 Test MSE 6.630243523327565 Test RE 1.2307583765499308\n",
      "100 Train Loss 0.6572317 Test MSE 6.635030249375808 Test RE 1.2312025714148436\n",
      "101 Train Loss 0.65564966 Test MSE 6.649420726443075 Test RE 1.2325370036137981\n",
      "102 Train Loss 0.65321 Test MSE 6.657439710936594 Test RE 1.2332799793907967\n",
      "103 Train Loss 0.6508169 Test MSE 6.66247021233801 Test RE 1.2337458375438712\n",
      "104 Train Loss 0.6492161 Test MSE 6.661888995154856 Test RE 1.2336920219246494\n",
      "105 Train Loss 0.6471422 Test MSE 6.676103817152075 Test RE 1.2350075172533794\n",
      "106 Train Loss 0.6453452 Test MSE 6.679194666033861 Test RE 1.2352933710982144\n",
      "107 Train Loss 0.6441293 Test MSE 6.689393417390478 Test RE 1.2362361228042702\n",
      "108 Train Loss 0.6430029 Test MSE 6.6885798246606365 Test RE 1.2361609423474496\n",
      "109 Train Loss 0.64107555 Test MSE 6.688230972686765 Test RE 1.2361287050998457\n",
      "110 Train Loss 0.6398259 Test MSE 6.694774182367021 Test RE 1.236733220112224\n",
      "111 Train Loss 0.63820493 Test MSE 6.70474424012788 Test RE 1.237653767546329\n",
      "112 Train Loss 0.6368969 Test MSE 6.707263631133817 Test RE 1.2378862776014776\n",
      "113 Train Loss 0.63481146 Test MSE 6.719069680638703 Test RE 1.238975255315938\n",
      "114 Train Loss 0.63303673 Test MSE 6.714074472071642 Test RE 1.238514619334749\n",
      "115 Train Loss 0.63174325 Test MSE 6.718123164982346 Test RE 1.2388879849916552\n",
      "116 Train Loss 0.62993497 Test MSE 6.71123999040592 Test RE 1.2382531598002973\n",
      "117 Train Loss 0.62848663 Test MSE 6.714371667621567 Test RE 1.2385420301835386\n",
      "118 Train Loss 0.627125 Test MSE 6.728307522092047 Test RE 1.2398266771807007\n",
      "119 Train Loss 0.6246704 Test MSE 6.73570544191077 Test RE 1.240508098062604\n",
      "120 Train Loss 0.6230507 Test MSE 6.741267423086984 Test RE 1.2410201646153536\n",
      "121 Train Loss 0.6205933 Test MSE 6.757721405104796 Test RE 1.2425337730614845\n",
      "122 Train Loss 0.6191307 Test MSE 6.769540110470077 Test RE 1.2436198436849686\n",
      "123 Train Loss 0.6177397 Test MSE 6.775368260899805 Test RE 1.2441550679439244\n",
      "124 Train Loss 0.6161271 Test MSE 6.7867395014579595 Test RE 1.2451986758301705\n",
      "125 Train Loss 0.6146616 Test MSE 6.785515746025 Test RE 1.245086406356543\n",
      "126 Train Loss 0.6130391 Test MSE 6.801211406120109 Test RE 1.2465255869460046\n",
      "127 Train Loss 0.6113495 Test MSE 6.809117927471778 Test RE 1.2472499298531468\n",
      "128 Train Loss 0.6097334 Test MSE 6.818605728746976 Test RE 1.2481185842240519\n",
      "129 Train Loss 0.6081186 Test MSE 6.810372672667794 Test RE 1.2473648425910815\n",
      "130 Train Loss 0.60677737 Test MSE 6.814118673448861 Test RE 1.247707847852211\n",
      "131 Train Loss 0.6056473 Test MSE 6.827731973093287 Test RE 1.2489535662405282\n",
      "132 Train Loss 0.60469204 Test MSE 6.832824936420846 Test RE 1.2494192910959427\n",
      "133 Train Loss 0.6033578 Test MSE 6.841990987386035 Test RE 1.2502570414306309\n",
      "134 Train Loss 0.6022677 Test MSE 6.848073077324959 Test RE 1.250812617039519\n",
      "135 Train Loss 0.6009084 Test MSE 6.844311725128488 Test RE 1.250469061053943\n",
      "136 Train Loss 0.59981775 Test MSE 6.849336511590697 Test RE 1.2509279959657555\n",
      "137 Train Loss 0.5989414 Test MSE 6.84444429383449 Test RE 1.2504811712754864\n",
      "138 Train Loss 0.59780264 Test MSE 6.842140279573308 Test RE 1.2502706816554232\n",
      "139 Train Loss 0.59602886 Test MSE 6.855033456505382 Test RE 1.2514481183620505\n",
      "140 Train Loss 0.59455174 Test MSE 6.859807224702849 Test RE 1.251883789723106\n",
      "141 Train Loss 0.59371954 Test MSE 6.86776505058788 Test RE 1.2526097128688205\n",
      "142 Train Loss 0.5928073 Test MSE 6.8640880938614135 Test RE 1.2522743484294248\n",
      "143 Train Loss 0.59190834 Test MSE 6.861595879953395 Test RE 1.252046989831751\n",
      "144 Train Loss 0.5908099 Test MSE 6.865154918075053 Test RE 1.2523716595852423\n",
      "145 Train Loss 0.5894004 Test MSE 6.860322111450925 Test RE 1.2519307710928098\n",
      "146 Train Loss 0.5884436 Test MSE 6.870246028828441 Test RE 1.2528359448966797\n",
      "147 Train Loss 0.5874123 Test MSE 6.870077860294606 Test RE 1.2528206114666682\n",
      "148 Train Loss 0.5862744 Test MSE 6.881706664999565 Test RE 1.2538804718254746\n",
      "149 Train Loss 0.5854973 Test MSE 6.883707418285383 Test RE 1.2540627320757654\n",
      "Training time: 229.47\n",
      "2\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 61.552742 Test MSE 6.029208868348729 Test RE 1.173648977985749\n",
      "1 Train Loss 47.22899 Test MSE 8.506251099917487 Test RE 1.3940461765827141\n",
      "2 Train Loss 33.608517 Test MSE 7.860070661959032 Test RE 1.3400508713040924\n",
      "3 Train Loss 23.483467 Test MSE 5.6792428420004875 Test RE 1.1390775171601553\n",
      "4 Train Loss 16.081177 Test MSE 5.7819294372336305 Test RE 1.1493292352299436\n",
      "5 Train Loss 13.00006 Test MSE 5.909972187145945 Test RE 1.1619856876254777\n",
      "6 Train Loss 11.4587 Test MSE 5.714363000473529 Test RE 1.1425940886403512\n",
      "7 Train Loss 10.379047 Test MSE 5.804089146445584 Test RE 1.1515295773269552\n",
      "8 Train Loss 9.657066 Test MSE 5.764756098804346 Test RE 1.1476211118313917\n",
      "9 Train Loss 8.942214 Test MSE 5.568278315058883 Test RE 1.1278946258695364\n",
      "10 Train Loss 8.03113 Test MSE 5.4017459557737695 Test RE 1.1109004380147807\n",
      "11 Train Loss 7.5101347 Test MSE 5.226352017695307 Test RE 1.0927162190058188\n",
      "12 Train Loss 6.705345 Test MSE 4.9542825181676555 Test RE 1.063894208137109\n",
      "13 Train Loss 5.879241 Test MSE 4.645727154527252 Test RE 1.0302317031896806\n",
      "14 Train Loss 4.6559215 Test MSE 4.30862193563723 Test RE 0.9921498118446528\n",
      "15 Train Loss 3.868631 Test MSE 4.0383544818563095 Test RE 0.9605285529241767\n",
      "16 Train Loss 3.3425813 Test MSE 3.7399729086970077 Test RE 0.9243624360278047\n",
      "17 Train Loss 2.9003909 Test MSE 3.269504905501436 Test RE 0.8642692410524581\n",
      "18 Train Loss 2.4572666 Test MSE 2.7298702527377845 Test RE 0.789730776743543\n",
      "19 Train Loss 2.1445723 Test MSE 2.3980788991208386 Test RE 0.7401841722906957\n",
      "20 Train Loss 1.8424191 Test MSE 2.0135511401769586 Test RE 0.6782493596823768\n",
      "21 Train Loss 1.7016921 Test MSE 1.9463204047688438 Test RE 0.6668301505874417\n",
      "22 Train Loss 1.5249958 Test MSE 1.7353838244734208 Test RE 0.6296596053227383\n",
      "23 Train Loss 1.3620272 Test MSE 1.4947422823231962 Test RE 0.5843744509177206\n",
      "24 Train Loss 1.1371573 Test MSE 1.2772768657359699 Test RE 0.5401950290034837\n",
      "25 Train Loss 0.9038365 Test MSE 0.9936286219531428 Test RE 0.4764530449549313\n",
      "26 Train Loss 0.70511055 Test MSE 0.748457211499379 Test RE 0.413515267517887\n",
      "27 Train Loss 0.55607545 Test MSE 0.5786049261449803 Test RE 0.3635792786842577\n",
      "28 Train Loss 0.45577437 Test MSE 0.4886136659384392 Test RE 0.334111069852659\n",
      "29 Train Loss 0.38230228 Test MSE 0.38504645855214625 Test RE 0.29659554739683847\n",
      "30 Train Loss 0.31203663 Test MSE 0.24372053825174586 Test RE 0.23596855039044334\n",
      "31 Train Loss 0.24118312 Test MSE 0.09229808990701345 Test RE 0.14521263864396738\n",
      "32 Train Loss 0.18971896 Test MSE 0.060659082467694636 Test RE 0.11772155190761681\n",
      "33 Train Loss 0.15503563 Test MSE 0.03877754390600495 Test RE 0.09412353061879758\n",
      "34 Train Loss 0.12260083 Test MSE 0.03194204335652252 Test RE 0.08542586945564538\n",
      "35 Train Loss 0.10522409 Test MSE 0.027891095363745556 Test RE 0.0798253526040454\n",
      "36 Train Loss 0.08881336 Test MSE 0.02291907774808437 Test RE 0.0723613447662894\n",
      "37 Train Loss 0.077811696 Test MSE 0.0193935338560736 Test RE 0.06656355930499468\n",
      "38 Train Loss 0.06816993 Test MSE 0.017468495582899483 Test RE 0.06317362709227038\n",
      "39 Train Loss 0.06127148 Test MSE 0.01548558558814763 Test RE 0.05948012557185804\n",
      "40 Train Loss 0.05373542 Test MSE 0.01750827208220425 Test RE 0.0632455106982743\n",
      "41 Train Loss 0.047139414 Test MSE 0.01746047418595961 Test RE 0.06315912100836514\n",
      "42 Train Loss 0.042453386 Test MSE 0.01609144053358422 Test RE 0.06063250658356086\n",
      "43 Train Loss 0.03753893 Test MSE 0.016077548328593667 Test RE 0.06060632803581273\n",
      "44 Train Loss 0.033164833 Test MSE 0.012459096640266617 Test RE 0.05335207777671177\n",
      "45 Train Loss 0.029334996 Test MSE 0.010894007171427985 Test RE 0.049888665705332735\n",
      "46 Train Loss 0.02617982 Test MSE 0.009145221908440498 Test RE 0.045709364606249726\n",
      "47 Train Loss 0.024384957 Test MSE 0.008747230614492526 Test RE 0.04470368750307268\n",
      "48 Train Loss 0.0226352 Test MSE 0.009095382124008062 Test RE 0.04558464061069674\n",
      "49 Train Loss 0.020760294 Test MSE 0.008669104596097448 Test RE 0.04450360391870107\n",
      "50 Train Loss 0.018411063 Test MSE 0.007791319451391784 Test RE 0.042190392520019694\n",
      "51 Train Loss 0.017432094 Test MSE 0.007760159616824784 Test RE 0.04210594195227886\n",
      "52 Train Loss 0.01617779 Test MSE 0.007946307628468314 Test RE 0.04260796058118753\n",
      "53 Train Loss 0.014899631 Test MSE 0.00787876244461918 Test RE 0.042426486076933105\n",
      "54 Train Loss 0.0140345935 Test MSE 0.007607141816269377 Test RE 0.041688744550289904\n",
      "55 Train Loss 0.0132796485 Test MSE 0.006519709246810673 Test RE 0.038594211674443456\n",
      "56 Train Loss 0.012737081 Test MSE 0.006308965508154571 Test RE 0.03796532629675117\n",
      "57 Train Loss 0.011970929 Test MSE 0.005813032034236517 Test RE 0.03644260538965226\n",
      "58 Train Loss 0.01131797 Test MSE 0.005413701427108291 Test RE 0.0351686105436556\n",
      "59 Train Loss 0.010640074 Test MSE 0.004933572684188101 Test RE 0.03357289759069668\n",
      "60 Train Loss 0.010203836 Test MSE 0.005062796268198823 Test RE 0.03400973797283038\n",
      "61 Train Loss 0.009479134 Test MSE 0.004822283615979058 Test RE 0.03319207742651237\n",
      "62 Train Loss 0.008954343 Test MSE 0.004911419911095754 Test RE 0.0334974381226154\n",
      "63 Train Loss 0.008717548 Test MSE 0.005152442527740546 Test RE 0.03430951969846943\n",
      "64 Train Loss 0.008070724 Test MSE 0.004777694801751521 Test RE 0.03303826726494983\n",
      "65 Train Loss 0.007554069 Test MSE 0.004356189796369296 Test RE 0.03154724633698815\n",
      "66 Train Loss 0.0071968273 Test MSE 0.004626791912214111 Test RE 0.032512326240207085\n",
      "67 Train Loss 0.0069643455 Test MSE 0.004937739871052697 Test RE 0.03358707342394792\n",
      "68 Train Loss 0.006429715 Test MSE 0.0039315296721363436 Test RE 0.02997014465593932\n",
      "69 Train Loss 0.0060289376 Test MSE 0.0035909030562056438 Test RE 0.02864243265153631\n",
      "70 Train Loss 0.0057124593 Test MSE 0.0033530323218763916 Test RE 0.027677504510570734\n",
      "71 Train Loss 0.005379516 Test MSE 0.0030766318769622466 Test RE 0.026512203707489114\n",
      "72 Train Loss 0.0050638514 Test MSE 0.0028490294525297492 Test RE 0.025512706312168093\n",
      "73 Train Loss 0.0048517548 Test MSE 0.0025701415425464524 Test RE 0.02423185050326684\n",
      "74 Train Loss 0.004743263 Test MSE 0.002517715248393066 Test RE 0.02398343394111677\n",
      "75 Train Loss 0.0045954534 Test MSE 0.0026489418784295922 Test RE 0.024600519305813327\n",
      "76 Train Loss 0.004437812 Test MSE 0.0027050676521986495 Test RE 0.02485977111739298\n",
      "77 Train Loss 0.004250129 Test MSE 0.0027399944621399304 Test RE 0.02501974636751424\n",
      "78 Train Loss 0.0038997035 Test MSE 0.002694517432443496 Test RE 0.024811245107655214\n",
      "79 Train Loss 0.0037971064 Test MSE 0.0028972618979450963 Test RE 0.02572775774859538\n",
      "80 Train Loss 0.0037276067 Test MSE 0.002809343961663573 Test RE 0.025334393854033622\n",
      "81 Train Loss 0.0035033803 Test MSE 0.002867383243281512 Test RE 0.025594752349560095\n",
      "82 Train Loss 0.003363085 Test MSE 0.002872573428916748 Test RE 0.02561790611829329\n",
      "83 Train Loss 0.0033010766 Test MSE 0.002585470107180896 Test RE 0.024304003593077283\n",
      "84 Train Loss 0.0032252723 Test MSE 0.0027016910165586177 Test RE 0.0248442505072162\n",
      "85 Train Loss 0.0031328932 Test MSE 0.0025934489651556272 Test RE 0.024341476239356542\n",
      "86 Train Loss 0.002931662 Test MSE 0.002167685426806473 Test RE 0.022253902923327674\n",
      "87 Train Loss 0.0028358165 Test MSE 0.0021297867180865024 Test RE 0.022058507151238305\n",
      "88 Train Loss 0.002790826 Test MSE 0.002081214469194855 Test RE 0.021805521543322902\n",
      "89 Train Loss 0.0027010348 Test MSE 0.0019623083892903567 Test RE 0.021173453065167307\n",
      "90 Train Loss 0.0026568305 Test MSE 0.0019005752583161413 Test RE 0.020837739091292874\n",
      "91 Train Loss 0.0025161174 Test MSE 0.001703234983404728 Test RE 0.019726286871850435\n",
      "92 Train Loss 0.0024592425 Test MSE 0.0016574003129108724 Test RE 0.019459056028294393\n",
      "93 Train Loss 0.0023816568 Test MSE 0.0017528036640660398 Test RE 0.02001127206439899\n",
      "94 Train Loss 0.0023303253 Test MSE 0.0016812022965325254 Test RE 0.01959828403629217\n",
      "95 Train Loss 0.0022830155 Test MSE 0.0016640923767190056 Test RE 0.01949830124265833\n",
      "96 Train Loss 0.0022251217 Test MSE 0.0015618808328546946 Test RE 0.018890002176207173\n",
      "97 Train Loss 0.0021297408 Test MSE 0.0017295247031198441 Test RE 0.019877943187802158\n",
      "98 Train Loss 0.0020384723 Test MSE 0.0016149813268196008 Test RE 0.019208427505144513\n",
      "99 Train Loss 0.0019741917 Test MSE 0.0016091460581205488 Test RE 0.019173694048742498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Train Loss 0.0019322236 Test MSE 0.001530971243873725 Test RE 0.018702151769303427\n",
      "101 Train Loss 0.0019039013 Test MSE 0.0015189391620775267 Test RE 0.018628515607701478\n",
      "102 Train Loss 0.0018694175 Test MSE 0.0015670786988527586 Test RE 0.018921408587819575\n",
      "103 Train Loss 0.0018514647 Test MSE 0.0015637110756955624 Test RE 0.01890106677474548\n",
      "104 Train Loss 0.0018275611 Test MSE 0.0015879460370353722 Test RE 0.01904697142126679\n",
      "105 Train Loss 0.001793963 Test MSE 0.0015920706145152947 Test RE 0.019071691959536976\n",
      "106 Train Loss 0.0017632466 Test MSE 0.0014855874063135985 Test RE 0.018422864795316775\n",
      "107 Train Loss 0.0017361817 Test MSE 0.0014743302610787797 Test RE 0.018352931772401875\n",
      "108 Train Loss 0.0017070104 Test MSE 0.0014396803452524933 Test RE 0.01813598291940028\n",
      "109 Train Loss 0.0016659978 Test MSE 0.0013992866801688724 Test RE 0.01787974869329911\n",
      "110 Train Loss 0.0016365553 Test MSE 0.001428205477955329 Test RE 0.01806356256016727\n",
      "111 Train Loss 0.0016024709 Test MSE 0.0015182166621861102 Test RE 0.01862408465295607\n",
      "112 Train Loss 0.0015622572 Test MSE 0.0014585675227472847 Test RE 0.018254558338164063\n",
      "113 Train Loss 0.0015305295 Test MSE 0.0014862253268988982 Test RE 0.01842681981784976\n",
      "114 Train Loss 0.0015040935 Test MSE 0.001437720904650576 Test RE 0.018123636956244533\n",
      "115 Train Loss 0.001460822 Test MSE 0.0013864577233549673 Test RE 0.017797597301879624\n",
      "116 Train Loss 0.0014135558 Test MSE 0.0013183017827816392 Test RE 0.01735463483556386\n",
      "117 Train Loss 0.0013812467 Test MSE 0.0013536036225743821 Test RE 0.017585463288030834\n",
      "118 Train Loss 0.001355788 Test MSE 0.001292919691450958 Test RE 0.017186752987970205\n",
      "119 Train Loss 0.0013378853 Test MSE 0.0012800555131373815 Test RE 0.017101037624653682\n",
      "120 Train Loss 0.0013299923 Test MSE 0.0012411829163531684 Test RE 0.016839374476081234\n",
      "121 Train Loss 0.0013147683 Test MSE 0.001264966916209141 Test RE 0.016999949993255898\n",
      "122 Train Loss 0.0012895823 Test MSE 0.0012080498786200418 Test RE 0.016613092886983122\n",
      "123 Train Loss 0.0012801782 Test MSE 0.0012640632671113681 Test RE 0.01699387681704195\n",
      "124 Train Loss 0.0012710365 Test MSE 0.001256865351649837 Test RE 0.0169454238950843\n",
      "125 Train Loss 0.0012411134 Test MSE 0.0011863628018285413 Test RE 0.016463297295761552\n",
      "126 Train Loss 0.0012214186 Test MSE 0.0012011349565604415 Test RE 0.01656547767318896\n",
      "127 Train Loss 0.0011915357 Test MSE 0.0011849874253604602 Test RE 0.016453751397087622\n",
      "128 Train Loss 0.0011695792 Test MSE 0.0011384450330107596 Test RE 0.016127390193371904\n",
      "129 Train Loss 0.0011310789 Test MSE 0.0011134119354607795 Test RE 0.015949093223570705\n",
      "130 Train Loss 0.0011155547 Test MSE 0.0011146366843000344 Test RE 0.01595786278316174\n",
      "131 Train Loss 0.0010863922 Test MSE 0.0011047038990821397 Test RE 0.015886601569106554\n",
      "132 Train Loss 0.0010718463 Test MSE 0.0011207840941889653 Test RE 0.016001807432435875\n",
      "133 Train Loss 0.0010585757 Test MSE 0.0010780368025363083 Test RE 0.015693682203263382\n",
      "134 Train Loss 0.0010421592 Test MSE 0.001071000947765935 Test RE 0.015642385614122782\n",
      "135 Train Loss 0.0010283721 Test MSE 0.0010222283138049488 Test RE 0.015282063968458413\n",
      "136 Train Loss 0.0010152832 Test MSE 0.0010038521173928356 Test RE 0.015144081213609923\n",
      "137 Train Loss 0.0009938526 Test MSE 0.0009724650490714752 Test RE 0.014905448935379862\n",
      "138 Train Loss 0.0009804395 Test MSE 0.0009376592214335119 Test RE 0.014636275471417296\n",
      "139 Train Loss 0.00095839007 Test MSE 0.0009294857053842088 Test RE 0.014572344101878803\n",
      "140 Train Loss 0.0009326438 Test MSE 0.0009330663874559848 Test RE 0.01460038583235646\n",
      "141 Train Loss 0.0009086298 Test MSE 0.0009385009893664789 Test RE 0.014642843733751952\n",
      "142 Train Loss 0.00089103146 Test MSE 0.0009163132156524866 Test RE 0.014468717441521223\n",
      "143 Train Loss 0.0008797108 Test MSE 0.0008985429294330297 Test RE 0.014327732870536526\n",
      "144 Train Loss 0.0008717546 Test MSE 0.0008815614056844716 Test RE 0.014191697472764619\n",
      "145 Train Loss 0.00085971586 Test MSE 0.0008798159111454135 Test RE 0.014177640706916224\n",
      "146 Train Loss 0.0008501256 Test MSE 0.0008385414944568102 Test RE 0.013841091489821324\n",
      "147 Train Loss 0.00083910907 Test MSE 0.0008474996421655255 Test RE 0.013914827346585536\n",
      "148 Train Loss 0.0008360599 Test MSE 0.0008257088217526272 Test RE 0.013734774154314504\n",
      "149 Train Loss 0.00082911714 Test MSE 0.0008383599392827809 Test RE 0.013839593020261005\n",
      "Training time: 229.44\n",
      "3\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 60.135002 Test MSE 6.140880274218063 Test RE 1.1844681179048329\n",
      "1 Train Loss 49.838734 Test MSE 7.82753062582089 Test RE 1.3372741451208088\n",
      "2 Train Loss 40.004196 Test MSE 8.885922357747274 Test RE 1.4248177518561527\n",
      "3 Train Loss 33.66008 Test MSE 9.253866243143996 Test RE 1.4540176193440064\n",
      "4 Train Loss 28.838469 Test MSE 8.761371776269849 Test RE 1.4147969502511242\n",
      "5 Train Loss 25.403975 Test MSE 8.696378221833067 Test RE 1.4095395629877416\n",
      "6 Train Loss 22.728985 Test MSE 8.459373229404177 Test RE 1.3901995818824062\n",
      "7 Train Loss 20.859728 Test MSE 8.757222755386358 Test RE 1.4144619161173995\n",
      "8 Train Loss 19.584328 Test MSE 8.713541956552312 Test RE 1.410929856572309\n",
      "9 Train Loss 17.898256 Test MSE 8.529308508440785 Test RE 1.395934278590155\n",
      "10 Train Loss 16.37251 Test MSE 8.605473483368268 Test RE 1.4021531295247434\n",
      "11 Train Loss 13.10728 Test MSE 7.27109396714943 Test RE 1.2888665094073124\n",
      "12 Train Loss 10.41602 Test MSE 6.446491740773578 Test RE 1.2135838142642192\n",
      "13 Train Loss 8.309189 Test MSE 6.402214982272859 Test RE 1.2094089744393868\n",
      "14 Train Loss 5.455396 Test MSE 5.078948578446212 Test RE 1.0771965857356143\n",
      "15 Train Loss 3.2929416 Test MSE 5.1132246891256 Test RE 1.0808252919952521\n",
      "16 Train Loss 2.6963148 Test MSE 5.230469301365317 Test RE 1.0931465513775591\n",
      "17 Train Loss 2.2641592 Test MSE 5.302660254333919 Test RE 1.1006645055557038\n",
      "18 Train Loss 2.0180116 Test MSE 5.363804523810102 Test RE 1.1069921250468924\n",
      "19 Train Loss 1.8289151 Test MSE 5.414346913363805 Test RE 1.1121954133069392\n",
      "20 Train Loss 1.708942 Test MSE 5.443981736652417 Test RE 1.1152349984811332\n",
      "21 Train Loss 1.5870552 Test MSE 5.61516771182425 Test RE 1.132633561823002\n",
      "22 Train Loss 1.4929322 Test MSE 5.6538933592731935 Test RE 1.136532519533446\n",
      "23 Train Loss 1.4101436 Test MSE 5.649709575543764 Test RE 1.1361119344655743\n",
      "24 Train Loss 1.3522254 Test MSE 5.676070477132041 Test RE 1.138759334405445\n",
      "25 Train Loss 1.3136101 Test MSE 5.726941914313944 Test RE 1.1438509821700649\n",
      "26 Train Loss 1.2711811 Test MSE 5.760116279322862 Test RE 1.1471591819117042\n",
      "27 Train Loss 1.2411458 Test MSE 5.7882864071730245 Test RE 1.1499608794205276\n",
      "28 Train Loss 1.2134824 Test MSE 5.79814064582885 Test RE 1.1509393356710722\n",
      "29 Train Loss 1.1824408 Test MSE 5.8191527981417295 Test RE 1.153022921046948\n",
      "30 Train Loss 1.1532322 Test MSE 5.846978090414623 Test RE 1.1557763234285265\n",
      "31 Train Loss 1.1255591 Test MSE 5.90801185303945 Test RE 1.1617929566762646\n",
      "32 Train Loss 1.1068387 Test MSE 5.889351279338556 Test RE 1.1599567324369136\n",
      "33 Train Loss 1.0859108 Test MSE 5.938984438401897 Test RE 1.1648343092251612\n",
      "34 Train Loss 1.0623009 Test MSE 5.9538709895804125 Test RE 1.1662932718705414\n",
      "35 Train Loss 1.0416057 Test MSE 5.96419698234083 Test RE 1.1673042039788464\n",
      "36 Train Loss 1.0225593 Test MSE 5.988249224386201 Test RE 1.1696555711422554\n",
      "37 Train Loss 1.0091925 Test MSE 5.963812877628251 Test RE 1.167266615157901\n",
      "38 Train Loss 0.98831743 Test MSE 5.971753643572277 Test RE 1.1680434594211397\n",
      "39 Train Loss 0.97313815 Test MSE 5.977646435099837 Test RE 1.1686196167647978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Train Loss 0.95782536 Test MSE 5.9709021472945505 Test RE 1.1679601823660566\n",
      "41 Train Loss 0.94515336 Test MSE 5.999972019641062 Test RE 1.170799889643317\n",
      "42 Train Loss 0.9352565 Test MSE 6.004839836510528 Test RE 1.1712747321880788\n",
      "43 Train Loss 0.92444545 Test MSE 6.002021122135438 Test RE 1.1709997975902189\n",
      "44 Train Loss 0.91613007 Test MSE 6.024449580562653 Test RE 1.1731856638007128\n",
      "45 Train Loss 0.90619916 Test MSE 6.056662290757873 Test RE 1.1763179920041438\n",
      "46 Train Loss 0.8965441 Test MSE 6.075597646221201 Test RE 1.1781553585460443\n",
      "47 Train Loss 0.8887534 Test MSE 6.0532661694663314 Test RE 1.1759881503722278\n",
      "48 Train Loss 0.88288856 Test MSE 6.074130859079801 Test RE 1.1780131332420878\n",
      "49 Train Loss 0.87342066 Test MSE 6.0918057668563454 Test RE 1.1797258184961703\n",
      "50 Train Loss 0.86339474 Test MSE 6.1051192950778805 Test RE 1.181014249339158\n",
      "51 Train Loss 0.8552381 Test MSE 6.136415058600882 Test RE 1.1840374087001664\n",
      "52 Train Loss 0.8469418 Test MSE 6.140185379766927 Test RE 1.1844010995319019\n",
      "53 Train Loss 0.8412353 Test MSE 6.140350078816004 Test RE 1.1844169841033503\n",
      "54 Train Loss 0.83684206 Test MSE 6.140875445194393 Test RE 1.1844676521877493\n",
      "55 Train Loss 0.83208466 Test MSE 6.157554668238223 Test RE 1.1860751268639074\n",
      "56 Train Loss 0.8255572 Test MSE 6.16525877047348 Test RE 1.1868168813545437\n",
      "57 Train Loss 0.8202923 Test MSE 6.172079198662629 Test RE 1.1874731686372606\n",
      "58 Train Loss 0.8166344 Test MSE 6.185575255125141 Test RE 1.188770742204803\n",
      "59 Train Loss 0.8105298 Test MSE 6.166704317466781 Test RE 1.1869560076335384\n",
      "60 Train Loss 0.805443 Test MSE 6.1630167949072225 Test RE 1.1866010707542323\n",
      "61 Train Loss 0.79943454 Test MSE 6.1701539381367505 Test RE 1.1872879495680533\n",
      "62 Train Loss 0.79292554 Test MSE 6.181888757761185 Test RE 1.188416445863695\n",
      "63 Train Loss 0.7874278 Test MSE 6.195900232605093 Test RE 1.189762478053583\n",
      "64 Train Loss 0.78321445 Test MSE 6.19820142047613 Test RE 1.1899833993655804\n",
      "65 Train Loss 0.779117 Test MSE 6.195458651559834 Test RE 1.1897200801856247\n",
      "66 Train Loss 0.77315843 Test MSE 6.2020674133085025 Test RE 1.190354454599504\n",
      "67 Train Loss 0.76818097 Test MSE 6.2122565137908206 Test RE 1.1913318435108184\n",
      "68 Train Loss 0.7632064 Test MSE 6.232068962536439 Test RE 1.193230059710486\n",
      "69 Train Loss 0.7573445 Test MSE 6.244588567125792 Test RE 1.1944279984306967\n",
      "70 Train Loss 0.7518095 Test MSE 6.255952029597395 Test RE 1.1955142724484\n",
      "71 Train Loss 0.74785906 Test MSE 6.244426205609931 Test RE 1.1944124705541281\n",
      "72 Train Loss 0.743992 Test MSE 6.270746760132924 Test RE 1.196927076332914\n",
      "73 Train Loss 0.7406248 Test MSE 6.264353593576385 Test RE 1.1963167737781908\n",
      "74 Train Loss 0.73767567 Test MSE 6.283354496345327 Test RE 1.1981297212421094\n",
      "75 Train Loss 0.73295707 Test MSE 6.296570816675549 Test RE 1.1993891240212062\n",
      "76 Train Loss 0.72875285 Test MSE 6.299991133641089 Test RE 1.1997148357574456\n",
      "77 Train Loss 0.72490114 Test MSE 6.297907430191892 Test RE 1.1995164182813751\n",
      "78 Train Loss 0.72129834 Test MSE 6.296717008694025 Test RE 1.199403047480843\n",
      "79 Train Loss 0.716069 Test MSE 6.31987054817186 Test RE 1.2016061752434248\n",
      "80 Train Loss 0.71262205 Test MSE 6.328344448947298 Test RE 1.2024114829247188\n",
      "81 Train Loss 0.70873463 Test MSE 6.317116453250646 Test RE 1.2013443266773423\n",
      "82 Train Loss 0.70369077 Test MSE 6.314321858355988 Test RE 1.201078569181002\n",
      "83 Train Loss 0.70035774 Test MSE 6.316400730455184 Test RE 1.2012762692114083\n",
      "84 Train Loss 0.697336 Test MSE 6.324219934877448 Test RE 1.202019581736991\n",
      "85 Train Loss 0.6946877 Test MSE 6.344371115173056 Test RE 1.2039330864224895\n",
      "86 Train Loss 0.69177616 Test MSE 6.362545900098624 Test RE 1.2056563128918572\n",
      "87 Train Loss 0.6887334 Test MSE 6.364442817046125 Test RE 1.2058360255015148\n",
      "88 Train Loss 0.6849991 Test MSE 6.39169158867112 Test RE 1.2084146060125454\n",
      "89 Train Loss 0.68190503 Test MSE 6.407258230424159 Test RE 1.209885227493731\n",
      "90 Train Loss 0.67936885 Test MSE 6.407172510586079 Test RE 1.2098771342103836\n",
      "91 Train Loss 0.67716587 Test MSE 6.421374917525762 Test RE 1.2112173241058213\n",
      "92 Train Loss 0.6742607 Test MSE 6.423792647407133 Test RE 1.2114453220628112\n",
      "93 Train Loss 0.6714326 Test MSE 6.410825481736042 Test RE 1.2102219833998393\n",
      "94 Train Loss 0.6692347 Test MSE 6.43078357295972 Test RE 1.2121043424863633\n",
      "95 Train Loss 0.66679424 Test MSE 6.435726254150504 Test RE 1.2125700629179545\n",
      "96 Train Loss 0.66425186 Test MSE 6.446620010349575 Test RE 1.2135958878938164\n",
      "97 Train Loss 0.6618964 Test MSE 6.4417658211786195 Test RE 1.2131388938888943\n",
      "98 Train Loss 0.6591193 Test MSE 6.455560854920858 Test RE 1.2144371669376486\n",
      "99 Train Loss 0.6562823 Test MSE 6.463602164602667 Test RE 1.2151933077542842\n",
      "100 Train Loss 0.6524008 Test MSE 6.495822817640101 Test RE 1.2182183738650985\n",
      "101 Train Loss 0.6482058 Test MSE 6.525943442401708 Test RE 1.2210394991986724\n",
      "102 Train Loss 0.64460206 Test MSE 6.528839679380421 Test RE 1.221310419985787\n",
      "103 Train Loss 0.64163494 Test MSE 6.56334433348287 Test RE 1.2245334553239309\n",
      "104 Train Loss 0.63813305 Test MSE 6.5619068036602135 Test RE 1.224399346882476\n",
      "105 Train Loss 0.6354761 Test MSE 6.543249789695408 Test RE 1.2226574830498618\n",
      "106 Train Loss 0.632159 Test MSE 6.552177039103128 Test RE 1.2234912620002552\n",
      "107 Train Loss 0.6289871 Test MSE 6.587954646053731 Test RE 1.2268270995635269\n",
      "108 Train Loss 0.6247507 Test MSE 6.617170101190742 Test RE 1.2295443816794716\n",
      "109 Train Loss 0.6224757 Test MSE 6.615359377776315 Test RE 1.2293761438154391\n",
      "110 Train Loss 0.6188769 Test MSE 6.65244089781361 Test RE 1.2328168814056462\n",
      "111 Train Loss 0.6145814 Test MSE 6.6471207558379 Test RE 1.2323238238369765\n",
      "112 Train Loss 0.61129755 Test MSE 6.665668027193639 Test RE 1.234041885206797\n",
      "113 Train Loss 0.6075139 Test MSE 6.668455866183282 Test RE 1.2342999201423854\n",
      "114 Train Loss 0.6051706 Test MSE 6.680325721214066 Test RE 1.2353979589932733\n",
      "115 Train Loss 0.6031698 Test MSE 6.692630614241604 Test RE 1.2365352123768936\n",
      "116 Train Loss 0.6002968 Test MSE 6.711533686089385 Test RE 1.2382802535735769\n",
      "117 Train Loss 0.59754235 Test MSE 6.723497687148475 Test RE 1.2393834432925506\n",
      "118 Train Loss 0.59456426 Test MSE 6.73068730489379 Test RE 1.2400459193409694\n",
      "119 Train Loss 0.5920268 Test MSE 6.736122073636659 Test RE 1.2405464627923617\n",
      "120 Train Loss 0.58783984 Test MSE 6.7402104113554255 Test RE 1.2409228665692023\n",
      "121 Train Loss 0.58496445 Test MSE 6.747853094201355 Test RE 1.2416262046249464\n",
      "122 Train Loss 0.5830245 Test MSE 6.737839232887863 Test RE 1.2407045715730163\n",
      "123 Train Loss 0.58138925 Test MSE 6.754532616543059 Test RE 1.2422405791898112\n",
      "124 Train Loss 0.57986486 Test MSE 6.750551172466334 Test RE 1.2418744072627008\n",
      "125 Train Loss 0.57784224 Test MSE 6.760254311803149 Test RE 1.242766612437029\n",
      "126 Train Loss 0.57567847 Test MSE 6.7552161511147215 Test RE 1.2423034327541993\n",
      "127 Train Loss 0.57376134 Test MSE 6.763404939416126 Test RE 1.2430561754124467\n",
      "128 Train Loss 0.57271314 Test MSE 6.768852956722255 Test RE 1.2435567242034786\n",
      "129 Train Loss 0.5713944 Test MSE 6.768797917740983 Test RE 1.243551668381257\n",
      "130 Train Loss 0.5696011 Test MSE 6.76487406313492 Test RE 1.2431911742900685\n",
      "131 Train Loss 0.5677503 Test MSE 6.766710474728911 Test RE 1.2433599029129243\n",
      "132 Train Loss 0.5660628 Test MSE 6.760344052321732 Test RE 1.2427748611023168\n",
      "133 Train Loss 0.5638993 Test MSE 6.76867842283618 Test RE 1.2435406916357645\n",
      "134 Train Loss 0.5617731 Test MSE 6.779126881962476 Test RE 1.2445001162793428\n",
      "135 Train Loss 0.5594365 Test MSE 6.791683461428249 Test RE 1.2456521403882108\n",
      "136 Train Loss 0.557912 Test MSE 6.7962032742337195 Test RE 1.2460665573835992\n",
      "137 Train Loss 0.5568997 Test MSE 6.807206273019077 Test RE 1.2470748353490366\n",
      "138 Train Loss 0.5559677 Test MSE 6.804547165598729 Test RE 1.2468312383635551\n",
      "139 Train Loss 0.5539344 Test MSE 6.827096826747583 Test RE 1.2488954732496282\n",
      "140 Train Loss 0.5523579 Test MSE 6.830832344115362 Test RE 1.2492370996291027\n",
      "141 Train Loss 0.55086637 Test MSE 6.829632246604205 Test RE 1.2491273566202987\n",
      "142 Train Loss 0.5493243 Test MSE 6.832148095409293 Test RE 1.2493574075289045\n",
      "143 Train Loss 0.5475244 Test MSE 6.849800542538804 Test RE 1.2509703693746161\n",
      "144 Train Loss 0.5460441 Test MSE 6.859304271601951 Test RE 1.2518378955489042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 Train Loss 0.5442101 Test MSE 6.8617730412382905 Test RE 1.2520631531868656\n",
      "146 Train Loss 0.54274046 Test MSE 6.877127342246946 Test RE 1.2534632149450806\n",
      "147 Train Loss 0.5412425 Test MSE 6.880755134778578 Test RE 1.253793782108381\n",
      "148 Train Loss 0.54013085 Test MSE 6.887939824706656 Test RE 1.254448199327332\n",
      "149 Train Loss 0.5387453 Test MSE 6.896272446931511 Test RE 1.255206748604367\n",
      "Training time: 231.75\n",
      "4\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 47.869823 Test MSE 8.243558586493695 Test RE 1.3723517001338184\n",
      "1 Train Loss 37.69924 Test MSE 7.102273489981717 Test RE 1.2738161659426508\n",
      "2 Train Loss 29.914015 Test MSE 7.354119801470853 Test RE 1.296204158676269\n",
      "3 Train Loss 22.46656 Test MSE 6.77097795673584 Test RE 1.2437519087277573\n",
      "4 Train Loss 17.916676 Test MSE 6.471884680298302 Test RE 1.2159716380996355\n",
      "5 Train Loss 15.955847 Test MSE 6.593398927151787 Test RE 1.227333919403492\n",
      "6 Train Loss 14.236919 Test MSE 6.038138083840849 Test RE 1.1745177393457882\n",
      "7 Train Loss 12.410578 Test MSE 6.15575303373412 Test RE 1.1859015977344374\n",
      "8 Train Loss 10.886431 Test MSE 5.944237141805264 Test RE 1.1653493111523947\n",
      "9 Train Loss 9.088343 Test MSE 5.52996011185976 Test RE 1.1240071131734042\n",
      "10 Train Loss 7.3751802 Test MSE 5.251463800895145 Test RE 1.0953382362737398\n",
      "11 Train Loss 5.8428245 Test MSE 4.595402533587797 Test RE 1.0246365413603806\n",
      "12 Train Loss 4.6944294 Test MSE 4.250766175884732 Test RE 0.9854660528090172\n",
      "13 Train Loss 3.8040915 Test MSE 3.9828224513909656 Test RE 0.9539015041093794\n",
      "14 Train Loss 3.1096845 Test MSE 3.6554858248407065 Test RE 0.9138619860790728\n",
      "15 Train Loss 2.6863825 Test MSE 3.4662856614459345 Test RE 0.8898980100335799\n",
      "16 Train Loss 2.3683193 Test MSE 3.244449271972225 Test RE 0.8609512370593019\n",
      "17 Train Loss 2.044586 Test MSE 3.1308507430916506 Test RE 0.8457446170297395\n",
      "18 Train Loss 1.8608996 Test MSE 2.8515250729469566 Test RE 0.8071358873326607\n",
      "19 Train Loss 1.6874844 Test MSE 2.7241055017333706 Test RE 0.7888964866720594\n",
      "20 Train Loss 1.546102 Test MSE 2.5743715385416333 Test RE 0.7669087148634043\n",
      "21 Train Loss 1.4355222 Test MSE 2.4309496872976317 Test RE 0.7452398084037163\n",
      "22 Train Loss 1.3151499 Test MSE 2.2157112280629723 Test RE 0.7114831833214597\n",
      "23 Train Loss 1.2193613 Test MSE 2.0717383606164446 Test RE 0.6879795261195222\n",
      "24 Train Loss 1.1185341 Test MSE 1.991663883030023 Test RE 0.6745530095228136\n",
      "25 Train Loss 1.0595671 Test MSE 1.9494129530650721 Test RE 0.6673597103458117\n",
      "26 Train Loss 1.0193946 Test MSE 1.9252432259117414 Test RE 0.6632096889370969\n",
      "27 Train Loss 0.9681668 Test MSE 1.801863245287347 Test RE 0.6416068228044417\n",
      "28 Train Loss 0.91041005 Test MSE 1.6826163792700026 Test RE 0.6200127441706903\n",
      "29 Train Loss 0.86031944 Test MSE 1.5416211117851173 Test RE 0.5934674236625425\n",
      "30 Train Loss 0.7933163 Test MSE 1.3688559370079205 Test RE 0.5592254559073953\n",
      "31 Train Loss 0.6880701 Test MSE 1.1804703038308797 Test RE 0.5193206517349274\n",
      "32 Train Loss 0.5816888 Test MSE 1.0270131279941739 Test RE 0.4843909916146913\n",
      "33 Train Loss 0.48359653 Test MSE 1.020927128540372 Test RE 0.4829536274623952\n",
      "34 Train Loss 0.41295832 Test MSE 1.0292036569017629 Test RE 0.48490729819820394\n",
      "35 Train Loss 0.36736986 Test MSE 1.0182428448127214 Test RE 0.4823183040477648\n",
      "36 Train Loss 0.32833186 Test MSE 0.9626401106257817 Test RE 0.4689645741264128\n",
      "37 Train Loss 0.29460216 Test MSE 0.9013494439341917 Test RE 0.45378972475586604\n",
      "38 Train Loss 0.2650802 Test MSE 0.8657984044622086 Test RE 0.44475050598804616\n",
      "39 Train Loss 0.23290734 Test MSE 0.8297690993372222 Test RE 0.43539825997775605\n",
      "40 Train Loss 0.19337507 Test MSE 0.7854733391237363 Test RE 0.4236173943682439\n",
      "41 Train Loss 0.17230836 Test MSE 0.7604975021604822 Test RE 0.41682806881139084\n",
      "42 Train Loss 0.15361881 Test MSE 0.709459711383247 Test RE 0.4025982930542936\n",
      "43 Train Loss 0.13569218 Test MSE 0.6714061687275501 Test RE 0.3916523383629118\n",
      "44 Train Loss 0.121438295 Test MSE 0.6669956662763057 Test RE 0.39036382639098693\n",
      "45 Train Loss 0.10711597 Test MSE 0.6599420758598747 Test RE 0.3882942590578811\n",
      "46 Train Loss 0.1004079 Test MSE 0.6416663406356401 Test RE 0.3828800072646705\n",
      "47 Train Loss 0.0933434 Test MSE 0.6302570028777231 Test RE 0.3794607844809145\n",
      "48 Train Loss 0.08342801 Test MSE 0.5878206509513408 Test RE 0.3664632931330715\n",
      "49 Train Loss 0.07602755 Test MSE 0.5636756526530519 Test RE 0.3588580546019976\n",
      "50 Train Loss 0.07171434 Test MSE 0.526556574677484 Test RE 0.3468411201867641\n",
      "51 Train Loss 0.06783584 Test MSE 0.5234179409249059 Test RE 0.3458058712116874\n",
      "52 Train Loss 0.062340174 Test MSE 0.4951947899435023 Test RE 0.33635361032802663\n",
      "53 Train Loss 0.057881173 Test MSE 0.468382549109557 Test RE 0.32712099098646075\n",
      "54 Train Loss 0.052592635 Test MSE 0.4702685470131561 Test RE 0.3277789250795871\n",
      "55 Train Loss 0.04946139 Test MSE 0.44126732429227705 Test RE 0.3175111236450739\n",
      "56 Train Loss 0.046796937 Test MSE 0.43449168931204774 Test RE 0.3150640107497749\n",
      "57 Train Loss 0.043151677 Test MSE 0.4175161197667637 Test RE 0.30884792234150754\n",
      "58 Train Loss 0.03984592 Test MSE 0.4003643555613687 Test RE 0.3024375859846681\n",
      "59 Train Loss 0.035577327 Test MSE 0.38808303553198387 Test RE 0.2977627656607324\n",
      "60 Train Loss 0.033504453 Test MSE 0.36822595784614764 Test RE 0.29004491809510674\n",
      "61 Train Loss 0.030995259 Test MSE 0.35930601606492085 Test RE 0.28651034309926315\n",
      "62 Train Loss 0.027963817 Test MSE 0.3249827352827469 Test RE 0.2724822426827495\n",
      "63 Train Loss 0.024524324 Test MSE 0.2975263062585241 Test RE 0.26071783769252155\n",
      "64 Train Loss 0.023117105 Test MSE 0.2824197069618363 Test RE 0.2540127751649894\n",
      "65 Train Loss 0.021603135 Test MSE 0.2716607897989863 Test RE 0.24912742536143814\n",
      "66 Train Loss 0.020386945 Test MSE 0.2672620702641531 Test RE 0.2471022639286147\n",
      "67 Train Loss 0.019187866 Test MSE 0.2702407528372288 Test RE 0.24847544743822017\n",
      "68 Train Loss 0.017912073 Test MSE 0.2602660228518376 Test RE 0.24384665254236348\n",
      "69 Train Loss 0.016756216 Test MSE 0.247885232200355 Test RE 0.23797612439957466\n",
      "70 Train Loss 0.015981037 Test MSE 0.2459603691242348 Test RE 0.2370503649922367\n",
      "71 Train Loss 0.0154129965 Test MSE 0.24288249821643693 Test RE 0.23556250874165774\n",
      "72 Train Loss 0.014687121 Test MSE 0.24124370689207325 Test RE 0.23476646296032685\n",
      "73 Train Loss 0.013783372 Test MSE 0.23990649894638474 Test RE 0.2341149064444455\n",
      "74 Train Loss 0.013317673 Test MSE 0.23733830126718464 Test RE 0.23285843541040388\n",
      "75 Train Loss 0.012807079 Test MSE 0.2363203419901868 Test RE 0.2323585263771313\n",
      "76 Train Loss 0.012106562 Test MSE 0.22558691945383386 Test RE 0.22702046930286707\n",
      "77 Train Loss 0.011587693 Test MSE 0.21344011058083617 Test RE 0.22082390160456808\n",
      "78 Train Loss 0.0111377835 Test MSE 0.21114568264033076 Test RE 0.21963379369597166\n",
      "79 Train Loss 0.0106208725 Test MSE 0.20890020172742788 Test RE 0.21846279714813496\n",
      "80 Train Loss 0.009866972 Test MSE 0.189081319371424 Test RE 0.20784154989131318\n",
      "81 Train Loss 0.009448611 Test MSE 0.18145881782217654 Test RE 0.2036090599810994\n",
      "82 Train Loss 0.008951989 Test MSE 0.17378567103062198 Test RE 0.1992576678098578\n",
      "83 Train Loss 0.008558565 Test MSE 0.16778878199971453 Test RE 0.19578955577018817\n",
      "84 Train Loss 0.008006822 Test MSE 0.159117386359643 Test RE 0.19066320035040835\n",
      "85 Train Loss 0.0076021496 Test MSE 0.15141893878471196 Test RE 0.1859936680275972\n",
      "86 Train Loss 0.007321902 Test MSE 0.15389656501960305 Test RE 0.18750917521151947\n",
      "87 Train Loss 0.0069441004 Test MSE 0.14849490930306877 Test RE 0.1841890648807954\n",
      "88 Train Loss 0.0067736222 Test MSE 0.15116225531763058 Test RE 0.18583595410550963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 Train Loss 0.006619411 Test MSE 0.14442787575541965 Test RE 0.18164923454716542\n",
      "90 Train Loss 0.0062265415 Test MSE 0.13781365690034933 Test RE 0.17744108677522996\n",
      "91 Train Loss 0.0059600295 Test MSE 0.13163564026564573 Test RE 0.17341825239727524\n",
      "92 Train Loss 0.005717002 Test MSE 0.13244704547689434 Test RE 0.17395190840569463\n",
      "93 Train Loss 0.005450212 Test MSE 0.12949295268330707 Test RE 0.17200106149372982\n",
      "94 Train Loss 0.005161588 Test MSE 0.12546575285987904 Test RE 0.169305340973505\n",
      "95 Train Loss 0.004925963 Test MSE 0.11528945976349321 Test RE 0.1622941487534782\n",
      "96 Train Loss 0.004760282 Test MSE 0.10571151390481831 Test RE 0.1554065096424221\n",
      "97 Train Loss 0.004539044 Test MSE 0.1057898435580817 Test RE 0.15546407519719524\n",
      "98 Train Loss 0.00436417 Test MSE 0.09737222567803719 Test RE 0.14915080743067016\n",
      "99 Train Loss 0.004164127 Test MSE 0.09194410361730719 Test RE 0.1449339077185528\n",
      "100 Train Loss 0.004064411 Test MSE 0.08891374905986067 Test RE 0.14252548306306978\n",
      "101 Train Loss 0.003954756 Test MSE 0.08620235963655139 Test RE 0.14033552939560034\n",
      "102 Train Loss 0.0038482195 Test MSE 0.0855177681083198 Test RE 0.13977716869399254\n",
      "103 Train Loss 0.0037009213 Test MSE 0.08561497810344942 Test RE 0.13985659007628976\n",
      "104 Train Loss 0.003581624 Test MSE 0.08145203066291194 Test RE 0.13641402343451217\n",
      "105 Train Loss 0.0034590822 Test MSE 0.07629390299178583 Test RE 0.13202402736625338\n",
      "106 Train Loss 0.0033526076 Test MSE 0.07473670316996328 Test RE 0.13066974040769902\n",
      "107 Train Loss 0.00323368 Test MSE 0.07188631544475668 Test RE 0.1281537067728386\n",
      "108 Train Loss 0.0031509555 Test MSE 0.06906147562620553 Test RE 0.1256105123614905\n",
      "109 Train Loss 0.0029999262 Test MSE 0.06791505211036744 Test RE 0.12456357939668963\n",
      "110 Train Loss 0.0028684163 Test MSE 0.06735976919587504 Test RE 0.12405330966960866\n",
      "111 Train Loss 0.002771317 Test MSE 0.06628201071129954 Test RE 0.1230568793862374\n",
      "112 Train Loss 0.0026941365 Test MSE 0.0652209860762482 Test RE 0.12206797514580486\n",
      "113 Train Loss 0.0025998838 Test MSE 0.0649727910418283 Test RE 0.12183549212782023\n",
      "114 Train Loss 0.00252269 Test MSE 0.06441472071227257 Test RE 0.12131112334954841\n",
      "115 Train Loss 0.0024727318 Test MSE 0.06128803869304838 Test RE 0.11833028813787835\n",
      "116 Train Loss 0.002419784 Test MSE 0.058759624100140476 Test RE 0.11586374575966023\n",
      "117 Train Loss 0.0023681247 Test MSE 0.05869650460218881 Test RE 0.11580149870988497\n",
      "118 Train Loss 0.002303855 Test MSE 0.056500589814161326 Test RE 0.11361470653018495\n",
      "119 Train Loss 0.0022675472 Test MSE 0.05518939801329784 Test RE 0.11228865730063983\n",
      "120 Train Loss 0.002217946 Test MSE 0.05406056766743079 Test RE 0.11113436212729425\n",
      "121 Train Loss 0.0021737823 Test MSE 0.053052697320214504 Test RE 0.11009352947506773\n",
      "122 Train Loss 0.0021182587 Test MSE 0.050677265260250765 Test RE 0.10760058824701657\n",
      "123 Train Loss 0.0020688311 Test MSE 0.04782027111863727 Test RE 0.10452353213484217\n",
      "124 Train Loss 0.0020010378 Test MSE 0.045467458944884485 Test RE 0.10191976225811859\n",
      "125 Train Loss 0.0019227671 Test MSE 0.04258089259484847 Test RE 0.09863145521750555\n",
      "126 Train Loss 0.0018697124 Test MSE 0.04078830964591898 Test RE 0.0965330246537301\n",
      "127 Train Loss 0.0018422533 Test MSE 0.039567707913666886 Test RE 0.09507766487335739\n",
      "128 Train Loss 0.0018050406 Test MSE 0.039137848561180515 Test RE 0.09455979772115926\n",
      "129 Train Loss 0.0017653333 Test MSE 0.03849340436548403 Test RE 0.09377805504298124\n",
      "130 Train Loss 0.0017062409 Test MSE 0.036433003118327874 Test RE 0.09123375412477486\n",
      "131 Train Loss 0.0016351659 Test MSE 0.03542654827291314 Test RE 0.08996477126357633\n",
      "132 Train Loss 0.001559266 Test MSE 0.03351507078601505 Test RE 0.08750404528257984\n",
      "133 Train Loss 0.0015088959 Test MSE 0.03200426924702698 Test RE 0.08550903749840215\n",
      "134 Train Loss 0.0014618272 Test MSE 0.030062605109135172 Test RE 0.08287458494297821\n",
      "135 Train Loss 0.0014115192 Test MSE 0.02907002230098975 Test RE 0.0814949584656558\n",
      "136 Train Loss 0.0013641595 Test MSE 0.02850460474328379 Test RE 0.0806985203760726\n",
      "137 Train Loss 0.0013088603 Test MSE 0.025692715938710423 Test RE 0.07661486981103663\n",
      "138 Train Loss 0.0012387568 Test MSE 0.02432374371747623 Test RE 0.07454581543567063\n",
      "139 Train Loss 0.0012196072 Test MSE 0.023797495492785925 Test RE 0.07373500039275488\n",
      "140 Train Loss 0.0012072161 Test MSE 0.02411137453160075 Test RE 0.07421967441493077\n",
      "141 Train Loss 0.001188112 Test MSE 0.02334730054653689 Test RE 0.07303422031372919\n",
      "142 Train Loss 0.0011596039 Test MSE 0.021617492366004673 Test RE 0.07027659601403734\n",
      "143 Train Loss 0.0011351707 Test MSE 0.020798880741215747 Test RE 0.06893313698124959\n",
      "144 Train Loss 0.0010998796 Test MSE 0.019070703856017616 Test RE 0.06600721684329647\n",
      "145 Train Loss 0.001082386 Test MSE 0.01776771087720701 Test RE 0.06371237573955973\n",
      "146 Train Loss 0.0010651755 Test MSE 0.017676245808611542 Test RE 0.06354817406198442\n",
      "147 Train Loss 0.0010430841 Test MSE 0.01757166283235879 Test RE 0.06335990114114941\n",
      "148 Train Loss 0.0010235053 Test MSE 0.017402215197356824 Test RE 0.06305366393573074\n",
      "149 Train Loss 0.0010043716 Test MSE 0.017315214172434857 Test RE 0.06289585049380594\n",
      "Training time: 228.26\n",
      "5\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 67.89705 Test MSE 5.256722822197826 Test RE 1.09588655631211\n",
      "1 Train Loss 48.38909 Test MSE 8.773316682069302 Test RE 1.415761060700065\n",
      "2 Train Loss 38.54624 Test MSE 9.589502759347125 Test RE 1.4801512781013662\n",
      "3 Train Loss 33.740345 Test MSE 9.555728342484732 Test RE 1.4775424180402357\n",
      "4 Train Loss 29.864925 Test MSE 9.478832654934674 Test RE 1.4715854605570848\n",
      "5 Train Loss 27.376705 Test MSE 9.241511620538724 Test RE 1.453046682534548\n",
      "6 Train Loss 23.830563 Test MSE 9.298354205123092 Test RE 1.4575085235976848\n",
      "7 Train Loss 20.271496 Test MSE 9.323197482090647 Test RE 1.4594543052630358\n",
      "8 Train Loss 18.012272 Test MSE 9.20737072566065 Test RE 1.450360205588101\n",
      "9 Train Loss 16.11223 Test MSE 9.087069884159023 Test RE 1.4408540589807757\n",
      "10 Train Loss 14.226538 Test MSE 8.87984751359411 Test RE 1.424330631595393\n",
      "11 Train Loss 12.89258 Test MSE 8.800216868862305 Test RE 1.4179298578703732\n",
      "12 Train Loss 11.195976 Test MSE 8.439586059083155 Test RE 1.3885727343643877\n",
      "13 Train Loss 9.850225 Test MSE 8.013126352414327 Test RE 1.353035077016592\n",
      "14 Train Loss 8.5231285 Test MSE 7.737137678428266 Test RE 1.3295302492259047\n",
      "15 Train Loss 7.2280817 Test MSE 7.72186835905961 Test RE 1.3282176806253774\n",
      "16 Train Loss 5.7913723 Test MSE 7.576184482661098 Test RE 1.3156286759102376\n",
      "17 Train Loss 4.8025417 Test MSE 7.444157656985912 Test RE 1.3041148535194713\n",
      "18 Train Loss 4.1102195 Test MSE 7.328047631505624 Test RE 1.2939044367492052\n",
      "19 Train Loss 3.5396166 Test MSE 7.061360099817146 Test RE 1.270141891082003\n",
      "20 Train Loss 3.186997 Test MSE 7.001159571092463 Test RE 1.264716103448034\n",
      "21 Train Loss 2.96558 Test MSE 6.991884745289183 Test RE 1.2638781059092383\n",
      "22 Train Loss 2.7538788 Test MSE 7.053707947326986 Test RE 1.2694535000462963\n",
      "23 Train Loss 2.607854 Test MSE 7.019371084976439 Test RE 1.2663599337339868\n",
      "24 Train Loss 2.5192459 Test MSE 7.022637088519146 Test RE 1.2666545082047738\n",
      "25 Train Loss 2.4481435 Test MSE 7.046232789738175 Test RE 1.2687806709148741\n",
      "26 Train Loss 2.3584516 Test MSE 7.096716737719546 Test RE 1.2733177575169037\n",
      "27 Train Loss 2.2382712 Test MSE 7.130154611352868 Test RE 1.2763140024483153\n",
      "28 Train Loss 2.1274054 Test MSE 7.173602992698747 Test RE 1.2801967762802728\n",
      "29 Train Loss 2.0526733 Test MSE 7.173260145277954 Test RE 1.2801661837448588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 1.9602687 Test MSE 7.171627702736227 Test RE 1.2800205096297723\n",
      "31 Train Loss 1.913124 Test MSE 7.201942273138506 Test RE 1.2827229890672445\n",
      "32 Train Loss 1.8581221 Test MSE 7.235621169558305 Test RE 1.285718730025867\n",
      "33 Train Loss 1.8031105 Test MSE 7.3248612466050185 Test RE 1.2936230981142267\n",
      "34 Train Loss 1.762732 Test MSE 7.346818427939793 Test RE 1.2955605452184265\n",
      "35 Train Loss 1.7301062 Test MSE 7.330416909480443 Test RE 1.2941135901067196\n",
      "36 Train Loss 1.6878847 Test MSE 7.376704953264822 Test RE 1.2981930116194986\n",
      "37 Train Loss 1.640696 Test MSE 7.363051230552187 Test RE 1.2969910266474938\n",
      "38 Train Loss 1.5948017 Test MSE 7.368982778566147 Test RE 1.2975133383604471\n",
      "39 Train Loss 1.5516233 Test MSE 7.379786291094916 Test RE 1.2984641186801849\n",
      "40 Train Loss 1.5100595 Test MSE 7.383779260731421 Test RE 1.298815350169959\n",
      "41 Train Loss 1.4830952 Test MSE 7.376435968679884 Test RE 1.2981693427121803\n",
      "42 Train Loss 1.4507368 Test MSE 7.3859010264523 Test RE 1.2990019472936654\n",
      "43 Train Loss 1.41006 Test MSE 7.345163624908249 Test RE 1.2954146304748073\n",
      "44 Train Loss 1.3742305 Test MSE 7.351136933489036 Test RE 1.295941258551907\n",
      "45 Train Loss 1.3379748 Test MSE 7.337558912828071 Test RE 1.2947438621330136\n",
      "46 Train Loss 1.3039972 Test MSE 7.286325342421375 Test RE 1.2902157520064492\n",
      "47 Train Loss 1.2736592 Test MSE 7.2677822053351635 Test RE 1.288572956260204\n",
      "48 Train Loss 1.2444036 Test MSE 7.235887723602644 Test RE 1.2857424121924068\n",
      "49 Train Loss 1.2147881 Test MSE 7.157605271606192 Test RE 1.278768507815447\n",
      "50 Train Loss 1.1877468 Test MSE 7.115578421438036 Test RE 1.2750087493380695\n",
      "51 Train Loss 1.1641166 Test MSE 7.073113631992465 Test RE 1.2711985180211147\n",
      "52 Train Loss 1.1436985 Test MSE 7.039323037065259 Test RE 1.2681584156448469\n",
      "53 Train Loss 1.1095432 Test MSE 6.972821111174596 Test RE 1.2621539244864608\n",
      "54 Train Loss 1.0936484 Test MSE 6.939040610103744 Test RE 1.2590928997188218\n",
      "55 Train Loss 1.0705264 Test MSE 6.822486874029841 Test RE 1.2484737477740262\n",
      "56 Train Loss 1.0484363 Test MSE 6.767686398033641 Test RE 1.2434495609647824\n",
      "57 Train Loss 1.0262271 Test MSE 6.618729423272121 Test RE 1.2296892429070858\n",
      "58 Train Loss 1.0070565 Test MSE 6.433185509387279 Test RE 1.2123306854922986\n",
      "59 Train Loss 0.988205 Test MSE 6.362251814551638 Test RE 1.205628449030516\n",
      "60 Train Loss 0.97054285 Test MSE 6.283028130290757 Test RE 1.1980986045871456\n",
      "61 Train Loss 0.96151996 Test MSE 6.2522337916329995 Test RE 1.195158941458446\n",
      "62 Train Loss 0.94994783 Test MSE 6.2055392816234525 Test RE 1.1906875834926776\n",
      "63 Train Loss 0.9387891 Test MSE 6.186456008069906 Test RE 1.188855372657165\n",
      "64 Train Loss 0.92937684 Test MSE 6.1646041184360065 Test RE 1.1867538691806445\n",
      "65 Train Loss 0.92185307 Test MSE 6.183875790639316 Test RE 1.1886074257500177\n",
      "66 Train Loss 0.9127652 Test MSE 6.169693335620434 Test RE 1.1872436331677692\n",
      "67 Train Loss 0.90355694 Test MSE 6.140388772958849 Test RE 1.1844207159693825\n",
      "68 Train Loss 0.8919957 Test MSE 6.156196660874267 Test RE 1.1859443291966292\n",
      "69 Train Loss 0.8828093 Test MSE 6.152838015551191 Test RE 1.1856207763589057\n",
      "70 Train Loss 0.8731765 Test MSE 6.150491598744219 Test RE 1.1853946834739084\n",
      "71 Train Loss 0.86533844 Test MSE 6.149695875455503 Test RE 1.1853180004436954\n",
      "72 Train Loss 0.8585055 Test MSE 6.1643155304950445 Test RE 1.1867260906844694\n",
      "73 Train Loss 0.85148954 Test MSE 6.170919708727926 Test RE 1.1873616237418478\n",
      "74 Train Loss 0.84273833 Test MSE 6.17622887772924 Test RE 1.1878722889677025\n",
      "75 Train Loss 0.8373066 Test MSE 6.188646475260453 Test RE 1.1890658257994613\n",
      "76 Train Loss 0.83048725 Test MSE 6.19543228635046 Test RE 1.1897175487142564\n",
      "77 Train Loss 0.82585883 Test MSE 6.193685309715917 Test RE 1.1895497997017281\n",
      "78 Train Loss 0.8211439 Test MSE 6.195950871139859 Test RE 1.1897673399544566\n",
      "79 Train Loss 0.81554496 Test MSE 6.196302176614807 Test RE 1.1898010689062053\n",
      "80 Train Loss 0.8089756 Test MSE 6.187898500882179 Test RE 1.188993966981025\n",
      "81 Train Loss 0.8048384 Test MSE 6.186520075150713 Test RE 1.188861528548028\n",
      "82 Train Loss 0.8008083 Test MSE 6.178895244341882 Test RE 1.1881286720539925\n",
      "83 Train Loss 0.7961221 Test MSE 6.18718988825736 Test RE 1.1889258856883178\n",
      "84 Train Loss 0.7930026 Test MSE 6.186561706929074 Test RE 1.1888655287238774\n",
      "85 Train Loss 0.7888821 Test MSE 6.183015405557986 Test RE 1.188524735241235\n",
      "86 Train Loss 0.78505355 Test MSE 6.1775841699467575 Test RE 1.1880026132959924\n",
      "87 Train Loss 0.77997595 Test MSE 6.194232220979878 Test RE 1.1896023180160156\n",
      "88 Train Loss 0.77411276 Test MSE 6.201632866955176 Test RE 1.1903127529205508\n",
      "89 Train Loss 0.76804626 Test MSE 6.210516163666339 Test RE 1.191164957311904\n",
      "90 Train Loss 0.7629451 Test MSE 6.220479565173379 Test RE 1.1921200549490674\n",
      "91 Train Loss 0.75851107 Test MSE 6.220025099821875 Test RE 1.192076506284532\n",
      "92 Train Loss 0.75391734 Test MSE 6.235976139477247 Test RE 1.1936040471053155\n",
      "93 Train Loss 0.7511072 Test MSE 6.2538692867027 Test RE 1.1953152494924424\n",
      "94 Train Loss 0.7472557 Test MSE 6.263138027988113 Test RE 1.1962006985891807\n",
      "95 Train Loss 0.74391055 Test MSE 6.269637957086194 Test RE 1.1968212504151754\n",
      "96 Train Loss 0.73999864 Test MSE 6.268646216699282 Test RE 1.1967265892146726\n",
      "97 Train Loss 0.73706275 Test MSE 6.278417661547117 Test RE 1.1976589431880358\n",
      "98 Train Loss 0.73419124 Test MSE 6.28434993742039 Test RE 1.198224624394963\n",
      "99 Train Loss 0.73106706 Test MSE 6.275039801952767 Test RE 1.1973367228252862\n",
      "100 Train Loss 0.7287493 Test MSE 6.271183015459154 Test RE 1.1969687106669649\n",
      "101 Train Loss 0.7259209 Test MSE 6.267072054454146 Test RE 1.1965763207172737\n",
      "102 Train Loss 0.72249615 Test MSE 6.258829464824996 Test RE 1.1957891802000273\n",
      "103 Train Loss 0.7195833 Test MSE 6.277379536239838 Test RE 1.197559923695794\n",
      "104 Train Loss 0.7163552 Test MSE 6.2702515634116525 Test RE 1.1968798151303413\n",
      "105 Train Loss 0.71259874 Test MSE 6.2726971777485785 Test RE 1.1971132045759951\n",
      "106 Train Loss 0.7093029 Test MSE 6.295477332991304 Test RE 1.199284974522874\n",
      "107 Train Loss 0.7070188 Test MSE 6.306846103421898 Test RE 1.2003673583457348\n",
      "108 Train Loss 0.7049141 Test MSE 6.315211226082908 Test RE 1.2011631517323607\n",
      "109 Train Loss 0.70258653 Test MSE 6.321073972021579 Test RE 1.2017205741608012\n",
      "110 Train Loss 0.69979525 Test MSE 6.324103342789704 Test RE 1.2020085015864024\n",
      "111 Train Loss 0.69740224 Test MSE 6.33578616672572 Test RE 1.2031182537049716\n",
      "112 Train Loss 0.6957123 Test MSE 6.333726877579216 Test RE 1.2029227160363005\n",
      "113 Train Loss 0.69368213 Test MSE 6.333373187060134 Test RE 1.2028891285207706\n",
      "114 Train Loss 0.6910747 Test MSE 6.3382274425990355 Test RE 1.2033500213665593\n",
      "115 Train Loss 0.68890417 Test MSE 6.337747479591376 Test RE 1.203304458594066\n",
      "116 Train Loss 0.6858951 Test MSE 6.340136131305677 Test RE 1.203531195655986\n",
      "117 Train Loss 0.68395984 Test MSE 6.346676587232263 Test RE 1.2041518143254515\n",
      "118 Train Loss 0.68227357 Test MSE 6.3510518991849665 Test RE 1.2045668057033583\n",
      "119 Train Loss 0.6806675 Test MSE 6.347473795279675 Test RE 1.2042274388952703\n",
      "120 Train Loss 0.6791281 Test MSE 6.346532978605263 Test RE 1.2041381908514484\n",
      "121 Train Loss 0.67756647 Test MSE 6.3571101014360085 Test RE 1.2051411806277512\n",
      "122 Train Loss 0.6759873 Test MSE 6.352562720655387 Test RE 1.2047100715121886\n",
      "123 Train Loss 0.67441124 Test MSE 6.348575250360268 Test RE 1.2043319170654074\n",
      "124 Train Loss 0.67230237 Test MSE 6.346733122873262 Test RE 1.2041571775531301\n",
      "125 Train Loss 0.67066556 Test MSE 6.3509942783237845 Test RE 1.2045613413853817\n",
      "126 Train Loss 0.66963995 Test MSE 6.355063702820226 Test RE 1.2049471932885207\n",
      "127 Train Loss 0.66852456 Test MSE 6.357884819784782 Test RE 1.2052146115206674\n",
      "128 Train Loss 0.667346 Test MSE 6.361424265010287 Test RE 1.2055500373497972\n",
      "129 Train Loss 0.6658093 Test MSE 6.367595164770975 Test RE 1.2061346175374623\n",
      "130 Train Loss 0.66443336 Test MSE 6.370044438244534 Test RE 1.2063665629914546\n",
      "131 Train Loss 0.6631471 Test MSE 6.369438801422705 Test RE 1.2063092135188458\n",
      "132 Train Loss 0.6617891 Test MSE 6.382036757428655 Test RE 1.2075015888472878\n",
      "133 Train Loss 0.66009617 Test MSE 6.385576985117808 Test RE 1.2078364535664594\n",
      "134 Train Loss 0.65861064 Test MSE 6.397818101483913 Test RE 1.2089936072252805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 Train Loss 0.6564564 Test MSE 6.411929929302348 Test RE 1.2103262265402113\n",
      "136 Train Loss 0.65458024 Test MSE 6.412227317142621 Test RE 1.2103542939187626\n",
      "137 Train Loss 0.65287596 Test MSE 6.42052910114525 Test RE 1.211137551377714\n",
      "138 Train Loss 0.651652 Test MSE 6.424072453841626 Test RE 1.2114717057370392\n",
      "139 Train Loss 0.6503794 Test MSE 6.427604945526188 Test RE 1.2118047441336712\n",
      "140 Train Loss 0.64920396 Test MSE 6.437936799142709 Test RE 1.2127782919852221\n",
      "141 Train Loss 0.64798784 Test MSE 6.437880181970213 Test RE 1.2127729592030851\n",
      "142 Train Loss 0.64665204 Test MSE 6.441095117359334 Test RE 1.213075737442958\n",
      "143 Train Loss 0.6452903 Test MSE 6.445604518869508 Test RE 1.213500299444446\n",
      "144 Train Loss 0.6440634 Test MSE 6.448481575065555 Test RE 1.2137710978651006\n",
      "145 Train Loss 0.6428937 Test MSE 6.4538996648701 Test RE 1.2142809031532458\n",
      "146 Train Loss 0.641791 Test MSE 6.455780321142433 Test RE 1.2144578100449746\n",
      "147 Train Loss 0.640559 Test MSE 6.462221394699852 Test RE 1.2150635045948655\n",
      "148 Train Loss 0.63886786 Test MSE 6.456812908735339 Test RE 1.214554931063922\n",
      "149 Train Loss 0.6377456 Test MSE 6.462407138367151 Test RE 1.215080966758093\n",
      "Training time: 229.74\n",
      "6\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 64.10421 Test MSE 6.154386379333802 Test RE 1.1857699479108572\n",
      "1 Train Loss 43.72258 Test MSE 9.11544366860076 Test RE 1.443101792271368\n",
      "2 Train Loss 38.814346 Test MSE 8.73442716694383 Test RE 1.4126197509178704\n",
      "3 Train Loss 33.579655 Test MSE 7.816638869676543 Test RE 1.3363434343459104\n",
      "4 Train Loss 31.241854 Test MSE 8.002033674517287 Test RE 1.3520982404159174\n",
      "5 Train Loss 30.128834 Test MSE 8.139114097555149 Test RE 1.363630255644569\n",
      "6 Train Loss 28.816872 Test MSE 8.48388543658655 Test RE 1.3922122729734432\n",
      "7 Train Loss 27.312843 Test MSE 8.492348588391142 Test RE 1.3929065048166216\n",
      "8 Train Loss 25.707804 Test MSE 8.450239127692358 Test RE 1.3894488374921279\n",
      "9 Train Loss 23.871342 Test MSE 8.864990826519158 Test RE 1.423138623917235\n",
      "10 Train Loss 22.516987 Test MSE 8.908385784286079 Test RE 1.4266175698903316\n",
      "11 Train Loss 21.38075 Test MSE 9.119207561546004 Test RE 1.443399699880934\n",
      "12 Train Loss 20.106567 Test MSE 8.904082592526485 Test RE 1.4262729647811678\n",
      "13 Train Loss 18.890146 Test MSE 8.919783169966252 Test RE 1.4275298851914933\n",
      "14 Train Loss 17.845268 Test MSE 8.928300171038813 Test RE 1.428211256722783\n",
      "15 Train Loss 17.096458 Test MSE 8.635690082597318 Test RE 1.4046126787993862\n",
      "16 Train Loss 16.32861 Test MSE 8.540910118208037 Test RE 1.396883334502925\n",
      "17 Train Loss 14.991343 Test MSE 8.406104721534339 Test RE 1.3858156397877386\n",
      "18 Train Loss 13.652935 Test MSE 8.19738326827296 Test RE 1.368502769882608\n",
      "19 Train Loss 12.0283165 Test MSE 7.8801224844289175 Test RE 1.3417590841081386\n",
      "20 Train Loss 9.966814 Test MSE 7.1264021506302555 Test RE 1.2759781087179578\n",
      "21 Train Loss 9.169603 Test MSE 6.807349140218129 Test RE 1.2470879218596242\n",
      "22 Train Loss 7.8167124 Test MSE 6.622407960261513 Test RE 1.2300309118848123\n",
      "23 Train Loss 6.891446 Test MSE 6.397302002418223 Test RE 1.2089448427054763\n",
      "24 Train Loss 5.565121 Test MSE 5.87377724050476 Test RE 1.158421998877095\n",
      "25 Train Loss 4.4723034 Test MSE 5.545057453431027 Test RE 1.1255403930377341\n",
      "26 Train Loss 3.8873343 Test MSE 5.5318471920616945 Test RE 1.124198878629595\n",
      "27 Train Loss 3.2264543 Test MSE 5.502673278568453 Test RE 1.1212305539673193\n",
      "28 Train Loss 2.9021223 Test MSE 5.621097498225077 Test RE 1.1332314516123183\n",
      "29 Train Loss 2.742139 Test MSE 5.519841664462528 Test RE 1.1229783160467968\n",
      "30 Train Loss 2.545313 Test MSE 5.613575463303878 Test RE 1.1324729644846854\n",
      "31 Train Loss 2.3640237 Test MSE 5.607984788592093 Test RE 1.1319088975049145\n",
      "32 Train Loss 2.230988 Test MSE 5.551316264856133 Test RE 1.1261754232807648\n",
      "33 Train Loss 2.140938 Test MSE 5.597505861344991 Test RE 1.130850875997023\n",
      "34 Train Loss 2.0326185 Test MSE 5.555474976990607 Test RE 1.1265971757414053\n",
      "35 Train Loss 1.952364 Test MSE 5.542937111531604 Test RE 1.1253251780772617\n",
      "36 Train Loss 1.8718991 Test MSE 5.498292072300613 Test RE 1.1207841054623615\n",
      "37 Train Loss 1.8304818 Test MSE 5.509460706737671 Test RE 1.121921847646859\n",
      "38 Train Loss 1.7748992 Test MSE 5.5686150747917305 Test RE 1.1279287319009441\n",
      "39 Train Loss 1.7567917 Test MSE 5.569762343204192 Test RE 1.1280449161177046\n",
      "40 Train Loss 1.7302651 Test MSE 5.5726026705168135 Test RE 1.128332505445207\n",
      "41 Train Loss 1.7039304 Test MSE 5.613212068380963 Test RE 1.132436308561137\n",
      "42 Train Loss 1.6913204 Test MSE 5.564401150120554 Test RE 1.1275018837376176\n",
      "43 Train Loss 1.6748286 Test MSE 5.561074342602788 Test RE 1.1271647816431938\n",
      "44 Train Loss 1.6596687 Test MSE 5.577771575155152 Test RE 1.12885568031148\n",
      "45 Train Loss 1.6346786 Test MSE 5.556396036656674 Test RE 1.1266905629150474\n",
      "46 Train Loss 1.6091802 Test MSE 5.600516243735085 Test RE 1.131154925341174\n",
      "47 Train Loss 1.5950618 Test MSE 5.579877383565362 Test RE 1.1290687519145988\n",
      "48 Train Loss 1.5801314 Test MSE 5.605838986059241 Test RE 1.1316923236860343\n",
      "49 Train Loss 1.564245 Test MSE 5.590839340993711 Test RE 1.1301772646997288\n",
      "50 Train Loss 1.5510767 Test MSE 5.61422395984748 Test RE 1.1325383758788201\n",
      "51 Train Loss 1.5367154 Test MSE 5.594420467269012 Test RE 1.130539165601264\n",
      "52 Train Loss 1.5215801 Test MSE 5.607500155595229 Test RE 1.1318599875779272\n",
      "53 Train Loss 1.5094466 Test MSE 5.602405764309624 Test RE 1.1313457256322608\n",
      "54 Train Loss 1.4848295 Test MSE 5.591786217343797 Test RE 1.1302729652512662\n",
      "55 Train Loss 1.462208 Test MSE 5.583157317587721 Test RE 1.1294005447757185\n",
      "56 Train Loss 1.4452984 Test MSE 5.610037733531927 Test RE 1.1321160605147484\n",
      "57 Train Loss 1.4307001 Test MSE 5.624424433972463 Test RE 1.1335667625130117\n",
      "58 Train Loss 1.4147917 Test MSE 5.638534813308756 Test RE 1.1349878001498253\n",
      "59 Train Loss 1.4021473 Test MSE 5.649057763713058 Test RE 1.1360463954719189\n",
      "60 Train Loss 1.3931439 Test MSE 5.673285891908928 Test RE 1.1384799719988317\n",
      "61 Train Loss 1.3839424 Test MSE 5.683732664160188 Test RE 1.139527686771609\n",
      "62 Train Loss 1.37318 Test MSE 5.683185549123287 Test RE 1.1394728400913265\n",
      "63 Train Loss 1.3576562 Test MSE 5.702316423765718 Test RE 1.1413890891310163\n",
      "64 Train Loss 1.3360732 Test MSE 5.747584268779355 Test RE 1.145910592630488\n",
      "65 Train Loss 1.3202243 Test MSE 5.767392646394512 Test RE 1.1478835177113385\n",
      "66 Train Loss 1.3090521 Test MSE 5.8171288868181446 Test RE 1.1528223919345983\n",
      "67 Train Loss 1.2974882 Test MSE 5.842336593231544 Test RE 1.1553174883244077\n",
      "68 Train Loss 1.2844955 Test MSE 5.8626129100597595 Test RE 1.1573205647596614\n",
      "69 Train Loss 1.2701818 Test MSE 5.867974303890317 Test RE 1.1578496320446854\n",
      "70 Train Loss 1.2578776 Test MSE 5.856882036551541 Test RE 1.1567547693102302\n",
      "71 Train Loss 1.2499771 Test MSE 5.865993772698102 Test RE 1.1576542195633093\n",
      "72 Train Loss 1.2421021 Test MSE 5.885279970734329 Test RE 1.1595557240697092\n",
      "73 Train Loss 1.2340566 Test MSE 5.885351009747913 Test RE 1.1595627223303422\n",
      "74 Train Loss 1.2260302 Test MSE 5.882186526007504 Test RE 1.1592509388226144\n",
      "75 Train Loss 1.2193836 Test MSE 5.910159142659066 Test RE 1.1620040665539724\n",
      "76 Train Loss 1.2112535 Test MSE 5.918993032865632 Test RE 1.1628721636043682\n",
      "77 Train Loss 1.2043551 Test MSE 5.938643992533415 Test RE 1.164800922312344\n",
      "78 Train Loss 1.1969163 Test MSE 5.957040688429513 Test RE 1.1666036839165144\n",
      "79 Train Loss 1.1867071 Test MSE 5.961358248825047 Test RE 1.1670263744599958\n",
      "80 Train Loss 1.1775852 Test MSE 5.95348708905683 Test RE 1.166255670466663\n",
      "81 Train Loss 1.1665378 Test MSE 5.947697848270996 Test RE 1.165688492192967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 Train Loss 1.1607174 Test MSE 5.950317895798646 Test RE 1.165945215302777\n",
      "83 Train Loss 1.1569872 Test MSE 5.963025078693645 Test RE 1.1671895166820818\n",
      "84 Train Loss 1.1484877 Test MSE 5.9811765696655455 Test RE 1.1689646334582653\n",
      "85 Train Loss 1.1372759 Test MSE 5.9683020681603605 Test RE 1.1677058556750834\n",
      "86 Train Loss 1.1333406 Test MSE 5.978538401520988 Test RE 1.16870680246461\n",
      "87 Train Loss 1.1287115 Test MSE 5.999698854313939 Test RE 1.1707732373877666\n",
      "88 Train Loss 1.1261446 Test MSE 6.008148870432177 Test RE 1.1715974097385167\n",
      "89 Train Loss 1.1213361 Test MSE 5.99365645468036 Test RE 1.1701835359704926\n",
      "90 Train Loss 1.1171241 Test MSE 5.98298299113987 Test RE 1.169141144164619\n",
      "91 Train Loss 1.1120908 Test MSE 5.97321921117817 Test RE 1.16818677926842\n",
      "92 Train Loss 1.1064496 Test MSE 5.973365693487479 Test RE 1.1682011030059227\n",
      "93 Train Loss 1.1003541 Test MSE 5.982405090171061 Test RE 1.1690846786759979\n",
      "94 Train Loss 1.0928246 Test MSE 6.001060348338544 Test RE 1.1709060699169778\n",
      "95 Train Loss 1.0888195 Test MSE 6.013015613924045 Test RE 1.1720718245705974\n",
      "96 Train Loss 1.0837576 Test MSE 6.03682312232788 Test RE 1.174389841499048\n",
      "97 Train Loss 1.079623 Test MSE 6.048110465088216 Test RE 1.1754872357713675\n",
      "98 Train Loss 1.0729963 Test MSE 6.045830605534568 Test RE 1.1752656625691391\n",
      "99 Train Loss 1.068655 Test MSE 6.045719175715848 Test RE 1.1752548319445562\n",
      "100 Train Loss 1.0645673 Test MSE 6.059492453094389 Test RE 1.1765927953441124\n",
      "101 Train Loss 1.0590196 Test MSE 6.085286302010881 Test RE 1.1790943768368947\n",
      "102 Train Loss 1.0536622 Test MSE 6.07639506177268 Test RE 1.1782326718109508\n",
      "103 Train Loss 1.0490186 Test MSE 6.087813149702978 Test RE 1.1793391543651286\n",
      "104 Train Loss 1.0441611 Test MSE 6.092573241238568 Test RE 1.1798001298632148\n",
      "105 Train Loss 1.036872 Test MSE 6.1081854758982255 Test RE 1.181310783158465\n",
      "106 Train Loss 1.0319178 Test MSE 6.122695183421574 Test RE 1.1827130250353601\n",
      "107 Train Loss 1.0278025 Test MSE 6.119086498389697 Test RE 1.182364431177754\n",
      "108 Train Loss 1.0241092 Test MSE 6.1281013315143245 Test RE 1.1832350591059506\n",
      "109 Train Loss 1.0203586 Test MSE 6.130470403837326 Test RE 1.1834637513558368\n",
      "110 Train Loss 1.0166106 Test MSE 6.1479070293688345 Test RE 1.185145593081947\n",
      "111 Train Loss 1.0105689 Test MSE 6.14523001504798 Test RE 1.1848875380108481\n",
      "112 Train Loss 1.0047531 Test MSE 6.144338987107779 Test RE 1.1848016334822271\n",
      "113 Train Loss 1.0007497 Test MSE 6.121030421560095 Test RE 1.1825522241678625\n",
      "114 Train Loss 0.9961238 Test MSE 6.121119193451634 Test RE 1.182560799277766\n",
      "115 Train Loss 0.9898461 Test MSE 6.140955062282419 Test RE 1.184475330535935\n",
      "116 Train Loss 0.9863842 Test MSE 6.1541959987989365 Test RE 1.18575160739331\n",
      "117 Train Loss 0.98217905 Test MSE 6.17376640480974 Test RE 1.1876354620122598\n",
      "118 Train Loss 0.9774636 Test MSE 6.1782775547129 Test RE 1.1880692833548845\n",
      "119 Train Loss 0.97305083 Test MSE 6.181514913003841 Test RE 1.188380511055389\n",
      "120 Train Loss 0.9692624 Test MSE 6.1810781996441655 Test RE 1.18833853179792\n",
      "121 Train Loss 0.9661977 Test MSE 6.182187265228664 Test RE 1.1884451383001864\n",
      "122 Train Loss 0.9627743 Test MSE 6.195987433024616 Test RE 1.1897708503173614\n",
      "123 Train Loss 0.9594295 Test MSE 6.196037607868708 Test RE 1.1897756676646134\n",
      "124 Train Loss 0.95657384 Test MSE 6.205020022614905 Test RE 1.1906377660505192\n",
      "125 Train Loss 0.9527229 Test MSE 6.199132506748397 Test RE 1.1900727749380724\n",
      "126 Train Loss 0.9487819 Test MSE 6.187645130591953 Test RE 1.1889696244008805\n",
      "127 Train Loss 0.9453252 Test MSE 6.19938138731969 Test RE 1.1900966640079584\n",
      "128 Train Loss 0.94106704 Test MSE 6.203264922490736 Test RE 1.190469367216005\n",
      "129 Train Loss 0.93735033 Test MSE 6.226419370069886 Test RE 1.1926890843066107\n",
      "130 Train Loss 0.9338031 Test MSE 6.2316527674975575 Test RE 1.1931902154207552\n",
      "131 Train Loss 0.93083656 Test MSE 6.239169802422217 Test RE 1.1939096513118592\n",
      "132 Train Loss 0.92641366 Test MSE 6.249124984861138 Test RE 1.1948617692542853\n",
      "133 Train Loss 0.92302436 Test MSE 6.233072213550559 Test RE 1.1933261001346447\n",
      "134 Train Loss 0.9212933 Test MSE 6.2292586393747795 Test RE 1.1929609885380341\n",
      "135 Train Loss 0.91884685 Test MSE 6.227434875912913 Test RE 1.1927863419181863\n",
      "136 Train Loss 0.91597545 Test MSE 6.218529318743592 Test RE 1.1919331633988854\n",
      "137 Train Loss 0.91429055 Test MSE 6.213790766607411 Test RE 1.1914789471753409\n",
      "138 Train Loss 0.91216266 Test MSE 6.222286928889252 Test RE 1.1922932279357947\n",
      "139 Train Loss 0.9087773 Test MSE 6.209908612204137 Test RE 1.191106692290737\n",
      "140 Train Loss 0.9058394 Test MSE 6.218970472739714 Test RE 1.1919754416230244\n",
      "141 Train Loss 0.9027319 Test MSE 6.217603060760615 Test RE 1.1918443901000717\n",
      "142 Train Loss 0.8998052 Test MSE 6.229357321942975 Test RE 1.1929704378156034\n",
      "143 Train Loss 0.8959665 Test MSE 6.246805836643033 Test RE 1.1946400327156845\n",
      "144 Train Loss 0.89352894 Test MSE 6.242597934240231 Test RE 1.1942376050089079\n",
      "145 Train Loss 0.89233804 Test MSE 6.2398589190610085 Test RE 1.193975583183826\n",
      "146 Train Loss 0.89063793 Test MSE 6.232204440453041 Test RE 1.1932430293554737\n",
      "147 Train Loss 0.8877976 Test MSE 6.239406764249861 Test RE 1.1939323232646832\n",
      "148 Train Loss 0.8859597 Test MSE 6.228772846409917 Test RE 1.1929144706947097\n",
      "149 Train Loss 0.88345605 Test MSE 6.2314187199742985 Test RE 1.1931678083766455\n",
      "Training time: 232.07\n",
      "7\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "1 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "2 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "3 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "4 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "5 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "6 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "7 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "8 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "9 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "10 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "11 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "12 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "13 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "14 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "15 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "16 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "17 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "18 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "19 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "20 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "21 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "22 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "23 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "24 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "25 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "26 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "27 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "29 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "30 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "31 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "32 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "33 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "34 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "35 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "36 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "37 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "38 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "39 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "40 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "41 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "42 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "43 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "44 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "45 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "46 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "47 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "48 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "49 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "50 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "51 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "52 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "53 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "54 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "55 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "56 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "57 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "58 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "59 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "60 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "61 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "62 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "63 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "64 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "65 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "66 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "67 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "68 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "69 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "70 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "71 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "72 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "73 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "74 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "75 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "76 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "77 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "78 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "79 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "80 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "81 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "82 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "83 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "84 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "85 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "86 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "87 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "88 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "89 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "90 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "91 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "92 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "93 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "94 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "95 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "96 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "97 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "98 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "99 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "100 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "101 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "102 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "103 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "104 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "105 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "106 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "107 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "108 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "109 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "110 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "111 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "112 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "113 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "114 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "115 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "116 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "117 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "118 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "119 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "120 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "121 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "122 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "123 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "124 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "125 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "126 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "127 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "128 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "129 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "130 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "131 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "132 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "134 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "135 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "136 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "137 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "138 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "139 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "140 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "141 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "142 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "143 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "144 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "145 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "146 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "147 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "148 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "149 Train Loss 65.57034 Test MSE 5.3180648045185315 Test RE 1.1022620947516855\n",
      "Training time: 134.81\n",
      "8\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 61.19029 Test MSE 5.850173322607432 Test RE 1.1560920822074034\n",
      "1 Train Loss 37.00287 Test MSE 7.163847568141518 Test RE 1.2793260066063\n",
      "2 Train Loss 26.010073 Test MSE 8.001357144330745 Test RE 1.3520410827828162\n",
      "3 Train Loss 21.221245 Test MSE 8.646199945908783 Test RE 1.405467144298154\n",
      "4 Train Loss 17.352413 Test MSE 8.530763857900208 Test RE 1.3960533671154267\n",
      "5 Train Loss 14.57513 Test MSE 8.279102423532771 Test RE 1.3753071093712874\n",
      "6 Train Loss 12.373364 Test MSE 7.889817392610582 Test RE 1.3425842129435959\n",
      "7 Train Loss 10.557688 Test MSE 7.584667600599736 Test RE 1.316365030128558\n",
      "8 Train Loss 8.88077 Test MSE 7.334681358338289 Test RE 1.2944899587978564\n",
      "9 Train Loss 7.2355633 Test MSE 6.988028671857987 Test RE 1.2635295390274557\n",
      "10 Train Loss 5.940522 Test MSE 6.56299292373472 Test RE 1.2245006733509534\n",
      "11 Train Loss 5.223525 Test MSE 6.506287204980113 Test RE 1.219199217969489\n",
      "12 Train Loss 4.6980205 Test MSE 6.309331864471118 Test RE 1.2006038896027271\n",
      "13 Train Loss 4.2222524 Test MSE 6.162811067263775 Test RE 1.1865812656257242\n",
      "14 Train Loss 3.8007674 Test MSE 5.8922401183727295 Test RE 1.1602411879995806\n",
      "15 Train Loss 3.4238055 Test MSE 5.7152332362078715 Test RE 1.1426810876945153\n",
      "16 Train Loss 3.1265974 Test MSE 5.781992129988069 Test RE 1.1493354662312885\n",
      "17 Train Loss 2.8494244 Test MSE 5.522286511839516 Test RE 1.1232269832019715\n",
      "18 Train Loss 2.6504676 Test MSE 5.496914352261463 Test RE 1.120643677903918\n",
      "19 Train Loss 2.5066037 Test MSE 5.412852926050739 Test RE 1.112041958005518\n",
      "20 Train Loss 2.3325646 Test MSE 5.385819401550804 Test RE 1.1092615348822306\n",
      "21 Train Loss 2.2223341 Test MSE 5.348070093234745 Test RE 1.105367281799753\n",
      "22 Train Loss 2.0909417 Test MSE 5.2302466273384995 Test RE 1.0931232821524455\n",
      "23 Train Loss 1.9972016 Test MSE 5.114049249146718 Test RE 1.080912435574272\n",
      "24 Train Loss 1.8733914 Test MSE 4.960558862156059 Test RE 1.0645678932289986\n",
      "25 Train Loss 1.7710013 Test MSE 4.772391805215229 Test RE 1.044181768031044\n",
      "26 Train Loss 1.6889646 Test MSE 4.775768182021442 Test RE 1.0445510721349653\n",
      "27 Train Loss 1.5886815 Test MSE 4.6682404059606375 Test RE 1.032724944079402\n",
      "28 Train Loss 1.5155787 Test MSE 4.563049132575654 Test RE 1.0210232527526313\n",
      "29 Train Loss 1.4295012 Test MSE 4.390776641261697 Test RE 1.0015640619817419\n",
      "30 Train Loss 1.3568892 Test MSE 4.22044317345567 Test RE 0.9819448320669635\n",
      "31 Train Loss 1.2832397 Test MSE 4.108769009918373 Test RE 0.968866463653037\n",
      "32 Train Loss 1.2035036 Test MSE 3.904705946364679 Test RE 0.9445005761651957\n",
      "33 Train Loss 1.1144419 Test MSE 3.6824509460581765 Test RE 0.917226398207065\n",
      "34 Train Loss 1.0405684 Test MSE 3.5234185350868974 Test RE 0.8972018854991113\n",
      "35 Train Loss 0.9771935 Test MSE 3.5056431051419823 Test RE 0.8949358597119793\n",
      "36 Train Loss 0.92022204 Test MSE 3.4545034782402477 Test RE 0.8883843052530629\n",
      "37 Train Loss 0.87663954 Test MSE 3.3782874794064934 Test RE 0.8785295261092078\n",
      "38 Train Loss 0.8319844 Test MSE 3.3810751617290764 Test RE 0.8788919221791589\n",
      "39 Train Loss 0.8006613 Test MSE 3.31919333309442 Test RE 0.8708118595155604\n",
      "40 Train Loss 0.7672401 Test MSE 3.2960046638917895 Test RE 0.8677646793626149\n",
      "41 Train Loss 0.74820065 Test MSE 3.3395157345859094 Test RE 0.8734736482039523\n",
      "42 Train Loss 0.73485076 Test MSE 3.3511348403234194 Test RE 0.8749918578820199\n",
      "43 Train Loss 0.7208431 Test MSE 3.3436299723539693 Test RE 0.8740115363887999\n",
      "44 Train Loss 0.7080779 Test MSE 3.325873222128787 Test RE 0.8716876751584763\n",
      "45 Train Loss 0.70098126 Test MSE 3.314911690252859 Test RE 0.8702500199092528\n",
      "46 Train Loss 0.691866 Test MSE 3.3166414345388824 Test RE 0.8704770415950267\n",
      "47 Train Loss 0.68375546 Test MSE 3.3096156502446292 Test RE 0.869554568316678\n",
      "48 Train Loss 0.67726195 Test MSE 3.294111253265336 Test RE 0.8675153971158541\n",
      "49 Train Loss 0.6679218 Test MSE 3.3138558019154902 Test RE 0.8701114098772713\n",
      "50 Train Loss 0.65841305 Test MSE 3.2835872256299417 Test RE 0.8661285193028183\n",
      "51 Train Loss 0.6497748 Test MSE 3.299438725057403 Test RE 0.8682166176182156\n",
      "52 Train Loss 0.6432495 Test MSE 3.3170241173150914 Test RE 0.8705272591070892\n",
      "53 Train Loss 0.6343359 Test MSE 3.33543007685951 Test RE 0.8729391685326523\n",
      "54 Train Loss 0.6271065 Test MSE 3.3449667429169554 Test RE 0.8741862321761311\n",
      "55 Train Loss 0.61900544 Test MSE 3.3763362715945786 Test RE 0.8782757819748918\n",
      "56 Train Loss 0.6130057 Test MSE 3.378408111592229 Test RE 0.8785452112738888\n",
      "57 Train Loss 0.606017 Test MSE 3.402490698138882 Test RE 0.8816709541146407\n",
      "58 Train Loss 0.6007122 Test MSE 3.403458941674113 Test RE 0.8817963933228151\n",
      "59 Train Loss 0.5956829 Test MSE 3.3958295128545974 Test RE 0.8808074909402439\n",
      "60 Train Loss 0.5902604 Test MSE 3.3939814415672966 Test RE 0.8805677827104023\n",
      "61 Train Loss 0.58381253 Test MSE 3.3823621288463923 Test RE 0.8790591762824236\n",
      "62 Train Loss 0.5789288 Test MSE 3.386705792195131 Test RE 0.8796234434838346\n",
      "63 Train Loss 0.5724987 Test MSE 3.394433562797909 Test RE 0.8806264321371196\n",
      "64 Train Loss 0.568143 Test MSE 3.422438426556042 Test RE 0.8842516563627559\n",
      "65 Train Loss 0.56365484 Test MSE 3.440856127372561 Test RE 0.8866277445117638\n",
      "66 Train Loss 0.5585922 Test MSE 3.471696639992008 Test RE 0.8905923182642976\n",
      "67 Train Loss 0.5535894 Test MSE 3.474507224882206 Test RE 0.890952744184417\n",
      "68 Train Loss 0.5486051 Test MSE 3.486560871627718 Test RE 0.8924968382135715\n",
      "69 Train Loss 0.54280984 Test MSE 3.507844533934388 Test RE 0.89521681078308\n",
      "70 Train Loss 0.53766775 Test MSE 3.533355897525953 Test RE 0.898466217651008\n",
      "71 Train Loss 0.53346944 Test MSE 3.5396067593296854 Test RE 0.8992606050010239\n",
      "72 Train Loss 0.528358 Test MSE 3.5571744333657107 Test RE 0.9014894350387765\n",
      "73 Train Loss 0.5239047 Test MSE 3.570616347720711 Test RE 0.9031911111719275\n",
      "74 Train Loss 0.52058005 Test MSE 3.5872957246375705 Test RE 0.9052981862018553\n",
      "75 Train Loss 0.51782006 Test MSE 3.583149713730316 Test RE 0.9047748865411669\n",
      "76 Train Loss 0.5148682 Test MSE 3.5860917963946757 Test RE 0.9051462604059589\n",
      "77 Train Loss 0.5100469 Test MSE 3.602628888929188 Test RE 0.907230879452458\n",
      "78 Train Loss 0.50733244 Test MSE 3.604828904017792 Test RE 0.9075078462267393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 Train Loss 0.50357276 Test MSE 3.597462313056041 Test RE 0.9065801103828747\n",
      "80 Train Loss 0.49833894 Test MSE 3.607444628515276 Test RE 0.9078370380009961\n",
      "81 Train Loss 0.4947621 Test MSE 3.629889775870763 Test RE 0.9106568926672558\n",
      "82 Train Loss 0.49071288 Test MSE 3.6244946958151387 Test RE 0.9099798894984471\n",
      "83 Train Loss 0.48703733 Test MSE 3.6191567749126534 Test RE 0.909309562899131\n",
      "84 Train Loss 0.48383093 Test MSE 3.6120891175599485 Test RE 0.9084212580439912\n",
      "85 Train Loss 0.48065734 Test MSE 3.6096525189877466 Test RE 0.9081148105456035\n",
      "86 Train Loss 0.47897887 Test MSE 3.612120624933585 Test RE 0.9084252200040441\n",
      "87 Train Loss 0.47639093 Test MSE 3.624987336146157 Test RE 0.9100417295064595\n",
      "88 Train Loss 0.47445613 Test MSE 3.633312927807337 Test RE 0.9110861870124545\n",
      "89 Train Loss 0.4730028 Test MSE 3.627161856832208 Test RE 0.9103146418921005\n",
      "90 Train Loss 0.4715103 Test MSE 3.6294307917018025 Test RE 0.9105993164959955\n",
      "91 Train Loss 0.47038317 Test MSE 3.6291235122433245 Test RE 0.9105607685247643\n",
      "92 Train Loss 0.46872717 Test MSE 3.645359399173993 Test RE 0.9125953181486675\n",
      "93 Train Loss 0.46675658 Test MSE 3.643634066498504 Test RE 0.9123793289006713\n",
      "94 Train Loss 0.4650334 Test MSE 3.641573379205695 Test RE 0.91212129058498\n",
      "95 Train Loss 0.4627162 Test MSE 3.6417937124954385 Test RE 0.9121488841034722\n",
      "96 Train Loss 0.4614234 Test MSE 3.6397136995295662 Test RE 0.9118883596694511\n",
      "97 Train Loss 0.45958182 Test MSE 3.6487152098741005 Test RE 0.9130152757318926\n",
      "98 Train Loss 0.45830783 Test MSE 3.6555895023461438 Test RE 0.9138749455410666\n",
      "99 Train Loss 0.4570903 Test MSE 3.6642013426920137 Test RE 0.9149507659320543\n",
      "100 Train Loss 0.45563886 Test MSE 3.6663364665970857 Test RE 0.9152172972402962\n",
      "101 Train Loss 0.45427173 Test MSE 3.6688119971944664 Test RE 0.9155262249843387\n",
      "102 Train Loss 0.45272008 Test MSE 3.6711031644412686 Test RE 0.9158120527009715\n",
      "103 Train Loss 0.45027527 Test MSE 3.6887349712538637 Test RE 0.9180086784050027\n",
      "104 Train Loss 0.4482405 Test MSE 3.680385403967775 Test RE 0.9169691190868029\n",
      "105 Train Loss 0.44548574 Test MSE 3.7022572137192946 Test RE 0.9196897669604704\n",
      "106 Train Loss 0.44336072 Test MSE 3.7118694018323715 Test RE 0.9208828905049571\n",
      "107 Train Loss 0.44088706 Test MSE 3.726015596704925 Test RE 0.922635996462828\n",
      "108 Train Loss 0.43858808 Test MSE 3.7414525798774365 Test RE 0.9245452738763235\n",
      "109 Train Loss 0.43591556 Test MSE 3.7555768073915647 Test RE 0.9262887393571156\n",
      "110 Train Loss 0.4333446 Test MSE 3.768561813563838 Test RE 0.9278886914927598\n",
      "111 Train Loss 0.43069077 Test MSE 3.763315008577183 Test RE 0.9272425369425095\n",
      "112 Train Loss 0.42808878 Test MSE 3.7736494705935395 Test RE 0.9285148172455241\n",
      "113 Train Loss 0.42520225 Test MSE 3.7885983452656578 Test RE 0.9303521013719926\n",
      "114 Train Loss 0.42250842 Test MSE 3.7963790802604125 Test RE 0.9313069545483877\n",
      "115 Train Loss 0.4201519 Test MSE 3.8127562442601217 Test RE 0.9333135709513183\n",
      "116 Train Loss 0.4188054 Test MSE 3.8042011525756942 Test RE 0.932265894853339\n",
      "117 Train Loss 0.4168614 Test MSE 3.8085312882122766 Test RE 0.9327963202346347\n",
      "118 Train Loss 0.41463006 Test MSE 3.83022974194948 Test RE 0.9354497697251247\n",
      "119 Train Loss 0.41179696 Test MSE 3.826884737991859 Test RE 0.9350412085079854\n",
      "120 Train Loss 0.40932626 Test MSE 3.840264206051358 Test RE 0.9366743173299121\n",
      "121 Train Loss 0.40710494 Test MSE 3.844118646053025 Test RE 0.9371442653982499\n",
      "122 Train Loss 0.4046412 Test MSE 3.8641153174135234 Test RE 0.9395785631216051\n",
      "123 Train Loss 0.40208355 Test MSE 3.8779495634551004 Test RE 0.9412589927410169\n",
      "124 Train Loss 0.39859903 Test MSE 3.8923314126929607 Test RE 0.9430027644146584\n",
      "125 Train Loss 0.39607045 Test MSE 3.900204699894035 Test RE 0.9439560209688008\n",
      "126 Train Loss 0.3936722 Test MSE 3.9087080512069625 Test RE 0.9449844822912634\n",
      "127 Train Loss 0.39188123 Test MSE 3.9156477807946657 Test RE 0.9458229982969264\n",
      "128 Train Loss 0.38972953 Test MSE 3.929439180775358 Test RE 0.9474871875125414\n",
      "129 Train Loss 0.3881607 Test MSE 3.9410470223519103 Test RE 0.9488856276222519\n",
      "130 Train Loss 0.38599953 Test MSE 3.9544809688047318 Test RE 0.9505014969739187\n",
      "131 Train Loss 0.38270217 Test MSE 3.967731775889967 Test RE 0.9520926512678697\n",
      "132 Train Loss 0.3800584 Test MSE 3.966527698265298 Test RE 0.9519481757199685\n",
      "133 Train Loss 0.37789273 Test MSE 3.9772289538825327 Test RE 0.9532314365353474\n",
      "134 Train Loss 0.3754912 Test MSE 3.9865796236768114 Test RE 0.9543513267548783\n",
      "135 Train Loss 0.3738671 Test MSE 4.0081967629567705 Test RE 0.9569353030163399\n",
      "136 Train Loss 0.371772 Test MSE 4.013678137435629 Test RE 0.9575894037235885\n",
      "137 Train Loss 0.37045413 Test MSE 4.019607949259463 Test RE 0.9582965143875983\n",
      "138 Train Loss 0.36878765 Test MSE 4.029222037978556 Test RE 0.9594418556008381\n",
      "139 Train Loss 0.36680403 Test MSE 4.036792749530775 Test RE 0.9603428047988087\n",
      "140 Train Loss 0.36549547 Test MSE 4.041600037121149 Test RE 0.9609144554505346\n",
      "141 Train Loss 0.36407423 Test MSE 4.037090400117033 Test RE 0.9603782093077347\n",
      "142 Train Loss 0.36245942 Test MSE 4.047087128354479 Test RE 0.9615665284971894\n",
      "143 Train Loss 0.36083224 Test MSE 4.053525305834854 Test RE 0.9623310630435006\n",
      "144 Train Loss 0.3595706 Test MSE 4.055985179902662 Test RE 0.9626230131390688\n",
      "145 Train Loss 0.3579794 Test MSE 4.063544432803153 Test RE 0.9635196292736207\n",
      "146 Train Loss 0.35626468 Test MSE 4.074219152406914 Test RE 0.9647843571687775\n",
      "147 Train Loss 0.35509524 Test MSE 4.076621364901844 Test RE 0.9650687399458724\n",
      "148 Train Loss 0.35318983 Test MSE 4.087637049558548 Test RE 0.9663717455542604\n",
      "149 Train Loss 0.3511114 Test MSE 4.100077566323259 Test RE 0.9678411801489822\n",
      "Training time: 229.95\n",
      "9\n",
      "KG_rowdy_tune66\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 62.060623 Test MSE 7.75408321634966 Test RE 1.3309853921899375\n",
      "1 Train Loss 48.286858 Test MSE 9.311758960400072 Test RE 1.458558736799487\n",
      "2 Train Loss 40.783573 Test MSE 8.614007192314185 Test RE 1.402848187254733\n",
      "3 Train Loss 36.461098 Test MSE 8.729403078248135 Test RE 1.4122134193029807\n",
      "4 Train Loss 32.74727 Test MSE 8.95503860855418 Test RE 1.4303482586172191\n",
      "5 Train Loss 29.148163 Test MSE 8.810548667766971 Test RE 1.4187619662742494\n",
      "6 Train Loss 26.488846 Test MSE 8.397652756720474 Test RE 1.3851187765504545\n",
      "7 Train Loss 24.056808 Test MSE 8.45004586082973 Test RE 1.389432948240416\n",
      "8 Train Loss 21.919647 Test MSE 8.49749197458675 Test RE 1.3933282474938993\n",
      "9 Train Loss 20.208927 Test MSE 8.305020447463917 Test RE 1.377458151063876\n",
      "10 Train Loss 18.862995 Test MSE 8.374654129078246 Test RE 1.3832207657198157\n",
      "11 Train Loss 16.736862 Test MSE 7.948721611390769 Test RE 1.3475866617698007\n",
      "12 Train Loss 14.997082 Test MSE 7.829274040675437 Test RE 1.3374230614212634\n",
      "13 Train Loss 13.160498 Test MSE 7.369884926046123 Test RE 1.2975927599441115\n",
      "14 Train Loss 11.899839 Test MSE 6.729177069329024 Test RE 1.2399067904207637\n",
      "15 Train Loss 9.747983 Test MSE 6.486220877519518 Test RE 1.2173176730574464\n",
      "16 Train Loss 7.3376436 Test MSE 5.62511256118807 Test RE 1.1336361042111642\n",
      "17 Train Loss 5.924306 Test MSE 5.39482732290818 Test RE 1.1101887815450477\n",
      "18 Train Loss 4.591915 Test MSE 5.048369950235815 Test RE 1.0739489723625777\n",
      "19 Train Loss 3.6855497 Test MSE 5.0362443708149485 Test RE 1.0726584486326802\n",
      "20 Train Loss 3.0958538 Test MSE 5.082768409044949 Test RE 1.0776015844324587\n",
      "21 Train Loss 2.7528932 Test MSE 5.229072408373453 Test RE 1.093000569187791\n",
      "22 Train Loss 2.4727254 Test MSE 5.200939476419246 Test RE 1.0900563777081942\n",
      "23 Train Loss 2.2598152 Test MSE 5.225145820047054 Test RE 1.0925901169191705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Train Loss 2.1541598 Test MSE 5.240072151670011 Test RE 1.0941495693079126\n",
      "25 Train Loss 2.0710795 Test MSE 5.223665393469536 Test RE 1.0924353256377584\n",
      "26 Train Loss 2.0033748 Test MSE 5.165695975021657 Test RE 1.0863567857640941\n",
      "27 Train Loss 1.9425902 Test MSE 5.1701731335225 Test RE 1.0868274617508877\n",
      "28 Train Loss 1.867192 Test MSE 5.1941414998337105 Test RE 1.0893437563875925\n",
      "29 Train Loss 1.8019178 Test MSE 5.243873241894832 Test RE 1.0945463393493713\n",
      "30 Train Loss 1.7604827 Test MSE 5.273783549222541 Test RE 1.0976634690946463\n",
      "31 Train Loss 1.7271165 Test MSE 5.2540742224177235 Test RE 1.0956104403082116\n",
      "32 Train Loss 1.6989517 Test MSE 5.2576537087572826 Test RE 1.0959835845311476\n",
      "33 Train Loss 1.6737114 Test MSE 5.283932853219352 Test RE 1.0987191784679533\n",
      "34 Train Loss 1.6487734 Test MSE 5.297301915014801 Test RE 1.1001082541382146\n",
      "35 Train Loss 1.6294425 Test MSE 5.2738981203678215 Test RE 1.0976753922117588\n",
      "36 Train Loss 1.610702 Test MSE 5.280423467491584 Test RE 1.0983542542772893\n",
      "37 Train Loss 1.5901164 Test MSE 5.259569392957107 Test RE 1.096183233208862\n",
      "38 Train Loss 1.5703208 Test MSE 5.313076233630542 Test RE 1.1017449891022908\n",
      "39 Train Loss 1.5477468 Test MSE 5.34236336553355 Test RE 1.1047773761289386\n",
      "40 Train Loss 1.5216955 Test MSE 5.351925305073159 Test RE 1.1057656177657995\n",
      "41 Train Loss 1.4985371 Test MSE 5.335035644879773 Test RE 1.1040194458510495\n",
      "42 Train Loss 1.4803265 Test MSE 5.315960429934066 Test RE 1.1020439889243052\n",
      "43 Train Loss 1.450835 Test MSE 5.30336486609729 Test RE 1.1007376306815264\n",
      "44 Train Loss 1.4238425 Test MSE 5.3414171016832634 Test RE 1.104679530183408\n",
      "45 Train Loss 1.4057211 Test MSE 5.313416796266327 Test RE 1.1017802988878516\n",
      "46 Train Loss 1.3700607 Test MSE 5.396388051883234 Test RE 1.1103493592980802\n",
      "47 Train Loss 1.3500783 Test MSE 5.425351925945803 Test RE 1.1133251443267989\n",
      "48 Train Loss 1.318856 Test MSE 5.465446820456095 Test RE 1.1174314663761242\n",
      "49 Train Loss 1.2793596 Test MSE 5.539651547920018 Test RE 1.124991611644883\n",
      "50 Train Loss 1.248853 Test MSE 5.525980069659154 Test RE 1.1236025532053855\n",
      "51 Train Loss 1.2211232 Test MSE 5.532111042281094 Test RE 1.1242256885335584\n",
      "52 Train Loss 1.196242 Test MSE 5.575535862982715 Test RE 1.1286294206572016\n",
      "53 Train Loss 1.1701002 Test MSE 5.607994003595594 Test RE 1.1319098274771384\n",
      "54 Train Loss 1.1233908 Test MSE 5.632282571789169 Test RE 1.1343583648160043\n",
      "55 Train Loss 1.1011755 Test MSE 5.647448724558566 Test RE 1.1358845920888274\n",
      "56 Train Loss 1.0708783 Test MSE 5.6983324583664805 Test RE 1.1409902995145704\n",
      "57 Train Loss 1.0483124 Test MSE 5.730220611029991 Test RE 1.144178364907435\n",
      "58 Train Loss 1.0348719 Test MSE 5.743985685430993 Test RE 1.1455518070742068\n",
      "59 Train Loss 1.0170448 Test MSE 5.729545619800828 Test RE 1.1441109736882964\n",
      "60 Train Loss 0.9965378 Test MSE 5.755999516515323 Test RE 1.1467491705390165\n",
      "61 Train Loss 0.9860275 Test MSE 5.743385599039463 Test RE 1.1454919663953536\n",
      "62 Train Loss 0.9749681 Test MSE 5.775234426091213 Test RE 1.1486636268986163\n",
      "63 Train Loss 0.95936805 Test MSE 5.8145369575392705 Test RE 1.1525655326585906\n",
      "64 Train Loss 0.94887966 Test MSE 5.794839198313278 Test RE 1.150611617951642\n",
      "65 Train Loss 0.9383551 Test MSE 5.807760216488065 Test RE 1.151893689368738\n",
      "66 Train Loss 0.9255281 Test MSE 5.827142842312418 Test RE 1.1538142341606872\n",
      "67 Train Loss 0.9169884 Test MSE 5.8381428455719515 Test RE 1.154902758727168\n",
      "68 Train Loss 0.90749 Test MSE 5.872480645402088 Test RE 1.1582941350573206\n",
      "69 Train Loss 0.9002865 Test MSE 5.914729204993076 Test RE 1.1624532426848722\n",
      "70 Train Loss 0.89087677 Test MSE 5.933450012369816 Test RE 1.164291439313837\n",
      "71 Train Loss 0.88503873 Test MSE 5.95516278863048 Test RE 1.166419789125478\n",
      "72 Train Loss 0.8804869 Test MSE 5.948905134233657 Test RE 1.1658067940957257\n",
      "73 Train Loss 0.87499297 Test MSE 5.951517022510914 Test RE 1.166062691851602\n",
      "74 Train Loss 0.8680532 Test MSE 5.997276513847637 Test RE 1.1705368673822147\n",
      "75 Train Loss 0.864611 Test MSE 5.9833473382397 Test RE 1.1691767423520822\n",
      "76 Train Loss 0.8589981 Test MSE 6.0023777939744845 Test RE 1.1710345905739556\n",
      "77 Train Loss 0.8517315 Test MSE 6.031302041781705 Test RE 1.1738526894287267\n",
      "78 Train Loss 0.8471277 Test MSE 6.037078812354336 Test RE 1.1744147119138364\n",
      "79 Train Loss 0.8431796 Test MSE 6.05739617729154 Test RE 1.176389257145135\n",
      "80 Train Loss 0.83738637 Test MSE 6.083979140326691 Test RE 1.1789677312123052\n",
      "81 Train Loss 0.83061373 Test MSE 6.097679234009781 Test RE 1.1802944028972095\n",
      "82 Train Loss 0.8278224 Test MSE 6.092073623370775 Test RE 1.1797517544652654\n",
      "83 Train Loss 0.824736 Test MSE 6.071021001859118 Test RE 1.1777115327530017\n",
      "84 Train Loss 0.8211603 Test MSE 6.063960209617118 Test RE 1.1770264753566575\n",
      "85 Train Loss 0.8180874 Test MSE 6.076578073116581 Test RE 1.1782504149233486\n",
      "86 Train Loss 0.8136654 Test MSE 6.082070911688204 Test RE 1.178782826204332\n",
      "87 Train Loss 0.81042385 Test MSE 6.091250270036923 Test RE 1.1796720291186609\n",
      "88 Train Loss 0.80729634 Test MSE 6.115381976798838 Test RE 1.1820064727065387\n",
      "89 Train Loss 0.80455923 Test MSE 6.140314211217445 Test RE 1.1844135248335688\n",
      "90 Train Loss 0.80092335 Test MSE 6.151436122304898 Test RE 1.1854856997940992\n",
      "91 Train Loss 0.7987719 Test MSE 6.158162728788405 Test RE 1.186133688072789\n",
      "92 Train Loss 0.79677176 Test MSE 6.163849522773443 Test RE 1.186681232989307\n",
      "93 Train Loss 0.79474694 Test MSE 6.164998487165732 Test RE 1.1867918287253278\n",
      "94 Train Loss 0.7923737 Test MSE 6.169133465948507 Test RE 1.1871897636520947\n",
      "95 Train Loss 0.7901467 Test MSE 6.1668840689109246 Test RE 1.186973306622656\n",
      "96 Train Loss 0.78782237 Test MSE 6.1758329665181435 Test RE 1.1878342156139765\n",
      "97 Train Loss 0.78455466 Test MSE 6.186445538626594 Test RE 1.1888543666967908\n",
      "98 Train Loss 0.7817701 Test MSE 6.195903541570322 Test RE 1.189762795754159\n",
      "99 Train Loss 0.77867794 Test MSE 6.205956621943049 Test RE 1.190727621397484\n",
      "100 Train Loss 0.7751061 Test MSE 6.218443033945502 Test RE 1.191924894074755\n",
      "101 Train Loss 0.7719371 Test MSE 6.224931756435889 Test RE 1.1925465973950695\n",
      "102 Train Loss 0.7698637 Test MSE 6.221976419050216 Test RE 1.1922634781507582\n",
      "103 Train Loss 0.7670699 Test MSE 6.225107579674732 Test RE 1.1925634390194333\n",
      "104 Train Loss 0.76457757 Test MSE 6.235662538521124 Test RE 1.1935740341556078\n",
      "105 Train Loss 0.76166314 Test MSE 6.239057387140486 Test RE 1.193898895530351\n",
      "106 Train Loss 0.75936794 Test MSE 6.25382137528931 Test RE 1.1953106707788406\n",
      "107 Train Loss 0.7570077 Test MSE 6.246587312630507 Test RE 1.1946191372513943\n",
      "108 Train Loss 0.7553885 Test MSE 6.256588867100845 Test RE 1.1955751208169807\n",
      "109 Train Loss 0.7531398 Test MSE 6.269661381681453 Test RE 1.196823486192376\n",
      "110 Train Loss 0.75049675 Test MSE 6.269736668740485 Test RE 1.1968306719911355\n",
      "111 Train Loss 0.7466835 Test MSE 6.287905756815488 Test RE 1.198563566996617\n",
      "112 Train Loss 0.74356043 Test MSE 6.290903614102414 Test RE 1.198849249900819\n",
      "113 Train Loss 0.7416446 Test MSE 6.288052394261624 Test RE 1.1985775424983687\n",
      "114 Train Loss 0.73955286 Test MSE 6.267399147698785 Test RE 1.1966075463774395\n",
      "115 Train Loss 0.73770607 Test MSE 6.262627446286459 Test RE 1.1961519394341453\n",
      "116 Train Loss 0.7363323 Test MSE 6.272121760761637 Test RE 1.197058295574984\n",
      "117 Train Loss 0.7351184 Test MSE 6.280480598795863 Test RE 1.197855688009656\n",
      "118 Train Loss 0.733748 Test MSE 6.28820929264466 Test RE 1.1985924957536465\n",
      "119 Train Loss 0.73241055 Test MSE 6.287020031952436 Test RE 1.1984791481949104\n",
      "120 Train Loss 0.73056436 Test MSE 6.298417690882868 Test RE 1.1995650101101862\n",
      "121 Train Loss 0.7289479 Test MSE 6.2867648976633905 Test RE 1.1984548301375424\n",
      "122 Train Loss 0.72749114 Test MSE 6.298303084071314 Test RE 1.1995540963415854\n",
      "123 Train Loss 0.725417 Test MSE 6.317908106372875 Test RE 1.2014195998023471\n",
      "124 Train Loss 0.7238304 Test MSE 6.3198514248241295 Test RE 1.2016043572670965\n",
      "125 Train Loss 0.7219973 Test MSE 6.333059978531615 Test RE 1.2028593845138347\n",
      "126 Train Loss 0.7207301 Test MSE 6.327274462049456 Test RE 1.2023098276711124\n",
      "127 Train Loss 0.719508 Test MSE 6.329759139925177 Test RE 1.202545873967647\n",
      "128 Train Loss 0.7171609 Test MSE 6.324827225999051 Test RE 1.202077293067727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 Train Loss 0.7145859 Test MSE 6.335620402401501 Test RE 1.2031025149013321\n",
      "130 Train Loss 0.7123509 Test MSE 6.335093447598098 Test RE 1.2030524808247884\n",
      "131 Train Loss 0.7107895 Test MSE 6.341003805383595 Test RE 1.2036135469709246\n",
      "132 Train Loss 0.7088586 Test MSE 6.344371110951968 Test RE 1.203933086021984\n",
      "133 Train Loss 0.7079401 Test MSE 6.348458964785963 Test RE 1.2043208872623088\n",
      "134 Train Loss 0.707289 Test MSE 6.348458163445336 Test RE 1.2043208112539978\n",
      "135 Train Loss 0.7062289 Test MSE 6.355304533096551 Test RE 1.2049700242961954\n",
      "136 Train Loss 0.70525765 Test MSE 6.364041248468938 Test RE 1.2057979834050283\n",
      "137 Train Loss 0.70403504 Test MSE 6.363530356542398 Test RE 1.2057495829630251\n",
      "138 Train Loss 0.70224696 Test MSE 6.3711410121381755 Test RE 1.2064703937547532\n",
      "139 Train Loss 0.7009585 Test MSE 6.373927438296928 Test RE 1.2067341905513977\n",
      "140 Train Loss 0.69952065 Test MSE 6.377942497715307 Test RE 1.2071142032482371\n",
      "141 Train Loss 0.698296 Test MSE 6.3865773529659045 Test RE 1.207931060008286\n",
      "142 Train Loss 0.69737256 Test MSE 6.390425068008111 Test RE 1.2082948757446699\n",
      "143 Train Loss 0.6965971 Test MSE 6.380880350770091 Test RE 1.2073921859880905\n",
      "144 Train Loss 0.6957798 Test MSE 6.380946676734891 Test RE 1.2073984610817392\n",
      "145 Train Loss 0.69462043 Test MSE 6.3798204854045615 Test RE 1.2072919077950284\n",
      "146 Train Loss 0.6935469 Test MSE 6.386539894009182 Test RE 1.2079275175863322\n",
      "147 Train Loss 0.69233245 Test MSE 6.381387948926444 Test RE 1.2074402089744152\n",
      "148 Train Loss 0.69138986 Test MSE 6.381218925411408 Test RE 1.207424218163218\n",
      "149 Train Loss 0.6906264 Test MSE 6.3811573389285305 Test RE 1.2074183915969126\n",
      "Training time: 229.38\n",
      "0\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 72.79291 Test MSE 4.391532351613083 Test RE 1.0016502494408268\n",
      "1 Train Loss 71.71831 Test MSE 4.3671839378232775 Test RE 0.9988696148166609\n",
      "2 Train Loss 67.201775 Test MSE 4.478943285426721 Test RE 1.0115697690489536\n",
      "3 Train Loss 43.45428 Test MSE 7.974146756623193 Test RE 1.3497401672971159\n",
      "4 Train Loss 33.319176 Test MSE 8.323468302661492 Test RE 1.3789871691405617\n",
      "5 Train Loss 28.542107 Test MSE 8.351849372535723 Test RE 1.3813361794590273\n",
      "6 Train Loss 25.880692 Test MSE 8.805615211595123 Test RE 1.418364693621677\n",
      "7 Train Loss 22.7548 Test MSE 8.410546624690197 Test RE 1.3861817336027957\n",
      "8 Train Loss 19.569263 Test MSE 8.646048261011202 Test RE 1.4054548158141846\n",
      "9 Train Loss 17.321798 Test MSE 8.433629263934986 Test RE 1.388082609415506\n",
      "10 Train Loss 15.228528 Test MSE 8.15218768207997 Test RE 1.364724992860177\n",
      "11 Train Loss 13.764561 Test MSE 8.195842881154862 Test RE 1.3683741847592275\n",
      "12 Train Loss 12.174638 Test MSE 8.254059399147003 Test RE 1.3732254867195413\n",
      "13 Train Loss 10.82266 Test MSE 8.180484764215551 Test RE 1.3670914914751686\n",
      "14 Train Loss 9.002917 Test MSE 8.201277802158346 Test RE 1.3688278155319127\n",
      "15 Train Loss 7.7416277 Test MSE 7.64562129743337 Test RE 1.3216438873042886\n",
      "16 Train Loss 6.211686 Test MSE 7.251591125024377 Test RE 1.2871368220726502\n",
      "17 Train Loss 4.7529206 Test MSE 6.867521374176331 Test RE 1.2525874906360273\n",
      "18 Train Loss 3.6012588 Test MSE 6.723925519789015 Test RE 1.2394228751687013\n",
      "19 Train Loss 3.2961853 Test MSE 6.848609847747358 Test RE 1.250861637110801\n",
      "20 Train Loss 3.0856674 Test MSE 6.98172393584277 Test RE 1.2629594198854157\n",
      "21 Train Loss 2.9366481 Test MSE 6.921954209575853 Test RE 1.2575417756854859\n",
      "22 Train Loss 2.782415 Test MSE 6.909375558296049 Test RE 1.25639864675352\n",
      "23 Train Loss 2.6020758 Test MSE 6.960165993002167 Test RE 1.2610080496178013\n",
      "24 Train Loss 2.4678605 Test MSE 6.950009762308699 Test RE 1.2600876862177877\n",
      "25 Train Loss 2.3860328 Test MSE 7.01520671839521 Test RE 1.2659842327403803\n",
      "26 Train Loss 2.3200085 Test MSE 7.010120110538227 Test RE 1.265525177623973\n",
      "27 Train Loss 2.227912 Test MSE 7.044501109110527 Test RE 1.2686247537047968\n",
      "28 Train Loss 2.1600866 Test MSE 6.954250855846131 Test RE 1.2604720982464028\n",
      "29 Train Loss 2.1023607 Test MSE 7.038612574234021 Test RE 1.2680944178606641\n",
      "30 Train Loss 2.0644066 Test MSE 6.988128149749564 Test RE 1.263538532465596\n",
      "31 Train Loss 2.0000544 Test MSE 7.07274503032691 Test RE 1.2711653945609152\n",
      "32 Train Loss 1.9601945 Test MSE 7.113408514533227 Test RE 1.2748143265462202\n",
      "33 Train Loss 1.9129101 Test MSE 7.131796995358753 Test RE 1.2764609892333807\n",
      "34 Train Loss 1.8321089 Test MSE 7.148089951868039 Test RE 1.2779182277671843\n",
      "35 Train Loss 1.7953502 Test MSE 7.083044624373098 Test RE 1.2720906169815684\n",
      "36 Train Loss 1.7233353 Test MSE 6.9868007307470945 Test RE 1.2634185200188013\n",
      "37 Train Loss 1.6687862 Test MSE 6.798429520628694 Test RE 1.2462706289755694\n",
      "38 Train Loss 1.615288 Test MSE 6.770216995638247 Test RE 1.2436820167995224\n",
      "39 Train Loss 1.5668645 Test MSE 6.587683695314867 Test RE 1.2268018707068584\n",
      "40 Train Loss 1.5252513 Test MSE 6.595178392925105 Test RE 1.2274995283245034\n",
      "41 Train Loss 1.481894 Test MSE 6.5999602741792875 Test RE 1.2279444513457314\n",
      "42 Train Loss 1.4467934 Test MSE 6.457042780194149 Test RE 1.2145765507881494\n",
      "43 Train Loss 1.404336 Test MSE 6.482433045631025 Test RE 1.216962175752632\n",
      "44 Train Loss 1.3841372 Test MSE 6.377488216818521 Test RE 1.2070712129980141\n",
      "45 Train Loss 1.3617468 Test MSE 6.298747516318475 Test RE 1.1995964181472436\n",
      "46 Train Loss 1.3405036 Test MSE 6.228591293180063 Test RE 1.192897085323736\n",
      "47 Train Loss 1.3136139 Test MSE 6.206470095325753 Test RE 1.1907768800638456\n",
      "48 Train Loss 1.2887266 Test MSE 6.0966775070980335 Test RE 1.180197449516735\n",
      "49 Train Loss 1.2662001 Test MSE 6.145065843409352 Test RE 1.184871710594507\n",
      "50 Train Loss 1.2487977 Test MSE 6.147140238276959 Test RE 1.1850716827725707\n",
      "51 Train Loss 1.2348402 Test MSE 6.08361969496191 Test RE 1.1789329036154448\n",
      "52 Train Loss 1.2203739 Test MSE 6.079416117064015 Test RE 1.1785255316146304\n",
      "53 Train Loss 1.204402 Test MSE 6.052399628099069 Test RE 1.1759039744229585\n",
      "54 Train Loss 1.1931574 Test MSE 6.029582793578198 Test RE 1.1736853716626674\n",
      "55 Train Loss 1.1797429 Test MSE 6.021408064964707 Test RE 1.1728894779889008\n",
      "56 Train Loss 1.1670289 Test MSE 6.010905444771986 Test RE 1.1718661468380367\n",
      "57 Train Loss 1.1531324 Test MSE 6.022133100895713 Test RE 1.1729600894977281\n",
      "58 Train Loss 1.1451693 Test MSE 6.004015390832352 Test RE 1.171194323254224\n",
      "59 Train Loss 1.1353813 Test MSE 6.032179862536921 Test RE 1.1739381100192217\n",
      "60 Train Loss 1.1263568 Test MSE 6.010118248168019 Test RE 1.1717894097088166\n",
      "61 Train Loss 1.115551 Test MSE 5.98099135327249 Test RE 1.16894653391826\n",
      "62 Train Loss 1.107332 Test MSE 5.988173427731056 Test RE 1.169648168622989\n",
      "63 Train Loss 1.0982089 Test MSE 5.9605672531851495 Test RE 1.166948947189343\n",
      "64 Train Loss 1.0891882 Test MSE 5.947263384637082 Test RE 1.165645916181182\n",
      "65 Train Loss 1.0806593 Test MSE 5.935602034152494 Test RE 1.1645025604478754\n",
      "66 Train Loss 1.0716081 Test MSE 5.934013293507938 Test RE 1.164346702932943\n",
      "67 Train Loss 1.0595264 Test MSE 5.923281308892996 Test RE 1.163293334393859\n",
      "68 Train Loss 1.049319 Test MSE 5.908583288861552 Test RE 1.1618491408950318\n",
      "69 Train Loss 1.0411973 Test MSE 5.906560826672553 Test RE 1.161650277905755\n",
      "70 Train Loss 1.0336068 Test MSE 5.8999992840188575 Test RE 1.1610048654474763\n",
      "71 Train Loss 1.0242357 Test MSE 5.898568427103426 Test RE 1.1608640745344152\n",
      "72 Train Loss 1.0153608 Test MSE 5.929751630783629 Test RE 1.1639285252239622\n",
      "73 Train Loss 1.0055007 Test MSE 5.914783672129593 Test RE 1.1624585950308126\n",
      "74 Train Loss 0.99742293 Test MSE 5.901860953314746 Test RE 1.1611880211168368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 Train Loss 0.9858759 Test MSE 5.917376747371909 Test RE 1.1627133813819435\n",
      "76 Train Loss 0.97946143 Test MSE 5.937609705220014 Test RE 1.1646994857489075\n",
      "77 Train Loss 0.9702046 Test MSE 5.956273056886261 Test RE 1.1665285165066832\n",
      "78 Train Loss 0.9619551 Test MSE 5.969487323369263 Test RE 1.1678217982601546\n",
      "79 Train Loss 0.9525601 Test MSE 5.980696480374703 Test RE 1.168917718051457\n",
      "80 Train Loss 0.94248265 Test MSE 6.020703598191543 Test RE 1.1728208656456423\n",
      "81 Train Loss 0.93594974 Test MSE 5.994996720545765 Test RE 1.1703143634040054\n",
      "82 Train Loss 0.93056774 Test MSE 6.015600458216823 Test RE 1.1723237196130536\n",
      "83 Train Loss 0.92395985 Test MSE 6.021516327545339 Test RE 1.172900021990366\n",
      "84 Train Loss 0.9183109 Test MSE 6.02383983728734 Test RE 1.173126292387545\n",
      "85 Train Loss 0.91233796 Test MSE 6.039158889919395 Test RE 1.1746170169841568\n",
      "86 Train Loss 0.90701896 Test MSE 6.02666872848541 Test RE 1.1734017194574464\n",
      "87 Train Loss 0.9020607 Test MSE 6.0301106893838075 Test RE 1.173736749182914\n",
      "88 Train Loss 0.8971617 Test MSE 6.036331725555204 Test RE 1.174342042921008\n",
      "89 Train Loss 0.8917187 Test MSE 6.0229988195934485 Test RE 1.1730443965839685\n",
      "90 Train Loss 0.88504916 Test MSE 6.029338119509259 Test RE 1.1736615579678653\n",
      "91 Train Loss 0.8773243 Test MSE 6.025212543662915 Test RE 1.1732599501750351\n",
      "92 Train Loss 0.8721299 Test MSE 6.041264064369562 Test RE 1.1748217274679422\n",
      "93 Train Loss 0.8682106 Test MSE 6.055596821764941 Test RE 1.176214520371463\n",
      "94 Train Loss 0.8619674 Test MSE 6.08256726206315 Test RE 1.1788309247360362\n",
      "95 Train Loss 0.85743356 Test MSE 6.091307893959031 Test RE 1.1796776090214178\n",
      "96 Train Loss 0.85362345 Test MSE 6.088980850787438 Test RE 1.1794522532354428\n",
      "97 Train Loss 0.8485453 Test MSE 6.0929787452599165 Test RE 1.1798393912489964\n",
      "98 Train Loss 0.84485185 Test MSE 6.089173684237559 Test RE 1.1794709292710672\n",
      "99 Train Loss 0.8416014 Test MSE 6.100760837950485 Test RE 1.1805926098316675\n",
      "100 Train Loss 0.8381103 Test MSE 6.103280481267878 Test RE 1.1808363798534627\n",
      "101 Train Loss 0.8333283 Test MSE 6.105899420596062 Test RE 1.1810897032228505\n",
      "102 Train Loss 0.8288287 Test MSE 6.105794565750354 Test RE 1.1810795619232848\n",
      "103 Train Loss 0.8252939 Test MSE 6.131879329438036 Test RE 1.1835997373793696\n",
      "104 Train Loss 0.8219268 Test MSE 6.123910363712647 Test RE 1.1828303866065937\n",
      "105 Train Loss 0.8173266 Test MSE 6.154877069801134 Test RE 1.1858172178072217\n",
      "106 Train Loss 0.8144125 Test MSE 6.157101002809968 Test RE 1.1860314332858004\n",
      "107 Train Loss 0.811152 Test MSE 6.174275880405559 Test RE 1.1876844644171487\n",
      "108 Train Loss 0.80640006 Test MSE 6.181461894558171 Test RE 1.1883754147138337\n",
      "109 Train Loss 0.80357784 Test MSE 6.173787825432678 Test RE 1.1876375223323044\n",
      "110 Train Loss 0.79904974 Test MSE 6.197385469012831 Test RE 1.1899050701384692\n",
      "111 Train Loss 0.7963314 Test MSE 6.201231768420988 Test RE 1.190274259798614\n",
      "112 Train Loss 0.7934158 Test MSE 6.212958539487964 Test RE 1.1913991557619563\n",
      "113 Train Loss 0.7894471 Test MSE 6.214148976137732 Test RE 1.1915132895743117\n",
      "114 Train Loss 0.786472 Test MSE 6.218814296782806 Test RE 1.1919604745899142\n",
      "115 Train Loss 0.78449583 Test MSE 6.225533072475005 Test RE 1.1926041948200496\n",
      "116 Train Loss 0.7822657 Test MSE 6.222958760152676 Test RE 1.1923575931968424\n",
      "117 Train Loss 0.7787509 Test MSE 6.243319888643766 Test RE 1.1943066596060858\n",
      "118 Train Loss 0.77637 Test MSE 6.245304079963975 Test RE 1.1944964260042892\n",
      "119 Train Loss 0.7746511 Test MSE 6.249064067223596 Test RE 1.1948559453722434\n",
      "120 Train Loss 0.7722792 Test MSE 6.256505932591809 Test RE 1.1955671967894992\n",
      "121 Train Loss 0.7700003 Test MSE 6.272378184156381 Test RE 1.1970827650150182\n",
      "122 Train Loss 0.76813513 Test MSE 6.275152675269129 Test RE 1.1973474914230346\n",
      "123 Train Loss 0.76602703 Test MSE 6.264571891860436 Test RE 1.1963376180376888\n",
      "124 Train Loss 0.76339585 Test MSE 6.273567104310596 Test RE 1.1971962122870992\n",
      "125 Train Loss 0.7613176 Test MSE 6.279079312343008 Test RE 1.197722049145554\n",
      "126 Train Loss 0.75939465 Test MSE 6.283339648867152 Test RE 1.198128305659445\n",
      "127 Train Loss 0.7577226 Test MSE 6.289107275855716 Test RE 1.1986780747686812\n",
      "128 Train Loss 0.75558144 Test MSE 6.299950177652056 Test RE 1.1997109361021547\n",
      "129 Train Loss 0.754022 Test MSE 6.316528755722195 Test RE 1.2012884433072575\n",
      "130 Train Loss 0.7527375 Test MSE 6.302167662892129 Test RE 1.1999220573935594\n",
      "131 Train Loss 0.7509799 Test MSE 6.307986162368401 Test RE 1.2004758458278504\n",
      "132 Train Loss 0.7491379 Test MSE 6.307758286499187 Test RE 1.200454162049508\n",
      "133 Train Loss 0.74582934 Test MSE 6.31931482381782 Test RE 1.2015533437423156\n",
      "134 Train Loss 0.74428564 Test MSE 6.32889940758209 Test RE 1.202464203980891\n",
      "135 Train Loss 0.7426299 Test MSE 6.32642417665969 Test RE 1.2022290392657466\n",
      "136 Train Loss 0.74055296 Test MSE 6.319999290723925 Test RE 1.2016184141853907\n",
      "137 Train Loss 0.7389148 Test MSE 6.318816679624087 Test RE 1.2015059842868618\n",
      "138 Train Loss 0.73731303 Test MSE 6.3200369064711435 Test RE 1.201621990112\n",
      "139 Train Loss 0.73549306 Test MSE 6.3171658951423995 Test RE 1.201349027921999\n",
      "140 Train Loss 0.73289275 Test MSE 6.30238870746485 Test RE 1.1999431004653207\n",
      "141 Train Loss 0.73095775 Test MSE 6.301490753300324 Test RE 1.1998576144427264\n",
      "142 Train Loss 0.7291527 Test MSE 6.310633236340601 Test RE 1.2007277023615748\n",
      "143 Train Loss 0.7278092 Test MSE 6.297743585156255 Test RE 1.199500814996415\n",
      "144 Train Loss 0.7261852 Test MSE 6.295060678305889 Test RE 1.1992452876218371\n",
      "145 Train Loss 0.724679 Test MSE 6.293105479001821 Test RE 1.1990590347986767\n",
      "146 Train Loss 0.72313017 Test MSE 6.300451219103554 Test RE 1.19975864226972\n",
      "147 Train Loss 0.7215898 Test MSE 6.305120507309047 Test RE 1.200203132763186\n",
      "148 Train Loss 0.719577 Test MSE 6.310787221680714 Test RE 1.2007423517104454\n",
      "149 Train Loss 0.7179094 Test MSE 6.319956863555182 Test RE 1.2016143808500663\n",
      "Training time: 229.69\n",
      "1\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 65.27816 Test MSE 5.993897385392801 Test RE 1.1702070550295125\n",
      "1 Train Loss 44.699112 Test MSE 9.207998441725236 Test RE 1.4504096441798102\n",
      "2 Train Loss 35.49134 Test MSE 9.114538708921982 Test RE 1.4430301566277093\n",
      "3 Train Loss 30.226917 Test MSE 9.029469491978942 Test RE 1.4362802141127\n",
      "4 Train Loss 27.343166 Test MSE 8.8355883693859 Test RE 1.4207766064824372\n",
      "5 Train Loss 25.190784 Test MSE 8.86903711243217 Test RE 1.4234633715082396\n",
      "6 Train Loss 23.901901 Test MSE 8.792130969932789 Test RE 1.4172782902697654\n",
      "7 Train Loss 23.00677 Test MSE 8.94044629373956 Test RE 1.429182400894736\n",
      "8 Train Loss 22.292795 Test MSE 8.885535948761754 Test RE 1.4247867720464384\n",
      "9 Train Loss 21.529026 Test MSE 9.254344965340543 Test RE 1.454055228570691\n",
      "10 Train Loss 20.974722 Test MSE 9.207137732649342 Test RE 1.4503418547505125\n",
      "11 Train Loss 20.509054 Test MSE 9.219242505477652 Test RE 1.4512949355377374\n",
      "12 Train Loss 20.091417 Test MSE 9.172870996498 Test RE 1.447640428379578\n",
      "13 Train Loss 19.557772 Test MSE 8.996091225698063 Test RE 1.4336230851573626\n",
      "14 Train Loss 19.17273 Test MSE 8.729574882663696 Test RE 1.4122273162043617\n",
      "15 Train Loss 18.80066 Test MSE 8.644720407754615 Test RE 1.4053468873503845\n",
      "16 Train Loss 17.591087 Test MSE 7.359617170175777 Test RE 1.2966885389426832\n",
      "17 Train Loss 15.359589 Test MSE 7.049163404496965 Test RE 1.26904449421796\n",
      "18 Train Loss 14.437477 Test MSE 7.11595723923813 Test RE 1.2750426882220705\n",
      "19 Train Loss 13.9226055 Test MSE 7.0265088838609655 Test RE 1.2670036328417384\n",
      "20 Train Loss 13.544104 Test MSE 7.009141220039559 Test RE 1.2654368158125882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Train Loss 13.273595 Test MSE 6.969232383734172 Test RE 1.2618290839873545\n",
      "22 Train Loss 13.034433 Test MSE 7.024283156741573 Test RE 1.2668029479963092\n",
      "23 Train Loss 12.728866 Test MSE 6.9828024142922525 Test RE 1.2630569618344405\n",
      "24 Train Loss 12.5270195 Test MSE 7.058481478200886 Test RE 1.2698829727890981\n",
      "25 Train Loss 12.287369 Test MSE 7.053023725596102 Test RE 1.2693919289731666\n",
      "26 Train Loss 12.020356 Test MSE 7.182117842122624 Test RE 1.2809563283503638\n",
      "27 Train Loss 11.835011 Test MSE 7.119508470793683 Test RE 1.2753608047378557\n",
      "28 Train Loss 11.65476 Test MSE 7.214897431612178 Test RE 1.2838761788908386\n",
      "29 Train Loss 11.422045 Test MSE 7.148828663498978 Test RE 1.277984258600341\n",
      "30 Train Loss 11.034485 Test MSE 7.195310842607155 Test RE 1.2821322978977603\n",
      "31 Train Loss 10.220732 Test MSE 6.3965258707552355 Test RE 1.2088715048490133\n",
      "32 Train Loss 9.539862 Test MSE 6.276044184591967 Test RE 1.1974325418270846\n",
      "33 Train Loss 9.020193 Test MSE 6.153409602176922 Test RE 1.1856758460063652\n",
      "34 Train Loss 8.706421 Test MSE 6.302390757268383 Test RE 1.1999432956014444\n",
      "35 Train Loss 8.562263 Test MSE 6.292884976999504 Test RE 1.1990380279019226\n",
      "36 Train Loss 8.355578 Test MSE 6.223505007501862 Test RE 1.1924099242428237\n",
      "37 Train Loss 8.152157 Test MSE 6.2960346167551755 Test RE 1.1993380544737051\n",
      "38 Train Loss 8.031412 Test MSE 6.338645636011659 Test RE 1.203389718959938\n",
      "39 Train Loss 7.85528 Test MSE 6.370832493971978 Test RE 1.2064411821473697\n",
      "40 Train Loss 7.7084565 Test MSE 6.4332011463489245 Test RE 1.212332158880318\n",
      "41 Train Loss 7.5773735 Test MSE 6.451873745118471 Test RE 1.2140903029828871\n",
      "42 Train Loss 7.4656553 Test MSE 6.533161580195349 Test RE 1.2217145889893088\n",
      "43 Train Loss 7.3797293 Test MSE 6.530241125852708 Test RE 1.2214414929959028\n",
      "44 Train Loss 7.2648478 Test MSE 6.481401370852314 Test RE 1.2168653325510241\n",
      "45 Train Loss 7.2017975 Test MSE 6.504067265044286 Test RE 1.2189912053306442\n",
      "46 Train Loss 7.1260676 Test MSE 6.524358514169149 Test RE 1.2208912158501573\n",
      "47 Train Loss 7.056218 Test MSE 6.500713498592494 Test RE 1.2186768836307291\n",
      "48 Train Loss 7.0011673 Test MSE 6.5043484915643095 Test RE 1.2190175587595866\n",
      "49 Train Loss 6.937729 Test MSE 6.575457822241866 Test RE 1.2256629507138952\n",
      "50 Train Loss 6.8952436 Test MSE 6.566666674347953 Test RE 1.2248433432881305\n",
      "51 Train Loss 6.8206186 Test MSE 6.566323374141129 Test RE 1.2248113259428182\n",
      "52 Train Loss 6.780648 Test MSE 6.535113705119083 Test RE 1.221897101034949\n",
      "53 Train Loss 6.7026863 Test MSE 6.57148182707393 Test RE 1.2252923326519636\n",
      "54 Train Loss 6.620219 Test MSE 6.67012522508952 Test RE 1.2344544057285636\n",
      "55 Train Loss 6.5358763 Test MSE 6.616950131936306 Test RE 1.229523945132993\n",
      "56 Train Loss 6.440933 Test MSE 6.571436547397466 Test RE 1.2252881113106113\n",
      "57 Train Loss 6.293969 Test MSE 6.57520920874556 Test RE 1.2256397797621497\n",
      "58 Train Loss 6.162493 Test MSE 6.424611974240187 Test RE 1.21152257689233\n",
      "59 Train Loss 6.021284 Test MSE 6.367598440538868 Test RE 1.2061349277814752\n",
      "60 Train Loss 5.841919 Test MSE 6.351030890808483 Test RE 1.204564813433867\n",
      "61 Train Loss 5.2514 Test MSE 5.7962313907851435 Test RE 1.1507498251199533\n",
      "62 Train Loss 4.561093 Test MSE 5.387097657001691 Test RE 1.1093931616019939\n",
      "63 Train Loss 4.047796 Test MSE 5.219032908096012 Test RE 1.091950817847461\n",
      "64 Train Loss 3.542038 Test MSE 5.324645912440418 Test RE 1.102943908834248\n",
      "65 Train Loss 3.2056043 Test MSE 5.338086054627958 Test RE 1.1043350229767666\n",
      "66 Train Loss 3.004054 Test MSE 5.4583452294314485 Test RE 1.1167052566998352\n",
      "67 Train Loss 2.8209262 Test MSE 5.5763261235850585 Test RE 1.1287094021859465\n",
      "68 Train Loss 2.5364585 Test MSE 5.737914801171561 Test RE 1.144946273620384\n",
      "69 Train Loss 2.4401052 Test MSE 5.791761351513155 Test RE 1.1503060118310784\n",
      "70 Train Loss 2.264794 Test MSE 5.815609922464396 Test RE 1.1526718700465866\n",
      "71 Train Loss 2.121276 Test MSE 6.0350184412338255 Test RE 1.1742142890999678\n",
      "72 Train Loss 2.063112 Test MSE 6.004264344909188 Test RE 1.1712186045526662\n",
      "73 Train Loss 2.0102866 Test MSE 6.0395946095710995 Test RE 1.1746593899781164\n",
      "74 Train Loss 1.948087 Test MSE 5.983766532040464 Test RE 1.1692176979435491\n",
      "75 Train Loss 1.8931061 Test MSE 5.975454949486051 Test RE 1.1684053812898132\n",
      "76 Train Loss 1.8577348 Test MSE 5.955509725813852 Test RE 1.1664537654009302\n",
      "77 Train Loss 1.810181 Test MSE 5.940321610444241 Test RE 1.1649654340180569\n",
      "78 Train Loss 1.75928 Test MSE 5.918743197750498 Test RE 1.1628476214765906\n",
      "79 Train Loss 1.7399452 Test MSE 5.952300075345598 Test RE 1.1661393999128054\n",
      "80 Train Loss 1.715802 Test MSE 5.9651537706411935 Test RE 1.1673978308509874\n",
      "81 Train Loss 1.6820428 Test MSE 5.977896122198269 Test RE 1.1686440232094992\n",
      "82 Train Loss 1.6582023 Test MSE 5.9480792289924835 Test RE 1.1657258649717304\n",
      "83 Train Loss 1.6357366 Test MSE 5.966208029591598 Test RE 1.1675009870549096\n",
      "84 Train Loss 1.620128 Test MSE 5.965381477924552 Test RE 1.1674201121250418\n",
      "85 Train Loss 1.6027464 Test MSE 5.989590029951314 Test RE 1.1697865103252463\n",
      "86 Train Loss 1.5779128 Test MSE 5.981569732961411 Test RE 1.169003052858718\n",
      "87 Train Loss 1.5592512 Test MSE 6.036224294163158 Test RE 1.1743315927198357\n",
      "88 Train Loss 1.5323932 Test MSE 6.025744061853623 Test RE 1.173311698992941\n",
      "89 Train Loss 1.5127224 Test MSE 6.024786227543934 Test RE 1.1732184422221787\n",
      "90 Train Loss 1.4935888 Test MSE 6.030502366339423 Test RE 1.1737748677345743\n",
      "91 Train Loss 1.4729911 Test MSE 6.000134768097507 Test RE 1.1708157684325935\n",
      "92 Train Loss 1.4483792 Test MSE 6.010739822218566 Test RE 1.1718500021155602\n",
      "93 Train Loss 1.4217681 Test MSE 6.001603898645439 Test RE 1.170959096541084\n",
      "94 Train Loss 1.4021287 Test MSE 5.972454652697148 Test RE 1.1681120142497627\n",
      "95 Train Loss 1.3804874 Test MSE 6.015119693198221 Test RE 1.1722768727936743\n",
      "96 Train Loss 1.3663349 Test MSE 6.029209044509918 Test RE 1.1736489951315636\n",
      "97 Train Loss 1.3362415 Test MSE 6.038203367131438 Test RE 1.1745240886685895\n",
      "98 Train Loss 1.3153132 Test MSE 5.998616608001215 Test RE 1.170667638574017\n",
      "99 Train Loss 1.2919028 Test MSE 6.03434547445825 Test RE 1.1741488187752327\n",
      "100 Train Loss 1.2728276 Test MSE 6.039567901906651 Test RE 1.1746567927472138\n",
      "101 Train Loss 1.2550293 Test MSE 6.0695843745650215 Test RE 1.177572179534058\n",
      "102 Train Loss 1.2407783 Test MSE 6.079225597910188 Test RE 1.1785070649196496\n",
      "103 Train Loss 1.2279714 Test MSE 6.106650522135927 Test RE 1.1811623453476003\n",
      "104 Train Loss 1.2111189 Test MSE 6.112285143250779 Test RE 1.1817071503709102\n",
      "105 Train Loss 1.1943426 Test MSE 6.112782543420857 Test RE 1.1817552313558692\n",
      "106 Train Loss 1.1763699 Test MSE 6.130471259679774 Test RE 1.183463833964382\n",
      "107 Train Loss 1.1594621 Test MSE 6.120211740375717 Test RE 1.1824731389842704\n",
      "108 Train Loss 1.1501994 Test MSE 6.098519312552495 Test RE 1.1803757048003676\n",
      "109 Train Loss 1.1343338 Test MSE 6.128608677301018 Test RE 1.1832840381342853\n",
      "110 Train Loss 1.1206448 Test MSE 6.125238178224228 Test RE 1.182958613028354\n",
      "111 Train Loss 1.1107816 Test MSE 6.149129279548554 Test RE 1.1852633951582467\n",
      "112 Train Loss 1.0989368 Test MSE 6.143051604118695 Test RE 1.18467750512797\n",
      "113 Train Loss 1.0883651 Test MSE 6.153388990759398 Test RE 1.1856738602389651\n",
      "114 Train Loss 1.0797963 Test MSE 6.135216745322676 Test RE 1.183921794207848\n",
      "115 Train Loss 1.0734302 Test MSE 6.141831378855518 Test RE 1.1845598400564268\n",
      "116 Train Loss 1.06394 Test MSE 6.121146382450008 Test RE 1.1825634256445243\n",
      "117 Train Loss 1.0558742 Test MSE 6.12258171898517 Test RE 1.1827020660961574\n",
      "118 Train Loss 1.0486898 Test MSE 6.108739856224335 Test RE 1.1813643899620605\n",
      "119 Train Loss 1.0420259 Test MSE 6.08296169854201 Test RE 1.1788691459641205\n",
      "120 Train Loss 1.033325 Test MSE 6.07168080491374 Test RE 1.177775528294681\n",
      "121 Train Loss 1.0267265 Test MSE 6.07725754695604 Test RE 1.1783162881783857\n",
      "122 Train Loss 1.0208572 Test MSE 6.073219775581378 Test RE 1.177924782447504\n",
      "123 Train Loss 1.0160353 Test MSE 6.085179485499403 Test RE 1.1790840283262012\n",
      "124 Train Loss 1.0107183 Test MSE 6.10311065731869 Test RE 1.180819951336621\n",
      "125 Train Loss 1.0047536 Test MSE 6.134419877233397 Test RE 1.1838449053078044\n",
      "126 Train Loss 0.999694 Test MSE 6.149035691778421 Test RE 1.1852543754600746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 Train Loss 0.99470776 Test MSE 6.167246873631461 Test RE 1.1870082215959565\n",
      "128 Train Loss 0.9900035 Test MSE 6.154229797645267 Test RE 1.1857548634629373\n",
      "129 Train Loss 0.9848874 Test MSE 6.153155305593324 Test RE 1.1856513460582432\n",
      "130 Train Loss 0.9801136 Test MSE 6.171224033011683 Test RE 1.1873909012675559\n",
      "131 Train Loss 0.9743072 Test MSE 6.192092706847595 Test RE 1.1893968534243953\n",
      "132 Train Loss 0.96885777 Test MSE 6.187382893866121 Test RE 1.1889444294520435\n",
      "133 Train Loss 0.9647337 Test MSE 6.188359638933417 Test RE 1.1890382695941146\n",
      "134 Train Loss 0.9605862 Test MSE 6.182017169139946 Test RE 1.188428788806754\n",
      "135 Train Loss 0.9559392 Test MSE 6.158213686144531 Test RE 1.1861385955520476\n",
      "136 Train Loss 0.94967496 Test MSE 6.1663485601304915 Test RE 1.1869217693778855\n",
      "137 Train Loss 0.9469453 Test MSE 6.154309759651842 Test RE 1.1857625667039051\n",
      "138 Train Loss 0.944123 Test MSE 6.148917630668362 Test RE 1.1852429969996165\n",
      "139 Train Loss 0.9394829 Test MSE 6.133101552980332 Test RE 1.183717690726694\n",
      "140 Train Loss 0.93673456 Test MSE 6.152807416284497 Test RE 1.1856178281932503\n",
      "141 Train Loss 0.93292356 Test MSE 6.15841556046408 Test RE 1.1861580369819593\n",
      "142 Train Loss 0.92855585 Test MSE 6.131934298952469 Test RE 1.183605042584637\n",
      "143 Train Loss 0.9233472 Test MSE 6.1312818880364865 Test RE 1.1835420757170034\n",
      "144 Train Loss 0.91805255 Test MSE 6.154732129243307 Test RE 1.1858032553820632\n",
      "145 Train Loss 0.91253364 Test MSE 6.171977138554311 Test RE 1.1874633507025483\n",
      "146 Train Loss 0.9082037 Test MSE 6.177689012144617 Test RE 1.188012694281792\n",
      "147 Train Loss 0.9040148 Test MSE 6.181450377570532 Test RE 1.188374307652788\n",
      "148 Train Loss 0.9007368 Test MSE 6.186989680244256 Test RE 1.1889066496199876\n",
      "149 Train Loss 0.897594 Test MSE 6.19887962864613 Test RE 1.1900485016697016\n",
      "Training time: 230.82\n",
      "2\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 65.20663 Test MSE 5.741988065060196 Test RE 1.145352592039015\n",
      "1 Train Loss 44.826866 Test MSE 8.152640049078334 Test RE 1.364762856805943\n",
      "2 Train Loss 34.528755 Test MSE 6.803054612225985 Test RE 1.2466944868513068\n",
      "3 Train Loss 27.485264 Test MSE 6.104595215893602 Test RE 1.1809635575968658\n",
      "4 Train Loss 22.60551 Test MSE 5.586192094807729 Test RE 1.1297074511745178\n",
      "5 Train Loss 18.084438 Test MSE 5.230298519241136 Test RE 1.0931287048514378\n",
      "6 Train Loss 15.016619 Test MSE 5.5255392833954575 Test RE 1.1235577395757779\n",
      "7 Train Loss 12.609474 Test MSE 5.251179918739466 Test RE 1.0953086301302069\n",
      "8 Train Loss 10.762725 Test MSE 5.2498853609259 Test RE 1.095173610213895\n",
      "9 Train Loss 9.56653 Test MSE 4.878426520084314 Test RE 1.0557180435283242\n",
      "10 Train Loss 8.640442 Test MSE 4.786399650093298 Test RE 1.0457130776460568\n",
      "11 Train Loss 8.137534 Test MSE 4.507122804744472 Test RE 1.014746953092803\n",
      "12 Train Loss 7.46776 Test MSE 4.47530187094725 Test RE 1.0111584785322951\n",
      "13 Train Loss 6.7633543 Test MSE 3.9429868908774184 Test RE 0.9491191298995524\n",
      "14 Train Loss 5.5509076 Test MSE 3.7604302747977103 Test RE 0.9268870842826313\n",
      "15 Train Loss 4.7069016 Test MSE 3.553293226144264 Test RE 0.9009974965228142\n",
      "16 Train Loss 3.786869 Test MSE 3.4132395379891736 Test RE 0.8830625034021445\n",
      "17 Train Loss 3.047837 Test MSE 3.177784630147522 Test RE 0.8520602208343249\n",
      "18 Train Loss 2.5761366 Test MSE 3.005855267677496 Test RE 0.8286899901708593\n",
      "19 Train Loss 2.294283 Test MSE 2.857818616735103 Test RE 0.808026103122104\n",
      "20 Train Loss 1.9978861 Test MSE 2.712909013757826 Test RE 0.7872735750720243\n",
      "21 Train Loss 1.7458248 Test MSE 2.482329122201742 Test RE 0.7530741520558549\n",
      "22 Train Loss 1.5759318 Test MSE 2.3952306406181516 Test RE 0.7397444740313408\n",
      "23 Train Loss 1.4022756 Test MSE 2.4149963134864456 Test RE 0.7427904242317707\n",
      "24 Train Loss 1.2989327 Test MSE 2.3933618882731356 Test RE 0.7394558444233266\n",
      "25 Train Loss 1.2325131 Test MSE 2.4477089436586024 Test RE 0.7478042820001378\n",
      "26 Train Loss 1.1803938 Test MSE 2.4727965559711587 Test RE 0.7516267947499585\n",
      "27 Train Loss 1.1130673 Test MSE 2.3957597992113184 Test RE 0.7398261823481533\n",
      "28 Train Loss 1.0639756 Test MSE 2.4118322286490175 Test RE 0.7423036694022179\n",
      "29 Train Loss 1.0183449 Test MSE 2.336955812333575 Test RE 0.7306902471276056\n",
      "30 Train Loss 0.9473127 Test MSE 2.201710026438694 Test RE 0.7092316700600967\n",
      "31 Train Loss 0.8864754 Test MSE 2.084329586799779 Test RE 0.6900669962341185\n",
      "32 Train Loss 0.817126 Test MSE 2.0225380761518994 Test RE 0.6797612650207535\n",
      "33 Train Loss 0.74426705 Test MSE 1.9603167473639636 Test RE 0.6692235037388244\n",
      "34 Train Loss 0.68095165 Test MSE 1.7857527483885505 Test RE 0.638732072576429\n",
      "35 Train Loss 0.6298982 Test MSE 1.7339434914248635 Test RE 0.6293982487901397\n",
      "36 Train Loss 0.5980867 Test MSE 1.7297816197445826 Test RE 0.628642443168987\n",
      "37 Train Loss 0.5561804 Test MSE 1.7029328118886713 Test RE 0.6237446261896629\n",
      "38 Train Loss 0.5232396 Test MSE 1.697278645284591 Test RE 0.6227082704655219\n",
      "39 Train Loss 0.49412906 Test MSE 1.67491960646424 Test RE 0.6185930602064447\n",
      "40 Train Loss 0.45867503 Test MSE 1.6879256334736046 Test RE 0.6209901543198105\n",
      "41 Train Loss 0.4240579 Test MSE 1.6318606857864715 Test RE 0.6105898774019038\n",
      "42 Train Loss 0.3933903 Test MSE 1.6193087276297484 Test RE 0.6082370744618955\n",
      "43 Train Loss 0.36512697 Test MSE 1.5939705981631502 Test RE 0.6034596178773911\n",
      "44 Train Loss 0.34393725 Test MSE 1.5523744990126647 Test RE 0.5955336560112565\n",
      "45 Train Loss 0.32765374 Test MSE 1.5656536663097576 Test RE 0.5980753594267992\n",
      "46 Train Loss 0.31396285 Test MSE 1.5273602722195112 Test RE 0.5907160967158132\n",
      "47 Train Loss 0.29986426 Test MSE 1.506014860903368 Test RE 0.586573838028804\n",
      "48 Train Loss 0.2841139 Test MSE 1.4920584338203893 Test RE 0.5838495854744123\n",
      "49 Train Loss 0.27423516 Test MSE 1.4937652203980836 Test RE 0.584183426896671\n",
      "50 Train Loss 0.25958487 Test MSE 1.4835460576060946 Test RE 0.5821817365337068\n",
      "51 Train Loss 0.23700559 Test MSE 1.444135254010875 Test RE 0.5743967782353759\n",
      "52 Train Loss 0.21915787 Test MSE 1.413780842542728 Test RE 0.5683280698890943\n",
      "53 Train Loss 0.20909625 Test MSE 1.3875384410808103 Test RE 0.5630287504853522\n",
      "54 Train Loss 0.19459891 Test MSE 1.3708808001539425 Test RE 0.5596389167177297\n",
      "55 Train Loss 0.18697299 Test MSE 1.3593956120575774 Test RE 0.5572896689291961\n",
      "56 Train Loss 0.17368102 Test MSE 1.3441860117846878 Test RE 0.5541632811959429\n",
      "57 Train Loss 0.16572337 Test MSE 1.3540998511725968 Test RE 0.5562031004884217\n",
      "58 Train Loss 0.15492946 Test MSE 1.3240843858162616 Test RE 0.5500040562203953\n",
      "59 Train Loss 0.15018314 Test MSE 1.3387748292685608 Test RE 0.5530467308795588\n",
      "60 Train Loss 0.14657411 Test MSE 1.3228354885779012 Test RE 0.5497446087848413\n",
      "61 Train Loss 0.14336947 Test MSE 1.3110850250457164 Test RE 0.5472975308021217\n",
      "62 Train Loss 0.13857687 Test MSE 1.2948094634886096 Test RE 0.5438898983271735\n",
      "63 Train Loss 0.13615936 Test MSE 1.2788985403114734 Test RE 0.5405378453057958\n",
      "64 Train Loss 0.13361792 Test MSE 1.2721502815631285 Test RE 0.5391098532755697\n",
      "65 Train Loss 0.1290952 Test MSE 1.2499169722604802 Test RE 0.5343780894528164\n",
      "66 Train Loss 0.12340885 Test MSE 1.231231791800977 Test RE 0.5303688034691699\n",
      "67 Train Loss 0.11973734 Test MSE 1.2109898189743813 Test RE 0.5259909915996555\n",
      "68 Train Loss 0.114650205 Test MSE 1.2152416635216245 Test RE 0.5269135725651054\n",
      "69 Train Loss 0.11140962 Test MSE 1.212261861557513 Test RE 0.5262671736606482\n",
      "70 Train Loss 0.1091143 Test MSE 1.2218283838648865 Test RE 0.5283396026164118\n",
      "71 Train Loss 0.105118945 Test MSE 1.1974083291103306 Test RE 0.5230331285616708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 Train Loss 0.100635186 Test MSE 1.1599238980536088 Test RE 0.5147813547172955\n",
      "73 Train Loss 0.095968165 Test MSE 1.1399282164342532 Test RE 0.5103249623280227\n",
      "74 Train Loss 0.092575334 Test MSE 1.1336156210794979 Test RE 0.5089099840720034\n",
      "75 Train Loss 0.08786552 Test MSE 1.1051973964886592 Test RE 0.5024906520296584\n",
      "76 Train Loss 0.08192633 Test MSE 1.081817306347598 Test RE 0.4971472285218865\n",
      "77 Train Loss 0.07893127 Test MSE 1.0822200806391575 Test RE 0.49723976701580097\n",
      "78 Train Loss 0.07557874 Test MSE 1.0643455085134457 Test RE 0.49311632017643237\n",
      "79 Train Loss 0.0718163 Test MSE 1.051369637747853 Test RE 0.49010121116723343\n",
      "80 Train Loss 0.06903917 Test MSE 1.0405100396478542 Test RE 0.4875635132224886\n",
      "81 Train Loss 0.06694757 Test MSE 1.0289011169693332 Test RE 0.4848360224099156\n",
      "82 Train Loss 0.06521668 Test MSE 1.0153089686036747 Test RE 0.4816229478343622\n",
      "83 Train Loss 0.061567828 Test MSE 0.997427646705125 Test RE 0.47736300770886714\n",
      "84 Train Loss 0.059776258 Test MSE 0.9920957631584589 Test RE 0.4760853939476188\n",
      "85 Train Loss 0.05777318 Test MSE 0.9740992293461455 Test RE 0.4717475573907475\n",
      "86 Train Loss 0.05490975 Test MSE 0.9673201557477724 Test RE 0.470103169036386\n",
      "87 Train Loss 0.052495163 Test MSE 0.9564943189972651 Test RE 0.46746516982537206\n",
      "88 Train Loss 0.050131954 Test MSE 0.9505528178169145 Test RE 0.4660110203087213\n",
      "89 Train Loss 0.047715947 Test MSE 0.9423161954241807 Test RE 0.4639876146244046\n",
      "90 Train Loss 0.046049 Test MSE 0.9392699947902611 Test RE 0.4632370473056131\n",
      "91 Train Loss 0.04466041 Test MSE 0.9237995270943623 Test RE 0.459406280474425\n",
      "92 Train Loss 0.043152772 Test MSE 0.9183810386478023 Test RE 0.45805698959226904\n",
      "93 Train Loss 0.041623067 Test MSE 0.9015158130286071 Test RE 0.4538316025773057\n",
      "94 Train Loss 0.039695587 Test MSE 0.8981573853326067 Test RE 0.4529854816634836\n",
      "95 Train Loss 0.037524797 Test MSE 0.8775710945629627 Test RE 0.4477640429890773\n",
      "96 Train Loss 0.034445222 Test MSE 0.8702354231411302 Test RE 0.4458886719210212\n",
      "97 Train Loss 0.032281656 Test MSE 0.8555597414409315 Test RE 0.4421129443772116\n",
      "98 Train Loss 0.03139894 Test MSE 0.8526154250910866 Test RE 0.4413515467966573\n",
      "99 Train Loss 0.029889863 Test MSE 0.8378963320037549 Test RE 0.43752533389148823\n",
      "100 Train Loss 0.02862735 Test MSE 0.8297670671056386 Test RE 0.43539772679892486\n",
      "101 Train Loss 0.027355775 Test MSE 0.8251898952252287 Test RE 0.43419519284746705\n",
      "102 Train Loss 0.0267072 Test MSE 0.8122293919048281 Test RE 0.4307719447105465\n",
      "103 Train Loss 0.025616879 Test MSE 0.8082834017398834 Test RE 0.4297242779848192\n",
      "104 Train Loss 0.024465002 Test MSE 0.8043956304241981 Test RE 0.42868956447517065\n",
      "105 Train Loss 0.02366896 Test MSE 0.8017111653352725 Test RE 0.42797364567923263\n",
      "106 Train Loss 0.023074081 Test MSE 0.793236514724601 Test RE 0.4257056450179864\n",
      "107 Train Loss 0.022300623 Test MSE 0.7950141692566994 Test RE 0.42618238433431815\n",
      "108 Train Loss 0.021825176 Test MSE 0.7930449246889879 Test RE 0.4256542316730285\n",
      "109 Train Loss 0.021230968 Test MSE 0.7900947408468882 Test RE 0.42486176188194535\n",
      "110 Train Loss 0.020375958 Test MSE 0.792369478468591 Test RE 0.4254729255595065\n",
      "111 Train Loss 0.019563602 Test MSE 0.7831636878098197 Test RE 0.4229941212892177\n",
      "112 Train Loss 0.018770583 Test MSE 0.7768475985513437 Test RE 0.42128497852419317\n",
      "113 Train Loss 0.018397978 Test MSE 0.7772604087559478 Test RE 0.42139689728468765\n",
      "114 Train Loss 0.017716195 Test MSE 0.7691180198009093 Test RE 0.4191838610715643\n",
      "115 Train Loss 0.016921323 Test MSE 0.7683392838668198 Test RE 0.4189715944245968\n",
      "116 Train Loss 0.016300598 Test MSE 0.7599964867100527 Test RE 0.4166907431075777\n",
      "117 Train Loss 0.015987623 Test MSE 0.7533851577151496 Test RE 0.4148743550551723\n",
      "118 Train Loss 0.015612568 Test MSE 0.7484569329950467 Test RE 0.41351519058242403\n",
      "119 Train Loss 0.015388134 Test MSE 0.7524292538529965 Test RE 0.4146110728080758\n",
      "120 Train Loss 0.014979823 Test MSE 0.7529838465346308 Test RE 0.4147638432583494\n",
      "121 Train Loss 0.014661729 Test MSE 0.7446161753004782 Test RE 0.4124528352693703\n",
      "122 Train Loss 0.014112629 Test MSE 0.7496712827894868 Test RE 0.41385051286203667\n",
      "123 Train Loss 0.013732403 Test MSE 0.7510249859963061 Test RE 0.4142239952809996\n",
      "124 Train Loss 0.013027219 Test MSE 0.7501430836708253 Test RE 0.4139807194807408\n",
      "125 Train Loss 0.012761015 Test MSE 0.7482684438867143 Test RE 0.41346311810238184\n",
      "126 Train Loss 0.0123810265 Test MSE 0.7524264162995359 Test RE 0.41461029101883273\n",
      "127 Train Loss 0.012159056 Test MSE 0.7491620100811903 Test RE 0.41370991885584907\n",
      "128 Train Loss 0.011857804 Test MSE 0.7424788764973356 Test RE 0.41186047072952225\n",
      "129 Train Loss 0.011588023 Test MSE 0.7424620086322363 Test RE 0.4118557923160769\n",
      "130 Train Loss 0.011348725 Test MSE 0.7375889373047558 Test RE 0.41050198116565867\n",
      "131 Train Loss 0.011187149 Test MSE 0.7375689824143838 Test RE 0.4104964282234835\n",
      "132 Train Loss 0.011039669 Test MSE 0.7339243918653848 Test RE 0.40948096784032256\n",
      "133 Train Loss 0.010934584 Test MSE 0.7333387556252318 Test RE 0.40931756221247007\n",
      "134 Train Loss 0.0108166365 Test MSE 0.7319427141503968 Test RE 0.4089277720233594\n",
      "135 Train Loss 0.010630867 Test MSE 0.7266380225011799 Test RE 0.40744324301596563\n",
      "136 Train Loss 0.010440184 Test MSE 0.7241084942312327 Test RE 0.4067334413788618\n",
      "137 Train Loss 0.010168135 Test MSE 0.7107619771225114 Test RE 0.40296762311112244\n",
      "138 Train Loss 0.009927275 Test MSE 0.7059447522502779 Test RE 0.4015997348210842\n",
      "139 Train Loss 0.009760186 Test MSE 0.6983332247017658 Test RE 0.39942883422216097\n",
      "140 Train Loss 0.009470166 Test MSE 0.6955484680826604 Test RE 0.3986316337138063\n",
      "141 Train Loss 0.009283191 Test MSE 0.6900819397492772 Test RE 0.3970620596701015\n",
      "142 Train Loss 0.009206307 Test MSE 0.6881460423736089 Test RE 0.3965047264000428\n",
      "143 Train Loss 0.009031801 Test MSE 0.6896117847677655 Test RE 0.39692677681313804\n",
      "144 Train Loss 0.0089164805 Test MSE 0.6853802076308634 Test RE 0.395707097229651\n",
      "145 Train Loss 0.008668126 Test MSE 0.673591217394731 Test RE 0.3922891244996264\n",
      "146 Train Loss 0.008477368 Test MSE 0.6620270016067418 Test RE 0.3889071358013309\n",
      "147 Train Loss 0.008315312 Test MSE 0.6645508206011737 Test RE 0.38964773817092985\n",
      "148 Train Loss 0.00813347 Test MSE 0.656616018037907 Test RE 0.38731453631387114\n",
      "149 Train Loss 0.007998979 Test MSE 0.6559986738426284 Test RE 0.38713241875810206\n",
      "Training time: 229.58\n",
      "3\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 60.45284 Test MSE 5.966272246748012 Test RE 1.1675072702243356\n",
      "1 Train Loss 47.553596 Test MSE 8.53292852722997 Test RE 1.3962304791697795\n",
      "2 Train Loss 39.16213 Test MSE 8.791572356038595 Test RE 1.4172332656947522\n",
      "3 Train Loss 34.041508 Test MSE 8.855697622996578 Test RE 1.422392487511704\n",
      "4 Train Loss 30.533804 Test MSE 8.838962455969414 Test RE 1.4210478598225242\n",
      "5 Train Loss 27.184443 Test MSE 8.737225157450071 Test RE 1.4128459924384071\n",
      "6 Train Loss 24.534908 Test MSE 8.665070666183267 Test RE 1.4070000559709364\n",
      "7 Train Loss 22.172184 Test MSE 9.094657257423334 Test RE 1.4414554638691823\n",
      "8 Train Loss 20.122925 Test MSE 8.983972661753995 Test RE 1.4326571485384512\n",
      "9 Train Loss 18.300087 Test MSE 8.99507090724338 Test RE 1.4335417835380204\n",
      "10 Train Loss 17.05269 Test MSE 8.793798950524778 Test RE 1.4174127218757298\n",
      "11 Train Loss 15.695787 Test MSE 8.482141825486766 Test RE 1.3920692016456093\n",
      "12 Train Loss 14.34679 Test MSE 8.076597473050672 Test RE 1.3583831309537604\n",
      "13 Train Loss 12.134722 Test MSE 7.640740775298952 Test RE 1.3212219894819919\n",
      "14 Train Loss 10.399539 Test MSE 6.77947435194375 Test RE 1.2445320098327957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Train Loss 8.170076 Test MSE 6.043430321946583 Test RE 1.17503234054006\n",
      "16 Train Loss 6.367038 Test MSE 5.74893046583299 Test RE 1.1460447821502853\n",
      "17 Train Loss 5.2975187 Test MSE 5.442491832150193 Test RE 1.1150823797337608\n",
      "18 Train Loss 4.42261 Test MSE 5.318861580586934 Test RE 1.102344664558269\n",
      "19 Train Loss 3.8064933 Test MSE 5.298196077171129 Test RE 1.100201097030497\n",
      "20 Train Loss 3.384924 Test MSE 5.563316695794799 Test RE 1.1273920081335262\n",
      "21 Train Loss 3.0442123 Test MSE 5.423848428618227 Test RE 1.1131708688635222\n",
      "22 Train Loss 2.8089876 Test MSE 5.462027464304662 Test RE 1.1170818614774545\n",
      "23 Train Loss 2.6088428 Test MSE 5.384250805754474 Test RE 1.1090999893902704\n",
      "24 Train Loss 2.4373312 Test MSE 5.388504276399316 Test RE 1.1095379883889407\n",
      "25 Train Loss 2.3167965 Test MSE 5.321058906825308 Test RE 1.1025723411676716\n",
      "26 Train Loss 2.2044437 Test MSE 5.354343987865804 Test RE 1.1060154525466062\n",
      "27 Train Loss 2.0964978 Test MSE 5.387140988378081 Test RE 1.109397623321369\n",
      "28 Train Loss 2.0382857 Test MSE 5.345925993564953 Test RE 1.1051456826834645\n",
      "29 Train Loss 1.9748852 Test MSE 5.374736732208455 Test RE 1.108119655747306\n",
      "30 Train Loss 1.912304 Test MSE 5.4327579013757825 Test RE 1.1140847675605314\n",
      "31 Train Loss 1.8578379 Test MSE 5.466333540108155 Test RE 1.1175221093086982\n",
      "32 Train Loss 1.8079562 Test MSE 5.445169397344628 Test RE 1.1153566418483194\n",
      "33 Train Loss 1.7529038 Test MSE 5.392399441263551 Test RE 1.1099389394156223\n",
      "34 Train Loss 1.697128 Test MSE 5.402632479911801 Test RE 1.1109915936945476\n",
      "35 Train Loss 1.6458501 Test MSE 5.4342714034890145 Test RE 1.1142399421753635\n",
      "36 Train Loss 1.6033247 Test MSE 5.487168462198773 Test RE 1.119649800735612\n",
      "37 Train Loss 1.5749894 Test MSE 5.431755379269237 Test RE 1.1139819702190152\n",
      "38 Train Loss 1.5356336 Test MSE 5.428167363430193 Test RE 1.1136139818839865\n",
      "39 Train Loss 1.4951482 Test MSE 5.466024996807664 Test RE 1.1174905699941704\n",
      "40 Train Loss 1.4570105 Test MSE 5.485165369478317 Test RE 1.1194454178103908\n",
      "41 Train Loss 1.4346546 Test MSE 5.437427964055922 Test RE 1.1145635048946239\n",
      "42 Train Loss 1.4047225 Test MSE 5.487674471176195 Test RE 1.1197014247921564\n",
      "43 Train Loss 1.3796074 Test MSE 5.5229894024536 Test RE 1.1232984645151296\n",
      "44 Train Loss 1.3534262 Test MSE 5.526201906317859 Test RE 1.123625106103828\n",
      "45 Train Loss 1.3283969 Test MSE 5.580346440337775 Test RE 1.1291162069193317\n",
      "46 Train Loss 1.3001935 Test MSE 5.555927761008102 Test RE 1.1266430849394646\n",
      "47 Train Loss 1.27847 Test MSE 5.619961826588188 Test RE 1.133116968290418\n",
      "48 Train Loss 1.253231 Test MSE 5.601231668388682 Test RE 1.1312271713844788\n",
      "49 Train Loss 1.2238829 Test MSE 5.640290344770431 Test RE 1.1351644729728603\n",
      "50 Train Loss 1.2077948 Test MSE 5.651283336004217 Test RE 1.136270158841734\n",
      "51 Train Loss 1.1920753 Test MSE 5.632916788871919 Test RE 1.134422229616132\n",
      "52 Train Loss 1.1791394 Test MSE 5.631671895023076 Test RE 1.134296867095754\n",
      "53 Train Loss 1.1597363 Test MSE 5.621844035402984 Test RE 1.1333067012697624\n",
      "54 Train Loss 1.1465424 Test MSE 5.628225355120298 Test RE 1.1339497234942966\n",
      "55 Train Loss 1.1349461 Test MSE 5.624537221837436 Test RE 1.1335781282923452\n",
      "56 Train Loss 1.1240963 Test MSE 5.63701818797564 Test RE 1.134835148169018\n",
      "57 Train Loss 1.117063 Test MSE 5.661860204162783 Test RE 1.1373329759876247\n",
      "58 Train Loss 1.1070449 Test MSE 5.676973035050322 Test RE 1.138849868464521\n",
      "59 Train Loss 1.0985532 Test MSE 5.697854333719127 Test RE 1.1409424305079354\n",
      "60 Train Loss 1.0895023 Test MSE 5.70799103260027 Test RE 1.1419568694471738\n",
      "61 Train Loss 1.0811315 Test MSE 5.711511583497536 Test RE 1.1423089808591298\n",
      "62 Train Loss 1.0724773 Test MSE 5.701379219667374 Test RE 1.1412952887866052\n",
      "63 Train Loss 1.0641224 Test MSE 5.7084792556486725 Test RE 1.1420057060465516\n",
      "64 Train Loss 1.0577863 Test MSE 5.726139913044812 Test RE 1.1437708868877567\n",
      "65 Train Loss 1.0477469 Test MSE 5.744532832609625 Test RE 1.1456063659248057\n",
      "66 Train Loss 1.0384251 Test MSE 5.742984042300502 Test RE 1.1454519213686951\n",
      "67 Train Loss 1.0329661 Test MSE 5.744228595481005 Test RE 1.1455760292014991\n",
      "68 Train Loss 1.0255743 Test MSE 5.75306471283667 Test RE 1.1464567875417122\n",
      "69 Train Loss 1.016764 Test MSE 5.7643953739832074 Test RE 1.1475852055511042\n",
      "70 Train Loss 1.0105064 Test MSE 5.810958312741304 Test RE 1.1522107961151968\n",
      "71 Train Loss 1.0042353 Test MSE 5.7954846521216234 Test RE 1.150675696172463\n",
      "72 Train Loss 0.99872977 Test MSE 5.8017414165756955 Test RE 1.1512966593135965\n",
      "73 Train Loss 0.98889756 Test MSE 5.816783865308678 Test RE 1.1527882037270247\n",
      "74 Train Loss 0.98238546 Test MSE 5.824137198834803 Test RE 1.153516626771467\n",
      "75 Train Loss 0.97709835 Test MSE 5.829157611172936 Test RE 1.1540136859456742\n",
      "76 Train Loss 0.9685074 Test MSE 5.825475605638124 Test RE 1.1536491602061698\n",
      "77 Train Loss 0.96265244 Test MSE 5.8534833355422045 Test RE 1.1564190929134635\n",
      "78 Train Loss 0.9586556 Test MSE 5.8816019801163755 Test RE 1.159193336755252\n",
      "79 Train Loss 0.9530754 Test MSE 5.873951467035765 Test RE 1.1584391791634272\n",
      "80 Train Loss 0.9477088 Test MSE 5.896688137202989 Test RE 1.1606790351473322\n",
      "81 Train Loss 0.94360393 Test MSE 5.885737661674402 Test RE 1.159600811799956\n",
      "82 Train Loss 0.9382685 Test MSE 5.872130094622146 Test RE 1.1582595630428114\n",
      "83 Train Loss 0.93380547 Test MSE 5.882903488413418 Test RE 1.1593215855127306\n",
      "84 Train Loss 0.929431 Test MSE 5.883121132374976 Test RE 1.1593430304513932\n",
      "85 Train Loss 0.9258776 Test MSE 5.901767118019333 Test RE 1.1611787900577728\n",
      "86 Train Loss 0.92016673 Test MSE 5.9046769870191325 Test RE 1.1614650146503513\n",
      "87 Train Loss 0.9156267 Test MSE 5.911277280444594 Test RE 1.1621139806168395\n",
      "88 Train Loss 0.91001916 Test MSE 5.9448127020102035 Test RE 1.1654057281859893\n",
      "89 Train Loss 0.9036513 Test MSE 5.9352736703429265 Test RE 1.1644703492430666\n",
      "90 Train Loss 0.8999194 Test MSE 5.9666714987403315 Test RE 1.1675463332930767\n",
      "91 Train Loss 0.8937811 Test MSE 5.9734199564309725 Test RE 1.1682064090502644\n",
      "92 Train Loss 0.89021873 Test MSE 5.950269857068379 Test RE 1.1659405087777026\n",
      "93 Train Loss 0.8867291 Test MSE 5.959887454686315 Test RE 1.1668824004389542\n",
      "94 Train Loss 0.88174945 Test MSE 5.957128195621824 Test RE 1.1666122524191782\n",
      "95 Train Loss 0.8777343 Test MSE 5.965853613042742 Test RE 1.1674663094327231\n",
      "96 Train Loss 0.8738113 Test MSE 5.96447640372403 Test RE 1.1673315476376906\n",
      "97 Train Loss 0.8700808 Test MSE 5.967080103819191 Test RE 1.1675863101205641\n",
      "98 Train Loss 0.8659339 Test MSE 5.966358081997756 Test RE 1.1675156685100267\n",
      "99 Train Loss 0.86304164 Test MSE 5.986712518040973 Test RE 1.169505482827726\n",
      "100 Train Loss 0.86002207 Test MSE 5.993114807855234 Test RE 1.1701306600238786\n",
      "101 Train Loss 0.85578215 Test MSE 5.987670452293685 Test RE 1.1695990454086713\n",
      "102 Train Loss 0.8524145 Test MSE 5.9989616690305265 Test RE 1.1707013085014133\n",
      "103 Train Loss 0.8487142 Test MSE 6.0015774102043915 Test RE 1.1709565124889079\n",
      "104 Train Loss 0.8460357 Test MSE 6.009468751823737 Test RE 1.1717260920277577\n",
      "105 Train Loss 0.84278876 Test MSE 6.03342230826532 Test RE 1.1740590015813683\n",
      "106 Train Loss 0.83931744 Test MSE 6.051279454740886 Test RE 1.1757951516966145\n",
      "107 Train Loss 0.835477 Test MSE 6.055875249054327 Test RE 1.1762415603533172\n",
      "108 Train Loss 0.83104026 Test MSE 6.068869740243497 Test RE 1.1775028536778152\n",
      "109 Train Loss 0.8280377 Test MSE 6.073232193559268 Test RE 1.1779259867046337\n",
      "110 Train Loss 0.82439613 Test MSE 6.088242376175256 Test RE 1.1793807287901428\n",
      "111 Train Loss 0.8190308 Test MSE 6.088485876989749 Test RE 1.1794043133716123\n",
      "112 Train Loss 0.81464803 Test MSE 6.094465194625572 Test RE 1.1799832998886035\n",
      "113 Train Loss 0.808019 Test MSE 6.112049302917381 Test RE 1.1816843522773846\n",
      "114 Train Loss 0.8034969 Test MSE 6.117009199110541 Test RE 1.1821637203962418\n",
      "115 Train Loss 0.800433 Test MSE 6.124762843391557 Test RE 1.182912711764806\n",
      "116 Train Loss 0.7967837 Test MSE 6.13572604784979 Test RE 1.1839709336167366\n",
      "117 Train Loss 0.79322267 Test MSE 6.1469483442457875 Test RE 1.1850531855569235\n",
      "118 Train Loss 0.7884902 Test MSE 6.145397478907263 Test RE 1.1849036826049184\n",
      "119 Train Loss 0.7857181 Test MSE 6.141501293144091 Test RE 1.1845280082210097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 Train Loss 0.78318155 Test MSE 6.171943349384835 Test RE 1.1874601002485674\n",
      "121 Train Loss 0.7809104 Test MSE 6.175666258127927 Test RE 1.1878181835040282\n",
      "122 Train Loss 0.77905667 Test MSE 6.170620929892415 Test RE 1.1873328790138147\n",
      "123 Train Loss 0.77694356 Test MSE 6.195345605632125 Test RE 1.1897092259752058\n",
      "124 Train Loss 0.77484274 Test MSE 6.201655309390527 Test RE 1.1903149066672665\n",
      "125 Train Loss 0.7729894 Test MSE 6.209846705532387 Test RE 1.191100755195733\n",
      "126 Train Loss 0.77159774 Test MSE 6.202106860505542 Test RE 1.190358240117213\n",
      "127 Train Loss 0.76930046 Test MSE 6.2038565097085305 Test RE 1.1905261316521096\n",
      "128 Train Loss 0.7668969 Test MSE 6.209820902444493 Test RE 1.1910982805686723\n",
      "129 Train Loss 0.7647633 Test MSE 6.209387967342558 Test RE 1.1910567594643007\n",
      "130 Train Loss 0.7627944 Test MSE 6.225231856261236 Test RE 1.1925753429883048\n",
      "131 Train Loss 0.7606666 Test MSE 6.230831093809494 Test RE 1.1931115488645756\n",
      "132 Train Loss 0.75890553 Test MSE 6.243436671385215 Test RE 1.1943178294448982\n",
      "133 Train Loss 0.75687915 Test MSE 6.254767943082021 Test RE 1.19540112745367\n",
      "134 Train Loss 0.7538393 Test MSE 6.259523783816894 Test RE 1.1958555053905444\n",
      "135 Train Loss 0.7513062 Test MSE 6.261361461568648 Test RE 1.1960310327839137\n",
      "136 Train Loss 0.74897397 Test MSE 6.267594832542593 Test RE 1.1966262268641588\n",
      "137 Train Loss 0.7470895 Test MSE 6.267223616058755 Test RE 1.1965907895098111\n",
      "138 Train Loss 0.74509 Test MSE 6.275282342349045 Test RE 1.197359862098209\n",
      "139 Train Loss 0.7433586 Test MSE 6.285671312385497 Test RE 1.1983505897547582\n",
      "140 Train Loss 0.74190915 Test MSE 6.293371247188129 Test RE 1.1990843536481368\n",
      "141 Train Loss 0.7403032 Test MSE 6.29671937587322 Test RE 1.199403272931794\n",
      "142 Train Loss 0.7389432 Test MSE 6.310641125695284 Test RE 1.2007284529172964\n",
      "143 Train Loss 0.7373809 Test MSE 6.314852519009319 Test RE 1.2011290379218986\n",
      "144 Train Loss 0.7356119 Test MSE 6.326607864651842 Test RE 1.2022464925244283\n",
      "145 Train Loss 0.73390406 Test MSE 6.3258727427487225 Test RE 1.2021766428179752\n",
      "146 Train Loss 0.7327564 Test MSE 6.325983718882272 Test RE 1.2021871877922397\n",
      "147 Train Loss 0.7308243 Test MSE 6.335533649794185 Test RE 1.2030942779307838\n",
      "148 Train Loss 0.72933674 Test MSE 6.327804535211561 Test RE 1.2023601889150184\n",
      "149 Train Loss 0.7277153 Test MSE 6.350968310899776 Test RE 1.2045588788271038\n",
      "Training time: 229.54\n",
      "4\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 53.9849 Test MSE 7.799114014536787 Test RE 1.3348445569723537\n",
      "1 Train Loss 38.715122 Test MSE 7.862313305755744 Test RE 1.3402420300460334\n",
      "2 Train Loss 26.635178 Test MSE 6.788356153595422 Test RE 1.2453469748206958\n",
      "3 Train Loss 20.149414 Test MSE 6.448913831685225 Test RE 1.2138117781239874\n",
      "4 Train Loss 15.904688 Test MSE 5.539197709204447 Test RE 1.1249455279516092\n",
      "5 Train Loss 11.5961685 Test MSE 5.20903996053422 Test RE 1.0909049310227377\n",
      "6 Train Loss 9.052416 Test MSE 4.72265051716734 Test RE 1.0387259091694747\n",
      "7 Train Loss 7.890964 Test MSE 4.336570892115148 Test RE 0.995362524506992\n",
      "8 Train Loss 6.8615093 Test MSE 3.8558834627010965 Test RE 0.9385772216458752\n",
      "9 Train Loss 6.1625185 Test MSE 3.402199953542456 Test RE 0.8816332836895272\n",
      "10 Train Loss 5.225933 Test MSE 3.1508092875457465 Test RE 0.8484360604967701\n",
      "11 Train Loss 4.385232 Test MSE 2.7515367750362723 Test RE 0.7928585631845511\n",
      "12 Train Loss 3.8294134 Test MSE 2.676820204554334 Test RE 0.7820196415268331\n",
      "13 Train Loss 3.1504571 Test MSE 2.404016410410175 Test RE 0.7410999334215093\n",
      "14 Train Loss 2.731556 Test MSE 2.280046212145421 Test RE 0.7217385204612684\n",
      "15 Train Loss 2.477756 Test MSE 2.1816957172952973 Test RE 0.7060007295494315\n",
      "16 Train Loss 2.233366 Test MSE 2.1091017033428603 Test RE 0.6941555838205504\n",
      "17 Train Loss 1.9560738 Test MSE 1.9129505414789572 Test RE 0.6610890003249001\n",
      "18 Train Loss 1.7571021 Test MSE 1.865604050437331 Test RE 0.652856599001258\n",
      "19 Train Loss 1.6003808 Test MSE 1.7876978618713595 Test RE 0.6390798441903374\n",
      "20 Train Loss 1.4680285 Test MSE 1.6973248885653074 Test RE 0.6227167534206625\n",
      "21 Train Loss 1.3399147 Test MSE 1.6270754602665065 Test RE 0.6096939812646628\n",
      "22 Train Loss 1.2414792 Test MSE 1.5305444794721335 Test RE 0.5913315321133494\n",
      "23 Train Loss 1.1681261 Test MSE 1.4675477784479214 Test RE 0.5790341591289119\n",
      "24 Train Loss 1.0986611 Test MSE 1.3790533780052838 Test RE 0.5613045962870801\n",
      "25 Train Loss 1.0475242 Test MSE 1.3117484001976987 Test RE 0.5474359724981817\n",
      "26 Train Loss 0.9933792 Test MSE 1.1434306814885002 Test RE 0.5111083557335416\n",
      "27 Train Loss 0.9257675 Test MSE 0.9552573063153846 Test RE 0.4671627909111926\n",
      "28 Train Loss 0.75969386 Test MSE 0.7660700075603301 Test RE 0.41835242436146647\n",
      "29 Train Loss 0.6259117 Test MSE 0.5727749906929247 Test RE 0.3617429565219665\n",
      "30 Train Loss 0.53517914 Test MSE 0.5560962565066456 Test RE 0.3564372185856922\n",
      "31 Train Loss 0.4580471 Test MSE 0.46239909081591424 Test RE 0.32502483465096715\n",
      "32 Train Loss 0.3970518 Test MSE 0.41883708752100063 Test RE 0.30933611422063584\n",
      "33 Train Loss 0.33785245 Test MSE 0.37989358173704246 Test RE 0.2946042708024455\n",
      "34 Train Loss 0.2933659 Test MSE 0.3432550519239651 Test RE 0.28003771748027617\n",
      "35 Train Loss 0.2661079 Test MSE 0.30507909128343996 Test RE 0.26400629498291833\n",
      "36 Train Loss 0.21891774 Test MSE 0.24549894583993837 Test RE 0.23682790658117872\n",
      "37 Train Loss 0.1956729 Test MSE 0.17224430763488774 Test RE 0.19837205820551027\n",
      "38 Train Loss 0.16296354 Test MSE 0.09665465711422608 Test RE 0.1486002200464463\n",
      "39 Train Loss 0.14044453 Test MSE 0.07063381687203882 Test RE 0.1270323691687009\n",
      "40 Train Loss 0.1208784 Test MSE 0.048912780925262106 Test RE 0.10571077040132036\n",
      "41 Train Loss 0.096264906 Test MSE 0.028723586153132807 Test RE 0.08100790312665095\n",
      "42 Train Loss 0.081579745 Test MSE 0.020288178100980353 Test RE 0.06808157350482649\n",
      "43 Train Loss 0.071900114 Test MSE 0.02075826303851588 Test RE 0.06886579504096098\n",
      "44 Train Loss 0.06284949 Test MSE 0.015676533637623825 Test RE 0.05984571769897976\n",
      "45 Train Loss 0.04991043 Test MSE 0.011632920564277529 Test RE 0.05155282176231843\n",
      "46 Train Loss 0.04647802 Test MSE 0.010213689367804842 Test RE 0.048305811572940685\n",
      "47 Train Loss 0.041412197 Test MSE 0.008199814882849255 Test RE 0.043282275419056035\n",
      "48 Train Loss 0.039918188 Test MSE 0.007073104785519173 Test RE 0.04019880161305943\n",
      "49 Train Loss 0.037032202 Test MSE 0.005615293234666595 Test RE 0.03581741842608404\n",
      "50 Train Loss 0.034599166 Test MSE 0.004716569856829698 Test RE 0.032826244191085256\n",
      "51 Train Loss 0.03146803 Test MSE 0.005031521273465024 Test RE 0.033904529104883285\n",
      "52 Train Loss 0.028217386 Test MSE 0.00461936008018395 Test RE 0.032486204117282765\n",
      "53 Train Loss 0.02606617 Test MSE 0.004135445559827092 Test RE 0.030737547599880514\n",
      "54 Train Loss 0.025381623 Test MSE 0.003924611855423133 Test RE 0.02994376570583099\n",
      "55 Train Loss 0.023707991 Test MSE 0.003399959532101666 Test RE 0.02787051117608916\n",
      "56 Train Loss 0.021896847 Test MSE 0.0034882475334463807 Test RE 0.028230053954215146\n",
      "57 Train Loss 0.021160629 Test MSE 0.0032476374386675483 Test RE 0.02723904203772531\n",
      "58 Train Loss 0.019047232 Test MSE 0.003886119808239826 Test RE 0.02979656173292721\n",
      "59 Train Loss 0.01721653 Test MSE 0.004560161567099058 Test RE 0.03227737257611832\n",
      "60 Train Loss 0.016526354 Test MSE 0.004236003423160138 Test RE 0.031109011500828846\n",
      "61 Train Loss 0.016100032 Test MSE 0.00412124819920744 Test RE 0.030684739839601852\n",
      "62 Train Loss 0.015140038 Test MSE 0.004358733375187869 Test RE 0.03155645521002622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 Train Loss 0.014065318 Test MSE 0.0031737224484395888 Test RE 0.026927282840729216\n",
      "64 Train Loss 0.013688629 Test MSE 0.002912419061522692 Test RE 0.025794967954783088\n",
      "65 Train Loss 0.012652215 Test MSE 0.002485483254305799 Test RE 0.023829420500390965\n",
      "66 Train Loss 0.012172408 Test MSE 0.0025401331488696006 Test RE 0.024089972339059462\n",
      "67 Train Loss 0.011452835 Test MSE 0.002567187152036203 Test RE 0.02421791918213411\n",
      "68 Train Loss 0.01100422 Test MSE 0.0025496991284258723 Test RE 0.024135290363244775\n",
      "69 Train Loss 0.010745348 Test MSE 0.0021961865073896586 Test RE 0.022399724136049903\n",
      "70 Train Loss 0.010192977 Test MSE 0.0020908561152569493 Test RE 0.02185597241955815\n",
      "71 Train Loss 0.009691424 Test MSE 0.0017158922263600105 Test RE 0.019799447140785572\n",
      "72 Train Loss 0.009495202 Test MSE 0.0016888836773546682 Test RE 0.01964300510270616\n",
      "73 Train Loss 0.009010525 Test MSE 0.0016814023497647647 Test RE 0.019599450042146346\n",
      "74 Train Loss 0.008845524 Test MSE 0.001519324669119951 Test RE 0.01863087941809365\n",
      "75 Train Loss 0.0085980985 Test MSE 0.0015647924234407833 Test RE 0.018907600940172457\n",
      "76 Train Loss 0.0077911285 Test MSE 0.0013995652703420024 Test RE 0.01788152848383483\n",
      "77 Train Loss 0.0073180255 Test MSE 0.0014168402185562733 Test RE 0.01799154661614006\n",
      "78 Train Loss 0.007178153 Test MSE 0.0013526009233676103 Test RE 0.017578948752881775\n",
      "79 Train Loss 0.0070110895 Test MSE 0.0013280329320296672 Test RE 0.017418569375291675\n",
      "80 Train Loss 0.006476985 Test MSE 0.0011943068793012113 Test RE 0.016518325782147104\n",
      "81 Train Loss 0.0061410298 Test MSE 0.0011086475116840562 Test RE 0.015914932594584933\n",
      "82 Train Loss 0.0057908543 Test MSE 0.0011549581469356576 Test RE 0.016243932778926235\n",
      "83 Train Loss 0.005683896 Test MSE 0.0011146216033078619 Test RE 0.015957754828156687\n",
      "84 Train Loss 0.0056210244 Test MSE 0.0011057424478824354 Test RE 0.015894067431720726\n",
      "85 Train Loss 0.0055814413 Test MSE 0.0011002065814035478 Test RE 0.01585423092258116\n",
      "86 Train Loss 0.005477587 Test MSE 0.0012149699206126787 Test RE 0.016660607123333115\n",
      "87 Train Loss 0.005181458 Test MSE 0.0011529433797289924 Test RE 0.01622975822697337\n",
      "88 Train Loss 0.0050584814 Test MSE 0.001098734094761921 Test RE 0.015843617934075387\n",
      "89 Train Loss 0.0049884594 Test MSE 0.0010174976810930656 Test RE 0.015246662060414853\n",
      "90 Train Loss 0.0049005724 Test MSE 0.0010112296723396687 Test RE 0.01519962812347792\n",
      "91 Train Loss 0.004779784 Test MSE 0.0009535016631237957 Test RE 0.014759402883414914\n",
      "92 Train Loss 0.00457124 Test MSE 0.0008346555160084959 Test RE 0.013808982976093167\n",
      "93 Train Loss 0.004409683 Test MSE 0.0008018348958553299 Test RE 0.013534759298108698\n",
      "94 Train Loss 0.0042001866 Test MSE 0.0007312004562817753 Test RE 0.012924873081651132\n",
      "95 Train Loss 0.00402733 Test MSE 0.0007203913901547014 Test RE 0.012828985583736002\n",
      "96 Train Loss 0.0039406815 Test MSE 0.0007463179069067771 Test RE 0.013057799364718972\n",
      "97 Train Loss 0.0039047662 Test MSE 0.000732702318052509 Test RE 0.012938139905576634\n",
      "98 Train Loss 0.003858266 Test MSE 0.0007155177877671623 Test RE 0.012785516518963598\n",
      "99 Train Loss 0.0037681572 Test MSE 0.0006921554066245281 Test RE 0.012575054272633772\n",
      "100 Train Loss 0.0036438657 Test MSE 0.000677219023704614 Test RE 0.012438632448210975\n",
      "101 Train Loss 0.0035568657 Test MSE 0.0006487581921461467 Test RE 0.012174453850155642\n",
      "102 Train Loss 0.003449335 Test MSE 0.000604412529169148 Test RE 0.011750999005520924\n",
      "103 Train Loss 0.0033857576 Test MSE 0.0005568258197155116 Test RE 0.01127892588354998\n",
      "104 Train Loss 0.003358563 Test MSE 0.0005673618713097428 Test RE 0.011385133657593072\n",
      "105 Train Loss 0.0033284777 Test MSE 0.0005493265400256544 Test RE 0.011202716642999426\n",
      "106 Train Loss 0.0032684915 Test MSE 0.0005326274289661867 Test RE 0.01103112546474653\n",
      "107 Train Loss 0.0031850229 Test MSE 0.0004992244455497186 Test RE 0.010679624474171973\n",
      "108 Train Loss 0.0031163152 Test MSE 0.0005080246979963844 Test RE 0.010773342662302612\n",
      "109 Train Loss 0.0029990887 Test MSE 0.00043944133241204103 Test RE 0.010019787513707518\n",
      "110 Train Loss 0.0029431407 Test MSE 0.00039577196534176074 Test RE 0.00950890643433933\n",
      "111 Train Loss 0.0028571798 Test MSE 0.0004627840830296326 Test RE 0.010282465641356637\n",
      "112 Train Loss 0.0028205104 Test MSE 0.0004713552335669602 Test RE 0.010377248746014835\n",
      "113 Train Loss 0.002805375 Test MSE 0.000482318612231262 Test RE 0.010497238652657708\n",
      "114 Train Loss 0.0027814077 Test MSE 0.0004937260836447404 Test RE 0.01062064997747708\n",
      "115 Train Loss 0.0027179983 Test MSE 0.0005007393835890887 Test RE 0.010695816303305981\n",
      "116 Train Loss 0.0026637411 Test MSE 0.0004706627025981035 Test RE 0.010369622642342589\n",
      "117 Train Loss 0.002571555 Test MSE 0.0004817023081343111 Test RE 0.010490529851653779\n",
      "118 Train Loss 0.0024824415 Test MSE 0.0004390130354503919 Test RE 0.010014903482103288\n",
      "119 Train Loss 0.0023668287 Test MSE 0.0003930952566059556 Test RE 0.009476696276856475\n",
      "120 Train Loss 0.0022527208 Test MSE 0.00033261732887736453 Test RE 0.008717269969364179\n",
      "121 Train Loss 0.0021859212 Test MSE 0.0003132132182908292 Test RE 0.008459176786099993\n",
      "122 Train Loss 0.0021597599 Test MSE 0.0003115211591879394 Test RE 0.008436296508621205\n",
      "123 Train Loss 0.0021342386 Test MSE 0.0003121851103097385 Test RE 0.008445281945096403\n",
      "124 Train Loss 0.002111053 Test MSE 0.0002951865695690964 Test RE 0.008212140240274415\n",
      "125 Train Loss 0.0020837924 Test MSE 0.0003080171156801206 Test RE 0.008388715875352172\n",
      "126 Train Loss 0.0020484745 Test MSE 0.0002818663036504043 Test RE 0.008024715427657501\n",
      "127 Train Loss 0.00203253 Test MSE 0.00027629602758272076 Test RE 0.007945027060684144\n",
      "128 Train Loss 0.0020157807 Test MSE 0.0002747437780147395 Test RE 0.007922677779746916\n",
      "129 Train Loss 0.0019916245 Test MSE 0.00027451907035455473 Test RE 0.007919437214003079\n",
      "130 Train Loss 0.0019353454 Test MSE 0.0002318179323195605 Test RE 0.007277489277127723\n",
      "131 Train Loss 0.0019032338 Test MSE 0.00024779137664848456 Test RE 0.007524041018707061\n",
      "132 Train Loss 0.0018505709 Test MSE 0.0002442355501916713 Test RE 0.0074698606421164816\n",
      "133 Train Loss 0.0018242712 Test MSE 0.0002528093469330744 Test RE 0.007599843053885432\n",
      "134 Train Loss 0.0017947425 Test MSE 0.00024831597646600667 Test RE 0.007532001391859691\n",
      "135 Train Loss 0.0017527624 Test MSE 0.0002518330251219641 Test RE 0.007585153980493882\n",
      "136 Train Loss 0.0017213187 Test MSE 0.00023840636937126424 Test RE 0.007380180561668979\n",
      "137 Train Loss 0.0017037496 Test MSE 0.0002406427977303935 Test RE 0.00741471554030048\n",
      "138 Train Loss 0.00169192 Test MSE 0.0002583120300453187 Test RE 0.007682107435168612\n",
      "139 Train Loss 0.0016722446 Test MSE 0.0002579175277964218 Test RE 0.0076762390157737925\n",
      "140 Train Loss 0.0016480553 Test MSE 0.00026142921951724805 Test RE 0.007728320484164177\n",
      "141 Train Loss 0.0016344754 Test MSE 0.0002713645766872188 Test RE 0.007873804689783093\n",
      "142 Train Loss 0.0016031011 Test MSE 0.00027554029373522 Test RE 0.007934153872688844\n",
      "143 Train Loss 0.001562818 Test MSE 0.00025552314503770246 Test RE 0.00764052467113218\n",
      "144 Train Loss 0.0015118981 Test MSE 0.00026975764557643706 Test RE 0.007850457042948207\n",
      "145 Train Loss 0.001469885 Test MSE 0.00025667131521421035 Test RE 0.007657671434668779\n",
      "146 Train Loss 0.0014573596 Test MSE 0.0002672310889867347 Test RE 0.007813606770184112\n",
      "147 Train Loss 0.0014511403 Test MSE 0.000266585390915925 Test RE 0.007804161233432653\n",
      "148 Train Loss 0.0014382671 Test MSE 0.0002663664408219074 Test RE 0.007800955744896675\n",
      "149 Train Loss 0.0014264445 Test MSE 0.0002603610887163822 Test RE 0.007712516385784358\n",
      "Training time: 229.97\n",
      "5\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 68.6187 Test MSE 4.868999243364058 Test RE 1.0546974932622653\n",
      "1 Train Loss 52.69016 Test MSE 5.947742067521213 Test RE 1.1656928254473304\n",
      "2 Train Loss 36.193535 Test MSE 8.534424228969506 Test RE 1.3963528435399677\n",
      "3 Train Loss 31.60262 Test MSE 8.033920849975537 Test RE 1.3547895392334377\n",
      "4 Train Loss 29.750013 Test MSE 8.034814727204095 Test RE 1.3548649060348925\n",
      "5 Train Loss 28.661594 Test MSE 8.511971838762427 Test RE 1.3945148691719487\n",
      "6 Train Loss 27.83434 Test MSE 8.840272963579478 Test RE 1.4211532016553896\n",
      "7 Train Loss 26.71397 Test MSE 8.928476378452503 Test RE 1.4282253501204765\n",
      "8 Train Loss 25.414661 Test MSE 9.00677863724659 Test RE 1.4344744088966954\n",
      "9 Train Loss 24.137661 Test MSE 9.071538565360997 Test RE 1.4396222023819667\n",
      "10 Train Loss 22.945297 Test MSE 9.063607985156388 Test RE 1.438992786786189\n",
      "11 Train Loss 21.11549 Test MSE 8.85149510530301 Test RE 1.4220549455586213\n",
      "12 Train Loss 18.694847 Test MSE 7.991728310164338 Test RE 1.3512273146847424\n",
      "13 Train Loss 14.644997 Test MSE 6.63838618760178 Test RE 1.2315138976099285\n",
      "14 Train Loss 12.141851 Test MSE 6.523771308996006 Test RE 1.2208362733015625\n",
      "15 Train Loss 10.423338 Test MSE 6.128758278114524 Test RE 1.1832984801702977\n",
      "16 Train Loss 8.601753 Test MSE 5.744179985447122 Test RE 1.1455711820225893\n",
      "17 Train Loss 7.4507213 Test MSE 5.631984371656398 Test RE 1.134328335224257\n",
      "18 Train Loss 5.11493 Test MSE 5.305526885826052 Test RE 1.1009619763600367\n",
      "19 Train Loss 4.0488114 Test MSE 5.554814747100876 Test RE 1.1265302295997364\n",
      "20 Train Loss 3.4952579 Test MSE 5.393274640277219 Test RE 1.1100290086012377\n",
      "21 Train Loss 3.1480515 Test MSE 5.335644360923591 Test RE 1.1040824271716803\n",
      "22 Train Loss 2.9122927 Test MSE 5.444743109233536 Test RE 1.1153129818124772\n",
      "23 Train Loss 2.661861 Test MSE 5.459991870303812 Test RE 1.1168736844724667\n",
      "24 Train Loss 2.465806 Test MSE 5.557032593204366 Test RE 1.1267550995058793\n",
      "25 Train Loss 2.3407469 Test MSE 5.539049061301699 Test RE 1.1249304335350443\n",
      "26 Train Loss 2.2283785 Test MSE 5.668146285255029 Test RE 1.1379641628910913\n",
      "27 Train Loss 2.1067975 Test MSE 5.568613980633974 Test RE 1.1279286210895474\n",
      "28 Train Loss 1.9922355 Test MSE 5.603061543829156 Test RE 1.1314119375131944\n",
      "29 Train Loss 1.9062998 Test MSE 5.575131857188974 Test RE 1.1285885294230285\n",
      "30 Train Loss 1.8595562 Test MSE 5.521886623888691 Test RE 1.12318631408173\n",
      "31 Train Loss 1.784338 Test MSE 5.639919325873192 Test RE 1.135127136739126\n",
      "32 Train Loss 1.7303629 Test MSE 5.578278555396313 Test RE 1.1289069816702073\n",
      "33 Train Loss 1.6763442 Test MSE 5.5922010930187644 Test RE 1.130314894077196\n",
      "34 Train Loss 1.6332144 Test MSE 5.603375212754844 Test RE 1.1314436062533555\n",
      "35 Train Loss 1.5932512 Test MSE 5.592625151949847 Test RE 1.130357749388672\n",
      "36 Train Loss 1.5521691 Test MSE 5.57852292318238 Test RE 1.1289317084273838\n",
      "37 Train Loss 1.514542 Test MSE 5.591106716294424 Test RE 1.1302042890743171\n",
      "38 Train Loss 1.4702516 Test MSE 5.541677223677157 Test RE 1.1251972798106071\n",
      "39 Train Loss 1.4471376 Test MSE 5.551958628622089 Test RE 1.126240578401233\n",
      "40 Train Loss 1.4123015 Test MSE 5.555066805142765 Test RE 1.1265557883083188\n",
      "41 Train Loss 1.38531 Test MSE 5.568551464708953 Test RE 1.1279222897385812\n",
      "42 Train Loss 1.3644147 Test MSE 5.567650136631553 Test RE 1.1278310030568834\n",
      "43 Train Loss 1.3434898 Test MSE 5.572928176883689 Test RE 1.1283654589924965\n",
      "44 Train Loss 1.3260902 Test MSE 5.583000456680673 Test RE 1.1293846791975026\n",
      "45 Train Loss 1.3097832 Test MSE 5.565794140691321 Test RE 1.1276430041535117\n",
      "46 Train Loss 1.2983178 Test MSE 5.553083923554166 Test RE 1.126354708268575\n",
      "47 Train Loss 1.2842381 Test MSE 5.5253250107126215 Test RE 1.1235359543659695\n",
      "48 Train Loss 1.2753205 Test MSE 5.534646849143782 Test RE 1.1244833200760125\n",
      "49 Train Loss 1.2676336 Test MSE 5.495369569544865 Test RE 1.120486201134553\n",
      "50 Train Loss 1.2512078 Test MSE 5.527073034051288 Test RE 1.1237136644335097\n",
      "51 Train Loss 1.2410934 Test MSE 5.5357675647266005 Test RE 1.1245971631290714\n",
      "52 Train Loss 1.2296839 Test MSE 5.543252963253907 Test RE 1.1253572396743186\n",
      "53 Train Loss 1.2149479 Test MSE 5.564368454545675 Test RE 1.127498571217957\n",
      "54 Train Loss 1.2066501 Test MSE 5.5692398673150025 Test RE 1.1279920063114466\n",
      "55 Train Loss 1.1936803 Test MSE 5.5953773241453995 Test RE 1.1306358438836077\n",
      "56 Train Loss 1.184949 Test MSE 5.600715049167247 Test RE 1.131175001860761\n",
      "57 Train Loss 1.1767713 Test MSE 5.612119269850791 Test RE 1.132326069988673\n",
      "58 Train Loss 1.1703159 Test MSE 5.624081984429065 Test RE 1.133532252730383\n",
      "59 Train Loss 1.1623213 Test MSE 5.6417465521788515 Test RE 1.1353110016205996\n",
      "60 Train Loss 1.1531934 Test MSE 5.6301749470000715 Test RE 1.1341461040244947\n",
      "61 Train Loss 1.1471918 Test MSE 5.647781037124622 Test RE 1.1359180109996732\n",
      "62 Train Loss 1.1350105 Test MSE 5.6824036273258 Test RE 1.1393944501380102\n",
      "63 Train Loss 1.1275903 Test MSE 5.703400438785131 Test RE 1.141497573475547\n",
      "64 Train Loss 1.1194364 Test MSE 5.712589692425077 Test RE 1.142416787293685\n",
      "65 Train Loss 1.111941 Test MSE 5.7535853683802465 Test RE 1.1465086638552215\n",
      "66 Train Loss 1.1024184 Test MSE 5.741658954525991 Test RE 1.1453197677801843\n",
      "67 Train Loss 1.0931616 Test MSE 5.710259613717785 Test RE 1.1421837762891371\n",
      "68 Train Loss 1.086782 Test MSE 5.733244954827757 Test RE 1.1444802670948482\n",
      "69 Train Loss 1.0798993 Test MSE 5.7350271620277296 Test RE 1.1446581369137894\n",
      "70 Train Loss 1.0708427 Test MSE 5.774182623483169 Test RE 1.1485590231437597\n",
      "71 Train Loss 1.0632511 Test MSE 5.788613803211847 Test RE 1.1499934009032788\n",
      "72 Train Loss 1.0508342 Test MSE 5.8032703653171875 Test RE 1.1514483514948581\n",
      "73 Train Loss 1.0426015 Test MSE 5.813059675797195 Test RE 1.1524191089457667\n",
      "74 Train Loss 1.0313259 Test MSE 5.862876786497398 Test RE 1.157346609988657\n",
      "75 Train Loss 1.0248325 Test MSE 5.886390858554587 Test RE 1.159665156038684\n",
      "76 Train Loss 1.0122871 Test MSE 5.889915877340636 Test RE 1.1600123322413038\n",
      "77 Train Loss 1.0055026 Test MSE 5.915367344031912 Test RE 1.1625159494261277\n",
      "78 Train Loss 0.9996971 Test MSE 5.940152858248144 Test RE 1.1649488867766393\n",
      "79 Train Loss 0.9938859 Test MSE 5.938576066006138 Test RE 1.1647942607657034\n",
      "80 Train Loss 0.9882858 Test MSE 5.947131317178396 Test RE 1.1656329736949855\n",
      "81 Train Loss 0.98315096 Test MSE 5.953208246303559 Test RE 1.1662283582591066\n",
      "82 Train Loss 0.9785773 Test MSE 5.969408011477664 Test RE 1.1678140402686805\n",
      "83 Train Loss 0.97380936 Test MSE 5.951488958593153 Test RE 1.166059942609187\n",
      "84 Train Loss 0.9694185 Test MSE 5.955138696244148 Test RE 1.1664174296715382\n",
      "85 Train Loss 0.9638921 Test MSE 5.962059873313136 Test RE 1.1670950492617052\n",
      "86 Train Loss 0.95851713 Test MSE 5.970267497363434 Test RE 1.1678981092045075\n",
      "87 Train Loss 0.95379543 Test MSE 5.976054755557152 Test RE 1.1684640210972683\n",
      "88 Train Loss 0.95011055 Test MSE 5.985750189593872 Test RE 1.1694114835232086\n",
      "89 Train Loss 0.9451033 Test MSE 5.982006745073799 Test RE 1.1690457556261917\n",
      "90 Train Loss 0.9401227 Test MSE 5.988166162778942 Test RE 1.1696474591044177\n",
      "91 Train Loss 0.9365649 Test MSE 6.011172467586141 Test RE 1.1718921754891387\n",
      "92 Train Loss 0.9341718 Test MSE 6.016584060069008 Test RE 1.172419558146416\n",
      "93 Train Loss 0.9309913 Test MSE 6.017921406360618 Test RE 1.1725498516662696\n",
      "94 Train Loss 0.92735386 Test MSE 6.033506643137826 Test RE 1.1740672070214282\n",
      "95 Train Loss 0.9237556 Test MSE 6.047832741403498 Test RE 1.1754602468137316\n",
      "96 Train Loss 0.91933244 Test MSE 6.074305349831573 Test RE 1.1780300534341106\n",
      "97 Train Loss 0.91622084 Test MSE 6.0848599521193085 Test RE 1.179053071009996\n",
      "98 Train Loss 0.9123167 Test MSE 6.083156480506893 Test RE 1.178888020044036\n",
      "99 Train Loss 0.909377 Test MSE 6.099028698044504 Test RE 1.1804249998565521\n",
      "100 Train Loss 0.9062786 Test MSE 6.099354427204065 Test RE 1.180456520753452\n",
      "101 Train Loss 0.9000193 Test MSE 6.1001079114914685 Test RE 1.180529432401965\n",
      "102 Train Loss 0.8965875 Test MSE 6.122248033824937 Test RE 1.182669836595281\n",
      "103 Train Loss 0.89451265 Test MSE 6.110132896427115 Test RE 1.181499081757577\n",
      "104 Train Loss 0.89053696 Test MSE 6.117878092740147 Test RE 1.1822476779332158\n",
      "105 Train Loss 0.8871052 Test MSE 6.130284330520327 Test RE 1.1834457908501774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 0.8849068 Test MSE 6.138580611798502 Test RE 1.1842463148606264\n",
      "107 Train Loss 0.8815818 Test MSE 6.135596268891083 Test RE 1.1839584122520104\n",
      "108 Train Loss 0.87955004 Test MSE 6.12785492921237 Test RE 1.1832112707612963\n",
      "109 Train Loss 0.8767214 Test MSE 6.134651959320538 Test RE 1.183867299161126\n",
      "110 Train Loss 0.8746499 Test MSE 6.137868361338499 Test RE 1.184177609690473\n",
      "111 Train Loss 0.87237585 Test MSE 6.134904005576911 Test RE 1.1838916188990638\n",
      "112 Train Loss 0.87015295 Test MSE 6.139850817935994 Test RE 1.1843688317114882\n",
      "113 Train Loss 0.86803114 Test MSE 6.1351326166951505 Test RE 1.183913676967559\n",
      "114 Train Loss 0.86573154 Test MSE 6.129815423294485 Test RE 1.1834005289288028\n",
      "115 Train Loss 0.861701 Test MSE 6.1321879725726145 Test RE 1.1836295247672666\n",
      "116 Train Loss 0.8591237 Test MSE 6.140340647146306 Test RE 1.1844160744618863\n",
      "117 Train Loss 0.8558885 Test MSE 6.151739168597706 Test RE 1.1855149005055126\n",
      "118 Train Loss 0.85239965 Test MSE 6.158582351068909 Test RE 1.1861740994476166\n",
      "119 Train Loss 0.84928864 Test MSE 6.142863417358989 Test RE 1.1846593592338137\n",
      "120 Train Loss 0.8467994 Test MSE 6.152960766646917 Test RE 1.185632603057673\n",
      "121 Train Loss 0.84402466 Test MSE 6.152813584482492 Test RE 1.1856184224848625\n",
      "122 Train Loss 0.8411341 Test MSE 6.172959514259076 Test RE 1.1875578494915937\n",
      "123 Train Loss 0.8382642 Test MSE 6.161069029680504 Test RE 1.186413548715967\n",
      "124 Train Loss 0.83482784 Test MSE 6.182322134265068 Test RE 1.1884581016390159\n",
      "125 Train Loss 0.83211976 Test MSE 6.2052189742791395 Test RE 1.1906568536171553\n",
      "126 Train Loss 0.8285293 Test MSE 6.1903245603741155 Test RE 1.1892270257019768\n",
      "127 Train Loss 0.8247787 Test MSE 6.209206848421127 Test RE 1.1910393886308241\n",
      "128 Train Loss 0.8224177 Test MSE 6.2011114444070605 Test RE 1.190262712151574\n",
      "129 Train Loss 0.820381 Test MSE 6.1956767845839735 Test RE 1.189741024151948\n",
      "130 Train Loss 0.8182412 Test MSE 6.208420372301381 Test RE 1.19096395599316\n",
      "131 Train Loss 0.81587404 Test MSE 6.197247375451167 Test RE 1.1898918130040401\n",
      "132 Train Loss 0.8134682 Test MSE 6.207174966708343 Test RE 1.190844496656135\n",
      "133 Train Loss 0.8108815 Test MSE 6.205441451427046 Test RE 1.190678197873317\n",
      "134 Train Loss 0.80869925 Test MSE 6.221267060995211 Test RE 1.1921955121419086\n",
      "135 Train Loss 0.8062548 Test MSE 6.217563155180005 Test RE 1.1918405653690434\n",
      "136 Train Loss 0.80382824 Test MSE 6.2139482915229545 Test RE 1.191494049585293\n",
      "137 Train Loss 0.800462 Test MSE 6.219265413145398 Test RE 1.1920037065547904\n",
      "138 Train Loss 0.7981291 Test MSE 6.235643262546369 Test RE 1.1935721893379487\n",
      "139 Train Loss 0.7956015 Test MSE 6.228641453486466 Test RE 1.1929018886540577\n",
      "140 Train Loss 0.792161 Test MSE 6.2338440852506585 Test RE 1.1933999855397857\n",
      "141 Train Loss 0.79011947 Test MSE 6.2527121677909046 Test RE 1.1952046630857633\n",
      "142 Train Loss 0.7883802 Test MSE 6.261670404225908 Test RE 1.1960605391819925\n",
      "143 Train Loss 0.7863748 Test MSE 6.264436797173615 Test RE 1.196324718534741\n",
      "144 Train Loss 0.7831994 Test MSE 6.273381664154399 Test RE 1.197178518215328\n",
      "145 Train Loss 0.7805381 Test MSE 6.2679221768691695 Test RE 1.1966574751900674\n",
      "146 Train Loss 0.7773302 Test MSE 6.2617896689885635 Test RE 1.1960719296886688\n",
      "147 Train Loss 0.77456677 Test MSE 6.265874577001939 Test RE 1.1964619976646294\n",
      "148 Train Loss 0.7728975 Test MSE 6.258337763860284 Test RE 1.1957422079790099\n",
      "149 Train Loss 0.7713038 Test MSE 6.266729666494468 Test RE 1.1965436340880693\n",
      "Training time: 230.78\n",
      "6\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 58.72811 Test MSE 7.524492634961309 Test RE 1.3111327665829435\n",
      "1 Train Loss 42.936424 Test MSE 9.451806858792997 Test RE 1.4694860903637206\n",
      "2 Train Loss 38.434 Test MSE 9.086241577454484 Test RE 1.440788388952339\n",
      "3 Train Loss 34.157444 Test MSE 9.62974517785144 Test RE 1.4832537594476525\n",
      "4 Train Loss 29.074594 Test MSE 8.856647658731978 Test RE 1.4224687823170372\n",
      "5 Train Loss 25.835796 Test MSE 8.967182774213148 Test RE 1.4313177966527884\n",
      "6 Train Loss 21.832932 Test MSE 8.966814887124121 Test RE 1.4312884357736952\n",
      "7 Train Loss 18.68126 Test MSE 8.79091809353237 Test RE 1.4171805299722564\n",
      "8 Train Loss 16.718098 Test MSE 8.739443868444669 Test RE 1.4130253684932426\n",
      "9 Train Loss 14.859262 Test MSE 8.337648125775042 Test RE 1.3801612874630458\n",
      "10 Train Loss 13.9966955 Test MSE 8.19639570602 Test RE 1.36842033367455\n",
      "11 Train Loss 12.9139185 Test MSE 7.843691945201945 Test RE 1.3386539525969132\n",
      "12 Train Loss 11.857862 Test MSE 7.896937899213208 Test RE 1.3431899128805118\n",
      "13 Train Loss 10.72153 Test MSE 7.564088012743204 Test RE 1.3145779609859163\n",
      "14 Train Loss 8.983214 Test MSE 7.077660518295817 Test RE 1.2716070415388563\n",
      "15 Train Loss 7.3234496 Test MSE 7.245882852608285 Test RE 1.2866301212694546\n",
      "16 Train Loss 6.050655 Test MSE 6.967917233119329 Test RE 1.2617100196843083\n",
      "17 Train Loss 4.924675 Test MSE 6.6993218573291715 Test RE 1.2371531973772412\n",
      "18 Train Loss 4.212092 Test MSE 6.7198222828451435 Test RE 1.2390446421094674\n",
      "19 Train Loss 3.7035882 Test MSE 6.672983688288157 Test RE 1.234718888358474\n",
      "20 Train Loss 3.3823044 Test MSE 6.735721068554836 Test RE 1.2405095370334314\n",
      "21 Train Loss 3.1451638 Test MSE 6.7154074893514775 Test RE 1.2386375610341693\n",
      "22 Train Loss 2.9393685 Test MSE 6.704699642770452 Test RE 1.237649651343141\n",
      "23 Train Loss 2.824903 Test MSE 6.812364770800488 Test RE 1.2475472622329653\n",
      "24 Train Loss 2.7565029 Test MSE 6.775136575702464 Test RE 1.2441337956849419\n",
      "25 Train Loss 2.6986415 Test MSE 6.834266630854421 Test RE 1.2495510949873403\n",
      "26 Train Loss 2.6332793 Test MSE 6.894085142382065 Test RE 1.2550076745982386\n",
      "27 Train Loss 2.5899432 Test MSE 6.898601407658841 Test RE 1.2554186805193943\n",
      "28 Train Loss 2.5355024 Test MSE 6.9246697288346954 Test RE 1.2577884216437085\n",
      "29 Train Loss 2.4844863 Test MSE 6.924386002607329 Test RE 1.2577626535397222\n",
      "30 Train Loss 2.4342647 Test MSE 6.962336358066594 Test RE 1.2612046422347987\n",
      "31 Train Loss 2.3905818 Test MSE 7.046438877502571 Test RE 1.2687992253870204\n",
      "32 Train Loss 2.3344848 Test MSE 7.062181101723565 Test RE 1.2702157266172673\n",
      "33 Train Loss 2.2950587 Test MSE 7.14029241119021 Test RE 1.2772210248495637\n",
      "34 Train Loss 2.260329 Test MSE 7.134979907374532 Test RE 1.2767457989252027\n",
      "35 Train Loss 2.2297406 Test MSE 7.189617785759442 Test RE 1.2816249746831256\n",
      "36 Train Loss 2.2010975 Test MSE 7.206855954786354 Test RE 1.2831604972745378\n",
      "37 Train Loss 2.1822557 Test MSE 7.247651300262971 Test RE 1.2867871207167616\n",
      "38 Train Loss 2.1532595 Test MSE 7.271922877579872 Test RE 1.288939973211475\n",
      "39 Train Loss 2.1297417 Test MSE 7.3174920037752145 Test RE 1.2929722037612827\n",
      "40 Train Loss 2.0998435 Test MSE 7.31921444638011 Test RE 1.293124369241553\n",
      "41 Train Loss 2.0782862 Test MSE 7.3392198176254 Test RE 1.2948903907428233\n",
      "42 Train Loss 2.0571404 Test MSE 7.383064259180814 Test RE 1.29875246384583\n",
      "43 Train Loss 2.0435963 Test MSE 7.385629888749084 Test RE 1.29897810378184\n",
      "44 Train Loss 2.0269327 Test MSE 7.397236017177988 Test RE 1.29999834096865\n",
      "45 Train Loss 2.0050685 Test MSE 7.401770947109394 Test RE 1.3003967666843914\n",
      "46 Train Loss 1.9785204 Test MSE 7.408522947518498 Test RE 1.3009897516674638\n",
      "47 Train Loss 1.9631156 Test MSE 7.4217166427506935 Test RE 1.3021476901026787\n",
      "48 Train Loss 1.9311835 Test MSE 7.407525977986592 Test RE 1.3009022112230346\n",
      "49 Train Loss 1.9059029 Test MSE 7.430517871280694 Test RE 1.3029195535599472\n",
      "50 Train Loss 1.886416 Test MSE 7.409824308317702 Test RE 1.3011040107938832\n",
      "51 Train Loss 1.8589638 Test MSE 7.4373612551623225 Test RE 1.303519399143517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 1.8378806 Test MSE 7.483657469446088 Test RE 1.3075701900548713\n",
      "53 Train Loss 1.820921 Test MSE 7.463676732780415 Test RE 1.3058234721054518\n",
      "54 Train Loss 1.8082707 Test MSE 7.461842914146865 Test RE 1.3056630424265203\n",
      "55 Train Loss 1.7880362 Test MSE 7.4894593098920845 Test RE 1.3080769505432204\n",
      "56 Train Loss 1.7693789 Test MSE 7.500814757831876 Test RE 1.309068221946474\n",
      "57 Train Loss 1.7529082 Test MSE 7.513256346639018 Test RE 1.3101534467454021\n",
      "58 Train Loss 1.7384193 Test MSE 7.508746317957174 Test RE 1.3097601607753502\n",
      "59 Train Loss 1.7225382 Test MSE 7.5264650142292995 Test RE 1.3113045975465072\n",
      "60 Train Loss 1.7080967 Test MSE 7.539535641922534 Test RE 1.3124427241017214\n",
      "61 Train Loss 1.6928518 Test MSE 7.523507705080041 Test RE 1.3110469524181474\n",
      "62 Train Loss 1.675618 Test MSE 7.50117538581788 Test RE 1.3090996905920471\n",
      "63 Train Loss 1.6602359 Test MSE 7.4923884710671445 Test RE 1.3083327229225312\n",
      "64 Train Loss 1.6459022 Test MSE 7.510702092712506 Test RE 1.3099307238073763\n",
      "65 Train Loss 1.6300609 Test MSE 7.527737795619703 Test RE 1.311415468555105\n",
      "66 Train Loss 1.6144953 Test MSE 7.4894113874133135 Test RE 1.3080727655688733\n",
      "67 Train Loss 1.6035624 Test MSE 7.508801883427591 Test RE 1.3097650069441873\n",
      "68 Train Loss 1.5926437 Test MSE 7.495881000892437 Test RE 1.3086376229353698\n",
      "69 Train Loss 1.574947 Test MSE 7.451396325716725 Test RE 1.304748757454182\n",
      "70 Train Loss 1.5593368 Test MSE 7.4338966113464116 Test RE 1.303215745982369\n",
      "71 Train Loss 1.5419531 Test MSE 7.4244930149032315 Test RE 1.3023912259797406\n",
      "72 Train Loss 1.5274521 Test MSE 7.386322651343009 Test RE 1.2990390235918763\n",
      "73 Train Loss 1.5138886 Test MSE 7.378390923104223 Test RE 1.2983413562552157\n",
      "74 Train Loss 1.4965925 Test MSE 7.332890387545881 Test RE 1.2943319059025293\n",
      "75 Train Loss 1.4807379 Test MSE 7.276125436618952 Test RE 1.2893123687959884\n",
      "76 Train Loss 1.4673188 Test MSE 7.2702833922865695 Test RE 1.2887946665789403\n",
      "77 Train Loss 1.4476192 Test MSE 7.226930473289982 Test RE 1.28494636038886\n",
      "78 Train Loss 1.425647 Test MSE 7.219887160286671 Test RE 1.2843200581433096\n",
      "79 Train Loss 1.4118847 Test MSE 7.179513870624731 Test RE 1.2807240934973383\n",
      "80 Train Loss 1.3953 Test MSE 7.234705081205389 Test RE 1.285637336237467\n",
      "81 Train Loss 1.3778188 Test MSE 7.146920273709709 Test RE 1.2778136673739378\n",
      "82 Train Loss 1.3559773 Test MSE 7.0877766552670565 Test RE 1.2725154743252285\n",
      "83 Train Loss 1.3393619 Test MSE 7.069957513644103 Test RE 1.2709148734457716\n",
      "84 Train Loss 1.3197964 Test MSE 7.001373002827379 Test RE 1.2647353808614539\n",
      "85 Train Loss 1.2984574 Test MSE 6.889103430326473 Test RE 1.2545541541824423\n",
      "86 Train Loss 1.2706683 Test MSE 6.867565188163284 Test RE 1.252591486310846\n",
      "87 Train Loss 1.255478 Test MSE 6.813892667847389 Test RE 1.2476871561593914\n",
      "88 Train Loss 1.2359275 Test MSE 6.7311939005310135 Test RE 1.2400925854542533\n",
      "89 Train Loss 1.220834 Test MSE 6.732937023612233 Test RE 1.2402531434558035\n",
      "90 Train Loss 1.2087407 Test MSE 6.643201236664677 Test RE 1.231960446273196\n",
      "91 Train Loss 1.1871469 Test MSE 6.599637250298984 Test RE 1.227914401147055\n",
      "92 Train Loss 1.1720202 Test MSE 6.560024503502246 Test RE 1.2242237232068354\n",
      "93 Train Loss 1.1617715 Test MSE 6.523015207433972 Test RE 1.2207655241200641\n",
      "94 Train Loss 1.1517224 Test MSE 6.516330481241357 Test RE 1.2201398491228719\n",
      "95 Train Loss 1.1440514 Test MSE 6.505500219026971 Test RE 1.2191254799339035\n",
      "96 Train Loss 1.1352423 Test MSE 6.532215696781359 Test RE 1.2216261447205834\n",
      "97 Train Loss 1.1291046 Test MSE 6.508870996513492 Test RE 1.2194412795193719\n",
      "98 Train Loss 1.1196257 Test MSE 6.487420972330812 Test RE 1.2174302832415884\n",
      "99 Train Loss 1.1114665 Test MSE 6.447797136313035 Test RE 1.2137066816136561\n",
      "100 Train Loss 1.1030581 Test MSE 6.430779861040024 Test RE 1.212103992666269\n",
      "101 Train Loss 1.0971195 Test MSE 6.428937086327621 Test RE 1.2119303127493148\n",
      "102 Train Loss 1.0918148 Test MSE 6.407725587378305 Test RE 1.209929352292797\n",
      "103 Train Loss 1.0834392 Test MSE 6.378018333379586 Test RE 1.2071213797032918\n",
      "104 Train Loss 1.0755341 Test MSE 6.331425326751535 Test RE 1.2027041370397291\n",
      "105 Train Loss 1.0697272 Test MSE 6.296385429099522 Test RE 1.1993714673088807\n",
      "106 Train Loss 1.0615484 Test MSE 6.287731960894528 Test RE 1.1985470029046597\n",
      "107 Train Loss 1.0561684 Test MSE 6.27179806656753 Test RE 1.1970274060423418\n",
      "108 Train Loss 1.0497223 Test MSE 6.254121649271743 Test RE 1.195339366544643\n",
      "109 Train Loss 1.0437319 Test MSE 6.249805751176241 Test RE 1.1949268503251385\n",
      "110 Train Loss 1.0365847 Test MSE 6.233586099807037 Test RE 1.1933752910650828\n",
      "111 Train Loss 1.0303569 Test MSE 6.214273872197041 Test RE 1.1915252634236122\n",
      "112 Train Loss 1.0268928 Test MSE 6.217888441685643 Test RE 1.1918717419387475\n",
      "113 Train Loss 1.021991 Test MSE 6.215094617269396 Test RE 1.1916039456816427\n",
      "114 Train Loss 1.0142189 Test MSE 6.217571260172663 Test RE 1.191841342189129\n",
      "115 Train Loss 1.0094177 Test MSE 6.2112591205167 Test RE 1.1912362040227895\n",
      "116 Train Loss 1.0020696 Test MSE 6.198976517621783 Test RE 1.1900578019091534\n",
      "117 Train Loss 0.99784356 Test MSE 6.1950860091494135 Test RE 1.1896843002014452\n",
      "118 Train Loss 0.9950467 Test MSE 6.200302140519674 Test RE 1.1901850393279136\n",
      "119 Train Loss 0.99251485 Test MSE 6.200846429451365 Test RE 1.1902372779376422\n",
      "120 Train Loss 0.986297 Test MSE 6.178466369173672 Test RE 1.1880874375204455\n",
      "121 Train Loss 0.9824726 Test MSE 6.1922352606075775 Test RE 1.189410544435314\n",
      "122 Train Loss 0.9782367 Test MSE 6.187003668655951 Test RE 1.1889079936424558\n",
      "123 Train Loss 0.97448087 Test MSE 6.181298456745534 Test RE 1.1883597042908354\n",
      "124 Train Loss 0.96915466 Test MSE 6.161029163915486 Test RE 1.1864097103106488\n",
      "125 Train Loss 0.9641799 Test MSE 6.132239505045932 Test RE 1.1836344981331381\n",
      "126 Train Loss 0.95872945 Test MSE 6.111060073496049 Test RE 1.1815887211582183\n",
      "127 Train Loss 0.9524381 Test MSE 6.116619623471041 Test RE 1.1821260754046066\n",
      "128 Train Loss 0.9469055 Test MSE 6.10978367946723 Test RE 1.1814653177282175\n",
      "129 Train Loss 0.94252515 Test MSE 6.13066505908821 Test RE 1.183482539930744\n",
      "130 Train Loss 0.9389457 Test MSE 6.1090596458041135 Test RE 1.1813953114848783\n",
      "131 Train Loss 0.9360366 Test MSE 6.095430792966746 Test RE 1.1800767736187296\n",
      "132 Train Loss 0.93223184 Test MSE 6.124463675093795 Test RE 1.1828838213152455\n",
      "133 Train Loss 0.9273943 Test MSE 6.137774642537969 Test RE 1.1841685690820483\n",
      "134 Train Loss 0.9246099 Test MSE 6.147734823596523 Test RE 1.1851289947225088\n",
      "135 Train Loss 0.9207528 Test MSE 6.132398216842956 Test RE 1.1836498151753518\n",
      "136 Train Loss 0.91574466 Test MSE 6.117545843320944 Test RE 1.1822155747732974\n",
      "137 Train Loss 0.9099998 Test MSE 6.120477057545748 Test RE 1.1824987693905475\n",
      "138 Train Loss 0.9065254 Test MSE 6.123964339245994 Test RE 1.18283559926946\n",
      "139 Train Loss 0.9034917 Test MSE 6.121412600640167 Test RE 1.1825891411275666\n",
      "140 Train Loss 0.90074956 Test MSE 6.115713880009121 Test RE 1.1820385480880498\n",
      "141 Train Loss 0.8978834 Test MSE 6.122341492911744 Test RE 1.1826788635752796\n",
      "142 Train Loss 0.89583385 Test MSE 6.1090605663502595 Test RE 1.1813954004943923\n",
      "143 Train Loss 0.89097977 Test MSE 6.120840911039706 Test RE 1.182533917787516\n",
      "144 Train Loss 0.88507444 Test MSE 6.117935212376511 Test RE 1.1822531969545838\n",
      "145 Train Loss 0.88156295 Test MSE 6.1052260023198786 Test RE 1.1810245703678357\n",
      "146 Train Loss 0.878605 Test MSE 6.106096124315568 Test RE 1.1811087276818704\n",
      "147 Train Loss 0.87446547 Test MSE 6.104694246811707 Test RE 1.1809731365637681\n",
      "148 Train Loss 0.8709985 Test MSE 6.106021229049754 Test RE 1.1811014841238285\n",
      "149 Train Loss 0.86888105 Test MSE 6.102443355821976 Test RE 1.1807553953663248\n",
      "Training time: 231.92\n",
      "7\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 54.88929 Test MSE 6.333136964204591 Test RE 1.2028666955655307\n",
      "1 Train Loss 37.66047 Test MSE 7.859159428728304 Test RE 1.339973191704859\n",
      "2 Train Loss 29.07861 Test MSE 7.605132908243525 Test RE 1.3181397728487838\n",
      "3 Train Loss 20.790014 Test MSE 6.3793248527807105 Test RE 1.2072450111088777\n",
      "4 Train Loss 17.256868 Test MSE 5.980031314260816 Test RE 1.1688527134087232\n",
      "5 Train Loss 14.103522 Test MSE 5.680626031703251 Test RE 1.139216220893669\n",
      "6 Train Loss 12.962991 Test MSE 5.923932856939997 Test RE 1.163357312501495\n",
      "7 Train Loss 11.858307 Test MSE 5.99569200208113 Test RE 1.170382226191442\n",
      "8 Train Loss 11.011951 Test MSE 5.922142774208457 Test RE 1.1631815286741205\n",
      "9 Train Loss 9.87895 Test MSE 5.84939525382432 Test RE 1.1560151999493233\n",
      "10 Train Loss 8.774102 Test MSE 5.62060377834677 Test RE 1.133181682756613\n",
      "11 Train Loss 7.717 Test MSE 5.408789990974961 Test RE 1.1116245254151078\n",
      "12 Train Loss 6.827284 Test MSE 5.296141850188388 Test RE 1.099987790288116\n",
      "13 Train Loss 6.080836 Test MSE 5.065038967537411 Test RE 1.075720526479302\n",
      "14 Train Loss 4.951548 Test MSE 3.92049580215997 Test RE 0.9464083358878556\n",
      "15 Train Loss 4.3725867 Test MSE 3.7781735009355364 Test RE 0.9290712243806524\n",
      "16 Train Loss 3.9745564 Test MSE 3.54504787129673 Test RE 0.89995151490072\n",
      "17 Train Loss 3.335613 Test MSE 3.0818982500450365 Test RE 0.8391067378471203\n",
      "18 Train Loss 2.8535764 Test MSE 2.6840429257215894 Test RE 0.7830739717367738\n",
      "19 Train Loss 2.4220653 Test MSE 2.323857327637033 Test RE 0.7286396341459332\n",
      "20 Train Loss 2.173218 Test MSE 2.1150499140862506 Test RE 0.6951337435254488\n",
      "21 Train Loss 1.9544505 Test MSE 1.7074862357911829 Test RE 0.6245779760550045\n",
      "22 Train Loss 1.7953908 Test MSE 1.512394268511469 Test RE 0.5878148746699327\n",
      "23 Train Loss 1.6139355 Test MSE 1.2930140738220925 Test RE 0.5435126872128522\n",
      "24 Train Loss 1.448862 Test MSE 1.1388557885951633 Test RE 0.5100848527013327\n",
      "25 Train Loss 1.2426684 Test MSE 0.8486408416694654 Test RE 0.44032163482479614\n",
      "26 Train Loss 0.9392813 Test MSE 0.34842845541890605 Test RE 0.2821401339080569\n",
      "27 Train Loss 0.65593684 Test MSE 0.1752786115744106 Test RE 0.20011171891992172\n",
      "28 Train Loss 0.53230566 Test MSE 0.17781054354745351 Test RE 0.2015518621846284\n",
      "29 Train Loss 0.3725884 Test MSE 0.09347489931988963 Test RE 0.14613544396435577\n",
      "30 Train Loss 0.29673877 Test MSE 0.1030467628057697 Test RE 0.15343528233465303\n",
      "31 Train Loss 0.22356056 Test MSE 0.11737139479459574 Test RE 0.16375297283170306\n",
      "32 Train Loss 0.18449281 Test MSE 0.0937541345521772 Test RE 0.14635355457780327\n",
      "33 Train Loss 0.15825193 Test MSE 0.06919959228615229 Test RE 0.12573605441565364\n",
      "34 Train Loss 0.1308367 Test MSE 0.04985568633802476 Test RE 0.10672481482674183\n",
      "35 Train Loss 0.115201324 Test MSE 0.035379248889249905 Test RE 0.0899046934443113\n",
      "36 Train Loss 0.096432656 Test MSE 0.03107538767692403 Test RE 0.08425900725688787\n",
      "37 Train Loss 0.08619061 Test MSE 0.030997901594176234 Test RE 0.08415389231043849\n",
      "38 Train Loss 0.07518649 Test MSE 0.025918274766251245 Test RE 0.07695043958079929\n",
      "39 Train Loss 0.06535704 Test MSE 0.017114174951588276 Test RE 0.06252965664299254\n",
      "40 Train Loss 0.05750777 Test MSE 0.016841818984025515 Test RE 0.062030110940866384\n",
      "41 Train Loss 0.05282441 Test MSE 0.0180383057134523 Test RE 0.06419569896310658\n",
      "42 Train Loss 0.04706396 Test MSE 0.016843617665382858 Test RE 0.06203342321448321\n",
      "43 Train Loss 0.042154815 Test MSE 0.013834906754159795 Test RE 0.056220690912137\n",
      "44 Train Loss 0.0377326 Test MSE 0.014023773543219995 Test RE 0.056603137582938785\n",
      "45 Train Loss 0.035845473 Test MSE 0.009537286814987033 Test RE 0.04667888589107831\n",
      "46 Train Loss 0.032596614 Test MSE 0.008614974464072939 Test RE 0.0443644454762651\n",
      "47 Train Loss 0.030506892 Test MSE 0.006792227742009749 Test RE 0.03939255770952732\n",
      "48 Train Loss 0.028068209 Test MSE 0.007296003814676069 Test RE 0.04082729308662191\n",
      "49 Train Loss 0.024147058 Test MSE 0.008025069477067924 Test RE 0.042818599734996354\n",
      "50 Train Loss 0.02236638 Test MSE 0.007668039336915537 Test RE 0.041855277568010364\n",
      "51 Train Loss 0.02004166 Test MSE 0.008057646393300972 Test RE 0.04290542049067901\n",
      "52 Train Loss 0.017560702 Test MSE 0.007571024157723741 Test RE 0.04158966060086834\n",
      "53 Train Loss 0.016696494 Test MSE 0.007534779293748784 Test RE 0.04148998980309713\n",
      "54 Train Loss 0.014648718 Test MSE 0.006692403429732059 Test RE 0.039102013096054974\n",
      "55 Train Loss 0.013940385 Test MSE 0.006216449270397797 Test RE 0.037685931747224975\n",
      "56 Train Loss 0.012973029 Test MSE 0.0046779447819786536 Test RE 0.032691557048173545\n",
      "57 Train Loss 0.012506328 Test MSE 0.004346773179752756 Test RE 0.031513130624387285\n",
      "58 Train Loss 0.012071574 Test MSE 0.0040891641473270075 Test RE 0.030565065616485705\n",
      "59 Train Loss 0.011849814 Test MSE 0.004214913820541353 Test RE 0.031031474343878727\n",
      "60 Train Loss 0.011440557 Test MSE 0.004853543066227723 Test RE 0.03329948401556069\n",
      "61 Train Loss 0.010935456 Test MSE 0.005235678405317468 Test RE 0.0345855384659095\n",
      "62 Train Loss 0.01045979 Test MSE 0.004985566665294946 Test RE 0.033749343108404994\n",
      "63 Train Loss 0.010212362 Test MSE 0.004672851557588367 Test RE 0.03267375534359377\n",
      "64 Train Loss 0.009572453 Test MSE 0.005264515992046027 Test RE 0.03468065449604511\n",
      "65 Train Loss 0.009073582 Test MSE 0.005249094398363648 Test RE 0.034629821407668765\n",
      "66 Train Loss 0.008831254 Test MSE 0.00509170417648373 Test RE 0.034106695356784844\n",
      "67 Train Loss 0.0082504 Test MSE 0.0047173433223683 Test RE 0.03282893565210254\n",
      "68 Train Loss 0.008119327 Test MSE 0.004922324194619744 Test RE 0.033534602838142684\n",
      "69 Train Loss 0.007982273 Test MSE 0.004776663849448849 Test RE 0.0330347025002697\n",
      "70 Train Loss 0.0077647706 Test MSE 0.0042913172714635186 Test RE 0.03131146389774454\n",
      "71 Train Loss 0.007485917 Test MSE 0.004065404812790304 Test RE 0.030476139916803615\n",
      "72 Train Loss 0.0070402757 Test MSE 0.00387112352073124 Test RE 0.029739014649721913\n",
      "73 Train Loss 0.006736448 Test MSE 0.003917206817874824 Test RE 0.029915503114555264\n",
      "74 Train Loss 0.006616941 Test MSE 0.003897060400025202 Test RE 0.029838475378890717\n",
      "75 Train Loss 0.00650284 Test MSE 0.004046121388337081 Test RE 0.030403775304062977\n",
      "76 Train Loss 0.0062623164 Test MSE 0.004127298202475758 Test RE 0.030707254219504206\n",
      "77 Train Loss 0.006082939 Test MSE 0.004071331295387287 Test RE 0.030498345643439905\n",
      "78 Train Loss 0.005887157 Test MSE 0.0038733473418328494 Test RE 0.029747555419960315\n",
      "79 Train Loss 0.005748718 Test MSE 0.0037197626249083327 Test RE 0.029151819985494654\n",
      "80 Train Loss 0.0056605507 Test MSE 0.0034028005954481813 Test RE 0.027882153278367433\n",
      "81 Train Loss 0.005320632 Test MSE 0.0030301715165183037 Test RE 0.026311261203244764\n",
      "82 Train Loss 0.004761388 Test MSE 0.0024090270197831853 Test RE 0.023460047971242043\n",
      "83 Train Loss 0.0045639076 Test MSE 0.0022093400804533148 Test RE 0.022466703092152644\n",
      "84 Train Loss 0.004440964 Test MSE 0.0019988320185556478 Test RE 0.021369590949001524\n",
      "85 Train Loss 0.004350948 Test MSE 0.0017495630566492823 Test RE 0.01999276494947772\n",
      "86 Train Loss 0.0042521763 Test MSE 0.001606349574157209 Test RE 0.01915702612615769\n",
      "87 Train Loss 0.0040910677 Test MSE 0.001849735936225064 Test RE 0.020557151063195576\n",
      "88 Train Loss 0.003866468 Test MSE 0.001848375410094439 Test RE 0.020549589528215367\n",
      "89 Train Loss 0.0035784368 Test MSE 0.001699192778307887 Test RE 0.019702865246608383\n",
      "90 Train Loss 0.0034700509 Test MSE 0.0017408120197989483 Test RE 0.019942701949940047\n",
      "91 Train Loss 0.0034282347 Test MSE 0.0016411554782380026 Test RE 0.01936345825911946\n",
      "92 Train Loss 0.0033676047 Test MSE 0.001522539037216975 Test RE 0.018650577269478455\n",
      "93 Train Loss 0.0032425951 Test MSE 0.0014236115561665251 Test RE 0.01803448781137885\n",
      "94 Train Loss 0.003083189 Test MSE 0.0014186751557960715 Test RE 0.018003193192988983\n",
      "95 Train Loss 0.0029634102 Test MSE 0.001278089675908743 Test RE 0.017087901173503985\n",
      "96 Train Loss 0.0028883128 Test MSE 0.0013061836976817412 Test RE 0.01727468710675293\n",
      "97 Train Loss 0.0028541107 Test MSE 0.001282789273476742 Test RE 0.017119288866098342\n",
      "98 Train Loss 0.002817121 Test MSE 0.00123361157587685 Test RE 0.016787934971570054\n",
      "99 Train Loss 0.002789928 Test MSE 0.0012049657610931803 Test RE 0.016591872954284062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Train Loss 0.0027739187 Test MSE 0.0011576848077329363 Test RE 0.016263096063904116\n",
      "101 Train Loss 0.0027383687 Test MSE 0.0011109758894118954 Test RE 0.01593163607265132\n",
      "102 Train Loss 0.0026171044 Test MSE 0.001021150878727114 Test RE 0.015274008149364915\n",
      "103 Train Loss 0.0024948712 Test MSE 0.0009769576698496 Test RE 0.014939839562915296\n",
      "104 Train Loss 0.0024006022 Test MSE 0.0009806246516142212 Test RE 0.014967851425425848\n",
      "105 Train Loss 0.0022956268 Test MSE 0.0010300329585122882 Test RE 0.015340291805787687\n",
      "106 Train Loss 0.0022531287 Test MSE 0.0009413084066363514 Test RE 0.014664728567041218\n",
      "107 Train Loss 0.0022145854 Test MSE 0.0009498952094449888 Test RE 0.014731464006773427\n",
      "108 Train Loss 0.0021677709 Test MSE 0.0008998239178928699 Test RE 0.014337942245706517\n",
      "109 Train Loss 0.0021205875 Test MSE 0.000822968627102863 Test RE 0.013711965126350048\n",
      "110 Train Loss 0.002085745 Test MSE 0.0008233891464545005 Test RE 0.013715467939269334\n",
      "111 Train Loss 0.00205493 Test MSE 0.0008051578330164384 Test RE 0.013562775448966016\n",
      "112 Train Loss 0.0019896694 Test MSE 0.0007408601871382903 Test RE 0.013009966814472614\n",
      "113 Train Loss 0.0018835821 Test MSE 0.0006460994116619477 Test RE 0.01214948119224828\n",
      "114 Train Loss 0.0018011885 Test MSE 0.0005366259092729302 Test RE 0.011072453853647302\n",
      "115 Train Loss 0.001718844 Test MSE 0.0005058637184337424 Test RE 0.010750405014081022\n",
      "116 Train Loss 0.0016567074 Test MSE 0.000493223559049982 Test RE 0.010615243643118139\n",
      "117 Train Loss 0.0016144878 Test MSE 0.0004914740752261488 Test RE 0.0105964005706755\n",
      "118 Train Loss 0.0015844904 Test MSE 0.0004921236225645532 Test RE 0.010603400523963295\n",
      "119 Train Loss 0.0015551687 Test MSE 0.0004959337592180549 Test RE 0.010644368389594832\n",
      "120 Train Loss 0.0015446321 Test MSE 0.0005151863595169538 Test RE 0.010849013214080822\n",
      "121 Train Loss 0.0015379344 Test MSE 0.0005371188351381506 Test RE 0.011077538071552177\n",
      "122 Train Loss 0.0015088061 Test MSE 0.0005474987336697323 Test RE 0.011184063386088048\n",
      "123 Train Loss 0.0014849384 Test MSE 0.0005613712870144404 Test RE 0.011324868245085525\n",
      "124 Train Loss 0.0014630882 Test MSE 0.0005500401504274779 Test RE 0.011209990805019967\n",
      "125 Train Loss 0.0014340137 Test MSE 0.000557992126873546 Test RE 0.0112907319191152\n",
      "126 Train Loss 0.001413632 Test MSE 0.0005004045935937953 Test RE 0.010692240140596337\n",
      "127 Train Loss 0.0014015837 Test MSE 0.0004882905291731594 Test RE 0.010562025476280289\n",
      "128 Train Loss 0.0013860365 Test MSE 0.0004611712739461431 Test RE 0.010264532734419407\n",
      "129 Train Loss 0.001358059 Test MSE 0.0004480702599853922 Test RE 0.01011768420209243\n",
      "130 Train Loss 0.0013431679 Test MSE 0.0004562386942856819 Test RE 0.010209491646141837\n",
      "131 Train Loss 0.0013324074 Test MSE 0.0004544425908386478 Test RE 0.010189375656000822\n",
      "132 Train Loss 0.0013156789 Test MSE 0.0004496821631513503 Test RE 0.010135866714505922\n",
      "133 Train Loss 0.001291588 Test MSE 0.00043463687808381287 Test RE 0.009964863328256395\n",
      "134 Train Loss 0.0012636659 Test MSE 0.0004569192189970335 Test RE 0.010217103037435074\n",
      "135 Train Loss 0.0012145495 Test MSE 0.0004549278971909389 Test RE 0.010194814901060037\n",
      "136 Train Loss 0.0011905028 Test MSE 0.0004365139817129641 Test RE 0.009986358201037245\n",
      "137 Train Loss 0.0011613049 Test MSE 0.0004511093977108302 Test RE 0.010151938954087602\n",
      "138 Train Loss 0.0011213485 Test MSE 0.0004353404364395528 Test RE 0.00997292526264103\n",
      "139 Train Loss 0.0011021835 Test MSE 0.0004613310920479513 Test RE 0.010266311158326507\n",
      "140 Train Loss 0.0010722493 Test MSE 0.00048001676525955385 Test RE 0.010472159861708989\n",
      "141 Train Loss 0.0010203039 Test MSE 0.0004915478348213253 Test RE 0.010597195685751997\n",
      "142 Train Loss 0.0009765978 Test MSE 0.0005099127650856706 Test RE 0.010793343589193828\n",
      "143 Train Loss 0.0009507687 Test MSE 0.0005170730940151492 Test RE 0.010868860887249041\n",
      "144 Train Loss 0.000936176 Test MSE 0.0005397720860299347 Test RE 0.011104864687490683\n",
      "145 Train Loss 0.0009272989 Test MSE 0.0005385213218959335 Test RE 0.011091991085452974\n",
      "146 Train Loss 0.00091331964 Test MSE 0.0005500259329005979 Test RE 0.011209845925254917\n",
      "147 Train Loss 0.00090140966 Test MSE 0.0005508757948754915 Test RE 0.011218502921244279\n",
      "148 Train Loss 0.00089253846 Test MSE 0.0005847493290877555 Test RE 0.011558272423281052\n",
      "149 Train Loss 0.0008787954 Test MSE 0.0005859521684261034 Test RE 0.011570154097924381\n",
      "Training time: 229.58\n",
      "8\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 70.782875 Test MSE 5.611446219768106 Test RE 1.1322581691681988\n",
      "1 Train Loss 51.511864 Test MSE 6.861961670581258 Test RE 1.252080362603836\n",
      "2 Train Loss 35.107037 Test MSE 7.497971644473625 Test RE 1.308820103427565\n",
      "3 Train Loss 24.806923 Test MSE 7.36096083397778 Test RE 1.2968069033830196\n",
      "4 Train Loss 19.487278 Test MSE 6.9501080244797215 Test RE 1.2600965940120439\n",
      "5 Train Loss 14.977657 Test MSE 6.934005425240345 Test RE 1.2586359982271709\n",
      "6 Train Loss 13.188892 Test MSE 6.6217547568515425 Test RE 1.2299702481349946\n",
      "7 Train Loss 11.594503 Test MSE 6.637593175045421 Test RE 1.2314403379280812\n",
      "8 Train Loss 10.343784 Test MSE 6.6286536876099005 Test RE 1.2306108087470828\n",
      "9 Train Loss 8.618994 Test MSE 6.362735288510635 Test RE 1.2056742566237344\n",
      "10 Train Loss 7.7493896 Test MSE 6.340290898930429 Test RE 1.2035458851298306\n",
      "11 Train Loss 6.4935956 Test MSE 6.109537803021804 Test RE 1.181441544593962\n",
      "12 Train Loss 5.659504 Test MSE 5.990231469798189 Test RE 1.1698491462976783\n",
      "13 Train Loss 4.8534417 Test MSE 5.959723747788831 Test RE 1.1668663742966183\n",
      "14 Train Loss 4.185051 Test MSE 5.658473826070266 Test RE 1.1369928037300128\n",
      "15 Train Loss 3.9679375 Test MSE 5.7711118754717035 Test RE 1.1482535769357929\n",
      "16 Train Loss 3.6663723 Test MSE 5.733058252347499 Test RE 1.144461632007234\n",
      "17 Train Loss 3.39448 Test MSE 5.634838530270207 Test RE 1.1346157244196118\n",
      "18 Train Loss 3.2039404 Test MSE 5.526982853519466 Test RE 1.1237044970578831\n",
      "19 Train Loss 3.0099747 Test MSE 5.31765512860218 Test RE 1.1022196376787357\n",
      "20 Train Loss 2.8739648 Test MSE 5.2559810610984945 Test RE 1.0958092348779889\n",
      "21 Train Loss 2.6897428 Test MSE 5.140559380926575 Test RE 1.0837104230540735\n",
      "22 Train Loss 2.5996304 Test MSE 5.1129456547946806 Test RE 1.080795800676649\n",
      "23 Train Loss 2.4987276 Test MSE 5.049554025359251 Test RE 1.0740749102117235\n",
      "24 Train Loss 2.3531065 Test MSE 4.934961540078378 Test RE 1.0618176656082936\n",
      "25 Train Loss 2.308539 Test MSE 4.915175667499866 Test RE 1.0596869408642986\n",
      "26 Train Loss 2.240821 Test MSE 4.83900704799813 Test RE 1.0514440981309852\n",
      "27 Train Loss 2.18538 Test MSE 4.7777922357665155 Test RE 1.0447723981567436\n",
      "28 Train Loss 2.1324766 Test MSE 4.656194425968854 Test RE 1.0313916558916263\n",
      "29 Train Loss 2.0820134 Test MSE 4.5987541486918575 Test RE 1.0250101279328312\n",
      "30 Train Loss 2.0207317 Test MSE 4.552524421850645 Test RE 1.0198450736839333\n",
      "31 Train Loss 1.9674733 Test MSE 4.386283418276063 Test RE 1.00105146444662\n",
      "32 Train Loss 1.9136891 Test MSE 4.327023461156243 Test RE 0.9942662215131515\n",
      "33 Train Loss 1.840256 Test MSE 4.135527258294389 Test RE 0.9720162023044644\n",
      "34 Train Loss 1.7273796 Test MSE 3.946759844405402 Test RE 0.9495731164633411\n",
      "35 Train Loss 1.6167486 Test MSE 3.590293495412961 Test RE 0.905676369368095\n",
      "36 Train Loss 1.512608 Test MSE 3.458300359341308 Test RE 0.888872387441977\n",
      "37 Train Loss 1.410707 Test MSE 3.3806922119334546 Test RE 0.8788421479214651\n",
      "38 Train Loss 1.3514708 Test MSE 3.2659652927880773 Test RE 0.8638012792496947\n",
      "39 Train Loss 1.2995651 Test MSE 3.3190689454104905 Test RE 0.8707955424056021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Train Loss 1.2582848 Test MSE 3.3059612500906925 Test RE 0.8690743648195912\n",
      "41 Train Loss 1.2124344 Test MSE 3.3006435302541277 Test RE 0.8683751197918489\n",
      "42 Train Loss 1.1775582 Test MSE 3.3058999756425953 Test RE 0.8690663108384974\n",
      "43 Train Loss 1.1451929 Test MSE 3.215429545246105 Test RE 0.8570922325065335\n",
      "44 Train Loss 1.110451 Test MSE 3.1734650683211796 Test RE 0.8514809212879835\n",
      "45 Train Loss 1.072582 Test MSE 3.150646981238127 Test RE 0.8484142076511811\n",
      "46 Train Loss 1.039941 Test MSE 3.139984349658333 Test RE 0.8469773607187887\n",
      "47 Train Loss 1.0023274 Test MSE 3.149399110591814 Test RE 0.8482461761257303\n",
      "48 Train Loss 0.9775221 Test MSE 3.050750387602951 Test RE 0.834855663803568\n",
      "49 Train Loss 0.9446786 Test MSE 3.075191152185133 Test RE 0.8381931716118759\n",
      "50 Train Loss 0.91987777 Test MSE 3.04574795792104 Test RE 0.8341709109331892\n",
      "51 Train Loss 0.90082175 Test MSE 3.032541574077719 Test RE 0.8323604609010056\n",
      "52 Train Loss 0.8853468 Test MSE 3.0373898383593145 Test RE 0.8330255617322813\n",
      "53 Train Loss 0.868899 Test MSE 3.0244312507952813 Test RE 0.8312466703914873\n",
      "54 Train Loss 0.8548213 Test MSE 3.0243353363135004 Test RE 0.8312334895288501\n",
      "55 Train Loss 0.84511817 Test MSE 3.0236229587609795 Test RE 0.8311355858761085\n",
      "56 Train Loss 0.83427835 Test MSE 3.0219279020094794 Test RE 0.8309025840255416\n",
      "57 Train Loss 0.8223022 Test MSE 3.031549155211422 Test RE 0.832224252081042\n",
      "58 Train Loss 0.8134368 Test MSE 3.0107320259750447 Test RE 0.8293619591405614\n",
      "59 Train Loss 0.79725575 Test MSE 2.9957743247114714 Test RE 0.8272992058717175\n",
      "60 Train Loss 0.78582054 Test MSE 3.017894867255874 Test RE 0.8303479417696542\n",
      "61 Train Loss 0.7740728 Test MSE 3.021550956035256 Test RE 0.8308507602954834\n",
      "62 Train Loss 0.75436574 Test MSE 3.031015680409405 Test RE 0.8321510238107819\n",
      "63 Train Loss 0.7458441 Test MSE 3.0229973082689106 Test RE 0.8310495918057694\n",
      "64 Train Loss 0.7346141 Test MSE 3.00935176861231 Test RE 0.8291718286058315\n",
      "65 Train Loss 0.7274407 Test MSE 2.997103706285246 Test RE 0.8274827434514688\n",
      "66 Train Loss 0.72205883 Test MSE 3.0054417959242947 Test RE 0.8286329928013274\n",
      "67 Train Loss 0.7139152 Test MSE 2.9904308956628154 Test RE 0.8265610682314207\n",
      "68 Train Loss 0.70543975 Test MSE 2.968648334198416 Test RE 0.8235451944889393\n",
      "69 Train Loss 0.69233215 Test MSE 2.9618007793406265 Test RE 0.8225948416790225\n",
      "70 Train Loss 0.6851804 Test MSE 2.991035766481487 Test RE 0.8266446577555249\n",
      "71 Train Loss 0.67895037 Test MSE 3.024959588856387 Test RE 0.831319272484134\n",
      "72 Train Loss 0.6720569 Test MSE 3.0188671253944652 Test RE 0.8304816852511865\n",
      "73 Train Loss 0.6654626 Test MSE 3.018045988101951 Test RE 0.8303687313130561\n",
      "74 Train Loss 0.6596691 Test MSE 3.0097371849197034 Test RE 0.8292249241123288\n",
      "75 Train Loss 0.65339434 Test MSE 3.0116883834859034 Test RE 0.8294936718859609\n",
      "76 Train Loss 0.6454665 Test MSE 3.0295077230640817 Test RE 0.8319439967785116\n",
      "77 Train Loss 0.6373157 Test MSE 3.0415741542580905 Test RE 0.8335991533119437\n",
      "78 Train Loss 0.6306578 Test MSE 3.023075583343441 Test RE 0.8310603510028539\n",
      "79 Train Loss 0.624194 Test MSE 3.0279747576899574 Test RE 0.8317334835809879\n",
      "80 Train Loss 0.6197774 Test MSE 3.006172939229386 Test RE 0.828733778752937\n",
      "81 Train Loss 0.61058986 Test MSE 3.0172834746878197 Test RE 0.83026382779328\n",
      "82 Train Loss 0.6057745 Test MSE 3.016143628899087 Test RE 0.8301069876868071\n",
      "83 Train Loss 0.5998148 Test MSE 3.0245702141468196 Test RE 0.8312657667912493\n",
      "84 Train Loss 0.5955773 Test MSE 3.0408283835818746 Test RE 0.8334969509843311\n",
      "85 Train Loss 0.5915363 Test MSE 3.034555217532405 Test RE 0.8326367636344828\n",
      "86 Train Loss 0.5876193 Test MSE 3.0427810250282383 Test RE 0.8337645194387023\n",
      "87 Train Loss 0.58248323 Test MSE 3.0517037461567793 Test RE 0.8349860996826077\n",
      "88 Train Loss 0.57872564 Test MSE 3.0498701878650216 Test RE 0.8347352192154192\n",
      "89 Train Loss 0.57494944 Test MSE 3.055331354071356 Test RE 0.8354822327962247\n",
      "90 Train Loss 0.5724243 Test MSE 3.0543237981443685 Test RE 0.8353444630440973\n",
      "91 Train Loss 0.5693855 Test MSE 3.0634958815868005 Test RE 0.8365977855703685\n",
      "92 Train Loss 0.56358933 Test MSE 3.066014236422617 Test RE 0.8369415786343729\n",
      "93 Train Loss 0.55802023 Test MSE 3.071513752198271 Test RE 0.8376918542215569\n",
      "94 Train Loss 0.55617845 Test MSE 3.0732894429062574 Test RE 0.8379339606940714\n",
      "95 Train Loss 0.5520551 Test MSE 3.0665086442533234 Test RE 0.8370090561081208\n",
      "96 Train Loss 0.5486922 Test MSE 3.0720087796405013 Test RE 0.8377593557505334\n",
      "97 Train Loss 0.54541606 Test MSE 3.0888631491670324 Test RE 0.8400543673757651\n",
      "98 Train Loss 0.5424846 Test MSE 3.1023446071527108 Test RE 0.8418855956851514\n",
      "99 Train Loss 0.5400662 Test MSE 3.0867804164639256 Test RE 0.8397711072172288\n",
      "100 Train Loss 0.53679687 Test MSE 3.0961052188259055 Test RE 0.8410385758345941\n",
      "101 Train Loss 0.5333697 Test MSE 3.0888056374971513 Test RE 0.8400465468359721\n",
      "102 Train Loss 0.5296809 Test MSE 3.086132793655266 Test RE 0.8396830083927889\n",
      "103 Train Loss 0.52632725 Test MSE 3.107510119447751 Test RE 0.842586188662035\n",
      "104 Train Loss 0.5219629 Test MSE 3.0986039943952965 Test RE 0.8413778961484326\n",
      "105 Train Loss 0.51807237 Test MSE 3.0999445602701843 Test RE 0.8415598814116474\n",
      "106 Train Loss 0.5163806 Test MSE 3.1077809577946502 Test RE 0.8426229061093717\n",
      "107 Train Loss 0.51239824 Test MSE 3.1247281954012562 Test RE 0.844917262713877\n",
      "108 Train Loss 0.5049391 Test MSE 3.1169206004134478 Test RE 0.8438610272141621\n",
      "109 Train Loss 0.50118136 Test MSE 3.139314484995026 Test RE 0.8468870114679828\n",
      "110 Train Loss 0.4986951 Test MSE 3.1476653798910297 Test RE 0.8480126660440624\n",
      "111 Train Loss 0.4957906 Test MSE 3.1250945607559024 Test RE 0.8449667933162782\n",
      "112 Train Loss 0.4930666 Test MSE 3.1410325249623 Test RE 0.8471187159895959\n",
      "113 Train Loss 0.48941967 Test MSE 3.169854641643476 Test RE 0.8509964218147914\n",
      "114 Train Loss 0.48576108 Test MSE 3.1817223209281353 Test RE 0.8525879644265786\n",
      "115 Train Loss 0.48271126 Test MSE 3.1853531209184025 Test RE 0.8530742880966746\n",
      "116 Train Loss 0.48023212 Test MSE 3.18903469793289 Test RE 0.8535671301169435\n",
      "117 Train Loss 0.4768666 Test MSE 3.204369357830213 Test RE 0.855616882721785\n",
      "118 Train Loss 0.47357425 Test MSE 3.2161549559556186 Test RE 0.8571889083647474\n",
      "119 Train Loss 0.46874285 Test MSE 3.242754392316171 Test RE 0.8607263299588449\n",
      "120 Train Loss 0.46371186 Test MSE 3.2491887435807634 Test RE 0.861579843721689\n",
      "121 Train Loss 0.46044976 Test MSE 3.258542127464088 Test RE 0.8628190600910024\n",
      "122 Train Loss 0.4586308 Test MSE 3.257585114510353 Test RE 0.862692348570686\n",
      "123 Train Loss 0.45565012 Test MSE 3.270727026380213 Test RE 0.8644307552310873\n",
      "124 Train Loss 0.45259324 Test MSE 3.251481094812194 Test RE 0.8618837188638712\n",
      "125 Train Loss 0.45098627 Test MSE 3.2554623280244757 Test RE 0.862411218526069\n",
      "126 Train Loss 0.44887418 Test MSE 3.258663682483667 Test RE 0.8628351530254436\n",
      "127 Train Loss 0.44661164 Test MSE 3.2582014260556855 Test RE 0.8627739522879085\n",
      "128 Train Loss 0.4444902 Test MSE 3.254634279595854 Test RE 0.8623015315448783\n",
      "129 Train Loss 0.44221655 Test MSE 3.2588894397500843 Test RE 0.8628650407264876\n",
      "130 Train Loss 0.4395097 Test MSE 3.243436057114071 Test RE 0.8608167925622082\n",
      "131 Train Loss 0.43712154 Test MSE 3.248496013220082 Test RE 0.8614879939742214\n",
      "132 Train Loss 0.4355321 Test MSE 3.2585555739962704 Test RE 0.8628208403215221\n",
      "133 Train Loss 0.4334147 Test MSE 3.2605019750195448 Test RE 0.8630784920047688\n",
      "134 Train Loss 0.43201602 Test MSE 3.268111535014016 Test RE 0.8640850578779639\n",
      "135 Train Loss 0.43072042 Test MSE 3.273800281928617 Test RE 0.8648367800736899\n",
      "136 Train Loss 0.42917898 Test MSE 3.2643210240688543 Test RE 0.8635838090520686\n",
      "137 Train Loss 0.4277007 Test MSE 3.2676055605510763 Test RE 0.8640181657459296\n",
      "138 Train Loss 0.4260551 Test MSE 3.2742340713003983 Test RE 0.8648940750435499\n",
      "139 Train Loss 0.42384142 Test MSE 3.2782806142941845 Test RE 0.8654283603623567\n",
      "140 Train Loss 0.422497 Test MSE 3.290142843321301 Test RE 0.8669926925182609\n",
      "141 Train Loss 0.4209802 Test MSE 3.2879472613716647 Test RE 0.8667033629551973\n",
      "142 Train Loss 0.41918242 Test MSE 3.27662391786691 Test RE 0.8652096583313665\n",
      "143 Train Loss 0.41753367 Test MSE 3.290083664154817 Test RE 0.866984895267799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 Train Loss 0.41531482 Test MSE 3.2877145530031475 Test RE 0.8666726914330634\n",
      "145 Train Loss 0.41365546 Test MSE 3.285351036895581 Test RE 0.8663611128106027\n",
      "146 Train Loss 0.41224056 Test MSE 3.2883858885056685 Test RE 0.8667611721145291\n",
      "147 Train Loss 0.41141075 Test MSE 3.2836133807232186 Test RE 0.8661319688270038\n",
      "148 Train Loss 0.4099094 Test MSE 3.287740703404318 Test RE 0.8666761381729083\n",
      "149 Train Loss 0.40804526 Test MSE 3.2917499552346134 Test RE 0.8672044134438265\n",
      "Training time: 229.08\n",
      "9\n",
      "KG_rowdy_tune67\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 65.805275 Test MSE 6.445032388509962 Test RE 1.213446441364272\n",
      "1 Train Loss 51.008278 Test MSE 8.911761685888804 Test RE 1.4268878581595643\n",
      "2 Train Loss 38.624626 Test MSE 8.967401325871085 Test RE 1.4313352388628655\n",
      "3 Train Loss 32.036156 Test MSE 8.663886026959755 Test RE 1.406903874157174\n",
      "4 Train Loss 27.913815 Test MSE 8.799350615550013 Test RE 1.4178600688707101\n",
      "5 Train Loss 25.429619 Test MSE 8.659316567589544 Test RE 1.4065328144529206\n",
      "6 Train Loss 23.00786 Test MSE 8.470638055988074 Test RE 1.391124895541427\n",
      "7 Train Loss 21.109116 Test MSE 8.62710338969509 Test RE 1.4039141835296356\n",
      "8 Train Loss 19.541904 Test MSE 8.252148428265016 Test RE 1.373066513679863\n",
      "9 Train Loss 18.073826 Test MSE 8.381983425181165 Test RE 1.383825914137916\n",
      "10 Train Loss 16.563066 Test MSE 8.417312982236384 Test RE 1.3867392191003558\n",
      "11 Train Loss 15.495467 Test MSE 8.357841869481996 Test RE 1.3818316486770015\n",
      "12 Train Loss 14.036011 Test MSE 7.884094831851153 Test RE 1.3420972299756513\n",
      "13 Train Loss 10.705278 Test MSE 6.558432145225767 Test RE 1.2240751322153616\n",
      "14 Train Loss 9.525299 Test MSE 6.238948464542923 Test RE 1.1938884738329343\n",
      "15 Train Loss 8.642585 Test MSE 6.195891145969719 Test RE 1.1897616056265443\n",
      "16 Train Loss 7.9760695 Test MSE 6.1155460997517785 Test RE 1.182022333783726\n",
      "17 Train Loss 7.190403 Test MSE 6.257484330464199 Test RE 1.195660675057286\n",
      "18 Train Loss 6.157449 Test MSE 5.763668855900791 Test RE 1.1475128850716134\n",
      "19 Train Loss 5.126114 Test MSE 5.4740833986737565 Test RE 1.1183140085553143\n",
      "20 Train Loss 4.305394 Test MSE 5.411736902594214 Test RE 1.1119273115423594\n",
      "21 Train Loss 3.5758636 Test MSE 5.352140592788694 Test RE 1.1057878579266953\n",
      "22 Train Loss 3.0647535 Test MSE 5.371554842161326 Test RE 1.1077915990371072\n",
      "23 Train Loss 2.5973275 Test MSE 5.195898642899577 Test RE 1.0895279996326754\n",
      "24 Train Loss 2.3819654 Test MSE 5.205008989410067 Test RE 1.0904827555966878\n",
      "25 Train Loss 2.157333 Test MSE 5.319562872227568 Test RE 1.1024173342081716\n",
      "26 Train Loss 2.0068245 Test MSE 5.268173432273515 Test RE 1.097079480490178\n",
      "27 Train Loss 1.8920323 Test MSE 5.364365565975506 Test RE 1.10705001800481\n",
      "28 Train Loss 1.7525458 Test MSE 5.433982579548299 Test RE 1.1142103316330039\n",
      "29 Train Loss 1.6810559 Test MSE 5.450483240260132 Test RE 1.1159007373842496\n",
      "30 Train Loss 1.6157553 Test MSE 5.44829663739312 Test RE 1.1156768786534066\n",
      "31 Train Loss 1.5838608 Test MSE 5.454822519379818 Test RE 1.1163448485929648\n",
      "32 Train Loss 1.5450573 Test MSE 5.507247685991402 Test RE 1.121696500209875\n",
      "33 Train Loss 1.4967204 Test MSE 5.527952369643303 Test RE 1.1238030500916916\n",
      "34 Train Loss 1.4577227 Test MSE 5.504351119464282 Test RE 1.1214014802607075\n",
      "35 Train Loss 1.4117473 Test MSE 5.520764103237608 Test RE 1.1230721444146745\n",
      "36 Train Loss 1.3730714 Test MSE 5.526733872107355 Test RE 1.1236791862607558\n",
      "37 Train Loss 1.3372269 Test MSE 5.550457396874611 Test RE 1.126088302192658\n",
      "38 Train Loss 1.3092135 Test MSE 5.590766180422516 Test RE 1.1301698700421747\n",
      "39 Train Loss 1.280046 Test MSE 5.588857344350987 Test RE 1.129976918564921\n",
      "40 Train Loss 1.2511569 Test MSE 5.655357076275829 Test RE 1.1366796265102375\n",
      "41 Train Loss 1.2232428 Test MSE 5.678271612727014 Test RE 1.1389801139708005\n",
      "42 Train Loss 1.2041668 Test MSE 5.733472716136749 Test RE 1.1445029999221563\n",
      "43 Train Loss 1.1874415 Test MSE 5.726682385172614 Test RE 1.1438250637976617\n",
      "44 Train Loss 1.1707108 Test MSE 5.753064080005384 Test RE 1.1464567244871686\n",
      "45 Train Loss 1.1460395 Test MSE 5.754662670683219 Test RE 1.1466159950698902\n",
      "46 Train Loss 1.1287248 Test MSE 5.7417871125884545 Test RE 1.1453325498998161\n",
      "47 Train Loss 1.1088842 Test MSE 5.702156776635037 Test RE 1.1413731113462935\n",
      "48 Train Loss 1.0902526 Test MSE 5.776966828098766 Test RE 1.1488358967856265\n",
      "49 Train Loss 1.0757954 Test MSE 5.767269685524157 Test RE 1.1478712812019338\n",
      "50 Train Loss 1.0532306 Test MSE 5.80072485380201 Test RE 1.1511957916160633\n",
      "51 Train Loss 1.0366408 Test MSE 5.831957384850779 Test RE 1.1542907919605379\n",
      "52 Train Loss 1.022788 Test MSE 5.878329382302894 Test RE 1.1588707969576724\n",
      "53 Train Loss 1.0096055 Test MSE 5.873968223987943 Test RE 1.1584408315345942\n",
      "54 Train Loss 1.0002812 Test MSE 5.878551203164361 Test RE 1.1588926619533841\n",
      "55 Train Loss 0.9862042 Test MSE 5.876835712723704 Test RE 1.1587235544406351\n",
      "56 Train Loss 0.9772865 Test MSE 5.897745001479377 Test RE 1.1607830448236507\n",
      "57 Train Loss 0.96905035 Test MSE 5.93567565380714 Test RE 1.164509782125644\n",
      "58 Train Loss 0.95266193 Test MSE 5.970095907075409 Test RE 1.1678813259185854\n",
      "59 Train Loss 0.9414869 Test MSE 5.987893269127908 Test RE 1.1696208071217002\n",
      "60 Train Loss 0.93245435 Test MSE 6.001975057933861 Test RE 1.170995303997717\n",
      "61 Train Loss 0.925104 Test MSE 6.0201060887911835 Test RE 1.172762667391222\n",
      "62 Train Loss 0.9194086 Test MSE 6.030237471163841 Test RE 1.1737490878993873\n",
      "63 Train Loss 0.91325474 Test MSE 6.018176908439418 Test RE 1.1725747427976532\n",
      "64 Train Loss 0.90552634 Test MSE 6.034762170191073 Test RE 1.1741893579155964\n",
      "65 Train Loss 0.8990699 Test MSE 6.04005183817665 Test RE 1.1747038530377165\n",
      "66 Train Loss 0.8918352 Test MSE 6.035713192211029 Test RE 1.17428187489575\n",
      "67 Train Loss 0.8868534 Test MSE 6.036569656893518 Test RE 1.1743651869456655\n",
      "68 Train Loss 0.87889785 Test MSE 6.043266491508857 Test RE 1.1750164135451981\n",
      "69 Train Loss 0.8731626 Test MSE 6.069379891374291 Test RE 1.1775523432709931\n",
      "70 Train Loss 0.864011 Test MSE 6.074127280336206 Test RE 1.1780127862123912\n",
      "71 Train Loss 0.8557519 Test MSE 6.1175062528241355 Test RE 1.18221174933587\n",
      "72 Train Loss 0.8508595 Test MSE 6.124486831106419 Test RE 1.1828860574985482\n",
      "73 Train Loss 0.8461621 Test MSE 6.119604895664529 Test RE 1.1824145139407636\n",
      "74 Train Loss 0.840204 Test MSE 6.1245864648820865 Test RE 1.1828956791148586\n",
      "75 Train Loss 0.8355658 Test MSE 6.1454072064419085 Test RE 1.1849046203951181\n",
      "76 Train Loss 0.8310105 Test MSE 6.1327553959133505 Test RE 1.1836842852774063\n",
      "77 Train Loss 0.8257916 Test MSE 6.153181069048974 Test RE 1.185653828235466\n",
      "78 Train Loss 0.82005113 Test MSE 6.156291567175669 Test RE 1.1859534706489228\n",
      "79 Train Loss 0.8147656 Test MSE 6.150276941707825 Test RE 1.1853739976859663\n",
      "80 Train Loss 0.811734 Test MSE 6.165505618655452 Test RE 1.186840640345691\n",
      "81 Train Loss 0.8078438 Test MSE 6.171592717719391 Test RE 1.187426369622521\n",
      "82 Train Loss 0.8050826 Test MSE 6.172600062122519 Test RE 1.1875232731737304\n",
      "83 Train Loss 0.80218196 Test MSE 6.179035014210104 Test RE 1.1881421100264986\n",
      "84 Train Loss 0.7997178 Test MSE 6.173469961331266 Test RE 1.1876069485416487\n",
      "85 Train Loss 0.7967297 Test MSE 6.177423441722211 Test RE 1.1879871584848918\n",
      "86 Train Loss 0.7929692 Test MSE 6.176455365300129 Test RE 1.1878940689120794\n",
      "87 Train Loss 0.790379 Test MSE 6.199498149064633 Test RE 1.19010787134464\n",
      "88 Train Loss 0.78774035 Test MSE 6.214274136151585 Test RE 1.1915252887289425\n",
      "89 Train Loss 0.78474355 Test MSE 6.205338500667566 Test RE 1.190668320918216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 Train Loss 0.78270996 Test MSE 6.20870278375094 Test RE 1.1909910432401718\n",
      "91 Train Loss 0.77880335 Test MSE 6.223526336683526 Test RE 1.192411967553311\n",
      "92 Train Loss 0.77523196 Test MSE 6.2245010897325495 Test RE 1.192505344011486\n",
      "93 Train Loss 0.77271545 Test MSE 6.225440929053231 Test RE 1.1925953689864486\n",
      "94 Train Loss 0.770475 Test MSE 6.23380680251729 Test RE 1.193396416852521\n",
      "95 Train Loss 0.76780593 Test MSE 6.220607117264316 Test RE 1.192132277208186\n",
      "96 Train Loss 0.765619 Test MSE 6.230094593901156 Test RE 1.193041032387592\n",
      "97 Train Loss 0.76298404 Test MSE 6.246893348504962 Test RE 1.1946484005768112\n",
      "98 Train Loss 0.75977635 Test MSE 6.23444748366365 Test RE 1.19345774109343\n",
      "99 Train Loss 0.75639105 Test MSE 6.230163073427061 Test RE 1.1930475891628183\n",
      "100 Train Loss 0.75278443 Test MSE 6.242379489510374 Test RE 1.1942167100869563\n",
      "101 Train Loss 0.7506628 Test MSE 6.241618814906577 Test RE 1.1941439463275647\n",
      "102 Train Loss 0.7475561 Test MSE 6.259938653289131 Test RE 1.1958951342616266\n",
      "103 Train Loss 0.74358946 Test MSE 6.254302866404419 Test RE 1.1953566842765009\n",
      "104 Train Loss 0.741324 Test MSE 6.260257062730726 Test RE 1.195925548254559\n",
      "105 Train Loss 0.7383706 Test MSE 6.278707410600869 Test RE 1.1976865788568105\n",
      "106 Train Loss 0.73626506 Test MSE 6.290624871094298 Test RE 1.1988226897618894\n",
      "107 Train Loss 0.73404247 Test MSE 6.281903056376996 Test RE 1.197991330689399\n",
      "108 Train Loss 0.7320925 Test MSE 6.28050297181381 Test RE 1.1978578215743185\n",
      "109 Train Loss 0.7298149 Test MSE 6.272509410569472 Test RE 1.1970952872235965\n",
      "110 Train Loss 0.7278892 Test MSE 6.281455731753212 Test RE 1.197948676372959\n",
      "111 Train Loss 0.7253842 Test MSE 6.280561780207965 Test RE 1.1978634297183095\n",
      "112 Train Loss 0.7226787 Test MSE 6.281968623614864 Test RE 1.1979975826783968\n",
      "113 Train Loss 0.72060245 Test MSE 6.296069286305064 Test RE 1.1993413565881155\n",
      "114 Train Loss 0.7183817 Test MSE 6.308540484131691 Test RE 1.2005285912882766\n",
      "115 Train Loss 0.71588194 Test MSE 6.321993530822782 Test RE 1.2018079811860123\n",
      "116 Train Loss 0.7134885 Test MSE 6.338912042516512 Test RE 1.203415007286417\n",
      "117 Train Loss 0.7111826 Test MSE 6.3424535408466305 Test RE 1.2037511294084233\n",
      "118 Train Loss 0.7074697 Test MSE 6.3637638702670625 Test RE 1.2057717056274428\n",
      "119 Train Loss 0.70423234 Test MSE 6.3597799542283004 Test RE 1.2053942210612172\n",
      "120 Train Loss 0.70054567 Test MSE 6.380269752905813 Test RE 1.2073344158461061\n",
      "121 Train Loss 0.6972005 Test MSE 6.387626651402721 Test RE 1.2080302859352834\n",
      "122 Train Loss 0.6948688 Test MSE 6.393609644377912 Test RE 1.2085959064273089\n",
      "123 Train Loss 0.6917794 Test MSE 6.407581161392428 Test RE 1.2099157167038628\n",
      "124 Train Loss 0.6879372 Test MSE 6.421802310498766 Test RE 1.2112576314517054\n",
      "125 Train Loss 0.68580943 Test MSE 6.4152432496437815 Test RE 1.210638899996068\n",
      "126 Train Loss 0.6833799 Test MSE 6.428486098894166 Test RE 1.2118878037840217\n",
      "127 Train Loss 0.6802381 Test MSE 6.44449248397552 Test RE 1.2133956147029334\n",
      "128 Train Loss 0.6769539 Test MSE 6.471321939635116 Test RE 1.215918771616746\n",
      "129 Train Loss 0.675137 Test MSE 6.467677811843296 Test RE 1.2155763696009148\n",
      "130 Train Loss 0.67298925 Test MSE 6.474948990613378 Test RE 1.2162594733795724\n",
      "131 Train Loss 0.6706623 Test MSE 6.4871813439698025 Test RE 1.2174077986888936\n",
      "132 Train Loss 0.6681376 Test MSE 6.4671703338069655 Test RE 1.2155286793457631\n",
      "133 Train Loss 0.6664137 Test MSE 6.469274035588066 Test RE 1.2157263625518169\n",
      "134 Train Loss 0.6641712 Test MSE 6.476638493396482 Test RE 1.2164181417908306\n",
      "135 Train Loss 0.66174555 Test MSE 6.4959339142400765 Test RE 1.2182287912782959\n",
      "136 Train Loss 0.658753 Test MSE 6.504091724659837 Test RE 1.2189934974370285\n",
      "137 Train Loss 0.6556922 Test MSE 6.508963744008037 Test RE 1.2194499676405977\n",
      "138 Train Loss 0.65278876 Test MSE 6.524379679322006 Test RE 1.2208931961466254\n",
      "139 Train Loss 0.65058655 Test MSE 6.52666813410303 Test RE 1.221107294195312\n",
      "140 Train Loss 0.6476442 Test MSE 6.539093155779307 Test RE 1.222269071549794\n",
      "141 Train Loss 0.64548075 Test MSE 6.5498316125216505 Test RE 1.223272261066728\n",
      "142 Train Loss 0.64354795 Test MSE 6.5566229591678695 Test RE 1.2239062860367633\n",
      "143 Train Loss 0.6423553 Test MSE 6.5679284244396 Test RE 1.2249610112045257\n",
      "144 Train Loss 0.641378 Test MSE 6.574823515256202 Test RE 1.2256038319922113\n",
      "145 Train Loss 0.63988554 Test MSE 6.579407846761576 Test RE 1.2260310370109464\n",
      "146 Train Loss 0.638757 Test MSE 6.587299718676592 Test RE 1.2267661168558577\n",
      "147 Train Loss 0.63729763 Test MSE 6.585050381550585 Test RE 1.226556649677295\n",
      "148 Train Loss 0.635751 Test MSE 6.580774805391779 Test RE 1.2261583924436608\n",
      "149 Train Loss 0.6345854 Test MSE 6.579634673261991 Test RE 1.2260521706706304\n",
      "Training time: 229.62\n",
      "0\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 73.049706 Test MSE 4.395919356111028 Test RE 1.0021504333080231\n",
      "1 Train Loss 71.478035 Test MSE 4.357242629905918 Test RE 0.9977320707939167\n",
      "2 Train Loss 65.19554 Test MSE 5.169990241651931 Test RE 1.0868082386358946\n",
      "3 Train Loss 47.95851 Test MSE 6.599709552486109 Test RE 1.2279211273238342\n",
      "4 Train Loss 42.566284 Test MSE 6.777787336394961 Test RE 1.2443771545024003\n",
      "5 Train Loss 36.606796 Test MSE 8.482900176890576 Test RE 1.392131429680707\n",
      "6 Train Loss 33.08515 Test MSE 8.926884007269399 Test RE 1.428097984251682\n",
      "7 Train Loss 29.789558 Test MSE 9.332941010353279 Test RE 1.460216732579552\n",
      "8 Train Loss 27.58751 Test MSE 8.912522363330236 Test RE 1.4269487539893044\n",
      "9 Train Loss 25.899895 Test MSE 9.285311477429374 Test RE 1.4564859470589313\n",
      "10 Train Loss 24.469803 Test MSE 9.258388544469964 Test RE 1.454372860195788\n",
      "11 Train Loss 23.272446 Test MSE 9.235412645857185 Test RE 1.4525671312490689\n",
      "12 Train Loss 22.12624 Test MSE 9.12980131514511 Test RE 1.4442378528869815\n",
      "13 Train Loss 21.095507 Test MSE 9.079777615904675 Test RE 1.440275808606948\n",
      "14 Train Loss 19.519073 Test MSE 9.0168943741876 Test RE 1.4352797297716304\n",
      "15 Train Loss 18.55615 Test MSE 8.949571373202883 Test RE 1.4299115634310788\n",
      "16 Train Loss 17.498686 Test MSE 8.920298756189863 Test RE 1.427571142029973\n",
      "17 Train Loss 16.512953 Test MSE 8.894324040497816 Test RE 1.4254911787642082\n",
      "18 Train Loss 15.10498 Test MSE 9.029731137893837 Test RE 1.4363010234265083\n",
      "19 Train Loss 13.1325035 Test MSE 8.294868917691801 Test RE 1.3766160349481331\n",
      "20 Train Loss 11.843998 Test MSE 8.226621847931801 Test RE 1.3709411980727266\n",
      "21 Train Loss 10.236456 Test MSE 7.779874607924291 Test RE 1.3331970957978059\n",
      "22 Train Loss 8.480377 Test MSE 6.742126045752428 Test RE 1.2410991953114412\n",
      "23 Train Loss 7.148966 Test MSE 6.318954179600058 Test RE 1.2015190568409184\n",
      "24 Train Loss 5.452364 Test MSE 5.555957803225237 Test RE 1.1266461309483304\n",
      "25 Train Loss 4.5119667 Test MSE 5.44709615609422 Test RE 1.1155539573897542\n",
      "26 Train Loss 4.035812 Test MSE 5.382006901073432 Test RE 1.1088688547257801\n",
      "27 Train Loss 3.6420732 Test MSE 5.314060466373863 Test RE 1.101847031989569\n",
      "28 Train Loss 3.3355663 Test MSE 5.225909906276659 Test RE 1.0926700001008065\n",
      "29 Train Loss 3.0404801 Test MSE 5.267039274995856 Test RE 1.0969613819055586\n",
      "30 Train Loss 2.8858793 Test MSE 5.266224880782173 Test RE 1.0968765720635325\n",
      "31 Train Loss 2.72425 Test MSE 5.14342120227087 Test RE 1.0840120394603692\n",
      "32 Train Loss 2.5308576 Test MSE 5.151878945782619 Test RE 1.0849029377055348\n",
      "33 Train Loss 2.4633753 Test MSE 5.140010371813835 Test RE 1.0836525516494142\n",
      "34 Train Loss 2.3941162 Test MSE 5.17161141474908 Test RE 1.0869786225337186\n",
      "35 Train Loss 2.2857368 Test MSE 5.170926537105835 Test RE 1.086906645740992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 Train Loss 2.2060108 Test MSE 5.220542273341062 Test RE 1.0921087047104994\n",
      "37 Train Loss 2.1095495 Test MSE 5.349664215677186 Test RE 1.1055320103346629\n",
      "38 Train Loss 2.0249543 Test MSE 5.333545354173885 Test RE 1.103865236493773\n",
      "39 Train Loss 1.9390669 Test MSE 5.358172989545425 Test RE 1.106410849086627\n",
      "40 Train Loss 1.8602407 Test MSE 5.420317095111303 Test RE 1.1128084308558208\n",
      "41 Train Loss 1.8156472 Test MSE 5.413086699618946 Test RE 1.1120659715168069\n",
      "42 Train Loss 1.7577826 Test MSE 5.447328319489163 Test RE 1.115577730426523\n",
      "43 Train Loss 1.7161138 Test MSE 5.424075856870148 Test RE 1.1131942068913352\n",
      "44 Train Loss 1.6768882 Test MSE 5.511958710388948 Test RE 1.1221761599489604\n",
      "45 Train Loss 1.6398991 Test MSE 5.530178823999455 Test RE 1.1240293404196338\n",
      "46 Train Loss 1.598282 Test MSE 5.5565433776738935 Test RE 1.1267055012520582\n",
      "47 Train Loss 1.5623996 Test MSE 5.501913820328094 Test RE 1.1211531772884182\n",
      "48 Train Loss 1.5318134 Test MSE 5.5241031877558076 Test RE 1.1234117229481084\n",
      "49 Train Loss 1.5034661 Test MSE 5.539917692349073 Test RE 1.1250186356058203\n",
      "50 Train Loss 1.4769384 Test MSE 5.566532158932955 Test RE 1.1277177637924785\n",
      "51 Train Loss 1.4568368 Test MSE 5.594921306823966 Test RE 1.1305897701333851\n",
      "52 Train Loss 1.4408885 Test MSE 5.602070237677744 Test RE 1.131311847123595\n",
      "53 Train Loss 1.4222136 Test MSE 5.605738688284387 Test RE 1.131682199712631\n",
      "54 Train Loss 1.4116329 Test MSE 5.610110801693611 Test RE 1.132123433136283\n",
      "55 Train Loss 1.3939766 Test MSE 5.642758035898204 Test RE 1.1354127694967309\n",
      "56 Train Loss 1.3760691 Test MSE 5.639853615430937 Test RE 1.1351205240626743\n",
      "57 Train Loss 1.3530188 Test MSE 5.633817737430041 Test RE 1.1345129477330365\n",
      "58 Train Loss 1.338591 Test MSE 5.66274116323251 Test RE 1.1374214544022232\n",
      "59 Train Loss 1.3281643 Test MSE 5.6857526215419565 Test RE 1.1397301587230912\n",
      "60 Train Loss 1.3147204 Test MSE 5.677530580384327 Test RE 1.1389057912984852\n",
      "61 Train Loss 1.3081821 Test MSE 5.692768535350203 Test RE 1.1404331248803983\n",
      "62 Train Loss 1.2990279 Test MSE 5.680514676302016 Test RE 1.1392050550027657\n",
      "63 Train Loss 1.2837458 Test MSE 5.703887866835956 Test RE 1.1415463501707765\n",
      "64 Train Loss 1.2772137 Test MSE 5.697516988222552 Test RE 1.1409086548561416\n",
      "65 Train Loss 1.2695701 Test MSE 5.702118436823125 Test RE 1.1413692741925914\n",
      "66 Train Loss 1.2525303 Test MSE 5.696575414084138 Test RE 1.1408143774303476\n",
      "67 Train Loss 1.2404827 Test MSE 5.710103340019344 Test RE 1.14216814700813\n",
      "68 Train Loss 1.2288517 Test MSE 5.721928955426256 Test RE 1.1433502495466277\n",
      "69 Train Loss 1.2172909 Test MSE 5.679186908842844 Test RE 1.1390719079301064\n",
      "70 Train Loss 1.2072364 Test MSE 5.690871924556447 Test RE 1.1402431349006277\n",
      "71 Train Loss 1.1989775 Test MSE 5.6926943609281855 Test RE 1.140425695169976\n",
      "72 Train Loss 1.1907289 Test MSE 5.7042993184389506 Test RE 1.1415875223165668\n",
      "73 Train Loss 1.1829813 Test MSE 5.71812425949624 Test RE 1.1429700610257587\n",
      "74 Train Loss 1.1752157 Test MSE 5.7157643217569785 Test RE 1.1427341780313753\n",
      "75 Train Loss 1.1677442 Test MSE 5.735437473021457 Test RE 1.1446990833124846\n",
      "76 Train Loss 1.159982 Test MSE 5.749614071794272 Test RE 1.1461129182811005\n",
      "77 Train Loss 1.1523613 Test MSE 5.764186749493615 Test RE 1.14756443871187\n",
      "78 Train Loss 1.1447814 Test MSE 5.7874467908395095 Test RE 1.1498774729608843\n",
      "79 Train Loss 1.1400144 Test MSE 5.776141484700464 Test RE 1.148753827940499\n",
      "80 Train Loss 1.1337314 Test MSE 5.777080237056405 Test RE 1.1488471732604628\n",
      "81 Train Loss 1.1268874 Test MSE 5.783794233831493 Test RE 1.1495145619869132\n",
      "82 Train Loss 1.1190652 Test MSE 5.7733143201276125 Test RE 1.1484726615568197\n",
      "83 Train Loss 1.1094105 Test MSE 5.781719071862922 Test RE 1.1493083268746553\n",
      "84 Train Loss 1.1024573 Test MSE 5.780413728245587 Test RE 1.1491785793931977\n",
      "85 Train Loss 1.0960566 Test MSE 5.774753922805802 Test RE 1.1486158411217384\n",
      "86 Train Loss 1.0892975 Test MSE 5.758131318987137 Test RE 1.1469615069369448\n",
      "87 Train Loss 1.0836772 Test MSE 5.775875298206564 Test RE 1.148727358170185\n",
      "88 Train Loss 1.0747988 Test MSE 5.7827207495991795 Test RE 1.1494078808905506\n",
      "89 Train Loss 1.0653327 Test MSE 5.772997631081562 Test RE 1.1484411619987422\n",
      "90 Train Loss 1.0565693 Test MSE 5.778546012305932 Test RE 1.148992908206352\n",
      "91 Train Loss 1.0500023 Test MSE 5.783698584056505 Test RE 1.1495050568714702\n",
      "92 Train Loss 1.0444473 Test MSE 5.800692863111983 Test RE 1.151192617219808\n",
      "93 Train Loss 1.0394882 Test MSE 5.7852146760858245 Test RE 1.1496557079847736\n",
      "94 Train Loss 1.0327007 Test MSE 5.803894358814451 Test RE 1.1515102542605058\n",
      "95 Train Loss 1.0294713 Test MSE 5.7911469709362775 Test RE 1.1502449989222832\n",
      "96 Train Loss 1.0238903 Test MSE 5.7941306365553755 Test RE 1.1505412705022737\n",
      "97 Train Loss 1.0188253 Test MSE 5.801570337591908 Test RE 1.151279684745068\n",
      "98 Train Loss 1.0141469 Test MSE 5.813587237856956 Test RE 1.152471401442255\n",
      "99 Train Loss 1.0087907 Test MSE 5.819989800711215 Test RE 1.15310584105955\n",
      "100 Train Loss 1.0024434 Test MSE 5.823438898746007 Test RE 1.1534474727593573\n",
      "101 Train Loss 0.9981893 Test MSE 5.828526481927167 Test RE 1.153951211095002\n",
      "102 Train Loss 0.9937247 Test MSE 5.808030007656914 Test RE 1.1519204438424282\n",
      "103 Train Loss 0.9885164 Test MSE 5.839505707996754 Test RE 1.1550375517400313\n",
      "104 Train Loss 0.98500633 Test MSE 5.826653433272781 Test RE 1.1537657799706362\n",
      "105 Train Loss 0.98085463 Test MSE 5.840979386842921 Test RE 1.1551832872795378\n",
      "106 Train Loss 0.9761199 Test MSE 5.861950101798197 Test RE 1.157255141430035\n",
      "107 Train Loss 0.9714809 Test MSE 5.870190819360412 Test RE 1.1580682892151972\n",
      "108 Train Loss 0.96805775 Test MSE 5.874319827107277 Test RE 1.1584755019055755\n",
      "109 Train Loss 0.96330214 Test MSE 5.884534318384192 Test RE 1.1594822651311922\n",
      "110 Train Loss 0.95897317 Test MSE 5.88641983371737 Test RE 1.1596680102023067\n",
      "111 Train Loss 0.95499724 Test MSE 5.893904552864335 Test RE 1.1604050483528006\n",
      "112 Train Loss 0.9509675 Test MSE 5.884871119609086 Test RE 1.1595154461306043\n",
      "113 Train Loss 0.94796646 Test MSE 5.897643749227646 Test RE 1.1607730806423002\n",
      "114 Train Loss 0.9454497 Test MSE 5.879459833895871 Test RE 1.1589822218435613\n",
      "115 Train Loss 0.9427844 Test MSE 5.886005959152565 Test RE 1.1596272413187283\n",
      "116 Train Loss 0.93962526 Test MSE 5.898187188027823 Test RE 1.1608265591691687\n",
      "117 Train Loss 0.9365309 Test MSE 5.895276591142592 Test RE 1.1605401054685012\n",
      "118 Train Loss 0.9332203 Test MSE 5.9321387139735595 Test RE 1.164162777417664\n",
      "119 Train Loss 0.92944014 Test MSE 5.931043912285666 Test RE 1.1640553468394648\n",
      "120 Train Loss 0.92655677 Test MSE 5.922223085688978 Test RE 1.163189415727636\n",
      "121 Train Loss 0.9233356 Test MSE 5.943157969538359 Test RE 1.1652435221577166\n",
      "122 Train Loss 0.91978157 Test MSE 5.941407276463737 Test RE 1.1650718849550679\n",
      "123 Train Loss 0.91501397 Test MSE 5.945119968286328 Test RE 1.1654358456404197\n",
      "124 Train Loss 0.91258144 Test MSE 5.950420279068314 Test RE 1.1659552460920553\n",
      "125 Train Loss 0.90876216 Test MSE 5.961365325355033 Test RE 1.1670270671288754\n",
      "126 Train Loss 0.906636 Test MSE 5.968560627586624 Test RE 1.1677311491406905\n",
      "127 Train Loss 0.90436006 Test MSE 5.959691463080414 Test RE 1.1668632137481376\n",
      "128 Train Loss 0.9012483 Test MSE 5.974827249441042 Test RE 1.1683440112871852\n",
      "129 Train Loss 0.8989667 Test MSE 5.963493381112886 Test RE 1.1672353480290834\n",
      "130 Train Loss 0.8960321 Test MSE 5.986275464935741 Test RE 1.1694627928429993\n",
      "131 Train Loss 0.8934393 Test MSE 5.974285364232811 Test RE 1.1682910287768165\n",
      "132 Train Loss 0.891118 Test MSE 5.980377897248494 Test RE 1.168886584351434\n",
      "133 Train Loss 0.8878069 Test MSE 5.994801574815967 Test RE 1.1702953155446192\n",
      "134 Train Loss 0.8853729 Test MSE 5.994260530286472 Test RE 1.1702425034408626\n",
      "135 Train Loss 0.88243103 Test MSE 6.011115329104597 Test RE 1.1718866058353878\n",
      "136 Train Loss 0.8798452 Test MSE 6.017895012148398 Test RE 1.1725472802997237\n",
      "137 Train Loss 0.8768587 Test MSE 6.029535920542078 Test RE 1.1736808096302993\n",
      "138 Train Loss 0.87381107 Test MSE 6.0291258314722 Test RE 1.1736408959568332\n",
      "139 Train Loss 0.87116486 Test MSE 6.04461035455156 Test RE 1.1751470526092975\n",
      "140 Train Loss 0.8680891 Test MSE 6.0502881231853305 Test RE 1.1756988373066437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 Train Loss 0.8651751 Test MSE 6.054174897647621 Test RE 1.1760764178826182\n",
      "142 Train Loss 0.86151093 Test MSE 6.073054153253846 Test RE 1.1779087207881676\n",
      "143 Train Loss 0.8577892 Test MSE 6.0720537906552545 Test RE 1.1778117033462512\n",
      "144 Train Loss 0.8553608 Test MSE 6.090609753374447 Test RE 1.1796100041301978\n",
      "145 Train Loss 0.8520895 Test MSE 6.086962042143288 Test RE 1.1792567126467604\n",
      "146 Train Loss 0.848848 Test MSE 6.0813916683087665 Test RE 1.1787170013563246\n",
      "147 Train Loss 0.8463999 Test MSE 6.079154774617388 Test RE 1.1785002000655105\n",
      "148 Train Loss 0.84365416 Test MSE 6.075230589762049 Test RE 1.178119768955422\n",
      "149 Train Loss 0.8408379 Test MSE 6.083555550558225 Test RE 1.1789266883890488\n",
      "Training time: 229.80\n",
      "1\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 61.341396 Test MSE 7.4310507085601945 Test RE 1.302966268450945\n",
      "1 Train Loss 48.98504 Test MSE 8.00177525516748 Test RE 1.3520764077679062\n",
      "2 Train Loss 41.601067 Test MSE 9.256000435209137 Test RE 1.454185277590145\n",
      "3 Train Loss 39.038925 Test MSE 9.15285300355627 Test RE 1.44605996990962\n",
      "4 Train Loss 36.03721 Test MSE 9.814732909381629 Test RE 1.4974326665629163\n",
      "5 Train Loss 34.933243 Test MSE 10.153818456854163 Test RE 1.5230801476179407\n",
      "6 Train Loss 33.603874 Test MSE 10.275687970423855 Test RE 1.5321931426778843\n",
      "7 Train Loss 32.439995 Test MSE 10.412960124594392 Test RE 1.5423934168483364\n",
      "8 Train Loss 31.89809 Test MSE 10.40248889071472 Test RE 1.5416177092523053\n",
      "9 Train Loss 30.690792 Test MSE 9.834585413768707 Test RE 1.498946348659855\n",
      "10 Train Loss 28.875616 Test MSE 9.690243194927858 Test RE 1.4879056694548436\n",
      "11 Train Loss 26.605225 Test MSE 9.52207891669955 Test RE 1.4749386238090931\n",
      "12 Train Loss 24.66568 Test MSE 9.531508648150474 Test RE 1.4756687602429206\n",
      "13 Train Loss 23.567524 Test MSE 9.610752905123064 Test RE 1.4817903633311396\n",
      "14 Train Loss 22.733252 Test MSE 9.62527362771973 Test RE 1.4829093467171124\n",
      "15 Train Loss 22.274263 Test MSE 9.712038279490574 Test RE 1.489578012194103\n",
      "16 Train Loss 21.841236 Test MSE 9.672221456125328 Test RE 1.4865214355530874\n",
      "17 Train Loss 21.50166 Test MSE 9.458658398306795 Test RE 1.470018603259265\n",
      "18 Train Loss 21.247072 Test MSE 9.400152952995773 Test RE 1.465465235625994\n",
      "19 Train Loss 20.872961 Test MSE 9.443727651541373 Test RE 1.4688579130752615\n",
      "20 Train Loss 20.678482 Test MSE 9.32013998872767 Test RE 1.4592149754748862\n",
      "21 Train Loss 20.448114 Test MSE 9.28864709039823 Test RE 1.4567475342543705\n",
      "22 Train Loss 20.187954 Test MSE 9.2540038588117 Test RE 1.4540284307636002\n",
      "23 Train Loss 19.574669 Test MSE 9.312974457338173 Test RE 1.458653929116807\n",
      "24 Train Loss 19.162756 Test MSE 9.232528228046402 Test RE 1.4523402795718097\n",
      "25 Train Loss 18.57888 Test MSE 9.162510005735696 Test RE 1.4468226240661954\n",
      "26 Train Loss 17.820286 Test MSE 8.992849108046073 Test RE 1.4333647288644706\n",
      "27 Train Loss 16.463034 Test MSE 8.589973401753769 Test RE 1.4008897892020091\n",
      "28 Train Loss 15.894493 Test MSE 8.414828734922 Test RE 1.3865345660589867\n",
      "29 Train Loss 15.335286 Test MSE 8.035606936119036 Test RE 1.354931697220372\n",
      "30 Train Loss 14.872065 Test MSE 7.956222330691137 Test RE 1.3482223291360642\n",
      "31 Train Loss 14.574305 Test MSE 7.807362578707129 Test RE 1.3355502551603697\n",
      "32 Train Loss 14.378254 Test MSE 7.860487001654277 Test RE 1.3400863613783873\n",
      "33 Train Loss 14.194126 Test MSE 7.8118171394363225 Test RE 1.3359312059164916\n",
      "34 Train Loss 14.041883 Test MSE 7.783524921054256 Test RE 1.3335098268116543\n",
      "35 Train Loss 13.885979 Test MSE 7.889210728686121 Test RE 1.3425325949513975\n",
      "36 Train Loss 13.755555 Test MSE 7.9436481252283215 Test RE 1.3471565263384229\n",
      "37 Train Loss 13.678919 Test MSE 7.932346202541208 Test RE 1.3461978434967357\n",
      "38 Train Loss 13.584482 Test MSE 8.02120399670387 Test RE 1.3537168697799127\n",
      "39 Train Loss 13.491669 Test MSE 7.991049426632241 Test RE 1.3511699212512702\n",
      "40 Train Loss 13.434277 Test MSE 7.948601742571313 Test RE 1.3475765007502583\n",
      "41 Train Loss 13.337208 Test MSE 7.996000360650149 Test RE 1.3515884218102139\n",
      "42 Train Loss 13.297716 Test MSE 8.010332773334474 Test RE 1.3527992052849411\n",
      "43 Train Loss 13.1971655 Test MSE 7.996175086145198 Test RE 1.3516031889222302\n",
      "44 Train Loss 13.071384 Test MSE 7.96753715546728 Test RE 1.3491806658315442\n",
      "45 Train Loss 12.925623 Test MSE 7.982314833605448 Test RE 1.3504312732014987\n",
      "46 Train Loss 12.82229 Test MSE 7.972480071644619 Test RE 1.3495991046047584\n",
      "47 Train Loss 12.676476 Test MSE 7.832767606138246 Test RE 1.337721419473601\n",
      "48 Train Loss 12.587767 Test MSE 7.799006181306674 Test RE 1.3348353289307096\n",
      "49 Train Loss 12.498985 Test MSE 7.814738558738065 Test RE 1.3361809845736925\n",
      "50 Train Loss 12.412611 Test MSE 7.903742443951634 Test RE 1.3437684806715764\n",
      "51 Train Loss 12.2674675 Test MSE 7.827005160135963 Test RE 1.3372292584572114\n",
      "52 Train Loss 12.170665 Test MSE 7.765428350294777 Test RE 1.3319587302252118\n",
      "53 Train Loss 12.021921 Test MSE 7.758254628549936 Test RE 1.3313433547010602\n",
      "54 Train Loss 11.9457 Test MSE 7.782002120272309 Test RE 1.3333793737611745\n",
      "55 Train Loss 11.729784 Test MSE 7.692663483799011 Test RE 1.3257035754426512\n",
      "56 Train Loss 11.545853 Test MSE 7.697312152474823 Test RE 1.3261040756037377\n",
      "57 Train Loss 11.26499 Test MSE 7.61152318950759 Test RE 1.3186934459603168\n",
      "58 Train Loss 11.007694 Test MSE 7.590790363257846 Test RE 1.3168962442274736\n",
      "59 Train Loss 10.783234 Test MSE 7.421715520088197 Test RE 1.3021475916165401\n",
      "60 Train Loss 10.340377 Test MSE 7.1844361321587265 Test RE 1.2811630493174742\n",
      "61 Train Loss 9.823454 Test MSE 7.130605884650322 Test RE 1.276354391286062\n",
      "62 Train Loss 9.380185 Test MSE 6.840377497932978 Test RE 1.2501096139130368\n",
      "63 Train Loss 9.026943 Test MSE 6.745475549309458 Test RE 1.241407447482889\n",
      "64 Train Loss 8.691284 Test MSE 6.543048019126096 Test RE 1.2226386316987599\n",
      "65 Train Loss 8.470652 Test MSE 6.6665161358716025 Test RE 1.2341203895921395\n",
      "66 Train Loss 8.294367 Test MSE 6.637964470678418 Test RE 1.2314747797817582\n",
      "67 Train Loss 8.095228 Test MSE 6.666007507395122 Test RE 1.2340733094730694\n",
      "68 Train Loss 7.929233 Test MSE 6.49204518594353 Test RE 1.2178640962212792\n",
      "69 Train Loss 7.790644 Test MSE 6.387088313357358 Test RE 1.2079793795187783\n",
      "70 Train Loss 7.656625 Test MSE 6.3688165776095245 Test RE 1.2062502905372294\n",
      "71 Train Loss 7.5704584 Test MSE 6.329339424141173 Test RE 1.2025060038998987\n",
      "72 Train Loss 7.4639626 Test MSE 6.3346424176105876 Test RE 1.2030096541160649\n",
      "73 Train Loss 7.3742695 Test MSE 6.222044180808841 Test RE 1.192269970432681\n",
      "74 Train Loss 7.2918653 Test MSE 6.11996671911992 Test RE 1.1824494687285967\n",
      "75 Train Loss 7.189087 Test MSE 6.106591761924497 Test RE 1.1811566625665195\n",
      "76 Train Loss 7.1091957 Test MSE 6.027120926190013 Test RE 1.17344574042783\n",
      "77 Train Loss 6.9492674 Test MSE 5.93659496383795 Test RE 1.1645999575444288\n",
      "78 Train Loss 6.825231 Test MSE 5.919113154150416 Test RE 1.1628839633301715\n",
      "79 Train Loss 6.4894543 Test MSE 5.284222349496766 Test RE 1.0987492763859594\n",
      "80 Train Loss 5.7176657 Test MSE 4.806973580478466 Test RE 1.0479581219074783\n",
      "81 Train Loss 5.376562 Test MSE 4.715384926351348 Test RE 1.0379265844788892\n",
      "82 Train Loss 5.0185337 Test MSE 4.771154528344908 Test RE 1.0440464034434436\n",
      "83 Train Loss 4.6542697 Test MSE 4.833992122745944 Test RE 1.050899122646702\n",
      "84 Train Loss 4.376986 Test MSE 4.904241733155482 Test RE 1.058507634259485\n",
      "85 Train Loss 4.207956 Test MSE 5.011011833167873 Test RE 1.069967963501392\n",
      "86 Train Loss 3.9705749 Test MSE 4.904902660761879 Test RE 1.0585789575532942\n",
      "87 Train Loss 3.8003693 Test MSE 4.991610999327211 Test RE 1.0678946894308659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 Train Loss 3.6973548 Test MSE 5.1137828995671 Test RE 1.0808842872022584\n",
      "89 Train Loss 3.591839 Test MSE 5.133338310510048 Test RE 1.0829489981960676\n",
      "90 Train Loss 3.5220299 Test MSE 5.1067845561218705 Test RE 1.0801444250096093\n",
      "91 Train Loss 3.4475982 Test MSE 5.17318743845572 Test RE 1.087144235671015\n",
      "92 Train Loss 3.389605 Test MSE 5.226756844884981 Test RE 1.092758538454326\n",
      "93 Train Loss 3.293595 Test MSE 5.264268701055191 Test RE 1.0966728315229257\n",
      "94 Train Loss 3.2137127 Test MSE 5.444771639142094 Test RE 1.1153159038728082\n",
      "95 Train Loss 3.1382606 Test MSE 5.516448404145532 Test RE 1.122633093865368\n",
      "96 Train Loss 3.0510848 Test MSE 5.523829156654412 Test RE 1.1233838583736042\n",
      "97 Train Loss 2.9903402 Test MSE 5.527190419443267 Test RE 1.123725597229385\n",
      "98 Train Loss 2.948509 Test MSE 5.552777144263563 Test RE 1.1263235951901833\n",
      "99 Train Loss 2.9089715 Test MSE 5.561123461235431 Test RE 1.1271697595186163\n",
      "100 Train Loss 2.8609943 Test MSE 5.640021869877313 Test RE 1.135137456031475\n",
      "101 Train Loss 2.8299701 Test MSE 5.6845853737426335 Test RE 1.1396131631472133\n",
      "102 Train Loss 2.7898333 Test MSE 5.66658540766517 Test RE 1.1378074674769183\n",
      "103 Train Loss 2.7532513 Test MSE 5.6465625552159056 Test RE 1.1357954699345936\n",
      "104 Train Loss 2.7002692 Test MSE 5.633906768919936 Test RE 1.1345219120786807\n",
      "105 Train Loss 2.6657248 Test MSE 5.662666083079562 Test RE 1.1374139140558281\n",
      "106 Train Loss 2.642108 Test MSE 5.651443006124715 Test RE 1.1362862106923404\n",
      "107 Train Loss 2.6035666 Test MSE 5.659555415093129 Test RE 1.1371014637868966\n",
      "108 Train Loss 2.5870302 Test MSE 5.678900842808655 Test RE 1.1390432195023412\n",
      "109 Train Loss 2.5617187 Test MSE 5.651477724475727 Test RE 1.1362897009445538\n",
      "110 Train Loss 2.5275762 Test MSE 5.703429627175813 Test RE 1.1415004944027083\n",
      "111 Train Loss 2.494763 Test MSE 5.674332797377911 Test RE 1.1385850104149817\n",
      "112 Train Loss 2.4755569 Test MSE 5.726276802089745 Test RE 1.1437845582938853\n",
      "113 Train Loss 2.4561281 Test MSE 5.7306786284191 Test RE 1.1442240911675075\n",
      "114 Train Loss 2.4349666 Test MSE 5.708718632576781 Test RE 1.142029649985013\n",
      "115 Train Loss 2.4084506 Test MSE 5.734746415354652 Test RE 1.144630119357147\n",
      "116 Train Loss 2.3724566 Test MSE 5.771936745801175 Test RE 1.148335634473799\n",
      "117 Train Loss 2.3359704 Test MSE 5.731458152281524 Test RE 1.1443019108910275\n",
      "118 Train Loss 2.313186 Test MSE 5.75071777456526 Test RE 1.1462229176034557\n",
      "119 Train Loss 2.2942772 Test MSE 5.7455043073844525 Test RE 1.1457032302539139\n",
      "120 Train Loss 2.2758431 Test MSE 5.738088679970104 Test RE 1.1449636214184216\n",
      "121 Train Loss 2.2669535 Test MSE 5.746665333944501 Test RE 1.1458189837731905\n",
      "122 Train Loss 2.2563298 Test MSE 5.73487298316088 Test RE 1.1446427504757106\n",
      "123 Train Loss 2.2463813 Test MSE 5.722668565318937 Test RE 1.1434241412217363\n",
      "124 Train Loss 2.2361093 Test MSE 5.7496907303507125 Test RE 1.1461205587129524\n",
      "125 Train Loss 2.2318175 Test MSE 5.741431420120081 Test RE 1.1452970737960186\n",
      "126 Train Loss 2.225942 Test MSE 5.7380850403883 Test RE 1.1449632583019163\n",
      "127 Train Loss 2.218121 Test MSE 5.733782832091014 Test RE 1.1445339518302122\n",
      "128 Train Loss 2.2089322 Test MSE 5.695679263062882 Test RE 1.1407246408688685\n",
      "129 Train Loss 2.195057 Test MSE 5.696252711313835 Test RE 1.1407820642292499\n",
      "130 Train Loss 2.1850057 Test MSE 5.710589867330702 Test RE 1.1422168049857648\n",
      "131 Train Loss 2.1763191 Test MSE 5.708023442172163 Test RE 1.141960111417993\n",
      "132 Train Loss 2.168753 Test MSE 5.719841782646013 Test RE 1.1431417021149097\n",
      "133 Train Loss 2.1539078 Test MSE 5.721790180139779 Test RE 1.1433363844915272\n",
      "134 Train Loss 2.1334467 Test MSE 5.76138525356316 Test RE 1.1472855365905665\n",
      "135 Train Loss 2.1220665 Test MSE 5.768891329282325 Test RE 1.1480326493681712\n",
      "136 Train Loss 2.0959709 Test MSE 5.804962642815155 Test RE 1.1516162247782757\n",
      "137 Train Loss 2.075683 Test MSE 5.799772806696934 Test RE 1.151101317423424\n",
      "138 Train Loss 2.0579507 Test MSE 5.8229328630506325 Test RE 1.153397356471997\n",
      "139 Train Loss 2.0317547 Test MSE 5.834384168663514 Test RE 1.1545309277053508\n",
      "140 Train Loss 2.0026977 Test MSE 5.853684992716755 Test RE 1.156439012522443\n",
      "141 Train Loss 1.9909716 Test MSE 5.860086880217444 Test RE 1.1570712099667286\n",
      "142 Train Loss 1.9847095 Test MSE 5.871192185630496 Test RE 1.1581670595199829\n",
      "143 Train Loss 1.973337 Test MSE 5.864578935380131 Test RE 1.1575146020297236\n",
      "144 Train Loss 1.954635 Test MSE 5.880451054008386 Test RE 1.1590799143276889\n",
      "145 Train Loss 1.9371284 Test MSE 5.877534941929779 Test RE 1.1587924851792302\n",
      "146 Train Loss 1.9259363 Test MSE 5.869367268606619 Test RE 1.1579870515267874\n",
      "147 Train Loss 1.9171073 Test MSE 5.851637534750852 Test RE 1.156236749558875\n",
      "148 Train Loss 1.9105018 Test MSE 5.845017491978179 Test RE 1.1555825307369603\n",
      "149 Train Loss 1.9018149 Test MSE 5.848719384827933 Test RE 1.1559484120704338\n",
      "Training time: 230.97\n",
      "2\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 53.73644 Test MSE 7.912666767284176 Test RE 1.3445269087970162\n",
      "1 Train Loss 43.106853 Test MSE 8.000610814989235 Test RE 1.3519780252636862\n",
      "2 Train Loss 34.12639 Test MSE 7.34116879669643 Test RE 1.295062312746011\n",
      "3 Train Loss 26.879625 Test MSE 7.132709962993723 Test RE 1.2765426888581644\n",
      "4 Train Loss 21.414324 Test MSE 6.770580090746638 Test RE 1.2437153664545275\n",
      "5 Train Loss 17.798857 Test MSE 6.487101052996131 Test RE 1.2174002648190367\n",
      "6 Train Loss 15.430033 Test MSE 6.134630839050819 Test RE 1.1838652612608218\n",
      "7 Train Loss 13.72525 Test MSE 6.223451025808673 Test RE 1.1924047528445372\n",
      "8 Train Loss 12.385413 Test MSE 5.8778454847829 Test RE 1.1588230975001197\n",
      "9 Train Loss 11.269333 Test MSE 5.804564178834524 Test RE 1.151576699505836\n",
      "10 Train Loss 10.356115 Test MSE 5.901765674930384 Test RE 1.1611786480931416\n",
      "11 Train Loss 9.660896 Test MSE 5.705882879738859 Test RE 1.1417459684528943\n",
      "12 Train Loss 9.189779 Test MSE 5.630783899464996 Test RE 1.1342074362564791\n",
      "13 Train Loss 8.438547 Test MSE 5.464390401463451 Test RE 1.1173234667091214\n",
      "14 Train Loss 7.9593935 Test MSE 5.552208195970321 Test RE 1.1262658910642815\n",
      "15 Train Loss 7.7068152 Test MSE 5.512751821227337 Test RE 1.1222568915099553\n",
      "16 Train Loss 7.383108 Test MSE 5.458769026775496 Test RE 1.1167486075246895\n",
      "17 Train Loss 7.108347 Test MSE 5.413893695377632 Test RE 1.1121488631391696\n",
      "18 Train Loss 6.7769194 Test MSE 5.3362831462964735 Test RE 1.1041485157778204\n",
      "19 Train Loss 6.447635 Test MSE 5.121908131072821 Test RE 1.0817426487545334\n",
      "20 Train Loss 6.195487 Test MSE 4.994686618889673 Test RE 1.0682236345370453\n",
      "21 Train Loss 5.886388 Test MSE 4.803026644347552 Test RE 1.047527801966789\n",
      "22 Train Loss 5.446743 Test MSE 4.683999150790145 Test RE 1.0344665786176215\n",
      "23 Train Loss 5.139289 Test MSE 4.7044520125760005 Test RE 1.0367226374868468\n",
      "24 Train Loss 4.925861 Test MSE 4.552350107451361 Test RE 1.0198255487603238\n",
      "25 Train Loss 4.7305474 Test MSE 4.4986715694908295 Test RE 1.013795138655275\n",
      "26 Train Loss 4.3244834 Test MSE 4.28516724198601 Test RE 0.989445661187018\n",
      "27 Train Loss 4.1754766 Test MSE 4.233070002621867 Test RE 0.9834126387858865\n",
      "28 Train Loss 3.9329267 Test MSE 4.0855307595944845 Test RE 0.9661227359967226\n",
      "29 Train Loss 3.6704245 Test MSE 3.8840055170325836 Test RE 0.9419936589591749\n",
      "30 Train Loss 3.4278665 Test MSE 3.81869045899327 Test RE 0.9340395981906031\n",
      "31 Train Loss 3.2727375 Test MSE 3.7480438865164962 Test RE 0.9253592999403417\n",
      "32 Train Loss 3.1352873 Test MSE 3.7348779778636265 Test RE 0.9237325962089707\n",
      "33 Train Loss 3.022826 Test MSE 3.6676343356547982 Test RE 0.9153792746145201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 2.9013317 Test MSE 3.558877081063319 Test RE 0.901705158966684\n",
      "35 Train Loss 2.807736 Test MSE 3.485574094944538 Test RE 0.8923705307396401\n",
      "36 Train Loss 2.7040997 Test MSE 3.4242624520092866 Test RE 0.8844872607012053\n",
      "37 Train Loss 2.6039648 Test MSE 3.3363006774064323 Test RE 0.8730530866353704\n",
      "38 Train Loss 2.4881344 Test MSE 3.246326039340955 Test RE 0.8612002117622992\n",
      "39 Train Loss 2.36208 Test MSE 3.1871542383109466 Test RE 0.8533154340142138\n",
      "40 Train Loss 2.2354689 Test MSE 3.0906696957746522 Test RE 0.8402999877649522\n",
      "41 Train Loss 2.1567883 Test MSE 2.9388207103323745 Test RE 0.8193974463509209\n",
      "42 Train Loss 2.0726933 Test MSE 2.795698905009291 Test RE 0.7991959206680924\n",
      "43 Train Loss 2.0026808 Test MSE 2.6742953719257927 Test RE 0.7816507459033153\n",
      "44 Train Loss 1.8845267 Test MSE 2.5867691944522773 Test RE 0.7687531360555169\n",
      "45 Train Loss 1.7932702 Test MSE 2.465027443862493 Test RE 0.7504451231929683\n",
      "46 Train Loss 1.664334 Test MSE 2.353766174225267 Test RE 0.7333135653490895\n",
      "47 Train Loss 1.567858 Test MSE 2.354555264902683 Test RE 0.7334364752657381\n",
      "48 Train Loss 1.5215585 Test MSE 2.2221942653570537 Test RE 0.7125233014680588\n",
      "49 Train Loss 1.4335009 Test MSE 2.241499578617739 Test RE 0.7156116316893024\n",
      "50 Train Loss 1.3705118 Test MSE 2.1891201651142183 Test RE 0.7072009917302317\n",
      "51 Train Loss 1.3444848 Test MSE 2.1856432200518037 Test RE 0.7066391504550698\n",
      "52 Train Loss 1.3200972 Test MSE 2.1233789002449606 Test RE 0.696501103823258\n",
      "53 Train Loss 1.28503 Test MSE 2.069054170940175 Test RE 0.6875337009829708\n",
      "54 Train Loss 1.2391444 Test MSE 1.8667154510982054 Test RE 0.653051033941497\n",
      "55 Train Loss 1.1624742 Test MSE 1.8202706913467182 Test RE 0.6448757537642775\n",
      "56 Train Loss 1.1216513 Test MSE 1.7287114254635754 Test RE 0.6284479464676322\n",
      "57 Train Loss 1.0769713 Test MSE 1.674150587464211 Test RE 0.6184510341559455\n",
      "58 Train Loss 1.0449619 Test MSE 1.6617003665297883 Test RE 0.6161471132911323\n",
      "59 Train Loss 1.0163401 Test MSE 1.6546719052187564 Test RE 0.614842679840738\n",
      "60 Train Loss 0.98739374 Test MSE 1.6276289842882026 Test RE 0.6097976800712962\n",
      "61 Train Loss 0.949996 Test MSE 1.6182436847088768 Test RE 0.6080370183728386\n",
      "62 Train Loss 0.9150616 Test MSE 1.5968532451558408 Test RE 0.6040050405091939\n",
      "63 Train Loss 0.88508165 Test MSE 1.5178787428185423 Test RE 0.5888797220523098\n",
      "64 Train Loss 0.84828645 Test MSE 1.4293590778057783 Test RE 0.5714506517596577\n",
      "65 Train Loss 0.8139002 Test MSE 1.3242446882648722 Test RE 0.5500373487845035\n",
      "66 Train Loss 0.75771004 Test MSE 1.1101544805394716 Test RE 0.5036162887657756\n",
      "67 Train Loss 0.7060475 Test MSE 0.9853003023780816 Test RE 0.47445209462842447\n",
      "68 Train Loss 0.6679273 Test MSE 0.87706801526607 Test RE 0.4476356812449331\n",
      "69 Train Loss 0.6376444 Test MSE 0.8076687301799097 Test RE 0.42956085168654307\n",
      "70 Train Loss 0.60823816 Test MSE 0.7879904528835311 Test RE 0.4242956098016819\n",
      "71 Train Loss 0.558788 Test MSE 0.8173433727017717 Test RE 0.4321259358153369\n",
      "72 Train Loss 0.5258552 Test MSE 0.7495562473178957 Test RE 0.41381875940124285\n",
      "73 Train Loss 0.4915626 Test MSE 0.7284683105396688 Test RE 0.4079560633348068\n",
      "74 Train Loss 0.46310622 Test MSE 0.6483811731953897 Test RE 0.38487815165371875\n",
      "75 Train Loss 0.43064228 Test MSE 0.6770524269562936 Test RE 0.393295710588461\n",
      "76 Train Loss 0.3874957 Test MSE 0.6328703486497458 Test RE 0.38024668323489214\n",
      "77 Train Loss 0.36368436 Test MSE 0.59694904219619 Test RE 0.3692977742155714\n",
      "78 Train Loss 0.33694065 Test MSE 0.566886226904116 Test RE 0.359878592294752\n",
      "79 Train Loss 0.3216327 Test MSE 0.5621574500700519 Test RE 0.35837445506082727\n",
      "80 Train Loss 0.30282414 Test MSE 0.5191948187962249 Test RE 0.34440800349114686\n",
      "81 Train Loss 0.28609487 Test MSE 0.5069255388620396 Test RE 0.3403142588612408\n",
      "82 Train Loss 0.26987097 Test MSE 0.4688122877543352 Test RE 0.32727102251712936\n",
      "83 Train Loss 0.25725883 Test MSE 0.45583835757451213 Test RE 0.32271079544221626\n",
      "84 Train Loss 0.24313727 Test MSE 0.42794654375114083 Test RE 0.3126819573225382\n",
      "85 Train Loss 0.23016308 Test MSE 0.39574415808506797 Test RE 0.3006874600713284\n",
      "86 Train Loss 0.21693319 Test MSE 0.3457465372431352 Test RE 0.28105219398443915\n",
      "87 Train Loss 0.20445672 Test MSE 0.33768326877664545 Test RE 0.27775560516315884\n",
      "88 Train Loss 0.19239423 Test MSE 0.2837509881851755 Test RE 0.2546107590438742\n",
      "89 Train Loss 0.17516571 Test MSE 0.2600873001470548 Test RE 0.24376291434046338\n",
      "90 Train Loss 0.15882969 Test MSE 0.2266424323040339 Test RE 0.2275509596792827\n",
      "91 Train Loss 0.14822505 Test MSE 0.21317342947679754 Test RE 0.22068590512397265\n",
      "92 Train Loss 0.13117932 Test MSE 0.2016737388887852 Test RE 0.21465091061065952\n",
      "93 Train Loss 0.11869736 Test MSE 0.18525731244580904 Test RE 0.2057291065300082\n",
      "94 Train Loss 0.10957728 Test MSE 0.17654450125431667 Test RE 0.2008330380349321\n",
      "95 Train Loss 0.10306821 Test MSE 0.17848172032840215 Test RE 0.20193190014850762\n",
      "96 Train Loss 0.09620052 Test MSE 0.1621359447397058 Test RE 0.19246320495220132\n",
      "97 Train Loss 0.08770613 Test MSE 0.14807294832275736 Test RE 0.1839271842218522\n",
      "98 Train Loss 0.081568345 Test MSE 0.13520885939414246 Test RE 0.17575619217332075\n",
      "99 Train Loss 0.07633175 Test MSE 0.1228726685500403 Test RE 0.16754663329037187\n",
      "100 Train Loss 0.07303468 Test MSE 0.11643750554038158 Test RE 0.16310020493565447\n",
      "101 Train Loss 0.06734859 Test MSE 0.10127537927649634 Test RE 0.15211078213373772\n",
      "102 Train Loss 0.061506595 Test MSE 0.1078344677466029 Test RE 0.15695923010986446\n",
      "103 Train Loss 0.05540961 Test MSE 0.10002580728712948 Test RE 0.15116947084223556\n",
      "104 Train Loss 0.05391226 Test MSE 0.09757123236692881 Test RE 0.1493031448029788\n",
      "105 Train Loss 0.051981676 Test MSE 0.09883384312807951 Test RE 0.15026606088293976\n",
      "106 Train Loss 0.04987891 Test MSE 0.08871219989557713 Test RE 0.1423638534517787\n",
      "107 Train Loss 0.04800779 Test MSE 0.08440406446577968 Test RE 0.1388640222272947\n",
      "108 Train Loss 0.04532934 Test MSE 0.082251123652564 Test RE 0.13708154169828524\n",
      "109 Train Loss 0.04255742 Test MSE 0.07899239476738895 Test RE 0.13433856362441646\n",
      "110 Train Loss 0.040476155 Test MSE 0.08270323229386349 Test RE 0.1374577725311419\n",
      "111 Train Loss 0.03867811 Test MSE 0.07782378072331701 Test RE 0.13334115814539746\n",
      "112 Train Loss 0.036678053 Test MSE 0.06944752972815828 Test RE 0.12596110488486523\n",
      "113 Train Loss 0.035273355 Test MSE 0.06715979065065288 Test RE 0.12386902726592797\n",
      "114 Train Loss 0.03385119 Test MSE 0.06431192762362194 Test RE 0.12121429048447824\n",
      "115 Train Loss 0.031896405 Test MSE 0.05905705064526881 Test RE 0.11615661229826861\n",
      "116 Train Loss 0.030695047 Test MSE 0.0544396115675578 Test RE 0.11152328905164303\n",
      "117 Train Loss 0.029542016 Test MSE 0.04677468758634663 Test RE 0.1033745204802099\n",
      "118 Train Loss 0.028271673 Test MSE 0.04742873199671826 Test RE 0.10409474778786557\n",
      "119 Train Loss 0.027276529 Test MSE 0.04810950241295799 Test RE 0.10483915039932339\n",
      "120 Train Loss 0.02538296 Test MSE 0.04771328231816498 Test RE 0.10440654085744958\n",
      "121 Train Loss 0.02433816 Test MSE 0.04727616394751722 Test RE 0.10392718769942584\n",
      "122 Train Loss 0.022955414 Test MSE 0.04571541614754879 Test RE 0.10219729456856008\n",
      "123 Train Loss 0.021599967 Test MSE 0.04185719480670285 Test RE 0.09778970138610882\n",
      "124 Train Loss 0.020856638 Test MSE 0.03642976196323054 Test RE 0.09122969586305067\n",
      "125 Train Loss 0.020199453 Test MSE 0.03476231041952654 Test RE 0.08911737322270563\n",
      "126 Train Loss 0.01963761 Test MSE 0.03159761459907679 Test RE 0.08496405063675673\n",
      "127 Train Loss 0.018807774 Test MSE 0.02981729967944575 Test RE 0.08253577153840964\n",
      "128 Train Loss 0.017792204 Test MSE 0.027953864224648347 Test RE 0.07991512553156954\n",
      "129 Train Loss 0.01713808 Test MSE 0.024952497052908706 Test RE 0.07550314929430696\n",
      "130 Train Loss 0.016310137 Test MSE 0.024438128136620392 Test RE 0.07472088878805516\n",
      "131 Train Loss 0.015890805 Test MSE 0.024701042084847708 Test RE 0.07512175027613306\n",
      "132 Train Loss 0.015492839 Test MSE 0.023877540619178475 Test RE 0.07385890361329046\n",
      "133 Train Loss 0.01497682 Test MSE 0.022713323056568615 Test RE 0.07203580259671788\n",
      "134 Train Loss 0.014475209 Test MSE 0.021669150752372843 Test RE 0.07036051438064934\n",
      "135 Train Loss 0.0141668245 Test MSE 0.019918439611051057 Test RE 0.06745835039910068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 Train Loss 0.013709567 Test MSE 0.019098035320642495 Test RE 0.06605449952370113\n",
      "137 Train Loss 0.012971958 Test MSE 0.01820435714451544 Test RE 0.06449049848527555\n",
      "138 Train Loss 0.012162866 Test MSE 0.018467668480369626 Test RE 0.06495522555247406\n",
      "139 Train Loss 0.011754808 Test MSE 0.018196086796479244 Test RE 0.0644758476120242\n",
      "140 Train Loss 0.010867078 Test MSE 0.017309539379536505 Test RE 0.06288554307944824\n",
      "141 Train Loss 0.0104601225 Test MSE 0.017264056939493257 Test RE 0.06280286990122172\n",
      "142 Train Loss 0.010330133 Test MSE 0.017061958773044533 Test RE 0.06243419326262984\n",
      "143 Train Loss 0.010006042 Test MSE 0.01633678348011136 Test RE 0.061092983818520845\n",
      "144 Train Loss 0.00882179 Test MSE 0.01392904218371503 Test RE 0.05641163498273276\n",
      "145 Train Loss 0.00806965 Test MSE 0.01351803222992408 Test RE 0.05557312247235271\n",
      "146 Train Loss 0.0077876 Test MSE 0.012998186099593736 Test RE 0.054494093879862884\n",
      "147 Train Loss 0.007695241 Test MSE 0.012704251066026174 Test RE 0.05387441832903957\n",
      "148 Train Loss 0.007599709 Test MSE 0.012441443134881634 Test RE 0.05331426664612418\n",
      "149 Train Loss 0.007503742 Test MSE 0.012264891500438496 Test RE 0.052934634117721556\n",
      "Training time: 230.02\n",
      "3\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 61.78984 Test MSE 5.829575143136364 Test RE 1.1540550151568811\n",
      "1 Train Loss 46.035393 Test MSE 8.502357783827357 Test RE 1.3937271121954622\n",
      "2 Train Loss 36.670376 Test MSE 8.507902128228661 Test RE 1.3941814593297897\n",
      "3 Train Loss 32.395447 Test MSE 8.386675659126256 Test RE 1.3842131927881582\n",
      "4 Train Loss 29.05967 Test MSE 8.733456748426946 Test RE 1.4125412757977904\n",
      "5 Train Loss 26.67802 Test MSE 8.804159201537091 Test RE 1.4182474253453743\n",
      "6 Train Loss 24.58106 Test MSE 8.67387974400597 Test RE 1.4077150659793687\n",
      "7 Train Loss 22.956875 Test MSE 8.707241517280739 Test RE 1.4104196687855095\n",
      "8 Train Loss 21.975576 Test MSE 9.07848640350016 Test RE 1.4401733959604457\n",
      "9 Train Loss 20.85663 Test MSE 8.951941939471752 Test RE 1.4301009286834363\n",
      "10 Train Loss 19.69603 Test MSE 8.753038858502874 Test RE 1.414123985360917\n",
      "11 Train Loss 18.717659 Test MSE 8.918732542522761 Test RE 1.4274458110491177\n",
      "12 Train Loss 18.055712 Test MSE 8.637335428535387 Test RE 1.4047464818697017\n",
      "13 Train Loss 17.037853 Test MSE 7.988801911234638 Test RE 1.350979896850403\n",
      "14 Train Loss 15.320725 Test MSE 7.798155290763539 Test RE 1.334762510053989\n",
      "15 Train Loss 13.31692 Test MSE 6.475474672806818 Test RE 1.2163088446543229\n",
      "16 Train Loss 11.3152075 Test MSE 6.442347183648016 Test RE 1.213193634897092\n",
      "17 Train Loss 10.252695 Test MSE 6.292445723028663 Test RE 1.198996179734666\n",
      "18 Train Loss 8.437338 Test MSE 5.809415026478072 Test RE 1.152057782698315\n",
      "19 Train Loss 6.628285 Test MSE 5.724818269920396 Test RE 1.1436388831131814\n",
      "20 Train Loss 5.0405827 Test MSE 5.336041043975712 Test RE 1.1041234683859507\n",
      "21 Train Loss 4.4720216 Test MSE 5.2036612379855915 Test RE 1.090341565174042\n",
      "22 Train Loss 3.9262657 Test MSE 5.076557325139679 Test RE 1.0769429748634762\n",
      "23 Train Loss 3.597146 Test MSE 5.0637171208046885 Test RE 1.0755801494301922\n",
      "24 Train Loss 3.3396428 Test MSE 5.116693641055788 Test RE 1.0811918606005986\n",
      "25 Train Loss 3.0603886 Test MSE 5.149705825894964 Test RE 1.0846741015036951\n",
      "26 Train Loss 2.91105 Test MSE 5.208683849998044 Test RE 1.0908676411015024\n",
      "27 Train Loss 2.7418103 Test MSE 5.377348884198772 Test RE 1.108388899200407\n",
      "28 Train Loss 2.5830827 Test MSE 5.331837225164458 Test RE 1.1036884595941034\n",
      "29 Train Loss 2.4929783 Test MSE 5.446038993127558 Test RE 1.1154456997490747\n",
      "30 Train Loss 2.3789454 Test MSE 5.474399517636856 Test RE 1.118346298450755\n",
      "31 Train Loss 2.3074336 Test MSE 5.4915047615468415 Test RE 1.1200921215706705\n",
      "32 Train Loss 2.2379336 Test MSE 5.475618841368456 Test RE 1.1184708372476702\n",
      "33 Train Loss 2.1745994 Test MSE 5.450197409554052 Test RE 1.1158714773293712\n",
      "34 Train Loss 2.1028361 Test MSE 5.470548012935893 Test RE 1.1179528238897745\n",
      "35 Train Loss 2.029001 Test MSE 5.448781297568564 Test RE 1.1157265007796477\n",
      "36 Train Loss 1.9725809 Test MSE 5.481475675480674 Test RE 1.1190688470424344\n",
      "37 Train Loss 1.9126544 Test MSE 5.443745432767381 Test RE 1.1152107940260623\n",
      "38 Train Loss 1.8706287 Test MSE 5.410925914644938 Test RE 1.1118439932424589\n",
      "39 Train Loss 1.8283553 Test MSE 5.4054686134564776 Test RE 1.1112831651761232\n",
      "40 Train Loss 1.7807025 Test MSE 5.390668247253923 Test RE 1.1097607558526792\n",
      "41 Train Loss 1.7448108 Test MSE 5.386793968719601 Test RE 1.1093618911041145\n",
      "42 Train Loss 1.6994988 Test MSE 5.381413110978011 Test RE 1.108807682980997\n",
      "43 Train Loss 1.6552479 Test MSE 5.391480376621936 Test RE 1.1098443480269153\n",
      "44 Train Loss 1.606498 Test MSE 5.415471118658509 Test RE 1.1123108723914699\n",
      "45 Train Loss 1.5769821 Test MSE 5.41674997845442 Test RE 1.1124422003640522\n",
      "46 Train Loss 1.5461748 Test MSE 5.457144963532618 Test RE 1.1165824706837162\n",
      "47 Train Loss 1.5230515 Test MSE 5.458988333150112 Test RE 1.1167710400206883\n",
      "48 Train Loss 1.4907594 Test MSE 5.48419945741891 Test RE 1.1193468489102194\n",
      "49 Train Loss 1.4624095 Test MSE 5.506511874727392 Test RE 1.121621564004252\n",
      "50 Train Loss 1.4375384 Test MSE 5.506322916068363 Test RE 1.121602319341775\n",
      "51 Train Loss 1.42055 Test MSE 5.524571361611375 Test RE 1.1234593271325857\n",
      "52 Train Loss 1.4035097 Test MSE 5.533680076452455 Test RE 1.124385105386526\n",
      "53 Train Loss 1.3790835 Test MSE 5.5985618264847545 Test RE 1.1309575380372119\n",
      "54 Train Loss 1.3564564 Test MSE 5.607806516149592 Test RE 1.131890906214358\n",
      "55 Train Loss 1.3419473 Test MSE 5.616017561535292 Test RE 1.1327192700276771\n",
      "56 Train Loss 1.3319874 Test MSE 5.599916808947512 Test RE 1.1310943888006824\n",
      "57 Train Loss 1.3159013 Test MSE 5.608475043751328 Test RE 1.131958372679174\n",
      "58 Train Loss 1.2878932 Test MSE 5.619226669143757 Test RE 1.1330428533191488\n",
      "59 Train Loss 1.2745335 Test MSE 5.578006256258865 Test RE 1.1288794279951995\n",
      "60 Train Loss 1.2519088 Test MSE 5.590436273894443 Test RE 1.1301365243515766\n",
      "61 Train Loss 1.235651 Test MSE 5.582185246956473 Test RE 1.1293022218350828\n",
      "62 Train Loss 1.2225945 Test MSE 5.553240815069411 Test RE 1.1263706196298247\n",
      "63 Train Loss 1.209233 Test MSE 5.613002454711788 Test RE 1.132415164130555\n",
      "64 Train Loss 1.1964865 Test MSE 5.611265699036438 Test RE 1.1322399565979435\n",
      "65 Train Loss 1.1845162 Test MSE 5.6246484782126105 Test RE 1.13358933962982\n",
      "66 Train Loss 1.1744256 Test MSE 5.623980764779722 Test RE 1.133522052287564\n",
      "67 Train Loss 1.1666541 Test MSE 5.6143368675259735 Test RE 1.1325497640632634\n",
      "68 Train Loss 1.1575527 Test MSE 5.626748000762498 Test RE 1.133800888345722\n",
      "69 Train Loss 1.1521639 Test MSE 5.654591296390366 Test RE 1.1366026662183601\n",
      "70 Train Loss 1.1426812 Test MSE 5.668340186827876 Test RE 1.1379836270282955\n",
      "71 Train Loss 1.1318098 Test MSE 5.679776032489166 Test RE 1.1391309865275132\n",
      "72 Train Loss 1.1255733 Test MSE 5.6798975462833345 Test RE 1.1391431718132623\n",
      "73 Train Loss 1.1186872 Test MSE 5.67432540329955 Test RE 1.1385842685841945\n",
      "74 Train Loss 1.110951 Test MSE 5.675541329786863 Test RE 1.1387062531826828\n",
      "75 Train Loss 1.1006774 Test MSE 5.676793241607845 Test RE 1.13883183426229\n",
      "76 Train Loss 1.0947738 Test MSE 5.683145027320166 Test RE 1.1394687777942227\n",
      "77 Train Loss 1.0853264 Test MSE 5.695867198515989 Test RE 1.1407434604708804\n",
      "78 Train Loss 1.0795064 Test MSE 5.711011129817633 Test RE 1.1422589341028535\n",
      "79 Train Loss 1.0729196 Test MSE 5.709709053572423 Test RE 1.142128712590921\n",
      "80 Train Loss 1.066549 Test MSE 5.6941807796218376 Test RE 1.1405745736556185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 Train Loss 1.0599692 Test MSE 5.696469041641791 Test RE 1.1408037261381876\n",
      "82 Train Loss 1.0545237 Test MSE 5.706195502545392 Test RE 1.141777245903516\n",
      "83 Train Loss 1.0465178 Test MSE 5.70699726454733 Test RE 1.1418574570929172\n",
      "84 Train Loss 1.035809 Test MSE 5.720777990635757 Test RE 1.1432352514338053\n",
      "85 Train Loss 1.0268106 Test MSE 5.758710763996914 Test RE 1.1470192152771859\n",
      "86 Train Loss 1.0219178 Test MSE 5.750602097663187 Test RE 1.1462113892874983\n",
      "87 Train Loss 1.0142394 Test MSE 5.772549982208179 Test RE 1.1483966350136652\n",
      "88 Train Loss 1.01021 Test MSE 5.767858974136101 Test RE 1.1479299233526166\n",
      "89 Train Loss 1.0044019 Test MSE 5.784117892656823 Test RE 1.1495467247258513\n",
      "90 Train Loss 0.99804276 Test MSE 5.791102662539606 Test RE 1.1502405986187314\n",
      "91 Train Loss 0.99491113 Test MSE 5.782036172430656 Test RE 1.149339843567313\n",
      "92 Train Loss 0.98740673 Test MSE 5.774461882269719 Test RE 1.148586796886124\n",
      "93 Train Loss 0.9785883 Test MSE 5.765562594397254 Test RE 1.147701385739256\n",
      "94 Train Loss 0.97133464 Test MSE 5.772202223171378 Test RE 1.148362042734355\n",
      "95 Train Loss 0.96754044 Test MSE 5.78650923220599 Test RE 1.1497843298827235\n",
      "96 Train Loss 0.96410656 Test MSE 5.788853790719235 Test RE 1.1500172391829397\n",
      "97 Train Loss 0.961623 Test MSE 5.794060151232015 Test RE 1.1505342723410987\n",
      "98 Train Loss 0.95860875 Test MSE 5.798637725267053 Test RE 1.1509886701087848\n",
      "99 Train Loss 0.9552802 Test MSE 5.805063702655521 Test RE 1.1516262491016414\n",
      "100 Train Loss 0.95023715 Test MSE 5.808454494861523 Test RE 1.1519625378531746\n",
      "101 Train Loss 0.94564295 Test MSE 5.807822671323744 Test RE 1.1518998829041969\n",
      "102 Train Loss 0.94277626 Test MSE 5.7989820317045675 Test RE 1.151022840800669\n",
      "103 Train Loss 0.93918794 Test MSE 5.806934110587649 Test RE 1.1518117627757662\n",
      "104 Train Loss 0.9361098 Test MSE 5.817062670275157 Test RE 1.152815830610946\n",
      "105 Train Loss 0.9314586 Test MSE 5.846954096223474 Test RE 1.155773951951667\n",
      "106 Train Loss 0.9261683 Test MSE 5.8464219828658655 Test RE 1.155721359033961\n",
      "107 Train Loss 0.92051566 Test MSE 5.852169159842774 Test RE 1.156289270797941\n",
      "108 Train Loss 0.91503304 Test MSE 5.859510641366373 Test RE 1.157014319532345\n",
      "109 Train Loss 0.9107749 Test MSE 5.862640986315585 Test RE 1.157323335980433\n",
      "110 Train Loss 0.9044658 Test MSE 5.871159704049992 Test RE 1.1581638558138683\n",
      "111 Train Loss 0.9005087 Test MSE 5.886835850478426 Test RE 1.159708988659452\n",
      "112 Train Loss 0.8979478 Test MSE 5.880131466762164 Test RE 1.1590484174078401\n",
      "113 Train Loss 0.8944211 Test MSE 5.8873794802299795 Test RE 1.1597625350612053\n",
      "114 Train Loss 0.8915664 Test MSE 5.9005026502600115 Test RE 1.1610543907238822\n",
      "115 Train Loss 0.88824296 Test MSE 5.906167944737468 Test RE 1.1616116429867154\n",
      "116 Train Loss 0.8857765 Test MSE 5.9058095645308795 Test RE 1.161576399751184\n",
      "117 Train Loss 0.88148725 Test MSE 5.912876646146456 Test RE 1.1622711817978615\n",
      "118 Train Loss 0.87862134 Test MSE 5.904737547614287 Test RE 1.1614709708467987\n",
      "119 Train Loss 0.87480605 Test MSE 5.89819875027956 Test RE 1.1608276969562454\n",
      "120 Train Loss 0.87154746 Test MSE 5.901142436074331 Test RE 1.1611173350218493\n",
      "121 Train Loss 0.8691177 Test MSE 5.910596561311122 Test RE 1.1620470664830682\n",
      "122 Train Loss 0.86652404 Test MSE 5.921349691321701 Test RE 1.1631036404597788\n",
      "123 Train Loss 0.86359155 Test MSE 5.922567891376921 Test RE 1.1632232770397815\n",
      "124 Train Loss 0.86047053 Test MSE 5.919715699669574 Test RE 1.1629431506334118\n",
      "125 Train Loss 0.85763264 Test MSE 5.931856535053882 Test RE 1.1641350887443773\n",
      "126 Train Loss 0.8545406 Test MSE 5.934995077841062 Test RE 1.1644430197100994\n",
      "127 Train Loss 0.8513159 Test MSE 5.926234430139242 Test RE 1.1635832850146355\n",
      "128 Train Loss 0.8483216 Test MSE 5.934388043109938 Test RE 1.1643834682343628\n",
      "129 Train Loss 0.8446548 Test MSE 5.9366386884866 Test RE 1.1646042463354371\n",
      "130 Train Loss 0.84117144 Test MSE 5.944903896532432 Test RE 1.1654146669210121\n",
      "131 Train Loss 0.8371638 Test MSE 5.951162491396876 Test RE 1.16602796023104\n",
      "132 Train Loss 0.8338456 Test MSE 5.9538574934610295 Test RE 1.1662919500042983\n",
      "133 Train Loss 0.831601 Test MSE 5.96565297801901 Test RE 1.1674466779922552\n",
      "134 Train Loss 0.8292341 Test MSE 5.975350828080522 Test RE 1.1683952016012773\n",
      "135 Train Loss 0.82708657 Test MSE 5.9983247115890315 Test RE 1.1706391555200906\n",
      "136 Train Loss 0.82469887 Test MSE 6.00048192892574 Test RE 1.1708496389628738\n",
      "137 Train Loss 0.8215103 Test MSE 6.008513751491543 Test RE 1.17163298535614\n",
      "138 Train Loss 0.8188948 Test MSE 6.0146469000412255 Test RE 1.1722308009444613\n",
      "139 Train Loss 0.81516474 Test MSE 6.022021803837213 Test RE 1.1729492505135437\n",
      "140 Train Loss 0.81189734 Test MSE 6.026150568361783 Test RE 1.1733512750845414\n",
      "141 Train Loss 0.8096255 Test MSE 6.020268422302828 Test RE 1.1727784791888825\n",
      "142 Train Loss 0.8074964 Test MSE 6.028442020780732 Test RE 1.1735743381363337\n",
      "143 Train Loss 0.80500704 Test MSE 6.033760952791372 Test RE 1.174091949969117\n",
      "144 Train Loss 0.802977 Test MSE 6.036973968076975 Test RE 1.174404514001881\n",
      "145 Train Loss 0.80089664 Test MSE 6.052127982937249 Test RE 1.1758775855334855\n",
      "146 Train Loss 0.799 Test MSE 6.056851234393506 Test RE 1.1763363400689721\n",
      "147 Train Loss 0.79615724 Test MSE 6.069501673445513 Test RE 1.1775641570020956\n",
      "148 Train Loss 0.79362327 Test MSE 6.069468516684981 Test RE 1.1775609405711438\n",
      "149 Train Loss 0.79138273 Test MSE 6.082920243627232 Test RE 1.178865129006127\n",
      "Training time: 231.86\n",
      "4\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 57.326923 Test MSE 7.582890774781794 Test RE 1.3162108316524688\n",
      "1 Train Loss 47.643974 Test MSE 7.566592886817751 Test RE 1.314795606502676\n",
      "2 Train Loss 37.051437 Test MSE 7.722958179107015 Test RE 1.3283114058171557\n",
      "3 Train Loss 27.67763 Test MSE 6.555535450306903 Test RE 1.223804780724074\n",
      "4 Train Loss 22.081783 Test MSE 6.326125947717144 Test RE 1.2022007022691614\n",
      "5 Train Loss 18.974699 Test MSE 6.211402095422983 Test RE 1.1912499142787314\n",
      "6 Train Loss 16.369415 Test MSE 6.513739866715241 Test RE 1.2198972872815501\n",
      "7 Train Loss 14.239029 Test MSE 5.982351548259759 Test RE 1.1690794470703745\n",
      "8 Train Loss 12.608248 Test MSE 6.0782960432523865 Test RE 1.178416960629734\n",
      "9 Train Loss 10.983349 Test MSE 5.5664392772610665 Test RE 1.1277083553542206\n",
      "10 Train Loss 10.186743 Test MSE 5.7085553284362405 Test RE 1.1420133153645642\n",
      "11 Train Loss 9.4716015 Test MSE 5.783639129997704 Test RE 1.1494991486350814\n",
      "12 Train Loss 8.7699175 Test MSE 5.546960716849139 Test RE 1.1257335394645447\n",
      "13 Train Loss 7.964279 Test MSE 5.38831410336133 Test RE 1.109518409108594\n",
      "14 Train Loss 7.036707 Test MSE 5.377897366054339 Test RE 1.1084454247961955\n",
      "15 Train Loss 6.394934 Test MSE 5.067180950749952 Test RE 1.075947961230437\n",
      "16 Train Loss 5.911377 Test MSE 4.940382617264685 Test RE 1.062400711245264\n",
      "17 Train Loss 5.5139756 Test MSE 4.7679294530488345 Test RE 1.043693480745066\n",
      "18 Train Loss 4.9923425 Test MSE 4.524094653383847 Test RE 1.0166557039904858\n",
      "19 Train Loss 4.4009233 Test MSE 4.2290881769050355 Test RE 0.9829500077630472\n",
      "20 Train Loss 3.934571 Test MSE 4.015598609501506 Test RE 0.9578184708915607\n",
      "21 Train Loss 3.5863676 Test MSE 3.5889129370536734 Test RE 0.9055022249278176\n",
      "22 Train Loss 3.252731 Test MSE 3.4393443026535957 Test RE 0.8864329422647863\n",
      "23 Train Loss 3.0421324 Test MSE 3.1751791382297894 Test RE 0.8517108435919429\n",
      "24 Train Loss 2.8853443 Test MSE 3.0067426720838593 Test RE 0.8288123062532045\n",
      "25 Train Loss 2.680167 Test MSE 2.5964021537389366 Test RE 0.7701831991256773\n",
      "26 Train Loss 2.493 Test MSE 2.384002115671359 Test RE 0.7380085249618576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Train Loss 2.2696278 Test MSE 2.293915176459254 Test RE 0.7239302721263344\n",
      "28 Train Loss 2.1136546 Test MSE 2.0514851833349703 Test RE 0.6846084458327193\n",
      "29 Train Loss 1.9139934 Test MSE 1.9413889188122297 Test RE 0.6659848249173143\n",
      "30 Train Loss 1.7844052 Test MSE 1.581244884817048 Test RE 0.6010458835386637\n",
      "31 Train Loss 1.6377903 Test MSE 1.3934611022871122 Test RE 0.564229105580671\n",
      "32 Train Loss 1.4781187 Test MSE 1.2370105129733717 Test RE 0.5316119754238513\n",
      "33 Train Loss 1.336285 Test MSE 1.0740360882460311 Test RE 0.49535607939338744\n",
      "34 Train Loss 1.2296594 Test MSE 1.0027917129799486 Test RE 0.4786448918501349\n",
      "35 Train Loss 1.16899 Test MSE 0.9253093292436235 Test RE 0.45978154014983535\n",
      "36 Train Loss 1.0594039 Test MSE 0.8180553406878963 Test RE 0.43231410205792126\n",
      "37 Train Loss 0.96277434 Test MSE 0.740678455652982 Test RE 0.411360811903498\n",
      "38 Train Loss 0.9079603 Test MSE 0.6938573194029497 Test RE 0.39814672456061695\n",
      "39 Train Loss 0.81860954 Test MSE 0.6255613721582418 Test RE 0.3780445852965172\n",
      "40 Train Loss 0.7380582 Test MSE 0.5479143471761301 Test RE 0.35380535070313185\n",
      "41 Train Loss 0.6687657 Test MSE 0.4624816334927335 Test RE 0.3250538433830797\n",
      "42 Train Loss 0.5989053 Test MSE 0.431851798547537 Test RE 0.3141054172812458\n",
      "43 Train Loss 0.52677447 Test MSE 0.3741084922471679 Test RE 0.29235252133096484\n",
      "44 Train Loss 0.4784093 Test MSE 0.336412186555688 Test RE 0.27723235882220126\n",
      "45 Train Loss 0.44825727 Test MSE 0.31429150741475054 Test RE 0.26796272353766515\n",
      "46 Train Loss 0.41936493 Test MSE 0.32287889581796364 Test RE 0.2715988270047545\n",
      "47 Train Loss 0.39446357 Test MSE 0.3096908513822324 Test RE 0.26599424981196174\n",
      "48 Train Loss 0.3539937 Test MSE 0.25135052524627227 Test RE 0.23963373609835065\n",
      "49 Train Loss 0.3095705 Test MSE 0.21752420165085448 Test RE 0.22292657926969675\n",
      "50 Train Loss 0.29384932 Test MSE 0.19841029850590008 Test RE 0.21290711031989715\n",
      "51 Train Loss 0.25172907 Test MSE 0.14958001746451313 Test RE 0.18486080933378332\n",
      "52 Train Loss 0.23205031 Test MSE 0.12403912124663004 Test RE 0.1683400301765601\n",
      "53 Train Loss 0.21514022 Test MSE 0.07907954103407949 Test RE 0.13441264592827998\n",
      "54 Train Loss 0.19975883 Test MSE 0.05973404798174117 Test RE 0.1168204926818631\n",
      "55 Train Loss 0.17970133 Test MSE 0.04953585830421924 Test RE 0.1063819401329639\n",
      "56 Train Loss 0.16361955 Test MSE 0.039995487452972434 Test RE 0.09559024118521364\n",
      "57 Train Loss 0.15548906 Test MSE 0.037166264640140785 Test RE 0.09214727946801798\n",
      "58 Train Loss 0.14631845 Test MSE 0.03708804769866889 Test RE 0.0920502657582618\n",
      "59 Train Loss 0.13723476 Test MSE 0.033537428651669796 Test RE 0.08753322734117194\n",
      "60 Train Loss 0.13224444 Test MSE 0.0354241704213963 Test RE 0.08996175196776542\n",
      "61 Train Loss 0.119504645 Test MSE 0.031623615484175575 Test RE 0.08499900084219875\n",
      "62 Train Loss 0.11151953 Test MSE 0.03007101646427436 Test RE 0.0828861780635664\n",
      "63 Train Loss 0.098019026 Test MSE 0.028245763785347593 Test RE 0.0803312864064865\n",
      "64 Train Loss 0.09528365 Test MSE 0.025126821783390558 Test RE 0.07576643271758532\n",
      "65 Train Loss 0.090794645 Test MSE 0.023196008758888564 Test RE 0.07279720284210409\n",
      "66 Train Loss 0.088007346 Test MSE 0.021932896699623925 Test RE 0.07078741560674932\n",
      "67 Train Loss 0.08337659 Test MSE 0.02092977490001548 Test RE 0.06914970616831598\n",
      "68 Train Loss 0.08061663 Test MSE 0.018136848116839834 Test RE 0.06437080915430561\n",
      "69 Train Loss 0.07775942 Test MSE 0.018572055880468435 Test RE 0.06513854464622872\n",
      "70 Train Loss 0.072449766 Test MSE 0.016453497339263615 Test RE 0.06131082681966525\n",
      "71 Train Loss 0.071151234 Test MSE 0.015144486722634076 Test RE 0.058821397670630826\n",
      "72 Train Loss 0.06463058 Test MSE 0.014043378024448164 Test RE 0.05664268783662311\n",
      "73 Train Loss 0.06308092 Test MSE 0.013042402835434114 Test RE 0.054586703157564635\n",
      "74 Train Loss 0.062079277 Test MSE 0.011610459602897168 Test RE 0.051503028358920865\n",
      "75 Train Loss 0.05888028 Test MSE 0.009685328097306415 Test RE 0.047039774261935764\n",
      "76 Train Loss 0.052917816 Test MSE 0.008297348788032101 Test RE 0.04353892817483922\n",
      "77 Train Loss 0.050459225 Test MSE 0.008281297782463792 Test RE 0.04349679532629835\n",
      "78 Train Loss 0.04959898 Test MSE 0.007213038747662014 Test RE 0.04059449965170458\n",
      "79 Train Loss 0.04872559 Test MSE 0.006812982200628051 Test RE 0.03945269612403337\n",
      "80 Train Loss 0.04328703 Test MSE 0.004881221910610117 Test RE 0.03339429938024763\n",
      "81 Train Loss 0.035997417 Test MSE 0.00547529214051683 Test RE 0.03536809826205943\n",
      "82 Train Loss 0.034364294 Test MSE 0.0046962389267996285 Test RE 0.03275541848003739\n",
      "83 Train Loss 0.03351829 Test MSE 0.004619415254074235 Test RE 0.03248639812520578\n",
      "84 Train Loss 0.032824468 Test MSE 0.00420610239942472 Test RE 0.030999021196087127\n",
      "85 Train Loss 0.03183073 Test MSE 0.004036340862365844 Test RE 0.03036700616085132\n",
      "86 Train Loss 0.029607467 Test MSE 0.003893600490292814 Test RE 0.0298252267574466\n",
      "87 Train Loss 0.0285719 Test MSE 0.004233758013158535 Test RE 0.03110076531476067\n",
      "88 Train Loss 0.027740799 Test MSE 0.004548416698216699 Test RE 0.03223577998006037\n",
      "89 Train Loss 0.02737742 Test MSE 0.004624446427433477 Test RE 0.032504084370392976\n",
      "90 Train Loss 0.026321374 Test MSE 0.0045987657732437445 Test RE 0.03241370725705987\n",
      "91 Train Loss 0.024839498 Test MSE 0.004893023614951969 Test RE 0.03343464498688772\n",
      "92 Train Loss 0.023794372 Test MSE 0.0042680885227025095 Test RE 0.031226604983487994\n",
      "93 Train Loss 0.023198217 Test MSE 0.004669377460502343 Test RE 0.03266160720421239\n",
      "94 Train Loss 0.022293275 Test MSE 0.005423189062191483 Test RE 0.035199413949231456\n",
      "95 Train Loss 0.021331314 Test MSE 0.005076427895499116 Test RE 0.03405549296673188\n",
      "96 Train Loss 0.020446965 Test MSE 0.005115440795062669 Test RE 0.034186102590281126\n",
      "97 Train Loss 0.019863872 Test MSE 0.004852840670056293 Test RE 0.03329707440715252\n",
      "98 Train Loss 0.019324223 Test MSE 0.004349203853159113 Test RE 0.031521940311499186\n",
      "99 Train Loss 0.018843682 Test MSE 0.003941776578427221 Test RE 0.030009175446383568\n",
      "100 Train Loss 0.0184811 Test MSE 0.003610954824922503 Test RE 0.028722291656848396\n",
      "101 Train Loss 0.018200688 Test MSE 0.0036657307363071804 Test RE 0.028939321245158186\n",
      "102 Train Loss 0.017846117 Test MSE 0.003616095593947939 Test RE 0.028742729762465825\n",
      "103 Train Loss 0.01728674 Test MSE 0.0035697601908226224 Test RE 0.028557986326352196\n",
      "104 Train Loss 0.016847314 Test MSE 0.0035040814027250257 Test RE 0.028294052406427343\n",
      "105 Train Loss 0.016285094 Test MSE 0.003376473092156081 Test RE 0.027774081580804813\n",
      "106 Train Loss 0.015381747 Test MSE 0.003338738529299523 Test RE 0.027618447663746597\n",
      "107 Train Loss 0.014599419 Test MSE 0.0033102428930104582 Test RE 0.027500335436596687\n",
      "108 Train Loss 0.014379131 Test MSE 0.003410963517576901 Test RE 0.027915576264332793\n",
      "109 Train Loss 0.014255796 Test MSE 0.0032323667321909506 Test RE 0.027174926269432756\n",
      "110 Train Loss 0.014185429 Test MSE 0.003225434766368681 Test RE 0.027145771662399832\n",
      "111 Train Loss 0.013921795 Test MSE 0.0034934051502491874 Test RE 0.028250916295421463\n",
      "112 Train Loss 0.013436069 Test MSE 0.0033015559822692354 Test RE 0.02746422783032416\n",
      "113 Train Loss 0.012600163 Test MSE 0.0030068600413323734 Test RE 0.026209857945866874\n",
      "114 Train Loss 0.011819459 Test MSE 0.0027473335835745826 Test RE 0.02505323186620637\n",
      "115 Train Loss 0.011441915 Test MSE 0.0027100041173821953 Test RE 0.024882444017645354\n",
      "116 Train Loss 0.011260181 Test MSE 0.002629199166444465 Test RE 0.024508673329260374\n",
      "117 Train Loss 0.011132174 Test MSE 0.0027369705826369006 Test RE 0.02500593656157925\n",
      "118 Train Loss 0.010998918 Test MSE 0.0027548173167219036 Test RE 0.02508733114608691\n",
      "119 Train Loss 0.010785257 Test MSE 0.00271443472281091 Test RE 0.02490277595512025\n",
      "120 Train Loss 0.01058349 Test MSE 0.0023705344231391054 Test RE 0.023271865239810344\n",
      "121 Train Loss 0.010150903 Test MSE 0.0020388970063427614 Test RE 0.02158269653683943\n",
      "122 Train Loss 0.009633283 Test MSE 0.0020732011778876384 Test RE 0.02176350220370314\n",
      "123 Train Loss 0.009366168 Test MSE 0.0019217678426536743 Test RE 0.02095359383414665\n",
      "124 Train Loss 0.009196085 Test MSE 0.001937788201189589 Test RE 0.021040749886954844\n",
      "125 Train Loss 0.009112608 Test MSE 0.0020149016089345047 Test RE 0.021455319299128018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 Train Loss 0.009005891 Test MSE 0.002123252181257914 Test RE 0.022024641586430662\n",
      "127 Train Loss 0.008925339 Test MSE 0.002177522707881579 Test RE 0.02230434153559071\n",
      "128 Train Loss 0.0088793645 Test MSE 0.002223166203806781 Test RE 0.022536892137878576\n",
      "129 Train Loss 0.008794014 Test MSE 0.0021861705581305035 Test RE 0.02234858756752581\n",
      "130 Train Loss 0.008481329 Test MSE 0.0020967776221436137 Test RE 0.02188689965244684\n",
      "131 Train Loss 0.00815511 Test MSE 0.0019492529386272131 Test RE 0.021102900881008878\n",
      "132 Train Loss 0.007875854 Test MSE 0.0019986247303632825 Test RE 0.02136848285720381\n",
      "133 Train Loss 0.007611892 Test MSE 0.00208458939612471 Test RE 0.021823194453216486\n",
      "134 Train Loss 0.0074905204 Test MSE 0.002148678728011571 Test RE 0.022156124783951493\n",
      "135 Train Loss 0.0074533336 Test MSE 0.002144969849851731 Test RE 0.022136994455718456\n",
      "136 Train Loss 0.0074276365 Test MSE 0.002069087400556297 Test RE 0.021741899220845826\n",
      "137 Train Loss 0.0073904507 Test MSE 0.00209467154045834 Test RE 0.02187590488150161\n",
      "138 Train Loss 0.0073341145 Test MSE 0.002050730595035912 Test RE 0.021645238009815774\n",
      "139 Train Loss 0.007290084 Test MSE 0.002161293166121051 Test RE 0.022221066568534537\n",
      "140 Train Loss 0.0071965405 Test MSE 0.002202547383139072 Test RE 0.0224321391522989\n",
      "141 Train Loss 0.0070274575 Test MSE 0.0021742376729865843 Test RE 0.02228751089703052\n",
      "142 Train Loss 0.0067146635 Test MSE 0.0019938028730125696 Test RE 0.021342690622333026\n",
      "143 Train Loss 0.006591052 Test MSE 0.0018395731064318175 Test RE 0.020500600672684357\n",
      "144 Train Loss 0.006472421 Test MSE 0.0017799312507652339 Test RE 0.020165531556971778\n",
      "145 Train Loss 0.0064225486 Test MSE 0.0017148705511721668 Test RE 0.019793551777549014\n",
      "146 Train Loss 0.0063489354 Test MSE 0.001577355017880583 Test RE 0.01898334699011293\n",
      "147 Train Loss 0.0062691323 Test MSE 0.0014706221014083166 Test RE 0.018329837066413057\n",
      "148 Train Loss 0.006106502 Test MSE 0.0014459280483954478 Test RE 0.018175292191927855\n",
      "149 Train Loss 0.005969291 Test MSE 0.0013185768773798993 Test RE 0.017356445466986004\n",
      "Training time: 229.09\n",
      "5\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 67.61013 Test MSE 4.750833523993144 Test RE 1.0418206622563833\n",
      "1 Train Loss 49.546677 Test MSE 5.950392190825151 Test RE 1.1659524942130635\n",
      "2 Train Loss 35.6438 Test MSE 6.126620977522424 Test RE 1.1830921345323988\n",
      "3 Train Loss 28.682232 Test MSE 5.733555971715072 Test RE 1.1445113095381567\n",
      "4 Train Loss 24.203806 Test MSE 5.665830491642291 Test RE 1.137731674240245\n",
      "5 Train Loss 22.289198 Test MSE 5.700320917932181 Test RE 1.1411893590814108\n",
      "6 Train Loss 20.128654 Test MSE 5.313276725542631 Test RE 1.1017657763887865\n",
      "7 Train Loss 18.86148 Test MSE 5.306676501684212 Test RE 1.1010812496027322\n",
      "8 Train Loss 17.89429 Test MSE 5.405123246998445 Test RE 1.1112476635305941\n",
      "9 Train Loss 17.073235 Test MSE 5.433063391865165 Test RE 1.1141160902812104\n",
      "10 Train Loss 16.401691 Test MSE 5.507003506015277 Test RE 1.1216716330823802\n",
      "11 Train Loss 15.61501 Test MSE 5.646266860470912 Test RE 1.135765730323499\n",
      "12 Train Loss 14.860033 Test MSE 5.660387177019884 Test RE 1.1371850183143821\n",
      "13 Train Loss 14.077023 Test MSE 5.600924799945963 Test RE 1.1311961833183093\n",
      "14 Train Loss 13.105639 Test MSE 5.458970670929703 Test RE 1.1167692333972807\n",
      "15 Train Loss 12.241066 Test MSE 5.439944459571577 Test RE 1.1148213905745787\n",
      "16 Train Loss 11.217796 Test MSE 5.271188793431822 Test RE 1.0973934050093093\n",
      "17 Train Loss 10.166214 Test MSE 5.1725976986355 Test RE 1.0870822670562172\n",
      "18 Train Loss 9.446472 Test MSE 4.885841964574608 Test RE 1.0565201101174257\n",
      "19 Train Loss 8.271971 Test MSE 4.572767742188274 Test RE 1.0221099875372046\n",
      "20 Train Loss 7.8885417 Test MSE 4.70725484562449 Test RE 1.0370314224198027\n",
      "21 Train Loss 6.9637413 Test MSE 4.60930550901128 Test RE 1.0261853434729915\n",
      "22 Train Loss 6.59929 Test MSE 4.394177323855363 Test RE 1.0019518455691823\n",
      "23 Train Loss 5.228604 Test MSE 3.5913909520576586 Test RE 0.9058147793068825\n",
      "24 Train Loss 4.3172393 Test MSE 3.580683196222803 Test RE 0.9044634249144926\n",
      "25 Train Loss 4.0666623 Test MSE 3.5015079586035127 Test RE 0.8944078848497029\n",
      "26 Train Loss 3.6906378 Test MSE 3.510481144892997 Test RE 0.8955531847401463\n",
      "27 Train Loss 3.4009416 Test MSE 3.628317608620767 Test RE 0.9104596607830127\n",
      "28 Train Loss 3.3099105 Test MSE 3.6837311727756634 Test RE 0.9173858240509424\n",
      "29 Train Loss 3.1844144 Test MSE 3.6668099569167056 Test RE 0.9152763933631248\n",
      "30 Train Loss 3.0855765 Test MSE 3.6853921486076775 Test RE 0.917592623066152\n",
      "31 Train Loss 3.0121782 Test MSE 3.679549349778989 Test RE 0.9168649615962179\n",
      "32 Train Loss 2.9297078 Test MSE 3.699616376093309 Test RE 0.9193616989110219\n",
      "33 Train Loss 2.8372757 Test MSE 3.8512850583244775 Test RE 0.9380173959688316\n",
      "34 Train Loss 2.7659595 Test MSE 3.888638704436308 Test RE 0.9425553384342196\n",
      "35 Train Loss 2.6524253 Test MSE 3.882083602738076 Test RE 0.9417605677484479\n",
      "36 Train Loss 2.5825062 Test MSE 3.962671252304147 Test RE 0.9514852986491321\n",
      "37 Train Loss 2.4054852 Test MSE 4.0933891050895825 Test RE 0.9670514377273095\n",
      "38 Train Loss 2.3838065 Test MSE 4.11093272590754 Test RE 0.9691215371235534\n",
      "39 Train Loss 2.3060098 Test MSE 4.15862126115865 Test RE 0.9747264363390191\n",
      "40 Train Loss 2.2561684 Test MSE 4.183763729066285 Test RE 0.9776685289950854\n",
      "41 Train Loss 2.1966484 Test MSE 4.131382637010789 Test RE 0.9715290033732266\n",
      "42 Train Loss 2.1196811 Test MSE 4.071915453480106 Test RE 0.9645115580294787\n",
      "43 Train Loss 2.0725858 Test MSE 4.076919240647052 Test RE 0.965103997735747\n",
      "44 Train Loss 2.003089 Test MSE 4.109484047217972 Test RE 0.9689507645130208\n",
      "45 Train Loss 1.9666686 Test MSE 4.129387356273161 Test RE 0.9712943716066719\n",
      "46 Train Loss 1.9189873 Test MSE 4.1959528540516216 Test RE 0.9790916801921447\n",
      "47 Train Loss 1.8704178 Test MSE 4.137601812819297 Test RE 0.9722599738549662\n",
      "48 Train Loss 1.8368324 Test MSE 4.190671613531517 Test RE 0.9784753187930658\n",
      "49 Train Loss 1.8082186 Test MSE 4.182745576740587 Test RE 0.977549560033288\n",
      "50 Train Loss 1.7722268 Test MSE 4.224663453491306 Test RE 0.9824356628325663\n",
      "51 Train Loss 1.7468811 Test MSE 4.212095920499508 Test RE 0.9809732991748563\n",
      "52 Train Loss 1.7189897 Test MSE 4.1881511148737625 Test RE 0.9781810203010335\n",
      "53 Train Loss 1.691283 Test MSE 4.234554423286772 Test RE 0.9835850514895466\n",
      "54 Train Loss 1.6810203 Test MSE 4.225906531710662 Test RE 0.9825801896765799\n",
      "55 Train Loss 1.6536814 Test MSE 4.218990765684899 Test RE 0.9817758560889072\n",
      "56 Train Loss 1.6261953 Test MSE 4.2348889196287365 Test RE 0.9836238984462622\n",
      "57 Train Loss 1.607054 Test MSE 4.215014684290073 Test RE 0.981313122098365\n",
      "58 Train Loss 1.59817 Test MSE 4.239363637628583 Test RE 0.9841434253554264\n",
      "59 Train Loss 1.5863932 Test MSE 4.22066474428647 Test RE 0.9819706074971486\n",
      "60 Train Loss 1.5674272 Test MSE 4.212391629366823 Test RE 0.9810077330312462\n",
      "61 Train Loss 1.5504271 Test MSE 4.255753249081716 Test RE 0.9860439663555463\n",
      "62 Train Loss 1.5235003 Test MSE 4.282093750678849 Test RE 0.9890907627719469\n",
      "63 Train Loss 1.5179161 Test MSE 4.296064247310773 Test RE 0.9907029223612726\n",
      "64 Train Loss 1.506883 Test MSE 4.27324257874345 Test RE 0.9880679989580733\n",
      "65 Train Loss 1.4914932 Test MSE 4.230461381817682 Test RE 0.9831095790665924\n",
      "66 Train Loss 1.4689656 Test MSE 4.246926161123895 Test RE 0.9850208319884781\n",
      "67 Train Loss 1.4456565 Test MSE 4.220032659924643 Test RE 0.981897075062971\n",
      "68 Train Loss 1.4302796 Test MSE 4.208814154585017 Test RE 0.9805910723561038\n",
      "69 Train Loss 1.4171828 Test MSE 4.210398520983926 Test RE 0.9807756218878451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Train Loss 1.4030018 Test MSE 4.232992226855361 Test RE 0.983403604441657\n",
      "71 Train Loss 1.3568238 Test MSE 4.266893478189083 Test RE 0.987333700015325\n",
      "72 Train Loss 1.3337044 Test MSE 4.300257274547387 Test RE 0.9911862753779801\n",
      "73 Train Loss 1.3270494 Test MSE 4.317817698171167 Test RE 0.9932080053168775\n",
      "74 Train Loss 1.3162835 Test MSE 4.330809138637933 Test RE 0.9947010641217465\n",
      "75 Train Loss 1.3041463 Test MSE 4.330961328335776 Test RE 0.9947185414475328\n",
      "76 Train Loss 1.2824273 Test MSE 4.2992337178353255 Test RE 0.9910683061870732\n",
      "77 Train Loss 1.253529 Test MSE 4.337123804158613 Test RE 0.9954259767599248\n",
      "78 Train Loss 1.2289613 Test MSE 4.360172636620008 Test RE 0.9980674744688568\n",
      "79 Train Loss 1.2174227 Test MSE 4.323861794993138 Test RE 0.9939029102973418\n",
      "80 Train Loss 1.2043256 Test MSE 4.304717682871082 Test RE 0.9917001922657743\n",
      "81 Train Loss 1.1922057 Test MSE 4.296658220367396 Test RE 0.9907714071965493\n",
      "82 Train Loss 1.1843283 Test MSE 4.288215875350627 Test RE 0.9897975635247365\n",
      "83 Train Loss 1.1786419 Test MSE 4.264426981369983 Test RE 0.987048292438097\n",
      "84 Train Loss 1.168932 Test MSE 4.238222865315927 Test RE 0.9840110046428711\n",
      "85 Train Loss 1.1588961 Test MSE 4.210276253573732 Test RE 0.9807613812209269\n",
      "86 Train Loss 1.1440486 Test MSE 4.201240867770572 Test RE 0.9797084435595951\n",
      "87 Train Loss 1.1287984 Test MSE 4.180404166165776 Test RE 0.9772759161746764\n",
      "88 Train Loss 1.1086205 Test MSE 4.151065476059072 Test RE 0.9738405451572533\n",
      "89 Train Loss 1.1009295 Test MSE 4.148715775256858 Test RE 0.9735648860731683\n",
      "90 Train Loss 1.0878682 Test MSE 4.122995439830704 Test RE 0.9705423427568609\n",
      "91 Train Loss 1.074478 Test MSE 4.112790556699835 Test RE 0.9693404972210236\n",
      "92 Train Loss 1.0627215 Test MSE 4.107718140684079 Test RE 0.9687425558517044\n",
      "93 Train Loss 1.0550988 Test MSE 4.087398434310207 Test RE 0.9663435392340151\n",
      "94 Train Loss 1.0492772 Test MSE 4.063956051832036 Test RE 0.9635684281704514\n",
      "95 Train Loss 1.0348155 Test MSE 3.986149826606709 Test RE 0.9542998805906459\n",
      "96 Train Loss 1.0227019 Test MSE 3.9979852907286477 Test RE 0.9557155587631303\n",
      "97 Train Loss 1.0093726 Test MSE 3.9543389610723283 Test RE 0.9504844302874041\n",
      "98 Train Loss 0.99983346 Test MSE 3.9455867948540666 Test RE 0.9494319906864939\n",
      "99 Train Loss 0.9911401 Test MSE 3.8986041972518404 Test RE 0.9437623184264269\n",
      "100 Train Loss 0.9787195 Test MSE 3.8975042293091935 Test RE 0.9436291705768929\n",
      "101 Train Loss 0.97026384 Test MSE 3.821872384887599 Test RE 0.9344286616613195\n",
      "102 Train Loss 0.95198756 Test MSE 3.7836070475531427 Test RE 0.9297390521184172\n",
      "103 Train Loss 0.9327818 Test MSE 3.7235499443664644 Test RE 0.9223306735226018\n",
      "104 Train Loss 0.9212499 Test MSE 3.69312518379556 Test RE 0.9185548080115858\n",
      "105 Train Loss 0.9053029 Test MSE 3.6497881078396115 Test RE 0.9131495010928358\n",
      "106 Train Loss 0.89113206 Test MSE 3.6420257853982636 Test RE 0.9121779469340114\n",
      "107 Train Loss 0.8733759 Test MSE 3.5967194484265974 Test RE 0.9064865025824436\n",
      "108 Train Loss 0.85542935 Test MSE 3.5267348856969742 Test RE 0.8976240232861624\n",
      "109 Train Loss 0.8463214 Test MSE 3.496024562370834 Test RE 0.8937072846410015\n",
      "110 Train Loss 0.83869237 Test MSE 3.5023609547681795 Test RE 0.8945168207776386\n",
      "111 Train Loss 0.8310968 Test MSE 3.5021244736536743 Test RE 0.8944866211625316\n",
      "112 Train Loss 0.8201249 Test MSE 3.472027956053414 Test RE 0.8906348134086477\n",
      "113 Train Loss 0.8099984 Test MSE 3.4607109304067625 Test RE 0.8891821229450796\n",
      "114 Train Loss 0.80076313 Test MSE 3.4303283907674813 Test RE 0.8852703302900262\n",
      "115 Train Loss 0.7954551 Test MSE 3.428421183331702 Test RE 0.8850241980383132\n",
      "116 Train Loss 0.78721756 Test MSE 3.378001566557095 Test RE 0.8784923492560823\n",
      "117 Train Loss 0.77999794 Test MSE 3.3451579258394784 Test RE 0.8742112140524133\n",
      "118 Train Loss 0.771052 Test MSE 3.299898624421019 Test RE 0.8682771246301824\n",
      "119 Train Loss 0.7639193 Test MSE 3.3082460355810808 Test RE 0.8693746262853719\n",
      "120 Train Loss 0.75976664 Test MSE 3.2919876593926443 Test RE 0.8672357242020035\n",
      "121 Train Loss 0.7564301 Test MSE 3.2869876462930603 Test RE 0.8665768763902852\n",
      "122 Train Loss 0.7530812 Test MSE 3.3167589381560605 Test RE 0.8704924613045656\n",
      "123 Train Loss 0.7444493 Test MSE 3.283600563780218 Test RE 0.8661302784369335\n",
      "124 Train Loss 0.73910195 Test MSE 3.29396470804892 Test RE 0.8674961003107702\n",
      "125 Train Loss 0.73399115 Test MSE 3.272324740717759 Test RE 0.8646418619325634\n",
      "126 Train Loss 0.72740936 Test MSE 3.2775811511744175 Test RE 0.8653360303295521\n",
      "127 Train Loss 0.7235385 Test MSE 3.2681447817916403 Test RE 0.8640894530723131\n",
      "128 Train Loss 0.71557456 Test MSE 3.2397947098682307 Test RE 0.8603334451080498\n",
      "129 Train Loss 0.70744455 Test MSE 3.2253436736826115 Test RE 0.8584125510656632\n",
      "130 Train Loss 0.70098543 Test MSE 3.199306207713558 Test RE 0.8549406452381584\n",
      "131 Train Loss 0.696655 Test MSE 3.1975628564371474 Test RE 0.8547076783278971\n",
      "132 Train Loss 0.69132745 Test MSE 3.1941085177595725 Test RE 0.8542458816814509\n",
      "133 Train Loss 0.6871257 Test MSE 3.1728497714667467 Test RE 0.8513983713120423\n",
      "134 Train Loss 0.6845664 Test MSE 3.1680567318180777 Test RE 0.8507550492575329\n",
      "135 Train Loss 0.6786727 Test MSE 3.1687678792396436 Test RE 0.8508505302356616\n",
      "136 Train Loss 0.674295 Test MSE 3.165107947754088 Test RE 0.8503590214745469\n",
      "137 Train Loss 0.66919875 Test MSE 3.1503733293184326 Test RE 0.848377362009706\n",
      "138 Train Loss 0.6647673 Test MSE 3.133274793689226 Test RE 0.8460719611352123\n",
      "139 Train Loss 0.65923995 Test MSE 3.128271980134091 Test RE 0.8453962414042994\n",
      "140 Train Loss 0.65582305 Test MSE 3.129916179183526 Test RE 0.8456183795543171\n",
      "141 Train Loss 0.65177363 Test MSE 3.1175585976803686 Test RE 0.8439473870466346\n",
      "142 Train Loss 0.64764553 Test MSE 3.1153319234375743 Test RE 0.8436459441839596\n",
      "143 Train Loss 0.6434946 Test MSE 3.10881145125112 Test RE 0.8427625950762729\n",
      "144 Train Loss 0.63875335 Test MSE 3.111269045300549 Test RE 0.8430956418379039\n",
      "145 Train Loss 0.63277316 Test MSE 3.0904009031317172 Test RE 0.8402634469197847\n",
      "146 Train Loss 0.62569594 Test MSE 3.0753977938694614 Test RE 0.8382213329082968\n",
      "147 Train Loss 0.61857384 Test MSE 3.0382318148123963 Test RE 0.8331410127189798\n",
      "148 Train Loss 0.6148912 Test MSE 3.0240335766514983 Test RE 0.831192019426148\n",
      "149 Train Loss 0.6119127 Test MSE 3.012028417193684 Test RE 0.8295404974223403\n",
      "Training time: 232.69\n",
      "6\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 60.674927 Test MSE 7.163390347595461 Test RE 1.279285180537406\n",
      "1 Train Loss 47.95027 Test MSE 8.279052110807164 Test RE 1.3753029304427749\n",
      "2 Train Loss 43.90712 Test MSE 8.800045210651515 Test RE 1.417916028637923\n",
      "3 Train Loss 39.924767 Test MSE 9.284259581225722 Test RE 1.4564034449568115\n",
      "4 Train Loss 35.426956 Test MSE 9.250627785190787 Test RE 1.453763175048003\n",
      "5 Train Loss 32.676224 Test MSE 9.452039247609187 Test RE 1.469504155165458\n",
      "6 Train Loss 29.995602 Test MSE 9.543698146353169 Test RE 1.4766120481891463\n",
      "7 Train Loss 27.327118 Test MSE 9.771655245087988 Test RE 1.494142875669758\n",
      "8 Train Loss 25.6316 Test MSE 9.401812969635879 Test RE 1.4655946265677156\n",
      "9 Train Loss 23.807537 Test MSE 9.212283298700857 Test RE 1.450747072291315\n",
      "10 Train Loss 22.241623 Test MSE 9.297969425891127 Test RE 1.4574783663892201\n",
      "11 Train Loss 21.031315 Test MSE 9.390875025600591 Test RE 1.464741851830863\n",
      "12 Train Loss 19.827501 Test MSE 9.112258818669769 Test RE 1.4428496671781745\n",
      "13 Train Loss 18.797234 Test MSE 8.880332222795865 Test RE 1.4243695048272496\n",
      "14 Train Loss 17.203123 Test MSE 8.369504402228678 Test RE 1.3827954165417626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Train Loss 15.552292 Test MSE 7.883955476207716 Test RE 1.3420853687757612\n",
      "16 Train Loss 14.2526245 Test MSE 7.163949813182053 Test RE 1.2793351360769818\n",
      "17 Train Loss 12.945648 Test MSE 7.233257296536594 Test RE 1.285508691107222\n",
      "18 Train Loss 11.997786 Test MSE 6.974665349589376 Test RE 1.2623208267217405\n",
      "19 Train Loss 11.423611 Test MSE 7.00983735129581 Test RE 1.2654996543416792\n",
      "20 Train Loss 10.735193 Test MSE 7.082374423865025 Test RE 1.272030432697036\n",
      "21 Train Loss 10.11969 Test MSE 6.977288904214053 Test RE 1.2625582184890107\n",
      "22 Train Loss 9.733249 Test MSE 7.018326658585207 Test RE 1.2662657181039791\n",
      "23 Train Loss 9.446702 Test MSE 7.142785921148479 Test RE 1.2774440188928269\n",
      "24 Train Loss 9.156254 Test MSE 7.208416059934582 Test RE 1.28329937593283\n",
      "25 Train Loss 8.921957 Test MSE 7.355914469464243 Test RE 1.2963623090922385\n",
      "26 Train Loss 8.662239 Test MSE 7.433730740224931 Test RE 1.3032012066987029\n",
      "27 Train Loss 8.384917 Test MSE 7.449875395274158 Test RE 1.304615592253256\n",
      "28 Train Loss 8.067077 Test MSE 7.456881258104222 Test RE 1.3052288783557837\n",
      "29 Train Loss 7.682706 Test MSE 7.219923411898977 Test RE 1.2843232824744766\n",
      "30 Train Loss 6.864614 Test MSE 6.459122479521731 Test RE 1.2147721318585727\n",
      "31 Train Loss 6.179269 Test MSE 6.002899777812766 Test RE 1.1710855077156832\n",
      "32 Train Loss 5.260023 Test MSE 5.746561236649213 Test RE 1.1458086058243864\n",
      "33 Train Loss 4.67636 Test MSE 5.673803127624198 Test RE 1.1385318686503278\n",
      "34 Train Loss 4.267839 Test MSE 5.920775622936624 Test RE 1.163047258279417\n",
      "35 Train Loss 4.0290365 Test MSE 6.008424701028764 Test RE 1.1716243031053832\n",
      "36 Train Loss 3.805146 Test MSE 5.9894024694835775 Test RE 1.1697681945956555\n",
      "37 Train Loss 3.6229992 Test MSE 5.860813807752044 Test RE 1.1571429734795042\n",
      "38 Train Loss 3.4528413 Test MSE 5.751744647323694 Test RE 1.1463252502683814\n",
      "39 Train Loss 3.2520185 Test MSE 5.668263270191253 Test RE 1.137975906058208\n",
      "40 Train Loss 3.153802 Test MSE 5.618438594913384 Test RE 1.1329633981524003\n",
      "41 Train Loss 3.025405 Test MSE 5.475643764102555 Test RE 1.1184733826512459\n",
      "42 Train Loss 2.9109104 Test MSE 5.361438797652966 Test RE 1.1067479766033417\n",
      "43 Train Loss 2.8047178 Test MSE 5.250037659673358 Test RE 1.0951894955473802\n",
      "44 Train Loss 2.7137635 Test MSE 5.148911711962786 Test RE 1.0845904668210538\n",
      "45 Train Loss 2.6315408 Test MSE 5.116954470679293 Test RE 1.081219417778329\n",
      "46 Train Loss 2.5027618 Test MSE 5.099278344831896 Test RE 1.079350307528103\n",
      "47 Train Loss 2.4489458 Test MSE 5.175490308554084 Test RE 1.0873861825777882\n",
      "48 Train Loss 2.3602514 Test MSE 5.201802161834757 Test RE 1.0901467783705499\n",
      "49 Train Loss 2.285304 Test MSE 5.181074348632266 Test RE 1.087972636296466\n",
      "50 Train Loss 2.2256737 Test MSE 5.08694786536232 Test RE 1.078044538244677\n",
      "51 Train Loss 2.1722174 Test MSE 5.121112800234567 Test RE 1.0816586588950174\n",
      "52 Train Loss 2.108872 Test MSE 5.165669391144165 Test RE 1.0863539904376756\n",
      "53 Train Loss 2.07482 Test MSE 5.169948409683231 Test RE 1.0868038417784482\n",
      "54 Train Loss 2.0398402 Test MSE 5.170964359153373 Test RE 1.0869106207500507\n",
      "55 Train Loss 1.990716 Test MSE 5.178050980824422 Test RE 1.0876551518106965\n",
      "56 Train Loss 1.9435606 Test MSE 5.144857417212794 Test RE 1.0841633750752668\n",
      "57 Train Loss 1.9337436 Test MSE 5.178092357578229 Test RE 1.0876594974177316\n",
      "58 Train Loss 1.8812473 Test MSE 5.1667397907637085 Test RE 1.0864665385488106\n",
      "59 Train Loss 1.854734 Test MSE 5.162508365963665 Test RE 1.0860215535781224\n",
      "60 Train Loss 1.8164351 Test MSE 5.187513494721632 Test RE 1.0886485037851383\n",
      "61 Train Loss 1.7968783 Test MSE 5.163799116475728 Test RE 1.086157310769024\n",
      "62 Train Loss 1.770767 Test MSE 5.18892081915312 Test RE 1.0887961639061614\n",
      "63 Train Loss 1.7497616 Test MSE 5.210208265706552 Test RE 1.0910272605141613\n",
      "64 Train Loss 1.7354238 Test MSE 5.201992013464585 Test RE 1.090166671885124\n",
      "65 Train Loss 1.7153244 Test MSE 5.202208970471061 Test RE 1.0901894051795076\n",
      "66 Train Loss 1.6976458 Test MSE 5.23558732863484 Test RE 1.0936812439248524\n",
      "67 Train Loss 1.6755992 Test MSE 5.293970124725686 Test RE 1.0997622377534015\n",
      "68 Train Loss 1.6610801 Test MSE 5.292078014009131 Test RE 1.099565687921203\n",
      "69 Train Loss 1.6428754 Test MSE 5.352465465804252 Test RE 1.105821417880742\n",
      "70 Train Loss 1.625542 Test MSE 5.366035293603678 Test RE 1.1072222963628304\n",
      "71 Train Loss 1.6055796 Test MSE 5.396412725291768 Test RE 1.1103518976692812\n",
      "72 Train Loss 1.5840161 Test MSE 5.380856363139831 Test RE 1.1087503242319734\n",
      "73 Train Loss 1.5733154 Test MSE 5.387815393567082 Test RE 1.1094670627606764\n",
      "74 Train Loss 1.5547502 Test MSE 5.428110617502443 Test RE 1.1136081610222222\n",
      "75 Train Loss 1.5403492 Test MSE 5.411355640097288 Test RE 1.111888142634319\n",
      "76 Train Loss 1.5292896 Test MSE 5.4018089043184965 Test RE 1.1109069108628893\n",
      "77 Train Loss 1.5166928 Test MSE 5.397275018702921 Test RE 1.110440605754586\n",
      "78 Train Loss 1.5063419 Test MSE 5.394530074532145 Test RE 1.1101581961028777\n",
      "79 Train Loss 1.4986371 Test MSE 5.412047376525122 Test RE 1.1119592069853776\n",
      "80 Train Loss 1.4914176 Test MSE 5.383779447649095 Test RE 1.1090514408799343\n",
      "81 Train Loss 1.4855185 Test MSE 5.384353562874235 Test RE 1.1091105727918233\n",
      "82 Train Loss 1.480411 Test MSE 5.389220959026076 Test RE 1.1096117714018694\n",
      "83 Train Loss 1.4692897 Test MSE 5.427026224736959 Test RE 1.1134969207550667\n",
      "84 Train Loss 1.4613075 Test MSE 5.443317759321504 Test RE 1.1151669863740585\n",
      "85 Train Loss 1.4552732 Test MSE 5.446255336488454 Test RE 1.1154678550141526\n",
      "86 Train Loss 1.4488106 Test MSE 5.4442761751197315 Test RE 1.11526515688905\n",
      "87 Train Loss 1.4393638 Test MSE 5.443411411402141 Test RE 1.115176579536165\n",
      "88 Train Loss 1.433311 Test MSE 5.447192729990483 Test RE 1.1155638464124153\n",
      "89 Train Loss 1.4232099 Test MSE 5.450256880022813 Test RE 1.1158775652940645\n",
      "90 Train Loss 1.4124373 Test MSE 5.440474436338622 Test RE 1.1148756939825804\n",
      "91 Train Loss 1.4042828 Test MSE 5.456741117878315 Test RE 1.1165411546361974\n",
      "92 Train Loss 1.3981019 Test MSE 5.4701983602812065 Test RE 1.1179170960780427\n",
      "93 Train Loss 1.392799 Test MSE 5.467665324305475 Test RE 1.1176582341568686\n",
      "94 Train Loss 1.3841736 Test MSE 5.485779102533133 Test RE 1.1195080432184312\n",
      "95 Train Loss 1.3752759 Test MSE 5.455863011794197 Test RE 1.1164513133732035\n",
      "96 Train Loss 1.3683522 Test MSE 5.46432711610597 Test RE 1.117316996598592\n",
      "97 Train Loss 1.362395 Test MSE 5.451855968369143 Test RE 1.1160412507850137\n",
      "98 Train Loss 1.3588414 Test MSE 5.456856071245083 Test RE 1.1165529152719074\n",
      "99 Train Loss 1.3549705 Test MSE 5.468979606933974 Test RE 1.11779255387588\n",
      "100 Train Loss 1.3479278 Test MSE 5.498094613875408 Test RE 1.1207639800990192\n",
      "101 Train Loss 1.3402921 Test MSE 5.496455144968419 Test RE 1.1205968681425922\n",
      "102 Train Loss 1.3351686 Test MSE 5.487757941951505 Test RE 1.1197099404203275\n",
      "103 Train Loss 1.3296971 Test MSE 5.507414722047963 Test RE 1.121713510734012\n",
      "104 Train Loss 1.3210206 Test MSE 5.519703363942099 Test RE 1.1229642477575406\n",
      "105 Train Loss 1.3146946 Test MSE 5.508819836748146 Test RE 1.121856593805218\n",
      "106 Train Loss 1.309572 Test MSE 5.508391351234811 Test RE 1.1218129629858684\n",
      "107 Train Loss 1.3028585 Test MSE 5.519156593233213 Test RE 1.1229086270906707\n",
      "108 Train Loss 1.2916181 Test MSE 5.554582694798049 Test RE 1.1265066989622552\n",
      "109 Train Loss 1.2829968 Test MSE 5.579468688167608 Test RE 1.1290274021123696\n",
      "110 Train Loss 1.2783622 Test MSE 5.574962884660799 Test RE 1.128571426517936\n",
      "111 Train Loss 1.2715454 Test MSE 5.588921728163051 Test RE 1.1299834272309643\n",
      "112 Train Loss 1.2665359 Test MSE 5.604405262332735 Test RE 1.1315475962067172\n",
      "113 Train Loss 1.2606041 Test MSE 5.598251137458569 Test RE 1.13092615667696\n",
      "114 Train Loss 1.255048 Test MSE 5.599182168427352 Test RE 1.1310201934998572\n",
      "115 Train Loss 1.2488297 Test MSE 5.617805039769359 Test RE 1.132899517857797\n",
      "116 Train Loss 1.2447457 Test MSE 5.610061738039934 Test RE 1.132118482589364\n",
      "117 Train Loss 1.2414362 Test MSE 5.596168496320304 Test RE 1.1307157755798154\n",
      "118 Train Loss 1.2387835 Test MSE 5.5935253860462515 Test RE 1.1304487214825498\n",
      "119 Train Loss 1.232374 Test MSE 5.60561628257843 Test RE 1.1316698440604607\n",
      "120 Train Loss 1.2265038 Test MSE 5.596309063531607 Test RE 1.1307299764178866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 Train Loss 1.2220451 Test MSE 5.618559103234433 Test RE 1.1329755483950803\n",
      "122 Train Loss 1.2174582 Test MSE 5.631580016415228 Test RE 1.1342876142447316\n",
      "123 Train Loss 1.2103454 Test MSE 5.625971621108012 Test RE 1.1337226646267526\n",
      "124 Train Loss 1.205884 Test MSE 5.636664395988506 Test RE 1.1347995352023184\n",
      "125 Train Loss 1.2029833 Test MSE 5.629251469176149 Test RE 1.1340530872233066\n",
      "126 Train Loss 1.1993291 Test MSE 5.638332477098763 Test RE 1.134967435711392\n",
      "127 Train Loss 1.1961337 Test MSE 5.643350502626852 Test RE 1.1354723748021787\n",
      "128 Train Loss 1.190164 Test MSE 5.659559534830851 Test RE 1.1371018776497\n",
      "129 Train Loss 1.1850257 Test MSE 5.632143386513828 Test RE 1.1343443485663964\n",
      "130 Train Loss 1.1804758 Test MSE 5.637106566358778 Test RE 1.1348440442288739\n",
      "131 Train Loss 1.1732398 Test MSE 5.650478451939287 Test RE 1.1361892393181048\n",
      "132 Train Loss 1.1670923 Test MSE 5.64465210017105 Test RE 1.135603311454559\n",
      "133 Train Loss 1.1614058 Test MSE 5.646551774602875 Test RE 1.1357943856840278\n",
      "134 Train Loss 1.1569098 Test MSE 5.664530144039462 Test RE 1.1376011080723183\n",
      "135 Train Loss 1.1518415 Test MSE 5.677354134234611 Test RE 1.1388880937185017\n",
      "136 Train Loss 1.1491555 Test MSE 5.673287652451358 Test RE 1.1384801486462082\n",
      "137 Train Loss 1.1434851 Test MSE 5.713141929293262 Test RE 1.1424720047569157\n",
      "138 Train Loss 1.1410056 Test MSE 5.719669205970973 Test RE 1.1431244567880612\n",
      "139 Train Loss 1.1384095 Test MSE 5.711979563830439 Test RE 1.1423557782068574\n",
      "140 Train Loss 1.1356881 Test MSE 5.705426686094535 Test RE 1.1417003254142568\n",
      "141 Train Loss 1.132346 Test MSE 5.740006536252324 Test RE 1.1451549475153209\n",
      "142 Train Loss 1.1279732 Test MSE 5.736595886951048 Test RE 1.1448146776694854\n",
      "143 Train Loss 1.1244428 Test MSE 5.742946786940968 Test RE 1.1454482060273277\n",
      "144 Train Loss 1.1210387 Test MSE 5.744272423141039 Test RE 1.1455803994855287\n",
      "145 Train Loss 1.1168375 Test MSE 5.7482092142426415 Test RE 1.1459728894257313\n",
      "146 Train Loss 1.1123652 Test MSE 5.768415998938605 Test RE 1.14798535206581\n",
      "147 Train Loss 1.1074061 Test MSE 5.774257375382269 Test RE 1.1485664576757042\n",
      "148 Train Loss 1.1028507 Test MSE 5.763566867058249 Test RE 1.1475027323345623\n",
      "149 Train Loss 1.0996736 Test MSE 5.7767863616751045 Test RE 1.1488179524273652\n",
      "Training time: 230.17\n",
      "7\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 63.5906 Test MSE 5.5242371931395065 Test RE 1.1234253488979598\n",
      "1 Train Loss 53.607082 Test MSE 5.297242262485927 Test RE 1.1001020600015394\n",
      "2 Train Loss 43.255486 Test MSE 5.3273735395185495 Test RE 1.1032263721701077\n",
      "3 Train Loss 37.546013 Test MSE 4.9508542386988275 Test RE 1.063526046062395\n",
      "4 Train Loss 31.802666 Test MSE 3.8820791970786193 Test RE 0.941760033360481\n",
      "5 Train Loss 25.907648 Test MSE 3.589002401438076 Test RE 0.9055135110325104\n",
      "6 Train Loss 20.997982 Test MSE 3.710535669162233 Test RE 0.9207174318354577\n",
      "7 Train Loss 18.30627 Test MSE 3.29388117628142 Test RE 0.8674851008088953\n",
      "8 Train Loss 16.547693 Test MSE 2.8876257197602846 Test RE 0.8122290362641533\n",
      "9 Train Loss 12.293304 Test MSE 2.2400756270873385 Test RE 0.7153842932206648\n",
      "10 Train Loss 9.023504 Test MSE 2.5370126881387334 Test RE 0.7613237531261706\n",
      "11 Train Loss 6.7455235 Test MSE 2.2437504029405875 Test RE 0.7159708358422703\n",
      "12 Train Loss 5.556693 Test MSE 2.2564085243991228 Test RE 0.717987570792492\n",
      "13 Train Loss 4.8034873 Test MSE 2.1904357067162503 Test RE 0.707413454392103\n",
      "14 Train Loss 4.5809517 Test MSE 2.166298924083689 Test RE 0.7035051034430824\n",
      "15 Train Loss 4.396491 Test MSE 2.1679484313419337 Test RE 0.7037728910380163\n",
      "16 Train Loss 4.2876024 Test MSE 2.148690336815614 Test RE 0.7006400770907452\n",
      "17 Train Loss 4.174204 Test MSE 2.1394984207726675 Test RE 0.6991398313105486\n",
      "18 Train Loss 4.093121 Test MSE 2.1512030180721062 Test RE 0.701049622100884\n",
      "19 Train Loss 3.9988084 Test MSE 2.1230946617371314 Test RE 0.696454484950835\n",
      "20 Train Loss 3.9219751 Test MSE 2.131943107865954 Test RE 0.6979042866307767\n",
      "21 Train Loss 3.8786812 Test MSE 2.136241706751526 Test RE 0.6986075183172427\n",
      "22 Train Loss 3.8528147 Test MSE 2.1140283250120593 Test RE 0.6949658451688476\n",
      "23 Train Loss 3.7209573 Test MSE 2.1148890827593685 Test RE 0.6951073135563471\n",
      "24 Train Loss 3.6567252 Test MSE 2.1200159360108395 Test RE 0.6959493331380782\n",
      "25 Train Loss 3.5185542 Test MSE 2.1170740646077517 Test RE 0.6954662933237217\n",
      "26 Train Loss 3.3556805 Test MSE 2.091801128264009 Test RE 0.6913027057903331\n",
      "27 Train Loss 3.2280848 Test MSE 2.107660494370269 Test RE 0.6939183751982735\n",
      "28 Train Loss 3.0818372 Test MSE 2.1003437398669833 Test RE 0.6927128574018111\n",
      "29 Train Loss 2.9839244 Test MSE 2.088061659880763 Test RE 0.6906845158141017\n",
      "30 Train Loss 2.8745832 Test MSE 2.133783670126226 Test RE 0.6982054811520284\n",
      "31 Train Loss 2.6733398 Test MSE 1.9927581233355196 Test RE 0.6747382872050239\n",
      "32 Train Loss 2.4986172 Test MSE 1.9852384844127124 Test RE 0.6734640272375565\n",
      "33 Train Loss 2.2279584 Test MSE 1.8880012739909384 Test RE 0.656763792115337\n",
      "34 Train Loss 2.1136947 Test MSE 1.8051689059042102 Test RE 0.6421950923490376\n",
      "35 Train Loss 2.0167356 Test MSE 1.7350181573918366 Test RE 0.6295932632498157\n",
      "36 Train Loss 1.8978368 Test MSE 1.6910821929183844 Test RE 0.6215705343802965\n",
      "37 Train Loss 1.7736199 Test MSE 1.4487086895353314 Test RE 0.5753055885678752\n",
      "38 Train Loss 1.6154883 Test MSE 1.1875615537699067 Test RE 0.520878132069357\n",
      "39 Train Loss 1.4386914 Test MSE 1.0743604961759197 Test RE 0.4954308838200605\n",
      "40 Train Loss 1.3495133 Test MSE 0.9907262245137909 Test RE 0.4757566744105608\n",
      "41 Train Loss 1.2069032 Test MSE 0.8241626867837039 Test RE 0.43392486243260064\n",
      "42 Train Loss 1.0588866 Test MSE 0.7582019096012194 Test RE 0.4161984871308506\n",
      "43 Train Loss 0.9423783 Test MSE 0.5561172231288112 Test RE 0.3564439379386459\n",
      "44 Train Loss 0.75606143 Test MSE 0.45648537679741336 Test RE 0.3229397428796006\n",
      "45 Train Loss 0.59850454 Test MSE 0.34634892425326175 Test RE 0.2812969231340368\n",
      "46 Train Loss 0.4865115 Test MSE 0.14201174391983906 Test RE 0.18012342260880454\n",
      "47 Train Loss 0.33971304 Test MSE 0.06623416302220714 Test RE 0.12301245518854165\n",
      "48 Train Loss 0.26324382 Test MSE 0.06538135078011359 Test RE 0.12221795276564298\n",
      "49 Train Loss 0.22257118 Test MSE 0.055513986389852714 Test RE 0.11261837787203752\n",
      "50 Train Loss 0.19829491 Test MSE 0.057800260338330585 Test RE 0.11491400408381833\n",
      "51 Train Loss 0.17486794 Test MSE 0.05887357972455209 Test RE 0.11597604166370187\n",
      "52 Train Loss 0.13585028 Test MSE 0.0431761831416678 Test RE 0.0993185073353407\n",
      "53 Train Loss 0.11960846 Test MSE 0.03924403157693047 Test RE 0.09468798365733991\n",
      "54 Train Loss 0.11226828 Test MSE 0.04005449285181573 Test RE 0.09566072740626441\n",
      "55 Train Loss 0.10025956 Test MSE 0.030230410176304505 Test RE 0.0831055599835559\n",
      "56 Train Loss 0.088654235 Test MSE 0.02487984956976444 Test RE 0.07539315805856958\n",
      "57 Train Loss 0.0832154 Test MSE 0.018772569893574856 Test RE 0.06548923619552822\n",
      "58 Train Loss 0.07786153 Test MSE 0.01715789689367232 Test RE 0.06260947860815902\n",
      "59 Train Loss 0.07300233 Test MSE 0.015250621350377476 Test RE 0.059027151998696535\n",
      "60 Train Loss 0.06733705 Test MSE 0.016941190206253502 Test RE 0.06221283889761096\n",
      "61 Train Loss 0.062567234 Test MSE 0.015250152220563008 Test RE 0.05902624411405404\n",
      "62 Train Loss 0.057762586 Test MSE 0.013402199860434278 Test RE 0.05533451468796536\n",
      "63 Train Loss 0.050281484 Test MSE 0.00946631170176355 Test RE 0.04650487277246682\n",
      "64 Train Loss 0.044905044 Test MSE 0.008164858488232861 Test RE 0.04318991917285789\n",
      "65 Train Loss 0.041514948 Test MSE 0.00789547611615575 Test RE 0.04247146310798246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 Train Loss 0.039237186 Test MSE 0.006584366251520527 Test RE 0.03878511204547787\n",
      "67 Train Loss 0.037025902 Test MSE 0.006592834183672177 Test RE 0.03881004414653372\n",
      "68 Train Loss 0.033599008 Test MSE 0.005122522139512048 Test RE 0.03420975645081005\n",
      "69 Train Loss 0.030780878 Test MSE 0.005927635220777601 Test RE 0.03680008274688767\n",
      "70 Train Loss 0.03024359 Test MSE 0.005739056736467664 Test RE 0.03620998287196612\n",
      "71 Train Loss 0.028617978 Test MSE 0.0052216946275716394 Test RE 0.034539320974183794\n",
      "72 Train Loss 0.027286014 Test MSE 0.004850540820437935 Test RE 0.033289183426984\n",
      "73 Train Loss 0.02654394 Test MSE 0.004998506010382499 Test RE 0.03379311059246996\n",
      "74 Train Loss 0.025771517 Test MSE 0.005219750280639869 Test RE 0.03453288985552436\n",
      "75 Train Loss 0.024901977 Test MSE 0.005261903335209937 Test RE 0.0346720478270068\n",
      "76 Train Loss 0.024297278 Test MSE 0.005686655353317006 Test RE 0.03604429324635107\n",
      "77 Train Loss 0.02395841 Test MSE 0.0056741514220435005 Test RE 0.036004643983314974\n",
      "78 Train Loss 0.02288888 Test MSE 0.005030626705998675 Test RE 0.03390151498298274\n",
      "79 Train Loss 0.022282008 Test MSE 0.004823319033208552 Test RE 0.03319564065578001\n",
      "80 Train Loss 0.020784723 Test MSE 0.004357579552011084 Test RE 0.031552278196179374\n",
      "81 Train Loss 0.019973254 Test MSE 0.004721524627436747 Test RE 0.03284348169864424\n",
      "82 Train Loss 0.01966261 Test MSE 0.0047516312795109535 Test RE 0.032948028014224376\n",
      "83 Train Loss 0.018968074 Test MSE 0.004525865703460238 Test RE 0.0321557683798487\n",
      "84 Train Loss 0.01862036 Test MSE 0.004778664156485478 Test RE 0.03304161869046215\n",
      "85 Train Loss 0.018079378 Test MSE 0.004599603207962928 Test RE 0.03241665838890034\n",
      "86 Train Loss 0.017591834 Test MSE 0.004634179666837511 Test RE 0.0325382726506385\n",
      "87 Train Loss 0.017367298 Test MSE 0.004552075484058455 Test RE 0.03224874274424743\n",
      "88 Train Loss 0.017015742 Test MSE 0.004559030767187901 Test RE 0.03227337035903697\n",
      "89 Train Loss 0.016477976 Test MSE 0.004684958669604787 Test RE 0.032716055950367647\n",
      "90 Train Loss 0.016218714 Test MSE 0.004354387673597451 Test RE 0.0315407202333633\n",
      "91 Train Loss 0.015811354 Test MSE 0.004466235540468852 Test RE 0.03194323318760953\n",
      "92 Train Loss 0.015203257 Test MSE 0.0035072505307387125 Test RE 0.028306844233858038\n",
      "93 Train Loss 0.01477548 Test MSE 0.0031107499866600526 Test RE 0.026658801089413584\n",
      "94 Train Loss 0.014221333 Test MSE 0.003048263866774134 Test RE 0.02638969308377786\n",
      "95 Train Loss 0.013818689 Test MSE 0.0031763174282715026 Test RE 0.026938289077013622\n",
      "96 Train Loss 0.013491413 Test MSE 0.0032161816012537406 Test RE 0.027106805641604656\n",
      "97 Train Loss 0.013301263 Test MSE 0.003233899417612082 Test RE 0.027181368248419876\n",
      "98 Train Loss 0.013105288 Test MSE 0.003152924759666024 Test RE 0.02683890936925742\n",
      "99 Train Loss 0.012701444 Test MSE 0.0028544188587024595 Test RE 0.02553682564393377\n",
      "100 Train Loss 0.011717543 Test MSE 0.0019547869036161806 Test RE 0.021132835412005297\n",
      "101 Train Loss 0.010985376 Test MSE 0.0015770502605803914 Test RE 0.018981513036126465\n",
      "102 Train Loss 0.010814719 Test MSE 0.001472053560042199 Test RE 0.018338755748408812\n",
      "103 Train Loss 0.010594133 Test MSE 0.0013218623300522302 Test RE 0.017378055243501767\n",
      "104 Train Loss 0.010168627 Test MSE 0.0013497616279875963 Test RE 0.01756048874461465\n",
      "105 Train Loss 0.009523652 Test MSE 0.0011497101834131401 Test RE 0.016206985714776866\n",
      "106 Train Loss 0.009370124 Test MSE 0.0010246918481849057 Test RE 0.015300467506221079\n",
      "107 Train Loss 0.009164887 Test MSE 0.0010930994698500028 Test RE 0.01580294039736821\n",
      "108 Train Loss 0.008957834 Test MSE 0.001002440074634963 Test RE 0.015133426449342244\n",
      "109 Train Loss 0.008899079 Test MSE 0.0010249945017203142 Test RE 0.01530272691655422\n",
      "110 Train Loss 0.008807303 Test MSE 0.00094848732377417 Test RE 0.014720542850629363\n",
      "111 Train Loss 0.008621508 Test MSE 0.0009146738760042074 Test RE 0.014455768943125159\n",
      "112 Train Loss 0.008474626 Test MSE 0.0007946576373130971 Test RE 0.01347404802995212\n",
      "113 Train Loss 0.008350114 Test MSE 0.0007169789238079901 Test RE 0.012798564308878164\n",
      "114 Train Loss 0.00821639 Test MSE 0.0006756663913945579 Test RE 0.012424365494701417\n",
      "115 Train Loss 0.007807566 Test MSE 0.0006635186036167651 Test RE 0.012312170253031945\n",
      "116 Train Loss 0.007387016 Test MSE 0.0007286592703109079 Test RE 0.01290239423047077\n",
      "117 Train Loss 0.0072417627 Test MSE 0.0006620614076982066 Test RE 0.01229864304712142\n",
      "118 Train Loss 0.007117058 Test MSE 0.0006749051848148046 Test RE 0.012417364869765751\n",
      "119 Train Loss 0.007070247 Test MSE 0.0006572295897894735 Test RE 0.012253682245034139\n",
      "120 Train Loss 0.0070161726 Test MSE 0.0006914880357909795 Test RE 0.012568990426078041\n",
      "121 Train Loss 0.006912591 Test MSE 0.0006663840464365019 Test RE 0.012338727015873453\n",
      "122 Train Loss 0.0067424728 Test MSE 0.0005899409588721391 Test RE 0.011609468437270886\n",
      "123 Train Loss 0.006316265 Test MSE 0.0005448868159446028 Test RE 0.01115735393934563\n",
      "124 Train Loss 0.00619578 Test MSE 0.0005929976956631028 Test RE 0.011639506391931627\n",
      "125 Train Loss 0.00611471 Test MSE 0.0006651086219922664 Test RE 0.01232691351932419\n",
      "126 Train Loss 0.006091688 Test MSE 0.0006336809534445729 Test RE 0.012032154147074177\n",
      "127 Train Loss 0.0060431226 Test MSE 0.0006695325656321298 Test RE 0.012367841562675006\n",
      "128 Train Loss 0.0058502774 Test MSE 0.0007046745645649373 Test RE 0.01268826843802338\n",
      "129 Train Loss 0.0056336317 Test MSE 0.0007813435161448448 Test RE 0.01336069551076287\n",
      "130 Train Loss 0.005593476 Test MSE 0.000754379291104676 Test RE 0.013128132133219532\n",
      "131 Train Loss 0.0055178506 Test MSE 0.0007456038513638278 Test RE 0.013051551206106687\n",
      "132 Train Loss 0.005476067 Test MSE 0.0007341653781682805 Test RE 0.012951050903623836\n",
      "133 Train Loss 0.0054484447 Test MSE 0.0007178047960476825 Test RE 0.012805933379669515\n",
      "134 Train Loss 0.0054011196 Test MSE 0.0006697022532452315 Test RE 0.012369408728087007\n",
      "135 Train Loss 0.0053181686 Test MSE 0.0006901879827580483 Test RE 0.012557169511759288\n",
      "136 Train Loss 0.005209647 Test MSE 0.0007507312543518203 Test RE 0.013096351072568449\n",
      "137 Train Loss 0.0051185293 Test MSE 0.0007024322799182335 Test RE 0.012668065226735288\n",
      "138 Train Loss 0.0050618043 Test MSE 0.0006727928101228879 Test RE 0.012397917187057366\n",
      "139 Train Loss 0.004968694 Test MSE 0.0006467395583775884 Test RE 0.012155498474454945\n",
      "140 Train Loss 0.0049283924 Test MSE 0.0006242603337425446 Test RE 0.011942381218358476\n",
      "141 Train Loss 0.0048949127 Test MSE 0.0006307980404942611 Test RE 0.012004752979785057\n",
      "142 Train Loss 0.0048519885 Test MSE 0.0006189256241661984 Test RE 0.01189124403594601\n",
      "143 Train Loss 0.0047820397 Test MSE 0.0005771614399302928 Test RE 0.011483035683619233\n",
      "144 Train Loss 0.004684855 Test MSE 0.0005613974906884303 Test RE 0.011325132552950444\n",
      "145 Train Loss 0.0045043197 Test MSE 0.0005608497355270668 Test RE 0.011319606242436199\n",
      "146 Train Loss 0.004403461 Test MSE 0.0005101767607589703 Test RE 0.01079613723106367\n",
      "147 Train Loss 0.0043567643 Test MSE 0.000508271392389376 Test RE 0.010775958086978716\n",
      "148 Train Loss 0.0043344377 Test MSE 0.0005455586457842813 Test RE 0.011164230169392234\n",
      "149 Train Loss 0.0043192892 Test MSE 0.0005465860887290802 Test RE 0.011174737943469518\n",
      "Training time: 230.27\n",
      "8\n",
      "KG_rowdy_tune68\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.23\n",
      "0\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 72.92986 Test MSE 4.385784872185137 Test RE 1.000994572947742\n",
      "1 Train Loss 69.43683 Test MSE 4.54066437376541 Test RE 1.0185157782879986\n",
      "2 Train Loss 57.18489 Test MSE 5.703857532544256 Test RE 1.1415433146933247\n",
      "3 Train Loss 46.546585 Test MSE 7.136885043478304 Test RE 1.2769162417436057\n",
      "4 Train Loss 35.35545 Test MSE 6.716916939268417 Test RE 1.2387767600563813\n",
      "5 Train Loss 28.676136 Test MSE 6.483893210582352 Test RE 1.2170992281101134\n",
      "6 Train Loss 24.263975 Test MSE 6.121702689179083 Test RE 1.1826171617426016\n",
      "7 Train Loss 22.154972 Test MSE 6.22937416323045 Test RE 1.1929720504333647\n",
      "8 Train Loss 20.366825 Test MSE 6.277523155186208 Test RE 1.19757362298781\n",
      "9 Train Loss 18.9873 Test MSE 6.551158088587211 Test RE 1.2233961237341742\n",
      "10 Train Loss 17.75961 Test MSE 6.647270133089356 Test RE 1.2323376704420173\n",
      "11 Train Loss 16.724895 Test MSE 7.050282201808645 Test RE 1.2691451974614547\n",
      "12 Train Loss 15.534315 Test MSE 6.830724081331408 Test RE 1.2492271999261606\n",
      "13 Train Loss 14.775646 Test MSE 6.5672999988691245 Test RE 1.2249024070916963\n",
      "14 Train Loss 14.268396 Test MSE 6.572640235278929 Test RE 1.2254003239835043\n",
      "15 Train Loss 13.694095 Test MSE 6.532347400646084 Test RE 1.2216384599962107\n",
      "16 Train Loss 13.000949 Test MSE 6.525913013000514 Test RE 1.2210366524421508\n",
      "17 Train Loss 12.39764 Test MSE 6.541136324211031 Test RE 1.222460008311194\n",
      "18 Train Loss 11.345054 Test MSE 6.124930773467539 Test RE 1.1829289283322904\n",
      "19 Train Loss 10.730457 Test MSE 5.886181749536728 Test RE 1.159644557797647\n",
      "20 Train Loss 10.251005 Test MSE 5.606377800205409 Test RE 1.131746709584651\n",
      "21 Train Loss 9.466403 Test MSE 5.804889300231318 Test RE 1.1516089497291928\n",
      "22 Train Loss 8.998445 Test MSE 5.8949980448904595 Test RE 1.1605126879325807\n",
      "23 Train Loss 8.691597 Test MSE 5.906300687613248 Test RE 1.1616246966964205\n",
      "24 Train Loss 8.418406 Test MSE 5.79752186882031 Test RE 1.1508779199652057\n",
      "25 Train Loss 8.189305 Test MSE 5.7562229767437705 Test RE 1.1467714299523346\n",
      "26 Train Loss 7.8939934 Test MSE 5.708174874914481 Test RE 1.1419752593064085\n",
      "27 Train Loss 7.5558023 Test MSE 5.671597169244675 Test RE 1.1383105181709214\n",
      "28 Train Loss 7.0507336 Test MSE 5.558632528110189 Test RE 1.1269172908413922\n",
      "29 Train Loss 6.416381 Test MSE 5.05583231635231 Test RE 1.0747424206531728\n",
      "30 Train Loss 5.593647 Test MSE 4.933146268838319 Test RE 1.0616223586804947\n",
      "31 Train Loss 4.6540103 Test MSE 5.082950654367494 Test RE 1.0776209032437993\n",
      "32 Train Loss 4.166884 Test MSE 4.995563512059749 Test RE 1.0683174018712693\n",
      "33 Train Loss 3.6718326 Test MSE 4.98033800017767 Test RE 1.06668814704936\n",
      "34 Train Loss 3.4223185 Test MSE 5.0042117975909175 Test RE 1.069241733900251\n",
      "35 Train Loss 3.2979665 Test MSE 5.085390875065216 Test RE 1.0778795440883282\n",
      "36 Train Loss 3.1730947 Test MSE 5.108441922081388 Test RE 1.0803196868947489\n",
      "37 Train Loss 2.9215546 Test MSE 5.148027983929808 Test RE 1.0844973865563265\n",
      "38 Train Loss 2.8402283 Test MSE 5.143649829118452 Test RE 1.0840361315472853\n",
      "39 Train Loss 2.7037113 Test MSE 5.130370672720326 Test RE 1.0826359207409726\n",
      "40 Train Loss 2.6391783 Test MSE 5.211348869480052 Test RE 1.0911466762503068\n",
      "41 Train Loss 2.5528102 Test MSE 5.317289227102007 Test RE 1.10218171581777\n",
      "42 Train Loss 2.4696476 Test MSE 5.313842870420467 Test RE 1.1018244729773654\n",
      "43 Train Loss 2.3298278 Test MSE 5.190427417793881 Test RE 1.0889542179432548\n",
      "44 Train Loss 2.2582242 Test MSE 5.235601690094965 Test RE 1.0936827439331436\n",
      "45 Train Loss 2.2120712 Test MSE 5.249518494258005 Test RE 1.09513534369139\n",
      "46 Train Loss 2.1098185 Test MSE 5.314233031922394 Test RE 1.101864922197544\n",
      "47 Train Loss 2.0538294 Test MSE 5.302986849055103 Test RE 1.1006984003995384\n",
      "48 Train Loss 2.0310192 Test MSE 5.279833272919701 Test RE 1.0982928708638702\n",
      "49 Train Loss 1.9709193 Test MSE 5.320239868563407 Test RE 1.1024874817719543\n",
      "50 Train Loss 1.9345739 Test MSE 5.382206018159403 Test RE 1.1088893668411488\n",
      "51 Train Loss 1.9064231 Test MSE 5.360292743573542 Test RE 1.1066296817881713\n",
      "52 Train Loss 1.8532083 Test MSE 5.449017247178319 Test RE 1.1157506577762488\n",
      "53 Train Loss 1.823658 Test MSE 5.460096945210003 Test RE 1.1168844312680488\n",
      "54 Train Loss 1.8044033 Test MSE 5.452205043649787 Test RE 1.1160769795514351\n",
      "55 Train Loss 1.7853332 Test MSE 5.4079599664745786 Test RE 1.1115392280571341\n",
      "56 Train Loss 1.7490326 Test MSE 5.406988030267238 Test RE 1.1114393388407313\n",
      "57 Train Loss 1.7165439 Test MSE 5.418220341678309 Test RE 1.1125931749447893\n",
      "58 Train Loss 1.6883157 Test MSE 5.431336593434336 Test RE 1.1139390256431505\n",
      "59 Train Loss 1.650391 Test MSE 5.484636202891322 Test RE 1.1193914187639848\n",
      "60 Train Loss 1.632689 Test MSE 5.476738475965994 Test RE 1.118585181824347\n",
      "61 Train Loss 1.61356 Test MSE 5.493780905278875 Test RE 1.1203242279464398\n",
      "62 Train Loss 1.6001735 Test MSE 5.503924250397752 Test RE 1.1213579963991378\n",
      "63 Train Loss 1.582161 Test MSE 5.547348737920894 Test RE 1.1257729124399591\n",
      "64 Train Loss 1.5673487 Test MSE 5.543977089103473 Test RE 1.1254307410697433\n",
      "65 Train Loss 1.5550466 Test MSE 5.576809505429012 Test RE 1.1287583220120831\n",
      "66 Train Loss 1.5439239 Test MSE 5.565276198230952 Test RE 1.1275905347515176\n",
      "67 Train Loss 1.5322585 Test MSE 5.5864613793980515 Test RE 1.1297346798427168\n",
      "68 Train Loss 1.5102234 Test MSE 5.572412261905734 Test RE 1.1283132284508501\n",
      "69 Train Loss 1.4965216 Test MSE 5.579829925557433 Test RE 1.1290639504230937\n",
      "70 Train Loss 1.4673257 Test MSE 5.567502016515429 Test RE 1.1278160007160285\n",
      "71 Train Loss 1.4498702 Test MSE 5.556885958466105 Test RE 1.1267402334306609\n",
      "72 Train Loss 1.4382408 Test MSE 5.556623215651557 Test RE 1.1267135956337098\n",
      "73 Train Loss 1.4254776 Test MSE 5.576879838672872 Test RE 1.1287654397900828\n",
      "74 Train Loss 1.4133995 Test MSE 5.5924464565292125 Test RE 1.1303396906629815\n",
      "75 Train Loss 1.3983102 Test MSE 5.620167078207936 Test RE 1.1331376598873373\n",
      "76 Train Loss 1.3878163 Test MSE 5.6348246167332565 Test RE 1.1346143236228128\n",
      "77 Train Loss 1.3764088 Test MSE 5.641740295915123 Test RE 1.135310372134062\n",
      "78 Train Loss 1.3656827 Test MSE 5.668123918795844 Test RE 1.1379619176902063\n",
      "79 Train Loss 1.344581 Test MSE 5.643137124915033 Test RE 1.1354509082295\n",
      "80 Train Loss 1.3315457 Test MSE 5.6394996046317285 Test RE 1.1350848980289665\n",
      "81 Train Loss 1.3240083 Test MSE 5.613419580621094 Test RE 1.13245724062468\n",
      "82 Train Loss 1.3180655 Test MSE 5.600936554317532 Test RE 1.1311973703091864\n",
      "83 Train Loss 1.3082565 Test MSE 5.620260025375065 Test RE 1.1331470298489894\n",
      "84 Train Loss 1.2947278 Test MSE 5.5971637441762425 Test RE 1.1308163169075576\n",
      "85 Train Loss 1.2884713 Test MSE 5.595831580970154 Test RE 1.1306817378953091\n",
      "86 Train Loss 1.2841556 Test MSE 5.598773522504252 Test RE 1.130978920041486\n",
      "87 Train Loss 1.2779647 Test MSE 5.590086906102142 Test RE 1.1301012105180916\n",
      "88 Train Loss 1.2684712 Test MSE 5.613092784031669 Test RE 1.132424275999015\n",
      "89 Train Loss 1.260238 Test MSE 5.619293798365834 Test RE 1.1330496211595158\n",
      "90 Train Loss 1.2519817 Test MSE 5.643705843312402 Test RE 1.13550812246491\n",
      "91 Train Loss 1.2415464 Test MSE 5.644335354414253 Test RE 1.1355714492095428\n",
      "92 Train Loss 1.228768 Test MSE 5.653186052996826 Test RE 1.1364614267769821\n",
      "93 Train Loss 1.2167714 Test MSE 5.670589053849818 Test RE 1.1382093474317625\n",
      "94 Train Loss 1.2065911 Test MSE 5.689945567513986 Test RE 1.140150327044425\n",
      "95 Train Loss 1.1994634 Test MSE 5.7064263754639954 Test RE 1.1418003438484357\n",
      "96 Train Loss 1.1947899 Test MSE 5.694248346993884 Test RE 1.1405813406868148\n",
      "97 Train Loss 1.1851008 Test MSE 5.716076491645645 Test RE 1.142765383160774\n",
      "98 Train Loss 1.1774768 Test MSE 5.728491524294091 Test RE 1.1440057247043103\n",
      "99 Train Loss 1.172636 Test MSE 5.740569841273651 Test RE 1.1452111369728197\n",
      "100 Train Loss 1.1692225 Test MSE 5.760752555122893 Test RE 1.147222539093667\n",
      "101 Train Loss 1.1649308 Test MSE 5.752026659296305 Test RE 1.1463533524793084\n",
      "102 Train Loss 1.1607333 Test MSE 5.765627169599318 Test RE 1.147707812938698\n",
      "103 Train Loss 1.153954 Test MSE 5.77707398307693 Test RE 1.1488465514179147\n",
      "104 Train Loss 1.1507773 Test MSE 5.791671751228818 Test RE 1.1502971140072464\n",
      "105 Train Loss 1.1466112 Test MSE 5.799908419428839 Test RE 1.1511147751128066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 1.1431789 Test MSE 5.803163419868737 Test RE 1.151437741724858\n",
      "107 Train Loss 1.1408558 Test MSE 5.808350704287794 Test RE 1.1519522456672808\n",
      "108 Train Loss 1.1354144 Test MSE 5.8044668371451165 Test RE 1.1515670435792305\n",
      "109 Train Loss 1.1299963 Test MSE 5.8314029931149856 Test RE 1.1542359266346842\n",
      "110 Train Loss 1.1265426 Test MSE 5.841744428471616 Test RE 1.1552589367818253\n",
      "111 Train Loss 1.1212363 Test MSE 5.860339031398737 Test RE 1.1570961032609741\n",
      "112 Train Loss 1.1177311 Test MSE 5.878355967758457 Test RE 1.1588734175213766\n",
      "113 Train Loss 1.1128391 Test MSE 5.895244611295295 Test RE 1.160536957698832\n",
      "114 Train Loss 1.1066 Test MSE 5.907515750392074 Test RE 1.1617441770972845\n",
      "115 Train Loss 1.1009225 Test MSE 5.885677794046791 Test RE 1.1595949142616946\n",
      "116 Train Loss 1.0994637 Test MSE 5.887351639287253 Test RE 1.1597597928462184\n",
      "117 Train Loss 1.0961864 Test MSE 5.878817284941415 Test RE 1.1589188892259719\n",
      "118 Train Loss 1.093444 Test MSE 5.883355310823309 Test RE 1.1593661041264198\n",
      "119 Train Loss 1.0887798 Test MSE 5.868568742464518 Test RE 1.1579082769039526\n",
      "120 Train Loss 1.0855769 Test MSE 5.874449343148318 Test RE 1.1584882727742085\n",
      "121 Train Loss 1.0816473 Test MSE 5.87141432714257 Test RE 1.1581889694268788\n",
      "122 Train Loss 1.0752436 Test MSE 5.893625377136003 Test RE 1.1603775656579312\n",
      "123 Train Loss 1.0715699 Test MSE 5.8946806916305015 Test RE 1.1604814498016465\n",
      "124 Train Loss 1.065044 Test MSE 5.902437019573088 Test RE 1.161244690099866\n",
      "125 Train Loss 1.0609301 Test MSE 5.924974108708701 Test RE 1.16345954987179\n",
      "126 Train Loss 1.055663 Test MSE 5.9058267262209645 Test RE 1.1615780874621988\n",
      "127 Train Loss 1.0524163 Test MSE 5.91507816992108 Test RE 1.1624875341473306\n",
      "128 Train Loss 1.0483052 Test MSE 5.927942336115583 Test RE 1.1637509418723846\n",
      "129 Train Loss 1.0433931 Test MSE 5.934889536249222 Test RE 1.164432666060714\n",
      "130 Train Loss 1.0400869 Test MSE 5.956992599488966 Test RE 1.1665989751314518\n",
      "131 Train Loss 1.0340812 Test MSE 5.939036112144541 Test RE 1.164839376692336\n",
      "132 Train Loss 1.0313473 Test MSE 5.9427556215657535 Test RE 1.1652040783715736\n",
      "133 Train Loss 1.025447 Test MSE 5.956368312414162 Test RE 1.1665378443064944\n",
      "134 Train Loss 1.0218899 Test MSE 5.951544846153005 Test RE 1.1660654175493488\n",
      "135 Train Loss 1.0178968 Test MSE 5.950996919714738 Test RE 1.1660117396561591\n",
      "136 Train Loss 1.0118526 Test MSE 5.945986150104455 Test RE 1.165520742377441\n",
      "137 Train Loss 1.0071946 Test MSE 5.960239885020152 Test RE 1.1669169009792442\n",
      "138 Train Loss 1.0039401 Test MSE 5.9521739290554345 Test RE 1.1661270429300714\n",
      "139 Train Loss 0.99785596 Test MSE 5.9760465758683745 Test RE 1.1684632214329662\n",
      "140 Train Loss 0.99237853 Test MSE 5.963268642054924 Test RE 1.1672133537190972\n",
      "141 Train Loss 0.98924017 Test MSE 5.971178630414303 Test RE 1.1679872232996436\n",
      "142 Train Loss 0.98731947 Test MSE 5.963104622884543 Test RE 1.1671973015592945\n",
      "143 Train Loss 0.9853207 Test MSE 5.972493577408422 Test RE 1.1681158207540774\n",
      "144 Train Loss 0.98159873 Test MSE 5.973559475654824 Test RE 1.1682200516788572\n",
      "145 Train Loss 0.97895455 Test MSE 5.969639513476201 Test RE 1.1678366847807178\n",
      "146 Train Loss 0.97657895 Test MSE 5.9632548042666516 Test RE 1.1672119994567285\n",
      "147 Train Loss 0.9726198 Test MSE 5.959589449040962 Test RE 1.1668532269107263\n",
      "148 Train Loss 0.96863854 Test MSE 5.94520403545857 Test RE 1.1654440855540078\n",
      "149 Train Loss 0.9650066 Test MSE 5.9645798861780674 Test RE 1.1673416740763836\n",
      "Training time: 230.18\n",
      "1\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 66.65143 Test MSE 6.21154602157785 Test RE 1.1912637155931396\n",
      "1 Train Loss 52.889557 Test MSE 8.573112101051171 Test RE 1.3995142071350077\n",
      "2 Train Loss 44.300476 Test MSE 9.135872628681112 Test RE 1.444717981821796\n",
      "3 Train Loss 40.019432 Test MSE 9.662058143255047 Test RE 1.485740231702482\n",
      "4 Train Loss 37.061676 Test MSE 9.009295207131348 Test RE 1.4346747970218803\n",
      "5 Train Loss 33.29683 Test MSE 8.741446439298374 Test RE 1.4131872507239691\n",
      "6 Train Loss 31.103703 Test MSE 8.730876232494179 Test RE 1.4123325752413929\n",
      "7 Train Loss 28.360678 Test MSE 8.515569830338857 Test RE 1.3948095672009728\n",
      "8 Train Loss 26.133358 Test MSE 8.60899536116338 Test RE 1.4024400229090364\n",
      "9 Train Loss 24.681904 Test MSE 8.869815515831876 Test RE 1.4235258362607734\n",
      "10 Train Loss 24.0191 Test MSE 8.705162135911817 Test RE 1.410251247162389\n",
      "11 Train Loss 23.097609 Test MSE 9.145923404822284 Test RE 1.4455124623348805\n",
      "12 Train Loss 22.591305 Test MSE 9.209769249820484 Test RE 1.4505491030255142\n",
      "13 Train Loss 22.015991 Test MSE 9.371547782032273 Test RE 1.4632337919704153\n",
      "14 Train Loss 21.53794 Test MSE 9.33086919646881 Test RE 1.4600546472726728\n",
      "15 Train Loss 21.279762 Test MSE 9.32346943002385 Test RE 1.4594755904867198\n",
      "16 Train Loss 20.915588 Test MSE 9.274965862232648 Test RE 1.4556743187817658\n",
      "17 Train Loss 20.49981 Test MSE 9.30846744758518 Test RE 1.4583009289502782\n",
      "18 Train Loss 20.128069 Test MSE 9.36360468964821 Test RE 1.4626135601121815\n",
      "19 Train Loss 19.849056 Test MSE 9.268057888638317 Test RE 1.4551321263370784\n",
      "20 Train Loss 19.514927 Test MSE 9.505768333624053 Test RE 1.4736748546264986\n",
      "21 Train Loss 19.30199 Test MSE 9.361656349861336 Test RE 1.4624613849329298\n",
      "22 Train Loss 19.049381 Test MSE 9.306232449590684 Test RE 1.4581258466751374\n",
      "23 Train Loss 17.93677 Test MSE 8.1691968215102 Test RE 1.366147966859093\n",
      "24 Train Loss 15.529652 Test MSE 8.05846067328481 Test RE 1.3568570818015349\n",
      "25 Train Loss 14.494303 Test MSE 8.070173139083408 Test RE 1.3578427769884716\n",
      "26 Train Loss 13.930543 Test MSE 7.8657181848253614 Test RE 1.3405322034281997\n",
      "27 Train Loss 13.377482 Test MSE 7.604349391069949 Test RE 1.318071870567282\n",
      "28 Train Loss 12.659953 Test MSE 7.276426385063802 Test RE 1.2893390321997173\n",
      "29 Train Loss 11.927015 Test MSE 7.024474353265191 Test RE 1.2668201886645876\n",
      "30 Train Loss 11.402222 Test MSE 6.755916808920838 Test RE 1.2423678575637809\n",
      "31 Train Loss 10.768795 Test MSE 6.503429049561798 Test RE 1.2189313967436164\n",
      "32 Train Loss 10.302582 Test MSE 6.377846549326977 Test RE 1.2071051234315116\n",
      "33 Train Loss 9.986271 Test MSE 6.364665699308725 Test RE 1.2058571394557502\n",
      "34 Train Loss 9.6755085 Test MSE 6.324916862853815 Test RE 1.2020858110906012\n",
      "35 Train Loss 9.161762 Test MSE 6.2685294675947425 Test RE 1.1967154450693998\n",
      "36 Train Loss 8.813503 Test MSE 6.211540076834682 Test RE 1.191263145545159\n",
      "37 Train Loss 8.4549 Test MSE 6.1945654514080815 Test RE 1.1896343160380785\n",
      "38 Train Loss 8.27893 Test MSE 6.167345640748849 Test RE 1.1870177263971577\n",
      "39 Train Loss 8.08927 Test MSE 6.231582196229072 Test RE 1.1931834591725663\n",
      "40 Train Loss 7.899194 Test MSE 6.343716195974861 Test RE 1.203870944783332\n",
      "41 Train Loss 7.798701 Test MSE 6.3256111274070355 Test RE 1.2021517837101678\n",
      "42 Train Loss 7.6961527 Test MSE 6.244577853847749 Test RE 1.1944269738440008\n",
      "43 Train Loss 7.5201206 Test MSE 6.233632393081431 Test RE 1.1933797223143146\n",
      "44 Train Loss 7.402708 Test MSE 6.170578034126236 Test RE 1.1873287520675442\n",
      "45 Train Loss 7.291763 Test MSE 6.1680359388473205 Test RE 1.1870841547441382\n",
      "46 Train Loss 7.11119 Test MSE 6.164834273844945 Test RE 1.186776022693463\n",
      "47 Train Loss 7.002785 Test MSE 6.156200141226331 Test RE 1.1859446644282214\n",
      "48 Train Loss 6.9009647 Test MSE 6.129490574388317 Test RE 1.183369171421755\n",
      "49 Train Loss 6.8047924 Test MSE 6.162565486043713 Test RE 1.1865576234132007\n",
      "50 Train Loss 6.5963607 Test MSE 6.113443768967984 Test RE 1.1818191454255778\n",
      "51 Train Loss 6.4472313 Test MSE 6.108434781137578 Test RE 1.1813348904783638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 6.1745863 Test MSE 6.047320066688663 Test RE 1.1754104238817533\n",
      "53 Train Loss 5.598668 Test MSE 5.844784729076737 Test RE 1.1555595214456313\n",
      "54 Train Loss 5.038412 Test MSE 5.807355541044888 Test RE 1.1518535576146558\n",
      "55 Train Loss 4.6578403 Test MSE 5.717183350274286 Test RE 1.1428760201072834\n",
      "56 Train Loss 3.8008997 Test MSE 5.3854224591632525 Test RE 1.1092206570693606\n",
      "57 Train Loss 3.3961842 Test MSE 5.40610845080506 Test RE 1.111348933704702\n",
      "58 Train Loss 3.0651357 Test MSE 5.521069840960906 Test RE 1.1231032416287905\n",
      "59 Train Loss 2.7940013 Test MSE 5.66477875155652 Test RE 1.1376260715800286\n",
      "60 Train Loss 2.59782 Test MSE 5.596809075941992 Test RE 1.1307804888526398\n",
      "61 Train Loss 2.4332829 Test MSE 5.5954028057197 Test RE 1.1306384183613234\n",
      "62 Train Loss 2.313681 Test MSE 5.496837693773878 Test RE 1.1206358637791676\n",
      "63 Train Loss 2.2449577 Test MSE 5.561770309286818 Test RE 1.1272353115934\n",
      "64 Train Loss 2.1191328 Test MSE 5.644780089415296 Test RE 1.1356161859579936\n",
      "65 Train Loss 2.0629654 Test MSE 5.696013053601456 Test RE 1.1407580659878265\n",
      "66 Train Loss 2.0278387 Test MSE 5.681147924687134 Test RE 1.1392685509796892\n",
      "67 Train Loss 1.9727957 Test MSE 5.641978051338101 Test RE 1.13533429412797\n",
      "68 Train Loss 1.9287626 Test MSE 5.6087660559362265 Test RE 1.1319877397890958\n",
      "69 Train Loss 1.8951354 Test MSE 5.622254077118445 Test RE 1.1333480306403194\n",
      "70 Train Loss 1.8623304 Test MSE 5.571584656345313 Test RE 1.1282294377214497\n",
      "71 Train Loss 1.8378904 Test MSE 5.577032273013599 Test RE 1.1287808661077448\n",
      "72 Train Loss 1.8112707 Test MSE 5.556544520342158 Test RE 1.1267056171020093\n",
      "73 Train Loss 1.7825242 Test MSE 5.587991094008317 Test RE 1.1298893442393734\n",
      "74 Train Loss 1.7686224 Test MSE 5.583455114103295 Test RE 1.1294306645666419\n",
      "75 Train Loss 1.7488158 Test MSE 5.620223705483188 Test RE 1.1331433684664278\n",
      "76 Train Loss 1.7308857 Test MSE 5.636076099113994 Test RE 1.1347403143233517\n",
      "77 Train Loss 1.6992166 Test MSE 5.713216987222741 Test RE 1.1424795094979656\n",
      "78 Train Loss 1.6893626 Test MSE 5.686863329027427 Test RE 1.1398414760002857\n",
      "79 Train Loss 1.677496 Test MSE 5.694871773763725 Test RE 1.1406437764497208\n",
      "80 Train Loss 1.6579069 Test MSE 5.6831356421382 Test RE 1.1394678369308286\n",
      "81 Train Loss 1.6404861 Test MSE 5.693837447896257 Test RE 1.1405401875556078\n",
      "82 Train Loss 1.6208609 Test MSE 5.684779772539029 Test RE 1.1396326489600488\n",
      "83 Train Loss 1.6044037 Test MSE 5.7161513638661186 Test RE 1.1427728674116986\n",
      "84 Train Loss 1.5976114 Test MSE 5.703711546274687 Test RE 1.1415287060959458\n",
      "85 Train Loss 1.5901394 Test MSE 5.71225938121473 Test RE 1.1423837586195638\n",
      "86 Train Loss 1.5796325 Test MSE 5.730753378649068 Test RE 1.1442315536986127\n",
      "87 Train Loss 1.5680664 Test MSE 5.7308428672858875 Test RE 1.1442404875433834\n",
      "88 Train Loss 1.5613848 Test MSE 5.747019768756489 Test RE 1.1458543183412124\n",
      "89 Train Loss 1.5400784 Test MSE 5.772395024823759 Test RE 1.1483812212248172\n",
      "90 Train Loss 1.5247071 Test MSE 5.730663482896289 Test RE 1.1442225791403418\n",
      "91 Train Loss 1.5169003 Test MSE 5.713705285953057 Test RE 1.1425283313242312\n",
      "92 Train Loss 1.5027702 Test MSE 5.712983407807134 Test RE 1.1424561546678933\n",
      "93 Train Loss 1.4940312 Test MSE 5.724932823548684 Test RE 1.1436503251644372\n",
      "94 Train Loss 1.4899067 Test MSE 5.738982280958606 Test RE 1.1450527713819607\n",
      "95 Train Loss 1.4855474 Test MSE 5.735057284860393 Test RE 1.144661143028605\n",
      "96 Train Loss 1.4806125 Test MSE 5.76110771181418 Test RE 1.1472579023103313\n",
      "97 Train Loss 1.4761157 Test MSE 5.766302437652073 Test RE 1.1477750205213486\n",
      "98 Train Loss 1.469728 Test MSE 5.777563009032786 Test RE 1.1488951749854635\n",
      "99 Train Loss 1.4643394 Test MSE 5.791569959945387 Test RE 1.1502870054635417\n",
      "100 Train Loss 1.4592003 Test MSE 5.808455096997287 Test RE 1.1519625975625023\n",
      "101 Train Loss 1.449074 Test MSE 5.824795924778237 Test RE 1.1535818578793713\n",
      "102 Train Loss 1.4394498 Test MSE 5.820680909685372 Test RE 1.1531743032188915\n",
      "103 Train Loss 1.4321344 Test MSE 5.842087815267856 Test RE 1.15529289023875\n",
      "104 Train Loss 1.4272056 Test MSE 5.818977306192784 Test RE 1.1530055346874377\n",
      "105 Train Loss 1.4236072 Test MSE 5.800861193918872 Test RE 1.1512093203775946\n",
      "106 Train Loss 1.4164655 Test MSE 5.822524452255383 Test RE 1.153356907079672\n",
      "107 Train Loss 1.4091376 Test MSE 5.8331200391633455 Test RE 1.1544058454664432\n",
      "108 Train Loss 1.4012393 Test MSE 5.833662849676852 Test RE 1.1544595567777456\n",
      "109 Train Loss 1.3927082 Test MSE 5.8364681189270735 Test RE 1.1547370994412949\n",
      "110 Train Loss 1.3861032 Test MSE 5.831423354321422 Test RE 1.1542379417256916\n",
      "111 Train Loss 1.3812181 Test MSE 5.830437719146156 Test RE 1.1541403921633433\n",
      "112 Train Loss 1.3746483 Test MSE 5.856399524660151 Test RE 1.1567071194323446\n",
      "113 Train Loss 1.3643669 Test MSE 5.860373943930058 Test RE 1.1570995499125727\n",
      "114 Train Loss 1.3563817 Test MSE 5.899955173685114 Test RE 1.161000525412389\n",
      "115 Train Loss 1.3502101 Test MSE 5.896618755787949 Test RE 1.1606722067557949\n",
      "116 Train Loss 1.3446684 Test MSE 5.897205622113082 Test RE 1.1607299637953343\n",
      "117 Train Loss 1.3353412 Test MSE 5.9058593381430144 Test RE 1.1615812945696455\n",
      "118 Train Loss 1.3305776 Test MSE 5.926077733399219 Test RE 1.163567901644729\n",
      "119 Train Loss 1.3193599 Test MSE 5.902484370357523 Test RE 1.161249347984104\n",
      "120 Train Loss 1.3128359 Test MSE 5.92199059244936 Test RE 1.1631665833954317\n",
      "121 Train Loss 1.3049518 Test MSE 5.938002059583513 Test RE 1.1647379665011937\n",
      "122 Train Loss 1.2967907 Test MSE 5.925723435937234 Test RE 1.1635331184934756\n",
      "123 Train Loss 1.2882413 Test MSE 5.900791737370427 Test RE 1.1610828325167017\n",
      "124 Train Loss 1.2818083 Test MSE 5.921489321170279 Test RE 1.1631173538052384\n",
      "125 Train Loss 1.2748779 Test MSE 5.932918565342507 Test RE 1.1642392965403305\n",
      "126 Train Loss 1.2717719 Test MSE 5.940195416242853 Test RE 1.1649530598847178\n",
      "127 Train Loss 1.2683669 Test MSE 5.939010399611518 Test RE 1.164836855154936\n",
      "128 Train Loss 1.2637507 Test MSE 5.947757451100693 Test RE 1.1656943329535767\n",
      "129 Train Loss 1.2579975 Test MSE 5.93260443001083 Test RE 1.164208474143663\n",
      "130 Train Loss 1.2539268 Test MSE 5.946443933484529 Test RE 1.165565608421715\n",
      "131 Train Loss 1.2474165 Test MSE 5.971778756150258 Test RE 1.1680459153623406\n",
      "132 Train Loss 1.2418193 Test MSE 5.996254858946355 Test RE 1.170437160818748\n",
      "133 Train Loss 1.2357041 Test MSE 5.979707243035427 Test RE 1.1688210416127696\n",
      "134 Train Loss 1.2272356 Test MSE 5.988921969287051 Test RE 1.169721271290383\n",
      "135 Train Loss 1.2200803 Test MSE 6.000098072679755 Test RE 1.1708121882097244\n",
      "136 Train Loss 1.2105308 Test MSE 5.991706099407122 Test RE 1.1699931297182895\n",
      "137 Train Loss 1.2026398 Test MSE 5.9978419457595 Test RE 1.1705920460368744\n",
      "138 Train Loss 1.195499 Test MSE 6.016664679749319 Test RE 1.1724274130830703\n",
      "139 Train Loss 1.1885943 Test MSE 6.00310061040995 Test RE 1.1711050974294575\n",
      "140 Train Loss 1.1817589 Test MSE 5.981007301044615 Test RE 1.168948092362289\n",
      "141 Train Loss 1.1751792 Test MSE 5.998444206447563 Test RE 1.1706508158311217\n",
      "142 Train Loss 1.1671929 Test MSE 6.011090021848411 Test RE 1.1718841389665833\n",
      "143 Train Loss 1.1619985 Test MSE 6.040355779011961 Test RE 1.1747334087425652\n",
      "144 Train Loss 1.159306 Test MSE 6.05469345249463 Test RE 1.1761267837110603\n",
      "145 Train Loss 1.1510673 Test MSE 6.0838410816376385 Test RE 1.1789543544683156\n",
      "146 Train Loss 1.1423291 Test MSE 6.073312321945896 Test RE 1.1779337572784037\n",
      "147 Train Loss 1.1318616 Test MSE 6.061894056464325 Test RE 1.176825936099393\n",
      "148 Train Loss 1.1250396 Test MSE 6.068762134133649 Test RE 1.1774924145788968\n",
      "149 Train Loss 1.1196018 Test MSE 6.073573904818843 Test RE 1.1779591243237881\n",
      "Training time: 230.86\n",
      "2\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 61.505657 Test MSE 6.5598876007971 Test RE 1.2242109488327648\n",
      "1 Train Loss 47.80747 Test MSE 8.664420484067131 Test RE 1.4069472679747232\n",
      "2 Train Loss 36.517414 Test MSE 7.4302458042744135 Test RE 1.302895700265104\n",
      "3 Train Loss 25.367971 Test MSE 6.7027238504542215 Test RE 1.2374672778602898\n",
      "4 Train Loss 21.178734 Test MSE 6.204127875468848 Test RE 1.1905521690447862\n",
      "5 Train Loss 17.714184 Test MSE 5.870562638176941 Test RE 1.1581049647489052\n",
      "6 Train Loss 15.636663 Test MSE 5.683887509032759 Test RE 1.1395432090373552\n",
      "7 Train Loss 13.666342 Test MSE 5.517082421374061 Test RE 1.1226976053246058\n",
      "8 Train Loss 11.282526 Test MSE 5.1397422740186345 Test RE 1.083624290164776\n",
      "9 Train Loss 9.826484 Test MSE 4.5145088148750325 Test RE 1.0155780668153809\n",
      "10 Train Loss 8.663704 Test MSE 4.320614728249026 Test RE 0.9935296473025134\n",
      "11 Train Loss 7.5136223 Test MSE 3.990254386801108 Test RE 0.9547910780692023\n",
      "12 Train Loss 6.836418 Test MSE 4.029189687366409 Test RE 0.959438003915158\n",
      "13 Train Loss 6.3322124 Test MSE 3.965618678442449 Test RE 0.9518390892075795\n",
      "14 Train Loss 5.8848896 Test MSE 3.7996118895376747 Test RE 0.931703397714731\n",
      "15 Train Loss 5.5123777 Test MSE 3.5907063169893596 Test RE 0.9057284364205651\n",
      "16 Train Loss 5.203972 Test MSE 3.617970210548463 Test RE 0.909160489117511\n",
      "17 Train Loss 4.822596 Test MSE 3.4393382350899238 Test RE 0.8864321603583795\n",
      "18 Train Loss 4.474495 Test MSE 3.2650657731621924 Test RE 0.8636823159964968\n",
      "19 Train Loss 4.08949 Test MSE 3.143004843628645 Test RE 0.8473846358494959\n",
      "20 Train Loss 3.7318048 Test MSE 2.9363348300501224 Test RE 0.8190508183860015\n",
      "21 Train Loss 3.4293084 Test MSE 2.8983657282711945 Test RE 0.8137381048596701\n",
      "22 Train Loss 3.2379868 Test MSE 2.8431959742450754 Test RE 0.8059562324773005\n",
      "23 Train Loss 3.0363858 Test MSE 2.6783326245728056 Test RE 0.7822405333038911\n",
      "24 Train Loss 2.8574548 Test MSE 2.661363444994778 Test RE 0.7797585652497836\n",
      "25 Train Loss 2.7031052 Test MSE 2.54073942262836 Test RE 0.7618827196469372\n",
      "26 Train Loss 2.5330777 Test MSE 2.5173617076484183 Test RE 0.7583695224513947\n",
      "27 Train Loss 2.3897743 Test MSE 2.4028749656621073 Test RE 0.7409239726710348\n",
      "28 Train Loss 2.268391 Test MSE 2.328543330332347 Test RE 0.729373906365348\n",
      "29 Train Loss 2.173154 Test MSE 2.3340443804084003 Test RE 0.730234950135826\n",
      "30 Train Loss 2.0801618 Test MSE 2.1584492985609165 Test RE 0.7022293646394749\n",
      "31 Train Loss 2.0042152 Test MSE 2.139477806730967 Test RE 0.6991364632004784\n",
      "32 Train Loss 1.9470229 Test MSE 2.134651766618851 Test RE 0.6983474936961717\n",
      "33 Train Loss 1.8586366 Test MSE 2.086175303959714 Test RE 0.690372462956923\n",
      "34 Train Loss 1.7882609 Test MSE 2.0472375660532074 Test RE 0.6838993348223529\n",
      "35 Train Loss 1.6889412 Test MSE 1.9067718162153797 Test RE 0.6600204962298946\n",
      "36 Train Loss 1.6131885 Test MSE 1.8966326447931199 Test RE 0.6582633429068054\n",
      "37 Train Loss 1.5529596 Test MSE 1.8053085533181195 Test RE 0.6422199318943077\n",
      "38 Train Loss 1.5013471 Test MSE 1.6811518376727188 Test RE 0.6197428573030808\n",
      "39 Train Loss 1.4333495 Test MSE 1.5420271923073265 Test RE 0.5935455815481994\n",
      "40 Train Loss 1.3450173 Test MSE 1.4607238050373195 Test RE 0.5776863605110029\n",
      "41 Train Loss 1.3065684 Test MSE 1.4523774656247894 Test RE 0.576033593032967\n",
      "42 Train Loss 1.2671028 Test MSE 1.3639126774894754 Test RE 0.5582147955740102\n",
      "43 Train Loss 1.1990197 Test MSE 1.376895377332501 Test RE 0.560865247833104\n",
      "44 Train Loss 1.1220016 Test MSE 1.3307134336764894 Test RE 0.5513791389555853\n",
      "45 Train Loss 1.074369 Test MSE 1.280158587396214 Test RE 0.5408040648030618\n",
      "46 Train Loss 1.0347862 Test MSE 1.2144306937557814 Test RE 0.526737730054611\n",
      "47 Train Loss 0.9747202 Test MSE 1.0730362128176643 Test RE 0.49512544948023157\n",
      "48 Train Loss 0.9369902 Test MSE 1.0520273955807216 Test RE 0.4902544957470743\n",
      "49 Train Loss 0.8939685 Test MSE 1.0087203115774641 Test RE 0.48005770349039184\n",
      "50 Train Loss 0.865809 Test MSE 0.9821836005625632 Test RE 0.47370110686838185\n",
      "51 Train Loss 0.83520234 Test MSE 0.9397132699373145 Test RE 0.4633463434878188\n",
      "52 Train Loss 0.8093434 Test MSE 0.9063629277198847 Test RE 0.4550500087758845\n",
      "53 Train Loss 0.769791 Test MSE 0.8145311878827974 Test RE 0.4313819002475408\n",
      "54 Train Loss 0.72838753 Test MSE 0.7754364615001317 Test RE 0.4209021743160112\n",
      "55 Train Loss 0.7007052 Test MSE 0.7202706302157481 Test RE 0.4056541407581015\n",
      "56 Train Loss 0.6773313 Test MSE 0.7071952538627111 Test RE 0.4019552717897546\n",
      "57 Train Loss 0.63647026 Test MSE 0.6253641682937416 Test RE 0.377984992638701\n",
      "58 Train Loss 0.6114427 Test MSE 0.5943995642839573 Test RE 0.3685083232973179\n",
      "59 Train Loss 0.5669707 Test MSE 0.4950787912111676 Test RE 0.33631421282388196\n",
      "60 Train Loss 0.53252804 Test MSE 0.4300101185146683 Test RE 0.3134349329326237\n",
      "61 Train Loss 0.49818316 Test MSE 0.3362126173037381 Test RE 0.2771501155734321\n",
      "62 Train Loss 0.43866268 Test MSE 0.20437630454405462 Test RE 0.2160843586008652\n",
      "63 Train Loss 0.40648594 Test MSE 0.15265388330961926 Test RE 0.18675059260060195\n",
      "64 Train Loss 0.34554702 Test MSE 0.10339910740103077 Test RE 0.15369737673050357\n",
      "65 Train Loss 0.2625823 Test MSE 0.051536463624583743 Test RE 0.10850890165263448\n",
      "66 Train Loss 0.23255992 Test MSE 0.043254693538852286 Test RE 0.09940876535960416\n",
      "67 Train Loss 0.21411885 Test MSE 0.03744864395756474 Test RE 0.09249667224167482\n",
      "68 Train Loss 0.19479665 Test MSE 0.027918767684475126 Test RE 0.0798649423923981\n",
      "69 Train Loss 0.17967889 Test MSE 0.02544562061484688 Test RE 0.07624556449596337\n",
      "70 Train Loss 0.14581296 Test MSE 0.022080596734592544 Test RE 0.07102536321925218\n",
      "71 Train Loss 0.12999797 Test MSE 0.020972528182516954 Test RE 0.06922029624221669\n",
      "72 Train Loss 0.12098523 Test MSE 0.02016851124239183 Test RE 0.06788049193944444\n",
      "73 Train Loss 0.11209776 Test MSE 0.02027911088394339 Test RE 0.06806635825514248\n",
      "74 Train Loss 0.104186416 Test MSE 0.020410480230481483 Test RE 0.06828647141333116\n",
      "75 Train Loss 0.09708187 Test MSE 0.016802894139506603 Test RE 0.06195838741898561\n",
      "76 Train Loss 0.09229212 Test MSE 0.01577373169928201 Test RE 0.0600309595142895\n",
      "77 Train Loss 0.08905282 Test MSE 0.014824384729181721 Test RE 0.058196437355731157\n",
      "78 Train Loss 0.07609667 Test MSE 0.014979992995972453 Test RE 0.05850107753221827\n",
      "79 Train Loss 0.07223387 Test MSE 0.015460352118968979 Test RE 0.05943164494374719\n",
      "80 Train Loss 0.070749834 Test MSE 0.015468301094822397 Test RE 0.05944692143934401\n",
      "81 Train Loss 0.067288615 Test MSE 0.014964209518086724 Test RE 0.058470249954024944\n",
      "82 Train Loss 0.06216418 Test MSE 0.01230943340024844 Test RE 0.05303066726885254\n",
      "83 Train Loss 0.05862877 Test MSE 0.013122954535585271 Test RE 0.054755011232542075\n",
      "84 Train Loss 0.05619061 Test MSE 0.012417588112501324 Test RE 0.053263130164855906\n",
      "85 Train Loss 0.053429823 Test MSE 0.012113354402045532 Test RE 0.052606604618782096\n",
      "86 Train Loss 0.052203584 Test MSE 0.011619657787594617 Test RE 0.05152342550915081\n",
      "87 Train Loss 0.050817043 Test MSE 0.011780922884566088 Test RE 0.051879731156314425\n",
      "88 Train Loss 0.049435895 Test MSE 0.011339891284458174 Test RE 0.05089938158266609\n",
      "89 Train Loss 0.047302842 Test MSE 0.010968293019797445 Test RE 0.050058471243319094\n",
      "90 Train Loss 0.043941345 Test MSE 0.009840755748631679 Test RE 0.047415713114647526\n",
      "91 Train Loss 0.041419476 Test MSE 0.00883229826148056 Test RE 0.04492053536169078\n",
      "92 Train Loss 0.03947382 Test MSE 0.009097434004254808 Test RE 0.04558978217306935\n",
      "93 Train Loss 0.03810579 Test MSE 0.009044583596110633 Test RE 0.04545716521048972\n",
      "94 Train Loss 0.037228234 Test MSE 0.008294591520461457 Test RE 0.04353169342716978\n",
      "95 Train Loss 0.035767984 Test MSE 0.0072901642471890965 Test RE 0.04081095116412724\n",
      "96 Train Loss 0.032658823 Test MSE 0.007449042275854215 Test RE 0.041253260555752354\n",
      "97 Train Loss 0.029383294 Test MSE 0.007551091759845269 Test RE 0.04153487752368366\n",
      "98 Train Loss 0.0282761 Test MSE 0.006998101902037701 Test RE 0.03998510044605423\n",
      "99 Train Loss 0.027667154 Test MSE 0.007037663501404623 Test RE 0.040097962846772056\n",
      "100 Train Loss 0.027012112 Test MSE 0.007066995668216096 Test RE 0.04018143779248759\n",
      "101 Train Loss 0.026351176 Test MSE 0.007036406383798984 Test RE 0.04009438139489613\n",
      "102 Train Loss 0.025678976 Test MSE 0.006963658093996696 Test RE 0.03988657816259657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 Train Loss 0.025112262 Test MSE 0.006989394402955473 Test RE 0.03996021665600494\n",
      "104 Train Loss 0.02450045 Test MSE 0.007071314212052547 Test RE 0.04019371307940085\n",
      "105 Train Loss 0.023714036 Test MSE 0.006511945713701871 Test RE 0.0385712262406256\n",
      "106 Train Loss 0.023370631 Test MSE 0.006204022695352951 Test RE 0.03764824614027667\n",
      "107 Train Loss 0.022907337 Test MSE 0.00601263995045364 Test RE 0.0370630076585852\n",
      "108 Train Loss 0.022402048 Test MSE 0.005713624972523146 Test RE 0.036129664255581354\n",
      "109 Train Loss 0.021817377 Test MSE 0.005639461357043278 Test RE 0.03589441443413856\n",
      "110 Train Loss 0.02142442 Test MSE 0.005852281890253966 Test RE 0.03656542947245266\n",
      "111 Train Loss 0.020835156 Test MSE 0.005256177893561683 Test RE 0.03465317948189336\n",
      "112 Train Loss 0.020433795 Test MSE 0.005360826452665798 Test RE 0.03499644532611544\n",
      "113 Train Loss 0.019321488 Test MSE 0.004939677343245194 Test RE 0.033593662231813017\n",
      "114 Train Loss 0.018650357 Test MSE 0.004550976647558037 Test RE 0.03224485020835876\n",
      "115 Train Loss 0.018325804 Test MSE 0.004393838680206933 Test RE 0.031683278448606765\n",
      "116 Train Loss 0.018060083 Test MSE 0.004260458049949093 Test RE 0.0311986790924506\n",
      "117 Train Loss 0.01767503 Test MSE 0.004308018235097507 Test RE 0.03137233376446656\n",
      "118 Train Loss 0.016931146 Test MSE 0.0038569273356615585 Test RE 0.029684435104534636\n",
      "119 Train Loss 0.016252913 Test MSE 0.003798386709544898 Test RE 0.029458297860847665\n",
      "120 Train Loss 0.015921526 Test MSE 0.0036710697422123466 Test RE 0.028960388121110688\n",
      "121 Train Loss 0.015360885 Test MSE 0.003512772635573061 Test RE 0.028329119785639064\n",
      "122 Train Loss 0.014832203 Test MSE 0.003660541938267483 Test RE 0.028918832360496614\n",
      "123 Train Loss 0.014307941 Test MSE 0.003621675506104863 Test RE 0.028764897329716294\n",
      "124 Train Loss 0.013895136 Test MSE 0.00346733852746952 Test RE 0.028145319492375698\n",
      "125 Train Loss 0.013660291 Test MSE 0.003568743239347641 Test RE 0.028553918244263635\n",
      "126 Train Loss 0.0132312095 Test MSE 0.0036263995120497843 Test RE 0.028783651254987875\n",
      "127 Train Loss 0.012835225 Test MSE 0.0035404669277531407 Test RE 0.028440572295161497\n",
      "128 Train Loss 0.012531599 Test MSE 0.003484638602495015 Test RE 0.028215446808448074\n",
      "129 Train Loss 0.01204025 Test MSE 0.003283388994282912 Test RE 0.027388561908137522\n",
      "130 Train Loss 0.011704198 Test MSE 0.0031469489039252776 Test RE 0.026813462913808084\n",
      "131 Train Loss 0.011562363 Test MSE 0.00327668921200141 Test RE 0.02736060434588669\n",
      "132 Train Loss 0.011255178 Test MSE 0.0033110155795479856 Test RE 0.027503544853517418\n",
      "133 Train Loss 0.011117489 Test MSE 0.003381727171311882 Test RE 0.027795682596784884\n",
      "134 Train Loss 0.011005861 Test MSE 0.0032759429159707116 Test RE 0.02735748835412001\n",
      "135 Train Loss 0.010947814 Test MSE 0.0032319402420383546 Test RE 0.027173133431283764\n",
      "136 Train Loss 0.01082516 Test MSE 0.0032713152905752187 Test RE 0.027338158812693733\n",
      "137 Train Loss 0.010677898 Test MSE 0.0033845732296902452 Test RE 0.027807376546946667\n",
      "138 Train Loss 0.010508939 Test MSE 0.003407838008647566 Test RE 0.027902783635688235\n",
      "139 Train Loss 0.010303221 Test MSE 0.00351529544145181 Test RE 0.02833929067485696\n",
      "140 Train Loss 0.010129884 Test MSE 0.0032306626184021537 Test RE 0.027167761972248024\n",
      "141 Train Loss 0.010087622 Test MSE 0.0032271633314060032 Test RE 0.027153044627155083\n",
      "142 Train Loss 0.009898294 Test MSE 0.003133146415503492 Test RE 0.02675459649737172\n",
      "143 Train Loss 0.009569942 Test MSE 0.002937736870768906 Test RE 0.025906843839194192\n",
      "144 Train Loss 0.009300073 Test MSE 0.002838269246888517 Test RE 0.025464482581064523\n",
      "145 Train Loss 0.0092008095 Test MSE 0.0026589866187249037 Test RE 0.024647117537628396\n",
      "146 Train Loss 0.009101858 Test MSE 0.002614389594790553 Test RE 0.024439550472155284\n",
      "147 Train Loss 0.008996842 Test MSE 0.0025611839507706357 Test RE 0.024189586589422357\n",
      "148 Train Loss 0.008929435 Test MSE 0.0024593626562300756 Test RE 0.023703874953610884\n",
      "149 Train Loss 0.008853813 Test MSE 0.002427943661929788 Test RE 0.02355197669131366\n",
      "Training time: 228.42\n",
      "3\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 69.21727 Test MSE 5.228546441512721 Test RE 1.0929455980102931\n",
      "1 Train Loss 55.22747 Test MSE 7.552655621686892 Test RE 1.3135841562979818\n",
      "2 Train Loss 42.11349 Test MSE 8.962403638884522 Test RE 1.4309363294024806\n",
      "3 Train Loss 38.717976 Test MSE 8.87697844582439 Test RE 1.4241005132717686\n",
      "4 Train Loss 34.351505 Test MSE 8.703601351726515 Test RE 1.4101248166330482\n",
      "5 Train Loss 31.957634 Test MSE 8.544215800731179 Test RE 1.397153633923187\n",
      "6 Train Loss 29.527403 Test MSE 8.689247273710173 Test RE 1.4089615398962094\n",
      "7 Train Loss 27.344015 Test MSE 8.61557858117496 Test RE 1.4029761369673812\n",
      "8 Train Loss 25.620323 Test MSE 8.592364621313692 Test RE 1.4010847608168688\n",
      "9 Train Loss 24.415 Test MSE 8.587667090167596 Test RE 1.4007017149732475\n",
      "10 Train Loss 23.016418 Test MSE 8.457901847834878 Test RE 1.3900786744025406\n",
      "11 Train Loss 21.962177 Test MSE 8.732853954827611 Test RE 1.4124925273149576\n",
      "12 Train Loss 21.122393 Test MSE 8.944438982884098 Test RE 1.4295014925778753\n",
      "13 Train Loss 20.50776 Test MSE 9.003813335831053 Test RE 1.4342382534780158\n",
      "14 Train Loss 19.79095 Test MSE 8.95044236510377 Test RE 1.4299811428018663\n",
      "15 Train Loss 19.449993 Test MSE 8.935722213875808 Test RE 1.4288047651655802\n",
      "16 Train Loss 18.813843 Test MSE 8.87363138595118 Test RE 1.4238320097993624\n",
      "17 Train Loss 18.110245 Test MSE 8.671348186571239 Test RE 1.4075096232184303\n",
      "18 Train Loss 17.351007 Test MSE 8.52858726344425 Test RE 1.3958752566953543\n",
      "19 Train Loss 16.64158 Test MSE 8.444106500366733 Test RE 1.3889445607296036\n",
      "20 Train Loss 15.821413 Test MSE 8.196612280352355 Test RE 1.368438412521221\n",
      "21 Train Loss 15.134084 Test MSE 7.961465142613025 Test RE 1.3486664665504096\n",
      "22 Train Loss 14.320509 Test MSE 8.013575987218859 Test RE 1.3530730374268976\n",
      "23 Train Loss 13.303024 Test MSE 7.883240767751935 Test RE 1.342024535003676\n",
      "24 Train Loss 11.948942 Test MSE 7.613810989582071 Test RE 1.3188916113093845\n",
      "25 Train Loss 11.0210285 Test MSE 7.2621022540739615 Test RE 1.2880693320498686\n",
      "26 Train Loss 9.995832 Test MSE 6.601488509876368 Test RE 1.2280866097714738\n",
      "27 Train Loss 9.240799 Test MSE 5.840156533116522 Test RE 1.155101915621694\n",
      "28 Train Loss 8.671921 Test MSE 5.705631155044421 Test RE 1.1417207831458165\n",
      "29 Train Loss 7.9088087 Test MSE 5.62955707168948 Test RE 1.1340838697147324\n",
      "30 Train Loss 7.380562 Test MSE 5.4500342181172865 Test RE 1.115854771325983\n",
      "31 Train Loss 6.88777 Test MSE 5.399627573335732 Test RE 1.1106825878266011\n",
      "32 Train Loss 6.2263575 Test MSE 5.357019446944319 Test RE 1.1062917449861471\n",
      "33 Train Loss 5.722637 Test MSE 5.24525013822882 Test RE 1.0946900287423358\n",
      "34 Train Loss 5.06159 Test MSE 5.059326352686379 Test RE 1.0751137285074555\n",
      "35 Train Loss 4.658218 Test MSE 4.978357688241167 Test RE 1.066476054487003\n",
      "36 Train Loss 4.1889668 Test MSE 5.244043852192503 Test RE 1.094564144829144\n",
      "37 Train Loss 3.8686404 Test MSE 5.178294296446838 Test RE 1.0876807058639881\n",
      "38 Train Loss 3.629299 Test MSE 5.154347760887248 Test RE 1.0851628529699373\n",
      "39 Train Loss 3.4839308 Test MSE 5.111288335211833 Test RE 1.080620620913098\n",
      "40 Train Loss 3.3218455 Test MSE 5.187884742435846 Test RE 1.0886874580007104\n",
      "41 Train Loss 3.155344 Test MSE 5.162530935914276 Test RE 1.0860239275622696\n",
      "42 Train Loss 3.067256 Test MSE 5.091584676834006 Test RE 1.0785357513298468\n",
      "43 Train Loss 2.937665 Test MSE 5.03414212162984 Test RE 1.0724345485838638\n",
      "44 Train Loss 2.839298 Test MSE 5.062968410422544 Test RE 1.075500630000581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 Train Loss 2.7309318 Test MSE 5.084806892784702 Test RE 1.0778176530123122\n",
      "46 Train Loss 2.652198 Test MSE 5.077083052718808 Test RE 1.0769987374530805\n",
      "47 Train Loss 2.586334 Test MSE 5.11423262879451 Test RE 1.0809318150869818\n",
      "48 Train Loss 2.5367095 Test MSE 5.112108057389843 Test RE 1.0807072696324003\n",
      "49 Train Loss 2.4384942 Test MSE 5.180125119136925 Test RE 1.087872967487117\n",
      "50 Train Loss 2.3536313 Test MSE 5.221321369311192 Test RE 1.0921901929643854\n",
      "51 Train Loss 2.310886 Test MSE 5.232413470673517 Test RE 1.0933496941930936\n",
      "52 Train Loss 2.2603178 Test MSE 5.232265873931561 Test RE 1.093334273394295\n",
      "53 Train Loss 2.2072208 Test MSE 5.201554979997348 Test RE 1.090120876992859\n",
      "54 Train Loss 2.1744225 Test MSE 5.221059538735345 Test RE 1.0921628079068393\n",
      "55 Train Loss 2.1199422 Test MSE 5.191360434813723 Test RE 1.0890520872594567\n",
      "56 Train Loss 2.0821273 Test MSE 5.203273454154321 Test RE 1.0903009375574746\n",
      "57 Train Loss 2.0537574 Test MSE 5.213150379407673 Test RE 1.0913352590689542\n",
      "58 Train Loss 2.0269194 Test MSE 5.198180431140426 Test RE 1.0897672074644316\n",
      "59 Train Loss 1.9834278 Test MSE 5.209124856149656 Test RE 1.0909138206328062\n",
      "60 Train Loss 1.9462161 Test MSE 5.173811589143077 Test RE 1.0872098162598254\n",
      "61 Train Loss 1.909116 Test MSE 5.160046709792237 Test RE 1.085762597055528\n",
      "62 Train Loss 1.8777611 Test MSE 5.127290053934215 Test RE 1.0823108283074168\n",
      "63 Train Loss 1.8339701 Test MSE 5.163274695307593 Test RE 1.0861021558011965\n",
      "64 Train Loss 1.8084594 Test MSE 5.2130587207298555 Test RE 1.091325664986747\n",
      "65 Train Loss 1.7899026 Test MSE 5.216516970004937 Test RE 1.0916875878698327\n",
      "66 Train Loss 1.7659445 Test MSE 5.220826548192418 Test RE 1.0921384386727193\n",
      "67 Train Loss 1.7437129 Test MSE 5.187289731910978 Test RE 1.0886250241666053\n",
      "68 Train Loss 1.7164514 Test MSE 5.180414139864196 Test RE 1.0879033155427589\n",
      "69 Train Loss 1.7034488 Test MSE 5.212375602750802 Test RE 1.091254159115917\n",
      "70 Train Loss 1.683994 Test MSE 5.214596058951916 Test RE 1.0914865698483547\n",
      "71 Train Loss 1.6648599 Test MSE 5.249404791678507 Test RE 1.0951234835190828\n",
      "72 Train Loss 1.6547791 Test MSE 5.261870279714828 Test RE 1.0964229788527802\n",
      "73 Train Loss 1.6356549 Test MSE 5.241415948129874 Test RE 1.0942898555504692\n",
      "74 Train Loss 1.6141391 Test MSE 5.220900056207362 Test RE 1.0921461271723605\n",
      "75 Train Loss 1.5933789 Test MSE 5.23788370343395 Test RE 1.0939210667525334\n",
      "76 Train Loss 1.5799559 Test MSE 5.265806679894366 Test RE 1.0968330186762536\n",
      "77 Train Loss 1.5554233 Test MSE 5.297378462882726 Test RE 1.10011620258428\n",
      "78 Train Loss 1.5356468 Test MSE 5.309957656085494 Test RE 1.1014216000369712\n",
      "79 Train Loss 1.5245156 Test MSE 5.302470821360223 Test RE 1.1006448452340447\n",
      "80 Train Loss 1.511572 Test MSE 5.322702847081569 Test RE 1.1027426477845197\n",
      "81 Train Loss 1.4926245 Test MSE 5.362995853755844 Test RE 1.1069086744735999\n",
      "82 Train Loss 1.4809512 Test MSE 5.355966663671501 Test RE 1.1061830331657665\n",
      "83 Train Loss 1.4683468 Test MSE 5.362048605503813 Test RE 1.1068109153443022\n",
      "84 Train Loss 1.4577163 Test MSE 5.354286984124005 Test RE 1.1060095650665314\n",
      "85 Train Loss 1.4489942 Test MSE 5.355300183076377 Test RE 1.106114205957788\n",
      "86 Train Loss 1.4335352 Test MSE 5.329111824375208 Test RE 1.1034063450284677\n",
      "87 Train Loss 1.4254103 Test MSE 5.333380180143603 Test RE 1.1038481436156264\n",
      "88 Train Loss 1.4149408 Test MSE 5.307687328693996 Test RE 1.1011861127567215\n",
      "89 Train Loss 1.405615 Test MSE 5.332765973041707 Test RE 1.1037845806529931\n",
      "90 Train Loss 1.3947465 Test MSE 5.336287593986903 Test RE 1.1041489759211098\n",
      "91 Train Loss 1.3836641 Test MSE 5.365799857640748 Test RE 1.1071980062871352\n",
      "92 Train Loss 1.374355 Test MSE 5.386365485204967 Test RE 1.1093177690588096\n",
      "93 Train Loss 1.3647114 Test MSE 5.383390390645057 Test RE 1.1090113675419884\n",
      "94 Train Loss 1.3515534 Test MSE 5.395281453731615 Test RE 1.1102355078168689\n",
      "95 Train Loss 1.338536 Test MSE 5.38397313476791 Test RE 1.1090713903455773\n",
      "96 Train Loss 1.3308749 Test MSE 5.414990337222529 Test RE 1.1122614962359518\n",
      "97 Train Loss 1.3245599 Test MSE 5.3808486607935215 Test RE 1.1087495306796609\n",
      "98 Train Loss 1.3182015 Test MSE 5.405467870468087 Test RE 1.111283088802493\n",
      "99 Train Loss 1.3071282 Test MSE 5.388125739764368 Test RE 1.1094990157787934\n",
      "100 Train Loss 1.301438 Test MSE 5.417579870222072 Test RE 1.1125274148625697\n",
      "101 Train Loss 1.2965631 Test MSE 5.411108336788597 Test RE 1.1118627352524582\n",
      "102 Train Loss 1.2903838 Test MSE 5.423237744127255 Test RE 1.1131081997706795\n",
      "103 Train Loss 1.2843446 Test MSE 5.4256916574198355 Test RE 1.1133600015744542\n",
      "104 Train Loss 1.2758517 Test MSE 5.399407532220065 Test RE 1.1106599567911857\n",
      "105 Train Loss 1.2669691 Test MSE 5.411806992523261 Test RE 1.1119345120636923\n",
      "106 Train Loss 1.2618484 Test MSE 5.406881360428478 Test RE 1.111428375468967\n",
      "107 Train Loss 1.2579266 Test MSE 5.410713555787899 Test RE 1.1118221751433024\n",
      "108 Train Loss 1.2495909 Test MSE 5.4209713123778815 Test RE 1.1128755852778738\n",
      "109 Train Loss 1.2443882 Test MSE 5.436228091798964 Test RE 1.114440523254942\n",
      "110 Train Loss 1.2381794 Test MSE 5.443138406475512 Test RE 1.115148614304931\n",
      "111 Train Loss 1.2334907 Test MSE 5.464660046095868 Test RE 1.1173510339706731\n",
      "112 Train Loss 1.2290854 Test MSE 5.480312139938983 Test RE 1.1189500701328512\n",
      "113 Train Loss 1.2240574 Test MSE 5.484471306038866 Test RE 1.1193745912569082\n",
      "114 Train Loss 1.2201484 Test MSE 5.481392838235919 Test RE 1.119060391205384\n",
      "115 Train Loss 1.2145691 Test MSE 5.499859704887124 Test RE 1.1209438689349795\n",
      "116 Train Loss 1.2070317 Test MSE 5.476494323419518 Test RE 1.118560248329201\n",
      "117 Train Loss 1.2013799 Test MSE 5.487786178824879 Test RE 1.1197128211110818\n",
      "118 Train Loss 1.1968147 Test MSE 5.487341901762749 Test RE 1.119667495657874\n",
      "119 Train Loss 1.1920183 Test MSE 5.513660410055917 Test RE 1.1223493705564007\n",
      "120 Train Loss 1.1866626 Test MSE 5.514654319360978 Test RE 1.1224505250647516\n",
      "121 Train Loss 1.182661 Test MSE 5.508013024600508 Test RE 1.121774438216735\n",
      "122 Train Loss 1.178658 Test MSE 5.515208388014633 Test RE 1.1225069111040866\n",
      "123 Train Loss 1.1749336 Test MSE 5.517768447757458 Test RE 1.1227674045570346\n",
      "124 Train Loss 1.1711879 Test MSE 5.526100973875329 Test RE 1.1236148449202688\n",
      "125 Train Loss 1.1678011 Test MSE 5.53377826955183 Test RE 1.124395081240486\n",
      "126 Train Loss 1.1651492 Test MSE 5.542348709707487 Test RE 1.1252654479245183\n",
      "127 Train Loss 1.16296 Test MSE 5.555296330729882 Test RE 1.1265790617195044\n",
      "128 Train Loss 1.1605015 Test MSE 5.54038660384348 Test RE 1.1250662466928887\n",
      "129 Train Loss 1.1576914 Test MSE 5.548089615854682 Test RE 1.1258480864106473\n",
      "130 Train Loss 1.1538379 Test MSE 5.548287766633301 Test RE 1.1258681911402488\n",
      "131 Train Loss 1.1497016 Test MSE 5.574042613508238 Test RE 1.128478274813333\n",
      "132 Train Loss 1.1441555 Test MSE 5.589544468438361 Test RE 1.1300463791404738\n",
      "133 Train Loss 1.1402993 Test MSE 5.59098826049289 Test RE 1.1301923164926024\n",
      "134 Train Loss 1.1371183 Test MSE 5.585644573768786 Test RE 1.1296520866485702\n",
      "135 Train Loss 1.1332831 Test MSE 5.57537868927185 Test RE 1.1286135125786982\n",
      "136 Train Loss 1.1289862 Test MSE 5.568926459406248 Test RE 1.127960267097663\n",
      "137 Train Loss 1.1262279 Test MSE 5.579518517171659 Test RE 1.1290324436484487\n",
      "138 Train Loss 1.1225859 Test MSE 5.598634144189878 Test RE 1.1309648424121712\n",
      "139 Train Loss 1.117672 Test MSE 5.594403423307765 Test RE 1.1305374434496565\n",
      "140 Train Loss 1.1136749 Test MSE 5.6114649540662045 Test RE 1.1322600592374905\n",
      "141 Train Loss 1.110913 Test MSE 5.6271156137656915 Test RE 1.133837925115633\n",
      "142 Train Loss 1.1080754 Test MSE 5.633114665753959 Test RE 1.1344421548139272\n",
      "143 Train Loss 1.106321 Test MSE 5.6430079617814 Test RE 1.135437913752017\n",
      "144 Train Loss 1.1042603 Test MSE 5.6447120926011465 Test RE 1.1356093461419101\n",
      "145 Train Loss 1.1017505 Test MSE 5.632742957880732 Test RE 1.134404725428747\n",
      "146 Train Loss 1.0986527 Test MSE 5.624055961003452 Test RE 1.1335296302200375\n",
      "147 Train Loss 1.0942914 Test MSE 5.632277235392598 Test RE 1.1343578274328523\n",
      "148 Train Loss 1.0894816 Test MSE 5.638491417885652 Test RE 1.1349834325816355\n",
      "149 Train Loss 1.0864474 Test MSE 5.648914688105479 Test RE 1.1360320088640756\n",
      "Training time: 229.84\n",
      "4\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 58.65153 Test MSE 7.52873229441983 Test RE 1.3115020920582934\n",
      "1 Train Loss 49.0903 Test MSE 6.996527928088316 Test RE 1.2642976954291998\n",
      "2 Train Loss 40.65938 Test MSE 7.6425983350146005 Test RE 1.3213825825232128\n",
      "3 Train Loss 32.738136 Test MSE 7.801467336255925 Test RE 1.3350459312406615\n",
      "4 Train Loss 25.633244 Test MSE 6.304100169604469 Test RE 1.2001060162960313\n",
      "5 Train Loss 22.859379 Test MSE 6.645514805941406 Test RE 1.2321749496146226\n",
      "6 Train Loss 19.640638 Test MSE 6.462887163327089 Test RE 1.2151260937788033\n",
      "7 Train Loss 15.973734 Test MSE 6.303776560611138 Test RE 1.2000752133207055\n",
      "8 Train Loss 12.74456 Test MSE 6.245239652986007 Test RE 1.194490264735565\n",
      "9 Train Loss 11.671165 Test MSE 5.897612940060951 Test RE 1.1607700487112813\n",
      "10 Train Loss 10.559646 Test MSE 5.744438115389759 Test RE 1.145596921371133\n",
      "11 Train Loss 9.6821165 Test MSE 5.538882009654941 Test RE 1.1249134700728844\n",
      "12 Train Loss 8.944482 Test MSE 5.358885346417786 Test RE 1.1064843940411557\n",
      "13 Train Loss 8.454704 Test MSE 5.288123311425022 Test RE 1.0991547654115656\n",
      "14 Train Loss 7.8350563 Test MSE 5.187864081867652 Test RE 1.0886852901688309\n",
      "15 Train Loss 7.2741766 Test MSE 5.071393240277707 Test RE 1.0763950799412583\n",
      "16 Train Loss 6.4538174 Test MSE 4.6857172080870795 Test RE 1.0346562786852096\n",
      "17 Train Loss 6.0591507 Test MSE 4.580751435507308 Test RE 1.023001860301358\n",
      "18 Train Loss 5.5205226 Test MSE 4.540415734934293 Test RE 1.0184878918358613\n",
      "19 Train Loss 5.047559 Test MSE 4.347202537376905 Test RE 0.9965819053825801\n",
      "20 Train Loss 4.552516 Test MSE 4.181422466564038 Test RE 0.9773949357502899\n",
      "21 Train Loss 4.169352 Test MSE 4.071428372252456 Test RE 0.9644538690217903\n",
      "22 Train Loss 3.878579 Test MSE 3.900491008993925 Test RE 0.9439906676424704\n",
      "23 Train Loss 3.651041 Test MSE 3.9148169949418397 Test RE 0.9457226549955924\n",
      "24 Train Loss 3.3611631 Test MSE 3.5977925211112805 Test RE 0.906621716542986\n",
      "25 Train Loss 3.2071571 Test MSE 3.5692150307737434 Test RE 0.9030138614913615\n",
      "26 Train Loss 3.0346758 Test MSE 3.4527146806682496 Test RE 0.8881542656146514\n",
      "27 Train Loss 2.9271224 Test MSE 3.32646454772296 Test RE 0.87176516282695\n",
      "28 Train Loss 2.7656913 Test MSE 3.252932623425519 Test RE 0.862076078783924\n",
      "29 Train Loss 2.6280437 Test MSE 3.0725356803399335 Test RE 0.8378311975153582\n",
      "30 Train Loss 2.487369 Test MSE 2.9461834437679983 Test RE 0.8204232372411148\n",
      "31 Train Loss 2.4115877 Test MSE 2.996439617442434 Test RE 0.827391062856615\n",
      "32 Train Loss 2.2570825 Test MSE 2.8828904012051573 Test RE 0.8115627897190852\n",
      "33 Train Loss 2.1704707 Test MSE 2.8250999110659087 Test RE 0.8033873072511797\n",
      "34 Train Loss 2.0669928 Test MSE 2.6834609630136814 Test RE 0.7829890728422644\n",
      "35 Train Loss 2.0166876 Test MSE 2.7006552406716193 Test RE 0.7854935688248595\n",
      "36 Train Loss 1.9437456 Test MSE 2.6893982338416853 Test RE 0.7838547924593835\n",
      "37 Train Loss 1.8807149 Test MSE 2.608866532019599 Test RE 0.772029669817583\n",
      "38 Train Loss 1.8344319 Test MSE 2.565736136905824 Test RE 0.7656213855787007\n",
      "39 Train Loss 1.7793373 Test MSE 2.5232245817735497 Test RE 0.7592521209392731\n",
      "40 Train Loss 1.7114463 Test MSE 2.4981762785932853 Test RE 0.755474135513448\n",
      "41 Train Loss 1.6795968 Test MSE 2.4650927501305766 Test RE 0.7504550639435114\n",
      "42 Train Loss 1.6308049 Test MSE 2.3859568526497297 Test RE 0.738311024056156\n",
      "43 Train Loss 1.579497 Test MSE 2.2706294696805807 Test RE 0.7202465643576564\n",
      "44 Train Loss 1.545216 Test MSE 2.214699352798489 Test RE 0.7113207040148238\n",
      "45 Train Loss 1.5187418 Test MSE 2.1849942388638692 Test RE 0.7065342317842763\n",
      "46 Train Loss 1.4799063 Test MSE 2.1638227293528844 Test RE 0.7031029166304323\n",
      "47 Train Loss 1.4467709 Test MSE 2.101375800321513 Test RE 0.6928830280578049\n",
      "48 Train Loss 1.40877 Test MSE 2.0458074417737655 Test RE 0.6836604197280255\n",
      "49 Train Loss 1.3834852 Test MSE 2.038764373761166 Test RE 0.6824825918268541\n",
      "50 Train Loss 1.3428154 Test MSE 1.9887266288203824 Test RE 0.6740554193601949\n",
      "51 Train Loss 1.3181912 Test MSE 1.943010035354664 Test RE 0.6662628253008887\n",
      "52 Train Loss 1.284868 Test MSE 1.883433633421496 Test RE 0.6559688568651888\n",
      "53 Train Loss 1.2630775 Test MSE 1.839329450092583 Test RE 0.6482429802560157\n",
      "54 Train Loss 1.241051 Test MSE 1.684756294665377 Test RE 0.620406878347683\n",
      "55 Train Loss 1.2057271 Test MSE 1.6251891618500665 Test RE 0.6093404640690503\n",
      "56 Train Loss 1.1554252 Test MSE 1.418078184635029 Test RE 0.5691911623037584\n",
      "57 Train Loss 1.1152996 Test MSE 1.4093716312999627 Test RE 0.567441144813159\n",
      "58 Train Loss 1.0705948 Test MSE 1.351564671109696 Test RE 0.5556821877864678\n",
      "59 Train Loss 1.021727 Test MSE 1.3866139911599973 Test RE 0.5628411597880645\n",
      "60 Train Loss 0.99123716 Test MSE 1.2974585660280669 Test RE 0.5444459970994183\n",
      "61 Train Loss 0.94072646 Test MSE 1.2347182356925182 Test RE 0.5311191877289914\n",
      "62 Train Loss 0.91551274 Test MSE 1.224513597112824 Test RE 0.5289198501791694\n",
      "63 Train Loss 0.8739387 Test MSE 1.1385139807530906 Test RE 0.5100083003895324\n",
      "64 Train Loss 0.8419344 Test MSE 1.0821154823937955 Test RE 0.49721573693870913\n",
      "65 Train Loss 0.82028526 Test MSE 1.0769388395182036 Test RE 0.4960250165368383\n",
      "66 Train Loss 0.80195004 Test MSE 1.080539454960948 Test RE 0.49685352459330223\n",
      "67 Train Loss 0.78251374 Test MSE 1.0542477954423828 Test RE 0.4907715864842524\n",
      "68 Train Loss 0.7302501 Test MSE 0.9090736928177165 Test RE 0.4557299862453627\n",
      "69 Train Loss 0.6896396 Test MSE 0.7995691060502621 Test RE 0.4274015206210568\n",
      "70 Train Loss 0.65454084 Test MSE 0.6946298165423735 Test RE 0.39836829867846285\n",
      "71 Train Loss 0.6269705 Test MSE 0.663671949488103 Test RE 0.38938999758241283\n",
      "72 Train Loss 0.5992465 Test MSE 0.6390018611203637 Test RE 0.38208423761750093\n",
      "73 Train Loss 0.55629295 Test MSE 0.5755292821847541 Test RE 0.3626116664500557\n",
      "74 Train Loss 0.507916 Test MSE 0.5312966369675203 Test RE 0.3483987544680671\n",
      "75 Train Loss 0.4745599 Test MSE 0.4735586844608332 Test RE 0.32892354555808845\n",
      "76 Train Loss 0.44244516 Test MSE 0.4725653631074604 Test RE 0.3285783947827343\n",
      "77 Train Loss 0.40989992 Test MSE 0.4651347968930637 Test RE 0.32598489399101\n",
      "78 Train Loss 0.38010952 Test MSE 0.4190185397880033 Test RE 0.30940311361362843\n",
      "79 Train Loss 0.35550508 Test MSE 0.3868381027118727 Test RE 0.29728478495617056\n",
      "80 Train Loss 0.32712156 Test MSE 0.3352419383844799 Test RE 0.2767497465567177\n",
      "81 Train Loss 0.30613798 Test MSE 0.3403012264591426 Test RE 0.27883020461082697\n",
      "82 Train Loss 0.29632884 Test MSE 0.3351640758965325 Test RE 0.27671760607445706\n",
      "83 Train Loss 0.27236956 Test MSE 0.2765267619090608 Test RE 0.25134870057585207\n",
      "84 Train Loss 0.2514822 Test MSE 0.18358418062319862 Test RE 0.20479798910681024\n",
      "85 Train Loss 0.24018839 Test MSE 0.15116768246896292 Test RE 0.18583929009302663\n",
      "86 Train Loss 0.22312999 Test MSE 0.12222075520109558 Test RE 0.16710157438933376\n",
      "87 Train Loss 0.20258571 Test MSE 0.06756927911834183 Test RE 0.12424608216128806\n",
      "88 Train Loss 0.19110954 Test MSE 0.05263772717120167 Test RE 0.10966211676594502\n",
      "89 Train Loss 0.17343128 Test MSE 0.051945009206026974 Test RE 0.108938144558008\n",
      "90 Train Loss 0.16266131 Test MSE 0.04327740073103685 Test RE 0.0994348549880694\n",
      "91 Train Loss 0.15160574 Test MSE 0.038358315110663205 Test RE 0.09361335745390302\n",
      "92 Train Loss 0.13794008 Test MSE 0.041425000825808085 Test RE 0.09728353050732262\n",
      "93 Train Loss 0.124578044 Test MSE 0.033398258570012274 Test RE 0.08735142046035098\n",
      "94 Train Loss 0.11631392 Test MSE 0.030627649342172464 Test RE 0.08364979738756415\n",
      "95 Train Loss 0.1104894 Test MSE 0.03188796876853799 Test RE 0.08535353022975682\n",
      "96 Train Loss 0.10499629 Test MSE 0.029752561420279603 Test RE 0.08244612348791601\n",
      "97 Train Loss 0.10154548 Test MSE 0.02891745127816294 Test RE 0.08128081816792607\n",
      "98 Train Loss 0.09673607 Test MSE 0.02549210269306939 Test RE 0.07631517245175945\n",
      "99 Train Loss 0.091418006 Test MSE 0.02706872816606385 Test RE 0.07863972491801695\n",
      "100 Train Loss 0.08780974 Test MSE 0.026019394228234127 Test RE 0.07710040350326847\n",
      "101 Train Loss 0.0825061 Test MSE 0.023489277093744803 Test RE 0.07325594681017851\n",
      "102 Train Loss 0.078733414 Test MSE 0.024139407731103645 Test RE 0.0742628078026475\n",
      "103 Train Loss 0.07245823 Test MSE 0.022277056504013928 Test RE 0.07134063382164188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 Train Loss 0.06867643 Test MSE 0.01908467745455812 Test RE 0.06603139501361513\n",
      "105 Train Loss 0.06629129 Test MSE 0.018708843261265363 Test RE 0.06537798460991963\n",
      "106 Train Loss 0.060963936 Test MSE 0.02048218456735242 Test RE 0.0684063153170007\n",
      "107 Train Loss 0.05798175 Test MSE 0.01841419661574393 Test RE 0.0648611206892566\n",
      "108 Train Loss 0.055416245 Test MSE 0.01671732763773138 Test RE 0.06180042864598089\n",
      "109 Train Loss 0.05312324 Test MSE 0.014677003542626682 Test RE 0.05790642584257593\n",
      "110 Train Loss 0.05188957 Test MSE 0.013363868586157584 Test RE 0.055255327642611984\n",
      "111 Train Loss 0.049814045 Test MSE 0.013511374571876848 Test RE 0.05555943584970741\n",
      "112 Train Loss 0.048143405 Test MSE 0.01366525710956888 Test RE 0.05587492638025672\n",
      "113 Train Loss 0.046618994 Test MSE 0.013252585070463943 Test RE 0.05502478580321442\n",
      "114 Train Loss 0.045185328 Test MSE 0.013081165508231636 Test RE 0.054667760180276734\n",
      "115 Train Loss 0.043672483 Test MSE 0.012673722337132093 Test RE 0.05380964840402202\n",
      "116 Train Loss 0.04233753 Test MSE 0.012766416224882279 Test RE 0.05400606814979333\n",
      "117 Train Loss 0.04101297 Test MSE 0.012943370118377021 Test RE 0.054379066167034355\n",
      "118 Train Loss 0.040173694 Test MSE 0.013430652582164379 Test RE 0.05539322082699297\n",
      "119 Train Loss 0.039712712 Test MSE 0.013315591610884903 Test RE 0.055155432407537085\n",
      "120 Train Loss 0.038025588 Test MSE 0.012721599341402653 Test RE 0.053911189854869826\n",
      "121 Train Loss 0.037036754 Test MSE 0.013009791976894525 Test RE 0.05451841691419856\n",
      "122 Train Loss 0.03613777 Test MSE 0.013645616929803059 Test RE 0.05583475925510436\n",
      "123 Train Loss 0.035261374 Test MSE 0.013058829004244248 Test RE 0.05462106677405808\n",
      "124 Train Loss 0.034081876 Test MSE 0.013580347001925615 Test RE 0.055701064344608565\n",
      "125 Train Loss 0.03295465 Test MSE 0.012523431183958777 Test RE 0.05348964642103876\n",
      "126 Train Loss 0.032336473 Test MSE 0.012434667248450534 Test RE 0.05329974660163173\n",
      "127 Train Loss 0.031600133 Test MSE 0.012060960751758134 Test RE 0.05249271218209125\n",
      "128 Train Loss 0.03111102 Test MSE 0.011921765232678634 Test RE 0.05218892400115743\n",
      "129 Train Loss 0.030338626 Test MSE 0.012560280579544279 Test RE 0.05356828354974044\n",
      "130 Train Loss 0.02944096 Test MSE 0.012420536021526122 Test RE 0.053269452066622855\n",
      "131 Train Loss 0.02911945 Test MSE 0.012512136538321653 Test RE 0.05346552033006328\n",
      "132 Train Loss 0.02879343 Test MSE 0.012393126881388924 Test RE 0.05321064316054609\n",
      "133 Train Loss 0.028485268 Test MSE 0.012203720853360089 Test RE 0.052802464447617\n",
      "134 Train Loss 0.028063936 Test MSE 0.011620572095602159 Test RE 0.0515254525634205\n",
      "135 Train Loss 0.027360259 Test MSE 0.010676424778855888 Test RE 0.049387948040322614\n",
      "136 Train Loss 0.026173351 Test MSE 0.010438193603294307 Test RE 0.048833824055020646\n",
      "137 Train Loss 0.02530904 Test MSE 0.010189194770807077 Test RE 0.04824785300349087\n",
      "138 Train Loss 0.02496852 Test MSE 0.010492378664294671 Test RE 0.04896040911204212\n",
      "139 Train Loss 0.02463651 Test MSE 0.01046323913806976 Test RE 0.048892375203903535\n",
      "140 Train Loss 0.02383719 Test MSE 0.010485912616761609 Test RE 0.04894532058294027\n",
      "141 Train Loss 0.023626572 Test MSE 0.010861900013434135 Test RE 0.049815094741247866\n",
      "142 Train Loss 0.023156136 Test MSE 0.010981717604211492 Test RE 0.050089096276326614\n",
      "143 Train Loss 0.022692112 Test MSE 0.011263239129602209 Test RE 0.050727062346975875\n",
      "144 Train Loss 0.022329206 Test MSE 0.011461698088427551 Test RE 0.05117201783267479\n",
      "145 Train Loss 0.021986272 Test MSE 0.011373243653131332 Test RE 0.05097417809052801\n",
      "146 Train Loss 0.021729387 Test MSE 0.011116627479130276 Test RE 0.05039582817989615\n",
      "147 Train Loss 0.021619072 Test MSE 0.010809093111723327 Test RE 0.049693855093776385\n",
      "148 Train Loss 0.021513969 Test MSE 0.010758091485862249 Test RE 0.049576478727843785\n",
      "149 Train Loss 0.021002479 Test MSE 0.010551940149338242 Test RE 0.04909917783079636\n",
      "Training time: 228.25\n",
      "5\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 69.56799 Test MSE 4.655234962029396 Test RE 1.0312853851912616\n",
      "1 Train Loss 53.902306 Test MSE 5.085364285080103 Test RE 1.0778767261300628\n",
      "2 Train Loss 41.737167 Test MSE 6.084176924124565 Test RE 1.178986894560419\n",
      "3 Train Loss 31.752983 Test MSE 5.797044778770849 Test RE 1.1508305649303543\n",
      "4 Train Loss 28.132465 Test MSE 5.414505217687282 Test RE 1.1122116723367321\n",
      "5 Train Loss 23.376348 Test MSE 5.5173451105369855 Test RE 1.1227243329463041\n",
      "6 Train Loss 21.24493 Test MSE 5.482738990418901 Test RE 1.1191977954341215\n",
      "7 Train Loss 19.691793 Test MSE 5.5736052353282926 Test RE 1.128433999814843\n",
      "8 Train Loss 18.459446 Test MSE 5.197523184932742 Test RE 1.0896983114328878\n",
      "9 Train Loss 17.45993 Test MSE 5.257106882967605 Test RE 1.0959265887963527\n",
      "10 Train Loss 16.435244 Test MSE 4.949230233878787 Test RE 1.0633516000977261\n",
      "11 Train Loss 15.504336 Test MSE 4.978247805437618 Test RE 1.0664642847395502\n",
      "12 Train Loss 14.651144 Test MSE 5.321920274923719 Test RE 1.1026615792521994\n",
      "13 Train Loss 14.179607 Test MSE 5.35228163552966 Test RE 1.105802428015075\n",
      "14 Train Loss 13.565105 Test MSE 5.466298267250996 Test RE 1.117518503760204\n",
      "15 Train Loss 12.8513155 Test MSE 5.73374255727081 Test RE 1.1445299321470972\n",
      "16 Train Loss 12.065337 Test MSE 5.731661855440933 Test RE 1.1443222456677338\n",
      "17 Train Loss 11.63855 Test MSE 5.5820435394991 Test RE 1.1292878877029269\n",
      "18 Train Loss 10.4489155 Test MSE 5.169638946121548 Test RE 1.0867713142564894\n",
      "19 Train Loss 9.7577095 Test MSE 5.074691367193894 Test RE 1.0767450341268805\n",
      "20 Train Loss 8.307619 Test MSE 4.449483051577657 Test RE 1.0082374821673639\n",
      "21 Train Loss 7.660025 Test MSE 4.42922541192276 Test RE 1.0059397082853618\n",
      "22 Train Loss 7.164129 Test MSE 4.33212107431554 Test RE 0.9948517155309641\n",
      "23 Train Loss 6.6314178 Test MSE 4.424326861170422 Test RE 1.0053832893343408\n",
      "24 Train Loss 6.3695717 Test MSE 4.436324906255819 Test RE 1.0067455832507881\n",
      "25 Train Loss 5.978454 Test MSE 4.21288075169425 Test RE 0.9810646862895938\n",
      "26 Train Loss 5.0329766 Test MSE 3.6253553953526128 Test RE 0.9100879283899311\n",
      "27 Train Loss 4.6459856 Test MSE 3.6809424656026377 Test RE 0.9170385124971474\n",
      "28 Train Loss 4.3165936 Test MSE 3.7633115833776336 Test RE 0.9272421149752504\n",
      "29 Train Loss 4.1383038 Test MSE 3.682309662457409 Test RE 0.9172088025495593\n",
      "30 Train Loss 3.648528 Test MSE 3.511226317346636 Test RE 0.8956482295681881\n",
      "31 Train Loss 3.525127 Test MSE 3.5829779140279716 Test RE 0.9047531958595234\n",
      "32 Train Loss 3.3405442 Test MSE 3.7166262365638674 Test RE 0.9214727664840203\n",
      "33 Train Loss 3.1602998 Test MSE 3.77272569330263 Test RE 0.9284011615643843\n",
      "34 Train Loss 2.9877412 Test MSE 3.744292977037688 Test RE 0.924896150640661\n",
      "35 Train Loss 2.8915453 Test MSE 3.8634775237840286 Test RE 0.939501018599449\n",
      "36 Train Loss 2.7941914 Test MSE 3.866045879183956 Test RE 0.9398132465870457\n",
      "37 Train Loss 2.7431297 Test MSE 3.8001894129222324 Test RE 0.9317742023219401\n",
      "38 Train Loss 2.6803355 Test MSE 3.8647489119255733 Test RE 0.9396555907684512\n",
      "39 Train Loss 2.6260395 Test MSE 3.903449508179915 Test RE 0.9443486054298412\n",
      "40 Train Loss 2.5522318 Test MSE 3.8993184557306133 Test RE 0.9438487672337174\n",
      "41 Train Loss 2.5176682 Test MSE 3.9089677120477986 Test RE 0.9450158700780987\n",
      "42 Train Loss 2.4366055 Test MSE 3.921618650221945 Test RE 0.946543854039348\n",
      "43 Train Loss 2.376937 Test MSE 3.986123316530398 Test RE 0.9542967072773207\n",
      "44 Train Loss 2.3413997 Test MSE 3.980566317387528 Test RE 0.9536312893924164\n",
      "45 Train Loss 2.281178 Test MSE 4.021579585557075 Test RE 0.9585315100116667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 2.2525797 Test MSE 4.0070279422612245 Test RE 0.9567957680328733\n",
      "47 Train Loss 2.1980095 Test MSE 4.074978855206209 Test RE 0.964874302650981\n",
      "48 Train Loss 2.1270394 Test MSE 4.088595658830409 Test RE 0.9664850529001149\n",
      "49 Train Loss 2.0706027 Test MSE 4.098848805170962 Test RE 0.9676961420686315\n",
      "50 Train Loss 2.0390248 Test MSE 4.1430567004824566 Test RE 0.9729006616630451\n",
      "51 Train Loss 2.006157 Test MSE 4.121525085876402 Test RE 0.9703692685873876\n",
      "52 Train Loss 1.9421535 Test MSE 4.03584596323436 Test RE 0.9602301791596944\n",
      "53 Train Loss 1.9008187 Test MSE 3.918602465425542 Test RE 0.9461797823899006\n",
      "54 Train Loss 1.8573782 Test MSE 3.8854102629274396 Test RE 0.942163991119327\n",
      "55 Train Loss 1.7714739 Test MSE 3.8108557983507536 Test RE 0.9330809396311399\n",
      "56 Train Loss 1.7424724 Test MSE 3.7988397275078616 Test RE 0.9316087219212469\n",
      "57 Train Loss 1.702229 Test MSE 3.7384799578011836 Test RE 0.9241779205900436\n",
      "58 Train Loss 1.6511519 Test MSE 3.639241695149832 Test RE 0.911829230121047\n",
      "59 Train Loss 1.6228333 Test MSE 3.5951921275348235 Test RE 0.9062940156782517\n",
      "60 Train Loss 1.5956749 Test MSE 3.573889218268791 Test RE 0.903604954361277\n",
      "61 Train Loss 1.5488611 Test MSE 3.5182558744175685 Test RE 0.8965443356201747\n",
      "62 Train Loss 1.5024569 Test MSE 3.5083335766591928 Test RE 0.8952792114975965\n",
      "63 Train Loss 1.4817444 Test MSE 3.486735218589322 Test RE 0.8925191527769047\n",
      "64 Train Loss 1.4499036 Test MSE 3.5366219659798617 Test RE 0.8988813717497175\n",
      "65 Train Loss 1.4187982 Test MSE 3.529742471652633 Test RE 0.8980066868785771\n",
      "66 Train Loss 1.3731157 Test MSE 3.5261532798007096 Test RE 0.8975500051125425\n",
      "67 Train Loss 1.3641918 Test MSE 3.5109814948695646 Test RE 0.8956170042040664\n",
      "68 Train Loss 1.3337479 Test MSE 3.484457095807526 Test RE 0.892227533208095\n",
      "69 Train Loss 1.3096994 Test MSE 3.4665622790907293 Test RE 0.8899335172890137\n",
      "70 Train Loss 1.2999665 Test MSE 3.4484323452780106 Test RE 0.8876033144298018\n",
      "71 Train Loss 1.2831078 Test MSE 3.4369011231328597 Test RE 0.8861180421897311\n",
      "72 Train Loss 1.2684336 Test MSE 3.4247560726263595 Test RE 0.8845510095259875\n",
      "73 Train Loss 1.242069 Test MSE 3.456187162501724 Test RE 0.888600772897825\n",
      "74 Train Loss 1.2219666 Test MSE 3.4557854482512154 Test RE 0.8885491301554305\n",
      "75 Train Loss 1.2067106 Test MSE 3.4585394327662655 Test RE 0.8889031109291551\n",
      "76 Train Loss 1.1789104 Test MSE 3.442010514270893 Test RE 0.8867764612239663\n",
      "77 Train Loss 1.1652049 Test MSE 3.4271105220138693 Test RE 0.8848550126024108\n",
      "78 Train Loss 1.1478207 Test MSE 3.3890614755555104 Test RE 0.8799293091594526\n",
      "79 Train Loss 1.1341134 Test MSE 3.4028466628765335 Test RE 0.8817170726186502\n",
      "80 Train Loss 1.1139256 Test MSE 3.3723107942183597 Test RE 0.8777520584119819\n",
      "81 Train Loss 1.0998068 Test MSE 3.364169007439706 Test RE 0.8766918375137729\n",
      "82 Train Loss 1.0770727 Test MSE 3.3497236269370885 Test RE 0.8748076023525891\n",
      "83 Train Loss 1.0531658 Test MSE 3.3642096636052834 Test RE 0.8766971349320567\n",
      "84 Train Loss 1.0461195 Test MSE 3.3867591290045778 Test RE 0.879630369996817\n",
      "85 Train Loss 1.0391545 Test MSE 3.4060676362790456 Test RE 0.882134269717033\n",
      "86 Train Loss 1.0325189 Test MSE 3.3959943897657108 Test RE 0.8808288735001042\n",
      "87 Train Loss 1.0237424 Test MSE 3.395287529109081 Test RE 0.8807371984843569\n",
      "88 Train Loss 1.0144331 Test MSE 3.417694654187105 Test RE 0.8836386222328401\n",
      "89 Train Loss 1.008114 Test MSE 3.4148024607376417 Test RE 0.8832646574704438\n",
      "90 Train Loss 0.9961061 Test MSE 3.4340064916767123 Test RE 0.8857448098263712\n",
      "91 Train Loss 0.9886739 Test MSE 3.432348686694166 Test RE 0.8855309824171888\n",
      "92 Train Loss 0.97997534 Test MSE 3.439899556048169 Test RE 0.8865044929723278\n",
      "93 Train Loss 0.9729639 Test MSE 3.4454417340871397 Test RE 0.8872183493348446\n",
      "94 Train Loss 0.96571565 Test MSE 3.4378082276362365 Test RE 0.8862349714535888\n",
      "95 Train Loss 0.95501256 Test MSE 3.4128274318326928 Test RE 0.8830091923943192\n",
      "96 Train Loss 0.9507637 Test MSE 3.3921177744453264 Test RE 0.8803259854879862\n",
      "97 Train Loss 0.9485575 Test MSE 3.396198135192784 Test RE 0.880855296123747\n",
      "98 Train Loss 0.94274247 Test MSE 3.398496211726556 Test RE 0.8811532661602447\n",
      "99 Train Loss 0.9366746 Test MSE 3.4026839754244884 Test RE 0.881695995263026\n",
      "100 Train Loss 0.93148726 Test MSE 3.375828263725481 Test RE 0.8782097062412091\n",
      "101 Train Loss 0.9262916 Test MSE 3.3696106694394743 Test RE 0.8774005910020606\n",
      "102 Train Loss 0.92245656 Test MSE 3.3739111561368538 Test RE 0.8779603064705837\n",
      "103 Train Loss 0.91936743 Test MSE 3.372336550896087 Test RE 0.8777554104063715\n",
      "104 Train Loss 0.9147954 Test MSE 3.3721551401540353 Test RE 0.8777318011966367\n",
      "105 Train Loss 0.90936935 Test MSE 3.3620103925631906 Test RE 0.8764105282652962\n",
      "106 Train Loss 0.9022512 Test MSE 3.373668691988625 Test RE 0.8779287588523021\n",
      "107 Train Loss 0.8978624 Test MSE 3.3723543484572014 Test RE 0.8777577265875585\n",
      "108 Train Loss 0.8943535 Test MSE 3.3832208208904127 Test RE 0.8791707541072824\n",
      "109 Train Loss 0.8849592 Test MSE 3.388868566240738 Test RE 0.8799042655040169\n",
      "110 Train Loss 0.8741183 Test MSE 3.3866893950351566 Test RE 0.8796213140777592\n",
      "111 Train Loss 0.8629565 Test MSE 3.4412109892289835 Test RE 0.8866734631126063\n",
      "112 Train Loss 0.85848933 Test MSE 3.4345171102822643 Test RE 0.8858106601631698\n",
      "113 Train Loss 0.8496176 Test MSE 3.4299678554060895 Test RE 0.8852238070991028\n",
      "114 Train Loss 0.8451836 Test MSE 3.4098760970190134 Test RE 0.8826273067759541\n",
      "115 Train Loss 0.8375984 Test MSE 3.3988268550346126 Test RE 0.881196129286558\n",
      "116 Train Loss 0.8285297 Test MSE 3.37038995626997 Test RE 0.8775020429597061\n",
      "117 Train Loss 0.82297134 Test MSE 3.349514683632584 Test RE 0.8747803183044027\n",
      "118 Train Loss 0.81705797 Test MSE 3.3588819774588194 Test RE 0.876002674967756\n",
      "119 Train Loss 0.80963886 Test MSE 3.342657885200333 Test RE 0.8738844773011584\n",
      "120 Train Loss 0.8054094 Test MSE 3.3287507342209612 Test RE 0.8720646813393691\n",
      "121 Train Loss 0.80092263 Test MSE 3.317256961070497 Test RE 0.870557812589969\n",
      "122 Train Loss 0.797397 Test MSE 3.3348336892190797 Test RE 0.8728611226146131\n",
      "123 Train Loss 0.7931388 Test MSE 3.338670088455244 Test RE 0.8733630488781131\n",
      "124 Train Loss 0.7880622 Test MSE 3.372585258252858 Test RE 0.8777877767197458\n",
      "125 Train Loss 0.7837302 Test MSE 3.3789538445034912 Test RE 0.8786161665373527\n",
      "126 Train Loss 0.7819065 Test MSE 3.3731195674406336 Test RE 0.8778573066891296\n",
      "127 Train Loss 0.77882624 Test MSE 3.3759630144294115 Test RE 0.8782272335242897\n",
      "128 Train Loss 0.7745291 Test MSE 3.3638635081231683 Test RE 0.876652030530648\n",
      "129 Train Loss 0.7709215 Test MSE 3.371780160604094 Test RE 0.8776829984855565\n",
      "130 Train Loss 0.76785827 Test MSE 3.363702224191763 Test RE 0.8766310142824516\n",
      "131 Train Loss 0.76627463 Test MSE 3.370475655845056 Test RE 0.8775131990981883\n",
      "132 Train Loss 0.7649432 Test MSE 3.348581398541613 Test RE 0.8746584385122053\n",
      "133 Train Loss 0.7633994 Test MSE 3.3507026721028432 Test RE 0.8749354358213514\n",
      "134 Train Loss 0.758786 Test MSE 3.3541612456311842 Test RE 0.8753868706955219\n",
      "135 Train Loss 0.75331616 Test MSE 3.366541089890095 Test RE 0.8770008616541743\n",
      "136 Train Loss 0.75055176 Test MSE 3.3694020381367094 Test RE 0.8773734282108877\n",
      "137 Train Loss 0.7466802 Test MSE 3.3587959127373717 Test RE 0.8759914519760479\n",
      "138 Train Loss 0.74453026 Test MSE 3.3532125029969033 Test RE 0.8752630579861369\n",
      "139 Train Loss 0.74257493 Test MSE 3.3423012024265133 Test RE 0.8738378515521902\n",
      "140 Train Loss 0.7406474 Test MSE 3.34581930765674 Test RE 0.8742976313215294\n",
      "141 Train Loss 0.7389826 Test MSE 3.3622860594981785 Test RE 0.8764464580251253\n",
      "142 Train Loss 0.73721254 Test MSE 3.351833675979449 Test RE 0.8750830872211338\n",
      "143 Train Loss 0.73550636 Test MSE 3.3615222413939616 Test RE 0.8763469002117272\n",
      "144 Train Loss 0.7322793 Test MSE 3.3777022462597874 Test RE 0.8784534273652594\n",
      "145 Train Loss 0.72778136 Test MSE 3.376022441622555 Test RE 0.8782349632223835\n",
      "146 Train Loss 0.72402054 Test MSE 3.398236311539728 Test RE 0.8811195723935281\n",
      "147 Train Loss 0.72089267 Test MSE 3.3850081722076806 Test RE 0.8794029558468367\n",
      "148 Train Loss 0.71814513 Test MSE 3.383415980227815 Test RE 0.8791961109959748\n",
      "149 Train Loss 0.7157953 Test MSE 3.374077509449415 Test RE 0.8779819504615286\n",
      "Training time: 232.10\n",
      "6\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 60.04138 Test MSE 7.564833827747618 Test RE 1.3146427677279715\n",
      "1 Train Loss 49.101704 Test MSE 8.329284335248056 Test RE 1.3794688694049824\n",
      "2 Train Loss 43.254135 Test MSE 8.890461047688271 Test RE 1.425181584679634\n",
      "3 Train Loss 37.875656 Test MSE 8.411227273865967 Test RE 1.3862378229634724\n",
      "4 Train Loss 33.160553 Test MSE 8.689562169987356 Test RE 1.4089870698822962\n",
      "5 Train Loss 31.946665 Test MSE 8.60986432095237 Test RE 1.4025107996480732\n",
      "6 Train Loss 30.289013 Test MSE 8.635657960628082 Test RE 1.4046100664449142\n",
      "7 Train Loss 28.761684 Test MSE 8.568754961001142 Test RE 1.3991585221565708\n",
      "8 Train Loss 27.886942 Test MSE 8.718802339601284 Test RE 1.4113556829298288\n",
      "9 Train Loss 26.890085 Test MSE 8.720093394373798 Test RE 1.4114601737744419\n",
      "10 Train Loss 26.084423 Test MSE 8.593499960045891 Test RE 1.4011773228369455\n",
      "11 Train Loss 25.010895 Test MSE 8.779197150169411 Test RE 1.4162354504589891\n",
      "12 Train Loss 23.662346 Test MSE 8.832899820895888 Test RE 1.4205604286080982\n",
      "13 Train Loss 22.850212 Test MSE 8.502536951639756 Test RE 1.39374179692931\n",
      "14 Train Loss 21.58679 Test MSE 8.40450222781664 Test RE 1.3856835413438855\n",
      "15 Train Loss 20.669106 Test MSE 8.587127298827562 Test RE 1.4006576926253038\n",
      "16 Train Loss 19.763721 Test MSE 8.366523425665255 Test RE 1.3825491386477793\n",
      "17 Train Loss 18.956554 Test MSE 8.54817358448158 Test RE 1.3974771856614816\n",
      "18 Train Loss 18.058762 Test MSE 8.380840942898992 Test RE 1.3837316017069974\n",
      "19 Train Loss 17.183308 Test MSE 8.213415448054583 Test RE 1.3698403531558545\n",
      "20 Train Loss 16.651451 Test MSE 8.271358102256803 Test RE 1.3746637236853334\n",
      "21 Train Loss 16.173573 Test MSE 8.20615151771839 Test RE 1.3692344769544138\n",
      "22 Train Loss 15.521172 Test MSE 8.16472428623002 Test RE 1.3657739410123881\n",
      "23 Train Loss 15.206652 Test MSE 7.958558312031335 Test RE 1.34842023656847\n",
      "24 Train Loss 14.987793 Test MSE 7.878867955726591 Test RE 1.3416522747097859\n",
      "25 Train Loss 14.663927 Test MSE 8.006800488268821 Test RE 1.3525009031127888\n",
      "26 Train Loss 14.349983 Test MSE 8.095447472502611 Test RE 1.3599673747249956\n",
      "27 Train Loss 13.809477 Test MSE 8.349861561533727 Test RE 1.3811717848121075\n",
      "28 Train Loss 13.062361 Test MSE 7.688398970701321 Test RE 1.3253360652813386\n",
      "29 Train Loss 11.38471 Test MSE 7.578584851674272 Test RE 1.315837075284344\n",
      "30 Train Loss 10.724798 Test MSE 7.560068754417115 Test RE 1.3142286571127584\n",
      "31 Train Loss 9.8326845 Test MSE 7.33146630132625 Test RE 1.2942062167381034\n",
      "32 Train Loss 9.169789 Test MSE 7.242005490385254 Test RE 1.286285829297698\n",
      "33 Train Loss 8.89658 Test MSE 7.150083604982325 Test RE 1.2780964255830911\n",
      "34 Train Loss 8.43076 Test MSE 7.206935823306836 Test RE 1.2831676074379132\n",
      "35 Train Loss 7.2918754 Test MSE 6.691613042510781 Test RE 1.236441205163574\n",
      "36 Train Loss 6.7152867 Test MSE 6.419303095989224 Test RE 1.211021912016077\n",
      "37 Train Loss 6.222488 Test MSE 6.607281417234063 Test RE 1.2286253240272254\n",
      "38 Train Loss 5.9895725 Test MSE 6.607961074220664 Test RE 1.228688513579751\n",
      "39 Train Loss 5.7612906 Test MSE 6.573318188420935 Test RE 1.225463521005429\n",
      "40 Train Loss 5.5059547 Test MSE 6.733654097002108 Test RE 1.2403191866138266\n",
      "41 Train Loss 5.413924 Test MSE 6.618459330034746 Test RE 1.2296641524315761\n",
      "42 Train Loss 5.231158 Test MSE 6.601223251611393 Test RE 1.2280619362909913\n",
      "43 Train Loss 5.1451664 Test MSE 6.531578565394397 Test RE 1.2215665665180175\n",
      "44 Train Loss 4.941766 Test MSE 6.5507344874793425 Test RE 1.2233565703968923\n",
      "45 Train Loss 4.8692446 Test MSE 6.572911222274833 Test RE 1.2254255850747864\n",
      "46 Train Loss 4.7239757 Test MSE 6.4250880296272594 Test RE 1.2115674621840689\n",
      "47 Train Loss 4.6701217 Test MSE 6.388369933683629 Test RE 1.2081005687990207\n",
      "48 Train Loss 4.6163697 Test MSE 6.3571130625667625 Test RE 1.205141461304045\n",
      "49 Train Loss 4.455884 Test MSE 6.215157839051189 Test RE 1.1916100063402244\n",
      "50 Train Loss 4.360939 Test MSE 6.193313640747312 Test RE 1.1895141080772846\n",
      "51 Train Loss 4.2849135 Test MSE 6.124657412067395 Test RE 1.182902530424444\n",
      "52 Train Loss 4.229448 Test MSE 6.252811107545273 Test RE 1.1952141192053494\n",
      "53 Train Loss 4.0663853 Test MSE 6.227252656400166 Test RE 1.1927688908696943\n",
      "54 Train Loss 3.9599497 Test MSE 6.027580094583532 Test RE 1.173490438297707\n",
      "55 Train Loss 3.9055207 Test MSE 5.922149158384315 Test RE 1.1631821556392\n",
      "56 Train Loss 3.84139 Test MSE 5.88653763951399 Test RE 1.159679614448529\n",
      "57 Train Loss 3.6448197 Test MSE 5.706084852740791 Test RE 1.141766175651755\n",
      "58 Train Loss 3.5781095 Test MSE 5.7082934600307516 Test RE 1.141987121291066\n",
      "59 Train Loss 3.5122175 Test MSE 5.716466369516574 Test RE 1.1428043549396003\n",
      "60 Train Loss 3.378838 Test MSE 5.749085912067032 Test RE 1.1460602760880063\n",
      "61 Train Loss 3.3422604 Test MSE 5.774704483572874 Test RE 1.1486109243055054\n",
      "62 Train Loss 3.257604 Test MSE 5.739485622121037 Test RE 1.1451029840789155\n",
      "63 Train Loss 3.137597 Test MSE 5.754253352282012 Test RE 1.1465752160183003\n",
      "64 Train Loss 3.03175 Test MSE 5.662408878258957 Test RE 1.1373880824369873\n",
      "65 Train Loss 2.9614093 Test MSE 5.606285641353329 Test RE 1.131737407597704\n",
      "66 Train Loss 2.8909564 Test MSE 5.62763786183144 Test RE 1.133890539186982\n",
      "67 Train Loss 2.8401053 Test MSE 5.617455382781458 Test RE 1.1328642609919743\n",
      "68 Train Loss 2.7814484 Test MSE 5.605392789060439 Test RE 1.1316472842398348\n",
      "69 Train Loss 2.7490778 Test MSE 5.632371912326793 Test RE 1.1343673615045577\n",
      "70 Train Loss 2.7212698 Test MSE 5.638840921477217 Test RE 1.1350186081817877\n",
      "71 Train Loss 2.6598177 Test MSE 5.617589755645438 Test RE 1.132877810303411\n",
      "72 Train Loss 2.6044247 Test MSE 5.572111194755589 Test RE 1.1282827476984723\n",
      "73 Train Loss 2.5578313 Test MSE 5.583091876369554 Test RE 1.129393925800126\n",
      "74 Train Loss 2.5095956 Test MSE 5.529739826466762 Test RE 1.1239847255965045\n",
      "75 Train Loss 2.4936666 Test MSE 5.533188354470689 Test RE 1.124335147930772\n",
      "76 Train Loss 2.481749 Test MSE 5.512158821617932 Test RE 1.1221965300228474\n",
      "77 Train Loss 2.4644756 Test MSE 5.506298212234553 Test RE 1.12159980333347\n",
      "78 Train Loss 2.423419 Test MSE 5.488756780337873 Test RE 1.1198118361667824\n",
      "79 Train Loss 2.3930924 Test MSE 5.503430812812387 Test RE 1.121307729302516\n",
      "80 Train Loss 2.3566597 Test MSE 5.489871037895054 Test RE 1.119925495373357\n",
      "81 Train Loss 2.318138 Test MSE 5.474814345699031 Test RE 1.1183886695490042\n",
      "82 Train Loss 2.2976296 Test MSE 5.49068060032699 Test RE 1.1200080670930852\n",
      "83 Train Loss 2.2732978 Test MSE 5.476661275389037 Test RE 1.1185772979600623\n",
      "84 Train Loss 2.2378817 Test MSE 5.448338506085803 Test RE 1.115681165483377\n",
      "85 Train Loss 2.2154334 Test MSE 5.44932826741215 Test RE 1.1157824998555665\n",
      "86 Train Loss 2.2053304 Test MSE 5.467265776616446 Test RE 1.117617397172854\n",
      "87 Train Loss 2.1860023 Test MSE 5.468266017761508 Test RE 1.1177196270466003\n",
      "88 Train Loss 2.159742 Test MSE 5.5094056229645405 Test RE 1.1219162391266895\n",
      "89 Train Loss 2.1366618 Test MSE 5.535224500839857 Test RE 1.1245419997684107\n",
      "90 Train Loss 2.1184156 Test MSE 5.503357471675263 Test RE 1.1213002577578814\n",
      "91 Train Loss 2.1059594 Test MSE 5.502705320205707 Test RE 1.121233818381593\n",
      "92 Train Loss 2.0893085 Test MSE 5.513701328013243 Test RE 1.1223535351362834\n",
      "93 Train Loss 2.0767877 Test MSE 5.524562343309011 Test RE 1.1234584101655145\n",
      "94 Train Loss 2.0471363 Test MSE 5.506180578696292 Test RE 1.1215878226476292\n",
      "95 Train Loss 2.0080316 Test MSE 5.503493755950199 Test RE 1.121314141523141\n",
      "96 Train Loss 1.9987549 Test MSE 5.5057506041358675 Test RE 1.1215440297099266\n",
      "97 Train Loss 1.982345 Test MSE 5.478085406974036 Test RE 1.1187227239444397\n",
      "98 Train Loss 1.9645826 Test MSE 5.50151836514116 Test RE 1.1211128845992828\n",
      "99 Train Loss 1.9484271 Test MSE 5.480489326580905 Test RE 1.118968158646592\n",
      "100 Train Loss 1.9383005 Test MSE 5.47828799752282 Test RE 1.1187434100544906\n",
      "101 Train Loss 1.9301785 Test MSE 5.498773852612499 Test RE 1.120833207972808\n",
      "102 Train Loss 1.9179709 Test MSE 5.509247909671058 Test RE 1.121900180917919\n",
      "103 Train Loss 1.9125037 Test MSE 5.516827323155893 Test RE 1.1226716494436282\n",
      "104 Train Loss 1.9039164 Test MSE 5.511264714865799 Test RE 1.1221055126720731\n",
      "105 Train Loss 1.889845 Test MSE 5.508396321391143 Test RE 1.1218134690850345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 1.8826979 Test MSE 5.528895761257635 Test RE 1.1238989392269587\n",
      "107 Train Loss 1.8723329 Test MSE 5.557992565393725 Test RE 1.1268524182485695\n",
      "108 Train Loss 1.8632302 Test MSE 5.5726401412346345 Test RE 1.1283362989471257\n",
      "109 Train Loss 1.842378 Test MSE 5.615988056154828 Test RE 1.132716294488823\n",
      "110 Train Loss 1.8290027 Test MSE 5.5790833334285335 Test RE 1.1289884124166814\n",
      "111 Train Loss 1.8169897 Test MSE 5.561140270177324 Test RE 1.1271714629978506\n",
      "112 Train Loss 1.7977703 Test MSE 5.550101800623724 Test RE 1.1260522295626436\n",
      "113 Train Loss 1.7897536 Test MSE 5.53084428792903 Test RE 1.1240969673901766\n",
      "114 Train Loss 1.7801824 Test MSE 5.541037011027644 Test RE 1.1251322826708197\n",
      "115 Train Loss 1.7701359 Test MSE 5.524416783641554 Test RE 1.1234436097795655\n",
      "116 Train Loss 1.7576311 Test MSE 5.501956344715331 Test RE 1.121157509986212\n",
      "117 Train Loss 1.7492248 Test MSE 5.478542756164637 Test RE 1.1187694223998095\n",
      "118 Train Loss 1.7375417 Test MSE 5.480620967239146 Test RE 1.1189815973024901\n",
      "119 Train Loss 1.7248938 Test MSE 5.496814344077637 Test RE 1.120633483634777\n",
      "120 Train Loss 1.695684 Test MSE 5.539573718731162 Test RE 1.124983708847082\n",
      "121 Train Loss 1.6825653 Test MSE 5.585982200490906 Test RE 1.129686227289172\n",
      "122 Train Loss 1.6767972 Test MSE 5.603998220767308 Test RE 1.131506503954584\n",
      "123 Train Loss 1.6684828 Test MSE 5.637459532985193 Test RE 1.134879572721993\n",
      "124 Train Loss 1.6577709 Test MSE 5.649552890698442 Test RE 1.136096180314448\n",
      "125 Train Loss 1.6455935 Test MSE 5.646939031024228 Test RE 1.1358333330049397\n",
      "126 Train Loss 1.6324359 Test MSE 5.633478971403003 Test RE 1.1344788376286987\n",
      "127 Train Loss 1.6264373 Test MSE 5.617064451919729 Test RE 1.1328248410698778\n",
      "128 Train Loss 1.620521 Test MSE 5.626387001288804 Test RE 1.1337645167071586\n",
      "129 Train Loss 1.6125348 Test MSE 5.653053392422433 Test RE 1.1364480923042866\n",
      "130 Train Loss 1.6002836 Test MSE 5.672566874894919 Test RE 1.1384078257661563\n",
      "131 Train Loss 1.5910028 Test MSE 5.690827344436072 Test RE 1.1402386687769448\n",
      "132 Train Loss 1.5868713 Test MSE 5.675179499805455 Test RE 1.138669954915656\n",
      "133 Train Loss 1.5805366 Test MSE 5.690931075141839 Test RE 1.1402490606950015\n",
      "134 Train Loss 1.5716383 Test MSE 5.669717456124052 Test RE 1.1381218698528603\n",
      "135 Train Loss 1.5641083 Test MSE 5.692168008019285 Test RE 1.1403729714314488\n",
      "136 Train Loss 1.5514873 Test MSE 5.677695282897275 Test RE 1.1389223107414714\n",
      "137 Train Loss 1.5401146 Test MSE 5.687447176295476 Test RE 1.1398999859567651\n",
      "138 Train Loss 1.5323279 Test MSE 5.697083865308465 Test RE 1.1408652883270012\n",
      "139 Train Loss 1.5247142 Test MSE 5.672789853681454 Test RE 1.1384301999669992\n",
      "140 Train Loss 1.5188375 Test MSE 5.6748774337568975 Test RE 1.138639651194793\n",
      "141 Train Loss 1.5119206 Test MSE 5.679426979254447 Test RE 1.1390959830817378\n",
      "142 Train Loss 1.5050044 Test MSE 5.697521185675597 Test RE 1.1409090751190065\n",
      "143 Train Loss 1.498245 Test MSE 5.697329653477504 Test RE 1.1408898981249787\n",
      "144 Train Loss 1.4935963 Test MSE 5.7136787474292 Test RE 1.14252567796279\n",
      "145 Train Loss 1.4868491 Test MSE 5.693934224524843 Test RE 1.1405498802423166\n",
      "146 Train Loss 1.4786973 Test MSE 5.694062573662043 Test RE 1.1405627349542213\n",
      "147 Train Loss 1.4706304 Test MSE 5.689689513659329 Test RE 1.140124672741836\n",
      "148 Train Loss 1.4628356 Test MSE 5.700441002906911 Test RE 1.1412013793672502\n",
      "149 Train Loss 1.4526826 Test MSE 5.693864206475256 Test RE 1.1405428675758165\n",
      "Training time: 230.09\n",
      "7\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 61.15281 Test MSE 5.772106766069508 Test RE 1.1483525472453315\n",
      "1 Train Loss 44.563908 Test MSE 7.269145705378101 Test RE 1.2886938244173352\n",
      "2 Train Loss 35.105118 Test MSE 7.8714243895597535 Test RE 1.3410183614762563\n",
      "3 Train Loss 30.778593 Test MSE 7.495950249019768 Test RE 1.3086436676214745\n",
      "4 Train Loss 26.597195 Test MSE 6.9139989554351375 Test RE 1.256818934986713\n",
      "5 Train Loss 23.39935 Test MSE 6.641949598017964 Test RE 1.2318443846119653\n",
      "6 Train Loss 20.831173 Test MSE 5.963548678076395 Test RE 1.1672407596575283\n",
      "7 Train Loss 19.011076 Test MSE 6.047867689809855 Test RE 1.175463643104996\n",
      "8 Train Loss 17.29229 Test MSE 6.205894598077525 Test RE 1.1907216711694293\n",
      "9 Train Loss 15.061457 Test MSE 5.750691461505013 Test RE 1.1462202952640916\n",
      "10 Train Loss 13.580275 Test MSE 5.531763639501864 Test RE 1.1241903886943634\n",
      "11 Train Loss 12.493146 Test MSE 5.784698907056427 Test RE 1.1496044592361614\n",
      "12 Train Loss 11.830756 Test MSE 5.658457484686195 Test RE 1.1369911619401873\n",
      "13 Train Loss 11.115418 Test MSE 5.8325146580185505 Test RE 1.1543459398189564\n",
      "14 Train Loss 10.671506 Test MSE 5.7659032991950845 Test RE 1.1477352958378473\n",
      "15 Train Loss 9.93455 Test MSE 5.66868373091292 Test RE 1.13801811169291\n",
      "16 Train Loss 9.3096485 Test MSE 5.582943059545753 Test RE 1.1293788737518538\n",
      "17 Train Loss 8.464787 Test MSE 5.294301296267488 Test RE 1.0997966357809286\n",
      "18 Train Loss 7.8282733 Test MSE 4.9744701219400165 Test RE 1.0660595711463612\n",
      "19 Train Loss 7.386266 Test MSE 4.958302430121202 Test RE 1.064325743262345\n",
      "20 Train Loss 6.8442793 Test MSE 4.932311293439909 Test RE 1.0615325107400941\n",
      "21 Train Loss 6.5365686 Test MSE 4.901670705531233 Test RE 1.058230138849674\n",
      "22 Train Loss 6.1214614 Test MSE 4.7896062790011875 Test RE 1.0460633046015255\n",
      "23 Train Loss 5.6840005 Test MSE 4.701717867611651 Test RE 1.0364213311988317\n",
      "24 Train Loss 5.5067043 Test MSE 4.746265337072856 Test RE 1.0413196579468817\n",
      "25 Train Loss 5.2346106 Test MSE 4.70030561043941 Test RE 1.0362656643310242\n",
      "26 Train Loss 4.914939 Test MSE 4.6350897366781885 Test RE 1.0290515557982065\n",
      "27 Train Loss 4.672319 Test MSE 4.517234086452073 Test RE 1.0158845573530308\n",
      "28 Train Loss 4.475863 Test MSE 4.466917214962603 Test RE 1.010210811645672\n",
      "29 Train Loss 4.2966123 Test MSE 4.417733803177494 Test RE 1.0046339073582573\n",
      "30 Train Loss 3.9553585 Test MSE 4.287368108259209 Test RE 0.9896997187213536\n",
      "31 Train Loss 3.847223 Test MSE 4.252631070194736 Test RE 0.9856822007261389\n",
      "32 Train Loss 3.628919 Test MSE 4.156855096681944 Test RE 0.9745194314304189\n",
      "33 Train Loss 3.4488218 Test MSE 4.039472885647244 Test RE 0.9606615507098158\n",
      "34 Train Loss 3.2966833 Test MSE 4.0924607463408975 Test RE 0.9669417704628789\n",
      "35 Train Loss 3.1683795 Test MSE 3.9474240487585575 Test RE 0.9496530154297026\n",
      "36 Train Loss 3.0658047 Test MSE 3.9063481578371246 Test RE 0.9446991707140852\n",
      "37 Train Loss 2.9915388 Test MSE 3.80280319041516 Test RE 0.9320945852740812\n",
      "38 Train Loss 2.8474643 Test MSE 3.7174294551845044 Test RE 0.9215723331410642\n",
      "39 Train Loss 2.7791219 Test MSE 3.6088858712778493 Test RE 0.9080183689758842\n",
      "40 Train Loss 2.6723914 Test MSE 3.4322499692719517 Test RE 0.8855182479935603\n",
      "41 Train Loss 2.6061714 Test MSE 3.3436070732664622 Test RE 0.874008543518613\n",
      "42 Train Loss 2.540658 Test MSE 3.25093158698101 Test RE 0.8618108856147547\n",
      "43 Train Loss 2.4146526 Test MSE 3.129732284452316 Test RE 0.8455935375074528\n",
      "44 Train Loss 2.3324482 Test MSE 3.074621139278383 Test RE 0.8381154848853007\n",
      "45 Train Loss 2.2072682 Test MSE 2.9622136953495617 Test RE 0.8226521802319352\n",
      "46 Train Loss 2.1364636 Test MSE 2.866367612579512 Test RE 0.8092337818376178\n",
      "47 Train Loss 2.0533495 Test MSE 2.7247508470005193 Test RE 0.7889899266039742\n",
      "48 Train Loss 1.974016 Test MSE 2.6486825939625778 Test RE 0.7778986522517289\n",
      "49 Train Loss 1.8563479 Test MSE 2.547608015232158 Test RE 0.7629118551017426\n",
      "50 Train Loss 1.7763491 Test MSE 2.455460294279302 Test RE 0.7489874111055622\n",
      "51 Train Loss 1.7299846 Test MSE 2.45772298558585 Test RE 0.7493324252496306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 1.6886842 Test MSE 2.3939576878190483 Test RE 0.7395478781528197\n",
      "53 Train Loss 1.6365861 Test MSE 2.317478322570037 Test RE 0.7276388863926484\n",
      "54 Train Loss 1.5850525 Test MSE 2.1045458438010245 Test RE 0.6934054575953267\n",
      "55 Train Loss 1.4853922 Test MSE 1.9189888060737037 Test RE 0.6621315482392385\n",
      "56 Train Loss 1.3672363 Test MSE 1.774816824783903 Test RE 0.6367732761449965\n",
      "57 Train Loss 1.3146092 Test MSE 1.729979861518448 Test RE 0.6286784649480459\n",
      "58 Train Loss 1.1672466 Test MSE 1.5870260001580625 Test RE 0.6021436089661318\n",
      "59 Train Loss 1.0614189 Test MSE 1.468494978213108 Test RE 0.5792209920749416\n",
      "60 Train Loss 1.0061518 Test MSE 1.412974744552347 Test RE 0.5681660244635286\n",
      "61 Train Loss 0.96629316 Test MSE 1.292689154506025 Test RE 0.5434443937310521\n",
      "62 Train Loss 0.92909604 Test MSE 1.2008396168978375 Test RE 0.5237819931206896\n",
      "63 Train Loss 0.87205064 Test MSE 1.1228063940255755 Test RE 0.5064778988793405\n",
      "64 Train Loss 0.837641 Test MSE 1.1223930705031306 Test RE 0.5063846688714021\n",
      "65 Train Loss 0.7837935 Test MSE 1.0658310378687739 Test RE 0.49346032658067107\n",
      "66 Train Loss 0.7326693 Test MSE 0.9955604232783586 Test RE 0.47691597731907986\n",
      "67 Train Loss 0.70220894 Test MSE 0.9420596028603566 Test RE 0.4639244384431938\n",
      "68 Train Loss 0.6632623 Test MSE 0.9296245554712821 Test RE 0.4608524001770178\n",
      "69 Train Loss 0.6130285 Test MSE 0.8666767496133015 Test RE 0.4449760466117181\n",
      "70 Train Loss 0.54583997 Test MSE 0.8233613172455302 Test RE 0.43371384903524296\n",
      "71 Train Loss 0.5189562 Test MSE 0.8000236946110141 Test RE 0.4275230011989926\n",
      "72 Train Loss 0.4886542 Test MSE 0.7224368975272191 Test RE 0.40626370022738645\n",
      "73 Train Loss 0.4000322 Test MSE 0.603051386837587 Test RE 0.37118055820807133\n",
      "74 Train Loss 0.35807425 Test MSE 0.5358796518072892 Test RE 0.34989818808547773\n",
      "75 Train Loss 0.3277221 Test MSE 0.48905651887266327 Test RE 0.3342624456398492\n",
      "76 Train Loss 0.30518094 Test MSE 0.4738652253767058 Test RE 0.32902998665670913\n",
      "77 Train Loss 0.27440158 Test MSE 0.44939236829977686 Test RE 0.32042095221078665\n",
      "78 Train Loss 0.2614178 Test MSE 0.4282647435300554 Test RE 0.31279818310245217\n",
      "79 Train Loss 0.24785821 Test MSE 0.41153321178325875 Test RE 0.3066270784783469\n",
      "80 Train Loss 0.22987999 Test MSE 0.3980821651136817 Test RE 0.3015743640390454\n",
      "81 Train Loss 0.21987373 Test MSE 0.38939486418409264 Test RE 0.2982656015911256\n",
      "82 Train Loss 0.20554473 Test MSE 0.3721499689595565 Test RE 0.29158625888412953\n",
      "83 Train Loss 0.1959765 Test MSE 0.3432283232215545 Test RE 0.28002681423138\n",
      "84 Train Loss 0.19221735 Test MSE 0.3354516856824083 Test RE 0.27683630857095676\n",
      "85 Train Loss 0.18823326 Test MSE 0.33271065973466496 Test RE 0.27570295315514987\n",
      "86 Train Loss 0.18343215 Test MSE 0.33230264617014255 Test RE 0.2755338496860972\n",
      "87 Train Loss 0.17703424 Test MSE 0.3279650401368963 Test RE 0.2737296463229112\n",
      "88 Train Loss 0.17351499 Test MSE 0.3158464979779691 Test RE 0.26862479262975614\n",
      "89 Train Loss 0.16928029 Test MSE 0.30014340202858253 Test RE 0.2618619880387652\n",
      "90 Train Loss 0.16653043 Test MSE 0.25936912423212827 Test RE 0.24342613189846993\n",
      "91 Train Loss 0.16213845 Test MSE 0.21667238350017118 Test RE 0.22248966426518435\n",
      "92 Train Loss 0.1584383 Test MSE 0.18487083145850175 Test RE 0.20551440002581767\n",
      "93 Train Loss 0.14943297 Test MSE 0.10461785808623313 Test RE 0.15460052784148123\n",
      "94 Train Loss 0.14129524 Test MSE 0.06208698358469916 Test RE 0.11909906187979666\n",
      "95 Train Loss 0.13137335 Test MSE 0.043918972864646 Test RE 0.10016918669745369\n",
      "96 Train Loss 0.12049876 Test MSE 0.041716596323452405 Test RE 0.09762532523769978\n",
      "97 Train Loss 0.11078621 Test MSE 0.03604284615859641 Test RE 0.09074393319596635\n",
      "98 Train Loss 0.101254195 Test MSE 0.03622986155435687 Test RE 0.09097904997505063\n",
      "99 Train Loss 0.09325455 Test MSE 0.035239593708284965 Test RE 0.08972707419552736\n",
      "100 Train Loss 0.08785624 Test MSE 0.03529806138142996 Test RE 0.08980147855821975\n",
      "101 Train Loss 0.08325817 Test MSE 0.03521730015130417 Test RE 0.0896986877713662\n",
      "102 Train Loss 0.073341675 Test MSE 0.03741513230744157 Test RE 0.09245527675226732\n",
      "103 Train Loss 0.06655164 Test MSE 0.0370909516132974 Test RE 0.09205386935696422\n",
      "104 Train Loss 0.063234344 Test MSE 0.03589708536583382 Test RE 0.09056025864070984\n",
      "105 Train Loss 0.0600008 Test MSE 0.03555522862537571 Test RE 0.0901280133170232\n",
      "106 Train Loss 0.055425335 Test MSE 0.035994280268227576 Test RE 0.09068277618488034\n",
      "107 Train Loss 0.04692363 Test MSE 0.028544005024863088 Test RE 0.0807542735866093\n",
      "108 Train Loss 0.043411776 Test MSE 0.02517333364847638 Test RE 0.07583652532244638\n",
      "109 Train Loss 0.041614562 Test MSE 0.02372067229600723 Test RE 0.07361588833263395\n",
      "110 Train Loss 0.039865248 Test MSE 0.022649594615089863 Test RE 0.07193467353513217\n",
      "111 Train Loss 0.03774513 Test MSE 0.020717492748360593 Test RE 0.06879813383053397\n",
      "112 Train Loss 0.03601989 Test MSE 0.021184788830936545 Test RE 0.06956969989703989\n",
      "113 Train Loss 0.034582 Test MSE 0.020960871609646034 Test RE 0.06920105717941451\n",
      "114 Train Loss 0.03326618 Test MSE 0.021816316427474013 Test RE 0.07059903621527895\n",
      "115 Train Loss 0.03185158 Test MSE 0.02166124245764688 Test RE 0.07034767394982816\n",
      "116 Train Loss 0.030453114 Test MSE 0.021558112136457447 Test RE 0.0701800096485917\n",
      "117 Train Loss 0.029353471 Test MSE 0.02208671007862429 Test RE 0.07103519475677472\n",
      "118 Train Loss 0.02868811 Test MSE 0.021626238034087125 Test RE 0.07029081028139894\n",
      "119 Train Loss 0.027648112 Test MSE 0.02072759287292628 Test RE 0.0688149019081314\n",
      "120 Train Loss 0.026829068 Test MSE 0.019530610039457146 Test RE 0.06679838531819693\n",
      "121 Train Loss 0.025911052 Test MSE 0.019854530024340598 Test RE 0.06735004123543017\n",
      "122 Train Loss 0.025334252 Test MSE 0.019600965515641756 Test RE 0.06691859168684394\n",
      "123 Train Loss 0.024659492 Test MSE 0.020015328952047173 Test RE 0.06762222031684324\n",
      "124 Train Loss 0.02333318 Test MSE 0.01889653038734138 Test RE 0.06570510223531653\n",
      "125 Train Loss 0.02249358 Test MSE 0.01670212393888562 Test RE 0.061772319822199676\n",
      "126 Train Loss 0.021748584 Test MSE 0.01485300818777765 Test RE 0.058252594155226246\n",
      "127 Train Loss 0.020899866 Test MSE 0.013503648119607066 Test RE 0.05554354780238693\n",
      "128 Train Loss 0.02059251 Test MSE 0.013398545135892682 Test RE 0.05532696942674708\n",
      "129 Train Loss 0.01957594 Test MSE 0.011585549003199979 Test RE 0.0514477480225076\n",
      "130 Train Loss 0.018839456 Test MSE 0.010446784007214568 Test RE 0.04885391450432411\n",
      "131 Train Loss 0.018277287 Test MSE 0.008552986003761882 Test RE 0.04420454665315806\n",
      "132 Train Loss 0.017517526 Test MSE 0.0076983173701941745 Test RE 0.04193783106597603\n",
      "133 Train Loss 0.016818607 Test MSE 0.007181073304377141 Test RE 0.040504450086121906\n",
      "134 Train Loss 0.016302766 Test MSE 0.005895554584448806 Test RE 0.036700365769586296\n",
      "135 Train Loss 0.0157095 Test MSE 0.005349732096678416 Test RE 0.0349602135888862\n",
      "136 Train Loss 0.015297839 Test MSE 0.005813509334446243 Test RE 0.03644410148549836\n",
      "137 Train Loss 0.014833124 Test MSE 0.006209005373820102 Test RE 0.037663361450517414\n",
      "138 Train Loss 0.0140769845 Test MSE 0.006248051347471661 Test RE 0.037781600827228826\n",
      "139 Train Loss 0.013807881 Test MSE 0.005743050023637585 Test RE 0.036222578296829754\n",
      "140 Train Loss 0.013421107 Test MSE 0.005629534820708826 Test RE 0.03586280998497578\n",
      "141 Train Loss 0.013064098 Test MSE 0.005467700898540176 Test RE 0.03534357163303706\n",
      "142 Train Loss 0.012731253 Test MSE 0.004671170653503735 Test RE 0.03266787816259695\n",
      "143 Train Loss 0.012434556 Test MSE 0.004446312824470473 Test RE 0.031871908327594706\n",
      "144 Train Loss 0.011810668 Test MSE 0.004115992840344135 Test RE 0.030665169220046053\n",
      "145 Train Loss 0.011404477 Test MSE 0.004427572161972044 Test RE 0.0318046693120438\n",
      "146 Train Loss 0.011051799 Test MSE 0.003921457627589476 Test RE 0.029931730318930903\n",
      "147 Train Loss 0.010738517 Test MSE 0.004148148034180226 Test RE 0.030784718278584672\n",
      "148 Train Loss 0.010407689 Test MSE 0.003648081866567106 Test RE 0.028869572184674466\n",
      "149 Train Loss 0.010172139 Test MSE 0.0035505308093893243 Test RE 0.028480965193702818\n",
      "Training time: 228.96\n",
      "8\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 72.5685 Test MSE 5.698696591464111 Test RE 1.1410267545387396\n",
      "1 Train Loss 55.013725 Test MSE 6.4512691071107255 Test RE 1.2140334123515344\n",
      "2 Train Loss 42.830784 Test MSE 7.509248307812451 Test RE 1.3098039414077745\n",
      "3 Train Loss 36.579395 Test MSE 8.104357483355043 Test RE 1.3607155725114892\n",
      "4 Train Loss 27.710583 Test MSE 7.89984905450465 Test RE 1.3434374692224713\n",
      "5 Train Loss 23.938507 Test MSE 7.034048483330704 Test RE 1.267683212052803\n",
      "6 Train Loss 20.332718 Test MSE 7.017372916314987 Test RE 1.2661796767844842\n",
      "7 Train Loss 18.984455 Test MSE 7.070918448006901 Test RE 1.2710012406040285\n",
      "8 Train Loss 17.916973 Test MSE 7.008799037803866 Test RE 1.2654059264874826\n",
      "9 Train Loss 17.130299 Test MSE 7.183046888062874 Test RE 1.2810391749994805\n",
      "10 Train Loss 16.445 Test MSE 7.088006737166394 Test RE 1.2725361282210466\n",
      "11 Train Loss 15.7577915 Test MSE 7.033234696655334 Test RE 1.26760987920981\n",
      "12 Train Loss 15.244409 Test MSE 7.128044712899808 Test RE 1.2761251501491362\n",
      "13 Train Loss 14.767516 Test MSE 7.186438433183513 Test RE 1.2813415668329013\n",
      "14 Train Loss 14.403345 Test MSE 7.1505589652555175 Test RE 1.278138910832346\n",
      "15 Train Loss 13.977021 Test MSE 7.069411691930004 Test RE 1.2708658132977673\n",
      "16 Train Loss 13.397165 Test MSE 6.9103870783465275 Test RE 1.2564906106294094\n",
      "17 Train Loss 12.819423 Test MSE 6.977803272030987 Test RE 1.2626047557153681\n",
      "18 Train Loss 12.292315 Test MSE 6.957184524306823 Test RE 1.2607379368979512\n",
      "19 Train Loss 11.565418 Test MSE 6.329092480959452 Test RE 1.2024825454048464\n",
      "20 Train Loss 11.102524 Test MSE 6.348556085308767 Test RE 1.2043300992480448\n",
      "21 Train Loss 10.36083 Test MSE 6.086199448275162 Test RE 1.1791828398264481\n",
      "22 Train Loss 9.594104 Test MSE 6.03518557975656 Test RE 1.1742305487920268\n",
      "23 Train Loss 8.801382 Test MSE 6.17056458354795 Test RE 1.187327458001822\n",
      "24 Train Loss 8.168174 Test MSE 6.032699874791379 Test RE 1.1739887093930161\n",
      "25 Train Loss 7.3474016 Test MSE 6.005375927761127 Test RE 1.1713270146917998\n",
      "26 Train Loss 6.9586196 Test MSE 5.850826126286128 Test RE 1.1561565828700346\n",
      "27 Train Loss 6.6917667 Test MSE 5.858792089604984 Test RE 1.1569433750271152\n",
      "28 Train Loss 6.1241407 Test MSE 5.839815626695307 Test RE 1.155068201850097\n",
      "29 Train Loss 5.932542 Test MSE 5.740755188019036 Test RE 1.1452296246360294\n",
      "30 Train Loss 5.6283407 Test MSE 5.6600698663134015 Test RE 1.137153143636252\n",
      "31 Train Loss 5.422524 Test MSE 5.468762971796183 Test RE 1.1177704148701237\n",
      "32 Train Loss 5.267292 Test MSE 5.558100568230153 Test RE 1.1268633666858652\n",
      "33 Train Loss 5.1914854 Test MSE 5.627297554130508 Test RE 1.1338562550409836\n",
      "34 Train Loss 5.0095963 Test MSE 5.61963469577798 Test RE 1.1330839891637217\n",
      "35 Train Loss 4.769533 Test MSE 5.5770609946437935 Test RE 1.1287837727060286\n",
      "36 Train Loss 4.6752577 Test MSE 5.582708867158751 Test RE 1.1293551860028272\n",
      "37 Train Loss 4.5337286 Test MSE 5.516252412291381 Test RE 1.1226131508803325\n",
      "38 Train Loss 4.4470253 Test MSE 5.464888996075178 Test RE 1.117374440258946\n",
      "39 Train Loss 4.3958216 Test MSE 5.452262953309599 Test RE 1.1160829066457094\n",
      "40 Train Loss 4.320369 Test MSE 5.372712482976666 Test RE 1.1079109644462117\n",
      "41 Train Loss 4.2850494 Test MSE 5.375894200410363 Test RE 1.1082389680302112\n",
      "42 Train Loss 4.168439 Test MSE 5.240473714913694 Test RE 1.0941914925696683\n",
      "43 Train Loss 4.1219416 Test MSE 5.260912732099894 Test RE 1.0963232115722619\n",
      "44 Train Loss 3.9907713 Test MSE 5.160694296000975 Test RE 1.0858307265574674\n",
      "45 Train Loss 3.9207444 Test MSE 5.089029402602394 Test RE 1.0782650791666213\n",
      "46 Train Loss 3.857928 Test MSE 5.036578245284965 Test RE 1.0726940036325294\n",
      "47 Train Loss 3.8105252 Test MSE 4.991369088445658 Test RE 1.067868812166412\n",
      "48 Train Loss 3.566425 Test MSE 4.755881021582382 Test RE 1.0423739537216208\n",
      "49 Train Loss 3.4885647 Test MSE 4.778758631181734 Test RE 1.0448780549282373\n",
      "50 Train Loss 3.4420316 Test MSE 4.724595677208193 Test RE 1.0389398017831997\n",
      "51 Train Loss 3.299485 Test MSE 4.577313059469699 Test RE 1.0226178484809314\n",
      "52 Train Loss 3.2299585 Test MSE 4.56033811265394 Test RE 1.0207199001525524\n",
      "53 Train Loss 3.1697342 Test MSE 4.4961315526297305 Test RE 1.0135088963404513\n",
      "54 Train Loss 3.037031 Test MSE 4.447049769681468 Test RE 1.0079617578318212\n",
      "55 Train Loss 2.9329338 Test MSE 4.357969348787393 Test RE 0.9978152702581229\n",
      "56 Train Loss 2.8952847 Test MSE 4.3514471294337325 Test RE 0.9970683160740059\n",
      "57 Train Loss 2.846479 Test MSE 4.344443276232272 Test RE 0.9962655794019537\n",
      "58 Train Loss 2.7594862 Test MSE 4.270547461467009 Test RE 0.9877563645145411\n",
      "59 Train Loss 2.7058988 Test MSE 4.279852611088733 Test RE 0.9888318963491629\n",
      "60 Train Loss 2.6593144 Test MSE 4.255134498789197 Test RE 0.9859722825507172\n",
      "61 Train Loss 2.5910952 Test MSE 4.196932735771642 Test RE 0.979205997257622\n",
      "62 Train Loss 2.5347419 Test MSE 4.143229537011762 Test RE 0.9729209547741706\n",
      "63 Train Loss 2.5061336 Test MSE 4.135827388222315 Test RE 0.9720514730017323\n",
      "64 Train Loss 2.4609149 Test MSE 4.124558909377999 Test RE 0.9707263436359731\n",
      "65 Train Loss 2.424883 Test MSE 4.119496084920781 Test RE 0.9701303858305508\n",
      "66 Train Loss 2.3633518 Test MSE 4.0511442598645235 Test RE 0.9620483842747891\n",
      "67 Train Loss 2.315546 Test MSE 4.04419704623497 Test RE 0.9612231330560106\n",
      "68 Train Loss 2.2802362 Test MSE 4.018713938151456 Test RE 0.9581899398930851\n",
      "69 Train Loss 2.2404625 Test MSE 4.0139632106366365 Test RE 0.9576234097176182\n",
      "70 Train Loss 2.1859431 Test MSE 4.001179949122132 Test RE 0.9560973229303704\n",
      "71 Train Loss 2.1653154 Test MSE 4.001353407141868 Test RE 0.9561180469359221\n",
      "72 Train Loss 2.1468182 Test MSE 4.0379980261291415 Test RE 0.9604861602291987\n",
      "73 Train Loss 2.1019514 Test MSE 4.012377138134194 Test RE 0.9574341939540549\n",
      "74 Train Loss 2.0823045 Test MSE 4.003830116707569 Test RE 0.9564139043811497\n",
      "75 Train Loss 2.0655456 Test MSE 3.993791902240167 Test RE 0.9552142139890317\n",
      "76 Train Loss 2.0200646 Test MSE 3.9319020667135507 Test RE 0.9477840730505361\n",
      "77 Train Loss 1.9869893 Test MSE 3.902851759228572 Test RE 0.944276296949944\n",
      "78 Train Loss 1.9744265 Test MSE 3.9130420898449683 Test RE 0.945508244173356\n",
      "79 Train Loss 1.9414471 Test MSE 3.848391291154566 Test RE 0.9376649273796472\n",
      "80 Train Loss 1.9096632 Test MSE 3.8510989645798706 Test RE 0.9379947332373275\n",
      "81 Train Loss 1.8852668 Test MSE 3.8257866824464517 Test RE 0.934907052279713\n",
      "82 Train Loss 1.8704797 Test MSE 3.850304635455781 Test RE 0.9378979926750087\n",
      "83 Train Loss 1.8545914 Test MSE 3.8384096593095762 Test RE 0.9364481198624576\n",
      "84 Train Loss 1.828913 Test MSE 3.8158353197630253 Test RE 0.9336903538892098\n",
      "85 Train Loss 1.8072203 Test MSE 3.7720835772613097 Test RE 0.9283221514938172\n",
      "86 Train Loss 1.7920747 Test MSE 3.7786230466717505 Test RE 0.9291264954771733\n",
      "87 Train Loss 1.7634033 Test MSE 3.759396284811632 Test RE 0.926759644364369\n",
      "88 Train Loss 1.7350293 Test MSE 3.7752069032467115 Test RE 0.9287064023584942\n",
      "89 Train Loss 1.7133157 Test MSE 3.757282539957493 Test RE 0.9264990694323785\n",
      "90 Train Loss 1.7025399 Test MSE 3.739238049095357 Test RE 0.9242716185274108\n",
      "91 Train Loss 1.6719062 Test MSE 3.701423796166827 Test RE 0.9195862451504996\n",
      "92 Train Loss 1.6412613 Test MSE 3.662649136572819 Test RE 0.9147569525359132\n",
      "93 Train Loss 1.6219327 Test MSE 3.6235815896393513 Test RE 0.9098652582649619\n",
      "94 Train Loss 1.5951319 Test MSE 3.601302241196352 Test RE 0.9070638227489509\n",
      "95 Train Loss 1.5808433 Test MSE 3.538824879037311 Test RE 0.8991612785750394\n",
      "96 Train Loss 1.5589988 Test MSE 3.5121443677742135 Test RE 0.8957653106712189\n",
      "97 Train Loss 1.5334585 Test MSE 3.4707013215718003 Test RE 0.8904646448853162\n",
      "98 Train Loss 1.5100497 Test MSE 3.4529754209451133 Test RE 0.8881878005630409\n",
      "99 Train Loss 1.4975402 Test MSE 3.4457645324141635 Test RE 0.8872599094472139\n",
      "100 Train Loss 1.4859953 Test MSE 3.447929804181135 Test RE 0.887538636722549\n",
      "101 Train Loss 1.4683676 Test MSE 3.4523612933964114 Test RE 0.8881088129095575\n",
      "102 Train Loss 1.4555395 Test MSE 3.468292703340712 Test RE 0.8901556062470561\n",
      "103 Train Loss 1.4390827 Test MSE 3.441739328926256 Test RE 0.8867415273508524\n",
      "104 Train Loss 1.4208188 Test MSE 3.4634101866001705 Test RE 0.8895288237494436\n",
      "105 Train Loss 1.4025408 Test MSE 3.429836669100235 Test RE 0.8852068783177806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 1.3905829 Test MSE 3.414425984784865 Test RE 0.8832159669425205\n",
      "107 Train Loss 1.3806151 Test MSE 3.442194907356106 Test RE 0.8868002138036032\n",
      "108 Train Loss 1.3657792 Test MSE 3.420549830348129 Test RE 0.884007645431406\n",
      "109 Train Loss 1.3500168 Test MSE 3.4037396178819237 Test RE 0.8818327525340622\n",
      "110 Train Loss 1.3370322 Test MSE 3.3669899449145477 Test RE 0.8770593241996368\n",
      "111 Train Loss 1.3265538 Test MSE 3.3506885095085406 Test RE 0.8749335867511817\n",
      "112 Train Loss 1.3155695 Test MSE 3.3742556010044207 Test RE 0.8780051211070111\n",
      "113 Train Loss 1.3084431 Test MSE 3.368559472105876 Test RE 0.8772637216132463\n",
      "114 Train Loss 1.2941647 Test MSE 3.294056240883028 Test RE 0.867508153236661\n",
      "115 Train Loss 1.2783923 Test MSE 3.2872953346150644 Test RE 0.8666174347029658\n",
      "116 Train Loss 1.259864 Test MSE 3.2879208749443087 Test RE 0.8666998852152292\n",
      "117 Train Loss 1.2506465 Test MSE 3.314034591320873 Test RE 0.8701348817198407\n",
      "118 Train Loss 1.2382078 Test MSE 3.3058783234829203 Test RE 0.8690634648368817\n",
      "119 Train Loss 1.2260185 Test MSE 3.3001837670949667 Test RE 0.8683146375269518\n",
      "120 Train Loss 1.2197517 Test MSE 3.2969483174213425 Test RE 0.8678888919598902\n",
      "121 Train Loss 1.214361 Test MSE 3.294536241139959 Test RE 0.8675713563118059\n",
      "122 Train Loss 1.2025123 Test MSE 3.299265898378956 Test RE 0.8681938784538162\n",
      "123 Train Loss 1.1894765 Test MSE 3.284807529979135 Test RE 0.8662894472978734\n",
      "124 Train Loss 1.1801361 Test MSE 3.249401641691509 Test RE 0.8616080701084642\n",
      "125 Train Loss 1.1676334 Test MSE 3.244162031618012 Test RE 0.8609131249805873\n",
      "126 Train Loss 1.1598749 Test MSE 3.2035545112064168 Test RE 0.8555080873897148\n",
      "127 Train Loss 1.1504515 Test MSE 3.1732055129960575 Test RE 0.8514460995833526\n",
      "128 Train Loss 1.1380206 Test MSE 3.186243682461915 Test RE 0.853193531086855\n",
      "129 Train Loss 1.1298822 Test MSE 3.1517235610126857 Test RE 0.8485591473364172\n",
      "130 Train Loss 1.1175196 Test MSE 3.1406427519029148 Test RE 0.8470661545635675\n",
      "131 Train Loss 1.104114 Test MSE 3.0967324238536253 Test RE 0.8411237597791699\n",
      "132 Train Loss 1.0941355 Test MSE 3.0668444593570463 Test RE 0.8370548855220743\n",
      "133 Train Loss 1.08432 Test MSE 3.076104804526259 Test RE 0.83831767773885\n",
      "134 Train Loss 1.0770849 Test MSE 3.0833150873320023 Test RE 0.8392995964375987\n",
      "135 Train Loss 1.0670218 Test MSE 3.055455565757888 Test RE 0.835499215504557\n",
      "136 Train Loss 1.0579243 Test MSE 3.0278895886893205 Test RE 0.8317217862563088\n",
      "137 Train Loss 1.0451576 Test MSE 3.019226447359784 Test RE 0.8305311080014822\n",
      "138 Train Loss 1.0277601 Test MSE 2.9961209393330006 Test RE 0.8273470642342123\n",
      "139 Train Loss 1.0212148 Test MSE 3.006141590245206 Test RE 0.8287294576392857\n",
      "140 Train Loss 1.0132456 Test MSE 2.9805160010495673 Test RE 0.8251896822359724\n",
      "141 Train Loss 1.0065712 Test MSE 2.9770959362290172 Test RE 0.8247161044616383\n",
      "142 Train Loss 0.9983061 Test MSE 2.9721290556862243 Test RE 0.824027853830286\n",
      "143 Train Loss 0.9936026 Test MSE 2.9862299919712125 Test RE 0.8259802951123031\n",
      "144 Train Loss 0.9850521 Test MSE 2.969020662995234 Test RE 0.8235968375168561\n",
      "145 Train Loss 0.9782231 Test MSE 2.951060731552704 Test RE 0.8211020452011881\n",
      "146 Train Loss 0.96558654 Test MSE 2.9534367608802046 Test RE 0.8214325314524366\n",
      "147 Train Loss 0.9602574 Test MSE 2.966300441436904 Test RE 0.8232194606779814\n",
      "148 Train Loss 0.95459497 Test MSE 2.9614195076066996 Test RE 0.8225418937802499\n",
      "149 Train Loss 0.9417767 Test MSE 2.9506977715262246 Test RE 0.8210515487167772\n",
      "Training time: 231.66\n",
      "9\n",
      "KG_rowdy_tune69\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 72.2993 Test MSE 4.866574352660263 Test RE 1.05443482689828\n",
      "1 Train Loss 64.162636 Test MSE 6.207335935351994 Test RE 1.1908599374469715\n",
      "2 Train Loss 50.33941 Test MSE 8.511681251186051 Test RE 1.3944910655126859\n",
      "3 Train Loss 40.082462 Test MSE 9.011371625772812 Test RE 1.434840115939661\n",
      "4 Train Loss 33.97038 Test MSE 8.500201426679913 Test RE 1.3935503633408917\n",
      "5 Train Loss 30.25623 Test MSE 8.568153291095252 Test RE 1.3991093991300418\n",
      "6 Train Loss 28.62489 Test MSE 8.76919253482726 Test RE 1.415428262191748\n",
      "7 Train Loss 27.750212 Test MSE 8.860188835458846 Test RE 1.422753128614349\n",
      "8 Train Loss 25.558891 Test MSE 8.71419667456311 Test RE 1.4109828627919347\n",
      "9 Train Loss 24.262783 Test MSE 8.765694712127676 Test RE 1.4151459436724108\n",
      "10 Train Loss 23.347624 Test MSE 8.745813646394975 Test RE 1.4135402192393045\n",
      "11 Train Loss 22.420544 Test MSE 8.884055077069595 Test RE 1.4246680389543571\n",
      "12 Train Loss 21.716114 Test MSE 8.85451522089643 Test RE 1.422297526274367\n",
      "13 Train Loss 20.934923 Test MSE 8.945481084083715 Test RE 1.4295847645324091\n",
      "14 Train Loss 20.242836 Test MSE 9.028177600779923 Test RE 1.4361774625532715\n",
      "15 Train Loss 19.719261 Test MSE 9.008103853523147 Test RE 1.4345799360219302\n",
      "16 Train Loss 18.906555 Test MSE 8.817378134462949 Test RE 1.4193117340025123\n",
      "17 Train Loss 18.4566 Test MSE 8.626599991848042 Test RE 1.403873223217969\n",
      "18 Train Loss 17.453953 Test MSE 8.246979093119231 Test RE 1.3726363861222162\n",
      "19 Train Loss 16.483212 Test MSE 8.22403915954991 Test RE 1.370725982647186\n",
      "20 Train Loss 15.755044 Test MSE 7.519733324072792 Test RE 1.3107180492195547\n",
      "21 Train Loss 13.675543 Test MSE 7.038034015098125 Test RE 1.2680422994438603\n",
      "22 Train Loss 12.675377 Test MSE 6.794508920075923 Test RE 1.2459112199419629\n",
      "23 Train Loss 10.832959 Test MSE 6.552493320244522 Test RE 1.2235207913109556\n",
      "24 Train Loss 10.140596 Test MSE 6.549907074604204 Test RE 1.2232793078438007\n",
      "25 Train Loss 9.266907 Test MSE 6.681418664009639 Test RE 1.2354990142511864\n",
      "26 Train Loss 8.552029 Test MSE 6.545791056744714 Test RE 1.222894887829515\n",
      "27 Train Loss 7.7911634 Test MSE 6.267634336254005 Test RE 1.1966299979361499\n",
      "28 Train Loss 7.1058645 Test MSE 6.327776968454872 Test RE 1.2023575699018445\n",
      "29 Train Loss 6.809957 Test MSE 6.242395634584624 Test RE 1.1942182544263398\n",
      "30 Train Loss 6.081261 Test MSE 6.334431558828568 Test RE 1.202989631891869\n",
      "31 Train Loss 5.795169 Test MSE 6.372867124972642 Test RE 1.2066338152670586\n",
      "32 Train Loss 5.241146 Test MSE 6.334834771818627 Test RE 1.2030279189365058\n",
      "33 Train Loss 4.5479507 Test MSE 5.818943690706818 Test RE 1.153002204300043\n",
      "34 Train Loss 4.1066904 Test MSE 5.599400237804329 Test RE 1.1310422180080901\n",
      "35 Train Loss 3.5431418 Test MSE 5.564913300307054 Test RE 1.127553770454433\n",
      "36 Train Loss 3.1189854 Test MSE 5.540827318900075 Test RE 1.1251109930084482\n",
      "37 Train Loss 2.8664887 Test MSE 5.5374474358263575 Test RE 1.1247677840006538\n",
      "38 Train Loss 2.6213062 Test MSE 5.465117346127001 Test RE 1.117397784726344\n",
      "39 Train Loss 2.4563966 Test MSE 5.521381252302271 Test RE 1.1231349150331658\n",
      "40 Train Loss 2.3318245 Test MSE 5.6123461993761925 Test RE 1.1323489629109182\n",
      "41 Train Loss 2.2447672 Test MSE 5.613619268400899 Test RE 1.1324773830581618\n",
      "42 Train Loss 2.1482463 Test MSE 5.6434064364576395 Test RE 1.1354780018815416\n",
      "43 Train Loss 2.057049 Test MSE 5.705849993493695 Test RE 1.1417426781827706\n",
      "44 Train Loss 1.9609795 Test MSE 5.757484402857247 Test RE 1.1468970755529133\n",
      "45 Train Loss 1.895582 Test MSE 5.6518476738725765 Test RE 1.1363268914662912\n",
      "46 Train Loss 1.8184475 Test MSE 5.6689924481300995 Test RE 1.138049099574581\n",
      "47 Train Loss 1.7464306 Test MSE 5.660828333889401 Test RE 1.1372293321742437\n",
      "48 Train Loss 1.7077572 Test MSE 5.66595207988971 Test RE 1.1377438819879313\n",
      "49 Train Loss 1.6197658 Test MSE 5.702472853807166 Test RE 1.1414047447264586\n",
      "50 Train Loss 1.5818725 Test MSE 5.656735711759547 Test RE 1.136818165187304\n",
      "51 Train Loss 1.5437224 Test MSE 5.728192694492539 Test RE 1.1439758854821767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 1.5208677 Test MSE 5.72508416974822 Test RE 1.1436654420218497\n",
      "53 Train Loss 1.4790916 Test MSE 5.733784091121819 Test RE 1.1445340774892638\n",
      "54 Train Loss 1.4543908 Test MSE 5.749689185911352 Test RE 1.1461204047817322\n",
      "55 Train Loss 1.4284165 Test MSE 5.7670495091848295 Test RE 1.1478493699230539\n",
      "56 Train Loss 1.4151329 Test MSE 5.758350753461991 Test RE 1.1469833612924838\n",
      "57 Train Loss 1.3884907 Test MSE 5.770090594901974 Test RE 1.1481519725155216\n",
      "58 Train Loss 1.3709077 Test MSE 5.747491308397694 Test RE 1.1459013257183568\n",
      "59 Train Loss 1.33762 Test MSE 5.782615108666073 Test RE 1.1493973819333232\n",
      "60 Train Loss 1.3153708 Test MSE 5.815005128044179 Test RE 1.1526119324261062\n",
      "61 Train Loss 1.3004361 Test MSE 5.803938671356979 Test RE 1.1515146501235731\n",
      "62 Train Loss 1.2758265 Test MSE 5.822706306183128 Test RE 1.1533749182402668\n",
      "63 Train Loss 1.2451131 Test MSE 5.822705004398266 Test RE 1.1533747893100055\n",
      "64 Train Loss 1.2308384 Test MSE 5.868572275935036 Test RE 1.1579086254927078\n",
      "65 Train Loss 1.2164168 Test MSE 5.889971032284681 Test RE 1.1600177635808022\n",
      "66 Train Loss 1.2045064 Test MSE 5.875229669934655 Test RE 1.1585652135527924\n",
      "67 Train Loss 1.1966327 Test MSE 5.856464584156326 Test RE 1.1567135444186432\n",
      "68 Train Loss 1.1874079 Test MSE 5.8507646425222415 Test RE 1.1561505080830243\n",
      "69 Train Loss 1.1782581 Test MSE 5.859646628480621 Test RE 1.1570277454082603\n",
      "70 Train Loss 1.1669444 Test MSE 5.865271582564905 Test RE 1.157582955236973\n",
      "71 Train Loss 1.1514447 Test MSE 5.907771084456952 Test RE 1.1617692832222979\n",
      "72 Train Loss 1.1376711 Test MSE 5.922046633971438 Test RE 1.1631720870745181\n",
      "73 Train Loss 1.1268152 Test MSE 5.905294151693917 Test RE 1.1615257119967075\n",
      "74 Train Loss 1.1148126 Test MSE 5.9126613527192555 Test RE 1.1622500219091259\n",
      "75 Train Loss 1.1088027 Test MSE 5.912200545630977 Test RE 1.1622047306729157\n",
      "76 Train Loss 1.104075 Test MSE 5.938879623260033 Test RE 1.1648240302950401\n",
      "77 Train Loss 1.0964047 Test MSE 5.952667941615774 Test RE 1.1661754344472104\n",
      "78 Train Loss 1.0894305 Test MSE 5.9310698565983175 Test RE 1.1640578928147838\n",
      "79 Train Loss 1.0819571 Test MSE 5.944199062427011 Test RE 1.1653455784742375\n",
      "80 Train Loss 1.076334 Test MSE 5.942573804731162 Test RE 1.16518625369973\n",
      "81 Train Loss 1.0674913 Test MSE 5.9434530885519665 Test RE 1.1652724530099392\n",
      "82 Train Loss 1.0615643 Test MSE 5.937480087058535 Test RE 1.1646867729707508\n",
      "83 Train Loss 1.0568818 Test MSE 5.9446919280382735 Test RE 1.165393890017099\n",
      "84 Train Loss 1.0502107 Test MSE 5.956133342994612 Test RE 1.166514835032298\n",
      "85 Train Loss 1.0457269 Test MSE 5.960758466848727 Test RE 1.1669676647697684\n",
      "86 Train Loss 1.0426046 Test MSE 5.969497293656007 Test RE 1.167822773512526\n",
      "87 Train Loss 1.0367811 Test MSE 5.956482659179115 Test RE 1.1665490414975945\n",
      "88 Train Loss 1.0334907 Test MSE 5.965335730610344 Test RE 1.1674156357611019\n",
      "89 Train Loss 1.0293589 Test MSE 5.96147848910106 Test RE 1.1670381438303261\n",
      "90 Train Loss 1.0245253 Test MSE 5.95730721145723 Test RE 1.1666297810412896\n",
      "91 Train Loss 1.0207931 Test MSE 5.948180157621648 Test RE 1.1657357551068397\n",
      "92 Train Loss 1.009483 Test MSE 5.9910462449646475 Test RE 1.1699287034590513\n",
      "93 Train Loss 1.0054127 Test MSE 5.989559948942215 Test RE 1.1697835728618584\n",
      "94 Train Loss 0.9992039 Test MSE 5.998204812409194 Test RE 1.170627455638641\n",
      "95 Train Loss 0.9956087 Test MSE 6.002609338172779 Test RE 1.1710571769272238\n",
      "96 Train Loss 0.9924163 Test MSE 6.013499779690853 Test RE 1.1721190110130861\n",
      "97 Train Loss 0.987609 Test MSE 5.998624170222701 Test RE 1.170668376481251\n",
      "98 Train Loss 0.983509 Test MSE 5.999610894271789 Test RE 1.1707646551536188\n",
      "99 Train Loss 0.9795524 Test MSE 6.021704528614389 Test RE 1.1729183512035781\n",
      "100 Train Loss 0.9751716 Test MSE 6.015629127183323 Test RE 1.1723265131221665\n",
      "101 Train Loss 0.9729245 Test MSE 6.031061400127384 Test RE 1.1738292715440937\n",
      "102 Train Loss 0.96701074 Test MSE 6.023450699865638 Test RE 1.1730884000526007\n",
      "103 Train Loss 0.9635451 Test MSE 6.044755331496764 Test RE 1.1751611451808874\n",
      "104 Train Loss 0.9601094 Test MSE 6.035238313575489 Test RE 1.1742356788352593\n",
      "105 Train Loss 0.9549126 Test MSE 6.021494427945837 Test RE 1.172897889133566\n",
      "106 Train Loss 0.94819 Test MSE 6.0212382731976035 Test RE 1.1728729412935923\n",
      "107 Train Loss 0.94556004 Test MSE 6.031971475696327 Test RE 1.1739178324933375\n",
      "108 Train Loss 0.94167256 Test MSE 6.034336435790707 Test RE 1.1741479394135155\n",
      "109 Train Loss 0.9393395 Test MSE 6.04979373588468 Test RE 1.1756508013753677\n",
      "110 Train Loss 0.93466413 Test MSE 6.0487534546438 Test RE 1.1755497185858201\n",
      "111 Train Loss 0.93210447 Test MSE 6.058360287041216 Test RE 1.176482871892576\n",
      "112 Train Loss 0.929546 Test MSE 6.066338928592725 Test RE 1.1772573097121646\n",
      "113 Train Loss 0.92708814 Test MSE 6.052368921482689 Test RE 1.1759009914674154\n",
      "114 Train Loss 0.92305356 Test MSE 6.066537969673011 Test RE 1.1772766228965588\n",
      "115 Train Loss 0.91948783 Test MSE 6.070200167457534 Test RE 1.1776319136231141\n",
      "116 Train Loss 0.9176104 Test MSE 6.055177172683304 Test RE 1.176173764199148\n",
      "117 Train Loss 0.9139583 Test MSE 6.073508896577255 Test RE 1.1779528201890688\n",
      "118 Train Loss 0.9118735 Test MSE 6.058480207054182 Test RE 1.1764945155664759\n",
      "119 Train Loss 0.9085446 Test MSE 6.0621967065975655 Test RE 1.1768553132278619\n",
      "120 Train Loss 0.9057709 Test MSE 6.070544755171738 Test RE 1.177665338528329\n",
      "121 Train Loss 0.9046101 Test MSE 6.071447070686695 Test RE 1.1777528583692534\n",
      "122 Train Loss 0.9018871 Test MSE 6.077854218319305 Test RE 1.1783741309079776\n",
      "123 Train Loss 0.89972883 Test MSE 6.06940433106802 Test RE 1.1775547141054248\n",
      "124 Train Loss 0.89741886 Test MSE 6.055918436325296 Test RE 1.1762457545094327\n",
      "125 Train Loss 0.8957583 Test MSE 6.0687242031692525 Test RE 1.1774887347928338\n",
      "126 Train Loss 0.8927307 Test MSE 6.0734318287370375 Test RE 1.1779453465383947\n",
      "127 Train Loss 0.8912048 Test MSE 6.0779734844329285 Test RE 1.1783856925059106\n",
      "128 Train Loss 0.888525 Test MSE 6.080000669445989 Test RE 1.1785821894691113\n",
      "129 Train Loss 0.8850843 Test MSE 6.059337312538915 Test RE 1.1765777331561786\n",
      "130 Train Loss 0.882726 Test MSE 6.071510010761659 Test RE 1.1777589629815655\n",
      "131 Train Loss 0.8802845 Test MSE 6.069048432960478 Test RE 1.1775201888361193\n",
      "132 Train Loss 0.87748843 Test MSE 6.0832720498722574 Test RE 1.1788992183991713\n",
      "133 Train Loss 0.87462467 Test MSE 6.102687806707451 Test RE 1.1807790444028348\n",
      "134 Train Loss 0.87286854 Test MSE 6.099031252473188 Test RE 1.1804252470525662\n",
      "135 Train Loss 0.87147796 Test MSE 6.105371907350841 Test RE 1.181038682572439\n",
      "136 Train Loss 0.86965454 Test MSE 6.11214473789133 Test RE 1.1816935777899393\n",
      "137 Train Loss 0.86763906 Test MSE 6.10593443598293 Test RE 1.1810930898044776\n",
      "138 Train Loss 0.8647032 Test MSE 6.105756072757646 Test RE 1.1810758389550347\n",
      "139 Train Loss 0.8615304 Test MSE 6.0900741910511735 Test RE 1.1795581399828876\n",
      "140 Train Loss 0.858959 Test MSE 6.090451178601987 Test RE 1.1795946479004333\n",
      "141 Train Loss 0.8578724 Test MSE 6.0961707475113815 Test RE 1.1801483991282555\n",
      "142 Train Loss 0.8566477 Test MSE 6.092328300760461 Test RE 1.1797764137993303\n",
      "143 Train Loss 0.85509056 Test MSE 6.101954023832459 Test RE 1.180708054249329\n",
      "144 Train Loss 0.85335094 Test MSE 6.100183028230102 Test RE 1.180536700900254\n",
      "145 Train Loss 0.8514247 Test MSE 6.102200227637915 Test RE 1.1807318738227592\n",
      "146 Train Loss 0.8503752 Test MSE 6.10459746225246 Test RE 1.1809637748813546\n",
      "147 Train Loss 0.84877247 Test MSE 6.115154493055048 Test RE 1.181984487999842\n",
      "148 Train Loss 0.8468353 Test MSE 6.107797367428514 Test RE 1.181273252863655\n",
      "149 Train Loss 0.8459349 Test MSE 6.1065959848536755 Test RE 1.181157070972736\n",
      "Training time: 231.11\n",
      "0\n",
      "KG_rowdy_tune70\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.60\n",
      "0\n",
      "KG_rowdy_tune71\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.35\n",
      "0\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 73.06941 Test MSE 4.392219168575419 Test RE 1.0017285732957526\n",
      "1 Train Loss 69.83291 Test MSE 4.342272280666161 Test RE 0.9960166224822791\n",
      "2 Train Loss 57.992035 Test MSE 6.346715731205219 Test RE 1.2041555277030538\n",
      "3 Train Loss 42.508003 Test MSE 8.536782980424428 Test RE 1.3965457928045562\n",
      "4 Train Loss 33.339455 Test MSE 8.221880913143815 Test RE 1.3705461100513836\n",
      "5 Train Loss 29.335718 Test MSE 8.368028654048597 Test RE 1.3826735008533475\n",
      "6 Train Loss 26.397442 Test MSE 8.472268236544176 Test RE 1.3912587506089034\n",
      "7 Train Loss 24.963215 Test MSE 8.601633015556912 Test RE 1.4018402167661554\n",
      "8 Train Loss 23.37884 Test MSE 8.771057894140457 Test RE 1.4155787972545275\n",
      "9 Train Loss 21.69276 Test MSE 8.795857158411197 Test RE 1.4175785864455812\n",
      "10 Train Loss 20.39898 Test MSE 8.76708747488401 Test RE 1.4152583639850922\n",
      "11 Train Loss 18.918625 Test MSE 8.741404825588441 Test RE 1.4131838869766342\n",
      "12 Train Loss 17.85415 Test MSE 8.517542072187869 Test RE 1.3949710797358341\n",
      "13 Train Loss 15.284131 Test MSE 6.809934637190242 Test RE 1.247324727397182\n",
      "14 Train Loss 12.756792 Test MSE 6.141908484823454 Test RE 1.184567275651834\n",
      "15 Train Loss 11.213085 Test MSE 6.312972192754489 Test RE 1.2009501990171974\n",
      "16 Train Loss 10.405257 Test MSE 6.372658666517941 Test RE 1.2066140804230276\n",
      "17 Train Loss 9.777355 Test MSE 6.554480482255455 Test RE 1.2237063046421957\n",
      "18 Train Loss 9.177963 Test MSE 6.634113043846085 Test RE 1.231117469705168\n",
      "19 Train Loss 8.806715 Test MSE 6.57071067942026 Test RE 1.2252204379824077\n",
      "20 Train Loss 8.449778 Test MSE 6.50087680476366 Test RE 1.2186921908893804\n",
      "21 Train Loss 8.151611 Test MSE 6.490771624995653 Test RE 1.217744634619974\n",
      "22 Train Loss 7.844306 Test MSE 6.5005416041374255 Test RE 1.218660771154484\n",
      "23 Train Loss 7.556104 Test MSE 6.536113799538994 Test RE 1.2219905933427202\n",
      "24 Train Loss 7.204549 Test MSE 6.431181314125012 Test RE 1.2121418259698238\n",
      "25 Train Loss 6.8025923 Test MSE 6.257936012698329 Test RE 1.1957038272979532\n",
      "26 Train Loss 6.1497025 Test MSE 6.045965201710828 Test RE 1.1752787447570292\n",
      "27 Train Loss 5.332068 Test MSE 5.960864468218916 Test RE 1.166978040934327\n",
      "28 Train Loss 4.2501 Test MSE 5.217564662371624 Test RE 1.0917972103762619\n",
      "29 Train Loss 3.521151 Test MSE 5.069030545757859 Test RE 1.0761443116696034\n",
      "30 Train Loss 2.9412596 Test MSE 4.980522773736281 Test RE 1.0667079342542436\n",
      "31 Train Loss 2.4986334 Test MSE 5.159048532257376 Test RE 1.085657575113738\n",
      "32 Train Loss 2.3553824 Test MSE 5.236073964488095 Test RE 1.0937320703274347\n",
      "33 Train Loss 2.2182903 Test MSE 5.2973402837293735 Test RE 1.1001122382100919\n",
      "34 Train Loss 2.0981998 Test MSE 5.330634473756682 Test RE 1.103563968010537\n",
      "35 Train Loss 1.9530019 Test MSE 5.343591122575636 Test RE 1.104904316229167\n",
      "36 Train Loss 1.8887973 Test MSE 5.3735353590490025 Test RE 1.1079958041357416\n",
      "37 Train Loss 1.812573 Test MSE 5.357524401132068 Test RE 1.1063438834459358\n",
      "38 Train Loss 1.7735438 Test MSE 5.387254395332362 Test RE 1.1094093004562064\n",
      "39 Train Loss 1.7118876 Test MSE 5.417683642553171 Test RE 1.112538069897952\n",
      "40 Train Loss 1.6514529 Test MSE 5.47686575931479 Test RE 1.1185981801116722\n",
      "41 Train Loss 1.6085873 Test MSE 5.491088928901068 Test RE 1.1200497124580175\n",
      "42 Train Loss 1.5758086 Test MSE 5.4613165291350905 Test RE 1.1170091596618938\n",
      "43 Train Loss 1.5418221 Test MSE 5.481681521534527 Test RE 1.1190898590615685\n",
      "44 Train Loss 1.5094696 Test MSE 5.479599714907221 Test RE 1.1188773376015666\n",
      "45 Train Loss 1.4686365 Test MSE 5.498906121766929 Test RE 1.1208466883207127\n",
      "46 Train Loss 1.4436812 Test MSE 5.499322855900633 Test RE 1.120889159151635\n",
      "47 Train Loss 1.4132502 Test MSE 5.5255626481407205 Test RE 1.123560115055462\n",
      "48 Train Loss 1.386163 Test MSE 5.559379737066299 Test RE 1.126993030188493\n",
      "49 Train Loss 1.3552787 Test MSE 5.5758290830000865 Test RE 1.1286590978394089\n",
      "50 Train Loss 1.3326807 Test MSE 5.58790000629596 Test RE 1.1298801352541343\n",
      "51 Train Loss 1.305676 Test MSE 5.609035465891652 Test RE 1.1320149262594688\n",
      "52 Train Loss 1.2716162 Test MSE 5.6441853786699125 Test RE 1.1355563624638074\n",
      "53 Train Loss 1.2573428 Test MSE 5.640720521830145 Test RE 1.135207760851221\n",
      "54 Train Loss 1.2336891 Test MSE 5.68656607603777 Test RE 1.1398116857895364\n",
      "55 Train Loss 1.2189729 Test MSE 5.682198541458859 Test RE 1.1393738887856\n",
      "56 Train Loss 1.2030692 Test MSE 5.6920105980818265 Test RE 1.1403572035132425\n",
      "57 Train Loss 1.1857988 Test MSE 5.716555278453745 Test RE 1.142813241996652\n",
      "58 Train Loss 1.1781132 Test MSE 5.726089265701317 Test RE 1.1437658285861818\n",
      "59 Train Loss 1.1586243 Test MSE 5.74020079567135 Test RE 1.1451743251285056\n",
      "60 Train Loss 1.14951 Test MSE 5.728299880423344 Test RE 1.143986588469405\n",
      "61 Train Loss 1.1343584 Test MSE 5.756616083710567 Test RE 1.146810587238622\n",
      "62 Train Loss 1.1213324 Test MSE 5.746731232231192 Test RE 1.1458255534346409\n",
      "63 Train Loss 1.1073616 Test MSE 5.783745891653249 Test RE 1.149509758033685\n",
      "64 Train Loss 1.0958458 Test MSE 5.8000906960870555 Test RE 1.1511328633040971\n",
      "65 Train Loss 1.084476 Test MSE 5.822410725476613 Test RE 1.1533456432191764\n",
      "66 Train Loss 1.0745537 Test MSE 5.830966870463498 Test RE 1.1541927639647709\n",
      "67 Train Loss 1.0665144 Test MSE 5.830497576982195 Test RE 1.1541463166043868\n",
      "68 Train Loss 1.0577357 Test MSE 5.82255025882179 Test RE 1.1533594630284598\n",
      "69 Train Loss 1.0452805 Test MSE 5.865616747136707 Test RE 1.1576170159570314\n",
      "70 Train Loss 1.0371649 Test MSE 5.860835375722622 Test RE 1.1571451026379682\n",
      "71 Train Loss 1.0239266 Test MSE 5.9006585623473224 Test RE 1.161069730198201\n",
      "72 Train Loss 1.0189385 Test MSE 5.92265254308358 Test RE 1.163231590028807\n",
      "73 Train Loss 1.006718 Test MSE 5.931367943039528 Test RE 1.164087144326175\n",
      "74 Train Loss 0.9994085 Test MSE 5.942105742229768 Test RE 1.165140365272429\n",
      "75 Train Loss 0.9900606 Test MSE 5.932837288633081 Test RE 1.164231321893279\n",
      "76 Train Loss 0.9816385 Test MSE 5.935418553978773 Test RE 1.164484561870641\n",
      "77 Train Loss 0.9773369 Test MSE 5.948904200192421 Test RE 1.165806702573703\n",
      "78 Train Loss 0.9713335 Test MSE 5.939951889898632 Test RE 1.164929180226922\n",
      "79 Train Loss 0.96311104 Test MSE 5.9482388892441325 Test RE 1.1657415102606405\n",
      "80 Train Loss 0.9544622 Test MSE 5.966276880482362 Test RE 1.1675077235993463\n",
      "81 Train Loss 0.945555 Test MSE 5.96728488801773 Test RE 1.1676063451436551\n",
      "82 Train Loss 0.93956095 Test MSE 5.98133374365529 Test RE 1.168979992445428\n",
      "83 Train Loss 0.93138915 Test MSE 5.983030146874378 Test RE 1.169145751531951\n",
      "84 Train Loss 0.92434734 Test MSE 5.990034654520703 Test RE 1.1698299278353566\n",
      "85 Train Loss 0.91792077 Test MSE 6.00118999071327 Test RE 1.1709187175338025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 0.9109421 Test MSE 6.008871841352848 Test RE 1.171667897787049\n",
      "87 Train Loss 0.90612954 Test MSE 6.009811273441261 Test RE 1.1717594839808785\n",
      "88 Train Loss 0.89922273 Test MSE 6.001370621998801 Test RE 1.1709363392856567\n",
      "89 Train Loss 0.8931825 Test MSE 6.008478452236849 Test RE 1.1716295437536397\n",
      "90 Train Loss 0.8876448 Test MSE 6.014499893723571 Test RE 1.1722164753831004\n",
      "91 Train Loss 0.88340026 Test MSE 6.000736660411904 Test RE 1.170874491058661\n",
      "92 Train Loss 0.87954307 Test MSE 6.005777125678931 Test RE 1.171366140145112\n",
      "93 Train Loss 0.8745666 Test MSE 6.013623934830248 Test RE 1.1721311107764025\n",
      "94 Train Loss 0.8691492 Test MSE 6.018065412919466 Test RE 1.1725638809172076\n",
      "95 Train Loss 0.86482507 Test MSE 6.023418249969071 Test RE 1.173085240182087\n",
      "96 Train Loss 0.86042833 Test MSE 6.014125699917511 Test RE 1.172180009926713\n",
      "97 Train Loss 0.8556888 Test MSE 6.020853494208693 Test RE 1.172835465275031\n",
      "98 Train Loss 0.85138655 Test MSE 6.044224653618231 Test RE 1.1751095594940193\n",
      "99 Train Loss 0.8479385 Test MSE 6.052588586517524 Test RE 1.1759223303837898\n",
      "100 Train Loss 0.84365255 Test MSE 6.061977405218082 Test RE 1.1768340265276556\n",
      "101 Train Loss 0.84069824 Test MSE 6.050117929483234 Test RE 1.1756823010739232\n",
      "102 Train Loss 0.83782107 Test MSE 6.053456232527666 Test RE 1.176006612318823\n",
      "103 Train Loss 0.8348606 Test MSE 6.047965139184274 Test RE 1.1754731131976899\n",
      "104 Train Loss 0.831403 Test MSE 6.0489223636648015 Test RE 1.1755661318491004\n",
      "105 Train Loss 0.82710576 Test MSE 6.06180436720714 Test RE 1.1768172301542315\n",
      "106 Train Loss 0.82364255 Test MSE 6.062179348566706 Test RE 1.1768536283678632\n",
      "107 Train Loss 0.820408 Test MSE 6.070609656015657 Test RE 1.1776716337846136\n",
      "108 Train Loss 0.8163567 Test MSE 6.078088315926895 Test RE 1.1783968241068268\n",
      "109 Train Loss 0.8140458 Test MSE 6.071047332187661 Test RE 1.1777140866478035\n",
      "110 Train Loss 0.8111801 Test MSE 6.068447935202991 Test RE 1.177461932938815\n",
      "111 Train Loss 0.8076457 Test MSE 6.097072714513633 Test RE 1.1802357011074454\n",
      "112 Train Loss 0.80313426 Test MSE 6.108240223602793 Test RE 1.1813160771945659\n",
      "113 Train Loss 0.79959303 Test MSE 6.118839459856616 Test RE 1.1823405638469988\n",
      "114 Train Loss 0.7972233 Test MSE 6.122647206225831 Test RE 1.1827083911801894\n",
      "115 Train Loss 0.7940481 Test MSE 6.118002012275342 Test RE 1.1822596512709203\n",
      "116 Train Loss 0.7908306 Test MSE 6.134142857395561 Test RE 1.183818174807387\n",
      "117 Train Loss 0.78745914 Test MSE 6.141495580987676 Test RE 1.1845274573613331\n",
      "118 Train Loss 0.784206 Test MSE 6.134431599633395 Test RE 1.1838460364251033\n",
      "119 Train Loss 0.78214115 Test MSE 6.150974267908945 Test RE 1.1854411953850175\n",
      "120 Train Loss 0.7799696 Test MSE 6.163494810238825 Test RE 1.1866470873825394\n",
      "121 Train Loss 0.7761233 Test MSE 6.156548937600785 Test RE 1.185978260423378\n",
      "122 Train Loss 0.7731214 Test MSE 6.162657265287592 Test RE 1.1865664590966736\n",
      "123 Train Loss 0.76992166 Test MSE 6.154267377642448 Test RE 1.185758483785696\n",
      "124 Train Loss 0.7673969 Test MSE 6.158145658556957 Test RE 1.1861320441091991\n",
      "125 Train Loss 0.7657244 Test MSE 6.157691764080044 Test RE 1.1860883305682721\n",
      "126 Train Loss 0.76312655 Test MSE 6.158109890839981 Test RE 1.1861285994605009\n",
      "127 Train Loss 0.7606325 Test MSE 6.158665676184728 Test RE 1.1861821238397792\n",
      "128 Train Loss 0.75866735 Test MSE 6.173151703910986 Test RE 1.1875763361310034\n",
      "129 Train Loss 0.7573947 Test MSE 6.177279429686415 Test RE 1.1879733108469623\n",
      "130 Train Loss 0.7558267 Test MSE 6.166257238175033 Test RE 1.1869129803500502\n",
      "131 Train Loss 0.7544608 Test MSE 6.1824291186433555 Test RE 1.1884683846603712\n",
      "132 Train Loss 0.7523617 Test MSE 6.184993043002104 Test RE 1.1887147948598862\n",
      "133 Train Loss 0.75075185 Test MSE 6.190337407061137 Test RE 1.1892282596937749\n",
      "134 Train Loss 0.74929667 Test MSE 6.20606253209244 Test RE 1.190737781765168\n",
      "135 Train Loss 0.74741626 Test MSE 6.208828242908379 Test RE 1.1910030763478254\n",
      "136 Train Loss 0.74562323 Test MSE 6.203060820469925 Test RE 1.1904497824324065\n",
      "137 Train Loss 0.74380845 Test MSE 6.193115751329906 Test RE 1.1894951041847117\n",
      "138 Train Loss 0.74246424 Test MSE 6.193269706516325 Test RE 1.1895098889723514\n",
      "139 Train Loss 0.74087274 Test MSE 6.187832600479464 Test RE 1.1889876356401132\n",
      "140 Train Loss 0.73987126 Test MSE 6.187919078126022 Test RE 1.1889959439202427\n",
      "141 Train Loss 0.73835874 Test MSE 6.1881673149223815 Test RE 1.189019792776395\n",
      "142 Train Loss 0.7366537 Test MSE 6.192953813524147 Test RE 1.189479552603402\n",
      "143 Train Loss 0.7347201 Test MSE 6.195955758429661 Test RE 1.1897678091912824\n",
      "144 Train Loss 0.73345625 Test MSE 6.2034299292577595 Test RE 1.1904852003456312\n",
      "145 Train Loss 0.7316827 Test MSE 6.1974633434394395 Test RE 1.189912546104296\n",
      "146 Train Loss 0.7305985 Test MSE 6.200522987314321 Test RE 1.1902062355700058\n",
      "147 Train Loss 0.7281624 Test MSE 6.206635334488635 Test RE 1.1907927313981952\n",
      "148 Train Loss 0.7261165 Test MSE 6.209083367368317 Test RE 1.1910275456102553\n",
      "149 Train Loss 0.7246454 Test MSE 6.214970509366574 Test RE 1.1915920481793445\n",
      "Training time: 232.97\n",
      "1\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 66.53747 Test MSE 5.911313387253083 Test RE 1.162117529778964\n",
      "1 Train Loss 46.849365 Test MSE 8.232734493742019 Test RE 1.371450430296853\n",
      "2 Train Loss 37.0544 Test MSE 8.569209653242137 Test RE 1.3991956441239635\n",
      "3 Train Loss 32.642365 Test MSE 8.481131687900632 Test RE 1.3919863084731063\n",
      "4 Train Loss 30.212631 Test MSE 8.135844300789383 Test RE 1.3633563166351392\n",
      "5 Train Loss 27.91251 Test MSE 8.696273902137712 Test RE 1.4095311087108564\n",
      "6 Train Loss 26.597847 Test MSE 8.687074449200926 Test RE 1.4087853671232264\n",
      "7 Train Loss 25.232117 Test MSE 9.337489054316396 Test RE 1.4605724790163612\n",
      "8 Train Loss 24.203667 Test MSE 9.149042496207763 Test RE 1.4457589273952451\n",
      "9 Train Loss 23.04808 Test MSE 9.190306364423614 Test RE 1.4490155791401145\n",
      "10 Train Loss 22.096546 Test MSE 9.08225778910624 Test RE 1.4404725033781505\n",
      "11 Train Loss 21.490507 Test MSE 8.950074526894491 Test RE 1.4299517583823134\n",
      "12 Train Loss 20.871552 Test MSE 9.17230634393305 Test RE 1.4475958716393247\n",
      "13 Train Loss 20.280228 Test MSE 9.2202323400699 Test RE 1.4513728434229554\n",
      "14 Train Loss 19.662622 Test MSE 9.077396892652732 Test RE 1.4400869756285373\n",
      "15 Train Loss 18.829727 Test MSE 8.590611742782807 Test RE 1.4009418399345919\n",
      "16 Train Loss 17.45914 Test MSE 8.143893033126984 Test RE 1.3640305292343566\n",
      "17 Train Loss 15.053491 Test MSE 7.037698576636512 Test RE 1.2680120811168722\n",
      "18 Train Loss 14.351246 Test MSE 7.041136348903038 Test RE 1.2683217423300686\n",
      "19 Train Loss 13.642908 Test MSE 6.857440737363339 Test RE 1.251667834478914\n",
      "20 Train Loss 13.091688 Test MSE 6.94731723780865 Test RE 1.2598435753638138\n",
      "21 Train Loss 12.679671 Test MSE 6.870350009871878 Test RE 1.2528454256849477\n",
      "22 Train Loss 12.362234 Test MSE 6.971989429767042 Test RE 1.262078650702825\n",
      "23 Train Loss 11.965996 Test MSE 6.986170361544957 Test RE 1.263361524111822\n",
      "24 Train Loss 11.579143 Test MSE 6.972675392810783 Test RE 1.262140736139684\n",
      "25 Train Loss 10.753611 Test MSE 6.4510743872374 Test RE 1.2140150905134457\n",
      "26 Train Loss 9.285007 Test MSE 5.744878921725269 Test RE 1.1456408749035263\n",
      "27 Train Loss 8.560355 Test MSE 5.774063602583214 Test RE 1.148547185690569\n",
      "28 Train Loss 8.161194 Test MSE 5.8873745445892895 Test RE 1.1597620489219662\n",
      "29 Train Loss 7.84345 Test MSE 5.9651333997618 Test RE 1.1673958375293034\n",
      "30 Train Loss 7.640086 Test MSE 6.042145183306128 Test RE 1.174907398274451\n",
      "31 Train Loss 7.446927 Test MSE 6.057254336965519 Test RE 1.1763754838663458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 Train Loss 7.240734 Test MSE 6.059406718481263 Test RE 1.1765844716201606\n",
      "33 Train Loss 7.0353465 Test MSE 6.084180401743449 Test RE 1.1789872315054617\n",
      "34 Train Loss 6.8229647 Test MSE 6.17503627899761 Test RE 1.1877575973486698\n",
      "35 Train Loss 6.5251584 Test MSE 6.054459383584313 Test RE 1.1761040494985413\n",
      "36 Train Loss 6.203476 Test MSE 5.997958447399498 Test RE 1.1706034147284914\n",
      "37 Train Loss 5.906284 Test MSE 5.768394437204689 Test RE 1.147983206539392\n",
      "38 Train Loss 4.7438416 Test MSE 5.081106616238329 Test RE 1.0774254110549724\n",
      "39 Train Loss 4.3012366 Test MSE 5.0350066777519515 Test RE 1.0725266337919726\n",
      "40 Train Loss 4.024081 Test MSE 5.086059777976181 Test RE 1.077950430778756\n",
      "41 Train Loss 3.614192 Test MSE 4.9792062874048035 Test RE 1.0665669451161355\n",
      "42 Train Loss 3.4596317 Test MSE 5.066410305801357 Test RE 1.0758661400562903\n",
      "43 Train Loss 3.3097641 Test MSE 5.105456137659482 Test RE 1.0800039278821103\n",
      "44 Train Loss 3.0614116 Test MSE 5.087157745002882 Test RE 1.078066777244609\n",
      "45 Train Loss 2.9768436 Test MSE 5.142447401751691 Test RE 1.0839094169631445\n",
      "46 Train Loss 2.8844805 Test MSE 5.203202792987708 Test RE 1.0902935343142617\n",
      "47 Train Loss 2.7610242 Test MSE 5.2512373281777585 Test RE 1.0953146174399468\n",
      "48 Train Loss 2.6684847 Test MSE 5.281854773031832 Test RE 1.0985031035146493\n",
      "49 Train Loss 2.5407674 Test MSE 5.442963487008918 Test RE 1.1151306960789593\n",
      "50 Train Loss 2.4960742 Test MSE 5.439861196842745 Test RE 1.1148128589225543\n",
      "51 Train Loss 2.4305556 Test MSE 5.450648007715971 Test RE 1.1159176040296308\n",
      "52 Train Loss 2.317151 Test MSE 5.468735998505509 Test RE 1.1177676583067435\n",
      "53 Train Loss 2.2793226 Test MSE 5.508271262911342 Test RE 1.121800734608868\n",
      "54 Train Loss 2.187303 Test MSE 5.5029354768069325 Test RE 1.121257266544947\n",
      "55 Train Loss 2.1642964 Test MSE 5.509150744286618 Test RE 1.121890287521868\n",
      "56 Train Loss 2.0564167 Test MSE 5.6003444531311235 Test RE 1.1311375766478102\n",
      "57 Train Loss 2.0274725 Test MSE 5.549909301259223 Test RE 1.1260327014327138\n",
      "58 Train Loss 1.9714386 Test MSE 5.505104162520502 Test RE 1.1214781863700298\n",
      "59 Train Loss 1.9363428 Test MSE 5.540680161542671 Test RE 1.125096052147605\n",
      "60 Train Loss 1.8913089 Test MSE 5.551326582241425 Test RE 1.1261764698055707\n",
      "61 Train Loss 1.8239657 Test MSE 5.621314201802408 Test RE 1.1332532954731291\n",
      "62 Train Loss 1.7632782 Test MSE 5.631530500899007 Test RE 1.1342826276370603\n",
      "63 Train Loss 1.712403 Test MSE 5.689720247506968 Test RE 1.1401277520285509\n",
      "64 Train Loss 1.6658603 Test MSE 5.730310624749075 Test RE 1.1441873515898375\n",
      "65 Train Loss 1.6172203 Test MSE 5.735807003237393 Test RE 1.1447359587982895\n",
      "66 Train Loss 1.5913606 Test MSE 5.733251697598823 Test RE 1.1444809400964573\n",
      "67 Train Loss 1.5535238 Test MSE 5.752043312508914 Test RE 1.146355011933742\n",
      "68 Train Loss 1.5384736 Test MSE 5.756288755222436 Test RE 1.1467779822232291\n",
      "69 Train Loss 1.4950907 Test MSE 5.778441692102146 Test RE 1.1489825367638595\n",
      "70 Train Loss 1.4742701 Test MSE 5.788014674297516 Test RE 1.1499338864711484\n",
      "71 Train Loss 1.4459907 Test MSE 5.814739768917211 Test RE 1.1525856332587978\n",
      "72 Train Loss 1.4334102 Test MSE 5.797629767706874 Test RE 1.150888629529669\n",
      "73 Train Loss 1.4198548 Test MSE 5.823647800174189 Test RE 1.1534681611075728\n",
      "74 Train Loss 1.3915002 Test MSE 5.770161712250877 Test RE 1.1481590480779833\n",
      "75 Train Loss 1.3811822 Test MSE 5.780740849266015 Test RE 1.1492110956774044\n",
      "76 Train Loss 1.3432475 Test MSE 5.785590895807426 Test RE 1.1496930891489097\n",
      "77 Train Loss 1.3302579 Test MSE 5.785092095414596 Test RE 1.1496435281156785\n",
      "78 Train Loss 1.3236059 Test MSE 5.801670740820584 Test RE 1.1512896468493448\n",
      "79 Train Loss 1.2989368 Test MSE 5.813489996877727 Test RE 1.152461762994284\n",
      "80 Train Loss 1.2879643 Test MSE 5.837220609664861 Test RE 1.1548115366650102\n",
      "81 Train Loss 1.2767022 Test MSE 5.836841663661635 Test RE 1.154774051503141\n",
      "82 Train Loss 1.253944 Test MSE 5.776346542049924 Test RE 1.1487742185702263\n",
      "83 Train Loss 1.2465719 Test MSE 5.7522589384524005 Test RE 1.1463764983474474\n",
      "84 Train Loss 1.2285113 Test MSE 5.751015834562957 Test RE 1.146252621614924\n",
      "85 Train Loss 1.2125678 Test MSE 5.793516478343753 Test RE 1.1504802921485664\n",
      "86 Train Loss 1.2029252 Test MSE 5.806815532386662 Test RE 1.1518000026574873\n",
      "87 Train Loss 1.1850466 Test MSE 5.8143165340997465 Test RE 1.152543686132495\n",
      "88 Train Loss 1.1786836 Test MSE 5.798321036929253 Test RE 1.1509572394794751\n",
      "89 Train Loss 1.1736915 Test MSE 5.816209762449333 Test RE 1.1527313135837682\n",
      "90 Train Loss 1.1609175 Test MSE 5.8131129252198726 Test RE 1.1524243871912283\n",
      "91 Train Loss 1.142451 Test MSE 5.818940361326587 Test RE 1.1530018744477963\n",
      "92 Train Loss 1.135961 Test MSE 5.837266993543412 Test RE 1.1548161248530573\n",
      "93 Train Loss 1.1294494 Test MSE 5.852859177331906 Test RE 1.1563574366592164\n",
      "94 Train Loss 1.117148 Test MSE 5.844878381551366 Test RE 1.1555687793208371\n",
      "95 Train Loss 1.1071241 Test MSE 5.839714307456672 Test RE 1.1550581817445078\n",
      "96 Train Loss 1.1009963 Test MSE 5.8540423084896425 Test RE 1.1564743071782448\n",
      "97 Train Loss 1.0839337 Test MSE 5.86415270133872 Test RE 1.1574725375356592\n",
      "98 Train Loss 1.0749887 Test MSE 5.8536481453809825 Test RE 1.156435372784081\n",
      "99 Train Loss 1.0714747 Test MSE 5.865477058442399 Test RE 1.1576032316459177\n",
      "100 Train Loss 1.0613192 Test MSE 5.865362744195294 Test RE 1.1575919511323878\n",
      "101 Train Loss 1.0437552 Test MSE 5.865250063480234 Test RE 1.1575808317079832\n",
      "102 Train Loss 1.034351 Test MSE 5.845897264525628 Test RE 1.1556694946797923\n",
      "103 Train Loss 1.0307524 Test MSE 5.839488909134319 Test RE 1.1550358903553297\n",
      "104 Train Loss 1.0226382 Test MSE 5.8744597597506765 Test RE 1.1584892998922942\n",
      "105 Train Loss 1.0161059 Test MSE 5.8673163233882635 Test RE 1.1577847149369722\n",
      "106 Train Loss 1.0118418 Test MSE 5.880974281068973 Test RE 1.1591314791210388\n",
      "107 Train Loss 1.0048114 Test MSE 5.877099162786337 Test RE 1.1587495261018175\n",
      "108 Train Loss 0.9938931 Test MSE 5.87584300486655 Test RE 1.15862568522897\n",
      "109 Train Loss 0.99055874 Test MSE 5.87742891485413 Test RE 1.1587820331841505\n",
      "110 Train Loss 0.98776025 Test MSE 5.8724211668601765 Test RE 1.1582882692380136\n",
      "111 Train Loss 0.98213184 Test MSE 5.889288666228257 Test RE 1.159950566334025\n",
      "112 Train Loss 0.97581005 Test MSE 5.903230443289053 Test RE 1.161322736516389\n",
      "113 Train Loss 0.97309905 Test MSE 5.890999695167568 Test RE 1.1601190556852037\n",
      "114 Train Loss 0.9698864 Test MSE 5.874777334863828 Test RE 1.1585206136141837\n",
      "115 Train Loss 0.9611133 Test MSE 5.907052034436387 Test RE 1.1616985801064053\n",
      "116 Train Loss 0.95706046 Test MSE 5.901654790593912 Test RE 1.1611677397365758\n",
      "117 Train Loss 0.95289284 Test MSE 5.903999044083664 Test RE 1.161398336184624\n",
      "118 Train Loss 0.9495958 Test MSE 5.913684525224693 Test RE 1.162350579911188\n",
      "119 Train Loss 0.9460481 Test MSE 5.909286788950851 Test RE 1.161918306091347\n",
      "120 Train Loss 0.9403429 Test MSE 5.9302972923794535 Test RE 1.1639820769176776\n",
      "121 Train Loss 0.9357867 Test MSE 5.933409259823523 Test RE 1.1642874409720503\n",
      "122 Train Loss 0.9312167 Test MSE 5.935920692627845 Test RE 1.1645338187455196\n",
      "123 Train Loss 0.9275058 Test MSE 5.9614833416824915 Test RE 1.1670386188086799\n",
      "124 Train Loss 0.92438567 Test MSE 5.967672521841577 Test RE 1.1676442682838089\n",
      "125 Train Loss 0.9205761 Test MSE 5.969675495376583 Test RE 1.1678402043332667\n",
      "126 Train Loss 0.91770047 Test MSE 5.979480446550346 Test RE 1.1687988760612875\n",
      "127 Train Loss 0.9148182 Test MSE 5.979347187467714 Test RE 1.1687858520255718\n",
      "128 Train Loss 0.91115946 Test MSE 5.974937777056378 Test RE 1.1683548177653365\n",
      "129 Train Loss 0.90793633 Test MSE 5.969078831103855 Test RE 1.1677818405294929\n",
      "130 Train Loss 0.90425444 Test MSE 5.9790487687027785 Test RE 1.1687566856323643\n",
      "131 Train Loss 0.9004986 Test MSE 5.999311870212424 Test RE 1.1707354789980189\n",
      "132 Train Loss 0.8961203 Test MSE 6.013893085800304 Test RE 1.17215734094136\n",
      "133 Train Loss 0.89079195 Test MSE 6.025563580575124 Test RE 1.1732941275213504\n",
      "134 Train Loss 0.8875333 Test MSE 6.028806745117179 Test RE 1.1736098385729667\n",
      "135 Train Loss 0.8858129 Test MSE 6.042255653205173 Test RE 1.1749181387734362\n",
      "136 Train Loss 0.8828617 Test MSE 6.048366119488622 Test RE 1.1755120795064904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 Train Loss 0.87903076 Test MSE 6.034297432868324 Test RE 1.1741441448558676\n",
      "138 Train Loss 0.8745499 Test MSE 6.0546179557726525 Test RE 1.1761194510529915\n",
      "139 Train Loss 0.8721086 Test MSE 6.060532642550025 Test RE 1.1766937796187553\n",
      "140 Train Loss 0.8708894 Test MSE 6.058253696826399 Test RE 1.1764725223831642\n",
      "141 Train Loss 0.8682527 Test MSE 6.053410670535395 Test RE 1.1760021866400916\n",
      "142 Train Loss 0.8660145 Test MSE 6.054519309800543 Test RE 1.176109869943169\n",
      "143 Train Loss 0.86313874 Test MSE 6.057213046916395 Test RE 1.1763714744025202\n",
      "144 Train Loss 0.8617805 Test MSE 6.067327144576729 Test RE 1.177353194324697\n",
      "145 Train Loss 0.8597866 Test MSE 6.0771730890246625 Test RE 1.1783081003978613\n",
      "146 Train Loss 0.8578465 Test MSE 6.079432378611918 Test RE 1.178527107805189\n",
      "147 Train Loss 0.8556462 Test MSE 6.077651826904702 Test RE 1.1783545109249876\n",
      "148 Train Loss 0.85422355 Test MSE 6.08811534029449 Test RE 1.1793684243809273\n",
      "149 Train Loss 0.8534569 Test MSE 6.09434691552234 Test RE 1.1799718494955618\n",
      "Training time: 236.03\n",
      "2\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "1 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "2 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "3 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "4 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "5 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "6 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "7 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "8 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "9 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "10 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "11 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "12 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "13 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "14 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "15 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "16 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "17 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "18 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "19 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "20 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "21 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "22 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "23 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "24 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "25 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "26 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "27 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "28 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "29 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "30 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "31 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "32 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "33 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "34 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "35 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "36 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "37 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "38 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "39 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "40 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "41 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "42 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "43 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "44 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "45 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "46 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "47 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "48 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "49 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "50 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "51 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "52 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "53 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "54 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "55 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "56 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "57 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "58 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "59 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "60 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "61 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "62 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "63 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "64 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "65 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "66 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "67 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "68 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "69 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "70 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "71 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "72 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "73 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "74 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "75 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "76 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "77 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "78 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "79 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "80 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "81 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "82 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "83 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "85 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "86 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "87 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "88 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "89 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "90 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "91 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "92 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "93 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "94 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "95 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "96 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "97 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "98 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "99 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "100 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "101 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "102 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "103 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "104 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "105 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "106 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "107 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "108 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "109 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "110 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "111 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "112 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "113 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "114 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "115 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "116 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "117 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "118 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "119 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "120 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "121 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "122 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "123 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "124 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "125 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "126 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "127 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "128 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "129 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "130 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "131 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "132 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "133 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "134 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "135 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "136 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "137 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "138 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "139 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "140 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "141 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "142 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "143 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "144 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "145 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "146 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "147 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "148 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "149 Train Loss 70.46707 Test MSE 4.945141298284885 Test RE 1.0629122515101073\n",
      "Training time: 133.75\n",
      "3\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 67.36009 Test MSE 5.327103367352106 Test RE 1.103198397330734\n",
      "1 Train Loss 55.689796 Test MSE 6.845502892033976 Test RE 1.250577870574853\n",
      "2 Train Loss 42.0126 Test MSE 9.045682393470079 Test RE 1.4375690952634748\n",
      "3 Train Loss 36.18896 Test MSE 8.790092589817345 Test RE 1.4171139888416524\n",
      "4 Train Loss 31.366722 Test MSE 8.699775034261824 Test RE 1.409814819763154\n",
      "5 Train Loss 26.59322 Test MSE 8.653247952629089 Test RE 1.4060398654982096\n",
      "6 Train Loss 23.439526 Test MSE 8.842236233243648 Test RE 1.421310999502197\n",
      "7 Train Loss 21.51014 Test MSE 8.534001427455669 Test RE 1.396318254949549\n",
      "8 Train Loss 20.035208 Test MSE 8.513955981340917 Test RE 1.3946773905687095\n",
      "9 Train Loss 18.27241 Test MSE 8.56897995976963 Test RE 1.3991768916209382\n",
      "10 Train Loss 17.266077 Test MSE 8.597309209860548 Test RE 1.4014878391068368\n",
      "11 Train Loss 16.20776 Test MSE 8.76255797256048 Test RE 1.4148927212181361\n",
      "12 Train Loss 15.112978 Test MSE 8.67890974508545 Test RE 1.4081231752836283\n",
      "13 Train Loss 14.203984 Test MSE 8.674507081445586 Test RE 1.4077659714809494\n",
      "14 Train Loss 12.69236 Test MSE 8.18263681449201 Test RE 1.367271300877683\n",
      "15 Train Loss 11.014072 Test MSE 7.750644115295586 Test RE 1.3306901992707394\n",
      "16 Train Loss 9.253586 Test MSE 7.074754080331168 Test RE 1.2713459223120671\n",
      "17 Train Loss 7.6420927 Test MSE 6.970213136123375 Test RE 1.261917866961233\n",
      "18 Train Loss 6.6929665 Test MSE 6.549229687340419 Test RE 1.2232160508205292\n",
      "19 Train Loss 4.6883116 Test MSE 5.479922354153333 Test RE 1.1189102769078847\n",
      "20 Train Loss 3.7521095 Test MSE 5.7204227854350975 Test RE 1.143199758935127\n",
      "21 Train Loss 3.2711139 Test MSE 5.787680616673341 Test RE 1.149900701541029\n",
      "22 Train Loss 2.6509292 Test MSE 5.8647879159208935 Test RE 1.157535225494358\n",
      "23 Train Loss 2.3079226 Test MSE 6.083012278478535 Test RE 1.178874047113066\n",
      "24 Train Loss 2.0957315 Test MSE 5.987218439503323 Test RE 1.169554897712987\n",
      "25 Train Loss 1.8711498 Test MSE 6.109611367318482 Test RE 1.181448657378715\n",
      "26 Train Loss 1.7236105 Test MSE 6.006462914665658 Test RE 1.1714330163420388\n",
      "27 Train Loss 1.6211132 Test MSE 5.939217709020029 Test RE 1.1648571851018406\n",
      "28 Train Loss 1.5293415 Test MSE 6.016758920254984 Test RE 1.1724365950572615\n",
      "29 Train Loss 1.460933 Test MSE 5.941351879809453 Test RE 1.1650664534779895\n",
      "30 Train Loss 1.4114615 Test MSE 5.908135532147331 Test RE 1.1618051171769546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 Train Loss 1.3696713 Test MSE 5.934808120327267 Test RE 1.164424679081039\n",
      "32 Train Loss 1.3177264 Test MSE 5.968920874783685 Test RE 1.1677663892557002\n",
      "33 Train Loss 1.2640777 Test MSE 6.037329592466298 Test RE 1.1744391042402889\n",
      "34 Train Loss 1.2316988 Test MSE 6.025413084522975 Test RE 1.173279475179341\n",
      "35 Train Loss 1.2018424 Test MSE 6.013197212137994 Test RE 1.1720895232227067\n",
      "36 Train Loss 1.1763021 Test MSE 6.016413544920757 Test RE 1.1724029443412038\n",
      "37 Train Loss 1.1570003 Test MSE 5.9988242175372575 Test RE 1.1706878965500076\n",
      "38 Train Loss 1.1376424 Test MSE 5.9930877700264515 Test RE 1.1701280205092741\n",
      "39 Train Loss 1.1221416 Test MSE 6.006407781749273 Test RE 1.171427640077533\n",
      "40 Train Loss 1.1106015 Test MSE 6.022945551441138 Test RE 1.1730392092970694\n",
      "41 Train Loss 1.0922635 Test MSE 6.013842059826241 Test RE 1.172152368239311\n",
      "42 Train Loss 1.0703747 Test MSE 5.9953739525811995 Test RE 1.1703511835346267\n",
      "43 Train Loss 1.0529764 Test MSE 5.9716447005679125 Test RE 1.1680328050345348\n",
      "44 Train Loss 1.0375113 Test MSE 5.965987639195149 Test RE 1.1674794232424874\n",
      "45 Train Loss 1.0252383 Test MSE 5.985291651384357 Test RE 1.169366691299968\n",
      "46 Train Loss 1.0123706 Test MSE 5.999053124455515 Test RE 1.1707102322605196\n",
      "47 Train Loss 1.0005531 Test MSE 6.01869164601215 Test RE 1.1726248871670204\n",
      "48 Train Loss 0.9879112 Test MSE 6.021112867633402 Test RE 1.172860727397371\n",
      "49 Train Loss 0.9758854 Test MSE 6.05157385784502 Test RE 1.1758237533778717\n",
      "50 Train Loss 0.9636114 Test MSE 6.058361033667503 Test RE 1.1764829443868627\n",
      "51 Train Loss 0.9537406 Test MSE 6.0648502639100625 Test RE 1.1771128528222232\n",
      "52 Train Loss 0.942334 Test MSE 6.075550955960152 Test RE 1.178150831543918\n",
      "53 Train Loss 0.93406904 Test MSE 6.087686384863441 Test RE 1.179326875775655\n",
      "54 Train Loss 0.9251785 Test MSE 6.095166331264016 Test RE 1.1800511734184587\n",
      "55 Train Loss 0.9138434 Test MSE 6.1516987590233985 Test RE 1.185511006791083\n",
      "56 Train Loss 0.90548193 Test MSE 6.157722595416214 Test RE 1.1860912999148774\n",
      "57 Train Loss 0.89859784 Test MSE 6.131237100409978 Test RE 1.1835377529556124\n",
      "58 Train Loss 0.8908813 Test MSE 6.1515466172659305 Test RE 1.1854963468694635\n",
      "59 Train Loss 0.8847374 Test MSE 6.1500778191744505 Test RE 1.1853548085839012\n",
      "60 Train Loss 0.8748555 Test MSE 6.140128118704054 Test RE 1.184395576879103\n",
      "61 Train Loss 0.8691145 Test MSE 6.15050925982216 Test RE 1.1853963853974483\n",
      "62 Train Loss 0.8620193 Test MSE 6.155286555400945 Test RE 1.1858566635177619\n",
      "63 Train Loss 0.85227597 Test MSE 6.175375888678923 Test RE 1.187790258568372\n",
      "64 Train Loss 0.8469127 Test MSE 6.179238838448847 Test RE 1.1881617061417065\n",
      "65 Train Loss 0.8425059 Test MSE 6.186317784596103 Test RE 1.1888420913344535\n",
      "66 Train Loss 0.8363746 Test MSE 6.219274268163815 Test RE 1.1920045551446412\n",
      "67 Train Loss 0.8325603 Test MSE 6.216207160491255 Test RE 1.1917105934200998\n",
      "68 Train Loss 0.826915 Test MSE 6.231214063565714 Test RE 1.1931482148093961\n",
      "69 Train Loss 0.8217828 Test MSE 6.241126457452156 Test RE 1.1940968465857955\n",
      "70 Train Loss 0.81654084 Test MSE 6.23850809026011 Test RE 1.193846337961693\n",
      "71 Train Loss 0.81001407 Test MSE 6.245599698847579 Test RE 1.1945246961667066\n",
      "72 Train Loss 0.80498046 Test MSE 6.24604112526502 Test RE 1.1945669087216169\n",
      "73 Train Loss 0.80102897 Test MSE 6.251033281023323 Test RE 1.1950441928806548\n",
      "74 Train Loss 0.79566586 Test MSE 6.258192470629829 Test RE 1.1957283277552908\n",
      "75 Train Loss 0.7929028 Test MSE 6.271800894524424 Test RE 1.1970276759124405\n",
      "76 Train Loss 0.7893841 Test MSE 6.2758280633247425 Test RE 1.1974119243123966\n",
      "77 Train Loss 0.78617233 Test MSE 6.2850535809329005 Test RE 1.1982917036786274\n",
      "78 Train Loss 0.7822614 Test MSE 6.29936968057534 Test RE 1.1996556622733794\n",
      "79 Train Loss 0.7777196 Test MSE 6.317687129406821 Test RE 1.2013985890203671\n",
      "80 Train Loss 0.7737816 Test MSE 6.335387897440232 Test RE 1.203080438936212\n",
      "81 Train Loss 0.76979244 Test MSE 6.323843148326768 Test RE 1.2019837740355874\n",
      "82 Train Loss 0.766025 Test MSE 6.320219447036558 Test RE 1.2016393431098487\n",
      "83 Train Loss 0.7613036 Test MSE 6.350174197540275 Test RE 1.2044835685630202\n",
      "84 Train Loss 0.7573397 Test MSE 6.351534302553639 Test RE 1.2046125521450646\n",
      "85 Train Loss 0.75218546 Test MSE 6.354012774208871 Test RE 1.204847558894886\n",
      "86 Train Loss 0.7481409 Test MSE 6.354091302031868 Test RE 1.2048550040926593\n",
      "87 Train Loss 0.74107116 Test MSE 6.354135711158706 Test RE 1.2048592144874009\n",
      "88 Train Loss 0.738733 Test MSE 6.350213535999006 Test RE 1.2044872993625462\n",
      "89 Train Loss 0.7349647 Test MSE 6.356973935978772 Test RE 1.2051282738606819\n",
      "90 Train Loss 0.73232585 Test MSE 6.372854878537665 Test RE 1.2066326559011586\n",
      "91 Train Loss 0.72731006 Test MSE 6.383753392687968 Test RE 1.2076639743452808\n",
      "92 Train Loss 0.72386944 Test MSE 6.387446131593833 Test RE 1.2080132158285748\n",
      "93 Train Loss 0.72052324 Test MSE 6.386402871808657 Test RE 1.2079145595701717\n",
      "94 Train Loss 0.7183825 Test MSE 6.402594789850021 Test RE 1.2094448476396227\n",
      "95 Train Loss 0.71575296 Test MSE 6.403271489524546 Test RE 1.2095087599546657\n",
      "96 Train Loss 0.7123919 Test MSE 6.432329151668394 Test RE 1.212249992708689\n",
      "97 Train Loss 0.70939434 Test MSE 6.446041636897114 Test RE 1.2135414463890775\n",
      "98 Train Loss 0.7064183 Test MSE 6.442948910223899 Test RE 1.213250290785522\n",
      "99 Train Loss 0.7030382 Test MSE 6.448789615392706 Test RE 1.2138000880992115\n",
      "100 Train Loss 0.7003721 Test MSE 6.453560845399831 Test RE 1.214249028826589\n",
      "101 Train Loss 0.69755036 Test MSE 6.457403588159241 Test RE 1.2146104844933279\n",
      "102 Train Loss 0.6948637 Test MSE 6.469847186101105 Test RE 1.21578021548431\n",
      "103 Train Loss 0.6911989 Test MSE 6.4640431345145615 Test RE 1.2152347594504815\n",
      "104 Train Loss 0.68891656 Test MSE 6.474531824340191 Test RE 1.2162202923292573\n",
      "105 Train Loss 0.686275 Test MSE 6.475776317483092 Test RE 1.2163371737601893\n",
      "106 Train Loss 0.68191326 Test MSE 6.475679384089642 Test RE 1.2163280702855426\n",
      "107 Train Loss 0.679515 Test MSE 6.482671424614149 Test RE 1.2169845512663484\n",
      "108 Train Loss 0.67697275 Test MSE 6.48449057617192 Test RE 1.2171552929178717\n",
      "109 Train Loss 0.6738661 Test MSE 6.483131880054866 Test RE 1.2170277708876296\n",
      "110 Train Loss 0.6711961 Test MSE 6.510465112482581 Test RE 1.219590599717031\n",
      "111 Train Loss 0.66922855 Test MSE 6.506493381742725 Test RE 1.2192185353273333\n",
      "112 Train Loss 0.66696423 Test MSE 6.519166058333835 Test RE 1.220405291791495\n",
      "113 Train Loss 0.6638099 Test MSE 6.513898616728747 Test RE 1.219912152592022\n",
      "114 Train Loss 0.66206753 Test MSE 6.519085630465247 Test RE 1.2203977636124081\n",
      "115 Train Loss 0.65992707 Test MSE 6.540106361961137 Test RE 1.2223637607201179\n",
      "116 Train Loss 0.6577504 Test MSE 6.541643289834191 Test RE 1.2225073802937847\n",
      "117 Train Loss 0.6554868 Test MSE 6.549516677956726 Test RE 1.223242851505444\n",
      "118 Train Loss 0.65377265 Test MSE 6.557192576566309 Test RE 1.223959449317456\n",
      "119 Train Loss 0.65200824 Test MSE 6.565948831360426 Test RE 1.2247763938540681\n",
      "120 Train Loss 0.64936054 Test MSE 6.571299636505183 Test RE 1.2252753472702689\n",
      "121 Train Loss 0.6471083 Test MSE 6.562841593215055 Test RE 1.2244865559053315\n",
      "122 Train Loss 0.6445328 Test MSE 6.569548240038504 Test RE 1.225112054920431\n",
      "123 Train Loss 0.6418125 Test MSE 6.575261372371785 Test RE 1.225644641484912\n",
      "124 Train Loss 0.64017946 Test MSE 6.584417538812114 Test RE 1.2264977104077233\n",
      "125 Train Loss 0.63830954 Test MSE 6.567914610057673 Test RE 1.2249597229681854\n",
      "126 Train Loss 0.63620365 Test MSE 6.581175024189013 Test RE 1.2261956771244658\n",
      "127 Train Loss 0.63471955 Test MSE 6.589966258183512 Test RE 1.2270143892493615\n",
      "128 Train Loss 0.6333343 Test MSE 6.594970258771055 Test RE 1.227480159129584\n",
      "129 Train Loss 0.632244 Test MSE 6.599081579050984 Test RE 1.227862706556523\n",
      "130 Train Loss 0.6298318 Test MSE 6.597210555489338 Test RE 1.22768862756603\n",
      "131 Train Loss 0.6280624 Test MSE 6.592882096822737 Test RE 1.227285815547541\n",
      "132 Train Loss 0.6267031 Test MSE 6.600467903027159 Test RE 1.2279916734513026\n",
      "133 Train Loss 0.6253066 Test MSE 6.601602667335161 Test RE 1.22809722818278\n",
      "134 Train Loss 0.624002 Test MSE 6.6090675506091205 Test RE 1.2287913787379456\n",
      "135 Train Loss 0.62284046 Test MSE 6.610722798644703 Test RE 1.2289452451619647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 Train Loss 0.6216564 Test MSE 6.614680726516665 Test RE 1.2293130830639654\n",
      "137 Train Loss 0.6207603 Test MSE 6.615054898475578 Test RE 1.2293478517851462\n",
      "138 Train Loss 0.6196679 Test MSE 6.622660917382342 Test RE 1.230054403499095\n",
      "139 Train Loss 0.61881524 Test MSE 6.625013135068182 Test RE 1.2302728277012942\n",
      "140 Train Loss 0.6176499 Test MSE 6.617821699851826 Test RE 1.229604917357004\n",
      "141 Train Loss 0.61652017 Test MSE 6.615544161818576 Test RE 1.229393313518097\n",
      "142 Train Loss 0.6153539 Test MSE 6.622763109985733 Test RE 1.2300638937914756\n",
      "143 Train Loss 0.614015 Test MSE 6.6281803869482765 Test RE 1.2305668737842046\n",
      "144 Train Loss 0.61270213 Test MSE 6.628613412564585 Test RE 1.23060707020652\n",
      "145 Train Loss 0.61137444 Test MSE 6.6261404911374315 Test RE 1.2303774989308072\n",
      "146 Train Loss 0.61006594 Test MSE 6.6378486392922165 Test RE 1.2314640352188935\n",
      "147 Train Loss 0.6089291 Test MSE 6.638809256699491 Test RE 1.2315531396152781\n",
      "148 Train Loss 0.6078887 Test MSE 6.651585183963066 Test RE 1.2327375892763672\n",
      "149 Train Loss 0.60668397 Test MSE 6.659756484977984 Test RE 1.2334945500539807\n",
      "Training time: 234.71\n",
      "4\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 52.99119 Test MSE 7.367666063635657 Test RE 1.297397411131314\n",
      "1 Train Loss 41.898693 Test MSE 7.783338241130556 Test RE 1.3334938352777468\n",
      "2 Train Loss 30.742723 Test MSE 7.679627206710084 Test RE 1.3245798055560984\n",
      "3 Train Loss 22.90604 Test MSE 6.768188807806569 Test RE 1.2434957148186234\n",
      "4 Train Loss 19.94317 Test MSE 6.718206438568829 Test RE 1.2388956632020367\n",
      "5 Train Loss 15.197722 Test MSE 6.322095244384231 Test RE 1.201817648997097\n",
      "6 Train Loss 12.816326 Test MSE 5.993332005405052 Test RE 1.170151863289446\n",
      "7 Train Loss 11.059246 Test MSE 5.688859170845764 Test RE 1.140041475858374\n",
      "8 Train Loss 9.092695 Test MSE 5.1710384791068265 Test RE 1.0869184105422764\n",
      "9 Train Loss 8.087947 Test MSE 5.129565678599285 Test RE 1.0825509805098903\n",
      "10 Train Loss 6.955387 Test MSE 4.606738289206007 Test RE 1.025899529237249\n",
      "11 Train Loss 5.568243 Test MSE 4.249236265523118 Test RE 0.985288695322677\n",
      "12 Train Loss 4.0662775 Test MSE 3.5750224803077733 Test RE 0.9037482072666375\n",
      "13 Train Loss 3.4619465 Test MSE 3.359224255603602 Test RE 0.8760473072195437\n",
      "14 Train Loss 2.8681104 Test MSE 2.8348949245525055 Test RE 0.8047788297924839\n",
      "15 Train Loss 2.5254521 Test MSE 2.364049946350804 Test RE 0.7349137690115999\n",
      "16 Train Loss 2.2051628 Test MSE 2.2161567116365326 Test RE 0.7115547039549218\n",
      "17 Train Loss 1.9639459 Test MSE 1.939206293518069 Test RE 0.6656103496911553\n",
      "18 Train Loss 1.8229996 Test MSE 1.5785036891136435 Test RE 0.6005246805678681\n",
      "19 Train Loss 1.629002 Test MSE 1.48388445353009 Test RE 0.5822481303920545\n",
      "20 Train Loss 1.4716948 Test MSE 1.2292625069394527 Test RE 0.529944486443571\n",
      "21 Train Loss 1.2897421 Test MSE 0.9778145762552444 Test RE 0.4726463558352615\n",
      "22 Train Loss 1.0725225 Test MSE 0.8121488998333665 Test RE 0.4307505993950552\n",
      "23 Train Loss 0.9608818 Test MSE 0.6085759592312426 Test RE 0.3728768803333891\n",
      "24 Train Loss 0.850653 Test MSE 0.42548166582453295 Test RE 0.3117801672834713\n",
      "25 Train Loss 0.6657053 Test MSE 0.2918113095791071 Test RE 0.25820171352528615\n",
      "26 Train Loss 0.57115364 Test MSE 0.24176168139170928 Test RE 0.23501836142275678\n",
      "27 Train Loss 0.5090304 Test MSE 0.16634167211177694 Test RE 0.19494342485876734\n",
      "28 Train Loss 0.4223563 Test MSE 0.1260718816808566 Test RE 0.1697138078330086\n",
      "29 Train Loss 0.33896998 Test MSE 0.06020982506004427 Test RE 0.11728480306695457\n",
      "30 Train Loss 0.28608787 Test MSE 0.028667107020807662 Test RE 0.08092822109549923\n",
      "31 Train Loss 0.23599268 Test MSE 0.02977206333049086 Test RE 0.08247313954017549\n",
      "32 Train Loss 0.21258253 Test MSE 0.03516443166724145 Test RE 0.08963133430118053\n",
      "33 Train Loss 0.18187757 Test MSE 0.04044712526737544 Test RE 0.09612843907036955\n",
      "34 Train Loss 0.16052873 Test MSE 0.0451131989070438 Test RE 0.10152193153216986\n",
      "35 Train Loss 0.13424726 Test MSE 0.04231361837768423 Test RE 0.09832142011975495\n",
      "36 Train Loss 0.12389737 Test MSE 0.04460037927634812 Test RE 0.1009432623040058\n",
      "37 Train Loss 0.10771275 Test MSE 0.03415973817361519 Test RE 0.08834161346363673\n",
      "38 Train Loss 0.09929976 Test MSE 0.029761701527644287 Test RE 0.08245878640698473\n",
      "39 Train Loss 0.08735679 Test MSE 0.02520192897404486 Test RE 0.07587958586165669\n",
      "40 Train Loss 0.07605785 Test MSE 0.023779868768239867 Test RE 0.07370768770132152\n",
      "41 Train Loss 0.07053642 Test MSE 0.027039713411827725 Test RE 0.07859756697023827\n",
      "42 Train Loss 0.067104235 Test MSE 0.02694180248965211 Test RE 0.07845513684900719\n",
      "43 Train Loss 0.061570548 Test MSE 0.023577968061678417 Test RE 0.07339411665184668\n",
      "44 Train Loss 0.054180883 Test MSE 0.024497033942530604 Test RE 0.0748108884188131\n",
      "45 Train Loss 0.051002625 Test MSE 0.024444567128450473 Test RE 0.0747307319213327\n",
      "46 Train Loss 0.048876137 Test MSE 0.02456175174188989 Test RE 0.07490964328413577\n",
      "47 Train Loss 0.046399567 Test MSE 0.021558120938791583 Test RE 0.07018002397609467\n",
      "48 Train Loss 0.041433904 Test MSE 0.017762556495889245 Test RE 0.06370313364580166\n",
      "49 Train Loss 0.039972164 Test MSE 0.01601459904073142 Test RE 0.06048756406659542\n",
      "50 Train Loss 0.037469093 Test MSE 0.013875055759372071 Test RE 0.05630220825150236\n",
      "51 Train Loss 0.033338048 Test MSE 0.01482577417127717 Test RE 0.05819916457465905\n",
      "52 Train Loss 0.031750575 Test MSE 0.014047812962393305 Test RE 0.056651631089996414\n",
      "53 Train Loss 0.026742123 Test MSE 0.011262697017136503 Test RE 0.05072584155678236\n",
      "54 Train Loss 0.024751646 Test MSE 0.011603382845607395 Test RE 0.0514873300145398\n",
      "55 Train Loss 0.023527022 Test MSE 0.01009162387975506 Test RE 0.048016288573527605\n",
      "56 Train Loss 0.023027234 Test MSE 0.010102202417724037 Test RE 0.04804144850294419\n",
      "57 Train Loss 0.022176027 Test MSE 0.010304969535058854 Test RE 0.04852118696351109\n",
      "58 Train Loss 0.021067804 Test MSE 0.009735094929594741 Test RE 0.04716047337378473\n",
      "59 Train Loss 0.020384379 Test MSE 0.00948863485631763 Test RE 0.04655967363848417\n",
      "60 Train Loss 0.019951703 Test MSE 0.00996820317229881 Test RE 0.04772176534209528\n",
      "61 Train Loss 0.018548727 Test MSE 0.009014402794447242 Test RE 0.04538125900181329\n",
      "62 Train Loss 0.017038966 Test MSE 0.008629711355082966 Test RE 0.044402374470838286\n",
      "63 Train Loss 0.016769677 Test MSE 0.00802498932191018 Test RE 0.042818385896337643\n",
      "64 Train Loss 0.01596623 Test MSE 0.0077375694282909935 Test RE 0.04204461109977455\n",
      "65 Train Loss 0.01391718 Test MSE 0.008907114421842737 Test RE 0.045110389393995295\n",
      "66 Train Loss 0.01317133 Test MSE 0.009621031035820345 Test RE 0.04688337503593914\n",
      "67 Train Loss 0.012886902 Test MSE 0.01020207648252847 Test RE 0.04827834209677624\n",
      "68 Train Loss 0.012314677 Test MSE 0.009420819551501373 Test RE 0.04639299421883616\n",
      "69 Train Loss 0.011602076 Test MSE 0.008435793073990094 Test RE 0.04390065695838205\n",
      "70 Train Loss 0.011244042 Test MSE 0.008852672660158606 Test RE 0.04497231699673283\n",
      "71 Train Loss 0.010907925 Test MSE 0.009069547662017813 Test RE 0.04551985542138462\n",
      "72 Train Loss 0.010335204 Test MSE 0.008823129527566542 Test RE 0.044897213494178474\n",
      "73 Train Loss 0.009170776 Test MSE 0.0075607007311441635 Test RE 0.04156129625693752\n",
      "74 Train Loss 0.008525086 Test MSE 0.0068311411922224495 Test RE 0.039505238785440454\n",
      "75 Train Loss 0.00822913 Test MSE 0.006441050890300692 Test RE 0.03836069134570663\n",
      "76 Train Loss 0.007891638 Test MSE 0.006552171002302639 Test RE 0.038690173028879664\n",
      "77 Train Loss 0.00782306 Test MSE 0.006117395755606609 Test RE 0.0373844804127022\n",
      "78 Train Loss 0.007631674 Test MSE 0.005967176741557065 Test RE 0.03692262002812002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 Train Loss 0.0072015924 Test MSE 0.005367457410449461 Test RE 0.03501808268348493\n",
      "80 Train Loss 0.006755134 Test MSE 0.0049583425445202285 Test RE 0.03365707135851341\n",
      "81 Train Loss 0.006653414 Test MSE 0.004789824469978728 Test RE 0.03308017965228295\n",
      "82 Train Loss 0.0065546683 Test MSE 0.004818253140599958 Test RE 0.03317820352085204\n",
      "83 Train Loss 0.0059520346 Test MSE 0.003574526225052641 Test RE 0.02857704404079059\n",
      "84 Train Loss 0.005776531 Test MSE 0.0032030539713910153 Test RE 0.027051427553768517\n",
      "85 Train Loss 0.0053603994 Test MSE 0.003209361859537137 Test RE 0.02707805112189768\n",
      "86 Train Loss 0.0052183475 Test MSE 0.0028637211772337087 Test RE 0.0255784030144062\n",
      "87 Train Loss 0.0051216274 Test MSE 0.00259601563924643 Test RE 0.024353518347563188\n",
      "88 Train Loss 0.004946707 Test MSE 0.002203607072816674 Test RE 0.022437534779195932\n",
      "89 Train Loss 0.0047932887 Test MSE 0.0022411773877340914 Test RE 0.02262800032419146\n",
      "90 Train Loss 0.0045951307 Test MSE 0.0023825807199913127 Test RE 0.02333092039358392\n",
      "91 Train Loss 0.0044635884 Test MSE 0.0023223186317041914 Test RE 0.023033978839117345\n",
      "92 Train Loss 0.004350456 Test MSE 0.0025681624385873133 Test RE 0.02422251899637049\n",
      "93 Train Loss 0.0043177973 Test MSE 0.0025701079746567775 Test RE 0.024231692260087062\n",
      "94 Train Loss 0.004178299 Test MSE 0.002326395581837765 Test RE 0.023054188642093774\n",
      "95 Train Loss 0.0038089834 Test MSE 0.001793030811956698 Test RE 0.020239600532463695\n",
      "96 Train Loss 0.0035736745 Test MSE 0.001564514062215084 Test RE 0.018905919126987494\n",
      "97 Train Loss 0.0034862217 Test MSE 0.001545220326074336 Test RE 0.01878898269484416\n",
      "98 Train Loss 0.003429236 Test MSE 0.0015989397500464017 Test RE 0.019112790963030712\n",
      "99 Train Loss 0.003404404 Test MSE 0.0016654453076199072 Test RE 0.019506225831164972\n",
      "100 Train Loss 0.0033743763 Test MSE 0.00170588825200751 Test RE 0.01974164551899457\n",
      "101 Train Loss 0.0033579809 Test MSE 0.0017719416468422516 Test RE 0.02012022199339305\n",
      "102 Train Loss 0.0032989462 Test MSE 0.0017388318632615104 Test RE 0.0199313564090773\n",
      "103 Train Loss 0.0031499101 Test MSE 0.001558900141340648 Test RE 0.018871968739567018\n",
      "104 Train Loss 0.0030011786 Test MSE 0.0014837946835957112 Test RE 0.018411745605046347\n",
      "105 Train Loss 0.0028828792 Test MSE 0.0014788808761852772 Test RE 0.0183812337020287\n",
      "106 Train Loss 0.0028059806 Test MSE 0.001382360647584214 Test RE 0.017771281297911216\n",
      "107 Train Loss 0.002786599 Test MSE 0.0014248292487892761 Test RE 0.01804219910336709\n",
      "108 Train Loss 0.0027549025 Test MSE 0.001446007510347913 Test RE 0.018175791602795487\n",
      "109 Train Loss 0.0026908983 Test MSE 0.0013402982800795162 Test RE 0.017498821071024556\n",
      "110 Train Loss 0.002540731 Test MSE 0.0011431842777517806 Test RE 0.016160923770996302\n",
      "111 Train Loss 0.002395099 Test MSE 0.001078352451131028 Test RE 0.015695979585952688\n",
      "112 Train Loss 0.0023392653 Test MSE 0.001030274820538107 Test RE 0.015342092726936714\n",
      "113 Train Loss 0.002294013 Test MSE 0.000984467419982034 Test RE 0.014997149968544015\n",
      "114 Train Loss 0.002244072 Test MSE 0.0009339752549114844 Test RE 0.014607494965134011\n",
      "115 Train Loss 0.002206958 Test MSE 0.000862794391658413 Test RE 0.014039825725837094\n",
      "116 Train Loss 0.0021443502 Test MSE 0.0009050967529118568 Test RE 0.014379889993613126\n",
      "117 Train Loss 0.0020956106 Test MSE 0.0009630233344344541 Test RE 0.014832913547108967\n",
      "118 Train Loss 0.0020525374 Test MSE 0.0009673844728516392 Test RE 0.01486646170495358\n",
      "119 Train Loss 0.0019715126 Test MSE 0.0010356261929481303 Test RE 0.015381885467237892\n",
      "120 Train Loss 0.0019391899 Test MSE 0.001061514383271027 Test RE 0.015572954038744195\n",
      "121 Train Loss 0.0019194057 Test MSE 0.0011070794445277438 Test RE 0.015903673599553993\n",
      "122 Train Loss 0.0019058377 Test MSE 0.0010962967572177998 Test RE 0.015826035115567252\n",
      "123 Train Loss 0.0018956362 Test MSE 0.0010806544572037253 Test RE 0.01571272410096402\n",
      "124 Train Loss 0.0018504364 Test MSE 0.0009663091737599779 Test RE 0.014858196977754305\n",
      "125 Train Loss 0.0017752657 Test MSE 0.0008888791764754125 Test RE 0.014250477815524689\n",
      "126 Train Loss 0.0016821609 Test MSE 0.0007317683859544743 Test RE 0.012929891537320538\n",
      "127 Train Loss 0.0016251728 Test MSE 0.0006103287861087966 Test RE 0.011808370937611253\n",
      "128 Train Loss 0.0015651191 Test MSE 0.0004933672437307103 Test RE 0.01061678973393136\n",
      "129 Train Loss 0.0015365107 Test MSE 0.0004587929424994285 Test RE 0.010238030631514275\n",
      "130 Train Loss 0.0014915814 Test MSE 0.0004406509250334202 Test RE 0.01003356811582792\n",
      "131 Train Loss 0.001469228 Test MSE 0.00044199323187375225 Test RE 0.010048838577457319\n",
      "132 Train Loss 0.0014537738 Test MSE 0.0004454434321076976 Test RE 0.010087982964743641\n",
      "133 Train Loss 0.0014307047 Test MSE 0.00043282715176795735 Test RE 0.009944096007885999\n",
      "134 Train Loss 0.0014171385 Test MSE 0.00043702017869389154 Test RE 0.009992146789633484\n",
      "135 Train Loss 0.001388582 Test MSE 0.0004167769334085353 Test RE 0.009757979417191984\n",
      "136 Train Loss 0.0013562243 Test MSE 0.00040245090871808006 Test RE 0.009588805654473587\n",
      "137 Train Loss 0.0013284272 Test MSE 0.0003748005241732961 Test RE 0.009253545293982805\n",
      "138 Train Loss 0.0012962575 Test MSE 0.0003601515989422789 Test RE 0.009070907408460154\n",
      "139 Train Loss 0.001279064 Test MSE 0.0003558575799140119 Test RE 0.009016669905770332\n",
      "140 Train Loss 0.0012603626 Test MSE 0.0003677540688456109 Test RE 0.00916614669723262\n",
      "141 Train Loss 0.0012408018 Test MSE 0.00038204759935615 Test RE 0.009342579407221965\n",
      "142 Train Loss 0.0012005066 Test MSE 0.0003803761143708866 Test RE 0.009322119785242994\n",
      "143 Train Loss 0.0011634517 Test MSE 0.0003534711374740964 Test RE 0.00898638537358572\n",
      "144 Train Loss 0.0011368301 Test MSE 0.00035033910285577313 Test RE 0.008946483535642416\n",
      "145 Train Loss 0.0011107838 Test MSE 0.00033956247973841524 Test RE 0.00880780941074177\n",
      "146 Train Loss 0.0010883454 Test MSE 0.0003515906541633801 Test RE 0.008962449496726616\n",
      "147 Train Loss 0.0010534921 Test MSE 0.0003630342691677597 Test RE 0.009107137040391948\n",
      "148 Train Loss 0.0010314354 Test MSE 0.00034221988335347115 Test RE 0.008842207041281804\n",
      "149 Train Loss 0.0010208688 Test MSE 0.0003529092073697396 Test RE 0.008979239487432563\n",
      "Training time: 232.37\n",
      "5\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 68.04628 Test MSE 4.9596594244024415 Test RE 1.0644713762851898\n",
      "1 Train Loss 47.057747 Test MSE 7.432628397595519 Test RE 1.3031045777275887\n",
      "2 Train Loss 34.291782 Test MSE 8.115344122368592 Test RE 1.361637584381992\n",
      "3 Train Loss 29.966335 Test MSE 8.236990071065408 Test RE 1.3718048422689275\n",
      "4 Train Loss 28.620758 Test MSE 8.231374248635706 Test RE 1.3713371273717536\n",
      "5 Train Loss 27.299868 Test MSE 8.859621065286417 Test RE 1.4227075421293602\n",
      "6 Train Loss 25.920563 Test MSE 9.12244530009219 Test RE 1.443655913815876\n",
      "7 Train Loss 24.639423 Test MSE 9.198479999390186 Test RE 1.4496597955419135\n",
      "8 Train Loss 23.080582 Test MSE 8.971134076083269 Test RE 1.4316331100543567\n",
      "9 Train Loss 21.627663 Test MSE 8.960647051808982 Test RE 1.4307960942860398\n",
      "10 Train Loss 19.81302 Test MSE 9.004399369676177 Test RE 1.4342849280619359\n",
      "11 Train Loss 18.181309 Test MSE 9.175970682267018 Test RE 1.4478850001946806\n",
      "12 Train Loss 16.377811 Test MSE 8.82306056187723 Test RE 1.4197690035441204\n",
      "13 Train Loss 14.632341 Test MSE 8.824909457820496 Test RE 1.4199177539481223\n",
      "14 Train Loss 12.796019 Test MSE 8.309598216529592 Test RE 1.3778377296971323\n",
      "15 Train Loss 10.873663 Test MSE 7.460775464949199 Test RE 1.305569648687774\n",
      "16 Train Loss 9.160677 Test MSE 7.191193842908836 Test RE 1.2817654413656867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 Train Loss 8.355574 Test MSE 7.290755577905387 Test RE 1.290607931242677\n",
      "18 Train Loss 7.69173 Test MSE 7.084315349316862 Test RE 1.2722047207935179\n",
      "19 Train Loss 6.179116 Test MSE 6.179958779235335 Test RE 1.188230920261864\n",
      "20 Train Loss 5.083574 Test MSE 6.08863992506595 Test RE 1.1794192336506433\n",
      "21 Train Loss 4.4687133 Test MSE 6.469122829148288 Test RE 1.2157121548734773\n",
      "22 Train Loss 4.1250134 Test MSE 6.504027309804456 Test RE 1.2189874611226912\n",
      "23 Train Loss 3.8291879 Test MSE 6.481488701144669 Test RE 1.2168735305348555\n",
      "24 Train Loss 3.6121802 Test MSE 6.61068920229839 Test RE 1.2289421223474275\n",
      "25 Train Loss 3.392642 Test MSE 6.5783920954289785 Test RE 1.225936393939912\n",
      "26 Train Loss 3.2205598 Test MSE 6.646849460056098 Test RE 1.232298675529999\n",
      "27 Train Loss 3.0886953 Test MSE 6.71319298598919 Test RE 1.238433314812437\n",
      "28 Train Loss 2.9975085 Test MSE 6.854227721825651 Test RE 1.2513745691382068\n",
      "29 Train Loss 2.9319673 Test MSE 6.833964819001293 Test RE 1.2495235036219698\n",
      "30 Train Loss 2.8633018 Test MSE 6.806378389203832 Test RE 1.2469989992112818\n",
      "31 Train Loss 2.810221 Test MSE 6.795106266071408 Test RE 1.2459659864990305\n",
      "32 Train Loss 2.7342155 Test MSE 6.839033841848335 Test RE 1.2499868283003581\n",
      "33 Train Loss 2.682561 Test MSE 6.858802904639969 Test RE 1.251792144434287\n",
      "34 Train Loss 2.60698 Test MSE 6.853218527526403 Test RE 1.251282441576819\n",
      "35 Train Loss 2.567391 Test MSE 6.858834115061224 Test RE 1.2517949925198968\n",
      "36 Train Loss 2.5230346 Test MSE 6.8399230331768095 Test RE 1.2500680854887793\n",
      "37 Train Loss 2.4878652 Test MSE 6.833869269092666 Test RE 1.2495147684091696\n",
      "38 Train Loss 2.4447653 Test MSE 6.940040031150408 Test RE 1.2591835692153355\n",
      "39 Train Loss 2.3896112 Test MSE 6.938088308981926 Test RE 1.2590064989618992\n",
      "40 Train Loss 2.3729467 Test MSE 6.973978790191063 Test RE 1.262258696174072\n",
      "41 Train Loss 2.3483799 Test MSE 6.971290713577291 Test RE 1.2620154078587402\n",
      "42 Train Loss 2.3173416 Test MSE 6.970215414032022 Test RE 1.2619180731624875\n",
      "43 Train Loss 2.290139 Test MSE 7.0305747283269895 Test RE 1.2673701516064455\n",
      "44 Train Loss 2.2646608 Test MSE 7.086794703171483 Test RE 1.2724273230911332\n",
      "45 Train Loss 2.2302232 Test MSE 7.067939780045365 Test RE 1.2707335038528738\n",
      "46 Train Loss 2.197685 Test MSE 7.094462028860222 Test RE 1.2731154675703484\n",
      "47 Train Loss 2.178227 Test MSE 7.164147354473144 Test RE 1.2793527743756143\n",
      "48 Train Loss 2.14522 Test MSE 7.173785136990845 Test RE 1.2802130288562554\n",
      "49 Train Loss 2.1343164 Test MSE 7.146737839171055 Test RE 1.2777973583327258\n",
      "50 Train Loss 2.1097097 Test MSE 7.2014434460374295 Test RE 1.2826785657682356\n",
      "51 Train Loss 2.0932343 Test MSE 7.213963003158175 Test RE 1.2837930363866685\n",
      "52 Train Loss 2.0782125 Test MSE 7.202889060798766 Test RE 1.2828073014888004\n",
      "53 Train Loss 2.0524445 Test MSE 7.195284722403712 Test RE 1.2821299707163787\n",
      "54 Train Loss 2.042973 Test MSE 7.182917732583042 Test RE 1.2810276580223776\n",
      "55 Train Loss 2.0186257 Test MSE 7.217677000753803 Test RE 1.284123464386015\n",
      "56 Train Loss 2.0039515 Test MSE 7.2161761615559685 Test RE 1.2839899475336483\n",
      "57 Train Loss 1.9929314 Test MSE 7.24891941739433 Test RE 1.2868996899721121\n",
      "58 Train Loss 1.9757648 Test MSE 7.208342629816896 Test RE 1.2832928396103285\n",
      "59 Train Loss 1.9646983 Test MSE 7.211984705489644 Test RE 1.283616995914059\n",
      "60 Train Loss 1.939188 Test MSE 7.249209518898786 Test RE 1.2869254405550294\n",
      "61 Train Loss 1.9265703 Test MSE 7.232936607018103 Test RE 1.2854801940058693\n",
      "62 Train Loss 1.9017345 Test MSE 7.190782457604086 Test RE 1.281728777981294\n",
      "63 Train Loss 1.8824428 Test MSE 7.133907264812929 Test RE 1.2766498250488347\n",
      "64 Train Loss 1.8674245 Test MSE 7.149971172959693 Test RE 1.2780863767823294\n",
      "65 Train Loss 1.8502116 Test MSE 7.130131834320967 Test RE 1.2763119638762541\n",
      "66 Train Loss 1.8294994 Test MSE 7.141313352722204 Test RE 1.2773123321313025\n",
      "67 Train Loss 1.8100903 Test MSE 7.146925760634191 Test RE 1.2778141578835198\n",
      "68 Train Loss 1.78241 Test MSE 7.1059121557084675 Test RE 1.2741424275073001\n",
      "69 Train Loss 1.7631752 Test MSE 7.0750448612915156 Test RE 1.2713720489721245\n",
      "70 Train Loss 1.7365762 Test MSE 7.077638941662319 Test RE 1.2716051032557234\n",
      "71 Train Loss 1.7211045 Test MSE 7.05672472000883 Test RE 1.269724934821004\n",
      "72 Train Loss 1.7029638 Test MSE 7.035253022885546 Test RE 1.267791749064581\n",
      "73 Train Loss 1.6828859 Test MSE 7.019807546321595 Test RE 1.2663993039682842\n",
      "74 Train Loss 1.665249 Test MSE 7.028125703960828 Test RE 1.267149395064854\n",
      "75 Train Loss 1.6476824 Test MSE 6.953888973690309 Test RE 1.2604393018817044\n",
      "76 Train Loss 1.6275228 Test MSE 6.907427888342339 Test RE 1.2562215524310067\n",
      "77 Train Loss 1.6131347 Test MSE 6.832024527259462 Test RE 1.2493461093632898\n",
      "78 Train Loss 1.5997239 Test MSE 6.793603093836906 Test RE 1.2458281663537567\n",
      "79 Train Loss 1.5853722 Test MSE 6.7562294021232026 Test RE 1.242396599129577\n",
      "80 Train Loss 1.5676949 Test MSE 6.745289604275094 Test RE 1.2413903371146426\n",
      "81 Train Loss 1.5531619 Test MSE 6.694672405263129 Test RE 1.236723819376636\n",
      "82 Train Loss 1.5281237 Test MSE 6.622786344510176 Test RE 1.2300660514954476\n",
      "83 Train Loss 1.5064601 Test MSE 6.6165855725319185 Test RE 1.2294900744915191\n",
      "84 Train Loss 1.4894121 Test MSE 6.621919493814007 Test RE 1.2299855477277646\n",
      "85 Train Loss 1.471996 Test MSE 6.560558804222605 Test RE 1.2242735774641273\n",
      "86 Train Loss 1.4560635 Test MSE 6.530252397870871 Test RE 1.2214425471763295\n",
      "87 Train Loss 1.4425496 Test MSE 6.540313926733135 Test RE 1.2223831577779174\n",
      "88 Train Loss 1.4289443 Test MSE 6.479101372251138 Test RE 1.2166494041782816\n",
      "89 Train Loss 1.4145844 Test MSE 6.467982990696143 Test RE 1.2156050478867588\n",
      "90 Train Loss 1.387144 Test MSE 6.420033043983019 Test RE 1.211090763562233\n",
      "91 Train Loss 1.3727554 Test MSE 6.432731673737558 Test RE 1.2122879221841787\n",
      "92 Train Loss 1.3582864 Test MSE 6.402763288721988 Test RE 1.2094607621835258\n",
      "93 Train Loss 1.342547 Test MSE 6.37276154398157 Test RE 1.2066238199133785\n",
      "94 Train Loss 1.3163582 Test MSE 6.305339797369277 Test RE 1.2002240039208876\n",
      "95 Train Loss 1.3051614 Test MSE 6.262144031432089 Test RE 1.1961057728068312\n",
      "96 Train Loss 1.2914655 Test MSE 6.215952493458242 Test RE 1.191686182030516\n",
      "97 Train Loss 1.2795783 Test MSE 6.206029904174736 Test RE 1.1907346516528614\n",
      "98 Train Loss 1.2669436 Test MSE 6.2120825675441536 Test RE 1.1913151644544326\n",
      "99 Train Loss 1.2537711 Test MSE 6.211156269909043 Test RE 1.1912263412983188\n",
      "100 Train Loss 1.2387377 Test MSE 6.214179769409994 Test RE 1.191516241752302\n",
      "101 Train Loss 1.2243204 Test MSE 6.209769913418891 Test RE 1.1910933904867886\n",
      "102 Train Loss 1.2121344 Test MSE 6.19122545469993 Test RE 1.1893135582328802\n",
      "103 Train Loss 1.1973823 Test MSE 6.166768687159564 Test RE 1.186962202497946\n",
      "104 Train Loss 1.1832777 Test MSE 6.1951628467034405 Test RE 1.1896916779963713\n",
      "105 Train Loss 1.1676122 Test MSE 6.179834058823381 Test RE 1.1882189301011783\n",
      "106 Train Loss 1.1548318 Test MSE 6.1595734993709526 Test RE 1.1862695456947225\n",
      "107 Train Loss 1.1485815 Test MSE 6.16845606151263 Test RE 1.187124581913495\n",
      "108 Train Loss 1.1414953 Test MSE 6.1483353815624655 Test RE 1.185186879561209\n",
      "109 Train Loss 1.1286106 Test MSE 6.137135435653158 Test RE 1.1841069059830855\n",
      "110 Train Loss 1.1166639 Test MSE 6.13746040783535 Test RE 1.184138255846175\n",
      "111 Train Loss 1.1085775 Test MSE 6.121207378809958 Test RE 1.1825693176686791\n",
      "112 Train Loss 1.10298 Test MSE 6.127990418593412 Test RE 1.1832243513317764\n",
      "113 Train Loss 1.0924529 Test MSE 6.1144884451817765 Test RE 1.1819201167976836\n",
      "114 Train Loss 1.0838116 Test MSE 6.130415051333018 Test RE 1.1834584085496611\n",
      "115 Train Loss 1.0784637 Test MSE 6.132248908698503 Test RE 1.1836354056713476\n",
      "116 Train Loss 1.0724034 Test MSE 6.14168894872597 Test RE 1.1845461049032435\n",
      "117 Train Loss 1.0660213 Test MSE 6.134311444945325 Test RE 1.1838344424130531\n",
      "118 Train Loss 1.0577523 Test MSE 6.144229078560799 Test RE 1.184791036702931\n",
      "119 Train Loss 1.0531164 Test MSE 6.136503582597674 Test RE 1.1840459491382522\n",
      "120 Train Loss 1.0462053 Test MSE 6.142880088418829 Test RE 1.1846609667507266\n",
      "121 Train Loss 1.0406836 Test MSE 6.132416659983548 Test RE 1.1836515950828834\n",
      "122 Train Loss 1.0350448 Test MSE 6.141595617211583 Test RE 1.184537104455421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 Train Loss 1.0296425 Test MSE 6.1231341717828505 Test RE 1.182755423679346\n",
      "124 Train Loss 1.02198 Test MSE 6.116260154895578 Test RE 1.182091338618114\n",
      "125 Train Loss 1.0171809 Test MSE 6.116200717189402 Test RE 1.1820855948329763\n",
      "126 Train Loss 1.0111601 Test MSE 6.124623950828246 Test RE 1.1828992991058689\n",
      "127 Train Loss 1.0025537 Test MSE 6.122479179131641 Test RE 1.1826921622181885\n",
      "128 Train Loss 0.9978502 Test MSE 6.1333390248688895 Test RE 1.1837406071053103\n",
      "129 Train Loss 0.99413 Test MSE 6.145382676476079 Test RE 1.1849022555641258\n",
      "130 Train Loss 0.98950374 Test MSE 6.14400126613736 Test RE 1.184769071976695\n",
      "131 Train Loss 0.98446417 Test MSE 6.1440089921355385 Test RE 1.1847698168919725\n",
      "132 Train Loss 0.97999847 Test MSE 6.119236375922796 Test RE 1.1823789111805372\n",
      "133 Train Loss 0.9762472 Test MSE 6.112944794366307 Test RE 1.1817709148543325\n",
      "134 Train Loss 0.96751064 Test MSE 6.093850696169065 Test RE 1.1799238101571858\n",
      "135 Train Loss 0.9608522 Test MSE 6.0976389861629485 Test RE 1.1802905076130439\n",
      "136 Train Loss 0.95594287 Test MSE 6.089196842333436 Test RE 1.1794731721266918\n",
      "137 Train Loss 0.9517006 Test MSE 6.097794790745831 Test RE 1.1803055866867598\n",
      "138 Train Loss 0.94806755 Test MSE 6.105553808570505 Test RE 1.1810562761588703\n",
      "139 Train Loss 0.9442326 Test MSE 6.106685035099828 Test RE 1.1811656831311887\n",
      "140 Train Loss 0.93822396 Test MSE 6.101905506464352 Test RE 1.1807033602643413\n",
      "141 Train Loss 0.93174386 Test MSE 6.121419430161849 Test RE 1.1825898008213704\n",
      "142 Train Loss 0.92789197 Test MSE 6.124649458986531 Test RE 1.1829017624041367\n",
      "143 Train Loss 0.9231923 Test MSE 6.118610512568978 Test RE 1.1823184439499903\n",
      "144 Train Loss 0.9181285 Test MSE 6.132778167891966 Test RE 1.1836864828873281\n",
      "145 Train Loss 0.91347283 Test MSE 6.147716698212743 Test RE 1.1851272476616557\n",
      "146 Train Loss 0.9069728 Test MSE 6.159703874384622 Test RE 1.1862821000615036\n",
      "147 Train Loss 0.9034486 Test MSE 6.172468397941961 Test RE 1.1875106079183386\n",
      "148 Train Loss 0.90034175 Test MSE 6.173888152684757 Test RE 1.1876471721557502\n",
      "149 Train Loss 0.8964314 Test MSE 6.163544750973464 Test RE 1.1866518948748048\n",
      "Training time: 235.52\n",
      "6\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 65.148125 Test MSE 6.645996575795979 Test RE 1.232219612368768\n",
      "1 Train Loss 45.435886 Test MSE 9.131716309714125 Test RE 1.4443893108725483\n",
      "2 Train Loss 39.48478 Test MSE 8.947944385022138 Test RE 1.4297815820688398\n",
      "3 Train Loss 34.919426 Test MSE 9.214486437280149 Test RE 1.450920536657777\n",
      "4 Train Loss 31.331846 Test MSE 9.241499352794483 Test RE 1.4530457181029859\n",
      "5 Train Loss 28.059303 Test MSE 9.392431440701431 Test RE 1.4648632277345506\n",
      "6 Train Loss 25.504251 Test MSE 9.597164957744647 Test RE 1.4807424947931065\n",
      "7 Train Loss 22.419662 Test MSE 9.441650505916282 Test RE 1.4686963667194424\n",
      "8 Train Loss 21.297258 Test MSE 9.614563872321567 Test RE 1.4820841225624681\n",
      "9 Train Loss 19.918852 Test MSE 9.38645795292777 Test RE 1.4643973348312957\n",
      "10 Train Loss 19.022814 Test MSE 9.285132286670805 Test RE 1.4564718931372342\n",
      "11 Train Loss 18.227592 Test MSE 9.292112308805104 Test RE 1.4570192356987366\n",
      "12 Train Loss 17.611256 Test MSE 9.148538232018492 Test RE 1.4457190841821657\n",
      "13 Train Loss 16.83479 Test MSE 9.130016865116568 Test RE 1.444254901647398\n",
      "14 Train Loss 15.740623 Test MSE 8.803188494359574 Test RE 1.4181692383843518\n",
      "15 Train Loss 14.835366 Test MSE 8.535462166302556 Test RE 1.3964377515925943\n",
      "16 Train Loss 12.98674 Test MSE 8.612818776004982 Test RE 1.4027514131788716\n",
      "17 Train Loss 11.758764 Test MSE 8.376714443857695 Test RE 1.383390903786697\n",
      "18 Train Loss 10.178396 Test MSE 8.094598938994674 Test RE 1.3598960995958858\n",
      "19 Train Loss 8.699731 Test MSE 7.378738210392891 Test RE 1.2983719111653902\n",
      "20 Train Loss 7.3753448 Test MSE 7.273555526633394 Test RE 1.2890846576752608\n",
      "21 Train Loss 5.975239 Test MSE 6.8357797986216395 Test RE 1.2496894182263365\n",
      "22 Train Loss 5.026642 Test MSE 6.666607528419866 Test RE 1.234128848959702\n",
      "23 Train Loss 4.028415 Test MSE 6.528981984194216 Test RE 1.2213237299622457\n",
      "24 Train Loss 3.244371 Test MSE 6.200668904822483 Test RE 1.190220240106938\n",
      "25 Train Loss 2.7828898 Test MSE 6.077422924001743 Test RE 1.1783323205037775\n",
      "26 Train Loss 2.6211302 Test MSE 6.011644853985381 Test RE 1.1719382210029412\n",
      "27 Train Loss 2.443854 Test MSE 5.876778200894324 Test RE 1.158717884682481\n",
      "28 Train Loss 2.257847 Test MSE 6.000277808614149 Test RE 1.170829724210319\n",
      "29 Train Loss 2.1491585 Test MSE 5.996904315954599 Test RE 1.170500544385056\n",
      "30 Train Loss 2.031716 Test MSE 6.004510065997543 Test RE 1.171242570033639\n",
      "31 Train Loss 1.9478548 Test MSE 6.038368901303401 Test RE 1.1745401880385642\n",
      "32 Train Loss 1.8706815 Test MSE 6.078065054277888 Test RE 1.1783945691643087\n",
      "33 Train Loss 1.826041 Test MSE 6.10257420495201 Test RE 1.1807680542292642\n",
      "34 Train Loss 1.7822655 Test MSE 6.073024808329834 Test RE 1.1779058749644038\n",
      "35 Train Loss 1.724371 Test MSE 6.011827861881201 Test RE 1.1719560590756175\n",
      "36 Train Loss 1.6673512 Test MSE 5.926951557924879 Test RE 1.1636536849180072\n",
      "37 Train Loss 1.6375422 Test MSE 5.905506952001785 Test RE 1.1615466398959826\n",
      "38 Train Loss 1.6015749 Test MSE 5.880887005134512 Test RE 1.1591228781092424\n",
      "39 Train Loss 1.5567045 Test MSE 5.879600906251208 Test RE 1.1589961261286232\n",
      "40 Train Loss 1.5332583 Test MSE 5.877954377821892 Test RE 1.158833831636006\n",
      "41 Train Loss 1.4921446 Test MSE 5.833426753505443 Test RE 1.1544361952768987\n",
      "42 Train Loss 1.4607348 Test MSE 5.832034736840759 Test RE 1.1542984468856188\n",
      "43 Train Loss 1.4404311 Test MSE 5.810255023670607 Test RE 1.1521410690808336\n",
      "44 Train Loss 1.419192 Test MSE 5.795887549528214 Test RE 1.150715692499308\n",
      "45 Train Loss 1.3792464 Test MSE 5.804834623752229 Test RE 1.1516035261915794\n",
      "46 Train Loss 1.3591628 Test MSE 5.8031906193266645 Test RE 1.151440440119117\n",
      "47 Train Loss 1.3401386 Test MSE 5.815026498814795 Test RE 1.1526140504107032\n",
      "48 Train Loss 1.3257395 Test MSE 5.817254596234164 Test RE 1.1528348482381765\n",
      "49 Train Loss 1.3004602 Test MSE 5.785090923530056 Test RE 1.1496434116741832\n",
      "50 Train Loss 1.2821026 Test MSE 5.795963271338528 Test RE 1.150723209380032\n",
      "51 Train Loss 1.26777 Test MSE 5.839253210386252 Test RE 1.1550125798169657\n",
      "52 Train Loss 1.2377565 Test MSE 5.876907432987784 Test RE 1.1587306248872016\n",
      "53 Train Loss 1.2241765 Test MSE 5.8878786350911625 Test RE 1.1598116986015623\n",
      "54 Train Loss 1.2075312 Test MSE 5.869690996498175 Test RE 1.1580189857643768\n",
      "55 Train Loss 1.1884234 Test MSE 5.8437583085471205 Test RE 1.1554580513189467\n",
      "56 Train Loss 1.1734369 Test MSE 5.848474912892639 Test RE 1.1559242529443117\n",
      "57 Train Loss 1.1640177 Test MSE 5.857060043900628 Test RE 1.1567723477149356\n",
      "58 Train Loss 1.1524638 Test MSE 5.856242921935579 Test RE 1.1566916538978764\n",
      "59 Train Loss 1.1447625 Test MSE 5.846078278566315 Test RE 1.1556873867822457\n",
      "60 Train Loss 1.1308308 Test MSE 5.849913676452482 Test RE 1.1560664267115683\n",
      "61 Train Loss 1.1194712 Test MSE 5.883771199707756 Test RE 1.15940708065508\n",
      "62 Train Loss 1.1112183 Test MSE 5.858124183231485 Test RE 1.1568774269727782\n",
      "63 Train Loss 1.1025646 Test MSE 5.872749413946881 Test RE 1.1583206408464413\n",
      "64 Train Loss 1.0896536 Test MSE 5.918248416633268 Test RE 1.1627990159660209\n",
      "65 Train Loss 1.0836737 Test MSE 5.935556046678952 Test RE 1.1644980493103272\n",
      "66 Train Loss 1.0763246 Test MSE 5.9531340510942705 Test RE 1.1662210908477257\n",
      "67 Train Loss 1.0685741 Test MSE 5.929399611060583 Test RE 1.1638939764010408\n",
      "68 Train Loss 1.0647907 Test MSE 5.940715036722953 Test RE 1.1650040110898967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 Train Loss 1.0569375 Test MSE 5.9244071221841805 Test RE 1.1634038802893722\n",
      "70 Train Loss 1.0496851 Test MSE 5.929000949029747 Test RE 1.1638548486506568\n",
      "71 Train Loss 1.0460974 Test MSE 5.924118256396592 Test RE 1.163375516972345\n",
      "72 Train Loss 1.0387326 Test MSE 5.930725105071086 Test RE 1.1640240610965702\n",
      "73 Train Loss 1.0298411 Test MSE 5.943848130891595 Test RE 1.165311178335128\n",
      "74 Train Loss 1.0233771 Test MSE 5.936616073110592 Test RE 1.164602028077817\n",
      "75 Train Loss 1.0127006 Test MSE 5.932026790733197 Test RE 1.1641517950813405\n",
      "76 Train Loss 1.0047023 Test MSE 5.92278245346368 Test RE 1.1632443474063718\n",
      "77 Train Loss 0.9999377 Test MSE 5.902311936627448 Test RE 1.1612323856334643\n",
      "78 Train Loss 0.9948144 Test MSE 5.894539340193981 Test RE 1.1604675358415908\n",
      "79 Train Loss 0.98639846 Test MSE 5.897614820922036 Test RE 1.1607702338071044\n",
      "80 Train Loss 0.981246 Test MSE 5.9071121939670315 Test RE 1.1617044956682612\n",
      "81 Train Loss 0.9764731 Test MSE 5.889449346215315 Test RE 1.1599663899403452\n",
      "82 Train Loss 0.9713793 Test MSE 5.891558885624596 Test RE 1.160174115279881\n",
      "83 Train Loss 0.9630176 Test MSE 5.888889303319733 Test RE 1.159911236534474\n",
      "84 Train Loss 0.95799065 Test MSE 5.892617618075991 Test RE 1.1602783541435593\n",
      "85 Train Loss 0.9549659 Test MSE 5.907513817300715 Test RE 1.1617439870209556\n",
      "86 Train Loss 0.9480263 Test MSE 5.938647528409152 Test RE 1.1648012690742233\n",
      "87 Train Loss 0.94420975 Test MSE 5.948679194106737 Test RE 1.1657846551449325\n",
      "88 Train Loss 0.9399494 Test MSE 5.938383348490727 Test RE 1.1647753607739715\n",
      "89 Train Loss 0.9327321 Test MSE 5.953596453262241 Test RE 1.1662663823433375\n",
      "90 Train Loss 0.9278147 Test MSE 5.965875434403338 Test RE 1.16746844455719\n",
      "91 Train Loss 0.9209485 Test MSE 5.997884431470643 Test RE 1.1705961919736887\n",
      "92 Train Loss 0.91280854 Test MSE 5.976374587781089 Test RE 1.1684952881674093\n",
      "93 Train Loss 0.9081656 Test MSE 6.000869557902379 Test RE 1.1708874565851284\n",
      "94 Train Loss 0.8993468 Test MSE 6.016440917901217 Test RE 1.1724056113891175\n",
      "95 Train Loss 0.8860634 Test MSE 6.035555498081647 Test RE 1.174266534656614\n",
      "96 Train Loss 0.8805586 Test MSE 6.054574608478382 Test RE 1.176115240904014\n",
      "97 Train Loss 0.87418014 Test MSE 6.074490668374246 Test RE 1.1780480233199733\n",
      "98 Train Loss 0.8671872 Test MSE 6.079536677228232 Test RE 1.1785372171551898\n",
      "99 Train Loss 0.8600724 Test MSE 6.081369574298922 Test RE 1.178714860184525\n",
      "100 Train Loss 0.85310715 Test MSE 6.082070623202842 Test RE 1.1787827982482624\n",
      "101 Train Loss 0.8492222 Test MSE 6.079541080102358 Test RE 1.1785376439105786\n",
      "102 Train Loss 0.84391785 Test MSE 6.081244056429627 Test RE 1.1787026959393359\n",
      "103 Train Loss 0.83609957 Test MSE 6.087277061812714 Test RE 1.1792872273970498\n",
      "104 Train Loss 0.83081985 Test MSE 6.091206813843895 Test RE 1.179667821103511\n",
      "105 Train Loss 0.82728404 Test MSE 6.096584994458611 Test RE 1.180188495164536\n",
      "106 Train Loss 0.82238185 Test MSE 6.1046386041744345 Test RE 1.1809677544261088\n",
      "107 Train Loss 0.8199443 Test MSE 6.122552909946033 Test RE 1.1826992835648864\n",
      "108 Train Loss 0.81707656 Test MSE 6.124360336343416 Test RE 1.1828738418086266\n",
      "109 Train Loss 0.8144391 Test MSE 6.134852098958343 Test RE 1.1838866105125738\n",
      "110 Train Loss 0.8109659 Test MSE 6.130698816235689 Test RE 1.1834857982183242\n",
      "111 Train Loss 0.80755264 Test MSE 6.136640566594603 Test RE 1.18405916468024\n",
      "112 Train Loss 0.8044026 Test MSE 6.134922186514419 Test RE 1.183893373143594\n",
      "113 Train Loss 0.80018795 Test MSE 6.146069404374496 Test RE 1.1849684583335556\n",
      "114 Train Loss 0.7964692 Test MSE 6.188642592744226 Test RE 1.1890654528125644\n",
      "115 Train Loss 0.79103005 Test MSE 6.184619756546825 Test RE 1.188678922723538\n",
      "116 Train Loss 0.78672314 Test MSE 6.202995159392922 Test RE 1.190443481799223\n",
      "117 Train Loss 0.7841973 Test MSE 6.204281892001393 Test RE 1.190566946591492\n",
      "118 Train Loss 0.77992797 Test MSE 6.21215601240646 Test RE 1.1913222068366494\n",
      "119 Train Loss 0.7771537 Test MSE 6.209550766891468 Test RE 1.1910723730991104\n",
      "120 Train Loss 0.77506804 Test MSE 6.2294045728705285 Test RE 1.1929749622673185\n",
      "121 Train Loss 0.7724131 Test MSE 6.235293548949536 Test RE 1.193538719312614\n",
      "122 Train Loss 0.7694694 Test MSE 6.235926814995789 Test RE 1.1935993265919758\n",
      "123 Train Loss 0.76669985 Test MSE 6.232277080384444 Test RE 1.1932499833025132\n",
      "124 Train Loss 0.76429176 Test MSE 6.237160873333036 Test RE 1.1937174243806312\n",
      "125 Train Loss 0.76219356 Test MSE 6.249739417323849 Test RE 1.19492050898312\n",
      "126 Train Loss 0.759213 Test MSE 6.247959418380056 Test RE 1.1947503331910572\n",
      "127 Train Loss 0.756772 Test MSE 6.2570693161352 Test RE 1.1956210245752026\n",
      "128 Train Loss 0.75438416 Test MSE 6.253908336255725 Test RE 1.1953189812984024\n",
      "129 Train Loss 0.7510181 Test MSE 6.2632341145994745 Test RE 1.196209874375367\n",
      "130 Train Loss 0.748592 Test MSE 6.274882643268129 Test RE 1.1973217290524516\n",
      "131 Train Loss 0.7461845 Test MSE 6.277957973912721 Test RE 1.197615097818561\n",
      "132 Train Loss 0.74432003 Test MSE 6.285440458558313 Test RE 1.198328583643849\n",
      "133 Train Loss 0.7419851 Test MSE 6.283037391039462 Test RE 1.1980994875440396\n",
      "134 Train Loss 0.7393385 Test MSE 6.2832781304620235 Test RE 1.1981224403770447\n",
      "135 Train Loss 0.7366977 Test MSE 6.28689719795233 Test RE 1.1984674403662308\n",
      "136 Train Loss 0.7341254 Test MSE 6.2973543236791505 Test RE 1.1994637440464806\n",
      "137 Train Loss 0.73236716 Test MSE 6.310059540396865 Test RE 1.2006731223976406\n",
      "138 Train Loss 0.73000693 Test MSE 6.315438852485916 Test RE 1.201184798988022\n",
      "139 Train Loss 0.727623 Test MSE 6.321599059907236 Test RE 1.2017704862338434\n",
      "140 Train Loss 0.7258959 Test MSE 6.334730335971437 Test RE 1.203018002359179\n",
      "141 Train Loss 0.7236249 Test MSE 6.336692766179051 Test RE 1.203204328842765\n",
      "142 Train Loss 0.72208774 Test MSE 6.331913638293011 Test RE 1.2027505154582883\n",
      "143 Train Loss 0.7198447 Test MSE 6.325758411826489 Test RE 1.20216577897429\n",
      "144 Train Loss 0.7183671 Test MSE 6.322830309261949 Test RE 1.2018875141471854\n",
      "145 Train Loss 0.71653396 Test MSE 6.324260742796698 Test RE 1.2020234598310018\n",
      "146 Train Loss 0.71484905 Test MSE 6.322864685920627 Test RE 1.201890781419804\n",
      "147 Train Loss 0.7126272 Test MSE 6.3236563419622 Test RE 1.2019660206005265\n",
      "148 Train Loss 0.7113131 Test MSE 6.32665189863173 Test RE 1.2022506764099232\n",
      "149 Train Loss 0.71013707 Test MSE 6.324678434578425 Test RE 1.2020631535637003\n",
      "Training time: 235.01\n",
      "7\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 51.747643 Test MSE 6.930422610131001 Test RE 1.2583107862856289\n",
      "1 Train Loss 43.04988 Test MSE 7.965516266727043 Test RE 1.3490095516669522\n",
      "2 Train Loss 32.97248 Test MSE 7.113166165129829 Test RE 1.2747926102956821\n",
      "3 Train Loss 25.397093 Test MSE 6.642686124090362 Test RE 1.2319126823566395\n",
      "4 Train Loss 18.599693 Test MSE 6.317717171693883 Test RE 1.201401445502307\n",
      "5 Train Loss 15.754544 Test MSE 6.167545744258693 Test RE 1.1870369830190897\n",
      "6 Train Loss 13.98465 Test MSE 6.066896133292937 Test RE 1.1773113751255584\n",
      "7 Train Loss 12.645209 Test MSE 6.107196620369411 Test RE 1.1812151579531194\n",
      "8 Train Loss 11.937943 Test MSE 6.0576830767235705 Test RE 1.1764171157665277\n",
      "9 Train Loss 11.251813 Test MSE 5.9502016260826975 Test RE 1.165933823912971\n",
      "10 Train Loss 10.609976 Test MSE 5.935554174069495 Test RE 1.1644978656164815\n",
      "11 Train Loss 9.847536 Test MSE 5.818719967795113 Test RE 1.1529800391525944\n",
      "12 Train Loss 9.079722 Test MSE 5.684230168488107 Test RE 1.1395775578320713\n",
      "13 Train Loss 8.442595 Test MSE 5.739660799678413 Test RE 1.1451204590606736\n",
      "14 Train Loss 7.3757267 Test MSE 5.565235181354087 Test RE 1.1275863794925791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Train Loss 6.788872 Test MSE 5.4819368406206515 Test RE 1.1191159205604009\n",
      "16 Train Loss 6.2166786 Test MSE 5.393234305922259 Test RE 1.110024857840267\n",
      "17 Train Loss 5.6061916 Test MSE 5.219210079444157 Test RE 1.0919693520050402\n",
      "18 Train Loss 4.9171576 Test MSE 5.001607125716563 Test RE 1.0689634296960542\n",
      "19 Train Loss 4.5256634 Test MSE 4.849055458324242 Test RE 1.052535216873609\n",
      "20 Train Loss 4.1040773 Test MSE 4.757517995193641 Test RE 1.0425533307752566\n",
      "21 Train Loss 3.762395 Test MSE 4.607981255336183 Test RE 1.0260379213365185\n",
      "22 Train Loss 3.431561 Test MSE 4.391042454652933 Test RE 1.0015943783850134\n",
      "23 Train Loss 3.202194 Test MSE 4.234525789385453 Test RE 0.9835817260009473\n",
      "24 Train Loss 2.9493897 Test MSE 3.9822948846525352 Test RE 0.9538383248718374\n",
      "25 Train Loss 2.6809053 Test MSE 3.8197835448798845 Test RE 0.9341732712992796\n",
      "26 Train Loss 2.4220939 Test MSE 3.5552184314294446 Test RE 0.9012415476240655\n",
      "27 Train Loss 2.2661102 Test MSE 3.4214971927073847 Test RE 0.8841300552238237\n",
      "28 Train Loss 2.0236442 Test MSE 3.2143079380066224 Test RE 0.8569427338647426\n",
      "29 Train Loss 1.846262 Test MSE 3.1674231745049632 Test RE 0.85066997675422\n",
      "30 Train Loss 1.7053082 Test MSE 3.045613897998852 Test RE 0.8341525525332931\n",
      "31 Train Loss 1.6026528 Test MSE 2.8991566044295163 Test RE 0.813849119519336\n",
      "32 Train Loss 1.5001453 Test MSE 2.8227750451847995 Test RE 0.8030566725447038\n",
      "33 Train Loss 1.4154786 Test MSE 2.7453809224705057 Test RE 0.7919711584875815\n",
      "34 Train Loss 1.3594515 Test MSE 2.6812719159982428 Test RE 0.7826696440131612\n",
      "35 Train Loss 1.2966187 Test MSE 2.582054971636283 Test RE 0.7680523146894309\n",
      "36 Train Loss 1.2485604 Test MSE 2.5526587588914986 Test RE 0.7636677336086883\n",
      "37 Train Loss 1.1655655 Test MSE 2.4818347730419883 Test RE 0.7529991619774775\n",
      "38 Train Loss 1.0937793 Test MSE 2.421609344082204 Test RE 0.7438067275795303\n",
      "39 Train Loss 1.0495913 Test MSE 2.2778335556912417 Test RE 0.721388232161207\n",
      "40 Train Loss 0.9906201 Test MSE 2.126147537394964 Test RE 0.6969550337958714\n",
      "41 Train Loss 0.937358 Test MSE 1.9584237283727584 Test RE 0.6689003011768341\n",
      "42 Train Loss 0.8755263 Test MSE 1.9021816329644186 Test RE 0.6592255818877975\n",
      "43 Train Loss 0.80884075 Test MSE 1.7935458891086238 Test RE 0.6401242893778644\n",
      "44 Train Loss 0.75248766 Test MSE 1.707137908152439 Test RE 0.6245142657703644\n",
      "45 Train Loss 0.6803925 Test MSE 1.609715694750928 Test RE 0.6064327534374767\n",
      "46 Train Loss 0.61684304 Test MSE 1.608129307627664 Test RE 0.6061338577210114\n",
      "47 Train Loss 0.5704864 Test MSE 1.470795351560148 Test RE 0.5796744846489614\n",
      "48 Train Loss 0.5328785 Test MSE 1.3767949848457501 Test RE 0.5608448004976392\n",
      "49 Train Loss 0.4832491 Test MSE 1.2770026071886669 Test RE 0.5401370302008554\n",
      "50 Train Loss 0.40472853 Test MSE 1.0842385068401594 Test RE 0.4977032467921901\n",
      "51 Train Loss 0.36155435 Test MSE 0.9532254634427662 Test RE 0.46666569622332044\n",
      "52 Train Loss 0.31119868 Test MSE 0.8790221202237657 Test RE 0.4481340692880507\n",
      "53 Train Loss 0.27948916 Test MSE 0.8921652102498027 Test RE 0.45147187678624684\n",
      "54 Train Loss 0.25168893 Test MSE 0.8668399409429759 Test RE 0.4450179381328338\n",
      "55 Train Loss 0.22252274 Test MSE 0.8085769258767186 Test RE 0.42980229703006\n",
      "56 Train Loss 0.19668558 Test MSE 0.7399437717728419 Test RE 0.41115674552634307\n",
      "57 Train Loss 0.17932627 Test MSE 0.730403576623886 Test RE 0.40849759675756103\n",
      "58 Train Loss 0.1565605 Test MSE 0.7321965831592285 Test RE 0.4089986826874942\n",
      "59 Train Loss 0.13306655 Test MSE 0.6993831768492165 Test RE 0.39972899439619525\n",
      "60 Train Loss 0.12176146 Test MSE 0.6965278572946471 Test RE 0.39891218798280503\n",
      "61 Train Loss 0.11131923 Test MSE 0.6947362901117758 Test RE 0.39839882865891535\n",
      "62 Train Loss 0.10304048 Test MSE 0.6770253276881205 Test RE 0.39328783960819563\n",
      "63 Train Loss 0.09149491 Test MSE 0.6383815465745833 Test RE 0.3818987374077671\n",
      "64 Train Loss 0.08199696 Test MSE 0.6118819710418596 Test RE 0.3738883117857034\n",
      "65 Train Loss 0.0765828 Test MSE 0.5922408578306649 Test RE 0.3678385508731569\n",
      "66 Train Loss 0.06695851 Test MSE 0.5794662472486262 Test RE 0.3638497931880514\n",
      "67 Train Loss 0.06318094 Test MSE 0.5851042549885552 Test RE 0.36561557528727245\n",
      "68 Train Loss 0.05899623 Test MSE 0.571611405896528 Test RE 0.3613753317117788\n",
      "69 Train Loss 0.055438325 Test MSE 0.5496501567714994 Test RE 0.354365340683443\n",
      "70 Train Loss 0.053001236 Test MSE 0.5476362748747792 Test RE 0.35371555933844395\n",
      "71 Train Loss 0.050061595 Test MSE 0.5508655747223866 Test RE 0.3547569208145332\n",
      "72 Train Loss 0.047483504 Test MSE 0.5525301125194007 Test RE 0.3552924969363593\n",
      "73 Train Loss 0.043048963 Test MSE 0.5523844397159074 Test RE 0.3552456579815929\n",
      "74 Train Loss 0.039136697 Test MSE 0.5322114085546683 Test RE 0.3486985570575697\n",
      "75 Train Loss 0.036199387 Test MSE 0.5207999423900825 Test RE 0.34493997220887695\n",
      "76 Train Loss 0.0339703 Test MSE 0.5117107218463773 Test RE 0.34191670427425747\n",
      "77 Train Loss 0.032124862 Test MSE 0.5034329633414529 Test RE 0.33913989746494466\n",
      "78 Train Loss 0.029207328 Test MSE 0.5029150410116008 Test RE 0.33896540221159777\n",
      "79 Train Loss 0.028489083 Test MSE 0.4956767135949744 Test RE 0.3365172402211481\n",
      "80 Train Loss 0.02667786 Test MSE 0.49010123802117195 Test RE 0.3346192797355521\n",
      "81 Train Loss 0.026067749 Test MSE 0.49837314960141 Test RE 0.3374313103036935\n",
      "82 Train Loss 0.02496042 Test MSE 0.4863503742117423 Test RE 0.33333635908544584\n",
      "83 Train Loss 0.024107952 Test MSE 0.47841915360410836 Test RE 0.3306072243787793\n",
      "84 Train Loss 0.023314185 Test MSE 0.46930059676138447 Test RE 0.32744141885699557\n",
      "85 Train Loss 0.020983621 Test MSE 0.45079612150627846 Test RE 0.32092100658196954\n",
      "86 Train Loss 0.020571252 Test MSE 0.4554446050485255 Test RE 0.32257138676703007\n",
      "87 Train Loss 0.019677559 Test MSE 0.44182358081968093 Test RE 0.3177111860560487\n",
      "88 Train Loss 0.019177571 Test MSE 0.43894251945982266 Test RE 0.31667361976014646\n",
      "89 Train Loss 0.018322594 Test MSE 0.4428099146087542 Test RE 0.31806562003593325\n",
      "90 Train Loss 0.017818943 Test MSE 0.44807830127830883 Test RE 0.31995213822103413\n",
      "91 Train Loss 0.017130272 Test MSE 0.448854142903885 Test RE 0.3202290148590666\n",
      "92 Train Loss 0.016543986 Test MSE 0.43509962418688886 Test RE 0.315284350346597\n",
      "93 Train Loss 0.01563665 Test MSE 0.42930091659774705 Test RE 0.3131763571750548\n",
      "94 Train Loss 0.014187609 Test MSE 0.4221089762664757 Test RE 0.31054200601801213\n",
      "95 Train Loss 0.013832362 Test MSE 0.42506990133474043 Test RE 0.3116292664490219\n",
      "96 Train Loss 0.0136488695 Test MSE 0.4247880439552821 Test RE 0.31152593100528475\n",
      "97 Train Loss 0.012740629 Test MSE 0.41313202357932266 Test RE 0.30722212615922645\n",
      "98 Train Loss 0.012294082 Test MSE 0.40757490753393666 Test RE 0.30514887953552544\n",
      "99 Train Loss 0.012000287 Test MSE 0.4026815989256779 Test RE 0.3033115528395263\n",
      "100 Train Loss 0.011439331 Test MSE 0.3919967654315714 Test RE 0.2992604343926776\n",
      "101 Train Loss 0.010768571 Test MSE 0.3797250738996475 Test RE 0.29453892535155085\n",
      "102 Train Loss 0.010544558 Test MSE 0.37922531280365884 Test RE 0.29434503828585024\n",
      "103 Train Loss 0.010058359 Test MSE 0.38094403190121257 Test RE 0.295011297252186\n",
      "104 Train Loss 0.009453807 Test MSE 0.3640035464736683 Test RE 0.28837716483568304\n",
      "105 Train Loss 0.0090163 Test MSE 0.3469140590506774 Test RE 0.2815263245751755\n",
      "106 Train Loss 0.008775347 Test MSE 0.33899317705227955 Test RE 0.2782938050746406\n",
      "107 Train Loss 0.008585654 Test MSE 0.3292351728783383 Test RE 0.2742591799310205\n",
      "108 Train Loss 0.00849265 Test MSE 0.33280384576840094 Test RE 0.275741560072685\n",
      "109 Train Loss 0.008318341 Test MSE 0.3419701803162671 Test RE 0.2795131077851093\n",
      "110 Train Loss 0.007699089 Test MSE 0.33215235135196225 Test RE 0.2754715330091389\n",
      "111 Train Loss 0.007144965 Test MSE 0.3240718211164111 Test RE 0.2721000960615759\n",
      "112 Train Loss 0.0068512857 Test MSE 0.3295026046471875 Test RE 0.27437054520327847\n",
      "113 Train Loss 0.006739202 Test MSE 0.3306177813731382 Test RE 0.2748344462387417\n",
      "114 Train Loss 0.0066539026 Test MSE 0.33190207603721283 Test RE 0.2753677301661963\n",
      "115 Train Loss 0.006434216 Test MSE 0.3319290140024335 Test RE 0.2753789046908035\n",
      "116 Train Loss 0.00590821 Test MSE 0.32912711510298764 Test RE 0.27421416914332725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 Train Loss 0.005772718 Test MSE 0.3243740595541081 Test RE 0.27222695056864343\n",
      "118 Train Loss 0.005572523 Test MSE 0.3158191408653513 Test RE 0.2686131588806292\n",
      "119 Train Loss 0.0052859634 Test MSE 0.30800477917172014 Test RE 0.2652691757443282\n",
      "120 Train Loss 0.005108635 Test MSE 0.30692943358366603 Test RE 0.26480570005621046\n",
      "121 Train Loss 0.0050167004 Test MSE 0.2985633213417909 Test RE 0.26117180284597974\n",
      "122 Train Loss 0.0049038464 Test MSE 0.2932763360461794 Test RE 0.25884904751253385\n",
      "123 Train Loss 0.004727989 Test MSE 0.2934871008641094 Test RE 0.25894204252677044\n",
      "124 Train Loss 0.00463181 Test MSE 0.29125732268174376 Test RE 0.2579565065808399\n",
      "125 Train Loss 0.004529889 Test MSE 0.2876887175467223 Test RE 0.2563713412065346\n",
      "126 Train Loss 0.004262707 Test MSE 0.2837620433675442 Test RE 0.2546157189225629\n",
      "127 Train Loss 0.004046569 Test MSE 0.27069042593020637 Test RE 0.24868208962745525\n",
      "128 Train Loss 0.0039717066 Test MSE 0.2673350096900311 Test RE 0.24713598039968024\n",
      "129 Train Loss 0.003888859 Test MSE 0.255918611075962 Test RE 0.24180150259809816\n",
      "130 Train Loss 0.003770884 Test MSE 0.24340790786761343 Test RE 0.2358171585308928\n",
      "131 Train Loss 0.0036993027 Test MSE 0.24070244291489867 Test RE 0.23450294938242458\n",
      "132 Train Loss 0.0036279992 Test MSE 0.2373563980327572 Test RE 0.23286731283172601\n",
      "133 Train Loss 0.0035011303 Test MSE 0.23505125371430877 Test RE 0.23173378023424437\n",
      "134 Train Loss 0.003376652 Test MSE 0.24407978577074738 Test RE 0.23614239684065186\n",
      "135 Train Loss 0.0032371238 Test MSE 0.24833709191370418 Test RE 0.23819292405155076\n",
      "136 Train Loss 0.0031579158 Test MSE 0.24390800681994265 Test RE 0.23605928583525096\n",
      "137 Train Loss 0.0030945062 Test MSE 0.23887421560697825 Test RE 0.23361068198552948\n",
      "138 Train Loss 0.0030591707 Test MSE 0.23916604783293938 Test RE 0.23375333931568473\n",
      "139 Train Loss 0.0030171217 Test MSE 0.23926081036682104 Test RE 0.23379964368287068\n",
      "140 Train Loss 0.0029764608 Test MSE 0.23702408879007023 Test RE 0.23270424357128772\n",
      "141 Train Loss 0.002883577 Test MSE 0.22982087099034398 Test RE 0.22914099436505958\n",
      "142 Train Loss 0.002816489 Test MSE 0.22623315411603928 Test RE 0.22734540742116857\n",
      "143 Train Loss 0.002720855 Test MSE 0.22825080829327646 Test RE 0.22835694397607426\n",
      "144 Train Loss 0.0026554177 Test MSE 0.22368682898048362 Test RE 0.22606236499591753\n",
      "145 Train Loss 0.0026158746 Test MSE 0.2199286761316333 Test RE 0.2241552888253933\n",
      "146 Train Loss 0.0025914807 Test MSE 0.21856142280697433 Test RE 0.2234574378616484\n",
      "147 Train Loss 0.002560753 Test MSE 0.21380722486578876 Test RE 0.22101372717120768\n",
      "148 Train Loss 0.0025425998 Test MSE 0.2127992721331518 Test RE 0.22049214852895574\n",
      "149 Train Loss 0.0025278453 Test MSE 0.21124474538949192 Test RE 0.21968531020285925\n",
      "Training time: 231.38\n",
      "8\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 70.13859 Test MSE 5.372128634967111 Test RE 1.1078507649485125\n",
      "1 Train Loss 53.026848 Test MSE 6.175861905044168 Test RE 1.1878369985690271\n",
      "2 Train Loss 34.9093 Test MSE 6.8440002197864205 Test RE 1.2504406044142913\n",
      "3 Train Loss 24.061497 Test MSE 7.524256292886976 Test RE 1.3111121752762513\n",
      "4 Train Loss 19.463127 Test MSE 6.971008118622294 Test RE 1.261989828463447\n",
      "5 Train Loss 15.017489 Test MSE 6.956744718027962 Test RE 1.2606980867817141\n",
      "6 Train Loss 13.209843 Test MSE 6.661543534975479 Test RE 1.2336600342262047\n",
      "7 Train Loss 11.894451 Test MSE 6.6353858028198305 Test RE 1.2312355593918152\n",
      "8 Train Loss 10.870404 Test MSE 6.681004852505922 Test RE 1.2354607535428603\n",
      "9 Train Loss 9.805332 Test MSE 6.544014067013421 Test RE 1.2227288865669812\n",
      "10 Train Loss 9.134104 Test MSE 6.3155799530400625 Test RE 1.201198217445397\n",
      "11 Train Loss 8.080794 Test MSE 6.172562304194821 Test RE 1.1875196411154403\n",
      "12 Train Loss 6.865923 Test MSE 6.1362261766116815 Test RE 1.1840191859218911\n",
      "13 Train Loss 5.723448 Test MSE 5.894420166830539 Test RE 1.1604558048554658\n",
      "14 Train Loss 4.9295096 Test MSE 5.903641533550882 Test RE 1.1613631720170219\n",
      "15 Train Loss 4.3366137 Test MSE 5.7803117372871435 Test RE 1.1491684411619871\n",
      "16 Train Loss 3.973907 Test MSE 5.6443518571522535 Test RE 1.1355731092831591\n",
      "17 Train Loss 3.566714 Test MSE 5.430722896706083 Test RE 1.11387609085392\n",
      "18 Train Loss 3.3441942 Test MSE 5.449625515689105 Test RE 1.115812931120349\n",
      "19 Train Loss 3.1485085 Test MSE 5.312522299075649 Test RE 1.1016875543412157\n",
      "20 Train Loss 3.0067983 Test MSE 5.24415144516881 Test RE 1.0945753734547399\n",
      "21 Train Loss 2.8185267 Test MSE 5.0633635129311365 Test RE 1.0755425939901404\n",
      "22 Train Loss 2.6754956 Test MSE 4.832480658821331 Test RE 1.0507348153563782\n",
      "23 Train Loss 2.5781043 Test MSE 4.653623918080426 Test RE 1.0311069205312957\n",
      "24 Train Loss 2.493505 Test MSE 4.574510340986519 Test RE 1.022304722769764\n",
      "25 Train Loss 2.418333 Test MSE 4.530212280083462 Test RE 1.0173428490898768\n",
      "26 Train Loss 2.3595538 Test MSE 4.535852415672441 Test RE 1.0179759504128842\n",
      "27 Train Loss 2.2188177 Test MSE 4.274169880084611 Test RE 0.9881751994109899\n",
      "28 Train Loss 2.1163754 Test MSE 4.082341415057755 Test RE 0.965745563477998\n",
      "29 Train Loss 1.9728472 Test MSE 3.924922062890888 Test RE 0.9469424352168542\n",
      "30 Train Loss 1.8733337 Test MSE 3.853483530701696 Test RE 0.93828508728344\n",
      "31 Train Loss 1.7790906 Test MSE 3.6982668054284895 Test RE 0.9191939981786508\n",
      "32 Train Loss 1.6966594 Test MSE 3.6627543473462296 Test RE 0.9147700907852692\n",
      "33 Train Loss 1.6130196 Test MSE 3.5498116616839956 Test RE 0.9005559836178596\n",
      "34 Train Loss 1.5448915 Test MSE 3.4454776052207086 Test RE 0.8872229678203011\n",
      "35 Train Loss 1.5012355 Test MSE 3.4607381434180957 Test RE 0.8891856189428828\n",
      "36 Train Loss 1.4585377 Test MSE 3.356624968322498 Test RE 0.8757083094165388\n",
      "37 Train Loss 1.4160156 Test MSE 3.3288493254171936 Test RE 0.872077595683274\n",
      "38 Train Loss 1.3351943 Test MSE 3.264492633907452 Test RE 0.863606508647066\n",
      "39 Train Loss 1.2678963 Test MSE 3.163183782073848 Test RE 0.8501005025825501\n",
      "40 Train Loss 1.186119 Test MSE 3.0680490717099462 Test RE 0.8372192609369198\n",
      "41 Train Loss 1.151174 Test MSE 3.0748582381058083 Test RE 0.8381477998208435\n",
      "42 Train Loss 1.0951415 Test MSE 3.0151889824346205 Test RE 0.8299756077669348\n",
      "43 Train Loss 1.0453458 Test MSE 3.0056727175037916 Test RE 0.828664825985448\n",
      "44 Train Loss 1.0078207 Test MSE 2.953636950327661 Test RE 0.8214603700945767\n",
      "45 Train Loss 0.9689632 Test MSE 2.9573558306009344 Test RE 0.8219773516706955\n",
      "46 Train Loss 0.9380329 Test MSE 2.957638356105254 Test RE 0.8220166137739023\n",
      "47 Train Loss 0.9186055 Test MSE 2.9511831870064213 Test RE 0.8211190810045124\n",
      "48 Train Loss 0.90155435 Test MSE 2.9528961970428975 Test RE 0.8213573551278738\n",
      "49 Train Loss 0.88019216 Test MSE 2.930349986758057 Test RE 0.8182156971567031\n",
      "50 Train Loss 0.8660481 Test MSE 2.9404189231539473 Test RE 0.8196202216810252\n",
      "51 Train Loss 0.8437926 Test MSE 2.9347713643559548 Test RE 0.8188327355658096\n",
      "52 Train Loss 0.8286476 Test MSE 2.9261528184456047 Test RE 0.8176295180997193\n",
      "53 Train Loss 0.8114031 Test MSE 2.931876297575124 Test RE 0.8184287585481959\n",
      "54 Train Loss 0.80052316 Test MSE 2.937394729451108 Test RE 0.81919862733794\n",
      "55 Train Loss 0.78664166 Test MSE 2.9437254265021333 Test RE 0.8200809239882774\n",
      "56 Train Loss 0.77174014 Test MSE 2.9577289515300547 Test RE 0.8220292032735437\n",
      "57 Train Loss 0.7568637 Test MSE 2.9400392914257996 Test RE 0.8195673101923773\n",
      "58 Train Loss 0.7456446 Test MSE 2.94694403411515 Test RE 0.8205291311439202\n",
      "59 Train Loss 0.73731357 Test MSE 2.9719651143690893 Test RE 0.8240051270118773\n",
      "60 Train Loss 0.72253954 Test MSE 2.9858672741323264 Test RE 0.8259301303750746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 Train Loss 0.70907867 Test MSE 2.985890421170915 Test RE 0.8259333317564141\n",
      "62 Train Loss 0.70054924 Test MSE 2.997898419070037 Test RE 0.8275924439477731\n",
      "63 Train Loss 0.69382995 Test MSE 2.9873955274018993 Test RE 0.8261414708058643\n",
      "64 Train Loss 0.68278134 Test MSE 2.9838021928044753 Test RE 0.8256444666559348\n",
      "65 Train Loss 0.6720314 Test MSE 2.9587656039537498 Test RE 0.8221732468834967\n",
      "66 Train Loss 0.66482866 Test MSE 2.9648106617923737 Test RE 0.8230127099381996\n",
      "67 Train Loss 0.657598 Test MSE 2.9646884148179167 Test RE 0.8229957422693769\n",
      "68 Train Loss 0.65272105 Test MSE 2.9724209142514613 Test RE 0.8240683119797713\n",
      "69 Train Loss 0.6422018 Test MSE 2.983505114398196 Test RE 0.8256033635210694\n",
      "70 Train Loss 0.6388106 Test MSE 2.9885155257615392 Test RE 0.82629631979999\n",
      "71 Train Loss 0.6311703 Test MSE 2.9888253164671648 Test RE 0.8263391457924241\n",
      "72 Train Loss 0.6240476 Test MSE 2.9808990533547113 Test RE 0.8252427067214309\n",
      "73 Train Loss 0.61920786 Test MSE 2.99373259597452 Test RE 0.8270172406305311\n",
      "74 Train Loss 0.6098965 Test MSE 2.992882371221098 Test RE 0.8268997951944406\n",
      "75 Train Loss 0.60388976 Test MSE 2.995798890498236 Test RE 0.8273025978518895\n",
      "76 Train Loss 0.59614277 Test MSE 3.0011751149773813 Test RE 0.8280445987259739\n",
      "77 Train Loss 0.5884235 Test MSE 3.0071829283689535 Test RE 0.8288729826247296\n",
      "78 Train Loss 0.58433837 Test MSE 3.0139614567807866 Test RE 0.8298066432225498\n",
      "79 Train Loss 0.5776656 Test MSE 3.0119384606372823 Test RE 0.8295281098958328\n",
      "80 Train Loss 0.57238865 Test MSE 2.999983491092915 Test RE 0.8278801938432935\n",
      "81 Train Loss 0.56678367 Test MSE 3.0147385024222264 Test RE 0.8299136047896217\n",
      "82 Train Loss 0.56146175 Test MSE 3.0154646064113444 Test RE 0.8300135416993181\n",
      "83 Train Loss 0.5574256 Test MSE 3.0126289337454715 Test RE 0.8296231872085952\n",
      "84 Train Loss 0.55279166 Test MSE 3.021280274482202 Test RE 0.8308135441415277\n",
      "85 Train Loss 0.5483929 Test MSE 3.0324207457239734 Test RE 0.8323438784826641\n",
      "86 Train Loss 0.5434592 Test MSE 3.0556704759609605 Test RE 0.8355285980540585\n",
      "87 Train Loss 0.53886336 Test MSE 3.0472442049237456 Test RE 0.8343757821983563\n",
      "88 Train Loss 0.53480566 Test MSE 3.0659085151884033 Test RE 0.8369271489460866\n",
      "89 Train Loss 0.52846634 Test MSE 3.083412518327936 Test RE 0.8393128570268119\n",
      "90 Train Loss 0.5225822 Test MSE 3.081842132730548 Test RE 0.8390990982972012\n",
      "91 Train Loss 0.52057487 Test MSE 3.0828220151272765 Test RE 0.8392324849298887\n",
      "92 Train Loss 0.5155755 Test MSE 3.0873806231516703 Test RE 0.8398527475782798\n",
      "93 Train Loss 0.50849944 Test MSE 3.094744623740172 Test RE 0.8408537567444636\n",
      "94 Train Loss 0.50534314 Test MSE 3.0922917024739154 Test RE 0.8405204567192696\n",
      "95 Train Loss 0.5005064 Test MSE 3.0947350048055084 Test RE 0.8408524499930812\n",
      "96 Train Loss 0.49705184 Test MSE 3.0965228530825533 Test RE 0.8410952978533041\n",
      "97 Train Loss 0.49428555 Test MSE 3.116479242536374 Test RE 0.8438012794783678\n",
      "98 Train Loss 0.49231398 Test MSE 3.1058371698331846 Test RE 0.8423593520703573\n",
      "99 Train Loss 0.4899029 Test MSE 3.1136486328382267 Test RE 0.8434179920423098\n",
      "100 Train Loss 0.48542377 Test MSE 3.1319859161991794 Test RE 0.84589792672337\n",
      "101 Train Loss 0.48304132 Test MSE 3.126212152329038 Test RE 0.8451178676817511\n",
      "102 Train Loss 0.4801346 Test MSE 3.1299819106170785 Test RE 0.845627258932121\n",
      "103 Train Loss 0.47536308 Test MSE 3.133124563069713 Test RE 0.846051677654372\n",
      "104 Train Loss 0.47290006 Test MSE 3.144640394593149 Test RE 0.8476050873872757\n",
      "105 Train Loss 0.4707622 Test MSE 3.1478211436048618 Test RE 0.8480336479389288\n",
      "106 Train Loss 0.46897912 Test MSE 3.154009037137403 Test RE 0.8488667584226878\n",
      "107 Train Loss 0.46712765 Test MSE 3.1583418103613083 Test RE 0.8494496173894441\n",
      "108 Train Loss 0.46511194 Test MSE 3.1543626493418997 Test RE 0.8489143425020794\n",
      "109 Train Loss 0.4627626 Test MSE 3.1634465677184833 Test RE 0.8501358134567307\n",
      "110 Train Loss 0.45910084 Test MSE 3.161201337586264 Test RE 0.8498340714635884\n",
      "111 Train Loss 0.4576557 Test MSE 3.1623363545547085 Test RE 0.8499866225703033\n",
      "112 Train Loss 0.455686 Test MSE 3.172107375769395 Test RE 0.851298758737975\n",
      "113 Train Loss 0.45199057 Test MSE 3.1764535195468953 Test RE 0.851881746626466\n",
      "114 Train Loss 0.4494609 Test MSE 3.182982051236085 Test RE 0.8527567290927242\n",
      "115 Train Loss 0.44818017 Test MSE 3.1918990090771158 Test RE 0.8539503703978044\n",
      "116 Train Loss 0.44633242 Test MSE 3.1877650815999874 Test RE 0.8533972024186721\n",
      "117 Train Loss 0.44335806 Test MSE 3.19176702520321 Test RE 0.8539327149452325\n",
      "118 Train Loss 0.44077718 Test MSE 3.1977511786537667 Test RE 0.8547328471958564\n",
      "119 Train Loss 0.4387229 Test MSE 3.1936500673192105 Test RE 0.8541845745198269\n",
      "120 Train Loss 0.43671903 Test MSE 3.1981963767630925 Test RE 0.854792344039546\n",
      "121 Train Loss 0.4341516 Test MSE 3.203935577408626 Test RE 0.8555589676732547\n",
      "122 Train Loss 0.43251735 Test MSE 3.2098401863094743 Test RE 0.8563469697448589\n",
      "123 Train Loss 0.43086648 Test MSE 3.205920196778188 Test RE 0.8558239068390132\n",
      "124 Train Loss 0.42928594 Test MSE 3.213416493415903 Test RE 0.856823894918345\n",
      "125 Train Loss 0.42783695 Test MSE 3.2166365642923527 Test RE 0.8572530865334439\n",
      "126 Train Loss 0.42607677 Test MSE 3.2283848378600424 Test RE 0.8588171526645667\n",
      "127 Train Loss 0.42481625 Test MSE 3.2352470730606444 Test RE 0.8597294164077535\n",
      "128 Train Loss 0.42281282 Test MSE 3.2444523553097158 Test RE 0.8609516461584086\n",
      "129 Train Loss 0.4200225 Test MSE 3.246230661715614 Test RE 0.8611875605631482\n",
      "130 Train Loss 0.4182198 Test MSE 3.241528178520747 Test RE 0.8605635772236022\n",
      "131 Train Loss 0.4168485 Test MSE 3.2559262655563956 Test RE 0.862472667659577\n",
      "132 Train Loss 0.41513324 Test MSE 3.265892531757399 Test RE 0.8637916570682251\n",
      "133 Train Loss 0.41343766 Test MSE 3.2643846012583775 Test RE 0.8635922187586755\n",
      "134 Train Loss 0.4119736 Test MSE 3.268775877834868 Test RE 0.8641728791668668\n",
      "135 Train Loss 0.40924653 Test MSE 3.267780407960144 Test RE 0.8640412819565602\n",
      "136 Train Loss 0.40787977 Test MSE 3.2761419676284214 Test RE 0.865146025252597\n",
      "137 Train Loss 0.40706855 Test MSE 3.2847839522704043 Test RE 0.8662863382638237\n",
      "138 Train Loss 0.4052859 Test MSE 3.296031225902307 Test RE 0.8677681759487019\n",
      "139 Train Loss 0.40254343 Test MSE 3.304113213157145 Test RE 0.8688314239748749\n",
      "140 Train Loss 0.40134123 Test MSE 3.3067761189950495 Test RE 0.8691814649923223\n",
      "141 Train Loss 0.40055007 Test MSE 3.309359715813134 Test RE 0.8695209460958163\n",
      "142 Train Loss 0.39846206 Test MSE 3.3138488274209563 Test RE 0.8701104942383862\n",
      "143 Train Loss 0.39625612 Test MSE 3.318615910336954 Test RE 0.8707361109216812\n",
      "144 Train Loss 0.39478064 Test MSE 3.3112656922864403 Test RE 0.869771303877219\n",
      "145 Train Loss 0.39311126 Test MSE 3.308042391322731 Test RE 0.8693478680162289\n",
      "146 Train Loss 0.39068758 Test MSE 3.3159107354346853 Test RE 0.870381147624602\n",
      "147 Train Loss 0.38927114 Test MSE 3.3220897532645237 Test RE 0.8711917239551473\n",
      "148 Train Loss 0.38728765 Test MSE 3.3168840688320955 Test RE 0.8705088815939002\n",
      "149 Train Loss 0.38546643 Test MSE 3.314337678862395 Test RE 0.8701746702321904\n",
      "Training time: 236.62\n",
      "9\n",
      "KG_rowdy_tune72\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 61.383835 Test MSE 6.572731543125656 Test RE 1.2254088356525115\n",
      "1 Train Loss 43.115868 Test MSE 8.446061469044901 Test RE 1.3891053347538784\n",
      "2 Train Loss 34.627304 Test MSE 7.952957715824818 Test RE 1.3479456979617899\n",
      "3 Train Loss 30.742172 Test MSE 8.464425951527334 Test RE 1.3906146979563745\n",
      "4 Train Loss 27.951138 Test MSE 8.983936162632641 Test RE 1.4326542383125305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Train Loss 26.293005 Test MSE 9.017775249866691 Test RE 1.4353498355130159\n",
      "6 Train Loss 24.48138 Test MSE 9.12974699772129 Test RE 1.4442335566600686\n",
      "7 Train Loss 22.820103 Test MSE 9.040027077056013 Test RE 1.4371196444183545\n",
      "8 Train Loss 21.859547 Test MSE 9.16319188230649 Test RE 1.4468764595378403\n",
      "9 Train Loss 20.725496 Test MSE 9.324774972126024 Test RE 1.4595777702679218\n",
      "10 Train Loss 19.890535 Test MSE 9.27583935297036 Test RE 1.4557428628668794\n",
      "11 Train Loss 18.801992 Test MSE 9.078564692221907 Test RE 1.4401796056459693\n",
      "12 Train Loss 18.069447 Test MSE 9.039740046893442 Test RE 1.4370968292234436\n",
      "13 Train Loss 17.112225 Test MSE 8.993500024499006 Test RE 1.4334166025138262\n",
      "14 Train Loss 16.254265 Test MSE 8.827851570584858 Test RE 1.4201544254992593\n",
      "15 Train Loss 15.102669 Test MSE 8.516248920402035 Test RE 1.3948651819427138\n",
      "16 Train Loss 14.298522 Test MSE 8.443763435625565 Test RE 1.3889163456220572\n",
      "17 Train Loss 13.649475 Test MSE 8.215867329988452 Test RE 1.370044801366997\n",
      "18 Train Loss 13.220403 Test MSE 8.393183534500412 Test RE 1.3847501480989215\n",
      "19 Train Loss 12.765283 Test MSE 8.292972728707383 Test RE 1.376458680239891\n",
      "20 Train Loss 12.209499 Test MSE 8.251138955712662 Test RE 1.3729825285599997\n",
      "21 Train Loss 11.464476 Test MSE 7.9279482816520215 Test RE 1.345824606353953\n",
      "22 Train Loss 9.567993 Test MSE 6.754991569825823 Test RE 1.2422827820141789\n",
      "23 Train Loss 8.608255 Test MSE 6.775672447420599 Test RE 1.2441829963855378\n",
      "24 Train Loss 8.278145 Test MSE 6.5664129241199936 Test RE 1.2248196777592113\n",
      "25 Train Loss 7.957146 Test MSE 6.6714609480488685 Test RE 1.2345780021000885\n",
      "26 Train Loss 7.8020563 Test MSE 6.703509444870202 Test RE 1.2375397945655586\n",
      "27 Train Loss 7.6617174 Test MSE 6.757496649116276 Test RE 1.2425131100885844\n",
      "28 Train Loss 7.512389 Test MSE 6.725865355615743 Test RE 1.2396016474876894\n",
      "29 Train Loss 7.3628263 Test MSE 6.747041671566522 Test RE 1.2415515502214336\n",
      "30 Train Loss 7.240527 Test MSE 6.68369408431153 Test RE 1.2357093767782288\n",
      "31 Train Loss 7.1263576 Test MSE 6.791883856403799 Test RE 1.2456705173186375\n",
      "32 Train Loss 6.9943943 Test MSE 6.694323828352306 Test RE 1.2366916222089426\n",
      "33 Train Loss 6.8843317 Test MSE 6.691200933175672 Test RE 1.236403130875265\n",
      "34 Train Loss 6.756891 Test MSE 6.641489007762456 Test RE 1.2318016723519525\n",
      "35 Train Loss 6.631615 Test MSE 6.5910654292206905 Test RE 1.2271167146932098\n",
      "36 Train Loss 6.476733 Test MSE 6.559276964111985 Test RE 1.224153968777722\n",
      "37 Train Loss 6.3050156 Test MSE 6.463601236765942 Test RE 1.2151932205350378\n",
      "38 Train Loss 6.1402006 Test MSE 6.376633048550933 Test RE 1.2069902811664444\n",
      "39 Train Loss 5.864168 Test MSE 6.357655714749782 Test RE 1.20519289649821\n",
      "40 Train Loss 5.3721414 Test MSE 6.440051103602799 Test RE 1.212977421934649\n",
      "41 Train Loss 4.7302656 Test MSE 6.376794549902992 Test RE 1.2070055658258099\n",
      "42 Train Loss 4.0220084 Test MSE 6.1625052673270355 Test RE 1.1865518260588308\n",
      "43 Train Loss 3.483181 Test MSE 6.070660589421144 Test RE 1.1776765742028288\n",
      "44 Train Loss 2.846754 Test MSE 6.144078378294689 Test RE 1.1847765068557312\n",
      "45 Train Loss 2.2965262 Test MSE 5.781174331388057 Test RE 1.1492541829856582\n",
      "46 Train Loss 2.0296597 Test MSE 5.6427193309115165 Test RE 1.1354088754602327\n",
      "47 Train Loss 1.8406708 Test MSE 5.6834937390203315 Test RE 1.1395037355507014\n",
      "48 Train Loss 1.6223354 Test MSE 5.760469751100248 Test RE 1.1471943793065802\n",
      "49 Train Loss 1.5038867 Test MSE 5.656792607311113 Test RE 1.1368238822419092\n",
      "50 Train Loss 1.4023168 Test MSE 5.699909977637854 Test RE 1.1411482237532344\n",
      "51 Train Loss 1.3380535 Test MSE 5.736521154765283 Test RE 1.1448072207400204\n",
      "52 Train Loss 1.2907662 Test MSE 5.750509259421976 Test RE 1.146202136979904\n",
      "53 Train Loss 1.2523237 Test MSE 5.78740288964039 Test RE 1.1498731117030225\n",
      "54 Train Loss 1.2248669 Test MSE 5.83550346259607 Test RE 1.1546416675411872\n",
      "55 Train Loss 1.1946757 Test MSE 5.811339851301699 Test RE 1.1522486216862067\n",
      "56 Train Loss 1.1700716 Test MSE 5.84106763642857 Test RE 1.1551920139035026\n",
      "57 Train Loss 1.1429343 Test MSE 5.880356911834561 Test RE 1.1590706362350305\n",
      "58 Train Loss 1.1223965 Test MSE 5.907124091702813 Test RE 1.1617056655839266\n",
      "59 Train Loss 1.1030824 Test MSE 5.956557458798601 Test RE 1.1665563660509821\n",
      "60 Train Loss 1.0861514 Test MSE 5.994209044174307 Test RE 1.170237477686154\n",
      "61 Train Loss 1.067371 Test MSE 5.980969654805521 Test RE 1.168944413502993\n",
      "62 Train Loss 1.0478264 Test MSE 5.992674685735299 Test RE 1.1700876932312594\n",
      "63 Train Loss 1.0333868 Test MSE 6.002151672944766 Test RE 1.1710125328119791\n",
      "64 Train Loss 1.0127544 Test MSE 5.975629807956104 Test RE 1.168422476564105\n",
      "65 Train Loss 0.99888647 Test MSE 5.99341188461148 Test RE 1.1701596611630425\n",
      "66 Train Loss 0.98978287 Test MSE 5.994621564887927 Test RE 1.170277744791495\n",
      "67 Train Loss 0.97782975 Test MSE 6.00642816070443 Test RE 1.1714296273261484\n",
      "68 Train Loss 0.96423084 Test MSE 6.019092134284974 Test RE 1.1726639001893977\n",
      "69 Train Loss 0.9564419 Test MSE 6.022818013598812 Test RE 1.1730267894868256\n",
      "70 Train Loss 0.9467771 Test MSE 6.032215488003471 Test RE 1.1739415765961536\n",
      "71 Train Loss 0.9393682 Test MSE 6.018579635700291 Test RE 1.172613975602005\n",
      "72 Train Loss 0.9314928 Test MSE 6.040101487827874 Test RE 1.17470868110197\n",
      "73 Train Loss 0.9212673 Test MSE 6.083857590419155 Test RE 1.1789559540405585\n",
      "74 Train Loss 0.91427433 Test MSE 6.072666152702907 Test RE 1.1778710925601716\n",
      "75 Train Loss 0.9069495 Test MSE 6.077789935943691 Test RE 1.1783678993593036\n",
      "76 Train Loss 0.8996947 Test MSE 6.074621918620773 Test RE 1.1780607501695752\n",
      "77 Train Loss 0.8940838 Test MSE 6.082942150309125 Test RE 1.178867251753022\n",
      "78 Train Loss 0.87934077 Test MSE 6.126326433215765 Test RE 1.183063694937215\n",
      "79 Train Loss 0.87266546 Test MSE 6.1238015486100945 Test RE 1.1828198777671481\n",
      "80 Train Loss 0.8652093 Test MSE 6.129359361605377 Test RE 1.183356505279983\n",
      "81 Train Loss 0.8594041 Test MSE 6.104941651339199 Test RE 1.1809970669302046\n",
      "82 Train Loss 0.8528639 Test MSE 6.130627862189782 Test RE 1.1834789496231524\n",
      "83 Train Loss 0.8462761 Test MSE 6.142138338631682 Test RE 1.1845894409733062\n",
      "84 Train Loss 0.8415359 Test MSE 6.148059245229636 Test RE 1.1851602644846833\n",
      "85 Train Loss 0.83611184 Test MSE 6.1507705477721615 Test RE 1.185421564328896\n",
      "86 Train Loss 0.8320762 Test MSE 6.141561793754841 Test RE 1.1845338426650678\n",
      "87 Train Loss 0.8282082 Test MSE 6.136996401736539 Test RE 1.184093493214622\n",
      "88 Train Loss 0.82483137 Test MSE 6.157207363582561 Test RE 1.1860416772849427\n",
      "89 Train Loss 0.8210376 Test MSE 6.152026166627708 Test RE 1.1855425541871325\n",
      "90 Train Loss 0.81713957 Test MSE 6.167263813070935 Test RE 1.1870098517593448\n",
      "91 Train Loss 0.8131268 Test MSE 6.1889711939284675 Test RE 1.189097020569431\n",
      "92 Train Loss 0.8093416 Test MSE 6.176574512962056 Test RE 1.1879055264641856\n",
      "93 Train Loss 0.8054689 Test MSE 6.16882152970194 Test RE 1.187159748723555\n",
      "94 Train Loss 0.8021069 Test MSE 6.180261502382309 Test RE 1.1882600224461555\n",
      "95 Train Loss 0.7986709 Test MSE 6.19065131730585 Test RE 1.1892584120244938\n",
      "96 Train Loss 0.79606557 Test MSE 6.205020877777675 Test RE 1.1906378480961093\n",
      "97 Train Loss 0.79306686 Test MSE 6.211816037154993 Test RE 1.1912896073971297\n",
      "98 Train Loss 0.7891222 Test MSE 6.212681818974366 Test RE 1.1913726234540996\n",
      "99 Train Loss 0.7846272 Test MSE 6.2246587289359825 Test RE 1.1925204443705038\n",
      "100 Train Loss 0.7808641 Test MSE 6.245893522058479 Test RE 1.1945527939452076\n",
      "101 Train Loss 0.77763027 Test MSE 6.263373966369902 Test RE 1.1962232293874753\n",
      "102 Train Loss 0.77458864 Test MSE 6.244712083855327 Test RE 1.1944398111473329\n",
      "103 Train Loss 0.7719662 Test MSE 6.236966424339517 Test RE 1.1936988166386175\n",
      "104 Train Loss 0.76937014 Test MSE 6.257114936307484 Test RE 1.1956253831922283\n",
      "105 Train Loss 0.76593983 Test MSE 6.2496172414161295 Test RE 1.1949088291992453\n",
      "106 Train Loss 0.76277965 Test MSE 6.246943239402322 Test RE 1.1946531711050088\n",
      "107 Train Loss 0.7604039 Test MSE 6.245307284394455 Test RE 1.1944967324489566\n",
      "108 Train Loss 0.757853 Test MSE 6.234975820351677 Test RE 1.1935083096605363\n",
      "109 Train Loss 0.7557985 Test MSE 6.250556036092192 Test RE 1.19499857324915\n",
      "110 Train Loss 0.75352734 Test MSE 6.261011164415792 Test RE 1.195997575833049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 Train Loss 0.75183094 Test MSE 6.267884021739058 Test RE 1.1966538329391059\n",
      "112 Train Loss 0.74904907 Test MSE 6.251895307235363 Test RE 1.1951265891709828\n",
      "113 Train Loss 0.7465979 Test MSE 6.268912526165505 Test RE 1.1967520090759496\n",
      "114 Train Loss 0.74427134 Test MSE 6.275429908047797 Test RE 1.1973739402062804\n",
      "115 Train Loss 0.74218744 Test MSE 6.268630212264552 Test RE 1.1967250615367535\n",
      "116 Train Loss 0.7400638 Test MSE 6.285687935703275 Test RE 1.1983521743547556\n",
      "117 Train Loss 0.738038 Test MSE 6.288209110826826 Test RE 1.1985924784255415\n",
      "118 Train Loss 0.73557836 Test MSE 6.277902474546161 Test RE 1.1976098041365637\n",
      "119 Train Loss 0.7336396 Test MSE 6.299630787141786 Test RE 1.1996805246596929\n",
      "120 Train Loss 0.7311323 Test MSE 6.303264145954151 Test RE 1.200026437113304\n",
      "121 Train Loss 0.72903216 Test MSE 6.288155094289706 Test RE 1.1985873303815597\n",
      "122 Train Loss 0.7264296 Test MSE 6.293147607262598 Test RE 1.199063048253348\n",
      "123 Train Loss 0.7242634 Test MSE 6.304372119987475 Test RE 1.2001319014947343\n",
      "124 Train Loss 0.722144 Test MSE 6.3229097350240435 Test RE 1.20189506302382\n",
      "125 Train Loss 0.7203743 Test MSE 6.320627899943236 Test RE 1.2016781712832194\n",
      "126 Train Loss 0.7182955 Test MSE 6.3294192094191555 Test RE 1.2025135830457632\n",
      "127 Train Loss 0.7153204 Test MSE 6.331250992596201 Test RE 1.2026875788524047\n",
      "128 Train Loss 0.71341604 Test MSE 6.343907848668156 Test RE 1.203889129973149\n",
      "129 Train Loss 0.71078074 Test MSE 6.346208403909793 Test RE 1.2041073994110636\n",
      "130 Train Loss 0.70932424 Test MSE 6.354411713596675 Test RE 1.2048853817337934\n",
      "131 Train Loss 0.707789 Test MSE 6.350327436090109 Test RE 1.2044981014085863\n",
      "132 Train Loss 0.7059794 Test MSE 6.364093162273138 Test RE 1.2058029014618346\n",
      "133 Train Loss 0.7041858 Test MSE 6.370010641184324 Test RE 1.206363362723557\n",
      "134 Train Loss 0.7023539 Test MSE 6.376971835649788 Test RE 1.2070223441141947\n",
      "135 Train Loss 0.7004535 Test MSE 6.384880823875964 Test RE 1.2077706120734983\n",
      "136 Train Loss 0.6988911 Test MSE 6.379182091544986 Test RE 1.2072315027237563\n",
      "137 Train Loss 0.6966001 Test MSE 6.3783006346931455 Test RE 1.2071480939711574\n",
      "138 Train Loss 0.6953183 Test MSE 6.37804626209534 Test RE 1.2071240226333702\n",
      "139 Train Loss 0.6935133 Test MSE 6.380821806043081 Test RE 1.20738664704956\n",
      "140 Train Loss 0.69013476 Test MSE 6.386882665890323 Test RE 1.2079599324807013\n",
      "141 Train Loss 0.6877242 Test MSE 6.391415613163287 Test RE 1.2083885177360822\n",
      "142 Train Loss 0.6854747 Test MSE 6.388250564466861 Test RE 1.2080892818280224\n",
      "143 Train Loss 0.6838261 Test MSE 6.394137754504304 Test RE 1.2086458202156605\n",
      "144 Train Loss 0.6824548 Test MSE 6.392919173144654 Test RE 1.2085306441354335\n",
      "145 Train Loss 0.6805379 Test MSE 6.408711567062692 Test RE 1.210022436793427\n",
      "146 Train Loss 0.6792991 Test MSE 6.400334595366066 Test RE 1.2092313543644373\n",
      "147 Train Loss 0.677989 Test MSE 6.400652514199299 Test RE 1.209261386594918\n",
      "148 Train Loss 0.6763646 Test MSE 6.405934966016753 Test RE 1.2097602847591464\n",
      "149 Train Loss 0.67524564 Test MSE 6.402839897579698 Test RE 1.2094679977415266\n",
      "Training time: 236.80\n",
      "0\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 73.02993 Test MSE 4.39471272603588 Test RE 1.0020128843966685\n",
      "1 Train Loss 69.29422 Test MSE 4.848446922756564 Test RE 1.0524691704839955\n",
      "2 Train Loss 48.219925 Test MSE 7.770763423486779 Test RE 1.332416198692476\n",
      "3 Train Loss 39.763863 Test MSE 8.448903545062795 Test RE 1.3893390301224613\n",
      "4 Train Loss 34.031147 Test MSE 9.010227696117362 Test RE 1.4347490416659239\n",
      "5 Train Loss 31.39591 Test MSE 9.406446332971042 Test RE 1.465955716285304\n",
      "6 Train Loss 29.426012 Test MSE 9.49856742426164 Test RE 1.473116572058629\n",
      "7 Train Loss 27.140514 Test MSE 9.570501818507504 Test RE 1.478684141954165\n",
      "8 Train Loss 26.127218 Test MSE 9.697497620725755 Test RE 1.4884625121288193\n",
      "9 Train Loss 24.516325 Test MSE 9.876594549221709 Test RE 1.5021443654633782\n",
      "10 Train Loss 23.065235 Test MSE 9.895770665434712 Test RE 1.503601918795559\n",
      "11 Train Loss 21.819508 Test MSE 9.671064381789757 Test RE 1.4864325176527886\n",
      "12 Train Loss 20.976938 Test MSE 9.76831486716553 Test RE 1.4938874722422866\n",
      "13 Train Loss 20.399965 Test MSE 9.699970470247031 Test RE 1.4886522780528841\n",
      "14 Train Loss 19.27877 Test MSE 9.683688265894201 Test RE 1.4874023401885539\n",
      "15 Train Loss 18.50541 Test MSE 9.500282942401554 Test RE 1.4732495944394104\n",
      "16 Train Loss 17.787994 Test MSE 9.39930109759795 Test RE 1.4653988328365417\n",
      "17 Train Loss 17.145048 Test MSE 9.266511344451365 Test RE 1.4550107136286528\n",
      "18 Train Loss 16.114494 Test MSE 9.180563129881323 Test RE 1.4482472781747378\n",
      "19 Train Loss 14.99362 Test MSE 8.489592950036116 Test RE 1.3926804979604772\n",
      "20 Train Loss 13.444744 Test MSE 8.496906377658949 Test RE 1.393280236692517\n",
      "21 Train Loss 11.334957 Test MSE 7.963438152655296 Test RE 1.3488335694389417\n",
      "22 Train Loss 10.067418 Test MSE 7.684389769844906 Test RE 1.3249904646309452\n",
      "23 Train Loss 8.4985695 Test MSE 6.9755960754934545 Test RE 1.2624050483611653\n",
      "24 Train Loss 6.4583893 Test MSE 6.989339432843086 Test RE 1.2636480350758186\n",
      "25 Train Loss 5.4152756 Test MSE 6.3542235307237735 Test RE 1.2048675405486777\n",
      "26 Train Loss 4.6792293 Test MSE 6.475317680950526 Test RE 1.2162941004270371\n",
      "27 Train Loss 4.2840514 Test MSE 6.4579735326765215 Test RE 1.2146640853951751\n",
      "28 Train Loss 3.8960843 Test MSE 6.503505265292363 Test RE 1.2189385392429057\n",
      "29 Train Loss 3.6272051 Test MSE 6.760248334875169 Test RE 1.242766063054725\n",
      "30 Train Loss 3.3810449 Test MSE 6.894299651328189 Test RE 1.2550271991815602\n",
      "31 Train Loss 3.097248 Test MSE 7.039718068216583 Test RE 1.2681939982604147\n",
      "32 Train Loss 2.9625356 Test MSE 6.974456623037747 Test RE 1.262301938228079\n",
      "33 Train Loss 2.813051 Test MSE 6.792341989194964 Test RE 1.2457125287030932\n",
      "34 Train Loss 2.6877418 Test MSE 6.81810452610874 Test RE 1.2480727118090724\n",
      "35 Train Loss 2.6021252 Test MSE 6.8118698272973095 Test RE 1.247501941947806\n",
      "36 Train Loss 2.521547 Test MSE 6.873446312887429 Test RE 1.2531277076718872\n",
      "37 Train Loss 2.4186351 Test MSE 6.682705971445285 Test RE 1.235618030177773\n",
      "38 Train Loss 2.3368764 Test MSE 6.6618561251222665 Test RE 1.2336889783774654\n",
      "39 Train Loss 2.2765796 Test MSE 6.661863746297253 Test RE 1.233689684048431\n",
      "40 Train Loss 2.1942234 Test MSE 6.6000898294837045 Test RE 1.2279565033831603\n",
      "41 Train Loss 2.1186686 Test MSE 6.579728158465055 Test RE 1.226060880677698\n",
      "42 Train Loss 2.0844958 Test MSE 6.468806908785904 Test RE 1.2156824697891326\n",
      "43 Train Loss 2.045081 Test MSE 6.455269685864649 Test RE 1.214409778882684\n",
      "44 Train Loss 1.99542 Test MSE 6.359875670860502 Test RE 1.205403291802818\n",
      "45 Train Loss 1.9502332 Test MSE 6.282973952190607 Test RE 1.1980934390169162\n",
      "46 Train Loss 1.9112587 Test MSE 6.231741853069849 Test RE 1.1931987441094731\n",
      "47 Train Loss 1.8661726 Test MSE 6.071437070763485 Test RE 1.1777518884651386\n",
      "48 Train Loss 1.8354925 Test MSE 5.945669128818063 Test RE 1.1654896710125788\n",
      "49 Train Loss 1.8025311 Test MSE 5.946041893165716 Test RE 1.1655262056883395\n",
      "50 Train Loss 1.764697 Test MSE 5.839450879379218 Test RE 1.1550321292553223\n",
      "51 Train Loss 1.7363341 Test MSE 5.788746769959987 Test RE 1.1500066087290206\n",
      "52 Train Loss 1.6826912 Test MSE 5.730364927857162 Test RE 1.144192773004687\n",
      "53 Train Loss 1.6661804 Test MSE 5.672108642105357 Test RE 1.138361844260738\n",
      "54 Train Loss 1.6294776 Test MSE 5.634789032289297 Test RE 1.134610741019422\n",
      "55 Train Loss 1.6180003 Test MSE 5.654884792092695 Test RE 1.1366321629274752\n",
      "56 Train Loss 1.5973603 Test MSE 5.683861721594331 Test RE 1.1395406240166606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 Train Loss 1.5749302 Test MSE 5.621294417885332 Test RE 1.1332513012589522\n",
      "58 Train Loss 1.5558531 Test MSE 5.6222685940656465 Test RE 1.133349493820627\n",
      "59 Train Loss 1.5276822 Test MSE 5.563053097267872 Test RE 1.1273652990309218\n",
      "60 Train Loss 1.5058773 Test MSE 5.5751294395783315 Test RE 1.1285882847213775\n",
      "61 Train Loss 1.4870794 Test MSE 5.557021669194653 Test RE 1.1267539920182508\n",
      "62 Train Loss 1.4649447 Test MSE 5.584520451920481 Test RE 1.1295384085876032\n",
      "63 Train Loss 1.4553919 Test MSE 5.5830390621116885 Test RE 1.129388583935402\n",
      "64 Train Loss 1.4398472 Test MSE 5.563057424425003 Test RE 1.1273657374849289\n",
      "65 Train Loss 1.4290773 Test MSE 5.5485210297593035 Test RE 1.1258918579708557\n",
      "66 Train Loss 1.4177306 Test MSE 5.580178594664728 Test RE 1.1290992260117108\n",
      "67 Train Loss 1.4076471 Test MSE 5.563161557055336 Test RE 1.1273762887880407\n",
      "68 Train Loss 1.4023361 Test MSE 5.5737721855781235 Test RE 1.1284509000902923\n",
      "69 Train Loss 1.3846061 Test MSE 5.544286488999495 Test RE 1.1254621448156987\n",
      "70 Train Loss 1.3766233 Test MSE 5.5254148132963765 Test RE 1.1235450846905644\n",
      "71 Train Loss 1.367886 Test MSE 5.548339982198568 Test RE 1.1258734889643862\n",
      "72 Train Loss 1.3635278 Test MSE 5.540831908693762 Test RE 1.1251114590062101\n",
      "73 Train Loss 1.3563397 Test MSE 5.518702100683484 Test RE 1.1228623913929219\n",
      "74 Train Loss 1.3477653 Test MSE 5.490075995342353 Test RE 1.119946400684864\n",
      "75 Train Loss 1.3406904 Test MSE 5.486620071866066 Test RE 1.1195938501599434\n",
      "76 Train Loss 1.3324722 Test MSE 5.480059801753642 Test RE 1.1189243090928538\n",
      "77 Train Loss 1.3244191 Test MSE 5.494381364019094 Test RE 1.120385450818788\n",
      "78 Train Loss 1.3082395 Test MSE 5.488207274181379 Test RE 1.1197557798570619\n",
      "79 Train Loss 1.2985284 Test MSE 5.5086176019508875 Test RE 1.121836001325358\n",
      "80 Train Loss 1.2892107 Test MSE 5.510288906666424 Test RE 1.1220061699360269\n",
      "81 Train Loss 1.2818663 Test MSE 5.5241791243987315 Test RE 1.1234194443663001\n",
      "82 Train Loss 1.2756665 Test MSE 5.523489662468283 Test RE 1.1233493362931772\n",
      "83 Train Loss 1.2604394 Test MSE 5.513828451425857 Test RE 1.122366473503877\n",
      "84 Train Loss 1.2535963 Test MSE 5.49299295943801 Test RE 1.1202438837822284\n",
      "85 Train Loss 1.2457448 Test MSE 5.523189398524201 Test RE 1.1233188025267482\n",
      "86 Train Loss 1.2376212 Test MSE 5.528803428099343 Test RE 1.1238895545707455\n",
      "87 Train Loss 1.22938 Test MSE 5.531536581642991 Test RE 1.1241673165876505\n",
      "88 Train Loss 1.22448 Test MSE 5.519424202781162 Test RE 1.122935850220008\n",
      "89 Train Loss 1.2175623 Test MSE 5.5500518683308995 Test RE 1.1260471642054537\n",
      "90 Train Loss 1.2118375 Test MSE 5.540862024450313 Test RE 1.1251145166279997\n",
      "91 Train Loss 1.2068756 Test MSE 5.5540097490278395 Test RE 1.1264485988377015\n",
      "92 Train Loss 1.1994466 Test MSE 5.540010053963608 Test RE 1.1250280137329203\n",
      "93 Train Loss 1.1942726 Test MSE 5.537466544507904 Test RE 1.1247697246791981\n",
      "94 Train Loss 1.190785 Test MSE 5.537296814580086 Test RE 1.1247524867829912\n",
      "95 Train Loss 1.1839956 Test MSE 5.552624605056426 Test RE 1.1263081245811826\n",
      "96 Train Loss 1.1787918 Test MSE 5.565054408397599 Test RE 1.127568065910836\n",
      "97 Train Loss 1.1742904 Test MSE 5.577898341431162 Test RE 1.1288685080165737\n",
      "98 Train Loss 1.1698714 Test MSE 5.590950433207994 Test RE 1.1301884931811355\n",
      "99 Train Loss 1.1650398 Test MSE 5.597932886200298 Test RE 1.130894010585361\n",
      "100 Train Loss 1.1606414 Test MSE 5.595250330457609 Test RE 1.130623013253808\n",
      "101 Train Loss 1.1571952 Test MSE 5.60572946776472 Test RE 1.1316812689965512\n",
      "102 Train Loss 1.1531208 Test MSE 5.6240718074565565 Test RE 1.1335312271468458\n",
      "103 Train Loss 1.1475213 Test MSE 5.632714728132648 Test RE 1.134401882763993\n",
      "104 Train Loss 1.1445959 Test MSE 5.6206060845543835 Test RE 1.133181915236259\n",
      "105 Train Loss 1.1410176 Test MSE 5.62094733362984 Test RE 1.1332163146769763\n",
      "106 Train Loss 1.1374063 Test MSE 5.631117040369112 Test RE 1.134240988006011\n",
      "107 Train Loss 1.1327775 Test MSE 5.653190924082127 Test RE 1.1364619163946337\n",
      "108 Train Loss 1.1266507 Test MSE 5.660299446177774 Test RE 1.1371762056145838\n",
      "109 Train Loss 1.1222687 Test MSE 5.669788398887493 Test RE 1.1381289902480682\n",
      "110 Train Loss 1.1195667 Test MSE 5.663096212461155 Test RE 1.1374571115396825\n",
      "111 Train Loss 1.1164397 Test MSE 5.675192966145172 Test RE 1.1386713058603564\n",
      "112 Train Loss 1.1128876 Test MSE 5.669125663569225 Test RE 1.1380624709824014\n",
      "113 Train Loss 1.108826 Test MSE 5.671979227540478 Test RE 1.1383488577814254\n",
      "114 Train Loss 1.1047894 Test MSE 5.677931315796841 Test RE 1.1389459841096405\n",
      "115 Train Loss 1.1001376 Test MSE 5.680466409863975 Test RE 1.1392002151695697\n",
      "116 Train Loss 1.096158 Test MSE 5.682413396995302 Test RE 1.1393954296093003\n",
      "117 Train Loss 1.0935161 Test MSE 5.681531295933083 Test RE 1.1393069899925052\n",
      "118 Train Loss 1.0900145 Test MSE 5.686195348084909 Test RE 1.1397745309464773\n",
      "119 Train Loss 1.0854957 Test MSE 5.69799101893854 Test RE 1.1409561153989547\n",
      "120 Train Loss 1.0828726 Test MSE 5.701099644820923 Test RE 1.1412673059639833\n",
      "121 Train Loss 1.078633 Test MSE 5.710296587913856 Test RE 1.142187474129637\n",
      "122 Train Loss 1.0744689 Test MSE 5.7221484568050744 Test RE 1.1433721796117668\n",
      "123 Train Loss 1.0698388 Test MSE 5.747756193615621 Test RE 1.1459277310497393\n",
      "124 Train Loss 1.064127 Test MSE 5.752958153620793 Test RE 1.1464461700614548\n",
      "125 Train Loss 1.0582539 Test MSE 5.754359260565497 Test RE 1.1465857674527646\n",
      "126 Train Loss 1.051214 Test MSE 5.745932440013356 Test RE 1.145745916132492\n",
      "127 Train Loss 1.0473648 Test MSE 5.758679537616773 Test RE 1.1470161054399268\n",
      "128 Train Loss 1.0411333 Test MSE 5.764706592742385 Test RE 1.1476161841013304\n",
      "129 Train Loss 1.0339079 Test MSE 5.773866731179819 Test RE 1.1485276051975826\n",
      "130 Train Loss 1.0258796 Test MSE 5.7771803977819545 Test RE 1.1488571323455836\n",
      "131 Train Loss 1.0127263 Test MSE 5.838125802738116 Test RE 1.1549010730172855\n",
      "132 Train Loss 0.99911904 Test MSE 5.84556471806066 Test RE 1.1556366238258107\n",
      "133 Train Loss 0.9920023 Test MSE 5.857017063672936 Test RE 1.1567681033986976\n",
      "134 Train Loss 0.98318875 Test MSE 5.87356511832218 Test RE 1.1584010813983383\n",
      "135 Train Loss 0.9773253 Test MSE 5.8606537994333685 Test RE 1.157127177570312\n",
      "136 Train Loss 0.9699075 Test MSE 5.876893501436691 Test RE 1.1587292514671967\n",
      "137 Train Loss 0.9645241 Test MSE 5.890358480767932 Test RE 1.1600559165470519\n",
      "138 Train Loss 0.9588205 Test MSE 5.903004200960152 Test RE 1.161300482355682\n",
      "139 Train Loss 0.9530809 Test MSE 5.917557256979007 Test RE 1.1627311155354396\n",
      "140 Train Loss 0.94835603 Test MSE 5.929596106428563 Test RE 1.1639132614800949\n",
      "141 Train Loss 0.9439663 Test MSE 5.93940951146912 Test RE 1.1648759940315772\n",
      "142 Train Loss 0.940038 Test MSE 5.937520458601501 Test RE 1.1646907325732656\n",
      "143 Train Loss 0.9361291 Test MSE 5.9421003982865965 Test RE 1.1651398413466048\n",
      "144 Train Loss 0.93221843 Test MSE 5.955248938910886 Test RE 1.1664282260928664\n",
      "145 Train Loss 0.927745 Test MSE 5.968760232234671 Test RE 1.1677506750055409\n",
      "146 Train Loss 0.92289156 Test MSE 5.9910924719512675 Test RE 1.1699332170424879\n",
      "147 Train Loss 0.9191351 Test MSE 6.006325547670113 Test RE 1.1714196210080243\n",
      "148 Train Loss 0.91642904 Test MSE 6.019390693525767 Test RE 1.1726929830888206\n",
      "149 Train Loss 0.91225576 Test MSE 6.024949683989369 Test RE 1.1732343572113868\n",
      "Training time: 232.52\n",
      "1\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 69.53492 Test MSE 5.341222284729897 Test RE 1.104659384568603\n",
      "1 Train Loss 52.29545 Test MSE 8.635968558015337 Test RE 1.404635325915357\n",
      "2 Train Loss 43.3797 Test MSE 9.922865802078181 Test RE 1.5056589819425408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Train Loss 40.098152 Test MSE 9.989147877134453 Test RE 1.5106793108297278\n",
      "4 Train Loss 37.79384 Test MSE 10.1255803004379 Test RE 1.520960801104194\n",
      "5 Train Loss 36.59515 Test MSE 10.186385631001956 Test RE 1.52552074209981\n",
      "6 Train Loss 35.868923 Test MSE 10.158421004890226 Test RE 1.5234253012844547\n",
      "7 Train Loss 35.077194 Test MSE 10.109169008227061 Test RE 1.5197277332884005\n",
      "8 Train Loss 34.459717 Test MSE 10.09057486055948 Test RE 1.5183294458609642\n",
      "9 Train Loss 33.795044 Test MSE 9.931098268498491 Test RE 1.5062834344644818\n",
      "10 Train Loss 33.39164 Test MSE 10.069938384583663 Test RE 1.516776065309331\n",
      "11 Train Loss 32.77091 Test MSE 10.021696928662847 Test RE 1.5131385390398049\n",
      "12 Train Loss 32.084316 Test MSE 10.043221907688606 Test RE 1.5147626554637685\n",
      "13 Train Loss 31.436018 Test MSE 10.15798191419697 Test RE 1.5233923764283224\n",
      "14 Train Loss 31.085499 Test MSE 10.35458009326713 Test RE 1.5380636422815113\n",
      "15 Train Loss 30.388134 Test MSE 10.028640763979359 Test RE 1.5136626601298142\n",
      "16 Train Loss 29.628592 Test MSE 9.926182607394399 Test RE 1.505910600807735\n",
      "17 Train Loss 29.256342 Test MSE 9.486909228617689 Test RE 1.4722122696874667\n",
      "18 Train Loss 28.732567 Test MSE 9.377773335283718 Test RE 1.4637197270446876\n",
      "19 Train Loss 28.396574 Test MSE 9.194211498592987 Test RE 1.4493234034411735\n",
      "20 Train Loss 26.11632 Test MSE 8.85473594297532 Test RE 1.4223152534171064\n",
      "21 Train Loss 24.099503 Test MSE 9.028662707784813 Test RE 1.4362160467736729\n",
      "22 Train Loss 23.279507 Test MSE 9.375167176946764 Test RE 1.4635163231926775\n",
      "23 Train Loss 22.513435 Test MSE 9.179951613765324 Test RE 1.448199043590084\n",
      "24 Train Loss 22.031906 Test MSE 8.97172666299596 Test RE 1.4316803924284902\n",
      "25 Train Loss 21.571543 Test MSE 9.065650419272927 Test RE 1.4391549122008187\n",
      "26 Train Loss 21.199171 Test MSE 8.96038333893538 Test RE 1.4307750398843004\n",
      "27 Train Loss 20.960009 Test MSE 8.852732268062603 Test RE 1.4221543215357773\n",
      "28 Train Loss 20.679573 Test MSE 9.028391131062627 Test RE 1.4361944463555343\n",
      "29 Train Loss 20.534582 Test MSE 9.133811946248178 Test RE 1.444555037734013\n",
      "30 Train Loss 20.310062 Test MSE 8.943568866312512 Test RE 1.429431959810548\n",
      "31 Train Loss 20.03178 Test MSE 8.856513685948553 Test RE 1.422458023572299\n",
      "32 Train Loss 19.798407 Test MSE 8.809447121895658 Test RE 1.4186732725789493\n",
      "33 Train Loss 19.634995 Test MSE 8.846415937824066 Test RE 1.4216468850219874\n",
      "34 Train Loss 19.349655 Test MSE 8.88014929509281 Test RE 1.424354834318472\n",
      "35 Train Loss 19.06238 Test MSE 9.186581688618316 Test RE 1.4487219186240434\n",
      "36 Train Loss 18.953373 Test MSE 9.117878099693502 Test RE 1.4432944815946762\n",
      "37 Train Loss 18.713552 Test MSE 8.81484070549069 Test RE 1.419107497448509\n",
      "38 Train Loss 18.504347 Test MSE 8.759721705961072 Test RE 1.414663716299407\n",
      "39 Train Loss 18.233093 Test MSE 8.531882353331033 Test RE 1.3961448846019635\n",
      "40 Train Loss 17.947306 Test MSE 8.058994388140583 Test RE 1.356902013632866\n",
      "41 Train Loss 16.881924 Test MSE 7.116183400866312 Test RE 1.2750629499682753\n",
      "42 Train Loss 15.879125 Test MSE 6.787105027451871 Test RE 1.2452322078638642\n",
      "43 Train Loss 15.440487 Test MSE 6.804620146881527 Test RE 1.24683792470851\n",
      "44 Train Loss 14.785931 Test MSE 7.05597522217655 Test RE 1.2696575040089564\n",
      "45 Train Loss 14.253542 Test MSE 6.927452687819609 Test RE 1.2580411428640061\n",
      "46 Train Loss 13.951677 Test MSE 6.9311223034133596 Test RE 1.2583743040126785\n",
      "47 Train Loss 13.674325 Test MSE 6.787664182728314 Test RE 1.2452835010011065\n",
      "48 Train Loss 13.454834 Test MSE 6.804697122751826 Test RE 1.246844976987761\n",
      "49 Train Loss 13.265376 Test MSE 6.856889653967884 Test RE 1.25161753967906\n",
      "50 Train Loss 13.064072 Test MSE 6.795869299481281 Test RE 1.2460359402974144\n",
      "51 Train Loss 12.931309 Test MSE 6.791884346647591 Test RE 1.2456705622754007\n",
      "52 Train Loss 12.770416 Test MSE 6.781508604129149 Test RE 1.244718713251284\n",
      "53 Train Loss 12.67078 Test MSE 6.848870813283303 Test RE 1.2508854688573288\n",
      "54 Train Loss 12.331806 Test MSE 6.895548620837775 Test RE 1.2551408742319372\n",
      "55 Train Loss 12.13534 Test MSE 6.791628566302704 Test RE 1.2456471062630783\n",
      "56 Train Loss 11.606571 Test MSE 6.333769241988876 Test RE 1.2029267390251746\n",
      "57 Train Loss 10.962589 Test MSE 6.078274282709362 Test RE 1.178414851237912\n",
      "58 Train Loss 10.534859 Test MSE 5.772291019684818 Test RE 1.1483708755982653\n",
      "59 Train Loss 10.287601 Test MSE 5.763181639003502 Test RE 1.1474643830239417\n",
      "60 Train Loss 9.958106 Test MSE 5.719391499251827 Test RE 1.1430967054282835\n",
      "61 Train Loss 9.684164 Test MSE 5.59410904945982 Test RE 1.130507698988063\n",
      "62 Train Loss 9.472589 Test MSE 5.551641223329163 Test RE 1.126208384372607\n",
      "63 Train Loss 9.044922 Test MSE 5.292436071799085 Test RE 1.0996028851620432\n",
      "64 Train Loss 8.4710045 Test MSE 4.8736464506809645 Test RE 1.0552007002549286\n",
      "65 Train Loss 7.5716047 Test MSE 4.7405100040143955 Test RE 1.0406881130423131\n",
      "66 Train Loss 6.899762 Test MSE 4.836891882604635 Test RE 1.051214276059028\n",
      "67 Train Loss 6.503309 Test MSE 4.7231922971965306 Test RE 1.038785488510817\n",
      "68 Train Loss 6.125417 Test MSE 4.838068189763867 Test RE 1.0513420932334931\n",
      "69 Train Loss 5.9460444 Test MSE 4.778062083042493 Test RE 1.0448019018470525\n",
      "70 Train Loss 5.6802473 Test MSE 4.777223507034255 Test RE 1.04471021360206\n",
      "71 Train Loss 5.536023 Test MSE 4.7823144400139315 Test RE 1.045266722364482\n",
      "72 Train Loss 5.386452 Test MSE 4.831160590481235 Test RE 1.0505912931575794\n",
      "73 Train Loss 5.181357 Test MSE 4.76758626821446 Test RE 1.043655918714909\n",
      "74 Train Loss 4.9991117 Test MSE 4.882824635288734 Test RE 1.0561938243488398\n",
      "75 Train Loss 4.886855 Test MSE 4.884487038357757 Test RE 1.0563736045544945\n",
      "76 Train Loss 4.7967978 Test MSE 4.92199939345801 Test RE 1.06042226609132\n",
      "77 Train Loss 4.7092996 Test MSE 5.001283879288396 Test RE 1.0689288863797866\n",
      "78 Train Loss 4.569269 Test MSE 5.092608894101986 Test RE 1.0786442243754273\n",
      "79 Train Loss 4.5253963 Test MSE 5.158324971633405 Test RE 1.0855814402787385\n",
      "80 Train Loss 4.4597073 Test MSE 5.153995993723361 Test RE 1.085125822952762\n",
      "81 Train Loss 4.3885245 Test MSE 5.101016362544945 Test RE 1.0795342325864483\n",
      "82 Train Loss 4.344355 Test MSE 5.1546445243690995 Test RE 1.0851940918469347\n",
      "83 Train Loss 4.2937536 Test MSE 5.192588823370732 Test RE 1.0891809263192027\n",
      "84 Train Loss 4.252496 Test MSE 5.188098797837774 Test RE 1.0887099177351856\n",
      "85 Train Loss 4.2110286 Test MSE 5.2351683314636475 Test RE 1.0936374801131474\n",
      "86 Train Loss 4.177253 Test MSE 5.2319431151515365 Test RE 1.0933005510370108\n",
      "87 Train Loss 4.080666 Test MSE 5.179346558599133 Test RE 1.087791212049738\n",
      "88 Train Loss 4.0129633 Test MSE 5.157492016967682 Test RE 1.0854937881205968\n",
      "89 Train Loss 3.980302 Test MSE 5.178751359812909 Test RE 1.0877287070016832\n",
      "90 Train Loss 3.9558406 Test MSE 5.193363347932334 Test RE 1.0892621541953968\n",
      "91 Train Loss 3.8801079 Test MSE 5.23942595623219 Test RE 1.094082103036611\n",
      "92 Train Loss 3.8623452 Test MSE 5.268753814865899 Test RE 1.0971399101918031\n",
      "93 Train Loss 3.8177726 Test MSE 5.310299789132672 Test RE 1.1014570830561206\n",
      "94 Train Loss 3.77527 Test MSE 5.273098294630911 Test RE 1.0975921537514381\n",
      "95 Train Loss 3.7340012 Test MSE 5.248528459228088 Test RE 1.0950320700789056\n",
      "96 Train Loss 3.7040272 Test MSE 5.232137302593698 Test RE 1.0933208401784364\n",
      "97 Train Loss 3.6840084 Test MSE 5.209783185870569 Test RE 1.0909827533538867\n",
      "98 Train Loss 3.6551232 Test MSE 5.175645411653406 Test RE 1.0874024762710839\n",
      "99 Train Loss 3.6252673 Test MSE 5.170536384581869 Test RE 1.0868656407714423\n",
      "100 Train Loss 3.6058779 Test MSE 5.173479220131677 Test RE 1.087174894167168\n",
      "101 Train Loss 3.5452647 Test MSE 5.209994656535753 Test RE 1.0910048952069322\n",
      "102 Train Loss 3.5154853 Test MSE 5.206965428767581 Test RE 1.090687679636606\n",
      "103 Train Loss 3.5007539 Test MSE 5.19186966173654 Test RE 1.0891054991782678\n",
      "104 Train Loss 3.4566574 Test MSE 5.1292334018543455 Test RE 1.0825159178589838\n",
      "105 Train Loss 3.4146357 Test MSE 5.158070691182659 Test RE 1.085554682994015\n",
      "106 Train Loss 3.3801038 Test MSE 5.173948725912616 Test RE 1.0872242249265767\n",
      "107 Train Loss 3.3611403 Test MSE 5.157580465786851 Test RE 1.085503095961678\n",
      "108 Train Loss 3.2969918 Test MSE 5.161493979012298 Test RE 1.0859148515511252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 Train Loss 3.2822247 Test MSE 5.145972194515852 Test RE 1.084280825877411\n",
      "110 Train Loss 3.2647161 Test MSE 5.131307649310558 Test RE 1.0827347789196895\n",
      "111 Train Loss 3.2096233 Test MSE 5.047303655435039 Test RE 1.0738355489515157\n",
      "112 Train Loss 3.1702626 Test MSE 5.001797000049648 Test RE 1.068983719853491\n",
      "113 Train Loss 3.130282 Test MSE 5.009058618976308 Test RE 1.0697594147720697\n",
      "114 Train Loss 3.1068397 Test MSE 5.039953984307281 Test RE 1.073053427061742\n",
      "115 Train Loss 3.0837336 Test MSE 4.990846157727729 Test RE 1.0678128720003468\n",
      "116 Train Loss 3.0101202 Test MSE 4.944284313259001 Test RE 1.0628201470285346\n",
      "117 Train Loss 2.9594922 Test MSE 4.97776155746317 Test RE 1.0664122002731042\n",
      "118 Train Loss 2.9389567 Test MSE 4.9816436560655095 Test RE 1.0668279604908866\n",
      "119 Train Loss 2.8604307 Test MSE 4.917238286844826 Test RE 1.0599092626766902\n",
      "120 Train Loss 2.7956812 Test MSE 4.791368802322351 Test RE 1.0462557568906241\n",
      "121 Train Loss 2.767315 Test MSE 4.762848818649889 Test RE 1.0431372604396814\n",
      "122 Train Loss 2.730664 Test MSE 4.736085163742005 Test RE 1.0402023052145022\n",
      "123 Train Loss 2.7025511 Test MSE 4.7126277451166585 Test RE 1.037623091741835\n",
      "124 Train Loss 2.6740866 Test MSE 4.653607692451257 Test RE 1.0311051229673538\n",
      "125 Train Loss 2.6163323 Test MSE 4.642972225305347 Test RE 1.029926192747261\n",
      "126 Train Loss 2.5711443 Test MSE 4.698789195343791 Test RE 1.0360984905566621\n",
      "127 Train Loss 2.5177903 Test MSE 4.753819373162884 Test RE 1.042147997526457\n",
      "128 Train Loss 2.4920568 Test MSE 4.74803401111068 Test RE 1.0415136613753526\n",
      "129 Train Loss 2.4760313 Test MSE 4.784815676707995 Test RE 1.0455400333053302\n",
      "130 Train Loss 2.461515 Test MSE 4.769057781003449 Test RE 1.0438169681916525\n",
      "131 Train Loss 2.4429526 Test MSE 4.765291942811871 Test RE 1.0434047670526594\n",
      "132 Train Loss 2.4231799 Test MSE 4.742551467666776 Test RE 1.040912171031426\n",
      "133 Train Loss 2.4042416 Test MSE 4.721621901238681 Test RE 1.0386127832673444\n",
      "134 Train Loss 2.3964875 Test MSE 4.704595197563452 Test RE 1.036738414243412\n",
      "135 Train Loss 2.3795297 Test MSE 4.6753787949069405 Test RE 1.0335142325089568\n",
      "136 Train Loss 2.3501244 Test MSE 4.644100470234961 Test RE 1.0300513214756724\n",
      "137 Train Loss 2.3363953 Test MSE 4.6281664430683245 Test RE 1.0282827369792489\n",
      "138 Train Loss 2.3260677 Test MSE 4.642765545406885 Test RE 1.0299032691328645\n",
      "139 Train Loss 2.314281 Test MSE 4.623191352129085 Test RE 1.0277299072842239\n",
      "140 Train Loss 2.2915065 Test MSE 4.631953467764253 Test RE 1.028703350184693\n",
      "141 Train Loss 2.2764847 Test MSE 4.617390594801308 Test RE 1.027084954206174\n",
      "142 Train Loss 2.26672 Test MSE 4.641572835325118 Test RE 1.029770971378237\n",
      "143 Train Loss 2.236869 Test MSE 4.658247466820958 Test RE 1.0316190149371676\n",
      "144 Train Loss 2.2189612 Test MSE 4.684082172894884 Test RE 1.0344757463404706\n",
      "145 Train Loss 2.1987624 Test MSE 4.6907101615208875 Test RE 1.0352073805703004\n",
      "146 Train Loss 2.1845589 Test MSE 4.641209423303199 Test RE 1.029730657621511\n",
      "147 Train Loss 2.1616635 Test MSE 4.6296658449445225 Test RE 1.0284492915131098\n",
      "148 Train Loss 2.1408744 Test MSE 4.69570050077508 Test RE 1.035757900915105\n",
      "149 Train Loss 2.130253 Test MSE 4.692887199519848 Test RE 1.0354475813388346\n",
      "Training time: 237.64\n",
      "2\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 70.89523 Test MSE 4.9300706044673674 Test RE 1.0612913627012899\n",
      "1 Train Loss 55.23651 Test MSE 7.685596356685742 Test RE 1.3250944841663213\n",
      "2 Train Loss 42.45244 Test MSE 7.997033908173222 Test RE 1.35167577083875\n",
      "3 Train Loss 33.526875 Test MSE 7.4959902628597606 Test RE 1.308647160426703\n",
      "4 Train Loss 26.286139 Test MSE 6.986248776526651 Test RE 1.263368614276223\n",
      "5 Train Loss 19.728348 Test MSE 5.9359338476075685 Test RE 1.164535109144354\n",
      "6 Train Loss 16.359303 Test MSE 6.413977103242523 Test RE 1.2105194250465672\n",
      "7 Train Loss 14.505426 Test MSE 6.146501032925799 Test RE 1.1850100668158081\n",
      "8 Train Loss 13.298735 Test MSE 6.231754686622021 Test RE 1.1931999727363007\n",
      "9 Train Loss 12.659444 Test MSE 6.036122728706333 Test RE 1.174321713031757\n",
      "10 Train Loss 11.984648 Test MSE 6.142775215421923 Test RE 1.184650854272998\n",
      "11 Train Loss 11.327342 Test MSE 5.9138500203671365 Test RE 1.1623668440548163\n",
      "12 Train Loss 10.53174 Test MSE 6.020266949330948 Test RE 1.172778335717719\n",
      "13 Train Loss 9.917772 Test MSE 5.7073958448361095 Test RE 1.1418973304192634\n",
      "14 Train Loss 9.2241745 Test MSE 5.6302893308864705 Test RE 1.1341576247482246\n",
      "15 Train Loss 8.624376 Test MSE 5.648787521030721 Test RE 1.1360192217458034\n",
      "16 Train Loss 8.159689 Test MSE 5.47698685845022 Test RE 1.118610546721488\n",
      "17 Train Loss 7.688813 Test MSE 5.3131831879361435 Test RE 1.1017560783255642\n",
      "18 Train Loss 7.054161 Test MSE 5.055973840855331 Test RE 1.0747574628176504\n",
      "19 Train Loss 5.81796 Test MSE 4.293632820879629 Test RE 0.9904225305821476\n",
      "20 Train Loss 5.1183405 Test MSE 4.18080110554908 Test RE 0.9773223124172452\n",
      "21 Train Loss 4.7737093 Test MSE 4.1706040935169675 Test RE 0.9761297357796072\n",
      "22 Train Loss 4.3201165 Test MSE 3.9203846520402004 Test RE 0.9463949199641062\n",
      "23 Train Loss 4.062331 Test MSE 3.74702584852671 Test RE 0.9252336190614135\n",
      "24 Train Loss 3.7881417 Test MSE 3.5932145748287065 Test RE 0.9060447257035308\n",
      "25 Train Loss 3.592347 Test MSE 3.587887486256847 Test RE 0.9053728522832667\n",
      "26 Train Loss 3.3349297 Test MSE 3.4303476373650676 Test RE 0.8852728137866426\n",
      "27 Train Loss 3.0479298 Test MSE 3.0820878718513045 Test RE 0.8391325515624003\n",
      "28 Train Loss 2.8265965 Test MSE 2.9342678618278955 Test RE 0.8187624912458811\n",
      "29 Train Loss 2.5843432 Test MSE 2.7670514732436806 Test RE 0.7950907103678198\n",
      "30 Train Loss 2.3656893 Test MSE 2.267518022819553 Test RE 0.7197529177317619\n",
      "31 Train Loss 2.2123523 Test MSE 2.1641128167785824 Test RE 0.7031500449087539\n",
      "32 Train Loss 2.048771 Test MSE 2.1033431293390934 Test RE 0.6932072941867421\n",
      "33 Train Loss 1.9342942 Test MSE 1.937304042788969 Test RE 0.6652838067037612\n",
      "34 Train Loss 1.7957076 Test MSE 1.7657280253623995 Test RE 0.6351407321670034\n",
      "35 Train Loss 1.6835341 Test MSE 1.572948095505327 Test RE 0.5994669662891092\n",
      "36 Train Loss 1.3941419 Test MSE 1.0644472214983054 Test RE 0.49313988166759326\n",
      "37 Train Loss 1.2179928 Test MSE 1.0390874424174366 Test RE 0.48723009801455364\n",
      "38 Train Loss 1.1078377 Test MSE 1.0556760953909174 Test RE 0.4911039238039942\n",
      "39 Train Loss 0.9828732 Test MSE 0.9206256254397407 Test RE 0.458616409471092\n",
      "40 Train Loss 0.86031437 Test MSE 0.8007010276115857 Test RE 0.427703942197038\n",
      "41 Train Loss 0.73741275 Test MSE 0.66733619598704 Test RE 0.3904634623596019\n",
      "42 Train Loss 0.66880476 Test MSE 0.5460724541574558 Test RE 0.3532101662520708\n",
      "43 Train Loss 0.5822918 Test MSE 0.4741480431282945 Test RE 0.3291281597611821\n",
      "44 Train Loss 0.51560783 Test MSE 0.41417619201670486 Test RE 0.30761012465491944\n",
      "45 Train Loss 0.4451778 Test MSE 0.30390232611114054 Test RE 0.2634966343945069\n",
      "46 Train Loss 0.40336734 Test MSE 0.25359830315973686 Test RE 0.2407028496962324\n",
      "47 Train Loss 0.33680475 Test MSE 0.20801820340963698 Test RE 0.21800112302995542\n",
      "48 Train Loss 0.29031357 Test MSE 0.1659755182530301 Test RE 0.19472875041810575\n",
      "49 Train Loss 0.24723552 Test MSE 0.1729989335469238 Test RE 0.19880613087575363\n",
      "50 Train Loss 0.21432534 Test MSE 0.16468002877288276 Test RE 0.1939673030671947\n",
      "51 Train Loss 0.18142948 Test MSE 0.18718582123063177 Test RE 0.2067971431740349\n",
      "52 Train Loss 0.17025514 Test MSE 0.18818030208371053 Test RE 0.2073457514210955\n",
      "53 Train Loss 0.15644717 Test MSE 0.18524319785052737 Test RE 0.20572126921889403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 Train Loss 0.14709942 Test MSE 0.18332745090663857 Test RE 0.20465474113207732\n",
      "55 Train Loss 0.13638261 Test MSE 0.18686904578996735 Test RE 0.20662208719440928\n",
      "56 Train Loss 0.117716126 Test MSE 0.17056197959253244 Test RE 0.19740092083906297\n",
      "57 Train Loss 0.11202833 Test MSE 0.1697089316940754 Test RE 0.19690666204075427\n",
      "58 Train Loss 0.103677355 Test MSE 0.146000148679267 Test RE 0.18263529451727928\n",
      "59 Train Loss 0.09712174 Test MSE 0.12664477242794936 Test RE 0.17009897407639457\n",
      "60 Train Loss 0.09243827 Test MSE 0.10982297985325488 Test RE 0.15839981570268447\n",
      "61 Train Loss 0.089196645 Test MSE 0.11643499482150563 Test RE 0.16309844647746352\n",
      "62 Train Loss 0.082798004 Test MSE 0.09451343401172874 Test RE 0.14694500627086293\n",
      "63 Train Loss 0.07993917 Test MSE 0.08198301346704295 Test RE 0.13685794015136543\n",
      "64 Train Loss 0.07630214 Test MSE 0.07583204667943404 Test RE 0.1316238073591993\n",
      "65 Train Loss 0.07162693 Test MSE 0.07608949414135756 Test RE 0.13184704743163095\n",
      "66 Train Loss 0.070441574 Test MSE 0.07525328398250379 Test RE 0.13112055798781433\n",
      "67 Train Loss 0.06673445 Test MSE 0.06882452590466503 Test RE 0.12539484256106634\n",
      "68 Train Loss 0.059442688 Test MSE 0.0552548144610083 Test RE 0.1123551859271003\n",
      "69 Train Loss 0.056946576 Test MSE 0.055094165052182974 Test RE 0.11219173471383347\n",
      "70 Train Loss 0.05484486 Test MSE 0.049440999209727776 Test RE 0.10628003284206683\n",
      "71 Train Loss 0.051264998 Test MSE 0.04139694051522233 Test RE 0.09725057615053859\n",
      "72 Train Loss 0.04124914 Test MSE 0.033594319200887575 Test RE 0.08760743850636635\n",
      "73 Train Loss 0.036984045 Test MSE 0.030872499679098237 Test RE 0.08398349764741951\n",
      "74 Train Loss 0.03592912 Test MSE 0.028140072364874077 Test RE 0.08018085172340031\n",
      "75 Train Loss 0.03485997 Test MSE 0.02512557688434841 Test RE 0.07576455578446896\n",
      "76 Train Loss 0.033192113 Test MSE 0.022436018348365044 Test RE 0.07159471317372175\n",
      "77 Train Loss 0.03133911 Test MSE 0.01951611547612894 Test RE 0.06677359364169855\n",
      "78 Train Loss 0.0303921 Test MSE 0.01919455262130413 Test RE 0.066221201679217\n",
      "79 Train Loss 0.028583493 Test MSE 0.019738517160811406 Test RE 0.06715298498657137\n",
      "80 Train Loss 0.027342036 Test MSE 0.020906143938514914 Test RE 0.06911065807643904\n",
      "81 Train Loss 0.026699066 Test MSE 0.021271929909004925 Test RE 0.06971263635184896\n",
      "82 Train Loss 0.026033487 Test MSE 0.020108821598247405 Test RE 0.06777996977773126\n",
      "83 Train Loss 0.024092857 Test MSE 0.017838414688247956 Test RE 0.06383901656731794\n",
      "84 Train Loss 0.021433692 Test MSE 0.014661058473934589 Test RE 0.057874962579478585\n",
      "85 Train Loss 0.021111142 Test MSE 0.01472200302048265 Test RE 0.05799512803138384\n",
      "86 Train Loss 0.020506011 Test MSE 0.013738019829586579 Test RE 0.05602348611689336\n",
      "87 Train Loss 0.019794736 Test MSE 0.012253511332344095 Test RE 0.052910070311477826\n",
      "88 Train Loss 0.01922676 Test MSE 0.012646182791194234 Test RE 0.053751153387885074\n",
      "89 Train Loss 0.0183196 Test MSE 0.012381517703832749 Test RE 0.0531857149667957\n",
      "90 Train Loss 0.01758381 Test MSE 0.01390626438545758 Test RE 0.05636549187546567\n",
      "91 Train Loss 0.017403811 Test MSE 0.015266565234632344 Test RE 0.059057999142899276\n",
      "92 Train Loss 0.016932305 Test MSE 0.01613360729615189 Test RE 0.06071189673467671\n",
      "93 Train Loss 0.016360179 Test MSE 0.016209836832313945 Test RE 0.06085515626039199\n",
      "94 Train Loss 0.013635516 Test MSE 0.012919667295134756 Test RE 0.054329251937003206\n",
      "95 Train Loss 0.012925097 Test MSE 0.012253468269425779 Test RE 0.05290997733959506\n",
      "96 Train Loss 0.012582166 Test MSE 0.013100489413222534 Test RE 0.054708123737953133\n",
      "97 Train Loss 0.012511255 Test MSE 0.0130085133094766 Test RE 0.054515737677033285\n",
      "98 Train Loss 0.012067499 Test MSE 0.011963327409980419 Test RE 0.052279816501910964\n",
      "99 Train Loss 0.011784349 Test MSE 0.0115274754620064 Test RE 0.05131864294438786\n",
      "100 Train Loss 0.010960871 Test MSE 0.0108054097544861 Test RE 0.04968538741684078\n",
      "101 Train Loss 0.009903268 Test MSE 0.010169836790620177 Test RE 0.04820199928137444\n",
      "102 Train Loss 0.0097530605 Test MSE 0.010102663925655654 Test RE 0.048042545850601616\n",
      "103 Train Loss 0.009652311 Test MSE 0.009737157751742125 Test RE 0.04716546965357012\n",
      "104 Train Loss 0.009493038 Test MSE 0.008954931060178518 Test RE 0.04523131183252247\n",
      "105 Train Loss 0.009059779 Test MSE 0.009199058823097952 Test RE 0.04584371017583596\n",
      "106 Train Loss 0.008324247 Test MSE 0.009552977715019027 Test RE 0.04671726854334086\n",
      "107 Train Loss 0.007908422 Test MSE 0.009361679362015504 Test RE 0.04624714650493247\n",
      "108 Train Loss 0.0077952775 Test MSE 0.009831086843730512 Test RE 0.047392413547979614\n",
      "109 Train Loss 0.0076926835 Test MSE 0.00949019859018602 Test RE 0.046563510014330664\n",
      "110 Train Loss 0.0076588923 Test MSE 0.009530939265216429 Test RE 0.04666334971849066\n",
      "111 Train Loss 0.00758464 Test MSE 0.009921491268033468 Test RE 0.047609819780749636\n",
      "112 Train Loss 0.007309067 Test MSE 0.00978315637734935 Test RE 0.04727674394010546\n",
      "113 Train Loss 0.006604117 Test MSE 0.00957641027145447 Test RE 0.04677452998496731\n",
      "114 Train Loss 0.0062889224 Test MSE 0.009422081094171015 Test RE 0.04639610035956313\n",
      "115 Train Loss 0.006205994 Test MSE 0.009223334195190332 Test RE 0.04590415874571921\n",
      "116 Train Loss 0.0061887554 Test MSE 0.009338965510689278 Test RE 0.04619100867379708\n",
      "117 Train Loss 0.0061689424 Test MSE 0.009450076637326906 Test RE 0.046464976896178754\n",
      "118 Train Loss 0.006143594 Test MSE 0.009351426796912015 Test RE 0.04622181548516623\n",
      "119 Train Loss 0.005884007 Test MSE 0.008412319196271004 Test RE 0.04383953427927584\n",
      "120 Train Loss 0.005572022 Test MSE 0.007322773134108836 Test RE 0.04090212296764123\n",
      "121 Train Loss 0.0053498023 Test MSE 0.005854647266745438 Test RE 0.036572818237311726\n",
      "122 Train Loss 0.0053170514 Test MSE 0.005567622442522179 Test RE 0.035665059152809674\n",
      "123 Train Loss 0.0053024264 Test MSE 0.005596124288209019 Test RE 0.03575623113838527\n",
      "124 Train Loss 0.005202855 Test MSE 0.0053602702590863464 Test RE 0.03499462981284829\n",
      "125 Train Loss 0.0048629697 Test MSE 0.005164215305416009 Test RE 0.034348694117310424\n",
      "126 Train Loss 0.004496394 Test MSE 0.0051671011689677455 Test RE 0.03435829013471837\n",
      "127 Train Loss 0.0044170315 Test MSE 0.005212040852578911 Test RE 0.034507378366315816\n",
      "128 Train Loss 0.004336983 Test MSE 0.00551028817968991 Test RE 0.035480948117083674\n",
      "129 Train Loss 0.0043046973 Test MSE 0.005421232100883483 Test RE 0.03519306251046603\n",
      "130 Train Loss 0.004288217 Test MSE 0.0050318462706809095 Test RE 0.03390562407189609\n",
      "131 Train Loss 0.00421756 Test MSE 0.004520381778816809 Test RE 0.03213628114009424\n",
      "132 Train Loss 0.004162904 Test MSE 0.004305340152846752 Test RE 0.03136258093298973\n",
      "133 Train Loss 0.0040461766 Test MSE 0.004277528689734498 Test RE 0.031261119444020505\n",
      "134 Train Loss 0.0038621943 Test MSE 0.004142786582017105 Test RE 0.030764817330102792\n",
      "135 Train Loss 0.0036912798 Test MSE 0.0037308341347035852 Test RE 0.02919517152265748\n",
      "136 Train Loss 0.003581032 Test MSE 0.0034654120418894613 Test RE 0.028137499505185033\n",
      "137 Train Loss 0.003528716 Test MSE 0.0034769728341773574 Test RE 0.02818439449738513\n",
      "138 Train Loss 0.0034811073 Test MSE 0.0035520179984241517 Test RE 0.02848692939270991\n",
      "139 Train Loss 0.0034164065 Test MSE 0.003805405130594651 Test RE 0.029485500899461906\n",
      "140 Train Loss 0.0033626065 Test MSE 0.0038677584171138814 Test RE 0.029726086022793256\n",
      "141 Train Loss 0.0033003758 Test MSE 0.003730757554337251 Test RE 0.029194871886125424\n",
      "142 Train Loss 0.0032657755 Test MSE 0.003894850566463661 Test RE 0.029830014204599412\n",
      "143 Train Loss 0.0032465316 Test MSE 0.0041056015075533305 Test RE 0.030626435752305104\n",
      "144 Train Loss 0.0032281547 Test MSE 0.004210938844692209 Test RE 0.031016838403269974\n",
      "145 Train Loss 0.0031976989 Test MSE 0.004182477743899989 Test RE 0.03091184162084912\n",
      "146 Train Loss 0.0031527022 Test MSE 0.0042325623910485334 Test RE 0.031096373544120134\n",
      "147 Train Loss 0.0030217038 Test MSE 0.0036618971558251413 Test RE 0.02892418507647571\n",
      "148 Train Loss 0.002887837 Test MSE 0.0037390460933413128 Test RE 0.029227284684059846\n",
      "149 Train Loss 0.0028316479 Test MSE 0.0034621573628005513 Test RE 0.02812428317727773\n",
      "Training time: 233.64\n",
      "3\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 69.03205 Test MSE 5.243185002341144 Test RE 1.0944745093519372\n",
      "1 Train Loss 56.1354 Test MSE 7.144473049428419 Test RE 1.2775948763246257\n",
      "2 Train Loss 42.37059 Test MSE 8.765925709764625 Test RE 1.4151645898394327\n",
      "3 Train Loss 34.89017 Test MSE 8.141130226258714 Test RE 1.3637991366698323\n",
      "4 Train Loss 30.890408 Test MSE 8.726921806872252 Test RE 1.4120126991769428\n",
      "5 Train Loss 28.84851 Test MSE 8.672350331995677 Test RE 1.4075909536267555\n",
      "6 Train Loss 27.334831 Test MSE 8.540406312518519 Test RE 1.3968421346694015\n",
      "7 Train Loss 26.295662 Test MSE 8.443531633277436 Test RE 1.3888972808837827\n",
      "8 Train Loss 24.892487 Test MSE 8.468074082753883 Test RE 1.3909143401544761\n",
      "9 Train Loss 23.455765 Test MSE 8.449253468456636 Test RE 1.3893678005535803\n",
      "10 Train Loss 22.308563 Test MSE 8.690032236125877 Test RE 1.409025179291111\n",
      "11 Train Loss 21.3321 Test MSE 8.611357139242472 Test RE 1.4026323812984927\n",
      "12 Train Loss 20.425919 Test MSE 8.924056182861987 Test RE 1.427871772608208\n",
      "13 Train Loss 19.248896 Test MSE 8.907044097179758 Test RE 1.426510134799375\n",
      "14 Train Loss 18.010807 Test MSE 8.580699504881713 Test RE 1.4001333715017754\n",
      "15 Train Loss 16.357166 Test MSE 8.700577749679757 Test RE 1.409879859030513\n",
      "16 Train Loss 15.290342 Test MSE 8.439366726517303 Test RE 1.3885546907543482\n",
      "17 Train Loss 13.993032 Test MSE 7.794691414068746 Test RE 1.334466031840984\n",
      "18 Train Loss 12.704297 Test MSE 7.781304323174517 Test RE 1.3333195916446159\n",
      "19 Train Loss 11.12341 Test MSE 7.849798428376357 Test RE 1.3391749366892374\n",
      "20 Train Loss 10.1194515 Test MSE 7.7755413845224775 Test RE 1.3328257629812754\n",
      "21 Train Loss 8.778474 Test MSE 7.750341877276131 Test RE 1.3306642537438098\n",
      "22 Train Loss 7.5513597 Test MSE 7.432520736860671 Test RE 1.303095140036307\n",
      "23 Train Loss 5.9559965 Test MSE 7.006284824119376 Test RE 1.2651789413613723\n",
      "24 Train Loss 4.8967266 Test MSE 6.928197501417639 Test RE 1.2581087709668473\n",
      "25 Train Loss 4.2808642 Test MSE 6.9011051776529735 Test RE 1.2556464799155225\n",
      "26 Train Loss 3.810545 Test MSE 7.10176382140312 Test RE 1.2737704597527018\n",
      "27 Train Loss 3.3763614 Test MSE 7.094381686697872 Test RE 1.2731082587686973\n",
      "28 Train Loss 3.1639519 Test MSE 7.109995547071 Test RE 1.2745084660141957\n",
      "29 Train Loss 2.99201 Test MSE 7.122685523468672 Test RE 1.2756453353721606\n",
      "30 Train Loss 2.7587693 Test MSE 7.052467712671419 Test RE 1.269341892828592\n",
      "31 Train Loss 2.5638955 Test MSE 7.06303823316872 Test RE 1.2702928068275308\n",
      "32 Train Loss 2.4095 Test MSE 7.077753317100437 Test RE 1.2716153778546693\n",
      "33 Train Loss 2.2866151 Test MSE 7.069454281676936 Test RE 1.2708696414643963\n",
      "34 Train Loss 2.2167463 Test MSE 7.042015236209218 Test RE 1.2684008969608935\n",
      "35 Train Loss 2.1272123 Test MSE 6.980534197960757 Test RE 1.2628518064436847\n",
      "36 Train Loss 2.063366 Test MSE 6.980685139922835 Test RE 1.262865459861435\n",
      "37 Train Loss 1.9933435 Test MSE 6.991660395013865 Test RE 1.2638578285672921\n",
      "38 Train Loss 1.949424 Test MSE 7.006317567871241 Test RE 1.2651818977539508\n",
      "39 Train Loss 1.8867996 Test MSE 7.0069482581930425 Test RE 1.2652388406497188\n",
      "40 Train Loss 1.8207324 Test MSE 7.0255111944826405 Test RE 1.2669136791419562\n",
      "41 Train Loss 1.7719269 Test MSE 6.997018477180737 Test RE 1.2643420166427175\n",
      "42 Train Loss 1.7369838 Test MSE 6.995076858572933 Test RE 1.264166581897215\n",
      "43 Train Loss 1.6704282 Test MSE 6.973808117453954 Test RE 1.2622432505818804\n",
      "44 Train Loss 1.6339004 Test MSE 6.924675409138611 Test RE 1.2577889375252815\n",
      "45 Train Loss 1.6018369 Test MSE 6.937536072485262 Test RE 1.2589563927119625\n",
      "46 Train Loss 1.5738289 Test MSE 6.921545869683805 Test RE 1.2575046826890015\n",
      "47 Train Loss 1.5499808 Test MSE 6.937293759869021 Test RE 1.258934406254675\n",
      "48 Train Loss 1.5209688 Test MSE 6.926314430646241 Test RE 1.2579377835740237\n",
      "49 Train Loss 1.5007205 Test MSE 6.9154339500269195 Test RE 1.2569493540694816\n",
      "50 Train Loss 1.4517226 Test MSE 6.864388282477386 Test RE 1.252301731119477\n",
      "51 Train Loss 1.4435612 Test MSE 6.830103165711768 Test RE 1.2491704210034917\n",
      "52 Train Loss 1.4225262 Test MSE 6.854655645703009 Test RE 1.2514136315039215\n",
      "53 Train Loss 1.408256 Test MSE 6.8404700299993655 Test RE 1.2501180692091538\n",
      "54 Train Loss 1.3882726 Test MSE 6.822320202580732 Test RE 1.2484584977483804\n",
      "55 Train Loss 1.3577422 Test MSE 6.791812780990862 Test RE 1.245663999482062\n",
      "56 Train Loss 1.3321375 Test MSE 6.704047723084921 Test RE 1.2375894795361582\n",
      "57 Train Loss 1.3182458 Test MSE 6.688674135532094 Test RE 1.2361696574265713\n",
      "58 Train Loss 1.2910765 Test MSE 6.592448185543166 Test RE 1.2272454279057428\n",
      "59 Train Loss 1.2790954 Test MSE 6.582314567722461 Test RE 1.2263018316385341\n",
      "60 Train Loss 1.2714553 Test MSE 6.546138325811562 Test RE 1.2229273260734599\n",
      "61 Train Loss 1.25163 Test MSE 6.542924014441057 Test RE 1.222627045841805\n",
      "62 Train Loss 1.2411845 Test MSE 6.52320694296907 Test RE 1.2207834653944265\n",
      "63 Train Loss 1.2302619 Test MSE 6.442350107257488 Test RE 1.2131939101775062\n",
      "64 Train Loss 1.2153009 Test MSE 6.3812709867863875 Test RE 1.207429143557371\n",
      "65 Train Loss 1.1999657 Test MSE 6.318143738605987 Test RE 1.2014420036216922\n",
      "66 Train Loss 1.186823 Test MSE 6.26450215446274 Test RE 1.196330959186464\n",
      "67 Train Loss 1.1694376 Test MSE 6.22716870409147 Test RE 1.1927608507238099\n",
      "68 Train Loss 1.1626438 Test MSE 6.181754051501837 Test RE 1.1884034977169111\n",
      "69 Train Loss 1.1529465 Test MSE 6.152164231594514 Test RE 1.1855558572006948\n",
      "70 Train Loss 1.1424087 Test MSE 6.122865974237803 Test RE 1.1827295206396833\n",
      "71 Train Loss 1.1357496 Test MSE 6.069858157158072 Test RE 1.1775987377882455\n",
      "72 Train Loss 1.1243795 Test MSE 6.025467899686357 Test RE 1.1732848120217245\n",
      "73 Train Loss 1.1110477 Test MSE 5.971395736590398 Test RE 1.1680084565393902\n",
      "74 Train Loss 1.100065 Test MSE 5.936340468940373 Test RE 1.1645749947563997\n",
      "75 Train Loss 1.0889286 Test MSE 5.896164141555668 Test RE 1.1606274634633487\n",
      "76 Train Loss 1.083704 Test MSE 5.891586552037205 Test RE 1.1601768393312495\n",
      "77 Train Loss 1.0779405 Test MSE 5.880144235682665 Test RE 1.1590496758651676\n",
      "78 Train Loss 1.0725336 Test MSE 5.857659825688158 Test RE 1.1568315748032756\n",
      "79 Train Loss 1.0678931 Test MSE 5.849512581483357 Test RE 1.1560267936159514\n",
      "80 Train Loss 1.0609459 Test MSE 5.869494390817769 Test RE 1.1579995916414776\n",
      "81 Train Loss 1.0557256 Test MSE 5.869132167976045 Test RE 1.157963859400633\n",
      "82 Train Loss 1.0512624 Test MSE 5.880310767651351 Test RE 1.1590660885116932\n",
      "83 Train Loss 1.0472046 Test MSE 5.8814423502566475 Test RE 1.159177606081371\n",
      "84 Train Loss 1.0405023 Test MSE 5.8586235666669655 Test RE 1.1569267356844175\n",
      "85 Train Loss 1.0347154 Test MSE 5.848550286203251 Test RE 1.1559317015149517\n",
      "86 Train Loss 1.0318685 Test MSE 5.868263329438833 Test RE 1.15787814648485\n",
      "87 Train Loss 1.0286952 Test MSE 5.861173987324738 Test RE 1.15717852936579\n",
      "88 Train Loss 1.0245048 Test MSE 5.854474911169599 Test RE 1.1565170370233562\n",
      "89 Train Loss 1.0209886 Test MSE 5.856686970312399 Test RE 1.156735506016222\n",
      "90 Train Loss 1.017118 Test MSE 5.854661911198847 Test RE 1.1565355072530588\n",
      "91 Train Loss 1.0116607 Test MSE 5.846418605810237 Test RE 1.1557210252455439\n",
      "92 Train Loss 1.0073442 Test MSE 5.849866166794348 Test RE 1.156061732246379\n",
      "93 Train Loss 1.0043622 Test MSE 5.853200432166663 Test RE 1.1563911472613464\n",
      "94 Train Loss 1.0013701 Test MSE 5.8594201988741474 Test RE 1.1570053901465305\n",
      "95 Train Loss 0.9966275 Test MSE 5.863504537183862 Test RE 1.1574085681116695\n",
      "96 Train Loss 0.99310213 Test MSE 5.863419225483615 Test RE 1.1574001481597993\n",
      "97 Train Loss 0.9899174 Test MSE 5.858835146873735 Test RE 1.1569476263070329\n",
      "98 Train Loss 0.9849538 Test MSE 5.840187129187874 Test RE 1.1551049413568897\n",
      "99 Train Loss 0.98148906 Test MSE 5.849498738472323 Test RE 1.156025425732653\n",
      "100 Train Loss 0.9792388 Test MSE 5.846355091241547 Test RE 1.1557147474431178\n",
      "101 Train Loss 0.97614837 Test MSE 5.846819494120082 Test RE 1.1557606484009832\n",
      "102 Train Loss 0.9704768 Test MSE 5.8683408666437655 Test RE 1.1578857959659257\n",
      "103 Train Loss 0.9684087 Test MSE 5.862554804683914 Test RE 1.1573148295427842\n",
      "104 Train Loss 0.96419126 Test MSE 5.874497164596968 Test RE 1.1584929881501922\n",
      "105 Train Loss 0.9606088 Test MSE 5.876919669329382 Test RE 1.1587318311863075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 0.9568051 Test MSE 5.892689134867611 Test RE 1.1602853950835015\n",
      "107 Train Loss 0.953229 Test MSE 5.90092943013406 Test RE 1.161096379154043\n",
      "108 Train Loss 0.95088285 Test MSE 5.900820147848439 Test RE 1.1610856276398007\n",
      "109 Train Loss 0.9473591 Test MSE 5.896130671200326 Test RE 1.1606241692310462\n",
      "110 Train Loss 0.9457437 Test MSE 5.899180054581069 Test RE 1.1609242584561563\n",
      "111 Train Loss 0.94354796 Test MSE 5.894455285825613 Test RE 1.160459261852069\n",
      "112 Train Loss 0.9403673 Test MSE 5.896708826165071 Test RE 1.1606810713092355\n",
      "113 Train Loss 0.937523 Test MSE 5.894372889450377 Test RE 1.1604511510117708\n",
      "114 Train Loss 0.93385625 Test MSE 5.904741150232488 Test RE 1.1614713251670192\n",
      "115 Train Loss 0.9313804 Test MSE 5.902165767153059 Test RE 1.161218006710412\n",
      "116 Train Loss 0.9284408 Test MSE 5.910805532102492 Test RE 1.1620676085507131\n",
      "117 Train Loss 0.92613065 Test MSE 5.931066320828684 Test RE 1.1640575458418716\n",
      "118 Train Loss 0.9227724 Test MSE 5.928017669216455 Test RE 1.1637583364018518\n",
      "119 Train Loss 0.9202544 Test MSE 5.927942344453557 Test RE 1.163750942690824\n",
      "120 Train Loss 0.9178094 Test MSE 5.935224025996711 Test RE 1.1644654792494262\n",
      "121 Train Loss 0.9152892 Test MSE 5.931408927217835 Test RE 1.1640911660858377\n",
      "122 Train Loss 0.9125409 Test MSE 5.931638190842496 Test RE 1.1641136633697522\n",
      "123 Train Loss 0.90968657 Test MSE 5.936161955292634 Test RE 1.1645574844658095\n",
      "124 Train Loss 0.90793586 Test MSE 5.94009102905373 Test RE 1.1649428239664432\n",
      "125 Train Loss 0.90569013 Test MSE 5.934005260457661 Test RE 1.1643459148272959\n",
      "126 Train Loss 0.9034661 Test MSE 5.943703678796591 Test RE 1.1652970180924638\n",
      "127 Train Loss 0.90217286 Test MSE 5.953625386773444 Test RE 1.1662692162724344\n",
      "128 Train Loss 0.8995911 Test MSE 5.962489966822439 Test RE 1.1671371446921244\n",
      "129 Train Loss 0.89821255 Test MSE 5.9646053140328155 Test RE 1.1673441623457554\n",
      "130 Train Loss 0.8965521 Test MSE 5.9677257205865555 Test RE 1.1676494727476086\n",
      "131 Train Loss 0.89330393 Test MSE 5.976899239850846 Test RE 1.1685465767879928\n",
      "132 Train Loss 0.89025235 Test MSE 5.992263152849887 Test RE 1.170047516026831\n",
      "133 Train Loss 0.8871454 Test MSE 5.996701077152208 Test RE 1.1704807097227115\n",
      "134 Train Loss 0.8850069 Test MSE 5.988409814877033 Test RE 1.1696712547165296\n",
      "135 Train Loss 0.88310623 Test MSE 5.998138576659926 Test RE 1.1706209922380804\n",
      "136 Train Loss 0.88097346 Test MSE 5.989284244108415 Test RE 1.1697566494568181\n",
      "137 Train Loss 0.8785187 Test MSE 6.006822077548525 Test RE 1.1714680393643915\n",
      "138 Train Loss 0.8765838 Test MSE 6.012747673458964 Test RE 1.1720457104717414\n",
      "139 Train Loss 0.87471104 Test MSE 6.021403816880888 Test RE 1.1728890642539702\n",
      "140 Train Loss 0.87291336 Test MSE 6.029667473142278 Test RE 1.1736936132624674\n",
      "141 Train Loss 0.87128246 Test MSE 6.034452868550317 Test RE 1.1741592669742826\n",
      "142 Train Loss 0.8681238 Test MSE 6.038183382591558 Test RE 1.1745221450156942\n",
      "143 Train Loss 0.86538255 Test MSE 6.053944247481921 Test RE 1.1760540147633733\n",
      "144 Train Loss 0.86264485 Test MSE 6.050471032317533 Test RE 1.1757166087271465\n",
      "145 Train Loss 0.86008346 Test MSE 6.051663823595608 Test RE 1.175832493540006\n",
      "146 Train Loss 0.85732406 Test MSE 6.048010669792404 Test RE 1.1754775378185107\n",
      "147 Train Loss 0.8548543 Test MSE 6.048400283787061 Test RE 1.1755153994517447\n",
      "148 Train Loss 0.8526716 Test MSE 6.048079262300185 Test RE 1.1754842035411714\n",
      "149 Train Loss 0.8488115 Test MSE 6.041761485802587 Test RE 1.1748700923028834\n",
      "Training time: 236.72\n",
      "4\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 61.90807 Test MSE 7.788794052023809 Test RE 1.3339611165066703\n",
      "1 Train Loss 48.75449 Test MSE 6.649479813778576 Test RE 1.2325424798175655\n",
      "2 Train Loss 37.394215 Test MSE 7.439692762652247 Test RE 1.3037237005746034\n",
      "3 Train Loss 28.763494 Test MSE 7.57990585272309 Test RE 1.3159517501511586\n",
      "4 Train Loss 23.21842 Test MSE 7.198529180554441 Test RE 1.2824190036295642\n",
      "5 Train Loss 19.590166 Test MSE 6.7464097149008095 Test RE 1.2414934043562202\n",
      "6 Train Loss 17.327457 Test MSE 6.904431441186371 Test RE 1.2559490479708952\n",
      "7 Train Loss 15.589733 Test MSE 6.512561149753192 Test RE 1.219786906861816\n",
      "8 Train Loss 13.432364 Test MSE 5.854681662092129 Test RE 1.1565374580565777\n",
      "9 Train Loss 10.6537 Test MSE 5.175652812934281 Test RE 1.0874032537749152\n",
      "10 Train Loss 9.284618 Test MSE 5.189614091462036 Test RE 1.0888688964690492\n",
      "11 Train Loss 7.950039 Test MSE 4.879369711031875 Test RE 1.0558200944225338\n",
      "12 Train Loss 7.241892 Test MSE 4.903462892000765 Test RE 1.0584235802826776\n",
      "13 Train Loss 6.7125254 Test MSE 4.758905690104723 Test RE 1.0427053680844272\n",
      "14 Train Loss 6.2419844 Test MSE 4.640039687072157 Test RE 1.0296008865799249\n",
      "15 Train Loss 5.8617234 Test MSE 4.6039871714556435 Test RE 1.0255931528241022\n",
      "16 Train Loss 5.649783 Test MSE 4.450020290899642 Test RE 1.0082983486169725\n",
      "17 Train Loss 5.378851 Test MSE 4.332532524762792 Test RE 0.9948989582623528\n",
      "18 Train Loss 5.1709805 Test MSE 4.1340777561325925 Test RE 0.9718458415525587\n",
      "19 Train Loss 4.944437 Test MSE 4.060693357417171 Test RE 0.9631815562975893\n",
      "20 Train Loss 4.8073225 Test MSE 3.9618317229644724 Test RE 0.9513845027356653\n",
      "21 Train Loss 4.6741495 Test MSE 3.862638851487503 Test RE 0.939399041010966\n",
      "22 Train Loss 4.452366 Test MSE 3.7473824927575357 Test RE 0.9252776501669101\n",
      "23 Train Loss 4.1237087 Test MSE 3.646220419643642 Test RE 0.9127030876125634\n",
      "24 Train Loss 3.8612702 Test MSE 3.6471352601059457 Test RE 0.9128175795042899\n",
      "25 Train Loss 3.432991 Test MSE 3.6745583344746935 Test RE 0.9162429234812514\n",
      "26 Train Loss 3.152585 Test MSE 3.756809603854054 Test RE 0.9264407575215208\n",
      "27 Train Loss 2.9844596 Test MSE 3.711501818165156 Test RE 0.9208372922020371\n",
      "28 Train Loss 2.7346184 Test MSE 3.6635480430770024 Test RE 0.9148691978667907\n",
      "29 Train Loss 2.553103 Test MSE 3.656619668981863 Test RE 0.9140037041394783\n",
      "30 Train Loss 2.328679 Test MSE 3.5636525611776855 Test RE 0.9023099328039079\n",
      "31 Train Loss 2.204753 Test MSE 3.4773475120403563 Test RE 0.8913168310209256\n",
      "32 Train Loss 2.0301917 Test MSE 3.315517557918399 Test RE 0.87032954423867\n",
      "33 Train Loss 1.8434181 Test MSE 3.210008912979817 Test RE 0.8563694765778711\n",
      "34 Train Loss 1.7341048 Test MSE 3.0302435196711843 Test RE 0.8320450205193096\n",
      "35 Train Loss 1.6415792 Test MSE 2.7724336267833665 Test RE 0.795863594689254\n",
      "36 Train Loss 1.5465906 Test MSE 2.7196216638630863 Test RE 0.7882469632378508\n",
      "37 Train Loss 1.4633799 Test MSE 2.5441811392782325 Test RE 0.7623985728289466\n",
      "38 Train Loss 1.3687748 Test MSE 2.417626252447493 Test RE 0.7431947647922205\n",
      "39 Train Loss 1.2977258 Test MSE 2.3022901448483615 Test RE 0.7252505845460977\n",
      "40 Train Loss 1.237921 Test MSE 2.2656574357887314 Test RE 0.7194575644529179\n",
      "41 Train Loss 1.1647154 Test MSE 2.140364604099365 Test RE 0.6992813415772345\n",
      "42 Train Loss 1.1181242 Test MSE 2.140670117274019 Test RE 0.699331247102468\n",
      "43 Train Loss 1.0544482 Test MSE 2.0679824202865675 Test RE 0.6873556099134552\n",
      "44 Train Loss 1.0099504 Test MSE 2.0114721324807503 Test RE 0.6778991203018626\n",
      "45 Train Loss 0.94006366 Test MSE 1.9310903880115593 Test RE 0.6642160435048245\n",
      "46 Train Loss 0.90422916 Test MSE 1.8839746664539234 Test RE 0.6560630665389645\n",
      "47 Train Loss 0.8469046 Test MSE 1.7428851017501095 Test RE 0.63101900435201\n",
      "48 Train Loss 0.7863103 Test MSE 1.7034773917634127 Test RE 0.6238443516796979\n",
      "49 Train Loss 0.7192164 Test MSE 1.5917996906572738 Test RE 0.6030485370906228\n",
      "50 Train Loss 0.67376685 Test MSE 1.53845005699687 Test RE 0.5928567397352126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 Train Loss 0.6253587 Test MSE 1.5084950438475273 Test RE 0.5870566393592577\n",
      "52 Train Loss 0.58760715 Test MSE 1.419482025489086 Test RE 0.5694728308873527\n",
      "53 Train Loss 0.5208919 Test MSE 1.3623416499571321 Test RE 0.5578932121221153\n",
      "54 Train Loss 0.5008535 Test MSE 1.3494168766986907 Test RE 0.5552404902306237\n",
      "55 Train Loss 0.47205612 Test MSE 1.3223002620416582 Test RE 0.5496333826823095\n",
      "56 Train Loss 0.4260373 Test MSE 1.2323441621158115 Test RE 0.530608333232777\n",
      "57 Train Loss 0.39851552 Test MSE 1.1846504547887138 Test RE 0.5202393196269935\n",
      "58 Train Loss 0.3664209 Test MSE 1.1193201265710913 Test RE 0.5056909911022828\n",
      "59 Train Loss 0.31439298 Test MSE 1.0111805747191465 Test RE 0.48064277597401733\n",
      "60 Train Loss 0.2967595 Test MSE 0.9805672482250122 Test RE 0.4733111679811792\n",
      "61 Train Loss 0.25741488 Test MSE 0.9752399368439449 Test RE 0.4720236937997612\n",
      "62 Train Loss 0.21825348 Test MSE 0.8798705528692868 Test RE 0.4483502867553658\n",
      "63 Train Loss 0.20584105 Test MSE 0.860458839423266 Test RE 0.4433769489275075\n",
      "64 Train Loss 0.17753252 Test MSE 0.8491198346018821 Test RE 0.4404458812599972\n",
      "65 Train Loss 0.16393907 Test MSE 0.8306564457456617 Test RE 0.4356310029470433\n",
      "66 Train Loss 0.1558667 Test MSE 0.8210238130938998 Test RE 0.43309775955597674\n",
      "67 Train Loss 0.14662313 Test MSE 0.789794070160682 Test RE 0.4247809135821174\n",
      "68 Train Loss 0.13516754 Test MSE 0.7977027469755894 Test RE 0.4269024075771098\n",
      "69 Train Loss 0.12594001 Test MSE 0.798399789969228 Test RE 0.42708888327667255\n",
      "70 Train Loss 0.114142306 Test MSE 0.79310260070607 Test RE 0.4256697097333656\n",
      "71 Train Loss 0.10215129 Test MSE 0.7977920107024691 Test RE 0.4269262923099057\n",
      "72 Train Loss 0.09274866 Test MSE 0.7947400522801296 Test RE 0.4261089052046463\n",
      "73 Train Loss 0.0861222 Test MSE 0.7911445242842452 Test RE 0.425143920947147\n",
      "74 Train Loss 0.079284325 Test MSE 0.7654566047667636 Test RE 0.4181849005494507\n",
      "75 Train Loss 0.07388455 Test MSE 0.7482676060532558 Test RE 0.4134628866257416\n",
      "76 Train Loss 0.07058409 Test MSE 0.7558690157656254 Test RE 0.4155576981174543\n",
      "77 Train Loss 0.06757354 Test MSE 0.7506002480687449 Test RE 0.4141068476982881\n",
      "78 Train Loss 0.06108714 Test MSE 0.7449073149662833 Test RE 0.41253346046202294\n",
      "79 Train Loss 0.05789601 Test MSE 0.7425292651794956 Test RE 0.4118744460458027\n",
      "80 Train Loss 0.056272715 Test MSE 0.7380386479895866 Test RE 0.410627104379554\n",
      "81 Train Loss 0.05397177 Test MSE 0.7349954375731589 Test RE 0.4097796450254206\n",
      "82 Train Loss 0.051160417 Test MSE 0.731979687745755 Test RE 0.40893810024901683\n",
      "83 Train Loss 0.04916629 Test MSE 0.7246978595160212 Test RE 0.4068989316439471\n",
      "84 Train Loss 0.047830757 Test MSE 0.717031995835091 Test RE 0.40474111895119375\n",
      "85 Train Loss 0.046074066 Test MSE 0.7157002467668129 Test RE 0.40436507986059755\n",
      "86 Train Loss 0.04466879 Test MSE 0.7263899135342671 Test RE 0.407373676774102\n",
      "87 Train Loss 0.041687645 Test MSE 0.7368285773132801 Test RE 0.4102903390504133\n",
      "88 Train Loss 0.039672304 Test MSE 0.7386156220587832 Test RE 0.4107875803287442\n",
      "89 Train Loss 0.03725864 Test MSE 0.7323482245576778 Test RE 0.4090410332820937\n",
      "90 Train Loss 0.03665029 Test MSE 0.7325562141519822 Test RE 0.4090991137389563\n",
      "91 Train Loss 0.034932133 Test MSE 0.7387619466509817 Test RE 0.4108282681687439\n",
      "92 Train Loss 0.03374682 Test MSE 0.737787974190468 Test RE 0.41055736399512976\n",
      "93 Train Loss 0.031431846 Test MSE 0.742378678097849 Test RE 0.4118326792638913\n",
      "94 Train Loss 0.029229056 Test MSE 0.7423550113207673 Test RE 0.4118261146694433\n",
      "95 Train Loss 0.02872376 Test MSE 0.7428765352889642 Test RE 0.4119707486234408\n",
      "96 Train Loss 0.027724177 Test MSE 0.7441179659449795 Test RE 0.41231482977632794\n",
      "97 Train Loss 0.025955796 Test MSE 0.7525160087698649 Test RE 0.41463497439896274\n",
      "98 Train Loss 0.02489638 Test MSE 0.7585416996987528 Test RE 0.4162917368852023\n",
      "99 Train Loss 0.02457089 Test MSE 0.7564089319023302 Test RE 0.4157060877527207\n",
      "100 Train Loss 0.02403117 Test MSE 0.7498944962133485 Test RE 0.4139121199402401\n",
      "101 Train Loss 0.023064911 Test MSE 0.7402726733870904 Test RE 0.41124811401846234\n",
      "102 Train Loss 0.022247918 Test MSE 0.7377173066642742 Test RE 0.4105377013216638\n",
      "103 Train Loss 0.0214696 Test MSE 0.7364312536888051 Test RE 0.41017970271531645\n",
      "104 Train Loss 0.020941177 Test MSE 0.7319243812126152 Test RE 0.40892265079310436\n",
      "105 Train Loss 0.020390742 Test MSE 0.7273525763761869 Test RE 0.40764352747651794\n",
      "106 Train Loss 0.019411748 Test MSE 0.7247529127503461 Test RE 0.40691438682745257\n",
      "107 Train Loss 0.018614948 Test MSE 0.715362414573154 Test RE 0.404269632313167\n",
      "108 Train Loss 0.018072702 Test MSE 0.7119589215666968 Test RE 0.4033067851509558\n",
      "109 Train Loss 0.017721009 Test MSE 0.7061772784823129 Test RE 0.4016658694473718\n",
      "110 Train Loss 0.017232161 Test MSE 0.7059249291475214 Test RE 0.4015940962716989\n",
      "111 Train Loss 0.016569253 Test MSE 0.6996798230200941 Test RE 0.39981375873449065\n",
      "112 Train Loss 0.016048228 Test MSE 0.6971504502410182 Test RE 0.3990904324258567\n",
      "113 Train Loss 0.015727717 Test MSE 0.6897292145571241 Test RE 0.39696057049584027\n",
      "114 Train Loss 0.015402572 Test MSE 0.6913859455138989 Test RE 0.39743703459378055\n",
      "115 Train Loss 0.014790247 Test MSE 0.6786167322995664 Test RE 0.3937497962675488\n",
      "116 Train Loss 0.01442547 Test MSE 0.674122449656451 Test RE 0.39244378474557057\n",
      "117 Train Loss 0.014207311 Test MSE 0.6727021620265538 Test RE 0.3920301529594438\n",
      "118 Train Loss 0.01363628 Test MSE 0.671781414576227 Test RE 0.3917617694286593\n",
      "119 Train Loss 0.013266192 Test MSE 0.6721710065738176 Test RE 0.3918753518565328\n",
      "120 Train Loss 0.013054029 Test MSE 0.6698224127175402 Test RE 0.3911901382850787\n",
      "121 Train Loss 0.01274799 Test MSE 0.6658133392990082 Test RE 0.3900176904114276\n",
      "122 Train Loss 0.012484357 Test MSE 0.6670387321405012 Test RE 0.3903764284849946\n",
      "123 Train Loss 0.012299148 Test MSE 0.6648893506339664 Test RE 0.389746971113667\n",
      "124 Train Loss 0.011957652 Test MSE 0.6608166020346016 Test RE 0.388551449107566\n",
      "125 Train Loss 0.011622837 Test MSE 0.6609575452538338 Test RE 0.3885928832756311\n",
      "126 Train Loss 0.011401487 Test MSE 0.6596138292589697 Test RE 0.38819768079134476\n",
      "127 Train Loss 0.0111329695 Test MSE 0.6581754861995232 Test RE 0.38777420107044996\n",
      "128 Train Loss 0.010968415 Test MSE 0.6548165727194166 Test RE 0.38678345767636124\n",
      "129 Train Loss 0.01074697 Test MSE 0.6472196707539847 Test RE 0.384533264020507\n",
      "130 Train Loss 0.010566116 Test MSE 0.6469828646952274 Test RE 0.3844629106755456\n",
      "131 Train Loss 0.010362843 Test MSE 0.643919534593858 Test RE 0.3835516545459795\n",
      "132 Train Loss 0.010188346 Test MSE 0.6419531967665997 Test RE 0.3829655807148331\n",
      "133 Train Loss 0.01010505 Test MSE 0.6438710340015655 Test RE 0.38353720954802345\n",
      "134 Train Loss 0.009954191 Test MSE 0.6415616904888392 Test RE 0.3828487838076602\n",
      "135 Train Loss 0.009783481 Test MSE 0.6385559187282129 Test RE 0.38195089113847774\n",
      "136 Train Loss 0.009661961 Test MSE 0.6364783332691665 Test RE 0.38132903320716965\n",
      "137 Train Loss 0.009476748 Test MSE 0.6397214885389796 Test RE 0.382299323786384\n",
      "138 Train Loss 0.009297105 Test MSE 0.6387830771043222 Test RE 0.38201882225207756\n",
      "139 Train Loss 0.009200687 Test MSE 0.6382303632695637 Test RE 0.3818535135660369\n",
      "140 Train Loss 0.008992029 Test MSE 0.6344833426299196 Test RE 0.3807309414309843\n",
      "141 Train Loss 0.008724298 Test MSE 0.627652714954053 Test RE 0.37867598707996053\n",
      "142 Train Loss 0.008579253 Test MSE 0.6219749466624388 Test RE 0.3769593379680066\n",
      "143 Train Loss 0.008421628 Test MSE 0.6177195408554902 Test RE 0.37566759130301436\n",
      "144 Train Loss 0.008251481 Test MSE 0.6141860097571669 Test RE 0.3745915877115048\n",
      "145 Train Loss 0.008150559 Test MSE 0.6083274143708789 Test RE 0.37280073035156763\n",
      "146 Train Loss 0.007995682 Test MSE 0.6017281007455134 Test RE 0.3707730905965032\n",
      "147 Train Loss 0.007756163 Test MSE 0.5953980311873819 Test RE 0.3688177018695978\n",
      "148 Train Loss 0.0076360796 Test MSE 0.5925734948399521 Test RE 0.3679418361649446\n",
      "149 Train Loss 0.007540692 Test MSE 0.5920088564440267 Test RE 0.3677664962251696\n",
      "Training time: 235.24\n",
      "5\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 73.09586 Test MSE 4.604897429586075 Test RE 1.0256945332506986\n",
      "1 Train Loss 66.09712 Test MSE 5.111166800972506 Test RE 1.0806077735469106\n",
      "2 Train Loss 46.643166 Test MSE 5.424265042037759 Test RE 1.1132136201519383\n",
      "3 Train Loss 32.34905 Test MSE 5.010528206829543 Test RE 1.0699163295009515\n",
      "4 Train Loss 22.672009 Test MSE 5.3731079282343694 Test RE 1.1079517362236782\n",
      "5 Train Loss 20.114687 Test MSE 5.386180054186828 Test RE 1.109298674207715\n",
      "6 Train Loss 18.639786 Test MSE 5.376833352965058 Test RE 1.1083357668107316\n",
      "7 Train Loss 17.450443 Test MSE 5.304939031452252 Test RE 1.100900981169949\n",
      "8 Train Loss 16.649141 Test MSE 5.179020483025279 Test RE 1.0877569695325977\n",
      "9 Train Loss 15.937964 Test MSE 5.114724876094158 Test RE 1.080983833933497\n",
      "10 Train Loss 15.318272 Test MSE 5.138427811253053 Test RE 1.083485715622832\n",
      "11 Train Loss 14.427958 Test MSE 5.030550279742096 Test RE 1.072051891262586\n",
      "12 Train Loss 13.096637 Test MSE 4.162480351116518 Test RE 0.9751785915744233\n",
      "13 Train Loss 10.804146 Test MSE 4.0009279723720965 Test RE 0.9560672170500721\n",
      "14 Train Loss 9.768398 Test MSE 3.703370748005291 Test RE 0.9198280649007428\n",
      "15 Train Loss 9.400354 Test MSE 3.850785999438645 Test RE 0.9379566187119368\n",
      "16 Train Loss 8.688257 Test MSE 3.570940953458663 Test RE 0.903232164918062\n",
      "17 Train Loss 8.141869 Test MSE 3.546155193436593 Test RE 0.9000920572102601\n",
      "18 Train Loss 7.7885323 Test MSE 3.606642020275922 Test RE 0.9077360415763438\n",
      "19 Train Loss 7.3711014 Test MSE 3.5406370882281255 Test RE 0.8993914764277328\n",
      "20 Train Loss 6.776863 Test MSE 3.55192992793509 Test RE 0.900824636300393\n",
      "21 Train Loss 6.351129 Test MSE 3.4785154835115333 Test RE 0.8914665062009267\n",
      "22 Train Loss 5.799144 Test MSE 3.4839588999831164 Test RE 0.8921637470989826\n",
      "23 Train Loss 5.450915 Test MSE 3.570580037564342 Test RE 0.9031865188143817\n",
      "24 Train Loss 5.0790963 Test MSE 3.3790107265077856 Test RE 0.8786235619088978\n",
      "25 Train Loss 4.7534294 Test MSE 3.3333549944400604 Test RE 0.8726675839837152\n",
      "26 Train Loss 4.0670233 Test MSE 3.1532771549338565 Test RE 0.848768263695546\n",
      "27 Train Loss 3.5277057 Test MSE 2.9111775525317003 Test RE 0.8155346300185593\n",
      "28 Train Loss 3.068782 Test MSE 2.7491716992295503 Test RE 0.7925177402405051\n",
      "29 Train Loss 2.699179 Test MSE 2.51937013039898 Test RE 0.7586719865192915\n",
      "30 Train Loss 2.360106 Test MSE 2.6270276776752466 Test RE 0.7747121809043472\n",
      "31 Train Loss 2.1812963 Test MSE 2.6999645015356553 Test RE 0.7853931106400673\n",
      "32 Train Loss 1.832558 Test MSE 2.6600851470833144 Test RE 0.7795712771387487\n",
      "33 Train Loss 1.687275 Test MSE 2.6439513864000723 Test RE 0.7772035812393836\n",
      "34 Train Loss 1.5543015 Test MSE 2.612518376851739 Test RE 0.7725698175412117\n",
      "35 Train Loss 1.341232 Test MSE 2.686583766083073 Test RE 0.7834445312534314\n",
      "36 Train Loss 1.2536668 Test MSE 2.648453297477396 Test RE 0.7778649801749532\n",
      "37 Train Loss 1.18098 Test MSE 2.636963306018037 Test RE 0.7761758099692745\n",
      "38 Train Loss 1.0862751 Test MSE 2.7096030023884974 Test RE 0.786793734281547\n",
      "39 Train Loss 1.05537 Test MSE 2.7246334810529613 Test RE 0.7889729339406557\n",
      "40 Train Loss 0.99653715 Test MSE 2.7497036563112625 Test RE 0.7925944115216212\n",
      "41 Train Loss 0.9161157 Test MSE 2.7950935609147995 Test RE 0.7991093922652663\n",
      "42 Train Loss 0.8853062 Test MSE 2.7872814672775466 Test RE 0.7979918830727953\n",
      "43 Train Loss 0.841141 Test MSE 2.8447419526792035 Test RE 0.8061753207209021\n",
      "44 Train Loss 0.8052559 Test MSE 2.9051542600110194 Test RE 0.814690513325939\n",
      "45 Train Loss 0.7865669 Test MSE 2.943051207011053 Test RE 0.8199870045280556\n",
      "46 Train Loss 0.7554119 Test MSE 2.9794924917564267 Test RE 0.8250479849881593\n",
      "47 Train Loss 0.74719363 Test MSE 2.952046091826081 Test RE 0.8212391168988685\n",
      "48 Train Loss 0.7191855 Test MSE 2.932912890143497 Test RE 0.8185734273725365\n",
      "49 Train Loss 0.7119474 Test MSE 2.9321368714256857 Test RE 0.818465127134919\n",
      "50 Train Loss 0.69722927 Test MSE 2.9355050120577797 Test RE 0.8189350769650413\n",
      "51 Train Loss 0.6910362 Test MSE 2.943662291116166 Test RE 0.8200721296213139\n",
      "52 Train Loss 0.6754059 Test MSE 2.969639888815892 Test RE 0.8236827186704351\n",
      "53 Train Loss 0.67314696 Test MSE 2.957277089475352 Test RE 0.821966408812208\n",
      "54 Train Loss 0.6583844 Test MSE 2.959769828493233 Test RE 0.8223127605549314\n",
      "55 Train Loss 0.655112 Test MSE 2.9552839696605058 Test RE 0.8216893712506222\n",
      "56 Train Loss 0.62985414 Test MSE 2.9094626664621646 Test RE 0.815294391322646\n",
      "57 Train Loss 0.62774676 Test MSE 2.922968045776995 Test RE 0.8171844502552152\n",
      "58 Train Loss 0.6110939 Test MSE 2.960355581651495 Test RE 0.8223941264204389\n",
      "59 Train Loss 0.59764713 Test MSE 2.9685830378700078 Test RE 0.823536137374872\n",
      "60 Train Loss 0.59293294 Test MSE 2.97105162000235 Test RE 0.8238784798503359\n",
      "61 Train Loss 0.5818492 Test MSE 2.986438275930658 Test RE 0.8260090999007852\n",
      "62 Train Loss 0.5756713 Test MSE 2.9871051267947086 Test RE 0.8261013157923734\n",
      "63 Train Loss 0.5722862 Test MSE 2.99436723334339 Test RE 0.8271048951246854\n",
      "64 Train Loss 0.5618068 Test MSE 2.9728640577196512 Test RE 0.8241297378159179\n",
      "65 Train Loss 0.5505778 Test MSE 2.9632707441303165 Test RE 0.8227989464701115\n",
      "66 Train Loss 0.5482874 Test MSE 2.9615645737276535 Test RE 0.8225620397778555\n",
      "67 Train Loss 0.5389222 Test MSE 2.940165795831405 Test RE 0.8195849422288739\n",
      "68 Train Loss 0.52717775 Test MSE 2.9423851771557583 Test RE 0.8198942153291109\n",
      "69 Train Loss 0.5189904 Test MSE 2.953232307454964 Test RE 0.8214040988813549\n",
      "70 Train Loss 0.515911 Test MSE 2.956568424000001 Test RE 0.8218679171763044\n",
      "71 Train Loss 0.5100169 Test MSE 2.955749047802222 Test RE 0.821754024044747\n",
      "72 Train Loss 0.5003354 Test MSE 2.9894826173051268 Test RE 0.8264300048250279\n",
      "73 Train Loss 0.49816883 Test MSE 2.9990715341717094 Test RE 0.8277543517410626\n",
      "74 Train Loss 0.49428272 Test MSE 3.016022603921404 Test RE 0.8300903331935475\n",
      "75 Train Loss 0.48421627 Test MSE 3.007677909492229 Test RE 0.8289411959007948\n",
      "76 Train Loss 0.48251873 Test MSE 3.0072781319111073 Test RE 0.8288861030469437\n",
      "77 Train Loss 0.47851935 Test MSE 3.03157330155318 Test RE 0.8322275664147651\n",
      "78 Train Loss 0.46918988 Test MSE 3.0490095832458195 Test RE 0.8346174391746612\n",
      "79 Train Loss 0.46660355 Test MSE 3.062865135121547 Test RE 0.8365116571274898\n",
      "80 Train Loss 0.46462303 Test MSE 3.0701184898207945 Test RE 0.8375015681302334\n",
      "81 Train Loss 0.45686758 Test MSE 3.090366715813029 Test RE 0.8402587992325447\n",
      "82 Train Loss 0.45180982 Test MSE 3.094781500355368 Test RE 0.8408587664870792\n",
      "83 Train Loss 0.45060843 Test MSE 3.0949608639793427 Test RE 0.8408831328745611\n",
      "84 Train Loss 0.44853476 Test MSE 3.0991821019127035 Test RE 0.8414563805566482\n",
      "85 Train Loss 0.4438795 Test MSE 3.0980327219873223 Test RE 0.8413003324885346\n",
      "86 Train Loss 0.44130296 Test MSE 3.090083307295015 Test RE 0.8402202695072906\n",
      "87 Train Loss 0.43894094 Test MSE 3.1206628025279413 Test RE 0.8443674487185133\n",
      "88 Train Loss 0.43652782 Test MSE 3.1284952496475 Test RE 0.8454264094716722\n",
      "89 Train Loss 0.4298517 Test MSE 3.130227063437235 Test RE 0.8456603747542104\n",
      "90 Train Loss 0.42676756 Test MSE 3.1322214688511663 Test RE 0.8459297355754885\n",
      "91 Train Loss 0.42373016 Test MSE 3.1380367027390474 Test RE 0.8467146414588419\n",
      "92 Train Loss 0.415678 Test MSE 3.141944070728669 Test RE 0.8472416264430611\n",
      "93 Train Loss 0.41242683 Test MSE 3.155643555057389 Test RE 0.8490866861713633\n",
      "94 Train Loss 0.41038686 Test MSE 3.1634364299786206 Test RE 0.850134451261662\n",
      "95 Train Loss 0.40865457 Test MSE 3.1631657171445395 Test RE 0.8500980751188828\n",
      "96 Train Loss 0.40648586 Test MSE 3.1606192367260713 Test RE 0.8497558240085556\n",
      "97 Train Loss 0.4033572 Test MSE 3.1669147925581127 Test RE 0.850601706335412\n",
      "98 Train Loss 0.3999434 Test MSE 3.159397320959265 Test RE 0.849591547590362\n",
      "99 Train Loss 0.39745614 Test MSE 3.1753100336715057 Test RE 0.8517283991239732\n",
      "100 Train Loss 0.3958723 Test MSE 3.1741723889039095 Test RE 0.8515758075420992\n",
      "101 Train Loss 0.3945667 Test MSE 3.1676530761968102 Test RE 0.8507008483661629\n",
      "102 Train Loss 0.39330962 Test MSE 3.168899315930115 Test RE 0.85086817618235\n",
      "103 Train Loss 0.3910347 Test MSE 3.1791743704805584 Test RE 0.8522465161872105\n",
      "104 Train Loss 0.38841772 Test MSE 3.1673524502344756 Test RE 0.8506604795468592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 Train Loss 0.38754743 Test MSE 3.1685180243929563 Test RE 0.8508169851279614\n",
      "106 Train Loss 0.38537002 Test MSE 3.174188081549352 Test RE 0.8515779125728064\n",
      "107 Train Loss 0.38350847 Test MSE 3.1837828443073852 Test RE 0.8528639930866362\n",
      "108 Train Loss 0.38030386 Test MSE 3.1900751803178795 Test RE 0.8537063649038998\n",
      "109 Train Loss 0.3794976 Test MSE 3.188165708927406 Test RE 0.8534508267432904\n",
      "110 Train Loss 0.37853438 Test MSE 3.1961957108685213 Test RE 0.8545249399743935\n",
      "111 Train Loss 0.37789083 Test MSE 3.1997129201955063 Test RE 0.8549949857668598\n",
      "112 Train Loss 0.3774876 Test MSE 3.1981073369290813 Test RE 0.8547804449737586\n",
      "113 Train Loss 0.37686682 Test MSE 3.2062733474106735 Test RE 0.8558710425149937\n",
      "114 Train Loss 0.37589043 Test MSE 3.207878412099051 Test RE 0.8560852408006315\n",
      "115 Train Loss 0.3749875 Test MSE 3.2110163458565153 Test RE 0.856503848024944\n",
      "116 Train Loss 0.3740006 Test MSE 3.2070053885609187 Test RE 0.8559687411508978\n",
      "117 Train Loss 0.37312245 Test MSE 3.2107948236962316 Test RE 0.856474303196338\n",
      "118 Train Loss 0.37236202 Test MSE 3.205029193498185 Test RE 0.855704971424079\n",
      "119 Train Loss 0.37193674 Test MSE 3.2109711867826025 Test RE 0.8564978251567292\n",
      "120 Train Loss 0.3711591 Test MSE 3.212546635855066 Test RE 0.8567079178593484\n",
      "121 Train Loss 0.37009647 Test MSE 3.2105628150177825 Test RE 0.8564433586682871\n",
      "122 Train Loss 0.3688157 Test MSE 3.2120469613561538 Test RE 0.8566412897610008\n",
      "123 Train Loss 0.36720714 Test MSE 3.223787580051544 Test RE 0.8582054519793448\n",
      "124 Train Loss 0.36638173 Test MSE 3.2304501395490473 Test RE 0.8590918152311178\n",
      "125 Train Loss 0.36564896 Test MSE 3.2332451400586977 Test RE 0.8594633799988919\n",
      "126 Train Loss 0.36408937 Test MSE 3.2389051476583166 Test RE 0.8602153245586585\n",
      "127 Train Loss 0.362244 Test MSE 3.240922947799891 Test RE 0.8604832348974742\n",
      "128 Train Loss 0.36056516 Test MSE 3.244048835506479 Test RE 0.8608981052517234\n",
      "129 Train Loss 0.3599602 Test MSE 3.2427202730128335 Test RE 0.8607218017929034\n",
      "130 Train Loss 0.35938105 Test MSE 3.2514706415864087 Test RE 0.8618823334225764\n",
      "131 Train Loss 0.3588249 Test MSE 3.2576322991110853 Test RE 0.8626985963961749\n",
      "132 Train Loss 0.35753524 Test MSE 3.265252381996525 Test RE 0.8637069967316838\n",
      "133 Train Loss 0.35633934 Test MSE 3.2602844317800757 Test RE 0.8630496988887957\n",
      "134 Train Loss 0.35575512 Test MSE 3.2616482093005406 Test RE 0.8632301869325715\n",
      "135 Train Loss 0.3550104 Test MSE 3.267301534165739 Test RE 0.8639779695800491\n",
      "136 Train Loss 0.35418916 Test MSE 3.270603672806285 Test RE 0.8644144543249571\n",
      "137 Train Loss 0.3530604 Test MSE 3.26975563174603 Test RE 0.8643023792237052\n",
      "138 Train Loss 0.35190555 Test MSE 3.2722146256655833 Test RE 0.8646273140358444\n",
      "139 Train Loss 0.35086328 Test MSE 3.2761695313302255 Test RE 0.8651496646823186\n",
      "140 Train Loss 0.3504588 Test MSE 3.274995942916216 Test RE 0.8649946939829699\n",
      "141 Train Loss 0.34982732 Test MSE 3.282437786621986 Test RE 0.8659769093441968\n",
      "142 Train Loss 0.34926757 Test MSE 3.2904717947272846 Test RE 0.8670360327850092\n",
      "143 Train Loss 0.34867355 Test MSE 3.295071851181924 Test RE 0.8676418762593379\n",
      "144 Train Loss 0.34816915 Test MSE 3.2969853373871763 Test RE 0.867893764515333\n",
      "145 Train Loss 0.34700203 Test MSE 3.312455292695037 Test RE 0.8699275262226727\n",
      "146 Train Loss 0.3457467 Test MSE 3.321337262147913 Test RE 0.8710930509497175\n",
      "147 Train Loss 0.3448946 Test MSE 3.3191803817500687 Test RE 0.8708101605793837\n",
      "148 Train Loss 0.34422606 Test MSE 3.3235208040967894 Test RE 0.8713793446248629\n",
      "149 Train Loss 0.3435106 Test MSE 3.324412668306275 Test RE 0.8714962537652171\n",
      "Training time: 237.23\n",
      "6\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 71.98628 Test MSE 5.063413544488157 Test RE 1.0755479077442842\n",
      "1 Train Loss 54.78881 Test MSE 8.178011490440861 Test RE 1.3668848138004654\n",
      "2 Train Loss 47.548912 Test MSE 8.777169153180745 Test RE 1.4160718656195104\n",
      "3 Train Loss 42.90318 Test MSE 9.37892481914217 Test RE 1.4638095883498927\n",
      "4 Train Loss 39.317528 Test MSE 9.412730008768527 Test RE 1.4664452769687477\n",
      "5 Train Loss 36.719154 Test MSE 9.423872941201811 Test RE 1.4673130203041271\n",
      "6 Train Loss 33.027443 Test MSE 8.83903091471965 Test RE 1.4210533628989666\n",
      "7 Train Loss 29.810675 Test MSE 8.94286470803547 Test RE 1.4293756866284426\n",
      "8 Train Loss 25.757391 Test MSE 8.847209283548388 Test RE 1.4217106301703195\n",
      "9 Train Loss 23.397318 Test MSE 9.052997770162987 Test RE 1.4381502694453745\n",
      "10 Train Loss 22.044083 Test MSE 8.910131367203915 Test RE 1.426757334677188\n",
      "11 Train Loss 19.993448 Test MSE 8.546106380611779 Test RE 1.3973081995679892\n",
      "12 Train Loss 18.837536 Test MSE 8.337307359340064 Test RE 1.38013308301977\n",
      "13 Train Loss 17.167133 Test MSE 8.378921822064271 Test RE 1.383573162941433\n",
      "14 Train Loss 15.087505 Test MSE 7.948565440970381 Test RE 1.3475734235272578\n",
      "15 Train Loss 14.201019 Test MSE 7.617032735155506 Test RE 1.31917062295097\n",
      "16 Train Loss 13.119284 Test MSE 7.521352000448847 Test RE 1.3108591123456574\n",
      "17 Train Loss 11.791376 Test MSE 7.073187386395818 Test RE 1.2712051456711646\n",
      "18 Train Loss 10.911696 Test MSE 6.967143525725935 Test RE 1.2616399685170658\n",
      "19 Train Loss 9.255287 Test MSE 6.068613464731945 Test RE 1.177477991689925\n",
      "20 Train Loss 7.8580027 Test MSE 5.861123396374349 Test RE 1.157173535239355\n",
      "21 Train Loss 6.4345407 Test MSE 5.836312965527678 Test RE 1.1547217508971555\n",
      "22 Train Loss 5.5823994 Test MSE 6.0804368691402955 Test RE 1.1786244664357002\n",
      "23 Train Loss 5.1548166 Test MSE 5.897974328055266 Test RE 1.1608056124162902\n",
      "24 Train Loss 4.5372043 Test MSE 5.8435276597687125 Test RE 1.1554352485605417\n",
      "25 Train Loss 4.2215786 Test MSE 5.780279320103461 Test RE 1.1491652187703267\n",
      "26 Train Loss 3.9210734 Test MSE 5.913830656675325 Test RE 1.1623649410870636\n",
      "27 Train Loss 3.6768591 Test MSE 5.899979157314557 Test RE 1.1610028851742233\n",
      "28 Train Loss 3.5167665 Test MSE 5.851953298295822 Test RE 1.156267945312843\n",
      "29 Train Loss 3.371148 Test MSE 5.869862009502274 Test RE 1.1580358550393737\n",
      "30 Train Loss 3.195778 Test MSE 5.808137330314571 Test RE 1.1519310865725945\n",
      "31 Train Loss 3.0721588 Test MSE 5.714960068686108 Test RE 1.1426537793522387\n",
      "32 Train Loss 2.9497278 Test MSE 5.672722836353721 Test RE 1.1384234753414526\n",
      "33 Train Loss 2.8189592 Test MSE 5.579368165450891 Test RE 1.1290172314832971\n",
      "34 Train Loss 2.6885116 Test MSE 5.514397292049549 Test RE 1.1224243671420926\n",
      "35 Train Loss 2.627227 Test MSE 5.509980255483047 Test RE 1.1219747456869897\n",
      "36 Train Loss 2.553351 Test MSE 5.5154222376714275 Test RE 1.1225286732365312\n",
      "37 Train Loss 2.474556 Test MSE 5.4133398100939205 Test RE 1.1120919707545402\n",
      "38 Train Loss 2.435615 Test MSE 5.4101621598156875 Test RE 1.1117655218126024\n",
      "39 Train Loss 2.3838205 Test MSE 5.357616599639277 Test RE 1.1063534030307325\n",
      "40 Train Loss 2.325435 Test MSE 5.360401950121341 Test RE 1.1066409545485871\n",
      "41 Train Loss 2.2800844 Test MSE 5.304784608667959 Test RE 1.100884957853665\n",
      "42 Train Loss 2.2243714 Test MSE 5.328811051680292 Test RE 1.103375206708072\n",
      "43 Train Loss 2.1705453 Test MSE 5.2954449678896225 Test RE 1.099915418053772\n",
      "44 Train Loss 2.143207 Test MSE 5.2566305616508915 Test RE 1.0958769393377974\n",
      "45 Train Loss 2.1192079 Test MSE 5.241120455803594 Test RE 1.0942590090372593\n",
      "46 Train Loss 2.0772908 Test MSE 5.290189527505874 Test RE 1.0993694795281517\n",
      "47 Train Loss 2.0517206 Test MSE 5.246509869018691 Test RE 1.0948214745180431\n",
      "48 Train Loss 2.0131104 Test MSE 5.2740656748091475 Test RE 1.0976928289276489\n",
      "49 Train Loss 1.9966323 Test MSE 5.313531903274438 Test RE 1.101792233011582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Train Loss 1.9630282 Test MSE 5.318838371093376 Test RE 1.1023422594487435\n",
      "51 Train Loss 1.9219741 Test MSE 5.34193830290152 Test RE 1.1047334247081522\n",
      "52 Train Loss 1.8946664 Test MSE 5.363820452314629 Test RE 1.1069937687231213\n",
      "53 Train Loss 1.8633032 Test MSE 5.333890849695283 Test RE 1.1039009889149174\n",
      "54 Train Loss 1.8197615 Test MSE 5.381390000300708 Test RE 1.1088053020706732\n",
      "55 Train Loss 1.7978084 Test MSE 5.39169502179778 Test RE 1.109866440323244\n",
      "56 Train Loss 1.7740515 Test MSE 5.409362105216247 Test RE 1.1116833148491883\n",
      "57 Train Loss 1.7475142 Test MSE 5.400130042166759 Test RE 1.1107342645757183\n",
      "58 Train Loss 1.7287592 Test MSE 5.370191261961265 Test RE 1.1076509825292562\n",
      "59 Train Loss 1.7063454 Test MSE 5.383105602251235 Test RE 1.1089820330779903\n",
      "60 Train Loss 1.6764336 Test MSE 5.427542999096582 Test RE 1.1135499344071682\n",
      "61 Train Loss 1.6646028 Test MSE 5.407344923396382 Test RE 1.1114760190142332\n",
      "62 Train Loss 1.6370223 Test MSE 5.3937803963108575 Test RE 1.1100810540416441\n",
      "63 Train Loss 1.6262048 Test MSE 5.400180656591697 Test RE 1.1107394699174313\n",
      "64 Train Loss 1.6100041 Test MSE 5.43706669509813 Test RE 1.1145264778400181\n",
      "65 Train Loss 1.5986218 Test MSE 5.4528102360883794 Test RE 1.1161389198674283\n",
      "66 Train Loss 1.581314 Test MSE 5.500958147159562 Test RE 1.1210558018499888\n",
      "67 Train Loss 1.5734601 Test MSE 5.49442115692283 Test RE 1.1203895079916264\n",
      "68 Train Loss 1.558182 Test MSE 5.501754276706835 Test RE 1.1211369216598788\n",
      "69 Train Loss 1.5475266 Test MSE 5.497157857814975 Test RE 1.120668499096279\n",
      "70 Train Loss 1.539461 Test MSE 5.508715577606913 Test RE 1.1218459777057685\n",
      "71 Train Loss 1.5172954 Test MSE 5.50458510161321 Test RE 1.1214253145995872\n",
      "72 Train Loss 1.5029358 Test MSE 5.553806752401782 Test RE 1.1264280130479054\n",
      "73 Train Loss 1.495881 Test MSE 5.548983439699961 Test RE 1.1259387725213985\n",
      "74 Train Loss 1.4792728 Test MSE 5.5492880496996895 Test RE 1.1259696761550286\n",
      "75 Train Loss 1.4671702 Test MSE 5.501169603160532 Test RE 1.1210773482508471\n",
      "76 Train Loss 1.4539912 Test MSE 5.505433975144664 Test RE 1.121511779932745\n",
      "77 Train Loss 1.4364971 Test MSE 5.558608541962833 Test RE 1.1269148594490295\n",
      "78 Train Loss 1.4244945 Test MSE 5.56548394189744 Test RE 1.1276115802124824\n",
      "79 Train Loss 1.4170498 Test MSE 5.528385821426777 Test RE 1.1238471084387402\n",
      "80 Train Loss 1.400281 Test MSE 5.527883157538417 Test RE 1.1237960148449277\n",
      "81 Train Loss 1.385965 Test MSE 5.541965259794435 Test RE 1.1252265212506376\n",
      "82 Train Loss 1.3740582 Test MSE 5.510340225073802 Test RE 1.1220113946562384\n",
      "83 Train Loss 1.3627859 Test MSE 5.507594210663165 Test RE 1.121731789107304\n",
      "84 Train Loss 1.3491609 Test MSE 5.539826327933805 Test RE 1.1250093586544916\n",
      "85 Train Loss 1.3380396 Test MSE 5.54336583884581 Test RE 1.125368697271395\n",
      "86 Train Loss 1.327829 Test MSE 5.547735992653599 Test RE 1.1258122062810947\n",
      "87 Train Loss 1.3166218 Test MSE 5.5399872985196925 Test RE 1.1250257032192292\n",
      "88 Train Loss 1.3096565 Test MSE 5.560762016685351 Test RE 1.1271331287919717\n",
      "89 Train Loss 1.3016131 Test MSE 5.545819102677935 Test RE 1.1256176904836273\n",
      "90 Train Loss 1.2787651 Test MSE 5.577046688259959 Test RE 1.128782324916208\n",
      "91 Train Loss 1.2709887 Test MSE 5.570895424741937 Test RE 1.1281596518811237\n",
      "92 Train Loss 1.2616594 Test MSE 5.582210945102083 Test RE 1.129304821259703\n",
      "93 Train Loss 1.2548987 Test MSE 5.584954742368867 Test RE 1.129582328044022\n",
      "94 Train Loss 1.2463169 Test MSE 5.582448063642115 Test RE 1.1293288060454372\n",
      "95 Train Loss 1.233541 Test MSE 5.598088869734954 Test RE 1.1309097663669925\n",
      "96 Train Loss 1.2242568 Test MSE 5.6000311719844165 Test RE 1.1311059385016256\n",
      "97 Train Loss 1.2146862 Test MSE 5.610721129384991 Test RE 1.1321850136927174\n",
      "98 Train Loss 1.2116401 Test MSE 5.614587626032798 Test RE 1.1325750558584842\n",
      "99 Train Loss 1.2045214 Test MSE 5.624649909055384 Test RE 1.1335894838155427\n",
      "100 Train Loss 1.1935818 Test MSE 5.6365661781553085 Test RE 1.1347896483233801\n",
      "101 Train Loss 1.1882455 Test MSE 5.62712943646912 Test RE 1.1338393177203727\n",
      "102 Train Loss 1.1790427 Test MSE 5.643862868585105 Test RE 1.1355239190210484\n",
      "103 Train Loss 1.1723049 Test MSE 5.640043320575559 Test RE 1.1351396146638746\n",
      "104 Train Loss 1.1667135 Test MSE 5.649423381175585 Test RE 1.1360831583886144\n",
      "105 Train Loss 1.1622502 Test MSE 5.668155326862094 Test RE 1.1379650705088726\n",
      "106 Train Loss 1.153445 Test MSE 5.678179094359976 Test RE 1.1389708350020706\n",
      "107 Train Loss 1.1489079 Test MSE 5.696995960036447 Test RE 1.1408564865906445\n",
      "108 Train Loss 1.1411754 Test MSE 5.704693786881679 Test RE 1.14162699363829\n",
      "109 Train Loss 1.1304455 Test MSE 5.715145811411922 Test RE 1.142672347977444\n",
      "110 Train Loss 1.1200501 Test MSE 5.718416005919155 Test RE 1.142999218591983\n",
      "111 Train Loss 1.1144856 Test MSE 5.725489665037373 Test RE 1.1437059429755503\n",
      "112 Train Loss 1.1095164 Test MSE 5.7432075037756505 Test RE 1.1454742061151186\n",
      "113 Train Loss 1.1010196 Test MSE 5.7422739108565075 Test RE 1.1453811004707253\n",
      "114 Train Loss 1.0961072 Test MSE 5.7367621027118885 Test RE 1.1448312628419524\n",
      "115 Train Loss 1.0878813 Test MSE 5.711805041702005 Test RE 1.1423383264738387\n",
      "116 Train Loss 1.0826478 Test MSE 5.7336769116621 Test RE 1.1445233802677282\n",
      "117 Train Loss 1.0787238 Test MSE 5.7481846440342546 Test RE 1.1459704402435826\n",
      "118 Train Loss 1.0682564 Test MSE 5.755052845889055 Test RE 1.1466548655975353\n",
      "119 Train Loss 1.0621948 Test MSE 5.776819401860738 Test RE 1.1488212377404923\n",
      "120 Train Loss 1.0556031 Test MSE 5.774843161153273 Test RE 1.148624715974669\n",
      "121 Train Loss 1.0515491 Test MSE 5.772225160592502 Test RE 1.1483643243971062\n",
      "122 Train Loss 1.0462751 Test MSE 5.768471202640638 Test RE 1.147990845158689\n",
      "123 Train Loss 1.0379354 Test MSE 5.781941376760751 Test RE 1.1493304218961458\n",
      "124 Train Loss 1.0300833 Test MSE 5.7875516513044545 Test RE 1.1498878900018215\n",
      "125 Train Loss 1.0241386 Test MSE 5.776678693869791 Test RE 1.1488072465369061\n",
      "126 Train Loss 1.0188949 Test MSE 5.77656018411673 Test RE 1.148795462467843\n",
      "127 Train Loss 1.0120362 Test MSE 5.814211441892881 Test RE 1.1525332701269253\n",
      "128 Train Loss 1.0055166 Test MSE 5.841422405227993 Test RE 1.1552270948070866\n",
      "129 Train Loss 1.0001321 Test MSE 5.85373100513026 Test RE 1.156443557560785\n",
      "130 Train Loss 0.9923103 Test MSE 5.847682466964127 Test RE 1.1558459386390836\n",
      "131 Train Loss 0.9860748 Test MSE 5.84490398747341 Test RE 1.1555713105430234\n",
      "132 Train Loss 0.98173 Test MSE 5.827966629994105 Test RE 1.1538957890828843\n",
      "133 Train Loss 0.9781874 Test MSE 5.824989361922629 Test RE 1.153601012518495\n",
      "134 Train Loss 0.97357875 Test MSE 5.822430332516686 Test RE 1.1533475851703954\n",
      "135 Train Loss 0.9681582 Test MSE 5.827194250125341 Test RE 1.1538193236991696\n",
      "136 Train Loss 0.96301806 Test MSE 5.840873739251858 Test RE 1.1551728401545511\n",
      "137 Train Loss 0.9576153 Test MSE 5.876693506507312 Test RE 1.1587095351028995\n",
      "138 Train Loss 0.95337033 Test MSE 5.880172901875443 Test RE 1.1590525010935653\n",
      "139 Train Loss 0.9509762 Test MSE 5.884570329699865 Test RE 1.159485812941072\n",
      "140 Train Loss 0.94810945 Test MSE 5.889595176337195 Test RE 1.159980750959768\n",
      "141 Train Loss 0.94549716 Test MSE 5.892901981557751 Test RE 1.1603063499201003\n",
      "142 Train Loss 0.9404945 Test MSE 5.894907637540167 Test RE 1.160503788923746\n",
      "143 Train Loss 0.93563634 Test MSE 5.903264682705385 Test RE 1.1613261044143053\n",
      "144 Train Loss 0.9322423 Test MSE 5.90767066400775 Test RE 1.1617594092878312\n",
      "145 Train Loss 0.9297734 Test MSE 5.9064340119598 Test RE 1.161637807439323\n",
      "146 Train Loss 0.9250139 Test MSE 5.905211283248344 Test RE 1.1615175621767784\n",
      "147 Train Loss 0.92150706 Test MSE 5.893798395300519 Test RE 1.1603945980370074\n",
      "148 Train Loss 0.9169277 Test MSE 5.9266084587560055 Test RE 1.1636200036582283\n",
      "149 Train Loss 0.9149177 Test MSE 5.942153940018636 Test RE 1.1651450906238352\n",
      "Training time: 235.57\n",
      "7\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 57.73447 Test MSE 6.12679840055777 Test RE 1.183109265205138\n",
      "1 Train Loss 39.404686 Test MSE 8.07658680692922 Test RE 1.358382233999054\n",
      "2 Train Loss 29.891068 Test MSE 7.4124616614610845 Test RE 1.3013355389196803\n",
      "3 Train Loss 23.300339 Test MSE 6.509713427546733 Test RE 1.2195201919712821\n",
      "4 Train Loss 20.85397 Test MSE 6.217713795208397 Test RE 1.1918550033252542\n",
      "5 Train Loss 17.93891 Test MSE 6.0384774287502365 Test RE 1.1745507429812274\n",
      "6 Train Loss 15.552708 Test MSE 5.767678050502745 Test RE 1.1479119193339513\n",
      "7 Train Loss 13.620774 Test MSE 6.034796881383258 Test RE 1.1741927348054146\n",
      "8 Train Loss 12.751505 Test MSE 5.8914631306971 Test RE 1.1601646871436406\n",
      "9 Train Loss 12.222397 Test MSE 5.936847732646417 Test RE 1.1646247504949327\n",
      "10 Train Loss 11.907215 Test MSE 5.9298532919234646 Test RE 1.1639385025215607\n",
      "11 Train Loss 11.576504 Test MSE 5.846090570692081 Test RE 1.1556886017717276\n",
      "12 Train Loss 11.051466 Test MSE 5.735161335293264 Test RE 1.144671526704068\n",
      "13 Train Loss 10.67977 Test MSE 5.606076746752611 Test RE 1.131716322689506\n",
      "14 Train Loss 10.235344 Test MSE 5.714972586998192 Test RE 1.1426550308123198\n",
      "15 Train Loss 9.701305 Test MSE 5.59140894192198 Test RE 1.1302348350915936\n",
      "16 Train Loss 9.084822 Test MSE 5.3000792069714775 Test RE 1.1003966010641943\n",
      "17 Train Loss 8.59931 Test MSE 5.324506861709609 Test RE 1.1029295072984124\n",
      "18 Train Loss 8.155879 Test MSE 5.271130985907708 Test RE 1.0973873876029767\n",
      "19 Train Loss 7.8608103 Test MSE 5.174832976621197 Test RE 1.0873171266704615\n",
      "20 Train Loss 7.3820972 Test MSE 4.885851449875464 Test RE 1.0565211356731343\n",
      "21 Train Loss 6.8641863 Test MSE 4.757620488312302 Test RE 1.0425645607870877\n",
      "22 Train Loss 6.4502344 Test MSE 4.6113675617291525 Test RE 1.0264148587071864\n",
      "23 Train Loss 6.003977 Test MSE 4.386941025638375 Test RE 1.0011265022495295\n",
      "24 Train Loss 5.7156134 Test MSE 4.2185346322987005 Test RE 0.9817227826318634\n",
      "25 Train Loss 5.5267925 Test MSE 4.0334620589658785 Test RE 0.9599465416056339\n",
      "26 Train Loss 5.33434 Test MSE 3.8492918600702493 Test RE 0.93777463328363\n",
      "27 Train Loss 5.153242 Test MSE 3.658855244490964 Test RE 0.9142830621621719\n",
      "28 Train Loss 5.0431886 Test MSE 3.5437969895958554 Test RE 0.8997927254788717\n",
      "29 Train Loss 4.884969 Test MSE 3.4430082241963302 Test RE 0.8869049735525848\n",
      "30 Train Loss 4.746525 Test MSE 3.3427791484683786 Test RE 0.8739003283290208\n",
      "31 Train Loss 4.590517 Test MSE 3.1370579269049204 Test RE 0.8465825830189925\n",
      "32 Train Loss 4.4145107 Test MSE 3.0716388945445776 Test RE 0.8377089190411905\n",
      "33 Train Loss 4.287327 Test MSE 3.0396844913713332 Test RE 0.8333401647025686\n",
      "34 Train Loss 4.097274 Test MSE 2.9209314155472432 Test RE 0.8168997067106766\n",
      "35 Train Loss 3.8410535 Test MSE 2.8410664061581885 Test RE 0.8056543433014132\n",
      "36 Train Loss 3.5998104 Test MSE 2.906677890412391 Test RE 0.8149041206622019\n",
      "37 Train Loss 3.2627463 Test MSE 2.783826568001811 Test RE 0.7974971651053764\n",
      "38 Train Loss 2.972186 Test MSE 2.7304171659942136 Test RE 0.7898098817119353\n",
      "39 Train Loss 2.806224 Test MSE 2.47965930449799 Test RE 0.7526690664483003\n",
      "40 Train Loss 2.5691142 Test MSE 2.2225335605473124 Test RE 0.7125776951152536\n",
      "41 Train Loss 2.2011082 Test MSE 2.0310431236938835 Test RE 0.6811890098911231\n",
      "42 Train Loss 1.996604 Test MSE 1.7822650511240048 Test RE 0.6381080240113564\n",
      "43 Train Loss 1.8375767 Test MSE 1.5823074080434043 Test RE 0.6012477871058768\n",
      "44 Train Loss 1.5470774 Test MSE 1.1222106143221582 Test RE 0.5063435082609307\n",
      "45 Train Loss 1.1610721 Test MSE 0.7724542649830859 Test RE 0.4200920356259262\n",
      "46 Train Loss 1.0208112 Test MSE 0.7259957646171672 Test RE 0.4072631385646795\n",
      "47 Train Loss 0.82373875 Test MSE 0.6000217388248115 Test RE 0.3702470039404142\n",
      "48 Train Loss 0.7301933 Test MSE 0.5392050648815196 Test RE 0.35098215952053025\n",
      "49 Train Loss 0.6203397 Test MSE 0.503347353681545 Test RE 0.33911106057124857\n",
      "50 Train Loss 0.5661308 Test MSE 0.43268205928002046 Test RE 0.31440721545515476\n",
      "51 Train Loss 0.50908226 Test MSE 0.4226686047264901 Test RE 0.31074779479627823\n",
      "52 Train Loss 0.45578638 Test MSE 0.4404563462956002 Test RE 0.317219222412005\n",
      "53 Train Loss 0.40593898 Test MSE 0.4377226486362277 Test RE 0.31623327773440507\n",
      "54 Train Loss 0.38481486 Test MSE 0.4108706727600773 Test RE 0.30638015522849715\n",
      "55 Train Loss 0.3506946 Test MSE 0.3912069264841122 Test RE 0.29895879066443637\n",
      "56 Train Loss 0.33201703 Test MSE 0.3757846836765582 Test RE 0.2930067314369297\n",
      "57 Train Loss 0.31144655 Test MSE 0.3649523978656195 Test RE 0.28875277792021126\n",
      "58 Train Loss 0.29062796 Test MSE 0.33985054076167487 Test RE 0.278645505864838\n",
      "59 Train Loss 0.2599762 Test MSE 0.2907621980005906 Test RE 0.2577371559428012\n",
      "60 Train Loss 0.24794906 Test MSE 0.29366468641298576 Test RE 0.2590203720522757\n",
      "61 Train Loss 0.2280701 Test MSE 0.26629256146738406 Test RE 0.2466536677719039\n",
      "62 Train Loss 0.20443994 Test MSE 0.23591108848436007 Test RE 0.23215724292740011\n",
      "63 Train Loss 0.18476939 Test MSE 0.22841116069636158 Test RE 0.22843714337612717\n",
      "64 Train Loss 0.17149016 Test MSE 0.19666715482582905 Test RE 0.2119697939926894\n",
      "65 Train Loss 0.16342591 Test MSE 0.17492902300910182 Test RE 0.1999120605456026\n",
      "66 Train Loss 0.14334287 Test MSE 0.15253268112761253 Test RE 0.18667644095314145\n",
      "67 Train Loss 0.13561383 Test MSE 0.15688032157197548 Test RE 0.18931816908756519\n",
      "68 Train Loss 0.12068573 Test MSE 0.12296379619416518 Test RE 0.16760875166188244\n",
      "69 Train Loss 0.10995546 Test MSE 0.09145680402316 Test RE 0.14454932589439864\n",
      "70 Train Loss 0.10060989 Test MSE 0.06608183289615649 Test RE 0.12287091728424879\n",
      "71 Train Loss 0.09363465 Test MSE 0.06326631359078319 Test RE 0.1202248724847516\n",
      "72 Train Loss 0.0870581 Test MSE 0.06311083628344344 Test RE 0.12007705497658425\n",
      "73 Train Loss 0.07926244 Test MSE 0.06028719821377714 Test RE 0.1173601377949839\n",
      "74 Train Loss 0.075253114 Test MSE 0.05677158974146383 Test RE 0.11388685188068676\n",
      "75 Train Loss 0.06816007 Test MSE 0.048675222474903586 Test RE 0.10545375115162396\n",
      "76 Train Loss 0.06181205 Test MSE 0.04255177490472555 Test RE 0.0985977263415731\n",
      "77 Train Loss 0.05480171 Test MSE 0.03362671078948927 Test RE 0.08764966380615709\n",
      "78 Train Loss 0.051506557 Test MSE 0.029925013197971646 Test RE 0.08268471534038088\n",
      "79 Train Loss 0.048439156 Test MSE 0.029400218851326838 Test RE 0.08195648840938578\n",
      "80 Train Loss 0.04375301 Test MSE 0.028045848556722718 Test RE 0.08004650096695211\n",
      "81 Train Loss 0.04074172 Test MSE 0.029343131048289332 Test RE 0.08187688034046878\n",
      "82 Train Loss 0.039542887 Test MSE 0.028512680253377776 Test RE 0.08070995073218568\n",
      "83 Train Loss 0.038177174 Test MSE 0.027393319601468083 Test RE 0.07910981930306861\n",
      "84 Train Loss 0.035004493 Test MSE 0.024216816720714334 Test RE 0.07438178354081758\n",
      "85 Train Loss 0.032350473 Test MSE 0.02184586457158395 Test RE 0.07064682990754864\n",
      "86 Train Loss 0.031500872 Test MSE 0.019490062730462544 Test RE 0.06672900955380953\n",
      "87 Train Loss 0.030133404 Test MSE 0.017643978446010868 Test RE 0.06349014509345186\n",
      "88 Train Loss 0.02765272 Test MSE 0.0166943728496098 Test RE 0.06175798456966454\n",
      "89 Train Loss 0.025793321 Test MSE 0.016763898302132103 Test RE 0.06188644973284628\n",
      "90 Train Loss 0.023876248 Test MSE 0.017529657849046858 Test RE 0.06328412504486969\n",
      "91 Train Loss 0.022873133 Test MSE 0.017970531981651043 Test RE 0.06407498705836544\n",
      "92 Train Loss 0.022369154 Test MSE 0.019470747862960713 Test RE 0.06669593676504208\n",
      "93 Train Loss 0.020539992 Test MSE 0.021151700211355498 Test RE 0.06951534804775156\n",
      "94 Train Loss 0.018128939 Test MSE 0.016801404120986126 Test RE 0.06195564023773495\n",
      "95 Train Loss 0.017892234 Test MSE 0.016684404629375458 Test RE 0.061739543951356717\n",
      "96 Train Loss 0.016568735 Test MSE 0.015435532433602616 Test RE 0.05938392070030194\n",
      "97 Train Loss 0.01485886 Test MSE 0.012966385648916933 Test RE 0.05442739234357743\n",
      "98 Train Loss 0.014362617 Test MSE 0.013517418131199442 Test RE 0.05557186016691325\n",
      "99 Train Loss 0.014032839 Test MSE 0.013561949110118864 Test RE 0.05566332121956824\n",
      "100 Train Loss 0.013058826 Test MSE 0.00924816486639111 Test RE 0.04596590783385198\n",
      "101 Train Loss 0.012905179 Test MSE 0.00939611989219941 Test RE 0.04633213734697894\n",
      "102 Train Loss 0.012551766 Test MSE 0.008577129109618758 Test RE 0.044266892304738834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 Train Loss 0.011199022 Test MSE 0.007583952427623293 Test RE 0.04162515467706248\n",
      "104 Train Loss 0.009574786 Test MSE 0.00524788022571381 Test RE 0.03462581604878492\n",
      "105 Train Loss 0.008980181 Test MSE 0.005603523817879686 Test RE 0.0357798628410368\n",
      "106 Train Loss 0.008879349 Test MSE 0.005439570091288112 Test RE 0.03525253471075796\n",
      "107 Train Loss 0.008558586 Test MSE 0.00541055776758779 Test RE 0.03515839810458839\n",
      "108 Train Loss 0.0076852986 Test MSE 0.005597329287327659 Test RE 0.0357600805800369\n",
      "109 Train Loss 0.0069271466 Test MSE 0.006208842627827489 Test RE 0.037662867844783336\n",
      "110 Train Loss 0.006661123 Test MSE 0.006439105422081347 Test RE 0.038354897637248205\n",
      "111 Train Loss 0.006536269 Test MSE 0.005947663477831214 Test RE 0.036862200266029904\n",
      "112 Train Loss 0.006430674 Test MSE 0.005887176428169569 Test RE 0.03667427910433304\n",
      "113 Train Loss 0.006264901 Test MSE 0.0058637698834218595 Test RE 0.03660130073330877\n",
      "114 Train Loss 0.006109217 Test MSE 0.006284129902869119 Test RE 0.03789052626613119\n",
      "115 Train Loss 0.005909537 Test MSE 0.0065074909767905914 Test RE 0.03855803094780451\n",
      "116 Train Loss 0.0056243534 Test MSE 0.006005400697984677 Test RE 0.03704068890328016\n",
      "117 Train Loss 0.005546182 Test MSE 0.005645974817773594 Test RE 0.03591513710385687\n",
      "118 Train Loss 0.005463171 Test MSE 0.00548067639676371 Test RE 0.03538548401116273\n",
      "119 Train Loss 0.0053949794 Test MSE 0.005114640396470466 Test RE 0.034183427984132826\n",
      "120 Train Loss 0.005089782 Test MSE 0.005614573244486377 Test RE 0.03581512210644763\n",
      "121 Train Loss 0.0049173804 Test MSE 0.0051987923731547335 Test RE 0.03446349333210706\n",
      "122 Train Loss 0.0046677925 Test MSE 0.004657697762468482 Test RE 0.03262073274473665\n",
      "123 Train Loss 0.004579842 Test MSE 0.005139997254598095 Test RE 0.034268058828829724\n",
      "124 Train Loss 0.004497808 Test MSE 0.005588405610739965 Test RE 0.03573156352603704\n",
      "125 Train Loss 0.0044467435 Test MSE 0.005584161738193328 Test RE 0.03571799355526693\n",
      "126 Train Loss 0.004395189 Test MSE 0.00537802459812527 Test RE 0.03505253667837258\n",
      "127 Train Loss 0.0043391543 Test MSE 0.005318300643910878 Test RE 0.034857360860109494\n",
      "128 Train Loss 0.0042568156 Test MSE 0.005514767755916603 Test RE 0.035495367265159825\n",
      "129 Train Loss 0.0038383673 Test MSE 0.0053781828136437145 Test RE 0.035053052277955146\n",
      "130 Train Loss 0.0035451704 Test MSE 0.004850811572047904 Test RE 0.033290112495985714\n",
      "131 Train Loss 0.0034047132 Test MSE 0.004657104840082324 Test RE 0.03261865637790635\n",
      "132 Train Loss 0.003382039 Test MSE 0.004611440975784903 Test RE 0.032458346146712155\n",
      "133 Train Loss 0.0033454194 Test MSE 0.0046187653353479555 Test RE 0.032484112742748025\n",
      "134 Train Loss 0.0031767748 Test MSE 0.004595537060050909 Test RE 0.03240232671009383\n",
      "135 Train Loss 0.003022269 Test MSE 0.004283288972643222 Test RE 0.031282161069060364\n",
      "136 Train Loss 0.0028992128 Test MSE 0.004275508688336743 Test RE 0.03125373726537962\n",
      "137 Train Loss 0.0027911118 Test MSE 0.003793662045616027 Test RE 0.029439971150694168\n",
      "138 Train Loss 0.0027229998 Test MSE 0.0038204071953665346 Test RE 0.02954356413758481\n",
      "139 Train Loss 0.002663321 Test MSE 0.0033887166462885257 Test RE 0.027824392326599362\n",
      "140 Train Loss 0.0026213345 Test MSE 0.0033937769593255437 Test RE 0.027845159423044018\n",
      "141 Train Loss 0.0025900642 Test MSE 0.0034142916691933963 Test RE 0.027929191862671385\n",
      "142 Train Loss 0.00253772 Test MSE 0.003479223984882207 Test RE 0.028193516951918917\n",
      "143 Train Loss 0.002421116 Test MSE 0.0034966715027959644 Test RE 0.028264120588728764\n",
      "144 Train Loss 0.0023450041 Test MSE 0.0034571975015138326 Test RE 0.028104130636023603\n",
      "145 Train Loss 0.0023087321 Test MSE 0.003645993040024354 Test RE 0.028861305900430255\n",
      "146 Train Loss 0.0022270652 Test MSE 0.003953813056404588 Test RE 0.030054958033456272\n",
      "147 Train Loss 0.002098169 Test MSE 0.0038426911680285026 Test RE 0.029629600876028478\n",
      "148 Train Loss 0.002034388 Test MSE 0.0037688901174476844 Test RE 0.029343694878673957\n",
      "149 Train Loss 0.0019944585 Test MSE 0.0037327119330252782 Test RE 0.029202517835241824\n",
      "Training time: 231.83\n",
      "8\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "1 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "2 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "3 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "4 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "5 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "6 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "7 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "8 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "9 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "10 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "11 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "12 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "13 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "14 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "15 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "16 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "17 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "18 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "19 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "20 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "21 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "22 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "23 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "24 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "25 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "26 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "27 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "28 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "29 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "30 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "31 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "32 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "33 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "34 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "35 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "36 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "37 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "38 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "39 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "40 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "41 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "42 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "43 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "44 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "46 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "47 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "48 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "49 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "50 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "51 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "52 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "53 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "54 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "55 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "56 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "57 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "58 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "59 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "60 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "61 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "62 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "63 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "64 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "65 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "66 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "67 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "68 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "69 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "70 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "71 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "72 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "73 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "74 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "75 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "76 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "77 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "78 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "79 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "80 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "81 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "82 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "83 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "84 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "85 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "86 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "87 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "88 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "89 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "90 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "91 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "92 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "93 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "94 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "95 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "96 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "97 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "98 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "99 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "100 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "101 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "102 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "103 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "104 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "105 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "106 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "107 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "108 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "109 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "110 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "111 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "112 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "113 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "114 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "115 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "116 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "117 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "118 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "119 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "120 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "121 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "122 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "123 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "124 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "125 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "126 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "127 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "128 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "129 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "130 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "131 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "132 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "133 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "134 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "135 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "136 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "137 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "138 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "139 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "140 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "141 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "142 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "143 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "144 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "145 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "146 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "147 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "148 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "149 Train Loss 72.8719 Test MSE 4.4962677908957325 Test RE 1.0135242515015517\n",
      "Training time: 100.80\n",
      "9\n",
      "KG_rowdy_tune73\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 66.6812 Test MSE 6.11590852624994 Test RE 1.1820573584455758\n",
      "1 Train Loss 51.58285 Test MSE 7.723184708431573 Test RE 1.3283308866476935\n",
      "2 Train Loss 41.00624 Test MSE 8.031932564176172 Test RE 1.3546218828962049\n",
      "3 Train Loss 34.74386 Test MSE 8.110913966969166 Test RE 1.3612658755867886\n",
      "4 Train Loss 31.384548 Test MSE 8.146524445616482 Test RE 1.364250880672037\n",
      "5 Train Loss 29.558664 Test MSE 8.443134375356488 Test RE 1.3888646075333335\n",
      "6 Train Loss 28.196972 Test MSE 8.601641813114966 Test RE 1.4018409336513977\n",
      "7 Train Loss 26.876862 Test MSE 8.83503567303099 Test RE 1.4207321685627856\n",
      "8 Train Loss 26.295544 Test MSE 8.733446408801408 Test RE 1.4125404396367722\n",
      "9 Train Loss 25.440624 Test MSE 8.558054632071858 Test RE 1.3982846418003456\n",
      "10 Train Loss 24.598017 Test MSE 8.249992514437153 Test RE 1.3728871418182853\n",
      "11 Train Loss 23.63694 Test MSE 8.452811724136788 Test RE 1.3896603237631864\n",
      "12 Train Loss 22.651909 Test MSE 8.68290874739009 Test RE 1.4084475500884976\n",
      "13 Train Loss 21.603401 Test MSE 8.22723981215763 Test RE 1.370992688023438\n",
      "14 Train Loss 20.638737 Test MSE 8.296319679577689 Test RE 1.3767364138702154\n",
      "15 Train Loss 19.864162 Test MSE 8.33776765132681 Test RE 1.3801711801777365\n",
      "16 Train Loss 19.168459 Test MSE 8.267566810900515 Test RE 1.374348639512615\n",
      "17 Train Loss 18.67635 Test MSE 8.305270876476717 Test RE 1.3774789187962808\n",
      "18 Train Loss 17.740417 Test MSE 8.190759075542974 Test RE 1.3679497239950387\n",
      "19 Train Loss 17.408945 Test MSE 8.027767794598049 Test RE 1.354270633710939\n",
      "20 Train Loss 17.146172 Test MSE 8.037160072855045 Test RE 1.3550626327262398\n",
      "21 Train Loss 16.597569 Test MSE 8.16488640005632 Test RE 1.3657874999356678\n",
      "22 Train Loss 15.916502 Test MSE 8.020856764427236 Test RE 1.3536875687374514\n",
      "23 Train Loss 15.624552 Test MSE 8.013354824618583 Test RE 1.3530543659114256\n",
      "24 Train Loss 15.276052 Test MSE 7.993594108021994 Test RE 1.351385038383511\n",
      "25 Train Loss 14.764362 Test MSE 7.962711747240565 Test RE 1.348772049380997\n",
      "26 Train Loss 14.362547 Test MSE 8.195698741525602 Test RE 1.3683621519629832\n",
      "27 Train Loss 13.847971 Test MSE 8.11523358196719 Test RE 1.361628310808658\n",
      "28 Train Loss 13.128094 Test MSE 7.894367806308699 Test RE 1.3429713215840247\n",
      "29 Train Loss 12.463723 Test MSE 7.915554166511331 Test RE 1.3447722010591243\n",
      "30 Train Loss 11.918804 Test MSE 7.541562232737385 Test RE 1.3126191013871213\n",
      "31 Train Loss 11.060459 Test MSE 7.4202018871655016 Test RE 1.3020148006221208\n",
      "32 Train Loss 10.561464 Test MSE 7.443533574895925 Test RE 1.304060187040105\n",
      "33 Train Loss 9.333737 Test MSE 6.287751262524777 Test RE 1.1985488425102184\n",
      "34 Train Loss 8.517334 Test MSE 5.585143912657412 Test RE 1.1296014581547735\n",
      "35 Train Loss 7.5622377 Test MSE 5.583629658364316 Test RE 1.129448317981602\n",
      "36 Train Loss 6.93235 Test MSE 5.365637364767921 Test RE 1.1071812414848972\n",
      "37 Train Loss 6.355486 Test MSE 5.7648511753598255 Test RE 1.1476305754939085\n",
      "38 Train Loss 5.888391 Test MSE 5.967893116373029 Test RE 1.1676658490222835\n",
      "39 Train Loss 5.4907355 Test MSE 6.032806333637383 Test RE 1.173999068016389\n",
      "40 Train Loss 5.282684 Test MSE 6.168934186915339 Test RE 1.1871705888409017\n",
      "41 Train Loss 5.0030174 Test MSE 6.1630698336348 Test RE 1.1866061766688862\n",
      "42 Train Loss 4.7391915 Test MSE 6.256329347821953 Test RE 1.195550324716632\n",
      "43 Train Loss 4.53285 Test MSE 6.438290875590467 Test RE 1.2128116419806318\n",
      "44 Train Loss 4.286566 Test MSE 6.6354923868233096 Test RE 1.2312454480020678\n",
      "45 Train Loss 4.178502 Test MSE 6.684243808937286 Test RE 1.2357601934298312\n",
      "46 Train Loss 4.0685744 Test MSE 6.719388954542761 Test RE 1.2390046915166735\n",
      "47 Train Loss 3.9235868 Test MSE 6.714594426047725 Test RE 1.2385625751726135\n",
      "48 Train Loss 3.787072 Test MSE 6.681627152253499 Test RE 1.235518290472548\n",
      "49 Train Loss 3.7000918 Test MSE 6.708148515954424 Test RE 1.2379679316642138\n",
      "50 Train Loss 3.5336444 Test MSE 6.8181629552746434 Test RE 1.248078059607058\n",
      "51 Train Loss 3.458948 Test MSE 6.817600272896974 Test RE 1.2480265584897934\n",
      "52 Train Loss 3.390568 Test MSE 6.801223102073325 Test RE 1.2465266587623185\n",
      "53 Train Loss 3.2519763 Test MSE 6.821540481844511 Test RE 1.2483871527539006\n",
      "54 Train Loss 3.1707535 Test MSE 6.839226059513618 Test RE 1.250004394221737\n",
      "55 Train Loss 3.0928657 Test MSE 6.79703656289437 Test RE 1.2461429457187474\n",
      "56 Train Loss 3.044452 Test MSE 6.8172649240202015 Test RE 1.2479958637119675\n",
      "57 Train Loss 2.9701548 Test MSE 6.8095494480236365 Test RE 1.2472894507908703\n",
      "58 Train Loss 2.930231 Test MSE 6.771147680797479 Test RE 1.2437674968233132\n",
      "59 Train Loss 2.882415 Test MSE 6.7670570161715595 Test RE 1.2433917404076464\n",
      "60 Train Loss 2.7596622 Test MSE 6.812002554816926 Test RE 1.24751409551475\n",
      "61 Train Loss 2.7281194 Test MSE 6.784310801178436 Test RE 1.2449758527071597\n",
      "62 Train Loss 2.6593978 Test MSE 6.816462236988362 Test RE 1.2479223899951744\n",
      "63 Train Loss 2.6277206 Test MSE 6.878882493340275 Test RE 1.253623156507221\n",
      "64 Train Loss 2.521402 Test MSE 6.9073007474685895 Test RE 1.2562099911202458\n",
      "65 Train Loss 2.4442003 Test MSE 6.890479765360338 Test RE 1.2546794680653814\n",
      "66 Train Loss 2.4137888 Test MSE 6.870772509903856 Test RE 1.25288394767393\n",
      "67 Train Loss 2.3738458 Test MSE 6.975397820121817 Test RE 1.2623871086498024\n",
      "68 Train Loss 2.3174074 Test MSE 6.974389927797388 Test RE 1.2622959026516178\n",
      "69 Train Loss 2.2789617 Test MSE 7.012643677694067 Test RE 1.2657529447917084\n",
      "70 Train Loss 2.1863384 Test MSE 7.028012080280113 Test RE 1.267139152023802\n",
      "71 Train Loss 2.1762176 Test MSE 7.027629021313917 Test RE 1.2671046190988282\n",
      "72 Train Loss 2.0994346 Test MSE 7.02908865974671 Test RE 1.2672362010711216\n",
      "73 Train Loss 2.0825372 Test MSE 7.042687075919635 Test RE 1.2684614010736137\n",
      "74 Train Loss 2.0348709 Test MSE 7.107452674187022 Test RE 1.2742805331818055\n",
      "75 Train Loss 2.0181813 Test MSE 7.090255850791155 Test RE 1.2727380080613715\n",
      "76 Train Loss 1.93328 Test MSE 6.998131284856298 Test RE 1.2644425532904693\n",
      "77 Train Loss 1.9107401 Test MSE 6.926713295095976 Test RE 1.2579740033734261\n",
      "78 Train Loss 1.886304 Test MSE 6.923710502770451 Test RE 1.257701302310252\n",
      "79 Train Loss 1.8361584 Test MSE 7.001296552786157 Test RE 1.2647284758346893\n",
      "80 Train Loss 1.8197876 Test MSE 6.990696623996187 Test RE 1.263770716818712\n",
      "81 Train Loss 1.7842739 Test MSE 6.9829451922233154 Test RE 1.2630698746828422\n",
      "82 Train Loss 1.7532287 Test MSE 6.958775682393795 Test RE 1.2608820985679052\n",
      "83 Train Loss 1.7380668 Test MSE 6.963901706437504 Test RE 1.2613464131559646\n",
      "84 Train Loss 1.6997436 Test MSE 6.9206872474173755 Test RE 1.257426683133112\n",
      "85 Train Loss 1.6487106 Test MSE 6.945796123996962 Test RE 1.2597056465557641\n",
      "86 Train Loss 1.6381867 Test MSE 6.957145924032202 Test RE 1.2607344394416227\n",
      "87 Train Loss 1.6308986 Test MSE 6.946581549268233 Test RE 1.2597768678141201\n",
      "88 Train Loss 1.5972458 Test MSE 6.955216330866527 Test RE 1.2605595923643722\n",
      "89 Train Loss 1.5583853 Test MSE 7.025634580148373 Test RE 1.2669248041901606\n",
      "90 Train Loss 1.5440304 Test MSE 7.0515573840384285 Test RE 1.2692599672099296\n",
      "91 Train Loss 1.5342648 Test MSE 7.041547538204537 Test RE 1.268358775607918\n",
      "92 Train Loss 1.5168843 Test MSE 7.031039574553547 Test RE 1.267412048785387\n",
      "93 Train Loss 1.4822428 Test MSE 6.967982048562172 Test RE 1.2617158878728039\n",
      "94 Train Loss 1.4727598 Test MSE 6.972269568507741 Test RE 1.2621040059888577\n",
      "95 Train Loss 1.4634519 Test MSE 6.955917811790229 Test RE 1.2606231587705359\n",
      "96 Train Loss 1.4384634 Test MSE 6.935402966328774 Test RE 1.2587628301802098\n",
      "97 Train Loss 1.4162738 Test MSE 6.897356799529276 Test RE 1.2553054275073394\n",
      "98 Train Loss 1.4054796 Test MSE 6.903476132190222 Test RE 1.255862157331196\n",
      "99 Train Loss 1.3849703 Test MSE 6.853286982829575 Test RE 1.2512886909547312\n",
      "100 Train Loss 1.3693743 Test MSE 6.8671085942901815 Test RE 1.2525498459995426\n",
      "101 Train Loss 1.3603812 Test MSE 6.8454920001632535 Test RE 1.2505768756780478\n",
      "102 Train Loss 1.3533387 Test MSE 6.848008009785375 Test RE 1.2508066746750113\n",
      "103 Train Loss 1.3427252 Test MSE 6.8410260444941215 Test RE 1.2501688749022954\n",
      "104 Train Loss 1.3226768 Test MSE 6.772685825290206 Test RE 1.2439087568860547\n",
      "105 Train Loss 1.3097658 Test MSE 6.741662919740134 Test RE 1.2410565681647276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Train Loss 1.3031895 Test MSE 6.713690317135507 Test RE 1.2384791871756113\n",
      "107 Train Loss 1.2965555 Test MSE 6.671875372918408 Test RE 1.2346163469158675\n",
      "108 Train Loss 1.2912827 Test MSE 6.654640601708264 Test RE 1.2330206868959719\n",
      "109 Train Loss 1.2817495 Test MSE 6.628761968542551 Test RE 1.230620859893832\n",
      "110 Train Loss 1.2690561 Test MSE 6.656054670818527 Test RE 1.2331516844926194\n",
      "111 Train Loss 1.2624925 Test MSE 6.635265342697813 Test RE 1.2312243832926955\n",
      "112 Train Loss 1.2552857 Test MSE 6.576506026383727 Test RE 1.2257606392566145\n",
      "113 Train Loss 1.2440877 Test MSE 6.541197495085274 Test RE 1.222465724349578\n",
      "114 Train Loss 1.2288598 Test MSE 6.508483572990399 Test RE 1.2194049869528598\n",
      "115 Train Loss 1.2202549 Test MSE 6.463748995821868 Test RE 1.2152071102205475\n",
      "116 Train Loss 1.2093954 Test MSE 6.433088744428451 Test RE 1.2123215678032597\n",
      "117 Train Loss 1.2012815 Test MSE 6.421296197612803 Test RE 1.2112098999002758\n",
      "118 Train Loss 1.1923233 Test MSE 6.403162744862674 Test RE 1.2094984895655547\n",
      "119 Train Loss 1.1851196 Test MSE 6.395602063483557 Test RE 1.2087842071006831\n",
      "120 Train Loss 1.1786312 Test MSE 6.388832462423825 Test RE 1.2081443022651557\n",
      "121 Train Loss 1.1719704 Test MSE 6.391896669626378 Test RE 1.2084339921821114\n",
      "122 Train Loss 1.161494 Test MSE 6.386489906029565 Test RE 1.2079227903024436\n",
      "123 Train Loss 1.1580622 Test MSE 6.391409958492944 Test RE 1.2083879831878195\n",
      "124 Train Loss 1.1533637 Test MSE 6.346366339562022 Test RE 1.20412238239714\n",
      "125 Train Loss 1.1470637 Test MSE 6.355738366687747 Test RE 1.2050111511650377\n",
      "126 Train Loss 1.142342 Test MSE 6.319321996847647 Test RE 1.2015540256813997\n",
      "127 Train Loss 1.1362518 Test MSE 6.272158070708674 Test RE 1.197061760515722\n",
      "128 Train Loss 1.132776 Test MSE 6.251923562472394 Test RE 1.195129289835761\n",
      "129 Train Loss 1.1282449 Test MSE 6.236698087614541 Test RE 1.1936731377544771\n",
      "130 Train Loss 1.1233144 Test MSE 6.2210514436195945 Test RE 1.192174852339624\n",
      "131 Train Loss 1.1204389 Test MSE 6.234169728556331 Test RE 1.1934311555238184\n",
      "132 Train Loss 1.1164246 Test MSE 6.217276984825875 Test RE 1.1918131371505625\n",
      "133 Train Loss 1.1100218 Test MSE 6.2177891066175635 Test RE 1.1918622214130414\n",
      "134 Train Loss 1.1041155 Test MSE 6.217939133751371 Test RE 1.1918766003660175\n",
      "135 Train Loss 1.1002074 Test MSE 6.1801831063731845 Test RE 1.1882524859415151\n",
      "136 Train Loss 1.0956573 Test MSE 6.180458496015829 Test RE 1.1882789599776842\n",
      "137 Train Loss 1.0933907 Test MSE 6.187935096306122 Test RE 1.1889974828494532\n",
      "138 Train Loss 1.0913292 Test MSE 6.211111190518346 Test RE 1.1912220184433826\n",
      "139 Train Loss 1.0882354 Test MSE 6.2050818842590285 Test RE 1.1906437011342033\n",
      "140 Train Loss 1.0859494 Test MSE 6.204283244415582 Test RE 1.1905670763518394\n",
      "141 Train Loss 1.0836443 Test MSE 6.211789394845173 Test RE 1.1912870526900485\n",
      "142 Train Loss 1.079787 Test MSE 6.217429040926227 Test RE 1.1918277111634625\n",
      "143 Train Loss 1.0760719 Test MSE 6.2343720008700405 Test RE 1.1934505162513516\n",
      "144 Train Loss 1.0736407 Test MSE 6.210532216950786 Test RE 1.1911664968053235\n",
      "145 Train Loss 1.070437 Test MSE 6.214001138435479 Test RE 1.1914991161424147\n",
      "146 Train Loss 1.0675219 Test MSE 6.182419355864413 Test RE 1.1884674462946838\n",
      "147 Train Loss 1.0647532 Test MSE 6.170307497797339 Test RE 1.1873027237861704\n",
      "148 Train Loss 1.0628308 Test MSE 6.157021810944737 Test RE 1.186023805967084\n",
      "149 Train Loss 1.060627 Test MSE 6.154538331052443 Test RE 1.185784586142701\n",
      "Training time: 240.38\n",
      "0\n",
      "KG_rowdy_tune74\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 76.11553 Test MSE 4.384488318669763 Test RE 1.0008466018315592\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.11\n"
     ]
    }
   ],
   "source": [
    "nan_tune = []\n",
    "for tune_reps in range(59,75):\n",
    "#for tune_reps in range(1,5):\n",
    "    max_reps = 10 #10\n",
    "    max_iter = 150 #100\n",
    "    label = \"KG_rowdy_tune\"+str(tune_reps)\n",
    "\n",
    "    train_loss_full = []\n",
    "    test_mse_full = []\n",
    "    test_re_full = []\n",
    "    alpha_full = []\n",
    "    omega_full = []\n",
    "    elapsed_time= np.zeros((max_reps,1))\n",
    "    time_threshold = np.empty((max_reps,1))\n",
    "    time_threshold[:] = np.nan\n",
    "    epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "    n_val = lrnr_tune[tune_reps,1]\n",
    "    rowdy_terms = int(lrnr_tune[tune_reps,2])\n",
    "\n",
    "    N_I = 200  #Total number of data points for 'y'\n",
    "    N_B = 400\n",
    "    N_f = 10000 #Total number of collocation points\n",
    "\n",
    "    for reps in range(max_reps):\n",
    "        print(reps)\n",
    "        print(label)\n",
    "\n",
    "        train_loss = []\n",
    "        test_mse_loss = []\n",
    "        test_re_loss = []\n",
    "        alpha_val = []\n",
    "        omega_val = []\n",
    "\n",
    "        torch.manual_seed(reps*36)\n",
    "\n",
    "        layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "        PINN = Sequentialmodel(layers,n_val,rowdy_terms)\n",
    "\n",
    "        PINN.to(device)\n",
    "\n",
    "        'Neural Network Summary'\n",
    "        print(PINN)\n",
    "\n",
    "        params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "        optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lrnr_tune[tune_reps,0], \n",
    "                                max_iter = 10, \n",
    "                                max_eval = 15, \n",
    "                                tolerance_grad = 1e-8, \n",
    "                                tolerance_change = 1e-8, \n",
    "                                history_size = 100, \n",
    "                                line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        nan_flag = train_model(max_iter,reps)\n",
    "        \n",
    "        torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "        train_loss_full.append(train_loss)\n",
    "        test_mse_full.append(test_mse_loss)\n",
    "        test_re_full.append(test_re_loss)\n",
    "        #elapsed_time[reps] = time.time() - start_time\n",
    "        alpha_full.append(alpha_val)\n",
    "        omega_full.append(omega_val)\n",
    "        \n",
    "        if(nan_flag == 1):\n",
    "            nan_tune.append(tune_reps)\n",
    "            break\n",
    "\n",
    "        \n",
    "      #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "    mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"alpha\": alpha_full,  \"omega\": omega_full,\"label\": label}\n",
    "    savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_O3sPdAnSq_2"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1660688516819,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "jQ4afiEWSq_2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0.596973766966899\n",
      "1   0.5072998354747253\n",
      "2   0.6490636715259515\n",
      "3   0.7478114379605724\n",
      "4   0.7307756400749132\n",
      "5   [[1.39820987 1.40606195 1.40857236 1.4004214         nan]]\n",
      "6   0.6369661983453053\n",
      "7   0.6534731561974925\n",
      "8   [[nan]]\n",
      "9   0.7085471705904642\n",
      "10   [[1.39931289 1.40377694 1.34170088        nan]]\n",
      "11   [[1.40566328 1.40801557 1.39946563 1.41554158 1.50086596 1.42153959\n",
      "  1.40316584 1.4084073  1.41551259 1.40295589 1.37523476 1.39143502\n",
      "  1.38436655 1.3823696  1.38273455 1.39102242 1.39152609 1.38885467\n",
      "  1.36260162        nan]]\n",
      "12   0.77939949900916\n",
      "13   0.81809848750763\n",
      "14   0.7777616994715444\n",
      "15   [[1.40028253 1.38943248        nan]]\n",
      "16   [[nan]]\n",
      "17   0.6584977126706268\n",
      "18   [[1.39891729 1.40650667        nan]]\n",
      "19   0.8209052688189985\n",
      "20   [[1.40936385 1.41607491        nan]]\n",
      "21   0.6452496479726479\n",
      "22   0.7869274085695085\n",
      "23   0.7651063921627932\n",
      "24   0.7415352949185082\n",
      "25   0.8407026087017467\n",
      "26   0.7332776605437219\n",
      "27   nan\n",
      "28   0.7809511340987055\n",
      "29   [[nan]]\n",
      "30   0.8308645931340276\n",
      "31   [[nan]]\n",
      "32   nan\n",
      "33   0.7222974426598492\n",
      "34   nan\n",
      "35   0.8550575480574427\n",
      "36   [[nan]]\n",
      "37   [[nan]]\n",
      "38   0.7943954497827805\n",
      "39   0.7456377511616964\n",
      "40   0.8265896494123751\n",
      "41   [[nan]]\n",
      "42   0.7904327916536339\n",
      "43   [[nan]]\n",
      "44   0.8250926632778774\n",
      "45   [[nan]]\n",
      "46   [[nan]]\n",
      "47   nan\n",
      "48   [[nan]]\n",
      "49   [[1.00079456        nan]]\n",
      "50   0.8404916571188883\n",
      "51   0.8621609151710125\n",
      "52   0.6826901811689854\n",
      "53   0.7892193720156359\n",
      "54   0.7111381020367263\n",
      "55   nan\n",
      "56   0.8302561152292623\n",
      "57   0.7884930123963446\n",
      "58   0.7682028575027705\n",
      "59   0.7535819766017576\n",
      "60   0.8476975559780495\n",
      "61   nan\n",
      "62   nan\n",
      "63   0.7714319735698474\n",
      "64   0.7734934265863782\n",
      "65   [[nan]]\n",
      "66   0.9521431428762515\n",
      "67   0.8473192464157533\n",
      "68   [[nan]]\n",
      "69   0.7603198364706919\n",
      "70   nan\n",
      "71   nan\n",
      "72   0.9364992965341509\n",
      "73   0.8044595510124098\n",
      "74   nan\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(75):\n",
    "    label = \"KG_rowdy_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 3.  , 2.  ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrnr_tune[1]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
