{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/atanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_2D_4(xt): #True function for 2D_4 Heat Transfer in a rod x \\in [0,1] t \\in [0,0.1]\n",
    "    term1 = 4*u0/np.pi\n",
    "    \n",
    "    resol_n = 10000\n",
    "    \n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "\n",
    "    u = np.zeros((np.shape(xt)[0],1))\n",
    "    \n",
    "    for i in range(resol_n):\n",
    "        j = 2*i-1\n",
    "        term2 = np.sin(j*np.pi*x)/j\n",
    "        term3 = np.exp(-1*np.square(j*np.pi)*t)\n",
    "        \n",
    "        u = u + term2*term3\n",
    "        \n",
    "    u = term1*u\n",
    "    \n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = 50.0\n",
    "loss_thresh = 0.1\n",
    "\n",
    "x_ll = np.array(0.0)\n",
    "x_ul = np.array(1.0)\n",
    "\n",
    "x = np.linspace(x_ll,x_ul,100).reshape(-1,1)\n",
    "t = np.linspace(0,0.1,100).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "u_true = true_2D_4(xt)\n",
    "u_true_norm = np.linalg.norm(u_true,2)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_f,N_train,seed):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    #X_Train\n",
    "    np.random.seed(seed)\n",
    "    x_train = np.random.uniform(x_ll,x_ul,(N_train,1))\n",
    "    t_train = np.random.uniform(0,0.1,(N_train,1))\n",
    "    \n",
    "    xt_train = np.hstack((x_train,t_train))\n",
    "    u_train = true_2D_4(xt_train)\n",
    "    \n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_train, u_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "        \n",
    "\n",
    "        self.lambda1 = Parameter(torch.tensor(0.0))\n",
    "        self.lambda1.requiresGrad = True\n",
    "        \n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = (xt - lbxt)/(ubxt - lbxt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) \n",
    "            \n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    \n",
    "    def loss_PDE(self, xt_coll,f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_t = autograd.grad(u,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_tt = autograd.grad(u_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_tt[:,[0]]\n",
    "                \n",
    "        du_dt = u_x_t[:,[1]]\n",
    "        \n",
    "        f = du_dt - self.lambda1*d2u_dx2\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_coll,f_hat, xt_train, u_train):\n",
    "\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_train = self.loss_function(self.forward(xt_train),u_train)\n",
    "        \n",
    "        loss_val = loss_f + loss_train\n",
    "        \n",
    "        #print(self.iter,\"train_loss\",loss_train.cpu().detach().numpy(),\"F Loss\",(loss_f).cpu().detach().numpy())\n",
    "        return loss_val\n",
    "     \n",
    "    'callable for optimizer'                                    \n",
    "    \n",
    "    def test(self):\n",
    "        u_pred = self.forward(xt_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "               \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xt_coll,f_hat, xt_train, u_train,seed):    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_coll,f_hat, xt_train, u_train)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    lambda1_val.append(PINN.lambda1.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "    \n",
    "    xt_coll, xt_train, u_train = trainingdata(N_f,N_train,123)\n",
    "    \n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_train = torch.from_numpy(xt_train).float().to(device)\n",
    "    u_train = torch.from_numpy(u_train).float().to(device)\n",
    "    \n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    nan_flag = 0\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        train_step(xt_coll,f_hat, xt_train, u_train,i)\n",
    "\n",
    "        loss_np = PINN.loss(xt_coll,f_hat, xt_train, u_train).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1],\"Lambda1\",lambda1_val[-1])\n",
    "\n",
    "        if(np.isnan(loss_np)):\n",
    "            nan_flag =1\n",
    "            print(\"NAN BREAK!\")\n",
    "            break\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_HT_tanh_tune0\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 864.9692 Test MSE 867.2630784375818 Test RE 0.49575214220650465 Lambda1 -0.061118077\n",
      "1 Train Loss 854.7452 Test MSE 858.0515976082977 Test RE 0.4931123422669899 Lambda1 -0.064031824\n",
      "2 Train Loss 854.72455 Test MSE 858.0641975195732 Test RE 0.49311596276543657 Lambda1 -0.06412847\n",
      "3 Train Loss 854.72296 Test MSE 858.0688300233674 Test RE 0.4931172938770782 Lambda1 -0.06414687\n",
      "4 Train Loss 854.7226 Test MSE 858.0704154080778 Test RE 0.493117749423434 Lambda1 -0.064153135\n",
      "5 Train Loss 854.722 Test MSE 858.0735710435405 Test RE 0.4931186561662833 Lambda1 -0.064164825\n",
      "6 Train Loss 854.722 Test MSE 858.0743162903171 Test RE 0.49311887030585233 Lambda1 -0.06416777\n",
      "7 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "8 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "9 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "10 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "11 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "12 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "13 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "14 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "15 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "16 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "17 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "18 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "19 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "20 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "21 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "22 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "23 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "24 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "25 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "26 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "27 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "28 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "29 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "30 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "31 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "32 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "33 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "34 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "35 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "36 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "37 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "38 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "39 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "40 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "41 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "42 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "43 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "44 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "45 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "46 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "47 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "48 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "49 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "50 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "51 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "52 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "53 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "54 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "55 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "56 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "57 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "58 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "59 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "60 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "61 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "62 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "63 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "64 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "65 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "66 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "67 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "68 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "69 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "70 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "71 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "72 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "73 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "74 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.4931189469445027 Lambda1 -0.06416873\n",
      "Training time: 95.51\n",
      "Training time: 95.51\n",
      "inv_HT_tanh_tune0\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 871.29895 Test MSE 873.3036358629704 Test RE 0.4974756232341131 Lambda1 -0.07345898\n",
      "1 Train Loss 854.73676 Test MSE 858.0515528836796 Test RE 0.4931123294156291 Lambda1 -0.07824003\n",
      "2 Train Loss 854.72125 Test MSE 858.0686669510102 Test RE 0.4931172470196465 Lambda1 -0.0783584\n",
      "3 Train Loss 854.7207 Test MSE 858.0719054710615 Test RE 0.4931181775795462 Lambda1 -0.07837215\n",
      "4 Train Loss 854.7206 Test MSE 858.0727547985153 Test RE 0.4931184216259367 Lambda1 -0.07837553\n",
      "5 Train Loss 854.7206 Test MSE 858.0734960746935 Test RE 0.49311863462469346 Lambda1 -0.07837848\n",
      "6 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "7 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "8 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "9 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "10 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "11 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "12 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "13 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "14 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "15 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "16 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "17 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "18 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "19 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "20 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "21 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "22 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "23 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "24 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "25 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "26 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "27 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "28 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "29 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "30 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "31 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "32 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "33 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "34 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "35 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "36 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "37 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "38 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "39 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "40 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "41 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "42 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "43 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "44 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "45 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "46 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "47 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "48 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "49 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "50 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "51 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "52 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "53 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "54 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "55 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "56 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "57 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "58 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "59 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "60 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "61 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "62 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "63 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "64 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "65 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "66 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "67 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "68 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "69 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "70 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "71 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "72 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "73 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "74 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "Training time: 94.21\n",
      "Training time: 94.21\n",
      "inv_HT_tanh_tune0\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 986.329 Test MSE 985.874994155171 Test RE 0.5285670619581786 Lambda1 -0.16944893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Train Loss 854.743 Test MSE 858.0489291773008 Test RE 0.49311157550815765 Lambda1 -0.20422046\n",
      "2 Train Loss 854.7198 Test MSE 858.0649491413108 Test RE 0.49311617873796904 Lambda1 -0.20456733\n",
      "3 Train Loss 854.71857 Test MSE 858.069059369714 Test RE 0.4931173597777603 Lambda1 -0.20461935\n",
      "4 Train Loss 854.7178 Test MSE 858.0724074718803 Test RE 0.4931183218248543 Lambda1 -0.20466124\n",
      "5 Train Loss 854.6151 Test MSE 857.9992040046138 Test RE 0.49309728703773026 Lambda1 -0.20773268\n",
      "6 Train Loss 853.9165 Test MSE 856.6911869548809 Test RE 0.4927212810574673 Lambda1 -0.3012978\n",
      "7 Train Loss 846.1438 Test MSE 849.1348073438112 Test RE 0.4905434627640393 Lambda1 -0.40877977\n",
      "8 Train Loss 838.1612 Test MSE 839.5329370397657 Test RE 0.4877620870416766 Lambda1 -0.5716223\n",
      "9 Train Loss 827.2542 Test MSE 825.9948688300084 Test RE 0.4838133472719104 Lambda1 -0.49048388\n",
      "10 Train Loss 820.034 Test MSE 819.986604781849 Test RE 0.4820505132022647 Lambda1 -0.4896545\n",
      "11 Train Loss 808.2378 Test MSE 808.9742965587199 Test RE 0.4788026353927891 Lambda1 -0.48995578\n",
      "12 Train Loss 800.67694 Test MSE 800.8602834463316 Test RE 0.47639538852035335 Lambda1 -0.49453077\n",
      "13 Train Loss 789.28424 Test MSE 792.1244203874339 Test RE 0.47378998005355355 Lambda1 -0.57638955\n",
      "14 Train Loss 784.43756 Test MSE 786.4809418143435 Test RE 0.4720992083916488 Lambda1 -0.68585783\n",
      "15 Train Loss 777.30133 Test MSE 776.5930859913354 Test RE 0.4691221407861454 Lambda1 -0.80801326\n",
      "16 Train Loss 767.89954 Test MSE 758.3009006935687 Test RE 0.46356427207960765 Lambda1 -0.94519156\n",
      "17 Train Loss 759.6332 Test MSE 753.5938670641497 Test RE 0.46212328124633795 Lambda1 -0.9424591\n",
      "18 Train Loss 746.5012 Test MSE 746.134890009032 Test RE 0.45983057493065155 Lambda1 -0.9977052\n",
      "19 Train Loss 731.1354 Test MSE 733.806012505144 Test RE 0.45601570889854876 Lambda1 -1.0494226\n",
      "20 Train Loss 717.7616 Test MSE 718.5771906000978 Test RE 0.45125900803619734 Lambda1 -1.1079932\n",
      "21 Train Loss 708.9161 Test MSE 709.8898157938581 Test RE 0.4485229227362741 Lambda1 -1.1973488\n",
      "22 Train Loss 702.4577 Test MSE 702.6583348366238 Test RE 0.4462325761224155 Lambda1 -1.241236\n",
      "23 Train Loss 685.38916 Test MSE 683.4312373332875 Test RE 0.4400850172022756 Lambda1 -1.3001264\n",
      "24 Train Loss 673.2361 Test MSE 673.1520692760525 Test RE 0.43676292239797193 Lambda1 -1.4018389\n",
      "25 Train Loss 667.0369 Test MSE 666.961462526274 Test RE 0.4347499503149262 Lambda1 -1.4001321\n",
      "26 Train Loss 662.75366 Test MSE 660.5577415998661 Test RE 0.4326578262887741 Lambda1 -1.4377838\n",
      "27 Train Loss 655.9118 Test MSE 655.4746610099957 Test RE 0.4309899313654838 Lambda1 -1.4856229\n",
      "28 Train Loss 644.004 Test MSE 651.6633690707671 Test RE 0.4297350978045135 Lambda1 -1.5283515\n",
      "29 Train Loss 638.4995 Test MSE 646.9079407706903 Test RE 0.42816425894237975 Lambda1 -1.5583163\n",
      "30 Train Loss 634.19495 Test MSE 642.2058972129829 Test RE 0.426605367375004 Lambda1 -1.6031978\n",
      "31 Train Loss 632.2628 Test MSE 641.0478754323581 Test RE 0.4262205677235095 Lambda1 -1.6144161\n",
      "32 Train Loss 630.06506 Test MSE 637.2918700005241 Test RE 0.42497008496783073 Lambda1 -1.6420094\n",
      "33 Train Loss 626.7794 Test MSE 634.2184239646921 Test RE 0.4239441020221256 Lambda1 -1.673108\n",
      "34 Train Loss 625.16864 Test MSE 634.021936762535 Test RE 0.4238784258764238 Lambda1 -1.6702212\n",
      "35 Train Loss 623.71893 Test MSE 633.5416705361174 Test RE 0.42371785331075673 Lambda1 -1.678134\n",
      "36 Train Loss 621.9171 Test MSE 632.8602064502363 Test RE 0.4234899076188562 Lambda1 -1.6889063\n",
      "37 Train Loss 621.44635 Test MSE 632.8717268363979 Test RE 0.4234937621391901 Lambda1 -1.6851516\n",
      "38 Train Loss 620.14185 Test MSE 632.5294454311614 Test RE 0.4233792257818604 Lambda1 -1.6796582\n",
      "39 Train Loss 618.3239 Test MSE 630.4547303914758 Test RE 0.4226843073677772 Lambda1 -1.6990231\n",
      "40 Train Loss 616.8132 Test MSE 628.4691866808556 Test RE 0.42201818499877713 Lambda1 -1.7255164\n",
      "41 Train Loss 616.4646 Test MSE 628.2467674611796 Test RE 0.4219435009381213 Lambda1 -1.7273834\n",
      "42 Train Loss 615.68146 Test MSE 627.9338986851482 Test RE 0.4218384232892293 Lambda1 -1.7277085\n",
      "43 Train Loss 614.6719 Test MSE 627.0177954876985 Test RE 0.4215305974330509 Lambda1 -1.7416936\n",
      "44 Train Loss 614.341 Test MSE 627.1646739064086 Test RE 0.421579966145269 Lambda1 -1.7341632\n",
      "45 Train Loss 613.4434 Test MSE 627.4318879451137 Test RE 0.42166976719219074 Lambda1 -1.7144656\n",
      "46 Train Loss 612.41724 Test MSE 628.2064194859876 Test RE 0.4219299514539523 Lambda1 -1.6996815\n",
      "47 Train Loss 611.73267 Test MSE 627.8852761368778 Test RE 0.42182209095217194 Lambda1 -1.7051371\n",
      "48 Train Loss 610.9484 Test MSE 627.0844287637494 Test RE 0.42155299489822373 Lambda1 -1.7137454\n",
      "49 Train Loss 610.7404 Test MSE 627.2078542707872 Test RE 0.4215944788115467 Lambda1 -1.7062478\n",
      "50 Train Loss 610.3393 Test MSE 627.1063882312518 Test RE 0.4215603758806138 Lambda1 -1.7002066\n",
      "51 Train Loss 609.76825 Test MSE 626.7577136548082 Test RE 0.4214431646502757 Lambda1 -1.7015487\n",
      "52 Train Loss 609.44696 Test MSE 626.6034405385057 Test RE 0.42139129344841364 Lambda1 -1.7051551\n",
      "53 Train Loss 608.8669 Test MSE 626.1629813838839 Test RE 0.4212431628530956 Lambda1 -1.7121116\n",
      "54 Train Loss 608.4996 Test MSE 625.73915797309 Test RE 0.42110057782338745 Lambda1 -1.7130865\n",
      "55 Train Loss 608.3201 Test MSE 625.4671026515198 Test RE 0.4210090260109541 Lambda1 -1.7131695\n",
      "56 Train Loss 608.1597 Test MSE 625.4403482722836 Test RE 0.4210000215760675 Lambda1 -1.7074473\n",
      "57 Train Loss 607.9447 Test MSE 625.2877571806744 Test RE 0.4209486619445795 Lambda1 -1.6998405\n",
      "58 Train Loss 607.5842 Test MSE 624.7998924746256 Test RE 0.4207844127118204 Lambda1 -1.6943141\n",
      "59 Train Loss 607.1381 Test MSE 624.6995335928611 Test RE 0.4207506169721351 Lambda1 -1.6818995\n",
      "60 Train Loss 606.0088 Test MSE 624.2187904540936 Test RE 0.42058868960418516 Lambda1 -1.6294631\n",
      "61 Train Loss 605.1975 Test MSE 624.3303072920272 Test RE 0.42062625706197737 Lambda1 -1.5931525\n",
      "62 Train Loss 604.8676 Test MSE 624.1476388131256 Test RE 0.4205647184992525 Lambda1 -1.5759503\n",
      "63 Train Loss 604.5347 Test MSE 624.160660935708 Test RE 0.4205691057759254 Lambda1 -1.5473197\n",
      "64 Train Loss 604.38635 Test MSE 623.9491786602085 Test RE 0.4204978497256842 Lambda1 -1.5392842\n",
      "65 Train Loss 604.2551 Test MSE 623.6366180636317 Test RE 0.4203925146061494 Lambda1 -1.5427706\n",
      "66 Train Loss 604.1781 Test MSE 623.61054492356 Test RE 0.42038372658186746 Lambda1 -1.5520681\n",
      "67 Train Loss 604.13184 Test MSE 623.6187872477708 Test RE 0.42038650469999483 Lambda1 -1.5566317\n",
      "68 Train Loss 603.9961 Test MSE 623.3380387548151 Test RE 0.4202918666243697 Lambda1 -1.5693891\n",
      "69 Train Loss 603.8889 Test MSE 623.1453507994354 Test RE 0.42022690071906266 Lambda1 -1.5762246\n",
      "70 Train Loss 603.7663 Test MSE 623.1319678714849 Test RE 0.42022238821124763 Lambda1 -1.5778062\n",
      "71 Train Loss 603.67145 Test MSE 622.9957478016538 Test RE 0.42017645423999156 Lambda1 -1.5799738\n",
      "72 Train Loss 603.6338 Test MSE 622.8459536033636 Test RE 0.42012593721870267 Lambda1 -1.5789855\n",
      "73 Train Loss 603.56335 Test MSE 622.7099685180772 Test RE 0.42008007196121894 Lambda1 -1.5754119\n",
      "74 Train Loss 603.5068 Test MSE 622.6126645778961 Test RE 0.42004725006565574 Lambda1 -1.5731106\n",
      "Training time: 141.80\n",
      "Training time: 141.80\n",
      "inv_HT_tanh_tune0\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 917.9278 Test MSE 918.6440177455344 Test RE 0.5102262475566711 Lambda1 -0.04750236\n",
      "1 Train Loss 854.75055 Test MSE 858.0498991391536 Test RE 0.493111854221449 Lambda1 -0.05382655\n",
      "2 Train Loss 854.7214 Test MSE 858.0669600665213 Test RE 0.4931167565608808 Lambda1 -0.053936683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Train Loss 854.7206 Test MSE 858.0707456696383 Test RE 0.4931178443211365 Lambda1 -0.05394729\n",
      "4 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "5 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "6 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "7 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "8 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "9 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "10 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "11 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "12 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "13 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "14 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "15 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "16 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "17 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "18 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "19 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "20 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "21 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "22 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "23 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "24 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "25 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "26 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "27 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "28 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "29 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "30 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "31 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "32 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "33 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "34 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "35 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "36 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "37 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "38 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "39 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "40 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "41 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "42 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "43 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "44 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "45 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "46 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "47 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "48 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "49 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "50 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "51 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "52 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "53 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "54 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "55 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "56 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "57 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "58 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "59 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "60 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "61 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "62 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "63 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "64 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "65 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "66 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "67 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "68 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "69 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "70 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "71 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "72 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "73 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "74 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.4931181050885074 Lambda1 -0.053949777\n",
      "Training time: 181.35\n",
      "Training time: 181.35\n",
      "inv_HT_tanh_tune0\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 887.261 Test MSE 888.7233605281776 Test RE 0.5018483130428719 Lambda1 -0.055308588\n",
      "1 Train Loss 854.7608 Test MSE 858.0516336352415 Test RE 0.49311235261912406 Lambda1 -0.060398422\n",
      "2 Train Loss 854.7232 Test MSE 858.064453300856 Test RE 0.4931160362621659 Lambda1 -0.06053708\n",
      "3 Train Loss 854.7212 Test MSE 858.0718819684839 Test RE 0.4931181708262961 Lambda1 -0.0605623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 854.7212 Test MSE 858.0727298888664 Test RE 0.49311841446838106 Lambda1 -0.06056479\n",
      "5 Train Loss 854.721 Test MSE 858.0735049384131 Test RE 0.4931186371715995 Lambda1 -0.06056691\n",
      "6 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "7 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "8 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "9 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "10 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "11 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "12 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "13 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "14 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "15 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "16 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "17 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "18 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "19 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "20 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "21 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "22 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "23 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "24 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "25 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "26 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "27 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "28 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "29 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "30 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "31 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "32 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "33 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "34 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "35 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "36 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "37 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "38 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "39 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "40 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "41 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "42 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "43 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "44 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "45 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "46 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "47 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "48 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "49 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "50 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "51 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "52 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "53 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "54 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "55 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "56 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "57 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "58 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "59 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "60 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "61 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "62 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "63 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "64 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "65 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "66 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "67 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "68 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "69 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "70 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "71 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "72 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "73 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "74 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.49311875766525853 Lambda1 -0.060568072\n",
      "Training time: 158.81\n",
      "Training time: 158.81\n",
      "inv_HT_tanh_tune0\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 1617.2461 Test MSE 1611.430323851346 Test RE 0.6757638206327687 Lambda1 -0.004962055\n",
      "1 Train Loss 854.74286 Test MSE 858.0472671626154 Test RE 0.4931110979368625 Lambda1 -0.009778857\n",
      "2 Train Loss 854.71765 Test MSE 858.0630735534819 Test RE 0.4931156398025368 Lambda1 -0.009798538\n",
      "3 Train Loss 854.71484 Test MSE 858.0715857460137 Test RE 0.4931180857094788 Lambda1 -0.009805831\n",
      "4 Train Loss 854.7069 Test MSE 858.0882672958396 Test RE 0.4931228789773565 Lambda1 -0.00984145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Train Loss 854.5593 Test MSE 857.605964676293 Test RE 0.4929842755874478 Lambda1 -0.01126781\n",
      "6 Train Loss 854.5206 Test MSE 857.6668894376643 Test RE 0.49300178620256796 Lambda1 -0.03042694\n",
      "7 Train Loss 854.34827 Test MSE 857.6732064767123 Test RE 0.49300360177096525 Lambda1 -0.6050727\n",
      "8 Train Loss 853.36084 Test MSE 855.0818064433017 Test RE 0.49225825026470543 Lambda1 -1.0872748\n",
      "9 Train Loss 847.3179 Test MSE 847.9624053142682 Test RE 0.49020469864860683 Lambda1 -1.0254208\n",
      "10 Train Loss 844.2757 Test MSE 841.7496938859288 Test RE 0.4884056217312272 Lambda1 -1.0729787\n",
      "11 Train Loss 833.08075 Test MSE 834.2600860085398 Test RE 0.48622793169935824 Lambda1 -1.1400706\n",
      "12 Train Loss 822.0457 Test MSE 821.1093931618373 Test RE 0.48238043052123586 Lambda1 -1.0483912\n",
      "13 Train Loss 804.98303 Test MSE 803.2182555490705 Test RE 0.47709619827554073 Lambda1 -1.1122309\n",
      "14 Train Loss 790.8389 Test MSE 792.2711349526143 Test RE 0.47383385489867313 Lambda1 -1.1632926\n",
      "15 Train Loss 779.25385 Test MSE 780.5036567806975 Test RE 0.47030180082808126 Lambda1 -1.0045487\n",
      "16 Train Loss 771.62524 Test MSE 773.5170743346857 Test RE 0.468192144783122 Lambda1 -1.0763049\n",
      "17 Train Loss 766.7449 Test MSE 767.2874433742177 Test RE 0.46630300711032757 Lambda1 -1.1455791\n",
      "18 Train Loss 755.175 Test MSE 757.0519886877123 Test RE 0.4631823725182962 Lambda1 -1.2674751\n",
      "19 Train Loss 747.9855 Test MSE 747.0023091757025 Test RE 0.46009778532478385 Lambda1 -1.3001293\n",
      "20 Train Loss 745.013 Test MSE 741.0725264150108 Test RE 0.45826799455827383 Lambda1 -1.2622354\n",
      "21 Train Loss 741.33624 Test MSE 739.5811706699342 Test RE 0.4578066464631723 Lambda1 -1.2611662\n",
      "22 Train Loss 737.1529 Test MSE 738.1578226734212 Test RE 0.45736590242044695 Lambda1 -1.2737378\n",
      "23 Train Loss 732.1811 Test MSE 733.0511162149985 Test RE 0.45578108752640356 Lambda1 -1.200205\n",
      "24 Train Loss 719.86206 Test MSE 719.3561823446826 Test RE 0.45150354114112395 Lambda1 -1.1774188\n",
      "25 Train Loss 715.42694 Test MSE 716.9513688548287 Test RE 0.4507482193704767 Lambda1 -1.217444\n",
      "26 Train Loss 713.92255 Test MSE 715.6855659017662 Test RE 0.4503501376387285 Lambda1 -1.2522404\n",
      "27 Train Loss 706.57263 Test MSE 704.4292760400162 Test RE 0.44679455220384945 Lambda1 -1.2494602\n",
      "28 Train Loss 704.58264 Test MSE 700.7090966696472 Test RE 0.4456132013856192 Lambda1 -1.2366508\n",
      "29 Train Loss 698.8892 Test MSE 696.1944414813083 Test RE 0.444175342990766 Lambda1 -1.3189163\n",
      "30 Train Loss 695.70465 Test MSE 698.1475257155353 Test RE 0.44479794512358084 Lambda1 -1.3615152\n",
      "31 Train Loss 694.51965 Test MSE 696.7860000796968 Test RE 0.4443640115115788 Lambda1 -1.3558695\n",
      "32 Train Loss 689.5006 Test MSE 692.4498388043305 Test RE 0.44297919530006763 Lambda1 -1.3962586\n",
      "33 Train Loss 685.80963 Test MSE 688.3071670953411 Test RE 0.4416521169865309 Lambda1 -1.4070857\n",
      "34 Train Loss 684.59424 Test MSE 684.6243006064901 Test RE 0.44046897706400734 Lambda1 -1.3963566\n",
      "35 Train Loss 681.0957 Test MSE 681.0175720663327 Test RE 0.43930720856729727 Lambda1 -1.4147851\n",
      "36 Train Loss 679.5747 Test MSE 679.8972257234038 Test RE 0.4389457062860273 Lambda1 -1.4271268\n",
      "37 Train Loss 677.1584 Test MSE 678.7949619301122 Test RE 0.4385897479142788 Lambda1 -1.4573675\n",
      "38 Train Loss 676.18713 Test MSE 677.5479637754221 Test RE 0.43818670130100484 Lambda1 -1.4906389\n",
      "39 Train Loss 674.2078 Test MSE 673.656342491146 Test RE 0.4369264861902135 Lambda1 -1.5331287\n",
      "40 Train Loss 672.0934 Test MSE 673.1064007674856 Test RE 0.43674810654098467 Lambda1 -1.5988797\n",
      "41 Train Loss 668.84595 Test MSE 673.455643432227 Test RE 0.4368613956823744 Lambda1 -1.7629079\n",
      "42 Train Loss 667.54724 Test MSE 673.0966266757368 Test RE 0.43674493554784277 Lambda1 -1.8337003\n",
      "43 Train Loss 664.90814 Test MSE 669.77636359937 Test RE 0.4356664122498538 Lambda1 -1.9178514\n",
      "44 Train Loss 662.62 Test MSE 666.1462473083966 Test RE 0.4344841754835798 Lambda1 -1.9215149\n",
      "45 Train Loss 661.3187 Test MSE 664.293789467994 Test RE 0.4338796356000291 Lambda1 -1.8859845\n",
      "46 Train Loss 658.21655 Test MSE 659.7656708395612 Test RE 0.43239834980055397 Lambda1 -1.8591247\n",
      "47 Train Loss 656.62354 Test MSE 660.2200863468257 Test RE 0.43254723197401823 Lambda1 -1.8299835\n",
      "48 Train Loss 655.8187 Test MSE 660.0621888968669 Test RE 0.43249550514054275 Lambda1 -1.8420038\n",
      "49 Train Loss 652.7005 Test MSE 656.9715864596536 Test RE 0.4314817824719272 Lambda1 -1.9792182\n",
      "50 Train Loss 651.8909 Test MSE 656.8238731386745 Test RE 0.43143327261904935 Lambda1 -2.0410435\n",
      "51 Train Loss 651.008 Test MSE 655.6707638565885 Test RE 0.4310543976499053 Lambda1 -2.01211\n",
      "52 Train Loss 649.2449 Test MSE 653.9242593710215 Test RE 0.43047991691837767 Lambda1 -1.9717286\n",
      "53 Train Loss 647.31335 Test MSE 652.1292475520685 Test RE 0.4298886806013678 Lambda1 -1.9315928\n",
      "54 Train Loss 646.13544 Test MSE 651.5985159589978 Test RE 0.4297137137947019 Lambda1 -1.9268882\n",
      "55 Train Loss 645.64734 Test MSE 650.963845522321 Test RE 0.4295043877861273 Lambda1 -1.9226445\n",
      "56 Train Loss 645.01056 Test MSE 650.45868894929 Test RE 0.42933770489369105 Lambda1 -1.9161798\n",
      "57 Train Loss 642.08356 Test MSE 649.8486399507739 Test RE 0.42913632509699745 Lambda1 -1.9277767\n",
      "58 Train Loss 640.40173 Test MSE 649.2824273883969 Test RE 0.42894933130032237 Lambda1 -1.9409143\n",
      "59 Train Loss 638.5264 Test MSE 647.5621874321662 Test RE 0.42838071497066676 Lambda1 -1.9667101\n",
      "60 Train Loss 637.55524 Test MSE 646.0069127973493 Test RE 0.4278659766232498 Lambda1 -2.0039985\n",
      "61 Train Loss 637.121 Test MSE 645.224847428488 Test RE 0.42760690780273464 Lambda1 -2.032973\n",
      "62 Train Loss 636.3755 Test MSE 644.6847361049239 Test RE 0.42742789758117855 Lambda1 -2.0453618\n",
      "63 Train Loss 635.7971 Test MSE 644.3338597997235 Test RE 0.4273115657333274 Lambda1 -2.0649054\n",
      "64 Train Loss 635.0206 Test MSE 643.643256263749 Test RE 0.4270825059146214 Lambda1 -2.1210198\n",
      "65 Train Loss 634.5772 Test MSE 642.8865373751815 Test RE 0.4268313757726824 Lambda1 -2.1695302\n",
      "66 Train Loss 634.1089 Test MSE 642.4760647168965 Test RE 0.4266950915497244 Lambda1 -2.2218888\n",
      "67 Train Loss 633.79535 Test MSE 642.3401535033665 Test RE 0.4266499570161662 Lambda1 -2.246289\n",
      "68 Train Loss 633.4617 Test MSE 642.0235659630484 Test RE 0.4265448034562209 Lambda1 -2.2886882\n",
      "69 Train Loss 632.8683 Test MSE 641.4836550994097 Test RE 0.42636541392693417 Lambda1 -2.3139136\n",
      "70 Train Loss 632.34576 Test MSE 641.297651503202 Test RE 0.4263035953214898 Lambda1 -2.3127632\n",
      "71 Train Loss 632.13544 Test MSE 640.9046725402311 Test RE 0.426172958621762 Lambda1 -2.3389027\n",
      "72 Train Loss 631.8541 Test MSE 640.289427922454 Test RE 0.4259683544222612 Lambda1 -2.4030447\n",
      "73 Train Loss 631.11884 Test MSE 639.6307544951625 Test RE 0.42574919866371247 Lambda1 -2.522584\n",
      "74 Train Loss 630.9023 Test MSE 639.4919630293095 Test RE 0.4257030051678884 Lambda1 -2.5746815\n",
      "Training time: 228.75\n",
      "Training time: 228.75\n",
      "inv_HT_tanh_tune0\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 994.21375 Test MSE 993.6475893418625 Test RE 0.5306465710749012 Lambda1 -0.010616232\n",
      "1 Train Loss 854.73785 Test MSE 858.0522664747089 Test RE 0.4931125344618529 Lambda1 -0.013407396\n",
      "2 Train Loss 854.72235 Test MSE 858.0685751958923 Test RE 0.4931172206546049 Lambda1 -0.013429513\n",
      "3 Train Loss 854.722 Test MSE 858.0700913720956 Test RE 0.49311765631457816 Lambda1 -0.013430776\n",
      "4 Train Loss 854.7217 Test MSE 858.0714582838507 Test RE 0.4931180490843876 Lambda1 -0.013431786\n",
      "5 Train Loss 854.72156 Test MSE 858.0725116919758 Test RE 0.49311835177153274 Lambda1 -0.01343253\n",
      "6 Train Loss 854.7212 Test MSE 858.0737438333681 Test RE 0.4931187058158041 Lambda1 -0.013433391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Train Loss 854.7212 Test MSE 858.0749774942888 Test RE 0.49311906029644315 Lambda1 -0.013434086\n",
      "8 Train Loss 854.721 Test MSE 858.0759245687145 Test RE 0.4931193324290272 Lambda1 -0.013434595\n",
      "9 Train Loss 854.7209 Test MSE 858.076728298875 Test RE 0.49311956337291923 Lambda1 -0.013434994\n",
      "10 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "11 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "12 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "13 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "14 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "15 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "16 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "17 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "18 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "19 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "20 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "21 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "22 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "23 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "24 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "25 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "26 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "27 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "28 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "29 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "30 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "31 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "32 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "33 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "34 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "35 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "36 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "37 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "38 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "39 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "40 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "41 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "42 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "43 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "44 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "45 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "46 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "47 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "48 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "49 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "50 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "51 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "52 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "53 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "54 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "55 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "56 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "57 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "58 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "59 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "60 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "61 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "62 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "63 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "64 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "65 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "66 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "67 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "68 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "69 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "70 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "71 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "72 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "73 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "74 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511133 Lambda1 -0.01343537\n",
      "Training time: 176.39\n",
      "Training time: 176.39\n",
      "inv_HT_tanh_tune0\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 1215.711 Test MSE 1212.757519545453 Test RE 0.5862409597926166 Lambda1 -0.12137388\n",
      "1 Train Loss 854.79 Test MSE 858.0600831086658 Test RE 0.49311478052048685 Lambda1 -0.17385224\n",
      "2 Train Loss 854.7206 Test MSE 858.068462648555 Test RE 0.49311718831509627 Lambda1 -0.17448814\n",
      "3 Train Loss 854.7196 Test MSE 858.072351281943 Test RE 0.4931183056791959 Lambda1 -0.17452917\n",
      "4 Train Loss 854.7192 Test MSE 858.0739042755365 Test RE 0.4931187519173375 Lambda1 -0.17454654\n",
      "5 Train Loss 854.7165 Test MSE 858.0849690182384 Test RE 0.4931219312556761 Lambda1 -0.17467555\n",
      "6 Train Loss 854.49976 Test MSE 857.7826544501664 Test RE 0.49303505694725747 Lambda1 -0.17090853\n",
      "7 Train Loss 854.19696 Test MSE 857.3631625168987 Test RE 0.49291448472493254 Lambda1 -0.20380409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 851.7523 Test MSE 854.1288936485564 Test RE 0.4919838847355173 Lambda1 -0.34896958\n",
      "9 Train Loss 844.9795 Test MSE 846.9479118746411 Test RE 0.4899113729771211 Lambda1 -0.4908115\n",
      "10 Train Loss 839.40656 Test MSE 841.2402365082471 Test RE 0.48825779898208105 Lambda1 -0.66516155\n",
      "11 Train Loss 832.54535 Test MSE 831.8588231417215 Test RE 0.48552766899947153 Lambda1 -0.855953\n",
      "12 Train Loss 823.54736 Test MSE 825.6414941993311 Test RE 0.4837098444179829 Lambda1 -0.79927486\n",
      "13 Train Loss 808.71826 Test MSE 810.687090016981 Test RE 0.47930923764336436 Lambda1 -0.70477533\n",
      "14 Train Loss 799.9319 Test MSE 802.1124775410227 Test RE 0.4767676797334283 Lambda1 -0.6060579\n",
      "15 Train Loss 782.2531 Test MSE 779.6511214576774 Test RE 0.47004487797959366 Lambda1 -0.46562496\n",
      "16 Train Loss 773.10474 Test MSE 774.9298278601954 Test RE 0.4686195033939489 Lambda1 -0.48706505\n",
      "17 Train Loss 767.06085 Test MSE 770.2691400992019 Test RE 0.467208160728317 Lambda1 -0.5301925\n",
      "18 Train Loss 757.92786 Test MSE 759.2756906825839 Test RE 0.46386213054395603 Lambda1 -0.5081124\n",
      "19 Train Loss 748.5891 Test MSE 750.6908809700882 Test RE 0.4612323292519405 Lambda1 -0.42092112\n",
      "20 Train Loss 730.837 Test MSE 728.7876158700817 Test RE 0.45445371995050715 Lambda1 -0.42465648\n",
      "21 Train Loss 714.38586 Test MSE 717.2395066605685 Test RE 0.4508387865706423 Lambda1 -0.3748022\n",
      "22 Train Loss 701.02637 Test MSE 700.6847482649781 Test RE 0.44560545918214234 Lambda1 -0.38344032\n",
      "23 Train Loss 690.3048 Test MSE 688.7535891630976 Test RE 0.4417953170736864 Lambda1 -0.4045541\n",
      "24 Train Loss 678.6778 Test MSE 679.1949464810962 Test RE 0.438718949880729 Lambda1 -0.43504834\n",
      "25 Train Loss 663.7598 Test MSE 672.061992488794 Test RE 0.4364091405054239 Lambda1 -0.5239611\n",
      "26 Train Loss 657.2302 Test MSE 666.048646740309 Test RE 0.4344523450440067 Lambda1 -0.5468411\n",
      "27 Train Loss 652.9964 Test MSE 660.603495792197 Test RE 0.43267281026774124 Lambda1 -0.56895965\n",
      "28 Train Loss 647.91223 Test MSE 654.6546420875525 Test RE 0.4307202561788499 Lambda1 -0.60783905\n",
      "29 Train Loss 639.4543 Test MSE 650.4128640357334 Test RE 0.42932258117401817 Lambda1 -0.6304064\n",
      "30 Train Loss 634.9685 Test MSE 649.1727273253998 Test RE 0.4289130930206186 Lambda1 -0.6253346\n",
      "31 Train Loss 627.0797 Test MSE 638.2292231532083 Test RE 0.4252825012242631 Lambda1 -0.62116694\n",
      "32 Train Loss 622.41736 Test MSE 632.0859747472975 Test RE 0.4232307827354628 Lambda1 -0.633092\n",
      "33 Train Loss 619.19586 Test MSE 628.1061700621239 Test RE 0.4218962842381624 Lambda1 -0.6164733\n",
      "34 Train Loss 615.2246 Test MSE 625.6104271549779 Test RE 0.42105725992525256 Lambda1 -0.5866823\n",
      "35 Train Loss 612.3419 Test MSE 624.3895319684135 Test RE 0.4206462071292004 Lambda1 -0.57663566\n",
      "36 Train Loss 610.4512 Test MSE 624.5173523600166 Test RE 0.4206892607109366 Lambda1 -0.5688688\n",
      "37 Train Loss 609.1285 Test MSE 622.5385704525837 Test RE 0.4200222554250391 Lambda1 -0.5702307\n",
      "38 Train Loss 607.49554 Test MSE 620.6323433798145 Test RE 0.4193787036190229 Lambda1 -0.5939802\n",
      "39 Train Loss 606.87366 Test MSE 620.5203529560246 Test RE 0.4193408643747747 Lambda1 -0.61098933\n",
      "40 Train Loss 605.6593 Test MSE 620.6093525037185 Test RE 0.4193709357567685 Lambda1 -0.63234633\n",
      "41 Train Loss 604.4909 Test MSE 620.4805364862501 Test RE 0.41932741039166094 Lambda1 -0.6540956\n",
      "42 Train Loss 603.473 Test MSE 620.5910257574242 Test RE 0.41936474364779297 Lambda1 -0.6895599\n",
      "43 Train Loss 602.8736 Test MSE 620.8660834552883 Test RE 0.41945766855141453 Lambda1 -0.7127545\n",
      "44 Train Loss 602.63336 Test MSE 620.7060060415296 Test RE 0.4194035908451739 Lambda1 -0.7280133\n",
      "45 Train Loss 602.4726 Test MSE 620.5897743258156 Test RE 0.41936432081976416 Lambda1 -0.73433024\n",
      "46 Train Loss 602.1938 Test MSE 620.3538144373853 Test RE 0.41928458814433395 Lambda1 -0.7445321\n",
      "47 Train Loss 601.9314 Test MSE 620.2203124913234 Test RE 0.4192394700850873 Lambda1 -0.7651766\n",
      "48 Train Loss 601.7073 Test MSE 620.315094245131 Test RE 0.4192715028429938 Lambda1 -0.7934515\n",
      "49 Train Loss 601.491 Test MSE 620.1091015724106 Test RE 0.41920188175076156 Lambda1 -0.82873166\n",
      "50 Train Loss 601.289 Test MSE 619.6888709498659 Test RE 0.4190598169735014 Lambda1 -0.8606361\n",
      "51 Train Loss 600.96954 Test MSE 619.4032010325404 Test RE 0.418963214800508 Lambda1 -0.91595566\n",
      "52 Train Loss 600.5697 Test MSE 618.7774413893081 Test RE 0.41875152997224785 Lambda1 -0.97746646\n",
      "53 Train Loss 599.99713 Test MSE 617.3712023810531 Test RE 0.41827543013222923 Lambda1 -1.0544437\n",
      "54 Train Loss 598.945 Test MSE 614.6576349136543 Test RE 0.4173551826805996 Lambda1 -1.1817812\n",
      "55 Train Loss 598.2924 Test MSE 612.7130416495934 Test RE 0.41669446608631155 Lambda1 -1.2479728\n",
      "56 Train Loss 595.4213 Test MSE 600.5534944677049 Test RE 0.41253900788321113 Lambda1 -1.3953793\n",
      "57 Train Loss 582.6515 Test MSE 583.9659304656357 Test RE 0.4068018561329012 Lambda1 -1.4472445\n",
      "58 Train Loss 575.45856 Test MSE 571.6706359601656 Test RE 0.4024965046119804 Lambda1 -1.4592468\n",
      "59 Train Loss 540.4763 Test MSE 539.9390084369398 Test RE 0.39116638181335955 Lambda1 -1.4717196\n",
      "60 Train Loss 528.66876 Test MSE 525.3723251351406 Test RE 0.3858537865839574 Lambda1 -1.4903271\n",
      "61 Train Loss 513.19666 Test MSE 509.22516787100926 Test RE 0.3798779630862816 Lambda1 -1.547141\n",
      "62 Train Loss 499.19318 Test MSE 500.6962359296718 Test RE 0.37668327174061295 Lambda1 -1.5293058\n",
      "63 Train Loss 485.92288 Test MSE 487.30300997587665 Test RE 0.3716111340033309 Lambda1 -1.4535612\n",
      "64 Train Loss 461.10266 Test MSE 450.3895857788314 Test RE 0.35725913352618555 Lambda1 -1.4112148\n",
      "65 Train Loss 436.45624 Test MSE 418.21528788195894 Test RE 0.3442620280424258 Lambda1 -1.3692726\n",
      "66 Train Loss 416.21466 Test MSE 394.55740100280104 Test RE 0.3343830599644708 Lambda1 -1.4517075\n",
      "67 Train Loss 395.33328 Test MSE 361.3968142177887 Test RE 0.32002310201682554 Lambda1 -1.4560066\n",
      "68 Train Loss 374.23456 Test MSE 340.94694461906226 Test RE 0.3108369021598767 Lambda1 -1.3792982\n",
      "69 Train Loss 364.2919 Test MSE 333.85047603503966 Test RE 0.3075850128489757 Lambda1 -1.2892205\n",
      "70 Train Loss 353.0301 Test MSE 337.9240407546317 Test RE 0.3094558631021051 Lambda1 -1.2070408\n",
      "71 Train Loss 335.71277 Test MSE 315.40880485507495 Test RE 0.2989689437063335 Lambda1 -1.2260349\n",
      "72 Train Loss 320.43176 Test MSE 308.6050670503116 Test RE 0.2957268088640502 Lambda1 -1.2235329\n",
      "73 Train Loss 315.2716 Test MSE 306.6461304057946 Test RE 0.2947867200617545 Lambda1 -1.2193662\n",
      "74 Train Loss 308.8374 Test MSE 302.49336636744414 Test RE 0.29278383710552813 Lambda1 -1.2188872\n",
      "Training time: 208.67\n",
      "Training time: 208.67\n",
      "inv_HT_tanh_tune0\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 870.203 Test MSE 872.2530915070676 Test RE 0.4971763129751257 Lambda1 -0.0057098474\n",
      "1 Train Loss 854.77057 Test MSE 858.0542791538973 Test RE 0.4931131127930295 Lambda1 -0.005316264\n",
      "2 Train Loss 854.72296 Test MSE 858.0679085289763 Test RE 0.49311702909357463 Lambda1 -0.0052955016\n",
      "3 Train Loss 854.7226 Test MSE 858.0694682756903 Test RE 0.49311747727332156 Lambda1 -0.0052946596\n",
      "4 Train Loss 854.722 Test MSE 858.0726145836574 Test RE 0.49311838133650215 Lambda1 -0.0052926065\n",
      "5 Train Loss 854.72186 Test MSE 858.0735529963958 Test RE 0.4931186509806069 Lambda1 -0.005291946\n",
      "6 Train Loss 854.7218 Test MSE 858.0743965005988 Test RE 0.49311889335350784 Lambda1 -0.005291203\n",
      "7 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "8 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "10 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "11 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "12 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "13 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "14 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "15 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "16 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "17 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "18 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "19 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "20 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "21 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "22 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "23 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "24 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "25 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "26 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "27 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "28 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "29 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "30 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "31 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "32 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "33 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "34 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "35 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "36 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "37 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "38 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "39 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "40 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "41 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "42 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "43 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "44 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "45 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "46 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "47 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "48 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "49 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "50 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "51 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "52 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "53 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "54 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "55 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "56 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "57 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "58 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "59 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "60 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "61 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "62 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "63 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "64 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "65 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "66 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "67 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "68 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "69 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "70 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "71 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "72 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "73 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "74 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.493119066827407 Lambda1 -0.005290434\n",
      "Training time: 202.40\n",
      "Training time: 202.40\n",
      "inv_HT_tanh_tune0\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 929.144 Test MSE 929.6353981434457 Test RE 0.5132695458170614 Lambda1 -0.013554936\n",
      "1 Train Loss 854.7696 Test MSE 858.0533922547871 Test RE 0.49311285794802456 Lambda1 -0.015710806\n",
      "2 Train Loss 854.72235 Test MSE 858.0654673886484 Test RE 0.4931163276521675 Lambda1 -0.015756082\n",
      "3 Train Loss 854.7212 Test MSE 858.0697799273028 Test RE 0.4931175668236719 Lambda1 -0.01576039\n",
      "4 Train Loss 854.7206 Test MSE 858.0730935253756 Test RE 0.4931185189559342 Lambda1 -0.015763469\n",
      "5 Train Loss 854.7204 Test MSE 858.0742907136824 Test RE 0.49311886295665114 Lambda1 -0.015764585\n",
      "6 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "7 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "8 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "9 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "11 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "12 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "13 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "14 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "15 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "16 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "17 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "18 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "19 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "20 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "21 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "22 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "23 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "24 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "25 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "26 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "27 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "28 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "29 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "30 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "31 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "32 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "33 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "34 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "35 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "36 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "37 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "38 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "39 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "40 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "41 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "42 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "43 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "44 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "45 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "46 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "47 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "48 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "49 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "50 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "51 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "52 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "53 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "54 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "55 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "56 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "57 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "58 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "59 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "60 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "61 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "62 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "63 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "64 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "65 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "66 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "67 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "68 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "69 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "70 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "71 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "72 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "73 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "74 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351945 Lambda1 -0.015765209\n",
      "Training time: 193.47\n",
      "Training time: 193.47\n",
      "inv_HT_tanh_tune1\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 947.34717 Test MSE 947.5073595174223 Test RE 0.5181797851394339 Lambda1 -0.04849267\n",
      "1 Train Loss 864.514 Test MSE 866.8314982982606 Test RE 0.49562877514025727 Lambda1 -0.053787056\n",
      "2 Train Loss 855.84357 Test MSE 858.8487677406853 Test RE 0.49334135132300916 Lambda1 -0.05530907\n",
      "3 Train Loss 854.8556 Test MSE 858.0909603185535 Test RE 0.4931236527847388 Lambda1 -0.055811785\n",
      "4 Train Loss 854.73755 Test MSE 858.0522522484407 Test RE 0.49311253037401853 Lambda1 -0.05598427\n",
      "5 Train Loss 854.7214 Test MSE 858.0733734996065 Test RE 0.4931185994038983 Lambda1 -0.056064498\n",
      "6 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "7 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "8 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "9 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "10 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "12 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "13 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "14 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "15 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "16 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "17 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "18 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "19 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "20 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "21 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "22 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "23 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "24 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "25 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "26 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "27 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "28 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "29 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "30 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "31 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "32 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "33 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "34 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "35 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "36 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "37 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "38 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "39 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "40 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "41 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "42 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "43 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "44 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "45 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "46 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "47 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "48 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "49 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "50 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "51 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "52 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "53 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "54 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "55 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "56 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "57 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "58 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "59 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "60 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "61 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "62 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "63 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "64 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "65 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "66 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "67 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "68 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "69 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "70 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "71 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "72 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "73 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "74 Train Loss 854.7212 Test MSE 858.0748571101707 Test RE 0.49311902570523203 Lambda1 -0.056067802\n",
      "Training time: 186.33\n",
      "Training time: 186.33\n",
      "inv_HT_tanh_tune1\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 1008.253 Test MSE 1007.4943712913185 Test RE 0.5343311399236775 Lambda1 -0.06589482\n",
      "1 Train Loss 869.82526 Test MSE 871.8917220172509 Test RE 0.4970733136480649 Lambda1 -0.07539746\n",
      "2 Train Loss 856.5249 Test MSE 859.4362028088698 Test RE 0.4935100402021365 Lambda1 -0.07805164\n",
      "3 Train Loss 854.9394 Test MSE 858.1416408572819 Test RE 0.4931382149958176 Lambda1 -0.0789539\n",
      "4 Train Loss 854.72296 Test MSE 858.0660366640233 Test RE 0.49311649122880963 Lambda1 -0.07938855\n",
      "5 Train Loss 854.7212 Test MSE 858.0754455617054 Test RE 0.4931191947910614 Lambda1 -0.07942317\n",
      "6 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "7 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "8 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "9 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "10 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "12 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "13 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "14 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "15 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "16 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "17 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "18 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "19 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "20 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "21 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "22 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "23 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "24 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "25 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "26 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "27 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "28 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "29 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "30 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "31 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "32 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "33 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "34 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "35 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "36 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "37 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "38 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "39 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "40 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "41 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "42 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "43 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "44 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "45 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "46 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "47 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "48 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "49 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "50 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "51 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "52 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "53 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "54 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "55 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "56 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "57 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "58 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "59 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "60 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "61 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "62 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "63 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "64 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "65 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "66 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "67 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "68 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "69 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "70 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "71 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "72 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "73 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "74 Train Loss 854.721 Test MSE 858.0760360101864 Test RE 0.49311936445063564 Lambda1 -0.07942533\n",
      "Training time: 219.99\n",
      "Training time: 219.99\n",
      "inv_HT_tanh_tune1\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 1125.7422 Test MSE 1123.6311400011318 Test RE 0.5642883107486463 Lambda1 -0.15652639\n",
      "1 Train Loss 854.7214 Test MSE 858.085630941898 Test RE 0.49312212145188167 Lambda1 -0.20752992\n",
      "2 Train Loss 854.72076 Test MSE 858.0791235018436 Test RE 0.49312025161010065 Lambda1 -0.20747662\n",
      "3 Train Loss 854.72046 Test MSE 858.0765861482259 Test RE 0.4931195225273476 Lambda1 -0.2074549\n",
      "4 Train Loss 854.7192 Test MSE 858.0662175762519 Test RE 0.49311654321245346 Lambda1 -0.20736371\n",
      "5 Train Loss 854.6793 Test MSE 857.9543468716837 Test RE 0.49308439703762474 Lambda1 -0.2075436\n",
      "6 Train Loss 854.26904 Test MSE 857.4480932895761 Test RE 0.4929388982833733 Lambda1 -0.22728977\n",
      "7 Train Loss 852.9637 Test MSE 854.1583774144269 Test RE 0.4919923760841885 Lambda1 -0.3387061\n",
      "8 Train Loss 849.16016 Test MSE 851.8868129596588 Test RE 0.49133773377826745 Lambda1 -0.37261644\n",
      "9 Train Loss 834.04065 Test MSE 835.2937231483219 Test RE 0.4865290534238095 Lambda1 -0.5915895\n",
      "10 Train Loss 822.97595 Test MSE 824.3670381211647 Test RE 0.48333637419317677 Lambda1 -0.5538484\n",
      "11 Train Loss 806.35504 Test MSE 810.6975864093996 Test RE 0.47931234056780064 Lambda1 -0.6452425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 791.27 Test MSE 794.7809911227279 Test RE 0.4745837966755958 Lambda1 -0.7069036\n",
      "13 Train Loss 769.21497 Test MSE 772.6739050037622 Test RE 0.4679368996777939 Lambda1 -0.8072376\n",
      "14 Train Loss 754.3715 Test MSE 754.8850652886754 Test RE 0.4625190099097414 Lambda1 -0.83742476\n",
      "15 Train Loss 746.489 Test MSE 741.8512813930477 Test RE 0.4585087164594656 Lambda1 -0.8908044\n",
      "16 Train Loss 739.27094 Test MSE 739.4304072740321 Test RE 0.45775998221235426 Lambda1 -0.9090943\n",
      "17 Train Loss 729.9098 Test MSE 736.5570321451951 Test RE 0.45686970475658617 Lambda1 -0.90899616\n",
      "18 Train Loss 714.4671 Test MSE 722.2989259795945 Test RE 0.4524261043693907 Lambda1 -0.899548\n",
      "19 Train Loss 707.2326 Test MSE 712.2024622741417 Test RE 0.4492529173862274 Lambda1 -0.91276574\n",
      "20 Train Loss 700.808 Test MSE 700.6528743447226 Test RE 0.4455953238435075 Lambda1 -0.928216\n",
      "21 Train Loss 695.0875 Test MSE 701.8527035963526 Test RE 0.44597668930609874 Lambda1 -0.9115493\n",
      "22 Train Loss 690.7589 Test MSE 697.1945420343981 Test RE 0.444494262936804 Lambda1 -0.91505694\n",
      "23 Train Loss 688.8301 Test MSE 692.853212615939 Test RE 0.44310820117273325 Lambda1 -0.9225029\n",
      "24 Train Loss 685.2041 Test MSE 685.5969330153248 Test RE 0.44078174886438726 Lambda1 -0.911138\n",
      "25 Train Loss 682.2768 Test MSE 682.7315519624606 Test RE 0.4398596837063115 Lambda1 -0.904512\n",
      "26 Train Loss 678.88556 Test MSE 678.4297633149351 Test RE 0.4384717491613835 Lambda1 -0.8996116\n",
      "27 Train Loss 673.75543 Test MSE 675.4594782925436 Test RE 0.4375108429719426 Lambda1 -0.89250314\n",
      "28 Train Loss 670.42236 Test MSE 672.4126228566101 Test RE 0.43652296805858676 Lambda1 -0.89434314\n",
      "29 Train Loss 665.9271 Test MSE 671.7348063636906 Test RE 0.4363028970338033 Lambda1 -0.8613318\n",
      "30 Train Loss 663.3473 Test MSE 670.6400314807386 Test RE 0.4359472148331291 Lambda1 -0.8430268\n",
      "31 Train Loss 656.82324 Test MSE 662.3243750918905 Test RE 0.4332360024168866 Lambda1 -0.7801629\n",
      "32 Train Loss 646.54596 Test MSE 647.7881279000379 Test RE 0.42845544146019404 Lambda1 -0.72177535\n",
      "33 Train Loss 633.7005 Test MSE 631.511811029046 Test RE 0.42303851540268833 Lambda1 -0.6840557\n",
      "34 Train Loss 607.9019 Test MSE 606.2249071786446 Test RE 0.41448236609422623 Lambda1 -0.64527786\n",
      "35 Train Loss 599.4436 Test MSE 595.9276743307089 Test RE 0.41094712617387713 Lambda1 -0.6449618\n",
      "36 Train Loss 591.39716 Test MSE 585.0782707829848 Test RE 0.40718911059865154 Lambda1 -0.6368449\n",
      "37 Train Loss 583.16113 Test MSE 578.9282670124921 Test RE 0.40504338906085174 Lambda1 -0.63067687\n",
      "38 Train Loss 568.0618 Test MSE 556.4648065763519 Test RE 0.3971074383014024 Lambda1 -0.65048367\n",
      "39 Train Loss 554.9919 Test MSE 541.2957125288144 Test RE 0.39165751513605834 Lambda1 -0.6727363\n",
      "40 Train Loss 544.6607 Test MSE 531.7764451526175 Test RE 0.38819838017164715 Lambda1 -0.65960777\n",
      "41 Train Loss 534.2169 Test MSE 519.2423059647908 Test RE 0.3835961199076486 Lambda1 -0.6387244\n",
      "42 Train Loss 521.2465 Test MSE 504.68622762537103 Test RE 0.3781811667256179 Lambda1 -0.6319541\n",
      "43 Train Loss 508.41495 Test MSE 488.6570132901022 Test RE 0.37212704880773106 Lambda1 -0.6286609\n",
      "44 Train Loss 488.71606 Test MSE 463.4557648291877 Test RE 0.3624042774012534 Lambda1 -0.6066373\n",
      "45 Train Loss 457.4207 Test MSE 434.1809785779893 Test RE 0.35077171587162154 Lambda1 -0.5577395\n",
      "46 Train Loss 442.60645 Test MSE 418.01086902185807 Test RE 0.34417788208345496 Lambda1 -0.56202334\n",
      "47 Train Loss 435.87195 Test MSE 406.243222623852 Test RE 0.3392987307028116 Lambda1 -0.56556386\n",
      "48 Train Loss 422.87598 Test MSE 382.62441000616343 Test RE 0.3292876988185957 Lambda1 -0.55929196\n",
      "49 Train Loss 407.9829 Test MSE 373.43596765959126 Test RE 0.3253098722290125 Lambda1 -0.5291185\n",
      "50 Train Loss 384.36835 Test MSE 359.3808531254569 Test RE 0.3191292696385165 Lambda1 -0.50120336\n",
      "51 Train Loss 377.06403 Test MSE 345.51346096265155 Test RE 0.31291159517694045 Lambda1 -0.4929135\n",
      "52 Train Loss 370.55554 Test MSE 333.5736674896738 Test RE 0.307457470997018 Lambda1 -0.46684995\n",
      "53 Train Loss 363.12265 Test MSE 322.2162135121711 Test RE 0.30217801605822814 Lambda1 -0.44491762\n",
      "54 Train Loss 343.65143 Test MSE 311.03886341370287 Test RE 0.2968906351131509 Lambda1 -0.43033114\n",
      "55 Train Loss 330.86417 Test MSE 300.7090401405197 Test RE 0.2919190337340177 Lambda1 -0.39321798\n",
      "56 Train Loss 320.12988 Test MSE 291.7033697509021 Test RE 0.28751459378691396 Lambda1 -0.396935\n",
      "57 Train Loss 310.47726 Test MSE 286.0309779372899 Test RE 0.28470540107046105 Lambda1 -0.41045833\n",
      "58 Train Loss 304.32336 Test MSE 279.7804419876276 Test RE 0.2815774337932987 Lambda1 -0.4231294\n",
      "59 Train Loss 301.54953 Test MSE 279.8480319763226 Test RE 0.28161144379437897 Lambda1 -0.42864057\n",
      "60 Train Loss 297.83002 Test MSE 276.1696509649361 Test RE 0.2797545419013857 Lambda1 -0.43980637\n",
      "61 Train Loss 293.136 Test MSE 270.941777859418 Test RE 0.277094023459236 Lambda1 -0.45093098\n",
      "62 Train Loss 291.8521 Test MSE 267.89079869318914 Test RE 0.2755294778316589 Lambda1 -0.44968128\n",
      "63 Train Loss 289.75366 Test MSE 266.68404479620904 Test RE 0.2749081956465409 Lambda1 -0.4478826\n",
      "64 Train Loss 281.86276 Test MSE 263.8273304181009 Test RE 0.2734318256273684 Lambda1 -0.45744014\n",
      "65 Train Loss 279.48315 Test MSE 260.5649311174109 Test RE 0.2717359841536181 Lambda1 -0.46092796\n",
      "66 Train Loss 277.4927 Test MSE 257.1081361606904 Test RE 0.26992746785184 Lambda1 -0.45981666\n",
      "67 Train Loss 272.3228 Test MSE 253.97670078312157 Test RE 0.26827864815705793 Lambda1 -0.47020516\n",
      "68 Train Loss 270.9646 Test MSE 252.8328633435957 Test RE 0.26767384178808334 Lambda1 -0.47554502\n",
      "69 Train Loss 270.37808 Test MSE 251.9597979313532 Test RE 0.2672112854860565 Lambda1 -0.47438103\n",
      "70 Train Loss 268.849 Test MSE 249.28495237374278 Test RE 0.2657891220404484 Lambda1 -0.4747485\n",
      "71 Train Loss 264.52695 Test MSE 246.00780358830806 Test RE 0.2640362842793555 Lambda1 -0.4827099\n",
      "72 Train Loss 258.452 Test MSE 244.32904493519422 Test RE 0.2631338495348872 Lambda1 -0.4930751\n",
      "73 Train Loss 255.29922 Test MSE 241.54101417700858 Test RE 0.26162823620054093 Lambda1 -0.50629735\n",
      "74 Train Loss 253.8778 Test MSE 239.12882567450396 Test RE 0.2603185617757442 Lambda1 -0.5156213\n",
      "Training time: 319.60\n",
      "Training time: 319.60\n",
      "inv_HT_tanh_tune1\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 1043.138 Test MSE 1041.9354349511136 Test RE 0.543387413579671 Lambda1 -0.040052935\n",
      "1 Train Loss 872.28107 Test MSE 874.2462168825392 Test RE 0.4977440205027924 Lambda1 -0.046859905\n",
      "2 Train Loss 856.7337 Test MSE 859.6194731496787 Test RE 0.4935626566335287 Lambda1 -0.04857118\n",
      "3 Train Loss 854.9588 Test MSE 858.1536654708738 Test RE 0.4931416700057063 Lambda1 -0.049123295\n",
      "4 Train Loss 854.74866 Test MSE 858.0495839224735 Test RE 0.49311176364565845 Lambda1 -0.04930988\n",
      "5 Train Loss 854.7198 Test MSE 858.0747658985791 Test RE 0.4931189994964625 Lambda1 -0.049404655\n",
      "6 Train Loss 854.7198 Test MSE 858.0759308901478 Test RE 0.4931193342454288 Lambda1 -0.049406856\n",
      "7 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "8 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "9 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "10 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "11 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "12 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "14 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "15 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "16 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "17 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "18 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "19 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "20 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "21 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "22 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "23 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "24 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "25 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "26 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "27 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "28 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "29 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "30 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "31 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "32 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "33 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "34 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "35 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "36 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "37 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "38 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "39 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "40 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "41 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "42 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "43 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "44 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "45 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "46 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "47 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "48 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "49 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "50 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "51 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "52 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "53 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "54 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "55 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "56 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "57 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "58 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "59 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "60 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "61 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "62 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "63 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "64 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "65 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "66 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "67 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "68 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "69 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "70 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "71 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "72 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "73 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "74 Train Loss 854.71967 Test MSE 858.0765335007287 Test RE 0.4931195073996135 Lambda1 -0.04940813\n",
      "Training time: 235.92\n",
      "Training time: 235.92\n",
      "inv_HT_tanh_tune1\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 903.12256 Test MSE 904.1687913545346 Test RE 0.5061904262835576 Lambda1 -0.06320093\n",
      "1 Train Loss 859.3186 Test MSE 861.9636079281237 Test RE 0.49423515751626823 Lambda1 -0.067042276\n",
      "2 Train Loss 855.2676 Test MSE 858.3792561342036 Test RE 0.4932064840656383 Lambda1 -0.06816232\n",
      "3 Train Loss 854.7868 Test MSE 858.058847849014 Test RE 0.49311442557738727 Lambda1 -0.06854251\n",
      "4 Train Loss 854.721 Test MSE 858.0748290236237 Test RE 0.4931190176348343 Lambda1 -0.06873455\n",
      "5 Train Loss 854.72076 Test MSE 858.0760212729147 Test RE 0.4931193602160261 Lambda1 -0.068737395\n",
      "6 Train Loss 854.72076 Test MSE 858.0767173015523 Test RE 0.4931195602129484 Lambda1 -0.06873891\n",
      "7 Train Loss 854.72076 Test MSE 858.0773169443427 Test RE 0.49311973251428887 Lambda1 -0.0687401\n",
      "8 Train Loss 854.72076 Test MSE 858.0779540991107 Test RE 0.49311991559425405 Lambda1 -0.06874108\n",
      "9 Train Loss 854.72076 Test MSE 858.0786505449953 Test RE 0.49312011571084274 Lambda1 -0.06874191\n",
      "10 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "11 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "12 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "13 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "15 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "16 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "17 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "18 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "19 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "20 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "21 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "22 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "23 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "24 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "25 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "26 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "27 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "28 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "29 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "30 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "31 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "32 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "33 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "34 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "35 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "36 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "37 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "38 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "39 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "40 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "41 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "42 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "43 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "44 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "45 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "46 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "47 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "48 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "49 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "50 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "51 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "52 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "53 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "54 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "55 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "56 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "57 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "58 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "59 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "60 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "61 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "62 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "63 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "64 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "65 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "66 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "67 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "68 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "69 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "70 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "71 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "72 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "73 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "74 Train Loss 854.7206 Test MSE 858.0790663467111 Test RE 0.4931202351871665 Lambda1 -0.068742365\n",
      "Training time: 212.66\n",
      "Training time: 212.66\n",
      "inv_HT_tanh_tune1\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 1252.8375 Test MSE 1249.5652253552678 Test RE 0.5950707943249175 Lambda1 0.0056813187\n",
      "1 Train Loss 888.8661 Test MSE 890.2813188252392 Test RE 0.5022879978888706 Lambda1 0.00820773\n",
      "2 Train Loss 858.7753 Test MSE 861.4627092725514 Test RE 0.49409153329624567 Lambda1 0.0089033265\n",
      "3 Train Loss 854.7112 Test MSE 858.0467462544545 Test RE 0.49311094825651036 Lambda1 0.009231314\n",
      "4 Train Loss 854.70386 Test MSE 858.0627482681267 Test RE 0.4931155463342847 Lambda1 0.009227889\n",
      "5 Train Loss 854.53754 Test MSE 857.7251958426725 Test RE 0.49301854368361586 Lambda1 0.0010133539\n",
      "6 Train Loss 854.52356 Test MSE 857.6729416354179 Test RE 0.49300352565355765 Lambda1 -0.009094491\n",
      "7 Train Loss 854.48724 Test MSE 857.6135504569484 Test RE 0.49298645587913514 Lambda1 -0.22853838\n",
      "8 Train Loss 851.76086 Test MSE 854.1655335354658 Test RE 0.4919944370307953 Lambda1 -1.282822\n",
      "9 Train Loss 839.8612 Test MSE 839.261862682241 Test RE 0.48768333464062363 Lambda1 -1.0413646\n",
      "10 Train Loss 830.10657 Test MSE 823.221340729259 Test RE 0.48300038929012823 Lambda1 -1.1361681\n",
      "11 Train Loss 821.70874 Test MSE 807.5998346211157 Test RE 0.47839571531650626 Lambda1 -1.2134902\n",
      "12 Train Loss 811.5157 Test MSE 799.5762617771026 Test RE 0.4760133322508083 Lambda1 -1.3873394\n",
      "13 Train Loss 791.2552 Test MSE 791.9611040153557 Test RE 0.4737411356754313 Lambda1 -1.5148379\n",
      "14 Train Loss 773.1983 Test MSE 774.7393952238348 Test RE 0.46856192016029785 Lambda1 -1.4800391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Train Loss 757.21844 Test MSE 762.7397529096784 Test RE 0.4649190712137467 Lambda1 -1.5333858\n",
      "16 Train Loss 735.21625 Test MSE 737.1808783366724 Test RE 0.4570631426628837 Lambda1 -1.4335583\n",
      "17 Train Loss 721.6652 Test MSE 724.5680660322797 Test RE 0.45313620729746906 Lambda1 -1.4440577\n",
      "18 Train Loss 717.68506 Test MSE 718.0318163913929 Test RE 0.45108773086403675 Lambda1 -1.472376\n",
      "19 Train Loss 710.3857 Test MSE 708.9740488254441 Test RE 0.44823352921396026 Lambda1 -1.4956928\n",
      "20 Train Loss 702.1558 Test MSE 703.9179276035335 Test RE 0.4466323576585895 Lambda1 -1.5475113\n",
      "21 Train Loss 690.13605 Test MSE 692.3936159509957 Test RE 0.4429612112826713 Lambda1 -1.5572107\n",
      "22 Train Loss 683.2707 Test MSE 686.291033924739 Test RE 0.4410048169687703 Lambda1 -1.5924108\n",
      "23 Train Loss 681.36835 Test MSE 683.5155564005512 Test RE 0.44011216434719996 Lambda1 -1.5980897\n",
      "24 Train Loss 680.4868 Test MSE 681.9427221452212 Test RE 0.4396055027514075 Lambda1 -1.5815499\n",
      "25 Train Loss 677.27637 Test MSE 680.4589249605697 Test RE 0.4391269870420973 Lambda1 -1.519205\n",
      "26 Train Loss 675.7628 Test MSE 678.7563576818085 Test RE 0.43857727605663527 Lambda1 -1.5106053\n",
      "27 Train Loss 674.679 Test MSE 679.1115110439504 Test RE 0.4386920019243294 Lambda1 -1.4654233\n",
      "28 Train Loss 672.5287 Test MSE 676.5672443005595 Test RE 0.4378694589257069 Lambda1 -1.4074067\n",
      "29 Train Loss 670.28406 Test MSE 674.6912265780088 Test RE 0.437261964916529 Lambda1 -1.3713988\n",
      "30 Train Loss 668.8334 Test MSE 673.6176196126349 Test RE 0.43691392838193904 Lambda1 -1.3477085\n",
      "31 Train Loss 667.56995 Test MSE 673.2911752390087 Test RE 0.436808048299828 Lambda1 -1.3648751\n",
      "32 Train Loss 666.65594 Test MSE 671.9771934804982 Test RE 0.43638160716015456 Lambda1 -1.3757879\n",
      "33 Train Loss 663.56793 Test MSE 668.8631836532744 Test RE 0.43536931492721725 Lambda1 -1.3857441\n",
      "34 Train Loss 662.20764 Test MSE 667.409123737779 Test RE 0.4348958268417112 Lambda1 -1.3897732\n",
      "35 Train Loss 661.5837 Test MSE 666.2025836650789 Test RE 0.43450254737870797 Lambda1 -1.3816102\n",
      "36 Train Loss 660.6977 Test MSE 663.737310094269 Test RE 0.4336978668874615 Lambda1 -1.3860484\n",
      "37 Train Loss 659.76587 Test MSE 663.4645562928828 Test RE 0.4336087466171055 Lambda1 -1.3978796\n",
      "38 Train Loss 658.4734 Test MSE 661.9071135482536 Test RE 0.4330995124956253 Lambda1 -1.389778\n",
      "39 Train Loss 656.8458 Test MSE 660.8346150973366 Test RE 0.4327484912889522 Lambda1 -1.3530833\n",
      "40 Train Loss 655.32996 Test MSE 659.2140782134816 Test RE 0.4322175601479786 Lambda1 -1.3234978\n",
      "41 Train Loss 654.00696 Test MSE 659.3769324326843 Test RE 0.43227094501103225 Lambda1 -1.3216709\n",
      "42 Train Loss 653.0322 Test MSE 660.664497428089 Test RE 0.4326927868044336 Lambda1 -1.3044463\n",
      "43 Train Loss 652.29596 Test MSE 660.8358159374066 Test RE 0.4327488844746909 Lambda1 -1.2985195\n",
      "44 Train Loss 651.29584 Test MSE 660.8725842310006 Test RE 0.43276092318107967 Lambda1 -1.3058089\n",
      "45 Train Loss 648.5217 Test MSE 658.508712032041 Test RE 0.43198625952980163 Lambda1 -1.315334\n",
      "46 Train Loss 646.06366 Test MSE 655.1135637350138 Test RE 0.4308712000561374 Lambda1 -1.314887\n",
      "47 Train Loss 644.43835 Test MSE 654.2619533150969 Test RE 0.4305910549408702 Lambda1 -1.3240377\n",
      "48 Train Loss 643.59467 Test MSE 653.4586688266622 Test RE 0.43032663994134984 Lambda1 -1.3392864\n",
      "49 Train Loss 643.07965 Test MSE 651.8772008100054 Test RE 0.42980559698466797 Lambda1 -1.3499318\n",
      "50 Train Loss 642.48474 Test MSE 650.9294607334098 Test RE 0.42949304413560113 Lambda1 -1.3513434\n",
      "51 Train Loss 641.3721 Test MSE 648.6939369358195 Test RE 0.42875489371757 Lambda1 -1.372042\n",
      "52 Train Loss 639.6676 Test MSE 647.0896897830783 Test RE 0.42822440116763877 Lambda1 -1.3968056\n",
      "53 Train Loss 638.7862 Test MSE 645.903715435116 Test RE 0.4278318002059155 Lambda1 -1.3983555\n",
      "54 Train Loss 637.8932 Test MSE 644.7820915303448 Test RE 0.4274601698311601 Lambda1 -1.4168131\n",
      "55 Train Loss 636.11163 Test MSE 643.5112403023431 Test RE 0.42703870478842193 Lambda1 -1.4774563\n",
      "56 Train Loss 634.8664 Test MSE 642.2207125493783 Test RE 0.4266102881220744 Lambda1 -1.5608299\n",
      "57 Train Loss 633.2239 Test MSE 639.9810035401541 Test RE 0.42586574859602294 Lambda1 -1.6223181\n",
      "58 Train Loss 629.9889 Test MSE 638.3670251193604 Test RE 0.42532841074992583 Lambda1 -1.6927829\n",
      "59 Train Loss 628.3499 Test MSE 636.1151524544028 Test RE 0.42457756402966196 Lambda1 -1.7594596\n",
      "60 Train Loss 625.9182 Test MSE 633.6117439886877 Test RE 0.4237412855120729 Lambda1 -1.8189344\n",
      "61 Train Loss 625.2158 Test MSE 633.1167725321043 Test RE 0.4235757418483123 Lambda1 -1.832905\n",
      "62 Train Loss 624.3353 Test MSE 630.9126557344282 Test RE 0.42283778604957056 Lambda1 -1.886197\n",
      "63 Train Loss 623.57166 Test MSE 629.5677350498086 Test RE 0.4223868625584492 Lambda1 -1.9128684\n",
      "64 Train Loss 623.1414 Test MSE 628.4615095683411 Test RE 0.42201560739350036 Lambda1 -1.9452059\n",
      "65 Train Loss 621.1409 Test MSE 627.0019022759813 Test RE 0.4215252550667477 Lambda1 -2.0262096\n",
      "66 Train Loss 618.6 Test MSE 625.8125711864469 Test RE 0.4211252793619499 Lambda1 -2.1353915\n",
      "67 Train Loss 614.9691 Test MSE 622.4366276239554 Test RE 0.41998786397373794 Lambda1 -2.2839556\n",
      "68 Train Loss 612.7119 Test MSE 621.9798443924643 Test RE 0.41983372890617016 Lambda1 -2.3519483\n",
      "69 Train Loss 610.53644 Test MSE 622.0232719187256 Test RE 0.4198483853473803 Lambda1 -2.403019\n",
      "70 Train Loss 608.8588 Test MSE 621.6625263888924 Test RE 0.4197266210973915 Lambda1 -2.4223056\n",
      "71 Train Loss 607.73956 Test MSE 621.500581793169 Test RE 0.419671947635178 Lambda1 -2.3991215\n",
      "72 Train Loss 607.4986 Test MSE 621.8329904277856 Test RE 0.4197841630819434 Lambda1 -2.3751523\n",
      "73 Train Loss 607.3949 Test MSE 621.6450196795798 Test RE 0.4197207110711576 Lambda1 -2.3720348\n",
      "74 Train Loss 606.92993 Test MSE 620.2189359507356 Test RE 0.41923900484680393 Lambda1 -2.3822696\n",
      "Training time: 315.19\n",
      "Training time: 315.19\n",
      "inv_HT_tanh_tune1\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 1170.0033 Test MSE 1167.462144499516 Test RE 0.5751890030771755 Lambda1 -0.025701715\n",
      "1 Train Loss 884.4692 Test MSE 886.014558899004 Test RE 0.5010829202175102 Lambda1 -0.03328906\n",
      "2 Train Loss 858.2071 Test MSE 860.9439611560825 Test RE 0.49394274702458707 Lambda1 -0.035314724\n",
      "3 Train Loss 855.1385 Test MSE 858.2808406020837 Test RE 0.4931782095182313 Lambda1 -0.035979405\n",
      "4 Train Loss 854.7709 Test MSE 858.0533281774123 Test RE 0.49311283953577983 Lambda1 -0.036207177\n",
      "5 Train Loss 854.72015 Test MSE 858.0728086579497 Test RE 0.493118437101943 Lambda1 -0.03632113\n",
      "6 Train Loss 854.72 Test MSE 858.0748587738983 Test RE 0.4931190261832882 Lambda1 -0.036324903\n",
      "7 Train Loss 854.72 Test MSE 858.0762039252676 Test RE 0.49311941269937504 Lambda1 -0.03632732\n",
      "8 Train Loss 854.71967 Test MSE 858.0781960715778 Test RE 0.4931199851225722 Lambda1 -0.03633115\n",
      "9 Train Loss 854.71936 Test MSE 858.0811207105843 Test RE 0.49312082548695935 Lambda1 -0.036337275\n",
      "10 Train Loss 854.7182 Test MSE 858.088978409682 Test RE 0.49312308330740384 Lambda1 -0.03635687\n",
      "11 Train Loss 854.4698 Test MSE 857.5953303311621 Test RE 0.4929812190665053 Lambda1 -0.036905676\n",
      "12 Train Loss 854.3441 Test MSE 857.5064628564721 Test RE 0.49295567605719814 Lambda1 -0.04093133\n",
      "13 Train Loss 853.0919 Test MSE 853.9771168546627 Test RE 0.4919401705755275 Lambda1 -0.0572523\n",
      "14 Train Loss 788.9751 Test MSE 792.216111147316 Test RE 0.4738174005604275 Lambda1 0.034347672\n",
      "15 Train Loss 741.25073 Test MSE 745.9510338006378 Test RE 0.4597739176721198 Lambda1 0.005991993\n",
      "16 Train Loss 684.463 Test MSE 699.3416992344087 Test RE 0.4451781935406196 Lambda1 0.00047138231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 Train Loss 667.8766 Test MSE 685.5726313428529 Test RE 0.44077393681907295 Lambda1 5.9467424e-05\n",
      "18 Train Loss 653.1075 Test MSE 674.4313097754823 Test RE 0.4371777318072454 Lambda1 9.355965e-05\n",
      "19 Train Loss 644.39606 Test MSE 661.7931171352907 Test RE 0.4330622157844953 Lambda1 0.0004003861\n",
      "20 Train Loss 639.344 Test MSE 657.714281958608 Test RE 0.4317256050868782 Lambda1 0.00053118105\n",
      "21 Train Loss 635.1487 Test MSE 653.3269426075954 Test RE 0.43028326446793813 Lambda1 0.00078213395\n",
      "22 Train Loss 630.2464 Test MSE 649.1289250651192 Test RE 0.42889862254221384 Lambda1 -0.00011479037\n",
      "23 Train Loss 627.1841 Test MSE 647.8461176406566 Test RE 0.42847461861304714 Lambda1 9.029649e-05\n",
      "24 Train Loss 623.764 Test MSE 645.668290096733 Test RE 0.42775382292874753 Lambda1 0.00032909753\n",
      "25 Train Loss 617.1231 Test MSE 636.7695016626151 Test RE 0.424795881878309 Lambda1 0.00063767907\n",
      "26 Train Loss 600.38416 Test MSE 610.5679763682674 Test RE 0.4159644175491454 Lambda1 0.0015390489\n",
      "27 Train Loss 580.9577 Test MSE 589.5116702377204 Test RE 0.40872892604221195 Lambda1 0.001730501\n",
      "28 Train Loss 516.6766 Test MSE 520.5713862384889 Test RE 0.3840867426862864 Lambda1 -0.00063169154\n",
      "29 Train Loss 448.5407 Test MSE 431.5098912535693 Test RE 0.3496910750791213 Lambda1 6.022591e-05\n",
      "30 Train Loss 394.64258 Test MSE 385.051831372304 Test RE 0.3303305704070674 Lambda1 0.0001495741\n",
      "31 Train Loss 334.7237 Test MSE 307.67213912874206 Test RE 0.2952794723635811 Lambda1 -0.00073208613\n",
      "32 Train Loss 298.4385 Test MSE 299.3670355736199 Test RE 0.291266917094461 Lambda1 0.00015683194\n",
      "33 Train Loss 289.21176 Test MSE 296.8566368603447 Test RE 0.29004310925396326 Lambda1 -1.8191431e-05\n",
      "34 Train Loss 280.41272 Test MSE 288.64564175653175 Test RE 0.2860037140224252 Lambda1 0.0011618289\n",
      "35 Train Loss 276.6273 Test MSE 284.1244682125574 Test RE 0.28375497757031065 Lambda1 0.002242923\n",
      "36 Train Loss 275.5765 Test MSE 282.6092699066781 Test RE 0.28299735221051514 Lambda1 0.0023510328\n",
      "37 Train Loss 273.12314 Test MSE 280.97718726192437 Test RE 0.28217900708406274 Lambda1 0.00072114007\n",
      "38 Train Loss 272.76837 Test MSE 280.33893671865695 Test RE 0.2818583346138247 Lambda1 0.00075538363\n",
      "39 Train Loss 272.17383 Test MSE 279.8610116782306 Test RE 0.2816179744642321 Lambda1 0.00070060807\n",
      "40 Train Loss 271.51923 Test MSE 278.7611307539763 Test RE 0.2810640366919174 Lambda1 0.00089405023\n",
      "41 Train Loss 270.8256 Test MSE 278.42417933717115 Test RE 0.28089411780656093 Lambda1 0.0010319944\n",
      "42 Train Loss 270.4644 Test MSE 278.2527915714348 Test RE 0.2808076504131016 Lambda1 0.0014497626\n",
      "43 Train Loss 270.36288 Test MSE 278.3668235396768 Test RE 0.2808651840121257 Lambda1 0.0012574154\n",
      "44 Train Loss 270.21378 Test MSE 278.3658913360543 Test RE 0.28086471372662647 Lambda1 0.0012987293\n",
      "45 Train Loss 270.11554 Test MSE 278.30892996110725 Test RE 0.280835975904787 Lambda1 0.001628439\n",
      "46 Train Loss 269.85867 Test MSE 277.6753914296577 Test RE 0.2805161482566609 Lambda1 0.0024511458\n",
      "47 Train Loss 269.29672 Test MSE 276.3465797879561 Test RE 0.27984414029979704 Lambda1 0.004286972\n",
      "48 Train Loss 268.52133 Test MSE 275.2727790668285 Test RE 0.279299915510093 Lambda1 0.0062916875\n",
      "49 Train Loss 267.1573 Test MSE 273.17722061492435 Test RE 0.2782347766630528 Lambda1 0.010763835\n",
      "50 Train Loss 265.36218 Test MSE 271.0521961839462 Test RE 0.2771504804984946 Lambda1 0.016019393\n",
      "51 Train Loss 262.65167 Test MSE 268.06703451120046 Test RE 0.27562009344743016 Lambda1 0.022368645\n",
      "52 Train Loss 257.90085 Test MSE 262.1503890411492 Test RE 0.27256144557049694 Lambda1 0.032821864\n",
      "53 Train Loss 253.26521 Test MSE 257.14620559696425 Test RE 0.2699474508954182 Lambda1 0.04284869\n",
      "54 Train Loss 244.25183 Test MSE 245.88444930737907 Test RE 0.26397007887980506 Lambda1 0.06685435\n",
      "55 Train Loss 237.00433 Test MSE 235.18195556170932 Test RE 0.25816131778355855 Lambda1 0.09427987\n",
      "56 Train Loss 230.67557 Test MSE 227.5723572270256 Test RE 0.25395041369111665 Lambda1 0.11940039\n",
      "57 Train Loss 225.60378 Test MSE 223.5048956759161 Test RE 0.2516707195667183 Lambda1 0.13150121\n",
      "58 Train Loss 218.26045 Test MSE 217.09530666180166 Test RE 0.24803581092982163 Lambda1 0.14437537\n",
      "59 Train Loss 209.32903 Test MSE 206.73520331750456 Test RE 0.24204515197516377 Lambda1 0.16562784\n",
      "60 Train Loss 198.95966 Test MSE 192.87490780812104 Test RE 0.233790595069263 Lambda1 0.1963219\n",
      "61 Train Loss 190.21904 Test MSE 178.13086280552145 Test RE 0.22467707245265647 Lambda1 0.23494928\n",
      "62 Train Loss 177.73529 Test MSE 164.66203820031885 Test RE 0.21601599708114114 Lambda1 0.2527323\n",
      "63 Train Loss 162.16489 Test MSE 142.28737562826421 Test RE 0.20080399795816087 Lambda1 0.30020303\n",
      "64 Train Loss 154.75096 Test MSE 129.94125335147575 Test RE 0.19189457467714352 Lambda1 0.3290909\n",
      "65 Train Loss 149.68997 Test MSE 121.4354575626957 Test RE 0.1855076942396921 Lambda1 0.34914654\n",
      "66 Train Loss 143.8952 Test MSE 115.09188834301031 Test RE 0.18059741449374503 Lambda1 0.3627527\n",
      "67 Train Loss 136.74954 Test MSE 113.05239140535099 Test RE 0.17899011511552648 Lambda1 0.35659182\n",
      "68 Train Loss 129.11452 Test MSE 109.89880599584724 Test RE 0.17647600249584422 Lambda1 0.35258114\n",
      "69 Train Loss 121.34719 Test MSE 108.05023714493622 Test RE 0.17498548792608626 Lambda1 0.35052013\n",
      "70 Train Loss 116.10245 Test MSE 104.35074351838418 Test RE 0.17196376480048392 Lambda1 0.35760954\n",
      "71 Train Loss 110.99599 Test MSE 102.44970535269186 Test RE 0.17039016657261521 Lambda1 0.36546093\n",
      "72 Train Loss 105.89386 Test MSE 101.82672110929856 Test RE 0.16987131562489813 Lambda1 0.36526313\n",
      "73 Train Loss 100.08888 Test MSE 95.13975308103025 Test RE 0.16419887626974322 Lambda1 0.3827145\n",
      "74 Train Loss 95.49794 Test MSE 90.91598984325648 Test RE 0.16051266534731806 Lambda1 0.39079088\n",
      "Training time: 286.62\n",
      "Training time: 286.62\n",
      "inv_HT_tanh_tune1\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 944.02356 Test MSE 944.2420283535192 Test RE 0.5172861303923357 Lambda1 -0.18497603\n",
      "1 Train Loss 864.7176 Test MSE 867.0248286430902 Test RE 0.4956840423635156 Lambda1 -0.20571174\n",
      "2 Train Loss 855.88696 Test MSE 858.885182746371 Test RE 0.49335180999650546 Lambda1 -0.21213052\n",
      "3 Train Loss 854.85266 Test MSE 858.0865604328085 Test RE 0.49312238853035795 Lambda1 -0.2142661\n",
      "4 Train Loss 854.71027 Test MSE 858.069785011485 Test RE 0.49311756828456677 Lambda1 -0.21539715\n",
      "5 Train Loss 854.51764 Test MSE 857.7041617416462 Test RE 0.49301249846920203 Lambda1 -0.2166249\n",
      "6 Train Loss 854.40454 Test MSE 857.5413098318741 Test RE 0.4929656922148293 Lambda1 -0.20970134\n",
      "7 Train Loss 852.6528 Test MSE 855.2604805001264 Test RE 0.4923096776157441 Lambda1 -0.3309523\n",
      "8 Train Loss 846.4162 Test MSE 849.0733782174851 Test RE 0.4905257187020289 Lambda1 -0.35830575\n",
      "9 Train Loss 840.4488 Test MSE 841.7169523934975 Test RE 0.48839612289529766 Lambda1 -0.48052022\n",
      "10 Train Loss 828.8639 Test MSE 831.6375091016046 Test RE 0.4854630779685467 Lambda1 -0.609127\n",
      "11 Train Loss 822.46405 Test MSE 824.4748389331713 Test RE 0.48336797562065204 Lambda1 -0.621087\n",
      "12 Train Loss 816.36255 Test MSE 818.5575790578364 Test RE 0.48163028501256056 Lambda1 -0.6818077\n",
      "13 Train Loss 805.08777 Test MSE 807.6656673259829 Test RE 0.47841521348923405 Lambda1 -0.8543524\n",
      "14 Train Loss 793.646 Test MSE 792.8292824186581 Test RE 0.4740007312312631 Lambda1 -0.98812914\n",
      "15 Train Loss 766.4565 Test MSE 762.2906562733092 Test RE 0.46478218026671836 Lambda1 -0.9855907\n",
      "16 Train Loss 752.8809 Test MSE 755.002759778905 Test RE 0.46255506428409454 Lambda1 -1.0027413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 Train Loss 735.2846 Test MSE 736.7075707602929 Test RE 0.45691639022412595 Lambda1 -1.041368\n",
      "18 Train Loss 717.5692 Test MSE 719.9109305488226 Test RE 0.4516776013037251 Lambda1 -1.0174984\n",
      "19 Train Loss 704.29346 Test MSE 707.3676844905598 Test RE 0.44772544667520325 Lambda1 -1.0379151\n",
      "20 Train Loss 695.1343 Test MSE 692.8171058769088 Test RE 0.44309665514802127 Lambda1 -1.1174809\n",
      "21 Train Loss 683.8917 Test MSE 679.5462931200636 Test RE 0.4388324095729916 Lambda1 -1.0912564\n",
      "22 Train Loss 671.58966 Test MSE 666.9981981789556 Test RE 0.43476192297314326 Lambda1 -1.1021165\n",
      "23 Train Loss 655.6397 Test MSE 657.4759352032188 Test RE 0.431647372240085 Lambda1 -1.050863\n",
      "24 Train Loss 648.51605 Test MSE 654.4903454407608 Test RE 0.4306662045233837 Lambda1 -1.0151676\n",
      "25 Train Loss 639.4373 Test MSE 648.9977391795019 Test RE 0.4288552811607887 Lambda1 -1.0538315\n",
      "26 Train Loss 632.51495 Test MSE 642.5137818567609 Test RE 0.42670761612701164 Lambda1 -1.0794855\n",
      "27 Train Loss 628.0675 Test MSE 637.5349621983954 Test RE 0.42505112873069106 Lambda1 -1.1264364\n",
      "28 Train Loss 623.36676 Test MSE 636.2627541232383 Test RE 0.4246268198301651 Lambda1 -1.1774329\n",
      "29 Train Loss 621.1355 Test MSE 634.4457249436582 Test RE 0.42402006502896694 Lambda1 -1.2048318\n",
      "30 Train Loss 618.59393 Test MSE 633.425173651048 Test RE 0.4236788944847236 Lambda1 -1.2592809\n",
      "31 Train Loss 616.0262 Test MSE 631.2409195704488 Test RE 0.4229477729886357 Lambda1 -1.3086888\n",
      "32 Train Loss 614.8518 Test MSE 630.193510441 Test RE 0.42259673167997763 Lambda1 -1.3266789\n",
      "33 Train Loss 613.2112 Test MSE 629.2236264050173 Test RE 0.4222714128386668 Lambda1 -1.3429011\n",
      "34 Train Loss 612.55786 Test MSE 628.59994968064 Test RE 0.42206208650962773 Lambda1 -1.3663588\n",
      "35 Train Loss 612.0739 Test MSE 628.2218035967807 Test RE 0.42193511773145265 Lambda1 -1.3658055\n",
      "36 Train Loss 611.61383 Test MSE 628.0758941157404 Test RE 0.4218861160024261 Lambda1 -1.3667417\n",
      "37 Train Loss 609.39667 Test MSE 626.8351462494986 Test RE 0.42146919738125177 Lambda1 -1.3988938\n",
      "38 Train Loss 608.7229 Test MSE 626.3525443157753 Test RE 0.4213069210508215 Lambda1 -1.4148332\n",
      "39 Train Loss 608.516 Test MSE 626.1227868058627 Test RE 0.42122964244115285 Lambda1 -1.4175439\n",
      "40 Train Loss 608.339 Test MSE 626.3349406414053 Test RE 0.4213010005815693 Lambda1 -1.4055132\n",
      "41 Train Loss 608.0005 Test MSE 626.1410114509597 Test RE 0.4212357727921306 Lambda1 -1.4231695\n",
      "42 Train Loss 607.8309 Test MSE 626.0723453047478 Test RE 0.4212126746164095 Lambda1 -1.4357587\n",
      "43 Train Loss 607.6181 Test MSE 626.1475818496864 Test RE 0.42123798290109477 Lambda1 -1.4468663\n",
      "44 Train Loss 607.3137 Test MSE 625.987367476816 Test RE 0.4211840877021952 Lambda1 -1.4351193\n",
      "45 Train Loss 606.50806 Test MSE 625.69152531214 Test RE 0.4210845499605585 Lambda1 -1.4219146\n",
      "46 Train Loss 606.29376 Test MSE 625.6798723851657 Test RE 0.42108062878681807 Lambda1 -1.4194208\n",
      "47 Train Loss 606.2541 Test MSE 625.6248870229452 Test RE 0.4210621258905087 Lambda1 -1.4171398\n",
      "48 Train Loss 606.0325 Test MSE 625.1908359238256 Test RE 0.4209160366020697 Lambda1 -1.4225276\n",
      "49 Train Loss 605.809 Test MSE 624.9945280940659 Test RE 0.4208499483005122 Lambda1 -1.4500514\n",
      "50 Train Loss 605.76544 Test MSE 625.0482096134981 Test RE 0.42086802156241493 Lambda1 -1.4586138\n",
      "51 Train Loss 605.73615 Test MSE 625.0853861085574 Test RE 0.42088053752921323 Lambda1 -1.4598942\n",
      "52 Train Loss 605.6267 Test MSE 624.9782924138793 Test RE 0.42084448198902064 Lambda1 -1.4629107\n",
      "53 Train Loss 605.14166 Test MSE 624.6137856957301 Test RE 0.42072173931429835 Lambda1 -1.4492801\n",
      "54 Train Loss 604.899 Test MSE 624.3333170357987 Test RE 0.42062727092892943 Lambda1 -1.4367322\n",
      "55 Train Loss 604.78156 Test MSE 623.854069123626 Test RE 0.42046579993607985 Lambda1 -1.4406229\n",
      "56 Train Loss 604.6619 Test MSE 623.2489648968152 Test RE 0.4202618360845708 Lambda1 -1.4541103\n",
      "57 Train Loss 604.5343 Test MSE 622.8197169470463 Test RE 0.42011708846898943 Lambda1 -1.475425\n",
      "58 Train Loss 604.2783 Test MSE 622.290338187192 Test RE 0.4199385068217256 Lambda1 -1.5010189\n",
      "59 Train Loss 604.07086 Test MSE 621.9984888195978 Test RE 0.4198400213132141 Lambda1 -1.5152347\n",
      "60 Train Loss 603.7865 Test MSE 622.0163352084292 Test RE 0.4198460442977214 Lambda1 -1.5147434\n",
      "61 Train Loss 603.4906 Test MSE 622.193756042714 Test RE 0.4199059174234282 Lambda1 -1.5113935\n",
      "62 Train Loss 603.36115 Test MSE 622.139463457181 Test RE 0.4198875965426166 Lambda1 -1.5161067\n",
      "63 Train Loss 602.91174 Test MSE 621.8916923777598 Test RE 0.41980397673591824 Lambda1 -1.5268735\n",
      "64 Train Loss 602.6367 Test MSE 621.8647283805418 Test RE 0.4197948757010426 Lambda1 -1.5380801\n",
      "65 Train Loss 602.3799 Test MSE 622.1148857129638 Test RE 0.41987930258886635 Lambda1 -1.5680269\n",
      "66 Train Loss 602.3317 Test MSE 622.0511327529858 Test RE 0.4198577878856991 Lambda1 -1.5727289\n",
      "67 Train Loss 602.3014 Test MSE 621.8523500360674 Test RE 0.41979069762886567 Lambda1 -1.5785342\n",
      "68 Train Loss 602.22375 Test MSE 621.6903259000181 Test RE 0.41973600566211594 Lambda1 -1.5832667\n",
      "69 Train Loss 602.03406 Test MSE 621.4762104566206 Test RE 0.4196637191098585 Lambda1 -1.6048797\n",
      "70 Train Loss 601.8329 Test MSE 621.3090274292822 Test RE 0.4196072685418801 Lambda1 -1.6185858\n",
      "71 Train Loss 601.5587 Test MSE 620.7222140323146 Test RE 0.41940906658175003 Lambda1 -1.6238328\n",
      "72 Train Loss 601.12537 Test MSE 619.7908877571522 Test RE 0.41909430959330835 Lambda1 -1.6535\n",
      "73 Train Loss 600.8876 Test MSE 619.2461807051809 Test RE 0.4189101073006011 Lambda1 -1.6777914\n",
      "74 Train Loss 600.6542 Test MSE 618.9083974489328 Test RE 0.4187958392388186 Lambda1 -1.7062417\n",
      "Training time: 311.94\n",
      "Training time: 311.94\n",
      "inv_HT_tanh_tune1\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 1066.6389 Test MSE 1065.1602998238775 Test RE 0.5494101218919102 Lambda1 -0.000642362\n",
      "1 Train Loss 875.8081 Test MSE 877.6397122334849 Test RE 0.4987091125188037 Lambda1 0.0007657674\n",
      "2 Train Loss 857.2026 Test MSE 860.0364376371615 Test RE 0.4936823451449497 Lambda1 0.0012653619\n",
      "3 Train Loss 855.02057 Test MSE 858.1961963837433 Test RE 0.49315389013968686 Lambda1 0.0014469393\n",
      "4 Train Loss 854.7225 Test MSE 858.0718168988336 Test RE 0.4931181521291286 Lambda1 0.0015400571\n",
      "5 Train Loss 854.722 Test MSE 858.0752213940679 Test RE 0.4931191303786763 Lambda1 0.0015421332\n",
      "6 Train Loss 854.7217 Test MSE 858.0772999088691 Test RE 0.49311972761931744 Lambda1 0.0015433943\n",
      "7 Train Loss 854.72156 Test MSE 858.0788065466847 Test RE 0.4931201605363186 Lambda1 0.0015442742\n",
      "8 Train Loss 854.721 Test MSE 858.0829568495685 Test RE 0.49312135308153365 Lambda1 0.0015465895\n",
      "9 Train Loss 854.6708 Test MSE 857.9891454586856 Test RE 0.4930943966759314 Lambda1 0.0015701795\n",
      "10 Train Loss 854.4941 Test MSE 857.6145941609599 Test RE 0.4929867558579453 Lambda1 -0.0025975406\n",
      "11 Train Loss 854.36505 Test MSE 857.6034343880093 Test RE 0.4929835483343106 Lambda1 -0.058874123\n",
      "12 Train Loss 851.56146 Test MSE 851.3898911315382 Test RE 0.491194409537978 Lambda1 -0.08962431\n",
      "13 Train Loss 796.398 Test MSE 800.1567473615717 Test RE 0.4761860917219804 Lambda1 0.05777188\n",
      "14 Train Loss 705.677 Test MSE 715.9592000500149 Test RE 0.4504362225099642 Lambda1 0.005327677\n",
      "15 Train Loss 665.6193 Test MSE 678.7275345743751 Test RE 0.438567963956641 Lambda1 0.0019038799\n",
      "16 Train Loss 655.14197 Test MSE 669.8769864308996 Test RE 0.4356991368606535 Lambda1 0.0006865055\n",
      "17 Train Loss 650.6756 Test MSE 666.3808416378533 Test RE 0.4345606741142756 Lambda1 0.0005068977\n",
      "18 Train Loss 645.4865 Test MSE 664.267363757363 Test RE 0.43387100561438957 Lambda1 0.0012550176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Train Loss 640.4466 Test MSE 662.8119621977258 Test RE 0.4333954419855611 Lambda1 0.0006389443\n",
      "20 Train Loss 638.5149 Test MSE 661.0387331642728 Test RE 0.43281531963267383 Lambda1 0.0003695792\n",
      "21 Train Loss 635.0029 Test MSE 658.4537971177434 Test RE 0.43196824687288576 Lambda1 0.00011597082\n",
      "22 Train Loss 634.35016 Test MSE 658.1787139908269 Test RE 0.43187800546958693 Lambda1 0.00013250782\n",
      "23 Train Loss 631.841 Test MSE 655.2915950240457 Test RE 0.4309297420773968 Lambda1 -0.00025769573\n",
      "24 Train Loss 629.75244 Test MSE 653.0829046587272 Test RE 0.43020289486584706 Lambda1 0.000118172444\n",
      "25 Train Loss 629.26733 Test MSE 652.6411122915612 Test RE 0.43005736012022977 Lambda1 0.0001576619\n",
      "26 Train Loss 628.8088 Test MSE 652.2826388139663 Test RE 0.4299392359861259 Lambda1 0.0001539256\n",
      "27 Train Loss 628.5118 Test MSE 651.9413088291211 Test RE 0.4298267308024994 Lambda1 0.00024464627\n",
      "28 Train Loss 626.6776 Test MSE 650.4514859705425 Test RE 0.4293353277104988 Lambda1 2.0526199e-05\n",
      "29 Train Loss 626.003 Test MSE 649.4928266425136 Test RE 0.429018825949595 Lambda1 0.0001729578\n",
      "30 Train Loss 625.61804 Test MSE 649.084674768087 Test RE 0.428884003555011 Lambda1 0.000149713\n",
      "31 Train Loss 625.54877 Test MSE 649.0451290373916 Test RE 0.4288709383954849 Lambda1 0.00022448269\n",
      "32 Train Loss 624.7547 Test MSE 648.5058962632007 Test RE 0.42869274638001265 Lambda1 0.00036802187\n",
      "33 Train Loss 624.5621 Test MSE 648.1514553993644 Test RE 0.4285755793693122 Lambda1 0.00022458717\n",
      "34 Train Loss 624.41205 Test MSE 648.1173175685136 Test RE 0.4285642927840815 Lambda1 0.00019942208\n",
      "35 Train Loss 624.1582 Test MSE 647.6606198309447 Test RE 0.42841327164238774 Lambda1 0.0003209861\n",
      "36 Train Loss 624.11066 Test MSE 647.628101482899 Test RE 0.4284025164209636 Lambda1 0.00053275\n",
      "37 Train Loss 624.0305 Test MSE 647.8707601792806 Test RE 0.42848276761760706 Lambda1 0.00054549135\n",
      "38 Train Loss 623.344 Test MSE 646.2261036437178 Test RE 0.4279385581620544 Lambda1 0.0005236893\n",
      "39 Train Loss 621.9399 Test MSE 645.3359833472199 Test RE 0.42764373251628846 Lambda1 3.15398e-07\n",
      "40 Train Loss 619.64966 Test MSE 642.4260839918 Test RE 0.4266784940871678 Lambda1 -0.00020330655\n",
      "41 Train Loss 603.5904 Test MSE 600.9580315921417 Test RE 0.4126779291040841 Lambda1 0.0018732854\n",
      "42 Train Loss 568.6902 Test MSE 561.0335557426342 Test RE 0.39873429368032753 Lambda1 0.0019967637\n",
      "43 Train Loss 484.0929 Test MSE 462.58946154655564 Test RE 0.36206541133458914 Lambda1 0.0005003601\n",
      "44 Train Loss 416.87634 Test MSE 408.89856947464466 Test RE 0.34040581177870965 Lambda1 0.0016331259\n",
      "45 Train Loss 377.57944 Test MSE 359.2152569090495 Test RE 0.31905573666057624 Lambda1 0.0048388885\n",
      "46 Train Loss 343.64417 Test MSE 324.3046392564487 Test RE 0.30315570906522904 Lambda1 0.006109311\n",
      "47 Train Loss 305.43613 Test MSE 302.1493287725884 Test RE 0.29261729245481166 Lambda1 0.0058431407\n",
      "48 Train Loss 296.7532 Test MSE 295.6306091455035 Test RE 0.28944354574879705 Lambda1 0.005751909\n",
      "49 Train Loss 288.64703 Test MSE 289.09003384033247 Test RE 0.28622379166520867 Lambda1 0.004877537\n",
      "50 Train Loss 281.77917 Test MSE 284.5927464148721 Test RE 0.2839887159154717 Lambda1 0.005218261\n",
      "51 Train Loss 280.3133 Test MSE 284.2786225364336 Test RE 0.28383194405868634 Lambda1 0.0046338937\n",
      "52 Train Loss 278.5225 Test MSE 284.01756582430096 Test RE 0.2837015908647862 Lambda1 0.0053174193\n",
      "53 Train Loss 276.284 Test MSE 282.59073968763397 Test RE 0.28298807422595 Lambda1 0.006597818\n",
      "54 Train Loss 274.2288 Test MSE 281.47440694989575 Test RE 0.2824285699451284 Lambda1 0.007139239\n",
      "55 Train Loss 273.41043 Test MSE 280.40330163154704 Test RE 0.28189068963764463 Lambda1 0.0076333983\n",
      "56 Train Loss 272.17892 Test MSE 279.7020459645296 Test RE 0.2815379812543434 Lambda1 0.009127963\n",
      "57 Train Loss 271.20145 Test MSE 278.2408686415657 Test RE 0.280801634146796 Lambda1 0.009245614\n",
      "58 Train Loss 270.39206 Test MSE 277.4147763453257 Test RE 0.2803844767011037 Lambda1 0.008700658\n",
      "59 Train Loss 269.5284 Test MSE 276.8924162446285 Test RE 0.28012037636071224 Lambda1 0.009188387\n",
      "60 Train Loss 267.69727 Test MSE 274.7610702446925 Test RE 0.2790401972912501 Lambda1 0.012193364\n",
      "61 Train Loss 267.21112 Test MSE 274.42084502669593 Test RE 0.2788673818355108 Lambda1 0.013080472\n",
      "62 Train Loss 266.22415 Test MSE 273.0907657673897 Test RE 0.27819074545018735 Lambda1 0.014980762\n",
      "63 Train Loss 265.33698 Test MSE 271.26912351767055 Test RE 0.27726136226109227 Lambda1 0.017150387\n",
      "64 Train Loss 264.26276 Test MSE 269.4698619908075 Test RE 0.2763403291856272 Lambda1 0.019635998\n",
      "65 Train Loss 261.9435 Test MSE 266.400807405494 Test RE 0.27476217085264065 Lambda1 0.027888477\n",
      "66 Train Loss 260.51065 Test MSE 265.39990536266816 Test RE 0.27424552674190217 Lambda1 0.032046553\n",
      "67 Train Loss 258.60187 Test MSE 262.80876530056 Test RE 0.27290349247433116 Lambda1 0.040296257\n",
      "68 Train Loss 257.01038 Test MSE 259.6007736599763 Test RE 0.27123277160052417 Lambda1 0.049004022\n",
      "69 Train Loss 254.95775 Test MSE 255.93342019670774 Test RE 0.26931011841554225 Lambda1 0.05837917\n",
      "70 Train Loss 251.77046 Test MSE 251.80042357575516 Test RE 0.2671267613609044 Lambda1 0.07030141\n",
      "71 Train Loss 248.42616 Test MSE 249.24091234422704 Test RE 0.26576564313067674 Lambda1 0.080359235\n",
      "72 Train Loss 245.0838 Test MSE 246.65192724036694 Test RE 0.2643817221752178 Lambda1 0.091911264\n",
      "73 Train Loss 240.9992 Test MSE 241.9093154596204 Test RE 0.2618276253428694 Lambda1 0.11716704\n",
      "74 Train Loss 237.05922 Test MSE 237.5319279012322 Test RE 0.25944790456779765 Lambda1 0.13402092\n",
      "Training time: 309.51\n",
      "Training time: 309.51\n",
      "inv_HT_tanh_tune1\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 1037.4636 Test MSE 1036.3302051036212 Test RE 0.5419238302139757 Lambda1 -0.0010868796\n",
      "1 Train Loss 870.6405 Test MSE 872.672347985164 Test RE 0.4972957848063748 Lambda1 -0.0013965084\n",
      "2 Train Loss 856.57697 Test MSE 859.4816880632605 Test RE 0.49352309942203726 Lambda1 -0.0014704694\n",
      "3 Train Loss 854.94476 Test MSE 858.1451581147975 Test RE 0.4931392256053913 Lambda1 -0.0014972687\n",
      "4 Train Loss 854.7248 Test MSE 858.0631830510974 Test RE 0.49311567126583283 Lambda1 -0.001511203\n",
      "5 Train Loss 854.7217 Test MSE 858.0739474596195 Test RE 0.493118764325873 Lambda1 -0.0015130787\n",
      "6 Train Loss 854.7215 Test MSE 858.0760405174054 Test RE 0.4931193657457405 Lambda1 -0.0015137678\n",
      "7 Train Loss 854.7214 Test MSE 858.0778410725035 Test RE 0.49311988311720895 Lambda1 -0.0015147211\n",
      "8 Train Loss 854.7212 Test MSE 858.0799666936522 Test RE 0.4931204938924517 Lambda1 -0.0015164897\n",
      "9 Train Loss 854.72076 Test MSE 858.081985001299 Test RE 0.49312107383156967 Lambda1 -0.0015190206\n",
      "10 Train Loss 854.7203 Test MSE 858.085615748766 Test RE 0.49312211708630954 Lambda1 -0.0015254952\n",
      "11 Train Loss 854.5135 Test MSE 857.6655817899458 Test RE 0.4930014103731436 Lambda1 -0.0031573174\n",
      "12 Train Loss 854.3391 Test MSE 857.6262407664601 Test RE 0.4929901032839386 Lambda1 -0.05765661\n",
      "13 Train Loss 851.58075 Test MSE 854.4129107958328 Test RE 0.4920656758131981 Lambda1 -0.33928108\n",
      "14 Train Loss 842.86273 Test MSE 844.1099579414343 Test RE 0.48908988647429064 Lambda1 -0.5921987\n",
      "15 Train Loss 826.81866 Test MSE 827.9180394293459 Test RE 0.4843762530918324 Lambda1 -0.7456059\n",
      "16 Train Loss 809.15765 Test MSE 812.8000163925675 Test RE 0.47993345265289067 Lambda1 -0.65481955\n",
      "17 Train Loss 799.97784 Test MSE 801.8902018386348 Test RE 0.47670161592283145 Lambda1 -0.56477875\n",
      "18 Train Loss 791.6492 Test MSE 793.0810642125163 Test RE 0.4740759903591478 Lambda1 -0.46958193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Train Loss 782.0029 Test MSE 782.8679723317074 Test RE 0.47101358548546896 Lambda1 -0.5208932\n",
      "20 Train Loss 767.10925 Test MSE 764.7205343807195 Test RE 0.4655223608503658 Lambda1 -0.6125814\n",
      "21 Train Loss 740.58484 Test MSE 738.8313050970385 Test RE 0.4575745012181471 Lambda1 -0.7460082\n",
      "22 Train Loss 723.412 Test MSE 714.6488446195433 Test RE 0.4500238373771995 Lambda1 -0.8307121\n",
      "23 Train Loss 693.86566 Test MSE 695.501748387284 Test RE 0.4439543172651665 Lambda1 -0.8950557\n",
      "24 Train Loss 667.32434 Test MSE 668.9678578876238 Test RE 0.43540338031457787 Lambda1 -0.9322054\n",
      "25 Train Loss 650.3468 Test MSE 653.5592883066023 Test RE 0.4303597694858078 Lambda1 -0.9661239\n",
      "26 Train Loss 639.3883 Test MSE 641.7056086165087 Test RE 0.4264391688215968 Lambda1 -1.0219808\n",
      "27 Train Loss 631.96094 Test MSE 642.6098080557781 Test RE 0.42673950149723017 Lambda1 -0.9999981\n",
      "28 Train Loss 627.532 Test MSE 639.9550064475538 Test RE 0.42585709882073586 Lambda1 -1.0151228\n",
      "29 Train Loss 622.29956 Test MSE 634.1955832310696 Test RE 0.42393646799485396 Lambda1 -1.0628674\n",
      "30 Train Loss 619.77545 Test MSE 632.2085159380168 Test RE 0.42327180618221544 Lambda1 -1.0923908\n",
      "31 Train Loss 617.32886 Test MSE 631.3439376043283 Test RE 0.4229822839567167 Lambda1 -1.0824429\n",
      "32 Train Loss 613.54987 Test MSE 628.010869730936 Test RE 0.4218642766073206 Lambda1 -1.1204962\n",
      "33 Train Loss 612.3182 Test MSE 627.1820006745512 Test RE 0.42158578963005705 Lambda1 -1.1286224\n",
      "34 Train Loss 609.82794 Test MSE 624.531621792952 Test RE 0.42069406679268906 Lambda1 -1.1705463\n",
      "35 Train Loss 609.2342 Test MSE 624.6160172191446 Test RE 0.42072249085836877 Lambda1 -1.1685961\n",
      "36 Train Loss 608.3103 Test MSE 624.1803556083296 Test RE 0.4205757410110759 Lambda1 -1.161113\n",
      "37 Train Loss 607.9319 Test MSE 623.6885257922329 Test RE 0.42041000970334724 Lambda1 -1.1645619\n",
      "38 Train Loss 607.42035 Test MSE 623.8979072175009 Test RE 0.42048057269811007 Lambda1 -1.164177\n",
      "39 Train Loss 606.26373 Test MSE 622.9665225923782 Test RE 0.4201665987242294 Lambda1 -1.1695595\n",
      "40 Train Loss 605.5901 Test MSE 622.8121834072757 Test RE 0.4201145476226746 Lambda1 -1.1598023\n",
      "41 Train Loss 605.3133 Test MSE 622.658003051934 Test RE 0.42006254364683215 Lambda1 -1.1589547\n",
      "42 Train Loss 605.07574 Test MSE 622.1421079139463 Test RE 0.41988848892565983 Lambda1 -1.1741028\n",
      "43 Train Loss 604.7819 Test MSE 622.0615021045014 Test RE 0.4198612873044901 Lambda1 -1.1752346\n",
      "44 Train Loss 604.5729 Test MSE 622.0990525049655 Test RE 0.41987395946110617 Lambda1 -1.1709645\n",
      "45 Train Loss 604.395 Test MSE 621.9158240713207 Test RE 0.41981212162896975 Lambda1 -1.1630837\n",
      "46 Train Loss 603.8913 Test MSE 621.5900688551393 Test RE 0.41970215988190096 Lambda1 -1.1668113\n",
      "47 Train Loss 603.74084 Test MSE 621.5699021678321 Test RE 0.41969535147930853 Lambda1 -1.1774956\n",
      "48 Train Loss 603.53613 Test MSE 621.6221344847443 Test RE 0.41971298521608763 Lambda1 -1.1827028\n",
      "49 Train Loss 603.36334 Test MSE 621.4347135197777 Test RE 0.41964970807511043 Lambda1 -1.1857862\n",
      "50 Train Loss 603.2655 Test MSE 621.4186974280128 Test RE 0.4196443002732984 Lambda1 -1.1828547\n",
      "51 Train Loss 603.0736 Test MSE 621.6146627227918 Test RE 0.4197104627794146 Lambda1 -1.1757681\n",
      "52 Train Loss 602.9894 Test MSE 621.5588227472068 Test RE 0.41969161094904894 Lambda1 -1.1660317\n",
      "53 Train Loss 602.928 Test MSE 621.5491795452291 Test RE 0.41968835527434667 Lambda1 -1.1703928\n",
      "54 Train Loss 602.8561 Test MSE 621.5133681638922 Test RE 0.4196762646492424 Lambda1 -1.1745186\n",
      "55 Train Loss 602.78516 Test MSE 621.3721675706767 Test RE 0.4196285891633581 Lambda1 -1.186796\n",
      "56 Train Loss 602.67993 Test MSE 621.2649407908738 Test RE 0.419592381101589 Lambda1 -1.1977919\n",
      "57 Train Loss 602.6075 Test MSE 621.2594179156162 Test RE 0.41959051606673997 Lambda1 -1.2068684\n",
      "58 Train Loss 602.54767 Test MSE 621.1537245441152 Test RE 0.419554822585582 Lambda1 -1.21994\n",
      "59 Train Loss 602.4985 Test MSE 620.998161795896 Test RE 0.4195022823000114 Lambda1 -1.2272372\n",
      "60 Train Loss 602.36865 Test MSE 620.9284729613233 Test RE 0.41947874322439016 Lambda1 -1.2539859\n",
      "61 Train Loss 602.1613 Test MSE 620.7013184892047 Test RE 0.41940200718079024 Lambda1 -1.2782793\n",
      "62 Train Loss 602.04456 Test MSE 620.5054517564835 Test RE 0.41933582931075114 Lambda1 -1.2896683\n",
      "63 Train Loss 601.9211 Test MSE 620.0155973350156 Test RE 0.41917027551414726 Lambda1 -1.3195739\n",
      "64 Train Loss 601.5289 Test MSE 619.1312612353903 Test RE 0.4188712349081488 Lambda1 -1.3702036\n",
      "65 Train Loss 601.15173 Test MSE 618.3739588106124 Test RE 0.41861498128135843 Lambda1 -1.4077206\n",
      "66 Train Loss 600.5545 Test MSE 617.1154412937907 Test RE 0.4181887807547635 Lambda1 -1.4556931\n",
      "67 Train Loss 599.6287 Test MSE 615.2870891852283 Test RE 0.41756882907858656 Lambda1 -1.4812827\n",
      "68 Train Loss 598.4175 Test MSE 613.7184523632823 Test RE 0.41703620628756316 Lambda1 -1.4739026\n",
      "69 Train Loss 596.9071 Test MSE 612.9476134599009 Test RE 0.4167742223630833 Lambda1 -1.4599996\n",
      "70 Train Loss 595.8682 Test MSE 612.8832890203912 Test RE 0.41675235306214264 Lambda1 -1.4511888\n",
      "71 Train Loss 595.28265 Test MSE 612.1106745727069 Test RE 0.4164895865326318 Lambda1 -1.4467176\n",
      "72 Train Loss 594.81964 Test MSE 611.5147141201904 Test RE 0.4162867867957548 Lambda1 -1.4490101\n",
      "73 Train Loss 594.131 Test MSE 610.2259308346117 Test RE 0.415847887769721 Lambda1 -1.4538795\n",
      "74 Train Loss 592.55493 Test MSE 607.4983588424865 Test RE 0.41491747388463374 Lambda1 -1.4444029\n",
      "Training time: 316.45\n",
      "Training time: 316.45\n",
      "inv_HT_tanh_tune2\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 874.64636 Test MSE 876.5208779026659 Test RE 0.4983911284925284 Lambda1 -0.059641086\n",
      "1 Train Loss 854.78296 Test MSE 858.0574531505094 Test RE 0.49311402482035693 Lambda1 -0.063478686\n",
      "2 Train Loss 854.721 Test MSE 858.0737838528244 Test RE 0.4931187173150153 Lambda1 -0.06369362\n",
      "3 Train Loss 854.7204 Test MSE 858.0818016460541 Test RE 0.49312102114642914 Lambda1 -0.06372369\n",
      "4 Train Loss 854.603 Test MSE 857.8089717223343 Test RE 0.4930426201908095 Lambda1 -0.065805875\n",
      "5 Train Loss 854.4856 Test MSE 857.5989975505602 Test RE 0.4929822730999713 Lambda1 -0.104420096\n",
      "6 Train Loss 849.4417 Test MSE 851.4851514826059 Test RE 0.49122188816064416 Lambda1 -0.47569266\n",
      "7 Train Loss 835.93835 Test MSE 834.900470609307 Test RE 0.4864145120925707 Lambda1 -0.81896347\n",
      "8 Train Loss 822.67285 Test MSE 826.3521575040953 Test RE 0.4839179740358992 Lambda1 -0.9198219\n",
      "9 Train Loss 805.08777 Test MSE 806.8995849903612 Test RE 0.478188267854969 Lambda1 -0.637262\n",
      "10 Train Loss 795.6307 Test MSE 795.8299286226411 Test RE 0.4748968669460911 Lambda1 -0.48946413\n",
      "11 Train Loss 777.486 Test MSE 779.7926257838919 Test RE 0.47008753190786867 Lambda1 -0.4231634\n",
      "12 Train Loss 740.7941 Test MSE 737.8440253991614 Test RE 0.4572686769862176 Lambda1 -0.62634575\n",
      "13 Train Loss 715.9572 Test MSE 711.2466961982083 Test RE 0.4489513705135201 Lambda1 -0.7676933\n",
      "14 Train Loss 694.3223 Test MSE 693.8777349037621 Test RE 0.4434356922781783 Lambda1 -0.8244687\n",
      "15 Train Loss 680.3045 Test MSE 681.2922082209373 Test RE 0.4393957800566086 Lambda1 -0.76488537\n",
      "16 Train Loss 663.8695 Test MSE 663.8342290190828 Test RE 0.4337295300138153 Lambda1 -0.7065236\n",
      "17 Train Loss 650.1589 Test MSE 652.1659170020116 Test RE 0.4299007668250107 Lambda1 -0.7317695\n",
      "18 Train Loss 633.0092 Test MSE 637.3451627008687 Test RE 0.4249878533805519 Lambda1 -0.7504191\n",
      "19 Train Loss 625.35126 Test MSE 631.0141078806932 Test RE 0.4228717813071947 Lambda1 -0.7571445\n",
      "20 Train Loss 617.6333 Test MSE 628.4244797790523 Test RE 0.4220031743494871 Lambda1 -0.76703954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Train Loss 609.76074 Test MSE 625.0925322647954 Test RE 0.42088294333612347 Lambda1 -0.8085054\n",
      "22 Train Loss 606.1035 Test MSE 623.2549043453133 Test RE 0.420263838588967 Lambda1 -0.8369485\n",
      "23 Train Loss 605.46375 Test MSE 623.2514504086522 Test RE 0.42026267408413887 Lambda1 -0.8471455\n",
      "24 Train Loss 604.9089 Test MSE 623.3945048269061 Test RE 0.4203109025983785 Lambda1 -0.8600273\n",
      "25 Train Loss 604.129 Test MSE 622.9917058719773 Test RE 0.4201750912078677 Lambda1 -0.8909781\n",
      "26 Train Loss 603.8328 Test MSE 622.6458407622354 Test RE 0.4200584411160122 Lambda1 -0.9154309\n",
      "27 Train Loss 603.37396 Test MSE 622.652208032127 Test RE 0.420060588900878 Lambda1 -0.92404366\n",
      "28 Train Loss 603.242 Test MSE 622.8536441115892 Test RE 0.4201285309354827 Lambda1 -0.9258491\n",
      "29 Train Loss 602.91833 Test MSE 622.4385379354486 Test RE 0.41998850846266444 Lambda1 -0.9553163\n",
      "30 Train Loss 602.8519 Test MSE 622.210711361579 Test RE 0.41991163878445975 Lambda1 -0.9662854\n",
      "31 Train Loss 602.63824 Test MSE 622.0130994671799 Test RE 0.4198449522725979 Lambda1 -0.9798506\n",
      "32 Train Loss 602.4569 Test MSE 621.9824415421775 Test RE 0.41983460543771717 Lambda1 -0.97907484\n",
      "33 Train Loss 601.9512 Test MSE 621.4647922891967 Test RE 0.4196598639239836 Lambda1 -0.96776575\n",
      "34 Train Loss 601.6743 Test MSE 621.2794035153144 Test RE 0.4195972650192783 Lambda1 -0.9533489\n",
      "35 Train Loss 601.54126 Test MSE 621.0455133404379 Test RE 0.4195182756664816 Lambda1 -0.94574344\n",
      "36 Train Loss 601.3344 Test MSE 620.3808245173641 Test RE 0.4192937158281877 Lambda1 -0.93121827\n",
      "37 Train Loss 600.5755 Test MSE 619.0863578165603 Test RE 0.41885604500196894 Lambda1 -0.9096171\n",
      "38 Train Loss 600.17053 Test MSE 618.7133344624128 Test RE 0.4187298375451658 Lambda1 -0.91248596\n",
      "39 Train Loss 599.6769 Test MSE 618.4667012251418 Test RE 0.4186463715978626 Lambda1 -0.93299705\n",
      "40 Train Loss 598.708 Test MSE 616.4589755067957 Test RE 0.4179662942834281 Lambda1 -0.94751465\n",
      "41 Train Loss 598.17395 Test MSE 615.0296646108246 Test RE 0.41748146845818584 Lambda1 -0.93976504\n",
      "42 Train Loss 596.51794 Test MSE 612.1426702562633 Test RE 0.4165004715697942 Lambda1 -0.9380109\n",
      "43 Train Loss 593.36597 Test MSE 608.4512104432704 Test RE 0.4152427421491125 Lambda1 -0.94458276\n",
      "44 Train Loss 590.3303 Test MSE 603.4674290821322 Test RE 0.4135386332678138 Lambda1 -0.96667355\n",
      "45 Train Loss 585.61365 Test MSE 599.6373921591243 Test RE 0.4122242381111027 Lambda1 -0.9508828\n",
      "46 Train Loss 579.6525 Test MSE 586.5777862453114 Test RE 0.4077105755681274 Lambda1 -0.9702873\n",
      "47 Train Loss 569.82745 Test MSE 573.9747035973422 Test RE 0.4033068021509869 Lambda1 -1.0559247\n",
      "48 Train Loss 556.6318 Test MSE 561.0966271411372 Test RE 0.3987567059072887 Lambda1 -1.1470065\n",
      "49 Train Loss 531.65405 Test MSE 518.7138253248776 Test RE 0.3834008596896873 Lambda1 -1.1578078\n",
      "50 Train Loss 496.40195 Test MSE 481.65659965435975 Test RE 0.369451920368202 Lambda1 -1.135671\n",
      "51 Train Loss 476.64642 Test MSE 462.9445509841324 Test RE 0.3622043476391169 Lambda1 -1.1813285\n",
      "52 Train Loss 424.04703 Test MSE 383.58069086723265 Test RE 0.32969893110260207 Lambda1 -1.2869517\n",
      "53 Train Loss 404.78592 Test MSE 367.53172892491995 Test RE 0.322727957518207 Lambda1 -1.2215136\n",
      "54 Train Loss 374.6421 Test MSE 352.19102006480415 Test RE 0.3159208650001373 Lambda1 -1.0726948\n",
      "55 Train Loss 359.1435 Test MSE 345.031471749995 Test RE 0.3126932641053469 Lambda1 -0.99095666\n",
      "56 Train Loss 347.7187 Test MSE 334.62333728759205 Test RE 0.3079408354912529 Lambda1 -0.93730474\n",
      "57 Train Loss 334.2542 Test MSE 328.36618268339697 Test RE 0.30504814104032896 Lambda1 -0.9301559\n",
      "58 Train Loss 319.34027 Test MSE 312.4248965594037 Test RE 0.2975513931437381 Lambda1 -0.84137195\n",
      "59 Train Loss 314.24124 Test MSE 307.67911980089343 Test RE 0.29528282209408285 Lambda1 -0.7770939\n",
      "60 Train Loss 311.9285 Test MSE 304.78256410488063 Test RE 0.29388960816215726 Lambda1 -0.75895154\n",
      "61 Train Loss 308.06616 Test MSE 300.0216217242476 Test RE 0.2915851805618313 Lambda1 -0.72727853\n",
      "62 Train Loss 302.94177 Test MSE 296.501720591766 Test RE 0.28986967232806093 Lambda1 -0.6520054\n",
      "63 Train Loss 298.9836 Test MSE 293.33996317181186 Test RE 0.2883200118797407 Lambda1 -0.6028189\n",
      "64 Train Loss 294.26016 Test MSE 289.4262355403054 Test RE 0.28639017748381035 Lambda1 -0.5624709\n",
      "65 Train Loss 292.49948 Test MSE 288.88382880423984 Test RE 0.28612169316842445 Lambda1 -0.5470421\n",
      "66 Train Loss 291.15115 Test MSE 289.25762652687763 Test RE 0.286306745171713 Lambda1 -0.5482613\n",
      "67 Train Loss 289.35077 Test MSE 288.8832082426685 Test RE 0.28612138585419444 Lambda1 -0.55580115\n",
      "68 Train Loss 287.58398 Test MSE 286.7462101078538 Test RE 0.28506113758154916 Lambda1 -0.54775816\n",
      "69 Train Loss 286.7451 Test MSE 286.4694037740607 Test RE 0.28492351452379844 Lambda1 -0.54425025\n",
      "70 Train Loss 284.89752 Test MSE 284.9916514289076 Test RE 0.2841876754024266 Lambda1 -0.5348655\n",
      "71 Train Loss 282.8006 Test MSE 283.4714764426476 Test RE 0.2834287187133399 Lambda1 -0.5122914\n",
      "72 Train Loss 281.53787 Test MSE 282.5820027179166 Test RE 0.28298369956500324 Lambda1 -0.49584025\n",
      "73 Train Loss 280.83658 Test MSE 281.83211339743843 Test RE 0.2826079724794478 Lambda1 -0.48163134\n",
      "74 Train Loss 280.50073 Test MSE 281.3289774859648 Test RE 0.28235559929266657 Lambda1 -0.47172344\n",
      "Training time: 301.67\n",
      "Training time: 301.67\n",
      "inv_HT_tanh_tune2\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 873.532 Test MSE 875.4484716686532 Test RE 0.4980861492572831 Lambda1 -0.057161275\n",
      "1 Train Loss 854.77795 Test MSE 858.0551236058399 Test RE 0.49311335544097945 Lambda1 -0.060879398\n",
      "2 Train Loss 854.7198 Test MSE 858.0728663945295 Test RE 0.4931184536920105 Lambda1 -0.06108488\n",
      "3 Train Loss 854.719 Test MSE 858.0815379944721 Test RE 0.49312094538899737 Lambda1 -0.061112847\n",
      "4 Train Loss 854.4769 Test MSE 857.6636801306809 Test RE 0.49300086381907915 Lambda1 -0.06806605\n",
      "5 Train Loss 852.774 Test MSE 854.2236053748401 Test RE 0.4920111612693669 Lambda1 -0.61329305\n",
      "6 Train Loss 849.2095 Test MSE 852.3913167734102 Test RE 0.4914832020890414 Lambda1 -0.8728433\n",
      "7 Train Loss 820.4964 Test MSE 810.4093310950151 Test RE 0.479227119755809 Lambda1 -0.98703074\n",
      "8 Train Loss 788.21356 Test MSE 781.989298033254 Test RE 0.47074918347858136 Lambda1 -1.0823376\n",
      "9 Train Loss 765.18286 Test MSE 751.7738579419166 Test RE 0.4615649055377155 Lambda1 -1.213314\n",
      "10 Train Loss 725.14404 Test MSE 711.9036677453404 Test RE 0.4491586686277225 Lambda1 -1.4153719\n",
      "11 Train Loss 678.3521 Test MSE 670.0324157910383 Test RE 0.43574968084980736 Lambda1 -1.5806081\n",
      "12 Train Loss 655.29565 Test MSE 649.8668816857437 Test RE 0.4291423481427439 Lambda1 -1.5827031\n",
      "13 Train Loss 643.5226 Test MSE 642.7878893874921 Test RE 0.42679862685881975 Lambda1 -1.5897892\n",
      "14 Train Loss 634.3677 Test MSE 638.0005340059813 Test RE 0.42520630116725333 Lambda1 -1.5911354\n",
      "15 Train Loss 629.3668 Test MSE 639.2338443019586 Test RE 0.42561708304966805 Lambda1 -1.5220941\n",
      "16 Train Loss 623.1299 Test MSE 636.4565970506774 Test RE 0.42469149801308936 Lambda1 -1.4587259\n",
      "17 Train Loss 617.88135 Test MSE 629.8919994443457 Test RE 0.4224956255881478 Lambda1 -1.5116658\n",
      "18 Train Loss 615.26447 Test MSE 628.7988644839351 Test RE 0.4221288601041501 Lambda1 -1.5015197\n",
      "19 Train Loss 613.656 Test MSE 627.8149198113139 Test RE 0.42179845710940833 Lambda1 -1.4570795\n",
      "20 Train Loss 612.4137 Test MSE 627.1555595964255 Test RE 0.42157690281548166 Lambda1 -1.4220577\n",
      "21 Train Loss 611.8253 Test MSE 627.2861893917861 Test RE 0.4216208055094388 Lambda1 -1.4041071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 Train Loss 610.5172 Test MSE 627.3792746617662 Test RE 0.4216520872683012 Lambda1 -1.3786447\n",
      "23 Train Loss 609.8303 Test MSE 626.565708743772 Test RE 0.42137860592698984 Lambda1 -1.3574497\n",
      "24 Train Loss 609.22144 Test MSE 626.4859688584227 Test RE 0.4213517916995497 Lambda1 -1.348018\n",
      "25 Train Loss 608.8105 Test MSE 626.5564431634668 Test RE 0.4213754902667391 Lambda1 -1.3495291\n",
      "26 Train Loss 608.1979 Test MSE 626.246389145587 Test RE 0.4212712176730346 Lambda1 -1.3430953\n",
      "27 Train Loss 607.192 Test MSE 625.8841201538602 Test RE 0.4211493522386442 Lambda1 -1.3178619\n",
      "28 Train Loss 606.79645 Test MSE 625.3157421789192 Test RE 0.42095808170022475 Lambda1 -1.3048463\n",
      "29 Train Loss 606.3093 Test MSE 624.3272272470068 Test RE 0.4206252195107074 Lambda1 -1.304777\n",
      "30 Train Loss 604.38214 Test MSE 623.061978630574 Test RE 0.4201987881767619 Lambda1 -1.3230113\n",
      "31 Train Loss 603.2434 Test MSE 622.3900616251497 Test RE 0.41997215352282813 Lambda1 -1.3459051\n",
      "32 Train Loss 602.96893 Test MSE 622.134286594208 Test RE 0.4198858495829708 Lambda1 -1.3489206\n",
      "33 Train Loss 602.2451 Test MSE 621.5003715497648 Test RE 0.41967187665112027 Lambda1 -1.3786223\n",
      "34 Train Loss 601.6554 Test MSE 620.7509530490149 Test RE 0.419418775646758 Lambda1 -1.4126539\n",
      "35 Train Loss 600.86285 Test MSE 619.7359333652928 Test RE 0.4190757294690186 Lambda1 -1.4377992\n",
      "36 Train Loss 600.0944 Test MSE 619.1366531920722 Test RE 0.4188730588595287 Lambda1 -1.4549904\n",
      "37 Train Loss 599.3844 Test MSE 618.0377474002838 Test RE 0.41850116482205163 Lambda1 -1.4741364\n",
      "38 Train Loss 598.7559 Test MSE 616.6027823537765 Test RE 0.41801504279089813 Lambda1 -1.500506\n",
      "39 Train Loss 597.8272 Test MSE 615.5744997693786 Test RE 0.417666344280338 Lambda1 -1.4817933\n",
      "40 Train Loss 597.3614 Test MSE 614.9028479061659 Test RE 0.4174384247185049 Lambda1 -1.4552535\n",
      "41 Train Loss 596.34625 Test MSE 613.1316489836348 Test RE 0.4168367852184933 Lambda1 -1.4004588\n",
      "42 Train Loss 592.62683 Test MSE 607.9964408914585 Test RE 0.4150875324532343 Lambda1 -1.3313999\n",
      "43 Train Loss 590.77795 Test MSE 605.8577418417497 Test RE 0.41435682967566023 Lambda1 -1.2849846\n",
      "44 Train Loss 589.5852 Test MSE 603.0819945103759 Test RE 0.4134065486370674 Lambda1 -1.2630847\n",
      "45 Train Loss 587.06854 Test MSE 599.3814640350458 Test RE 0.41213625907852813 Lambda1 -1.2521318\n",
      "46 Train Loss 580.94775 Test MSE 589.5194360903942 Test RE 0.4087316182011038 Lambda1 -1.2733984\n",
      "47 Train Loss 572.48157 Test MSE 577.402389103066 Test RE 0.4045092516053897 Lambda1 -1.4022379\n",
      "48 Train Loss 559.6211 Test MSE 560.8612815788006 Test RE 0.39867307016673187 Lambda1 -1.5354756\n",
      "49 Train Loss 543.20276 Test MSE 539.9972123650075 Test RE 0.39118746457091236 Lambda1 -1.6511177\n",
      "50 Train Loss 525.7271 Test MSE 519.2879905809699 Test RE 0.3836129945496577 Lambda1 -1.733582\n",
      "51 Train Loss 509.40036 Test MSE 491.03765126181116 Test RE 0.3730324112581546 Lambda1 -1.7819484\n",
      "52 Train Loss 493.9014 Test MSE 478.32950144941697 Test RE 0.36817369341140943 Lambda1 -1.755172\n",
      "53 Train Loss 480.29797 Test MSE 472.8258430147987 Test RE 0.3660494624368147 Lambda1 -1.6919026\n",
      "54 Train Loss 457.21066 Test MSE 450.8051545263922 Test RE 0.3574239147559149 Lambda1 -1.7025393\n",
      "55 Train Loss 445.00494 Test MSE 438.1188298958827 Test RE 0.35235880641875816 Lambda1 -1.7539132\n",
      "56 Train Loss 436.65085 Test MSE 435.69948041822875 Test RE 0.3513845738910109 Lambda1 -1.7192507\n",
      "57 Train Loss 420.00867 Test MSE 415.0991857522284 Test RE 0.34297709010257355 Lambda1 -1.6866164\n",
      "58 Train Loss 414.07278 Test MSE 405.4703047935107 Test RE 0.3389758023656574 Lambda1 -1.6873506\n",
      "59 Train Loss 408.85764 Test MSE 400.3473475777756 Test RE 0.3368275826038301 Lambda1 -1.6575614\n",
      "60 Train Loss 400.69702 Test MSE 393.4388067850823 Test RE 0.3339087253826249 Lambda1 -1.5986515\n",
      "61 Train Loss 391.24588 Test MSE 383.418894429403 Test RE 0.3296293893604403 Lambda1 -1.6029773\n",
      "62 Train Loss 379.66135 Test MSE 372.3075302068117 Test RE 0.32481799462223815 Lambda1 -1.6900496\n",
      "63 Train Loss 374.59595 Test MSE 368.77133928648664 Test RE 0.3232717475212251 Lambda1 -1.6649048\n",
      "64 Train Loss 370.07874 Test MSE 365.24089542491373 Test RE 0.32172060004955444 Lambda1 -1.6538357\n",
      "65 Train Loss 364.981 Test MSE 358.83081367002427 Test RE 0.3188849593141838 Lambda1 -1.6650012\n",
      "66 Train Loss 356.77997 Test MSE 354.75019218883955 Test RE 0.31706659617599803 Lambda1 -1.6844978\n",
      "67 Train Loss 348.71158 Test MSE 348.9314698972798 Test RE 0.31445553288949013 Lambda1 -1.6720159\n",
      "68 Train Loss 343.5302 Test MSE 339.78013498018555 Test RE 0.31030456372091114 Lambda1 -1.6537228\n",
      "69 Train Loss 337.13986 Test MSE 332.60161666317805 Test RE 0.30700917072299516 Lambda1 -1.6343806\n",
      "70 Train Loss 329.2314 Test MSE 324.64264373711023 Test RE 0.3033136489932342 Lambda1 -1.6103894\n",
      "71 Train Loss 321.3354 Test MSE 318.30821416465346 Test RE 0.3003399427533095 Lambda1 -1.5813513\n",
      "72 Train Loss 317.2715 Test MSE 315.9997024579595 Test RE 0.2992488619689778 Lambda1 -1.5421395\n",
      "73 Train Loss 313.51447 Test MSE 311.4421111087748 Test RE 0.29708302535835557 Lambda1 -1.4924508\n",
      "74 Train Loss 309.9649 Test MSE 304.09932199824414 Test RE 0.29356001185503094 Lambda1 -1.473606\n",
      "Training time: 275.57\n",
      "Training time: 275.57\n",
      "inv_HT_tanh_tune2\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 885.51556 Test MSE 887.029682514531 Test RE 0.5013698881280749 Lambda1 -0.16108468\n",
      "1 Train Loss 854.8072 Test MSE 858.0646226740639 Test RE 0.4931160849302121 Lambda1 -0.17433986\n",
      "2 Train Loss 854.71265 Test MSE 858.069209392991 Test RE 0.49311740288564193 Lambda1 -0.17510536\n",
      "3 Train Loss 854.2634 Test MSE 857.4991166404102 Test RE 0.49295356448905375 Lambda1 -0.19235396\n",
      "4 Train Loss 849.63855 Test MSE 852.3494924219742 Test RE 0.4914711441187606 Lambda1 -0.30960432\n",
      "5 Train Loss 844.98505 Test MSE 845.4915994616229 Test RE 0.4894899946579903 Lambda1 -0.40714547\n",
      "6 Train Loss 824.1646 Test MSE 825.9153827770795 Test RE 0.48379006786667644 Lambda1 -0.8069841\n",
      "7 Train Loss 811.9008 Test MSE 816.0185258070705 Test RE 0.48088272934203713 Lambda1 -0.7911522\n",
      "8 Train Loss 804.65424 Test MSE 807.7539530950506 Test RE 0.4784413605093389 Lambda1 -0.783211\n",
      "9 Train Loss 786.16864 Test MSE 791.278206144248 Test RE 0.47353684118259004 Lambda1 -0.58966196\n",
      "10 Train Loss 774.3386 Test MSE 774.7868976180297 Test RE 0.4685762846498313 Lambda1 -0.4516501\n",
      "11 Train Loss 747.47156 Test MSE 744.7560415467537 Test RE 0.4594054977202892 Lambda1 -0.3698496\n",
      "12 Train Loss 731.7115 Test MSE 734.0681717049976 Test RE 0.45609715960606245 Lambda1 -0.39973688\n",
      "13 Train Loss 720.4276 Test MSE 719.8814684162272 Test RE 0.4516683588259627 Lambda1 -0.4596906\n",
      "14 Train Loss 698.59515 Test MSE 699.1530764132222 Test RE 0.4451181539135732 Lambda1 -0.48008585\n",
      "15 Train Loss 679.1974 Test MSE 685.306838218645 Test RE 0.44068848559650764 Lambda1 -0.46099973\n",
      "16 Train Loss 669.1477 Test MSE 677.4160256629694 Test RE 0.43814403543517194 Lambda1 -0.45941216\n",
      "17 Train Loss 663.54425 Test MSE 674.0529038236139 Test RE 0.4370550700442393 Lambda1 -0.47478643\n",
      "18 Train Loss 661.39856 Test MSE 673.5707726869101 Test RE 0.43689873546712216 Lambda1 -0.49230003\n",
      "19 Train Loss 657.55286 Test MSE 671.5873244998555 Test RE 0.4362549984463534 Lambda1 -0.50192404\n",
      "20 Train Loss 655.1672 Test MSE 668.531568692021 Test RE 0.43526137590370256 Lambda1 -0.4772795\n",
      "21 Train Loss 650.7902 Test MSE 663.9672754416898 Test RE 0.43377299212282594 Lambda1 -0.42798254\n",
      "22 Train Loss 648.7368 Test MSE 660.6852893405751 Test RE 0.432699595434086 Lambda1 -0.4074746\n",
      "23 Train Loss 647.06824 Test MSE 658.1423361635485 Test RE 0.43186607026092255 Lambda1 -0.3771425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Train Loss 645.69385 Test MSE 657.9750840644467 Test RE 0.4318111922411262 Lambda1 -0.3641791\n",
      "25 Train Loss 642.51385 Test MSE 654.8052572937332 Test RE 0.43076980084342936 Lambda1 -0.3599065\n",
      "26 Train Loss 640.63477 Test MSE 653.4556193248967 Test RE 0.43032563583547295 Lambda1 -0.37268043\n",
      "27 Train Loss 639.6078 Test MSE 654.0254424249202 Test RE 0.4305132201543527 Lambda1 -0.3861659\n",
      "28 Train Loss 637.99664 Test MSE 651.7663369123617 Test RE 0.4297690471944898 Lambda1 -0.39060423\n",
      "29 Train Loss 636.74664 Test MSE 648.9024648508085 Test RE 0.4288238015452161 Lambda1 -0.38741598\n",
      "30 Train Loss 634.009 Test MSE 644.6349888064801 Test RE 0.4274114059596092 Lambda1 -0.39043254\n",
      "31 Train Loss 625.8843 Test MSE 635.304418574856 Test RE 0.4243069140051518 Lambda1 -0.3979405\n",
      "32 Train Loss 619.76117 Test MSE 629.1516943158249 Test RE 0.42224727536844864 Lambda1 -0.40721828\n",
      "33 Train Loss 612.21313 Test MSE 624.4063569006638 Test RE 0.4206518745018082 Lambda1 -0.4165267\n",
      "34 Train Loss 601.83276 Test MSE 610.4030632725512 Test RE 0.4159082382086556 Lambda1 -0.44078174\n",
      "35 Train Loss 589.43536 Test MSE 587.2325983699617 Test RE 0.40793808108280954 Lambda1 -0.43958685\n",
      "36 Train Loss 556.0628 Test MSE 561.4490045705909 Test RE 0.39888189896857856 Lambda1 -0.42471427\n",
      "37 Train Loss 520.2719 Test MSE 496.3945106313487 Test RE 0.375061646431509 Lambda1 -0.38480532\n",
      "38 Train Loss 481.2879 Test MSE 451.8793196233611 Test RE 0.3578494909240913 Lambda1 -0.36098206\n",
      "39 Train Loss 455.32977 Test MSE 433.87396872513796 Test RE 0.35064767840577493 Lambda1 -0.37733296\n",
      "40 Train Loss 405.459 Test MSE 380.2796407810163 Test RE 0.3282771906452986 Lambda1 -0.38250974\n",
      "41 Train Loss 391.10065 Test MSE 371.15365330205634 Test RE 0.32431425671323666 Lambda1 -0.36540765\n",
      "42 Train Loss 373.61075 Test MSE 363.55172216674714 Test RE 0.32097578802507387 Lambda1 -0.36706445\n",
      "43 Train Loss 352.40387 Test MSE 337.583278774555 Test RE 0.3092997963867423 Lambda1 -0.4057528\n",
      "44 Train Loss 342.61295 Test MSE 326.2726065615788 Test RE 0.304074132831919 Lambda1 -0.4438714\n",
      "45 Train Loss 319.40137 Test MSE 307.23636189511467 Test RE 0.2950702859428205 Lambda1 -0.49644068\n",
      "46 Train Loss 304.48804 Test MSE 292.2988578973726 Test RE 0.28780791272120515 Lambda1 -0.53053546\n",
      "47 Train Loss 294.28204 Test MSE 289.5457022670877 Test RE 0.2864492781508687 Lambda1 -0.5750829\n",
      "48 Train Loss 287.83554 Test MSE 281.99626476280093 Test RE 0.28269026212875303 Lambda1 -0.59426546\n",
      "49 Train Loss 280.5977 Test MSE 267.6764912045698 Test RE 0.27541924663900297 Lambda1 -0.6274094\n",
      "50 Train Loss 271.0027 Test MSE 256.007553544436 Test RE 0.26934911960401586 Lambda1 -0.68778884\n",
      "51 Train Loss 262.93094 Test MSE 251.16187319005564 Test RE 0.2667878378344094 Lambda1 -0.725938\n",
      "52 Train Loss 254.32326 Test MSE 247.95111121288832 Test RE 0.2650770935544244 Lambda1 -0.7747183\n",
      "53 Train Loss 248.89786 Test MSE 239.80996676817682 Test RE 0.26068904739704946 Lambda1 -0.79639286\n",
      "54 Train Loss 240.15376 Test MSE 228.84082413637182 Test RE 0.2546571780573869 Lambda1 -0.810733\n",
      "55 Train Loss 235.46457 Test MSE 226.76583948148462 Test RE 0.2535000134167983 Lambda1 -0.8222554\n",
      "56 Train Loss 227.0712 Test MSE 214.83643872777694 Test RE 0.2467420353908637 Lambda1 -0.8422311\n",
      "57 Train Loss 222.87296 Test MSE 210.19201951545688 Test RE 0.24406037940881853 Lambda1 -0.8481773\n",
      "58 Train Loss 217.81903 Test MSE 206.4698223130813 Test RE 0.24188974831935972 Lambda1 -0.845779\n",
      "59 Train Loss 205.04381 Test MSE 197.4864691724884 Test RE 0.23656900498894617 Lambda1 -0.86575764\n",
      "60 Train Loss 200.09834 Test MSE 188.19591986422503 Test RE 0.23093740021432158 Lambda1 -0.8886771\n",
      "61 Train Loss 191.98608 Test MSE 175.21661339728018 Test RE 0.2228316169173474 Lambda1 -0.9080934\n",
      "62 Train Loss 183.40845 Test MSE 169.1401322291371 Test RE 0.21893364292308787 Lambda1 -0.9217621\n",
      "63 Train Loss 166.95155 Test MSE 161.76716696534527 Test RE 0.21410872263745198 Lambda1 -0.9542466\n",
      "64 Train Loss 161.14534 Test MSE 155.4968596289508 Test RE 0.20991814594934896 Lambda1 -0.9824275\n",
      "65 Train Loss 157.21198 Test MSE 151.56048029280763 Test RE 0.2072440911882755 Lambda1 -0.9922983\n",
      "66 Train Loss 153.21432 Test MSE 149.87706374558525 Test RE 0.20608992383332614 Lambda1 -0.98958373\n",
      "67 Train Loss 150.769 Test MSE 148.05104142799675 Test RE 0.2048306315095506 Lambda1 -1.0043182\n",
      "68 Train Loss 148.318 Test MSE 146.85687303487006 Test RE 0.20400288487969154 Lambda1 -1.0234581\n",
      "69 Train Loss 146.45277 Test MSE 145.87368125122705 Test RE 0.20331884881745807 Lambda1 -1.037455\n",
      "70 Train Loss 143.85378 Test MSE 142.63545064658035 Test RE 0.2010494595162742 Lambda1 -1.0644286\n",
      "71 Train Loss 139.56412 Test MSE 138.74024171026912 Test RE 0.1982852430692059 Lambda1 -1.1026278\n",
      "72 Train Loss 137.76192 Test MSE 137.7517830827695 Test RE 0.19757763617017018 Lambda1 -1.1142232\n",
      "73 Train Loss 136.69633 Test MSE 137.04084319237327 Test RE 0.1970671254318314 Lambda1 -1.1229302\n",
      "74 Train Loss 134.99884 Test MSE 134.83557475401247 Test RE 0.19547508740530048 Lambda1 -1.1409302\n",
      "Training time: 281.63\n",
      "Training time: 281.63\n",
      "inv_HT_tanh_tune2\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 867.9032 Test MSE 870.05451784047 Test RE 0.4965493341633414 Lambda1 -0.03796715\n",
      "1 Train Loss 854.7632 Test MSE 858.0530874290116 Test RE 0.49311277035818213 Lambda1 -0.039957423\n",
      "2 Train Loss 854.722 Test MSE 858.075747268763 Test RE 0.49311928148362966 Lambda1 -0.040067524\n",
      "3 Train Loss 854.72156 Test MSE 858.082285766315 Test RE 0.4931211602531223 Lambda1 -0.040076733\n",
      "4 Train Loss 854.4895 Test MSE 857.594432053059 Test RE 0.4929809608827591 Lambda1 -0.046184618\n",
      "5 Train Loss 853.86884 Test MSE 856.7305160483846 Test RE 0.49273259088487603 Lambda1 -0.26767474\n",
      "6 Train Loss 849.4162 Test MSE 851.7737584055792 Test RE 0.4913051297922536 Lambda1 -0.38280618\n",
      "7 Train Loss 840.03546 Test MSE 842.1722887270438 Test RE 0.48852820674608793 Lambda1 -0.4995249\n",
      "8 Train Loss 816.58453 Test MSE 799.9168877971028 Test RE 0.47611471423883683 Lambda1 -0.6825658\n",
      "9 Train Loss 793.2358 Test MSE 792.4780997814389 Test RE 0.4738957406185226 Lambda1 -0.7300007\n",
      "10 Train Loss 780.38684 Test MSE 781.9068187018635 Test RE 0.470724356986795 Lambda1 -0.814874\n",
      "11 Train Loss 772.6703 Test MSE 774.8647120377765 Test RE 0.46859981439482024 Lambda1 -0.8100468\n",
      "12 Train Loss 761.48474 Test MSE 764.902113858209 Test RE 0.46557762567330546 Lambda1 -0.72381204\n",
      "13 Train Loss 749.7467 Test MSE 754.5269390139314 Test RE 0.4624092846895008 Lambda1 -0.6717907\n",
      "14 Train Loss 743.82635 Test MSE 747.1728805754134 Test RE 0.46015031196544287 Lambda1 -0.63082546\n",
      "15 Train Loss 734.7111 Test MSE 738.7634191259783 Test RE 0.4575534790966538 Lambda1 -0.57240236\n",
      "16 Train Loss 731.5861 Test MSE 733.3934387851873 Test RE 0.4558874961648744 Lambda1 -0.5631051\n",
      "17 Train Loss 725.50024 Test MSE 725.620084535474 Test RE 0.45346504787604147 Lambda1 -0.5100318\n",
      "18 Train Loss 720.9224 Test MSE 722.9181379380867 Test RE 0.45261999060444336 Lambda1 -0.4875795\n",
      "19 Train Loss 718.1136 Test MSE 720.6739519782211 Test RE 0.4519169006415111 Lambda1 -0.4947653\n",
      "20 Train Loss 714.8574 Test MSE 718.8920510292714 Test RE 0.4513578617473509 Lambda1 -0.48899117\n",
      "21 Train Loss 711.84625 Test MSE 716.3339908353802 Test RE 0.4505541044073862 Lambda1 -0.49110714\n",
      "22 Train Loss 708.9197 Test MSE 714.4475045154859 Test RE 0.4499604396472301 Lambda1 -0.49075308\n",
      "23 Train Loss 706.8031 Test MSE 712.7575772960896 Test RE 0.44942796484816994 Lambda1 -0.4980524\n",
      "24 Train Loss 704.787 Test MSE 712.2148526124101 Test RE 0.4492568252436834 Lambda1 -0.5017682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Train Loss 702.35095 Test MSE 711.595581976541 Test RE 0.4490614684202871 Lambda1 -0.50192696\n",
      "26 Train Loss 699.4838 Test MSE 709.4457111159759 Test RE 0.4483826035721126 Lambda1 -0.48422676\n",
      "27 Train Loss 696.4348 Test MSE 708.5860735111223 Test RE 0.4481108679242366 Lambda1 -0.4852028\n",
      "28 Train Loss 695.1338 Test MSE 707.1725671786575 Test RE 0.44766369306915416 Lambda1 -0.4899241\n",
      "29 Train Loss 693.0548 Test MSE 704.6407929898562 Test RE 0.44686162602588436 Lambda1 -0.49666017\n",
      "30 Train Loss 692.4653 Test MSE 704.0172148845604 Test RE 0.4466638551862663 Lambda1 -0.49397722\n",
      "31 Train Loss 691.0513 Test MSE 703.0539225300892 Test RE 0.44635817007652584 Lambda1 -0.47901288\n",
      "32 Train Loss 689.3647 Test MSE 700.8551676622656 Test RE 0.4456596456026702 Lambda1 -0.4482756\n",
      "33 Train Loss 688.77765 Test MSE 699.9179283951419 Test RE 0.4453615601533961 Lambda1 -0.4352648\n",
      "34 Train Loss 688.31177 Test MSE 699.372287448053 Test RE 0.44518792916543126 Lambda1 -0.4428521\n",
      "35 Train Loss 686.0977 Test MSE 697.9992799442872 Test RE 0.4447507180599679 Lambda1 -0.4605389\n",
      "36 Train Loss 684.1218 Test MSE 696.1522656133676 Test RE 0.4441618885854863 Lambda1 -0.45967302\n",
      "37 Train Loss 682.2976 Test MSE 693.1842697585117 Test RE 0.4432140508774052 Lambda1 -0.49187362\n",
      "38 Train Loss 681.53107 Test MSE 691.9819897119129 Test RE 0.4428295220522541 Lambda1 -0.52690727\n",
      "39 Train Loss 680.28766 Test MSE 690.5701127658708 Test RE 0.4423775304949119 Lambda1 -0.5536993\n",
      "40 Train Loss 678.50543 Test MSE 689.4951498312779 Test RE 0.4420330870824061 Lambda1 -0.53233856\n",
      "41 Train Loss 677.4148 Test MSE 688.1952316066968 Test RE 0.44161620383761363 Lambda1 -0.5160861\n",
      "42 Train Loss 675.16327 Test MSE 685.1542580349933 Test RE 0.4406394243078892 Lambda1 -0.5192284\n",
      "43 Train Loss 674.23694 Test MSE 683.4089361206583 Test RE 0.4400778368825353 Lambda1 -0.5125119\n",
      "44 Train Loss 672.66364 Test MSE 681.0880946457901 Test RE 0.439329954144486 Lambda1 -0.49070218\n",
      "45 Train Loss 670.62384 Test MSE 679.9044201761192 Test RE 0.4389480286706869 Lambda1 -0.49134165\n",
      "46 Train Loss 668.7077 Test MSE 677.9272828361148 Test RE 0.43830934155689216 Lambda1 -0.47386098\n",
      "47 Train Loss 667.3145 Test MSE 675.5549602937216 Test RE 0.4375417648377079 Lambda1 -0.46262604\n",
      "48 Train Loss 666.75 Test MSE 675.04450965708 Test RE 0.43737642989741043 Lambda1 -0.45626125\n",
      "49 Train Loss 665.3408 Test MSE 674.8468265537467 Test RE 0.43731238355701874 Lambda1 -0.44085956\n",
      "50 Train Loss 664.66785 Test MSE 674.7091558657035 Test RE 0.43726777479160595 Lambda1 -0.44321415\n",
      "51 Train Loss 663.21356 Test MSE 674.3241311262005 Test RE 0.4371429929244124 Lambda1 -0.4525064\n",
      "52 Train Loss 662.2401 Test MSE 673.4860401974494 Test RE 0.43687125455249576 Lambda1 -0.44998297\n",
      "53 Train Loss 661.3174 Test MSE 672.4306615562684 Test RE 0.43652882328321896 Lambda1 -0.457046\n",
      "54 Train Loss 659.4299 Test MSE 671.1321046011565 Test RE 0.4361071207146704 Lambda1 -0.46219158\n",
      "55 Train Loss 658.6475 Test MSE 670.441646997473 Test RE 0.4358827304930173 Lambda1 -0.46287692\n",
      "56 Train Loss 656.717 Test MSE 669.3746051309018 Test RE 0.43553572763941906 Lambda1 -0.46129882\n",
      "57 Train Loss 655.3747 Test MSE 668.2771317633882 Test RE 0.4351785397953498 Lambda1 -0.47396752\n",
      "58 Train Loss 654.7008 Test MSE 667.3596280024707 Test RE 0.434879700385637 Lambda1 -0.48664472\n",
      "59 Train Loss 653.0715 Test MSE 665.8944837271824 Test RE 0.4344020631622498 Lambda1 -0.49330807\n",
      "60 Train Loss 651.5084 Test MSE 663.8237473496482 Test RE 0.43372610579485776 Lambda1 -0.48559156\n",
      "61 Train Loss 649.6197 Test MSE 661.5752674713935 Test RE 0.4329909320094571 Lambda1 -0.49332985\n",
      "62 Train Loss 648.3222 Test MSE 660.4786621994657 Test RE 0.43263192745859674 Lambda1 -0.50323474\n",
      "63 Train Loss 647.6731 Test MSE 659.8870312733889 Test RE 0.43243811667588994 Lambda1 -0.4985071\n",
      "64 Train Loss 646.8442 Test MSE 659.0495001511848 Test RE 0.4321636034962561 Lambda1 -0.4861913\n",
      "65 Train Loss 645.60645 Test MSE 658.5033194161485 Test RE 0.43198449072956013 Lambda1 -0.47141626\n",
      "66 Train Loss 644.20123 Test MSE 656.5299739792003 Test RE 0.4313367383207087 Lambda1 -0.47404855\n",
      "67 Train Loss 642.6165 Test MSE 653.6668004976189 Test RE 0.43039516567700875 Lambda1 -0.50469196\n",
      "68 Train Loss 641.41046 Test MSE 653.49843616927 Test RE 0.4303397338732149 Lambda1 -0.52578217\n",
      "69 Train Loss 639.7486 Test MSE 652.0341937443638 Test RE 0.4298573493543297 Lambda1 -0.5370618\n",
      "70 Train Loss 639.2549 Test MSE 651.0464054170833 Test RE 0.42953162333311895 Lambda1 -0.5511517\n",
      "71 Train Loss 638.4762 Test MSE 649.4107276529272 Test RE 0.42899171008025283 Lambda1 -0.5656531\n",
      "72 Train Loss 637.29034 Test MSE 647.8191474490197 Test RE 0.42846569970272697 Lambda1 -0.5857775\n",
      "73 Train Loss 635.6781 Test MSE 646.3007742535855 Test RE 0.42796328132777267 Lambda1 -0.6209936\n",
      "74 Train Loss 633.65 Test MSE 645.7507948449888 Test RE 0.4277811516629276 Lambda1 -0.6493021\n",
      "Training time: 297.26\n",
      "Training time: 297.26\n",
      "inv_HT_tanh_tune2\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 893.922 Test MSE 895.199284417736 Test RE 0.5036734212368608 Lambda1 -0.044685576\n",
      "1 Train Loss 854.8398 Test MSE 858.0817670132241 Test RE 0.4931210111950605 Lambda1 -0.0488089\n",
      "2 Train Loss 854.7196 Test MSE 858.0705927591797 Test RE 0.4931178003836875 Lambda1 -0.049027592\n",
      "3 Train Loss 854.719 Test MSE 858.079609549029 Test RE 0.4931203912706925 Lambda1 -0.049032103\n",
      "4 Train Loss 854.54474 Test MSE 857.5895695621361 Test RE 0.4929795632997317 Lambda1 -0.05074703\n",
      "5 Train Loss 854.50244 Test MSE 857.6681139359906 Test RE 0.4930021381338679 Lambda1 -0.060982063\n",
      "6 Train Loss 853.54724 Test MSE 856.3557766610439 Test RE 0.4926248169107051 Lambda1 -0.47945875\n",
      "7 Train Loss 847.9721 Test MSE 849.9740892000209 Test RE 0.4907858286068434 Lambda1 -0.43067995\n",
      "8 Train Loss 823.2445 Test MSE 820.2351303252034 Test RE 0.48212355877938834 Lambda1 -0.51753145\n",
      "9 Train Loss 809.2762 Test MSE 809.9825488789801 Test RE 0.47910091652831777 Lambda1 -0.49235737\n",
      "10 Train Loss 784.2333 Test MSE 784.0022654847676 Test RE 0.4713546864882222 Lambda1 -0.48585895\n",
      "11 Train Loss 769.36127 Test MSE 770.9821195816849 Test RE 0.4674243402215385 Lambda1 -0.45493475\n",
      "12 Train Loss 735.3492 Test MSE 736.2174701673266 Test RE 0.45676438130043395 Lambda1 -0.5149472\n",
      "13 Train Loss 719.35254 Test MSE 705.3463682739682 Test RE 0.44708529717379725 Lambda1 -0.57281494\n",
      "14 Train Loss 700.81055 Test MSE 694.1310565122724 Test RE 0.44351662987460433 Lambda1 -0.5888326\n",
      "15 Train Loss 685.9061 Test MSE 690.1573687778173 Test RE 0.4422453093390814 Lambda1 -0.55579245\n",
      "16 Train Loss 669.9912 Test MSE 675.4120179927833 Test RE 0.43749547213092094 Lambda1 -0.5860728\n",
      "17 Train Loss 654.16 Test MSE 662.529161765591 Test RE 0.4333029742106656 Lambda1 -0.62699234\n",
      "18 Train Loss 640.0859 Test MSE 646.7327492818877 Test RE 0.4281062786576912 Lambda1 -0.6842682\n",
      "19 Train Loss 635.0287 Test MSE 640.0370203245312 Test RE 0.42588438595220207 Lambda1 -0.7426612\n",
      "20 Train Loss 628.23804 Test MSE 635.7029085161475 Test RE 0.42443996481257595 Lambda1 -0.75983644\n",
      "21 Train Loss 624.8264 Test MSE 633.3057473120633 Test RE 0.42363895227326215 Lambda1 -0.7632339\n",
      "22 Train Loss 618.8051 Test MSE 630.8750119766621 Test RE 0.4228251714344713 Lambda1 -0.7790392\n",
      "23 Train Loss 614.44257 Test MSE 628.2270763441362 Test RE 0.4219368884059146 Lambda1 -0.80446225\n",
      "24 Train Loss 612.69183 Test MSE 625.8586207730657 Test RE 0.42114077304902964 Lambda1 -0.8318689\n",
      "25 Train Loss 610.9688 Test MSE 625.0696997334942 Test RE 0.4208752565455787 Lambda1 -0.8382375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 Train Loss 608.7091 Test MSE 624.7786114174013 Test RE 0.4207772465666865 Lambda1 -0.83234024\n",
      "27 Train Loss 607.8227 Test MSE 624.5270092281901 Test RE 0.420692513242682 Lambda1 -0.84339046\n",
      "28 Train Loss 607.0773 Test MSE 623.9425581591935 Test RE 0.42049561884381037 Lambda1 -0.8467441\n",
      "29 Train Loss 606.17706 Test MSE 622.7999891449132 Test RE 0.4201104348160943 Lambda1 -0.8603106\n",
      "30 Train Loss 604.0005 Test MSE 621.6053250522206 Test RE 0.4197073103982132 Lambda1 -0.90200484\n",
      "31 Train Loss 603.76794 Test MSE 621.6623935399905 Test RE 0.41972657624972803 Lambda1 -0.90882725\n",
      "32 Train Loss 603.05145 Test MSE 621.7058096982544 Test RE 0.41974123259495316 Lambda1 -0.9034634\n",
      "33 Train Loss 602.7142 Test MSE 621.3022967420543 Test RE 0.4196049957172411 Lambda1 -0.90527797\n",
      "34 Train Loss 602.34534 Test MSE 621.1007814673305 Test RE 0.4195369421514459 Lambda1 -0.9148981\n",
      "35 Train Loss 601.64075 Test MSE 620.3051662111964 Test RE 0.41926814764625425 Lambda1 -0.91205585\n",
      "36 Train Loss 601.1755 Test MSE 619.1300413595511 Test RE 0.41887082225643585 Lambda1 -0.9038629\n",
      "37 Train Loss 600.0172 Test MSE 617.185423335003 Test RE 0.4182124917761396 Lambda1 -0.8734229\n",
      "38 Train Loss 599.8331 Test MSE 616.8520049324717 Test RE 0.4180995122946763 Lambda1 -0.8698579\n",
      "39 Train Loss 599.46545 Test MSE 616.9907812525432 Test RE 0.4181465406323081 Lambda1 -0.882217\n",
      "40 Train Loss 598.6573 Test MSE 615.3596536875108 Test RE 0.4175934515527542 Lambda1 -0.8882821\n",
      "41 Train Loss 595.0102 Test MSE 608.262097209355 Test RE 0.41517820616063994 Lambda1 -0.8929071\n",
      "42 Train Loss 585.60144 Test MSE 597.2407654122634 Test RE 0.41139962578622136 Lambda1 -0.91026294\n",
      "43 Train Loss 570.98035 Test MSE 575.9720984050673 Test RE 0.4040079334879317 Lambda1 -0.788421\n",
      "44 Train Loss 553.9731 Test MSE 556.7300797217467 Test RE 0.39720207985513356 Lambda1 -0.7213829\n",
      "45 Train Loss 537.36285 Test MSE 531.3033690122571 Test RE 0.38802566825943996 Lambda1 -0.7119693\n",
      "46 Train Loss 505.4397 Test MSE 492.87297987390383 Test RE 0.3737288940172664 Lambda1 -0.5869487\n",
      "47 Train Loss 455.91614 Test MSE 440.4746659242751 Test RE 0.3533048815582265 Lambda1 -0.5172999\n",
      "48 Train Loss 436.27426 Test MSE 421.9135432483325 Test RE 0.345780823104318 Lambda1 -0.46720126\n",
      "49 Train Loss 410.4268 Test MSE 398.07618201312346 Test RE 0.3358708143795759 Lambda1 -0.4387589\n",
      "50 Train Loss 385.97482 Test MSE 375.3625280081571 Test RE 0.32614793137141573 Lambda1 -0.44361317\n",
      "51 Train Loss 352.81772 Test MSE 330.9740426814387 Test RE 0.30625708037633426 Lambda1 -0.45892566\n",
      "52 Train Loss 336.5009 Test MSE 322.33382528858965 Test RE 0.30223315985498467 Lambda1 -0.45695013\n",
      "53 Train Loss 323.7781 Test MSE 313.89508976844485 Test RE 0.29825067256694926 Lambda1 -0.44975054\n",
      "54 Train Loss 316.54462 Test MSE 308.2751542026597 Test RE 0.2955686938926616 Lambda1 -0.44490764\n",
      "55 Train Loss 310.241 Test MSE 304.37917793701604 Test RE 0.293695059213254 Lambda1 -0.43584755\n",
      "56 Train Loss 307.4043 Test MSE 303.20694810665054 Test RE 0.29312897216369505 Lambda1 -0.42247516\n",
      "57 Train Loss 300.13925 Test MSE 296.58894825749707 Test RE 0.2899123074862769 Lambda1 -0.4185337\n",
      "58 Train Loss 294.0785 Test MSE 290.80646119602 Test RE 0.28707223889106653 Lambda1 -0.4218625\n",
      "59 Train Loss 289.84222 Test MSE 288.27460351871457 Test RE 0.2858198338195629 Lambda1 -0.43258533\n",
      "60 Train Loss 287.48322 Test MSE 287.0857569446557 Test RE 0.2852298633876245 Lambda1 -0.43364945\n",
      "61 Train Loss 285.64014 Test MSE 285.2995746213537 Test RE 0.2843411612173332 Lambda1 -0.42908624\n",
      "62 Train Loss 283.59427 Test MSE 283.51565639196 Test RE 0.283450804495529 Lambda1 -0.42843196\n",
      "63 Train Loss 282.24744 Test MSE 282.93511889657753 Test RE 0.2831604534348013 Lambda1 -0.42741743\n",
      "64 Train Loss 281.29855 Test MSE 282.42723310151666 Test RE 0.28290619413866364 Lambda1 -0.42593217\n",
      "65 Train Loss 280.18137 Test MSE 281.5563451325452 Test RE 0.2824696749253096 Lambda1 -0.42323253\n",
      "66 Train Loss 278.95605 Test MSE 279.9841146305764 Test RE 0.2816799055498658 Lambda1 -0.419487\n",
      "67 Train Loss 277.61368 Test MSE 278.78209309322636 Test RE 0.28107460425008796 Lambda1 -0.4171964\n",
      "68 Train Loss 276.58313 Test MSE 278.33744793005917 Test RE 0.28085036399231317 Lambda1 -0.41734272\n",
      "69 Train Loss 276.1215 Test MSE 277.97772789560213 Test RE 0.2806688214687285 Lambda1 -0.41369638\n",
      "70 Train Loss 275.83942 Test MSE 277.68718701292744 Test RE 0.2805221063223526 Lambda1 -0.41181684\n",
      "71 Train Loss 275.46277 Test MSE 277.1566443323194 Test RE 0.2802539986953272 Lambda1 -0.4165404\n",
      "72 Train Loss 275.128 Test MSE 276.8067961633575 Test RE 0.2800770639001065 Lambda1 -0.42703807\n",
      "73 Train Loss 274.92038 Test MSE 276.786292355967 Test RE 0.2800666906856489 Lambda1 -0.43420815\n",
      "74 Train Loss 274.60532 Test MSE 276.77172550370295 Test RE 0.2800593208412989 Lambda1 -0.43296042\n",
      "Training time: 292.23\n",
      "Training time: 292.23\n",
      "inv_HT_tanh_tune2\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 1061.7477 Test MSE 1060.3243209069922 Test RE 0.5481615030932346 Lambda1 0.0050289445\n",
      "1 Train Loss 855.1823 Test MSE 858.3114323243186 Test RE 0.493186998620614 Lambda1 0.0064903083\n",
      "2 Train Loss 854.6977 Test MSE 858.0499617400283 Test RE 0.4931118722094661 Lambda1 0.006493933\n",
      "3 Train Loss 854.53906 Test MSE 857.710040425297 Test RE 0.49301418801419755 Lambda1 -0.011334063\n",
      "4 Train Loss 854.51556 Test MSE 857.6475717728458 Test RE 0.49299623410710697 Lambda1 -0.08587877\n",
      "5 Train Loss 853.1172 Test MSE 855.4806136244906 Test RE 0.4923730306510807 Lambda1 -1.2577523\n",
      "6 Train Loss 845.14764 Test MSE 842.7185623601515 Test RE 0.48868662255943746 Lambda1 -0.782922\n",
      "7 Train Loss 831.0224 Test MSE 826.4018074377152 Test RE 0.48393251150287586 Lambda1 -1.0743535\n",
      "8 Train Loss 816.9299 Test MSE 810.6218851378924 Test RE 0.4792899614455964 Lambda1 -1.2534432\n",
      "9 Train Loss 794.4422 Test MSE 797.2991423258933 Test RE 0.47533502793490406 Lambda1 -1.7963135\n",
      "10 Train Loss 784.7678 Test MSE 787.0055342197422 Test RE 0.4722566301179199 Lambda1 -1.8587348\n",
      "11 Train Loss 771.7882 Test MSE 767.3918118176842 Test RE 0.4663347199088391 Lambda1 -1.409753\n",
      "12 Train Loss 757.84985 Test MSE 759.2928490490169 Test RE 0.46386737177026083 Lambda1 -1.2803149\n",
      "13 Train Loss 749.4551 Test MSE 751.197745589485 Test RE 0.4613880144387108 Lambda1 -1.2296398\n",
      "14 Train Loss 743.025 Test MSE 739.5999428406777 Test RE 0.45781245648805036 Lambda1 -1.2484611\n",
      "15 Train Loss 732.778 Test MSE 728.3517206731123 Test RE 0.4543177929541845 Lambda1 -1.3008926\n",
      "16 Train Loss 722.0869 Test MSE 716.250599892224 Test RE 0.4505278783552028 Lambda1 -1.3565056\n",
      "17 Train Loss 710.6931 Test MSE 712.3079803441594 Test RE 0.4492861962272935 Lambda1 -1.4313583\n",
      "18 Train Loss 704.20355 Test MSE 705.2332817258376 Test RE 0.4470494556624993 Lambda1 -1.5493599\n",
      "19 Train Loss 698.2314 Test MSE 699.1993684294266 Test RE 0.4451328896534427 Lambda1 -1.6339664\n",
      "20 Train Loss 688.7531 Test MSE 694.4827151593655 Test RE 0.4436289621984115 Lambda1 -1.5965241\n",
      "21 Train Loss 684.4013 Test MSE 689.1224824166494 Test RE 0.4419136130057283 Lambda1 -1.6264417\n",
      "22 Train Loss 679.81213 Test MSE 687.4384556778458 Test RE 0.4413733247639882 Lambda1 -1.6777091\n",
      "23 Train Loss 674.13074 Test MSE 679.7688521252891 Test RE 0.4389042649492537 Lambda1 -1.6844524\n",
      "24 Train Loss 669.99396 Test MSE 674.7110286648995 Test RE 0.43726838165617987 Lambda1 -1.7105985\n",
      "25 Train Loss 666.49664 Test MSE 670.5250628582692 Test RE 0.4359098457553573 Lambda1 -1.73666\n",
      "26 Train Loss 662.43756 Test MSE 668.3690735960323 Test RE 0.43520847478375735 Lambda1 -1.7030077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Train Loss 660.12213 Test MSE 667.8340894966843 Test RE 0.4350342624863576 Lambda1 -1.6639451\n",
      "28 Train Loss 658.57996 Test MSE 665.8122734630074 Test RE 0.4343752470438125 Lambda1 -1.6658874\n",
      "29 Train Loss 657.99225 Test MSE 664.6999524662979 Test RE 0.43401225683455547 Lambda1 -1.6710596\n",
      "30 Train Loss 656.5524 Test MSE 661.9847215163214 Test RE 0.43312490200063514 Lambda1 -1.6822565\n",
      "31 Train Loss 655.0783 Test MSE 660.87823559619 Test RE 0.43276277352624937 Lambda1 -1.7167598\n",
      "32 Train Loss 653.3794 Test MSE 660.580394275311 Test RE 0.43266524484787644 Lambda1 -1.7210463\n",
      "33 Train Loss 651.2367 Test MSE 658.9690428356897 Test RE 0.4321372232435903 Lambda1 -1.7130919\n",
      "34 Train Loss 649.6526 Test MSE 658.5015216238538 Test RE 0.43198390104466716 Lambda1 -1.7436465\n",
      "35 Train Loss 648.166 Test MSE 658.1590335277692 Test RE 0.4318715485434592 Lambda1 -1.7808026\n",
      "36 Train Loss 647.6611 Test MSE 657.8960669572309 Test RE 0.43178526307104403 Lambda1 -1.7930996\n",
      "37 Train Loss 647.1488 Test MSE 657.2432311770223 Test RE 0.4315709778312034 Lambda1 -1.7881519\n",
      "38 Train Loss 646.76044 Test MSE 656.9727316751596 Test RE 0.4314821585455829 Lambda1 -1.7975177\n",
      "39 Train Loss 646.57904 Test MSE 656.9362687941305 Test RE 0.4314701844558204 Lambda1 -1.7945856\n",
      "40 Train Loss 646.37665 Test MSE 656.9979236763802 Test RE 0.4314904311833497 Lambda1 -1.7868688\n",
      "41 Train Loss 644.83887 Test MSE 655.9596191927844 Test RE 0.4311493375643975 Lambda1 -1.7779379\n",
      "42 Train Loss 644.1736 Test MSE 655.3001127787086 Test RE 0.4309325427709508 Lambda1 -1.7762445\n",
      "43 Train Loss 643.57056 Test MSE 654.867533743275 Test RE 0.4307902849306023 Lambda1 -1.7822773\n",
      "44 Train Loss 643.33636 Test MSE 654.7651910527228 Test RE 0.43075662166496953 Lambda1 -1.7920175\n",
      "45 Train Loss 642.8698 Test MSE 654.3729764608588 Test RE 0.4306275873613542 Lambda1 -1.8084155\n",
      "46 Train Loss 642.0439 Test MSE 653.7332770883796 Test RE 0.4304170502792892 Lambda1 -1.8201034\n",
      "47 Train Loss 640.88654 Test MSE 652.7207181929624 Test RE 0.4300835874443049 Lambda1 -1.8674116\n",
      "48 Train Loss 640.4554 Test MSE 652.1286994984428 Test RE 0.4298884999607199 Lambda1 -1.9094776\n",
      "49 Train Loss 640.36835 Test MSE 651.8244974545802 Test RE 0.42978822204427924 Lambda1 -1.9234036\n",
      "50 Train Loss 639.87 Test MSE 650.6360169701634 Test RE 0.42939622391927307 Lambda1 -1.9751827\n",
      "51 Train Loss 639.0524 Test MSE 649.7072038518118 Test RE 0.4290896229367724 Lambda1 -2.0160835\n",
      "52 Train Loss 638.55597 Test MSE 649.1430059813058 Test RE 0.42890327435526104 Lambda1 -2.041535\n",
      "53 Train Loss 638.0945 Test MSE 647.8051044921191 Test RE 0.42846105569213694 Lambda1 -2.1134448\n",
      "54 Train Loss 637.61145 Test MSE 646.9610527367515 Test RE 0.4281818349971911 Lambda1 -2.1681538\n",
      "55 Train Loss 636.8246 Test MSE 646.154987836286 Test RE 0.4279150106503968 Lambda1 -2.2192411\n",
      "56 Train Loss 634.6047 Test MSE 644.0028387086984 Test RE 0.42720178777405265 Lambda1 -2.2814534\n",
      "57 Train Loss 633.2407 Test MSE 641.9149660286357 Test RE 0.42650872635624854 Lambda1 -2.3611455\n",
      "58 Train Loss 630.76166 Test MSE 639.9900939771259 Test RE 0.4258687731326713 Lambda1 -2.4501073\n",
      "59 Train Loss 629.3581 Test MSE 638.0800726737662 Test RE 0.4252328052898265 Lambda1 -2.5343604\n",
      "60 Train Loss 628.5149 Test MSE 636.3828122627446 Test RE 0.4246668799318964 Lambda1 -2.6186728\n",
      "61 Train Loss 627.5937 Test MSE 635.6845955179805 Test RE 0.4244338512458667 Lambda1 -2.658415\n",
      "62 Train Loss 626.6398 Test MSE 635.4030417052162 Test RE 0.4243398469196403 Lambda1 -2.6660268\n",
      "63 Train Loss 625.24084 Test MSE 634.2423426452467 Test RE 0.42395209618278235 Lambda1 -2.7358315\n",
      "64 Train Loss 623.68463 Test MSE 632.4753625178466 Test RE 0.42336112538226306 Lambda1 -2.7994368\n",
      "65 Train Loss 622.73926 Test MSE 630.9989568322636 Test RE 0.4228667045670575 Lambda1 -2.84823\n",
      "66 Train Loss 621.89667 Test MSE 629.6965256051908 Test RE 0.4224300641503911 Lambda1 -2.9044268\n",
      "67 Train Loss 619.50275 Test MSE 626.0742620986179 Test RE 0.42121331941190376 Lambda1 -3.0239134\n",
      "68 Train Loss 617.25775 Test MSE 623.0165915472663 Test RE 0.4201834831626619 Lambda1 -3.0817215\n",
      "69 Train Loss 615.8495 Test MSE 621.9011414696951 Test RE 0.4198071659980934 Lambda1 -3.090857\n",
      "70 Train Loss 614.737 Test MSE 620.5547697850592 Test RE 0.4193524934717513 Lambda1 -3.117257\n",
      "71 Train Loss 613.5089 Test MSE 620.6339356969428 Test RE 0.4193792416053781 Lambda1 -3.1009398\n",
      "72 Train Loss 612.10803 Test MSE 620.0995598073338 Test RE 0.41919865655921673 Lambda1 -3.1074266\n",
      "73 Train Loss 611.25854 Test MSE 620.0030513244584 Test RE 0.41916603453913936 Lambda1 -3.1208522\n",
      "74 Train Loss 610.2143 Test MSE 619.5815685259856 Test RE 0.41902353418473437 Lambda1 -3.1450846\n",
      "Training time: 299.81\n",
      "Training time: 299.81\n",
      "inv_HT_tanh_tune2\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 976.1761 Test MSE 975.8724563403063 Test RE 0.5258788454878616 Lambda1 -0.011420265\n",
      "1 Train Loss 855.0686 Test MSE 858.2293866438404 Test RE 0.49316342627355625 Lambda1 -0.013202033\n",
      "2 Train Loss 854.7182 Test MSE 858.0652267467104 Test RE 0.4931162585056504 Lambda1 -0.013282464\n",
      "3 Train Loss 854.71405 Test MSE 858.0855285510062 Test RE 0.4931220920310328 Lambda1 -0.013255204\n",
      "4 Train Loss 854.427 Test MSE 857.6434693472119 Test RE 0.4929950550197561 Lambda1 -0.0064400365\n",
      "5 Train Loss 848.62225 Test MSE 852.0922663395396 Test RE 0.4913969792735641 Lambda1 0.04429853\n",
      "6 Train Loss 767.24316 Test MSE 767.1451163808704 Test RE 0.46625975696754335 Lambda1 0.003753351\n",
      "7 Train Loss 696.8677 Test MSE 708.4737760033753 Test RE 0.44807535796330006 Lambda1 0.000497274\n",
      "8 Train Loss 680.94214 Test MSE 694.4338587648026 Test RE 0.4436133574235575 Lambda1 0.0008219795\n",
      "9 Train Loss 656.94006 Test MSE 675.0127974710327 Test RE 0.43736615625958297 Lambda1 0.000103467166\n",
      "10 Train Loss 644.4322 Test MSE 665.2406518025647 Test RE 0.4341887443118749 Lambda1 -7.674704e-05\n",
      "11 Train Loss 642.067 Test MSE 663.7561954363423 Test RE 0.4337040368542447 Lambda1 -7.487802e-05\n",
      "12 Train Loss 640.6352 Test MSE 662.4817040221051 Test RE 0.43328745493177934 Lambda1 -9.494683e-06\n",
      "13 Train Loss 634.58417 Test MSE 656.3636200494667 Test RE 0.4312820880303674 Lambda1 -1.7788016e-06\n",
      "14 Train Loss 625.89355 Test MSE 647.5854622167692 Test RE 0.42838841336587424 Lambda1 -4.6729445e-05\n",
      "15 Train Loss 624.54285 Test MSE 647.585135436262 Test RE 0.42838830528052585 Lambda1 -3.148803e-05\n",
      "16 Train Loss 623.78455 Test MSE 647.0147766022952 Test RE 0.42819961281062957 Lambda1 0.00015918036\n",
      "17 Train Loss 623.4579 Test MSE 646.9886724610554 Test RE 0.42819097475758866 Lambda1 0.0002635849\n",
      "18 Train Loss 623.27386 Test MSE 647.0064005894365 Test RE 0.4281968411451279 Lambda1 0.00023583423\n",
      "19 Train Loss 622.8665 Test MSE 646.3031119532408 Test RE 0.42796405530851844 Lambda1 4.827417e-05\n",
      "20 Train Loss 622.5712 Test MSE 645.448761984065 Test RE 0.42768109830055734 Lambda1 0.00011565343\n",
      "21 Train Loss 616.6924 Test MSE 637.7741841784572 Test RE 0.42513086713091724 Lambda1 0.0016299814\n",
      "22 Train Loss 607.96326 Test MSE 630.3397253575687 Test RE 0.42264575341789967 Lambda1 -0.00026056572\n",
      "23 Train Loss 577.52075 Test MSE 600.3263112465609 Test RE 0.41246097086676664 Lambda1 -2.1396962e-05\n",
      "24 Train Loss 519.09515 Test MSE 527.4605648821536 Test RE 0.38661986816784044 Lambda1 -0.0007089318\n",
      "25 Train Loss 430.2921 Test MSE 435.5250318083566 Test RE 0.3513142218591374 Lambda1 0.0002101193\n",
      "26 Train Loss 396.07635 Test MSE 396.5873843571528 Test RE 0.33524215067313606 Lambda1 1.9960207e-05\n",
      "27 Train Loss 381.844 Test MSE 379.4463677737593 Test RE 0.32791733107701404 Lambda1 -4.9858827e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 Train Loss 368.62338 Test MSE 369.13187534027526 Test RE 0.32342973518806867 Lambda1 -8.069877e-06\n",
      "29 Train Loss 338.87802 Test MSE 344.6691801493527 Test RE 0.3125290531472478 Lambda1 -3.282821e-05\n",
      "30 Train Loss 324.60486 Test MSE 330.945964233165 Test RE 0.3062440893183221 Lambda1 -5.8740065e-05\n",
      "31 Train Loss 314.78412 Test MSE 323.29782175562326 Test RE 0.30268476338815176 Lambda1 7.975223e-05\n",
      "32 Train Loss 300.6737 Test MSE 306.7970299092654 Test RE 0.2948592429050571 Lambda1 0.00010036823\n",
      "33 Train Loss 286.28625 Test MSE 291.16967051146713 Test RE 0.2872514556362916 Lambda1 0.00014017882\n",
      "34 Train Loss 281.7604 Test MSE 286.4215823677789 Test RE 0.2848997318586137 Lambda1 0.0001264567\n",
      "35 Train Loss 280.97873 Test MSE 286.29634531953883 Test RE 0.2848374392369023 Lambda1 6.9062866e-05\n",
      "36 Train Loss 278.57092 Test MSE 285.19823972979856 Test RE 0.2842906594950727 Lambda1 0.0003314747\n",
      "37 Train Loss 277.29868 Test MSE 284.13973388507486 Test RE 0.2837626003780315 Lambda1 0.00016012575\n",
      "38 Train Loss 276.57376 Test MSE 283.429336472609 Test RE 0.28340765112344546 Lambda1 -6.551804e-05\n",
      "39 Train Loss 275.21863 Test MSE 282.053914786045 Test RE 0.2827191566025067 Lambda1 1.2666524e-06\n",
      "40 Train Loss 274.23898 Test MSE 281.4711866903733 Test RE 0.28242695435260795 Lambda1 8.4888256e-05\n",
      "41 Train Loss 272.983 Test MSE 280.42746007402997 Test RE 0.2819028326710848 Lambda1 1.0328914e-05\n",
      "42 Train Loss 271.89166 Test MSE 279.73877431734013 Test RE 0.28155646536452406 Lambda1 0.00030618816\n",
      "43 Train Loss 271.3893 Test MSE 279.750081042415 Test RE 0.28156215540407464 Lambda1 0.0002985133\n",
      "44 Train Loss 271.02188 Test MSE 279.4163832012663 Test RE 0.28139417561535257 Lambda1 0.00024929034\n",
      "45 Train Loss 270.68192 Test MSE 279.2717753587049 Test RE 0.2813213504817599 Lambda1 0.00012725618\n",
      "46 Train Loss 270.59882 Test MSE 279.1841463846657 Test RE 0.2812772109775299 Lambda1 0.00012250115\n",
      "47 Train Loss 270.53174 Test MSE 279.0662088369878 Test RE 0.28121779383469403 Lambda1 0.00017264191\n",
      "48 Train Loss 270.47653 Test MSE 279.10649360923685 Test RE 0.2812380907850305 Lambda1 0.00017804265\n",
      "49 Train Loss 270.40018 Test MSE 279.11429001624316 Test RE 0.2812420187325341 Lambda1 0.0002233746\n",
      "50 Train Loss 270.31918 Test MSE 278.97334081411276 Test RE 0.2811709979260777 Lambda1 0.0002510552\n",
      "51 Train Loss 270.1958 Test MSE 279.11351510741935 Test RE 0.28124162832423005 Lambda1 0.00020052442\n",
      "52 Train Loss 270.14236 Test MSE 279.1547067532403 Test RE 0.2812623804152726 Lambda1 0.0002073552\n",
      "53 Train Loss 270.11356 Test MSE 279.028216562849 Test RE 0.28119865058689497 Lambda1 0.00023397627\n",
      "54 Train Loss 270.0702 Test MSE 279.04492201757165 Test RE 0.281207068160348 Lambda1 0.00020958285\n",
      "55 Train Loss 270.0372 Test MSE 279.0498212747503 Test RE 0.28120953675875554 Lambda1 0.00018816566\n",
      "56 Train Loss 270.02173 Test MSE 279.00215220813686 Test RE 0.2811855167314188 Lambda1 0.00018881114\n",
      "57 Train Loss 270.0076 Test MSE 279.0443355578863 Test RE 0.2812067726582938 Lambda1 0.0001673482\n",
      "58 Train Loss 269.99094 Test MSE 279.0745762277147 Test RE 0.2812220097545149 Lambda1 0.00015572716\n",
      "59 Train Loss 269.98334 Test MSE 279.0684352944788 Test RE 0.2812189156441339 Lambda1 0.00015526026\n",
      "60 Train Loss 269.95554 Test MSE 279.13766760854435 Test RE 0.281253796387465 Lambda1 0.00013624146\n",
      "61 Train Loss 269.9201 Test MSE 279.179492011242 Test RE 0.2812748663339517 Lambda1 0.00013271785\n",
      "62 Train Loss 269.91217 Test MSE 279.18701221706743 Test RE 0.2812786546327068 Lambda1 0.00013502222\n",
      "63 Train Loss 269.89398 Test MSE 279.2328161654259 Test RE 0.28130172723999297 Lambda1 0.00012673181\n",
      "64 Train Loss 269.8639 Test MSE 279.23518257739477 Test RE 0.2813029192101435 Lambda1 0.000114256414\n",
      "65 Train Loss 269.83942 Test MSE 279.20738624601563 Test RE 0.28128891778008175 Lambda1 0.00010240231\n",
      "66 Train Loss 269.8309 Test MSE 279.21773219133576 Test RE 0.28129412926972563 Lambda1 9.0287846e-05\n",
      "67 Train Loss 269.79337 Test MSE 279.2954555624125 Test RE 0.28133327722528284 Lambda1 8.475218e-05\n",
      "68 Train Loss 269.77975 Test MSE 279.30684824449315 Test RE 0.28133901506998804 Lambda1 7.8107005e-05\n",
      "69 Train Loss 269.77203 Test MSE 279.30213265717384 Test RE 0.28133664011158677 Lambda1 8.1916296e-05\n",
      "70 Train Loss 269.74677 Test MSE 279.24242553672747 Test RE 0.2813065674832106 Lambda1 7.3226605e-05\n",
      "71 Train Loss 269.7139 Test MSE 279.2635293370181 Test RE 0.2813171971814876 Lambda1 6.27055e-05\n",
      "72 Train Loss 269.6878 Test MSE 279.27961320204315 Test RE 0.28132529813669116 Lambda1 5.7063047e-05\n",
      "73 Train Loss 269.67496 Test MSE 279.2850617693407 Test RE 0.28132804236196024 Lambda1 5.5040524e-05\n",
      "74 Train Loss 269.6702 Test MSE 279.30863918807995 Test RE 0.28133991705556455 Lambda1 5.653294e-05\n",
      "Training time: 256.32\n",
      "Training time: 256.32\n",
      "inv_HT_tanh_tune2\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 917.4896 Test MSE 918.215206209342 Test RE 0.5101071500417641 Lambda1 -0.110988475\n",
      "1 Train Loss 854.9023 Test MSE 858.1196363643771 Test RE 0.4931318924230632 Lambda1 -0.12403928\n",
      "2 Train Loss 854.7242 Test MSE 858.0743914520777 Test RE 0.4931188919028638 Lambda1 -0.12472435\n",
      "3 Train Loss 854.72217 Test MSE 858.0871488760475 Test RE 0.4931225576126505 Lambda1 -0.124849014\n",
      "4 Train Loss 854.54504 Test MSE 857.7468163127894 Test RE 0.49302475734363876 Lambda1 -0.12773351\n",
      "5 Train Loss 854.3437 Test MSE 857.4497430101467 Test RE 0.49293937248761727 Lambda1 -0.121736415\n",
      "6 Train Loss 852.3438 Test MSE 851.8976257744401 Test RE 0.49134085199008354 Lambda1 -0.50782293\n",
      "7 Train Loss 838.54584 Test MSE 838.9528521600014 Test RE 0.4875935455278367 Lambda1 -0.7574639\n",
      "8 Train Loss 821.3907 Test MSE 823.9484338742463 Test RE 0.48321364224194036 Lambda1 -0.9609702\n",
      "9 Train Loss 806.2473 Test MSE 808.2848254653851 Test RE 0.4785985553951015 Lambda1 -1.1474291\n",
      "10 Train Loss 792.4944 Test MSE 793.414527005711 Test RE 0.47417564605456003 Lambda1 -1.191952\n",
      "11 Train Loss 762.6603 Test MSE 765.8518333764785 Test RE 0.4658665717907518 Lambda1 -1.2492237\n",
      "12 Train Loss 727.44055 Test MSE 717.78516202165 Test RE 0.45101024661184186 Lambda1 -1.3347164\n",
      "13 Train Loss 705.7287 Test MSE 704.7146979704204 Test RE 0.44688505954989444 Lambda1 -1.2883767\n",
      "14 Train Loss 687.4347 Test MSE 675.8107508264123 Test RE 0.43762459188768515 Lambda1 -1.2117412\n",
      "15 Train Loss 673.44543 Test MSE 672.6936693465728 Test RE 0.436614184691851 Lambda1 -1.0846695\n",
      "16 Train Loss 649.31305 Test MSE 650.0930596493668 Test RE 0.4292170204343037 Lambda1 -0.9236006\n",
      "17 Train Loss 624.06384 Test MSE 631.3788384984323 Test RE 0.4229939750928853 Lambda1 -0.82659507\n",
      "18 Train Loss 615.38055 Test MSE 621.6832213575143 Test RE 0.4197336073291453 Lambda1 -0.8362185\n",
      "19 Train Loss 610.95135 Test MSE 618.159658392491 Test RE 0.4185424384956459 Lambda1 -0.8069632\n",
      "20 Train Loss 608.2626 Test MSE 618.0797460417922 Test RE 0.418515384165348 Lambda1 -0.7784362\n",
      "21 Train Loss 603.82916 Test MSE 619.1083827399756 Test RE 0.4188634956509352 Lambda1 -0.78102255\n",
      "22 Train Loss 601.75256 Test MSE 618.2629795831592 Test RE 0.4185774152978817 Lambda1 -0.7741266\n",
      "23 Train Loss 600.6868 Test MSE 616.1988587477825 Test RE 0.41787810389828106 Lambda1 -0.78550726\n",
      "24 Train Loss 599.63495 Test MSE 614.598682987037 Test RE 0.4173351678945835 Lambda1 -0.80100244\n",
      "25 Train Loss 597.3856 Test MSE 608.4755648660827 Test RE 0.4152510525082198 Lambda1 -0.7921533\n",
      "26 Train Loss 591.2537 Test MSE 596.0473094395959 Test RE 0.41098837382782427 Lambda1 -0.76468265\n",
      "27 Train Loss 583.5473 Test MSE 579.242159812876 Test RE 0.4051531807067638 Lambda1 -0.7431349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 Train Loss 574.2333 Test MSE 568.7570923543374 Test RE 0.4014695241876584 Lambda1 -0.71548027\n",
      "29 Train Loss 561.4694 Test MSE 561.6014578764182 Test RE 0.398936050579964 Lambda1 -0.76763725\n",
      "30 Train Loss 549.1252 Test MSE 546.4377564544717 Test RE 0.3935133952675683 Lambda1 -0.8590627\n",
      "31 Train Loss 533.6268 Test MSE 529.218985480625 Test RE 0.38726377856000305 Lambda1 -0.8517682\n",
      "32 Train Loss 462.06937 Test MSE 434.97987510387253 Test RE 0.35109427896277123 Lambda1 -0.6386748\n",
      "33 Train Loss 410.30392 Test MSE 402.37955353378317 Test RE 0.33768138689244803 Lambda1 -0.55960375\n",
      "34 Train Loss 376.14813 Test MSE 364.6004654070687 Test RE 0.3214384165218355 Lambda1 -0.51997316\n",
      "35 Train Loss 351.6122 Test MSE 337.91431580779937 Test RE 0.30945141023236994 Lambda1 -0.51348925\n",
      "36 Train Loss 326.1882 Test MSE 316.7561734393897 Test RE 0.2996068334511686 Lambda1 -0.48344165\n",
      "37 Train Loss 308.12198 Test MSE 295.0138052400089 Test RE 0.28914144048226753 Lambda1 -0.49573687\n",
      "38 Train Loss 301.52637 Test MSE 289.6496801179013 Test RE 0.28650070648603676 Lambda1 -0.51473534\n",
      "39 Train Loss 294.25015 Test MSE 287.1094192396487 Test RE 0.2852416178093254 Lambda1 -0.51711124\n",
      "40 Train Loss 290.3931 Test MSE 285.2680579007273 Test RE 0.2843254553606772 Lambda1 -0.4916157\n",
      "41 Train Loss 287.51712 Test MSE 282.80646953766524 Test RE 0.28309607020650646 Lambda1 -0.46913013\n",
      "42 Train Loss 285.5013 Test MSE 281.90433414554855 Test RE 0.2826441799427617 Lambda1 -0.4530538\n",
      "43 Train Loss 283.40942 Test MSE 281.7436863643521 Test RE 0.28256363376879534 Lambda1 -0.45044008\n",
      "44 Train Loss 280.55258 Test MSE 280.14933237919024 Test RE 0.28176300250762065 Lambda1 -0.4531608\n",
      "45 Train Loss 279.3049 Test MSE 279.43594077671634 Test RE 0.2814040234479306 Lambda1 -0.45284572\n",
      "46 Train Loss 278.80493 Test MSE 279.2702084837862 Test RE 0.28132056129354727 Lambda1 -0.4473694\n",
      "47 Train Loss 277.31653 Test MSE 278.1660363889454 Test RE 0.28076387112519846 Lambda1 -0.42785114\n",
      "48 Train Loss 276.78146 Test MSE 277.6946779645779 Test RE 0.2805258900103692 Lambda1 -0.4230251\n",
      "49 Train Loss 275.784 Test MSE 276.66699778705004 Test RE 0.2800063299727148 Lambda1 -0.4089646\n",
      "50 Train Loss 275.02902 Test MSE 275.1948833797777 Test RE 0.27926039507834133 Lambda1 -0.3998285\n",
      "51 Train Loss 272.80667 Test MSE 270.71501073353437 Test RE 0.27697804103480295 Lambda1 -0.3978481\n",
      "52 Train Loss 270.34885 Test MSE 268.6297072986345 Test RE 0.2759092051457972 Lambda1 -0.40459746\n",
      "53 Train Loss 265.8036 Test MSE 263.6795616132268 Test RE 0.273355240776887 Lambda1 -0.42798308\n",
      "54 Train Loss 261.761 Test MSE 260.05206303527035 Test RE 0.27146842443700936 Lambda1 -0.460853\n",
      "55 Train Loss 257.04514 Test MSE 256.0321245625005 Test RE 0.2693620450493786 Lambda1 -0.49250308\n",
      "56 Train Loss 253.80788 Test MSE 252.78636554448437 Test RE 0.26764922707492944 Lambda1 -0.48424962\n",
      "57 Train Loss 247.87672 Test MSE 246.62284364725653 Test RE 0.26436613462802694 Lambda1 -0.5079068\n",
      "58 Train Loss 240.4443 Test MSE 234.74382094678873 Test RE 0.2579207335559283 Lambda1 -0.5872199\n",
      "59 Train Loss 236.3491 Test MSE 230.68817328661711 Test RE 0.2556829895833535 Lambda1 -0.57175994\n",
      "60 Train Loss 231.08182 Test MSE 223.36688375125252 Test RE 0.25159300555548364 Lambda1 -0.571688\n",
      "61 Train Loss 226.73491 Test MSE 213.66531540084202 Test RE 0.2460685922905215 Lambda1 -0.6113592\n",
      "62 Train Loss 222.83653 Test MSE 208.33340958864508 Test RE 0.24297893905642412 Lambda1 -0.6228862\n",
      "63 Train Loss 219.08968 Test MSE 205.86009256545535 Test RE 0.24153231975783132 Lambda1 -0.6183169\n",
      "64 Train Loss 212.6612 Test MSE 197.88887477223042 Test RE 0.23680990313254124 Lambda1 -0.6700748\n",
      "65 Train Loss 204.81596 Test MSE 195.29982088949276 Test RE 0.2352556666317448 Lambda1 -0.7185258\n",
      "66 Train Loss 201.3294 Test MSE 193.32024641754705 Test RE 0.23406034490171068 Lambda1 -0.7592273\n",
      "67 Train Loss 198.02292 Test MSE 187.44254004619305 Test RE 0.23047469611471863 Lambda1 -0.7815512\n",
      "68 Train Loss 196.59315 Test MSE 184.65745340430607 Test RE 0.22875605145389008 Lambda1 -0.8017261\n",
      "69 Train Loss 193.97375 Test MSE 182.17224241763148 Test RE 0.22721148112945308 Lambda1 -0.84452426\n",
      "70 Train Loss 188.19922 Test MSE 175.3173512076011 Test RE 0.22289566433610672 Lambda1 -0.8795807\n",
      "71 Train Loss 184.83777 Test MSE 171.1838285663405 Test RE 0.22025234361348509 Lambda1 -0.8748647\n",
      "72 Train Loss 182.54817 Test MSE 171.68302127423578 Test RE 0.22057325104303863 Lambda1 -0.8737483\n",
      "73 Train Loss 180.97594 Test MSE 169.29137036648103 Test RE 0.21903150177414707 Lambda1 -0.8771924\n",
      "74 Train Loss 178.72778 Test MSE 165.78863481361125 Test RE 0.2167537143075631 Lambda1 -0.8918584\n",
      "Training time: 257.47\n",
      "Training time: 257.47\n",
      "inv_HT_tanh_tune2\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 881.1246 Test MSE 882.7748628026835 Test RE 0.5001659809715787 Lambda1 0.022923015\n",
      "1 Train Loss 854.80176 Test MSE 858.064522312589 Test RE 0.49311605609213977 Lambda1 0.025597308\n",
      "2 Train Loss 854.72076 Test MSE 858.073138380595 Test RE 0.49311853184466076 Lambda1 0.025752878\n",
      "3 Train Loss 854.71967 Test MSE 858.0839263870783 Test RE 0.4931216316673684 Lambda1 0.025809916\n",
      "4 Train Loss 854.4549 Test MSE 857.6214827892005 Test RE 0.49298873576575736 Lambda1 -0.007296202\n",
      "5 Train Loss 852.4728 Test MSE 853.446596595728 Test RE 0.49178734167224974 Lambda1 -0.6735306\n",
      "6 Train Loss 837.3362 Test MSE 836.5895551451144 Test RE 0.4869062953274586 Lambda1 -0.69681925\n",
      "7 Train Loss 821.1722 Test MSE 816.3726484368564 Test RE 0.4809870609106641 Lambda1 -0.45287314\n",
      "8 Train Loss 807.49176 Test MSE 802.7886162639418 Test RE 0.47696858247112095 Lambda1 -0.40419644\n",
      "9 Train Loss 786.1534 Test MSE 783.746401501869 Test RE 0.47127776545481664 Lambda1 -0.45202446\n",
      "10 Train Loss 768.8471 Test MSE 769.9902703019508 Test RE 0.46712357857836184 Lambda1 -0.54221475\n",
      "11 Train Loss 745.46045 Test MSE 745.5283150098697 Test RE 0.4596436258647509 Lambda1 -0.5224034\n",
      "12 Train Loss 725.1316 Test MSE 725.241041831806 Test RE 0.4533465939675106 Lambda1 -0.515045\n",
      "13 Train Loss 714.89624 Test MSE 713.1913022942007 Test RE 0.44956468629748686 Lambda1 -0.4973532\n",
      "14 Train Loss 695.084 Test MSE 695.4022915219193 Test RE 0.44392257335978175 Lambda1 -0.43882948\n",
      "15 Train Loss 687.62946 Test MSE 694.2845700942771 Test RE 0.4435656710908514 Lambda1 -0.42812046\n",
      "16 Train Loss 677.9414 Test MSE 688.6100997831305 Test RE 0.4417492946360875 Lambda1 -0.42245248\n",
      "17 Train Loss 671.7018 Test MSE 680.9286274353847 Test RE 0.4392785196648039 Lambda1 -0.3947239\n",
      "18 Train Loss 665.3235 Test MSE 675.8364913925514 Test RE 0.4376329260237403 Lambda1 -0.39269212\n",
      "19 Train Loss 660.2315 Test MSE 669.464288577702 Test RE 0.43556490340789894 Lambda1 -0.38240433\n",
      "20 Train Loss 654.47736 Test MSE 665.4793436001627 Test RE 0.4342666319130487 Lambda1 -0.35841256\n",
      "21 Train Loss 652.62115 Test MSE 663.2727812572376 Test RE 0.43354607458590994 Lambda1 -0.3606189\n",
      "22 Train Loss 650.1975 Test MSE 662.1654345643144 Test RE 0.43318401664303474 Lambda1 -0.35462674\n",
      "23 Train Loss 648.91815 Test MSE 661.1478930125747 Test RE 0.43285105438008303 Lambda1 -0.3452386\n",
      "24 Train Loss 646.0543 Test MSE 659.5239525727876 Test RE 0.43231913367946856 Lambda1 -0.35500598\n",
      "25 Train Loss 644.09045 Test MSE 658.602708436067 Test RE 0.4320170895745205 Lambda1 -0.3680355\n",
      "26 Train Loss 642.4831 Test MSE 658.2431981118897 Test RE 0.43189916126732636 Lambda1 -0.37503928\n",
      "27 Train Loss 641.3263 Test MSE 657.4311554556225 Test RE 0.43163267254654913 Lambda1 -0.36999226\n",
      "28 Train Loss 640.431 Test MSE 656.2863755526749 Test RE 0.4312567094543357 Lambda1 -0.35898003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Train Loss 639.7449 Test MSE 655.6562342913716 Test RE 0.43104962157323273 Lambda1 -0.34985334\n",
      "30 Train Loss 639.39905 Test MSE 654.9783913907685 Test RE 0.4308267460270681 Lambda1 -0.35063592\n",
      "31 Train Loss 639.02985 Test MSE 654.3892787711084 Test RE 0.43063295141294317 Lambda1 -0.35036892\n",
      "32 Train Loss 638.56104 Test MSE 654.2878754406403 Test RE 0.43059958495302403 Lambda1 -0.33935428\n",
      "33 Train Loss 637.9715 Test MSE 653.6517549583898 Test RE 0.43039021241595365 Lambda1 -0.33144674\n",
      "34 Train Loss 637.30096 Test MSE 652.8437042953802 Test RE 0.4301241038637309 Lambda1 -0.33925632\n",
      "35 Train Loss 636.45044 Test MSE 651.2621691502294 Test RE 0.42960279312108646 Lambda1 -0.35265824\n",
      "36 Train Loss 634.72363 Test MSE 649.7176710454388 Test RE 0.4290930793753423 Lambda1 -0.37114397\n",
      "37 Train Loss 632.9366 Test MSE 647.7130004073489 Test RE 0.4284305955923939 Lambda1 -0.37665737\n",
      "38 Train Loss 632.0946 Test MSE 646.058771631997 Test RE 0.4278831499577823 Lambda1 -0.38567972\n",
      "39 Train Loss 630.30804 Test MSE 641.3156478087457 Test RE 0.4263095768153529 Lambda1 -0.4018244\n",
      "40 Train Loss 623.56177 Test MSE 631.3804073242177 Test RE 0.4229945006121161 Lambda1 -0.41338864\n",
      "41 Train Loss 617.4162 Test MSE 626.5842235513592 Test RE 0.4213848316795864 Lambda1 -0.4299847\n",
      "42 Train Loss 611.70154 Test MSE 622.9558450375304 Test RE 0.42016299791185474 Lambda1 -0.4476264\n",
      "43 Train Loss 605.7436 Test MSE 618.3790568299734 Test RE 0.4186167068576465 Lambda1 -0.43405673\n",
      "44 Train Loss 602.11035 Test MSE 612.9130993846943 Test RE 0.4167624882613121 Lambda1 -0.43942437\n",
      "45 Train Loss 598.1662 Test MSE 603.9736449414778 Test RE 0.4137120443932498 Lambda1 -0.44313505\n",
      "46 Train Loss 587.6349 Test MSE 590.6367405903883 Test RE 0.4091187653163095 Lambda1 -0.43999133\n",
      "47 Train Loss 557.1823 Test MSE 540.3052664770171 Test RE 0.39129902970742547 Lambda1 -0.40420267\n",
      "48 Train Loss 516.4883 Test MSE 487.49976516507456 Test RE 0.37168614794592486 Lambda1 -0.42638192\n",
      "49 Train Loss 466.6375 Test MSE 448.77995932405656 Test RE 0.3566201661961758 Lambda1 -0.43667808\n",
      "50 Train Loss 432.7798 Test MSE 420.4777923482327 Test RE 0.3451919842187553 Lambda1 -0.4072801\n",
      "51 Train Loss 413.98465 Test MSE 411.5166394984633 Test RE 0.34149383742496814 Lambda1 -0.38102123\n",
      "52 Train Loss 400.4047 Test MSE 395.1186521730147 Test RE 0.3346208025467739 Lambda1 -0.3691008\n",
      "53 Train Loss 390.04486 Test MSE 380.78605616142016 Test RE 0.3284956999877907 Lambda1 -0.39625385\n",
      "54 Train Loss 377.72452 Test MSE 368.07118429774516 Test RE 0.3229647173401281 Lambda1 -0.4241563\n",
      "55 Train Loss 364.2665 Test MSE 352.5456143142155 Test RE 0.3160798632890914 Lambda1 -0.42465678\n",
      "56 Train Loss 350.74478 Test MSE 337.1840557129645 Test RE 0.30911685465427097 Lambda1 -0.41936758\n",
      "57 Train Loss 343.74103 Test MSE 331.7195088471541 Test RE 0.30660178396610255 Lambda1 -0.41961712\n",
      "58 Train Loss 335.5345 Test MSE 324.9742891727915 Test RE 0.303468537624951 Lambda1 -0.42832738\n",
      "59 Train Loss 325.00656 Test MSE 316.473426590229 Test RE 0.29947308420164925 Lambda1 -0.46477684\n",
      "60 Train Loss 315.73785 Test MSE 305.6064865763078 Test RE 0.29428657776453526 Lambda1 -0.5145441\n",
      "61 Train Loss 302.17743 Test MSE 293.14805057440356 Test RE 0.2882256822582863 Lambda1 -0.580416\n",
      "62 Train Loss 291.95575 Test MSE 289.3046124958151 Test RE 0.28632999754668265 Lambda1 -0.6633009\n",
      "63 Train Loss 288.39307 Test MSE 288.07738554265734 Test RE 0.28572204779768445 Lambda1 -0.67281884\n",
      "64 Train Loss 283.32248 Test MSE 284.0388877861137 Test RE 0.2837122397852909 Lambda1 -0.69434875\n",
      "65 Train Loss 279.74402 Test MSE 280.38230987570586 Test RE 0.281880137887276 Lambda1 -0.7433436\n",
      "66 Train Loss 277.02173 Test MSE 277.4433081479084 Test RE 0.28039889494687614 Lambda1 -0.76702094\n",
      "67 Train Loss 273.09363 Test MSE 272.33658588796953 Test RE 0.27780634776653795 Lambda1 -0.7763299\n",
      "68 Train Loss 266.77414 Test MSE 262.03772805168245 Test RE 0.2725028716692485 Lambda1 -0.76169634\n",
      "69 Train Loss 261.45456 Test MSE 257.60670934094253 Test RE 0.27018905703956303 Lambda1 -0.7368833\n",
      "70 Train Loss 255.78459 Test MSE 250.94632338414104 Test RE 0.26667333317390385 Lambda1 -0.7523104\n",
      "71 Train Loss 248.57098 Test MSE 239.78425784435458 Test RE 0.26067507338549284 Lambda1 -0.7652974\n",
      "72 Train Loss 241.88849 Test MSE 229.6941170109413 Test RE 0.25513151424885866 Lambda1 -0.75698924\n",
      "73 Train Loss 237.71921 Test MSE 225.08328200703855 Test RE 0.2525578025416333 Lambda1 -0.7501912\n",
      "74 Train Loss 236.14995 Test MSE 222.7752612135448 Test RE 0.25125959269098147 Lambda1 -0.743288\n",
      "Training time: 297.69\n",
      "Training time: 297.69\n",
      "inv_HT_tanh_tune2\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 878.05365 Test MSE 879.8058338577204 Test RE 0.49932417063602613 Lambda1 0.0015862046\n",
      "1 Train Loss 854.78467 Test MSE 858.054469043588 Test RE 0.49311316735664706 Lambda1 0.0017211621\n",
      "2 Train Loss 854.71423 Test MSE 858.0687439145709 Test RE 0.49311726913446063 Lambda1 0.0017221755\n",
      "3 Train Loss 854.53424 Test MSE 857.7677519964976 Test RE 0.49303077412341645 Lambda1 0.0011424981\n",
      "4 Train Loss 853.7298 Test MSE 856.944108952159 Test RE 0.492794009046169 Lambda1 -0.316469\n",
      "5 Train Loss 847.10126 Test MSE 843.5221017265156 Test RE 0.48891955048786717 Lambda1 -0.5793136\n",
      "6 Train Loss 827.4766 Test MSE 829.7796708978208 Test RE 0.48492052420368964 Lambda1 -0.665021\n",
      "7 Train Loss 811.7253 Test MSE 812.9731711236681 Test RE 0.47998457120652654 Lambda1 -0.85671926\n",
      "8 Train Loss 790.9654 Test MSE 793.5791213640731 Test RE 0.47422482752671 Lambda1 -1.0776122\n",
      "9 Train Loss 769.3834 Test MSE 765.2459799330334 Test RE 0.465682265442731 Lambda1 -1.2350905\n",
      "10 Train Loss 729.89374 Test MSE 732.910554327394 Test RE 0.45573738762608457 Lambda1 -1.1476209\n",
      "11 Train Loss 690.48474 Test MSE 688.7282824548768 Test RE 0.44178720060935156 Lambda1 -1.2899655\n",
      "12 Train Loss 670.65344 Test MSE 673.009649799519 Test RE 0.43671671676325596 Lambda1 -1.3066658\n",
      "13 Train Loss 643.378 Test MSE 651.9998785359553 Test RE 0.4298460379547515 Lambda1 -1.3463215\n",
      "14 Train Loss 625.8228 Test MSE 631.8840561813654 Test RE 0.4231631772339401 Lambda1 -1.4075025\n",
      "15 Train Loss 613.61304 Test MSE 624.8726829685612 Test RE 0.420808923129935 Lambda1 -1.4672074\n",
      "16 Train Loss 605.1813 Test MSE 621.103454913628 Test RE 0.4195378450711581 Lambda1 -1.4757135\n",
      "17 Train Loss 603.2833 Test MSE 620.906521521121 Test RE 0.41947132832530465 Lambda1 -1.4854282\n",
      "18 Train Loss 602.71063 Test MSE 621.1025497118509 Test RE 0.41953753935192695 Lambda1 -1.4946679\n",
      "19 Train Loss 602.48193 Test MSE 620.7905293364515 Test RE 0.4194321455605522 Lambda1 -1.4967027\n",
      "20 Train Loss 602.1614 Test MSE 620.8044967405294 Test RE 0.41943686401632063 Lambda1 -1.4847097\n",
      "21 Train Loss 601.7723 Test MSE 620.8913168522406 Test RE 0.41946619231732524 Lambda1 -1.4748104\n",
      "22 Train Loss 601.5062 Test MSE 620.4356080795899 Test RE 0.4193122285669592 Lambda1 -1.4723237\n",
      "23 Train Loss 601.34784 Test MSE 620.2875664076158 Test RE 0.4192621996953183 Lambda1 -1.4562342\n",
      "24 Train Loss 601.10815 Test MSE 620.1944830451833 Test RE 0.41923074025486495 Lambda1 -1.4531877\n",
      "25 Train Loss 600.67554 Test MSE 619.403804840376 Test RE 0.4189634190077269 Lambda1 -1.4466549\n",
      "26 Train Loss 600.39844 Test MSE 618.4886372768317 Test RE 0.41865379589976903 Lambda1 -1.427339\n",
      "27 Train Loss 600.16724 Test MSE 617.6378633743485 Test RE 0.4183657531823837 Lambda1 -1.4183618\n",
      "28 Train Loss 599.5109 Test MSE 616.7223277587289 Test RE 0.41805556268241556 Lambda1 -1.436125\n",
      "29 Train Loss 597.147 Test MSE 613.8570001074329 Test RE 0.4170832768659453 Lambda1 -1.4656988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 593.9532 Test MSE 608.0322527227528 Test RE 0.4150997568881145 Lambda1 -1.4920381\n",
      "31 Train Loss 589.52026 Test MSE 596.5383366451815 Test RE 0.41115762627164104 Lambda1 -1.5064931\n",
      "32 Train Loss 584.22046 Test MSE 591.8448475212984 Test RE 0.40953696375946397 Lambda1 -1.375371\n",
      "33 Train Loss 578.9812 Test MSE 587.7953668563314 Test RE 0.4081335059627864 Lambda1 -1.2202448\n",
      "34 Train Loss 570.1476 Test MSE 577.8977779854698 Test RE 0.40468274103555274 Lambda1 -1.1826429\n",
      "35 Train Loss 562.54565 Test MSE 563.7947695632776 Test RE 0.3997143057317355 Lambda1 -1.1651422\n",
      "36 Train Loss 552.6693 Test MSE 539.7125811454347 Test RE 0.3910843540003851 Lambda1 -1.0972934\n",
      "37 Train Loss 529.4397 Test MSE 519.4601219045016 Test RE 0.3836765684648991 Lambda1 -1.1197699\n",
      "38 Train Loss 486.12418 Test MSE 476.7915191757694 Test RE 0.36758131879311473 Lambda1 -1.230951\n",
      "39 Train Loss 464.93747 Test MSE 462.0791265556097 Test RE 0.3618656384761626 Lambda1 -1.2199792\n",
      "40 Train Loss 434.56027 Test MSE 425.9147258694292 Test RE 0.34741654628796403 Lambda1 -1.1401802\n",
      "41 Train Loss 400.21622 Test MSE 386.9749435567831 Test RE 0.33115444848641273 Lambda1 -1.0957516\n",
      "42 Train Loss 366.8076 Test MSE 353.3101492467697 Test RE 0.3164224050985474 Lambda1 -1.0822436\n",
      "43 Train Loss 354.1352 Test MSE 342.91953398100355 Test RE 0.31173479736633736 Lambda1 -1.1085638\n",
      "44 Train Loss 338.17978 Test MSE 320.59029107928603 Test RE 0.30141464759907055 Lambda1 -1.1225898\n",
      "45 Train Loss 325.22562 Test MSE 304.62844541695955 Test RE 0.2938152935301875 Lambda1 -1.1248295\n",
      "46 Train Loss 314.9691 Test MSE 303.25120080641875 Test RE 0.29315036229873515 Lambda1 -1.1410998\n",
      "47 Train Loss 308.8867 Test MSE 300.3361618829173 Test RE 0.29173798825390745 Lambda1 -1.1262317\n",
      "48 Train Loss 302.0541 Test MSE 293.92913257071757 Test RE 0.2886094100864089 Lambda1 -1.0834465\n",
      "49 Train Loss 300.11032 Test MSE 292.8793634674559 Test RE 0.2880935642417501 Lambda1 -1.0644263\n",
      "50 Train Loss 297.07092 Test MSE 292.31212789854476 Test RE 0.2878144457060084 Lambda1 -1.0123129\n",
      "51 Train Loss 294.05322 Test MSE 289.930330628818 Test RE 0.28663947256709954 Lambda1 -0.9616193\n",
      "52 Train Loss 292.52664 Test MSE 289.0401035382321 Test RE 0.2861990729688757 Lambda1 -0.9353742\n",
      "53 Train Loss 290.92444 Test MSE 289.47827376914256 Test RE 0.2864159225026272 Lambda1 -0.90333325\n",
      "54 Train Loss 289.9843 Test MSE 288.5146108310657 Test RE 0.2859387908435025 Lambda1 -0.87204736\n",
      "55 Train Loss 288.70187 Test MSE 287.6239475847125 Test RE 0.2854970939314778 Lambda1 -0.8350382\n",
      "56 Train Loss 288.0993 Test MSE 287.50472883219015 Test RE 0.28543791920801154 Lambda1 -0.81868404\n",
      "57 Train Loss 287.28262 Test MSE 286.8670684483714 Test RE 0.28512120530931556 Lambda1 -0.7986164\n",
      "58 Train Loss 285.13287 Test MSE 285.3416153925785 Test RE 0.2843621102169674 Lambda1 -0.71152943\n",
      "59 Train Loss 283.6745 Test MSE 283.80366191479305 Test RE 0.28359473777359984 Lambda1 -0.6628354\n",
      "60 Train Loss 280.96024 Test MSE 281.18553236213864 Test RE 0.28228360582352596 Lambda1 -0.5986772\n",
      "61 Train Loss 278.9 Test MSE 279.7835810159709 Test RE 0.28157901338381636 Lambda1 -0.5598153\n",
      "62 Train Loss 276.65485 Test MSE 277.6955125811308 Test RE 0.2805263115729592 Lambda1 -0.50603086\n",
      "63 Train Loss 275.5287 Test MSE 276.81755780090265 Test RE 0.2800825082363611 Lambda1 -0.4827202\n",
      "64 Train Loss 274.68094 Test MSE 276.39240936496805 Test RE 0.27986734414567044 Lambda1 -0.46848506\n",
      "65 Train Loss 273.78644 Test MSE 275.74112779159145 Test RE 0.27953741477735716 Lambda1 -0.45134214\n",
      "66 Train Loss 273.32452 Test MSE 275.20854925518375 Test RE 0.27926732887438527 Lambda1 -0.44137612\n",
      "67 Train Loss 272.85916 Test MSE 274.5280248981693 Test RE 0.27892183479132543 Lambda1 -0.42306504\n",
      "68 Train Loss 272.3253 Test MSE 273.6823671253496 Test RE 0.2784919072025099 Lambda1 -0.40588602\n",
      "69 Train Loss 270.94366 Test MSE 271.92416174322784 Test RE 0.277595914314552 Lambda1 -0.3910559\n",
      "70 Train Loss 268.06674 Test MSE 268.0514734551974 Test RE 0.2756120935791106 Lambda1 -0.3808954\n",
      "71 Train Loss 266.0852 Test MSE 265.52065061004555 Test RE 0.2743079044553482 Lambda1 -0.3902966\n",
      "72 Train Loss 264.76434 Test MSE 263.7321194428075 Test RE 0.27338248263480935 Lambda1 -0.39628118\n",
      "73 Train Loss 261.41016 Test MSE 257.67905189937994 Test RE 0.2702269923783293 Lambda1 -0.41089422\n",
      "74 Train Loss 256.97144 Test MSE 249.34521302008437 Test RE 0.26582124523181744 Lambda1 -0.42325133\n",
      "Training time: 294.60\n",
      "Training time: 294.60\n",
      "inv_HT_tanh_tune3\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 854.83856 Test MSE 858.0819589487538 Test RE 0.49312106634565395 Lambda1 -0.0687016\n",
      "1 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "2 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "3 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "4 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "5 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "6 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "7 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "8 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "9 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "10 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "11 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "12 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "13 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "14 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "15 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "16 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "17 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "18 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "19 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "20 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "21 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "22 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "23 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "24 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "25 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "26 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "27 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "28 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "29 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "31 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "32 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "33 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "34 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "35 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "36 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "37 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "38 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "39 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "40 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "41 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "42 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "43 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "44 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "45 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "46 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "47 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "48 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "49 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "50 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "51 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "52 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "53 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "54 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "55 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "56 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "57 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "58 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "59 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "60 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "61 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "62 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "63 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "64 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "65 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "66 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "67 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "68 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "69 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "70 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "71 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "72 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "73 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "74 Train Loss 854.72107 Test MSE 858.0785913132843 Test RE 0.49312009869122064 Lambda1 -0.069059156\n",
      "Training time: 246.13\n",
      "Training time: 246.13\n",
      "inv_HT_tanh_tune3\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 854.77356 Test MSE 858.054227109265 Test RE 0.49311309783832813 Lambda1 -0.078024566\n",
      "1 Train Loss 854.7204 Test MSE 858.078866102663 Test RE 0.4931201776491134 Lambda1 -0.07830658\n",
      "2 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "3 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "4 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "5 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "6 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "7 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "8 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "9 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "10 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "11 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "12 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "13 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "14 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "15 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "16 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "17 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "18 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "19 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "20 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "21 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "22 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "23 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "24 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "25 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "26 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "27 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "28 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "29 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "31 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "32 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "33 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "34 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "35 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "36 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "37 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "38 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "39 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "40 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "41 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "42 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "43 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "44 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "45 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "46 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "47 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "48 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "49 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "50 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "51 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "52 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "53 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "54 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "55 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "56 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "57 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "58 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "59 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "60 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "61 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "62 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "63 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "64 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "65 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "66 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "67 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "68 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "69 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "70 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "71 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "72 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "73 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "74 Train Loss 854.67664 Test MSE 857.9973889389717 Test RE 0.49309676547290066 Lambda1 -0.07849782\n",
      "Training time: 242.22\n",
      "Training time: 242.22\n",
      "inv_HT_tanh_tune3\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 854.736 Test MSE 858.064458767269 Test RE 0.49311603783289626 Lambda1 -0.20808835\n",
      "1 Train Loss 854.7167 Test MSE 858.085960305543 Test RE 0.49312221609073703 Lambda1 -0.20838381\n",
      "2 Train Loss 854.39355 Test MSE 857.47861615026 Test RE 0.4929476718590216 Lambda1 -0.21461403\n",
      "3 Train Loss 853.1511 Test MSE 855.7669802817031 Test RE 0.49245543311524625 Lambda1 -0.40967476\n",
      "4 Train Loss 849.67505 Test MSE 852.035569517526 Test RE 0.49138063062703935 Lambda1 -0.49030367\n",
      "5 Train Loss 839.4955 Test MSE 842.9095492448464 Test RE 0.4887419954041564 Lambda1 -0.5665998\n",
      "6 Train Loss 827.5543 Test MSE 831.3471246697382 Test RE 0.48537831554112837 Lambda1 -0.5418039\n",
      "7 Train Loss 816.9448 Test MSE 817.2920074846795 Test RE 0.4812578167850004 Lambda1 -0.60293484\n",
      "8 Train Loss 804.2699 Test MSE 805.7654653412856 Test RE 0.4778520962810532 Lambda1 -0.5931196\n",
      "9 Train Loss 788.06354 Test MSE 792.289052764182 Test RE 0.4738392129240701 Lambda1 -0.6552197\n",
      "10 Train Loss 778.07074 Test MSE 782.5074505636541 Test RE 0.4709051187891851 Lambda1 -0.6444482\n",
      "11 Train Loss 773.9988 Test MSE 775.7357103488806 Test RE 0.4688631087533813 Lambda1 -0.6331345\n",
      "12 Train Loss 767.6878 Test MSE 765.3139775387643 Test RE 0.46570295459139766 Lambda1 -0.64666307\n",
      "13 Train Loss 761.01184 Test MSE 758.8792787609294 Test RE 0.4637410253329523 Lambda1 -0.66729736\n",
      "14 Train Loss 756.722 Test MSE 759.9708028194483 Test RE 0.46407441340603794 Lambda1 -0.69752467\n",
      "15 Train Loss 752.32056 Test MSE 754.8468565701639 Test RE 0.4625073044971589 Lambda1 -0.7459062\n",
      "16 Train Loss 748.78937 Test MSE 753.464159844363 Test RE 0.4620835096212801 Lambda1 -0.837154\n",
      "17 Train Loss 745.7239 Test MSE 750.7358211928845 Test RE 0.4612461349167971 Lambda1 -0.797198\n",
      "18 Train Loss 742.8093 Test MSE 746.5256533782085 Test RE 0.45995096966575166 Lambda1 -0.77722234\n",
      "19 Train Loss 738.6361 Test MSE 744.2960077672631 Test RE 0.45926358904007814 Lambda1 -0.7243769\n",
      "20 Train Loss 736.4395 Test MSE 740.1162621045884 Test RE 0.45797222945254096 Lambda1 -0.6518804\n",
      "21 Train Loss 733.75037 Test MSE 735.0396216651227 Test RE 0.456398854388879 Lambda1 -0.6672324\n",
      "22 Train Loss 731.372 Test MSE 734.3870507114904 Test RE 0.4561962130886962 Lambda1 -0.6750446\n",
      "23 Train Loss 728.9149 Test MSE 730.6308263856964 Test RE 0.45502804701689 Lambda1 -0.63140786\n",
      "24 Train Loss 726.4083 Test MSE 728.0387958765473 Test RE 0.4542201872424351 Lambda1 -0.5977537\n",
      "25 Train Loss 724.48724 Test MSE 727.9130288293358 Test RE 0.45418095279547727 Lambda1 -0.5871838\n",
      "26 Train Loss 722.0158 Test MSE 725.0301088079415 Test RE 0.4532806622865258 Lambda1 -0.56530255\n",
      "27 Train Loss 718.7694 Test MSE 721.4034114750403 Test RE 0.452145555845282 Lambda1 -0.5332138\n",
      "28 Train Loss 717.4596 Test MSE 719.7035313484957 Test RE 0.45161253469811624 Lambda1 -0.5265406\n",
      "29 Train Loss 716.27026 Test MSE 720.2265116322445 Test RE 0.45177658944451304 Lambda1 -0.49699587\n",
      "30 Train Loss 714.0007 Test MSE 719.1371308656395 Test RE 0.45143479213245 Lambda1 -0.44028032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 Train Loss 712.67267 Test MSE 717.5241457887042 Test RE 0.45092823620969363 Lambda1 -0.42536825\n",
      "32 Train Loss 710.5399 Test MSE 714.7160050061063 Test RE 0.45004498277263283 Lambda1 -0.4020352\n",
      "33 Train Loss 707.89325 Test MSE 709.8968519004856 Test RE 0.44852514550889255 Lambda1 -0.40685514\n",
      "34 Train Loss 706.45746 Test MSE 710.5633569345132 Test RE 0.4487356508320243 Lambda1 -0.40541622\n",
      "35 Train Loss 704.65186 Test MSE 708.2562948304624 Test RE 0.44800657952909007 Lambda1 -0.4175802\n",
      "36 Train Loss 702.208 Test MSE 706.2440992547 Test RE 0.44736972104899125 Lambda1 -0.41250217\n",
      "37 Train Loss 699.97565 Test MSE 703.2755593202664 Test RE 0.4464285214345831 Lambda1 -0.3899191\n",
      "38 Train Loss 698.7307 Test MSE 704.1829992838876 Test RE 0.44671644306231506 Lambda1 -0.37580612\n",
      "39 Train Loss 697.38184 Test MSE 702.5347778313034 Test RE 0.44619334113292347 Lambda1 -0.40856034\n",
      "40 Train Loss 696.10144 Test MSE 701.7089641654712 Test RE 0.4459310189555665 Lambda1 -0.40842816\n",
      "41 Train Loss 694.966 Test MSE 698.2974297784465 Test RE 0.44484569537543056 Lambda1 -0.4053623\n",
      "42 Train Loss 693.22144 Test MSE 698.0361133905668 Test RE 0.44476245266059145 Lambda1 -0.40487322\n",
      "43 Train Loss 691.04803 Test MSE 697.3712453702154 Test RE 0.44455058770572115 Lambda1 -0.4029906\n",
      "44 Train Loss 689.923 Test MSE 696.6401942353929 Test RE 0.4443175164186272 Lambda1 -0.41022697\n",
      "45 Train Loss 687.99695 Test MSE 693.2691231670822 Test RE 0.4432411771941286 Lambda1 -0.42842287\n",
      "46 Train Loss 687.1573 Test MSE 692.295138192891 Test RE 0.4429297094192939 Lambda1 -0.42652074\n",
      "47 Train Loss 685.983 Test MSE 690.6011144084517 Test RE 0.442387460171795 Lambda1 -0.43663952\n",
      "48 Train Loss 685.0099 Test MSE 691.3941084305143 Test RE 0.44264137661922515 Lambda1 -0.43122983\n",
      "49 Train Loss 684.3567 Test MSE 690.2198773366913 Test RE 0.4422653362867694 Lambda1 -0.4414628\n",
      "50 Train Loss 683.41296 Test MSE 687.2880873942977 Test RE 0.4413250497668497 Lambda1 -0.45447782\n",
      "51 Train Loss 682.91473 Test MSE 686.4567594202791 Test RE 0.4410580606558967 Lambda1 -0.45009696\n",
      "52 Train Loss 682.2757 Test MSE 686.0170494724883 Test RE 0.4409167781345998 Lambda1 -0.43751705\n",
      "53 Train Loss 681.716 Test MSE 685.7418891849752 Test RE 0.44082834377603225 Lambda1 -0.42270005\n",
      "54 Train Loss 680.7027 Test MSE 684.7770872398074 Test RE 0.4405181237403366 Lambda1 -0.39320925\n",
      "55 Train Loss 679.79877 Test MSE 683.7857586732374 Test RE 0.44019914668116383 Lambda1 -0.3985187\n",
      "56 Train Loss 677.9932 Test MSE 681.89513947584 Test RE 0.43959016570951864 Lambda1 -0.39904135\n",
      "57 Train Loss 677.3498 Test MSE 681.7070884091422 Test RE 0.4395295470785315 Lambda1 -0.38397616\n",
      "58 Train Loss 675.04 Test MSE 679.3588492563864 Test RE 0.4387718823386364 Lambda1 -0.40310577\n",
      "59 Train Loss 674.30176 Test MSE 678.5613888753263 Test RE 0.4385142821498676 Lambda1 -0.41001397\n",
      "60 Train Loss 673.2579 Test MSE 678.7961078432854 Test RE 0.43859011811852733 Lambda1 -0.45836207\n",
      "61 Train Loss 673.0571 Test MSE 678.822350806837 Test RE 0.4385985962116592 Lambda1 -0.4588546\n",
      "62 Train Loss 671.10266 Test MSE 676.1872686572289 Test RE 0.4377464829037521 Lambda1 -0.4748541\n",
      "63 Train Loss 669.5972 Test MSE 674.1643125408592 Test RE 0.4370911871892317 Lambda1 -0.48904106\n",
      "64 Train Loss 669.2305 Test MSE 673.3741600024748 Test RE 0.4368349662938877 Lambda1 -0.48195082\n",
      "65 Train Loss 668.66437 Test MSE 672.4865522358651 Test RE 0.4365469644738581 Lambda1 -0.45879197\n",
      "66 Train Loss 667.61194 Test MSE 670.904661585656 Test RE 0.4360332172886103 Lambda1 -0.42707044\n",
      "67 Train Loss 666.68695 Test MSE 670.3356944215244 Test RE 0.43584828698620715 Lambda1 -0.42479262\n",
      "68 Train Loss 665.65094 Test MSE 669.988619066057 Test RE 0.43573543920988306 Lambda1 -0.4230952\n",
      "69 Train Loss 664.6255 Test MSE 668.7643841468297 Test RE 0.43533715897735936 Lambda1 -0.43819508\n",
      "70 Train Loss 663.17523 Test MSE 666.5643590002228 Test RE 0.43462050772131045 Lambda1 -0.43518454\n",
      "71 Train Loss 661.75037 Test MSE 664.4293045487187 Test RE 0.4339238887877308 Lambda1 -0.4562143\n",
      "72 Train Loss 660.279 Test MSE 662.6165338066576 Test RE 0.43333154451319716 Lambda1 -0.45159152\n",
      "73 Train Loss 658.61566 Test MSE 660.3452484836878 Test RE 0.4325882304011816 Lambda1 -0.47148907\n",
      "74 Train Loss 657.47455 Test MSE 658.7817211358823 Test RE 0.432075798178467 Lambda1 -0.4863163\n",
      "Training time: 304.13\n",
      "Training time: 304.13\n",
      "inv_HT_tanh_tune3\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 854.7618 Test MSE 858.0524223022558 Test RE 0.493112579237979 Lambda1 -0.059926722\n",
      "1 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "2 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "3 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "4 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "5 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "6 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "7 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "8 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "9 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "10 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "11 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "12 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "13 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "14 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "15 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "16 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "17 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "18 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "19 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "20 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "21 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "22 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "23 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "24 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "25 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "26 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "27 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "28 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "29 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "30 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "31 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "33 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "34 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "35 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "36 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "37 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "38 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "39 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "40 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "41 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "42 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "43 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "44 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "45 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "46 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "47 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "48 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "49 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "50 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "51 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "52 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "53 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "54 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "55 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "56 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "57 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "58 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "59 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "60 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "61 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "62 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "63 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "64 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "65 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "66 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "67 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "68 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "69 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "70 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "71 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "72 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "73 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "74 Train Loss 854.7214 Test MSE 858.0793849818112 Test RE 0.49312032674364853 Lambda1 -0.06008402\n",
      "Training time: 236.48\n",
      "Training time: 236.48\n",
      "inv_HT_tanh_tune3\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 854.81366 Test MSE 858.0696961727197 Test RE 0.4931175427575305 Lambda1 -0.060304318\n",
      "1 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "2 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "3 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "4 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "5 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "6 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "7 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "8 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "9 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "10 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "11 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "12 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "13 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "14 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "15 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "16 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "17 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "18 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "19 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "20 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "21 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "22 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "23 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "24 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "25 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "26 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "27 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "28 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "29 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "30 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "31 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "32 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "34 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "35 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "36 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "37 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "38 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "39 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "40 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "41 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "42 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "43 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "44 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "45 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "46 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "47 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "48 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "49 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "50 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "51 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "52 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "53 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "54 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "55 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "56 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "57 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "58 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "59 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "60 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "61 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "62 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "63 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "64 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "65 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "66 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "67 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "68 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "69 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "70 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "71 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "72 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "73 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "74 Train Loss 854.7209 Test MSE 858.0765548773005 Test RE 0.4931195135419585 Lambda1 -0.06057904\n",
      "Training time: 247.85\n",
      "Training time: 247.85\n",
      "inv_HT_tanh_tune3\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 855.6152 Test MSE 858.6584232501292 Test RE 0.4932866792926917 Lambda1 0.0052494435\n",
      "1 Train Loss 854.71704 Test MSE 858.0872828277342 Test RE 0.49312259610209525 Lambda1 0.005307674\n",
      "2 Train Loss 854.51117 Test MSE 857.648875452031 Test RE 0.4929966087998746 Lambda1 -0.018906057\n",
      "3 Train Loss 852.9519 Test MSE 855.2660006087186 Test RE 0.4923112663706079 Lambda1 -1.8874406\n",
      "4 Train Loss 850.00446 Test MSE 852.7927980218719 Test RE 0.4915989341808006 Lambda1 -2.2829819\n",
      "5 Train Loss 843.7705 Test MSE 846.517494185566 Test RE 0.4897868710358709 Lambda1 -2.6950183\n",
      "6 Train Loss 839.2395 Test MSE 842.5654519168505 Test RE 0.4886422267031894 Lambda1 -2.6673043\n",
      "7 Train Loss 833.7598 Test MSE 835.0719071701816 Test RE 0.48646444915318376 Lambda1 -2.5460277\n",
      "8 Train Loss 827.3226 Test MSE 827.5983245260102 Test RE 0.48428271891747104 Lambda1 -2.094969\n",
      "9 Train Loss 819.47943 Test MSE 820.1924725084313 Test RE 0.4821110217609921 Lambda1 -2.0958886\n",
      "10 Train Loss 806.91376 Test MSE 806.9464689766761 Test RE 0.47820215994697746 Lambda1 -1.8079406\n",
      "11 Train Loss 783.5472 Test MSE 780.2689938141614 Test RE 0.4702310960265641 Lambda1 -1.9215304\n",
      "12 Train Loss 764.9924 Test MSE 757.9719070525925 Test RE 0.4634637010246532 Lambda1 -2.0516896\n",
      "13 Train Loss 748.92474 Test MSE 732.5272665627879 Test RE 0.45561820431834127 Lambda1 -2.5466588\n",
      "14 Train Loss 736.02484 Test MSE 729.479821665289 Test RE 0.45466948983387034 Lambda1 -2.646674\n",
      "15 Train Loss 732.4184 Test MSE 726.5591998506093 Test RE 0.45375839578715427 Lambda1 -2.604361\n",
      "16 Train Loss 725.73883 Test MSE 721.2672403200444 Test RE 0.452102880632433 Lambda1 -2.4800692\n",
      "17 Train Loss 716.6577 Test MSE 708.2721670615219 Test RE 0.44801159948031377 Lambda1 -2.524722\n",
      "18 Train Loss 706.40283 Test MSE 698.1277942339563 Test RE 0.44479165950044963 Lambda1 -2.739022\n",
      "19 Train Loss 695.54974 Test MSE 692.5056935035926 Test RE 0.4429970608330055 Lambda1 -2.6965168\n",
      "20 Train Loss 689.74304 Test MSE 686.1317001395149 Test RE 0.44095362072534117 Lambda1 -2.6596014\n",
      "21 Train Loss 677.4096 Test MSE 678.897157562582 Test RE 0.4386227625006316 Lambda1 -2.632856\n",
      "22 Train Loss 672.9419 Test MSE 673.3995580437943 Test RE 0.43684320439431384 Lambda1 -2.6176715\n",
      "23 Train Loss 667.06866 Test MSE 665.4289183235607 Test RE 0.43425017878788535 Lambda1 -2.5819001\n",
      "24 Train Loss 658.39246 Test MSE 654.8882799437777 Test RE 0.43079710859369696 Lambda1 -2.65007\n",
      "25 Train Loss 655.80774 Test MSE 650.535953417421 Test RE 0.42936320348794643 Lambda1 -2.6590629\n",
      "26 Train Loss 653.6168 Test MSE 648.3190095000783 Test RE 0.42863097148091145 Lambda1 -2.6561956\n",
      "27 Train Loss 652.19714 Test MSE 648.0010551454452 Test RE 0.428525852090959 Lambda1 -2.6623065\n",
      "28 Train Loss 649.4554 Test MSE 643.1276045381403 Test RE 0.42691139407983986 Lambda1 -2.6677945\n",
      "29 Train Loss 647.3333 Test MSE 639.2658430861345 Test RE 0.42562773569178797 Lambda1 -2.6300778\n",
      "30 Train Loss 644.48755 Test MSE 642.6619191040375 Test RE 0.42675680390349896 Lambda1 -2.642434\n",
      "31 Train Loss 642.1607 Test MSE 642.6986696194185 Test RE 0.42676900573762894 Lambda1 -2.6531951\n",
      "32 Train Loss 638.39 Test MSE 637.0844401887716 Test RE 0.42490091835589994 Lambda1 -2.6419992\n",
      "33 Train Loss 635.2063 Test MSE 629.2937440244477 Test RE 0.4222949401190834 Lambda1 -2.6981769\n",
      "34 Train Loss 634.38715 Test MSE 627.1074239446812 Test RE 0.42156072399982475 Lambda1 -2.7234728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 Train Loss 632.188 Test MSE 622.7155115943839 Test RE 0.4200819416363724 Lambda1 -2.7095578\n",
      "36 Train Loss 628.0303 Test MSE 620.5203339375569 Test RE 0.41934085794853854 Lambda1 -2.7205968\n",
      "37 Train Loss 623.2993 Test MSE 618.618787845863 Test RE 0.4186978429204078 Lambda1 -2.7333467\n",
      "38 Train Loss 620.7122 Test MSE 617.0440263241289 Test RE 0.4181645828485345 Lambda1 -2.745106\n",
      "39 Train Loss 619.4988 Test MSE 614.6198474504107 Test RE 0.417342353558237 Lambda1 -2.7836347\n",
      "40 Train Loss 618.35187 Test MSE 614.3428427456232 Test RE 0.41724829637432753 Lambda1 -2.8109987\n",
      "41 Train Loss 613.5989 Test MSE 615.885704228232 Test RE 0.4177719068117716 Lambda1 -2.9331136\n",
      "42 Train Loss 611.90674 Test MSE 615.3508379405603 Test RE 0.41759046028467206 Lambda1 -3.0383625\n",
      "43 Train Loss 611.3677 Test MSE 616.1401652896349 Test RE 0.41785820180439603 Lambda1 -3.0462253\n",
      "44 Train Loss 610.81464 Test MSE 616.1936169433826 Test RE 0.41787632651756146 Lambda1 -3.1229672\n",
      "45 Train Loss 609.86945 Test MSE 615.504712037114 Test RE 0.41764266817517465 Lambda1 -3.0744843\n",
      "46 Train Loss 609.20087 Test MSE 615.5973146629952 Test RE 0.4176740841436075 Lambda1 -3.08254\n",
      "47 Train Loss 605.73486 Test MSE 613.7987878325309 Test RE 0.4170635003202691 Lambda1 -3.0933495\n",
      "48 Train Loss 602.94867 Test MSE 612.9142725420849 Test RE 0.4167628871170062 Lambda1 -3.000498\n",
      "49 Train Loss 600.37665 Test MSE 611.5395350014365 Test RE 0.4162952350798394 Lambda1 -2.9750018\n",
      "50 Train Loss 596.44385 Test MSE 607.221596923286 Test RE 0.41482294981182555 Lambda1 -2.9431872\n",
      "51 Train Loss 594.9572 Test MSE 604.823494822895 Test RE 0.41400300869300555 Lambda1 -2.9234507\n",
      "52 Train Loss 594.44495 Test MSE 604.103587475355 Test RE 0.4137565462524016 Lambda1 -2.944167\n",
      "53 Train Loss 593.36456 Test MSE 603.9222324474916 Test RE 0.41369443566078545 Lambda1 -2.9648678\n",
      "54 Train Loss 592.4485 Test MSE 602.9041899995979 Test RE 0.4133456025563973 Lambda1 -2.9699645\n",
      "55 Train Loss 592.08746 Test MSE 602.9159532091383 Test RE 0.41334963491120547 Lambda1 -2.9647877\n",
      "56 Train Loss 591.00525 Test MSE 601.4087295282575 Test RE 0.41283264725586066 Lambda1 -2.9962096\n",
      "57 Train Loss 589.51855 Test MSE 600.543201016348 Test RE 0.4125354724209704 Lambda1 -3.0913365\n",
      "58 Train Loss 589.11005 Test MSE 600.8271073575906 Test RE 0.41263297381422 Lambda1 -3.1072261\n",
      "59 Train Loss 588.76086 Test MSE 600.3849737600033 Test RE 0.4124811227456107 Lambda1 -3.0743585\n",
      "60 Train Loss 588.1924 Test MSE 599.9131208125209 Test RE 0.41231900285758233 Lambda1 -3.0616472\n",
      "61 Train Loss 587.8056 Test MSE 599.7953462902303 Test RE 0.41227852778253277 Lambda1 -3.0987866\n",
      "62 Train Loss 587.6723 Test MSE 599.6935558937162 Test RE 0.41224354270326796 Lambda1 -3.1292875\n",
      "63 Train Loss 587.5937 Test MSE 599.6128649794839 Test RE 0.41221580734822416 Lambda1 -3.1398926\n",
      "64 Train Loss 586.9016 Test MSE 599.5426182268974 Test RE 0.41219166037634425 Lambda1 -3.17541\n",
      "65 Train Loss 586.3412 Test MSE 599.0855709491642 Test RE 0.4120345180914389 Lambda1 -3.1827028\n",
      "66 Train Loss 586.081 Test MSE 599.0870232548123 Test RE 0.4120350175190033 Lambda1 -3.2155695\n",
      "67 Train Loss 585.8046 Test MSE 598.6239530891852 Test RE 0.41187574348947703 Lambda1 -3.2254837\n",
      "68 Train Loss 585.65533 Test MSE 598.5372660019744 Test RE 0.4118459204252681 Lambda1 -3.25193\n",
      "69 Train Loss 585.59607 Test MSE 598.5717239484126 Test RE 0.41185777529315065 Lambda1 -3.2390676\n",
      "70 Train Loss 585.53876 Test MSE 598.6739170084383 Test RE 0.4118929316565214 Lambda1 -3.2134352\n",
      "71 Train Loss 585.40015 Test MSE 598.8099416490206 Test RE 0.4119397220746866 Lambda1 -3.2053356\n",
      "72 Train Loss 585.28455 Test MSE 598.9473868838774 Test RE 0.4119869957581417 Lambda1 -3.200638\n",
      "73 Train Loss 585.08856 Test MSE 598.9680604177283 Test RE 0.4119941058597922 Lambda1 -3.1854763\n",
      "74 Train Loss 584.7471 Test MSE 598.7676459684074 Test RE 0.4119251735699109 Lambda1 -3.1316683\n",
      "Training time: 274.30\n",
      "Training time: 274.30\n",
      "inv_HT_tanh_tune3\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 855.00977 Test MSE 858.1876776991832 Test RE 0.4931514425450269 Lambda1 -0.005354711\n",
      "1 Train Loss 854.7176 Test MSE 858.0789149171856 Test RE 0.4931201916754615 Lambda1 -0.0053054043\n",
      "2 Train Loss 854.462 Test MSE 857.6565408362569 Test RE 0.4929988119159123 Lambda1 -0.0062020416\n",
      "3 Train Loss 850.71185 Test MSE 853.1127990239153 Test RE 0.4916911590431975 Lambda1 -0.06350001\n",
      "4 Train Loss 798.86237 Test MSE 800.5464622006701 Test RE 0.4763020403758055 Lambda1 0.002217073\n",
      "5 Train Loss 765.3745 Test MSE 771.5596002691054 Test RE 0.46759936244056144 Lambda1 -0.0005149718\n",
      "6 Train Loss 724.0545 Test MSE 730.5964475208041 Test RE 0.45501734152020873 Lambda1 -0.0005762838\n",
      "7 Train Loss 665.3515 Test MSE 679.2501807657588 Test RE 0.43873678852547143 Lambda1 -0.0008836096\n",
      "8 Train Loss 639.5268 Test MSE 655.7732191379235 Test RE 0.43108807466959964 Lambda1 -0.00020061039\n",
      "9 Train Loss 635.5332 Test MSE 653.8801372398046 Test RE 0.4304653938207033 Lambda1 0.00029941933\n",
      "10 Train Loss 629.19305 Test MSE 650.8513905730692 Test RE 0.4294672874305441 Lambda1 8.065605e-05\n",
      "11 Train Loss 626.47687 Test MSE 649.0410618330149 Test RE 0.4288695946457113 Lambda1 -1.7083457e-05\n",
      "12 Train Loss 625.0579 Test MSE 647.7576158961303 Test RE 0.42844535082447116 Lambda1 5.3635373e-05\n",
      "13 Train Loss 624.7061 Test MSE 647.4925680870394 Test RE 0.4283576867680897 Lambda1 1.9091902e-05\n",
      "14 Train Loss 623.11334 Test MSE 645.7125079269216 Test RE 0.42776846978563543 Lambda1 -4.1696447e-05\n",
      "15 Train Loss 621.7378 Test MSE 644.8704038811665 Test RE 0.42748944229426084 Lambda1 -2.917679e-05\n",
      "16 Train Loss 620.5684 Test MSE 642.9572281043785 Test RE 0.42685484195998386 Lambda1 -8.539884e-05\n",
      "17 Train Loss 617.9717 Test MSE 640.3384504616803 Test RE 0.4259846608375867 Lambda1 9.524748e-05\n",
      "18 Train Loss 607.29474 Test MSE 626.0025247438036 Test RE 0.4211891868154968 Lambda1 1.1873848e-05\n",
      "19 Train Loss 584.4998 Test MSE 603.7665270975505 Test RE 0.4136411021471007 Lambda1 -2.50005e-06\n",
      "20 Train Loss 539.08417 Test MSE 536.0590014562367 Test RE 0.3897583850657738 Lambda1 -8.177851e-05\n",
      "21 Train Loss 443.62997 Test MSE 454.490368751589 Test RE 0.3588818647380365 Lambda1 0.00024102142\n",
      "22 Train Loss 381.2972 Test MSE 391.7299279603142 Test RE 0.3331827795785157 Lambda1 1.5329424e-05\n",
      "23 Train Loss 337.47134 Test MSE 331.04457411090027 Test RE 0.30628971072827266 Lambda1 0.0008530118\n",
      "24 Train Loss 308.50882 Test MSE 307.8451191440226 Test RE 0.29536246699317054 Lambda1 0.0004991941\n",
      "25 Train Loss 296.3555 Test MSE 305.05345038284327 Test RE 0.29402018154482384 Lambda1 -0.00012477578\n",
      "26 Train Loss 287.55206 Test MSE 293.4682166392099 Test RE 0.2883830343194085 Lambda1 -0.0005787508\n",
      "27 Train Loss 280.9669 Test MSE 287.74303618564164 Test RE 0.28555619181118047 Lambda1 -0.00022544127\n",
      "28 Train Loss 277.91388 Test MSE 285.04514497657635 Test RE 0.28421434547079516 Lambda1 -0.0001369522\n",
      "29 Train Loss 275.95847 Test MSE 282.5577930275613 Test RE 0.2829715772528637 Lambda1 0.00046181408\n",
      "30 Train Loss 273.7019 Test MSE 280.77328111116316 Test RE 0.2820765993434203 Lambda1 0.0009999193\n",
      "31 Train Loss 272.6181 Test MSE 279.3970440293162 Test RE 0.2813844374166622 Lambda1 0.0012784232\n",
      "32 Train Loss 272.22598 Test MSE 279.40268535565207 Test RE 0.28138727812929426 Lambda1 0.0011454736\n",
      "33 Train Loss 271.81592 Test MSE 279.228705921532 Test RE 0.2812996568834757 Lambda1 0.0008748222\n",
      "34 Train Loss 271.26797 Test MSE 278.8989880204314 Test RE 0.2811335261692877 Lambda1 0.0010832499\n",
      "35 Train Loss 270.9871 Test MSE 278.54183145557505 Test RE 0.2809534594514198 Lambda1 0.0015300045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 Train Loss 270.61716 Test MSE 278.2838979966332 Test RE 0.2808233459933929 Lambda1 0.0023418043\n",
      "37 Train Loss 270.2836 Test MSE 277.616532481818 Test RE 0.2804864161289763 Lambda1 0.004444581\n",
      "38 Train Loss 269.79672 Test MSE 277.0805092936141 Test RE 0.2802155031098768 Lambda1 0.005358171\n",
      "39 Train Loss 269.5377 Test MSE 276.8799323338549 Test RE 0.28011406156659674 Lambda1 0.006575723\n",
      "40 Train Loss 269.03058 Test MSE 275.9122608720833 Test RE 0.2796241459065781 Lambda1 0.0087293675\n",
      "41 Train Loss 268.60324 Test MSE 275.4286678360508 Test RE 0.2793789889981405 Lambda1 0.011461302\n",
      "42 Train Loss 267.95645 Test MSE 274.2951219232577 Test RE 0.278803494397929 Lambda1 0.013818086\n",
      "43 Train Loss 266.75354 Test MSE 272.76620798250894 Test RE 0.27802538684852945 Lambda1 0.01692662\n",
      "44 Train Loss 265.61853 Test MSE 270.76485457372496 Test RE 0.27700353835348385 Lambda1 0.02187449\n",
      "45 Train Loss 264.36914 Test MSE 269.24369710974855 Test RE 0.2762243392259314 Lambda1 0.026520185\n",
      "46 Train Loss 260.6369 Test MSE 265.6049728401832 Test RE 0.274351457410833 Lambda1 0.034328602\n",
      "47 Train Loss 259.01767 Test MSE 263.0660173517105 Test RE 0.2730370264745733 Lambda1 0.03951165\n",
      "48 Train Loss 258.3563 Test MSE 262.39462704183865 Test RE 0.27268838485272595 Lambda1 0.038695276\n",
      "49 Train Loss 256.8793 Test MSE 259.3385333316496 Test RE 0.2710957416872482 Lambda1 0.04459817\n",
      "50 Train Loss 255.28452 Test MSE 257.334731447369 Test RE 0.2700463882843786 Lambda1 0.047657393\n",
      "51 Train Loss 251.37244 Test MSE 250.82613953023161 Test RE 0.2666094675895249 Lambda1 0.05830728\n",
      "52 Train Loss 248.52751 Test MSE 246.46388861095213 Test RE 0.2642809253643223 Lambda1 0.064002275\n",
      "53 Train Loss 243.9918 Test MSE 239.88035266435529 Test RE 0.26072730161619695 Lambda1 0.07655022\n",
      "54 Train Loss 240.50395 Test MSE 233.6804935643952 Test RE 0.2573359142037312 Lambda1 0.09153052\n",
      "55 Train Loss 232.94273 Test MSE 226.37549138445192 Test RE 0.25328173568025686 Lambda1 0.11630023\n",
      "56 Train Loss 228.35896 Test MSE 222.541719431564 Test RE 0.2511278567889575 Lambda1 0.12806718\n",
      "57 Train Loss 220.2751 Test MSE 212.12405340081858 Test RE 0.24517948545686663 Lambda1 0.14598782\n",
      "58 Train Loss 217.27768 Test MSE 207.83145155227828 Test RE 0.2426860460785471 Lambda1 0.1574326\n",
      "59 Train Loss 213.45026 Test MSE 204.70177975089976 Test RE 0.24085184634969245 Lambda1 0.17225045\n",
      "60 Train Loss 207.25041 Test MSE 203.72202045498236 Test RE 0.240274763248516 Lambda1 0.18443403\n",
      "61 Train Loss 201.3579 Test MSE 200.8104405904196 Test RE 0.23855158976089755 Lambda1 0.17568433\n",
      "62 Train Loss 198.93932 Test MSE 196.95010306361115 Test RE 0.23624753013057587 Lambda1 0.17824261\n",
      "63 Train Loss 193.9078 Test MSE 190.14064961261104 Test RE 0.23212753378023188 Lambda1 0.1890891\n",
      "64 Train Loss 188.4408 Test MSE 182.74441031735665 Test RE 0.22756801513138397 Lambda1 0.19951737\n",
      "65 Train Loss 183.76064 Test MSE 172.7525613043776 Test RE 0.22125924096372981 Lambda1 0.21174814\n",
      "66 Train Loss 177.73358 Test MSE 168.81818218412505 Test RE 0.2187251788857496 Lambda1 0.21344958\n",
      "67 Train Loss 173.8927 Test MSE 163.9162895146793 Test RE 0.21552627747496914 Lambda1 0.2204154\n",
      "68 Train Loss 169.86891 Test MSE 158.70110949595963 Test RE 0.21206995885149074 Lambda1 0.22290573\n",
      "69 Train Loss 168.32419 Test MSE 158.06640034820322 Test RE 0.21164545773863697 Lambda1 0.22196168\n",
      "70 Train Loss 164.81227 Test MSE 151.3074872437448 Test RE 0.20707104735450502 Lambda1 0.22769618\n",
      "71 Train Loss 162.8311 Test MSE 151.11751185347856 Test RE 0.2069410116258556 Lambda1 0.22903922\n",
      "72 Train Loss 160.08932 Test MSE 149.40190704825028 Test RE 0.2057629800650968 Lambda1 0.22885312\n",
      "73 Train Loss 157.6004 Test MSE 144.4394316767617 Test RE 0.2023168507101065 Lambda1 0.23263888\n",
      "74 Train Loss 156.5962 Test MSE 143.35114061537283 Test RE 0.20155322291140537 Lambda1 0.23461999\n",
      "Training time: 282.87\n",
      "Training time: 282.87\n",
      "inv_HT_tanh_tune3\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 854.9064 Test MSE 858.121161454057 Test RE 0.49313233063120687 Lambda1 -0.16383904\n",
      "1 Train Loss 854.721 Test MSE 858.0833931746196 Test RE 0.4931214784547102 Lambda1 -0.1649276\n",
      "2 Train Loss 854.45605 Test MSE 857.6027955716694 Test RE 0.4929833647261345 Lambda1 -0.16424716\n",
      "3 Train Loss 853.2766 Test MSE 854.5249681750174 Test RE 0.49209794228619536 Lambda1 -0.32947737\n",
      "4 Train Loss 846.14557 Test MSE 845.797797678782 Test RE 0.4895786220294708 Lambda1 -0.51835304\n",
      "5 Train Loss 839.56494 Test MSE 836.5115517419396 Test RE 0.48688359528704445 Lambda1 -0.5866991\n",
      "6 Train Loss 828.8058 Test MSE 829.9413163665707 Test RE 0.4849677544451014 Lambda1 -0.81941843\n",
      "7 Train Loss 809.9513 Test MSE 812.4170584544322 Test RE 0.47982037688028595 Lambda1 -0.87546325\n",
      "8 Train Loss 791.34546 Test MSE 794.6089081364496 Test RE 0.47453241634632076 Lambda1 -0.929367\n",
      "9 Train Loss 771.6471 Test MSE 776.5409236724462 Test RE 0.46910638548902095 Lambda1 -0.8121059\n",
      "10 Train Loss 758.939 Test MSE 761.9011773748886 Test RE 0.46466342898818763 Lambda1 -0.579171\n",
      "11 Train Loss 743.049 Test MSE 746.3263693474502 Test RE 0.45988957391814694 Lambda1 -0.45684946\n",
      "12 Train Loss 728.61816 Test MSE 728.8518426432087 Test RE 0.4544737446135825 Lambda1 -0.41081908\n",
      "13 Train Loss 720.3035 Test MSE 723.877528639688 Test RE 0.4529202289111034 Lambda1 -0.39346078\n",
      "14 Train Loss 712.84534 Test MSE 715.1380826489367 Test RE 0.45017785085448725 Lambda1 -0.36515582\n",
      "15 Train Loss 706.3541 Test MSE 708.903398758558 Test RE 0.4482111951681354 Lambda1 -0.38510245\n",
      "16 Train Loss 700.6833 Test MSE 701.7584802516961 Test RE 0.44594675223702224 Lambda1 -0.38248575\n",
      "17 Train Loss 689.409 Test MSE 697.4005705533668 Test RE 0.44455993451378345 Lambda1 -0.38735962\n",
      "18 Train Loss 686.5225 Test MSE 695.0115785570514 Test RE 0.44379784650990917 Lambda1 -0.38795003\n",
      "19 Train Loss 682.7285 Test MSE 691.8288490631566 Test RE 0.4427805186434094 Lambda1 -0.37812197\n",
      "20 Train Loss 680.1158 Test MSE 689.7985332081569 Test RE 0.4421303254328548 Lambda1 -0.36488292\n",
      "21 Train Loss 671.5743 Test MSE 683.5575717809886 Test RE 0.4401256908834216 Lambda1 -0.350837\n",
      "22 Train Loss 669.82556 Test MSE 680.9386932105191 Test RE 0.4392817664532937 Lambda1 -0.3514541\n",
      "23 Train Loss 666.7266 Test MSE 679.503173289064 Test RE 0.43881848654838423 Lambda1 -0.35931513\n",
      "24 Train Loss 664.46277 Test MSE 677.6862895324059 Test RE 0.43823142832927886 Lambda1 -0.36251083\n",
      "25 Train Loss 662.5005 Test MSE 675.3200249654357 Test RE 0.4374656770559326 Lambda1 -0.36244655\n",
      "26 Train Loss 659.667 Test MSE 674.290474316594 Test RE 0.43713208346604093 Lambda1 -0.39209569\n",
      "27 Train Loss 658.6959 Test MSE 672.8968081506811 Test RE 0.4366801036922283 Lambda1 -0.39582983\n",
      "28 Train Loss 654.0074 Test MSE 666.9418531179073 Test RE 0.4347435592020542 Lambda1 -0.38420135\n",
      "29 Train Loss 652.4179 Test MSE 664.928911741973 Test RE 0.43408699926220334 Lambda1 -0.38816607\n",
      "30 Train Loss 649.26465 Test MSE 662.168339521978 Test RE 0.4331849668435308 Lambda1 -0.36349735\n",
      "31 Train Loss 648.28125 Test MSE 660.8511657673364 Test RE 0.43275391036996286 Lambda1 -0.3639469\n",
      "32 Train Loss 647.0045 Test MSE 659.5301089364779 Test RE 0.4323211514284797 Lambda1 -0.35709196\n",
      "33 Train Loss 644.77466 Test MSE 657.2690597202409 Test RE 0.43157945775127965 Lambda1 -0.37749055\n",
      "34 Train Loss 643.2673 Test MSE 656.3405701551595 Test RE 0.4312745151747736 Lambda1 -0.36868963\n",
      "35 Train Loss 642.4573 Test MSE 655.857956185782 Test RE 0.43111592572372825 Lambda1 -0.36716157\n",
      "36 Train Loss 642.0372 Test MSE 656.0835759226331 Test RE 0.43119007279855925 Lambda1 -0.37127474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Train Loss 641.45374 Test MSE 656.0796304315446 Test RE 0.4311887762723163 Lambda1 -0.3836235\n",
      "38 Train Loss 641.19135 Test MSE 655.2806094024567 Test RE 0.43092612990614754 Lambda1 -0.37862754\n",
      "39 Train Loss 640.52655 Test MSE 653.4191998706642 Test RE 0.4303136438633257 Lambda1 -0.39030352\n",
      "40 Train Loss 640.1109 Test MSE 651.7182659712074 Test RE 0.4297531981222423 Lambda1 -0.39910343\n",
      "41 Train Loss 639.6038 Test MSE 651.0358079230489 Test RE 0.4295281274399676 Lambda1 -0.40275604\n",
      "42 Train Loss 638.62714 Test MSE 651.112607490229 Test RE 0.42955346137789274 Lambda1 -0.41467887\n",
      "43 Train Loss 637.7159 Test MSE 650.7584345185825 Test RE 0.42943661759509993 Lambda1 -0.4287593\n",
      "44 Train Loss 637.256 Test MSE 650.7486750699178 Test RE 0.4294333974444915 Lambda1 -0.42927465\n",
      "45 Train Loss 635.6931 Test MSE 649.5204780518234 Test RE 0.4290279583436808 Lambda1 -0.42749202\n",
      "46 Train Loss 634.59784 Test MSE 648.179931836465 Test RE 0.4285849939678457 Lambda1 -0.4456875\n",
      "47 Train Loss 633.3362 Test MSE 647.15487514106 Test RE 0.4282459694744563 Lambda1 -0.46649817\n",
      "48 Train Loss 632.72546 Test MSE 646.209443182897 Test RE 0.4279330417495364 Lambda1 -0.47445786\n",
      "49 Train Loss 630.8113 Test MSE 646.0819214943652 Test RE 0.4278908159378244 Lambda1 -0.5090789\n",
      "50 Train Loss 628.08905 Test MSE 642.5143347809761 Test RE 0.4267077997315737 Lambda1 -0.5467574\n",
      "51 Train Loss 624.6868 Test MSE 636.4688932606562 Test RE 0.4246956004692803 Lambda1 -0.5724592\n",
      "52 Train Loss 622.2149 Test MSE 635.2421200530656 Test RE 0.42428610953660506 Lambda1 -0.5762093\n",
      "53 Train Loss 619.7111 Test MSE 632.1875830007511 Test RE 0.42326479868762606 Lambda1 -0.5606085\n",
      "54 Train Loss 617.7148 Test MSE 628.6280431240914 Test RE 0.4220715178219344 Lambda1 -0.5722009\n",
      "55 Train Loss 614.4005 Test MSE 626.1128466952605 Test RE 0.42122629877922163 Lambda1 -0.58234626\n",
      "56 Train Loss 610.856 Test MSE 621.8071925761964 Test RE 0.4197754552439642 Lambda1 -0.6055717\n",
      "57 Train Loss 607.4708 Test MSE 620.4452283725425 Test RE 0.41931547942070435 Lambda1 -0.5688507\n",
      "58 Train Loss 604.315 Test MSE 616.050320153366 Test RE 0.41782773479550467 Lambda1 -0.54308474\n",
      "59 Train Loss 602.7464 Test MSE 611.5442980912536 Test RE 0.4162968562732542 Lambda1 -0.5351921\n",
      "60 Train Loss 600.01465 Test MSE 607.1891578013858 Test RE 0.41481186928370545 Lambda1 -0.52758837\n",
      "61 Train Loss 597.519 Test MSE 607.4431813040566 Test RE 0.4148986305047259 Lambda1 -0.530242\n",
      "62 Train Loss 594.7535 Test MSE 603.6678653492424 Test RE 0.41360730413095376 Lambda1 -0.5341011\n",
      "63 Train Loss 588.6697 Test MSE 596.674211373778 Test RE 0.4112044487025202 Lambda1 -0.54933614\n",
      "64 Train Loss 541.1354 Test MSE 535.4026924021542 Test RE 0.3895197170270761 Lambda1 -0.70780426\n",
      "65 Train Loss 496.3813 Test MSE 476.3895802286555 Test RE 0.36742634917532574 Lambda1 -0.7894756\n",
      "66 Train Loss 480.4513 Test MSE 459.9075604250144 Test RE 0.36101433342873857 Lambda1 -0.79769194\n",
      "67 Train Loss 451.21838 Test MSE 418.3178753437402 Test RE 0.34430424888314604 Lambda1 -0.83628726\n",
      "68 Train Loss 409.5333 Test MSE 384.57038942339716 Test RE 0.330123994664133 Lambda1 -0.87335104\n",
      "69 Train Loss 373.23663 Test MSE 352.76684906662126 Test RE 0.31617902334151 Lambda1 -0.83114916\n",
      "70 Train Loss 355.51944 Test MSE 332.8206229593821 Test RE 0.30711023138141286 Lambda1 -0.77229553\n",
      "71 Train Loss 342.96866 Test MSE 327.9209935119953 Test RE 0.3048412832739882 Lambda1 -0.7541113\n",
      "72 Train Loss 334.2043 Test MSE 319.03296321126356 Test RE 0.30068166708793753 Lambda1 -0.76501954\n",
      "73 Train Loss 324.90903 Test MSE 310.30828024477324 Test RE 0.2965417545637922 Lambda1 -0.7463691\n",
      "74 Train Loss 317.1187 Test MSE 307.7756029373777 Test RE 0.2953291163952843 Lambda1 -0.7238984\n",
      "Training time: 277.60\n",
      "Training time: 277.60\n",
      "inv_HT_tanh_tune3\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 854.7674 Test MSE 858.0534832647722 Test RE 0.49311288409919013 Lambda1 -0.0055653797\n",
      "1 Train Loss 854.7215 Test MSE 858.0798846344405 Test RE 0.4931204703136004 Lambda1 -0.0055393875\n",
      "2 Train Loss 854.6619 Test MSE 857.9532681670615 Test RE 0.49308408706041723 Lambda1 -0.0050884527\n",
      "3 Train Loss 854.4135 Test MSE 857.6455483019975 Test RE 0.49299565253716543 Lambda1 -0.030035228\n",
      "4 Train Loss 852.25574 Test MSE 851.0076274805201 Test RE 0.491084127015733 Lambda1 -0.18822154\n",
      "5 Train Loss 832.81 Test MSE 832.9685477903487 Test RE 0.4858514153084216 Lambda1 0.11543584\n",
      "6 Train Loss 769.9385 Test MSE 773.8217718894762 Test RE 0.4682843489248372 Lambda1 -0.0015927431\n",
      "7 Train Loss 730.389 Test MSE 728.9857795902545 Test RE 0.4545155007196184 Lambda1 0.0065009664\n",
      "8 Train Loss 685.0318 Test MSE 691.9667988361861 Test RE 0.442824661372889 Lambda1 0.0020654914\n",
      "9 Train Loss 652.9976 Test MSE 669.235895760988 Test RE 0.43549059893574404 Lambda1 0.00075786654\n",
      "10 Train Loss 645.5128 Test MSE 665.3283806525162 Test RE 0.4342173727663806 Lambda1 0.00037208005\n",
      "11 Train Loss 643.6251 Test MSE 662.5037289283057 Test RE 0.4332946574221866 Lambda1 0.00044613646\n",
      "12 Train Loss 640.5541 Test MSE 659.1861224670519 Test RE 0.4322083953766102 Lambda1 0.00084910664\n",
      "13 Train Loss 634.8363 Test MSE 654.8170616535501 Test RE 0.43077368363052826 Lambda1 0.0012449882\n",
      "14 Train Loss 631.37317 Test MSE 651.8972371563101 Test RE 0.4298122022683026 Lambda1 0.0018515023\n",
      "15 Train Loss 626.50885 Test MSE 647.460393729964 Test RE 0.4283470439398438 Lambda1 0.0014639007\n",
      "16 Train Loss 620.91943 Test MSE 642.3521764730059 Test RE 0.426653949897079 Lambda1 0.0015832392\n",
      "17 Train Loss 616.2828 Test MSE 635.0257495976914 Test RE 0.4242138451239987 Lambda1 -0.00016330468\n",
      "18 Train Loss 601.8002 Test MSE 614.1395873121571 Test RE 0.41717926732956156 Lambda1 5.7991125e-05\n",
      "19 Train Loss 584.475 Test MSE 599.7032368196374 Test RE 0.41224687013863304 Lambda1 -3.3554337e-05\n",
      "20 Train Loss 541.6624 Test MSE 546.2249476080052 Test RE 0.3934367613914277 Lambda1 -6.043587e-05\n",
      "21 Train Loss 495.9803 Test MSE 487.39587694875524 Test RE 0.37164654190802493 Lambda1 -7.971117e-06\n",
      "22 Train Loss 450.80716 Test MSE 435.49361982903986 Test RE 0.35130155246788136 Lambda1 -3.503033e-06\n",
      "23 Train Loss 411.3814 Test MSE 395.2069873852511 Test RE 0.33465820542252517 Lambda1 6.034641e-05\n",
      "24 Train Loss 382.16922 Test MSE 374.6738926408609 Test RE 0.3258486205864366 Lambda1 -0.00010302122\n",
      "25 Train Loss 362.00833 Test MSE 353.0340442299327 Test RE 0.3162987419529829 Lambda1 -6.0330963e-06\n",
      "26 Train Loss 349.36252 Test MSE 340.21577651735845 Test RE 0.31050342504470213 Lambda1 2.1180836e-05\n",
      "27 Train Loss 337.87354 Test MSE 336.03466785934876 Test RE 0.30858954849848125 Lambda1 -0.00023198861\n",
      "28 Train Loss 323.44928 Test MSE 325.8848239128488 Test RE 0.30389337948764067 Lambda1 -0.00021745553\n",
      "29 Train Loss 314.46024 Test MSE 320.2046681636978 Test RE 0.3012333143333808 Lambda1 -3.0689425e-05\n",
      "30 Train Loss 302.7544 Test MSE 307.68682561951283 Test RE 0.29528651974770215 Lambda1 0.00013470367\n",
      "31 Train Loss 294.19846 Test MSE 299.89628068742843 Test RE 0.29152426594075775 Lambda1 7.13643e-05\n",
      "32 Train Loss 291.23145 Test MSE 298.09317963011506 Test RE 0.2906465621589058 Lambda1 -6.25474e-06\n",
      "33 Train Loss 289.54227 Test MSE 294.45785898793616 Test RE 0.288868872046948 Lambda1 5.5542132e-05\n",
      "34 Train Loss 287.11963 Test MSE 291.84723271055714 Test RE 0.28758548361218406 Lambda1 2.6653273e-05\n",
      "35 Train Loss 282.16 Test MSE 286.2214857561608 Test RE 0.28480019775492865 Lambda1 3.5442914e-05\n",
      "36 Train Loss 281.4581 Test MSE 285.4348188958357 Test RE 0.28440854820484107 Lambda1 0.00010400839\n",
      "37 Train Loss 280.75653 Test MSE 284.85721968963344 Test RE 0.2841206412461914 Lambda1 4.2698368e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 Train Loss 278.93112 Test MSE 283.5215989644139 Test RE 0.28345377508653247 Lambda1 -3.9870825e-05\n",
      "39 Train Loss 277.19974 Test MSE 282.1799731697703 Test RE 0.2827823273952207 Lambda1 -1.5043495e-06\n",
      "40 Train Loss 276.46918 Test MSE 282.046224134245 Test RE 0.28271530218089036 Lambda1 9.55914e-07\n",
      "41 Train Loss 275.55115 Test MSE 281.8440712417478 Test RE 0.2826139677974575 Lambda1 -1.8624149e-05\n",
      "42 Train Loss 274.94623 Test MSE 282.426616720294 Test RE 0.2829058854252314 Lambda1 -1.2173136e-06\n",
      "43 Train Loss 274.34747 Test MSE 281.2022089768707 Test RE 0.28229197656917404 Lambda1 -1.8644594e-05\n",
      "44 Train Loss 273.42734 Test MSE 280.67933800586553 Test RE 0.28202940580614994 Lambda1 2.7587117e-05\n",
      "45 Train Loss 272.43 Test MSE 280.3741696257936 Test RE 0.28187604598963917 Lambda1 3.1982076e-05\n",
      "46 Train Loss 272.04123 Test MSE 279.9976768486631 Test RE 0.2816867276477086 Lambda1 1.5889254e-05\n",
      "47 Train Loss 271.88596 Test MSE 279.96669785428276 Test RE 0.28167114428102463 Lambda1 6.403828e-06\n",
      "48 Train Loss 271.59265 Test MSE 279.83801461930784 Test RE 0.2816064035094833 Lambda1 5.387242e-05\n",
      "49 Train Loss 271.38376 Test MSE 279.779329588616 Test RE 0.28157687402084264 Lambda1 1.110741e-05\n",
      "50 Train Loss 271.24243 Test MSE 279.53015876683725 Test RE 0.2814514602359766 Lambda1 6.1034312e-05\n",
      "51 Train Loss 270.94632 Test MSE 279.4774606906316 Test RE 0.281424928841878 Lambda1 1.593531e-05\n",
      "52 Train Loss 270.6765 Test MSE 279.31463189447925 Test RE 0.2813429351836162 Lambda1 9.385869e-05\n",
      "53 Train Loss 270.6203 Test MSE 279.3837528794549 Test RE 0.281377744491155 Lambda1 5.690098e-05\n",
      "54 Train Loss 270.4637 Test MSE 279.4436401118201 Test RE 0.2814079002021984 Lambda1 5.0904833e-05\n",
      "55 Train Loss 270.41223 Test MSE 279.3630611047073 Test RE 0.28136732457114666 Lambda1 4.4845583e-05\n",
      "56 Train Loss 270.34625 Test MSE 279.2965479082486 Test RE 0.281333827382701 Lambda1 4.556622e-05\n",
      "57 Train Loss 270.28638 Test MSE 279.38096116374487 Test RE 0.2813763386674019 Lambda1 5.2409803e-05\n",
      "58 Train Loss 270.26556 Test MSE 279.43636662962797 Test RE 0.2814042378739574 Lambda1 4.9616752e-05\n",
      "59 Train Loss 270.25555 Test MSE 279.4426883037086 Test RE 0.28140742095251847 Lambda1 5.4104137e-05\n",
      "60 Train Loss 270.22925 Test MSE 279.4243005875644 Test RE 0.2813981623010703 Lambda1 6.6999004e-05\n",
      "61 Train Loss 270.20734 Test MSE 279.45496633558014 Test RE 0.28141360306333457 Lambda1 7.2578034e-05\n",
      "62 Train Loss 270.15704 Test MSE 279.3087840274416 Test RE 0.28133999000190957 Lambda1 0.00012607401\n",
      "63 Train Loss 270.14362 Test MSE 279.2651118271155 Test RE 0.2813179942441208 Lambda1 0.00013401586\n",
      "64 Train Loss 270.12094 Test MSE 279.2076643828425 Test RE 0.28128905788523545 Lambda1 0.00014075328\n",
      "65 Train Loss 270.07584 Test MSE 279.17662021829796 Test RE 0.28127341965667624 Lambda1 0.00014814385\n",
      "66 Train Loss 270.064 Test MSE 279.2680222010374 Test RE 0.2813194601243658 Lambda1 0.00013118902\n",
      "67 Train Loss 270.0364 Test MSE 279.20262424189605 Test RE 0.2812865190170784 Lambda1 0.00013731679\n",
      "68 Train Loss 270.01447 Test MSE 279.18465044745693 Test RE 0.2812774648983093 Lambda1 0.00014116302\n",
      "69 Train Loss 269.9652 Test MSE 279.2219467699118 Test RE 0.28129625222181726 Lambda1 0.000120649514\n",
      "70 Train Loss 269.936 Test MSE 279.2433571296246 Test RE 0.281307036722405 Lambda1 8.433569e-05\n",
      "71 Train Loss 269.9235 Test MSE 279.2887531486397 Test RE 0.2813299015467548 Lambda1 6.6760105e-05\n",
      "72 Train Loss 269.8886 Test MSE 279.38512381718607 Test RE 0.281378434851438 Lambda1 4.943332e-05\n",
      "73 Train Loss 269.8271 Test MSE 279.522571805063 Test RE 0.28144764065534683 Lambda1 4.34431e-05\n",
      "74 Train Loss 269.80475 Test MSE 279.4858317300045 Test RE 0.2814291434957425 Lambda1 3.7103615e-05\n",
      "Training time: 270.21\n",
      "Training time: 270.21\n",
      "inv_HT_tanh_tune3\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 854.7646 Test MSE 858.0527194831371 Test RE 0.4931126646311406 Lambda1 -0.016162816\n",
      "1 Train Loss 854.72015 Test MSE 858.0849908685686 Test RE 0.49312193753412015 Lambda1 -0.01622542\n",
      "2 Train Loss 854.50964 Test MSE 857.6677201921555 Test RE 0.4930020249685469 Lambda1 -0.018690389\n",
      "3 Train Loss 851.0883 Test MSE 853.5626274683088 Test RE 0.49182077116581446 Lambda1 -0.60575897\n",
      "4 Train Loss 840.49097 Test MSE 842.0340211847071 Test RE 0.4884881019076092 Lambda1 -0.5824116\n",
      "5 Train Loss 819.58594 Test MSE 820.4734863172496 Test RE 0.48219360496952035 Lambda1 -0.85626334\n",
      "6 Train Loss 783.8123 Test MSE 777.5989631101862 Test RE 0.46942585616497595 Lambda1 -1.1786873\n",
      "7 Train Loss 755.8137 Test MSE 754.9442070233478 Test RE 0.4625371276617514 Lambda1 -1.3414822\n",
      "8 Train Loss 733.6229 Test MSE 735.6825971958732 Test RE 0.4565984280856637 Lambda1 -1.3591119\n",
      "9 Train Loss 722.88446 Test MSE 726.662098054518 Test RE 0.4537905261840462 Lambda1 -1.3702223\n",
      "10 Train Loss 713.37744 Test MSE 720.0889616750114 Test RE 0.45173344689364675 Lambda1 -1.4509279\n",
      "11 Train Loss 702.96234 Test MSE 709.747848906716 Test RE 0.44847807170053855 Lambda1 -1.5165201\n",
      "12 Train Loss 695.39453 Test MSE 695.6514114972788 Test RE 0.44400208135052144 Lambda1 -1.5821571\n",
      "13 Train Loss 689.17224 Test MSE 692.3323914389756 Test RE 0.4429416265530277 Lambda1 -1.5899495\n",
      "14 Train Loss 663.81714 Test MSE 671.5139308513425 Test RE 0.4362311599821137 Lambda1 -1.7421644\n",
      "15 Train Loss 655.9908 Test MSE 665.4562751908625 Test RE 0.43425910506242316 Lambda1 -1.728036\n",
      "16 Train Loss 651.2646 Test MSE 660.148301078247 Test RE 0.4325237160556649 Lambda1 -1.7602968\n",
      "17 Train Loss 648.3169 Test MSE 655.6985169191703 Test RE 0.4310635203329221 Lambda1 -1.7304206\n",
      "18 Train Loss 646.0404 Test MSE 653.9407274314736 Test RE 0.43048533736620603 Lambda1 -1.7321553\n",
      "19 Train Loss 642.0223 Test MSE 652.9361809135758 Test RE 0.4301545667553581 Lambda1 -1.7261117\n",
      "20 Train Loss 636.41504 Test MSE 649.456214717027 Test RE 0.4290067338786715 Lambda1 -1.6780623\n",
      "21 Train Loss 632.3565 Test MSE 646.4117035653506 Test RE 0.4280000069803335 Lambda1 -1.6494074\n",
      "22 Train Loss 630.5503 Test MSE 641.9727176175393 Test RE 0.4265279119212735 Lambda1 -1.6314938\n",
      "23 Train Loss 628.75024 Test MSE 641.0839201397484 Test RE 0.42623255027604995 Lambda1 -1.6159002\n",
      "24 Train Loss 626.03174 Test MSE 640.5187295494175 Test RE 0.42604462187968084 Lambda1 -1.6356094\n",
      "25 Train Loss 625.016 Test MSE 638.2860471083576 Test RE 0.42530143305550805 Lambda1 -1.6331447\n",
      "26 Train Loss 621.3285 Test MSE 635.6200491477379 Test RE 0.4244123025406108 Lambda1 -1.5851437\n",
      "27 Train Loss 620.4871 Test MSE 634.9040236172838 Test RE 0.42417318510269864 Lambda1 -1.5736241\n",
      "28 Train Loss 619.3267 Test MSE 635.0355996252483 Test RE 0.424217135149532 Lambda1 -1.5801271\n",
      "29 Train Loss 618.5659 Test MSE 635.0103434724041 Test RE 0.42420869924504007 Lambda1 -1.5767316\n",
      "30 Train Loss 617.1586 Test MSE 634.6548527766466 Test RE 0.4240899426306147 Lambda1 -1.546662\n",
      "31 Train Loss 616.44415 Test MSE 634.5849119434919 Test RE 0.4240665740066899 Lambda1 -1.5223706\n",
      "32 Train Loss 616.03265 Test MSE 634.1020953698026 Test RE 0.42390522024143973 Lambda1 -1.4932244\n",
      "33 Train Loss 614.94196 Test MSE 633.0672288869379 Test RE 0.42355916836792995 Lambda1 -1.4447454\n",
      "34 Train Loss 614.6803 Test MSE 632.6348138789142 Test RE 0.4234144881356222 Lambda1 -1.4195663\n",
      "35 Train Loss 613.89984 Test MSE 631.5679808752367 Test RE 0.4230573285741708 Lambda1 -1.4306653\n",
      "36 Train Loss 613.17786 Test MSE 630.4670395703539 Test RE 0.42268843365242703 Lambda1 -1.4371095\n",
      "37 Train Loss 612.5249 Test MSE 629.609359502648 Test RE 0.42240082557661635 Lambda1 -1.4237665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 Train Loss 612.26416 Test MSE 629.1521185394537 Test RE 0.42224741772461083 Lambda1 -1.4029624\n",
      "39 Train Loss 611.5675 Test MSE 628.6713358804418 Test RE 0.4220860513167341 Lambda1 -1.3835708\n",
      "40 Train Loss 610.95245 Test MSE 627.6907930434973 Test RE 0.4217567576645278 Lambda1 -1.3778565\n",
      "41 Train Loss 610.56177 Test MSE 627.9825186510328 Test RE 0.4218547541265972 Lambda1 -1.392654\n",
      "42 Train Loss 610.45575 Test MSE 627.713069239702 Test RE 0.4217642414870036 Lambda1 -1.402867\n",
      "43 Train Loss 609.8055 Test MSE 626.7857271697766 Test RE 0.4214525829408095 Lambda1 -1.3764263\n",
      "44 Train Loss 609.1227 Test MSE 626.1550798489421 Test RE 0.4212405050162626 Lambda1 -1.3900405\n",
      "45 Train Loss 608.7682 Test MSE 626.0936079380227 Test RE 0.4212198271560945 Lambda1 -1.4031742\n",
      "46 Train Loss 608.59406 Test MSE 626.2008500675388 Test RE 0.4212559004975866 Lambda1 -1.4141185\n",
      "47 Train Loss 608.2146 Test MSE 626.0196774292544 Test RE 0.4211949571405858 Lambda1 -1.4311615\n",
      "48 Train Loss 607.92706 Test MSE 626.1399738969478 Test RE 0.42123542378524637 Lambda1 -1.4398319\n",
      "49 Train Loss 607.60004 Test MSE 626.1838561818117 Test RE 0.42125018442166334 Lambda1 -1.4349653\n",
      "50 Train Loss 607.2754 Test MSE 625.797264112307 Test RE 0.42112012906968316 Lambda1 -1.4247419\n",
      "51 Train Loss 607.0604 Test MSE 625.6671805414824 Test RE 0.42107635797928783 Lambda1 -1.4184678\n",
      "52 Train Loss 606.78735 Test MSE 625.2360027418662 Test RE 0.42093124083539024 Lambda1 -1.4020201\n",
      "53 Train Loss 606.5068 Test MSE 625.2238706609309 Test RE 0.42092715694016286 Lambda1 -1.3909547\n",
      "54 Train Loss 605.8362 Test MSE 624.5430084427628 Test RE 0.4206979018860732 Lambda1 -1.3670335\n",
      "55 Train Loss 605.53326 Test MSE 624.3492807841975 Test RE 0.4206326484611042 Lambda1 -1.3520385\n",
      "56 Train Loss 605.3681 Test MSE 623.9915921778405 Test RE 0.4205121413462998 Lambda1 -1.3491735\n",
      "57 Train Loss 605.2635 Test MSE 624.0867422170012 Test RE 0.42054420125065256 Lambda1 -1.3517249\n",
      "58 Train Loss 605.1345 Test MSE 624.0377844637262 Test RE 0.4205277057047183 Lambda1 -1.3532032\n",
      "59 Train Loss 604.6889 Test MSE 623.8397662694467 Test RE 0.42046097998235094 Lambda1 -1.3577701\n",
      "60 Train Loss 604.56116 Test MSE 623.7388793200896 Test RE 0.420426980273595 Lambda1 -1.3550179\n",
      "61 Train Loss 604.39087 Test MSE 623.4713231647783 Test RE 0.4203367983915496 Lambda1 -1.3478932\n",
      "62 Train Loss 604.2609 Test MSE 623.3908028152446 Test RE 0.42030965459397607 Lambda1 -1.3426405\n",
      "63 Train Loss 604.15234 Test MSE 623.2738572392935 Test RE 0.4202702285550686 Lambda1 -1.3361722\n",
      "64 Train Loss 603.98413 Test MSE 623.2377557984156 Test RE 0.42025805687455964 Lambda1 -1.3269993\n",
      "65 Train Loss 603.9241 Test MSE 623.253506049981 Test RE 0.42026336715000245 Lambda1 -1.3167498\n",
      "66 Train Loss 603.8938 Test MSE 623.2740766059133 Test RE 0.4202703025139313 Lambda1 -1.3031195\n",
      "67 Train Loss 603.83264 Test MSE 623.1542739349387 Test RE 0.42022990942975025 Lambda1 -1.2910197\n",
      "68 Train Loss 603.8044 Test MSE 623.1836956457132 Test RE 0.4202398297154941 Lambda1 -1.2859603\n",
      "69 Train Loss 603.67645 Test MSE 623.025379463861 Test RE 0.4201864465864563 Lambda1 -1.2839588\n",
      "70 Train Loss 603.52814 Test MSE 622.8980043753072 Test RE 0.42014349165761955 Lambda1 -1.2802908\n",
      "71 Train Loss 603.3412 Test MSE 622.8837672032405 Test RE 0.42013869015775784 Lambda1 -1.2882911\n",
      "72 Train Loss 603.0469 Test MSE 622.8160082259335 Test RE 0.4201158376259339 Lambda1 -1.2989985\n",
      "73 Train Loss 602.9558 Test MSE 622.7821755362517 Test RE 0.4201044266782292 Lambda1 -1.3111264\n",
      "74 Train Loss 602.9345 Test MSE 622.7767038433261 Test RE 0.4201025811794668 Lambda1 -1.3121519\n",
      "Training time: 295.24\n",
      "Training time: 295.24\n",
      "inv_HT_tanh_tune4\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "1 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "2 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "3 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "4 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "5 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "6 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "7 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "8 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "9 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "10 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "11 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "12 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "13 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "14 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "15 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "16 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "17 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "18 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "19 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "20 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "21 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "22 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "23 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "24 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "25 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "26 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "27 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "28 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "29 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "30 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "31 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "32 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "33 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "34 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "35 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "36 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "37 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "38 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "40 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "41 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "42 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "43 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "44 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "45 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "46 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "47 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "48 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "49 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "50 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "51 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "52 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "53 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "54 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "55 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "56 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "57 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "58 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "59 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "60 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "61 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "62 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "63 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "64 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "65 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "66 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "67 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "68 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "69 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "70 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "71 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "72 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "73 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "74 Train Loss 854.7209 Test MSE 858.0781735124077 Test RE 0.49311997864042545 Lambda1 -0.044368897\n",
      "Training time: 190.56\n",
      "Training time: 190.56\n",
      "inv_HT_tanh_tune4\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "1 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "2 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "3 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "4 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "5 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "6 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "7 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "8 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "9 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "10 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "11 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "12 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "13 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "14 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "15 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "16 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "17 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "18 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "19 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "20 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "21 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "22 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "23 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "24 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "25 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "26 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "27 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "28 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "29 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "30 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "31 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "32 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "33 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "34 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "35 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "36 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "37 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "38 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "39 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "41 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "42 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "43 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "44 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "45 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "46 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "47 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "48 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "49 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "50 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "51 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "52 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "53 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "54 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "55 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "56 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "57 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "58 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "59 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "60 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "61 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "62 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "63 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "64 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "65 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "66 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "67 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "68 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "69 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "70 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "71 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "72 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "73 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "74 Train Loss 854.7212 Test MSE 858.0782494581302 Test RE 0.4931200004626518 Lambda1 -0.07346136\n",
      "Training time: 198.77\n",
      "Training time: 198.77\n",
      "inv_HT_tanh_tune4\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "1 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "2 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "3 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "4 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "5 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "6 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "7 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "8 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "9 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "10 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "11 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "12 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "13 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "14 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "15 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "16 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "17 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "18 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "19 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "20 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "21 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "22 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "23 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "24 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "25 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "26 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "27 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "28 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "29 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "30 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "31 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "32 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "33 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "34 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "35 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "36 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "37 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "38 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "39 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "40 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "41 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "43 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "44 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "45 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "46 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "47 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "48 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "49 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "50 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "51 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "52 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "53 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "54 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "55 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "56 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "57 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "58 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "59 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "60 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "61 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "62 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "63 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "64 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "65 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "66 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "67 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "68 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "69 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "70 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "71 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "72 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "73 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "74 Train Loss 854.7204 Test MSE 858.0776376486937 Test RE 0.4931198246654423 Lambda1 -0.32304457\n",
      "Training time: 179.69\n",
      "Training time: 179.69\n",
      "inv_HT_tanh_tune4\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "1 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "2 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "3 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "4 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "5 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "6 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "7 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "8 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "9 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "10 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "11 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "12 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "13 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "14 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "15 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "16 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "17 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "18 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "19 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "20 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "21 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "22 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "23 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "24 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "25 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "26 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "27 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "28 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "29 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "30 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "31 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "32 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "33 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "34 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "35 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "36 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "37 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "38 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "39 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "40 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "41 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "42 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "44 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "45 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "46 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "47 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "48 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "49 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "50 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "51 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "52 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "53 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "54 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "55 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "56 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "57 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "58 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "59 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "60 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "61 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "62 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "63 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "64 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "65 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "66 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "67 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "68 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "69 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "70 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "71 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "72 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "73 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "74 Train Loss 854.7214 Test MSE 858.0786020268781 Test RE 0.49312010176966153 Lambda1 -0.045282047\n",
      "Training time: 160.90\n",
      "Training time: 160.90\n",
      "inv_HT_tanh_tune4\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 854.72 Test MSE 858.0769271770816 Test RE 0.4931196205185833 Lambda1 -0.003862888\n",
      "1 Train Loss 854.5028 Test MSE 857.6367682105027 Test RE 0.4929931290249623 Lambda1 -0.008708122\n",
      "2 Train Loss 854.171 Test MSE 857.2472762686305 Test RE 0.49288117098857426 Lambda1 -0.5970764\n",
      "3 Train Loss 851.74695 Test MSE 853.1367350892393 Test RE 0.4916980567647906 Lambda1 -0.7116089\n",
      "4 Train Loss 841.2943 Test MSE 843.5854336869096 Test RE 0.48893790427632405 Lambda1 -1.005792\n",
      "5 Train Loss 834.2758 Test MSE 837.1315026758198 Test RE 0.4870639801451113 Lambda1 -1.1623008\n",
      "6 Train Loss 828.53217 Test MSE 830.9517812308839 Test RE 0.4852628920643479 Lambda1 -0.9115295\n",
      "7 Train Loss 822.83954 Test MSE 825.2874991196638 Test RE 0.4836061376251867 Lambda1 -0.8187497\n",
      "8 Train Loss 818.3952 Test MSE 819.0383575459064 Test RE 0.48177170663940316 Lambda1 -0.7654044\n",
      "9 Train Loss 810.4036 Test MSE 810.6069843563388 Test RE 0.47928555629199304 Lambda1 -0.787003\n",
      "10 Train Loss 793.9339 Test MSE 793.8426501198586 Test RE 0.4743035603852693 Lambda1 -0.83008516\n",
      "11 Train Loss 787.645 Test MSE 786.133465449471 Test RE 0.4719949074282495 Lambda1 -0.73663867\n",
      "12 Train Loss 781.3857 Test MSE 781.2604974898563 Test RE 0.4705297672822563 Lambda1 -0.6689363\n",
      "13 Train Loss 773.74445 Test MSE 774.4675875173364 Test RE 0.4684797183811092 Lambda1 -0.70874625\n",
      "14 Train Loss 766.96027 Test MSE 768.0565094841585 Test RE 0.4665366405586168 Lambda1 -0.65349954\n",
      "15 Train Loss 759.673 Test MSE 760.9513878082809 Test RE 0.46437371286913864 Lambda1 -0.56695235\n",
      "16 Train Loss 754.35175 Test MSE 754.6244149362121 Test RE 0.46243915261966395 Lambda1 -0.6231888\n",
      "17 Train Loss 751.651 Test MSE 751.3306990343759 Test RE 0.46142884284394275 Lambda1 -0.67256314\n",
      "18 Train Loss 747.63574 Test MSE 748.8707119285407 Test RE 0.4606728244453314 Lambda1 -0.68028903\n",
      "19 Train Loss 745.07104 Test MSE 746.9189077135065 Test RE 0.4600721000633716 Lambda1 -0.73808753\n",
      "20 Train Loss 742.64856 Test MSE 741.6218108856344 Test RE 0.4584377976864102 Lambda1 -0.75460225\n",
      "21 Train Loss 740.36206 Test MSE 739.2925374002871 Test RE 0.4577173045969572 Lambda1 -0.72736514\n",
      "22 Train Loss 738.3303 Test MSE 736.5587617915401 Test RE 0.4568702411865682 Lambda1 -0.72841\n",
      "23 Train Loss 734.70154 Test MSE 729.8449281493719 Test RE 0.4547832572116085 Lambda1 -0.7222756\n",
      "24 Train Loss 731.5807 Test MSE 727.8538353606299 Test RE 0.4541624855531472 Lambda1 -0.7260228\n",
      "25 Train Loss 727.65326 Test MSE 727.0098065465062 Test RE 0.4538990827946014 Lambda1 -0.6654742\n",
      "26 Train Loss 724.85986 Test MSE 727.2627373097787 Test RE 0.45397803293862593 Lambda1 -0.6595367\n",
      "27 Train Loss 721.848 Test MSE 723.48862296296 Test RE 0.4527985460946694 Lambda1 -0.6996937\n",
      "28 Train Loss 719.33673 Test MSE 719.053840437621 Test RE 0.45140864879745746 Lambda1 -0.73207015\n",
      "29 Train Loss 717.8781 Test MSE 717.6653617137468 Test RE 0.4509726076190442 Lambda1 -0.77161545\n",
      "30 Train Loss 716.00867 Test MSE 717.4673378948921 Test RE 0.4509103853885375 Lambda1 -0.7745964\n",
      "31 Train Loss 713.2484 Test MSE 716.9256590962699 Test RE 0.45074013741939345 Lambda1 -0.7891762\n",
      "32 Train Loss 711.721 Test MSE 716.7122758618909 Test RE 0.4506730540719571 Lambda1 -0.8132216\n",
      "33 Train Loss 709.95276 Test MSE 713.5034104312458 Test RE 0.4496630452151011 Lambda1 -0.7983253\n",
      "34 Train Loss 704.7158 Test MSE 709.980716821159 Test RE 0.4485516383823072 Lambda1 -0.7660712\n",
      "35 Train Loss 703.6708 Test MSE 708.0329704467855 Test RE 0.4479359421890984 Lambda1 -0.7474336\n",
      "36 Train Loss 700.8657 Test MSE 706.1764494665802 Test RE 0.447348294185637 Lambda1 -0.75019145\n",
      "37 Train Loss 700.3826 Test MSE 704.5924107109286 Test RE 0.4468462844822332 Lambda1 -0.7400671\n",
      "38 Train Loss 699.3179 Test MSE 703.830434950233 Test RE 0.44660459997347907 Lambda1 -0.7293693\n",
      "39 Train Loss 697.7553 Test MSE 702.639262138755 Test RE 0.44622651989534434 Lambda1 -0.7312471\n",
      "40 Train Loss 696.8568 Test MSE 701.2726763764899 Test RE 0.445792368518787 Lambda1 -0.7500642\n",
      "41 Train Loss 696.2403 Test MSE 699.8882835619396 Test RE 0.4453521284697432 Lambda1 -0.7446267\n",
      "42 Train Loss 695.85706 Test MSE 699.2180907616757 Test RE 0.4451388492341025 Lambda1 -0.7511899\n",
      "43 Train Loss 695.025 Test MSE 698.2546608512189 Test RE 0.44483207233767663 Lambda1 -0.74103075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 Train Loss 694.41016 Test MSE 696.286251730985 Test RE 0.44420462971179125 Lambda1 -0.7520455\n",
      "45 Train Loss 693.68506 Test MSE 695.6753651207041 Test RE 0.44400972552900575 Lambda1 -0.7537741\n",
      "46 Train Loss 692.0835 Test MSE 695.0224299162292 Test RE 0.4438013110500593 Lambda1 -0.75293964\n",
      "47 Train Loss 691.0096 Test MSE 693.5147736770015 Test RE 0.4433196984883943 Lambda1 -0.7670556\n",
      "48 Train Loss 690.39844 Test MSE 693.6272859661505 Test RE 0.44335565799000415 Lambda1 -0.7644753\n",
      "49 Train Loss 689.88885 Test MSE 692.3364681187418 Test RE 0.44294293064375834 Lambda1 -0.776381\n",
      "50 Train Loss 689.4788 Test MSE 692.7262753494905 Test RE 0.44306760850515753 Lambda1 -0.7723392\n",
      "51 Train Loss 689.2754 Test MSE 692.7792999921735 Test RE 0.4430845654569161 Lambda1 -0.7738815\n",
      "52 Train Loss 688.71606 Test MSE 693.4807657714323 Test RE 0.44330882881420347 Lambda1 -0.7650799\n",
      "53 Train Loss 687.5668 Test MSE 692.1354047297556 Test RE 0.4428786078196575 Lambda1 -0.76832634\n",
      "54 Train Loss 685.17645 Test MSE 692.006347403475 Test RE 0.4428373157594283 Lambda1 -0.78533137\n",
      "55 Train Loss 684.19476 Test MSE 691.6820547755271 Test RE 0.4427335409124918 Lambda1 -0.7782387\n",
      "56 Train Loss 682.741 Test MSE 692.0714113568752 Test RE 0.4428581335375867 Lambda1 -0.7815561\n",
      "57 Train Loss 682.0261 Test MSE 691.6642969961446 Test RE 0.44272785765459044 Lambda1 -0.797747\n",
      "58 Train Loss 681.82764 Test MSE 691.7470793114053 Test RE 0.44275435095537996 Lambda1 -0.80800843\n",
      "59 Train Loss 681.5425 Test MSE 692.0459907023777 Test RE 0.44285000009441955 Lambda1 -0.811439\n",
      "60 Train Loss 681.2773 Test MSE 692.3702673434392 Test RE 0.44295374254347447 Lambda1 -0.8173016\n",
      "61 Train Loss 681.06055 Test MSE 692.4734714746419 Test RE 0.4429867544699668 Lambda1 -0.8246986\n",
      "62 Train Loss 680.5539 Test MSE 692.8810810562178 Test RE 0.4431171125915187 Lambda1 -0.8475875\n",
      "63 Train Loss 680.33484 Test MSE 693.1132951938702 Test RE 0.44319136013633553 Lambda1 -0.8643012\n",
      "64 Train Loss 679.9086 Test MSE 692.803935991596 Test RE 0.44309244367589273 Lambda1 -0.8611469\n",
      "65 Train Loss 679.6494 Test MSE 692.2731060940549 Test RE 0.44292266130625657 Lambda1 -0.8700631\n",
      "66 Train Loss 678.8563 Test MSE 691.5582124966045 Test RE 0.4426939045038812 Lambda1 -0.8698156\n",
      "67 Train Loss 678.31384 Test MSE 691.3848418365106 Test RE 0.442638410299712 Lambda1 -0.8722179\n",
      "68 Train Loss 678.20557 Test MSE 690.9620262582524 Test RE 0.4425030421036284 Lambda1 -0.87829536\n",
      "69 Train Loss 678.0735 Test MSE 690.6595134123085 Test RE 0.44240616448627457 Lambda1 -0.8774194\n",
      "70 Train Loss 677.35236 Test MSE 690.2613668040984 Test RE 0.44227862848402333 Lambda1 -0.8875343\n",
      "71 Train Loss 676.828 Test MSE 689.6772480259069 Test RE 0.4420914545076108 Lambda1 -0.90647805\n",
      "72 Train Loss 676.306 Test MSE 689.6413867101998 Test RE 0.44207996058972154 Lambda1 -0.9020939\n",
      "73 Train Loss 676.0669 Test MSE 689.4142191788618 Test RE 0.4420071441327301 Lambda1 -0.8986675\n",
      "74 Train Loss 675.8496 Test MSE 689.1070916092506 Test RE 0.44190867814621193 Lambda1 -0.90167177\n",
      "Training time: 274.09\n",
      "Training time: 274.09\n",
      "inv_HT_tanh_tune4\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 854.721 Test MSE 858.0767531263208 Test RE 0.49311957050683786 Lambda1 0.008045207\n",
      "1 Train Loss 854.5252 Test MSE 857.6942745092147 Test RE 0.49300965684651354 Lambda1 -0.0005489157\n",
      "2 Train Loss 854.33215 Test MSE 857.5965694479896 Test RE 0.49298157521414393 Lambda1 -0.6651576\n",
      "3 Train Loss 851.13934 Test MSE 853.9718505472335 Test RE 0.49193865372447987 Lambda1 -1.7270794\n",
      "4 Train Loss 848.31256 Test MSE 850.6248817651913 Test RE 0.4909736806000757 Lambda1 -1.4232152\n",
      "5 Train Loss 842.51196 Test MSE 844.04218521185 Test RE 0.4890702518155195 Lambda1 -1.6789948\n",
      "6 Train Loss 836.68787 Test MSE 837.4681966726599 Test RE 0.48716191877939413 Lambda1 -1.7917314\n",
      "7 Train Loss 831.057 Test MSE 832.3485844946005 Test RE 0.4856705764804551 Lambda1 -2.0195415\n",
      "8 Train Loss 823.97284 Test MSE 822.7781489091017 Test RE 0.48287035704389797 Lambda1 -1.8646481\n",
      "9 Train Loss 812.8686 Test MSE 813.88065838626 Test RE 0.4802523896371117 Lambda1 -1.6989894\n",
      "10 Train Loss 793.976 Test MSE 783.260940726174 Test RE 0.47113178564019004 Lambda1 -1.4818901\n",
      "11 Train Loss 775.34503 Test MSE 754.4354383915364 Test RE 0.4623812459158109 Lambda1 -1.4719641\n",
      "12 Train Loss 763.677 Test MSE 738.0610422476592 Test RE 0.45733591864436657 Lambda1 -1.4030426\n",
      "13 Train Loss 754.6043 Test MSE 741.6301618336526 Test RE 0.4584403787724735 Lambda1 -1.5119096\n",
      "14 Train Loss 743.38556 Test MSE 731.0161957426021 Test RE 0.4551480328860391 Lambda1 -1.4375321\n",
      "15 Train Loss 735.7975 Test MSE 726.1813753111604 Test RE 0.45364039896673647 Lambda1 -1.3683352\n",
      "16 Train Loss 721.77 Test MSE 721.6658037156074 Test RE 0.4522277766232179 Lambda1 -1.3861103\n",
      "17 Train Loss 711.3701 Test MSE 712.6784202522766 Test RE 0.44940300799185556 Lambda1 -1.347698\n",
      "18 Train Loss 704.5732 Test MSE 702.4527065399153 Test RE 0.44616727784436727 Lambda1 -1.3022765\n",
      "19 Train Loss 699.2659 Test MSE 697.6425209983134 Test RE 0.4446370438186765 Lambda1 -1.3059313\n",
      "20 Train Loss 694.58386 Test MSE 691.3791808545665 Test RE 0.44263659815904427 Lambda1 -1.3252966\n",
      "21 Train Loss 686.2221 Test MSE 681.8478544815167 Test RE 0.4395749240853721 Lambda1 -1.2711391\n",
      "22 Train Loss 682.73895 Test MSE 681.5998613834363 Test RE 0.43949497849309316 Lambda1 -1.2712029\n",
      "23 Train Loss 677.8422 Test MSE 675.6600424318514 Test RE 0.4375757931840722 Lambda1 -1.2639924\n",
      "24 Train Loss 672.9988 Test MSE 670.8639062675558 Test RE 0.4360199732739413 Lambda1 -1.2808217\n",
      "25 Train Loss 668.8809 Test MSE 670.1747847534396 Test RE 0.4357959725913624 Lambda1 -1.316702\n",
      "26 Train Loss 665.95715 Test MSE 667.8106124429416 Test RE 0.4350266158173102 Lambda1 -1.3561686\n",
      "27 Train Loss 659.56366 Test MSE 660.849327887863 Test RE 0.43275330860808126 Lambda1 -1.3215814\n",
      "28 Train Loss 655.729 Test MSE 655.0678845302538 Test RE 0.43085617808287674 Lambda1 -1.3390942\n",
      "29 Train Loss 649.87866 Test MSE 649.7369710044794 Test RE 0.4290994524645516 Lambda1 -1.4135292\n",
      "30 Train Loss 641.81433 Test MSE 644.2045814752524 Test RE 0.42726869595890044 Lambda1 -1.4562178\n",
      "31 Train Loss 639.4446 Test MSE 642.8404998050233 Test RE 0.42681609264722353 Lambda1 -1.4928168\n",
      "32 Train Loss 637.19226 Test MSE 643.5034788091534 Test RE 0.4270361294891999 Lambda1 -1.5647594\n",
      "33 Train Loss 636.13794 Test MSE 643.4754721108845 Test RE 0.42702683660846563 Lambda1 -1.6043122\n",
      "34 Train Loss 634.90454 Test MSE 643.8135509324858 Test RE 0.4271390007687912 Lambda1 -1.6090604\n",
      "35 Train Loss 632.5685 Test MSE 643.2210712061321 Test RE 0.42694241477900036 Lambda1 -1.6192915\n",
      "36 Train Loss 631.5096 Test MSE 643.6847078148153 Test RE 0.4270962580569082 Lambda1 -1.6512258\n",
      "37 Train Loss 630.27545 Test MSE 642.6924755432657 Test RE 0.4267669492170421 Lambda1 -1.667498\n",
      "38 Train Loss 629.89886 Test MSE 642.3216623899099 Test RE 0.42664381596341067 Lambda1 -1.6705226\n",
      "39 Train Loss 628.23676 Test MSE 640.3792477854627 Test RE 0.4259982308155546 Lambda1 -1.6773363\n",
      "40 Train Loss 627.07874 Test MSE 638.3278606552623 Test RE 0.42531536338522996 Lambda1 -1.6570088\n",
      "41 Train Loss 625.922 Test MSE 638.1257210763654 Test RE 0.42524801564661996 Lambda1 -1.6792578\n",
      "42 Train Loss 625.45764 Test MSE 637.3231993482867 Test RE 0.4249805306306278 Lambda1 -1.6896586\n",
      "43 Train Loss 623.7141 Test MSE 636.6256105924136 Test RE 0.4247478835151933 Lambda1 -1.6955057\n",
      "44 Train Loss 621.8585 Test MSE 635.9866814676009 Test RE 0.424534687631623 Lambda1 -1.6836587\n",
      "45 Train Loss 619.70087 Test MSE 634.8049566948046 Test RE 0.42414009098940514 Lambda1 -1.658669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 Train Loss 618.2745 Test MSE 630.6870608011034 Test RE 0.4227621824062248 Lambda1 -1.6245859\n",
      "47 Train Loss 617.6612 Test MSE 630.3554478091902 Test RE 0.4226510243739476 Lambda1 -1.6464885\n",
      "48 Train Loss 617.18567 Test MSE 630.7603540680233 Test RE 0.4227867466657707 Lambda1 -1.6697356\n",
      "49 Train Loss 616.23083 Test MSE 629.9210120467944 Test RE 0.42250535547556434 Lambda1 -1.7127981\n",
      "50 Train Loss 614.3803 Test MSE 626.8706033042833 Test RE 0.4214811174571989 Lambda1 -1.7601194\n",
      "51 Train Loss 613.0293 Test MSE 625.8099869585222 Test RE 0.4211244098645314 Lambda1 -1.8534524\n",
      "52 Train Loss 612.26337 Test MSE 624.0039132175933 Test RE 0.4205162929416893 Lambda1 -1.9398222\n",
      "53 Train Loss 611.3873 Test MSE 623.8145567634853 Test RE 0.4204524844349043 Lambda1 -2.0101855\n",
      "54 Train Loss 610.8838 Test MSE 623.4449409412088 Test RE 0.42032790501001593 Lambda1 -2.0246942\n",
      "55 Train Loss 609.7556 Test MSE 622.5861503660013 Test RE 0.420038306029499 Lambda1 -2.0596328\n",
      "56 Train Loss 607.1527 Test MSE 620.8551118322565 Test RE 0.41945396231598675 Lambda1 -2.1495595\n",
      "57 Train Loss 606.08356 Test MSE 618.7271174943937 Test RE 0.4187345015262691 Lambda1 -2.1448185\n",
      "58 Train Loss 604.6177 Test MSE 617.7665809605267 Test RE 0.418409345251212 Lambda1 -2.187466\n",
      "59 Train Loss 602.5814 Test MSE 617.2023352268029 Test RE 0.4182182215906266 Lambda1 -2.2442095\n",
      "60 Train Loss 601.48773 Test MSE 616.8845581987296 Test RE 0.4181105443777971 Lambda1 -2.3049188\n",
      "61 Train Loss 600.89935 Test MSE 616.3939547823524 Test RE 0.41794425130167967 Lambda1 -2.3586206\n",
      "62 Train Loss 599.54956 Test MSE 613.6362955552406 Test RE 0.4170082916060479 Lambda1 -2.351179\n",
      "63 Train Loss 598.8085 Test MSE 612.5418840904191 Test RE 0.4166362615237254 Lambda1 -2.4111297\n",
      "64 Train Loss 598.20337 Test MSE 612.627734328286 Test RE 0.4166654571345918 Lambda1 -2.4680293\n",
      "65 Train Loss 597.79297 Test MSE 611.8709112270395 Test RE 0.4164080091958555 Lambda1 -2.5212083\n",
      "66 Train Loss 597.2485 Test MSE 610.8973516519632 Test RE 0.416076599919316 Lambda1 -2.54057\n",
      "67 Train Loss 596.5243 Test MSE 609.097040457214 Test RE 0.4154630598149652 Lambda1 -2.5558436\n",
      "68 Train Loss 595.2439 Test MSE 608.1021123698085 Test RE 0.41512360257185715 Lambda1 -2.6356275\n",
      "69 Train Loss 594.4494 Test MSE 606.8989003710946 Test RE 0.4147127102175121 Lambda1 -2.6148076\n",
      "70 Train Loss 593.86334 Test MSE 606.4959378468428 Test RE 0.41457500900461863 Lambda1 -2.5758073\n",
      "71 Train Loss 590.7978 Test MSE 604.4372393949426 Test RE 0.41387079123650916 Lambda1 -2.5310183\n",
      "72 Train Loss 589.88885 Test MSE 604.228590691585 Test RE 0.4137993520102217 Lambda1 -2.4908466\n",
      "73 Train Loss 588.3225 Test MSE 603.2169204529586 Test RE 0.4134527912286754 Lambda1 -2.4844456\n",
      "74 Train Loss 587.5917 Test MSE 602.1940023804676 Test RE 0.41310208175123575 Lambda1 -2.5131352\n",
      "Training time: 264.95\n",
      "Training time: 264.95\n",
      "inv_HT_tanh_tune4\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 854.7189 Test MSE 858.0757720723193 Test RE 0.493119288610688 Lambda1 -0.019842098\n",
      "1 Train Loss 854.49036 Test MSE 857.5961032400146 Test RE 0.492981441216422 Lambda1 -0.040467195\n",
      "2 Train Loss 853.88715 Test MSE 857.3049077452741 Test RE 0.4928977385491146 Lambda1 -0.5424083\n",
      "3 Train Loss 846.1606 Test MSE 847.7530318063676 Test RE 0.49014417579226643 Lambda1 -0.6113882\n",
      "4 Train Loss 823.73737 Test MSE 822.2478717841237 Test RE 0.4827147279870708 Lambda1 -0.6556196\n",
      "5 Train Loss 806.8303 Test MSE 805.5367076080546 Test RE 0.47778426008885794 Lambda1 -0.82361925\n",
      "6 Train Loss 779.8934 Test MSE 780.505389217427 Test RE 0.4703023227780137 Lambda1 -0.8010337\n",
      "7 Train Loss 757.67737 Test MSE 760.1309053539899 Test RE 0.46412329395301605 Lambda1 -0.87047565\n",
      "8 Train Loss 743.9263 Test MSE 735.7193826008288 Test RE 0.456609843299364 Lambda1 -0.9345073\n",
      "9 Train Loss 725.3825 Test MSE 724.7446608460538 Test RE 0.45319142407605195 Lambda1 -0.9372457\n",
      "10 Train Loss 712.6248 Test MSE 715.4040597148847 Test RE 0.45026155906107934 Lambda1 -0.9267104\n",
      "11 Train Loss 699.28656 Test MSE 700.1051965204799 Test RE 0.4454211360287425 Lambda1 -0.9894795\n",
      "12 Train Loss 689.2656 Test MSE 689.7043795780959 Test RE 0.44210015024858323 Lambda1 -0.9622931\n",
      "13 Train Loss 679.8504 Test MSE 679.4436751430319 Test RE 0.43879927438059946 Lambda1 -0.9458988\n",
      "14 Train Loss 672.7409 Test MSE 674.5744912794287 Test RE 0.43722413567544743 Lambda1 -0.9759568\n",
      "15 Train Loss 662.8792 Test MSE 667.5619739165428 Test RE 0.4349456239578885 Lambda1 -0.9846341\n",
      "16 Train Loss 653.96533 Test MSE 663.59837859888 Test RE 0.43365247434611326 Lambda1 -0.9352935\n",
      "17 Train Loss 646.56934 Test MSE 655.025460404186 Test RE 0.43084222609927103 Lambda1 -0.9467218\n",
      "18 Train Loss 640.9575 Test MSE 647.7947397540706 Test RE 0.4284576280374775 Lambda1 -0.9739424\n",
      "19 Train Loss 632.46747 Test MSE 639.116888202038 Test RE 0.42557814519331805 Lambda1 -0.9758418\n",
      "20 Train Loss 623.0814 Test MSE 627.8927210462439 Test RE 0.4218245917417636 Lambda1 -0.96536565\n",
      "21 Train Loss 615.66034 Test MSE 619.0602612745703 Test RE 0.41884721682362036 Lambda1 -0.9833514\n",
      "22 Train Loss 608.4461 Test MSE 614.0035706137654 Test RE 0.41713306733699385 Lambda1 -0.96021247\n",
      "23 Train Loss 598.7666 Test MSE 602.8338123842998 Test RE 0.41332147672739467 Lambda1 -0.98676574\n",
      "24 Train Loss 590.5539 Test MSE 589.1571255580101 Test RE 0.4086059984833335 Lambda1 -1.0136892\n",
      "25 Train Loss 582.8013 Test MSE 584.5744048870831 Test RE 0.40701373842384503 Lambda1 -1.0005016\n",
      "26 Train Loss 566.02576 Test MSE 563.4706858912044 Test RE 0.3995994062078465 Lambda1 -0.9561363\n",
      "27 Train Loss 548.3384 Test MSE 546.1255583096837 Test RE 0.3934009655322642 Lambda1 -0.93546844\n",
      "28 Train Loss 534.98486 Test MSE 532.1922387972559 Test RE 0.3883501158132043 Lambda1 -0.92537665\n",
      "29 Train Loss 504.82352 Test MSE 502.44221230802043 Test RE 0.37733946575240007 Lambda1 -0.87144685\n",
      "30 Train Loss 493.39795 Test MSE 489.5171117545642 Test RE 0.37245440028249227 Lambda1 -0.8162734\n",
      "31 Train Loss 484.86234 Test MSE 477.8650586572864 Test RE 0.3679949075058419 Lambda1 -0.7690899\n",
      "32 Train Loss 471.39038 Test MSE 466.644684262904 Test RE 0.3636489451346115 Lambda1 -0.7182261\n",
      "33 Train Loss 460.34607 Test MSE 457.91533216689976 Test RE 0.3602315635930898 Lambda1 -0.75114006\n",
      "34 Train Loss 445.6989 Test MSE 434.6120573656491 Test RE 0.35094580540989895 Lambda1 -0.7054245\n",
      "35 Train Loss 435.41376 Test MSE 428.4315638403126 Test RE 0.34844152048501476 Lambda1 -0.66157734\n",
      "36 Train Loss 428.70706 Test MSE 424.5449054440675 Test RE 0.3468574184707685 Lambda1 -0.60704434\n",
      "37 Train Loss 420.09528 Test MSE 417.33563896140265 Test RE 0.3438997874258289 Lambda1 -0.594393\n",
      "38 Train Loss 414.62747 Test MSE 412.2216731548707 Test RE 0.3417862455454062 Lambda1 -0.5187615\n",
      "39 Train Loss 408.4107 Test MSE 407.48340836475046 Test RE 0.3398162443034775 Lambda1 -0.5065422\n",
      "40 Train Loss 395.37506 Test MSE 392.3712556486976 Test RE 0.3334554061266366 Lambda1 -0.49663776\n",
      "41 Train Loss 386.07056 Test MSE 378.9162440379888 Test RE 0.32768818470148 Lambda1 -0.49997178\n",
      "42 Train Loss 379.98862 Test MSE 373.66042036627755 Test RE 0.32540762086509867 Lambda1 -0.49068862\n",
      "43 Train Loss 372.5271 Test MSE 370.1156394295222 Test RE 0.3238604306518192 Lambda1 -0.49189517\n",
      "44 Train Loss 369.96887 Test MSE 367.01376052866215 Test RE 0.32250046447842545 Lambda1 -0.5268801\n",
      "45 Train Loss 366.22974 Test MSE 365.78495064058166 Test RE 0.3219601250308408 Lambda1 -0.558876\n",
      "46 Train Loss 364.13135 Test MSE 363.6023505738149 Test RE 0.3209981368768886 Lambda1 -0.58353996\n",
      "47 Train Loss 362.58145 Test MSE 362.24854112319423 Test RE 0.3203999895092836 Lambda1 -0.593274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 Train Loss 360.83966 Test MSE 362.82799143457294 Test RE 0.3206561419412057 Lambda1 -0.58564305\n",
      "49 Train Loss 357.65088 Test MSE 360.8352670621001 Test RE 0.319774375522019 Lambda1 -0.5985331\n",
      "50 Train Loss 356.88974 Test MSE 359.4958461100609 Test RE 0.3191803222916523 Lambda1 -0.60574776\n",
      "51 Train Loss 355.78174 Test MSE 357.5937274315347 Test RE 0.31833479922294966 Lambda1 -0.60241103\n",
      "52 Train Loss 352.88095 Test MSE 354.57357991873613 Test RE 0.3169876605983418 Lambda1 -0.5977046\n",
      "53 Train Loss 351.58066 Test MSE 354.1157888608792 Test RE 0.3167829626255117 Lambda1 -0.6092882\n",
      "54 Train Loss 349.3104 Test MSE 349.36552378126345 Test RE 0.3146510558454304 Lambda1 -0.6247065\n",
      "55 Train Loss 346.88248 Test MSE 344.8751786603107 Test RE 0.31262243385341515 Lambda1 -0.62479097\n",
      "56 Train Loss 342.2267 Test MSE 335.89703371102587 Test RE 0.3085263454815847 Lambda1 -0.54881823\n",
      "57 Train Loss 333.2324 Test MSE 321.3945286864169 Test RE 0.30179247744040116 Lambda1 -0.5501907\n",
      "58 Train Loss 322.93484 Test MSE 311.4358278323157 Test RE 0.2970800285507178 Lambda1 -0.505097\n",
      "59 Train Loss 311.35315 Test MSE 301.9250792159465 Test RE 0.2925086847702633 Lambda1 -0.48257202\n",
      "60 Train Loss 300.2873 Test MSE 289.08517712641844 Test RE 0.2862213873745945 Lambda1 -0.48303327\n",
      "61 Train Loss 289.77475 Test MSE 278.973233989776 Test RE 0.28117094409314125 Lambda1 -0.51503474\n",
      "62 Train Loss 277.81384 Test MSE 263.2404749844743 Test RE 0.27312754652563653 Lambda1 -0.5656146\n",
      "63 Train Loss 267.86612 Test MSE 256.5452075803665 Test RE 0.26963180791697233 Lambda1 -0.5779426\n",
      "64 Train Loss 264.17636 Test MSE 254.36392260937873 Test RE 0.2684830838038473 Lambda1 -0.5812825\n",
      "65 Train Loss 258.69394 Test MSE 242.37145184595417 Test RE 0.2620775998814347 Lambda1 -0.604014\n",
      "66 Train Loss 249.98845 Test MSE 235.14188748197955 Test RE 0.258139325303616 Lambda1 -0.6115947\n",
      "67 Train Loss 242.0412 Test MSE 223.22359248253517 Test RE 0.2515122933568683 Lambda1 -0.6229013\n",
      "68 Train Loss 238.37367 Test MSE 217.0594783681407 Test RE 0.24801534280756424 Lambda1 -0.6357354\n",
      "69 Train Loss 233.04648 Test MSE 210.94773349407888 Test RE 0.24449872706030845 Lambda1 -0.6622126\n",
      "70 Train Loss 230.66457 Test MSE 209.85149739435073 Test RE 0.24386260395241888 Lambda1 -0.6793851\n",
      "71 Train Loss 222.58932 Test MSE 200.82086332051898 Test RE 0.23855778049123466 Lambda1 -0.6938407\n",
      "72 Train Loss 220.34189 Test MSE 201.05610017827655 Test RE 0.23869746009837578 Lambda1 -0.68830526\n",
      "73 Train Loss 216.31648 Test MSE 197.21537890002006 Test RE 0.23640657973570617 Lambda1 -0.71355027\n",
      "74 Train Loss 209.57487 Test MSE 196.18976181044235 Test RE 0.23579106312833095 Lambda1 -0.7540124\n",
      "Training time: 259.98\n",
      "Training time: 259.98\n",
      "inv_HT_tanh_tune4\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 854.721 Test MSE 858.0760435993888 Test RE 0.49311936663131806 Lambda1 -0.23230882\n",
      "1 Train Loss 854.367 Test MSE 857.1649937039095 Test RE 0.49285751591191324 Lambda1 -0.26462486\n",
      "2 Train Loss 852.44653 Test MSE 855.4022386139046 Test RE 0.49235047571250745 Lambda1 -0.45077044\n",
      "3 Train Loss 849.3302 Test MSE 849.5714438805811 Test RE 0.49066956857739186 Lambda1 -0.73283774\n",
      "4 Train Loss 844.066 Test MSE 844.0858480289232 Test RE 0.48908290160314627 Lambda1 -0.8778495\n",
      "5 Train Loss 838.70966 Test MSE 840.3572684869711 Test RE 0.4880014933582724 Lambda1 -1.2260861\n",
      "6 Train Loss 833.2771 Test MSE 836.7295547571191 Test RE 0.48694703444522436 Lambda1 -1.3140675\n",
      "7 Train Loss 825.9566 Test MSE 829.6645074568185 Test RE 0.4848868724670113 Lambda1 -1.2388517\n",
      "8 Train Loss 820.8706 Test MSE 822.4820085960398 Test RE 0.48278345011256174 Lambda1 -1.1475843\n",
      "9 Train Loss 815.3139 Test MSE 817.5004015249993 Test RE 0.4813191687055361 Lambda1 -1.1126789\n",
      "10 Train Loss 806.5811 Test MSE 807.9115362566105 Test RE 0.4784880273347675 Lambda1 -1.0625844\n",
      "11 Train Loss 803.16614 Test MSE 804.8592698833758 Test RE 0.47758331508091173 Lambda1 -1.0866652\n",
      "12 Train Loss 797.04895 Test MSE 799.6424953061073 Test RE 0.4760330473120664 Lambda1 -1.0440497\n",
      "13 Train Loss 793.8977 Test MSE 796.074058279728 Test RE 0.4749697013013211 Lambda1 -1.0667845\n",
      "14 Train Loss 790.68866 Test MSE 792.7076569843822 Test RE 0.47396437235979616 Lambda1 -1.1561053\n",
      "15 Train Loss 787.8905 Test MSE 789.4515872399909 Test RE 0.47298995950429046 Lambda1 -1.2364801\n",
      "16 Train Loss 784.8108 Test MSE 788.0441069277739 Test RE 0.4725681343700072 Lambda1 -1.3508438\n",
      "17 Train Loss 781.9144 Test MSE 784.0660372683965 Test RE 0.4713738564059412 Lambda1 -1.3756891\n",
      "18 Train Loss 780.8658 Test MSE 780.534349518385 Test RE 0.4703110478750197 Lambda1 -1.4553173\n",
      "19 Train Loss 777.5986 Test MSE 779.1440647010833 Test RE 0.4698920030659598 Lambda1 -1.5407815\n",
      "20 Train Loss 774.9971 Test MSE 777.6999417349806 Test RE 0.4694563348827004 Lambda1 -1.6343099\n",
      "21 Train Loss 772.319 Test MSE 772.885343917458 Test RE 0.4680009197653105 Lambda1 -1.6678276\n",
      "22 Train Loss 770.11444 Test MSE 768.4422490413617 Test RE 0.46665377975680794 Lambda1 -1.6892977\n",
      "23 Train Loss 768.45593 Test MSE 767.2109543696773 Test RE 0.4662797642291423 Lambda1 -1.6891683\n",
      "24 Train Loss 767.19055 Test MSE 766.3126608525766 Test RE 0.4660067110591883 Lambda1 -1.6617726\n",
      "25 Train Loss 765.8827 Test MSE 766.4918443219323 Test RE 0.4660611900094378 Lambda1 -1.5718848\n",
      "26 Train Loss 764.3332 Test MSE 763.6879284630392 Test RE 0.465207956106448 Lambda1 -1.5165799\n",
      "27 Train Loss 761.33563 Test MSE 758.6882296455161 Test RE 0.4636826478729382 Lambda1 -1.5518755\n",
      "28 Train Loss 758.3559 Test MSE 757.1198318798777 Test RE 0.4632031260908363 Lambda1 -1.560339\n",
      "29 Train Loss 757.0848 Test MSE 756.2647853023002 Test RE 0.4629414950279742 Lambda1 -1.4832232\n",
      "30 Train Loss 755.69147 Test MSE 754.0297147871473 Test RE 0.46225689848667195 Lambda1 -1.42734\n",
      "31 Train Loss 753.4473 Test MSE 751.5122542763646 Test RE 0.4614845904428376 Lambda1 -1.4841259\n",
      "32 Train Loss 751.296 Test MSE 749.077679432535 Test RE 0.46073647876935675 Lambda1 -1.4893961\n",
      "33 Train Loss 749.09644 Test MSE 747.3469638089989 Test RE 0.460203913876727 Lambda1 -1.5075858\n",
      "34 Train Loss 748.28284 Test MSE 747.611360902495 Test RE 0.4602853123591768 Lambda1 -1.5290525\n",
      "35 Train Loss 745.80115 Test MSE 746.2764591830108 Test RE 0.45987419623020853 Lambda1 -1.6134764\n",
      "36 Train Loss 744.4525 Test MSE 745.0522059431986 Test RE 0.4594968336883646 Lambda1 -1.6023002\n",
      "37 Train Loss 741.93134 Test MSE 741.2085125296869 Test RE 0.45831003850355173 Lambda1 -1.6479169\n",
      "38 Train Loss 741.04 Test MSE 739.6505093224922 Test RE 0.4578281065498183 Lambda1 -1.6607233\n",
      "39 Train Loss 736.67505 Test MSE 737.6141198456315 Test RE 0.4571974310350183 Lambda1 -1.591167\n",
      "40 Train Loss 735.63947 Test MSE 738.5526905115568 Test RE 0.45748821700803205 Lambda1 -1.6008943\n",
      "41 Train Loss 733.64435 Test MSE 736.440596690274 Test RE 0.45683359218684194 Lambda1 -1.616703\n",
      "42 Train Loss 732.69824 Test MSE 735.7401372370183 Test RE 0.45661628373342655 Lambda1 -1.6006919\n",
      "43 Train Loss 730.7448 Test MSE 734.869991041984 Test RE 0.45634618805161137 Lambda1 -1.5754822\n",
      "44 Train Loss 728.3885 Test MSE 731.1240931818057 Test RE 0.4551816213998795 Lambda1 -1.5775548\n",
      "45 Train Loss 725.44556 Test MSE 726.6486423501843 Test RE 0.45378632471307845 Lambda1 -1.5802583\n",
      "46 Train Loss 724.14294 Test MSE 724.9970485432056 Test RE 0.45327032771603926 Lambda1 -1.5650823\n",
      "47 Train Loss 722.9982 Test MSE 722.0168909647848 Test RE 0.4523377666626354 Lambda1 -1.5973796\n",
      "48 Train Loss 720.8515 Test MSE 721.5512527012157 Test RE 0.4521918838275907 Lambda1 -1.6310476\n",
      "49 Train Loss 719.6888 Test MSE 720.5767635203672 Test RE 0.4518864273689541 Lambda1 -1.6544125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Train Loss 718.2571 Test MSE 720.416007846301 Test RE 0.45183601819472224 Lambda1 -1.6102357\n",
      "51 Train Loss 716.84375 Test MSE 718.0187880591037 Test RE 0.4510836384635514 Lambda1 -1.6112568\n",
      "52 Train Loss 713.8975 Test MSE 713.0545873011499 Test RE 0.44952159464834324 Lambda1 -1.6251949\n",
      "53 Train Loss 713.5314 Test MSE 712.5710453851943 Test RE 0.4493691523252811 Lambda1 -1.6170813\n",
      "54 Train Loss 711.25836 Test MSE 711.7463973700502 Test RE 0.449109052888024 Lambda1 -1.6253324\n",
      "55 Train Loss 709.1292 Test MSE 712.3161250852189 Test RE 0.4492887648558716 Lambda1 -1.6305659\n",
      "56 Train Loss 708.59045 Test MSE 712.6331013245793 Test RE 0.4493887190884516 Lambda1 -1.6210525\n",
      "57 Train Loss 707.7305 Test MSE 710.7167102254745 Test RE 0.44878407112815244 Lambda1 -1.5948297\n",
      "58 Train Loss 706.35626 Test MSE 709.8850078781234 Test RE 0.44852140386389355 Lambda1 -1.5810791\n",
      "59 Train Loss 704.66974 Test MSE 707.6221278165966 Test RE 0.44780596386003646 Lambda1 -1.5629799\n",
      "60 Train Loss 702.3421 Test MSE 705.8951050984331 Test RE 0.4472591723652518 Lambda1 -1.5851897\n",
      "61 Train Loss 701.23645 Test MSE 703.6637847520535 Test RE 0.4465517242043045 Lambda1 -1.5945897\n",
      "62 Train Loss 700.47284 Test MSE 701.0154921597181 Test RE 0.44571061624277186 Lambda1 -1.6091962\n",
      "63 Train Loss 699.9053 Test MSE 701.4836754575041 Test RE 0.44585942852909455 Lambda1 -1.6068058\n",
      "64 Train Loss 699.17163 Test MSE 700.9916432713825 Test RE 0.44570303453220766 Lambda1 -1.5981544\n",
      "65 Train Loss 698.09143 Test MSE 699.9502537672466 Test RE 0.44537184443913125 Lambda1 -1.6392883\n",
      "66 Train Loss 696.10376 Test MSE 699.1199096145544 Test RE 0.44510759591148324 Lambda1 -1.7246797\n",
      "67 Train Loss 694.1022 Test MSE 697.8351817362361 Test RE 0.44469843499321465 Lambda1 -1.7954612\n",
      "68 Train Loss 691.55133 Test MSE 694.5180022294452 Test RE 0.44364023257785357 Lambda1 -1.7705891\n",
      "69 Train Loss 689.7161 Test MSE 692.8495379503076 Test RE 0.4431070261210721 Lambda1 -1.7237921\n",
      "70 Train Loss 685.84436 Test MSE 689.2313506308468 Test RE 0.4419485185900952 Lambda1 -1.7304536\n",
      "71 Train Loss 682.21155 Test MSE 686.1283615835157 Test RE 0.44095254793556465 Lambda1 -1.7121677\n",
      "72 Train Loss 681.4671 Test MSE 685.1767399627486 Test RE 0.440646653586788 Lambda1 -1.7131184\n",
      "73 Train Loss 680.3177 Test MSE 683.545291955859 Test RE 0.4401217375289307 Lambda1 -1.7395688\n",
      "74 Train Loss 679.86426 Test MSE 682.5785802896802 Test RE 0.4398104038386718 Lambda1 -1.7515713\n",
      "Training time: 265.45\n",
      "Training time: 265.45\n",
      "inv_HT_tanh_tune4\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 854.7215 Test MSE 858.0764501203072 Test RE 0.4931194834410783 Lambda1 -0.03933148\n",
      "1 Train Loss 854.65704 Test MSE 857.8873085879404 Test RE 0.4930651325059037 Lambda1 -0.039254945\n",
      "2 Train Loss 853.92804 Test MSE 856.8864842751069 Test RE 0.4927774399533132 Lambda1 -0.50508493\n",
      "3 Train Loss 851.7691 Test MSE 855.2901677697827 Test RE 0.4923182219152058 Lambda1 -0.82705706\n",
      "4 Train Loss 847.3354 Test MSE 850.1188701511431 Test RE 0.49082762600652935 Lambda1 -0.98053813\n",
      "5 Train Loss 841.5787 Test MSE 843.0300376132894 Test RE 0.48877692538057904 Lambda1 -1.0044162\n",
      "6 Train Loss 832.4684 Test MSE 834.3165740268172 Test RE 0.4862443927454009 Lambda1 -0.96804494\n",
      "7 Train Loss 827.70703 Test MSE 830.9541499873268 Test RE 0.48526358372228107 Lambda1 -0.93195766\n",
      "8 Train Loss 814.3691 Test MSE 816.8938475960854 Test RE 0.48114057539501126 Lambda1 -0.87218356\n",
      "9 Train Loss 794.9292 Test MSE 792.8883084686315 Test RE 0.4740183755531505 Lambda1 -1.0472893\n",
      "10 Train Loss 772.5052 Test MSE 772.1018976892387 Test RE 0.46776366172872014 Lambda1 -1.0172328\n",
      "11 Train Loss 754.27374 Test MSE 750.6801778535622 Test RE 0.46122904118684815 Lambda1 -1.0742807\n",
      "12 Train Loss 742.7596 Test MSE 743.492574387282 Test RE 0.4590156451280496 Lambda1 -1.289796\n",
      "13 Train Loss 734.7833 Test MSE 734.2793366170453 Test RE 0.45616275623247304 Lambda1 -1.444362\n",
      "14 Train Loss 725.1246 Test MSE 729.7024179294599 Test RE 0.45473885433670724 Lambda1 -1.5113944\n",
      "15 Train Loss 714.6134 Test MSE 712.8713419713258 Test RE 0.44946383046928196 Lambda1 -1.6577549\n",
      "16 Train Loss 700.91284 Test MSE 701.6011770125507 Test RE 0.4458967686585568 Lambda1 -1.5113685\n",
      "17 Train Loss 687.84705 Test MSE 686.6400911628372 Test RE 0.44111695332730827 Lambda1 -1.4629534\n",
      "18 Train Loss 680.507 Test MSE 680.3239115778982 Test RE 0.4390834201499818 Lambda1 -1.3912278\n",
      "19 Train Loss 673.90674 Test MSE 676.6010677987188 Test RE 0.4378804039513976 Lambda1 -1.2712183\n",
      "20 Train Loss 667.78516 Test MSE 668.981153388636 Test RE 0.43540770703764275 Lambda1 -1.3515636\n",
      "21 Train Loss 663.5648 Test MSE 664.4658388633802 Test RE 0.43393581849482293 Lambda1 -1.3461301\n",
      "22 Train Loss 651.11304 Test MSE 655.4628441661922 Test RE 0.430986046422284 Lambda1 -1.3038399\n",
      "23 Train Loss 644.26166 Test MSE 650.9194977894895 Test RE 0.4294897572729343 Lambda1 -1.2570837\n",
      "24 Train Loss 641.4013 Test MSE 650.6991395716798 Test RE 0.4294170527303592 Lambda1 -1.2551031\n",
      "25 Train Loss 637.4682 Test MSE 648.5908370855276 Test RE 0.428720820390085 Lambda1 -1.2529608\n",
      "26 Train Loss 634.353 Test MSE 645.7285060213396 Test RE 0.4277737689225553 Lambda1 -1.2706716\n",
      "27 Train Loss 632.56335 Test MSE 642.8803609102663 Test RE 0.4268293253989416 Lambda1 -1.2974021\n",
      "28 Train Loss 629.4387 Test MSE 640.8382614921458 Test RE 0.4261508778605485 Lambda1 -1.3589997\n",
      "29 Train Loss 628.20135 Test MSE 638.7535740063295 Test RE 0.42545716531908556 Lambda1 -1.3926992\n",
      "30 Train Loss 627.1291 Test MSE 637.6370711498253 Test RE 0.4250851659129251 Lambda1 -1.4353125\n",
      "31 Train Loss 626.17084 Test MSE 636.7865145687778 Test RE 0.4248015565880638 Lambda1 -1.430087\n",
      "32 Train Loss 625.0462 Test MSE 634.900338189771 Test RE 0.4241719540018259 Lambda1 -1.4123892\n",
      "33 Train Loss 623.7329 Test MSE 634.5654656366423 Test RE 0.42406007637985893 Lambda1 -1.3816346\n",
      "34 Train Loss 621.60974 Test MSE 633.2549798028062 Test RE 0.4236219719082834 Lambda1 -1.4286411\n",
      "35 Train Loss 620.10095 Test MSE 633.4075800870513 Test RE 0.4236730105430882 Lambda1 -1.4939607\n",
      "36 Train Loss 619.54926 Test MSE 633.0865714598699 Test RE 0.42356563897733196 Lambda1 -1.4843936\n",
      "37 Train Loss 617.8554 Test MSE 631.1783660179276 Test RE 0.4229268162188925 Lambda1 -1.5436229\n",
      "38 Train Loss 615.09247 Test MSE 628.9717969415478 Test RE 0.4221869031183112 Lambda1 -1.5777974\n",
      "39 Train Loss 613.6349 Test MSE 627.2513085213142 Test RE 0.4216090830250273 Lambda1 -1.5453508\n",
      "40 Train Loss 612.6963 Test MSE 625.3770961266138 Test RE 0.4209787327128966 Lambda1 -1.5626243\n",
      "41 Train Loss 611.95087 Test MSE 623.72572500567 Test RE 0.420422546961811 Lambda1 -1.5837758\n",
      "42 Train Loss 608.83484 Test MSE 623.3845666256954 Test RE 0.4203075522713088 Lambda1 -1.4824592\n",
      "43 Train Loss 607.11426 Test MSE 621.9285586298121 Test RE 0.4198164197143732 Lambda1 -1.404279\n",
      "44 Train Loss 606.3404 Test MSE 620.8516460028565 Test RE 0.4194527915453224 Lambda1 -1.3492477\n",
      "45 Train Loss 606.16504 Test MSE 620.3821336731398 Test RE 0.41929415823426996 Lambda1 -1.2946296\n",
      "46 Train Loss 605.7934 Test MSE 620.2132177256498 Test RE 0.41923707221593687 Lambda1 -1.27527\n",
      "47 Train Loss 604.11206 Test MSE 618.1982105095188 Test RE 0.4185554896914649 Lambda1 -1.1833482\n",
      "48 Train Loss 602.72626 Test MSE 616.8717366552387 Test RE 0.41810619927763765 Lambda1 -1.1258723\n",
      "49 Train Loss 601.44666 Test MSE 616.2898674683602 Test RE 0.41790896175117903 Lambda1 -1.0456054\n",
      "50 Train Loss 600.65656 Test MSE 615.5308817907529 Test RE 0.4176515466527467 Lambda1 -0.996817\n",
      "51 Train Loss 596.77625 Test MSE 611.6899057714323 Test RE 0.4163464131181001 Lambda1 -1.0837644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 595.06775 Test MSE 608.1296461246421 Test RE 0.4151330004853719 Lambda1 -1.1446526\n",
      "53 Train Loss 594.50323 Test MSE 607.3313093068762 Test RE 0.4148604230829297 Lambda1 -1.1121081\n",
      "54 Train Loss 593.5663 Test MSE 606.282885514459 Test RE 0.4145021858203562 Lambda1 -1.0556307\n",
      "55 Train Loss 592.707 Test MSE 604.6622585414892 Test RE 0.4139478217206479 Lambda1 -1.043834\n",
      "56 Train Loss 591.1246 Test MSE 604.714108061151 Test RE 0.4139655692609708 Lambda1 -1.0588856\n",
      "57 Train Loss 590.754 Test MSE 604.5288561901536 Test RE 0.4139021560138074 Lambda1 -1.0673432\n",
      "58 Train Loss 590.13306 Test MSE 603.9226948840912 Test RE 0.41369459404824105 Lambda1 -1.0823127\n",
      "59 Train Loss 588.94293 Test MSE 603.2872828728799 Test RE 0.4134769041883996 Lambda1 -1.0933801\n",
      "60 Train Loss 587.8546 Test MSE 602.5343363264408 Test RE 0.41321879895732566 Lambda1 -1.0790482\n",
      "61 Train Loss 587.05054 Test MSE 602.2103045712698 Test RE 0.4131076733241788 Lambda1 -1.0584216\n",
      "62 Train Loss 584.95807 Test MSE 600.1411651593753 Test RE 0.4123973626071365 Lambda1 -1.0221691\n",
      "63 Train Loss 582.44336 Test MSE 597.6628567807843 Test RE 0.41154497551040103 Lambda1 -0.9880785\n",
      "64 Train Loss 580.29706 Test MSE 595.3287616370102 Test RE 0.41074057147724824 Lambda1 -0.89869165\n",
      "65 Train Loss 579.14087 Test MSE 593.1836711047359 Test RE 0.40999991280698544 Lambda1 -0.87316024\n",
      "66 Train Loss 577.9272 Test MSE 591.4560087764137 Test RE 0.40940240991160004 Lambda1 -0.8255862\n",
      "67 Train Loss 573.5503 Test MSE 586.0502729333484 Test RE 0.4075272059137268 Lambda1 -0.80579716\n",
      "68 Train Loss 568.46716 Test MSE 577.1526966968646 Test RE 0.40442177897618264 Lambda1 -0.81486917\n",
      "69 Train Loss 564.92035 Test MSE 572.6583903225011 Test RE 0.40284407895663427 Lambda1 -0.82535654\n",
      "70 Train Loss 557.9677 Test MSE 565.4955133056158 Test RE 0.40031674099065884 Lambda1 -0.8005111\n",
      "71 Train Loss 554.95465 Test MSE 560.2948052113773 Test RE 0.39847168710305814 Lambda1 -0.7398385\n",
      "72 Train Loss 550.6837 Test MSE 556.404289281362 Test RE 0.397085844373877 Lambda1 -0.72466826\n",
      "73 Train Loss 548.9051 Test MSE 555.1159842522316 Test RE 0.39662586934677563 Lambda1 -0.78452414\n",
      "74 Train Loss 545.8389 Test MSE 548.1849491144294 Test RE 0.3941420075775281 Lambda1 -0.82237166\n",
      "Training time: 278.85\n",
      "Training time: 278.85\n",
      "inv_HT_tanh_tune4\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 854.72076 Test MSE 858.0775140104085 Test RE 0.49311978913923293 Lambda1 0.04085296\n",
      "1 Train Loss 854.5247 Test MSE 857.670896143171 Test RE 0.49300293776309156 Lambda1 0.038213067\n",
      "2 Train Loss 852.478 Test MSE 855.246587140029 Test RE 0.492305678913849 Lambda1 -0.6541311\n",
      "3 Train Loss 847.95654 Test MSE 849.3594307632078 Test RE 0.49060834072154574 Lambda1 -0.6174361\n",
      "4 Train Loss 838.3955 Test MSE 836.3621863839552 Test RE 0.4868401250032345 Lambda1 -0.77131325\n",
      "5 Train Loss 828.4235 Test MSE 831.0298869949156 Test RE 0.485285697803013 Lambda1 -0.60222274\n",
      "6 Train Loss 816.99274 Test MSE 818.9783333238955 Test RE 0.4817540527032639 Lambda1 -0.4506069\n",
      "7 Train Loss 805.5849 Test MSE 806.7815593770268 Test RE 0.4781532941552519 Lambda1 -0.49041328\n",
      "8 Train Loss 795.229 Test MSE 797.4620699501961 Test RE 0.4753835926747059 Lambda1 -0.55616033\n",
      "9 Train Loss 781.43054 Test MSE 782.6597962149383 Test RE 0.47095095659912417 Lambda1 -0.6510861\n",
      "10 Train Loss 769.4613 Test MSE 772.0048784849682 Test RE 0.46773427215973673 Lambda1 -0.6420993\n",
      "11 Train Loss 759.048 Test MSE 760.9902889576653 Test RE 0.4643855825106135 Lambda1 -0.75586325\n",
      "12 Train Loss 752.6732 Test MSE 756.9511563369084 Test RE 0.46315152567858026 Lambda1 -0.79401314\n",
      "13 Train Loss 742.51636 Test MSE 742.6207911746607 Test RE 0.45874645649118484 Lambda1 -0.73328424\n",
      "14 Train Loss 731.63666 Test MSE 731.9136839702824 Test RE 0.45542734591775696 Lambda1 -0.6788964\n",
      "15 Train Loss 721.2506 Test MSE 726.4435196800457 Test RE 0.45372227145059085 Lambda1 -0.5654063\n",
      "16 Train Loss 713.54346 Test MSE 716.788658583503 Test RE 0.4506970683929554 Lambda1 -0.49745923\n",
      "17 Train Loss 704.1513 Test MSE 710.5278017283892 Test RE 0.4487244237626872 Lambda1 -0.45529118\n",
      "18 Train Loss 697.9403 Test MSE 703.9862729997259 Test RE 0.4466540395360707 Lambda1 -0.42350298\n",
      "19 Train Loss 685.80524 Test MSE 689.0824833639608 Test RE 0.44190078772223745 Lambda1 -0.39287218\n",
      "20 Train Loss 675.67676 Test MSE 676.8234657295434 Test RE 0.4379523634111603 Lambda1 -0.45663497\n",
      "21 Train Loss 666.07135 Test MSE 666.1716150337616 Test RE 0.43449244826928846 Lambda1 -0.52587724\n",
      "22 Train Loss 653.2789 Test MSE 657.8206028237993 Test RE 0.4317604983423932 Lambda1 -0.5237908\n",
      "23 Train Loss 648.6941 Test MSE 645.0151366078563 Test RE 0.4275374118095754 Lambda1 -0.5702263\n",
      "24 Train Loss 638.6748 Test MSE 645.165425232541 Test RE 0.4275872170494939 Lambda1 -0.58582395\n",
      "25 Train Loss 634.2565 Test MSE 644.3048082602957 Test RE 0.4273019323743594 Lambda1 -0.58925843\n",
      "26 Train Loss 625.4473 Test MSE 637.287503771053 Test RE 0.42496862918267564 Lambda1 -0.64974827\n",
      "27 Train Loss 618.60724 Test MSE 631.9139789193912 Test RE 0.42317319651743857 Lambda1 -0.67164797\n",
      "28 Train Loss 615.1786 Test MSE 629.2417830434775 Test RE 0.4222775052466319 Lambda1 -0.6887704\n",
      "29 Train Loss 613.83246 Test MSE 628.3598810290697 Test RE 0.4219814839323934 Lambda1 -0.69211113\n",
      "30 Train Loss 611.1371 Test MSE 626.9704595087119 Test RE 0.4215146856517165 Lambda1 -0.72717434\n",
      "31 Train Loss 609.73376 Test MSE 626.109607728477 Test RE 0.42122520924738904 Lambda1 -0.7760169\n",
      "32 Train Loss 608.26624 Test MSE 625.3416626892056 Test RE 0.42096680636080674 Lambda1 -0.85134417\n",
      "33 Train Loss 607.2193 Test MSE 624.7923189739383 Test RE 0.4207818624387374 Lambda1 -0.91845286\n",
      "34 Train Loss 605.97437 Test MSE 623.7851833368453 Test RE 0.4204425854389137 Lambda1 -0.9324644\n",
      "35 Train Loss 604.8416 Test MSE 622.0373128178486 Test RE 0.41985312392857577 Lambda1 -0.9374455\n",
      "36 Train Loss 604.1015 Test MSE 620.9016884668797 Test RE 0.4194696957674579 Lambda1 -0.9385679\n",
      "37 Train Loss 603.53265 Test MSE 620.8353320058964 Test RE 0.41944728056974273 Lambda1 -0.94448334\n",
      "38 Train Loss 601.629 Test MSE 618.4255810579215 Test RE 0.4186324540377716 Lambda1 -0.9066576\n",
      "39 Train Loss 599.75464 Test MSE 616.1520762491527 Test RE 0.4178622407133593 Lambda1 -0.8646175\n",
      "40 Train Loss 596.6251 Test MSE 611.6106916984635 Test RE 0.41631945373667695 Lambda1 -0.7499363\n",
      "41 Train Loss 595.16644 Test MSE 608.8365822331888 Test RE 0.415374221473868 Lambda1 -0.68992704\n",
      "42 Train Loss 593.4349 Test MSE 602.1483948769741 Test RE 0.4130864381950888 Lambda1 -0.6410846\n",
      "43 Train Loss 588.9616 Test MSE 592.2218643769272 Test RE 0.40966738455934176 Lambda1 -0.61541146\n",
      "44 Train Loss 577.4688 Test MSE 582.5795163093385 Test RE 0.40631866784117615 Lambda1 -0.65408534\n",
      "45 Train Loss 552.7998 Test MSE 542.3015951970639 Test RE 0.39202125222444023 Lambda1 -0.58004606\n",
      "46 Train Loss 517.5399 Test MSE 506.382405248106 Test RE 0.37881613983898216 Lambda1 -0.42378488\n",
      "47 Train Loss 490.22083 Test MSE 465.22638407488364 Test RE 0.36309589494598044 Lambda1 -0.399927\n",
      "48 Train Loss 440.11502 Test MSE 394.5100628423719 Test RE 0.3343630000774804 Lambda1 -0.43050918\n",
      "49 Train Loss 395.54752 Test MSE 349.43928901061446 Test RE 0.3146842718909331 Lambda1 -0.44343024\n",
      "50 Train Loss 357.92435 Test MSE 324.5910615813371 Test RE 0.3032895514297761 Lambda1 -0.41509786\n",
      "51 Train Loss 344.32364 Test MSE 314.28564457297836 Test RE 0.29843615973563936 Lambda1 -0.40997007\n",
      "52 Train Loss 333.03372 Test MSE 303.55291928900857 Test RE 0.2932961603907574 Lambda1 -0.43303427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 Train Loss 326.28333 Test MSE 305.77872304867253 Test RE 0.294369494431251 Lambda1 -0.4085879\n",
      "54 Train Loss 317.63495 Test MSE 301.2527620240548 Test RE 0.29218282873602097 Lambda1 -0.38396418\n",
      "55 Train Loss 314.44678 Test MSE 301.0433018369174 Test RE 0.2920812341291584 Lambda1 -0.37609372\n",
      "56 Train Loss 308.08368 Test MSE 297.25760640112264 Test RE 0.2902389263467792 Lambda1 -0.37724954\n",
      "57 Train Loss 305.82867 Test MSE 293.4200599315331 Test RE 0.2883593722216702 Lambda1 -0.39015153\n",
      "58 Train Loss 300.52515 Test MSE 291.08109676860164 Test RE 0.2872077614016676 Lambda1 -0.43353805\n",
      "59 Train Loss 297.71155 Test MSE 290.52620105946755 Test RE 0.28693387487712146 Lambda1 -0.44393244\n",
      "60 Train Loss 295.77893 Test MSE 288.6886935765861 Test RE 0.28602504211396773 Lambda1 -0.45894608\n",
      "61 Train Loss 293.55017 Test MSE 286.72316941279496 Test RE 0.28504968470360964 Lambda1 -0.48338947\n",
      "62 Train Loss 292.04044 Test MSE 285.9122681801487 Test RE 0.2846463151339234 Lambda1 -0.4616664\n",
      "63 Train Loss 290.11172 Test MSE 286.245713041894 Test RE 0.284812250990108 Lambda1 -0.44914997\n",
      "64 Train Loss 288.12756 Test MSE 284.36477827947846 Test RE 0.283874950984982 Lambda1 -0.44561303\n",
      "65 Train Loss 284.73456 Test MSE 283.85395330257273 Test RE 0.28361986384323706 Lambda1 -0.4530252\n",
      "66 Train Loss 282.8381 Test MSE 283.12755168987803 Test RE 0.28325673009250396 Lambda1 -0.46234348\n",
      "67 Train Loss 281.7494 Test MSE 282.37429031286155 Test RE 0.2828796766094051 Lambda1 -0.4657323\n",
      "68 Train Loss 281.0755 Test MSE 281.66734051500873 Test RE 0.28252534715711825 Lambda1 -0.47776052\n",
      "69 Train Loss 279.56128 Test MSE 280.5923998327309 Test RE 0.2819857242504828 Lambda1 -0.47332212\n",
      "70 Train Loss 279.3536 Test MSE 280.45099541298913 Test RE 0.2819146620039147 Lambda1 -0.48113444\n",
      "71 Train Loss 278.28894 Test MSE 279.55089249645874 Test RE 0.28146189816206174 Lambda1 -0.47594473\n",
      "72 Train Loss 277.85684 Test MSE 279.2433962064624 Test RE 0.2813070564052171 Lambda1 -0.47914562\n",
      "73 Train Loss 277.1769 Test MSE 278.4271343804947 Test RE 0.2808956084315616 Lambda1 -0.4760023\n",
      "74 Train Loss 276.99585 Test MSE 278.05066122587914 Test RE 0.28070563875170684 Lambda1 -0.47383177\n",
      "Training time: 267.72\n",
      "Training time: 267.72\n"
     ]
    }
   ],
   "source": [
    "nan_tune = []\n",
    "for tune_reps in range(5):\n",
    "    label = \"inv_HT_tanh_tune\" + str(tune_reps)\n",
    "    max_reps = 10 #10\n",
    "    max_iter = 75 #75\n",
    "\n",
    "    train_loss_full = []\n",
    "    test_mse_full = []\n",
    "    test_re_full = []\n",
    "\n",
    "   \n",
    "    lambda1_full = []\n",
    "    elapsed_time= np.zeros((max_reps,1))\n",
    "    \n",
    "    time_threshold = np.empty((max_reps,1))\n",
    "    time_threshold[:] = np.nan\n",
    "    epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "    \n",
    "\n",
    "    for reps in range(max_reps):\n",
    "        print(label)\n",
    "        'Generate Training data'\n",
    "        print(reps)\n",
    "        torch.manual_seed(reps*36)\n",
    "        \n",
    "        train_loss = []\n",
    "        test_mse_loss = []\n",
    "        test_re_loss = []   \n",
    "        \n",
    "        lambda1_val = []\n",
    "\n",
    "        N_f = 50000 #Total number of collocation points \n",
    "        N_train = 5000\n",
    "\n",
    "        layers = np.array([2,50,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "        \n",
    "        PINN = Sequentialmodel(layers)\n",
    "\n",
    "        PINN.to(device)\n",
    "\n",
    "        'Neural Network Summary'\n",
    "        print(PINN)\n",
    "\n",
    "        params = list(PINN.parameters())\n",
    "\n",
    "        optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lr_tune[tune_reps], \n",
    "                                  max_iter = 10, \n",
    "                                  max_eval = 15, \n",
    "                                  tolerance_grad = -1, \n",
    "                                  tolerance_change = -1, \n",
    "                                  history_size = 100, \n",
    "                                  line_search_fn = 'strong_wolfe')\n",
    "        \n",
    "        \n",
    "        nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "        torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "        train_loss_full.append(train_loss)\n",
    "        test_mse_full.append(test_mse_loss)\n",
    "        test_re_full.append(test_re_loss)\n",
    "        #elapsed_time[reps] = time.time() - start_time\n",
    "\n",
    "\n",
    "        lambda1_full.append(lambda1_val)\n",
    "        \n",
    "        if(nan_flag == 1):\n",
    "            nan_tune.append(tune_reps)\n",
    "            break\n",
    "\n",
    "        print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "    mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time,\"lambda1\": lambda1_full, \"label\": label}\n",
    "    savemat(label+'.mat', mdic) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45903665368606655\n",
      "0.39057095824037635\n",
      "0.2913429174527885\n",
      "0.40148717401800055\n",
      "0.4177939778731867\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"inv_HT_tanh_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
