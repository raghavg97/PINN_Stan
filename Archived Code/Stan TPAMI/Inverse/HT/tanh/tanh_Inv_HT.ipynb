{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/atanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_2D_4(xt): #True function for 2D_4 Heat Transfer in a rod x \\in [0,1] t \\in [0,0.1]\n",
    "    term1 = 4*u0/np.pi\n",
    "    \n",
    "    resol_n = 10000\n",
    "    \n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "\n",
    "    u = np.zeros((np.shape(xt)[0],1))\n",
    "    \n",
    "    for i in range(resol_n):\n",
    "        j = 2*i-1\n",
    "        term2 = np.sin(j*np.pi*x)/j\n",
    "        term3 = np.exp(-1*np.square(j*np.pi)*t)\n",
    "        \n",
    "        u = u + term2*term3\n",
    "        \n",
    "    u = term1*u\n",
    "    \n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = 50.0\n",
    "loss_thresh = 0.1\n",
    "label = \"inv_HT_tanh\" \n",
    "\n",
    "x_ll = np.array(0.0)\n",
    "x_ul = np.array(1.0)\n",
    "\n",
    "x = np.linspace(x_ll,x_ul,100).reshape(-1,1)\n",
    "t = np.linspace(0,0.1,100).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "u_true = true_2D_4(xt)\n",
    "u_true_norm = np.linalg.norm(u_true,2)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_f,N_train,seed):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    #X_Train\n",
    "    np.random.seed(seed)\n",
    "    x_train = np.random.uniform(x_ll,x_ul,(N_train,1))\n",
    "    t_train = np.random.uniform(0,0.1,(N_train,1))\n",
    "    \n",
    "    xt_train = np.hstack((x_train,t_train))\n",
    "    u_train = true_2D_4(xt_train)\n",
    "    \n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_train, u_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "        \n",
    "\n",
    "        self.lambda1 = Parameter(torch.tensor(0.0))\n",
    "        self.lambda1.requiresGrad = True\n",
    "        \n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = (xt - lbxt)/(ubxt - lbxt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) \n",
    "            \n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    \n",
    "    def loss_PDE(self, xt_coll,f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_t = autograd.grad(u,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_tt = autograd.grad(u_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_tt[:,[0]]\n",
    "                \n",
    "        du_dt = u_x_t[:,[1]]\n",
    "        \n",
    "        f = du_dt - self.lambda1*d2u_dx2\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_coll,f_hat, xt_train, u_train):\n",
    "\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_train = self.loss_function(self.forward(xt_train),u_train)\n",
    "        \n",
    "        loss_val = loss_f + loss_train\n",
    "        \n",
    "        #print(self.iter,\"train_loss\",loss_train.cpu().detach().numpy(),\"F Loss\",(loss_f).cpu().detach().numpy())\n",
    "        return loss_val\n",
    "     \n",
    "    'callable for optimizer'                                    \n",
    "    \n",
    "    def test(self):\n",
    "        u_pred = self.forward(xt_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "               \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xt_coll,f_hat, xt_train, u_train,seed):    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_coll,f_hat, xt_train, u_train)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    lambda1_val.append(PINN.lambda1.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "    \n",
    "    xt_coll, xt_train, u_train = trainingdata(N_f,N_train,123)\n",
    "    \n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_train = torch.from_numpy(xt_train).float().to(device)\n",
    "    u_train = torch.from_numpy(u_train).float().to(device)\n",
    "    \n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        train_step(xt_coll,f_hat, xt_train, u_train,i)\n",
    "\n",
    "        loss_np = PINN.loss(xt_coll,f_hat, xt_train, u_train).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1],\"Lambda1\",lambda1_val[-1])\n",
    "\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_HT_tanh\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 854.7452 Test MSE 858.0515976082977 Test RE 0.4931123422669901 Lambda1 -0.064031824\n",
      "1 Train Loss 854.7232 Test MSE 858.068268896447 Test RE 0.493117132642091 Lambda1 -0.064144745\n",
      "2 Train Loss 854.7226 Test MSE 858.0704154080778 Test RE 0.49311774942343417 Lambda1 -0.064153135\n",
      "3 Train Loss 854.722 Test MSE 858.0737967893878 Test RE 0.4931187210322141 Lambda1 -0.06416583\n",
      "4 Train Loss 854.722 Test MSE 858.0740620608112 Test RE 0.4931187972554336 Lambda1 -0.064166814\n",
      "5 Train Loss 854.722 Test MSE 858.0743162903171 Test RE 0.4931188703058524 Lambda1 -0.06416777\n",
      "6 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "7 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "8 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "9 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "10 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "11 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "12 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "13 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "14 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "15 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "16 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "17 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "18 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "19 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "20 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "21 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "22 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "23 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "24 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "25 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "26 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "27 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "28 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "29 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "30 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "31 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "32 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "33 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "34 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "35 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "36 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "37 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "38 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "39 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "40 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "41 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "42 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "43 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "44 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "45 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "46 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "47 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "48 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "49 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "50 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "51 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "52 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "53 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "54 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "55 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "56 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "57 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "58 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "59 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "60 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "61 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "62 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "63 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "64 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "65 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "66 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "67 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "68 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "69 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "70 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "71 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "72 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "73 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "74 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "75 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "77 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "78 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "79 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "80 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "81 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "82 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "83 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "84 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "85 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "86 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "87 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "88 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "89 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "90 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "91 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "92 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "93 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "94 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "95 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "96 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "97 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "98 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "99 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "100 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "101 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "102 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "103 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "104 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "105 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "106 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "107 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "108 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "109 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "110 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "111 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "112 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "113 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "114 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "115 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "116 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "117 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "118 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "119 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "120 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "121 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "122 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "123 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "124 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "125 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "126 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "127 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "128 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "129 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "130 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "131 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "132 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "133 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "134 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "135 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "136 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "137 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "138 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "139 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "140 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "141 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "142 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "143 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "144 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "145 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "146 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "147 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "148 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "149 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "150 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "151 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "152 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "153 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "154 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "155 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "156 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "157 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "158 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "160 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "161 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "162 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "163 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "164 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "165 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "166 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "167 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "168 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "169 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "170 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "171 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "172 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "173 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "174 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "175 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "176 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "177 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "178 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "179 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "180 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "181 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "182 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "183 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "184 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "185 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "186 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "187 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "188 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "189 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "190 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "191 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "192 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "193 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "194 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "195 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "196 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "197 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "198 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "199 Train Loss 854.72186 Test MSE 858.0745830076004 Test RE 0.49311894694450276 Lambda1 -0.06416873\n",
      "Training time: 141.72\n",
      "Training time: 141.72\n",
      "inv_HT_tanh\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 854.729 Test MSE 858.0554595436707 Test RE 0.4931134519705673 Lambda1 -0.07828253\n",
      "1 Train Loss 854.72076 Test MSE 858.071298000912 Test RE 0.4931180030285418 Lambda1 -0.07836967\n",
      "2 Train Loss 854.72076 Test MSE 858.0716141551953 Test RE 0.493118093872598 Lambda1 -0.078370936\n",
      "3 Train Loss 854.7207 Test MSE 858.0721939697886 Test RE 0.4931182604770013 Lambda1 -0.078373305\n",
      "4 Train Loss 854.7207 Test MSE 858.0724768252462 Test RE 0.4931183417529014 Lambda1 -0.07837442\n",
      "5 Train Loss 854.7206 Test MSE 858.0730162591452 Test RE 0.4931184967542069 Lambda1 -0.078376554\n",
      "6 Train Loss 854.7206 Test MSE 858.0732587630295 Test RE 0.49311856643542284 Lambda1 -0.07837754\n",
      "7 Train Loss 854.7206 Test MSE 858.0734960746935 Test RE 0.4931186346246935 Lambda1 -0.07837848\n",
      "8 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "9 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "10 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "11 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "12 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "13 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "14 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "15 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "16 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "17 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "18 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "19 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "20 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "21 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "22 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "23 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "24 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "25 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "26 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "27 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "28 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "29 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "30 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "31 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "32 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "33 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "35 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "36 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "37 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "38 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "39 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "40 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "41 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "42 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "43 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "44 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "45 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "46 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "47 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "48 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "49 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "50 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "51 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "52 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "53 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "54 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "55 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "56 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "57 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "58 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "59 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "60 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "61 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "62 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "63 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "64 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "65 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "66 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "67 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "68 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "69 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "70 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "71 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "72 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "73 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "74 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "75 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "76 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "77 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "78 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "79 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "80 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "81 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "82 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "83 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "84 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "85 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "86 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "87 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "88 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "89 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "90 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "91 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "92 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "93 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "94 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "95 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "96 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "97 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "98 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "99 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "100 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "101 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "102 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "103 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "104 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "105 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "106 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "107 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "108 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "109 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "110 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "111 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "112 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "113 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "114 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "115 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "116 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "117 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "119 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "120 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "121 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "122 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "123 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "124 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "125 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "126 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "127 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "128 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "129 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "130 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "131 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "132 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "133 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "134 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "135 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "136 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "137 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "138 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "139 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "140 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "141 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "142 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "143 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "144 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "145 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "146 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "147 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "148 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "149 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "150 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "151 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "152 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "153 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "154 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "155 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "156 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "157 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "158 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "159 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "160 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "161 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "162 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "163 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "164 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "165 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "166 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "167 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "168 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "169 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "170 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "171 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "172 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "173 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "174 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "175 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "176 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "177 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "178 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "179 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "180 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "181 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "182 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "183 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "184 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "185 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "186 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "187 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "188 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "189 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "190 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "191 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "192 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "193 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "194 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "195 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "196 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "197 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "198 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "199 Train Loss 854.72046 Test MSE 858.0737249352622 Test RE 0.4931187003856127 Lambda1 -0.07837939\n",
      "Training time: 141.08\n",
      "Training time: 141.08\n",
      "inv_HT_tanh\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 854.7341 Test MSE 858.0505923575197 Test RE 0.4931120534138999 Lambda1 -0.20431243\n",
      "1 Train Loss 854.71796 Test MSE 858.0719378445281 Test RE 0.4931181868817647 Lambda1 -0.20465478\n",
      "2 Train Loss 854.5918 Test MSE 857.9657892169399 Test RE 0.4930876851048283 Lambda1 -0.20750839\n",
      "3 Train Loss 845.0267 Test MSE 845.55750408621 Test RE 0.4895090717403268 Lambda1 -0.4348272\n",
      "4 Train Loss 825.30554 Test MSE 825.0739924462073 Test RE 0.48354357771925793 Lambda1 -0.48224747\n",
      "5 Train Loss 805.5671 Test MSE 805.2207586865452 Test RE 0.4776905522384507 Lambda1 -0.47133225\n",
      "6 Train Loss 788.0081 Test MSE 791.039167134788 Test RE 0.47346530987627317 Lambda1 -0.5810787\n",
      "7 Train Loss 774.0561 Test MSE 770.6159268385935 Test RE 0.46731332096011635 Lambda1 -0.86167693\n",
      "8 Train Loss 754.43506 Test MSE 748.2079840309057 Test RE 0.4604689385789477 Lambda1 -0.96542853\n",
      "9 Train Loss 721.62366 Test MSE 721.9936724834458 Test RE 0.45233049350839066 Lambda1 -1.0919011\n",
      "10 Train Loss 704.18384 Test MSE 704.090017149428 Test RE 0.4466869492946025 Lambda1 -1.2355982\n",
      "11 Train Loss 676.67706 Test MSE 675.6869466936287 Test RE 0.4375845050626472 Lambda1 -1.3787874\n",
      "12 Train Loss 663.29645 Test MSE 661.0178613549024 Test RE 0.4328084866668435 Lambda1 -1.4330467\n",
      "13 Train Loss 644.004 Test MSE 651.6633690707671 Test RE 0.4297350978045136 Lambda1 -1.5283515\n",
      "14 Train Loss 633.63055 Test MSE 641.7529967053272 Test RE 0.42645491417575326 Lambda1 -1.60923\n",
      "15 Train Loss 628.9111 Test MSE 635.4790231284588 Test RE 0.4243652174164565 Lambda1 -1.657255\n",
      "16 Train Loss 624.78534 Test MSE 633.956807719428 Test RE 0.42385665414923723 Lambda1 -1.67052\n",
      "17 Train Loss 621.7881 Test MSE 632.9114907357429 Test RE 0.4235070661770472 Lambda1 -1.6877139\n",
      "18 Train Loss 619.3308 Test MSE 631.5698653081523 Test RE 0.4230579597196569 Lambda1 -1.6881661\n",
      "19 Train Loss 616.5385 Test MSE 628.258444948209 Test RE 0.4219474223406009 Lambda1 -1.7276697\n",
      "20 Train Loss 614.6719 Test MSE 627.0177954876985 Test RE 0.42153059743305094 Lambda1 -1.7416936\n",
      "21 Train Loss 613.4009 Test MSE 627.4452098136177 Test RE 0.4216742436935299 Lambda1 -1.7138515\n",
      "22 Train Loss 611.5412 Test MSE 627.6664587190442 Test RE 0.4217485822496838 Lambda1 -1.7085799\n",
      "23 Train Loss 610.72394 Test MSE 627.2075191561364 Test RE 0.42159436618340884 Lambda1 -1.7056049\n",
      "24 Train Loss 609.6854 Test MSE 626.7171828053432 Test RE 0.42142953759371554 Lambda1 -1.7018946\n",
      "25 Train Loss 608.7472 Test MSE 626.0226832740851 Test RE 0.42119596832698347 Lambda1 -1.7126517\n",
      "26 Train Loss 608.2617 Test MSE 625.4346412103831 Test RE 0.4209981007864424 Lambda1 -1.7116084\n",
      "27 Train Loss 607.7848 Test MSE 625.0439273997109 Test RE 0.42086657987367515 Lambda1 -1.6961278\n",
      "28 Train Loss 606.5672 Test MSE 624.4200963212897 Test RE 0.42065650248259706 Lambda1 -1.655849\n",
      "29 Train Loss 604.9714 Test MSE 624.2058435261134 Test RE 0.42058432786452565 Lambda1 -1.583991\n",
      "30 Train Loss 604.4125 Test MSE 624.0252404474223 Test RE 0.42052347909133264 Lambda1 -1.5401956\n",
      "31 Train Loss 604.18713 Test MSE 623.597182819387 Test RE 0.4203792227763409 Lambda1 -1.550628\n",
      "32 Train Loss 604.0219 Test MSE 623.4062227154349 Test RE 0.4203148528522883 Lambda1 -1.5663944\n",
      "33 Train Loss 603.7663 Test MSE 623.1319678714849 Test RE 0.4202223882112478 Lambda1 -1.5778062\n",
      "34 Train Loss 603.6338 Test MSE 622.8459536033636 Test RE 0.4201259372187027 Lambda1 -1.5789855\n",
      "35 Train Loss 603.498 Test MSE 622.6064464082784 Test RE 0.4200451525082832 Lambda1 -1.5729803\n",
      "36 Train Loss 603.35803 Test MSE 622.5307409293565 Test RE 0.4200196141554851 Lambda1 -1.5831771\n",
      "37 Train Loss 603.15466 Test MSE 622.3150217108755 Test RE 0.41994683529692095 Lambda1 -1.5902172\n",
      "38 Train Loss 602.78754 Test MSE 621.8572197019582 Test RE 0.419792341295919 Lambda1 -1.5908536\n",
      "39 Train Loss 602.44727 Test MSE 621.1486171932323 Test RE 0.41955309771618693 Lambda1 -1.585693\n",
      "40 Train Loss 602.09204 Test MSE 620.6205630272788 Test RE 0.4193747234426178 Lambda1 -1.5661881\n",
      "41 Train Loss 601.69147 Test MSE 620.2547433265689 Test RE 0.419251106728152 Lambda1 -1.5296161\n",
      "42 Train Loss 601.3805 Test MSE 619.976978832538 Test RE 0.419157221019656 Lambda1 -1.5020576\n",
      "43 Train Loss 601.08636 Test MSE 619.4738399580924 Test RE 0.4189871041407273 Lambda1 -1.5103034\n",
      "44 Train Loss 600.8796 Test MSE 619.2796328314294 Test RE 0.41892142206117927 Lambda1 -1.5051341\n",
      "45 Train Loss 600.6226 Test MSE 619.0607408945077 Test RE 0.4188473790755445 Lambda1 -1.478313\n",
      "46 Train Loss 600.44037 Test MSE 619.1834773468545 Test RE 0.4188888978556731 Lambda1 -1.4654632\n",
      "47 Train Loss 600.3218 Test MSE 619.0397885952569 Test RE 0.4188402910070372 Lambda1 -1.4670764\n",
      "48 Train Loss 600.263 Test MSE 619.1940041281184 Test RE 0.4188924586201487 Lambda1 -1.4653527\n",
      "49 Train Loss 599.9724 Test MSE 618.7534310762697 Test RE 0.41874340552217615 Lambda1 -1.476225\n",
      "50 Train Loss 599.5295 Test MSE 618.2582761516366 Test RE 0.41857582313239616 Lambda1 -1.4705809\n",
      "51 Train Loss 598.9265 Test MSE 617.3262068245791 Test RE 0.41826018737503556 Lambda1 -1.4621658\n",
      "52 Train Loss 598.24756 Test MSE 615.9928710988526 Test RE 0.41780825232210445 Lambda1 -1.46852\n",
      "53 Train Loss 597.7095 Test MSE 615.1575012806054 Test RE 0.41752485390015126 Lambda1 -1.4548187\n",
      "54 Train Loss 597.1187 Test MSE 613.6850591943944 Test RE 0.4170248604091271 Lambda1 -1.4442123\n",
      "55 Train Loss 596.03217 Test MSE 612.1351550219993 Test RE 0.41649791488785226 Lambda1 -1.4455888\n",
      "56 Train Loss 594.4726 Test MSE 610.4979289991545 Test RE 0.4159405561201475 Lambda1 -1.4610767\n",
      "57 Train Loss 593.9344 Test MSE 609.6083073499226 Test RE 0.4156373899612743 Lambda1 -1.4578925\n",
      "58 Train Loss 593.2976 Test MSE 608.791692342193 Test RE 0.4153589082947833 Lambda1 -1.4386162\n",
      "59 Train Loss 592.4264 Test MSE 607.7271380819813 Test RE 0.41499559390542773 Lambda1 -1.4533464\n",
      "60 Train Loss 590.0109 Test MSE 603.6226296036817 Test RE 0.41359180704525206 Lambda1 -1.475593\n",
      "61 Train Loss 588.40686 Test MSE 599.7641881297837 Test RE 0.4122678191237962 Lambda1 -1.4716858\n",
      "62 Train Loss 587.0576 Test MSE 597.6738433490299 Test RE 0.41154875811637154 Lambda1 -1.4821317\n",
      "63 Train Loss 585.9712 Test MSE 596.6838538242595 Test RE 0.4112077712883132 Lambda1 -1.4768687\n",
      "64 Train Loss 584.24426 Test MSE 593.9966676194781 Test RE 0.41028078227670617 Lambda1 -1.4345201\n",
      "65 Train Loss 581.8606 Test MSE 591.9333631772481 Test RE 0.40956758756048417 Lambda1 -1.4638175\n",
      "66 Train Loss 579.56854 Test MSE 587.4890340620982 Test RE 0.4080271415901465 Lambda1 -1.4676037\n",
      "67 Train Loss 578.07556 Test MSE 585.042155571514 Test RE 0.40717654309399887 Lambda1 -1.4648517\n",
      "68 Train Loss 576.05035 Test MSE 583.3865259291526 Test RE 0.40659999389826257 Lambda1 -1.4406911\n",
      "69 Train Loss 574.38025 Test MSE 581.827621342811 Test RE 0.40605637952595974 Lambda1 -1.4162971\n",
      "70 Train Loss 570.7612 Test MSE 575.2098850990955 Test RE 0.4037405228189086 Lambda1 -1.3175418\n",
      "71 Train Loss 566.6617 Test MSE 572.7888940236039 Test RE 0.40288997861452175 Lambda1 -1.2805619\n",
      "72 Train Loss 560.9835 Test MSE 568.2304417697798 Test RE 0.4012836072730365 Lambda1 -1.2836076\n",
      "73 Train Loss 556.19507 Test MSE 564.6413314597819 Test RE 0.4000142872056404 Lambda1 -1.2868685\n",
      "74 Train Loss 554.79803 Test MSE 561.6569169819822 Test RE 0.3989557479027255 Lambda1 -1.2692068\n",
      "75 Train Loss 553.94965 Test MSE 561.564680510746 Test RE 0.39892298788486613 Lambda1 -1.240426\n",
      "76 Train Loss 551.6827 Test MSE 557.1964385146015 Test RE 0.39736840812894036 Lambda1 -1.2006594\n",
      "77 Train Loss 550.756 Test MSE 555.6297666527796 Test RE 0.3968093735759212 Lambda1 -1.1837385\n",
      "78 Train Loss 547.88354 Test MSE 555.1271426721837 Test RE 0.39662985562703 Lambda1 -1.1547142\n",
      "79 Train Loss 547.0894 Test MSE 555.0306080700848 Test RE 0.3965953678790412 Lambda1 -1.1253728\n",
      "80 Train Loss 545.67596 Test MSE 552.9761066282676 Test RE 0.39586066859998764 Lambda1 -1.1217277\n",
      "81 Train Loss 542.56335 Test MSE 549.1946979179116 Test RE 0.39450484252893997 Lambda1 -1.1348368\n",
      "82 Train Loss 539.5 Test MSE 547.6615537653109 Test RE 0.39395380343370734 Lambda1 -1.1346165\n",
      "83 Train Loss 537.62177 Test MSE 545.5684474310685 Test RE 0.39320025721814306 Lambda1 -1.1429898\n",
      "84 Train Loss 531.9812 Test MSE 539.2211218325658 Test RE 0.39090625381421945 Lambda1 -1.1320195\n",
      "85 Train Loss 528.5452 Test MSE 535.8278039527407 Test RE 0.38967432633018506 Lambda1 -1.1481818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 527.06433 Test MSE 535.3480263476123 Test RE 0.38949983101421415 Lambda1 -1.146766\n",
      "87 Train Loss 525.26855 Test MSE 533.7553124864435 Test RE 0.38891999897370855 Lambda1 -1.1599909\n",
      "88 Train Loss 523.93243 Test MSE 531.7117138335549 Test RE 0.3881747524252638 Lambda1 -1.1703378\n",
      "89 Train Loss 522.3976 Test MSE 530.8170137870209 Test RE 0.38784802820456 Lambda1 -1.1358569\n",
      "90 Train Loss 521.42065 Test MSE 531.0356634800678 Test RE 0.38792789953412504 Lambda1 -1.1191646\n",
      "91 Train Loss 519.9181 Test MSE 530.408396979772 Test RE 0.38769871899831365 Lambda1 -1.099393\n",
      "92 Train Loss 517.88043 Test MSE 527.802215715338 Test RE 0.3867450601029118 Lambda1 -1.128538\n",
      "93 Train Loss 515.09344 Test MSE 526.6477704379471 Test RE 0.3863218708825872 Lambda1 -1.1287899\n",
      "94 Train Loss 512.31244 Test MSE 522.9936919542098 Test RE 0.38497931549114534 Lambda1 -1.187776\n",
      "95 Train Loss 508.81915 Test MSE 519.3083668184605 Test RE 0.383620520732572 Lambda1 -1.2455368\n",
      "96 Train Loss 504.77725 Test MSE 515.3066953564997 Test RE 0.3821396163557649 Lambda1 -1.2948897\n",
      "97 Train Loss 501.28403 Test MSE 509.8729764300691 Test RE 0.3801195163284874 Lambda1 -1.3535848\n",
      "98 Train Loss 498.7749 Test MSE 507.33380266696736 Test RE 0.37917183503059015 Lambda1 -1.3516552\n",
      "99 Train Loss 496.858 Test MSE 505.2779404358836 Test RE 0.37840279858003095 Lambda1 -1.3410462\n",
      "100 Train Loss 495.76266 Test MSE 503.830981992732 Test RE 0.37786059632482316 Lambda1 -1.3381543\n",
      "101 Train Loss 495.20532 Test MSE 502.5643392505625 Test RE 0.3773853222848879 Lambda1 -1.3325018\n",
      "102 Train Loss 493.94754 Test MSE 500.3633684805028 Test RE 0.37655803967662493 Lambda1 -1.3270193\n",
      "103 Train Loss 492.27127 Test MSE 500.0081518037435 Test RE 0.37642435338791613 Lambda1 -1.296016\n",
      "104 Train Loss 490.58966 Test MSE 497.88434722328697 Test RE 0.37562406393605624 Lambda1 -1.2544632\n",
      "105 Train Loss 489.5921 Test MSE 497.4876748129785 Test RE 0.37547440127535864 Lambda1 -1.2039523\n",
      "106 Train Loss 486.48325 Test MSE 492.3196030586889 Test RE 0.3735190316426116 Lambda1 -1.1130738\n",
      "107 Train Loss 483.86288 Test MSE 487.787790744785 Test RE 0.371795931906781 Lambda1 -1.0755453\n",
      "108 Train Loss 479.47012 Test MSE 480.04853750449007 Test RE 0.36883467734978287 Lambda1 -0.99271625\n",
      "109 Train Loss 474.2346 Test MSE 473.98125553765317 Test RE 0.3664964346973308 Lambda1 -0.9840886\n",
      "110 Train Loss 470.76526 Test MSE 473.4432454050254 Test RE 0.36628837290300537 Lambda1 -0.93406224\n",
      "111 Train Loss 468.95773 Test MSE 471.2587343480114 Test RE 0.36544235160237 Lambda1 -0.91130745\n",
      "112 Train Loss 464.58633 Test MSE 465.6575556473321 Test RE 0.3632641145224927 Lambda1 -0.8122188\n",
      "113 Train Loss 458.8232 Test MSE 461.1177121508382 Test RE 0.36148898870997476 Lambda1 -0.75897837\n",
      "114 Train Loss 454.719 Test MSE 456.9596719343582 Test RE 0.3598554691944892 Lambda1 -0.75493693\n",
      "115 Train Loss 450.17435 Test MSE 455.1708156528816 Test RE 0.3591504168746854 Lambda1 -0.7404975\n",
      "116 Train Loss 446.8142 Test MSE 452.4088534989463 Test RE 0.3580591021385335 Lambda1 -0.70576984\n",
      "117 Train Loss 443.3157 Test MSE 450.1681955140044 Test RE 0.3571713168683938 Lambda1 -0.71459585\n",
      "118 Train Loss 440.02014 Test MSE 445.16574868254986 Test RE 0.35518125845635 Lambda1 -0.6781572\n",
      "119 Train Loss 437.15054 Test MSE 442.2971646677509 Test RE 0.3540350405008501 Lambda1 -0.6517757\n",
      "120 Train Loss 435.26843 Test MSE 440.8522893143952 Test RE 0.35345629503887344 Lambda1 -0.6697003\n",
      "121 Train Loss 432.344 Test MSE 437.84360327079446 Test RE 0.35224811297924347 Lambda1 -0.6794974\n",
      "122 Train Loss 429.17725 Test MSE 433.736692888292 Test RE 0.3505922023170652 Lambda1 -0.646929\n",
      "123 Train Loss 423.10748 Test MSE 427.4424011039977 Test RE 0.3480390471756428 Lambda1 -0.5702718\n",
      "124 Train Loss 419.09872 Test MSE 423.886805880618 Test RE 0.34658847725616926 Lambda1 -0.5544091\n",
      "125 Train Loss 417.45078 Test MSE 421.55014810743563 Test RE 0.3456318801024235 Lambda1 -0.54229903\n",
      "126 Train Loss 412.5492 Test MSE 416.8199186898387 Test RE 0.34368723558411096 Lambda1 -0.5022039\n",
      "127 Train Loss 407.85458 Test MSE 410.74312868359556 Test RE 0.3411727405415607 Lambda1 -0.5055757\n",
      "128 Train Loss 404.0227 Test MSE 405.29598146332705 Test RE 0.33890292681514417 Lambda1 -0.50752676\n",
      "129 Train Loss 399.25583 Test MSE 399.3782544289675 Test RE 0.33641966797919515 Lambda1 -0.51754355\n",
      "130 Train Loss 394.80154 Test MSE 395.49967870492355 Test RE 0.3347821068537114 Lambda1 -0.49320915\n",
      "131 Train Loss 388.68567 Test MSE 393.9359281424053 Test RE 0.33411961047419236 Lambda1 -0.48821744\n",
      "132 Train Loss 386.45514 Test MSE 391.8245966462755 Test RE 0.33322303699597755 Lambda1 -0.46893573\n",
      "133 Train Loss 385.2214 Test MSE 389.4670991226939 Test RE 0.33221907029606307 Lambda1 -0.46512815\n",
      "134 Train Loss 383.797 Test MSE 387.2362747941633 Test RE 0.3312662469341931 Lambda1 -0.44851136\n",
      "135 Train Loss 382.46814 Test MSE 387.2032761594379 Test RE 0.33125213208044435 Lambda1 -0.44451874\n",
      "136 Train Loss 378.402 Test MSE 385.1544545001291 Test RE 0.3303745869461184 Lambda1 -0.45990023\n",
      "137 Train Loss 376.49942 Test MSE 383.02524834617935 Test RE 0.3294601349996932 Lambda1 -0.45704985\n",
      "138 Train Loss 372.16937 Test MSE 378.31428994203964 Test RE 0.3274277951688284 Lambda1 -0.489165\n",
      "139 Train Loss 370.42657 Test MSE 374.68500307702953 Test RE 0.3258534518457429 Lambda1 -0.4936399\n",
      "140 Train Loss 365.97177 Test MSE 370.5726843806911 Test RE 0.32406033183286925 Lambda1 -0.52958894\n",
      "141 Train Loss 363.45004 Test MSE 368.69386888744003 Test RE 0.3232377897484226 Lambda1 -0.52109045\n",
      "142 Train Loss 359.73703 Test MSE 363.37298679237637 Test RE 0.3208968765839527 Lambda1 -0.552906\n",
      "143 Train Loss 357.08673 Test MSE 360.1783866775402 Test RE 0.3194831772679599 Lambda1 -0.5754267\n",
      "144 Train Loss 354.6943 Test MSE 357.66542399924623 Test RE 0.31836671025331503 Lambda1 -0.59764063\n",
      "145 Train Loss 352.6339 Test MSE 353.63370686740336 Test RE 0.31656726005336217 Lambda1 -0.6030398\n",
      "146 Train Loss 349.01526 Test MSE 350.7286782986076 Test RE 0.3152643110253728 Lambda1 -0.6102503\n",
      "147 Train Loss 348.04044 Test MSE 349.6059273895554 Test RE 0.3147592952618787 Lambda1 -0.6088111\n",
      "148 Train Loss 343.99475 Test MSE 347.47568750707023 Test RE 0.3137988748606202 Lambda1 -0.59849876\n",
      "149 Train Loss 342.86328 Test MSE 347.14888929534925 Test RE 0.31365127743468074 Lambda1 -0.59022766\n",
      "150 Train Loss 341.79086 Test MSE 347.17803447793585 Test RE 0.3136644435892765 Lambda1 -0.59056467\n",
      "151 Train Loss 340.43353 Test MSE 345.10706323206716 Test RE 0.31272751555009204 Lambda1 -0.61668456\n",
      "152 Train Loss 339.38647 Test MSE 343.6284775055417 Test RE 0.3120568674706396 Lambda1 -0.6277333\n",
      "153 Train Loss 338.55212 Test MSE 343.53464580721885 Test RE 0.3120142592077856 Lambda1 -0.61161274\n",
      "154 Train Loss 337.85617 Test MSE 341.62087617216974 Test RE 0.31114395782259713 Lambda1 -0.6186693\n",
      "155 Train Loss 336.8862 Test MSE 340.1901371698059 Test RE 0.3104917247418688 Lambda1 -0.6173828\n",
      "156 Train Loss 335.51767 Test MSE 337.5593609186684 Test RE 0.30928883921045547 Lambda1 -0.6189365\n",
      "157 Train Loss 334.24106 Test MSE 335.4419030475935 Test RE 0.3083172525384475 Lambda1 -0.60673\n",
      "158 Train Loss 332.07254 Test MSE 334.0425750788791 Test RE 0.30767349301278135 Lambda1 -0.6107843\n",
      "159 Train Loss 330.97205 Test MSE 333.4915094953549 Test RE 0.30741960583082484 Lambda1 -0.60808355\n",
      "160 Train Loss 329.81833 Test MSE 331.1061502897804 Test RE 0.30631819522031617 Lambda1 -0.5959104\n",
      "161 Train Loss 326.71664 Test MSE 327.2769003468812 Test RE 0.30454175579617776 Lambda1 -0.5873021\n",
      "162 Train Loss 324.54492 Test MSE 325.44696144051994 Test RE 0.3036891536029819 Lambda1 -0.5943992\n",
      "163 Train Loss 323.27332 Test MSE 323.67800717012807 Test RE 0.3028626837344525 Lambda1 -0.58298147\n",
      "164 Train Loss 321.3139 Test MSE 322.24085807283956 Test RE 0.3021895718113942 Lambda1 -0.5850499\n",
      "165 Train Loss 318.4652 Test MSE 318.56407341343686 Test RE 0.30046062659490763 Lambda1 -0.5453622\n",
      "166 Train Loss 317.62796 Test MSE 317.5111309741613 Test RE 0.2999636628360154 Lambda1 -0.529741\n",
      "167 Train Loss 314.43832 Test MSE 315.7919941542574 Test RE 0.2991504968592561 Lambda1 -0.52308625\n",
      "168 Train Loss 312.1517 Test MSE 314.6721452927612 Test RE 0.29861960806039756 Lambda1 -0.5257856\n",
      "169 Train Loss 310.3942 Test MSE 311.71335749263756 Test RE 0.2972123674663912 Lambda1 -0.5267712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 Train Loss 307.3172 Test MSE 309.2273936554931 Test RE 0.29602483697822285 Lambda1 -0.51007414\n",
      "171 Train Loss 304.8896 Test MSE 306.4485241645773 Test RE 0.29469172280355793 Lambda1 -0.48604292\n",
      "172 Train Loss 303.43082 Test MSE 304.873897503122 Test RE 0.29393363943095385 Lambda1 -0.4805516\n",
      "173 Train Loss 302.55927 Test MSE 303.81064605525506 Test RE 0.2934206431881493 Lambda1 -0.46637025\n",
      "174 Train Loss 300.94748 Test MSE 302.0470879043363 Test RE 0.29256778055046306 Lambda1 -0.44111875\n",
      "175 Train Loss 299.23264 Test MSE 299.9061210580838 Test RE 0.29152904873315066 Lambda1 -0.41453794\n",
      "176 Train Loss 298.52432 Test MSE 300.2930629779609 Test RE 0.2917170549788968 Lambda1 -0.42274493\n",
      "177 Train Loss 296.60052 Test MSE 298.07295992501844 Test RE 0.29063670469178643 Lambda1 -0.42332947\n",
      "178 Train Loss 295.55112 Test MSE 296.90662265288165 Test RE 0.29006752747917597 Lambda1 -0.42368537\n",
      "179 Train Loss 294.92184 Test MSE 296.08385389694234 Test RE 0.28966534031189617 Lambda1 -0.41458154\n",
      "180 Train Loss 294.50668 Test MSE 294.8822316815241 Test RE 0.2890769560238256 Lambda1 -0.4027647\n",
      "181 Train Loss 293.20468 Test MSE 292.19865020226996 Test RE 0.28775857445142433 Lambda1 -0.38443565\n",
      "182 Train Loss 291.88126 Test MSE 290.87826557602716 Test RE 0.2871076778764787 Lambda1 -0.3707301\n",
      "183 Train Loss 290.89987 Test MSE 289.99426932218773 Test RE 0.28667107730292923 Lambda1 -0.36728\n",
      "184 Train Loss 290.40845 Test MSE 289.75443722600204 Test RE 0.28655251091453177 Lambda1 -0.36346176\n",
      "185 Train Loss 289.9731 Test MSE 289.9196936984905 Test RE 0.2866342144210171 Lambda1 -0.37248436\n",
      "186 Train Loss 289.36926 Test MSE 289.5479377634797 Test RE 0.2864503839436447 Lambda1 -0.36881903\n",
      "187 Train Loss 288.9851 Test MSE 289.3360150723772 Test RE 0.28634553697346543 Lambda1 -0.36185712\n",
      "188 Train Loss 288.76666 Test MSE 288.86191831199125 Test RE 0.2861108424641109 Lambda1 -0.35534236\n",
      "189 Train Loss 288.41162 Test MSE 288.41937186454555 Test RE 0.2858915926052734 Lambda1 -0.3546141\n",
      "190 Train Loss 287.6731 Test MSE 287.68586521206055 Test RE 0.28552782216457695 Lambda1 -0.3518704\n",
      "191 Train Loss 287.31152 Test MSE 287.72530252823367 Test RE 0.28554739223470943 Lambda1 -0.35375267\n",
      "192 Train Loss 286.71564 Test MSE 287.0166695923024 Test RE 0.28519554095732097 Lambda1 -0.33998203\n",
      "193 Train Loss 286.1959 Test MSE 286.8380475669519 Test RE 0.2851067828138784 Lambda1 -0.34091944\n",
      "194 Train Loss 285.87402 Test MSE 286.54900128964647 Test RE 0.28496309576426354 Lambda1 -0.33696666\n",
      "195 Train Loss 285.6757 Test MSE 286.79903918112007 Test RE 0.28508739568301344 Lambda1 -0.3398678\n",
      "196 Train Loss 285.2955 Test MSE 286.4939434218737 Test RE 0.2849357178741008 Lambda1 -0.33970425\n",
      "197 Train Loss 284.94516 Test MSE 286.36930142871535 Test RE 0.2848737290952172 Lambda1 -0.34265965\n",
      "198 Train Loss 284.31436 Test MSE 285.7460674322391 Test RE 0.2845635706825214 Lambda1 -0.3358505\n",
      "199 Train Loss 283.91086 Test MSE 285.28970891066365 Test RE 0.28433624489054016 Lambda1 -0.34036127\n",
      "Training time: 807.77\n",
      "Training time: 807.77\n",
      "inv_HT_tanh\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 854.75055 Test MSE 858.0498991391536 Test RE 0.4931118542214491 Lambda1 -0.05382655\n",
      "1 Train Loss 854.7207 Test MSE 858.0703513311151 Test RE 0.4931177310114905 Lambda1 -0.053946268\n",
      "2 Train Loss 854.7206 Test MSE 858.0710179703617 Test RE 0.49311792256429754 Lambda1 -0.053948157\n",
      "3 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "4 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "5 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "6 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "7 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "8 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "9 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "10 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "11 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "12 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "13 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "14 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "15 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "16 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "17 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "18 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "19 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "20 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "21 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "22 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "23 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "24 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "25 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "26 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "27 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "28 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "29 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "30 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "31 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "32 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "33 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "34 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "35 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "36 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "37 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "38 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "39 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "40 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "41 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "42 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "43 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "44 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "46 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "47 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "48 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "49 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "50 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "51 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "52 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "53 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "54 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "55 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "56 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "57 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "58 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "59 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "60 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "61 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "62 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "63 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "64 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "65 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "66 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "67 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "68 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "69 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "70 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "71 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "72 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "73 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "74 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "75 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "76 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "77 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "78 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "79 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "80 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "81 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "82 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "83 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "84 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "85 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "86 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "87 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "88 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "89 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "90 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "91 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "92 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "93 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "94 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "95 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "96 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "97 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "98 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "99 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "100 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "101 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "102 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "103 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "104 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "105 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "106 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "107 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "108 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "109 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "110 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "111 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "112 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "113 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "114 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "115 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "116 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "117 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "118 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "119 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "120 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "121 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "122 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "123 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "124 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "125 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "126 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "127 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "129 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "130 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "131 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "132 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "133 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "134 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "135 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "136 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "137 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "138 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "139 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "140 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "141 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "142 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "143 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "144 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "145 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "146 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "147 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "148 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "149 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "150 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "151 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "152 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "153 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "154 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "155 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "156 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "157 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "158 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "159 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "160 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "161 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "162 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "163 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "164 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "165 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "166 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "167 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "168 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "169 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "170 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "171 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "172 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "173 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "174 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "175 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "176 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "177 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "178 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "179 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "180 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "181 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "182 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "183 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "184 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "185 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "186 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "187 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "188 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "189 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "190 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "191 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "192 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "193 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "194 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "195 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "196 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "197 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "198 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "199 Train Loss 854.7204 Test MSE 858.0716531886594 Test RE 0.49311810508850756 Lambda1 -0.053949777\n",
      "Training time: 109.57\n",
      "Training time: 109.57\n",
      "inv_HT_tanh\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 854.73895 Test MSE 858.0514872624871 Test RE 0.49311231055975757 Lambda1 -0.06045791\n",
      "1 Train Loss 854.7214 Test MSE 858.0715299673675 Test RE 0.4931180696819934 Lambda1 -0.060561325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Train Loss 854.7212 Test MSE 858.0721603300303 Test RE 0.4931182508109271 Lambda1 -0.06056318\n",
      "3 Train Loss 854.7212 Test MSE 858.0724409538686 Test RE 0.4931183314455936 Lambda1 -0.06056401\n",
      "4 Train Loss 854.7212 Test MSE 858.0727298888664 Test RE 0.4931184144683811 Lambda1 -0.06056479\n",
      "5 Train Loss 854.72107 Test MSE 858.0732502405824 Test RE 0.4931185639865778 Lambda1 -0.06056621\n",
      "6 Train Loss 854.721 Test MSE 858.0737377509001 Test RE 0.4931187040680648 Lambda1 -0.06056751\n",
      "7 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "8 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "9 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "10 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "11 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "12 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "13 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "14 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "15 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "16 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "17 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "18 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "19 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "20 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "21 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "22 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "23 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "24 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "25 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "26 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "27 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "28 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "29 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "30 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "31 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "32 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "33 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "34 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "35 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "36 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "37 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "38 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "39 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "40 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "41 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "42 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "43 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "44 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "45 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "46 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "47 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "48 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "49 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "50 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "51 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "52 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "53 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "54 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "55 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "56 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "57 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "58 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "59 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "60 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "61 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "62 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "63 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "64 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "65 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "66 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "67 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "68 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "69 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "70 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "71 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "72 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "73 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "74 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "75 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "76 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "77 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "78 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "79 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "80 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "81 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "82 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "83 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "84 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "85 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "86 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "88 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "89 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "90 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "91 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "92 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "93 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "94 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "95 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "96 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "97 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "98 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "99 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "100 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "101 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "102 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "103 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "104 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "105 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "106 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "107 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "108 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "109 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "110 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "111 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "112 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "113 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "114 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "115 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "116 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "117 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "118 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "119 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "120 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "121 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "122 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "123 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "124 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "125 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "126 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "127 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "128 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "129 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "130 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "131 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "132 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "133 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "134 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "135 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "136 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "137 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "138 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "139 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "140 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "141 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "142 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "143 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "144 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "145 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "146 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "147 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "148 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "149 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "150 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "151 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "152 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "153 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "154 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "155 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "156 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "157 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "158 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "159 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "160 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "161 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "162 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "163 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "164 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "165 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "166 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "167 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "168 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "169 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "170 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "172 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "173 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "174 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "175 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "176 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "177 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "178 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "179 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "180 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "181 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "182 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "183 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "184 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "185 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "186 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "187 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "188 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "189 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "190 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "191 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "192 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "193 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "194 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "195 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "196 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "197 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "198 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "199 Train Loss 854.721 Test MSE 858.0739242794037 Test RE 0.4931187576652586 Lambda1 -0.060568072\n",
      "Training time: 147.48\n",
      "Training time: 147.48\n",
      "inv_HT_tanh\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 854.7306 Test MSE 858.0496275916498 Test RE 0.4931117761937587 Lambda1 -0.009785617\n",
      "1 Train Loss 854.71484 Test MSE 858.0715857460137 Test RE 0.4931180857094789 Lambda1 -0.009805831\n",
      "2 Train Loss 854.5593 Test MSE 857.605964676293 Test RE 0.49298427558744784 Lambda1 -0.01126781\n",
      "3 Train Loss 854.34827 Test MSE 857.6732064767123 Test RE 0.4930036017709653 Lambda1 -0.6050727\n",
      "4 Train Loss 847.3179 Test MSE 847.9624053142682 Test RE 0.49020469864860694 Lambda1 -1.0254208\n",
      "5 Train Loss 836.3904 Test MSE 835.4639854850776 Test RE 0.4865786367921296 Lambda1 -1.1385474\n",
      "6 Train Loss 811.6383 Test MSE 814.6699926802505 Test RE 0.48048521726967536 Lambda1 -1.0449116\n",
      "7 Train Loss 780.16187 Test MSE 781.1331736914151 Test RE 0.4704914240673211 Lambda1 -1.0058061\n",
      "8 Train Loss 767.12213 Test MSE 768.0680897828721 Test RE 0.46654015762619433 Lambda1 -1.1308511\n",
      "9 Train Loss 749.0324 Test MSE 749.0698506484466 Test RE 0.4607340711313124 Lambda1 -1.2932439\n",
      "10 Train Loss 741.91925 Test MSE 739.8839501743824 Test RE 0.457900348338635 Lambda1 -1.2571139\n",
      "11 Train Loss 732.1811 Test MSE 733.0511162149985 Test RE 0.4557810875264037 Lambda1 -1.200205\n",
      "12 Train Loss 715.42694 Test MSE 716.9513688548287 Test RE 0.45074821937047677 Lambda1 -1.217444\n",
      "13 Train Loss 705.98645 Test MSE 704.31381507043 Test RE 0.44675793430052413 Lambda1 -1.2427638\n",
      "14 Train Loss 698.23474 Test MSE 696.6571767122572 Test RE 0.44432293210237606 Lambda1 -1.327232\n",
      "15 Train Loss 693.83765 Test MSE 695.6789501056056 Test RE 0.44401086957275904 Lambda1 -1.3541446\n",
      "16 Train Loss 685.3949 Test MSE 686.9937939396349 Test RE 0.4412305530177545 Lambda1 -1.4017296\n",
      "17 Train Loss 680.86725 Test MSE 680.9195903635945 Test RE 0.4392756046715657 Lambda1 -1.418168\n",
      "18 Train Loss 676.7984 Test MSE 678.6924870747002 Test RE 0.4385566406286332 Lambda1 -1.4740622\n",
      "19 Train Loss 673.0275 Test MSE 673.3137868868545 Test RE 0.4368153830661244 Lambda1 -1.5602392\n",
      "20 Train Loss 668.1354 Test MSE 673.2657802902604 Test RE 0.4367998105395492 Lambda1 -1.8081868\n",
      "21 Train Loss 662.84735 Test MSE 666.2603838858258 Test RE 0.4345213958484214 Lambda1 -1.9290856\n",
      "22 Train Loss 658.5934 Test MSE 660.038220180666 Test RE 0.43248765250460586 Lambda1 -1.8598825\n",
      "23 Train Loss 655.8187 Test MSE 660.0621888968669 Test RE 0.4324955051405429 Lambda1 -1.8420038\n",
      "24 Train Loss 651.8909 Test MSE 656.8238731386745 Test RE 0.4314332726190494 Lambda1 -2.0410435\n",
      "25 Train Loss 648.9369 Test MSE 653.6676248388696 Test RE 0.4303954370632693 Lambda1 -1.9678433\n",
      "26 Train Loss 645.94196 Test MSE 651.4354754930796 Test RE 0.42965994977780986 Lambda1 -1.9279764\n",
      "27 Train Loss 644.3957 Test MSE 650.1468883790247 Test RE 0.4292347899892684 Lambda1 -1.9184024\n",
      "28 Train Loss 640.1815 Test MSE 649.0888207784986 Test RE 0.4288853732951804 Lambda1 -1.9436615\n",
      "29 Train Loss 637.44135 Test MSE 645.7985629216168 Test RE 0.42779697348236156 Lambda1 -2.0121932\n",
      "30 Train Loss 636.2356 Test MSE 644.6214822500701 Test RE 0.4274069283198565 Lambda1 -2.0475383\n",
      "31 Train Loss 634.897 Test MSE 643.4581381415225 Test RE 0.42702108493627833 Lambda1 -2.1338203\n",
      "32 Train Loss 633.9221 Test MSE 642.4317737717975 Test RE 0.42668038356632054 Lambda1 -2.2341847\n",
      "33 Train Loss 633.12775 Test MSE 641.7120320121695 Test RE 0.4264413031185511 Lambda1 -2.3086174\n",
      "34 Train Loss 632.18085 Test MSE 641.0173248677102 Test RE 0.42621041135715154 Lambda1 -2.3296516\n",
      "35 Train Loss 631.18805 Test MSE 639.6586698915166 Test RE 0.4257584890456038 Lambda1 -2.5121174\n",
      "36 Train Loss 630.69745 Test MSE 639.318402471305 Test RE 0.42564523253800557 Lambda1 -2.6217647\n",
      "37 Train Loss 629.6823 Test MSE 639.2627195636768 Test RE 0.4256266958588066 Lambda1 -2.6987617\n",
      "38 Train Loss 628.92664 Test MSE 639.2040117399644 Test RE 0.42560715131946086 Lambda1 -2.6068084\n",
      "39 Train Loss 628.2538 Test MSE 639.0392841159869 Test RE 0.4255523067229017 Lambda1 -2.5343196\n",
      "40 Train Loss 627.042 Test MSE 637.2973267228814 Test RE 0.42497190433734494 Lambda1 -2.5817168\n",
      "41 Train Loss 625.4887 Test MSE 635.7228967518687 Test RE 0.4244466375360015 Lambda1 -2.5367062\n",
      "42 Train Loss 624.3272 Test MSE 634.0528987844199 Test RE 0.42388877565465277 Lambda1 -2.501531\n",
      "43 Train Loss 623.2432 Test MSE 631.4118955010046 Test RE 0.4230050482624705 Lambda1 -2.5316424\n",
      "44 Train Loss 620.833 Test MSE 628.146199946007 Test RE 0.4219097279766596 Lambda1 -2.7200527\n",
      "45 Train Loss 617.52783 Test MSE 625.1997907898175 Test RE 0.42091905106820404 Lambda1 -2.8188107\n",
      "46 Train Loss 615.8056 Test MSE 624.3709679942409 Test RE 0.4206399538826549 Lambda1 -2.801382\n",
      "47 Train Loss 614.7707 Test MSE 623.4439802249717 Test RE 0.4203275811514261 Lambda1 -2.867549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 Train Loss 613.40656 Test MSE 621.185044710741 Test RE 0.4195653999682751 Lambda1 -2.8910477\n",
      "49 Train Loss 610.42236 Test MSE 619.1993247862039 Test RE 0.41889425836202604 Lambda1 -2.8723526\n",
      "50 Train Loss 606.57043 Test MSE 616.2621345020021 Test RE 0.4178995587200915 Lambda1 -2.736588\n",
      "51 Train Loss 605.0752 Test MSE 615.2913885725154 Test RE 0.4175702879804639 Lambda1 -2.6729193\n",
      "52 Train Loss 603.97076 Test MSE 614.6683945214659 Test RE 0.4173588355746475 Lambda1 -2.7291799\n",
      "53 Train Loss 598.2642 Test MSE 611.4544861901505 Test RE 0.41626628630062434 Lambda1 -2.6725807\n",
      "54 Train Loss 596.8316 Test MSE 610.906508189412 Test RE 0.4160797181245944 Lambda1 -2.6595728\n",
      "55 Train Loss 594.5929 Test MSE 608.7860333428745 Test RE 0.4153569778140697 Lambda1 -2.6390784\n",
      "56 Train Loss 593.593 Test MSE 608.3963383414248 Test RE 0.41522401775890544 Lambda1 -2.6390884\n",
      "57 Train Loss 591.8493 Test MSE 607.158490803439 Test RE 0.41480139380402353 Lambda1 -2.6707878\n",
      "58 Train Loss 590.8742 Test MSE 606.2884856897597 Test RE 0.4145041001738687 Lambda1 -2.654538\n",
      "59 Train Loss 590.0761 Test MSE 605.7945400808736 Test RE 0.4143352167107146 Lambda1 -2.627946\n",
      "60 Train Loss 588.3658 Test MSE 603.9907851447623 Test RE 0.4137179147307161 Lambda1 -2.4954097\n",
      "61 Train Loss 587.59753 Test MSE 604.0354859701749 Test RE 0.4137332238964943 Lambda1 -2.40504\n",
      "62 Train Loss 587.2132 Test MSE 603.6366503583419 Test RE 0.41359661040690426 Lambda1 -2.385288\n",
      "63 Train Loss 585.7827 Test MSE 602.2830439216739 Test RE 0.4131326216489098 Lambda1 -2.3260682\n",
      "64 Train Loss 583.8008 Test MSE 598.0899085209217 Test RE 0.41169198114413125 Lambda1 -2.143546\n",
      "65 Train Loss 579.6928 Test MSE 590.7213496629826 Test RE 0.40914806752303295 Lambda1 -2.0699184\n",
      "66 Train Loss 577.01807 Test MSE 587.7855616496768 Test RE 0.40813010184437787 Lambda1 -1.9832587\n",
      "67 Train Loss 573.4207 Test MSE 585.5318679304696 Test RE 0.4073469219922816 Lambda1 -1.9475029\n",
      "68 Train Loss 567.0687 Test MSE 581.6444962875967 Test RE 0.4059924731849066 Lambda1 -1.8939021\n",
      "69 Train Loss 564.661 Test MSE 578.3725049257113 Test RE 0.40484892471794376 Lambda1 -1.8735297\n",
      "70 Train Loss 560.02423 Test MSE 572.2387927106269 Test RE 0.4026964661817203 Lambda1 -1.856892\n",
      "71 Train Loss 549.4586 Test MSE 560.199217468223 Test RE 0.39843769550293423 Lambda1 -1.9454772\n",
      "72 Train Loss 542.4139 Test MSE 553.0018946045227 Test RE 0.3958698989504361 Lambda1 -2.0607545\n",
      "73 Train Loss 540.71826 Test MSE 548.4604727411887 Test RE 0.3942410451319905 Lambda1 -2.0952716\n",
      "74 Train Loss 537.8477 Test MSE 547.2767640171863 Test RE 0.39381538215876405 Lambda1 -2.040238\n",
      "75 Train Loss 533.68146 Test MSE 538.5733837991274 Test RE 0.39067139567905107 Lambda1 -2.0151062\n",
      "76 Train Loss 530.5546 Test MSE 537.417251742885 Test RE 0.39025185175803917 Lambda1 -1.954756\n",
      "77 Train Loss 525.2424 Test MSE 533.1976401650851 Test RE 0.3887167723309742 Lambda1 -1.8444307\n",
      "78 Train Loss 521.1962 Test MSE 528.8305454677301 Test RE 0.38712162912413844 Lambda1 -1.7722969\n",
      "79 Train Loss 515.6336 Test MSE 524.373391659469 Test RE 0.3854867843283 Lambda1 -1.7842276\n",
      "80 Train Loss 511.5811 Test MSE 519.6580744986163 Test RE 0.38374966602772387 Lambda1 -1.8039951\n",
      "81 Train Loss 500.94278 Test MSE 496.6089097482491 Test RE 0.37514263464057773 Lambda1 -1.9038913\n",
      "82 Train Loss 486.89435 Test MSE 474.55697813303937 Test RE 0.36671895008374156 Lambda1 -2.0247493\n",
      "83 Train Loss 481.6398 Test MSE 472.3907236369942 Test RE 0.3658809946204543 Lambda1 -2.0378182\n",
      "84 Train Loss 476.56973 Test MSE 464.8690161340697 Test RE 0.3629564104227741 Lambda1 -2.0413163\n",
      "85 Train Loss 460.03732 Test MSE 434.3106504811736 Test RE 0.35082409246409296 Lambda1 -2.2120986\n",
      "86 Train Loss 451.3042 Test MSE 418.2340826519276 Test RE 0.3442697635952862 Lambda1 -2.2843091\n",
      "87 Train Loss 441.75037 Test MSE 409.2700539846696 Test RE 0.3405604060808923 Lambda1 -2.3125658\n",
      "88 Train Loss 422.5865 Test MSE 395.10573061715473 Test RE 0.33461533095397605 Lambda1 -2.2740164\n",
      "89 Train Loss 416.52325 Test MSE 393.05913057937573 Test RE 0.3337475722425313 Lambda1 -2.200512\n",
      "90 Train Loss 410.74368 Test MSE 379.5855674703776 Test RE 0.32797747371026054 Lambda1 -2.189643\n",
      "91 Train Loss 405.3367 Test MSE 373.5046663634311 Test RE 0.325339793474923 Lambda1 -2.1678636\n",
      "92 Train Loss 399.4031 Test MSE 363.19151963455715 Test RE 0.3208167392067636 Lambda1 -2.103174\n",
      "93 Train Loss 390.3539 Test MSE 359.69172639806305 Test RE 0.31926726713385406 Lambda1 -2.023351\n",
      "94 Train Loss 386.21082 Test MSE 357.06224189952917 Test RE 0.31809814343163245 Lambda1 -2.003054\n",
      "95 Train Loss 381.34344 Test MSE 365.02624422932865 Test RE 0.32162604894430397 Lambda1 -2.0010512\n",
      "96 Train Loss 378.20242 Test MSE 360.0456128977505 Test RE 0.3194242857567271 Lambda1 -1.9858776\n",
      "97 Train Loss 374.48566 Test MSE 349.9400517307021 Test RE 0.31490966975215834 Lambda1 -2.0136096\n",
      "98 Train Loss 371.7751 Test MSE 348.46568547658825 Test RE 0.31424558134704156 Lambda1 -2.0320253\n",
      "99 Train Loss 369.02353 Test MSE 348.8753368474747 Test RE 0.31443023844119894 Lambda1 -2.0422578\n",
      "100 Train Loss 361.7227 Test MSE 334.4606415223471 Test RE 0.30786596509880665 Lambda1 -2.0293794\n",
      "101 Train Loss 353.5953 Test MSE 314.6934477606131 Test RE 0.29862971576620834 Lambda1 -2.0799634\n",
      "102 Train Loss 347.44403 Test MSE 309.4047973141668 Test RE 0.2961097394808603 Lambda1 -2.1082058\n",
      "103 Train Loss 342.491 Test MSE 300.02736365855003 Test RE 0.2915879707856327 Lambda1 -2.114016\n",
      "104 Train Loss 333.00165 Test MSE 282.2486782961192 Test RE 0.2828167511936939 Lambda1 -2.1238394\n",
      "105 Train Loss 325.87814 Test MSE 281.3039773998885 Test RE 0.282343053355917 Lambda1 -2.0796478\n",
      "106 Train Loss 319.69833 Test MSE 281.61597779852656 Test RE 0.2824995863946528 Lambda1 -2.0240366\n",
      "107 Train Loss 317.03223 Test MSE 282.6096467511427 Test RE 0.2829975408914282 Lambda1 -1.9744258\n",
      "108 Train Loss 314.51276 Test MSE 278.89971885781165 Test RE 0.28113389451547044 Lambda1 -1.9557264\n",
      "109 Train Loss 309.90115 Test MSE 271.73504621875475 Test RE 0.2774993674916623 Lambda1 -1.9926383\n",
      "110 Train Loss 306.24313 Test MSE 264.328444808658 Test RE 0.273691381033964 Lambda1 -2.0052733\n",
      "111 Train Loss 301.64548 Test MSE 256.5322339504722 Test RE 0.2696249901176009 Lambda1 -2.0512102\n",
      "112 Train Loss 296.53317 Test MSE 247.71194982740283 Test RE 0.264949222581729 Lambda1 -2.0880787\n",
      "113 Train Loss 284.57004 Test MSE 238.49834933843758 Test RE 0.25997516315708297 Lambda1 -2.120479\n",
      "114 Train Loss 276.3641 Test MSE 232.19030386450837 Test RE 0.25651408126905695 Lambda1 -2.1204534\n",
      "115 Train Loss 264.26947 Test MSE 210.07218059423798 Test RE 0.243990795171766 Lambda1 -2.1307395\n",
      "116 Train Loss 247.80707 Test MSE 202.9787313711312 Test RE 0.23983603598713138 Lambda1 -2.1133897\n",
      "117 Train Loss 244.56274 Test MSE 198.49427913641807 Test RE 0.2371718645267126 Lambda1 -2.1180077\n",
      "118 Train Loss 243.38564 Test MSE 194.76325227147876 Test RE 0.2349322725072831 Lambda1 -2.1301286\n",
      "119 Train Loss 242.52382 Test MSE 195.2185494025214 Test RE 0.23520671224135276 Lambda1 -2.13207\n",
      "120 Train Loss 239.88066 Test MSE 192.96910899302094 Test RE 0.23384768041773765 Lambda1 -2.1327736\n",
      "121 Train Loss 236.92014 Test MSE 185.97671345163405 Test RE 0.22957175536546992 Lambda1 -2.1613412\n",
      "122 Train Loss 235.34154 Test MSE 185.74438494364344 Test RE 0.2294283160871471 Lambda1 -2.1444728\n",
      "123 Train Loss 232.53494 Test MSE 187.04475738708877 Test RE 0.2302300143888573 Lambda1 -2.131097\n",
      "124 Train Loss 227.7717 Test MSE 189.91041636154992 Test RE 0.23198695451750173 Lambda1 -2.1026852\n",
      "125 Train Loss 226.56328 Test MSE 191.39613051188522 Test RE 0.2328926310730499 Lambda1 -2.0922573\n",
      "126 Train Loss 225.58194 Test MSE 194.1420228898061 Test RE 0.23455729572135028 Lambda1 -2.076993\n",
      "127 Train Loss 224.61703 Test MSE 194.22016031159345 Test RE 0.23460449276384063 Lambda1 -2.0632439\n",
      "128 Train Loss 223.88629 Test MSE 193.99979756509083 Test RE 0.2344713635284168 Lambda1 -2.0610147\n",
      "129 Train Loss 222.52554 Test MSE 190.77411206473107 Test RE 0.23251388412032412 Lambda1 -2.063465\n",
      "130 Train Loss 218.61086 Test MSE 187.28043973305856 Test RE 0.2303750172981286 Lambda1 -2.0415668\n",
      "131 Train Loss 216.02963 Test MSE 185.8078010735024 Test RE 0.2294674780091829 Lambda1 -2.06101\n",
      "132 Train Loss 209.83707 Test MSE 180.2008021889976 Test RE 0.22597871284838142 Lambda1 -2.0875032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 Train Loss 204.99506 Test MSE 181.6181024118848 Test RE 0.22686564670618986 Lambda1 -2.0908687\n",
      "134 Train Loss 202.85176 Test MSE 180.19503539352925 Test RE 0.2259750969281758 Lambda1 -2.0792441\n",
      "135 Train Loss 201.58217 Test MSE 179.9923824956884 Test RE 0.2258479918976271 Lambda1 -2.0647576\n",
      "136 Train Loss 201.40518 Test MSE 179.94981940771552 Test RE 0.22582128699998255 Lambda1 -2.059956\n",
      "137 Train Loss 200.7139 Test MSE 179.5289626319766 Test RE 0.22555706319639995 Lambda1 -2.0689769\n",
      "138 Train Loss 198.81572 Test MSE 178.3414418361359 Test RE 0.22480983525684134 Lambda1 -2.0917413\n",
      "139 Train Loss 195.39162 Test MSE 174.7534105478635 Test RE 0.22253688303380095 Lambda1 -2.0970788\n",
      "140 Train Loss 192.9559 Test MSE 172.40722912531893 Test RE 0.22103798184519657 Lambda1 -2.0904348\n",
      "141 Train Loss 189.51093 Test MSE 170.23628420101963 Test RE 0.21964192243417502 Lambda1 -2.099388\n",
      "142 Train Loss 187.77863 Test MSE 170.6317187916084 Test RE 0.2198968728849749 Lambda1 -2.1040344\n",
      "143 Train Loss 186.56822 Test MSE 170.35062036897304 Test RE 0.2197156693459715 Lambda1 -2.1083863\n",
      "144 Train Loss 185.72797 Test MSE 171.739766587261 Test RE 0.22060970037857433 Lambda1 -2.119466\n",
      "145 Train Loss 184.22101 Test MSE 169.83862103593378 Test RE 0.2193852363533828 Lambda1 -2.1167586\n",
      "146 Train Loss 173.71182 Test MSE 159.59510116350828 Test RE 0.21266643397785806 Lambda1 -2.084666\n",
      "147 Train Loss 169.07626 Test MSE 155.59006136542985 Test RE 0.2099810469139317 Lambda1 -2.0694773\n",
      "148 Train Loss 168.44035 Test MSE 156.47365938266094 Test RE 0.21057644536368758 Lambda1 -2.0697803\n",
      "149 Train Loss 167.8717 Test MSE 155.3903442654977 Test RE 0.20984623665792418 Lambda1 -2.0571468\n",
      "150 Train Loss 166.62427 Test MSE 155.93811908720713 Test RE 0.2102157813706652 Lambda1 -2.0348945\n",
      "151 Train Loss 164.55338 Test MSE 153.30303342057843 Test RE 0.20843207151581006 Lambda1 -2.0135818\n",
      "152 Train Loss 162.3289 Test MSE 152.0652777181656 Test RE 0.20758893477061163 Lambda1 -1.9934378\n",
      "153 Train Loss 161.70319 Test MSE 151.6527291141716 Test RE 0.207307152201609 Lambda1 -1.9893034\n",
      "154 Train Loss 161.07596 Test MSE 149.95377775072077 Test RE 0.20614266025785935 Lambda1 -1.98533\n",
      "155 Train Loss 158.30379 Test MSE 147.47213895259333 Test RE 0.20442977954926111 Lambda1 -2.0016336\n",
      "156 Train Loss 157.14816 Test MSE 146.77994583907522 Test RE 0.20394944704861162 Lambda1 -2.0079422\n",
      "157 Train Loss 156.31284 Test MSE 145.00475020954653 Test RE 0.20271238595748609 Lambda1 -2.0025854\n",
      "158 Train Loss 154.04378 Test MSE 141.81295978607844 Test RE 0.20046895720678928 Lambda1 -2.0183659\n",
      "159 Train Loss 144.03569 Test MSE 136.23129556450476 Test RE 0.19648419144617776 Lambda1 -2.0149293\n",
      "160 Train Loss 137.41812 Test MSE 132.75221031635942 Test RE 0.1939590512181093 Lambda1 -2.0013442\n",
      "161 Train Loss 134.41275 Test MSE 129.5934179718223 Test RE 0.19163756449337155 Lambda1 -2.0094736\n",
      "162 Train Loss 131.49876 Test MSE 127.30032476322717 Test RE 0.1899345300034155 Lambda1 -2.0146413\n",
      "163 Train Loss 129.01787 Test MSE 123.69599536680363 Test RE 0.1872263584933064 Lambda1 -2.0042799\n",
      "164 Train Loss 127.67207 Test MSE 123.59397336008143 Test RE 0.1871491322704693 Lambda1 -1.9975684\n",
      "165 Train Loss 127.057175 Test MSE 122.66182049719231 Test RE 0.18644205177143894 Lambda1 -1.9942397\n",
      "166 Train Loss 126.35033 Test MSE 122.3620905190191 Test RE 0.1862141224475483 Lambda1 -1.9968125\n",
      "167 Train Loss 126.03551 Test MSE 121.75767898597074 Test RE 0.1857536477485427 Lambda1 -1.9965433\n",
      "168 Train Loss 125.65101 Test MSE 121.93377840125564 Test RE 0.1858879279433031 Lambda1 -1.9920574\n",
      "169 Train Loss 125.314186 Test MSE 121.05653956198813 Test RE 0.18521804603741676 Lambda1 -1.9968706\n",
      "170 Train Loss 124.58277 Test MSE 119.68285991355656 Test RE 0.18416417415394404 Lambda1 -1.9980245\n",
      "171 Train Loss 123.27236 Test MSE 117.43461227325513 Test RE 0.18242620757234262 Lambda1 -2.0199952\n",
      "172 Train Loss 122.45032 Test MSE 115.63394208243761 Test RE 0.18102219903971467 Lambda1 -2.0250196\n",
      "173 Train Loss 121.504684 Test MSE 113.88281192447825 Test RE 0.17964629367526314 Lambda1 -2.0351496\n",
      "174 Train Loss 121.224815 Test MSE 114.16134480689853 Test RE 0.17986584762429353 Lambda1 -2.0364318\n",
      "175 Train Loss 121.16089 Test MSE 114.18238070419906 Test RE 0.17988241831739119 Lambda1 -2.0369782\n",
      "176 Train Loss 120.95488 Test MSE 113.80893522902468 Test RE 0.17958801522497816 Lambda1 -2.042648\n",
      "177 Train Loss 120.61671 Test MSE 112.95681687894879 Test RE 0.1789144399690616 Lambda1 -2.051966\n",
      "178 Train Loss 120.486046 Test MSE 112.45627331377757 Test RE 0.17851758962910158 Lambda1 -2.060771\n",
      "179 Train Loss 120.43595 Test MSE 112.54791108452932 Test RE 0.1785903095503847 Lambda1 -2.0636375\n",
      "180 Train Loss 120.348564 Test MSE 112.81415793518563 Test RE 0.17880142417400255 Lambda1 -2.0656645\n",
      "181 Train Loss 120.27053 Test MSE 112.6277341359926 Test RE 0.17865362968035284 Lambda1 -2.072248\n",
      "182 Train Loss 120.12988 Test MSE 112.3979920801051 Test RE 0.17847132465244053 Lambda1 -2.079649\n",
      "183 Train Loss 120.091934 Test MSE 112.34128631548707 Test RE 0.1784262988049449 Lambda1 -2.0818474\n",
      "184 Train Loss 120.0131 Test MSE 112.3002164236429 Test RE 0.17839368114986262 Lambda1 -2.0841465\n",
      "185 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "186 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "187 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "188 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "189 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "190 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "191 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "192 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "193 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "194 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "195 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "196 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "197 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "198 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "199 Train Loss 120.00116 Test MSE 112.33018259937852 Test RE 0.1784174808360996 Lambda1 -2.0837512\n",
      "Training time: 756.67\n",
      "Training time: 756.67\n",
      "inv_HT_tanh\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 854.73 Test MSE 858.0561073034396 Test RE 0.49311363810014197 Lambda1 -0.013415628\n",
      "1 Train Loss 854.722 Test MSE 858.0700913720956 Test RE 0.4931176563145782 Lambda1 -0.013430776\n",
      "2 Train Loss 854.7218 Test MSE 858.0710188582707 Test RE 0.49311792281943007 Lambda1 -0.013431461\n",
      "3 Train Loss 854.72156 Test MSE 858.0721701237298 Test RE 0.49311825362505646 Lambda1 -0.013432293\n",
      "4 Train Loss 854.72156 Test MSE 858.0725116919758 Test RE 0.4931183517715329 Lambda1 -0.01343253\n",
      "5 Train Loss 854.7214 Test MSE 858.0731568062301 Test RE 0.4931185371390943 Lambda1 -0.013432979\n",
      "6 Train Loss 854.7214 Test MSE 858.0734609618099 Test RE 0.49311862453533784 Lambda1 -0.013433181\n",
      "7 Train Loss 854.7212 Test MSE 858.074061425557 Test RE 0.4931187970728994 Lambda1 -0.013433577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 854.7212 Test MSE 858.0744072473688 Test RE 0.4931188964414892 Lambda1 -0.013433753\n",
      "9 Train Loss 854.7212 Test MSE 858.0746323530797 Test RE 0.49311896112345105 Lambda1 -0.013433923\n",
      "10 Train Loss 854.7212 Test MSE 858.0749774942888 Test RE 0.49311906029644326 Lambda1 -0.013434086\n",
      "11 Train Loss 854.72107 Test MSE 858.0755940378101 Test RE 0.49311923745421804 Lambda1 -0.013434424\n",
      "12 Train Loss 854.721 Test MSE 858.076207078836 Test RE 0.49311941360552164 Lambda1 -0.013434733\n",
      "13 Train Loss 854.721 Test MSE 858.0764387495575 Test RE 0.4931194801738066 Lambda1 -0.0134348655\n",
      "14 Train Loss 854.7209 Test MSE 858.0770280863547 Test RE 0.49311964951385134 Lambda1 -0.013435118\n",
      "15 Train Loss 854.7209 Test MSE 858.0773515495762 Test RE 0.493119742457754 Lambda1 -0.013435246\n",
      "16 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "17 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "18 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "19 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "20 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "21 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "22 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "23 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "24 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "25 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "26 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "27 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "28 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "29 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "30 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "31 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "32 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "33 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "34 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "35 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "36 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "37 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "38 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "39 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "40 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "41 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "42 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "43 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "44 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "45 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "46 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "47 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "48 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "49 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "50 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "51 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "52 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "53 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "54 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "55 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "56 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "57 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "58 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "59 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "60 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "61 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "62 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "63 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "64 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "65 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "66 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "67 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "68 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "69 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "70 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "71 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "72 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "73 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "74 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "75 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "76 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "77 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "78 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "79 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "80 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "81 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "82 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "83 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "84 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "85 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "86 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "87 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "88 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "89 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "90 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "91 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "93 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "94 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "95 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "96 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "97 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "98 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "99 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "100 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "101 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "102 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "103 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "104 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "105 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "106 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "107 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "108 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "109 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "110 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "111 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "112 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "113 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "114 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "115 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "116 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "117 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "118 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "119 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "120 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "121 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "122 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "123 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "124 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "125 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "126 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "127 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "128 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "129 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "130 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "131 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "132 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "133 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "134 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "135 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "136 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "137 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "138 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "139 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "140 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "141 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "142 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "143 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "144 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "145 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "146 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "147 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "148 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "149 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "150 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "151 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "152 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "153 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "154 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "155 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "156 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "157 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "158 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "159 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "160 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "161 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "162 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "163 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "164 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "165 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "166 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "167 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "168 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "169 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "170 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "171 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "172 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "173 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "174 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "176 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "177 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "178 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "179 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "180 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "181 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "182 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "183 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "184 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "185 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "186 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "187 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "188 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "189 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "190 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "191 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "192 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "193 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "194 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "195 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "196 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "197 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "198 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "199 Train Loss 854.7207 Test MSE 858.0776397704631 Test RE 0.49311982527511145 Lambda1 -0.01343537\n",
      "Training time: 123.94\n",
      "Training time: 123.94\n",
      "inv_HT_tanh\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 854.79 Test MSE 858.0600831086658 Test RE 0.49311478052048696 Lambda1 -0.17385224\n",
      "1 Train Loss 854.7198 Test MSE 858.0719172566319 Test RE 0.4931181809660218 Lambda1 -0.17452395\n",
      "2 Train Loss 854.7196 Test MSE 858.0727798876535 Test RE 0.49311842883506674 Lambda1 -0.17453389\n",
      "3 Train Loss 854.7157 Test MSE 858.0879603058819 Test RE 0.4931227907674421 Lambda1 -0.1747145\n",
      "4 Train Loss 853.3772 Test MSE 856.5724227599628 Test RE 0.4926871265830259 Lambda1 -0.3243358\n",
      "5 Train Loss 843.1442 Test MSE 845.3122887832506 Test RE 0.48943808672825795 Lambda1 -0.53616506\n",
      "6 Train Loss 829.362 Test MSE 830.763818556956 Test RE 0.48520800532396685 Lambda1 -0.8508527\n",
      "7 Train Loss 804.32227 Test MSE 807.1624058477873 Test RE 0.4782661385223493 Lambda1 -0.668928\n",
      "8 Train Loss 775.8033 Test MSE 776.2501551467502 Test RE 0.46901855100477685 Lambda1 -0.4764038\n",
      "9 Train Loss 760.8567 Test MSE 761.4203598748071 Test RE 0.46451678689433934 Lambda1 -0.5283578\n",
      "10 Train Loss 736.8513 Test MSE 736.8120187461005 Test RE 0.456948779130605 Lambda1 -0.4195752\n",
      "11 Train Loss 706.2048 Test MSE 708.8884449839959 Test RE 0.4482064678071673 Lambda1 -0.36740106\n",
      "12 Train Loss 683.9841 Test MSE 682.9902647385642 Test RE 0.43994301553787624 Lambda1 -0.41280746\n",
      "13 Train Loss 659.2462 Test MSE 668.822717117865 Test RE 0.43535614470443484 Lambda1 -0.5423461\n",
      "14 Train Loss 649.2484 Test MSE 655.1305286074253 Test RE 0.4308767789572754 Lambda1 -0.60608333\n",
      "15 Train Loss 634.9685 Test MSE 649.1727273253998 Test RE 0.42891309302061864 Lambda1 -0.6253346\n",
      "16 Train Loss 622.41736 Test MSE 632.0859747472975 Test RE 0.42323078273546283 Lambda1 -0.633092\n",
      "17 Train Loss 614.65393 Test MSE 625.2399695555076 Test RE 0.4209325761336877 Lambda1 -0.5843664\n",
      "18 Train Loss 610.0067 Test MSE 624.1396797141667 Test RE 0.4205620369807494 Lambda1 -0.5677171\n",
      "19 Train Loss 607.24335 Test MSE 620.5552566552032 Test RE 0.4193526579779149 Lambda1 -0.59999233\n",
      "20 Train Loss 605.17126 Test MSE 620.5952169921115 Test RE 0.4193661597600309 Lambda1 -0.63848853\n",
      "21 Train Loss 603.01355 Test MSE 620.8408536228015 Test RE 0.4194491458163922 Lambda1 -0.70605576\n",
      "22 Train Loss 602.5299 Test MSE 620.6322963409208 Test RE 0.41937868772627196 Lambda1 -0.73263717\n",
      "23 Train Loss 601.97815 Test MSE 620.2300785890395 Test RE 0.4192427707811717 Lambda1 -0.7612138\n",
      "24 Train Loss 601.51086 Test MSE 620.1598444402746 Test RE 0.41921903282184064 Lambda1 -0.8260892\n",
      "25 Train Loss 601.02527 Test MSE 619.4414558985586 Test RE 0.4189761523621509 Lambda1 -0.9045081\n",
      "26 Train Loss 599.99713 Test MSE 617.3712023810531 Test RE 0.4182754301322293 Lambda1 -1.0544437\n",
      "27 Train Loss 598.2924 Test MSE 612.7130416495934 Test RE 0.4166944660863116 Lambda1 -1.2479728\n",
      "28 Train Loss 582.6515 Test MSE 583.9659304656357 Test RE 0.40680185613290126 Lambda1 -1.4472445\n",
      "29 Train Loss 540.4763 Test MSE 539.9390084369398 Test RE 0.39116638181335966 Lambda1 -1.4717196\n",
      "30 Train Loss 513.19666 Test MSE 509.22516787100926 Test RE 0.37987796308628163 Lambda1 -1.547141\n",
      "31 Train Loss 483.0945 Test MSE 482.31780436326096 Test RE 0.3697054200304019 Lambda1 -1.4445174\n",
      "32 Train Loss 434.44714 Test MSE 416.3590758505347 Test RE 0.34349718995880774 Lambda1 -1.3732902\n",
      "33 Train Loss 392.84583 Test MSE 357.97115421212345 Test RE 0.3185027501445915 Lambda1 -1.4449805\n",
      "34 Train Loss 363.1602 Test MSE 334.75564798164396 Test RE 0.30800170966585005 Lambda1 -1.2828624\n",
      "35 Train Loss 333.1831 Test MSE 312.6063467896401 Test RE 0.2976377865977637 Lambda1 -1.2331947\n",
      "36 Train Loss 313.3326 Test MSE 304.45406855159877 Test RE 0.293731187917698 Lambda1 -1.2185054\n",
      "37 Train Loss 301.65674 Test MSE 300.8176528911689 Test RE 0.2919717479237007 Lambda1 -1.2332006\n",
      "38 Train Loss 296.628 Test MSE 297.5537823706769 Test RE 0.2903834817626406 Lambda1 -1.2323856\n",
      "39 Train Loss 293.2549 Test MSE 294.3149290942512 Test RE 0.2887987550379658 Lambda1 -1.2070861\n",
      "40 Train Loss 290.73737 Test MSE 292.40827499107047 Test RE 0.28786177567347865 Lambda1 -1.1693357\n",
      "41 Train Loss 289.41068 Test MSE 291.9114187495542 Test RE 0.2876171062492819 Lambda1 -1.1530774\n",
      "42 Train Loss 287.78607 Test MSE 290.47836651684923 Test RE 0.2869102523679888 Lambda1 -1.115431\n",
      "43 Train Loss 286.87592 Test MSE 289.4368008505912 Test RE 0.28639540467662017 Lambda1 -1.0852143\n",
      "44 Train Loss 285.70938 Test MSE 288.13368899610776 Test RE 0.2857499679900738 Lambda1 -0.9965605\n",
      "45 Train Loss 285.29614 Test MSE 287.8219316232391 Test RE 0.28559533704459067 Lambda1 -0.954432\n",
      "46 Train Loss 284.71106 Test MSE 287.53671323058575 Test RE 0.2854537960011768 Lambda1 -0.95213723\n",
      "47 Train Loss 283.9306 Test MSE 286.8314999807506 Test RE 0.2851035287617992 Lambda1 -0.8789809\n",
      "48 Train Loss 282.3735 Test MSE 284.49751246615557 Test RE 0.2839411960294402 Lambda1 -0.7586861\n",
      "49 Train Loss 281.11465 Test MSE 283.28998865081496 Test RE 0.2833379739781093 Lambda1 -0.6998906\n",
      "50 Train Loss 278.97308 Test MSE 281.3741137324357 Test RE 0.2823782488627503 Lambda1 -0.61712426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 Train Loss 278.02307 Test MSE 279.93897977943124 Test RE 0.2816572005241915 Lambda1 -0.557384\n",
      "52 Train Loss 277.5938 Test MSE 279.3449369604677 Test RE 0.2813581973360217 Lambda1 -0.53515774\n",
      "53 Train Loss 277.12302 Test MSE 278.7462915691315 Test RE 0.2810565557050793 Lambda1 -0.5145538\n",
      "54 Train Loss 276.3627 Test MSE 278.14566702794525 Test RE 0.28075359114022747 Lambda1 -0.49719742\n",
      "55 Train Loss 276.08868 Test MSE 278.13161339057467 Test RE 0.28074649834772974 Lambda1 -0.49854577\n",
      "56 Train Loss 275.7911 Test MSE 277.88981104913694 Test RE 0.28062443397547515 Lambda1 -0.490083\n",
      "57 Train Loss 275.01743 Test MSE 277.30821315982166 Test RE 0.2803306195611442 Lambda1 -0.46746397\n",
      "58 Train Loss 274.59158 Test MSE 276.78679319270753 Test RE 0.2800669440717972 Lambda1 -0.44398358\n",
      "59 Train Loss 274.33276 Test MSE 276.4162468550205 Test RE 0.2798794124785366 Lambda1 -0.42762432\n",
      "60 Train Loss 274.16614 Test MSE 276.1614881552984 Test RE 0.2797504074862948 Lambda1 -0.42115772\n",
      "61 Train Loss 273.91788 Test MSE 275.9202991127192 Test RE 0.27962821906700036 Lambda1 -0.40854898\n",
      "62 Train Loss 273.76282 Test MSE 275.74806138113195 Test RE 0.27954092927939544 Lambda1 -0.4047669\n",
      "63 Train Loss 272.9313 Test MSE 274.794532386769 Test RE 0.2790571884145696 Lambda1 -0.40391046\n",
      "64 Train Loss 272.47668 Test MSE 274.07058749898505 Test RE 0.27868935857590876 Lambda1 -0.3991263\n",
      "65 Train Loss 271.96198 Test MSE 273.20901631698075 Test RE 0.2782509683730254 Lambda1 -0.40203118\n",
      "66 Train Loss 271.11224 Test MSE 271.5399285253659 Test RE 0.27739972123628437 Lambda1 -0.40024823\n",
      "67 Train Loss 270.5353 Test MSE 270.45126462238534 Test RE 0.2768430841986345 Lambda1 -0.41426128\n",
      "68 Train Loss 267.71844 Test MSE 265.83129297915605 Test RE 0.27446831900053714 Lambda1 -0.46411452\n",
      "69 Train Loss 263.0158 Test MSE 259.206006631256 Test RE 0.27102646541206526 Lambda1 -0.4657386\n",
      "70 Train Loss 259.7019 Test MSE 253.34978837156814 Test RE 0.26794733601350545 Lambda1 -0.5042303\n",
      "71 Train Loss 250.28296 Test MSE 238.48215194555382 Test RE 0.2599663350218633 Lambda1 -0.54891\n",
      "72 Train Loss 243.09706 Test MSE 234.45032054478546 Test RE 0.25775944386707617 Lambda1 -0.54481554\n",
      "73 Train Loss 238.0388 Test MSE 230.10329006292937 Test RE 0.2553586565286185 Lambda1 -0.57762474\n",
      "74 Train Loss 234.34175 Test MSE 222.83282746998552 Test RE 0.2512920539700985 Lambda1 -0.59947884\n",
      "75 Train Loss 222.82729 Test MSE 214.87749345690293 Test RE 0.24676561017077991 Lambda1 -0.7009504\n",
      "76 Train Loss 213.43237 Test MSE 205.58951029225412 Test RE 0.2413735326591087 Lambda1 -0.6917727\n",
      "77 Train Loss 207.45648 Test MSE 194.7847499525014 Test RE 0.2349452378886844 Lambda1 -0.7314918\n",
      "78 Train Loss 203.61037 Test MSE 189.5697715075667 Test RE 0.2317788020825204 Lambda1 -0.7712142\n",
      "79 Train Loss 198.24425 Test MSE 184.61162030945613 Test RE 0.22872766037550052 Lambda1 -0.7790146\n",
      "80 Train Loss 194.26408 Test MSE 182.01415650756505 Test RE 0.22711287464271607 Lambda1 -0.79361606\n",
      "81 Train Loss 189.09097 Test MSE 174.51268287854407 Test RE 0.22238355484824304 Lambda1 -0.8770639\n",
      "82 Train Loss 183.58101 Test MSE 169.20683148146608 Test RE 0.21897680615928825 Lambda1 -0.9670723\n",
      "83 Train Loss 176.11295 Test MSE 159.90717696513065 Test RE 0.21287425876280583 Lambda1 -1.0836977\n",
      "84 Train Loss 168.18823 Test MSE 152.848389274908 Test RE 0.20812277305790683 Lambda1 -1.103536\n",
      "85 Train Loss 162.278 Test MSE 147.69291171755322 Test RE 0.20458274284538425 Lambda1 -1.1847947\n",
      "86 Train Loss 160.2666 Test MSE 147.01611877066392 Test RE 0.20411346120757018 Lambda1 -1.1903275\n",
      "87 Train Loss 155.4111 Test MSE 140.09142064737847 Test RE 0.19924844483529222 Lambda1 -1.2223552\n",
      "88 Train Loss 147.17702 Test MSE 135.63103694838645 Test RE 0.1960508419253008 Lambda1 -1.2534097\n",
      "89 Train Loss 141.62039 Test MSE 128.10301431151436 Test RE 0.190532403128204 Lambda1 -1.28802\n",
      "90 Train Loss 133.64307 Test MSE 124.5466153109707 Test RE 0.18786900508189222 Lambda1 -1.3585775\n",
      "91 Train Loss 129.59943 Test MSE 120.69367101338273 Test RE 0.18494024095155961 Lambda1 -1.4112171\n",
      "92 Train Loss 127.30054 Test MSE 118.65586910069086 Test RE 0.18337232140308152 Lambda1 -1.4339445\n",
      "93 Train Loss 126.40358 Test MSE 118.91328385866362 Test RE 0.18357111969744797 Lambda1 -1.4381794\n",
      "94 Train Loss 125.63693 Test MSE 118.99156190620936 Test RE 0.18363153020983983 Lambda1 -1.426898\n",
      "95 Train Loss 124.64167 Test MSE 119.15668110633075 Test RE 0.18375889461867032 Lambda1 -1.4070513\n",
      "96 Train Loss 122.515335 Test MSE 118.66842525523482 Test RE 0.18338202336858897 Lambda1 -1.4295615\n",
      "97 Train Loss 121.63466 Test MSE 118.05050297131913 Test RE 0.1829039529111702 Lambda1 -1.4292964\n",
      "98 Train Loss 120.59464 Test MSE 118.00268831067714 Test RE 0.1828669078501303 Lambda1 -1.4183023\n",
      "99 Train Loss 119.60224 Test MSE 116.38781173917637 Test RE 0.18161132295968693 Lambda1 -1.4259738\n",
      "100 Train Loss 118.74344 Test MSE 115.5121488234326 Test RE 0.18092684169200565 Lambda1 -1.4258212\n",
      "101 Train Loss 118.15293 Test MSE 114.45579612667015 Test RE 0.1800976582682882 Lambda1 -1.4372343\n",
      "102 Train Loss 117.64151 Test MSE 115.24485859481057 Test RE 0.18071739192623523 Lambda1 -1.4454888\n",
      "103 Train Loss 116.40437 Test MSE 113.51355135178109 Test RE 0.17935480915389493 Lambda1 -1.4651989\n",
      "104 Train Loss 114.895706 Test MSE 111.83695047537489 Test RE 0.17802534203104328 Lambda1 -1.4898257\n",
      "105 Train Loss 113.88772 Test MSE 110.6916230270484 Test RE 0.1771114131791 Lambda1 -1.4934115\n",
      "106 Train Loss 113.08539 Test MSE 109.7966194266645 Test RE 0.17639393758615024 Lambda1 -1.5037612\n",
      "107 Train Loss 112.22993 Test MSE 108.60699893302319 Test RE 0.1754357416910177 Lambda1 -1.5264448\n",
      "108 Train Loss 111.60681 Test MSE 108.11285991919411 Test RE 0.17503618883018712 Lambda1 -1.5330824\n",
      "109 Train Loss 110.71174 Test MSE 108.42428308336916 Test RE 0.17528810671251446 Lambda1 -1.5264435\n",
      "110 Train Loss 110.14959 Test MSE 108.3639643963038 Test RE 0.17523934171689165 Lambda1 -1.5401155\n",
      "111 Train Loss 109.38237 Test MSE 108.10750361214268 Test RE 0.17503185280954228 Lambda1 -1.560918\n",
      "112 Train Loss 108.46782 Test MSE 107.49999323957942 Test RE 0.1745393639935891 Lambda1 -1.5827566\n",
      "113 Train Loss 107.88701 Test MSE 106.60982682323086 Test RE 0.17381521484672424 Lambda1 -1.6126744\n",
      "114 Train Loss 106.906685 Test MSE 105.6993979444146 Test RE 0.17307144808896183 Lambda1 -1.6260996\n",
      "115 Train Loss 106.3987 Test MSE 105.11848692904391 Test RE 0.17259520304320924 Lambda1 -1.6343892\n",
      "116 Train Loss 106.064 Test MSE 104.72547459019681 Test RE 0.17227225525797576 Lambda1 -1.6407489\n",
      "117 Train Loss 105.70692 Test MSE 104.39065725558649 Test RE 0.17199664937837347 Lambda1 -1.6536455\n",
      "118 Train Loss 105.45867 Test MSE 104.45298282489577 Test RE 0.17204798629783982 Lambda1 -1.6557819\n",
      "119 Train Loss 105.36273 Test MSE 104.37592988581719 Test RE 0.1719845163596343 Lambda1 -1.6597908\n",
      "120 Train Loss 105.20732 Test MSE 104.19179138022753 Test RE 0.17183274309312832 Lambda1 -1.6651481\n",
      "121 Train Loss 104.57733 Test MSE 103.65631613877247 Test RE 0.17139062235015265 Lambda1 -1.6868337\n",
      "122 Train Loss 104.25258 Test MSE 103.47230891327895 Test RE 0.17123843132883873 Lambda1 -1.7028112\n",
      "123 Train Loss 103.89707 Test MSE 103.0205348052871 Test RE 0.17086419730682834 Lambda1 -1.69828\n",
      "124 Train Loss 103.30066 Test MSE 102.64092274133438 Test RE 0.17054910492088227 Lambda1 -1.7073724\n",
      "125 Train Loss 102.99758 Test MSE 102.38729309181292 Test RE 0.1703382579038387 Lambda1 -1.7192588\n",
      "126 Train Loss 102.74245 Test MSE 102.08932156073654 Test RE 0.1700902147541503 Lambda1 -1.7305623\n",
      "127 Train Loss 102.13526 Test MSE 101.15722763083166 Test RE 0.1693119570941404 Lambda1 -1.769204\n",
      "128 Train Loss 101.938126 Test MSE 100.95482679031772 Test RE 0.1691424880302098 Lambda1 -1.7843218\n",
      "129 Train Loss 101.81957 Test MSE 100.7817836327593 Test RE 0.16899746523080525 Lambda1 -1.7982463\n",
      "130 Train Loss 101.129135 Test MSE 100.17645876138005 Test RE 0.16848917674482802 Lambda1 -1.8237463\n",
      "131 Train Loss 100.71322 Test MSE 99.6748819123864 Test RE 0.1680668403926117 Lambda1 -1.8434777\n",
      "132 Train Loss 100.087585 Test MSE 99.25302264254475 Test RE 0.1677108041905791 Lambda1 -1.8914168\n",
      "133 Train Loss 99.832886 Test MSE 99.17947124226492 Test RE 0.16764865167225884 Lambda1 -1.9192752\n",
      "134 Train Loss 99.62605 Test MSE 99.04497461672103 Test RE 0.1675349394937668 Lambda1 -1.931435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 Train Loss 99.23843 Test MSE 98.4632822800948 Test RE 0.16704224766692008 Lambda1 -1.9698157\n",
      "136 Train Loss 98.97276 Test MSE 97.65275104066527 Test RE 0.16635329670973129 Lambda1 -2.0058513\n",
      "137 Train Loss 98.87466 Test MSE 97.50211104870391 Test RE 0.16622493816013217 Lambda1 -2.010341\n",
      "138 Train Loss 98.74979 Test MSE 97.2179842201589 Test RE 0.165982566886281 Lambda1 -2.0289843\n",
      "139 Train Loss 98.607765 Test MSE 96.73634927785498 Test RE 0.16557090301766245 Lambda1 -2.0560992\n",
      "140 Train Loss 98.475494 Test MSE 96.57874594839602 Test RE 0.16543597357919082 Lambda1 -2.0537775\n",
      "141 Train Loss 98.33328 Test MSE 96.34428857967185 Test RE 0.16523504297163155 Lambda1 -2.0643282\n",
      "142 Train Loss 98.17472 Test MSE 96.42444495560949 Test RE 0.1653037646818063 Lambda1 -2.0645552\n",
      "143 Train Loss 98.121086 Test MSE 96.28627012835824 Test RE 0.1651852832757278 Lambda1 -2.0640802\n",
      "144 Train Loss 98.070786 Test MSE 96.25817719866089 Test RE 0.1651611839047605 Lambda1 -2.0614898\n",
      "145 Train Loss 97.986755 Test MSE 96.29893904795486 Test RE 0.16519615009109223 Lambda1 -2.0539365\n",
      "146 Train Loss 97.89015 Test MSE 96.3224684701303 Test RE 0.16521633064859234 Lambda1 -2.0558279\n",
      "147 Train Loss 97.11722 Test MSE 95.18035766655409 Test RE 0.16423391165650705 Lambda1 -2.148814\n",
      "148 Train Loss 96.41303 Test MSE 94.02984069906219 Test RE 0.163238284033238 Lambda1 -2.2069337\n",
      "149 Train Loss 95.658554 Test MSE 93.56755018676397 Test RE 0.16283651534607696 Lambda1 -2.2635658\n",
      "150 Train Loss 95.52589 Test MSE 93.13434705160284 Test RE 0.16245912421437067 Lambda1 -2.2867758\n",
      "151 Train Loss 95.50879 Test MSE 93.07687719969077 Test RE 0.16240899264178063 Lambda1 -2.290854\n",
      "152 Train Loss 95.42488 Test MSE 93.01170258985881 Test RE 0.1623521213937737 Lambda1 -2.290911\n",
      "153 Train Loss 95.329544 Test MSE 92.89192058913433 Test RE 0.16224754784865694 Lambda1 -2.2806654\n",
      "154 Train Loss 95.21486 Test MSE 92.83833110598556 Test RE 0.16220074067455992 Lambda1 -2.284381\n",
      "155 Train Loss 95.12652 Test MSE 92.80928763747201 Test RE 0.1621753673156115 Lambda1 -2.2761118\n",
      "156 Train Loss 95.016884 Test MSE 92.60487068085031 Test RE 0.1619966693081727 Lambda1 -2.287884\n",
      "157 Train Loss 94.933914 Test MSE 92.46934374209853 Test RE 0.1618780850958214 Lambda1 -2.2969127\n",
      "158 Train Loss 94.74452 Test MSE 92.07938360755375 Test RE 0.16153638972163997 Lambda1 -2.3137965\n",
      "159 Train Loss 94.5659 Test MSE 91.67662611274893 Test RE 0.16118272048205173 Lambda1 -2.3368528\n",
      "160 Train Loss 94.09298 Test MSE 91.4791524442431 Test RE 0.16100903116099752 Lambda1 -2.3493917\n",
      "161 Train Loss 93.6989 Test MSE 91.68283849804331 Test RE 0.1611881815916165 Lambda1 -2.3337598\n",
      "162 Train Loss 93.30575 Test MSE 91.66287120447211 Test RE 0.16117062832292436 Lambda1 -2.3182628\n",
      "163 Train Loss 93.045815 Test MSE 91.65384952162363 Test RE 0.16116269672503108 Lambda1 -2.3163157\n",
      "164 Train Loss 92.76382 Test MSE 91.82471112235545 Test RE 0.1613128469642296 Lambda1 -2.309558\n",
      "165 Train Loss 92.67012 Test MSE 91.90136322159276 Test RE 0.16138016211729098 Lambda1 -2.2980213\n",
      "166 Train Loss 92.61588 Test MSE 92.02093665017371 Test RE 0.1614851143503353 Lambda1 -2.2877982\n",
      "167 Train Loss 92.38188 Test MSE 92.25057629706636 Test RE 0.16168648307832237 Lambda1 -2.268617\n",
      "168 Train Loss 92.214836 Test MSE 92.46273822979202 Test RE 0.1618723031429238 Lambda1 -2.2539237\n",
      "169 Train Loss 92.07845 Test MSE 92.17539058791156 Test RE 0.16162058110064637 Lambda1 -2.253375\n",
      "170 Train Loss 91.95591 Test MSE 92.29166430418185 Test RE 0.16172248629947214 Lambda1 -2.2426999\n",
      "171 Train Loss 91.542786 Test MSE 91.99559799118316 Test RE 0.16146287974748058 Lambda1 -2.2400699\n",
      "172 Train Loss 90.83371 Test MSE 91.69172081548201 Test RE 0.16119598943190974 Lambda1 -2.2722912\n",
      "173 Train Loss 90.57888 Test MSE 91.47225920956187 Test RE 0.16100296478457835 Lambda1 -2.2958984\n",
      "174 Train Loss 90.466156 Test MSE 91.39138533114955 Test RE 0.16093177482135157 Lambda1 -2.309375\n",
      "175 Train Loss 90.298775 Test MSE 91.15868065788132 Test RE 0.16072675853195637 Lambda1 -2.321516\n",
      "176 Train Loss 90.153435 Test MSE 90.86441447823537 Test RE 0.16046713059747747 Lambda1 -2.3351264\n",
      "177 Train Loss 90.01953 Test MSE 90.49094110616664 Test RE 0.16013701286502624 Lambda1 -2.347288\n",
      "178 Train Loss 89.904755 Test MSE 90.3820376090578 Test RE 0.16004062348806475 Lambda1 -2.3497689\n",
      "179 Train Loss 89.71631 Test MSE 90.46334508325955 Test RE 0.16011259339503786 Lambda1 -2.3385382\n",
      "180 Train Loss 89.508194 Test MSE 90.23483533621375 Test RE 0.15991024391185882 Lambda1 -2.3404016\n",
      "181 Train Loss 89.34734 Test MSE 90.05528110801646 Test RE 0.15975106559671437 Lambda1 -2.3447912\n",
      "182 Train Loss 89.09294 Test MSE 89.89295492749363 Test RE 0.1596070236473899 Lambda1 -2.3584714\n",
      "183 Train Loss 88.95686 Test MSE 89.66406075240123 Test RE 0.15940369067349114 Lambda1 -2.371688\n",
      "184 Train Loss 88.84374 Test MSE 89.51615884823616 Test RE 0.15927216729903873 Lambda1 -2.375333\n",
      "185 Train Loss 88.75373 Test MSE 89.31614652430537 Test RE 0.15909413122493626 Lambda1 -2.3815796\n",
      "186 Train Loss 88.73573 Test MSE 89.27541141381832 Test RE 0.1590578474377274 Lambda1 -2.383417\n",
      "187 Train Loss 88.70124 Test MSE 89.15550603696707 Test RE 0.1589509966319932 Lambda1 -2.39035\n",
      "188 Train Loss 88.63236 Test MSE 89.01257726401174 Test RE 0.1588235351631045 Lambda1 -2.3996274\n",
      "189 Train Loss 88.58136 Test MSE 88.89453945516959 Test RE 0.15871819386274982 Lambda1 -2.4081037\n",
      "190 Train Loss 88.2997 Test MSE 88.53151955505497 Test RE 0.15839378244571928 Lambda1 -2.423046\n",
      "191 Train Loss 87.96285 Test MSE 88.04187393167071 Test RE 0.15795515698697388 Lambda1 -2.4556465\n",
      "192 Train Loss 87.6102 Test MSE 87.48075201982658 Test RE 0.15745100045075452 Lambda1 -2.4937863\n",
      "193 Train Loss 87.48324 Test MSE 87.38636710314871 Test RE 0.1573660388458057 Lambda1 -2.4981687\n",
      "194 Train Loss 87.03342 Test MSE 87.39762099096426 Test RE 0.1573761715632504 Lambda1 -2.4953604\n",
      "195 Train Loss 86.76572 Test MSE 87.39842023895613 Test RE 0.15737689116122167 Lambda1 -2.490146\n",
      "196 Train Loss 86.693405 Test MSE 87.40848304563546 Test RE 0.15738595086530735 Lambda1 -2.4912577\n",
      "197 Train Loss 86.667564 Test MSE 87.34566068042237 Test RE 0.1573293823576339 Lambda1 -2.4956758\n",
      "198 Train Loss 86.61123 Test MSE 87.33197954377842 Test RE 0.15731706045718988 Lambda1 -2.498837\n",
      "199 Train Loss 86.50543 Test MSE 87.3129673872816 Test RE 0.15729993557700298 Lambda1 -2.4998925\n",
      "Training time: 840.08\n",
      "Training time: 840.08\n",
      "inv_HT_tanh\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 854.7599 Test MSE 858.0521369077966 Test RE 0.49311249723156203 Lambda1 -0.005313517\n",
      "1 Train Loss 854.7226 Test MSE 858.0694682756903 Test RE 0.4931174772733216 Lambda1 -0.0052946596\n",
      "2 Train Loss 854.722 Test MSE 858.0729792729795 Test RE 0.4931184861265782 Lambda1 -0.0052923993\n",
      "3 Train Loss 854.722 Test MSE 858.0732723231233 Test RE 0.49311857033178824 Lambda1 -0.005292172\n",
      "4 Train Loss 854.7218 Test MSE 858.0740665585311 Test RE 0.4931187985478106 Lambda1 -0.005291453\n",
      "5 Train Loss 854.7218 Test MSE 858.0743965005988 Test RE 0.49311889335350795 Lambda1 -0.005291203\n",
      "6 Train Loss 854.7218 Test MSE 858.074604672151 Test RE 0.4931189531696029 Lambda1 -0.005290954\n",
      "7 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "8 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "9 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "10 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "12 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "13 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "14 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "15 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "16 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "17 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "18 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "19 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "20 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "21 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "22 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "23 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "24 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "25 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "26 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "27 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "28 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "29 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "30 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "31 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "32 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "33 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "34 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "35 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "36 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "37 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "38 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "39 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "40 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "41 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "42 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "43 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "44 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "45 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "46 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "47 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "48 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "49 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "50 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "51 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "52 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "53 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "54 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "55 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "56 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "57 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "58 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "59 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "60 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "61 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "62 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "63 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "64 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "65 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "66 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "67 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "68 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "69 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "70 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "71 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "72 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "73 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "74 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "75 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "76 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "77 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "78 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "79 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "80 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "81 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "82 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "83 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "84 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "85 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "86 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "87 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "88 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "89 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "90 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "91 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "92 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "94 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "95 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "96 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "97 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "98 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "99 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "100 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "101 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "102 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "103 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "104 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "105 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "106 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "107 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "108 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "109 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "110 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "111 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "112 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "113 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "114 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "115 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "116 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "117 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "118 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "119 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "120 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "121 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "122 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "123 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "124 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "125 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "126 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "127 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "128 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "129 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "130 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "131 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "132 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "133 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "134 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "135 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "136 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "137 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "138 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "139 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "140 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "141 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "142 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "143 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "144 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "145 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "146 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "147 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "148 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "149 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "150 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "151 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "152 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "153 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "154 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "155 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "156 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "157 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "158 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "159 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "160 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "161 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "162 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "163 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "164 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "165 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "166 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "167 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "168 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "169 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "170 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "171 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "172 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "173 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "174 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "176 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "177 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "178 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "179 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "180 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "181 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "182 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "183 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "184 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "185 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "186 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "187 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "188 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "189 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "190 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "191 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "192 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "193 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "194 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "195 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "196 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "197 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "198 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "199 Train Loss 854.72156 Test MSE 858.0750002233099 Test RE 0.49311906682740714 Lambda1 -0.005290434\n",
      "Training time: 130.62\n",
      "Training time: 130.62\n",
      "inv_HT_tanh\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 854.7464 Test MSE 858.0504125876137 Test RE 0.49311200175802267 Lambda1 -0.015726244\n",
      "1 Train Loss 854.7212 Test MSE 858.0697799273028 Test RE 0.493117566823672 Lambda1 -0.01576039\n",
      "2 Train Loss 854.7206 Test MSE 858.0730935253756 Test RE 0.4931185189559343 Lambda1 -0.015763469\n",
      "3 Train Loss 854.7206 Test MSE 858.0734230670743 Test RE 0.49311861364664306 Lambda1 -0.015763767\n",
      "4 Train Loss 854.7204 Test MSE 858.0746209006483 Test RE 0.4931189578327051 Lambda1 -0.015764892\n",
      "5 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "6 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "7 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "8 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "9 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "10 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "11 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "12 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "13 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "14 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "15 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "16 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "17 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "18 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "19 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "20 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "21 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "22 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "23 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "24 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "25 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "26 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "27 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "28 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "29 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "30 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "31 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "32 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "33 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "34 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "35 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "36 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "37 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "38 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "39 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "40 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "41 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "42 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "43 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "44 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "45 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "46 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "47 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "48 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "49 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "51 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "52 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "53 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "54 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "55 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "56 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "57 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "58 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "59 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "60 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "61 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "62 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "63 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "64 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "65 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "66 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "67 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "68 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "69 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "70 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "71 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "72 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "73 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "74 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "75 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "76 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "77 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "78 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "79 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "80 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "81 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "82 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "83 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "84 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "85 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "86 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "87 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "88 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "89 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "90 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "91 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "92 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "93 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "94 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "95 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "96 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "97 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "98 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "99 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "100 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "101 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "102 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "103 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "104 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "105 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "106 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "107 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "108 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "109 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "110 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "111 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "112 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "113 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "114 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "115 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "116 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "117 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "118 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "119 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "120 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "121 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "122 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "123 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "124 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "125 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "126 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "127 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "128 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "129 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "130 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "131 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "132 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "133 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "135 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "136 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "137 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "138 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "139 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "140 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "141 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "142 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "143 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "144 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "145 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "146 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "147 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "148 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "149 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "150 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "151 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "152 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "153 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "154 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "155 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "156 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "157 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "158 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "159 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "160 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "161 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "162 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "163 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "164 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "165 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "166 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "167 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "168 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "169 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "170 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "171 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "172 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "173 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "174 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "175 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "176 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "177 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "178 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "179 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "180 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "181 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "182 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "183 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "184 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "185 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "186 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "187 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "188 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "189 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "190 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "191 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "192 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "193 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "194 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "195 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "196 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "197 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "198 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "199 Train Loss 854.72015 Test MSE 858.074914985662 Test RE 0.4931190423351946 Lambda1 -0.015765209\n",
      "Training time: 99.11\n",
      "Training time: 99.11\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 200 #75\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "\n",
    "\n",
    "lambda1_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    'Generate Training data'\n",
    "    print(reps)\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []   \n",
    "\n",
    "    lambda1_val = []\n",
    "\n",
    "    N_f = 50000 #Total number of collocation points \n",
    "    N_train = 5000\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.05, \n",
    "                              max_iter = 20, \n",
    "                              max_eval = 30, \n",
    "                              tolerance_grad = 1e-8, \n",
    "                              tolerance_change = 1e-8, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "\n",
    "\n",
    "    lambda1_full.append(lambda1_val)\n",
    "\n",
    "    if(nan_flag == 1):\n",
    "        nan_tune.append(tune_reps)\n",
    "        break\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time,\"lambda1\": lambda1_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
