{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/atanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_2D_4(xt): #True function for 2D_4 Heat Transfer in a rod x \\in [0,1] t \\in [0,0.1]\n",
    "    term1 = 4*u0/np.pi\n",
    "    \n",
    "    resol_n = 10000\n",
    "    \n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "\n",
    "    u = np.zeros((np.shape(xt)[0],1))\n",
    "    \n",
    "    for i in range(resol_n):\n",
    "        j = 2*i-1\n",
    "        term2 = np.sin(j*np.pi*x)/j\n",
    "        term3 = np.exp(-1*np.square(j*np.pi)*t)\n",
    "        \n",
    "        u = u + term2*term3\n",
    "        \n",
    "    u = term1*u\n",
    "    \n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = 50.0\n",
    "loss_thresh = 0.1\n",
    "label = \"inv_HT_swish\"\n",
    "\n",
    "x_ll = np.array(0.0)\n",
    "x_ul = np.array(1.0)\n",
    "\n",
    "x = np.linspace(x_ll,x_ul,100).reshape(-1,1)\n",
    "t = np.linspace(0,0.1,100).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "u_true = true_2D_4(xt)\n",
    "u_true_norm = np.linalg.norm(u_true,2)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_f,N_train,seed):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    #X_Train\n",
    "    np.random.seed(seed)\n",
    "    x_train = np.random.uniform(x_ll,x_ul,(N_train,1))\n",
    "    t_train = np.random.uniform(0,0.1,(N_train,1))\n",
    "    \n",
    "    xt_train = np.hstack((x_train,t_train))\n",
    "    u_train = true_2D_4(xt_train)\n",
    "    \n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_train, u_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "        \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "    \n",
    "        self.lambda1 = Parameter(torch.tensor(0.0))\n",
    "        self.lambda1.requiresGrad = True\n",
    "        \n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = (xt - lbxt)/(ubxt - lbxt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    \n",
    "    def loss_PDE(self, xt_coll,f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_t = autograd.grad(u,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_tt = autograd.grad(u_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_tt[:,[0]]\n",
    "                \n",
    "        du_dt = u_x_t[:,[1]]\n",
    "        \n",
    "        f = du_dt - self.lambda1*d2u_dx2\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_coll,f_hat, xt_train, u_train):\n",
    "\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_train = self.loss_function(self.forward(xt_train),u_train)\n",
    "        \n",
    "        loss_val = loss_f + loss_train\n",
    "        \n",
    "        #print(self.iter,\"train_loss\",loss_train.cpu().detach().numpy(),\"F Loss\",(loss_f).cpu().detach().numpy())\n",
    "        return loss_val\n",
    "     \n",
    "    'callable for optimizer'                                    \n",
    "    \n",
    "    def test(self):\n",
    "        u_pred = self.forward(xt_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "               \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xt_coll,f_hat, xt_train, u_train,seed):    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_coll,f_hat, xt_train, u_train)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    lambda1_val.append(PINN.lambda1.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "    \n",
    "    xt_coll, xt_train, u_train = trainingdata(N_f,N_train,123)\n",
    "    \n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_train = torch.from_numpy(xt_train).float().to(device)\n",
    "    u_train = torch.from_numpy(u_train).float().to(device)\n",
    "    \n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        train_step(xt_coll,f_hat, xt_train, u_train,i)\n",
    "\n",
    "        loss_np = PINN.loss(xt_coll,f_hat, xt_train, u_train).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1],\"Lambda1\",lambda1_val[-1])\n",
    "\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_HT_swish\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 854.39606 Test MSE 857.706490676958 Test RE 0.4930131678103855 Lambda1 0.09474899\n",
      "1 Train Loss 815.4092 Test MSE 815.2977084481136 Test RE 0.48067029225326185 Lambda1 0.41177243\n",
      "2 Train Loss 569.86536 Test MSE 489.4307583379397 Test RE 0.37242154736706595 Lambda1 0.31319812\n",
      "3 Train Loss 339.29486 Test MSE 292.6940713330292 Test RE 0.28800241764044804 Lambda1 0.15482962\n",
      "4 Train Loss 279.4018 Test MSE 254.29136847908794 Test RE 0.2684447903506789 Lambda1 0.08685085\n",
      "5 Train Loss 222.85995 Test MSE 218.36653317049405 Test RE 0.24876095203549736 Lambda1 0.17398629\n",
      "6 Train Loss 200.88658 Test MSE 196.3678209366717 Test RE 0.23589803922232042 Lambda1 0.24664272\n",
      "7 Train Loss 180.05566 Test MSE 174.2907324419363 Test RE 0.22224209283513588 Lambda1 0.5842435\n",
      "8 Train Loss 87.79797 Test MSE 78.52404281834252 Test RE 0.14917309355530886 Lambda1 0.72599274\n",
      "9 Train Loss 55.05013 Test MSE 56.0173514010417 Test RE 0.12599417176934502 Lambda1 0.68802965\n",
      "10 Train Loss 49.34861 Test MSE 52.26076939135977 Test RE 0.12169621478413553 Lambda1 0.7975467\n",
      "11 Train Loss 42.76735 Test MSE 45.23133147935923 Test RE 0.11321627369588201 Lambda1 0.8875959\n",
      "12 Train Loss 39.69285 Test MSE 42.57351723044871 Test RE 0.1098395983577643 Lambda1 0.8889945\n",
      "13 Train Loss 37.656796 Test MSE 40.97400120610647 Test RE 0.10775647067072798 Lambda1 0.8822803\n",
      "14 Train Loss 36.395855 Test MSE 39.45815035080357 Test RE 0.10574443772745988 Lambda1 0.90982896\n",
      "15 Train Loss 36.150185 Test MSE 39.380270682603204 Test RE 0.10564003078937584 Lambda1 0.89022166\n",
      "16 Train Loss 35.227734 Test MSE 39.502596697006304 Test RE 0.10580397715168455 Lambda1 0.88436335\n",
      "17 Train Loss 34.92041 Test MSE 39.674772891331834 Test RE 0.10603430529084504 Lambda1 0.8824922\n",
      "18 Train Loss 34.780678 Test MSE 39.59233867638637 Test RE 0.10592409168248834 Lambda1 0.8951971\n",
      "19 Train Loss 34.4253 Test MSE 39.09631709910886 Test RE 0.10525848015345626 Lambda1 0.9226645\n",
      "20 Train Loss 34.348778 Test MSE 39.11327264233964 Test RE 0.10528130226795905 Lambda1 0.91991055\n",
      "21 Train Loss 34.307007 Test MSE 39.10657655383069 Test RE 0.10527228994240238 Lambda1 0.92012036\n",
      "22 Train Loss 34.246235 Test MSE 39.083309280969345 Test RE 0.10524096831124216 Lambda1 0.9117767\n",
      "23 Train Loss 34.141727 Test MSE 38.89129177567024 Test RE 0.1049821239287172 Lambda1 0.9050187\n",
      "24 Train Loss 33.994267 Test MSE 38.73976269517021 Test RE 0.10477740753384165 Lambda1 0.9002847\n",
      "25 Train Loss 33.88385 Test MSE 38.66857217667281 Test RE 0.1046810906303343 Lambda1 0.90298176\n",
      "26 Train Loss 33.7398 Test MSE 38.157207234265705 Test RE 0.10398661974812277 Lambda1 0.940328\n",
      "27 Train Loss 33.640972 Test MSE 37.83021717143129 Test RE 0.10354010185113413 Lambda1 0.9816731\n",
      "28 Train Loss 33.44736 Test MSE 37.6234038918411 Test RE 0.10325669329408374 Lambda1 0.973985\n",
      "29 Train Loss 33.049126 Test MSE 37.07837850123209 Test RE 0.10250605914986173 Lambda1 1.0288398\n",
      "30 Train Loss 32.75448 Test MSE 36.53714121254493 Test RE 0.10175516257060027 Lambda1 1.0512118\n",
      "31 Train Loss 32.13823 Test MSE 35.572720250978804 Test RE 0.10040323571759419 Lambda1 1.0568274\n",
      "32 Train Loss 31.513294 Test MSE 34.77784470765817 Test RE 0.09927513871926691 Lambda1 0.9597662\n",
      "33 Train Loss 31.363527 Test MSE 34.65691214392282 Test RE 0.09910238431118262 Lambda1 0.9330345\n",
      "34 Train Loss 31.325886 Test MSE 34.59173065905697 Test RE 0.09900914633514359 Lambda1 0.93590754\n",
      "35 Train Loss 30.997791 Test MSE 34.38540687416378 Test RE 0.098713432685868 Lambda1 0.97311443\n",
      "36 Train Loss 30.90031 Test MSE 34.200874357829555 Test RE 0.09844819890157001 Lambda1 0.9976391\n",
      "37 Train Loss 30.810629 Test MSE 33.9964724691942 Test RE 0.09815356967531515 Lambda1 0.9960408\n",
      "38 Train Loss 30.686642 Test MSE 33.76629490841986 Test RE 0.09782072453864485 Lambda1 0.9981442\n",
      "39 Train Loss 30.516045 Test MSE 33.779374544221405 Test RE 0.09783966851186042 Lambda1 1.0272031\n",
      "40 Train Loss 30.441467 Test MSE 33.63847384629911 Test RE 0.09763540061841285 Lambda1 1.0337472\n",
      "41 Train Loss 30.306465 Test MSE 33.493557269318806 Test RE 0.0974248640212203 Lambda1 1.0347207\n",
      "42 Train Loss 30.238392 Test MSE 33.51015961229738 Test RE 0.09744900718108891 Lambda1 1.0042752\n",
      "43 Train Loss 30.188307 Test MSE 33.47534139685021 Test RE 0.0973983675782665 Lambda1 0.9586319\n",
      "44 Train Loss 30.110928 Test MSE 33.41826258115325 Test RE 0.0973152951570557 Lambda1 0.95502913\n",
      "45 Train Loss 29.999048 Test MSE 33.35622565734002 Test RE 0.09722492621665219 Lambda1 0.9801772\n",
      "46 Train Loss 29.93208 Test MSE 33.313043409905816 Test RE 0.09716197319357187 Lambda1 0.9691583\n",
      "47 Train Loss 29.919924 Test MSE 33.30054592344515 Test RE 0.09714374618356672 Lambda1 0.95584345\n",
      "48 Train Loss 29.916643 Test MSE 33.30179816347807 Test RE 0.09714557267230668 Lambda1 0.9472047\n",
      "49 Train Loss 29.909653 Test MSE 33.31180604645914 Test RE 0.09716016870832911 Lambda1 0.9497947\n",
      "50 Train Loss 29.860851 Test MSE 33.32583236187014 Test RE 0.09718062175348152 Lambda1 0.94135255\n",
      "51 Train Loss 29.843287 Test MSE 33.30328843117233 Test RE 0.09714774629801091 Lambda1 0.9494901\n",
      "52 Train Loss 29.834433 Test MSE 33.301031703177976 Test RE 0.09714445473487808 Lambda1 0.95409435\n",
      "53 Train Loss 29.81303 Test MSE 33.29696490502036 Test RE 0.09713852280226691 Lambda1 0.9456559\n",
      "54 Train Loss 29.79048 Test MSE 33.31060911962975 Test RE 0.09715842316116231 Lambda1 0.93759596\n",
      "55 Train Loss 29.780544 Test MSE 33.31414479096605 Test RE 0.09716357934331997 Lambda1 0.9370245\n",
      "56 Train Loss 29.753075 Test MSE 33.34084724932718 Test RE 0.09720251155603522 Lambda1 0.9271489\n",
      "57 Train Loss 29.698662 Test MSE 33.31408675319445 Test RE 0.09716349470719747 Lambda1 0.94467825\n",
      "58 Train Loss 29.681234 Test MSE 33.3225044840002 Test RE 0.09717576946185488 Lambda1 0.9460151\n",
      "59 Train Loss 29.672152 Test MSE 33.31937113236532 Test RE 0.09717120058237012 Lambda1 0.94222915\n",
      "60 Train Loss 29.663696 Test MSE 33.30414049233411 Test RE 0.09714898904754148 Lambda1 0.94296664\n",
      "61 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "62 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "63 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "64 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "65 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "66 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "67 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "68 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "69 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "70 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "71 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "72 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "73 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "74 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "75 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "76 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "78 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "79 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "80 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "81 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "82 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "83 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "84 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "85 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "86 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "87 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "88 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "89 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "90 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "91 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "92 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "93 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "94 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "95 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "96 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "97 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "98 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "99 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "100 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "101 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "102 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "103 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "104 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "105 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "106 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "107 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "108 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "109 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "110 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "111 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "112 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "113 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "114 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "115 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "116 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "117 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "118 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "119 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "120 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "121 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "122 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "123 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "124 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "125 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "126 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "127 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "128 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "129 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "130 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "131 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "132 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "133 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "134 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "135 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "136 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "137 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "138 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "139 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "140 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "141 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "142 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "143 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "144 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "145 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "146 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "147 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "148 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "149 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "150 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "151 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "152 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "153 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "154 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "155 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "156 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "157 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "158 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "159 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "161 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "162 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "163 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "164 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "165 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "166 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "167 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "168 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "169 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "170 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "171 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "172 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "173 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "174 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "175 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "176 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "177 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "178 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "179 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "180 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "181 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "182 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "183 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "184 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "185 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "186 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "187 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "188 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "189 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "190 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "191 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "192 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "193 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "194 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "195 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "196 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "197 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "198 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "199 Train Loss 29.660843 Test MSE 33.31379060260357 Test RE 0.09716306283147874 Lambda1 0.93747133\n",
      "Training time: 542.57\n",
      "Training time: 542.57\n",
      "inv_HT_swish\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 854.52234 Test MSE 857.6668799961642 Test RE 0.4930017834889991 Lambda1 0.004784368\n",
      "1 Train Loss 853.1014 Test MSE 854.2448269666288 Test RE 0.49201727278109914 Lambda1 1.4808812\n",
      "2 Train Loss 781.85376 Test MSE 766.6010614941813 Test RE 0.46609439327997865 Lambda1 1.8271803\n",
      "3 Train Loss 610.46545 Test MSE 603.1185274380429 Test RE 0.41341906992186767 Lambda1 1.8387321\n",
      "4 Train Loss 537.0442 Test MSE 536.8183772059434 Test RE 0.39003435125711183 Lambda1 1.9535911\n",
      "5 Train Loss 429.44092 Test MSE 393.0965749875176 Test RE 0.3337634689381237 Lambda1 2.0031607\n",
      "6 Train Loss 298.92322 Test MSE 246.18773107878758 Test RE 0.26413282329541327 Lambda1 1.9819894\n",
      "7 Train Loss 172.97604 Test MSE 137.14091036437415 Test RE 0.197139061472634 Lambda1 1.8793253\n",
      "8 Train Loss 86.67529 Test MSE 62.282963882709666 Test RE 0.1328537465580995 Lambda1 1.7743388\n",
      "9 Train Loss 55.603382 Test MSE 43.815625641303455 Test RE 0.1114303973835787 Lambda1 1.7469107\n",
      "10 Train Loss 41.535244 Test MSE 41.820063898559205 Test RE 0.10886330541565198 Lambda1 1.6995522\n",
      "11 Train Loss 38.129635 Test MSE 39.97349308247891 Test RE 0.10643273466782785 Lambda1 1.6358181\n",
      "12 Train Loss 35.79267 Test MSE 37.79872132982769 Test RE 0.1034969913176236 Lambda1 1.4929261\n",
      "13 Train Loss 34.271763 Test MSE 36.184003092366375 Test RE 0.10126222751818599 Lambda1 1.316758\n",
      "14 Train Loss 32.971878 Test MSE 34.84082853100366 Test RE 0.09936499332984983 Lambda1 1.121493\n",
      "15 Train Loss 32.391262 Test MSE 34.677546164495716 Test RE 0.09913188169324451 Lambda1 1.134216\n",
      "16 Train Loss 31.6601 Test MSE 34.11042559511917 Test RE 0.09831793303787079 Lambda1 1.0703754\n",
      "17 Train Loss 31.403996 Test MSE 33.76721480597869 Test RE 0.0978220569980262 Lambda1 0.99876565\n",
      "18 Train Loss 30.77708 Test MSE 33.64932895239454 Test RE 0.09765115277691515 Lambda1 0.9714035\n",
      "19 Train Loss 30.739702 Test MSE 33.65378652302441 Test RE 0.09765762055070648 Lambda1 0.9617746\n",
      "20 Train Loss 30.654406 Test MSE 33.66488645995809 Test RE 0.09767372429672254 Lambda1 0.9279819\n",
      "21 Train Loss 30.61954 Test MSE 33.700348111483 Test RE 0.09772515414373283 Lambda1 0.89880323\n",
      "22 Train Loss 30.57189 Test MSE 33.662092787654316 Test RE 0.09766967149767464 Lambda1 0.8992867\n",
      "23 Train Loss 30.555595 Test MSE 33.57079783131809 Test RE 0.0975371366246751 Lambda1 0.9282204\n",
      "24 Train Loss 30.528673 Test MSE 33.579817828868364 Test RE 0.09755023916768513 Lambda1 0.9216024\n",
      "25 Train Loss 30.51013 Test MSE 33.53135710685381 Test RE 0.09747982392824654 Lambda1 0.9208633\n",
      "26 Train Loss 30.39923 Test MSE 33.622518320795244 Test RE 0.09761224247955354 Lambda1 0.90723675\n",
      "27 Train Loss 30.379072 Test MSE 33.653297827559456 Test RE 0.09765691149216553 Lambda1 0.8995368\n",
      "28 Train Loss 30.259031 Test MSE 33.61314854038949 Test RE 0.09759864044955868 Lambda1 0.9126405\n",
      "29 Train Loss 30.183445 Test MSE 33.58251323000492 Test RE 0.0975541541941258 Lambda1 0.9445199\n",
      "30 Train Loss 30.180597 Test MSE 33.575696948227275 Test RE 0.09754425335162199 Lambda1 0.95027554\n",
      "31 Train Loss 30.166782 Test MSE 33.52371037433178 Test RE 0.09746870829342355 Lambda1 0.94988716\n",
      "32 Train Loss 30.13521 Test MSE 33.50928958893681 Test RE 0.09744774213991923 Lambda1 0.95766515\n",
      "33 Train Loss 30.087664 Test MSE 33.41607311380395 Test RE 0.09731210719731603 Lambda1 0.9601047\n",
      "34 Train Loss 30.054178 Test MSE 33.38485651441795 Test RE 0.09726664310525444 Lambda1 0.9635657\n",
      "35 Train Loss 29.985886 Test MSE 33.365665121067536 Test RE 0.09723868206323005 Lambda1 0.94915783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 Train Loss 29.928612 Test MSE 33.422668215921554 Test RE 0.09732170963652381 Lambda1 0.9389247\n",
      "37 Train Loss 29.908829 Test MSE 33.39254459431444 Test RE 0.09727784205523946 Lambda1 0.9455327\n",
      "38 Train Loss 29.892931 Test MSE 33.42682478351306 Test RE 0.09732776109365698 Lambda1 0.95105153\n",
      "39 Train Loss 29.871616 Test MSE 33.3928826603178 Test RE 0.0972783344742576 Lambda1 0.96341825\n",
      "40 Train Loss 29.840893 Test MSE 33.406255271157676 Test RE 0.09729781070684738 Lambda1 0.9625426\n",
      "41 Train Loss 29.812746 Test MSE 33.415504500739075 Test RE 0.09731127925486564 Lambda1 0.944656\n",
      "42 Train Loss 29.799517 Test MSE 33.381118138089604 Test RE 0.09726119708070892 Lambda1 0.94193804\n",
      "43 Train Loss 29.784088 Test MSE 33.383532906796525 Test RE 0.09726471492344306 Lambda1 0.9408504\n",
      "44 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "45 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "46 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "47 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "48 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "49 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "50 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "51 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "52 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "53 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "54 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "55 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "56 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "57 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "58 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "59 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "60 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "61 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "62 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "63 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "64 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "65 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "66 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "67 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "68 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "69 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "70 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "71 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "72 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "73 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "74 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "75 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "76 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "77 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "78 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "79 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "80 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "81 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "82 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "83 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "84 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "85 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "86 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "87 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "88 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "89 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "90 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "91 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "92 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "93 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "94 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "95 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "96 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "97 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "98 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "99 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "100 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "101 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "102 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "103 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "104 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "105 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "106 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "107 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "108 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "109 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "110 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "111 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "112 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "113 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "114 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "115 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "116 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "117 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "118 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "119 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "120 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "122 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "123 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "124 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "125 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "126 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "127 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "128 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "129 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "130 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "131 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "132 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "133 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "134 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "135 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "136 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "137 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "138 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "139 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "140 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "141 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "142 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "143 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "144 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "145 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "146 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "147 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "148 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "149 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "150 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "151 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "152 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "153 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "154 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "155 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "156 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "157 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "158 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "159 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "160 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "161 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "162 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "163 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "164 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "165 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "166 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "167 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "168 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "169 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "170 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "171 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "172 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "173 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "174 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "175 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "176 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "177 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "178 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "179 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "180 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "181 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "182 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "183 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "184 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "185 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "186 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "187 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "188 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "189 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "190 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "191 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "192 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "193 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "194 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "195 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "196 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "197 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "198 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "199 Train Loss 29.779665 Test MSE 33.39262363422588 Test RE 0.09727795718314548 Lambda1 0.9297644\n",
      "Training time: 481.19\n",
      "Training time: 481.19\n",
      "inv_HT_swish\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 854.7319 Test MSE 858.0902776154883 Test RE 0.4931234566184162 Lambda1 2.5573274e-06\n",
      "1 Train Loss 854.7069 Test MSE 858.0658091829024 Test RE 0.493116425863969 Lambda1 6.574123e-05\n",
      "2 Train Loss 854.4695 Test MSE 857.6152799623939 Test RE 0.4929869529691878 Lambda1 0.0021232571\n",
      "3 Train Loss 837.5253 Test MSE 803.6686194273974 Test RE 0.4772299332736064 Lambda1 0.07005347\n",
      "4 Train Loss 453.28 Test MSE 407.8675514922141 Test RE 0.3399763825096236 Lambda1 0.008603565\n",
      "5 Train Loss 283.8557 Test MSE 291.11055037205415 Test RE 0.2872222918703665 Lambda1 0.00042917763\n",
      "6 Train Loss 279.01135 Test MSE 287.08752001945965 Test RE 0.2852307392248983 Lambda1 -0.00093697256\n",
      "7 Train Loss 274.34326 Test MSE 281.1230409750456 Test RE 0.28225223636765784 Lambda1 0.002254108\n",
      "8 Train Loss 253.06113 Test MSE 238.0229252866726 Test RE 0.25971591586520326 Lambda1 0.082826085\n",
      "9 Train Loss 184.73083 Test MSE 173.81539262993806 Test RE 0.22193882759728722 Lambda1 0.27905118\n",
      "10 Train Loss 157.89767 Test MSE 147.78132550747108 Test RE 0.20464396863218554 Lambda1 0.4402662\n",
      "11 Train Loss 104.0491 Test MSE 74.37041092182642 Test RE 0.14517413973399096 Lambda1 0.53462917\n",
      "12 Train Loss 68.88437 Test MSE 63.25401837390963 Test RE 0.13388540320342257 Lambda1 0.58343804\n",
      "13 Train Loss 50.352352 Test MSE 47.08261050235864 Test RE 0.11550996115704823 Lambda1 0.72099817\n",
      "14 Train Loss 42.404156 Test MSE 43.47913946195585 Test RE 0.11100170268784106 Lambda1 0.6680749\n",
      "15 Train Loss 38.639843 Test MSE 39.682464451743186 Test RE 0.10604458297716282 Lambda1 0.8281839\n",
      "16 Train Loss 35.341187 Test MSE 38.27424946805965 Test RE 0.10414598030310601 Lambda1 0.8563114\n",
      "17 Train Loss 34.816967 Test MSE 37.04834827321187 Test RE 0.10246454029182582 Lambda1 0.91878796\n",
      "18 Train Loss 33.138035 Test MSE 36.59846351076135 Test RE 0.10184051742098818 Lambda1 0.915272\n",
      "19 Train Loss 32.07191 Test MSE 35.34584092586115 Test RE 0.10008254256124627 Lambda1 1.0089512\n",
      "20 Train Loss 31.853199 Test MSE 34.84190282460939 Test RE 0.09936652524454034 Lambda1 1.0532981\n",
      "21 Train Loss 31.143398 Test MSE 33.84869795672487 Test RE 0.09794001233831257 Lambda1 1.0219446\n",
      "22 Train Loss 30.76681 Test MSE 33.68478774122078 Test RE 0.0977025903537668 Lambda1 1.0354675\n",
      "23 Train Loss 30.607353 Test MSE 33.570104528083306 Test RE 0.0975361294522836 Lambda1 1.0113698\n",
      "24 Train Loss 30.433525 Test MSE 33.64977379921693 Test RE 0.09765179825281019 Lambda1 0.97113127\n",
      "25 Train Loss 30.303051 Test MSE 33.53440676306609 Test RE 0.09748425669233987 Lambda1 0.9493363\n",
      "26 Train Loss 30.171898 Test MSE 33.613215107129186 Test RE 0.09759873709061073 Lambda1 0.915158\n",
      "27 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "28 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "29 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "30 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "31 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "32 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "33 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "34 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "35 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "36 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "37 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "38 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "39 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "40 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "41 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "42 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "43 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "44 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "45 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "46 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "47 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "48 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "49 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "50 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "51 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "52 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "53 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "54 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "55 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "56 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "57 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "58 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "59 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "60 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "61 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "62 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "63 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "64 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "65 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "66 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "67 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "68 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "69 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "70 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "71 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "72 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "73 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "74 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "75 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "76 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "77 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "78 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "79 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "80 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "81 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "82 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "83 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "84 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "85 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "87 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "88 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "89 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "90 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "91 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "92 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "93 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "94 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "95 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "96 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "97 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "98 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "99 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "100 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "101 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "102 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "103 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "104 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "105 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "106 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "107 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "108 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "109 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "110 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "111 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "112 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "113 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "114 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "115 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "116 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "117 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "118 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "119 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "120 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "121 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "122 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "123 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "124 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "125 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "126 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "127 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "128 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "129 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "130 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "131 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "132 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "133 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "134 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "135 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "136 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "137 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "138 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "139 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "140 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "141 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "142 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "143 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "144 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "145 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "146 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "147 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "148 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "149 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "150 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "151 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "152 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "153 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "154 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "155 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "156 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "157 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "158 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "159 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "160 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "161 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "162 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "163 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "164 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "165 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "166 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "167 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "168 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "169 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "170 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "172 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "173 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "174 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "175 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "176 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "177 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "178 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "179 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "180 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "181 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "182 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "183 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "184 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "185 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "186 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "187 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "188 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "189 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "190 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "191 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "192 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "193 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "194 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "195 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "196 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "197 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "198 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "199 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "Training time: 464.40\n",
      "Training time: 464.40\n",
      "inv_HT_swish\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 854.4453 Test MSE 857.3725812573874 Test RE 0.49291719222454716 Lambda1 0.13022149\n",
      "1 Train Loss 814.71783 Test MSE 810.3849248487703 Test RE 0.4792199035116814 Lambda1 1.1076999\n",
      "2 Train Loss 544.5475 Test MSE 492.7888433372412 Test RE 0.37369699371219256 Lambda1 1.1078966\n",
      "3 Train Loss 242.54202 Test MSE 204.73720250661853 Test RE 0.24087268463226458 Lambda1 0.7231295\n",
      "4 Train Loss 125.60567 Test MSE 112.73237133507995 Test RE 0.1787365998106083 Lambda1 0.6039553\n",
      "5 Train Loss 80.397156 Test MSE 71.51038900037327 Test RE 0.142355332771247 Lambda1 0.570614\n",
      "6 Train Loss 59.95739 Test MSE 61.34623970012682 Test RE 0.13185091386040598 Lambda1 0.5656316\n",
      "7 Train Loss 50.631226 Test MSE 52.48501269642614 Test RE 0.12195702562268872 Lambda1 0.7034853\n",
      "8 Train Loss 46.58948 Test MSE 48.33219358245246 Test RE 0.11703275369119379 Lambda1 0.7919151\n",
      "9 Train Loss 44.192383 Test MSE 45.21325601784814 Test RE 0.11319364954551885 Lambda1 0.8630394\n",
      "10 Train Loss 40.259094 Test MSE 40.30223557462394 Test RE 0.10686949058569173 Lambda1 1.0025092\n",
      "11 Train Loss 37.627808 Test MSE 38.85736331242072 Test RE 0.10493632113907479 Lambda1 0.98511815\n",
      "12 Train Loss 36.427044 Test MSE 38.03943874169503 Test RE 0.10382602346444922 Lambda1 0.893071\n",
      "13 Train Loss 34.632324 Test MSE 35.79453322791832 Test RE 0.10071578042999063 Lambda1 0.89209586\n",
      "14 Train Loss 33.355618 Test MSE 34.3124987706932 Test RE 0.09860872506625183 Lambda1 1.040915\n",
      "15 Train Loss 32.405598 Test MSE 34.14085222453779 Test RE 0.09836177324882257 Lambda1 0.9870859\n",
      "16 Train Loss 31.647072 Test MSE 34.2885774411405 Test RE 0.09857434600378569 Lambda1 0.8995388\n",
      "17 Train Loss 30.586124 Test MSE 33.740740192030856 Test RE 0.09778370161350534 Lambda1 0.93124706\n",
      "18 Train Loss 30.427816 Test MSE 33.549622920601756 Test RE 0.09750637080920341 Lambda1 0.9685342\n",
      "19 Train Loss 30.089687 Test MSE 33.464208445263374 Test RE 0.09738217026055278 Lambda1 0.9906578\n",
      "20 Train Loss 30.009705 Test MSE 33.43835818246069 Test RE 0.09734455035040503 Lambda1 1.0085672\n",
      "21 Train Loss 29.914526 Test MSE 33.47831928408516 Test RE 0.09740269964619101 Lambda1 0.9797295\n",
      "22 Train Loss 29.8584 Test MSE 33.40189223435181 Test RE 0.09729145669039665 Lambda1 0.993206\n",
      "23 Train Loss 29.81821 Test MSE 33.356439020119296 Test RE 0.09722523716531158 Lambda1 0.99476564\n",
      "24 Train Loss 29.75864 Test MSE 33.35188029396517 Test RE 0.0972185931950758 Lambda1 0.971791\n",
      "25 Train Loss 29.725788 Test MSE 33.35208786578083 Test RE 0.0972188957238737 Lambda1 0.9551825\n",
      "26 Train Loss 29.681057 Test MSE 33.28532412549913 Test RE 0.09712154126989657 Lambda1 0.95019776\n",
      "27 Train Loss 29.668676 Test MSE 33.28035545061124 Test RE 0.09711429207845905 Lambda1 0.93437064\n",
      "28 Train Loss 29.650047 Test MSE 33.26430309477433 Test RE 0.09709086833225783 Lambda1 0.9441622\n",
      "29 Train Loss 29.644268 Test MSE 33.276267263556356 Test RE 0.09710832709431597 Lambda1 0.9360223\n",
      "30 Train Loss 29.635214 Test MSE 33.277857539795875 Test RE 0.0971106474750698 Lambda1 0.9335077\n",
      "31 Train Loss 29.609087 Test MSE 33.31360890739398 Test RE 0.09716279786482653 Lambda1 0.92638874\n",
      "32 Train Loss 29.60052 Test MSE 33.2953752637161 Test RE 0.09713620401357903 Lambda1 0.93545675\n",
      "33 Train Loss 29.590616 Test MSE 33.29699920348822 Test RE 0.09713857283237703 Lambda1 0.93604225\n",
      "34 Train Loss 29.584316 Test MSE 33.29115823919065 Test RE 0.0971300524276231 Lambda1 0.93591386\n",
      "35 Train Loss 29.579706 Test MSE 33.28884712802578 Test RE 0.0971266809281544 Lambda1 0.9375729\n",
      "36 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "37 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "38 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "39 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "40 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "41 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "42 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "43 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "44 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "45 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "46 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "47 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "49 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "50 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "51 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "52 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "53 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "54 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "55 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "56 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "57 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "58 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "59 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "60 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "61 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "62 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "63 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "64 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "65 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "66 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "67 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "68 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "69 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "70 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "71 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "72 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "73 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "74 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "75 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "76 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "77 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "78 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "79 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "80 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "81 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "82 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "83 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "84 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "85 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "86 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "87 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "88 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "89 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "90 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "91 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "92 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "93 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "94 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "95 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "96 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "97 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "98 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "99 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "100 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "101 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "102 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "103 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "104 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "105 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "106 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "107 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "108 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "109 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "110 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "111 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "112 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "113 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "114 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "115 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "116 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "117 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "118 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "119 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "120 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "121 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "122 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "123 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "124 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "125 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "126 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "127 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "128 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "129 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "130 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "131 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "133 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "134 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "135 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "136 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "137 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "138 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "139 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "140 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "141 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "142 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "143 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "144 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "145 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "146 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "147 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "148 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "149 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "150 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "151 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "152 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "153 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "154 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "155 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "156 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "157 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "158 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "159 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "160 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "161 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "162 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "163 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "164 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "165 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "166 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "167 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "168 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "169 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "170 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "171 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "172 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "173 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "174 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "175 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "176 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "177 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "178 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "179 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "180 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "181 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "182 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "183 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "184 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "185 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "186 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "187 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "188 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "189 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "190 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "191 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "192 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "193 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "194 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "195 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "196 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "197 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "198 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "199 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "Training time: 481.86\n",
      "Training time: 481.86\n",
      "inv_HT_swish\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 854.52423 Test MSE 857.5841518660778 Test RE 0.4929780061343056 Lambda1 0.08285925\n",
      "1 Train Loss 835.7833 Test MSE 818.407886529098 Test RE 0.4815862442794709 Lambda1 2.644427\n",
      "2 Train Loss 690.22925 Test MSE 679.6813236776649 Test RE 0.4388760069277389 Lambda1 1.8238686\n",
      "3 Train Loss 593.3642 Test MSE 580.5273319311887 Test RE 0.4056023909950165 Lambda1 1.2864742\n",
      "4 Train Loss 528.72687 Test MSE 520.237448590477 Test RE 0.38396353038266196 Lambda1 1.4978979\n",
      "5 Train Loss 407.7292 Test MSE 366.5181612966768 Test RE 0.32228264570247134 Lambda1 1.5851254\n",
      "6 Train Loss 278.76425 Test MSE 247.3343505773599 Test RE 0.2647472081399292 Lambda1 1.5417815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Train Loss 82.02294 Test MSE 59.90091391136994 Test RE 0.13028844322855668 Lambda1 1.3507178\n",
      "8 Train Loss 47.9648 Test MSE 43.588472386768224 Test RE 0.11114117786072876 Lambda1 1.1889246\n",
      "9 Train Loss 38.95297 Test MSE 38.68958229985314 Test RE 0.10470952540069893 Lambda1 1.0587195\n",
      "10 Train Loss 36.743782 Test MSE 38.411225354308904 Test RE 0.10433217268577678 Lambda1 1.0495143\n",
      "11 Train Loss 33.818024 Test MSE 37.05018374507667 Test RE 0.10246707844076214 Lambda1 0.93152916\n",
      "12 Train Loss 32.85012 Test MSE 36.40120947078927 Test RE 0.10156570268366655 Lambda1 0.854919\n",
      "13 Train Loss 32.220573 Test MSE 35.846240686896934 Test RE 0.10078849932362455 Lambda1 0.9041216\n",
      "14 Train Loss 31.927963 Test MSE 35.59912696777377 Test RE 0.10044049499852371 Lambda1 0.9510107\n",
      "15 Train Loss 31.668736 Test MSE 35.441233000455114 Test RE 0.10021750396446705 Lambda1 0.9981032\n",
      "16 Train Loss 31.374823 Test MSE 35.258638966453596 Test RE 0.09995900916823292 Lambda1 1.0470092\n",
      "17 Train Loss 30.61119 Test MSE 34.158736583604615 Test RE 0.09838753281310018 Lambda1 0.97962457\n",
      "18 Train Loss 30.44341 Test MSE 33.61608804678712 Test RE 0.09760290790989017 Lambda1 0.94812053\n",
      "19 Train Loss 30.270239 Test MSE 33.52330222440612 Test RE 0.0974681149526703 Lambda1 0.9695188\n",
      "20 Train Loss 29.98366 Test MSE 33.29473269371424 Test RE 0.09713526668952954 Lambda1 0.9993457\n",
      "21 Train Loss 29.946545 Test MSE 33.26821422092158 Test RE 0.09709657600440305 Lambda1 0.99057245\n",
      "22 Train Loss 29.878395 Test MSE 33.329182075138306 Test RE 0.09718550563807532 Lambda1 0.93001205\n",
      "23 Train Loss 29.78924 Test MSE 33.42355107648925 Test RE 0.09732299500566108 Lambda1 0.8963131\n",
      "24 Train Loss 29.635513 Test MSE 33.27852245346046 Test RE 0.09711161763779542 Lambda1 0.943518\n",
      "25 Train Loss 29.597378 Test MSE 33.276265869262495 Test RE 0.09710832505986984 Lambda1 0.9426607\n",
      "26 Train Loss 29.573826 Test MSE 33.2700495603108 Test RE 0.09709925427729711 Lambda1 0.94415146\n",
      "27 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "28 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "29 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "30 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "31 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "32 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "33 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "34 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "35 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "36 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "37 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "38 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "39 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "40 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "41 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "42 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "43 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "44 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "45 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "46 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "47 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "48 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "49 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "50 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "51 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "52 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "53 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "54 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "55 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "56 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "57 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "58 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "59 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "60 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "61 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "62 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "63 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "64 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "65 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "66 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "67 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "68 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "69 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "70 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "71 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "72 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "73 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "74 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "75 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "76 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "77 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "78 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "79 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "80 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "81 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "82 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "83 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "84 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "85 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "86 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "87 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "88 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "89 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "90 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "91 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "93 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "94 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "95 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "96 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "97 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "98 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "99 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "100 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "101 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "102 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "103 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "104 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "105 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "106 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "107 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "108 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "109 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "110 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "111 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "112 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "113 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "114 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "115 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "116 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "117 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "118 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "119 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "120 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "121 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "122 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "123 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "124 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "125 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "126 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "127 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "128 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "129 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "130 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "131 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "132 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "133 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "134 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "135 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "136 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "137 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "138 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "139 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "140 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "141 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "142 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "143 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "144 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "145 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "146 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "147 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "148 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "149 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "150 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "151 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "152 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "153 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "154 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "155 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "156 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "157 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "158 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "159 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "160 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "161 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "162 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "163 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "164 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "165 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "166 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "167 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "168 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "169 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "170 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "171 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "172 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "173 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "174 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "175 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "177 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "178 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "179 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "180 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "181 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "182 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "183 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "184 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "185 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "186 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "187 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "188 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "189 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "190 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "191 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "192 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "193 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "194 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "195 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "196 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "197 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "198 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "199 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "Training time: 404.94\n",
      "Training time: 404.94\n",
      "inv_HT_swish\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 854.52954 Test MSE 857.6981638484865 Test RE 0.49301077465719684 Lambda1 -0.002593048\n",
      "1 Train Loss 853.3049 Test MSE 856.5002934031263 Test RE 0.4926663823045682 Lambda1 -0.8611491\n",
      "2 Train Loss 791.51965 Test MSE 783.5114542793028 Test RE 0.4712071216207608 Lambda1 -0.8088548\n",
      "3 Train Loss 614.24493 Test MSE 577.9912388839512 Test RE 0.4047154635039061 Lambda1 -1.3520828\n",
      "4 Train Loss 491.2816 Test MSE 474.8374278602883 Test RE 0.36682729433317046 Lambda1 -1.2438884\n",
      "5 Train Loss 431.72986 Test MSE 401.6905795191931 Test RE 0.3373921657151305 Lambda1 -1.2602311\n",
      "6 Train Loss 387.7212 Test MSE 370.7232060519997 Test RE 0.32412613963867953 Lambda1 -1.4205232\n",
      "7 Train Loss 349.93814 Test MSE 336.01432571026294 Test RE 0.30858020798958924 Lambda1 -1.6664151\n",
      "8 Train Loss 315.6512 Test MSE 292.64080277743733 Test RE 0.2879762090964857 Lambda1 -1.8961501\n",
      "9 Train Loss 261.29736 Test MSE 250.68524957964513 Test RE 0.26653457932024754 Lambda1 -2.0936399\n",
      "10 Train Loss 230.3267 Test MSE 220.41225819526687 Test RE 0.24992347033213005 Lambda1 -2.1656847\n",
      "11 Train Loss 202.05214 Test MSE 187.96936993583873 Test RE 0.2307983573319403 Lambda1 -2.2031586\n",
      "12 Train Loss 180.76668 Test MSE 172.97535847981447 Test RE 0.22140187285781593 Lambda1 -2.2498155\n",
      "13 Train Loss 159.93031 Test MSE 149.3663535264908 Test RE 0.2057384956591983 Lambda1 -2.3681638\n",
      "14 Train Loss 144.3582 Test MSE 137.07144928237082 Test RE 0.19708913024920596 Lambda1 -2.4630451\n",
      "15 Train Loss 126.50418 Test MSE 119.60207541018289 Test RE 0.1841020093512345 Lambda1 -2.6291575\n",
      "16 Train Loss 116.15647 Test MSE 113.06432054903453 Test RE 0.17899955827038463 Lambda1 -2.7801838\n",
      "17 Train Loss 108.15798 Test MSE 102.08181595609744 Test RE 0.1700839621248316 Lambda1 -2.9154289\n",
      "18 Train Loss 100.45042 Test MSE 97.84556822220472 Test RE 0.166517449565276 Lambda1 -2.897602\n",
      "19 Train Loss 96.84737 Test MSE 97.00384877084151 Test RE 0.165799666853381 Lambda1 -2.914555\n",
      "20 Train Loss 94.689644 Test MSE 94.83196276524764 Test RE 0.16393305802016186 Lambda1 -3.00714\n",
      "21 Train Loss 93.04699 Test MSE 95.15617445164666 Test RE 0.16421304623642166 Lambda1 -2.996988\n",
      "22 Train Loss 91.71983 Test MSE 94.2282486200448 Test RE 0.16341041397276426 Lambda1 -3.0708716\n",
      "23 Train Loss 89.48581 Test MSE 93.13647613876522 Test RE 0.1624609811429365 Lambda1 -3.221755\n",
      "24 Train Loss 88.72845 Test MSE 92.43232638372592 Test RE 0.1618456803080507 Lambda1 -3.2579315\n",
      "25 Train Loss 87.93017 Test MSE 92.2515076350448 Test RE 0.16168729924873704 Lambda1 -3.2495008\n",
      "26 Train Loss 87.33929 Test MSE 91.69435182911762 Test RE 0.16119830210419958 Lambda1 -3.3153155\n",
      "27 Train Loss 86.21158 Test MSE 90.66790099831886 Test RE 0.16029351465224048 Lambda1 -3.3916097\n",
      "28 Train Loss 85.144966 Test MSE 89.67321592520341 Test RE 0.15941182844391322 Lambda1 -3.463587\n",
      "29 Train Loss 83.99319 Test MSE 88.12394989186043 Test RE 0.15802876571738753 Lambda1 -3.5493171\n",
      "30 Train Loss 82.83303 Test MSE 86.77000265140461 Test RE 0.15681007985958856 Lambda1 -3.6260133\n",
      "31 Train Loss 81.36854 Test MSE 84.47497786327065 Test RE 0.15472240731613976 Lambda1 -3.7348943\n",
      "32 Train Loss 79.23644 Test MSE 82.37151157686246 Test RE 0.15278393402830037 Lambda1 -3.83617\n",
      "33 Train Loss 79.023994 Test MSE 82.192920904793 Test RE 0.15261821780765575 Lambda1 -3.8544686\n",
      "34 Train Loss 78.36029 Test MSE 80.8243871712183 Test RE 0.15134231777903595 Lambda1 -3.9484773\n",
      "35 Train Loss 77.71352 Test MSE 79.50421464325069 Test RE 0.15010122844838258 Lambda1 -4.0483465\n",
      "36 Train Loss 76.429184 Test MSE 79.07428011544985 Test RE 0.14969482746447738 Lambda1 -4.0636535\n",
      "37 Train Loss 74.84378 Test MSE 77.28555218781929 Test RE 0.14799203010761375 Lambda1 -4.148231\n",
      "38 Train Loss 73.732574 Test MSE 76.18955254189022 Test RE 0.14693893308243583 Lambda1 -4.186915\n",
      "39 Train Loss 72.96626 Test MSE 75.15244439504127 Test RE 0.14593542462293602 Lambda1 -4.251089\n",
      "40 Train Loss 72.028755 Test MSE 74.36758704357604 Test RE 0.14517138354384593 Lambda1 -4.338529\n",
      "41 Train Loss 71.73615 Test MSE 74.3854886578048 Test RE 0.1451888551725003 Lambda1 -4.3363104\n",
      "42 Train Loss 71.59397 Test MSE 74.48867085753929 Test RE 0.14528951804516024 Lambda1 -4.310916\n",
      "43 Train Loss 70.70585 Test MSE 74.61943660833435 Test RE 0.14541699086623663 Lambda1 -4.288123\n",
      "44 Train Loss 70.134285 Test MSE 74.69766417933347 Test RE 0.14549319512774025 Lambda1 -4.2712913\n",
      "45 Train Loss 69.97442 Test MSE 74.7070525011107 Test RE 0.14550233794385617 Lambda1 -4.2684216\n",
      "46 Train Loss 69.802155 Test MSE 74.56333504241591 Test RE 0.1453623157357464 Lambda1 -4.283266\n",
      "47 Train Loss 69.695564 Test MSE 74.53973295025956 Test RE 0.14533930760238137 Lambda1 -4.3112745\n",
      "48 Train Loss 69.54629 Test MSE 74.6390932629335 Test RE 0.14543614286920303 Lambda1 -4.3342333\n",
      "49 Train Loss 69.474525 Test MSE 74.5207329539231 Test RE 0.14532078310412658 Lambda1 -4.3359146\n",
      "50 Train Loss 69.3536 Test MSE 74.46139800422911 Test RE 0.14526291787608756 Lambda1 -4.346556\n",
      "51 Train Loss 69.29149 Test MSE 74.52519993706379 Test RE 0.1453251385078832 Lambda1 -4.360135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 Train Loss 69.23299 Test MSE 74.44948605137728 Test RE 0.14525129820277688 Lambda1 -4.3604445\n",
      "53 Train Loss 69.20817 Test MSE 74.43316346508945 Test RE 0.1452353746085499 Lambda1 -4.362398\n",
      "54 Train Loss 69.144165 Test MSE 74.40982791130827 Test RE 0.14521260644035677 Lambda1 -4.3698063\n",
      "55 Train Loss 69.11042 Test MSE 74.361575497465 Test RE 0.14516551591967006 Lambda1 -4.3679996\n",
      "56 Train Loss 69.09784 Test MSE 74.35424649390474 Test RE 0.14515836205833865 Lambda1 -4.3627543\n",
      "57 Train Loss 69.06365 Test MSE 74.29659901831783 Test RE 0.14510207989488105 Lambda1 -4.3717875\n",
      "58 Train Loss 68.939545 Test MSE 74.20596026497168 Test RE 0.14501354363995272 Lambda1 -4.427207\n",
      "59 Train Loss 68.82455 Test MSE 74.15821123718752 Test RE 0.14496688047476175 Lambda1 -4.4704237\n",
      "60 Train Loss 68.7441 Test MSE 74.07968445419617 Test RE 0.14489010679206646 Lambda1 -4.5158887\n",
      "61 Train Loss 68.65449 Test MSE 73.99641266614867 Test RE 0.14480864956901113 Lambda1 -4.5505366\n",
      "62 Train Loss 68.59023 Test MSE 73.9360085137078 Test RE 0.14474953299000384 Lambda1 -4.578298\n",
      "63 Train Loss 68.45859 Test MSE 73.7898197294115 Test RE 0.14460636033991894 Lambda1 -4.58989\n",
      "64 Train Loss 68.279625 Test MSE 73.66260400364105 Test RE 0.14448165385002443 Lambda1 -4.6118903\n",
      "65 Train Loss 68.1543 Test MSE 73.50915615515204 Test RE 0.14433108927824126 Lambda1 -4.6379695\n",
      "66 Train Loss 68.09241 Test MSE 73.49258564523095 Test RE 0.14431482072974622 Lambda1 -4.6494255\n",
      "67 Train Loss 68.060265 Test MSE 73.43778085879114 Test RE 0.14426100157295996 Lambda1 -4.661916\n",
      "68 Train Loss 67.9722 Test MSE 73.40241319288796 Test RE 0.14422625931020927 Lambda1 -4.687622\n",
      "69 Train Loss 67.79902 Test MSE 73.28509662994831 Test RE 0.1441109572757433 Lambda1 -4.7190037\n",
      "70 Train Loss 67.58541 Test MSE 73.18497814769013 Test RE 0.1440124849934144 Lambda1 -4.769237\n",
      "71 Train Loss 67.40983 Test MSE 73.00499857261524 Test RE 0.143835295209408 Lambda1 -4.8307652\n",
      "72 Train Loss 67.356735 Test MSE 72.94928974023851 Test RE 0.14378040564214542 Lambda1 -4.860301\n",
      "73 Train Loss 67.33455 Test MSE 72.90570631170398 Test RE 0.14373744854616197 Lambda1 -4.8916006\n",
      "74 Train Loss 67.26178 Test MSE 72.86683964654158 Test RE 0.14369912959740774 Lambda1 -4.901401\n",
      "75 Train Loss 67.1537 Test MSE 72.66573660941745 Test RE 0.14350069710047883 Lambda1 -4.9966254\n",
      "76 Train Loss 66.91945 Test MSE 72.43766271941074 Test RE 0.14327531932736187 Lambda1 -5.0741763\n",
      "77 Train Loss 66.79818 Test MSE 72.36914786428876 Test RE 0.14320754512194953 Lambda1 -5.0640526\n",
      "78 Train Loss 66.76653 Test MSE 72.31689322884323 Test RE 0.14315583379463304 Lambda1 -5.054763\n",
      "79 Train Loss 66.69174 Test MSE 72.05319483034995 Test RE 0.14289459165296958 Lambda1 -5.0666456\n",
      "80 Train Loss 66.54315 Test MSE 72.01426602478963 Test RE 0.14285598498643376 Lambda1 -5.116821\n",
      "81 Train Loss 66.36254 Test MSE 71.66060259198316 Test RE 0.1425047690163122 Lambda1 -5.2122297\n",
      "82 Train Loss 66.26307 Test MSE 71.42078254822823 Test RE 0.14226611528147903 Lambda1 -5.3016276\n",
      "83 Train Loss 66.22412 Test MSE 71.35355260798214 Test RE 0.14219914041802767 Lambda1 -5.320215\n",
      "84 Train Loss 66.186775 Test MSE 71.40147222863642 Test RE 0.14224688145503964 Lambda1 -5.310972\n",
      "85 Train Loss 66.150856 Test MSE 71.3245707831364 Test RE 0.14217025882073242 Lambda1 -5.3502674\n",
      "86 Train Loss 66.13209 Test MSE 71.26900927861907 Test RE 0.14211487305150133 Lambda1 -5.3904643\n",
      "87 Train Loss 66.11627 Test MSE 71.26811841456033 Test RE 0.1421139848293306 Lambda1 -5.4169245\n",
      "88 Train Loss 65.98871 Test MSE 71.39608955289364 Test RE 0.1422415196379431 Lambda1 -5.4646688\n",
      "89 Train Loss 65.939224 Test MSE 71.39385515539908 Test RE 0.14223929383969722 Lambda1 -5.489322\n",
      "90 Train Loss 65.90091 Test MSE 71.1990445352197 Test RE 0.14204509888042555 Lambda1 -5.5049844\n",
      "91 Train Loss 65.86772 Test MSE 71.1429425806895 Test RE 0.1419891249683948 Lambda1 -5.5209603\n",
      "92 Train Loss 65.82005 Test MSE 71.0553270131625 Test RE 0.1419016652013801 Lambda1 -5.537779\n",
      "93 Train Loss 65.78919 Test MSE 70.87231371648635 Test RE 0.1417188032224123 Lambda1 -5.568437\n",
      "94 Train Loss 65.71112 Test MSE 70.74216812832826 Test RE 0.14158862155337706 Lambda1 -5.613694\n",
      "95 Train Loss 65.62378 Test MSE 70.51098998799594 Test RE 0.14135708370095182 Lambda1 -5.6386094\n",
      "96 Train Loss 65.51538 Test MSE 70.41628717012092 Test RE 0.14126212394968338 Lambda1 -5.6252503\n",
      "97 Train Loss 65.34937 Test MSE 70.43198328820539 Test RE 0.1412778670648167 Lambda1 -5.6048226\n",
      "98 Train Loss 65.20938 Test MSE 70.33446226946799 Test RE 0.14118002562028398 Lambda1 -5.607538\n",
      "99 Train Loss 65.081696 Test MSE 70.3002763502792 Test RE 0.14114571132118087 Lambda1 -5.625711\n",
      "100 Train Loss 64.82266 Test MSE 69.93324147652176 Test RE 0.14077677113636525 Lambda1 -5.666392\n",
      "101 Train Loss 64.736305 Test MSE 69.89462808879568 Test RE 0.14073790107623432 Lambda1 -5.6789274\n",
      "102 Train Loss 64.66924 Test MSE 69.90411678126577 Test RE 0.1407474538371449 Lambda1 -5.704122\n",
      "103 Train Loss 64.57367 Test MSE 69.80647516662314 Test RE 0.1406491219247812 Lambda1 -5.760056\n",
      "104 Train Loss 64.512695 Test MSE 69.68401303666515 Test RE 0.1405256967569984 Lambda1 -5.8089375\n",
      "105 Train Loss 64.47421 Test MSE 69.61782182826067 Test RE 0.14045893987002242 Lambda1 -5.8551316\n",
      "106 Train Loss 64.4086 Test MSE 69.53670945710675 Test RE 0.14037709101431153 Lambda1 -5.8828006\n",
      "107 Train Loss 64.344345 Test MSE 69.41060790337767 Test RE 0.14024974962844647 Lambda1 -5.939611\n",
      "108 Train Loss 64.26177 Test MSE 69.34113743714988 Test RE 0.14017954670907562 Lambda1 -5.997114\n",
      "109 Train Loss 64.236336 Test MSE 69.33708573848978 Test RE 0.14017545120675504 Lambda1 -6.004899\n",
      "110 Train Loss 64.17623 Test MSE 69.29362641283113 Test RE 0.14013151450680744 Lambda1 -6.043933\n",
      "111 Train Loss 64.04559 Test MSE 69.15596075247224 Test RE 0.13999224564820872 Lambda1 -6.080097\n",
      "112 Train Loss 63.950733 Test MSE 69.05052212290181 Test RE 0.13988548535706893 Lambda1 -6.141713\n",
      "113 Train Loss 63.9014 Test MSE 68.9765359223797 Test RE 0.1398105230752359 Lambda1 -6.186437\n",
      "114 Train Loss 63.83054 Test MSE 68.80910956554082 Test RE 0.13964073933657192 Lambda1 -6.2672796\n",
      "115 Train Loss 63.79858 Test MSE 68.72998330530086 Test RE 0.1395604270939901 Lambda1 -6.267491\n",
      "116 Train Loss 63.76326 Test MSE 68.65788025037133 Test RE 0.13948720305705758 Lambda1 -6.275563\n",
      "117 Train Loss 63.736485 Test MSE 68.59182280520378 Test RE 0.1394200848646845 Lambda1 -6.294047\n",
      "118 Train Loss 63.71081 Test MSE 68.49338104354636 Test RE 0.1393200023320869 Lambda1 -6.309404\n",
      "119 Train Loss 63.67084 Test MSE 68.48743458508899 Test RE 0.13931395445873304 Lambda1 -6.3100214\n",
      "120 Train Loss 63.65135 Test MSE 68.4757428506549 Test RE 0.1393020625599505 Lambda1 -6.3043723\n",
      "121 Train Loss 63.632874 Test MSE 68.4039705728695 Test RE 0.13922903927371347 Lambda1 -6.313665\n",
      "122 Train Loss 63.595295 Test MSE 68.32290173970217 Test RE 0.13914651130145317 Lambda1 -6.3413386\n",
      "123 Train Loss 63.582436 Test MSE 68.29409965922193 Test RE 0.1391171790323698 Lambda1 -6.3656697\n",
      "124 Train Loss 63.579166 Test MSE 68.26973149096985 Test RE 0.1390923574643472 Lambda1 -6.375138\n",
      "125 Train Loss 63.575294 Test MSE 68.24669539866757 Test RE 0.1390688886835829 Lambda1 -6.3754916\n",
      "126 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "127 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "128 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "129 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "130 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "131 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "132 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "133 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "134 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "135 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "136 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "138 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "139 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "140 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "141 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "142 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "143 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "144 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "145 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "146 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "147 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "148 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "149 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "150 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "151 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "152 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "153 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "154 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "155 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "156 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "157 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "158 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "159 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "160 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "161 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "162 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "163 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "164 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "165 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "166 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "167 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "168 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "169 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "170 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "171 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "172 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "173 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "174 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "175 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "176 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "177 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "178 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "179 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "180 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "181 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "182 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "183 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "184 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "185 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "186 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "187 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "188 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "189 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "190 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "191 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "192 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "193 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "194 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "195 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "196 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "197 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "198 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "199 Train Loss 63.575283 Test MSE 68.24671487889363 Test RE 0.13906890853138054 Lambda1 -6.375489\n",
      "Training time: 913.26\n",
      "Training time: 913.26\n",
      "inv_HT_swish\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 854.48785 Test MSE 857.6143107326528 Test RE 0.49298667439570454 Lambda1 0.045531698\n",
      "1 Train Loss 850.3509 Test MSE 854.4812945701365 Test RE 0.49208536689840426 Lambda1 0.34712976\n",
      "2 Train Loss 756.5487 Test MSE 747.6088270252038 Test RE 0.4602845323365944 Lambda1 0.9853338\n",
      "3 Train Loss 489.36044 Test MSE 401.0338741093414 Test RE 0.3371162594537031 Lambda1 1.019378\n",
      "4 Train Loss 379.38193 Test MSE 338.4988022843223 Test RE 0.3097189218636855 Lambda1 0.95029885\n",
      "5 Train Loss 298.9972 Test MSE 277.36030949893444 Test RE 0.2803569503953739 Lambda1 1.3036212\n",
      "6 Train Loss 290.1933 Test MSE 276.16014140036935 Test RE 0.2797497253569689 Lambda1 1.367275\n",
      "7 Train Loss 284.35367 Test MSE 270.9399330581434 Test RE 0.27709308011214157 Lambda1 1.3796023\n",
      "8 Train Loss 281.7162 Test MSE 267.1754035401619 Test RE 0.27516133486856176 Lambda1 1.0943832\n",
      "9 Train Loss 274.93228 Test MSE 252.22962794684292 Test RE 0.26735432880560017 Lambda1 0.9070915\n",
      "10 Train Loss 252.8869 Test MSE 236.07239821885554 Test RE 0.2586495794575798 Lambda1 0.87141734\n",
      "11 Train Loss 230.46465 Test MSE 206.91745539918264 Test RE 0.24215181865342922 Lambda1 0.6837455\n",
      "12 Train Loss 196.42244 Test MSE 184.4493278106241 Test RE 0.2286271007646766 Lambda1 0.613662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Train Loss 186.26031 Test MSE 170.57157222761458 Test RE 0.2198581133648827 Lambda1 0.6347733\n",
      "14 Train Loss 171.60214 Test MSE 150.01869035390783 Test RE 0.20618727336826584 Lambda1 0.59948075\n",
      "15 Train Loss 143.0403 Test MSE 131.76263393172175 Test RE 0.19323478332929428 Lambda1 0.50555366\n",
      "16 Train Loss 102.81215 Test MSE 80.5952168431018 Test RE 0.1511276066626821 Lambda1 0.8126011\n",
      "17 Train Loss 79.61096 Test MSE 55.781430277444656 Test RE 0.12572857504956736 Lambda1 0.82748157\n",
      "18 Train Loss 56.0162 Test MSE 47.797798519404 Test RE 0.11638395668909865 Lambda1 0.72648656\n",
      "19 Train Loss 47.068375 Test MSE 41.90116979888348 Test RE 0.10896881911835823 Lambda1 0.8164954\n",
      "20 Train Loss 38.295517 Test MSE 36.597301704281286 Test RE 0.10183890096088662 Lambda1 1.0474349\n",
      "21 Train Loss 34.678394 Test MSE 35.27337093527321 Test RE 0.09997988971353697 Lambda1 1.1538057\n",
      "22 Train Loss 33.21342 Test MSE 35.65667348414978 Test RE 0.10052164399155093 Lambda1 0.95959437\n",
      "23 Train Loss 33.016754 Test MSE 35.636789493196055 Test RE 0.10049361206938105 Lambda1 0.9573083\n",
      "24 Train Loss 32.743816 Test MSE 35.39553935949884 Test RE 0.10015287896121618 Lambda1 0.9481948\n",
      "25 Train Loss 32.58183 Test MSE 34.941760352352276 Test RE 0.0995088165002418 Lambda1 0.9835617\n",
      "26 Train Loss 31.70998 Test MSE 34.289576090715194 Test RE 0.09857578147471069 Lambda1 0.9452311\n",
      "27 Train Loss 31.609972 Test MSE 34.12723492182053 Test RE 0.09834215517339664 Lambda1 0.9335004\n",
      "28 Train Loss 31.501253 Test MSE 34.36915771809296 Test RE 0.09869010593678725 Lambda1 0.9211675\n",
      "29 Train Loss 31.288296 Test MSE 33.92728533489767 Test RE 0.09805364132463601 Lambda1 0.9534249\n",
      "30 Train Loss 31.185673 Test MSE 33.83404518204546 Test RE 0.09791881140057156 Lambda1 0.95264536\n",
      "31 Train Loss 30.742779 Test MSE 33.758050117388294 Test RE 0.0978087812580377 Lambda1 0.9316543\n",
      "32 Train Loss 30.17772 Test MSE 33.54687896793163 Test RE 0.09750238330779334 Lambda1 1.0139321\n",
      "33 Train Loss 30.162935 Test MSE 33.54955234413343 Test RE 0.09750626824979572 Lambda1 0.99725896\n",
      "34 Train Loss 30.142546 Test MSE 33.56244573535636 Test RE 0.09752500271287526 Lambda1 0.9948089\n",
      "35 Train Loss 30.12457 Test MSE 33.5627528167112 Test RE 0.09752544886691447 Lambda1 0.99419016\n",
      "36 Train Loss 30.087921 Test MSE 33.51797128017747 Test RE 0.09746036485484437 Lambda1 0.9735402\n",
      "37 Train Loss 30.077124 Test MSE 33.51567662538348 Test RE 0.09745702870840388 Lambda1 0.9798871\n",
      "38 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "39 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "40 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "41 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "42 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "43 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "44 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "45 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "46 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "47 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "48 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "49 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "50 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "51 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "52 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "53 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "54 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "55 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "56 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "57 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "58 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "59 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "60 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "61 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "62 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "63 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "64 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "65 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "66 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "67 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "68 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "69 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "70 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "71 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "72 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "73 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "74 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "75 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "76 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "77 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "78 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "79 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "80 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "81 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "82 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "83 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "84 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "85 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "86 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "87 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "88 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "89 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "90 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "91 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "92 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "93 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "94 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "95 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "96 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "97 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "99 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "100 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "101 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "102 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "103 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "104 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "105 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "106 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "107 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "108 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "109 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "110 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "111 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "112 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "113 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "114 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "115 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "116 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "117 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "118 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "119 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "120 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "121 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "122 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "123 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "124 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "125 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "126 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "127 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "128 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "129 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "130 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "131 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "132 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "133 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "134 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "135 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "136 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "137 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "138 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "139 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "140 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "141 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "142 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "143 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "144 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "145 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "146 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "147 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "148 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "149 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "150 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "151 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "152 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "153 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "154 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "155 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "156 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "157 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "158 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "159 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "160 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "161 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "162 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "163 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "164 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "165 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "166 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "167 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "168 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "169 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "170 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "171 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "172 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "173 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "174 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "175 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "176 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "177 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "178 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "179 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "180 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "181 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "183 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "184 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "185 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "186 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "187 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "188 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "189 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "190 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "191 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "192 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "193 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "194 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "195 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "196 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "197 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "198 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "199 Train Loss 30.070791 Test MSE 33.52834726675247 Test RE 0.09747544884037732 Lambda1 0.9721389\n",
      "Training time: 469.67\n",
      "Training time: 469.67\n",
      "inv_HT_swish\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 854.3666 Test MSE 857.3712404678047 Test RE 0.4929168068037224 Lambda1 0.0002763635\n",
      "1 Train Loss 849.275 Test MSE 853.717896456612 Test RE 0.4918655019439757 Lambda1 0.003034791\n",
      "2 Train Loss 826.18866 Test MSE 822.1544322808502 Test RE 0.4826872995756157 Lambda1 0.054197073\n",
      "3 Train Loss 471.83905 Test MSE 322.7671405703035 Test RE 0.3024362385466412 Lambda1 0.1210135\n",
      "4 Train Loss 261.3961 Test MSE 221.78053503151614 Test RE 0.250698008523826 Lambda1 0.1670486\n",
      "5 Train Loss 171.13707 Test MSE 162.14519244036967 Test RE 0.21435874655445158 Lambda1 0.34095135\n",
      "6 Train Loss 95.47404 Test MSE 88.1277735403056 Test RE 0.1580321940696727 Lambda1 0.48752427\n",
      "7 Train Loss 57.67575 Test MSE 57.66330239611294 Test RE 0.1278318064291103 Lambda1 0.6608691\n",
      "8 Train Loss 50.553284 Test MSE 53.63384164292681 Test RE 0.12328454120915884 Lambda1 0.71873444\n",
      "9 Train Loss 47.39503 Test MSE 49.01481824644221 Test RE 0.11785631797804602 Lambda1 0.767154\n",
      "10 Train Loss 44.156063 Test MSE 46.67059230052159 Test RE 0.1150034388606489 Lambda1 0.79624516\n",
      "11 Train Loss 40.134636 Test MSE 42.6990513083432 Test RE 0.11000141800679196 Lambda1 0.91934997\n",
      "12 Train Loss 39.02686 Test MSE 41.76039030067714 Test RE 0.10878560844962663 Lambda1 0.97648543\n",
      "13 Train Loss 37.72253 Test MSE 41.3443453625113 Test RE 0.10824235450348242 Lambda1 1.007823\n",
      "14 Train Loss 37.184395 Test MSE 41.01235870511295 Test RE 0.10780689657148906 Lambda1 1.0284635\n",
      "15 Train Loss 36.954674 Test MSE 40.68768100953787 Test RE 0.10737931758728554 Lambda1 1.0435045\n",
      "16 Train Loss 36.124 Test MSE 39.869091861618955 Test RE 0.10629365535109617 Lambda1 1.0736015\n",
      "17 Train Loss 35.722828 Test MSE 39.30871504814689 Test RE 0.10554401092664882 Lambda1 1.0902623\n",
      "18 Train Loss 34.847374 Test MSE 38.287916519084455 Test RE 0.10416457297839593 Lambda1 0.9856032\n",
      "19 Train Loss 34.341328 Test MSE 38.36841003822765 Test RE 0.1042740092140227 Lambda1 0.91965055\n",
      "20 Train Loss 34.154755 Test MSE 38.34105412217919 Test RE 0.10423682993468128 Lambda1 0.92704374\n",
      "21 Train Loss 33.72887 Test MSE 38.1549428925974 Test RE 0.10398353429262927 Lambda1 0.88706493\n",
      "22 Train Loss 33.245956 Test MSE 37.904370484714406 Test RE 0.10364152980232566 Lambda1 0.8639046\n",
      "23 Train Loss 32.871384 Test MSE 37.42209585902641 Test RE 0.10298007981351134 Lambda1 0.92254347\n",
      "24 Train Loss 32.602196 Test MSE 37.06411997182 Test RE 0.10248634784830286 Lambda1 0.9377268\n",
      "25 Train Loss 32.099297 Test MSE 36.40492175754793 Test RE 0.10157088151434664 Lambda1 0.958024\n",
      "26 Train Loss 31.413006 Test MSE 35.81149948347575 Test RE 0.10073964674529558 Lambda1 0.904898\n",
      "27 Train Loss 31.021564 Test MSE 35.16510075714185 Test RE 0.09982632968289012 Lambda1 0.92875034\n",
      "28 Train Loss 30.610373 Test MSE 34.45632842315502 Test RE 0.09881518083978878 Lambda1 0.94811493\n",
      "29 Train Loss 30.2058 Test MSE 33.814018091112665 Test RE 0.09788982699730261 Lambda1 1.0224261\n",
      "30 Train Loss 30.06583 Test MSE 33.69741464446398 Test RE 0.09772090077883659 Lambda1 1.0019052\n",
      "31 Train Loss 29.982687 Test MSE 33.644789420112176 Test RE 0.09764456563942966 Lambda1 0.97776526\n",
      "32 Train Loss 29.968473 Test MSE 33.61927392857768 Test RE 0.09760753283768546 Lambda1 0.963368\n",
      "33 Train Loss 29.924438 Test MSE 33.59526105661517 Test RE 0.09757266807722283 Lambda1 0.9518806\n",
      "34 Train Loss 29.888744 Test MSE 33.47878482473623 Test RE 0.09740337687192306 Lambda1 0.9606959\n",
      "35 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "36 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "37 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "38 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "39 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "40 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "41 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "42 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "43 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "44 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "45 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "46 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "47 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "48 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "49 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "50 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "51 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "52 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "53 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "54 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "55 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "56 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "57 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "58 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "60 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "61 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "62 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "63 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "64 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "65 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "66 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "67 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "68 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "69 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "70 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "71 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "72 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "73 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "74 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "75 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "76 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "77 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "78 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "79 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "80 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "81 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "82 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "83 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "84 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "85 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "86 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "87 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "88 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "89 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "90 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "91 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "92 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "93 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "94 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "95 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "96 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "97 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "98 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "99 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "100 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "101 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "102 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "103 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "104 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "105 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "106 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "107 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "108 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "109 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "110 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "111 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "112 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "113 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "114 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "115 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "116 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "117 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "118 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "119 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "120 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "121 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "122 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "123 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "124 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "125 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "126 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "127 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "128 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "129 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "130 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "131 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "132 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "133 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "134 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "135 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "136 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "137 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "138 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "139 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "140 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "141 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "142 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "143 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "145 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "146 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "147 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "148 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "149 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "150 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "151 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "152 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "153 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "154 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "155 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "156 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "157 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "158 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "159 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "160 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "161 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "162 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "163 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "164 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "165 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "166 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "167 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "168 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "169 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "170 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "171 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "172 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "173 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "174 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "175 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "176 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "177 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "178 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "179 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "180 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "181 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "182 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "183 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "184 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "185 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "186 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "187 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "188 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "189 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "190 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "191 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "192 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "193 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "194 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "195 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "196 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "197 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "198 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "199 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "Training time: 374.80\n",
      "Training time: 374.80\n",
      "inv_HT_swish\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 854.52515 Test MSE 857.6835242063268 Test RE 0.49300656715598934 Lambda1 -0.001258337\n",
      "1 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "2 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "3 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "4 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "5 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "6 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "7 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "8 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "9 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "10 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "11 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "12 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "13 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "14 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "15 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "16 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "17 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "18 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "19 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "21 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "22 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "23 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "24 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "25 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "26 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "27 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "28 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "29 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "30 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "31 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "32 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "33 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "34 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "35 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "36 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "37 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "38 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "39 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "40 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "41 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "42 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "43 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "44 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "45 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "46 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "47 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "48 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "49 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "50 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "51 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "52 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "53 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "54 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "55 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "56 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "57 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "58 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "59 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "60 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "61 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "62 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "63 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "64 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "65 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "66 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "67 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "68 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "69 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "70 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "71 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "72 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "73 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "74 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "75 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "76 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "77 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "78 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "79 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "80 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "81 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "82 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "83 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "84 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "85 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "86 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "87 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "88 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "89 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "90 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "91 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "92 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "93 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "94 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "95 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "96 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "97 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "98 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "99 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "100 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "101 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "102 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "103 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "105 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "106 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "107 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "108 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "109 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "110 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "111 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "112 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "113 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "114 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "115 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "116 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "117 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "118 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "119 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "120 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "121 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "122 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "123 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "124 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "125 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "126 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "127 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "128 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "129 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "130 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "131 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "132 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "133 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "134 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "135 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "136 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "137 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "138 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "139 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "140 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "141 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "142 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "143 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "144 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "145 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "146 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "147 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "148 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "149 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "150 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "151 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "152 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "153 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "154 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "155 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "156 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "157 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "158 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "159 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "160 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "161 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "162 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "163 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "164 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "165 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "166 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "167 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "168 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "169 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "170 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "171 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "172 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "173 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "174 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "175 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "176 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "177 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "178 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "179 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "180 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "181 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "182 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "183 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "184 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "185 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "186 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "188 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "189 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "190 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "191 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "192 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "193 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "194 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "195 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "196 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "197 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "198 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "199 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "Training time: 289.17\n",
      "Training time: 289.17\n",
      "inv_HT_swish\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "1 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "2 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "3 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "4 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "5 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "6 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "7 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "8 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "9 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "10 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "11 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "12 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "13 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "14 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "15 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "16 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "17 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "18 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "19 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "20 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "21 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "22 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "23 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "24 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "25 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "26 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "27 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "28 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "29 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "30 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "31 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "32 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "33 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "34 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "35 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "36 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "37 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "38 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "39 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "40 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "41 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "42 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "43 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "44 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "45 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "46 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "47 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "48 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "49 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "50 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "51 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "52 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "53 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "54 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "55 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "56 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "57 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "58 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "59 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "60 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "61 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "63 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "64 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "65 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "66 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "67 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "68 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "69 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "70 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "71 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "72 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "73 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "74 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "75 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "76 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "77 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "78 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "79 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "80 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "81 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "82 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "83 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "84 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "85 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "86 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "87 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "88 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "89 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "90 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "91 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "92 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "93 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "94 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "95 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "96 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "97 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "98 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "99 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "100 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "101 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "102 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "103 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "104 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "105 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "106 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "107 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "108 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "109 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "110 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "111 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "112 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "113 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "114 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "115 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "116 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "117 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "118 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "119 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "120 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "121 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "122 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "123 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "124 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "125 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "126 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "127 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "128 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "129 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "130 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "131 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "132 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "133 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "134 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "135 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "136 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "137 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "138 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "139 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "140 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "141 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "142 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "143 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "144 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "146 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "147 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "148 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "149 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "150 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "151 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "152 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "153 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "154 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "155 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "156 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "157 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "158 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "159 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "160 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "161 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "162 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "163 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "164 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "165 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "166 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "167 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "168 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "169 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "170 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "171 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "172 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "173 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "174 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "175 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "176 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "177 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "178 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "179 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "180 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "181 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "182 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "183 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "184 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "185 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "186 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "187 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "188 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "189 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "190 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "191 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "192 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "193 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "194 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "195 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "196 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "197 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "198 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "199 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "Training time: 258.84\n",
      "Training time: 258.84\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "max_reps = 10 #10\n",
    "max_iter = 200 #75\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "\n",
    "lambda1_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    'Generate Training data'\n",
    "    print(reps)\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []   \n",
    "    beta_val = []\n",
    "\n",
    "    lambda1_val = []\n",
    "\n",
    "    N_f = 50000 #Total number of collocation points \n",
    "    N_train = 5000\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                              max_iter = 20, \n",
    "                              max_eval = 30, \n",
    "                              tolerance_grad = 1e-8, \n",
    "                              tolerance_change = 1e-8, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "    lambda1_full.append(lambda1_val)\n",
    "\n",
    "\n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full,\"lambda1\": lambda1_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'inv_HT_swish_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'inv_HT_swish_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-88cda4360795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"inv_HT_swish_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'inv_HT_swish_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"inv_HT_swish_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
