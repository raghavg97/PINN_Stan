{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/PINN_Stan/1D FODE/atanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tune = np.array([0.05,0.1,0.25,0.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_2D_4(xt): #True function for 2D_4 Heat Transfer in a rod x \\in [0,1] t \\in [0,0.1]\n",
    "    term1 = 4*u0/np.pi\n",
    "    \n",
    "    resol_n = 10000\n",
    "    \n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "\n",
    "    u = np.zeros((np.shape(xt)[0],1))\n",
    "    \n",
    "    for i in range(resol_n):\n",
    "        j = 2*i-1\n",
    "        term2 = np.sin(j*np.pi*x)/j\n",
    "        term3 = np.exp(-1*np.square(j*np.pi)*t)\n",
    "        \n",
    "        u = u + term2*term3\n",
    "        \n",
    "    u = term1*u\n",
    "    \n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = 50.0\n",
    "loss_thresh = 0.1\n",
    "\n",
    "x_ll = np.array(0.0)\n",
    "x_ul = np.array(1.0)\n",
    "\n",
    "x = np.linspace(x_ll,x_ul,100).reshape(-1,1)\n",
    "t = np.linspace(0,0.1,100).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "u_true = true_2D_4(xt)\n",
    "u_true_norm = np.linalg.norm(u_true,2)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_f,N_train,seed):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    #X_Train\n",
    "    np.random.seed(seed)\n",
    "    x_train = np.random.uniform(x_ll,x_ul,(N_train,1))\n",
    "    t_train = np.random.uniform(0,0.1,(N_train,1))\n",
    "    \n",
    "    xt_train = np.hstack((x_train,t_train))\n",
    "    u_train = true_2D_4(xt_train)\n",
    "    \n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_train, u_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "        \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "    \n",
    "        self.lambda1 = Parameter(torch.tensor(0.0))\n",
    "        self.lambda1.requiresGrad = True\n",
    "        \n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = (xt - lbxt)/(ubxt - lbxt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    \n",
    "    def loss_PDE(self, xt_coll,f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_t = autograd.grad(u,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_tt = autograd.grad(u_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_tt[:,[0]]\n",
    "                \n",
    "        du_dt = u_x_t[:,[1]]\n",
    "        \n",
    "        f = du_dt - self.lambda1*d2u_dx2\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_coll,f_hat, xt_train, u_train):\n",
    "\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_train = self.loss_function(self.forward(xt_train),u_train)\n",
    "        \n",
    "        loss_val = loss_f + loss_train\n",
    "        \n",
    "        #print(self.iter,\"train_loss\",loss_train.cpu().detach().numpy(),\"F Loss\",(loss_f).cpu().detach().numpy())\n",
    "        return loss_val\n",
    "     \n",
    "    'callable for optimizer'                                    \n",
    "    \n",
    "    def test(self):\n",
    "        u_pred = self.forward(xt_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "               \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xt_coll,f_hat, xt_train, u_train,seed):    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_coll,f_hat, xt_train, u_train)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    lambda1_val.append(PINN.lambda1.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "    \n",
    "    xt_coll, xt_train, u_train = trainingdata(N_f,N_train,123)\n",
    "    \n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_train = torch.from_numpy(xt_train).float().to(device)\n",
    "    u_train = torch.from_numpy(u_train).float().to(device)\n",
    "    \n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    nan_flag = 0\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        train_step(xt_coll,f_hat, xt_train, u_train,i)\n",
    "\n",
    "        loss_np = PINN.loss(xt_coll,f_hat, xt_train, u_train).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1],\"Lambda1\",lambda1_val[-1])\n",
    "\n",
    "        if(np.isnan(loss_np)):\n",
    "            nan_flag =1\n",
    "            print(\"NAN BREAK!\")\n",
    "            break\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_HT_swish_tune0\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 854.70496 Test MSE 858.0623826558389 Test RE 0.4931154412783769 Lambda1 -2.800156e-07\n",
      "1 Train Loss 854.70483 Test MSE 858.0623619364424 Test RE 0.49311543532481533 Lambda1 -2.9849858e-07\n",
      "2 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "3 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "4 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "5 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "6 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "7 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "8 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "9 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "10 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "11 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "12 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "13 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "14 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "15 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "16 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "17 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "18 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "19 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "20 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "21 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "22 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "23 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "24 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "25 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "26 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "27 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "28 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "29 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "30 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "31 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "32 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "33 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "34 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "35 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "36 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "37 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "38 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "39 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "40 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "41 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "42 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "43 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "44 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "45 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "46 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "47 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "48 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "49 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "50 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "51 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "52 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "53 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "54 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "55 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "56 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "57 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "58 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "59 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "60 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "61 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "62 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "63 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "64 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "65 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "66 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "67 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "68 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "69 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "70 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "71 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "72 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "73 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 Train Loss 854.7048 Test MSE 858.0623458460402 Test RE 0.49311543070136005 Lambda1 -3.1082334e-07\n",
      "Training time: 204.29\n",
      "Training time: 204.29\n",
      "inv_HT_swish_tune0\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 854.78894 Test MSE 858.0861395707866 Test RE 0.49312226760053535 Lambda1 1.7028183e-06\n",
      "1 Train Loss 854.7581 Test MSE 858.0991175207283 Test RE 0.49312599665034246 Lambda1 3.3546223e-06\n",
      "2 Train Loss 854.75586 Test MSE 858.1051127883958 Test RE 0.493127719305173 Lambda1 4.583917e-06\n",
      "3 Train Loss 854.75507 Test MSE 858.1087046565121 Test RE 0.4931287513744687 Lambda1 5.7993198e-06\n",
      "4 Train Loss 854.75336 Test MSE 858.1146127661225 Test RE 0.49313044897623204 Lambda1 9.8000755e-06\n",
      "5 Train Loss 854.753 Test MSE 858.1155946055219 Test RE 0.49313073109167327 Lambda1 1.0977884e-05\n",
      "6 Train Loss 854.7462 Test MSE 858.1271731793378 Test RE 0.49313405799270293 Lambda1 4.0694627e-05\n",
      "7 Train Loss 854.7041 Test MSE 858.1081133320503 Test RE 0.49312858146642435 Lambda1 0.0002604885\n",
      "8 Train Loss 854.52563 Test MSE 857.7053565645858 Test RE 0.4930128418640833 Lambda1 0.004881918\n",
      "9 Train Loss 854.52185 Test MSE 857.6733668082954 Test RE 0.49300364785147927 Lambda1 0.0076630134\n",
      "10 Train Loss 854.52014 Test MSE 857.65732458271 Test RE 0.4929990371727393 Lambda1 0.012031201\n",
      "11 Train Loss 854.5201 Test MSE 857.6564329292434 Test RE 0.49299878090231386 Lambda1 0.012612368\n",
      "12 Train Loss 854.5197 Test MSE 857.6547181724973 Test RE 0.49299828806312135 Lambda1 0.014480832\n",
      "13 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "14 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "15 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "16 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "17 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "18 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "19 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "20 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "21 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "22 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "23 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "24 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "25 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "26 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "27 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "28 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "29 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "30 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "31 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "32 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "33 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "34 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "35 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "36 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "37 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "38 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "39 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "40 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "41 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "42 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "43 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "44 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "45 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "46 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "47 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "48 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "49 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "50 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "51 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "52 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "53 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "54 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "55 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "56 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "57 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "58 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "59 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "60 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "61 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "62 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "63 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "64 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "65 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "66 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "67 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "68 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "69 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "70 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "71 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "72 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "73 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "74 Train Loss 854.5193 Test MSE 857.6532732395509 Test RE 0.4929978727737548 Lambda1 0.016739467\n",
      "Training time: 233.37\n",
      "Training time: 233.37\n",
      "inv_HT_swish_tune0\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 857.5235 Test MSE 861.436863405015 Test RE 0.4940841212980428 Lambda1 2.7314732e-06\n",
      "1 Train Loss 854.7409 Test MSE 858.1311850141361 Test RE 0.4931352107181519 Lambda1 2.7868648e-06\n",
      "2 Train Loss 854.7331 Test MSE 858.1050368133319 Test RE 0.49312769747485746 Lambda1 2.8318825e-06\n",
      "3 Train Loss 854.732 Test MSE 858.0986397027079 Test RE 0.49312585935587633 Lambda1 2.8590155e-06\n",
      "4 Train Loss 854.7315 Test MSE 858.0945313967663 Test RE 0.49312467888883627 Lambda1 2.895078e-06\n",
      "5 Train Loss 854.7313 Test MSE 858.0935405926466 Test RE 0.4931243941940348 Lambda1 2.9084924e-06\n",
      "6 Train Loss 854.7311 Test MSE 858.0922861082237 Test RE 0.4931240337338588 Lambda1 2.931885e-06\n",
      "7 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "8 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "9 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "10 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "11 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "12 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "13 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "14 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "15 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "16 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "17 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "18 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "19 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "20 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "21 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "22 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "23 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "24 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "25 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "26 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "27 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "28 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "29 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "30 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "31 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "32 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "33 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "34 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "35 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "36 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "37 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "38 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "39 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "40 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "41 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "42 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "43 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "44 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "45 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "46 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "47 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "48 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "49 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "50 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "51 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "52 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "53 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "54 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "55 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "56 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "57 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "58 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "59 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "60 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "61 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "62 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "63 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "64 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "65 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "66 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "67 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "68 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "69 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "70 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "71 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "72 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "73 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "74 Train Loss 854.731 Test MSE 858.0910011750925 Test RE 0.49312366452436 Lambda1 2.9643177e-06\n",
      "Training time: 249.66\n",
      "Training time: 249.66\n",
      "inv_HT_swish_tune0\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 855.70715 Test MSE 859.3992753804348 Test RE 0.4934994377557918 Lambda1 2.597614e-07\n",
      "1 Train Loss 854.7089 Test MSE 858.0849035026941 Test RE 0.49312191243052844 Lambda1 7.235779e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Train Loss 854.7061 Test MSE 858.0743914834615 Test RE 0.49311889191188146 Lambda1 4.8941433e-09\n",
      "3 Train Loss 854.6964 Test MSE 858.0352321592655 Test RE 0.4931076397273019 Lambda1 -1.1648385e-06\n",
      "4 Train Loss 854.5969 Test MSE 857.7799342268551 Test RE 0.49303427518365356 Lambda1 -1.0092516e-05\n",
      "5 Train Loss 854.5015 Test MSE 857.6427232256827 Test RE 0.4929948405749911 Lambda1 0.0009949289\n",
      "6 Train Loss 854.4987 Test MSE 857.6466479786297 Test RE 0.4929959685975857 Lambda1 0.0011780597\n",
      "7 Train Loss 854.49805 Test MSE 857.648331093135 Test RE 0.4929964523447447 Lambda1 0.001277107\n",
      "8 Train Loss 854.4972 Test MSE 857.65033184342 Test RE 0.49299702738359313 Lambda1 0.0014650475\n",
      "9 Train Loss 854.4955 Test MSE 857.6540700388476 Test RE 0.4929981017825393 Lambda1 0.0019709223\n",
      "10 Train Loss 854.48425 Test MSE 857.6766622879613 Test RE 0.4930045949963941 Lambda1 0.0056500086\n",
      "11 Train Loss 854.3221 Test MSE 857.7489097995061 Test RE 0.4930253590014537 Lambda1 0.02382882\n",
      "12 Train Loss 849.18195 Test MSE 848.1367773580786 Test RE 0.4902550980535543 Lambda1 0.19081776\n",
      "13 Train Loss 794.9409 Test MSE 789.0415736755558 Test RE 0.4728671163247156 Lambda1 0.15840404\n",
      "14 Train Loss 743.87305 Test MSE 731.8857137966199 Test RE 0.45541864372791063 Lambda1 0.023695754\n",
      "15 Train Loss 687.4372 Test MSE 676.3213292777548 Test RE 0.43778987447546946 Lambda1 0.00337498\n",
      "16 Train Loss 613.5299 Test MSE 614.2430830778844 Test RE 0.41721441770068995 Lambda1 0.00082230795\n",
      "17 Train Loss 526.36487 Test MSE 515.6506943428801 Test RE 0.3822671459517317 Lambda1 -0.0002232382\n",
      "18 Train Loss 481.08795 Test MSE 453.90437903378216 Test RE 0.3586504308860699 Lambda1 -0.00030793884\n",
      "19 Train Loss 388.36942 Test MSE 381.0329215423596 Test RE 0.3286021653843321 Lambda1 0.0003025416\n",
      "20 Train Loss 358.536 Test MSE 368.95428093083837 Test RE 0.3233519225863598 Lambda1 -7.877767e-05\n",
      "21 Train Loss 337.44266 Test MSE 341.57133670392625 Test RE 0.3111213970452301 Lambda1 0.00041939563\n",
      "22 Train Loss 314.23483 Test MSE 319.1544459151041 Test RE 0.3007389090495867 Lambda1 0.0012038221\n",
      "23 Train Loss 298.03482 Test MSE 306.9997066647387 Test RE 0.29495662202257733 Lambda1 0.00063604955\n",
      "24 Train Loss 292.09076 Test MSE 299.9922775912078 Test RE 0.29157092071697716 Lambda1 -0.00088573445\n",
      "25 Train Loss 287.5249 Test MSE 296.78055066566463 Test RE 0.2900059369492609 Lambda1 -0.001525391\n",
      "26 Train Loss 284.08212 Test MSE 293.31342767607777 Test RE 0.28830697088902296 Lambda1 -0.00019562953\n",
      "27 Train Loss 283.0236 Test MSE 291.9575707749534 Test RE 0.28763984189186564 Lambda1 0.0011300552\n",
      "28 Train Loss 282.8586 Test MSE 291.5273813882252 Test RE 0.28742785009118366 Lambda1 0.001340345\n",
      "29 Train Loss 282.00708 Test MSE 290.24067667335265 Test RE 0.2867928432642882 Lambda1 0.00046334186\n",
      "30 Train Loss 279.82544 Test MSE 288.0021801664434 Test RE 0.28568475011699124 Lambda1 -0.0014328121\n",
      "31 Train Loss 276.6867 Test MSE 284.2398740743946 Test RE 0.28381259961060884 Lambda1 0.001442857\n",
      "32 Train Loss 274.0439 Test MSE 279.5709658587158 Test RE 0.28147200327239236 Lambda1 0.0040737283\n",
      "33 Train Loss 272.76608 Test MSE 277.79311281817166 Test RE 0.2805756048239486 Lambda1 0.0046474077\n",
      "34 Train Loss 271.71393 Test MSE 278.2716712927872 Test RE 0.2808171767870103 Lambda1 0.002351659\n",
      "35 Train Loss 271.30682 Test MSE 277.71762884085626 Test RE 0.2805374822058317 Lambda1 0.002587888\n",
      "36 Train Loss 270.562 Test MSE 276.55501022835415 Test RE 0.27994965462048227 Lambda1 0.004638879\n",
      "37 Train Loss 270.42355 Test MSE 276.88854349464236 Test RE 0.280118417404971 Lambda1 0.004016966\n",
      "38 Train Loss 270.28348 Test MSE 277.1784482669954 Test RE 0.2802650222804167 Lambda1 0.0033744073\n",
      "39 Train Loss 270.22003 Test MSE 276.92468028040474 Test RE 0.2801366959672703 Lambda1 0.0037378008\n",
      "40 Train Loss 270.16745 Test MSE 276.82365254035767 Test RE 0.280085591531603 Lambda1 0.0038352935\n",
      "41 Train Loss 270.1455 Test MSE 276.8213106809086 Test RE 0.2800844068017754 Lambda1 0.0037469915\n",
      "42 Train Loss 270.13733 Test MSE 276.74198667315085 Test RE 0.2800442743975018 Lambda1 0.0038112428\n",
      "43 Train Loss 270.0588 Test MSE 276.4387309824474 Test RE 0.2798907951604225 Lambda1 0.004234356\n",
      "44 Train Loss 269.79376 Test MSE 276.1612215332346 Test RE 0.2797502724427565 Lambda1 0.004546436\n",
      "45 Train Loss 269.71872 Test MSE 276.0577168248206 Test RE 0.2796978425906583 Lambda1 0.004591306\n",
      "46 Train Loss 269.708 Test MSE 275.95466464101673 Test RE 0.27964563219736743 Lambda1 0.0047362433\n",
      "47 Train Loss 269.6368 Test MSE 275.747365371923 Test RE 0.2795405764878239 Lambda1 0.0052020955\n",
      "48 Train Loss 269.5697 Test MSE 275.93681416171984 Test RE 0.27963658743397757 Lambda1 0.0050188503\n",
      "49 Train Loss 269.53625 Test MSE 276.1278205082727 Test RE 0.2797333543752414 Lambda1 0.00471586\n",
      "50 Train Loss 269.38193 Test MSE 275.8794540234989 Test RE 0.279607521310602 Lambda1 0.0052796076\n",
      "51 Train Loss 268.7408 Test MSE 273.437130373208 Test RE 0.2783671060363193 Lambda1 0.010073697\n",
      "52 Train Loss 262.47488 Test MSE 265.9227032092872 Test RE 0.274515505047492 Lambda1 0.02790925\n",
      "53 Train Loss 249.81148 Test MSE 250.92382319325893 Test RE 0.26666137775785864 Lambda1 0.059775796\n",
      "54 Train Loss 228.63393 Test MSE 225.13534054259839 Test RE 0.2525870073521626 Lambda1 0.113599576\n",
      "55 Train Loss 206.58394 Test MSE 203.68928671340322 Test RE 0.24025545898294445 Lambda1 0.16060667\n",
      "56 Train Loss 181.56216 Test MSE 175.2523248276828 Test RE 0.22285432375489717 Lambda1 0.26742464\n",
      "57 Train Loss 161.32236 Test MSE 149.20121400216814 Test RE 0.20562473190802774 Lambda1 0.35829276\n",
      "58 Train Loss 133.20149 Test MSE 115.4401505183761 Test RE 0.18087044737964256 Lambda1 0.54827964\n",
      "59 Train Loss 112.48308 Test MSE 89.37148918617896 Test RE 0.15914341307133206 Lambda1 0.6222573\n",
      "60 Train Loss 91.61952 Test MSE 72.85811277795511 Test RE 0.143690524304686 Lambda1 0.5789559\n",
      "61 Train Loss 73.44164 Test MSE 55.234256296369246 Test RE 0.12511040386799663 Lambda1 0.61209434\n",
      "62 Train Loss 55.75773 Test MSE 44.88356710876084 Test RE 0.11278019811553783 Lambda1 0.7040072\n",
      "63 Train Loss 47.76996 Test MSE 41.050024315408294 Test RE 0.1078563899534388 Lambda1 0.78097856\n",
      "64 Train Loss 43.36506 Test MSE 39.36419282033918 Test RE 0.10561846365398583 Lambda1 0.802611\n",
      "65 Train Loss 41.115643 Test MSE 39.97153084262175 Test RE 0.10643012232273338 Lambda1 0.7743958\n",
      "66 Train Loss 40.18393 Test MSE 39.806024378050815 Test RE 0.1062095510208619 Lambda1 0.7672107\n",
      "67 Train Loss 39.6901 Test MSE 39.21188423081949 Test RE 0.1054139352630328 Lambda1 0.7843877\n",
      "68 Train Loss 39.003292 Test MSE 39.230397779598015 Test RE 0.10543881746098112 Lambda1 0.78496736\n",
      "69 Train Loss 37.35833 Test MSE 39.678837390314335 Test RE 0.10603973651649846 Lambda1 0.755117\n",
      "70 Train Loss 36.83024 Test MSE 39.87628679155515 Test RE 0.10630324599972571 Lambda1 0.75255036\n",
      "71 Train Loss 36.543106 Test MSE 40.16669234050308 Test RE 0.10668962914695529 Lambda1 0.7495119\n",
      "72 Train Loss 36.2183 Test MSE 40.17452009798321 Test RE 0.10670002457422956 Lambda1 0.74584585\n",
      "73 Train Loss 35.663525 Test MSE 39.80129209942682 Test RE 0.10620323755280268 Lambda1 0.7591475\n",
      "74 Train Loss 35.241444 Test MSE 39.570738701844206 Test RE 0.10589519379593212 Lambda1 0.778413\n",
      "Training time: 251.77\n",
      "Training time: 251.77\n",
      "inv_HT_swish_tune0\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 854.7528 Test MSE 858.0512292927632 Test RE 0.4931122364336368 Lambda1 -1.148121e-07\n",
      "1 Train Loss 854.72107 Test MSE 858.0692877285334 Test RE 0.4931174253946762 Lambda1 -1.3646057e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Train Loss 854.7201 Test MSE 858.0745195272635 Test RE 0.49311892870403845 Lambda1 -1.382017e-07\n",
      "3 Train Loss 854.72 Test MSE 858.0755295244949 Test RE 0.4931192189169482 Lambda1 -1.341914e-07\n",
      "4 Train Loss 854.7196 Test MSE 858.0767852034593 Test RE 0.4931195797238832 Lambda1 -1.1945416e-07\n",
      "5 Train Loss 854.71875 Test MSE 858.080133263228 Test RE 0.49312054175446374 Lambda1 -3.758843e-08\n",
      "6 Train Loss 854.71796 Test MSE 858.0832110544771 Test RE 0.4931214261245059 Lambda1 1.0041202e-07\n",
      "7 Train Loss 854.71686 Test MSE 858.0862106808111 Test RE 0.4931222880331785 Lambda1 4.1038675e-07\n",
      "8 Train Loss 854.7021 Test MSE 858.10055807387 Test RE 0.49312641057333284 Lambda1 1.0154796e-05\n",
      "9 Train Loss 854.58765 Test MSE 857.8334675935643 Test RE 0.49304965988304417 Lambda1 0.0012123251\n",
      "10 Train Loss 854.5368 Test MSE 857.6934740164683 Test RE 0.4930094267815836 Lambda1 0.0051944447\n",
      "11 Train Loss 854.5365 Test MSE 857.6935325087186 Test RE 0.49300944359250226 Lambda1 0.005314832\n",
      "12 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "13 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "14 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "15 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "16 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "17 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "18 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "19 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "20 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "21 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "22 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "23 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "24 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "25 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "26 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "27 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "28 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "29 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "30 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "31 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "32 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "33 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "34 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "35 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "36 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "37 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "38 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "39 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "40 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "41 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "42 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "43 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "44 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "45 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "46 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "47 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "48 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "49 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "50 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "51 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "52 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "53 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "54 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "55 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "56 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "57 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "58 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "59 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "60 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "61 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "62 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "63 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "64 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "65 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "66 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "67 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "68 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "69 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "70 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "71 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "72 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "73 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "74 Train Loss 854.5363 Test MSE 857.6935976607874 Test RE 0.4930094623174801 Lambda1 0.00540524\n",
      "Training time: 248.72\n",
      "Training time: 248.72\n",
      "inv_HT_swish_tune0\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 857.7988 Test MSE 861.7361643602634 Test RE 0.49416994709271417 Lambda1 -2.823519e-07\n",
      "1 Train Loss 854.7359 Test MSE 858.1227536976398 Test RE 0.49313278813444766 Lambda1 4.0268013e-08\n",
      "2 Train Loss 854.72577 Test MSE 858.086256329039 Test RE 0.49312230114966843 Lambda1 1.9472269e-07\n",
      "3 Train Loss 854.7234 Test MSE 858.0743955299024 Test RE 0.49311889307458745 Lambda1 3.508808e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 854.7062 Test MSE 858.0207529260088 Test RE 0.49310347914601704 Lambda1 4.169955e-07\n",
      "5 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "6 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "7 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "8 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "9 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "10 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "11 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "12 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "13 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "14 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "15 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "16 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "17 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "18 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "19 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "20 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "21 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "22 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "23 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "24 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "25 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "26 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "27 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "28 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "29 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "30 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "31 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "32 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "33 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "34 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "35 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "36 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "37 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "38 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "39 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "40 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "41 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "42 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "43 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "44 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "45 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "46 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "47 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "48 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "49 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "50 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "51 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "52 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "53 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "54 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "55 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "56 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "57 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "58 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "59 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "60 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "61 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "62 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "63 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "64 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "65 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "66 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "67 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "68 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "69 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "70 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "71 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "72 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "73 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "74 Train Loss 854.53467 Test MSE 857.7633492394589 Test RE 0.49302950880568264 Lambda1 -0.0006653195\n",
      "Training time: 260.73\n",
      "Training time: 260.73\n",
      "inv_HT_swish_tune0\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 854.9038 Test MSE 858.40917213961 Test RE 0.4932150785413221 Lambda1 3.339107e-07\n",
      "1 Train Loss 854.7254 Test MSE 858.1151601406988 Test RE 0.4931306062553551 Lambda1 3.0878672e-07\n",
      "2 Train Loss 854.7093 Test MSE 858.0621993525963 Test RE 0.49311538860757687 Lambda1 5.1585994e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Train Loss 854.64557 Test MSE 857.9283023784305 Test RE 0.49307691282196664 Lambda1 1.0306757e-05\n",
      "4 Train Loss 854.5218 Test MSE 857.6770470660476 Test RE 0.49300470558430654 Lambda1 0.00085506303\n",
      "5 Train Loss 854.52094 Test MSE 857.6760679825474 Test RE 0.49300442418881385 Lambda1 0.00091523136\n",
      "6 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "7 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "8 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "9 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "10 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "11 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "12 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "13 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "14 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "15 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "16 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "17 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "18 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "19 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "20 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "21 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "22 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "23 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "24 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "25 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "26 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "27 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "28 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "29 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "30 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "31 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "32 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "33 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "34 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "35 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "36 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "37 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "38 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "39 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "40 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "41 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "42 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "43 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "44 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "45 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "46 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "47 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "48 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "49 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "50 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "51 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "52 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "53 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "54 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "55 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "56 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "57 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "58 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "59 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "60 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "61 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "62 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "63 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "64 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "65 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "66 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "67 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "68 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "69 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "70 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "71 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "72 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "73 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "74 Train Loss 854.5203 Test MSE 857.678580735616 Test RE 0.4930051463714179 Lambda1 0.00096758653\n",
      "Training time: 269.74\n",
      "Training time: 269.74\n",
      "inv_HT_swish_tune0\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 855.3004 Test MSE 858.911396509327 Test RE 0.49335933865632203 Lambda1 -3.8325075e-07\n",
      "1 Train Loss 854.7119 Test MSE 858.0734971619994 Test RE 0.49311863493712066 Lambda1 -1.0587271e-07\n",
      "2 Train Loss 854.70795 Test MSE 858.0603001721712 Test RE 0.4931148428921193 Lambda1 1.3124813e-07\n",
      "3 Train Loss 854.6494 Test MSE 857.9280549186894 Test RE 0.4930768417107247 Lambda1 9.294137e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 854.51697 Test MSE 857.6454218614049 Test RE 0.4929956161965903 Lambda1 0.0001948965\n",
      "5 Train Loss 854.51025 Test MSE 857.641088508971 Test RE 0.4929943707364052 Lambda1 0.00025441492\n",
      "6 Train Loss 854.50995 Test MSE 857.6426138219833 Test RE 0.4929948091309763 Lambda1 0.00026252677\n",
      "7 Train Loss 854.5099 Test MSE 857.6434435326654 Test RE 0.4929950476003304 Lambda1 0.00026810623\n",
      "8 Train Loss 854.50977 Test MSE 857.6441982737144 Test RE 0.49299526452236275 Lambda1 0.00027447895\n",
      "9 Train Loss 854.5097 Test MSE 857.6449535834981 Test RE 0.4929954816077609 Lambda1 0.00028253085\n",
      "10 Train Loss 854.5096 Test MSE 857.6456894594452 Test RE 0.49299569310754154 Lambda1 0.00029223002\n",
      "11 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "12 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "13 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "14 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "15 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "16 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "17 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "18 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "19 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "20 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "21 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "22 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "23 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "24 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "25 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "26 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "27 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "28 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "29 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "30 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "31 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "32 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "33 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "34 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "35 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "36 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "37 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "38 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "39 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "40 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "41 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "42 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "43 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "44 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "45 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "46 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "47 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "48 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "49 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "50 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "51 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "52 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "53 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "54 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "55 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "56 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "57 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "58 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "59 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "60 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "61 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "62 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "63 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "64 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "65 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "66 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "67 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "68 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "69 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "70 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "71 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "72 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "73 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "74 Train Loss 854.50946 Test MSE 857.6462279316712 Test RE 0.4929958478710121 Lambda1 0.00030066687\n",
      "Training time: 302.42\n",
      "Training time: 302.42\n",
      "inv_HT_swish_tune0\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 854.7943 Test MSE 858.085249680455 Test RE 0.49312201190076826 Lambda1 -1.2803536e-06\n",
      "1 Train Loss 854.752 Test MSE 858.103292665812 Test RE 0.4931271963194915 Lambda1 -3.407561e-06\n",
      "2 Train Loss 854.7515 Test MSE 858.1048562202736 Test RE 0.49312764558409833 Lambda1 -3.7075806e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Train Loss 854.74945 Test MSE 858.1114009566493 Test RE 0.493129526114352 Lambda1 -6.1682767e-06\n",
      "4 Train Loss 854.7457 Test MSE 858.1202622296141 Test RE 0.4931320722546621 Lambda1 -1.3536946e-05\n",
      "5 Train Loss 854.73627 Test MSE 858.1299588645459 Test RE 0.4931348584073612 Lambda1 -3.717556e-05\n",
      "6 Train Loss 854.56964 Test MSE 857.897767099309 Test RE 0.49306813797732507 Lambda1 -0.0007640358\n",
      "7 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "8 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "9 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "10 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "11 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "12 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "13 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "14 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "15 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "16 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "17 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "18 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "19 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "20 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "21 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "22 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "23 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "24 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "25 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "26 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "27 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "28 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "29 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "30 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "31 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "32 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "33 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "34 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "35 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "36 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "37 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "38 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "39 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "40 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "41 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "42 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "43 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "44 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "45 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "46 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "47 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "48 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "49 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "50 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "51 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "52 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "53 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "54 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "55 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "56 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "57 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "58 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "59 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "60 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "61 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "62 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "63 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "64 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "65 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "66 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "67 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "68 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "69 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "70 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "71 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "72 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "73 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "74 Train Loss 854.52795 Test MSE 857.7284238266981 Test RE 0.49301947140177876 Lambda1 -0.0013072285\n",
      "Training time: 335.42\n",
      "Training time: 335.42\n",
      "inv_HT_swish_tune0\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 854.75165 Test MSE 858.1063699089119 Test RE 0.49312808052009693 Lambda1 9.741591e-07\n",
      "1 Train Loss 854.5337 Test MSE 857.7447841324876 Test RE 0.4930241733042843 Lambda1 0.0033775978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Train Loss 854.52783 Test MSE 857.7007754544458 Test RE 0.49301152524111513 Lambda1 0.0062619452\n",
      "3 Train Loss 854.5273 Test MSE 857.691718358007 Test RE 0.49300892219769626 Lambda1 0.007825994\n",
      "4 Train Loss 854.52716 Test MSE 857.6891460306058 Test RE 0.49300818289866655 Lambda1 0.008854957\n",
      "5 Train Loss 854.52655 Test MSE 857.6821117510092 Test RE 0.493006161207866 Lambda1 0.012852614\n",
      "6 Train Loss 854.5256 Test MSE 857.6681644302754 Test RE 0.4930021526463522 Lambda1 0.024091113\n",
      "7 Train Loss 854.514 Test MSE 857.5559134848099 Test RE 0.4929698897206209 Lambda1 0.2070348\n",
      "8 Train Loss 854.2104 Test MSE 857.5316200500645 Test RE 0.49296290707583007 Lambda1 2.0308423\n",
      "9 Train Loss 850.54285 Test MSE 850.3056350912204 Test RE 0.49088153867754286 Lambda1 4.575272\n",
      "10 Train Loss 827.26807 Test MSE 821.6396294684679 Test RE 0.48253615541073774 Lambda1 3.9940412\n",
      "11 Train Loss 721.91223 Test MSE 705.3602399867674 Test RE 0.44708969345952737 Lambda1 2.8662083\n",
      "12 Train Loss 638.13055 Test MSE 616.1030718321238 Test RE 0.41784562346620446 Lambda1 2.7833467\n",
      "13 Train Loss 588.04694 Test MSE 583.1894032768181 Test RE 0.4065312942991379 Lambda1 3.1011858\n",
      "14 Train Loss 561.90326 Test MSE 563.8904321823067 Test RE 0.39974821531864785 Lambda1 3.4404867\n",
      "15 Train Loss 547.49713 Test MSE 545.9728711126656 Test RE 0.39334596765783186 Lambda1 3.4218242\n",
      "16 Train Loss 537.73663 Test MSE 531.5924585365416 Test RE 0.38813121897458747 Lambda1 3.4346738\n",
      "17 Train Loss 517.5642 Test MSE 518.1692274209615 Test RE 0.38319954045761573 Lambda1 3.1584265\n",
      "18 Train Loss 501.14563 Test MSE 500.4341734753527 Test RE 0.3765846815618862 Lambda1 3.1744163\n",
      "19 Train Loss 458.77588 Test MSE 436.3246873703468 Test RE 0.35163659315483564 Lambda1 2.8331084\n",
      "20 Train Loss 404.2486 Test MSE 381.28391420525975 Test RE 0.3287103753973498 Lambda1 2.5291665\n",
      "21 Train Loss 344.86877 Test MSE 322.5185910600556 Test RE 0.30231976935494015 Lambda1 2.428809\n",
      "22 Train Loss 304.2432 Test MSE 292.2804173221796 Test RE 0.28779883395298134 Lambda1 2.0360541\n",
      "23 Train Loss 271.25443 Test MSE 242.99040545554 Test RE 0.26241202550009457 Lambda1 1.9131052\n",
      "24 Train Loss 256.09866 Test MSE 229.91913066562557 Test RE 0.25525645001671166 Lambda1 1.855691\n",
      "25 Train Loss 209.6941 Test MSE 194.69181995741272 Test RE 0.23488918610699963 Lambda1 1.8218055\n",
      "26 Train Loss 195.59602 Test MSE 182.72094509709947 Test RE 0.22755340427401693 Lambda1 1.7114016\n",
      "27 Train Loss 178.35867 Test MSE 158.58807139177 Test RE 0.21199441981986303 Lambda1 1.6316152\n",
      "28 Train Loss 166.08173 Test MSE 147.50161546878633 Test RE 0.20445020909164513 Lambda1 1.6141366\n",
      "29 Train Loss 156.58954 Test MSE 135.20856640020043 Test RE 0.19574526915000892 Lambda1 1.5864857\n",
      "30 Train Loss 145.8141 Test MSE 128.00615022967608 Test RE 0.19046035472052214 Lambda1 1.4687773\n",
      "31 Train Loss 134.01157 Test MSE 121.72417357720414 Test RE 0.18572808804597135 Lambda1 1.3462268\n",
      "32 Train Loss 115.17896 Test MSE 102.65777273306993 Test RE 0.1705631033973155 Lambda1 1.268935\n",
      "33 Train Loss 105.34078 Test MSE 95.07413199582905 Test RE 0.16414223976031483 Lambda1 1.211332\n",
      "34 Train Loss 101.56156 Test MSE 89.62290105187687 Test RE 0.1593670998631075 Lambda1 1.1726704\n",
      "35 Train Loss 92.75424 Test MSE 78.86100460492455 Test RE 0.1494928161576321 Lambda1 1.0902077\n",
      "36 Train Loss 90.22535 Test MSE 79.51352466405196 Test RE 0.15011001669097612 Lambda1 1.09572\n",
      "37 Train Loss 85.743904 Test MSE 78.51924068993318 Test RE 0.14916853215425807 Lambda1 1.1289968\n",
      "38 Train Loss 82.528885 Test MSE 74.43418013762084 Test RE 0.14523636648035054 Lambda1 1.1402481\n",
      "39 Train Loss 74.37584 Test MSE 64.8099343445367 Test RE 0.13552204965806974 Lambda1 1.0630562\n",
      "40 Train Loss 67.24951 Test MSE 58.649601267037134 Test RE 0.12892041729161788 Lambda1 1.0257285\n",
      "41 Train Loss 58.161373 Test MSE 52.57868870985708 Test RE 0.12206581243912885 Lambda1 0.92171067\n",
      "42 Train Loss 53.70649 Test MSE 49.34972209667405 Test RE 0.11825827133413307 Lambda1 0.8461299\n",
      "43 Train Loss 46.108776 Test MSE 44.56312189413946 Test RE 0.11237688111807101 Lambda1 0.7681444\n",
      "44 Train Loss 43.419838 Test MSE 44.07489684741193 Test RE 0.11175959593087721 Lambda1 0.74835396\n",
      "45 Train Loss 41.8131 Test MSE 42.943714708242 Test RE 0.11031611912037537 Lambda1 0.7376254\n",
      "46 Train Loss 40.953354 Test MSE 42.006091973413554 Test RE 0.10910516491891617 Lambda1 0.72179425\n",
      "47 Train Loss 40.04813 Test MSE 41.17806292045188 Test RE 0.10802446573692165 Lambda1 0.71914905\n",
      "48 Train Loss 38.714275 Test MSE 40.073051647984535 Test RE 0.10656519370448468 Lambda1 0.72116774\n",
      "49 Train Loss 38.07834 Test MSE 39.62389468500027 Test RE 0.10596629524895916 Lambda1 0.7294591\n",
      "50 Train Loss 35.907036 Test MSE 37.491408462760305 Test RE 0.10307540471742821 Lambda1 0.7722182\n",
      "51 Train Loss 34.105564 Test MSE 36.62863079867192 Test RE 0.10188248119595425 Lambda1 0.79810935\n",
      "52 Train Loss 33.14769 Test MSE 35.861837467578574 Test RE 0.10081042359146486 Lambda1 0.8199829\n",
      "53 Train Loss 32.412403 Test MSE 35.273000336573375 Test RE 0.09997936449417917 Lambda1 0.85616297\n",
      "54 Train Loss 32.233276 Test MSE 35.17172053471833 Test RE 0.09983572531929527 Lambda1 0.8613839\n",
      "55 Train Loss 31.777323 Test MSE 35.12548490905636 Test RE 0.09977008330417324 Lambda1 0.86419165\n",
      "56 Train Loss 31.48958 Test MSE 34.93325166447145 Test RE 0.0994967000384038 Lambda1 0.87611926\n",
      "57 Train Loss 31.18476 Test MSE 34.812400554203585 Test RE 0.09932444719067626 Lambda1 0.8832479\n",
      "58 Train Loss 30.974247 Test MSE 34.755676689831645 Test RE 0.09924349380464106 Lambda1 0.8864586\n",
      "59 Train Loss 30.868713 Test MSE 34.6558899156962 Test RE 0.0991009227556757 Lambda1 0.89817107\n",
      "60 Train Loss 30.770464 Test MSE 34.36700318660843 Test RE 0.09868701254889205 Lambda1 0.9225464\n",
      "61 Train Loss 30.618708 Test MSE 34.11809426715696 Test RE 0.09832898428685008 Lambda1 0.95425475\n",
      "62 Train Loss 30.480711 Test MSE 33.93037609289169 Test RE 0.09805810754070572 Lambda1 0.98492956\n",
      "63 Train Loss 30.354898 Test MSE 33.813391905507245 Test RE 0.097888920605696 Lambda1 1.0040053\n",
      "64 Train Loss 30.332031 Test MSE 33.81856802722849 Test RE 0.09789641269019914 Lambda1 1.0010755\n",
      "65 Train Loss 30.319838 Test MSE 33.869164480796826 Test RE 0.09796961744619068 Lambda1 0.9944478\n",
      "66 Train Loss 30.286459 Test MSE 33.87036976797794 Test RE 0.09797136063170092 Lambda1 0.99462503\n",
      "67 Train Loss 30.249937 Test MSE 33.785341065557425 Test RE 0.09784830894262687 Lambda1 0.99765253\n",
      "68 Train Loss 30.166965 Test MSE 33.632372934101134 Test RE 0.09762654629255572 Lambda1 0.9945584\n",
      "69 Train Loss 30.129704 Test MSE 33.64194183705215 Test RE 0.09764043339637823 Lambda1 0.9902955\n",
      "70 Train Loss 30.114923 Test MSE 33.626090295123184 Test RE 0.09761742738511257 Lambda1 0.997018\n",
      "71 Train Loss 30.092037 Test MSE 33.531553462774866 Test RE 0.09748010934336607 Lambda1 1.0023454\n",
      "72 Train Loss 30.04003 Test MSE 33.456140495175845 Test RE 0.09737043052597912 Lambda1 1.00218\n",
      "73 Train Loss 30.000404 Test MSE 33.37210818625973 Test RE 0.09724807023101624 Lambda1 1.0074134\n",
      "74 Train Loss 29.97436 Test MSE 33.31038864397122 Test RE 0.09715810162542128 Lambda1 1.0043492\n",
      "Training time: 331.75\n",
      "Training time: 331.75\n",
      "inv_HT_swish_tune1\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 854.71704 Test MSE 858.0863715278829 Test RE 0.4931223342507213 Lambda1 -3.2490163e-07\n",
      "1 Train Loss 854.71545 Test MSE 858.0730977414718 Test RE 0.49311852016738994 Lambda1 -4.4152569e-07\n",
      "2 Train Loss 854.71515 Test MSE 858.0711335343506 Test RE 0.49311795577056533 Lambda1 -5.2799754e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Train Loss 854.7045 Test MSE 858.026549683409 Test RE 0.493105144837904 Lambda1 -8.475499e-06\n",
      "4 Train Loss 854.5284 Test MSE 857.6007268127445 Test RE 0.4929827701243236 Lambda1 0.00016688413\n",
      "5 Train Loss 854.51666 Test MSE 857.6599805787785 Test RE 0.492999800532681 Lambda1 0.00031684685\n",
      "6 Train Loss 854.5165 Test MSE 857.6648030742722 Test RE 0.4930011865632924 Lambda1 0.0003691849\n",
      "7 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "8 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "9 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "10 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "11 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "12 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "13 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "14 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "15 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "16 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "17 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "18 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "19 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "20 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "21 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "22 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "23 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "24 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "25 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "26 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "27 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "28 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "29 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "30 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "31 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "32 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "33 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "34 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "35 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "36 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "37 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "38 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "39 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "40 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "41 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "42 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "43 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "44 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "45 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "46 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "47 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "48 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "49 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "50 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "51 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "52 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "53 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "54 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "55 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "56 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "57 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "58 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "59 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "60 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "61 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "62 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "63 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "64 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "65 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "66 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "67 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "68 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "69 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "70 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "71 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "72 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "73 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "74 Train Loss 854.5163 Test MSE 857.6657451039733 Test RE 0.4930014573110433 Lambda1 0.0003862071\n",
      "Training time: 266.59\n",
      "Training time: 266.59\n",
      "inv_HT_swish_tune1\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 854.75415 Test MSE 858.1207249248039 Test RE 0.4931322052021153 Lambda1 2.0186455e-06\n",
      "1 Train Loss 854.75305 Test MSE 858.1126731934634 Test RE 0.4931298916713788 Lambda1 2.863849e-06\n",
      "2 Train Loss 854.7507 Test MSE 858.0990611884628 Test RE 0.49312598046403916 Lambda1 1.1396625e-05\n",
      "3 Train Loss 854.73315 Test MSE 858.0515260370404 Test RE 0.4931123217014021 Lambda1 0.00010852379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Train Loss 854.552 Test MSE 857.8404880961565 Test RE 0.49305167743625467 Lambda1 0.0037293518\n",
      "5 Train Loss 854.51935 Test MSE 857.6578784754686 Test RE 0.49299919636717787 Lambda1 0.019434981\n",
      "6 Train Loss 854.5192 Test MSE 857.6564905957478 Test RE 0.4929987974762675 Lambda1 0.020864919\n",
      "7 Train Loss 854.5181 Test MSE 857.6503728874918 Test RE 0.49299703918012866 Lambda1 0.032299455\n",
      "8 Train Loss 854.2816 Test MSE 857.3559352325029 Test RE 0.4929124071685205 Lambda1 0.61467415\n",
      "9 Train Loss 851.25916 Test MSE 853.0071672232516 Test RE 0.4916607176816348 Lambda1 1.5766397\n",
      "10 Train Loss 824.6035 Test MSE 822.0535572009866 Test RE 0.48265768676102433 Lambda1 1.3668755\n",
      "11 Train Loss 792.194 Test MSE 784.7055358219517 Test RE 0.4715660477804572 Lambda1 1.2551804\n",
      "12 Train Loss 768.6304 Test MSE 760.581476076477 Test RE 0.4642608290712097 Lambda1 1.2699544\n",
      "13 Train Loss 727.1885 Test MSE 711.4499260721954 Test RE 0.44901550706007826 Lambda1 1.3500056\n",
      "14 Train Loss 681.29254 Test MSE 675.3585981507159 Test RE 0.4374781705427519 Lambda1 1.5440987\n",
      "15 Train Loss 603.0563 Test MSE 583.5447391246979 Test RE 0.40665512469111637 Lambda1 2.0370562\n",
      "16 Train Loss 541.601 Test MSE 529.2366541410651 Test RE 0.38727024315715647 Lambda1 2.0716856\n",
      "17 Train Loss 509.0057 Test MSE 470.06971286367747 Test RE 0.36498104107067403 Lambda1 2.209092\n",
      "18 Train Loss 433.7237 Test MSE 390.2674169857447 Test RE 0.33256023442416466 Lambda1 2.3177953\n",
      "19 Train Loss 385.4196 Test MSE 345.22434136848244 Test RE 0.31278064831488517 Lambda1 2.4069417\n",
      "20 Train Loss 354.75598 Test MSE 280.2141260672765 Test RE 0.28179558407485966 Lambda1 2.4601362\n",
      "21 Train Loss 320.71713 Test MSE 251.8136743608797 Test RE 0.26713378992880576 Lambda1 2.4537883\n",
      "22 Train Loss 228.0257 Test MSE 177.63037905573242 Test RE 0.2243612194972152 Lambda1 2.444584\n",
      "23 Train Loss 204.24576 Test MSE 153.809904077454 Test RE 0.20877635993530028 Lambda1 2.4269001\n",
      "24 Train Loss 197.87003 Test MSE 156.3841438292834 Test RE 0.21051620339135854 Lambda1 2.3604944\n",
      "25 Train Loss 179.44717 Test MSE 151.0182150450129 Test RE 0.2068730117018709 Lambda1 2.2328954\n",
      "26 Train Loss 162.55893 Test MSE 130.7012709214692 Test RE 0.19245494564926308 Lambda1 2.1641083\n",
      "27 Train Loss 143.03664 Test MSE 111.7403047151407 Test RE 0.17794840362590397 Lambda1 2.1979587\n",
      "28 Train Loss 128.22766 Test MSE 105.754300802491 Test RE 0.17311639102973767 Lambda1 2.1178215\n",
      "29 Train Loss 117.13732 Test MSE 91.22334284652386 Test RE 0.16078375311291448 Lambda1 2.0120084\n",
      "30 Train Loss 93.1811 Test MSE 76.97894414122017 Test RE 0.14769818061663617 Lambda1 1.8985798\n",
      "31 Train Loss 72.60663 Test MSE 61.57996583932835 Test RE 0.1321018478065175 Lambda1 1.6817394\n",
      "32 Train Loss 58.400917 Test MSE 54.26333503621913 Test RE 0.12400591798540861 Lambda1 1.5837207\n",
      "33 Train Loss 54.54777 Test MSE 51.1283257941649 Test RE 0.12037047008478273 Lambda1 1.5202966\n",
      "34 Train Loss 51.243786 Test MSE 48.444630738175626 Test RE 0.11716880364966482 Lambda1 1.4283938\n",
      "35 Train Loss 50.562912 Test MSE 47.74379206130619 Test RE 0.11631818732354066 Lambda1 1.389805\n",
      "36 Train Loss 49.909645 Test MSE 48.21427698963554 Test RE 0.1168899034511183 Lambda1 1.4136634\n",
      "37 Train Loss 49.159832 Test MSE 48.1741486130529 Test RE 0.11684125003607397 Lambda1 1.4048147\n",
      "38 Train Loss 48.6616 Test MSE 47.56146229158617 Test RE 0.11609586988368822 Lambda1 1.3677958\n",
      "39 Train Loss 48.140957 Test MSE 47.05728177565428 Test RE 0.11547888690484429 Lambda1 1.3238565\n",
      "40 Train Loss 46.69272 Test MSE 46.025299719148755 Test RE 0.11420562196023912 Lambda1 1.2526567\n",
      "41 Train Loss 43.887203 Test MSE 44.00316198423935 Test RE 0.11166861075984635 Lambda1 1.1477435\n",
      "42 Train Loss 41.64725 Test MSE 42.40644562743297 Test RE 0.109623864279379 Lambda1 1.070898\n",
      "43 Train Loss 40.046616 Test MSE 41.18603080898756 Test RE 0.10803491651104491 Lambda1 1.0084366\n",
      "44 Train Loss 37.771397 Test MSE 40.438280379640005 Test RE 0.10704971371624036 Lambda1 0.9193883\n",
      "45 Train Loss 37.31307 Test MSE 40.58321156840549 Test RE 0.10724137574587807 Lambda1 0.8823207\n",
      "46 Train Loss 37.12897 Test MSE 40.44725493213114 Test RE 0.10706159194112985 Lambda1 0.872111\n",
      "47 Train Loss 36.776596 Test MSE 40.25466266247011 Test RE 0.1068063973847583 Lambda1 0.89688706\n",
      "48 Train Loss 36.55316 Test MSE 40.09330449269181 Test RE 0.10659211922682177 Lambda1 0.9182152\n",
      "49 Train Loss 36.490944 Test MSE 40.053860097391535 Test RE 0.10653967286012755 Lambda1 0.9136691\n",
      "50 Train Loss 36.27666 Test MSE 40.07918437570579 Test RE 0.106573347691872 Lambda1 0.9065307\n",
      "51 Train Loss 36.166523 Test MSE 40.1456527776484 Test RE 0.10666168314179604 Lambda1 0.8952519\n",
      "52 Train Loss 35.58079 Test MSE 40.04020885765335 Test RE 0.1065215157766877 Lambda1 0.8507424\n",
      "53 Train Loss 35.424774 Test MSE 40.114129112158444 Test RE 0.10661979781541035 Lambda1 0.8517782\n",
      "54 Train Loss 35.414436 Test MSE 40.10576254917599 Test RE 0.10660867844436542 Lambda1 0.85398656\n",
      "55 Train Loss 35.362152 Test MSE 39.96110305939956 Test RE 0.10641623865837105 Lambda1 0.8818554\n",
      "56 Train Loss 35.201042 Test MSE 39.750722986516706 Test RE 0.10613574840605194 Lambda1 0.90229714\n",
      "57 Train Loss 35.135548 Test MSE 39.579629337832294 Test RE 0.10590708923655022 Lambda1 0.9028242\n",
      "58 Train Loss 35.101463 Test MSE 39.541739791453715 Test RE 0.10585638471439736 Lambda1 0.91151583\n",
      "59 Train Loss 35.06285 Test MSE 39.49890380700997 Test RE 0.10579903150742895 Lambda1 0.93238956\n",
      "60 Train Loss 35.0381 Test MSE 39.46355015382349 Test RE 0.10575167298298117 Lambda1 0.9456309\n",
      "61 Train Loss 35.030453 Test MSE 39.433164956715736 Test RE 0.10571095307592941 Lambda1 0.9510834\n",
      "62 Train Loss 35.008884 Test MSE 39.357796195873945 Test RE 0.10560988188146003 Lambda1 0.9512103\n",
      "63 Train Loss 34.96634 Test MSE 39.28003993630288 Test RE 0.10550550752531068 Lambda1 0.9286201\n",
      "64 Train Loss 34.945393 Test MSE 39.30364139854224 Test RE 0.10553719932508601 Lambda1 0.9111445\n",
      "65 Train Loss 34.923203 Test MSE 39.30233682873984 Test RE 0.10553544781071142 Lambda1 0.9115116\n",
      "66 Train Loss 34.830956 Test MSE 39.12519409771434 Test RE 0.10529734555249688 Lambda1 0.9253921\n",
      "67 Train Loss 34.759666 Test MSE 38.98382366529045 Test RE 0.10510693879874443 Lambda1 0.93011165\n",
      "68 Train Loss 34.665825 Test MSE 38.824328949169534 Test RE 0.10489170615074653 Lambda1 0.9376031\n",
      "69 Train Loss 34.600784 Test MSE 38.70938942100389 Test RE 0.10473632497767425 Lambda1 0.9419732\n",
      "70 Train Loss 34.583294 Test MSE 38.67022558974973 Test RE 0.10468332861358885 Lambda1 0.9406449\n",
      "71 Train Loss 34.502735 Test MSE 38.45003195922044 Test RE 0.10438486243038504 Lambda1 0.9388618\n",
      "72 Train Loss 34.309734 Test MSE 38.15372222130234 Test RE 0.10398187093368984 Lambda1 0.93885165\n",
      "73 Train Loss 34.173466 Test MSE 38.19910249042227 Test RE 0.10404369089155516 Lambda1 0.9329043\n",
      "74 Train Loss 34.122444 Test MSE 38.220969362677565 Test RE 0.10407346625863043 Lambda1 0.9256916\n",
      "Training time: 327.06\n",
      "Training time: 327.06\n",
      "inv_HT_swish_tune1\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 854.7353 Test MSE 858.1132443017433 Test RE 0.49313005577017727 Lambda1 2.4166357e-06\n",
      "1 Train Loss 854.732 Test MSE 858.0951573925556 Test RE 0.4931248587605782 Lambda1 2.3968635e-06\n",
      "2 Train Loss 854.7315 Test MSE 858.0893205866154 Test RE 0.49312318162781815 Lambda1 2.3525151e-06\n",
      "3 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "4 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "5 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "7 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "8 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "9 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "10 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "11 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "12 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "13 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "14 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "15 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "16 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "17 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "18 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "19 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "20 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "21 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "22 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "23 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "24 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "25 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "26 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "27 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "28 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "29 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "30 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "31 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "32 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "33 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "34 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "35 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "36 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "37 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "38 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "39 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "40 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "41 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "42 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "43 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "44 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "45 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "46 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "47 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "48 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "49 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "50 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "51 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "52 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "53 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "54 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "55 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "56 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "57 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "58 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "59 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "60 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "61 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "62 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "63 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "64 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "65 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "66 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "67 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "68 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "69 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "70 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "71 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "72 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "73 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "74 Train Loss 854.7312 Test MSE 858.0878224287709 Test RE 0.4931227511500883 Lambda1 2.3245125e-06\n",
      "Training time: 255.24\n",
      "Training time: 255.24\n",
      "inv_HT_swish_tune1\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 861.7907 Test MSE 864.2665183600184 Test RE 0.4948949418066279 Lambda1 2.0611405e-07\n",
      "1 Train Loss 855.2962 Test MSE 858.3995882967722 Test RE 0.49321232524537356 Lambda1 -4.3962135e-07\n",
      "2 Train Loss 854.74603 Test MSE 858.0243642518336 Test RE 0.49310451685719625 Lambda1 -1.9967033e-06\n",
      "3 Train Loss 854.65155 Test MSE 858.0457946568631 Test RE 0.4931106748195892 Lambda1 -1.5370817e-05\n",
      "4 Train Loss 854.49976 Test MSE 857.6665695820788 Test RE 0.4930016942732936 Lambda1 0.00014505068\n",
      "5 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "7 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "8 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "9 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "10 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "11 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "12 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "13 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "14 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "15 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "16 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "17 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "18 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "19 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "20 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "21 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "22 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "23 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "24 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "25 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "26 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "27 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "28 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "29 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "30 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "31 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "32 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "33 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "34 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "35 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "36 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "37 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "38 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "39 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "40 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "41 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "42 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "43 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "44 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "45 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "46 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "47 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "48 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "49 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "50 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "51 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "52 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "53 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "54 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "55 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "56 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "57 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "58 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "59 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "60 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "61 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "62 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "63 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "64 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "65 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "66 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "67 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "68 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "69 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "70 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "71 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "72 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "73 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "74 Train Loss 854.4986 Test MSE 857.6545533657098 Test RE 0.4929982406958846 Lambda1 0.00018645004\n",
      "Training time: 313.28\n",
      "Training time: 313.28\n",
      "inv_HT_swish_tune1\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 854.72876 Test MSE 858.1230030602668 Test RE 0.4931328597843823 Lambda1 -6.6211547e-09\n",
      "1 Train Loss 854.7168 Test MSE 858.0789285748815 Test RE 0.4931201955998591 Lambda1 1.7339016e-07\n",
      "2 Train Loss 854.7162 Test MSE 858.0729092547728 Test RE 0.4931184660075011 Lambda1 5.263271e-07\n",
      "3 Train Loss 854.71564 Test MSE 858.0674563873697 Test RE 0.4931168991745128 Lambda1 1.4713121e-06\n",
      "4 Train Loss 854.715 Test MSE 858.0640813274517 Test RE 0.4931159293785455 Lambda1 2.4886624e-06\n",
      "5 Train Loss 854.7031 Test MSE 858.0203592841126 Test RE 0.4931033660332455 Lambda1 3.0440218e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Train Loss 854.53546 Test MSE 857.667078883072 Test RE 0.4930018406508161 Lambda1 0.0033559122\n",
      "7 Train Loss 854.53357 Test MSE 857.682814167551 Test RE 0.49300636308663154 Lambda1 0.0038313537\n",
      "8 Train Loss 854.53345 Test MSE 857.6849927809081 Test RE 0.493006989232771 Lambda1 0.0040013664\n",
      "9 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "10 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "11 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "12 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "13 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "14 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "15 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "16 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "17 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "18 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "19 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "20 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "21 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "22 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "23 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "24 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "25 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "26 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "27 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "28 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "29 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "30 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "31 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "32 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "33 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "34 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "35 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "36 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "37 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "38 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "39 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "40 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "41 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "42 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "43 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "44 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "45 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "46 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "47 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "48 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "49 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "50 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "51 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "52 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "53 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "54 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "55 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "56 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "57 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "58 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "59 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "60 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "61 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "62 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "63 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "64 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "65 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "66 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "67 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "68 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "69 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "70 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "71 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "72 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "73 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "74 Train Loss 854.5333 Test MSE 857.6856361331169 Test RE 0.4930071741357823 Lambda1 0.004070326\n",
      "Training time: 272.54\n",
      "Training time: 272.54\n",
      "inv_HT_swish_tune1\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 854.7337 Test MSE 858.0874402559333 Test RE 0.4931226413372363 Lambda1 -2.6753867e-07\n",
      "1 Train Loss 854.57983 Test MSE 857.8923227157403 Test RE 0.4930665734224151 Lambda1 -0.00035610012\n",
      "2 Train Loss 854.5362 Test MSE 857.7341132407126 Test RE 0.49302110652728043 Lambda1 -0.0018789184\n",
      "3 Train Loss 854.53033 Test MSE 857.7087485362664 Test RE 0.49301381672330025 Lambda1 -0.0027447261\n",
      "4 Train Loss 854.52966 Test MSE 857.7014354520859 Test RE 0.4930117149263701 Lambda1 -0.0032154059\n",
      "5 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "6 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "8 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "9 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "10 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "11 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "12 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "13 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "14 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "15 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "16 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "17 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "18 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "19 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "20 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "21 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "22 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "23 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "24 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "25 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "26 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "27 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "28 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "29 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "30 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "31 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "32 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "33 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "34 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "35 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "36 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "37 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "38 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "39 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "40 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "41 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "42 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "43 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "44 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "45 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "46 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "47 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "48 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "49 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "50 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "51 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "52 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "53 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "54 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "55 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "56 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "57 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "58 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "59 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "60 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "61 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "62 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "63 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "64 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "65 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "66 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "67 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "68 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "69 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "70 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "71 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "72 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "73 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "74 Train Loss 854.52966 Test MSE 857.7010698296249 Test RE 0.4930116098454127 Lambda1 -0.0032536301\n",
      "Training time: 289.42\n",
      "Training time: 289.42\n",
      "inv_HT_swish_tune1\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 854.71857 Test MSE 858.1021718338702 Test RE 0.4931268742645022 Lambda1 4.4136561e-07\n",
      "1 Train Loss 854.71173 Test MSE 858.0682654842844 Test RE 0.4931171316616354 Lambda1 7.341389e-07\n",
      "2 Train Loss 854.6833 Test MSE 857.9850663710158 Test RE 0.4930932245295969 Lambda1 1.2995227e-05\n",
      "3 Train Loss 854.51996 Test MSE 857.6511901115438 Test RE 0.4929972740596055 Lambda1 0.0013582263\n",
      "4 Train Loss 854.5187 Test MSE 857.6703602320723 Test RE 0.4930027837379356 Lambda1 0.0015595537\n",
      "5 Train Loss 854.51843 Test MSE 857.6787849419472 Test RE 0.4930052050616827 Lambda1 0.0017753679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Train Loss 854.51794 Test MSE 857.692474839328 Test RE 0.49300913961378573 Lambda1 0.0025657949\n",
      "7 Train Loss 854.5176 Test MSE 857.6956826473022 Test RE 0.49301006155097005 Lambda1 0.0028482603\n",
      "8 Train Loss 854.51624 Test MSE 857.7182868242203 Test RE 0.49301655803536176 Lambda1 0.0058608376\n",
      "9 Train Loss 854.4222 Test MSE 857.9879403457269 Test RE 0.4930940503809585 Lambda1 0.1626996\n",
      "10 Train Loss 851.59546 Test MSE 851.5665385742099 Test RE 0.4912453637112508 Lambda1 0.50063884\n",
      "11 Train Loss 801.8542 Test MSE 795.8137767770249 Test RE 0.4748920477632972 Lambda1 0.91952443\n",
      "12 Train Loss 774.8765 Test MSE 765.1157667734852 Test RE 0.46564264384362725 Lambda1 1.014344\n",
      "13 Train Loss 720.8136 Test MSE 699.6072671788618 Test RE 0.44526271147823226 Lambda1 0.98766047\n",
      "14 Train Loss 614.4565 Test MSE 571.6844386583462 Test RE 0.4025013636198505 Lambda1 0.8820466\n",
      "15 Train Loss 537.7811 Test MSE 456.1223881859257 Test RE 0.35952563781199265 Lambda1 0.8561764\n",
      "16 Train Loss 372.4426 Test MSE 285.6345120524237 Test RE 0.28450801839377915 Lambda1 0.74556607\n",
      "17 Train Loss 288.1876 Test MSE 266.13640522295526 Test RE 0.2746257865958065 Lambda1 0.6118867\n",
      "18 Train Loss 258.6037 Test MSE 232.44958977698136 Test RE 0.2566572653919159 Lambda1 0.58968776\n",
      "19 Train Loss 205.2086 Test MSE 193.22114212325175 Test RE 0.23400034249802307 Lambda1 0.6420607\n",
      "20 Train Loss 193.91147 Test MSE 174.83241937988376 Test RE 0.22258718360385762 Lambda1 0.651336\n",
      "21 Train Loss 188.86195 Test MSE 170.85284697449237 Test RE 0.22003931314341113 Lambda1 0.6720515\n",
      "22 Train Loss 160.71674 Test MSE 139.67252754336084 Test RE 0.19895033134365278 Lambda1 0.6486918\n",
      "23 Train Loss 144.42017 Test MSE 134.24540695658632 Test RE 0.19504682649017444 Lambda1 0.6215103\n",
      "24 Train Loss 130.33733 Test MSE 115.91935493901134 Test RE 0.1812454648912688 Lambda1 0.5963023\n",
      "25 Train Loss 123.79961 Test MSE 103.09742822773624 Test RE 0.17092795101508934 Lambda1 0.5970779\n",
      "26 Train Loss 87.96744 Test MSE 69.8759953183666 Test RE 0.14071914060876692 Lambda1 0.6186259\n",
      "27 Train Loss 76.595 Test MSE 60.15111630147808 Test RE 0.13056026304084942 Lambda1 0.6591561\n",
      "28 Train Loss 69.11702 Test MSE 53.90220278227463 Test RE 0.12359258829820018 Lambda1 0.6995696\n",
      "29 Train Loss 64.10227 Test MSE 54.772651227389204 Test RE 0.12458651916225984 Lambda1 0.708435\n",
      "30 Train Loss 55.060844 Test MSE 50.931387041928765 Test RE 0.12013842178755305 Lambda1 0.66669714\n",
      "31 Train Loss 49.393974 Test MSE 47.40674522023219 Test RE 0.11590688658188589 Lambda1 0.6588202\n",
      "32 Train Loss 45.961338 Test MSE 46.89019825274932 Test RE 0.11527369255385729 Lambda1 0.6406573\n",
      "33 Train Loss 44.44339 Test MSE 46.862726961731646 Test RE 0.1152399202386895 Lambda1 0.6236091\n",
      "34 Train Loss 43.977627 Test MSE 47.083010898184774 Test RE 0.1155104523108681 Lambda1 0.6153386\n",
      "35 Train Loss 42.478046 Test MSE 45.743056697458556 Test RE 0.11385490931695491 Lambda1 0.6357132\n",
      "36 Train Loss 40.94472 Test MSE 43.20934837204275 Test RE 0.11065678013831738 Lambda1 0.6622797\n",
      "37 Train Loss 39.15835 Test MSE 41.1684904897393 Test RE 0.108011909089735 Lambda1 0.69330937\n",
      "38 Train Loss 38.442577 Test MSE 39.99592220275282 Test RE 0.10646259017523362 Lambda1 0.718725\n",
      "39 Train Loss 36.476505 Test MSE 38.16940210147687 Test RE 0.10400323524238576 Lambda1 0.7726734\n",
      "40 Train Loss 35.462208 Test MSE 37.20837424418389 Test RE 0.10268559359429918 Lambda1 0.80077803\n",
      "41 Train Loss 34.274796 Test MSE 36.49621714398199 Test RE 0.1016981602734694 Lambda1 0.83167464\n",
      "42 Train Loss 32.728508 Test MSE 35.057087126058505 Test RE 0.0996728977737505 Lambda1 0.85686344\n",
      "43 Train Loss 32.51637 Test MSE 34.69053852445193 Test RE 0.09915045043033775 Lambda1 0.8723895\n",
      "44 Train Loss 32.188534 Test MSE 34.62330530983148 Test RE 0.09905432282828441 Lambda1 0.8826267\n",
      "45 Train Loss 31.569786 Test MSE 34.317812130930214 Test RE 0.09861635965154432 Lambda1 0.9004069\n",
      "46 Train Loss 30.895226 Test MSE 33.833830663014204 Test RE 0.09791850098126248 Lambda1 0.9323896\n",
      "47 Train Loss 30.79279 Test MSE 33.759889993207025 Test RE 0.09781144660095523 Lambda1 0.9403556\n",
      "48 Train Loss 30.771463 Test MSE 33.713904472391604 Test RE 0.09774480771308167 Lambda1 0.94462305\n",
      "49 Train Loss 30.746065 Test MSE 33.62023713525402 Test RE 0.09760893107659595 Lambda1 0.95374423\n",
      "50 Train Loss 30.71778 Test MSE 33.5950344738942 Test RE 0.09757233903798916 Lambda1 0.95468384\n",
      "51 Train Loss 30.701553 Test MSE 33.59323687294879 Test RE 0.09756972855584532 Lambda1 0.9518867\n",
      "52 Train Loss 30.696743 Test MSE 33.57500373977728 Test RE 0.09754324639039948 Lambda1 0.95465434\n",
      "53 Train Loss 30.67144 Test MSE 33.55166354613403 Test RE 0.09750933613261092 Lambda1 0.9564419\n",
      "54 Train Loss 30.624115 Test MSE 33.4947515674625 Test RE 0.09742660097164493 Lambda1 0.9638187\n",
      "55 Train Loss 30.610865 Test MSE 33.47278309270276 Test RE 0.0973946457430556 Lambda1 0.9682656\n",
      "56 Train Loss 30.548223 Test MSE 33.441887338904706 Test RE 0.09734968719177092 Lambda1 0.9641003\n",
      "57 Train Loss 30.397463 Test MSE 33.5058767074384 Test RE 0.09744277954493613 Lambda1 0.9564438\n",
      "58 Train Loss 30.3729 Test MSE 33.5547814237281 Test RE 0.09751386668459434 Lambda1 0.94881\n",
      "59 Train Loss 30.289385 Test MSE 33.57937053242712 Test RE 0.0975495894616571 Lambda1 0.9444496\n",
      "60 Train Loss 30.200167 Test MSE 33.465396075080285 Test RE 0.09738389827009342 Lambda1 0.9587184\n",
      "61 Train Loss 30.180033 Test MSE 33.447457689494605 Test RE 0.09735779452887433 Lambda1 0.96018857\n",
      "62 Train Loss 30.154127 Test MSE 33.47572671093205 Test RE 0.09739892812302894 Lambda1 0.9515228\n",
      "63 Train Loss 30.131577 Test MSE 33.527064010792934 Test RE 0.09747358344649826 Lambda1 0.9426949\n",
      "64 Train Loss 30.109123 Test MSE 33.53881077980998 Test RE 0.09749065770320545 Lambda1 0.93693566\n",
      "65 Train Loss 30.064363 Test MSE 33.47501932743915 Test RE 0.09739789903770758 Lambda1 0.9418018\n",
      "66 Train Loss 30.03787 Test MSE 33.444546967986795 Test RE 0.09735355821897879 Lambda1 0.9495076\n",
      "67 Train Loss 30.027575 Test MSE 33.43035181336348 Test RE 0.09733289572529064 Lambda1 0.95481384\n",
      "68 Train Loss 29.992746 Test MSE 33.41417827592903 Test RE 0.09730934814660723 Lambda1 0.96135074\n",
      "69 Train Loss 29.941448 Test MSE 33.37535243845004 Test RE 0.09725279707649656 Lambda1 0.968723\n",
      "70 Train Loss 29.918842 Test MSE 33.380253262585214 Test RE 0.09725993709637583 Lambda1 0.9738008\n",
      "71 Train Loss 29.913065 Test MSE 33.38614109778074 Test RE 0.0972685144014442 Lambda1 0.9773662\n",
      "72 Train Loss 29.910984 Test MSE 33.39119645462362 Test RE 0.0972758783617686 Lambda1 0.97986704\n",
      "73 Train Loss 29.909676 Test MSE 33.386118724181536 Test RE 0.09726848180937082 Lambda1 0.98053193\n",
      "74 Train Loss 29.90854 Test MSE 33.382141354656476 Test RE 0.09726268772139296 Lambda1 0.9804063\n",
      "Training time: 307.67\n",
      "Training time: 307.67\n",
      "inv_HT_swish_tune1\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 863.83746 Test MSE 866.1926207733296 Test RE 0.49544609577789356 Lambda1 -4.0523227e-07\n",
      "1 Train Loss 855.6604 Test MSE 858.6968626217244 Test RE 0.49329772059692106 Lambda1 -4.797802e-07\n",
      "2 Train Loss 854.82806 Test MSE 858.0775934070244 Test RE 0.493119811953047 Lambda1 -5.0549255e-07\n",
      "3 Train Loss 854.718 Test MSE 858.0694707108578 Test RE 0.4931174779730455 Lambda1 -4.3737143e-07\n",
      "4 Train Loss 854.7135 Test MSE 858.0850783264484 Test RE 0.49312196266414715 Lambda1 -1.36326e-07\n",
      "5 Train Loss 854.6109 Test MSE 857.9740044625944 Test RE 0.49309004582061444 Lambda1 1.8209132e-05\n",
      "6 Train Loss 854.5094 Test MSE 857.6512601531433 Test RE 0.49299729419035176 Lambda1 0.00013560697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "8 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "9 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "10 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "11 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "12 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "13 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "14 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "15 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "16 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "17 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "18 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "19 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "20 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "21 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "22 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "23 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "24 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "25 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "26 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "27 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "28 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "29 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "30 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "31 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "32 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "33 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "34 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "35 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "36 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "37 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "38 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "39 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "40 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "41 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "42 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "43 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "44 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "45 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "46 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "47 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "48 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "49 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "50 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "51 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "52 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "53 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "54 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "55 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "56 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "57 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "58 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "59 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "60 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "61 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "62 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "63 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "64 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "65 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "66 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "67 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "68 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "69 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "70 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "71 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "72 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "73 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "74 Train Loss 854.509 Test MSE 857.6480063790094 Test RE 0.4929963590180739 Lambda1 0.00014583622\n",
      "Training time: 237.74\n",
      "Training time: 237.74\n",
      "inv_HT_swish_tune1\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 854.74554 Test MSE 858.0731191282939 Test RE 0.49311852631269265 Lambda1 -1.1707033e-06\n",
      "1 Train Loss 854.7359 Test MSE 858.0952958425652 Test RE 0.49312489854237734 Lambda1 -1.8964454e-06\n",
      "2 Train Loss 854.73425 Test MSE 858.1016326758053 Test RE 0.4931267193450871 Lambda1 -3.7251953e-06\n",
      "3 Train Loss 854.6877 Test MSE 858.0888601338089 Test RE 0.4931230493222539 Lambda1 -7.2116e-05\n",
      "4 Train Loss 854.62506 Test MSE 857.9617309022885 Test RE 0.49308651891185845 Lambda1 -0.00030234148\n",
      "5 Train Loss 854.5497 Test MSE 857.7041452859693 Test RE 0.49301249373980055 Lambda1 -0.0010376049\n",
      "6 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "7 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "9 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "10 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "11 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "12 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "13 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "14 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "15 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "16 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "17 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "18 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "19 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "20 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "21 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "22 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "23 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "24 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "25 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "26 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "27 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "28 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "29 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "30 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "31 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "32 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "33 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "34 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "35 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "36 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "37 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "38 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "39 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "40 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "41 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "42 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "43 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "44 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "45 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "46 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "47 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "48 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "49 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "50 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "51 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "52 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "53 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "54 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "55 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "56 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "57 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "58 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "59 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "60 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "61 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "62 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "63 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "64 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "65 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "66 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "67 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "68 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "69 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "70 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "71 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "72 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "73 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "74 Train Loss 854.52246 Test MSE 857.6951073058332 Test RE 0.49300989619559615 Lambda1 -0.0015262965\n",
      "Training time: 285.91\n",
      "Training time: 285.91\n",
      "inv_HT_swish_tune1\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 854.74915 Test MSE 858.0900217803446 Test RE 0.4931233831073166 Lambda1 2.0003527e-06\n",
      "1 Train Loss 854.7449 Test MSE 858.1073207731195 Test RE 0.49312835373663977 Lambda1 6.8254276e-06\n",
      "2 Train Loss 854.67737 Test MSE 858.052732881598 Test RE 0.4931126684811085 Lambda1 0.00026331763\n",
      "3 Train Loss 854.65643 Test MSE 857.9940839341053 Test RE 0.49309581576792494 Lambda1 0.0005597825\n",
      "4 Train Loss 854.5565 Test MSE 857.6626626308981 Test RE 0.49300057138019415 Lambda1 0.0023514538\n",
      "5 Train Loss 854.53015 Test MSE 857.6599994454988 Test RE 0.49299980595516163 Lambda1 0.0029929117\n",
      "6 Train Loss 854.5274 Test MSE 857.6728821519647 Test RE 0.49300350855755787 Lambda1 0.003501555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "8 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "9 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "10 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "11 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "12 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "13 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "14 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "15 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "16 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "17 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "18 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "19 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "20 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "21 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "22 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "23 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "24 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "25 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "26 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "27 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "28 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "29 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "30 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "31 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "32 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "33 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "34 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "35 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "36 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "37 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "38 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "39 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "40 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "41 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "42 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "43 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "44 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "45 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "46 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "47 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "48 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "49 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "50 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "51 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "52 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "53 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "54 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "55 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "56 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "57 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "58 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "59 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "60 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "61 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "62 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "63 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "64 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "65 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "66 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "67 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "68 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "69 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "70 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "71 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "72 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "73 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "74 Train Loss 854.52704 Test MSE 857.6783804615507 Test RE 0.49300508881130567 Lambda1 0.0038048693\n",
      "Training time: 286.25\n",
      "Training time: 286.25\n",
      "inv_HT_swish_tune2\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 855.05383 Test MSE 858.6109957945768 Test RE 0.49327305591552056 Lambda1 -1.1094235e-06\n",
      "1 Train Loss 854.68933 Test MSE 858.0562440572805 Test RE 0.49311367739546336 Lambda1 -3.3183942e-06\n",
      "2 Train Loss 854.6805 Test MSE 858.0145823969826 Test RE 0.49310170604508025 Lambda1 -1.4940925e-05\n",
      "3 Train Loss 854.5735 Test MSE 857.6979665341424 Test RE 0.49301071794837575 Lambda1 -0.000101746875\n",
      "4 Train Loss 854.51715 Test MSE 857.6635390530545 Test RE 0.4930008232720698 Lambda1 0.00030534356\n",
      "5 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "7 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "8 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "9 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "10 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "11 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "12 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "13 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "14 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "15 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "16 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "17 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "18 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "19 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "20 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "21 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "22 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "23 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "24 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "25 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "26 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "27 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "28 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "29 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "30 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "31 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "32 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "33 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "34 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "35 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "36 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "37 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "38 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "39 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "40 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "41 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "42 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "43 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "44 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "45 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "46 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "47 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "48 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "49 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "50 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "51 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "52 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "53 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "54 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "55 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "56 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "57 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "58 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "59 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "60 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "61 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "62 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "63 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "64 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "65 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "66 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "67 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "68 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "69 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "70 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "71 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "72 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "73 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "74 Train Loss 854.5168 Test MSE 857.6695036776968 Test RE 0.4930025375572252 Lambda1 0.00035821195\n",
      "Training time: 286.14\n",
      "Training time: 286.14\n",
      "inv_HT_swish_tune2\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 854.758 Test MSE 858.1065165516947 Test RE 0.49312812265570694 Lambda1 3.7644093e-06\n",
      "1 Train Loss 854.7515 Test MSE 858.1261573215684 Test RE 0.4931337661046076 Lambda1 2.7183936e-05\n",
      "2 Train Loss 854.6339 Test MSE 858.0074201086992 Test RE 0.4930996479542188 Lambda1 0.0013263905\n",
      "3 Train Loss 854.5211 Test MSE 857.6585096630471 Test RE 0.49299937777687486 Lambda1 0.009628248\n",
      "4 Train Loss 848.60364 Test MSE 847.8127743853355 Test RE 0.49016144612935225 Lambda1 1.7294085\n",
      "5 Train Loss 834.8349 Test MSE 836.2091762756368 Test RE 0.4867955899508459 Lambda1 2.0144298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Train Loss 801.21954 Test MSE 786.1753897275194 Test RE 0.4720074929387197 Lambda1 1.932894\n",
      "7 Train Loss 720.87146 Test MSE 707.3179761662448 Test RE 0.44770971505980844 Lambda1 1.6893843\n",
      "8 Train Loss 661.2155 Test MSE 653.0270128402112 Test RE 0.4301844857661574 Lambda1 1.7552786\n",
      "9 Train Loss 483.41275 Test MSE 396.1392354845441 Test RE 0.3350526831501745 Lambda1 1.88356\n",
      "10 Train Loss 343.45804 Test MSE 301.7251910666765 Test RE 0.2924118417052735 Lambda1 1.863449\n",
      "11 Train Loss 238.05533 Test MSE 153.96473708026696 Test RE 0.20888141604299518 Lambda1 1.6540498\n",
      "12 Train Loss 141.17162 Test MSE 93.91119745773162 Test RE 0.16313526762902059 Lambda1 1.6059886\n",
      "13 Train Loss 91.421295 Test MSE 52.93740308555092 Test RE 0.1224814973243423 Lambda1 1.45232\n",
      "14 Train Loss 53.727592 Test MSE 44.81707246967603 Test RE 0.11269662567865009 Lambda1 1.3407681\n",
      "15 Train Loss 42.62733 Test MSE 41.77175055182907 Test RE 0.108800404142257 Lambda1 1.1936641\n",
      "16 Train Loss 38.590458 Test MSE 37.16624507793657 Test RE 0.1026274442694517 Lambda1 1.0600089\n",
      "17 Train Loss 36.420925 Test MSE 36.11839188050142 Test RE 0.10117037820032121 Lambda1 1.0072747\n",
      "18 Train Loss 34.689075 Test MSE 36.20153584359332 Test RE 0.10128675756293652 Lambda1 0.9691838\n",
      "19 Train Loss 34.27441 Test MSE 35.666287736740834 Test RE 0.10053519510617051 Lambda1 0.94066876\n",
      "20 Train Loss 33.698345 Test MSE 35.6169015857602 Test RE 0.10046556680207558 Lambda1 0.94037837\n",
      "21 Train Loss 33.586643 Test MSE 35.68105228712603 Test RE 0.10055600191649629 Lambda1 0.9545022\n",
      "22 Train Loss 33.114635 Test MSE 35.92032755142851 Test RE 0.10089260019291628 Lambda1 0.9712815\n",
      "23 Train Loss 32.521526 Test MSE 35.658269369809425 Test RE 0.10052389348988468 Lambda1 0.9447972\n",
      "24 Train Loss 32.415665 Test MSE 35.54003163246743 Test RE 0.1003570936545189 Lambda1 0.94437915\n",
      "25 Train Loss 31.954004 Test MSE 35.42020264452162 Test RE 0.10018776568576766 Lambda1 0.9508942\n",
      "26 Train Loss 31.776503 Test MSE 35.338838863158244 Test RE 0.10007262882132445 Lambda1 0.93875206\n",
      "27 Train Loss 31.760357 Test MSE 35.320758678839844 Test RE 0.10004702578630777 Lambda1 0.9321661\n",
      "28 Train Loss 31.691563 Test MSE 35.25671768164579 Test RE 0.09995628568899954 Lambda1 0.9236129\n",
      "29 Train Loss 31.603477 Test MSE 35.138719841394845 Test RE 0.09978887772004616 Lambda1 0.9214919\n",
      "30 Train Loss 31.549942 Test MSE 34.98261074844946 Test RE 0.09956696736517005 Lambda1 0.9203272\n",
      "31 Train Loss 31.448689 Test MSE 34.81924272418191 Test RE 0.09933420752536407 Lambda1 0.91923916\n",
      "32 Train Loss 31.343082 Test MSE 34.83372845895041 Test RE 0.0993548682181877 Lambda1 0.9219988\n",
      "33 Train Loss 31.251287 Test MSE 34.91729227037486 Test RE 0.0994739697116607 Lambda1 0.9241389\n",
      "34 Train Loss 31.213774 Test MSE 34.87641976791941 Test RE 0.09941573294276228 Lambda1 0.92406493\n",
      "35 Train Loss 31.094473 Test MSE 34.722379924138096 Test RE 0.09919594359848269 Lambda1 0.94599175\n",
      "36 Train Loss 30.943342 Test MSE 34.56296504798436 Test RE 0.09896797101836155 Lambda1 0.9795101\n",
      "37 Train Loss 30.829958 Test MSE 34.408353920277854 Test RE 0.09874636531786964 Lambda1 1.0047325\n",
      "38 Train Loss 30.791708 Test MSE 34.31669560708865 Test RE 0.098614755405739 Lambda1 1.0183811\n",
      "39 Train Loss 30.757578 Test MSE 34.258124268487784 Test RE 0.09853056220422399 Lambda1 1.029189\n",
      "40 Train Loss 30.649706 Test MSE 34.03178594256036 Test RE 0.0982045344310549 Lambda1 1.0371219\n",
      "41 Train Loss 30.5596 Test MSE 33.91785570541336 Test RE 0.09804001403685343 Lambda1 1.0228673\n",
      "42 Train Loss 30.39963 Test MSE 33.94580013507052 Test RE 0.09808039259494829 Lambda1 0.9855513\n",
      "43 Train Loss 30.342644 Test MSE 33.92597369580779 Test RE 0.09805174591463407 Lambda1 0.9654873\n",
      "44 Train Loss 30.313473 Test MSE 33.88051389621117 Test RE 0.09798603067590779 Lambda1 0.9527292\n",
      "45 Train Loss 30.302752 Test MSE 33.87575549423228 Test RE 0.09797914953331506 Lambda1 0.94922763\n",
      "46 Train Loss 30.268522 Test MSE 33.85046142590457 Test RE 0.09794256357298568 Lambda1 0.94872916\n",
      "47 Train Loss 30.242298 Test MSE 33.87626094927923 Test RE 0.09797988049665705 Lambda1 0.9484273\n",
      "48 Train Loss 30.229002 Test MSE 33.92202265866226 Test RE 0.09804603616885339 Lambda1 0.94791406\n",
      "49 Train Loss 30.223488 Test MSE 33.89953324175857 Test RE 0.09801352979695119 Lambda1 0.94745183\n",
      "50 Train Loss 30.19913 Test MSE 33.85858981280405 Test RE 0.09795432216106405 Lambda1 0.94853175\n",
      "51 Train Loss 30.12783 Test MSE 33.838742574240044 Test RE 0.09792560850529437 Lambda1 0.96009123\n",
      "52 Train Loss 30.101124 Test MSE 33.76506732607734 Test RE 0.0978189463736739 Lambda1 0.9678379\n",
      "53 Train Loss 30.074451 Test MSE 33.72913777771741 Test RE 0.09776688774751027 Lambda1 0.97471535\n",
      "54 Train Loss 29.95641 Test MSE 33.70227593253644 Test RE 0.09772794927680929 Lambda1 0.9713693\n",
      "55 Train Loss 29.911737 Test MSE 33.6669323732101 Test RE 0.09767669221005786 Lambda1 0.9636653\n",
      "56 Train Loss 29.887123 Test MSE 33.67307532671042 Test RE 0.09768560297156875 Lambda1 0.957568\n",
      "57 Train Loss 29.849722 Test MSE 33.61011832665623 Test RE 0.09759424110854031 Lambda1 0.9561367\n",
      "58 Train Loss 29.821915 Test MSE 33.53206196814337 Test RE 0.09748084848256297 Lambda1 0.95802754\n",
      "59 Train Loss 29.806435 Test MSE 33.50839447492846 Test RE 0.09744644059902327 Lambda1 0.95699614\n",
      "60 Train Loss 29.799187 Test MSE 33.48691027330634 Test RE 0.09741519626915375 Lambda1 0.95238113\n",
      "61 Train Loss 29.789082 Test MSE 33.48481566669234 Test RE 0.09741214956069931 Lambda1 0.9444281\n",
      "62 Train Loss 29.777294 Test MSE 33.489417051195424 Test RE 0.09741884237576932 Lambda1 0.93297756\n",
      "63 Train Loss 29.751799 Test MSE 33.44573224441515 Test RE 0.09735528331119689 Lambda1 0.92950094\n",
      "64 Train Loss 29.724092 Test MSE 33.43835370696166 Test RE 0.09734454383594858 Lambda1 0.9344689\n",
      "65 Train Loss 29.689548 Test MSE 33.42796373818094 Test RE 0.09732941920752629 Lambda1 0.9360918\n",
      "66 Train Loss 29.6591 Test MSE 33.352186234382444 Test RE 0.09721903909240598 Lambda1 0.9437274\n",
      "67 Train Loss 29.620663 Test MSE 33.31967208157306 Test RE 0.0971716394191309 Lambda1 0.9475102\n",
      "68 Train Loss 29.585524 Test MSE 33.27432897571404 Test RE 0.09710549885295526 Lambda1 0.93864006\n",
      "69 Train Loss 29.575851 Test MSE 33.275665302037055 Test RE 0.09710744875450675 Lambda1 0.9289343\n",
      "70 Train Loss 29.573576 Test MSE 33.29152020592522 Test RE 0.09713058046200522 Lambda1 0.9245253\n",
      "71 Train Loss 29.567986 Test MSE 33.28628150176068 Test RE 0.09712293799941547 Lambda1 0.9252341\n",
      "72 Train Loss 29.56649 Test MSE 33.27288931468563 Test RE 0.09710339812667725 Lambda1 0.9272525\n",
      "73 Train Loss 29.564402 Test MSE 33.26995444200861 Test RE 0.09709911547493683 Lambda1 0.92784643\n",
      "74 Train Loss 29.56317 Test MSE 33.26277996463783 Test RE 0.09708864547311681 Lambda1 0.93136847\n",
      "Training time: 285.09\n",
      "Training time: 285.09\n",
      "inv_HT_swish_tune2\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 854.7279 Test MSE 858.1004129605033 Test RE 0.49312636887703276 Lambda1 1.682678e-06\n",
      "1 Train Loss 854.71936 Test MSE 858.0601193366289 Test RE 0.49311479093033134 Lambda1 1.6946933e-07\n",
      "2 Train Loss 854.604 Test MSE 857.8281046963497 Test RE 0.49304811868718257 Lambda1 0.00017102869\n",
      "3 Train Loss 854.51135 Test MSE 857.6279977372 Test RE 0.4929906082642562 Lambda1 0.008782873\n",
      "4 Train Loss 854.50964 Test MSE 857.6589126475528 Test RE 0.4929994935986645 Lambda1 0.015061003\n",
      "5 Train Loss 854.40137 Test MSE 857.7102745530286 Test RE 0.4930142553028385 Lambda1 0.3318467\n",
      "6 Train Loss 852.3007 Test MSE 854.9601003907666 Test RE 0.49222321680943615 Lambda1 0.7663932\n",
      "7 Train Loss 838.36127 Test MSE 833.4457894863136 Test RE 0.4859905774363398 Lambda1 0.99810815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 820.23816 Test MSE 812.2553391441123 Test RE 0.4797726181081326 Lambda1 0.8466273\n",
      "9 Train Loss 714.56244 Test MSE 675.7613361918358 Test RE 0.43760859224978443 Lambda1 1.0175916\n",
      "10 Train Loss 628.22864 Test MSE 596.1892896515358 Test RE 0.41103732022938805 Lambda1 0.8423505\n",
      "11 Train Loss 478.39212 Test MSE 449.596495478504 Test RE 0.35694444641408907 Lambda1 0.78881687\n",
      "12 Train Loss 383.47284 Test MSE 351.4435229082467 Test RE 0.3155854285887898 Lambda1 0.83600867\n",
      "13 Train Loss 267.34637 Test MSE 243.15103464346714 Test RE 0.26249874511105964 Lambda1 0.8393054\n",
      "14 Train Loss 175.6841 Test MSE 145.84826116976296 Test RE 0.20330113278109999 Lambda1 0.8563356\n",
      "15 Train Loss 140.73119 Test MSE 117.92409389222232 Test RE 0.18280599944027914 Lambda1 0.8619259\n",
      "16 Train Loss 105.23401 Test MSE 98.68483993052676 Test RE 0.1672300775420695 Lambda1 0.85518736\n",
      "17 Train Loss 92.05893 Test MSE 84.63784308747502 Test RE 0.15487148557699018 Lambda1 0.8378788\n",
      "18 Train Loss 77.18799 Test MSE 73.21079587797506 Test RE 0.14403788465696146 Lambda1 0.8163177\n",
      "19 Train Loss 67.780426 Test MSE 63.988294171678135 Test RE 0.13466025637973744 Lambda1 0.8046235\n",
      "20 Train Loss 61.79647 Test MSE 61.73210245732826 Test RE 0.13226492950351681 Lambda1 0.80133325\n",
      "21 Train Loss 58.447742 Test MSE 59.17644933284521 Test RE 0.1294981673363154 Lambda1 0.802995\n",
      "22 Train Loss 56.774464 Test MSE 57.41604728629533 Test RE 0.1275574462994262 Lambda1 0.80546564\n",
      "23 Train Loss 52.23542 Test MSE 53.17549959603159 Test RE 0.12275663076501392 Lambda1 0.8126213\n",
      "24 Train Loss 49.271515 Test MSE 49.68644823708468 Test RE 0.11866103910718898 Lambda1 0.82378167\n",
      "25 Train Loss 47.285576 Test MSE 47.24695341352257 Test RE 0.11571138060438917 Lambda1 0.8387039\n",
      "26 Train Loss 45.002533 Test MSE 43.655818762447325 Test RE 0.11122700406868422 Lambda1 0.87238985\n",
      "27 Train Loss 43.00757 Test MSE 41.98597754245343 Test RE 0.10907903952871466 Lambda1 0.9045349\n",
      "28 Train Loss 38.28342 Test MSE 39.841121661357995 Test RE 0.10625636360066797 Lambda1 0.9587593\n",
      "29 Train Loss 36.49595 Test MSE 39.2592472643105 Test RE 0.10547757945035192 Lambda1 0.98478705\n",
      "30 Train Loss 35.83524 Test MSE 39.316325232501015 Test RE 0.1055542271154505 Lambda1 1.0059906\n",
      "31 Train Loss 35.53019 Test MSE 39.170450480897344 Test RE 0.10535822703677573 Lambda1 1.0065036\n",
      "32 Train Loss 35.39034 Test MSE 39.18304098509651 Test RE 0.10537515825158097 Lambda1 1.0043248\n",
      "33 Train Loss 35.245224 Test MSE 39.18890457117607 Test RE 0.10538304244307774 Lambda1 1.0030426\n",
      "34 Train Loss 35.159466 Test MSE 39.16674559229862 Test RE 0.1053532443301724 Lambda1 1.0035813\n",
      "35 Train Loss 35.047123 Test MSE 39.198944557026834 Test RE 0.10539654086194132 Lambda1 1.00493\n",
      "36 Train Loss 34.914463 Test MSE 39.205386174938816 Test RE 0.10540520048738909 Lambda1 1.005506\n",
      "37 Train Loss 34.894264 Test MSE 39.208680651358364 Test RE 0.10540962905813693 Lambda1 1.0055014\n",
      "38 Train Loss 34.880688 Test MSE 39.20569080850632 Test RE 0.10540560999617109 Lambda1 1.0035375\n",
      "39 Train Loss 34.833313 Test MSE 39.18837094078595 Test RE 0.10538232494681056 Lambda1 0.9986249\n",
      "40 Train Loss 34.737926 Test MSE 39.18840382640142 Test RE 0.1053823691635234 Lambda1 0.9985518\n",
      "41 Train Loss 34.70543 Test MSE 39.207122855598406 Test RE 0.10540753502817304 Lambda1 1.0002787\n",
      "42 Train Loss 34.66752 Test MSE 39.15800952063347 Test RE 0.10534149424976182 Lambda1 1.0021054\n",
      "43 Train Loss 34.640068 Test MSE 39.1116108724476 Test RE 0.10527906574893629 Lambda1 1.0027283\n",
      "44 Train Loss 34.62008 Test MSE 39.08456469005338 Test RE 0.10524265853923341 Lambda1 1.000809\n",
      "45 Train Loss 34.52963 Test MSE 39.03984797831776 Test RE 0.10518243716414848 Lambda1 0.9869402\n",
      "46 Train Loss 34.425392 Test MSE 39.00217781851266 Test RE 0.10513167882760317 Lambda1 0.97511727\n",
      "47 Train Loss 34.352047 Test MSE 38.94959702060427 Test RE 0.10506078827434435 Lambda1 0.96046436\n",
      "48 Train Loss 34.34079 Test MSE 38.94956070453605 Test RE 0.10506073929571638 Lambda1 0.9545803\n",
      "49 Train Loss 34.337852 Test MSE 38.94300971951171 Test RE 0.10505190376253883 Lambda1 0.9543059\n",
      "50 Train Loss 34.331837 Test MSE 38.92253648855093 Test RE 0.10502428603790367 Lambda1 0.95406175\n",
      "51 Train Loss 34.31954 Test MSE 38.89664834710971 Test RE 0.10498935337339702 Lambda1 0.9523293\n",
      "52 Train Loss 34.29987 Test MSE 38.864632434509076 Test RE 0.10494613600032371 Lambda1 0.9507531\n",
      "53 Train Loss 34.26708 Test MSE 38.85119812808162 Test RE 0.10492799610911618 Lambda1 0.95291066\n",
      "54 Train Loss 34.219 Test MSE 38.728915444667976 Test RE 0.10476273751165137 Lambda1 0.9597587\n",
      "55 Train Loss 34.181477 Test MSE 38.542050577377545 Test RE 0.104509694716513 Lambda1 0.96309817\n",
      "56 Train Loss 34.139282 Test MSE 38.50287564668537 Test RE 0.10445656831480443 Lambda1 0.96281683\n",
      "57 Train Loss 34.09354 Test MSE 38.42631000123061 Test RE 0.10435265705575515 Lambda1 0.96113664\n",
      "58 Train Loss 34.02222 Test MSE 38.417519740473715 Test RE 0.10434072070887503 Lambda1 0.953261\n",
      "59 Train Loss 33.926205 Test MSE 38.32587101498801 Test RE 0.10421618893104685 Lambda1 0.940637\n",
      "60 Train Loss 33.901985 Test MSE 38.31272585048667 Test RE 0.10419831515025743 Lambda1 0.9361216\n",
      "61 Train Loss 33.827675 Test MSE 38.408310021743915 Test RE 0.1043282133125811 Lambda1 0.92193365\n",
      "62 Train Loss 33.74788 Test MSE 38.33541758442714 Test RE 0.1042291676985278 Lambda1 0.90997785\n",
      "63 Train Loss 33.696125 Test MSE 38.25869403448212 Test RE 0.10412481462985533 Lambda1 0.9030197\n",
      "64 Train Loss 33.642048 Test MSE 38.0649737925134 Test RE 0.1038608656979133 Lambda1 0.9027428\n",
      "65 Train Loss 33.471497 Test MSE 37.88268431309153 Test RE 0.10361187742262508 Lambda1 0.90852255\n",
      "66 Train Loss 33.3876 Test MSE 37.8338455063445 Test RE 0.10354506705074258 Lambda1 0.91498697\n",
      "67 Train Loss 33.333984 Test MSE 37.7217735066055 Test RE 0.10339159191382319 Lambda1 0.9173591\n",
      "68 Train Loss 33.279755 Test MSE 37.67581267901486 Test RE 0.10332858571026571 Lambda1 0.9220534\n",
      "69 Train Loss 33.236492 Test MSE 37.617879224878855 Test RE 0.10324911184575214 Lambda1 0.9246785\n",
      "70 Train Loss 33.109837 Test MSE 37.57566759646288 Test RE 0.10319116683990466 Lambda1 0.910901\n",
      "71 Train Loss 33.066082 Test MSE 37.63929375959416 Test RE 0.10327849570735465 Lambda1 0.90304434\n",
      "72 Train Loss 33.016006 Test MSE 37.49460091170596 Test RE 0.10307979313567993 Lambda1 0.8952841\n",
      "73 Train Loss 32.888187 Test MSE 37.193930469753305 Test RE 0.10266566109865158 Lambda1 0.90067756\n",
      "74 Train Loss 32.809074 Test MSE 37.1858232494158 Test RE 0.10265447138992358 Lambda1 0.8976189\n",
      "Training time: 284.42\n",
      "Training time: 284.42\n",
      "inv_HT_swish_tune2\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 854.7152 Test MSE 858.0653697911465 Test RE 0.49311629960831477 Lambda1 5.6955486e-07\n",
      "1 Train Loss 854.7127 Test MSE 858.0796269643711 Test RE 0.49312039627480886 Lambda1 3.913022e-06\n",
      "2 Train Loss 854.6541 Test MSE 858.0632478517289 Test RE 0.4931156898857941 Lambda1 0.00015261683\n",
      "3 Train Loss 854.5159 Test MSE 857.6766820565056 Test RE 0.49300460067801255 Lambda1 0.00232004\n",
      "4 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "5 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "6 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "7 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "8 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "9 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "11 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "12 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "13 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "14 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "15 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "16 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "17 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "18 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "19 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "20 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "21 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "22 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "23 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "24 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "25 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "26 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "27 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "28 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "29 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "30 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "31 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "32 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "33 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "34 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "35 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "36 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "37 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "38 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "39 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "40 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "41 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "42 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "43 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "44 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "45 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "46 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "47 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "48 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "49 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "50 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "51 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "52 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "53 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "54 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "55 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "56 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "57 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "58 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "59 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "60 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "61 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "62 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "63 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "64 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "65 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "66 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "67 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "68 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "69 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "70 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "71 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "72 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "73 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "74 Train Loss 854.5132 Test MSE 857.6660792714514 Test RE 0.4930015533537258 Lambda1 0.002842125\n",
      "Training time: 304.11\n",
      "Training time: 304.11\n",
      "inv_HT_swish_tune2\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 854.7234 Test MSE 858.0706946734998 Test RE 0.4931178296678537 Lambda1 -2.6090058e-07\n",
      "1 Train Loss 854.71936 Test MSE 858.0882845350012 Test RE 0.4931228839308242 Lambda1 -1.0903018e-06\n",
      "2 Train Loss 854.65533 Test MSE 858.0539611518353 Test RE 0.4931130214171079 Lambda1 1.738553e-05\n",
      "3 Train Loss 854.5344 Test MSE 857.6838892629256 Test RE 0.4930066720753893 Lambda1 0.0064853285\n",
      "4 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "5 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "6 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "7 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "8 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "9 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "10 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "12 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "13 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "14 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "15 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "16 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "17 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "18 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "19 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "20 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "21 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "22 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "23 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "24 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "25 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "26 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "27 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "28 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "29 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "30 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "31 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "32 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "33 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "34 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "35 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "36 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "37 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "38 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "39 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "40 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "41 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "42 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "43 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "44 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "45 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "46 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "47 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "48 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "49 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "50 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "51 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "52 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "53 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "54 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "55 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "56 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "57 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "58 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "59 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "60 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "61 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "62 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "63 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "64 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "65 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "66 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "67 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "68 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "69 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "70 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "71 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "72 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "73 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "74 Train Loss 854.53265 Test MSE 857.6891179370226 Test RE 0.49300817482443204 Lambda1 0.008092696\n",
      "Training time: 285.93\n",
      "Training time: 285.93\n",
      "inv_HT_swish_tune2\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 854.73883 Test MSE 858.1221275253063 Test RE 0.4931326082148711 Lambda1 -1.1441546e-05\n",
      "1 Train Loss 854.5401 Test MSE 857.7626816312027 Test RE 0.49302931694003843 Lambda1 -0.00040424857\n",
      "2 Train Loss 854.5346 Test MSE 857.703510649701 Test RE 0.49301231134376766 Lambda1 -0.0005802922\n",
      "3 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "4 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "5 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "6 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "7 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "8 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "9 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "10 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "12 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "13 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "14 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "15 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "16 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "17 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "18 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "19 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "20 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "21 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "22 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "23 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "24 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "25 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "26 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "27 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "28 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "29 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "30 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "31 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "32 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "33 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "34 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "35 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "36 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "37 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "38 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "39 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "40 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "41 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "42 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "43 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "44 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "45 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "46 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "47 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "48 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "49 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "50 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "51 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "52 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "53 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "54 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "55 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "56 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "57 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "58 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "59 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "60 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "61 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "62 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "63 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "64 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "65 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "66 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "67 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "68 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "69 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "70 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "71 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "72 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "73 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "74 Train Loss 854.5345 Test MSE 857.7010749626189 Test RE 0.49301161132065036 Lambda1 -0.0006121758\n",
      "Training time: 256.72\n",
      "Training time: 256.72\n",
      "inv_HT_swish_tune2\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 854.7195 Test MSE 858.0715167565417 Test RE 0.493118065885983 Lambda1 3.6711774e-07\n",
      "1 Train Loss 854.7033 Test MSE 858.0937843198838 Test RE 0.4931244642259322 Lambda1 1.5775971e-06\n",
      "2 Train Loss 854.5374 Test MSE 857.781951004688 Test RE 0.4930348547845355 Lambda1 0.0009213877\n",
      "3 Train Loss 854.51953 Test MSE 857.680397896775 Test RE 0.49300566863543877 Lambda1 0.0017434679\n",
      "4 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "5 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "6 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "7 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "8 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "9 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "11 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "12 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "13 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "14 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "15 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "16 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "17 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "18 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "19 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "20 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "21 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "22 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "23 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "24 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "25 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "26 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "27 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "28 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "29 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "30 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "31 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "32 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "33 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "34 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "35 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "36 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "37 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "38 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "39 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "40 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "41 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "42 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "43 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "44 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "45 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "46 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "47 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "48 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "49 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "50 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "51 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "52 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "53 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "54 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "55 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "56 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "57 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "58 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "59 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "60 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "61 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "62 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "63 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "64 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "65 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "66 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "67 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "68 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "69 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "70 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "71 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "72 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "73 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "74 Train Loss 854.51935 Test MSE 857.6793683400674 Test RE 0.49300537273416445 Lambda1 0.001849087\n",
      "Training time: 256.61\n",
      "Training time: 256.61\n",
      "inv_HT_swish_tune2\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 854.7458 Test MSE 858.1525033307709 Test RE 0.4931413360912058 Lambda1 -4.5603642e-07\n",
      "1 Train Loss 854.72345 Test MSE 858.0826600351149 Test RE 0.49312126779516563 Lambda1 -4.5791214e-07\n",
      "2 Train Loss 854.72 Test MSE 858.06096834054 Test RE 0.49311503488543024 Lambda1 -4.8098985e-07\n",
      "3 Train Loss 854.61444 Test MSE 857.8319713752005 Test RE 0.49304922989849304 Lambda1 1.8291196e-06\n",
      "4 Train Loss 854.5061 Test MSE 857.618948773722 Test RE 0.49298800744794175 Lambda1 8.406528e-05\n",
      "5 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "6 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "7 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "8 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "9 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "11 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "12 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "13 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "14 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "15 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "16 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "17 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "18 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "19 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "20 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "21 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "22 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "23 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "24 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "25 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "26 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "27 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "28 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "29 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "30 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "31 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "32 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "33 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "34 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "35 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "36 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "37 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "38 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "39 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "40 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "41 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "42 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "43 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "44 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "45 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "46 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "47 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "48 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "49 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "50 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "51 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "52 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "53 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "54 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "55 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "56 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "57 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "58 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "59 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "60 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "61 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "62 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "63 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "64 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "65 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "66 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "67 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "68 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "69 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "70 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "71 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "72 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "73 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "74 Train Loss 854.50543 Test MSE 857.6337462640304 Test RE 0.49299226047535316 Lambda1 9.759117e-05\n",
      "Training time: 270.02\n",
      "Training time: 270.02\n",
      "inv_HT_swish_tune2\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 854.77216 Test MSE 858.137614822178 Test RE 0.49313705819722004 Lambda1 -9.035633e-06\n",
      "1 Train Loss 854.6558 Test MSE 858.0622554311502 Test RE 0.49311540472132565 Lambda1 -0.00032139444\n",
      "2 Train Loss 854.5227 Test MSE 857.6873063060439 Test RE 0.4930076541524687 Lambda1 -0.0017852482\n",
      "3 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "4 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "5 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "6 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "7 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "8 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "10 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "11 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "12 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "13 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "14 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "15 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "16 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "17 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "18 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "19 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "20 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "21 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "22 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "23 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "24 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "25 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "26 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "27 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "28 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "29 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "30 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "31 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "32 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "33 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "34 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "35 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "36 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "37 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "38 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "39 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "40 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "41 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "42 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "43 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "44 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "45 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "46 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "47 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "48 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "49 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "50 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "51 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "52 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "53 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "54 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "55 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "56 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "57 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "58 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "59 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "60 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "61 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "62 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "63 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "64 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "65 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "66 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "67 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "68 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "69 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "70 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "71 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "72 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "73 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "74 Train Loss 854.5223 Test MSE 857.6871759871218 Test RE 0.49300761669812615 Lambda1 -0.0018079107\n",
      "Training time: 287.60\n",
      "Training time: 287.60\n",
      "inv_HT_swish_tune2\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 854.73706 Test MSE 858.0752647371335 Test RE 0.4931191428328842 Lambda1 1.2867521e-06\n",
      "1 Train Loss 854.7319 Test MSE 858.0950579156665 Test RE 0.4931248301771932 Lambda1 3.6805047e-06\n",
      "2 Train Loss 854.6897 Test MSE 858.0755464843221 Test RE 0.4931192237901887 Lambda1 8.767603e-05\n",
      "3 Train Loss 854.66 Test MSE 857.9851494498154 Test RE 0.49309324840273505 Lambda1 0.00035119092\n",
      "4 Train Loss 854.5253 Test MSE 857.6848224194001 Test RE 0.49300694026991215 Lambda1 0.003470997\n",
      "5 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "6 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "7 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "9 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "10 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "11 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "12 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "13 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "14 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "15 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "16 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "17 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "18 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "19 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "20 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "21 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "22 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "23 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "24 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "25 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "26 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "27 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "28 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "29 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "30 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "31 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "32 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "33 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "34 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "35 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "36 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "37 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "38 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "39 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "40 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "41 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "42 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "43 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "44 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "45 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "46 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "47 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "48 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "49 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "50 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "51 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "52 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "53 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "54 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "55 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "56 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "57 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "58 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "59 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "60 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "61 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "62 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "63 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "64 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "65 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "66 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "67 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "68 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "69 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "70 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "71 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "72 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "73 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "74 Train Loss 854.5252 Test MSE 857.6787431884255 Test RE 0.49300519306144197 Lambda1 0.0036904714\n",
      "Training time: 272.66\n",
      "Training time: 272.66\n",
      "inv_HT_swish_tune3\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 854.69867 Test MSE 858.0369522465046 Test RE 0.49310813398890196 Lambda1 -6.591912e-06\n",
      "1 Train Loss 854.5183 Test MSE 857.6621324231472 Test RE 0.4930004189934949 Lambda1 6.2377076e-05\n",
      "2 Train Loss 854.5163 Test MSE 857.6817843729656 Test RE 0.4930060671174065 Lambda1 0.0011105848\n",
      "3 Train Loss 849.15753 Test MSE 847.9182344302162 Test RE 0.4901919309499719 Lambda1 0.2705156\n",
      "4 Train Loss 777.17175 Test MSE 768.2442653731642 Test RE 0.46659366087417786 Lambda1 0.26567715\n",
      "5 Train Loss 627.151 Test MSE 545.533445057738 Test RE 0.39318764361941105 Lambda1 0.044342566\n",
      "6 Train Loss 353.37582 Test MSE 312.2692869032274 Test RE 0.29747728311389054 Lambda1 0.003577413\n",
      "7 Train Loss 301.3948 Test MSE 299.53384807962095 Test RE 0.29134805528286045 Lambda1 0.0016397968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 288.3817 Test MSE 295.7925574379526 Test RE 0.28952281438457633 Lambda1 0.00045899343\n",
      "9 Train Loss 282.2411 Test MSE 288.65031241707766 Test RE 0.28600602796843033 Lambda1 0.0012812671\n",
      "10 Train Loss 276.09586 Test MSE 285.0113627805163 Test RE 0.28419750310493586 Lambda1 0.0005896075\n",
      "11 Train Loss 274.70993 Test MSE 283.26748827448387 Test RE 0.28332672166088657 Lambda1 0.0008545761\n",
      "12 Train Loss 274.64606 Test MSE 283.3025687619217 Test RE 0.2833442650292681 Lambda1 0.0006386624\n",
      "13 Train Loss 273.9485 Test MSE 282.6713295378552 Test RE 0.2830284229309525 Lambda1 0.00024132285\n",
      "14 Train Loss 272.77197 Test MSE 280.0382045269734 Test RE 0.28170711298829526 Lambda1 0.0013369696\n",
      "15 Train Loss 271.6268 Test MSE 278.84069536056205 Test RE 0.2811041447836838 Lambda1 0.0009993295\n",
      "16 Train Loss 271.20392 Test MSE 277.94316458529977 Test RE 0.28065137196799395 Lambda1 0.001765707\n",
      "17 Train Loss 271.10184 Test MSE 278.1108832479086 Test RE 0.28073603563307886 Lambda1 0.0014640156\n",
      "18 Train Loss 271.0921 Test MSE 278.1155866645482 Test RE 0.2807384095296758 Lambda1 0.0014640124\n",
      "19 Train Loss 270.94315 Test MSE 277.9691125210052 Test RE 0.28066447204514516 Lambda1 0.0014029692\n",
      "20 Train Loss 270.69806 Test MSE 277.84976122404026 Test RE 0.2806042112756421 Lambda1 0.0014583543\n",
      "21 Train Loss 270.62637 Test MSE 277.90724754747333 Test RE 0.2806332378799872 Lambda1 0.0013840835\n",
      "22 Train Loss 270.62137 Test MSE 277.92680395236664 Test RE 0.2806431118230513 Lambda1 0.0013639826\n",
      "23 Train Loss 270.61105 Test MSE 277.9137087987702 Test RE 0.28063650017585934 Lambda1 0.0014023863\n",
      "24 Train Loss 270.54984 Test MSE 277.82179493361093 Test RE 0.28059008915383377 Lambda1 0.0013276577\n",
      "25 Train Loss 270.5379 Test MSE 277.73030075201075 Test RE 0.2805438824216081 Lambda1 0.0013825342\n",
      "26 Train Loss 270.50647 Test MSE 277.81112575984884 Test RE 0.2805847013599068 Lambda1 0.0013237502\n",
      "27 Train Loss 270.48367 Test MSE 277.7317432255902 Test RE 0.2805446109640317 Lambda1 0.0013434037\n",
      "28 Train Loss 270.47403 Test MSE 277.7356410158349 Test RE 0.2805465795906613 Lambda1 0.0013226729\n",
      "29 Train Loss 270.46817 Test MSE 277.71042847013706 Test RE 0.28053384544180265 Lambda1 0.0013388374\n",
      "30 Train Loss 270.4664 Test MSE 277.7319477214875 Test RE 0.28054471424752875 Lambda1 0.0013410622\n",
      "31 Train Loss 270.45773 Test MSE 277.68119034149345 Test RE 0.28051907736015674 Lambda1 0.0013645681\n",
      "32 Train Loss 270.41467 Test MSE 277.70546673994306 Test RE 0.2805313393431365 Lambda1 0.0014145697\n",
      "33 Train Loss 270.38495 Test MSE 277.6537872127889 Test RE 0.28050523542503614 Lambda1 0.0014966072\n",
      "34 Train Loss 270.37418 Test MSE 277.6600010527458 Test RE 0.2805083742348927 Lambda1 0.0014889241\n",
      "35 Train Loss 270.34485 Test MSE 277.5525453618357 Test RE 0.2804540899701372 Lambda1 0.0015935837\n",
      "36 Train Loss 270.30957 Test MSE 277.5432271514531 Test RE 0.2804493821189731 Lambda1 0.0018392793\n",
      "37 Train Loss 270.28336 Test MSE 277.480891480309 Test RE 0.2804178861564309 Lambda1 0.0018946949\n",
      "38 Train Loss 270.26672 Test MSE 277.4854545799713 Test RE 0.2804201918458322 Lambda1 0.0019859963\n",
      "39 Train Loss 270.25717 Test MSE 277.4564517161673 Test RE 0.28040553666116486 Lambda1 0.0019013738\n",
      "40 Train Loss 270.18118 Test MSE 277.2832022360164 Test RE 0.28031797751606297 Lambda1 0.002066725\n",
      "41 Train Loss 270.13257 Test MSE 277.10635763594524 Test RE 0.2802285732051952 Lambda1 0.0023028767\n",
      "42 Train Loss 270.10645 Test MSE 277.1186322215333 Test RE 0.28023477957942894 Lambda1 0.0023646648\n",
      "43 Train Loss 270.0657 Test MSE 276.99398502937817 Test RE 0.28017174807748624 Lambda1 0.0025416047\n",
      "44 Train Loss 269.9834 Test MSE 276.92115916008265 Test RE 0.2801349149809247 Lambda1 0.0028984933\n",
      "45 Train Loss 269.942 Test MSE 276.8574423955134 Test RE 0.2801026850181924 Lambda1 0.003123807\n",
      "46 Train Loss 269.9175 Test MSE 276.72441229957013 Test RE 0.28003538221439817 Lambda1 0.0032350891\n",
      "47 Train Loss 269.87634 Test MSE 276.59755792128203 Test RE 0.2799711887699335 Lambda1 0.0033485696\n",
      "48 Train Loss 269.853 Test MSE 276.55080825360625 Test RE 0.27994752783592897 Lambda1 0.0034518961\n",
      "49 Train Loss 269.79022 Test MSE 276.46518546408214 Test RE 0.2799041872577197 Lambda1 0.0036587853\n",
      "50 Train Loss 269.74597 Test MSE 276.41594752712524 Test RE 0.2798792609394373 Lambda1 0.0038795383\n",
      "51 Train Loss 269.67108 Test MSE 276.2458399792786 Test RE 0.2797931282429777 Lambda1 0.0043248087\n",
      "52 Train Loss 269.62692 Test MSE 276.06376756342934 Test RE 0.27970090783600077 Lambda1 0.004609209\n",
      "53 Train Loss 269.58215 Test MSE 275.9433664452494 Test RE 0.27963990748269013 Lambda1 0.004937914\n",
      "54 Train Loss 269.53198 Test MSE 276.0036177670758 Test RE 0.27967043504105404 Lambda1 0.0049777958\n",
      "55 Train Loss 269.41833 Test MSE 275.6152790422192 Test RE 0.2794736168063402 Lambda1 0.005880922\n",
      "56 Train Loss 269.27875 Test MSE 275.3601598874491 Test RE 0.2793442415771833 Lambda1 0.006497644\n",
      "57 Train Loss 269.22336 Test MSE 275.4277614270749 Test RE 0.27937852929321294 Lambda1 0.006661695\n",
      "58 Train Loss 269.04678 Test MSE 274.73710993496405 Test RE 0.2790280302922762 Lambda1 0.008106487\n",
      "59 Train Loss 268.34152 Test MSE 272.938847521605 Test RE 0.27811335702385537 Lambda1 0.0127458405\n",
      "60 Train Loss 267.14758 Test MSE 271.0069253706886 Test RE 0.27712733486131413 Lambda1 0.019160762\n",
      "61 Train Loss 266.6613 Test MSE 270.79503488419 Test RE 0.27701897577030454 Lambda1 0.020225555\n",
      "62 Train Loss 265.77045 Test MSE 266.5063915926139 Test RE 0.27481661450623457 Lambda1 0.03285867\n",
      "63 Train Loss 264.90482 Test MSE 266.4302654427501 Test RE 0.27477736174226985 Lambda1 0.033551045\n",
      "64 Train Loss 262.55823 Test MSE 259.31743064624885 Test RE 0.2710847117711389 Lambda1 0.061199598\n",
      "65 Train Loss 256.6965 Test MSE 249.91064020911554 Test RE 0.26612246907687215 Lambda1 0.100381956\n",
      "66 Train Loss 248.9364 Test MSE 243.29242218285742 Test RE 0.2625750529458467 Lambda1 0.12183247\n",
      "67 Train Loss 247.82771 Test MSE 242.43371187258484 Test RE 0.26211125877667396 Lambda1 0.1300487\n",
      "68 Train Loss 246.06061 Test MSE 240.04615306355296 Test RE 0.26081739074415805 Lambda1 0.15543291\n",
      "69 Train Loss 244.12372 Test MSE 237.73621137878447 Test RE 0.2595594464771757 Lambda1 0.17899632\n",
      "70 Train Loss 242.71552 Test MSE 237.407610974618 Test RE 0.25938000214377377 Lambda1 0.17108515\n",
      "71 Train Loss 237.08344 Test MSE 238.6354872955279 Test RE 0.2600498960414977 Lambda1 0.1381337\n",
      "72 Train Loss 234.7075 Test MSE 234.90194688875042 Test RE 0.2580075880106384 Lambda1 0.15370624\n",
      "73 Train Loss 232.47513 Test MSE 232.17296385106314 Test RE 0.2565045028314763 Lambda1 0.16822976\n",
      "74 Train Loss 229.53304 Test MSE 231.32553523484916 Test RE 0.25603595566753173 Lambda1 0.16549999\n",
      "Training time: 295.59\n",
      "Training time: 295.59\n",
      "inv_HT_swish_tune3\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 854.7583 Test MSE 858.116302906063 Test RE 0.49313093461011176 Lambda1 2.806751e-06\n",
      "1 Train Loss 854.5152 Test MSE 857.6166736001553 Test RE 0.4929873535246413 Lambda1 0.020850614\n",
      "2 Train Loss 852.75616 Test MSE 856.3354424817767 Test RE 0.49261896818458184 Lambda1 1.0412331\n",
      "3 Train Loss 849.06934 Test MSE 851.4876286322899 Test RE 0.49122260269410234 Lambda1 1.5908667\n",
      "4 Train Loss 810.31006 Test MSE 767.3069252895273 Test RE 0.4663089269374453 Lambda1 1.8922548\n",
      "5 Train Loss 745.68225 Test MSE 732.3185332860564 Test RE 0.45555328560411856 Lambda1 1.780338\n",
      "6 Train Loss 671.78 Test MSE 634.7060461796872 Test RE 0.42410704654896375 Lambda1 1.5727035\n",
      "7 Train Loss 612.45233 Test MSE 585.2348129090543 Test RE 0.40724358022191237 Lambda1 1.449152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Train Loss 527.1052 Test MSE 503.09924113705586 Test RE 0.37758610298136575 Lambda1 1.5278293\n",
      "9 Train Loss 440.34583 Test MSE 426.3452482455939 Test RE 0.34759208943059705 Lambda1 1.6824493\n",
      "10 Train Loss 262.375 Test MSE 214.06012374013994 Test RE 0.24629582874060538 Lambda1 2.0182142\n",
      "11 Train Loss 212.81952 Test MSE 166.02861744670253 Test RE 0.21691053542133557 Lambda1 2.010314\n",
      "12 Train Loss 148.60349 Test MSE 114.28137955746911 Test RE 0.17996038259995348 Lambda1 1.9337988\n",
      "13 Train Loss 111.391304 Test MSE 95.40086748258493 Test RE 0.16442404667670063 Lambda1 1.8908681\n",
      "14 Train Loss 82.86972 Test MSE 75.10222425636083 Test RE 0.14588665626880357 Lambda1 1.7614725\n",
      "15 Train Loss 59.101883 Test MSE 52.968267159787004 Test RE 0.12251719729225444 Lambda1 1.6867508\n",
      "16 Train Loss 46.064102 Test MSE 45.67387957788038 Test RE 0.11376878548449092 Lambda1 1.5791856\n",
      "17 Train Loss 43.716858 Test MSE 44.2786983240421 Test RE 0.11201768503790883 Lambda1 1.5435245\n",
      "18 Train Loss 41.470245 Test MSE 43.1044321456842 Test RE 0.1105223561288567 Lambda1 1.4644206\n",
      "19 Train Loss 38.46983 Test MSE 41.436606365516106 Test RE 0.10836306004377348 Lambda1 1.3083498\n",
      "20 Train Loss 37.422832 Test MSE 40.58351092421939 Test RE 0.10724177126989991 Lambda1 1.2189132\n",
      "21 Train Loss 36.963646 Test MSE 39.895011393221814 Test RE 0.10632820133641083 Lambda1 1.1147538\n",
      "22 Train Loss 36.332077 Test MSE 39.62001994413436 Test RE 0.1059611140069825 Lambda1 1.0374808\n",
      "23 Train Loss 35.766544 Test MSE 39.575119479858515 Test RE 0.10590105533040603 Lambda1 0.9766481\n",
      "24 Train Loss 35.410637 Test MSE 39.73347253002439 Test RE 0.106112716261582 Lambda1 0.9498195\n",
      "25 Train Loss 35.258842 Test MSE 39.593624091490355 Test RE 0.10592581114800578 Lambda1 0.94232553\n",
      "26 Train Loss 34.96211 Test MSE 39.40258920735658 Test RE 0.105669961966063 Lambda1 0.9576306\n",
      "27 Train Loss 34.70501 Test MSE 39.26804068027895 Test RE 0.10548939139741288 Lambda1 0.9224961\n",
      "28 Train Loss 34.450912 Test MSE 39.25158692648002 Test RE 0.10546728845693504 Lambda1 0.9272652\n",
      "29 Train Loss 34.266014 Test MSE 38.90886688124144 Test RE 0.10500584213690008 Lambda1 0.93072134\n",
      "30 Train Loss 34.243626 Test MSE 38.84505021808767 Test RE 0.10491969374742462 Lambda1 0.9310947\n",
      "31 Train Loss 34.23196 Test MSE 38.89748026211894 Test RE 0.10499047611475885 Lambda1 0.92338604\n",
      "32 Train Loss 34.21098 Test MSE 38.85625972037278 Test RE 0.10493483097476683 Lambda1 0.9106527\n",
      "33 Train Loss 34.17226 Test MSE 38.8322515513672 Test RE 0.10490240785369481 Lambda1 0.91513914\n",
      "34 Train Loss 34.154427 Test MSE 38.864492145270525 Test RE 0.10494594658869323 Lambda1 0.91877407\n",
      "35 Train Loss 34.115414 Test MSE 38.80930586310157 Test RE 0.10487141024814796 Lambda1 0.92291677\n",
      "36 Train Loss 34.062347 Test MSE 38.71125273220919 Test RE 0.10473884573584691 Lambda1 0.93702036\n",
      "37 Train Loss 34.01689 Test MSE 38.575086600281345 Test RE 0.10455447496424769 Lambda1 0.9269565\n",
      "38 Train Loss 33.980453 Test MSE 38.51881282448537 Test RE 0.1044781845011408 Lambda1 0.9159869\n",
      "39 Train Loss 33.89059 Test MSE 38.33926223879367 Test RE 0.10423439413276665 Lambda1 0.9293389\n",
      "40 Train Loss 33.840107 Test MSE 38.30550711100223 Test RE 0.10418849836080715 Lambda1 0.93138295\n",
      "41 Train Loss 33.793728 Test MSE 38.254206504054295 Test RE 0.1041187078221299 Lambda1 0.9291671\n",
      "42 Train Loss 33.731823 Test MSE 38.171610836314606 Test RE 0.10400624435745114 Lambda1 0.91026753\n",
      "43 Train Loss 33.681747 Test MSE 38.08381702456394 Test RE 0.10388656954132328 Lambda1 0.91052765\n",
      "44 Train Loss 33.58759 Test MSE 38.05576892380695 Test RE 0.10384830712580975 Lambda1 0.9347954\n",
      "45 Train Loss 33.54852 Test MSE 37.947364815504 Test RE 0.1037002926215318 Lambda1 0.9234615\n",
      "46 Train Loss 33.502808 Test MSE 37.915263798250734 Test RE 0.1036564214699765 Lambda1 0.9247063\n",
      "47 Train Loss 33.38643 Test MSE 37.74596588920919 Test RE 0.10342474104498987 Lambda1 0.9154266\n",
      "48 Train Loss 33.130447 Test MSE 37.50511268284873 Test RE 0.10309424155271382 Lambda1 0.92078084\n",
      "49 Train Loss 32.998978 Test MSE 37.390254999932324 Test RE 0.10293625982004044 Lambda1 0.9023285\n",
      "50 Train Loss 32.91317 Test MSE 37.36343299757112 Test RE 0.10289933239166929 Lambda1 0.8800239\n",
      "51 Train Loss 32.753895 Test MSE 37.03262355890833 Test RE 0.10244279307906276 Lambda1 0.87854534\n",
      "52 Train Loss 32.702103 Test MSE 36.838196383688775 Test RE 0.10217351868607995 Lambda1 0.89805174\n",
      "53 Train Loss 32.541878 Test MSE 36.57946185054448 Test RE 0.10181407655482219 Lambda1 0.9150015\n",
      "54 Train Loss 32.49017 Test MSE 36.64642380150064 Test RE 0.10190722379676594 Lambda1 0.8915436\n",
      "55 Train Loss 32.41753 Test MSE 36.54255852828783 Test RE 0.10176270584566816 Lambda1 0.8803988\n",
      "56 Train Loss 32.314457 Test MSE 36.29572515862283 Test RE 0.10141843613354828 Lambda1 0.89125067\n",
      "57 Train Loss 32.2859 Test MSE 36.09830163558261 Test RE 0.10114223713021053 Lambda1 0.8989147\n",
      "58 Train Loss 31.95033 Test MSE 35.47279811720634 Test RE 0.10026212251900346 Lambda1 0.8951485\n",
      "59 Train Loss 31.45326 Test MSE 35.00150948782093 Test RE 0.09959385838412375 Lambda1 0.8618475\n",
      "60 Train Loss 31.15987 Test MSE 34.82029424142403 Test RE 0.09933570742649907 Lambda1 0.8377581\n",
      "61 Train Loss 31.024122 Test MSE 34.52022425677978 Test RE 0.09890675986517239 Lambda1 0.83625454\n",
      "62 Train Loss 30.799618 Test MSE 34.2736949569911 Test RE 0.09855295126431056 Lambda1 0.8333361\n",
      "63 Train Loss 30.527111 Test MSE 33.96630638574651 Test RE 0.0981100127166715 Lambda1 0.8475539\n",
      "64 Train Loss 30.364855 Test MSE 33.84941852050971 Test RE 0.09794105479569881 Lambda1 0.8739007\n",
      "65 Train Loss 30.236856 Test MSE 33.613550700305574 Test RE 0.09759922430060146 Lambda1 0.924\n",
      "66 Train Loss 30.20067 Test MSE 33.54015683855727 Test RE 0.09749261404621323 Lambda1 0.93208015\n",
      "67 Train Loss 30.141573 Test MSE 33.52481482261099 Test RE 0.09747031384751244 Lambda1 0.9127157\n",
      "68 Train Loss 30.090221 Test MSE 33.48087736067851 Test RE 0.09740642084265426 Lambda1 0.9157571\n",
      "69 Train Loss 30.012913 Test MSE 33.44972573722605 Test RE 0.09736109535346792 Lambda1 0.9211807\n",
      "70 Train Loss 29.988956 Test MSE 33.45416878534599 Test RE 0.09736756126101186 Lambda1 0.9392104\n",
      "71 Train Loss 29.965986 Test MSE 33.44599106154768 Test RE 0.09735565999851734 Lambda1 0.9373439\n",
      "72 Train Loss 29.946394 Test MSE 33.44754337545688 Test RE 0.09735791923477939 Lambda1 0.93402827\n",
      "73 Train Loss 29.924236 Test MSE 33.464772404911095 Test RE 0.0973829908295368 Lambda1 0.9251732\n",
      "74 Train Loss 29.908098 Test MSE 33.43094333792291 Test RE 0.09733375683713143 Lambda1 0.9252743\n",
      "Training time: 303.79\n",
      "Training time: 303.79\n",
      "inv_HT_swish_tune3\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 854.73145 Test MSE 858.0748274550976 Test RE 0.49311901718413353 Lambda1 3.1212348e-06\n",
      "1 Train Loss 854.7282 Test MSE 858.0950602173227 Test RE 0.49312483083854414 Lambda1 1.1717417e-05\n",
      "2 Train Loss 854.55756 Test MSE 857.5757958971473 Test RE 0.4929756044347593 Lambda1 8.027048e-05\n",
      "3 Train Loss 854.51135 Test MSE 857.704049176023 Test RE 0.49301246611756877 Lambda1 -0.015087297\n",
      "4 Train Loss 853.3022 Test MSE 856.3875552863527 Test RE 0.4926339572672416 Lambda1 -1.134206\n",
      "5 Train Loss 833.3311 Test MSE 827.171551073726 Test RE 0.4841578360766743 Lambda1 -1.2463291\n",
      "6 Train Loss 784.52606 Test MSE 787.9312195128241 Test RE 0.47253428543614956 Lambda1 -1.002079\n",
      "7 Train Loss 748.2548 Test MSE 750.6776018777141 Test RE 0.4612282498272754 Lambda1 -1.0538375\n",
      "8 Train Loss 701.5892 Test MSE 683.9374809558958 Test RE 0.44024798092061385 Lambda1 -1.0313715\n",
      "9 Train Loss 659.8712 Test MSE 626.8049336516153 Test RE 0.42145904013903507 Lambda1 -0.925813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Train Loss 576.2146 Test MSE 542.2659702094768 Test RE 0.3920083756427228 Lambda1 -0.7648795\n",
      "11 Train Loss 481.1788 Test MSE 456.171839891525 Test RE 0.35954512674148786 Lambda1 -0.7230661\n",
      "12 Train Loss 440.58218 Test MSE 422.101770755434 Test RE 0.3458579457825094 Lambda1 -0.7306255\n",
      "13 Train Loss 379.38358 Test MSE 358.4271587144641 Test RE 0.3187055492562341 Lambda1 -0.7527044\n",
      "14 Train Loss 335.60684 Test MSE 314.3508850339659 Test RE 0.2984671333143883 Lambda1 -0.83849835\n",
      "15 Train Loss 314.79526 Test MSE 281.12549689191894 Test RE 0.2822534692557795 Lambda1 -0.90625435\n",
      "16 Train Loss 257.04697 Test MSE 237.95564357057995 Test RE 0.25967920644421233 Lambda1 -0.84501857\n",
      "17 Train Loss 233.84665 Test MSE 221.91984876097106 Test RE 0.25077673543175943 Lambda1 -0.81636846\n",
      "18 Train Loss 221.69469 Test MSE 206.7875425171875 Test RE 0.24207578934998228 Lambda1 -0.83002305\n",
      "19 Train Loss 209.44235 Test MSE 197.3993604509365 Test RE 0.23651682547364608 Lambda1 -0.82724833\n",
      "20 Train Loss 191.38638 Test MSE 183.328967186268 Test RE 0.22793169311145411 Lambda1 -0.8063098\n",
      "21 Train Loss 184.41197 Test MSE 178.50896137075625 Test RE 0.22491539456780296 Lambda1 -0.8062438\n",
      "22 Train Loss 181.65315 Test MSE 177.86082358155323 Test RE 0.22450670715853246 Lambda1 -0.8134464\n",
      "23 Train Loss 178.41841 Test MSE 175.84629465881866 Test RE 0.22323165620376348 Lambda1 -0.82294744\n",
      "24 Train Loss 174.56036 Test MSE 170.65638400744515 Test RE 0.21991276561546547 Lambda1 -0.86027133\n",
      "25 Train Loss 167.81941 Test MSE 164.1712263299146 Test RE 0.2156938149280995 Lambda1 -0.90444577\n",
      "26 Train Loss 160.20358 Test MSE 158.30340117903137 Test RE 0.2118040662761788 Lambda1 -0.9422233\n",
      "27 Train Loss 158.40196 Test MSE 155.95866305341698 Test RE 0.21022962828540273 Lambda1 -0.96124357\n",
      "28 Train Loss 152.46902 Test MSE 152.0410363529002 Test RE 0.20757238779868958 Lambda1 -1.0114428\n",
      "29 Train Loss 148.49185 Test MSE 147.33114177468102 Test RE 0.2043320291703957 Lambda1 -1.0563166\n",
      "30 Train Loss 143.14305 Test MSE 142.29596137061571 Test RE 0.20081005620955208 Lambda1 -1.1067786\n",
      "31 Train Loss 138.24706 Test MSE 135.51415887590355 Test RE 0.19596635173921298 Lambda1 -1.203991\n",
      "32 Train Loss 134.06125 Test MSE 129.23330888624028 Test RE 0.19137112181139532 Lambda1 -1.3085082\n",
      "33 Train Loss 126.21135 Test MSE 120.88463692239577 Test RE 0.18508649270568983 Lambda1 -1.4711922\n",
      "34 Train Loss 122.69848 Test MSE 118.07620129818785 Test RE 0.1829238599411041 Lambda1 -1.553495\n",
      "35 Train Loss 119.952866 Test MSE 116.17686472908345 Test RE 0.1814466676592197 Lambda1 -1.6253737\n",
      "36 Train Loss 116.46101 Test MSE 115.26996980281814 Test RE 0.1807370795066556 Lambda1 -1.6507068\n",
      "37 Train Loss 114.56288 Test MSE 113.56355248775687 Test RE 0.17939430645068233 Lambda1 -1.7142731\n",
      "38 Train Loss 113.90614 Test MSE 112.5943666454134 Test RE 0.17862716344208693 Lambda1 -1.7473826\n",
      "39 Train Loss 112.76185 Test MSE 112.34584012199892 Test RE 0.1784299150649782 Lambda1 -1.7486502\n",
      "40 Train Loss 111.318634 Test MSE 110.63549124112231 Test RE 0.17706650083468484 Lambda1 -1.7827352\n",
      "41 Train Loss 110.05185 Test MSE 108.35664650059803 Test RE 0.17523342459820654 Lambda1 -1.8568972\n",
      "42 Train Loss 106.33678 Test MSE 104.74054196465289 Test RE 0.17228464764498339 Lambda1 -2.017\n",
      "43 Train Loss 103.248825 Test MSE 102.88290398891961 Test RE 0.17075002570793893 Lambda1 -2.0554504\n",
      "44 Train Loss 101.88395 Test MSE 102.729571987694 Test RE 0.1706227392282634 Lambda1 -2.0525067\n",
      "45 Train Loss 100.07195 Test MSE 102.66334638824989 Test RE 0.17056773357287908 Lambda1 -2.0579507\n",
      "46 Train Loss 99.33996 Test MSE 102.67148098531374 Test RE 0.1705744909617123 Lambda1 -2.0888076\n",
      "47 Train Loss 97.29498 Test MSE 100.11980150035613 Test RE 0.16844152340626256 Lambda1 -2.1797826\n",
      "48 Train Loss 96.36306 Test MSE 99.35157717087135 Test RE 0.16779404879972812 Lambda1 -2.2141876\n",
      "49 Train Loss 95.41866 Test MSE 98.77257454760809 Test RE 0.1673043980117247 Lambda1 -2.25253\n",
      "50 Train Loss 94.93147 Test MSE 98.6551544031837 Test RE 0.16720492329127665 Lambda1 -2.291686\n",
      "51 Train Loss 93.18761 Test MSE 97.02653498790211 Test RE 0.16581905344157905 Lambda1 -2.3843055\n",
      "52 Train Loss 92.09283 Test MSE 95.93150919805751 Test RE 0.16488069487190296 Lambda1 -2.4552486\n",
      "53 Train Loss 91.88864 Test MSE 95.82707190051758 Test RE 0.16479092049273247 Lambda1 -2.4570997\n",
      "54 Train Loss 90.77319 Test MSE 95.48689855992481 Test RE 0.16449816754487914 Lambda1 -2.5326858\n",
      "55 Train Loss 90.08567 Test MSE 94.41006881745254 Test RE 0.1635679940798062 Lambda1 -2.5930302\n",
      "56 Train Loss 89.62544 Test MSE 93.89640867369002 Test RE 0.1631224221574685 Lambda1 -2.6720123\n",
      "57 Train Loss 89.24513 Test MSE 92.80179911166447 Test RE 0.16216882444176156 Lambda1 -2.761446\n",
      "58 Train Loss 88.9604 Test MSE 92.13622718927103 Test RE 0.1615862428478949 Lambda1 -2.81169\n",
      "59 Train Loss 88.104546 Test MSE 92.52725907692634 Test RE 0.16192877084533006 Lambda1 -2.8542705\n",
      "60 Train Loss 87.6044 Test MSE 91.95139986070701 Test RE 0.16142408868067254 Lambda1 -2.8461373\n",
      "61 Train Loss 86.98678 Test MSE 91.14487656516053 Test RE 0.16071458870314037 Lambda1 -2.879814\n",
      "62 Train Loss 86.6306 Test MSE 91.16983367714722 Test RE 0.16073659047442887 Lambda1 -2.8721275\n",
      "63 Train Loss 86.420616 Test MSE 90.78362312334384 Test RE 0.16039577571096347 Lambda1 -2.8997984\n",
      "64 Train Loss 86.02327 Test MSE 90.47983188837648 Test RE 0.16012718286694072 Lambda1 -2.9835882\n",
      "65 Train Loss 85.805595 Test MSE 90.63462568396457 Test RE 0.160264097920957 Lambda1 -2.9832652\n",
      "66 Train Loss 85.30778 Test MSE 89.6727573594186 Test RE 0.15941142084782714 Lambda1 -3.0189738\n",
      "67 Train Loss 84.853195 Test MSE 88.81717431258913 Test RE 0.15864911240620802 Lambda1 -3.0871918\n",
      "68 Train Loss 84.243095 Test MSE 88.48280801778787 Test RE 0.15835020098297398 Lambda1 -3.1276689\n",
      "69 Train Loss 83.989456 Test MSE 88.4382801829402 Test RE 0.15831035211821184 Lambda1 -3.1353946\n",
      "70 Train Loss 83.86116 Test MSE 88.19863696613824 Test RE 0.15809571804119155 Lambda1 -3.156242\n",
      "71 Train Loss 83.534485 Test MSE 87.48971494731363 Test RE 0.1574590661436186 Lambda1 -3.2062705\n",
      "72 Train Loss 82.88671 Test MSE 86.49143128308027 Test RE 0.15655816148913698 Lambda1 -3.3028677\n",
      "73 Train Loss 81.95777 Test MSE 86.24763081419336 Test RE 0.15633735413240954 Lambda1 -3.401494\n",
      "74 Train Loss 80.9386 Test MSE 85.35392172625674 Test RE 0.15552525094862718 Lambda1 -3.523421\n",
      "Training time: 287.85\n",
      "Training time: 287.85\n",
      "inv_HT_swish_tune3\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 854.7147 Test MSE 858.0720382286388 Test RE 0.49311821572621645 Lambda1 7.5558063e-07\n",
      "1 Train Loss 854.6553 Test MSE 857.8792064057099 Test RE 0.49306280416222303 Lambda1 0.0001776414\n",
      "2 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "3 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "4 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "5 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "6 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "7 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "8 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "9 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "10 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "12 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "13 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "14 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "15 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "16 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "17 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "18 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "19 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "20 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "21 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "22 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "23 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "24 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "25 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "26 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "27 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "28 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "29 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "30 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "31 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "32 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "33 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "34 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "35 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "36 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "37 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "38 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "39 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "40 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "41 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "42 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "43 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "44 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "45 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "46 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "47 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "48 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "49 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "50 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "51 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "52 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "53 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "54 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "55 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "56 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "57 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "58 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "59 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "60 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "61 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "62 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "63 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "64 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "65 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "66 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "67 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "68 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "69 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "70 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "71 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "72 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "73 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "74 Train Loss 854.5148 Test MSE 857.6669013030083 Test RE 0.49300178961277064 Lambda1 0.0012026377\n",
      "Training time: 264.82\n",
      "Training time: 264.82\n",
      "inv_HT_swish_tune3\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 854.7136 Test MSE 858.0693196122903 Test RE 0.49311743455619506 Lambda1 4.3910882e-07\n",
      "1 Train Loss 854.6863 Test MSE 858.0948113287428 Test RE 0.49312475932365407 Lambda1 0.0001193543\n",
      "2 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "3 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "4 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "5 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "6 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "7 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "8 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "9 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "10 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "12 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "13 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "14 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "15 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "16 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "17 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "18 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "19 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "20 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "21 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "22 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "23 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "24 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "25 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "26 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "27 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "28 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "29 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "30 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "31 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "32 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "33 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "34 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "35 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "36 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "37 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "38 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "39 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "40 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "41 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "42 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "43 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "44 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "45 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "46 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "47 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "48 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "49 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "50 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "51 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "52 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "53 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "54 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "55 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "56 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "57 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "58 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "59 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "60 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "61 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "62 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "63 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "64 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "65 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "66 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "67 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "68 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "69 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "70 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "71 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "72 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "73 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "74 Train Loss 854.5331 Test MSE 857.6887117976692 Test RE 0.49300805809796283 Lambda1 0.0014598484\n",
      "Training time: 245.65\n",
      "Training time: 245.65\n",
      "inv_HT_swish_tune3\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 854.74445 Test MSE 858.1022218306085 Test RE 0.49312688863035253 Lambda1 1.2866494e-07\n",
      "1 Train Loss 854.5574 Test MSE 857.7672209497191 Test RE 0.4930306215049226 Lambda1 -0.0007962206\n",
      "2 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "3 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "4 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "5 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "6 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "7 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "8 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "9 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "10 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "12 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "13 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "14 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "15 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "16 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "17 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "18 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "19 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "20 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "21 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "22 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "23 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "24 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "25 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "26 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "27 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "28 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "29 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "30 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "31 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "32 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "33 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "34 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "35 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "36 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "37 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "38 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "39 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "40 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "41 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "42 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "43 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "44 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "45 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "46 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "47 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "48 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "49 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "50 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "51 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "52 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "53 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "54 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "55 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "56 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "57 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "58 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "59 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "60 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "61 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "62 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "63 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "64 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "65 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "66 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "67 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "68 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "69 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "70 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "71 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "72 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "73 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "74 Train Loss 854.5328 Test MSE 857.7041428807772 Test RE 0.4930124930485426 Lambda1 -0.00191771\n",
      "Training time: 301.29\n",
      "Training time: 301.29\n",
      "inv_HT_swish_tune3\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 854.71484 Test MSE 858.0703810530979 Test RE 0.4931177395518371 Lambda1 5.355073e-07\n",
      "1 Train Loss 854.5683 Test MSE 857.6237343928289 Test RE 0.4929893829128495 Lambda1 8.401793e-05\n",
      "2 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "3 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "4 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "5 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "6 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "7 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "8 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "9 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "10 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "11 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "13 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "14 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "15 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "16 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "17 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "18 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "19 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "20 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "21 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "22 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "23 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "24 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "25 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "26 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "27 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "28 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "29 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "30 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "31 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "32 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "33 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "34 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "35 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "36 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "37 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "38 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "39 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "40 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "41 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "42 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "43 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "44 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "45 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "46 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "47 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "48 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "49 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "50 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "51 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "52 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "53 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "54 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "55 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "56 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "57 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "58 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "59 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "60 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "61 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "62 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "63 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "64 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "65 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "66 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "67 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "68 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "69 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "70 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "71 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "72 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "73 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "74 Train Loss 854.5195 Test MSE 857.6754865136417 Test RE 0.49300425707047957 Lambda1 0.00046293472\n",
      "Training time: 309.39\n",
      "Training time: 309.39\n",
      "inv_HT_swish_tune3\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 854.7217 Test MSE 858.089705461469 Test RE 0.49312329221694123 Lambda1 -3.8499982e-07\n",
      "1 Train Loss 854.5091 Test MSE 857.6136344826326 Test RE 0.4929864800295949 Lambda1 5.4489105e-05\n",
      "2 Train Loss 854.5037 Test MSE 857.6480654303812 Test RE 0.49299637599013607 Lambda1 0.0010830417\n",
      "3 Train Loss 854.2124 Test MSE 856.9318205393612 Test RE 0.4927904757481081 Lambda1 0.040718272\n",
      "4 Train Loss 851.591 Test MSE 854.1427952927448 Test RE 0.4919878884386667 Lambda1 0.08049019\n",
      "5 Train Loss 847.41907 Test MSE 852.1583707446076 Test RE 0.491416039929473 Lambda1 0.09754814\n",
      "6 Train Loss 829.76526 Test MSE 828.0341293708997 Test RE 0.48441021130822526 Lambda1 0.2147713\n",
      "7 Train Loss 735.4396 Test MSE 695.7722495472735 Test RE 0.4440406423417745 Lambda1 0.43577945\n",
      "8 Train Loss 587.8113 Test MSE 544.1777841692073 Test RE 0.3926988003834198 Lambda1 0.34450412\n",
      "9 Train Loss 404.35828 Test MSE 323.34074614682004 Test RE 0.3027048565145053 Lambda1 0.24353626\n",
      "10 Train Loss 330.43198 Test MSE 303.3635132672683 Test RE 0.29320464302471805 Lambda1 0.107761264\n",
      "11 Train Loss 288.077 Test MSE 282.18579718214767 Test RE 0.282785245602453 Lambda1 0.0035310779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Train Loss 281.55637 Test MSE 281.45037799312536 Test RE 0.2824165144818721 Lambda1 0.0029601287\n",
      "13 Train Loss 276.27737 Test MSE 281.3604850314364 Test RE 0.2823714101111792 Lambda1 0.003320116\n",
      "14 Train Loss 274.3201 Test MSE 281.0150935808283 Test RE 0.28219804066967225 Lambda1 0.003375754\n",
      "15 Train Loss 273.59082 Test MSE 280.43872625849684 Test RE 0.2819084953430209 Lambda1 0.003239996\n",
      "16 Train Loss 272.6423 Test MSE 280.5106777848635 Test RE 0.2819446573345092 Lambda1 0.0021824508\n",
      "17 Train Loss 271.73056 Test MSE 278.90100673762873 Test RE 0.2811345436130245 Lambda1 0.0039064717\n",
      "18 Train Loss 271.20932 Test MSE 278.51553108650955 Test RE 0.28094019509886636 Lambda1 0.0044502118\n",
      "19 Train Loss 271.11075 Test MSE 278.323888487209 Test RE 0.28084352297816106 Lambda1 0.0048715095\n",
      "20 Train Loss 270.88516 Test MSE 277.16815888194486 Test RE 0.28025982024989887 Lambda1 0.005902401\n",
      "21 Train Loss 270.7762 Test MSE 277.15508993472696 Test RE 0.2802532128098712 Lambda1 0.005425736\n",
      "22 Train Loss 270.10724 Test MSE 276.0879410955446 Test RE 0.2797131535771383 Lambda1 0.00577288\n",
      "23 Train Loss 269.8763 Test MSE 275.6718122851211 Test RE 0.27950227766254243 Lambda1 0.0057996693\n",
      "24 Train Loss 269.6595 Test MSE 275.8396957134283 Test RE 0.2795873727947953 Lambda1 0.005416284\n",
      "25 Train Loss 269.58258 Test MSE 275.79619370783956 Test RE 0.279565325404201 Lambda1 0.005150484\n",
      "26 Train Loss 269.5478 Test MSE 275.36206844909 Test RE 0.2793452096634534 Lambda1 0.0057396875\n",
      "27 Train Loss 269.43088 Test MSE 274.62305031491024 Test RE 0.278970103762058 Lambda1 0.0072180843\n",
      "28 Train Loss 269.14087 Test MSE 274.5094801564879 Test RE 0.278912413857464 Lambda1 0.00723627\n",
      "29 Train Loss 268.9607 Test MSE 274.2697143207959 Test RE 0.27879058149530844 Lambda1 0.008099484\n",
      "30 Train Loss 268.86166 Test MSE 274.570764596433 Test RE 0.2789435458190416 Lambda1 0.0076349904\n",
      "31 Train Loss 268.66016 Test MSE 274.11937145830746 Test RE 0.27871416051747216 Lambda1 0.00827979\n",
      "32 Train Loss 267.2937 Test MSE 269.97560532970607 Test RE 0.276599526571879 Lambda1 0.016616162\n",
      "33 Train Loss 258.56647 Test MSE 254.35742899382151 Test RE 0.26847965675130187 Lambda1 0.060840346\n",
      "34 Train Loss 212.1343 Test MSE 198.1459230963633 Test RE 0.2369636556724577 Lambda1 0.21379907\n",
      "35 Train Loss 190.11261 Test MSE 166.1510130758933 Test RE 0.21699047347881043 Lambda1 0.29726815\n",
      "36 Train Loss 159.6872 Test MSE 142.27286671277406 Test RE 0.20079375979578767 Lambda1 0.33560827\n",
      "37 Train Loss 127.349464 Test MSE 101.59616251804682 Test RE 0.1696788932151014 Lambda1 0.48088476\n",
      "38 Train Loss 84.621475 Test MSE 63.10710561174753 Test RE 0.1337298327812811 Lambda1 0.5606983\n",
      "39 Train Loss 70.28429 Test MSE 53.79692618412666 Test RE 0.12347183473016893 Lambda1 0.6623351\n",
      "40 Train Loss 64.80733 Test MSE 53.30723708296649 Test RE 0.12290859592380127 Lambda1 0.7360415\n",
      "41 Train Loss 52.96341 Test MSE 45.16641282998409 Test RE 0.11313499721714418 Lambda1 0.7355851\n",
      "42 Train Loss 41.83056 Test MSE 37.719418000881156 Test RE 0.10338836376114119 Lambda1 0.78958267\n",
      "43 Train Loss 39.695538 Test MSE 37.12154207267997 Test RE 0.10256570631983963 Lambda1 0.838206\n",
      "44 Train Loss 37.11579 Test MSE 36.980191338745186 Test RE 0.10237024615777798 Lambda1 0.8339354\n",
      "45 Train Loss 36.550392 Test MSE 37.036397491573254 Test RE 0.10244801283284587 Lambda1 0.8361658\n",
      "46 Train Loss 35.347763 Test MSE 37.09389308777849 Test RE 0.10252750254713483 Lambda1 0.8366016\n",
      "47 Train Loss 34.72611 Test MSE 36.89496520770947 Test RE 0.10225221468902222 Lambda1 0.8544407\n",
      "48 Train Loss 34.123486 Test MSE 36.83453080370624 Test RE 0.10216843517821524 Lambda1 0.8610444\n",
      "49 Train Loss 33.946728 Test MSE 36.697528958358596 Test RE 0.10197825624259893 Lambda1 0.88253623\n",
      "50 Train Loss 33.720783 Test MSE 36.44913717591248 Test RE 0.10163254400392699 Lambda1 0.90950483\n",
      "51 Train Loss 33.352177 Test MSE 36.262689963235964 Test RE 0.10137227173626205 Lambda1 0.90804017\n",
      "52 Train Loss 33.04687 Test MSE 36.01176484517686 Test RE 0.10102093258150027 Lambda1 0.9258206\n",
      "53 Train Loss 32.66372 Test MSE 35.69311645828056 Test RE 0.1005730000459582 Lambda1 0.9209347\n",
      "54 Train Loss 32.024014 Test MSE 35.27639325332075 Test RE 0.09998417289578788 Lambda1 0.9388943\n",
      "55 Train Loss 31.770662 Test MSE 34.70890769244138 Test RE 0.09917669779227628 Lambda1 0.9745046\n",
      "56 Train Loss 31.253845 Test MSE 34.209054218852145 Test RE 0.09845997118013215 Lambda1 1.0237907\n",
      "57 Train Loss 31.141058 Test MSE 34.0842549714722 Test RE 0.098280209448997 Lambda1 1.0375308\n",
      "58 Train Loss 30.992338 Test MSE 34.04981793761412 Test RE 0.09823054818732974 Lambda1 1.0395062\n",
      "59 Train Loss 30.95168 Test MSE 33.93045482155408 Test RE 0.09805822130276871 Lambda1 1.0456101\n",
      "60 Train Loss 30.884966 Test MSE 34.018565741229295 Test RE 0.09818545800308912 Lambda1 1.0252047\n",
      "61 Train Loss 30.783098 Test MSE 33.985928862793195 Test RE 0.0981383479069561 Lambda1 1.0100524\n",
      "62 Train Loss 30.61778 Test MSE 34.10512614918247 Test RE 0.0983102953317994 Lambda1 0.9727335\n",
      "63 Train Loss 30.47927 Test MSE 34.06271263911953 Test RE 0.0982491464321405 Lambda1 0.963561\n",
      "64 Train Loss 30.359121 Test MSE 33.91194283615031 Test RE 0.09803146805067241 Lambda1 0.9673366\n",
      "65 Train Loss 30.313818 Test MSE 33.89679934642653 Test RE 0.09800957746916529 Lambda1 0.9539291\n",
      "66 Train Loss 30.27084 Test MSE 33.99094994842365 Test RE 0.09814559712547327 Lambda1 0.9358933\n",
      "67 Train Loss 30.218386 Test MSE 33.83996676335981 Test RE 0.09792737982377661 Lambda1 0.94351935\n",
      "68 Train Loss 30.17142 Test MSE 33.72684589410457 Test RE 0.09776356607744727 Lambda1 0.9545845\n",
      "69 Train Loss 30.06906 Test MSE 33.49122852754278 Test RE 0.09742147708186408 Lambda1 0.97368234\n",
      "70 Train Loss 30.002382 Test MSE 33.3848743697293 Test RE 0.09726666911593936 Lambda1 0.988301\n",
      "71 Train Loss 29.97353 Test MSE 33.35674198064924 Test RE 0.09722567868939747 Lambda1 0.9866578\n",
      "72 Train Loss 29.958939 Test MSE 33.37301992516091 Test RE 0.09724939864938614 Lambda1 0.9833357\n",
      "73 Train Loss 29.884369 Test MSE 33.40116249409496 Test RE 0.09729039390808664 Lambda1 0.9696824\n",
      "74 Train Loss 29.842155 Test MSE 33.37008571485359 Test RE 0.09724512339259296 Lambda1 0.9598121\n",
      "Training time: 293.37\n",
      "Training time: 293.37\n",
      "inv_HT_swish_tune3\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 854.7416 Test MSE 858.1046115959682 Test RE 0.49312757529489315 Lambda1 -2.6127425e-06\n",
      "1 Train Loss 854.6287 Test MSE 857.9784494819415 Test RE 0.49309132312735304 Lambda1 -0.00032409662\n",
      "2 Train Loss 854.522 Test MSE 857.6777028370155 Test RE 0.4930048940574108 Lambda1 -0.0021166955\n",
      "3 Train Loss 854.49536 Test MSE 857.7512001476234 Test RE 0.4930260172354288 Lambda1 -0.039782353\n",
      "4 Train Loss 852.7543 Test MSE 854.3146763952699 Test RE 0.4920373878709428 Lambda1 -0.4854226\n",
      "5 Train Loss 834.62067 Test MSE 830.666983677347 Test RE 0.48517972627102146 Lambda1 -0.45916966\n",
      "6 Train Loss 790.9515 Test MSE 786.5951604477981 Test RE 0.4721334880327406 Lambda1 -0.48892617\n",
      "7 Train Loss 574.2269 Test MSE 498.35076146997017 Test RE 0.3757999636247447 Lambda1 -0.5383387\n",
      "8 Train Loss 473.0265 Test MSE 422.82838904488597 Test RE 0.3461555027553489 Lambda1 -0.58236724\n",
      "9 Train Loss 432.27914 Test MSE 392.9527225379945 Test RE 0.3337023935066006 Lambda1 -0.509341\n",
      "10 Train Loss 405.52905 Test MSE 382.55124929706335 Test RE 0.3292562161522843 Lambda1 -0.48346934\n",
      "11 Train Loss 390.6189 Test MSE 376.2417359597102 Test RE 0.32652967450720266 Lambda1 -0.5012533\n",
      "12 Train Loss 385.94336 Test MSE 372.4207522744555 Test RE 0.32486738090424905 Lambda1 -0.51607275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Train Loss 376.37006 Test MSE 366.48074300094 Test RE 0.3222661941641531 Lambda1 -0.5336099\n",
      "14 Train Loss 374.22696 Test MSE 367.32993629750683 Test RE 0.32263934875481814 Lambda1 -0.5405975\n",
      "15 Train Loss 371.66238 Test MSE 367.96223119567463 Test RE 0.3229169132553353 Lambda1 -0.59380645\n",
      "16 Train Loss 368.03226 Test MSE 364.55762133283275 Test RE 0.32141952990855865 Lambda1 -0.6341462\n",
      "17 Train Loss 361.0214 Test MSE 355.5611682012428 Test RE 0.31742880403717866 Lambda1 -0.6997679\n",
      "18 Train Loss 351.31332 Test MSE 349.3201801617329 Test RE 0.31463063614205866 Lambda1 -0.8602429\n",
      "19 Train Loss 347.56952 Test MSE 344.80673653161807 Test RE 0.3125914116055977 Lambda1 -0.9887632\n",
      "20 Train Loss 345.64172 Test MSE 342.0889287173607 Test RE 0.3113570330229248 Lambda1 -1.0644727\n",
      "21 Train Loss 335.8147 Test MSE 329.5100699516026 Test RE 0.30557900770880136 Lambda1 -1.2825131\n",
      "22 Train Loss 327.78076 Test MSE 318.9083274547357 Test RE 0.3006229280982088 Lambda1 -1.4963632\n",
      "23 Train Loss 308.9371 Test MSE 304.22132388053325 Test RE 0.2936188927534587 Lambda1 -1.7274759\n",
      "24 Train Loss 284.0551 Test MSE 264.49826365396547 Test RE 0.27377928396802476 Lambda1 -1.6814044\n",
      "25 Train Loss 246.64601 Test MSE 230.77403758341796 Test RE 0.25573056895705326 Lambda1 -1.5311671\n",
      "26 Train Loss 206.26775 Test MSE 182.81904275414502 Test RE 0.227614479539723 Lambda1 -1.3650192\n",
      "27 Train Loss 178.03542 Test MSE 158.60560901915727 Test RE 0.212006141307897 Lambda1 -1.2169032\n",
      "28 Train Loss 154.76001 Test MSE 137.88457446841738 Test RE 0.19767284469516996 Lambda1 -1.253093\n",
      "29 Train Loss 124.87895 Test MSE 120.148507481974 Test RE 0.1845220881858408 Lambda1 -1.3975354\n",
      "30 Train Loss 116.792046 Test MSE 115.65608872555084 Test RE 0.18103953323254596 Lambda1 -1.466423\n",
      "31 Train Loss 107.392685 Test MSE 107.95179627903865 Test RE 0.17490575812337653 Lambda1 -1.6545624\n",
      "32 Train Loss 103.9141 Test MSE 106.7099800577009 Test RE 0.17389683991796617 Lambda1 -1.6683987\n",
      "33 Train Loss 101.14978 Test MSE 103.65548369834973 Test RE 0.1713899341491154 Lambda1 -1.7787011\n",
      "34 Train Loss 99.603355 Test MSE 102.77628399818704 Test RE 0.17066152662518963 Lambda1 -1.8032893\n",
      "35 Train Loss 98.04768 Test MSE 101.19220162398506 Test RE 0.16934122343343577 Lambda1 -1.8383528\n",
      "36 Train Loss 94.72433 Test MSE 96.98645478871313 Test RE 0.16578480122809555 Lambda1 -2.0100617\n",
      "37 Train Loss 94.25924 Test MSE 95.63109673186976 Test RE 0.1646223279633777 Lambda1 -2.0741267\n",
      "38 Train Loss 93.80168 Test MSE 95.85302313266773 Test RE 0.16481323275717594 Lambda1 -2.0518885\n",
      "39 Train Loss 92.2685 Test MSE 93.5557854210266 Test RE 0.16282627785628778 Lambda1 -2.1808114\n",
      "40 Train Loss 91.251015 Test MSE 93.37141088214968 Test RE 0.1626657542430591 Lambda1 -2.164978\n",
      "41 Train Loss 89.18802 Test MSE 91.29812466161817 Test RE 0.16084964215717598 Lambda1 -2.2628274\n",
      "42 Train Loss 88.20653 Test MSE 90.20496113187531 Test RE 0.15988377083885785 Lambda1 -2.35722\n",
      "43 Train Loss 87.887474 Test MSE 90.06179748637693 Test RE 0.15975684526639716 Lambda1 -2.3775806\n",
      "44 Train Loss 87.523865 Test MSE 89.93807194037464 Test RE 0.1596470717737143 Lambda1 -2.3735528\n",
      "45 Train Loss 86.106606 Test MSE 88.9686668646207 Test RE 0.15878435606410998 Lambda1 -2.4148476\n",
      "46 Train Loss 85.29294 Test MSE 87.70480837967429 Test RE 0.15765250385337543 Lambda1 -2.4386368\n",
      "47 Train Loss 85.095795 Test MSE 87.97101846960312 Test RE 0.15789158361075992 Lambda1 -2.411885\n",
      "48 Train Loss 84.81494 Test MSE 88.03983585370845 Test RE 0.15795332872745832 Lambda1 -2.3884451\n",
      "49 Train Loss 84.51094 Test MSE 87.66128232108761 Test RE 0.1576133791815194 Lambda1 -2.403081\n",
      "50 Train Loss 84.11618 Test MSE 86.98070892061271 Test RE 0.15700035778785465 Lambda1 -2.4604905\n",
      "51 Train Loss 83.66768 Test MSE 86.01420942285921 Test RE 0.15612565436314288 Lambda1 -2.5430868\n",
      "52 Train Loss 82.92072 Test MSE 84.68339132023137 Test RE 0.15491315236231049 Lambda1 -2.6474378\n",
      "53 Train Loss 82.11189 Test MSE 83.68269708970573 Test RE 0.1539951365212741 Lambda1 -2.7343788\n",
      "54 Train Loss 81.70154 Test MSE 83.23557836479056 Test RE 0.1535831856024225 Lambda1 -2.8325205\n",
      "55 Train Loss 81.0477 Test MSE 83.22421033993174 Test RE 0.15357269731650133 Lambda1 -2.8354056\n",
      "56 Train Loss 80.61782 Test MSE 83.04241165986318 Test RE 0.15340487008643625 Lambda1 -2.851345\n",
      "57 Train Loss 80.33716 Test MSE 83.02996473317242 Test RE 0.15339337300507655 Lambda1 -2.8473117\n",
      "58 Train Loss 79.8839 Test MSE 82.1847320018524 Test RE 0.1526106149211221 Lambda1 -2.944098\n",
      "59 Train Loss 79.333694 Test MSE 81.35365016802585 Test RE 0.1518370272927777 Lambda1 -3.0414472\n",
      "60 Train Loss 78.97559 Test MSE 80.9272918428693 Test RE 0.15143863077385483 Lambda1 -3.0815701\n",
      "61 Train Loss 78.76008 Test MSE 80.5876272906475 Test RE 0.15112049074472234 Lambda1 -3.146561\n",
      "62 Train Loss 78.09386 Test MSE 79.51091633838828 Test RE 0.1501075546002717 Lambda1 -3.2463524\n",
      "63 Train Loss 76.458336 Test MSE 79.08568934840326 Test RE 0.14970562643447252 Lambda1 -3.289846\n",
      "64 Train Loss 76.174446 Test MSE 79.00275216424426 Test RE 0.14962710767761547 Lambda1 -3.2884567\n",
      "65 Train Loss 75.812065 Test MSE 78.9882604894461 Test RE 0.1496133838086898 Lambda1 -3.282916\n",
      "66 Train Loss 75.32787 Test MSE 78.96099154522679 Test RE 0.1495875562289452 Lambda1 -3.2982428\n",
      "67 Train Loss 74.98893 Test MSE 79.23448209811828 Test RE 0.14984638922397464 Lambda1 -3.2530236\n",
      "68 Train Loss 74.705826 Test MSE 78.84587103014138 Test RE 0.1494784714934192 Lambda1 -3.2963688\n",
      "69 Train Loss 74.3495 Test MSE 78.50865760994488 Test RE 0.14915847910425675 Lambda1 -3.3535602\n",
      "70 Train Loss 74.22069 Test MSE 78.37162149612294 Test RE 0.14902824489675193 Lambda1 -3.4011314\n",
      "71 Train Loss 74.06096 Test MSE 78.1201227828753 Test RE 0.14878893295821538 Lambda1 -3.4401517\n",
      "72 Train Loss 73.88011 Test MSE 77.99171627727338 Test RE 0.14866660004530122 Lambda1 -3.4652638\n",
      "73 Train Loss 73.757385 Test MSE 77.85390441581723 Test RE 0.14853519455451294 Lambda1 -3.5004275\n",
      "74 Train Loss 73.63421 Test MSE 77.62963607861805 Test RE 0.14832110275225546 Lambda1 -3.5429041\n",
      "Training time: 272.00\n",
      "Training time: 272.00\n",
      "inv_HT_swish_tune3\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 854.7604 Test MSE 858.1248172266438 Test RE 0.49313338105264903 Lambda1 5.5864916e-06\n",
      "1 Train Loss 854.6998 Test MSE 858.002474518073 Test RE 0.49309822682868204 Lambda1 0.00023175092\n",
      "2 Train Loss 854.5571 Test MSE 857.8317730089808 Test RE 0.4930491728918058 Lambda1 0.004060493\n",
      "3 Train Loss 854.5292 Test MSE 857.6809749000059 Test RE 0.49300583446983154 Lambda1 0.007316127\n",
      "4 Train Loss 854.4802 Test MSE 857.629579583903 Test RE 0.4929910629107993 Lambda1 0.5914448\n",
      "5 Train Loss 854.086 Test MSE 856.5740389620278 Test RE 0.49268759138994384 Lambda1 2.6281307\n",
      "6 Train Loss 841.5281 Test MSE 839.6233184001736 Test RE 0.4877883417677274 Lambda1 2.354316\n",
      "7 Train Loss 814.3674 Test MSE 800.8420577551798 Test RE 0.4763899676718005 Lambda1 2.5770133\n",
      "8 Train Loss 719.397 Test MSE 686.178833631451 Test RE 0.4409687660152347 Lambda1 1.7838619\n",
      "9 Train Loss 659.1873 Test MSE 651.1976849934086 Test RE 0.4295815242212755 Lambda1 1.735792\n",
      "10 Train Loss 607.026 Test MSE 592.1346247511703 Test RE 0.40963720959642813 Lambda1 1.8676804\n",
      "11 Train Loss 572.02045 Test MSE 568.639120492063 Test RE 0.4014278855300715 Lambda1 1.8217045\n",
      "12 Train Loss 523.29297 Test MSE 512.3640695746155 Test RE 0.3810469623741111 Lambda1 1.6796801\n",
      "13 Train Loss 484.40274 Test MSE 460.46364033274773 Test RE 0.36123252093854974 Lambda1 1.8834181\n",
      "14 Train Loss 432.80475 Test MSE 375.6514697759755 Test RE 0.3262734362160959 Lambda1 2.162409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Train Loss 396.47354 Test MSE 350.7036079075642 Test RE 0.31525304314040054 Lambda1 2.1250234\n",
      "16 Train Loss 361.018 Test MSE 316.59360534308826 Test RE 0.29952994029544366 Lambda1 2.05233\n",
      "17 Train Loss 335.52728 Test MSE 305.97924354120914 Test RE 0.29446599794454703 Lambda1 1.8711069\n",
      "18 Train Loss 292.18756 Test MSE 259.2945617560656 Test RE 0.27107275819136223 Lambda1 1.4837159\n",
      "19 Train Loss 224.59543 Test MSE 185.683692327021 Test RE 0.22939082977901765 Lambda1 1.0786082\n",
      "20 Train Loss 195.97003 Test MSE 160.40232424964333 Test RE 0.213203583075092 Lambda1 0.68702257\n",
      "21 Train Loss 173.0772 Test MSE 146.60204061230218 Test RE 0.20382581069784525 Lambda1 0.57005024\n",
      "22 Train Loss 159.13689 Test MSE 143.9941096978108 Test RE 0.20200472786900595 Lambda1 0.60733217\n",
      "23 Train Loss 126.86461 Test MSE 108.58357171144618 Test RE 0.17541681936697684 Lambda1 0.63074464\n",
      "24 Train Loss 103.953064 Test MSE 89.18611325836005 Test RE 0.15897827835068792 Lambda1 0.6502938\n",
      "25 Train Loss 88.46758 Test MSE 78.51365935818127 Test RE 0.1491632304355126 Lambda1 0.65100527\n",
      "26 Train Loss 76.07492 Test MSE 66.17287487960826 Test RE 0.13693963694128092 Lambda1 0.6550686\n",
      "27 Train Loss 66.53545 Test MSE 59.12325509197654 Test RE 0.12943995071867834 Lambda1 0.6317524\n",
      "28 Train Loss 61.427788 Test MSE 55.70531686010526 Test RE 0.12564276783638323 Lambda1 0.6075569\n",
      "29 Train Loss 55.975346 Test MSE 54.92186577308029 Test RE 0.1247561063249168 Lambda1 0.580866\n",
      "30 Train Loss 51.974983 Test MSE 49.874207103146226 Test RE 0.11888503030197237 Lambda1 0.5568829\n",
      "31 Train Loss 48.51913 Test MSE 46.377303524066484 Test RE 0.11464151528186423 Lambda1 0.5911455\n",
      "32 Train Loss 43.94143 Test MSE 42.56391686602918 Test RE 0.10982721319798766 Lambda1 0.67086864\n",
      "33 Train Loss 39.214367 Test MSE 38.902539785667685 Test RE 0.10499730412148381 Lambda1 0.7324277\n",
      "34 Train Loss 35.951553 Test MSE 35.91142246086868 Test RE 0.10088009316006935 Lambda1 0.7839085\n",
      "35 Train Loss 33.622597 Test MSE 35.61799058570249 Test RE 0.10046710267627157 Lambda1 0.7829176\n",
      "36 Train Loss 33.208 Test MSE 35.53808712467839 Test RE 0.10035434818960709 Lambda1 0.78174263\n",
      "37 Train Loss 32.013626 Test MSE 34.60066335483318 Test RE 0.09902192918060228 Lambda1 0.861321\n",
      "38 Train Loss 31.826729 Test MSE 34.465140619806995 Test RE 0.09882781600983392 Lambda1 0.89212364\n",
      "39 Train Loss 31.603369 Test MSE 34.39203501631762 Test RE 0.09872294624404168 Lambda1 0.95481026\n",
      "40 Train Loss 31.316278 Test MSE 34.31148716620027 Test RE 0.09860727145943021 Lambda1 1.008943\n",
      "41 Train Loss 31.161993 Test MSE 34.29995296502508 Test RE 0.09859069608190801 Lambda1 1.0118351\n",
      "42 Train Loss 30.986992 Test MSE 34.24723129996339 Test RE 0.09851489620284308 Lambda1 1.0041652\n",
      "43 Train Loss 30.919575 Test MSE 34.18516533511118 Test RE 0.09842558686826619 Lambda1 0.9804445\n",
      "44 Train Loss 30.883194 Test MSE 34.17751032862408 Test RE 0.09841456614212936 Lambda1 0.9575283\n",
      "45 Train Loss 30.763613 Test MSE 34.21609289242173 Test RE 0.0984700999598935 Lambda1 0.9404485\n",
      "46 Train Loss 30.708168 Test MSE 34.18143145643476 Test RE 0.09842021144836874 Lambda1 0.956003\n",
      "47 Train Loss 30.697607 Test MSE 34.17858010738416 Test RE 0.09841610635070064 Lambda1 0.96586293\n",
      "48 Train Loss 30.637985 Test MSE 34.10930636197012 Test RE 0.09831632001794273 Lambda1 0.9698683\n",
      "49 Train Loss 30.544716 Test MSE 34.08607121853238 Test RE 0.09828282794196029 Lambda1 0.94152457\n",
      "50 Train Loss 30.537432 Test MSE 34.088420065513354 Test RE 0.0982862141835925 Lambda1 0.9343197\n",
      "51 Train Loss 30.505901 Test MSE 34.02744291656903 Test RE 0.09819826795925732 Lambda1 0.9403393\n",
      "52 Train Loss 30.452028 Test MSE 33.95415080237637 Test RE 0.09809245574208227 Lambda1 0.971091\n",
      "53 Train Loss 30.42968 Test MSE 33.90063763391173 Test RE 0.0980151263453585 Lambda1 0.9658644\n",
      "54 Train Loss 30.400131 Test MSE 33.85991622874501 Test RE 0.09795624083078204 Lambda1 0.9541533\n",
      "55 Train Loss 30.38542 Test MSE 33.846498170121535 Test RE 0.09793682978417304 Lambda1 0.96345884\n",
      "56 Train Loss 30.301199 Test MSE 33.73931217190383 Test RE 0.09778163232618813 Lambda1 0.9838082\n",
      "57 Train Loss 30.137577 Test MSE 33.66489001280971 Test RE 0.09767372945076105 Lambda1 0.98572874\n",
      "58 Train Loss 30.089006 Test MSE 33.607566189325055 Test RE 0.09759053569709146 Lambda1 0.97492075\n",
      "59 Train Loss 30.06543 Test MSE 33.567401935177024 Test RE 0.09753220325424468 Lambda1 0.9595567\n",
      "60 Train Loss 30.040934 Test MSE 33.538169714113266 Test RE 0.09748972597346303 Lambda1 0.95805\n",
      "61 Train Loss 30.031214 Test MSE 33.5454021835424 Test RE 0.09750023718292701 Lambda1 0.95881355\n",
      "62 Train Loss 30.020033 Test MSE 33.551471548812984 Test RE 0.09750905713663699 Lambda1 0.96452653\n",
      "63 Train Loss 29.99748 Test MSE 33.5883782367627 Test RE 0.09756267247849112 Lambda1 0.98296434\n",
      "64 Train Loss 29.95546 Test MSE 33.53986672803223 Test RE 0.09749219240694144 Lambda1 0.9650298\n",
      "65 Train Loss 29.935923 Test MSE 33.52091431963231 Test RE 0.09746464350585031 Lambda1 0.9545279\n",
      "66 Train Loss 29.92954 Test MSE 33.538577146150715 Test RE 0.09749031813930557 Lambda1 0.9495225\n",
      "67 Train Loss 29.920773 Test MSE 33.52154944890402 Test RE 0.09746556684514583 Lambda1 0.946159\n",
      "68 Train Loss 29.917938 Test MSE 33.52220164571932 Test RE 0.09746651498782061 Lambda1 0.94376004\n",
      "69 Train Loss 29.911423 Test MSE 33.52822162242221 Test RE 0.0974752662001645 Lambda1 0.95389664\n",
      "70 Train Loss 29.90032 Test MSE 33.52990230319777 Test RE 0.09747770925776036 Lambda1 0.949118\n",
      "71 Train Loss 29.89184 Test MSE 33.557600930511 Test RE 0.09751796349615899 Lambda1 0.9456755\n",
      "72 Train Loss 29.88799 Test MSE 33.54521703508814 Test RE 0.09749996811411374 Lambda1 0.94055104\n",
      "73 Train Loss 29.87151 Test MSE 33.55697954109337 Test RE 0.09751706061708858 Lambda1 0.9320227\n",
      "74 Train Loss 29.855547 Test MSE 33.54176053417141 Test RE 0.0974949447838039 Lambda1 0.9364406\n",
      "Training time: 274.16\n",
      "Training time: 274.16\n",
      "inv_HT_swish_tune4\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 854.70013 Test MSE 858.020043662 Test RE 0.49310327533939496 Lambda1 -9.80088e-06\n",
      "1 Train Loss 854.39606 Test MSE 857.706490676958 Test RE 0.4930131678103855 Lambda1 0.09474899\n",
      "2 Train Loss 851.68396 Test MSE 856.9103825178033 Test RE 0.49278431159440095 Lambda1 0.23951873\n",
      "3 Train Loss 815.4092 Test MSE 815.2977084481136 Test RE 0.48067029225326185 Lambda1 0.41177243\n",
      "4 Train Loss 747.96826 Test MSE 726.6248096188449 Test RE 0.453778882976033 Lambda1 0.40243563\n",
      "5 Train Loss 606.3187 Test MSE 512.8724510395155 Test RE 0.3812359580467104 Lambda1 0.3404357\n",
      "6 Train Loss 490.77063 Test MSE 425.57677180048887 Test RE 0.347278685199484 Lambda1 0.28158325\n",
      "7 Train Loss 362.4515 Test MSE 312.4796545694609 Test RE 0.29757746758354214 Lambda1 0.18936636\n",
      "8 Train Loss 307.23718 Test MSE 285.60323204264483 Test RE 0.28449243964387255 Lambda1 0.11235165\n",
      "9 Train Loss 290.77393 Test MSE 269.1372679913011 Test RE 0.27616973958438695 Lambda1 0.09312609\n",
      "10 Train Loss 249.32582 Test MSE 248.61848998232693 Test RE 0.2654335911400118 Lambda1 0.07631124\n",
      "11 Train Loss 229.82251 Test MSE 229.3142303363744 Test RE 0.2549204483954325 Lambda1 0.12842344\n",
      "12 Train Loss 218.87625 Test MSE 212.2347394839706 Test RE 0.2452434442990257 Lambda1 0.20544963\n",
      "13 Train Loss 202.6624 Test MSE 198.98957785210789 Test RE 0.23746758521699676 Lambda1 0.24246576\n",
      "14 Train Loss 195.83574 Test MSE 186.9688790312337 Test RE 0.23018331100280087 Lambda1 0.32624802\n",
      "15 Train Loss 185.24763 Test MSE 179.00735293267743 Test RE 0.2252291541708715 Lambda1 0.51245576\n",
      "16 Train Loss 171.31464 Test MSE 163.90670626224917 Test RE 0.21551997708555076 Lambda1 0.6041475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 Train Loss 117.87914 Test MSE 110.45570659918533 Test RE 0.17692257423278254 Lambda1 0.71542585\n",
      "18 Train Loss 64.759384 Test MSE 61.62029536585433 Test RE 0.1321450983418871 Lambda1 0.7108162\n",
      "19 Train Loss 57.455418 Test MSE 55.79507741930195 Test RE 0.1257439540991638 Lambda1 0.682231\n",
      "20 Train Loss 51.929314 Test MSE 54.65127849531976 Test RE 0.1244484046819026 Lambda1 0.7078118\n",
      "21 Train Loss 49.501938 Test MSE 52.5573700291491 Test RE 0.1220410633822393 Lambda1 0.7839126\n",
      "22 Train Loss 48.43628 Test MSE 49.73921034487649 Test RE 0.11872402555067883 Lambda1 0.86805993\n",
      "23 Train Loss 44.694218 Test MSE 46.34931245780186 Test RE 0.11460691406162636 Lambda1 0.9049093\n",
      "24 Train Loss 42.116917 Test MSE 44.634356325170856 Test RE 0.1124666628293801 Lambda1 0.8829119\n",
      "25 Train Loss 40.28073 Test MSE 43.090685273384594 Test RE 0.11050473081985233 Lambda1 0.90460986\n",
      "26 Train Loss 39.26316 Test MSE 42.2263319512925 Test RE 0.10939081282805538 Lambda1 0.8922421\n",
      "27 Train Loss 38.35128 Test MSE 41.4835337345694 Test RE 0.10842440380250534 Lambda1 0.87740666\n",
      "28 Train Loss 37.20912 Test MSE 40.58747680814012 Test RE 0.107247011058384 Lambda1 0.88585955\n",
      "29 Train Loss 36.467754 Test MSE 39.553022175259485 Test RE 0.10587148555702924 Lambda1 0.90201247\n",
      "30 Train Loss 36.361504 Test MSE 39.47748223536867 Test RE 0.1057703384465911 Lambda1 0.90995073\n",
      "31 Train Loss 36.165276 Test MSE 39.4116584962523 Test RE 0.10568212228715343 Lambda1 0.8935581\n",
      "32 Train Loss 36.000362 Test MSE 39.32288451738651 Test RE 0.10556303174517608 Lambda1 0.8776669\n",
      "33 Train Loss 35.345787 Test MSE 39.41469761272521 Test RE 0.10568619689476327 Lambda1 0.88850564\n",
      "34 Train Loss 35.213764 Test MSE 39.51134690428898 Test RE 0.10581569480502515 Lambda1 0.88218653\n",
      "35 Train Loss 34.97593 Test MSE 39.58358374285332 Test RE 0.10591237969874491 Lambda1 0.88990915\n",
      "36 Train Loss 34.84163 Test MSE 39.737400942653444 Test RE 0.10611796176625507 Lambda1 0.8830245\n",
      "37 Train Loss 34.80121 Test MSE 39.620729114474905 Test RE 0.10596206231724525 Lambda1 0.88791114\n",
      "38 Train Loss 34.65479 Test MSE 39.49584914932725 Test RE 0.10579494043094569 Lambda1 0.9106183\n",
      "39 Train Loss 34.43043 Test MSE 39.0871478810984 Test RE 0.10524613634950711 Lambda1 0.9230699\n",
      "40 Train Loss 34.414097 Test MSE 39.07551170268352 Test RE 0.10523046938421264 Lambda1 0.9189261\n",
      "41 Train Loss 34.38895 Test MSE 39.11975243814802 Test RE 0.1052900227487927 Lambda1 0.91643006\n",
      "42 Train Loss 34.32422 Test MSE 39.09674051721342 Test RE 0.10525905013330078 Lambda1 0.9227715\n",
      "43 Train Loss 34.31218 Test MSE 39.08591319708958 Test RE 0.10524447408000445 Lambda1 0.92437774\n",
      "44 Train Loss 34.305126 Test MSE 39.13456991451633 Test RE 0.10530996132995607 Lambda1 0.9178392\n",
      "45 Train Loss 34.296673 Test MSE 39.11705658165912 Test RE 0.10528639476467092 Lambda1 0.9209325\n",
      "46 Train Loss 34.212635 Test MSE 39.00975494032763 Test RE 0.10514189052469143 Lambda1 0.9107818\n",
      "47 Train Loss 34.163094 Test MSE 38.9127384319535 Test RE 0.10501106620744112 Lambda1 0.91201\n",
      "48 Train Loss 34.11947 Test MSE 38.879004680638914 Test RE 0.10496553888906653 Lambda1 0.89602035\n",
      "49 Train Loss 34.05447 Test MSE 38.73729230314162 Test RE 0.10477406671060246 Lambda1 0.9027881\n",
      "50 Train Loss 33.977753 Test MSE 38.73044470239477 Test RE 0.10476480583247189 Lambda1 0.9014086\n",
      "51 Train Loss 33.919773 Test MSE 38.694780425889 Test RE 0.10471655927127825 Lambda1 0.90041786\n",
      "52 Train Loss 33.86691 Test MSE 38.60216563196371 Test RE 0.10459116622659852 Lambda1 0.9048379\n",
      "53 Train Loss 33.80693 Test MSE 38.323538599477594 Test RE 0.1042130177160501 Lambda1 0.92342764\n",
      "54 Train Loss 33.68815 Test MSE 37.967749474967164 Test RE 0.10372814187207872 Lambda1 0.96242106\n",
      "55 Train Loss 33.66245 Test MSE 37.89480813920155 Test RE 0.10362845586629316 Lambda1 0.9706999\n",
      "56 Train Loss 33.599247 Test MSE 37.7437262994279 Test RE 0.1034216727379053 Lambda1 0.9882923\n",
      "57 Train Loss 33.48648 Test MSE 37.66611211769205 Test RE 0.1033152826155386 Lambda1 0.97735095\n",
      "58 Train Loss 33.401466 Test MSE 37.58076129460533 Test RE 0.10319816081867421 Lambda1 0.9751681\n",
      "59 Train Loss 33.15452 Test MSE 37.28286309044763 Test RE 0.10278832728269795 Lambda1 1.0153816\n",
      "60 Train Loss 32.91131 Test MSE 37.00863696454953 Test RE 0.10240961082628852 Lambda1 1.031695\n",
      "61 Train Loss 32.84576 Test MSE 36.6751301683956 Test RE 0.10194712964825525 Lambda1 1.0294263\n",
      "62 Train Loss 32.5202 Test MSE 36.159997066163456 Test RE 0.10122863108323216 Lambda1 1.0783626\n",
      "63 Train Loss 32.20396 Test MSE 35.80946926750972 Test RE 0.10073679115224642 Lambda1 1.0792296\n",
      "64 Train Loss 32.0455 Test MSE 35.59886376305203 Test RE 0.10044012369080277 Lambda1 1.0436229\n",
      "65 Train Loss 31.592762 Test MSE 34.961540793914864 Test RE 0.09953697835903637 Lambda1 0.9778442\n",
      "66 Train Loss 31.421547 Test MSE 34.6938852094519 Test RE 0.09915523296379912 Lambda1 0.93351126\n",
      "67 Train Loss 31.392885 Test MSE 34.65122578957925 Test RE 0.09909425383509639 Lambda1 0.92213506\n",
      "68 Train Loss 31.349758 Test MSE 34.65987377202232 Test RE 0.09910661864883441 Lambda1 0.93976885\n",
      "69 Train Loss 31.33262 Test MSE 34.60646124743528 Test RE 0.09903022518429577 Lambda1 0.9458152\n",
      "70 Train Loss 31.251162 Test MSE 34.46643157956066 Test RE 0.09882966688779386 Lambda1 0.93647027\n",
      "71 Train Loss 31.066011 Test MSE 34.474162383274596 Test RE 0.0988407499892722 Lambda1 0.9607044\n",
      "72 Train Loss 30.954432 Test MSE 34.34832318887494 Test RE 0.09866018850881961 Lambda1 0.98070896\n",
      "73 Train Loss 30.907324 Test MSE 34.24774059755968 Test RE 0.09851562871772672 Lambda1 0.99688345\n",
      "74 Train Loss 30.895397 Test MSE 34.153523517538034 Test RE 0.09838002492009389 Lambda1 0.9985334\n",
      "Training time: 297.69\n",
      "Training time: 297.69\n",
      "inv_HT_swish_tune4\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 854.7197 Test MSE 858.0490645330894 Test RE 0.49311161440192075 Lambda1 0.00017101111\n",
      "1 Train Loss 854.518 Test MSE 857.6897576368632 Test RE 0.4930083586772906 Lambda1 0.056265812\n",
      "2 Train Loss 854.16296 Test MSE 856.264457591719 Test RE 0.4925985502348742 Lambda1 0.87372524\n",
      "3 Train Loss 851.2885 Test MSE 851.3476337635774 Test RE 0.4911822195644527 Lambda1 1.7122843\n",
      "4 Train Loss 818.29047 Test MSE 813.3762342360262 Test RE 0.4801035419847945 Lambda1 1.6820501\n",
      "5 Train Loss 777.98987 Test MSE 756.6520048923414 Test RE 0.4630599965629387 Lambda1 1.7982761\n",
      "6 Train Loss 662.33795 Test MSE 644.8506596418594 Test RE 0.42748289794177835 Lambda1 1.8457228\n",
      "7 Train Loss 605.7761 Test MSE 599.7392263925545 Test RE 0.4122592398952842 Lambda1 1.842998\n",
      "8 Train Loss 587.1149 Test MSE 580.6740613814152 Test RE 0.4056536461663788 Lambda1 1.8756403\n",
      "9 Train Loss 520.6697 Test MSE 519.8011367307752 Test RE 0.3838024856686744 Lambda1 1.9322339\n",
      "10 Train Loss 469.24594 Test MSE 443.2563532459063 Test RE 0.3544187219738966 Lambda1 1.9637073\n",
      "11 Train Loss 400.39566 Test MSE 360.2602652629313 Test RE 0.31951948891947707 Lambda1 2.030232\n",
      "12 Train Loss 355.0045 Test MSE 327.4352518852288 Test RE 0.3046154225040288 Lambda1 2.0208552\n",
      "13 Train Loss 283.66962 Test MSE 230.2991974938725 Test RE 0.2554673381881648 Lambda1 1.9648454\n",
      "14 Train Loss 212.74864 Test MSE 176.59344673868247 Test RE 0.22370539722243482 Lambda1 1.9319814\n",
      "15 Train Loss 154.80675 Test MSE 127.7416518930815 Test RE 0.19026347942594435 Lambda1 1.8531083\n",
      "16 Train Loss 109.048676 Test MSE 79.45988985038267 Test RE 0.15005938077109787 Lambda1 1.826592\n",
      "17 Train Loss 78.89502 Test MSE 58.350963845188325 Test RE 0.12859177399796004 Lambda1 1.7796926\n",
      "18 Train Loss 56.995808 Test MSE 45.23446602527865 Test RE 0.11322019659013449 Lambda1 1.754668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Train Loss 54.156757 Test MSE 43.613424270513214 Test RE 0.11117298426319455 Lambda1 1.7428331\n",
      "20 Train Loss 48.975773 Test MSE 43.190095182349296 Test RE 0.11063212420808186 Lambda1 1.7589861\n",
      "21 Train Loss 40.343163 Test MSE 41.42500913881447 Test RE 0.10834789472224216 Lambda1 1.7082089\n",
      "22 Train Loss 39.55408 Test MSE 41.16970207198056 Test RE 0.10801349846484348 Lambda1 1.6983961\n",
      "23 Train Loss 36.66212 Test MSE 38.88690626669813 Test RE 0.10497620469840671 Lambda1 1.5743935\n",
      "24 Train Loss 36.11083 Test MSE 38.28139793713455 Test RE 0.10415570550440051 Lambda1 1.5373026\n",
      "25 Train Loss 35.625298 Test MSE 37.510789703676224 Test RE 0.10310204376911565 Lambda1 1.4621761\n",
      "26 Train Loss 34.810566 Test MSE 36.72760247351066 Test RE 0.10202003312323839 Lambda1 1.3877017\n",
      "27 Train Loss 34.22495 Test MSE 36.160689048578895 Test RE 0.1012295996687301 Lambda1 1.3165513\n",
      "28 Train Loss 33.504993 Test MSE 35.32248904221116 Test RE 0.10004947640734621 Lambda1 1.1974069\n",
      "29 Train Loss 32.88686 Test MSE 34.814313903830126 Test RE 0.09932717667470667 Lambda1 1.1281602\n",
      "30 Train Loss 32.526867 Test MSE 34.79420337457433 Test RE 0.09929848430051509 Lambda1 1.14307\n",
      "31 Train Loss 32.288116 Test MSE 34.65701039741462 Test RE 0.09910252479035113 Lambda1 1.1294522\n",
      "32 Train Loss 31.84909 Test MSE 34.255299104723775 Test RE 0.09852649936191801 Lambda1 1.0981731\n",
      "33 Train Loss 31.642818 Test MSE 34.09538928511222 Test RE 0.09829626075075952 Lambda1 1.0640136\n",
      "34 Train Loss 31.504583 Test MSE 33.90622176416924 Test RE 0.09802319856366602 Lambda1 1.0301356\n",
      "35 Train Loss 31.320364 Test MSE 33.734502935301535 Test RE 0.09777466313011098 Lambda1 0.9982191\n",
      "36 Train Loss 30.968319 Test MSE 33.72507216686787 Test RE 0.09776099530370211 Lambda1 0.9849149\n",
      "37 Train Loss 30.766346 Test MSE 33.660306744149494 Test RE 0.09766708038431977 Lambda1 0.96921754\n",
      "38 Train Loss 30.753277 Test MSE 33.65476190396923 Test RE 0.09765903573606712 Lambda1 0.9634285\n",
      "39 Train Loss 30.739609 Test MSE 33.65330998909082 Test RE 0.09765692913764995 Lambda1 0.9617494\n",
      "40 Train Loss 30.704643 Test MSE 33.65477517282567 Test RE 0.09765905498777955 Lambda1 0.95063794\n",
      "41 Train Loss 30.64994 Test MSE 33.663882592655675 Test RE 0.09767226799908713 Lambda1 0.9278726\n",
      "42 Train Loss 30.631498 Test MSE 33.696340040481914 Test RE 0.09771934261617893 Lambda1 0.9080305\n",
      "43 Train Loss 30.60997 Test MSE 33.706878609545605 Test RE 0.09773462233992435 Lambda1 0.8968964\n",
      "44 Train Loss 30.581139 Test MSE 33.69356766024851 Test RE 0.09771532258394086 Lambda1 0.89429516\n",
      "45 Train Loss 30.570805 Test MSE 33.649193690887095 Test RE 0.0976509565106624 Lambda1 0.9009253\n",
      "46 Train Loss 30.56613 Test MSE 33.606986446989445 Test RE 0.09758969395793103 Lambda1 0.9135927\n",
      "47 Train Loss 30.552702 Test MSE 33.568389419641015 Test RE 0.09753363784288707 Lambda1 0.93376416\n",
      "48 Train Loss 30.533243 Test MSE 33.57190444644543 Test RE 0.09753874420013298 Lambda1 0.92496186\n",
      "49 Train Loss 30.526352 Test MSE 33.56967623902894 Test RE 0.09753550726491667 Lambda1 0.92331344\n",
      "50 Train Loss 30.519184 Test MSE 33.5429426192389 Test RE 0.09749666273630811 Lambda1 0.9274061\n",
      "51 Train Loss 30.502024 Test MSE 33.53903459640449 Test RE 0.09749098299784312 Lambda1 0.9170584\n",
      "52 Train Loss 30.43317 Test MSE 33.59396220864633 Test RE 0.09757078189919202 Lambda1 0.9122996\n",
      "53 Train Loss 30.394543 Test MSE 33.64020132783378 Test RE 0.09763790758687887 Lambda1 0.90483016\n",
      "54 Train Loss 30.38643 Test MSE 33.65712735036984 Test RE 0.09766246768956374 Lambda1 0.90192616\n",
      "55 Train Loss 30.372976 Test MSE 33.64525968168774 Test RE 0.09764524803821445 Lambda1 0.89874655\n",
      "56 Train Loss 30.316477 Test MSE 33.627804149419816 Test RE 0.09761991503553778 Lambda1 0.9029732\n",
      "57 Train Loss 30.239702 Test MSE 33.59846679612462 Test RE 0.09757732327390477 Lambda1 0.9171481\n",
      "58 Train Loss 30.191483 Test MSE 33.56880783596389 Test RE 0.09753424569955876 Lambda1 0.9362825\n",
      "59 Train Loss 30.182297 Test MSE 33.57845840035131 Test RE 0.09754826456020173 Lambda1 0.9470874\n",
      "60 Train Loss 30.18048 Test MSE 33.57557544684866 Test RE 0.09754407685830903 Lambda1 0.9507674\n",
      "61 Train Loss 30.17329 Test MSE 33.53960803379847 Test RE 0.0974918164257718 Lambda1 0.9533192\n",
      "62 Train Loss 30.166574 Test MSE 33.52171519561682 Test RE 0.09746580780324018 Lambda1 0.94979507\n",
      "63 Train Loss 30.154486 Test MSE 33.5010318631051 Test RE 0.0974357343306067 Lambda1 0.95439124\n",
      "64 Train Loss 30.133446 Test MSE 33.507513360986245 Test RE 0.09744515939795077 Lambda1 0.95761526\n",
      "65 Train Loss 30.117537 Test MSE 33.48579637338844 Test RE 0.09741357605873985 Lambda1 0.96117574\n",
      "66 Train Loss 30.08709 Test MSE 33.411976487524726 Test RE 0.0973061420506464 Lambda1 0.96006507\n",
      "67 Train Loss 30.067917 Test MSE 33.399287531230115 Test RE 0.09728766318822395 Lambda1 0.9656792\n",
      "68 Train Loss 30.051981 Test MSE 33.381671506425754 Test RE 0.09726200324069927 Lambda1 0.9628439\n",
      "69 Train Loss 30.03838 Test MSE 33.35355567892799 Test RE 0.09722103498429827 Lambda1 0.9612901\n",
      "70 Train Loss 29.98098 Test MSE 33.36708176760629 Test RE 0.09724074633168873 Lambda1 0.9477188\n",
      "71 Train Loss 29.941969 Test MSE 33.39640470926087 Test RE 0.09728346445996161 Lambda1 0.94379395\n",
      "72 Train Loss 29.9284 Test MSE 33.4233292074658 Test RE 0.09732267198502144 Lambda1 0.93898153\n",
      "73 Train Loss 29.920387 Test MSE 33.393604596224776 Test RE 0.09727938602083672 Lambda1 0.9435694\n",
      "74 Train Loss 29.908508 Test MSE 33.39274717516021 Test RE 0.09727813713005136 Lambda1 0.9457946\n",
      "Training time: 299.32\n",
      "Training time: 299.32\n",
      "inv_HT_swish_tune4\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 854.72906 Test MSE 858.0732117436115 Test RE 0.4931185529248349 Lambda1 7.5627313e-06\n",
      "1 Train Loss 854.7021 Test MSE 858.0729313547645 Test RE 0.49311847235772716 Lambda1 5.915133e-05\n",
      "2 Train Loss 854.52734 Test MSE 857.7075179503046 Test RE 0.4930134630507391 Lambda1 0.0002911472\n",
      "3 Train Loss 853.9911 Test MSE 857.445617441032 Test RE 0.4929381866117607 Lambda1 0.032701764\n",
      "4 Train Loss 852.5449 Test MSE 855.9346305201478 Test RE 0.4925036683414012 Lambda1 0.0466088\n",
      "5 Train Loss 821.4916 Test MSE 785.7324629962602 Test RE 0.4718745110408651 Lambda1 0.06471315\n",
      "6 Train Loss 566.8236 Test MSE 501.0382099585619 Test RE 0.3768118865564442 Lambda1 0.016372241\n",
      "7 Train Loss 434.31268 Test MSE 362.9840136566124 Test RE 0.32072507833493846 Lambda1 0.006677759\n",
      "8 Train Loss 305.80167 Test MSE 307.7915162528834 Test RE 0.295336751186047 Lambda1 0.0017684385\n",
      "9 Train Loss 282.05643 Test MSE 289.39101858720585 Test RE 0.2863727531887142 Lambda1 2.544417e-05\n",
      "10 Train Loss 280.87088 Test MSE 288.8503913611171 Test RE 0.28610513382216374 Lambda1 -0.00060545333\n",
      "11 Train Loss 278.7529 Test MSE 287.0717169258439 Test RE 0.2852228886744701 Lambda1 -0.0008263135\n",
      "12 Train Loss 275.39322 Test MSE 283.213981115876 Test RE 0.28329996122343326 Lambda1 0.0015492183\n",
      "13 Train Loss 274.18466 Test MSE 279.73730128812224 Test RE 0.28155572406320295 Lambda1 0.00326144\n",
      "14 Train Loss 269.8764 Test MSE 267.69974798627004 Test RE 0.27543121113043356 Lambda1 0.020845614\n",
      "15 Train Loss 251.80017 Test MSE 235.25261703713238 Test RE 0.258200097734909 Lambda1 0.08959633\n",
      "16 Train Loss 214.46173 Test MSE 185.35151513993907 Test RE 0.22918555459100318 Lambda1 0.22400455\n",
      "17 Train Loss 180.24713 Test MSE 170.88110641178068 Test RE 0.2200575098845737 Lambda1 0.29260612\n",
      "18 Train Loss 165.66064 Test MSE 159.83936198853584 Test RE 0.21282911509252017 Lambda1 0.37420842\n",
      "19 Train Loss 153.91866 Test MSE 138.15589991919364 Test RE 0.197867236689752 Lambda1 0.45866683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Train Loss 118.22928 Test MSE 101.87843841814811 Test RE 0.16991444856672766 Lambda1 0.5271018\n",
      "21 Train Loss 102.49512 Test MSE 74.22558008568835 Test RE 0.1450327129336383 Lambda1 0.533199\n",
      "22 Train Loss 89.422905 Test MSE 78.1023898248923 Test RE 0.14877204475099093 Lambda1 0.50326353\n",
      "23 Train Loss 67.6567 Test MSE 64.17289130157307 Test RE 0.13485435434014484 Lambda1 0.57802105\n",
      "24 Train Loss 56.125595 Test MSE 50.75443664237343 Test RE 0.11992954235482715 Lambda1 0.73957336\n",
      "25 Train Loss 50.11982 Test MSE 46.913281500157936 Test RE 0.1153020627022761 Lambda1 0.73033595\n",
      "26 Train Loss 43.656902 Test MSE 43.89245642316026 Test RE 0.11152805129879848 Lambda1 0.674392\n",
      "27 Train Loss 42.328625 Test MSE 43.442510236789246 Test RE 0.11095493585771514 Lambda1 0.6705415\n",
      "28 Train Loss 39.784996 Test MSE 41.938849124257 Test RE 0.1090178028219368 Lambda1 0.73981667\n",
      "29 Train Loss 38.33761 Test MSE 39.82690918958686 Test RE 0.10623740956261533 Lambda1 0.82887715\n",
      "30 Train Loss 36.547028 Test MSE 38.33038211574645 Test RE 0.10422232207144624 Lambda1 0.8570499\n",
      "31 Train Loss 35.30975 Test MSE 38.221103968326936 Test RE 0.1040736495201281 Lambda1 0.85722196\n",
      "32 Train Loss 34.869133 Test MSE 37.42816841903253 Test RE 0.10298843486862638 Lambda1 0.89549774\n",
      "33 Train Loss 34.797512 Test MSE 37.04697798684875 Test RE 0.10246264537522208 Lambda1 0.91764766\n",
      "34 Train Loss 33.67444 Test MSE 36.76660963654844 Test RE 0.10207419478546455 Lambda1 0.93803614\n",
      "35 Train Loss 33.138035 Test MSE 36.59846351076135 Test RE 0.10184051742098818 Lambda1 0.915272\n",
      "36 Train Loss 32.80577 Test MSE 36.279550787340895 Test RE 0.10139583619617354 Lambda1 0.9183828\n",
      "37 Train Loss 32.095577 Test MSE 35.37239336611866 Test RE 0.10012012741948427 Lambda1 1.0048114\n",
      "38 Train Loss 31.992699 Test MSE 35.04352860971456 Test RE 0.09965362139604073 Lambda1 1.0401425\n",
      "39 Train Loss 31.86045 Test MSE 34.858647870321285 Test RE 0.09939040019112838 Lambda1 1.051686\n",
      "40 Train Loss 31.719788 Test MSE 34.47651623955076 Test RE 0.0988441242982092 Lambda1 1.0562224\n",
      "41 Train Loss 31.225868 Test MSE 33.923957600945855 Test RE 0.09804883244544564 Lambda1 1.0207969\n",
      "42 Train Loss 30.892094 Test MSE 33.708171853299966 Test RE 0.09773649723138278 Lambda1 1.0354258\n",
      "43 Train Loss 30.775284 Test MSE 33.673447718252234 Test RE 0.09768614312407009 Lambda1 1.0378581\n",
      "44 Train Loss 30.730928 Test MSE 33.71175121738164 Test RE 0.09774168625828582 Lambda1 1.022932\n",
      "45 Train Loss 30.645206 Test MSE 33.60922783583678 Test RE 0.09759294823371994 Lambda1 1.0080099\n",
      "46 Train Loss 30.49106 Test MSE 33.5970867587664 Test RE 0.09757531928760606 Lambda1 0.9955105\n",
      "47 Train Loss 30.45514 Test MSE 33.61691027341224 Test RE 0.0976041015529271 Lambda1 0.9774846\n",
      "48 Train Loss 30.361908 Test MSE 33.588851032299466 Test RE 0.09756335913018739 Lambda1 0.9708371\n",
      "49 Train Loss 30.310238 Test MSE 33.53350544974768 Test RE 0.09748294662817342 Lambda1 0.9583524\n",
      "50 Train Loss 30.234755 Test MSE 33.63031427867033 Test RE 0.09762355836042678 Lambda1 0.93286693\n",
      "51 Train Loss 30.17858 Test MSE 33.59066828912795 Test RE 0.097565998328569 Lambda1 0.9228572\n",
      "52 Train Loss 30.15915 Test MSE 33.65571860109034 Test RE 0.0976604237930475 Lambda1 0.90706813\n",
      "53 Train Loss 30.153965 Test MSE 33.64318504060273 Test RE 0.09764223748088466 Lambda1 0.9079436\n",
      "54 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "55 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "56 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "57 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "58 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "59 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "60 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "61 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "62 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "63 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "64 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "65 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "66 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "67 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "68 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "69 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "70 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "71 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "72 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "73 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "74 Train Loss 30.15335 Test MSE 33.64281497226342 Test RE 0.09764170045681876 Lambda1 0.9093519\n",
      "Training time: 270.79\n",
      "Training time: 270.79\n",
      "inv_HT_swish_tune4\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 854.61066 Test MSE 857.9869080897856 Test RE 0.4930937537570829 Lambda1 0.00015286366\n",
      "1 Train Loss 854.4453 Test MSE 857.3725812573874 Test RE 0.49291719222454716 Lambda1 0.13022149\n",
      "2 Train Loss 838.7922 Test MSE 831.6257806853166 Test RE 0.48545965476247255 Lambda1 1.2905438\n",
      "3 Train Loss 803.9594 Test MSE 797.2952371123773 Test RE 0.47533386382538084 Lambda1 1.0509024\n",
      "4 Train Loss 708.8737 Test MSE 674.5824920825589 Test RE 0.437226728520201 Lambda1 1.3822895\n",
      "5 Train Loss 532.2001 Test MSE 491.44693665575403 Test RE 0.37318784222746576 Lambda1 1.0930791\n",
      "6 Train Loss 314.97995 Test MSE 289.2709037958091 Test RE 0.2863133160062962 Lambda1 0.7628042\n",
      "7 Train Loss 234.02168 Test MSE 198.83619888317338 Test RE 0.2373760488787699 Lambda1 0.73101777\n",
      "8 Train Loss 181.11127 Test MSE 165.91920524172014 Test RE 0.21683905204831655 Lambda1 0.6819622\n",
      "9 Train Loss 124.54267 Test MSE 111.54346817678078 Test RE 0.17779160171436179 Lambda1 0.6053827\n",
      "10 Train Loss 93.201 Test MSE 81.67702502816266 Test RE 0.15213849859483705 Lambda1 0.58212847\n",
      "11 Train Loss 79.39064 Test MSE 70.38746531290566 Test RE 0.14123321122485863 Lambda1 0.57100785\n",
      "12 Train Loss 62.802357 Test MSE 65.89222315305611 Test RE 0.13664893488267293 Lambda1 0.53070664\n",
      "13 Train Loss 59.490654 Test MSE 60.59831452573747 Test RE 0.13104469461489865 Lambda1 0.57414407\n",
      "14 Train Loss 54.757477 Test MSE 56.53169340469852 Test RE 0.12657127883584476 Lambda1 0.6420061\n",
      "15 Train Loss 50.203365 Test MSE 52.069037241347345 Test RE 0.12147277263636934 Lambda1 0.7142175\n",
      "16 Train Loss 49.040417 Test MSE 50.07580005450557 Test RE 0.11912505632086651 Lambda1 0.7659581\n",
      "17 Train Loss 46.446636 Test MSE 48.17905200313338 Test RE 0.1168471962091261 Lambda1 0.7959256\n",
      "18 Train Loss 44.955734 Test MSE 46.50676137438496 Test RE 0.11480140924342463 Lambda1 0.8317468\n",
      "19 Train Loss 44.109634 Test MSE 45.00701932087367 Test RE 0.11293519252890728 Lambda1 0.8685695\n",
      "20 Train Loss 41.465195 Test MSE 42.10081251224609 Test RE 0.10922810757088477 Lambda1 0.9449201\n",
      "21 Train Loss 40.224564 Test MSE 40.192807527241314 Test RE 0.10672430672050942 Lambda1 1.0078878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 Train Loss 39.579052 Test MSE 39.92576076301157 Test RE 0.10636917006041811 Lambda1 1.0703316\n",
      "23 Train Loss 37.540207 Test MSE 38.64397529145303 Test RE 0.10464779177528022 Lambda1 0.97836995\n",
      "24 Train Loss 37.227055 Test MSE 38.0892062501425 Test RE 0.10389391975456744 Lambda1 0.9482208\n",
      "25 Train Loss 36.33763 Test MSE 37.97166871406974 Test RE 0.10373349542745959 Lambda1 0.8939825\n",
      "26 Train Loss 35.531975 Test MSE 36.92062008338453 Test RE 0.10228775899672676 Lambda1 0.88016623\n",
      "27 Train Loss 34.467228 Test MSE 35.58949468713062 Test RE 0.10042690566964523 Lambda1 0.90357554\n",
      "28 Train Loss 33.57186 Test MSE 34.481769520414495 Test RE 0.09885165458584697 Lambda1 0.99640244\n",
      "29 Train Loss 33.338257 Test MSE 34.24233544439675 Test RE 0.09850785429137503 Lambda1 1.0476843\n",
      "30 Train Loss 32.96259 Test MSE 34.12759653194143 Test RE 0.09834267618578603 Lambda1 1.0679717\n",
      "31 Train Loss 32.401535 Test MSE 34.145131874097295 Test RE 0.09836793801479972 Lambda1 0.9836296\n",
      "32 Train Loss 32.23562 Test MSE 34.10123800741444 Test RE 0.09830469125839908 Lambda1 0.95798844\n",
      "33 Train Loss 31.451437 Test MSE 34.26328057640813 Test RE 0.0985379770118549 Lambda1 0.89780766\n",
      "34 Train Loss 30.894335 Test MSE 34.19815375633148 Test RE 0.09844428315892984 Lambda1 0.8827245\n",
      "35 Train Loss 30.559593 Test MSE 33.73043830049547 Test RE 0.09776877256946563 Lambda1 0.9359249\n",
      "36 Train Loss 30.4582 Test MSE 33.48550784469172 Test RE 0.09741315637822255 Lambda1 0.98208416\n",
      "37 Train Loss 30.421915 Test MSE 33.560021306871 Test RE 0.09752148022427946 Lambda1 0.9660967\n",
      "38 Train Loss 30.174366 Test MSE 33.45031658601041 Test RE 0.09736195523242862 Lambda1 0.99406815\n",
      "39 Train Loss 30.08928 Test MSE 33.46558717015421 Test RE 0.0973841763118747 Lambda1 0.9895863\n",
      "40 Train Loss 30.057665 Test MSE 33.46108808731814 Test RE 0.09737762997218734 Lambda1 1.0073454\n",
      "41 Train Loss 30.00735 Test MSE 33.43844744588727 Test RE 0.09734468028056303 Lambda1 1.0101447\n",
      "42 Train Loss 29.93505 Test MSE 33.457292945551266 Test RE 0.09737210755179888 Lambda1 0.9962562\n",
      "43 Train Loss 29.913479 Test MSE 33.480978038515254 Test RE 0.09740656729431765 Lambda1 0.97855175\n",
      "44 Train Loss 29.880701 Test MSE 33.41674694876961 Test RE 0.0973130883414742 Lambda1 0.99824685\n",
      "45 Train Loss 29.8563 Test MSE 33.412202678444224 Test RE 0.09730647141949565 Lambda1 0.99066466\n",
      "46 Train Loss 29.837643 Test MSE 33.38464696680503 Test RE 0.09726633784671823 Lambda1 0.9988385\n",
      "47 Train Loss 29.815134 Test MSE 33.35367445290267 Test RE 0.09722120808905775 Lambda1 0.9925203\n",
      "48 Train Loss 29.787584 Test MSE 33.35436562238476 Test RE 0.09722221541411309 Lambda1 0.98113537\n",
      "49 Train Loss 29.75336 Test MSE 33.35402221155599 Test RE 0.09722171492119583 Lambda1 0.97162145\n",
      "50 Train Loss 29.73488 Test MSE 33.36077807098978 Test RE 0.09723156055509836 Lambda1 0.96059334\n",
      "51 Train Loss 29.723196 Test MSE 33.35285505812781 Test RE 0.0972200138722212 Lambda1 0.9500782\n",
      "52 Train Loss 29.687428 Test MSE 33.296961588112886 Test RE 0.09713851796399557 Lambda1 0.9515973\n",
      "53 Train Loss 29.680725 Test MSE 33.2870695689491 Test RE 0.09712408770650506 Lambda1 0.94955486\n",
      "54 Train Loss 29.674139 Test MSE 33.26797534820822 Test RE 0.09709622741694884 Lambda1 0.9408357\n",
      "55 Train Loss 29.66832 Test MSE 33.28103555928667 Test RE 0.09711528437457824 Lambda1 0.9345847\n",
      "56 Train Loss 29.653225 Test MSE 33.26837036013611 Test RE 0.09709680385801164 Lambda1 0.9449606\n",
      "57 Train Loss 29.649805 Test MSE 33.26300207092908 Test RE 0.09708896961864817 Lambda1 0.9440729\n",
      "58 Train Loss 29.648048 Test MSE 33.27404770913558 Test RE 0.09710508843762954 Lambda1 0.9374539\n",
      "59 Train Loss 29.643791 Test MSE 33.27786316206143 Test RE 0.09711065567844986 Lambda1 0.9366384\n",
      "60 Train Loss 29.641716 Test MSE 33.27433733662365 Test RE 0.0971055110529045 Lambda1 0.93811625\n",
      "61 Train Loss 29.634354 Test MSE 33.27949281927247 Test RE 0.09711303346247495 Lambda1 0.93309414\n",
      "62 Train Loss 29.62075 Test MSE 33.28410438777925 Test RE 0.09711976174850544 Lambda1 0.9322891\n",
      "63 Train Loss 29.608047 Test MSE 33.32149844655397 Test RE 0.09717430253728912 Lambda1 0.9262256\n",
      "64 Train Loss 29.603615 Test MSE 33.30064724640514 Test RE 0.09714389397220122 Lambda1 0.93346536\n",
      "65 Train Loss 29.599733 Test MSE 33.30141584451436 Test RE 0.09714501503423129 Lambda1 0.93429977\n",
      "66 Train Loss 29.593998 Test MSE 33.28907141332651 Test RE 0.09712700812557977 Lambda1 0.94014174\n",
      "67 Train Loss 29.59045 Test MSE 33.2951456066808 Test RE 0.09713586901133134 Lambda1 0.9356967\n",
      "68 Train Loss 29.587866 Test MSE 33.28886054224736 Test RE 0.09712670049745162 Lambda1 0.9373264\n",
      "69 Train Loss 29.584095 Test MSE 33.29164355851388 Test RE 0.09713076040718895 Lambda1 0.9352838\n",
      "70 Train Loss 29.581984 Test MSE 33.29195475313677 Test RE 0.09713121437245603 Lambda1 0.93666553\n",
      "71 Train Loss 29.579515 Test MSE 33.28949520995051 Test RE 0.09712762637603539 Lambda1 0.9377711\n",
      "72 Train Loss 29.578268 Test MSE 33.281644742818116 Test RE 0.0971161731804729 Lambda1 0.9416382\n",
      "73 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "74 Train Loss 29.577734 Test MSE 33.28075518632509 Test RE 0.09711487530441588 Lambda1 0.94245493\n",
      "Training time: 242.32\n",
      "Training time: 242.32\n",
      "inv_HT_swish_tune4\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 854.71515 Test MSE 858.0722660350071 Test RE 0.49311828118427675 Lambda1 1.7253772e-07\n",
      "1 Train Loss 854.5325 Test MSE 857.6621756207935 Test RE 0.4930004314089069 Lambda1 0.011239418\n",
      "2 Train Loss 852.47815 Test MSE 855.789820533314 Test RE 0.4924620048404994 Lambda1 3.4175277\n",
      "3 Train Loss 835.7833 Test MSE 818.407886529098 Test RE 0.4815862442794709 Lambda1 2.644427\n",
      "4 Train Loss 752.14404 Test MSE 745.6552671449241 Test RE 0.4596827593587834 Lambda1 1.9886378\n",
      "5 Train Loss 692.67065 Test MSE 675.8955878674213 Test RE 0.437652059348295 Lambda1 1.7984283\n",
      "6 Train Loss 644.9481 Test MSE 634.834877203817 Test RE 0.4241500864515925 Lambda1 1.5345901\n",
      "7 Train Loss 599.63275 Test MSE 584.1414409672162 Test RE 0.40686298352941724 Lambda1 1.2914178\n",
      "8 Train Loss 554.4334 Test MSE 544.5090245768164 Test RE 0.39281829986132316 Lambda1 1.3902987\n",
      "9 Train Loss 529.6619 Test MSE 521.4752833574529 Test RE 0.38442005367420606 Lambda1 1.494574\n",
      "10 Train Loss 473.41614 Test MSE 434.0152258287694 Test RE 0.35070475424825526 Lambda1 1.5852906\n",
      "11 Train Loss 418.25195 Test MSE 371.2104612999549 Test RE 0.3243390751927705 Lambda1 1.588363\n",
      "12 Train Loss 357.68347 Test MSE 282.99757183653946 Test RE 0.28319170304974056 Lambda1 1.5728997\n",
      "13 Train Loss 292.21896 Test MSE 249.83845252108034 Test RE 0.2660840310311014 Lambda1 1.56583\n",
      "14 Train Loss 150.10048 Test MSE 116.39158618883658 Test RE 0.18161426775789447 Lambda1 1.3945715\n",
      "15 Train Loss 103.9122 Test MSE 78.38660732871342 Test RE 0.14904249243646156 Lambda1 1.3723348\n",
      "16 Train Loss 58.63514 Test MSE 45.45228330550004 Test RE 0.1134924635233017 Lambda1 1.2967521\n",
      "17 Train Loss 53.319443 Test MSE 42.8087948853596 Test RE 0.11014268815153991 Lambda1 1.2532898\n",
      "18 Train Loss 43.707527 Test MSE 39.271794962373725 Test RE 0.10549443401554418 Lambda1 1.1493022\n",
      "19 Train Loss 40.25365 Test MSE 39.160705930293815 Test RE 0.1053451210803462 Lambda1 1.0996889\n",
      "20 Train Loss 38.122604 Test MSE 38.3566365388036 Test RE 0.10425800953903605 Lambda1 1.0478945\n",
      "21 Train Loss 37.006546 Test MSE 38.387070704609684 Test RE 0.10429936322222545 Lambda1 1.0635347\n",
      "22 Train Loss 34.30783 Test MSE 37.315668830572406 Test RE 0.10283353982032156 Lambda1 0.98066896\n",
      "23 Train Loss 33.835762 Test MSE 37.02874683675112 Test RE 0.1024374308794431 Lambda1 0.93627983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Train Loss 33.74928 Test MSE 37.013438376719776 Test RE 0.10241625379999399 Lambda1 0.93181616\n",
      "25 Train Loss 33.178276 Test MSE 36.62509360804972 Test RE 0.10187756173200016 Lambda1 0.8639409\n",
      "26 Train Loss 32.639065 Test MSE 36.410361338916395 Test RE 0.1015784695328197 Lambda1 0.85153276\n",
      "27 Train Loss 32.255795 Test MSE 35.93986584139817 Test RE 0.10092003592395665 Lambda1 0.8967626\n",
      "28 Train Loss 32.2028 Test MSE 35.780992625505725 Test RE 0.10069672889874703 Lambda1 0.90775675\n",
      "29 Train Loss 31.986856 Test MSE 35.60947156108688 Test RE 0.10045508721877756 Lambda1 0.9364906\n",
      "30 Train Loss 31.877712 Test MSE 35.56231117495783 Test RE 0.10038854494654503 Lambda1 0.9669323\n",
      "31 Train Loss 31.725471 Test MSE 35.512073868912275 Test RE 0.10031761265555279 Lambda1 0.98968333\n",
      "32 Train Loss 31.532518 Test MSE 35.37993852524415 Test RE 0.10013080498384093 Lambda1 1.0302043\n",
      "33 Train Loss 31.381035 Test MSE 35.262776992162784 Test RE 0.09996487469263259 Lambda1 1.046411\n",
      "34 Train Loss 31.330685 Test MSE 35.23201118783932 Test RE 0.09992125687305808 Lambda1 1.0493362\n",
      "35 Train Loss 30.770176 Test MSE 34.451292189956305 Test RE 0.09880795902447799 Lambda1 1.0041229\n",
      "36 Train Loss 30.546839 Test MSE 33.94084764640013 Test RE 0.09807323766342238 Lambda1 0.9612827\n",
      "37 Train Loss 30.472183 Test MSE 33.75049701957472 Test RE 0.09779783867372349 Lambda1 0.95606554\n",
      "38 Train Loss 30.382692 Test MSE 33.50093636579134 Test RE 0.09743559545641378 Lambda1 0.9520325\n",
      "39 Train Loss 30.32062 Test MSE 33.48569385458635 Test RE 0.09741342693983195 Lambda1 0.9652619\n",
      "40 Train Loss 30.193748 Test MSE 33.48216932820673 Test RE 0.09740830019481989 Lambda1 0.9791156\n",
      "41 Train Loss 30.000256 Test MSE 33.347033246990236 Test RE 0.09721152852277061 Lambda1 0.9996599\n",
      "42 Train Loss 29.9648 Test MSE 33.26396241146222 Test RE 0.0970903711427752 Lambda1 0.9974532\n",
      "43 Train Loss 29.947662 Test MSE 33.26738807785774 Test RE 0.0970953704067678 Lambda1 0.9914555\n",
      "44 Train Loss 29.93734 Test MSE 33.2538349295433 Test RE 0.09707559004394761 Lambda1 0.97680616\n",
      "45 Train Loss 29.91051 Test MSE 33.31946155367255 Test RE 0.09717133243271307 Lambda1 0.94197434\n",
      "46 Train Loss 29.837524 Test MSE 33.38621074543191 Test RE 0.09726861585851297 Lambda1 0.9163513\n",
      "47 Train Loss 29.814465 Test MSE 33.42653864777348 Test RE 0.0973273445268625 Lambda1 0.90158963\n",
      "48 Train Loss 29.755585 Test MSE 33.43958674673796 Test RE 0.09734633861013368 Lambda1 0.90159607\n",
      "49 Train Loss 29.652897 Test MSE 33.317944161663206 Test RE 0.09716911978167907 Lambda1 0.92972136\n",
      "50 Train Loss 29.623978 Test MSE 33.28664786181259 Test RE 0.09712347248186733 Lambda1 0.950317\n",
      "51 Train Loss 29.606058 Test MSE 33.28925008691999 Test RE 0.09712726878181834 Lambda1 0.9406464\n",
      "52 Train Loss 29.584137 Test MSE 33.26392964755693 Test RE 0.09709032332735759 Lambda1 0.93998986\n",
      "53 Train Loss 29.575712 Test MSE 33.266333903697785 Test RE 0.09709383201966679 Lambda1 0.9420331\n",
      "54 Train Loss 29.571486 Test MSE 33.283495326636576 Test RE 0.09711887315401325 Lambda1 0.9457654\n",
      "55 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "56 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "57 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "58 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "59 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "60 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "61 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "62 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "63 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "64 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "65 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "66 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "67 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "68 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "69 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "70 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "71 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "72 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "73 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "74 Train Loss 29.569666 Test MSE 33.28211566648397 Test RE 0.09711686025803264 Lambda1 0.9418511\n",
      "Training time: 244.65\n",
      "Training time: 244.65\n",
      "inv_HT_swish_tune4\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 854.56805 Test MSE 857.8411344538788 Test RE 0.49305186318623007 Lambda1 -0.00090318493\n",
      "1 Train Loss 854.4526 Test MSE 857.7214929341816 Test RE 0.49301747947066576 Lambda1 -0.28693107\n",
      "2 Train Loss 853.34216 Test MSE 856.6187531597425 Test RE 0.4927004506653121 Lambda1 -0.82553935\n",
      "3 Train Loss 850.8948 Test MSE 851.9992249665074 Test RE 0.491370150314074 Lambda1 -1.0581679\n",
      "4 Train Loss 828.909 Test MSE 828.4027307542966 Test RE 0.4845180174970902 Lambda1 -0.98343456\n",
      "5 Train Loss 790.3342 Test MSE 788.9678860868222 Test RE 0.47284503557997826 Lambda1 -0.8514269\n",
      "6 Train Loss 735.27246 Test MSE 719.2309559873264 Test RE 0.4514642403009868 Lambda1 -1.1741843\n",
      "7 Train Loss 614.24493 Test MSE 577.9912388839512 Test RE 0.4047154635039061 Lambda1 -1.3520828\n",
      "8 Train Loss 532.744 Test MSE 524.9000902101914 Test RE 0.38568033378708266 Lambda1 -1.2985787\n",
      "9 Train Loss 499.10995 Test MSE 483.99909522948695 Test RE 0.3703492295638244 Lambda1 -1.2413967\n",
      "10 Train Loss 465.5202 Test MSE 447.1403604942754 Test RE 0.3559681216586786 Lambda1 -1.2576323\n",
      "11 Train Loss 436.34418 Test MSE 405.4858401855109 Test RE 0.3389822961476493 Lambda1 -1.2536067\n",
      "12 Train Loss 414.21042 Test MSE 397.2679049868186 Test RE 0.33552965529882145 Lambda1 -1.3601418\n",
      "13 Train Loss 393.7975 Test MSE 378.0826628050543 Test RE 0.3273275441645902 Lambda1 -1.4386371\n",
      "14 Train Loss 377.97736 Test MSE 361.2672332305808 Test RE 0.31996572377529864 Lambda1 -1.4395596\n",
      "15 Train Loss 354.65692 Test MSE 338.3034966869991 Test RE 0.3096295588195047 Lambda1 -1.632617\n",
      "16 Train Loss 341.802 Test MSE 327.87149191563907 Test RE 0.30481827361619745 Lambda1 -1.6819063\n",
      "17 Train Loss 320.1778 Test MSE 298.76785173266705 Test RE 0.2909752853787976 Lambda1 -1.8404903\n",
      "18 Train Loss 298.40686 Test MSE 281.0787248073714 Test RE 0.28222998840395197 Lambda1 -1.9841199\n",
      "19 Train Loss 264.01263 Test MSE 252.47788813063474 Test RE 0.267485869876246 Lambda1 -2.0967329\n",
      "20 Train Loss 246.60892 Test MSE 236.7503615171874 Test RE 0.2590207139183371 Lambda1 -2.1276388\n",
      "21 Train Loss 233.68777 Test MSE 223.56905547319852 Test RE 0.25170683954444506 Lambda1 -2.1559129\n",
      "22 Train Loss 214.92378 Test MSE 200.89747496566685 Test RE 0.23860328014945856 Lambda1 -2.1885004\n",
      "23 Train Loss 203.54199 Test MSE 191.66859692635163 Test RE 0.2330583419802527 Lambda1 -2.1919818\n",
      "24 Train Loss 192.987 Test MSE 184.84140074316292 Test RE 0.22886996126917475 Lambda1 -2.2159662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Train Loss 181.4499 Test MSE 173.73221415163857 Test RE 0.22188571739009214 Lambda1 -2.2468631\n",
      "26 Train Loss 171.43456 Test MSE 164.3980109399315 Test RE 0.2158427422322694 Lambda1 -2.295101\n",
      "27 Train Loss 163.79729 Test MSE 154.17669129750254 Test RE 0.20902514398758282 Lambda1 -2.3422692\n",
      "28 Train Loss 151.30907 Test MSE 142.45921928706272 Test RE 0.20092521911765326 Lambda1 -2.4206474\n",
      "29 Train Loss 145.15363 Test MSE 138.0546607329624 Test RE 0.19779472589153135 Lambda1 -2.4529104\n",
      "30 Train Loss 141.70729 Test MSE 131.17065111064946 Test RE 0.1928002123024395 Lambda1 -2.505256\n",
      "31 Train Loss 132.25688 Test MSE 125.58872500497824 Test RE 0.18865333904881762 Lambda1 -2.5904367\n",
      "32 Train Loss 122.33466 Test MSE 116.52180301718003 Test RE 0.18171583275849246 Lambda1 -2.6766157\n",
      "33 Train Loss 118.82705 Test MSE 115.19276016671787 Test RE 0.1806765391000549 Lambda1 -2.7401948\n",
      "34 Train Loss 111.882545 Test MSE 106.8035099547431 Test RE 0.17397303237517017 Lambda1 -2.8188107\n",
      "35 Train Loss 108.5777 Test MSE 102.27215197872583 Test RE 0.17024245278423103 Lambda1 -2.9002278\n",
      "36 Train Loss 106.44556 Test MSE 101.6865633663338 Test RE 0.16975436705590344 Lambda1 -2.927906\n",
      "37 Train Loss 101.21894 Test MSE 98.44459986741263 Test RE 0.16702639962600138 Lambda1 -2.9000652\n",
      "38 Train Loss 98.98064 Test MSE 97.73052649685758 Test RE 0.16641952950027084 Lambda1 -2.882463\n",
      "39 Train Loss 97.137146 Test MSE 97.28373014009433 Test RE 0.1660386821836539 Lambda1 -2.9023788\n",
      "40 Train Loss 95.71064 Test MSE 96.17596913697015 Test RE 0.16509064194474815 Lambda1 -2.9579473\n",
      "41 Train Loss 94.8244 Test MSE 94.93496218966398 Test RE 0.16402205980713405 Lambda1 -3.0031457\n",
      "42 Train Loss 94.39577 Test MSE 94.71413548004774 Test RE 0.16383118418858883 Lambda1 -3.0166929\n",
      "43 Train Loss 93.314316 Test MSE 95.14148310659208 Test RE 0.16420036916284314 Lambda1 -2.9967775\n",
      "44 Train Loss 92.17108 Test MSE 94.8608140123249 Test RE 0.1639579932495101 Lambda1 -3.016426\n",
      "45 Train Loss 91.876015 Test MSE 94.66028919529774 Test RE 0.16378460743042597 Lambda1 -3.0437756\n",
      "46 Train Loss 91.43735 Test MSE 93.9034756690724 Test RE 0.1631285606441823 Lambda1 -3.1113508\n",
      "47 Train Loss 89.715904 Test MSE 93.27400326127199 Test RE 0.16258088341064422 Lambda1 -3.2001603\n",
      "48 Train Loss 89.23191 Test MSE 92.81870620750547 Test RE 0.16218359613269856 Lambda1 -3.242113\n",
      "49 Train Loss 88.80618 Test MSE 92.34488728639737 Test RE 0.16176911083760023 Lambda1 -3.2590103\n",
      "50 Train Loss 88.53776 Test MSE 92.34502363528848 Test RE 0.1617692302650606 Lambda1 -3.267137\n",
      "51 Train Loss 88.00505 Test MSE 92.23080130645789 Test RE 0.16166915245461033 Lambda1 -3.25415\n",
      "52 Train Loss 87.84773 Test MSE 92.07907312945427 Test RE 0.1615361173829709 Lambda1 -3.2525823\n",
      "53 Train Loss 87.42894 Test MSE 91.72751746911588 Test RE 0.16122745199950678 Lambda1 -3.303859\n",
      "54 Train Loss 86.76556 Test MSE 91.07111571243041 Test RE 0.16064954475942325 Lambda1 -3.347816\n",
      "55 Train Loss 86.45272 Test MSE 90.96235776642703 Test RE 0.16055359153773455 Lambda1 -3.3726118\n",
      "56 Train Loss 85.73275 Test MSE 90.1382855096811 Test RE 0.15982467031704672 Lambda1 -3.4171174\n",
      "57 Train Loss 85.30334 Test MSE 89.66180636978979 Test RE 0.1594016867537252 Lambda1 -3.45297\n",
      "58 Train Loss 84.480286 Test MSE 89.0357012553842 Test RE 0.15884416368369314 Lambda1 -3.5096688\n",
      "59 Train Loss 84.05488 Test MSE 88.27636656355521 Test RE 0.15816536770140976 Lambda1 -3.5390422\n",
      "60 Train Loss 83.881226 Test MSE 87.81298763156636 Test RE 0.15774970191157958 Lambda1 -3.559966\n",
      "61 Train Loss 83.340614 Test MSE 87.17729370069263 Test RE 0.15717767562093543 Lambda1 -3.5856538\n",
      "62 Train Loss 82.3408 Test MSE 86.0408802108661 Test RE 0.15614985775651893 Lambda1 -3.6719608\n",
      "63 Train Loss 81.5705 Test MSE 84.58042079140075 Test RE 0.1548189406109557 Lambda1 -3.729\n",
      "64 Train Loss 80.64075 Test MSE 83.73068538203178 Test RE 0.15403928486218102 Lambda1 -3.7751393\n",
      "65 Train Loss 79.48711 Test MSE 82.65156038506305 Test RE 0.1530434330495907 Lambda1 -3.8286195\n",
      "66 Train Loss 79.171135 Test MSE 82.34183434414959 Test RE 0.15275640865725068 Lambda1 -3.8386502\n",
      "67 Train Loss 79.09106 Test MSE 82.27897350433763 Test RE 0.15269808939851598 Lambda1 -3.8441916\n",
      "68 Train Loss 78.867455 Test MSE 81.95735358199839 Test RE 0.15239935673459779 Lambda1 -3.8770504\n",
      "69 Train Loss 78.43377 Test MSE 81.06341350532594 Test RE 0.1515659389825559 Lambda1 -3.935224\n",
      "70 Train Loss 78.22994 Test MSE 80.34810632028342 Test RE 0.15089574494006944 Lambda1 -3.9805055\n",
      "71 Train Loss 77.91673 Test MSE 79.70216405682196 Test RE 0.1502879731308574 Lambda1 -4.0349345\n",
      "72 Train Loss 77.3768 Test MSE 79.13355137724048 Test RE 0.1497509199086376 Lambda1 -4.0801516\n",
      "73 Train Loss 76.5746 Test MSE 79.0646799539454 Test RE 0.1496857401978031 Lambda1 -4.0743566\n",
      "74 Train Loss 76.10448 Test MSE 78.90559678623833 Test RE 0.14953507575542654 Lambda1 -4.0697837\n",
      "Training time: 240.91\n",
      "Training time: 240.91\n",
      "inv_HT_swish_tune4\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 854.6811 Test MSE 858.0875132408659 Test RE 0.49312266230859675 Lambda1 2.9011146e-06\n",
      "1 Train Loss 854.48785 Test MSE 857.6143107326528 Test RE 0.49298667439570454 Lambda1 0.045531698\n",
      "2 Train Loss 854.11285 Test MSE 857.1587046377847 Test RE 0.4928557078474121 Lambda1 0.1546107\n",
      "3 Train Loss 850.3509 Test MSE 854.4812945701365 Test RE 0.49208536689840426 Lambda1 0.34712976\n",
      "4 Train Loss 842.03015 Test MSE 842.466425471122 Test RE 0.4886135108777967 Lambda1 0.65714973\n",
      "5 Train Loss 770.14056 Test MSE 754.3742274924804 Test RE 0.4623624879516191 Lambda1 0.9975076\n",
      "6 Train Loss 601.7779 Test MSE 533.409134937939 Test RE 0.38879385764466845 Lambda1 1.0244153\n",
      "7 Train Loss 521.22473 Test MSE 435.3328638983557 Test RE 0.3512367076366108 Lambda1 1.0302047\n",
      "8 Train Loss 414.56784 Test MSE 349.2550944507667 Test RE 0.3146013236176674 Lambda1 0.9498152\n",
      "9 Train Loss 384.71582 Test MSE 343.8521404377865 Test RE 0.3121584076587102 Lambda1 0.95145077\n",
      "10 Train Loss 321.06592 Test MSE 307.95348417446536 Test RE 0.2954144479156017 Lambda1 1.1641998\n",
      "11 Train Loss 302.00735 Test MSE 278.20882584614816 Test RE 0.28078546483201794 Lambda1 1.28591\n",
      "12 Train Loss 298.27585 Test MSE 278.7944498387793 Test RE 0.28108083336050577 Lambda1 1.2873235\n",
      "13 Train Loss 292.69067 Test MSE 276.2504779589583 Test RE 0.2797954770012372 Lambda1 1.3710688\n",
      "14 Train Loss 288.70282 Test MSE 276.01293959320327 Test RE 0.2796751578363152 Lambda1 1.354019\n",
      "15 Train Loss 285.5743 Test MSE 273.3079041962497 Test RE 0.27830132022299214 Lambda1 1.4150631\n",
      "16 Train Loss 283.8907 Test MSE 269.08380241595125 Test RE 0.276142306914955 Lambda1 1.3451761\n",
      "17 Train Loss 281.9644 Test MSE 267.4190443673152 Test RE 0.2752867679314753 Lambda1 1.1187508\n",
      "18 Train Loss 279.72647 Test MSE 264.11581022360156 Test RE 0.27358127566535406 Lambda1 0.98102176\n",
      "19 Train Loss 276.3207 Test MSE 257.898006499782 Test RE 0.27034177640737767 Lambda1 0.9093637\n",
      "20 Train Loss 270.34583 Test MSE 243.9360683570541 Test RE 0.2629221533520402 Lambda1 0.9459148\n",
      "21 Train Loss 254.73833 Test MSE 239.18125064295927 Test RE 0.2603470954425943 Lambda1 0.9132318\n",
      "22 Train Loss 248.74327 Test MSE 227.91594054721136 Test RE 0.25414204552862585 Lambda1 0.83627903\n",
      "23 Train Loss 241.80426 Test MSE 219.36768645968087 Test RE 0.2493305517801868 Lambda1 0.7090732\n",
      "24 Train Loss 217.76378 Test MSE 197.69941868923226 Test RE 0.2366965167176674 Lambda1 0.64063454\n",
      "25 Train Loss 200.67822 Test MSE 187.04668333372572 Test RE 0.2302311996922753 Lambda1 0.6149047\n",
      "26 Train Loss 194.10556 Test MSE 179.7289220423345 Test RE 0.22568264100000354 Lambda1 0.61920696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Train Loss 187.77438 Test MSE 171.97998604644008 Test RE 0.22076393438458217 Lambda1 0.62727123\n",
      "28 Train Loss 184.38763 Test MSE 169.50859433201748 Test RE 0.2191719804013767 Lambda1 0.646461\n",
      "29 Train Loss 175.91898 Test MSE 160.28948827427305 Test RE 0.2131285802139546 Lambda1 0.6271951\n",
      "30 Train Loss 164.63351 Test MSE 146.64323433888387 Test RE 0.20385444520709722 Lambda1 0.5663452\n",
      "31 Train Loss 145.15773 Test MSE 130.78048806072343 Test RE 0.19251325962256646 Lambda1 0.505344\n",
      "32 Train Loss 140.69623 Test MSE 128.8419875925269 Test RE 0.19108116416841203 Lambda1 0.54131407\n",
      "33 Train Loss 114.272804 Test MSE 94.25027411783472 Test RE 0.16342951114088788 Lambda1 0.72702056\n",
      "34 Train Loss 97.641785 Test MSE 68.26794813875007 Test RE 0.13909054075671595 Lambda1 0.8821654\n",
      "35 Train Loss 88.14826 Test MSE 59.99647450902195 Test RE 0.13039232711833532 Lambda1 0.8666523\n",
      "36 Train Loss 70.2449 Test MSE 47.48259421267229 Test RE 0.11599957283200502 Lambda1 0.8019104\n",
      "37 Train Loss 57.467575 Test MSE 49.39116649415704 Test RE 0.11830791816109709 Lambda1 0.7172473\n",
      "38 Train Loss 54.334 Test MSE 47.27204247291515 Test RE 0.1157420990337646 Lambda1 0.72952867\n",
      "39 Train Loss 49.642017 Test MSE 46.74306363426391 Test RE 0.11509269441975357 Lambda1 0.72954637\n",
      "40 Train Loss 43.448925 Test MSE 39.52585919246593 Test RE 0.10583512576595223 Lambda1 0.9004157\n",
      "41 Train Loss 39.320705 Test MSE 37.06857453344459 Test RE 0.10249250633845777 Lambda1 1.0176477\n",
      "42 Train Loss 36.533722 Test MSE 35.47319874948477 Test RE 0.10026268870113882 Lambda1 1.1214595\n",
      "43 Train Loss 34.76156 Test MSE 35.31072187216443 Test RE 0.10003281001009856 Lambda1 1.1643294\n",
      "44 Train Loss 33.92639 Test MSE 35.456705671232626 Test RE 0.10023937768484513 Lambda1 1.0764831\n",
      "45 Train Loss 33.41861 Test MSE 35.640726041229385 Test RE 0.10049916233095688 Lambda1 1.005453\n",
      "46 Train Loss 33.16357 Test MSE 35.81116035740824 Test RE 0.10073916975436228 Lambda1 0.9387653\n",
      "47 Train Loss 33.034447 Test MSE 35.66336404309432 Test RE 0.10053107440629128 Lambda1 0.9496492\n",
      "48 Train Loss 32.823746 Test MSE 35.40825715009484 Test RE 0.10017087005517959 Lambda1 0.964649\n",
      "49 Train Loss 32.75575 Test MSE 35.331241213825464 Test RE 0.10006187072009093 Lambda1 0.9591422\n",
      "50 Train Loss 32.68693 Test MSE 35.35892836479888 Test RE 0.10010106953508673 Lambda1 0.95641315\n",
      "51 Train Loss 32.649048 Test MSE 35.141458407357135 Test RE 0.09979276620973548 Lambda1 0.97581255\n",
      "52 Train Loss 32.460995 Test MSE 34.73851769875406 Test RE 0.09921899236166999 Lambda1 0.9882475\n",
      "53 Train Loss 31.99234 Test MSE 34.37330681340337 Test RE 0.09869606276444265 Lambda1 0.97071093\n",
      "54 Train Loss 31.651192 Test MSE 34.22100698606168 Test RE 0.09847717081279109 Lambda1 0.9339838\n",
      "55 Train Loss 31.613617 Test MSE 34.14107915258928 Test RE 0.0983621001447112 Lambda1 0.93345827\n",
      "56 Train Loss 31.569742 Test MSE 34.21928200397598 Test RE 0.09847468880669016 Lambda1 0.9281404\n",
      "57 Train Loss 31.523098 Test MSE 34.409157538190335 Test RE 0.09874751843732452 Lambda1 0.9088737\n",
      "58 Train Loss 31.47646 Test MSE 34.325094694311076 Test RE 0.09862682275725917 Lambda1 0.93589497\n",
      "59 Train Loss 31.36179 Test MSE 33.93426214755943 Test RE 0.098063722690025 Lambda1 0.9610564\n",
      "60 Train Loss 31.21878 Test MSE 33.900417381259984 Test RE 0.09801480794240124 Lambda1 0.94567996\n",
      "61 Train Loss 31.188032 Test MSE 33.8753034845916 Test RE 0.09797849585537842 Lambda1 0.9469666\n",
      "62 Train Loss 31.16833 Test MSE 33.76823468358726 Test RE 0.09782353425596445 Lambda1 0.95609075\n",
      "63 Train Loss 30.914013 Test MSE 33.689462711006634 Test RE 0.0977093699840064 Lambda1 0.94476163\n",
      "64 Train Loss 30.62339 Test MSE 33.74128835215919 Test RE 0.09778449591897136 Lambda1 0.94086653\n",
      "65 Train Loss 30.250858 Test MSE 33.57566772632874 Test RE 0.09754421090382263 Lambda1 0.99884486\n",
      "66 Train Loss 30.17279 Test MSE 33.55589331870808 Test RE 0.09751548231545301 Lambda1 1.014002\n",
      "67 Train Loss 30.16403 Test MSE 33.54658862442851 Test RE 0.09750196137219672 Lambda1 1.001622\n",
      "68 Train Loss 30.16212 Test MSE 33.55009814600008 Test RE 0.0975070613883483 Lambda1 0.99516064\n",
      "69 Train Loss 30.152061 Test MSE 33.5756475324154 Test RE 0.09754418157008526 Lambda1 0.9925299\n",
      "70 Train Loss 30.133135 Test MSE 33.5630384650695 Test RE 0.09752586387943206 Lambda1 0.99290353\n",
      "71 Train Loss 30.126934 Test MSE 33.56786173622527 Test RE 0.09753287124242874 Lambda1 0.99112755\n",
      "72 Train Loss 30.11844 Test MSE 33.55305620311102 Test RE 0.09751135981241998 Lambda1 0.9937406\n",
      "73 Train Loss 30.08972 Test MSE 33.51073514691001 Test RE 0.0974498440173862 Lambda1 0.97714835\n",
      "74 Train Loss 30.087458 Test MSE 33.51605713290751 Test RE 0.09745758192754155 Lambda1 0.97395086\n",
      "Training time: 244.47\n",
      "Training time: 244.47\n",
      "inv_HT_swish_tune4\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 854.6677 Test MSE 858.0678644705978 Test RE 0.4931170164337741 Lambda1 -8.931951e-07\n",
      "1 Train Loss 854.4431 Test MSE 857.7401210952901 Test RE 0.4930228331660366 Lambda1 0.00032806638\n",
      "2 Train Loss 853.17706 Test MSE 856.4901723132534 Test RE 0.49266347142671923 Lambda1 0.0018782942\n",
      "3 Train Loss 849.40674 Test MSE 853.8400016254766 Test RE 0.4919006758421932 Lambda1 0.002535113\n",
      "4 Train Loss 843.3125 Test MSE 844.968596474072 Test RE 0.4893385772271401 Lambda1 0.03258918\n",
      "5 Train Loss 830.46893 Test MSE 825.0497581125471 Test RE 0.4835364762698369 Lambda1 0.051618263\n",
      "6 Train Loss 795.352 Test MSE 783.7826531043189 Test RE 0.471288664628714 Lambda1 0.07361915\n",
      "7 Train Loss 538.8103 Test MSE 428.15068809823225 Test RE 0.3483272842514795 Lambda1 0.11281855\n",
      "8 Train Loss 373.17645 Test MSE 284.6197979284547 Test RE 0.2840022126439609 Lambda1 0.12620473\n",
      "9 Train Loss 278.24088 Test MSE 236.27436154699052 Test RE 0.25876019501985326 Lambda1 0.14644554\n",
      "10 Train Loss 255.5614 Test MSE 220.62496520486533 Test RE 0.25004403453102014 Lambda1 0.17531443\n",
      "11 Train Loss 209.99979 Test MSE 175.3337849966673 Test RE 0.22290611091903134 Lambda1 0.28041816\n",
      "12 Train Loss 146.84503 Test MSE 140.4148351690863 Test RE 0.19947830435011896 Lambda1 0.36155024\n",
      "13 Train Loss 112.163574 Test MSE 100.8686051968721 Test RE 0.16907024358939512 Lambda1 0.44552898\n",
      "14 Train Loss 82.71366 Test MSE 73.68701441073632 Test RE 0.14450559112390227 Lambda1 0.5488724\n",
      "15 Train Loss 61.91414 Test MSE 59.20005673564341 Test RE 0.12952399526784564 Lambda1 0.6329796\n",
      "16 Train Loss 57.357956 Test MSE 57.35113214820806 Test RE 0.12748531706523325 Lambda1 0.6643422\n",
      "17 Train Loss 53.60743 Test MSE 56.062032174464434 Test RE 0.1260444097294493 Lambda1 0.71733636\n",
      "18 Train Loss 50.099953 Test MSE 52.91016202465858 Test RE 0.12244997938921014 Lambda1 0.7240553\n",
      "19 Train Loss 48.650692 Test MSE 50.47956074198671 Test RE 0.11960434422078091 Lambda1 0.7519657\n",
      "20 Train Loss 46.533478 Test MSE 49.222381317910155 Test RE 0.11810559745055989 Lambda1 0.7529801\n",
      "21 Train Loss 44.81407 Test MSE 47.15248440117034 Test RE 0.11559564182492303 Lambda1 0.7940211\n",
      "22 Train Loss 42.982513 Test MSE 45.70271614506626 Test RE 0.1138046942314136 Lambda1 0.8170675\n",
      "23 Train Loss 40.9409 Test MSE 43.81648203544185 Test RE 0.11143148635436788 Lambda1 0.8780383\n",
      "24 Train Loss 39.74979 Test MSE 42.42408534411043 Test RE 0.10964666190869468 Lambda1 0.9346114\n",
      "25 Train Loss 39.29553 Test MSE 41.92655486835843 Test RE 0.1090018225192634 Lambda1 0.966604\n",
      "26 Train Loss 38.415646 Test MSE 41.5193035551718 Test RE 0.1084711390423511 Lambda1 0.9982726\n",
      "27 Train Loss 37.948215 Test MSE 41.32773821717127 Test RE 0.10822061299266914 Lambda1 1.0082173\n",
      "28 Train Loss 37.65628 Test MSE 41.386473360126715 Test RE 0.10829748746770555 Lambda1 1.005016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Train Loss 37.502094 Test MSE 41.21598959767619 Test RE 0.10807420175908823 Lambda1 1.0016783\n",
      "30 Train Loss 37.05812 Test MSE 40.925800787989914 Test RE 0.10769307150087606 Lambda1 1.0264082\n",
      "31 Train Loss 36.976856 Test MSE 40.787496475021925 Test RE 0.1075109489668943 Lambda1 1.0362802\n",
      "32 Train Loss 36.862545 Test MSE 40.530403501619595 Test RE 0.10717158021963749 Lambda1 1.0484316\n",
      "33 Train Loss 36.441063 Test MSE 40.081829885282964 Test RE 0.10657686493110742 Lambda1 1.0603565\n",
      "34 Train Loss 35.970455 Test MSE 39.7031185512766 Test RE 0.10607217665711458 Lambda1 1.0795447\n",
      "35 Train Loss 35.797 Test MSE 39.49208548660727 Test RE 0.1057898995726263 Lambda1 1.0948632\n",
      "36 Train Loss 35.671326 Test MSE 39.14181437568629 Test RE 0.10531970819345268 Lambda1 1.0806856\n",
      "37 Train Loss 35.282475 Test MSE 38.57697152895686 Test RE 0.104557029402072 Lambda1 1.0347381\n",
      "38 Train Loss 34.78856 Test MSE 38.200242200288315 Test RE 0.10404524300572546 Lambda1 0.9688883\n",
      "39 Train Loss 34.42927 Test MSE 38.31753809703181 Test RE 0.10420485882767218 Lambda1 0.9327683\n",
      "40 Train Loss 34.290985 Test MSE 38.437095682768415 Test RE 0.10436730113111611 Lambda1 0.9087551\n",
      "41 Train Loss 34.211746 Test MSE 38.430107526160846 Test RE 0.10435781331492266 Lambda1 0.9150743\n",
      "42 Train Loss 34.071518 Test MSE 38.29569118914838 Test RE 0.1041751481696528 Lambda1 0.89938337\n",
      "43 Train Loss 33.980026 Test MSE 38.35043537233301 Test RE 0.1042495814355254 Lambda1 0.8724883\n",
      "44 Train Loss 33.70133 Test MSE 38.168942763348035 Test RE 0.1040026094427588 Lambda1 0.8835937\n",
      "45 Train Loss 33.540634 Test MSE 38.17166475226714 Test RE 0.1040063178098629 Lambda1 0.8628146\n",
      "46 Train Loss 33.15725 Test MSE 37.84284084921777 Test RE 0.1035573757126228 Lambda1 0.86832553\n",
      "47 Train Loss 32.90894 Test MSE 37.52863562050283 Test RE 0.10312656646942771 Lambda1 0.90391266\n",
      "48 Train Loss 32.868484 Test MSE 37.42551737055201 Test RE 0.10298478745305509 Lambda1 0.9226403\n",
      "49 Train Loss 32.799545 Test MSE 37.29998450168098 Test RE 0.10281192631821086 Lambda1 0.9314903\n",
      "50 Train Loss 32.55605 Test MSE 37.058343950927075 Test RE 0.10247836187222488 Lambda1 0.9284942\n",
      "51 Train Loss 32.35134 Test MSE 36.70828064257665 Test RE 0.1019931940019276 Lambda1 0.9544978\n",
      "52 Train Loss 32.007942 Test MSE 36.29564255972093 Test RE 0.10141832073350895 Lambda1 0.9556327\n",
      "53 Train Loss 31.559643 Test MSE 35.946166605757305 Test RE 0.10092888188767465 Lambda1 0.89694786\n",
      "54 Train Loss 31.384974 Test MSE 35.794911705903345 Test RE 0.1007163128940492 Lambda1 0.9049024\n",
      "55 Train Loss 31.21634 Test MSE 35.33565858123097 Test RE 0.10006812575410767 Lambda1 0.90503293\n",
      "56 Train Loss 30.974836 Test MSE 35.117897581925845 Test RE 0.09975930723738291 Lambda1 0.939481\n",
      "57 Train Loss 30.813354 Test MSE 34.84478552241051 Test RE 0.09937063577978689 Lambda1 0.94711304\n",
      "58 Train Loss 30.553762 Test MSE 34.33216157257826 Test RE 0.098636974919785 Lambda1 0.94997835\n",
      "59 Train Loss 30.275537 Test MSE 33.97769036244789 Test RE 0.09812645236895197 Lambda1 0.9953035\n",
      "60 Train Loss 30.196022 Test MSE 33.818608703347955 Test RE 0.0978964715638477 Lambda1 1.0228848\n",
      "61 Train Loss 30.138357 Test MSE 33.78215776965642 Test RE 0.09784369914073783 Lambda1 1.0124953\n",
      "62 Train Loss 30.035603 Test MSE 33.65881840461834 Test RE 0.09766492111428379 Lambda1 0.99831015\n",
      "63 Train Loss 29.994059 Test MSE 33.612859073100466 Test RE 0.09759822020218652 Lambda1 0.9896353\n",
      "64 Train Loss 29.97805 Test MSE 33.64566695941238 Test RE 0.09764583903698325 Lambda1 0.9763642\n",
      "65 Train Loss 29.972324 Test MSE 33.665216297300915 Test RE 0.09767420278285695 Lambda1 0.962816\n",
      "66 Train Loss 29.968292 Test MSE 33.6205488658891 Test RE 0.09760938359606243 Lambda1 0.96356887\n",
      "67 Train Loss 29.945417 Test MSE 33.58060221204979 Test RE 0.09755137848774499 Lambda1 0.96505743\n",
      "68 Train Loss 29.913197 Test MSE 33.58767226914987 Test RE 0.09756164717669744 Lambda1 0.94745284\n",
      "69 Train Loss 29.893036 Test MSE 33.503038563780024 Test RE 0.09743865247096083 Lambda1 0.95556474\n",
      "70 Train Loss 29.888744 Test MSE 33.47878482473623 Test RE 0.09740337687192306 Lambda1 0.9606959\n",
      "71 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "72 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "73 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "74 Train Loss 29.887312 Test MSE 33.4734082402117 Test RE 0.09739555522428579 Lambda1 0.9600491\n",
      "Training time: 238.22\n",
      "Training time: 238.22\n",
      "inv_HT_swish_tune4\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 854.7261 Test MSE 858.0597317088807 Test RE 0.49311467954827704 Lambda1 -1.2805835e-05\n",
      "1 Train Loss 854.52515 Test MSE 857.6835242063268 Test RE 0.49300656715598934 Lambda1 -0.001258337\n",
      "2 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "3 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "4 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "5 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "6 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "7 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "8 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "9 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "10 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "11 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "12 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "13 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "14 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "15 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "16 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "17 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "18 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "19 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "20 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "21 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "22 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "23 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "24 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "25 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "26 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "27 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "28 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "29 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "31 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "32 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "33 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "34 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "35 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "36 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "37 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "38 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "39 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "40 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "41 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "42 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "43 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "44 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "45 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "46 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "47 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "48 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "49 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "50 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "51 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "52 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "53 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "54 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "55 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "56 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "57 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "58 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "59 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "60 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "61 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "62 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "63 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "64 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "65 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "66 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "67 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "68 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "69 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "70 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "71 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "72 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "73 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "74 Train Loss 854.525 Test MSE 857.6885200748483 Test RE 0.4930080029958612 Lambda1 -0.0013049756\n",
      "Training time: 207.38\n",
      "Training time: 207.38\n",
      "inv_HT_swish_tune4\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 854.68005 Test MSE 858.0488217038218 Test RE 0.49311154462622503 Lambda1 0.00015224397\n",
      "1 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "2 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "3 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "4 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "5 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "6 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "7 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "8 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "9 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "10 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "11 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "12 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "13 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "14 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "15 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "16 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "17 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "18 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "19 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "20 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "21 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "22 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "23 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "24 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "25 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "26 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "27 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "28 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "29 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "31 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "32 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "33 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "34 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "35 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "36 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "37 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "38 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "39 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "40 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "41 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "42 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "43 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "44 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "45 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "46 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "47 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "48 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "49 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "50 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "51 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "52 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "53 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "54 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "55 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "56 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "57 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "58 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "59 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "60 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "61 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "62 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "63 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "64 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "65 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "66 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "67 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "68 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "69 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "70 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "71 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "72 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "73 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "74 Train Loss 854.52704 Test MSE 857.6824494782511 Test RE 0.4930062582727298 Lambda1 0.0031461688\n",
      "Training time: 191.38\n",
      "Training time: 191.38\n"
     ]
    }
   ],
   "source": [
    "nan_tune = []\n",
    "for tune_reps in range(5):\n",
    "    label = \"inv_HT_swish_tune\" + str(tune_reps)\n",
    "    max_reps = 10 #10\n",
    "    max_iter = 75 #75\n",
    "\n",
    "    train_loss_full = []\n",
    "    test_mse_full = []\n",
    "    test_re_full = []\n",
    "    beta_full = []\n",
    "   \n",
    "    lambda1_full = []\n",
    "    elapsed_time= np.zeros((max_reps,1))\n",
    "    \n",
    "    time_threshold = np.empty((max_reps,1))\n",
    "    time_threshold[:] = np.nan\n",
    "    epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "    for reps in range(max_reps):\n",
    "        print(label)\n",
    "        'Generate Training data'\n",
    "        print(reps)\n",
    "        torch.manual_seed(reps*36)\n",
    "        \n",
    "        train_loss = []\n",
    "        test_mse_loss = []\n",
    "        test_re_loss = []   \n",
    "        beta_val = []\n",
    "        \n",
    "        lambda1_val = []\n",
    "\n",
    "        N_f = 50000 #Total number of collocation points \n",
    "        N_train = 5000\n",
    "\n",
    "        layers = np.array([2,50,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "        \n",
    "        PINN = Sequentialmodel(layers)\n",
    "\n",
    "        PINN.to(device)\n",
    "\n",
    "        'Neural Network Summary'\n",
    "        print(PINN)\n",
    "\n",
    "        params = list(PINN.parameters())\n",
    "\n",
    "        optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lr_tune[tune_reps], \n",
    "                                  max_iter = 10, \n",
    "                                  max_eval = 15, \n",
    "                                  tolerance_grad = -1, \n",
    "                                  tolerance_change = -1, \n",
    "                                  history_size = 100, \n",
    "                                  line_search_fn = 'strong_wolfe')\n",
    "        \n",
    "        \n",
    "        nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "        torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "        train_loss_full.append(train_loss)\n",
    "        test_mse_full.append(test_mse_loss)\n",
    "        test_re_full.append(test_re_loss)\n",
    "        #elapsed_time[reps] = time.time() - start_time\n",
    "        beta_full.append(beta_val)\n",
    "\n",
    "        lambda1_full.append(lambda1_val)\n",
    "        \n",
    "        if(nan_flag == 1):\n",
    "            nan_tune.append(tune_reps)\n",
    "            break\n",
    "\n",
    "        print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "    mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full,\"lambda1\": lambda1_full, \"label\": label}\n",
    "    savemat(label+'.mat', mdic) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4147349700188199\n",
      "0.41454887311432104\n",
      "0.41437774368881597\n",
      "0.2823982732211698\n",
      "0.18179340722452575\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"inv_HT_swish_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
