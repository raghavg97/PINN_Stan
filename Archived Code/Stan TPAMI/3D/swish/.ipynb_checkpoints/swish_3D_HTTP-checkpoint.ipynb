{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLsZ-c_nCQr2",
    "outputId": "0238c820-5951-4e75-a35b-19e4de8c9b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SV23gJi7JexL",
    "outputId": "6f051579-557f-463f-d7b4-955ed617736e"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOyXTKXGJf97",
    "outputId": "11b7b7db-47b0-4cf8-c699-473f1c6b8c5f"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/gdrive/MyDrive/Virginia Tech /Fall 2022/Codes from GPU/MURI Aug17 Thin Plate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "APjvgycyCTj0",
    "outputId": "19bce659-211e-4bec-d94d-7c94148b0d09"
   },
   "outputs": [],
   "source": [
    "# !pip install smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lxFUD2gACQr7"
   },
   "outputs": [],
   "source": [
    "#Material Properties This link - https://www.mathworks.com/help/pde/ug/nonlinear-heat-transfer-in-a-thin-plate.html#heatTransferThinPlateExample-1\n",
    "k = 400\n",
    "rho = 8960\n",
    "cp = 386\n",
    "t_z = 0.01\n",
    "stef_bolt = 5.670373e-8\n",
    "hc = 1\n",
    "Ta = 300\n",
    "emiss = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CUcT7YuXCQr7"
   },
   "outputs": [],
   "source": [
    "label = \"3D_HTTP_swish\"\n",
    "loss_thresh = 10000\n",
    "x = np.linspace(0,1,100).reshape(-1,1)\n",
    "y = np.linspace(0,1,100).reshape(-1,1)\n",
    "t = np.linspace(0,1,100).reshape(-1,1) #t is actually from 0 to 5000, let us scale it to 0 to 1\n",
    "\n",
    "X,Y,T = np.meshgrid(x,y,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "Y = Y.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xyt = np.hstack((X,Y,T))\n",
    "\n",
    "initial_pts = np.logical_and(T==0,Y!=0).reshape(-1,)\n",
    "\n",
    "DBC_pts = (Y == 0).reshape(-1,)\n",
    "\n",
    "\n",
    "NBC_pts_x0 = (X == 0).reshape(-1,)\n",
    "NBC_pts_x1 = (X == 1).reshape(-1,)\n",
    "\n",
    "NBC_pts_y0 = (Y == 0).reshape(-1,)\n",
    "NBC_pts_y1 = (Y == 1).reshape(-1,)\n",
    "\n",
    "xyt_initial = xyt[initial_pts,:]\n",
    "xyt_DBC = xyt[DBC_pts,:]\n",
    "\n",
    "xyt_NBC_x0 = xyt[NBC_pts_x0,:]\n",
    "xyt_NBC_x1 = xyt[NBC_pts_x1,:]\n",
    "\n",
    "#xyt_NBC_y0 = xyt[NBC_pts_y0,:]\n",
    "xyt_NBC_y1 = xyt[NBC_pts_y1,:]\n",
    "\n",
    "u_initial = 300*np.ones((np.shape(xyt_initial)[0],1))\n",
    "u_DBC = 1000*np.ones((np.shape(xyt_DBC)[0],1))\n",
    "\n",
    "xyt_I_DBC = np.vstack((xyt_initial,xyt_DBC))\n",
    "#xyt_NBC = np.vstack((xyt_NBC_1,xyt_NBC_2,xyt_NBC_3,xyt_NBC_4))\n",
    "xyt_NBC_x = np.vstack((xyt_NBC_x0,xyt_NBC_x1))\n",
    "#xyt_NBC_y = np.vstack((xyt_NBC_y0,xyt_NBC_y1))\n",
    "xyt_NBC_y = np.vstack((xyt_NBC_y1))\n",
    "\n",
    "u_I_DBC = np.vstack((u_initial,u_DBC))\n",
    "\n",
    "\n",
    "lb_xyt = xyt[0]\n",
    "ub_xyt = xyt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_data = scipy.io.loadmat('./../3D_HTTP_FEA.mat')\n",
    "xy = fea_data['xy']\n",
    "t = fea_data['t']/3000\n",
    "xyt = np.zeros((497*101,3))\n",
    "u_true = np.ones((497*101,1))\n",
    "\n",
    "\n",
    "for i in range(101):\n",
    "    t_temp = t[0,i]*np.ones((497,1))\n",
    "    xyt[497*i:497*(i+1)] = np.hstack((xy,t_temp))\n",
    "    u_true[497*i:497*(i+1)] = fea_data['u'][:,i].reshape(-1,1)\n",
    "    #print(i)\n",
    "#print(xyt)\n",
    "\n",
    "xyt_test_tensor = torch.from_numpy(xyt).float().to(device)\n",
    "u_true_norm = np.linalg.norm(u_true,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gp2G6x6BCQr8"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_D,N_N,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    #choose random N_u points for training\n",
    "    idx = np.random.choice(xyt_I_DBC.shape[0], N_D, replace=False) \n",
    "    xyt_D = xyt_I_DBC[idx,:] #choose indices from  set 'idx' (x,t)\n",
    "    u_D = u_I_DBC[idx].reshape(-1,1)      #choose corresponding u\n",
    "\n",
    "    idx = np.random.choice(xyt_NBC_x.shape[0], N_D, replace=False) \n",
    "    xyt_Nx = xyt_NBC_x[idx,:] #choose indices from  set 'idx' (x,t)\n",
    "\n",
    "    idx = np.random.choice(xyt_NBC_y.shape[0], N_D, replace=False) \n",
    "    xyt_Ny = xyt_NBC_y[idx,:] #choose indices from  set 'idx' (x,t)\n",
    "\n",
    "    '''Collocation Points'''\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    \n",
    "    xyt_coll = lb_xyt + (ub_xyt - lb_xyt)*samples\n",
    "    xyt_coll = np.vstack((xyt_coll, xyt_D,xyt_Nx,xyt_Ny)) # append training points to collocation points \n",
    "\n",
    "    return xyt_coll, xyt_D, u_D, xyt_Nx,xyt_Ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VRolFlBzCQr9"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "     \n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)   \n",
    "        \n",
    "        self.beta = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "        self.iter = 0\n",
    "\n",
    "    \n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xyt):\n",
    "        if torch.is_tensor(xyt) != True:         \n",
    "            xyt = torch.from_numpy(xyt)                \n",
    "        \n",
    "        ubxyt = torch.from_numpy(ub_xyt).float().to(device)\n",
    "        lbxyt = torch.from_numpy(lb_xyt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xyt = (xyt - lbxyt)/(ubxyt - lbxyt)\n",
    "        \n",
    "        #convert to float\n",
    "        a = xyt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = z*self.activation(self.beta[:,i]*z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_D(self,xyt_D,u_D):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xyt_D), u_D)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_N(self,xyt_Nx,xyt_Ny,N_hat):\n",
    "        \n",
    "        g1 = xyt_Nx.clone()             \n",
    "        g1.requires_grad = True\n",
    "        u1 = self.forward(g1)\n",
    "        \n",
    "        u1_x_y_t = autograd.grad(u1,g1,torch.ones([xyt_Nx.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        du1_dx = u1_x_y_t[:,[0]]\n",
    "        \n",
    "        g2 = xyt_Ny.clone()             \n",
    "        g2.requires_grad = True\n",
    "        u2 = self.forward(g2)\n",
    "        \n",
    "        u2_x_y_t = autograd.grad(u2,g2,torch.ones([xyt_Ny.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        du2_dy = u2_x_y_t[:,[1]]\n",
    "               \n",
    "        loss_N1 = self.loss_function(du1_dx,N_hat)\n",
    "        loss_N2 = self.loss_function(du2_dy,N_hat)\n",
    "        \n",
    "        #return loss_N1+loss_N2       \n",
    "        return loss_N1 + loss_N2\n",
    "    \n",
    "    def loss_PDE(self, xyt_coll, f_hat):\n",
    "        \n",
    "        g = xyt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        u = self.forward(g) \n",
    "        \n",
    "        u_x_y_t = autograd.grad(u,g,torch.ones([xyt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        u_xx_yy_tt = autograd.grad(u_x_y_t,g,torch.ones(xyt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        du_dt = u_x_y_t[:,[2]]\n",
    "        \n",
    "        d2u_dx2 = u_xx_yy_tt[:,[0]]\n",
    "        d2u_dy2 = u_xx_yy_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        f = rho*cp*t_z*du_dt/3000 - k*t_z*(d2u_dx2+d2u_dy2) + 2*hc*(u-Ta) + 2*emiss*stef_bolt*(torch.pow(u,4)-Ta**4) \n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xyt_D,u_D,xyt_Nx,xyt_Ny,N_hat,xyt_coll,f_hat):\n",
    "\n",
    "        loss_D = self.loss_D(xyt_D,u_D)\n",
    "        loss_N = self.loss_N(xyt_Nx,xyt_Ny,N_hat)\n",
    "        loss_f = self.loss_PDE(xyt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_D + loss_N + loss_f\n",
    "        \n",
    "        #print(self.iter,\"loss_D:\",loss_D.cpu().detach().numpy(),\"loss_N:\",loss_N.cpu().detach().numpy(),\"loss_f:\",loss_f.cpu().detach().numpy())\n",
    "        \n",
    "        return loss_val\n",
    "       \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        u_pred = self.forward(xyt_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred\n",
    "\n",
    "    def test_loss(self):\n",
    "        u_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(u_pred.reshape(-1,1) - u_true.reshape(-1,1),2)/u_true_norm\n",
    "        \n",
    "        return test_mse, test_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(xyt_D,u_D,xyt_Nx,xyt_Ny,N_hat,xyt_coll,f_hat,seed):    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xyt_D,u_D,xyt_Nx,xyt_Ny,N_hat,xyt_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "    \n",
    "    xyt_coll_np_array, xyt_D_np_array, u_D_np_array,xyt_Nx_np_array,xyt_Ny_np_array = trainingdata(N_D,N_N,N_f,(reps)*22)\n",
    "\n",
    "    xyt_coll = torch.from_numpy(xyt_coll_np_array).float().to(device)\n",
    "    xyt_D = torch.from_numpy(xyt_D_np_array).float().to(device)\n",
    "    u_D = torch.from_numpy(u_D_np_array).float().to(device)\n",
    "    xyt_Nx = torch.from_numpy(xyt_Nx_np_array).float().to(device)\n",
    "    xyt_Ny = torch.from_numpy(xyt_Ny_np_array).float().to(device)\n",
    "\n",
    "    N_hat = torch.zeros(xyt_Nx.shape[0],1).to(device)    \n",
    "    f_hat = torch.zeros(xyt_coll.shape[0],1).to(device)\n",
    "\n",
    "    nan_flag = 0\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        train_step(xyt_D,u_D,xyt_Nx,xyt_Ny,N_hat,xyt_coll,f_hat,i)\n",
    "\n",
    "        loss_np = PINN.loss(xyt_D,u_D,xyt_Nx,xyt_Ny,N_hat,xyt_coll,f_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "\n",
    "        if(np.isnan(loss_np)):\n",
    "            nan_flag =1\n",
    "            print(\"NAN BREAK!\")\n",
    "            break\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVnXJfj0CQr-",
    "outputId": "1f2921b0-e258-465d-aa27-cdeb80b78a0b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D_HTTP_swish_tune0\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 248944.42 Test MSE 90358.42709689916 Test RE 0.5328729726988807\n",
      "1 Train Loss 243755.5 Test MSE 85893.8507646575 Test RE 0.5195416853746291\n",
      "2 Train Loss 228857.62 Test MSE 75520.47951162135 Test RE 0.4871601231801967\n",
      "3 Train Loss 211980.2 Test MSE 66881.09219846984 Test RE 0.458449011406987\n",
      "4 Train Loss 204560.3 Test MSE 62212.80991339392 Test RE 0.4421598159540957\n",
      "5 Train Loss 196338.3 Test MSE 57818.99460653636 Test RE 0.4262600484870081\n",
      "6 Train Loss 193725.36 Test MSE 55200.06226624983 Test RE 0.41649438039980896\n",
      "7 Train Loss 189389.84 Test MSE 52073.680247238924 Test RE 0.4045279170016393\n",
      "8 Train Loss 184557.7 Test MSE 49463.61736300241 Test RE 0.3942596201596677\n",
      "9 Train Loss 183665.4 Test MSE 48393.14766963177 Test RE 0.38997008916908843\n",
      "10 Train Loss 182334.42 Test MSE 47769.128461789966 Test RE 0.3874476410586867\n",
      "11 Train Loss 181506.42 Test MSE 47789.334081005756 Test RE 0.3875295746430063\n",
      "12 Train Loss 179929.56 Test MSE 47335.441336743854 Test RE 0.38568484800739067\n",
      "13 Train Loss 175618.64 Test MSE 43671.33744361481 Test RE 0.3704568319588946\n",
      "14 Train Loss 170341.45 Test MSE 42362.43404950154 Test RE 0.36486299191194016\n",
      "15 Train Loss 168036.28 Test MSE 42139.11057678636 Test RE 0.3638999907917313\n",
      "16 Train Loss 164551.16 Test MSE 40109.04389084323 Test RE 0.3550262923149569\n",
      "17 Train Loss 160605.1 Test MSE 39047.490654137924 Test RE 0.3502966040085108\n",
      "18 Train Loss 156869.19 Test MSE 37473.036443140256 Test RE 0.3431616954928674\n",
      "19 Train Loss 152082.34 Test MSE 35666.624417753315 Test RE 0.33478837274457784\n",
      "20 Train Loss 148886.34 Test MSE 34655.4039051309 Test RE 0.33000828611949945\n",
      "21 Train Loss 143720.16 Test MSE 32492.44012260732 Test RE 0.31954389590802207\n",
      "22 Train Loss 137650.1 Test MSE 29862.47447035669 Test RE 0.3063389771531271\n",
      "23 Train Loss 134977.47 Test MSE 28982.163814760326 Test RE 0.3017899448096138\n",
      "24 Train Loss 132381.03 Test MSE 27348.2868943285 Test RE 0.2931598061111986\n",
      "25 Train Loss 130175.945 Test MSE 26446.330951435968 Test RE 0.28828502030163644\n",
      "26 Train Loss 125079.44 Test MSE 24770.1843762676 Test RE 0.27899985774138464\n",
      "27 Train Loss 122600.414 Test MSE 23780.417338992243 Test RE 0.2733688956012813\n",
      "28 Train Loss 120137.65 Test MSE 22517.635406390076 Test RE 0.26601170922415396\n",
      "29 Train Loss 118388.48 Test MSE 21183.101856161447 Test RE 0.25800857459213244\n",
      "30 Train Loss 114777.336 Test MSE 20148.903634689697 Test RE 0.2516315380153027\n",
      "31 Train Loss 111647.3 Test MSE 19201.53709343353 Test RE 0.2456446783466959\n",
      "32 Train Loss 110013.664 Test MSE 18390.188146045326 Test RE 0.240398884665982\n",
      "33 Train Loss 106468.47 Test MSE 17227.665909664727 Test RE 0.23267653233687863\n",
      "34 Train Loss 104803.21 Test MSE 16085.662370858787 Test RE 0.22483236904316228\n",
      "35 Train Loss 102963.055 Test MSE 15029.464942233193 Test RE 0.21732571747190874\n",
      "36 Train Loss 100726.09 Test MSE 14249.968020569439 Test RE 0.21161493096308293\n",
      "37 Train Loss 99826.555 Test MSE 14484.328951041301 Test RE 0.21334798818082193\n",
      "38 Train Loss 98518.24 Test MSE 14719.732883621517 Test RE 0.21507470045351818\n",
      "39 Train Loss 96329.99 Test MSE 13494.613320896922 Test RE 0.2059299834204419\n",
      "40 Train Loss 94456.766 Test MSE 13188.114983315902 Test RE 0.2035779443378371\n",
      "41 Train Loss 91112.305 Test MSE 13132.739893766906 Test RE 0.20315009678640233\n",
      "42 Train Loss 89415.44 Test MSE 13048.816223642345 Test RE 0.20249994963741882\n",
      "43 Train Loss 87909.28 Test MSE 13100.879844318843 Test RE 0.20290352590908692\n",
      "44 Train Loss 86324.78 Test MSE 13500.508367798167 Test RE 0.2059749581941552\n",
      "45 Train Loss 83898.67 Test MSE 13183.744837236924 Test RE 0.2035442117281858\n",
      "46 Train Loss 81331.8 Test MSE 11327.6669156773 Test RE 0.18867293151162795\n",
      "47 Train Loss 78362.55 Test MSE 10536.796311126967 Test RE 0.18196742712805328\n",
      "48 Train Loss 75068.79 Test MSE 9920.164653747446 Test RE 0.17656263537936934\n",
      "49 Train Loss 73224.664 Test MSE 10038.042537977937 Test RE 0.17760855383622542\n",
      "50 Train Loss 71010.11 Test MSE 10034.410858313764 Test RE 0.17757642228658635\n",
      "51 Train Loss 68900.02 Test MSE 9217.23156738803 Test RE 0.1701921840188029\n",
      "52 Train Loss 67806.02 Test MSE 8927.597500444777 Test RE 0.16749685740450218\n",
      "53 Train Loss 66584.59 Test MSE 8624.695617827005 Test RE 0.16463086144114206\n",
      "54 Train Loss 65696.68 Test MSE 7993.040710112366 Test RE 0.15848763130743052\n",
      "55 Train Loss 64793.883 Test MSE 8122.796092151719 Test RE 0.15976886052504932\n",
      "56 Train Loss 63995.043 Test MSE 8592.794992362496 Test RE 0.16432611487443594\n",
      "57 Train Loss 62023.83 Test MSE 8534.397235004306 Test RE 0.16376677204013332\n",
      "58 Train Loss 58876.94 Test MSE 8095.525325796965 Test RE 0.15950043803004935\n",
      "59 Train Loss 55980.844 Test MSE 7138.813025360856 Test RE 0.14977949635100793\n",
      "60 Train Loss 55354.875 Test MSE 6959.262013021732 Test RE 0.14788392070853115\n",
      "61 Train Loss 54945.43 Test MSE 6972.3448821944085 Test RE 0.14802286055190852\n",
      "62 Train Loss 54386.527 Test MSE 6867.163692529734 Test RE 0.14690211959265972\n",
      "63 Train Loss 54108.727 Test MSE 6802.786493830917 Test RE 0.14621192082853235\n",
      "64 Train Loss 52689.016 Test MSE 6661.49774193856 Test RE 0.14468559836643488\n",
      "65 Train Loss 51776.164 Test MSE 6588.8478474801395 Test RE 0.14389446922650875\n",
      "66 Train Loss 51078.617 Test MSE 6470.0185281166605 Test RE 0.14259100315839285\n",
      "67 Train Loss 49175.7 Test MSE 6121.292384060131 Test RE 0.1386950381182626\n",
      "68 Train Loss 47647.836 Test MSE 5965.30628564724 Test RE 0.13691648331679548\n",
      "69 Train Loss 46952.09 Test MSE 5965.697725225111 Test RE 0.13692097542907658\n",
      "70 Train Loss 46201.594 Test MSE 6130.789262140191 Test RE 0.1388025856180293\n",
      "71 Train Loss 45268.117 Test MSE 5676.568237868075 Test RE 0.13356180930807338\n",
      "72 Train Loss 44284.95 Test MSE 5355.324219641451 Test RE 0.12972755908695516\n",
      "73 Train Loss 43664.016 Test MSE 5599.703173198133 Test RE 0.13265446290162813\n",
      "74 Train Loss 42933.805 Test MSE 5517.370154049121 Test RE 0.13167563543349184\n",
      "75 Train Loss 42532.65 Test MSE 5557.3749338187 Test RE 0.132152143313886\n",
      "76 Train Loss 41950.285 Test MSE 5671.74713165504 Test RE 0.13350508027575284\n",
      "77 Train Loss 41329.637 Test MSE 5406.746637363775 Test RE 0.13034890031606283\n",
      "78 Train Loss 41070.305 Test MSE 5252.899992604849 Test RE 0.1284810060092561\n",
      "79 Train Loss 40417.96 Test MSE 5148.203639943841 Test RE 0.1271941744434167\n",
      "80 Train Loss 39991.246 Test MSE 5197.621730592664 Test RE 0.12780319085061556\n",
      "81 Train Loss 39712.41 Test MSE 5185.7178782526 Test RE 0.12765675634091428\n",
      "82 Train Loss 39474.71 Test MSE 5135.172894092292 Test RE 0.12703310029017245\n",
      "83 Train Loss 39295.914 Test MSE 5055.000014366742 Test RE 0.12603754718457616\n",
      "84 Train Loss 39048.133 Test MSE 4940.423875184774 Test RE 0.12460098287160808\n",
      "85 Train Loss 38579.53 Test MSE 4982.75273857447 Test RE 0.12513362633123085\n",
      "86 Train Loss 38498.51 Test MSE 4971.034011350364 Test RE 0.12498639144711364\n",
      "87 Train Loss 38433.008 Test MSE 4916.097151322582 Test RE 0.12429383571862553\n",
      "88 Train Loss 38291.418 Test MSE 4870.0502129380675 Test RE 0.1237103631400706\n",
      "89 Train Loss 37923.363 Test MSE 4864.894820500153 Test RE 0.12364486644927615\n",
      "90 Train Loss 37802.84 Test MSE 4854.779420369614 Test RE 0.12351625440687741\n",
      "91 Train Loss 37597.684 Test MSE 4824.028048218437 Test RE 0.12312444172748893\n",
      "92 Train Loss 37322.53 Test MSE 4793.678965773867 Test RE 0.1227365284017684\n",
      "93 Train Loss 37137.01 Test MSE 4822.0633112500545 Test RE 0.12309936602560212\n",
      "94 Train Loss 36941.613 Test MSE 4879.154463983067 Test RE 0.12382594349992644\n",
      "95 Train Loss 36722.145 Test MSE 4872.733649792516 Test RE 0.1237444411491689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 Train Loss 36548.62 Test MSE 4929.835998369054 Test RE 0.1244673943901724\n",
      "97 Train Loss 36392.53 Test MSE 4940.183667554989 Test RE 0.12459795373166617\n",
      "98 Train Loss 36229.035 Test MSE 4869.583421346408 Test RE 0.12370443421340563\n",
      "99 Train Loss 36122.4 Test MSE 4875.121987324809 Test RE 0.12377476368561946\n",
      "Training time: 199.53\n",
      "3D_HTTP_swish_tune0\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 243699.88 Test MSE 88181.9078612032 Test RE 0.5264160324198637\n",
      "1 Train Loss 239569.98 Test MSE 84823.7036986714 Test RE 0.5162950697659173\n",
      "2 Train Loss 233944.34 Test MSE 81473.68020141542 Test RE 0.5059971016563817\n",
      "3 Train Loss 212601.73 Test MSE 68303.06941748758 Test RE 0.4632969834197875\n",
      "4 Train Loss 204483.48 Test MSE 65200.66695768783 Test RE 0.45265297738588756\n",
      "5 Train Loss 193862.25 Test MSE 58448.49317691538 Test RE 0.4285741987729053\n",
      "6 Train Loss 186283.92 Test MSE 52085.34772507526 Test RE 0.404573233139616\n",
      "7 Train Loss 182524.84 Test MSE 50826.41594473774 Test RE 0.3996539459762747\n",
      "8 Train Loss 177273.36 Test MSE 48060.03394088941 Test RE 0.3886255939422634\n",
      "9 Train Loss 172174.44 Test MSE 45710.41449388976 Test RE 0.3790067475684366\n",
      "10 Train Loss 169403.86 Test MSE 44276.06056597125 Test RE 0.37301289763351725\n",
      "11 Train Loss 166223.2 Test MSE 42611.69413517705 Test RE 0.3659348424065487\n",
      "12 Train Loss 164006.45 Test MSE 41347.07732592361 Test RE 0.36046389431352716\n",
      "13 Train Loss 160549.52 Test MSE 39902.82639298834 Test RE 0.354112446290363\n",
      "14 Train Loss 154917.9 Test MSE 36321.33260445697 Test RE 0.3378471418986745\n",
      "15 Train Loss 147803.77 Test MSE 35060.31254457093 Test RE 0.33193057162610956\n",
      "16 Train Loss 138680.11 Test MSE 30634.92452092509 Test RE 0.31027570388876535\n",
      "17 Train Loss 130788.94 Test MSE 26771.781721262538 Test RE 0.29005342623533586\n",
      "18 Train Loss 123150.016 Test MSE 25755.571310435036 Test RE 0.284495208350122\n",
      "19 Train Loss 114986.875 Test MSE 23676.48479786494 Test RE 0.27277086077182505\n",
      "20 Train Loss 103904.84 Test MSE 19685.367527548322 Test RE 0.24872023877378985\n",
      "21 Train Loss 95445.766 Test MSE 15948.642232272814 Test RE 0.22387274281464511\n",
      "22 Train Loss 86578.53 Test MSE 11833.64543765014 Test RE 0.1928406730384208\n",
      "23 Train Loss 80113.76 Test MSE 10122.25727707699 Test RE 0.17835202636487263\n",
      "24 Train Loss 75298.336 Test MSE 8784.022640600244 Test RE 0.1661445445133735\n",
      "25 Train Loss 71137.48 Test MSE 8654.338189714437 Test RE 0.16491353206586262\n",
      "26 Train Loss 65220.777 Test MSE 7794.516911088352 Test RE 0.15650707108707596\n",
      "27 Train Loss 57214.625 Test MSE 6642.384224643698 Test RE 0.14447787952160696\n",
      "28 Train Loss 51444.58 Test MSE 5850.128556655854 Test RE 0.13558825364006563\n",
      "29 Train Loss 49295.918 Test MSE 5710.026458024913 Test RE 0.13395484386479603\n",
      "30 Train Loss 46961.203 Test MSE 5505.14409824277 Test RE 0.13152966312695458\n",
      "31 Train Loss 46141.664 Test MSE 5528.5415976525655 Test RE 0.13180887491460475\n",
      "32 Train Loss 45043.484 Test MSE 5620.805992802069 Test RE 0.13290418602627863\n",
      "33 Train Loss 43886.445 Test MSE 5413.879315027074 Test RE 0.13043485128831991\n",
      "34 Train Loss 42909.926 Test MSE 4991.213777876137 Test RE 0.12523982379937335\n",
      "35 Train Loss 41448.016 Test MSE 4829.38622186832 Test RE 0.1231928015133104\n",
      "36 Train Loss 40936.38 Test MSE 4953.506906402398 Test RE 0.1247658554398746\n",
      "37 Train Loss 40607.582 Test MSE 4844.883400760562 Test RE 0.1233903019483135\n",
      "38 Train Loss 40342.67 Test MSE 4632.954540515679 Test RE 0.12066140600598693\n",
      "39 Train Loss 39539.582 Test MSE 4509.853223924015 Test RE 0.11904757851176173\n",
      "40 Train Loss 38869.504 Test MSE 4578.059278378629 Test RE 0.11994442534951613\n",
      "41 Train Loss 38525.668 Test MSE 4402.1775549488675 Test RE 0.1176178238239049\n",
      "42 Train Loss 38173.816 Test MSE 4286.457717820037 Test RE 0.11606162162440868\n",
      "43 Train Loss 37989.81 Test MSE 4184.585194819541 Test RE 0.11467416045577516\n",
      "44 Train Loss 37597.71 Test MSE 4024.7034452469584 Test RE 0.11246213007393188\n",
      "45 Train Loss 37387.74 Test MSE 4117.868514476164 Test RE 0.11375633717961207\n",
      "46 Train Loss 37087.137 Test MSE 4340.454329369176 Test RE 0.11679034938373463\n",
      "47 Train Loss 36665.32 Test MSE 4432.81488233274 Test RE 0.11802639977797928\n",
      "48 Train Loss 36129.465 Test MSE 4304.509922121636 Test RE 0.11630575873617233\n",
      "49 Train Loss 35798.9 Test MSE 4378.696754263218 Test RE 0.11730372321787434\n",
      "50 Train Loss 35488.477 Test MSE 4383.020388541074 Test RE 0.11736162323798409\n",
      "51 Train Loss 34837.4 Test MSE 4380.160645736729 Test RE 0.11732333014430235\n",
      "52 Train Loss 34599.727 Test MSE 4327.30880602712 Test RE 0.11661335933350954\n",
      "53 Train Loss 34381.01 Test MSE 4274.664501261428 Test RE 0.11590185303811\n",
      "54 Train Loss 34263.945 Test MSE 4323.176920488296 Test RE 0.11655767251429643\n",
      "55 Train Loss 33999.906 Test MSE 4304.458675547211 Test RE 0.11630506640538803\n",
      "56 Train Loss 33780.9 Test MSE 4206.582457236651 Test RE 0.11497517132240723\n",
      "57 Train Loss 33660.324 Test MSE 4221.660109493154 Test RE 0.11518103975014916\n",
      "58 Train Loss 33447.11 Test MSE 4268.060218836101 Test RE 0.11581228525440992\n",
      "59 Train Loss 33377.164 Test MSE 4248.560844899024 Test RE 0.11554742813303205\n",
      "60 Train Loss 33289.992 Test MSE 4233.790469289497 Test RE 0.11534639949021826\n",
      "61 Train Loss 33087.207 Test MSE 4231.678624662886 Test RE 0.11531762810204144\n",
      "62 Train Loss 32878.688 Test MSE 4278.853847646531 Test RE 0.1159586334125355\n",
      "63 Train Loss 32764.34 Test MSE 4407.15538830107 Test RE 0.11768430416251727\n",
      "64 Train Loss 32681.02 Test MSE 4463.616443715945 Test RE 0.11843574510028743\n",
      "65 Train Loss 32540.643 Test MSE 4419.969562101883 Test RE 0.11785526847013672\n",
      "66 Train Loss 32473.893 Test MSE 4386.305665486828 Test RE 0.11740559898738066\n",
      "67 Train Loss 32455.934 Test MSE 4366.003214772287 Test RE 0.11713357211808839\n",
      "68 Train Loss 32425.967 Test MSE 4330.6086115908465 Test RE 0.11665781283789245\n",
      "69 Train Loss 32381.947 Test MSE 4331.139118348688 Test RE 0.11666495800712771\n",
      "70 Train Loss 32306.082 Test MSE 4371.132355868319 Test RE 0.1172023556531066\n",
      "71 Train Loss 32268.516 Test MSE 4368.022337472803 Test RE 0.11716065406295866\n",
      "72 Train Loss 32217.365 Test MSE 4345.499280930674 Test RE 0.11685820294254909\n",
      "73 Train Loss 32170.031 Test MSE 4353.926918301825 Test RE 0.11697146513170796\n",
      "74 Train Loss 32116.977 Test MSE 4352.313725882335 Test RE 0.11694979332067294\n",
      "75 Train Loss 32101.11 Test MSE 4348.900568179184 Test RE 0.11690392732819352\n",
      "76 Train Loss 32089.027 Test MSE 4333.986514567518 Test RE 0.11670330089701107\n",
      "77 Train Loss 32055.906 Test MSE 4299.299982822839 Test RE 0.11623535241629641\n",
      "78 Train Loss 31961.139 Test MSE 4323.388211804417 Test RE 0.1165605208042897\n",
      "79 Train Loss 31896.775 Test MSE 4364.471108763708 Test RE 0.11711301821700552\n",
      "80 Train Loss 31793.008 Test MSE 4349.624659658526 Test RE 0.11691365916881946\n",
      "81 Train Loss 31748.762 Test MSE 4329.675972256539 Test RE 0.11664525045543457\n",
      "82 Train Loss 31628.94 Test MSE 4365.36341329984 Test RE 0.11712498932806639\n",
      "83 Train Loss 31503.576 Test MSE 4425.399997504426 Test RE 0.11792764554808811\n",
      "84 Train Loss 31383.0 Test MSE 4425.907571867782 Test RE 0.11793440825127956\n",
      "85 Train Loss 31355.283 Test MSE 4414.1386615331785 Test RE 0.11777750445680754\n",
      "86 Train Loss 31311.72 Test MSE 4446.468106776694 Test RE 0.1182080227481323\n",
      "87 Train Loss 31287.553 Test MSE 4490.555455623631 Test RE 0.11879260175849421\n",
      "88 Train Loss 31264.184 Test MSE 4512.670510302007 Test RE 0.11908475696764731\n",
      "89 Train Loss 31234.953 Test MSE 4499.327636501164 Test RE 0.11890857424588322\n",
      "90 Train Loss 31153.521 Test MSE 4443.565245120117 Test RE 0.11816943059459827\n",
      "91 Train Loss 31118.74 Test MSE 4420.279743465358 Test RE 0.11785940377763339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Train Loss 31066.586 Test MSE 4388.228503168521 Test RE 0.11743132988617444\n",
      "93 Train Loss 31034.383 Test MSE 4389.983357237702 Test RE 0.11745480795354485\n",
      "94 Train Loss 31015.924 Test MSE 4408.403518659568 Test RE 0.11770096740009264\n",
      "95 Train Loss 30990.432 Test MSE 4433.873959803142 Test RE 0.11804049822772351\n",
      "96 Train Loss 30962.836 Test MSE 4442.206281032695 Test RE 0.11815135948688611\n",
      "97 Train Loss 30946.514 Test MSE 4438.448169956806 Test RE 0.11810137082630097\n",
      "98 Train Loss 30932.674 Test MSE 4442.5947073455545 Test RE 0.11815652494869075\n",
      "99 Train Loss 30895.51 Test MSE 4445.196975491186 Test RE 0.11819112521816452\n",
      "Training time: 201.08\n",
      "3D_HTTP_swish_tune0\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 254398.8 Test MSE 91350.99498663105 Test RE 0.5357917266241736\n",
      "1 Train Loss 244316.05 Test MSE 86774.57873241471 Test RE 0.5221984990315384\n",
      "2 Train Loss 204239.92 Test MSE 56769.70419339611 Test RE 0.42237448752174517\n",
      "3 Train Loss 180037.38 Test MSE 49399.863199689324 Test RE 0.3940054556020736\n",
      "4 Train Loss 176390.95 Test MSE 47147.06481031925 Test RE 0.3849166456024996\n",
      "5 Train Loss 155607.17 Test MSE 37448.93101838519 Test RE 0.34305130426303126\n",
      "6 Train Loss 146844.75 Test MSE 32936.428800255126 Test RE 0.32171967126189255\n",
      "7 Train Loss 131929.28 Test MSE 28064.187115535107 Test RE 0.2969720629520885\n",
      "8 Train Loss 120057.39 Test MSE 22799.576498164075 Test RE 0.26767188186137764\n",
      "9 Train Loss 112882.11 Test MSE 21069.34349852169 Test RE 0.25731485789625735\n",
      "10 Train Loss 77456.34 Test MSE 10278.197351551127 Test RE 0.17972059111819016\n",
      "11 Train Loss 73079.81 Test MSE 9583.13511328457 Test RE 0.17353743255214868\n",
      "12 Train Loss 64849.664 Test MSE 11045.03414798402 Test RE 0.1863043063956186\n",
      "13 Train Loss 61809.53 Test MSE 9335.938546162768 Test RE 0.17128461441416248\n",
      "14 Train Loss 60863.13 Test MSE 7549.65416139028 Test RE 0.15402914015791028\n",
      "15 Train Loss 53831.47 Test MSE 4391.246672620397 Test RE 0.11747170685497932\n",
      "16 Train Loss 50290.01 Test MSE 4989.217414050284 Test RE 0.12521477485628857\n",
      "17 Train Loss 46144.93 Test MSE 6569.3808846072025 Test RE 0.14368174156399774\n",
      "18 Train Loss 45004.93 Test MSE 5319.153728438562 Test RE 0.1292887192226271\n",
      "19 Train Loss 43556.28 Test MSE 4594.670162995373 Test RE 0.12016182959063604\n",
      "20 Train Loss 41690.047 Test MSE 5355.0554489699425 Test RE 0.12972430369108912\n",
      "21 Train Loss 39425.836 Test MSE 5631.350655988613 Test RE 0.13302879210793045\n",
      "22 Train Loss 38917.46 Test MSE 4855.964819990984 Test RE 0.12353133307183346\n",
      "23 Train Loss 38038.14 Test MSE 4872.857893197464 Test RE 0.12374601873721441\n",
      "24 Train Loss 37716.098 Test MSE 5181.1677027123515 Test RE 0.12760073824101442\n",
      "25 Train Loss 37566.53 Test MSE 5135.8315369438 Test RE 0.12704124673065506\n",
      "26 Train Loss 36865.34 Test MSE 4767.661539210954 Test RE 0.12240300238923363\n",
      "27 Train Loss 36675.41 Test MSE 4782.283894512941 Test RE 0.12259056288801809\n",
      "28 Train Loss 36350.523 Test MSE 4809.749169181035 Test RE 0.12294208562615849\n",
      "29 Train Loss 34731.93 Test MSE 4012.540213353892 Test RE 0.11229206312982527\n",
      "30 Train Loss 32959.72 Test MSE 3497.892421561267 Test RE 0.10484375972443763\n",
      "31 Train Loss 31156.674 Test MSE 4478.641116023712 Test RE 0.11863490685275523\n",
      "32 Train Loss 30675.166 Test MSE 4195.223900343862 Test RE 0.11481983919606477\n",
      "33 Train Loss 30253.934 Test MSE 4153.177789804817 Test RE 0.11424300645835678\n",
      "34 Train Loss 29652.164 Test MSE 3904.8149429073865 Test RE 0.11077444696161667\n",
      "35 Train Loss 29186.695 Test MSE 3565.93295721327 Test RE 0.10585855198854882\n",
      "36 Train Loss 29123.729 Test MSE 3617.7600717994237 Test RE 0.10662504877383229\n",
      "37 Train Loss 29024.092 Test MSE 3732.105440251812 Test RE 0.1082969722152791\n",
      "38 Train Loss 28137.979 Test MSE 3771.5265748390157 Test RE 0.10886742436161415\n",
      "39 Train Loss 27487.014 Test MSE 3715.4033911033307 Test RE 0.10805437328514107\n",
      "40 Train Loss 27212.766 Test MSE 3614.4117653852354 Test RE 0.10657569558683837\n",
      "41 Train Loss 27145.506 Test MSE 3560.059813051081 Test RE 0.10577134076617437\n",
      "42 Train Loss 27047.842 Test MSE 3650.187449286279 Test RE 0.1071018434317671\n",
      "43 Train Loss 26958.53 Test MSE 3596.670387180184 Test RE 0.10631380986236008\n",
      "44 Train Loss 26738.834 Test MSE 3236.800020252846 Test RE 0.1008549680816418\n",
      "45 Train Loss 26498.496 Test MSE 3088.6467678815575 Test RE 0.09851979144064121\n",
      "46 Train Loss 26271.393 Test MSE 3019.478412885554 Test RE 0.09741040000536412\n",
      "47 Train Loss 26104.951 Test MSE 3045.0770133265296 Test RE 0.09782244255750785\n",
      "48 Train Loss 25971.27 Test MSE 3111.9829141740393 Test RE 0.09889127224266936\n",
      "49 Train Loss 25906.248 Test MSE 3105.1453755879866 Test RE 0.09878257230234\n",
      "50 Train Loss 25850.82 Test MSE 3123.6322370410953 Test RE 0.0990761929662626\n",
      "51 Train Loss 25681.707 Test MSE 3155.477938944371 Test RE 0.0995799574370103\n",
      "52 Train Loss 25540.74 Test MSE 3170.887878746645 Test RE 0.09982281323597504\n",
      "53 Train Loss 25194.463 Test MSE 3361.3982513605156 Test RE 0.10277780707760988\n",
      "54 Train Loss 25087.191 Test MSE 3333.036113860376 Test RE 0.10234328949673512\n",
      "55 Train Loss 25014.727 Test MSE 3175.4924526171444 Test RE 0.09989526530462861\n",
      "56 Train Loss 24798.111 Test MSE 2932.0544791110465 Test RE 0.09598986479019657\n",
      "57 Train Loss 24656.281 Test MSE 2883.3711901542392 Test RE 0.0951896301903772\n",
      "58 Train Loss 24593.307 Test MSE 2760.3125752912947 Test RE 0.09313619563412516\n",
      "59 Train Loss 24579.057 Test MSE 2735.9193888840923 Test RE 0.09272375500417802\n",
      "60 Train Loss 24414.314 Test MSE 2658.372565583731 Test RE 0.09140022932515893\n",
      "61 Train Loss 23994.086 Test MSE 2722.754539640778 Test RE 0.09250039932789886\n",
      "62 Train Loss 23892.615 Test MSE 2807.552050228358 Test RE 0.09392977250255707\n",
      "63 Train Loss 23861.71 Test MSE 2817.4251781240837 Test RE 0.09409478578758762\n",
      "64 Train Loss 23821.125 Test MSE 2838.7508228025686 Test RE 0.0944502254170963\n",
      "65 Train Loss 23786.787 Test MSE 2900.340201007333 Test RE 0.09546932090745774\n",
      "66 Train Loss 23755.178 Test MSE 2900.6159755348167 Test RE 0.09547385957865283\n",
      "67 Train Loss 23740.066 Test MSE 2883.894239960352 Test RE 0.09519826360185667\n",
      "68 Train Loss 23696.002 Test MSE 2872.0028208385934 Test RE 0.09500179110096352\n",
      "69 Train Loss 23580.271 Test MSE 2933.7503045655617 Test RE 0.09601761982114913\n",
      "70 Train Loss 23380.416 Test MSE 2637.6705877964946 Test RE 0.09104364579960693\n",
      "71 Train Loss 23213.895 Test MSE 2492.4908948837838 Test RE 0.08850262506737122\n",
      "72 Train Loss 23121.201 Test MSE 2481.795631868953 Test RE 0.08831253882502446\n",
      "73 Train Loss 23046.951 Test MSE 2376.1700587149207 Test RE 0.08641280878664563\n",
      "74 Train Loss 22987.092 Test MSE 2298.9967668544946 Test RE 0.08499796781604059\n",
      "75 Train Loss 22922.875 Test MSE 2405.767748087416 Test RE 0.08694932430768745\n",
      "76 Train Loss 22538.533 Test MSE 2568.323141770452 Test RE 0.08983885220863336\n",
      "77 Train Loss 21712.64 Test MSE 2196.1035452800365 Test RE 0.08307412367485528\n",
      "78 Train Loss 20924.309 Test MSE 2235.682264361494 Test RE 0.0838193720668049\n",
      "79 Train Loss 20416.477 Test MSE 1781.3238774938102 Test RE 0.07481881180355301\n",
      "80 Train Loss 19965.082 Test MSE 2002.6398288243483 Test RE 0.07933060873655731\n",
      "81 Train Loss 19866.686 Test MSE 2009.0635188632953 Test RE 0.07945773774947731\n",
      "82 Train Loss 19768.172 Test MSE 2034.166540288958 Test RE 0.0799526044453354\n",
      "83 Train Loss 19500.936 Test MSE 1885.6496675037579 Test RE 0.07697857487739089\n",
      "84 Train Loss 19366.957 Test MSE 1867.4723023850838 Test RE 0.07660664571734897\n",
      "85 Train Loss 19189.639 Test MSE 1831.379601080162 Test RE 0.07586274419186835\n",
      "86 Train Loss 19001.281 Test MSE 1879.5978615080141 Test RE 0.0768549480466897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 Train Loss 18914.773 Test MSE 1896.076051252308 Test RE 0.07719110156271257\n",
      "88 Train Loss 18854.346 Test MSE 1806.3239069577455 Test RE 0.07534200564241131\n",
      "89 Train Loss 18778.807 Test MSE 1732.4828197323466 Test RE 0.07378597672080059\n",
      "90 Train Loss 18750.225 Test MSE 1759.1241152295995 Test RE 0.07435113512588948\n",
      "91 Train Loss 18713.498 Test MSE 1752.1893784551637 Test RE 0.07420443862516937\n",
      "92 Train Loss 18628.17 Test MSE 1738.5126578131124 Test RE 0.0739142697780199\n",
      "93 Train Loss 18545.016 Test MSE 1826.6930401366908 Test RE 0.07576561437727962\n",
      "94 Train Loss 18501.893 Test MSE 1835.422514083254 Test RE 0.07594643448516958\n",
      "95 Train Loss 18487.01 Test MSE 1799.4729510098578 Test RE 0.07519899277730431\n",
      "96 Train Loss 18465.988 Test MSE 1816.8256622717875 Test RE 0.07556070302446682\n",
      "97 Train Loss 18409.883 Test MSE 1930.83493573465 Test RE 0.07789542232802095\n",
      "98 Train Loss 18391.115 Test MSE 1953.4553024914082 Test RE 0.07835037897119147\n",
      "99 Train Loss 18373.955 Test MSE 1919.0085577695984 Test RE 0.07765650090427892\n",
      "Training time: 204.58\n",
      "3D_HTTP_swish_tune0\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 247106.56 Test MSE 87340.80953874307 Test RE 0.5238994815668531\n",
      "1 Train Loss 241626.67 Test MSE 84464.76876592338 Test RE 0.5152015499870629\n",
      "2 Train Loss 235220.77 Test MSE 73087.49936020178 Test RE 0.47924866714987996\n",
      "3 Train Loss 207405.28 Test MSE 64254.55163186276 Test RE 0.4493567925246407\n",
      "4 Train Loss 194259.89 Test MSE 53595.05652411219 Test RE 0.4103946861639601\n",
      "5 Train Loss 191017.45 Test MSE 51906.04187915836 Test RE 0.40387625319098497\n",
      "6 Train Loss 184281.88 Test MSE 51030.83030260765 Test RE 0.4004568063341001\n",
      "7 Train Loss 179312.95 Test MSE 47472.46480476353 Test RE 0.3862426719557546\n",
      "8 Train Loss 165728.47 Test MSE 39587.96982585565 Test RE 0.3527126025856238\n",
      "9 Train Loss 161820.98 Test MSE 37859.0690342548 Test RE 0.34492472551934633\n",
      "10 Train Loss 161190.94 Test MSE 37843.65470525561 Test RE 0.3448545002783758\n",
      "11 Train Loss 159758.66 Test MSE 37593.73970925957 Test RE 0.34371392504537907\n",
      "12 Train Loss 158940.44 Test MSE 36703.38158906915 Test RE 0.3396193306153592\n",
      "13 Train Loss 156993.69 Test MSE 36521.04633616934 Test RE 0.3387746989657929\n",
      "14 Train Loss 153374.86 Test MSE 35392.68454873922 Test RE 0.3335002124012507\n",
      "15 Train Loss 144393.14 Test MSE 32346.004537815097 Test RE 0.31882302919320876\n",
      "16 Train Loss 139106.4 Test MSE 27164.135960558095 Test RE 0.29217113654259086\n",
      "17 Train Loss 132105.97 Test MSE 25430.79241490156 Test RE 0.28269576900851795\n",
      "18 Train Loss 124071.28 Test MSE 24240.867070315864 Test RE 0.27600276777186805\n",
      "19 Train Loss 120269.91 Test MSE 22089.290676286935 Test RE 0.2634694393547609\n",
      "20 Train Loss 114814.32 Test MSE 19413.132774938476 Test RE 0.24699443858744513\n",
      "21 Train Loss 111969.805 Test MSE 19162.803619253733 Test RE 0.2453967951988255\n",
      "22 Train Loss 100736.08 Test MSE 15263.202365696976 Test RE 0.21900911657437822\n",
      "23 Train Loss 95981.25 Test MSE 14080.426713389415 Test RE 0.210352302651893\n",
      "24 Train Loss 85401.945 Test MSE 12759.668365943553 Test RE 0.20024378958434028\n",
      "25 Train Loss 79354.59 Test MSE 10308.902842036881 Test RE 0.1799888430975524\n",
      "26 Train Loss 77437.5 Test MSE 10057.61031063323 Test RE 0.17778158118365225\n",
      "27 Train Loss 74591.375 Test MSE 9491.239184269194 Test RE 0.1727033736026334\n",
      "28 Train Loss 69743.66 Test MSE 7766.386178805713 Test RE 0.15622439557968515\n",
      "29 Train Loss 67007.945 Test MSE 7220.6063178120185 Test RE 0.15063510541534533\n",
      "30 Train Loss 64555.31 Test MSE 7581.24063865447 Test RE 0.15435101978405158\n",
      "31 Train Loss 59072.336 Test MSE 5971.33381232078 Test RE 0.13698563813903633\n",
      "32 Train Loss 49704.402 Test MSE 4958.347438272747 Test RE 0.12482680070988765\n",
      "33 Train Loss 47601.977 Test MSE 5012.726792996887 Test RE 0.12550943649982058\n",
      "34 Train Loss 46815.54 Test MSE 4965.4875718428175 Test RE 0.12491664509919313\n",
      "35 Train Loss 45008.695 Test MSE 5175.285939938316 Test RE 0.12752829024891543\n",
      "36 Train Loss 42478.125 Test MSE 5123.155713869172 Test RE 0.1268843736695969\n",
      "37 Train Loss 42329.055 Test MSE 5063.6110911780825 Test RE 0.12614485254422764\n",
      "38 Train Loss 42044.836 Test MSE 4744.382924973192 Test RE 0.12210381390253801\n",
      "39 Train Loss 40808.617 Test MSE 4136.248544482852 Test RE 0.11400992917314087\n",
      "40 Train Loss 40224.594 Test MSE 4392.1087353660505 Test RE 0.11748323695338952\n",
      "41 Train Loss 39864.484 Test MSE 4700.294693817985 Test RE 0.1215351513198577\n",
      "42 Train Loss 39720.71 Test MSE 4641.87261235084 Test RE 0.12077748201524108\n",
      "43 Train Loss 39030.48 Test MSE 4131.501989025866 Test RE 0.11394449430077419\n",
      "44 Train Loss 38472.664 Test MSE 3871.062548454172 Test RE 0.11029465245609893\n",
      "45 Train Loss 38312.496 Test MSE 4043.125819732111 Test RE 0.11271922405200444\n",
      "46 Train Loss 37976.555 Test MSE 4364.381457539773 Test RE 0.11711181539321797\n",
      "47 Train Loss 37816.98 Test MSE 4305.085451687315 Test RE 0.1163135337403801\n",
      "48 Train Loss 37557.273 Test MSE 4173.476393080387 Test RE 0.11452184678223493\n",
      "49 Train Loss 36572.7 Test MSE 4099.697842229806 Test RE 0.11350507679812694\n",
      "50 Train Loss 34572.88 Test MSE 4128.634301618144 Test RE 0.11390494283585696\n",
      "51 Train Loss 34141.273 Test MSE 4368.357086265032 Test RE 0.11716514335273748\n",
      "52 Train Loss 33813.145 Test MSE 4461.687267284907 Test RE 0.11841014835111417\n",
      "53 Train Loss 33709.863 Test MSE 4433.192650272754 Test RE 0.11803142882173695\n",
      "54 Train Loss 33513.355 Test MSE 4428.985398935859 Test RE 0.1179754075971309\n",
      "55 Train Loss 33139.24 Test MSE 4206.339390643026 Test RE 0.1149718495015174\n",
      "56 Train Loss 32749.828 Test MSE 3857.5859288774486 Test RE 0.11010249655720261\n",
      "57 Train Loss 32502.414 Test MSE 3917.1976355740135 Test RE 0.11094994826229462\n",
      "58 Train Loss 32366.754 Test MSE 4105.795558823559 Test RE 0.11358945675123097\n",
      "59 Train Loss 32186.266 Test MSE 4083.027734200907 Test RE 0.11327407571796497\n",
      "60 Train Loss 31916.217 Test MSE 3930.7972029197235 Test RE 0.11114237714801387\n",
      "61 Train Loss 31709.512 Test MSE 3868.121188059618 Test RE 0.11025274174458626\n",
      "62 Train Loss 31663.885 Test MSE 3915.426229739321 Test RE 0.11092485894740817\n",
      "63 Train Loss 31556.01 Test MSE 3978.8129095404365 Test RE 0.11181913320479607\n",
      "64 Train Loss 31133.162 Test MSE 3881.463949971012 Test RE 0.11044273187239594\n",
      "65 Train Loss 30945.219 Test MSE 3825.0521981240377 Test RE 0.10963722766415719\n",
      "66 Train Loss 30859.266 Test MSE 3812.55977347899 Test RE 0.10945804645916339\n",
      "67 Train Loss 30787.361 Test MSE 3876.9462920238802 Test RE 0.11037844069813445\n",
      "68 Train Loss 30755.021 Test MSE 3943.3496115833386 Test RE 0.11131969392074255\n",
      "69 Train Loss 30648.719 Test MSE 4018.9190027235445 Test RE 0.11238128378975909\n",
      "70 Train Loss 30457.99 Test MSE 3931.506006227478 Test RE 0.11115239732070174\n",
      "71 Train Loss 30261.91 Test MSE 3872.7046672577685 Test RE 0.11031804367193777\n",
      "72 Train Loss 30164.459 Test MSE 3854.5455364789864 Test RE 0.11005909884866243\n",
      "73 Train Loss 30073.902 Test MSE 3857.661340442098 Test RE 0.11010357274333459\n",
      "74 Train Loss 29928.715 Test MSE 3917.0559401868663 Test RE 0.11094794156777642\n",
      "75 Train Loss 29859.135 Test MSE 3945.967347392571 Test RE 0.11135663677801483\n",
      "76 Train Loss 29822.557 Test MSE 3917.0867401466408 Test RE 0.11094837776086025\n",
      "77 Train Loss 29767.79 Test MSE 3900.666316220015 Test RE 0.1107155857911613\n",
      "78 Train Loss 29687.28 Test MSE 3874.898456720349 Test RE 0.11034928544202478\n",
      "79 Train Loss 29628.094 Test MSE 3874.4034191070546 Test RE 0.11034223638095451\n",
      "80 Train Loss 29531.03 Test MSE 3894.202777041047 Test RE 0.11062381797973786\n",
      "81 Train Loss 29367.482 Test MSE 3939.74066939788 Test RE 0.1112687425291082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 Train Loss 29227.736 Test MSE 3976.4024813094534 Test RE 0.111785257167441\n",
      "83 Train Loss 29095.336 Test MSE 3910.100195609269 Test RE 0.11084938943337008\n",
      "84 Train Loss 29020.014 Test MSE 3891.8399068615677 Test RE 0.11059025149665379\n",
      "85 Train Loss 28946.73 Test MSE 3988.6324426808455 Test RE 0.11195703049764191\n",
      "86 Train Loss 28913.512 Test MSE 4068.0962775331177 Test RE 0.11306676680495117\n",
      "87 Train Loss 28878.488 Test MSE 4080.773189071868 Test RE 0.11324279785312653\n",
      "88 Train Loss 28849.332 Test MSE 4022.800036563354 Test RE 0.11243553349197898\n",
      "89 Train Loss 28817.6 Test MSE 3973.240642203348 Test RE 0.11174080526800277\n",
      "90 Train Loss 28797.207 Test MSE 3978.483081218928 Test RE 0.11181449842022423\n",
      "91 Train Loss 28706.932 Test MSE 4048.686060852122 Test RE 0.11279670503578483\n",
      "92 Train Loss 28575.021 Test MSE 4116.376150173872 Test RE 0.11373572198995142\n",
      "93 Train Loss 28488.52 Test MSE 4024.248590613077 Test RE 0.11245577490179598\n",
      "94 Train Loss 28419.543 Test MSE 3905.922679483866 Test RE 0.1107901583598525\n",
      "95 Train Loss 28389.775 Test MSE 3878.7948874634117 Test RE 0.11040475274239114\n",
      "96 Train Loss 28367.941 Test MSE 3850.372398900492 Test RE 0.10999950477489662\n",
      "97 Train Loss 28335.865 Test MSE 3791.2431939172243 Test RE 0.10915161956234488\n",
      "98 Train Loss 28291.828 Test MSE 3724.0731182592003 Test RE 0.10818036984274007\n",
      "99 Train Loss 28244.977 Test MSE 3722.9651861195575 Test RE 0.10816427651956423\n",
      "Training time: 227.59\n",
      "3D_HTTP_swish_tune0\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 247972.48 Test MSE 89077.02422695502 Test RE 0.529081056773153\n",
      "1 Train Loss 241832.31 Test MSE 85314.20659233029 Test RE 0.5177856859844076\n",
      "2 Train Loss 228241.9 Test MSE 74804.54563277343 Test RE 0.48484548630682917\n",
      "3 Train Loss 213872.11 Test MSE 67131.24809005317 Test RE 0.459305581473345\n",
      "4 Train Loss 198273.64 Test MSE 57756.63355340127 Test RE 0.4260301136953698\n",
      "5 Train Loss 192565.47 Test MSE 53800.19600481623 Test RE 0.41117934572770143\n",
      "6 Train Loss 185430.61 Test MSE 50725.93487059129 Test RE 0.39925870342322656\n",
      "7 Train Loss 181748.3 Test MSE 47087.16024862336 Test RE 0.38467203236846104\n",
      "8 Train Loss 179778.78 Test MSE 46478.68552477652 Test RE 0.38217852573049765\n",
      "9 Train Loss 176261.5 Test MSE 44693.97835791106 Test RE 0.3747691807750784\n",
      "10 Train Loss 175623.17 Test MSE 44285.13299917605 Test RE 0.3730511119779664\n",
      "11 Train Loss 174578.4 Test MSE 44465.104835444734 Test RE 0.37380837085423785\n",
      "12 Train Loss 173436.69 Test MSE 43809.97602550149 Test RE 0.37104439025211566\n",
      "13 Train Loss 170760.72 Test MSE 42796.77889074271 Test RE 0.36672870399778446\n",
      "14 Train Loss 167627.23 Test MSE 40461.40665885065 Test RE 0.3565823565450639\n",
      "15 Train Loss 164205.86 Test MSE 39913.04100029986 Test RE 0.35415776749258837\n",
      "16 Train Loss 161441.27 Test MSE 38836.49155689492 Test RE 0.3493488813030673\n",
      "17 Train Loss 157257.44 Test MSE 37430.543709194935 Test RE 0.3429670753585661\n",
      "18 Train Loss 154111.67 Test MSE 36069.15416757512 Test RE 0.33667226538231954\n",
      "19 Train Loss 148269.34 Test MSE 33210.93133065131 Test RE 0.32305754581426205\n",
      "20 Train Loss 141990.4 Test MSE 30856.713117482566 Test RE 0.3113968346111917\n",
      "21 Train Loss 140063.86 Test MSE 30184.04694125703 Test RE 0.30798395804474776\n",
      "22 Train Loss 136709.98 Test MSE 28581.253520437 Test RE 0.29969534566736417\n",
      "23 Train Loss 133907.02 Test MSE 27529.854348889745 Test RE 0.29413135188557643\n",
      "24 Train Loss 130763.22 Test MSE 25904.110942977764 Test RE 0.2853144108956324\n",
      "25 Train Loss 123608.88 Test MSE 22218.393888915372 Test RE 0.26423825523823496\n",
      "26 Train Loss 119227.82 Test MSE 21527.664442228557 Test RE 0.26009848338964664\n",
      "27 Train Loss 117263.96 Test MSE 21176.272577314972 Test RE 0.25796698119021816\n",
      "28 Train Loss 115873.83 Test MSE 20959.89208961092 Test RE 0.2566456356901569\n",
      "29 Train Loss 112158.73 Test MSE 19778.448608237508 Test RE 0.2493075746690626\n",
      "30 Train Loss 110356.18 Test MSE 19138.873106324983 Test RE 0.24524352154878068\n",
      "31 Train Loss 108337.836 Test MSE 18976.42479462315 Test RE 0.2442005057341934\n",
      "32 Train Loss 106182.83 Test MSE 18729.98601116921 Test RE 0.24260965972747364\n",
      "33 Train Loss 104655.1 Test MSE 18767.775901220975 Test RE 0.2428542827760747\n",
      "34 Train Loss 103725.01 Test MSE 19226.81022716869 Test RE 0.24580628440205463\n",
      "35 Train Loss 102340.414 Test MSE 19074.604446793728 Test RE 0.24483140934168232\n",
      "36 Train Loss 100182.9 Test MSE 18531.429730625823 Test RE 0.24132028290616786\n",
      "37 Train Loss 99020.52 Test MSE 18305.32937118212 Test RE 0.23984360099359847\n",
      "38 Train Loss 94885.54 Test MSE 17340.023161178684 Test RE 0.23343404669917192\n",
      "39 Train Loss 92251.984 Test MSE 16395.941201887643 Test RE 0.22699042516148857\n",
      "40 Train Loss 90337.01 Test MSE 16484.952135585987 Test RE 0.2276057384788424\n",
      "41 Train Loss 88705.28 Test MSE 16156.607264935681 Test RE 0.22532762871898435\n",
      "42 Train Loss 87516.234 Test MSE 15934.889317403802 Test RE 0.22377619645136496\n",
      "43 Train Loss 84951.84 Test MSE 15412.244963250303 Test RE 0.2200758124221975\n",
      "44 Train Loss 81578.766 Test MSE 14439.100537864339 Test RE 0.21301463012486047\n",
      "45 Train Loss 80038.12 Test MSE 13800.402438251918 Test RE 0.20825010919580253\n",
      "46 Train Loss 79187.13 Test MSE 13569.988553856665 Test RE 0.20650430168947523\n",
      "47 Train Loss 76554.58 Test MSE 13197.069183235615 Test RE 0.20364704323123434\n",
      "48 Train Loss 74362.92 Test MSE 12494.566686750353 Test RE 0.19815268518291057\n",
      "49 Train Loss 71646.85 Test MSE 11503.792996560556 Test RE 0.19013404659850516\n",
      "50 Train Loss 69546.7 Test MSE 10711.07962607348 Test RE 0.1834661663319291\n",
      "51 Train Loss 68684.19 Test MSE 10157.962627852987 Test RE 0.17866630981112636\n",
      "52 Train Loss 68375.87 Test MSE 9933.565178455903 Test RE 0.17668184879713703\n",
      "53 Train Loss 67117.79 Test MSE 9747.467251637847 Test RE 0.17501902276529765\n",
      "54 Train Loss 65554.0 Test MSE 9805.497556441469 Test RE 0.1755392264031237\n",
      "55 Train Loss 65037.54 Test MSE 9848.906154912524 Test RE 0.1759273503659809\n",
      "56 Train Loss 64450.457 Test MSE 9762.596331610657 Test RE 0.17515479393926456\n",
      "57 Train Loss 64094.664 Test MSE 9589.264111819353 Test RE 0.17359291756048265\n",
      "58 Train Loss 63548.656 Test MSE 9225.713476614555 Test RE 0.17027047339994716\n",
      "59 Train Loss 62196.44 Test MSE 8894.06660376446 Test RE 0.1671820132771626\n",
      "60 Train Loss 61618.562 Test MSE 8857.812608967617 Test RE 0.1668409316770075\n",
      "61 Train Loss 61195.21 Test MSE 8855.463343859994 Test RE 0.16681880547110872\n",
      "62 Train Loss 60427.89 Test MSE 8792.06466605675 Test RE 0.16622058216905006\n",
      "63 Train Loss 59688.637 Test MSE 8762.480126850141 Test RE 0.1659406875548469\n",
      "64 Train Loss 58657.055 Test MSE 8757.075498456226 Test RE 0.16588950420986392\n",
      "65 Train Loss 57360.605 Test MSE 8520.63546520687 Test RE 0.16363468128883854\n",
      "66 Train Loss 55257.746 Test MSE 8017.38465387562 Test RE 0.1587287961471692\n",
      "67 Train Loss 52724.395 Test MSE 7756.525728945452 Test RE 0.15612519036097253\n",
      "68 Train Loss 51501.06 Test MSE 7628.413995780226 Test RE 0.1548304903973824\n",
      "69 Train Loss 50352.08 Test MSE 7339.362928733162 Test RE 0.15186879398897343\n",
      "70 Train Loss 49864.715 Test MSE 7137.612779583047 Test RE 0.14976690463832742\n",
      "71 Train Loss 48749.836 Test MSE 7015.107470747005 Test RE 0.14847609149057456\n",
      "72 Train Loss 48390.97 Test MSE 7064.133172869228 Test RE 0.14899400737233554\n",
      "73 Train Loss 47925.41 Test MSE 7137.594078478183 Test RE 0.1497667084376852\n",
      "74 Train Loss 47625.344 Test MSE 7140.404081324231 Test RE 0.14979618640041478\n",
      "75 Train Loss 47410.67 Test MSE 7128.728005998697 Test RE 0.1496736620215032\n",
      "76 Train Loss 47123.07 Test MSE 7123.855762605426 Test RE 0.1496225048475501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 Train Loss 47007.453 Test MSE 7121.097025168896 Test RE 0.14959353112962703\n",
      "78 Train Loss 46842.77 Test MSE 7100.558122372817 Test RE 0.14937764405305073\n",
      "79 Train Loss 46639.223 Test MSE 7054.818377906745 Test RE 0.14889574291419574\n",
      "80 Train Loss 45962.008 Test MSE 6953.803756120662 Test RE 0.14782591550884566\n",
      "81 Train Loss 45626.355 Test MSE 6905.542542928764 Test RE 0.147312047141299\n",
      "82 Train Loss 45461.87 Test MSE 6813.924456981556 Test RE 0.14633156569466904\n",
      "83 Train Loss 44711.094 Test MSE 6727.047748550885 Test RE 0.14539571830403045\n",
      "84 Train Loss 44032.96 Test MSE 6721.106532542399 Test RE 0.1453314985886969\n",
      "85 Train Loss 43678.23 Test MSE 6701.5858574837275 Test RE 0.1451202958756675\n",
      "86 Train Loss 43307.754 Test MSE 6638.975165943857 Test RE 0.14444079970454082\n",
      "87 Train Loss 42777.97 Test MSE 6435.735068118583 Test RE 0.14221271938821148\n",
      "88 Train Loss 42300.082 Test MSE 6296.136723641466 Test RE 0.14066188639937172\n",
      "89 Train Loss 42102.67 Test MSE 6247.302963255861 Test RE 0.14011532742195612\n",
      "90 Train Loss 41916.953 Test MSE 6183.732424414938 Test RE 0.13940062043902787\n",
      "91 Train Loss 41652.77 Test MSE 6106.145546930008 Test RE 0.13852333480728535\n",
      "92 Train Loss 41106.2 Test MSE 6144.968340295531 Test RE 0.13896300183894927\n",
      "93 Train Loss 40860.867 Test MSE 6209.6812011178035 Test RE 0.1396927974346289\n",
      "94 Train Loss 40669.5 Test MSE 6202.788111416774 Test RE 0.13961524253907506\n",
      "95 Train Loss 40315.832 Test MSE 6088.615813318102 Test RE 0.13832435310588667\n",
      "96 Train Loss 40037.24 Test MSE 5975.565459071705 Test RE 0.13703416767925466\n",
      "97 Train Loss 39771.34 Test MSE 5869.532762833384 Test RE 0.13581293283705154\n",
      "98 Train Loss 39522.81 Test MSE 5832.762486740263 Test RE 0.13538685762817124\n",
      "99 Train Loss 39157.01 Test MSE 5771.509986292507 Test RE 0.1346741018606469\n",
      "Training time: 255.16\n",
      "3D_HTTP_swish_tune0\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 243250.67 Test MSE 86878.07516116294 Test RE 0.5225098204750347\n",
      "1 Train Loss 243164.88 Test MSE 87321.7655717589 Test RE 0.5238423624011384\n",
      "2 Train Loss 242809.08 Test MSE 87473.3653714301 Test RE 0.5242968880204023\n",
      "3 Train Loss 226810.08 Test MSE 77402.26019127613 Test RE 0.4931921818282735\n",
      "4 Train Loss 215318.61 Test MSE 67784.07142878676 Test RE 0.46153345572674603\n",
      "5 Train Loss 209034.1 Test MSE 61558.01614975019 Test RE 0.43982678084986604\n",
      "6 Train Loss 197087.73 Test MSE 60009.904201759375 Test RE 0.434261000831557\n",
      "7 Train Loss 188836.16 Test MSE 54542.60046916555 Test RE 0.41400661691735846\n",
      "8 Train Loss 184417.53 Test MSE 50188.332614183404 Test RE 0.39713736136795097\n",
      "9 Train Loss 179754.69 Test MSE 49340.8751893466 Test RE 0.3937701458392045\n",
      "10 Train Loss 178499.86 Test MSE 48155.22887321864 Test RE 0.3890102886942993\n",
      "11 Train Loss 176771.52 Test MSE 47213.15034480363 Test RE 0.38518631790087293\n",
      "12 Train Loss 172973.06 Test MSE 45257.64255287614 Test RE 0.37712500263704285\n",
      "13 Train Loss 169844.4 Test MSE 43394.607955921965 Test RE 0.36928124112340355\n",
      "14 Train Loss 167840.34 Test MSE 42247.27502394094 Test RE 0.3643667283990863\n",
      "15 Train Loss 164848.69 Test MSE 42414.199306590985 Test RE 0.36508584808935013\n",
      "16 Train Loss 162256.53 Test MSE 40967.06362726587 Test RE 0.3588035905643874\n",
      "17 Train Loss 159234.44 Test MSE 39418.733330745476 Test RE 0.35195788118279137\n",
      "18 Train Loss 158373.5 Test MSE 39158.10924286126 Test RE 0.3507924349909205\n",
      "19 Train Loss 157233.14 Test MSE 38340.47782279404 Test RE 0.3471107969636934\n",
      "20 Train Loss 154287.2 Test MSE 36459.20784924012 Test RE 0.3384877659174833\n",
      "21 Train Loss 150087.58 Test MSE 34511.075459889435 Test RE 0.32932038075078884\n",
      "22 Train Loss 148825.53 Test MSE 33787.9016843936 Test RE 0.3258516865042744\n",
      "23 Train Loss 147674.23 Test MSE 33363.35397996122 Test RE 0.32379803871374296\n",
      "24 Train Loss 145404.64 Test MSE 32098.418165509782 Test RE 0.31760050001482026\n",
      "25 Train Loss 142054.0 Test MSE 29581.941125330744 Test RE 0.3048966807092944\n",
      "26 Train Loss 139451.53 Test MSE 28903.104422759494 Test RE 0.3013780428001293\n",
      "27 Train Loss 136517.48 Test MSE 28427.181798089103 Test RE 0.2988864767671863\n",
      "28 Train Loss 135275.69 Test MSE 28161.602310071863 Test RE 0.2974870347532574\n",
      "29 Train Loss 132611.17 Test MSE 27308.94308503236 Test RE 0.2929488573448812\n",
      "30 Train Loss 131602.81 Test MSE 27090.229679758242 Test RE 0.29177340643482413\n",
      "31 Train Loss 129485.03 Test MSE 27115.40394169768 Test RE 0.2919089437598571\n",
      "32 Train Loss 127818.56 Test MSE 27118.241373616947 Test RE 0.2919242164456207\n",
      "33 Train Loss 126696.74 Test MSE 26644.278173974184 Test RE 0.28936189625026576\n",
      "34 Train Loss 123576.6 Test MSE 25190.933681448074 Test RE 0.2813594423124678\n",
      "35 Train Loss 120053.875 Test MSE 23669.00103824495 Test RE 0.2727277481031591\n",
      "36 Train Loss 115942.75 Test MSE 22935.509699757033 Test RE 0.2684686384047103\n",
      "37 Train Loss 115028.84 Test MSE 22303.58045588422 Test RE 0.264744322766825\n",
      "38 Train Loss 111856.03 Test MSE 20987.848105257362 Test RE 0.25681673386570064\n",
      "39 Train Loss 110764.02 Test MSE 20565.245460234757 Test RE 0.2542180077575464\n",
      "40 Train Loss 109325.516 Test MSE 19957.59318937799 Test RE 0.2504340893134399\n",
      "41 Train Loss 107943.53 Test MSE 19238.707831322812 Test RE 0.24588232544975522\n",
      "42 Train Loss 106488.72 Test MSE 18766.495213799502 Test RE 0.24284599661225537\n",
      "43 Train Loss 105020.86 Test MSE 18698.981070265512 Test RE 0.24240877293317786\n",
      "44 Train Loss 102793.055 Test MSE 18058.72766104516 Test RE 0.2382225869405892\n",
      "45 Train Loss 101447.484 Test MSE 17523.615101918556 Test RE 0.2346665642979688\n",
      "46 Train Loss 99693.59 Test MSE 17087.074066599118 Test RE 0.23172517199459391\n",
      "47 Train Loss 98472.08 Test MSE 17132.182497858776 Test RE 0.23203083782837394\n",
      "48 Train Loss 96449.3 Test MSE 17303.132340516386 Test RE 0.23318559954824167\n",
      "49 Train Loss 94678.79 Test MSE 17010.089474688884 Test RE 0.2312025720892206\n",
      "50 Train Loss 92866.86 Test MSE 15952.269978510083 Test RE 0.22389820289174203\n",
      "51 Train Loss 91118.65 Test MSE 15111.049641781554 Test RE 0.2179147755950115\n",
      "52 Train Loss 89780.555 Test MSE 14436.903872626044 Test RE 0.21299842621970824\n",
      "53 Train Loss 87757.664 Test MSE 14022.448040464136 Test RE 0.20991877431265749\n",
      "54 Train Loss 84424.33 Test MSE 13734.552292237537 Test RE 0.20775267088062757\n",
      "55 Train Loss 78648.71 Test MSE 12189.125875979898 Test RE 0.19571568996578778\n",
      "56 Train Loss 73354.875 Test MSE 10102.992871355069 Test RE 0.1781822281660748\n",
      "57 Train Loss 70951.39 Test MSE 9630.426956122945 Test RE 0.17396510078003657\n",
      "58 Train Loss 69617.52 Test MSE 9394.596395222332 Test RE 0.17182186381520723\n",
      "59 Train Loss 67609.82 Test MSE 9878.050952075988 Test RE 0.17618745942015\n",
      "60 Train Loss 63623.39 Test MSE 8964.8594973416 Test RE 0.16784604252889987\n",
      "61 Train Loss 62205.914 Test MSE 8611.216416470435 Test RE 0.16450216355191888\n",
      "62 Train Loss 60076.773 Test MSE 8724.946430801017 Test RE 0.16558490635502057\n",
      "63 Train Loss 58562.9 Test MSE 8387.07946911907 Test RE 0.16234717700123577\n",
      "64 Train Loss 54619.902 Test MSE 7935.226937463067 Test RE 0.15791341950142937\n",
      "65 Train Loss 52697.793 Test MSE 7466.6395482996995 Test RE 0.15317996125786798\n",
      "66 Train Loss 50691.082 Test MSE 7336.827135270606 Test RE 0.15184255593747514\n",
      "67 Train Loss 48466.984 Test MSE 6928.433073754862 Test RE 0.14755600054060067\n",
      "68 Train Loss 47209.58 Test MSE 6674.145686021246 Test RE 0.14482288787888764\n",
      "69 Train Loss 46032.957 Test MSE 6713.14205845921 Test RE 0.1452453645528653\n",
      "70 Train Loss 44750.68 Test MSE 6618.229547394216 Test RE 0.1442149472034656\n",
      "71 Train Loss 43797.07 Test MSE 6528.180270861256 Test RE 0.14323047477825196\n",
      "72 Train Loss 43454.168 Test MSE 6427.412785549651 Test RE 0.14212073942877138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 Train Loss 43110.242 Test MSE 6163.810149696809 Test RE 0.13917588417132543\n",
      "74 Train Loss 41820.605 Test MSE 5636.713538727757 Test RE 0.13309212043587407\n",
      "75 Train Loss 41059.246 Test MSE 5785.177389136139 Test RE 0.1348334671564044\n",
      "76 Train Loss 40114.68 Test MSE 5690.885198930545 Test RE 0.1337301324008671\n",
      "77 Train Loss 39558.46 Test MSE 5523.0771186000175 Test RE 0.13174371804715918\n",
      "78 Train Loss 39136.816 Test MSE 5583.492935427929 Test RE 0.13246231710285883\n",
      "79 Train Loss 38730.0 Test MSE 5602.873901593428 Test RE 0.13269201415526505\n",
      "80 Train Loss 38082.75 Test MSE 5355.7115413701695 Test RE 0.12973225024961024\n",
      "81 Train Loss 37462.69 Test MSE 5322.343916284234 Test RE 0.1293274841744625\n",
      "82 Train Loss 36661.85 Test MSE 5234.62190233292 Test RE 0.1282572787476795\n",
      "83 Train Loss 36447.13 Test MSE 5109.54833799624 Test RE 0.12671575578565333\n",
      "84 Train Loss 36128.79 Test MSE 5118.501541630917 Test RE 0.1268267260063255\n",
      "85 Train Loss 35860.914 Test MSE 5090.119974396305 Test RE 0.1264746166168918\n",
      "86 Train Loss 35596.938 Test MSE 5029.879127187403 Test RE 0.12572398453517664\n",
      "87 Train Loss 35450.152 Test MSE 4993.028263212946 Test RE 0.1252625863161409\n",
      "88 Train Loss 35248.293 Test MSE 4993.655767062323 Test RE 0.12527045731961695\n",
      "89 Train Loss 35118.41 Test MSE 4924.571744553652 Test RE 0.12440092128960693\n",
      "90 Train Loss 34840.824 Test MSE 4866.781609722239 Test RE 0.12366884119020491\n",
      "91 Train Loss 34680.855 Test MSE 4913.4304331182975 Test RE 0.12426011978648156\n",
      "92 Train Loss 34412.3 Test MSE 4858.2236332857965 Test RE 0.1235600608104276\n",
      "93 Train Loss 34138.42 Test MSE 4720.936199434611 Test RE 0.12180172187308164\n",
      "94 Train Loss 34065.17 Test MSE 4771.514050755339 Test RE 0.12245244630985269\n",
      "95 Train Loss 33932.715 Test MSE 4794.638976687911 Test RE 0.12274881776334157\n",
      "96 Train Loss 33838.383 Test MSE 4687.988675465503 Test RE 0.12137594917250506\n",
      "97 Train Loss 33719.453 Test MSE 4601.191523609014 Test RE 0.12024707409551295\n",
      "98 Train Loss 33556.17 Test MSE 4627.790087480387 Test RE 0.12059413533501598\n",
      "99 Train Loss 33257.34 Test MSE 4689.937080297894 Test RE 0.1214011694679402\n",
      "Training time: 246.48\n",
      "3D_HTTP_swish_tune0\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 250982.72 Test MSE 87882.14232362887 Test RE 0.525520521511256\n",
      "1 Train Loss 250187.84 Test MSE 89041.7821085969 Test RE 0.5289763845414313\n",
      "2 Train Loss 247876.5 Test MSE 87169.8922768866 Test RE 0.5233866209970024\n",
      "3 Train Loss 240943.25 Test MSE 83978.07033855762 Test RE 0.5137150719935063\n",
      "4 Train Loss 227222.64 Test MSE 73738.80959682254 Test RE 0.48137931362534625\n",
      "5 Train Loss 207971.67 Test MSE 62413.05418708171 Test RE 0.44287083382875486\n",
      "6 Train Loss 199433.53 Test MSE 58390.88386305051 Test RE 0.42836293624898103\n",
      "7 Train Loss 190398.48 Test MSE 53948.69077057228 Test RE 0.41174640599355533\n",
      "8 Train Loss 189044.23 Test MSE 52178.50501796233 Test RE 0.40493487140952567\n",
      "9 Train Loss 184392.81 Test MSE 49438.82731163823 Test RE 0.3941608107553591\n",
      "10 Train Loss 179826.4 Test MSE 46690.94171138918 Test RE 0.38305018715090683\n",
      "11 Train Loss 177672.89 Test MSE 46064.20794070407 Test RE 0.38047065512398276\n",
      "12 Train Loss 175238.69 Test MSE 45292.323059318296 Test RE 0.3772694686404457\n",
      "13 Train Loss 173371.42 Test MSE 44799.33281998704 Test RE 0.37521063134836696\n",
      "14 Train Loss 171230.56 Test MSE 43763.22371502024 Test RE 0.37084635529933685\n",
      "15 Train Loss 167857.28 Test MSE 41521.98726792302 Test RE 0.361225522281729\n",
      "16 Train Loss 162066.33 Test MSE 39101.92427274949 Test RE 0.35054068206207983\n",
      "17 Train Loss 156718.39 Test MSE 36102.59713649717 Test RE 0.33682830884513554\n",
      "18 Train Loss 148422.67 Test MSE 32869.03371932397 Test RE 0.32139034857696175\n",
      "19 Train Loss 134627.12 Test MSE 28965.54588152302 Test RE 0.30170341151465424\n",
      "20 Train Loss 121504.86 Test MSE 23751.980415918875 Test RE 0.2732053977213299\n",
      "21 Train Loss 113992.51 Test MSE 20171.05549552138 Test RE 0.2517698228495436\n",
      "22 Train Loss 106653.695 Test MSE 16105.409032004094 Test RE 0.22497032814007953\n",
      "23 Train Loss 97821.56 Test MSE 14270.10873051072 Test RE 0.21176442498339737\n",
      "24 Train Loss 91825.125 Test MSE 14020.279907733777 Test RE 0.2099025450009737\n",
      "25 Train Loss 86313.18 Test MSE 13094.781134799707 Test RE 0.2028562926802019\n",
      "26 Train Loss 81816.89 Test MSE 11837.255017631232 Test RE 0.19287008159068783\n",
      "27 Train Loss 72597.984 Test MSE 11000.796542493461 Test RE 0.18593083877018013\n",
      "28 Train Loss 71210.25 Test MSE 10677.262238050063 Test RE 0.18317631453161043\n",
      "29 Train Loss 69354.83 Test MSE 9927.902358730287 Test RE 0.17663148117623462\n",
      "30 Train Loss 68436.484 Test MSE 9421.705611711415 Test RE 0.17206959136394448\n",
      "31 Train Loss 66451.36 Test MSE 9220.074758496692 Test RE 0.17021843114034446\n",
      "32 Train Loss 63972.727 Test MSE 8678.659548006739 Test RE 0.16514509841930983\n",
      "33 Train Loss 60916.62 Test MSE 8649.2079496678 Test RE 0.1648646449408266\n",
      "34 Train Loss 58034.652 Test MSE 8601.084999665785 Test RE 0.1644053636105299\n",
      "35 Train Loss 54796.492 Test MSE 7447.415537433091 Test RE 0.15298264149429042\n",
      "36 Train Loss 52746.67 Test MSE 6759.98472103835 Test RE 0.14575122694705664\n",
      "37 Train Loss 52102.598 Test MSE 6630.59543494284 Test RE 0.1443496141531068\n",
      "38 Train Loss 49983.59 Test MSE 6625.989580849776 Test RE 0.14429947018295586\n",
      "39 Train Loss 48767.76 Test MSE 6692.882436330458 Test RE 0.1450260306205366\n",
      "40 Train Loss 46654.53 Test MSE 6071.820178684025 Test RE 0.13813343535325925\n",
      "41 Train Loss 44813.613 Test MSE 5674.362265449836 Test RE 0.13353585504441504\n",
      "42 Train Loss 44135.98 Test MSE 5676.670122244602 Test RE 0.13356300790201608\n",
      "43 Train Loss 43663.11 Test MSE 5498.582577011053 Test RE 0.13145125537090177\n",
      "44 Train Loss 42302.445 Test MSE 5236.984683988138 Test RE 0.12828622159800054\n",
      "45 Train Loss 41937.645 Test MSE 5234.299843416337 Test RE 0.12825333318710516\n",
      "46 Train Loss 41429.4 Test MSE 5132.097725339145 Test RE 0.12699505807323408\n",
      "47 Train Loss 40279.62 Test MSE 4936.368806751139 Test RE 0.12454983652794806\n",
      "48 Train Loss 39555.133 Test MSE 5010.457440779802 Test RE 0.12548102308598208\n",
      "49 Train Loss 38558.38 Test MSE 4927.2737994113495 Test RE 0.12443504527388312\n",
      "50 Train Loss 38149.31 Test MSE 4901.156069631099 Test RE 0.12410481407559584\n",
      "51 Train Loss 37318.08 Test MSE 4602.54782532258 Test RE 0.12026479551559509\n",
      "52 Train Loss 36443.727 Test MSE 4224.3577723361495 Test RE 0.11521783451584368\n",
      "53 Train Loss 35812.59 Test MSE 4278.757346252514 Test RE 0.11595732579216975\n",
      "54 Train Loss 35765.22 Test MSE 4274.420891906834 Test RE 0.11589855041893524\n",
      "55 Train Loss 35111.01 Test MSE 4294.088851785669 Test RE 0.1161648873042841\n",
      "56 Train Loss 34946.523 Test MSE 4284.948848432504 Test RE 0.11604119248999625\n",
      "57 Train Loss 34818.18 Test MSE 4216.183303178486 Test RE 0.1151063026850963\n",
      "58 Train Loss 34701.516 Test MSE 4253.466168434127 Test RE 0.11561411353895713\n",
      "59 Train Loss 34572.883 Test MSE 4307.597382079756 Test RE 0.11634746209059756\n",
      "60 Train Loss 34439.832 Test MSE 4284.9693155849645 Test RE 0.11604146962631999\n",
      "61 Train Loss 34331.918 Test MSE 4225.932705788324 Test RE 0.11523931038527617\n",
      "62 Train Loss 34306.242 Test MSE 4262.640498623877 Test RE 0.11573873081321331\n",
      "63 Train Loss 34252.066 Test MSE 4314.398006708492 Test RE 0.11643926771927314\n",
      "64 Train Loss 34233.605 Test MSE 4310.235777444498 Test RE 0.11638308793803809\n",
      "65 Train Loss 34176.445 Test MSE 4229.448977267913 Test RE 0.11528724399808613\n",
      "66 Train Loss 34113.457 Test MSE 4189.506057616066 Test RE 0.11474156618241325\n",
      "67 Train Loss 33896.56 Test MSE 4152.39617043886 Test RE 0.11423225580518835\n",
      "68 Train Loss 33735.582 Test MSE 4134.115124832493 Test RE 0.11398052301046636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 Train Loss 33669.953 Test MSE 4177.858271175548 Test RE 0.11458195124598544\n",
      "70 Train Loss 33639.25 Test MSE 4190.83418066187 Test RE 0.11475975195905916\n",
      "71 Train Loss 33559.883 Test MSE 4155.588562917798 Test RE 0.11427615866454999\n",
      "72 Train Loss 33402.0 Test MSE 4168.620695454492 Test RE 0.11445520625916186\n",
      "73 Train Loss 33338.805 Test MSE 4223.632251819319 Test RE 0.11520793993578374\n",
      "74 Train Loss 33289.81 Test MSE 4227.383484051913 Test RE 0.11525908972770395\n",
      "75 Train Loss 33243.633 Test MSE 4202.995940824135 Test RE 0.11492614717098729\n",
      "76 Train Loss 33201.477 Test MSE 4208.614483139536 Test RE 0.11500293784320552\n",
      "77 Train Loss 33161.32 Test MSE 4219.2270587889925 Test RE 0.11514784407690702\n",
      "78 Train Loss 33124.363 Test MSE 4212.999492356087 Test RE 0.11506283376103138\n",
      "79 Train Loss 33090.066 Test MSE 4242.818617241631 Test RE 0.11546931650829699\n",
      "80 Train Loss 32981.08 Test MSE 4324.723946021487 Test RE 0.11657852541602148\n",
      "81 Train Loss 32955.953 Test MSE 4303.1836310963345 Test RE 0.11628783948743339\n",
      "82 Train Loss 32915.07 Test MSE 4281.511476317378 Test RE 0.11599463921714558\n",
      "83 Train Loss 32861.547 Test MSE 4332.1496202888575 Test RE 0.11667856681623451\n",
      "84 Train Loss 32802.07 Test MSE 4331.250663969732 Test RE 0.11666646031183928\n",
      "85 Train Loss 32752.416 Test MSE 4317.479141892714 Test RE 0.11648083795615291\n",
      "86 Train Loss 32663.957 Test MSE 4364.9295439320285 Test RE 0.11711916871211896\n",
      "87 Train Loss 32629.316 Test MSE 4345.959671752438 Test RE 0.1168643931425338\n",
      "88 Train Loss 32615.895 Test MSE 4333.058798363048 Test RE 0.11669080970242092\n",
      "89 Train Loss 32595.207 Test MSE 4344.9373715543525 Test RE 0.11685064732712465\n",
      "90 Train Loss 32538.988 Test MSE 4357.417047070274 Test RE 0.11701833818482675\n",
      "91 Train Loss 32520.889 Test MSE 4364.14065354804 Test RE 0.1171085845365769\n",
      "92 Train Loss 32500.914 Test MSE 4358.270215942711 Test RE 0.11702979353969964\n",
      "93 Train Loss 32466.896 Test MSE 4345.603379177927 Test RE 0.11685960262765603\n",
      "94 Train Loss 32407.785 Test MSE 4352.270735734359 Test RE 0.1169492157311823\n",
      "95 Train Loss 32339.514 Test MSE 4384.385495939535 Test RE 0.11737989816410001\n",
      "96 Train Loss 32312.516 Test MSE 4377.786262110604 Test RE 0.11729152670391593\n",
      "97 Train Loss 32252.178 Test MSE 4327.322331608125 Test RE 0.11661354157867346\n",
      "98 Train Loss 32096.576 Test MSE 4315.851247824036 Test RE 0.11645887649019712\n",
      "99 Train Loss 31999.424 Test MSE 4388.2989444537525 Test RE 0.11743227240553068\n",
      "Training time: 252.27\n",
      "3D_HTTP_swish_tune0\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 248176.86 Test MSE 86789.62706138166 Test RE 0.522243776543994\n",
      "1 Train Loss 248026.75 Test MSE 87378.50516215699 Test RE 0.5240125248697439\n",
      "2 Train Loss 247625.89 Test MSE 87603.03902073493 Test RE 0.5246853623427659\n",
      "3 Train Loss 237967.67 Test MSE 79663.17412802567 Test RE 0.500343388592658\n",
      "4 Train Loss 219456.64 Test MSE 68907.71684237075 Test RE 0.4653431147235488\n",
      "5 Train Loss 196555.77 Test MSE 56459.94484853869 Test RE 0.42122058504071397\n",
      "6 Train Loss 175087.36 Test MSE 39402.37128101654 Test RE 0.3518848277183342\n",
      "7 Train Loss 164531.23 Test MSE 39307.38390096841 Test RE 0.3514604270377013\n",
      "8 Train Loss 152543.2 Test MSE 32819.86882256011 Test RE 0.3211498937369383\n",
      "9 Train Loss 138836.19 Test MSE 27077.21369329981 Test RE 0.291703304131667\n",
      "10 Train Loss 130799.92 Test MSE 25716.993720490307 Test RE 0.2842820651009639\n",
      "11 Train Loss 107922.3 Test MSE 19161.171883100236 Test RE 0.2453863470578562\n",
      "12 Train Loss 101912.94 Test MSE 16491.00840013525 Test RE 0.2276475436953126\n",
      "13 Train Loss 84555.39 Test MSE 11043.021129799487 Test RE 0.18628732813003954\n",
      "14 Train Loss 59696.79 Test MSE 4827.4821345754635 Test RE 0.12316851343996728\n",
      "15 Train Loss 54578.453 Test MSE 5580.9639645450225 Test RE 0.13243231515889398\n",
      "16 Train Loss 47860.7 Test MSE 6498.128097083886 Test RE 0.1429004170794779\n",
      "17 Train Loss 41392.11 Test MSE 6423.237035950659 Test RE 0.1420745655590197\n",
      "18 Train Loss 39460.246 Test MSE 5224.653397949978 Test RE 0.12813509776304965\n",
      "19 Train Loss 37132.484 Test MSE 4680.665318274788 Test RE 0.12128110819649025\n",
      "20 Train Loss 35922.723 Test MSE 5016.48069932683 Test RE 0.1255564231512339\n",
      "21 Train Loss 35058.85 Test MSE 4935.212427972304 Test RE 0.12453524734009414\n",
      "22 Train Loss 34747.43 Test MSE 4959.083124878633 Test RE 0.12483606085153022\n",
      "23 Train Loss 33777.98 Test MSE 5148.130239236635 Test RE 0.12719326770231948\n",
      "24 Train Loss 32707.18 Test MSE 4706.8060875107385 Test RE 0.12161930448332041\n",
      "25 Train Loss 32584.104 Test MSE 4622.9475161292385 Test RE 0.12053102329383372\n",
      "26 Train Loss 32527.508 Test MSE 4627.872144894768 Test RE 0.12059520448453258\n",
      "27 Train Loss 32078.207 Test MSE 4602.962433238518 Test RE 0.12027021225597838\n",
      "28 Train Loss 31406.152 Test MSE 4537.371234675975 Test RE 0.11941022562108373\n",
      "29 Train Loss 31300.889 Test MSE 4523.812279798065 Test RE 0.11923167628555348\n",
      "30 Train Loss 31279.822 Test MSE 4531.946632368033 Test RE 0.11933882450893975\n",
      "31 Train Loss 31203.623 Test MSE 4552.736765298081 Test RE 0.11961224245499387\n",
      "32 Train Loss 30906.965 Test MSE 4523.167384783229 Test RE 0.1192231774079\n",
      "33 Train Loss 30796.652 Test MSE 4528.666425327441 Test RE 0.11929562818036336\n",
      "34 Train Loss 30733.906 Test MSE 4528.792144504921 Test RE 0.11929728403693983\n",
      "35 Train Loss 30706.443 Test MSE 4503.158008621569 Test RE 0.11895917816153036\n",
      "36 Train Loss 30495.6 Test MSE 4368.164127126904 Test RE 0.11716255561388048\n",
      "37 Train Loss 30418.824 Test MSE 4329.842270902399 Test RE 0.11664749054927306\n",
      "38 Train Loss 30397.586 Test MSE 4340.036967091395 Test RE 0.11678473418145881\n",
      "39 Train Loss 30326.168 Test MSE 4382.382863565172 Test RE 0.11735308760726242\n",
      "40 Train Loss 30161.64 Test MSE 4405.459533592298 Test RE 0.11766165977328867\n",
      "41 Train Loss 29787.582 Test MSE 4178.7544809108 Test RE 0.11459424031218045\n",
      "42 Train Loss 29657.367 Test MSE 4267.801061205494 Test RE 0.11580876912629488\n",
      "43 Train Loss 29433.178 Test MSE 4144.287977927498 Test RE 0.11412067327905336\n",
      "44 Train Loss 29284.654 Test MSE 4085.744593508449 Test RE 0.11331175591138615\n",
      "45 Train Loss 29257.846 Test MSE 4058.6538880434223 Test RE 0.11293547189369657\n",
      "46 Train Loss 29231.605 Test MSE 3993.6884602064406 Test RE 0.11202796677037648\n",
      "47 Train Loss 29188.73 Test MSE 3984.7220674477953 Test RE 0.11190213682678347\n",
      "48 Train Loss 28921.266 Test MSE 4000.0451785093655 Test RE 0.11211708827877227\n",
      "49 Train Loss 28592.736 Test MSE 3935.663017112904 Test RE 0.11121114575554976\n",
      "50 Train Loss 28398.08 Test MSE 3897.5718105509045 Test RE 0.11067166022081547\n",
      "51 Train Loss 28279.2 Test MSE 3676.0388834239297 Test RE 0.10748043376064442\n",
      "52 Train Loss 28196.703 Test MSE 3622.3535629165044 Test RE 0.10669271852442212\n",
      "53 Train Loss 28155.355 Test MSE 3623.7069289308465 Test RE 0.10671264766886741\n",
      "54 Train Loss 28076.43 Test MSE 3635.872709406972 Test RE 0.10689162942110483\n",
      "55 Train Loss 27793.615 Test MSE 3588.3641864443134 Test RE 0.10619097760639114\n",
      "56 Train Loss 27652.396 Test MSE 3510.200543528877 Test RE 0.10502805593093996\n",
      "57 Train Loss 27599.807 Test MSE 3566.2783855194334 Test RE 0.1058636790696307\n",
      "58 Train Loss 27558.857 Test MSE 3624.610453565925 Test RE 0.10672595055160154\n",
      "59 Train Loss 27458.234 Test MSE 3575.1706734756735 Test RE 0.10599557906949271\n",
      "60 Train Loss 27200.383 Test MSE 3411.3952361495044 Test RE 0.10353933743353676\n",
      "61 Train Loss 27120.76 Test MSE 3495.5529155593968 Test RE 0.10480869237493592\n",
      "62 Train Loss 27008.89 Test MSE 3490.6509059861028 Test RE 0.10473517704339223\n",
      "63 Train Loss 26917.018 Test MSE 3386.1678808608613 Test RE 0.10315578900183313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 Train Loss 26871.508 Test MSE 3378.744641464079 Test RE 0.10304265665303657\n",
      "65 Train Loss 26793.893 Test MSE 3458.481061656632 Test RE 0.10425144015410011\n",
      "66 Train Loss 26556.762 Test MSE 3292.960940483384 Test RE 0.10172616023280351\n",
      "67 Train Loss 26338.611 Test MSE 3219.85060965855 Test RE 0.10059055940941716\n",
      "68 Train Loss 26262.32 Test MSE 3241.904594130677 Test RE 0.10093446307950768\n",
      "69 Train Loss 26116.82 Test MSE 3048.739703432351 Test RE 0.09788125644214318\n",
      "70 Train Loss 25993.625 Test MSE 2929.2286825837477 Test RE 0.09594359804882643\n",
      "71 Train Loss 25907.98 Test MSE 2887.1950318793083 Test RE 0.09525272811593882\n",
      "72 Train Loss 25773.828 Test MSE 2705.9181422713245 Test RE 0.09221396357516463\n",
      "73 Train Loss 25480.111 Test MSE 2672.543186456459 Test RE 0.09164351285995156\n",
      "74 Train Loss 25272.607 Test MSE 2777.5499695918616 Test RE 0.09342654803431824\n",
      "75 Train Loss 25067.416 Test MSE 2758.6150704004885 Test RE 0.09310755332328949\n",
      "76 Train Loss 24877.89 Test MSE 2737.619549879283 Test RE 0.09275256082878665\n",
      "77 Train Loss 24752.836 Test MSE 2725.4130696522993 Test RE 0.09254554755642877\n",
      "78 Train Loss 24307.117 Test MSE 2494.4712286009853 Test RE 0.08853777663679782\n",
      "79 Train Loss 24202.314 Test MSE 2441.9819330619534 Test RE 0.08760130692381217\n",
      "80 Train Loss 24111.56 Test MSE 2366.8648823123535 Test RE 0.08624344481793327\n",
      "81 Train Loss 23912.924 Test MSE 2239.2591811800407 Test RE 0.08388639748946236\n",
      "82 Train Loss 23429.115 Test MSE 2338.512682968997 Test RE 0.08572534212412897\n",
      "83 Train Loss 23170.955 Test MSE 2481.0088604731036 Test RE 0.088298539427542\n",
      "84 Train Loss 23075.23 Test MSE 2639.946095684209 Test RE 0.09108290882833124\n",
      "85 Train Loss 22912.643 Test MSE 2729.5843491820738 Test RE 0.0926163415505711\n",
      "86 Train Loss 22656.75 Test MSE 2494.1596061889422 Test RE 0.08853224616265709\n",
      "87 Train Loss 22198.852 Test MSE 2598.0431717339966 Test RE 0.0903571541145558\n",
      "88 Train Loss 21811.562 Test MSE 2477.549187996034 Test RE 0.08823695347307958\n",
      "89 Train Loss 21632.637 Test MSE 2337.886411687551 Test RE 0.08571386240986362\n",
      "90 Train Loss 21566.098 Test MSE 2275.2369375820203 Test RE 0.08455760567971173\n",
      "91 Train Loss 21437.375 Test MSE 2160.915379578397 Test RE 0.0824058877643969\n",
      "92 Train Loss 21320.072 Test MSE 2050.914576395743 Test RE 0.0802810692361848\n",
      "93 Train Loss 21268.002 Test MSE 2035.8495518416091 Test RE 0.07998567286249074\n",
      "94 Train Loss 20948.77 Test MSE 2038.033923687333 Test RE 0.08002857181114771\n",
      "95 Train Loss 20749.8 Test MSE 1938.5835925894917 Test RE 0.07805156735513624\n",
      "96 Train Loss 20683.516 Test MSE 1916.1129224873812 Test RE 0.07759788996349118\n",
      "97 Train Loss 20574.918 Test MSE 1875.1481613208887 Test RE 0.07676392216220099\n",
      "98 Train Loss 20410.383 Test MSE 1875.6974542789726 Test RE 0.0767751646856599\n",
      "99 Train Loss 20329.838 Test MSE 1933.6546392235955 Test RE 0.07795227904315302\n",
      "Training time: 250.72\n",
      "3D_HTTP_swish_tune0\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 243406.52 Test MSE 86679.1575635982 Test RE 0.5219113037614312\n",
      "1 Train Loss 243313.89 Test MSE 87151.48807836027 Test RE 0.5233313667141906\n",
      "2 Train Loss 242324.94 Test MSE 87333.40188750153 Test RE 0.5238772643069253\n",
      "3 Train Loss 232720.67 Test MSE 76943.42176971708 Test RE 0.4917281942924217\n",
      "4 Train Loss 218301.4 Test MSE 69568.43285041206 Test RE 0.46756874458497233\n",
      "5 Train Loss 198533.42 Test MSE 54705.79669178476 Test RE 0.4146255262774251\n",
      "6 Train Loss 187830.77 Test MSE 53336.24383964843 Test RE 0.4094025807589718\n",
      "7 Train Loss 183790.02 Test MSE 49537.6976646982 Test RE 0.39455474560502796\n",
      "8 Train Loss 178800.66 Test MSE 47160.10319929429 Test RE 0.3849698657344432\n",
      "9 Train Loss 174895.8 Test MSE 45573.678068376415 Test RE 0.37843944969252985\n",
      "10 Train Loss 168818.31 Test MSE 41386.57268058422 Test RE 0.3606360135070201\n",
      "11 Train Loss 167432.89 Test MSE 41164.727394475856 Test RE 0.3596681524790742\n",
      "12 Train Loss 164940.62 Test MSE 40875.36617643522 Test RE 0.35840180674972727\n",
      "13 Train Loss 160877.83 Test MSE 39567.83198065512 Test RE 0.35262288119633517\n",
      "14 Train Loss 156507.27 Test MSE 36425.61040861005 Test RE 0.33833177043076024\n",
      "15 Train Loss 148444.31 Test MSE 34044.70572430273 Test RE 0.32708765596045675\n",
      "16 Train Loss 140171.69 Test MSE 28771.75516924929 Test RE 0.30069246147061196\n",
      "17 Train Loss 133937.86 Test MSE 28405.543512972898 Test RE 0.2987727014722401\n",
      "18 Train Loss 123354.42 Test MSE 24485.699334782712 Test RE 0.27739307723806683\n",
      "19 Train Loss 115292.38 Test MSE 21576.052672262354 Test RE 0.2603906340063864\n",
      "20 Train Loss 111083.875 Test MSE 19560.300017520924 Test RE 0.24792887974997582\n",
      "21 Train Loss 107569.734 Test MSE 16603.72083219209 Test RE 0.22842417948246613\n",
      "22 Train Loss 103205.38 Test MSE 14666.532277894754 Test RE 0.21468568314674016\n",
      "23 Train Loss 99218.805 Test MSE 14157.92323591012 Test RE 0.2109303818345886\n",
      "24 Train Loss 94536.98 Test MSE 12608.572242791324 Test RE 0.19905464561576042\n",
      "25 Train Loss 89972.6 Test MSE 10785.632572436949 Test RE 0.18410355422197655\n",
      "26 Train Loss 83336.54 Test MSE 9465.829185036284 Test RE 0.17247203744087664\n",
      "27 Train Loss 78995.57 Test MSE 9077.213695678145 Test RE 0.16889455247569102\n",
      "28 Train Loss 72040.16 Test MSE 9856.162143163267 Test RE 0.17599214394507093\n",
      "29 Train Loss 69102.85 Test MSE 9581.552627105211 Test RE 0.17352310363350698\n",
      "30 Train Loss 63363.625 Test MSE 7622.0697078431 Test RE 0.15476609342495606\n",
      "31 Train Loss 61845.76 Test MSE 6968.8856462329295 Test RE 0.14798613621182255\n",
      "32 Train Loss 59681.258 Test MSE 6495.793738115961 Test RE 0.14287474731511968\n",
      "33 Train Loss 55760.29 Test MSE 5897.2001196834035 Test RE 0.13613264885028137\n",
      "34 Train Loss 51381.56 Test MSE 5482.121822747721 Test RE 0.13125434929484456\n",
      "35 Train Loss 46805.89 Test MSE 5987.9329797697355 Test RE 0.13717590296043672\n",
      "36 Train Loss 44648.848 Test MSE 5498.132796229401 Test RE 0.13144587894373227\n",
      "37 Train Loss 43897.805 Test MSE 5183.420275233878 Test RE 0.12762847317444048\n",
      "38 Train Loss 42347.06 Test MSE 4888.1798053523435 Test RE 0.12394041569813603\n",
      "39 Train Loss 42107.086 Test MSE 4753.059691787523 Test RE 0.12221541770625703\n",
      "40 Train Loss 40807.547 Test MSE 4392.7612088267315 Test RE 0.11749196304057691\n",
      "41 Train Loss 39613.95 Test MSE 4475.958074031708 Test RE 0.11859936592475936\n",
      "42 Train Loss 37554.594 Test MSE 4570.963728452429 Test RE 0.11985143816518794\n",
      "43 Train Loss 35725.496 Test MSE 4898.03216484416 Test RE 0.12406525673302216\n",
      "44 Train Loss 35466.76 Test MSE 4816.358389391079 Test RE 0.12302652582691194\n",
      "45 Train Loss 34477.613 Test MSE 4533.5167265513655 Test RE 0.11935949520338326\n",
      "46 Train Loss 33817.07 Test MSE 4485.9678523616385 Test RE 0.11873190630649302\n",
      "47 Train Loss 33589.723 Test MSE 4540.8968406749345 Test RE 0.11945660838747134\n",
      "48 Train Loss 33358.53 Test MSE 4601.409041661238 Test RE 0.12024991635931465\n",
      "49 Train Loss 33059.4 Test MSE 4548.70254823625 Test RE 0.11955923601978509\n",
      "50 Train Loss 32710.824 Test MSE 4503.5206138391295 Test RE 0.11896396750606285\n",
      "51 Train Loss 32325.672 Test MSE 4428.759878096238 Test RE 0.1179724039462632\n",
      "52 Train Loss 32215.852 Test MSE 4376.238194485003 Test RE 0.11727078662441938\n",
      "53 Train Loss 32047.896 Test MSE 4372.2262476206015 Test RE 0.117217019893367\n",
      "54 Train Loss 31780.41 Test MSE 4401.408346483225 Test RE 0.11760754748030398\n",
      "55 Train Loss 31347.465 Test MSE 4335.978916234542 Test RE 0.11673012298486911\n",
      "56 Train Loss 31176.46 Test MSE 4390.687932875397 Test RE 0.11746423310043595\n",
      "57 Train Loss 31072.785 Test MSE 4393.503571162857 Test RE 0.11750189050069618\n",
      "58 Train Loss 30772.129 Test MSE 4332.252309126595 Test RE 0.11667994967653063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 Train Loss 30396.445 Test MSE 4225.274606664902 Test RE 0.11523033700031811\n",
      "60 Train Loss 29893.15 Test MSE 4234.256488680612 Test RE 0.11535274748737867\n",
      "61 Train Loss 29461.186 Test MSE 4298.583358798993 Test RE 0.1162256647325278\n",
      "62 Train Loss 29309.762 Test MSE 4199.337124975767 Test RE 0.11487611319914244\n",
      "63 Train Loss 29009.688 Test MSE 4198.891809782047 Test RE 0.1148700220669764\n",
      "64 Train Loss 28750.898 Test MSE 4238.889283090765 Test RE 0.11541583524184469\n",
      "65 Train Loss 28407.873 Test MSE 4070.831051540624 Test RE 0.1131047649353369\n",
      "66 Train Loss 28331.246 Test MSE 4043.7697325299077 Test RE 0.11272819959030622\n",
      "67 Train Loss 28224.67 Test MSE 4042.538907243162 Test RE 0.11271104242171044\n",
      "68 Train Loss 28088.361 Test MSE 3973.0787133617114 Test RE 0.11173852825470947\n",
      "69 Train Loss 27944.64 Test MSE 3839.134880181607 Test RE 0.10983886774993805\n",
      "70 Train Loss 27896.371 Test MSE 3799.257978875768 Test RE 0.10926693330647634\n",
      "71 Train Loss 27872.395 Test MSE 3795.457269436116 Test RE 0.10921226529211886\n",
      "72 Train Loss 27836.91 Test MSE 3777.475236131965 Test RE 0.108953246409788\n",
      "73 Train Loss 27752.93 Test MSE 3776.060791668756 Test RE 0.108932846177444\n",
      "74 Train Loss 27673.71 Test MSE 3724.8544828401136 Test RE 0.10819171815322028\n",
      "75 Train Loss 27603.693 Test MSE 3716.578944978011 Test RE 0.1080714661385719\n",
      "76 Train Loss 27385.564 Test MSE 3802.2914877002977 Test RE 0.1093105465687039\n",
      "77 Train Loss 27094.824 Test MSE 3686.1443293091506 Test RE 0.10762806444634967\n",
      "78 Train Loss 26647.871 Test MSE 3681.5010238016334 Test RE 0.10756025545431243\n",
      "79 Train Loss 26482.994 Test MSE 3678.339195871528 Test RE 0.10751405689708018\n",
      "80 Train Loss 26389.215 Test MSE 3725.976470031647 Test RE 0.10820801148532096\n",
      "81 Train Loss 26206.502 Test MSE 3842.308836664055 Test RE 0.10988426232083551\n",
      "82 Train Loss 26038.783 Test MSE 3853.200459086502 Test RE 0.1100398941303188\n",
      "83 Train Loss 25851.947 Test MSE 3889.6888182418047 Test RE 0.1105596846802309\n",
      "84 Train Loss 25648.918 Test MSE 3918.7030806162616 Test RE 0.11097126618139783\n",
      "85 Train Loss 25340.994 Test MSE 3771.6211019159427 Test RE 0.10886878864404895\n",
      "86 Train Loss 24882.188 Test MSE 3467.6440788875902 Test RE 0.10438945245475745\n",
      "87 Train Loss 24706.0 Test MSE 3227.9702802755673 Test RE 0.10071731186449324\n",
      "88 Train Loss 24167.742 Test MSE 3221.598881404502 Test RE 0.10061786436688845\n",
      "89 Train Loss 23786.06 Test MSE 3227.524140541568 Test RE 0.10071035152354851\n",
      "90 Train Loss 23687.12 Test MSE 3144.0110879688664 Test RE 0.0993988584376151\n",
      "91 Train Loss 23374.531 Test MSE 3017.2842045382013 Test RE 0.09737500025616087\n",
      "92 Train Loss 23229.734 Test MSE 2985.275427173129 Test RE 0.09685712310265607\n",
      "93 Train Loss 23087.822 Test MSE 2868.9026487391516 Test RE 0.09495050260237939\n",
      "94 Train Loss 22969.195 Test MSE 2912.1350836365305 Test RE 0.09566324762738919\n",
      "95 Train Loss 22705.527 Test MSE 2697.5838079456835 Test RE 0.09207184273863023\n",
      "96 Train Loss 22361.828 Test MSE 2411.166292264292 Test RE 0.08704682680569627\n",
      "97 Train Loss 22077.19 Test MSE 2352.5220466924898 Test RE 0.08598173676029292\n",
      "98 Train Loss 21649.195 Test MSE 2256.0493931856813 Test RE 0.08420030488474664\n",
      "99 Train Loss 21090.13 Test MSE 2219.362412022279 Test RE 0.08351288278883874\n",
      "Training time: 248.83\n",
      "3D_HTTP_swish_tune0\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 244444.55 Test MSE 89095.16301779314 Test RE 0.5291349225269967\n",
      "1 Train Loss 242764.72 Test MSE 88214.19339072962 Test RE 0.5265123904224736\n",
      "2 Train Loss 240857.5 Test MSE 86675.90699596946 Test RE 0.5219015175340249\n",
      "3 Train Loss 236566.08 Test MSE 84318.61147268064 Test RE 0.5147556062628615\n",
      "4 Train Loss 222578.17 Test MSE 72406.8037772795 Test RE 0.4770117211994695\n",
      "5 Train Loss 208571.7 Test MSE 67656.00116070126 Test RE 0.46109724218602827\n",
      "6 Train Loss 188185.33 Test MSE 53816.35745978338 Test RE 0.4112410997545716\n",
      "7 Train Loss 184087.36 Test MSE 51333.82696314798 Test RE 0.4016439073144494\n",
      "8 Train Loss 167650.66 Test MSE 44051.109512188734 Test RE 0.37206411748279133\n",
      "9 Train Loss 159325.34 Test MSE 39765.72567172681 Test RE 0.3535035815808294\n",
      "10 Train Loss 154602.67 Test MSE 37598.39077433286 Test RE 0.3437351863830638\n",
      "11 Train Loss 151510.92 Test MSE 36034.57841757183 Test RE 0.33651086033458655\n",
      "12 Train Loss 143634.16 Test MSE 31105.683047306 Test RE 0.31265057620938363\n",
      "13 Train Loss 139880.67 Test MSE 28107.38789150799 Test RE 0.29720054792553147\n",
      "14 Train Loss 132720.61 Test MSE 26579.846981373994 Test RE 0.2890118170177894\n",
      "15 Train Loss 124694.43 Test MSE 25393.997664319293 Test RE 0.2824911846345928\n",
      "16 Train Loss 117523.38 Test MSE 23418.27266057847 Test RE 0.2712793844381437\n",
      "17 Train Loss 111040.99 Test MSE 20349.53899849279 Test RE 0.25288126175337733\n",
      "18 Train Loss 96518.15 Test MSE 15092.639780188923 Test RE 0.21778199185097985\n",
      "19 Train Loss 90303.0 Test MSE 12503.223682156366 Test RE 0.19822131940995757\n",
      "20 Train Loss 85563.07 Test MSE 11478.000223246325 Test RE 0.189920776230843\n",
      "21 Train Loss 78453.914 Test MSE 11100.1867291539 Test RE 0.18676887572593726\n",
      "22 Train Loss 73880.14 Test MSE 10112.818754450687 Test RE 0.17826885458850444\n",
      "23 Train Loss 65066.42 Test MSE 7516.752642795237 Test RE 0.15369314290851321\n",
      "24 Train Loss 62596.176 Test MSE 6492.466150620579 Test RE 0.14283814754425164\n",
      "25 Train Loss 58060.383 Test MSE 6923.635857748255 Test RE 0.147504908138322\n",
      "26 Train Loss 56755.26 Test MSE 7599.172064495713 Test RE 0.15453345029529916\n",
      "27 Train Loss 52349.406 Test MSE 6475.23680488875 Test RE 0.14264849366989524\n",
      "28 Train Loss 49827.695 Test MSE 6394.28839743557 Test RE 0.14175404883841666\n",
      "29 Train Loss 47284.277 Test MSE 6572.149578138494 Test RE 0.1437120160152357\n",
      "30 Train Loss 46285.75 Test MSE 5509.093762078984 Test RE 0.13157683762407707\n",
      "31 Train Loss 45287.62 Test MSE 5139.462370300371 Test RE 0.1270861454094341\n",
      "32 Train Loss 42977.684 Test MSE 5007.436905077396 Test RE 0.12544319449901198\n",
      "33 Train Loss 41174.844 Test MSE 5589.058412596237 Test RE 0.13252831811622082\n",
      "34 Train Loss 40811.477 Test MSE 6414.223270499307 Test RE 0.14197484353438966\n",
      "35 Train Loss 39482.18 Test MSE 6035.121927674685 Test RE 0.13771536150967276\n",
      "36 Train Loss 38640.67 Test MSE 5628.033479022597 Test RE 0.1329896056786266\n",
      "37 Train Loss 36853.305 Test MSE 5531.604509944935 Test RE 0.13184538211226787\n",
      "38 Train Loss 36137.645 Test MSE 5232.284540935395 Test RE 0.12822864085461097\n",
      "39 Train Loss 35316.125 Test MSE 5148.4706563747 Test RE 0.12719747292347816\n",
      "40 Train Loss 34362.645 Test MSE 4705.130191857356 Test RE 0.1215976507964852\n",
      "41 Train Loss 33665.586 Test MSE 4912.438521861788 Test RE 0.12424757648964832\n",
      "42 Train Loss 32762.188 Test MSE 4493.426209334484 Test RE 0.11883056697460205\n",
      "43 Train Loss 32461.51 Test MSE 4123.190044695213 Test RE 0.11382981722563155\n",
      "44 Train Loss 32057.174 Test MSE 4164.972930798068 Test RE 0.11440511810512517\n",
      "45 Train Loss 31278.602 Test MSE 4304.579275064948 Test RE 0.11630669567375045\n",
      "46 Train Loss 30788.678 Test MSE 4188.878846328574 Test RE 0.11473297687639246\n",
      "47 Train Loss 30522.137 Test MSE 4153.7995410883295 Test RE 0.11425155751025944\n",
      "48 Train Loss 30466.896 Test MSE 4139.4156325746035 Test RE 0.11405356900676886\n",
      "49 Train Loss 30369.912 Test MSE 4048.490239343334 Test RE 0.1127939772016527\n",
      "50 Train Loss 30305.367 Test MSE 3919.520114270322 Test RE 0.1109828341072897\n",
      "51 Train Loss 30093.145 Test MSE 3848.6335012218706 Test RE 0.10997466308885975\n",
      "52 Train Loss 29772.355 Test MSE 4116.531051338487 Test RE 0.11373786193409327\n",
      "53 Train Loss 29536.166 Test MSE 4132.72834489468 Test RE 0.11396140414756845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 Train Loss 29410.867 Test MSE 4090.44502010079 Test RE 0.11337691667717148\n",
      "55 Train Loss 29311.436 Test MSE 4033.7456891010256 Test RE 0.11258839272777954\n",
      "56 Train Loss 29285.5 Test MSE 4012.041205150846 Test RE 0.11228508047047292\n",
      "57 Train Loss 29218.902 Test MSE 3906.7781548188227 Test RE 0.1108022903279679\n",
      "58 Train Loss 29105.877 Test MSE 3828.916180472127 Test RE 0.10969259022621747\n",
      "59 Train Loss 28895.496 Test MSE 3886.9754878158224 Test RE 0.11052111639061504\n",
      "60 Train Loss 28582.885 Test MSE 3939.926024448696 Test RE 0.1112713599578405\n",
      "61 Train Loss 28460.498 Test MSE 3913.777263105258 Test RE 0.11090149869966989\n",
      "62 Train Loss 28389.248 Test MSE 3939.72740402426 Test RE 0.1112685552042551\n",
      "63 Train Loss 28360.326 Test MSE 3930.9896741347006 Test RE 0.11114509815413631\n",
      "64 Train Loss 28344.865 Test MSE 3926.8455669243253 Test RE 0.1110864973058808\n",
      "65 Train Loss 28268.586 Test MSE 3968.0901558025344 Test RE 0.1116683573367879\n",
      "66 Train Loss 28059.781 Test MSE 3952.2239088334245 Test RE 0.11144488303410553\n",
      "67 Train Loss 27904.674 Test MSE 3817.867019303418 Test RE 0.10953420509909227\n",
      "68 Train Loss 27544.957 Test MSE 3501.7273862261477 Test RE 0.10490121746204316\n",
      "69 Train Loss 26763.697 Test MSE 3485.923633030291 Test RE 0.10466423332468887\n",
      "70 Train Loss 26104.738 Test MSE 3667.4414628006402 Test RE 0.10735467401648745\n",
      "71 Train Loss 25444.176 Test MSE 3286.7446209040327 Test RE 0.10163009759311536\n",
      "72 Train Loss 25283.762 Test MSE 3220.248236040605 Test RE 0.1005967702915804\n",
      "73 Train Loss 24832.066 Test MSE 3319.6632966609236 Test RE 0.10213777212316016\n",
      "74 Train Loss 24230.975 Test MSE 3484.6847590175166 Test RE 0.10464563318667357\n",
      "75 Train Loss 23962.053 Test MSE 3570.2825829062476 Test RE 0.10592309396944448\n",
      "76 Train Loss 23692.65 Test MSE 3369.356120374533 Test RE 0.10289939469710149\n",
      "77 Train Loss 23557.473 Test MSE 3323.601096063272 Test RE 0.10219833230961556\n",
      "78 Train Loss 23305.37 Test MSE 3550.785088593142 Test RE 0.1056334723235692\n",
      "79 Train Loss 22756.541 Test MSE 3308.3621194666603 Test RE 0.10196376936836897\n",
      "80 Train Loss 22520.555 Test MSE 3221.7357380959184 Test RE 0.1006200015171485\n",
      "81 Train Loss 22419.438 Test MSE 3151.9018541904547 Test RE 0.09952351474829442\n",
      "82 Train Loss 22263.773 Test MSE 3095.544663099585 Test RE 0.09862974253657794\n",
      "83 Train Loss 22154.344 Test MSE 2917.5018117577765 Test RE 0.095751355203205\n",
      "84 Train Loss 21850.152 Test MSE 2673.0932476410117 Test RE 0.09165294338027911\n",
      "85 Train Loss 21561.016 Test MSE 2466.814773996601 Test RE 0.08804559497881252\n",
      "86 Train Loss 21420.732 Test MSE 2321.760473200072 Test RE 0.08541773847596892\n",
      "87 Train Loss 21391.693 Test MSE 2268.3534918763153 Test RE 0.08442959954253806\n",
      "88 Train Loss 21369.02 Test MSE 2174.026716081277 Test RE 0.08265550822162053\n",
      "89 Train Loss 21350.447 Test MSE 2097.5638304311733 Test RE 0.08118895564682833\n",
      "90 Train Loss 21325.834 Test MSE 2100.927839368917 Test RE 0.08125403375092986\n",
      "91 Train Loss 21306.492 Test MSE 2135.206666966919 Test RE 0.08191422385209662\n",
      "92 Train Loss 21299.223 Test MSE 2155.5089472910795 Test RE 0.08230273683345903\n",
      "93 Train Loss 21238.07 Test MSE 2181.4881908252555 Test RE 0.08279722766723095\n",
      "94 Train Loss 21194.537 Test MSE 2127.9427767837756 Test RE 0.08177477064281077\n",
      "95 Train Loss 21153.33 Test MSE 2140.090030252415 Test RE 0.08200784206343532\n",
      "96 Train Loss 21139.494 Test MSE 2168.0276121887287 Test RE 0.08254138783755735\n",
      "97 Train Loss 21130.018 Test MSE 2182.6078189387986 Test RE 0.08281847238738167\n",
      "98 Train Loss 21105.662 Test MSE 2270.1799963432595 Test RE 0.08446358454765795\n",
      "99 Train Loss 21094.713 Test MSE 2298.2261703433705 Test RE 0.0849837214656433\n",
      "Training time: 249.93\n",
      "3D_HTTP_swish_tune1\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 245042.86 Test MSE 86162.00177079483 Test RE 0.5203520289665363\n",
      "1 Train Loss 234161.44 Test MSE 81302.61025863727 Test RE 0.5054656025227695\n",
      "2 Train Loss 209958.94 Test MSE 64841.336847699975 Test RE 0.45140393676449064\n",
      "3 Train Loss 198313.34 Test MSE 59390.78220820958 Test RE 0.43201505827501224\n",
      "4 Train Loss 191637.86 Test MSE 54383.207761909645 Test RE 0.413401237665699\n",
      "5 Train Loss 188467.53 Test MSE 51113.55019964491 Test RE 0.40078124092028156\n",
      "6 Train Loss 184395.22 Test MSE 49268.535835489274 Test RE 0.39348138397530086\n",
      "7 Train Loss 179539.75 Test MSE 46662.88813129295 Test RE 0.382935094765409\n",
      "8 Train Loss 178151.62 Test MSE 46204.83742532846 Test RE 0.3810509822378074\n",
      "9 Train Loss 174512.88 Test MSE 44761.29352281696 Test RE 0.3750513010764862\n",
      "10 Train Loss 170451.45 Test MSE 41992.92348824107 Test RE 0.36326822973626083\n",
      "11 Train Loss 162145.88 Test MSE 40803.841438840616 Test RE 0.3580880992356905\n",
      "12 Train Loss 156540.36 Test MSE 37954.21273281728 Test RE 0.3453578690492732\n",
      "13 Train Loss 149403.98 Test MSE 32900.5661031763 Test RE 0.3215444719772369\n",
      "14 Train Loss 143859.36 Test MSE 31000.679679051456 Test RE 0.3121224232686768\n",
      "15 Train Loss 139507.6 Test MSE 29398.588752066596 Test RE 0.3039503191530421\n",
      "16 Train Loss 132523.16 Test MSE 25316.10607182848 Test RE 0.28205760604726554\n",
      "17 Train Loss 124093.29 Test MSE 25932.127939475406 Test RE 0.2854686623312708\n",
      "18 Train Loss 117113.62 Test MSE 22803.681977700537 Test RE 0.2676959803784663\n",
      "19 Train Loss 109716.89 Test MSE 20642.41381755094 Test RE 0.2546945208496417\n",
      "20 Train Loss 99509.29 Test MSE 16967.24024924249 Test RE 0.23091118332321955\n",
      "21 Train Loss 93484.04 Test MSE 14897.71921375515 Test RE 0.21637110076313126\n",
      "22 Train Loss 88245.01 Test MSE 13238.861011095194 Test RE 0.20396923806188064\n",
      "23 Train Loss 79442.32 Test MSE 10506.771616203096 Test RE 0.181707983272253\n",
      "24 Train Loss 75965.5 Test MSE 9974.52957148584 Test RE 0.177045777466049\n",
      "25 Train Loss 71457.96 Test MSE 10080.736549229641 Test RE 0.17798585727037128\n",
      "26 Train Loss 64303.44 Test MSE 8726.461456096697 Test RE 0.165599282055456\n",
      "27 Train Loss 59304.61 Test MSE 8608.689050791789 Test RE 0.16447802133945708\n",
      "28 Train Loss 56520.992 Test MSE 8398.993004112153 Test RE 0.1624624401526823\n",
      "29 Train Loss 51289.914 Test MSE 7526.1525678504195 Test RE 0.15378921183044042\n",
      "30 Train Loss 47056.61 Test MSE 5621.957020959793 Test RE 0.13291779338345897\n",
      "31 Train Loss 45522.195 Test MSE 4964.734775737914 Test RE 0.12490717570400235\n",
      "32 Train Loss 44935.105 Test MSE 4588.9494398477245 Test RE 0.12008700086087985\n",
      "33 Train Loss 43368.598 Test MSE 4839.158508380505 Test RE 0.12331737914086291\n",
      "34 Train Loss 42723.9 Test MSE 4907.269624514063 Test RE 0.12418219226220462\n",
      "35 Train Loss 41906.844 Test MSE 4525.615767527655 Test RE 0.11925544069315791\n",
      "36 Train Loss 41682.332 Test MSE 4323.449676947795 Test RE 0.11656134936551399\n",
      "37 Train Loss 41375.047 Test MSE 4414.938656072705 Test RE 0.11778817665120533\n",
      "38 Train Loss 40311.84 Test MSE 4419.542561036982 Test RE 0.11784957549647297\n",
      "39 Train Loss 39378.426 Test MSE 4545.189848589579 Test RE 0.11951306276557491\n",
      "40 Train Loss 38502.56 Test MSE 4658.226885704456 Test RE 0.12099005691711649\n",
      "41 Train Loss 37846.49 Test MSE 4473.102832793366 Test RE 0.11856153225702072\n",
      "42 Train Loss 37622.07 Test MSE 4519.795594316254 Test RE 0.11917873172597455\n",
      "43 Train Loss 36959.684 Test MSE 4585.127966103909 Test RE 0.12003698888031458\n",
      "44 Train Loss 36290.816 Test MSE 4318.800207999451 Test RE 0.1164986570483653\n",
      "45 Train Loss 35782.2 Test MSE 4298.14796492066 Test RE 0.11621977846487162\n",
      "46 Train Loss 35270.17 Test MSE 4230.393356411337 Test RE 0.1153001143261625\n",
      "47 Train Loss 34918.125 Test MSE 4309.375061056505 Test RE 0.11637146701546502\n",
      "48 Train Loss 34395.16 Test MSE 4473.146302148356 Test RE 0.11856210834268265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 Train Loss 34042.223 Test MSE 4369.092039399976 Test RE 0.1171749991481877\n",
      "50 Train Loss 33813.613 Test MSE 4435.123585933687 Test RE 0.11805713109783694\n",
      "51 Train Loss 33727.79 Test MSE 4554.391055977286 Test RE 0.1196339717418345\n",
      "52 Train Loss 33519.21 Test MSE 4632.501950940479 Test RE 0.12065551220455001\n",
      "53 Train Loss 33294.06 Test MSE 4617.304159488615 Test RE 0.12045743309411669\n",
      "54 Train Loss 32705.64 Test MSE 4439.895773287676 Test RE 0.11812062868327146\n",
      "55 Train Loss 32568.035 Test MSE 4376.430128706249 Test RE 0.11727335824293252\n",
      "56 Train Loss 32488.635 Test MSE 4415.108043692522 Test RE 0.11779043621459571\n",
      "57 Train Loss 32369.322 Test MSE 4450.833270937462 Test RE 0.1182660318053837\n",
      "58 Train Loss 32242.66 Test MSE 4469.29589541627 Test RE 0.11851106925396634\n",
      "59 Train Loss 32198.258 Test MSE 4570.732821874363 Test RE 0.11984841092228944\n",
      "60 Train Loss 32048.512 Test MSE 4668.2653432513 Test RE 0.1211203532664043\n",
      "61 Train Loss 31856.58 Test MSE 4608.2809801206095 Test RE 0.12033967600914745\n",
      "62 Train Loss 31651.834 Test MSE 4611.563812950082 Test RE 0.12038253197960855\n",
      "63 Train Loss 31567.148 Test MSE 4593.876876568085 Test RE 0.12015145595554141\n",
      "64 Train Loss 31509.246 Test MSE 4543.492357952968 Test RE 0.11949074342832412\n",
      "65 Train Loss 31401.047 Test MSE 4526.762044537702 Test RE 0.1192705426286799\n",
      "66 Train Loss 31346.281 Test MSE 4514.8661126315355 Test RE 0.11911372329410662\n",
      "67 Train Loss 31316.898 Test MSE 4492.75391883832 Test RE 0.11882167713803896\n",
      "68 Train Loss 31238.83 Test MSE 4469.5007196910465 Test RE 0.11851378485685696\n",
      "69 Train Loss 31186.953 Test MSE 4486.844659008161 Test RE 0.11874350913575524\n",
      "70 Train Loss 31102.291 Test MSE 4488.584817539634 Test RE 0.11876653338945667\n",
      "71 Train Loss 31060.768 Test MSE 4504.436958241796 Test RE 0.11897606986224246\n",
      "72 Train Loss 31036.521 Test MSE 4516.4093374356435 Test RE 0.11913407866485262\n",
      "73 Train Loss 30985.043 Test MSE 4568.842372820415 Test RE 0.1198236237868664\n",
      "74 Train Loss 30954.79 Test MSE 4588.909931954379 Test RE 0.12008648392397567\n",
      "75 Train Loss 30934.13 Test MSE 4580.402186653412 Test RE 0.1199751133359105\n",
      "76 Train Loss 30898.713 Test MSE 4587.256447600678 Test RE 0.12006484708484579\n",
      "77 Train Loss 30878.514 Test MSE 4591.926516488177 Test RE 0.12012594770974941\n",
      "78 Train Loss 30856.535 Test MSE 4594.257670748079 Test RE 0.12015643563047386\n",
      "79 Train Loss 30831.678 Test MSE 4590.135114598535 Test RE 0.12010251366296155\n",
      "80 Train Loss 30814.123 Test MSE 4584.259696810775 Test RE 0.12002562285445065\n",
      "81 Train Loss 30777.68 Test MSE 4588.5660900464145 Test RE 0.12008198486648032\n",
      "82 Train Loss 30717.004 Test MSE 4570.400167961697 Test RE 0.11984404961199296\n",
      "83 Train Loss 30670.594 Test MSE 4543.486533022673 Test RE 0.11949066683245693\n",
      "84 Train Loss 30604.096 Test MSE 4544.769414362388 Test RE 0.11950753510381679\n",
      "85 Train Loss 30495.533 Test MSE 4516.395642282064 Test RE 0.11913389803898163\n",
      "86 Train Loss 30464.441 Test MSE 4534.383191592881 Test RE 0.1193709009061874\n",
      "87 Train Loss 30438.0 Test MSE 4567.1267326688285 Test RE 0.11980112426667579\n",
      "88 Train Loss 30401.64 Test MSE 4552.687201051385 Test RE 0.1196115913623507\n",
      "89 Train Loss 30348.178 Test MSE 4567.728224178478 Test RE 0.11980901292303556\n",
      "90 Train Loss 30314.148 Test MSE 4538.047149742031 Test RE 0.11941911933517262\n",
      "91 Train Loss 30277.574 Test MSE 4546.122163229552 Test RE 0.1195253194664541\n",
      "92 Train Loss 30229.088 Test MSE 4560.545660789957 Test RE 0.1197147785090058\n",
      "93 Train Loss 30195.32 Test MSE 4571.052337012224 Test RE 0.1198525998252327\n",
      "94 Train Loss 30177.266 Test MSE 4576.97489272391 Test RE 0.11993021914233716\n",
      "95 Train Loss 30170.352 Test MSE 4565.990556428076 Test RE 0.11978622171793318\n",
      "96 Train Loss 30166.21 Test MSE 4555.346676640899 Test RE 0.11964652212427572\n",
      "97 Train Loss 30155.803 Test MSE 4534.052971186009 Test RE 0.11936655418211252\n",
      "98 Train Loss 30125.572 Test MSE 4505.770462392373 Test RE 0.11899367953732867\n",
      "99 Train Loss 30090.172 Test MSE 4510.490926993682 Test RE 0.11905599500770586\n",
      "Training time: 267.83\n",
      "3D_HTTP_swish_tune1\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 243878.36 Test MSE 87355.18020577193 Test RE 0.5239425798354818\n",
      "1 Train Loss 241943.95 Test MSE 87875.98891208976 Test RE 0.525502123002962\n",
      "2 Train Loss 239188.48 Test MSE 85748.50238325435 Test RE 0.5191019186416707\n",
      "3 Train Loss 220556.11 Test MSE 74491.55543924558 Test RE 0.4838301004718168\n",
      "4 Train Loss 207140.66 Test MSE 64535.30622021199 Test RE 0.45033743489339084\n",
      "5 Train Loss 189861.64 Test MSE 55135.20804666519 Test RE 0.4162496401273796\n",
      "6 Train Loss 186349.64 Test MSE 52853.63147761652 Test RE 0.40754613453974753\n",
      "7 Train Loss 180657.94 Test MSE 49199.16920003713 Test RE 0.39320428934276597\n",
      "8 Train Loss 175421.4 Test MSE 47182.209961815635 Test RE 0.3850600843696695\n",
      "9 Train Loss 170317.25 Test MSE 43333.896820775124 Test RE 0.3690228296367426\n",
      "10 Train Loss 167503.56 Test MSE 42593.509651785214 Test RE 0.36585675297261433\n",
      "11 Train Loss 164484.72 Test MSE 41195.39231369013 Test RE 0.35980209168264204\n",
      "12 Train Loss 158624.56 Test MSE 38277.45304663504 Test RE 0.3468253860976722\n",
      "13 Train Loss 150919.27 Test MSE 33309.41418298757 Test RE 0.32353618456209204\n",
      "14 Train Loss 146728.75 Test MSE 31494.046252379572 Test RE 0.31459628706878023\n",
      "15 Train Loss 138970.28 Test MSE 29628.257014452054 Test RE 0.3051352728566907\n",
      "16 Train Loss 129827.15 Test MSE 26515.569608191447 Test RE 0.2886621505006248\n",
      "17 Train Loss 123464.984 Test MSE 23326.76023628835 Test RE 0.270748821513995\n",
      "18 Train Loss 118265.54 Test MSE 19809.45942336096 Test RE 0.24950294396131584\n",
      "19 Train Loss 112125.41 Test MSE 19196.462522185073 Test RE 0.24561221678422548\n",
      "20 Train Loss 105067.67 Test MSE 19097.027516837683 Test RE 0.2449752723351375\n",
      "21 Train Loss 99857.484 Test MSE 17846.073810186685 Test RE 0.23681581643140556\n",
      "22 Train Loss 95018.01 Test MSE 17178.039400965044 Test RE 0.23234116329688168\n",
      "23 Train Loss 89748.34 Test MSE 14271.300826203522 Test RE 0.21177326998211973\n",
      "24 Train Loss 83565.555 Test MSE 12510.005462305917 Test RE 0.1982750699948365\n",
      "25 Train Loss 78372.96 Test MSE 11436.37336957714 Test RE 0.1895760739674273\n",
      "26 Train Loss 76170.875 Test MSE 11182.78334437453 Test RE 0.18746246253063253\n",
      "27 Train Loss 71000.17 Test MSE 9536.818905258733 Test RE 0.17311756312068524\n",
      "28 Train Loss 65667.266 Test MSE 8643.353684599926 Test RE 0.16480884071508495\n",
      "29 Train Loss 62373.766 Test MSE 7815.189915276555 Test RE 0.15671448155868262\n",
      "30 Train Loss 60412.508 Test MSE 7355.562404758737 Test RE 0.15203630436207052\n",
      "31 Train Loss 56856.2 Test MSE 6733.365263893864 Test RE 0.14546397440697648\n",
      "32 Train Loss 52095.617 Test MSE 5844.298358227292 Test RE 0.13552067363159379\n",
      "33 Train Loss 50531.414 Test MSE 5468.192512193849 Test RE 0.13108749369742626\n",
      "34 Train Loss 48838.285 Test MSE 4996.560627073668 Test RE 0.12530688756775074\n",
      "35 Train Loss 47926.37 Test MSE 4854.163329598218 Test RE 0.12350841680682588\n",
      "36 Train Loss 47622.99 Test MSE 4847.3758549294735 Test RE 0.12342203698743394\n",
      "37 Train Loss 46874.957 Test MSE 4809.498286667614 Test RE 0.12293887917811008\n",
      "38 Train Loss 46026.914 Test MSE 4704.958179791872 Test RE 0.12159542806795395\n",
      "39 Train Loss 45557.68 Test MSE 4667.024878840416 Test RE 0.1211042599791926\n",
      "40 Train Loss 44622.457 Test MSE 4529.205760942901 Test RE 0.11930273164742013\n",
      "41 Train Loss 44225.605 Test MSE 4616.020596350701 Test RE 0.12044068896569388\n",
      "42 Train Loss 43764.84 Test MSE 4818.969168466036 Test RE 0.12305986549331273\n",
      "43 Train Loss 43361.45 Test MSE 4811.539886695237 Test RE 0.12296496977776403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 Train Loss 43190.805 Test MSE 4616.738943967262 Test RE 0.12045006012363241\n",
      "45 Train Loss 43064.19 Test MSE 4573.046678489449 Test RE 0.11987874270517497\n",
      "46 Train Loss 42685.84 Test MSE 4484.69232508156 Test RE 0.11871502516094756\n",
      "47 Train Loss 42115.875 Test MSE 4381.928884026748 Test RE 0.11734700903288711\n",
      "48 Train Loss 40761.805 Test MSE 4476.414028866569 Test RE 0.1186054064837117\n",
      "49 Train Loss 40364.812 Test MSE 4540.2247892133855 Test RE 0.11944776828807184\n",
      "50 Train Loss 39685.16 Test MSE 4443.414862973001 Test RE 0.11816743099269424\n",
      "51 Train Loss 39026.047 Test MSE 4354.612662144223 Test RE 0.11698067627665099\n",
      "52 Train Loss 38753.617 Test MSE 4299.129210675572 Test RE 0.1162330439058509\n",
      "53 Train Loss 38666.723 Test MSE 4278.818890949978 Test RE 0.11595815974140951\n",
      "54 Train Loss 38382.258 Test MSE 4193.17877975471 Test RE 0.11479184914740906\n",
      "55 Train Loss 38055.617 Test MSE 4121.954849746353 Test RE 0.11381276579876916\n",
      "56 Train Loss 37790.85 Test MSE 4109.9252388412615 Test RE 0.1136465675118744\n",
      "57 Train Loss 37473.48 Test MSE 4047.5594527419353 Test RE 0.11278101024958291\n",
      "58 Train Loss 37118.863 Test MSE 4109.576056466748 Test RE 0.11364173965991708\n",
      "59 Train Loss 36951.414 Test MSE 4100.513650159846 Test RE 0.11351636954934739\n",
      "60 Train Loss 36240.996 Test MSE 4129.979671634078 Test RE 0.1139235000392114\n",
      "61 Train Loss 35568.043 Test MSE 4093.6331011448647 Test RE 0.1134210908923662\n",
      "62 Train Loss 35135.07 Test MSE 3998.5121984365296 Test RE 0.1120956023048835\n",
      "63 Train Loss 34866.246 Test MSE 3973.9989362496844 Test RE 0.11175146764068335\n",
      "64 Train Loss 34705.727 Test MSE 4025.247173993622 Test RE 0.11246972651286617\n",
      "65 Train Loss 34564.234 Test MSE 3997.1231701056136 Test RE 0.11207613037578212\n",
      "66 Train Loss 34438.043 Test MSE 3987.14624979761 Test RE 0.11193617056046616\n",
      "67 Train Loss 34214.06 Test MSE 3977.0735937825075 Test RE 0.1117946899795917\n",
      "68 Train Loss 33819.246 Test MSE 4030.3425354650526 Test RE 0.112540888934032\n",
      "69 Train Loss 33676.895 Test MSE 4048.379007651795 Test RE 0.1127924276917965\n",
      "70 Train Loss 33594.51 Test MSE 4059.441020804596 Test RE 0.11294642267967461\n",
      "71 Train Loss 33522.066 Test MSE 4074.1945884968427 Test RE 0.11315148187115677\n",
      "72 Train Loss 33375.71 Test MSE 4057.481886906427 Test RE 0.11291916475568975\n",
      "73 Train Loss 33192.207 Test MSE 3993.312659459913 Test RE 0.11202269580540221\n",
      "74 Train Loss 33081.223 Test MSE 3981.771389666282 Test RE 0.11186069751287372\n",
      "75 Train Loss 33016.83 Test MSE 3965.169535146628 Test RE 0.11162725432092283\n",
      "76 Train Loss 32963.4 Test MSE 3925.6897213333173 Test RE 0.11107014725012888\n",
      "77 Train Loss 32890.504 Test MSE 3929.447165556389 Test RE 0.11112328951264754\n",
      "78 Train Loss 32792.938 Test MSE 4010.268039389262 Test RE 0.11226026491480895\n",
      "79 Train Loss 32717.738 Test MSE 4039.747574121287 Test RE 0.11267212277228145\n",
      "80 Train Loss 32636.809 Test MSE 4048.6076138257904 Test RE 0.11279561226039796\n",
      "81 Train Loss 32618.426 Test MSE 4068.0186416897686 Test RE 0.1130656879126294\n",
      "82 Train Loss 32543.016 Test MSE 4108.755648546124 Test RE 0.11363039576025513\n",
      "83 Train Loss 32442.484 Test MSE 4096.216351166325 Test RE 0.11345687192352574\n",
      "84 Train Loss 32241.518 Test MSE 4172.586491917885 Test RE 0.11450963651095974\n",
      "85 Train Loss 32195.168 Test MSE 4212.060038562615 Test RE 0.11505000415559144\n",
      "86 Train Loss 32087.336 Test MSE 4237.964718069878 Test RE 0.11540324759725674\n",
      "87 Train Loss 32021.633 Test MSE 4254.907383673521 Test RE 0.11563369882582811\n",
      "88 Train Loss 31919.865 Test MSE 4331.829154284385 Test RE 0.11667425115208194\n",
      "89 Train Loss 31857.752 Test MSE 4317.07527743139 Test RE 0.11647538991929043\n",
      "90 Train Loss 31785.344 Test MSE 4355.031839381964 Test RE 0.11698630645096993\n",
      "91 Train Loss 31748.943 Test MSE 4372.068922467487 Test RE 0.11721491097328231\n",
      "92 Train Loss 31724.69 Test MSE 4410.0591362981 Test RE 0.1177230671811357\n",
      "93 Train Loss 31656.645 Test MSE 4412.765135737901 Test RE 0.1177591789080237\n",
      "94 Train Loss 31578.555 Test MSE 4376.619599735989 Test RE 0.11727589680322079\n",
      "95 Train Loss 31522.727 Test MSE 4332.162652033123 Test RE 0.1166787423092615\n",
      "96 Train Loss 31431.79 Test MSE 4287.345190561041 Test RE 0.11607363576305348\n",
      "97 Train Loss 31338.889 Test MSE 4272.773862896771 Test RE 0.1158762191287435\n",
      "98 Train Loss 31263.55 Test MSE 4225.7502106573365 Test RE 0.11523682207777552\n",
      "99 Train Loss 31179.23 Test MSE 4150.4575654138025 Test RE 0.11420558721806623\n",
      "Training time: 271.30\n",
      "3D_HTTP_swish_tune1\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 245874.88 Test MSE 86400.41122700255 Test RE 0.521071436270236\n",
      "1 Train Loss 243364.28 Test MSE 86415.80817782227 Test RE 0.5211178628656989\n",
      "2 Train Loss 231123.34 Test MSE 75005.41327501208 Test RE 0.4854960114716714\n",
      "3 Train Loss 209412.83 Test MSE 64643.21216076914 Test RE 0.4507137698905781\n",
      "4 Train Loss 195301.75 Test MSE 53898.84874533837 Test RE 0.4115561602556487\n",
      "5 Train Loss 187034.23 Test MSE 51427.02084701398 Test RE 0.40200832377114604\n",
      "6 Train Loss 174348.23 Test MSE 42550.256362559965 Test RE 0.3656709438255187\n",
      "7 Train Loss 160431.9 Test MSE 39108.71223797058 Test RE 0.3505711070954396\n",
      "8 Train Loss 152400.9 Test MSE 35701.49370789731 Test RE 0.33495198482274513\n",
      "9 Train Loss 141006.06 Test MSE 28840.524612083453 Test RE 0.3010516003448003\n",
      "10 Train Loss 113008.37 Test MSE 14018.306189870118 Test RE 0.2098877698685617\n",
      "11 Train Loss 97423.82 Test MSE 12360.004266483056 Test RE 0.19708277675115907\n",
      "12 Train Loss 82355.76 Test MSE 10144.998539405091 Test RE 0.17855226207210395\n",
      "13 Train Loss 72476.84 Test MSE 7455.018629987013 Test RE 0.1530607118305227\n",
      "14 Train Loss 65486.668 Test MSE 7104.495290981075 Test RE 0.14941905230973\n",
      "15 Train Loss 57415.984 Test MSE 8745.869006461482 Test RE 0.16578332523843525\n",
      "16 Train Loss 52406.83 Test MSE 7308.92524162622 Test RE 0.15155355290695688\n",
      "17 Train Loss 50090.2 Test MSE 5920.241609052823 Test RE 0.1363983377338203\n",
      "18 Train Loss 48889.06 Test MSE 5839.234482605173 Test RE 0.13546194899839029\n",
      "19 Train Loss 47505.9 Test MSE 6340.455449006265 Test RE 0.14115608021768816\n",
      "20 Train Loss 43719.89 Test MSE 5551.3573063699 Test RE 0.13208057555330838\n",
      "21 Train Loss 41545.664 Test MSE 4884.081203506251 Test RE 0.12388844451829617\n",
      "22 Train Loss 39873.164 Test MSE 4978.774721371885 Test RE 0.12508366568334306\n",
      "23 Train Loss 38383.867 Test MSE 4577.2584971459155 Test RE 0.11993393472024713\n",
      "24 Train Loss 37807.535 Test MSE 4468.848611971967 Test RE 0.11850513886058883\n",
      "25 Train Loss 36797.242 Test MSE 4375.361396044686 Test RE 0.1172590381787219\n",
      "26 Train Loss 36172.09 Test MSE 4379.087467849467 Test RE 0.11730895663989341\n",
      "27 Train Loss 35141.72 Test MSE 3873.0767619161893 Test RE 0.11032334329743816\n",
      "28 Train Loss 34445.32 Test MSE 3851.3337050431214 Test RE 0.11001323547278523\n",
      "29 Train Loss 34136.42 Test MSE 3645.2443744017646 Test RE 0.10702930033727874\n",
      "30 Train Loss 33904.066 Test MSE 3893.878520827966 Test RE 0.11061921226079095\n",
      "31 Train Loss 33549.586 Test MSE 3953.3414674992932 Test RE 0.1114606383903972\n",
      "32 Train Loss 33065.42 Test MSE 4059.6111929912317 Test RE 0.11294879001771403\n",
      "33 Train Loss 33022.582 Test MSE 4085.0647403594357 Test RE 0.11330232818564595\n",
      "34 Train Loss 32425.584 Test MSE 3904.6249423942672 Test RE 0.11077175189692016\n",
      "35 Train Loss 32207.262 Test MSE 3962.091477339645 Test RE 0.11158391924464527\n",
      "36 Train Loss 31873.719 Test MSE 3959.264341668674 Test RE 0.11154410199476152\n",
      "37 Train Loss 31620.324 Test MSE 3977.8480707366607 Test RE 0.11180557464066095\n",
      "38 Train Loss 31458.725 Test MSE 3865.4770829709273 Test RE 0.1102150529473121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Train Loss 31203.193 Test MSE 3964.345291248004 Test RE 0.11161565168143545\n",
      "40 Train Loss 31172.643 Test MSE 3957.3713433535654 Test RE 0.11151743314621126\n",
      "41 Train Loss 31013.584 Test MSE 3839.8567353501717 Test RE 0.10984919351735568\n",
      "42 Train Loss 30913.795 Test MSE 3890.0097168461034 Test RE 0.11056424516288801\n",
      "43 Train Loss 30773.732 Test MSE 3854.63216168142 Test RE 0.11006033554933996\n",
      "44 Train Loss 30739.223 Test MSE 3871.4772506291733 Test RE 0.11030056016318911\n",
      "45 Train Loss 30640.95 Test MSE 3849.6461412130966 Test RE 0.10998913022600221\n",
      "46 Train Loss 30422.223 Test MSE 3908.976860313735 Test RE 0.11083346529202755\n",
      "47 Train Loss 30350.238 Test MSE 3910.075266346446 Test RE 0.11084903606672605\n",
      "48 Train Loss 30012.555 Test MSE 3823.70038037443 Test RE 0.10961785241909462\n",
      "49 Train Loss 29737.297 Test MSE 3761.1459607009433 Test RE 0.1087174997365208\n",
      "50 Train Loss 29672.604 Test MSE 3758.372694246014 Test RE 0.10867741113098978\n",
      "51 Train Loss 29636.732 Test MSE 3742.1946518596224 Test RE 0.10844325608108434\n",
      "52 Train Loss 29569.984 Test MSE 3727.9120999254337 Test RE 0.10823611465080393\n",
      "53 Train Loss 29500.926 Test MSE 3668.78304365237 Test RE 0.10737430784125158\n",
      "54 Train Loss 28911.3 Test MSE 3559.7475334766896 Test RE 0.10576670166523564\n",
      "55 Train Loss 28656.7 Test MSE 3672.7746345752985 Test RE 0.10743270292682525\n",
      "56 Train Loss 28556.418 Test MSE 3755.511738292865 Test RE 0.10863603943847697\n",
      "57 Train Loss 28463.477 Test MSE 3795.5598366028853 Test RE 0.10921374093999951\n",
      "58 Train Loss 28351.293 Test MSE 3697.2173463935405 Test RE 0.10778959823713487\n",
      "59 Train Loss 28227.523 Test MSE 3731.478650530516 Test RE 0.10828787784745289\n",
      "60 Train Loss 28178.48 Test MSE 3679.164667931631 Test RE 0.10752612006834925\n",
      "61 Train Loss 28120.385 Test MSE 3729.3503279727033 Test RE 0.10825699137755428\n",
      "62 Train Loss 27947.93 Test MSE 3647.9966404351135 Test RE 0.1070696978382137\n",
      "63 Train Loss 27793.11 Test MSE 3706.5185152176286 Test RE 0.10792509737100708\n",
      "64 Train Loss 27716.062 Test MSE 3648.7921857893234 Test RE 0.1070813719385079\n",
      "65 Train Loss 27642.852 Test MSE 3559.786006439676 Test RE 0.10576727321523538\n",
      "66 Train Loss 27606.605 Test MSE 3597.3295923471437 Test RE 0.10632355212316096\n",
      "67 Train Loss 27501.398 Test MSE 3486.7177313748252 Test RE 0.10467615397619316\n",
      "68 Train Loss 27293.875 Test MSE 3613.748653704329 Test RE 0.10656591877736854\n",
      "69 Train Loss 27224.951 Test MSE 3596.055530743557 Test RE 0.10630472221779207\n",
      "70 Train Loss 27102.37 Test MSE 3648.8847334763395 Test RE 0.10708272993177687\n",
      "71 Train Loss 26918.834 Test MSE 3653.241919095606 Test RE 0.10714664536907242\n",
      "72 Train Loss 26668.79 Test MSE 3456.9087307817413 Test RE 0.10422773951935299\n",
      "73 Train Loss 26574.299 Test MSE 3326.707195421143 Test RE 0.10224607631283623\n",
      "74 Train Loss 26502.281 Test MSE 3318.654641156006 Test RE 0.10212225403537509\n",
      "75 Train Loss 26366.805 Test MSE 3235.6299472209816 Test RE 0.1008367373685702\n",
      "76 Train Loss 26212.262 Test MSE 3271.2017163403525 Test RE 0.10138951017007652\n",
      "77 Train Loss 26050.61 Test MSE 3327.853496374379 Test RE 0.10226369052910639\n",
      "78 Train Loss 25899.24 Test MSE 3040.202778628899 Test RE 0.09774411933268122\n",
      "79 Train Loss 25817.22 Test MSE 3025.7235274578316 Test RE 0.09751108376543925\n",
      "80 Train Loss 25767.254 Test MSE 3024.5388133463866 Test RE 0.09749199179185292\n",
      "81 Train Loss 25748.613 Test MSE 3012.296144135027 Test RE 0.09729447862535923\n",
      "82 Train Loss 25729.014 Test MSE 2963.62788330354 Test RE 0.09650530737000275\n",
      "83 Train Loss 25713.043 Test MSE 2926.8213974848663 Test RE 0.09590416598482357\n",
      "84 Train Loss 25653.436 Test MSE 2901.376374991972 Test RE 0.0954863730437761\n",
      "85 Train Loss 25597.36 Test MSE 2977.192633334455 Test RE 0.096725911290648\n",
      "86 Train Loss 25540.994 Test MSE 2924.84694492928 Test RE 0.09587181174343924\n",
      "87 Train Loss 25443.076 Test MSE 3082.268689373293 Test RE 0.09841801682174527\n",
      "88 Train Loss 25315.662 Test MSE 2963.757647121447 Test RE 0.09650742011164046\n",
      "89 Train Loss 25230.576 Test MSE 2986.7548369592064 Test RE 0.09688111982104487\n",
      "90 Train Loss 25167.2 Test MSE 2964.184231879946 Test RE 0.09651436519928296\n",
      "91 Train Loss 25009.678 Test MSE 3039.2847934729866 Test RE 0.09772936136561984\n",
      "92 Train Loss 24843.426 Test MSE 3161.8641106560267 Test RE 0.09968067328540611\n",
      "93 Train Loss 24750.625 Test MSE 2917.622401708723 Test RE 0.09575333404206426\n",
      "94 Train Loss 24681.377 Test MSE 2926.4431203809945 Test RE 0.09589796821640764\n",
      "95 Train Loss 24591.414 Test MSE 2894.2784146779463 Test RE 0.09536950204436266\n",
      "96 Train Loss 24327.85 Test MSE 2805.3676388515278 Test RE 0.09389322443759189\n",
      "97 Train Loss 24142.334 Test MSE 2781.7273754924254 Test RE 0.0934967779101195\n",
      "98 Train Loss 24061.646 Test MSE 2791.567173711965 Test RE 0.09366199490864752\n",
      "99 Train Loss 23943.48 Test MSE 2833.767157190385 Test RE 0.09436728134355403\n",
      "Training time: 271.29\n",
      "3D_HTTP_swish_tune1\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 246660.11 Test MSE 87696.09494072771 Test RE 0.5249639606680865\n",
      "1 Train Loss 230998.28 Test MSE 76427.94635297135 Test RE 0.49007828225833916\n",
      "2 Train Loss 201706.52 Test MSE 59269.56254416921 Test RE 0.43157395051889735\n",
      "3 Train Loss 192279.83 Test MSE 53280.21226395273 Test RE 0.40918747843936265\n",
      "4 Train Loss 186628.64 Test MSE 49146.92798193932 Test RE 0.39299547558471026\n",
      "5 Train Loss 177994.17 Test MSE 46582.07977363636 Test RE 0.3826033775710256\n",
      "6 Train Loss 170840.38 Test MSE 43561.05843358065 Test RE 0.36998879687435876\n",
      "7 Train Loss 166930.92 Test MSE 41128.33650046531 Test RE 0.3595091384345777\n",
      "8 Train Loss 164981.88 Test MSE 38649.15776011861 Test RE 0.3485052937201399\n",
      "9 Train Loss 160203.06 Test MSE 36939.69899357559 Test RE 0.3407109083229417\n",
      "10 Train Loss 156183.17 Test MSE 36857.70487264306 Test RE 0.3403325645385917\n",
      "11 Train Loss 147157.31 Test MSE 33224.24666843199 Test RE 0.32312230143981174\n",
      "12 Train Loss 141893.08 Test MSE 31900.63164657468 Test RE 0.31662048031278694\n",
      "13 Train Loss 137337.22 Test MSE 29255.37153107007 Test RE 0.3032090579672469\n",
      "14 Train Loss 133781.61 Test MSE 27423.338878074774 Test RE 0.2935617901655032\n",
      "15 Train Loss 126455.92 Test MSE 23704.57265297183 Test RE 0.27293260939218683\n",
      "16 Train Loss 122871.195 Test MSE 22500.81781271264 Test RE 0.26591235348860115\n",
      "17 Train Loss 113937.68 Test MSE 20178.078105150224 Test RE 0.2518136462210762\n",
      "18 Train Loss 108524.375 Test MSE 17462.772201592725 Test RE 0.23425882282536736\n",
      "19 Train Loss 100607.54 Test MSE 15398.558550638048 Test RE 0.21997807463739236\n",
      "20 Train Loss 95139.5 Test MSE 14718.23812278189 Test RE 0.2150637799631689\n",
      "21 Train Loss 91000.12 Test MSE 14250.55191824285 Test RE 0.21161926641843107\n",
      "22 Train Loss 84593.31 Test MSE 12560.812528888813 Test RE 0.19867729073082505\n",
      "23 Train Loss 79396.88 Test MSE 10092.084919009074 Test RE 0.17808601270907992\n",
      "24 Train Loss 77426.44 Test MSE 9030.568002537022 Test RE 0.16846003859920408\n",
      "25 Train Loss 74479.94 Test MSE 8661.844609508593 Test RE 0.1649850361983822\n",
      "26 Train Loss 70540.836 Test MSE 8332.267400836106 Test RE 0.16181581378873547\n",
      "27 Train Loss 62814.32 Test MSE 8565.0701492126 Test RE 0.16406079976766633\n",
      "28 Train Loss 60450.035 Test MSE 8318.190431177294 Test RE 0.1616790659447282\n",
      "29 Train Loss 59403.047 Test MSE 7623.481697671894 Test RE 0.15478042798489033\n",
      "30 Train Loss 58860.926 Test MSE 7338.728074334351 Test RE 0.15186222552670386\n",
      "31 Train Loss 57983.617 Test MSE 7418.000535288001 Test RE 0.15268022538155182\n",
      "32 Train Loss 56493.688 Test MSE 6950.153413783016 Test RE 0.14778711041366688\n",
      "33 Train Loss 53113.402 Test MSE 6574.279312895003 Test RE 0.1437352993930785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Train Loss 49572.082 Test MSE 6415.0438030989835 Test RE 0.1419839242334202\n",
      "35 Train Loss 47744.94 Test MSE 6296.694364356305 Test RE 0.1406681153824447\n",
      "36 Train Loss 46066.273 Test MSE 5597.884871425845 Test RE 0.13263292377522798\n",
      "37 Train Loss 45600.297 Test MSE 5397.784799658699 Test RE 0.1302408269924283\n",
      "38 Train Loss 44929.984 Test MSE 5110.762607701537 Test RE 0.12673081171162\n",
      "39 Train Loss 43753.89 Test MSE 4910.0208656683935 Test RE 0.1242169985099395\n",
      "40 Train Loss 43184.848 Test MSE 5069.383306179886 Test RE 0.1262167308744989\n",
      "41 Train Loss 41769.73 Test MSE 5374.001917696588 Test RE 0.12995358678178107\n",
      "42 Train Loss 40228.594 Test MSE 4967.363464753133 Test RE 0.12494023876628273\n",
      "43 Train Loss 38852.85 Test MSE 4961.274199598951 Test RE 0.12486363600241569\n",
      "44 Train Loss 38280.38 Test MSE 5251.181570946216 Test RE 0.12845998879938617\n",
      "45 Train Loss 38048.36 Test MSE 4962.531316873851 Test RE 0.12487945434719806\n",
      "46 Train Loss 37651.137 Test MSE 4720.841922564145 Test RE 0.12180050567972506\n",
      "47 Train Loss 36704.938 Test MSE 4477.92941696545 Test RE 0.11862548036558633\n",
      "48 Train Loss 36182.613 Test MSE 4769.576365669302 Test RE 0.12242758015937405\n",
      "49 Train Loss 36015.35 Test MSE 4750.988871037354 Test RE 0.12218879130014704\n",
      "50 Train Loss 35361.875 Test MSE 4630.271736454594 Test RE 0.12062646525882505\n",
      "51 Train Loss 35018.297 Test MSE 4965.168429655884 Test RE 0.12491263070873142\n",
      "52 Train Loss 34806.527 Test MSE 4899.695995121284 Test RE 0.12408632703190266\n",
      "53 Train Loss 34215.805 Test MSE 4740.525592555542 Test RE 0.12205416669029716\n",
      "54 Train Loss 33696.004 Test MSE 4690.31780299314 Test RE 0.12140609695861543\n",
      "55 Train Loss 33379.625 Test MSE 4542.066888869355 Test RE 0.11947199752660201\n",
      "56 Train Loss 33250.63 Test MSE 4561.966029907645 Test RE 0.11973341947321021\n",
      "57 Train Loss 32965.473 Test MSE 4545.909611737012 Test RE 0.11952252526283438\n",
      "58 Train Loss 32691.955 Test MSE 4447.211861718525 Test RE 0.11821790858592597\n",
      "59 Train Loss 32631.146 Test MSE 4388.010084748304 Test RE 0.11742840735323082\n",
      "60 Train Loss 32431.273 Test MSE 4244.097068888782 Test RE 0.11548671188062706\n",
      "61 Train Loss 32144.578 Test MSE 4311.156990426923 Test RE 0.11639552436716685\n",
      "62 Train Loss 31805.072 Test MSE 4466.059998892702 Test RE 0.11846815880392701\n",
      "63 Train Loss 31523.043 Test MSE 4488.8854159913 Test RE 0.11877051019281426\n",
      "64 Train Loss 31437.217 Test MSE 4502.868920650652 Test RE 0.11895535970575838\n",
      "65 Train Loss 31380.643 Test MSE 4509.3579030385445 Test RE 0.11904104078555934\n",
      "66 Train Loss 31315.174 Test MSE 4488.289021555731 Test RE 0.11876261999093352\n",
      "67 Train Loss 31197.045 Test MSE 4342.292353126883 Test RE 0.11681507498845607\n",
      "68 Train Loss 31159.049 Test MSE 4330.43774680768 Test RE 0.11665551143983285\n",
      "69 Train Loss 30929.34 Test MSE 4257.991346171868 Test RE 0.11567559696415787\n",
      "70 Train Loss 30780.873 Test MSE 4194.670809442881 Test RE 0.11481227012429633\n",
      "71 Train Loss 30589.875 Test MSE 4153.950531749088 Test RE 0.11425363401409959\n",
      "72 Train Loss 30467.62 Test MSE 4191.062497690468 Test RE 0.1147628779773629\n",
      "73 Train Loss 30391.291 Test MSE 4291.6837302732765 Test RE 0.11613235073928027\n",
      "74 Train Loss 30344.816 Test MSE 4299.956449454572 Test RE 0.11624422615365466\n",
      "75 Train Loss 30282.086 Test MSE 4266.065399490943 Test RE 0.11578521773711344\n",
      "76 Train Loss 30222.723 Test MSE 4255.179690803401 Test RE 0.115637398950652\n",
      "77 Train Loss 30218.166 Test MSE 4256.984886518378 Test RE 0.11566192505969763\n",
      "78 Train Loss 30187.07 Test MSE 4293.814623382119 Test RE 0.11616117799349654\n",
      "79 Train Loss 30126.283 Test MSE 4346.8080360178665 Test RE 0.11687579899355505\n",
      "80 Train Loss 30033.48 Test MSE 4281.835092853238 Test RE 0.11599902284127414\n",
      "81 Train Loss 29958.348 Test MSE 4274.22742910698 Test RE 0.11589592757102847\n",
      "82 Train Loss 29898.385 Test MSE 4281.800723065071 Test RE 0.11599855728506325\n",
      "83 Train Loss 29880.102 Test MSE 4258.26402491145 Test RE 0.1156793007963696\n",
      "84 Train Loss 29854.816 Test MSE 4229.329437839618 Test RE 0.11528561477065123\n",
      "85 Train Loss 29798.33 Test MSE 4243.822335786598 Test RE 0.11548297391992779\n",
      "86 Train Loss 29729.195 Test MSE 4266.312975381409 Test RE 0.11578857741515614\n",
      "87 Train Loss 29669.766 Test MSE 4322.803717264414 Test RE 0.11655264141809317\n",
      "88 Train Loss 29624.588 Test MSE 4266.529035545829 Test RE 0.11579150933582005\n",
      "89 Train Loss 29600.691 Test MSE 4234.774515606782 Test RE 0.11535980350793593\n",
      "90 Train Loss 29579.32 Test MSE 4240.632644324993 Test RE 0.1154395667898206\n",
      "91 Train Loss 29538.959 Test MSE 4228.847018950809 Test RE 0.11527903955050807\n",
      "92 Train Loss 29500.717 Test MSE 4283.5597228013285 Test RE 0.11602238142981978\n",
      "93 Train Loss 29436.686 Test MSE 4295.527403409278 Test RE 0.11618434372445201\n",
      "94 Train Loss 29417.268 Test MSE 4325.7476968277 Test RE 0.11659232286283144\n",
      "95 Train Loss 29383.55 Test MSE 4348.616977324395 Test RE 0.11690011562628745\n",
      "96 Train Loss 29288.264 Test MSE 4312.919900374762 Test RE 0.1164193200507347\n",
      "97 Train Loss 29139.443 Test MSE 4332.7113955986715 Test RE 0.11668613176884855\n",
      "98 Train Loss 29052.162 Test MSE 4304.151788325189 Test RE 0.11630092033527492\n",
      "99 Train Loss 28885.787 Test MSE 4297.329862637687 Test RE 0.11620871739954518\n",
      "Training time: 271.75\n",
      "3D_HTTP_swish_tune1\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 254519.89 Test MSE 85763.77374364265 Test RE 0.5191481412539156\n",
      "1 Train Loss 244557.83 Test MSE 86238.67696445613 Test RE 0.5205835069930181\n",
      "2 Train Loss 241252.02 Test MSE 85084.64460883416 Test RE 0.5170885923768829\n",
      "3 Train Loss 222230.86 Test MSE 71340.59508975479 Test RE 0.4734866363865566\n",
      "4 Train Loss 199393.72 Test MSE 59297.99973717463 Test RE 0.4316774714447698\n",
      "5 Train Loss 195605.36 Test MSE 56746.91130436884 Test RE 0.42228968787842935\n",
      "6 Train Loss 188804.28 Test MSE 51872.59438850646 Test RE 0.40374610626002205\n",
      "7 Train Loss 185833.44 Test MSE 49682.235812417544 Test RE 0.3951299305347379\n",
      "8 Train Loss 184433.67 Test MSE 48662.68387218514 Test RE 0.3910545929514514\n",
      "9 Train Loss 181888.22 Test MSE 47171.24214623811 Test RE 0.385015326891637\n",
      "10 Train Loss 179880.16 Test MSE 46693.532972795256 Test RE 0.38306081629393685\n",
      "11 Train Loss 178720.05 Test MSE 46638.87452539137 Test RE 0.3828365492596697\n",
      "12 Train Loss 177467.33 Test MSE 46169.39915755775 Test RE 0.38090482462987685\n",
      "13 Train Loss 175878.81 Test MSE 45311.121376444884 Test RE 0.3773477522756263\n",
      "14 Train Loss 172275.5 Test MSE 44028.383100956264 Test RE 0.37196812928741196\n",
      "15 Train Loss 168144.2 Test MSE 42288.080230998785 Test RE 0.3645426506494945\n",
      "16 Train Loss 163549.53 Test MSE 40457.094522691914 Test RE 0.35656335482502627\n",
      "17 Train Loss 159478.25 Test MSE 38934.053974733666 Test RE 0.34978741142708414\n",
      "18 Train Loss 155923.55 Test MSE 37729.69329593664 Test RE 0.3443348657896876\n",
      "19 Train Loss 150118.0 Test MSE 35881.641917422785 Test RE 0.3357959981398614\n",
      "20 Train Loss 147135.25 Test MSE 34639.15254051225 Test RE 0.329930899719811\n",
      "21 Train Loss 141872.28 Test MSE 32210.701244988082 Test RE 0.3181555122581303\n",
      "22 Train Loss 138802.72 Test MSE 30909.60215245182 Test RE 0.3116635906133429\n",
      "23 Train Loss 136942.14 Test MSE 29837.476028109882 Test RE 0.30621072923163184\n",
      "24 Train Loss 133579.55 Test MSE 27815.410023449364 Test RE 0.295652867351591\n",
      "25 Train Loss 130321.74 Test MSE 26175.080613141563 Test RE 0.28680279286336624\n",
      "26 Train Loss 127629.695 Test MSE 25154.044274341533 Test RE 0.2811533565491239\n",
      "27 Train Loss 125127.016 Test MSE 24404.383481252517 Test RE 0.27693208952188997\n",
      "28 Train Loss 119903.23 Test MSE 22288.584006873672 Test RE 0.264655303599185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Train Loss 117272.12 Test MSE 21225.855279654144 Test RE 0.25826881007969765\n",
      "30 Train Loss 111926.7 Test MSE 20502.94523747788 Test RE 0.2538326524865076\n",
      "31 Train Loss 106800.484 Test MSE 19616.227149891612 Test RE 0.24828306792625504\n",
      "32 Train Loss 102887.555 Test MSE 18793.64401744786 Test RE 0.24302159134829074\n",
      "33 Train Loss 97565.836 Test MSE 17938.46933426117 Test RE 0.23742806520088522\n",
      "34 Train Loss 94872.8 Test MSE 17094.03758803049 Test RE 0.23177238484180201\n",
      "35 Train Loss 92170.516 Test MSE 15844.523511662119 Test RE 0.22314078360002265\n",
      "36 Train Loss 90233.78 Test MSE 15087.118263245653 Test RE 0.21774215134012326\n",
      "37 Train Loss 88549.4 Test MSE 14591.552756822128 Test RE 0.21413621257955825\n",
      "38 Train Loss 86894.03 Test MSE 14258.960481628717 Test RE 0.21168169037282844\n",
      "39 Train Loss 85444.95 Test MSE 13922.497508742015 Test RE 0.20916929692592146\n",
      "40 Train Loss 84154.51 Test MSE 13606.2048449712 Test RE 0.2067796827835164\n",
      "41 Train Loss 83274.52 Test MSE 13247.219452575371 Test RE 0.20403361655823227\n",
      "42 Train Loss 82573.59 Test MSE 12956.42255625625 Test RE 0.20178176380655402\n",
      "43 Train Loss 81731.195 Test MSE 12383.345492183407 Test RE 0.19726877926924752\n",
      "44 Train Loss 81363.04 Test MSE 12167.424149705328 Test RE 0.1955413845815878\n",
      "45 Train Loss 81050.83 Test MSE 12003.36575858529 Test RE 0.19421862811956725\n",
      "46 Train Loss 80526.734 Test MSE 11997.132093468394 Test RE 0.19416819013664324\n",
      "47 Train Loss 80301.27 Test MSE 11837.421477399748 Test RE 0.192871437690401\n",
      "48 Train Loss 80001.375 Test MSE 11826.035879785066 Test RE 0.19277866052292783\n",
      "49 Train Loss 79168.016 Test MSE 11895.28076113131 Test RE 0.19334222434656134\n",
      "50 Train Loss 78307.98 Test MSE 11596.88555188918 Test RE 0.19090181074820012\n",
      "51 Train Loss 77079.055 Test MSE 11018.523360715997 Test RE 0.18608058408400335\n",
      "52 Train Loss 76012.11 Test MSE 10633.303092522585 Test RE 0.18279884982399366\n",
      "53 Train Loss 74304.98 Test MSE 10376.727119306419 Test RE 0.1805799632246202\n",
      "54 Train Loss 72576.47 Test MSE 10264.050670301785 Test RE 0.17959686682710607\n",
      "55 Train Loss 68948.2 Test MSE 10323.195056164112 Test RE 0.1801135677233756\n",
      "56 Train Loss 67112.97 Test MSE 10267.167720311412 Test RE 0.17962413529732735\n",
      "57 Train Loss 65209.758 Test MSE 10166.130994785304 Test RE 0.1787381312362243\n",
      "58 Train Loss 64487.184 Test MSE 10080.290581883346 Test RE 0.17798192021884915\n",
      "59 Train Loss 63748.805 Test MSE 10034.320833502032 Test RE 0.17757562571167695\n",
      "60 Train Loss 63083.78 Test MSE 10004.581561925866 Test RE 0.17731228509646565\n",
      "61 Train Loss 62245.535 Test MSE 9825.409533250335 Test RE 0.1757173693426088\n",
      "62 Train Loss 61639.914 Test MSE 9615.507722416012 Test RE 0.17383029720486814\n",
      "63 Train Loss 60973.92 Test MSE 9541.292289337509 Test RE 0.17315816002024872\n",
      "64 Train Loss 60514.574 Test MSE 9420.519635478548 Test RE 0.17205876121935515\n",
      "65 Train Loss 60362.98 Test MSE 9421.563628786243 Test RE 0.17206829483458103\n",
      "66 Train Loss 60165.027 Test MSE 9394.556706910578 Test RE 0.17182150087641704\n",
      "67 Train Loss 60045.156 Test MSE 9374.05508783594 Test RE 0.17163391656504248\n",
      "68 Train Loss 59879.06 Test MSE 9341.001829669129 Test RE 0.17133105564779633\n",
      "69 Train Loss 59756.785 Test MSE 9238.67863147398 Test RE 0.17039007433981282\n",
      "70 Train Loss 59599.625 Test MSE 9190.576260889151 Test RE 0.1699459165067027\n",
      "71 Train Loss 59413.65 Test MSE 9154.01667055464 Test RE 0.16960756208132385\n",
      "72 Train Loss 59219.477 Test MSE 9079.085999634211 Test RE 0.16891197002499234\n",
      "73 Train Loss 58998.246 Test MSE 9017.492754522167 Test RE 0.168338038816783\n",
      "74 Train Loss 58475.77 Test MSE 8995.059688964335 Test RE 0.16812851883630375\n",
      "75 Train Loss 57611.49 Test MSE 8827.111637657506 Test RE 0.1665515473261961\n",
      "76 Train Loss 56761.78 Test MSE 8715.46545234249 Test RE 0.16549491533558694\n",
      "77 Train Loss 56085.938 Test MSE 8524.752744081134 Test RE 0.1636742116883086\n",
      "78 Train Loss 55284.5 Test MSE 8262.058846714834 Test RE 0.16113263314480938\n",
      "79 Train Loss 54395.004 Test MSE 8168.438756175264 Test RE 0.16021710895106225\n",
      "80 Train Loss 54026.203 Test MSE 8123.129171754473 Test RE 0.15977213619530303\n",
      "81 Train Loss 53282.652 Test MSE 8055.59063500886 Test RE 0.15910654911883895\n",
      "82 Train Loss 51871.12 Test MSE 8127.4541698765015 Test RE 0.1598146642789815\n",
      "83 Train Loss 50554.19 Test MSE 8113.3750388798235 Test RE 0.1596761813771691\n",
      "84 Train Loss 50061.44 Test MSE 7955.636697920619 Test RE 0.15811636929367445\n",
      "85 Train Loss 49849.94 Test MSE 7871.201818110105 Test RE 0.1572750696337169\n",
      "86 Train Loss 49616.203 Test MSE 7805.5900694641605 Test RE 0.1566182012919386\n",
      "87 Train Loss 48958.33 Test MSE 7741.858635017848 Test RE 0.1559775091405923\n",
      "88 Train Loss 48637.715 Test MSE 7636.649726709771 Test RE 0.15491404631608915\n",
      "89 Train Loss 48126.31 Test MSE 7582.0426120539205 Test RE 0.15435918349659491\n",
      "90 Train Loss 47877.535 Test MSE 7526.172896896378 Test RE 0.15378941953190647\n",
      "91 Train Loss 47540.26 Test MSE 7378.645348254794 Test RE 0.15227467474355563\n",
      "92 Train Loss 47120.31 Test MSE 7316.816389755924 Test RE 0.1516353439275635\n",
      "93 Train Loss 46895.35 Test MSE 7291.135581383581 Test RE 0.15136900260241246\n",
      "94 Train Loss 46671.883 Test MSE 7272.372693260274 Test RE 0.15117411189138882\n",
      "95 Train Loss 46018.266 Test MSE 7247.01453037075 Test RE 0.15091031591122311\n",
      "96 Train Loss 45249.24 Test MSE 7187.524511128191 Test RE 0.1502896356473047\n",
      "97 Train Loss 44920.87 Test MSE 7121.457642278555 Test RE 0.14959731883984087\n",
      "98 Train Loss 44508.67 Test MSE 7055.097361755658 Test RE 0.14889868693731279\n",
      "99 Train Loss 43711.555 Test MSE 6885.207000663412 Test RE 0.1470949838896501\n",
      "Training time: 266.88\n",
      "3D_HTTP_swish_tune1\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 243468.36 Test MSE 87161.58043369651 Test RE 0.523361667362693\n",
      "1 Train Loss 241778.48 Test MSE 86507.36827397268 Test RE 0.521393859647044\n",
      "2 Train Loss 234809.66 Test MSE 78644.29550284526 Test RE 0.49713343790347003\n",
      "3 Train Loss 232150.89 Test MSE 77941.69946630164 Test RE 0.4949077990475967\n",
      "4 Train Loss 207048.55 Test MSE 63162.230252800684 Test RE 0.44552090846584996\n",
      "5 Train Loss 189157.61 Test MSE 53097.99469042592 Test RE 0.4084871714676729\n",
      "6 Train Loss 184912.36 Test MSE 50700.24889324764 Test RE 0.3991576047583131\n",
      "7 Train Loss 180796.0 Test MSE 49563.41176958632 Test RE 0.3946571353640509\n",
      "8 Train Loss 177525.58 Test MSE 48191.59835228166 Test RE 0.3891571619574218\n",
      "9 Train Loss 174247.78 Test MSE 45451.3443658564 Test RE 0.37793118471498716\n",
      "10 Train Loss 171305.9 Test MSE 44869.548320992646 Test RE 0.3755045563445641\n",
      "11 Train Loss 168520.42 Test MSE 43740.1309903052 Test RE 0.37074849935892984\n",
      "12 Train Loss 166806.25 Test MSE 43096.8079736379 Test RE 0.3680119443616338\n",
      "13 Train Loss 162443.11 Test MSE 40358.93391035386 Test RE 0.35613052921341415\n",
      "14 Train Loss 158626.66 Test MSE 38886.704830668874 Test RE 0.34957465201257654\n",
      "15 Train Loss 156854.02 Test MSE 36699.05577030426 Test RE 0.3395993164518164\n",
      "16 Train Loss 153894.58 Test MSE 36551.45628422445 Test RE 0.3389157132350853\n",
      "17 Train Loss 144796.53 Test MSE 32671.79435134836 Test RE 0.3204246035150218\n",
      "18 Train Loss 138731.02 Test MSE 29697.94462006762 Test RE 0.3054939111923822\n",
      "19 Train Loss 136573.2 Test MSE 28713.38903142098 Test RE 0.3003873155529931\n",
      "20 Train Loss 133982.34 Test MSE 27957.085141373624 Test RE 0.2964048507629391\n",
      "21 Train Loss 131758.84 Test MSE 26161.084631455153 Test RE 0.28672610497405726\n",
      "22 Train Loss 128889.29 Test MSE 24957.801648824166 Test RE 0.28005448142486145\n",
      "23 Train Loss 126752.87 Test MSE 24216.8426484715 Test RE 0.27586596469013924\n",
      "24 Train Loss 123350.21 Test MSE 23345.44603401294 Test RE 0.2708572408768507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Train Loss 121799.414 Test MSE 22597.297427698497 Test RE 0.2664818367696003\n",
      "26 Train Loss 120164.81 Test MSE 22016.34644616182 Test RE 0.26303405942212604\n",
      "27 Train Loss 116510.25 Test MSE 19781.070167591595 Test RE 0.24932409651467305\n",
      "28 Train Loss 114200.79 Test MSE 18678.328750694112 Test RE 0.2422748702753553\n",
      "29 Train Loss 111452.3 Test MSE 18959.564523342797 Test RE 0.24409199736758674\n",
      "30 Train Loss 106830.27 Test MSE 18066.41653853209 Test RE 0.23827329564482966\n",
      "31 Train Loss 103008.03 Test MSE 17371.514304293592 Test RE 0.23364591984241226\n",
      "32 Train Loss 97580.32 Test MSE 15364.261778858621 Test RE 0.21973296262200512\n",
      "33 Train Loss 89113.766 Test MSE 13453.157698287025 Test RE 0.20561343036432375\n",
      "34 Train Loss 84530.836 Test MSE 12414.646350645206 Test RE 0.1975179358964108\n",
      "35 Train Loss 78862.42 Test MSE 11095.506540306056 Test RE 0.18672949775020928\n",
      "36 Train Loss 72104.82 Test MSE 8312.359221801184 Test RE 0.16162238596255815\n",
      "37 Train Loss 66973.16 Test MSE 7466.677098077055 Test RE 0.1531803464288791\n",
      "38 Train Loss 60900.98 Test MSE 6053.99335082051 Test RE 0.13793050682299102\n",
      "39 Train Loss 58833.46 Test MSE 6142.644682725523 Test RE 0.1389367256285089\n",
      "40 Train Loss 56453.117 Test MSE 5579.3125784430395 Test RE 0.13241272059903073\n",
      "41 Train Loss 52637.984 Test MSE 6027.104087957839 Test RE 0.13762385162088298\n",
      "42 Train Loss 49734.387 Test MSE 6052.996706703206 Test RE 0.13791915288862042\n",
      "43 Train Loss 48814.113 Test MSE 5530.628547605437 Test RE 0.13183375060430721\n",
      "44 Train Loss 47563.906 Test MSE 5003.22583162644 Test RE 0.12539043680854148\n",
      "45 Train Loss 46186.945 Test MSE 4619.07624717871 Test RE 0.120480546219191\n",
      "46 Train Loss 45424.188 Test MSE 4574.375890762187 Test RE 0.1198961635550026\n",
      "47 Train Loss 45006.582 Test MSE 4910.216979897453 Test RE 0.12421947919976939\n",
      "48 Train Loss 44616.18 Test MSE 4865.775647857445 Test RE 0.12365605937899811\n",
      "49 Train Loss 44048.656 Test MSE 4963.356892818343 Test RE 0.12488984150441397\n",
      "50 Train Loss 41699.324 Test MSE 4541.573393298188 Test RE 0.11946550703398504\n",
      "51 Train Loss 40342.367 Test MSE 4351.114135632073 Test RE 0.11693367528451339\n",
      "52 Train Loss 39573.94 Test MSE 4336.8906295910665 Test RE 0.11674239458725601\n",
      "53 Train Loss 39031.35 Test MSE 4455.636850162075 Test RE 0.11832983413410939\n",
      "54 Train Loss 38782.57 Test MSE 4531.3928488497395 Test RE 0.11933153295207687\n",
      "55 Train Loss 38400.72 Test MSE 4597.067598488669 Test RE 0.12019317489461974\n",
      "56 Train Loss 37625.812 Test MSE 4826.815566011316 Test RE 0.12316000972197134\n",
      "57 Train Loss 37088.152 Test MSE 4759.390762986687 Test RE 0.12229678603241677\n",
      "58 Train Loss 36337.95 Test MSE 4847.374028066165 Test RE 0.12342201372998302\n",
      "59 Train Loss 35775.62 Test MSE 4834.746139120327 Test RE 0.12326114561370519\n",
      "60 Train Loss 35087.484 Test MSE 4608.905563030618 Test RE 0.12034783084592453\n",
      "61 Train Loss 34414.742 Test MSE 4531.494623498003 Test RE 0.11933287303193808\n",
      "62 Train Loss 34120.305 Test MSE 4547.601202181164 Test RE 0.11954476111590155\n",
      "63 Train Loss 33791.707 Test MSE 4430.032975139767 Test RE 0.1179893589777947\n",
      "64 Train Loss 33589.297 Test MSE 4455.56279232629 Test RE 0.11832885074069857\n",
      "65 Train Loss 33454.832 Test MSE 4577.848167840973 Test RE 0.11994165978636936\n",
      "66 Train Loss 33335.977 Test MSE 4628.184428429812 Test RE 0.12059927322933542\n",
      "67 Train Loss 33107.92 Test MSE 4524.7484673500785 Test RE 0.1192440129420975\n",
      "68 Train Loss 33030.707 Test MSE 4623.30010847554 Test RE 0.1205356196585827\n",
      "69 Train Loss 32853.586 Test MSE 4693.7185129410755 Test RE 0.12145010166458022\n",
      "70 Train Loss 32809.29 Test MSE 4674.980148011624 Test RE 0.12120743135791899\n",
      "71 Train Loss 32733.047 Test MSE 4653.867352640854 Test RE 0.1209334276852391\n",
      "72 Train Loss 32679.73 Test MSE 4656.043118281966 Test RE 0.1209616936445398\n",
      "73 Train Loss 32636.418 Test MSE 4687.370082480084 Test RE 0.12136794096334044\n",
      "74 Train Loss 32440.531 Test MSE 4884.3176567663795 Test RE 0.12389144339063629\n",
      "75 Train Loss 32240.037 Test MSE 4847.513842668338 Test RE 0.12342379367054661\n",
      "76 Train Loss 32029.254 Test MSE 4795.247411144438 Test RE 0.1227566058618188\n",
      "77 Train Loss 31914.297 Test MSE 4763.949460171316 Test RE 0.12235534190696322\n",
      "78 Train Loss 31778.832 Test MSE 4732.605052481483 Test RE 0.12195215911265293\n",
      "79 Train Loss 31695.162 Test MSE 4703.474533692793 Test RE 0.12157625480435472\n",
      "80 Train Loss 31572.7 Test MSE 4707.703956132397 Test RE 0.12163090395736927\n",
      "81 Train Loss 31441.281 Test MSE 4648.706757590108 Test RE 0.12086635856751832\n",
      "82 Train Loss 31303.617 Test MSE 4545.912660472045 Test RE 0.11952256534199127\n",
      "83 Train Loss 31206.658 Test MSE 4489.7696676838605 Test RE 0.11878220773501022\n",
      "84 Train Loss 31139.016 Test MSE 4489.471834235823 Test RE 0.11877826790024913\n",
      "85 Train Loss 31078.352 Test MSE 4518.351110447989 Test RE 0.1191596860071426\n",
      "86 Train Loss 30987.357 Test MSE 4513.6462314531655 Test RE 0.11909763041318044\n",
      "87 Train Loss 30849.295 Test MSE 4654.88535358849 Test RE 0.12094665363293068\n",
      "88 Train Loss 30645.852 Test MSE 4710.841461841761 Test RE 0.12167142839315803\n",
      "89 Train Loss 30520.078 Test MSE 4711.726889239697 Test RE 0.12168286224796204\n",
      "90 Train Loss 30431.617 Test MSE 4718.104900416177 Test RE 0.12176519216774064\n",
      "91 Train Loss 30309.326 Test MSE 4572.669410105604 Test RE 0.11987379770947384\n",
      "92 Train Loss 30229.062 Test MSE 4514.177637026938 Test RE 0.11910464107359577\n",
      "93 Train Loss 30122.02 Test MSE 4441.992302417247 Test RE 0.11814851380985342\n",
      "94 Train Loss 29992.434 Test MSE 4415.484389485327 Test RE 0.11779545636246386\n",
      "95 Train Loss 29755.887 Test MSE 4321.955409977472 Test RE 0.11654120470795609\n",
      "96 Train Loss 29651.604 Test MSE 4362.773988450009 Test RE 0.11709024636190224\n",
      "97 Train Loss 29550.338 Test MSE 4263.716171495564 Test RE 0.11575333316588622\n",
      "98 Train Loss 29482.98 Test MSE 4190.51820667523 Test RE 0.11475542563901354\n",
      "99 Train Loss 29362.002 Test MSE 4230.147278929581 Test RE 0.11529676083489057\n",
      "Training time: 267.62\n",
      "3D_HTTP_swish_tune1\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 250227.86 Test MSE 88758.01361386967 Test RE 0.5281328108046567\n",
      "1 Train Loss 247760.22 Test MSE 87156.49285436199 Test RE 0.5233463929559787\n",
      "2 Train Loss 234578.92 Test MSE 79723.52348844161 Test RE 0.500532871922339\n",
      "3 Train Loss 216746.22 Test MSE 65437.40550021248 Test RE 0.4534740066372353\n",
      "4 Train Loss 200908.84 Test MSE 57786.62853112399 Test RE 0.4261407252762636\n",
      "5 Train Loss 193149.9 Test MSE 55781.01543127864 Test RE 0.41868034188186637\n",
      "6 Train Loss 185432.19 Test MSE 49615.736004290884 Test RE 0.3948654007418323\n",
      "7 Train Loss 182046.45 Test MSE 47921.5301884365 Test RE 0.38806520171136616\n",
      "8 Train Loss 178316.4 Test MSE 46403.36730529433 Test RE 0.38186874204508275\n",
      "9 Train Loss 175332.45 Test MSE 44033.78849277789 Test RE 0.37199096196527165\n",
      "10 Train Loss 173589.22 Test MSE 43339.60861411482 Test RE 0.3690471490822993\n",
      "11 Train Loss 170831.11 Test MSE 42555.85710244851 Test RE 0.36569500902073737\n",
      "12 Train Loss 169308.1 Test MSE 42213.34400898811 Test RE 0.3642203779384803\n",
      "13 Train Loss 166708.86 Test MSE 40627.741366661656 Test RE 0.3573145504405032\n",
      "14 Train Loss 161604.61 Test MSE 39375.84474119587 Test RE 0.35176635948746504\n",
      "15 Train Loss 158719.9 Test MSE 37297.49591255895 Test RE 0.34235699024439264\n",
      "16 Train Loss 153170.67 Test MSE 35045.50158768006 Test RE 0.33186045347336657\n",
      "17 Train Loss 145414.94 Test MSE 32287.256483904366 Test RE 0.3185333683038897\n",
      "18 Train Loss 138920.27 Test MSE 30466.206462856055 Test RE 0.3094201217259854\n",
      "19 Train Loss 131231.84 Test MSE 26829.903205493403 Test RE 0.2903681082367056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Train Loss 119677.74 Test MSE 23492.840510222897 Test RE 0.2717109415237055\n",
      "21 Train Loss 108513.87 Test MSE 19634.489389376286 Test RE 0.24839861384631484\n",
      "22 Train Loss 103152.805 Test MSE 17793.424166604786 Test RE 0.23646623035294462\n",
      "23 Train Loss 96337.586 Test MSE 15167.378768124676 Test RE 0.21832055584272994\n",
      "24 Train Loss 84094.586 Test MSE 12543.262920205481 Test RE 0.19853844909806542\n",
      "25 Train Loss 75897.74 Test MSE 9476.090392286053 Test RE 0.17256549422773226\n",
      "26 Train Loss 71998.23 Test MSE 9397.797758401071 Test RE 0.17185113688411355\n",
      "27 Train Loss 70512.484 Test MSE 9574.514902299845 Test RE 0.17345936489369423\n",
      "28 Train Loss 66691.31 Test MSE 8779.64219056822 Test RE 0.1661031125486713\n",
      "29 Train Loss 61254.863 Test MSE 6838.416354068509 Test RE 0.14659431610585463\n",
      "30 Train Loss 58492.324 Test MSE 6711.832767029156 Test RE 0.1452311999647598\n",
      "31 Train Loss 56067.656 Test MSE 6411.315859072758 Test RE 0.1419426630153095\n",
      "32 Train Loss 54267.484 Test MSE 6065.813343153039 Test RE 0.1380650909259926\n",
      "33 Train Loss 52494.395 Test MSE 6072.247413589988 Test RE 0.13813829504816372\n",
      "34 Train Loss 50503.3 Test MSE 5540.592144968707 Test RE 0.13195244844632836\n",
      "35 Train Loss 49301.625 Test MSE 5297.40517950873 Test RE 0.12902413558000841\n",
      "36 Train Loss 48173.004 Test MSE 4804.447899559992 Test RE 0.12287431402227178\n",
      "37 Train Loss 47283.125 Test MSE 4597.390534933737 Test RE 0.12019739650700047\n",
      "38 Train Loss 45283.87 Test MSE 4607.48284568718 Test RE 0.12032925440088969\n",
      "39 Train Loss 44646.65 Test MSE 4622.761598686717 Test RE 0.12052859961880588\n",
      "40 Train Loss 44303.71 Test MSE 4599.0340060453345 Test RE 0.12021887861693992\n",
      "41 Train Loss 43872.3 Test MSE 4501.169433169002 Test RE 0.11893290932721894\n",
      "42 Train Loss 43465.574 Test MSE 4419.921581108327 Test RE 0.11785462877928092\n",
      "43 Train Loss 43180.605 Test MSE 4445.841688850586 Test RE 0.11819969588838433\n",
      "44 Train Loss 42721.78 Test MSE 4672.022134356753 Test RE 0.12116907932672666\n",
      "45 Train Loss 42205.105 Test MSE 4680.181772266186 Test RE 0.12127484343427285\n",
      "46 Train Loss 41680.383 Test MSE 4580.004783566997 Test RE 0.11996990860577977\n",
      "47 Train Loss 41248.477 Test MSE 4329.932217125934 Test RE 0.11664870213460513\n",
      "48 Train Loss 40919.98 Test MSE 4221.214282084796 Test RE 0.1151749577564657\n",
      "49 Train Loss 39714.21 Test MSE 4056.9002706799533 Test RE 0.11291107131571208\n",
      "50 Train Loss 38975.67 Test MSE 4172.2931981494385 Test RE 0.11450561196250775\n",
      "51 Train Loss 38635.9 Test MSE 4209.014976604633 Test RE 0.11500840957619354\n",
      "52 Train Loss 38330.28 Test MSE 4171.6171948000665 Test RE 0.11449633537177425\n",
      "53 Train Loss 37857.17 Test MSE 4400.6028493615095 Test RE 0.11759678537097987\n",
      "54 Train Loss 37677.5 Test MSE 4433.496277362997 Test RE 0.11803547070853447\n",
      "55 Train Loss 37475.59 Test MSE 4421.976012482256 Test RE 0.11788201570385347\n",
      "56 Train Loss 37310.17 Test MSE 4360.886429362406 Test RE 0.1170649140080009\n",
      "57 Train Loss 37206.85 Test MSE 4323.371826398155 Test RE 0.11656029992506216\n",
      "58 Train Loss 37042.29 Test MSE 4275.3940435240875 Test RE 0.1159117429011278\n",
      "59 Train Loss 36991.094 Test MSE 4345.029648839544 Test RE 0.11685188815090834\n",
      "60 Train Loss 36877.727 Test MSE 4348.281144471815 Test RE 0.11689560158682408\n",
      "61 Train Loss 36754.15 Test MSE 4316.606269746612 Test RE 0.11646906279580709\n",
      "62 Train Loss 36619.645 Test MSE 4347.65642219932 Test RE 0.11688720402620097\n",
      "63 Train Loss 36497.695 Test MSE 4330.993462460499 Test RE 0.11666299627368013\n",
      "64 Train Loss 36339.785 Test MSE 4342.748321117844 Test RE 0.11682120798602237\n",
      "65 Train Loss 36188.254 Test MSE 4480.697510545994 Test RE 0.11866213968619425\n",
      "66 Train Loss 36040.094 Test MSE 4528.478008384722 Test RE 0.11929314648385167\n",
      "67 Train Loss 35901.26 Test MSE 4364.732547909451 Test RE 0.11711652579766905\n",
      "68 Train Loss 35800.824 Test MSE 4334.218087553757 Test RE 0.11670641869292578\n",
      "69 Train Loss 35672.65 Test MSE 4324.643006996635 Test RE 0.11657743450288661\n",
      "70 Train Loss 35537.375 Test MSE 4293.9890364425355 Test RE 0.11616353718021022\n",
      "71 Train Loss 35362.19 Test MSE 4279.454979822688 Test RE 0.11596677858645967\n",
      "72 Train Loss 35270.46 Test MSE 4282.099799417571 Test RE 0.11600260836332114\n",
      "73 Train Loss 35101.15 Test MSE 4327.103192777713 Test RE 0.11661058884292984\n",
      "74 Train Loss 34999.766 Test MSE 4353.367777726651 Test RE 0.11696395402811471\n",
      "75 Train Loss 34790.746 Test MSE 4381.800961350158 Test RE 0.1173452961510214\n",
      "76 Train Loss 34649.227 Test MSE 4357.852282268076 Test RE 0.11702418215469437\n",
      "77 Train Loss 34565.812 Test MSE 4380.578588554928 Test RE 0.11732892734467691\n",
      "78 Train Loss 34499.938 Test MSE 4393.886314718516 Test RE 0.11750700852452552\n",
      "79 Train Loss 34412.82 Test MSE 4335.110719193889 Test RE 0.116718435909945\n",
      "80 Train Loss 34296.207 Test MSE 4364.2148904972355 Test RE 0.11710958057998604\n",
      "81 Train Loss 34187.086 Test MSE 4381.3818087737245 Test RE 0.11733968353192392\n",
      "82 Train Loss 34124.76 Test MSE 4381.231813446923 Test RE 0.11733767496983269\n",
      "83 Train Loss 34092.254 Test MSE 4396.946478637678 Test RE 0.11754792083923796\n",
      "84 Train Loss 34043.906 Test MSE 4343.1213940914795 Test RE 0.11682622576465534\n",
      "85 Train Loss 34006.71 Test MSE 4386.006788459329 Test RE 0.11740159898864859\n",
      "86 Train Loss 33978.7 Test MSE 4435.129426493594 Test RE 0.11805720883180605\n",
      "87 Train Loss 33944.168 Test MSE 4436.73127819246 Test RE 0.11807852648119481\n",
      "88 Train Loss 33893.027 Test MSE 4436.30094963096 Test RE 0.118072799991193\n",
      "89 Train Loss 33763.047 Test MSE 4406.248338237683 Test RE 0.11767219305692682\n",
      "90 Train Loss 33663.406 Test MSE 4390.684231774023 Test RE 0.11746418359257602\n",
      "91 Train Loss 33592.527 Test MSE 4389.5056966292095 Test RE 0.11744841783122904\n",
      "92 Train Loss 33544.598 Test MSE 4431.834904544767 Test RE 0.11801335280371199\n",
      "93 Train Loss 33506.363 Test MSE 4431.391744385344 Test RE 0.1180074522991991\n",
      "94 Train Loss 33406.906 Test MSE 4442.137142820726 Test RE 0.11815044003324023\n",
      "95 Train Loss 33251.582 Test MSE 4445.033790202516 Test RE 0.1181889557721303\n",
      "96 Train Loss 33198.625 Test MSE 4465.29420328024 Test RE 0.11845800149685677\n",
      "97 Train Loss 33127.668 Test MSE 4491.543341813187 Test RE 0.11880566774981277\n",
      "98 Train Loss 33032.996 Test MSE 4558.782179694907 Test RE 0.11969163049373308\n",
      "99 Train Loss 32935.395 Test MSE 4549.169834498557 Test RE 0.11956537699659896\n",
      "Training time: 263.51\n",
      "3D_HTTP_swish_tune1\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 248087.12 Test MSE 87233.07272086965 Test RE 0.5235762610696176\n",
      "1 Train Loss 247574.81 Test MSE 87784.71809952645 Test RE 0.5252291504491741\n",
      "2 Train Loss 232053.1 Test MSE 74597.11659714465 Test RE 0.48417279424535126\n",
      "3 Train Loss 213270.0 Test MSE 63588.317480655816 Test RE 0.4470211064297802\n",
      "4 Train Loss 188978.64 Test MSE 46831.16928925059 Test RE 0.38362496598666385\n",
      "5 Train Loss 165027.06 Test MSE 42036.68935690833 Test RE 0.3634574831624516\n",
      "6 Train Loss 156400.36 Test MSE 35329.72499240024 Test RE 0.33320345091192455\n",
      "7 Train Loss 150021.3 Test MSE 31713.65685616223 Test RE 0.3156912346315397\n",
      "8 Train Loss 124021.14 Test MSE 21260.544802228527 Test RE 0.25847976893300056\n",
      "9 Train Loss 90116.055 Test MSE 12946.249092941911 Test RE 0.20170252810346612\n",
      "10 Train Loss 78177.68 Test MSE 9955.80122412693 Test RE 0.1768794872817935\n",
      "11 Train Loss 66145.41 Test MSE 8177.8022393745705 Test RE 0.1603089111045587\n",
      "12 Train Loss 60240.562 Test MSE 10290.389197147475 Test RE 0.179827150480564\n",
      "13 Train Loss 55299.758 Test MSE 7610.02209614104 Test RE 0.15464373170140294\n",
      "14 Train Loss 51308.242 Test MSE 5404.038046794591 Test RE 0.13031624611060807\n",
      "15 Train Loss 44648.66 Test MSE 6929.978155141111 Test RE 0.14757245255206541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Train Loss 43496.26 Test MSE 6051.015801400807 Test RE 0.13789658331272076\n",
      "17 Train Loss 39973.777 Test MSE 4547.923451098687 Test RE 0.1195489965892562\n",
      "18 Train Loss 36214.0 Test MSE 5098.542056889436 Test RE 0.1265792054491723\n",
      "19 Train Loss 35157.01 Test MSE 4773.819804624972 Test RE 0.12248202927843659\n",
      "20 Train Loss 34523.117 Test MSE 4538.501231650886 Test RE 0.1194250937888815\n",
      "21 Train Loss 34149.297 Test MSE 4592.293206549843 Test RE 0.12013074396592457\n",
      "22 Train Loss 33518.42 Test MSE 4418.798304183985 Test RE 0.11783965206594588\n",
      "23 Train Loss 32620.922 Test MSE 4451.08492362124 Test RE 0.1182693751729976\n",
      "24 Train Loss 31982.863 Test MSE 4362.788769637435 Test RE 0.11709044471407636\n",
      "25 Train Loss 31097.26 Test MSE 4252.477216714944 Test RE 0.11560067233376634\n",
      "26 Train Loss 30697.4 Test MSE 4207.805859152014 Test RE 0.11499188924255031\n",
      "27 Train Loss 30035.873 Test MSE 4205.184281116902 Test RE 0.11495606211669582\n",
      "28 Train Loss 29947.355 Test MSE 4265.590941443274 Test RE 0.11577877892866505\n",
      "29 Train Loss 29452.693 Test MSE 4056.67884101112 Test RE 0.1129079898741401\n",
      "30 Train Loss 29204.748 Test MSE 4137.427353246843 Test RE 0.11402617412651851\n",
      "31 Train Loss 29108.297 Test MSE 4020.7682991470256 Test RE 0.11240713681190712\n",
      "32 Train Loss 29082.61 Test MSE 3998.789365188755 Test RE 0.11209948732937476\n",
      "33 Train Loss 29024.55 Test MSE 3946.8252756971974 Test RE 0.1113687416448216\n",
      "34 Train Loss 28993.871 Test MSE 3928.614844029134 Test RE 0.1111115200193315\n",
      "35 Train Loss 28674.135 Test MSE 3654.2694820386246 Test RE 0.1071617131066748\n",
      "36 Train Loss 28124.377 Test MSE 3430.376551807426 Test RE 0.10382698903867053\n",
      "37 Train Loss 27914.92 Test MSE 3442.5037671238424 Test RE 0.10401035394931311\n",
      "38 Train Loss 27365.852 Test MSE 3471.0721178849385 Test RE 0.1044410383021629\n",
      "39 Train Loss 26329.104 Test MSE 3117.50310337926 Test RE 0.09897894249626533\n",
      "40 Train Loss 25225.605 Test MSE 3251.1114510627685 Test RE 0.10107768603455501\n",
      "41 Train Loss 24652.4 Test MSE 3274.8794585695764 Test RE 0.10144648918999596\n",
      "42 Train Loss 24129.293 Test MSE 2842.5935971968775 Test RE 0.09451413172363474\n",
      "43 Train Loss 23658.78 Test MSE 2915.3062558213533 Test RE 0.09571531974611192\n",
      "44 Train Loss 22981.666 Test MSE 2572.2773685170578 Test RE 0.08990798419543551\n",
      "45 Train Loss 22573.426 Test MSE 2497.5332989008534 Test RE 0.08859210192720976\n",
      "46 Train Loss 22232.246 Test MSE 2292.4587955270385 Test RE 0.08487702159779491\n",
      "47 Train Loss 22176.781 Test MSE 2305.7754902684346 Test RE 0.08512318626450643\n",
      "48 Train Loss 22030.027 Test MSE 2379.7462061134706 Test RE 0.08647781018598064\n",
      "49 Train Loss 21501.855 Test MSE 2316.5974485713864 Test RE 0.08532271158965152\n",
      "50 Train Loss 21401.076 Test MSE 2340.0216961694864 Test RE 0.08575299641308047\n",
      "51 Train Loss 21379.037 Test MSE 2406.113440050297 Test RE 0.08695557108751958\n",
      "52 Train Loss 21313.53 Test MSE 2408.688419333095 Test RE 0.08700208778880889\n",
      "53 Train Loss 21251.73 Test MSE 2458.2599783033947 Test RE 0.087892793429759\n",
      "54 Train Loss 21221.756 Test MSE 2492.2505290382474 Test RE 0.08849835754502122\n",
      "55 Train Loss 21196.5 Test MSE 2532.240579729709 Test RE 0.08920554364674889\n",
      "56 Train Loss 21030.473 Test MSE 2506.0725902624063 Test RE 0.08874342487993125\n",
      "57 Train Loss 20890.031 Test MSE 2341.948325864397 Test RE 0.08578829101670898\n",
      "58 Train Loss 20725.975 Test MSE 2261.942521000773 Test RE 0.08431020485948776\n",
      "59 Train Loss 20689.371 Test MSE 2243.5486906514407 Test RE 0.08396670515142123\n",
      "60 Train Loss 20625.143 Test MSE 2197.826124515683 Test RE 0.08310669812022635\n",
      "61 Train Loss 20500.625 Test MSE 2185.921491320486 Test RE 0.08288131675157218\n",
      "62 Train Loss 20415.41 Test MSE 2145.767741645542 Test RE 0.08211655441627368\n",
      "63 Train Loss 20397.941 Test MSE 2204.4630225779897 Test RE 0.08323208449700072\n",
      "64 Train Loss 20385.582 Test MSE 2202.5801408330617 Test RE 0.08319653170049379\n",
      "65 Train Loss 20339.535 Test MSE 2167.5480780990174 Test RE 0.0825322588951956\n",
      "66 Train Loss 20260.531 Test MSE 2211.8824288439505 Test RE 0.08337203103248739\n",
      "67 Train Loss 20199.107 Test MSE 2130.026966284298 Test RE 0.08181480752919287\n",
      "68 Train Loss 20166.78 Test MSE 2067.4425570542426 Test RE 0.0806039060349887\n",
      "69 Train Loss 20139.328 Test MSE 2059.4921956484054 Test RE 0.080448775376604\n",
      "70 Train Loss 20105.182 Test MSE 2050.258208689158 Test RE 0.08026822176838382\n",
      "71 Train Loss 20063.2 Test MSE 2078.974240571122 Test RE 0.08082838777575088\n",
      "72 Train Loss 20044.303 Test MSE 2130.7466656193606 Test RE 0.08182862826727297\n",
      "73 Train Loss 20026.639 Test MSE 2124.9553116894763 Test RE 0.08171734779289629\n",
      "74 Train Loss 20005.832 Test MSE 2117.262078893249 Test RE 0.08156928806147293\n",
      "75 Train Loss 19958.285 Test MSE 2047.535698708204 Test RE 0.08021491052487924\n",
      "76 Train Loss 19879.32 Test MSE 1996.9525548850572 Test RE 0.07921788360385582\n",
      "77 Train Loss 19836.695 Test MSE 2025.390598538869 Test RE 0.07977994950061182\n",
      "78 Train Loss 19815.885 Test MSE 2024.8670900644115 Test RE 0.07976963835893747\n",
      "79 Train Loss 19801.24 Test MSE 2003.1489783454413 Test RE 0.07934069257038967\n",
      "80 Train Loss 19793.475 Test MSE 1990.210581390353 Test RE 0.07908404556700613\n",
      "81 Train Loss 19717.88 Test MSE 1964.7396391615111 Test RE 0.07857635263639978\n",
      "82 Train Loss 19655.096 Test MSE 1919.251744701038 Test RE 0.07766142127001137\n",
      "83 Train Loss 19578.277 Test MSE 1847.9834960231103 Test RE 0.0762058666326975\n",
      "84 Train Loss 19510.314 Test MSE 1840.281932710562 Test RE 0.0760469049661857\n",
      "85 Train Loss 19451.154 Test MSE 1892.8622574656647 Test RE 0.0771256554820749\n",
      "86 Train Loss 19413.809 Test MSE 1955.2477079168839 Test RE 0.07838631617552412\n",
      "87 Train Loss 19361.809 Test MSE 1936.618949361601 Test RE 0.07801200693723083\n",
      "88 Train Loss 19342.39 Test MSE 1976.3246939300404 Test RE 0.07880767422310957\n",
      "89 Train Loss 19295.557 Test MSE 1941.7139488516727 Test RE 0.07811455939210268\n",
      "90 Train Loss 19271.133 Test MSE 1878.2820343649041 Test RE 0.07682804188398805\n",
      "91 Train Loss 19265.16 Test MSE 1871.6743361649515 Test RE 0.07669278430042979\n",
      "92 Train Loss 19262.11 Test MSE 1887.5309744692702 Test RE 0.07701696594968661\n",
      "93 Train Loss 19239.44 Test MSE 1903.9814109171161 Test RE 0.07735185162538973\n",
      "94 Train Loss 19195.008 Test MSE 1901.8161533579555 Test RE 0.07730785583710563\n",
      "95 Train Loss 19138.453 Test MSE 1896.365392035167 Test RE 0.07719699101048681\n",
      "96 Train Loss 19032.188 Test MSE 1904.8011248459134 Test RE 0.07736850083393038\n",
      "97 Train Loss 18902.064 Test MSE 1853.6304839463767 Test RE 0.07632221111361757\n",
      "98 Train Loss 18822.736 Test MSE 1857.2239894632648 Test RE 0.07639615559539258\n",
      "99 Train Loss 18727.4 Test MSE 1904.275879954356 Test RE 0.07735783299803227\n",
      "Training time: 274.66\n",
      "3D_HTTP_swish_tune1\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 243426.31 Test MSE 86627.93310168426 Test RE 0.5217570649718717\n",
      "1 Train Loss 243185.86 Test MSE 87413.3510836525 Test RE 0.5241170006740279\n",
      "2 Train Loss 226780.45 Test MSE 77664.03166692764 Test RE 0.4940254564199665\n",
      "3 Train Loss 203667.36 Test MSE 60577.479770629165 Test RE 0.43630979497163713\n",
      "4 Train Loss 186075.69 Test MSE 52431.922679914525 Test RE 0.4059170129355277\n",
      "5 Train Loss 176562.73 Test MSE 45486.35131562777 Test RE 0.3780766993489699\n",
      "6 Train Loss 170213.39 Test MSE 42729.32955030028 Test RE 0.36643960089705285\n",
      "7 Train Loss 166265.56 Test MSE 40128.67680182458 Test RE 0.35511317230719497\n",
      "8 Train Loss 161301.25 Test MSE 38491.38119991969 Test RE 0.34779321871691005\n",
      "9 Train Loss 155998.81 Test MSE 37097.35667271365 Test RE 0.341437206861006\n",
      "10 Train Loss 150501.17 Test MSE 35448.25911626574 Test RE 0.33376194530335707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Train Loss 145875.28 Test MSE 33436.335052357834 Test RE 0.3241519932230108\n",
      "12 Train Loss 141861.08 Test MSE 30028.33794118398 Test RE 0.30718853983595723\n",
      "13 Train Loss 132077.92 Test MSE 26610.54579823385 Test RE 0.2891786682513294\n",
      "14 Train Loss 125406.984 Test MSE 24703.989477764684 Test RE 0.27862681404418316\n",
      "15 Train Loss 121374.25 Test MSE 22102.5600520178 Test RE 0.2635485625406702\n",
      "16 Train Loss 115346.84 Test MSE 20045.178183526423 Test RE 0.25098300961070785\n",
      "17 Train Loss 110403.52 Test MSE 18396.493186859352 Test RE 0.24044009128316987\n",
      "18 Train Loss 106029.875 Test MSE 17229.120653913276 Test RE 0.23268635600375415\n",
      "19 Train Loss 97060.336 Test MSE 15402.780784248527 Test RE 0.22000823119904672\n",
      "20 Train Loss 90983.03 Test MSE 13125.370924561214 Test RE 0.203093093568627\n",
      "21 Train Loss 82384.54 Test MSE 12527.897170766893 Test RE 0.1984168050352459\n",
      "22 Train Loss 77475.02 Test MSE 13104.37081501828 Test RE 0.20293055779898872\n",
      "23 Train Loss 71910.63 Test MSE 11235.141306038433 Test RE 0.18790080110288662\n",
      "24 Train Loss 68894.91 Test MSE 9690.928414770673 Test RE 0.17451069774752076\n",
      "25 Train Loss 67517.36 Test MSE 9913.33394605253 Test RE 0.17650183722343155\n",
      "26 Train Loss 65262.832 Test MSE 9401.414069917793 Test RE 0.17188419821864948\n",
      "27 Train Loss 62183.68 Test MSE 8709.183450183904 Test RE 0.16543526121679744\n",
      "28 Train Loss 59202.453 Test MSE 8671.718865734436 Test RE 0.16507904853498767\n",
      "29 Train Loss 56577.887 Test MSE 8122.758440695195 Test RE 0.15976849023769946\n",
      "30 Train Loss 54846.47 Test MSE 7890.500579542018 Test RE 0.15746775659223985\n",
      "31 Train Loss 52496.957 Test MSE 7110.785542193999 Test RE 0.14948518476444214\n",
      "32 Train Loss 50601.844 Test MSE 7378.060958270354 Test RE 0.15226864453390088\n",
      "33 Train Loss 49143.79 Test MSE 7261.593554665005 Test RE 0.15106203492260317\n",
      "34 Train Loss 47382.3 Test MSE 7102.21167371931 Test RE 0.14939503629331968\n",
      "35 Train Loss 44688.625 Test MSE 6300.1504794800485 Test RE 0.14070671488242567\n",
      "36 Train Loss 43454.99 Test MSE 6029.046980896925 Test RE 0.1376460319964291\n",
      "37 Train Loss 42093.41 Test MSE 5604.026908381594 Test RE 0.13270566669549824\n",
      "38 Train Loss 40905.57 Test MSE 5336.498371825656 Test RE 0.12949933934796942\n",
      "39 Train Loss 39556.496 Test MSE 5190.84114591121 Test RE 0.12771980048353587\n",
      "40 Train Loss 37878.406 Test MSE 4786.530981139865 Test RE 0.12264498638176209\n",
      "41 Train Loss 36014.94 Test MSE 4589.685477960316 Test RE 0.12009663106782174\n",
      "42 Train Loss 34740.848 Test MSE 4546.087699275701 Test RE 0.11952486640747845\n",
      "43 Train Loss 34143.684 Test MSE 4646.62807172297 Test RE 0.12083933263355176\n",
      "44 Train Loss 33020.36 Test MSE 4720.479951104642 Test RE 0.12179583605164973\n",
      "45 Train Loss 32300.129 Test MSE 4385.771199039675 Test RE 0.11739844589891019\n",
      "46 Train Loss 31917.064 Test MSE 4364.553485574922 Test RE 0.11711412343127207\n",
      "47 Train Loss 31556.066 Test MSE 4236.039095600447 Test RE 0.11537702648048752\n",
      "48 Train Loss 30677.16 Test MSE 4255.800445104926 Test RE 0.11564583335299004\n",
      "49 Train Loss 29479.422 Test MSE 3889.1404402915064 Test RE 0.11055189091662367\n",
      "50 Train Loss 29250.46 Test MSE 3892.6124938729586 Test RE 0.11060122784126934\n",
      "51 Train Loss 28899.424 Test MSE 3721.1611176572237 Test RE 0.10813806630866567\n",
      "52 Train Loss 28607.8 Test MSE 3814.7821757071483 Test RE 0.10948994423665541\n",
      "53 Train Loss 28183.402 Test MSE 3771.6656504229995 Test RE 0.10886943159406262\n",
      "54 Train Loss 27908.166 Test MSE 3776.649865842486 Test RE 0.10894134273343722\n",
      "55 Train Loss 27465.277 Test MSE 3669.379193341632 Test RE 0.10738303124617507\n",
      "56 Train Loss 26838.453 Test MSE 3524.4702464535167 Test RE 0.10524131997018166\n",
      "57 Train Loss 26477.863 Test MSE 3421.389496196878 Test RE 0.1036908945231242\n",
      "58 Train Loss 26200.217 Test MSE 3387.950715872728 Test RE 0.103182941458207\n",
      "59 Train Loss 25831.11 Test MSE 3475.5637429880107 Test RE 0.10450859067684401\n",
      "60 Train Loss 25341.592 Test MSE 3292.5708012830637 Test RE 0.1017201339635736\n",
      "61 Train Loss 24958.05 Test MSE 3127.70466229839 Test RE 0.09914075705969987\n",
      "62 Train Loss 24742.984 Test MSE 2989.908833350489 Test RE 0.09693225928400943\n",
      "63 Train Loss 24673.633 Test MSE 2975.995746302132 Test RE 0.09670646652490106\n",
      "64 Train Loss 24490.598 Test MSE 2941.3804676311142 Test RE 0.09614240112130909\n",
      "65 Train Loss 24414.63 Test MSE 2989.228041999897 Test RE 0.09692122309456731\n",
      "66 Train Loss 24223.69 Test MSE 2904.4515787668356 Test RE 0.09553696322063358\n",
      "67 Train Loss 24057.674 Test MSE 2722.4272838181223 Test RE 0.0924948402142346\n",
      "68 Train Loss 23949.666 Test MSE 2655.2644525324854 Test RE 0.09134678208949887\n",
      "69 Train Loss 23860.764 Test MSE 2574.189131102854 Test RE 0.08994138860153421\n",
      "70 Train Loss 23784.4 Test MSE 2613.918460521853 Test RE 0.09063279643502688\n",
      "71 Train Loss 23489.986 Test MSE 2616.0927802014608 Test RE 0.09067048385950946\n",
      "72 Train Loss 23352.9 Test MSE 2584.1862478891017 Test RE 0.09011586748056663\n",
      "73 Train Loss 23138.758 Test MSE 2429.132102348668 Test RE 0.08737052169967466\n",
      "74 Train Loss 22836.277 Test MSE 2499.0792648467163 Test RE 0.08861951681388015\n",
      "75 Train Loss 22726.928 Test MSE 2512.9800218417677 Test RE 0.08886564147631495\n",
      "76 Train Loss 22674.072 Test MSE 2464.2737414264293 Test RE 0.08800023600597387\n",
      "77 Train Loss 22574.984 Test MSE 2459.229032380343 Test RE 0.08791011553530474\n",
      "78 Train Loss 22486.23 Test MSE 2494.453810885743 Test RE 0.08853746752750528\n",
      "79 Train Loss 22290.28 Test MSE 2475.53835427368 Test RE 0.0882011386729992\n",
      "80 Train Loss 22208.283 Test MSE 2451.7405643001534 Test RE 0.0877761682701812\n",
      "81 Train Loss 22071.982 Test MSE 2381.583034760609 Test RE 0.08651117808862398\n",
      "82 Train Loss 22025.896 Test MSE 2390.3431674497606 Test RE 0.08667013827833912\n",
      "83 Train Loss 21930.93 Test MSE 2325.914200161948 Test RE 0.08549411229237112\n",
      "84 Train Loss 21901.059 Test MSE 2317.1790215705864 Test RE 0.08533342088905643\n",
      "85 Train Loss 21845.744 Test MSE 2290.8063948103845 Test RE 0.08484642647131968\n",
      "86 Train Loss 21668.943 Test MSE 2161.1839766019907 Test RE 0.08241100904046143\n",
      "87 Train Loss 21493.91 Test MSE 2183.3617443994594 Test RE 0.0828327749027842\n",
      "88 Train Loss 21317.834 Test MSE 2270.478312460788 Test RE 0.08446913389197275\n",
      "89 Train Loss 21188.244 Test MSE 2318.969962703584 Test RE 0.08536639149977712\n",
      "90 Train Loss 21113.676 Test MSE 2337.6125735135556 Test RE 0.08570884240230335\n",
      "91 Train Loss 21090.018 Test MSE 2344.8741527416823 Test RE 0.08584186251076063\n",
      "92 Train Loss 21061.662 Test MSE 2373.126493861252 Test RE 0.0863574492683104\n",
      "93 Train Loss 21022.828 Test MSE 2398.838071263785 Test RE 0.08682400771533728\n",
      "94 Train Loss 20962.123 Test MSE 2354.583469962641 Test RE 0.08601939973183703\n",
      "95 Train Loss 20841.26 Test MSE 2391.993640229491 Test RE 0.08670005490745762\n",
      "96 Train Loss 20741.28 Test MSE 2280.462951290166 Test RE 0.08465466057089235\n",
      "97 Train Loss 20690.979 Test MSE 2180.896982910923 Test RE 0.08278600741550944\n",
      "98 Train Loss 20667.871 Test MSE 2151.389991381384 Test RE 0.08222406319844917\n",
      "99 Train Loss 20644.863 Test MSE 2070.3823437428714 Test RE 0.08066119278129041\n",
      "Training time: 268.31\n",
      "3D_HTTP_swish_tune1\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 244054.33 Test MSE 88751.01936537228 Test RE 0.5281120016137919\n",
      "1 Train Loss 240937.19 Test MSE 86595.63977746078 Test RE 0.5216598051156677\n",
      "2 Train Loss 235598.94 Test MSE 82017.46080644446 Test RE 0.5076828842533488\n",
      "3 Train Loss 227845.89 Test MSE 76788.0502199179 Test RE 0.49123147100079484\n",
      "4 Train Loss 217820.81 Test MSE 70149.71316963872 Test RE 0.46951807076689633\n",
      "5 Train Loss 200855.2 Test MSE 60788.655161344075 Test RE 0.4370696295866416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Train Loss 197193.06 Test MSE 55834.31262016501 Test RE 0.4188803127628301\n",
      "7 Train Loss 189716.66 Test MSE 52660.688208516745 Test RE 0.40680157663807165\n",
      "8 Train Loss 175368.88 Test MSE 47159.51139607014 Test RE 0.3849674502698129\n",
      "9 Train Loss 169083.89 Test MSE 44366.65705363272 Test RE 0.373394327109066\n",
      "10 Train Loss 164180.98 Test MSE 40755.36215104771 Test RE 0.3578753127086345\n",
      "11 Train Loss 157615.9 Test MSE 37754.40509396944 Test RE 0.3444476117473963\n",
      "12 Train Loss 154739.25 Test MSE 36083.51441030059 Test RE 0.3367392785192619\n",
      "13 Train Loss 150974.94 Test MSE 33478.3379203601 Test RE 0.3243555298866805\n",
      "14 Train Loss 140446.83 Test MSE 30841.23703226405 Test RE 0.3113187347768621\n",
      "15 Train Loss 133840.81 Test MSE 27419.02137707828 Test RE 0.29353868022951474\n",
      "16 Train Loss 124049.18 Test MSE 22505.807510797382 Test RE 0.26594183572392055\n",
      "17 Train Loss 110433.99 Test MSE 18950.73046268448 Test RE 0.24403512436432365\n",
      "18 Train Loss 90083.84 Test MSE 13741.986623658773 Test RE 0.20780889015985887\n",
      "19 Train Loss 70722.01 Test MSE 9362.115499996027 Test RE 0.171524578016223\n",
      "20 Train Loss 62065.96 Test MSE 8530.834792708574 Test RE 0.16373258857327833\n",
      "21 Train Loss 60207.98 Test MSE 7840.336049977055 Test RE 0.15696640113117502\n",
      "22 Train Loss 57029.848 Test MSE 6622.093864632588 Test RE 0.1442570438833198\n",
      "23 Train Loss 54353.844 Test MSE 6072.881364478886 Test RE 0.13814550577290932\n",
      "24 Train Loss 51506.688 Test MSE 5064.069384272622 Test RE 0.12615056092168456\n",
      "25 Train Loss 49138.29 Test MSE 5253.888152326957 Test RE 0.1284930901708728\n",
      "26 Train Loss 45921.258 Test MSE 5867.290915048285 Test RE 0.1357869937194483\n",
      "27 Train Loss 45188.484 Test MSE 5793.28848731868 Test RE 0.13492795556606751\n",
      "28 Train Loss 44912.754 Test MSE 5595.214097699898 Test RE 0.13260128014574288\n",
      "29 Train Loss 44259.273 Test MSE 5904.016747374576 Test RE 0.1362113046156352\n",
      "30 Train Loss 42516.48 Test MSE 5609.384291440465 Test RE 0.1327690840619036\n",
      "31 Train Loss 41502.02 Test MSE 5106.37214496002 Test RE 0.12667636519373948\n",
      "32 Train Loss 40881.605 Test MSE 4731.774832065133 Test RE 0.1219414618738259\n",
      "33 Train Loss 40500.406 Test MSE 4789.991284117106 Test RE 0.12268930993681507\n",
      "34 Train Loss 39864.93 Test MSE 4753.219370706135 Test RE 0.12221747060092933\n",
      "35 Train Loss 39355.133 Test MSE 5014.602517011129 Test RE 0.12553291663894517\n",
      "36 Train Loss 38626.17 Test MSE 5208.268818500335 Test RE 0.12793402334883547\n",
      "37 Train Loss 38462.914 Test MSE 5377.119323734956 Test RE 0.12999127372050162\n",
      "38 Train Loss 38051.348 Test MSE 4944.878050090184 Test RE 0.12465713893724345\n",
      "39 Train Loss 37543.234 Test MSE 4910.858037119076 Test RE 0.12422758772079862\n",
      "40 Train Loss 37205.42 Test MSE 4892.747932553681 Test RE 0.12399831489500171\n",
      "41 Train Loss 36656.402 Test MSE 5066.829866487114 Test RE 0.1261849392950215\n",
      "42 Train Loss 36470.895 Test MSE 5023.112162975585 Test RE 0.12563938448600168\n",
      "43 Train Loss 36301.0 Test MSE 4961.932662687844 Test RE 0.12487192171333569\n",
      "44 Train Loss 36203.176 Test MSE 4960.837016668506 Test RE 0.12485813444669462\n",
      "45 Train Loss 36155.766 Test MSE 4838.888889639315 Test RE 0.12331394371509544\n",
      "46 Train Loss 36016.094 Test MSE 4699.396651151263 Test RE 0.12152354045582932\n",
      "47 Train Loss 35883.16 Test MSE 4839.998613912359 Test RE 0.12332808297668785\n",
      "48 Train Loss 35780.676 Test MSE 4916.716470221299 Test RE 0.12430166460146427\n",
      "49 Train Loss 35713.64 Test MSE 4970.6971453478545 Test RE 0.12498215647514603\n",
      "50 Train Loss 35531.707 Test MSE 5079.400221995216 Test RE 0.12634136915432717\n",
      "51 Train Loss 35330.723 Test MSE 5024.11717183712 Test RE 0.1256519526285633\n",
      "52 Train Loss 35215.047 Test MSE 5158.60093373201 Test RE 0.1273225501108467\n",
      "53 Train Loss 34979.01 Test MSE 5375.208875991759 Test RE 0.12996817923599008\n",
      "54 Train Loss 34444.97 Test MSE 5172.577659767172 Test RE 0.1274949174516337\n",
      "55 Train Loss 34103.684 Test MSE 4932.316961187804 Test RE 0.12449870984735747\n",
      "56 Train Loss 34034.938 Test MSE 5011.295930716325 Test RE 0.125491522144684\n",
      "57 Train Loss 33986.586 Test MSE 5089.042168285059 Test RE 0.12646122574082608\n",
      "58 Train Loss 33777.723 Test MSE 4915.677900795106 Test RE 0.1242885356436233\n",
      "59 Train Loss 33662.23 Test MSE 4825.835446221843 Test RE 0.12314750482204197\n",
      "60 Train Loss 33615.29 Test MSE 4824.882016330197 Test RE 0.1231353392277843\n",
      "61 Train Loss 33495.254 Test MSE 4835.025295480217 Test RE 0.12326470408762057\n",
      "62 Train Loss 33413.918 Test MSE 4803.315695596774 Test RE 0.12285983504515696\n",
      "63 Train Loss 33361.74 Test MSE 4861.18313872298 Test RE 0.12359768989320818\n",
      "64 Train Loss 33332.45 Test MSE 4887.457647423316 Test RE 0.12393126015727184\n",
      "65 Train Loss 33298.098 Test MSE 4804.53327893115 Test RE 0.12287540581109684\n",
      "66 Train Loss 33229.56 Test MSE 4741.390370372914 Test RE 0.12206529888656863\n",
      "67 Train Loss 33156.61 Test MSE 4780.652944639657 Test RE 0.1225696569655417\n",
      "68 Train Loss 33095.395 Test MSE 4762.487984913139 Test RE 0.12233657249904208\n",
      "69 Train Loss 33050.34 Test MSE 4715.283202447881 Test RE 0.12172877542957944\n",
      "70 Train Loss 32993.164 Test MSE 4665.212267376322 Test RE 0.12108074003940067\n",
      "71 Train Loss 32933.254 Test MSE 4700.069937564234 Test RE 0.12153224553270606\n",
      "72 Train Loss 32811.32 Test MSE 4775.129339366503 Test RE 0.12249882751139639\n",
      "73 Train Loss 32664.8 Test MSE 4726.099682727555 Test RE 0.12186831346149642\n",
      "74 Train Loss 32601.893 Test MSE 4716.598377730413 Test RE 0.1217457503924817\n",
      "75 Train Loss 32556.664 Test MSE 4747.10915202674 Test RE 0.12213889063636854\n",
      "76 Train Loss 32491.49 Test MSE 4862.564385017726 Test RE 0.12361524803915043\n",
      "77 Train Loss 32393.268 Test MSE 4842.291992267534 Test RE 0.12335729832174172\n",
      "78 Train Loss 32330.396 Test MSE 4759.41342113708 Test RE 0.12229707714275113\n",
      "79 Train Loss 32310.463 Test MSE 4798.492706429498 Test RE 0.12279813803100464\n",
      "80 Train Loss 32289.781 Test MSE 4771.412207733744 Test RE 0.12245113949260908\n",
      "81 Train Loss 32279.592 Test MSE 4741.718617406518 Test RE 0.12206952411120625\n",
      "82 Train Loss 32257.092 Test MSE 4724.599004995545 Test RE 0.12184896351156943\n",
      "83 Train Loss 32248.428 Test MSE 4744.919192976177 Test RE 0.12211071453843007\n",
      "84 Train Loss 32224.938 Test MSE 4718.263489234613 Test RE 0.12176723858638668\n",
      "85 Train Loss 32151.55 Test MSE 4709.691042488615 Test RE 0.12165657099308158\n",
      "86 Train Loss 32090.652 Test MSE 4617.84461614592 Test RE 0.1204644826748296\n",
      "87 Train Loss 32014.846 Test MSE 4552.47440160445 Test RE 0.1196087959168475\n",
      "88 Train Loss 31936.363 Test MSE 4587.502153968701 Test RE 0.12006806254737955\n",
      "89 Train Loss 31890.924 Test MSE 4549.116110846423 Test RE 0.11956467098781944\n",
      "90 Train Loss 31863.344 Test MSE 4504.704240151985 Test RE 0.11897959967959734\n",
      "91 Train Loss 31847.193 Test MSE 4523.899244060151 Test RE 0.11923282231508263\n",
      "92 Train Loss 31834.75 Test MSE 4561.324750787151 Test RE 0.11972500366739695\n",
      "93 Train Loss 31815.61 Test MSE 4563.734145710909 Test RE 0.11975662022053547\n",
      "94 Train Loss 31781.105 Test MSE 4581.472949180059 Test RE 0.1199891358325508\n",
      "95 Train Loss 31713.084 Test MSE 4599.036940613503 Test RE 0.12021891697178115\n",
      "96 Train Loss 31640.643 Test MSE 4611.828194291284 Test RE 0.12038598270049264\n",
      "97 Train Loss 31615.062 Test MSE 4603.711314551634 Test RE 0.12027999556973207\n",
      "98 Train Loss 31541.29 Test MSE 4665.6289071091915 Test RE 0.12108614664450419\n",
      "99 Train Loss 31501.926 Test MSE 4596.672314052572 Test RE 0.12018800730553182\n",
      "Training time: 271.67\n",
      "3D_HTTP_swish_tune2\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 250455.5 Test MSE 90740.14897759797 Test RE 0.5339973553673072\n",
      "1 Train Loss 241237.86 Test MSE 84928.01740935976 Test RE 0.5166124345149694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Train Loss 218355.81 Test MSE 71633.09202817702 Test RE 0.47445629276278395\n",
      "3 Train Loss 196155.05 Test MSE 57652.52978273278 Test RE 0.4256459903325005\n",
      "4 Train Loss 190744.77 Test MSE 54203.231683026585 Test RE 0.412716614638069\n",
      "5 Train Loss 186673.11 Test MSE 50771.69212296635 Test RE 0.39943873818535075\n",
      "6 Train Loss 181811.78 Test MSE 48862.61182117045 Test RE 0.3918570826485024\n",
      "7 Train Loss 179860.2 Test MSE 46987.134805968446 Test RE 0.384263243160946\n",
      "8 Train Loss 178880.53 Test MSE 46007.71913332634 Test RE 0.38023729686604196\n",
      "9 Train Loss 177356.64 Test MSE 45029.18399016309 Test RE 0.3761719432616066\n",
      "10 Train Loss 173209.61 Test MSE 43108.971908646046 Test RE 0.3680638757895159\n",
      "11 Train Loss 167524.45 Test MSE 41523.6457723475 Test RE 0.36123273638905035\n",
      "12 Train Loss 162119.25 Test MSE 39260.657839852734 Test RE 0.3512514682731524\n",
      "13 Train Loss 158311.38 Test MSE 36857.36503598844 Test RE 0.3403309955620752\n",
      "14 Train Loss 151808.4 Test MSE 34470.72334551571 Test RE 0.329127795323595\n",
      "15 Train Loss 148122.11 Test MSE 32892.83179871934 Test RE 0.32150667522612153\n",
      "16 Train Loss 145006.75 Test MSE 31322.424729176455 Test RE 0.31373794627252655\n",
      "17 Train Loss 141092.55 Test MSE 29656.809563178456 Test RE 0.3052822658393579\n",
      "18 Train Loss 137407.02 Test MSE 28262.749045781373 Test RE 0.29802079118665314\n",
      "19 Train Loss 131305.52 Test MSE 27387.961966699306 Test RE 0.2933723773995988\n",
      "20 Train Loss 125599.88 Test MSE 25002.349324548 Test RE 0.28030430739704965\n",
      "21 Train Loss 116673.86 Test MSE 21136.947528655906 Test RE 0.2577273432150323\n",
      "22 Train Loss 110510.19 Test MSE 20093.842864419596 Test RE 0.25128748692206154\n",
      "23 Train Loss 103921.55 Test MSE 18967.358101522736 Test RE 0.24414216082481988\n",
      "24 Train Loss 99007.984 Test MSE 17583.26497119153 Test RE 0.2350656240234533\n",
      "25 Train Loss 94427.055 Test MSE 16381.416224320017 Test RE 0.2268898587677371\n",
      "26 Train Loss 92199.63 Test MSE 15615.229721951999 Test RE 0.22152031028156163\n",
      "27 Train Loss 89106.54 Test MSE 15378.58990567645 Test RE 0.21983539605262561\n",
      "28 Train Loss 85911.61 Test MSE 14580.994744499185 Test RE 0.2140587272725343\n",
      "29 Train Loss 83017.17 Test MSE 12958.893350231061 Test RE 0.20180100281320873\n",
      "30 Train Loss 78537.77 Test MSE 11345.08910243099 Test RE 0.1888179672077932\n",
      "31 Train Loss 76146.73 Test MSE 10086.68984825685 Test RE 0.17803840534717358\n",
      "32 Train Loss 74238.97 Test MSE 9865.94002927426 Test RE 0.1760794195263448\n",
      "33 Train Loss 72535.516 Test MSE 9728.4328842623 Test RE 0.17484805505557374\n",
      "34 Train Loss 69719.27 Test MSE 9313.29401526659 Test RE 0.171076760938856\n",
      "35 Train Loss 65740.38 Test MSE 9127.162705461964 Test RE 0.16935860138124106\n",
      "36 Train Loss 61970.957 Test MSE 8098.418931731915 Test RE 0.15952894082395688\n",
      "37 Train Loss 60217.703 Test MSE 7299.137863068834 Test RE 0.15145204626587538\n",
      "38 Train Loss 57364.652 Test MSE 7007.51908507922 Test RE 0.14839576494488413\n",
      "39 Train Loss 54161.84 Test MSE 6620.311028443241 Test RE 0.14423762374247828\n",
      "40 Train Loss 52425.86 Test MSE 6088.805188165357 Test RE 0.13832650424748927\n",
      "41 Train Loss 50463.21 Test MSE 5663.232422062987 Test RE 0.13340483039499926\n",
      "42 Train Loss 46896.18 Test MSE 5440.115472368868 Test RE 0.13075051895782122\n",
      "43 Train Loss 44197.47 Test MSE 5068.6508818318025 Test RE 0.12620761265039057\n",
      "44 Train Loss 43246.46 Test MSE 4764.1694156546855 Test RE 0.1223581664979836\n",
      "45 Train Loss 42811.72 Test MSE 4714.764115437726 Test RE 0.12172207492374605\n",
      "46 Train Loss 42280.414 Test MSE 4717.397007909272 Test RE 0.1217560571545964\n",
      "47 Train Loss 41620.97 Test MSE 4799.893263268452 Test RE 0.12281605753561002\n",
      "48 Train Loss 41251.66 Test MSE 4764.106162375806 Test RE 0.12235735422828424\n",
      "49 Train Loss 40965.12 Test MSE 4805.035138136024 Test RE 0.12288182314027568\n",
      "50 Train Loss 40671.34 Test MSE 4777.952529118271 Test RE 0.12253503452358165\n",
      "51 Train Loss 40306.53 Test MSE 4525.39036830696 Test RE 0.11925247088534864\n",
      "52 Train Loss 39997.793 Test MSE 4456.864012330641 Test RE 0.11834612808980757\n",
      "53 Train Loss 39533.766 Test MSE 4485.1086522374435 Test RE 0.11872053536523877\n",
      "54 Train Loss 39199.605 Test MSE 4504.14947544934 Test RE 0.1189722731481503\n",
      "55 Train Loss 38959.992 Test MSE 4581.1646731981145 Test RE 0.11998509887856891\n",
      "56 Train Loss 38555.492 Test MSE 4714.87004434636 Test RE 0.12172344231072608\n",
      "57 Train Loss 38262.43 Test MSE 4589.703336701833 Test RE 0.12009686471919229\n",
      "58 Train Loss 37862.652 Test MSE 4382.080666544226 Test RE 0.11734904136507297\n",
      "59 Train Loss 37540.043 Test MSE 4257.434526239547 Test RE 0.11566803323530986\n",
      "60 Train Loss 37266.434 Test MSE 4208.25381321789 Test RE 0.11499800997568131\n",
      "61 Train Loss 36748.08 Test MSE 4338.061726956626 Test RE 0.11675815558911373\n",
      "62 Train Loss 36129.81 Test MSE 4367.2447922968195 Test RE 0.1171502258017519\n",
      "63 Train Loss 35868.54 Test MSE 4213.421520203303 Test RE 0.11506859669835019\n",
      "64 Train Loss 35495.0 Test MSE 4182.928129068896 Test RE 0.11465145313467252\n",
      "65 Train Loss 35187.793 Test MSE 4212.575312474025 Test RE 0.11505704114606322\n",
      "66 Train Loss 34906.34 Test MSE 4108.720257320557 Test RE 0.11362990637515033\n",
      "67 Train Loss 34667.906 Test MSE 4078.2310949823877 Test RE 0.1132075203848545\n",
      "68 Train Loss 34488.094 Test MSE 4127.115151818681 Test RE 0.11388398498648772\n",
      "69 Train Loss 34318.82 Test MSE 4130.801255120883 Test RE 0.11393483096810353\n",
      "70 Train Loss 34022.535 Test MSE 4274.317345003145 Test RE 0.11589714660201803\n",
      "71 Train Loss 33822.117 Test MSE 4376.954375202042 Test RE 0.11728038203906953\n",
      "72 Train Loss 33525.543 Test MSE 4379.138937707172 Test RE 0.11730964603666938\n",
      "73 Train Loss 33224.637 Test MSE 4356.291168669567 Test RE 0.11700321948841988\n",
      "74 Train Loss 33004.86 Test MSE 4222.248989295724 Test RE 0.11518907277756343\n",
      "75 Train Loss 32829.273 Test MSE 4118.613605007387 Test RE 0.11376662829693013\n",
      "76 Train Loss 32627.9 Test MSE 4222.121206186384 Test RE 0.11518732971014996\n",
      "77 Train Loss 32472.719 Test MSE 4232.292018572924 Test RE 0.1153259856090667\n",
      "78 Train Loss 32142.41 Test MSE 4219.686903674042 Test RE 0.11515411876937227\n",
      "79 Train Loss 31811.693 Test MSE 4213.204048581566 Test RE 0.11506562708361755\n",
      "80 Train Loss 31616.846 Test MSE 4224.0134919484435 Test RE 0.11521313935848282\n",
      "81 Train Loss 31428.521 Test MSE 4202.69714686785 Test RE 0.11492206200780856\n",
      "82 Train Loss 31287.406 Test MSE 4241.658518999678 Test RE 0.1154535292544482\n",
      "83 Train Loss 31169.363 Test MSE 4310.606082394087 Test RE 0.11638808723623481\n",
      "84 Train Loss 30977.207 Test MSE 4473.498644942762 Test RE 0.11856677772740053\n",
      "85 Train Loss 30798.059 Test MSE 4451.32127227306 Test RE 0.11827251513064792\n",
      "86 Train Loss 30708.758 Test MSE 4471.034944046247 Test RE 0.11853412394454638\n",
      "87 Train Loss 30612.527 Test MSE 4537.765080240877 Test RE 0.11941540793534003\n",
      "88 Train Loss 30533.66 Test MSE 4504.049947820305 Test RE 0.11897095868315032\n",
      "89 Train Loss 30439.52 Test MSE 4567.0193289478475 Test RE 0.11979971559521496\n",
      "90 Train Loss 30200.994 Test MSE 4606.064163140714 Test RE 0.12031072778218349\n",
      "91 Train Loss 30116.93 Test MSE 4507.115025209363 Test RE 0.11901143261020797\n",
      "92 Train Loss 30082.518 Test MSE 4493.832988079947 Test RE 0.11883594557133205\n",
      "93 Train Loss 30026.7 Test MSE 4535.158589780929 Test RE 0.11938110692756472\n",
      "94 Train Loss 29923.936 Test MSE 4458.6212002997245 Test RE 0.11836945569172906\n",
      "95 Train Loss 29890.451 Test MSE 4448.674526554259 Test RE 0.1182373476151419\n",
      "96 Train Loss 29858.336 Test MSE 4465.467175097133 Test RE 0.11846029582466437\n",
      "97 Train Loss 29788.701 Test MSE 4482.593526185573 Test RE 0.1186872430854351\n",
      "98 Train Loss 29752.916 Test MSE 4487.553560541634 Test RE 0.11875288923886332\n",
      "99 Train Loss 29696.062 Test MSE 4516.8742682656275 Test RE 0.11914021049176797\n",
      "Training time: 241.98\n",
      "3D_HTTP_swish_tune2\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 242985.86 Test MSE 88363.74028157447 Test RE 0.5269584918124026\n",
      "1 Train Loss 237568.06 Test MSE 83062.83022764123 Test RE 0.5109080253587357\n",
      "2 Train Loss 219193.73 Test MSE 73346.60781493042 Test RE 0.4800974273310164\n",
      "3 Train Loss 194910.36 Test MSE 58354.45618695377 Test RE 0.4282292963746053\n",
      "4 Train Loss 184693.44 Test MSE 52205.004229858285 Test RE 0.40503768283465064\n",
      "5 Train Loss 178708.69 Test MSE 48168.69272276454 Test RE 0.389064667108394\n",
      "6 Train Loss 173844.1 Test MSE 45607.23370721252 Test RE 0.3785787454591234\n",
      "7 Train Loss 171785.53 Test MSE 44783.49668241777 Test RE 0.3751443087940521\n",
      "8 Train Loss 170206.83 Test MSE 42549.153418231384 Test RE 0.36566620452026294\n",
      "9 Train Loss 167815.5 Test MSE 42613.844483638095 Test RE 0.3659440755233504\n",
      "10 Train Loss 165528.97 Test MSE 41533.76166700411 Test RE 0.3612767350518664\n",
      "11 Train Loss 162033.67 Test MSE 39760.24611721568 Test RE 0.35347922506719665\n",
      "12 Train Loss 155355.12 Test MSE 37707.11428706023 Test RE 0.34423181825813465\n",
      "13 Train Loss 147516.23 Test MSE 34810.57618324625 Test RE 0.33074627987595967\n",
      "14 Train Loss 135878.7 Test MSE 30143.92854564161 Test RE 0.3077792152771966\n",
      "15 Train Loss 130091.555 Test MSE 26754.69778419738 Test RE 0.2899608652449957\n",
      "16 Train Loss 121459.445 Test MSE 23638.569958083386 Test RE 0.27255236957136686\n",
      "17 Train Loss 117261.98 Test MSE 22478.271552088598 Test RE 0.2657790954024486\n",
      "18 Train Loss 110585.77 Test MSE 19646.651624377628 Test RE 0.24847553498649902\n",
      "19 Train Loss 101099.05 Test MSE 14096.943697374365 Test RE 0.21047564292341667\n",
      "20 Train Loss 87996.66 Test MSE 12426.831521397511 Test RE 0.19761484560377265\n",
      "21 Train Loss 81071.66 Test MSE 11583.206566041938 Test RE 0.19078918940448208\n",
      "22 Train Loss 77606.6 Test MSE 10183.191762757631 Test RE 0.17888804724071977\n",
      "23 Train Loss 75113.26 Test MSE 9343.060339029813 Test RE 0.17134993302089313\n",
      "24 Train Loss 72509.19 Test MSE 8512.318871046438 Test RE 0.1635548037095075\n",
      "25 Train Loss 71399.15 Test MSE 8285.780848676844 Test RE 0.16136378913959168\n",
      "26 Train Loss 68009.1 Test MSE 7347.408883563142 Test RE 0.15195201611324788\n",
      "27 Train Loss 66363.52 Test MSE 6964.796743985019 Test RE 0.1479427153795308\n",
      "28 Train Loss 63939.184 Test MSE 6874.6474652548095 Test RE 0.14698214409506108\n",
      "29 Train Loss 62464.496 Test MSE 6955.530625143677 Test RE 0.14784426950305912\n",
      "30 Train Loss 60087.71 Test MSE 6357.141524152687 Test RE 0.14134169727534718\n",
      "31 Train Loss 57912.137 Test MSE 6490.445794995392 Test RE 0.14281592129752235\n",
      "32 Train Loss 57246.65 Test MSE 6557.260013725011 Test RE 0.14354912998893668\n",
      "33 Train Loss 54866.754 Test MSE 5544.207571263648 Test RE 0.13199549317327136\n",
      "34 Train Loss 52689.27 Test MSE 5132.359404540472 Test RE 0.1269982956910216\n",
      "35 Train Loss 51745.438 Test MSE 5153.294372817661 Test RE 0.1272570460408475\n",
      "36 Train Loss 51047.26 Test MSE 4918.677522581835 Test RE 0.12432645124237941\n",
      "37 Train Loss 50453.652 Test MSE 4977.536058124684 Test RE 0.12506810500968385\n",
      "38 Train Loss 49596.477 Test MSE 5097.529911735409 Test RE 0.12656664078981364\n",
      "39 Train Loss 48894.938 Test MSE 4935.893596065604 Test RE 0.12454384134808633\n",
      "40 Train Loss 48074.234 Test MSE 4966.132389869134 Test RE 0.12492475567127138\n",
      "41 Train Loss 47295.953 Test MSE 4959.862953945121 Test RE 0.12484587586768138\n",
      "42 Train Loss 46587.062 Test MSE 4992.791805252157 Test RE 0.12525962021172035\n",
      "43 Train Loss 45865.074 Test MSE 4974.8921552962 Test RE 0.12503488457347184\n",
      "44 Train Loss 45435.2 Test MSE 4922.991352344866 Test RE 0.12438095833314221\n",
      "45 Train Loss 44976.707 Test MSE 4716.573694663159 Test RE 0.12174543183000977\n",
      "46 Train Loss 44523.11 Test MSE 4520.585916906422 Test RE 0.11918915095012872\n",
      "47 Train Loss 43875.887 Test MSE 4456.678150013668 Test RE 0.11834366040010036\n",
      "48 Train Loss 43149.29 Test MSE 4345.798369715186 Test RE 0.11686222438798548\n",
      "49 Train Loss 42135.027 Test MSE 4395.278119170248 Test RE 0.11752561777117759\n",
      "50 Train Loss 41442.383 Test MSE 4731.962344941828 Test RE 0.12194387802512095\n",
      "51 Train Loss 40965.582 Test MSE 4932.28917970785 Test RE 0.12449835922478905\n",
      "52 Train Loss 39933.234 Test MSE 5206.399120025262 Test RE 0.1279110579905008\n",
      "53 Train Loss 39149.977 Test MSE 5359.429761656845 Test RE 0.12977727595607003\n",
      "54 Train Loss 38645.863 Test MSE 5384.8561765776585 Test RE 0.1300847588920747\n",
      "55 Train Loss 38450.71 Test MSE 5509.6306189945735 Test RE 0.1315832484983008\n",
      "56 Train Loss 38242.14 Test MSE 5790.641609364853 Test RE 0.13489712863297504\n",
      "57 Train Loss 38015.316 Test MSE 5810.302890909534 Test RE 0.1351259463604112\n",
      "58 Train Loss 37622.66 Test MSE 5412.188669666522 Test RE 0.13041448361091557\n",
      "59 Train Loss 37284.637 Test MSE 5428.171231528111 Test RE 0.13060690308615422\n",
      "60 Train Loss 37025.305 Test MSE 5229.929372516753 Test RE 0.1281997783152327\n",
      "61 Train Loss 36824.45 Test MSE 4921.705927577937 Test RE 0.12436471893814088\n",
      "62 Train Loss 36526.863 Test MSE 4713.471673957895 Test RE 0.12170539016099131\n",
      "63 Train Loss 36352.766 Test MSE 4837.205069422565 Test RE 0.12329248666341984\n",
      "64 Train Loss 36170.195 Test MSE 4992.0861668476755 Test RE 0.12525076833833754\n",
      "65 Train Loss 36058.188 Test MSE 4917.483899164311 Test RE 0.1243113650767296\n",
      "66 Train Loss 35851.355 Test MSE 4917.022026507853 Test RE 0.1243055269926758\n",
      "67 Train Loss 35444.836 Test MSE 5152.76924438915 Test RE 0.12725056203369778\n",
      "68 Train Loss 35119.14 Test MSE 5464.657477911778 Test RE 0.13104511463881044\n",
      "69 Train Loss 34807.35 Test MSE 5656.243247155476 Test RE 0.13332248541299885\n",
      "70 Train Loss 34535.55 Test MSE 5411.476837829043 Test RE 0.13040590702205165\n",
      "71 Train Loss 34134.008 Test MSE 4988.228722935347 Test RE 0.12520236761294218\n",
      "72 Train Loss 33964.977 Test MSE 4742.7810943764325 Test RE 0.122083199405348\n",
      "73 Train Loss 33634.61 Test MSE 4623.475999388603 Test RE 0.12053791249249554\n",
      "74 Train Loss 33413.438 Test MSE 4520.426572463229 Test RE 0.11918705030470285\n",
      "75 Train Loss 33163.145 Test MSE 4499.706265933357 Test RE 0.11891357736439814\n",
      "76 Train Loss 32687.39 Test MSE 4509.055831068149 Test RE 0.11903705357000179\n",
      "77 Train Loss 32563.162 Test MSE 4528.091408459683 Test RE 0.11928805429771944\n",
      "78 Train Loss 32499.32 Test MSE 4523.066011592502 Test RE 0.11922184138597187\n",
      "79 Train Loss 32398.559 Test MSE 4571.793279519908 Test RE 0.11986231315609787\n",
      "80 Train Loss 32250.576 Test MSE 4549.283296053022 Test RE 0.11956686803666128\n",
      "81 Train Loss 32064.234 Test MSE 4398.089181619366 Test RE 0.11756319435169817\n",
      "82 Train Loss 31939.959 Test MSE 4412.284198033258 Test RE 0.11775276157437083\n",
      "83 Train Loss 31848.154 Test MSE 4507.897844038854 Test RE 0.11902176741915836\n",
      "84 Train Loss 31795.197 Test MSE 4458.4133382056025 Test RE 0.11836669645197662\n",
      "85 Train Loss 31752.805 Test MSE 4382.505719383635 Test RE 0.1173547325352653\n",
      "86 Train Loss 31697.855 Test MSE 4407.825776171181 Test RE 0.11769325450838375\n",
      "87 Train Loss 31650.799 Test MSE 4488.42705476591 Test RE 0.11876444619459049\n",
      "88 Train Loss 31549.33 Test MSE 4486.864873940194 Test RE 0.11874377662766161\n",
      "89 Train Loss 31348.988 Test MSE 4576.360391546547 Test RE 0.1199221680019669\n",
      "90 Train Loss 31219.215 Test MSE 4598.504031696128 Test RE 0.1202119516451579\n",
      "91 Train Loss 31174.598 Test MSE 4640.868399040019 Test RE 0.12076441693077657\n",
      "92 Train Loss 31108.111 Test MSE 4623.419137819447 Test RE 0.12053717127572258\n",
      "93 Train Loss 31063.562 Test MSE 4582.396770772435 Test RE 0.12000123270274612\n",
      "94 Train Loss 31035.818 Test MSE 4537.724364502157 Test RE 0.11941487219832313\n",
      "95 Train Loss 30975.793 Test MSE 4518.354373042265 Test RE 0.11915972902832771\n",
      "96 Train Loss 30919.785 Test MSE 4530.647332510488 Test RE 0.1193217161838113\n",
      "97 Train Loss 30883.598 Test MSE 4515.017660229744 Test RE 0.1191157223840853\n",
      "98 Train Loss 30845.24 Test MSE 4504.143121869638 Test RE 0.11897218923662713\n",
      "99 Train Loss 30796.854 Test MSE 4532.535825226033 Test RE 0.11934658180437914\n",
      "Training time: 270.98\n",
      "3D_HTTP_swish_tune2\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.94\n",
      "3D_HTTP_swish_tune2\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 247111.1 Test MSE 87438.98118481926 Test RE 0.5241938321137184\n",
      "1 Train Loss 246985.12 Test MSE 87353.78892150379 Test RE 0.5239384074671717\n",
      "2 Train Loss 239450.16 Test MSE 83602.46591909733 Test RE 0.5125649509682509\n",
      "3 Train Loss 213100.22 Test MSE 66390.45416096726 Test RE 0.4567643307236271\n",
      "4 Train Loss 192741.3 Test MSE 54239.86982360539 Test RE 0.412856076940304\n",
      "5 Train Loss 189438.5 Test MSE 51435.35429921788 Test RE 0.4020408940172029\n",
      "6 Train Loss 183088.47 Test MSE 48114.23844983933 Test RE 0.3888446878701294\n",
      "7 Train Loss 172347.62 Test MSE 44236.18178816527 Test RE 0.3728448762550157\n",
      "8 Train Loss 165665.94 Test MSE 41116.543216535756 Test RE 0.3594575912814163\n",
      "9 Train Loss 162006.56 Test MSE 39127.9418382498 Test RE 0.3506572837221289\n",
      "10 Train Loss 158760.89 Test MSE 37260.81614680853 Test RE 0.34218860543979546\n",
      "11 Train Loss 152775.39 Test MSE 34564.7352310218 Test RE 0.32957630428103063\n",
      "12 Train Loss 146500.84 Test MSE 31810.893904372282 Test RE 0.3161748337015281\n",
      "13 Train Loss 141329.36 Test MSE 26174.95632445111 Test RE 0.2868021119411872\n",
      "14 Train Loss 117293.914 Test MSE 22898.69329957229 Test RE 0.26825307706231993\n",
      "15 Train Loss 96604.695 Test MSE 16701.168183257163 Test RE 0.22909351037773784\n",
      "16 Train Loss 88352.31 Test MSE 14919.49534397441 Test RE 0.21652917881060782\n",
      "17 Train Loss 78513.06 Test MSE 10574.757477255593 Test RE 0.18229492160928934\n",
      "18 Train Loss 66478.336 Test MSE 8926.14588138286 Test RE 0.1674832394341881\n",
      "19 Train Loss 59322.445 Test MSE 7571.474886640514 Test RE 0.1542515743508847\n",
      "20 Train Loss 57105.133 Test MSE 7086.860289751678 Test RE 0.14923349075546616\n",
      "21 Train Loss 53690.85 Test MSE 6578.108041155378 Test RE 0.14377714757716148\n",
      "22 Train Loss 50378.15 Test MSE 6066.514170406314 Test RE 0.13807306652450635\n",
      "23 Train Loss 45938.996 Test MSE 5109.929945635569 Test RE 0.12672048759308546\n",
      "24 Train Loss 43418.285 Test MSE 5519.636529631005 Test RE 0.1317026769221545\n",
      "25 Train Loss 41330.598 Test MSE 5925.576701719402 Test RE 0.13645978234621786\n",
      "26 Train Loss 40309.914 Test MSE 5297.869110369924 Test RE 0.12902978522977193\n",
      "27 Train Loss 39953.477 Test MSE 4889.047263048845 Test RE 0.12395141245995582\n",
      "28 Train Loss 39160.562 Test MSE 4595.609804605184 Test RE 0.12017411592228877\n",
      "29 Train Loss 38775.848 Test MSE 4776.706733212306 Test RE 0.12251905868504179\n",
      "30 Train Loss 38062.01 Test MSE 4705.975607457187 Test RE 0.12160857461042024\n",
      "31 Train Loss 36769.8 Test MSE 4355.199392976472 Test RE 0.11698855686937625\n",
      "32 Train Loss 35691.82 Test MSE 4224.164579437469 Test RE 0.11521519985240707\n",
      "33 Train Loss 35247.383 Test MSE 4073.26470556144 Test RE 0.11313856844321993\n",
      "34 Train Loss 34986.832 Test MSE 4305.816432942711 Test RE 0.11632340803963112\n",
      "35 Train Loss 34616.086 Test MSE 4306.305226302372 Test RE 0.116330010329438\n",
      "36 Train Loss 34523.676 Test MSE 4200.234589476456 Test RE 0.11488838796093434\n",
      "37 Train Loss 33824.266 Test MSE 4646.721710026949 Test RE 0.12084055019744779\n",
      "38 Train Loss 32784.496 Test MSE 4437.484097413448 Test RE 0.1180885437673797\n",
      "39 Train Loss 32603.99 Test MSE 4324.021000593937 Test RE 0.11656905062957512\n",
      "40 Train Loss 32339.693 Test MSE 4105.962310698065 Test RE 0.11359176337637233\n",
      "41 Train Loss 32026.475 Test MSE 4031.067772484747 Test RE 0.11255101402225798\n",
      "42 Train Loss 31859.441 Test MSE 4149.2204956828045 Test RE 0.11418856610632525\n",
      "43 Train Loss 31721.404 Test MSE 4066.7639508612315 Test RE 0.11304825025631317\n",
      "44 Train Loss 31306.334 Test MSE 4105.4368602775185 Test RE 0.11358449483065619\n",
      "45 Train Loss 30857.064 Test MSE 4168.210720087536 Test RE 0.11444957790239996\n",
      "46 Train Loss 30582.982 Test MSE 3986.7968569530644 Test RE 0.11193126598067141\n",
      "47 Train Loss 30502.846 Test MSE 3888.071419813032 Test RE 0.11053669599636598\n",
      "48 Train Loss 30345.28 Test MSE 3936.0917257123256 Test RE 0.11121720266083375\n",
      "49 Train Loss 30217.188 Test MSE 4119.109400354101 Test RE 0.11377347565783072\n",
      "50 Train Loss 30107.658 Test MSE 4148.635654392953 Test RE 0.11418051826435165\n",
      "51 Train Loss 30039.236 Test MSE 4186.984531923008 Test RE 0.11470703140075474\n",
      "52 Train Loss 30001.771 Test MSE 4211.9379229527385 Test RE 0.1150483363845808\n",
      "53 Train Loss 29975.637 Test MSE 4193.631129322022 Test RE 0.11479804070823713\n",
      "54 Train Loss 29889.023 Test MSE 4251.734198412599 Test RE 0.11559057267147411\n",
      "55 Train Loss 29806.686 Test MSE 4290.98781458294 Test RE 0.11612293466779836\n",
      "56 Train Loss 29696.955 Test MSE 4150.271490132372 Test RE 0.11420302712985485\n",
      "57 Train Loss 29606.945 Test MSE 4072.4290533049275 Test RE 0.11312696235370343\n",
      "58 Train Loss 29582.314 Test MSE 4016.747167240039 Test RE 0.11235091410041075\n",
      "59 Train Loss 29545.273 Test MSE 3982.4344979132184 Test RE 0.1118700115412036\n",
      "60 Train Loss 29470.873 Test MSE 4055.562967454198 Test RE 0.11289245996525316\n",
      "61 Train Loss 29413.545 Test MSE 4065.7025343609243 Test RE 0.11303349662049979\n",
      "62 Train Loss 29281.709 Test MSE 4087.23975929714 Test RE 0.11333248706089671\n",
      "63 Train Loss 29194.09 Test MSE 3981.138753362304 Test RE 0.11185181077096183\n",
      "64 Train Loss 29080.377 Test MSE 3983.219891881409 Test RE 0.1118810421935397\n",
      "65 Train Loss 29019.865 Test MSE 4033.3976781901474 Test RE 0.11258353584818555\n",
      "66 Train Loss 28974.734 Test MSE 4053.696974807604 Test RE 0.11286648567530293\n",
      "67 Train Loss 28900.605 Test MSE 4044.946368007306 Test RE 0.11274459893551997\n",
      "68 Train Loss 28775.623 Test MSE 3996.7430098348177 Test RE 0.1120708005543859\n",
      "69 Train Loss 28697.75 Test MSE 3923.8381388521047 Test RE 0.11104395060585506\n",
      "70 Train Loss 28616.178 Test MSE 3862.2372980110954 Test RE 0.11016885581390584\n",
      "71 Train Loss 28552.445 Test MSE 3895.0466882309124 Test RE 0.1106358039529818\n",
      "72 Train Loss 28337.852 Test MSE 3870.9743790143602 Test RE 0.11029339638325418\n",
      "73 Train Loss 27853.182 Test MSE 3774.5326908570823 Test RE 0.10891080240959958\n",
      "74 Train Loss 27740.758 Test MSE 3822.321713583817 Test RE 0.10959808882588823\n",
      "75 Train Loss 27579.154 Test MSE 3714.0773863212307 Test RE 0.10803508959143475\n",
      "76 Train Loss 27353.973 Test MSE 3718.112762563942 Test RE 0.10809376417380258\n",
      "77 Train Loss 27140.97 Test MSE 3848.40607793339 Test RE 0.10997141373178063\n",
      "78 Train Loss 27026.773 Test MSE 3779.9643859261946 Test RE 0.10898913761647933\n",
      "79 Train Loss 26931.43 Test MSE 3692.8594711130013 Test RE 0.10772605421457399\n",
      "80 Train Loss 26817.695 Test MSE 3557.047647338045 Test RE 0.10572658474473756\n",
      "81 Train Loss 26718.604 Test MSE 3455.550639485229 Test RE 0.10420726390050289\n",
      "82 Train Loss 26640.266 Test MSE 3567.184836800178 Test RE 0.10587713205342142\n",
      "83 Train Loss 26547.83 Test MSE 3605.327043993509 Test RE 0.10644167382581349\n",
      "84 Train Loss 26485.762 Test MSE 3547.3146368476887 Test RE 0.1055818378992733\n",
      "85 Train Loss 26422.473 Test MSE 3403.4442085107044 Test RE 0.10341860613071578\n",
      "86 Train Loss 26338.723 Test MSE 3438.0345733981108 Test RE 0.10394281685713763\n",
      "87 Train Loss 26201.816 Test MSE 3466.1248453116914 Test RE 0.10436658255637794\n",
      "88 Train Loss 26101.342 Test MSE 3328.4400971066752 Test RE 0.1022727031422714\n",
      "89 Train Loss 25981.535 Test MSE 3310.973322641089 Test RE 0.10200400009186639\n",
      "90 Train Loss 25796.598 Test MSE 3161.1970278778194 Test RE 0.09967015753176119\n",
      "91 Train Loss 25722.93 Test MSE 3141.568671351544 Test RE 0.0993602420675402\n",
      "92 Train Loss 25660.816 Test MSE 3264.7834930479953 Test RE 0.10128999627881934\n",
      "93 Train Loss 25578.037 Test MSE 3186.3570956599106 Test RE 0.10006601041976182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 Train Loss 25462.305 Test MSE 3192.969531563666 Test RE 0.10016978679050641\n",
      "95 Train Loss 25245.389 Test MSE 2976.8182694446764 Test RE 0.09671982975155344\n",
      "96 Train Loss 25153.31 Test MSE 2995.6885003566967 Test RE 0.0970259018883742\n",
      "97 Train Loss 25093.762 Test MSE 2985.318232311973 Test RE 0.09685781750554143\n",
      "98 Train Loss 25058.201 Test MSE 2965.10656563357 Test RE 0.09652937970683624\n",
      "99 Train Loss 25014.023 Test MSE 3012.033331894777 Test RE 0.09729023423230831\n",
      "Training time: 271.36\n",
      "3D_HTTP_swish_tune2\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 248916.3 Test MSE 89362.31051270837 Test RE 0.5299276213657405\n",
      "1 Train Loss 233845.84 Test MSE 80528.01838243466 Test RE 0.503051986471501\n",
      "2 Train Loss 213870.53 Test MSE 65868.18399429576 Test RE 0.4549641819197685\n",
      "3 Train Loss 199897.42 Test MSE 59816.2779211611 Test RE 0.433559847586848\n",
      "4 Train Loss 191310.83 Test MSE 53740.94148095242 Test RE 0.41095285074777277\n",
      "5 Train Loss 187431.2 Test MSE 50689.76751751659 Test RE 0.3991163432539561\n",
      "6 Train Loss 183266.14 Test MSE 47928.36484994843 Test RE 0.38809287403031895\n",
      "7 Train Loss 177857.25 Test MSE 46646.81050811773 Test RE 0.38286911924598405\n",
      "8 Train Loss 176440.16 Test MSE 44957.49426545932 Test RE 0.3758723774818778\n",
      "9 Train Loss 175105.38 Test MSE 44519.243162655985 Test RE 0.3740358661422465\n",
      "10 Train Loss 172278.23 Test MSE 44307.68303288663 Test RE 0.3731460788885748\n",
      "11 Train Loss 167647.12 Test MSE 41631.870646245734 Test RE 0.3617031783074316\n",
      "12 Train Loss 165313.72 Test MSE 39543.235869393175 Test RE 0.3525132656392908\n",
      "13 Train Loss 163135.44 Test MSE 38823.89962084582 Test RE 0.34929224210597054\n",
      "14 Train Loss 159875.67 Test MSE 38444.52729407901 Test RE 0.34758147738445677\n",
      "15 Train Loss 157958.58 Test MSE 37656.19463966457 Test RE 0.3439993145961387\n",
      "16 Train Loss 155076.9 Test MSE 36491.26150651923 Test RE 0.33863652651658765\n",
      "17 Train Loss 151212.31 Test MSE 35095.05460103406 Test RE 0.33209498965922774\n",
      "18 Train Loss 149084.67 Test MSE 34580.15235904008 Test RE 0.3296497975911371\n",
      "19 Train Loss 145901.89 Test MSE 32890.25877303922 Test RE 0.32149410012898355\n",
      "20 Train Loss 143974.77 Test MSE 31932.995624851806 Test RE 0.31678104924437434\n",
      "21 Train Loss 141651.86 Test MSE 31029.152181896265 Test RE 0.31226572443292927\n",
      "22 Train Loss 136637.48 Test MSE 28483.730874793353 Test RE 0.2991836106384135\n",
      "23 Train Loss 133615.33 Test MSE 27370.907130487118 Test RE 0.29328101979844556\n",
      "24 Train Loss 130512.52 Test MSE 26202.627849204462 Test RE 0.2869536719905458\n",
      "25 Train Loss 128484.01 Test MSE 25462.81533460191 Test RE 0.28287370085803676\n",
      "26 Train Loss 127411.78 Test MSE 25180.80025176956 Test RE 0.28130284609922623\n",
      "27 Train Loss 125248.11 Test MSE 24116.118909944562 Test RE 0.2752916700889395\n",
      "28 Train Loss 122289.91 Test MSE 22708.872021650786 Test RE 0.2671389063114517\n",
      "29 Train Loss 119095.96 Test MSE 21347.45856490627 Test RE 0.25900756670232417\n",
      "30 Train Loss 116423.01 Test MSE 21040.79948333758 Test RE 0.25714049820352053\n",
      "31 Train Loss 113835.41 Test MSE 20331.91651796554 Test RE 0.25277174181961504\n",
      "32 Train Loss 111582.18 Test MSE 19850.343383219726 Test RE 0.2497602808821\n",
      "33 Train Loss 109594.73 Test MSE 19585.03460820869 Test RE 0.24808558700707717\n",
      "34 Train Loss 107306.58 Test MSE 19325.88483017189 Test RE 0.24643878318194543\n",
      "35 Train Loss 106055.35 Test MSE 18729.096955545472 Test RE 0.24260390168681456\n",
      "36 Train Loss 103965.3 Test MSE 17885.117817873514 Test RE 0.237074730153894\n",
      "37 Train Loss 102772.766 Test MSE 17329.16383395661 Test RE 0.23336094028865287\n",
      "38 Train Loss 100301.45 Test MSE 16839.38791026947 Test RE 0.2300395518772273\n",
      "39 Train Loss 97551.836 Test MSE 16639.802045695214 Test RE 0.22867223680035478\n",
      "40 Train Loss 95910.77 Test MSE 15979.796960066096 Test RE 0.22409129720381968\n",
      "41 Train Loss 94950.8 Test MSE 15554.436448175562 Test RE 0.22108867789197056\n",
      "42 Train Loss 92461.45 Test MSE 15064.644963629611 Test RE 0.2175799199538067\n",
      "43 Train Loss 90482.87 Test MSE 14635.83237879826 Test RE 0.21446087603928776\n",
      "44 Train Loss 88833.19 Test MSE 14258.124691433373 Test RE 0.21167548641166947\n",
      "45 Train Loss 86893.52 Test MSE 13800.46713359481 Test RE 0.20825059732636583\n",
      "46 Train Loss 85462.17 Test MSE 13378.593466090359 Test RE 0.20504283160243336\n",
      "47 Train Loss 82483.2 Test MSE 12875.782715239437 Test RE 0.20115284611056503\n",
      "48 Train Loss 81721.13 Test MSE 12872.871911023234 Test RE 0.20113010770075687\n",
      "49 Train Loss 80479.59 Test MSE 12757.09442453489 Test RE 0.20022359149757527\n",
      "50 Train Loss 79116.88 Test MSE 12306.540435230721 Test RE 0.19665606899406055\n",
      "51 Train Loss 78049.27 Test MSE 11816.978912289555 Test RE 0.19270482663219932\n",
      "52 Train Loss 77275.555 Test MSE 11791.027565750557 Test RE 0.19249311015006662\n",
      "53 Train Loss 77047.91 Test MSE 11801.257091819083 Test RE 0.19257659254281093\n",
      "54 Train Loss 76503.4 Test MSE 11626.12162256518 Test RE 0.19114229366196744\n",
      "55 Train Loss 75734.484 Test MSE 11423.366828715754 Test RE 0.18946824125081727\n",
      "56 Train Loss 74239.37 Test MSE 11299.973530040179 Test RE 0.1884421607069074\n",
      "57 Train Loss 73189.984 Test MSE 11290.119494709648 Test RE 0.18835997818198838\n",
      "58 Train Loss 72118.85 Test MSE 11077.110761595688 Test RE 0.18657463958911807\n",
      "59 Train Loss 71524.34 Test MSE 10954.869844586103 Test RE 0.18554231596881862\n",
      "60 Train Loss 70200.55 Test MSE 10909.226099321333 Test RE 0.18515537910112573\n",
      "61 Train Loss 69337.45 Test MSE 10783.309848596962 Test RE 0.18408372948121685\n",
      "62 Train Loss 68440.414 Test MSE 10632.627048122255 Test RE 0.18279303873678765\n",
      "63 Train Loss 66633.59 Test MSE 10284.663040582991 Test RE 0.17977711050215417\n",
      "64 Train Loss 65802.98 Test MSE 10139.808801393789 Test RE 0.17850658646183815\n",
      "65 Train Loss 64129.34 Test MSE 10040.552061581267 Test RE 0.17763075363277953\n",
      "66 Train Loss 62579.24 Test MSE 10146.543012790824 Test RE 0.17856585294255567\n",
      "67 Train Loss 61886.402 Test MSE 10095.641502916262 Test RE 0.1781173898754004\n",
      "68 Train Loss 61085.445 Test MSE 9510.628682377597 Test RE 0.17287969005610912\n",
      "69 Train Loss 60162.543 Test MSE 8840.701016218909 Test RE 0.16667970145445865\n",
      "70 Train Loss 58958.684 Test MSE 8695.843258150155 Test RE 0.16530851087749504\n",
      "71 Train Loss 57747.812 Test MSE 8822.955905013669 Test RE 0.1665123371511346\n",
      "72 Train Loss 56830.016 Test MSE 8866.29003760339 Test RE 0.16692075069695803\n",
      "73 Train Loss 55595.035 Test MSE 8798.106001180773 Test RE 0.16627768034988266\n",
      "74 Train Loss 54810.62 Test MSE 8709.747920378724 Test RE 0.16544062232565418\n",
      "75 Train Loss 54182.94 Test MSE 8649.903424406844 Test RE 0.1648712731137048\n",
      "76 Train Loss 53608.188 Test MSE 8584.212715381065 Test RE 0.16424403188794287\n",
      "77 Train Loss 53029.42 Test MSE 8589.488394012096 Test RE 0.16429449461911583\n",
      "78 Train Loss 52487.492 Test MSE 8512.712246075625 Test RE 0.16355858279916377\n",
      "79 Train Loss 51998.355 Test MSE 8315.407204896546 Test RE 0.16165201516508587\n",
      "80 Train Loss 51292.16 Test MSE 8111.918638454316 Test RE 0.15966184930854962\n",
      "81 Train Loss 50401.96 Test MSE 7839.283947088889 Test RE 0.15695586903513137\n",
      "82 Train Loss 48606.707 Test MSE 7252.128133914933 Test RE 0.15096354882810556\n",
      "83 Train Loss 47474.977 Test MSE 6754.017115431247 Test RE 0.14568687932512556\n",
      "84 Train Loss 46775.062 Test MSE 6359.226787342665 Test RE 0.14136487675560103\n",
      "85 Train Loss 45866.867 Test MSE 5744.947225493946 Test RE 0.1343638328396095\n",
      "86 Train Loss 44197.61 Test MSE 5276.170201842641 Test RE 0.12876527527474982\n",
      "87 Train Loss 43432.355 Test MSE 5136.216114433522 Test RE 0.12704600314534853\n",
      "88 Train Loss 42995.65 Test MSE 5068.51331979234 Test RE 0.12620590001572762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 Train Loss 42434.16 Test MSE 5087.124023402237 Test RE 0.126437390821938\n",
      "90 Train Loss 41999.113 Test MSE 5157.601373084317 Test RE 0.1273102141327523\n",
      "91 Train Loss 41598.43 Test MSE 5189.442012149268 Test RE 0.12770258659440117\n",
      "92 Train Loss 41016.523 Test MSE 5094.361655615558 Test RE 0.12652730233883586\n",
      "93 Train Loss 40289.4 Test MSE 4994.071828765536 Test RE 0.1252756758565638\n",
      "94 Train Loss 39811.42 Test MSE 5057.804214915935 Test RE 0.12607250124547884\n",
      "95 Train Loss 39130.4 Test MSE 5098.573597288872 Test RE 0.1265795969682067\n",
      "96 Train Loss 38673.08 Test MSE 5012.768433386043 Test RE 0.12550995779802224\n",
      "97 Train Loss 38506.0 Test MSE 4984.155950515704 Test RE 0.12515124476903006\n",
      "98 Train Loss 38386.92 Test MSE 5012.301439648189 Test RE 0.12550411135505699\n",
      "99 Train Loss 38138.08 Test MSE 5022.956732247942 Test RE 0.125637440634124\n",
      "Training time: 273.28\n",
      "3D_HTTP_swish_tune2\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 243403.2 Test MSE 86495.77599050543 Test RE 0.5213589241956637\n",
      "1 Train Loss 243162.98 Test MSE 87281.37493781593 Test RE 0.5237211968920361\n",
      "2 Train Loss 242739.48 Test MSE 87495.64172080133 Test RE 0.5243636436386055\n",
      "3 Train Loss 230947.84 Test MSE 79988.93847381488 Test RE 0.5013653648480214\n",
      "4 Train Loss 216283.4 Test MSE 67889.29384458218 Test RE 0.46189154009828687\n",
      "5 Train Loss 210386.11 Test MSE 60592.179268961634 Test RE 0.43636272838933765\n",
      "6 Train Loss 189132.62 Test MSE 54679.93922034342 Test RE 0.41452752537504806\n",
      "7 Train Loss 185728.39 Test MSE 52456.119978590534 Test RE 0.40601066735192576\n",
      "8 Train Loss 184065.61 Test MSE 50927.86160860992 Test RE 0.4000525866143446\n",
      "9 Train Loss 179939.05 Test MSE 49220.41620003692 Test RE 0.39328918416811137\n",
      "10 Train Loss 176035.94 Test MSE 45949.66027345569 Test RE 0.3799973033016138\n",
      "11 Train Loss 170199.86 Test MSE 43416.9533032438 Test RE 0.36937630657026965\n",
      "12 Train Loss 167290.67 Test MSE 43020.753540121914 Test RE 0.3676870792446632\n",
      "13 Train Loss 164619.47 Test MSE 42230.42134835931 Test RE 0.3642940428684814\n",
      "14 Train Loss 161049.0 Test MSE 39671.917510320505 Test RE 0.35308637429041845\n",
      "15 Train Loss 159359.34 Test MSE 38721.22191256899 Test RE 0.3488300490823627\n",
      "16 Train Loss 155125.17 Test MSE 35847.986533934454 Test RE 0.33563848034287713\n",
      "17 Train Loss 150450.2 Test MSE 34496.51986429768 Test RE 0.32925092536937894\n",
      "18 Train Loss 146555.16 Test MSE 34473.1345207772 Test RE 0.3291393061194805\n",
      "19 Train Loss 138128.47 Test MSE 29797.863259568363 Test RE 0.30600739629290685\n",
      "20 Train Loss 131711.53 Test MSE 28872.4091036546 Test RE 0.3012179673892816\n",
      "21 Train Loss 122607.336 Test MSE 23883.22983337611 Test RE 0.2739592011661062\n",
      "22 Train Loss 117390.164 Test MSE 21279.48478600572 Test RE 0.2585948768205867\n",
      "23 Train Loss 112632.83 Test MSE 19063.38727002077 Test RE 0.2447594099175176\n",
      "24 Train Loss 107042.43 Test MSE 18208.23339923329 Test RE 0.23920666050558434\n",
      "25 Train Loss 101194.66 Test MSE 16523.44921511357 Test RE 0.22787134576032397\n",
      "26 Train Loss 95310.484 Test MSE 14665.20117435469 Test RE 0.21467594071575302\n",
      "27 Train Loss 87518.016 Test MSE 12088.710816501369 Test RE 0.1949078615046337\n",
      "28 Train Loss 80988.64 Test MSE 9357.305606857344 Test RE 0.17148051100576275\n",
      "29 Train Loss 77464.36 Test MSE 8866.329172030257 Test RE 0.16692111907768295\n",
      "30 Train Loss 69609.67 Test MSE 9810.320503630115 Test RE 0.1755823915936041\n",
      "31 Train Loss 62553.156 Test MSE 9973.867567141395 Test RE 0.17703990215043724\n",
      "32 Train Loss 56174.33 Test MSE 6785.920038857573 Test RE 0.14603055344010057\n",
      "33 Train Loss 53004.453 Test MSE 6256.353264959263 Test RE 0.14021678136661356\n",
      "34 Train Loss 48779.53 Test MSE 5847.821209557595 Test RE 0.13556151234589314\n",
      "35 Train Loss 46584.39 Test MSE 5973.586638085805 Test RE 0.13701147622505935\n",
      "36 Train Loss 42854.047 Test MSE 5337.892389030203 Test RE 0.12951625235971476\n",
      "37 Train Loss 41063.73 Test MSE 4960.040172880457 Test RE 0.1248481062574901\n",
      "38 Train Loss 38326.844 Test MSE 5219.538291607254 Test RE 0.12807235818010784\n",
      "39 Train Loss 37634.95 Test MSE 5417.542631583635 Test RE 0.1304789733789274\n",
      "40 Train Loss 37000.22 Test MSE 5426.854141657547 Test RE 0.1305910569145992\n",
      "41 Train Loss 36644.316 Test MSE 5260.422359223313 Test RE 0.12857296811299718\n",
      "42 Train Loss 36035.86 Test MSE 4921.9611536928305 Test RE 0.12436794350224735\n",
      "43 Train Loss 35352.78 Test MSE 4943.048109400141 Test RE 0.1246340709993725\n",
      "44 Train Loss 34996.426 Test MSE 5084.605281832756 Test RE 0.12640608604738027\n",
      "45 Train Loss 34347.543 Test MSE 4885.950591847011 Test RE 0.12391215148051166\n",
      "46 Train Loss 33931.22 Test MSE 4894.601605045604 Test RE 0.12402180174759755\n",
      "47 Train Loss 33763.0 Test MSE 4912.2739994721405 Test RE 0.12424549588555979\n",
      "48 Train Loss 33086.387 Test MSE 4651.327125147289 Test RE 0.12090041854190675\n",
      "49 Train Loss 32471.395 Test MSE 4531.84900330781 Test RE 0.11933753907897134\n",
      "50 Train Loss 32244.965 Test MSE 4682.079197006394 Test RE 0.12129942437809195\n",
      "51 Train Loss 32090.479 Test MSE 4601.382319533281 Test RE 0.12024956719036577\n",
      "52 Train Loss 31842.719 Test MSE 4526.604309820393 Test RE 0.11926846462358176\n",
      "53 Train Loss 31654.094 Test MSE 4630.620068014303 Test RE 0.12063100248870723\n",
      "54 Train Loss 31500.79 Test MSE 4561.158816073168 Test RE 0.11972282593219852\n",
      "55 Train Loss 31321.564 Test MSE 4617.782607756753 Test RE 0.12046367387394742\n",
      "56 Train Loss 31157.934 Test MSE 4656.498217485886 Test RE 0.1209676051260233\n",
      "57 Train Loss 31050.865 Test MSE 4604.131853931613 Test RE 0.12028548910703346\n",
      "58 Train Loss 31020.191 Test MSE 4549.499752841694 Test RE 0.11956971252344656\n",
      "59 Train Loss 30954.48 Test MSE 4496.998822089955 Test RE 0.11887779722036701\n",
      "60 Train Loss 30852.69 Test MSE 4513.153996740126 Test RE 0.1190911361529618\n",
      "61 Train Loss 30807.746 Test MSE 4500.132802346179 Test RE 0.11891921326214325\n",
      "62 Train Loss 30723.754 Test MSE 4461.161841458515 Test RE 0.11840317592363056\n",
      "63 Train Loss 30654.592 Test MSE 4532.00773364455 Test RE 0.11933962898994203\n",
      "64 Train Loss 30618.512 Test MSE 4548.011085862111 Test RE 0.11955014838937751\n",
      "65 Train Loss 30593.928 Test MSE 4520.197786266463 Test RE 0.11918403414057113\n",
      "66 Train Loss 30512.451 Test MSE 4497.2527503173405 Test RE 0.11888115345898327\n",
      "67 Train Loss 30459.246 Test MSE 4499.278959852989 Test RE 0.11890793102905661\n",
      "68 Train Loss 30438.844 Test MSE 4503.139629056074 Test RE 0.11895893539631616\n",
      "69 Train Loss 30412.283 Test MSE 4499.74129584417 Test RE 0.11891404023060054\n",
      "70 Train Loss 30378.334 Test MSE 4485.76648384342 Test RE 0.11872924142601021\n",
      "71 Train Loss 30252.836 Test MSE 4527.038016773695 Test RE 0.11927417821371404\n",
      "72 Train Loss 30166.865 Test MSE 4491.907286524869 Test RE 0.11881048099721403\n",
      "73 Train Loss 30132.217 Test MSE 4435.081858252521 Test RE 0.11805657572865527\n",
      "74 Train Loss 30093.629 Test MSE 4420.739126814032 Test RE 0.11786552796479845\n",
      "75 Train Loss 30032.012 Test MSE 4469.655475305631 Test RE 0.11851583659775657\n",
      "76 Train Loss 29956.082 Test MSE 4460.832733071887 Test RE 0.11839880842943426\n",
      "77 Train Loss 29875.395 Test MSE 4404.710585397865 Test RE 0.11765165783903032\n",
      "78 Train Loss 29809.598 Test MSE 4404.25906622308 Test RE 0.11764562755169816\n",
      "79 Train Loss 29727.803 Test MSE 4359.509504733055 Test RE 0.11704643126468502\n",
      "80 Train Loss 29669.486 Test MSE 4330.537616592597 Test RE 0.11665685660334145\n",
      "81 Train Loss 29641.361 Test MSE 4295.612085984746 Test RE 0.1161854889552981\n",
      "82 Train Loss 29589.59 Test MSE 4261.092309922183 Test RE 0.11571771078250516\n",
      "83 Train Loss 29501.186 Test MSE 4247.934193945541 Test RE 0.11553890635602995\n",
      "84 Train Loss 29467.006 Test MSE 4275.442567931656 Test RE 0.11591240068057902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 Train Loss 29448.723 Test MSE 4258.472863077942 Test RE 0.11568213739324884\n",
      "86 Train Loss 29416.885 Test MSE 4264.651497368519 Test RE 0.11576602879876668\n",
      "87 Train Loss 29193.88 Test MSE 4278.3282050956705 Test RE 0.11595151063315264\n",
      "88 Train Loss 28859.357 Test MSE 4169.974291987715 Test RE 0.1144737871768331\n",
      "89 Train Loss 28560.414 Test MSE 4133.045820807441 Test RE 0.11396578131719734\n",
      "90 Train Loss 28372.902 Test MSE 4061.2077314194325 Test RE 0.11297099773036429\n",
      "91 Train Loss 28286.76 Test MSE 3950.013577801736 Test RE 0.11141371519804527\n",
      "92 Train Loss 28190.299 Test MSE 3937.693708213642 Test RE 0.11123983296267785\n",
      "93 Train Loss 28080.812 Test MSE 3861.135552842512 Test RE 0.11015314126135656\n",
      "94 Train Loss 28005.002 Test MSE 3756.5725639082284 Test RE 0.10865138165603401\n",
      "95 Train Loss 27918.773 Test MSE 3744.3703913136355 Test RE 0.10847477635297786\n",
      "96 Train Loss 27885.43 Test MSE 3762.1407204732036 Test RE 0.10873187576001687\n",
      "97 Train Loss 27826.059 Test MSE 3714.0107060824007 Test RE 0.10803411978962935\n",
      "98 Train Loss 27635.82 Test MSE 3739.320073385361 Test RE 0.10840159756710363\n",
      "99 Train Loss 27528.479 Test MSE 3762.7991484617182 Test RE 0.10874139015400536\n",
      "Training time: 256.60\n",
      "3D_HTTP_swish_tune2\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 250729.5 Test MSE 88339.5122114787 Test RE 0.5268862446298965\n",
      "1 Train Loss 248971.33 Test MSE 88521.88830852532 Test RE 0.527429840075629\n",
      "2 Train Loss 242945.8 Test MSE 84111.53135104262 Test RE 0.5141231173028381\n",
      "3 Train Loss 218845.23 Test MSE 67970.91592628951 Test RE 0.46216911865320054\n",
      "4 Train Loss 200372.36 Test MSE 58708.095656722995 Test RE 0.42952491325284364\n",
      "5 Train Loss 193930.12 Test MSE 55285.2529767761 Test RE 0.41681564609761373\n",
      "6 Train Loss 189134.11 Test MSE 52525.22914307589 Test RE 0.4062780319832791\n",
      "7 Train Loss 184496.6 Test MSE 49676.864191973356 Test RE 0.3951085693243176\n",
      "8 Train Loss 179547.72 Test MSE 47940.297406102196 Test RE 0.388141182081568\n",
      "9 Train Loss 175401.0 Test MSE 45197.609357916364 Test RE 0.37687479592745377\n",
      "10 Train Loss 172294.47 Test MSE 44370.19769502349 Test RE 0.37340922601200494\n",
      "11 Train Loss 167762.11 Test MSE 42145.181357246336 Test RE 0.36392620251479935\n",
      "12 Train Loss 163327.06 Test MSE 38622.18643691741 Test RE 0.34838367024994915\n",
      "13 Train Loss 159840.0 Test MSE 37256.54113882505 Test RE 0.34216897488506015\n",
      "14 Train Loss 151327.03 Test MSE 34400.42520974007 Test RE 0.3287920193892513\n",
      "15 Train Loss 143552.94 Test MSE 32145.72044720453 Test RE 0.3178344320658894\n",
      "16 Train Loss 134889.64 Test MSE 27965.83824221347 Test RE 0.2964512479193564\n",
      "17 Train Loss 126640.01 Test MSE 24755.946343371405 Test RE 0.2789196609189313\n",
      "18 Train Loss 119709.305 Test MSE 22027.33093084576 Test RE 0.2630996682484929\n",
      "19 Train Loss 107452.52 Test MSE 18144.377445004953 Test RE 0.23878684533596584\n",
      "20 Train Loss 97213.01 Test MSE 14758.956124957233 Test RE 0.21536106144528436\n",
      "21 Train Loss 86004.58 Test MSE 11817.302410591541 Test RE 0.19270746433080316\n",
      "22 Train Loss 81076.0 Test MSE 11270.93936226963 Test RE 0.18819991322361157\n",
      "23 Train Loss 78542.03 Test MSE 11066.458108667586 Test RE 0.18648490531668413\n",
      "24 Train Loss 70459.3 Test MSE 9074.543695117496 Test RE 0.1688697110579025\n",
      "25 Train Loss 67483.54 Test MSE 9141.663293720669 Test RE 0.16949308045212266\n",
      "26 Train Loss 63825.24 Test MSE 8634.266274154697 Test RE 0.16472217994081775\n",
      "27 Train Loss 61589.21 Test MSE 7870.559645873116 Test RE 0.15726865385721403\n",
      "28 Train Loss 57608.242 Test MSE 7089.6828996296335 Test RE 0.1492632067350237\n",
      "29 Train Loss 53910.2 Test MSE 6764.147580329765 Test RE 0.14579609749734976\n",
      "30 Train Loss 51500.31 Test MSE 6387.680311434762 Test RE 0.14168078305625934\n",
      "31 Train Loss 48237.066 Test MSE 5709.161517758454 Test RE 0.133944697911254\n",
      "32 Train Loss 46047.11 Test MSE 5332.108017070434 Test RE 0.12944605862104\n",
      "33 Train Loss 44551.402 Test MSE 4992.201900995252 Test RE 0.12525222020699603\n",
      "34 Train Loss 43591.32 Test MSE 4842.748547650613 Test RE 0.12336311355461328\n",
      "35 Train Loss 42564.668 Test MSE 4761.208791418478 Test RE 0.12232014173239589\n",
      "36 Train Loss 42117.953 Test MSE 4727.839806809881 Test RE 0.12189074702030499\n",
      "37 Train Loss 40706.562 Test MSE 4529.937595276293 Test RE 0.11931236979515218\n",
      "38 Train Loss 39620.28 Test MSE 4485.497740800254 Test RE 0.11872568482808195\n",
      "39 Train Loss 39315.215 Test MSE 4546.561386479102 Test RE 0.11953109329185586\n",
      "40 Train Loss 38256.074 Test MSE 4321.058411898967 Test RE 0.11652911033731042\n",
      "41 Train Loss 37692.08 Test MSE 4367.379423062005 Test RE 0.11715203150577591\n",
      "42 Train Loss 37090.637 Test MSE 4245.263702587403 Test RE 0.11550258350539037\n",
      "43 Train Loss 36690.523 Test MSE 4124.297458088694 Test RE 0.1138451025023002\n",
      "44 Train Loss 36391.977 Test MSE 4193.906292277432 Test RE 0.11480180685373718\n",
      "45 Train Loss 36158.004 Test MSE 4197.099092943931 Test RE 0.1148454975713274\n",
      "46 Train Loss 35911.953 Test MSE 4231.55433834947 Test RE 0.11531593462418326\n",
      "47 Train Loss 35755.418 Test MSE 4149.114265691111 Test RE 0.11418710434644969\n",
      "48 Train Loss 35603.77 Test MSE 4107.938068303673 Test RE 0.11361908983256756\n",
      "49 Train Loss 35384.625 Test MSE 4036.790314617174 Test RE 0.11263087493423604\n",
      "50 Train Loss 35328.766 Test MSE 4003.3613980599794 Test RE 0.1121635537353675\n",
      "51 Train Loss 35267.227 Test MSE 4035.2613626168736 Test RE 0.11260954319574451\n",
      "52 Train Loss 35222.887 Test MSE 4061.539994832248 Test RE 0.11297561893716092\n",
      "53 Train Loss 35047.207 Test MSE 4031.9378364656286 Test RE 0.11256315984878598\n",
      "54 Train Loss 34937.996 Test MSE 4046.8218372869487 Test RE 0.11277073333981334\n",
      "55 Train Loss 34878.66 Test MSE 4091.2799426911993 Test RE 0.11338848707092501\n",
      "56 Train Loss 34825.71 Test MSE 4058.381349530738 Test RE 0.1129316800229049\n",
      "57 Train Loss 34726.766 Test MSE 4103.561304205482 Test RE 0.11355854650496398\n",
      "58 Train Loss 34700.28 Test MSE 4178.427315523746 Test RE 0.11458975428613995\n",
      "59 Train Loss 34642.76 Test MSE 4160.247633885658 Test RE 0.11434020152836616\n",
      "60 Train Loss 34566.957 Test MSE 4106.531165221143 Test RE 0.11359963180593564\n",
      "61 Train Loss 34484.094 Test MSE 4034.531586376578 Test RE 0.11259936002821778\n",
      "62 Train Loss 34443.78 Test MSE 4008.772711315408 Test RE 0.11223933344897925\n",
      "63 Train Loss 34414.855 Test MSE 4060.967820058647 Test RE 0.11296766086263069\n",
      "64 Train Loss 34383.45 Test MSE 4055.3537900015 Test RE 0.11288954854926739\n",
      "65 Train Loss 34341.645 Test MSE 4051.9039095708567 Test RE 0.11284152088916612\n",
      "66 Train Loss 34287.34 Test MSE 4139.087388835677 Test RE 0.114049046857334\n",
      "67 Train Loss 34238.43 Test MSE 4124.466658620525 Test RE 0.11384743774297157\n",
      "68 Train Loss 34212.516 Test MSE 4118.391473637978 Test RE 0.11376356033764697\n",
      "69 Train Loss 34177.562 Test MSE 4128.569507241777 Test RE 0.11390404902592441\n",
      "70 Train Loss 34153.383 Test MSE 4180.036164377304 Test RE 0.11461181280698851\n",
      "71 Train Loss 34106.008 Test MSE 4220.981929795987 Test RE 0.11517178787079654\n",
      "72 Train Loss 34016.023 Test MSE 4189.247237713608 Test RE 0.11473802186725587\n",
      "73 Train Loss 33987.02 Test MSE 4199.429718447058 Test RE 0.11487737967515275\n",
      "74 Train Loss 33962.68 Test MSE 4215.819890513398 Test RE 0.11510134180144126\n",
      "75 Train Loss 33934.188 Test MSE 4196.154352853097 Test RE 0.11483257135137079\n",
      "76 Train Loss 33908.297 Test MSE 4158.644217341527 Test RE 0.11431816526330647\n",
      "77 Train Loss 33899.42 Test MSE 4147.269506183921 Test RE 0.11416171685982505\n",
      "78 Train Loss 33863.207 Test MSE 4122.684278850776 Test RE 0.11382283561690248\n",
      "79 Train Loss 33809.266 Test MSE 4137.682026639334 Test RE 0.11402968343112518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Train Loss 33714.12 Test MSE 4158.124785551083 Test RE 0.11431102563552248\n",
      "81 Train Loss 33667.39 Test MSE 4187.435892907971 Test RE 0.11471321399863951\n",
      "82 Train Loss 33650.324 Test MSE 4189.387722375512 Test RE 0.11473994569702309\n",
      "83 Train Loss 33627.883 Test MSE 4155.576862529849 Test RE 0.11427599778765969\n",
      "84 Train Loss 33577.086 Test MSE 4189.040229810806 Test RE 0.11473518699390574\n",
      "85 Train Loss 33547.176 Test MSE 4220.914205785298 Test RE 0.1151708639238561\n",
      "86 Train Loss 33510.83 Test MSE 4202.827194389387 Test RE 0.11492384005809354\n",
      "87 Train Loss 33449.934 Test MSE 4231.447949438141 Test RE 0.11531448498973743\n",
      "88 Train Loss 33418.855 Test MSE 4233.140056992407 Test RE 0.11533753915587439\n",
      "89 Train Loss 33394.5 Test MSE 4229.525989235562 Test RE 0.11528829359782561\n",
      "90 Train Loss 33372.73 Test MSE 4211.9217114317535 Test RE 0.11504811497695937\n",
      "91 Train Loss 33351.234 Test MSE 4207.941766913784 Test RE 0.11499374628688878\n",
      "92 Train Loss 33337.555 Test MSE 4225.726246359596 Test RE 0.11523649532237203\n",
      "93 Train Loss 33301.348 Test MSE 4235.014257469594 Test RE 0.11536306887456498\n",
      "94 Train Loss 33234.21 Test MSE 4163.849116609149 Test RE 0.11438968237826966\n",
      "95 Train Loss 33211.582 Test MSE 4138.9211923515695 Test RE 0.1140467571326801\n",
      "96 Train Loss 33142.836 Test MSE 4128.244243397868 Test RE 0.11389956204823176\n",
      "97 Train Loss 33101.855 Test MSE 4165.3010575800645 Test RE 0.11440962457425952\n",
      "98 Train Loss 33087.47 Test MSE 4190.311893775952 Test RE 0.11475260071202159\n",
      "99 Train Loss 33060.965 Test MSE 4239.163783636567 Test RE 0.11541957221098452\n",
      "Training time: 274.79\n",
      "3D_HTTP_swish_tune2\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 248767.19 Test MSE 85945.64598081888 Test RE 0.5196983072872438\n",
      "1 Train Loss 248032.2 Test MSE 87280.84340293692 Test RE 0.5237196021846483\n",
      "2 Train Loss 247611.55 Test MSE 87702.30142375117 Test RE 0.5249825368787293\n",
      "3 Train Loss 236636.28 Test MSE 78479.84116417496 Test RE 0.4966133840637592\n",
      "4 Train Loss 220413.12 Test MSE 68591.66122477481 Test RE 0.4642747050827592\n",
      "5 Train Loss 203781.28 Test MSE 61615.062121885036 Test RE 0.44003052796294045\n",
      "6 Train Loss 173223.0 Test MSE 43989.43574501357 Test RE 0.3718035720250932\n",
      "7 Train Loss 163678.56 Test MSE 38601.9490504462 Test RE 0.3482923846517268\n",
      "8 Train Loss 156376.83 Test MSE 34561.57169789832 Test RE 0.329561221720641\n",
      "9 Train Loss 146055.62 Test MSE 31843.596334328347 Test RE 0.31633730994916903\n",
      "10 Train Loss 130467.16 Test MSE 24703.671952275723 Test RE 0.2786250234143796\n",
      "11 Train Loss 112600.62 Test MSE 20408.43352626672 Test RE 0.2532469349560845\n",
      "12 Train Loss 89671.484 Test MSE 14346.95625681197 Test RE 0.21233385729015458\n",
      "13 Train Loss 73895.42 Test MSE 8414.205861224953 Test RE 0.16260950538728322\n",
      "14 Train Loss 58834.12 Test MSE 7360.616173851667 Test RE 0.1520885250082175\n",
      "15 Train Loss 55356.438 Test MSE 6142.51197691719 Test RE 0.13893522482461926\n",
      "16 Train Loss 53135.27 Test MSE 4750.429375933715 Test RE 0.12218159637240356\n",
      "17 Train Loss 46234.62 Test MSE 4228.348328124657 Test RE 0.11527224215465014\n",
      "18 Train Loss 42883.4 Test MSE 5589.521990570293 Test RE 0.13253381420615\n",
      "19 Train Loss 40976.605 Test MSE 6506.440593911143 Test RE 0.14299178797945547\n",
      "20 Train Loss 36941.29 Test MSE 5552.97755151151 Test RE 0.1320998489747743\n",
      "21 Train Loss 35599.945 Test MSE 5039.213837082145 Test RE 0.12584059299553813\n",
      "22 Train Loss 34357.336 Test MSE 4722.290978036849 Test RE 0.12181919748836148\n",
      "23 Train Loss 32858.22 Test MSE 4428.5878471609585 Test RE 0.11797011266149789\n",
      "24 Train Loss 31989.484 Test MSE 4538.3892069889325 Test RE 0.11942361988399146\n",
      "25 Train Loss 31750.934 Test MSE 4580.593328055262 Test RE 0.11997761660649447\n",
      "26 Train Loss 31342.852 Test MSE 4557.442241876596 Test RE 0.1196740390490776\n",
      "27 Train Loss 31140.691 Test MSE 4543.962375852114 Test RE 0.11949692384322898\n",
      "28 Train Loss 31022.234 Test MSE 4457.72305835615 Test RE 0.118357532955681\n",
      "29 Train Loss 30561.709 Test MSE 4309.266236069887 Test RE 0.11636999763729367\n",
      "30 Train Loss 30335.783 Test MSE 4476.725271591686 Test RE 0.11860952969796763\n",
      "31 Train Loss 30226.682 Test MSE 4485.458908549911 Test RE 0.11872517090568578\n",
      "32 Train Loss 30003.557 Test MSE 4339.550405622118 Test RE 0.11677818763070619\n",
      "33 Train Loss 29586.709 Test MSE 4162.925785396266 Test RE 0.11437699875103766\n",
      "34 Train Loss 29327.371 Test MSE 4151.703334698695 Test RE 0.11422272546561203\n",
      "35 Train Loss 29132.059 Test MSE 3994.5483409126036 Test RE 0.11204002648703396\n",
      "36 Train Loss 28978.004 Test MSE 4001.573828393598 Test RE 0.1121385094621826\n",
      "37 Train Loss 28803.508 Test MSE 3984.769047933833 Test RE 0.11190279649654111\n",
      "38 Train Loss 28252.014 Test MSE 3875.9333406789874 Test RE 0.11036402016124046\n",
      "39 Train Loss 27878.617 Test MSE 4058.8321657942615 Test RE 0.11293795223094416\n",
      "40 Train Loss 27699.488 Test MSE 4089.8500178524205 Test RE 0.11336867038937472\n",
      "41 Train Loss 27341.305 Test MSE 3785.4799054783057 Test RE 0.1090686241583163\n",
      "42 Train Loss 27002.854 Test MSE 3409.187385818529 Test RE 0.10350582675185568\n",
      "43 Train Loss 26526.727 Test MSE 3333.3710732921854 Test RE 0.10234843195359616\n",
      "44 Train Loss 25136.559 Test MSE 3116.5792796881265 Test RE 0.09896427597243004\n",
      "45 Train Loss 24928.334 Test MSE 2986.703861962841 Test RE 0.09688029308164511\n",
      "46 Train Loss 24851.982 Test MSE 3116.715625749434 Test RE 0.09896644072430255\n",
      "47 Train Loss 24717.361 Test MSE 3122.172142151552 Test RE 0.0990530344218408\n",
      "48 Train Loss 24582.248 Test MSE 3005.0947551553263 Test RE 0.09717810981368222\n",
      "49 Train Loss 24464.8 Test MSE 2872.667015502498 Test RE 0.09501277577592317\n",
      "50 Train Loss 24307.328 Test MSE 2968.831660175758 Test RE 0.09658999611168845\n",
      "51 Train Loss 24164.3 Test MSE 2982.604717128784 Test RE 0.09681378787635803\n",
      "52 Train Loss 24013.65 Test MSE 2868.326158768443 Test RE 0.09494096223638111\n",
      "53 Train Loss 23813.262 Test MSE 2696.6550199456165 Test RE 0.09205599103747152\n",
      "54 Train Loss 23392.6 Test MSE 2663.5149599683846 Test RE 0.09148858957801631\n",
      "55 Train Loss 23048.41 Test MSE 2743.656909580612 Test RE 0.09285477959347534\n",
      "56 Train Loss 22879.867 Test MSE 2595.7192273233295 Test RE 0.09031673292672526\n",
      "57 Train Loss 22744.74 Test MSE 2439.8861461128204 Test RE 0.08756370773405271\n",
      "58 Train Loss 22675.453 Test MSE 2401.777435782258 Test RE 0.08687718539338127\n",
      "59 Train Loss 22509.854 Test MSE 2429.309629878869 Test RE 0.08737371427811337\n",
      "60 Train Loss 22450.94 Test MSE 2392.8358072846454 Test RE 0.08671531613202997\n",
      "61 Train Loss 22381.021 Test MSE 2327.533633711832 Test RE 0.0855238700415173\n",
      "62 Train Loss 22049.143 Test MSE 2272.91162758068 Test RE 0.08451438536579904\n",
      "63 Train Loss 21881.979 Test MSE 2359.66873372745 Test RE 0.08611223895657641\n",
      "64 Train Loss 21769.852 Test MSE 2406.0380345137173 Test RE 0.08695420852024405\n",
      "65 Train Loss 21627.98 Test MSE 2297.5997151946917 Test RE 0.08497213815869739\n",
      "66 Train Loss 21574.361 Test MSE 2245.7850235697883 Test RE 0.08400854305257126\n",
      "67 Train Loss 21543.605 Test MSE 2250.025227990571 Test RE 0.08408781275365179\n",
      "68 Train Loss 21466.725 Test MSE 2258.6413807037884 Test RE 0.08424866009582466\n",
      "69 Train Loss 21322.365 Test MSE 2276.386898495385 Test RE 0.08457897173094434\n",
      "70 Train Loss 21238.395 Test MSE 2266.310513826156 Test RE 0.08439157048880401\n",
      "71 Train Loss 21213.629 Test MSE 2240.6760551807984 Test RE 0.08391293252863691\n",
      "72 Train Loss 21026.848 Test MSE 2261.563812185452 Test RE 0.08430314668845619\n",
      "73 Train Loss 20950.46 Test MSE 2260.2321837262816 Test RE 0.08427832382063015\n",
      "74 Train Loss 20891.629 Test MSE 2179.690817024841 Test RE 0.08276311145369972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 Train Loss 20857.254 Test MSE 2149.722566690665 Test RE 0.08219219333544288\n",
      "76 Train Loss 20797.041 Test MSE 2081.2990631367684 Test RE 0.0808735685077343\n",
      "77 Train Loss 20763.652 Test MSE 2012.031008562556 Test RE 0.07951639767034224\n",
      "78 Train Loss 20698.55 Test MSE 1962.7218425270285 Test RE 0.07853599313383958\n",
      "79 Train Loss 20534.314 Test MSE 2066.4473633760963 Test RE 0.08058450376595927\n",
      "80 Train Loss 20381.105 Test MSE 2129.318674320921 Test RE 0.08180120357258515\n",
      "81 Train Loss 20138.98 Test MSE 2032.1859144621046 Test RE 0.07991367086837267\n",
      "82 Train Loss 19993.55 Test MSE 2058.648493215063 Test RE 0.0804322951538087\n",
      "83 Train Loss 19961.762 Test MSE 2065.9297336249388 Test RE 0.08057441022331854\n",
      "84 Train Loss 19913.86 Test MSE 2006.3901137311793 Test RE 0.07940485404639772\n",
      "85 Train Loss 19851.553 Test MSE 1939.4496242087823 Test RE 0.0780689995612957\n",
      "86 Train Loss 19753.748 Test MSE 1878.818096317768 Test RE 0.07683900446876255\n",
      "87 Train Loss 19700.342 Test MSE 1827.458664975109 Test RE 0.07578149059676847\n",
      "88 Train Loss 19550.139 Test MSE 1948.5104442088602 Test RE 0.07825115043730217\n",
      "89 Train Loss 19472.43 Test MSE 2077.3915509282847 Test RE 0.08079761524235334\n",
      "90 Train Loss 19467.326 Test MSE 2057.1731945001684 Test RE 0.08040346970620281\n",
      "91 Train Loss 19454.424 Test MSE 2059.3248362186673 Test RE 0.08044550657696095\n",
      "92 Train Loss 19447.041 Test MSE 2059.2659740036997 Test RE 0.0804443568713741\n",
      "93 Train Loss 19440.559 Test MSE 2022.0584898600903 Test RE 0.07971429675975931\n",
      "94 Train Loss 19426.965 Test MSE 2049.123172301516 Test RE 0.08024600018551423\n",
      "95 Train Loss 19333.26 Test MSE 2096.5982634977613 Test RE 0.08117026672934886\n",
      "96 Train Loss 19147.92 Test MSE 1912.205733206121 Test RE 0.07751873378267407\n",
      "97 Train Loss 18776.707 Test MSE 1826.706108892624 Test RE 0.07576588540271456\n",
      "98 Train Loss 18627.635 Test MSE 1828.8497594038163 Test RE 0.07581032822720865\n",
      "99 Train Loss 18403.295 Test MSE 1643.5474957898218 Test RE 0.07186716143465864\n",
      "Training time: 269.97\n",
      "3D_HTTP_swish_tune2\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 239465.92 Test MSE 84789.09586819464 Test RE 0.5161897355589009\n",
      "1 Train Loss 237376.0 Test MSE 80784.22527507211 Test RE 0.5038516027827961\n",
      "2 Train Loss 220383.4 Test MSE 63744.777998175465 Test RE 0.44757072140873805\n",
      "3 Train Loss 206502.89 Test MSE 64130.07520656685 Test RE 0.4489213257630932\n",
      "4 Train Loss 188290.45 Test MSE 53158.51045044679 Test RE 0.40871988150198807\n",
      "5 Train Loss 184452.7 Test MSE 49842.0287792193 Test RE 0.39576484858788513\n",
      "6 Train Loss 179546.77 Test MSE 46668.49493253731 Test RE 0.38295809994748214\n",
      "7 Train Loss 176642.06 Test MSE 46242.532661736026 Test RE 0.3812063867284589\n",
      "8 Train Loss 173110.3 Test MSE 45225.71367410055 Test RE 0.3769919499380993\n",
      "9 Train Loss 170907.88 Test MSE 43469.86627002165 Test RE 0.36960132057384376\n",
      "10 Train Loss 168896.36 Test MSE 41803.55275318045 Test RE 0.3624482093896189\n",
      "11 Train Loss 163321.05 Test MSE 39844.39516075027 Test RE 0.35385308111816843\n",
      "12 Train Loss 159587.03 Test MSE 39299.18231013679 Test RE 0.3514237585455783\n",
      "13 Train Loss 156003.84 Test MSE 37625.34472220549 Test RE 0.34385837463922975\n",
      "14 Train Loss 146015.3 Test MSE 34020.02256237079 Test RE 0.3269690615811877\n",
      "15 Train Loss 136032.81 Test MSE 29921.853231519475 Test RE 0.3066433892282143\n",
      "16 Train Loss 127704.63 Test MSE 23894.2624809183 Test RE 0.27402247037959454\n",
      "17 Train Loss 112434.76 Test MSE 20874.468614121844 Test RE 0.2561221133013861\n",
      "18 Train Loss 104290.68 Test MSE 19120.961075281284 Test RE 0.2451287332372279\n",
      "19 Train Loss 96855.51 Test MSE 17817.524434300238 Test RE 0.23662631676995763\n",
      "20 Train Loss 91211.375 Test MSE 16119.196868662013 Test RE 0.22506660605953482\n",
      "21 Train Loss 83344.42 Test MSE 14244.444278748759 Test RE 0.2115739126414754\n",
      "22 Train Loss 75916.86 Test MSE 11966.659004271538 Test RE 0.19392143672128648\n",
      "23 Train Loss 71532.06 Test MSE 10276.308807860518 Test RE 0.17970407918670614\n",
      "24 Train Loss 65611.39 Test MSE 9213.560131601278 Test RE 0.1701582849078895\n",
      "25 Train Loss 62933.055 Test MSE 8754.553310957861 Test RE 0.1658656129824245\n",
      "26 Train Loss 59473.863 Test MSE 7744.222147682045 Test RE 0.15600131651703714\n",
      "27 Train Loss 55100.33 Test MSE 6542.348857083652 Test RE 0.1433858223112894\n",
      "28 Train Loss 53406.84 Test MSE 6696.798266128494 Test RE 0.14506844987834097\n",
      "29 Train Loss 51842.32 Test MSE 6676.136690672298 Test RE 0.14484448776266143\n",
      "30 Train Loss 49876.492 Test MSE 6477.709147263365 Test RE 0.14267572373640786\n",
      "31 Train Loss 48193.85 Test MSE 6502.836744471529 Test RE 0.1429521816659096\n",
      "32 Train Loss 45904.926 Test MSE 6229.996384237861 Test RE 0.13992111571687657\n",
      "33 Train Loss 44773.074 Test MSE 5814.584134150911 Test RE 0.13517572005796338\n",
      "34 Train Loss 42777.33 Test MSE 5542.323697070709 Test RE 0.13197306579957127\n",
      "35 Train Loss 41762.465 Test MSE 5229.989326598559 Test RE 0.12820051313184508\n",
      "36 Train Loss 40745.62 Test MSE 4984.412731008499 Test RE 0.1251544685831245\n",
      "37 Train Loss 40217.906 Test MSE 4917.961540880896 Test RE 0.1243174021938071\n",
      "38 Train Loss 39444.625 Test MSE 4731.98668934499 Test RE 0.12194419170546067\n",
      "39 Train Loss 38517.54 Test MSE 4687.513377054428 Test RE 0.1213697960797725\n",
      "40 Train Loss 37911.145 Test MSE 4696.532744138189 Test RE 0.12148650536534705\n",
      "41 Train Loss 37399.098 Test MSE 4586.959015363722 Test RE 0.12006095459100531\n",
      "42 Train Loss 36944.965 Test MSE 4498.426190074128 Test RE 0.11889666190169569\n",
      "43 Train Loss 35542.203 Test MSE 4536.0499755883 Test RE 0.1193928385345019\n",
      "44 Train Loss 34916.09 Test MSE 4583.012035359915 Test RE 0.12000928853405872\n",
      "45 Train Loss 34554.543 Test MSE 4676.635532906994 Test RE 0.1212288889027693\n",
      "46 Train Loss 34408.992 Test MSE 4758.093393848359 Test RE 0.12228011636838751\n",
      "47 Train Loss 33881.094 Test MSE 4712.919804939889 Test RE 0.12169826511549366\n",
      "48 Train Loss 33581.31 Test MSE 4677.312281737582 Test RE 0.12123766000973396\n",
      "49 Train Loss 32773.82 Test MSE 4732.1712437322285 Test RE 0.12194656968300202\n",
      "50 Train Loss 32349.65 Test MSE 4654.097569862882 Test RE 0.12093641881190458\n",
      "51 Train Loss 32108.38 Test MSE 4711.6476880929895 Test RE 0.12168183953771683\n",
      "52 Train Loss 31898.492 Test MSE 4720.217116608342 Test RE 0.12179244523194815\n",
      "53 Train Loss 31704.863 Test MSE 4601.602145728796 Test RE 0.12025243955429095\n",
      "54 Train Loss 31549.555 Test MSE 4551.434939882647 Test RE 0.11959514006161887\n",
      "55 Train Loss 31499.553 Test MSE 4578.884376063536 Test RE 0.11995523357664196\n",
      "56 Train Loss 31447.357 Test MSE 4567.079931039323 Test RE 0.11980051043411492\n",
      "57 Train Loss 31280.8 Test MSE 4564.793126203178 Test RE 0.11977051373016305\n",
      "58 Train Loss 31141.705 Test MSE 4593.205867077536 Test RE 0.12014268061026188\n",
      "59 Train Loss 31003.447 Test MSE 4702.474347744161 Test RE 0.1215633276240322\n",
      "60 Train Loss 30955.73 Test MSE 4701.878534954895 Test RE 0.12155562622320391\n",
      "61 Train Loss 30876.465 Test MSE 4599.758232880536 Test RE 0.12022834389926952\n",
      "62 Train Loss 30748.723 Test MSE 4586.22156156404 Test RE 0.12005130299331204\n",
      "63 Train Loss 30576.535 Test MSE 4506.433775635378 Test RE 0.11900243799267358\n",
      "64 Train Loss 30465.857 Test MSE 4391.622031491154 Test RE 0.117476727422973\n",
      "65 Train Loss 30348.12 Test MSE 4342.941837328415 Test RE 0.11682381077853692\n",
      "66 Train Loss 30284.955 Test MSE 4279.961588157699 Test RE 0.1159736425444024\n",
      "67 Train Loss 30166.312 Test MSE 4293.121982548861 Test RE 0.11615180856012178\n",
      "68 Train Loss 30095.283 Test MSE 4345.8510554512795 Test RE 0.11686293276802623\n",
      "69 Train Loss 30034.852 Test MSE 4361.165720500145 Test RE 0.11706866263457966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Train Loss 29936.453 Test MSE 4381.48285163429 Test RE 0.1173410365604253\n",
      "71 Train Loss 29815.713 Test MSE 4384.291464179761 Test RE 0.1173786394361007\n",
      "72 Train Loss 29600.023 Test MSE 4357.901863063024 Test RE 0.11702484786512926\n",
      "73 Train Loss 29187.639 Test MSE 4301.472562446426 Test RE 0.11626471750645523\n",
      "74 Train Loss 28868.303 Test MSE 4089.5312250479456 Test RE 0.11336425191186109\n",
      "75 Train Loss 28622.906 Test MSE 4104.855777470426 Test RE 0.11357645618154431\n",
      "76 Train Loss 28542.52 Test MSE 4103.263496599675 Test RE 0.11355442579005955\n",
      "77 Train Loss 28411.447 Test MSE 4152.415682102785 Test RE 0.11423252418742774\n",
      "78 Train Loss 28237.535 Test MSE 4068.437501344611 Test RE 0.11307150861309663\n",
      "79 Train Loss 28102.982 Test MSE 3947.664120497969 Test RE 0.111380575982555\n",
      "80 Train Loss 27965.928 Test MSE 3906.934912397614 Test RE 0.11080451324975148\n",
      "81 Train Loss 27685.17 Test MSE 3829.7119131723125 Test RE 0.10970398789626082\n",
      "82 Train Loss 27373.979 Test MSE 3685.2233919359633 Test RE 0.10761461883899347\n",
      "83 Train Loss 27085.451 Test MSE 3370.525552887891 Test RE 0.10291725025376224\n",
      "84 Train Loss 26785.82 Test MSE 3267.5941662366677 Test RE 0.10133358750474011\n",
      "85 Train Loss 26266.738 Test MSE 3409.510791127747 Test RE 0.10351073606546742\n",
      "86 Train Loss 25749.824 Test MSE 3171.7217627409354 Test RE 0.0998359381362306\n",
      "87 Train Loss 25463.543 Test MSE 3138.8013039379707 Test RE 0.09931646984653741\n",
      "88 Train Loss 25190.232 Test MSE 3071.0529234384676 Test RE 0.0982387917864235\n",
      "89 Train Loss 24729.5 Test MSE 3098.564918083625 Test RE 0.09867784624349595\n",
      "90 Train Loss 23833.502 Test MSE 3132.8958210502146 Test RE 0.09922299660809716\n",
      "91 Train Loss 23555.492 Test MSE 2957.1876300491476 Test RE 0.096400392605581\n",
      "92 Train Loss 23453.178 Test MSE 2903.587150796142 Test RE 0.09552274522341833\n",
      "93 Train Loss 23282.559 Test MSE 2925.622312039398 Test RE 0.095884518549149\n",
      "94 Train Loss 23163.12 Test MSE 2817.561336738614 Test RE 0.09409705943463606\n",
      "95 Train Loss 22990.244 Test MSE 2643.444814519714 Test RE 0.0911432449038854\n",
      "96 Train Loss 22830.54 Test MSE 2579.8040815028653 Test RE 0.09003942750200869\n",
      "97 Train Loss 22636.84 Test MSE 2604.2205100787564 Test RE 0.09046451093719564\n",
      "98 Train Loss 22398.637 Test MSE 2573.616943434942 Test RE 0.0899313920140862\n",
      "99 Train Loss 22182.855 Test MSE 2526.2097868689752 Test RE 0.08909925420965564\n",
      "Training time: 268.38\n",
      "3D_HTTP_swish_tune2\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 243946.48 Test MSE 88979.14184103809 Test RE 0.5287902862226148\n",
      "1 Train Loss 239331.64 Test MSE 85509.38283390924 Test RE 0.5183776256793678\n",
      "2 Train Loss 224381.03 Test MSE 76026.83094748591 Test RE 0.48879055596527843\n",
      "3 Train Loss 212326.23 Test MSE 70343.77865508123 Test RE 0.47016707072328257\n",
      "4 Train Loss 189774.45 Test MSE 53465.00673019728 Test RE 0.40989646707301536\n",
      "5 Train Loss 181108.03 Test MSE 50951.938561047056 Test RE 0.4001471410354358\n",
      "6 Train Loss 168625.39 Test MSE 43398.323686105454 Test RE 0.3692970509226691\n",
      "7 Train Loss 161947.23 Test MSE 41291.29914822778 Test RE 0.3602206751321329\n",
      "8 Train Loss 156109.19 Test MSE 39013.65503341735 Test RE 0.35014480076111293\n",
      "9 Train Loss 152131.88 Test MSE 34814.803211508566 Test RE 0.3307663604317379\n",
      "10 Train Loss 148448.25 Test MSE 34676.862120603866 Test RE 0.3301104389192765\n",
      "11 Train Loss 145365.83 Test MSE 32942.095273217965 Test RE 0.3217473448361508\n",
      "12 Train Loss 143606.72 Test MSE 31512.014323126285 Test RE 0.31468601644620703\n",
      "13 Train Loss 141523.75 Test MSE 30990.33170170467 Test RE 0.31207032593770945\n",
      "14 Train Loss 137635.08 Test MSE 29192.682770841904 Test RE 0.3028840237530467\n",
      "15 Train Loss 130684.945 Test MSE 27389.847643897327 Test RE 0.2933824766556416\n",
      "16 Train Loss 123255.016 Test MSE 24614.370954776234 Test RE 0.27812096840484085\n",
      "17 Train Loss 113650.125 Test MSE 23149.07921556995 Test RE 0.26971569721351263\n",
      "18 Train Loss 107198.05 Test MSE 21333.109789292223 Test RE 0.2589205056088293\n",
      "19 Train Loss 93744.766 Test MSE 13819.691126774029 Test RE 0.20839559295627255\n",
      "20 Train Loss 86934.25 Test MSE 12257.054529887497 Test RE 0.19626028325561934\n",
      "21 Train Loss 79832.195 Test MSE 9109.281468792202 Test RE 0.1691926228614506\n",
      "22 Train Loss 75285.84 Test MSE 8056.083319111597 Test RE 0.1591114145639937\n",
      "23 Train Loss 74071.58 Test MSE 8582.08075389488 Test RE 0.1642236349274965\n",
      "24 Train Loss 71786.81 Test MSE 8465.88035499776 Test RE 0.1631080611879865\n",
      "25 Train Loss 68715.66 Test MSE 8701.398865641528 Test RE 0.16536130866464957\n",
      "26 Train Loss 63757.555 Test MSE 7586.877935233834 Test RE 0.15440839566914266\n",
      "27 Train Loss 56404.797 Test MSE 6404.158658379081 Test RE 0.1418634128401169\n",
      "28 Train Loss 50858.75 Test MSE 5861.4218986765745 Test RE 0.1357190632645674\n",
      "29 Train Loss 48321.97 Test MSE 5895.490768935041 Test RE 0.1361129178503757\n",
      "30 Train Loss 46658.17 Test MSE 6118.850871262885 Test RE 0.13866737570143356\n",
      "31 Train Loss 45282.18 Test MSE 5420.276753580204 Test RE 0.13051189424880344\n",
      "32 Train Loss 44264.75 Test MSE 5071.766656961442 Test RE 0.12624639753976447\n",
      "33 Train Loss 43019.84 Test MSE 5310.024977134513 Test RE 0.1291777286925069\n",
      "34 Train Loss 42098.707 Test MSE 4854.198435710779 Test RE 0.12350886342267386\n",
      "35 Train Loss 41649.594 Test MSE 4312.128405012276 Test RE 0.116408637081655\n",
      "36 Train Loss 41106.445 Test MSE 4175.343086758016 Test RE 0.11454745532631481\n",
      "37 Train Loss 39973.69 Test MSE 3965.309632394524 Test RE 0.11162922630886025\n",
      "38 Train Loss 39212.855 Test MSE 4291.960814096233 Test RE 0.11613609960317232\n",
      "39 Train Loss 37927.75 Test MSE 5008.836469949012 Test RE 0.1254607237885367\n",
      "40 Train Loss 37374.09 Test MSE 4854.083703948532 Test RE 0.12350740381266063\n",
      "41 Train Loss 36628.152 Test MSE 4888.720685621746 Test RE 0.12394727255219878\n",
      "42 Train Loss 36292.617 Test MSE 4802.926551438174 Test RE 0.1228548581543436\n",
      "43 Train Loss 35666.688 Test MSE 5398.71795222641 Test RE 0.13025208432432112\n",
      "44 Train Loss 35138.47 Test MSE 5394.831376625968 Test RE 0.1302051911803744\n",
      "45 Train Loss 34588.895 Test MSE 4513.412806779609 Test RE 0.11909455078714086\n",
      "46 Train Loss 34137.824 Test MSE 4311.434645704719 Test RE 0.11639927246905604\n",
      "47 Train Loss 33321.566 Test MSE 4409.146277151425 Test RE 0.1177108825213549\n",
      "48 Train Loss 32987.07 Test MSE 4089.131269261897 Test RE 0.1133587082694946\n",
      "49 Train Loss 32600.268 Test MSE 4067.249432407645 Test RE 0.11305499778360587\n",
      "50 Train Loss 32425.314 Test MSE 4253.209365460669 Test RE 0.11561062338585582\n",
      "51 Train Loss 32329.021 Test MSE 4236.462683314612 Test RE 0.11538279496705145\n",
      "52 Train Loss 32266.281 Test MSE 4055.2860659382486 Test RE 0.11288860592240402\n",
      "53 Train Loss 32195.38 Test MSE 4127.817843574552 Test RE 0.11389367964345748\n",
      "54 Train Loss 31982.059 Test MSE 4350.935763268947 Test RE 0.11693127843291311\n",
      "55 Train Loss 31727.088 Test MSE 4539.74258873844 Test RE 0.11944142506690252\n",
      "56 Train Loss 31567.355 Test MSE 4601.612671705389 Test RE 0.12025257709047944\n",
      "57 Train Loss 31433.465 Test MSE 4293.8032043076355 Test RE 0.11616102353247042\n",
      "58 Train Loss 30963.227 Test MSE 4149.610069221681 Test RE 0.11419392660713662\n",
      "59 Train Loss 30297.443 Test MSE 3843.797496811775 Test RE 0.10990554698168047\n",
      "60 Train Loss 30008.344 Test MSE 3885.0288965510454 Test RE 0.11049343852352604\n",
      "61 Train Loss 29902.908 Test MSE 3924.77312728152 Test RE 0.11105717982442684\n",
      "62 Train Loss 29783.166 Test MSE 3780.622334498219 Test RE 0.10899862264331367\n",
      "63 Train Loss 29716.564 Test MSE 3735.186370619155 Test RE 0.10834166369094482\n",
      "64 Train Loss 29541.564 Test MSE 3718.171560935637 Test RE 0.10809461886980057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Train Loss 29486.523 Test MSE 3740.0314061448375 Test RE 0.10841190772232097\n",
      "66 Train Loss 29450.541 Test MSE 3768.141493052481 Test RE 0.10881855716469332\n",
      "67 Train Loss 29420.605 Test MSE 3780.0077973882544 Test RE 0.10898976346420498\n",
      "68 Train Loss 29336.303 Test MSE 3657.0455666649545 Test RE 0.10720240981879668\n",
      "69 Train Loss 29163.283 Test MSE 3493.9212935881155 Test RE 0.10478422870217027\n",
      "70 Train Loss 28908.777 Test MSE 3483.8043796218612 Test RE 0.10463241338556352\n",
      "71 Train Loss 28786.713 Test MSE 3596.9709075887786 Test RE 0.10631825130385762\n",
      "72 Train Loss 28722.0 Test MSE 3601.0499247903304 Test RE 0.10637851744286231\n",
      "73 Train Loss 28539.344 Test MSE 3537.699111333602 Test RE 0.10543864313453263\n",
      "74 Train Loss 28460.32 Test MSE 3487.382398038196 Test RE 0.10468613061324077\n",
      "75 Train Loss 28375.018 Test MSE 3503.5210044586584 Test RE 0.10492807972575813\n",
      "76 Train Loss 28317.887 Test MSE 3621.0021642883676 Test RE 0.1066728146357983\n",
      "77 Train Loss 28244.207 Test MSE 3667.3342158562828 Test RE 0.10735310431932382\n",
      "78 Train Loss 28138.887 Test MSE 3599.038216754369 Test RE 0.10634879938575859\n",
      "79 Train Loss 27982.486 Test MSE 3513.84861326941 Test RE 0.10508261836548753\n",
      "80 Train Loss 27798.998 Test MSE 3392.9152042226083 Test RE 0.10325851265687848\n",
      "81 Train Loss 27698.617 Test MSE 3395.831049614532 Test RE 0.10330287291645596\n",
      "82 Train Loss 27654.389 Test MSE 3371.0775360122416 Test RE 0.10292567716802101\n",
      "83 Train Loss 27590.43 Test MSE 3327.096822816995 Test RE 0.10225206372076168\n",
      "84 Train Loss 27514.236 Test MSE 3418.5969922968056 Test RE 0.10364857014946952\n",
      "85 Train Loss 27425.3 Test MSE 3373.7031789122025 Test RE 0.1029657524064576\n",
      "86 Train Loss 27370.484 Test MSE 3368.5533937493024 Test RE 0.10288713641967279\n",
      "87 Train Loss 27326.188 Test MSE 3364.97690684499 Test RE 0.10283250284598701\n",
      "88 Train Loss 27283.703 Test MSE 3367.6027511587745 Test RE 0.10287261745795198\n",
      "89 Train Loss 27219.145 Test MSE 3412.1322518929555 Test RE 0.1035505214206312\n",
      "90 Train Loss 27108.719 Test MSE 3425.5170794558885 Test RE 0.10375342230538982\n",
      "91 Train Loss 27010.064 Test MSE 3389.6569469799483 Test RE 0.10320892055277381\n",
      "92 Train Loss 26979.42 Test MSE 3443.319708602154 Test RE 0.10402267947450437\n",
      "93 Train Loss 26927.297 Test MSE 3450.969486958957 Test RE 0.10413816526061986\n",
      "94 Train Loss 26714.867 Test MSE 3278.311987600886 Test RE 0.10149964027940786\n",
      "95 Train Loss 26459.033 Test MSE 3237.732417467206 Test RE 0.10086949324840842\n",
      "96 Train Loss 26395.258 Test MSE 3152.3005483232128 Test RE 0.09952980907288346\n",
      "97 Train Loss 26308.0 Test MSE 3085.175449993745 Test RE 0.09846441287433594\n",
      "98 Train Loss 26044.152 Test MSE 2995.324042364557 Test RE 0.09701999958227868\n",
      "99 Train Loss 25765.756 Test MSE 3124.5800239331707 Test RE 0.09909122290382182\n",
      "Training time: 273.62\n",
      "3D_HTTP_swish_tune3\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smartlab/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 249601.31 Test MSE 90786.01725580585 Test RE 0.5341323035958686\n",
      "1 Train Loss 229821.17 Test MSE 78701.44542171125 Test RE 0.4973140357193832\n",
      "2 Train Loss 204202.61 Test MSE 62263.379013861544 Test RE 0.4423394821862571\n",
      "3 Train Loss 192478.25 Test MSE 54317.00514098701 Test RE 0.4131495369963938\n",
      "4 Train Loss 186814.64 Test MSE 50551.26535650798 Test RE 0.39857070761142155\n",
      "5 Train Loss 184330.53 Test MSE 49256.8663489742 Test RE 0.39343478224915285\n",
      "6 Train Loss 179879.42 Test MSE 47625.48422645044 Test RE 0.3868646649396842\n",
      "7 Train Loss 177446.11 Test MSE 45214.033653063336 Test RE 0.3769432657064623\n",
      "8 Train Loss 174263.47 Test MSE 43280.37599204344 Test RE 0.36879487287293056\n",
      "9 Train Loss 169837.97 Test MSE 41584.75447618083 Test RE 0.36149844461787356\n",
      "10 Train Loss 166424.8 Test MSE 39851.058551823044 Test RE 0.35388266825183023\n",
      "11 Train Loss 161619.4 Test MSE 39283.87831921906 Test RE 0.3513553257005203\n",
      "12 Train Loss 153741.6 Test MSE 35797.084360465204 Test RE 0.3354001015808374\n",
      "13 Train Loss 146454.1 Test MSE 32332.38803407634 Test RE 0.3187559156191327\n",
      "14 Train Loss 139361.7 Test MSE 30105.438329996767 Test RE 0.3075826537639067\n",
      "15 Train Loss 131297.31 Test MSE 28096.39325446452 Test RE 0.29714241495755744\n",
      "16 Train Loss 122765.484 Test MSE 22757.414573278664 Test RE 0.2674242723489786\n",
      "17 Train Loss 113905.0 Test MSE 19277.69110726798 Test RE 0.24613131430811233\n",
      "18 Train Loss 108667.44 Test MSE 17529.55990304869 Test RE 0.2347063656675192\n",
      "19 Train Loss 104432.31 Test MSE 16420.601199947956 Test RE 0.22716106130315117\n",
      "20 Train Loss 96610.14 Test MSE 14287.06174979578 Test RE 0.2118901766798049\n",
      "21 Train Loss 90906.42 Test MSE 13385.065426374302 Test RE 0.20509242084421736\n",
      "22 Train Loss 83810.65 Test MSE 12671.465075252396 Test RE 0.19955048040992981\n",
      "23 Train Loss 80141.06 Test MSE 11455.49328413675 Test RE 0.18973447928107434\n",
      "24 Train Loss 75953.695 Test MSE 9513.717664383683 Test RE 0.17290776280056439\n",
      "25 Train Loss 74346.83 Test MSE 8708.820840681488 Test RE 0.16543181720723454\n",
      "26 Train Loss 72293.305 Test MSE 8665.785608408356 Test RE 0.16502256468878954\n",
      "27 Train Loss 69808.85 Test MSE 8226.710948923213 Test RE 0.16078757357459705\n",
      "28 Train Loss 66947.07 Test MSE 7525.202347723163 Test RE 0.1537795031369239\n",
      "29 Train Loss 65274.562 Test MSE 7357.711816887822 Test RE 0.1520585164506202\n",
      "30 Train Loss 62791.164 Test MSE 7368.475959423193 Test RE 0.15216970464210217\n",
      "31 Train Loss 61143.97 Test MSE 6748.342055394616 Test RE 0.14562565979300474\n",
      "32 Train Loss 58058.887 Test MSE 6502.575143612513 Test RE 0.1429493062446818\n",
      "33 Train Loss 54380.93 Test MSE 5643.124265551632 Test RE 0.13316778285547642\n",
      "34 Train Loss 53526.344 Test MSE 5641.634799668987 Test RE 0.13315020731134106\n",
      "35 Train Loss 51703.78 Test MSE 6065.262641623565 Test RE 0.13805882347443865\n",
      "36 Train Loss 49443.7 Test MSE 5335.991506996723 Test RE 0.12949318922717962\n",
      "37 Train Loss 48450.625 Test MSE 5364.721074668312 Test RE 0.1298413240742349\n",
      "38 Train Loss 46881.266 Test MSE 5047.868790765893 Test RE 0.1259486135403341\n",
      "39 Train Loss 46555.89 Test MSE 5074.2901739940335 Test RE 0.12627780132240846\n",
      "40 Train Loss 45976.23 Test MSE 4882.7827184614325 Test RE 0.12387197489184829\n",
      "41 Train Loss 45659.68 Test MSE 4668.304923776207 Test RE 0.12112086673303966\n",
      "42 Train Loss 45479.137 Test MSE 4695.283144076303 Test RE 0.1214703424157652\n",
      "43 Train Loss 44694.293 Test MSE 4729.035647846726 Test RE 0.1219061613265534\n",
      "44 Train Loss 43915.406 Test MSE 4606.874082519293 Test RE 0.1203213048934997\n",
      "45 Train Loss 43425.137 Test MSE 4597.331115108387 Test RE 0.1201966197477355\n",
      "46 Train Loss 43175.535 Test MSE 4460.824139511107 Test RE 0.11839869438482566\n",
      "47 Train Loss 42948.125 Test MSE 4446.7789391463775 Test RE 0.11821215436864937\n",
      "48 Train Loss 42541.867 Test MSE 4392.610514600422 Test RE 0.11748994773500088\n",
      "49 Train Loss 42078.203 Test MSE 4214.2235610284615 Test RE 0.11507954804991764\n",
      "50 Train Loss 41906.855 Test MSE 4428.463172389802 Test RE 0.11796845208697351\n",
      "51 Train Loss 41517.6 Test MSE 4413.6390661956 Test RE 0.117770839197555\n",
      "52 Train Loss 41138.79 Test MSE 4444.334647369169 Test RE 0.11817966065596881\n",
      "53 Train Loss 40875.547 Test MSE 4314.874538979224 Test RE 0.11644569799488605\n",
      "54 Train Loss 40616.082 Test MSE 4396.8486436726025 Test RE 0.1175466130725004\n",
      "55 Train Loss 40350.277 Test MSE 4240.919088245936 Test RE 0.11544346554815912\n",
      "56 Train Loss 40079.227 Test MSE 4179.574406540785 Test RE 0.11460548219616545\n",
      "57 Train Loss 39378.633 Test MSE 4207.215642110055 Test RE 0.11498382416598237\n",
      "58 Train Loss 38817.867 Test MSE 4366.776957794881 Test RE 0.11714395086320342\n",
      "59 Train Loss 38382.81 Test MSE 4225.201126715186 Test RE 0.11522933503512424\n",
      "60 Train Loss 37965.28 Test MSE 4130.3631637852895 Test RE 0.11392878913957462\n",
      "61 Train Loss 37787.406 Test MSE 4340.817499054749 Test RE 0.11679523525789237\n",
      "62 Train Loss 37144.336 Test MSE 4393.324444173056 Test RE 0.11749949514877049\n",
      "63 Train Loss 36862.53 Test MSE 4491.74385053607 Test RE 0.11880831954509201\n",
      "64 Train Loss 36698.777 Test MSE 4502.577329484167 Test RE 0.11895150806203202\n",
      "65 Train Loss 36620.402 Test MSE 4405.156527755849 Test RE 0.11765761334153478\n",
      "66 Train Loss 36484.543 Test MSE 4294.442487450361 Test RE 0.11616967053104199\n",
      "67 Train Loss 36362.73 Test MSE 4297.052562738745 Test RE 0.11620496795669467\n",
      "68 Train Loss 36228.824 Test MSE 4267.217744437054 Test RE 0.11580085456977962\n",
      "69 Train Loss 36177.383 Test MSE 4268.688878187023 Test RE 0.1158208141635107\n",
      "70 Train Loss 36068.918 Test MSE 4247.217216595401 Test RE 0.11552915546643677\n",
      "71 Train Loss 35837.85 Test MSE 4199.299232351302 Test RE 0.11487559490695633\n",
      "72 Train Loss 35477.24 Test MSE 4332.152023167723 Test RE 0.11667859917481489\n",
      "73 Train Loss 35352.703 Test MSE 4329.068624794729 Test RE 0.11663706893309306\n",
      "74 Train Loss 35154.32 Test MSE 4485.276230207797 Test RE 0.11872275323352995\n",
      "75 Train Loss 35059.395 Test MSE 4418.274500940698 Test RE 0.11783266751754498\n",
      "76 Train Loss 34938.414 Test MSE 4485.777463915623 Test RE 0.11872938673616518\n",
      "77 Train Loss 34898.54 Test MSE 4584.041979952467 Test RE 0.12002277267650238\n",
      "78 Train Loss 34734.5 Test MSE 4643.382258796746 Test RE 0.12079712026142919\n",
      "79 Train Loss 34656.33 Test MSE 4588.523725742769 Test RE 0.12008143053193314\n",
      "80 Train Loss 34552.113 Test MSE 4713.028929345379 Test RE 0.1216996740270078\n",
      "81 Train Loss 34440.63 Test MSE 4595.561794464865 Test RE 0.12017348819370846\n",
      "82 Train Loss 34341.895 Test MSE 4487.087603132427 Test RE 0.11874672382776504\n",
      "83 Train Loss 34181.777 Test MSE 4449.6007304556515 Test RE 0.1182496553477665\n",
      "84 Train Loss 34058.42 Test MSE 4394.37988529458 Test RE 0.1175136081915492\n",
      "85 Train Loss 33975.28 Test MSE 4493.422419644262 Test RE 0.11883051686460673\n",
      "86 Train Loss 33913.566 Test MSE 4509.5351314132695 Test RE 0.11904338005905976\n",
      "87 Train Loss 33822.97 Test MSE 4540.343212474892 Test RE 0.11944932606359168\n",
      "88 Train Loss 33747.305 Test MSE 4480.294039179065 Test RE 0.1186567970075798\n",
      "89 Train Loss 33476.56 Test MSE 4564.370445088087 Test RE 0.1197649684727041\n",
      "90 Train Loss 33213.234 Test MSE 4530.002830353667 Test RE 0.11931322889348304\n",
      "91 Train Loss 32624.092 Test MSE 4458.798029340301 Test RE 0.1183718029364057\n",
      "92 Train Loss 31672.906 Test MSE 4395.424941721101 Test RE 0.11752758070349083\n",
      "93 Train Loss 31158.582 Test MSE 4594.810905234931 Test RE 0.1201636699529361\n",
      "94 Train Loss 30409.914 Test MSE 4712.356002931459 Test RE 0.12169098557528232\n",
      "95 Train Loss 30130.004 Test MSE 4554.787235486313 Test RE 0.11963917501675227\n",
      "96 Train Loss 29980.605 Test MSE 4554.5031121895645 Test RE 0.11963544346957054\n",
      "97 Train Loss 29859.484 Test MSE 4578.351310125083 Test RE 0.11994825088117732\n",
      "98 Train Loss 29657.182 Test MSE 4535.283331895751 Test RE 0.1193827487388765\n",
      "99 Train Loss 29415.246 Test MSE 4500.610789244997 Test RE 0.11892552866650499\n",
      "Training time: 275.67\n",
      "3D_HTTP_swish_tune3\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 243731.12 Test MSE 88095.54260793593 Test RE 0.5261581836593797\n",
      "1 Train Loss 233749.94 Test MSE 80560.97199142263 Test RE 0.5031549052021328\n",
      "2 Train Loss 210925.98 Test MSE 67240.46406332134 Test RE 0.4596790522588234\n",
      "3 Train Loss 193687.17 Test MSE 57500.84193707409 Test RE 0.4250856693156762\n",
      "4 Train Loss 186471.89 Test MSE 52539.83796896186 Test RE 0.4063345270475822\n",
      "5 Train Loss 179307.92 Test MSE 49658.3886257863 Test RE 0.3950350891087305\n",
      "6 Train Loss 173763.12 Test MSE 46949.741078157116 Test RE 0.3841103087976984\n",
      "7 Train Loss 166735.42 Test MSE 43628.74616931637 Test RE 0.3702761404762377\n",
      "8 Train Loss 161490.08 Test MSE 39699.03075983934 Test RE 0.35320700979832353\n",
      "9 Train Loss 155386.2 Test MSE 36559.01576599896 Test RE 0.33895075827792914\n",
      "10 Train Loss 145423.73 Test MSE 32145.4646746805 Test RE 0.31783316761333574\n",
      "11 Train Loss 131342.73 Test MSE 26874.357909617196 Test RE 0.2906085654184831\n",
      "12 Train Loss 119265.4 Test MSE 23494.987291033158 Test RE 0.2717233557421979\n",
      "13 Train Loss 110877.02 Test MSE 21235.984911352487 Test RE 0.2583304296431097\n",
      "14 Train Loss 103334.234 Test MSE 18254.187843720778 Test RE 0.23950832848830536\n",
      "15 Train Loss 94093.11 Test MSE 15006.22365177744 Test RE 0.21715761819756704\n",
      "16 Train Loss 87873.875 Test MSE 12816.811855409887 Test RE 0.20069167921048894\n",
      "17 Train Loss 84240.3 Test MSE 10832.537138612402 Test RE 0.18450343477353845\n",
      "18 Train Loss 81301.66 Test MSE 9766.989254800093 Test RE 0.17519419713653028\n",
      "19 Train Loss 75593.234 Test MSE 9852.422958851143 Test RE 0.1759587572434535\n",
      "20 Train Loss 65096.47 Test MSE 9795.838497220175 Test RE 0.1754527462660876\n",
      "21 Train Loss 61412.188 Test MSE 7380.413628283995 Test RE 0.15229291983620774\n",
      "22 Train Loss 58527.02 Test MSE 6782.5227105050535 Test RE 0.14599399422290513\n",
      "23 Train Loss 53671.53 Test MSE 6992.608254368178 Test RE 0.1482378001628648\n",
      "24 Train Loss 50817.844 Test MSE 6559.2980953737615 Test RE 0.14357143672354875\n",
      "25 Train Loss 48928.49 Test MSE 5603.060248121627 Test RE 0.13269422074522216\n",
      "26 Train Loss 45743.516 Test MSE 5236.634088532112 Test RE 0.12828192739801206\n",
      "27 Train Loss 44145.758 Test MSE 4949.153748848247 Test RE 0.1247110210756636\n",
      "28 Train Loss 43201.6 Test MSE 4550.805419905102 Test RE 0.11958686902903673\n",
      "29 Train Loss 42432.06 Test MSE 4800.012749702781 Test RE 0.1228175861905886\n",
      "30 Train Loss 42113.4 Test MSE 4663.060643721278 Test RE 0.12105281524039906\n",
      "31 Train Loss 40706.09 Test MSE 4181.899097231257 Test RE 0.11463734970655337\n",
      "32 Train Loss 39911.668 Test MSE 4029.7237824699628 Test RE 0.11253224975704565\n",
      "33 Train Loss 38598.062 Test MSE 3996.6091413793815 Test RE 0.11206892366731037\n",
      "34 Train Loss 37334.312 Test MSE 4163.355671356828 Test RE 0.1143829041886084\n",
      "35 Train Loss 36000.95 Test MSE 4245.508490728116 Test RE 0.11550591348169825\n",
      "36 Train Loss 35469.254 Test MSE 4433.073414436941 Test RE 0.11802984151527292\n",
      "37 Train Loss 35057.55 Test MSE 4470.296253853479 Test RE 0.11852433162432781\n",
      "38 Train Loss 34743.324 Test MSE 4457.047263065943 Test RE 0.11834856105523053\n",
      "39 Train Loss 34152.56 Test MSE 4342.479606913152 Test RE 0.11681759368451462\n",
      "40 Train Loss 33866.316 Test MSE 4442.435641212269 Test RE 0.11815440964547018\n",
      "41 Train Loss 33431.543 Test MSE 4710.628009504398 Test RE 0.12166867184263612\n",
      "42 Train Loss 33128.434 Test MSE 4672.200333699688 Test RE 0.12117139010820534\n",
      "43 Train Loss 32766.887 Test MSE 4506.571801671954 Test RE 0.11900426042143947\n",
      "44 Train Loss 32536.154 Test MSE 4452.159217395562 Test RE 0.11828364679330225\n",
      "45 Train Loss 32379.998 Test MSE 4477.6621680170365 Test RE 0.11862194044736102\n",
      "46 Train Loss 32326.404 Test MSE 4592.886470410682 Test RE 0.12013850337110105\n",
      "47 Train Loss 32173.877 Test MSE 4525.017043842691 Test RE 0.11924755188616926\n",
      "48 Train Loss 32080.752 Test MSE 4552.020384099412 Test RE 0.11960283148560377\n",
      "49 Train Loss 32007.457 Test MSE 4483.895507381277 Test RE 0.11870447834651623\n",
      "50 Train Loss 31905.166 Test MSE 4505.927487982853 Test RE 0.1189957529773939\n",
      "51 Train Loss 31736.348 Test MSE 4579.229935943608 Test RE 0.11995975989033357\n",
      "52 Train Loss 31647.908 Test MSE 4651.713545113628 Test RE 0.12090544048125197\n",
      "53 Train Loss 31548.75 Test MSE 4767.805732655798 Test RE 0.12240485335715375\n",
      "54 Train Loss 31456.94 Test MSE 4853.786269616221 Test RE 0.12350361979211355\n",
      "55 Train Loss 31215.143 Test MSE 4721.254134554346 Test RE 0.12180582321987196\n",
      "56 Train Loss 31066.068 Test MSE 4496.145607622363 Test RE 0.11886651935796115\n",
      "57 Train Loss 30956.713 Test MSE 4400.26766712581 Test RE 0.11759230676823279\n",
      "58 Train Loss 30833.47 Test MSE 4171.740732570717 Test RE 0.11449803069958614\n",
      "59 Train Loss 30640.562 Test MSE 3994.5694861327434 Test RE 0.11204032302968249\n",
      "60 Train Loss 30502.605 Test MSE 4020.351955616219 Test RE 0.11240131687995347\n",
      "61 Train Loss 30421.941 Test MSE 4134.2038311380675 Test RE 0.11398174585218245\n",
      "62 Train Loss 30382.283 Test MSE 4163.154103306933 Test RE 0.11438013524213499\n",
      "63 Train Loss 30333.32 Test MSE 4177.627206422832 Test RE 0.11457878261093409\n",
      "64 Train Loss 30242.406 Test MSE 4105.7637847461365 Test RE 0.11358901722530668\n",
      "65 Train Loss 30139.664 Test MSE 4064.4205699390986 Test RE 0.11301567481181109\n",
      "66 Train Loss 30014.182 Test MSE 4032.178089310683 Test RE 0.11256651347397141\n",
      "67 Train Loss 29976.607 Test MSE 4111.09592669991 Test RE 0.11366275213521126\n",
      "68 Train Loss 29873.158 Test MSE 4177.1392457068905 Test RE 0.11457209082457498\n",
      "69 Train Loss 29804.729 Test MSE 4078.1673834792336 Test RE 0.11320663609834723\n",
      "70 Train Loss 29772.984 Test MSE 3934.308968208397 Test RE 0.11119201323788742\n",
      "71 Train Loss 29712.326 Test MSE 3891.522888858619 Test RE 0.1105857472241893\n",
      "72 Train Loss 29555.283 Test MSE 3803.450951001999 Test RE 0.10932721177007483\n",
      "73 Train Loss 29479.96 Test MSE 3796.1970906208244 Test RE 0.10922290875413414\n",
      "74 Train Loss 29194.084 Test MSE 3967.518201778223 Test RE 0.11166030919958281\n",
      "75 Train Loss 28879.87 Test MSE 3922.022913715645 Test RE 0.1110182623535705\n",
      "76 Train Loss 28591.314 Test MSE 3789.677384982508 Test RE 0.10912907705809805\n",
      "77 Train Loss 28414.88 Test MSE 3778.9797642008566 Test RE 0.10897494170733557\n",
      "78 Train Loss 28247.54 Test MSE 3809.8366321868157 Test RE 0.10941894897777574\n",
      "79 Train Loss 28042.475 Test MSE 3602.2239337898027 Test RE 0.10639585671363558\n",
      "80 Train Loss 27824.58 Test MSE 3454.3859684766517 Test RE 0.10418970122814747\n",
      "81 Train Loss 27617.336 Test MSE 3558.580729566875 Test RE 0.10574936629043855\n",
      "82 Train Loss 27326.785 Test MSE 3479.454702896766 Test RE 0.10456707399353907\n",
      "83 Train Loss 27164.785 Test MSE 3525.8449551874 Test RE 0.1052618424950919\n",
      "84 Train Loss 26934.219 Test MSE 3533.597254220264 Test RE 0.10537749891712749\n",
      "85 Train Loss 26754.455 Test MSE 3284.927630304047 Test RE 0.1016020019420077\n",
      "86 Train Loss 26455.299 Test MSE 3194.585685938227 Test RE 0.10019513456741928\n",
      "87 Train Loss 26005.832 Test MSE 3132.7578078305614 Test RE 0.09922081105249186\n",
      "88 Train Loss 25723.152 Test MSE 3152.6953289562794 Test RE 0.09953604122148496\n",
      "89 Train Loss 25511.16 Test MSE 3198.220449024151 Test RE 0.10025211880256774\n",
      "90 Train Loss 25301.908 Test MSE 3039.1996502982292 Test RE 0.09772799245040847\n",
      "91 Train Loss 24890.555 Test MSE 2958.5924781899434 Test RE 0.0964232879793131\n",
      "92 Train Loss 24742.344 Test MSE 2977.1353841536884 Test RE 0.09672498130282339\n",
      "93 Train Loss 24633.537 Test MSE 3072.430661672035 Test RE 0.0982608252984361\n",
      "94 Train Loss 24451.715 Test MSE 3052.7866254816045 Test RE 0.09794619908862823\n",
      "95 Train Loss 24268.762 Test MSE 2856.732842004117 Test RE 0.09474889985655086\n",
      "96 Train Loss 24098.982 Test MSE 2813.394278331927 Test RE 0.09402745082972803\n",
      "97 Train Loss 23912.125 Test MSE 2766.1984516123075 Test RE 0.09323544095440314\n",
      "98 Train Loss 23780.684 Test MSE 2758.154102801167 Test RE 0.0930997738112218\n",
      "99 Train Loss 23703.672 Test MSE 2790.4554611666613 Test RE 0.09364334309462367\n",
      "Training time: 270.79\n",
      "3D_HTTP_swish_tune3\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 246304.61 Test MSE 85681.82628902743 Test RE 0.5189000584434629\n",
      "1 Train Loss 236289.55 Test MSE 81954.39338939503 Test RE 0.5074876550584942\n",
      "2 Train Loss 202777.17 Test MSE 62454.25585843339 Test RE 0.44301698921529964\n",
      "3 Train Loss 178179.95 Test MSE 44333.94446416394 Test RE 0.3732566454746962\n",
      "4 Train Loss 161577.62 Test MSE 39197.53356143611 Test RE 0.3509689791829963\n",
      "5 Train Loss 122037.195 Test MSE 21721.71759273858 Test RE 0.26126813413542427\n",
      "6 Train Loss 93827.44 Test MSE 16620.066829024665 Test RE 0.2285365911050785\n",
      "7 Train Loss 82089.42 Test MSE 14724.531807975978 Test RE 0.21510975690177128\n",
      "8 Train Loss 58561.008 Test MSE 10022.915535575197 Test RE 0.17747467823445845\n",
      "9 Train Loss 54925.08 Test MSE 6136.100119503678 Test RE 0.13886269216616579\n",
      "10 Train Loss 48293.73 Test MSE 6478.468654685201 Test RE 0.14268408781176495\n",
      "11 Train Loss 44978.29 Test MSE 4874.962051453464 Test RE 0.12377273335826613\n",
      "12 Train Loss 41587.305 Test MSE 5971.119515488827 Test RE 0.13698318007417357\n",
      "13 Train Loss 38675.73 Test MSE 5438.94318046983 Test RE 0.13073643046711692\n",
      "14 Train Loss 37369.754 Test MSE 5036.397497990576 Test RE 0.12580542289508148\n",
      "15 Train Loss 37186.195 Test MSE 4815.635976959335 Test RE 0.12301729901928975\n",
      "16 Train Loss 35550.2 Test MSE 4758.584266155851 Test RE 0.12228642376610865\n",
      "17 Train Loss 34681.95 Test MSE 4617.49335619985 Test RE 0.12045990097536761\n",
      "18 Train Loss 34391.984 Test MSE 4732.58823893423 Test RE 0.1219519424824685\n",
      "19 Train Loss 33677.266 Test MSE 4097.843233197342 Test RE 0.1134794003505762\n",
      "20 Train Loss 32524.332 Test MSE 3978.650111540374 Test RE 0.11181684557304747\n",
      "21 Train Loss 32150.84 Test MSE 4038.969329153291 Test RE 0.11266126928026081\n",
      "22 Train Loss 31271.56 Test MSE 4095.9280647989867 Test RE 0.11345287937990009\n",
      "23 Train Loss 31084.936 Test MSE 4115.204214051833 Test RE 0.11371953050447102\n",
      "24 Train Loss 30275.33 Test MSE 4224.264527611078 Test RE 0.11521656290070503\n",
      "25 Train Loss 29561.715 Test MSE 4122.376210944332 Test RE 0.11381858282728917\n",
      "26 Train Loss 29296.07 Test MSE 3932.045185853326 Test RE 0.11116001896152566\n",
      "27 Train Loss 29237.758 Test MSE 3940.3982555187745 Test RE 0.11127802813113155\n",
      "28 Train Loss 28968.541 Test MSE 3886.349115993986 Test RE 0.11051221099586808\n",
      "29 Train Loss 27193.352 Test MSE 3425.643391180817 Test RE 0.10375533517761125\n",
      "30 Train Loss 26545.258 Test MSE 3466.2727281441703 Test RE 0.10436880894202659\n",
      "31 Train Loss 26202.629 Test MSE 3252.068890174995 Test RE 0.10109256842285104\n",
      "32 Train Loss 25934.283 Test MSE 3021.3866975653054 Test RE 0.09744117641574472\n",
      "33 Train Loss 25584.982 Test MSE 2900.531232794992 Test RE 0.09547246491358771\n",
      "34 Train Loss 24888.734 Test MSE 2803.2736103237653 Test RE 0.09385817523554124\n",
      "35 Train Loss 24443.395 Test MSE 2545.029471906693 Test RE 0.08943052291657655\n",
      "36 Train Loss 24251.77 Test MSE 2426.9466429422605 Test RE 0.08733120977932332\n",
      "37 Train Loss 23963.135 Test MSE 2412.7601077670365 Test RE 0.08707559165350648\n",
      "38 Train Loss 23657.1 Test MSE 2607.4550550705217 Test RE 0.09052067375583116\n",
      "39 Train Loss 23577.209 Test MSE 2608.1390079901907 Test RE 0.0905325450668136\n",
      "40 Train Loss 23513.873 Test MSE 2640.279846844916 Test RE 0.09108866615532077\n",
      "41 Train Loss 23399.994 Test MSE 2642.5447557500856 Test RE 0.09112772703483267\n",
      "42 Train Loss 22827.34 Test MSE 2709.226579707811 Test RE 0.09227031984983688\n",
      "43 Train Loss 22216.088 Test MSE 2620.456171478736 Test RE 0.09074606718175805\n",
      "44 Train Loss 22047.05 Test MSE 2663.644778857656 Test RE 0.0914908191135253\n",
      "45 Train Loss 21808.201 Test MSE 2473.3906139179317 Test RE 0.0881628693709293\n",
      "46 Train Loss 21595.557 Test MSE 2248.4179303345672 Test RE 0.08405777347053549\n",
      "47 Train Loss 21477.352 Test MSE 2116.383215880385 Test RE 0.0815523568388665\n",
      "48 Train Loss 21284.818 Test MSE 1926.4457293942464 Test RE 0.07780683536517903\n",
      "49 Train Loss 21196.121 Test MSE 1950.5427033945846 Test RE 0.07829194703039208\n",
      "50 Train Loss 21137.045 Test MSE 2021.2352069931485 Test RE 0.07969806723511234\n",
      "51 Train Loss 21053.113 Test MSE 2125.1058125857503 Test RE 0.08172024157524117\n",
      "52 Train Loss 20744.877 Test MSE 2111.684943990079 Test RE 0.08146178533323357\n",
      "53 Train Loss 20660.863 Test MSE 2017.7279290630715 Test RE 0.07962889056658605\n",
      "54 Train Loss 20584.86 Test MSE 2013.6939301115833 Test RE 0.07954925059863834\n",
      "55 Train Loss 20461.45 Test MSE 1911.1260625572122 Test RE 0.07749684635774233\n",
      "56 Train Loss 20231.418 Test MSE 1888.9271419598406 Test RE 0.0770454446100955\n",
      "57 Train Loss 20145.219 Test MSE 1740.546822436687 Test RE 0.0739574992124002\n",
      "58 Train Loss 20011.041 Test MSE 1917.058456003762 Test RE 0.07761703350028079\n",
      "59 Train Loss 19536.62 Test MSE 1619.8377071398263 Test RE 0.07134690106798787\n",
      "60 Train Loss 19359.117 Test MSE 1658.8526664831982 Test RE 0.07220100949662525\n",
      "61 Train Loss 19259.086 Test MSE 1724.1993019696708 Test RE 0.07360936896890978\n",
      "62 Train Loss 19178.674 Test MSE 1715.8202274312891 Test RE 0.07343029177263842\n",
      "63 Train Loss 19130.107 Test MSE 1769.0424360036154 Test RE 0.07456044436752278\n",
      "64 Train Loss 19089.521 Test MSE 1795.5513964349595 Test RE 0.0751170082731697\n",
      "65 Train Loss 19042.867 Test MSE 1785.4803532773287 Test RE 0.07490605067848272\n",
      "66 Train Loss 19001.596 Test MSE 1754.0477290346107 Test RE 0.07424377835619182\n",
      "67 Train Loss 18896.184 Test MSE 1764.469717996952 Test RE 0.07446401805025885\n",
      "68 Train Loss 18827.844 Test MSE 1770.735536476119 Test RE 0.07459611568062512\n",
      "69 Train Loss 18741.836 Test MSE 1836.7097050027073 Test RE 0.07597306062346361\n",
      "70 Train Loss 18706.697 Test MSE 1791.9805252614883 Test RE 0.07504227728697264\n",
      "71 Train Loss 18684.53 Test MSE 1778.1070051178992 Test RE 0.07475122405838466\n",
      "72 Train Loss 18605.344 Test MSE 1787.2863381704499 Test RE 0.07494392424141015\n",
      "73 Train Loss 18569.604 Test MSE 1825.667440712923 Test RE 0.07574434203465777\n",
      "74 Train Loss 18449.535 Test MSE 1750.9063595325626 Test RE 0.07417726601051099\n",
      "75 Train Loss 18400.453 Test MSE 1774.6518421305532 Test RE 0.07467856159958952\n",
      "76 Train Loss 18350.592 Test MSE 1722.1806997661677 Test RE 0.07356626735372031\n",
      "77 Train Loss 18327.268 Test MSE 1727.4086469264425 Test RE 0.0736778436598673\n",
      "78 Train Loss 18290.076 Test MSE 1733.9616067233112 Test RE 0.07381746057370152\n",
      "79 Train Loss 18264.164 Test MSE 1740.5800294681678 Test RE 0.07395820470829931\n",
      "80 Train Loss 18222.4 Test MSE 1711.8310765793324 Test RE 0.0733448821938035\n",
      "81 Train Loss 18210.803 Test MSE 1705.164864092709 Test RE 0.07320193307178303\n",
      "82 Train Loss 18197.738 Test MSE 1718.083803616705 Test RE 0.0734787118442432\n",
      "83 Train Loss 18177.777 Test MSE 1682.0136651619791 Test RE 0.07270329969722697\n",
      "84 Train Loss 18139.111 Test MSE 1659.0016627746663 Test RE 0.0722042519307855\n",
      "85 Train Loss 18102.037 Test MSE 1651.574942408939 Test RE 0.07204245514540505\n",
      "86 Train Loss 18078.105 Test MSE 1654.380669836303 Test RE 0.07210362273573596\n",
      "87 Train Loss 18028.34 Test MSE 1655.8913285810104 Test RE 0.07213653508662456\n",
      "88 Train Loss 17867.98 Test MSE 1633.5205750094303 Test RE 0.0716476032026151\n",
      "89 Train Loss 17776.297 Test MSE 1628.7113667282301 Test RE 0.0715420574768102\n",
      "90 Train Loss 17749.613 Test MSE 1678.8479283026743 Test RE 0.07263484962488187\n",
      "91 Train Loss 17709.521 Test MSE 1655.0546372035972 Test RE 0.07211830815289279\n",
      "92 Train Loss 17669.06 Test MSE 1702.0694885579296 Test RE 0.07313546137697445\n",
      "93 Train Loss 17592.143 Test MSE 1692.4886705438553 Test RE 0.0729293339601291\n",
      "94 Train Loss 17541.357 Test MSE 1759.431472888283 Test RE 0.07435763023118032\n",
      "95 Train Loss 17492.746 Test MSE 1707.513815547218 Test RE 0.07325233541551664\n",
      "96 Train Loss 17479.191 Test MSE 1703.7526206370048 Test RE 0.07317161331591188\n",
      "97 Train Loss 17472.443 Test MSE 1686.666401454903 Test RE 0.07280378511048176\n",
      "98 Train Loss 17465.514 Test MSE 1662.1423866676882 Test RE 0.07227256602509108\n",
      "99 Train Loss 17419.596 Test MSE 1657.3985953824272 Test RE 0.07216935857913741\n",
      "Training time: 245.59\n",
      "3D_HTTP_swish_tune3\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 247147.53 Test MSE 87000.8518612705 Test RE 0.5228788973818923\n",
      "1 Train Loss 247068.44 Test MSE 87566.91500426045 Test RE 0.524577171478437\n",
      "2 Train Loss 238210.66 Test MSE 79679.4161024345 Test RE 0.5003943917721512\n",
      "3 Train Loss 214484.97 Test MSE 69611.20943387099 Test RE 0.4677124729900369\n",
      "4 Train Loss 192735.36 Test MSE 55419.96077971034 Test RE 0.4173231427247587\n",
      "5 Train Loss 185326.31 Test MSE 48281.66790736285 Test RE 0.3895206573729977\n",
      "6 Train Loss 174198.52 Test MSE 46307.196185770634 Test RE 0.38147282474051175\n",
      "7 Train Loss 161155.06 Test MSE 39255.92315663471 Test RE 0.35123028785149807\n",
      "8 Train Loss 155843.11 Test MSE 35792.957593857 Test RE 0.33538076819296997\n",
      "9 Train Loss 151844.12 Test MSE 34383.495366339856 Test RE 0.32871110349363997\n",
      "10 Train Loss 137219.1 Test MSE 26762.783351000493 Test RE 0.29000467663203827\n",
      "11 Train Loss 117547.59 Test MSE 19071.59505621505 Test RE 0.24481209511679597\n",
      "12 Train Loss 87897.28 Test MSE 11055.493324453022 Test RE 0.18639249664029742\n",
      "13 Train Loss 78826.44 Test MSE 10223.159565321223 Test RE 0.17923876048290535\n",
      "14 Train Loss 63619.44 Test MSE 8414.337552731766 Test RE 0.16261077789043746\n",
      "15 Train Loss 55281.49 Test MSE 5984.616483753586 Test RE 0.13713790935322984\n",
      "16 Train Loss 53209.516 Test MSE 6365.8709400372 Test RE 0.14143870684949703\n",
      "17 Train Loss 48921.492 Test MSE 6302.349214897363 Test RE 0.14073126587134757\n",
      "18 Train Loss 43608.246 Test MSE 5432.9683609740905 Test RE 0.1306646020633747\n",
      "19 Train Loss 41444.445 Test MSE 5207.822731413747 Test RE 0.1279285444709401\n",
      "20 Train Loss 39698.598 Test MSE 5582.289337205593 Test RE 0.13244803930184187\n",
      "21 Train Loss 38359.445 Test MSE 4443.241845359587 Test RE 0.11816513036957553\n",
      "22 Train Loss 37839.668 Test MSE 4367.326892422631 Test RE 0.11715132695402668\n",
      "23 Train Loss 37068.312 Test MSE 4755.889731448497 Test RE 0.12225179669499127\n",
      "24 Train Loss 36164.473 Test MSE 4549.267143950015 Test RE 0.11956665577706377\n",
      "25 Train Loss 35570.645 Test MSE 5027.992733844788 Test RE 0.12570040671928487\n",
      "26 Train Loss 34201.37 Test MSE 4901.0511007368395 Test RE 0.12410348508151031\n",
      "27 Train Loss 33892.766 Test MSE 4639.5873760735485 Test RE 0.12074774842658474\n",
      "28 Train Loss 33339.56 Test MSE 4280.429419207127 Test RE 0.11597998075412869\n",
      "29 Train Loss 32893.953 Test MSE 4591.321702962452 Test RE 0.12011803641258326\n",
      "30 Train Loss 32602.84 Test MSE 4627.7270609436155 Test RE 0.12059331413780955\n",
      "31 Train Loss 32117.473 Test MSE 5016.605482929407 Test RE 0.12555798473258115\n",
      "32 Train Loss 31371.494 Test MSE 4414.487849807638 Test RE 0.11778216286396131\n",
      "33 Train Loss 31237.244 Test MSE 4366.119563173107 Test RE 0.11713513283762236\n",
      "34 Train Loss 30890.408 Test MSE 4329.819343566454 Test RE 0.11664718171357236\n",
      "35 Train Loss 30622.057 Test MSE 4301.229889069409 Test RE 0.11626143784476207\n",
      "36 Train Loss 30464.676 Test MSE 4153.305972318187 Test RE 0.11424476942679371\n",
      "37 Train Loss 29952.016 Test MSE 4160.066026463115 Test RE 0.11433770585289933\n",
      "38 Train Loss 29649.312 Test MSE 3903.9662644436817 Test RE 0.1107624083634287\n",
      "39 Train Loss 29205.21 Test MSE 3848.2068298086265 Test RE 0.10996856685424987\n",
      "40 Train Loss 29008.988 Test MSE 3893.5575246283156 Test RE 0.11061465265802253\n",
      "41 Train Loss 28782.852 Test MSE 4028.599840767704 Test RE 0.112516555317971\n",
      "42 Train Loss 28592.158 Test MSE 3851.7770218624714 Test RE 0.11001956695662761\n",
      "43 Train Loss 28398.498 Test MSE 3716.5016878636147 Test RE 0.10807034288340417\n",
      "44 Train Loss 28243.248 Test MSE 3772.502950126704 Test RE 0.10888151528502436\n",
      "45 Train Loss 27979.404 Test MSE 3770.7452422278193 Test RE 0.1088561469553446\n",
      "46 Train Loss 27696.008 Test MSE 3911.895389486837 Test RE 0.1108748329386381\n",
      "47 Train Loss 27042.662 Test MSE 3525.6447632416766 Test RE 0.10525885415152424\n",
      "48 Train Loss 26864.256 Test MSE 3507.2438614831053 Test RE 0.10498381344640378\n",
      "49 Train Loss 26757.545 Test MSE 3577.1176842927403 Test RE 0.10602443733501367\n",
      "50 Train Loss 26539.828 Test MSE 3479.3442825244138 Test RE 0.1045654147641714\n",
      "51 Train Loss 26336.256 Test MSE 3296.979027495172 Test RE 0.1017882046904455\n",
      "52 Train Loss 26204.031 Test MSE 3206.751740067702 Test RE 0.10038574161077202\n",
      "53 Train Loss 25941.508 Test MSE 3088.306344370278 Test RE 0.09851436197912668\n",
      "54 Train Loss 25638.81 Test MSE 3153.805274439166 Test RE 0.09955356112835773\n",
      "55 Train Loss 25222.746 Test MSE 2996.4707397470293 Test RE 0.0970385688476319\n",
      "56 Train Loss 24903.191 Test MSE 3018.390699127746 Test RE 0.09739285323709157\n",
      "57 Train Loss 24777.902 Test MSE 3028.9631779782558 Test RE 0.09756327249259819\n",
      "58 Train Loss 24600.033 Test MSE 2957.402802173491 Test RE 0.09640389970464795\n",
      "59 Train Loss 24557.252 Test MSE 2984.496449721692 Test RE 0.09684448533449393\n",
      "60 Train Loss 24245.86 Test MSE 2833.230569456815 Test RE 0.09435834646639285\n",
      "61 Train Loss 23862.021 Test MSE 2632.2554131301736 Test RE 0.09095014084310155\n",
      "62 Train Loss 23701.342 Test MSE 2497.420972586927 Test RE 0.08859010969428377\n",
      "63 Train Loss 23490.666 Test MSE 2640.3608857889785 Test RE 0.09109006405120827\n",
      "64 Train Loss 23375.654 Test MSE 2567.792562054179 Test RE 0.08982957200280343\n",
      "65 Train Loss 23289.281 Test MSE 2674.1080433284537 Test RE 0.09167033899229288\n",
      "66 Train Loss 23034.746 Test MSE 2927.2431259293203 Test RE 0.09591107519662569\n",
      "67 Train Loss 22947.074 Test MSE 3004.5984741470593 Test RE 0.09717008516794368\n",
      "68 Train Loss 22879.873 Test MSE 2799.086321718005 Test RE 0.09378805041119682\n",
      "69 Train Loss 22692.719 Test MSE 2737.2306126246726 Test RE 0.09274597185484346\n",
      "70 Train Loss 22294.605 Test MSE 2517.572622525468 Test RE 0.08894680768244215\n",
      "71 Train Loss 22046.346 Test MSE 2422.5982486805324 Test RE 0.08725293842831908\n",
      "72 Train Loss 21785.355 Test MSE 2379.2929306367664 Test RE 0.08646957398472972\n",
      "73 Train Loss 21689.998 Test MSE 2356.7525824634454 Test RE 0.08605901242880479\n",
      "74 Train Loss 21566.242 Test MSE 2350.5907155329633 Test RE 0.08594643564512162\n",
      "75 Train Loss 21448.145 Test MSE 2282.2874322920156 Test RE 0.08468851771822208\n",
      "76 Train Loss 21338.432 Test MSE 2250.207127447247 Test RE 0.08409121165294856\n",
      "77 Train Loss 21274.145 Test MSE 2266.2179105136074 Test RE 0.08438984631668295\n",
      "78 Train Loss 21208.605 Test MSE 2332.1271132189104 Test RE 0.08560822081145636\n",
      "79 Train Loss 21079.545 Test MSE 2281.7127078713647 Test RE 0.08467785393785131\n",
      "80 Train Loss 20953.982 Test MSE 2383.353959574714 Test RE 0.0865433365982957\n",
      "81 Train Loss 20835.15 Test MSE 2426.5937873536986 Test RE 0.08732486097357957\n",
      "82 Train Loss 20720.22 Test MSE 2296.4532362717114 Test RE 0.08495093539640336\n",
      "83 Train Loss 20609.71 Test MSE 2414.604492357367 Test RE 0.08710886686363666\n",
      "84 Train Loss 20546.115 Test MSE 2405.6566396093604 Test RE 0.08694731644166505\n",
      "85 Train Loss 20484.709 Test MSE 2361.1269941098 Test RE 0.0861388432569404\n",
      "86 Train Loss 20392.209 Test MSE 2366.9768351058933 Test RE 0.0862454844528262\n",
      "87 Train Loss 20228.947 Test MSE 2553.7708822354084 Test RE 0.08958397473071679\n",
      "88 Train Loss 19986.146 Test MSE 2339.6986585781024 Test RE 0.08574707715225366\n",
      "89 Train Loss 19915.43 Test MSE 2279.2986202834645 Test RE 0.08463304683880245\n",
      "90 Train Loss 19869.205 Test MSE 2211.062940638671 Test RE 0.0833565852012319\n",
      "91 Train Loss 19803.836 Test MSE 2180.867206211673 Test RE 0.08278544225757706\n",
      "92 Train Loss 19658.455 Test MSE 2105.2084246260392 Test RE 0.08133676810924752\n",
      "93 Train Loss 19534.822 Test MSE 2078.301140757192 Test RE 0.0808153020010253\n",
      "94 Train Loss 19471.027 Test MSE 1943.7351077347614 Test RE 0.07815520412035004\n",
      "95 Train Loss 19405.688 Test MSE 2012.5640703761908 Test RE 0.07952693039768692\n",
      "96 Train Loss 19362.703 Test MSE 2093.0960027165524 Test RE 0.08110244299206784\n",
      "97 Train Loss 19281.893 Test MSE 2022.6543888923127 Test RE 0.07972604176450843\n",
      "98 Train Loss 19136.71 Test MSE 2083.807331803198 Test RE 0.0809222860518572\n",
      "99 Train Loss 19000.01 Test MSE 2371.5206968710327 Test RE 0.08632822705893489\n",
      "Training time: 239.55\n",
      "3D_HTTP_swish_tune3\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 249094.48 Test MSE 89515.02909419514 Test RE 0.5303802464533459\n",
      "1 Train Loss 241361.16 Test MSE 85314.3934286554 Test RE 0.5177862529539994\n",
      "2 Train Loss 220071.84 Test MSE 70128.49316586638 Test RE 0.4694470517395073\n",
      "3 Train Loss 205072.44 Test MSE 60674.59580152467 Test RE 0.4366593944154569\n",
      "4 Train Loss 194733.48 Test MSE 56161.60966773247 Test RE 0.4201062431511344\n",
      "5 Train Loss 191232.98 Test MSE 52920.90526071722 Test RE 0.40780542089982\n",
      "6 Train Loss 187499.25 Test MSE 50918.26947506652 Test RE 0.40001491039527565\n",
      "7 Train Loss 184968.61 Test MSE 49851.64680598287 Test RE 0.3958030321588852\n",
      "8 Train Loss 182212.64 Test MSE 47770.511516781306 Test RE 0.38745324988527063\n",
      "9 Train Loss 181038.72 Test MSE 46992.453189803775 Test RE 0.3842849895560302\n",
      "10 Train Loss 177438.73 Test MSE 45921.67106532038 Test RE 0.3798815522417946\n",
      "11 Train Loss 174977.22 Test MSE 45255.33552351954 Test RE 0.37711539045343095\n",
      "12 Train Loss 173122.52 Test MSE 44110.04139943688 Test RE 0.3723129093115045\n",
      "13 Train Loss 171590.14 Test MSE 42660.735916156606 Test RE 0.36614535898173695\n",
      "14 Train Loss 170013.19 Test MSE 42172.96275318305 Test RE 0.36404612977574996\n",
      "15 Train Loss 168223.08 Test MSE 41344.050242285964 Test RE 0.3604506990117185\n",
      "16 Train Loss 165865.42 Test MSE 40021.78611242242 Test RE 0.3546398997511037\n",
      "17 Train Loss 164782.69 Test MSE 39595.809597130574 Test RE 0.35274752543283505\n",
      "18 Train Loss 162959.22 Test MSE 38886.769284008435 Test RE 0.34957494171627485\n",
      "19 Train Loss 160989.5 Test MSE 38356.336537219875 Test RE 0.3471825770014631\n",
      "20 Train Loss 158990.03 Test MSE 37680.97545818162 Test RE 0.3441124856515451\n",
      "21 Train Loss 158046.8 Test MSE 37061.66892520239 Test RE 0.34127293563169286\n",
      "22 Train Loss 156973.89 Test MSE 36630.4267293454 Test RE 0.3392816341419279\n",
      "23 Train Loss 155475.48 Test MSE 35943.88798357593 Test RE 0.33608713480011565\n",
      "24 Train Loss 153474.66 Test MSE 35189.86780396552 Test RE 0.33254328290566737\n",
      "25 Train Loss 151824.25 Test MSE 34258.439509178876 Test RE 0.3281127830759052\n",
      "26 Train Loss 150490.3 Test MSE 33399.33631637352 Test RE 0.323972599554636\n",
      "27 Train Loss 148438.75 Test MSE 32779.334386470706 Test RE 0.32095151311910847\n",
      "28 Train Loss 147104.94 Test MSE 32259.91954583749 Test RE 0.31839849201130793\n",
      "29 Train Loss 146376.25 Test MSE 31947.937689834205 Test RE 0.3168551545600819\n",
      "30 Train Loss 144815.0 Test MSE 30883.79247586699 Test RE 0.31153344308959263\n",
      "31 Train Loss 143546.3 Test MSE 29971.06257730647 Test RE 0.3068954378134373\n",
      "32 Train Loss 142695.27 Test MSE 29574.484955721586 Test RE 0.3048582534704591\n",
      "33 Train Loss 142112.2 Test MSE 29400.644064197226 Test RE 0.30396094384433253\n",
      "34 Train Loss 141341.17 Test MSE 29040.867230161402 Test RE 0.30209542818698\n",
      "35 Train Loss 140321.05 Test MSE 28444.603554579382 Test RE 0.2989780498589825\n",
      "36 Train Loss 138964.38 Test MSE 27536.3647159432 Test RE 0.29416612849283513\n",
      "37 Train Loss 137402.67 Test MSE 26976.453910624892 Test RE 0.29116005481115786\n",
      "38 Train Loss 135718.7 Test MSE 26285.701109205074 Test RE 0.2874081934375822\n",
      "39 Train Loss 134688.56 Test MSE 25679.98884183926 Test RE 0.2840774608910804\n",
      "40 Train Loss 133311.77 Test MSE 25200.210932424496 Test RE 0.2814112467019931\n",
      "41 Train Loss 131697.75 Test MSE 24700.59263930387 Test RE 0.2786076575671319\n",
      "42 Train Loss 130678.266 Test MSE 24064.75186897586 Test RE 0.27499832984263\n",
      "43 Train Loss 130179.85 Test MSE 23822.897105659555 Test RE 0.2736129507274858\n",
      "44 Train Loss 129469.01 Test MSE 23637.881965449928 Test RE 0.2725484032699529\n",
      "45 Train Loss 128867.23 Test MSE 23313.771669732196 Test RE 0.27067343323217535\n",
      "46 Train Loss 128425.09 Test MSE 23110.271643114185 Test RE 0.2694895240292251\n",
      "47 Train Loss 127790.13 Test MSE 22798.341329299914 Test RE 0.2676646311904655\n",
      "48 Train Loss 127162.68 Test MSE 22668.145331566924 Test RE 0.26689925183206614\n",
      "49 Train Loss 126247.67 Test MSE 22272.42005646037 Test RE 0.26455932058214515\n",
      "50 Train Loss 125195.61 Test MSE 22025.142300470357 Test RE 0.2630865971634908\n",
      "51 Train Loss 123891.92 Test MSE 21682.321411997422 Test RE 0.26103109860044105\n",
      "52 Train Loss 123201.734 Test MSE 21468.791438031956 Test RE 0.25974258638371256\n",
      "53 Train Loss 122253.03 Test MSE 21123.933005428466 Test RE 0.25764798655854\n",
      "54 Train Loss 121319.03 Test MSE 20891.54343369788 Test RE 0.2562268427922073\n",
      "55 Train Loss 120503.76 Test MSE 20697.280598520865 Test RE 0.25503278058902223\n",
      "56 Train Loss 119836.78 Test MSE 20453.721527806167 Test RE 0.25352776718958386\n",
      "57 Train Loss 119001.24 Test MSE 20140.24726024868 Test RE 0.2515774792224414\n",
      "58 Train Loss 116829.81 Test MSE 19514.36650912219 Test RE 0.2476376025995034\n",
      "59 Train Loss 114394.26 Test MSE 19391.43418249777 Test RE 0.2468563637554806\n",
      "60 Train Loss 112853.97 Test MSE 18964.893067391797 Test RE 0.24412629571828628\n",
      "61 Train Loss 111562.445 Test MSE 18738.030776510328 Test RE 0.24266175608920681\n",
      "62 Train Loss 110785.54 Test MSE 18539.441390456628 Test RE 0.24137244205219519\n",
      "63 Train Loss 110422.836 Test MSE 18329.70566325373 Test RE 0.2400032417319187\n",
      "64 Train Loss 110054.8 Test MSE 18149.88650048733 Test RE 0.2388230932079365\n",
      "65 Train Loss 109733.195 Test MSE 17914.85471731726 Test RE 0.237271735830081\n",
      "66 Train Loss 109064.125 Test MSE 17561.648799512088 Test RE 0.2349210893902017\n",
      "67 Train Loss 108321.375 Test MSE 17332.411445682243 Test RE 0.23338280603558625\n",
      "68 Train Loss 107680.664 Test MSE 17163.154326512984 Test RE 0.23224047762046346\n",
      "69 Train Loss 106671.57 Test MSE 16949.064188615335 Test RE 0.23078746902948588\n",
      "70 Train Loss 106224.055 Test MSE 16623.186075002064 Test RE 0.2285580359165096\n",
      "71 Train Loss 105405.555 Test MSE 16139.61498471465 Test RE 0.22520910638960068\n",
      "72 Train Loss 104264.31 Test MSE 15992.148728682434 Test RE 0.22417788745245848\n",
      "73 Train Loss 102269.93 Test MSE 15675.466883517205 Test RE 0.22194716633920059\n",
      "74 Train Loss 100890.14 Test MSE 15568.05192804387 Test RE 0.22118542103001074\n",
      "75 Train Loss 99573.32 Test MSE 15123.1402391462 Test RE 0.21800193674741744\n",
      "76 Train Loss 98768.37 Test MSE 14709.7950339165 Test RE 0.21500208565324405\n",
      "77 Train Loss 97884.43 Test MSE 14350.465842318756 Test RE 0.21235982650087115\n",
      "78 Train Loss 97265.89 Test MSE 14222.858280837832 Test RE 0.2114135425534147\n",
      "79 Train Loss 96560.875 Test MSE 14122.110314118709 Test RE 0.21066343532569712\n",
      "80 Train Loss 95603.15 Test MSE 13869.474972988915 Test RE 0.20877061608094752\n",
      "81 Train Loss 94308.06 Test MSE 13444.069371216578 Test RE 0.20554396719989607\n",
      "82 Train Loss 93758.32 Test MSE 13373.517021174215 Test RE 0.20500392663826272\n",
      "83 Train Loss 92994.57 Test MSE 13245.972170494479 Test RE 0.20402401101552584\n",
      "84 Train Loss 91831.3 Test MSE 13050.83297931523 Test RE 0.20251559769072305\n",
      "85 Train Loss 91231.78 Test MSE 12900.953913041134 Test RE 0.20134936953878435\n",
      "86 Train Loss 90596.84 Test MSE 12817.180364809143 Test RE 0.20069456433665686\n",
      "87 Train Loss 89992.71 Test MSE 12555.231323782027 Test RE 0.19863314621746025\n",
      "88 Train Loss 88746.23 Test MSE 12289.041677520976 Test RE 0.1965162059240168\n",
      "89 Train Loss 87773.12 Test MSE 12102.529255069605 Test RE 0.19501922793221368\n",
      "90 Train Loss 86083.37 Test MSE 11860.327351943124 Test RE 0.19305795440062276\n",
      "91 Train Loss 85325.164 Test MSE 11607.212904380509 Test RE 0.1909867935462112\n",
      "92 Train Loss 84654.12 Test MSE 11381.065433515703 Test RE 0.18911710989731698\n",
      "93 Train Loss 83937.88 Test MSE 11141.475358362964 Test RE 0.18711590922306154\n",
      "94 Train Loss 82837.76 Test MSE 10794.697892023927 Test RE 0.1841809074510378\n",
      "95 Train Loss 82159.164 Test MSE 10618.610600077476 Test RE 0.18267251565015333\n",
      "96 Train Loss 81754.56 Test MSE 10499.545451713098 Test RE 0.18164548654781246\n",
      "97 Train Loss 81143.62 Test MSE 10332.905475443125 Test RE 0.1801982589044553\n",
      "98 Train Loss 79816.09 Test MSE 10192.836825547398 Test RE 0.17897274456005513\n",
      "99 Train Loss 78032.9 Test MSE 10243.058119479258 Test RE 0.1794131125668183\n",
      "Training time: 236.23\n",
      "3D_HTTP_swish_tune3\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss 243215.86 Test MSE 87176.20578430952 Test RE 0.5234055744762371\n",
      "1 Train Loss 237725.05 Test MSE 83103.86396407965 Test RE 0.5110342062069154\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 7.38\n",
      "3D_HTTP_swish_tune3\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.24\n",
      "3D_HTTP_swish_tune3\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 248107.64 Test MSE 87109.57095391792 Test RE 0.5232054986146402\n",
      "1 Train Loss 246962.83 Test MSE 87238.3955182555 Test RE 0.5235922346433747\n",
      "2 Train Loss 229790.84 Test MSE 71152.5365005405 Test RE 0.47286215331917214\n",
      "3 Train Loss 205599.08 Test MSE 59200.88305468049 Test RE 0.43132383166503047\n",
      "4 Train Loss 170011.58 Test MSE 40949.674105472805 Test RE 0.35872743078423214\n",
      "5 Train Loss 158561.94 Test MSE 37706.7717133961 Test RE 0.3442302545608674\n",
      "6 Train Loss 138506.44 Test MSE 27468.97964422393 Test RE 0.293805976603985\n",
      "7 Train Loss 124964.84 Test MSE 23627.23711253779 Test RE 0.2724870279663023\n",
      "8 Train Loss 104479.44 Test MSE 15278.843073418067 Test RE 0.21912130078064737\n",
      "9 Train Loss 72379.21 Test MSE 9016.47189391577 Test RE 0.16832850986338824\n",
      "10 Train Loss 64321.805 Test MSE 7626.178567582869 Test RE 0.15480780299446187\n",
      "11 Train Loss 57054.125 Test MSE 6186.114955957864 Test RE 0.13942747269971834\n",
      "12 Train Loss 45503.418 Test MSE 5189.858989445995 Test RE 0.12770771701204592\n",
      "13 Train Loss 45294.883 Test MSE 5354.096979124647 Test RE 0.1297126938769096\n",
      "14 Train Loss 44286.477 Test MSE 5404.287146331415 Test RE 0.13031924954453963\n",
      "15 Train Loss 41118.164 Test MSE 4591.56778781894 Test RE 0.12012125540218993\n",
      "16 Train Loss 39216.086 Test MSE 4235.333125579204 Test RE 0.1153674118246772\n",
      "17 Train Loss 37505.79 Test MSE 5409.690754490955 Test RE 0.13038438470507488\n",
      "18 Train Loss 35847.508 Test MSE 4719.401067420132 Test RE 0.12178191680500834\n",
      "19 Train Loss 33645.42 Test MSE 4489.769411076893 Test RE 0.1187822043405886\n",
      "20 Train Loss 33254.37 Test MSE 4420.563582231773 Test RE 0.11786318776108105\n",
      "21 Train Loss 32799.145 Test MSE 4475.463451807495 Test RE 0.11859281274643282\n",
      "22 Train Loss 31388.812 Test MSE 4534.899052629768 Test RE 0.11937769091960403\n",
      "23 Train Loss 31084.895 Test MSE 4465.0086401995 Test RE 0.11845421364199772\n",
      "24 Train Loss 30806.984 Test MSE 4428.76857526652 Test RE 0.11797251978293195\n",
      "25 Train Loss 30664.367 Test MSE 4396.703940902738 Test RE 0.1175446787939037\n",
      "26 Train Loss 30616.055 Test MSE 4399.1700133923205 Test RE 0.11757763905994167\n",
      "27 Train Loss 30232.623 Test MSE 4275.11735811684 Test RE 0.11590799218173728\n",
      "28 Train Loss 30186.283 Test MSE 4283.88334322197 Test RE 0.11602676405842442\n",
      "29 Train Loss 30019.945 Test MSE 4322.549939271655 Test RE 0.11654922015131214\n",
      "30 Train Loss 29736.52 Test MSE 4261.102547682444 Test RE 0.11571784979492063\n",
      "31 Train Loss 29698.34 Test MSE 4276.610271412899 Test RE 0.11592822852426544\n",
      "32 Train Loss 29652.85 Test MSE 4273.533958702754 Test RE 0.11588652544429862\n",
      "33 Train Loss 29461.088 Test MSE 4210.924178076563 Test RE 0.1150344904207732\n",
      "34 Train Loss 29157.318 Test MSE 4004.1644282814846 Test RE 0.11217480255830649\n",
      "35 Train Loss 28962.209 Test MSE 3821.1465690712844 Test RE 0.10958123997027108\n",
      "36 Train Loss 28782.275 Test MSE 3531.410400252587 Test RE 0.10534488613612233\n",
      "37 Train Loss 28320.008 Test MSE 3448.8753644813814 Test RE 0.10410656382700426\n",
      "38 Train Loss 28163.904 Test MSE 3407.335159142493 Test RE 0.1034777053436013\n",
      "39 Train Loss 28063.096 Test MSE 3417.2852906663506 Test RE 0.10362868347626587\n",
      "40 Train Loss 27840.275 Test MSE 3279.6518676097917 Test RE 0.10152038013674834\n",
      "41 Train Loss 27332.6 Test MSE 3253.4211457412043 Test RE 0.10111358408782774\n",
      "42 Train Loss 27086.8 Test MSE 3153.3598148036976 Test RE 0.09954653015224253\n",
      "43 Train Loss 25610.576 Test MSE 3002.9622585234897 Test RE 0.09714362358510004\n",
      "44 Train Loss 25068.088 Test MSE 2754.1355526977227 Test RE 0.09303192726171802\n",
      "45 Train Loss 24625.996 Test MSE 2873.137038041341 Test RE 0.09502054839963352\n",
      "46 Train Loss 23877.32 Test MSE 2449.092018534096 Test RE 0.08772874440704395\n",
      "47 Train Loss 23729.807 Test MSE 2484.863441858117 Test RE 0.08836710464268632\n",
      "48 Train Loss 23527.607 Test MSE 2501.1530617035987 Test RE 0.0886562785060312\n",
      "49 Train Loss 23133.957 Test MSE 2486.194920284489 Test RE 0.08839077659467671\n",
      "50 Train Loss 22930.959 Test MSE 2451.6262270342 Test RE 0.08777412151934358\n",
      "51 Train Loss 22643.635 Test MSE 2696.9168113517057 Test RE 0.09206045932916779\n",
      "52 Train Loss 21880.701 Test MSE 2478.04551113754 Test RE 0.0882457912085886\n",
      "53 Train Loss 21280.68 Test MSE 2183.501356096472 Test RE 0.08283542316742491\n",
      "54 Train Loss 20894.057 Test MSE 2130.431350721989 Test RE 0.0818225734085304\n",
      "55 Train Loss 20654.59 Test MSE 2232.439686643727 Test RE 0.08375856524874666\n",
      "56 Train Loss 20415.574 Test MSE 2261.6461306466217 Test RE 0.08430468094588496\n",
      "57 Train Loss 20218.932 Test MSE 2469.109453655978 Test RE 0.08808653633267856\n",
      "58 Train Loss 20088.807 Test MSE 2616.989734843218 Test RE 0.09068602618702162\n",
      "59 Train Loss 19817.475 Test MSE 2662.2380840348656 Test RE 0.09146665735987242\n",
      "60 Train Loss 19626.7 Test MSE 2386.204808620433 Test RE 0.08659508053933397\n",
      "61 Train Loss 19231.791 Test MSE 2184.1141457075846 Test RE 0.08284704604223299\n",
      "62 Train Loss 19031.781 Test MSE 2301.2223247335323 Test RE 0.08503909926532381\n",
      "63 Train Loss 18822.998 Test MSE 2209.876239349148 Test RE 0.08333421301053896\n",
      "64 Train Loss 18681.896 Test MSE 2177.2315213330735 Test RE 0.08271640840610353\n",
      "65 Train Loss 18361.678 Test MSE 2190.3912723482044 Test RE 0.08296601150200293\n",
      "66 Train Loss 18221.457 Test MSE 2130.849049128452 Test RE 0.0818305941981842\n",
      "67 Train Loss 18125.744 Test MSE 2152.331169363594 Test RE 0.08224204669197929\n",
      "68 Train Loss 17898.271 Test MSE 2244.8186701254986 Test RE 0.08399046681663758\n",
      "69 Train Loss 17768.59 Test MSE 2252.312908680225 Test RE 0.08413054942868224\n",
      "70 Train Loss 17602.51 Test MSE 2226.3417910925455 Test RE 0.08364409401780439\n",
      "71 Train Loss 17189.28 Test MSE 2174.192764927366 Test RE 0.0826586647122011\n",
      "72 Train Loss 16728.037 Test MSE 2212.4619945817835 Test RE 0.08338295304336046\n",
      "73 Train Loss 16654.947 Test MSE 2200.6355428898914 Test RE 0.08315979761626618\n",
      "74 Train Loss 16519.621 Test MSE 2042.2336466032962 Test RE 0.08011098576271262\n",
      "75 Train Loss 16415.277 Test MSE 1997.6994947150529 Test RE 0.07923269754130369\n",
      "76 Train Loss 16377.009 Test MSE 1892.514358406281 Test RE 0.07711856749247085\n",
      "77 Train Loss 16177.978 Test MSE 2026.8439237463226 Test RE 0.07980856754095716\n",
      "78 Train Loss 16084.607 Test MSE 1980.8105194992484 Test RE 0.07889706163668322\n",
      "79 Train Loss 15896.449 Test MSE 1996.5427805464974 Test RE 0.07920975543846233\n",
      "80 Train Loss 15683.483 Test MSE 1934.9987172270055 Test RE 0.07797936654387783\n",
      "81 Train Loss 15592.8125 Test MSE 1912.6276693701761 Test RE 0.0775272857267769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 Train Loss 15566.503 Test MSE 1914.8896282471903 Test RE 0.07757311579538322\n",
      "83 Train Loss 15540.447 Test MSE 1883.7412667413555 Test RE 0.07693961134085756\n",
      "84 Train Loss 15373.677 Test MSE 2053.4902368389253 Test RE 0.0803314642884311\n",
      "85 Train Loss 15250.854 Test MSE 2090.8794244484166 Test RE 0.08105948807469326\n",
      "86 Train Loss 15185.879 Test MSE 2186.194810705256 Test RE 0.0828864981733488\n",
      "87 Train Loss 15153.588 Test MSE 2276.6511592824377 Test RE 0.0845838808825967\n",
      "88 Train Loss 15107.114 Test MSE 2306.722925856844 Test RE 0.08514067288745227\n",
      "89 Train Loss 15011.942 Test MSE 2377.5824074553148 Test RE 0.08643848600854599\n",
      "90 Train Loss 14981.961 Test MSE 2400.286593755838 Test RE 0.0868502178104331\n",
      "91 Train Loss 14917.447 Test MSE 2267.7324418729 Test RE 0.08441804080780076\n",
      "92 Train Loss 14906.588 Test MSE 2263.8731273462104 Test RE 0.08434617728099927\n",
      "93 Train Loss 14858.627 Test MSE 2267.4012040579723 Test RE 0.08441187529461584\n",
      "94 Train Loss 14793.813 Test MSE 2248.548074038236 Test RE 0.08406020616588013\n",
      "95 Train Loss 14765.595 Test MSE 2233.186976085545 Test RE 0.08377258279526821\n",
      "96 Train Loss 14698.204 Test MSE 2128.1268248665046 Test RE 0.08177830696072719\n",
      "97 Train Loss 14579.929 Test MSE 2347.6990710579958 Test RE 0.08589355467904392\n",
      "98 Train Loss 14546.408 Test MSE 2385.1256171455093 Test RE 0.08657549646150654\n",
      "99 Train Loss 14527.001 Test MSE 2314.759754948537 Test RE 0.0852888627845632\n",
      "Training time: 238.71\n",
      "3D_HTTP_swish_tune3\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 239415.53 Test MSE 84021.10772745982 Test RE 0.5138466904229082\n",
      "1 Train Loss 224158.83 Test MSE 69703.09774080155 Test RE 0.4680210664926587\n",
      "2 Train Loss 201071.27 Test MSE 60178.538338459 Test RE 0.43487073230211726\n",
      "3 Train Loss 187054.17 Test MSE 52786.56455549276 Test RE 0.40728748115681973\n",
      "4 Train Loss 178244.31 Test MSE 46883.0317474991 Test RE 0.38383732699350265\n",
      "5 Train Loss 173593.11 Test MSE 45538.53170287371 Test RE 0.37829349552383673\n",
      "6 Train Loss 167120.95 Test MSE 41999.57245855915 Test RE 0.3632969877254012\n",
      "7 Train Loss 161798.38 Test MSE 38871.36228592019 Test RE 0.3495056837894899\n",
      "8 Train Loss 158716.58 Test MSE 36677.3311300984 Test RE 0.33949878573014347\n",
      "9 Train Loss 152583.27 Test MSE 34810.48449837588 Test RE 0.330745844312216\n",
      "10 Train Loss 143707.81 Test MSE 30701.286201321822 Test RE 0.31061158325989763\n",
      "11 Train Loss 130103.47 Test MSE 26143.722071509696 Test RE 0.28663094214866347\n",
      "12 Train Loss 117068.59 Test MSE 21549.33492874153 Test RE 0.2602293624950233\n",
      "13 Train Loss 109350.93 Test MSE 18929.976103472934 Test RE 0.24390145721863693\n",
      "14 Train Loss 99376.22 Test MSE 16055.988041321489 Test RE 0.22462489143184958\n",
      "15 Train Loss 83561.42 Test MSE 12591.358352949039 Test RE 0.19891871924017132\n",
      "16 Train Loss 72398.7 Test MSE 9362.309023595952 Test RE 0.17152635079302098\n",
      "17 Train Loss 62768.586 Test MSE 8337.55393356981 Test RE 0.16186713889094806\n",
      "18 Train Loss 52597.133 Test MSE 5987.123447535684 Test RE 0.13716662997182155\n",
      "19 Train Loss 49107.56 Test MSE 5676.659203691083 Test RE 0.13356287945386608\n",
      "20 Train Loss 46538.688 Test MSE 5001.172658585332 Test RE 0.12536470594101673\n",
      "21 Train Loss 45333.074 Test MSE 4635.658961159488 Test RE 0.12069661804911391\n",
      "22 Train Loss 43237.508 Test MSE 4542.152425623731 Test RE 0.1194731224768774\n",
      "23 Train Loss 42559.79 Test MSE 4428.728070998216 Test RE 0.11797198031000194\n",
      "24 Train Loss 40826.234 Test MSE 4556.189803450182 Test RE 0.11965759400643051\n",
      "25 Train Loss 40418.61 Test MSE 4439.424002715054 Test RE 0.11811435293718714\n",
      "26 Train Loss 39436.465 Test MSE 4556.959239081311 Test RE 0.11966769728719663\n",
      "27 Train Loss 39111.953 Test MSE 4531.039298490222 Test RE 0.11932687759215194\n",
      "28 Train Loss 38250.324 Test MSE 4448.41814992806 Test RE 0.11823394056335133\n",
      "29 Train Loss 36625.832 Test MSE 4156.93968224675 Test RE 0.11429473463475447\n",
      "30 Train Loss 34660.89 Test MSE 4157.295265985007 Test RE 0.11429962290389417\n",
      "31 Train Loss 33854.27 Test MSE 4096.522000748456 Test RE 0.11346110478083198\n",
      "32 Train Loss 33408.32 Test MSE 4317.336100913732 Test RE 0.116478908396038\n",
      "33 Train Loss 32864.656 Test MSE 4842.6821480948065 Test RE 0.1233622678278591\n",
      "34 Train Loss 31914.967 Test MSE 4956.505060337632 Test RE 0.12480360754790454\n",
      "35 Train Loss 31181.275 Test MSE 4807.547642935801 Test RE 0.12291394577962189\n",
      "36 Train Loss 30897.271 Test MSE 4756.316899024045 Test RE 0.12225728681713185\n",
      "37 Train Loss 30746.123 Test MSE 4727.132597359691 Test RE 0.12188163022325081\n",
      "38 Train Loss 30640.918 Test MSE 4633.959763704189 Test RE 0.12067449539243506\n",
      "39 Train Loss 30419.43 Test MSE 4441.193709569935 Test RE 0.11813789281000209\n",
      "40 Train Loss 30241.328 Test MSE 4434.217953784476 Test RE 0.11804507711672355\n",
      "41 Train Loss 30163.596 Test MSE 4417.313097341835 Test RE 0.11781984679829484\n",
      "42 Train Loss 30003.717 Test MSE 4403.956847983997 Test RE 0.11764159108792337\n",
      "43 Train Loss 29902.326 Test MSE 4392.367942058421 Test RE 0.11748670362439073\n",
      "44 Train Loss 29642.744 Test MSE 4316.48817846338 Test RE 0.11646746963739829\n",
      "45 Train Loss 29522.12 Test MSE 4339.784039450065 Test RE 0.11678133115540748\n",
      "46 Train Loss 29441.762 Test MSE 4305.863791681847 Test RE 0.11632404774581401\n",
      "47 Train Loss 29296.732 Test MSE 4145.387099433527 Test RE 0.11413580545271673\n",
      "48 Train Loss 29125.783 Test MSE 4204.894460595779 Test RE 0.11495210067319354\n",
      "49 Train Loss 28885.734 Test MSE 4310.375548327862 Test RE 0.11638497493865438\n",
      "50 Train Loss 28316.94 Test MSE 4273.818450879338 Test RE 0.11589038270406399\n",
      "51 Train Loss 27897.65 Test MSE 3722.7518283073864 Test RE 0.10816117710513426\n",
      "52 Train Loss 27373.176 Test MSE 3621.8519573464546 Test RE 0.10668533112920936\n",
      "53 Train Loss 26888.836 Test MSE 3427.3256402135685 Test RE 0.10378080789459017\n",
      "54 Train Loss 26155.93 Test MSE 3230.3989283227725 Test RE 0.10075519339526043\n",
      "55 Train Loss 25791.05 Test MSE 3397.195770602133 Test RE 0.10332362857762821\n",
      "56 Train Loss 25589.62 Test MSE 3323.898139084842 Test RE 0.1022028991367248\n",
      "57 Train Loss 25252.523 Test MSE 3439.584646868254 Test RE 0.10396624606399014\n",
      "58 Train Loss 24710.383 Test MSE 3053.502714249521 Test RE 0.09795768598061505\n",
      "59 Train Loss 24550.691 Test MSE 3077.6086556020073 Test RE 0.098343590350717\n",
      "60 Train Loss 24157.928 Test MSE 3076.670831314024 Test RE 0.09832860533392122\n",
      "61 Train Loss 23654.453 Test MSE 2743.0181935258615 Test RE 0.0928439707911141\n",
      "62 Train Loss 23314.104 Test MSE 2665.9256553626324 Test RE 0.0915299824823698\n",
      "63 Train Loss 23014.084 Test MSE 2428.2381458333466 Test RE 0.08735444339863101\n",
      "64 Train Loss 22674.531 Test MSE 2326.8467486016784 Test RE 0.08551124951333466\n",
      "65 Train Loss 22428.922 Test MSE 2346.9392058492963 Test RE 0.08587965323684138\n",
      "66 Train Loss 22274.793 Test MSE 2285.9428980733746 Test RE 0.08475631200958396\n",
      "67 Train Loss 22163.416 Test MSE 2316.8997441679917 Test RE 0.08532827833985346\n",
      "68 Train Loss 22000.316 Test MSE 2306.6724249104045 Test RE 0.08513974089253286\n",
      "69 Train Loss 21908.445 Test MSE 2201.5176497981197 Test RE 0.08317646291158316\n",
      "70 Train Loss 21785.916 Test MSE 2075.12779108019 Test RE 0.08075358015105161\n",
      "71 Train Loss 21708.084 Test MSE 2119.7041874134484 Test RE 0.08161631663848556\n",
      "72 Train Loss 21630.58 Test MSE 2170.4344760641925 Test RE 0.08258719232275168\n",
      "73 Train Loss 21474.596 Test MSE 2135.7282167008952 Test RE 0.08192422750508671\n",
      "74 Train Loss 21259.133 Test MSE 2060.951756902299 Test RE 0.08047727733432403\n",
      "75 Train Loss 20959.33 Test MSE 1965.7792569608912 Test RE 0.07859713874205201\n",
      "76 Train Loss 20632.018 Test MSE 2088.6176397859836 Test RE 0.08101563362933334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 Train Loss 20443.59 Test MSE 2102.361431678194 Test RE 0.08128175133628197\n",
      "78 Train Loss 20240.586 Test MSE 1986.9508649532554 Test RE 0.07901925412991138\n",
      "79 Train Loss 19955.266 Test MSE 2107.8279643646842 Test RE 0.08138735660563917\n",
      "80 Train Loss 19744.498 Test MSE 1873.7747980025417 Test RE 0.07673580596651647\n",
      "81 Train Loss 19604.977 Test MSE 1900.2015510217166 Test RE 0.07727503248865059\n",
      "82 Train Loss 19531.465 Test MSE 1826.021476889238 Test RE 0.07575168590701321\n",
      "83 Train Loss 19462.078 Test MSE 1743.7754363792167 Test RE 0.0740260608798417\n",
      "84 Train Loss 19417.3 Test MSE 1832.8970445402308 Test RE 0.07589416683872446\n",
      "85 Train Loss 19224.44 Test MSE 1670.4500110391957 Test RE 0.07245295519239046\n",
      "86 Train Loss 19116.908 Test MSE 1757.1831353195987 Test RE 0.07431010507901739\n",
      "87 Train Loss 19041.312 Test MSE 1835.774381887216 Test RE 0.0759537139601327\n",
      "88 Train Loss 18969.07 Test MSE 1876.242125907427 Test RE 0.07678631099781144\n",
      "89 Train Loss 18874.871 Test MSE 1946.1118389220846 Test RE 0.07820297224515568\n",
      "90 Train Loss 18847.195 Test MSE 1885.3741220058494 Test RE 0.07697295032394205\n",
      "91 Train Loss 18740.898 Test MSE 1917.0561353642245 Test RE 0.07761698652174169\n",
      "92 Train Loss 18650.053 Test MSE 1885.7617952051403 Test RE 0.07698086355871253\n",
      "93 Train Loss 18585.94 Test MSE 1866.8251715008776 Test RE 0.07659337140484732\n",
      "94 Train Loss 18546.352 Test MSE 1869.053766308272 Test RE 0.07663907591943368\n",
      "95 Train Loss 18433.918 Test MSE 1914.438532565477 Test RE 0.07756397820381616\n",
      "96 Train Loss 18382.39 Test MSE 1840.1814442849084 Test RE 0.07604482867071613\n",
      "97 Train Loss 18335.041 Test MSE 1863.061963961572 Test RE 0.07651613274238232\n",
      "98 Train Loss 18296.098 Test MSE 1868.5343554848453 Test RE 0.07662842616386246\n",
      "99 Train Loss 18256.188 Test MSE 1833.8684971994678 Test RE 0.07591427648534227\n",
      "Training time: 238.14\n",
      "3D_HTTP_swish_tune3\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.62\n",
      "3D_HTTP_swish_tune4\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 248529.67 Test MSE 89966.67836458274 Test RE 0.5317165832433248\n",
      "1 Train Loss 230129.23 Test MSE 76468.71032201649 Test RE 0.49020896006510273\n",
      "2 Train Loss 208016.62 Test MSE 63632.29958909009 Test RE 0.44717567516985907\n",
      "3 Train Loss 197544.14 Test MSE 57933.636254274024 Test RE 0.4266824265963457\n",
      "4 Train Loss 188830.67 Test MSE 52363.56509495537 Test RE 0.40565232155037606\n",
      "5 Train Loss 184544.31 Test MSE 48572.880765754635 Test RE 0.3906935962776988\n",
      "6 Train Loss 183475.7 Test MSE 48384.66643575398 Test RE 0.3899359151938878\n",
      "7 Train Loss 181938.86 Test MSE 48355.32894270752 Test RE 0.3898176806615581\n",
      "8 Train Loss 180200.44 Test MSE 47433.62595255458 Test RE 0.3860846404355466\n",
      "9 Train Loss 178060.73 Test MSE 46602.79007637035 Test RE 0.38268842048109636\n",
      "10 Train Loss 173732.73 Test MSE 44044.92265263486 Test RE 0.3720379888642925\n",
      "11 Train Loss 170195.05 Test MSE 42449.33658341076 Test RE 0.3652370411686767\n",
      "12 Train Loss 163800.23 Test MSE 40117.625117037824 Test RE 0.3550642687622907\n",
      "13 Train Loss 158568.03 Test MSE 37693.64116427835 Test RE 0.34417031405654874\n",
      "14 Train Loss 155204.9 Test MSE 36804.19245375099 Test RE 0.3400854162968438\n",
      "15 Train Loss 151680.22 Test MSE 35373.1473113242 Test RE 0.33340815139565405\n",
      "16 Train Loss 147688.8 Test MSE 33101.80885251051 Test RE 0.32252636761247155\n",
      "17 Train Loss 144708.56 Test MSE 31020.387902895207 Test RE 0.3122216211136393\n",
      "18 Train Loss 141080.02 Test MSE 29460.509120742237 Test RE 0.30427024634724953\n",
      "19 Train Loss 137966.14 Test MSE 28273.25964792927 Test RE 0.298076201344966\n",
      "20 Train Loss 134641.08 Test MSE 26686.755440254423 Test RE 0.28959245996323574\n",
      "21 Train Loss 133571.8 Test MSE 25995.34044136668 Test RE 0.285816381673549\n",
      "22 Train Loss 129917.44 Test MSE 24950.980939111523 Test RE 0.28001621080965067\n",
      "23 Train Loss 126060.766 Test MSE 24200.08808351071 Test RE 0.2757705184337552\n",
      "24 Train Loss 122065.03 Test MSE 22401.766760089697 Test RE 0.26532642035961757\n",
      "25 Train Loss 117635.6 Test MSE 21580.21341835392 Test RE 0.2604157397822741\n",
      "26 Train Loss 114496.57 Test MSE 20452.09370875794 Test RE 0.2535176784255506\n",
      "27 Train Loss 110880.66 Test MSE 18809.77163177646 Test RE 0.24312584249868635\n",
      "28 Train Loss 108460.69 Test MSE 17345.03401664594 Test RE 0.2334677727145954\n",
      "29 Train Loss 105773.34 Test MSE 16618.240177846244 Test RE 0.2285240319466628\n",
      "30 Train Loss 104283.06 Test MSE 16972.607881711552 Test RE 0.23094770512455012\n",
      "31 Train Loss 101857.0 Test MSE 16839.893797009114 Test RE 0.23004300726068597\n",
      "32 Train Loss 98383.07 Test MSE 15373.506517881902 Test RE 0.21979905979100328\n",
      "33 Train Loss 94572.87 Test MSE 13671.002982822964 Test RE 0.2072714813288571\n",
      "34 Train Loss 89695.0 Test MSE 13722.783342763603 Test RE 0.20766364159749273\n",
      "35 Train Loss 84386.375 Test MSE 11233.397962187695 Test RE 0.18788622236259314\n",
      "36 Train Loss 81760.8 Test MSE 9212.551579535848 Test RE 0.1701489715597445\n",
      "37 Train Loss 75582.336 Test MSE 8403.098264820183 Test RE 0.1625021395067369\n",
      "38 Train Loss 71119.61 Test MSE 8030.101672019095 Test RE 0.15885463251731616\n",
      "39 Train Loss 63873.04 Test MSE 7598.636280590716 Test RE 0.1545280024653116\n",
      "40 Train Loss 60499.035 Test MSE 7163.838660204748 Test RE 0.15004179820047067\n",
      "41 Train Loss 58293.71 Test MSE 6579.169431419712 Test RE 0.14378874646763964\n",
      "42 Train Loss 56733.637 Test MSE 6052.931205695304 Test RE 0.13791840665758806\n",
      "43 Train Loss 54888.438 Test MSE 6064.088410570173 Test RE 0.13804545877662594\n",
      "44 Train Loss 53040.242 Test MSE 5702.72271077637 Test RE 0.133869145016375\n",
      "45 Train Loss 51768.695 Test MSE 5347.302212973465 Test RE 0.1296303599900069\n",
      "46 Train Loss 50870.848 Test MSE 5386.360794591195 Test RE 0.13010293154094452\n",
      "47 Train Loss 49285.426 Test MSE 5509.961374474146 Test RE 0.13158719805774596\n",
      "48 Train Loss 47966.01 Test MSE 5136.732483168147 Test RE 0.12705238926050297\n",
      "49 Train Loss 47527.75 Test MSE 5193.5727288777125 Test RE 0.12775340114056094\n",
      "50 Train Loss 46502.68 Test MSE 5184.413698398236 Test RE 0.12764070284140025\n",
      "51 Train Loss 45814.758 Test MSE 5049.234388651076 Test RE 0.12596564880180278\n",
      "52 Train Loss 44964.305 Test MSE 5254.106435523608 Test RE 0.12849575939320268\n",
      "53 Train Loss 43682.39 Test MSE 5129.679503395442 Test RE 0.12696513479064633\n",
      "54 Train Loss 43136.37 Test MSE 4896.114782573719 Test RE 0.1240409710811165\n",
      "55 Train Loss 42808.54 Test MSE 4804.27905190783 Test RE 0.12287215485412652\n",
      "56 Train Loss 42462.516 Test MSE 4993.801376340379 Test RE 0.1252722836777738\n",
      "57 Train Loss 42065.445 Test MSE 4856.730909922582 Test RE 0.123541077003451\n",
      "58 Train Loss 41269.64 Test MSE 4927.781718730445 Test RE 0.12444145869206653\n",
      "59 Train Loss 40653.258 Test MSE 4892.004922930897 Test RE 0.12398889938448635\n",
      "60 Train Loss 40021.574 Test MSE 4661.483682633971 Test RE 0.12103234459506541\n",
      "61 Train Loss 39693.99 Test MSE 4761.345145820054 Test RE 0.12232189325927108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 Train Loss 39396.78 Test MSE 4606.429737949535 Test RE 0.12031550210762504\n",
      "63 Train Loss 38894.504 Test MSE 4394.352476951024 Test RE 0.11751324171681875\n",
      "64 Train Loss 38704.133 Test MSE 4443.86704991175 Test RE 0.11817344353160485\n",
      "65 Train Loss 38187.523 Test MSE 4332.669517583002 Test RE 0.11668556784997461\n",
      "66 Train Loss 37635.973 Test MSE 4412.4987597898 Test RE 0.11775562459623018\n",
      "67 Train Loss 37129.688 Test MSE 4434.00713424757 Test RE 0.11804227092806137\n",
      "68 Train Loss 36930.883 Test MSE 4370.416635349329 Test RE 0.11719276001998208\n",
      "69 Train Loss 36521.434 Test MSE 4418.934718833424 Test RE 0.11784147099155154\n",
      "70 Train Loss 36256.89 Test MSE 4250.04722860832 Test RE 0.11556763883519472\n",
      "71 Train Loss 35871.81 Test MSE 4409.868728419004 Test RE 0.1177205257592629\n",
      "72 Train Loss 35500.53 Test MSE 4218.312244867121 Test RE 0.11513536020724491\n",
      "73 Train Loss 35035.17 Test MSE 4220.531579459831 Test RE 0.11516564367996586\n",
      "74 Train Loss 34506.996 Test MSE 4402.052708310058 Test RE 0.11761615597953715\n",
      "75 Train Loss 34095.723 Test MSE 4450.750895726659 Test RE 0.11826493737724128\n",
      "76 Train Loss 33762.145 Test MSE 4370.743632502457 Test RE 0.1171971441537278\n",
      "77 Train Loss 33336.31 Test MSE 4387.8554172644035 Test RE 0.11742633779140196\n",
      "78 Train Loss 32917.664 Test MSE 4643.582647863434 Test RE 0.1207997267839684\n",
      "79 Train Loss 32605.693 Test MSE 4868.589592555763 Test RE 0.12369181020730653\n",
      "80 Train Loss 32445.377 Test MSE 4717.353567514043 Test RE 0.1217554965548195\n",
      "81 Train Loss 32009.395 Test MSE 4544.06171914253 Test RE 0.11949823009884286\n",
      "82 Train Loss 31717.465 Test MSE 4546.392213207782 Test RE 0.11952886945141178\n",
      "83 Train Loss 31365.12 Test MSE 4520.7787972573415 Test RE 0.1191916936515028\n",
      "84 Train Loss 31179.309 Test MSE 4595.795579484434 Test RE 0.12017654488244925\n",
      "85 Train Loss 31065.396 Test MSE 4520.615884998942 Test RE 0.11918954601679144\n",
      "86 Train Loss 30954.5 Test MSE 4578.6970221383945 Test RE 0.11995277945114943\n",
      "87 Train Loss 30568.094 Test MSE 4560.4447646501885 Test RE 0.11971345423481465\n",
      "88 Train Loss 30400.844 Test MSE 4612.826902150835 Test RE 0.12039901700203863\n",
      "89 Train Loss 30253.936 Test MSE 4538.174903031753 Test RE 0.11942080024300337\n",
      "90 Train Loss 29815.91 Test MSE 4255.429771451444 Test RE 0.11564079695648109\n",
      "91 Train Loss 29567.875 Test MSE 4179.659781452797 Test RE 0.11460665269608263\n",
      "92 Train Loss 29348.068 Test MSE 4265.087706253337 Test RE 0.115771949198021\n",
      "93 Train Loss 29203.309 Test MSE 4297.9115331563835 Test RE 0.11621658192238658\n",
      "94 Train Loss 29085.191 Test MSE 4342.622663496746 Test RE 0.11681951786030093\n",
      "95 Train Loss 28939.012 Test MSE 4419.448492156906 Test RE 0.11784832129013574\n",
      "96 Train Loss 28846.97 Test MSE 4396.297790188899 Test RE 0.11753924950432423\n",
      "97 Train Loss 28687.734 Test MSE 4261.330518971605 Test RE 0.11572094523727039\n",
      "98 Train Loss 28364.934 Test MSE 4200.604271258926 Test RE 0.11489344377491821\n",
      "99 Train Loss 28177.797 Test MSE 4139.551119004007 Test RE 0.11405543552438321\n",
      "Training time: 249.62\n",
      "3D_HTTP_swish_tune4\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.50\n",
      "3D_HTTP_swish_tune4\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.10\n",
      "3D_HTTP_swish_tune4\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 247071.89 Test MSE 87061.30435775433 Test RE 0.523060526900476\n",
      "1 Train Loss 235098.03 Test MSE 74287.23072044742 Test RE 0.4831660900877476\n",
      "2 Train Loss 208251.47 Test MSE 62061.632289565445 Test RE 0.44162226325308346\n",
      "3 Train Loss 190732.06 Test MSE 52061.956656333205 Test RE 0.4044823778084921\n",
      "4 Train Loss 184936.19 Test MSE 48424.27329695397 Test RE 0.3900954799850042\n",
      "5 Train Loss 169130.64 Test MSE 41607.605072608436 Test RE 0.36159775169223407\n",
      "6 Train Loss 165280.95 Test MSE 39978.76092522341 Test RE 0.35444922171496734\n",
      "7 Train Loss 161953.81 Test MSE 38275.711385086615 Test RE 0.34681749556078556\n",
      "8 Train Loss 154426.92 Test MSE 35288.60202591064 Test RE 0.3330094739709218\n",
      "9 Train Loss 142301.33 Test MSE 30339.79622344292 Test RE 0.3087775322247593\n",
      "10 Train Loss 121363.586 Test MSE 22497.571530986206 Test RE 0.26589317068469903\n",
      "11 Train Loss 109290.08 Test MSE 18639.995430759616 Test RE 0.24202613362075912\n",
      "12 Train Loss 95879.05 Test MSE 14266.337304327299 Test RE 0.21173643967901304\n",
      "13 Train Loss 78288.516 Test MSE 9964.453825195362 Test RE 0.17695633369614594\n",
      "14 Train Loss 64749.72 Test MSE 5877.082368436007 Test RE 0.1359002485252405\n",
      "15 Train Loss 60759.766 Test MSE 5486.678429528968 Test RE 0.13130888568173735\n",
      "16 Train Loss 55442.33 Test MSE 6031.916572101296 Test RE 0.13767878517080848\n",
      "17 Train Loss 51400.883 Test MSE 5975.237853098781 Test RE 0.13703041122913626\n",
      "18 Train Loss 50202.42 Test MSE 6116.793641423057 Test RE 0.1386440629380587\n",
      "19 Train Loss 46740.613 Test MSE 4877.388293926905 Test RE 0.12380353003976825\n",
      "20 Train Loss 45250.836 Test MSE 4973.412672405005 Test RE 0.12501629113243676\n",
      "21 Train Loss 44369.094 Test MSE 4598.808816562901 Test RE 0.12021593535119984\n",
      "22 Train Loss 43326.453 Test MSE 4440.138720874127 Test RE 0.1181238603727698\n",
      "23 Train Loss 42385.555 Test MSE 4792.221442895767 Test RE 0.1227178679011916\n",
      "24 Train Loss 37994.66 Test MSE 4889.749255999206 Test RE 0.12396031091090548\n",
      "25 Train Loss 36607.508 Test MSE 5394.3400616994095 Test RE 0.13019926205988464\n",
      "26 Train Loss 35011.88 Test MSE 5036.709630716269 Test RE 0.12580932125508754\n",
      "27 Train Loss 34000.832 Test MSE 4981.355666369436 Test RE 0.12511608251797326\n",
      "28 Train Loss 33817.438 Test MSE 5167.821436876348 Test RE 0.1274362877175968\n",
      "29 Train Loss 33363.766 Test MSE 5194.4856979132255 Test RE 0.12776462942022512\n",
      "30 Train Loss 32943.543 Test MSE 4916.9656178567275 Test RE 0.12430481396686693\n",
      "31 Train Loss 32617.996 Test MSE 4724.307007364051 Test RE 0.12184519809587359\n",
      "32 Train Loss 32452.875 Test MSE 4825.815338953197 Test RE 0.12314724826930934\n",
      "33 Train Loss 32405.244 Test MSE 4851.345231912708 Test RE 0.12347256002871661\n",
      "34 Train Loss 32298.166 Test MSE 4788.959108958673 Test RE 0.12267609032186622\n",
      "35 Train Loss 32256.047 Test MSE 4709.726499566567 Test RE 0.12165702894014897\n",
      "36 Train Loss 31943.414 Test MSE 4715.742064345355 Test RE 0.12173469822738743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 Train Loss 31742.008 Test MSE 4601.969605390201 Test RE 0.12025724082102417\n",
      "38 Train Loss 31635.168 Test MSE 4601.57833321697 Test RE 0.12025212841088342\n",
      "39 Train Loss 31563.275 Test MSE 4569.974453553765 Test RE 0.11983846798621986\n",
      "40 Train Loss 31520.062 Test MSE 4613.369282039428 Test RE 0.12040609510049766\n",
      "41 Train Loss 31479.95 Test MSE 4667.6603762321665 Test RE 0.12111250493434174\n",
      "42 Train Loss 31407.846 Test MSE 4728.381642489496 Test RE 0.12189773148533417\n",
      "43 Train Loss 31317.213 Test MSE 4737.902410501672 Test RE 0.1220203925235477\n",
      "44 Train Loss 31205.389 Test MSE 4661.187546872165 Test RE 0.12102850004928639\n",
      "45 Train Loss 30986.756 Test MSE 4524.151937092455 Test RE 0.11923615228344307\n",
      "46 Train Loss 30842.973 Test MSE 4466.253432886248 Test RE 0.11847072432263306\n",
      "47 Train Loss 30811.143 Test MSE 4415.181553860171 Test RE 0.11779141679747013\n",
      "48 Train Loss 30690.848 Test MSE 4341.13285806644 Test RE 0.11679947774920044\n",
      "49 Train Loss 30535.0 Test MSE 4305.284717521392 Test RE 0.11631622556210865\n",
      "50 Train Loss 30436.895 Test MSE 4461.516435109342 Test RE 0.11840788144448532\n",
      "51 Train Loss 30233.115 Test MSE 4367.9503700490795 Test RE 0.11715968889102112\n",
      "52 Train Loss 30091.268 Test MSE 4290.848394366576 Test RE 0.11612104815391322\n",
      "53 Train Loss 30040.898 Test MSE 4287.667703790642 Test RE 0.11607800146927631\n",
      "54 Train Loss 29979.271 Test MSE 4255.731717701015 Test RE 0.11564489956038268\n",
      "55 Train Loss 29883.113 Test MSE 4329.459800398629 Test RE 0.11664233848980304\n",
      "56 Train Loss 29830.787 Test MSE 4333.058807011842 Test RE 0.11669080981887847\n",
      "57 Train Loss 29767.082 Test MSE 4339.023732682072 Test RE 0.11677110097749391\n",
      "58 Train Loss 29694.99 Test MSE 4290.640250352894 Test RE 0.11611823167195735\n",
      "59 Train Loss 29622.422 Test MSE 4268.018914734131 Test RE 0.11581172486704804\n",
      "60 Train Loss 29490.445 Test MSE 4296.193814137879 Test RE 0.11619335582973232\n",
      "61 Train Loss 29348.225 Test MSE 4190.118021985412 Test RE 0.11474994607078413\n",
      "62 Train Loss 29186.982 Test MSE 4154.029242731522 Test RE 0.11425471647441185\n",
      "63 Train Loss 29105.594 Test MSE 4101.9616603188115 Test RE 0.11353641073951234\n",
      "64 Train Loss 28993.814 Test MSE 4097.077858967353 Test RE 0.11346880230428147\n",
      "65 Train Loss 28819.969 Test MSE 3949.834082815428 Test RE 0.11141118375985105\n",
      "66 Train Loss 28653.406 Test MSE 3984.8181963116335 Test RE 0.11190348660227803\n",
      "67 Train Loss 28338.223 Test MSE 3956.3672709486714 Test RE 0.11150328503236406\n",
      "68 Train Loss 27944.998 Test MSE 3782.4513277113842 Test RE 0.1090249851860225\n",
      "69 Train Loss 27372.533 Test MSE 3579.774736727787 Test RE 0.10606380704832293\n",
      "70 Train Loss 26996.27 Test MSE 3494.5703520605034 Test RE 0.10479396102402597\n",
      "71 Train Loss 26408.637 Test MSE 3630.153061029286 Test RE 0.10680751988030647\n",
      "72 Train Loss 26116.152 Test MSE 3360.1493674397416 Test RE 0.10275871242328995\n",
      "73 Train Loss 25994.04 Test MSE 3379.6803060397324 Test RE 0.10305692329640673\n",
      "74 Train Loss 25778.31 Test MSE 3224.3580939156536 Test RE 0.10066094338775007\n",
      "75 Train Loss 25405.508 Test MSE 3196.513071041842 Test RE 0.10022535530802405\n",
      "76 Train Loss 25012.863 Test MSE 3082.4793452669255 Test RE 0.09842137992586594\n",
      "77 Train Loss 24765.559 Test MSE 3190.1431853493914 Test RE 0.10012544293217916\n",
      "78 Train Loss 24535.438 Test MSE 3038.920538355559 Test RE 0.09772350480904624\n",
      "79 Train Loss 24303.973 Test MSE 3084.3774438025375 Test RE 0.0984516777326802\n",
      "80 Train Loss 24091.477 Test MSE 2804.123310308097 Test RE 0.09387239882886043\n",
      "81 Train Loss 23943.744 Test MSE 2697.3312351891323 Test RE 0.09206753232880877\n",
      "82 Train Loss 23647.4 Test MSE 2598.631639539214 Test RE 0.090367386674613\n",
      "83 Train Loss 23330.717 Test MSE 2584.3248212416456 Test RE 0.09011828361649347\n",
      "84 Train Loss 23139.74 Test MSE 2471.427527049147 Test RE 0.08812787576240522\n",
      "85 Train Loss 23048.443 Test MSE 2543.4696690589844 Test RE 0.08940311353571304\n",
      "86 Train Loss 23004.63 Test MSE 2608.155704933664 Test RE 0.09053283485473584\n",
      "87 Train Loss 22931.934 Test MSE 2542.5534102118595 Test RE 0.08938700880809462\n",
      "88 Train Loss 22787.701 Test MSE 2392.7132797949685 Test RE 0.08671309593246816\n",
      "89 Train Loss 22574.89 Test MSE 2438.170566333792 Test RE 0.08753291757961615\n",
      "90 Train Loss 22449.361 Test MSE 2498.95659603371 Test RE 0.0886173418159732\n",
      "91 Train Loss 22392.508 Test MSE 2499.4790055584704 Test RE 0.08862660410653661\n",
      "92 Train Loss 22353.533 Test MSE 2503.2138276459787 Test RE 0.08869279410853712\n",
      "93 Train Loss 22253.268 Test MSE 2416.1027596077997 Test RE 0.08713588829164612\n",
      "94 Train Loss 22214.533 Test MSE 2412.121153642055 Test RE 0.08706406108478373\n",
      "95 Train Loss 22176.098 Test MSE 2380.945371627805 Test RE 0.08649959573329456\n",
      "96 Train Loss 22063.996 Test MSE 2371.7001055504425 Test RE 0.08633149241949475\n",
      "97 Train Loss 22000.293 Test MSE 2389.6929158516655 Test RE 0.08665834891897521\n",
      "98 Train Loss 21903.24 Test MSE 2403.6813346623403 Test RE 0.08691161252370486\n",
      "99 Train Loss 21849.355 Test MSE 2431.7195079949793 Test RE 0.08741704095131982\n",
      "Training time: 255.62\n",
      "3D_HTTP_swish_tune4\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 247998.72 Test MSE 89137.44800013915 Test RE 0.529260472590399\n",
      "1 Train Loss 233208.27 Test MSE 80308.32907406312 Test RE 0.5023653272032924\n",
      "2 Train Loss 211984.42 Test MSE 67141.5978231994 Test RE 0.45934098605116197\n",
      "3 Train Loss 198644.56 Test MSE 55969.83825752011 Test RE 0.4193883750262965\n",
      "4 Train Loss 193418.61 Test MSE 53981.73835273026 Test RE 0.41187249932191206\n",
      "5 Train Loss 189402.19 Test MSE 51901.452621991506 Test RE 0.4038583984972617\n",
      "6 Train Loss 184260.14 Test MSE 49367.06788610748 Test RE 0.39387464878487044\n",
      "7 Train Loss 182501.94 Test MSE 48947.85694545009 Test RE 0.39219874827122964\n",
      "8 Train Loss 181000.23 Test MSE 47619.027924025664 Test RE 0.3868384415849961\n",
      "9 Train Loss 179257.1 Test MSE 47057.782441325 Test RE 0.384552014682285\n",
      "10 Train Loss 176122.58 Test MSE 44881.89898685182 Test RE 0.3755562329535254\n",
      "11 Train Loss 174175.8 Test MSE 44065.67018848654 Test RE 0.3721256035342713\n",
      "12 Train Loss 170886.84 Test MSE 43538.12160198426 Test RE 0.3698913762831401\n",
      "13 Train Loss 168326.0 Test MSE 42225.349023950504 Test RE 0.3642721644098298\n",
      "14 Train Loss 163713.39 Test MSE 39806.869262552915 Test RE 0.3536864104658107\n",
      "15 Train Loss 158842.06 Test MSE 37380.30544247358 Test RE 0.34273683749640926\n",
      "16 Train Loss 154504.7 Test MSE 35666.715337492155 Test RE 0.3347887994579621\n",
      "17 Train Loss 151133.06 Test MSE 33974.661900709456 Test RE 0.3267510064614299\n",
      "18 Train Loss 147414.78 Test MSE 31333.850324382936 Test RE 0.31379516272319746\n",
      "19 Train Loss 143675.14 Test MSE 30030.739598016662 Test RE 0.30720082401076193\n",
      "20 Train Loss 140030.56 Test MSE 29400.948572302965 Test RE 0.30396251793113416\n",
      "21 Train Loss 137770.25 Test MSE 28633.709690940726 Test RE 0.299970240249697\n",
      "22 Train Loss 132302.23 Test MSE 26771.49897825512 Test RE 0.2900518945704763\n",
      "23 Train Loss 125655.83 Test MSE 25167.727590993094 Test RE 0.2812298171635102\n",
      "24 Train Loss 122220.56 Test MSE 24642.367739202447 Test RE 0.2782790931025767\n",
      "25 Train Loss 118716.4 Test MSE 23447.126384447896 Test RE 0.2714464550628777\n",
      "26 Train Loss 116489.94 Test MSE 23115.57329067575 Test RE 0.2695204335868647\n",
      "27 Train Loss 114425.305 Test MSE 22847.816648283922 Test RE 0.26795490704790514\n",
      "28 Train Loss 111280.87 Test MSE 21935.573090291487 Test RE 0.2625511076644517\n",
      "29 Train Loss 109159.53 Test MSE 20517.29234053699 Test RE 0.253921447689276\n",
      "30 Train Loss 107645.06 Test MSE 20165.548224782833 Test RE 0.25173545034894906\n",
      "31 Train Loss 104816.836 Test MSE 20549.82381944867 Test RE 0.25412267230295615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 Train Loss 99855.71 Test MSE 18680.636889521655 Test RE 0.24228983914028723\n",
      "33 Train Loss 94393.17 Test MSE 16772.525676905152 Test RE 0.2295824017562561\n",
      "34 Train Loss 91935.95 Test MSE 15851.581628950133 Test RE 0.22319047832467495\n",
      "35 Train Loss 89564.27 Test MSE 14908.050182807816 Test RE 0.21644611008910403\n",
      "36 Train Loss 86747.125 Test MSE 14384.174068473463 Test RE 0.21260908929475147\n",
      "37 Train Loss 83586.27 Test MSE 12893.065507181684 Test RE 0.20128780167215735\n",
      "38 Train Loss 79788.62 Test MSE 12341.738889675615 Test RE 0.1969371003415433\n",
      "39 Train Loss 78155.78 Test MSE 12103.9327453515 Test RE 0.19503053547176336\n",
      "40 Train Loss 76802.54 Test MSE 11839.975277998929 Test RE 0.19289224157201612\n",
      "41 Train Loss 76320.164 Test MSE 11660.303597744109 Test RE 0.19142307628317848\n",
      "42 Train Loss 75103.555 Test MSE 11679.789044689122 Test RE 0.19158295236133915\n",
      "43 Train Loss 73861.516 Test MSE 11508.86028998594 Test RE 0.19017591795906438\n",
      "44 Train Loss 72895.24 Test MSE 11152.403554155671 Test RE 0.18720765372045148\n",
      "45 Train Loss 72220.08 Test MSE 11153.15261755231 Test RE 0.18721394061841423\n",
      "46 Train Loss 71121.086 Test MSE 11248.832748266588 Test RE 0.1880152567025233\n",
      "47 Train Loss 70453.8 Test MSE 10926.382435956863 Test RE 0.18530091371810192\n",
      "48 Train Loss 68375.78 Test MSE 10815.40655405766 Test RE 0.18435749009765237\n",
      "49 Train Loss 66509.02 Test MSE 10808.2850443607 Test RE 0.18429678411116893\n",
      "50 Train Loss 65088.004 Test MSE 10431.562755598101 Test RE 0.18105647038816028\n",
      "51 Train Loss 64507.023 Test MSE 10450.831258578748 Test RE 0.18122361109796184\n",
      "52 Train Loss 63985.03 Test MSE 10572.951642001099 Test RE 0.18227935583144148\n",
      "53 Train Loss 62699.37 Test MSE 10379.550966141198 Test RE 0.1806045324102731\n",
      "54 Train Loss 62081.836 Test MSE 10096.152528053532 Test RE 0.1781218978262702\n",
      "55 Train Loss 60951.055 Test MSE 9948.039240796928 Test RE 0.17681052229818736\n",
      "56 Train Loss 59339.473 Test MSE 9738.201773104483 Test RE 0.17493582061123975\n",
      "57 Train Loss 58541.88 Test MSE 9645.737463669666 Test RE 0.1741033312152848\n",
      "58 Train Loss 58143.652 Test MSE 9631.147681948854 Test RE 0.17397161029388097\n",
      "59 Train Loss 57766.332 Test MSE 9464.293687506552 Test RE 0.17245804811553683\n",
      "60 Train Loss 57272.88 Test MSE 9409.084250780319 Test RE 0.17195430012489502\n",
      "61 Train Loss 56694.688 Test MSE 9465.934574264593 Test RE 0.1724729975598468\n",
      "62 Train Loss 56040.535 Test MSE 9313.893544222992 Test RE 0.1710822672517251\n",
      "63 Train Loss 55404.742 Test MSE 9148.481705113312 Test RE 0.16955627782118632\n",
      "64 Train Loss 54652.875 Test MSE 8979.129122496934 Test RE 0.16797957210522588\n",
      "65 Train Loss 54292.793 Test MSE 8786.421749454512 Test RE 0.1661672318202792\n",
      "66 Train Loss 53783.285 Test MSE 8772.253056067071 Test RE 0.16603319987088247\n",
      "67 Train Loss 53216.414 Test MSE 8696.411595151994 Test RE 0.1653139128497717\n",
      "68 Train Loss 52881.484 Test MSE 8678.807469028514 Test RE 0.16514650579838\n",
      "69 Train Loss 52627.066 Test MSE 8675.915488873115 Test RE 0.1651189881807393\n",
      "70 Train Loss 52309.523 Test MSE 8575.544277392843 Test RE 0.16416108317375824\n",
      "71 Train Loss 51894.086 Test MSE 8438.746762467314 Test RE 0.1628464664491199\n",
      "72 Train Loss 51398.66 Test MSE 8269.241053381962 Test RE 0.16120265421917115\n",
      "73 Train Loss 50862.684 Test MSE 8115.186065143334 Test RE 0.15969400143487317\n",
      "74 Train Loss 50279.086 Test MSE 8104.56606325399 Test RE 0.15958947482257774\n",
      "75 Train Loss 49845.586 Test MSE 7925.824715791093 Test RE 0.15781983824325632\n",
      "76 Train Loss 49486.742 Test MSE 7777.671667473048 Test RE 0.15633786074757589\n",
      "77 Train Loss 48898.406 Test MSE 7481.533486348946 Test RE 0.15333266156238157\n",
      "78 Train Loss 47313.75 Test MSE 7245.488294118944 Test RE 0.1508944240621074\n",
      "79 Train Loss 46475.984 Test MSE 6916.604527828329 Test RE 0.1474299894719537\n",
      "80 Train Loss 44354.26 Test MSE 6759.939692300965 Test RE 0.14575074151662135\n",
      "81 Train Loss 43803.945 Test MSE 6609.73415580478 Test RE 0.1441223577988006\n",
      "82 Train Loss 43458.695 Test MSE 6546.929110805093 Test RE 0.14343600524676153\n",
      "83 Train Loss 42305.742 Test MSE 6469.183291352774 Test RE 0.14258179908181753\n",
      "84 Train Loss 41519.082 Test MSE 6399.202471470036 Test RE 0.141808508073341\n",
      "85 Train Loss 40867.508 Test MSE 6346.7387725087865 Test RE 0.1412260049808169\n",
      "86 Train Loss 39934.375 Test MSE 5895.154160202704 Test RE 0.13610903204573827\n",
      "87 Train Loss 39582.934 Test MSE 5857.324378681064 Test RE 0.13567161668856972\n",
      "88 Train Loss 38996.87 Test MSE 5744.295022789895 Test RE 0.13435620570754422\n",
      "89 Train Loss 38272.227 Test MSE 5577.467150624859 Test RE 0.13239082020143592\n",
      "90 Train Loss 37036.066 Test MSE 5246.471599751106 Test RE 0.1284023657129651\n",
      "91 Train Loss 35869.914 Test MSE 5334.7894660458205 Test RE 0.12947860291428195\n",
      "92 Train Loss 35506.547 Test MSE 5204.197138421564 Test RE 0.12788400593616114\n",
      "93 Train Loss 35139.34 Test MSE 5107.989366993345 Test RE 0.12669642322958305\n",
      "94 Train Loss 34912.97 Test MSE 4988.981168261833 Test RE 0.1252118102817927\n",
      "95 Train Loss 34767.49 Test MSE 5001.672750547969 Test RE 0.12537097370249287\n",
      "96 Train Loss 34489.24 Test MSE 4941.830746689624 Test RE 0.12461872275574817\n",
      "97 Train Loss 34181.566 Test MSE 4861.2566324073705 Test RE 0.12359862419407903\n",
      "98 Train Loss 34102.598 Test MSE 4837.994230751085 Test RE 0.12330254347237407\n",
      "99 Train Loss 33950.7 Test MSE 4782.118572788148 Test RE 0.12258844391527361\n",
      "Training time: 255.59\n",
      "3D_HTTP_swish_tune4\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 3.96\n",
      "3D_HTTP_swish_tune4\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.04\n",
      "3D_HTTP_swish_tune4\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 248547.25 Test MSE 88408.05994971067 Test RE 0.527090625749384\n",
      "1 Train Loss 236713.45 Test MSE 75821.2667523575 Test RE 0.4881293035700236\n",
      "2 Train Loss 223787.81 Test MSE 68093.23549946098 Test RE 0.46258478848569806\n",
      "3 Train Loss 197532.03 Test MSE 56834.485274719314 Test RE 0.42261540893452837\n",
      "4 Train Loss 176692.22 Test MSE 44377.36197804143 Test RE 0.3734393712619186\n",
      "5 Train Loss 169334.1 Test MSE 40765.711004912904 Test RE 0.35792074678205876\n",
      "6 Train Loss 160140.4 Test MSE 37535.865928035106 Test RE 0.3434492574935262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Train Loss 152426.47 Test MSE 34238.91090720573 Test RE 0.3280192514171919\n",
      "8 Train Loss 141147.16 Test MSE 28209.199976298234 Test RE 0.29773832923644106\n",
      "9 Train Loss 129597.875 Test MSE 26457.114052364806 Test RE 0.2883437862920564\n",
      "10 Train Loss 111681.39 Test MSE 20637.030585864264 Test RE 0.2546613084301039\n",
      "11 Train Loss 100804.18 Test MSE 17301.974509134714 Test RE 0.2331777976625395\n",
      "12 Train Loss 83316.195 Test MSE 13633.180653404967 Test RE 0.20698456309865776\n",
      "13 Train Loss 69111.5 Test MSE 12236.484447376492 Test RE 0.1960955297490367\n",
      "14 Train Loss 52467.55 Test MSE 7191.530233902551 Test RE 0.15033150922700775\n",
      "15 Train Loss 47162.082 Test MSE 5499.475612581234 Test RE 0.1314619295654894\n",
      "16 Train Loss 43931.01 Test MSE 6018.6512439404905 Test RE 0.13752731096897697\n",
      "17 Train Loss 40725.312 Test MSE 5473.161898934098 Test RE 0.13114704504993366\n",
      "18 Train Loss 37518.297 Test MSE 5413.578260561931 Test RE 0.13043122463375084\n",
      "19 Train Loss 35888.41 Test MSE 5331.46058637081 Test RE 0.12943819963767178\n",
      "20 Train Loss 33820.414 Test MSE 4838.006121581353 Test RE 0.12330269499887918\n",
      "21 Train Loss 33054.773 Test MSE 4468.535863838882 Test RE 0.11850099205314221\n",
      "22 Train Loss 32811.24 Test MSE 4482.355222575682 Test RE 0.11868408821825574\n",
      "23 Train Loss 31962.234 Test MSE 4612.354103760699 Test RE 0.1203928466079036\n",
      "24 Train Loss 31537.896 Test MSE 4534.598324309461 Test RE 0.11937373263439745\n",
      "25 Train Loss 31470.457 Test MSE 4544.713767368111 Test RE 0.11950680346543512\n",
      "26 Train Loss 31381.0 Test MSE 4499.846148927697 Test RE 0.11891542569149026\n",
      "27 Train Loss 31166.031 Test MSE 4598.258553582977 Test RE 0.12020874301505839\n",
      "28 Train Loss 31141.736 Test MSE 4621.916126859983 Test RE 0.1205175771820102\n",
      "29 Train Loss 31063.348 Test MSE 4554.632948928808 Test RE 0.1196371487011617\n",
      "30 Train Loss 30954.395 Test MSE 4546.073843876242 Test RE 0.11952468426558623\n",
      "31 Train Loss 30689.918 Test MSE 4574.315725121262 Test RE 0.11989537507003585\n",
      "32 Train Loss 30647.158 Test MSE 4563.511681461979 Test RE 0.11975370135076817\n",
      "33 Train Loss 30644.078 Test MSE 4568.104846946888 Test RE 0.11981395212583225\n",
      "34 Train Loss 30601.855 Test MSE 4558.8090208192125 Test RE 0.1196919828524417\n",
      "35 Train Loss 30414.797 Test MSE 4456.287408884846 Test RE 0.1183384723713144\n",
      "36 Train Loss 30285.996 Test MSE 4336.945985547998 Test RE 0.11674313963329215\n",
      "37 Train Loss 30101.041 Test MSE 4309.68343124712 Test RE 0.11637563059475517\n",
      "38 Train Loss 30044.63 Test MSE 4250.713035845054 Test RE 0.11557669082365606\n",
      "39 Train Loss 29994.332 Test MSE 4268.473599124883 Test RE 0.1158178935816488\n",
      "40 Train Loss 29913.805 Test MSE 4245.988754472062 Test RE 0.1155124464722508\n",
      "41 Train Loss 29883.121 Test MSE 4269.056724594924 Test RE 0.11582580437875821\n",
      "42 Train Loss 29868.48 Test MSE 4274.57183482256 Test RE 0.1159005967675672\n",
      "43 Train Loss 29818.854 Test MSE 4281.239063389342 Test RE 0.11599094905514178\n",
      "44 Train Loss 29772.916 Test MSE 4280.614383849971 Test RE 0.1159824865732738\n",
      "45 Train Loss 29652.516 Test MSE 4261.557072703153 Test RE 0.11572402134969552\n",
      "46 Train Loss 29590.496 Test MSE 4319.6288849644025 Test RE 0.11650983319896352\n",
      "47 Train Loss 29459.309 Test MSE 4227.436757016431 Test RE 0.11525981596582217\n",
      "48 Train Loss 29373.986 Test MSE 4233.586334188404 Test RE 0.11534361870395557\n",
      "49 Train Loss 29265.691 Test MSE 4159.1899260420805 Test RE 0.11432566558886043\n",
      "50 Train Loss 29109.576 Test MSE 4136.29942601838 Test RE 0.11401063041030778\n",
      "51 Train Loss 29069.03 Test MSE 4146.003672505527 Test RE 0.11414429325445001\n",
      "52 Train Loss 29038.023 Test MSE 4130.493464537892 Test RE 0.11393058618372087\n",
      "53 Train Loss 29023.994 Test MSE 4127.074610986288 Test RE 0.11388342564143482\n",
      "54 Train Loss 28979.574 Test MSE 4062.7049703076377 Test RE 0.11299182022893314\n",
      "55 Train Loss 28890.82 Test MSE 4045.5907219726637 Test RE 0.1127535786017332\n",
      "56 Train Loss 28815.86 Test MSE 4027.810345198418 Test RE 0.11250552969145547\n",
      "57 Train Loss 28725.264 Test MSE 3989.8483313112065 Test RE 0.11197409360257825\n",
      "58 Train Loss 28442.54 Test MSE 3890.9403963549616 Test RE 0.11057747054417849\n",
      "59 Train Loss 28103.06 Test MSE 3922.2994418671296 Test RE 0.11102217603975138\n",
      "60 Train Loss 27738.125 Test MSE 3656.055555554193 Test RE 0.1071878982740719\n",
      "61 Train Loss 27365.664 Test MSE 3541.1932528786483 Test RE 0.10549070050379661\n",
      "62 Train Loss 27160.322 Test MSE 3355.175845308174 Test RE 0.10268263515252107\n",
      "63 Train Loss 26841.09 Test MSE 3455.6930879805996 Test RE 0.10420941175138405\n",
      "64 Train Loss 26701.545 Test MSE 3470.983012599798 Test RE 0.10443969774974741\n",
      "65 Train Loss 26626.44 Test MSE 3365.168141192777 Test RE 0.10283542483145222\n",
      "66 Train Loss 26468.959 Test MSE 3387.4928314288327 Test RE 0.10317596859110104\n",
      "67 Train Loss 26358.363 Test MSE 3434.6542635162996 Test RE 0.10389170548364102\n",
      "68 Train Loss 26287.186 Test MSE 3386.888132259672 Test RE 0.10316675924215828\n",
      "69 Train Loss 26115.328 Test MSE 3206.8371014757613 Test RE 0.10038707769973722\n",
      "70 Train Loss 26046.066 Test MSE 3392.5285400579605 Test RE 0.10325262870432954\n",
      "71 Train Loss 25995.424 Test MSE 3448.853761776783 Test RE 0.10410623778059357\n",
      "72 Train Loss 25888.744 Test MSE 3395.524306333299 Test RE 0.1032982071693464\n",
      "73 Train Loss 25692.217 Test MSE 3324.4102375340854 Test RE 0.10221077181035254\n",
      "74 Train Loss 25574.996 Test MSE 3333.8093934863473 Test RE 0.1023551608638974\n",
      "75 Train Loss 25487.697 Test MSE 3273.151373213885 Test RE 0.10141972006348408\n",
      "76 Train Loss 25401.234 Test MSE 3172.3581293326993 Test RE 0.09984595305462815\n",
      "77 Train Loss 25270.041 Test MSE 2959.0407094635916 Test RE 0.09643059184029622\n",
      "78 Train Loss 25154.701 Test MSE 3006.161987532605 Test RE 0.09719536424776454\n",
      "79 Train Loss 25115.373 Test MSE 2960.042797732157 Test RE 0.0964469187168937\n",
      "80 Train Loss 24918.48 Test MSE 2913.1294499962123 Test RE 0.09567957863432358\n",
      "81 Train Loss 24816.656 Test MSE 3089.2666454013643 Test RE 0.0985296771842594\n",
      "82 Train Loss 24725.098 Test MSE 3115.8138973731975 Test RE 0.09895212319996942\n",
      "83 Train Loss 24662.451 Test MSE 3128.944416271454 Test RE 0.0991604037308875\n",
      "84 Train Loss 24588.0 Test MSE 3336.116424359964 Test RE 0.1023905701585236\n",
      "85 Train Loss 24420.725 Test MSE 3195.2637900476284 Test RE 0.10020576804763538\n",
      "86 Train Loss 24353.146 Test MSE 3035.3945064392724 Test RE 0.09766679450636388\n",
      "87 Train Loss 24327.988 Test MSE 2987.6724491671157 Test RE 0.09689600093384042\n",
      "88 Train Loss 24263.756 Test MSE 3205.904558775177 Test RE 0.10037248044388102\n",
      "89 Train Loss 24159.957 Test MSE 3142.574142162647 Test RE 0.09937614110417828\n",
      "90 Train Loss 24075.066 Test MSE 3170.1791180026844 Test RE 0.09981165635372627\n",
      "91 Train Loss 23895.064 Test MSE 3074.329516963186 Test RE 0.09829118469283382\n",
      "92 Train Loss 23810.912 Test MSE 3372.2039255279005 Test RE 0.10294287118382829\n",
      "93 Train Loss 23665.15 Test MSE 3311.6788880298955 Test RE 0.10201486799250599\n",
      "94 Train Loss 23419.0 Test MSE 2946.707170865349 Test RE 0.09622941645255205\n",
      "95 Train Loss 23252.412 Test MSE 2824.4186723079224 Test RE 0.09421149580526002\n",
      "96 Train Loss 22998.535 Test MSE 2554.147775229964 Test RE 0.08959058501966154\n",
      "97 Train Loss 22685.475 Test MSE 2578.224414304702 Test RE 0.09001185678243323\n",
      "98 Train Loss 22506.29 Test MSE 2550.7903306518865 Test RE 0.08953168194027279\n",
      "99 Train Loss 22389.535 Test MSE 2533.939923036619 Test RE 0.08923547078336728\n",
      "Training time: 255.33\n",
      "3D_HTTP_swish_tune4\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 243366.64 Test MSE 86838.11598431483 Test RE 0.5223896436430646\n",
      "1 Train Loss 236485.14 Test MSE 78752.50817621568 Test RE 0.49747534220284495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Train Loss 207944.48 Test MSE 60200.678192945314 Test RE 0.4349507200321485\n",
      "3 Train Loss 191091.55 Test MSE 54838.390391828754 Test RE 0.41512769847578695\n",
      "4 Train Loss 185156.7 Test MSE 50796.74332198054 Test RE 0.39953726932442174\n",
      "5 Train Loss 179657.89 Test MSE 48124.40692862862 Test RE 0.3888857749807504\n",
      "6 Train Loss 175894.19 Test MSE 45860.63426669849 Test RE 0.37962900847476133\n",
      "7 Train Loss 171062.81 Test MSE 43162.32900927397 Test RE 0.3682915864872673\n",
      "8 Train Loss 162664.25 Test MSE 37046.50099672264 Test RE 0.341203093482588\n",
      "9 Train Loss 153153.14 Test MSE 37611.62527152872 Test RE 0.3437956778298371\n",
      "10 Train Loss 141693.03 Test MSE 31232.204702047362 Test RE 0.3132857804810356\n",
      "11 Train Loss 129317.5 Test MSE 24526.06629742557 Test RE 0.2776216372762281\n",
      "12 Train Loss 122280.31 Test MSE 19707.65047585284 Test RE 0.2488609690069525\n",
      "13 Train Loss 107993.33 Test MSE 17554.110628776903 Test RE 0.23487066515683458\n",
      "14 Train Loss 103836.55 Test MSE 15006.679657133254 Test RE 0.217160917638085\n",
      "15 Train Loss 92165.484 Test MSE 13157.19054392373 Test RE 0.20333912215978153\n",
      "16 Train Loss 78482.52 Test MSE 12718.529402343584 Test RE 0.19992072191385013\n",
      "17 Train Loss 73433.336 Test MSE 10834.656214191757 Test RE 0.18452148029689797\n",
      "18 Train Loss 70082.14 Test MSE 10046.841592448307 Test RE 0.17768638001649403\n",
      "19 Train Loss 64275.35 Test MSE 8742.49176218443 Test RE 0.16575131327671336\n",
      "20 Train Loss 57748.477 Test MSE 8292.379371651283 Test RE 0.1614280287561232\n",
      "21 Train Loss 53085.918 Test MSE 7353.3946080431615 Test RE 0.15201389899929657\n",
      "22 Train Loss 50785.062 Test MSE 7218.428605608909 Test RE 0.1506123881648457\n",
      "23 Train Loss 48365.945 Test MSE 6215.403496356884 Test RE 0.1397571469022489\n",
      "24 Train Loss 45252.8 Test MSE 6227.750045667334 Test RE 0.13989588789029742\n",
      "25 Train Loss 42773.32 Test MSE 6083.862604867885 Test RE 0.1382703496283995\n",
      "26 Train Loss 41984.492 Test MSE 5627.075956845906 Test RE 0.13297829214310017\n",
      "27 Train Loss 39622.164 Test MSE 5133.877079187501 Test RE 0.12701707144615726\n",
      "28 Train Loss 37425.754 Test MSE 5172.093579252304 Test RE 0.12748895144654007\n",
      "29 Train Loss 36234.543 Test MSE 5093.174741603816 Test RE 0.12651256194676466\n",
      "30 Train Loss 35240.367 Test MSE 4808.377379235489 Test RE 0.12292455220206928\n",
      "31 Train Loss 34480.07 Test MSE 4638.684744310954 Test RE 0.12073600211751562\n",
      "32 Train Loss 33926.91 Test MSE 4699.886360300081 Test RE 0.12152987208132177\n",
      "33 Train Loss 33185.074 Test MSE 4553.217943778978 Test RE 0.11961856319342291\n",
      "34 Train Loss 32464.938 Test MSE 4356.619589809161 Test RE 0.11700762984633434\n",
      "35 Train Loss 32232.664 Test MSE 4414.205969139686 Test RE 0.11777840240002074\n",
      "36 Train Loss 32046.879 Test MSE 4380.978766256863 Test RE 0.11733428637971163\n",
      "37 Train Loss 31888.287 Test MSE 4520.743295170082 Test RE 0.11919122563897598\n",
      "38 Train Loss 31738.637 Test MSE 4602.8125628913 Test RE 0.12026825426854579\n",
      "39 Train Loss 31396.08 Test MSE 4656.341228798473 Test RE 0.12096556596432652\n",
      "40 Train Loss 30922.93 Test MSE 4610.232359963052 Test RE 0.12036515227293433\n",
      "41 Train Loss 30691.092 Test MSE 4591.552615607038 Test RE 0.12012105693984212\n",
      "42 Train Loss 30636.074 Test MSE 4597.0639479957445 Test RE 0.1201931271724129\n",
      "43 Train Loss 30553.633 Test MSE 4652.109665293213 Test RE 0.12091058826870515\n",
      "44 Train Loss 30443.697 Test MSE 4592.85866456215 Test RE 0.12013813970458052\n",
      "45 Train Loss 30395.746 Test MSE 4556.955600585476 Test RE 0.11966764951295922\n",
      "46 Train Loss 30237.148 Test MSE 4551.272355056821 Test RE 0.11959300397388797\n",
      "47 Train Loss 30162.043 Test MSE 4428.197523147812 Test RE 0.11796491376017257\n",
      "48 Train Loss 30111.258 Test MSE 4413.6371967101095 Test RE 0.11777081425544994\n",
      "49 Train Loss 30045.96 Test MSE 4341.391887960769 Test RE 0.11680296233560555\n",
      "50 Train Loss 30001.273 Test MSE 4343.589972785275 Test RE 0.11683252777637096\n",
      "51 Train Loss 29952.762 Test MSE 4361.491460778261 Test RE 0.11707303454671604\n",
      "52 Train Loss 29781.541 Test MSE 4563.641265412848 Test RE 0.11975540158171694\n",
      "53 Train Loss 29545.86 Test MSE 4551.207836130539 Test RE 0.11959215629449733\n",
      "54 Train Loss 29203.176 Test MSE 4360.404004512513 Test RE 0.11705843865184772\n",
      "55 Train Loss 28865.398 Test MSE 4207.390152635342 Test RE 0.11498620884045453\n",
      "56 Train Loss 28238.676 Test MSE 3839.33798955464 Test RE 0.10984177322333231\n",
      "57 Train Loss 28052.393 Test MSE 3768.663990914375 Test RE 0.10882610140005478\n",
      "58 Train Loss 27722.29 Test MSE 3667.5492716160857 Test RE 0.10735625191422633\n",
      "59 Train Loss 27523.469 Test MSE 3572.965878415719 Test RE 0.1059628904803547\n",
      "60 Train Loss 27378.822 Test MSE 3501.2207431399565 Test RE 0.10489362843622373\n",
      "61 Train Loss 27190.398 Test MSE 3454.836409803496 Test RE 0.10419649401532684\n",
      "62 Train Loss 26919.963 Test MSE 3440.722211988359 Test RE 0.10398343688938018\n",
      "63 Train Loss 26787.477 Test MSE 3519.771791206432 Test RE 0.10517114821359962\n",
      "64 Train Loss 26518.697 Test MSE 3313.7458017595713 Test RE 0.10204669822852343\n",
      "65 Train Loss 26134.406 Test MSE 3260.52594748545 Test RE 0.10122392949948326\n",
      "66 Train Loss 25665.354 Test MSE 3174.409676666279 Test RE 0.09987823276329988\n",
      "67 Train Loss 25170.008 Test MSE 3204.149811171438 Test RE 0.10034500731206812\n",
      "68 Train Loss 24618.033 Test MSE 3126.3805976666536 Test RE 0.09911976999734176\n",
      "69 Train Loss 24446.797 Test MSE 3072.0778004271365 Test RE 0.09825518262712366\n",
      "70 Train Loss 24383.762 Test MSE 3050.41273738148 Test RE 0.09790810953898782\n",
      "71 Train Loss 23825.342 Test MSE 2911.3411087171594 Test RE 0.09565020575347992\n",
      "72 Train Loss 23491.135 Test MSE 2761.3192622395195 Test RE 0.09315317748727933\n",
      "73 Train Loss 23332.812 Test MSE 2645.3883069327244 Test RE 0.09117674355265444\n",
      "74 Train Loss 23170.643 Test MSE 2602.24286302749 Test RE 0.09043015500400685\n",
      "75 Train Loss 22852.117 Test MSE 2568.4464515081004 Test RE 0.08984100884386177\n",
      "76 Train Loss 22734.291 Test MSE 2614.5220798563473 Test RE 0.09064326052392496\n",
      "77 Train Loss 22625.145 Test MSE 2638.673818390088 Test RE 0.09106095825095624\n",
      "78 Train Loss 22484.158 Test MSE 2636.971956133159 Test RE 0.0910315877764533\n",
      "79 Train Loss 22318.705 Test MSE 2608.181053154163 Test RE 0.09053327479025815\n",
      "80 Train Loss 22272.965 Test MSE 2650.1301223580294 Test RE 0.09125842338000631\n",
      "81 Train Loss 22198.703 Test MSE 2535.0546302146804 Test RE 0.08925509644254076\n",
      "82 Train Loss 22092.34 Test MSE 2454.039020492921 Test RE 0.08781730280508793\n",
      "83 Train Loss 22016.637 Test MSE 2370.8777449102568 Test RE 0.08631652387930898\n",
      "84 Train Loss 21948.55 Test MSE 2304.1425889955826 Test RE 0.085093039709189\n",
      "85 Train Loss 21755.734 Test MSE 2281.6295307794585 Test RE 0.08467631050913554\n",
      "86 Train Loss 21622.383 Test MSE 2118.659871855923 Test RE 0.08159620918899466\n",
      "87 Train Loss 21490.219 Test MSE 2099.689111005969 Test RE 0.08123007611778021\n",
      "88 Train Loss 21352.791 Test MSE 2047.0802326649264 Test RE 0.08020598828730047\n",
      "89 Train Loss 21293.186 Test MSE 1989.5408228380588 Test RE 0.0790707375097253\n",
      "90 Train Loss 21225.521 Test MSE 2010.0930530638216 Test RE 0.07947809399515052\n",
      "91 Train Loss 20921.828 Test MSE 1830.008745032124 Test RE 0.07583434582751136\n",
      "92 Train Loss 20737.969 Test MSE 1690.6300540011819 Test RE 0.07288927906863384\n",
      "93 Train Loss 20649.309 Test MSE 1616.4911685988 Test RE 0.07127316263073334\n",
      "94 Train Loss 20501.717 Test MSE 1630.7225515595248 Test RE 0.07158621505835158\n",
      "95 Train Loss 20385.305 Test MSE 1613.8782663099444 Test RE 0.0712155362329181\n",
      "96 Train Loss 20305.887 Test MSE 1642.5517240522277 Test RE 0.07184538715337056\n",
      "97 Train Loss 20256.988 Test MSE 1711.7295293372722 Test RE 0.07334270672185826\n",
      "98 Train Loss 20220.055 Test MSE 1770.322670098465 Test RE 0.07458741872309561\n",
      "99 Train Loss 20151.611 Test MSE 1766.9476758467993 Test RE 0.07451628700074579\n",
      "Training time: 257.64\n",
      "3D_HTTP_swish_tune4\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Sigmoid()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "NAN BREAK!\n",
      "Training time: 4.50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "max_reps = 10\n",
    "max_iter = 100\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "\n",
    "    print(reps)\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "    N_D = 5000 #Total number of data points for 'y'\n",
    "    N_N = 3500\n",
    "    N_f = 10000 #Total number of collocation points \n",
    "\n",
    "    layers = np.array([3,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.05, \n",
    "                              max_iter = 10, \n",
    "                              max_eval = 15, \n",
    "                              tolerance_grad = 1e-8, \n",
    "                              tolerance_change = 1e-8, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "    if(nan_flag == 1):\n",
    "        nan_tune.append(tune_reps)\n",
    "        break\n",
    "\n",
    "    #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jFzPEF73CQsD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0.10477430933593798\n",
      "1   0.11040017357748655\n",
      "2   [[0.52879029 0.51837763 0.48879056 0.47016707 0.40989647 0.40014714\n",
      "  0.36929705 0.36022068 0.3501448  0.33076636 0.33011044 0.32174734\n",
      "  0.31468602 0.31207033 0.30288402 0.29338248 0.27812097 0.2697157\n",
      "  0.25892051 0.20839559 0.19626028 0.16919262 0.15911141 0.16422363\n",
      "  0.16310806 0.16536131 0.1544084  0.14186341 0.13571906 0.13611292\n",
      "  0.13866738 0.13051189 0.1262464  0.12917773 0.12350886 0.11640864\n",
      "  0.11454746 0.11162923 0.1161361  0.12546072 0.1235074  0.12394727\n",
      "  0.12285486 0.13025208 0.13020519 0.11909455 0.11639927 0.11771088\n",
      "  0.11335871 0.113055   0.11561062 0.11538279 0.11288861 0.11389368\n",
      "  0.11693128 0.11944143 0.12025258 0.11616102 0.11419393 0.10990555\n",
      "  0.11049344 0.11105718 0.10899862 0.10834166 0.10809462 0.10841191\n",
      "  0.10881856 0.10898976 0.10720241 0.10478423 0.10463241 0.10631825\n",
      "  0.10637852 0.10543864 0.10468613 0.10492808 0.10667281 0.1073531\n",
      "  0.1063488  0.10508262 0.10325851 0.10330287 0.10292568 0.10225206\n",
      "  0.10364857 0.10296575 0.10288714 0.1028325  0.10287262 0.10355052\n",
      "  0.10375342 0.10320892 0.10402268 0.10413817 0.10149964 0.10086949\n",
      "  0.09952981 0.09846441 0.09702    0.09909122]]\n",
      "3   [[nan]]\n",
      "4   [[nan]]\n"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"3D_HTTP_swish_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(tune_reps,\" \",np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HT_stan_v3_15Aug2022_MP4Video.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
