{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('burgers_shock_10sin.mat')\n",
    "label = \"QCRE_2D_5_tanhxtanh_NW\"\n",
    "                     \n",
    "x_test = data['x']                                   # 256 points between -1 and 1 [256x1]\n",
    "t_test = data['t']   \n",
    "usol = data['usol']\n",
    "X_test, T_test = np.meshgrid(x_test,t_test)  \n",
    "\n",
    "xt_test_tensor = torch.from_numpy(np.hstack((X_test.flatten()[:,None], T_test.flatten()[:,None]))).float().to(device)\n",
    "\n",
    "u_true = usol.flatten('F')[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = scipy.io.loadmat('burgers_shock_10sin.mat')  \t# Load data from file\n",
    "\n",
    "pi = torch.from_numpy(np.array(np.pi)).double().to(device)\n",
    "\n",
    "label = \"QCRE_2D_5_tanhxtanh_NW\"\n",
    "# x = data['x']                                   # 256 points between -1 and 1 [256x1]\n",
    "# t = data['t']                                   # 100 time points between 0 and 0.2 [100x1] \n",
    "# usol = data['usol']   \n",
    "\n",
    "#usol = usol/1000# solution of 256x100 grid points\n",
    "\n",
    "x = np.linspace(-1,1,500).reshape(-1,1)\n",
    "t = np.linspace(0,0.2,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "#y_true = true_2D_1(xt)\n",
    "\n",
    "bound_pts_1 = (X==-1).reshape(-1,)\n",
    "xt_bound_1 = xt[bound_pts_1,:]\n",
    "u_bound_1 = np.zeros((np.shape(xt_bound_1)[0],1))\n",
    "\n",
    "bound_pts_2 = (X==1).reshape(-1,)\n",
    "xt_bound_2 = xt[bound_pts_2,:]\n",
    "u_bound_2 = np.zeros((np.shape(xt_bound_2)[0],1))\n",
    "\n",
    "bound_pts_3 = (T==0).reshape(-1,)\n",
    "xt_bound_3 = xt[bound_pts_3,:]\n",
    "u_bound_3 = -10*np.sin(np.pi*xt_bound_3[:,0].reshape(-1,1))\n",
    "#u_bound_3 = -10*np.ones((np.shape(bound_pts_3)[0],1))\n",
    "\n",
    "\n",
    "xt_bound = np.vstack((xt_bound_1,xt_bound_2,xt_bound_3))\n",
    "u_bound = np.vstack((u_bound_1,u_bound_2,u_bound_3))\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xt_bound_3[:,0],u_bound_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_u,N_f,seed):\n",
    "\n",
    "    '''Boundary Conditions'''\n",
    "    #Initial Condition -1 =< x =<1 and t = 0  \n",
    "#     leftedge_x = np.hstack((X[0,:][:,None], T[0,:][:,None])) #L1\n",
    "#     leftedge_u = usol[:,0][:,None]\n",
    "\n",
    "#     #Boundary Condition x = -1 and 0 =< t =<1\n",
    "#     bottomedge_x = np.hstack((X[:,0][:,None], T[:,0][:,None])) #L2\n",
    "#     bottomedge_u = usol[-1,:][:,None]\n",
    "\n",
    "#     #Boundary Condition x = 1 and 0 =< t =<1\n",
    "#     topedge_x = np.hstack((X[:,-1][:,None], T[:,0][:,None])) #L3\n",
    "#     topedge_u = usol[0,:][:,None]\n",
    "\n",
    "#     all_X_u_train = np.vstack([leftedge_x, bottomedge_x, topedge_x]) # X_u_train [456,2] (456 = 256(L1)+100(L2)+100(L3))\n",
    "#     all_u_train = np.vstack([leftedge_u, bottomedge_u, topedge_u])   #corresponding u [456x1]\n",
    "\n",
    "    #choose random N_u points for training\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.choice(xt_bound.shape[0], N_u, replace=True) \n",
    "\n",
    "    X_u_train = xt_bound[idx, :] #choose indices from  set 'idx' (x,t)\n",
    "    u_train = u_bound[idx,:]      #choose corresponding u\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    X_f_train = lb_xt + (ub_xt-lb_xt)*samples \n",
    "    \n",
    "    X_f_train = np.vstack((X_f_train, X_u_train)) # append training points to collocation points \n",
    "\n",
    "    return X_f_train, X_u_train, u_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n   Fortran Style ('F') flatten,stacked column wise!\\n   u = [c1 \\n        c2\\n        .\\n        .\\n        cn]\\n\\n   u =  [25600x1] \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_u_test = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "X_u_test = xt_test_tensor\n",
    "# Domain bounds\n",
    "lb = X_u_test[0]  # [-1. 0.]\n",
    "ub = X_u_test[-1] # [1.  0.99]\n",
    "\n",
    "'''\n",
    "   Fortran Style ('F') flatten,stacked column wise!\n",
    "   u = [c1 \n",
    "        c2\n",
    "        .\n",
    "        .\n",
    "        cn]\n",
    "\n",
    "   u =  [25600x1] \n",
    "'''\n",
    "#u_true = usol.flatten('F')[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        '''\n",
    "        Alternatively:\n",
    "        \n",
    "        *all layers are callable \n",
    "    \n",
    "        Simple linear Layers\n",
    "        self.fc1 = nn.Linear(2,50)\n",
    "        self.fc2 = nn.Linear(50,50)\n",
    "        self.fc3 = nn.Linear(50,50)\n",
    "        self.fc4 = nn.Linear(50,1)\n",
    "        \n",
    "        '''\n",
    "    \n",
    "        'Xavier Normal Initialization'\n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            # weights from a normal distribution with \n",
    "            # Recommended gain value for tanh = 5/3?\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        self.beta = Parameter(1*torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        self.beta_val = []\n",
    "        \n",
    "        \n",
    "    'foward pass'\n",
    "    def forward(self,x):\n",
    "         if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "         u_b = torch.from_numpy(ub_xt).float().to(device)\n",
    "         l_b = torch.from_numpy(lb_xt).float().to(device)\n",
    "        \n",
    "            \n",
    "         #preprocessing input \n",
    "         x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "         #convert to float\n",
    "         a = x.float()\n",
    "                        \n",
    "         '''     \n",
    "         Alternatively:\n",
    "        \n",
    "         a = self.activation(self.fc1(a))\n",
    "         a = self.activation(self.fc2(a))\n",
    "         a = self.activation(self.fc3(a))\n",
    "         a = self.fc4(a)\n",
    "         \n",
    "         '''\n",
    "        \n",
    "         for i in range(len(layers)-3):\n",
    "                z = self.linears[i](a)\n",
    "                a = self.activation(z) + self.beta[:,i]*z*self.activation(z)\n",
    "         \n",
    "         a = self.linears[-2](a)\n",
    "         a = self.linears[-1](a)   \n",
    "            \n",
    "        \n",
    "         return a\n",
    "                        \n",
    "    def loss_BC(self,x,y):\n",
    "                \n",
    "        loss_u = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_u\n",
    "    \n",
    "    def loss_PDE(self, x_to_train_f,f_hat):\n",
    "        \n",
    "        nu = 0.01/pi\n",
    "                \n",
    "        x_1_f = x_to_train_f[:,[0]]\n",
    "        x_2_f = x_to_train_f[:,[1]]\n",
    "                        \n",
    "        g = x_to_train_f.clone()\n",
    "                        \n",
    "        g.requires_grad = True\n",
    "        \n",
    "        u = self.forward(g)\n",
    "                \n",
    "        u_x_t = autograd.grad(u,g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "                                \n",
    "        u_xx_tt = autograd.grad(u_x_t,g,torch.ones(x_to_train_f.shape).to(device), create_graph=True)[0]\n",
    "                                                            \n",
    "        u_x = u_x_t[:,[0]]\n",
    "        \n",
    "        u_t = u_x_t[:,[1]]\n",
    "        \n",
    "        u_xx = u_xx_tt[:,[0]]\n",
    "                                        \n",
    "        f = u_t + (self.forward(g))*(u_x) - (nu)*u_xx \n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,x,y,x_to_train_f,f_hat):\n",
    "\n",
    "        loss_u = self.loss_BC(x,y)\n",
    "        loss_f = self.loss_PDE(x_to_train_f,f_hat)\n",
    "\n",
    "        \n",
    "        \n",
    "        loss_val = loss_u + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    'callable for optimizer'                                       \n",
    "    def closure(self):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         X_f_train_np_array, X_u_train_np_array, u_train_np_array = trainingdata(N_u,N_f,self.iter*32)\n",
    "        \n",
    "#         X_f_train = torch.from_numpy(X_f_train_np_array).float().to(device)\n",
    "#         X_u_train = torch.from_numpy(X_u_train_np_array).float().to(device)\n",
    "#         u_train = torch.from_numpy(u_train_np_array).float().to(device)\n",
    "        \n",
    "#     #u = torch.from_numpy(u_true).float().to(device)\n",
    "#         f_hat = torch.zeros(X_f_train.shape[0],1).to(device)\n",
    "        \n",
    "\n",
    "        loss = self.loss(X_u_train, u_train, X_f_train,f_hat)\n",
    "        \n",
    "        self.train_loss.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        \n",
    "        u_pred = self.test(xt_test_tensor)\n",
    "        self.test_loss.append(np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1))))\n",
    "        self.beta_val.append(self.beta.cpu().detach().numpy())\n",
    "        \n",
    "        print(self.iter,\"Train Loss\",self.train_loss[-1],\"Test Loss\",self.test_loss[-1])\n",
    "#         print(self.iter,\"Train Loss\",self.train_loss[-1])\n",
    "        loss.backward()\n",
    "        self.iter += 1\n",
    "     \n",
    "        return loss        \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self,xt_test_tensor):\n",
    "        u_pred = self.forward(xt_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0 Train Loss 20.604023 Test Loss 24.643764922173155\n",
      "1 Train Loss 19.652573 Test Loss 24.605853098306127\n",
      "2 Train Loss 17.86755 Test Loss 24.4661022311603\n",
      "3 Train Loss 17.702892 Test Loss 24.413271316071917\n",
      "4 Train Loss 17.521772 Test Loss 24.335553003139793\n",
      "5 Train Loss 17.284925 Test Loss 24.18411716437729\n",
      "6 Train Loss 17.016474 Test Loss 23.75240225615123\n",
      "7 Train Loss 16.922358 Test Loss 23.532411201182757\n",
      "8 Train Loss 17.33824 Test Loss 20.956389350281434\n",
      "9 Train Loss 16.571884 Test Loss 22.375901490315847\n",
      "10 Train Loss 16.441252 Test Loss 21.29929778577183\n",
      "11 Train Loss 16.116379 Test Loss 21.47073941633936\n",
      "12 Train Loss 15.993751 Test Loss 20.952510888502893\n",
      "13 Train Loss 15.936906 Test Loss 20.74961789931467\n",
      "14 Train Loss 15.878156 Test Loss 20.727367753376743\n",
      "15 Train Loss 15.866012 Test Loss 20.735236711972508\n",
      "16 Train Loss 15.850722 Test Loss 20.66076138447645\n",
      "17 Train Loss 15.729568 Test Loss 20.03751966269481\n",
      "18 Train Loss 15.599435 Test Loss 19.550701691786934\n",
      "19 Train Loss 15.952974 Test Loss 19.505883192616704\n",
      "20 Train Loss 15.413385 Test Loss 19.248225375896656\n",
      "21 Train Loss 15.058323 Test Loss 19.53684692307327\n",
      "22 Train Loss 14.703648 Test Loss 19.081847401821673\n",
      "23 Train Loss 15.545881 Test Loss 18.35009855971704\n",
      "24 Train Loss 14.530028 Test Loss 18.71444287928954\n",
      "25 Train Loss 14.303813 Test Loss 18.53748814334115\n",
      "26 Train Loss 14.206202 Test Loss 18.251124683823278\n",
      "27 Train Loss 14.141878 Test Loss 17.897221075394757\n",
      "28 Train Loss 14.104399 Test Loss 17.866547119568285\n",
      "29 Train Loss 14.076775 Test Loss 17.902520768062097\n",
      "30 Train Loss 14.038871 Test Loss 17.80552639306973\n",
      "31 Train Loss 13.9693 Test Loss 17.51515115901069\n",
      "32 Train Loss 13.921635 Test Loss 17.372062849344957\n",
      "33 Train Loss 13.808474 Test Loss 17.004720926408545\n",
      "34 Train Loss 13.681248 Test Loss 16.87049509951671\n",
      "35 Train Loss 15.404011 Test Loss 17.50325174504284\n",
      "36 Train Loss 13.493881 Test Loss 16.747237972669915\n",
      "37 Train Loss 13.444689 Test Loss 16.864584924428158\n",
      "38 Train Loss 13.313505 Test Loss 16.762369883797977\n",
      "39 Train Loss 13.263128 Test Loss 16.60774013995441\n",
      "40 Train Loss 13.201643 Test Loss 16.317717659519694\n",
      "41 Train Loss 13.151226 Test Loss 16.317717361956383\n",
      "42 Train Loss 13.092853 Test Loss 16.321934525229402\n",
      "43 Train Loss 13.034379 Test Loss 16.236495343237273\n",
      "44 Train Loss 12.9923 Test Loss 16.192187236303447\n",
      "45 Train Loss 12.953291 Test Loss 16.15995157604786\n",
      "46 Train Loss 12.887168 Test Loss 16.03341614080913\n",
      "47 Train Loss 12.836559 Test Loss 16.015611210190414\n",
      "48 Train Loss 12.796638 Test Loss 16.059725778472654\n",
      "49 Train Loss 12.72615 Test Loss 15.969256327322935\n",
      "50 Train Loss 12.664698 Test Loss 15.915089823392567\n",
      "51 Train Loss 12.634623 Test Loss 15.931698634983285\n",
      "52 Train Loss 12.586959 Test Loss 15.920289014642494\n",
      "53 Train Loss 12.4886465 Test Loss 15.934146610956109\n",
      "54 Train Loss 12.419608 Test Loss 15.842507248733884\n",
      "55 Train Loss 12.339833 Test Loss 15.61119529674036\n",
      "56 Train Loss 12.297912 Test Loss 15.675983408643658\n",
      "57 Train Loss 12.262204 Test Loss 15.50838945302912\n",
      "58 Train Loss 12.203083 Test Loss 15.373140042197615\n",
      "59 Train Loss 12.169424 Test Loss 15.023658886080748\n",
      "60 Train Loss 12.12074 Test Loss 15.11747849721843\n",
      "61 Train Loss 12.07113 Test Loss 15.029328981458155\n",
      "62 Train Loss 11.982582 Test Loss 14.964614849416517\n",
      "63 Train Loss 11.917344 Test Loss 15.086664436133926\n",
      "64 Train Loss 11.885592 Test Loss 15.032847758591176\n",
      "65 Train Loss 11.822601 Test Loss 15.114992416317161\n",
      "66 Train Loss 11.768034 Test Loss 15.037015357499124\n",
      "67 Train Loss 11.690797 Test Loss 14.908880785302502\n",
      "68 Train Loss 11.637833 Test Loss 14.715531035247436\n",
      "69 Train Loss 11.575476 Test Loss 14.696359034486989\n",
      "70 Train Loss 11.567192 Test Loss 14.721989240749679\n",
      "71 Train Loss 11.52559 Test Loss 14.748460822670603\n",
      "72 Train Loss 11.4920635 Test Loss 14.671121501756263\n",
      "73 Train Loss 11.467151 Test Loss 14.631639518296227\n",
      "74 Train Loss 11.44363 Test Loss 14.565686237437612\n",
      "75 Train Loss 11.42275 Test Loss 14.566714605718898\n",
      "76 Train Loss 11.401385 Test Loss 14.566958683422142\n",
      "77 Train Loss 11.372069 Test Loss 14.514759409120717\n",
      "78 Train Loss 11.314749 Test Loss 14.38261032939227\n",
      "79 Train Loss 11.286438 Test Loss 14.401890489407817\n",
      "80 Train Loss 11.237189 Test Loss 14.328865918889264\n",
      "81 Train Loss 11.204879 Test Loss 14.319704654837503\n",
      "82 Train Loss 11.175845 Test Loss 14.365564233202136\n",
      "83 Train Loss 11.147849 Test Loss 14.343039967641689\n",
      "84 Train Loss 11.110211 Test Loss 14.293914117772836\n",
      "85 Train Loss 11.071993 Test Loss 14.251547172645123\n",
      "86 Train Loss 11.045355 Test Loss 14.11727442688878\n",
      "87 Train Loss 11.033503 Test Loss 14.02750073560024\n",
      "88 Train Loss 11.017305 Test Loss 14.041527900482263\n",
      "89 Train Loss 11.003045 Test Loss 14.066150913467341\n",
      "90 Train Loss 10.989298 Test Loss 14.09350370114848\n",
      "91 Train Loss 10.970059 Test Loss 14.057019484059635\n",
      "92 Train Loss 10.944661 Test Loss 13.999201828541567\n",
      "93 Train Loss 10.9102125 Test Loss 13.90047632194283\n",
      "94 Train Loss 10.885252 Test Loss 13.797659834095548\n",
      "95 Train Loss 10.866995 Test Loss 13.744738982717804\n",
      "96 Train Loss 10.839754 Test Loss 13.757458417635778\n",
      "97 Train Loss 10.805967 Test Loss 13.764548296254002\n",
      "98 Train Loss 10.780277 Test Loss 13.781620568857507\n",
      "99 Train Loss 10.76535 Test Loss 13.792927305607181\n",
      "100 Train Loss 10.748221 Test Loss 13.816285909438266\n",
      "101 Train Loss 10.725503 Test Loss 13.763569084940018\n",
      "102 Train Loss 10.701332 Test Loss 13.725686648674937\n",
      "103 Train Loss 10.67318 Test Loss 13.656548288674768\n",
      "104 Train Loss 10.719814 Test Loss 13.501856446624354\n",
      "105 Train Loss 10.659392 Test Loss 13.595224395358272\n",
      "106 Train Loss 10.645257 Test Loss 13.518887500675227\n",
      "107 Train Loss 10.617925 Test Loss 13.526108202118301\n",
      "108 Train Loss 10.595874 Test Loss 13.52699464837974\n",
      "109 Train Loss 10.568861 Test Loss 13.543712401394346\n",
      "110 Train Loss 10.529208 Test Loss 13.501013912188503\n",
      "111 Train Loss 10.500482 Test Loss 13.49822689901461\n",
      "112 Train Loss 10.474626 Test Loss 13.552052233317186\n",
      "113 Train Loss 10.458838 Test Loss 13.508421305017187\n",
      "114 Train Loss 10.448506 Test Loss 13.520530966559285\n",
      "115 Train Loss 10.439756 Test Loss 13.505251524490548\n",
      "116 Train Loss 10.429221 Test Loss 13.489516067536927\n",
      "117 Train Loss 10.412389 Test Loss 13.467651078347913\n",
      "118 Train Loss 10.39283 Test Loss 13.450166739814724\n",
      "119 Train Loss 10.365424 Test Loss 13.427709833146643\n",
      "120 Train Loss 10.328557 Test Loss 13.38764356526567\n",
      "121 Train Loss 10.308046 Test Loss 13.30337362447336\n",
      "122 Train Loss 10.284403 Test Loss 13.288090755047097\n",
      "123 Train Loss 10.273695 Test Loss 13.266887790105779\n",
      "124 Train Loss 10.255627 Test Loss 13.249170953364342\n",
      "125 Train Loss 10.224995 Test Loss 13.200516375087922\n",
      "126 Train Loss 10.207564 Test Loss 13.155258315868359\n",
      "127 Train Loss 10.185367 Test Loss 13.13828000653719\n",
      "128 Train Loss 10.171065 Test Loss 13.168206371481796\n",
      "129 Train Loss 10.163265 Test Loss 13.132395408601688\n",
      "130 Train Loss 10.151646 Test Loss 13.142433733915228\n",
      "131 Train Loss 10.138231 Test Loss 13.142023125960478\n",
      "132 Train Loss 10.119432 Test Loss 13.116512810672418\n",
      "133 Train Loss 10.10269 Test Loss 13.110714459516528\n",
      "134 Train Loss 10.0881815 Test Loss 13.106710580590264\n",
      "135 Train Loss 10.077512 Test Loss 13.071452907432151\n",
      "136 Train Loss 10.06212 Test Loss 13.072937888941716\n",
      "137 Train Loss 10.039851 Test Loss 13.050962027049227\n",
      "138 Train Loss 10.027051 Test Loss 13.025989677078641\n",
      "139 Train Loss 10.015127 Test Loss 13.014238918383025\n",
      "140 Train Loss 10.008246 Test Loss 13.000067199204565\n",
      "141 Train Loss 10.002974 Test Loss 12.993292695631123\n",
      "142 Train Loss 10.000468 Test Loss 13.005838132777148\n",
      "143 Train Loss 9.993279 Test Loss 12.989235092501204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 Train Loss 9.989927 Test Loss 12.990797617374344\n",
      "145 Train Loss 9.986322 Test Loss 12.980303352110102\n",
      "146 Train Loss 9.982006 Test Loss 12.989038170602647\n",
      "147 Train Loss 9.976697 Test Loss 12.991739211612499\n",
      "148 Train Loss 9.971518 Test Loss 12.982386080180365\n",
      "149 Train Loss 9.96719 Test Loss 12.980250106026215\n",
      "150 Train Loss 9.962116 Test Loss 12.978915506769244\n",
      "151 Train Loss 9.95335 Test Loss 12.965455972570618\n",
      "152 Train Loss 9.950003 Test Loss 12.954867894983668\n",
      "153 Train Loss 9.946561 Test Loss 12.956335204847443\n",
      "154 Train Loss 9.944464 Test Loss 12.947631103162404\n",
      "155 Train Loss 9.941664 Test Loss 12.9451395789538\n",
      "156 Train Loss 9.931007 Test Loss 12.929704698472475\n",
      "157 Train Loss 9.918931 Test Loss 12.911819337228833\n",
      "158 Train Loss 9.903914 Test Loss 12.901654516170694\n",
      "159 Train Loss 9.8906555 Test Loss 12.878814607308412\n",
      "160 Train Loss 9.881534 Test Loss 12.883576276118422\n",
      "161 Train Loss 9.874165 Test Loss 12.864828300117665\n",
      "162 Train Loss 9.868316 Test Loss 12.859148219177614\n",
      "163 Train Loss 9.862545 Test Loss 12.846719830245645\n",
      "164 Train Loss 9.859278 Test Loss 12.843610309417906\n",
      "165 Train Loss 9.856364 Test Loss 12.83835848618666\n",
      "166 Train Loss 9.852752 Test Loss 12.843089767179338\n",
      "167 Train Loss 9.846056 Test Loss 12.838000017156933\n",
      "168 Train Loss 9.837723 Test Loss 12.833290006274213\n",
      "169 Train Loss 9.827581 Test Loss 12.81305485373813\n",
      "170 Train Loss 9.815642 Test Loss 12.791504302606258\n",
      "171 Train Loss 9.804814 Test Loss 12.762698282091169\n",
      "172 Train Loss 9.796348 Test Loss 12.747386624181322\n",
      "173 Train Loss 9.786958 Test Loss 12.746205270836583\n",
      "174 Train Loss 9.781237 Test Loss 12.759129908544832\n",
      "175 Train Loss 9.777397 Test Loss 12.755684738488924\n",
      "176 Train Loss 9.775571 Test Loss 12.758618452605928\n",
      "177 Train Loss 9.773055 Test Loss 12.749191695868113\n",
      "178 Train Loss 9.766944 Test Loss 12.723434264691257\n",
      "179 Train Loss 9.761719 Test Loss 12.705674145017635\n",
      "180 Train Loss 9.7532835 Test Loss 12.675530086227702\n",
      "181 Train Loss 9.740084 Test Loss 12.648474555235682\n",
      "182 Train Loss 9.729113 Test Loss 12.628847162516712\n",
      "183 Train Loss 9.740793 Test Loss 12.63882539011962\n",
      "184 Train Loss 9.721449 Test Loss 12.63230120004778\n",
      "185 Train Loss 9.709582 Test Loss 12.626657359982474\n",
      "186 Train Loss 9.699152 Test Loss 12.635522250628428\n",
      "187 Train Loss 9.687651 Test Loss 12.648343379479044\n",
      "188 Train Loss 9.679716 Test Loss 12.64063176375625\n",
      "189 Train Loss 9.670513 Test Loss 12.61944698368781\n",
      "190 Train Loss 9.654456 Test Loss 12.597637845133384\n",
      "191 Train Loss 9.637806 Test Loss 12.57517800753354\n",
      "192 Train Loss 9.626288 Test Loss 12.549985055687616\n",
      "193 Train Loss 9.62134 Test Loss 12.574999587852119\n",
      "194 Train Loss 9.616156 Test Loss 12.556466457215363\n",
      "195 Train Loss 9.612901 Test Loss 12.545267664847941\n",
      "196 Train Loss 9.608766 Test Loss 12.542301787851336\n",
      "197 Train Loss 9.600343 Test Loss 12.544847760306682\n",
      "198 Train Loss 9.592165 Test Loss 12.534997956748382\n",
      "199 Train Loss 9.5873165 Test Loss 12.538108339036404\n",
      "200 Train Loss 9.5844 Test Loss 12.546736284558376\n",
      "201 Train Loss 9.581156 Test Loss 12.540924765733884\n",
      "202 Train Loss 9.57911 Test Loss 12.538013861154747\n",
      "203 Train Loss 9.5769415 Test Loss 12.529930623838466\n",
      "204 Train Loss 9.573113 Test Loss 12.526043592927953\n",
      "205 Train Loss 9.565129 Test Loss 12.506259321821258\n",
      "206 Train Loss 9.557273 Test Loss 12.49519209442381\n",
      "207 Train Loss 9.550156 Test Loss 12.491321453263888\n",
      "208 Train Loss 9.544309 Test Loss 12.485745124778134\n",
      "209 Train Loss 9.539188 Test Loss 12.48604110355564\n",
      "210 Train Loss 9.53314 Test Loss 12.492325908469798\n",
      "211 Train Loss 9.521973 Test Loss 12.477569255029517\n",
      "212 Train Loss 9.508224 Test Loss 12.461664934638739\n",
      "213 Train Loss 9.500715 Test Loss 12.451460268472138\n",
      "214 Train Loss 9.496084 Test Loss 12.440675339942054\n",
      "215 Train Loss 9.492661 Test Loss 12.438589325693046\n",
      "216 Train Loss 9.4898205 Test Loss 12.437090330518545\n",
      "217 Train Loss 9.487302 Test Loss 12.43941185635825\n",
      "218 Train Loss 9.483708 Test Loss 12.445021254731605\n",
      "219 Train Loss 9.478204 Test Loss 12.437424237548882\n",
      "220 Train Loss 9.473091 Test Loss 12.443497282737011\n",
      "221 Train Loss 9.469614 Test Loss 12.442867586390442\n",
      "222 Train Loss 9.467677 Test Loss 12.435849440267848\n",
      "223 Train Loss 9.4654875 Test Loss 12.43104332135689\n",
      "224 Train Loss 9.461502 Test Loss 12.425500747824309\n",
      "225 Train Loss 9.456912 Test Loss 12.41576624122009\n",
      "226 Train Loss 9.451022 Test Loss 12.403268133080138\n",
      "227 Train Loss 9.447081 Test Loss 12.393059752314898\n",
      "228 Train Loss 9.444234 Test Loss 12.38681821808021\n",
      "229 Train Loss 9.441271 Test Loss 12.388266902164116\n",
      "230 Train Loss 9.436878 Test Loss 12.384150239479942\n",
      "231 Train Loss 9.432257 Test Loss 12.378951665823886\n",
      "232 Train Loss 9.426662 Test Loss 12.374183059578433\n",
      "233 Train Loss 9.42228 Test Loss 12.371831494483942\n",
      "234 Train Loss 9.419516 Test Loss 12.367381794157113\n",
      "235 Train Loss 9.417097 Test Loss 12.370460015341585\n",
      "236 Train Loss 9.413814 Test Loss 12.365367064609897\n",
      "237 Train Loss 9.410555 Test Loss 12.36912445218856\n",
      "238 Train Loss 9.4075 Test Loss 12.368225984782345\n",
      "239 Train Loss 9.403602 Test Loss 12.364264484935154\n",
      "240 Train Loss 9.401211 Test Loss 12.361395432708651\n",
      "241 Train Loss 9.398984 Test Loss 12.356296426511019\n",
      "242 Train Loss 9.397294 Test Loss 12.348826624768249\n",
      "243 Train Loss 9.395218 Test Loss 12.347139560645807\n",
      "244 Train Loss 9.392251 Test Loss 12.337648113044564\n",
      "245 Train Loss 9.389715 Test Loss 12.335876249866432\n",
      "246 Train Loss 9.3869 Test Loss 12.328583918205986\n",
      "247 Train Loss 9.383427 Test Loss 12.328605983819694\n",
      "248 Train Loss 9.380514 Test Loss 12.327279494992531\n",
      "249 Train Loss 9.378694 Test Loss 12.324276070001524\n",
      "250 Train Loss 9.377283 Test Loss 12.325685474574453\n",
      "251 Train Loss 9.375548 Test Loss 12.32049103940729\n",
      "252 Train Loss 9.3729105 Test Loss 12.315564295855657\n",
      "253 Train Loss 9.369358 Test Loss 12.311733739834574\n",
      "254 Train Loss 9.366048 Test Loss 12.310114246042367\n",
      "255 Train Loss 9.363026 Test Loss 12.312996923863246\n",
      "256 Train Loss 9.36075 Test Loss 12.319518402703926\n",
      "257 Train Loss 9.358335 Test Loss 12.321460773434177\n",
      "258 Train Loss 9.35614 Test Loss 12.32108899861517\n",
      "259 Train Loss 9.3538685 Test Loss 12.318606881512489\n",
      "260 Train Loss 9.350684 Test Loss 12.310499860046507\n",
      "261 Train Loss 9.347616 Test Loss 12.308904726646093\n",
      "262 Train Loss 9.343934 Test Loss 12.301535307545068\n",
      "263 Train Loss 9.341236 Test Loss 12.299866978212295\n",
      "264 Train Loss 9.3399 Test Loss 12.301434450194451\n",
      "265 Train Loss 9.338774 Test Loss 12.29861142740821\n",
      "266 Train Loss 9.337121 Test Loss 12.297942791759569\n",
      "267 Train Loss 9.33577 Test Loss 12.293457926247086\n",
      "268 Train Loss 9.334043 Test Loss 12.29016393945788\n",
      "269 Train Loss 9.330181 Test Loss 12.286758430412938\n",
      "270 Train Loss 9.3228035 Test Loss 12.273418196779119\n",
      "271 Train Loss 9.316171 Test Loss 12.273185617648284\n",
      "272 Train Loss 9.310574 Test Loss 12.274077936480838\n",
      "273 Train Loss 9.309173 Test Loss 12.257314068367066\n",
      "274 Train Loss 9.306622 Test Loss 12.257621940925834\n",
      "275 Train Loss 9.304272 Test Loss 12.260071728910777\n",
      "276 Train Loss 9.302223 Test Loss 12.251711331867092\n",
      "277 Train Loss 9.298026 Test Loss 12.236228130289474\n",
      "278 Train Loss 9.293399 Test Loss 12.211917850443758\n",
      "279 Train Loss 9.288432 Test Loss 12.215874811060141\n",
      "280 Train Loss 9.283247 Test Loss 12.209663484768338\n",
      "281 Train Loss 9.277266 Test Loss 12.212665417881935\n",
      "282 Train Loss 9.271097 Test Loss 12.214912234932049\n",
      "283 Train Loss 9.267057 Test Loss 12.210326107543406\n",
      "284 Train Loss 9.264289 Test Loss 12.210997528733817\n",
      "285 Train Loss 9.259826 Test Loss 12.207266922692448\n",
      "286 Train Loss 9.2564945 Test Loss 12.198690517502413\n",
      "287 Train Loss 9.252837 Test Loss 12.190242376285022\n",
      "288 Train Loss 9.246556 Test Loss 12.17845143595358\n",
      "289 Train Loss 9.239699 Test Loss 12.17611442053309\n",
      "290 Train Loss 9.23393 Test Loss 12.176046097371298\n",
      "291 Train Loss 9.231966 Test Loss 12.168844515275975\n",
      "292 Train Loss 9.228895 Test Loss 12.187594357252507\n",
      "293 Train Loss 9.225926 Test Loss 12.177339079401442\n",
      "294 Train Loss 9.223156 Test Loss 12.168322167363359\n",
      "295 Train Loss 9.21935 Test Loss 12.165690663730851\n",
      "296 Train Loss 9.214702 Test Loss 12.153249100668322\n",
      "297 Train Loss 9.209514 Test Loss 12.164610883689186\n",
      "298 Train Loss 9.206306 Test Loss 12.166643923764468\n",
      "299 Train Loss 9.203954 Test Loss 12.166030828178506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 Train Loss 9.202213 Test Loss 12.166253485185083\n",
      "301 Train Loss 9.200333 Test Loss 12.163759116503137\n",
      "302 Train Loss 9.197249 Test Loss 12.160045675130807\n",
      "303 Train Loss 9.193637 Test Loss 12.157877140627118\n",
      "304 Train Loss 9.1905365 Test Loss 12.1608198157469\n",
      "305 Train Loss 9.18756 Test Loss 12.160086409112004\n",
      "306 Train Loss 9.184197 Test Loss 12.163806283261337\n",
      "307 Train Loss 9.18053 Test Loss 12.157755820617856\n",
      "308 Train Loss 9.177009 Test Loss 12.15838854059773\n",
      "309 Train Loss 9.17333 Test Loss 12.152364351957733\n",
      "310 Train Loss 9.169933 Test Loss 12.144333480329935\n",
      "311 Train Loss 9.167769 Test Loss 12.15034218985087\n",
      "312 Train Loss 9.164641 Test Loss 12.149856634771018\n",
      "313 Train Loss 9.159487 Test Loss 12.149001516061658\n",
      "314 Train Loss 9.155525 Test Loss 12.158392719713811\n",
      "315 Train Loss 9.150526 Test Loss 12.148687313388313\n",
      "316 Train Loss 9.147721 Test Loss 12.137293575835919\n",
      "317 Train Loss 9.146586 Test Loss 12.136261010669264\n",
      "318 Train Loss 9.1452675 Test Loss 12.133759034879962\n",
      "319 Train Loss 9.144097 Test Loss 12.132564599756959\n",
      "320 Train Loss 9.142496 Test Loss 12.130927546949271\n",
      "321 Train Loss 9.140465 Test Loss 12.125404446873413\n",
      "322 Train Loss 9.137153 Test Loss 12.118376403230407\n",
      "323 Train Loss 9.132786 Test Loss 12.110780011240038\n",
      "324 Train Loss 9.127205 Test Loss 12.102431625181817\n",
      "325 Train Loss 9.12323 Test Loss 12.101170866769685\n",
      "326 Train Loss 9.120607 Test Loss 12.105468122208089\n",
      "327 Train Loss 9.118349 Test Loss 12.101595798254852\n",
      "328 Train Loss 9.116375 Test Loss 12.102232339987927\n",
      "329 Train Loss 9.114085 Test Loss 12.095829120243547\n",
      "330 Train Loss 9.111892 Test Loss 12.094139312645119\n",
      "331 Train Loss 9.109947 Test Loss 12.088243810461732\n",
      "332 Train Loss 9.108265 Test Loss 12.086891600957617\n",
      "333 Train Loss 9.106119 Test Loss 12.088110641503702\n",
      "334 Train Loss 9.103406 Test Loss 12.087922241920564\n",
      "335 Train Loss 9.100945 Test Loss 12.086634098549217\n",
      "336 Train Loss 9.099076 Test Loss 12.086263261875674\n",
      "337 Train Loss 9.097697 Test Loss 12.082770178227852\n",
      "338 Train Loss 9.096319 Test Loss 12.080299589575938\n",
      "339 Train Loss 9.094362 Test Loss 12.077308329913034\n",
      "340 Train Loss 9.091958 Test Loss 12.072212409701576\n",
      "341 Train Loss 9.088055 Test Loss 12.065441274340294\n",
      "342 Train Loss 9.085772 Test Loss 12.063817539865733\n",
      "343 Train Loss 9.08388 Test Loss 12.051943040611144\n",
      "344 Train Loss 9.081849 Test Loss 12.05484779129642\n",
      "345 Train Loss 9.079458 Test Loss 12.05639864836795\n",
      "346 Train Loss 9.077261 Test Loss 12.05430031592002\n",
      "347 Train Loss 9.075423 Test Loss 12.05062254140135\n",
      "348 Train Loss 9.074083 Test Loss 12.048384787425093\n",
      "349 Train Loss 9.07184 Test Loss 12.046463635115272\n",
      "350 Train Loss 9.067464 Test Loss 12.038084621025103\n",
      "351 Train Loss 9.063183 Test Loss 12.033067895737277\n",
      "352 Train Loss 9.058013 Test Loss 12.026474557657458\n",
      "353 Train Loss 9.055325 Test Loss 12.016944073521843\n",
      "354 Train Loss 9.054083 Test Loss 12.018843779124273\n",
      "355 Train Loss 9.051912 Test Loss 12.018092820178849\n",
      "356 Train Loss 9.049831 Test Loss 12.01979210430373\n",
      "357 Train Loss 9.047682 Test Loss 12.018141101782314\n",
      "358 Train Loss 9.04523 Test Loss 12.018959310547814\n",
      "359 Train Loss 9.042963 Test Loss 12.018749396971684\n",
      "360 Train Loss 9.0409355 Test Loss 12.017234501262203\n",
      "361 Train Loss 9.039091 Test Loss 12.008401383841733\n",
      "362 Train Loss 9.03725 Test Loss 12.012887925912857\n",
      "363 Train Loss 9.035583 Test Loss 12.013381844610688\n",
      "364 Train Loss 9.033629 Test Loss 12.010778751209916\n",
      "365 Train Loss 9.0315895 Test Loss 12.009017543512988\n",
      "366 Train Loss 9.029283 Test Loss 12.009792604090014\n",
      "367 Train Loss 9.026529 Test Loss 12.008962332841278\n",
      "368 Train Loss 9.02392 Test Loss 12.007637629122032\n",
      "369 Train Loss 9.021507 Test Loss 12.005650130750317\n",
      "370 Train Loss 9.019014 Test Loss 12.001597609180402\n",
      "371 Train Loss 9.015294 Test Loss 11.993033678988148\n",
      "372 Train Loss 9.010554 Test Loss 11.988836488240715\n",
      "373 Train Loss 9.006219 Test Loss 11.976232723551199\n",
      "374 Train Loss 9.001702 Test Loss 11.979676017774603\n",
      "375 Train Loss 8.998274 Test Loss 11.972813828492315\n",
      "376 Train Loss 8.997134 Test Loss 11.973520682235646\n",
      "377 Train Loss 8.994272 Test Loss 11.968158709602132\n",
      "378 Train Loss 8.99329 Test Loss 11.962862984820577\n",
      "379 Train Loss 8.9917965 Test Loss 11.96015895358109\n",
      "380 Train Loss 8.989248 Test Loss 11.950376903042054\n",
      "381 Train Loss 8.98735 Test Loss 11.94818383174072\n",
      "382 Train Loss 8.984675 Test Loss 11.948738682907948\n",
      "383 Train Loss 8.981412 Test Loss 11.947243054132336\n",
      "384 Train Loss 8.978081 Test Loss 11.94404618475711\n",
      "385 Train Loss 8.974322 Test Loss 11.941849268149877\n",
      "386 Train Loss 8.969978 Test Loss 11.93865690233221\n",
      "387 Train Loss 8.967512 Test Loss 11.932868572570788\n",
      "388 Train Loss 8.965378 Test Loss 11.93785937216162\n",
      "389 Train Loss 8.963499 Test Loss 11.935484412099651\n",
      "390 Train Loss 8.961659 Test Loss 11.934870986868798\n",
      "391 Train Loss 8.959423 Test Loss 11.93069580945757\n",
      "392 Train Loss 8.95688 Test Loss 11.92768974610282\n",
      "393 Train Loss 8.953714 Test Loss 11.925818458955144\n",
      "394 Train Loss 8.949685 Test Loss 11.925680207425641\n",
      "395 Train Loss 8.945489 Test Loss 11.927982092922035\n",
      "396 Train Loss 8.941679 Test Loss 11.934713050689815\n",
      "397 Train Loss 8.937985 Test Loss 11.935588115969985\n",
      "398 Train Loss 8.934975 Test Loss 11.932155128256005\n",
      "399 Train Loss 8.932246 Test Loss 11.928044288535327\n",
      "400 Train Loss 8.929144 Test Loss 11.92388284619892\n",
      "401 Train Loss 8.925055 Test Loss 11.911731199068972\n",
      "402 Train Loss 8.921911 Test Loss 11.920809047969701\n",
      "403 Train Loss 8.916998 Test Loss 11.91311744022419\n",
      "404 Train Loss 8.912923 Test Loss 11.91399528150482\n",
      "405 Train Loss 8.909576 Test Loss 11.909181058256282\n",
      "406 Train Loss 8.90603 Test Loss 11.907603286243084\n",
      "407 Train Loss 8.903865 Test Loss 11.908521637490002\n",
      "408 Train Loss 8.901455 Test Loss 11.904516795834606\n",
      "409 Train Loss 8.898096 Test Loss 11.89790247943482\n",
      "410 Train Loss 8.895298 Test Loss 11.896196393206198\n",
      "411 Train Loss 8.892835 Test Loss 11.897897188346603\n",
      "412 Train Loss 8.890678 Test Loss 11.900710992926406\n",
      "413 Train Loss 8.888983 Test Loss 11.900178954700756\n",
      "414 Train Loss 8.887072 Test Loss 11.901828032857978\n",
      "415 Train Loss 8.885479 Test Loss 11.903337560207301\n",
      "416 Train Loss 8.8845625 Test Loss 11.900357424860761\n",
      "417 Train Loss 8.88372 Test Loss 11.900769803619756\n",
      "418 Train Loss 8.882505 Test Loss 11.901029722889517\n",
      "419 Train Loss 8.880603 Test Loss 11.904244466085855\n",
      "420 Train Loss 8.878342 Test Loss 11.900437819953865\n",
      "421 Train Loss 8.875736 Test Loss 11.89902929672509\n",
      "422 Train Loss 8.873628 Test Loss 11.898251341409443\n",
      "423 Train Loss 8.872245 Test Loss 11.892491922469999\n",
      "424 Train Loss 8.870241 Test Loss 11.886896855837733\n",
      "425 Train Loss 8.867929 Test Loss 11.882613331628761\n",
      "426 Train Loss 8.865146 Test Loss 11.877978517362514\n",
      "427 Train Loss 8.862154 Test Loss 11.878953807234138\n",
      "428 Train Loss 8.858698 Test Loss 11.878872658666767\n",
      "429 Train Loss 8.856025 Test Loss 11.877759568400869\n",
      "430 Train Loss 8.854454 Test Loss 11.877636250869477\n",
      "431 Train Loss 8.853174 Test Loss 11.875046260361916\n",
      "432 Train Loss 8.851996 Test Loss 11.87387708848759\n",
      "433 Train Loss 8.850841 Test Loss 11.871491330816852\n",
      "434 Train Loss 8.848724 Test Loss 11.870566108128184\n",
      "435 Train Loss 8.846206 Test Loss 11.86650857651522\n",
      "436 Train Loss 8.844008 Test Loss 11.866438351903673\n",
      "437 Train Loss 8.841211 Test Loss 11.864754947988592\n",
      "438 Train Loss 8.838284 Test Loss 11.862185747711374\n",
      "439 Train Loss 8.836057 Test Loss 11.86059723483406\n",
      "440 Train Loss 8.834207 Test Loss 11.859097143347707\n",
      "441 Train Loss 8.832638 Test Loss 11.858596007531425\n",
      "442 Train Loss 8.831128 Test Loss 11.856375598983082\n",
      "443 Train Loss 8.829946 Test Loss 11.85901287242054\n",
      "444 Train Loss 8.828921 Test Loss 11.856010553147893\n",
      "445 Train Loss 8.827459 Test Loss 11.854026224917822\n",
      "446 Train Loss 8.825816 Test Loss 11.852567309297267\n",
      "447 Train Loss 8.8232 Test Loss 11.848787763033648\n",
      "448 Train Loss 8.820976 Test Loss 11.845848742356532\n",
      "449 Train Loss 8.819416 Test Loss 11.844090493280646\n",
      "450 Train Loss 8.818207 Test Loss 11.842888226693498\n",
      "451 Train Loss 8.816659 Test Loss 11.844951422455184\n",
      "452 Train Loss 8.815468 Test Loss 11.842220075423965\n",
      "453 Train Loss 8.814472 Test Loss 11.846401865860443\n",
      "454 Train Loss 8.813703 Test Loss 11.84612874129866\n",
      "455 Train Loss 8.81302 Test Loss 11.84499214529078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456 Train Loss 8.812113 Test Loss 11.845291726207249\n",
      "457 Train Loss 8.810302 Test Loss 11.845274072389484\n",
      "458 Train Loss 8.807956 Test Loss 11.843051661819196\n",
      "459 Train Loss 8.8056345 Test Loss 11.840133981731391\n",
      "460 Train Loss 8.803664 Test Loss 11.840970931960804\n",
      "461 Train Loss 8.802772 Test Loss 11.838770266137121\n",
      "462 Train Loss 8.80193 Test Loss 11.836558073093954\n",
      "463 Train Loss 8.800756 Test Loss 11.833786331409092\n",
      "464 Train Loss 8.798947 Test Loss 11.831467265351266\n",
      "465 Train Loss 8.796739 Test Loss 11.828936053360826\n",
      "466 Train Loss 8.794729 Test Loss 11.827911321211594\n",
      "467 Train Loss 8.793248 Test Loss 11.829751437372423\n",
      "468 Train Loss 8.791854 Test Loss 11.829027351481288\n",
      "469 Train Loss 8.790713 Test Loss 11.831169816725199\n",
      "470 Train Loss 8.789423 Test Loss 11.828887384984753\n",
      "471 Train Loss 8.788265 Test Loss 11.826281511664506\n",
      "472 Train Loss 8.787364 Test Loss 11.823930671380603\n",
      "473 Train Loss 8.786347 Test Loss 11.82113306343018\n",
      "474 Train Loss 8.7846985 Test Loss 11.817593711174078\n",
      "475 Train Loss 8.782435 Test Loss 11.810395106022925\n",
      "476 Train Loss 8.78011 Test Loss 11.808966361616767\n",
      "477 Train Loss 8.777457 Test Loss 11.80022722356634\n",
      "478 Train Loss 8.775177 Test Loss 11.800736809622427\n",
      "479 Train Loss 8.773022 Test Loss 11.80073204358413\n",
      "480 Train Loss 8.771799 Test Loss 11.798506612587296\n",
      "481 Train Loss 8.770312 Test Loss 11.803117896787994\n",
      "482 Train Loss 8.76893 Test Loss 11.79971763249449\n",
      "483 Train Loss 8.767984 Test Loss 11.796304095140902\n",
      "484 Train Loss 8.767112 Test Loss 11.79513304185816\n",
      "485 Train Loss 8.765417 Test Loss 11.7928922544498\n",
      "486 Train Loss 8.763327 Test Loss 11.79106283173288\n",
      "487 Train Loss 8.761271 Test Loss 11.7876735296871\n",
      "488 Train Loss 8.759366 Test Loss 11.785313328554567\n",
      "489 Train Loss 8.757785 Test Loss 11.782757099346533\n",
      "490 Train Loss 8.755929 Test Loss 11.779772663196143\n",
      "491 Train Loss 8.753588 Test Loss 11.778773826658322\n",
      "492 Train Loss 8.751043 Test Loss 11.775852398035676\n",
      "493 Train Loss 8.749244 Test Loss 11.77407805211617\n",
      "494 Train Loss 8.747757 Test Loss 11.776274572774405\n",
      "495 Train Loss 8.746312 Test Loss 11.77490929072402\n",
      "496 Train Loss 8.744925 Test Loss 11.77446198461825\n",
      "497 Train Loss 8.743227 Test Loss 11.77340645879677\n",
      "498 Train Loss 8.740845 Test Loss 11.768643606325291\n",
      "499 Train Loss 8.738878 Test Loss 11.765997947258127\n",
      "500 Train Loss 8.735962 Test Loss 11.765218324968522\n",
      "501 Train Loss 8.73325 Test Loss 11.762051499487328\n",
      "502 Train Loss 8.731394 Test Loss 11.763322186943688\n",
      "503 Train Loss 8.72931 Test Loss 11.76247295482897\n",
      "504 Train Loss 8.726575 Test Loss 11.761223268050077\n",
      "505 Train Loss 8.725307 Test Loss 11.758118297934205\n",
      "506 Train Loss 8.724308 Test Loss 11.76018140787591\n",
      "507 Train Loss 8.723505 Test Loss 11.758857564287043\n",
      "508 Train Loss 8.722437 Test Loss 11.756984115520417\n",
      "509 Train Loss 8.721323 Test Loss 11.756694126625941\n",
      "510 Train Loss 8.719908 Test Loss 11.75453620690211\n",
      "511 Train Loss 8.717877 Test Loss 11.752006674861306\n",
      "512 Train Loss 8.715861 Test Loss 11.748256374908788\n",
      "513 Train Loss 8.713811 Test Loss 11.742775856379767\n",
      "514 Train Loss 8.712169 Test Loss 11.742496112776607\n",
      "515 Train Loss 8.710523 Test Loss 11.74121635004003\n",
      "516 Train Loss 8.709257 Test Loss 11.741158214530497\n",
      "517 Train Loss 8.707712 Test Loss 11.74079582206452\n",
      "518 Train Loss 8.706514 Test Loss 11.738188920040242\n",
      "519 Train Loss 8.705265 Test Loss 11.736018197144041\n",
      "520 Train Loss 8.703545 Test Loss 11.734447240288118\n",
      "521 Train Loss 8.701366 Test Loss 11.72731478357454\n",
      "522 Train Loss 8.6998415 Test Loss 11.721645724519917\n",
      "523 Train Loss 8.696247 Test Loss 11.72023490938434\n",
      "524 Train Loss 8.694445 Test Loss 11.71942380832509\n",
      "525 Train Loss 8.693149 Test Loss 11.715495094899884\n",
      "526 Train Loss 8.692123 Test Loss 11.714016239397091\n",
      "527 Train Loss 8.690833 Test Loss 11.712629522362167\n",
      "528 Train Loss 8.689194 Test Loss 11.710481259819312\n",
      "529 Train Loss 8.687672 Test Loss 11.709274409066547\n",
      "530 Train Loss 8.68664 Test Loss 11.704946890214963\n",
      "531 Train Loss 8.685587 Test Loss 11.704681853645411\n",
      "532 Train Loss 8.684314 Test Loss 11.703313553508702\n",
      "533 Train Loss 8.682262 Test Loss 11.6999207746576\n",
      "534 Train Loss 8.680493 Test Loss 11.698356505865021\n",
      "535 Train Loss 8.679215 Test Loss 11.69595895903657\n",
      "536 Train Loss 8.678038 Test Loss 11.69693660490869\n",
      "537 Train Loss 8.6762295 Test Loss 11.695090460040799\n",
      "538 Train Loss 8.674981 Test Loss 11.693607312452462\n",
      "539 Train Loss 8.67372 Test Loss 11.689213044231517\n",
      "540 Train Loss 8.672286 Test Loss 11.684728522291865\n",
      "541 Train Loss 8.670859 Test Loss 11.681358990010033\n",
      "542 Train Loss 8.669419 Test Loss 11.679556148106755\n",
      "543 Train Loss 8.667995 Test Loss 11.67892217537608\n",
      "544 Train Loss 8.666599 Test Loss 11.679115050709244\n",
      "545 Train Loss 8.664242 Test Loss 11.676623682578313\n",
      "546 Train Loss 8.661449 Test Loss 11.673245193754997\n",
      "547 Train Loss 8.6592045 Test Loss 11.66802866109868\n",
      "548 Train Loss 8.658214 Test Loss 11.66341845785005\n",
      "549 Train Loss 8.657207 Test Loss 11.66051960336622\n",
      "550 Train Loss 8.656203 Test Loss 11.658000230421122\n",
      "551 Train Loss 8.654924 Test Loss 11.657212158078691\n",
      "552 Train Loss 8.653137 Test Loss 11.654876276044636\n",
      "553 Train Loss 8.651475 Test Loss 11.65361145104248\n",
      "554 Train Loss 8.65028 Test Loss 11.653384342899251\n",
      "555 Train Loss 8.649401 Test Loss 11.652197436941565\n",
      "556 Train Loss 8.648716 Test Loss 11.651181363648893\n",
      "557 Train Loss 8.648029 Test Loss 11.65032588097779\n",
      "558 Train Loss 8.647101 Test Loss 11.647236538653186\n",
      "559 Train Loss 8.645959 Test Loss 11.645252148510735\n",
      "560 Train Loss 8.644705 Test Loss 11.641548597099101\n",
      "561 Train Loss 8.643046 Test Loss 11.6403530617149\n",
      "562 Train Loss 8.6405735 Test Loss 11.63588895135926\n",
      "563 Train Loss 8.637304 Test Loss 11.631056504030068\n",
      "564 Train Loss 8.633755 Test Loss 11.626429238745574\n",
      "565 Train Loss 8.630828 Test Loss 11.619675226873788\n",
      "566 Train Loss 8.628787 Test Loss 11.61958318382121\n",
      "567 Train Loss 8.627243 Test Loss 11.618199260858354\n",
      "568 Train Loss 8.625629 Test Loss 11.61813500061241\n",
      "569 Train Loss 8.624204 Test Loss 11.615077083192885\n",
      "570 Train Loss 8.622857 Test Loss 11.612506224156506\n",
      "571 Train Loss 8.621664 Test Loss 11.611276855640586\n",
      "572 Train Loss 8.620371 Test Loss 11.60589039998448\n",
      "573 Train Loss 8.619144 Test Loss 11.606012093828781\n",
      "574 Train Loss 8.618118 Test Loss 11.605393380371101\n",
      "575 Train Loss 8.616765 Test Loss 11.605151142689081\n",
      "576 Train Loss 8.6155205 Test Loss 11.604602534609274\n",
      "577 Train Loss 8.613624 Test Loss 11.604442445909594\n",
      "578 Train Loss 8.611459 Test Loss 11.602546214253577\n",
      "579 Train Loss 8.609999 Test Loss 11.600374114350068\n",
      "580 Train Loss 8.608926 Test Loss 11.597932853391177\n",
      "581 Train Loss 8.608092 Test Loss 11.596177140575868\n",
      "582 Train Loss 8.606025 Test Loss 11.594010088156928\n",
      "583 Train Loss 8.602746 Test Loss 11.59014863304463\n",
      "584 Train Loss 8.599644 Test Loss 11.590880279054854\n",
      "585 Train Loss 8.596225 Test Loss 11.587448151905042\n",
      "586 Train Loss 8.593295 Test Loss 11.586467244015559\n",
      "587 Train Loss 8.590026 Test Loss 11.576226672813474\n",
      "588 Train Loss 8.587653 Test Loss 11.568522540090658\n",
      "589 Train Loss 8.5864725 Test Loss 11.564634431719622\n",
      "590 Train Loss 8.58568 Test Loss 11.564040095036354\n",
      "591 Train Loss 8.585082 Test Loss 11.565148958842718\n",
      "592 Train Loss 8.584497 Test Loss 11.56678574851328\n",
      "593 Train Loss 8.583926 Test Loss 11.565456607980503\n",
      "594 Train Loss 8.582502 Test Loss 11.56467264834526\n",
      "595 Train Loss 8.581012 Test Loss 11.561090195567068\n",
      "596 Train Loss 8.579578 Test Loss 11.560095582484847\n",
      "597 Train Loss 8.578129 Test Loss 11.55852030570526\n",
      "598 Train Loss 8.576619 Test Loss 11.56110262850507\n",
      "599 Train Loss 8.574858 Test Loss 11.560901794949869\n",
      "600 Train Loss 8.573178 Test Loss 11.560918219383787\n",
      "601 Train Loss 8.569851 Test Loss 11.553803111763598\n",
      "602 Train Loss 8.566736 Test Loss 11.54848408195515\n",
      "603 Train Loss 8.564571 Test Loss 11.543629864029192\n",
      "604 Train Loss 8.562853 Test Loss 11.54327695784883\n",
      "605 Train Loss 8.561415 Test Loss 11.542098886700852\n",
      "606 Train Loss 8.560032 Test Loss 11.543216434499248\n",
      "607 Train Loss 8.559036 Test Loss 11.543857148371506\n",
      "608 Train Loss 8.558332 Test Loss 11.544136268807568\n",
      "609 Train Loss 8.55709 Test Loss 11.542412352680367\n",
      "610 Train Loss 8.555593 Test Loss 11.540217803072354\n",
      "611 Train Loss 8.554795 Test Loss 11.539425149336655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612 Train Loss 8.55401 Test Loss 11.539216604492596\n",
      "613 Train Loss 8.553268 Test Loss 11.540559313716322\n",
      "614 Train Loss 8.552425 Test Loss 11.542318969831479\n",
      "615 Train Loss 8.551632 Test Loss 11.543507852619923\n",
      "616 Train Loss 8.551079 Test Loss 11.544546472384729\n",
      "617 Train Loss 8.550542 Test Loss 11.544185083894646\n",
      "618 Train Loss 8.549882 Test Loss 11.542632700300457\n",
      "619 Train Loss 8.549029 Test Loss 11.541391497623618\n",
      "620 Train Loss 8.547797 Test Loss 11.540646648352785\n",
      "621 Train Loss 8.546483 Test Loss 11.540826105332348\n",
      "622 Train Loss 8.545293 Test Loss 11.542206982018307\n",
      "623 Train Loss 8.543288 Test Loss 11.543961294373318\n",
      "624 Train Loss 8.542027 Test Loss 11.545175076534509\n",
      "625 Train Loss 8.541339 Test Loss 11.544338560957199\n",
      "626 Train Loss 8.540673 Test Loss 11.544169429785047\n",
      "627 Train Loss 8.540071 Test Loss 11.542654462743617\n",
      "628 Train Loss 8.539241 Test Loss 11.541440171890988\n",
      "629 Train Loss 8.537896 Test Loss 11.539462214144894\n",
      "630 Train Loss 8.536117 Test Loss 11.53711901631521\n",
      "631 Train Loss 8.534596 Test Loss 11.535125137622716\n",
      "632 Train Loss 8.53252 Test Loss 11.533773261982063\n",
      "633 Train Loss 8.531403 Test Loss 11.535025372645134\n",
      "634 Train Loss 8.530484 Test Loss 11.53407947486801\n",
      "635 Train Loss 8.529859 Test Loss 11.536157491490355\n",
      "636 Train Loss 8.529261 Test Loss 11.538698773889285\n",
      "637 Train Loss 8.528208 Test Loss 11.537837611235398\n",
      "638 Train Loss 8.527423 Test Loss 11.537316867845256\n",
      "639 Train Loss 8.526975 Test Loss 11.536710783263635\n",
      "640 Train Loss 8.526539 Test Loss 11.537418106798533\n",
      "641 Train Loss 8.526095 Test Loss 11.53813781356448\n",
      "642 Train Loss 8.525743 Test Loss 11.539001714602852\n",
      "643 Train Loss 8.525417 Test Loss 11.539161169229972\n",
      "644 Train Loss 8.524281 Test Loss 11.53822562958824\n",
      "645 Train Loss 8.5231495 Test Loss 11.536351014043484\n",
      "646 Train Loss 8.522319 Test Loss 11.53538980499242\n",
      "647 Train Loss 8.520989 Test Loss 11.53399448102565\n",
      "648 Train Loss 8.519698 Test Loss 11.533025191897837\n",
      "649 Train Loss 8.518763 Test Loss 11.530444760002267\n",
      "650 Train Loss 8.517474 Test Loss 11.531706854811597\n",
      "651 Train Loss 8.516937 Test Loss 11.532591457219748\n",
      "652 Train Loss 8.51626 Test Loss 11.534265384262177\n",
      "653 Train Loss 8.51561 Test Loss 11.533340006581172\n",
      "654 Train Loss 8.514834 Test Loss 11.531928218186394\n",
      "655 Train Loss 8.513984 Test Loss 11.530875910715427\n",
      "656 Train Loss 8.513089 Test Loss 11.530089289634411\n",
      "657 Train Loss 8.512403 Test Loss 11.530636527618963\n",
      "658 Train Loss 8.511941 Test Loss 11.531296529979194\n",
      "659 Train Loss 8.511604 Test Loss 11.532162599428597\n",
      "660 Train Loss 8.511273 Test Loss 11.532717315671725\n",
      "661 Train Loss 8.510884 Test Loss 11.533197775446393\n",
      "662 Train Loss 8.510548 Test Loss 11.533368822980044\n",
      "663 Train Loss 8.510227 Test Loss 11.533806429346617\n",
      "664 Train Loss 8.510001 Test Loss 11.53425228339612\n",
      "665 Train Loss 8.509672 Test Loss 11.535127721471373\n",
      "666 Train Loss 8.509217 Test Loss 11.536687077142995\n",
      "667 Train Loss 8.508637 Test Loss 11.53839440796395\n",
      "668 Train Loss 8.507651 Test Loss 11.539631286561736\n",
      "669 Train Loss 8.506665 Test Loss 11.538539990123557\n",
      "670 Train Loss 8.505676 Test Loss 11.535114268186177\n",
      "671 Train Loss 8.504921 Test Loss 11.534043985963654\n",
      "672 Train Loss 8.504296 Test Loss 11.53224893828768\n",
      "673 Train Loss 8.503923 Test Loss 11.532198059429343\n",
      "674 Train Loss 8.503593 Test Loss 11.531781412313302\n",
      "675 Train Loss 8.503336 Test Loss 11.532427422385917\n",
      "676 Train Loss 8.504609 Test Loss 11.531023148065906\n",
      "677 Train Loss 8.503244 Test Loss 11.53213068505466\n",
      "678 Train Loss 8.503055 Test Loss 11.532238514121378\n",
      "679 Train Loss 8.502879 Test Loss 11.53238523013633\n",
      "680 Train Loss 8.502792 Test Loss 11.532446431660192\n",
      "681 Train Loss 8.5027 Test Loss 11.532700518184113\n",
      "682 Train Loss 8.502567 Test Loss 11.533144879664132\n",
      "683 Train Loss 8.50241 Test Loss 11.533998885517722\n",
      "684 Train Loss 8.501808 Test Loss 11.53478043873193\n",
      "685 Train Loss 8.5012 Test Loss 11.535624411286328\n",
      "686 Train Loss 8.500692 Test Loss 11.535248147521248\n",
      "687 Train Loss 8.500356 Test Loss 11.534765206180674\n",
      "688 Train Loss 8.500022 Test Loss 11.534005221287503\n",
      "689 Train Loss 8.499429 Test Loss 11.532430307906798\n",
      "690 Train Loss 8.498901 Test Loss 11.530977250471159\n",
      "691 Train Loss 8.498295 Test Loss 11.530298077184089\n",
      "692 Train Loss 8.497774 Test Loss 11.53014289051814\n",
      "693 Train Loss 8.497427 Test Loss 11.53029561796497\n",
      "694 Train Loss 8.497025 Test Loss 11.530737131199626\n",
      "695 Train Loss 8.496459 Test Loss 11.531018818441858\n",
      "696 Train Loss 8.496001 Test Loss 11.530128578900577\n",
      "697 Train Loss 8.495437 Test Loss 11.530992216337372\n",
      "698 Train Loss 8.494972 Test Loss 11.531268184590637\n",
      "699 Train Loss 8.494548 Test Loss 11.531090897110687\n",
      "700 Train Loss 8.493905 Test Loss 11.53089195782783\n",
      "701 Train Loss 8.49336 Test Loss 11.531709879216244\n",
      "702 Train Loss 8.492738 Test Loss 11.533111087244198\n",
      "703 Train Loss 8.492499 Test Loss 11.533764486471343\n",
      "704 Train Loss 8.491941 Test Loss 11.534808554559028\n",
      "705 Train Loss 8.491524 Test Loss 11.535441904558095\n",
      "706 Train Loss 8.491222 Test Loss 11.535417735322907\n",
      "707 Train Loss 8.492101 Test Loss 11.534069465121629\n",
      "708 Train Loss 8.490945 Test Loss 11.534964472189777\n",
      "709 Train Loss 8.490559 Test Loss 11.535347570188462\n",
      "710 Train Loss 8.490109 Test Loss 11.53569342849907\n",
      "711 Train Loss 8.48977 Test Loss 11.535141475908267\n",
      "712 Train Loss 8.489287 Test Loss 11.534103206242703\n",
      "713 Train Loss 8.488933 Test Loss 11.533358705860419\n",
      "714 Train Loss 8.488636 Test Loss 11.5325607468877\n",
      "715 Train Loss 8.488462 Test Loss 11.53164431330614\n",
      "716 Train Loss 8.488308 Test Loss 11.531118217851208\n",
      "717 Train Loss 8.488118 Test Loss 11.530711977914313\n",
      "718 Train Loss 8.487833 Test Loss 11.530186349449636\n",
      "719 Train Loss 8.487452 Test Loss 11.530622934233797\n",
      "720 Train Loss 8.487082 Test Loss 11.530545128166183\n",
      "721 Train Loss 8.486774 Test Loss 11.530800669514225\n",
      "722 Train Loss 8.486522 Test Loss 11.530939995149463\n",
      "723 Train Loss 8.486317 Test Loss 11.530667438882897\n",
      "724 Train Loss 8.486074 Test Loss 11.530037174357567\n",
      "725 Train Loss 8.485751 Test Loss 11.529604110018617\n",
      "726 Train Loss 8.485331 Test Loss 11.528772321603036\n",
      "727 Train Loss 8.4853325 Test Loss 11.525918565388531\n",
      "728 Train Loss 8.485126 Test Loss 11.527342194371192\n",
      "729 Train Loss 8.484695 Test Loss 11.526584364374123\n",
      "730 Train Loss 8.484046 Test Loss 11.526757253891326\n",
      "731 Train Loss 8.483538 Test Loss 11.526927535529317\n",
      "732 Train Loss 8.483267 Test Loss 11.526847869688117\n",
      "733 Train Loss 8.482933 Test Loss 11.52778054301886\n",
      "734 Train Loss 8.482529 Test Loss 11.526688916979403\n",
      "735 Train Loss 8.482152 Test Loss 11.525888319114081\n",
      "736 Train Loss 8.481718 Test Loss 11.525324362445994\n",
      "737 Train Loss 8.481218 Test Loss 11.52460508168694\n",
      "738 Train Loss 8.480443 Test Loss 11.524170515358433\n",
      "739 Train Loss 8.479903 Test Loss 11.523989311277278\n",
      "740 Train Loss 8.479541 Test Loss 11.523798570409628\n",
      "741 Train Loss 8.479298 Test Loss 11.523570015235345\n",
      "742 Train Loss 8.479142 Test Loss 11.523370614000198\n",
      "743 Train Loss 8.479006 Test Loss 11.523211865222605\n",
      "744 Train Loss 8.478858 Test Loss 11.52306239541357\n",
      "745 Train Loss 8.478632 Test Loss 11.523309972433813\n",
      "746 Train Loss 8.47944 Test Loss 11.518629146231904\n",
      "747 Train Loss 8.478472 Test Loss 11.521952249554031\n",
      "748 Train Loss 8.478176 Test Loss 11.521983291829649\n",
      "749 Train Loss 8.477904 Test Loss 11.521671687814491\n",
      "750 Train Loss 8.477697 Test Loss 11.521221551042823\n",
      "751 Train Loss 8.477373 Test Loss 11.520961927841256\n",
      "752 Train Loss 8.47665 Test Loss 11.521467988722447\n",
      "753 Train Loss 8.475804 Test Loss 11.522620260471818\n",
      "754 Train Loss 8.475655 Test Loss 11.52424754790663\n",
      "755 Train Loss 8.474933 Test Loss 11.524661095850057\n",
      "756 Train Loss 8.474609 Test Loss 11.524702398641212\n",
      "757 Train Loss 8.474299 Test Loss 11.525865741326243\n",
      "758 Train Loss 8.473833 Test Loss 11.525391488542475\n",
      "759 Train Loss 8.473407 Test Loss 11.524656497099134\n",
      "760 Train Loss 8.472893 Test Loss 11.523762286971884\n",
      "761 Train Loss 8.472693 Test Loss 11.523280196173262\n",
      "762 Train Loss 8.472503 Test Loss 11.523088570163385\n",
      "763 Train Loss 8.47229 Test Loss 11.523183205040903\n",
      "764 Train Loss 8.472093 Test Loss 11.523456466207165\n",
      "765 Train Loss 8.472704 Test Loss 11.520895663766748\n",
      "766 Train Loss 8.472009 Test Loss 11.522788027431064\n",
      "767 Train Loss 8.471626 Test Loss 11.523566779421158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 Train Loss 8.471382 Test Loss 11.52337426089408\n",
      "769 Train Loss 8.470987 Test Loss 11.522325397800843\n",
      "770 Train Loss 8.470726 Test Loss 11.52164139524957\n",
      "771 Train Loss 8.470319 Test Loss 11.52042260678724\n",
      "772 Train Loss 8.47061 Test Loss 11.51993890925668\n",
      "773 Train Loss 8.4702015 Test Loss 11.52025049558683\n",
      "774 Train Loss 8.469638 Test Loss 11.519458939566771\n",
      "775 Train Loss 8.469294 Test Loss 11.519505237730232\n",
      "776 Train Loss 8.468688 Test Loss 11.519009804202769\n",
      "777 Train Loss 8.468272 Test Loss 11.51798884427677\n",
      "778 Train Loss 8.467666 Test Loss 11.516078165669022\n",
      "779 Train Loss 8.467611 Test Loss 11.514295476138706\n",
      "780 Train Loss 8.466977 Test Loss 11.51389418616259\n",
      "781 Train Loss 8.466735 Test Loss 11.513976203004447\n",
      "782 Train Loss 8.466541 Test Loss 11.514108188640162\n",
      "783 Train Loss 8.466386 Test Loss 11.514219692431709\n",
      "784 Train Loss 8.466163 Test Loss 11.514399009986487\n",
      "785 Train Loss 8.465956 Test Loss 11.514946861523377\n",
      "786 Train Loss 8.469512 Test Loss 11.514352247462801\n",
      "787 Train Loss 8.465857 Test Loss 11.514851875623377\n",
      "788 Train Loss 8.465568 Test Loss 11.515579612420636\n",
      "789 Train Loss 8.465421 Test Loss 11.515732483398468\n",
      "790 Train Loss 8.46523 Test Loss 11.515996139235302\n",
      "791 Train Loss 8.464855 Test Loss 11.516177901580093\n",
      "792 Train Loss 8.464433 Test Loss 11.516274618210252\n",
      "793 Train Loss 8.463832 Test Loss 11.51579631715019\n",
      "794 Train Loss 8.463393 Test Loss 11.51608752045534\n",
      "795 Train Loss 8.463047 Test Loss 11.515283792281823\n",
      "796 Train Loss 8.474593 Test Loss 11.50321385640807\n",
      "797 Train Loss 8.462883 Test Loss 11.513930323051737\n",
      "798 Train Loss 8.462604 Test Loss 11.513758056787855\n",
      "799 Train Loss 8.462247 Test Loss 11.5137471085635\n",
      "800 Train Loss 8.46193 Test Loss 11.51347647482572\n",
      "801 Train Loss 8.461446 Test Loss 11.512576053410296\n",
      "802 Train Loss 8.460999 Test Loss 11.511106210028753\n",
      "803 Train Loss 8.460714 Test Loss 11.510211356313969\n",
      "804 Train Loss 8.4603615 Test Loss 11.509006292062963\n",
      "805 Train Loss 8.4601555 Test Loss 11.508681474880582\n",
      "806 Train Loss 8.459919 Test Loss 11.508628970676087\n",
      "807 Train Loss 8.459686 Test Loss 11.509062830625236\n",
      "808 Train Loss 8.459403 Test Loss 11.50916541368653\n",
      "809 Train Loss 8.459126 Test Loss 11.509250494020229\n",
      "810 Train Loss 8.458878 Test Loss 11.508874147863839\n",
      "811 Train Loss 8.458794 Test Loss 11.50850789534031\n",
      "812 Train Loss 8.458661 Test Loss 11.507777515803163\n",
      "813 Train Loss 8.458493 Test Loss 11.506867501139165\n",
      "814 Train Loss 8.4581785 Test Loss 11.505995892146617\n",
      "815 Train Loss 8.46194 Test Loss 11.499156361454416\n",
      "816 Train Loss 8.458052 Test Loss 11.504949454516721\n",
      "817 Train Loss 8.457722 Test Loss 11.504711849542016\n",
      "818 Train Loss 8.457418 Test Loss 11.504788920195017\n",
      "819 Train Loss 8.457191 Test Loss 11.505030207333464\n",
      "820 Train Loss 8.456945 Test Loss 11.50525028529512\n",
      "821 Train Loss 8.456767 Test Loss 11.50542265193422\n",
      "822 Train Loss 8.456602 Test Loss 11.505366306928831\n",
      "823 Train Loss 8.456466 Test Loss 11.505282714233227\n",
      "824 Train Loss 8.45624 Test Loss 11.50484794570353\n",
      "825 Train Loss 8.456399 Test Loss 11.505362228668638\n",
      "826 Train Loss 8.456096 Test Loss 11.505053289966977\n",
      "827 Train Loss 8.455849 Test Loss 11.504764598777513\n",
      "828 Train Loss 8.455609 Test Loss 11.504344523294133\n",
      "829 Train Loss 8.455339 Test Loss 11.503985178654998\n",
      "830 Train Loss 8.455042 Test Loss 11.503525971682807\n",
      "831 Train Loss 8.483621 Test Loss 11.490334172216656\n",
      "832 Train Loss 8.454947 Test Loss 11.50275822380201\n",
      "833 Train Loss 8.454663 Test Loss 11.502619209836611\n",
      "834 Train Loss 8.454472 Test Loss 11.50225949716255\n",
      "835 Train Loss 8.454307 Test Loss 11.502142139508074\n",
      "836 Train Loss 8.454133 Test Loss 11.50191128589149\n",
      "837 Train Loss 8.454004 Test Loss 11.50171179208947\n",
      "838 Train Loss 8.453884 Test Loss 11.50155480762528\n",
      "839 Train Loss 8.453765 Test Loss 11.500967852281379\n",
      "840 Train Loss 8.453662 Test Loss 11.500805497777572\n",
      "841 Train Loss 8.453463 Test Loss 11.500432640506853\n",
      "842 Train Loss 8.45326 Test Loss 11.500668024158033\n",
      "843 Train Loss 8.452698 Test Loss 11.500779943681543\n",
      "844 Train Loss 8.452417 Test Loss 11.501640433751648\n",
      "845 Train Loss 8.498598 Test Loss 11.497241455093755\n",
      "846 Train Loss 8.452311 Test Loss 11.501387895035712\n",
      "847 Train Loss 8.452159 Test Loss 11.501567255771699\n",
      "848 Train Loss 8.451953 Test Loss 11.501759829714054\n",
      "849 Train Loss 8.451658 Test Loss 11.501819641602186\n",
      "850 Train Loss 8.451318 Test Loss 11.50192625852377\n",
      "851 Train Loss 8.451179 Test Loss 11.501578603173465\n",
      "852 Train Loss 8.4509115 Test Loss 11.500176967247981\n",
      "853 Train Loss 8.450715 Test Loss 11.499386666852153\n",
      "854 Train Loss 8.450509 Test Loss 11.498041838020947\n",
      "855 Train Loss 8.450359 Test Loss 11.497468313593485\n",
      "856 Train Loss 8.45018 Test Loss 11.496901703456144\n",
      "857 Train Loss 8.449976 Test Loss 11.49736463292789\n",
      "858 Train Loss 8.449736 Test Loss 11.498124879885099\n",
      "859 Train Loss 8.449598 Test Loss 11.499041459683758\n",
      "860 Train Loss 8.4493475 Test Loss 11.500147489395006\n",
      "861 Train Loss 8.449074 Test Loss 11.50139391476333\n",
      "862 Train Loss 8.4488735 Test Loss 11.50170564381385\n",
      "863 Train Loss 8.448678 Test Loss 11.501215663678613\n",
      "864 Train Loss 8.448526 Test Loss 11.500498123750782\n",
      "865 Train Loss 8.448153 Test Loss 11.498991830623662\n",
      "866 Train Loss 8.447747 Test Loss 11.497493955908675\n",
      "867 Train Loss 8.44807 Test Loss 11.494528519438207\n",
      "868 Train Loss 8.4475975 Test Loss 11.496415590951953\n",
      "869 Train Loss 8.447193 Test Loss 11.496118130762675\n",
      "870 Train Loss 8.447236 Test Loss 11.494326026555406\n",
      "871 Train Loss 8.447014 Test Loss 11.495267756396709\n",
      "872 Train Loss 8.446642 Test Loss 11.494711701969422\n",
      "873 Train Loss 8.446306 Test Loss 11.496008052967731\n",
      "874 Train Loss 8.445989 Test Loss 11.496348081565916\n",
      "875 Train Loss 8.445551 Test Loss 11.495955063983487\n",
      "876 Train Loss 8.445155 Test Loss 11.495000605928151\n",
      "877 Train Loss 8.444941 Test Loss 11.494191891809123\n",
      "878 Train Loss 8.444756 Test Loss 11.493580129506489\n",
      "879 Train Loss 8.444498 Test Loss 11.493259587883514\n",
      "880 Train Loss 8.444262 Test Loss 11.493405164173284\n",
      "881 Train Loss 8.444076 Test Loss 11.49392229990234\n",
      "882 Train Loss 8.443944 Test Loss 11.493975811969515\n",
      "883 Train Loss 8.443773 Test Loss 11.49391413435483\n",
      "884 Train Loss 8.443549 Test Loss 11.49336998844373\n",
      "885 Train Loss 8.443269 Test Loss 11.493651976581994\n",
      "886 Train Loss 8.443048 Test Loss 11.490535636006157\n",
      "887 Train Loss 8.442275 Test Loss 11.490523184026667\n",
      "888 Train Loss 8.441925 Test Loss 11.491526092957082\n",
      "889 Train Loss 8.441674 Test Loss 11.491837199040992\n",
      "890 Train Loss 8.441475 Test Loss 11.491473210754034\n",
      "891 Train Loss 8.4412985 Test Loss 11.4911169102996\n",
      "892 Train Loss 8.441144 Test Loss 11.490690347608124\n",
      "893 Train Loss 8.441005 Test Loss 11.490327737111492\n",
      "894 Train Loss 8.4408455 Test Loss 11.49029131161539\n",
      "895 Train Loss 8.440694 Test Loss 11.490231043664435\n",
      "896 Train Loss 8.440372 Test Loss 11.49058961484009\n",
      "897 Train Loss 8.439834 Test Loss 11.49054761317397\n",
      "898 Train Loss 8.465413 Test Loss 11.486194125579551\n",
      "899 Train Loss 8.43977 Test Loss 11.49035781717938\n",
      "900 Train Loss 8.439503 Test Loss 11.490229736624087\n",
      "901 Train Loss 8.439186 Test Loss 11.48915149336812\n",
      "902 Train Loss 8.438992 Test Loss 11.48845453622618\n",
      "903 Train Loss 8.438647 Test Loss 11.487981115785404\n",
      "904 Train Loss 8.438307 Test Loss 11.488145664817313\n",
      "905 Train Loss 8.438095 Test Loss 11.48856909751328\n",
      "906 Train Loss 8.437848 Test Loss 11.489013615348505\n",
      "907 Train Loss 8.4375925 Test Loss 11.489778126616338\n",
      "908 Train Loss 8.437312 Test Loss 11.489436747394809\n",
      "909 Train Loss 8.436948 Test Loss 11.489495847542592\n",
      "910 Train Loss 8.436551 Test Loss 11.488196176611403\n",
      "911 Train Loss 8.436104 Test Loss 11.487294026587888\n",
      "912 Train Loss 8.435759 Test Loss 11.486596938637254\n",
      "913 Train Loss 8.4353485 Test Loss 11.48553218538255\n",
      "914 Train Loss 8.434888 Test Loss 11.484961334081431\n",
      "915 Train Loss 8.434541 Test Loss 11.484899589333885\n",
      "916 Train Loss 8.434125 Test Loss 11.484156988960429\n",
      "917 Train Loss 8.433858 Test Loss 11.4840284965388\n",
      "918 Train Loss 8.4335375 Test Loss 11.482959573983283\n",
      "919 Train Loss 8.433752 Test Loss 11.483430831879113\n",
      "920 Train Loss 8.433392 Test Loss 11.483138484289872\n",
      "921 Train Loss 8.433132 Test Loss 11.484308527334944\n",
      "922 Train Loss 8.432349 Test Loss 11.484955297101358\n",
      "923 Train Loss 8.431965 Test Loss 11.48559563689246\n",
      "924 Train Loss 8.431239 Test Loss 11.486633898605175\n",
      "925 Train Loss 8.430903 Test Loss 11.486771312796254\n",
      "926 Train Loss 8.430596 Test Loss 11.48612901654667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927 Train Loss 8.430356 Test Loss 11.484736611269252\n",
      "928 Train Loss 8.430101 Test Loss 11.483095859646959\n",
      "929 Train Loss 8.429903 Test Loss 11.481575585245642\n",
      "930 Train Loss 8.430022 Test Loss 11.481231761584313\n",
      "931 Train Loss 8.429784 Test Loss 11.481426512280336\n",
      "932 Train Loss 8.429615 Test Loss 11.481671943579741\n",
      "933 Train Loss 8.429334 Test Loss 11.481725213458063\n",
      "934 Train Loss 8.4291525 Test Loss 11.480736486040694\n",
      "935 Train Loss 8.428945 Test Loss 11.479339148389665\n",
      "936 Train Loss 8.4287815 Test Loss 11.477598779024262\n",
      "937 Train Loss 8.42868 Test Loss 11.476790405502475\n",
      "938 Train Loss 8.428607 Test Loss 11.476490990159284\n",
      "939 Train Loss 8.428523 Test Loss 11.476390969542672\n",
      "940 Train Loss 8.428424 Test Loss 11.476301426004266\n",
      "941 Train Loss 8.428287 Test Loss 11.476044937723168\n",
      "942 Train Loss 8.428083 Test Loss 11.475767986290384\n",
      "943 Train Loss 8.452701 Test Loss 11.458273905678208\n",
      "944 Train Loss 8.428009 Test Loss 11.474794637710188\n",
      "945 Train Loss 8.427668 Test Loss 11.474119166636553\n",
      "946 Train Loss 8.4271755 Test Loss 11.472942386736571\n",
      "947 Train Loss 8.426887 Test Loss 11.472439108112448\n",
      "948 Train Loss 8.426582 Test Loss 11.472171162701038\n",
      "949 Train Loss 8.426292 Test Loss 11.473408249046127\n",
      "950 Train Loss 8.425928 Test Loss 11.474117976978125\n",
      "951 Train Loss 8.425502 Test Loss 11.475009811881046\n",
      "952 Train Loss 8.425233 Test Loss 11.47552233893546\n",
      "953 Train Loss 8.424987 Test Loss 11.47587963924316\n",
      "954 Train Loss 8.424753 Test Loss 11.47604063276582\n",
      "955 Train Loss 8.424534 Test Loss 11.475722625430453\n",
      "956 Train Loss 8.424291 Test Loss 11.475305034299476\n",
      "957 Train Loss 8.423977 Test Loss 11.47433455155363\n",
      "958 Train Loss 8.442949 Test Loss 11.464246102396633\n",
      "959 Train Loss 8.42393 Test Loss 11.473837825171252\n",
      "960 Train Loss 8.423798 Test Loss 11.471658250677846\n",
      "961 Train Loss 8.423828 Test Loss 11.471334273945475\n",
      "962 Train Loss 8.423648 Test Loss 11.471493002910638\n",
      "963 Train Loss 8.439679 Test Loss 11.47705101747991\n",
      "964 Train Loss 8.423356 Test Loss 11.472142437701702\n",
      "965 Train Loss 8.423261 Test Loss 11.474145081176104\n",
      "966 Train Loss 8.422543 Test Loss 11.473887535957276\n",
      "967 Train Loss 8.422143 Test Loss 11.471483332444501\n",
      "968 Train Loss 8.421775 Test Loss 11.471533611074264\n",
      "969 Train Loss 8.421332 Test Loss 11.471339053591189\n",
      "970 Train Loss 8.420903 Test Loss 11.47122562577963\n",
      "971 Train Loss 8.420728 Test Loss 11.470691633215578\n",
      "972 Train Loss 8.420396 Test Loss 11.469518981587301\n",
      "973 Train Loss 8.420242 Test Loss 11.469164345413098\n",
      "974 Train Loss 8.42023 Test Loss 11.466121939684916\n",
      "975 Train Loss 8.4201 Test Loss 11.467607629144187\n",
      "976 Train Loss 8.419809 Test Loss 11.467375555866438\n",
      "977 Train Loss 8.41952 Test Loss 11.466747142936939\n",
      "978 Train Loss 8.419193 Test Loss 11.465740694659189\n",
      "979 Train Loss 8.418992 Test Loss 11.464742776381938\n",
      "980 Train Loss 8.4187155 Test Loss 11.463977059088549\n",
      "981 Train Loss 8.417867 Test Loss 11.459880430496785\n",
      "982 Train Loss 8.417143 Test Loss 11.460667697825318\n",
      "983 Train Loss 8.416762 Test Loss 11.460990622400221\n",
      "984 Train Loss 8.416418 Test Loss 11.459897048614748\n",
      "985 Train Loss 8.415959 Test Loss 11.457902497998107\n",
      "986 Train Loss 8.415615 Test Loss 11.455795130246697\n",
      "987 Train Loss 8.415274 Test Loss 11.453890378940406\n",
      "988 Train Loss 8.415027 Test Loss 11.453249908940418\n",
      "989 Train Loss 8.415438 Test Loss 11.448658698060946\n",
      "990 Train Loss 8.414863 Test Loss 11.451614434242678\n",
      "991 Train Loss 8.423875 Test Loss 11.445983740001953\n",
      "992 Train Loss 8.414617 Test Loss 11.450811648043471\n",
      "993 Train Loss 8.414039 Test Loss 11.451024185981009\n",
      "994 Train Loss 8.4132805 Test Loss 11.4501743103645\n",
      "995 Train Loss 8.412802 Test Loss 11.448851934490852\n",
      "996 Train Loss 8.412082 Test Loss 11.446410084216243\n",
      "997 Train Loss 8.411266 Test Loss 11.443711929721143\n",
      "998 Train Loss 8.410523 Test Loss 11.442601350986074\n",
      "999 Train Loss 8.409905 Test Loss 11.441902885607917\n",
      "1000 Train Loss 8.409552 Test Loss 11.44237466522194\n",
      "1001 Train Loss 8.409271 Test Loss 11.442019536475836\n",
      "1002 Train Loss 8.408994 Test Loss 11.441299194441688\n",
      "1003 Train Loss 8.408674 Test Loss 11.439977019690202\n",
      "1004 Train Loss 8.408357 Test Loss 11.438929170057268\n",
      "1005 Train Loss 8.408163 Test Loss 11.438213993215882\n",
      "1006 Train Loss 8.407603 Test Loss 11.438854724016682\n",
      "1007 Train Loss 8.407027 Test Loss 11.439376800386341\n",
      "1008 Train Loss 8.406698 Test Loss 11.440843627823615\n",
      "1009 Train Loss 8.406211 Test Loss 11.440942110759918\n",
      "1010 Train Loss 8.405493 Test Loss 11.440189740920015\n",
      "1011 Train Loss 8.404626 Test Loss 11.437289330139658\n",
      "1012 Train Loss 8.4039755 Test Loss 11.43528635810917\n",
      "1013 Train Loss 8.403373 Test Loss 11.43347372251586\n",
      "1014 Train Loss 8.402982 Test Loss 11.433949800028088\n",
      "1015 Train Loss 8.402616 Test Loss 11.434961906435205\n",
      "1016 Train Loss 8.402205 Test Loss 11.43675949423478\n",
      "1017 Train Loss 8.404748 Test Loss 11.440692155347676\n",
      "1018 Train Loss 8.40204 Test Loss 11.437541081473704\n",
      "1019 Train Loss 8.401333 Test Loss 11.436694839927917\n",
      "1020 Train Loss 8.400578 Test Loss 11.436111589431514\n",
      "1021 Train Loss 8.399906 Test Loss 11.434094348018721\n",
      "1022 Train Loss 8.399538 Test Loss 11.43362200121167\n",
      "1023 Train Loss 8.3991585 Test Loss 11.432704181593548\n",
      "1024 Train Loss 8.398779 Test Loss 11.43273161065841\n",
      "1025 Train Loss 8.408503 Test Loss 11.425157306851046\n",
      "1026 Train Loss 8.398645 Test Loss 11.431931235862724\n",
      "1027 Train Loss 8.4244175 Test Loss 11.414703406684454\n",
      "1028 Train Loss 8.3985815 Test Loss 11.431054896329226\n",
      "1029 Train Loss 8.397991 Test Loss 11.431411054630107\n",
      "1030 Train Loss 8.397388 Test Loss 11.429338347139183\n",
      "1031 Train Loss 8.3987 Test Loss 11.433374570160593\n",
      "1032 Train Loss 8.39703 Test Loss 11.430600633856521\n",
      "1033 Train Loss 8.396406 Test Loss 11.429181906883654\n",
      "1034 Train Loss 8.395606 Test Loss 11.426698358837397\n",
      "1035 Train Loss 8.394932 Test Loss 11.425683040251846\n",
      "1036 Train Loss 8.394191 Test Loss 11.424168665178316\n",
      "1037 Train Loss 8.393489 Test Loss 11.424098846712191\n",
      "1038 Train Loss 8.392327 Test Loss 11.423824918004106\n",
      "1039 Train Loss 8.391497 Test Loss 11.425388688129644\n",
      "1040 Train Loss 8.3910055 Test Loss 11.425976437010245\n",
      "1041 Train Loss 8.390554 Test Loss 11.427290699663576\n",
      "1042 Train Loss 8.389246 Test Loss 11.427097157953785\n",
      "1043 Train Loss 8.387901 Test Loss 11.425465723591573\n",
      "1044 Train Loss 8.387207 Test Loss 11.423043880686926\n",
      "1045 Train Loss 8.393651 Test Loss 11.414578459506018\n",
      "1046 Train Loss 8.386893 Test Loss 11.421478702955026\n",
      "1047 Train Loss 8.386427 Test Loss 11.420435744009813\n",
      "1048 Train Loss 8.385306 Test Loss 11.417529720885046\n",
      "1049 Train Loss 8.384556 Test Loss 11.416971902809673\n",
      "1050 Train Loss 8.383358 Test Loss 11.417469062579357\n",
      "1051 Train Loss 8.382551 Test Loss 11.418148471361292\n",
      "1052 Train Loss 8.381795 Test Loss 11.419425830952173\n",
      "1053 Train Loss 8.381047 Test Loss 11.419328831667292\n",
      "1054 Train Loss 8.379551 Test Loss 11.417772330647301\n",
      "1055 Train Loss 8.378426 Test Loss 11.41553104853974\n",
      "1056 Train Loss 8.522941 Test Loss 11.37797688892818\n",
      "1057 Train Loss 8.3777685 Test Loss 11.41266073083923\n",
      "1058 Train Loss 8.377268 Test Loss 11.411785345144416\n",
      "1059 Train Loss 8.377031 Test Loss 11.410115194340365\n",
      "1060 Train Loss 8.376892 Test Loss 11.410928030626904\n",
      "1061 Train Loss 8.376672 Test Loss 11.411351957956079\n",
      "1062 Train Loss 8.376467 Test Loss 11.411976674748441\n",
      "1063 Train Loss 8.37623 Test Loss 11.411914119607223\n",
      "1064 Train Loss 8.375943 Test Loss 11.412348048754373\n",
      "1065 Train Loss 8.3756075 Test Loss 11.412630192126871\n",
      "1066 Train Loss 8.376737 Test Loss 11.410675266093119\n",
      "1067 Train Loss 8.375352 Test Loss 11.41203162611645\n",
      "1068 Train Loss 8.375041 Test Loss 11.412965149319138\n",
      "1069 Train Loss 8.374735 Test Loss 11.413651604199433\n",
      "1070 Train Loss 8.374521 Test Loss 11.41361996886775\n",
      "1071 Train Loss 8.374313 Test Loss 11.413037752626368\n",
      "1072 Train Loss 8.374091 Test Loss 11.412014656550918\n",
      "1073 Train Loss 8.373354 Test Loss 11.411491903032438\n",
      "1074 Train Loss 8.372234 Test Loss 11.41101498920933\n",
      "1075 Train Loss 8.371624 Test Loss 11.411402799482234\n",
      "1076 Train Loss 8.371107 Test Loss 11.411942808521076\n",
      "1077 Train Loss 8.370712 Test Loss 11.412107830004944\n",
      "1078 Train Loss 8.370289 Test Loss 11.412127238853424\n",
      "1079 Train Loss 8.36993 Test Loss 11.4116874075079\n",
      "1080 Train Loss 8.369623 Test Loss 11.411889508024693\n",
      "1081 Train Loss 8.369357 Test Loss 11.41207639217697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082 Train Loss 8.369384 Test Loss 11.413852060890047\n",
      "1083 Train Loss 8.369147 Test Loss 11.412935288452445\n",
      "1084 Train Loss 8.368768 Test Loss 11.413316760520793\n",
      "1085 Train Loss 8.368419 Test Loss 11.413358529708061\n",
      "1086 Train Loss 8.367986 Test Loss 11.412419187021882\n",
      "1087 Train Loss 8.386655 Test Loss 11.417149149218089\n",
      "1088 Train Loss 8.367913 Test Loss 11.412687731466711\n",
      "1089 Train Loss 8.3675995 Test Loss 11.411517747222483\n",
      "1090 Train Loss 8.367465 Test Loss 11.409469137260446\n",
      "1091 Train Loss 8.366734 Test Loss 11.408203616997818\n",
      "1092 Train Loss 8.366308 Test Loss 11.408414186214511\n",
      "1093 Train Loss 8.365688 Test Loss 11.407139306525158\n",
      "1094 Train Loss 8.365425 Test Loss 11.406411055377012\n",
      "1095 Train Loss 8.364995 Test Loss 11.4048615233049\n",
      "1096 Train Loss 8.36477 Test Loss 11.405010129965962\n",
      "1097 Train Loss 8.364537 Test Loss 11.404884746270525\n",
      "1098 Train Loss 8.364373 Test Loss 11.404931348152848\n",
      "1099 Train Loss 8.364156 Test Loss 11.404495216567627\n",
      "1100 Train Loss 8.364013 Test Loss 11.404235348182935\n",
      "1101 Train Loss 8.36378 Test Loss 11.403496770252598\n",
      "1102 Train Loss 8.363916 Test Loss 11.403122769783227\n",
      "1103 Train Loss 8.36366 Test Loss 11.403344066402218\n",
      "1104 Train Loss 8.363422 Test Loss 11.403107614678383\n",
      "1105 Train Loss 8.363093 Test Loss 11.403441377357717\n",
      "1106 Train Loss 8.36276 Test Loss 11.404154389836515\n",
      "1107 Train Loss 8.3625345 Test Loss 11.40459826177552\n",
      "1108 Train Loss 8.362142 Test Loss 11.405081032043473\n",
      "1109 Train Loss 8.361747 Test Loss 11.404940261618234\n",
      "1110 Train Loss 8.361362 Test Loss 11.404266008648433\n",
      "1111 Train Loss 8.361011 Test Loss 11.403105749120465\n",
      "1112 Train Loss 8.360724 Test Loss 11.401986437878861\n",
      "1113 Train Loss 8.360484 Test Loss 11.401109025128068\n",
      "1114 Train Loss 8.360239 Test Loss 11.400491934817778\n",
      "1115 Train Loss 8.360098 Test Loss 11.400841380520639\n",
      "1116 Train Loss 8.360236 Test Loss 11.398867945026886\n",
      "1117 Train Loss 8.359909 Test Loss 11.399969313702076\n",
      "1118 Train Loss 8.359646 Test Loss 11.40038498539404\n",
      "1119 Train Loss 8.3591 Test Loss 11.400762893524812\n",
      "1120 Train Loss 8.35891 Test Loss 11.400886768646227\n",
      "1121 Train Loss 8.3586 Test Loss 11.400668155468386\n",
      "1122 Train Loss 8.358405 Test Loss 11.400436171221761\n",
      "1123 Train Loss 8.358193 Test Loss 11.400480016359397\n",
      "1124 Train Loss 8.357963 Test Loss 11.400629935695306\n",
      "1125 Train Loss 8.357761 Test Loss 11.400260990194589\n",
      "1126 Train Loss 8.357399 Test Loss 11.400541486779874\n",
      "1127 Train Loss 8.3569355 Test Loss 11.399866543638595\n",
      "1128 Train Loss 8.356349 Test Loss 11.397859665492565\n",
      "1129 Train Loss 8.356036 Test Loss 11.39724519304447\n",
      "1130 Train Loss 8.355726 Test Loss 11.396028708173022\n",
      "1131 Train Loss 8.355168 Test Loss 11.393281601316694\n",
      "1132 Train Loss 8.3548765 Test Loss 11.391995148728899\n",
      "1133 Train Loss 8.354524 Test Loss 11.390622048396764\n",
      "1134 Train Loss 8.354133 Test Loss 11.38994441612029\n",
      "1135 Train Loss 8.353791 Test Loss 11.389806314869661\n",
      "1136 Train Loss 8.353475 Test Loss 11.390120447585094\n",
      "1137 Train Loss 8.353097 Test Loss 11.390840844605593\n",
      "1138 Train Loss 8.352787 Test Loss 11.390995066162427\n",
      "1139 Train Loss 8.352303 Test Loss 11.392317608905438\n",
      "1140 Train Loss 8.351869 Test Loss 11.39201437124557\n",
      "1141 Train Loss 8.351161 Test Loss 11.39125357865093\n",
      "1142 Train Loss 8.350542 Test Loss 11.390619622008753\n",
      "1143 Train Loss 8.349709 Test Loss 11.389597328606635\n",
      "1144 Train Loss 8.348631 Test Loss 11.388428715642306\n",
      "1145 Train Loss 8.348016 Test Loss 11.387777380762778\n",
      "1146 Train Loss 8.347601 Test Loss 11.38755865301404\n",
      "1147 Train Loss 8.34729 Test Loss 11.386304538765792\n",
      "1148 Train Loss 8.350622 Test Loss 11.392155063439777\n",
      "1149 Train Loss 8.347087 Test Loss 11.38742729560847\n",
      "1150 Train Loss 8.346843 Test Loss 11.387500208097713\n",
      "1151 Train Loss 8.3466015 Test Loss 11.386981602392039\n",
      "1152 Train Loss 8.346472 Test Loss 11.386889293700165\n",
      "1153 Train Loss 8.346244 Test Loss 11.386682356683004\n",
      "1154 Train Loss 8.346115 Test Loss 11.386599329780676\n",
      "1155 Train Loss 8.345982 Test Loss 11.38664995939896\n",
      "1156 Train Loss 8.345884 Test Loss 11.386726533323332\n",
      "1157 Train Loss 8.345765 Test Loss 11.38688360068113\n",
      "1158 Train Loss 8.345632 Test Loss 11.387068730332782\n",
      "1159 Train Loss 8.345397 Test Loss 11.387280596073131\n",
      "1160 Train Loss 8.345074 Test Loss 11.38721313920496\n",
      "1161 Train Loss 8.347789 Test Loss 11.388771839039375\n",
      "1162 Train Loss 8.344982 Test Loss 11.387449987480107\n",
      "1163 Train Loss 8.344653 Test Loss 11.387303343329704\n",
      "1164 Train Loss 8.344352 Test Loss 11.387134158600395\n",
      "1165 Train Loss 8.344186 Test Loss 11.387178887910018\n",
      "1166 Train Loss 8.344019 Test Loss 11.3876341610433\n",
      "1167 Train Loss 8.343902 Test Loss 11.387182567652028\n",
      "1168 Train Loss 8.343726 Test Loss 11.387866787517039\n",
      "1169 Train Loss 8.343625 Test Loss 11.387774242876\n",
      "1170 Train Loss 8.343507 Test Loss 11.387416418363268\n",
      "1171 Train Loss 8.343396 Test Loss 11.386886592690653\n",
      "1172 Train Loss 8.343206 Test Loss 11.385711167231436\n",
      "1173 Train Loss 8.342934 Test Loss 11.384904053113484\n",
      "1174 Train Loss 8.342689 Test Loss 11.383713920485556\n",
      "1175 Train Loss 8.342519 Test Loss 11.383845661109701\n",
      "1176 Train Loss 8.342337 Test Loss 11.383750582700477\n",
      "1177 Train Loss 8.342161 Test Loss 11.38421944778828\n",
      "1178 Train Loss 8.342036 Test Loss 11.38453078700226\n",
      "1179 Train Loss 8.341881 Test Loss 11.38286128570619\n",
      "1180 Train Loss 8.341322 Test Loss 11.38317587284854\n",
      "1181 Train Loss 8.340856 Test Loss 11.382246560293968\n",
      "1182 Train Loss 8.340556 Test Loss 11.380905343366676\n",
      "1183 Train Loss 8.3401 Test Loss 11.38016224566454\n",
      "1184 Train Loss 8.339795 Test Loss 11.379976583117468\n",
      "1185 Train Loss 8.3394375 Test Loss 11.380539841534684\n",
      "1186 Train Loss 8.339261 Test Loss 11.380997320686111\n",
      "1187 Train Loss 8.339018 Test Loss 11.381908269035348\n",
      "1188 Train Loss 8.338861 Test Loss 11.382277838927989\n",
      "1189 Train Loss 8.338669 Test Loss 11.382378292862404\n",
      "1190 Train Loss 8.33853 Test Loss 11.382172714714892\n",
      "1191 Train Loss 8.338395 Test Loss 11.381921463995345\n",
      "1192 Train Loss 8.338267 Test Loss 11.382112734044826\n",
      "1193 Train Loss 8.340752 Test Loss 11.378652682968568\n",
      "1194 Train Loss 8.338226 Test Loss 11.38171636051614\n",
      "1195 Train Loss 8.337971 Test Loss 11.382427388756389\n",
      "1196 Train Loss 8.3376045 Test Loss 11.38310128857993\n",
      "1197 Train Loss 8.337097 Test Loss 11.38329023769347\n",
      "1198 Train Loss 8.336687 Test Loss 11.383309079351445\n",
      "1199 Train Loss 8.336286 Test Loss 11.382790321617374\n",
      "1200 Train Loss 8.335932 Test Loss 11.382089033719721\n",
      "1201 Train Loss 8.335646 Test Loss 11.381250467584426\n",
      "1202 Train Loss 8.335453 Test Loss 11.380883343296698\n",
      "1203 Train Loss 8.439218 Test Loss 11.37226495211076\n",
      "1204 Train Loss 8.335404 Test Loss 11.380617652942572\n",
      "1205 Train Loss 8.335247 Test Loss 11.380661259281375\n",
      "1206 Train Loss 8.3350115 Test Loss 11.3810009221646\n",
      "1207 Train Loss 8.334886 Test Loss 11.381310772923154\n",
      "1208 Train Loss 8.334728 Test Loss 11.381636108520302\n",
      "1209 Train Loss 8.334592 Test Loss 11.38169050877822\n",
      "1210 Train Loss 8.33448 Test Loss 11.381535799644437\n",
      "1211 Train Loss 8.334396 Test Loss 11.38129126580297\n",
      "1212 Train Loss 8.335006 Test Loss 11.37972938469435\n",
      "1213 Train Loss 8.334372 Test Loss 11.381022896846346\n",
      "1214 Train Loss 8.334272 Test Loss 11.380748952789993\n",
      "1215 Train Loss 8.3340845 Test Loss 11.380101048715462\n",
      "1216 Train Loss 8.3339 Test Loss 11.37949374088598\n",
      "1217 Train Loss 8.333688 Test Loss 11.378746942172654\n",
      "1218 Train Loss 8.333554 Test Loss 11.378315403824331\n",
      "1219 Train Loss 8.333467 Test Loss 11.378200195125821\n",
      "1220 Train Loss 8.333384 Test Loss 11.37812722036143\n",
      "1221 Train Loss 8.3333025 Test Loss 11.378151199244737\n",
      "1222 Train Loss 8.333055 Test Loss 11.378327508467475\n",
      "1223 Train Loss 8.332803 Test Loss 11.378598526165492\n",
      "1224 Train Loss 8.333363 Test Loss 11.379056132693075\n",
      "1225 Train Loss 8.332753 Test Loss 11.378697915406319\n",
      "1226 Train Loss 8.332598 Test Loss 11.378533103251568\n",
      "1227 Train Loss 8.332471 Test Loss 11.378426034561919\n",
      "1228 Train Loss 8.333098 Test Loss 11.378516630961995\n",
      "1229 Train Loss 8.332319 Test Loss 11.378453121616278\n",
      "1230 Train Loss 8.33184 Test Loss 11.378171801253846\n",
      "1231 Train Loss 8.331465 Test Loss 11.377986970830817\n",
      "1232 Train Loss 8.331186 Test Loss 11.377836039026068\n",
      "1233 Train Loss 8.330958 Test Loss 11.377703660773948\n",
      "1234 Train Loss 8.330566 Test Loss 11.377494019352987\n",
      "1235 Train Loss 8.332877 Test Loss 11.378161414359635\n",
      "1236 Train Loss 8.330471 Test Loss 11.377602179248107\n",
      "1237 Train Loss 8.330209 Test Loss 11.377698760659174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238 Train Loss 8.329952 Test Loss 11.37789378102433\n",
      "1239 Train Loss 8.329726 Test Loss 11.378047603854492\n",
      "1240 Train Loss 8.406215 Test Loss 11.381316750955062\n",
      "1241 Train Loss 8.329711 Test Loss 11.37808763633065\n",
      "1242 Train Loss 8.3293705 Test Loss 11.378862733308935\n",
      "1243 Train Loss 8.329174 Test Loss 11.377987819711922\n",
      "1244 Train Loss 8.329154 Test Loss 11.379450633011892\n",
      "1245 Train Loss 8.329018 Test Loss 11.378741513918785\n",
      "1246 Train Loss 8.328881 Test Loss 11.378333223240286\n",
      "1247 Train Loss 8.3286705 Test Loss 11.377424509434285\n",
      "1248 Train Loss 8.328518 Test Loss 11.376913227253933\n",
      "1249 Train Loss 8.3282585 Test Loss 11.37619921049414\n",
      "1250 Train Loss 8.328118 Test Loss 11.376087158344633\n",
      "1251 Train Loss 8.328018 Test Loss 11.376224432400159\n",
      "1252 Train Loss 8.327932 Test Loss 11.376450116156667\n",
      "1253 Train Loss 8.327801 Test Loss 11.37661363047886\n",
      "1254 Train Loss 8.327509 Test Loss 11.376663208841876\n",
      "1255 Train Loss 8.327324 Test Loss 11.375152246804035\n",
      "1256 Train Loss 8.327023 Test Loss 11.375040980755863\n",
      "1257 Train Loss 8.326885 Test Loss 11.374927109880463\n",
      "1258 Train Loss 8.326678 Test Loss 11.374679282696043\n",
      "1259 Train Loss 8.326542 Test Loss 11.374830976012843\n",
      "1260 Train Loss 8.326381 Test Loss 11.375214252612743\n",
      "1261 Train Loss 8.326258 Test Loss 11.375416394037073\n",
      "1262 Train Loss 8.326299 Test Loss 11.376804422632386\n",
      "1263 Train Loss 8.326195 Test Loss 11.37602307605694\n",
      "1264 Train Loss 8.326057 Test Loss 11.375726679216557\n",
      "1265 Train Loss 8.325827 Test Loss 11.375228127677557\n",
      "1266 Train Loss 8.325369 Test Loss 11.374022245735642\n",
      "1267 Train Loss 8.324997 Test Loss 11.372950452711068\n",
      "1268 Train Loss 8.32446 Test Loss 11.3711637737004\n",
      "1269 Train Loss 8.32399 Test Loss 11.370051972207277\n",
      "1270 Train Loss 8.323581 Test Loss 11.369478616109228\n",
      "1271 Train Loss 8.323147 Test Loss 11.368686731785221\n",
      "1272 Train Loss 8.322866 Test Loss 11.369088531986213\n",
      "1273 Train Loss 8.322605 Test Loss 11.36946921409216\n",
      "1274 Train Loss 8.322392 Test Loss 11.369596674417926\n",
      "1275 Train Loss 8.32218 Test Loss 11.369810463312733\n",
      "1276 Train Loss 8.321898 Test Loss 11.370244824404553\n",
      "1277 Train Loss 8.321663 Test Loss 11.370602048082354\n",
      "1278 Train Loss 8.321448 Test Loss 11.371031771237972\n",
      "1279 Train Loss 8.321264 Test Loss 11.371434883563923\n",
      "1280 Train Loss 8.321101 Test Loss 11.371633363000846\n",
      "1281 Train Loss 8.320956 Test Loss 11.371607304055644\n",
      "1282 Train Loss 8.320877 Test Loss 11.371887395971255\n",
      "1283 Train Loss 8.321027 Test Loss 11.370382037279771\n",
      "1284 Train Loss 8.320842 Test Loss 11.371429670590732\n",
      "1285 Train Loss 8.320713 Test Loss 11.371404190393337\n",
      "1286 Train Loss 8.320539 Test Loss 11.371044909448122\n",
      "1287 Train Loss 8.320415 Test Loss 11.37059756743085\n",
      "1288 Train Loss 8.320244 Test Loss 11.370030236163373\n",
      "1289 Train Loss 8.320043 Test Loss 11.369740471932849\n",
      "1290 Train Loss 8.319777 Test Loss 11.369786645032628\n",
      "1291 Train Loss 8.319564 Test Loss 11.370322978437391\n",
      "1292 Train Loss 8.319395 Test Loss 11.371166982875293\n",
      "1293 Train Loss 8.451788 Test Loss 11.371895998190015\n",
      "1294 Train Loss 8.319378 Test Loss 11.371161851042418\n",
      "1295 Train Loss 8.322606 Test Loss 11.37335804117158\n",
      "1296 Train Loss 8.319346 Test Loss 11.371351527247285\n",
      "1297 Train Loss 8.319174 Test Loss 11.371924722936244\n",
      "1298 Train Loss 8.318909 Test Loss 11.372361414100572\n",
      "1299 Train Loss 8.318594 Test Loss 11.372366601328313\n",
      "1300 Train Loss 8.318182 Test Loss 11.371911712492043\n",
      "1301 Train Loss 8.317768 Test Loss 11.371208777599266\n",
      "1302 Train Loss 8.317426 Test Loss 11.370715892474601\n",
      "1303 Train Loss 8.317179 Test Loss 11.370843251883773\n",
      "1304 Train Loss 8.327999 Test Loss 11.36657977187205\n",
      "1305 Train Loss 8.317151 Test Loss 11.370630775035561\n",
      "1306 Train Loss 8.316813 Test Loss 11.371222785389914\n",
      "1307 Train Loss 8.316488 Test Loss 11.372048208540225\n",
      "1308 Train Loss 8.316185 Test Loss 11.372762533631754\n",
      "1309 Train Loss 8.315884 Test Loss 11.373224044260747\n",
      "1310 Train Loss 8.315693 Test Loss 11.373163786003584\n",
      "1311 Train Loss 8.315453 Test Loss 11.372831597567115\n",
      "1312 Train Loss 8.315172 Test Loss 11.372174991547134\n",
      "1313 Train Loss 8.314944 Test Loss 11.371589059264604\n",
      "1314 Train Loss 8.314714 Test Loss 11.37097399086588\n",
      "1315 Train Loss 8.314528 Test Loss 11.370569037590341\n",
      "1316 Train Loss 8.314421 Test Loss 11.370409214727285\n",
      "1317 Train Loss 8.31433 Test Loss 11.370245787854541\n",
      "1318 Train Loss 8.314229 Test Loss 11.369932716608318\n",
      "1319 Train Loss 8.314122 Test Loss 11.36946186002218\n",
      "1320 Train Loss 8.314032 Test Loss 11.368883194539317\n",
      "1321 Train Loss 8.313945 Test Loss 11.368276208747815\n",
      "1322 Train Loss 8.313863 Test Loss 11.367607663691626\n",
      "1323 Train Loss 8.314508 Test Loss 11.366648342406148\n",
      "1324 Train Loss 8.313769 Test Loss 11.367350320223133\n",
      "1325 Train Loss 8.313683 Test Loss 11.367228525380327\n",
      "1326 Train Loss 8.313563 Test Loss 11.366106982328763\n",
      "1327 Train Loss 8.313433 Test Loss 11.365952046783006\n",
      "1328 Train Loss 8.313316 Test Loss 11.365737657324855\n",
      "1329 Train Loss 8.313131 Test Loss 11.365368654936198\n",
      "1330 Train Loss 8.312971 Test Loss 11.36513300826615\n",
      "1331 Train Loss 8.3137865 Test Loss 11.369037946409385\n",
      "1332 Train Loss 8.312911 Test Loss 11.365948864660318\n",
      "1333 Train Loss 8.313672 Test Loss 11.365066551126793\n",
      "1334 Train Loss 8.312867 Test Loss 11.365783867331738\n",
      "1335 Train Loss 8.312709 Test Loss 11.365927039974913\n",
      "1336 Train Loss 8.312429 Test Loss 11.36645990855872\n",
      "1337 Train Loss 8.312183 Test Loss 11.36724413791467\n",
      "1338 Train Loss 8.31203 Test Loss 11.367633348109377\n",
      "1339 Train Loss 8.311801 Test Loss 11.368124700923827\n",
      "1340 Train Loss 8.32868 Test Loss 11.37400222229857\n",
      "1341 Train Loss 8.31176 Test Loss 11.368387749924686\n",
      "1342 Train Loss 8.311394 Test Loss 11.368779806249565\n",
      "1343 Train Loss 8.311119 Test Loss 11.369069754840197\n",
      "1344 Train Loss 8.310852 Test Loss 11.369402594017068\n",
      "1345 Train Loss 8.310619 Test Loss 11.369726279411783\n",
      "1346 Train Loss 8.310373 Test Loss 11.370094523912396\n",
      "1347 Train Loss 8.3101845 Test Loss 11.370357149958426\n",
      "1348 Train Loss 8.319982 Test Loss 11.3676282018829\n",
      "1349 Train Loss 8.31015 Test Loss 11.370221444066708\n",
      "1350 Train Loss 8.309923 Test Loss 11.370407144185345\n",
      "1351 Train Loss 8.309745 Test Loss 11.37053029001259\n",
      "1352 Train Loss 8.309538 Test Loss 11.370591192245625\n",
      "1353 Train Loss 8.309422 Test Loss 11.370584378841722\n",
      "1354 Train Loss 8.309303 Test Loss 11.370471650731638\n",
      "1355 Train Loss 8.308981 Test Loss 11.370268446471696\n",
      "1356 Train Loss 8.308526 Test Loss 11.369768645842875\n",
      "1357 Train Loss 8.308362 Test Loss 11.369065609471411\n",
      "1358 Train Loss 8.308679 Test Loss 11.368883660650756\n",
      "1359 Train Loss 8.308261 Test Loss 11.369003569280565\n",
      "1360 Train Loss 8.310386 Test Loss 11.366508970546718\n",
      "1361 Train Loss 8.307837 Test Loss 11.368249812427079\n",
      "1362 Train Loss 8.307534 Test Loss 11.36778826620223\n",
      "1363 Train Loss 8.307174 Test Loss 11.366817733922396\n",
      "1364 Train Loss 8.307011 Test Loss 11.36626873261565\n",
      "1365 Train Loss 8.3066435 Test Loss 11.365060907349438\n",
      "1366 Train Loss 8.306398 Test Loss 11.364475941028466\n",
      "1367 Train Loss 8.30618 Test Loss 11.364164958899472\n",
      "1368 Train Loss 8.306057 Test Loss 11.364214906059333\n",
      "1369 Train Loss 8.305944 Test Loss 11.36415821165766\n",
      "1370 Train Loss 8.305847 Test Loss 11.36384453966923\n",
      "1371 Train Loss 8.305851 Test Loss 11.363257045986531\n",
      "1372 Train Loss 8.30572 Test Loss 11.36355005270818\n",
      "1373 Train Loss 8.3072405 Test Loss 11.36373593586365\n",
      "1374 Train Loss 8.30565 Test Loss 11.363569674783156\n",
      "1375 Train Loss 8.305528 Test Loss 11.363517878566551\n",
      "1376 Train Loss 8.305348 Test Loss 11.363592972035983\n",
      "1377 Train Loss 8.305247 Test Loss 11.363522633219539\n",
      "1378 Train Loss 8.305255 Test Loss 11.36574981671449\n",
      "1379 Train Loss 8.305154 Test Loss 11.364612740074925\n",
      "1380 Train Loss 8.30498 Test Loss 11.364491437996824\n",
      "1381 Train Loss 8.304874 Test Loss 11.364564725403318\n",
      "1382 Train Loss 8.304667 Test Loss 11.364512810968838\n",
      "1383 Train Loss 8.304488 Test Loss 11.364184350594956\n",
      "1384 Train Loss 8.304133 Test Loss 11.363031444632467\n",
      "1385 Train Loss 8.303916 Test Loss 11.362460472612174\n",
      "1386 Train Loss 8.303535 Test Loss 11.36166718012362\n",
      "1387 Train Loss 8.303259 Test Loss 11.361408610245505\n",
      "1388 Train Loss 8.302932 Test Loss 11.36150093563379\n",
      "1389 Train Loss 8.302753 Test Loss 11.361657529049346\n",
      "1390 Train Loss 8.30261 Test Loss 11.361684946197457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1391 Train Loss 8.3035345 Test Loss 11.360368167402719\n",
      "1392 Train Loss 8.302572 Test Loss 11.361459748127855\n",
      "1393 Train Loss 8.316162 Test Loss 11.35475289772516\n",
      "1394 Train Loss 8.302535 Test Loss 11.361110372841537\n",
      "1395 Train Loss 8.302426 Test Loss 11.360945666418187\n",
      "1396 Train Loss 8.302209 Test Loss 11.360128818155657\n",
      "1397 Train Loss 8.302058 Test Loss 11.359455905005122\n",
      "1398 Train Loss 8.301663 Test Loss 11.358350603558439\n",
      "1399 Train Loss 8.301307 Test Loss 11.35859052380743\n",
      "1400 Train Loss 8.300908 Test Loss 11.359846266977247\n",
      "1401 Train Loss 8.300681 Test Loss 11.36031018650002\n",
      "1402 Train Loss 8.299993 Test Loss 11.36073770635574\n",
      "1403 Train Loss 8.300207 Test Loss 11.36092640074927\n",
      "1404 Train Loss 8.2997 Test Loss 11.360808546425128\n",
      "1405 Train Loss 8.299304 Test Loss 11.360493268006762\n",
      "1406 Train Loss 8.299004 Test Loss 11.359699137503645\n",
      "1407 Train Loss 8.301588 Test Loss 11.360951536599408\n",
      "1408 Train Loss 8.298945 Test Loss 11.359848072591165\n",
      "1409 Train Loss 8.298746 Test Loss 11.359135698882376\n",
      "1410 Train Loss 8.298461 Test Loss 11.357979485498685\n",
      "1411 Train Loss 8.298158 Test Loss 11.358415630941888\n",
      "1412 Train Loss 8.297955 Test Loss 11.358572139012567\n",
      "1413 Train Loss 8.29777 Test Loss 11.358913673796177\n",
      "1414 Train Loss 8.303382 Test Loss 11.361358406943143\n",
      "1415 Train Loss 8.297688 Test Loss 11.359164494265976\n",
      "1416 Train Loss 8.2979145 Test Loss 11.360071572337743\n",
      "1417 Train Loss 8.297519 Test Loss 11.359518839488624\n",
      "1418 Train Loss 8.297294 Test Loss 11.360450660383076\n",
      "1419 Train Loss 8.297067 Test Loss 11.361680575979955\n",
      "1420 Train Loss 8.297611 Test Loss 11.36112712183293\n",
      "1421 Train Loss 8.296871 Test Loss 11.361485059245819\n",
      "1422 Train Loss 8.296646 Test Loss 11.36138469982258\n",
      "1423 Train Loss 8.296474 Test Loss 11.36111921702346\n",
      "1424 Train Loss 8.296345 Test Loss 11.360689955389782\n",
      "1425 Train Loss 8.307616 Test Loss 11.371731102286878\n",
      "1426 Train Loss 8.296303 Test Loss 11.361283152830442\n",
      "1427 Train Loss 8.295986 Test Loss 11.362032040696993\n",
      "1428 Train Loss 8.377391 Test Loss 11.359439618684688\n",
      "1429 Train Loss 8.29574 Test Loss 11.361800433604248\n",
      "1430 Train Loss 8.295377 Test Loss 11.360468841721378\n",
      "1431 Train Loss 8.299236 Test Loss 11.357935936627177\n",
      "1432 Train Loss 8.295233 Test Loss 11.360046205883043\n",
      "1433 Train Loss 8.294585 Test Loss 11.357727453722557\n",
      "1434 Train Loss 8.294296 Test Loss 11.357093060451021\n",
      "1435 Train Loss 8.294097 Test Loss 11.357146113603488\n",
      "1436 Train Loss 8.293954 Test Loss 11.357135055912046\n",
      "1437 Train Loss 8.293792 Test Loss 11.357334883839114\n",
      "1438 Train Loss 8.33861 Test Loss 11.355361723523444\n",
      "1439 Train Loss 8.293748 Test Loss 11.357210818788516\n",
      "1440 Train Loss 8.2935705 Test Loss 11.357040073541853\n",
      "1441 Train Loss 8.293389 Test Loss 11.35673917315875\n",
      "1442 Train Loss 8.296835 Test Loss 11.36142425181353\n",
      "1443 Train Loss 8.293333 Test Loss 11.35725656913159\n",
      "1444 Train Loss 8.29291 Test Loss 11.357358516578001\n",
      "1445 Train Loss 8.292645 Test Loss 11.357709081367897\n",
      "1446 Train Loss 8.292456 Test Loss 11.35801332235281\n",
      "1447 Train Loss 8.292631 Test Loss 11.358153930635762\n",
      "1448 Train Loss 8.292415 Test Loss 11.358053044978364\n",
      "1449 Train Loss 8.292352 Test Loss 11.358132559054047\n",
      "1450 Train Loss 8.292176 Test Loss 11.358218297398677\n",
      "1451 Train Loss 8.292032 Test Loss 11.358438522106109\n",
      "1452 Train Loss 8.291888 Test Loss 11.358751314393203\n",
      "1453 Train Loss 8.291657 Test Loss 11.358692690725057\n",
      "1454 Train Loss 8.291288 Test Loss 11.35907343160012\n",
      "1455 Train Loss 8.291068 Test Loss 11.358876357029814\n",
      "1456 Train Loss 8.290842 Test Loss 11.358483224027362\n",
      "1457 Train Loss 8.290661 Test Loss 11.358286113695822\n",
      "1458 Train Loss 8.290309 Test Loss 11.359346009665023\n",
      "1459 Train Loss 8.303843 Test Loss 11.34975652064762\n",
      "1460 Train Loss 8.290185 Test Loss 11.358498463270077\n",
      "1461 Train Loss 8.289517 Test Loss 11.359302498314612\n",
      "1462 Train Loss 8.288461 Test Loss 11.360117070981701\n",
      "1463 Train Loss 8.287986 Test Loss 11.359521515998974\n",
      "1464 Train Loss 8.287682 Test Loss 11.359068057092609\n",
      "1465 Train Loss 8.287475 Test Loss 11.359035164646926\n",
      "1466 Train Loss 8.287209 Test Loss 11.358730167857209\n",
      "1467 Train Loss 8.286905 Test Loss 11.358606328069254\n",
      "1468 Train Loss 8.287911 Test Loss 11.35779612437376\n",
      "1469 Train Loss 8.28636 Test Loss 11.358299602010836\n",
      "1470 Train Loss 8.285908 Test Loss 11.357918486444564\n",
      "1471 Train Loss 8.28541 Test Loss 11.357774221015479\n",
      "1472 Train Loss 8.285208 Test Loss 11.357941288002896\n",
      "1473 Train Loss 8.284811 Test Loss 11.358084592688217\n",
      "1474 Train Loss 8.284511 Test Loss 11.357940617170609\n",
      "1475 Train Loss 8.284439 Test Loss 11.358641647259617\n",
      "1476 Train Loss 8.284203 Test Loss 11.35699978590193\n",
      "1477 Train Loss 8.283959 Test Loss 11.356978915536006\n",
      "1478 Train Loss 8.283641 Test Loss 11.356996636875346\n",
      "1479 Train Loss 8.283455 Test Loss 11.356434904134929\n",
      "1480 Train Loss 8.283185 Test Loss 11.355621171224492\n",
      "1481 Train Loss 8.283015 Test Loss 11.355373574502524\n",
      "1482 Train Loss 8.282778 Test Loss 11.355905831164305\n",
      "1483 Train Loss 8.282598 Test Loss 11.356379759946362\n",
      "1484 Train Loss 8.2825165 Test Loss 11.357257878051957\n",
      "1485 Train Loss 8.2824545 Test Loss 11.356684397922216\n",
      "1486 Train Loss 8.282213 Test Loss 11.35683604866258\n",
      "1487 Train Loss 8.282079 Test Loss 11.356710304257254\n",
      "1488 Train Loss 8.281953 Test Loss 11.35639952166587\n",
      "1489 Train Loss 8.281859 Test Loss 11.355895083479368\n",
      "1490 Train Loss 8.28173 Test Loss 11.355316341460714\n",
      "1491 Train Loss 8.281611 Test Loss 11.354637865703939\n",
      "1492 Train Loss 8.281394 Test Loss 11.353605501797313\n",
      "1493 Train Loss 8.281509 Test Loss 11.351450937531492\n",
      "1494 Train Loss 8.28121 Test Loss 11.352645075044238\n",
      "1495 Train Loss 8.280852 Test Loss 11.350846681992069\n",
      "1496 Train Loss 8.280349 Test Loss 11.349628609420037\n",
      "1497 Train Loss 8.434801 Test Loss 11.339101373309395\n",
      "1498 Train Loss 8.280329 Test Loss 11.349440603986034\n",
      "1499 Train Loss 8.279974 Test Loss 11.34941761660767\n",
      "1500 Train Loss 8.281592 Test Loss 11.346759866713994\n",
      "1501 Train Loss 8.279854 Test Loss 11.348855064887543\n",
      "1502 Train Loss 8.279888 Test Loss 11.349751179549301\n",
      "1503 Train Loss 8.2797165 Test Loss 11.349279011844608\n",
      "1504 Train Loss 8.279484 Test Loss 11.349715938933617\n",
      "1505 Train Loss 8.279317 Test Loss 11.350486227432457\n",
      "1506 Train Loss 8.279105 Test Loss 11.351693598551265\n",
      "1507 Train Loss 8.27896 Test Loss 11.35167321115863\n",
      "1508 Train Loss 8.278708 Test Loss 11.35162979588299\n",
      "1509 Train Loss 8.278486 Test Loss 11.351350894576463\n",
      "1510 Train Loss 8.278252 Test Loss 11.351377392937474\n",
      "1511 Train Loss 8.278069 Test Loss 11.35158018923657\n",
      "1512 Train Loss 8.277916 Test Loss 11.352054734830558\n",
      "1513 Train Loss 8.277756 Test Loss 11.352487591304909\n",
      "1514 Train Loss 8.277609 Test Loss 11.35301171344173\n",
      "1515 Train Loss 8.286048 Test Loss 11.348042986331043\n",
      "1516 Train Loss 8.277595 Test Loss 11.352793138754784\n",
      "1517 Train Loss 8.277627 Test Loss 11.35248949594184\n",
      "1518 Train Loss 8.277514 Test Loss 11.352652630072797\n",
      "1519 Train Loss 8.277326 Test Loss 11.353051947829286\n",
      "1520 Train Loss 8.277199 Test Loss 11.352624604655082\n",
      "1521 Train Loss 8.27702 Test Loss 11.351765169605526\n",
      "1522 Train Loss 8.276924 Test Loss 11.351650407854073\n",
      "1523 Train Loss 8.276766 Test Loss 11.35177335806845\n",
      "1524 Train Loss 8.276667 Test Loss 11.352040838382763\n",
      "1525 Train Loss 8.276922 Test Loss 11.353515221609422\n",
      "1526 Train Loss 8.276629 Test Loss 11.352424611975556\n",
      "1527 Train Loss 8.276546 Test Loss 11.353217260605032\n",
      "1528 Train Loss 8.28489 Test Loss 11.351794665924858\n",
      "1529 Train Loss 8.276469 Test Loss 11.353074867368806\n",
      "1530 Train Loss 8.276145 Test Loss 11.353058798420477\n",
      "1531 Train Loss 8.275897 Test Loss 11.353460236374856\n",
      "1532 Train Loss 8.275785 Test Loss 11.353947809597166\n",
      "1533 Train Loss 8.275794 Test Loss 11.355528198325818\n",
      "1534 Train Loss 8.275497 Test Loss 11.354719839339902\n",
      "1535 Train Loss 8.275283 Test Loss 11.354577394056143\n",
      "1536 Train Loss 8.275026 Test Loss 11.354436935613865\n",
      "1537 Train Loss 8.274892 Test Loss 11.354291481880718\n",
      "1538 Train Loss 8.274782 Test Loss 11.35424281592665\n",
      "1539 Train Loss 8.274661 Test Loss 11.354124481587444\n",
      "1540 Train Loss 8.274549 Test Loss 11.353547695146997\n",
      "1541 Train Loss 8.274412 Test Loss 11.3533798691559\n",
      "1542 Train Loss 8.274228 Test Loss 11.353224407875938\n",
      "1543 Train Loss 8.273971 Test Loss 11.352422953846299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1544 Train Loss 8.273725 Test Loss 11.351525514811579\n",
      "1545 Train Loss 8.273214 Test Loss 11.34964428947564\n",
      "1546 Train Loss 8.272689 Test Loss 11.34816064341406\n",
      "1547 Train Loss 8.272073 Test Loss 11.347064912925841\n",
      "1548 Train Loss 8.279174 Test Loss 11.346763409971508\n",
      "1549 Train Loss 8.272008 Test Loss 11.34701465662026\n",
      "1550 Train Loss 8.271602 Test Loss 11.347241339563086\n",
      "1551 Train Loss 8.2713175 Test Loss 11.347949838884272\n",
      "1552 Train Loss 8.271095 Test Loss 11.348665797801795\n",
      "1553 Train Loss 8.270819 Test Loss 11.348814194239635\n",
      "1554 Train Loss 8.270581 Test Loss 11.348336328555211\n",
      "1555 Train Loss 9.525701 Test Loss 11.359228545590682\n",
      "1556 Train Loss 8.2706375 Test Loss 11.348303327445477\n",
      "1557 Train Loss 8.270519 Test Loss 11.348320001599014\n",
      "1558 Train Loss 8.269942 Test Loss 11.347772641205156\n",
      "1559 Train Loss 8.269462 Test Loss 11.347641765182834\n",
      "1560 Train Loss 8.269219 Test Loss 11.347949878446189\n",
      "1561 Train Loss 8.268997 Test Loss 11.348473805554963\n",
      "1562 Train Loss 8.268855 Test Loss 11.34866897845544\n",
      "1563 Train Loss 8.2687235 Test Loss 11.348535256733724\n",
      "1564 Train Loss 8.268575 Test Loss 11.348022090950844\n",
      "1565 Train Loss 8.268379 Test Loss 11.347221069938847\n",
      "1566 Train Loss 8.269742 Test Loss 11.344280724339734\n",
      "1567 Train Loss 8.268279 Test Loss 11.346607273150774\n",
      "1568 Train Loss 8.272611 Test Loss 11.342128025207053\n",
      "1569 Train Loss 8.267996 Test Loss 11.345721331689596\n",
      "1570 Train Loss 8.2677765 Test Loss 11.345893918608333\n",
      "1571 Train Loss 8.267519 Test Loss 11.34623403586624\n",
      "1572 Train Loss 8.267447 Test Loss 11.34631511893972\n",
      "1573 Train Loss 8.26835 Test Loss 11.348566530722383\n",
      "1574 Train Loss 8.267379 Test Loss 11.346783631346812\n",
      "1575 Train Loss 8.26718 Test Loss 11.346856332198755\n",
      "1576 Train Loss 8.267096 Test Loss 11.346787149999075\n",
      "1577 Train Loss 8.267024 Test Loss 11.346788174692318\n",
      "1578 Train Loss 8.266944 Test Loss 11.346992770685413\n",
      "1579 Train Loss 8.266772 Test Loss 11.347744020247083\n",
      "1580 Train Loss 8.266564 Test Loss 11.348682776453789\n",
      "1581 Train Loss 8.266339 Test Loss 11.349952246300154\n",
      "1582 Train Loss 8.266261 Test Loss 11.35047915646061\n",
      "1583 Train Loss 8.320187 Test Loss 11.364438459880846\n",
      "1584 Train Loss 8.266154 Test Loss 11.351003366891037\n",
      "1585 Train Loss 8.266042 Test Loss 11.350646178181332\n",
      "1586 Train Loss 8.265878 Test Loss 11.350267368543896\n",
      "1587 Train Loss 8.26574 Test Loss 11.35013923466971\n",
      "1588 Train Loss 8.265602 Test Loss 11.350182964977995\n",
      "1589 Train Loss 8.265464 Test Loss 11.350290027114752\n",
      "1590 Train Loss 8.265483 Test Loss 11.350596614250994\n",
      "1591 Train Loss 8.265404 Test Loss 11.35042913841844\n",
      "1592 Train Loss 8.49769 Test Loss 11.347283474610105\n",
      "1593 Train Loss 8.265273 Test Loss 11.350285463256734\n",
      "1594 Train Loss 8.265162 Test Loss 11.349956235921576\n",
      "1595 Train Loss 8.264954 Test Loss 11.349165513470119\n",
      "1596 Train Loss 8.264869 Test Loss 11.34905584430621\n",
      "1597 Train Loss 8.264705 Test Loss 11.349045993496125\n",
      "1598 Train Loss 8.264616 Test Loss 11.349122982347069\n",
      "1599 Train Loss 8.264464 Test Loss 11.349109686937272\n",
      "1600 Train Loss 8.264268 Test Loss 11.34891199174896\n",
      "1601 Train Loss 8.264145 Test Loss 11.348172869927637\n",
      "1602 Train Loss 8.264018 Test Loss 11.34832965303995\n",
      "1603 Train Loss 8.263858 Test Loss 11.348233698299566\n",
      "1604 Train Loss 8.263667 Test Loss 11.348025599366498\n",
      "1605 Train Loss 8.263526 Test Loss 11.347923241893497\n",
      "1606 Train Loss 8.263405 Test Loss 11.348041393229261\n",
      "1607 Train Loss 8.263282 Test Loss 11.348250135692533\n",
      "1608 Train Loss 8.263134 Test Loss 11.34847935829991\n",
      "1609 Train Loss 8.264872 Test Loss 11.345217353019759\n",
      "1610 Train Loss 8.263083 Test Loss 11.348015600257792\n",
      "1611 Train Loss 8.262861 Test Loss 11.347497846184282\n",
      "1612 Train Loss 8.262654 Test Loss 11.347086062225719\n",
      "1613 Train Loss 8.285826 Test Loss 11.361522772971568\n",
      "1614 Train Loss 8.262611 Test Loss 11.347649893702123\n",
      "1615 Train Loss 8.26218 Test Loss 11.347447285945345\n",
      "1616 Train Loss 8.262 Test Loss 11.348578847410035\n",
      "1617 Train Loss 8.261451 Test Loss 11.349012507684254\n",
      "1618 Train Loss 8.260998 Test Loss 11.350004448167137\n",
      "1619 Train Loss 8.260618 Test Loss 11.351011089104011\n",
      "1620 Train Loss 8.260449 Test Loss 11.351093495043438\n",
      "1621 Train Loss 8.260291 Test Loss 11.3505097166362\n",
      "1622 Train Loss 8.260169 Test Loss 11.349774956112604\n",
      "1623 Train Loss 8.262584 Test Loss 11.342943742997612\n",
      "1624 Train Loss 8.260061 Test Loss 11.348600071717225\n",
      "1625 Train Loss 8.259868 Test Loss 11.34808401742912\n",
      "1626 Train Loss 8.26824 Test Loss 11.349175431841825\n",
      "1627 Train Loss 8.259799 Test Loss 11.34816450232104\n",
      "1628 Train Loss 8.259493 Test Loss 11.347475323671267\n",
      "1629 Train Loss 8.259442 Test Loss 11.346995065870868\n",
      "1630 Train Loss 8.333708 Test Loss 11.350662134786505\n",
      "1631 Train Loss 8.259376 Test Loss 11.347046049527853\n",
      "1632 Train Loss 8.259261 Test Loss 11.347505378858429\n",
      "1633 Train Loss 8.259179 Test Loss 11.3480548072501\n",
      "1634 Train Loss 8.259089 Test Loss 11.348479467393506\n",
      "1635 Train Loss 8.258918 Test Loss 11.34733686767332\n",
      "1636 Train Loss 8.259037 Test Loss 11.348119638219787\n",
      "1637 Train Loss 8.258816 Test Loss 11.34764936696279\n",
      "1638 Train Loss 8.258698 Test Loss 11.347196231577625\n",
      "1639 Train Loss 8.2586155 Test Loss 11.346132226719023\n",
      "1640 Train Loss 8.258507 Test Loss 11.34623122383976\n",
      "1641 Train Loss 8.258428 Test Loss 11.346413714003884\n",
      "1642 Train Loss 8.258309 Test Loss 11.347248772812932\n",
      "1643 Train Loss 8.2581835 Test Loss 11.347404158361694\n",
      "1644 Train Loss 8.258081 Test Loss 11.34778857618247\n",
      "1645 Train Loss 8.258004 Test Loss 11.348097458719883\n",
      "1646 Train Loss 8.257885 Test Loss 11.348638197179922\n",
      "1647 Train Loss 8.257735 Test Loss 11.348873278440108\n",
      "1648 Train Loss 8.2575655 Test Loss 11.349169144933317\n",
      "1649 Train Loss 8.257407 Test Loss 11.349237375533626\n",
      "1650 Train Loss 8.257264 Test Loss 11.349244234858409\n",
      "1651 Train Loss 8.25715 Test Loss 11.349178231356227\n",
      "1652 Train Loss 8.256959 Test Loss 11.34893387342661\n",
      "1653 Train Loss 8.261192 Test Loss 11.348466034867693\n",
      "1654 Train Loss 8.256932 Test Loss 11.348894216642599\n",
      "1655 Train Loss 8.256764 Test Loss 11.348786738306297\n",
      "1656 Train Loss 8.256582 Test Loss 11.348400647880199\n",
      "1657 Train Loss 8.256443 Test Loss 11.34827403115547\n",
      "1658 Train Loss 8.2563095 Test Loss 11.348113134424954\n",
      "1659 Train Loss 8.256202 Test Loss 11.347911972892534\n",
      "1660 Train Loss 8.256121 Test Loss 11.348079958667897\n",
      "1661 Train Loss 8.256194 Test Loss 11.346195382546608\n",
      "1662 Train Loss 8.25602 Test Loss 11.347267015326608\n",
      "1663 Train Loss 8.25593 Test Loss 11.347383153502305\n",
      "1664 Train Loss 8.25581 Test Loss 11.347439691127924\n",
      "1665 Train Loss 8.255637 Test Loss 11.347314685992494\n",
      "1666 Train Loss 8.25534 Test Loss 11.346815907101723\n",
      "1667 Train Loss 8.255241 Test Loss 11.34650167862043\n",
      "1668 Train Loss 8.255132 Test Loss 11.346152050154958\n",
      "1669 Train Loss 8.258407 Test Loss 11.345307660916196\n",
      "1670 Train Loss 8.255083 Test Loss 11.34605872943784\n",
      "1671 Train Loss 8.255323 Test Loss 11.346371028819824\n",
      "1672 Train Loss 8.254911 Test Loss 11.34617734297479\n",
      "1673 Train Loss 8.254781 Test Loss 11.346079786001805\n",
      "1674 Train Loss 8.254525 Test Loss 11.345813995593609\n",
      "1675 Train Loss 8.254258 Test Loss 11.345447677471538\n",
      "1676 Train Loss 8.253831 Test Loss 11.344805010296957\n",
      "1677 Train Loss 8.254561 Test Loss 11.344073460022637\n",
      "1678 Train Loss 8.253696 Test Loss 11.34459764709181\n",
      "1679 Train Loss 8.253484 Test Loss 11.34426128842422\n",
      "1680 Train Loss 8.256311 Test Loss 11.343821347399919\n",
      "1681 Train Loss 8.2534485 Test Loss 11.34420767599301\n",
      "1682 Train Loss 8.253275 Test Loss 11.343971861494763\n",
      "1683 Train Loss 8.254477 Test Loss 11.343884422153927\n",
      "1684 Train Loss 8.2531805 Test Loss 11.343942765681803\n",
      "1685 Train Loss 8.253087 Test Loss 11.344077656679369\n",
      "1686 Train Loss 8.253011 Test Loss 11.344250291147288\n",
      "1687 Train Loss 8.25284 Test Loss 11.343914799592572\n",
      "1688 Train Loss 8.25255 Test Loss 11.344109941637452\n",
      "1689 Train Loss 8.252277 Test Loss 11.343604521357598\n",
      "1690 Train Loss 8.25198 Test Loss 11.342839954639699\n",
      "1691 Train Loss 8.251757 Test Loss 11.342060646515273\n",
      "1692 Train Loss 8.251427 Test Loss 11.340468012382669\n",
      "1693 Train Loss 8.251278 Test Loss 11.339441926230693\n",
      "1694 Train Loss 8.25118 Test Loss 11.338867893603727\n",
      "1695 Train Loss 8.251581 Test Loss 11.336999812961585\n",
      "1696 Train Loss 8.25109 Test Loss 11.338297553211719\n",
      "1697 Train Loss 8.25093 Test Loss 11.338735094456053\n",
      "1698 Train Loss 8.250756 Test Loss 11.33906797429604\n",
      "1699 Train Loss 8.250479 Test Loss 11.339867403624046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 Train Loss 8.250383 Test Loss 11.339826071145096\n",
      "1701 Train Loss 8.250254 Test Loss 11.339681165192482\n",
      "1702 Train Loss 8.250097 Test Loss 11.339962499230603\n",
      "1703 Train Loss 8.814668 Test Loss 11.314427431612572\n",
      "1704 Train Loss 8.250033 Test Loss 11.339575217211543\n",
      "1705 Train Loss 8.249707 Test Loss 11.340755468819786\n",
      "1706 Train Loss 8.249122 Test Loss 11.341176758604014\n",
      "1707 Train Loss 8.248722 Test Loss 11.34086680603091\n",
      "1708 Train Loss 8.247785 Test Loss 11.339880389286003\n",
      "1709 Train Loss 8.273455 Test Loss 11.341050970114267\n",
      "1710 Train Loss 8.247722 Test Loss 11.339917636801328\n",
      "1711 Train Loss 8.247076 Test Loss 11.339539707480267\n",
      "1712 Train Loss 8.256352 Test Loss 11.35089530720665\n",
      "1713 Train Loss 8.246858 Test Loss 11.341016190166602\n",
      "1714 Train Loss 8.245816 Test Loss 11.341510807098512\n",
      "1715 Train Loss 8.245464 Test Loss 11.342146949697762\n",
      "1716 Train Loss 8.245088 Test Loss 11.343395547945365\n",
      "1717 Train Loss 8.244993 Test Loss 11.343775095167702\n",
      "1718 Train Loss 8.244863 Test Loss 11.344135716212868\n",
      "1719 Train Loss 8.244751 Test Loss 11.344296708497398\n",
      "1720 Train Loss 8.244554 Test Loss 11.344558962259942\n",
      "1721 Train Loss 8.244338 Test Loss 11.344871010448566\n",
      "1722 Train Loss 8.244161 Test Loss 11.345214656831093\n",
      "1723 Train Loss 8.24403 Test Loss 11.345225077660025\n",
      "1724 Train Loss 8.2439 Test Loss 11.345085850318085\n",
      "1725 Train Loss 8.243765 Test Loss 11.344790632711728\n",
      "1726 Train Loss 8.243556 Test Loss 11.344193656168652\n",
      "1727 Train Loss 8.243443 Test Loss 11.343443563386595\n",
      "1728 Train Loss 8.243295 Test Loss 11.343155169917157\n",
      "1729 Train Loss 8.243186 Test Loss 11.34329745369318\n",
      "1730 Train Loss 8.251482 Test Loss 11.343495850351257\n",
      "1731 Train Loss 8.243116 Test Loss 11.343308875430512\n",
      "1732 Train Loss 8.24299 Test Loss 11.343525424293489\n",
      "1733 Train Loss 8.242788 Test Loss 11.343651841548747\n",
      "1734 Train Loss 8.242628 Test Loss 11.343612596742457\n",
      "1735 Train Loss 8.242515 Test Loss 11.343460298305637\n",
      "1736 Train Loss 8.24236 Test Loss 11.343206482725487\n",
      "1737 Train Loss 8.249036 Test Loss 11.34357017648153\n",
      "1738 Train Loss 8.24235 Test Loss 11.34321844142242\n",
      "1739 Train Loss 8.242165 Test Loss 11.343071893346895\n",
      "1740 Train Loss 8.241869 Test Loss 11.34287822533894\n",
      "1741 Train Loss 8.241612 Test Loss 11.342811946305558\n",
      "1742 Train Loss 8.241258 Test Loss 11.343276503047262\n",
      "1743 Train Loss 8.241116 Test Loss 11.343524897821714\n",
      "1744 Train Loss 8.240925 Test Loss 11.34328860779386\n",
      "1745 Train Loss 8.240712 Test Loss 11.343333982214961\n",
      "1746 Train Loss 8.240626 Test Loss 11.343348052311994\n",
      "1747 Train Loss 8.24061 Test Loss 11.342833939613401\n",
      "1748 Train Loss 8.240443 Test Loss 11.343084935876886\n",
      "1749 Train Loss 8.240317 Test Loss 11.342753022731381\n",
      "1750 Train Loss 8.240156 Test Loss 11.342033787247486\n",
      "1751 Train Loss 8.24 Test Loss 11.3414049112422\n",
      "1752 Train Loss 8.239775 Test Loss 11.34073836830742\n",
      "1753 Train Loss 8.2395525 Test Loss 11.340210722851355\n",
      "1754 Train Loss 8.239582 Test Loss 11.341585734639732\n",
      "1755 Train Loss 8.23941 Test Loss 11.340865477149586\n",
      "1756 Train Loss 8.23923 Test Loss 11.34021772005292\n",
      "1757 Train Loss 8.238853 Test Loss 11.34082672275238\n",
      "1758 Train Loss 8.238637 Test Loss 11.343843141005632\n",
      "1759 Train Loss 8.239388 Test Loss 11.341837902102311\n",
      "1760 Train Loss 8.238391 Test Loss 11.343182621250591\n",
      "1761 Train Loss 8.2382345 Test Loss 11.341221635141217\n",
      "1762 Train Loss 8.23811 Test Loss 11.341579305107603\n",
      "1763 Train Loss 8.237962 Test Loss 11.341729446420928\n",
      "1764 Train Loss 8.237839 Test Loss 11.341573991603395\n",
      "1765 Train Loss 8.23763 Test Loss 11.341180626401135\n",
      "1766 Train Loss 8.237413 Test Loss 11.340838815506144\n",
      "1767 Train Loss 8.237149 Test Loss 11.340603293141442\n",
      "1768 Train Loss 8.236941 Test Loss 11.340586173343944\n",
      "1769 Train Loss 8.236755 Test Loss 11.34163087663957\n",
      "1770 Train Loss 8.236624 Test Loss 11.34152853947249\n",
      "1771 Train Loss 8.238068 Test Loss 11.342389252373515\n",
      "1772 Train Loss 8.236579 Test Loss 11.341654838612326\n",
      "1773 Train Loss 8.236269 Test Loss 11.34071182243642\n",
      "1774 Train Loss 8.236112 Test Loss 11.340679247820907\n",
      "1775 Train Loss 8.235793 Test Loss 11.340354394363874\n",
      "1776 Train Loss 8.235629 Test Loss 11.340174039190174\n",
      "1777 Train Loss 8.235189 Test Loss 11.339882270218204\n",
      "1778 Train Loss 8.253611 Test Loss 11.33112374980576\n",
      "1779 Train Loss 8.235178 Test Loss 11.339658392160025\n",
      "1780 Train Loss 8.234919 Test Loss 11.339622667984543\n",
      "1781 Train Loss 8.234662 Test Loss 11.339874849135516\n",
      "1782 Train Loss 8.234484 Test Loss 11.340312806696115\n",
      "1783 Train Loss 8.234349 Test Loss 11.340824082105119\n",
      "1784 Train Loss 8.234301 Test Loss 11.341446714900583\n",
      "1785 Train Loss 8.234074 Test Loss 11.341771492127561\n",
      "1786 Train Loss 8.233899 Test Loss 11.341848236243901\n",
      "1787 Train Loss 8.233591 Test Loss 11.3421871315687\n",
      "1788 Train Loss 8.233423 Test Loss 11.342426850072968\n",
      "1789 Train Loss 8.233149 Test Loss 11.342211139941815\n",
      "1790 Train Loss 8.232865 Test Loss 11.341772979379014\n",
      "1791 Train Loss 8.2327 Test Loss 11.340920124372865\n",
      "1792 Train Loss 8.2325535 Test Loss 11.340869433446791\n",
      "1793 Train Loss 8.232354 Test Loss 11.340296038493731\n",
      "1794 Train Loss 8.232252 Test Loss 11.339921646944742\n",
      "1795 Train Loss 8.232142 Test Loss 11.339222722684625\n",
      "1796 Train Loss 8.232132 Test Loss 11.338523493357503\n",
      "1797 Train Loss 8.232065 Test Loss 11.338858299446542\n",
      "1798 Train Loss 8.23197 Test Loss 11.33922007263912\n",
      "1799 Train Loss 8.231817 Test Loss 11.339242508711271\n",
      "1800 Train Loss 8.231453 Test Loss 11.33899869583111\n",
      "1801 Train Loss 8.231245 Test Loss 11.339031904974387\n",
      "1802 Train Loss 8.230955 Test Loss 11.339112490177277\n",
      "1803 Train Loss 8.231057 Test Loss 11.34134682920506\n",
      "1804 Train Loss 8.230884 Test Loss 11.339974720912004\n",
      "1805 Train Loss 8.230907 Test Loss 11.339779540401125\n",
      "1806 Train Loss 8.230688 Test Loss 11.339879718338059\n",
      "1807 Train Loss 8.230588 Test Loss 11.339837689580358\n",
      "1808 Train Loss 8.230419 Test Loss 11.339784566649028\n",
      "1809 Train Loss 8.230318 Test Loss 11.339876037053616\n",
      "1810 Train Loss 8.230107 Test Loss 11.340091136818309\n",
      "1811 Train Loss 8.229952 Test Loss 11.340336021531877\n",
      "1812 Train Loss 8.22985 Test Loss 11.340247487698132\n",
      "1813 Train Loss 8.229776 Test Loss 11.340076267895428\n",
      "1814 Train Loss 8.230811 Test Loss 11.339446236242045\n",
      "1815 Train Loss 8.22972 Test Loss 11.339955986970876\n",
      "1816 Train Loss 8.229651 Test Loss 11.33989363453906\n",
      "1817 Train Loss 8.229144 Test Loss 11.339551797107413\n",
      "1818 Train Loss 8.228811 Test Loss 11.338528818361\n",
      "1819 Train Loss 8.228494 Test Loss 11.337273596979358\n",
      "1820 Train Loss 8.22948 Test Loss 11.33420216245596\n",
      "1821 Train Loss 8.228344 Test Loss 11.336446728215394\n",
      "1822 Train Loss 8.228024 Test Loss 11.33570188433152\n",
      "1823 Train Loss 8.227693 Test Loss 11.335241968947017\n",
      "1824 Train Loss 8.227549 Test Loss 11.335395742159475\n",
      "1825 Train Loss 8.227401 Test Loss 11.335588860531127\n",
      "1826 Train Loss 8.227041 Test Loss 11.336509024793964\n",
      "1827 Train Loss 8.226783 Test Loss 11.336695192027111\n",
      "1828 Train Loss 8.2264385 Test Loss 11.337066189229168\n",
      "1829 Train Loss 8.226291 Test Loss 11.337123402660161\n",
      "1830 Train Loss 8.22614 Test Loss 11.336763506343136\n",
      "1831 Train Loss 8.22601 Test Loss 11.336709988054993\n",
      "1832 Train Loss 8.225925 Test Loss 11.337115987561551\n",
      "1833 Train Loss 8.225841 Test Loss 11.33703417432631\n",
      "1834 Train Loss 8.225768 Test Loss 11.33724263719728\n",
      "1835 Train Loss 8.225882 Test Loss 11.335563567558447\n",
      "1836 Train Loss 8.225699 Test Loss 11.336595187839329\n",
      "1837 Train Loss 8.225599 Test Loss 11.3361917334398\n",
      "1838 Train Loss 8.225519 Test Loss 11.335908812614264\n",
      "1839 Train Loss 8.22538 Test Loss 11.335032775911797\n",
      "1840 Train Loss 8.225253 Test Loss 11.334851722670102\n",
      "1841 Train Loss 8.224896 Test Loss 11.333049261384087\n",
      "1842 Train Loss 8.224634 Test Loss 11.333909712242377\n",
      "1843 Train Loss 8.225119 Test Loss 11.33702318259517\n",
      "1844 Train Loss 8.224399 Test Loss 11.335013663793864\n",
      "1845 Train Loss 8.22411 Test Loss 11.334845710594081\n",
      "1846 Train Loss 8.223862 Test Loss 11.33393161596521\n",
      "1847 Train Loss 8.223686 Test Loss 11.333450394602641\n",
      "1848 Train Loss 8.224448 Test Loss 11.329988375795146\n",
      "1849 Train Loss 8.223568 Test Loss 11.332510674220153\n",
      "1850 Train Loss 8.223216 Test Loss 11.33215909226574\n",
      "1851 Train Loss 8.223006 Test Loss 11.332558317082901\n",
      "1852 Train Loss 8.222781 Test Loss 11.33311524249118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1853 Train Loss 8.222685 Test Loss 11.333468453721073\n",
      "1854 Train Loss 8.222554 Test Loss 11.333714036612916\n",
      "1855 Train Loss 8.222377 Test Loss 11.333761237409528\n",
      "1856 Train Loss 8.222176 Test Loss 11.333478810537557\n",
      "1857 Train Loss 8.221774 Test Loss 11.333442805919644\n",
      "1858 Train Loss 8.221492 Test Loss 11.332509985466166\n",
      "1859 Train Loss 8.221256 Test Loss 11.331492483872793\n",
      "1860 Train Loss 8.221042 Test Loss 11.330856896046255\n",
      "1861 Train Loss 8.224069 Test Loss 11.325532096319728\n",
      "1862 Train Loss 8.220941 Test Loss 11.33004068511816\n",
      "1863 Train Loss 8.220718 Test Loss 11.329770606565472\n",
      "1864 Train Loss 8.220482 Test Loss 11.329789955888023\n",
      "1865 Train Loss 8.220213 Test Loss 11.329452467890126\n",
      "1866 Train Loss 8.2198715 Test Loss 11.330163765322919\n",
      "1867 Train Loss 8.219555 Test Loss 11.330563218276986\n",
      "1868 Train Loss 8.218881 Test Loss 11.331337212187247\n",
      "1869 Train Loss 8.21861 Test Loss 11.331666734307795\n",
      "1870 Train Loss 8.218406 Test Loss 11.332052426645673\n",
      "1871 Train Loss 8.218057 Test Loss 11.332930372496063\n",
      "1872 Train Loss 8.217966 Test Loss 11.333642708056281\n",
      "1873 Train Loss 8.217874 Test Loss 11.333373647733952\n",
      "1874 Train Loss 8.217752 Test Loss 11.333181018987075\n",
      "1875 Train Loss 8.217665 Test Loss 11.33310333485806\n",
      "1876 Train Loss 8.21754 Test Loss 11.332736719663039\n",
      "1877 Train Loss 8.217491 Test Loss 11.333353539499491\n",
      "1878 Train Loss 8.217318 Test Loss 11.332815169545103\n",
      "1879 Train Loss 8.2171955 Test Loss 11.332526654421743\n",
      "1880 Train Loss 8.2169285 Test Loss 11.33256045838763\n",
      "1881 Train Loss 8.216747 Test Loss 11.332314176708426\n",
      "1882 Train Loss 8.2166195 Test Loss 11.332884565478956\n",
      "1883 Train Loss 8.217149 Test Loss 11.331700829787104\n",
      "1884 Train Loss 8.216564 Test Loss 11.332597920382677\n",
      "1885 Train Loss 8.216487 Test Loss 11.332817476968405\n",
      "1886 Train Loss 8.216313 Test Loss 11.333201587938513\n",
      "1887 Train Loss 8.216245 Test Loss 11.333258610204261\n",
      "1888 Train Loss 8.217107 Test Loss 11.33335847664656\n",
      "1889 Train Loss 8.216136 Test Loss 11.333280345265676\n",
      "1890 Train Loss 8.215944 Test Loss 11.333700321314723\n",
      "1891 Train Loss 8.215746 Test Loss 11.334173166651503\n",
      "1892 Train Loss 8.2155695 Test Loss 11.334834577124031\n",
      "1893 Train Loss 8.218545 Test Loss 11.333379196809426\n",
      "1894 Train Loss 8.215499 Test Loss 11.334638682559016\n",
      "1895 Train Loss 8.215318 Test Loss 11.335747297404462\n",
      "1896 Train Loss 8.214717 Test Loss 11.334984577821535\n",
      "1897 Train Loss 8.214072 Test Loss 11.333856989699777\n",
      "1898 Train Loss 8.213489 Test Loss 11.332543168762797\n",
      "1899 Train Loss 8.2130785 Test Loss 11.331698666104945\n",
      "1900 Train Loss 8.353175 Test Loss 11.322130138784463\n",
      "1901 Train Loss 8.213055 Test Loss 11.331565280105494\n",
      "1902 Train Loss 8.212788 Test Loss 11.33107798163934\n",
      "1903 Train Loss 8.21256 Test Loss 11.330790689866614\n",
      "1904 Train Loss 8.2123375 Test Loss 11.330538263115505\n",
      "1905 Train Loss 8.212204 Test Loss 11.330329820079065\n",
      "1906 Train Loss 8.212105 Test Loss 11.330157357665094\n",
      "1907 Train Loss 8.258925 Test Loss 11.317327890302657\n",
      "1908 Train Loss 8.212096 Test Loss 11.329990460537672\n",
      "1909 Train Loss 8.212156 Test Loss 11.32891678243644\n",
      "1910 Train Loss 8.212027 Test Loss 11.329537161635656\n",
      "1911 Train Loss 8.2119465 Test Loss 11.32924505837474\n",
      "1912 Train Loss 8.211791 Test Loss 11.328582558171352\n",
      "1913 Train Loss 8.211667 Test Loss 11.328033743863609\n",
      "1914 Train Loss 8.212124 Test Loss 11.325515580446815\n",
      "1915 Train Loss 8.211613 Test Loss 11.327399127699623\n",
      "1916 Train Loss 8.2114725 Test Loss 11.327020942266149\n",
      "1917 Train Loss 8.212951 Test Loss 11.322120291254201\n",
      "1918 Train Loss 8.211374 Test Loss 11.326051637756716\n",
      "1919 Train Loss 8.21103 Test Loss 11.326156733336388\n",
      "1920 Train Loss 8.2106905 Test Loss 11.32676931346042\n",
      "1921 Train Loss 8.210581 Test Loss 11.326911487015616\n",
      "1922 Train Loss 8.212237 Test Loss 11.329753008965602\n",
      "1923 Train Loss 8.210328 Test Loss 11.327658120650144\n",
      "1924 Train Loss 8.210148 Test Loss 11.32743180002712\n",
      "1925 Train Loss 8.2100315 Test Loss 11.327142543331309\n",
      "1926 Train Loss 8.209911 Test Loss 11.326903336974338\n",
      "1927 Train Loss 8.2389765 Test Loss 11.316619105865254\n",
      "1928 Train Loss 8.20982 Test Loss 11.326317505050385\n",
      "1929 Train Loss 8.209716 Test Loss 11.326147248969416\n",
      "1930 Train Loss 8.209654 Test Loss 11.325997383299207\n",
      "1931 Train Loss 8.20962 Test Loss 11.325948953686504\n",
      "1932 Train Loss 8.209486 Test Loss 11.32569650293723\n",
      "1933 Train Loss 8.2096615 Test Loss 11.325107260550675\n",
      "1934 Train Loss 8.209409 Test Loss 11.325485735364685\n",
      "1935 Train Loss 8.209258 Test Loss 11.325303114568955\n",
      "1936 Train Loss 8.209125 Test Loss 11.325476233640439\n",
      "1937 Train Loss 8.208889 Test Loss 11.32618529421683\n",
      "1938 Train Loss 8.211285 Test Loss 11.32493866068678\n",
      "1939 Train Loss 8.2088585 Test Loss 11.326052922051378\n",
      "1940 Train Loss 8.208856 Test Loss 11.32703450388982\n",
      "1941 Train Loss 8.208682 Test Loss 11.32654777964324\n",
      "1942 Train Loss 8.208874 Test Loss 11.326347995649112\n",
      "1943 Train Loss 8.208636 Test Loss 11.326486590706555\n",
      "1944 Train Loss 8.208506 Test Loss 11.328270303440895\n",
      "1945 Train Loss 8.208204 Test Loss 11.327487712251836\n",
      "1946 Train Loss 8.208132 Test Loss 11.327341915423228\n",
      "1947 Train Loss 8.207996 Test Loss 11.327377095840808\n",
      "1948 Train Loss 8.207878 Test Loss 11.32749464488598\n",
      "1949 Train Loss 8.207751 Test Loss 11.327715512515118\n",
      "1950 Train Loss 8.207687 Test Loss 11.327458197641755\n",
      "1951 Train Loss 8.207639 Test Loss 11.327159147171669\n",
      "1952 Train Loss 8.207552 Test Loss 11.327292162517217\n",
      "1953 Train Loss 8.20769 Test Loss 11.326729049232352\n",
      "1954 Train Loss 8.207485 Test Loss 11.327084691755278\n",
      "1955 Train Loss 8.20954 Test Loss 11.328850501206885\n",
      "1956 Train Loss 8.207391 Test Loss 11.327376384150652\n",
      "1957 Train Loss 8.207269 Test Loss 11.32719943031093\n",
      "1958 Train Loss 8.207231 Test Loss 11.326265893626582\n",
      "1959 Train Loss 8.207089 Test Loss 11.326698112675567\n",
      "1960 Train Loss 8.207373 Test Loss 11.325382255979319\n",
      "1961 Train Loss 8.206942 Test Loss 11.326210360090457\n",
      "1962 Train Loss 8.206807 Test Loss 11.326259391947126\n",
      "1963 Train Loss 8.20642 Test Loss 11.326324055322193\n",
      "1964 Train Loss 8.206195 Test Loss 11.326336973709244\n",
      "1965 Train Loss 8.205837 Test Loss 11.326377527297005\n",
      "1966 Train Loss 8.205756 Test Loss 11.324658028821643\n",
      "1967 Train Loss 8.2084055 Test Loss 11.328904776941851\n",
      "1968 Train Loss 8.205304 Test Loss 11.325836303717901\n",
      "1969 Train Loss 8.205008 Test Loss 11.326436706168984\n",
      "1970 Train Loss 8.204503 Test Loss 11.32739979908461\n",
      "1971 Train Loss 8.204131 Test Loss 11.32801331849611\n",
      "1972 Train Loss 8.205789 Test Loss 11.335695973569186\n",
      "1973 Train Loss 8.203921 Test Loss 11.329923270501736\n",
      "1974 Train Loss 8.203414 Test Loss 11.33052435857036\n",
      "1975 Train Loss 8.202913 Test Loss 11.330580456430345\n",
      "1976 Train Loss 8.202924 Test Loss 11.33236482950358\n",
      "1977 Train Loss 8.202443 Test Loss 11.331455031535258\n",
      "1978 Train Loss 8.202027 Test Loss 11.330187285341093\n",
      "1979 Train Loss 8.201882 Test Loss 11.329684164929208\n",
      "1980 Train Loss 8.201708 Test Loss 11.32885962124899\n",
      "1981 Train Loss 8.201624 Test Loss 11.328734110478196\n",
      "1982 Train Loss 8.201217 Test Loss 11.327820414284082\n",
      "1983 Train Loss 8.201047 Test Loss 11.328087295303483\n",
      "1984 Train Loss 8.2008915 Test Loss 11.328448846344308\n",
      "1985 Train Loss 8.200787 Test Loss 11.328615927835253\n",
      "1986 Train Loss 8.200546 Test Loss 11.328521663239052\n",
      "1987 Train Loss 8.202965 Test Loss 11.333018576643129\n",
      "1988 Train Loss 8.20048 Test Loss 11.329138757229067\n",
      "1989 Train Loss 8.200392 Test Loss 11.328145212746936\n",
      "1990 Train Loss 8.2001095 Test Loss 11.328573689576015\n",
      "1991 Train Loss 8.199871 Test Loss 11.328955887369787\n",
      "1992 Train Loss 8.199671 Test Loss 11.329329308646177\n",
      "1993 Train Loss 8.199525 Test Loss 11.329454857313587\n",
      "1994 Train Loss 8.199356 Test Loss 11.329640833455947\n",
      "1995 Train Loss 8.199206 Test Loss 11.329588246764935\n",
      "1996 Train Loss 8.199003 Test Loss 11.329513718823323\n",
      "1997 Train Loss 8.267548 Test Loss 11.324865539083165\n",
      "1998 Train Loss 8.198977 Test Loss 11.329412282859366\n",
      "1999 Train Loss 8.198792 Test Loss 11.32931357660864\n",
      "2000 Train Loss 8.198555 Test Loss 11.32903540834524\n",
      "2001 Train Loss 8.198389 Test Loss 11.32884883735977\n",
      "2002 Train Loss 8.198248 Test Loss 11.328724047235847\n",
      "2003 Train Loss 8.198134 Test Loss 11.328784970185955\n",
      "2004 Train Loss 8.1984 Test Loss 11.329294165316751\n",
      "2005 Train Loss 8.198095 Test Loss 11.32891528202115\n",
      "2006 Train Loss 8.197996 Test Loss 11.329313547559114\n",
      "2007 Train Loss 8.201982 Test Loss 11.328551068825503\n",
      "2008 Train Loss 8.197935 Test Loss 11.32921619211875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009 Train Loss 8.1978445 Test Loss 11.329359017276515\n",
      "2010 Train Loss 8.197698 Test Loss 11.328587321672718\n",
      "2011 Train Loss 8.198319 Test Loss 11.33213030974522\n",
      "2012 Train Loss 8.197516 Test Loss 11.32971181396983\n",
      "2013 Train Loss 8.197378 Test Loss 11.330190538146423\n",
      "2014 Train Loss 8.197152 Test Loss 11.330665384022506\n",
      "2015 Train Loss 8.199679 Test Loss 11.329925964798083\n",
      "2016 Train Loss 8.197121 Test Loss 11.330589450809544\n",
      "2017 Train Loss 8.196924 Test Loss 11.330470027609804\n",
      "2018 Train Loss 8.196745 Test Loss 11.329946419941699\n",
      "2019 Train Loss 8.197739 Test Loss 11.327232235910294\n",
      "2020 Train Loss 8.196676 Test Loss 11.32938994526288\n",
      "2021 Train Loss 8.196431 Test Loss 11.32860949725619\n",
      "2022 Train Loss 8.19632 Test Loss 11.328360266355524\n",
      "2023 Train Loss 8.19626 Test Loss 11.32826559731161\n",
      "2024 Train Loss 8.196218 Test Loss 11.32867408418163\n",
      "2025 Train Loss 8.196161 Test Loss 11.328660537011217\n",
      "2026 Train Loss 8.196068 Test Loss 11.328702046046189\n",
      "2027 Train Loss 8.195986 Test Loss 11.32864389721047\n",
      "2028 Train Loss 8.195863 Test Loss 11.328738840392614\n",
      "2029 Train Loss 8.195765 Test Loss 11.328464395255537\n",
      "2030 Train Loss 8.195631 Test Loss 11.328159011831287\n",
      "2031 Train Loss 8.195522 Test Loss 11.32801963632603\n",
      "2032 Train Loss 8.195433 Test Loss 11.32800200387253\n",
      "2033 Train Loss 8.195351 Test Loss 11.328146627258993\n",
      "2034 Train Loss 8.195258 Test Loss 11.328456795220228\n",
      "2035 Train Loss 8.195138 Test Loss 11.328877837825985\n",
      "2036 Train Loss 8.195152 Test Loss 11.32951307452577\n",
      "2037 Train Loss 8.195075 Test Loss 11.329174938622112\n",
      "2038 Train Loss 8.19499 Test Loss 11.330495781970079\n",
      "2039 Train Loss 8.194857 Test Loss 11.330048937098669\n",
      "2040 Train Loss 8.1948 Test Loss 11.329919404396822\n",
      "2041 Train Loss 8.1947565 Test Loss 11.329980386954968\n",
      "2042 Train Loss 8.194708 Test Loss 11.330171979596342\n",
      "2043 Train Loss 8.194657 Test Loss 11.330364704358665\n",
      "2044 Train Loss 8.194601 Test Loss 11.330459735983814\n",
      "2045 Train Loss 8.194544 Test Loss 11.33034954596361\n",
      "2046 Train Loss 8.194503 Test Loss 11.330210889056536\n",
      "2047 Train Loss 8.194855 Test Loss 11.330312631157028\n",
      "2048 Train Loss 8.194488 Test Loss 11.330225413937592\n",
      "2049 Train Loss 8.196615 Test Loss 11.331470344121437\n",
      "2050 Train Loss 8.194473 Test Loss 11.33032041485236\n",
      "2051 Train Loss 8.194429 Test Loss 11.329995524193096\n",
      "2052 Train Loss 8.194372 Test Loss 11.329470447256249\n",
      "2053 Train Loss 8.194825 Test Loss 11.329522965157919\n",
      "2054 Train Loss 8.194363 Test Loss 11.329476267789218\n",
      "2055 Train Loss 8.194321 Test Loss 11.329273262393517\n",
      "2056 Train Loss 8.194278 Test Loss 11.329172133282322\n",
      "2057 Train Loss 8.194229 Test Loss 11.329201765638881\n",
      "2058 Train Loss 8.194188 Test Loss 11.329308103754457\n",
      "2059 Train Loss 8.19416 Test Loss 11.32940976977883\n",
      "2060 Train Loss 8.194126 Test Loss 11.329481549010104\n",
      "2061 Train Loss 8.194071 Test Loss 11.329518048314322\n",
      "2062 Train Loss 8.193982 Test Loss 11.329550000408304\n",
      "2063 Train Loss 8.193923 Test Loss 11.32940717349096\n",
      "2064 Train Loss 8.1956415 Test Loss 11.328979878656666\n",
      "2065 Train Loss 8.19382 Test Loss 11.329322421798908\n",
      "2066 Train Loss 8.193701 Test Loss 11.32927682327999\n",
      "2067 Train Loss 8.193408 Test Loss 11.329102901785893\n",
      "2068 Train Loss 8.193107 Test Loss 11.32879061417161\n",
      "2069 Train Loss 8.192927 Test Loss 11.328547750725264\n",
      "2070 Train Loss 8.192929 Test Loss 11.328132644868438\n",
      "2071 Train Loss 8.192856 Test Loss 11.32833774395484\n",
      "2072 Train Loss 8.198357 Test Loss 11.330036003699034\n",
      "2073 Train Loss 8.19269 Test Loss 11.328562493456445\n",
      "2074 Train Loss 8.192578 Test Loss 11.328487367914793\n",
      "2075 Train Loss 8.192412 Test Loss 11.328408158427408\n",
      "2076 Train Loss 8.192349 Test Loss 11.328402105917126\n",
      "2077 Train Loss 8.192238 Test Loss 11.328438903964438\n",
      "2078 Train Loss 8.192065 Test Loss 11.32855653664044\n",
      "2079 Train Loss 8.1917305 Test Loss 11.329022441447485\n",
      "2080 Train Loss 8.19152 Test Loss 11.329365103193265\n",
      "2081 Train Loss 8.191327 Test Loss 11.32959609281673\n",
      "2082 Train Loss 8.191233 Test Loss 11.329430664905496\n",
      "2083 Train Loss 8.191077 Test Loss 11.329502255978054\n",
      "2084 Train Loss 8.190979 Test Loss 11.329351030953552\n",
      "2085 Train Loss 8.190763 Test Loss 11.329066467412805\n",
      "2086 Train Loss 8.190635 Test Loss 11.329008775830847\n",
      "2087 Train Loss 8.190462 Test Loss 11.329121649520312\n",
      "2088 Train Loss 8.190336 Test Loss 11.329355268133888\n",
      "2089 Train Loss 8.190244 Test Loss 11.329590513501605\n",
      "2090 Train Loss 8.190185 Test Loss 11.32966871557434\n",
      "2091 Train Loss 8.190123 Test Loss 11.329639134125419\n",
      "2092 Train Loss 8.190047 Test Loss 11.329428611273578\n",
      "2093 Train Loss 8.189945 Test Loss 11.32898816174779\n",
      "2094 Train Loss 8.189892 Test Loss 11.32873044868608\n",
      "2095 Train Loss 8.18983 Test Loss 11.328498416959809\n",
      "2096 Train Loss 8.189842 Test Loss 11.328201784785959\n",
      "2097 Train Loss 8.189802 Test Loss 11.328361534054686\n",
      "2098 Train Loss 8.189736 Test Loss 11.327953589120108\n",
      "2099 Train Loss 8.189698 Test Loss 11.3280834278952\n",
      "2100 Train Loss 8.189639 Test Loss 11.328361280949283\n",
      "2101 Train Loss 8.189602 Test Loss 11.32846807659565\n",
      "2102 Train Loss 8.189528 Test Loss 11.328599492423107\n",
      "2103 Train Loss 8.189455 Test Loss 11.3286885304304\n",
      "2104 Train Loss 8.189374 Test Loss 11.328909995482766\n",
      "2105 Train Loss 8.189286 Test Loss 11.329121973545341\n",
      "2106 Train Loss 8.189115 Test Loss 11.329731078259183\n",
      "2107 Train Loss 8.189045 Test Loss 11.330014535841306\n",
      "2108 Train Loss 8.190378 Test Loss 11.331277577299426\n",
      "2109 Train Loss 8.1889105 Test Loss 11.330304746695424\n",
      "2110 Train Loss 8.188827 Test Loss 11.330088881711974\n",
      "2111 Train Loss 8.1889105 Test Loss 11.33102408011308\n",
      "2112 Train Loss 8.188568 Test Loss 11.330510749842103\n",
      "2113 Train Loss 8.188404 Test Loss 11.330237414719525\n",
      "2114 Train Loss 8.188216 Test Loss 11.329775605335302\n",
      "2115 Train Loss 8.188003 Test Loss 11.329225747245262\n",
      "2116 Train Loss 8.188501 Test Loss 11.328589949613272\n",
      "2117 Train Loss 8.187953 Test Loss 11.329075907943144\n",
      "2118 Train Loss 8.187817 Test Loss 11.328379146312688\n",
      "2119 Train Loss 8.18747 Test Loss 11.328788350118105\n",
      "2120 Train Loss 8.187205 Test Loss 11.329208394476773\n",
      "2121 Train Loss 8.186825 Test Loss 11.32948818419876\n",
      "2122 Train Loss 8.210596 Test Loss 11.338664986924936\n",
      "2123 Train Loss 8.186714 Test Loss 11.330093077895297\n",
      "2124 Train Loss 8.186468 Test Loss 11.32992204151967\n",
      "2125 Train Loss 8.251566 Test Loss 11.33229231914097\n",
      "2126 Train Loss 8.186323 Test Loss 11.329818034028634\n",
      "2127 Train Loss 8.1874695 Test Loss 11.328154739624477\n",
      "2128 Train Loss 8.186174 Test Loss 11.32939096047267\n",
      "2129 Train Loss 8.185917 Test Loss 11.328638533222993\n",
      "2130 Train Loss 8.202605 Test Loss 11.335497644962087\n",
      "2131 Train Loss 8.185804 Test Loss 11.329162860862187\n",
      "2132 Train Loss 8.185509 Test Loss 11.328606256618516\n",
      "2133 Train Loss 8.185184 Test Loss 11.32809311627029\n",
      "2134 Train Loss 8.185177 Test Loss 11.327920046276956\n",
      "2135 Train Loss 8.185075 Test Loss 11.328002762675894\n",
      "2136 Train Loss 8.191108 Test Loss 11.326490580536325\n",
      "2137 Train Loss 8.184749 Test Loss 11.327688152272433\n",
      "2138 Train Loss 8.184542 Test Loss 11.32783987699069\n",
      "2139 Train Loss 8.184369 Test Loss 11.328188244690987\n",
      "2140 Train Loss 8.184308 Test Loss 11.32814336003712\n",
      "2141 Train Loss 8.18416 Test Loss 11.327913402995277\n",
      "2142 Train Loss 8.184086 Test Loss 11.327683638177167\n",
      "2143 Train Loss 8.25931 Test Loss 11.355218005660696\n",
      "2144 Train Loss 8.183958 Test Loss 11.328647863850472\n",
      "2145 Train Loss 8.183707 Test Loss 11.329285655593264\n",
      "2146 Train Loss 8.18345 Test Loss 11.330123622887388\n",
      "2147 Train Loss 8.183335 Test Loss 11.329958841356591\n",
      "2148 Train Loss 8.183206 Test Loss 11.32986305809639\n",
      "2149 Train Loss 8.182952 Test Loss 11.329127707982794\n",
      "2150 Train Loss 8.18266 Test Loss 11.328883601845577\n",
      "2151 Train Loss 8.182459 Test Loss 11.328526358619927\n",
      "2152 Train Loss 8.182325 Test Loss 11.328533016755408\n",
      "2153 Train Loss 8.185952 Test Loss 11.32602633791614\n",
      "2154 Train Loss 8.182219 Test Loss 11.328161511477976\n",
      "2155 Train Loss 8.181956 Test Loss 11.328440881581864\n",
      "2156 Train Loss 8.181782 Test Loss 11.328809008358341\n",
      "2157 Train Loss 8.18186 Test Loss 11.32955093610034\n",
      "2158 Train Loss 8.181542 Test Loss 11.329149997886397\n",
      "2159 Train Loss 8.237036 Test Loss 11.349552797296058\n",
      "2160 Train Loss 8.181255 Test Loss 11.330400505846413\n",
      "2161 Train Loss 8.1816 Test Loss 11.332042363396432\n",
      "2162 Train Loss 8.180935 Test Loss 11.331068673985833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2163 Train Loss 8.181015 Test Loss 11.33246810913484\n",
      "2164 Train Loss 8.180558 Test Loss 11.331722635306841\n",
      "2165 Train Loss 8.1801605 Test Loss 11.33080614336486\n",
      "2166 Train Loss 8.180013 Test Loss 11.33031392454963\n",
      "2167 Train Loss 8.179899 Test Loss 11.330081338023588\n",
      "2168 Train Loss 8.179735 Test Loss 11.330068565720904\n",
      "2169 Train Loss 8.201286 Test Loss 11.322619076533533\n",
      "2170 Train Loss 8.179695 Test Loss 11.329720906641764\n",
      "2171 Train Loss 8.180068 Test Loss 11.331281279886944\n",
      "2172 Train Loss 8.179269 Test Loss 11.330394722159177\n",
      "2173 Train Loss 8.179022 Test Loss 11.33140492248375\n",
      "2174 Train Loss 8.178754 Test Loss 11.331990179305667\n",
      "2175 Train Loss 8.178313 Test Loss 11.332117241564701\n",
      "2176 Train Loss 8.178538 Test Loss 11.332562631499783\n",
      "2177 Train Loss 8.178182 Test Loss 11.332285391193828\n",
      "2178 Train Loss 8.177703 Test Loss 11.33266925879176\n",
      "2179 Train Loss 8.177145 Test Loss 11.333376546815352\n",
      "2180 Train Loss 8.178025 Test Loss 11.333631281596238\n",
      "2181 Train Loss 8.176875 Test Loss 11.333459390692429\n",
      "2182 Train Loss 8.176371 Test Loss 11.33405555181657\n",
      "2183 Train Loss 8.176127 Test Loss 11.334184996769224\n",
      "2184 Train Loss 8.17591 Test Loss 11.333923125195438\n",
      "2185 Train Loss 8.1761875 Test Loss 11.334929484126594\n",
      "2186 Train Loss 8.175826 Test Loss 11.334251095679736\n",
      "2187 Train Loss 8.175481 Test Loss 11.333073995918477\n",
      "2188 Train Loss 8.175122 Test Loss 11.333310489630945\n",
      "2189 Train Loss 8.174267 Test Loss 11.334061694857692\n",
      "2190 Train Loss 8.174016 Test Loss 11.334247155876602\n",
      "2191 Train Loss 8.173493 Test Loss 11.33463444517776\n",
      "2192 Train Loss 8.173155 Test Loss 11.334546851200903\n",
      "2193 Train Loss 8.172766 Test Loss 11.334464154243646\n",
      "2194 Train Loss 8.172401 Test Loss 11.333913036114193\n",
      "2195 Train Loss 8.193715 Test Loss 11.33613373540269\n",
      "2196 Train Loss 8.172274 Test Loss 11.334031242123238\n",
      "2197 Train Loss 8.180586 Test Loss 11.339853630218501\n",
      "2198 Train Loss 8.1719475 Test Loss 11.334936594103047\n",
      "2199 Train Loss 8.1716175 Test Loss 11.334865504152376\n",
      "2200 Train Loss 8.17145 Test Loss 11.3346418637837\n",
      "2201 Train Loss 8.171315 Test Loss 11.33494112076907\n",
      "2202 Train Loss 8.171142 Test Loss 11.335437231055751\n",
      "2203 Train Loss 8.170947 Test Loss 11.335671840216676\n",
      "2204 Train Loss 8.170796 Test Loss 11.33534083680292\n",
      "2205 Train Loss 8.179931 Test Loss 11.335270854300711\n",
      "2206 Train Loss 8.170575 Test Loss 11.335336239685862\n",
      "2207 Train Loss 8.170304 Test Loss 11.334932579527651\n",
      "2208 Train Loss 8.219197 Test Loss 11.331959334263475\n",
      "2209 Train Loss 8.170265 Test Loss 11.334845108179444\n",
      "2210 Train Loss 8.171194 Test Loss 11.333215947456\n",
      "2211 Train Loss 8.170057 Test Loss 11.334346818872694\n",
      "2212 Train Loss 8.169623 Test Loss 11.33276416810631\n",
      "2213 Train Loss 8.169428 Test Loss 11.332338300841625\n",
      "2214 Train Loss 8.169046 Test Loss 11.331647423422009\n",
      "2215 Train Loss 8.168767 Test Loss 11.331182876369803\n",
      "2216 Train Loss 8.1694355 Test Loss 11.329967551431878\n",
      "2217 Train Loss 8.168569 Test Loss 11.3307822704245\n",
      "2218 Train Loss 8.173896 Test Loss 11.329455141355574\n",
      "2219 Train Loss 8.168109 Test Loss 11.330511404049748\n",
      "2220 Train Loss 8.167746 Test Loss 11.330532575051627\n",
      "2221 Train Loss 8.166975 Test Loss 11.330897509137156\n",
      "2222 Train Loss 8.166838 Test Loss 11.330776701554171\n",
      "2223 Train Loss 8.166658 Test Loss 11.330540028409784\n",
      "2224 Train Loss 8.173869 Test Loss 11.330781572545389\n",
      "2225 Train Loss 8.166484 Test Loss 11.330523962487012\n",
      "2226 Train Loss 8.166323 Test Loss 11.33072685210602\n",
      "2227 Train Loss 8.166186 Test Loss 11.331145980684042\n",
      "2228 Train Loss 8.166059 Test Loss 11.331633677412736\n",
      "2229 Train Loss 8.198698 Test Loss 11.340134475300635\n",
      "2230 Train Loss 8.165982 Test Loss 11.33199134183549\n",
      "2231 Train Loss 8.165701 Test Loss 11.332797052424498\n",
      "2232 Train Loss 8.165439 Test Loss 11.333251827305228\n",
      "2233 Train Loss 8.165216 Test Loss 11.333215050276172\n",
      "2234 Train Loss 8.164996 Test Loss 11.333351757193661\n",
      "2235 Train Loss 8.166715 Test Loss 11.33018251999781\n",
      "2236 Train Loss 8.164862 Test Loss 11.332680795589614\n",
      "2237 Train Loss 8.16453 Test Loss 11.332935965531515\n",
      "2238 Train Loss 8.163656 Test Loss 11.332481085719957\n",
      "2239 Train Loss 8.163055 Test Loss 11.332769293269727\n",
      "2240 Train Loss 8.162345 Test Loss 11.332809807755796\n",
      "2241 Train Loss 8.161757 Test Loss 11.332459659549608\n",
      "2242 Train Loss 8.160813 Test Loss 11.331021404264016\n",
      "2243 Train Loss 8.17774 Test Loss 11.328025367302898\n",
      "2244 Train Loss 8.160714 Test Loss 11.330768403524091\n",
      "2245 Train Loss 8.159913 Test Loss 11.32955133534075\n",
      "2246 Train Loss 8.159296 Test Loss 11.32841620171473\n",
      "2247 Train Loss 8.158924 Test Loss 11.328441330678311\n",
      "2248 Train Loss 8.158609 Test Loss 11.328367807410503\n",
      "2249 Train Loss 8.158189 Test Loss 11.32905912731689\n",
      "2250 Train Loss 8.157623 Test Loss 11.330140611934763\n",
      "2251 Train Loss 8.157323 Test Loss 11.330269303645041\n",
      "2252 Train Loss 8.156967 Test Loss 11.330107645939357\n",
      "2253 Train Loss 8.15673 Test Loss 11.329968294430032\n",
      "2254 Train Loss 8.165193 Test Loss 11.327869060388618\n",
      "2255 Train Loss 8.156581 Test Loss 11.329706268644586\n",
      "2256 Train Loss 8.156016 Test Loss 11.328179089887417\n",
      "2257 Train Loss 8.15564 Test Loss 11.32796243561895\n",
      "2258 Train Loss 8.155303 Test Loss 11.327770418371786\n",
      "2259 Train Loss 8.154846 Test Loss 11.327957228629845\n",
      "2260 Train Loss 8.154285 Test Loss 11.328126008696902\n",
      "2261 Train Loss 8.154083 Test Loss 11.328854863979085\n",
      "2262 Train Loss 8.217983 Test Loss 11.32609351234684\n",
      "2263 Train Loss 8.153946 Test Loss 11.328726878606787\n",
      "2264 Train Loss 8.153885 Test Loss 11.328839534844366\n",
      "2265 Train Loss 8.153355 Test Loss 11.3281406932611\n",
      "2266 Train Loss 8.152792 Test Loss 11.327185208560998\n",
      "2267 Train Loss 8.152128 Test Loss 11.326109430504474\n",
      "2268 Train Loss 8.153349 Test Loss 11.322865716037262\n",
      "2269 Train Loss 8.151661 Test Loss 11.324955039657093\n",
      "2270 Train Loss 8.151224 Test Loss 11.325196758775373\n",
      "2271 Train Loss 8.1506195 Test Loss 11.325644850620536\n",
      "2272 Train Loss 8.150082 Test Loss 11.326401529230443\n",
      "2273 Train Loss 8.149259 Test Loss 11.328234544159175\n",
      "2274 Train Loss 8.148951 Test Loss 11.32903007630799\n",
      "2275 Train Loss 8.148655 Test Loss 11.329457415293275\n",
      "2276 Train Loss 8.148452 Test Loss 11.329659594737802\n",
      "2277 Train Loss 8.1482315 Test Loss 11.32938906852167\n",
      "2278 Train Loss 8.314316 Test Loss 11.352392563669726\n",
      "2279 Train Loss 8.148149 Test Loss 11.329854878124038\n",
      "2280 Train Loss 8.147455 Test Loss 11.329288115804951\n",
      "2281 Train Loss 8.146502 Test Loss 11.327497083775084\n",
      "2282 Train Loss 8.1459255 Test Loss 11.326196576226415\n",
      "2283 Train Loss 8.145425 Test Loss 11.325647756124468\n",
      "2284 Train Loss 8.145058 Test Loss 11.325534398352616\n",
      "2285 Train Loss 8.144573 Test Loss 11.325458016757215\n",
      "2286 Train Loss 8.146059 Test Loss 11.32296308786802\n",
      "2287 Train Loss 8.144151 Test Loss 11.324609737041545\n",
      "2288 Train Loss 8.143494 Test Loss 11.32450737591209\n",
      "2289 Train Loss 8.14289 Test Loss 11.323387560020535\n",
      "2290 Train Loss 8.14238 Test Loss 11.32406819263245\n",
      "2291 Train Loss 8.141628 Test Loss 11.323631560511563\n",
      "2292 Train Loss 8.140463 Test Loss 11.322540670234648\n",
      "2293 Train Loss 8.139313 Test Loss 11.320558448441373\n",
      "2294 Train Loss 8.138166 Test Loss 11.318820572005702\n",
      "2295 Train Loss 8.1375065 Test Loss 11.317907140068092\n",
      "2296 Train Loss 8.137189 Test Loss 11.316908773676996\n",
      "2297 Train Loss 8.136807 Test Loss 11.316111519129297\n",
      "2298 Train Loss 8.136221 Test Loss 11.31661900977801\n",
      "2299 Train Loss 8.135738 Test Loss 11.316672380072193\n",
      "2300 Train Loss 8.139722 Test Loss 11.319152658203862\n",
      "2301 Train Loss 8.13558 Test Loss 11.317075341689716\n",
      "2302 Train Loss 8.135205 Test Loss 11.316552663132686\n",
      "2303 Train Loss 8.134961 Test Loss 11.316341358942088\n",
      "2304 Train Loss 8.134747 Test Loss 11.316428058949189\n",
      "2305 Train Loss 8.13438 Test Loss 11.317066855568912\n",
      "2306 Train Loss 8.134588 Test Loss 11.319513045618226\n",
      "2307 Train Loss 8.134007 Test Loss 11.318146996428265\n",
      "2308 Train Loss 8.13316 Test Loss 11.32034883227791\n",
      "2309 Train Loss 8.136648 Test Loss 11.323267978340514\n",
      "2310 Train Loss 8.132693 Test Loss 11.321078079447252\n",
      "2311 Train Loss 8.131813 Test Loss 11.319711880378302\n",
      "2312 Train Loss 8.130991 Test Loss 11.318756827434598\n",
      "2313 Train Loss 8.130475 Test Loss 11.318142980180813\n",
      "2314 Train Loss 8.129333 Test Loss 11.317885408457384\n",
      "2315 Train Loss 8.128437 Test Loss 11.318288461173431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2316 Train Loss 8.1294155 Test Loss 11.32224745990761\n",
      "2317 Train Loss 8.128221 Test Loss 11.319451131200145\n",
      "2318 Train Loss 8.14523 Test Loss 11.316050845604575\n",
      "2319 Train Loss 8.127937 Test Loss 11.31906334988455\n",
      "2320 Train Loss 8.127621 Test Loss 11.319051878549239\n",
      "2321 Train Loss 8.127333 Test Loss 11.31912016117796\n",
      "2322 Train Loss 8.127023 Test Loss 11.320496020560478\n",
      "2323 Train Loss 8.126353 Test Loss 11.320865831449485\n",
      "2324 Train Loss 8.125447 Test Loss 11.321642783467253\n",
      "2325 Train Loss 8.124542 Test Loss 11.322627976240788\n",
      "2326 Train Loss 8.123844 Test Loss 11.323497665474886\n",
      "2327 Train Loss 8.123303 Test Loss 11.323913741205326\n",
      "2328 Train Loss 8.122844 Test Loss 11.323784064931461\n",
      "2329 Train Loss 8.122371 Test Loss 11.323614972130008\n",
      "2330 Train Loss 8.121821 Test Loss 11.323354080159477\n",
      "2331 Train Loss 8.12113 Test Loss 11.323503029778273\n",
      "2332 Train Loss 8.122086 Test Loss 11.324075646862243\n",
      "2333 Train Loss 8.120963 Test Loss 11.323663627115518\n",
      "2334 Train Loss 8.120545 Test Loss 11.323575625101238\n",
      "2335 Train Loss 8.119795 Test Loss 11.323948394722583\n",
      "2336 Train Loss 8.119064 Test Loss 11.324581044083502\n",
      "2337 Train Loss 8.118345 Test Loss 11.324951580747495\n",
      "2338 Train Loss 8.11887 Test Loss 11.328324804643112\n",
      "2339 Train Loss 8.117976 Test Loss 11.326267448497582\n",
      "2340 Train Loss 8.117106 Test Loss 11.326110237330433\n",
      "2341 Train Loss 8.116475 Test Loss 11.325953631009686\n",
      "2342 Train Loss 8.1161 Test Loss 11.325779507368843\n",
      "2343 Train Loss 8.115711 Test Loss 11.325212432366598\n",
      "2344 Train Loss 8.115303 Test Loss 11.32463722735116\n",
      "2345 Train Loss 8.114869 Test Loss 11.322925707723646\n",
      "2346 Train Loss 8.114622 Test Loss 11.321624302501434\n",
      "2347 Train Loss 8.114756 Test Loss 11.317723330030956\n",
      "2348 Train Loss 8.1143265 Test Loss 11.319857120821263\n",
      "2349 Train Loss 8.113957 Test Loss 11.319988360848143\n",
      "2350 Train Loss 8.112999 Test Loss 11.319394365994382\n",
      "2351 Train Loss 8.112096 Test Loss 11.317459786955794\n",
      "2352 Train Loss 8.110866 Test Loss 11.313950678490949\n",
      "2353 Train Loss 8.11015 Test Loss 11.311597640139269\n",
      "2354 Train Loss 8.109835 Test Loss 11.309052903464096\n",
      "2355 Train Loss 8.138362 Test Loss 11.29105977017545\n",
      "2356 Train Loss 8.109346 Test Loss 11.306740012384662\n",
      "2357 Train Loss 8.108183 Test Loss 11.307768396957906\n",
      "2358 Train Loss 8.106929 Test Loss 11.307721149879178\n",
      "2359 Train Loss 8.10622 Test Loss 11.307122646109518\n",
      "2360 Train Loss 8.106669 Test Loss 11.305279783725355\n",
      "2361 Train Loss 8.105875 Test Loss 11.306380423173012\n",
      "2362 Train Loss 8.10513 Test Loss 11.302521248271626\n",
      "2363 Train Loss 8.10433 Test Loss 11.302489613518805\n",
      "2364 Train Loss 8.102856 Test Loss 11.303524990169644\n",
      "2365 Train Loss 8.102467 Test Loss 11.305215051456036\n",
      "2366 Train Loss 8.101971 Test Loss 11.304201353641142\n",
      "2367 Train Loss 8.101113 Test Loss 11.303628024816428\n",
      "2368 Train Loss 8.100327 Test Loss 11.30363802810862\n",
      "2369 Train Loss 8.106818 Test Loss 11.305462778074853\n",
      "2370 Train Loss 8.099905 Test Loss 11.303932690865173\n",
      "2371 Train Loss 8.099144 Test Loss 11.304118523273269\n",
      "2372 Train Loss 8.098576 Test Loss 11.306046662681535\n",
      "2373 Train Loss 8.0980835 Test Loss 11.306087928970108\n",
      "2374 Train Loss 8.09748 Test Loss 11.30609503063868\n",
      "2375 Train Loss 8.096798 Test Loss 11.305808724999768\n",
      "2376 Train Loss 8.096198 Test Loss 11.30447903871273\n",
      "2377 Train Loss 8.095313 Test Loss 11.302815884494247\n",
      "2378 Train Loss 8.094434 Test Loss 11.299105186230031\n",
      "2379 Train Loss 8.09759 Test Loss 11.300249202511614\n",
      "2380 Train Loss 8.093849 Test Loss 11.299409868584007\n",
      "2381 Train Loss 8.092541 Test Loss 11.298140131755117\n",
      "2382 Train Loss 8.090949 Test Loss 11.297402353949531\n",
      "2383 Train Loss 8.089039 Test Loss 11.296581872820514\n",
      "2384 Train Loss 8.086913 Test Loss 11.294669010733767\n",
      "2385 Train Loss 8.085502 Test Loss 11.29336831148302\n",
      "2386 Train Loss 8.08462 Test Loss 11.291222893409746\n",
      "2387 Train Loss 8.083903 Test Loss 11.289320052028692\n",
      "2388 Train Loss 8.083212 Test Loss 11.28728114840986\n",
      "2389 Train Loss 8.082464 Test Loss 11.284437645711932\n",
      "2390 Train Loss 8.081893 Test Loss 11.281558771603352\n",
      "2391 Train Loss 8.081341 Test Loss 11.279361048229752\n",
      "2392 Train Loss 8.080876 Test Loss 11.27747555213553\n",
      "2393 Train Loss 8.091543 Test Loss 11.276817256304453\n",
      "2394 Train Loss 8.080799 Test Loss 11.277399503905688\n",
      "2395 Train Loss 8.080277 Test Loss 11.276100931963104\n",
      "2396 Train Loss 8.0796 Test Loss 11.274712109279776\n",
      "2397 Train Loss 8.07949 Test Loss 11.27154737143312\n",
      "2398 Train Loss 8.080188 Test Loss 11.269689629519243\n",
      "2399 Train Loss 8.078704 Test Loss 11.270747360262542\n",
      "2400 Train Loss 8.078031 Test Loss 11.271932414022904\n",
      "2401 Train Loss 8.077297 Test Loss 11.272108614506744\n",
      "2402 Train Loss 8.076595 Test Loss 11.27254445869708\n",
      "2403 Train Loss 8.075642 Test Loss 11.272379000608373\n",
      "2404 Train Loss 8.074241 Test Loss 11.271905801470002\n",
      "2405 Train Loss 8.074083 Test Loss 11.272161173930321\n",
      "2406 Train Loss 8.072725 Test Loss 11.266805599179754\n",
      "2407 Train Loss 8.07046 Test Loss 11.269699194918985\n",
      "2408 Train Loss 8.069817 Test Loss 11.268294534440738\n",
      "2409 Train Loss 8.068703 Test Loss 11.265711576805922\n",
      "2410 Train Loss 8.068073 Test Loss 11.262745877091165\n",
      "2411 Train Loss 8.0672245 Test Loss 11.260352559899168\n",
      "2412 Train Loss 8.066382 Test Loss 11.259331686770823\n",
      "2413 Train Loss 8.065544 Test Loss 11.257000345207459\n",
      "2414 Train Loss 8.064488 Test Loss 11.254107592736055\n",
      "2415 Train Loss 8.06303 Test Loss 11.25171514903308\n",
      "2416 Train Loss 8.061487 Test Loss 11.24872781056098\n",
      "2417 Train Loss 8.233957 Test Loss 11.261451962224994\n",
      "2418 Train Loss 8.061411 Test Loss 11.248807188062587\n",
      "2419 Train Loss 8.060505 Test Loss 11.247466851323527\n",
      "2420 Train Loss 8.059747 Test Loss 11.24693557007178\n",
      "2421 Train Loss 8.058986 Test Loss 11.247950555000138\n",
      "2422 Train Loss 8.058893 Test Loss 11.242782102931214\n",
      "2423 Train Loss 8.058297 Test Loss 11.245239893639726\n",
      "2424 Train Loss 8.057552 Test Loss 11.246306989536542\n",
      "2425 Train Loss 8.056885 Test Loss 11.246485511409224\n",
      "2426 Train Loss 8.056459 Test Loss 11.246944561381234\n",
      "2427 Train Loss 8.055472 Test Loss 11.2466601667664\n",
      "2428 Train Loss 8.056645 Test Loss 11.247889210800132\n",
      "2429 Train Loss 8.054998 Test Loss 11.247073670124742\n",
      "2430 Train Loss 8.053422 Test Loss 11.246570431920599\n",
      "2431 Train Loss 8.052426 Test Loss 11.245237860329807\n",
      "2432 Train Loss 8.050821 Test Loss 11.243917711815925\n",
      "2433 Train Loss 8.049921 Test Loss 11.242071985409359\n",
      "2434 Train Loss 8.0604105 Test Loss 11.236380419449883\n",
      "2435 Train Loss 8.049628 Test Loss 11.241259211697944\n",
      "2436 Train Loss 8.052283 Test Loss 11.238145867580672\n",
      "2437 Train Loss 8.048991 Test Loss 11.240280003939128\n",
      "2438 Train Loss 8.048133 Test Loss 11.241694940436112\n",
      "2439 Train Loss 8.053373 Test Loss 11.245965826688934\n",
      "2440 Train Loss 8.047254 Test Loss 11.242837544625909\n",
      "2441 Train Loss 8.046093 Test Loss 11.243233264255538\n",
      "2442 Train Loss 8.045206 Test Loss 11.244573638575963\n",
      "2443 Train Loss 8.044614 Test Loss 11.244147063840575\n",
      "2444 Train Loss 8.045257 Test Loss 11.245231072586902\n",
      "2445 Train Loss 8.044347 Test Loss 11.244519075722572\n",
      "2446 Train Loss 8.059782 Test Loss 11.24341482729021\n",
      "2447 Train Loss 8.043753 Test Loss 11.244239376587261\n",
      "2448 Train Loss 8.0433 Test Loss 11.24309925204027\n",
      "2449 Train Loss 8.042081 Test Loss 11.24172370925523\n",
      "2450 Train Loss 8.040961 Test Loss 11.238631814832958\n",
      "2451 Train Loss 8.039728 Test Loss 11.236863754231699\n",
      "2452 Train Loss 8.037175 Test Loss 11.23356275441816\n",
      "2453 Train Loss 8.039063 Test Loss 11.226243083999247\n",
      "2454 Train Loss 8.035604 Test Loss 11.2305241794317\n",
      "2455 Train Loss 8.03231 Test Loss 11.227776425186828\n",
      "2456 Train Loss 8.031839 Test Loss 11.218081837813832\n",
      "2457 Train Loss 8.031621 Test Loss 11.221843955990638\n",
      "2458 Train Loss 8.03019 Test Loss 11.220039377185882\n",
      "2459 Train Loss 8.02881 Test Loss 11.223453491690826\n",
      "2460 Train Loss 8.027841 Test Loss 11.2228072986338\n",
      "2461 Train Loss 8.030086 Test Loss 11.220087030434788\n",
      "2462 Train Loss 8.027477 Test Loss 11.222051561679388\n",
      "2463 Train Loss 8.029725 Test Loss 11.216406086343024\n",
      "2464 Train Loss 8.026487 Test Loss 11.219984342978682\n",
      "2465 Train Loss 8.025774 Test Loss 11.219338424464773\n",
      "2466 Train Loss 8.0252075 Test Loss 11.218883481521914\n",
      "2467 Train Loss 8.02706 Test Loss 11.216943844000681\n",
      "2468 Train Loss 8.024971 Test Loss 11.218398175896509\n",
      "2469 Train Loss 8.031329 Test Loss 11.223148778102741\n",
      "2470 Train Loss 8.02382 Test Loss 11.219702018166581\n",
      "2471 Train Loss 8.022608 Test Loss 11.219786244019675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2472 Train Loss 8.020341 Test Loss 11.219511225435483\n",
      "2473 Train Loss 8.019003 Test Loss 11.216858188148692\n",
      "2474 Train Loss 8.017872 Test Loss 11.213729362212426\n",
      "2475 Train Loss 8.016501 Test Loss 11.20869941797677\n",
      "2476 Train Loss 8.014666 Test Loss 11.200355467256374\n",
      "2477 Train Loss 8.013277 Test Loss 11.195499471477037\n",
      "2478 Train Loss 8.012108 Test Loss 11.197359036230695\n",
      "2479 Train Loss 8.011192 Test Loss 11.197794019343176\n",
      "2480 Train Loss 8.010256 Test Loss 11.19702466294921\n",
      "2481 Train Loss 8.009211 Test Loss 11.194759373874406\n",
      "2482 Train Loss 8.008387 Test Loss 11.192756202099627\n",
      "2483 Train Loss 8.007017 Test Loss 11.191275133739252\n",
      "2484 Train Loss 8.005222 Test Loss 11.189620275392736\n",
      "2485 Train Loss 8.003889 Test Loss 11.188874851113631\n",
      "2486 Train Loss 8.001168 Test Loss 11.186456756154078\n",
      "2487 Train Loss 8.002031 Test Loss 11.183525160103084\n",
      "2488 Train Loss 7.9999123 Test Loss 11.185156356449058\n",
      "2489 Train Loss 8.027854 Test Loss 11.17794577724014\n",
      "2490 Train Loss 7.9995584 Test Loss 11.184364619582377\n",
      "2491 Train Loss 8.041226 Test Loss 11.163726365199382\n",
      "2492 Train Loss 7.998856 Test Loss 11.18160621300933\n",
      "2493 Train Loss 8.014687 Test Loss 11.187448129640126\n",
      "2494 Train Loss 7.998376 Test Loss 11.182361698747654\n",
      "2495 Train Loss 7.996506 Test Loss 11.181481131745107\n",
      "2496 Train Loss 7.995054 Test Loss 11.177565238397822\n",
      "2497 Train Loss 7.9942737 Test Loss 11.176793910803301\n",
      "2498 Train Loss 7.9925694 Test Loss 11.170082890984627\n",
      "2499 Train Loss 7.9906774 Test Loss 11.16420837546474\n",
      "2500 Train Loss 7.9965935 Test Loss 11.15413582050522\n",
      "2501 Train Loss 7.9893985 Test Loss 11.161130082478637\n",
      "2502 Train Loss 7.987541 Test Loss 11.158841299803187\n",
      "2503 Train Loss 7.985556 Test Loss 11.150188643971237\n",
      "2504 Train Loss 7.980609 Test Loss 11.135156937917307\n",
      "2505 Train Loss 8.05487 Test Loss 11.078068028340144\n",
      "2506 Train Loss 7.975413 Test Loss 11.11291821605116\n",
      "2507 Train Loss 7.9805803 Test Loss 11.095605902585673\n",
      "2508 Train Loss 7.9717355 Test Loss 11.105740642904356\n",
      "2509 Train Loss 7.9658446 Test Loss 11.091002095694893\n",
      "2510 Train Loss 7.95845 Test Loss 11.08196931596587\n",
      "2511 Train Loss 7.95494 Test Loss 11.080579636161472\n",
      "2512 Train Loss 7.9592304 Test Loss 11.060712408030357\n",
      "2513 Train Loss 7.9529285 Test Loss 11.072610510291451\n",
      "2514 Train Loss 7.951259 Test Loss 11.066177820945791\n",
      "2515 Train Loss 7.945601 Test Loss 11.064729189230729\n",
      "2516 Train Loss 7.9432864 Test Loss 11.066301276959173\n",
      "2517 Train Loss 7.9413266 Test Loss 11.065767289852591\n",
      "2518 Train Loss 7.9456973 Test Loss 11.054643358673921\n",
      "2519 Train Loss 7.940002 Test Loss 11.062080438997395\n",
      "2520 Train Loss 7.948814 Test Loss 11.045298291798742\n",
      "2521 Train Loss 7.9371524 Test Loss 11.05638528393371\n",
      "2522 Train Loss 7.9345922 Test Loss 11.053234958931794\n",
      "2523 Train Loss 7.932758 Test Loss 11.05613329861051\n",
      "2524 Train Loss 7.930644 Test Loss 11.055758829704676\n",
      "2525 Train Loss 7.929103 Test Loss 11.058558570956682\n",
      "2526 Train Loss 7.927638 Test Loss 11.056568059379536\n",
      "2527 Train Loss 7.925618 Test Loss 11.05376530582357\n",
      "2528 Train Loss 7.922892 Test Loss 11.048233281703869\n",
      "2529 Train Loss 7.9192734 Test Loss 11.044108809457292\n",
      "2530 Train Loss 7.916368 Test Loss 11.039017280878072\n",
      "2531 Train Loss 7.914115 Test Loss 11.036518726539514\n",
      "2532 Train Loss 7.912098 Test Loss 11.038757542905591\n",
      "2533 Train Loss 7.9093966 Test Loss 11.040140609939254\n",
      "2534 Train Loss 7.90782 Test Loss 11.041015414747841\n",
      "2535 Train Loss 7.906659 Test Loss 11.040865894904284\n",
      "2536 Train Loss 7.905657 Test Loss 11.03747439697114\n",
      "2537 Train Loss 7.904198 Test Loss 11.034060668843399\n",
      "2538 Train Loss 7.9018226 Test Loss 11.030829529887479\n",
      "2539 Train Loss 7.8985276 Test Loss 11.024748740081813\n",
      "2540 Train Loss 7.896593 Test Loss 11.022997719510846\n",
      "2541 Train Loss 7.894556 Test Loss 11.020350284423873\n",
      "2542 Train Loss 7.8907743 Test Loss 11.014982003590392\n",
      "2543 Train Loss 7.88802 Test Loss 11.008362281755762\n",
      "2544 Train Loss 7.889833 Test Loss 11.005939203891012\n",
      "2545 Train Loss 7.886307 Test Loss 11.007338180965137\n",
      "2546 Train Loss 7.881728 Test Loss 11.002688267646512\n",
      "2547 Train Loss 7.8771443 Test Loss 10.99788484736643\n",
      "2548 Train Loss 7.875713 Test Loss 10.99095577326564\n",
      "2549 Train Loss 7.875615 Test Loss 10.993612896600746\n",
      "2550 Train Loss 7.8741918 Test Loss 10.99226581851915\n",
      "2551 Train Loss 7.8716516 Test Loss 10.993608911848982\n",
      "2552 Train Loss 7.868062 Test Loss 10.98794964949446\n",
      "2553 Train Loss 7.8660316 Test Loss 10.987386606729972\n",
      "2554 Train Loss 7.864211 Test Loss 10.978297350175517\n",
      "2555 Train Loss 7.86189 Test Loss 10.975800767719955\n",
      "2556 Train Loss 7.8598485 Test Loss 10.975388364453714\n",
      "2557 Train Loss 7.858769 Test Loss 10.974807413003889\n",
      "2558 Train Loss 7.857862 Test Loss 10.975517381952024\n",
      "2559 Train Loss 7.855723 Test Loss 10.976051790430704\n",
      "2560 Train Loss 7.852662 Test Loss 10.973909536903987\n",
      "2561 Train Loss 7.849976 Test Loss 10.970699007612675\n",
      "2562 Train Loss 7.8475156 Test Loss 10.965873947413618\n",
      "2563 Train Loss 7.856113 Test Loss 10.962379771160737\n",
      "2564 Train Loss 7.8461866 Test Loss 10.964928208466961\n",
      "2565 Train Loss 7.844379 Test Loss 10.964668096380608\n",
      "2566 Train Loss 7.8428087 Test Loss 10.964615461708847\n",
      "2567 Train Loss 7.841552 Test Loss 10.964931105642577\n",
      "2568 Train Loss 7.840343 Test Loss 10.963556771636245\n",
      "2569 Train Loss 7.83926 Test Loss 10.961916723914841\n",
      "2570 Train Loss 7.837209 Test Loss 10.95834677115316\n",
      "2571 Train Loss 7.8335614 Test Loss 10.953275852720576\n",
      "2572 Train Loss 7.831935 Test Loss 10.94652954042345\n",
      "2573 Train Loss 7.8235645 Test Loss 10.943513009195694\n",
      "2574 Train Loss 7.8187313 Test Loss 10.946823051639344\n",
      "2575 Train Loss 7.8145013 Test Loss 10.945538239108084\n",
      "2576 Train Loss 7.81207 Test Loss 10.95072667966356\n",
      "2577 Train Loss 7.8092613 Test Loss 10.94413261907074\n",
      "2578 Train Loss 7.8090086 Test Loss 10.934338372537924\n",
      "2579 Train Loss 7.8068814 Test Loss 10.93903244319415\n",
      "2580 Train Loss 7.803827 Test Loss 10.935354447991779\n",
      "2581 Train Loss 7.8016624 Test Loss 10.931082067651827\n",
      "2582 Train Loss 7.799745 Test Loss 10.928536753120282\n",
      "2583 Train Loss 7.7978086 Test Loss 10.926756356937794\n",
      "2584 Train Loss 7.796061 Test Loss 10.925551849608361\n",
      "2585 Train Loss 7.7945533 Test Loss 10.925450855920472\n",
      "2586 Train Loss 7.793373 Test Loss 10.924791673032338\n",
      "2587 Train Loss 7.7920594 Test Loss 10.924736913209388\n",
      "2588 Train Loss 7.7905526 Test Loss 10.923628197736196\n",
      "2589 Train Loss 7.7895184 Test Loss 10.923688610137985\n",
      "2590 Train Loss 7.7872205 Test Loss 10.92508669919458\n",
      "2591 Train Loss 7.7848196 Test Loss 10.925413839212586\n",
      "2592 Train Loss 7.7830663 Test Loss 10.925101592796425\n",
      "2593 Train Loss 7.7810345 Test Loss 10.92355727867979\n",
      "2594 Train Loss 7.823744 Test Loss 10.905442801484133\n",
      "2595 Train Loss 7.78022 Test Loss 10.921175261197812\n",
      "2596 Train Loss 7.7770553 Test Loss 10.916457021809467\n",
      "2597 Train Loss 7.773902 Test Loss 10.91284262374176\n",
      "2598 Train Loss 7.7739305 Test Loss 10.904827589424265\n",
      "2599 Train Loss 7.7718086 Test Loss 10.90878190376853\n",
      "2600 Train Loss 7.7687483 Test Loss 10.905021010857011\n",
      "2601 Train Loss 7.7664967 Test Loss 10.90743216371576\n",
      "2602 Train Loss 7.7650886 Test Loss 10.906481703084264\n",
      "2603 Train Loss 7.7641096 Test Loss 10.906106387840742\n",
      "2604 Train Loss 7.76308 Test Loss 10.905614562234575\n",
      "2605 Train Loss 7.7621617 Test Loss 10.902080937456198\n",
      "2606 Train Loss 7.7613482 Test Loss 10.9001829673132\n",
      "2607 Train Loss 7.760704 Test Loss 10.898000341868542\n",
      "2608 Train Loss 7.760133 Test Loss 10.897637761346543\n",
      "2609 Train Loss 7.759228 Test Loss 10.896648722649493\n",
      "2610 Train Loss 7.7583547 Test Loss 10.897089778763235\n",
      "2611 Train Loss 7.7568264 Test Loss 10.896367800268514\n",
      "2612 Train Loss 7.7540097 Test Loss 10.89472397806261\n",
      "2613 Train Loss 7.751505 Test Loss 10.891577852002579\n",
      "2614 Train Loss 7.748963 Test Loss 10.889075919132338\n",
      "2615 Train Loss 7.7469296 Test Loss 10.884577942192768\n",
      "2616 Train Loss 7.7445807 Test Loss 10.882569066330227\n",
      "2617 Train Loss 7.742808 Test Loss 10.882855160318613\n",
      "2618 Train Loss 7.741359 Test Loss 10.88214584269946\n",
      "2619 Train Loss 7.7402897 Test Loss 10.880436635513126\n",
      "2620 Train Loss 7.738933 Test Loss 10.879925875911796\n",
      "2621 Train Loss 7.737939 Test Loss 10.877863063188363\n",
      "2622 Train Loss 7.736747 Test Loss 10.875959543416686\n",
      "2623 Train Loss 7.7357492 Test Loss 10.872126679505545\n",
      "2624 Train Loss 7.7349863 Test Loss 10.869994263824829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625 Train Loss 7.7343535 Test Loss 10.867032242644743\n",
      "2626 Train Loss 7.7338743 Test Loss 10.865935572953349\n",
      "2627 Train Loss 7.733491 Test Loss 10.865861105325761\n",
      "2628 Train Loss 7.73306 Test Loss 10.865185589643774\n",
      "2629 Train Loss 7.7322316 Test Loss 10.863781919410666\n",
      "2630 Train Loss 7.731023 Test Loss 10.862114323544\n",
      "2631 Train Loss 7.729351 Test Loss 10.859593060160066\n",
      "2632 Train Loss 7.7275486 Test Loss 10.857966165445053\n",
      "2633 Train Loss 7.725975 Test Loss 10.856830552502306\n",
      "2634 Train Loss 7.7238674 Test Loss 10.857599270060085\n",
      "2635 Train Loss 7.7620115 Test Loss 10.853816000871886\n",
      "2636 Train Loss 7.723014 Test Loss 10.857020537000034\n",
      "2637 Train Loss 7.7206745 Test Loss 10.857861408955143\n",
      "2638 Train Loss 7.7179995 Test Loss 10.85983851638503\n",
      "2639 Train Loss 7.7164607 Test Loss 10.859282738094592\n",
      "2640 Train Loss 7.7150874 Test Loss 10.855519709175775\n",
      "2641 Train Loss 7.7137036 Test Loss 10.855378780888412\n",
      "2642 Train Loss 7.712631 Test Loss 10.853353685667328\n",
      "2643 Train Loss 7.7116218 Test Loss 10.852163114206217\n",
      "2644 Train Loss 7.710399 Test Loss 10.850217495255524\n",
      "2645 Train Loss 7.708952 Test Loss 10.847574110143567\n",
      "2646 Train Loss 7.707542 Test Loss 10.843650939977774\n",
      "2647 Train Loss 7.7060094 Test Loss 10.843995633389795\n",
      "2648 Train Loss 7.703821 Test Loss 10.843353171009477\n",
      "2649 Train Loss 7.701971 Test Loss 10.841822525045664\n",
      "2650 Train Loss 7.6993017 Test Loss 10.837419363490703\n",
      "2651 Train Loss 7.698066 Test Loss 10.834402395494035\n",
      "2652 Train Loss 7.6971827 Test Loss 10.830396417612214\n",
      "2653 Train Loss 7.6967325 Test Loss 10.828089091838821\n",
      "2654 Train Loss 7.696385 Test Loss 10.825652983216491\n",
      "2655 Train Loss 7.696132 Test Loss 10.824161547890256\n",
      "2656 Train Loss 7.69567 Test Loss 10.82282849789995\n",
      "2657 Train Loss 7.694606 Test Loss 10.82052379284777\n",
      "2658 Train Loss 7.693691 Test Loss 10.819526901823346\n",
      "2659 Train Loss 7.6928396 Test Loss 10.81949624033415\n",
      "2660 Train Loss 7.69218 Test Loss 10.819714866731408\n",
      "2661 Train Loss 7.691557 Test Loss 10.820999915271045\n",
      "2662 Train Loss 7.6909313 Test Loss 10.820360149468364\n",
      "2663 Train Loss 7.690279 Test Loss 10.820154581797167\n",
      "2664 Train Loss 7.694534 Test Loss 10.818830585814453\n",
      "2665 Train Loss 7.689977 Test Loss 10.819869574347331\n",
      "2666 Train Loss 7.6889563 Test Loss 10.81875811373674\n",
      "2667 Train Loss 7.687736 Test Loss 10.818787352632699\n",
      "2668 Train Loss 7.686251 Test Loss 10.818784087082214\n",
      "2669 Train Loss 7.6838665 Test Loss 10.81815200314016\n",
      "2670 Train Loss 7.6947384 Test Loss 10.813323635085297\n",
      "2671 Train Loss 7.6827006 Test Loss 10.816951466017423\n",
      "2672 Train Loss 7.679794 Test Loss 10.813723028220435\n",
      "2673 Train Loss 7.6772156 Test Loss 10.808880569701278\n",
      "2674 Train Loss 7.6741066 Test Loss 10.799984387056131\n",
      "2675 Train Loss 7.6717587 Test Loss 10.795250519345194\n",
      "2676 Train Loss 7.6695523 Test Loss 10.785951654867201\n",
      "2677 Train Loss 7.668074 Test Loss 10.775190613793054\n",
      "2678 Train Loss 7.6664357 Test Loss 10.770457011417559\n",
      "2679 Train Loss 7.6648436 Test Loss 10.763011258255409\n",
      "2680 Train Loss 7.6633267 Test Loss 10.76095529425654\n",
      "2681 Train Loss 7.6623755 Test Loss 10.755310466091295\n",
      "2682 Train Loss 7.6608195 Test Loss 10.754539441691923\n",
      "2683 Train Loss 7.6582756 Test Loss 10.747027028663094\n",
      "2684 Train Loss 7.6578636 Test Loss 10.72062106712477\n",
      "2685 Train Loss 7.6542344 Test Loss 10.732989650692435\n",
      "2686 Train Loss 7.6477766 Test Loss 10.727047927100662\n",
      "2687 Train Loss 7.64401 Test Loss 10.71819036513279\n",
      "2688 Train Loss 7.6439204 Test Loss 10.723312988134929\n",
      "2689 Train Loss 7.6428733 Test Loss 10.720767897488964\n",
      "2690 Train Loss 7.64154 Test Loss 10.71582426253196\n",
      "2691 Train Loss 7.640024 Test Loss 10.712365769764453\n",
      "2692 Train Loss 7.637455 Test Loss 10.70795029518507\n",
      "2693 Train Loss 7.6353335 Test Loss 10.708302212669144\n",
      "2694 Train Loss 7.6338367 Test Loss 10.710511225135988\n",
      "2695 Train Loss 7.632618 Test Loss 10.710945311526181\n",
      "2696 Train Loss 7.6307507 Test Loss 10.71219226258857\n",
      "2697 Train Loss 7.626611 Test Loss 10.710218863825798\n",
      "2698 Train Loss 7.6218348 Test Loss 10.707399346223495\n",
      "2699 Train Loss 7.6208878 Test Loss 10.700294794518422\n",
      "2700 Train Loss 7.61706 Test Loss 10.70083567806852\n",
      "2701 Train Loss 7.614852 Test Loss 10.69957160057937\n",
      "2702 Train Loss 7.6125975 Test Loss 10.697038909811123\n",
      "2703 Train Loss 7.6106834 Test Loss 10.695439168787011\n",
      "2704 Train Loss 7.6088295 Test Loss 10.69440430465027\n",
      "2705 Train Loss 7.60753 Test Loss 10.695151435634191\n",
      "2706 Train Loss 7.605885 Test Loss 10.694494051132144\n",
      "2707 Train Loss 7.6048594 Test Loss 10.695488045062332\n",
      "2708 Train Loss 7.603312 Test Loss 10.69589804567695\n",
      "2709 Train Loss 7.6023874 Test Loss 10.695583132699646\n",
      "2710 Train Loss 7.6011157 Test Loss 10.693621250782279\n",
      "2711 Train Loss 7.599922 Test Loss 10.69596998343082\n",
      "2712 Train Loss 7.602118 Test Loss 10.691405946197381\n",
      "2713 Train Loss 7.599423 Test Loss 10.69457708499592\n",
      "2714 Train Loss 7.5980926 Test Loss 10.694756689591033\n",
      "2715 Train Loss 7.596466 Test Loss 10.696153351340927\n",
      "2716 Train Loss 7.594895 Test Loss 10.697150246558346\n",
      "2717 Train Loss 7.5917478 Test Loss 10.69826750083849\n",
      "2718 Train Loss 7.5889378 Test Loss 10.697186642569788\n",
      "2719 Train Loss 7.584889 Test Loss 10.694969758650622\n",
      "2720 Train Loss 7.580928 Test Loss 10.693505784172755\n",
      "2721 Train Loss 7.5754514 Test Loss 10.691836775972424\n",
      "2722 Train Loss 7.572436 Test Loss 10.693052922869168\n",
      "2723 Train Loss 7.569819 Test Loss 10.695313513424406\n",
      "2724 Train Loss 7.5684414 Test Loss 10.696469443945041\n",
      "2725 Train Loss 7.5668173 Test Loss 10.69699415165182\n",
      "2726 Train Loss 7.56512 Test Loss 10.694428378924902\n",
      "2727 Train Loss 7.564372 Test Loss 10.694305326557243\n",
      "2728 Train Loss 7.5635467 Test Loss 10.692303642123811\n",
      "2729 Train Loss 7.562728 Test Loss 10.69056526456552\n",
      "2730 Train Loss 7.5618362 Test Loss 10.690286467729065\n",
      "2731 Train Loss 7.5791554 Test Loss 10.70149111030229\n",
      "2732 Train Loss 7.561463 Test Loss 10.691704582724146\n",
      "2733 Train Loss 7.5605774 Test Loss 10.690393559918329\n",
      "2734 Train Loss 7.558469 Test Loss 10.692639740593586\n",
      "2735 Train Loss 7.556533 Test Loss 10.693602656274866\n",
      "2736 Train Loss 7.554894 Test Loss 10.694201477621602\n",
      "2737 Train Loss 7.553008 Test Loss 10.694677188572266\n",
      "2738 Train Loss 7.551344 Test Loss 10.69424031201764\n",
      "2739 Train Loss 7.549743 Test Loss 10.690809984978298\n",
      "2740 Train Loss 7.557521 Test Loss 10.689851694652909\n",
      "2741 Train Loss 7.548968 Test Loss 10.69055919972027\n",
      "2742 Train Loss 7.54747 Test Loss 10.688591049292327\n",
      "2743 Train Loss 7.545579 Test Loss 10.685277773237642\n",
      "2744 Train Loss 7.543928 Test Loss 10.684147794442454\n",
      "2745 Train Loss 7.542002 Test Loss 10.68358448743215\n",
      "2746 Train Loss 7.540288 Test Loss 10.68299412216962\n",
      "2747 Train Loss 7.539467 Test Loss 10.682383869209849\n",
      "2748 Train Loss 7.53894 Test Loss 10.682203495946439\n",
      "2749 Train Loss 7.538496 Test Loss 10.681480141756433\n",
      "2750 Train Loss 7.538001 Test Loss 10.681103645938725\n",
      "2751 Train Loss 7.537422 Test Loss 10.681268835932956\n",
      "2752 Train Loss 7.5391006 Test Loss 10.676261520365426\n",
      "2753 Train Loss 7.5372167 Test Loss 10.680001913903897\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c3962ae3baeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPINN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPINN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"only 'strong_wolfe' is supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m                     \u001b[0mx_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clone_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                     \u001b[0;32mdef\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36m_clone_param\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clone_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous_format\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clone_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous_format\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_reps = 1\n",
    "\n",
    "train_loss_full = []\n",
    "test_loss_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(reps)\n",
    "    N_u = 1000 #Total number of data points for 'u'\n",
    "    N_f = 10000 #Total number of collocation points \n",
    "    \n",
    "    X_f_train_np_array, X_u_train_np_array, u_train_np_array = trainingdata(N_u,N_f,reps*32)\n",
    "        \n",
    "    X_f_train = torch.from_numpy(X_f_train_np_array).float().to(device)\n",
    "    X_u_train = torch.from_numpy(X_u_train_np_array).float().to(device)\n",
    "    u_train = torch.from_numpy(u_train_np_array).float().to(device)\n",
    "        \n",
    "    #u = torch.from_numpy(u_true).float().to(device)\n",
    "    f_hat = torch.zeros(X_f_train.shape[0],1).to(device)\n",
    "        \n",
    "\n",
    "    #X_u_test_tensor = torch.from_numpy(X_u_test).float().to(device)\n",
    "    'Convert to tensor and send to GPU'\n",
    "\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    #layers = np.array([2,512,512,1])\n",
    "    PINN = Sequentialmodel(layers)\n",
    "       \n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    'L-BFGS Optimizer'\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                                  max_iter = 10000, \n",
    "                                  max_eval = None, \n",
    "                                  tolerance_grad = -1, \n",
    "                                  tolerance_change = -1, \n",
    "                                  history_size = 100, \n",
    "                                  line_search_fn = 'strong_wolfe')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    optimizer.step(PINN.closure)\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(PINN.train_loss)\n",
    "    test_loss_full.append(PINN.test_loss)\n",
    "    elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(PINN.beta_val)\n",
    "    \n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_loss\": test_loss_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label}\n",
    "savemat(label+'.mat', mdic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINN.W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = PINN.test(xt_test_tensor)\n",
    "\n",
    "cmap = plt.cm.rainbow\n",
    "plt.imshow(u_pred.reshape(100,256),cmap = cmap,aspect =1,vmin=-10,vmax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_u_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(u_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(u_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.rainbow\n",
    "plt.imshow(u_true.reshape(100,256),cmap = cmap,aspect = 1,vmin=-10,vmax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(u_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.rainbow\n",
    "plt.imshow(np.transpose(np.abs(u_pred - u_true).reshape(100,256)),cmap = cmap,aspect = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0 \n",
    "for i in range(10):\n",
    "    print(test_loss_full[i][-1])\n",
    "    a = a + test_loss_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
