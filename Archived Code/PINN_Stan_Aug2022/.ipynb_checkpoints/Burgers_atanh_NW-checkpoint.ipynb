{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('burgers_shock.mat')  \t# Load data from file\n",
    "\n",
    "pi = torch.from_numpy(np.array(np.pi)).double().to(device)\n",
    "\n",
    "label = \"QCRE_2D_5_atanh_NW\"\n",
    "x = data['x']                                   # 256 points between -1 and 1 [256x1]\n",
    "t = data['t']                                   # 100 time points between 0 and 1 [100x1] \n",
    "usol = data['usol']   \n",
    "\n",
    "#usol = usol/1000# solution of 256x100 grid points\n",
    "\n",
    "X, T = np.meshgrid(x,t)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_u,N_f,seed):\n",
    "\n",
    "    '''Boundary Conditions'''\n",
    "    #Initial Condition -1 =< x =<1 and t = 0  \n",
    "    leftedge_x = np.hstack((X[0,:][:,None], T[0,:][:,None])) #L1\n",
    "    leftedge_u = usol[:,0][:,None]\n",
    "\n",
    "    #Boundary Condition x = -1 and 0 =< t =<1\n",
    "    bottomedge_x = np.hstack((X[:,0][:,None], T[:,0][:,None])) #L2\n",
    "    bottomedge_u = usol[-1,:][:,None]\n",
    "\n",
    "    #Boundary Condition x = 1 and 0 =< t =<1\n",
    "    topedge_x = np.hstack((X[:,-1][:,None], T[:,0][:,None])) #L3\n",
    "    topedge_u = usol[0,:][:,None]\n",
    "\n",
    "    all_X_u_train = np.vstack([leftedge_x, bottomedge_x, topedge_x]) # X_u_train [456,2] (456 = 256(L1)+100(L2)+100(L3))\n",
    "    all_u_train = np.vstack([leftedge_u, bottomedge_u, topedge_u])   #corresponding u [456x1]\n",
    "\n",
    "    #choose random N_u points for training\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.choice(all_X_u_train.shape[0], N_u, replace=False) \n",
    "\n",
    "    X_u_train = all_X_u_train[idx, :] #choose indices from  set 'idx' (x,t)\n",
    "    u_train = all_u_train[idx,:]      #choose corresponding u\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    X_f_train = lb + (ub-lb)*lhs(2,N_f) \n",
    "    X_f_train = np.vstack((X_f_train, X_u_train)) # append training points to collocation points \n",
    "\n",
    "    return X_f_train, X_u_train, u_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_u_test = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "\n",
    "# Domain bounds\n",
    "lb = X_u_test[0]  # [-1. 0.]\n",
    "ub = X_u_test[-1] # [1.  0.99]\n",
    "\n",
    "'''\n",
    "   Fortran Style ('F') flatten,stacked column wise!\n",
    "   u = [c1 \n",
    "        c2\n",
    "        .\n",
    "        .\n",
    "        cn]\n",
    "\n",
    "   u =  [25600x1] \n",
    "'''\n",
    "u_true = usol.flatten('F')[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        '''\n",
    "        Alternatively:\n",
    "        \n",
    "        *all layers are callable \n",
    "    \n",
    "        Simple linear Layers\n",
    "        self.fc1 = nn.Linear(2,50)\n",
    "        self.fc2 = nn.Linear(50,50)\n",
    "        self.fc3 = nn.Linear(50,50)\n",
    "        self.fc4 = nn.Linear(50,1)\n",
    "        \n",
    "        '''\n",
    "    \n",
    "        'Xavier Normal Initialization'\n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            # weights from a normal distribution with \n",
    "            # Recommended gain value for tanh = 5/3?\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        self.alpha_val = []\n",
    "        \n",
    "        self.n = torch.tensor(1.0)\n",
    "        \n",
    "    'foward pass'\n",
    "    def forward(self,x):\n",
    "         if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "         u_b = torch.from_numpy(ub).float().to(device)\n",
    "         l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "         #preprocessing input \n",
    "         x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "         #convert to float\n",
    "         a = x.float()\n",
    "                        \n",
    "         '''     \n",
    "         Alternatively:\n",
    "        \n",
    "         a = self.activation(self.fc1(a))\n",
    "         a = self.activation(self.fc2(a))\n",
    "         a = self.activation(self.fc3(a))\n",
    "         a = self.fc4(a)\n",
    "         \n",
    "         '''\n",
    "        \n",
    "         for i in range(len(layers)-2):\n",
    "                z = self.linears[i](a)\n",
    "                a = self.activation(self.n*self.alpha[:,i]*z)  \n",
    "         \n",
    "         a = self.linears[-1](a)\n",
    "        \n",
    "         return a\n",
    "                        \n",
    "    def loss_BC(self,x,y):\n",
    "                \n",
    "        loss_u = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_u\n",
    "    \n",
    "    def loss_PDE(self, x_to_train_f,f_hat):\n",
    "        \n",
    "        nu = 0.01/pi\n",
    "                \n",
    "        x_1_f = x_to_train_f[:,[0]]\n",
    "        x_2_f = x_to_train_f[:,[1]]\n",
    "                        \n",
    "        g = x_to_train_f.clone()\n",
    "                        \n",
    "        g.requires_grad = True\n",
    "        \n",
    "        u = self.forward(g)\n",
    "                \n",
    "        u_x_t = autograd.grad(u,g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "                                \n",
    "        u_xx_tt = autograd.grad(u_x_t,g,torch.ones(x_to_train_f.shape).to(device), create_graph=True)[0]\n",
    "                                                            \n",
    "        u_x = u_x_t[:,[0]]\n",
    "        \n",
    "        u_t = u_x_t[:,[1]]\n",
    "        \n",
    "        u_xx = u_xx_tt[:,[0]]\n",
    "                                        \n",
    "        f = u_t + (self.forward(g))*(u_x) - (nu)*u_xx \n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,x,y,x_to_train_f,f_hat):\n",
    "\n",
    "        loss_u = self.loss_BC(x,y)\n",
    "        loss_f = self.loss_PDE(x_to_train_f,f_hat)\n",
    "        \n",
    "        loss_val = loss_u + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    'callable for optimizer'                                       \n",
    "    def closure(self):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = self.loss(X_u_train, u_train, X_f_train,f_hat)\n",
    "        \n",
    "        self.train_loss.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        \n",
    "        u_pred = self.test(X_u_test_tensor)\n",
    "        self.test_loss.append(np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1))))\n",
    "        self.alpha_val.append(self.alpha.cpu().detach().numpy())\n",
    "        \n",
    "        print(self.iter,\"Train Loss\",self.train_loss[-1],\"Test Loss\",self.test_loss[-1])\n",
    "        \n",
    "        loss.backward()\n",
    "        self.iter += 1\n",
    "     \n",
    "        return loss        \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self,xt_test_tensor):\n",
    "        u_pred = self.forward(X_u_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0 Train Loss 0.35217404 Test Loss 0.40761874210156224\n",
      "1 Train Loss 0.32600185 Test Loss 0.3948131488498962\n",
      "2 Train Loss 0.24855013 Test Loss 0.3598926118056299\n",
      "3 Train Loss 0.2381958 Test Loss 0.3453444272707547\n",
      "4 Train Loss 0.234891 Test Loss 0.2847747230383327\n",
      "5 Train Loss 0.22113676 Test Loss 0.3056078214107695\n",
      "6 Train Loss 0.22234143 Test Loss 0.2822616461506529\n",
      "7 Train Loss 0.21723087 Test Loss 0.2933852160269236\n",
      "8 Train Loss 0.2171567 Test Loss 0.29417366812461926\n",
      "9 Train Loss 0.21709213 Test Loss 0.29426583883764046\n",
      "10 Train Loss 0.2169328 Test Loss 0.2946814691644265\n",
      "11 Train Loss 0.21658868 Test Loss 0.2955435716082367\n",
      "12 Train Loss 0.21592686 Test Loss 0.29729220529009376\n",
      "13 Train Loss 0.21498498 Test Loss 0.29934564128096297\n",
      "14 Train Loss 0.21438338 Test Loss 0.2996630664522937\n",
      "15 Train Loss 0.21429054 Test Loss 0.2978279101333019\n",
      "16 Train Loss 0.21423544 Test Loss 0.2987471873049829\n",
      "17 Train Loss 0.21407828 Test Loss 0.2999155473225463\n",
      "18 Train Loss 0.2137976 Test Loss 0.3008422539253865\n",
      "19 Train Loss 0.21332164 Test Loss 0.30018732483867644\n",
      "20 Train Loss 0.21275692 Test Loss 0.2965832436824398\n",
      "21 Train Loss 0.21226232 Test Loss 0.29043239439515656\n",
      "22 Train Loss 0.21184088 Test Loss 0.28927246112734306\n",
      "23 Train Loss 0.20982105 Test Loss 0.28693529608994395\n",
      "24 Train Loss 0.38925964 Test Loss 0.4309641781132381\n",
      "25 Train Loss 0.20690468 Test Loss 0.28427113552762356\n",
      "26 Train Loss 1.8193685 Test Loss 2.0931702929814118\n",
      "27 Train Loss 0.20925717 Test Loss 0.28069223808362836\n",
      "28 Train Loss 0.20570043 Test Loss 0.28178392827367404\n",
      "29 Train Loss 0.20427747 Test Loss 0.28303782784871556\n",
      "30 Train Loss 0.19718558 Test Loss 0.2748330344667234\n",
      "31 Train Loss 0.18646488 Test Loss 0.23849353632725662\n",
      "32 Train Loss 0.17883758 Test Loss 0.24747916453580066\n",
      "33 Train Loss 0.1635863 Test Loss 0.22015941195696292\n",
      "34 Train Loss 0.3592369 Test Loss 0.3503750201965854\n",
      "35 Train Loss 0.15079705 Test Loss 0.1907151797733317\n",
      "36 Train Loss 0.14592278 Test Loss 0.20482022655230064\n",
      "37 Train Loss 0.13954742 Test Loss 0.1744809596215296\n",
      "38 Train Loss 0.13806123 Test Loss 0.17366056884657916\n",
      "39 Train Loss 0.13424985 Test Loss 0.16549253511352638\n",
      "40 Train Loss 0.1318404 Test Loss 0.17122107386090385\n",
      "41 Train Loss 0.12856707 Test Loss 0.1650857327191337\n",
      "42 Train Loss 0.12317704 Test Loss 0.1497179784283102\n",
      "43 Train Loss 0.12082532 Test Loss 0.14447194917034764\n",
      "44 Train Loss 0.11814072 Test Loss 0.14251188785444444\n",
      "45 Train Loss 0.115447804 Test Loss 0.14104098283722646\n",
      "46 Train Loss 0.11381235 Test Loss 0.14154626521752214\n",
      "47 Train Loss 0.11211058 Test Loss 0.13951807619494325\n",
      "48 Train Loss 0.10671982 Test Loss 0.13575449736801887\n",
      "49 Train Loss 0.10597707 Test Loss 0.12921186876200155\n",
      "50 Train Loss 0.10364898 Test Loss 0.1312397139242134\n",
      "51 Train Loss 0.10203816 Test Loss 0.1277369875617837\n",
      "52 Train Loss 0.10043046 Test Loss 0.12335803730679501\n",
      "53 Train Loss 0.10013636 Test Loss 0.12435769791512312\n",
      "54 Train Loss 0.09980051 Test Loss 0.12276900884738862\n",
      "55 Train Loss 0.09943806 Test Loss 0.12240807706006251\n",
      "56 Train Loss 0.098777235 Test Loss 0.1226465691272833\n",
      "57 Train Loss 0.09832874 Test Loss 0.12120909134853103\n",
      "58 Train Loss 0.097868994 Test Loss 0.12224577961576957\n",
      "59 Train Loss 0.097438484 Test Loss 0.1204318087487297\n",
      "60 Train Loss 0.097149245 Test Loss 0.12156112351113985\n",
      "61 Train Loss 0.096519075 Test Loss 0.12091182148410905\n",
      "62 Train Loss 0.09736807 Test Loss 0.12538436871817837\n",
      "63 Train Loss 0.0958837 Test Loss 0.12202946752459187\n",
      "64 Train Loss 0.095033914 Test Loss 0.12346362387583172\n",
      "65 Train Loss 0.094489254 Test Loss 0.1261221836096856\n",
      "66 Train Loss 0.094191454 Test Loss 0.12386014976111769\n",
      "67 Train Loss 0.09401256 Test Loss 0.12463858391714684\n",
      "68 Train Loss 0.09388499 Test Loss 0.12367989529880412\n",
      "69 Train Loss 0.093664974 Test Loss 0.12282237029241759\n",
      "70 Train Loss 0.09299447 Test Loss 0.12026195115894177\n",
      "71 Train Loss 0.09221703 Test Loss 0.11892245074661673\n",
      "72 Train Loss 0.09076044 Test Loss 0.11508712671509894\n",
      "73 Train Loss 0.08897279 Test Loss 0.11191404098593473\n",
      "74 Train Loss 0.08766014 Test Loss 0.11124371386141235\n",
      "75 Train Loss 0.08665168 Test Loss 0.10816452419090394\n",
      "76 Train Loss 0.08606263 Test Loss 0.10730404515522986\n",
      "77 Train Loss 0.08531267 Test Loss 0.10859168388354894\n",
      "78 Train Loss 0.08415495 Test Loss 0.11059266983046806\n",
      "79 Train Loss 0.08298642 Test Loss 0.11247263621531181\n",
      "80 Train Loss 0.08095253 Test Loss 0.11423947183087718\n",
      "81 Train Loss 0.078925684 Test Loss 0.10722547493426479\n",
      "82 Train Loss 0.077280186 Test Loss 0.10350892777781727\n",
      "83 Train Loss 0.07960985 Test Loss 0.10467187699439753\n",
      "84 Train Loss 0.076620586 Test Loss 0.10237721832679564\n",
      "85 Train Loss 0.076110214 Test Loss 0.09773076096542743\n",
      "86 Train Loss 0.07533251 Test Loss 0.09818682391527668\n",
      "87 Train Loss 0.0746021 Test Loss 0.09821461782910251\n",
      "88 Train Loss 0.07396675 Test Loss 0.10107554847943893\n",
      "89 Train Loss 0.07353117 Test Loss 0.09917284681581863\n",
      "90 Train Loss 0.07274154 Test Loss 0.09826361176773385\n",
      "91 Train Loss 0.07218075 Test Loss 0.09878160639825205\n",
      "92 Train Loss 0.07175742 Test Loss 0.09779181101182523\n",
      "93 Train Loss 0.07121089 Test Loss 0.09472928973545157\n",
      "94 Train Loss 0.07062914 Test Loss 0.09112441807572878\n",
      "95 Train Loss 0.07027514 Test Loss 0.08902635538618286\n",
      "96 Train Loss 0.07001704 Test Loss 0.08948527505049426\n",
      "97 Train Loss 0.06977331 Test Loss 0.09008346887447706\n",
      "98 Train Loss 0.06952958 Test Loss 0.09021403935475746\n",
      "99 Train Loss 0.06933276 Test Loss 0.08993738730524059\n",
      "100 Train Loss 0.0689233 Test Loss 0.08911446099425667\n",
      "101 Train Loss 0.068204075 Test Loss 0.08656636403365361\n",
      "102 Train Loss 0.06773571 Test Loss 0.08616841712790746\n",
      "103 Train Loss 0.06701669 Test Loss 0.08506250311953478\n",
      "104 Train Loss 0.06653883 Test Loss 0.08639003115852381\n",
      "105 Train Loss 0.06643602 Test Loss 0.08336568898890284\n",
      "106 Train Loss 0.06626172 Test Loss 0.08349669013671791\n",
      "107 Train Loss 0.0662037 Test Loss 0.0830103509600546\n",
      "108 Train Loss 0.06608921 Test Loss 0.08176057106678167\n",
      "109 Train Loss 0.06567983 Test Loss 0.07946430195567558\n",
      "110 Train Loss 0.06510332 Test Loss 0.07492945121387647\n",
      "111 Train Loss 0.064321145 Test Loss 0.07696287212063782\n",
      "112 Train Loss 0.06353229 Test Loss 0.07812243682373878\n",
      "113 Train Loss 0.06313257 Test Loss 0.07772677028377296\n",
      "114 Train Loss 0.06254311 Test Loss 0.08012878489837119\n",
      "115 Train Loss 0.062000662 Test Loss 0.07817692036392378\n",
      "116 Train Loss 0.08580962 Test Loss 0.0641077047266783\n",
      "117 Train Loss 0.060900725 Test Loss 0.07263765525902524\n",
      "118 Train Loss 0.06117896 Test Loss 0.06395701075513363\n",
      "119 Train Loss 0.060075708 Test Loss 0.06837160302270968\n",
      "120 Train Loss 0.057368167 Test Loss 0.06533060258383006\n",
      "121 Train Loss 0.13429184 Test Loss 0.04447494144178812\n",
      "122 Train Loss 0.055349108 Test Loss 0.06156082933097602\n",
      "123 Train Loss 0.059424087 Test Loss 0.0565988967985518\n",
      "124 Train Loss 0.054256946 Test Loss 0.059634881896153555\n",
      "125 Train Loss 0.0561739 Test Loss 0.0599468617358749\n",
      "126 Train Loss 0.053905413 Test Loss 0.0596734565913522\n",
      "127 Train Loss 0.05538372 Test Loss 0.06306649890934835\n",
      "128 Train Loss 0.053657513 Test Loss 0.06047504946687453\n",
      "129 Train Loss 0.053213134 Test Loss 0.059671062949755244\n",
      "130 Train Loss 0.052711144 Test Loss 0.0586102198688238\n",
      "131 Train Loss 0.05242207 Test Loss 0.058329662675889356\n",
      "132 Train Loss 0.05192292 Test Loss 0.05802837925659343\n",
      "133 Train Loss 0.0512321 Test Loss 0.056702192005427386\n",
      "134 Train Loss 0.050468333 Test Loss 0.05703230049028704\n",
      "135 Train Loss 0.049333602 Test Loss 0.05521495581474313\n",
      "136 Train Loss 0.04779905 Test Loss 0.05233763373576453\n",
      "137 Train Loss 0.04571849 Test Loss 0.04831911569266438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 Train Loss 0.044971462 Test Loss 0.04764482511422654\n",
      "139 Train Loss 0.044403404 Test Loss 0.04613845998933771\n",
      "140 Train Loss 0.043248374 Test Loss 0.046499510870365135\n",
      "141 Train Loss 0.0425273 Test Loss 0.044555519472887425\n",
      "142 Train Loss 0.040921807 Test Loss 0.03995828569680437\n",
      "143 Train Loss 0.042955123 Test Loss 0.037867651522391486\n",
      "144 Train Loss 0.040284283 Test Loss 0.038942136967483276\n",
      "145 Train Loss 0.039763726 Test Loss 0.04098758006138404\n",
      "146 Train Loss 0.03919868 Test Loss 0.039737384011031676\n",
      "147 Train Loss 0.038623504 Test Loss 0.04093580120575039\n",
      "148 Train Loss 0.037980366 Test Loss 0.04103366552160764\n",
      "149 Train Loss 0.036960565 Test Loss 0.04050781446962412\n",
      "150 Train Loss 0.036380846 Test Loss 0.03853005376971597\n",
      "151 Train Loss 0.035262395 Test Loss 0.03807101659498648\n",
      "152 Train Loss 0.035484888 Test Loss 0.03303344640305805\n",
      "153 Train Loss 0.03480409 Test Loss 0.035585432443847764\n",
      "154 Train Loss 0.03429756 Test Loss 0.03402129743218419\n",
      "155 Train Loss 0.033675943 Test Loss 0.032511554344478555\n",
      "156 Train Loss 0.03342009 Test Loss 0.030848149317712303\n",
      "157 Train Loss 0.03291868 Test Loss 0.02926210940758903\n",
      "158 Train Loss 0.0326026 Test Loss 0.030681160247796234\n",
      "159 Train Loss 0.032434016 Test Loss 0.029758274806587277\n",
      "160 Train Loss 0.03237839 Test Loss 0.02846794059106507\n",
      "161 Train Loss 0.03214758 Test Loss 0.027950873460053677\n",
      "162 Train Loss 0.032072145 Test Loss 0.02890165285893178\n",
      "163 Train Loss 0.031914026 Test Loss 0.028797773530533713\n",
      "164 Train Loss 0.031457506 Test Loss 0.02713017134818023\n",
      "165 Train Loss 0.03081517 Test Loss 0.026825727672629963\n",
      "166 Train Loss 0.030273104 Test Loss 0.026129983974782695\n",
      "167 Train Loss 0.030089032 Test Loss 0.02698685019571423\n",
      "168 Train Loss 0.029922094 Test Loss 0.026333887035663812\n",
      "169 Train Loss 0.02950539 Test Loss 0.025305971774605137\n",
      "170 Train Loss 0.028995162 Test Loss 0.02411001079879357\n",
      "171 Train Loss 0.027888205 Test Loss 0.02180979027449452\n",
      "172 Train Loss 0.027350504 Test Loss 0.021885926110721477\n",
      "173 Train Loss 0.027604587 Test Loss 0.023226720065191764\n",
      "174 Train Loss 0.02718285 Test Loss 0.0223595249483811\n",
      "175 Train Loss 0.027111381 Test Loss 0.02230798848735663\n",
      "176 Train Loss 0.026932735 Test Loss 0.02284207972905542\n",
      "177 Train Loss 0.026819319 Test Loss 0.022589114702905012\n",
      "178 Train Loss 0.026549235 Test Loss 0.02240833666451861\n",
      "179 Train Loss 0.026111387 Test Loss 0.02158222772850387\n",
      "180 Train Loss 0.025562227 Test Loss 0.020933902899488287\n",
      "181 Train Loss 0.024993055 Test Loss 0.019478711917490087\n",
      "182 Train Loss 0.024650374 Test Loss 0.01892146797204901\n",
      "183 Train Loss 0.024156976 Test Loss 0.01826380564575878\n",
      "184 Train Loss 0.024374556 Test Loss 0.018656686511845516\n",
      "185 Train Loss 0.023924304 Test Loss 0.01840862133305595\n",
      "186 Train Loss 0.023588223 Test Loss 0.018016236631708458\n",
      "187 Train Loss 0.023054728 Test Loss 0.016977438428943115\n",
      "188 Train Loss 0.022578428 Test Loss 0.015941518864941936\n",
      "189 Train Loss 0.021998502 Test Loss 0.015464289731669563\n",
      "190 Train Loss 0.021604462 Test Loss 0.015233893866553121\n",
      "191 Train Loss 0.021407265 Test Loss 0.015211657142871805\n",
      "192 Train Loss 0.021262104 Test Loss 0.015310333581611997\n",
      "193 Train Loss 0.021060903 Test Loss 0.0154284091675619\n",
      "194 Train Loss 0.020859784 Test Loss 0.015464843115216752\n",
      "195 Train Loss 0.020452231 Test Loss 0.015338314159075465\n",
      "196 Train Loss 0.019448869 Test Loss 0.014712678530471632\n",
      "197 Train Loss 0.018791266 Test Loss 0.014330106883989356\n",
      "198 Train Loss 0.0197265 Test Loss 0.014221021777494878\n",
      "199 Train Loss 0.018516108 Test Loss 0.01428927501116093\n",
      "200 Train Loss 0.01806055 Test Loss 0.014603636554606482\n",
      "201 Train Loss 0.017616784 Test Loss 0.013770352563937868\n",
      "202 Train Loss 0.01711978 Test Loss 0.01314858602420343\n",
      "203 Train Loss 0.01674947 Test Loss 0.013139811653931282\n",
      "204 Train Loss 0.016446706 Test Loss 0.013179617122038568\n",
      "205 Train Loss 0.016117884 Test Loss 0.012780376197424765\n",
      "206 Train Loss 0.015731404 Test Loss 0.01205683310706172\n",
      "207 Train Loss 0.015250826 Test Loss 0.011266658011077315\n",
      "208 Train Loss 0.015004756 Test Loss 0.010511676836174579\n",
      "209 Train Loss 0.014562448 Test Loss 0.010692447456503901\n",
      "210 Train Loss 0.014375856 Test Loss 0.010537637337668257\n",
      "211 Train Loss 0.014193267 Test Loss 0.010199776850023561\n",
      "212 Train Loss 0.014081854 Test Loss 0.009911916897252026\n",
      "213 Train Loss 0.014004869 Test Loss 0.010080048613967824\n",
      "214 Train Loss 0.01370698 Test Loss 0.009933394762867854\n",
      "215 Train Loss 0.013367139 Test Loss 0.009600516677328457\n",
      "216 Train Loss 0.01295045 Test Loss 0.009326792111582315\n",
      "217 Train Loss 0.012591574 Test Loss 0.00907689655616771\n",
      "218 Train Loss 0.012284489 Test Loss 0.008838870700275385\n",
      "219 Train Loss 0.012119862 Test Loss 0.00865634696639258\n",
      "220 Train Loss 0.012030858 Test Loss 0.008423355536807035\n",
      "221 Train Loss 0.011913373 Test Loss 0.008241242479421434\n",
      "222 Train Loss 0.011780206 Test Loss 0.007809261481657179\n",
      "223 Train Loss 0.011640161 Test Loss 0.007381583214857645\n",
      "224 Train Loss 0.011404168 Test Loss 0.006725401914873479\n",
      "225 Train Loss 0.011084262 Test Loss 0.006304832097994062\n",
      "226 Train Loss 0.010881204 Test Loss 0.006277437795993106\n",
      "227 Train Loss 0.01076577 Test Loss 0.006469214068131659\n",
      "228 Train Loss 0.010570833 Test Loss 0.006656830562162097\n",
      "229 Train Loss 0.0103253275 Test Loss 0.006834215677953711\n",
      "230 Train Loss 0.010064501 Test Loss 0.00690895165610695\n",
      "231 Train Loss 0.00979636 Test Loss 0.0066636581404081055\n",
      "232 Train Loss 0.009596061 Test Loss 0.00659620179668277\n",
      "233 Train Loss 0.009423457 Test Loss 0.005879239835980428\n",
      "234 Train Loss 0.009331119 Test Loss 0.005407849544800981\n",
      "235 Train Loss 0.0092752045 Test Loss 0.005174407418309739\n",
      "236 Train Loss 0.009216119 Test Loss 0.005034169394241435\n",
      "237 Train Loss 0.009153574 Test Loss 0.0048157621855367365\n",
      "238 Train Loss 0.00908221 Test Loss 0.004633202466197502\n",
      "239 Train Loss 0.0090122605 Test Loss 0.004454433687010029\n",
      "240 Train Loss 0.008923412 Test Loss 0.004415031086476382\n",
      "241 Train Loss 0.0087116435 Test Loss 0.004182845753818739\n",
      "242 Train Loss 0.008526631 Test Loss 0.003936933845979692\n",
      "243 Train Loss 0.008395068 Test Loss 0.003665359771023221\n",
      "244 Train Loss 0.008288346 Test Loss 0.0036204661503305337\n",
      "245 Train Loss 0.008224628 Test Loss 0.0036713821312971484\n",
      "246 Train Loss 0.008190202 Test Loss 0.0036623314737691797\n",
      "247 Train Loss 0.008140628 Test Loss 0.0038046977105475827\n",
      "248 Train Loss 0.008114692 Test Loss 0.003729834309600866\n",
      "249 Train Loss 0.008087123 Test Loss 0.0037629737989865507\n",
      "250 Train Loss 0.008038145 Test Loss 0.0038121006271928755\n",
      "251 Train Loss 0.007957173 Test Loss 0.00384885283082694\n",
      "252 Train Loss 0.007851513 Test Loss 0.0038141550953188306\n",
      "253 Train Loss 0.0077401176 Test Loss 0.003732549345204068\n",
      "254 Train Loss 0.007655983 Test Loss 0.0035676762975367145\n",
      "255 Train Loss 0.0076190108 Test Loss 0.0035874141719652607\n",
      "256 Train Loss 0.007596405 Test Loss 0.0035287740530617956\n",
      "257 Train Loss 0.0075725336 Test Loss 0.003524690319885656\n",
      "258 Train Loss 0.0075393384 Test Loss 0.0035182279434380296\n",
      "259 Train Loss 0.007474902 Test Loss 0.0035175646426158723\n",
      "260 Train Loss 0.00736518 Test Loss 0.0035480597014024323\n",
      "261 Train Loss 0.0071545076 Test Loss 0.0036135597620498188\n",
      "262 Train Loss 0.006937554 Test Loss 0.0037623296587548398\n",
      "263 Train Loss 0.0067983894 Test Loss 0.0035872016278765055\n",
      "264 Train Loss 0.006732636 Test Loss 0.003611530681096248\n",
      "265 Train Loss 0.006715642 Test Loss 0.0035687929871160056\n",
      "266 Train Loss 0.006706697 Test Loss 0.0035618765705356732\n",
      "267 Train Loss 0.0066801477 Test Loss 0.003507443611798012\n",
      "268 Train Loss 0.0065521286 Test Loss 0.003324065143487865\n",
      "269 Train Loss 0.006419164 Test Loss 0.00313214610883499\n",
      "270 Train Loss 0.0062614568 Test Loss 0.0029090614005341468\n",
      "271 Train Loss 0.006162515 Test Loss 0.0028570172016651346\n",
      "272 Train Loss 0.006081733 Test Loss 0.0028252514888976368\n",
      "273 Train Loss 0.0060347794 Test Loss 0.0029235922528648628\n",
      "274 Train Loss 0.0059522046 Test Loss 0.002876725701086743\n",
      "275 Train Loss 0.0058339247 Test Loss 0.0028238218508004724\n",
      "276 Train Loss 0.0056248805 Test Loss 0.0027217807411363194\n",
      "277 Train Loss 0.005413476 Test Loss 0.0026469642148934775\n",
      "278 Train Loss 0.00527053 Test Loss 0.002508358313294154\n",
      "279 Train Loss 0.005212889 Test Loss 0.002444489747264038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 Train Loss 0.0051771784 Test Loss 0.002348672995089306\n",
      "281 Train Loss 0.0051687043 Test Loss 0.002382302162219874\n",
      "282 Train Loss 0.0051465128 Test Loss 0.0023241814669567283\n",
      "283 Train Loss 0.005124087 Test Loss 0.002248999209466651\n",
      "284 Train Loss 0.00508801 Test Loss 0.0021462800324951407\n",
      "285 Train Loss 0.0050467425 Test Loss 0.002039478742231265\n",
      "286 Train Loss 0.0049965233 Test Loss 0.0020344712284350607\n",
      "287 Train Loss 0.0049469657 Test Loss 0.002055136919040651\n",
      "288 Train Loss 0.0049114353 Test Loss 0.002056479636011542\n",
      "289 Train Loss 0.004868974 Test Loss 0.0020185217458774706\n",
      "290 Train Loss 0.0048379037 Test Loss 0.0019983379081704414\n",
      "291 Train Loss 0.0047820415 Test Loss 0.0019000740501785422\n",
      "292 Train Loss 0.00468064 Test Loss 0.001815656441142966\n",
      "293 Train Loss 0.0045369808 Test Loss 0.0017193947748929542\n",
      "294 Train Loss 0.0044245133 Test Loss 0.0017331557748635601\n",
      "295 Train Loss 0.0043860823 Test Loss 0.0017259170052290793\n",
      "296 Train Loss 0.0043482557 Test Loss 0.0017288811774247915\n",
      "297 Train Loss 0.004342547 Test Loss 0.0017519519400712846\n",
      "298 Train Loss 0.0043257074 Test Loss 0.0017213567663796542\n",
      "299 Train Loss 0.004311896 Test Loss 0.0016752891303484256\n",
      "300 Train Loss 0.0042991755 Test Loss 0.00164844293930293\n",
      "301 Train Loss 0.0042785467 Test Loss 0.0016193568586374846\n",
      "302 Train Loss 0.004212596 Test Loss 0.001568396210922908\n",
      "303 Train Loss 0.004112038 Test Loss 0.001550265220871591\n",
      "304 Train Loss 0.003987744 Test Loss 0.0016080751744388777\n",
      "305 Train Loss 0.0038749764 Test Loss 0.0018967524887057547\n",
      "306 Train Loss 0.0038311544 Test Loss 0.0019301474515857691\n",
      "307 Train Loss 0.0038081722 Test Loss 0.0019845342706601102\n",
      "308 Train Loss 0.0037904575 Test Loss 0.002025147272099497\n",
      "309 Train Loss 0.0037748876 Test Loss 0.0019910231909303355\n",
      "310 Train Loss 0.0037302822 Test Loss 0.0018404328390029061\n",
      "311 Train Loss 0.0036784606 Test Loss 0.0015818379276306693\n",
      "312 Train Loss 0.003636477 Test Loss 0.0014576888133830015\n",
      "313 Train Loss 0.0035925854 Test Loss 0.0014422987193504024\n",
      "314 Train Loss 0.0035534757 Test Loss 0.0014370136746607667\n",
      "315 Train Loss 0.0034879672 Test Loss 0.0016307047023730432\n",
      "316 Train Loss 0.0034554359 Test Loss 0.001797093919210638\n",
      "317 Train Loss 0.0034287493 Test Loss 0.0018294797709381733\n",
      "318 Train Loss 0.0033933008 Test Loss 0.0018817821424167815\n",
      "319 Train Loss 0.0033579739 Test Loss 0.0018648472497908284\n",
      "320 Train Loss 0.003312882 Test Loss 0.0018167541660474927\n",
      "321 Train Loss 0.003271035 Test Loss 0.0017236264372902078\n",
      "322 Train Loss 0.003231083 Test Loss 0.0014985737627906746\n",
      "323 Train Loss 0.0031791106 Test Loss 0.001254458131323433\n",
      "324 Train Loss 0.0031531341 Test Loss 0.0012076418360520338\n",
      "325 Train Loss 0.0031348784 Test Loss 0.0011454018154031965\n",
      "326 Train Loss 0.0031174247 Test Loss 0.0010965819775405493\n",
      "327 Train Loss 0.00344224 Test Loss 0.0018548341089773773\n",
      "328 Train Loss 0.0031004173 Test Loss 0.0010911093063695175\n",
      "329 Train Loss 0.008794969 Test Loss 0.011871235234059259\n",
      "330 Train Loss 0.0030896764 Test Loss 0.001105248682363022\n",
      "331 Train Loss 0.0030727154 Test Loss 0.001191888080104519\n",
      "332 Train Loss 0.0030464688 Test Loss 0.0011432228254657018\n",
      "333 Train Loss 0.003026573 Test Loss 0.0011800516264115245\n",
      "334 Train Loss 0.003011631 Test Loss 0.0012189662232682474\n",
      "335 Train Loss 0.0030041656 Test Loss 0.0012714124526493767\n",
      "336 Train Loss 0.0029976738 Test Loss 0.0012922830458448745\n",
      "337 Train Loss 0.002988455 Test Loss 0.001305191972966754\n",
      "338 Train Loss 0.002975653 Test Loss 0.0013057994963907049\n",
      "339 Train Loss 0.0029722052 Test Loss 0.0012293624743257645\n",
      "340 Train Loss 0.0029166874 Test Loss 0.001195504774664869\n",
      "341 Train Loss 0.0028717578 Test Loss 0.001134257366606062\n",
      "342 Train Loss 0.0027970646 Test Loss 0.001057244430018102\n",
      "343 Train Loss 0.0027027796 Test Loss 0.0009073717579852997\n",
      "344 Train Loss 0.0026823364 Test Loss 0.0008978332338024556\n",
      "345 Train Loss 0.0026717475 Test Loss 0.0008590611272680998\n",
      "346 Train Loss 0.002663162 Test Loss 0.0008551130025004512\n",
      "347 Train Loss 0.0026546635 Test Loss 0.0008225595081538106\n",
      "348 Train Loss 0.0026321681 Test Loss 0.0007775895508425122\n",
      "349 Train Loss 0.0025996612 Test Loss 0.0008640022681156341\n",
      "350 Train Loss 0.002541718 Test Loss 0.0009470441356743334\n",
      "351 Train Loss 0.002475642 Test Loss 0.0010472647523900314\n",
      "352 Train Loss 0.0024424754 Test Loss 0.0013234101616419768\n",
      "353 Train Loss 0.002419049 Test Loss 0.0011720269978157218\n",
      "354 Train Loss 0.0023700683 Test Loss 0.001233264212512578\n",
      "355 Train Loss 0.0023464733 Test Loss 0.001256418451230238\n",
      "356 Train Loss 0.0023043128 Test Loss 0.001146420472971293\n",
      "357 Train Loss 0.002246173 Test Loss 0.0008824332858717801\n",
      "358 Train Loss 0.0022135545 Test Loss 0.0008733991826990625\n",
      "359 Train Loss 0.0021847123 Test Loss 0.0008942311993869478\n",
      "360 Train Loss 0.002170793 Test Loss 0.0008018666541891881\n",
      "361 Train Loss 0.0021632402 Test Loss 0.0008124145525399823\n",
      "362 Train Loss 0.0021595717 Test Loss 0.0008092175371679794\n",
      "363 Train Loss 0.002156491 Test Loss 0.0007998043070469272\n",
      "364 Train Loss 0.0021523847 Test Loss 0.0007905757397594919\n",
      "365 Train Loss 0.0021505426 Test Loss 0.0008011286012574551\n",
      "366 Train Loss 0.0021455039 Test Loss 0.0008077853777455392\n",
      "367 Train Loss 0.002139751 Test Loss 0.0008331137462369873\n",
      "368 Train Loss 0.0021323888 Test Loss 0.0008210637092863357\n",
      "369 Train Loss 0.0021214974 Test Loss 0.0008100271169111642\n",
      "370 Train Loss 0.002106473 Test Loss 0.0007640937587189317\n",
      "371 Train Loss 0.0020881006 Test Loss 0.000727827787601035\n",
      "372 Train Loss 0.0020680474 Test Loss 0.0007015417390395451\n",
      "373 Train Loss 0.0020485271 Test Loss 0.0006996647527337062\n",
      "374 Train Loss 0.0020293489 Test Loss 0.0007362264561936393\n",
      "375 Train Loss 0.002011741 Test Loss 0.000738742850215647\n",
      "376 Train Loss 0.0019956226 Test Loss 0.0007397545695169006\n",
      "377 Train Loss 0.001977176 Test Loss 0.0007308827070888236\n",
      "378 Train Loss 0.0019539567 Test Loss 0.0007078091277187199\n",
      "379 Train Loss 0.0019289166 Test Loss 0.0006789144333454635\n",
      "380 Train Loss 0.0019137041 Test Loss 0.000654813245547515\n",
      "381 Train Loss 0.0019089864 Test Loss 0.0006518218652080439\n",
      "382 Train Loss 0.0019061049 Test Loss 0.0006549916824091423\n",
      "383 Train Loss 0.0019031651 Test Loss 0.0006525737620378822\n",
      "384 Train Loss 0.0018975995 Test Loss 0.000661931376637829\n",
      "385 Train Loss 0.0018896384 Test Loss 0.0006686834242365623\n",
      "386 Train Loss 0.0018759846 Test Loss 0.0006762488402948582\n",
      "387 Train Loss 0.0018479701 Test Loss 0.0006741321327645591\n",
      "388 Train Loss 0.001829118 Test Loss 0.0006963958314326269\n",
      "389 Train Loss 0.0018003247 Test Loss 0.0006194129606940342\n",
      "390 Train Loss 0.0017582797 Test Loss 0.0006283235078615227\n",
      "391 Train Loss 0.0017438356 Test Loss 0.0006122654043711489\n",
      "392 Train Loss 0.0017334472 Test Loss 0.0005814211200478561\n",
      "393 Train Loss 0.0017284105 Test Loss 0.0005810155579186627\n",
      "394 Train Loss 0.0017238429 Test Loss 0.0005981123606348302\n",
      "395 Train Loss 0.001718958 Test Loss 0.0006279059366543366\n",
      "396 Train Loss 0.0017145695 Test Loss 0.0006639520479589065\n",
      "397 Train Loss 0.0017091393 Test Loss 0.0006907549978872538\n",
      "398 Train Loss 0.0017015482 Test Loss 0.0007103380290577336\n",
      "399 Train Loss 0.001697751 Test Loss 0.0007386349849501089\n",
      "400 Train Loss 0.0017894284 Test Loss 0.0006172441090231552\n",
      "401 Train Loss 0.0016860751 Test Loss 0.0007006115998033065\n",
      "402 Train Loss 0.0016751743 Test Loss 0.0006703395958726853\n",
      "403 Train Loss 0.00166459 Test Loss 0.000678233760206167\n",
      "404 Train Loss 0.0016544637 Test Loss 0.0007085044942538814\n",
      "405 Train Loss 0.001649372 Test Loss 0.0007398450719959002\n",
      "406 Train Loss 0.0016406145 Test Loss 0.0007986183110244655\n",
      "407 Train Loss 0.0016293757 Test Loss 0.0009761026163364909\n",
      "408 Train Loss 0.0016191303 Test Loss 0.0010301868895786258\n",
      "409 Train Loss 0.001610012 Test Loss 0.0010858103552491855\n",
      "410 Train Loss 0.0016020397 Test Loss 0.0009890687220619231\n",
      "411 Train Loss 0.0015965411 Test Loss 0.001028596001559435\n",
      "412 Train Loss 0.0015852633 Test Loss 0.0010173460264351626\n",
      "413 Train Loss 0.0015729095 Test Loss 0.0009214716079386709\n",
      "414 Train Loss 0.0015602005 Test Loss 0.0008969575180512543\n",
      "415 Train Loss 0.0015430478 Test Loss 0.0008584485473959191\n",
      "416 Train Loss 0.0015265318 Test Loss 0.0008192006001073122\n",
      "417 Train Loss 0.0015079181 Test Loss 0.0007891224070899283\n",
      "418 Train Loss 0.00149037 Test Loss 0.000784740021007188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419 Train Loss 0.0014852985 Test Loss 0.0007560619190970129\n",
      "420 Train Loss 0.001532133 Test Loss 0.0008542760851199571\n",
      "421 Train Loss 0.001479704 Test Loss 0.0007776704086349594\n",
      "422 Train Loss 0.0014758898 Test Loss 0.0007863711176628873\n",
      "423 Train Loss 0.0014728442 Test Loss 0.0007911934114064577\n",
      "424 Train Loss 0.0014705572 Test Loss 0.0007885902616494056\n",
      "425 Train Loss 0.001467822 Test Loss 0.0008023223529860513\n",
      "426 Train Loss 0.0014635477 Test Loss 0.0008171825288908276\n",
      "427 Train Loss 0.0014537468 Test Loss 0.0008640101304279648\n",
      "428 Train Loss 0.0014427509 Test Loss 0.0009042325099881779\n",
      "429 Train Loss 0.0014244581 Test Loss 0.000921101863083069\n",
      "430 Train Loss 0.001404976 Test Loss 0.0008905398346701818\n",
      "431 Train Loss 0.0013879924 Test Loss 0.0008529729836955276\n",
      "432 Train Loss 0.0013766713 Test Loss 0.0008288333870769782\n",
      "433 Train Loss 0.001368073 Test Loss 0.0008107216809560925\n",
      "434 Train Loss 0.001362305 Test Loss 0.0008183616812369991\n",
      "435 Train Loss 0.0013578302 Test Loss 0.000821137664704874\n",
      "436 Train Loss 0.0013551592 Test Loss 0.0008356984950171702\n",
      "437 Train Loss 0.0013534178 Test Loss 0.0008312457536562034\n",
      "438 Train Loss 0.0013523467 Test Loss 0.0008239323238421267\n",
      "439 Train Loss 0.0013517479 Test Loss 0.0008220478739693101\n",
      "440 Train Loss 0.0013505041 Test Loss 0.0008207083347807301\n",
      "441 Train Loss 0.0013454825 Test Loss 0.0008241465956224674\n",
      "442 Train Loss 0.0013381874 Test Loss 0.000845435526558451\n",
      "443 Train Loss 0.001319503 Test Loss 0.0008910092194547056\n",
      "444 Train Loss 0.0013020623 Test Loss 0.0009465211291224755\n",
      "445 Train Loss 0.001285261 Test Loss 0.0009410893307885412\n",
      "446 Train Loss 0.0012725029 Test Loss 0.0009266843556338246\n",
      "447 Train Loss 0.0012663708 Test Loss 0.0009082305757279419\n",
      "448 Train Loss 0.0012644473 Test Loss 0.0009086204498215636\n",
      "449 Train Loss 0.001259154 Test Loss 0.0008954555293046571\n",
      "450 Train Loss 0.0012561016 Test Loss 0.0009069818859207046\n",
      "451 Train Loss 0.0012510957 Test Loss 0.0009111671835311951\n",
      "452 Train Loss 0.0012490628 Test Loss 0.0009490452443685973\n",
      "453 Train Loss 0.0012469774 Test Loss 0.0009402299012201369\n",
      "454 Train Loss 0.0012457897 Test Loss 0.0009570421737897928\n",
      "455 Train Loss 0.001242646 Test Loss 0.0009488498516679948\n",
      "456 Train Loss 0.0012391211 Test Loss 0.0009423706865967074\n",
      "457 Train Loss 0.0012335107 Test Loss 0.0009475622354295862\n",
      "458 Train Loss 0.0012242527 Test Loss 0.0009602975746036368\n",
      "459 Train Loss 0.0012106621 Test Loss 0.0009723928462583605\n",
      "460 Train Loss 0.0012062814 Test Loss 0.0009969316307164883\n",
      "461 Train Loss 0.0011970146 Test Loss 0.000986423305066256\n",
      "462 Train Loss 0.0011693845 Test Loss 0.0010174792234929253\n",
      "463 Train Loss 0.0012074271 Test Loss 0.000980722593858418\n",
      "464 Train Loss 0.0011621099 Test Loss 0.0010042393981710281\n",
      "465 Train Loss 0.0011455938 Test Loss 0.0009647713548993609\n",
      "466 Train Loss 0.0011451952 Test Loss 0.000969402624935019\n",
      "467 Train Loss 0.0011417125 Test Loss 0.0009664676003496615\n",
      "468 Train Loss 0.001138634 Test Loss 0.00100000497672499\n",
      "469 Train Loss 0.0011374337 Test Loss 0.000984996981053542\n",
      "470 Train Loss 0.001136915 Test Loss 0.0009827268898834002\n",
      "471 Train Loss 0.0011364778 Test Loss 0.0009766924035432716\n",
      "472 Train Loss 0.0011350268 Test Loss 0.0009618611990990614\n",
      "473 Train Loss 0.0011303691 Test Loss 0.000933289184087634\n",
      "474 Train Loss 0.0011203286 Test Loss 0.0008981856189078865\n",
      "475 Train Loss 0.0010993818 Test Loss 0.0008436084698053015\n",
      "476 Train Loss 0.0010901303 Test Loss 0.000799953839745141\n",
      "477 Train Loss 0.0010816443 Test Loss 0.0008147086801829188\n",
      "478 Train Loss 0.001073529 Test Loss 0.000770923686944042\n",
      "479 Train Loss 0.0010529947 Test Loss 0.0007889506062912227\n",
      "480 Train Loss 0.0010249406 Test Loss 0.0007775036792803581\n",
      "481 Train Loss 0.001017356 Test Loss 0.0007828123173999857\n",
      "482 Train Loss 0.0010089194 Test Loss 0.0007978934987186936\n",
      "483 Train Loss 0.0010062283 Test Loss 0.0008142522608072948\n",
      "484 Train Loss 0.0010047153 Test Loss 0.0008159175610196322\n",
      "485 Train Loss 0.0010025149 Test Loss 0.0008394580650692167\n",
      "486 Train Loss 0.0010006581 Test Loss 0.0008560874134122737\n",
      "487 Train Loss 0.0009984173 Test Loss 0.0008893682363137731\n",
      "488 Train Loss 0.0009952503 Test Loss 0.0009710353336829906\n",
      "489 Train Loss 0.0010092955 Test Loss 0.0010779950935741972\n",
      "490 Train Loss 0.00099466 Test Loss 0.000987622902818607\n",
      "491 Train Loss 0.0009933534 Test Loss 0.001004817801615674\n",
      "492 Train Loss 0.0009916571 Test Loss 0.0010506681708900044\n",
      "493 Train Loss 0.0009881817 Test Loss 0.0010712768388249456\n",
      "494 Train Loss 0.00097568065 Test Loss 0.0011276334797824198\n",
      "495 Train Loss 0.0009629372 Test Loss 0.0012470210581888932\n",
      "496 Train Loss 0.0009471589 Test Loss 0.0011929067521454478\n",
      "497 Train Loss 0.00093003345 Test Loss 0.001028124044678852\n",
      "498 Train Loss 0.0009231794 Test Loss 0.0009470277914727102\n",
      "499 Train Loss 0.0009173901 Test Loss 0.0008596598880995549\n",
      "500 Train Loss 0.0009126323 Test Loss 0.0008516004317535196\n",
      "501 Train Loss 0.00090765697 Test Loss 0.0008233997419553383\n",
      "502 Train Loss 0.0009042673 Test Loss 0.0007810775071864544\n",
      "503 Train Loss 0.0009057493 Test Loss 0.0007710877431655877\n",
      "504 Train Loss 0.0009020668 Test Loss 0.0007757449631029168\n",
      "505 Train Loss 0.00089692563 Test Loss 0.0006716322718536681\n",
      "506 Train Loss 0.0008903772 Test Loss 0.0006861881867043298\n",
      "507 Train Loss 0.0008776174 Test Loss 0.0006915332702891667\n",
      "508 Train Loss 0.0008660302 Test Loss 0.0007006039331996987\n",
      "509 Train Loss 0.00085499854 Test Loss 0.0006819904270548928\n",
      "510 Train Loss 0.0008479885 Test Loss 0.0006989482887117933\n",
      "511 Train Loss 0.0008448842 Test Loss 0.0007157748120554662\n",
      "512 Train Loss 0.00083997764 Test Loss 0.0007486224300719748\n",
      "513 Train Loss 0.0008336576 Test Loss 0.0007937578955123733\n",
      "514 Train Loss 0.0008256949 Test Loss 0.0008544549897376978\n",
      "515 Train Loss 0.0008199819 Test Loss 0.0008313268088184192\n",
      "516 Train Loss 0.0008167798 Test Loss 0.0008192274460983615\n",
      "517 Train Loss 0.0008140969 Test Loss 0.0007867738099005066\n",
      "518 Train Loss 0.0008118198 Test Loss 0.0007505553584594927\n",
      "519 Train Loss 0.0008100658 Test Loss 0.0007224491690238075\n",
      "520 Train Loss 0.0008087974 Test Loss 0.0007021189600546163\n",
      "521 Train Loss 0.000808028 Test Loss 0.0007025524603111352\n",
      "522 Train Loss 0.0008062097 Test Loss 0.0007011430136578425\n",
      "523 Train Loss 0.000803608 Test Loss 0.0007037673273612319\n",
      "524 Train Loss 0.0008010662 Test Loss 0.0007089253984801823\n",
      "525 Train Loss 0.0007971222 Test Loss 0.0007212402995501436\n",
      "526 Train Loss 0.0007916222 Test Loss 0.0007350613119584854\n",
      "527 Train Loss 0.00078097865 Test Loss 0.0007296687012865468\n",
      "528 Train Loss 0.0008445935 Test Loss 0.0007957792847405608\n",
      "529 Train Loss 0.0007772188 Test Loss 0.0007388153879033422\n",
      "530 Train Loss 0.0007630652 Test Loss 0.0006976388189353292\n",
      "531 Train Loss 0.0007571508 Test Loss 0.0006416144708922944\n",
      "532 Train Loss 0.0007537745 Test Loss 0.0005847140001384569\n",
      "533 Train Loss 0.00075195136 Test Loss 0.0005802988519510762\n",
      "534 Train Loss 0.00075119187 Test Loss 0.0005764097866113187\n",
      "535 Train Loss 0.00075047236 Test Loss 0.0005740937546182906\n",
      "536 Train Loss 0.0007497949 Test Loss 0.0005785505402121199\n",
      "537 Train Loss 0.0007487231 Test Loss 0.0005778128668939773\n",
      "538 Train Loss 0.0007479251 Test Loss 0.0005840548489386554\n",
      "539 Train Loss 0.00074670237 Test Loss 0.0005734500826429401\n",
      "540 Train Loss 0.0007466015 Test Loss 0.0005695483414831552\n",
      "541 Train Loss 0.00074577966 Test Loss 0.0005713377544356921\n",
      "542 Train Loss 0.0007431162 Test Loss 0.0005438144630216491\n",
      "543 Train Loss 0.0007385748 Test Loss 0.0005049024234695321\n",
      "544 Train Loss 0.0007271856 Test Loss 0.0004255793284208885\n",
      "545 Train Loss 0.0007267588 Test Loss 0.00033659098746904626\n",
      "546 Train Loss 0.0007217216 Test Loss 0.0003762304174104663\n",
      "547 Train Loss 0.0007195126 Test Loss 0.00029352392504217216\n",
      "548 Train Loss 0.0007071401 Test Loss 0.00028072673467504635\n",
      "549 Train Loss 0.0006999679 Test Loss 0.00036653806540698616\n",
      "550 Train Loss 0.0006909325 Test Loss 0.00034313891021268554\n",
      "551 Train Loss 0.0006840213 Test Loss 0.0003175327003519404\n",
      "552 Train Loss 0.0006800749 Test Loss 0.0003353412437435627\n",
      "553 Train Loss 0.0006769009 Test Loss 0.0003467067571566116\n",
      "554 Train Loss 0.00067465316 Test Loss 0.0003651705664757312\n",
      "555 Train Loss 0.00067184947 Test Loss 0.0004003428579984802\n",
      "556 Train Loss 0.0006687429 Test Loss 0.0004463191402912036\n",
      "557 Train Loss 0.00066679454 Test Loss 0.0004927615344941772\n",
      "558 Train Loss 0.0006658718 Test Loss 0.0004995145939871438\n",
      "559 Train Loss 0.0006652358 Test Loss 0.0004924891019909241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560 Train Loss 0.0006647182 Test Loss 0.00048339122296266196\n",
      "561 Train Loss 0.0006662631 Test Loss 0.00049519255792266\n",
      "562 Train Loss 0.00066436274 Test Loss 0.00048691827524091424\n",
      "563 Train Loss 0.00066363654 Test Loss 0.00047611694152548015\n",
      "564 Train Loss 0.000662107 Test Loss 0.0004488772397072601\n",
      "565 Train Loss 0.00065953366 Test Loss 0.00041310729315560576\n",
      "566 Train Loss 0.00065564585 Test Loss 0.00036186907173565264\n",
      "567 Train Loss 0.0006518031 Test Loss 0.0003145492178006138\n",
      "568 Train Loss 0.00064794585 Test Loss 0.0002919967223882376\n",
      "569 Train Loss 0.0006436473 Test Loss 0.0002536564996312632\n",
      "570 Train Loss 0.0006403114 Test Loss 0.0002547324714538366\n",
      "571 Train Loss 0.00063680974 Test Loss 0.0002571255697494281\n",
      "572 Train Loss 0.00063168246 Test Loss 0.0002503689835794888\n",
      "573 Train Loss 0.00062798575 Test Loss 0.0002542870386049853\n",
      "574 Train Loss 0.00062391115 Test Loss 0.00027038136183567545\n",
      "575 Train Loss 0.0006203718 Test Loss 0.0002779298424713732\n",
      "576 Train Loss 0.0006178116 Test Loss 0.00027252902461893046\n",
      "577 Train Loss 0.0006153524 Test Loss 0.0002588397387559059\n",
      "578 Train Loss 0.00061183254 Test Loss 0.00025159614566938983\n",
      "579 Train Loss 0.0006078027 Test Loss 0.0003583407895056944\n",
      "580 Train Loss 0.00060495007 Test Loss 0.0003197132424484988\n",
      "581 Train Loss 0.00060307817 Test Loss 0.0003537389388886441\n",
      "582 Train Loss 0.00060171215 Test Loss 0.0003892373451657381\n",
      "583 Train Loss 0.00060055725 Test Loss 0.0004151076326529327\n",
      "584 Train Loss 0.0005983128 Test Loss 0.0004328694209060351\n",
      "585 Train Loss 0.00060032966 Test Loss 0.00044713561002039713\n",
      "586 Train Loss 0.00059731427 Test Loss 0.00043795031570633254\n",
      "587 Train Loss 0.00060882425 Test Loss 0.00039352904664884873\n",
      "588 Train Loss 0.00059670885 Test Loss 0.0004290993310621509\n",
      "589 Train Loss 0.0005958306 Test Loss 0.00041227745836122697\n",
      "590 Train Loss 0.00059284363 Test Loss 0.000436300175379743\n",
      "591 Train Loss 0.0005939398 Test Loss 0.00045505809744530437\n",
      "592 Train Loss 0.0005911414 Test Loss 0.0004441433267547072\n",
      "593 Train Loss 0.0005878476 Test Loss 0.0004436666330461146\n",
      "594 Train Loss 0.00058486767 Test Loss 0.0004798495001350609\n",
      "595 Train Loss 0.00058158813 Test Loss 0.0005080625257184494\n",
      "596 Train Loss 0.0005784981 Test Loss 0.0004909742418232183\n",
      "597 Train Loss 0.000573484 Test Loss 0.0005320423556272326\n",
      "598 Train Loss 0.0005680325 Test Loss 0.0005928866079112077\n",
      "599 Train Loss 0.0005630177 Test Loss 0.0006383455154321653\n",
      "600 Train Loss 0.0005577885 Test Loss 0.0006193325890484274\n",
      "601 Train Loss 0.00055240566 Test Loss 0.0006196318412998646\n",
      "602 Train Loss 0.0005489286 Test Loss 0.0005575480899615977\n",
      "603 Train Loss 0.0005489894 Test Loss 0.0005104096208244593\n",
      "604 Train Loss 0.0005451673 Test Loss 0.0005298867433880619\n",
      "605 Train Loss 0.00054262386 Test Loss 0.0005080224365308895\n",
      "606 Train Loss 0.0005401119 Test Loss 0.0004658574943257818\n",
      "607 Train Loss 0.00053805386 Test Loss 0.0004301961457038367\n",
      "608 Train Loss 0.00053607987 Test Loss 0.000393750350936517\n",
      "609 Train Loss 0.0005357274 Test Loss 0.00036863199085106105\n",
      "610 Train Loss 0.00053462654 Test Loss 0.00038001022002159964\n",
      "611 Train Loss 0.0005334499 Test Loss 0.0003672395361833293\n",
      "612 Train Loss 0.00053218147 Test Loss 0.00036290022582393126\n",
      "613 Train Loss 0.000531029 Test Loss 0.0003601216555283181\n",
      "614 Train Loss 0.0005295374 Test Loss 0.00035823276122224257\n",
      "615 Train Loss 0.0005283214 Test Loss 0.00036039068275482824\n",
      "616 Train Loss 0.00052665954 Test Loss 0.0003591007747871784\n",
      "617 Train Loss 0.000524614 Test Loss 0.00036018701900558897\n",
      "618 Train Loss 0.0005228599 Test Loss 0.00036396526632688915\n",
      "619 Train Loss 0.0005213652 Test Loss 0.0003582977965672522\n",
      "620 Train Loss 0.00051965576 Test Loss 0.00035708618363246893\n",
      "621 Train Loss 0.0005176428 Test Loss 0.00035729824421046845\n",
      "622 Train Loss 0.00052863214 Test Loss 0.00036668734853011973\n",
      "623 Train Loss 0.0005169603 Test Loss 0.00035899843626866016\n",
      "624 Train Loss 0.00051556283 Test Loss 0.0003716735326006284\n",
      "625 Train Loss 0.0005327257 Test Loss 0.0004418771433536018\n",
      "626 Train Loss 0.0005123364 Test Loss 0.00038833980468616554\n",
      "627 Train Loss 0.00051023206 Test Loss 0.00036539237501749777\n",
      "628 Train Loss 0.00050507765 Test Loss 0.0003699128492337716\n",
      "629 Train Loss 0.00050123566 Test Loss 0.0003520840872594402\n",
      "630 Train Loss 0.00049881253 Test Loss 0.00032284771124771813\n",
      "631 Train Loss 0.0004973832 Test Loss 0.00030247000876463127\n",
      "632 Train Loss 0.0004955315 Test Loss 0.00028055565396912266\n",
      "633 Train Loss 0.0004939333 Test Loss 0.00027340568409026626\n",
      "634 Train Loss 0.00049282203 Test Loss 0.0002727461089074009\n",
      "635 Train Loss 0.00050427235 Test Loss 0.0003141614155391591\n",
      "636 Train Loss 0.0004922756 Test Loss 0.0002778476884461119\n",
      "637 Train Loss 0.00049107976 Test Loss 0.0002922521854613847\n",
      "638 Train Loss 0.0004891692 Test Loss 0.0003374321129589177\n",
      "639 Train Loss 0.00048803358 Test Loss 0.0003739666813019168\n",
      "640 Train Loss 0.0004872633 Test Loss 0.0004069039762592413\n",
      "641 Train Loss 0.00048543216 Test Loss 0.00035862684576682736\n",
      "642 Train Loss 0.00048447694 Test Loss 0.00034979366117946783\n",
      "643 Train Loss 0.00048312132 Test Loss 0.0003339906624556913\n",
      "644 Train Loss 0.00048185312 Test Loss 0.0003318127531868663\n",
      "645 Train Loss 0.00048057144 Test Loss 0.0003424957095958544\n",
      "646 Train Loss 0.00048288103 Test Loss 0.0002992712300699008\n",
      "647 Train Loss 0.00047804113 Test Loss 0.0003175884081817936\n",
      "648 Train Loss 0.00047974594 Test Loss 0.00030852809625477355\n",
      "649 Train Loss 0.00047710387 Test Loss 0.0003141722198426539\n",
      "650 Train Loss 0.0004749006 Test Loss 0.0003407611865530434\n",
      "651 Train Loss 0.00047296716 Test Loss 0.0003493313248991164\n",
      "652 Train Loss 0.00047106802 Test Loss 0.00035099835161519864\n",
      "653 Train Loss 0.00046960905 Test Loss 0.0003403608549432943\n",
      "654 Train Loss 0.00046823832 Test Loss 0.0003313032872487409\n",
      "655 Train Loss 0.0004672766 Test Loss 0.0003242568927767271\n",
      "656 Train Loss 0.00046566248 Test Loss 0.00032509044725294604\n",
      "657 Train Loss 0.00046413514 Test Loss 0.00033003639665051096\n",
      "658 Train Loss 0.0004608474 Test Loss 0.0003322909569963055\n",
      "659 Train Loss 0.00045887424 Test Loss 0.00032835628780977165\n",
      "660 Train Loss 0.00045544963 Test Loss 0.0003113989816676637\n",
      "661 Train Loss 0.0004529267 Test Loss 0.0002969513563965829\n",
      "662 Train Loss 0.00045073853 Test Loss 0.0002885461494162915\n",
      "663 Train Loss 0.00044861576 Test Loss 0.0002891246702103584\n",
      "664 Train Loss 0.00048663846 Test Loss 0.0002856769963967112\n",
      "665 Train Loss 0.0004478179 Test Loss 0.0002875686751669203\n",
      "666 Train Loss 0.00044517577 Test Loss 0.00029734751762834443\n",
      "667 Train Loss 0.00044324665 Test Loss 0.0002963531503772897\n",
      "668 Train Loss 0.00044153188 Test Loss 0.0002885130829332308\n",
      "669 Train Loss 0.0004410955 Test Loss 0.00026600975689500354\n",
      "670 Train Loss 0.00044187554 Test Loss 0.000270835656026958\n",
      "671 Train Loss 0.00043931656 Test Loss 0.00026578175365295545\n",
      "672 Train Loss 0.00043809466 Test Loss 0.00026735739694294723\n",
      "673 Train Loss 0.0004372539 Test Loss 0.00026740507670669164\n",
      "674 Train Loss 0.00043621555 Test Loss 0.00026642237333249897\n",
      "675 Train Loss 0.0004349606 Test Loss 0.00026702843024392696\n",
      "676 Train Loss 0.00043352105 Test Loss 0.0002637662190479949\n",
      "677 Train Loss 0.0004321938 Test Loss 0.00026565509326185484\n",
      "678 Train Loss 0.00043069728 Test Loss 0.0002644821828315526\n",
      "679 Train Loss 0.00042887303 Test Loss 0.0002589329086922383\n",
      "680 Train Loss 0.00042682094 Test Loss 0.00025673734186171184\n",
      "681 Train Loss 0.0004245811 Test Loss 0.00026037809812626283\n",
      "682 Train Loss 0.00042302493 Test Loss 0.0002711020575509297\n",
      "683 Train Loss 0.00042471892 Test Loss 0.00030018498785246655\n",
      "684 Train Loss 0.0004222609 Test Loss 0.00028109193291349176\n",
      "685 Train Loss 0.00042102966 Test Loss 0.00029296846752021536\n",
      "686 Train Loss 0.00042032092 Test Loss 0.00028543910895354304\n",
      "687 Train Loss 0.0004192803 Test Loss 0.00026181124205611157\n",
      "688 Train Loss 0.0004187412 Test Loss 0.000249270945920715\n",
      "689 Train Loss 0.00041785225 Test Loss 0.00023285110183722614\n",
      "690 Train Loss 0.00041823467 Test Loss 0.00023267055105329973\n",
      "691 Train Loss 0.00041751345 Test Loss 0.00023272811912219737\n",
      "692 Train Loss 0.00041683353 Test Loss 0.00023186590768708296\n",
      "693 Train Loss 0.00041637084 Test Loss 0.00023503863100994137\n",
      "694 Train Loss 0.0004157291 Test Loss 0.00024054930578193664\n",
      "695 Train Loss 0.00041529653 Test Loss 0.00024369850570586386\n",
      "696 Train Loss 0.00041479504 Test Loss 0.0002447609895326227\n",
      "697 Train Loss 0.00041442842 Test Loss 0.0002442893761974336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698 Train Loss 0.0004141074 Test Loss 0.00023881871862410124\n",
      "699 Train Loss 0.0004136505 Test Loss 0.00022934416708435292\n",
      "700 Train Loss 0.0004131665 Test Loss 0.0002246568626844298\n",
      "701 Train Loss 0.0004123623 Test Loss 0.00022042272922564662\n",
      "702 Train Loss 0.0004112959 Test Loss 0.00022371902953119424\n",
      "703 Train Loss 0.00041002702 Test Loss 0.0002332206017402722\n",
      "704 Train Loss 0.00040788445 Test Loss 0.00025730801096216573\n",
      "705 Train Loss 0.00040648808 Test Loss 0.0002721711947376285\n",
      "706 Train Loss 0.00040466932 Test Loss 0.0002847998225237908\n",
      "707 Train Loss 0.000402854 Test Loss 0.0002759503209250485\n",
      "708 Train Loss 0.00040085684 Test Loss 0.00026110535031769383\n",
      "709 Train Loss 0.00039823673 Test Loss 0.00023133303985421798\n",
      "710 Train Loss 0.0003965324 Test Loss 0.00021956497196918285\n",
      "711 Train Loss 0.0003951508 Test Loss 0.0002210679934352769\n",
      "712 Train Loss 0.00039421895 Test Loss 0.00023488723345975674\n",
      "713 Train Loss 0.00039362308 Test Loss 0.00023869431268797077\n",
      "714 Train Loss 0.00039306216 Test Loss 0.00024130224464927584\n",
      "715 Train Loss 0.00039274603 Test Loss 0.00023861154271067345\n",
      "716 Train Loss 0.00040908187 Test Loss 0.0002537572349974247\n",
      "717 Train Loss 0.00039258145 Test Loss 0.00023896728367074432\n",
      "718 Train Loss 0.00039210898 Test Loss 0.00023644264268901777\n",
      "719 Train Loss 0.00039173165 Test Loss 0.0002350473485236173\n",
      "720 Train Loss 0.0003913143 Test Loss 0.00023633855349723044\n",
      "721 Train Loss 0.00039093173 Test Loss 0.0002415914676772218\n",
      "722 Train Loss 0.00039048205 Test Loss 0.0002445523596509711\n",
      "723 Train Loss 0.000390677 Test Loss 0.00023526313288852374\n",
      "724 Train Loss 0.0003901244 Test Loss 0.00023990034730823637\n",
      "725 Train Loss 0.00038938623 Test Loss 0.00024373116389801854\n",
      "726 Train Loss 0.00038821317 Test Loss 0.0002486248442582587\n",
      "727 Train Loss 0.000387071 Test Loss 0.00025615768429926576\n",
      "728 Train Loss 0.00038479143 Test Loss 0.0002752353497159604\n",
      "729 Train Loss 0.00038242195 Test Loss 0.000312150303956363\n",
      "730 Train Loss 0.00038007676 Test Loss 0.00033966110236997334\n",
      "731 Train Loss 0.00037796344 Test Loss 0.0003485590004519946\n",
      "732 Train Loss 0.00037545958 Test Loss 0.00035748100249755196\n",
      "733 Train Loss 0.00037950085 Test Loss 0.00035246274877155924\n",
      "734 Train Loss 0.000374534 Test Loss 0.0003556316671063532\n",
      "735 Train Loss 0.000372074 Test Loss 0.000370730518604566\n",
      "736 Train Loss 0.00037038207 Test Loss 0.00038911634031239595\n",
      "737 Train Loss 0.0003699031 Test Loss 0.0004190923526008447\n",
      "738 Train Loss 0.00036958497 Test Loss 0.0004328108675065445\n",
      "739 Train Loss 0.00036922755 Test Loss 0.00042958909718952343\n",
      "740 Train Loss 0.0003688414 Test Loss 0.0004272243382662719\n",
      "741 Train Loss 0.00036846692 Test Loss 0.0004235242171021773\n",
      "742 Train Loss 0.0003680849 Test Loss 0.0004190431696714269\n",
      "743 Train Loss 0.0003676152 Test Loss 0.0004158862484016212\n",
      "744 Train Loss 0.00036732684 Test Loss 0.00042102867944790906\n",
      "745 Train Loss 0.00036700213 Test Loss 0.0004297328170392613\n",
      "746 Train Loss 0.0003667305 Test Loss 0.0004405997976878965\n",
      "747 Train Loss 0.00036657928 Test Loss 0.00044575625254791114\n",
      "748 Train Loss 0.00036642942 Test Loss 0.00044465454614623235\n",
      "749 Train Loss 0.00036622147 Test Loss 0.00044483783425167546\n",
      "750 Train Loss 0.00036596833 Test Loss 0.0004367159841718873\n",
      "751 Train Loss 0.00036567784 Test Loss 0.0004348808235108913\n",
      "752 Train Loss 0.00037178886 Test Loss 0.00043787330782714835\n",
      "753 Train Loss 0.0003655665 Test Loss 0.00043511866287453094\n",
      "754 Train Loss 0.000365253 Test Loss 0.0004344962880076117\n",
      "755 Train Loss 0.00036489937 Test Loss 0.00043350625875531265\n",
      "756 Train Loss 0.0003645714 Test Loss 0.0004354622349724107\n",
      "757 Train Loss 0.00036427483 Test Loss 0.000433977715685876\n",
      "758 Train Loss 0.00036402984 Test Loss 0.00044531566062293895\n",
      "759 Train Loss 0.00036376144 Test Loss 0.0004447679090281412\n",
      "760 Train Loss 0.0003634537 Test Loss 0.00045086801681697\n",
      "761 Train Loss 0.00036318155 Test Loss 0.00045883246748933793\n",
      "762 Train Loss 0.000363131 Test Loss 0.0004938408882427841\n",
      "763 Train Loss 0.00036754448 Test Loss 0.000540013508901032\n",
      "764 Train Loss 0.00036243096 Test Loss 0.000505330091625484\n",
      "765 Train Loss 0.00036459567 Test Loss 0.0005291622262376327\n",
      "766 Train Loss 0.00036225058 Test Loss 0.0005104007586172116\n",
      "767 Train Loss 0.00041681802 Test Loss 0.00044843395295659\n",
      "768 Train Loss 0.00036202796 Test Loss 0.0005055498850282269\n",
      "769 Train Loss 0.00036109303 Test Loss 0.0005061178872335045\n",
      "770 Train Loss 0.00035943004 Test Loss 0.000499218269609813\n",
      "771 Train Loss 0.00035785994 Test Loss 0.0004955195998790536\n",
      "772 Train Loss 0.00035570655 Test Loss 0.0004922026359587462\n",
      "773 Train Loss 0.00035363645 Test Loss 0.0004794896391196781\n",
      "774 Train Loss 0.00035215213 Test Loss 0.00045483258085056877\n",
      "775 Train Loss 0.00034965106 Test Loss 0.0004485279606208777\n",
      "776 Train Loss 0.000348057 Test Loss 0.00044589149153310937\n",
      "777 Train Loss 0.0003461932 Test Loss 0.0004718141600967474\n",
      "778 Train Loss 0.00034386976 Test Loss 0.0004781647838363422\n",
      "779 Train Loss 0.00034147204 Test Loss 0.0004636097262142973\n",
      "780 Train Loss 0.00034185612 Test Loss 0.00042721809088293945\n",
      "781 Train Loss 0.00033989648 Test Loss 0.0004452400593048567\n",
      "782 Train Loss 0.00033810062 Test Loss 0.000437192753798013\n",
      "783 Train Loss 0.0003354259 Test Loss 0.00041517848784883147\n",
      "784 Train Loss 0.00033392484 Test Loss 0.00038722803703339587\n",
      "785 Train Loss 0.000332203 Test Loss 0.0003543502178124325\n",
      "786 Train Loss 0.00033054696 Test Loss 0.0003539755153389182\n",
      "787 Train Loss 0.00032896228 Test Loss 0.0003639059473277948\n",
      "788 Train Loss 0.00033076885 Test Loss 0.00032804132951747873\n",
      "789 Train Loss 0.0003284025 Test Loss 0.00035134960211858843\n",
      "790 Train Loss 0.00033019518 Test Loss 0.00029956753289574336\n",
      "791 Train Loss 0.00032776143 Test Loss 0.00033215388260666035\n",
      "792 Train Loss 0.00032665662 Test Loss 0.0003516773093316485\n",
      "793 Train Loss 0.00032564806 Test Loss 0.00035492269389234866\n",
      "794 Train Loss 0.0003251033 Test Loss 0.0003762255951196001\n",
      "795 Train Loss 0.00032469284 Test Loss 0.0003804133293037314\n",
      "796 Train Loss 0.00032445393 Test Loss 0.0003751839622014321\n",
      "797 Train Loss 0.0003243047 Test Loss 0.0003720362478728648\n",
      "798 Train Loss 0.00032413725 Test Loss 0.0003680477243636279\n",
      "799 Train Loss 0.0003239525 Test Loss 0.0003693554441384926\n",
      "800 Train Loss 0.0003250424 Test Loss 0.0003793687251939413\n",
      "801 Train Loss 0.00032389868 Test Loss 0.0003710797078729962\n",
      "802 Train Loss 0.00032366914 Test Loss 0.0003779272282738712\n",
      "803 Train Loss 0.00032346282 Test Loss 0.0003747938583816168\n",
      "804 Train Loss 0.00032323424 Test Loss 0.00038109438967484465\n",
      "805 Train Loss 0.00032279594 Test Loss 0.00039067511691801997\n",
      "806 Train Loss 0.00032238077 Test Loss 0.00040064418133118186\n",
      "807 Train Loss 0.00032159453 Test Loss 0.0004087342738911081\n",
      "808 Train Loss 0.00032063064 Test Loss 0.00041715106078506003\n",
      "809 Train Loss 0.00032865378 Test Loss 0.0004352029240379297\n",
      "810 Train Loss 0.0003204096 Test Loss 0.0004191116751690217\n",
      "811 Train Loss 0.0003187444 Test Loss 0.0004309920274443801\n",
      "812 Train Loss 0.00031702404 Test Loss 0.0004212788504303485\n",
      "813 Train Loss 0.00031483773 Test Loss 0.00041574119755635687\n",
      "814 Train Loss 0.00031346345 Test Loss 0.0004022928142294581\n",
      "815 Train Loss 0.0003425988 Test Loss 0.00033485768510004043\n",
      "816 Train Loss 0.00031132 Test Loss 0.0003811892365888523\n",
      "817 Train Loss 0.000309484 Test Loss 0.0003605264282994769\n",
      "818 Train Loss 0.00030759795 Test Loss 0.00034613461884062865\n",
      "819 Train Loss 0.0003095298 Test Loss 0.0003969216486605811\n",
      "820 Train Loss 0.0003066858 Test Loss 0.00036374908493386345\n",
      "821 Train Loss 0.00030495995 Test Loss 0.00037569901049017953\n",
      "822 Train Loss 0.0003017378 Test Loss 0.0004311681292406369\n",
      "823 Train Loss 0.00030056533 Test Loss 0.0004805946052003202\n",
      "824 Train Loss 0.00029821967 Test Loss 0.000493769878597493\n",
      "825 Train Loss 0.00029583243 Test Loss 0.0004901990944954631\n",
      "826 Train Loss 0.00029413425 Test Loss 0.00048540080580512237\n",
      "827 Train Loss 0.0002929261 Test Loss 0.00045839717798455454\n",
      "828 Train Loss 0.00029219355 Test Loss 0.00045958788505235325\n",
      "829 Train Loss 0.00029162102 Test Loss 0.0004506557088614988\n",
      "830 Train Loss 0.0002911388 Test Loss 0.0004265322768241878\n",
      "831 Train Loss 0.00029098208 Test Loss 0.00043031146371926677\n",
      "832 Train Loss 0.00029093624 Test Loss 0.0004026610259505354\n",
      "833 Train Loss 0.00029068705 Test Loss 0.00041562924724251426\n",
      "834 Train Loss 0.00029028943 Test Loss 0.00041389970041343983\n",
      "835 Train Loss 0.00028987383 Test Loss 0.0004253792889715459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836 Train Loss 0.00028931722 Test Loss 0.000447078322385244\n",
      "837 Train Loss 0.00028893887 Test Loss 0.0004642781876374792\n",
      "838 Train Loss 0.00028854792 Test Loss 0.00046912569307499136\n",
      "839 Train Loss 0.00028811558 Test Loss 0.00046646459659077937\n",
      "840 Train Loss 0.00028780333 Test Loss 0.00045120498191106973\n",
      "841 Train Loss 0.00028753665 Test Loss 0.00044172100334208557\n",
      "842 Train Loss 0.00028723985 Test Loss 0.0004395364406760673\n",
      "843 Train Loss 0.0002869124 Test Loss 0.00043367094052064757\n",
      "844 Train Loss 0.00028678845 Test Loss 0.00040712028870938216\n",
      "845 Train Loss 0.0002864737 Test Loss 0.0004101886488699767\n",
      "846 Train Loss 0.00028600445 Test Loss 0.0004284219759776942\n",
      "847 Train Loss 0.00028543922 Test Loss 0.0004364570820568633\n",
      "848 Train Loss 0.00028487606 Test Loss 0.0004444186373291517\n",
      "849 Train Loss 0.00028441768 Test Loss 0.0004494605269315964\n",
      "850 Train Loss 0.00028407108 Test Loss 0.00046641970501814996\n",
      "851 Train Loss 0.00028380597 Test Loss 0.00047720389178626944\n",
      "852 Train Loss 0.00028360568 Test Loss 0.00048130680065661737\n",
      "853 Train Loss 0.0002833258 Test Loss 0.0004905369307379665\n",
      "854 Train Loss 0.00028312026 Test Loss 0.0004856094946591688\n",
      "855 Train Loss 0.00028296313 Test Loss 0.0005014146819238408\n",
      "856 Train Loss 0.00028368644 Test Loss 0.0004884534657929912\n",
      "857 Train Loss 0.00028278073 Test Loss 0.0004972742483993311\n",
      "858 Train Loss 0.00028245468 Test Loss 0.00048024100474017636\n",
      "859 Train Loss 0.0002818455 Test Loss 0.00044504422851262805\n",
      "860 Train Loss 0.00028118474 Test Loss 0.00041320993182328346\n",
      "861 Train Loss 0.0002803029 Test Loss 0.00037597396386169194\n",
      "862 Train Loss 0.00028038828 Test Loss 0.00035185094792513846\n",
      "863 Train Loss 0.00027985423 Test Loss 0.0003639894189346696\n",
      "864 Train Loss 0.00027947946 Test Loss 0.00034851536393492916\n",
      "865 Train Loss 0.00027857712 Test Loss 0.00034480669259743656\n",
      "866 Train Loss 0.0002777417 Test Loss 0.0003520249351786061\n",
      "867 Train Loss 0.00027607978 Test Loss 0.0003529314175209592\n",
      "868 Train Loss 0.00027495556 Test Loss 0.00034410381768535525\n",
      "869 Train Loss 0.00027439318 Test Loss 0.00035874699590199933\n",
      "870 Train Loss 0.0002741047 Test Loss 0.0003467537011372726\n",
      "871 Train Loss 0.00027370895 Test Loss 0.00035145285503434447\n",
      "872 Train Loss 0.00027317522 Test Loss 0.0003484603830420333\n",
      "873 Train Loss 0.00027264105 Test Loss 0.0003559158509425888\n",
      "874 Train Loss 0.0002719254 Test Loss 0.00035397654930179365\n",
      "875 Train Loss 0.00027171048 Test Loss 0.00038553799387980705\n",
      "876 Train Loss 0.00027355686 Test Loss 0.0003841884246234675\n",
      "877 Train Loss 0.0002705053 Test Loss 0.00038477282304375465\n",
      "878 Train Loss 0.00026924282 Test Loss 0.00037314627839016653\n",
      "879 Train Loss 0.000267121 Test Loss 0.00036750922013293577\n",
      "880 Train Loss 0.00026682517 Test Loss 0.0003627097617420704\n",
      "881 Train Loss 0.00026590706 Test Loss 0.00036475044966657004\n",
      "882 Train Loss 0.00026459034 Test Loss 0.0003857564202485498\n",
      "883 Train Loss 0.00026381947 Test Loss 0.0004133922844974196\n",
      "884 Train Loss 0.00026344924 Test Loss 0.00040508968629156435\n",
      "885 Train Loss 0.00026313786 Test Loss 0.0003993808955311461\n",
      "886 Train Loss 0.00026262525 Test Loss 0.0003894396141410465\n",
      "887 Train Loss 0.00026217863 Test Loss 0.00038124447949427934\n",
      "888 Train Loss 0.00026179076 Test Loss 0.0003650410860405443\n",
      "889 Train Loss 0.00026138054 Test Loss 0.0003700616806754534\n",
      "890 Train Loss 0.00026107798 Test Loss 0.00037308476069023106\n",
      "891 Train Loss 0.00026077934 Test Loss 0.0003602819416117537\n",
      "892 Train Loss 0.0002605874 Test Loss 0.00035173111516662687\n",
      "893 Train Loss 0.00026048895 Test Loss 0.0003436003318821043\n",
      "894 Train Loss 0.0002604431 Test Loss 0.0003393752246237419\n",
      "895 Train Loss 0.00026038743 Test Loss 0.00033904290938467093\n",
      "896 Train Loss 0.00026030582 Test Loss 0.00034036399972127397\n",
      "897 Train Loss 0.0002602613 Test Loss 0.00034013947575011605\n",
      "898 Train Loss 0.00026023368 Test Loss 0.00032730771009224996\n",
      "899 Train Loss 0.00026035524 Test Loss 0.00033866431123523466\n",
      "900 Train Loss 0.00026014907 Test Loss 0.0003315659899648117\n",
      "901 Train Loss 0.00026005018 Test Loss 0.0003349147114077926\n",
      "902 Train Loss 0.0002599408 Test Loss 0.00033584716658451583\n",
      "903 Train Loss 0.00025969802 Test Loss 0.00032850755062433065\n",
      "904 Train Loss 0.0002610498 Test Loss 0.0003800263127421792\n",
      "905 Train Loss 0.00025963917 Test Loss 0.00033676937092037016\n",
      "906 Train Loss 0.0002592895 Test Loss 0.0003242032555325527\n",
      "907 Train Loss 0.00025891277 Test Loss 0.00031531766087669133\n",
      "908 Train Loss 0.0002582124 Test Loss 0.0003120861807331024\n",
      "909 Train Loss 0.00026843997 Test Loss 0.0002843409368790244\n",
      "910 Train Loss 0.00025806302 Test Loss 0.0003085720149310413\n",
      "911 Train Loss 0.0002572244 Test Loss 0.0003088577033063904\n",
      "912 Train Loss 0.00025646205 Test Loss 0.00031184459077798125\n",
      "913 Train Loss 0.00025518218 Test Loss 0.00032244995941232887\n",
      "914 Train Loss 0.00025424728 Test Loss 0.00031401274123058696\n",
      "915 Train Loss 0.0002526992 Test Loss 0.0003018059851878851\n",
      "916 Train Loss 0.0002517567 Test Loss 0.00029254102598310543\n",
      "917 Train Loss 0.00024935097 Test Loss 0.000284249023980739\n",
      "918 Train Loss 0.0002468205 Test Loss 0.00028869261335498156\n",
      "919 Train Loss 0.0002541839 Test Loss 0.0002968649030110441\n",
      "920 Train Loss 0.00024520973 Test Loss 0.0002914379989640746\n",
      "921 Train Loss 0.00024282542 Test Loss 0.0003014943865759227\n",
      "922 Train Loss 0.00024131537 Test Loss 0.0003087395222171387\n",
      "923 Train Loss 0.00024046589 Test Loss 0.00030516605339505563\n",
      "924 Train Loss 0.00023981617 Test Loss 0.00030532809570230773\n",
      "925 Train Loss 0.0002392669 Test Loss 0.0003126315824811029\n",
      "926 Train Loss 0.0002388791 Test Loss 0.0003115095411874222\n",
      "927 Train Loss 0.00023860746 Test Loss 0.0003204981584653015\n",
      "928 Train Loss 0.00026201922 Test Loss 0.0002850356950271067\n",
      "929 Train Loss 0.00023854955 Test Loss 0.0003184967852817558\n",
      "930 Train Loss 0.00023808007 Test Loss 0.0003429730148363951\n",
      "931 Train Loss 0.00023776926 Test Loss 0.00033754284351194207\n",
      "932 Train Loss 0.00023759672 Test Loss 0.00033592754721763706\n",
      "933 Train Loss 0.00023742084 Test Loss 0.0003389034620369371\n",
      "934 Train Loss 0.00023721758 Test Loss 0.0003428583453635503\n",
      "935 Train Loss 0.00023705163 Test Loss 0.0003504316273630578\n",
      "936 Train Loss 0.00023692852 Test Loss 0.00036372605329247084\n",
      "937 Train Loss 0.00023675906 Test Loss 0.0003626632585159129\n",
      "938 Train Loss 0.00023650333 Test Loss 0.00035976842751253785\n",
      "939 Train Loss 0.00023632967 Test Loss 0.00035924576855671096\n",
      "940 Train Loss 0.00023621685 Test Loss 0.0003635388111357022\n",
      "941 Train Loss 0.00023630193 Test Loss 0.00036606443478417306\n",
      "942 Train Loss 0.0002361358 Test Loss 0.0003645687152333669\n",
      "943 Train Loss 0.000235852 Test Loss 0.000365761275140935\n",
      "944 Train Loss 0.0002351242 Test Loss 0.00036736631438806733\n",
      "945 Train Loss 0.00023474023 Test Loss 0.00036399844822821993\n",
      "946 Train Loss 0.00023413627 Test Loss 0.0003629041621350551\n",
      "947 Train Loss 0.00023355009 Test Loss 0.000358851462093178\n",
      "948 Train Loss 0.00023328021 Test Loss 0.0003724013534304945\n",
      "949 Train Loss 0.0002328172 Test Loss 0.00038044342646727637\n",
      "950 Train Loss 0.00023250582 Test Loss 0.00038691129556999104\n",
      "951 Train Loss 0.000232057 Test Loss 0.00039851038040544687\n",
      "952 Train Loss 0.00023165418 Test Loss 0.00040229211047185893\n",
      "953 Train Loss 0.00023113885 Test Loss 0.0004032614576646866\n",
      "954 Train Loss 0.0002380927 Test Loss 0.0004343926928909568\n",
      "955 Train Loss 0.00023101119 Test Loss 0.0004067587698615859\n",
      "956 Train Loss 0.00023017812 Test Loss 0.00040084976237489146\n",
      "957 Train Loss 0.00022963171 Test Loss 0.00039835924708935065\n",
      "958 Train Loss 0.00022871981 Test Loss 0.0003849637294941422\n",
      "959 Train Loss 0.00022793256 Test Loss 0.00039367390788049397\n",
      "960 Train Loss 0.00022724591 Test Loss 0.0003997297971451211\n",
      "961 Train Loss 0.00022642832 Test Loss 0.0004002570528137226\n",
      "962 Train Loss 0.00022585857 Test Loss 0.00039305659128992205\n",
      "963 Train Loss 0.00022560256 Test Loss 0.0003765916031115848\n",
      "964 Train Loss 0.00022477594 Test Loss 0.0003606981458806449\n",
      "965 Train Loss 0.0002241611 Test Loss 0.0003558677861315679\n",
      "966 Train Loss 0.00022344898 Test Loss 0.00035373451720975476\n",
      "967 Train Loss 0.0002227643 Test Loss 0.00035441087377202917\n",
      "968 Train Loss 0.00022197308 Test Loss 0.0003539683382941954\n",
      "969 Train Loss 0.00022096603 Test Loss 0.00035935731726862254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970 Train Loss 0.00021998945 Test Loss 0.00034510634786226566\n",
      "971 Train Loss 0.00022386882 Test Loss 0.00035967767113779614\n",
      "972 Train Loss 0.00021943414 Test Loss 0.0003485011648848485\n",
      "973 Train Loss 0.00021862196 Test Loss 0.00034809940055440317\n",
      "974 Train Loss 0.0002180438 Test Loss 0.00034620797661883996\n",
      "975 Train Loss 0.00021756376 Test Loss 0.0003462043338134416\n",
      "976 Train Loss 0.00021703757 Test Loss 0.000348455526099327\n",
      "977 Train Loss 0.000216669 Test Loss 0.00034858356708515425\n",
      "978 Train Loss 0.0002163228 Test Loss 0.0003528088251728713\n",
      "979 Train Loss 0.0002159678 Test Loss 0.0003511211627115235\n",
      "980 Train Loss 0.00021571509 Test Loss 0.000365480661386605\n",
      "981 Train Loss 0.0002154072 Test Loss 0.0003658675478828134\n",
      "982 Train Loss 0.00021506903 Test Loss 0.0003456412602432155\n",
      "983 Train Loss 0.00021463542 Test Loss 0.00034840378636668943\n",
      "984 Train Loss 0.00021432323 Test Loss 0.0003593321989797232\n",
      "985 Train Loss 0.00021364467 Test Loss 0.0003767338557423408\n",
      "986 Train Loss 0.00021319359 Test Loss 0.0003677017929080448\n",
      "987 Train Loss 0.0002126625 Test Loss 0.00036813603659818827\n",
      "988 Train Loss 0.00021223423 Test Loss 0.0003768179734442338\n",
      "989 Train Loss 0.00021203792 Test Loss 0.0003740076726509249\n",
      "990 Train Loss 0.00021188884 Test Loss 0.00037016935016430315\n",
      "991 Train Loss 0.00021173854 Test Loss 0.00036719788326000804\n",
      "992 Train Loss 0.00021158149 Test Loss 0.0003636903075568782\n",
      "993 Train Loss 0.00021133284 Test Loss 0.0003581874071861312\n",
      "994 Train Loss 0.00021095749 Test Loss 0.00035105273196787127\n",
      "995 Train Loss 0.00021072113 Test Loss 0.0003421284526180724\n",
      "996 Train Loss 0.00021236227 Test Loss 0.0003686636679552784\n",
      "997 Train Loss 0.00021049005 Test Loss 0.0003486041453178385\n",
      "998 Train Loss 0.00021029238 Test Loss 0.00035394367158457783\n",
      "999 Train Loss 0.00021011544 Test Loss 0.000356525302393477\n",
      "1000 Train Loss 0.0002100174 Test Loss 0.0003582629169366866\n",
      "1001 Train Loss 0.00020981595 Test Loss 0.0003605317912003175\n",
      "1002 Train Loss 0.00020967275 Test Loss 0.00036698904079865527\n",
      "1003 Train Loss 0.00020954132 Test Loss 0.0003665510382081981\n",
      "1004 Train Loss 0.00020946137 Test Loss 0.00036370536969060655\n",
      "1005 Train Loss 0.00021063635 Test Loss 0.00031780644304293276\n",
      "1006 Train Loss 0.00020906952 Test Loss 0.00034737130238597744\n",
      "1007 Train Loss 0.00020847245 Test Loss 0.00034581053429113016\n",
      "1008 Train Loss 0.00020769915 Test Loss 0.00034546474770119065\n",
      "1009 Train Loss 0.00020645428 Test Loss 0.0003407358488546208\n",
      "1010 Train Loss 0.00020632189 Test Loss 0.00033986481236437954\n",
      "1011 Train Loss 0.0002060314 Test Loss 0.00034019849758120253\n",
      "1012 Train Loss 0.00020543826 Test Loss 0.0003424937436009149\n",
      "1013 Train Loss 0.00020469677 Test Loss 0.00034494873992611667\n",
      "1014 Train Loss 0.00020395659 Test Loss 0.00035032497350002663\n",
      "1015 Train Loss 0.00020287966 Test Loss 0.00036428002779038065\n",
      "1016 Train Loss 0.0002018984 Test Loss 0.0003718811259057022\n",
      "1017 Train Loss 0.00020138008 Test Loss 0.00038543624362161454\n",
      "1018 Train Loss 0.00020085153 Test Loss 0.0003838006131227709\n",
      "1019 Train Loss 0.00020056471 Test Loss 0.00037856931049804436\n",
      "1020 Train Loss 0.00020011459 Test Loss 0.00037675096097812533\n",
      "1021 Train Loss 0.0001998831 Test Loss 0.0003804166422289089\n",
      "1022 Train Loss 0.00021234073 Test Loss 0.0005075741039212182\n",
      "1023 Train Loss 0.000199815 Test Loss 0.0003882004127590177\n",
      "1024 Train Loss 0.00019941015 Test Loss 0.00039366578316519255\n",
      "1025 Train Loss 0.00019919756 Test Loss 0.00040338335685731073\n",
      "1026 Train Loss 0.00020026558 Test Loss 0.00043488498463913484\n",
      "1027 Train Loss 0.00019849392 Test Loss 0.0004149543796618696\n",
      "1028 Train Loss 0.00019796847 Test Loss 0.000406968656747476\n",
      "1029 Train Loss 0.00019761806 Test Loss 0.000396691497880676\n",
      "1030 Train Loss 0.00019750248 Test Loss 0.00039441424982638847\n",
      "1031 Train Loss 0.0001973286 Test Loss 0.0003940178124776664\n",
      "1032 Train Loss 0.00019711477 Test Loss 0.0004007766811374506\n",
      "1033 Train Loss 0.00019692915 Test Loss 0.00040969713762039776\n",
      "1034 Train Loss 0.00019705258 Test Loss 0.00039842126177307336\n",
      "1035 Train Loss 0.00019684655 Test Loss 0.0004052683851106238\n",
      "1036 Train Loss 0.00019905201 Test Loss 0.0004544126072736411\n",
      "1037 Train Loss 0.0001967384 Test Loss 0.00041364633354006345\n",
      "1038 Train Loss 0.00019652472 Test Loss 0.0004136855163343353\n",
      "1039 Train Loss 0.00019622355 Test Loss 0.0004162425576465808\n",
      "1040 Train Loss 0.00019582422 Test Loss 0.0004158259416284661\n",
      "1041 Train Loss 0.00019553019 Test Loss 0.0004164528172634528\n",
      "1042 Train Loss 0.00019522099 Test Loss 0.000411517656924455\n",
      "1043 Train Loss 0.0001949674 Test Loss 0.000406605435674339\n",
      "1044 Train Loss 0.00019469442 Test Loss 0.0004031062386694999\n",
      "1045 Train Loss 0.00019442188 Test Loss 0.0003940927744585682\n",
      "1046 Train Loss 0.00019419771 Test Loss 0.00039035301385816073\n",
      "1047 Train Loss 0.0001937639 Test Loss 0.00036728746866921064\n",
      "1048 Train Loss 0.00019513533 Test Loss 0.0003985396135494722\n",
      "1049 Train Loss 0.00019353535 Test Loss 0.00037579230321567095\n",
      "1050 Train Loss 0.00019314112 Test Loss 0.00036444659068653006\n",
      "1051 Train Loss 0.00019264428 Test Loss 0.0003474845202605054\n",
      "1052 Train Loss 0.00019256005 Test Loss 0.0003447694883773351\n",
      "1053 Train Loss 0.0001921819 Test Loss 0.00035197586691174105\n",
      "1054 Train Loss 0.00019199171 Test Loss 0.0003533462795155546\n",
      "1055 Train Loss 0.00019174984 Test Loss 0.0003548268170500616\n",
      "1056 Train Loss 0.00019163973 Test Loss 0.0003535418199599677\n",
      "1057 Train Loss 0.00019151982 Test Loss 0.0003514073901571392\n",
      "1058 Train Loss 0.0001914135 Test Loss 0.00035096243892208863\n",
      "1059 Train Loss 0.00019124922 Test Loss 0.0003577471848930562\n",
      "1060 Train Loss 0.00019109323 Test Loss 0.00035457722962407\n",
      "1061 Train Loss 0.00019075582 Test Loss 0.00035019646809563646\n",
      "1062 Train Loss 0.00019051507 Test Loss 0.0003510723583721634\n",
      "1063 Train Loss 0.00019030542 Test Loss 0.00035244191670805863\n",
      "1064 Train Loss 0.00019125626 Test Loss 0.0003917733108828208\n",
      "1065 Train Loss 0.00019013709 Test Loss 0.0003629623627315537\n",
      "1066 Train Loss 0.00018994523 Test Loss 0.0003691335149152675\n",
      "1067 Train Loss 0.00018963678 Test Loss 0.0003769424836142986\n",
      "1068 Train Loss 0.00018947312 Test Loss 0.00037849759754057105\n",
      "1069 Train Loss 0.00018903575 Test Loss 0.0003769381119247882\n",
      "1070 Train Loss 0.0001885939 Test Loss 0.00037273483169680474\n",
      "1071 Train Loss 0.00018802065 Test Loss 0.00035597655742054953\n",
      "1072 Train Loss 0.00018984867 Test Loss 0.00034364797916425357\n",
      "1073 Train Loss 0.00018779977 Test Loss 0.0003519588446319236\n",
      "1074 Train Loss 0.00018727782 Test Loss 0.0003432402251321409\n",
      "1075 Train Loss 0.00018676723 Test Loss 0.000333485094585061\n",
      "1076 Train Loss 0.00018630081 Test Loss 0.00032932707314636323\n",
      "1077 Train Loss 0.00018902858 Test Loss 0.00035662756382124516\n",
      "1078 Train Loss 0.00018618206 Test Loss 0.0003333199494505585\n",
      "1079 Train Loss 0.00018603215 Test Loss 0.0003131950138103342\n",
      "1080 Train Loss 0.00018535933 Test Loss 0.00031614972872651533\n",
      "1081 Train Loss 0.00018588484 Test Loss 0.00033416849024998197\n",
      "1082 Train Loss 0.00018517436 Test Loss 0.0003218022442055684\n",
      "1083 Train Loss 0.0001847162 Test Loss 0.0003263119429691256\n",
      "1084 Train Loss 0.0001841053 Test Loss 0.00032857815114563295\n",
      "1085 Train Loss 0.00018349111 Test Loss 0.00033197227334327264\n",
      "1086 Train Loss 0.00018285782 Test Loss 0.00033198143244729707\n",
      "1087 Train Loss 0.00018215613 Test Loss 0.0003358463735321952\n",
      "1088 Train Loss 0.00018130835 Test Loss 0.0003430239975009763\n",
      "1089 Train Loss 0.00018326251 Test Loss 0.0003653938957445213\n",
      "1090 Train Loss 0.00018090142 Test Loss 0.00035020639962378614\n",
      "1091 Train Loss 0.00018047573 Test Loss 0.000348352007697085\n",
      "1092 Train Loss 0.00017960896 Test Loss 0.00034912190570721564\n",
      "1093 Train Loss 0.00017933767 Test Loss 0.00035283977294503765\n",
      "1094 Train Loss 0.00017906795 Test Loss 0.00035015591191663807\n",
      "1095 Train Loss 0.00017882306 Test Loss 0.00034841894803864295\n",
      "1096 Train Loss 0.00017864483 Test Loss 0.00034182634364594616\n",
      "1097 Train Loss 0.00017846728 Test Loss 0.0003374511544222825\n",
      "1098 Train Loss 0.00017833675 Test Loss 0.00033496659234749\n",
      "1099 Train Loss 0.0001782325 Test Loss 0.00033140947260829577\n",
      "1100 Train Loss 0.00017803963 Test Loss 0.0003301157507788989\n",
      "1101 Train Loss 0.00017772404 Test Loss 0.0003239382602542844\n",
      "1102 Train Loss 0.00017767468 Test Loss 0.0003236845270685229\n",
      "1103 Train Loss 0.00017816448 Test Loss 0.0003556848314316425\n",
      "1104 Train Loss 0.00017763581 Test Loss 0.0003299326652821516\n",
      "1105 Train Loss 0.00017759422 Test Loss 0.0003358606482233771\n",
      "1106 Train Loss 0.00017744998 Test Loss 0.0003264385656092046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107 Train Loss 0.00017729087 Test Loss 0.00032880613401033344\n",
      "1108 Train Loss 0.00017712994 Test Loss 0.0003311163794561877\n",
      "1109 Train Loss 0.0001769625 Test Loss 0.00033546791351677323\n",
      "1110 Train Loss 0.00017686654 Test Loss 0.0003352776090179926\n",
      "1111 Train Loss 0.00017674314 Test Loss 0.00033441312199216283\n",
      "1112 Train Loss 0.00017657643 Test Loss 0.0003304674537863091\n",
      "1113 Train Loss 0.00017646242 Test Loss 0.0003284654085763382\n",
      "1114 Train Loss 0.0001761963 Test Loss 0.00032033135796891485\n",
      "1115 Train Loss 0.00017614663 Test Loss 0.00032273759034921306\n",
      "1116 Train Loss 0.00017593273 Test Loss 0.00031847435015043904\n",
      "1117 Train Loss 0.00017581215 Test Loss 0.00031633249734620275\n",
      "1118 Train Loss 0.00017556471 Test Loss 0.0003150774788076117\n",
      "1119 Train Loss 0.00017527542 Test Loss 0.0003145692967173716\n",
      "1120 Train Loss 0.00017493985 Test Loss 0.00031463960757098557\n",
      "1121 Train Loss 0.00017434802 Test Loss 0.00032073289562744987\n",
      "1122 Train Loss 0.00017410843 Test Loss 0.0003090634007932623\n",
      "1123 Train Loss 0.00017398229 Test Loss 0.00028710219774622187\n",
      "1124 Train Loss 0.00017323197 Test Loss 0.00030999191553420907\n",
      "1125 Train Loss 0.00017285209 Test Loss 0.0003192384600953154\n",
      "1126 Train Loss 0.00017225847 Test Loss 0.0003316065845899796\n",
      "1127 Train Loss 0.00017159543 Test Loss 0.00033327135814808243\n",
      "1128 Train Loss 0.00017066044 Test Loss 0.00032338544786278124\n",
      "1129 Train Loss 0.00018285375 Test Loss 0.00030411719990237207\n",
      "1130 Train Loss 0.00017039999 Test Loss 0.00032044696709087326\n",
      "1131 Train Loss 0.0001691606 Test Loss 0.0003052381532956189\n",
      "1132 Train Loss 0.00016793163 Test Loss 0.0002866507411818067\n",
      "1133 Train Loss 0.00016745506 Test Loss 0.00028200258702694507\n",
      "1134 Train Loss 0.00016735515 Test Loss 0.0002828239061164626\n",
      "1135 Train Loss 0.00016681335 Test Loss 0.00028242462027200225\n",
      "1136 Train Loss 0.00016584172 Test Loss 0.0003011056716972863\n",
      "1137 Train Loss 0.00016497997 Test Loss 0.00029829155246902344\n",
      "1138 Train Loss 0.00016396336 Test Loss 0.00028710231193257197\n",
      "1139 Train Loss 0.0001631258 Test Loss 0.000268985156625052\n",
      "1140 Train Loss 0.00016267615 Test Loss 0.00025420012616038915\n",
      "1141 Train Loss 0.00016244706 Test Loss 0.0002477124454174791\n",
      "1142 Train Loss 0.00016197603 Test Loss 0.0002500913545937794\n",
      "1143 Train Loss 0.00016168632 Test Loss 0.00025316266032721\n",
      "1144 Train Loss 0.0001613194 Test Loss 0.0002486161205163057\n",
      "1145 Train Loss 0.00016147883 Test Loss 0.00023267885240878407\n",
      "1146 Train Loss 0.00016082756 Test Loss 0.00024068776830113312\n",
      "1147 Train Loss 0.00016042085 Test Loss 0.00023462945014710994\n",
      "1148 Train Loss 0.00016011899 Test Loss 0.00023123001690474986\n",
      "1149 Train Loss 0.0001599527 Test Loss 0.00022970853582766028\n",
      "1150 Train Loss 0.00015985582 Test Loss 0.0002318731036947802\n",
      "1151 Train Loss 0.00015975749 Test Loss 0.00023463018649143096\n",
      "1152 Train Loss 0.00015963355 Test Loss 0.00023507589249856288\n",
      "1153 Train Loss 0.00015965317 Test Loss 0.00024062399298313173\n",
      "1154 Train Loss 0.00015956207 Test Loss 0.0002376331801559171\n",
      "1155 Train Loss 0.00015941879 Test Loss 0.000240006409249763\n",
      "1156 Train Loss 0.00016721337 Test Loss 0.00027502303640002763\n",
      "1157 Train Loss 0.00015935366 Test Loss 0.0002427030464876575\n",
      "1158 Train Loss 0.00015920086 Test Loss 0.00024499177075714524\n",
      "1159 Train Loss 0.00015895904 Test Loss 0.00024865084063212543\n",
      "1160 Train Loss 0.00016248024 Test Loss 0.0002528909697078683\n",
      "1161 Train Loss 0.0001588962 Test Loss 0.00024899133454546376\n",
      "1162 Train Loss 0.00015870966 Test Loss 0.0002477702978104614\n",
      "1163 Train Loss 0.0001587773 Test Loss 0.0002627218815111815\n",
      "1164 Train Loss 0.00015858092 Test Loss 0.0002543434985019173\n",
      "1165 Train Loss 0.00015853115 Test Loss 0.00024518372169363324\n",
      "1166 Train Loss 0.00015838775 Test Loss 0.000247214046334887\n",
      "1167 Train Loss 0.00015832613 Test Loss 0.0002461450661671799\n",
      "1168 Train Loss 0.00015826478 Test Loss 0.00024298637300956702\n",
      "1169 Train Loss 0.00015816049 Test Loss 0.000242643422102705\n",
      "1170 Train Loss 0.0001580503 Test Loss 0.00024107664698284247\n",
      "1171 Train Loss 0.00015795222 Test Loss 0.00023867555375921956\n",
      "1172 Train Loss 0.0001580072 Test Loss 0.00023210888866276503\n",
      "1173 Train Loss 0.00015788736 Test Loss 0.00023583234737233747\n",
      "1174 Train Loss 0.00015868687 Test Loss 0.00021791063169671095\n",
      "1175 Train Loss 0.00015777888 Test Loss 0.00023092575598386355\n",
      "1176 Train Loss 0.0001577088 Test Loss 0.00023008313696530538\n",
      "1177 Train Loss 0.0001575814 Test Loss 0.00023027020618093336\n",
      "1178 Train Loss 0.0001575121 Test Loss 0.0002313560590435669\n",
      "1179 Train Loss 0.00015734861 Test Loss 0.00023464327955449735\n",
      "1180 Train Loss 0.00015715939 Test Loss 0.00023967047019198662\n",
      "1181 Train Loss 0.00015695227 Test Loss 0.00024546020025291085\n",
      "1182 Train Loss 0.00015679578 Test Loss 0.00024601759481062053\n",
      "1183 Train Loss 0.0001566509 Test Loss 0.0002429578534631089\n",
      "1184 Train Loss 0.0001564877 Test Loss 0.0002390256832483708\n",
      "1185 Train Loss 0.00015630518 Test Loss 0.00023386721900981014\n",
      "1186 Train Loss 0.00015617697 Test Loss 0.00023098133417020223\n",
      "1187 Train Loss 0.00015605635 Test Loss 0.00023136627187008015\n",
      "1188 Train Loss 0.00015595456 Test Loss 0.00023432008183250946\n",
      "1189 Train Loss 0.00015587229 Test Loss 0.00023979538284286345\n",
      "1190 Train Loss 0.0001557962 Test Loss 0.0002401581242486122\n",
      "1191 Train Loss 0.0001557123 Test Loss 0.00023936946823774948\n",
      "1192 Train Loss 0.00015560901 Test Loss 0.00023732932098482928\n",
      "1193 Train Loss 0.00015550922 Test Loss 0.00023718642911148768\n",
      "1194 Train Loss 0.00015535623 Test Loss 0.00023970701729906396\n",
      "1195 Train Loss 0.00015525431 Test Loss 0.00024175229813833514\n",
      "1196 Train Loss 0.00015638844 Test Loss 0.00026371325648707274\n",
      "1197 Train Loss 0.0001549915 Test Loss 0.00024823379227176186\n",
      "1198 Train Loss 0.000154713 Test Loss 0.00025067494973156915\n",
      "1199 Train Loss 0.00015432453 Test Loss 0.0002573356182277813\n",
      "1200 Train Loss 0.00015402262 Test Loss 0.00025879179127771845\n",
      "1201 Train Loss 0.00015357406 Test Loss 0.0002606394132564902\n",
      "1202 Train Loss 0.000153242 Test Loss 0.00026208539741004894\n",
      "1203 Train Loss 0.00015294958 Test Loss 0.0002557484467225142\n",
      "1204 Train Loss 0.0001527455 Test Loss 0.00025380145529496276\n",
      "1205 Train Loss 0.00015247284 Test Loss 0.0002525644635963754\n",
      "1206 Train Loss 0.00015219305 Test Loss 0.00025004030101635424\n",
      "1207 Train Loss 0.00015186387 Test Loss 0.00025385241780522905\n",
      "1208 Train Loss 0.00017504362 Test Loss 0.0002405166587781893\n",
      "1209 Train Loss 0.0001517521 Test Loss 0.00025274850213084245\n",
      "1210 Train Loss 0.00015139137 Test Loss 0.0002497430888129287\n",
      "1211 Train Loss 0.00015295093 Test Loss 0.0002598662858618944\n",
      "1212 Train Loss 0.00015131215 Test Loss 0.000251040428833934\n",
      "1213 Train Loss 0.00015110917 Test Loss 0.0002513675323510273\n",
      "1214 Train Loss 0.00015111678 Test Loss 0.0002487404161075524\n",
      "1215 Train Loss 0.00015095407 Test Loss 0.00025001780731993936\n",
      "1216 Train Loss 0.00015077333 Test Loss 0.0002552925789511642\n",
      "1217 Train Loss 0.00015063077 Test Loss 0.00025521562359723563\n",
      "1218 Train Loss 0.00015037105 Test Loss 0.00025808903199620774\n",
      "1219 Train Loss 0.00015018311 Test Loss 0.00025999908136838004\n",
      "1220 Train Loss 0.00014990622 Test Loss 0.0002619013125886174\n",
      "1221 Train Loss 0.00014961412 Test Loss 0.0002620778126626432\n",
      "1222 Train Loss 0.00014945673 Test Loss 0.0002588166134661344\n",
      "1223 Train Loss 0.00014921276 Test Loss 0.0002545212078571457\n",
      "1224 Train Loss 0.0001489879 Test Loss 0.00025321683538495935\n",
      "1225 Train Loss 0.0001486033 Test Loss 0.00025488244485115695\n",
      "1226 Train Loss 0.00014877031 Test Loss 0.0002640968329041622\n",
      "1227 Train Loss 0.00014849537 Test Loss 0.0002583851814284232\n",
      "1228 Train Loss 0.00014826673 Test Loss 0.00027061418874306975\n",
      "1229 Train Loss 0.00014807028 Test Loss 0.0002780270170700799\n",
      "1230 Train Loss 0.00014785047 Test Loss 0.00028943096914366633\n",
      "1231 Train Loss 0.00014773813 Test Loss 0.000286284941394225\n",
      "1232 Train Loss 0.0001476042 Test Loss 0.000281879943090241\n",
      "1233 Train Loss 0.00014747801 Test Loss 0.000275380389411884\n",
      "1234 Train Loss 0.00014734433 Test Loss 0.0002674280748165\n",
      "1235 Train Loss 0.00014732417 Test Loss 0.0002554281067183469\n",
      "1236 Train Loss 0.0001472169 Test Loss 0.00026077763956413317\n",
      "1237 Train Loss 0.0001472029 Test Loss 0.0002547001229693986\n",
      "1238 Train Loss 0.00014705575 Test Loss 0.00025734917713567167\n",
      "1239 Train Loss 0.00014720944 Test Loss 0.00025416294339854494\n",
      "1240 Train Loss 0.00014693078 Test Loss 0.00025602080394859\n",
      "1241 Train Loss 0.00014686672 Test Loss 0.00026094799150270186\n",
      "1242 Train Loss 0.00014683312 Test Loss 0.00026252181281559406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1243 Train Loss 0.00014679777 Test Loss 0.0002617257020224208\n",
      "1244 Train Loss 0.00014673531 Test Loss 0.0002638074324349995\n",
      "1245 Train Loss 0.00014668652 Test Loss 0.0002617834902781269\n",
      "1246 Train Loss 0.00014662158 Test Loss 0.000260378765023807\n",
      "1247 Train Loss 0.00014654608 Test Loss 0.0002591004881698596\n",
      "1248 Train Loss 0.00014649038 Test Loss 0.0002592173004275653\n",
      "1249 Train Loss 0.00014637092 Test Loss 0.00026099080276952165\n",
      "1250 Train Loss 0.00014622943 Test Loss 0.0002635365704318799\n",
      "1251 Train Loss 0.00014605034 Test Loss 0.00026693778374410376\n",
      "1252 Train Loss 0.00014604541 Test Loss 0.0002620571951094288\n",
      "1253 Train Loss 0.00014594263 Test Loss 0.00026442519212738143\n",
      "1254 Train Loss 0.00014575676 Test Loss 0.00026302471773992695\n",
      "1255 Train Loss 0.00014542973 Test Loss 0.00025838864802790127\n",
      "1256 Train Loss 0.00014525827 Test Loss 0.0002558299469758845\n",
      "1257 Train Loss 0.00014503783 Test Loss 0.00025265015309939995\n",
      "1258 Train Loss 0.00014483061 Test Loss 0.0002539090826369407\n",
      "1259 Train Loss 0.00014459716 Test Loss 0.000257066591422508\n",
      "1260 Train Loss 0.00014433418 Test Loss 0.00026418986063041173\n",
      "1261 Train Loss 0.00014424328 Test Loss 0.00027924300512111527\n",
      "1262 Train Loss 0.0001436809 Test Loss 0.00028298177405466354\n",
      "1263 Train Loss 0.00014342892 Test Loss 0.0002803206937152813\n",
      "1264 Train Loss 0.00014307506 Test Loss 0.00028180578195469743\n",
      "1265 Train Loss 0.00014282152 Test Loss 0.0002843548866283421\n",
      "1266 Train Loss 0.00014261351 Test Loss 0.00029494236984298894\n",
      "1267 Train Loss 0.0001593304 Test Loss 0.00027133224480618265\n",
      "1268 Train Loss 0.00014237326 Test Loss 0.00029137949539883125\n",
      "1269 Train Loss 0.00014204273 Test Loss 0.0002873895348995016\n",
      "1270 Train Loss 0.0001416567 Test Loss 0.0002827101654123228\n",
      "1271 Train Loss 0.00014134125 Test Loss 0.0002802498658911808\n",
      "1272 Train Loss 0.00014090525 Test Loss 0.00027715780833721616\n",
      "1273 Train Loss 0.00014076852 Test Loss 0.00027250925182341817\n",
      "1274 Train Loss 0.00014024305 Test Loss 0.00027051786207498986\n",
      "1275 Train Loss 0.0001399133 Test Loss 0.00026697050349901554\n",
      "1276 Train Loss 0.00013951509 Test Loss 0.0002651209512902126\n",
      "1277 Train Loss 0.00013899984 Test Loss 0.0002572670524287991\n",
      "1278 Train Loss 0.0001384143 Test Loss 0.0002456106197664842\n",
      "1279 Train Loss 0.00013865257 Test Loss 0.00023615800723828957\n",
      "1280 Train Loss 0.00013817029 Test Loss 0.00024118262956403182\n",
      "1281 Train Loss 0.0001378259 Test Loss 0.00024193338380600776\n",
      "1282 Train Loss 0.00013752756 Test Loss 0.0002459360763545993\n",
      "1283 Train Loss 0.00013734266 Test Loss 0.00025053745209346927\n",
      "1284 Train Loss 0.00013716347 Test Loss 0.00025643986898054455\n",
      "1285 Train Loss 0.00013700567 Test Loss 0.00025501443438789644\n",
      "1286 Train Loss 0.00013687383 Test Loss 0.0002525710053009329\n",
      "1287 Train Loss 0.00013676578 Test Loss 0.000245675153441582\n",
      "1288 Train Loss 0.00013667939 Test Loss 0.00024216994299665305\n",
      "1289 Train Loss 0.00013663684 Test Loss 0.0002427403201167022\n",
      "1290 Train Loss 0.00013656734 Test Loss 0.00024218934488360824\n",
      "1291 Train Loss 0.00013652476 Test Loss 0.00024450326488570774\n",
      "1292 Train Loss 0.00013645255 Test Loss 0.0002481939646956508\n",
      "1293 Train Loss 0.00013642042 Test Loss 0.0002502570424087189\n",
      "1294 Train Loss 0.00014577014 Test Loss 0.0003248266572861522\n",
      "1295 Train Loss 0.00013632195 Test Loss 0.00025637463761344405\n",
      "1296 Train Loss 0.00013624202 Test Loss 0.00025482601727516355\n",
      "1297 Train Loss 0.0001361677 Test Loss 0.000250713673093165\n",
      "1298 Train Loss 0.00013611812 Test Loss 0.00025127262897663193\n",
      "1299 Train Loss 0.00013604898 Test Loss 0.0002523197258641322\n",
      "1300 Train Loss 0.00013974839 Test Loss 0.00026825444518649227\n",
      "1301 Train Loss 0.00013603523 Test Loss 0.00025319653290209\n",
      "1302 Train Loss 0.00013596514 Test Loss 0.00025403862652398416\n",
      "1303 Train Loss 0.0001359046 Test Loss 0.00025466956871271186\n",
      "1304 Train Loss 0.00013584724 Test Loss 0.0002545167656781533\n",
      "1305 Train Loss 0.00013576634 Test Loss 0.0002534146248794915\n",
      "1306 Train Loss 0.00013565771 Test Loss 0.0002512541399141534\n",
      "1307 Train Loss 0.0001355438 Test Loss 0.00024944783183246204\n",
      "1308 Train Loss 0.00013545444 Test Loss 0.0002482638779392466\n",
      "1309 Train Loss 0.00013534063 Test Loss 0.00024741725135507336\n",
      "1310 Train Loss 0.00013523364 Test Loss 0.0002486079207976281\n",
      "1311 Train Loss 0.00013503566 Test Loss 0.00025507645578714633\n",
      "1312 Train Loss 0.00013607764 Test Loss 0.00026027211827263705\n",
      "1313 Train Loss 0.00013493272 Test Loss 0.00025615454199588006\n",
      "1314 Train Loss 0.00013480254 Test Loss 0.00025670536566795786\n",
      "1315 Train Loss 0.00013441066 Test Loss 0.0002594448400971944\n",
      "1316 Train Loss 0.0001346479 Test Loss 0.0002591840396351817\n",
      "1317 Train Loss 0.00013430655 Test Loss 0.0002593382456264744\n",
      "1318 Train Loss 0.00013419295 Test Loss 0.00025850247778376933\n",
      "1319 Train Loss 0.00013454535 Test Loss 0.00024145449333954003\n",
      "1320 Train Loss 0.00013413117 Test Loss 0.00025353383582915563\n",
      "1321 Train Loss 0.000135136 Test Loss 0.00025410090663931776\n",
      "1322 Train Loss 0.0001340897 Test Loss 0.0002535763829602019\n",
      "1323 Train Loss 0.00013393036 Test Loss 0.00025425214899523705\n",
      "1324 Train Loss 0.00013381294 Test Loss 0.00025194892502408635\n",
      "1325 Train Loss 0.00013365567 Test Loss 0.0002480170309634865\n",
      "1326 Train Loss 0.00013369575 Test Loss 0.00024340838970165723\n",
      "1327 Train Loss 0.00013356167 Test Loss 0.00024588217571283686\n",
      "1328 Train Loss 0.00013342603 Test Loss 0.00024279467701155387\n",
      "1329 Train Loss 0.0001334579 Test Loss 0.00024152465119336257\n",
      "1330 Train Loss 0.00013337078 Test Loss 0.00024209450754111465\n",
      "1331 Train Loss 0.00013322677 Test Loss 0.0002406818529617374\n",
      "1332 Train Loss 0.00013402133 Test Loss 0.0002357348954457468\n",
      "1333 Train Loss 0.00013315072 Test Loss 0.00023941157621604374\n",
      "1334 Train Loss 0.00013297709 Test Loss 0.00023873399442088356\n",
      "1335 Train Loss 0.00013263522 Test Loss 0.00023812360344131474\n",
      "1336 Train Loss 0.0001322997 Test Loss 0.00023956338681058038\n",
      "1337 Train Loss 0.000131933 Test Loss 0.000246014282156938\n",
      "1338 Train Loss 0.00013177106 Test Loss 0.00024810706673699534\n",
      "1339 Train Loss 0.00013163371 Test Loss 0.0002505324414956042\n",
      "1340 Train Loss 0.0001315613 Test Loss 0.0002508255977197271\n",
      "1341 Train Loss 0.0001314657 Test Loss 0.00025030209792890917\n",
      "1342 Train Loss 0.00013137834 Test Loss 0.0002497399067381575\n",
      "1343 Train Loss 0.0001312862 Test Loss 0.0002485073212518953\n",
      "1344 Train Loss 0.00013120178 Test Loss 0.0002472613547859814\n",
      "1345 Train Loss 0.00013112026 Test Loss 0.0002492992062098305\n",
      "1346 Train Loss 0.00013102837 Test Loss 0.00024894839517967753\n",
      "1347 Train Loss 0.00013091194 Test Loss 0.0002480099741100317\n",
      "1348 Train Loss 0.00013075021 Test Loss 0.0002503451136160266\n",
      "1349 Train Loss 0.00013060964 Test Loss 0.0002492906791268744\n",
      "1350 Train Loss 0.00013041541 Test Loss 0.00024719328774882465\n",
      "1351 Train Loss 0.00013026688 Test Loss 0.00024948357571290166\n",
      "1352 Train Loss 0.00013013104 Test Loss 0.00025269669056928097\n",
      "1353 Train Loss 0.00013002475 Test Loss 0.00025459950989591205\n",
      "1354 Train Loss 0.00012994581 Test Loss 0.00025560668425848073\n",
      "1355 Train Loss 0.00012988687 Test Loss 0.000254862530129692\n",
      "1356 Train Loss 0.00012978721 Test Loss 0.00025319883135292324\n",
      "1357 Train Loss 0.00012972485 Test Loss 0.0002513963951941639\n",
      "1358 Train Loss 0.00012963588 Test Loss 0.0002491631657706936\n",
      "1359 Train Loss 0.00012954943 Test Loss 0.00024708281865506933\n",
      "1360 Train Loss 0.00012945221 Test Loss 0.0002458935165909328\n",
      "1361 Train Loss 0.00012935854 Test Loss 0.0002465159999265294\n",
      "1362 Train Loss 0.0001292716 Test Loss 0.0002489553129675717\n",
      "1363 Train Loss 0.00012919135 Test Loss 0.0002527712927811074\n",
      "1364 Train Loss 0.00012910487 Test Loss 0.00025582026867495503\n",
      "1365 Train Loss 0.00012898297 Test Loss 0.00026042007541258934\n",
      "1366 Train Loss 0.00012885843 Test Loss 0.00025870444676745035\n",
      "1367 Train Loss 0.00012877246 Test Loss 0.00025676262617982485\n",
      "1368 Train Loss 0.00012856512 Test Loss 0.00024870714616100043\n",
      "1369 Train Loss 0.00012840031 Test Loss 0.00024547972254870105\n",
      "1370 Train Loss 0.00012817857 Test Loss 0.0002421258521835006\n",
      "1371 Train Loss 0.00012803689 Test Loss 0.00024239816774279557\n",
      "1372 Train Loss 0.00012791123 Test Loss 0.00024247002059502962\n",
      "1373 Train Loss 0.00012784867 Test Loss 0.0002417968648030908\n",
      "1374 Train Loss 0.0001277789 Test Loss 0.00023970529187925302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375 Train Loss 0.00012788293 Test Loss 0.00024119336338185925\n",
      "1376 Train Loss 0.00012773387 Test Loss 0.00024017513081898685\n",
      "1377 Train Loss 0.00012758907 Test Loss 0.0002335872715251883\n",
      "1378 Train Loss 0.00012734265 Test Loss 0.00022786204729627107\n",
      "1379 Train Loss 0.00012708487 Test Loss 0.00022235154762979256\n",
      "1380 Train Loss 0.00012682953 Test Loss 0.00022101477140668604\n",
      "1381 Train Loss 0.00012656511 Test Loss 0.0002184716410195727\n",
      "1382 Train Loss 0.00012626508 Test Loss 0.00021679458018580546\n",
      "1383 Train Loss 0.0001258132 Test Loss 0.00021704299246299842\n",
      "1384 Train Loss 0.00012524857 Test Loss 0.00022024761175621442\n",
      "1385 Train Loss 0.00012455942 Test Loss 0.00022130779547009175\n",
      "1386 Train Loss 0.00012552842 Test Loss 0.00022242510326837188\n",
      "1387 Train Loss 0.00012383609 Test Loss 0.00022152760792434645\n",
      "1388 Train Loss 0.0001233073 Test Loss 0.000217424992475274\n",
      "1389 Train Loss 0.00012291477 Test Loss 0.00021616847270373603\n",
      "1390 Train Loss 0.00012276207 Test Loss 0.00021447259770394998\n",
      "1391 Train Loss 0.00012242181 Test Loss 0.00021170357032106218\n",
      "1392 Train Loss 0.00012225447 Test Loss 0.00021636779729209012\n",
      "1393 Train Loss 0.00012193149 Test Loss 0.00021416069709491803\n",
      "1394 Train Loss 0.00012263705 Test Loss 0.00021423855038828636\n",
      "1395 Train Loss 0.00012149193 Test Loss 0.00021414868022578165\n",
      "1396 Train Loss 0.00012153227 Test Loss 0.00020680555888880328\n",
      "1397 Train Loss 0.000121257704 Test Loss 0.00021047076236099016\n",
      "1398 Train Loss 0.000120826226 Test Loss 0.00021341707699011145\n",
      "1399 Train Loss 0.00012059843 Test Loss 0.0002148737423166555\n",
      "1400 Train Loss 0.000120516546 Test Loss 0.00021315808927209953\n",
      "1401 Train Loss 0.00012037401 Test Loss 0.00021386701480129627\n",
      "1402 Train Loss 0.00012016925 Test Loss 0.00021242374103997558\n",
      "1403 Train Loss 0.00011983294 Test Loss 0.00021174935579366526\n",
      "1404 Train Loss 0.00011926775 Test Loss 0.00021134435390508672\n",
      "1405 Train Loss 0.000118909724 Test Loss 0.00021047251849445032\n",
      "1406 Train Loss 0.00011866529 Test Loss 0.0002135553458888433\n",
      "1407 Train Loss 0.00011884706 Test Loss 0.00021688235474469464\n",
      "1408 Train Loss 0.00011851634 Test Loss 0.00021490560766373329\n",
      "1409 Train Loss 0.000118384196 Test Loss 0.0002143947844963816\n",
      "1410 Train Loss 0.00011827219 Test Loss 0.00021535415413913842\n",
      "1411 Train Loss 0.000118136726 Test Loss 0.00021638669135689675\n",
      "1412 Train Loss 0.0001180269 Test Loss 0.00021577527200681863\n",
      "1413 Train Loss 0.00011791225 Test Loss 0.00021559880235926643\n",
      "1414 Train Loss 0.00011796459 Test Loss 0.00021242977535571126\n",
      "1415 Train Loss 0.00011781663 Test Loss 0.00021414736979378488\n",
      "1416 Train Loss 0.00011770349 Test Loss 0.00021435099255645817\n",
      "1417 Train Loss 0.00011751734 Test Loss 0.00021691954323979238\n",
      "1418 Train Loss 0.00011742397 Test Loss 0.00021956545273660853\n",
      "1419 Train Loss 0.00011735235 Test Loss 0.00022168821406784556\n",
      "1420 Train Loss 0.00011729436 Test Loss 0.0002218380456575463\n",
      "1421 Train Loss 0.00011725602 Test Loss 0.0002230287441134312\n",
      "1422 Train Loss 0.0001172131 Test Loss 0.00022347724408271902\n",
      "1423 Train Loss 0.00011725424 Test Loss 0.00021921185237220906\n",
      "1424 Train Loss 0.00011719385 Test Loss 0.00022196823366551984\n",
      "1425 Train Loss 0.00011752557 Test Loss 0.00023252664597228246\n",
      "1426 Train Loss 0.00011718304 Test Loss 0.0002235373889168294\n",
      "1427 Train Loss 0.00011714467 Test Loss 0.00022337944287681877\n",
      "1428 Train Loss 0.00011709482 Test Loss 0.000222375671824886\n",
      "1429 Train Loss 0.00011705034 Test Loss 0.00022307660854654042\n",
      "1430 Train Loss 0.00011699279 Test Loss 0.00022238012638742672\n",
      "1431 Train Loss 0.000116930714 Test Loss 0.00022116308712886553\n",
      "1432 Train Loss 0.00011688778 Test Loss 0.00022239226572848034\n",
      "1433 Train Loss 0.00011680651 Test Loss 0.00022155917710530747\n",
      "1434 Train Loss 0.00011671909 Test Loss 0.00022189192411513033\n",
      "1435 Train Loss 0.000116587966 Test Loss 0.00022374932469995925\n",
      "1436 Train Loss 0.00011651257 Test Loss 0.0002239738608748402\n",
      "1437 Train Loss 0.00011632522 Test Loss 0.00022645721280607255\n",
      "1438 Train Loss 0.00011618153 Test Loss 0.00022857915517401092\n",
      "1439 Train Loss 0.00011603757 Test Loss 0.00022979423991145216\n",
      "1440 Train Loss 0.000115886025 Test Loss 0.00022894252647921568\n",
      "1441 Train Loss 0.00011572606 Test Loss 0.0002273002269049324\n",
      "1442 Train Loss 0.000115557516 Test Loss 0.00022379468994697044\n",
      "1443 Train Loss 0.000115464485 Test Loss 0.0002213893756263356\n",
      "1444 Train Loss 0.000115377086 Test Loss 0.00022035259622296176\n",
      "1445 Train Loss 0.0001152833 Test Loss 0.00021951835931428027\n",
      "1446 Train Loss 0.00011515104 Test Loss 0.00021986697332136622\n",
      "1447 Train Loss 0.000114982424 Test Loss 0.00022031373926354537\n",
      "1448 Train Loss 0.00014690278 Test Loss 0.00019101185471175\n",
      "1449 Train Loss 0.00011493128 Test Loss 0.00021809241203650441\n",
      "1450 Train Loss 0.000114734066 Test Loss 0.00021740077531864267\n",
      "1451 Train Loss 0.000114597045 Test Loss 0.0002136973344732473\n",
      "1452 Train Loss 0.00011451989 Test Loss 0.00021221101610273787\n",
      "1453 Train Loss 0.00011443431 Test Loss 0.0002121974600362822\n",
      "1454 Train Loss 0.0001143345 Test Loss 0.00021253766521009117\n",
      "1455 Train Loss 0.00011422913 Test Loss 0.00021423001986327038\n",
      "1456 Train Loss 0.00011410397 Test Loss 0.00021529789924063292\n",
      "1457 Train Loss 0.000114077004 Test Loss 0.0002189311071456875\n",
      "1458 Train Loss 0.000113853646 Test Loss 0.00021837925866416367\n",
      "1459 Train Loss 0.00011371735 Test Loss 0.00021920542332292068\n",
      "1460 Train Loss 0.000113655835 Test Loss 0.0002198073101792695\n",
      "1461 Train Loss 0.000113571674 Test Loss 0.00021955063741927784\n",
      "1462 Train Loss 0.00011332052 Test Loss 0.00022137166382832956\n",
      "1463 Train Loss 0.000112947004 Test Loss 0.00022388726102186087\n",
      "1464 Train Loss 0.00011244228 Test Loss 0.00022668418216503498\n",
      "1465 Train Loss 0.00011279479 Test Loss 0.00023256198877307635\n",
      "1466 Train Loss 0.00011215162 Test Loss 0.0002290630336008361\n",
      "1467 Train Loss 0.000111772475 Test Loss 0.00023366939000945628\n",
      "1468 Train Loss 0.00011144155 Test Loss 0.00023365493814643133\n",
      "1469 Train Loss 0.00011127125 Test Loss 0.00023632758661180879\n",
      "1470 Train Loss 0.000111088404 Test Loss 0.0002441848006377367\n",
      "1471 Train Loss 0.000112375186 Test Loss 0.0002570145142213625\n",
      "1472 Train Loss 0.00011081234 Test Loss 0.0002480384550609113\n",
      "1473 Train Loss 0.0001105331 Test Loss 0.00024605885750950975\n",
      "1474 Train Loss 0.00011028536 Test Loss 0.00023907923659951673\n",
      "1475 Train Loss 0.00011015896 Test Loss 0.00023787413768158302\n",
      "1476 Train Loss 0.00011000749 Test Loss 0.00023665793336419784\n",
      "1477 Train Loss 0.0001098739 Test Loss 0.0002346752937151922\n",
      "1478 Train Loss 0.00010981304 Test Loss 0.00023373029335682305\n",
      "1479 Train Loss 0.00010973485 Test Loss 0.00023406529961027253\n",
      "1480 Train Loss 0.00010966255 Test Loss 0.0002351068068456131\n",
      "1481 Train Loss 0.000109587476 Test Loss 0.00023554651268860858\n",
      "1482 Train Loss 0.00010946507 Test Loss 0.00023626770799906537\n",
      "1483 Train Loss 0.00010923731 Test Loss 0.00023649947794603465\n",
      "1484 Train Loss 0.000110250345 Test Loss 0.000210653987909811\n",
      "1485 Train Loss 0.00010919901 Test Loss 0.0002318672486765654\n",
      "1486 Train Loss 0.00011089147 Test Loss 0.0002190376613452476\n",
      "1487 Train Loss 0.00010907315 Test Loss 0.00022894425398903892\n",
      "1488 Train Loss 0.000108948785 Test Loss 0.0002278710505176354\n",
      "1489 Train Loss 0.00010884699 Test Loss 0.0002279285718724886\n",
      "1490 Train Loss 0.000108727814 Test Loss 0.00022693073557338155\n",
      "1491 Train Loss 0.00010856168 Test Loss 0.00023074497783780678\n",
      "1492 Train Loss 0.00010873274 Test Loss 0.00021913432970529698\n",
      "1493 Train Loss 0.00010848699 Test Loss 0.0002260824991521713\n",
      "1494 Train Loss 0.00010836366 Test Loss 0.00022640762700771151\n",
      "1495 Train Loss 0.00010825951 Test Loss 0.00022642246995898375\n",
      "1496 Train Loss 0.000108165055 Test Loss 0.00022543687718253876\n",
      "1497 Train Loss 0.00010806111 Test Loss 0.0002240360120663555\n",
      "1498 Train Loss 0.00010798492 Test Loss 0.0002235412770175152\n",
      "1499 Train Loss 0.000107916574 Test Loss 0.00022406894248970988\n",
      "1500 Train Loss 0.000107849584 Test Loss 0.0002250205873893361\n",
      "1501 Train Loss 0.00010831938 Test Loss 0.00022145295783789696\n",
      "1502 Train Loss 0.00010781436 Test Loss 0.00022424224035840943\n",
      "1503 Train Loss 0.00010776728 Test Loss 0.00022344489145348148\n",
      "1504 Train Loss 0.00010829889 Test Loss 0.00023355319757905019\n",
      "1505 Train Loss 0.00010771879 Test Loss 0.0002256706042091632\n",
      "1506 Train Loss 0.00010755199 Test Loss 0.00023016640191850026\n",
      "1507 Train Loss 0.000120189026 Test Loss 0.00028781392629816474\n",
      "1508 Train Loss 0.00010744507 Test Loss 0.0002337540213798142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1509 Train Loss 0.000107272586 Test Loss 0.00023602735524298914\n",
      "1510 Train Loss 0.000107110245 Test Loss 0.00023791056973352276\n",
      "1511 Train Loss 0.00010702981 Test Loss 0.00023707383213969753\n",
      "1512 Train Loss 0.000106953965 Test Loss 0.0002347698247931372\n",
      "1513 Train Loss 0.00010688836 Test Loss 0.0002317973773686519\n",
      "1514 Train Loss 0.00010684134 Test Loss 0.0002290142110455294\n",
      "1515 Train Loss 0.000106797976 Test Loss 0.00022722089505411265\n",
      "1516 Train Loss 0.00010672923 Test Loss 0.00022559480639938135\n",
      "1517 Train Loss 0.00010672313 Test Loss 0.00021640144067866244\n",
      "1518 Train Loss 0.000107891254 Test Loss 0.00021802398006314804\n",
      "1519 Train Loss 0.00010663383 Test Loss 0.00021669682582968786\n",
      "1520 Train Loss 0.0001065206 Test Loss 0.00022009394167580733\n",
      "1521 Train Loss 0.00010641016 Test Loss 0.00022086248642006704\n",
      "1522 Train Loss 0.0001063036 Test Loss 0.00021824212866244523\n",
      "1523 Train Loss 0.00010622491 Test Loss 0.0002140197267754012\n",
      "1524 Train Loss 0.00010613802 Test Loss 0.00020951619045570134\n",
      "1525 Train Loss 0.00010606306 Test Loss 0.00020555201451730014\n",
      "1526 Train Loss 0.00010601475 Test Loss 0.000205032932594471\n",
      "1527 Train Loss 0.000105955434 Test Loss 0.0002051195378165417\n",
      "1528 Train Loss 0.00010589819 Test Loss 0.00020484341585465523\n",
      "1529 Train Loss 0.000105850675 Test Loss 0.00020380379266534624\n",
      "1530 Train Loss 0.00010581687 Test Loss 0.0002027040672603678\n",
      "1531 Train Loss 0.0001057772 Test Loss 0.00020139404803211168\n",
      "1532 Train Loss 0.0001057059 Test Loss 0.00019962925956179938\n",
      "1533 Train Loss 0.00010563429 Test Loss 0.00019873852733540864\n",
      "1534 Train Loss 0.00010963807 Test Loss 0.00020089652176220028\n",
      "1535 Train Loss 0.00010560973 Test Loss 0.00019885505723329144\n",
      "1536 Train Loss 0.00010559967 Test Loss 0.0002001691569841129\n",
      "1537 Train Loss 0.00010550837 Test Loss 0.00019950720015389368\n",
      "1538 Train Loss 0.000105379506 Test Loss 0.00020219517892101641\n",
      "1539 Train Loss 0.00010528112 Test Loss 0.00020370417174985024\n",
      "1540 Train Loss 0.0001051555 Test Loss 0.0002058805645711346\n",
      "1541 Train Loss 0.00010507273 Test Loss 0.00020680892207145598\n",
      "1542 Train Loss 0.000104965395 Test Loss 0.00020744125277303655\n",
      "1543 Train Loss 0.000104879 Test Loss 0.00020632373339127404\n",
      "1544 Train Loss 0.00010481644 Test Loss 0.00020438682035443028\n",
      "1545 Train Loss 0.00010473783 Test Loss 0.00020185292147549812\n",
      "1546 Train Loss 0.00010467066 Test Loss 0.00019946837038899346\n",
      "1547 Train Loss 0.00010463449 Test Loss 0.00019910442719748816\n",
      "1548 Train Loss 0.00010460236 Test Loss 0.0001993248836700535\n",
      "1549 Train Loss 0.000104574516 Test Loss 0.00020029749787505574\n",
      "1550 Train Loss 0.000104519306 Test Loss 0.00020128859025672147\n",
      "1551 Train Loss 0.00010464288 Test Loss 0.00020572230618178712\n",
      "1552 Train Loss 0.00010447757 Test Loss 0.00020272730064785463\n",
      "1553 Train Loss 0.00010440704 Test Loss 0.00020331529275056663\n",
      "1554 Train Loss 0.00010432664 Test Loss 0.0002046840374731129\n",
      "1555 Train Loss 0.000104254555 Test Loss 0.000205509021107625\n",
      "1556 Train Loss 0.00010416439 Test Loss 0.00020654136841352853\n",
      "1557 Train Loss 0.00010406891 Test Loss 0.00020645876646602001\n",
      "1558 Train Loss 0.00010511559 Test Loss 0.00019810898345480585\n",
      "1559 Train Loss 0.00010401143 Test Loss 0.00020480284345226405\n",
      "1560 Train Loss 0.00010384654 Test Loss 0.00020251529157575937\n",
      "1561 Train Loss 0.00010372161 Test Loss 0.00020141383958368\n",
      "1562 Train Loss 0.000103530605 Test Loss 0.00020077062621480981\n",
      "1563 Train Loss 0.00010342599 Test Loss 0.00019879023691459974\n",
      "1564 Train Loss 0.00010329417 Test Loss 0.00019665323850851318\n",
      "1565 Train Loss 0.00010316252 Test Loss 0.00019364636736238127\n",
      "1566 Train Loss 0.000103072656 Test Loss 0.00019273101558416798\n",
      "1567 Train Loss 0.000102989536 Test Loss 0.00019205130342328156\n",
      "1568 Train Loss 0.000102922226 Test Loss 0.00019255087760266767\n",
      "1569 Train Loss 0.000102883285 Test Loss 0.0001919226556534507\n",
      "1570 Train Loss 0.0001033303 Test Loss 0.00019258697047633998\n",
      "1571 Train Loss 0.0001027791 Test Loss 0.00019205622660512403\n",
      "1572 Train Loss 0.00010261489 Test Loss 0.0001909509671239582\n",
      "1573 Train Loss 0.00010236133 Test Loss 0.0001901211599207283\n",
      "1574 Train Loss 0.00010222092 Test Loss 0.0001904434634390136\n",
      "1575 Train Loss 0.00010210029 Test Loss 0.00019271095336230898\n",
      "1576 Train Loss 0.000101954785 Test Loss 0.0001941252390861778\n",
      "1577 Train Loss 0.0001017951 Test Loss 0.0001952732601311514\n",
      "1578 Train Loss 0.00010145512 Test Loss 0.00019653858200654296\n",
      "1579 Train Loss 0.00010123718 Test Loss 0.00019587592369955928\n",
      "1580 Train Loss 0.000107439635 Test Loss 0.0001701550010116787\n",
      "1581 Train Loss 0.00010120409 Test Loss 0.00019302337099114914\n",
      "1582 Train Loss 0.000103239014 Test Loss 0.00020604338069546172\n",
      "1583 Train Loss 0.000101154335 Test Loss 0.00019471851610130937\n",
      "1584 Train Loss 0.00010329628 Test Loss 0.00022082393812816847\n",
      "1585 Train Loss 0.00010107113 Test Loss 0.0001988914012333855\n",
      "1586 Train Loss 0.00010102605 Test Loss 0.00019916651618627872\n",
      "1587 Train Loss 0.000100954836 Test Loss 0.00019379543826778596\n",
      "1588 Train Loss 0.00010082708 Test Loss 0.00019606227309291544\n",
      "1589 Train Loss 0.00010073568 Test Loss 0.0001956412433781295\n",
      "1590 Train Loss 0.00010063558 Test Loss 0.00019544308180324173\n",
      "1591 Train Loss 0.000100569014 Test Loss 0.00019463853585706146\n",
      "1592 Train Loss 0.000100476536 Test Loss 0.0001927974707438999\n",
      "1593 Train Loss 0.000100364006 Test Loss 0.00019120468689726367\n",
      "1594 Train Loss 0.00010026724 Test Loss 0.00018792192532010146\n",
      "1595 Train Loss 0.000100170466 Test Loss 0.00018769148838891688\n",
      "1596 Train Loss 9.9925186e-05 Test Loss 0.00018703157255459772\n",
      "1597 Train Loss 9.972671e-05 Test Loss 0.00018649078481318724\n",
      "1598 Train Loss 9.944844e-05 Test Loss 0.00018056107783283844\n",
      "1599 Train Loss 0.00018117124 Test Loss 0.00018067854178296976\n",
      "1600 Train Loss 9.9212644e-05 Test Loss 0.00017891201933687497\n",
      "1601 Train Loss 9.8916506e-05 Test Loss 0.0001834516549405464\n",
      "1602 Train Loss 9.8500954e-05 Test Loss 0.0001856738438637707\n",
      "1603 Train Loss 9.8144854e-05 Test Loss 0.00018254826074175584\n",
      "1604 Train Loss 9.77025e-05 Test Loss 0.00017828940694858856\n",
      "1605 Train Loss 9.750518e-05 Test Loss 0.00017845516357185945\n",
      "1606 Train Loss 9.723152e-05 Test Loss 0.00017793104903557209\n",
      "1607 Train Loss 9.703189e-05 Test Loss 0.00018040243105387873\n",
      "1608 Train Loss 9.689536e-05 Test Loss 0.00018245134759877678\n",
      "1609 Train Loss 9.677882e-05 Test Loss 0.0001834905200281315\n",
      "1610 Train Loss 9.659252e-05 Test Loss 0.00018392969123867933\n",
      "1611 Train Loss 9.645699e-05 Test Loss 0.00018328757118330876\n",
      "1612 Train Loss 9.633543e-05 Test Loss 0.00018136271064634224\n",
      "1613 Train Loss 9.621505e-05 Test Loss 0.00017997493174113616\n",
      "1614 Train Loss 9.610394e-05 Test Loss 0.00017840494714722765\n",
      "1615 Train Loss 9.97267e-05 Test Loss 0.00018429863824645867\n",
      "1616 Train Loss 9.607318e-05 Test Loss 0.0001787866614983075\n",
      "1617 Train Loss 9.6403324e-05 Test Loss 0.00017504391134594093\n",
      "1618 Train Loss 9.602967e-05 Test Loss 0.00017779926162467212\n",
      "1619 Train Loss 9.593392e-05 Test Loss 0.0001785025311489613\n",
      "1620 Train Loss 9.586353e-05 Test Loss 0.00017895296939288984\n",
      "1621 Train Loss 9.579677e-05 Test Loss 0.00017909072255483679\n",
      "1622 Train Loss 9.573749e-05 Test Loss 0.00017879364538099553\n",
      "1623 Train Loss 9.566374e-05 Test Loss 0.00017865956208199793\n",
      "1624 Train Loss 9.8617464e-05 Test Loss 0.00017461028163476887\n",
      "1625 Train Loss 9.562492e-05 Test Loss 0.00017795055766375322\n",
      "1626 Train Loss 9.555585e-05 Test Loss 0.00017792377150055124\n",
      "1627 Train Loss 9.542263e-05 Test Loss 0.00018020926555326243\n",
      "1628 Train Loss 9.536834e-05 Test Loss 0.00018247508479113373\n",
      "1629 Train Loss 9.529939e-05 Test Loss 0.00018521757658854045\n",
      "1630 Train Loss 9.5238254e-05 Test Loss 0.00018644632371836778\n",
      "1631 Train Loss 9.5731964e-05 Test Loss 0.00017979038218527292\n",
      "1632 Train Loss 9.5196796e-05 Test Loss 0.00018489696974409355\n",
      "1633 Train Loss 9.602825e-05 Test Loss 0.00020245138271048665\n",
      "1634 Train Loss 9.50338e-05 Test Loss 0.00018989113935159605\n",
      "1635 Train Loss 9.493966e-05 Test Loss 0.00018772803304783193\n",
      "1636 Train Loss 9.48596e-05 Test Loss 0.00018423034525262138\n",
      "1637 Train Loss 9.482067e-05 Test Loss 0.00018271861566382345\n",
      "1638 Train Loss 9.478343e-05 Test Loss 0.00018362181914955789\n",
      "1639 Train Loss 9.471932e-05 Test Loss 0.00018534986453856112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640 Train Loss 9.469025e-05 Test Loss 0.00018617649361113577\n",
      "1641 Train Loss 9.47289e-05 Test Loss 0.0001872406316510053\n",
      "1642 Train Loss 9.46628e-05 Test Loss 0.0001865641603742262\n",
      "1643 Train Loss 9.463035e-05 Test Loss 0.00018882718906218686\n",
      "1644 Train Loss 9.457387e-05 Test Loss 0.00018845838117839925\n",
      "1645 Train Loss 9.45321e-05 Test Loss 0.00018850472973311666\n",
      "1646 Train Loss 9.448183e-05 Test Loss 0.0001888394137404229\n",
      "1647 Train Loss 9.4416e-05 Test Loss 0.0001895104127722474\n",
      "1648 Train Loss 9.431677e-05 Test Loss 0.00019130280394464604\n",
      "1649 Train Loss 9.51526e-05 Test Loss 0.000197793910712788\n",
      "1650 Train Loss 9.426963e-05 Test Loss 0.0001924784835495656\n",
      "1651 Train Loss 9.41543e-05 Test Loss 0.00019100968151969738\n",
      "1652 Train Loss 9.402531e-05 Test Loss 0.0001887269745731095\n",
      "1653 Train Loss 9.397428e-05 Test Loss 0.0001870344372847789\n",
      "1654 Train Loss 9.391124e-05 Test Loss 0.00018660977558177414\n",
      "1655 Train Loss 9.385213e-05 Test Loss 0.0001859944568869136\n",
      "1656 Train Loss 9.382382e-05 Test Loss 0.00018585020770459044\n",
      "1657 Train Loss 9.3769704e-05 Test Loss 0.0001851911274093275\n",
      "1658 Train Loss 9.3657145e-05 Test Loss 0.0001851198246091686\n",
      "1659 Train Loss 9.354607e-05 Test Loss 0.0001815428978355158\n",
      "1660 Train Loss 9.334855e-05 Test Loss 0.00018212245247956806\n",
      "1661 Train Loss 9.29395e-05 Test Loss 0.00018322851662545128\n",
      "1662 Train Loss 9.2750226e-05 Test Loss 0.00018096554811297756\n",
      "1663 Train Loss 9.259326e-05 Test Loss 0.00017952469709932902\n",
      "1664 Train Loss 9.248538e-05 Test Loss 0.00017842111739522576\n",
      "1665 Train Loss 9.238934e-05 Test Loss 0.00017629592886320774\n",
      "1666 Train Loss 9.228662e-05 Test Loss 0.0001742890034806329\n",
      "1667 Train Loss 9.292054e-05 Test Loss 0.00016891990141417048\n",
      "1668 Train Loss 9.224269e-05 Test Loss 0.00017315079939421164\n",
      "1669 Train Loss 9.2179755e-05 Test Loss 0.00017237542442298732\n",
      "1670 Train Loss 9.194297e-05 Test Loss 0.00017612505937451045\n",
      "1671 Train Loss 9.1727125e-05 Test Loss 0.000176902932360672\n",
      "1672 Train Loss 9.1532056e-05 Test Loss 0.00018015809100557526\n",
      "1673 Train Loss 9.134585e-05 Test Loss 0.00018273913907566747\n",
      "1674 Train Loss 9.118098e-05 Test Loss 0.0001851584736460584\n",
      "1675 Train Loss 9.0990034e-05 Test Loss 0.00018480521183308904\n",
      "1676 Train Loss 9.0803704e-05 Test Loss 0.00018326176726711098\n",
      "1677 Train Loss 9.058101e-05 Test Loss 0.0001806854261083281\n",
      "1678 Train Loss 9.0349306e-05 Test Loss 0.00017988806915674474\n",
      "1679 Train Loss 9.016138e-05 Test Loss 0.00017969591084278347\n",
      "1680 Train Loss 8.9991336e-05 Test Loss 0.00018244858080259006\n",
      "1681 Train Loss 8.9882815e-05 Test Loss 0.00018494572389393313\n",
      "1682 Train Loss 8.9794106e-05 Test Loss 0.00018705098021200398\n",
      "1683 Train Loss 8.9712565e-05 Test Loss 0.0001866749618413999\n",
      "1684 Train Loss 8.959748e-05 Test Loss 0.00018439934817189067\n",
      "1685 Train Loss 8.9507674e-05 Test Loss 0.00018270985526356982\n",
      "1686 Train Loss 8.937644e-05 Test Loss 0.0001812655142846724\n",
      "1687 Train Loss 8.92292e-05 Test Loss 0.00018059842626242737\n",
      "1688 Train Loss 8.911372e-05 Test Loss 0.00018189526796365857\n",
      "1689 Train Loss 8.901612e-05 Test Loss 0.00018298165498901255\n",
      "1690 Train Loss 8.8894594e-05 Test Loss 0.00018444592892990157\n",
      "1691 Train Loss 8.897911e-05 Test Loss 0.00019605261505147416\n",
      "1692 Train Loss 8.8825116e-05 Test Loss 0.0001885784510276589\n",
      "1693 Train Loss 8.86556e-05 Test Loss 0.00018900152397413887\n",
      "1694 Train Loss 8.844305e-05 Test Loss 0.0001878263733191117\n",
      "1695 Train Loss 8.824971e-05 Test Loss 0.00018619062381814965\n",
      "1696 Train Loss 8.8117886e-05 Test Loss 0.0001853183975966497\n",
      "1697 Train Loss 8.797234e-05 Test Loss 0.0001841145090019415\n",
      "1698 Train Loss 8.7840235e-05 Test Loss 0.00018354910657426713\n",
      "1699 Train Loss 8.772219e-05 Test Loss 0.000182958496811201\n",
      "1700 Train Loss 8.761299e-05 Test Loss 0.0001802771864058579\n",
      "1701 Train Loss 8.75589e-05 Test Loss 0.00018285107371413065\n",
      "1702 Train Loss 8.7390166e-05 Test Loss 0.00018198081921957511\n",
      "1703 Train Loss 8.7281616e-05 Test Loss 0.00018104185931531764\n",
      "1704 Train Loss 8.714651e-05 Test Loss 0.00018034988071544792\n",
      "1705 Train Loss 8.704855e-05 Test Loss 0.0001808675464919334\n",
      "1706 Train Loss 8.876806e-05 Test Loss 0.00018308228369749008\n",
      "1707 Train Loss 8.699408e-05 Test Loss 0.00018088294036825106\n",
      "1708 Train Loss 8.737497e-05 Test Loss 0.0001720279087531947\n",
      "1709 Train Loss 8.687594e-05 Test Loss 0.00017783128710734602\n",
      "1710 Train Loss 8.6738575e-05 Test Loss 0.0001771778100096298\n",
      "1711 Train Loss 8.6533786e-05 Test Loss 0.0001780360199817848\n",
      "1712 Train Loss 8.64538e-05 Test Loss 0.00017794728184325609\n",
      "1713 Train Loss 8.65578e-05 Test Loss 0.00017866605126310272\n",
      "1714 Train Loss 8.642109e-05 Test Loss 0.00017817176493117732\n",
      "1715 Train Loss 8.652281e-05 Test Loss 0.00017236063919998435\n",
      "1716 Train Loss 8.63778e-05 Test Loss 0.0001759554159826949\n",
      "1717 Train Loss 8.633292e-05 Test Loss 0.00017635495689126874\n",
      "1718 Train Loss 8.6272725e-05 Test Loss 0.00017755901559805154\n",
      "1719 Train Loss 8.659851e-05 Test Loss 0.00017512630658930085\n",
      "1720 Train Loss 8.625883e-05 Test Loss 0.00017712131834785649\n",
      "1721 Train Loss 8.61954e-05 Test Loss 0.00017663977357474335\n",
      "1722 Train Loss 8.6111875e-05 Test Loss 0.00017750998034939995\n",
      "1723 Train Loss 8.610515e-05 Test Loss 0.0001734603440994429\n",
      "1724 Train Loss 8.6052976e-05 Test Loss 0.00017534355269087736\n",
      "1725 Train Loss 8.598249e-05 Test Loss 0.00017703180452744325\n",
      "1726 Train Loss 8.587331e-05 Test Loss 0.0001805356334132672\n",
      "1727 Train Loss 8.5824504e-05 Test Loss 0.00018169181881002113\n",
      "1728 Train Loss 8.575373e-05 Test Loss 0.00018296168877179615\n",
      "1729 Train Loss 8.568806e-05 Test Loss 0.00018391011325770898\n",
      "1730 Train Loss 8.618063e-05 Test Loss 0.0001866219252422126\n",
      "1731 Train Loss 8.566825e-05 Test Loss 0.0001843328527312228\n",
      "1732 Train Loss 8.558716e-05 Test Loss 0.00018537957294123726\n",
      "1733 Train Loss 8.55236e-05 Test Loss 0.000187037849942195\n",
      "1734 Train Loss 8.5477535e-05 Test Loss 0.00018914473827686301\n",
      "1735 Train Loss 8.545235e-05 Test Loss 0.00018981994438046847\n",
      "1736 Train Loss 8.543442e-05 Test Loss 0.00019001797936111185\n",
      "1737 Train Loss 8.541597e-05 Test Loss 0.00018974703248769673\n",
      "1738 Train Loss 8.540335e-05 Test Loss 0.00018973719414338647\n",
      "1739 Train Loss 8.5373795e-05 Test Loss 0.00018990334555459395\n",
      "1740 Train Loss 8.535053e-05 Test Loss 0.00019100157178524838\n",
      "1741 Train Loss 8.684122e-05 Test Loss 0.0001949112730818778\n",
      "1742 Train Loss 8.531996e-05 Test Loss 0.00019145573989816245\n",
      "1743 Train Loss 8.535962e-05 Test Loss 0.00018831601590591038\n",
      "1744 Train Loss 8.531179e-05 Test Loss 0.00019046962353862966\n",
      "1745 Train Loss 8.5328524e-05 Test Loss 0.00019338821786205767\n",
      "1746 Train Loss 8.5290594e-05 Test Loss 0.0001916768638031073\n",
      "1747 Train Loss 8.5246254e-05 Test Loss 0.00019443578480989935\n",
      "1748 Train Loss 8.523281e-05 Test Loss 0.00019623393457967084\n",
      "1749 Train Loss 8.52219e-05 Test Loss 0.00019641353025284802\n",
      "1750 Train Loss 8.520374e-05 Test Loss 0.00019602642948696492\n",
      "1751 Train Loss 8.5179636e-05 Test Loss 0.00019632933194588828\n",
      "1752 Train Loss 8.514679e-05 Test Loss 0.00019591566463713858\n",
      "1753 Train Loss 8.628106e-05 Test Loss 0.000199283854254735\n",
      "1754 Train Loss 8.512451e-05 Test Loss 0.0001962848437900062\n",
      "1755 Train Loss 8.506274e-05 Test Loss 0.00019457011659017605\n",
      "1756 Train Loss 8.4987056e-05 Test Loss 0.0001933720455805294\n",
      "1757 Train Loss 8.4905725e-05 Test Loss 0.00019129689629198023\n",
      "1758 Train Loss 8.481633e-05 Test Loss 0.00018937791742287553\n",
      "1759 Train Loss 8.507316e-05 Test Loss 0.00018788942883817548\n",
      "1760 Train Loss 8.476894e-05 Test Loss 0.0001889223439961439\n",
      "1761 Train Loss 8.4653344e-05 Test Loss 0.0001879370062156892\n",
      "1762 Train Loss 8.448084e-05 Test Loss 0.00018602846124965295\n",
      "1763 Train Loss 8.464666e-05 Test Loss 0.00018085427970749606\n",
      "1764 Train Loss 8.4388004e-05 Test Loss 0.00018394457431867247\n",
      "1765 Train Loss 8.425086e-05 Test Loss 0.0001846199594654082\n",
      "1766 Train Loss 8.417705e-05 Test Loss 0.00018610517938417504\n",
      "1767 Train Loss 8.4111896e-05 Test Loss 0.00018735179751594344\n",
      "1768 Train Loss 8.405533e-05 Test Loss 0.0001890465080662622\n",
      "1769 Train Loss 8.392988e-05 Test Loss 0.0001870255370502444\n",
      "1770 Train Loss 8.411481e-05 Test Loss 0.00018164566852452906\n",
      "1771 Train Loss 8.385909e-05 Test Loss 0.00018508512409352716\n",
      "1772 Train Loss 8.401468e-05 Test Loss 0.0001790681517547182\n",
      "1773 Train Loss 8.373852e-05 Test Loss 0.00018266684831023838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1774 Train Loss 8.353446e-05 Test Loss 0.0001849498653063163\n",
      "1775 Train Loss 8.343498e-05 Test Loss 0.0001891091303845216\n",
      "1776 Train Loss 8.3300794e-05 Test Loss 0.000188927882063274\n",
      "1777 Train Loss 8.312734e-05 Test Loss 0.00018801572144376292\n",
      "1778 Train Loss 8.3024766e-05 Test Loss 0.00018787720723591303\n",
      "1779 Train Loss 8.284734e-05 Test Loss 0.0001875924874543\n",
      "1780 Train Loss 8.27427e-05 Test Loss 0.00019052336296269203\n",
      "1781 Train Loss 8.2641185e-05 Test Loss 0.00019300157174148986\n",
      "1782 Train Loss 8.254489e-05 Test Loss 0.00019630503868210843\n",
      "1783 Train Loss 8.248104e-05 Test Loss 0.0001972420065018058\n",
      "1784 Train Loss 8.2422004e-05 Test Loss 0.0001967470938246821\n",
      "1785 Train Loss 8.237314e-05 Test Loss 0.00019704752346413816\n",
      "1786 Train Loss 8.233159e-05 Test Loss 0.00019809848813172014\n",
      "1787 Train Loss 8.224804e-05 Test Loss 0.0001985404200792085\n",
      "1788 Train Loss 8.2529834e-05 Test Loss 0.0002060163107263836\n",
      "1789 Train Loss 8.2201586e-05 Test Loss 0.00020057234744279298\n",
      "1790 Train Loss 8.20888e-05 Test Loss 0.00019869269927617428\n",
      "1791 Train Loss 8.194908e-05 Test Loss 0.00019917698760228496\n",
      "1792 Train Loss 8.22892e-05 Test Loss 0.00019593529690243805\n",
      "1793 Train Loss 8.179487e-05 Test Loss 0.0001978692258739901\n",
      "1794 Train Loss 8.163943e-05 Test Loss 0.00019614619525836757\n",
      "1795 Train Loss 8.1541e-05 Test Loss 0.000196139902433148\n",
      "1796 Train Loss 8.1502425e-05 Test Loss 0.0001944465583346072\n",
      "1797 Train Loss 8.1408e-05 Test Loss 0.00019446089348789303\n",
      "1798 Train Loss 8.1263875e-05 Test Loss 0.00019408524527705635\n",
      "1799 Train Loss 8.1164464e-05 Test Loss 0.00019387432207453162\n",
      "1800 Train Loss 8.10741e-05 Test Loss 0.00019379499775636338\n",
      "1801 Train Loss 8.101344e-05 Test Loss 0.00019390743861589572\n",
      "1802 Train Loss 8.092493e-05 Test Loss 0.0001947793064207366\n",
      "1803 Train Loss 8.081577e-05 Test Loss 0.000194231542218067\n",
      "1804 Train Loss 8.0668935e-05 Test Loss 0.0001923138006749281\n",
      "1805 Train Loss 8.0586375e-05 Test Loss 0.00018999906031429183\n",
      "1806 Train Loss 8.0536425e-05 Test Loss 0.00018797454618773205\n",
      "1807 Train Loss 8.047185e-05 Test Loss 0.0001862382546818518\n",
      "1808 Train Loss 8.0415186e-05 Test Loss 0.00018494120634645356\n",
      "1809 Train Loss 8.149526e-05 Test Loss 0.00018745367088692067\n",
      "1810 Train Loss 8.0392856e-05 Test Loss 0.00018517805910593728\n",
      "1811 Train Loss 8.031342e-05 Test Loss 0.00018372155219772778\n",
      "1812 Train Loss 8.0252124e-05 Test Loss 0.00018313356496529428\n",
      "1813 Train Loss 8.014946e-05 Test Loss 0.00018268585873592807\n",
      "1814 Train Loss 7.999387e-05 Test Loss 0.00018238837904581605\n",
      "1815 Train Loss 7.983934e-05 Test Loss 0.00018303667880836992\n",
      "1816 Train Loss 7.9747755e-05 Test Loss 0.0001843285658524294\n",
      "1817 Train Loss 7.960637e-05 Test Loss 0.0001814315231617442\n",
      "1818 Train Loss 7.951281e-05 Test Loss 0.0001808528270676477\n",
      "1819 Train Loss 7.943545e-05 Test Loss 0.00017939584577975304\n",
      "1820 Train Loss 7.9346224e-05 Test Loss 0.00017821832040570276\n",
      "1821 Train Loss 7.936368e-05 Test Loss 0.00017771162336871306\n",
      "1822 Train Loss 7.928398e-05 Test Loss 0.00017796076794746163\n",
      "1823 Train Loss 8.081541e-05 Test Loss 0.00019224120363695935\n",
      "1824 Train Loss 7.917212e-05 Test Loss 0.00018051233846101548\n",
      "1825 Train Loss 7.905491e-05 Test Loss 0.0001792545030865621\n",
      "1826 Train Loss 7.898461e-05 Test Loss 0.00017762720493041403\n",
      "1827 Train Loss 7.899916e-05 Test Loss 0.00017814503015520428\n",
      "1828 Train Loss 7.895244e-05 Test Loss 0.00017785605282226246\n",
      "1829 Train Loss 7.891872e-05 Test Loss 0.00017801290514582048\n",
      "1830 Train Loss 7.885463e-05 Test Loss 0.0001783087286107024\n",
      "1831 Train Loss 7.8804966e-05 Test Loss 0.0001770963141708324\n",
      "1832 Train Loss 7.8846824e-05 Test Loss 0.00018182231381389427\n",
      "1833 Train Loss 7.878098e-05 Test Loss 0.00017883587299838736\n",
      "1834 Train Loss 7.872242e-05 Test Loss 0.00017838823763052406\n",
      "1835 Train Loss 7.887605e-05 Test Loss 0.00017653452856103522\n",
      "1836 Train Loss 7.868498e-05 Test Loss 0.00017778931453915834\n",
      "1837 Train Loss 7.865355e-05 Test Loss 0.00017757273637997257\n",
      "1838 Train Loss 7.857231e-05 Test Loss 0.0001787858001986406\n",
      "1839 Train Loss 7.853121e-05 Test Loss 0.0001786364526616943\n",
      "1840 Train Loss 7.848943e-05 Test Loss 0.0001781582621219967\n",
      "1841 Train Loss 7.845572e-05 Test Loss 0.00017708556843984625\n",
      "1842 Train Loss 7.842397e-05 Test Loss 0.00017539709429362723\n",
      "1843 Train Loss 7.838498e-05 Test Loss 0.0001748578748064668\n",
      "1844 Train Loss 7.838357e-05 Test Loss 0.00017344049154693095\n",
      "1845 Train Loss 7.836326e-05 Test Loss 0.0001741314585871603\n",
      "1846 Train Loss 7.832105e-05 Test Loss 0.00017594144133565803\n",
      "1847 Train Loss 7.824952e-05 Test Loss 0.0001766499444192175\n",
      "1848 Train Loss 7.8125966e-05 Test Loss 0.00017950231148058425\n",
      "1849 Train Loss 7.802562e-05 Test Loss 0.00018277239909089788\n",
      "1850 Train Loss 7.792699e-05 Test Loss 0.00018327964579541167\n",
      "1851 Train Loss 7.794455e-05 Test Loss 0.000183482543274328\n",
      "1852 Train Loss 7.7839344e-05 Test Loss 0.0001833683412765774\n",
      "1853 Train Loss 7.781175e-05 Test Loss 0.00018220520463453312\n",
      "1854 Train Loss 7.774441e-05 Test Loss 0.00018173713905710165\n",
      "1855 Train Loss 7.771203e-05 Test Loss 0.00018146029899497918\n",
      "1856 Train Loss 7.7619334e-05 Test Loss 0.0001795980834036899\n",
      "1857 Train Loss 7.755235e-05 Test Loss 0.00017778600031748698\n",
      "1858 Train Loss 7.745704e-05 Test Loss 0.00017988327303741411\n",
      "1859 Train Loss 7.741803e-05 Test Loss 0.00018073803082436712\n",
      "1860 Train Loss 7.7334036e-05 Test Loss 0.0001835617421689326\n",
      "1861 Train Loss 7.7287026e-05 Test Loss 0.0001885894060843446\n",
      "1862 Train Loss 7.7227276e-05 Test Loss 0.00018757960886852526\n",
      "1863 Train Loss 7.716162e-05 Test Loss 0.00018685384531868943\n",
      "1864 Train Loss 7.8617755e-05 Test Loss 0.00018746622962103335\n",
      "1865 Train Loss 7.712606e-05 Test Loss 0.0001868691480091102\n",
      "1866 Train Loss 7.7040684e-05 Test Loss 0.00018561141479519369\n",
      "1867 Train Loss 7.697066e-05 Test Loss 0.0001895497835771563\n",
      "1868 Train Loss 7.68899e-05 Test Loss 0.00018963348739286213\n",
      "1869 Train Loss 7.676646e-05 Test Loss 0.0001914431034040322\n",
      "1870 Train Loss 7.6615834e-05 Test Loss 0.00019213547264709325\n",
      "1871 Train Loss 7.652408e-05 Test Loss 0.00019265805406098926\n",
      "1872 Train Loss 7.662807e-05 Test Loss 0.00019036634960362909\n",
      "1873 Train Loss 7.648037e-05 Test Loss 0.0001918041727532248\n",
      "1874 Train Loss 7.64388e-05 Test Loss 0.00019111102136951927\n",
      "1875 Train Loss 7.637671e-05 Test Loss 0.00019059896729014823\n",
      "1876 Train Loss 7.630301e-05 Test Loss 0.00019165515150588205\n",
      "1877 Train Loss 7.6221084e-05 Test Loss 0.00019268079846107594\n",
      "1878 Train Loss 7.6153505e-05 Test Loss 0.00019319216056439158\n",
      "1879 Train Loss 7.6118515e-05 Test Loss 0.00019095030760255867\n",
      "1880 Train Loss 7.6452336e-05 Test Loss 0.00019753416510487375\n",
      "1881 Train Loss 7.6104276e-05 Test Loss 0.00019209359462162546\n",
      "1882 Train Loss 7.606231e-05 Test Loss 0.00019130418092164943\n",
      "1883 Train Loss 7.5999815e-05 Test Loss 0.00019142523037504877\n",
      "1884 Train Loss 7.594659e-05 Test Loss 0.00019148267029427867\n",
      "1885 Train Loss 7.584809e-05 Test Loss 0.00018964770807091834\n",
      "1886 Train Loss 7.57776e-05 Test Loss 0.0001889292128454425\n",
      "1887 Train Loss 7.56786e-05 Test Loss 0.00018765066834195866\n",
      "1888 Train Loss 7.559564e-05 Test Loss 0.00018838011600441244\n",
      "1889 Train Loss 7.548775e-05 Test Loss 0.0001899056118741857\n",
      "1890 Train Loss 7.53621e-05 Test Loss 0.00019258345497529864\n",
      "1891 Train Loss 7.521025e-05 Test Loss 0.00019446689378662348\n",
      "1892 Train Loss 7.515185e-05 Test Loss 0.00019403385754283191\n",
      "1893 Train Loss 7.498193e-05 Test Loss 0.00019431294816415652\n",
      "1894 Train Loss 7.490098e-05 Test Loss 0.0001937536269953578\n",
      "1895 Train Loss 7.475935e-05 Test Loss 0.0001937108335348307\n",
      "1896 Train Loss 7.4605974e-05 Test Loss 0.00019261765257258068\n",
      "1897 Train Loss 8.221823e-05 Test Loss 0.00020711158837072237\n",
      "1898 Train Loss 7.455945e-05 Test Loss 0.00019349269865220263\n",
      "1899 Train Loss 7.43089e-05 Test Loss 0.00019022784012530822\n",
      "1900 Train Loss 8.939483e-05 Test Loss 0.00024345687225611008\n",
      "1901 Train Loss 7.427545e-05 Test Loss 0.00019221912754217556\n",
      "1902 Train Loss 7.417554e-05 Test Loss 0.0001928953355643353\n",
      "1903 Train Loss 7.4025214e-05 Test Loss 0.00019692733581031332\n",
      "1904 Train Loss 7.393389e-05 Test Loss 0.0001996907758542386\n",
      "1905 Train Loss 7.383181e-05 Test Loss 0.00020410512651067663\n",
      "1906 Train Loss 7.365711e-05 Test Loss 0.00020769167924679997\n",
      "1907 Train Loss 7.3414034e-05 Test Loss 0.00020942289525921704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1908 Train Loss 7.3253315e-05 Test Loss 0.0002080748488567113\n",
      "1909 Train Loss 7.315025e-05 Test Loss 0.00020493261308831865\n",
      "1910 Train Loss 7.3062525e-05 Test Loss 0.00020071802948251453\n",
      "1911 Train Loss 7.2992094e-05 Test Loss 0.00020088604321210263\n",
      "1912 Train Loss 7.284586e-05 Test Loss 0.00020025566599917455\n",
      "1913 Train Loss 7.269231e-05 Test Loss 0.00019997005486691502\n",
      "1914 Train Loss 7.253194e-05 Test Loss 0.0002001831753042261\n",
      "1915 Train Loss 7.276561e-05 Test Loss 0.00019140197426310097\n",
      "1916 Train Loss 7.235198e-05 Test Loss 0.00019636632980228307\n",
      "1917 Train Loss 7.216233e-05 Test Loss 0.00019405405763463807\n",
      "1918 Train Loss 7.2015755e-05 Test Loss 0.00019063054532664152\n",
      "1919 Train Loss 7.187216e-05 Test Loss 0.0001868234946834546\n",
      "1920 Train Loss 7.159045e-05 Test Loss 0.0001800759380258953\n",
      "1921 Train Loss 7.1458984e-05 Test Loss 0.00017741330040694096\n",
      "1922 Train Loss 7.143797e-05 Test Loss 0.00016697612739905484\n",
      "1923 Train Loss 7.1169314e-05 Test Loss 0.00017135650522852815\n",
      "1924 Train Loss 7.1008464e-05 Test Loss 0.00017331818725619587\n",
      "1925 Train Loss 7.086233e-05 Test Loss 0.00017647307127791604\n",
      "1926 Train Loss 7.083431e-05 Test Loss 0.00017825556022352487\n",
      "1927 Train Loss 7.0744376e-05 Test Loss 0.00017879923740990968\n",
      "1928 Train Loss 7.068575e-05 Test Loss 0.00017972751185439057\n",
      "1929 Train Loss 7.0578026e-05 Test Loss 0.00018245375404176553\n",
      "1930 Train Loss 7.048062e-05 Test Loss 0.00018321305120411785\n",
      "1931 Train Loss 7.0348724e-05 Test Loss 0.00018389960741895886\n",
      "1932 Train Loss 7.022791e-05 Test Loss 0.00018222373177454243\n",
      "1933 Train Loss 7.044511e-05 Test Loss 0.00017727418976932178\n",
      "1934 Train Loss 7.018451e-05 Test Loss 0.00018074697239903601\n",
      "1935 Train Loss 7.020972e-05 Test Loss 0.00018461876079486447\n",
      "1936 Train Loss 7.007878e-05 Test Loss 0.00018256526839947006\n",
      "1937 Train Loss 6.9980364e-05 Test Loss 0.00018049441891925292\n",
      "1938 Train Loss 6.991066e-05 Test Loss 0.00017760319416876825\n",
      "1939 Train Loss 6.9854614e-05 Test Loss 0.0001763682863372959\n",
      "1940 Train Loss 6.977718e-05 Test Loss 0.00017634104496958635\n",
      "1941 Train Loss 6.968703e-05 Test Loss 0.00017751210586267193\n",
      "1942 Train Loss 6.9680726e-05 Test Loss 0.00017993794150492426\n",
      "1943 Train Loss 6.963569e-05 Test Loss 0.0001786876556470084\n",
      "1944 Train Loss 6.976652e-05 Test Loss 0.00019016363419064407\n",
      "1945 Train Loss 6.9526286e-05 Test Loss 0.00018306755647753354\n",
      "1946 Train Loss 6.941677e-05 Test Loss 0.0001845515056865569\n",
      "1947 Train Loss 6.931535e-05 Test Loss 0.00018755066210163923\n",
      "1948 Train Loss 6.927129e-05 Test Loss 0.00018749111634452573\n",
      "1949 Train Loss 6.922267e-05 Test Loss 0.00018791368412131702\n",
      "1950 Train Loss 6.9181726e-05 Test Loss 0.00018732224187681628\n",
      "1951 Train Loss 6.915444e-05 Test Loss 0.000186691758824726\n",
      "1952 Train Loss 6.915802e-05 Test Loss 0.00018335620769288768\n",
      "1953 Train Loss 6.913283e-05 Test Loss 0.0001850739832128594\n",
      "1954 Train Loss 6.910037e-05 Test Loss 0.0001837825726123095\n",
      "1955 Train Loss 6.907468e-05 Test Loss 0.00018264638879822784\n",
      "1956 Train Loss 6.927927e-05 Test Loss 0.00017850374945055467\n",
      "1957 Train Loss 6.90633e-05 Test Loss 0.00018190567791320986\n",
      "1958 Train Loss 6.9026886e-05 Test Loss 0.00018148597627953332\n",
      "1959 Train Loss 6.897554e-05 Test Loss 0.00017916231931727075\n",
      "1960 Train Loss 6.891829e-05 Test Loss 0.00017825612156378398\n",
      "1961 Train Loss 6.887177e-05 Test Loss 0.00017814312344980883\n",
      "1962 Train Loss 6.88408e-05 Test Loss 0.00017809542885142293\n",
      "1963 Train Loss 6.880089e-05 Test Loss 0.00017760454268202976\n",
      "1964 Train Loss 6.8731235e-05 Test Loss 0.00017711126326439285\n",
      "1965 Train Loss 6.867064e-05 Test Loss 0.00017691519734065142\n",
      "1966 Train Loss 7.163668e-05 Test Loss 0.00019119961821721472\n",
      "1967 Train Loss 6.866213e-05 Test Loss 0.0001774136037589833\n",
      "1968 Train Loss 6.8640074e-05 Test Loss 0.0001839740160203261\n",
      "1969 Train Loss 7.874768e-05 Test Loss 0.00018576882106449046\n",
      "1970 Train Loss 6.861648e-05 Test Loss 0.0001840017882908579\n",
      "1971 Train Loss 6.849413e-05 Test Loss 0.00018084292321813615\n",
      "1972 Train Loss 6.8415626e-05 Test Loss 0.00018012539668463244\n",
      "1973 Train Loss 6.83086e-05 Test Loss 0.00018111281507417245\n",
      "1974 Train Loss 6.821623e-05 Test Loss 0.000182736512096424\n",
      "1975 Train Loss 6.811743e-05 Test Loss 0.0001843361673054056\n",
      "1976 Train Loss 6.8019835e-05 Test Loss 0.00018537077331989837\n",
      "1977 Train Loss 6.79554e-05 Test Loss 0.00018391716635579342\n",
      "1978 Train Loss 6.789502e-05 Test Loss 0.00018227569251759145\n",
      "1979 Train Loss 6.784768e-05 Test Loss 0.00018099451872076962\n",
      "1980 Train Loss 6.8280446e-05 Test Loss 0.00017679218828662118\n",
      "1981 Train Loss 6.782633e-05 Test Loss 0.0001801707824522779\n",
      "1982 Train Loss 6.774455e-05 Test Loss 0.0001798094752866298\n",
      "1983 Train Loss 6.76471e-05 Test Loss 0.0001806752960606051\n",
      "1984 Train Loss 6.7537745e-05 Test Loss 0.00018234449331579024\n",
      "1985 Train Loss 6.746622e-05 Test Loss 0.00018433977679794433\n",
      "1986 Train Loss 6.739814e-05 Test Loss 0.00018627364324089415\n",
      "1987 Train Loss 6.731121e-05 Test Loss 0.0001844067187016819\n",
      "1988 Train Loss 6.721939e-05 Test Loss 0.00018198304332817724\n",
      "1989 Train Loss 6.714757e-05 Test Loss 0.00017938832439473465\n",
      "1990 Train Loss 6.704047e-05 Test Loss 0.00017627509219050763\n",
      "1991 Train Loss 6.718734e-05 Test Loss 0.00017144586254450682\n",
      "1992 Train Loss 6.6969376e-05 Test Loss 0.000174406290080562\n",
      "1993 Train Loss 6.6879984e-05 Test Loss 0.00017156407465520183\n",
      "1994 Train Loss 6.676889e-05 Test Loss 0.00017234005859231662\n",
      "1995 Train Loss 6.6720386e-05 Test Loss 0.00017390396234450881\n",
      "1996 Train Loss 6.666379e-05 Test Loss 0.00017521550194569076\n",
      "1997 Train Loss 6.660912e-05 Test Loss 0.00017541915925834063\n",
      "1998 Train Loss 6.646402e-05 Test Loss 0.00017679734688239704\n",
      "1999 Train Loss 6.6319815e-05 Test Loss 0.00017665821932530857\n",
      "2000 Train Loss 6.623732e-05 Test Loss 0.00017435967400196333\n",
      "2001 Train Loss 6.61166e-05 Test Loss 0.00017307185036754324\n",
      "2002 Train Loss 6.6001405e-05 Test Loss 0.0001738589052177181\n",
      "2003 Train Loss 6.5925284e-05 Test Loss 0.00017359280337554052\n",
      "2004 Train Loss 6.581502e-05 Test Loss 0.00017271227473250803\n",
      "2005 Train Loss 6.569852e-05 Test Loss 0.0001714476313568818\n",
      "2006 Train Loss 6.556932e-05 Test Loss 0.00016960128740408617\n",
      "2007 Train Loss 6.606083e-05 Test Loss 0.00016641120281867818\n",
      "2008 Train Loss 6.5536806e-05 Test Loss 0.00016894323807972316\n",
      "2009 Train Loss 6.5433895e-05 Test Loss 0.00016877818787223764\n",
      "2010 Train Loss 6.536377e-05 Test Loss 0.00016853381853126938\n",
      "2011 Train Loss 6.5263346e-05 Test Loss 0.00016988189911716322\n",
      "2012 Train Loss 6.5189866e-05 Test Loss 0.00017092815878577165\n",
      "2013 Train Loss 6.510322e-05 Test Loss 0.0001714989409979566\n",
      "2014 Train Loss 6.503007e-05 Test Loss 0.00017183991483566487\n",
      "2015 Train Loss 6.498325e-05 Test Loss 0.00017194637029950633\n",
      "2016 Train Loss 6.489893e-05 Test Loss 0.00017236953559379315\n",
      "2017 Train Loss 6.477494e-05 Test Loss 0.00017151589149519604\n",
      "2018 Train Loss 6.465656e-05 Test Loss 0.0001716293520979495\n",
      "2019 Train Loss 6.46131e-05 Test Loss 0.0001737347783097218\n",
      "2020 Train Loss 6.441779e-05 Test Loss 0.00017448827972016818\n",
      "2021 Train Loss 6.431806e-05 Test Loss 0.00017598168767042787\n",
      "2022 Train Loss 6.4206746e-05 Test Loss 0.00017960033298904893\n",
      "2023 Train Loss 6.409976e-05 Test Loss 0.000182474809764216\n",
      "2024 Train Loss 6.396587e-05 Test Loss 0.00018428869436831356\n",
      "2025 Train Loss 7.836029e-05 Test Loss 0.00015465903435526234\n",
      "2026 Train Loss 6.392738e-05 Test Loss 0.0001822191544048644\n",
      "2027 Train Loss 6.3751395e-05 Test Loss 0.00018359221853011978\n",
      "2028 Train Loss 6.3652595e-05 Test Loss 0.0001836878697197804\n",
      "2029 Train Loss 6.350805e-05 Test Loss 0.00018451770453150096\n",
      "2030 Train Loss 6.3380896e-05 Test Loss 0.00018590040270552918\n",
      "2031 Train Loss 6.329313e-05 Test Loss 0.0001872850983457729\n",
      "2032 Train Loss 6.32147e-05 Test Loss 0.00018835296665785294\n",
      "2033 Train Loss 6.314393e-05 Test Loss 0.00018853058094094166\n",
      "2034 Train Loss 6.307325e-05 Test Loss 0.00018765837840041509\n",
      "2035 Train Loss 6.3051106e-05 Test Loss 0.00018857707961532192\n",
      "2036 Train Loss 6.334724e-05 Test Loss 0.00018934559672445167\n",
      "2037 Train Loss 6.299892e-05 Test Loss 0.00018876000810547422\n",
      "2038 Train Loss 6.293786e-05 Test Loss 0.00018663709177627898\n",
      "2039 Train Loss 6.288554e-05 Test Loss 0.00018419636634822633\n",
      "2040 Train Loss 6.388008e-05 Test Loss 0.0001790185523196527\n",
      "2041 Train Loss 6.287723e-05 Test Loss 0.00018374036209923078\n",
      "2042 Train Loss 6.2845575e-05 Test Loss 0.00018352124023916896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2043 Train Loss 6.28869e-05 Test Loss 0.00017619766938560804\n",
      "2044 Train Loss 6.279579e-05 Test Loss 0.0001803430760873248\n",
      "2045 Train Loss 6.273598e-05 Test Loss 0.0001806274294429682\n",
      "2046 Train Loss 6.265832e-05 Test Loss 0.00018159717358433276\n",
      "2047 Train Loss 6.271356e-05 Test Loss 0.0001827435963879747\n",
      "2048 Train Loss 6.2628635e-05 Test Loss 0.000182016480075395\n",
      "2049 Train Loss 6.257517e-05 Test Loss 0.0001816215130262575\n",
      "2050 Train Loss 6.2484105e-05 Test Loss 0.00018137147804121674\n",
      "2051 Train Loss 6.239493e-05 Test Loss 0.00018216837666772592\n",
      "2052 Train Loss 6.230591e-05 Test Loss 0.00018307254462416974\n",
      "2053 Train Loss 6.226395e-05 Test Loss 0.00018380530916312153\n",
      "2054 Train Loss 6.223179e-05 Test Loss 0.00018406966830897744\n",
      "2055 Train Loss 6.2200095e-05 Test Loss 0.00018434765220852172\n",
      "2056 Train Loss 6.213045e-05 Test Loss 0.00018474198720319968\n",
      "2057 Train Loss 6.271866e-05 Test Loss 0.00018242951209176739\n",
      "2058 Train Loss 6.207243e-05 Test Loss 0.0001841786964751302\n",
      "2059 Train Loss 6.1998886e-05 Test Loss 0.00018425726779311855\n",
      "2060 Train Loss 6.1918705e-05 Test Loss 0.00018385232672771539\n",
      "2061 Train Loss 6.189595e-05 Test Loss 0.00018252547660081597\n",
      "2062 Train Loss 6.1876235e-05 Test Loss 0.00018089793259965818\n",
      "2063 Train Loss 6.184254e-05 Test Loss 0.00017764560644944143\n",
      "2064 Train Loss 6.181189e-05 Test Loss 0.0001753325217908315\n",
      "2065 Train Loss 6.176136e-05 Test Loss 0.00017265746414288604\n",
      "2066 Train Loss 8.6425986e-05 Test Loss 0.0001749729119345717\n",
      "2067 Train Loss 6.1689396e-05 Test Loss 0.0001692368478570433\n",
      "2068 Train Loss 6.1615334e-05 Test Loss 0.0001698035590337647\n",
      "2069 Train Loss 6.1552615e-05 Test Loss 0.00017210565846834707\n",
      "2070 Train Loss 6.149875e-05 Test Loss 0.00017328728289965192\n",
      "2071 Train Loss 6.1456434e-05 Test Loss 0.00017325806815860143\n",
      "2072 Train Loss 6.1401224e-05 Test Loss 0.00017304413742818807\n",
      "2073 Train Loss 6.216789e-05 Test Loss 0.00017743358868049054\n",
      "2074 Train Loss 6.138395e-05 Test Loss 0.00017351286548404976\n",
      "2075 Train Loss 6.133552e-05 Test Loss 0.00017251243374807347\n",
      "2076 Train Loss 6.13131e-05 Test Loss 0.00017281577879771397\n",
      "2077 Train Loss 6.126065e-05 Test Loss 0.0001720907593820379\n",
      "2078 Train Loss 6.122671e-05 Test Loss 0.00017182981803084106\n",
      "2079 Train Loss 6.11852e-05 Test Loss 0.00017255782781189566\n",
      "2080 Train Loss 6.11578e-05 Test Loss 0.0001725681045474053\n",
      "2081 Train Loss 6.110408e-05 Test Loss 0.00017260106075481522\n",
      "2082 Train Loss 6.107346e-05 Test Loss 0.00017364889662151408\n",
      "2083 Train Loss 6.1010287e-05 Test Loss 0.00017175949239930656\n",
      "2084 Train Loss 6.0967745e-05 Test Loss 0.00017052732932527044\n",
      "2085 Train Loss 6.0919247e-05 Test Loss 0.00016884167527439402\n",
      "2086 Train Loss 6.0877726e-05 Test Loss 0.00016801397732470926\n",
      "2087 Train Loss 6.0846745e-05 Test Loss 0.00016750345483370103\n",
      "2088 Train Loss 6.0815604e-05 Test Loss 0.00016781961719073874\n",
      "2089 Train Loss 6.0784416e-05 Test Loss 0.00016800061333811886\n",
      "2090 Train Loss 6.075448e-05 Test Loss 0.00016843462790134503\n",
      "2091 Train Loss 6.0730265e-05 Test Loss 0.00016842671933801613\n",
      "2092 Train Loss 6.070024e-05 Test Loss 0.00016772964587240477\n",
      "2093 Train Loss 6.0667204e-05 Test Loss 0.0001677263098233888\n",
      "2094 Train Loss 6.0624403e-05 Test Loss 0.00016767338567265244\n",
      "2095 Train Loss 6.055505e-05 Test Loss 0.0001669988654789508\n",
      "2096 Train Loss 6.05051e-05 Test Loss 0.00016889924290940277\n",
      "2097 Train Loss 6.047541e-05 Test Loss 0.00016834782611074923\n",
      "2098 Train Loss 6.0441285e-05 Test Loss 0.00016731229414431768\n",
      "2099 Train Loss 6.0452454e-05 Test Loss 0.0001645866791459197\n",
      "2100 Train Loss 6.042177e-05 Test Loss 0.00016608907031890122\n",
      "2101 Train Loss 6.0369443e-05 Test Loss 0.0001650943864773265\n",
      "2102 Train Loss 6.0316113e-05 Test Loss 0.0001650556551988624\n",
      "2103 Train Loss 6.0244914e-05 Test Loss 0.00016510598021593392\n",
      "2104 Train Loss 6.020022e-05 Test Loss 0.00016549032733926536\n",
      "2105 Train Loss 6.0159527e-05 Test Loss 0.0001659980188074907\n",
      "2106 Train Loss 6.0116625e-05 Test Loss 0.00016596635676051908\n",
      "2107 Train Loss 6.0083283e-05 Test Loss 0.0001660292950761812\n",
      "2108 Train Loss 6.0029604e-05 Test Loss 0.000166064875162499\n",
      "2109 Train Loss 5.998915e-05 Test Loss 0.00016593488866505275\n",
      "2110 Train Loss 5.9948856e-05 Test Loss 0.00016580725575062016\n",
      "2111 Train Loss 5.9878006e-05 Test Loss 0.0001657723533636863\n",
      "2112 Train Loss 6.155493e-05 Test Loss 0.0001725266041309929\n",
      "2113 Train Loss 5.9866503e-05 Test Loss 0.00016626833219176917\n",
      "2114 Train Loss 5.9809958e-05 Test Loss 0.00016586285036703345\n",
      "2115 Train Loss 5.977034e-05 Test Loss 0.00016556698978674344\n",
      "2116 Train Loss 5.9737868e-05 Test Loss 0.00016490470559126484\n",
      "2117 Train Loss 5.9702557e-05 Test Loss 0.00016472060829872688\n",
      "2118 Train Loss 5.966762e-05 Test Loss 0.0001643392840749715\n",
      "2119 Train Loss 5.964623e-05 Test Loss 0.0001640402667785254\n",
      "2120 Train Loss 5.9603582e-05 Test Loss 0.00016435810117292312\n",
      "2121 Train Loss 6.0012317e-05 Test Loss 0.00016027657384422373\n",
      "2122 Train Loss 5.9583443e-05 Test Loss 0.0001635631551833607\n",
      "2123 Train Loss 5.9618702e-05 Test Loss 0.00016615944581375243\n",
      "2124 Train Loss 5.9560232e-05 Test Loss 0.00016454040170721485\n",
      "2125 Train Loss 5.9522616e-05 Test Loss 0.00016482130126605515\n",
      "2126 Train Loss 5.9543203e-05 Test Loss 0.000167858325149396\n",
      "2127 Train Loss 5.9450507e-05 Test Loss 0.0001662360317869287\n",
      "2128 Train Loss 5.938734e-05 Test Loss 0.00016703475952607697\n",
      "2129 Train Loss 5.9292674e-05 Test Loss 0.00016916880591218015\n",
      "2130 Train Loss 5.9381193e-05 Test Loss 0.00017180290732123456\n",
      "2131 Train Loss 5.9259415e-05 Test Loss 0.0001701424065223548\n",
      "2132 Train Loss 5.9219878e-05 Test Loss 0.00017031706828307423\n",
      "2133 Train Loss 5.913984e-05 Test Loss 0.00017081972144983418\n",
      "2134 Train Loss 5.9119826e-05 Test Loss 0.00017084600298262922\n",
      "2135 Train Loss 5.908491e-05 Test Loss 0.00017078823409086126\n",
      "2136 Train Loss 5.904045e-05 Test Loss 0.00017146805468512327\n",
      "2137 Train Loss 5.900723e-05 Test Loss 0.00017123426993984628\n",
      "2138 Train Loss 5.8978912e-05 Test Loss 0.00017097194434431568\n",
      "2139 Train Loss 5.8941183e-05 Test Loss 0.00017093465274334503\n",
      "2140 Train Loss 5.887431e-05 Test Loss 0.0001708826227527909\n",
      "2141 Train Loss 5.890693e-05 Test Loss 0.0001739204113604098\n",
      "2142 Train Loss 5.8841215e-05 Test Loss 0.0001721400792936769\n",
      "2143 Train Loss 5.8789992e-05 Test Loss 0.0001732328428487883\n",
      "2144 Train Loss 5.8745532e-05 Test Loss 0.00017409805555853458\n",
      "2145 Train Loss 5.872859e-05 Test Loss 0.00017494597155131428\n",
      "2146 Train Loss 5.87147e-05 Test Loss 0.00017490053114027529\n",
      "2147 Train Loss 5.8696234e-05 Test Loss 0.00017455998501298456\n",
      "2148 Train Loss 5.867402e-05 Test Loss 0.0001746071791363159\n",
      "2149 Train Loss 5.8719786e-05 Test Loss 0.00017301871552229922\n",
      "2150 Train Loss 5.865562e-05 Test Loss 0.00017404112532152946\n",
      "2151 Train Loss 5.8645743e-05 Test Loss 0.00017573014606309364\n",
      "2152 Train Loss 5.859812e-05 Test Loss 0.00017490133429721476\n",
      "2153 Train Loss 5.8549682e-05 Test Loss 0.00017570586331393427\n",
      "2154 Train Loss 5.8498634e-05 Test Loss 0.00017642783069187425\n",
      "2155 Train Loss 5.848035e-05 Test Loss 0.00017832801928763028\n",
      "2156 Train Loss 5.8452337e-05 Test Loss 0.00017803635751201236\n",
      "2157 Train Loss 5.8425496e-05 Test Loss 0.00017806501823515913\n",
      "2158 Train Loss 5.8399168e-05 Test Loss 0.0001780335491561442\n",
      "2159 Train Loss 5.837544e-05 Test Loss 0.0001765489289779994\n",
      "2160 Train Loss 5.834561e-05 Test Loss 0.0001769906981399752\n",
      "2161 Train Loss 5.8311904e-05 Test Loss 0.00017704101077565537\n",
      "2162 Train Loss 5.827862e-05 Test Loss 0.00017736822996684926\n",
      "2163 Train Loss 5.824327e-05 Test Loss 0.00017760254971395907\n",
      "2164 Train Loss 5.81825e-05 Test Loss 0.00017835199676858514\n",
      "2165 Train Loss 5.811038e-05 Test Loss 0.00017933182102212414\n",
      "2166 Train Loss 5.8112768e-05 Test Loss 0.00017678280860709678\n",
      "2167 Train Loss 5.808166e-05 Test Loss 0.00017803072423085901\n",
      "2168 Train Loss 5.806808e-05 Test Loss 0.00017873707208675965\n",
      "2169 Train Loss 5.8012985e-05 Test Loss 0.00017853796595662425\n",
      "2170 Train Loss 5.7981313e-05 Test Loss 0.000178503694920415\n",
      "2171 Train Loss 5.7928213e-05 Test Loss 0.00017854910602962796\n",
      "2172 Train Loss 5.7869976e-05 Test Loss 0.0001786589399539068\n",
      "2173 Train Loss 5.7814963e-05 Test Loss 0.00017821297567515305\n",
      "2174 Train Loss 5.7914804e-05 Test Loss 0.00017869967969062525\n",
      "2175 Train Loss 5.779198e-05 Test Loss 0.00017835398091156917\n",
      "2176 Train Loss 5.772971e-05 Test Loss 0.00017765694238870255\n",
      "2177 Train Loss 5.76885e-05 Test Loss 0.00017723274052150662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2178 Train Loss 5.763983e-05 Test Loss 0.00017763105707759418\n",
      "2179 Train Loss 5.760774e-05 Test Loss 0.0001777658205887434\n",
      "2180 Train Loss 5.7583515e-05 Test Loss 0.0001782349328416201\n",
      "2181 Train Loss 5.8202502e-05 Test Loss 0.00018174468838956574\n",
      "2182 Train Loss 5.757826e-05 Test Loss 0.0001785252617878553\n",
      "2183 Train Loss 5.754441e-05 Test Loss 0.00017990606800773808\n",
      "2184 Train Loss 5.752412e-05 Test Loss 0.00017990096346346616\n",
      "2185 Train Loss 5.7544206e-05 Test Loss 0.0001868340810267787\n",
      "2186 Train Loss 5.7494486e-05 Test Loss 0.00018279095540559768\n",
      "2187 Train Loss 5.742754e-05 Test Loss 0.00018248610113286867\n",
      "2188 Train Loss 5.7367186e-05 Test Loss 0.00018289343394921976\n",
      "2189 Train Loss 5.7305097e-05 Test Loss 0.0001846313940025063\n",
      "2190 Train Loss 5.7287507e-05 Test Loss 0.00018511427279489676\n",
      "2191 Train Loss 5.7255063e-05 Test Loss 0.00018469286788865173\n",
      "2192 Train Loss 5.722761e-05 Test Loss 0.00018534498604680212\n",
      "2193 Train Loss 5.719527e-05 Test Loss 0.00018680209959666698\n",
      "2194 Train Loss 5.7164594e-05 Test Loss 0.00018867651080121397\n",
      "2195 Train Loss 5.713661e-05 Test Loss 0.00019030283898439\n",
      "2196 Train Loss 5.7114783e-05 Test Loss 0.00019091277617831872\n",
      "2197 Train Loss 5.7070505e-05 Test Loss 0.00019238310679958563\n",
      "2198 Train Loss 5.825473e-05 Test Loss 0.00017910580698162984\n",
      "2199 Train Loss 5.703602e-05 Test Loss 0.00019031220275090113\n",
      "2200 Train Loss 5.6966303e-05 Test Loss 0.00019018602845089446\n",
      "2201 Train Loss 5.6858546e-05 Test Loss 0.00018965785279317644\n",
      "2202 Train Loss 5.6780234e-05 Test Loss 0.00018963245421809536\n",
      "2203 Train Loss 5.673174e-05 Test Loss 0.00018839270013944548\n",
      "2204 Train Loss 5.6673045e-05 Test Loss 0.0001897556694546658\n",
      "2205 Train Loss 5.6631347e-05 Test Loss 0.00019046331560625598\n",
      "2206 Train Loss 5.659045e-05 Test Loss 0.00019172588584510637\n",
      "2207 Train Loss 5.656553e-05 Test Loss 0.00019191746506901883\n",
      "2208 Train Loss 5.653583e-05 Test Loss 0.00019314032772052938\n",
      "2209 Train Loss 5.6499062e-05 Test Loss 0.00019272558145997152\n",
      "2210 Train Loss 5.6467976e-05 Test Loss 0.00019236017612923363\n",
      "2211 Train Loss 5.6439618e-05 Test Loss 0.000191398244101025\n",
      "2212 Train Loss 5.641267e-05 Test Loss 0.0001901394681503652\n",
      "2213 Train Loss 5.6387726e-05 Test Loss 0.00018987293645001722\n",
      "2214 Train Loss 5.6369834e-05 Test Loss 0.00018982281871302587\n",
      "2215 Train Loss 5.6342946e-05 Test Loss 0.00019030684730265578\n",
      "2216 Train Loss 5.6311008e-05 Test Loss 0.0001914056183894934\n",
      "2217 Train Loss 5.62739e-05 Test Loss 0.00019292084970736717\n",
      "2218 Train Loss 5.6238096e-05 Test Loss 0.0001938928840732115\n",
      "2219 Train Loss 5.6203535e-05 Test Loss 0.0001946986086403198\n",
      "2220 Train Loss 5.617665e-05 Test Loss 0.00019399808182164218\n",
      "2221 Train Loss 5.6151053e-05 Test Loss 0.00019299566162387605\n",
      "2222 Train Loss 5.6133977e-05 Test Loss 0.00019177219256986624\n",
      "2223 Train Loss 5.61245e-05 Test Loss 0.0001912194671374906\n",
      "2224 Train Loss 5.6090877e-05 Test Loss 0.00018791108683000927\n",
      "2225 Train Loss 5.604436e-05 Test Loss 0.00018919515605270585\n",
      "2226 Train Loss 5.599119e-05 Test Loss 0.00019041214044936087\n",
      "2227 Train Loss 5.5946402e-05 Test Loss 0.00019078790012588538\n",
      "2228 Train Loss 5.5936347e-05 Test Loss 0.00018966539817379737\n",
      "2229 Train Loss 5.5876983e-05 Test Loss 0.00018953946778239254\n",
      "2230 Train Loss 5.5831508e-05 Test Loss 0.0001902217048286158\n",
      "2231 Train Loss 5.5946635e-05 Test Loss 0.00018537925673252882\n",
      "2232 Train Loss 5.581751e-05 Test Loss 0.00018892489913421487\n",
      "2233 Train Loss 5.5795448e-05 Test Loss 0.0001883341324072073\n",
      "2234 Train Loss 5.5775447e-05 Test Loss 0.0001879298758296339\n",
      "2235 Train Loss 5.5751803e-05 Test Loss 0.00018726684383638036\n",
      "2236 Train Loss 5.5714983e-05 Test Loss 0.0001866471365378537\n",
      "2237 Train Loss 5.5654327e-05 Test Loss 0.00018573400464582277\n",
      "2238 Train Loss 5.5575714e-05 Test Loss 0.0001851525803870666\n",
      "2239 Train Loss 5.5504934e-05 Test Loss 0.0001846597477990803\n",
      "2240 Train Loss 5.547305e-05 Test Loss 0.00018458425576759906\n",
      "2241 Train Loss 5.544704e-05 Test Loss 0.0001846799666212827\n",
      "2242 Train Loss 5.542326e-05 Test Loss 0.00018481211102403439\n",
      "2243 Train Loss 5.5444536e-05 Test Loss 0.00018828597013461414\n",
      "2244 Train Loss 5.5398967e-05 Test Loss 0.00018628939322575767\n",
      "2245 Train Loss 5.5369994e-05 Test Loss 0.00018598864831664966\n",
      "2246 Train Loss 5.534698e-05 Test Loss 0.0001856186366725283\n",
      "2247 Train Loss 5.5319615e-05 Test Loss 0.00018549655562092815\n",
      "2248 Train Loss 5.5289645e-05 Test Loss 0.00018493813810028685\n",
      "2249 Train Loss 5.52571e-05 Test Loss 0.00018428771766937596\n",
      "2250 Train Loss 5.5220917e-05 Test Loss 0.00018389864892567165\n",
      "2251 Train Loss 5.519617e-05 Test Loss 0.00018372834647206997\n",
      "2252 Train Loss 5.5185592e-05 Test Loss 0.00018277940737728953\n",
      "2253 Train Loss 5.516959e-05 Test Loss 0.00018307543897522007\n",
      "2254 Train Loss 5.5159027e-05 Test Loss 0.0001833203340142433\n",
      "2255 Train Loss 5.5145203e-05 Test Loss 0.00018414860623109663\n",
      "2256 Train Loss 6.154712e-05 Test Loss 0.00017285222745311838\n",
      "2257 Train Loss 5.5138516e-05 Test Loss 0.00018356436465954986\n",
      "2258 Train Loss 5.5125725e-05 Test Loss 0.00018355032785378998\n",
      "2259 Train Loss 5.5102282e-05 Test Loss 0.000183083146560972\n",
      "2260 Train Loss 5.509592e-05 Test Loss 0.00018296913938871856\n",
      "2261 Train Loss 5.508106e-05 Test Loss 0.0001822617746510748\n",
      "2262 Train Loss 5.5062977e-05 Test Loss 0.00018193697241459657\n",
      "2263 Train Loss 5.5030825e-05 Test Loss 0.00018152939154298124\n",
      "2264 Train Loss 5.5004184e-05 Test Loss 0.00018203508458450706\n",
      "2265 Train Loss 5.4987027e-05 Test Loss 0.00018266196559391755\n",
      "2266 Train Loss 5.498129e-05 Test Loss 0.00018407459883649496\n",
      "2267 Train Loss 5.497282e-05 Test Loss 0.00018383933517193823\n",
      "2268 Train Loss 5.4967117e-05 Test Loss 0.00018370030608996744\n",
      "2269 Train Loss 5.4959997e-05 Test Loss 0.00018355861829251512\n",
      "2270 Train Loss 5.49521e-05 Test Loss 0.00018347553805330571\n",
      "2271 Train Loss 5.494184e-05 Test Loss 0.0001833274359142743\n",
      "2272 Train Loss 5.493455e-05 Test Loss 0.0001832289433404358\n",
      "2273 Train Loss 5.492613e-05 Test Loss 0.00018317248235071086\n",
      "2274 Train Loss 5.493957e-05 Test Loss 0.0001834925511601934\n",
      "2275 Train Loss 5.492325e-05 Test Loss 0.00018326350074191372\n",
      "2276 Train Loss 5.498346e-05 Test Loss 0.00018772249209617444\n",
      "2277 Train Loss 5.4917815e-05 Test Loss 0.0001842851321468829\n",
      "2278 Train Loss 5.490871e-05 Test Loss 0.0001841238158289983\n",
      "2279 Train Loss 5.490246e-05 Test Loss 0.00018410133188515355\n",
      "2280 Train Loss 5.488247e-05 Test Loss 0.00018405572468402454\n",
      "2281 Train Loss 5.4873253e-05 Test Loss 0.000184662055870724\n",
      "2282 Train Loss 5.4859956e-05 Test Loss 0.00018429557639466316\n",
      "2283 Train Loss 5.4839453e-05 Test Loss 0.0001841340988749491\n",
      "2284 Train Loss 5.481163e-05 Test Loss 0.00018427270864935046\n",
      "2285 Train Loss 5.4795426e-05 Test Loss 0.00018450857600247752\n",
      "2286 Train Loss 5.4777764e-05 Test Loss 0.00018519550204423445\n",
      "2287 Train Loss 5.4763692e-05 Test Loss 0.00018559874011284268\n",
      "2288 Train Loss 5.497428e-05 Test Loss 0.00019248586025141852\n",
      "2289 Train Loss 5.4756576e-05 Test Loss 0.00018645797663067014\n",
      "2290 Train Loss 5.473433e-05 Test Loss 0.00018679517689561335\n",
      "2291 Train Loss 5.4716536e-05 Test Loss 0.00018663398947908763\n",
      "2292 Train Loss 5.4704047e-05 Test Loss 0.00018653998303846232\n",
      "2293 Train Loss 5.4677363e-05 Test Loss 0.0001870049140524792\n",
      "2294 Train Loss 5.4644268e-05 Test Loss 0.00018825475493295922\n",
      "2295 Train Loss 5.461656e-05 Test Loss 0.00018957275329564932\n",
      "2296 Train Loss 5.458792e-05 Test Loss 0.0001914999515856096\n",
      "2297 Train Loss 5.4571236e-05 Test Loss 0.0001925420883024609\n",
      "2298 Train Loss 5.4554075e-05 Test Loss 0.00019299866668844577\n",
      "2299 Train Loss 5.4538068e-05 Test Loss 0.0001932408442684029\n",
      "2300 Train Loss 5.4544384e-05 Test Loss 0.00019370285050193643\n",
      "2301 Train Loss 5.4528606e-05 Test Loss 0.00019344072164324564\n",
      "2302 Train Loss 5.4529442e-05 Test Loss 0.0001952078872448828\n",
      "2303 Train Loss 5.450425e-05 Test Loss 0.00019431789932279332\n",
      "2304 Train Loss 5.4477903e-05 Test Loss 0.00019375487849416316\n",
      "2305 Train Loss 5.4435768e-05 Test Loss 0.00019253364057545346\n",
      "2306 Train Loss 5.43806e-05 Test Loss 0.0001907206239689628\n",
      "2307 Train Loss 5.4322874e-05 Test Loss 0.00018858583865588444\n",
      "2308 Train Loss 5.4251497e-05 Test Loss 0.00018507222789599807\n",
      "2309 Train Loss 5.4194847e-05 Test Loss 0.00018376891736153253\n",
      "2310 Train Loss 5.415175e-05 Test Loss 0.00018365305030176087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2311 Train Loss 5.412758e-05 Test Loss 0.0001836704535373243\n",
      "2312 Train Loss 5.6626865e-05 Test Loss 0.00019365654745007445\n",
      "2313 Train Loss 5.4123586e-05 Test Loss 0.00018392261628999524\n",
      "2314 Train Loss 5.4127784e-05 Test Loss 0.00018570478200672603\n",
      "2315 Train Loss 5.4103773e-05 Test Loss 0.00018474073923699993\n",
      "2316 Train Loss 5.4071712e-05 Test Loss 0.00018378686824430674\n",
      "2317 Train Loss 5.4028336e-05 Test Loss 0.00018271881913148796\n",
      "2318 Train Loss 5.3967833e-05 Test Loss 0.00018000731734088018\n",
      "2319 Train Loss 5.3881475e-05 Test Loss 0.00017858432596840258\n",
      "2320 Train Loss 5.3773623e-05 Test Loss 0.00017806316115554535\n",
      "2321 Train Loss 5.3656207e-05 Test Loss 0.00017837307196905068\n",
      "2322 Train Loss 5.355728e-05 Test Loss 0.0001778460301852071\n",
      "2323 Train Loss 5.3500167e-05 Test Loss 0.00017723703242450152\n",
      "2324 Train Loss 5.3457075e-05 Test Loss 0.0001760390065126046\n",
      "2325 Train Loss 5.3418786e-05 Test Loss 0.00017518261062710413\n",
      "2326 Train Loss 5.3372063e-05 Test Loss 0.0001745940587161126\n",
      "2327 Train Loss 5.3316573e-05 Test Loss 0.00017498225244535231\n",
      "2328 Train Loss 5.332075e-05 Test Loss 0.0001793311021996739\n",
      "2329 Train Loss 5.324016e-05 Test Loss 0.00017695458247674525\n",
      "2330 Train Loss 5.3170592e-05 Test Loss 0.0001785863232902996\n",
      "2331 Train Loss 5.3102085e-05 Test Loss 0.00017978067816828535\n",
      "2332 Train Loss 5.298201e-05 Test Loss 0.00018261826453782825\n",
      "2333 Train Loss 5.292049e-05 Test Loss 0.0001851960501451868\n",
      "2334 Train Loss 5.285003e-05 Test Loss 0.00018769445468311762\n",
      "2335 Train Loss 5.279562e-05 Test Loss 0.00018905469579822041\n",
      "2336 Train Loss 5.2732055e-05 Test Loss 0.00018878783179202788\n",
      "2337 Train Loss 5.267231e-05 Test Loss 0.00018794112687993417\n",
      "2338 Train Loss 5.263751e-05 Test Loss 0.00018848793328373855\n",
      "2339 Train Loss 5.2557036e-05 Test Loss 0.000189409500855249\n",
      "2340 Train Loss 5.2526946e-05 Test Loss 0.00019028377215347638\n",
      "2341 Train Loss 5.2421554e-05 Test Loss 0.00019563708510772303\n",
      "2342 Train Loss 5.235165e-05 Test Loss 0.0001977563752878479\n",
      "2343 Train Loss 5.2271982e-05 Test Loss 0.00020043138166526823\n",
      "2344 Train Loss 5.2211257e-05 Test Loss 0.00020056086710844176\n",
      "2345 Train Loss 5.2152685e-05 Test Loss 0.0002031479539418572\n",
      "2346 Train Loss 5.2107025e-05 Test Loss 0.00020298286396777977\n",
      "2347 Train Loss 5.2065647e-05 Test Loss 0.00020190047592027577\n",
      "2348 Train Loss 5.202418e-05 Test Loss 0.00020184714708559756\n",
      "2349 Train Loss 5.1955725e-05 Test Loss 0.00020271390295875335\n",
      "2350 Train Loss 5.182858e-05 Test Loss 0.00020716447384390595\n",
      "2351 Train Loss 5.1775125e-05 Test Loss 0.0002102693804332468\n",
      "2352 Train Loss 5.1707037e-05 Test Loss 0.0002112783648831996\n",
      "2353 Train Loss 5.164369e-05 Test Loss 0.00021135399292821226\n",
      "2354 Train Loss 5.1576673e-05 Test Loss 0.00021232726771329451\n",
      "2355 Train Loss 5.167388e-05 Test Loss 0.00021627795497642703\n",
      "2356 Train Loss 5.1546347e-05 Test Loss 0.00021362084097650374\n",
      "2357 Train Loss 5.1478448e-05 Test Loss 0.0002130117774596303\n",
      "2358 Train Loss 5.143729e-05 Test Loss 0.0002135504544764847\n",
      "2359 Train Loss 5.1399336e-05 Test Loss 0.000213476110660173\n",
      "2360 Train Loss 5.1361138e-05 Test Loss 0.00021345437498467297\n",
      "2361 Train Loss 5.1326722e-05 Test Loss 0.0002123825606855939\n",
      "2362 Train Loss 5.2142947e-05 Test Loss 0.00021731072330898223\n",
      "2363 Train Loss 5.1318013e-05 Test Loss 0.00021284187185535277\n",
      "2364 Train Loss 5.1282448e-05 Test Loss 0.00021253672539726205\n",
      "2365 Train Loss 5.1241586e-05 Test Loss 0.00021340380156849477\n",
      "2366 Train Loss 5.120593e-05 Test Loss 0.00021331038514677044\n",
      "2367 Train Loss 5.1170777e-05 Test Loss 0.00021452315229912851\n",
      "2368 Train Loss 5.113278e-05 Test Loss 0.0002166065472372228\n",
      "2369 Train Loss 5.110997e-05 Test Loss 0.00021620796507096701\n",
      "2370 Train Loss 5.1077754e-05 Test Loss 0.00021642163381978635\n",
      "2371 Train Loss 5.1036353e-05 Test Loss 0.0002181773833625506\n",
      "2372 Train Loss 5.1001545e-05 Test Loss 0.00021958080025534076\n",
      "2373 Train Loss 5.0961822e-05 Test Loss 0.0002216304189728307\n",
      "2374 Train Loss 5.093129e-05 Test Loss 0.00022577923212720183\n",
      "2375 Train Loss 5.1027535e-05 Test Loss 0.00022671875529020478\n",
      "2376 Train Loss 5.0902956e-05 Test Loss 0.00022607477025991162\n",
      "2377 Train Loss 5.113476e-05 Test Loss 0.00023967597487330717\n",
      "2378 Train Loss 5.0892122e-05 Test Loss 0.0002283660435010995\n",
      "2379 Train Loss 5.0860264e-05 Test Loss 0.00023560156067393956\n",
      "2380 Train Loss 5.2863666e-05 Test Loss 0.0002707603585955084\n",
      "2381 Train Loss 5.0833805e-05 Test Loss 0.0002393131478264648\n",
      "2382 Train Loss 5.079888e-05 Test Loss 0.00023584968806834237\n",
      "2383 Train Loss 5.077199e-05 Test Loss 0.0002324176164169325\n",
      "2384 Train Loss 5.0735267e-05 Test Loss 0.00023147540293710176\n",
      "2385 Train Loss 5.066189e-05 Test Loss 0.00023255561456062663\n",
      "2386 Train Loss 5.0607345e-05 Test Loss 0.00023398476056687604\n",
      "2387 Train Loss 5.0511775e-05 Test Loss 0.00023537921928034445\n",
      "2388 Train Loss 5.041942e-05 Test Loss 0.00023538079330556817\n",
      "2389 Train Loss 5.035416e-05 Test Loss 0.00023407341520218416\n",
      "2390 Train Loss 5.0300623e-05 Test Loss 0.00023045015535549495\n",
      "2391 Train Loss 5.02508e-05 Test Loss 0.00022757480740775884\n",
      "2392 Train Loss 5.0189883e-05 Test Loss 0.0002276948560730652\n",
      "2393 Train Loss 5.0126633e-05 Test Loss 0.0002265111214057812\n",
      "2394 Train Loss 5.008604e-05 Test Loss 0.00022892125377815202\n",
      "2395 Train Loss 5.004651e-05 Test Loss 0.00023006685537626043\n",
      "2396 Train Loss 5.001142e-05 Test Loss 0.0002305000870566036\n",
      "2397 Train Loss 4.9977323e-05 Test Loss 0.000228319003202848\n",
      "2398 Train Loss 4.994459e-05 Test Loss 0.00022512971254980921\n",
      "2399 Train Loss 5.2983327e-05 Test Loss 0.00020277774804840668\n",
      "2400 Train Loss 4.989955e-05 Test Loss 0.0002205046902892557\n",
      "2401 Train Loss 4.9846996e-05 Test Loss 0.00021996705742429736\n",
      "2402 Train Loss 4.980396e-05 Test Loss 0.00022082590413665805\n",
      "2403 Train Loss 4.9760536e-05 Test Loss 0.00022082994681516378\n",
      "2404 Train Loss 4.9730777e-05 Test Loss 0.00021928420122738822\n",
      "2405 Train Loss 4.9687118e-05 Test Loss 0.0002176783121605564\n",
      "2406 Train Loss 4.963344e-05 Test Loss 0.00021428799269381985\n",
      "2407 Train Loss 4.9565195e-05 Test Loss 0.0002115000025451634\n",
      "2408 Train Loss 4.9524577e-05 Test Loss 0.00021012037285096712\n",
      "2409 Train Loss 4.944843e-05 Test Loss 0.00020653479807786028\n",
      "2410 Train Loss 4.936236e-05 Test Loss 0.00020744155848592322\n",
      "2411 Train Loss 4.9297574e-05 Test Loss 0.00020603137290304492\n",
      "2412 Train Loss 4.9232927e-05 Test Loss 0.0002025114510209075\n",
      "2413 Train Loss 4.917872e-05 Test Loss 0.00019810318171731465\n",
      "2414 Train Loss 4.913685e-05 Test Loss 0.00019622280775113943\n",
      "2415 Train Loss 4.9087197e-05 Test Loss 0.00019488530542434773\n",
      "2416 Train Loss 4.903746e-05 Test Loss 0.0001945184944315322\n",
      "2417 Train Loss 4.895833e-05 Test Loss 0.00019390972455514687\n",
      "2418 Train Loss 4.89749e-05 Test Loss 0.00019616904753420625\n",
      "2419 Train Loss 4.8933143e-05 Test Loss 0.00019487144164013673\n",
      "2420 Train Loss 4.902947e-05 Test Loss 0.00019015201264512387\n",
      "2421 Train Loss 4.891135e-05 Test Loss 0.00019343486781900977\n",
      "2422 Train Loss 4.886806e-05 Test Loss 0.0001919238579765019\n",
      "2423 Train Loss 4.882573e-05 Test Loss 0.00019100969862473056\n",
      "2424 Train Loss 4.8789596e-05 Test Loss 0.0001901083307046187\n",
      "2425 Train Loss 4.8709997e-05 Test Loss 0.00018749468973741808\n",
      "2426 Train Loss 4.866192e-05 Test Loss 0.0001851010882302666\n",
      "2427 Train Loss 4.890198e-05 Test Loss 0.00018308322495700518\n",
      "2428 Train Loss 4.8633516e-05 Test Loss 0.0001846264244361044\n",
      "2429 Train Loss 4.85764e-05 Test Loss 0.00018303000664614578\n",
      "2430 Train Loss 4.8513277e-05 Test Loss 0.0001826727483541494\n",
      "2431 Train Loss 4.8480986e-05 Test Loss 0.00018298726058351496\n",
      "2432 Train Loss 4.8458238e-05 Test Loss 0.0001833604094461545\n",
      "2433 Train Loss 4.843272e-05 Test Loss 0.00018470006586381748\n",
      "2434 Train Loss 4.8411417e-05 Test Loss 0.00018617491519519705\n",
      "2435 Train Loss 4.8390102e-05 Test Loss 0.0001872637131898563\n",
      "2436 Train Loss 4.8364207e-05 Test Loss 0.0001872052327015774\n",
      "2437 Train Loss 4.8343438e-05 Test Loss 0.00018625822360096773\n",
      "2438 Train Loss 4.8328075e-05 Test Loss 0.0001851232780154837\n",
      "2439 Train Loss 4.830962e-05 Test Loss 0.00018399783765893216\n",
      "2440 Train Loss 4.8348338e-05 Test Loss 0.0001861624446173893\n",
      "2441 Train Loss 4.8301677e-05 Test Loss 0.00018466478503434303\n",
      "2442 Train Loss 4.829811e-05 Test Loss 0.00018697364168577014\n",
      "2443 Train Loss 4.8251153e-05 Test Loss 0.00018584220921531884\n",
      "2444 Train Loss 4.8214588e-05 Test Loss 0.0001877578709786076\n",
      "2445 Train Loss 4.8167796e-05 Test Loss 0.00018845228816820924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2446 Train Loss 4.8114765e-05 Test Loss 0.0001889410586406442\n",
      "2447 Train Loss 4.80719e-05 Test Loss 0.00018956252325257113\n",
      "2448 Train Loss 4.801926e-05 Test Loss 0.00018691459641786767\n",
      "2449 Train Loss 5.0350212e-05 Test Loss 0.00019448816992367993\n",
      "2450 Train Loss 4.798046e-05 Test Loss 0.00018776263894626933\n",
      "2451 Train Loss 4.7910824e-05 Test Loss 0.0001862521568714511\n",
      "2452 Train Loss 4.7787427e-05 Test Loss 0.0001836191423777291\n",
      "2453 Train Loss 4.7746038e-05 Test Loss 0.00018518944037706407\n",
      "2454 Train Loss 4.7704365e-05 Test Loss 0.00018617295949059656\n",
      "2455 Train Loss 4.7674395e-05 Test Loss 0.0001862202470369852\n",
      "2456 Train Loss 4.7651534e-05 Test Loss 0.00018562649695544025\n",
      "2457 Train Loss 4.7634792e-05 Test Loss 0.00018411461645127732\n",
      "2458 Train Loss 4.7616133e-05 Test Loss 0.00018229112808364892\n",
      "2459 Train Loss 4.7565074e-05 Test Loss 0.00018105785696675161\n",
      "2460 Train Loss 7.085398e-05 Test Loss 0.00017366640008604044\n",
      "2461 Train Loss 4.7553764e-05 Test Loss 0.00018058409863012156\n",
      "2462 Train Loss 4.7481193e-05 Test Loss 0.0001803847643286223\n",
      "2463 Train Loss 4.7450932e-05 Test Loss 0.00018168382459925238\n",
      "2464 Train Loss 4.7408277e-05 Test Loss 0.00018383460712067103\n",
      "2465 Train Loss 4.7372585e-05 Test Loss 0.00018533074667430847\n",
      "2466 Train Loss 4.7335117e-05 Test Loss 0.00018626999544801254\n",
      "2467 Train Loss 4.7283796e-05 Test Loss 0.00018731342822408533\n",
      "2468 Train Loss 4.7197493e-05 Test Loss 0.0001891257533759771\n",
      "2469 Train Loss 4.711889e-05 Test Loss 0.00018893749462590623\n",
      "2470 Train Loss 4.7048074e-05 Test Loss 0.00018960350926828693\n",
      "2471 Train Loss 4.7012243e-05 Test Loss 0.0001889694012710098\n",
      "2472 Train Loss 4.6982062e-05 Test Loss 0.00018558238561252913\n",
      "2473 Train Loss 4.696236e-05 Test Loss 0.00018519883011534327\n",
      "2474 Train Loss 4.6921145e-05 Test Loss 0.00018428060185893128\n",
      "2475 Train Loss 4.688622e-05 Test Loss 0.00018370446037150684\n",
      "2476 Train Loss 4.6832993e-05 Test Loss 0.0001840801802058738\n",
      "2477 Train Loss 4.675286e-05 Test Loss 0.00018451579605623924\n",
      "2478 Train Loss 4.7296966e-05 Test Loss 0.00018684289765585337\n",
      "2479 Train Loss 4.672749e-05 Test Loss 0.00018492456217264063\n",
      "2480 Train Loss 4.6600257e-05 Test Loss 0.0001829884094894129\n",
      "2481 Train Loss 4.6511348e-05 Test Loss 0.00018178366361515141\n",
      "2482 Train Loss 4.6353263e-05 Test Loss 0.00017780612627849967\n",
      "2483 Train Loss 4.6262463e-05 Test Loss 0.00017492113286636825\n",
      "2484 Train Loss 4.6158522e-05 Test Loss 0.00017429444632773998\n",
      "2485 Train Loss 4.604738e-05 Test Loss 0.00017403666585883178\n",
      "2486 Train Loss 4.590121e-05 Test Loss 0.00017598273758164795\n",
      "2487 Train Loss 4.5803205e-05 Test Loss 0.00017720993750638164\n",
      "2488 Train Loss 4.5726345e-05 Test Loss 0.00017833868152219176\n",
      "2489 Train Loss 4.5651752e-05 Test Loss 0.00017956518084632857\n",
      "2490 Train Loss 4.5557415e-05 Test Loss 0.00017973755768722647\n",
      "2491 Train Loss 4.5516972e-05 Test Loss 0.00018170430896597404\n",
      "2492 Train Loss 4.5456225e-05 Test Loss 0.00017674805743373706\n",
      "2493 Train Loss 4.52206e-05 Test Loss 0.00017843519691567507\n",
      "2494 Train Loss 4.5026973e-05 Test Loss 0.00017989743206831075\n",
      "2495 Train Loss 4.476911e-05 Test Loss 0.00018325635520693488\n",
      "2496 Train Loss 4.4710665e-05 Test Loss 0.00018216210000278533\n",
      "2497 Train Loss 4.4581626e-05 Test Loss 0.00018531587368632503\n",
      "2498 Train Loss 4.4522516e-05 Test Loss 0.00018499877593597405\n",
      "2499 Train Loss 4.44222e-05 Test Loss 0.0001855794439057691\n",
      "2500 Train Loss 4.4254004e-05 Test Loss 0.00018921397526439166\n",
      "2501 Train Loss 4.415975e-05 Test Loss 0.00019276099067063728\n",
      "2502 Train Loss 4.407427e-05 Test Loss 0.00019499227920554606\n",
      "2503 Train Loss 4.3998418e-05 Test Loss 0.000197713455379972\n",
      "2504 Train Loss 4.3960696e-05 Test Loss 0.00019874619736999033\n",
      "2505 Train Loss 4.3919354e-05 Test Loss 0.00019783365419363645\n",
      "2506 Train Loss 4.3886408e-05 Test Loss 0.0001980754444376746\n",
      "2507 Train Loss 4.3856424e-05 Test Loss 0.00019796272327338458\n",
      "2508 Train Loss 4.3769363e-05 Test Loss 0.0001960922596331999\n",
      "2509 Train Loss 4.4377655e-05 Test Loss 0.00020957555847683486\n",
      "2510 Train Loss 4.3758824e-05 Test Loss 0.00019733614213638458\n",
      "2511 Train Loss 4.3704382e-05 Test Loss 0.00019328927817947604\n",
      "2512 Train Loss 4.3643842e-05 Test Loss 0.0001924389208784931\n",
      "2513 Train Loss 4.3587715e-05 Test Loss 0.0001898212764013931\n",
      "2514 Train Loss 4.3523167e-05 Test Loss 0.00019150380014079516\n",
      "2515 Train Loss 4.3458513e-05 Test Loss 0.00019362929521236357\n",
      "2516 Train Loss 4.3391974e-05 Test Loss 0.00019539517945687445\n",
      "2517 Train Loss 4.3279117e-05 Test Loss 0.00019940227351969\n",
      "2518 Train Loss 4.3238284e-05 Test Loss 0.00020319866238681364\n",
      "2519 Train Loss 4.3112115e-05 Test Loss 0.00020360587919553627\n",
      "2520 Train Loss 4.306794e-05 Test Loss 0.0002049764506530069\n",
      "2521 Train Loss 4.301025e-05 Test Loss 0.00020883433790326713\n",
      "2522 Train Loss 4.2958207e-05 Test Loss 0.0002107070668184142\n",
      "2523 Train Loss 4.2904132e-05 Test Loss 0.00021346054359588313\n",
      "2524 Train Loss 4.2831518e-05 Test Loss 0.00021607558531336647\n",
      "2525 Train Loss 4.297241e-05 Test Loss 0.0002106014307716512\n",
      "2526 Train Loss 4.2806078e-05 Test Loss 0.000214520320385141\n",
      "2527 Train Loss 4.2755426e-05 Test Loss 0.00021989158914465157\n",
      "2528 Train Loss 4.266287e-05 Test Loss 0.00021623832121761205\n",
      "2529 Train Loss 4.2613497e-05 Test Loss 0.00021339299977256258\n",
      "2530 Train Loss 4.2544758e-05 Test Loss 0.00021341326994454079\n",
      "2531 Train Loss 4.2417378e-05 Test Loss 0.0002140178029912363\n",
      "2532 Train Loss 4.2410724e-05 Test Loss 0.00022047062977995777\n",
      "2533 Train Loss 4.2356332e-05 Test Loss 0.00021728601385635372\n",
      "2534 Train Loss 4.2260413e-05 Test Loss 0.00021840499164736178\n",
      "2535 Train Loss 4.217271e-05 Test Loss 0.0002199135732896054\n",
      "2536 Train Loss 4.209955e-05 Test Loss 0.0002238944457625317\n",
      "2537 Train Loss 4.2021224e-05 Test Loss 0.0002286621142140072\n",
      "2538 Train Loss 4.2039403e-05 Test Loss 0.00023668130956433213\n",
      "2539 Train Loss 4.19914e-05 Test Loss 0.00023230319084920382\n",
      "2540 Train Loss 4.1950916e-05 Test Loss 0.00023603247668232196\n",
      "2541 Train Loss 4.192179e-05 Test Loss 0.0002366844804692761\n",
      "2542 Train Loss 4.188893e-05 Test Loss 0.00023545471268398945\n",
      "2543 Train Loss 4.1856332e-05 Test Loss 0.000234800247278182\n",
      "2544 Train Loss 4.182799e-05 Test Loss 0.00023024780910720086\n",
      "2545 Train Loss 4.1773743e-05 Test Loss 0.00023173151264816903\n",
      "2546 Train Loss 4.172699e-05 Test Loss 0.00023114546171610858\n",
      "2547 Train Loss 4.1659696e-05 Test Loss 0.00023491810311235877\n",
      "2548 Train Loss 4.1643794e-05 Test Loss 0.00022936148974026234\n",
      "2549 Train Loss 4.1560277e-05 Test Loss 0.00023338813929793723\n",
      "2550 Train Loss 4.1503514e-05 Test Loss 0.0002356713162384139\n",
      "2551 Train Loss 4.1389918e-05 Test Loss 0.0002353259218252447\n",
      "2552 Train Loss 4.1277755e-05 Test Loss 0.0002323093256316019\n",
      "2553 Train Loss 4.118978e-05 Test Loss 0.00022467519568181334\n",
      "2554 Train Loss 4.1150444e-05 Test Loss 0.00022005349966977051\n",
      "2555 Train Loss 4.1107487e-05 Test Loss 0.00021887869096501983\n",
      "2556 Train Loss 4.1074338e-05 Test Loss 0.00021946163274491387\n",
      "2557 Train Loss 4.1042185e-05 Test Loss 0.00022000371585131892\n",
      "2558 Train Loss 4.099618e-05 Test Loss 0.00022263044610644522\n",
      "2559 Train Loss 4.0910694e-05 Test Loss 0.00022576594975177322\n",
      "2560 Train Loss 4.084222e-05 Test Loss 0.00022877589736120424\n",
      "2561 Train Loss 4.0788735e-05 Test Loss 0.00022854281264271515\n",
      "2562 Train Loss 4.0723986e-05 Test Loss 0.00022792052340423624\n",
      "2563 Train Loss 4.065027e-05 Test Loss 0.00022592945412906246\n",
      "2564 Train Loss 4.058964e-05 Test Loss 0.00022446791298396212\n",
      "2565 Train Loss 4.050182e-05 Test Loss 0.00022400700569866758\n",
      "2566 Train Loss 4.0416064e-05 Test Loss 0.00022341020219193575\n",
      "2567 Train Loss 4.036885e-05 Test Loss 0.00022125618907794297\n",
      "2568 Train Loss 4.0341187e-05 Test Loss 0.000219766559498559\n",
      "2569 Train Loss 4.0312378e-05 Test Loss 0.00022198629040499066\n",
      "2570 Train Loss 4.0287145e-05 Test Loss 0.00022398022113560785\n",
      "2571 Train Loss 4.026649e-05 Test Loss 0.00022523150954622273\n",
      "2572 Train Loss 4.0241088e-05 Test Loss 0.00022574053333493133\n",
      "2573 Train Loss 4.0249648e-05 Test Loss 0.00022615419832186165\n",
      "2574 Train Loss 4.0216306e-05 Test Loss 0.00022592873093912332\n",
      "2575 Train Loss 4.01925e-05 Test Loss 0.00022471966424468442\n",
      "2576 Train Loss 4.013755e-05 Test Loss 0.00022088955619881538\n",
      "2577 Train Loss 4.011002e-05 Test Loss 0.00021888033062454664\n",
      "2578 Train Loss 4.0083483e-05 Test Loss 0.00022063795359083713\n",
      "2579 Train Loss 4.005303e-05 Test Loss 0.00022094004874341402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2580 Train Loss 4.000988e-05 Test Loss 0.00022202881175936064\n",
      "2581 Train Loss 4.0176332e-05 Test Loss 0.00022582364143846595\n",
      "2582 Train Loss 3.999446e-05 Test Loss 0.00022287615932677405\n",
      "2583 Train Loss 3.9965278e-05 Test Loss 0.00022258712263008\n",
      "2584 Train Loss 3.9935883e-05 Test Loss 0.00022266362395423074\n",
      "2585 Train Loss 3.9887458e-05 Test Loss 0.00022268723957691216\n",
      "2586 Train Loss 3.9810446e-05 Test Loss 0.0002226471126021786\n",
      "2587 Train Loss 3.966855e-05 Test Loss 0.00022334310236311796\n",
      "2588 Train Loss 3.95249e-05 Test Loss 0.00022371251295653027\n",
      "2589 Train Loss 3.947267e-05 Test Loss 0.00022654825198634585\n",
      "2590 Train Loss 3.940407e-05 Test Loss 0.0002268463160360385\n",
      "2591 Train Loss 3.9358492e-05 Test Loss 0.00022680561619166492\n",
      "2592 Train Loss 3.932034e-05 Test Loss 0.0002272056656566619\n",
      "2593 Train Loss 3.927669e-05 Test Loss 0.00022855320786666525\n",
      "2594 Train Loss 3.921173e-05 Test Loss 0.0002303968130184194\n",
      "2595 Train Loss 3.9203136e-05 Test Loss 0.00022493424178145872\n",
      "2596 Train Loss 3.935009e-05 Test Loss 0.00024055033772234187\n",
      "2597 Train Loss 3.9167026e-05 Test Loss 0.00022959106424024343\n",
      "2598 Train Loss 3.9114762e-05 Test Loss 0.00023003789783643174\n",
      "2599 Train Loss 3.904539e-05 Test Loss 0.0002293059679347844\n",
      "2600 Train Loss 3.8957638e-05 Test Loss 0.00022731454337489846\n",
      "2601 Train Loss 3.887927e-05 Test Loss 0.00022459430888212\n",
      "2602 Train Loss 3.8833496e-05 Test Loss 0.0002209796204927876\n",
      "2603 Train Loss 3.8796745e-05 Test Loss 0.00022017529120046915\n",
      "2604 Train Loss 3.8759445e-05 Test Loss 0.00021976007025421317\n",
      "2605 Train Loss 3.871836e-05 Test Loss 0.00021968898434947858\n",
      "2606 Train Loss 3.9624363e-05 Test Loss 0.00020009030941522992\n",
      "2607 Train Loss 3.8699825e-05 Test Loss 0.00021701764677807368\n",
      "2608 Train Loss 3.8656188e-05 Test Loss 0.0002166022164097904\n",
      "2609 Train Loss 4.031355e-05 Test Loss 0.0001996460236689932\n",
      "2610 Train Loss 3.8638387e-05 Test Loss 0.00021487398903695599\n",
      "2611 Train Loss 3.8576705e-05 Test Loss 0.00021407475152241951\n",
      "2612 Train Loss 3.8809776e-05 Test Loss 0.00020446365697933733\n",
      "2613 Train Loss 3.85424e-05 Test Loss 0.00021148082681450776\n",
      "2614 Train Loss 3.848583e-05 Test Loss 0.00021116231561591744\n",
      "2615 Train Loss 3.844349e-05 Test Loss 0.00021250388355330822\n",
      "2616 Train Loss 3.8381942e-05 Test Loss 0.0002152471080801982\n",
      "2617 Train Loss 3.877873e-05 Test Loss 0.0002146138548908122\n",
      "2618 Train Loss 3.836906e-05 Test Loss 0.00021515268783173545\n",
      "2619 Train Loss 3.8360333e-05 Test Loss 0.0002149783390013993\n",
      "2620 Train Loss 3.830522e-05 Test Loss 0.0002150566671356796\n",
      "2621 Train Loss 3.82672e-05 Test Loss 0.00021347801277580084\n",
      "2622 Train Loss 3.8197195e-05 Test Loss 0.00020751198738976125\n",
      "2623 Train Loss 3.8155136e-05 Test Loss 0.000207784921602296\n",
      "2624 Train Loss 3.8115828e-05 Test Loss 0.00020533305356050844\n",
      "2625 Train Loss 3.8070943e-05 Test Loss 0.0002004540237661097\n",
      "2626 Train Loss 3.804888e-05 Test Loss 0.00019742142008139668\n",
      "2627 Train Loss 3.8028178e-05 Test Loss 0.00019576956244482117\n",
      "2628 Train Loss 3.8001413e-05 Test Loss 0.00019554934811199452\n",
      "2629 Train Loss 3.8113605e-05 Test Loss 0.0001942280077262851\n",
      "2630 Train Loss 3.7989663e-05 Test Loss 0.00019521952528714264\n",
      "2631 Train Loss 3.7965983e-05 Test Loss 0.00019631928902412522\n",
      "2632 Train Loss 3.7927228e-05 Test Loss 0.00019784959827327448\n",
      "2633 Train Loss 3.7914855e-05 Test Loss 0.0002008597928993091\n",
      "2634 Train Loss 3.7876278e-05 Test Loss 0.00020014699859715156\n",
      "2635 Train Loss 3.7831833e-05 Test Loss 0.00019998376436682633\n",
      "2636 Train Loss 3.779007e-05 Test Loss 0.00019964625345727935\n",
      "2637 Train Loss 3.7746595e-05 Test Loss 0.00019988077824216127\n",
      "2638 Train Loss 3.7698894e-05 Test Loss 0.0001993180569222068\n",
      "2639 Train Loss 3.764856e-05 Test Loss 0.00019958665729609065\n",
      "2640 Train Loss 3.7613194e-05 Test Loss 0.00020099152564504778\n",
      "2641 Train Loss 3.7687187e-05 Test Loss 0.00021265741553838644\n",
      "2642 Train Loss 3.7593938e-05 Test Loss 0.00020444932031259044\n",
      "2643 Train Loss 3.8520215e-05 Test Loss 0.0002166306397474798\n",
      "2644 Train Loss 3.754443e-05 Test Loss 0.00020671537901008054\n",
      "2645 Train Loss 3.7476086e-05 Test Loss 0.00020879940186668806\n",
      "2646 Train Loss 3.7399062e-05 Test Loss 0.00021066917752120149\n",
      "2647 Train Loss 3.7297403e-05 Test Loss 0.00020986630456982364\n",
      "2648 Train Loss 3.7193156e-05 Test Loss 0.0002086241736841489\n",
      "2649 Train Loss 3.707e-05 Test Loss 0.00020483583403741495\n",
      "2650 Train Loss 3.701987e-05 Test Loss 0.0002048010394059798\n",
      "2651 Train Loss 3.6961676e-05 Test Loss 0.0002031845897560318\n",
      "2652 Train Loss 3.69123e-05 Test Loss 0.00020058318966854023\n",
      "2653 Train Loss 3.7556885e-05 Test Loss 0.00021222632317162548\n",
      "2654 Train Loss 3.6901423e-05 Test Loss 0.0002019222810020272\n",
      "2655 Train Loss 3.6882368e-05 Test Loss 0.00020439861864156712\n",
      "2656 Train Loss 3.6857593e-05 Test Loss 0.00020587955698845095\n",
      "2657 Train Loss 3.6837253e-05 Test Loss 0.0002059700639515862\n",
      "2658 Train Loss 3.6792197e-05 Test Loss 0.00019927510763310464\n",
      "2659 Train Loss 3.673273e-05 Test Loss 0.00019941023635434925\n",
      "2660 Train Loss 3.666909e-05 Test Loss 0.00019895040488271005\n",
      "2661 Train Loss 3.661359e-05 Test Loss 0.00019949208913941152\n",
      "2662 Train Loss 3.6549554e-05 Test Loss 0.00020142663646803867\n",
      "2663 Train Loss 3.6453406e-05 Test Loss 0.00020423467165223567\n",
      "2664 Train Loss 3.630184e-05 Test Loss 0.0002090509763567309\n",
      "2665 Train Loss 3.654473e-05 Test Loss 0.00020319171762510965\n",
      "2666 Train Loss 3.6268415e-05 Test Loss 0.00020733212088006509\n",
      "2667 Train Loss 3.623379e-05 Test Loss 0.00020681756345416455\n",
      "2668 Train Loss 3.618572e-05 Test Loss 0.00021272816432003818\n",
      "2669 Train Loss 3.6120957e-05 Test Loss 0.00020885958174007304\n",
      "2670 Train Loss 3.6092508e-05 Test Loss 0.00020762933145702218\n",
      "2671 Train Loss 3.611325e-05 Test Loss 0.00020275338502287016\n",
      "2672 Train Loss 3.6065674e-05 Test Loss 0.0002054940100615451\n",
      "2673 Train Loss 3.6220914e-05 Test Loss 0.00020039778365482332\n",
      "2674 Train Loss 3.6006088e-05 Test Loss 0.00020353895944476063\n",
      "2675 Train Loss 3.597989e-05 Test Loss 0.00020377436291586616\n",
      "2676 Train Loss 3.5948324e-05 Test Loss 0.00020468289314709565\n",
      "2677 Train Loss 3.5930392e-05 Test Loss 0.00020499562756568233\n",
      "2678 Train Loss 3.590408e-05 Test Loss 0.00020468740284789878\n",
      "2679 Train Loss 3.6176265e-05 Test Loss 0.00019316295793901823\n",
      "2680 Train Loss 3.5899615e-05 Test Loss 0.00020329447639478427\n",
      "2681 Train Loss 3.5877085e-05 Test Loss 0.0002019645160694475\n",
      "2682 Train Loss 3.5855686e-05 Test Loss 0.00019933466885665115\n",
      "2683 Train Loss 3.5828176e-05 Test Loss 0.00019986984635725702\n",
      "2684 Train Loss 3.580175e-05 Test Loss 0.00020104746016768273\n",
      "2685 Train Loss 3.5772333e-05 Test Loss 0.00020238053965744967\n",
      "2686 Train Loss 3.6820093e-05 Test Loss 0.00022783180336042542\n",
      "2687 Train Loss 3.575098e-05 Test Loss 0.00020522647779578786\n",
      "2688 Train Loss 3.570779e-05 Test Loss 0.0002069798689646956\n",
      "2689 Train Loss 3.5643603e-05 Test Loss 0.00020967722331928127\n",
      "2690 Train Loss 3.559374e-05 Test Loss 0.0002123106269097788\n",
      "2691 Train Loss 3.5614277e-05 Test Loss 0.0002125962063911978\n",
      "2692 Train Loss 3.5566496e-05 Test Loss 0.00021242488396384915\n",
      "2693 Train Loss 3.5560774e-05 Test Loss 0.0002170680334090106\n",
      "2694 Train Loss 3.5507444e-05 Test Loss 0.000214795515448404\n",
      "2695 Train Loss 3.5483125e-05 Test Loss 0.000213869057969865\n",
      "2696 Train Loss 3.5457255e-05 Test Loss 0.00021178037656636526\n",
      "2697 Train Loss 3.544105e-05 Test Loss 0.00021175695864386214\n",
      "2698 Train Loss 3.5396206e-05 Test Loss 0.0002114047493522874\n",
      "2699 Train Loss 3.537868e-05 Test Loss 0.00020804360269179912\n",
      "2700 Train Loss 3.601722e-05 Test Loss 0.0001912669951949655\n",
      "2701 Train Loss 3.5368153e-05 Test Loss 0.00020607511988025073\n",
      "2702 Train Loss 3.5346915e-05 Test Loss 0.00020621690004439506\n",
      "2703 Train Loss 3.533666e-05 Test Loss 0.0002052155959863992\n",
      "2704 Train Loss 3.5314762e-05 Test Loss 0.00020534375998072825\n",
      "2705 Train Loss 3.5303077e-05 Test Loss 0.00020553313893750924\n",
      "2706 Train Loss 3.528103e-05 Test Loss 0.00020596394654907906\n",
      "2707 Train Loss 3.5262496e-05 Test Loss 0.00020657286485921511\n",
      "2708 Train Loss 3.5245437e-05 Test Loss 0.0002067118827677872\n",
      "2709 Train Loss 3.523548e-05 Test Loss 0.00020637293479665547\n",
      "2710 Train Loss 3.5222285e-05 Test Loss 0.00020550436670792072\n",
      "2711 Train Loss 3.5272336e-05 Test Loss 0.0002065205511884698\n",
      "2712 Train Loss 3.521988e-05 Test Loss 0.0002057164469390771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2713 Train Loss 3.519253e-05 Test Loss 0.00020314887823253685\n",
      "2714 Train Loss 3.5174446e-05 Test Loss 0.00020305063742432597\n",
      "2715 Train Loss 3.5153284e-05 Test Loss 0.00020295433579730685\n",
      "2716 Train Loss 3.5139215e-05 Test Loss 0.0002026249556433762\n",
      "2717 Train Loss 3.5107445e-05 Test Loss 0.00020240341119230122\n",
      "2718 Train Loss 3.5072677e-05 Test Loss 0.00020117715586781906\n",
      "2719 Train Loss 3.5031448e-05 Test Loss 0.00019690897464263033\n",
      "2720 Train Loss 3.500773e-05 Test Loss 0.00019636228672797917\n",
      "2721 Train Loss 3.498977e-05 Test Loss 0.00019561099199191974\n",
      "2722 Train Loss 3.498297e-05 Test Loss 0.00019632399143527354\n",
      "2723 Train Loss 3.497146e-05 Test Loss 0.00019740106271959576\n",
      "2724 Train Loss 3.4967714e-05 Test Loss 0.00019962943148129603\n",
      "2725 Train Loss 3.5266217e-05 Test Loss 0.00020710757281531728\n",
      "2726 Train Loss 3.4962526e-05 Test Loss 0.000200546335881751\n",
      "2727 Train Loss 3.4952554e-05 Test Loss 0.00019993962409493388\n",
      "2728 Train Loss 3.4928176e-05 Test Loss 0.00019943419271610503\n",
      "2729 Train Loss 3.4905526e-05 Test Loss 0.00020019593184116322\n",
      "2730 Train Loss 3.4880726e-05 Test Loss 0.00020149044513933668\n",
      "2731 Train Loss 3.4857792e-05 Test Loss 0.00020196638968189147\n",
      "2732 Train Loss 3.4821373e-05 Test Loss 0.00020205514840023134\n",
      "2733 Train Loss 3.4794237e-05 Test Loss 0.0002006602967777301\n",
      "2734 Train Loss 3.476685e-05 Test Loss 0.00019854290247730007\n",
      "2735 Train Loss 3.474957e-05 Test Loss 0.00019694402126313053\n",
      "2736 Train Loss 3.4733206e-05 Test Loss 0.00019619175283000764\n",
      "2737 Train Loss 3.4724875e-05 Test Loss 0.00019617237833289086\n",
      "2738 Train Loss 3.4711236e-05 Test Loss 0.00019682989245953722\n",
      "2739 Train Loss 3.4731715e-05 Test Loss 0.00019529742776549044\n",
      "2740 Train Loss 3.470219e-05 Test Loss 0.00019626493360207095\n",
      "2741 Train Loss 3.46858e-05 Test Loss 0.00019549957624711293\n",
      "2742 Train Loss 3.467404e-05 Test Loss 0.00019810593978278871\n",
      "2743 Train Loss 3.4638542e-05 Test Loss 0.00019462544629189876\n",
      "2744 Train Loss 3.4611043e-05 Test Loss 0.0001936799441506969\n",
      "2745 Train Loss 3.456835e-05 Test Loss 0.00019298700979092102\n",
      "2746 Train Loss 3.453903e-05 Test Loss 0.00019455267385693232\n",
      "2747 Train Loss 3.447913e-05 Test Loss 0.00019299842236295009\n",
      "2748 Train Loss 3.44446e-05 Test Loss 0.00019320328870646314\n",
      "2749 Train Loss 3.4414858e-05 Test Loss 0.0001941906749034524\n",
      "2750 Train Loss 3.442075e-05 Test Loss 0.00019151213089556058\n",
      "2751 Train Loss 3.4403987e-05 Test Loss 0.00019298008231671788\n",
      "2752 Train Loss 3.4457255e-05 Test Loss 0.0001951137186517881\n",
      "2753 Train Loss 3.4391276e-05 Test Loss 0.0001936629263909488\n",
      "2754 Train Loss 3.436909e-05 Test Loss 0.00019396611620041356\n",
      "2755 Train Loss 3.4317898e-05 Test Loss 0.00019419407878979372\n",
      "2756 Train Loss 3.4272955e-05 Test Loss 0.00019444338269528297\n",
      "2757 Train Loss 3.4210905e-05 Test Loss 0.00019601482177723472\n",
      "2758 Train Loss 3.4154327e-05 Test Loss 0.00019829320365704158\n",
      "2759 Train Loss 3.4074143e-05 Test Loss 0.00019781208354378442\n",
      "2760 Train Loss 3.4035435e-05 Test Loss 0.00019867165998422654\n",
      "2761 Train Loss 3.398207e-05 Test Loss 0.00019929493636607399\n",
      "2762 Train Loss 3.3957047e-05 Test Loss 0.0001982485025652779\n",
      "2763 Train Loss 3.3902677e-05 Test Loss 0.00019756995536554934\n",
      "2764 Train Loss 3.3846194e-05 Test Loss 0.00019835037906188843\n",
      "2765 Train Loss 3.378375e-05 Test Loss 0.0002023913617429678\n",
      "2766 Train Loss 3.372296e-05 Test Loss 0.00020816527097836535\n",
      "2767 Train Loss 3.3671342e-05 Test Loss 0.00021459133661075124\n",
      "2768 Train Loss 3.3626406e-05 Test Loss 0.00021702312584290326\n",
      "2769 Train Loss 3.359159e-05 Test Loss 0.00021660193770114733\n",
      "2770 Train Loss 3.3552387e-05 Test Loss 0.00021729631399482478\n",
      "2771 Train Loss 3.3525597e-05 Test Loss 0.00021801313931662698\n",
      "2772 Train Loss 3.3516822e-05 Test Loss 0.00022407222106740594\n",
      "2773 Train Loss 3.3584885e-05 Test Loss 0.00021992568722748474\n",
      "2774 Train Loss 3.3485892e-05 Test Loss 0.00022255105044351314\n",
      "2775 Train Loss 3.345178e-05 Test Loss 0.00022094229808483333\n",
      "2776 Train Loss 3.3431043e-05 Test Loss 0.00021976653288178293\n",
      "2777 Train Loss 3.340035e-05 Test Loss 0.00022035550091249439\n",
      "2778 Train Loss 3.338267e-05 Test Loss 0.00022046392019952618\n",
      "2779 Train Loss 3.3356784e-05 Test Loss 0.00022086702009532745\n",
      "2780 Train Loss 3.3338605e-05 Test Loss 0.00022072867720725558\n",
      "2781 Train Loss 3.3322212e-05 Test Loss 0.0002219058149817006\n",
      "2782 Train Loss 3.3297838e-05 Test Loss 0.0002228939967990645\n",
      "2783 Train Loss 3.327753e-05 Test Loss 0.00022308393529164015\n",
      "2784 Train Loss 3.485525e-05 Test Loss 0.00025276141218932233\n",
      "2785 Train Loss 3.3265715e-05 Test Loss 0.0002252902238271685\n",
      "2786 Train Loss 3.3204615e-05 Test Loss 0.00022445206407078954\n",
      "2787 Train Loss 3.311361e-05 Test Loss 0.00022214744781876578\n",
      "2788 Train Loss 3.3220847e-05 Test Loss 0.0002240337226071072\n",
      "2789 Train Loss 3.3084798e-05 Test Loss 0.00022270101621758718\n",
      "2790 Train Loss 3.299945e-05 Test Loss 0.00022004023831522588\n",
      "2791 Train Loss 3.2937052e-05 Test Loss 0.0002204619578561036\n",
      "2792 Train Loss 3.288266e-05 Test Loss 0.0002196179056961777\n",
      "2793 Train Loss 3.2939395e-05 Test Loss 0.00021448572899826477\n",
      "2794 Train Loss 3.2868793e-05 Test Loss 0.00021799226775402164\n",
      "2795 Train Loss 3.284757e-05 Test Loss 0.00021693340857011894\n",
      "2796 Train Loss 3.2821594e-05 Test Loss 0.00021799086867302895\n",
      "2797 Train Loss 3.280244e-05 Test Loss 0.00021720287844202393\n",
      "2798 Train Loss 3.2787535e-05 Test Loss 0.00021682159808449297\n",
      "2799 Train Loss 3.2777032e-05 Test Loss 0.0002144528131424268\n",
      "2800 Train Loss 3.2765645e-05 Test Loss 0.00021919326405283983\n",
      "2801 Train Loss 3.2752367e-05 Test Loss 0.00021881569109730842\n",
      "2802 Train Loss 3.2738564e-05 Test Loss 0.0002183735295063129\n",
      "2803 Train Loss 3.271675e-05 Test Loss 0.00021818256241064784\n",
      "2804 Train Loss 3.2692693e-05 Test Loss 0.00021766966867262344\n",
      "2805 Train Loss 3.2638996e-05 Test Loss 0.0002166657685785274\n",
      "2806 Train Loss 3.2593925e-05 Test Loss 0.00021501756893382333\n",
      "2807 Train Loss 3.2515025e-05 Test Loss 0.00021242431348930977\n",
      "2808 Train Loss 3.2477277e-05 Test Loss 0.00021125338400608412\n",
      "2809 Train Loss 3.2437485e-05 Test Loss 0.000210310405820238\n",
      "2810 Train Loss 3.2401884e-05 Test Loss 0.0002100105491800446\n",
      "2811 Train Loss 3.237708e-05 Test Loss 0.00020909586665083916\n",
      "2812 Train Loss 3.23396e-05 Test Loss 0.0002096198403378689\n",
      "2813 Train Loss 3.230707e-05 Test Loss 0.00021050202092150636\n",
      "2814 Train Loss 3.227499e-05 Test Loss 0.00021118243948948644\n",
      "2815 Train Loss 3.2238233e-05 Test Loss 0.0002107231649848376\n",
      "2816 Train Loss 3.2199165e-05 Test Loss 0.00021152472433864052\n",
      "2817 Train Loss 3.2163152e-05 Test Loss 0.00021081239666503873\n",
      "2818 Train Loss 3.2129832e-05 Test Loss 0.0002092293892342462\n",
      "2819 Train Loss 3.2184325e-05 Test Loss 0.00020005211342584748\n",
      "2820 Train Loss 3.212331e-05 Test Loss 0.0002067899014007538\n",
      "2821 Train Loss 3.2090164e-05 Test Loss 0.00020557054931384506\n",
      "2822 Train Loss 3.206535e-05 Test Loss 0.0002049571522885557\n",
      "2823 Train Loss 3.2049407e-05 Test Loss 0.0002048147066469113\n",
      "2824 Train Loss 3.2031043e-05 Test Loss 0.00020417011952590953\n",
      "2825 Train Loss 3.200721e-05 Test Loss 0.0002037054462219594\n",
      "2826 Train Loss 3.198764e-05 Test Loss 0.00020349332500458532\n",
      "2827 Train Loss 3.1970238e-05 Test Loss 0.00020079116884788576\n",
      "2828 Train Loss 3.193152e-05 Test Loss 0.0002023358878827066\n",
      "2829 Train Loss 3.188417e-05 Test Loss 0.00020420585476185263\n",
      "2830 Train Loss 3.1838652e-05 Test Loss 0.0002059496685876406\n",
      "2831 Train Loss 3.178657e-05 Test Loss 0.00020701834971335542\n",
      "2832 Train Loss 3.1732514e-05 Test Loss 0.00020804813299894788\n",
      "2833 Train Loss 3.165669e-05 Test Loss 0.00020760757762380117\n",
      "2834 Train Loss 3.157942e-05 Test Loss 0.00020734583522801102\n",
      "2835 Train Loss 3.1544325e-05 Test Loss 0.00020792605710571858\n",
      "2836 Train Loss 3.150518e-05 Test Loss 0.00021038543630389663\n",
      "2837 Train Loss 3.1472224e-05 Test Loss 0.00021121945473881584\n",
      "2838 Train Loss 3.1430016e-05 Test Loss 0.00021076920347286207\n",
      "2839 Train Loss 3.138261e-05 Test Loss 0.00021183232309180205\n",
      "2840 Train Loss 3.1311945e-05 Test Loss 0.00021284795431678147\n",
      "2841 Train Loss 3.1262174e-05 Test Loss 0.00021167808492733058\n",
      "2842 Train Loss 3.12215e-05 Test Loss 0.0002106073309724487\n",
      "2843 Train Loss 3.1192198e-05 Test Loss 0.00020958640421019388\n",
      "2844 Train Loss 3.1509608e-05 Test Loss 0.00021151755803190095\n",
      "2845 Train Loss 3.1183983e-05 Test Loss 0.00020985239019052145\n",
      "2846 Train Loss 3.1150783e-05 Test Loss 0.00020927040192580864\n",
      "2847 Train Loss 3.113225e-05 Test Loss 0.0002105298041036103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2848 Train Loss 3.1115756e-05 Test Loss 0.00021169686256056634\n",
      "2849 Train Loss 3.1106705e-05 Test Loss 0.00021208926521487672\n",
      "2850 Train Loss 3.1094834e-05 Test Loss 0.0002119532873863197\n",
      "2851 Train Loss 3.108621e-05 Test Loss 0.00021152612776499872\n",
      "2852 Train Loss 3.10674e-05 Test Loss 0.00020955120698849708\n",
      "2853 Train Loss 3.1048236e-05 Test Loss 0.00020620773857438524\n",
      "2854 Train Loss 3.1015894e-05 Test Loss 0.00020497650678296203\n",
      "2855 Train Loss 3.09741e-05 Test Loss 0.00020318779272158596\n",
      "2856 Train Loss 3.092269e-05 Test Loss 0.00019854238267516433\n",
      "2857 Train Loss 3.0863215e-05 Test Loss 0.0001963531758860321\n",
      "2858 Train Loss 3.0789473e-05 Test Loss 0.00019524052363286586\n",
      "2859 Train Loss 3.0790536e-05 Test Loss 0.00019741760378974582\n",
      "2860 Train Loss 3.076931e-05 Test Loss 0.00019636413928701043\n",
      "2861 Train Loss 3.074251e-05 Test Loss 0.00019914542947003215\n",
      "2862 Train Loss 3.072507e-05 Test Loss 0.00020130485614930783\n",
      "2863 Train Loss 3.0708317e-05 Test Loss 0.00020250984314415632\n",
      "2864 Train Loss 3.067439e-05 Test Loss 0.00020181283161122988\n",
      "2865 Train Loss 3.082834e-05 Test Loss 0.00020818479159869958\n",
      "2866 Train Loss 3.064607e-05 Test Loss 0.00020360211409482738\n",
      "2867 Train Loss 3.0589934e-05 Test Loss 0.00020155861318510405\n",
      "2868 Train Loss 3.0520125e-05 Test Loss 0.00019779051925177438\n",
      "2869 Train Loss 3.0488533e-05 Test Loss 0.00019749658753518199\n",
      "2870 Train Loss 3.0457053e-05 Test Loss 0.00019723552697966637\n",
      "2871 Train Loss 3.042863e-05 Test Loss 0.00019788828309256844\n",
      "2872 Train Loss 3.040371e-05 Test Loss 0.00019874606462019873\n",
      "2873 Train Loss 3.0374998e-05 Test Loss 0.00019815458949805587\n",
      "2874 Train Loss 3.1800337e-05 Test Loss 0.0002234662299427236\n",
      "2875 Train Loss 3.0363453e-05 Test Loss 0.00020003082085270874\n",
      "2876 Train Loss 3.0350977e-05 Test Loss 0.0001993253353668703\n",
      "2877 Train Loss 3.0330595e-05 Test Loss 0.00020037609746387304\n",
      "2878 Train Loss 3.0314612e-05 Test Loss 0.0001989119905113238\n",
      "2879 Train Loss 3.035695e-05 Test Loss 0.00019970194724796438\n",
      "2880 Train Loss 3.0304669e-05 Test Loss 0.00019914864515045168\n",
      "2881 Train Loss 3.0283656e-05 Test Loss 0.0001979981522793094\n",
      "2882 Train Loss 3.0263218e-05 Test Loss 0.00019747743595021803\n",
      "2883 Train Loss 3.0238185e-05 Test Loss 0.00019683717169790736\n",
      "2884 Train Loss 3.0213821e-05 Test Loss 0.00019650707012672082\n",
      "2885 Train Loss 3.018209e-05 Test Loss 0.0001961818169067694\n",
      "2886 Train Loss 3.0154728e-05 Test Loss 0.00019781745866413579\n",
      "2887 Train Loss 3.0133466e-05 Test Loss 0.00019723093855285464\n",
      "2888 Train Loss 3.0107647e-05 Test Loss 0.0001969104640467211\n",
      "2889 Train Loss 3.0085866e-05 Test Loss 0.00019697784552842699\n",
      "2890 Train Loss 3.0081063e-05 Test Loss 0.00019522248536826944\n",
      "2891 Train Loss 3.010288e-05 Test Loss 0.00019843674153421136\n",
      "2892 Train Loss 3.0070258e-05 Test Loss 0.0001963680208102491\n",
      "2893 Train Loss 3.0056572e-05 Test Loss 0.0001969488987104104\n",
      "2894 Train Loss 3.0041636e-05 Test Loss 0.00019707110845059141\n",
      "2895 Train Loss 3.0025909e-05 Test Loss 0.00019673481793343147\n",
      "2896 Train Loss 3.0001727e-05 Test Loss 0.00019539439472718593\n",
      "2897 Train Loss 2.9981988e-05 Test Loss 0.00019471912331002987\n",
      "2898 Train Loss 2.9968469e-05 Test Loss 0.0001938005919582413\n",
      "2899 Train Loss 2.9956122e-05 Test Loss 0.00019324390115020739\n",
      "2900 Train Loss 2.9942668e-05 Test Loss 0.00019192645431033564\n",
      "2901 Train Loss 2.9958657e-05 Test Loss 0.0001904335347929508\n",
      "2902 Train Loss 2.9933413e-05 Test Loss 0.00019134948150707645\n",
      "2903 Train Loss 2.9914534e-05 Test Loss 0.00018983248509215234\n",
      "2904 Train Loss 2.9893547e-05 Test Loss 0.00018777847002619601\n",
      "2905 Train Loss 2.9961087e-05 Test Loss 0.00018498296584962317\n",
      "2906 Train Loss 2.9890336e-05 Test Loss 0.00018728469499329235\n",
      "2907 Train Loss 2.9894545e-05 Test Loss 0.00018339656740175463\n",
      "2908 Train Loss 2.9875093e-05 Test Loss 0.00018543113786308407\n",
      "2909 Train Loss 2.9861312e-05 Test Loss 0.00018544937131251206\n",
      "2910 Train Loss 2.9845705e-05 Test Loss 0.00018560362925768104\n",
      "2911 Train Loss 2.9838931e-05 Test Loss 0.0001858880663580133\n",
      "2912 Train Loss 2.9824449e-05 Test Loss 0.00018619359280132045\n",
      "2913 Train Loss 2.9812452e-05 Test Loss 0.00018639437109940705\n",
      "2914 Train Loss 2.9793257e-05 Test Loss 0.0001862045259112527\n",
      "2915 Train Loss 2.9766263e-05 Test Loss 0.00018590651597957117\n",
      "2916 Train Loss 2.9726158e-05 Test Loss 0.00018729813616924745\n",
      "2917 Train Loss 2.9709556e-05 Test Loss 0.00018372970015117704\n",
      "2918 Train Loss 2.9669085e-05 Test Loss 0.00018656348039826283\n",
      "2919 Train Loss 2.965271e-05 Test Loss 0.000186870692558015\n",
      "2920 Train Loss 2.9639199e-05 Test Loss 0.00018713377930351278\n",
      "2921 Train Loss 2.9628693e-05 Test Loss 0.0001868199526970439\n",
      "2922 Train Loss 2.9615636e-05 Test Loss 0.0001867703671971709\n",
      "2923 Train Loss 2.9605157e-05 Test Loss 0.00018685744688303605\n",
      "2924 Train Loss 2.9595445e-05 Test Loss 0.00018701611670729785\n",
      "2925 Train Loss 2.9677805e-05 Test Loss 0.00018919405805519239\n",
      "2926 Train Loss 2.9594608e-05 Test Loss 0.0001873449071004323\n",
      "2927 Train Loss 2.9596691e-05 Test Loss 0.00018900672325721204\n",
      "2928 Train Loss 2.9579549e-05 Test Loss 0.0001881403518013401\n",
      "2929 Train Loss 2.956178e-05 Test Loss 0.00018860525800621635\n",
      "2930 Train Loss 2.9533778e-05 Test Loss 0.0001895112371661763\n",
      "2931 Train Loss 2.9491119e-05 Test Loss 0.0001924895137466022\n",
      "2932 Train Loss 2.9481595e-05 Test Loss 0.00020303259198987505\n",
      "2933 Train Loss 2.9401472e-05 Test Loss 0.00019940309947356246\n",
      "2934 Train Loss 2.9368226e-05 Test Loss 0.00019906442694132487\n",
      "2935 Train Loss 2.9330751e-05 Test Loss 0.0001998250004129517\n",
      "2936 Train Loss 2.9284549e-05 Test Loss 0.00020088289496526698\n",
      "2937 Train Loss 2.9235001e-05 Test Loss 0.00020232314138594122\n",
      "2938 Train Loss 2.9171828e-05 Test Loss 0.00020367322761140366\n",
      "2939 Train Loss 2.9130213e-05 Test Loss 0.0002039305294426935\n",
      "2940 Train Loss 2.9079734e-05 Test Loss 0.0002019940462390497\n",
      "2941 Train Loss 2.9043693e-05 Test Loss 0.00020074625713494953\n",
      "2942 Train Loss 2.901134e-05 Test Loss 0.00019883022736035504\n",
      "2943 Train Loss 2.8989718e-05 Test Loss 0.0001991185302919106\n",
      "2944 Train Loss 2.89696e-05 Test Loss 0.00020027008981953387\n",
      "2945 Train Loss 2.90842e-05 Test Loss 0.0002040290836755571\n",
      "2946 Train Loss 2.8962646e-05 Test Loss 0.00020096059000444602\n",
      "2947 Train Loss 2.8928673e-05 Test Loss 0.00020586984571597757\n",
      "2948 Train Loss 2.8909435e-05 Test Loss 0.00020704427312563838\n",
      "2949 Train Loss 2.8881539e-05 Test Loss 0.0002092662014959859\n",
      "2950 Train Loss 2.9093982e-05 Test Loss 0.00019957792956983668\n",
      "2951 Train Loss 2.8877705e-05 Test Loss 0.0002079980244666734\n",
      "2952 Train Loss 2.885863e-05 Test Loss 0.000206989391327667\n",
      "2953 Train Loss 2.8809423e-05 Test Loss 0.00020401305315052393\n",
      "2954 Train Loss 2.9365265e-05 Test Loss 0.00020081116328396384\n",
      "2955 Train Loss 2.878172e-05 Test Loss 0.00020340635917919482\n",
      "2956 Train Loss 2.87285e-05 Test Loss 0.00020098433731184203\n",
      "2957 Train Loss 2.8630106e-05 Test Loss 0.00019586903426031522\n",
      "2958 Train Loss 2.85711e-05 Test Loss 0.00019345488451765977\n",
      "2959 Train Loss 2.8469523e-05 Test Loss 0.00019152423914757212\n",
      "2960 Train Loss 2.838526e-05 Test Loss 0.00019161758269211138\n",
      "2961 Train Loss 2.8341241e-05 Test Loss 0.00019276294952884994\n",
      "2962 Train Loss 2.8283946e-05 Test Loss 0.00019421173941430126\n",
      "2963 Train Loss 2.8252061e-05 Test Loss 0.00019442298716061907\n",
      "2964 Train Loss 2.8216751e-05 Test Loss 0.00019420190394617238\n",
      "2965 Train Loss 2.8207773e-05 Test Loss 0.00019366948571874983\n",
      "2966 Train Loss 2.839374e-05 Test Loss 0.0001928488363034427\n",
      "2967 Train Loss 2.8179786e-05 Test Loss 0.00019341207068232808\n",
      "2968 Train Loss 2.8151986e-05 Test Loss 0.00019435982542838248\n",
      "2969 Train Loss 2.8129674e-05 Test Loss 0.00019472652808803288\n",
      "2970 Train Loss 2.8072554e-05 Test Loss 0.00019518598605354755\n",
      "2971 Train Loss 2.800782e-05 Test Loss 0.00019736676358553582\n",
      "2972 Train Loss 2.8107102e-05 Test Loss 0.00019897677638372384\n",
      "2973 Train Loss 2.7981067e-05 Test Loss 0.00019785119586648324\n",
      "2974 Train Loss 2.8059254e-05 Test Loss 0.00019229495844682608\n",
      "2975 Train Loss 2.7965096e-05 Test Loss 0.0001962519244374986\n",
      "2976 Train Loss 2.795396e-05 Test Loss 0.0001933677752407593\n",
      "2977 Train Loss 2.7936152e-05 Test Loss 0.00019450500139125152\n",
      "2978 Train Loss 2.792582e-05 Test Loss 0.0001948748826096238\n",
      "2979 Train Loss 2.7905498e-05 Test Loss 0.00019510989703563846\n",
      "2980 Train Loss 2.7887725e-05 Test Loss 0.0001959651004472615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2981 Train Loss 2.7870643e-05 Test Loss 0.0001967001559521121\n",
      "2982 Train Loss 2.7853832e-05 Test Loss 0.00019734448243898737\n",
      "2983 Train Loss 2.7994447e-05 Test Loss 0.00019558313006487504\n",
      "2984 Train Loss 2.7846272e-05 Test Loss 0.00019701205357777459\n",
      "2985 Train Loss 2.7836522e-05 Test Loss 0.00019845134589261545\n",
      "2986 Train Loss 2.7940509e-05 Test Loss 0.0001978220571518556\n",
      "2987 Train Loss 2.7829892e-05 Test Loss 0.00019833384267757757\n",
      "2988 Train Loss 2.781378e-05 Test Loss 0.0001978500746982404\n",
      "2989 Train Loss 2.7788894e-05 Test Loss 0.00019789433292101535\n",
      "2990 Train Loss 2.777731e-05 Test Loss 0.00019775295457429823\n",
      "2991 Train Loss 2.7771297e-05 Test Loss 0.00019692924510439534\n",
      "2992 Train Loss 2.7749578e-05 Test Loss 0.00019654335701612899\n",
      "2993 Train Loss 2.7739272e-05 Test Loss 0.00019597307955658883\n",
      "2994 Train Loss 2.7723205e-05 Test Loss 0.00019538576567991743\n",
      "2995 Train Loss 2.770825e-05 Test Loss 0.00019461848969414155\n",
      "2996 Train Loss 2.7692138e-05 Test Loss 0.00019421252411679993\n",
      "2997 Train Loss 2.7677845e-05 Test Loss 0.00019402425311116028\n",
      "2998 Train Loss 2.7662736e-05 Test Loss 0.00019424497787490444\n",
      "2999 Train Loss 2.765155e-05 Test Loss 0.00019428763625396728\n",
      "3000 Train Loss 2.764499e-05 Test Loss 0.00019461453761665548\n",
      "3001 Train Loss 2.7637281e-05 Test Loss 0.00019477547979606058\n",
      "3002 Train Loss 2.7628292e-05 Test Loss 0.0001952045324298484\n",
      "3003 Train Loss 2.7645317e-05 Test Loss 0.00019467345946497152\n",
      "3004 Train Loss 2.7622515e-05 Test Loss 0.0001950112582618424\n",
      "3005 Train Loss 2.7605322e-05 Test Loss 0.0001953763918362993\n",
      "3006 Train Loss 2.758102e-05 Test Loss 0.00019350786255663025\n",
      "3007 Train Loss 2.7521946e-05 Test Loss 0.00019044538628401207\n",
      "3008 Train Loss 2.7480677e-05 Test Loss 0.000189335666949146\n",
      "3009 Train Loss 2.7550996e-05 Test Loss 0.00019155612020464944\n",
      "3010 Train Loss 2.7462873e-05 Test Loss 0.00019002086450278227\n",
      "3011 Train Loss 2.7410522e-05 Test Loss 0.0001930319669782459\n",
      "3012 Train Loss 2.7379796e-05 Test Loss 0.00019336082622848012\n",
      "3013 Train Loss 2.7349586e-05 Test Loss 0.00019445827013059156\n",
      "3014 Train Loss 2.73314e-05 Test Loss 0.00019526568411284658\n",
      "3015 Train Loss 2.730915e-05 Test Loss 0.00019525426793841054\n",
      "3016 Train Loss 2.7268648e-05 Test Loss 0.00019426534276361832\n",
      "3017 Train Loss 2.9192157e-05 Test Loss 0.00015960756580664235\n",
      "3018 Train Loss 2.7249194e-05 Test Loss 0.00019020015545581032\n",
      "3019 Train Loss 2.721204e-05 Test Loss 0.00018859120421809247\n",
      "3020 Train Loss 2.7174956e-05 Test Loss 0.00018560699795620774\n",
      "3021 Train Loss 2.7144612e-05 Test Loss 0.00018398163433960886\n",
      "3022 Train Loss 2.707681e-05 Test Loss 0.00018074024984868255\n",
      "3023 Train Loss 2.7001646e-05 Test Loss 0.00017725239803209912\n",
      "3024 Train Loss 2.9144008e-05 Test Loss 0.0001682257037723876\n",
      "3025 Train Loss 2.6964977e-05 Test Loss 0.00017607692949490498\n",
      "3026 Train Loss 2.6902466e-05 Test Loss 0.00017669035424874266\n",
      "3027 Train Loss 2.6837279e-05 Test Loss 0.00017986052895424385\n",
      "3028 Train Loss 2.677674e-05 Test Loss 0.0001818522107166436\n",
      "3029 Train Loss 2.6677459e-05 Test Loss 0.0001833582598195164\n",
      "3030 Train Loss 2.663345e-05 Test Loss 0.00018252278295682555\n",
      "3031 Train Loss 2.6585927e-05 Test Loss 0.00018183468799392436\n",
      "3032 Train Loss 2.6551905e-05 Test Loss 0.0001805055007742711\n",
      "3033 Train Loss 2.6523445e-05 Test Loss 0.00017892852401294262\n",
      "3034 Train Loss 2.6490532e-05 Test Loss 0.00017684136036264135\n",
      "3035 Train Loss 2.6467209e-05 Test Loss 0.0001737515098013036\n",
      "3036 Train Loss 2.6522619e-05 Test Loss 0.00017317999038389155\n",
      "3037 Train Loss 2.6456797e-05 Test Loss 0.0001735529282152416\n",
      "3038 Train Loss 2.6442396e-05 Test Loss 0.00017385120078463646\n",
      "3039 Train Loss 2.6423235e-05 Test Loss 0.00017403950218222817\n",
      "3040 Train Loss 2.6411362e-05 Test Loss 0.00017349739645585675\n",
      "3041 Train Loss 2.6393718e-05 Test Loss 0.00017235539251998902\n",
      "3042 Train Loss 2.6379474e-05 Test Loss 0.00017226158348260018\n",
      "3043 Train Loss 2.635915e-05 Test Loss 0.0001725469298172552\n",
      "3044 Train Loss 2.6340116e-05 Test Loss 0.00017387209524465596\n",
      "3045 Train Loss 2.6315276e-05 Test Loss 0.00017600501013051732\n",
      "3046 Train Loss 2.6289883e-05 Test Loss 0.00017815696103415526\n",
      "3047 Train Loss 2.6261354e-05 Test Loss 0.0001796099329787748\n",
      "3048 Train Loss 2.6238074e-05 Test Loss 0.00017958885917412234\n",
      "3049 Train Loss 2.6220914e-05 Test Loss 0.00017839239125605995\n",
      "3050 Train Loss 2.6205587e-05 Test Loss 0.00017670456073654053\n",
      "3051 Train Loss 2.6194677e-05 Test Loss 0.00017570640153339253\n",
      "3052 Train Loss 2.6183054e-05 Test Loss 0.00017532203878511946\n",
      "3053 Train Loss 2.6168076e-05 Test Loss 0.00017557585943752383\n",
      "3054 Train Loss 2.6151196e-05 Test Loss 0.00017601643262380625\n",
      "3055 Train Loss 2.6133515e-05 Test Loss 0.00017672010674956145\n",
      "3056 Train Loss 2.6114232e-05 Test Loss 0.00017703207884088354\n",
      "3057 Train Loss 2.606654e-05 Test Loss 0.0001781413972081482\n",
      "3058 Train Loss 2.606973e-05 Test Loss 0.00017920279627869432\n",
      "3059 Train Loss 2.6051839e-05 Test Loss 0.00017863539531869842\n",
      "3060 Train Loss 2.6065047e-05 Test Loss 0.00017878785196182506\n",
      "3061 Train Loss 2.6028378e-05 Test Loss 0.0001787037513198063\n",
      "3062 Train Loss 2.6003678e-05 Test Loss 0.00017972816348811485\n",
      "3063 Train Loss 2.5967349e-05 Test Loss 0.0001800386703027776\n",
      "3064 Train Loss 2.5946312e-05 Test Loss 0.00017949005711364387\n",
      "3065 Train Loss 2.5922283e-05 Test Loss 0.00017792787467585828\n",
      "3066 Train Loss 2.5895828e-05 Test Loss 0.0001761304015826088\n",
      "3067 Train Loss 2.5860605e-05 Test Loss 0.00017408419129271563\n",
      "3068 Train Loss 2.5807505e-05 Test Loss 0.0001724160699058248\n",
      "3069 Train Loss 2.5770834e-05 Test Loss 0.00017271668455304641\n",
      "3070 Train Loss 2.8868863e-05 Test Loss 0.0001495934283158077\n",
      "3071 Train Loss 2.5741208e-05 Test Loss 0.0001698340760921728\n",
      "3072 Train Loss 2.5685518e-05 Test Loss 0.00017033270630313093\n",
      "3073 Train Loss 2.5646234e-05 Test Loss 0.00017236640424545373\n",
      "3074 Train Loss 2.5615176e-05 Test Loss 0.00017327972418594706\n",
      "3075 Train Loss 2.5572932e-05 Test Loss 0.00017340160057593447\n",
      "3076 Train Loss 3.0638304e-05 Test Loss 0.00018990754187799057\n",
      "3077 Train Loss 2.5567006e-05 Test Loss 0.00017405812188833462\n",
      "3078 Train Loss 2.5498448e-05 Test Loss 0.00017447936193307453\n",
      "3079 Train Loss 2.5451769e-05 Test Loss 0.00017375173630434539\n",
      "3080 Train Loss 2.5402584e-05 Test Loss 0.00017316803022110716\n",
      "3081 Train Loss 2.5382222e-05 Test Loss 0.0001734533440415746\n",
      "3082 Train Loss 2.5364612e-05 Test Loss 0.00017415871963052395\n",
      "3083 Train Loss 2.535429e-05 Test Loss 0.00017538389047107837\n",
      "3084 Train Loss 2.5344007e-05 Test Loss 0.00017559297601483974\n",
      "3085 Train Loss 2.53344e-05 Test Loss 0.00017633451616113762\n",
      "3086 Train Loss 2.5327023e-05 Test Loss 0.00017683721807354197\n",
      "3087 Train Loss 2.5316203e-05 Test Loss 0.00017784394768093924\n",
      "3088 Train Loss 2.5305322e-05 Test Loss 0.00017778965251996344\n",
      "3089 Train Loss 2.5289188e-05 Test Loss 0.00017847590579487548\n",
      "3090 Train Loss 2.52697e-05 Test Loss 0.00017840190208397158\n",
      "3091 Train Loss 2.5752417e-05 Test Loss 0.0001997025616176124\n",
      "3092 Train Loss 2.5260368e-05 Test Loss 0.000180754298414742\n",
      "3093 Train Loss 2.5245685e-05 Test Loss 0.00018291006510559002\n",
      "3094 Train Loss 2.5205201e-05 Test Loss 0.0001818907556206592\n",
      "3095 Train Loss 2.5182446e-05 Test Loss 0.00018238215988717102\n",
      "3096 Train Loss 2.516234e-05 Test Loss 0.00018356691599791068\n",
      "3097 Train Loss 2.51461e-05 Test Loss 0.00018466799082732482\n",
      "3098 Train Loss 2.5142257e-05 Test Loss 0.0001876684980558447\n",
      "3099 Train Loss 2.5131021e-05 Test Loss 0.00018542176330622016\n",
      "3100 Train Loss 2.5459205e-05 Test Loss 0.00019546859482134655\n",
      "3101 Train Loss 2.5119625e-05 Test Loss 0.00018697574131893623\n",
      "3102 Train Loss 2.5095791e-05 Test Loss 0.00018639501191632893\n",
      "3103 Train Loss 2.5083995e-05 Test Loss 0.00018626992743924398\n",
      "3104 Train Loss 2.5066664e-05 Test Loss 0.00018653704583398601\n",
      "3105 Train Loss 2.505449e-05 Test Loss 0.00018652823453655184\n",
      "3106 Train Loss 2.5031379e-05 Test Loss 0.00018618809129692166\n",
      "3107 Train Loss 2.5012836e-05 Test Loss 0.000186404001629982\n",
      "3108 Train Loss 2.4989684e-05 Test Loss 0.00018705042649325016\n",
      "3109 Train Loss 2.496998e-05 Test Loss 0.00018796513515592292\n",
      "3110 Train Loss 2.4949131e-05 Test Loss 0.0001876026060813369\n",
      "3111 Train Loss 2.4928804e-05 Test Loss 0.00018709913323540454\n",
      "3112 Train Loss 2.4908448e-05 Test Loss 0.0001877244154909342\n",
      "3113 Train Loss 2.489366e-05 Test Loss 0.00018675635284201613\n",
      "3114 Train Loss 2.4878831e-05 Test Loss 0.00018584490080025595\n",
      "3115 Train Loss 2.4848028e-05 Test Loss 0.0001872066094487804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3116 Train Loss 2.4827285e-05 Test Loss 0.0001868026281587081\n",
      "3117 Train Loss 2.480016e-05 Test Loss 0.00018609616236328136\n",
      "3118 Train Loss 2.4759436e-05 Test Loss 0.00018484333208891381\n",
      "3119 Train Loss 2.4714558e-05 Test Loss 0.00018417153768935583\n",
      "3120 Train Loss 2.4664247e-05 Test Loss 0.00018311523035952036\n",
      "3121 Train Loss 2.4628427e-05 Test Loss 0.00018348269999801686\n",
      "3122 Train Loss 2.460511e-05 Test Loss 0.0001840939918116995\n",
      "3123 Train Loss 2.4583584e-05 Test Loss 0.00018540800035197368\n",
      "3124 Train Loss 2.4567364e-05 Test Loss 0.00018530678452951852\n",
      "3125 Train Loss 2.4547688e-05 Test Loss 0.000185151293215867\n",
      "3126 Train Loss 2.4608678e-05 Test Loss 0.00018560391127954537\n",
      "3127 Train Loss 2.4541609e-05 Test Loss 0.00018525128516352923\n",
      "3128 Train Loss 2.455702e-05 Test Loss 0.0001877879013891316\n",
      "3129 Train Loss 2.4528501e-05 Test Loss 0.00018626860449049904\n",
      "3130 Train Loss 2.4511111e-05 Test Loss 0.00018609568842386525\n",
      "3131 Train Loss 2.4486788e-05 Test Loss 0.00018510239287178814\n",
      "3132 Train Loss 2.4469875e-05 Test Loss 0.00018420758375658553\n",
      "3133 Train Loss 2.4436687e-05 Test Loss 0.00018254494623530195\n",
      "3134 Train Loss 2.4388268e-05 Test Loss 0.00017987981510205476\n",
      "3135 Train Loss 2.434157e-05 Test Loss 0.00017864174398759917\n",
      "3136 Train Loss 2.433798e-05 Test Loss 0.00017765642806996418\n",
      "3137 Train Loss 2.4321696e-05 Test Loss 0.00017810589639771855\n",
      "3138 Train Loss 2.4286646e-05 Test Loss 0.00017665593249637513\n",
      "3139 Train Loss 2.4262892e-05 Test Loss 0.00017556550093212684\n",
      "3140 Train Loss 2.4251562e-05 Test Loss 0.00017360290747074934\n",
      "3141 Train Loss 2.4242661e-05 Test Loss 0.00017391549017404653\n",
      "3142 Train Loss 2.4246365e-05 Test Loss 0.00017446815463915583\n",
      "3143 Train Loss 2.42329e-05 Test Loss 0.00017416498931384843\n",
      "3144 Train Loss 2.4219633e-05 Test Loss 0.0001740001571310222\n",
      "3145 Train Loss 2.4199999e-05 Test Loss 0.00017410453619536904\n",
      "3146 Train Loss 2.4182433e-05 Test Loss 0.00017449833122694814\n",
      "3147 Train Loss 2.4160414e-05 Test Loss 0.00017587852074617925\n",
      "3148 Train Loss 2.4138986e-05 Test Loss 0.00017698317968979952\n",
      "3149 Train Loss 2.4107574e-05 Test Loss 0.00017880795533347892\n",
      "3150 Train Loss 2.4320938e-05 Test Loss 0.00017742818936912412\n",
      "3151 Train Loss 2.409931e-05 Test Loss 0.00017860558827223995\n",
      "3152 Train Loss 2.4078721e-05 Test Loss 0.00018014268160868968\n",
      "3153 Train Loss 2.4064379e-05 Test Loss 0.00018086984158280334\n",
      "3154 Train Loss 2.4056173e-05 Test Loss 0.00018129791593830951\n",
      "3155 Train Loss 2.404864e-05 Test Loss 0.0001808444557714994\n",
      "3156 Train Loss 2.4040877e-05 Test Loss 0.00018068874993847056\n",
      "3157 Train Loss 2.4035635e-05 Test Loss 0.0001812502618760132\n",
      "3158 Train Loss 2.4025872e-05 Test Loss 0.00018344303197185795\n",
      "3159 Train Loss 2.4031166e-05 Test Loss 0.00018345971088759087\n",
      "3160 Train Loss 2.40236e-05 Test Loss 0.00018344961983859335\n",
      "3161 Train Loss 2.4017074e-05 Test Loss 0.00018396881813536605\n",
      "3162 Train Loss 2.4006295e-05 Test Loss 0.000184537160677337\n",
      "3163 Train Loss 2.3998222e-05 Test Loss 0.00018544848003430091\n",
      "3164 Train Loss 2.4030787e-05 Test Loss 0.00018346784422405824\n",
      "3165 Train Loss 2.3994722e-05 Test Loss 0.00018492283396199626\n",
      "3166 Train Loss 2.3987413e-05 Test Loss 0.00018473498552505372\n",
      "3167 Train Loss 2.3974027e-05 Test Loss 0.00018448637836745665\n",
      "3168 Train Loss 2.3964738e-05 Test Loss 0.0001853670368135528\n",
      "3169 Train Loss 2.395162e-05 Test Loss 0.0001859659743568711\n",
      "3170 Train Loss 2.3977806e-05 Test Loss 0.00019280327149761702\n",
      "3171 Train Loss 2.3947665e-05 Test Loss 0.00018769935005632008\n",
      "3172 Train Loss 2.3937577e-05 Test Loss 0.00018722746082143953\n",
      "3173 Train Loss 2.3929912e-05 Test Loss 0.0001868766590799352\n",
      "3174 Train Loss 2.3920467e-05 Test Loss 0.00018594403313999117\n",
      "3175 Train Loss 2.3916822e-05 Test Loss 0.00018566732716117265\n",
      "3176 Train Loss 2.39123e-05 Test Loss 0.00018523228755236976\n",
      "3177 Train Loss 2.3905712e-05 Test Loss 0.0001855895794822394\n",
      "3178 Train Loss 2.3899265e-05 Test Loss 0.00018601450302578097\n",
      "3179 Train Loss 2.3900095e-05 Test Loss 0.0001867450701365332\n",
      "3180 Train Loss 2.3897308e-05 Test Loss 0.00018633357620737417\n",
      "3181 Train Loss 2.3886343e-05 Test Loss 0.0001859124056935256\n",
      "3182 Train Loss 2.387574e-05 Test Loss 0.00018606950743601736\n",
      "3183 Train Loss 2.3859866e-05 Test Loss 0.000186361528518758\n",
      "3184 Train Loss 2.385108e-05 Test Loss 0.00018644215516299033\n",
      "3185 Train Loss 2.3882469e-05 Test Loss 0.0001905427111605401\n",
      "3186 Train Loss 2.3847766e-05 Test Loss 0.00018746474063855223\n",
      "3187 Train Loss 2.3840545e-05 Test Loss 0.00018758418607769465\n",
      "3188 Train Loss 2.3829447e-05 Test Loss 0.00018813850420870343\n",
      "3189 Train Loss 2.3817262e-05 Test Loss 0.00018948065281181872\n",
      "3190 Train Loss 2.3803274e-05 Test Loss 0.0001913465831760339\n",
      "3191 Train Loss 2.3790046e-05 Test Loss 0.00019289766814526557\n",
      "3192 Train Loss 2.3778099e-05 Test Loss 0.0001935048170310793\n",
      "3193 Train Loss 2.376721e-05 Test Loss 0.000193589459681737\n",
      "3194 Train Loss 2.3757428e-05 Test Loss 0.00019302887504764237\n",
      "3195 Train Loss 2.374635e-05 Test Loss 0.0001923665108805002\n",
      "3196 Train Loss 2.3733945e-05 Test Loss 0.00019105494302801493\n",
      "3197 Train Loss 2.3719633e-05 Test Loss 0.00019120139399542106\n",
      "3198 Train Loss 2.371601e-05 Test Loss 0.00018770694874666955\n",
      "3199 Train Loss 2.3722203e-05 Test Loss 0.00019087869103839164\n",
      "3200 Train Loss 2.368895e-05 Test Loss 0.00018920332564425005\n",
      "3201 Train Loss 2.3738754e-05 Test Loss 0.000190967782077736\n",
      "3202 Train Loss 2.3680146e-05 Test Loss 0.00018968996273774092\n",
      "3203 Train Loss 2.3667857e-05 Test Loss 0.00019010472143512455\n",
      "3204 Train Loss 2.3654633e-05 Test Loss 0.0001904730125893724\n",
      "3205 Train Loss 2.3636409e-05 Test Loss 0.00019047433859537065\n",
      "3206 Train Loss 2.3613484e-05 Test Loss 0.00018993840316868204\n",
      "3207 Train Loss 2.3586877e-05 Test Loss 0.00018939201996428587\n",
      "3208 Train Loss 2.3557946e-05 Test Loss 0.0001873298547193508\n",
      "3209 Train Loss 2.353371e-05 Test Loss 0.00018566617882636563\n",
      "3210 Train Loss 2.3518649e-05 Test Loss 0.00018272239644670876\n",
      "3211 Train Loss 2.3506633e-05 Test Loss 0.00018279437679238726\n",
      "3212 Train Loss 2.3495897e-05 Test Loss 0.00018316654025868288\n",
      "3213 Train Loss 2.3478806e-05 Test Loss 0.00018277920875193226\n",
      "3214 Train Loss 2.3471024e-05 Test Loss 0.0001820025688839627\n",
      "3215 Train Loss 2.3458597e-05 Test Loss 0.00018116157987017333\n",
      "3216 Train Loss 2.3445447e-05 Test Loss 0.00018038733962834515\n",
      "3217 Train Loss 2.3426124e-05 Test Loss 0.0001796675366396487\n",
      "3218 Train Loss 2.3413053e-05 Test Loss 0.00017965974525363691\n",
      "3219 Train Loss 2.3403016e-05 Test Loss 0.00017974455935755948\n",
      "3220 Train Loss 2.347406e-05 Test Loss 0.0001828373783326602\n",
      "3221 Train Loss 2.3395405e-05 Test Loss 0.0001804240515223151\n",
      "3222 Train Loss 2.3383545e-05 Test Loss 0.0001807483910977089\n",
      "3223 Train Loss 2.3367269e-05 Test Loss 0.0001803192121541515\n",
      "3224 Train Loss 2.3357943e-05 Test Loss 0.00017990596034959334\n",
      "3225 Train Loss 2.3344604e-05 Test Loss 0.00017876060243953806\n",
      "3226 Train Loss 2.3328932e-05 Test Loss 0.00017724275848259523\n",
      "3227 Train Loss 2.332048e-05 Test Loss 0.0001763578260123104\n",
      "3228 Train Loss 2.3310658e-05 Test Loss 0.00017611845823023862\n",
      "3229 Train Loss 2.3298318e-05 Test Loss 0.00017628406143388927\n",
      "3230 Train Loss 2.3287155e-05 Test Loss 0.00017648423183586973\n",
      "3231 Train Loss 2.327784e-05 Test Loss 0.00017701122547665468\n",
      "3232 Train Loss 2.327748e-05 Test Loss 0.00017712325423556617\n",
      "3233 Train Loss 2.3270888e-05 Test Loss 0.0001770674948715735\n",
      "3234 Train Loss 2.3264984e-05 Test Loss 0.00017734607393402293\n",
      "3235 Train Loss 2.3254404e-05 Test Loss 0.0001780640398582003\n",
      "3236 Train Loss 2.3246452e-05 Test Loss 0.00017866967990019358\n",
      "3237 Train Loss 2.3239985e-05 Test Loss 0.0001796350042600706\n",
      "3238 Train Loss 2.3234885e-05 Test Loss 0.0001807349332462781\n",
      "3239 Train Loss 2.3230508e-05 Test Loss 0.00018105611567887484\n",
      "3240 Train Loss 2.3222074e-05 Test Loss 0.00018319663775358424\n",
      "3241 Train Loss 2.3215363e-05 Test Loss 0.0001827610092334116\n",
      "3242 Train Loss 2.3198218e-05 Test Loss 0.0001817274267784075\n",
      "3243 Train Loss 2.3188102e-05 Test Loss 0.00018123355155621004\n",
      "3244 Train Loss 2.3167897e-05 Test Loss 0.00018089363075161414\n",
      "3245 Train Loss 2.3153212e-05 Test Loss 0.00018085538141678512\n",
      "3246 Train Loss 2.3140406e-05 Test Loss 0.00017976631061979268\n",
      "3247 Train Loss 2.310123e-05 Test Loss 0.00018045914122513115\n",
      "3248 Train Loss 2.3086459e-05 Test Loss 0.0001805714981722598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3249 Train Loss 2.3167438e-05 Test Loss 0.00017691952733878347\n",
      "3250 Train Loss 2.308333e-05 Test Loss 0.00017999669910254035\n",
      "3251 Train Loss 2.3360812e-05 Test Loss 0.00018700048599814618\n",
      "3252 Train Loss 2.307308e-05 Test Loss 0.0001812206852657798\n",
      "3253 Train Loss 2.3054525e-05 Test Loss 0.00018288923172639818\n",
      "3254 Train Loss 2.3039021e-05 Test Loss 0.00018189206418736176\n",
      "3255 Train Loss 2.3016264e-05 Test Loss 0.00017915395349659164\n",
      "3256 Train Loss 2.3007971e-05 Test Loss 0.00017909446830714518\n",
      "3257 Train Loss 2.3000128e-05 Test Loss 0.0001794306431410219\n",
      "3258 Train Loss 2.2988404e-05 Test Loss 0.00017966640906406342\n",
      "3259 Train Loss 2.2980508e-05 Test Loss 0.00017970702247865694\n",
      "3260 Train Loss 2.2958564e-05 Test Loss 0.0001800718517036943\n",
      "3261 Train Loss 2.2940196e-05 Test Loss 0.00017944967317090846\n",
      "3262 Train Loss 2.3050075e-05 Test Loss 0.00017568302898965577\n",
      "3263 Train Loss 2.293149e-05 Test Loss 0.00017866397114615345\n",
      "3264 Train Loss 2.2908815e-05 Test Loss 0.00017768443084805924\n",
      "3265 Train Loss 2.2892596e-05 Test Loss 0.0001779913443429512\n",
      "3266 Train Loss 2.2873426e-05 Test Loss 0.0001793033612962584\n",
      "3267 Train Loss 2.3391138e-05 Test Loss 0.00018847116697989213\n",
      "3268 Train Loss 2.2871443e-05 Test Loss 0.00017990119047803569\n",
      "3269 Train Loss 2.2856768e-05 Test Loss 0.0001807807478580707\n",
      "3270 Train Loss 2.2843657e-05 Test Loss 0.00018212500854428122\n",
      "3271 Train Loss 2.2829925e-05 Test Loss 0.00018419113699234574\n",
      "3272 Train Loss 2.281735e-05 Test Loss 0.0001849012254999243\n",
      "3273 Train Loss 2.2812703e-05 Test Loss 0.00018778469030015393\n",
      "3274 Train Loss 2.2817596e-05 Test Loss 0.0001876981476359972\n",
      "3275 Train Loss 2.2793338e-05 Test Loss 0.0001877425141511831\n",
      "3276 Train Loss 2.2778106e-05 Test Loss 0.0001858158917991384\n",
      "3277 Train Loss 2.276502e-05 Test Loss 0.0001840444958742784\n",
      "3278 Train Loss 2.2750322e-05 Test Loss 0.00018315059757612645\n",
      "3279 Train Loss 2.272872e-05 Test Loss 0.0001828589436341292\n",
      "3280 Train Loss 2.2714652e-05 Test Loss 0.0001837684590712212\n",
      "3281 Train Loss 2.2707838e-05 Test Loss 0.00018342497601882155\n",
      "3282 Train Loss 2.2698641e-05 Test Loss 0.00018405004449128734\n",
      "3283 Train Loss 2.2689333e-05 Test Loss 0.00018422076150774133\n",
      "3284 Train Loss 2.2680542e-05 Test Loss 0.0001842514166268641\n",
      "3285 Train Loss 2.2669206e-05 Test Loss 0.00018414618635747906\n",
      "3286 Train Loss 2.2658704e-05 Test Loss 0.00018483872610064355\n",
      "3287 Train Loss 2.265029e-05 Test Loss 0.0001854703252329534\n",
      "3288 Train Loss 2.2642904e-05 Test Loss 0.00018625401519907687\n",
      "3289 Train Loss 2.2635188e-05 Test Loss 0.00018685210468231725\n",
      "3290 Train Loss 2.2626251e-05 Test Loss 0.00018704131862144806\n",
      "3291 Train Loss 2.2613582e-05 Test Loss 0.0001867090655452671\n",
      "3292 Train Loss 2.2602724e-05 Test Loss 0.00018600152751452895\n",
      "3293 Train Loss 2.2594497e-05 Test Loss 0.0001854428689166443\n",
      "3294 Train Loss 2.2586853e-05 Test Loss 0.00018550375627379427\n",
      "3295 Train Loss 2.2589464e-05 Test Loss 0.00018540653503281714\n",
      "3296 Train Loss 2.2582459e-05 Test Loss 0.0001854605888127558\n",
      "3297 Train Loss 2.2804476e-05 Test Loss 0.00019249638652878295\n",
      "3298 Train Loss 2.2575372e-05 Test Loss 0.00018644976457378811\n",
      "3299 Train Loss 2.2567663e-05 Test Loss 0.0001869743294921275\n",
      "3300 Train Loss 2.2553642e-05 Test Loss 0.00018777155327925934\n",
      "3301 Train Loss 2.2535984e-05 Test Loss 0.00018893632096203859\n",
      "3302 Train Loss 2.2524786e-05 Test Loss 0.00018956668361900194\n",
      "3303 Train Loss 2.2510441e-05 Test Loss 0.00018989961803899644\n",
      "3304 Train Loss 2.2493597e-05 Test Loss 0.0001898890052580051\n",
      "3305 Train Loss 2.247453e-05 Test Loss 0.00019070108821949664\n",
      "3306 Train Loss 2.2459135e-05 Test Loss 0.0001888786828064601\n",
      "3307 Train Loss 2.2457665e-05 Test Loss 0.00018701690687199582\n",
      "3308 Train Loss 2.2436927e-05 Test Loss 0.00018778453068672729\n",
      "3309 Train Loss 2.2429356e-05 Test Loss 0.0001881534977555318\n",
      "3310 Train Loss 2.2422686e-05 Test Loss 0.00018801054472325423\n",
      "3311 Train Loss 2.2417902e-05 Test Loss 0.00018774244185171593\n",
      "3312 Train Loss 2.2409924e-05 Test Loss 0.00018735924912269527\n",
      "3313 Train Loss 2.2402299e-05 Test Loss 0.00018732157097979042\n",
      "3314 Train Loss 2.2391276e-05 Test Loss 0.00018737305619863517\n",
      "3315 Train Loss 2.2375334e-05 Test Loss 0.00018796353001324266\n",
      "3316 Train Loss 2.2724744e-05 Test Loss 0.00018284858811812716\n",
      "3317 Train Loss 2.2370356e-05 Test Loss 0.00018736509625682935\n",
      "3318 Train Loss 2.235511e-05 Test Loss 0.0001885105124498368\n",
      "3319 Train Loss 2.2338103e-05 Test Loss 0.000189987512095854\n",
      "3320 Train Loss 2.2325294e-05 Test Loss 0.00019081415860394105\n",
      "3321 Train Loss 2.2318181e-05 Test Loss 0.00019093145885548345\n",
      "3322 Train Loss 2.2308755e-05 Test Loss 0.0001909462469205925\n",
      "3323 Train Loss 2.2305747e-05 Test Loss 0.00019220287002370633\n",
      "3324 Train Loss 2.2861583e-05 Test Loss 0.00018895246425318848\n",
      "3325 Train Loss 2.2294149e-05 Test Loss 0.00019176626637672475\n",
      "3326 Train Loss 2.2281725e-05 Test Loss 0.0001915055822822447\n",
      "3327 Train Loss 2.2260176e-05 Test Loss 0.00019172360553340842\n",
      "3328 Train Loss 2.2241393e-05 Test Loss 0.0001920731244831229\n",
      "3329 Train Loss 2.2215994e-05 Test Loss 0.00019299534530073446\n",
      "3330 Train Loss 2.2195542e-05 Test Loss 0.00019014520200535216\n",
      "3331 Train Loss 2.2178698e-05 Test Loss 0.0001909504286775478\n",
      "3332 Train Loss 2.216853e-05 Test Loss 0.00019126905522396295\n",
      "3333 Train Loss 2.2163344e-05 Test Loss 0.00019104853576316268\n",
      "3334 Train Loss 2.215791e-05 Test Loss 0.00019096629366739432\n",
      "3335 Train Loss 2.2149181e-05 Test Loss 0.00019113297391050874\n",
      "3336 Train Loss 2.2141301e-05 Test Loss 0.00019073494447884574\n",
      "3337 Train Loss 2.2135227e-05 Test Loss 0.00019100751821066926\n"
     ]
    }
   ],
   "source": [
    "max_reps = 1\n",
    "\n",
    "train_loss_full = []\n",
    "test_loss_full = []\n",
    "alpha_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(reps)\n",
    "    N_u = 200 #Total number of data points for 'u'\n",
    "    N_f = 10000 #Total number of collocation points \n",
    "    \n",
    "    X_f_train_np_array, X_u_train_np_array, u_train_np_array = trainingdata(N_u,N_f,reps*43)\n",
    "        \n",
    "    X_f_train = torch.from_numpy(X_f_train_np_array).float().to(device)\n",
    "    X_u_train = torch.from_numpy(X_u_train_np_array).float().to(device)\n",
    "    u_train = torch.from_numpy(u_train_np_array).float().to(device)\n",
    "        \n",
    "    u = torch.from_numpy(u_true).float().to(device)\n",
    "    f_hat = torch.zeros(X_f_train.shape[0],1).to(device)\n",
    "        \n",
    "\n",
    "    X_u_test_tensor = torch.from_numpy(X_u_test).float().to(device)\n",
    "    'Convert to tensor and send to GPU'\n",
    "\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    PINN = Sequentialmodel(layers)\n",
    "       \n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    'L-BFGS Optimizer'\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                                  max_iter = 3000, \n",
    "                                  max_eval = None, \n",
    "                                  tolerance_grad = -1, \n",
    "                                  tolerance_change = -1, \n",
    "                                  history_size = 100, \n",
    "                                  line_search_fn = 'strong_wolfe')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    optimizer.step(PINN.closure)\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(PINN.train_loss)\n",
    "    test_loss_full.append(PINN.test_loss)\n",
    "    elapsed_time[reps] = time.time() - start_time\n",
    "    alpha_full.append(PINN.alpha_val)\n",
    "    \n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_loss\": test_loss_full,\"Time\": elapsed_time, \"alpha\": alpha_full, \"label\": label}\n",
    "savemat(label+'.mat', mdic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f64901a0610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test(X_u_test_tensor)\n",
    "\n",
    "cmap = plt.cm.rainbow\n",
    "plt.imshow(np.transpose(u_pred.reshape(100,256)),cmap = cmap,aspect = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f649010bbd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.cm.rainbow\n",
    "plt.imshow(np.transpose(u_true.reshape(100,256)),cmap = cmap,aspect = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f645efb9ed0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAADOCAYAAADFckL3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnTUlEQVR4nO2df8wtV1nvv8/sffZ5z8uxLRU8np62lns93ptKIpgTxGBuqlwNILHXxFTqDypWj3+UADfcXAr+ocaQcBNEufGmuUdB2kQoDUJoSJWLFaImUssPo9CinkBrT3Pa4qWlrefHPvvdj3/MzDtr1qy1Zs3vNTPPJ3nzzo81a9aePfOZZz+zZoaYGYIgCMK0iIZugCAIgtA+IndBEIQJInIXBEGYICJ3QRCECSJyFwRBmCAid0EQhAnSmdyJ6DVE9I9EdJqIbu9qPYIgCEIR6qKfOxEtAPwTgB8HcAbAgwBuZuaHWl+ZIAiCUKCryP0VAE4z89eZeQ3gbgA3drQuQRAEQWPZUb3HADymjJ8B8EO2wrv0Ir4C13XUFEEQhGlyFl/8V2Z+sWleV3IvhYhOAjgJAJfjWvzK4kFEezRUcwRhlmwX03z8yFxc8lugR23zupL74wCuUcavTqbtw8ynAJwCgKvoBM/lyxCKTFUwwnD0sU+F7qyu5P4ggONE9BLEUn8DgJ/raF2jRsQmCOOkzrHb5wmhE7kz84aI3gzg0wAWAD7IzF/tYl1dIdIVBKFtqnqlycmgs5w7M98H4L6u6m+KyFsQhNAp9dSefdZgF1T7Zkoy3y6GbkF7RI6dUxCE+sxC7qGJfUpybopsi/kgJ/J+mbzchxS7iEsQMvo8HuREMgO5R3vUq+BF6IIwPHWPwymdFCYvdyC74ty15EXsgjBuqh7DIZ8MZiH3lK6j+GhPBC8Ic8LneB/qBDAruQP5fqNdiD79IkXygiAAw50AZid3lS7TNRLFC4LgS5kr6sh/1nJP6SqaV78QEb0gCHWx+kNuYvKnq2heP/OK7AVB6BKRuwX9mQ5dyl5ELwhC24jcPenyQqwpnybCFwShCSL3GnTd4yZeR3GaCF8QBF9E7g3pQ/TZuszTRfpCF4SwX4V8k1DoBCN3VYyhv+HERtd5evt67fNCOECFsAl5H6nTNjkhxAQjd5UpiB7oN6q3t8E+L+SDWuieqX7/Id812idByJ0p+0KKXQbNUhyb9IeK6l347OBTFYAwb1z79VTEH4TcVfSNbs8zs1ZOZN8Fvju6nATGh3THNTMV8Qcjd3WDunY6X9nHZccj/LHI3kaVnV5EEh4iej9M2yZU4QcjdxWb6PV5tjJZ2fEKf+yydyG/BsJGRF8N3wC0b8KQuzPnnh/36f/tvog4zhz+lGVvQy4GD490v61OKLIPQ+4KrqjdZ75exlUuv8y4pG9r1xykD8jF4KGRm+z88XFWFwQnd5UqoreVqVLOvOy4pT8X2ZuQyL9fyo4r2eb9ij5ouau0GbG3cVHEJc2QxD/3CN+GpBv6R35t9cto5K5iy8/byqVUieSanFXHEO2b2jJ34QMi/aGpc9yN6bsZTVqGiB4B8BziR8ZvmPkEEV0J4KMArgPwCICbmPnpZs00U/UnThPZV1mPvc6wo31XG+YufpF+uITSOyU0ohbq+FFmfhkzn0jGbwdwPzMfB3B/Mu6G4y8o/avDdlH9QEuXqbKcukybB/Z2wca/UIj2yPg3d9T9tuk+LAht0kVa5kYANyTDdwL4HIB3VKmg6g0xbRxMddMyXXd7Cj3FIzl9MxLpC0PTVO4M4P8REQP4v8x8CsARZj6bzH8CwBHTgkR0EsBJALgM19buWtVVlNSW7KssW4WxSX/usk+RHjxCXzSV+48w8+NE9F0APkNEX1NnMjMn4i+QnAhOAcBVdIJNNy+FdCA06cLU500NoUpfIvxyJNoX2qSR3Jn58eT/U0T0CQCvAPAkER1l5rNEdBTAUz516Y/HbesGpi5oKush7mAL9VEMEuGXE1KQI4yH2hdUiegFRPQd6TCAnwDwFQD3ArglKXYLgE9WbpTl4p3PxashLnA1vcCqX6Rt+2Ktfb3hXcSVC7bVsO3vcmFXaBK5HwHwCSJK6/kwM/8ZET0I4B4iuhXAowBu8qnM5wUd9oO9KKQmNzQ1oc070Ia6bTmk1E4ILzwZM3Lj0HypLXdm/jqAHzBM//8AXl2pLsrvYLa0TDXpm0XQp/S7En0b9dVrw7D99CWF0w3ylM5pEswdqroIzTuSf0RpuwPTt1dO23nOtqPwEGSvMoT403pF8v0gJ4FxEYzcVarvHH4XC5sKP6vHPs+n7W31zS9b79DCT/GRb5MTQLRHIviAmPojBMZCGHKn8i/XHs3baF/48Tz3WkMRKhBedO9C5DxvmvY4E4qEIXcP6jxawPSy7WLvGn/hx/Oat20oxiR7QXAhvw7KGYXcy1IOtvl+X2azCF9vi6tNoSGyF+bE3H4dhCF3zja87wZta8P3GeGn6wsVkb0gZFR9xlVohCF3BVPEXVX8dcqWf5HNI/x4vnn9ISKyFwQ/QuxJFIzcfSJdn1RL2XPYm9xFWmxjXvhV+uGXCT9dZ0iI7AWhGX3eVBaE3ImB5bq8O5su2LYied/8vGn9+S/LT/a2efrnDz3KF9kLQvu0dY9NEHJPSYWXRdlsFa9N9G2lcOr0RS+2yZx/rxvhm+pS1z00IntB6JYqx1QQcmcCNgeyi5iZ5DPZ66JXh1Wp+kre5yaldqJ5E+1G+HE5e/uGIuQbq6ZCG3f/yj0G0yQIuQPZkxBTkQPIyd4U1af4SD8dNy1jakvVtrsEXzWdk7WxfoSflbW3eQgkum9GF49ykBPENAlC7hwBm1U8nAndLHs1qjeJXiWtwyR+07gPVbpqVrmCbi7bfoSflTe3o29E9tWIf8GG9yjkKm2SE0E/BCF3oBht6+mVTPbFPLYuepPETXX7XqDdOrZStHEvq9ddlj5yy81f9rb5VYWfLedcVWuI7MvxeTx2yJS1WeTfDkHInSNgczAejjbFSFv/n87ThR5PL6ZvfOpzpnA2dsG7xN+U8ui/+tuVqgo/W848vWvpS97eTfardnySt1F3HxXyBCF3wNJjZVmUffpfF182r3h36XJdfDSsS/Smdu1H6BW2mKls+pnU+n0vyPpE+75315bN9z2Yhoj2JbovUuxVNR3ZA8XPI7IvJwi5py/rqNrf3BWRp9OTNewvm4o+rodLBV/I2zskX9b2fSmXbHVX7x99vh/tRPjxuv0Pqr6ifVMKbu7MSfYiejNByD3FJ2+tCzKN7G15+uL//I6gRvW6VG15++3CLPmyk1OlvvclEb5eb3Wp1Tv424iguoz2Jao3E+oL0ttAnudvJii5m/AVvq/si6mcYlSvd8V0iT7XlqXfBVrTZ6iKK51jSt9U7XsfL19+8LcR4efrs8+ru5186p4jIb0rtyki+CLBy12nruwBs9zzefwsX62KXr/wqqeDjH3sS0Tvk8IxLZOrU/mMxvkLu+C7FL6pXBsHXll7fXss+dQ1Z4Z+V25VROpmgpA7sVuEZZSlQtRUjprq0OWe/5+/MKmnb9T6VfGrdZtEb7soWuUzudA/o15n89ROO+mcbL3tHZg+7de/K5F8Nbp+ZWJVROx2gpA70Dwq8y1rk70rok+j+nTcJ6ovu1DrK/kqn832GQEU+uOb0lZtpXPiOupLv8sDVmTePfVTctIFsk2CkDttgeXFeNh2sdJEXSG68tNqzj6lKPt8Tj59oqVJ9IULsXvZZ0w/n6k9dT+r6TMax5ewpnNc9figngyzaf7RnBzk80S+43YJQ+4MLNfmC6FqF8S2ZO8qWyZ7039V9qY+9anYTeLXRW9ro6snTpWTnFXiDtk3zd2bZB9PF+ELQleUyp2IPgjg9QCeYuaXJtOuBPBRANcBeATATcz8NBERgPcDeB2AcwB+iZm/VNoKRe5AXla5YV0qWoTvSn+U4RKnfoE2XZf+3xTVx1Ji6BG8M8K3iL7qdQnfC4ymXzGui7Vl6RufE0DT6N5WXoQvCDE+kfuHAPw+gLuUabcDuJ+Z30NEtyfj7wDwWgDHk78fAnBH8t+J6WUdpaK39FIpi/DryF5fTxXZp2K3dcc0yt4gej3l40rj2D6jLfr3Tcu4+t7XSd8Uad4XW+5kFISYUrkz818S0XXa5BsB3JAM3wngc4jlfiOAu5iZAXyeiK4goqPMfLZsPfozMjJpFIWvDhtPAoYI1xbd10nluC5KqrK35e2Xa/N0U0S/NUi87BeKS+ImTNvENy2j19+m7LtK5wAifWH61M25H1GE/QSAI8nwMQCPKeXOJNOccmdSH/lrf7eo/uiAbNj8PzdNlY6SzjFFwHWj+zLZp//1HH6lqF4dXtpFX6UXjm8ZY/pGT9FY7i9wpYB8MZ3w4+nVu95JhC9MncYXVJmZiajykUFEJwGcBIDL6FpnVJyNm/LZuhA5V486XPivi7RGdG9rbxXZF/P2xXllUb3e88Y3cjdN803f+F5oDblnTtkyIv3p0GX/+xD3k7pyfzJNtxDRUQBPJdMfB3CNUu7qZFoBZj4F4BQAfPfyBNvSDKYINBNA/kYjdVjvi67Xa/xvu6i7NEyzRJ62qNkl+6qiB7JfOjbR564POKTe5JeL7fOahD+k7OPp9Q5sifDHTV83VNVdT5f7U1253wvgFgDvSf5/Upn+ZiK6G/GF1G/75NsBu1BMErVFy2o5W3onlmTxORRqZKyPmyJ8l8BtGE8OFWWfDqt5e2NUr6VvTJ8x1w7LScD1GdRproher78wbEnluOqqQpvClx46Qpv47oN19jGfrpAfQXzx9EVEdAbAbyCW+j1EdCuARwHclBS/D3E3yNOIu0K+qXKLLJSlFMoEkM95m97mVOyjbsp1O6c7Inwbal2FfLzhUQlNL8rqovdN4VSJ5tXPUzav6+je9vnaSufYlhPhh8FUXmZSp/0+vWVutsx6taEsA7itcitawCUjV4SvDuvRvnpCMNWti1RP61S9YKunhCLtM6j5evUk5nNRVh3e//MQvSt9YyqnT3OlbEyfRR/2kb3tBGEa19eTn9ZdOiduiwh/KMb+asI6BHGHateU5ZztqZ38/3TYJX2r+NX/y/wytnaWidbU7dIk+/QeAlf6Jn3NoS56dfu4Iv14fvEAMn0GHzHr63Klclz1+ODaB9p86YUIPwym/Gx7lWDk7nMwVk0N+CxrSuP4RfnmeabPUVX6VVI5++u19MKJxxm69PW26BLfLottdkX2xTbapRXXRblxvQ3OKL5iKsf0q8EV3feRyrEtL7IfhrE95tiHIOSuP/JXRU+v+OIStKmsS6gmUZjq1eVpS5Wo9djEvz9uifJN7U8jWtsz7F1RvS73XG8cg+j19qjCth0o+e1oKkOWsuXiV4dNsm+C67tvOwoU2YdH2Xcw6COOHV4LQu5wyN0VUbuospwr1ZAu75NrNuV29WFd9OqFUbW+qumdXB3L/LArfWOK6reL7Fk/pvRN+YnJ/PA09b+x3ZZuq3Hvpmy6+hlskjfON7ytS11XG3l7/XOn7a+LyD58Qv1OwpA7/KJyW/Rbp+6yyN4kE9P69Oi1rA593PXfJDof6QNFwev12E4ypvXb0jcm0eej7OK9BsZtaOgKmZtvkL4qfF/JF34JVMjbmwSvIrIXQiMIuacPDjPhzoVVX5d+4PuWd01zCT6d5pOr9snn+0T6pv9l7UzTMOq68ustpm+W63z6Rr8om7VBjbyLdxDvt8n1wLfCQ8uy7qx6hO9K56ifUV2+LG+vj9eRfTZdLtIK3ROE3F20nc+qd0JwXxx0Tasy7EpdlEX26bBJ/ubUiXmdupRSienPrE9739hEao/qU9Fnkre9nMXU1sIvrJyM2Sh79XOVib9u3t5H9qbP1LbsbcuL8OdHEHJnAjYHxrPzmaRqm2/CdUJwSd82zdYmW7TvW6etvWrUHP9lUX1aPneBdml4XMKClHElN1/jhSymvDoARJviXcqq+Gy5efU/gNxdxK68vd6msv3AlsrpoquePDtnfgQhd8AulrGuxwfXicHnBOH7S8B2MrJF+3p9vqT1FKL4Ffafs6+nbGLpp+IpisYnnaXOs6ZR9nsRmdM56jRTDt8nb69v7yppHL1N6rR4+Xaje1c9IvxpEIzcy6gjG59lysqUzm/5xSA+P+0BGB9NoJax5Xz19dqEkj8JlItE7Qapf4b9t2wl/9WUTbSnRvVUiOTVtto+V5nw99to2c5phF8W3ReW06L7sry96+RjokreXm93EyTKnwajkHsdSVadXxCGrZthiVhs0XT5PMtLSUrerVqGfkJQBaanb0z5/HgZ92MZdOGZfjGoLC/mUzbpMllEH0t+s+KC4GwnJHW+D+4oXP+8VPhMtkh+fzktldPV+2nVdtrk27X0deZ+EgjlpqdRyN20g9simrL5ddMydaStp0eM/b6XxWXU8modalSbz2FnjxbYRrEU03mbVVbH5gBnZdVyEWf1RMr6I3vPFkAR3TZLa0Tb7MSxvBRPX14iLNfZtNV52pfm6gKwOq8sr0XNxRMJFeYt1zDcoWt61r867C+gfFnzYxX0fbRs3LeM17zSC75lN+GULe+m61Rn2XUYrzpaOO79y1fZtxqW+5p9mWDkXmUHK4tobPNN001R5naRP2DUB4C56tSHU7Ior/ioYb0uXeyq3E3S3i5iaaey36wY651M4usd3pf6hV3G+uAW2wVjfZBx4dAWdGCL1WqL3d09rFZbLJeMF+xssLuzwXKxxe5qg8MHL2G12MMq2sNlBy7icLRGRIzLcAGX8QUsscXu3hqXbc5jZ3MJq709HL54AYfPX0DEW+xeWGP3/EVE2y1W6w1W6w2Wmz1E2y2iLSPa28ZtP7DANooAAOvVEhd2VtgsF9gsIzy/ewjnDq6wjSI8v7ODZw8ewnqxwLnFQTyzPIRztMIaCzzDh/DM3g4ucoRn1wfxzPmDWG8WuHBpgWf/7QDOnV9isyE8//wSl55bYnmJsHM+wmXfiodXFwiHn1lg99uEaI+w+ywlw8DO84TdZ8w9ktaHgPVu/D1sVowLh+PheF76HeSHN6t4OO1MEH9v8Uk1LROfeJPxKPmOD3A8PQI4YkQLRrLZsFzG2zKKgChiRMkJOh2Ph7Np6Xg6LTed9PJKGSU4zS+rXRvQ3uOT1m2bb6rDVs5Vvsry+XIeZVpaX53PVFjmO+31ByF30wuyXZgEqs93RfamHLdJxtZx7TV9pnywKZ0Q/89Hfts9JTpf5supkXqaroiHGWnqIh3OfpZTtnx6UO6l691ieWmBbcRYXmIsLxE2ByJsI8a3zi+wOrhFFDF2dpZYreLh1YEtdg7uYbnYYrlgrA7sYbXcIiLGarmH1SIejoixWuwhWnL8t8NYvnCbbTNLNLNVHznAhC3T/vCGo2x4G+3P22wjbNZx2e2WsN4ssOW43PrSAutNFE+/FGF9KcJmE2GzIVy4sMB6HWG7BRbnF9g9FyHaAqsLUfKLI2lHxFgfyn6JqN/ndhGnlZZrws7zwOpcPH/nuez7We8Szl3O+9cWLhxmrA9xNryTiX69w/GJOoq3xnon+T63wObAdl/s64OZ0BcHtziQSHy5ZCyXvC/odBzA/ncWl0u+pwjJf8ZykZwIiBFRIvnku9wXejIeD+vj9mH1e8+NG4bVfUNf1jRdn2crYytnK1u2jPf8mnXXmfcXjnYEIfeU6rmq8hucfNMzJqGnmHKh6jK2d7K6Inpd4gCSC4667LOTwXKdCTyNCmPJ836vEz3Cj9MsStpGT/UoEYLpV0y0TVMo8fezXMeplWgvFtyB89n0necpt6xar88Ps8UekG4KPc0SDxf3D1dqo05qxIb1l5vhCFqugcPfUttaPwdbJ53Q9TJdlDUFduqUPc+6fFM4XnWVlPGrw30iaKMdNoKRe52H6vuVtV1ksudNyzam6aKh7QQAZDucS/LpcCrzbDwv3+2ymPPN3wFavkMZ89YXNYErjyNI5+nLrA9lPV/ik0rWZnW66aSiYjup6uPZjVSevVlKThBNTwSuMoWylrx43Ty7z3zfMk3Kt1dHGBch26fbz/UJx7xg5J7S9hPYXM/i8M6/G8rpknaNuy54lady7M9Ft5O/mGgSc3oRMovK8/3U0/85aSc3I2X5feVXgdKHPV9Hfnvr29MsyHIBmyReLGOux1WXvU1+0/T2+JQvm+cz37dMlXJtLVde71TFPixByJ3JHkXrNH2jStljaYvl3SKtI3nXBVpb9F+2fnVcfwqkSe4qqZTXhxShK8+JKd5dqqR9tD2o2B6fPvIen8sicH0dZaJuK0LX21RWRxvzuizX1fLmOkXmfRCE3E2YIuZ26rVc2DOI1GdanXyY7zPGbdFpYZ5D4PZcv/mZ7erf/jwt5eO6kG0aduEb5epCaDuNUjYNqCfzNiLyLsp1tby7bpF6nwQn9/KDofoO0rbQ65StE63Z5GQTuN4Gc9SdjBvSKMWUUFHsZZ/F53MU55u/U+8IumY5Z9nAUyt1y7e1rF/9IvMhCULurjcxDSHzOtOr4CsIU87c1SZX1K2/ws9H5sW2lfdW8aGNE13Vss7pkl5pjIg8PIKQO9C9xMvm1VnGRNUD3iXzeNj8ViNTmqUwzXH3q1rONm5rcx3almStZTqQuM983zJ1yra5rF/9IvGxEIzcfWhT5mXzqpRJqRqRm5bRZa72Wdf/GyNvg9BNw1Xa7+qq6EsXEXDbEm9jvm+ZOmXbXLa8bpH42AlO7lVfjOEzr0oZnSYHqmtcPXjUz5zKPJ5ulrr6HyimXPRh07jeHp8eQbbxMroUapcib6uOJuWbLudXt4h8igQjd13qZSLuSuZl1L2op8s8/1gB7A+78uAmoevTTeNpe6oI3Jc2c8Z1Jd5K/R3kvkOLykXi0yDnSsd+Uip3IvoggNcDeIqZX5pM+00Avwrgm0mxdzHzfcm8dwK4NVntW5j502XrMPVzV6kq6bpSryOIsi57WZvM6RXbcJnQ9Xk+dBv9tVPOp5ton6mTPmTe1fciMp8WVR+l7BO5fwjA7wO4S5v+u8z8XnUCEV0P4A0Avh/AVQD+nIi+j5m9d9+ue6M0qcNX5EBR5rZh31RKFbH7plt86FJYbUTj3usKqBuiyFyoSp1n5JfKnZn/koiu86zvRgB3M/NFAN8gotMAXgHgb8oW7CKF4qJ6r5ZykcfDqDRcOs/yDZWlWdRybVNZgi1E41XW21X3wpBkLiKfD3VfftIk5/5mInojgC8AeDszPw3gGIDPK2XOJNMKENFJACcB4DK6tkEzijQ9uMsOHB+ZV5nnmubCp3dLk3oq1VHjrts+y3VZts1l7XWKzOdIk7da1ZX7HQB+G/EjF38bwO8A+OUqFTDzKQCnAOBodKL0E3TTBa/8gCm70FtF6FWmpegvDfGhbbn4irtOG4aWeJNlmiznrlNEPnfaeFVhLbkz85PpMBH9AYBPJaOPA7hGKXp1Mq2Urg6uKgeK68XMvuNVywEVUiwOyVZ9FVkdYRfqCCRq7isib2P5Yn0iciGjzffP1pI7ER1l5rPJ6E8D+EoyfC+ADxPR+xBfUD0O4G+bNNAvF1vvAPHtfllX6FVIP2ftnj4tyNpYb8d56VAj8qbL2usUmQt5unqhuE9XyI8AuAHAi4joDIDfAHADEb0McVrmEQC/BgDM/FUiugfAQwA2AG7z6SnjeraMSlsSz6bbyrczvQ6u7dDXerpYPrTybS9vrlNELhTpSuY6Pr1lbjZM/oCj/LsBvLtug5oeEF3c4dpGH/w2uid2/dyQNtbXh5RF5MJY6EvkJoK5Q7XNB4fF88qWbTY/xTdfri9Td31t0mfKYqgLlpIjF/piSJGbCEbuLnw2WpuPI2gi666i8rYeYFaVsfQ8kRuDhL4ITeI2gpO774brStRAvWhcXbaNNvjU2xZ9yzi0aDyuUyQu5BmLxG0EI/eyDVlFkG3LtM1b+IdIv+ht6GvZrh4D0QYicyFl7BK3EYzcdYaSoAldMG10eWyjLludQ9QTqshF4gIwXYG7CEruIQndRQgP5hpynaGKPK5XZD5n5ihxG0HIveyRv1Vp8+Kk77pCPDGFIPE26ynWKyKfIyJwP4KQe9+09cAtvc6xdWcMuR5z3SLzuSACb84s5W6j8SMAWr5wGsLjevuqq1i3iHwOiMSrUfCK4xgMQu6+jx8A+omO24jCh8ild7X+rj+LiHzaiMCr04bngpB7FUI6CQxN6JG9fR0i8ykiEq9HV64andx9CflCZ1W6uyDZTb3F9YjMp4aIvB59+igYuacCaHunqZti6fMCafdpj27rz9YjEp8aIvF6hBBUBiP3FJsghtjJ2or++8y/97sukfnUEJlXIwSJ2whO7jbqRvah9lppwjA3PonIp4RIvBohS9zGaOQ+R4Y6qYjIp4NIvBpjlLgNkftAhPBrQCQ+LUTk/kxJ4jZGJfcx7bwhyFtHZD4NxnQcDM0cJG5jVHKvQ9u9XkKUto5IfBqIxP2Ys8BdjEbuTXb0MQi5DiLxaSAS90MkXo1RyH3OO78IfBrMeR+uggi8PYKX+9QPCpH3dJj6vtoWIvB+CF7u0R4Ff9CIoOdD6PtiKIjAhyd4uQNFeVY5wES8QlVE4H6IwMMmKitARNcQ0WeJ6CEi+ioRvTWZfiURfYaI/jn5/8JkOhHR/yai00T090T0g603eo+8/wRBZbvg0j8hZrtw/wlhUyp3ABsAb2fm6wG8EsBtRHQ9gNsB3M/MxwHcn4wDwGsBHE/+TgK4o/VWC4IDEbcfIu9pU5qWYeazAM4mw88R0cMAjgG4EcANSbE7AXwOwDuS6XcxMwP4PBFdQURHk3oEoTEiaT9E0POmUs6diK4D8HIADwA4ogj7CQBHkuFjAB5TFjuTTBO5C5UQiZsRaQs+eMudiA4D+BMAb2PmZ4myfDYzMxFVOhKJ6CTitA0ux7VVFhUmhAg8j4hbaAsvuRPRAcRi/2Nm/ngy+ck03UJERwE8lUx/HMA1yuJXJ9NyMPMpAKcA4Co6IUf4xJm7xEXaQt/49JYhAB8A8DAzv0+ZdS+AW5LhWwB8Upn+xqTXzCsBfFvy7fNhbhcyyy5KysVJYSh8IvdXAfhFAP9ARH+XTHsXgPcAuIeIbgXwKICbknn3AXgdgNMAzgF4U5sNFsJhytJOETELY8Wnt8xfA7B1GH+1oTwDuK1hu4TAmJrIRdrC1AnmDtXtguWmo4AYs8xF3PNkiq/UbEIwchexD8vYZC4CHy8hf3dlbRuT/IORu9AfYxF5yBIQ5vn9qJ85dNGL3GdAyDKfoyBCQ76DaSJynyAhylwE0g+ynftjuwg7ehe5T4BQZC5i6QbZrmESstgBkfsoEZlPA9l+QpeI3AMnBJGLhKoh22v6hB61AyL34BhS5iIlP2Q7zZMxCF0lGLnXkdoU+sYPJXMRlB3ZNoLO2MQOBCT3OTCEyEVUdmTbCC7GKHSV0cp9DFF7nzIXUZmR7SJUYexCVxmV3EMWuoh8eGS7CFWZksx1RiH3kKQuEg8D2TZCVaYschNBy31IqfclcZGUH7KdBF/mJnEbwcl9CKF3LXIRU3Vkmwk2RN5+BCP3PqTepcRFRu0g23FeiKi7Ixi5t0kXEhfp9EOXB7t8h9UR+Y6XUcu9bYnLwT9tRFTCnBiN3NsSuQhcEIQ5EKTcm4p8zALvu+0SzQpC+NQ5ToORe1Whj0HgIbZRZC4IYdPWMRqM3G2EKMgQ26QiAheEsOnjGA1O7iGKM7Q2ibwFIWxCOEaDkDtTeAJVsX1RddscwhcvCEI5Yz5WS+VORNcAuAvAEQAM4BQzv5+IfhPArwL4ZlL0Xcx8X7LMOwHcCmAPwFuY+dMdtH1wxvzFC+0wlX0gtOBqKtt1SHwi9w2AtzPzl4joOwB8kYg+k8z7XWZ+r1qYiK4H8AYA3w/gKgB/TkTfx8zydQmlyEE9DLLdp0ep3Jn5LICzyfBzRPQwgGOORW4EcDczXwTwDSI6DeAVAP7GtgBxs50rtKhjyogEBGEcVMq5E9F1AF4O4AEArwLwZiJ6I4AvII7un0Ys/s8ri52B4WRARCcBnASAy3FtnbbvI8IRBEHIE/kWJKLDAP4EwNuY+VkAdwD4jwBehjiy/50qK2bmU8x8gplP7OLFiPao9z9BEISp4hW5E9EBxGL/Y2b+OAAw85PK/D8A8Klk9HEA1yiLX51Mc5LexNSndEMU/FAvzHYR4nYSxk2I+3mf9HFM+fSWIQAfAPAwM79PmX40yccDwE8D+EoyfC+ADxPR+xBfUD0O4G9d61C7Qvp+6U1TMaEKK9R2CUKbyH7ePcTslikR/QiAvwLwDwC2yeR3AbgZcUqGATwC4NdS2RPRrwP4ZcQ9bd7GzH9aso5vAngUwIsA/Gu9jzI5ZFtkyLbIkG2RIdsC+B5mfrFpRqnc+4SIvsDMJ4ZuRwjItsiQbZEh2yJDtoUb7wuqgiAIwngQuQuCIEyQ0OR+augGBIRsiwzZFhmyLTJkWzgIKucuCIIgtENokbsgCILQAkHInYheQ0T/SESniej2odvTJ0R0DRF9logeIqKvEtFbk+lXEtFniOifk/8vHLqtfUFECyL6MhF9Khl/CRE9kOwfHyWi1dBt7AMiuoKIPkZEXyOih4noh+e6XxDRf0+Oj68Q0UeIaGeu+4Uvg8udiBYA/g+A1wK4HsDNyZMl50L61M3rAbwSwG3J578dwP3MfBzA/cn4XHgrgIeV8f+F+Amk3wvgacSPk54D7wfwZ8z8nwH8AOJtMrv9goiOAXgLgBPM/FIAC8RPnp3rfuHF4HJH/MTI08z8dWZeA7gb8ZMlZwEzn2XmLyXDzyE+gI8h3gZ3JsXuBPDfBmlgzxDR1QB+EsAfJuME4McAfCwpMottQUSXA/gviO8OBzOvmfkZzHS/QHw3/SEiWgLYRfw8q9ntF1UIQe7HADymjBufIjkHtKduHlEe7/AE4pelzIHfA/A/kd0N/Z0AnmHmTTI+l/3jJYhfhPNHSYrqD4noBZjhfsHMjwN4L4B/QSz1bwP4Iua5X3gTgtwFGJ+6uQ/HXZom362JiF4P4Clm/uLQbQmAJYAfBHAHM78cwL9BS8HMaL94IeJfLC9B/LyqFwB4zaCNGgEhyL3WUySnhOmpmwCeJKKjyfyjAJ4aqn098ioAP0VEjyBOz/0Y4rzzFcnPcWA++8cZAGeY+YFk/GOIZT/H/eK/AvgGM3+TmS8B+DjifWWO+4U3Icj9QQDHkyvfK8QXSu4duE29YXvqJuJtcEsyfAuAT/bdtr5h5ncy89XMfB3i/eAvmPnnAXwWwM8kxeayLZ4A8BgR/adk0qsBPIQZ7heI0zGvJKLd5HhJt8Xs9osqBHETExG9DnGudQHgg8z87mFb1B+Op24+AOAeANcifmLmTcz8rUEaOQBEdAOA/8HMryei/4A4kr8SwJcB/ELyGsdJQ0QvQ3xheQXg6wDehDggm91+QUS/BeBnEfcu+zKAX0GcY5/dfuFLEHIXBEEQ2iWEtIwgCILQMiJ3QRCECSJyFwRBmCAid0EQhAkichcEQZggIndBEIQJInIXBEGYICJ3QRCECfLvyHanAIxUM1cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.cm.rainbow\n",
    "plt.imshow(np.transpose(np.abs(u_pred - u_true).reshape(100,256)),cmap = cmap,aspect = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00019100751821066926\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2c9903751109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_loss_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "a = 0 \n",
    "for i in range(10):\n",
    "    print(test_loss_full[i][-1])\n",
    "    a = a + test_loss_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
