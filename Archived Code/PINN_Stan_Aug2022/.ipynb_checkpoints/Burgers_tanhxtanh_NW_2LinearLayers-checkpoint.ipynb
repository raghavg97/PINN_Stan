{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('burgers_shock_10sin.mat')\n",
    "label = \"QCRE_2D_5_tanhxtanh_NW\"\n",
    "                     \n",
    "x_test = data['x']                                   # 256 points between -1 and 1 [256x1]\n",
    "t_test = data['t']   \n",
    "usol = data['usol']\n",
    "X_test, T_test = np.meshgrid(x_test,t_test)  \n",
    "\n",
    "xt_test_tensor = torch.from_numpy(np.hstack((X_test.flatten()[:,None], T_test.flatten()[:,None]))).float().to(device)\n",
    "\n",
    "u_true = usol.flatten('F')[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = scipy.io.loadmat('burgers_shock_10sin.mat')  \t# Load data from file\n",
    "\n",
    "pi = torch.from_numpy(np.array(np.pi)).double().to(device)\n",
    "\n",
    "label = \"QCRE_2D_5_tanhxtanh_NW\"\n",
    "# x = data['x']                                   # 256 points between -1 and 1 [256x1]\n",
    "# t = data['t']                                   # 100 time points between 0 and 0.2 [100x1] \n",
    "# usol = data['usol']   \n",
    "\n",
    "#usol = usol/1000# solution of 256x100 grid points\n",
    "\n",
    "x = np.linspace(-1,1,500).reshape(-1,1)\n",
    "t = np.linspace(0,0.2,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "#y_true = true_2D_1(xt)\n",
    "\n",
    "bound_pts_1 = (X==-1).reshape(-1,)\n",
    "xt_bound_1 = xt[bound_pts_1,:]\n",
    "u_bound_1 = np.zeros((np.shape(xt_bound_1)[0],1))\n",
    "\n",
    "bound_pts_2 = (X==1).reshape(-1,)\n",
    "xt_bound_2 = xt[bound_pts_2,:]\n",
    "u_bound_2 = np.zeros((np.shape(xt_bound_2)[0],1))\n",
    "\n",
    "bound_pts_3 = (T==0).reshape(-1,)\n",
    "xt_bound_3 = xt[bound_pts_3,:]\n",
    "u_bound_3 = -10*np.sin(np.pi*xt_bound_3[:,0].reshape(-1,1))\n",
    "#u_bound_3 = -10*np.ones((np.shape(bound_pts_3)[0],1))\n",
    "\n",
    "\n",
    "xt_bound = np.vstack((xt_bound_1,xt_bound_2,xt_bound_3))\n",
    "u_bound = np.vstack((u_bound_1,u_bound_2,u_bound_3))\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fde7c47b610>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwDElEQVR4nO3dd3yV9fn/8deVTQaBkBBGgJCA7DIMKBsVBaxfcVJcgKKIq9a2rlpt9Vc7bK2KaJ11tHUvUFC2VRSEgGzIYAcChL0JSa7fHzl8v0dMIAnnPvcZ1/PxOI+cc9+fc99v7hzOlc+9PqKqGGOMCV8RbgcwxhjjLisExhgT5qwQGGNMmLNCYIwxYc4KgTHGhLkotwPURWpqqmZmZrodwxhjgsqiRYt2qmraydODshBkZmaSm5vrdgxjjAkqIrKxqum2a8gYY8KcFQJjjAlzVgiMMSbMWSEwxpgwZ4XAGGPCnE8KgYj8U0R2iMgKr2kpIjJDRAo8PxtW897RnjYFIjLaF3mMMcbUnK96BK8DQ0+a9gAwS1XbArM8r39ARFKA3wHnAL2A31VXMIwxxjjDJ9cRqOpXIpJ50uThwCDP8zeAL4H7T2ozBJihqrsBRGQGlQXlbV/kMrWz7/Bx8rYfYMvew+w9fJz9R8qIihRioyJISYihZUo8makJpCbGuh3VGONDTl5Qlq6qxZ7n24D0Kto0BzZ7vS7yTPsRERkHjANo2bKlD2OGrwNHj/NlXglfF5TwTeEutuw9UqP3tUipR8/MFAaelcbgDukkxAbldYnGGA+//A9WVRWRMxoBR1VfAl4CyMnJsdF06khVmb9uN+/lbubzFcUcPV5Bcr1o+rZpxKjerTirSRKZjRJoUC+apLgoylU5eryCnQePsWn3YQq3H2TRxj38N6+EjxZvITYqgsEd0hndJ5OemQ0REbf/icaYWnKyEGwXkaaqWiwiTYEdVbTZwv/tPgLIoHIXkvExVWXm6h1MnFPI0s17SYqL4soeGVzevTndWzYkMqLqL/AoIDYqkuR60WSnJXJeu8bcAlRUKIs27eGzpVuZtHQrU5YX06V5Mnec14YhndKtIBgTRMRXQ1V6jhF8pqqdPa//CuxS1T+LyANAiqred9J7UoBFQA/PpMXA2SeOGVQnJydH7V5DNbdk814e/XQl32/aS4uUeowfmM2VPTKIi470yfKPlJbz0fdFvPr1etbtPET3lg34zcUd6JmZ4pPlG2N8Q0QWqWrOj6b7ohCIyNtU/mWfCmyn8kygT4D3gJbARmCEqu4WkRxgvKre7HnvTcBvPIt6XFVfO936rBDUzL4jx3l8yireyy0iLSmWey9qxxU9mhMV6czlI2XlFXy4uIi/z8hn+/5jjOzZggeHdSA5PtqR9RljasfRQuBvVghO78u8HTzw4XJKDh7j5v6tuev8tiT66aDukdJynp6Vzytfr6dhfAxPXNWF89tXda6AMcafqisEdmVxiDleXsEfPlvFmNcWkhQXxce39+HBYR38VgQA6sVE8uCwDky6oy+piTHc9Hou/++zVRwrK/dbBmNMzdl5fyFk+/6j3PnWYhZu2MPo3q148OIOPjsOUBedmyfzyR19+dPU1bw6dz25G3bz0qgc0uvHuZbJGPNj1iMIEau27ufSiXNZuXU/E67pzqPDO7taBE6Ii47k0eGdeeH6synYcZBLJ85lWdFet2MZY7xYIQgBX+WXMOLFeUSI8NHtfbi0azO3I/3I0M5N+PC2PkRFRDDixXnMXLXd7UjGGA8rBEHug0VF3PT6QjIa1uPj2/vSvkl9tyNVq0PT+ky6sy/t0pO49d+L+OT7LW5HMsZghSCovfXdJn79/lLOzWrE++N70yQ58Pe9pybG8p9bzqVXZgq/eHcJb87b4HYkY8KeFYIg9e/5G/nNx8s5r10ar4zOISkueM7VT4yN4rUbe3Jhx3QembSSV+eudzuSMWHNCkEQ+tf8jfz2kxVc0L4xL9xwdkAcFK6tuOhI/nFdD4Z1bsL/+2wVb323ye1IxoQtKwRBZtKSLTz8yQoGd2jM89f3IDYq+IrACVGRETwzsjvntUvjoU+W8/H3RW5HMiYsWSEIIl/ll/Dr95fSq3UKE68N7iJwQkxUBP+4/mx6ZzXi1+8vY4adTWSM31khCBJLN+9l/L8XkZ2WyMujcoJyd1B14qIjeXlUDp2b1efnb39v1xkY42dWCIJA0Z7DjH1jIY0SY3jzpl4k1wueA8M1lRAbxSuje9LIc0uKoj2H3Y5kTNiwQhDgDh0r4+Y3cjlWVsFrY3rROIRvz5CWFMvrN/aktKycm15fyL4jx92OZExYsEIQwCoqlHveXUL+9gNMvLYHbRonuh3JcW0aJ/HCDWezfuchfvHO91RUBN/dcY0JNlYIAtjfZ+QzfdV2fvvTjgw8K83tOH7TJzuVR/6nE3PySnh6Zr7bcYwJeVYIAtSMVduZOKeQn+W04Ma+mW7H8bvrz2nJiJwMJswuZNrKbW7HMSakOVoIRKSdiCzxeuwXkV+c1GaQiOzzavOIk5mCwebdh/nVe0vo3Lw+jw7vFJbj/4oIjw3vTNeMZH713lIKdxx0O5IxIcvRQqCqearaTVW7AWcDh4GPq2j69Yl2qvqYk5kC3bGycu58azEKPH9tcF417Ctx0ZH84/qziY2K4M63FnP0uA1sY4wT/Llr6AJgrapu9OM6g84fp6xmadE+/npVV1o2inc7juuaNajH30Z0Zc22A/xx6mq34xgTkvxZCEYCb1czr7eILBWRz0WkU1UNRGSciOSKSG5JSYlzKV00ZVkxb8zbyM39WjO0cxO34wSM89o15pb+rXlz3ka+WGHHC4zxNb8UAhGJAS4F3q9i9mKglap2BZ4FPqlqGar6kqrmqGpOWlronUFTvO8ID360jG4tGnD/sPZuxwk49w5pz08ykrn/w2Vs2XvE7TjGhBR/9QiGAYtV9Uc3klHV/ap60PN8KhAtIql+yhUQKiqUX7+/lLIK5emfdSM60k7mOllMVAQTRnanrLyCu9/+nrLyCrcjGRMy/PWNcw3V7BYSkSbiOS1GRHp5Mu3yU66A8Nq3G/imcBcPX9KRzNQEt+MErMzUBB6/vAu5G/fw0tfr3I5jTMhwvBCISAJwIfCR17TxIjLe8/IqYIWILAUmACNVNWwuJ83bdoC/fLGGwR3SGdmzhdtxAt7wbs24uEsTnpqRz5pt+92OY0xIkGD8zs3JydHc3Fy3Y5yx0rIKhj/3DSUHjvLFLwaQmhjrdqSgsOvgMYY8/RXp9eP4+Pa+xETZrjRjakJEFqlqzsnT7X+QiybOKWR18X7+fMVPrAjUQqPEWB6/vAsrt+5n4pxCt+MYE/SsELhkdfF+np9TyOXdmzO4Y7rbcYLOkE5NuKJ7c56bU8jyon1uxzEmqFkhcEFZeQX3fbCMBvHRPHJJR7fjBK3f/U8nUhNj+NX7Sygts7OIjKkrKwQueHXuepZv2cejl3amYUKM23GCVnJ8NH+8vAv52w/y0ldr3Y5jTNCyQuBn60oO8vcZ+VzUMZ2Lu9jVw2fqgg7p/LRLUybMLmRdid2Yzpi6sELgR6rKAx8tJzYqgj9c1jks7yrqhN/9T0dioyL4zcfLCcaz4IxxmxUCP/pw8RYWrN/Nby7uENJDTvpb4/pxPDisA/PX7eb93CK34xgTdKwQ+Mnew6X8aepqerRswIgcu3DM10b2bEHPzIY8PnU1JQeOuR3HmKBihcBP/jotjz2HS/nDZV2IiLBdQr4WESH86YouHC4t40+f2+2qjakNKwR+sHTzXt5asIkxfVrTsVl9t+OErDaNk7i5fxYfLd5C7obdbscxJmhYIXBYeYXy209WkJYYyz0XtnU7Tsi76/w2NE2O4+FJKymvsAPHxtSEFQKHvfXdRpZv2cfDl3QkKS7a7TghLz4mit/+tCOri/fz1nc2GJ4xNWGFwEE7Dx7jiWl59GuTyiU/aep2nLBxcZcm9MluxF+n5bHroB04NuZ0rBA46Mnp+RwpLef3l3ayawb8SER49NJOHC4t56/T8tyOY0zAs0LgkFVb9/Puwk2M6p1Jm8aJbscJO23Tk7ixbybv5m5myea9bscxJqBZIXCAqvLYZytJrhfN3RfYAWK33D34LNISY/nd5JVU2IFjY6rljxHKNojIchFZIiI/Gk1GKk0QkUIRWSYiPZzO5LRpK7czf91ufnnhWSTH2wFityTGRnHvkHYs3byXT5dtdTuOMQHLXz2C81S1W1Uj41A5sH1bz2Mc8A8/ZXLEsbJy/jh1NWelJ3JNr5Zuxwl7V/bIoFOz+jzxRR5Hj5e7HceYgBQIu4aGA29qpflAAxEJ2lNsXvtmA5t2H+bhSzoSFRkImze8RUQID/20A1v2HuHVuevdjmNMQPLHN5UC00VkkYiMq2J+c2Cz1+siz7QfEJFxIpIrIrklJSUORT0zJQeOMXF2IRe0b0z/tmluxzEefbJTubBjOs/PKbT7EBlTBX8Ugn6q2oPKXUB3iMiAuixEVV9S1RxVzUlLC8wv2SenV+5+eOinHdyOYk7y4LD2HCur4KmZ+W5HMSbgOF4IVHWL5+cO4GOg10lNtgDet+PM8EwLKmu27efd3M2M6p1JVpqdLhpostISuaF3K95ZsIm8bQfcjmNMQHG0EIhIgogknXgOXASsOKnZZGCU5+yhc4F9qlrsZC4n/OXzNSTFRvHzC9q4HcVU4+4L2pIUF83jU+3upMZ4c7pHkA7MFZGlwAJgiqp+ISLjRWS8p81UYB1QCLwM3O5wJp+bt3YXc/JKuP28NjSItzGIA1WD+Bh+fkFbvsovYU7eDrfjGBMwopxcuKquA7pWMf0Fr+cK3OFkDiepKn/+Yg1Nk+MY0yfT7TjmNG44txVvztvAXz5fw4C2aUTa2BDGBMTpo0Ht8xXbWLp5L/dceBZx0ZFuxzGnERMVwa8uaseabQeYvDToDkUZ4wgrBGfgeHkFf52Wx1npiVzZI8PtOKaGLunSlE7N6vPk9HxKyyrcjmOM66wQnIF3F25m/c5D3Dekve1iCCIREcJ9Q9tTtOeIjVlgDFYI6uzQsTKenllAr8wULujQ2O04ppYGtE2ld1Yjnp1dyMFjZW7HMcZVVgjq6NW569l58Bj3D2tvYw0EIRHhvqHt2HWolFe/tltPmPBmhaAOdh08xov/XcvQTk04u1VDt+OYOuresiFDOqXz8tfrbCQzE9asENTBxDmFHC2r4N6h7dyOYs7QvUPacbi0jOfmrHU7ijGusUJQS1v3HuE/8zdxVY8Msu1WEkGvTeMkrjo7g3/P30jRnsNuxzHGFVYIamninEIU5S67lUTI+MXgs0DgqRkFbkcxxhVWCGph067DvLdwM9f0aklGw3i34xgfadagHqN7t+Kj74so2G43pDPhxwpBLUyYXUBkhHDHedYbCDW3DWpDfHQkT8+0XoEJP1YIamhtyUE+WlzEqN6tSK8f53Yc42MpCTHc2Lc1U5YXs7p4v9txjPErKwQ19PTMAuKiIxk/MNvtKMYht/TPIik2iqdm2OA1JrxYIaiB1cX7+XTpVm7sm0mjxFi34xiHJMdHM7Z/a6av2s7yon1uxzHGb6wQ1MBTM/JJiotiXH/rDYS6m/q1JrleNH+fked2FGP8xrFCICItRGSOiKwSkZUicncVbQaJyD4RWeJ5POJUnrpaVrSX6au2c0v/LJLjo92OYxxWPy6acQOymJNXwuJNe9yOY4xfONkjKAN+paodgXOpHLi+YxXtvlbVbp7HYw7mqZMnp+fTMD6aG/tmuh3F+MmYPpk0SoixYwUmbDhWCFS1WFUXe54fAFYDzZ1anxNyN+zmv/kl3Dowm6Q46w2Ei4TYKMYPzObrgp0sWL/b7TjGOM4vxwhEJBPoDnxXxezeIrJURD4XkU6nWMY4EckVkdySkhKnov7Ak9PzSU2MZVTvVn5Znwkc15/birSkWJ6cnkflaKrGhC7HC4GIJAIfAr9Q1ZNP0F4MtFLVrsCzwCfVLUdVX1LVHFXNSUtLcyzvCd+u3cm8dbu4fVA28TGODu1sAlC9mEhuH5TNd+t3M2/tLrfjGOMoRwuBiERTWQT+o6ofnTxfVfer6kHP86lAtIikOpmppp6ZWUB6/ViuPael21GMS67p1ZKmyXE8OSPfegUmpDl51pAArwKrVfXv1bRp4mmHiPTy5HH9z6/563bx3frdjB+YbQPSh7G46EjuOK8Nizbu4auCnW7HMcYxTvYI+gI3AOd7nR56sYiMF5HxnjZXAStEZCkwARipAfCn1zMzC0hLiuWaXtYbCHcjclrQLDmOCbMKrFdgQpZjO79VdS5wyjEcVXUiMNGpDHWxYP1u5q3bxW9/2sF6A4aYqAhuO68ND3+ygm8Kd9GvbUDsuTTGp+zK4pNMmFVAamIM151jZwqZSiNyMmhSP45nZtmxAhOarBB4WbRxN3MLdzJuQBb1Yqw3YCrFRkVy26BsFm7Yw7x1rh/CMsbnrBB4eWZWIY0SYrj+XOsNmB/6Wc8WpNeP5Rkbr8CEICsEHt9v2sNX+SXcMiDLrhswP3LiFuTfrd/NfOsVmBBjhcBjwqwCGsZHc4P1Bkw1runVkrSkWCbMsl6BCS1WCIClm/cyJ6+Em/tnkRBrvQFTtbjoSG4dkMW3a3excIPdg8iEDisEVPYGGsRHM7pPpttRTIC77pxWpCbasQITWsK+EKzYso9Za3Ywtm9rEq03YE6jXkxlr2Bu4U4WbbRegQkNYV8InplVQP24KEbbeAOmhq47tyWNEmJ4Zlah21GM8YmwLgQrt+5jxqrt3NSvNfVtvAFTQ/ExUdwyIIuv8kv43kYxMyEgrAvBs7MKSYqL4sa+rd2OYoLMDee2omF8tJ1BZEJC2BaC1cX7+WLlNm7sWzlYuTG1kRAbxc39K8c2Xrp5r9txjDkjYVsInp1dQGJsFDfZsQFTR6P7ZNLAegUmBIRlIcjbdoCpy7cxpk8mDeJj3I5jglRibBQ392vNrDU7WF60z+04xtRZWBaCZ2cXkBATydh+dmzAnJlRfTKpHxfFM9YrMEEs7ApBwfYDTFlezKg+mTRMsN6AOTP146IZ2y+Lmau3s3Kr9QpMcPLH4PVDRSRPRApF5IEq5seKyLue+d+JSKaTeSbOKaRedCS39M9ycjUmjIzpm0lSXBTP2nUFJkg5PXh9JPAcMAzoCFwjIh1PajYW2KOqbYCngL84lWdtyUE+XbqVG3q3IsV6A8ZHkutFc2Pf1nyxchuri/e7HceYWnO6R9ALKFTVdapaCrwDDD+pzXDgDc/zD4ALTgxo72sTZxcSG2W9AeN7J25RMnG29QqMM+YW7OTnb3/P7kOlPl+204WgObDZ63WRZ1qVbVS1DNgHNDp5QSIyTkRyRSS3pKSk1kHKK5QDR49z/bktSU2MrfX7jTmV5PhoxvTJZOqKYvK3H3A7jgkxqsrTM/NZuGE3CbG+Hz0xaA4Wq+pLqpqjqjlpaWm1fn9khPDK6J48MKyDA+mMgbH9WhMfHWnXFRifm7duF7kb93DboGxio4KvEGwBWni9zvBMq7KNiEQByYBjQ0BFRjiy18kYGibEMKpPJlOWF1O4w3oFxneenVVI46RYRuS0OH3jOnC6ECwE2opIaxGJAUYCk09qMxkY7Xl+FTBbVdXhXMY44pb+WdSLjuRZO1ZgfGTB+t3MW7eLWwdmExft+94AOFwIPPv87wSmAauB91R1pYg8JiKXepq9CjQSkULgl8CPTjE1JlikJMRwQ+9WfLp0K2tLDrodx4SAZ2cXkJoYw7W9Wjq2DsePEajqVFU9S1WzVfVxz7RHVHWy5/lRVb1aVduoai9VXed0JmOcdEv/LGKjInnOegXmDC3etIevC3ZW9jRjnOkNQBAdLDYmWKQmxnL9uS35ZMkWNuw85HYcE8SenVVAw/horj+3laPrsUJgjANuGZBFdGQEE+dYr8DUzbKivczJK+Hm/lkkODyMrhUCYxzQOCmO685pxcffb2HjLusVmNqbMKuA5HrRjOrtbG8ArBAY45hbB2YRGSE8P2et21FMkFmxZR8zV+/g5n6tSfLDMLpWCIxxSHr9OK7t1ZIPFxexefdht+OYIPL0zALqx0Ux2k8DZ1khMMZBtw7MIkKE57+0XoGpmcrewHbG9suivh96A2CFwBhHNU2ux896tuCDRZvZsveI23FMEJgwq7I3MMaPw+haITDGYbcNygbgH1/aGUTm1FZt3c/0Vdu5qV9rkuv5pzcAVgiMcVyzBvW4OqcF7y0sonif9QpM9SbMKiApLoob+/p3GF0rBMb4we2DsqlQ5R92rMBUY3Xxfr5YuY0b+/q3NwBWCIzxi4yG8Vx1dgbvLNjMtn1H3Y5jAtCEWQUkxUYx1s+9AbBCYIzf3HFeG8pVeeG/1iswP7Rm234+X7GNMX0zSY73b28ArBAY4zctUuK5ontz3l6wiR37rVdg/s+zswpJjI1ibD//9wbACoExfnXn+W0oq1Be/Mpusmsq5W8/wNQVxYzu04oG8TGuZLBCYIwftWqUwPBuzfjPdxspOXDM7TgmAEyYVUB8dCQ398tyLYMVAmP87K7z21JaVsHLX1uvINwVbD/AlOXFjO6TScMEd3oD4FAhEJG/isgaEVkmIh+LSINq2m0QkeUiskREcp3IYkygaZ2awPBuzfnXvI3sPGi9gnD27OxC6kVHcnN/93oD4FyPYAbQWVV/AuQDD56i7Xmq2k1VcxzKYkzAueO8NhwtK7deQRgr2H6AT5dtZVTvTFJc7A2AQ4VAVad7xisGmA9kOLEeY4JVm8aJXNq1GW9+a72CcPX0zMpjA+MGuNsbAP8cI7gJ+LyaeQpMF5FFIjLuVAsRkXEikisiuSUlJT4PaYy/3X1BW46VldvVxmFo5dZ9TFlezNh+rV3vDcAZFAIRmSkiK6p4DPdq8xBQBvynmsX0U9UewDDgDhEZUN36VPUlVc1R1Zy0tLS6xjYmYGSlJXJljwz+NX+jXW0cZp6aUXmH0bEuHxs4oc6FQFUHq2rnKh6TAERkDHAJcJ2qajXL2OL5uQP4GOhV1zzGBKOfX9CWigpl4pwCt6MYP1myeS8zV29n3IAsv99TqDpOnTU0FLgPuFRVqxyaSUQSRCTpxHPgImCFE3mMCVQtUuL5Wc8WvLtws41iFib+PiOfhvHRjHHhnkLVceoYwUQgCZjhOTX0BQARaSYiUz1t0oG5IrIUWABMUdUvHMpjTMC68/w2iAjPzrZeQahbuGE3X+WXcNugbBJjo9yO878cSaKqbaqZvhW42PN8HdDVifUbE0yaJtfj+nNa8ca8DYwfmE1WWqLbkYwDVJW/TcsjLSmWG87NdDvOD9iVxcYEgNsGZRMTGcEzs6xXEKq+XbuL79bv5o5B2dSLiXQ7zg9YITAmAKQlxTK6TyaTl24lf/sBt+MYH1NVnpyeR9PkOEb2aul2nB+xQmBMgLh1QBYJMVE8NSPf7SjGx77MK2Hxpr3cdX5b4qIDqzcAVgiMCRgNE2IY2681n6/Yxoot+9yOY3xEVXlyRh4tUupxdU5g3mTBCoExAWRs/8rxap+cnud2FOMjlYV9P3dfcBbRkYH5lRuYqYwJU/Xjorl1YBZz8kr4bt0ut+OYM1RWXsHfpuVxVnoil3dv7nacalkhMCbA3NinNen1Y/nzF2uo5qJ8EyTeyy1i3c5D3DukPZER4nacalkhMCbA1IuJ5J7BZ/H9pr1MW7nd7Timjo6UlvP0zHxyWjVkcIfGbsc5JSsExgSgq87OIDstgSemraGsvMLtOKYO/vnNenYcOMb9w9ojEri9AbBCYExAioqM4L6h7VlXcoj3FxW5HcfU0p5Dpbzw37UM7tCYnpkpbsc5LSsExgSoizqm06NlA56akc+R0nK345haeP7LQg4eK+PeIe3djlIjVgiMCVAiwgPDOrDjwDH++c16t+OYGtqy9whvzNvIFd0zaNckye04NWKFwJgA1qt1CoM7NOaFL9ey51Cp23FMDTw9Ix8U7rmwrdtRaswKgTEB7t4h7TlUWsZzcwrdjmJOY822/Xy4uIgbercio2G823FqzAqBMQGuXZMkruyRwZvzNtrgNQFMVfnDZ6tJiovmrvOrvBN/wHKsEIjI70Vki2dgmiUicnE17YaKSJ6IFIrIA07lMSaY3XPhWYjAE9Ps1hOB6su8EuYW7uTuC9rSIN79Aelrw+kewVOq2s3zmHryTBGJBJ6jcvD6jsA1ItLR4UzGBJ1mDepx64AsPl26lUUbd7sdx5zkeHkFf5iyitapCVx/biu349Sa27uGegGFqrpOVUuBd4DhLmcyJiDdOjCb9PqxPPbZaioq7NYTgeTtBZtYW3KIB4e1JybK7a/V2nM68Z0iskxE/ikiDauY3xzY7PW6yDPtR0RknIjkikhuSUmJE1mNCWgJsVHcN6Q9SzfvZdLSLW7HMR77jhznqRn59M5qxIUd092OUydnVAhEZKaIrKjiMRz4B5ANdAOKgSfPZF2q+pKq5qhqTlpa2pksypigdXn35vwkI5m/fJ7H4dIyt+MY4Lk5hew9cpyHftoh4G8lUZ0zKgSqOlhVO1fxmKSq21W1XFUrgJep3A10si1AC6/XGZ5pxpgqREQIj1zSkW37j/Lif9e5HSfsbdx1iNe/2cBVPTLo3DzZ7Th15uRZQ029Xl4OrKii2UKgrYi0FpEYYCQw2alMxoSCnMwULvlJU178ai1b9x5xO05Y+/Pna4iKFH49pJ3bUc6Ik8cInhCR5SKyDDgPuAdARJqJyFQAVS0D7gSmAauB91R1pYOZjAkJDwxrT4XCE1+scTtK2JpbsJPPV2xj/MBs0uvHuR3njEQ5tWBVvaGa6VuBi71eTwV+dGqpMaZ6GQ3jGdc/i4lzCrmhdyvObhX4d7gMJaVlFfxu8gpapsQzbkCW23HOWPCd52SMAeC2Qdk0TY7jt5+stDEL/Oy1b9aztuQQv7+0I3HRkW7HOWNWCIwJUgmxUTxySUdWF+/nX/M3uh0nbBTvO8IzswoY3KEx57cPztNFT2aFwJggNrRzEwaclcaT0/PZsf+o23HCwuNTVlNWoTxySSe3o/iMFQJjgpiI8OilnSgtq+DxqavdjhPyvl27k8+WFXP7oGxaNgqeu4uejhUCY4Jc69QExg/KZtKSrXy7dqfbcULW8fIKfjdpJS1S6jF+YLbbcXzKCoExIeD2Qdm0SKnHI5NWUlpmB46d8NJX6yjYcZDfXdIpJA4Qe7NCYEwIiIuO5NFLO1G44yAvf21XHPvaupKDPDOrgGGdmzA4SO8ndCpWCIwJEee3T2dY5yY8M6uAtSUH3Y4TMlSV33y8nNioCB69NHQOEHuzQmBMCHl0eCfioiJ44MNldqtqH3kvdzPz1+3mNxd3oHGQX0FcHSsExoSQxklxPHxJRxZu2MN/FmxyO07Q23HgKI9PWU2v1in8LKfF6d8QpKwQGBNirjo7g/5tU/nz1NVssZvSnZFHJ6/iaFkFf7qiCxERwXmL6ZqwQmBMiBER/nh5FyoUHvp4Oaq2i6guPl26lSnLi7n7grZkpyW6HcdRVgiMCUEtUuK5d0g7vswr4f1FRW7HCTo79h/l4Ukr6NqiAbeGwE3lTscKgTEhakyfTM7NSuHRySvZvPuw23GChqry4EfLOVJazpNXdyUqMvS/JkP/X2hMmIqIEP52dVciRPjVe0spt7OIauT93CJmrdnB/UPb06ZxaO8SOsEKgTEhLKNhPI8O78SCDbvtQrMaKNpzmMc+W8W5WSmM6ZPpdhy/cWRgGhF5FzgxdlsDYK+qdqui3QbgAFAOlKlqjhN5jAlnl3dvzszV23lyeh4D2qbRsVl9tyMFpLLyCn7xzhJUlb9e1TWkzxI6mSM9AlX9map283z5fwh8dIrm53naWhEwxgEiwuOXdaFBfAx3v/M9h0vL3I4UkJ6ZVUDuxj388YoutEgJnTuL1oSju4ZERIARwNtOrscYc2oNE2J4akQ3CksO8sgkGxb8ZN8U7mTinEJG5GQwvFtzt+P4ndPHCPoD21W1oJr5CkwXkUUiMu5UCxKRcSKSKyK5JSUlPg9qTKjr1zaVu85vyweLing/d7PbcQJGyYFj/OLdJWSnJfL7EL2X0OnUuRCIyEwRWVHFY7hXs2s4dW+gn6r2AIYBd4jIgOoaqupLqpqjqjlpaWl1jW1MWLv7grb0zmrEw5NWkLftgNtxXFdRofzq/aXsP3Kcidd2Jz7GkcOmAa/OhUBVB6tq5yoekwBEJAq4Anj3FMvY4vm5A/gY6FXXPMaY04uMEJ65phuJsdHc/p9FHDoW3scLnplVwFf5JTzyPx1p3yR8D6I7uWtoMLBGVau8rFFEEkQk6cRz4CJghYN5jDFU3phuwshurN95iPs+WBa2t6CYvnIbz8wq4KqzM7i2V0u347jKyUIwkpN2C4lIMxGZ6nmZDswVkaXAAmCKqn7hYB5jjEefNqncP7Q9U5YXM3F2odtx/K5wxwHueXcJXTOS+cNlnak8ryV8ObZDTFXHVDFtK3Cx5/k6oKtT6zfGnNq4AVnkbTvAkzPyaZuexNDOTdyO5Bf7Dh9n3JuLqBcTyQs3nB1yw07WhV1ZbEyYEhH+eEUXurZowC/fW8KqrfvdjuS4Y2Xl3PrvXDbvOczz151N0+R6bkcKCFYIjAljcdGRvHzD2dSPi+bG1xdQtCd0b06nqtz3wTLmr9vN367uSq/WKW5HChhWCIwJc43rx/H6TT05XFrO6H8uYM+hUrcjOeJv0/OYtGQr9w5pF5YXjZ2KFQJjDO2b1OeVUTls3nOEm95YyJHScrcj+dRr36znuTlruaZXC24flO12nIBjhcAYA8A5WY2YMLIbSzbvZdy/cjl6PDSKwVvfbeLRT1cxpFM6/2+4nSFUFSsExpj/NbRzU/5y5U+YW7iTcf9aFPTF4INFRTz0yXLOb9+YZ6/pERaDzNSFbRVjzA+MyGnBX674CV8XlAR1MXg/dzP3fbCUvtmpPH9dD2Ki7OuuOrZljDE/MqLn/xWDm15fyP6jx92OVCuvfL2Oez9YRp/sVF4aZdcKnI4VAmNMlUb0bMHfR3RlwfrdjHhhHtv2HXU70mmpKk98sYY/TFnNT7s05dUxOWF7I7nasEJgjKnW5d0zeO3GnmzefZgrnv8moO9YevR4Ofe8u4Tnv1zLtee0ZMI13YmNsp5ATVghMMacUv+2abw3vjdlFcoVz3/DlGXFbkf6keJ9Rxjx4jw+WbKVX190Fo9f1pnIMBpq8kxZITDGnFanZslMvrMf7Zokccdbi/nDZ6soLatwOxYAc9bs4JIJc1m74yAvj8rhzvPb2imitWSFwBhTI02S43hnXG9G9W7FK3PXc9lz37Bmm3v3Jzp6vJzHPl3Fja8vJC0plkl39uXCjumu5QlmVgiMMTUWExXBY8M78/KoHHYcOMqlz37DMzML/H6K6Vf5JQx5+iv++c16xvTJ5JM7+tKmcZJfM4QSO5xujKm1Czum06PlAB6ZvJKnZubz/qLNPHRxB4Z2buLobpm1JQd5cnoeU5dvIys1gbduOYc+2amOrS9cSDCOTpSTk6O5ubluxzDGAN8W7uT3n64kf/tBOjStz13nt2FIpyY+PVhbsP0AL3+9jg8WFREXHcmtA7K5dWCWXR9QSyKySFVzfjT9TAqBiFwN/B7oAPRS1VyveQ8CY4Fy4OeqOq2K97cG3gEaAYuAG1T1tLc+tEJgTGApK69g0pKtPDenkHU7D9EsOY6rc1pwZY8MWjaKr9MyDxw9zuw1O3gvdzPfFO4iJiqC685pyR3ntSE1MdbH/4Lw4FQh6ABUAC8Cvz5RCESkI5XDVPYCmgEzgbNUtfyk978HfKSq74jIC8BSVf3H6dZrhcCYwFReoUxbuY23F2xibuFOVCE7LYFB7RrTtUUDOjatT6tG8USfdM+figql5OAx1u44yOJNe8jduIdvC3dRWl5Bs+Q4ru/dipE9W5KSEOPSvyw0OFIIvBb+JT8sBA8CqOqfPK+nAb9X1Xle7xGgBGiiqmUi0tvTZsjp1meFwJjAV7TnMNNWbufLvB18t243peX/d7ppcr1okutFU6FKWbmy+1DpD+afKB4Xd2lC9xYNibBrAnyiukLg1MHi5sB8r9dFnmneGgF7VbXsFG3+l4iMA8YBtGzZ0ndJjTGOyGgYz9h+rRnbrzXHysop3HGQ1cUHKNpzmN2HStl7+DiREUJUhJCSGENGg3q0bJRA14xkGsTbX/7+dNpCICIzgapGtX5IVSf5PlLVVPUl4CWo7BH4a73GmDMXGxVJp2bJdGqW7HYUU4XTFgJVHVyH5W4BWni9zvBM87YLaCAiUZ5eQVVtjDHGOMypC8omAyNFJNZzZlBbYIF3A608ODEHuMozaTTgtx6GMcaYSmdUCETkchEpAnoDUzwHhVHVlcB7wCrgC+COE2cMichUEWnmWcT9wC9FpJDKYwavnkkeY4wxtWcXlBljTJio7qwhu9eQMcaEOSsExhgT5qwQGGNMmLNCYIwxYS4oDxaLSAmwsY5vTwV2+jCOr1iu2rFctWO5aidUc7VS1bSTJwZlITgTIpJb1VFzt1mu2rFctWO5aifcctmuIWOMCXNWCIwxJsyFYyF4ye0A1bBctWO5asdy1U5Y5Qq7YwTGGGN+KBx7BMYYY7xYITDGmDAXkoVARK4WkZUiUiEi1Z5qJSJDRSRPRApF5AGv6a1F5DvP9HdFxCfDJYlIiojMEJECz8+GVbQ5T0SWeD2Oishlnnmvi8h6r3nd/JXL067ca92Tvaa7ub26icg8z+97mYj8zGueT7dXdZ8Xr/mxnn9/oWd7ZHrNe9AzPU9ETjscq49z/VJEVnm2zywRaeU1r8rfqZ9yjRGREq/13+w1b7Tn914gIqP9nOspr0z5IrLXa54j20tE/ikiO0RkRTXzRUQmeDIvE5EeXvPOfFupasg9gA5AO+BLIKeaNpHAWiALiAGWAh09894DRnqevwDc5qNcTwAPeJ4/APzlNO1TgN1AvOf168BVDmyvGuUCDlYz3bXtBZwFtPU8bwYUAw18vb1O9XnxanM78ILn+UjgXc/zjp72sUBrz3Ii/ZjrPK/P0G0ncp3qd+qnXGOAiVW8NwVY5/nZ0PO8ob9yndT+LuCfftheA4AewIpq5l8MfA4IcC7wnS+3VUj2CFR1tarmnaZZL6BQVdepainwDjBcRAQ4H/jA0+4N4DIfRRvuWV5Nl3sV8LmqHvbR+qtT21z/y+3tpar5qlrgeb4V2AH86MpJH6jy83KKvB8AF3i2z3DgHVU9pqrrgULP8vySS1XneH2G5lM5GqDTarK9qjMEmKGqu1V1DzADGOpSrmuAt3207mqp6ldU/tFXneHAm1ppPpWjOzbFR9sqJAtBDTUHNnu9LvJMawTs1crhM72n+0K6qhZ7nm8D0k/TfiQ//hA+7ukaPiUisX7OFSciuSIy/8TuKgJoe4lILyr/ylvrNdlX26u6z0uVbTzbYx+V26cm73Uyl7exVP5leUJVv1N/5rrS8/v5QERODG8bENvLswutNTDba7JT2+t0qsvtk2112jGLA5WIzASaVDHrIVV1bcjLU+XyfqGqKiLVnrvrqfZdgGlekx+k8gsxhsrzie8HHvNjrlaqukVEsoDZIrKcyi+7OvPx9voXMFpVKzyT67y9QpGIXA/kAAO9Jv/od6qqa6tegs99CrytqsdE5FYqe1Pn+2ndNTES+EA9oyt6uLm9HBO0hUBVB5/hIrYALbxeZ3im7aKy2xXl+avuxPQzziUi20WkqaoWe764dpxiUSOAj1X1uNeyT/x1fExEXgN+7c9cqrrF83OdiHwJdAc+xOXtJSL1gSlU/hEw32vZdd5eVaju81JVmyIRiQKSqfw81eS9TuZCRAZTWVwHquqxE9Or+Z364ovttLlUdZfXy1eoPCZ04r2DTnrvlz7IVKNcXkYCd3hPcHB7nU51uX2yrcJ519BCoK1UnvESQ+UvfbJWHoGZQ+X+eYDRgK96GJM9y6vJcn+0b9LzZXhiv/xlQJVnGDiRS0Qanti1IiKpQF9gldvby/O7+5jK/acfnDTPl9urys/LKfJeBcz2bJ/JwEipPKuoNdAWWHAGWWqVS0S6Ay8Cl6rqDq/pVf5O/ZirqdfLS4HVnufTgIs8+RoCF/HDnrGjuTzZ2lN58HWe1zQnt9fpTAZGec4eOhfY5/lDxzfbyokj4G4/gMup3Fd2DNgOTPNMbwZM9Wp3MZBPZUV/yGt6FpX/UQuB94FYH+VqBMwCCoCZQIpneg7wile7TCorfcRJ758NLKfyC+3fQKK/cgF9POte6vk5NhC2F3A9cBxY4vXo5sT2qurzQuWupks9z+M8//5Cz/bI8nrvQ5735QHDfPx5P12umZ7/Bye2z+TT/U79lOtPwErP+ucA7b3ee5NnOxYCN/ozl+f174E/n/Q+x7YXlX/0FXs+y0VUHssZD4z3zBfgOU/m5XidDemLbWW3mDDGmDAXzruGjDHGYIXAGGPCnhUCY4wJc1YIjDEmzFkhMMaYMGeFwBhjwpwVAmOMCXP/HzUv+jOOzBvMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xt_bound_3[:,0],u_bound_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_u,N_f,seed):\n",
    "\n",
    "    '''Boundary Conditions'''\n",
    "    #Initial Condition -1 =< x =<1 and t = 0  \n",
    "#     leftedge_x = np.hstack((X[0,:][:,None], T[0,:][:,None])) #L1\n",
    "#     leftedge_u = usol[:,0][:,None]\n",
    "\n",
    "#     #Boundary Condition x = -1 and 0 =< t =<1\n",
    "#     bottomedge_x = np.hstack((X[:,0][:,None], T[:,0][:,None])) #L2\n",
    "#     bottomedge_u = usol[-1,:][:,None]\n",
    "\n",
    "#     #Boundary Condition x = 1 and 0 =< t =<1\n",
    "#     topedge_x = np.hstack((X[:,-1][:,None], T[:,0][:,None])) #L3\n",
    "#     topedge_u = usol[0,:][:,None]\n",
    "\n",
    "#     all_X_u_train = np.vstack([leftedge_x, bottomedge_x, topedge_x]) # X_u_train [456,2] (456 = 256(L1)+100(L2)+100(L3))\n",
    "#     all_u_train = np.vstack([leftedge_u, bottomedge_u, topedge_u])   #corresponding u [456x1]\n",
    "\n",
    "    #choose random N_u points for training\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.choice(xt_bound.shape[0], N_u, replace=True) \n",
    "\n",
    "    X_u_train = xt_bound[idx, :] #choose indices from  set 'idx' (x,t)\n",
    "    u_train = u_bound[idx,:]      #choose corresponding u\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    X_f_train = lb_xt + (ub_xt-lb_xt)*samples \n",
    "    \n",
    "    X_f_train = np.vstack((X_f_train, X_u_train)) # append training points to collocation points \n",
    "\n",
    "    return X_f_train, X_u_train, u_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n   Fortran Style ('F') flatten,stacked column wise!\\n   u = [c1 \\n        c2\\n        .\\n        .\\n        cn]\\n\\n   u =  [25600x1] \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_u_test = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "X_u_test = xt_test_tensor\n",
    "# Domain bounds\n",
    "lb = X_u_test[0]  # [-1. 0.]\n",
    "ub = X_u_test[-1] # [1.  0.99]\n",
    "\n",
    "'''\n",
    "   Fortran Style ('F') flatten,stacked column wise!\n",
    "   u = [c1 \n",
    "        c2\n",
    "        .\n",
    "        .\n",
    "        cn]\n",
    "\n",
    "   u =  [25600x1] \n",
    "'''\n",
    "#u_true = usol.flatten('F')[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        '''\n",
    "        Alternatively:\n",
    "        \n",
    "        *all layers are callable \n",
    "    \n",
    "        Simple linear Layers\n",
    "        self.fc1 = nn.Linear(2,50)\n",
    "        self.fc2 = nn.Linear(50,50)\n",
    "        self.fc3 = nn.Linear(50,50)\n",
    "        self.fc4 = nn.Linear(50,1)\n",
    "        \n",
    "        '''\n",
    "    \n",
    "        'Xavier Normal Initialization'\n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            # weights from a normal distribution with \n",
    "            # Recommended gain value for tanh = 5/3?\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        self.beta = Parameter(1*torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        self.beta_val = []\n",
    "        \n",
    "        self.W1 = Parameter(torch.tensor(0.0))\n",
    "        self.W1.requiresGrad = True\n",
    "        \n",
    "        self.W2 = Parameter(torch.tensor(0.0))\n",
    "        self.W2.requiresGrad = True\n",
    "        \n",
    "    'foward pass'\n",
    "    def forward(self,x):\n",
    "         if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "         u_b = torch.from_numpy(ub_xt).float().to(device)\n",
    "         l_b = torch.from_numpy(lb_xt).float().to(device)\n",
    "        \n",
    "            \n",
    "         #preprocessing input \n",
    "         x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "         #convert to float\n",
    "         a = x.float()\n",
    "                        \n",
    "         '''     \n",
    "         Alternatively:\n",
    "        \n",
    "         a = self.activation(self.fc1(a))\n",
    "         a = self.activation(self.fc2(a))\n",
    "         a = self.activation(self.fc3(a))\n",
    "         a = self.fc4(a)\n",
    "         \n",
    "         '''\n",
    "        \n",
    "         for i in range(len(layers)-2):\n",
    "                z = self.linears[i](a)\n",
    "                a = self.activation(z) + self.beta[:,i]*z*self.activation(z)\n",
    "         \n",
    "         a = self.linears[-1](a)\n",
    "        \n",
    "         return a\n",
    "                        \n",
    "    def loss_BC(self,x,y):\n",
    "                \n",
    "        loss_u = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_u\n",
    "    \n",
    "    def loss_PDE(self, x_to_train_f,f_hat):\n",
    "        \n",
    "        nu = 0.01/pi\n",
    "                \n",
    "        x_1_f = x_to_train_f[:,[0]]\n",
    "        x_2_f = x_to_train_f[:,[1]]\n",
    "                        \n",
    "        g = x_to_train_f.clone()\n",
    "                        \n",
    "        g.requires_grad = True\n",
    "        \n",
    "        u = self.forward(g)\n",
    "                \n",
    "        u_x_t = autograd.grad(u,g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "                                \n",
    "        u_xx_tt = autograd.grad(u_x_t,g,torch.ones(x_to_train_f.shape).to(device), create_graph=True)[0]\n",
    "                                                            \n",
    "        u_x = u_x_t[:,[0]]\n",
    "        \n",
    "        u_t = u_x_t[:,[1]]\n",
    "        \n",
    "        u_xx = u_xx_tt[:,[0]]\n",
    "                                        \n",
    "        f = u_t + (self.forward(g))*(u_x) - (nu)*u_xx \n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,x,y,x_to_train_f,f_hat):\n",
    "\n",
    "        loss_u = self.loss_BC(x,y)\n",
    "        loss_f = self.loss_PDE(x_to_train_f,f_hat)\n",
    "        \n",
    "        p = torch.exp(self.W1)\n",
    "        q = torch.exp(self.W2)\n",
    "        \n",
    "        \n",
    "        loss_val = loss_u + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "     \n",
    "    'callable for optimizer'                                       \n",
    "    def closure(self):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         X_f_train_np_array, X_u_train_np_array, u_train_np_array = trainingdata(N_u,N_f,self.iter*32)\n",
    "        \n",
    "#         X_f_train = torch.from_numpy(X_f_train_np_array).float().to(device)\n",
    "#         X_u_train = torch.from_numpy(X_u_train_np_array).float().to(device)\n",
    "#         u_train = torch.from_numpy(u_train_np_array).float().to(device)\n",
    "        \n",
    "#     #u = torch.from_numpy(u_true).float().to(device)\n",
    "#         f_hat = torch.zeros(X_f_train.shape[0],1).to(device)\n",
    "        \n",
    "\n",
    "        loss = self.loss(X_u_train, u_train, X_f_train,f_hat)\n",
    "        \n",
    "        self.train_loss.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        \n",
    "        u_pred = self.test(xt_test_tensor)\n",
    "        self.test_loss.append(np.mean(np.square(u_pred.reshape(-1,1) - u_true.reshape(-1,1))))\n",
    "        self.beta_val.append(self.beta.cpu().detach().numpy())\n",
    "        \n",
    "        print(self.iter,\"Train Loss\",self.train_loss[-1],\"Test Loss\",self.test_loss[-1])\n",
    "#         print(self.iter,\"Train Loss\",self.train_loss[-1])\n",
    "        loss.backward()\n",
    "        self.iter += 1\n",
    "     \n",
    "        return loss        \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self,xt_test_tensor):\n",
    "        u_pred = self.forward(xt_test_tensor)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return u_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000,  0.0000],\n",
       "        [-0.9922,  0.0000],\n",
       "        [-0.9843,  0.0000],\n",
       "        ...,\n",
       "        [ 0.9843,  0.2000],\n",
       "        [ 0.9922,  0.2000],\n",
       "        [ 1.0000,  0.2000]], device='cuda:2')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (7): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0 Train Loss 17.827448 Test Loss 24.721722346936225\n",
      "1 Train Loss 17.403751 Test Loss 24.618225858028772\n",
      "2 Train Loss 15.7419195 Test Loss 24.182718528370277\n",
      "3 Train Loss 11.324237 Test Loss 23.931318691485455\n",
      "4 Train Loss 8.884783 Test Loss 26.424068888144514\n",
      "5 Train Loss 6.8815103 Test Loss 26.078839742918664\n",
      "6 Train Loss 5.8862824 Test Loss 27.093063530504867\n",
      "7 Train Loss 4.156912 Test Loss 29.359302248312243\n",
      "8 Train Loss 1.9836353 Test Loss 30.73883715215753\n",
      "9 Train Loss 0.968586 Test Loss 30.043436263136062\n",
      "10 Train Loss 1.7091908 Test Loss 30.884272851310108\n",
      "11 Train Loss 0.7042085 Test Loss 29.728313573325934\n",
      "12 Train Loss 0.5382434 Test Loss 29.52078497851991\n",
      "13 Train Loss 0.45806932 Test Loss 29.14685317777798\n",
      "14 Train Loss 0.32204136 Test Loss 29.26776029932782\n",
      "15 Train Loss 0.278949 Test Loss 29.55083359117139\n",
      "16 Train Loss 0.20273037 Test Loss 30.738688505254576\n",
      "17 Train Loss 0.14216155 Test Loss 34.13364508340787\n",
      "18 Train Loss 0.08758001 Test Loss 36.56515296049891\n",
      "19 Train Loss 0.10873167 Test Loss 39.395435078199945\n",
      "20 Train Loss 0.07991748 Test Loss 37.75709686181912\n",
      "21 Train Loss 0.1298145 Test Loss 38.863156306911364\n",
      "22 Train Loss 0.0767778 Test Loss 37.971266015323515\n",
      "23 Train Loss 0.07355629 Test Loss 38.27672125996079\n",
      "24 Train Loss 0.07063503 Test Loss 38.603359537509824\n",
      "25 Train Loss 0.06476657 Test Loss 41.621912244481244\n",
      "26 Train Loss 0.059736688 Test Loss 40.59201200319393\n",
      "27 Train Loss 0.056800455 Test Loss 41.49459813532564\n",
      "28 Train Loss 0.050597124 Test Loss 42.27670881986787\n",
      "29 Train Loss 0.04759871 Test Loss 42.11777919151425\n",
      "30 Train Loss 0.042523496 Test Loss 43.03410625093297\n",
      "31 Train Loss 0.03441541 Test Loss 43.71551144857381\n",
      "32 Train Loss 0.03024356 Test Loss 43.542709057946915\n",
      "33 Train Loss 0.027753267 Test Loss 43.92592997594112\n",
      "34 Train Loss 0.026888527 Test Loss 44.18410146505552\n",
      "35 Train Loss 0.025935058 Test Loss 44.424252470560994\n",
      "36 Train Loss 0.024833666 Test Loss 44.724181818338046\n",
      "37 Train Loss 0.022753892 Test Loss 45.46277138533969\n",
      "38 Train Loss 0.02080214 Test Loss 46.00773539364747\n",
      "39 Train Loss 0.01819656 Test Loss 46.64382324656286\n",
      "40 Train Loss 0.01708988 Test Loss 46.63075908022669\n",
      "41 Train Loss 0.01633075 Test Loss 46.85777124477386\n",
      "42 Train Loss 0.0153653165 Test Loss 46.6151972698507\n",
      "43 Train Loss 0.013684044 Test Loss 46.306753816921656\n",
      "44 Train Loss 0.012276564 Test Loss 46.32003929604781\n",
      "45 Train Loss 0.01112744 Test Loss 46.56028699402937\n",
      "46 Train Loss 0.010629728 Test Loss 46.90864634974453\n",
      "47 Train Loss 0.019798415 Test Loss 47.25677965133306\n",
      "48 Train Loss 0.009908816 Test Loss 47.04724967629167\n",
      "49 Train Loss 0.009315512 Test Loss 46.97589626157676\n",
      "50 Train Loss 0.0088565275 Test Loss 47.01682661996126\n",
      "51 Train Loss 0.00785617 Test Loss 47.09286926987891\n",
      "52 Train Loss 0.00753248 Test Loss 47.07318228838839\n",
      "53 Train Loss 0.00715077 Test Loss 47.14660176442099\n",
      "54 Train Loss 0.0066216937 Test Loss 47.265705086313055\n",
      "55 Train Loss 0.005725715 Test Loss 47.52974761524199\n",
      "56 Train Loss 0.005338896 Test Loss 47.797681828169026\n",
      "57 Train Loss 0.004880842 Test Loss 48.02919933177658\n",
      "58 Train Loss 0.0046618106 Test Loss 47.96589512654549\n",
      "59 Train Loss 0.0043414542 Test Loss 48.05470573750169\n",
      "60 Train Loss 0.004055159 Test Loss 48.21735823203553\n",
      "61 Train Loss 0.0039034635 Test Loss 48.46292630910655\n",
      "62 Train Loss 0.0037909294 Test Loss 48.5584395420761\n",
      "63 Train Loss 0.0036634416 Test Loss 48.54876000207527\n",
      "64 Train Loss 0.0034721955 Test Loss 48.57623520328707\n",
      "65 Train Loss 0.0031079287 Test Loss 48.415696150372554\n",
      "66 Train Loss 0.003216547 Test Loss 48.04310839932843\n",
      "67 Train Loss 0.002971374 Test Loss 48.24455534408681\n",
      "68 Train Loss 0.0026588102 Test Loss 47.75958400554966\n",
      "69 Train Loss 0.002395955 Test Loss 47.70768375106705\n",
      "70 Train Loss 0.0024167518 Test Loss 47.07329465832202\n",
      "71 Train Loss 0.0021119958 Test Loss 47.378606603900636\n",
      "72 Train Loss 0.0019022322 Test Loss 47.22554408937705\n",
      "73 Train Loss 0.0016818672 Test Loss 47.14194570534542\n",
      "74 Train Loss 0.0018458369 Test Loss 46.769300668440394\n",
      "75 Train Loss 0.0016219812 Test Loss 47.00431408217405\n",
      "76 Train Loss 0.0015192642 Test Loss 47.06239131669744\n",
      "77 Train Loss 0.0014734248 Test Loss 47.114134532749205\n",
      "78 Train Loss 0.0014544064 Test Loss 47.16418671867727\n",
      "79 Train Loss 0.0014406046 Test Loss 47.210813686688674\n",
      "80 Train Loss 0.0014318549 Test Loss 47.185109447215225\n",
      "81 Train Loss 0.001392659 Test Loss 47.059694377386116\n",
      "82 Train Loss 0.0013598168 Test Loss 46.932664389126536\n",
      "83 Train Loss 0.0012404901 Test Loss 46.42694966045285\n",
      "84 Train Loss 0.0011097761 Test Loss 45.89584998822135\n",
      "85 Train Loss 0.0009788163 Test Loss 44.9949342851766\n",
      "86 Train Loss 0.00096880575 Test Loss 44.50279820992717\n",
      "87 Train Loss 0.0009083345 Test Loss 44.73671552102828\n",
      "88 Train Loss 0.00091783213 Test Loss 44.520231479884266\n",
      "89 Train Loss 0.0008707567 Test Loss 44.631156796848565\n",
      "90 Train Loss 0.00084609515 Test Loss 44.46037381702837\n",
      "91 Train Loss 0.00080107525 Test Loss 44.267336853713935\n",
      "92 Train Loss 0.0007412812 Test Loss 44.06318079465298\n",
      "93 Train Loss 0.0006649601 Test Loss 43.66613514621102\n",
      "94 Train Loss 0.0006153778 Test Loss 43.44198933635181\n",
      "95 Train Loss 0.000591288 Test Loss 43.08284625492015\n",
      "96 Train Loss 0.0006985437 Test Loss 42.14109104366928\n",
      "97 Train Loss 0.00057540066 Test Loss 42.74312914400188\n",
      "98 Train Loss 0.0005670088 Test Loss 42.34396455088446\n",
      "99 Train Loss 0.00055920467 Test Loss 42.49739265720651\n",
      "100 Train Loss 0.0005378148 Test Loss 42.20111805409035\n",
      "101 Train Loss 0.0005244179 Test Loss 41.868581976149265\n",
      "102 Train Loss 0.00052408024 Test Loss 42.07931364578768\n",
      "103 Train Loss 0.00051962346 Test Loss 41.97509158239886\n",
      "104 Train Loss 0.00051689637 Test Loss 41.961570781649705\n",
      "105 Train Loss 0.00051421864 Test Loss 41.9376057838041\n",
      "106 Train Loss 0.00050484226 Test Loss 41.92940294406717\n",
      "107 Train Loss 0.00049972243 Test Loss 41.93552641292671\n",
      "108 Train Loss 0.00048150125 Test Loss 42.149300272987446\n",
      "109 Train Loss 0.00046378342 Test Loss 42.30172448350942\n",
      "110 Train Loss 0.00044519757 Test Loss 42.90041416018685\n",
      "111 Train Loss 0.00042762992 Test Loss 42.77124409319088\n",
      "112 Train Loss 0.00041567322 Test Loss 42.74883612754025\n",
      "113 Train Loss 0.00040660595 Test Loss 42.777680265630636\n",
      "114 Train Loss 0.0004014097 Test Loss 42.90184210096409\n",
      "115 Train Loss 0.00039649906 Test Loss 42.9337958669097\n",
      "116 Train Loss 0.0003875789 Test Loss 43.00097366289792\n",
      "117 Train Loss 0.0003791908 Test Loss 43.07841615987249\n",
      "118 Train Loss 0.00036905782 Test Loss 43.131295207653594\n",
      "119 Train Loss 0.00036298126 Test Loss 43.11254927723375\n",
      "120 Train Loss 0.0003569661 Test Loss 43.212769824153774\n",
      "121 Train Loss 0.00034854352 Test Loss 43.04722890411617\n",
      "122 Train Loss 0.00033070863 Test Loss 42.824313622996705\n",
      "123 Train Loss 0.00032273016 Test Loss 42.28997661327411\n",
      "124 Train Loss 0.00031423103 Test Loss 42.48541137952295\n",
      "125 Train Loss 0.0003033366 Test Loss 42.4104685048914\n",
      "126 Train Loss 0.00029955216 Test Loss 42.41216029292789\n",
      "127 Train Loss 0.00029518333 Test Loss 42.49224503101823\n",
      "128 Train Loss 0.00028070877 Test Loss 42.77878299646502\n",
      "129 Train Loss 0.00026039092 Test Loss 43.15630463525863\n",
      "130 Train Loss 0.00029851 Test Loss 43.51910883847925\n",
      "131 Train Loss 0.00024675968 Test Loss 43.32136828931325\n",
      "132 Train Loss 0.00023216417 Test Loss 43.088568593188064\n",
      "133 Train Loss 0.000222964 Test Loss 42.88696313788036\n",
      "134 Train Loss 0.0002097963 Test Loss 43.026499303996445\n",
      "135 Train Loss 0.00020588705 Test Loss 43.00662417691869\n",
      "136 Train Loss 0.00019326285 Test Loss 43.03963292849454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 Train Loss 0.00018322845 Test Loss 43.10150437223762\n",
      "138 Train Loss 0.00017388785 Test Loss 43.085233173081626\n",
      "139 Train Loss 0.00017576653 Test Loss 42.93997103230729\n",
      "140 Train Loss 0.00016987912 Test Loss 43.01343410769632\n",
      "141 Train Loss 0.00016230854 Test Loss 42.970350187528865\n",
      "142 Train Loss 0.0001544383 Test Loss 42.93549858991225\n",
      "143 Train Loss 0.0001466435 Test Loss 42.95535024907213\n",
      "144 Train Loss 0.00014274039 Test Loss 42.89226183123959\n",
      "145 Train Loss 0.00014145325 Test Loss 42.91568177716396\n",
      "146 Train Loss 0.00013872547 Test Loss 42.910814405880174\n",
      "147 Train Loss 0.00013753626 Test Loss 42.89073662961135\n",
      "148 Train Loss 0.00013627805 Test Loss 42.88448292055405\n",
      "149 Train Loss 0.0001355603 Test Loss 42.85370199720461\n",
      "150 Train Loss 0.00013494791 Test Loss 42.81749064207102\n",
      "151 Train Loss 0.00013388034 Test Loss 42.72826581614588\n",
      "152 Train Loss 0.00013281868 Test Loss 42.622057629266095\n",
      "153 Train Loss 0.00013197621 Test Loss 42.50825923473275\n",
      "154 Train Loss 0.00013086532 Test Loss 42.448771008189624\n",
      "155 Train Loss 0.00012994144 Test Loss 42.460898563694954\n",
      "156 Train Loss 0.00012909662 Test Loss 42.44562649101292\n",
      "157 Train Loss 0.00012739771 Test Loss 42.43227016538706\n",
      "158 Train Loss 0.00012376285 Test Loss 42.42382993915129\n",
      "159 Train Loss 0.00011990938 Test Loss 42.527469868693245\n",
      "160 Train Loss 0.000118014206 Test Loss 42.58780755179818\n",
      "161 Train Loss 0.00012054235 Test Loss 42.90645699928475\n",
      "162 Train Loss 0.00011578072 Test Loss 42.71631351771742\n",
      "163 Train Loss 0.00011506936 Test Loss 42.67276267153739\n",
      "164 Train Loss 0.000114192284 Test Loss 42.63993324631525\n",
      "165 Train Loss 0.00011310364 Test Loss 42.62126192310683\n",
      "166 Train Loss 0.000111731904 Test Loss 42.63251214846357\n",
      "167 Train Loss 0.00011472177 Test Loss 42.71718145216261\n",
      "168 Train Loss 0.000110559995 Test Loss 42.66744567900307\n",
      "169 Train Loss 0.0001092241 Test Loss 42.72560189345469\n",
      "170 Train Loss 0.00010806363 Test Loss 42.80114087066539\n",
      "171 Train Loss 0.00010744791 Test Loss 42.888930158071545\n",
      "172 Train Loss 0.000106841064 Test Loss 42.880105399566716\n",
      "173 Train Loss 0.00010641722 Test Loss 42.898218021724915\n",
      "174 Train Loss 0.00010582134 Test Loss 42.92187312068276\n",
      "175 Train Loss 0.00010482001 Test Loss 42.956013233102595\n",
      "176 Train Loss 0.000103200786 Test Loss 43.06996892850689\n",
      "177 Train Loss 0.000101993595 Test Loss 43.18397694005946\n",
      "178 Train Loss 0.00010113651 Test Loss 43.233283635739845\n",
      "179 Train Loss 0.000100267214 Test Loss 43.25427918183634\n",
      "180 Train Loss 9.87395e-05 Test Loss 43.320987107978496\n",
      "181 Train Loss 9.649612e-05 Test Loss 43.43438043174642\n",
      "182 Train Loss 9.250706e-05 Test Loss 43.69059741871636\n",
      "183 Train Loss 8.9806184e-05 Test Loss 43.939654152807094\n",
      "184 Train Loss 8.96118e-05 Test Loss 44.227257514060746\n",
      "185 Train Loss 8.772973e-05 Test Loss 44.09525715356134\n",
      "186 Train Loss 8.601099e-05 Test Loss 43.99423923256799\n",
      "187 Train Loss 8.454159e-05 Test Loss 44.01772125669027\n",
      "188 Train Loss 8.470801e-05 Test Loss 44.19191769059613\n",
      "189 Train Loss 8.3629966e-05 Test Loss 44.10766982130979\n",
      "190 Train Loss 8.299689e-05 Test Loss 44.069603046422884\n",
      "191 Train Loss 8.264481e-05 Test Loss 44.07685271692717\n",
      "192 Train Loss 8.2398685e-05 Test Loss 44.12635180275261\n",
      "193 Train Loss 8.225631e-05 Test Loss 44.146567114767315\n",
      "194 Train Loss 8.199699e-05 Test Loss 44.21586067764308\n",
      "195 Train Loss 8.1645856e-05 Test Loss 44.29577129757358\n",
      "196 Train Loss 8.13376e-05 Test Loss 44.43664756470359\n",
      "197 Train Loss 8.10047e-05 Test Loss 44.482022540408195\n",
      "198 Train Loss 8.072207e-05 Test Loss 44.55829567019788\n",
      "199 Train Loss 8.013482e-05 Test Loss 44.68291529993768\n",
      "200 Train Loss 7.9434016e-05 Test Loss 44.73933421321921\n",
      "201 Train Loss 7.886357e-05 Test Loss 44.841757156802416\n",
      "202 Train Loss 7.833453e-05 Test Loss 44.70083007110601\n",
      "203 Train Loss 7.787049e-05 Test Loss 44.74384948367888\n",
      "204 Train Loss 7.7350116e-05 Test Loss 44.75250415675344\n",
      "205 Train Loss 7.6981116e-05 Test Loss 44.735205913008734\n",
      "206 Train Loss 7.6609176e-05 Test Loss 44.68230726409756\n",
      "207 Train Loss 7.63674e-05 Test Loss 44.63007544799389\n",
      "208 Train Loss 7.601139e-05 Test Loss 44.52825142604431\n",
      "209 Train Loss 7.5674936e-05 Test Loss 44.44961421098744\n",
      "210 Train Loss 7.509728e-05 Test Loss 44.36080405658435\n",
      "211 Train Loss 7.4070565e-05 Test Loss 44.25442534674217\n",
      "212 Train Loss 7.131736e-05 Test Loss 43.99003164912827\n",
      "213 Train Loss 6.809923e-05 Test Loss 43.76044706708032\n",
      "214 Train Loss 6.805664e-05 Test Loss 43.48230289894254\n",
      "215 Train Loss 6.688406e-05 Test Loss 43.606519186794394\n",
      "216 Train Loss 6.5328546e-05 Test Loss 43.61282849042259\n",
      "217 Train Loss 6.9049376e-05 Test Loss 43.49440597321485\n",
      "218 Train Loss 6.430718e-05 Test Loss 43.57282823931249\n",
      "219 Train Loss 6.4585234e-05 Test Loss 43.537896172468216\n",
      "220 Train Loss 6.3499465e-05 Test Loss 43.5563395668996\n",
      "221 Train Loss 6.342071e-05 Test Loss 43.42541037702554\n",
      "222 Train Loss 6.3227024e-05 Test Loss 43.483608060970944\n",
      "223 Train Loss 6.240877e-05 Test Loss 43.2720370460899\n",
      "224 Train Loss 6.199165e-05 Test Loss 43.2480109430915\n",
      "225 Train Loss 6.17961e-05 Test Loss 43.21871608017196\n",
      "226 Train Loss 6.1630155e-05 Test Loss 43.15632409929433\n",
      "227 Train Loss 6.152263e-05 Test Loss 43.07141350374024\n",
      "228 Train Loss 6.139466e-05 Test Loss 43.00059946619678\n",
      "229 Train Loss 6.12662e-05 Test Loss 42.96346568976056\n",
      "230 Train Loss 6.112244e-05 Test Loss 42.91147130408746\n",
      "231 Train Loss 6.096147e-05 Test Loss 42.96602617406455\n",
      "232 Train Loss 6.075833e-05 Test Loss 42.97188936379033\n",
      "233 Train Loss 6.002996e-05 Test Loss 43.04115243131084\n",
      "234 Train Loss 5.939023e-05 Test Loss 43.20291337732865\n",
      "235 Train Loss 5.860417e-05 Test Loss 43.40827805707675\n",
      "236 Train Loss 6.0017886e-05 Test Loss 43.6843062841789\n",
      "237 Train Loss 5.830916e-05 Test Loss 43.5032830538014\n",
      "238 Train Loss 5.7360394e-05 Test Loss 43.4802525233421\n",
      "239 Train Loss 5.6402612e-05 Test Loss 43.53839152001661\n",
      "240 Train Loss 5.605605e-05 Test Loss 43.60569251824009\n",
      "241 Train Loss 5.559301e-05 Test Loss 43.63147161514728\n",
      "242 Train Loss 5.5310076e-05 Test Loss 43.49407058550198\n",
      "243 Train Loss 5.477064e-05 Test Loss 43.55033290601045\n",
      "244 Train Loss 5.4208456e-05 Test Loss 43.609253141940926\n",
      "245 Train Loss 5.332392e-05 Test Loss 43.603831389411546\n",
      "246 Train Loss 5.0482704e-05 Test Loss 43.343255692487546\n",
      "247 Train Loss 5.6176737e-05 Test Loss 43.16838444912803\n",
      "248 Train Loss 4.932016e-05 Test Loss 43.26621771376575\n",
      "249 Train Loss 4.9448725e-05 Test Loss 42.86485913934737\n",
      "250 Train Loss 4.7037873e-05 Test Loss 43.0565022163064\n",
      "251 Train Loss 4.6049558e-05 Test Loss 42.62616539110185\n",
      "252 Train Loss 5.9695645e-05 Test Loss 41.87280037676763\n",
      "253 Train Loss 4.431662e-05 Test Loss 42.4118344799216\n",
      "254 Train Loss 4.7929087e-05 Test Loss 41.787916143149545\n",
      "255 Train Loss 4.223476e-05 Test Loss 42.13193446459636\n",
      "256 Train Loss 4.0852156e-05 Test Loss 41.801914266410414\n",
      "257 Train Loss 3.936236e-05 Test Loss 41.305832319638476\n",
      "258 Train Loss 3.9157952e-05 Test Loss 40.962282398635374\n",
      "259 Train Loss 3.799689e-05 Test Loss 40.702749747347006\n",
      "260 Train Loss 3.8537706e-05 Test Loss 40.91973881650456\n",
      "261 Train Loss 3.769887e-05 Test Loss 40.77941570588243\n",
      "262 Train Loss 3.7689904e-05 Test Loss 40.897778928320655\n",
      "263 Train Loss 3.7217098e-05 Test Loss 40.83907972601844\n",
      "264 Train Loss 3.6338122e-05 Test Loss 40.42686829938624\n",
      "265 Train Loss 3.5638943e-05 Test Loss 39.94938096220512\n",
      "266 Train Loss 3.506039e-05 Test Loss 39.897382025617\n",
      "267 Train Loss 3.455204e-05 Test Loss 39.70481311153635\n",
      "268 Train Loss 3.4267418e-05 Test Loss 39.39979119829846\n",
      "269 Train Loss 3.403978e-05 Test Loss 39.534483576801605\n",
      "270 Train Loss 3.385475e-05 Test Loss 39.55357681747068\n",
      "271 Train Loss 3.3685166e-05 Test Loss 39.51089042849416\n",
      "272 Train Loss 3.3441996e-05 Test Loss 39.541424451159195\n",
      "273 Train Loss 3.2906664e-05 Test Loss 39.705905179837316\n",
      "274 Train Loss 3.2244072e-05 Test Loss 40.00069479277069\n",
      "275 Train Loss 3.1575368e-05 Test Loss 40.265333215878265\n",
      "276 Train Loss 3.0793017e-05 Test Loss 40.226546937418334\n",
      "277 Train Loss 3.0262254e-05 Test Loss 40.47997903223945\n",
      "278 Train Loss 2.9949251e-05 Test Loss 40.50360305050471\n",
      "279 Train Loss 2.976359e-05 Test Loss 40.704164535949026\n",
      "280 Train Loss 2.9508452e-05 Test Loss 40.758295201112034\n",
      "281 Train Loss 2.9184112e-05 Test Loss 40.846425818347605\n",
      "282 Train Loss 2.8760038e-05 Test Loss 41.148803959387685\n",
      "283 Train Loss 2.9316945e-05 Test Loss 41.18942909206921\n",
      "284 Train Loss 2.8192588e-05 Test Loss 41.167818774574414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 Train Loss 2.7605796e-05 Test Loss 41.3197126370474\n",
      "286 Train Loss 4.381583e-05 Test Loss 41.98768494599199\n",
      "287 Train Loss 2.7296304e-05 Test Loss 41.521836865562506\n",
      "288 Train Loss 2.6849535e-05 Test Loss 41.55910366041842\n",
      "289 Train Loss 2.6729324e-05 Test Loss 41.51297559382614\n",
      "290 Train Loss 2.6512225e-05 Test Loss 41.61080979437114\n",
      "291 Train Loss 2.6458625e-05 Test Loss 41.687960392534166\n",
      "292 Train Loss 2.6323e-05 Test Loss 41.66531558965311\n",
      "293 Train Loss 2.6226378e-05 Test Loss 41.69462785234572\n",
      "294 Train Loss 2.6129499e-05 Test Loss 41.715802988692424\n",
      "295 Train Loss 2.6061662e-05 Test Loss 41.77899135212297\n",
      "296 Train Loss 2.609942e-05 Test Loss 41.76542804335044\n",
      "297 Train Loss 2.6002937e-05 Test Loss 41.77300452815044\n",
      "298 Train Loss 2.5951362e-05 Test Loss 41.765337889239866\n",
      "299 Train Loss 2.5906558e-05 Test Loss 41.769048811066476\n",
      "300 Train Loss 2.5873258e-05 Test Loss 41.774053622008836\n",
      "301 Train Loss 2.5821926e-05 Test Loss 41.77745918136085\n",
      "302 Train Loss 2.5674895e-05 Test Loss 41.78907853934276\n",
      "303 Train Loss 2.509322e-05 Test Loss 41.841779695134676\n",
      "304 Train Loss 2.4520079e-05 Test Loss 41.892636875559866\n",
      "305 Train Loss 2.4439036e-05 Test Loss 42.122049246960124\n",
      "306 Train Loss 2.373652e-05 Test Loss 42.02608292807602\n",
      "307 Train Loss 2.1272654e-05 Test Loss 42.232643063116\n",
      "308 Train Loss 2.739338e-05 Test Loss 42.46457896841821\n",
      "309 Train Loss 2.0993386e-05 Test Loss 42.28674894164432\n",
      "310 Train Loss 2.2724995e-05 Test Loss 42.50918638697603\n",
      "311 Train Loss 2.0391206e-05 Test Loss 42.367883924733704\n",
      "312 Train Loss 1.9375548e-05 Test Loss 42.45108080784225\n",
      "313 Train Loss 1.9145755e-05 Test Loss 42.606241426991126\n",
      "314 Train Loss 1.8922607e-05 Test Loss 42.54748093661796\n",
      "315 Train Loss 2.0699346e-05 Test Loss 42.649755983969754\n",
      "316 Train Loss 1.8489647e-05 Test Loss 42.58327149490346\n",
      "317 Train Loss 1.7664539e-05 Test Loss 42.67209713143676\n",
      "318 Train Loss 1.8106186e-05 Test Loss 42.77449784964692\n",
      "319 Train Loss 1.7436269e-05 Test Loss 42.712139542543916\n",
      "320 Train Loss 1.7463257e-05 Test Loss 42.69392671949177\n",
      "321 Train Loss 1.7184151e-05 Test Loss 42.70317691026461\n",
      "322 Train Loss 1.69159e-05 Test Loss 42.77116739574564\n",
      "323 Train Loss 1.6650014e-05 Test Loss 42.70693583580262\n",
      "324 Train Loss 1.6478192e-05 Test Loss 42.66275591931043\n",
      "325 Train Loss 1.623949e-05 Test Loss 42.55543104882976\n",
      "326 Train Loss 1.6154865e-05 Test Loss 42.499422194306\n",
      "327 Train Loss 1.6100174e-05 Test Loss 42.49214425498315\n",
      "328 Train Loss 1.605236e-05 Test Loss 42.4923640356485\n",
      "329 Train Loss 1.6001162e-05 Test Loss 42.48360842904857\n",
      "330 Train Loss 1.5886937e-05 Test Loss 42.466586092701434\n",
      "331 Train Loss 1.5631646e-05 Test Loss 42.43399591550788\n",
      "332 Train Loss 1.5387881e-05 Test Loss 42.37090106410255\n",
      "333 Train Loss 1.5258805e-05 Test Loss 42.36173636859881\n",
      "334 Train Loss 1.5065798e-05 Test Loss 42.31686005141691\n",
      "335 Train Loss 1.5039273e-05 Test Loss 42.3148611706321\n",
      "336 Train Loss 1.4989067e-05 Test Loss 42.30547514304689\n",
      "337 Train Loss 1.4972195e-05 Test Loss 42.277760805652015\n",
      "338 Train Loss 1.4946454e-05 Test Loss 42.24410249273725\n",
      "339 Train Loss 1.4918582e-05 Test Loss 42.209595448689626\n",
      "340 Train Loss 1.4895557e-05 Test Loss 42.17998497167635\n",
      "341 Train Loss 1.4864399e-05 Test Loss 42.15349327468908\n",
      "342 Train Loss 1.4791386e-05 Test Loss 42.0912635784419\n",
      "343 Train Loss 1.4665691e-05 Test Loss 41.98666089533381\n",
      "344 Train Loss 1.4517831e-05 Test Loss 41.83183380437256\n",
      "345 Train Loss 1.4388777e-05 Test Loss 41.797248333415226\n",
      "346 Train Loss 1.4366846e-05 Test Loss 41.73823988055065\n",
      "347 Train Loss 1.4309197e-05 Test Loss 41.76459261005819\n",
      "348 Train Loss 1.4259111e-05 Test Loss 41.721319019708716\n",
      "349 Train Loss 1.40771235e-05 Test Loss 41.54175018493563\n",
      "350 Train Loss 1.3826722e-05 Test Loss 41.216044872388174\n",
      "351 Train Loss 1.3504285e-05 Test Loss 40.886617467074416\n",
      "352 Train Loss 1.3567081e-05 Test Loss 40.56704366388618\n",
      "353 Train Loss 1.333159e-05 Test Loss 40.72895218926406\n",
      "354 Train Loss 1.358513e-05 Test Loss 40.524054064240666\n",
      "355 Train Loss 1.3216489e-05 Test Loss 40.65051229570382\n",
      "356 Train Loss 1.31563775e-05 Test Loss 40.597841886773956\n",
      "357 Train Loss 1.311704e-05 Test Loss 40.64338226025464\n",
      "358 Train Loss 1.2992281e-05 Test Loss 40.58306239013533\n",
      "359 Train Loss 1.2870903e-05 Test Loss 40.47305698986421\n",
      "360 Train Loss 1.2726529e-05 Test Loss 40.36202719193397\n",
      "361 Train Loss 1.26817695e-05 Test Loss 40.28975765802504\n",
      "362 Train Loss 1.2647394e-05 Test Loss 40.29260727835623\n",
      "363 Train Loss 1.2608299e-05 Test Loss 40.23918298293487\n",
      "364 Train Loss 1.2575294e-05 Test Loss 40.27818590304677\n",
      "365 Train Loss 1.2533441e-05 Test Loss 40.4396278446749\n",
      "366 Train Loss 1.2526403e-05 Test Loss 40.452120395718005\n",
      "367 Train Loss 1.2519613e-05 Test Loss 40.44654569074736\n",
      "368 Train Loss 1.2512528e-05 Test Loss 40.461444750978636\n",
      "369 Train Loss 1.2503164e-05 Test Loss 40.481729435593685\n",
      "370 Train Loss 1.2492423e-05 Test Loss 40.49251303290303\n",
      "371 Train Loss 1.2465009e-05 Test Loss 40.50037783399708\n",
      "372 Train Loss 1.2408147e-05 Test Loss 40.5090650915038\n",
      "373 Train Loss 1.2330915e-05 Test Loss 40.532882776381854\n",
      "374 Train Loss 1.2213879e-05 Test Loss 40.56042656621122\n",
      "375 Train Loss 1.2069855e-05 Test Loss 40.520335334123594\n",
      "376 Train Loss 1.2135766e-05 Test Loss 40.67507091664299\n",
      "377 Train Loss 1.1965832e-05 Test Loss 40.59141989337711\n",
      "378 Train Loss 1.2163302e-05 Test Loss 40.39769687508818\n",
      "379 Train Loss 1.1834125e-05 Test Loss 40.50061913625541\n",
      "380 Train Loss 1.1641763e-05 Test Loss 40.326236588789364\n",
      "381 Train Loss 1.156438e-05 Test Loss 40.081337413502496\n",
      "382 Train Loss 1.14600625e-05 Test Loss 40.1811414509525\n",
      "383 Train Loss 1.1533433e-05 Test Loss 39.92974507282139\n",
      "384 Train Loss 1.1373644e-05 Test Loss 40.058055256402\n",
      "385 Train Loss 1.1269873e-05 Test Loss 40.04695604701886\n",
      "386 Train Loss 1.1194271e-05 Test Loss 40.01313294236881\n",
      "387 Train Loss 1.1135564e-05 Test Loss 40.037022732752746\n",
      "388 Train Loss 1.110579e-05 Test Loss 39.95258019989953\n",
      "389 Train Loss 1.10670035e-05 Test Loss 39.977794148342745\n",
      "390 Train Loss 1.1038682e-05 Test Loss 39.953694119076864\n",
      "391 Train Loss 1.0977323e-05 Test Loss 39.86988980462782\n",
      "392 Train Loss 1.0913493e-05 Test Loss 39.75039446156058\n",
      "393 Train Loss 1.0893855e-05 Test Loss 39.540419474931454\n",
      "394 Train Loss 1.0851135e-05 Test Loss 39.6328422151132\n",
      "395 Train Loss 1.0747457e-05 Test Loss 39.434816015105724\n",
      "396 Train Loss 1.103996e-05 Test Loss 39.15156722016893\n",
      "397 Train Loss 1.0692364e-05 Test Loss 39.33692063706705\n",
      "398 Train Loss 1.0586256e-05 Test Loss 39.10743727486702\n",
      "399 Train Loss 1.0467357e-05 Test Loss 39.11976399598142\n",
      "400 Train Loss 1.0363065e-05 Test Loss 38.98846711982134\n",
      "401 Train Loss 1.0320007e-05 Test Loss 38.85124573359726\n",
      "402 Train Loss 1.0291505e-05 Test Loss 38.80553735900505\n",
      "403 Train Loss 1.02903105e-05 Test Loss 38.833548176094745\n",
      "404 Train Loss 1.0276579e-05 Test Loss 38.81974962393995\n",
      "405 Train Loss 1.0240228e-05 Test Loss 38.82566675950148\n",
      "406 Train Loss 1.0185851e-05 Test Loss 38.77664944323042\n",
      "407 Train Loss 1.0072656e-05 Test Loss 38.721096940591345\n",
      "408 Train Loss 9.964931e-06 Test Loss 38.66364894890659\n",
      "409 Train Loss 9.895843e-06 Test Loss 38.724981770096626\n",
      "410 Train Loss 9.80973e-06 Test Loss 38.52999533656408\n",
      "411 Train Loss 9.842179e-06 Test Loss 38.478814133473094\n",
      "412 Train Loss 9.755119e-06 Test Loss 38.506777841443125\n",
      "413 Train Loss 9.684698e-06 Test Loss 38.494537292538745\n",
      "414 Train Loss 9.577694e-06 Test Loss 38.44500661047352\n",
      "415 Train Loss 9.539218e-06 Test Loss 38.30151636751664\n",
      "416 Train Loss 9.417951e-06 Test Loss 38.271357383544824\n",
      "417 Train Loss 9.341126e-06 Test Loss 38.26035361284622\n",
      "418 Train Loss 9.329042e-06 Test Loss 38.11911515994925\n",
      "419 Train Loss 9.299951e-06 Test Loss 38.177298761188155\n",
      "420 Train Loss 9.277062e-06 Test Loss 38.15610272777051\n",
      "421 Train Loss 9.259499e-06 Test Loss 38.133872322407825\n",
      "422 Train Loss 9.24001e-06 Test Loss 38.105517673285455\n",
      "423 Train Loss 9.214062e-06 Test Loss 38.0786208224902\n",
      "424 Train Loss 9.2284945e-06 Test Loss 37.87544870907427\n",
      "425 Train Loss 9.1617285e-06 Test Loss 37.96434744160455\n",
      "426 Train Loss 9.094801e-06 Test Loss 37.89540334182226\n",
      "427 Train Loss 9.059858e-06 Test Loss 37.895186030483586\n",
      "428 Train Loss 9.026653e-06 Test Loss 37.79074870790931\n",
      "429 Train Loss 9.0087e-06 Test Loss 37.824367464373005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430 Train Loss 8.976711e-06 Test Loss 37.80205707656634\n",
      "431 Train Loss 8.9373225e-06 Test Loss 37.8288581536147\n",
      "432 Train Loss 8.912785e-06 Test Loss 37.78815725793921\n",
      "433 Train Loss 8.863507e-06 Test Loss 37.80317822313429\n",
      "434 Train Loss 8.81673e-06 Test Loss 37.78980434776897\n",
      "435 Train Loss 8.867268e-06 Test Loss 37.715840053339825\n",
      "436 Train Loss 8.768528e-06 Test Loss 37.75177000010503\n",
      "437 Train Loss 8.717753e-06 Test Loss 37.73968878258234\n",
      "438 Train Loss 8.6811115e-06 Test Loss 37.73697206048291\n",
      "439 Train Loss 8.662959e-06 Test Loss 37.74951057914791\n",
      "440 Train Loss 8.704865e-06 Test Loss 37.720153600129805\n",
      "441 Train Loss 8.628082e-06 Test Loss 37.73634280003437\n",
      "442 Train Loss 8.615548e-06 Test Loss 37.69531931259739\n",
      "443 Train Loss 8.5916345e-06 Test Loss 37.718523790529915\n",
      "444 Train Loss 8.577414e-06 Test Loss 37.71842845237995\n",
      "445 Train Loss 8.54813e-06 Test Loss 37.721286519721765\n",
      "446 Train Loss 8.530056e-06 Test Loss 37.719965582709804\n",
      "447 Train Loss 8.501038e-06 Test Loss 37.72594367524163\n",
      "448 Train Loss 8.465563e-06 Test Loss 37.75711363171386\n",
      "449 Train Loss 8.476722e-06 Test Loss 37.8572139456541\n",
      "450 Train Loss 8.435123e-06 Test Loss 37.80054431855758\n",
      "451 Train Loss 8.4173535e-06 Test Loss 37.84754770171548\n",
      "452 Train Loss 8.409499e-06 Test Loss 37.83309917509993\n",
      "453 Train Loss 8.364914e-06 Test Loss 37.849868642922004\n",
      "454 Train Loss 8.250102e-06 Test Loss 37.88281347047331\n",
      "455 Train Loss 8.218172e-06 Test Loss 37.906454929916336\n",
      "456 Train Loss 8.319771e-06 Test Loss 37.885082866567544\n",
      "457 Train Loss 8.193647e-06 Test Loss 37.899783655314884\n",
      "458 Train Loss 8.173807e-06 Test Loss 37.92098143758827\n",
      "459 Train Loss 8.152505e-06 Test Loss 37.92630992105319\n",
      "460 Train Loss 8.123279e-06 Test Loss 37.92007803536536\n",
      "461 Train Loss 8.087625e-06 Test Loss 37.90759852664234\n",
      "462 Train Loss 8.062119e-06 Test Loss 37.88937490371514\n",
      "463 Train Loss 8.011476e-06 Test Loss 37.84477399048004\n",
      "464 Train Loss 7.950119e-06 Test Loss 37.82070387036542\n",
      "465 Train Loss 7.909103e-06 Test Loss 37.76250467123944\n",
      "466 Train Loss 7.8345165e-06 Test Loss 37.736653386949804\n",
      "467 Train Loss 7.763125e-06 Test Loss 37.645119097834495\n",
      "468 Train Loss 7.776527e-06 Test Loss 37.53166725122514\n",
      "469 Train Loss 7.733946e-06 Test Loss 37.58640222372395\n",
      "470 Train Loss 7.701312e-06 Test Loss 37.50539042125585\n",
      "471 Train Loss 7.718345e-06 Test Loss 37.49582833266344\n",
      "472 Train Loss 7.6803135e-06 Test Loss 37.50124782500179\n",
      "473 Train Loss 7.674866e-06 Test Loss 37.50349644474148\n",
      "474 Train Loss 7.666329e-06 Test Loss 37.52970130883497\n",
      "475 Train Loss 7.66053e-06 Test Loss 37.54280499529878\n",
      "476 Train Loss 7.654997e-06 Test Loss 37.55142893808604\n",
      "477 Train Loss 7.650471e-06 Test Loss 37.55362426793463\n",
      "478 Train Loss 7.645995e-06 Test Loss 37.54148978479881\n",
      "479 Train Loss 7.639793e-06 Test Loss 37.54217512046426\n",
      "480 Train Loss 7.633413e-06 Test Loss 37.5333961667993\n",
      "481 Train Loss 7.6273136e-06 Test Loss 37.527188200153276\n",
      "482 Train Loss 7.613147e-06 Test Loss 37.524437002468055\n",
      "483 Train Loss 7.5901908e-06 Test Loss 37.52031889649901\n",
      "484 Train Loss 7.5355847e-06 Test Loss 37.545124380217985\n",
      "485 Train Loss 7.4684613e-06 Test Loss 37.58018256130386\n",
      "486 Train Loss 7.4376876e-06 Test Loss 37.621050046362264\n",
      "487 Train Loss 7.416709e-06 Test Loss 37.64913986254018\n",
      "488 Train Loss 7.4035524e-06 Test Loss 37.65101624644609\n",
      "489 Train Loss 7.389476e-06 Test Loss 37.69375586255927\n",
      "490 Train Loss 7.3673427e-06 Test Loss 37.75106707616109\n",
      "491 Train Loss 7.3368246e-06 Test Loss 37.841455545281526\n",
      "492 Train Loss 7.3076076e-06 Test Loss 37.89807838103638\n",
      "493 Train Loss 7.295719e-06 Test Loss 38.01022800724315\n",
      "494 Train Loss 7.2847697e-06 Test Loss 37.96975485237654\n",
      "495 Train Loss 7.289998e-06 Test Loss 38.012418468670226\n",
      "496 Train Loss 7.2697394e-06 Test Loss 37.990233530177\n",
      "497 Train Loss 7.2460016e-06 Test Loss 38.00263504808879\n",
      "498 Train Loss 7.2322973e-06 Test Loss 38.0939235865055\n",
      "499 Train Loss 7.212182e-06 Test Loss 38.093950055606946\n",
      "500 Train Loss 7.2083385e-06 Test Loss 38.184809975326495\n",
      "501 Train Loss 7.1983577e-06 Test Loss 38.14457033343354\n",
      "502 Train Loss 7.1667423e-06 Test Loss 38.23629105627518\n",
      "503 Train Loss 7.1358963e-06 Test Loss 38.41833981095185\n",
      "504 Train Loss 7.12408e-06 Test Loss 38.480085423384566\n",
      "505 Train Loss 7.093052e-06 Test Loss 38.55007982563355\n",
      "506 Train Loss 7.0815368e-06 Test Loss 38.49471180506559\n",
      "507 Train Loss 7.021885e-06 Test Loss 38.569964279424305\n",
      "508 Train Loss 7.0009464e-06 Test Loss 38.71060872482017\n",
      "509 Train Loss 6.9558873e-06 Test Loss 38.764424017224\n",
      "510 Train Loss 6.9344587e-06 Test Loss 38.63583855703267\n",
      "511 Train Loss 6.877564e-06 Test Loss 38.756301853534495\n",
      "512 Train Loss 6.8619893e-06 Test Loss 38.92537902772098\n",
      "513 Train Loss 6.803975e-06 Test Loss 38.87668894200256\n",
      "514 Train Loss 6.7556666e-06 Test Loss 38.88605302725823\n",
      "515 Train Loss 6.719411e-06 Test Loss 39.047508589911885\n",
      "516 Train Loss 6.6640373e-06 Test Loss 39.10233037303321\n",
      "517 Train Loss 6.64732e-06 Test Loss 39.10636342105665\n",
      "518 Train Loss 6.627163e-06 Test Loss 39.197433970058896\n",
      "519 Train Loss 6.593935e-06 Test Loss 39.16728049775129\n",
      "520 Train Loss 6.5551285e-06 Test Loss 39.233438479139956\n",
      "521 Train Loss 6.5034146e-06 Test Loss 39.33923001170661\n",
      "522 Train Loss 6.499883e-06 Test Loss 39.47018621617817\n",
      "523 Train Loss 6.475576e-06 Test Loss 39.41305001517148\n",
      "524 Train Loss 6.46984e-06 Test Loss 39.444352094915054\n",
      "525 Train Loss 6.4223946e-06 Test Loss 39.4871201431698\n",
      "526 Train Loss 6.4167375e-06 Test Loss 39.42001834314468\n",
      "527 Train Loss 6.3818284e-06 Test Loss 39.459338689827995\n",
      "528 Train Loss 6.36296e-06 Test Loss 39.510562604438164\n",
      "529 Train Loss 6.337412e-06 Test Loss 39.50520264800782\n",
      "530 Train Loss 6.3093707e-06 Test Loss 39.528909242049075\n",
      "531 Train Loss 6.285097e-06 Test Loss 39.558086015030874\n",
      "532 Train Loss 6.263709e-06 Test Loss 39.55596029364354\n",
      "533 Train Loss 6.233502e-06 Test Loss 39.56183280311519\n",
      "534 Train Loss 6.2163526e-06 Test Loss 39.56819796988852\n",
      "535 Train Loss 6.205356e-06 Test Loss 39.52884817147288\n",
      "536 Train Loss 6.19047e-06 Test Loss 39.529066935172594\n",
      "537 Train Loss 6.1719966e-06 Test Loss 39.53224283164993\n",
      "538 Train Loss 6.1326305e-06 Test Loss 39.5460374040001\n",
      "539 Train Loss 6.080222e-06 Test Loss 39.527417777623114\n",
      "540 Train Loss 6.6286148e-06 Test Loss 39.53068197872864\n",
      "541 Train Loss 6.0375905e-06 Test Loss 39.52837431924875\n",
      "542 Train Loss 5.961111e-06 Test Loss 39.487879516679826\n",
      "543 Train Loss 5.9178114e-06 Test Loss 39.425379611111666\n",
      "544 Train Loss 5.9229524e-06 Test Loss 39.425917307098274\n",
      "545 Train Loss 5.8679357e-06 Test Loss 39.42526675186355\n",
      "546 Train Loss 5.858429e-06 Test Loss 39.41753459731516\n",
      "547 Train Loss 5.8984597e-06 Test Loss 39.432064741593365\n",
      "548 Train Loss 5.827568e-06 Test Loss 39.42342638669412\n",
      "549 Train Loss 5.8157757e-06 Test Loss 39.43824905274858\n",
      "550 Train Loss 5.797179e-06 Test Loss 39.41820797625891\n",
      "551 Train Loss 5.785633e-06 Test Loss 39.40112195179747\n",
      "552 Train Loss 5.770708e-06 Test Loss 39.380407468198776\n",
      "553 Train Loss 5.745374e-06 Test Loss 39.34890539393879\n",
      "554 Train Loss 5.7389734e-06 Test Loss 39.347582377617215\n",
      "555 Train Loss 5.7336683e-06 Test Loss 39.35262070983408\n",
      "556 Train Loss 5.7247057e-06 Test Loss 39.37614923031313\n",
      "557 Train Loss 5.719953e-06 Test Loss 39.37465060964383\n",
      "558 Train Loss 5.7115085e-06 Test Loss 39.37860582163635\n",
      "559 Train Loss 5.704852e-06 Test Loss 39.38094356798057\n",
      "560 Train Loss 5.693316e-06 Test Loss 39.39348235859946\n",
      "561 Train Loss 5.6794643e-06 Test Loss 39.415099675115464\n",
      "562 Train Loss 5.6720196e-06 Test Loss 39.443976022568116\n",
      "563 Train Loss 5.65839e-06 Test Loss 39.45453441387775\n",
      "564 Train Loss 5.647121e-06 Test Loss 39.46834004203722\n",
      "565 Train Loss 5.628582e-06 Test Loss 39.49499393100589\n",
      "566 Train Loss 5.607827e-06 Test Loss 39.52938403246206\n",
      "567 Train Loss 5.6118597e-06 Test Loss 39.66417493851937\n",
      "568 Train Loss 5.575729e-06 Test Loss 39.5998561422862\n",
      "569 Train Loss 5.521286e-06 Test Loss 39.67203526501692\n",
      "570 Train Loss 5.4856473e-06 Test Loss 39.73870835935841\n",
      "571 Train Loss 5.460576e-06 Test Loss 39.865810568441994\n",
      "572 Train Loss 5.3953763e-06 Test Loss 39.81582594197192\n",
      "573 Train Loss 5.3047906e-06 Test Loss 39.750439896171955\n",
      "574 Train Loss 5.2123632e-06 Test Loss 39.70830376223088\n",
      "575 Train Loss 5.151037e-06 Test Loss 39.74319394751611\n",
      "576 Train Loss 5.1646166e-06 Test Loss 39.71978681346943\n",
      "577 Train Loss 5.092911e-06 Test Loss 39.73188830933695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578 Train Loss 5.876069e-06 Test Loss 39.848584105153684\n",
      "579 Train Loss 5.0591625e-06 Test Loss 39.76053267518954\n",
      "580 Train Loss 5.0087947e-06 Test Loss 39.780025545412364\n",
      "581 Train Loss 4.952517e-06 Test Loss 39.78015558331626\n",
      "582 Train Loss 4.887781e-06 Test Loss 39.86090709343962\n",
      "583 Train Loss 4.9185055e-06 Test Loss 39.91301564019909\n",
      "584 Train Loss 4.8446127e-06 Test Loss 39.88530889850922\n",
      "585 Train Loss 4.772471e-06 Test Loss 39.981366650053836\n",
      "586 Train Loss 4.6976093e-06 Test Loss 40.02668341976769\n",
      "587 Train Loss 4.6922837e-06 Test Loss 40.098244216508164\n",
      "588 Train Loss 4.6657055e-06 Test Loss 40.06400747051054\n",
      "589 Train Loss 4.740748e-06 Test Loss 40.193625672713225\n",
      "590 Train Loss 4.643604e-06 Test Loss 40.11355104842127\n",
      "591 Train Loss 4.662279e-06 Test Loss 40.161160782460065\n",
      "592 Train Loss 4.630921e-06 Test Loss 40.13183472549379\n",
      "593 Train Loss 4.618497e-06 Test Loss 40.144046559556\n",
      "594 Train Loss 4.600769e-06 Test Loss 40.18590475436105\n",
      "595 Train Loss 4.580716e-06 Test Loss 40.187387294956075\n",
      "596 Train Loss 4.563258e-06 Test Loss 40.173063358306564\n",
      "597 Train Loss 4.5464403e-06 Test Loss 40.12638147185588\n",
      "598 Train Loss 4.5274173e-06 Test Loss 40.12694500157018\n",
      "599 Train Loss 4.5165984e-06 Test Loss 40.116064908597\n",
      "600 Train Loss 4.483562e-06 Test Loss 40.108470441738994\n",
      "601 Train Loss 4.458904e-06 Test Loss 40.12141808625023\n",
      "602 Train Loss 4.4320905e-06 Test Loss 40.11688132927769\n",
      "603 Train Loss 4.41953e-06 Test Loss 40.12097390944812\n",
      "604 Train Loss 4.390639e-06 Test Loss 40.054754084089325\n",
      "605 Train Loss 4.3748573e-06 Test Loss 40.01590325738111\n",
      "606 Train Loss 4.373712e-06 Test Loss 39.95469284622629\n",
      "607 Train Loss 4.360623e-06 Test Loss 39.982196298983034\n",
      "608 Train Loss 4.346147e-06 Test Loss 39.94718338812885\n",
      "609 Train Loss 4.3379937e-06 Test Loss 39.959811440043175\n",
      "610 Train Loss 4.332661e-06 Test Loss 39.96689951628252\n",
      "611 Train Loss 4.3275845e-06 Test Loss 39.95660959627093\n",
      "612 Train Loss 4.323493e-06 Test Loss 39.93964949361367\n",
      "613 Train Loss 4.3192827e-06 Test Loss 39.909762616192445\n",
      "614 Train Loss 4.3104446e-06 Test Loss 39.8649045782018\n",
      "615 Train Loss 4.3012924e-06 Test Loss 39.758811767744575\n",
      "616 Train Loss 4.2771326e-06 Test Loss 39.71263550434502\n",
      "617 Train Loss 4.2621623e-06 Test Loss 39.580642482012834\n",
      "618 Train Loss 4.2513902e-06 Test Loss 39.55226882099414\n",
      "619 Train Loss 4.268376e-06 Test Loss 39.57108166382236\n",
      "620 Train Loss 4.2466518e-06 Test Loss 39.558168704419316\n",
      "621 Train Loss 4.237543e-06 Test Loss 39.45837563317035\n",
      "622 Train Loss 4.232036e-06 Test Loss 39.414552987346894\n",
      "623 Train Loss 4.2230668e-06 Test Loss 39.40777346058504\n",
      "624 Train Loss 4.2055617e-06 Test Loss 39.269194215899034\n",
      "625 Train Loss 4.1908943e-06 Test Loss 39.22757217913392\n",
      "626 Train Loss 4.1765957e-06 Test Loss 39.15747939948924\n",
      "627 Train Loss 4.1638805e-06 Test Loss 39.09969347931934\n",
      "628 Train Loss 4.1844787e-06 Test Loss 39.112420371431185\n",
      "629 Train Loss 4.1552585e-06 Test Loss 39.104202541026034\n",
      "630 Train Loss 4.156324e-06 Test Loss 38.967468947111094\n",
      "631 Train Loss 4.144192e-06 Test Loss 39.030225113277076\n",
      "632 Train Loss 4.134111e-06 Test Loss 38.98637337213437\n",
      "633 Train Loss 4.1237995e-06 Test Loss 38.938741693718804\n",
      "634 Train Loss 4.1140233e-06 Test Loss 38.88264879959168\n",
      "635 Train Loss 4.107669e-06 Test Loss 38.84124607907497\n",
      "636 Train Loss 4.124364e-06 Test Loss 38.7065959732071\n",
      "637 Train Loss 4.1052817e-06 Test Loss 38.797635028134465\n",
      "638 Train Loss 4.101066e-06 Test Loss 38.77653149668147\n",
      "639 Train Loss 4.094488e-06 Test Loss 38.732125576761284\n",
      "640 Train Loss 4.0877117e-06 Test Loss 38.65535263227008\n",
      "641 Train Loss 4.0768696e-06 Test Loss 38.62789216840579\n",
      "642 Train Loss 4.067603e-06 Test Loss 38.50193563641185\n",
      "643 Train Loss 4.053097e-06 Test Loss 38.499437994901776\n",
      "644 Train Loss 4.0450964e-06 Test Loss 38.48411948978265\n",
      "645 Train Loss 4.0347086e-06 Test Loss 38.40646653977388\n",
      "646 Train Loss 4.0236173e-06 Test Loss 38.36658641536707\n",
      "647 Train Loss 4.007782e-06 Test Loss 38.3543211038616\n",
      "648 Train Loss 4.0000655e-06 Test Loss 38.28590411574352\n",
      "649 Train Loss 3.992805e-06 Test Loss 38.28118683768509\n",
      "650 Train Loss 3.982303e-06 Test Loss 38.24096017154603\n",
      "651 Train Loss 3.965416e-06 Test Loss 38.11582273886797\n",
      "652 Train Loss 3.9676097e-06 Test Loss 37.94069148173848\n",
      "653 Train Loss 3.9408587e-06 Test Loss 38.02505037225465\n",
      "654 Train Loss 3.9051183e-06 Test Loss 37.95357221955185\n",
      "655 Train Loss 3.830446e-06 Test Loss 37.8121395711973\n",
      "656 Train Loss 8.01385e-06 Test Loss 37.267052682681985\n",
      "657 Train Loss 3.824712e-06 Test Loss 37.72837745217075\n",
      "658 Train Loss 3.817927e-06 Test Loss 37.76120794581311\n",
      "659 Train Loss 3.938225e-06 Test Loss 37.66221797343747\n",
      "660 Train Loss 3.799364e-06 Test Loss 37.7338020650092\n",
      "661 Train Loss 3.804091e-06 Test Loss 37.74010321920948\n",
      "662 Train Loss 3.7873192e-06 Test Loss 37.73669786885579\n",
      "663 Train Loss 3.767504e-06 Test Loss 37.728123449966226\n",
      "664 Train Loss 3.7461018e-06 Test Loss 37.68177088961525\n",
      "665 Train Loss 3.72339e-06 Test Loss 37.67268046818671\n",
      "666 Train Loss 3.7049165e-06 Test Loss 37.64255328814866\n",
      "667 Train Loss 3.6934848e-06 Test Loss 37.67875250772726\n",
      "668 Train Loss 3.6721985e-06 Test Loss 37.66321236548126\n",
      "669 Train Loss 3.6585939e-06 Test Loss 37.67046543122201\n",
      "670 Train Loss 3.634098e-06 Test Loss 37.75137202246754\n",
      "671 Train Loss 3.6182932e-06 Test Loss 37.80010720217038\n",
      "672 Train Loss 3.5759135e-06 Test Loss 37.85148878819444\n",
      "673 Train Loss 3.526747e-06 Test Loss 37.91862183010872\n",
      "674 Train Loss 3.4873428e-06 Test Loss 37.94489263511034\n",
      "675 Train Loss 5.364349e-06 Test Loss 38.24778717372782\n",
      "676 Train Loss 3.4778327e-06 Test Loss 38.00895900070166\n",
      "677 Train Loss 3.449131e-06 Test Loss 38.00185509814778\n",
      "678 Train Loss 3.4488935e-06 Test Loss 38.0028045181016\n",
      "679 Train Loss 3.4372363e-06 Test Loss 38.00228592675649\n",
      "680 Train Loss 3.4275433e-06 Test Loss 38.01474161324528\n",
      "681 Train Loss 3.430745e-06 Test Loss 38.05284431497943\n",
      "682 Train Loss 3.423826e-06 Test Loss 38.0323001932013\n",
      "683 Train Loss 3.419319e-06 Test Loss 38.04108995977885\n",
      "684 Train Loss 3.4160657e-06 Test Loss 38.05714800243119\n",
      "685 Train Loss 3.4110894e-06 Test Loss 38.08574374064568\n",
      "686 Train Loss 3.4062614e-06 Test Loss 38.11386378887272\n",
      "687 Train Loss 3.3962333e-06 Test Loss 38.17353307342847\n",
      "688 Train Loss 3.3818574e-06 Test Loss 38.24609017822548\n",
      "689 Train Loss 3.3711387e-06 Test Loss 38.41018686410744\n",
      "690 Train Loss 3.3422766e-06 Test Loss 38.48751685029188\n",
      "691 Train Loss 3.3267838e-06 Test Loss 38.475287172674996\n",
      "692 Train Loss 3.3217254e-06 Test Loss 38.51950537472982\n",
      "693 Train Loss 3.314376e-06 Test Loss 38.479666724852926\n",
      "694 Train Loss 3.3118224e-06 Test Loss 38.481068609560424\n",
      "695 Train Loss 3.3091474e-06 Test Loss 38.49772479320215\n",
      "696 Train Loss 3.306357e-06 Test Loss 38.49382797923007\n",
      "697 Train Loss 3.2965856e-06 Test Loss 38.541546111210714\n",
      "698 Train Loss 3.2861938e-06 Test Loss 38.55203033443179\n",
      "699 Train Loss 3.2617531e-06 Test Loss 38.6001939966026\n",
      "700 Train Loss 3.2360406e-06 Test Loss 38.60327487391991\n",
      "701 Train Loss 3.240144e-06 Test Loss 38.71736513748156\n",
      "702 Train Loss 3.2207613e-06 Test Loss 38.663471505640786\n",
      "703 Train Loss 3.1582006e-06 Test Loss 38.70918301724566\n",
      "704 Train Loss 3.2159364e-06 Test Loss 38.725000928063\n",
      "705 Train Loss 3.1164568e-06 Test Loss 38.7165875948227\n",
      "706 Train Loss 3.1308139e-06 Test Loss 38.7886406976914\n",
      "707 Train Loss 3.090275e-06 Test Loss 38.748693249428996\n",
      "708 Train Loss 3.0731317e-06 Test Loss 38.81028104929152\n",
      "709 Train Loss 3.0754145e-06 Test Loss 38.75661238239884\n",
      "710 Train Loss 3.0588683e-06 Test Loss 38.78536806776426\n",
      "711 Train Loss 3.0783647e-06 Test Loss 38.80247508491839\n",
      "712 Train Loss 3.048499e-06 Test Loss 38.79160202023384\n",
      "713 Train Loss 3.0429062e-06 Test Loss 38.800180924573\n",
      "714 Train Loss 3.0369888e-06 Test Loss 38.8320957033983\n",
      "715 Train Loss 3.0335518e-06 Test Loss 38.83882655249024\n",
      "716 Train Loss 3.030626e-06 Test Loss 38.847645489261325\n",
      "717 Train Loss 3.0273231e-06 Test Loss 38.86281240155811\n",
      "718 Train Loss 3.0232572e-06 Test Loss 38.87965323639406\n",
      "719 Train Loss 3.0189876e-06 Test Loss 38.89403671096728\n",
      "720 Train Loss 3.0106412e-06 Test Loss 38.91405946688239\n",
      "721 Train Loss 3.007472e-06 Test Loss 38.961799911255234\n",
      "722 Train Loss 3.0033775e-06 Test Loss 38.94386919976307\n",
      "723 Train Loss 2.9867713e-06 Test Loss 38.98610914039696\n",
      "724 Train Loss 2.969009e-06 Test Loss 38.982393799188024\n",
      "725 Train Loss 3.0735778e-06 Test Loss 39.024230759478264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726 Train Loss 2.9554617e-06 Test Loss 38.99497607941864\n",
      "727 Train Loss 2.942696e-06 Test Loss 39.026350764892854\n",
      "728 Train Loss 2.9412236e-06 Test Loss 39.022889651251354\n",
      "729 Train Loss 2.9332557e-06 Test Loss 39.02512870993604\n",
      "730 Train Loss 2.9331723e-06 Test Loss 39.02706103103977\n",
      "731 Train Loss 2.9327412e-06 Test Loss 39.02614151177195\n",
      "732 Train Loss 2.9320342e-06 Test Loss 39.02722149749149\n",
      "733 Train Loss 2.9313082e-06 Test Loss 39.028739047730795\n",
      "734 Train Loss 2.9308399e-06 Test Loss 39.027230927644375\n",
      "735 Train Loss 2.9307018e-06 Test Loss 39.02594884958907\n",
      "736 Train Loss 2.9297375e-06 Test Loss 39.02052356748781\n",
      "737 Train Loss 2.9289704e-06 Test Loss 39.015764819011004\n",
      "738 Train Loss 2.927581e-06 Test Loss 39.00658067059556\n",
      "739 Train Loss 2.926515e-06 Test Loss 38.998474201835954\n",
      "740 Train Loss 2.9250773e-06 Test Loss 38.992786872867164\n",
      "741 Train Loss 2.9237785e-06 Test Loss 38.99049760643752\n",
      "742 Train Loss 2.923252e-06 Test Loss 38.98451085825135\n",
      "743 Train Loss 2.9222526e-06 Test Loss 38.98224485200463\n",
      "744 Train Loss 2.921346e-06 Test Loss 38.97285486775975\n",
      "745 Train Loss 2.919563e-06 Test Loss 38.94272768033602\n",
      "746 Train Loss 2.9153412e-06 Test Loss 38.8829325103451\n",
      "747 Train Loss 2.9091016e-06 Test Loss 38.79462265348872\n",
      "748 Train Loss 3.3355e-06 Test Loss 38.463297812465235\n",
      "749 Train Loss 2.9040878e-06 Test Loss 38.68511158849091\n",
      "750 Train Loss 2.9021494e-06 Test Loss 38.71572386551292\n",
      "751 Train Loss 2.8992356e-06 Test Loss 38.62234641942543\n",
      "752 Train Loss 2.8963186e-06 Test Loss 38.65718567535082\n",
      "753 Train Loss 2.8948616e-06 Test Loss 38.653168506158096\n",
      "754 Train Loss 2.889188e-06 Test Loss 38.65500976334233\n",
      "755 Train Loss 2.8788452e-06 Test Loss 38.573130875641134\n",
      "756 Train Loss 2.889908e-06 Test Loss 38.285011448073185\n",
      "757 Train Loss 2.8672443e-06 Test Loss 38.42672922892591\n",
      "758 Train Loss 2.868197e-06 Test Loss 38.29548573740077\n",
      "759 Train Loss 2.8600377e-06 Test Loss 38.358262677010195\n",
      "760 Train Loss 2.8565312e-06 Test Loss 38.196866990010804\n",
      "761 Train Loss 2.8512818e-06 Test Loss 38.26284588881524\n",
      "762 Train Loss 2.8370619e-06 Test Loss 38.152928196603625\n",
      "763 Train Loss 2.8315937e-06 Test Loss 38.11141371611259\n",
      "764 Train Loss 2.8270192e-06 Test Loss 38.02705143213772\n",
      "765 Train Loss 2.8334111e-06 Test Loss 38.045844541400605\n",
      "766 Train Loss 2.8244106e-06 Test Loss 38.03352510354\n",
      "767 Train Loss 2.8205257e-06 Test Loss 37.995852504954726\n",
      "768 Train Loss 2.8177653e-06 Test Loss 37.90210071072415\n",
      "769 Train Loss 2.814509e-06 Test Loss 37.86902575554262\n",
      "770 Train Loss 2.811698e-06 Test Loss 37.84247936289145\n",
      "771 Train Loss 2.8098561e-06 Test Loss 37.77053627914216\n",
      "772 Train Loss 2.8079576e-06 Test Loss 37.78440294008692\n",
      "773 Train Loss 2.806607e-06 Test Loss 37.75793245612944\n",
      "774 Train Loss 2.8045192e-06 Test Loss 37.718954695180344\n",
      "775 Train Loss 2.8024385e-06 Test Loss 37.67640300439765\n",
      "776 Train Loss 2.8003012e-06 Test Loss 37.6587332840971\n",
      "777 Train Loss 2.798647e-06 Test Loss 37.59722555529418\n",
      "778 Train Loss 2.796542e-06 Test Loss 37.55626212957258\n",
      "779 Train Loss 2.7938388e-06 Test Loss 37.49136278910322\n",
      "780 Train Loss 2.7895335e-06 Test Loss 37.40889701921618\n",
      "781 Train Loss 2.783176e-06 Test Loss 37.27978370408748\n",
      "782 Train Loss 2.7787994e-06 Test Loss 37.16833304411026\n",
      "783 Train Loss 3.8952307e-06 Test Loss 36.4850166827862\n",
      "784 Train Loss 2.7779895e-06 Test Loss 36.9775515828304\n",
      "785 Train Loss 2.7722053e-06 Test Loss 37.05406931871472\n",
      "786 Train Loss 2.7738104e-06 Test Loss 36.899267761145055\n",
      "787 Train Loss 2.7658343e-06 Test Loss 36.97523283317228\n",
      "788 Train Loss 2.7642604e-06 Test Loss 37.01895778346797\n",
      "789 Train Loss 2.748905e-06 Test Loss 36.97696357719101\n",
      "790 Train Loss 2.7974852e-06 Test Loss 36.74132479976488\n",
      "791 Train Loss 2.7423291e-06 Test Loss 36.89446505999127\n",
      "792 Train Loss 2.7309948e-06 Test Loss 36.874251270414035\n",
      "793 Train Loss 2.7135493e-06 Test Loss 36.83178764091111\n",
      "794 Train Loss 2.6969442e-06 Test Loss 36.74475736994941\n",
      "795 Train Loss 2.7089268e-06 Test Loss 36.78488164980884\n",
      "796 Train Loss 2.6855353e-06 Test Loss 36.76117481762065\n",
      "797 Train Loss 2.6737296e-06 Test Loss 36.66496385439313\n",
      "798 Train Loss 2.6662249e-06 Test Loss 36.671936498291956\n",
      "799 Train Loss 2.6620728e-06 Test Loss 36.680950085974516\n",
      "800 Train Loss 2.65222e-06 Test Loss 36.63556004942899\n",
      "801 Train Loss 2.647248e-06 Test Loss 36.623084828772015\n",
      "802 Train Loss 2.6410926e-06 Test Loss 36.596651141506726\n",
      "803 Train Loss 2.6333278e-06 Test Loss 36.564722850867476\n",
      "804 Train Loss 2.6299958e-06 Test Loss 36.534224171663226\n",
      "805 Train Loss 2.628873e-06 Test Loss 36.53902631081451\n",
      "806 Train Loss 2.6251764e-06 Test Loss 36.51739518442902\n",
      "807 Train Loss 2.6239863e-06 Test Loss 36.519620237625745\n",
      "808 Train Loss 2.6234752e-06 Test Loss 36.51458862765745\n",
      "809 Train Loss 2.621233e-06 Test Loss 36.49405920897391\n",
      "810 Train Loss 2.6183152e-06 Test Loss 36.461867870939024\n",
      "811 Train Loss 2.6113967e-06 Test Loss 36.38166245516851\n",
      "812 Train Loss 2.6030252e-06 Test Loss 36.296354797563225\n",
      "813 Train Loss 2.5890654e-06 Test Loss 36.19634476455397\n",
      "814 Train Loss 2.9819466e-06 Test Loss 35.8311896169526\n",
      "815 Train Loss 2.5846261e-06 Test Loss 36.12670235861343\n",
      "816 Train Loss 2.5751797e-06 Test Loss 36.04795942794758\n",
      "817 Train Loss 2.5991853e-06 Test Loss 36.011319935817106\n",
      "818 Train Loss 2.5721365e-06 Test Loss 36.03854736586016\n",
      "819 Train Loss 2.5681823e-06 Test Loss 35.9306628471031\n",
      "820 Train Loss 2.5650127e-06 Test Loss 35.9340498563601\n",
      "821 Train Loss 2.5627774e-06 Test Loss 35.90972559664371\n",
      "822 Train Loss 2.5602747e-06 Test Loss 35.86345854458041\n",
      "823 Train Loss 2.5583292e-06 Test Loss 35.847112014226475\n",
      "824 Train Loss 2.5558343e-06 Test Loss 35.78893123221801\n",
      "825 Train Loss 2.5511229e-06 Test Loss 35.821908209735504\n",
      "826 Train Loss 2.548144e-06 Test Loss 35.78650821991328\n",
      "827 Train Loss 2.5435393e-06 Test Loss 35.77063829568613\n",
      "828 Train Loss 2.5386971e-06 Test Loss 35.76076863822252\n",
      "829 Train Loss 2.5354573e-06 Test Loss 35.788124675580875\n",
      "830 Train Loss 2.5405232e-06 Test Loss 35.74742988846469\n",
      "831 Train Loss 2.5331235e-06 Test Loss 35.77151707101059\n",
      "832 Train Loss 2.5340162e-06 Test Loss 35.761797774962126\n",
      "833 Train Loss 2.5315155e-06 Test Loss 35.767280382830876\n",
      "834 Train Loss 2.5306972e-06 Test Loss 35.769537137107925\n",
      "835 Train Loss 2.5303098e-06 Test Loss 35.77207146241001\n",
      "836 Train Loss 2.5299412e-06 Test Loss 35.773581181002484\n",
      "837 Train Loss 2.5294862e-06 Test Loss 35.77209448861573\n",
      "838 Train Loss 2.529065e-06 Test Loss 35.76672695534025\n",
      "839 Train Loss 2.528385e-06 Test Loss 35.75494675263953\n",
      "840 Train Loss 2.5272839e-06 Test Loss 35.74348250977691\n",
      "841 Train Loss 2.5261415e-06 Test Loss 35.7189235749789\n",
      "842 Train Loss 2.5239717e-06 Test Loss 35.70053590636336\n",
      "843 Train Loss 2.5224845e-06 Test Loss 35.67780945782561\n",
      "844 Train Loss 2.5219877e-06 Test Loss 35.672743185669354\n",
      "845 Train Loss 2.5215131e-06 Test Loss 35.65380347448119\n",
      "846 Train Loss 2.5210993e-06 Test Loss 35.65774194052105\n",
      "847 Train Loss 2.5208653e-06 Test Loss 35.651021632702424\n",
      "848 Train Loss 2.520897e-06 Test Loss 35.643696119556765\n",
      "849 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "850 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "851 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "852 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "853 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "854 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "855 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "856 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "857 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "858 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "859 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "860 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "861 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "862 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "863 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "864 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "865 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "866 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "867 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "868 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "869 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "871 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "872 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "873 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "874 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "875 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "876 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "877 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "878 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "879 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "880 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "881 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "882 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "883 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "884 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "885 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "886 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "887 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "888 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "889 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "890 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "891 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "892 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "893 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "894 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "895 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "896 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "897 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "898 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "899 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "900 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "901 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "902 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "903 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "904 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "905 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "906 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "907 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "908 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "909 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "910 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "911 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "912 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "913 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "914 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "915 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "916 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "917 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "918 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "919 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "920 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "921 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "922 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "923 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "924 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "925 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "926 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "927 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "928 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "929 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "930 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "931 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "932 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "933 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "934 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "935 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "936 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "937 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "938 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "939 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "940 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "941 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "942 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "943 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "944 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "945 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "946 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "947 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "948 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "949 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "950 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "951 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "952 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "953 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "954 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "955 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "956 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "957 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "958 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "959 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "960 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "961 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "962 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "963 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "964 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "965 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "966 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "967 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "968 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "969 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "970 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "971 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "972 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "973 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "974 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "975 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "976 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "977 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "978 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "979 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "980 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "981 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "982 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "983 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "984 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "985 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "986 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "987 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "988 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "989 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "990 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "991 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "992 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "993 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "994 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "995 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "996 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "997 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "998 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "999 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1000 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1001 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1002 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1003 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1004 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1005 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1006 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1007 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1008 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1009 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1010 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1011 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1012 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1013 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1015 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1016 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1017 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1018 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1019 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1020 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1021 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1022 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1023 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1024 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1025 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1026 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1027 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1028 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1029 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1030 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1031 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1032 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1033 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1034 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1035 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1036 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1037 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1038 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1039 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1040 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1041 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1042 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1043 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1044 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1045 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1046 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1047 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1048 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1049 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1050 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1051 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1052 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1053 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1054 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1055 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1056 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1057 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1058 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1059 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1060 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1061 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1062 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1063 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1064 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1065 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1066 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1067 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1068 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1069 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1070 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1071 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1072 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1073 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1074 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1075 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1076 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1077 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1078 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1079 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1080 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1081 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1082 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1083 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1084 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1085 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1086 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1087 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1088 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1089 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1090 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1091 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1092 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1093 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1094 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1095 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1096 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1097 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1098 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1099 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1100 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1101 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1102 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1103 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1104 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1105 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1106 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1107 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1108 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1109 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1110 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1111 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1112 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1113 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1114 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1115 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1116 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1117 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1118 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1119 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1120 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1121 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1122 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1123 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1124 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1125 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1126 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1127 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1128 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1129 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1130 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1131 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1132 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1133 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1134 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1135 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1136 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1137 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1138 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1139 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1140 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1141 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1142 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1143 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1144 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1145 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1146 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1147 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1148 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1149 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1150 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1151 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1152 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1153 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1154 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1155 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1156 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1157 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1158 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1159 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1161 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1162 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1163 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1164 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1165 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1166 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1167 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1168 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1169 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1170 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1171 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1172 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1173 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1174 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1175 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1176 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1177 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1178 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1179 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1180 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1181 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1182 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1183 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1184 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1185 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1186 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1187 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1188 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1189 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1190 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1191 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1192 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1193 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1194 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1195 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1196 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1197 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1198 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1199 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1200 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1201 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1202 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1203 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1204 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1205 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1206 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1207 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1208 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1209 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1210 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1211 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1212 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1213 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1214 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1215 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1216 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1217 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1218 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1219 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1220 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1221 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1222 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1223 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1224 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1225 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1226 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1227 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1228 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1229 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1230 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1231 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1232 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1233 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1234 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1235 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1236 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1237 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1238 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1239 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1240 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1241 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1242 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1243 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1244 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1245 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1246 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1247 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1248 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1249 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1250 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1251 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1252 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1253 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1254 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1255 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1256 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1257 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1258 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1259 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1260 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1261 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1262 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1263 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1264 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1265 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1266 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1267 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1268 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1269 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1270 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1271 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1272 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1273 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1274 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1275 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1276 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1277 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1278 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1279 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1280 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1281 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1282 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1283 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1284 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1285 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1286 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1287 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1288 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1289 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1290 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1291 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1292 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1293 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1294 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1295 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1296 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1297 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1298 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1299 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1300 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1301 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1302 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1303 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1304 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1305 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1306 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1307 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1308 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1309 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1310 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1311 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1312 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1313 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1314 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1315 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1316 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1317 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1318 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1319 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1320 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1321 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1322 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1323 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1324 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1325 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1326 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1327 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1328 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1329 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1330 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1331 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1332 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1333 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1334 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1335 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1336 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1337 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1338 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1339 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1340 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1341 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1342 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1343 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1344 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1345 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1346 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1347 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1348 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1349 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1350 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1351 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1352 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1353 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1354 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1355 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1356 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1357 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1358 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1359 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1360 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1361 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1362 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1363 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1364 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1365 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1366 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1367 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1368 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1369 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1370 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1371 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1372 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1373 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1374 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1375 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1376 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1377 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1378 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1379 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1380 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1381 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1382 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1383 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1384 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1385 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1386 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1387 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1388 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1389 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1390 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1391 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1392 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1393 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1394 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1395 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1396 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1397 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1398 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1399 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1400 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1401 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1402 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1403 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1404 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1405 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1406 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1407 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1408 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1409 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1410 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1411 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1412 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1413 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1414 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1415 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1416 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1417 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1418 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1419 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1420 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1421 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1422 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1423 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1424 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1425 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1426 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1427 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1428 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1429 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1430 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1431 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1432 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1433 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1434 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1435 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1436 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1437 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1438 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1439 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1440 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1441 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1442 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1443 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1444 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1445 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1446 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1447 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1448 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1449 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1451 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1452 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1453 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1454 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1455 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1456 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1457 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1458 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1459 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1460 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1461 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1462 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1463 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1464 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1465 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1466 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1467 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1468 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1469 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1470 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1471 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1472 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1473 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1474 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1475 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1476 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1477 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1478 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1479 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1480 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1481 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1482 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1483 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1484 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1485 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1486 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1487 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1488 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1489 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1490 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1491 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1492 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1493 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1494 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1495 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1496 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1497 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1498 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1499 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1500 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1501 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1502 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1503 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1504 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1505 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1506 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1507 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1508 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1509 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1510 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1511 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1512 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1513 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1514 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1515 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1516 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1517 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1518 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1519 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1520 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1521 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1522 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1523 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1524 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1525 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1526 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1527 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1528 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1529 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1530 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1531 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1532 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1533 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1534 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1535 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1536 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1537 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1538 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1539 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1540 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1541 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1542 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1543 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1544 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1545 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1546 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1547 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1548 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1549 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1550 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1551 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1552 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1553 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1554 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1555 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1556 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1557 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1558 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1559 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1560 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1561 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1562 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1563 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1564 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1565 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1566 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1567 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1568 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1569 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1570 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1571 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1572 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1573 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1574 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1575 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1576 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1577 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1578 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1579 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1580 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1581 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1582 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1583 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1584 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1585 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1586 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1587 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1588 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1589 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1590 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1591 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1592 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1593 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1594 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1595 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1596 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1597 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1598 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1599 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1600 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1601 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1602 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1603 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1604 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1605 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1606 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1607 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1608 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1609 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1610 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1611 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1612 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1613 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1614 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1615 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1616 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1617 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1618 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1619 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1620 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1621 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1622 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1623 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1624 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1625 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1626 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1627 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1628 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1629 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1630 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1631 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1632 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1633 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1634 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1635 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1636 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1637 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1638 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1639 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1640 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1641 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1642 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1643 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1644 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1645 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1646 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1647 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1648 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1649 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1650 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1651 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1652 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1653 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1654 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1655 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1656 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1657 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1658 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1659 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1660 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1661 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1662 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1663 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1664 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1665 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1666 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1667 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1668 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1669 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1670 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1671 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1672 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1673 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1674 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1675 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1676 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1677 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1678 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1679 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1680 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1681 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1682 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1683 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1684 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1685 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1686 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1687 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1688 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1689 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1690 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1691 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1692 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1693 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1694 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1695 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1696 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1697 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1698 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1699 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1700 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1701 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1702 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1703 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1704 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1705 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1706 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1707 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1708 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1709 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1710 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1711 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1712 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1713 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1714 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1715 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1716 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1717 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1718 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1719 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1720 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1721 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1722 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1723 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1724 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1725 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1726 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1727 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1728 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1729 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1730 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1731 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1732 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1733 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1734 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1735 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1736 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1737 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1738 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1739 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1740 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1741 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1742 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1743 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1744 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1745 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1746 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1747 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1748 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1749 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1750 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1751 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1752 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1753 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1754 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1755 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1756 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1757 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1758 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1759 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1760 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1761 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1762 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1763 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1764 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1765 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1766 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1767 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1768 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1769 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1770 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1771 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1772 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1773 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1774 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1775 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1776 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1777 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1778 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1779 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1780 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1781 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1782 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1783 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1784 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1785 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1786 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1787 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1788 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1789 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1790 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1791 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1792 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1793 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1794 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1795 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1796 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1797 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1798 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1799 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1800 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1801 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1802 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1803 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1804 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1805 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1806 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1807 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1808 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1809 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1810 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1811 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1812 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1813 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1814 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1815 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1816 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1817 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1818 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1819 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1820 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1821 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1822 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1823 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1824 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1825 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1826 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1827 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1828 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1829 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1830 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1831 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1832 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1833 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1834 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1835 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1836 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1837 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1838 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1839 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1840 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1841 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1842 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1843 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1844 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1845 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1846 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1847 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1848 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1849 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1850 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1851 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1852 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1853 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1854 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1855 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1856 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1857 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1858 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1859 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1860 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1861 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1862 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1863 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1864 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1865 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1866 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1867 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1868 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1869 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1870 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1871 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1872 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1873 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1874 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1875 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1876 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1877 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1878 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1879 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1881 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1882 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1883 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1884 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1885 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1886 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1887 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1888 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1889 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1890 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1891 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1892 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1893 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1894 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1895 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1896 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1897 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1898 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1899 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1900 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1901 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1902 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1903 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1904 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1905 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1906 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1907 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1908 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1909 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1910 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1911 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1912 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1913 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1914 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1915 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1916 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1917 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1918 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1919 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1920 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1921 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1922 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1923 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1924 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1925 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1926 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1927 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1928 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1929 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1930 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1931 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1932 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1933 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1934 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1935 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1936 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1937 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1938 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1939 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1940 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1941 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1942 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1943 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1944 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1945 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1946 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1947 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1948 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1949 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1950 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1951 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1952 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1953 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1954 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1955 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1956 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1957 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1958 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1959 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1960 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1961 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1962 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1963 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1964 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1965 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1966 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1967 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1968 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1969 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1970 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1971 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1972 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1973 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1974 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1975 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1976 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1977 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1978 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1979 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1980 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1981 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1982 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1983 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1984 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1985 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1986 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1987 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1988 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1989 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1990 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1991 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1992 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1993 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1994 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "1995 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "1996 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "1997 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "1998 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "1999 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2000 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2001 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2002 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2003 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2004 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2005 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2006 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2007 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2008 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2009 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2010 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2011 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2012 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2013 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2014 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2015 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2016 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2017 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2018 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2019 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2020 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2021 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2022 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2023 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2024 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2026 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2027 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2028 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2029 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2030 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2031 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2032 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2033 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2034 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2035 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2036 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2037 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2038 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2039 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2040 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2041 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2042 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2043 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2044 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2045 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2046 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2047 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2048 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2049 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2050 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2051 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2052 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2053 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2054 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2055 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2056 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2057 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2058 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2059 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2060 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2061 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2062 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2063 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2064 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2065 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2066 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2067 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2068 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2069 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2070 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2071 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2072 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2073 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2074 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2075 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2076 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2077 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2078 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2079 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2080 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2081 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2082 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2083 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2084 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2085 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2086 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2087 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2088 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2089 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2090 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2091 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2092 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2093 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2094 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2095 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2096 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2097 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2098 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2099 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2100 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2101 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2102 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2103 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2104 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2105 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2106 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2107 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2108 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2109 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2110 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2111 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2112 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2113 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2114 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2115 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2116 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2117 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2118 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2119 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2120 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2121 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2122 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2123 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2124 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2125 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2126 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2127 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2128 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2129 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2130 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2131 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2132 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2133 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2134 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2135 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2136 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2137 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2138 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2139 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2140 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2141 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2142 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2143 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2144 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2145 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2146 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2147 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2148 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2149 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2150 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2151 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2152 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2153 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2154 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2155 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2156 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2157 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2158 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2159 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2160 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2161 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2162 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2163 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2164 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2165 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2166 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2167 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2168 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2170 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2171 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2172 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2173 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2174 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2175 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2176 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2177 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2178 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2179 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2180 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2181 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2182 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2183 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2184 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2185 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2186 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2187 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2188 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2189 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2190 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2191 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2192 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2193 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2194 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2195 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2196 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2197 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2198 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2199 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2200 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2201 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2202 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2203 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2204 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2205 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2206 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2207 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2208 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2209 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2210 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2211 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2212 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2213 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2214 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2215 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2216 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2217 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2218 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2219 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2220 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2221 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2222 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2223 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2224 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2225 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2226 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2227 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2228 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2229 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2230 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2231 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2232 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2233 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2234 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2235 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2236 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2237 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2238 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2239 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2240 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2241 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2242 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2243 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2244 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2245 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2246 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2247 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2248 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2249 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2250 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2251 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2252 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2253 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2254 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2255 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2256 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2257 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2258 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2259 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2260 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2261 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2262 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2263 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2264 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2265 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2266 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2267 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2268 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2269 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2270 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2271 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2272 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2273 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2274 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2275 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2276 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2277 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2278 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2279 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2280 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2281 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2282 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2283 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2284 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2285 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2286 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2287 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2288 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2289 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2290 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2291 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2292 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2293 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2294 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2295 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2296 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2297 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2298 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2299 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2300 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2301 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2302 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2303 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2304 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2305 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2306 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2307 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2308 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2309 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2310 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2311 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2312 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2313 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2314 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2315 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2316 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2317 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2318 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2319 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2320 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2321 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2322 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2323 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2324 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2325 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2326 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2327 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2328 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2329 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2330 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2331 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2332 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2333 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2334 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2335 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2336 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2337 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2338 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2339 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2340 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2341 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2342 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2343 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2344 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2345 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2346 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2347 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2348 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2349 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2350 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2351 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2352 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2353 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2354 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2355 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2356 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2357 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2358 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2359 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2360 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2361 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2362 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2363 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2364 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2365 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2366 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2367 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2368 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2369 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2370 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2371 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2372 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2373 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2374 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2375 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2376 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2377 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2378 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2379 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2380 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2381 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2382 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2383 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2384 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2385 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2386 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2387 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2388 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2389 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2390 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2391 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2392 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2393 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2394 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2395 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2396 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2397 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2398 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2399 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2400 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2401 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2402 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2403 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2404 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2405 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2406 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2407 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2408 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2409 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2410 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2411 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2412 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2413 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2414 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2415 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2416 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2417 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2418 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2419 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2420 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2421 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2422 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2423 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2424 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2425 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2426 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2427 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2428 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2429 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2430 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2431 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2432 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2433 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2434 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2435 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2436 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2437 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2438 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2439 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2440 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2441 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2442 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2443 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2444 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2445 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2446 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2447 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2448 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2449 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2450 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2451 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2452 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2453 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2454 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2455 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2456 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2457 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2458 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2459 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2460 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2461 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2462 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2463 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2464 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2465 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2466 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2467 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2468 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2469 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2470 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2471 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2472 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2473 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2474 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2475 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2476 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2477 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2478 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2479 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2480 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2481 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2482 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2483 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2484 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2485 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2486 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2487 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2488 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2489 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2490 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2491 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2492 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2493 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2494 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2495 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2496 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2497 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2498 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2499 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2500 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2501 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2502 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2503 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2504 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2505 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2506 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2507 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2508 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2509 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2510 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2511 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2512 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2513 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2514 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2515 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2516 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2517 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2518 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2519 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2520 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2521 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2522 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2523 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2524 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2525 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2526 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2527 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2528 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2529 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2530 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2531 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2532 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2533 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2534 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2535 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2536 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2537 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2538 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2539 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2540 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2541 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2542 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2543 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2544 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2545 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2546 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2547 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2548 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2549 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2550 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2551 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2552 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2553 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2554 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2555 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2556 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2557 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2558 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2559 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2560 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2561 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2562 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2563 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2564 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2565 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2566 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2567 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2568 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2569 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2570 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2571 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2572 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2573 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2574 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2575 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2576 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2577 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2578 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2579 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2580 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2581 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2582 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2583 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2584 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2585 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2586 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2587 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2588 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2589 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2590 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2591 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2592 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2593 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2594 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2595 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2596 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2597 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2598 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2599 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2601 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2602 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2603 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2604 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2605 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2606 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2607 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2608 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2609 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2610 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2611 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2612 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2613 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2614 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2615 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2616 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2617 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2618 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2619 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2620 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2621 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2622 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2623 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2624 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2625 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2626 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2627 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2628 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2629 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2630 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2631 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2632 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2633 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2634 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2635 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2636 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2637 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2638 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2639 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2640 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2641 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2642 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2643 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2644 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2645 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2646 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2647 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2648 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2649 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2650 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2651 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2652 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2653 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2654 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2655 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2656 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2657 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2658 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2659 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2660 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2661 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2662 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2663 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2664 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2665 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2666 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2667 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2668 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2669 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2670 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2671 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2672 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2673 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2674 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2675 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2676 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2677 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2678 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2679 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2680 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2681 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2682 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2683 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2684 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2685 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2686 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2687 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2688 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2689 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2690 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2691 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2692 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2693 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2694 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2695 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2696 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2697 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2698 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2699 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2700 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2701 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2702 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2703 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2704 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2705 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2706 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2707 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2708 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2709 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2710 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2711 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2712 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2713 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2714 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2715 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2716 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2717 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2718 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2719 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2720 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2721 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2722 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2723 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2724 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2725 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2726 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2727 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2728 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2729 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2730 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2731 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2732 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2733 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2734 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2735 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2736 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2737 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2738 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2739 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2740 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2741 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2742 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2743 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2744 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2745 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2746 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2747 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2748 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2749 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2750 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2751 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2752 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2753 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2754 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2755 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2756 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2757 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2758 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2759 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2760 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2761 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2762 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2763 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2764 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2765 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2766 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2767 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2768 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2769 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2770 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2771 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2772 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2773 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2774 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2775 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2776 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2777 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2778 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2779 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2780 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2781 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2782 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2783 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2784 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2785 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2786 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2787 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2788 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2789 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2790 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2791 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2792 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2793 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2794 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2795 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2796 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2797 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2798 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2799 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2800 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2801 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2802 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2803 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2804 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2805 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2806 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2807 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2808 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2809 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2810 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2811 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2812 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2813 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2814 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2815 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2816 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2817 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2818 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2819 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2820 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2821 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2822 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2823 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2824 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2825 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2826 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2827 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2828 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2829 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2830 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2831 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2832 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2833 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2834 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2835 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2836 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2837 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2838 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2839 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2840 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2841 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2842 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2843 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2844 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2845 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2846 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2847 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2848 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2849 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2850 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2851 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2852 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2853 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2854 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2855 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2856 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2857 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2858 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2859 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2860 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2861 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2862 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2863 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2864 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2865 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2866 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2867 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2868 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2869 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2870 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2871 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2872 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2873 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2874 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2875 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2876 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2877 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2878 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2879 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2880 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2881 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2882 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2883 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2884 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2885 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2886 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2887 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2888 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2889 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2890 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2891 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2892 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2893 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2894 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2895 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2896 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2897 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2898 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2899 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2900 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2901 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2902 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2903 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2904 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2905 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2906 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2907 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2908 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2909 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2910 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2911 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2912 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2913 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2914 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2915 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2916 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2917 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2918 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2919 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2920 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2921 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2922 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2923 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2924 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2925 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2926 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2927 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2928 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2929 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2930 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2931 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2932 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2933 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2934 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2935 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2936 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2937 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2938 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2939 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2940 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2941 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2942 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2943 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2944 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2945 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2946 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2947 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2948 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2949 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2950 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2951 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2952 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2953 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2954 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2955 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2956 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2957 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2958 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2959 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2960 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2961 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2962 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2963 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2964 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2965 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2966 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2967 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2968 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2969 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2970 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2971 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2972 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2973 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2974 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2975 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2976 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2977 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2978 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2979 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2980 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2981 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2982 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2983 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2984 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2985 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2986 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2987 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2988 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2989 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2990 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2991 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2992 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2993 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2994 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "2995 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "2996 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "2997 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "2998 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "2999 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "3000 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "3001 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "3002 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "3003 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "3004 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n",
      "3005 Train Loss 2.520868e-06 Test Loss 35.64367764282902\n",
      "3006 Train Loss 2.5209897e-06 Test Loss 35.64821412849053\n",
      "3007 Train Loss 2.5209677e-06 Test Loss 35.64945309585995\n",
      "3008 Train Loss 2.5210497e-06 Test Loss 35.64949983534691\n",
      "3009 Train Loss 2.5208524e-06 Test Loss 35.64950242410923\n"
     ]
    }
   ],
   "source": [
    "max_reps = 1\n",
    "\n",
    "train_loss_full = []\n",
    "test_loss_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(reps)\n",
    "    N_u = 1000 #Total number of data points for 'u'\n",
    "    N_f = 10000 #Total number of collocation points \n",
    "    \n",
    "    X_f_train_np_array, X_u_train_np_array, u_train_np_array = trainingdata(N_u,N_f,reps*32)\n",
    "        \n",
    "    X_f_train = torch.from_numpy(X_f_train_np_array).float().to(device)\n",
    "    X_u_train = torch.from_numpy(X_u_train_np_array).float().to(device)\n",
    "    u_train = torch.from_numpy(u_train_np_array).float().to(device)\n",
    "        \n",
    "    #u = torch.from_numpy(u_true).float().to(device)\n",
    "    f_hat = torch.zeros(X_f_train.shape[0],1).to(device)\n",
    "        \n",
    "\n",
    "    #X_u_test_tensor = torch.from_numpy(X_u_test).float().to(device)\n",
    "    'Convert to tensor and send to GPU'\n",
    "\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,50,50,50,50,50,1]) #9 hidden layers\n",
    "\n",
    "    #layers = np.array([2,512,512,1])\n",
    "    PINN = Sequentialmodel(layers)\n",
    "       \n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    'L-BFGS Optimizer'\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                                  max_iter = 10000, \n",
    "                                  max_eval = None, \n",
    "                                  tolerance_grad = -1, \n",
    "                                  tolerance_change = -1, \n",
    "                                  history_size = 100, \n",
    "                                  line_search_fn = 'strong_wolfe')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    optimizer.step(PINN.closure)\n",
    "    \n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(PINN.train_loss)\n",
    "    test_loss_full.append(PINN.test_loss)\n",
    "    elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(PINN.beta_val)\n",
    "    \n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_loss\": test_loss_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label}\n",
    "savemat(label+'.mat', mdic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(11.5856, device='cuda:2', requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINN.W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = PINN.test(xt_test_tensor)\n",
    "\n",
    "cmap = plt.cm.rainbow\n",
    "plt.imshow(u_pred.reshape(100,256),cmap = cmap,aspect =1,vmin=-10,vmax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_u_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(u_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(u_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.rainbow\n",
    "plt.imshow(u_true.reshape(100,256),cmap = cmap,aspect = 1,vmin=-10,vmax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(u_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.rainbow\n",
    "plt.imshow(np.transpose(np.abs(u_pred - u_true).reshape(100,256)),cmap = cmap,aspect = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0 \n",
    "for i in range(10):\n",
    "    print(test_loss_full[i][-1])\n",
    "    a = a + test_loss_full[i][-1]\n",
    "print(a/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
