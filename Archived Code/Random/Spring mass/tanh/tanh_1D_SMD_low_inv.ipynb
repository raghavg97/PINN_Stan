{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "510f67c6-b225-41ba-e78a-d0a6e54ded85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "tstart= 0 \n",
    "tstop= 60 \n",
    "\n",
    "increment = 0.1 \n",
    "# Initial condition\n",
    "x_init= [0,0] \n",
    "\n",
    "t = np.arange(tstart,tstop+1,increment)\n",
    "\n",
    "c = 2 # Damping constant \n",
    "k = 1 # Stiffness of the spring\n",
    "m = 5 # Mass \n",
    "F0 = 1\n",
    "\n",
    "def mydiff(x, t):    \n",
    "    F =F0\n",
    "    \n",
    "    dx1dt = x[1] \n",
    "    dx2dt = (F -c*x[1] -k*x[0])/m\n",
    "    dxdt= [dx1dt, dx2dt] \n",
    "    \n",
    "    return dxdt \n",
    "\n",
    "x_full_sol = odeint(mydiff, x_init, t) \n",
    "\n",
    "x_sol = x_full_sol[:,0]\n",
    "v_sol = x_full_sol[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "level = \"low\"\n",
    "label = \"1D_SMD_tanh_\" + level\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "t_test = t.reshape(-1,1)\n",
    "t_test_tensor = torch.from_numpy(t_test).float().to(device)\n",
    "\n",
    "# bc1_t = t[0].reshape(-1,1)\n",
    "# bc1_x = x_sol[0].reshape(-1,1)\n",
    "# t_bc1_train = torch.from_numpy(bc1_t).float().to(device)\n",
    "# x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "\n",
    "bc1_t = t.reshape(-1,1)\n",
    "bc1_x = x_sol.reshape(-1,1)/100\n",
    "t_bc1_train = torch.from_numpy(bc1_t).float().to(device)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "\n",
    "\n",
    "bc2_t = t[0].reshape(-1,1)\n",
    "t_bc2_train = torch.from_numpy(bc2_t).float().to(device)\n",
    "bc2_val = v_sol[0].reshape(-1,1)\n",
    "bc2_val =torch.from_numpy(bc2_val).float().to(device)\n",
    "\n",
    "t_test = t.reshape(-1,1)\n",
    "t_test_tensor = torch.from_numpy(t_test).float().to(device)\n",
    "x_true = x_sol\n",
    "x_true_norm = np.linalg.norm(x_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(t[0]) \n",
    "ub = np.array(t[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    \n",
    "    t01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=t01,random_state =seed)\n",
    "\n",
    "    t_coll = lb + (ub-lb)*sampling(N_f)\n",
    "    # t_coll = np.vstack((t_coll,)) # append training points to collocation points \n",
    "\n",
    "    return t_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "\n",
    "        \n",
    "        self.k = Parameter(torch.tensor(0.0))\n",
    "        self.k.requiresGrad = True\n",
    "        self.c = Parameter(torch.tensor(0.0))\n",
    "        self.c.requiresGrad = True\n",
    "        \n",
    "    'forward pass'\n",
    "    def forward(self,t):\n",
    "        if torch.is_tensor(t) != True:         \n",
    "            t = torch.from_numpy(t)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        t = 2.0*(t - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = t.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,t,x):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(t), x)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,t_bc2,bc2_val):\n",
    "        g = t_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        x = self.forward(g)    \n",
    "            \n",
    "        x_t = autograd.grad(x,g,torch.ones([t_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dx_dt = x_t[:,[0]]\n",
    "        \n",
    "        bc2 = dx_dt\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self,t_coll,f_hat):\n",
    "             \n",
    "        g = t_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        x = self.forward(g) \n",
    "\n",
    "        x_t = autograd.grad(x,g,torch.ones([t_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        x_tt = autograd.grad(x_t,g,torch.ones(t_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dx_dt = x_t[:,[0]]\n",
    "        \n",
    "        dx2_d2t = x_tt[:,[0]]\n",
    "        \n",
    "        f = m*dx2_d2t/100 + self.c*dx_dt/100 + self.k*x/100 -F0\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,t_bc1,x_bc1,t_bc2,bc2_val,t_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(t_bc1,x_bc1)\n",
    "        loss_bc2 = self.loss_BC2(t_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(t_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        x_pred = self.forward(t_test_tensor)\n",
    "        x_pred = x_pred.cpu().detach().numpy()\n",
    "\n",
    "        return x_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        x_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(x_pred.reshape(-1,1) - x_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(x_pred.reshape(-1,1) - x_true.reshape(-1,1),2)/x_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    t_coll = colloc_pts(N_f,rep*11)\n",
    "    t_coll =  torch.from_numpy(t_coll).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(t_coll.shape[0],1).to(device)\n",
    "    for i in range(max_iter):      \n",
    "        train_step(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat)\n",
    "         \n",
    "        loss_np = PINN.loss(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test RE\",test_re_loss[-1],\"c\",PINN.c.cpu().detach().numpy(),\"k\",PINN.k.cpu().detach().numpy())\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "42720d97-b37a-4c42-b7e5-b77a0ef391f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "1 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "2 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "3 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "4 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "5 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "6 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "7 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "8 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "9 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "10 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "11 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "12 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "13 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "14 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "15 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "16 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "17 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "18 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "19 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "20 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "21 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "22 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "23 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "24 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "25 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "26 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "27 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "28 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "29 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "30 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "31 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "32 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "33 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "34 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "35 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "36 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "37 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "38 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "39 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "40 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "41 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "42 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "43 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "44 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "45 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "46 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "47 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "48 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "49 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "50 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "51 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "52 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "53 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "54 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "55 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "56 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "57 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "58 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "59 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "60 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "61 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "62 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "63 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "64 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "65 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "66 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "67 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "68 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "69 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "70 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "71 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "72 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "73 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "74 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "75 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "76 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "77 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "78 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "79 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "80 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "81 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "82 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "83 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "84 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "85 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "86 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "87 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "88 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "89 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "90 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "91 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "92 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "93 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "94 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "95 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "96 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "97 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "98 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "99 Train Loss 1.0000058 Test RE 0.9907454116616567 c -3.8627586e-05 k 9.6246455e-05\n",
      "Training time: 1.17\n",
      "Training time: 1.17\n"
     ]
    }
   ],
   "source": [
    "max_reps = 1\n",
    "max_iter = 100\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "  beta_val = []\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers)\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.1, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "990b2054-f35e-4c8e-c378-69ff2eb19f4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f47b05e7890>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_pred = PINN.test()\n",
    "plt.plot(x_true,'b')\n",
    "plt.plot(x_pred,'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "aefc6a9f-3ad4-417a-b9f7-438009e620af"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_stan_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_stan_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18857/2016390461.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_stan_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_stan_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"1D_FODE_stan_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
