{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8byrnUmNKGR",
    "outputId": "510f67c6-b225-41ba-e78a-d0a6e54ded85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uoNYpDzlNKGV"
   },
   "outputs": [],
   "source": [
    "tstart= 0 \n",
    "tstop= 60 \n",
    "\n",
    "increment = 0.1 \n",
    "# Initial condition\n",
    "x_init= [0,0] \n",
    "\n",
    "t = np.arange(tstart,tstop+1,increment)\n",
    "\n",
    "c = 2 # Damping constant \n",
    "k = 1 # Stiffness of the spring\n",
    "m = 5 # Mass \n",
    "F0 = 20\n",
    "\n",
    "def mydiff(x, t):    \n",
    "    F =F0\n",
    "    \n",
    "    dx1dt = x[1] \n",
    "    dx2dt = (F -c*x[1] -k*x[0])/m\n",
    "    dxdt= [dx1dt, dx2dt] \n",
    "    \n",
    "    return dxdt \n",
    "\n",
    "x_full_sol = odeint(mydiff, x_init, t) \n",
    "\n",
    "x_sol = x_full_sol[:,0]\n",
    "v_sol = x_full_sol[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BR02v-fkNKGV"
   },
   "outputs": [],
   "source": [
    "level = \"low\"\n",
    "label = \"1D_SMD_stan_\" + level\n",
    "\n",
    "loss_thresh = 0.005\n",
    "\n",
    "t_test = t.reshape(-1,1)\n",
    "t_test_tensor = torch.from_numpy(t_test).float().to(device)\n",
    "\n",
    "bc1_t = t[0].reshape(-1,1)\n",
    "bc1_x = x_sol[0].reshape(-1,1)\n",
    "t_bc1_train = torch.from_numpy(bc1_t).float().to(device)\n",
    "x_bc1_train = torch.from_numpy(bc1_x).float().to(device)\n",
    "    \n",
    "\n",
    "bc2_t = t[0].reshape(-1,1)\n",
    "t_bc2_train = torch.from_numpy(bc2_t).float().to(device)\n",
    "bc2_val = v_sol[0].reshape(-1,1)\n",
    "bc2_val =torch.from_numpy(bc2_val).float().to(device)\n",
    "\n",
    "t_test = t.reshape(-1,1)\n",
    "t_test_tensor = torch.from_numpy(t_test).float().to(device)\n",
    "x_true = x_sol\n",
    "x_true_norm = np.linalg.norm(x_true,2)\n",
    "\n",
    "# Domain bounds\n",
    "lb = np.array(t[0]) \n",
    "ub = np.array(t[-1]) \n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SyyktBKBXRo1"
   },
   "outputs": [],
   "source": [
    "def colloc_pts(N_f,seed):\n",
    "    \n",
    "    t01 = np.array([[0.0, 1.0]])\n",
    "    sampling = LHS(xlimits=t01,random_state =seed)\n",
    "\n",
    "    t_coll = lb + (ub-lb)*sampling(N_f)\n",
    "    # t_coll = np.vstack((t_coll,)) # append training points to collocation points \n",
    "\n",
    "    return t_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "o1b21zLnNKGW"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        self.activation = nn.Tanh()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "        \n",
    "        self.beta = Parameter(0.0*torch.ones((50,len(layers)-2)))\n",
    "        self.beta.requiresGrad = True\n",
    "    \n",
    "    'forward pass'\n",
    "    def forward(self,t):\n",
    "        if torch.is_tensor(t) != True:         \n",
    "            t = torch.from_numpy(t)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        t = 2.0*(t - l_b)/(u_b - l_b) - 1.0 #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = t.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z) + self.beta[:,i]*z*self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC1(self,t,x):\n",
    "                \n",
    "        loss_bc1 = self.loss_function(self.forward(t), x)\n",
    "                \n",
    "        return loss_bc1\n",
    "    \n",
    "    def loss_BC2(self,t_bc2,bc2_val):\n",
    "        g = t_bc2.clone()             \n",
    "        g.requires_grad = True\n",
    "        x = self.forward(g)    \n",
    "            \n",
    "        x_t = autograd.grad(x,g,torch.ones([t_bc2.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        dx_dt = x_t[:,[0]]\n",
    "        \n",
    "        bc2 = dx_dt\n",
    "        \n",
    "        loss_bc2= self.loss_function(bc2,bc2_val)\n",
    "\n",
    "        return loss_bc2\n",
    "    \n",
    "    def loss_PDE(self,t_coll,f_hat):\n",
    "             \n",
    "        g = t_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "  \n",
    "        x = self.forward(g) \n",
    "\n",
    "        x_t = autograd.grad(x,g,torch.ones([t_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        x_tt = autograd.grad(x_t,g,torch.ones(t_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        dx_dt = x_t[:,[0]]\n",
    "        \n",
    "        dx2_d2t = x_tt[:,[0]]\n",
    "        \n",
    "        f = m*dx2_d2t + c*dx_dt + k*x - F0\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    \n",
    "    def loss(self,t_bc1,x_bc1,t_bc2,bc2_val,t_coll,f_hat):\n",
    "\n",
    "        loss_bc1 = self.loss_BC1(t_bc1,x_bc1)\n",
    "        loss_bc2 = self.loss_BC2(t_bc2,bc2_val)\n",
    "        loss_f = self.loss_PDE(t_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_bc1 + loss_bc2 + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "          \n",
    "    'test neural network'\n",
    "    \n",
    "    def test(self):\n",
    "        x_pred = self.forward(t_test_tensor)\n",
    "        x_pred = x_pred.cpu().detach().numpy()\n",
    "\n",
    "        return x_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        x_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(x_pred.reshape(-1,1) - x_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(x_pred.reshape(-1,1) - x_true.reshape(-1,1),2)/x_true_norm\n",
    "        \n",
    "        return test_mse, test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fLY2mT5BOgjD"
   },
   "outputs": [],
   "source": [
    "def train_step(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat)\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8srA5uGuObil"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0SezTZ_racQB"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep):\n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*123)\n",
    "    start_time = time.time()\n",
    "    thresh_flag = 0\n",
    "\n",
    "    t_coll = colloc_pts(N_f,rep*11)\n",
    "    t_coll =  torch.from_numpy(t_coll).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(t_coll.shape[0],1).to(device)\n",
    "    for i in range(max_iter):      \n",
    "        train_step(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat)\n",
    "         \n",
    "        loss_np = PINN.loss(t_bc1_train,x_bc1_train,t_bc2_train,bc2_val,t_coll,f_hat).cpu().detach().numpy()\n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1            \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])\n",
    "    \n",
    "    elapsed_time[rep] = time.time() - start_time\n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BYbcJ0NKGX",
    "outputId": "42720d97-b37a-4c42-b7e5-b77a0ef391f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 49.179108 Test MSE 42.10514732387395 Test RE 0.3293377933790751\n",
      "1 Train Loss 14.59921 Test MSE 5.495970235512807 Test RE 0.11898608131581646\n",
      "2 Train Loss 9.7152405 Test MSE 2.890993833185196 Test RE 0.08629736959795396\n",
      "3 Train Loss 4.109919 Test MSE 0.585093148899162 Test RE 0.03882276669933227\n",
      "4 Train Loss 1.984978 Test MSE 0.660171351402368 Test RE 0.04123844802811425\n",
      "5 Train Loss 0.9642118 Test MSE 0.5065014853260891 Test RE 0.03612138027936254\n",
      "6 Train Loss 0.42143777 Test MSE 0.22189191737314443 Test RE 0.02390808092353923\n",
      "7 Train Loss 0.189023 Test MSE 0.09142628595021393 Test RE 0.01534650603431243\n",
      "8 Train Loss 0.098405346 Test MSE 0.05230117651655512 Test RE 0.011607259793297808\n",
      "9 Train Loss 0.04550016 Test MSE 0.04014666121314493 Test RE 0.010169478728839708\n",
      "10 Train Loss 0.036924835 Test MSE 0.03341343197432194 Test RE 0.009277575950596742\n",
      "11 Train Loss 0.02855678 Test MSE 0.02484297045134983 Test RE 0.00799973751149057\n",
      "12 Train Loss 0.02126043 Test MSE 0.014484356820419467 Test RE 0.006108345353726062\n",
      "13 Train Loss 0.011827774 Test MSE 0.008381210867369647 Test RE 0.004646515170359928\n",
      "14 Train Loss 0.009121659 Test MSE 0.005709531406640549 Test RE 0.0038350780662986246\n",
      "15 Train Loss 0.006354557 Test MSE 0.004430956908170284 Test RE 0.0033784907867115063\n",
      "16 Train Loss 0.0053109853 Test MSE 0.004159091258726914 Test RE 0.0032732049597180286\n",
      "17 Train Loss 0.004212993 Test MSE 0.0036085911947839576 Test RE 0.003048897458160098\n",
      "18 Train Loss 0.0035893985 Test MSE 0.0034401884862177634 Test RE 0.002976905816912006\n",
      "19 Train Loss 0.0030159215 Test MSE 0.002864932990923364 Test RE 0.0027166344889167837\n",
      "20 Train Loss 0.0024396898 Test MSE 0.0017664568041448935 Test RE 0.0021331700949757454\n",
      "21 Train Loss 0.0020441785 Test MSE 0.0015053014476412825 Test RE 0.0019691813563215096\n",
      "22 Train Loss 0.0017342851 Test MSE 0.0016409226552143393 Test RE 0.0020559759551675785\n",
      "23 Train Loss 0.0016486712 Test MSE 0.0015524682643984337 Test RE 0.0019997943693093744\n",
      "24 Train Loss 0.0016186599 Test MSE 0.0015036595960874611 Test RE 0.0019681071576775617\n",
      "25 Train Loss 0.0015197245 Test MSE 0.0012891194997632525 Test RE 0.0018223028927523742\n",
      "26 Train Loss 0.0014141344 Test MSE 0.0011045891660746879 Test RE 0.0016868418428588332\n",
      "27 Train Loss 0.0013073934 Test MSE 0.0010831036741542003 Test RE 0.001670355803096378\n",
      "28 Train Loss 0.0012575547 Test MSE 0.0010589729008416227 Test RE 0.0016516438288428934\n",
      "29 Train Loss 0.0011773293 Test MSE 0.0009887424796440733 Test RE 0.0015959363710987594\n",
      "30 Train Loss 0.0010938016 Test MSE 0.0010035032956420618 Test RE 0.001607805008646666\n",
      "31 Train Loss 0.0010815058 Test MSE 0.0009882686768857454 Test RE 0.0015955539410528307\n",
      "32 Train Loss 0.0010769793 Test MSE 0.00098360929243648 Test RE 0.0015917882229216438\n",
      "33 Train Loss 0.0010750516 Test MSE 0.0009844397469296945 Test RE 0.001592460049016868\n",
      "34 Train Loss 0.0010562113 Test MSE 0.0009384295548332294 Test RE 0.0015548010103419636\n",
      "35 Train Loss 0.0009830205 Test MSE 0.0008943642414864499 Test RE 0.0015178581579339025\n",
      "36 Train Loss 0.0009204283 Test MSE 0.0008260407877773645 Test RE 0.0014587293521310233\n",
      "37 Train Loss 0.00082035916 Test MSE 0.0006470405079429868 Test RE 0.0012910400381188722\n",
      "38 Train Loss 0.00070999854 Test MSE 0.0005069593934788469 Test RE 0.0011427745579823407\n",
      "39 Train Loss 0.0006582861 Test MSE 0.0004235493686226862 Test RE 0.0010445422112068188\n",
      "40 Train Loss 0.00065455807 Test MSE 0.00041622880946953696 Test RE 0.0010354760160167413\n",
      "41 Train Loss 0.0006543233 Test MSE 0.000415961404218882 Test RE 0.001035143342972835\n",
      "42 Train Loss 0.0006524094 Test MSE 0.0004106580083226556 Test RE 0.0010285232748180593\n",
      "43 Train Loss 0.00056597777 Test MSE 0.0003081593950245009 Test RE 0.0008909671299743508\n",
      "44 Train Loss 0.0004645141 Test MSE 0.0002908919718249467 Test RE 0.0008656450370655005\n",
      "45 Train Loss 0.00042992094 Test MSE 0.00029218152545202675 Test RE 0.0008675616614088142\n",
      "46 Train Loss 0.00039161154 Test MSE 0.0002780014878658282 Test RE 0.0008462477672117268\n",
      "47 Train Loss 0.00032378957 Test MSE 0.00021586790801204824 Test RE 0.0007457066518126784\n",
      "48 Train Loss 0.00025060074 Test MSE 9.975354171933968e-05 Test RE 0.0005069184960984994\n",
      "49 Train Loss 0.00022584725 Test MSE 7.878773159566057e-05 Test RE 0.00045050879521313814\n",
      "50 Train Loss 0.00020200343 Test MSE 6.882147951266524e-05 Test RE 0.00042105223605843115\n",
      "51 Train Loss 0.00018732062 Test MSE 6.752514690193116e-05 Test RE 0.0004170678800788616\n",
      "52 Train Loss 0.00017434405 Test MSE 7.133807154809635e-05 Test RE 0.00042868141761797046\n",
      "53 Train Loss 0.00016981746 Test MSE 6.891036750725185e-05 Test RE 0.0004213240582582559\n",
      "54 Train Loss 0.00016068335 Test MSE 6.264239705658005e-05 Test RE 0.0004017058530609201\n",
      "55 Train Loss 0.00015994417 Test MSE 6.243111701452056e-05 Test RE 0.0004010278448842248\n",
      "56 Train Loss 0.00015920734 Test MSE 6.223680108385641e-05 Test RE 0.0004004032618786915\n",
      "57 Train Loss 0.00015844403 Test MSE 6.203870476687536e-05 Test RE 0.00039976552321533294\n",
      "58 Train Loss 0.00015765104 Test MSE 6.186116230340217e-05 Test RE 0.00039919308856984015\n",
      "59 Train Loss 0.00015688756 Test MSE 6.162849830740254e-05 Test RE 0.00039844168534457913\n",
      "60 Train Loss 0.00015612463 Test MSE 6.147051389113087e-05 Test RE 0.0003979306557716917\n",
      "61 Train Loss 0.00015539108 Test MSE 6.124330044000292e-05 Test RE 0.00039719453940409953\n",
      "62 Train Loss 0.00015464569 Test MSE 6.104096393529715e-05 Test RE 0.00039653786803375574\n",
      "63 Train Loss 0.0001512751 Test MSE 5.9292053292388054e-05 Test RE 0.00039081589688726495\n",
      "64 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "65 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "66 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "67 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "68 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "69 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "70 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "71 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "72 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "73 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "74 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "75 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "76 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "77 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "78 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "79 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "80 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "81 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "82 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "83 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "84 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "85 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "86 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "87 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "88 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "89 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "90 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "91 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "92 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "93 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "94 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "95 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "96 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "97 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "98 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "99 Train Loss 0.00014879213 Test MSE 5.866434052850194e-05 Test RE 0.0003887416486413215\n",
      "Training time: 24.42\n",
      "Training time: 24.42\n"
     ]
    }
   ],
   "source": [
    "max_reps = 1\n",
    "max_iter = 100\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "\n",
    "for reps in range(max_reps):   \n",
    "  train_loss = []\n",
    "  test_mse_loss = []\n",
    "  test_re_loss = []   \n",
    "  beta_val = []\n",
    "\n",
    "  torch.manual_seed(reps*36)\n",
    "  N_f = 10000 #Total number of collocation points\n",
    "\n",
    "  layers = np.array([1,50,50,50,1]) #9 hidden layers\n",
    "  PINN = Sequentialmodel(layers)\n",
    "\n",
    "  PINN.to(device)\n",
    "\n",
    "  'Neural Network Summary'\n",
    "  print(PINN)\n",
    "\n",
    "  params = list(PINN.parameters())\n",
    "\n",
    "  optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.1, \n",
    "                            max_iter = 10, \n",
    "                            max_eval = 15, \n",
    "                            tolerance_grad = 1e-6, \n",
    "                            tolerance_change = 1e-6, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "  train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "  torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "  train_loss_full.append(train_loss)\n",
    "  test_mse_full.append(test_mse_loss)\n",
    "  test_re_full.append(test_re_loss)\n",
    "  beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pmHEeBpzfFQh",
    "outputId": "990b2054-f35e-4c8e-c378-69ff2eb19f4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9308310790>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA87UlEQVR4nO3deXxU1f3/8fdkmywkYclOQggY9k0BWUQUF4obIrW/qm2Fb1srihREK1W/fkFtRW1r1brVDbVq0VZxKSpLZZVFCSCb7AECIYQEyISQTJY5vz8GRsISkzAzdyZ5PR+PeST33pN7PzkE8uace8/YjDFGAAAAfhJidQEAAKB5IXwAAAC/InwAAAC/InwAAAC/InwAAAC/InwAAAC/InwAAAC/InwAAAC/CrO6gFO5XC7l5+crNjZWNpvN6nIAAEA9GGNUWlqqtLQ0hYTUPbYRcOEjPz9fGRkZVpcBAAAaIS8vT+np6XW2aVD4mD59uj788ENt3rxZUVFRGjx4sJ544gl17tzZ02bs2LF68803a33dgAEDtGLFinpdIzY21lN8XFxcQ8oDAAAWcTgcysjI8Pwer0uDwseiRYs0fvx49e/fX9XV1XrwwQc1fPhwbdq0STExMZ52I0aM0IwZMzzbERER9b7GiamWuLg4wgcAAEGmPrdMNCh8fPHFF7W2Z8yYoaSkJOXk5Gjo0KGe/Xa7XSkpKQ05NQAAaCbO6WmXkpISSVLr1q1r7V+4cKGSkpLUqVMn3XbbbSosLDzrOZxOpxwOR60XAABoumzGGNOYLzTG6Prrr9fhw4e1ZMkSz/733ntPLVq0UGZmpnJzc/XQQw+purpaOTk5stvtp51n2rRpevjhh0/bX1JSwrQLAABBwuFwKD4+vl6/vxsdPsaPH6/Zs2dr6dKldd7Vun//fmVmZmrmzJkaPXr0acedTqecTmet4jMyMggfAAAEkYaEj0Y9ajthwgR98sknWrx48Q8+TpOamqrMzExt27btjMftdvsZR0QAAEDT1KDwYYzRhAkTNGvWLC1cuFBZWVk/+DXFxcXKy8tTampqo4sEAABNR4NuOB0/frzefvttvfvuu4qNjVVBQYEKCgpUXl4uSTp69KjuvfdeLV++XLt27dLChQt13XXXKSEhQTfccINPvgEAABBcGnTPx9me3Z0xY4bGjh2r8vJyjRo1SmvWrNGRI0eUmpqqYcOG6dFHH633qqUNmTMCAACBwWf3fPxQTomKitKcOXMackoAANDM8K62AADArwgfAADArwgfAADArxq1zgcCk9Ph1JrpX6h88TeyVToV2ruHOv7mcqVdWPdaLAAA+BPho4n47OMqdbixrwZWb/x+5yqp6rUwLe48Vl0/+KMSuydZVyAAAMcx7dIEPPqodM2ocD1Q/YgKQlK1uOtvtKjPRG2IGaBwVWvolldV1auvvppbZnWpAAAQPoLd80859X//5/687V2j1bJkj4Zu+rsuWfO0ehxdofUvfaXt9m563jVOl10Xo9mzra0XAADCRxDLmT5XV9/TRd21QdOnS3/7mxTZovZMWs/bByt1z9faPOp+VVZKN9wgzZ1rUcEAAIjwEbRK80uV8tCvlaVdeqbby5oy5extY5JiNPP9EP3kJ1KLqkNyXjNaO/7znf+KBQDgJISPILX6qgfVtiZPe8KyNHDBdJ1l5XuP8HDp7beld5Im67rqWQodPVKl+4/6p1gAAE5C+AhCu+Zt05B1z0uSDj76d8UkxdTr6yIipAsX/Un7QjPUvmq71lw6yYdVAgBwZoSPILTv9kcUKpe+TrpGfX9/ZYO+tk2XRBU99Q+5ZNPQra9pxZRZPqoSAIAzI3wEmdzPN2tg7ruSpBZPPdKoc/T+7SVaMvA+SVL2n25T4YZCr9UHAMAPIXwEmS0PvqVQubQyeaS6/eyCRp9n0LxHtDmqj9qYYm0Zea8XKwQAoG6EjyDicEj/b+sfNEKfK/QPD5/TuSJaRMi8+He5ZFP73AVa/PFhL1UJAEDdCB9B5O23pdKyEO3pOkJ9f9XnnM/XdcyFen3Ev9RNm3Tbfa3kdJ57jQAA/BDCR5AwLqO/v1AjSbrzTv3go7X1deM/f6yY5Fht3So984x3zgkAQF0IH0Fi2wfr9PnGDD0Zer9+/nPvnbdlS+mJJySbXNo67V0d2n7IeycHAOAMCB9BYv9f3lWa9mtI8la1bOndc//859LHrcbq1fKf6dv/90fvnhwAgFMQPoKAqXGp46qZ7s9vutnr5w8Nldree4skafCa57R7Ya7XrwEAwAmEjyCw4ZXlSq/ZI4didf6D1/jkGhfc/yOtbnOl7KrU3lsf8Mk1AACQCB9B4dDrH0mS1rUfqajWUb65iM2m2Jf+JJdsuihvpta//o1vrgMAaPYIH0Eg49tPJUkh14/06XWyb+yt5R1/IUmquO8hn14LANB8ET4C3O7529ShcouqFKbuk3/k8+tlvj5V1QpV/+I5Wvv8Vz6/HgCg+SF8BLj/Lg7X05qo+am/UHy7eJ9fL31oB63o8j/6Wv310qthMsbnlwQANDNhVheAur3zVXt9qaf11O+kq/x0zaxPnlGH7lGqXGvTjf+VrrjCTxcGADQLjHwEsGPHpKVL3Z9ffbX/rts2O1q3j3MvofrQQ2L0AwDgVYSPALZ65lYNqlyoDm2d6tTJv9e+/34pyV6iK1c8opWPL/DvxQEATRrhI4BV//1VLdQwvR493mvv5VJfqanSzJ5/1COaqug/PiDjYvgDAOAdhI8Alrzhv5Kk0MsuteT6PWdM1jFFqVfZCq18+AtLagAAND2EjwB1eMchdT62RpJ03m8us6SGhB4pWnXheElS7J/+j9EPAIBXED4C1NZXFilERtsjuirlgjTL6ujx1n06qhh1L1+lFf/7H8vqAAA0HYSPAFU+3/2Yy77zLrG0jtadE5UzeIIkqeVfp8pVw+gHAODcED4CVOJmd/gIHTrE4kqkXm/eq1K1UNeKNVpx/8dWlwMACHKEjwB0rOiYOpWtliRl3nKRxdVIrc5ro5yL79Zb+oUe/ainXC6rKwIABDPCRwD6Zp1dg7Rc98e/oPSLMq0uR5LU5+OH9dv4t/TFto7617+srgYAEMwIHwHoqxWhylE/7Rh+h2whfl7g4yxatrJp8mT35w8/LNXUWFsPACB4ET4C0Ikl1YdYf7tHLRMnSv1it+h/v7tFyyYz/AEAaBzCR4AxLqORC+7WL/WaBp9fbnU5tcTHS3/u/55u0T+V+tJUVTsZ/gAANBzhI8DsW7Zb4yqe1gu6Uz17B94fz/lvTNQRW0udV/mdlk96z+pyAABBKPB+uzVzebNWSZJ2RPeUPc5ucTWni8uI17dX3itJavvaw6quqLa4IgBAsCF8BBjnV+7wUZTZz+JKzq7vjAk6ZGutDlVbtey3/7S6HABAkCF8BJi4re7wYesfuOGjRVqc1v/od5KkdjMeUVU5ox8AgPojfAQQ4zLqeNgdPhKvCtzwIUn93rhLRbYEta/erq/Gv2t1OQCAIBJmdQH43p4FO5SpElXIrg7Xdbe6nDrFJLfQitGPaMEHxZr5+Y/1bZkUE2N1VQCAYMDIRwDJ+3yDJGl7TB9FxIRbXM0PG/LOHXqn/f9qR0GM/vpXq6sBAAQLwkcA+dg2Sm1UpA9HvmF1KfVit0uPPeb+/MnHXSrcdczaggAAQYHwEUBWrZIOqY0yruxidSn19tOfSv/TZbkWlvXTxuvvt7ocAEAQIHwECJdLyslxf94vsO81rSUkRPrtr4/pAq3RkHUvKHfedqtLAgAEOMJHgMhbskvvl47QY6EPqWtXq6tpmD73XK6cxBEKV7Xy/+dBq8sBAAQ4wkeAKPhirUZojkZFzFZYED6DFP/SE3LJpov2va81f1tqdTkAgABG+AgQ5SvXSZKKU3taXEnjnDe6l5Z1/ZUkKfp341l4DABwVoSPAGHful6SVN2tl8WVNF73j6frkK21OjvXaclNz1tdDgAgQBE+AkTyQXf4aDEoOEc+JKlVdoK++8V0SZJz9jztzTMWVwQACESEjwBQfqhcmZXbJEkZVwdv+JCkQa/9WlM6f6Sraz7VPffarC4HABCACB8BYNfn3ylULhXb2iipV4rV5ZyTkLAQ3TzzeoWE2PT++9Knn1pdEQAg0BA+AsC+nAIdVkvtie8pW0jwjxb06SPdfbcUK4f23DxFh3eXWF0SACCAED4CwBchV6u1DumfP/3Y6lK85tFHpS+iR2t82ZNad8U9VpcDAAggQbiiRNOzfr0k2ZTdN87qUrwmKkqK+/NUue78Updsf03LHxylQX+81uqyApox0tGj0qFDUvkxo5r9haqscKnK6ZKrxig81KWwiBCFREcqNDZaES2jFRcnxce732cHAIKFzRhT70cSpk+frg8//FCbN29WVFSUBg8erCeeeEKdO3f2tDHG6OGHH9bLL7+sw4cPa8CAAXr++efVvXv93iLe4XAoPj5eJSUliotrOr+M65KaKhUUSMuXSwMHWl2Ndy3pP1kXr/qrim1tVLF8rdoOSLe6JMvUVBvtXH5A++dvVPmGHarZvVdhBXmKLdmrNhX7tMQ1RL92vXy8tVG1whQq1xnPtVgX6xIt9mx/a+utyJBKlYW1VJm9lSqjWqomtqXUsqUq0s9T/ohfKjFRSkqS2h7ZqFapkYrLbKWQVvFSaKjvv3kATV5Dfn83aORj0aJFGj9+vPr376/q6mo9+OCDGj58uDZt2qSYmBhJ0pNPPqmnnnpKb7zxhjp16qQ//OEPuvLKK7VlyxbFxsY2/rtqooq3FGlJwUB9q97q3uV9SU3rF8GAL6fru5RF6npstdYOv0XJB75UWGTTH3AzRtq1dK++XXREn+3poTVrpJ3rj+mgM03ZOnPe3yV3MLPbpehomxxH4hVnSuRSiIwtREY22YxLEapSTXikWtjdIyWSlGl2Kb7GIdVIckpySDrgPrZs1SCN/OiXnuvs0Qi11F7PdmlInMrCW6k8qpX2J/fRZzfOUEKClJAg9fn6ZcVGVSsqrZVaZLRSVFor2Vq3cg+3tGghHf97DwAN0aCRj1MdPHhQSUlJWrRokYYOHSpjjNLS0jRp0iRNmTJFkuR0OpWcnKwnnnhCt99++2nncDqdcjqdnm2Hw6GMjIxmM/Kx9umF6nP3MO0O66DMqh1Wl+MTe77crpaXX6A4lerLC6fospWPW12STxTvLNH6p/+rmtlfqNOuucpw7dYCXarLtMDTZpstWxERNhW16aSqlHYKzUyXvWO6Iju2VUzndLUc0FnR0T9woZoaqbpasttVUyOVlkrlK75Vef5hOQ8cUWWh+1VddESuQ0e015ahd1Lu0cGD0sGD0uzcrmrrylMLlZ126mUapIu0zLOdp3Sla98Zy9gW2UO/7LdecXFSbKw0dcnlal2Rr2p7jGrs0aqJjJHLHi1XZLTKEzO08ZbHZLdLERFSx8//JnvJQZnwCJmwcLnCwt2fh4arJralCof9VLbj9163XP65wo4UqcZlU43LJpexqdqEqMZlU3VopHb1vl7V1e5uSdq0QPYjhTI1Lrmq3dNVpsYlU+NStQlVTrdfeLqv8/bZanlkl4zLJVPtklzudic+fpg9xXPeQXv/pQzHRvc7QLpqpBqXZFyej88kT1d1SISMkUYeflO9ji1XiHHJJtdpHx9NeUFloXEyRvrJ4Zd18dHPa7c76fP7Ut9WcViyJOlnR57XtY53TmsXIvf2xIxZ2mvvKEn6efEzuvnQc2f9Ebo389/aGtVbNpt0Q/GrGnPwT2dtO7X9W9oQM0CSNOLQu7pt/yPfHzzl/vjHM1/S6rhLZbNJQw9/pDv2ut/ryXgauj8am03PZf5ZX7ccLkm6sGSexu/6nefYia+xHf84o91ULUsYKUnqUfKVJuTefebzyqb3M+7R4qQbJUnnla7Rb7dNOO28J77mk7Rx+jL5ZklSxrEtmrT1jtPOd+Jr5yX/QnNTbpUkJVfs1uQtt5/1vEsSR+uzVPeKz60qD+jeLb8+a71ft7lKn6a5zxVd7dCUzWOP/xmb4y2MbMbIJpdWt7pC/8qYLEmKqCnXY+uvO0M7d9u1LYdpRtbxPytj9MLqgZ52ZaHxur//fM2dK69q0MyFOQfbtm0zksz69euNMcbs2LHDSDKrV6+u1W7kyJHm1ltvPeM5pk6d6u65U14lJSXnUlrQWHTTC8ZIZmXStVaX4lPLJ800RjJ7lG7efeGw1eV4zZYtxnxxzTNmTewQU6VQY9yDHsZIplohZm3cEHPf71zmX/8yZutWY2qcVVaXbIwxpqLCmLwdTrNu/gGz9LXNZs4jK8zHd3xuZoxZYMaPN+amm4y54gpj/pkw3syOGm0WhAwzq9XH5CrTHFGcMZJZoQtP/nbNLrWr9f2f/NqorrV2bVC3s7bdpXa1dq1U/7O2Pag2tXYt0CVnbXtU0bV2/UdXn7WtkYzk8my+rxvrbButo57N1zW2zraJOuDZfE531tm2vXZ6Np/Q7+ps200bPJv/p2l1tu2vlZ7Ne/VknW0v0QLP5h16vs62V+s/ns0xmlFn2xv1vmfzRr1fZ9sxmuHZvFr/qbPtnXrOs3mJFtTZ9l496dnsp6/rbDtVUz2b3bShzrZP6l7PZqZy62z7nO70bCaosM62b+hWz2a0jtbZ9n3dWGvXyRtFam3sdu//u1JSUmLq+/u70SMfxhhdf/31Onz4sJYsWSJJWrZsmS666CLt27dPaWlpnra/+c1vtHv3bs2ZM+e08zT3kY9F50/UJWuf1cJ+9+rSb87+v4+m4ONrXta4z67ToYhULVggDR5sdUWNk7++WO/OaaN//lNavVr6XCM0Qu6f7Vx7Z+X3GqG4n4xQ9v8MUWRCC4ur9Z5jx6SiIqmkRCotceno4So5nHaVlrpHX6I2r5HrcImqHccUUl6mkIpjCq0oU2jlMR2xtdJ/kn6lykrJ6ZR+njddSVX7FGqqFG4qFeaqUpipVLip0pHQ1vq/tNc8/1I+WPhbdajcohCbSyE2oxAZhdiMbDajY+Hx+kPfjxQWJoWFSb/aMElZjm8lW4hMSIh04mULUU2YXW+M/FBhYe7bXC5bOV1phWvcj7eHhMh2om1oiGw2mxaNeV2h4SEKC5M6L3lVCXlrZAsNkS30eJsTr5AQ7Rz7iEyE+67fxGUfK3bntzK2k64fEuLZzr/udrmi3NNV8euXKmb3plrHFXK8dluIii8aKVd0CxkjRe/coKj8He4puONtXfr+3I6uA1QT5f55iziQp8jCPZLcfXjCic+Pduil6ij3NLj94F5FFuw6rc2Jz4+276HqFi3d5y3KV3T+dvexk384jm+Utuuuytg27vMeLlBM3ubvT3jSR2Ok0swecrZMljHutnG717nz3iltJamkXU+Vt3FPS0YcKVSr7d/IJvd5vi/YSMbdtiwpS8ZIkaUHlbB5ae02kmwnnbc0zX3PYkRpsZLXzz9724weKsl0v/1FeNkRpeV8eva26d11+Lz+kqSw8lJlLH/f09am2t+bI72biroMkSSFVpar/aI33X++NvcYhmw2z/bRlPM8bW011cpY/v7xkZcT7Wzun32bTeWt03Uoe4Dnjyg151NPO1dYhA72uVI33iivasjIR6PDx/jx4zV79mwtXbpU6enuH4oT4SM/P1+pqametrfddpvy8vL0xRdfeLX4piAn4UfqWzxXS8a8qovf+JXV5fiUyyXdeKM0a5bUurW0eE65uveLsrqseqksr9HKR75QyKsv68Kiz5SlXO1TukJDpd/3+UJXZW9XhwnXKHVwltWlAoAlfHbD6QkTJkzQJ598osWLF3uChySlpLhX5ywoKKgVPgoLC5WcnNyYSzV5yUc2S5LiB3SxuBLfCwmR3npLuuIKKWvlPxU/YIp2zflS7a84z+rSzmrP8n3aOuU1dfnqVV3syvPsv73zIiVM/JluvFFKTBxhYYUAEHwatMiYMUZ33XWXPvzwQ3355ZfKyqr9v7ysrCylpKRo3rx5nn2VlZVatGiRBgfrGLsPHTtYpvQa99Bo+hVNP3xI7gckPv+0WlMjn1S6K08RI4Zp+yebrC6rlupqae7Lu7Q8+Xq1HdxOVyyZqnRXng7ZWuurAXdr3/zv9NDmn+mOO6TERKurBYDg06CRj/Hjx+vdd9/Vxx9/rNjYWBUUFEiS4uPjFRUVJZvNpkmTJumxxx5Tdna2srOz9dhjjyk6Olq33HKLT76BYJb7TZEqdIESQ4rVLruN1eX4TavEMFV/84V29L1UHSs36/CoIVr3/KfqdcdFlta1N7dKr74ZrldflUr3tVK+5itULq1rNVTOW3+jPo/+WBfFRlpaIwA0BQ2658Nms51x/4wZMzR27FhJ7tGRhx9+WH//+99rLTLWo0ePel2jOd3zMXOmdPPN0pCLjJYsDf73dGmoQ1uLlN/3WvU4ulLlitTXv/ibhr7xK7++v02Ns1qr//i5XK+8KhUUaKBWSnKPaPx14Hu6+K7eaje8eYxKAcC58MsNp77SnMLHtGnSww9Lv/619MorVldjjWMHy7Sh58268ID77W8XdPiV+qx6Va1a+fa6+V/lavsDr6vTV68rpSbfs//W/t/p6slddMMNLFkOAA3RkN/fvLGchTZ/5859XZrxf6yjE2PUb+9HWnjV46pWqP67s706d5ZmzHA/HeNNZWXSf6ct0erE4UoZ0lFDF/9BKTX5Kra10cILJmvHp5v01tdddNNNBA8A8CXCh4Ue/M9ArVcPXRiWY3UplgoJC9Gln03Rppe/0n8636uDB6Vf/lIa12Gulvz6TVUerWz0uR3bDmj2q/t1003u9zV5+uEjuqBonkJktKrVFVr62/cUc3ifLs35izpe29WL3xUA4GyYdrGIq9olZ3iMolSh3fO3KfPywH3c1J8qK6Vnn5Ueedjoy6P91U85OmxrpQ0dRips5DVqN7qf0ga3P+N9Iaa6RvkLtyr/P6tVuWK1Ejd8qU5la/WE7tPv9YQkqUuWU8+2+7M6PnSLOlzOmhwA4C3c8xEE9i7dpfSLs+RUhMKcxxQa0bTeUO5clRRXa80v/qIuc55Viiu/1jGHYrU89kf6Q+9/yWaTTGWV3s/poMTq/QpTzWnn+k/szVpw27u66SapXz/pLPdNAwDOgc8XGcO5K1i4WemS9tg7KZvgcZr4NmG69LMpqqm8V9/+/Ssdef1DJW1Zoo7l6xWnUjlLnVq69ETrcIWrXGGqUZmitS2mj4raXaCQwYN03rgrdG2/JF1r5TcDAKiF8GGRshz3yqZFCV2UbXEtgSw0IlS9JwyVJgyVJFWUOLVtca4SD4Xo/Wj3KEZoqLS7ZIGOZrdW6vkp6hNNmAOAQEb4sMr2bZIkZzuiR0NExtuVfd2ZAltPC6oBADQGT7tYJGa/+50hQ7sQPgAAzQsjHxbZVNVJYTqg2P7NeJEPAECzRPiwQGWl9D9H/yaXpPxRVlcDAIB/Me1igd273at3RkdLKSlWVwMAgH8RPiywY3OVJKPzzmPNCQBA80P4sEDUmy/pqFroj2WTrC4FAAC/I3xYYfs2xeiYWrTh3csAAM0P4cMC0fnux2xDOvN+LgCA5ofwYYGEI+7wEduH8AEAaH4IH35WXVGt9KpcSVLyEBYYAwA0P4QPP9u/co/CVa1yRSrlgjSrywEAwO8IH35WuMw95bLX3lEhYXQ/AKD5YYVTP9td3EJ7NEqhbTN5N1sAQLPEf7397CszWKM1S4tGPW11KQAAWILw4Wfb3bMu6tjR2joAALAK4cPPirYekmQIHwCAZovw4UfGZTR3c4aOqoWyw3dZXQ4AAJbghlM/Kt58UAk6Jpdsatsv1epyAACwBCMffnRghXtxsQMhabLH8b4uAIDmifDhRyXfusNHYYssiysBAMA6hA8/qtziDh+lCYQPAEDzRfjwo9Dd7vBRnU74AAA0X4QPP4opdIePsGzCBwCg+eJpFz/6r+1y7VGMMvr3sLoUAAAsQ/jwk5oa6UHH71UlafdVVlcDAIB1mHbxk/x8qapKCg+X2ra1uhoAAKzDyIef7NlYqgRVKD4jQaGhNqvLAQDAMox8+In59wc6qCT9wzHS6lIAALAU4cNPqre5n3SpSkizuBIAAKxF+PCT8L3u8FGTyWO2AIDmjfDhJy2K3OHD3qm9tYUAAGAxwoefJJbtkiTF9WbkAwDQvBE+/KCqrFIpNfskSUkXtre2GAAALEb48IMDq/cpREYVsiuhW5LV5QAAYCnW+fCDvIJw/VsTlRTv1C2s8QEAaOYIH36wvSJdd+tpXd5PusXqYgAAsBjTLn6we7f7Y7t21tYBAEAgIHz4wdFNe9RGRcpsZ6wuBQAAyxE+/OAnc29TkRJ1Wd6bVpcCAIDlCB9+0KrUPe8S05V5FwAACB8+ZlxGKZV7JEltzid8AABA+PCxw9uLFa1ySVJy33SLqwEAwHqEDx878I171ONASIoiW0ZaXA0AANYjfPiYY737fo+DUUy5AAAgET58rmKre+SjtCXhAwAAiRVOfW5DWB+t0USl9OijQVYXAwBAACB8+NhCc4n+rUv0zNVWVwIAQGBg2sXHWFodAIDaCB8+1mLHtyytDgDASZh28aGKIxX68lAfSdKh2CJJbSytBwCAQMDIhw8VfJMnSTqqGLXq2NriagAACAwNDh+LFy/Wddddp7S0NNlsNn300Ue1jo8dO1Y2m63Wa+DAgd6qN6gcWnt8gbGIdrKF2CyuBgCAwNDg8FFWVqbevXvrueeeO2ubESNGaP/+/Z7XZ599dk5FBquyTe67TQ/HcrcpAAAnNPiej6uuukpXXXVVnW3sdrtSUlIaXVRTUZPrHvk4lphpcSUAAAQOn9zzsXDhQiUlJalTp0667bbbVFhYeNa2TqdTDoej1qupCNvnHvlwpTPyAQDACV4PH1dddZXeeecdffnll/rLX/6ib775RpdddpmcTucZ20+fPl3x8fGeV0ZGhrdLskx0sXvkI6wj4QMAgBNsxphGL0Bhs9k0a9YsjRo16qxt9u/fr8zMTM2cOVOjR48+7bjT6awVTBwOhzIyMlRSUqK4uLjGlhYQpiS/obTCNRr8+m3q/z89rC4HAACfcTgcio+Pr9fvb5+v85GamqrMzExt27btjMftdrvsdruvy/A7Y6RnHWNVobHacYnV1QAAEDh8vs5HcXGx8vLylJqa6utLBZTDh6WKCvfnaWnW1gIAQCBp8MjH0aNHtX37ds92bm6u1q5dq9atW6t169aaNm2afvzjHys1NVW7du3SAw88oISEBN1www1eLTzQ5X9XovO1Q8daZygyMtHqcgAACBgNDh+rVq3SsGHDPNuTJ0+WJI0ZM0Yvvvii1q9fr7feektHjhxRamqqhg0bpvfee0+xsbHeqzoIlP93mVbram051lvSWqvLAQAgYDQ4fFx66aWq6x7VOXPmnFNBTUXFjn2SJEdsW4srAQAgsPDeLj5Ss8cdPsrbED4AADgZ4cNHQgrc4cOVQvgAAOBkhA8fiSp2h4/QdoQPAABORvjwkdhSd/iIPC/d4koAAAgshA8fSXTulSTFd2PkAwCAk/l8hdPmqKLc6DFzv9K1V2P78r4uAACcjPDhA/n7bXpK9ygyUpqUaXU1AAAEFqZdfGCf+3YPtW0r2WzW1gIAQKBh5MMHDq3fpwtUoLZJmZISrC4HAICAwsiHD8R/PlM56qcp+b+1uhQAAAIO4cMHbPvcT7pUJfGYLQAApyJ8+EDEQfdNH7Z0HrMFAOBUhA8fiClxh4+ILMIHAACnInz4QOtj7vDRojPhAwCAUxE+vMxV7VJyjTt8tO5J+AAA4FSEDy8r3nxQ4aqWSzYl9U61uhwAAAIO63x4WX6xXY/rz8qIOaxJ0eFWlwMAQMAhfHjZHkdLPaV71LeLNMnqYgAACEBMu3jZyUurAwCA0zHy4WXObzfrApXpvISOklpaXQ4AAAGHkQ8v6zv/CeWon67b87zVpQAAEJAIH14Wddg97xKWybwLAABnQvjwsvij7vARnU34AADgTAgfXpbodIeP+G6EDwAAzoTw4UVlhWWKV4kkKbEP4QMAgDMhfHhR4Rr3qEepWiguPc7iagAACEyEDy86smGvJOlgRFvJZrO4GgAAAhPrfHjRrpAOelt/Vrv2UZpodTEAAAQowocXbXG211O6R7cOtLoSAAACF9MuXsTS6gAA/DBGPrwoasM36iub2rfpLCnW6nIAAAhIjHx40a3f3KVV6q/eRf+1uhQAAAIW4cOL2pS7511iuzDvAgDA2RA+vKTGWa0k135JUuuehA8AAM6G8OElBzccUKhcqlaoEnskW10OAAABi/DhJcXr3FMuhaGpCo0ItbgaAAACF+HDS0o3u8PHoUimXAAAqAvhw0ucO93h42g84QMAgLqwzoeXrI0bqo/1F3XrkyUWOAUA4OwIH16SU9VL/1AvPT7U6koAAAhsTLt4CUurAwBQP4QPL8nYMl99tUrtkiqsLgUAgIDGtIsXGJfRc/tGqYXKtMu2VVK21SUBABCwGPnwAsdeh1qoTJKUdD7zLgAA1IXw4QUH17pv+Dhia6nohGiLqwEAILARPrygZJM7fByMYNQDAIAfQvjwgvLt7vBR0iLd4koAAAh8hA8vqN61V5JU3pqRDwAAfgjhwwtC9rtHPmpSCB8AAPwQHrX1gtktf6aPlK2hgwZZXQoAAAGP8OEF8yuGaLWG6LKLra4EAIDAx7SLF7C0OgAA9cfIxzmqPFatQQf+o71qq7apfUWeAwCgboSPc1S4Nl+zdIOcilB4QrnV5QAAEPD4b/o5OrTBPedSGJamkDC6EwCAH8Jvy3NUttm9xsfhKG74AACgPggf56gy1z3ycbQl4QMAgPogfJwjs9cdPioTCR8AANQH4eMchR88/pxtGuEDAID6aHD4WLx4sa677jqlpaXJZrPpo48+qnXcGKNp06YpLS1NUVFRuvTSS7Vx40Zv1RtwYo64w0dEFuEDAID6aHD4KCsrU+/evfXcc8+d8fiTTz6pp556Ss8995y++eYbpaSk6Morr1Rpaek5FxuIno36ve7WUwofcqHVpQAAEBRsxhjT6C+22TRr1iyNGjVKknvUIy0tTZMmTdKUKVMkSU6nU8nJyXriiSd0++23n3YOp9Mpp9Pp2XY4HMrIyFBJSYni4uIaW5pfGCNFRUlOp7Rzp5SVZXVFAABYw+FwKD4+vl6/v716z0dubq4KCgo0fPhwzz673a5LLrlEy5YtO+PXTJ8+XfHx8Z5XRkaGN0vyqUOH3MFDktLSrK0FAIBg4dXwUVBQIElKTk6utT85Odlz7FT333+/SkpKPK+8vDxvluRTBesP6np9pEtbrpXdbnU1AAAEB58sr26z2WptG2NO23eC3W6XPUh/cx9bvEof6QZtqegtaa3V5QAAEBS8OvKRkpIiSaeNchQWFp42GtIUVOxwP+niiOVJFwAA6sur4SMrK0spKSmaN2+eZ19lZaUWLVqkwYMHe/NSAaF6tzt8VLQhfAAAUF8NnnY5evSotm/f7tnOzc3V2rVr1bp1a7Vr106TJk3SY489puzsbGVnZ+uxxx5TdHS0brnlFq8WHghCC9zv61KTmm5xJQAABI8Gh49Vq1Zp2LBhnu3JkydLksaMGaM33nhD9913n8rLy3XnnXfq8OHDGjBggObOnavY2FjvVR0gog65Rz5C2zHyAQBAfZ3TOh++0JDnhK22Jaq3Oles06pHP1e//x1hdTkAAFjGsnU+mptEp3vaJa4rIx8AANSXTx61bQ4qyo1uNy8pXXv1UL/2VpcDAEDQIHw00r58m/6tnygqSnqqndXVAAAQPJh2aaR97ntN1batdJb10wAAwBkw8tFIjlVbNUobFduyi6SuVpcDAEDQYOSjkWK//FizNFq3H/yD1aUAABBUCB+NdXzepSqJJ10AAGgIwkcjRRS5w4ctnfABAEBDED4aqUWJO3xEdGRpdQAAGoLw0UitjrnDR2xnRj4AAGgIwkcjuKpdSq7JlyS17kn4AACgIQgfjVC8+aDCVS2XbErsmWJ1OQAABBXW+WiEfSUtdKfeV1bcIT0ZHW51OQAABBXCRyPkHYrRv/UT9c22uhIAAIIP0y6NcGJp9XQedAEAoMEY+WiMlSt0g/LVI/Z8SVlWVwMAQFBh5KMRui/9uz7Uj3XZgX9aXQoAAEGH8NEI0Yfc8y5hmTxmCwBAQxE+GiG+zB0+orMJHwAANBThoxESne7wEd+dO04BAGgowkcDHS04qniVSJIS+zDyAQBAQxE+GqhwjXvUw6FYxbWNtbgaAACCD+GjgUo2ucPHwQhGPQAAaAzW+Wig7ZE99Ef9Sz072zTV6mIAAAhChI8G2lGapA90o2LOt7oSAACCE9MuDXRiafW2zLoAANAojHw0UErObI1WhbJjL5KUYnU5AAAEHUY+GmjUuof1gW5Ut9KVVpcCAEBQInw0UOty97xLbBfmXQAAaAzCRwNUV1QryVUgSWrTi/ABAEBjED4a4OD6AoXKpSqFKaFbktXlAAAQlAgfDXBo3V5J0oHQNIVGhFpcDQAAwYnw0QCl37nDx6Fo3lAOAIDGInw0gHOHO3wcbUn4AACgsVjnowG+ShylZ5WhywYlarDVxQAAEKQIHw2wvrS9PlR7DRlodSUAAAQvpl0aYK971oWl1QEAOAeMfDTAoO9eV5Li1a7VcEmxVpcDAEBQInzUk6vapT8Uj1OEqrSvxW4RPgAAaBymXeqpePNBRahKLtmU1DvV6nIAAAhahI96KvrW/Z4uhSEpCo8Ot7gaAACCF+Gjnhyb3HebFkexxgcAAOeC8FFPFccXGCuNI3wAAHAuCB/1ZPa4w4czkfABAMC5IHzUU9gBd/gwbQkfAACcC8JHPb2acL9G6wOVDhtpdSkAAAQ11vmop2WHu2qbumrihVZXAgBAcGPkox6M+X5p9XRmXQAAOCeMfNTD4byjuq38Ne1VutqmjZZks7okAACCFuGjHoq+ydUzmqQiW4Iio35sdTkAAAQ1pl3qoWSje86lKJI5FwAAzhXhox7Kt7vDhyOW8AEAwLkifNSDa7c7fFQkED4AADhXhI96CN3vDh+uNMIHAADnivBRD1GH3OEjNJPwAQDAuSJ81EPLo+7wEdOprcWVAAAQ/Agf9fDLsH9otD5Qi4vPt7oUAACCHut8/ICSEmlJ2QWSLtA/elldDQAAwc/rIx/Tpk2TzWar9UpJSfH2Zfxmzx73xzZtpJgYa2sBAKAp8MnIR/fu3TV//nzPdmhoqC8u4xeHlmzURM1Teateki6zuhwAAIKeT8JHWFhYUI92nMy2ZLGe1t1aefR6ET4AADh3PrnhdNu2bUpLS1NWVpZuuukm7dy586xtnU6nHA5HrVcgce1yz7tUJLWzuBIAAJoGr4ePAQMG6K233tKcOXP0yiuvqKCgQIMHD1ZxcfEZ20+fPl3x8fGeV0ZGhrdLOifh+93hw2QQPgAA8AabMcb48gJlZWXq2LGj7rvvPk2ePPm0406nU06n07PtcDiUkZGhkpISxcXF+bK0elkXP0S9HF9p2aT3NPiv/8/qcgAACEgOh0Px8fH1+v3t80dtY2Ji1LNnT23btu2Mx+12u+x2u6/LaLQ2Ze6Rj7jujHwAAOANPl9kzOl06rvvvlNqaqqvL+V11RXVSqnZJ0lKuIDwAQCAN3g9fNx7771atGiRcnNztXLlSt14441yOBwaM2aMty/lc4Vr8xUqlyoVrqReTePpHQAArOb1aZe9e/fq5ptvVlFRkRITEzVw4ECtWLFCmZmZ3r6Uz+0qT9b1+lo9kw/q9TBWogcAwBu8Hj5mzpzp7VNaZneBXavUXzFdrK4EAICmg//O1+HE0urtuN0DAACv4Y3l6tB6wQeaqDx1iLpSUnerywEAoElg5KMOvde8oad1t/qUfWV1KQAANBmEjzrEO9zzLtFdmHcBAMBbCB91SHa6w0fLXoQPAAC8hfBxFo69DrU0RyRJyf0JHwAAeAvh4ywOfOMe9Thsa6XY1BYWVwMAQNNB+DiLw6tzJUkFkVkWVwIAQNNC+DiL8k3u8HGkNeEDAABvInycxedJY9RfX2v55Q9ZXQoAAE0K4eMsvsuP1yr1V+SA3laXAgBAk0L4OItc96yLOnSwtg4AAJoallc/A+My+tV3v9NOZahD8q8lxVhdEgAATQbh4wyKtxRpYvVfJEkVWbdbXA0AAE0L0y5ncGCFe85lf0hbRbaMtLgaAACaFsLHGRxZ6w4fhS14zBYAAG8jfJxB1eadkqTSBO42BQDA2wgfZxCyxz3yUZXOyAcAAN5G+DiDmEJ3+AjvRPgAAMDbCB9nkOBwh48WvZh2AQDA2wgfp6ipkQaa5bpQK5Vw5flWlwMAQJPDOh+n2LtXKqhJVHF4olKzra4GAICmh5GPU+x0P+ii9u2l0FBLSwEAoEli5OMUztnz9ZRmqyTmUknXW10OAABNDiMfp4j86r+6W09rWPVcq0sBAKBJInycInLPVvcn2Z2sLQQAgCaK8HGK1oe2SZKie3O3KQAAvkD4OImr2qWMCnf4SBrCyAcAAL5A+DhJQc4+RalCVQpT24vaW10OAABNEuHjJAWL3fd77A3voLBIHgQCAMAXCB8nKf3WvcjHwVbc7wEAgK8QPk7yceKvlahCzbn2OatLAQCgyWJu4STbtttUpEQl9k+0uhQAAJosRj5OsvXEEh/MugAA4DOMfBzndDj11NYfa6O6qUvWo5LsVpcEAECTxMjHcbvnbtE1mq3b9bLS2kdYXQ4AAE0W4eO4osWbJEm7Y7vLFmKzuBoAAJouwsdxlWs2SpKOpHW3uBIAAJo2wsdxkTvc4cN07WZxJQAANG2Ej+OSi9zho8UARj4AAPAlwofcT7q0q9ouSWo7nPABAIAv8aitpNzFeUpVCxmFKLlPqtXlAADQpDHyIWm14zy11BH9rP9WnnQBAMDHCB+SVq+WJJvas6w6AAA+R/iQlJPj/ti3r7V1AADQHDT7ez5cNUbPLD5fW3WeunR4SVKC1SUBANCkNfvwsWfBDvVyfatO2qzQC+OtLgcAgCav2U+77PvUPeeyI6aXwqPDLa4GAICmr9mHj6rl7vBRnMkNHwAA+EOzDx9x293hw9aP8AEAgD806/BRdaxKnQ6vlCQlX3ehxdUAANA8NOvwsfntb9RCZSq2tdF5o3pYXQ4AAM1Cs37aZd3KCpWrv6rSsnRRWLPOYQAA+E2z/o37Zt5lGqCvtfp3/7S6FAAAmo1mGz4qK6WvvnJ/PuzyZtsNAAD4XbOddlkzp1ARx8IVndBK3btbXQ0AAM1Hs/0vf/kjf1KhkvRs28dl441sAQDwm2YZPozLqOPafytc1Wp/ZbbV5QAA0Kw0y/Dx7d8WK6N6l44qRr1+N8LqcgAAaFZ8Fj5eeOEFZWVlKTIyUn379tWSJUt8dakGK//z85Kk1V1+ppikGIurAQCgefFJ+Hjvvfc0adIkPfjgg1qzZo0uvvhiXXXVVdqzZ48vLtcgG2d8rUF7/yVJSn74TourAQCg+bEZY4y3TzpgwABdcMEFevHFFz37unbtqlGjRmn69Om12jqdTjmdTs+2w+FQRkaGSkpKFBcX57WajhyRPnxiq0Y+cZESTJGWZv1cQ3b+w2vnBwCgOXM4HIqPj6/X72+vj3xUVlYqJydHw4cPr7V/+PDhWrZs2Wntp0+frvj4eM8rIyPD2yVJko4dkyY8kaFwU6lt9u7qPu8Zn1wHAADUzevho6ioSDU1NUpOTq61Pzk5WQUFBae1v//++1VSUuJ55eXlebskSVJamnTH5CgtnPSxUnYuV6uOrX1yHQAAUDefLTJmO2XxDGPMafskyW63y263+6qMWv78Z0m61C/XAgAAZ+b1kY+EhASFhoaeNspRWFh42mgIAABofrwePiIiItS3b1/Nmzev1v558+Zp8ODB3r4cAAAIMj6Zdpk8ebJ+8YtfqF+/fho0aJBefvll7dmzR+PGjfPF5QAAQBDxSfj46U9/quLiYj3yyCPav3+/evTooc8++0yZmZm+uBwAAAgiPlnn41w05DlhAAAQGCxd5wMAAKAuhA8AAOBXhA8AAOBXhA8AAOBXhA8AAOBXhA8AAOBXhA8AAOBXhA8AAOBXPntX28Y6seaZw+GwuBIAAFBfJ35v12ft0oALH6WlpZKkjIwMiysBAAANVVpaqvj4+DrbBNzy6i6XS/n5+YqNjZXNZvPquR0OhzIyMpSXl8fS7XWgn+qHfqof+ql+6Kf6oZ/qx4p+MsaotLRUaWlpCgmp+66OgBv5CAkJUXp6uk+vERcXxw9tPdBP9UM/1Q/9VD/0U/3QT/Xj7376oRGPE7jhFAAA+BXhAwAA+FWzCh92u11Tp06V3W63upSARj/VD/1UP/RT/dBP9UM/1U+g91PA3XAKAACatmY18gEAAKxH+AAAAH5F+AAAAH5F+AAAAH5F+AAAAH7VbMLHCy+8oKysLEVGRqpv375asmSJ1SX51eLFi3XdddcpLS1NNptNH330Ua3jxhhNmzZNaWlpioqK0qWXXqqNGzfWauN0OjVhwgQlJCQoJiZGI0eO1N69e/34Xfje9OnT1b9/f8XGxiopKUmjRo3Sli1barWhr6QXX3xRvXr18qyeOGjQIH3++eee4/TRmU2fPl02m02TJk3y7KOvpGnTpslms9V6paSkeI7TR9/bt2+ffv7zn6tNmzaKjo5Wnz59lJOT4zkeNH1lmoGZM2ea8PBw88orr5hNmzaZiRMnmpiYGLN7926rS/Obzz77zDz44IPmgw8+MJLMrFmzah1//PHHTWxsrPnggw/M+vXrzU9/+lOTmppqHA6Hp824ceNM27Ztzbx588zq1avNsGHDTO/evU11dbWfvxvf+dGPfmRmzJhhNmzYYNauXWuuueYa065dO3P06FFPG/rKmE8++cTMnj3bbNmyxWzZssU88MADJjw83GzYsMEYQx+dyddff23at29vevXqZSZOnOjZT18ZM3XqVNO9e3ezf/9+z6uwsNBznD5yO3TokMnMzDRjx441K1euNLm5uWb+/Plm+/btnjbB0lfNInxceOGFZty4cbX2denSxfz+97+3qCJrnRo+XC6XSUlJMY8//rhnX0VFhYmPjzcvvfSSMcaYI0eOmPDwcDNz5kxPm3379pmQkBDzxRdf+K12fyssLDSSzKJFi4wx9FVdWrVqZV599VX66AxKS0tNdna2mTdvnrnkkks84YO+cps6darp3bv3GY/RR9+bMmWKGTJkyFmPB1NfNflpl8rKSuXk5Gj48OG19g8fPlzLli2zqKrAkpubq4KCglp9ZLfbdckll3j6KCcnR1VVVbXapKWlqUePHk26H0tKSiRJrVu3lkRfnUlNTY1mzpypsrIyDRo0iD46g/Hjx+uaa67RFVdcUWs/ffW9bdu2KS0tTVlZWbrpppu0c+dOSfTRyT755BP169dPP/nJT5SUlKTzzz9fr7zyiud4MPVVkw8fRUVFqqmpUXJycq39ycnJKigosKiqwHKiH+rqo4KCAkVERKhVq1ZnbdPUGGM0efJkDRkyRD169JBEX51s/fr1atGihex2u8aNG6dZs2apW7du9NEpZs6cqdWrV2v69OmnHaOv3AYMGKC33npLc+bM0SuvvKKCggINHjxYxcXF9NFJdu7cqRdffFHZ2dmaM2eOxo0bp9/+9rd66623JAXXz1OY365kMZvNVmvbGHPavuauMX3UlPvxrrvu0rp167R06dLTjtFXUufOnbV27VodOXJEH3zwgcaMGaNFixZ5jtNHUl5eniZOnKi5c+cqMjLyrO2ae19dddVVns979uypQYMGqWPHjnrzzTc1cOBASfSRJLlcLvXr10+PPfaYJOn888/Xxo0b9eKLL+rWW2/1tAuGvmryIx8JCQkKDQ09LdEVFhaelg6bqxN3ldfVRykpKaqsrNThw4fP2qYpmTBhgj755BMtWLBA6enpnv301fciIiJ03nnnqV+/fpo+fbp69+6tZ555hj46SU5OjgoLC9W3b1+FhYUpLCxMixYt0rPPPquwsDDP90pf1RYTE6OePXtq27Zt/DydJDU1Vd26dau1r2vXrtqzZ4+k4Pr3qcmHj4iICPXt21fz5s2rtX/evHkaPHiwRVUFlqysLKWkpNTqo8rKSi1atMjTR3379lV4eHitNvv379eGDRuaVD8aY3TXXXfpww8/1JdffqmsrKxax+mrszPGyOl00kcnufzyy7V+/XqtXbvW8+rXr59+9rOfae3aterQoQN9dQZOp1PfffedUlNT+Xk6yUUXXXTao/9bt25VZmampCD798lvt7Za6MSjtq+99prZtGmTmTRpkomJiTG7du2yujS/KS0tNWvWrDFr1qwxksxTTz1l1qxZ43nc+PHHHzfx8fHmww8/NOvXrzc333zzGR/PSk9PN/PnzzerV682l112WZN7lO2OO+4w8fHxZuHChbUe+zt27JinDX1lzP33328WL15scnNzzbp168wDDzxgQkJCzNy5c40x9FFdTn7axRj6yhhj7rnnHrNw4UKzc+dOs2LFCnPttdea2NhYz7/R9JHb119/bcLCwswf//hHs23bNvPOO++Y6Oho8/bbb3vaBEtfNYvwYYwxzz//vMnMzDQRERHmggsu8Dw62VwsWLDASDrtNWbMGGOM+xGtqVOnmpSUFGO3283QoUPN+vXra52jvLzc3HXXXaZ169YmKirKXHvttWbPnj0WfDe+c6Y+kmRmzJjhaUNfGfPLX/7S8/cpMTHRXH755Z7gYQx9VJdTwwd9ZTxrUYSHh5u0tDQzevRos3HjRs9x+uh7n376qenRo4ex2+2mS5cu5uWXX651PFj6ymaMMf4bZwEAAM1dk7/nAwAABBbCBwAA8CvCBwAA8CvCBwAA8CvCBwAA8CvCBwAA8CvCBwAA8CvCBwAA8CvCBwAA8CvCBwAA8CvCBwAA8Kv/DxHunKzLIEa1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_pred = PINN.test()\n",
    "plt.plot(x_true,'b')\n",
    "plt.plot(x_pred,'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ky6HsA0AWWTD"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF7H51LTWXDq",
    "outputId": "aefc6a9f-3ad4-417a-b9f7-438009e620af"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1D_FODE_stan_tune0.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_stan_tune0.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12331/2016390461.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtune_reps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1D_FODE_stan_tune\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_re_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \"\"\"\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1D_FODE_stan_tune0.mat'"
     ]
    }
   ],
   "source": [
    "for tune_reps in range(5):\n",
    "    label = \"1D_FODE_stan_tune\"+str(tune_reps)+\".mat\"\n",
    "    data = sio.loadmat(label)\n",
    "    re = np.array(data[\"test_re_loss\"])\n",
    "    print(np.mean(re[:,-1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_1D_FODE_tune.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
