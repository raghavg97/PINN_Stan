{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"medium\"\n",
    "label = \"KG_tanhALR_\" + level\n",
    "\n",
    "x = np.linspace(0,2,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        self.lambdas = torch.ones((2,),device = device)\n",
    "        self.lambda_alpha = 0.1\n",
    "            \n",
    "\n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "                    \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "    \n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.lambdas[0]*self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.lambdas[1]*self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    def lambda_update(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "        loss_bc1 = self.lambdas[0]*self.loss_BC(xt_BC,y_BC)\n",
    "        loss_bc1.backward()\n",
    "        bc1_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc1_grads.append(param.grad.view(-1))\n",
    "        bc1_grads = torch.cat(bc1_grads)\n",
    "        bc1_grads = torch.mean(torch.abs(bc1_grads))      \n",
    "        \n",
    "        loss_bc2 = self.lambdas[1]*self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_bc2.backward()\n",
    "        bc2_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc2_grads.append(param.grad.view(-1))\n",
    "        bc2_grads = torch.cat(bc2_grads)\n",
    "        bc2_grads = torch.mean(torch.abs(bc2_grads))    \n",
    "    \n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        loss_f.backward()\n",
    "        f_grads = []\n",
    "        for param in self.parameters():\n",
    "            f_grads.append(param.grad.view(-1))   \n",
    "        f_grads = torch.cat(f_grads)\n",
    "        f_grads = torch.max(torch.abs(f_grads))\n",
    "    \n",
    "        self.lambdas[0] = (1.0-self.lambda_alpha)*self.lambdas[0] + self.lambda_alpha*f_grads/bc1_grads\n",
    "        self.lambdas[1] = (1.0-self.lambda_alpha)*self.lambdas[1] + self.lambda_alpha*f_grads/bc2_grads\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    PINN.lambda_update(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_tanhALR_medium\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 28202.146 Test MSE 5.405370834384136 Test RE 1.6845364576202395\n",
      "1 Train Loss 9597.947 Test MSE 9.098443795323595 Test RE 2.185502089069815\n",
      "2 Train Loss 8033.152 Test MSE 10.6773839609942 Test RE 2.3675551147384826\n",
      "3 Train Loss 5347.22 Test MSE 10.827292602999393 Test RE 2.384117219232513\n",
      "4 Train Loss 1804.2693 Test MSE 16.178842682126053 Test RE 2.9143478953177735\n",
      "5 Train Loss 777.03864 Test MSE 17.283755628969477 Test RE 3.0122202673691914\n",
      "6 Train Loss 495.44568 Test MSE 16.332233425717117 Test RE 2.9281306922855475\n",
      "7 Train Loss 374.83017 Test MSE 15.507185277749358 Test RE 2.8532127466635413\n",
      "8 Train Loss 317.884 Test MSE 15.783495050916407 Test RE 2.878520036937746\n",
      "9 Train Loss 271.90802 Test MSE 15.48635052082592 Test RE 2.851295378242756\n",
      "10 Train Loss 256.88397 Test MSE 13.588977955716421 Test RE 2.6709211351702837\n",
      "11 Train Loss 217.4809 Test MSE 12.03048043437627 Test RE 2.5130964299619984\n",
      "12 Train Loss 167.59915 Test MSE 8.199525947010462 Test RE 2.07473216476464\n",
      "13 Train Loss 119.126015 Test MSE 5.328017965509325 Test RE 1.6724398530452984\n",
      "14 Train Loss 80.584946 Test MSE 3.8100224748639726 Test RE 1.4142670931203616\n",
      "15 Train Loss 62.65329 Test MSE 3.1848366172209004 Test RE 1.2930378761150345\n",
      "16 Train Loss 46.225304 Test MSE 2.2189382374890108 Test RE 1.0792952723399514\n",
      "17 Train Loss 36.344135 Test MSE 2.012008099120025 Test RE 1.027738272948972\n",
      "18 Train Loss 30.273163 Test MSE 1.7135806428214257 Test RE 0.9484620126983483\n",
      "19 Train Loss 25.378696 Test MSE 1.1799381016904624 Test RE 0.7870408609347713\n",
      "20 Train Loss 21.64063 Test MSE 0.5715035202132831 Test RE 0.5477433612692966\n",
      "21 Train Loss 17.066572 Test MSE 0.3202760671988736 Test RE 0.4100434804387951\n",
      "22 Train Loss 12.907541 Test MSE 0.18029405464905163 Test RE 0.30765102793813326\n",
      "23 Train Loss 10.043305 Test MSE 0.1199424339429416 Test RE 0.25093087235628014\n",
      "24 Train Loss 7.7579007 Test MSE 0.023053642994768125 Test RE 0.11001133866095955\n",
      "25 Train Loss 6.208551 Test MSE 0.01709381055831149 Test RE 0.09472990700077066\n",
      "26 Train Loss 4.6020474 Test MSE 0.010077341018444153 Test RE 0.07273453142532733\n",
      "27 Train Loss 3.4840689 Test MSE 0.0020392672977828275 Test RE 0.03271935584933387\n",
      "28 Train Loss 2.7341793 Test MSE 0.007919528863826969 Test RE 0.06447885854491227\n",
      "29 Train Loss 2.3750992 Test MSE 0.009365644789071991 Test RE 0.07011912835577165\n",
      "30 Train Loss 1.9995468 Test MSE 0.01382863859073269 Test RE 0.08520348936482874\n",
      "31 Train Loss 1.5828294 Test MSE 0.00645398378949713 Test RE 0.05820785597144016\n",
      "32 Train Loss 1.3201133 Test MSE 0.002919046567264342 Test RE 0.0391460709859183\n",
      "33 Train Loss 1.135309 Test MSE 0.004388791344800887 Test RE 0.047999878110283084\n",
      "34 Train Loss 0.9196681 Test MSE 0.004869383330508318 Test RE 0.050559718816474475\n",
      "35 Train Loss 0.8400868 Test MSE 0.006161160210453394 Test RE 0.05687205466515186\n",
      "36 Train Loss 0.6961234 Test MSE 0.00280960166937457 Test RE 0.03840520112189962\n",
      "37 Train Loss 0.5523736 Test MSE 0.003300254783333213 Test RE 0.04162376895766519\n",
      "38 Train Loss 0.49615973 Test MSE 0.0024666178202213777 Test RE 0.03598475913153721\n",
      "39 Train Loss 0.43795446 Test MSE 0.002560093834847634 Test RE 0.036660265808261296\n",
      "40 Train Loss 0.3800607 Test MSE 0.0007100673742709123 Test RE 0.019307117820994788\n",
      "41 Train Loss 0.3395249 Test MSE 0.0005380606468817723 Test RE 0.01680673228986765\n",
      "42 Train Loss 0.3043002 Test MSE 0.0005439030608380954 Test RE 0.016897732046544083\n",
      "43 Train Loss 0.26434705 Test MSE 0.0005896993398571298 Test RE 0.01759474546380582\n",
      "44 Train Loss 0.25399366 Test MSE 0.000732187913236175 Test RE 0.019605546169573777\n",
      "45 Train Loss 0.2252445 Test MSE 0.0009661375325004058 Test RE 0.022520972724266487\n",
      "46 Train Loss 0.21630496 Test MSE 0.0012726249398568358 Test RE 0.025847460637016394\n",
      "47 Train Loss 0.19775403 Test MSE 0.0013137259869875717 Test RE 0.02626153232955106\n",
      "48 Train Loss 0.1835251 Test MSE 0.0009508631332871803 Test RE 0.02234223792301803\n",
      "49 Train Loss 0.16718292 Test MSE 0.0008268134133186029 Test RE 0.020833940734894703\n",
      "50 Train Loss 0.15708977 Test MSE 0.000726735365224707 Test RE 0.01953240924410358\n",
      "51 Train Loss 0.1500883 Test MSE 0.0007047479436512556 Test RE 0.01923466276282197\n",
      "52 Train Loss 0.13741435 Test MSE 0.0008243555866053712 Test RE 0.020802951683158176\n",
      "53 Train Loss 0.12665072 Test MSE 0.0008208406447361847 Test RE 0.020758553805351552\n",
      "54 Train Loss 0.120078 Test MSE 0.0007623513532979648 Test RE 0.020005308613159044\n",
      "55 Train Loss 0.10635597 Test MSE 0.0007688224721844013 Test RE 0.020090035406488495\n",
      "56 Train Loss 0.102306955 Test MSE 0.0007906776372733939 Test RE 0.02037358218603616\n",
      "57 Train Loss 0.09186837 Test MSE 0.0008000262046205028 Test RE 0.020493671659570938\n",
      "58 Train Loss 0.08943606 Test MSE 0.0008447563739129776 Test RE 0.021058789637388994\n",
      "59 Train Loss 0.083403684 Test MSE 0.0009343411879457874 Test RE 0.022147280934653707\n",
      "60 Train Loss 0.079934224 Test MSE 0.0008858462325487728 Test RE 0.021564869725321054\n",
      "61 Train Loss 0.07804531 Test MSE 0.0008715971966045812 Test RE 0.021390728721570596\n",
      "62 Train Loss 0.07598244 Test MSE 0.0008968279257814256 Test RE 0.021698126118220303\n",
      "63 Train Loss 0.06938922 Test MSE 0.0009380661545304441 Test RE 0.022191384642043926\n",
      "64 Train Loss 0.06853499 Test MSE 0.0008579020139828653 Test RE 0.021222009828406153\n",
      "65 Train Loss 0.061071575 Test MSE 0.0007718181331381885 Test RE 0.02012913703666292\n",
      "66 Train Loss 0.059641168 Test MSE 0.0007415196171957827 Test RE 0.019730086538496703\n",
      "67 Train Loss 0.05762407 Test MSE 0.0006956182036775359 Test RE 0.019109667779196336\n",
      "68 Train Loss 0.055035602 Test MSE 0.0006399305291657052 Test RE 0.018328802114808387\n",
      "69 Train Loss 0.0537019 Test MSE 0.0006405282253048841 Test RE 0.01833735968234499\n",
      "70 Train Loss 0.052237324 Test MSE 0.0006263934956536663 Test RE 0.018133902960516746\n",
      "71 Train Loss 0.05061911 Test MSE 0.0006338405662200576 Test RE 0.018241379686393718\n",
      "72 Train Loss 0.047961377 Test MSE 0.0005935639813710212 Test RE 0.017652305593315525\n",
      "73 Train Loss 0.047405344 Test MSE 0.0005922764427309415 Test RE 0.017633149811587763\n",
      "74 Train Loss 0.04570994 Test MSE 0.0006023182604165216 Test RE 0.01778200313853957\n",
      "75 Train Loss 0.04306959 Test MSE 0.0005093311784807521 Test RE 0.01635188404245703\n",
      "76 Train Loss 0.041439746 Test MSE 0.0005006587754273876 Test RE 0.016212074247374662\n",
      "77 Train Loss 0.040695146 Test MSE 0.0005048299803031719 Test RE 0.016279469067169785\n",
      "78 Train Loss 0.03923256 Test MSE 0.00045911373548968086 Test RE 0.015524864222552375\n",
      "79 Train Loss 0.03726362 Test MSE 0.00043459019310064615 Test RE 0.015104544346005258\n",
      "80 Train Loss 0.036201913 Test MSE 0.00043724676389598056 Test RE 0.0151506396762176\n",
      "81 Train Loss 0.035769936 Test MSE 0.0004428032471891276 Test RE 0.015246602091556882\n",
      "82 Train Loss 0.035259183 Test MSE 0.00042413950248161906 Test RE 0.014921827975003984\n",
      "83 Train Loss 0.03448092 Test MSE 0.00042515631662670266 Test RE 0.014939703748113625\n",
      "84 Train Loss 0.033346437 Test MSE 0.0004000601009234535 Test RE 0.014492065482717793\n",
      "85 Train Loss 0.03257664 Test MSE 0.0004223812303115286 Test RE 0.014890866602354644\n",
      "86 Train Loss 0.03220175 Test MSE 0.00042555065470582896 Test RE 0.014946630528239387\n",
      "87 Train Loss 0.031356663 Test MSE 0.0003967944408524192 Test RE 0.014432795468473045\n",
      "88 Train Loss 0.030240241 Test MSE 0.0003292695679133648 Test RE 0.013147508629196301\n",
      "89 Train Loss 0.028927028 Test MSE 0.0003008229038825771 Test RE 0.012566754104783421\n",
      "90 Train Loss 0.027870461 Test MSE 0.000287345088450407 Test RE 0.012282013113651898\n",
      "91 Train Loss 0.027362445 Test MSE 0.0002752813881072773 Test RE 0.012021428907081789\n",
      "92 Train Loss 0.026916137 Test MSE 0.0002593515102826195 Test RE 0.011668420143701359\n",
      "93 Train Loss 0.02651728 Test MSE 0.00024812458326809556 Test RE 0.01141307220898651\n",
      "94 Train Loss 0.02530776 Test MSE 0.0002337620581632324 Test RE 0.011077829557096948\n",
      "95 Train Loss 0.024801748 Test MSE 0.00023710829169791987 Test RE 0.011156835723028297\n",
      "96 Train Loss 0.024156002 Test MSE 0.00022223961847235246 Test RE 0.010801359206163002\n",
      "97 Train Loss 0.023676781 Test MSE 0.00019883470073828343 Test RE 0.010216773316757756\n",
      "98 Train Loss 0.022842092 Test MSE 0.00020181451984310108 Test RE 0.010293045015984686\n",
      "99 Train Loss 0.022283172 Test MSE 0.00019298279534311354 Test RE 0.010065305570229515\n",
      "100 Train Loss 0.021643938 Test MSE 0.0001839822897868035 Test RE 0.009827785690513437\n",
      "101 Train Loss 0.021122241 Test MSE 0.00015974954116207673 Test RE 0.009157722459839196\n",
      "102 Train Loss 0.020602906 Test MSE 0.0001489760204406686 Test RE 0.008843534045634309\n",
      "103 Train Loss 0.019984307 Test MSE 0.00014899348856842838 Test RE 0.008844052503081326\n",
      "104 Train Loss 0.019364247 Test MSE 0.0001366056705254782 Test RE 0.008468413022502579\n",
      "105 Train Loss 0.018721329 Test MSE 0.00012727311485296014 Test RE 0.008174025800412588\n",
      "106 Train Loss 0.018129075 Test MSE 0.00012334554498257105 Test RE 0.008046914775129872\n",
      "107 Train Loss 0.01773679 Test MSE 0.00011451080835822839 Test RE 0.007753377112019893\n",
      "108 Train Loss 0.01740283 Test MSE 0.00010862426590387694 Test RE 0.007551462931429294\n",
      "109 Train Loss 0.017304193 Test MSE 0.00010302678363927708 Test RE 0.007354323652989614\n",
      "110 Train Loss 0.017246338 Test MSE 9.617144721688344e-05 Test RE 0.007105436185931033\n",
      "111 Train Loss 0.016792908 Test MSE 8.484130408494351e-05 Test RE 0.006673771536305579\n",
      "112 Train Loss 0.016412575 Test MSE 7.279742032146486e-05 Test RE 0.006181952482272382\n",
      "113 Train Loss 0.016082805 Test MSE 6.970684504629763e-05 Test RE 0.006049303597731652\n",
      "114 Train Loss 0.015839148 Test MSE 6.565132255895701e-05 Test RE 0.00587069350360089\n",
      "115 Train Loss 0.015629586 Test MSE 6.420526516363542e-05 Test RE 0.005805678597512726\n",
      "116 Train Loss 0.015269438 Test MSE 5.9289309268387105e-05 Test RE 0.00557899359774548\n",
      "117 Train Loss 0.015332815 Test MSE 4.949653642392108e-05 Test RE 0.0050974746246063105\n",
      "118 Train Loss 0.015052325 Test MSE 5.0014322881269714e-05 Test RE 0.005124067762693248\n",
      "119 Train Loss 0.014452147 Test MSE 5.9213636433789476e-05 Test RE 0.005575432137333124\n",
      "120 Train Loss 0.014069985 Test MSE 5.7637414240973016e-05 Test RE 0.0055007247281618436\n",
      "121 Train Loss 0.013865956 Test MSE 5.562042818448616e-05 Test RE 0.0054036203876601935\n",
      "122 Train Loss 0.013675237 Test MSE 5.681486111514281e-05 Test RE 0.005461332802161322\n",
      "123 Train Loss 0.013470007 Test MSE 5.723222905018792e-05 Test RE 0.0054813558586693486\n",
      "124 Train Loss 0.013247114 Test MSE 4.8057792515521766e-05 Test RE 0.005022842689318452\n",
      "125 Train Loss 0.012935907 Test MSE 4.1678868911062415e-05 Test RE 0.0046776274549452344\n",
      "126 Train Loss 0.012739289 Test MSE 4.039848322614402e-05 Test RE 0.004605218042565604\n",
      "127 Train Loss 0.012492663 Test MSE 3.770613498733498e-05 Test RE 0.004449115462672963\n",
      "128 Train Loss 0.012412306 Test MSE 3.6867989117721435e-05 Test RE 0.0043993892874390475\n",
      "129 Train Loss 0.012257955 Test MSE 3.3964532412161594e-05 Test RE 0.004222605292293523\n",
      "130 Train Loss 0.012083158 Test MSE 3.29038277006545e-05 Test RE 0.004156146798778325\n",
      "131 Train Loss 0.011938017 Test MSE 3.046171671471761e-05 Test RE 0.003998939697119476\n",
      "132 Train Loss 0.01159927 Test MSE 3.183180653235053e-05 Test RE 0.0040878816224960805\n",
      "133 Train Loss 0.01128047 Test MSE 2.9853352126457472e-05 Test RE 0.003958805996590723\n",
      "134 Train Loss 0.010783326 Test MSE 2.3299406052908902e-05 Test RE 0.0034973580198419795\n",
      "135 Train Loss 0.0103981355 Test MSE 2.533500163013132e-05 Test RE 0.00364693594942874\n",
      "136 Train Loss 0.010214758 Test MSE 2.348835248348564e-05 Test RE 0.0035115102905472523\n",
      "137 Train Loss 0.010052268 Test MSE 2.1491592139845107e-05 Test RE 0.0033589378072219895\n",
      "138 Train Loss 0.0098921135 Test MSE 2.0369892842168916e-05 Test RE 0.0032701075763262154\n",
      "139 Train Loss 0.009722095 Test MSE 1.9842238424575755e-05 Test RE 0.003227475837145397\n",
      "140 Train Loss 0.00954515 Test MSE 2.182231051013273e-05 Test RE 0.003384683257737727\n",
      "141 Train Loss 0.00921187 Test MSE 2.2456722789320122e-05 Test RE 0.003433530081536601\n",
      "142 Train Loss 0.00890245 Test MSE 1.9372719640720818e-05 Test RE 0.0031890620127718893\n",
      "143 Train Loss 0.008725804 Test MSE 2.0176806146205767e-05 Test RE 0.0032545719595223023\n",
      "144 Train Loss 0.008577865 Test MSE 1.9550159241751886e-05 Test RE 0.0032036334326588233\n",
      "145 Train Loss 0.008395497 Test MSE 2.400349596188045e-05 Test RE 0.0035498084344667167\n",
      "146 Train Loss 0.008293836 Test MSE 2.27748896907893e-05 Test RE 0.0034577676650938143\n",
      "147 Train Loss 0.008221825 Test MSE 2.3540427785778224e-05 Test RE 0.003515400765991504\n",
      "148 Train Loss 0.008117631 Test MSE 2.35955931776571e-05 Test RE 0.0035195174069680363\n",
      "149 Train Loss 0.0079860315 Test MSE 2.328333257895708e-05 Test RE 0.0034961514570779977\n",
      "150 Train Loss 0.007859414 Test MSE 2.1149462389922958e-05 Test RE 0.0033320946845305515\n",
      "151 Train Loss 0.0076592485 Test MSE 1.989353110377352e-05 Test RE 0.0032316446973363446\n",
      "152 Train Loss 0.0074999863 Test MSE 2.4078097030670566e-05 Test RE 0.0035553204245317546\n",
      "153 Train Loss 0.007269138 Test MSE 2.5304563976144e-05 Test RE 0.0036447445634460065\n",
      "154 Train Loss 0.0071160938 Test MSE 2.3879357927376522e-05 Test RE 0.0035406173261134984\n",
      "155 Train Loss 0.0070240893 Test MSE 2.331025216833721e-05 Test RE 0.003498171953364497\n",
      "156 Train Loss 0.0069616283 Test MSE 2.1208227267944333e-05 Test RE 0.003336720672311396\n",
      "157 Train Loss 0.0069195842 Test MSE 2.3157019488879364e-05 Test RE 0.0034866551734054215\n",
      "158 Train Loss 0.0068559283 Test MSE 1.9400719061143826e-05 Test RE 0.003191365758698522\n",
      "159 Train Loss 0.006811355 Test MSE 1.9023333324554597e-05 Test RE 0.0031601738604330196\n",
      "160 Train Loss 0.0067185387 Test MSE 1.7841773408779393e-05 Test RE 0.0030604597866951085\n",
      "161 Train Loss 0.0066472697 Test MSE 1.8270879503944665e-05 Test RE 0.003097044134873479\n",
      "162 Train Loss 0.0065731835 Test MSE 2.026843922879013e-05 Test RE 0.00326195391646788\n",
      "163 Train Loss 0.0065092365 Test MSE 2.0105496728549225e-05 Test RE 0.003248815670594842\n",
      "164 Train Loss 0.0064042183 Test MSE 2.5362674908383892e-05 Test RE 0.0036489271695300143\n",
      "165 Train Loss 0.006224912 Test MSE 2.3488684683610876e-05 Test RE 0.003511535122430088\n",
      "166 Train Loss 0.0060890964 Test MSE 2.95246719935792e-05 Test RE 0.003936952802841745\n",
      "167 Train Loss 0.0060035414 Test MSE 2.7348706930635168e-05 Test RE 0.0037890999932006226\n",
      "168 Train Loss 0.0059076506 Test MSE 2.407667469236296e-05 Test RE 0.0035552154132613228\n",
      "169 Train Loss 0.005815436 Test MSE 2.3407175453165524e-05 Test RE 0.003505437052873888\n",
      "170 Train Loss 0.0057594734 Test MSE 2.3145866309014094e-05 Test RE 0.003485815428554568\n",
      "171 Train Loss 0.005707467 Test MSE 2.008791305118752e-05 Test RE 0.0032473947004242453\n",
      "172 Train Loss 0.005650778 Test MSE 2.2422365349490597e-05 Test RE 0.003430902528541419\n",
      "173 Train Loss 0.00564631 Test MSE 2.337943618981419e-05 Test RE 0.003503359333853366\n",
      "174 Train Loss 0.005578412 Test MSE 2.1091609022062556e-05 Test RE 0.003327534168832592\n",
      "175 Train Loss 0.0055625937 Test MSE 2.437357196366201e-05 Test RE 0.003577068506480248\n",
      "176 Train Loss 0.0055038063 Test MSE 2.2091777952479274e-05 Test RE 0.003405516606199776\n",
      "177 Train Loss 0.0053929286 Test MSE 2.3589557975184093e-05 Test RE 0.0035190672729449105\n",
      "178 Train Loss 0.0053031086 Test MSE 2.46218280237898e-05 Test RE 0.0035952393993783508\n",
      "179 Train Loss 0.005228449 Test MSE 2.6886673445394844e-05 Test RE 0.003756956822392259\n",
      "180 Train Loss 0.00515029 Test MSE 2.3332040195160527e-05 Test RE 0.003499806437236054\n",
      "181 Train Loss 0.0050463625 Test MSE 2.1623938806838044e-05 Test RE 0.003369264216182433\n",
      "182 Train Loss 0.0049211 Test MSE 1.9016749214086633e-05 Test RE 0.0031596269338216706\n",
      "183 Train Loss 0.0048543066 Test MSE 1.6620358069088862e-05 Test RE 0.002953846042192457\n",
      "184 Train Loss 0.0047768382 Test MSE 1.5506834887970434e-05 Test RE 0.0028531805118571264\n",
      "185 Train Loss 0.004762433 Test MSE 1.5160625881452878e-05 Test RE 0.002821150356788767\n",
      "186 Train Loss 0.0046951007 Test MSE 1.674925011695167e-05 Test RE 0.0029652775640210006\n",
      "187 Train Loss 0.004632622 Test MSE 1.7053979845007823e-05 Test RE 0.0029921305636476272\n",
      "188 Train Loss 0.004553515 Test MSE 1.806888187367992e-05 Test RE 0.0030798765348609447\n",
      "189 Train Loss 0.0044081556 Test MSE 2.158000469309021e-05 Test RE 0.0033658397498458783\n",
      "190 Train Loss 0.0043143784 Test MSE 2.161793968228484e-05 Test RE 0.003368796816649966\n",
      "191 Train Loss 0.0043110973 Test MSE 2.2564620144233467e-05 Test RE 0.0034417687031542956\n",
      "192 Train Loss 0.004225208 Test MSE 2.2054904644366293e-05 Test RE 0.0034026733514520026\n",
      "193 Train Loss 0.004127313 Test MSE 2.1094058511572572e-05 Test RE 0.003327727386035636\n",
      "194 Train Loss 0.004087094 Test MSE 1.914836709084483e-05 Test RE 0.0031705422143279605\n",
      "195 Train Loss 0.003976099 Test MSE 1.855051632386127e-05 Test RE 0.003120654354751782\n",
      "196 Train Loss 0.0039205896 Test MSE 1.862045429545671e-05 Test RE 0.0031265314664321877\n",
      "197 Train Loss 0.0038512165 Test MSE 1.7830325117095874e-05 Test RE 0.0030594777470244663\n",
      "198 Train Loss 0.003808803 Test MSE 1.614443871165297e-05 Test RE 0.002911247596347413\n",
      "199 Train Loss 0.0037559203 Test MSE 1.7199731640029993e-05 Test RE 0.003004889478733293\n",
      "200 Train Loss 0.0037018624 Test MSE 1.777699489904428e-05 Test RE 0.003054898896069881\n",
      "201 Train Loss 0.0036766762 Test MSE 1.741403661665449e-05 Test RE 0.003023551667001013\n",
      "202 Train Loss 0.0036423097 Test MSE 1.7365825033128835e-05 Test RE 0.003019363343242821\n",
      "203 Train Loss 0.003646006 Test MSE 1.9483562538908555e-05 Test RE 0.0031981722641811444\n",
      "204 Train Loss 0.003602094 Test MSE 1.7525353960180528e-05 Test RE 0.003033200135690663\n",
      "205 Train Loss 0.0035686453 Test MSE 1.7533923755253164e-05 Test RE 0.0030339416535708832\n",
      "206 Train Loss 0.0035592269 Test MSE 1.9014120628142635e-05 Test RE 0.003159408556908926\n",
      "207 Train Loss 0.0034823273 Test MSE 2.0273185983170407e-05 Test RE 0.0032623358597301147\n",
      "208 Train Loss 0.0033933173 Test MSE 2.0688821925056006e-05 Test RE 0.0032956079998779073\n",
      "209 Train Loss 0.003359538 Test MSE 1.986165218978658e-05 Test RE 0.0032290543420038266\n",
      "210 Train Loss 0.0032630113 Test MSE 1.77754964029979e-05 Test RE 0.0030547701383575286\n",
      "211 Train Loss 0.0032043462 Test MSE 1.7639452298836637e-05 Test RE 0.0030430579003942744\n",
      "212 Train Loss 0.0031744395 Test MSE 1.7766720926214853e-05 Test RE 0.0030540159998178793\n",
      "213 Train Loss 0.003135306 Test MSE 1.8712856121123456e-05 Test RE 0.0031342793895706217\n",
      "214 Train Loss 0.003093601 Test MSE 1.786152342275001e-05 Test RE 0.003062153211563873\n",
      "215 Train Loss 0.0030961663 Test MSE 1.804090219358255e-05 Test RE 0.003077491015193608\n",
      "216 Train Loss 0.0030613753 Test MSE 1.821253849786932e-05 Test RE 0.0030920955734730256\n",
      "217 Train Loss 0.003043989 Test MSE 1.8092531266592034e-05 Test RE 0.003081891418604305\n",
      "218 Train Loss 0.0030162442 Test MSE 1.7895953527412096e-05 Test RE 0.003065103113842589\n",
      "219 Train Loss 0.0030214523 Test MSE 1.759979957253988e-05 Test RE 0.003039635644730038\n",
      "220 Train Loss 0.0030283951 Test MSE 1.790205657151177e-05 Test RE 0.0030656257142408993\n",
      "221 Train Loss 0.00299525 Test MSE 1.743516972820003e-05 Test RE 0.0030253857529729524\n",
      "222 Train Loss 0.0029773419 Test MSE 1.7692975554729358e-05 Test RE 0.003047671167261096\n",
      "223 Train Loss 0.00296607 Test MSE 1.8193692212831133e-05 Test RE 0.003090495313357391\n",
      "224 Train Loss 0.0029494315 Test MSE 1.9064913532976956e-05 Test RE 0.003163625646765643\n",
      "225 Train Loss 0.0029484981 Test MSE 1.880936748123922e-05 Test RE 0.0031423515016151637\n",
      "226 Train Loss 0.0028584234 Test MSE 1.8030190204305832e-05 Test RE 0.0030765772320206636\n",
      "227 Train Loss 0.0028194156 Test MSE 1.7425094552380496e-05 Test RE 0.0030245114942576688\n",
      "228 Train Loss 0.002789129 Test MSE 1.7724349389920616e-05 Test RE 0.003050372091766672\n",
      "229 Train Loss 0.0027589977 Test MSE 1.7276830880901196e-05 Test RE 0.003011616782900197\n",
      "230 Train Loss 0.0027584853 Test MSE 1.753395899558956e-05 Test RE 0.0030339447024341115\n",
      "231 Train Loss 0.00272537 Test MSE 1.825702297149015e-05 Test RE 0.0030958695216827155\n",
      "232 Train Loss 0.00274062 Test MSE 1.6498900359020016e-05 Test RE 0.0029430332417780957\n",
      "233 Train Loss 0.0026982503 Test MSE 1.6352513620949762e-05 Test RE 0.0029299480995436107\n",
      "234 Train Loss 0.0026570878 Test MSE 1.5821830744022774e-05 Test RE 0.00288201365909748\n",
      "235 Train Loss 0.0026172237 Test MSE 1.587253859888326e-05 Test RE 0.0028866282902127094\n",
      "236 Train Loss 0.0025830558 Test MSE 1.615947311519414e-05 Test RE 0.002912602821103937\n",
      "237 Train Loss 0.0025429237 Test MSE 1.5818002871658623e-05 Test RE 0.0028816650064049866\n",
      "238 Train Loss 0.0025191887 Test MSE 1.5793555010275744e-05 Test RE 0.0028794372349899055\n",
      "239 Train Loss 0.002487619 Test MSE 1.5991310645470427e-05 Test RE 0.002897408284848019\n",
      "240 Train Loss 0.0024630812 Test MSE 1.631295972010376e-05 Test RE 0.0029264024354280034\n",
      "241 Train Loss 0.0024426798 Test MSE 1.673091429859262e-05 Test RE 0.0029636540382263787\n",
      "242 Train Loss 0.0024256737 Test MSE 1.6898133526713998e-05 Test RE 0.0029784275227340553\n",
      "243 Train Loss 0.0024096915 Test MSE 1.709750393276135e-05 Test RE 0.0029959462937362348\n",
      "244 Train Loss 0.0024105927 Test MSE 1.7175154262425053e-05 Test RE 0.00300274180845527\n",
      "245 Train Loss 0.0024077096 Test MSE 1.76782791390656e-05 Test RE 0.0030464051521971965\n",
      "246 Train Loss 0.00240526 Test MSE 1.7732293011742252e-05 Test RE 0.0030510555664446746\n",
      "247 Train Loss 0.0024225344 Test MSE 1.802972512270525e-05 Test RE 0.0030765375522204394\n",
      "248 Train Loss 0.002418164 Test MSE 1.636686149495077e-05 Test RE 0.002931233201941741\n",
      "249 Train Loss 0.0023827564 Test MSE 1.5925557579484514e-05 Test RE 0.002891445367725526\n",
      "250 Train Loss 0.0023690094 Test MSE 1.5139321620551692e-05 Test RE 0.002819167468578145\n",
      "251 Train Loss 0.0023325437 Test MSE 1.4962642373187073e-05 Test RE 0.0028026690368271523\n",
      "252 Train Loss 0.0023313938 Test MSE 1.4334610219550072e-05 Test RE 0.0027432198317750888\n",
      "253 Train Loss 0.0022888605 Test MSE 1.465783396229024e-05 Test RE 0.0027739751522949953\n",
      "254 Train Loss 0.002284229 Test MSE 1.3755225080336472e-05 Test RE 0.0026872094510868106\n",
      "255 Train Loss 0.0022339113 Test MSE 1.3808991981014394e-05 Test RE 0.0026924562575956425\n",
      "256 Train Loss 0.0022101034 Test MSE 1.3530099085391643e-05 Test RE 0.0026651285164676942\n",
      "257 Train Loss 0.0021694384 Test MSE 1.339458803957333e-05 Test RE 0.0026517485997782776\n",
      "258 Train Loss 0.002141513 Test MSE 1.3401059919480277e-05 Test RE 0.0026523891467629705\n",
      "259 Train Loss 0.002123128 Test MSE 1.3411428197172047e-05 Test RE 0.0026534150130071597\n",
      "260 Train Loss 0.0021086389 Test MSE 1.3411428197172047e-05 Test RE 0.0026534150130071597\n",
      "261 Train Loss 0.0020976656 Test MSE 1.3407129354054703e-05 Test RE 0.0026529897216473544\n",
      "262 Train Loss 0.0020877917 Test MSE 1.3407129354054703e-05 Test RE 0.0026529897216473544\n",
      "263 Train Loss 0.0020788412 Test MSE 1.3407129354054703e-05 Test RE 0.0026529897216473544\n",
      "264 Train Loss 0.0020761143 Test MSE 1.3407129354054703e-05 Test RE 0.0026529897216473544\n",
      "265 Train Loss 0.0020756274 Test MSE 1.3407129354054703e-05 Test RE 0.0026529897216473544\n",
      "266 Train Loss 0.0020757387 Test MSE 1.3407129354054703e-05 Test RE 0.0026529897216473544\n",
      "267 Train Loss 0.0020759583 Test MSE 1.3407129354054703e-05 Test RE 0.0026529897216473544\n",
      "268 Train Loss 0.0020722044 Test MSE 1.3407154005746448e-05 Test RE 0.002652992160672632\n",
      "269 Train Loss 0.0020714991 Test MSE 1.3407154005746448e-05 Test RE 0.002652992160672632\n",
      "270 Train Loss 0.0020730537 Test MSE 1.3425394198042883e-05 Test RE 0.002654796221382906\n",
      "271 Train Loss 0.0020695603 Test MSE 1.385370635652174e-05 Test RE 0.002696811904951445\n",
      "272 Train Loss 0.0020613568 Test MSE 1.3772023110274575e-05 Test RE 0.002688849775096177\n",
      "273 Train Loss 0.0020620252 Test MSE 1.3732960664769876e-05 Test RE 0.0026850337913906478\n",
      "274 Train Loss 0.0020498994 Test MSE 1.3569706005043825e-05 Test RE 0.002669026506905968\n",
      "275 Train Loss 0.0020481308 Test MSE 1.3725037247730648e-05 Test RE 0.002684259096385992\n",
      "276 Train Loss 0.0020366732 Test MSE 1.4020867514701583e-05 Test RE 0.0027130332131279173\n",
      "277 Train Loss 0.0020787085 Test MSE 1.5206310953958146e-05 Test RE 0.002825397790582945\n",
      "278 Train Loss 0.0020658947 Test MSE 1.4299101514998545e-05 Test RE 0.0027398200678796624\n",
      "279 Train Loss 0.0020368916 Test MSE 1.4905984320922592e-05 Test RE 0.0027973576628877853\n",
      "280 Train Loss 0.0020075052 Test MSE 1.4846493005189654e-05 Test RE 0.0027917698108927643\n",
      "281 Train Loss 0.0019903562 Test MSE 1.5119794757099911e-05 Test RE 0.002817348785353571\n",
      "282 Train Loss 0.001963471 Test MSE 1.390759081058903e-05 Test RE 0.002702051485051128\n",
      "283 Train Loss 0.0019506859 Test MSE 1.4049116174744916e-05 Test RE 0.0027157648910764148\n",
      "284 Train Loss 0.0019244018 Test MSE 1.3700491399513756e-05 Test RE 0.002681857758604909\n",
      "285 Train Loss 0.0019099952 Test MSE 1.3794751423622275e-05 Test RE 0.0026910675983761304\n",
      "286 Train Loss 0.0019105511 Test MSE 1.4706076099336696e-05 Test RE 0.0027785362818882465\n",
      "287 Train Loss 0.001878601 Test MSE 1.5693705766201453e-05 Test RE 0.0028703206841852115\n",
      "288 Train Loss 0.0018878342 Test MSE 1.5191422410459701e-05 Test RE 0.0028240142742315157\n",
      "289 Train Loss 0.0018663455 Test MSE 1.4706882575873356e-05 Test RE 0.002778612467866811\n",
      "290 Train Loss 0.001839736 Test MSE 1.475660557851665e-05 Test RE 0.00278330565736807\n",
      "291 Train Loss 0.0018144333 Test MSE 1.4055129643346863e-05 Test RE 0.00271634604577358\n",
      "292 Train Loss 0.0017995714 Test MSE 1.4244485206623255e-05 Test RE 0.002734582605237849\n",
      "293 Train Loss 0.0017876578 Test MSE 1.4518190826644829e-05 Test RE 0.002760729893569366\n",
      "294 Train Loss 0.0017799964 Test MSE 1.4523572525665443e-05 Test RE 0.00276124152896993\n",
      "295 Train Loss 0.0017701684 Test MSE 1.4816201652397947e-05 Test RE 0.0027889203277316134\n",
      "296 Train Loss 0.001768475 Test MSE 1.4155075633301702e-05 Test RE 0.0027259869019052294\n",
      "297 Train Loss 0.0017659779 Test MSE 1.372608815670672e-05 Test RE 0.002684361859603725\n",
      "298 Train Loss 0.0017447259 Test MSE 1.1734700936511248e-05 Test RE 0.0024820108782181334\n",
      "299 Train Loss 0.0017222193 Test MSE 1.1989286664999703e-05 Test RE 0.002508790172748849\n",
      "Training time: 245.04\n",
      "KG_tanhALR_medium\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 25614.475 Test MSE 17.161080951765822 Test RE 3.001511333961319\n",
      "1 Train Loss 10396.04 Test MSE 11.535997102895971 Test RE 2.4609071993951903\n",
      "2 Train Loss 7669.6533 Test MSE 10.82053163173521 Test RE 2.3833727364838224\n",
      "3 Train Loss 2827.2427 Test MSE 11.034009419384079 Test RE 2.4067686333320593\n",
      "4 Train Loss 897.13995 Test MSE 17.33164733411442 Test RE 3.0163906737645734\n",
      "5 Train Loss 492.45056 Test MSE 18.31422037425906 Test RE 3.100715252090184\n",
      "6 Train Loss 358.3156 Test MSE 16.04598326613116 Test RE 2.902357026782016\n",
      "7 Train Loss 287.42163 Test MSE 15.926635167004257 Test RE 2.891543189504194\n",
      "8 Train Loss 245.38297 Test MSE 15.856665484351787 Test RE 2.885184562661905\n",
      "9 Train Loss 215.7143 Test MSE 15.205964720770977 Test RE 2.8253656245943133\n",
      "10 Train Loss 187.21805 Test MSE 13.300857112913873 Test RE 2.642454278812904\n",
      "11 Train Loss 110.46369 Test MSE 6.965163421495721 Test RE 1.912200040024866\n",
      "12 Train Loss 61.493404 Test MSE 3.894210977966323 Test RE 1.4298069574595744\n",
      "13 Train Loss 39.31453 Test MSE 1.9901807354835688 Test RE 1.022148337661423\n",
      "14 Train Loss 23.493912 Test MSE 0.6414137619094966 Test RE 0.5802789339449314\n",
      "15 Train Loss 13.289652 Test MSE 0.22132823164761664 Test RE 0.3408678761974897\n",
      "16 Train Loss 8.683791 Test MSE 0.17980665873456111 Test RE 0.3072349040355145\n",
      "17 Train Loss 6.424488 Test MSE 0.11107935301027595 Test RE 0.24148176329452006\n",
      "18 Train Loss 4.613928 Test MSE 0.05475137656062917 Test RE 0.1695372713318111\n",
      "19 Train Loss 3.384469 Test MSE 0.027564100719139187 Test RE 0.12029278555585074\n",
      "20 Train Loss 2.801361 Test MSE 0.018188398770029958 Test RE 0.09771582460267872\n",
      "21 Train Loss 2.2363508 Test MSE 0.009455131165857463 Test RE 0.07045331728511472\n",
      "22 Train Loss 1.7728889 Test MSE 0.004387312237422667 Test RE 0.0479917889860648\n",
      "23 Train Loss 1.3601958 Test MSE 0.004116645794007726 Test RE 0.04648784539391578\n",
      "24 Train Loss 1.1081245 Test MSE 0.004212604307472495 Test RE 0.04702653728173564\n",
      "25 Train Loss 0.88266194 Test MSE 0.0028244114378017104 Test RE 0.038506287441807806\n",
      "26 Train Loss 0.69771266 Test MSE 0.002096343002075819 Test RE 0.03317407629885429\n",
      "27 Train Loss 0.600612 Test MSE 0.0017821595078245718 Test RE 0.03058728668430547\n",
      "28 Train Loss 0.5309857 Test MSE 0.001092126429811928 Test RE 0.02394440922703311\n",
      "29 Train Loss 0.46862411 Test MSE 0.0007039711492428887 Test RE 0.019224059327866555\n",
      "30 Train Loss 0.4176332 Test MSE 0.0004756323003111394 Test RE 0.015801682728872106\n",
      "31 Train Loss 0.38334405 Test MSE 0.0003616963327902952 Test RE 0.013779698661704384\n",
      "32 Train Loss 0.34108567 Test MSE 0.00032826320211937383 Test RE 0.013127401504890591\n",
      "33 Train Loss 0.3073107 Test MSE 0.00037792282420152587 Test RE 0.014085401416522127\n",
      "34 Train Loss 0.28217393 Test MSE 0.0003613295483363499 Test RE 0.013772710118055307\n",
      "35 Train Loss 0.253586 Test MSE 0.0006143955789847173 Test RE 0.01795939525564607\n",
      "36 Train Loss 0.22678024 Test MSE 0.000623452709537485 Test RE 0.018091285445608524\n",
      "37 Train Loss 0.20333953 Test MSE 0.0007261699757576754 Test RE 0.01952480980163713\n",
      "38 Train Loss 0.16575298 Test MSE 0.0009548124871027262 Test RE 0.022388588426616098\n",
      "39 Train Loss 0.14911693 Test MSE 0.0008084884616279637 Test RE 0.02060177220144863\n",
      "40 Train Loss 0.1394825 Test MSE 0.0008494279720744517 Test RE 0.021116938098960585\n",
      "41 Train Loss 0.13010822 Test MSE 0.0006271144503622774 Test RE 0.018144335670260272\n",
      "42 Train Loss 0.12161066 Test MSE 0.0006098828183671706 Test RE 0.017893317450196816\n",
      "43 Train Loss 0.11284544 Test MSE 0.0005668985310575839 Test RE 0.017251240648985516\n",
      "44 Train Loss 0.10157489 Test MSE 0.0006854349341660698 Test RE 0.018969277297246876\n",
      "45 Train Loss 0.095511645 Test MSE 0.0007212200969988524 Test RE 0.019458151373027473\n",
      "46 Train Loss 0.086917475 Test MSE 0.0006746942032297337 Test RE 0.01882006664791155\n",
      "47 Train Loss 0.08189193 Test MSE 0.000799374991851901 Test RE 0.020485329146843503\n",
      "48 Train Loss 0.07750114 Test MSE 0.0007145210433001443 Test RE 0.019367572015020044\n",
      "49 Train Loss 0.073134094 Test MSE 0.0007624687078096439 Test RE 0.020006848338162325\n",
      "50 Train Loss 0.06997539 Test MSE 0.0008044302196760406 Test RE 0.02055000142082623\n",
      "51 Train Loss 0.06677964 Test MSE 0.0007954660227586193 Test RE 0.020435180809965106\n",
      "52 Train Loss 0.06430402 Test MSE 0.000749534344020418 Test RE 0.019836426446995348\n",
      "53 Train Loss 0.06146938 Test MSE 0.0006958582970495523 Test RE 0.019112965355885653\n",
      "54 Train Loss 0.05665775 Test MSE 0.0006969750897211414 Test RE 0.019128296539179575\n",
      "55 Train Loss 0.05421986 Test MSE 0.0006326747160956587 Test RE 0.01822459588924541\n",
      "56 Train Loss 0.051266186 Test MSE 0.0006484004313444958 Test RE 0.018449700274186784\n",
      "57 Train Loss 0.04778406 Test MSE 0.0006342910475880633 Test RE 0.018247860765840045\n",
      "58 Train Loss 0.045424815 Test MSE 0.0006398142047128078 Test RE 0.01832713616461468\n",
      "59 Train Loss 0.042743914 Test MSE 0.0005809705873085785 Test RE 0.017464040934107906\n",
      "60 Train Loss 0.04131641 Test MSE 0.0005717429351232816 Test RE 0.017324793669931983\n",
      "61 Train Loss 0.03965514 Test MSE 0.0005842709772368532 Test RE 0.017513575729633753\n",
      "62 Train Loss 0.038199954 Test MSE 0.0005371313832405642 Test RE 0.01679221289096246\n",
      "63 Train Loss 0.035055574 Test MSE 0.0005107141637601351 Test RE 0.016374069101481765\n",
      "64 Train Loss 0.03370398 Test MSE 0.00047105770829062216 Test RE 0.015725509492344785\n",
      "65 Train Loss 0.03304166 Test MSE 0.0004514591916701374 Test RE 0.015394901604109421\n",
      "66 Train Loss 0.03180255 Test MSE 0.0004137338227706424 Test RE 0.014737648040084251\n",
      "67 Train Loss 0.029272947 Test MSE 0.00041159543909544485 Test RE 0.014699512926617057\n",
      "68 Train Loss 0.026558189 Test MSE 0.00039492324704676487 Test RE 0.014398724335902745\n",
      "69 Train Loss 0.025879914 Test MSE 0.0003729591861021293 Test RE 0.013992596859588298\n",
      "70 Train Loss 0.025272151 Test MSE 0.00037129909318051323 Test RE 0.013961420636502214\n",
      "71 Train Loss 0.02454056 Test MSE 0.00035773184350442865 Test RE 0.013703972168547305\n",
      "72 Train Loss 0.023610212 Test MSE 0.0003433772341311006 Test RE 0.013426209411988972\n",
      "73 Train Loss 0.022491701 Test MSE 0.00031727863702804055 Test RE 0.012905893686834627\n",
      "74 Train Loss 0.021837028 Test MSE 0.00030628093649301793 Test RE 0.012680245175618306\n",
      "75 Train Loss 0.021206249 Test MSE 0.0002812339472245674 Test RE 0.012150706730054526\n",
      "76 Train Loss 0.020913081 Test MSE 0.0002520852511818086 Test RE 0.011503801682441141\n",
      "77 Train Loss 0.020171067 Test MSE 0.00024263507923402185 Test RE 0.01128611477339572\n",
      "78 Train Loss 0.019180873 Test MSE 0.0002450699316937383 Test RE 0.011342601715395617\n",
      "79 Train Loss 0.018660227 Test MSE 0.0002519224532099797 Test RE 0.011500086474914304\n",
      "80 Train Loss 0.017999101 Test MSE 0.00022228620535996125 Test RE 0.010802491262055467\n",
      "81 Train Loss 0.016893683 Test MSE 0.00020198730478301172 Test RE 0.010297450305216541\n",
      "82 Train Loss 0.016139973 Test MSE 0.00020420914957118723 Test RE 0.010353930989155656\n",
      "83 Train Loss 0.015805077 Test MSE 0.00019789495887079114 Test RE 0.01019260122603293\n",
      "84 Train Loss 0.015488009 Test MSE 0.00019133035432397283 Test RE 0.010022120163098327\n",
      "85 Train Loss 0.015236923 Test MSE 0.00018959666260846212 Test RE 0.009976610378458754\n",
      "86 Train Loss 0.014960208 Test MSE 0.00017912500394706983 Test RE 0.009697187078942696\n",
      "87 Train Loss 0.014646711 Test MSE 0.00017841260955619125 Test RE 0.00967788462574139\n",
      "88 Train Loss 0.014268523 Test MSE 0.00017117567110083216 Test RE 0.00947957107771813\n",
      "89 Train Loss 0.013709293 Test MSE 0.00016583143951293757 Test RE 0.009330418054592437\n",
      "90 Train Loss 0.013308838 Test MSE 0.00016406961832101272 Test RE 0.009280721738816299\n",
      "91 Train Loss 0.012985634 Test MSE 0.00014791414505571144 Test RE 0.008811960088716929\n",
      "92 Train Loss 0.012427972 Test MSE 0.00012331299354045958 Test RE 0.008045852896630354\n",
      "93 Train Loss 0.012047285 Test MSE 0.00012701648722373304 Test RE 0.008165780778088234\n",
      "94 Train Loss 0.011533443 Test MSE 0.00012651376962293545 Test RE 0.008149605115631328\n",
      "95 Train Loss 0.011246349 Test MSE 0.00011177855318977357 Test RE 0.0076603199567632976\n",
      "96 Train Loss 0.01070437 Test MSE 0.00010492135183404105 Test RE 0.007421635251306273\n",
      "97 Train Loss 0.010505959 Test MSE 0.00010840842988179123 Test RE 0.007543956836211373\n",
      "98 Train Loss 0.010384289 Test MSE 9.954087374225635e-05 Test RE 0.007228836330629014\n",
      "99 Train Loss 0.010095733 Test MSE 8.451851808853439e-05 Test RE 0.006661063970781057\n",
      "100 Train Loss 0.009933664 Test MSE 7.716464204143266e-05 Test RE 0.00636468391702053\n",
      "101 Train Loss 0.0096552 Test MSE 7.325295640572668e-05 Test RE 0.006201264366156612\n",
      "102 Train Loss 0.009326255 Test MSE 7.492122467678341e-05 Test RE 0.006271480865486592\n",
      "103 Train Loss 0.009010505 Test MSE 7.113187474147804e-05 Test RE 0.006110824274989386\n",
      "104 Train Loss 0.008808017 Test MSE 7.574893156800857e-05 Test RE 0.006306028415946409\n",
      "105 Train Loss 0.008639652 Test MSE 7.429358171748069e-05 Test RE 0.006245156353316405\n",
      "106 Train Loss 0.008419489 Test MSE 7.272832508996582e-05 Test RE 0.006179018004379662\n",
      "107 Train Loss 0.008348857 Test MSE 6.288795053353991e-05 Test RE 0.00574581168884468\n",
      "108 Train Loss 0.0082599465 Test MSE 6.217312518821226e-05 Test RE 0.005713063046051508\n",
      "109 Train Loss 0.008016109 Test MSE 6.42157981362826e-05 Test RE 0.005806154793241648\n",
      "110 Train Loss 0.007791604 Test MSE 6.994840151884735e-05 Test RE 0.00605977591722242\n",
      "111 Train Loss 0.0077148047 Test MSE 6.720905016796318e-05 Test RE 0.005939933002615836\n",
      "112 Train Loss 0.0075575393 Test MSE 6.667662198074644e-05 Test RE 0.0059163582298095456\n",
      "113 Train Loss 0.0075057833 Test MSE 6.55314293940499e-05 Test RE 0.005865330491569641\n",
      "114 Train Loss 0.0074302256 Test MSE 6.339775249569759e-05 Test RE 0.005769053927915077\n",
      "115 Train Loss 0.0072801863 Test MSE 6.734765782208137e-05 Test RE 0.005946054917175483\n",
      "116 Train Loss 0.0070186197 Test MSE 6.2859767578272e-05 Test RE 0.005744524064593992\n",
      "117 Train Loss 0.006867224 Test MSE 5.740094477318642e-05 Test RE 0.005489429197622025\n",
      "118 Train Loss 0.0067306748 Test MSE 5.585592319840349e-05 Test RE 0.005415047677832079\n",
      "119 Train Loss 0.006549824 Test MSE 5.296157109072551e-05 Test RE 0.005272882547086067\n",
      "120 Train Loss 0.0064401715 Test MSE 5.090211466984239e-05 Test RE 0.005169345742304899\n",
      "121 Train Loss 0.0063223895 Test MSE 5.17879221660251e-05 Test RE 0.005214130672920078\n",
      "122 Train Loss 0.006193486 Test MSE 5.197449139486108e-05 Test RE 0.005223514345142888\n",
      "123 Train Loss 0.006046868 Test MSE 4.975957411181443e-05 Test RE 0.005111001341576851\n",
      "124 Train Loss 0.0059331227 Test MSE 5.017465090184517e-05 Test RE 0.005132274155016979\n",
      "125 Train Loss 0.005807109 Test MSE 4.822758859715601e-05 Test RE 0.005031708129945387\n",
      "126 Train Loss 0.005697581 Test MSE 4.928507538813079e-05 Test RE 0.0050865741547157775\n",
      "127 Train Loss 0.005647091 Test MSE 4.7573704096071526e-05 Test RE 0.004997480994163843\n",
      "128 Train Loss 0.005528303 Test MSE 5.182298145280968e-05 Test RE 0.005215895300336026\n",
      "129 Train Loss 0.0054778242 Test MSE 5.605475047585992e-05 Test RE 0.00542467694090558\n",
      "130 Train Loss 0.005369051 Test MSE 6.051658349360205e-05 Test RE 0.0056364397427663875\n",
      "131 Train Loss 0.0053003025 Test MSE 5.8998527390432066e-05 Test RE 0.005565295814477973\n",
      "132 Train Loss 0.0052406215 Test MSE 5.7446399591980075e-05 Test RE 0.005491602259687001\n",
      "133 Train Loss 0.005134096 Test MSE 5.91659481512952e-05 Test RE 0.005573186570659609\n",
      "134 Train Loss 0.0051183775 Test MSE 5.8860131995017695e-05 Test RE 0.005558764604641375\n",
      "135 Train Loss 0.0050362297 Test MSE 5.444529206126455e-05 Test RE 0.005346232400178963\n",
      "136 Train Loss 0.0049408176 Test MSE 5.5488932770637566e-05 Test RE 0.005397229104967844\n",
      "137 Train Loss 0.004847454 Test MSE 5.2925014540630885e-05 Test RE 0.005271062438040945\n",
      "138 Train Loss 0.0048303534 Test MSE 4.832146485839916e-05 Test RE 0.0050366029248108835\n",
      "139 Train Loss 0.004747024 Test MSE 4.7476428942323986e-05 Test RE 0.004992369141969155\n",
      "140 Train Loss 0.004674451 Test MSE 4.731044028150595e-05 Test RE 0.004983634257445304\n",
      "141 Train Loss 0.0046254843 Test MSE 4.711292702743999e-05 Test RE 0.004973220453206633\n",
      "142 Train Loss 0.0045928583 Test MSE 4.6761836366237993e-05 Test RE 0.004954655311047261\n",
      "143 Train Loss 0.004532821 Test MSE 4.6679172230814976e-05 Test RE 0.0049502740303177094\n",
      "144 Train Loss 0.0044460353 Test MSE 4.736436629332922e-05 Test RE 0.004986473704510976\n",
      "145 Train Loss 0.004345593 Test MSE 4.681858167964989e-05 Test RE 0.00495766062742657\n",
      "146 Train Loss 0.004291038 Test MSE 5.111163267984575e-05 Test RE 0.005179973579886878\n",
      "147 Train Loss 0.004227735 Test MSE 5.083311493483887e-05 Test RE 0.005165840932680123\n",
      "148 Train Loss 0.004200019 Test MSE 4.8824401736545443e-05 Test RE 0.005062745926030596\n",
      "149 Train Loss 0.0042405515 Test MSE 4.917249251176277e-05 Test RE 0.005080761151955266\n",
      "150 Train Loss 0.0041582114 Test MSE 4.7774340656293064e-05 Test RE 0.005008008053913041\n",
      "151 Train Loss 0.00410568 Test MSE 5.0366705022470605e-05 Test RE 0.005142087207657729\n",
      "152 Train Loss 0.0040406915 Test MSE 5.111022038318558e-05 Test RE 0.005179902013889672\n",
      "153 Train Loss 0.00396038 Test MSE 4.9679185879103914e-05 Test RE 0.005106871177201687\n",
      "154 Train Loss 0.0039106673 Test MSE 4.981808651266821e-05 Test RE 0.00511400547797477\n",
      "155 Train Loss 0.0038232266 Test MSE 4.558414569910471e-05 Test RE 0.004891866287270634\n",
      "156 Train Loss 0.0037593187 Test MSE 4.288788968096709e-05 Test RE 0.004744986773662524\n",
      "157 Train Loss 0.00369855 Test MSE 4.238182657646515e-05 Test RE 0.004716909053039562\n",
      "158 Train Loss 0.00364881 Test MSE 4.2036777936294974e-05 Test RE 0.00469766862131925\n",
      "159 Train Loss 0.0036036777 Test MSE 4.227869269766982e-05 Test RE 0.004711166385981248\n",
      "160 Train Loss 0.0035449571 Test MSE 4.127430568074993e-05 Test RE 0.004654869990971066\n",
      "161 Train Loss 0.003495517 Test MSE 4.0092158539320264e-05 Test RE 0.004587725104471926\n",
      "162 Train Loss 0.0034424877 Test MSE 3.84886986866854e-05 Test RE 0.004495047460145908\n",
      "163 Train Loss 0.0033433153 Test MSE 3.916142608341589e-05 Test RE 0.0045341607890731685\n",
      "164 Train Loss 0.0032200941 Test MSE 3.761042894436817e-05 Test RE 0.004443465483218066\n",
      "165 Train Loss 0.0031297216 Test MSE 3.318650501986572e-05 Test RE 0.004173961381650404\n",
      "166 Train Loss 0.0031261942 Test MSE 3.124959997366844e-05 Test RE 0.004050325244302235\n",
      "167 Train Loss 0.0030530747 Test MSE 3.1887027725657844e-05 Test RE 0.004091425874446675\n",
      "168 Train Loss 0.0030629195 Test MSE 3.193524555369343e-05 Test RE 0.004094518121682289\n",
      "169 Train Loss 0.0030238936 Test MSE 3.1597442126136865e-05 Test RE 0.004072805131180546\n",
      "170 Train Loss 0.0029848388 Test MSE 3.1160239444411076e-05 Test RE 0.0040445299969012645\n",
      "171 Train Loss 0.0029878488 Test MSE 3.19443234933189e-05 Test RE 0.004095100035905214\n",
      "172 Train Loss 0.0029796916 Test MSE 3.203064508684084e-05 Test RE 0.004100629298004802\n",
      "173 Train Loss 0.0029657104 Test MSE 3.059090095707473e-05 Test RE 0.004007410221770662\n",
      "174 Train Loss 0.0029521177 Test MSE 3.0112119892557395e-05 Test RE 0.00397592636985516\n",
      "175 Train Loss 0.0029162425 Test MSE 2.8822371864430263e-05 Test RE 0.003889847060219287\n",
      "176 Train Loss 0.0029113132 Test MSE 2.693284176314655e-05 Test RE 0.003760181058738335\n",
      "177 Train Loss 0.0028947936 Test MSE 2.5734471189325667e-05 Test RE 0.0036755750249305476\n",
      "178 Train Loss 0.002860365 Test MSE 2.5877611031321474e-05 Test RE 0.003685782960745087\n",
      "179 Train Loss 0.0028266006 Test MSE 2.6521917123959915e-05 Test RE 0.0037313855422257893\n",
      "180 Train Loss 0.002784217 Test MSE 2.7531137820851334e-05 Test RE 0.003801716676743032\n",
      "181 Train Loss 0.0027961845 Test MSE 2.8343070377951584e-05 Test RE 0.0038573683721421885\n",
      "182 Train Loss 0.0027859525 Test MSE 2.8329416428422692e-05 Test RE 0.0038564391387002454\n",
      "183 Train Loss 0.0027453562 Test MSE 2.7781991258462906e-05 Test RE 0.003818997313031294\n",
      "184 Train Loss 0.0027037668 Test MSE 2.7781834918941418e-05 Test RE 0.003818986567562281\n",
      "185 Train Loss 0.0026472488 Test MSE 2.510688268583957e-05 Test RE 0.003630480131170389\n",
      "186 Train Loss 0.0026142418 Test MSE 2.254740596043589e-05 Test RE 0.003440455617831601\n",
      "187 Train Loss 0.0025852534 Test MSE 2.1077312037355646e-05 Test RE 0.003326406190170854\n",
      "188 Train Loss 0.0025388186 Test MSE 1.9211016760902053e-05 Test RE 0.003175724672331183\n",
      "189 Train Loss 0.002498785 Test MSE 1.8414969147624213e-05 Test RE 0.0031092322623993518\n",
      "190 Train Loss 0.0024773893 Test MSE 1.9633513745555442e-05 Test RE 0.0032104557106893447\n",
      "191 Train Loss 0.0024840392 Test MSE 1.9225879032801104e-05 Test RE 0.0031769528571560716\n",
      "192 Train Loss 0.0024396614 Test MSE 1.8756147319195296e-05 Test RE 0.0031379027895378623\n",
      "193 Train Loss 0.0024269996 Test MSE 1.8228140261481566e-05 Test RE 0.003093419711153755\n",
      "194 Train Loss 0.0024335068 Test MSE 1.668216549576768e-05 Test RE 0.002959333294717281\n",
      "195 Train Loss 0.002391988 Test MSE 1.621165663605579e-05 Test RE 0.0029173018407477706\n",
      "196 Train Loss 0.0023536498 Test MSE 1.5795869785711117e-05 Test RE 0.0028796482389839544\n",
      "197 Train Loss 0.0022748632 Test MSE 1.4243783687194255e-05 Test RE 0.0027345152673727163\n",
      "198 Train Loss 0.0022501359 Test MSE 1.4106453734061664e-05 Test RE 0.0027213010676863463\n",
      "199 Train Loss 0.0022024878 Test MSE 1.3335598338844805e-05 Test RE 0.002645903012709493\n",
      "200 Train Loss 0.002160519 Test MSE 1.1371801043098293e-05 Test RE 0.00244333093745606\n",
      "201 Train Loss 0.0021321247 Test MSE 1.0728098183175614e-05 Test RE 0.0023731710259935457\n",
      "202 Train Loss 0.0021003115 Test MSE 1.1221872088330861e-05 Test RE 0.002427170721766732\n",
      "203 Train Loss 0.0020707895 Test MSE 1.080266218633515e-05 Test RE 0.0023814039262407224\n",
      "204 Train Loss 0.0020424435 Test MSE 1.135959110890251e-05 Test RE 0.002442018879582677\n",
      "205 Train Loss 0.0020155574 Test MSE 1.0908065837448148e-05 Test RE 0.0023929936320153155\n",
      "206 Train Loss 0.002002711 Test MSE 1.0854648049069656e-05 Test RE 0.0023871270874531356\n",
      "207 Train Loss 0.0019776165 Test MSE 1.0599567397515704e-05 Test RE 0.0023589119907479745\n",
      "208 Train Loss 0.0019858743 Test MSE 1.0375492657502909e-05 Test RE 0.002333845117773384\n",
      "209 Train Loss 0.0019660103 Test MSE 1.0712461450571939e-05 Test RE 0.0023714408883724744\n",
      "210 Train Loss 0.0019515029 Test MSE 1.0255882260756437e-05 Test RE 0.0023203536456672153\n",
      "211 Train Loss 0.0019146542 Test MSE 9.938213130078616e-06 Test RE 0.0022841352742893712\n",
      "212 Train Loss 0.001931392 Test MSE 9.879352815871433e-06 Test RE 0.0022773611904278743\n",
      "213 Train Loss 0.0019088525 Test MSE 1.0288346125605784e-05 Test RE 0.002324023155957001\n",
      "214 Train Loss 0.0018920595 Test MSE 1.0509495544278613e-05 Test RE 0.0023488679543168757\n",
      "215 Train Loss 0.0018819453 Test MSE 1.0583025536150899e-05 Test RE 0.0023570705933741247\n",
      "216 Train Loss 0.0018668117 Test MSE 1.0683131095245144e-05 Test RE 0.0023681922008766754\n",
      "217 Train Loss 0.0018542308 Test MSE 1.0987584440250239e-05 Test RE 0.0024017001239594726\n",
      "218 Train Loss 0.0018368711 Test MSE 1.1332000779171213e-05 Test RE 0.0024390514722961473\n",
      "219 Train Loss 0.0018275405 Test MSE 1.0574928075840793e-05 Test RE 0.002356168680314663\n",
      "220 Train Loss 0.0018115054 Test MSE 9.927472855895427e-06 Test RE 0.0022829007027216795\n",
      "221 Train Loss 0.0018415753 Test MSE 9.996275419907298e-06 Test RE 0.0022907978896361692\n",
      "222 Train Loss 0.0018298338 Test MSE 9.520161375249584e-06 Test RE 0.0022355779772294518\n",
      "223 Train Loss 0.001806142 Test MSE 8.769361457294654e-06 Test RE 0.0021456142916280183\n",
      "224 Train Loss 0.0017910986 Test MSE 9.0197624657084e-06 Test RE 0.0021760317008104554\n",
      "225 Train Loss 0.001787096 Test MSE 8.984731670426958e-06 Test RE 0.002171801973100732\n",
      "226 Train Loss 0.0017549865 Test MSE 8.962760634046947e-06 Test RE 0.002169144912825421\n",
      "227 Train Loss 0.0017451616 Test MSE 8.762617045123694e-06 Test RE 0.002144789049640078\n",
      "228 Train Loss 0.0017103418 Test MSE 8.452583123972092e-06 Test RE 0.0021065045078357877\n",
      "229 Train Loss 0.0016806697 Test MSE 8.155227900205556e-06 Test RE 0.0020691201909008236\n",
      "230 Train Loss 0.0016536922 Test MSE 7.935086707060388e-06 Test RE 0.0020410023557535482\n",
      "231 Train Loss 0.0016215572 Test MSE 8.021151145842077e-06 Test RE 0.002052040923809263\n",
      "232 Train Loss 0.0016005283 Test MSE 7.575109874881778e-06 Test RE 0.0019941698044514218\n",
      "233 Train Loss 0.0015861292 Test MSE 7.162621328463972e-06 Test RE 0.0019391154357691017\n",
      "234 Train Loss 0.0015712976 Test MSE 7.0051994256799474e-06 Test RE 0.0019176878618002067\n",
      "235 Train Loss 0.001564269 Test MSE 7.005269610194953e-06 Test RE 0.0019176974683543689\n",
      "236 Train Loss 0.0015419943 Test MSE 6.793347039973714e-06 Test RE 0.001888467730951714\n",
      "237 Train Loss 0.001524991 Test MSE 6.566228898194393e-06 Test RE 0.001856631338407204\n",
      "238 Train Loss 0.001511145 Test MSE 6.465067639983903e-06 Test RE 0.001842273920230821\n",
      "239 Train Loss 0.0015085875 Test MSE 6.653334910708842e-06 Test RE 0.0018689055780279865\n",
      "240 Train Loss 0.0015107277 Test MSE 6.9238914790095274e-06 Test RE 0.0019065262702220825\n",
      "241 Train Loss 0.0015055819 Test MSE 6.854633556277424e-06 Test RE 0.0018969670572357407\n",
      "242 Train Loss 0.0014930089 Test MSE 6.6920554256629035e-06 Test RE 0.0018743359378929367\n",
      "243 Train Loss 0.0014992096 Test MSE 6.559241622643079e-06 Test RE 0.0018556432333654972\n",
      "244 Train Loss 0.0014885819 Test MSE 6.571787271562718e-06 Test RE 0.0018574169999572316\n",
      "245 Train Loss 0.001461363 Test MSE 6.2809962111727985e-06 Test RE 0.0018158582076194334\n",
      "246 Train Loss 0.0014415648 Test MSE 5.866748224665626e-06 Test RE 0.0017549566488551116\n",
      "247 Train Loss 0.0014340432 Test MSE 5.547189288620501e-06 Test RE 0.0017064916221852726\n",
      "248 Train Loss 0.0014190458 Test MSE 5.186294201049123e-06 Test RE 0.0016500467241585682\n",
      "249 Train Loss 0.001406489 Test MSE 4.7431503421393516e-06 Test RE 0.0015779786136964707\n",
      "250 Train Loss 0.0014005554 Test MSE 4.393111735900374e-06 Test RE 0.001518636355008539\n",
      "251 Train Loss 0.0013882943 Test MSE 4.3868949439228156e-06 Test RE 0.0015175614462307238\n",
      "252 Train Loss 0.0013805957 Test MSE 4.434285204619986e-06 Test RE 0.0015257362999232331\n",
      "253 Train Loss 0.0013709952 Test MSE 4.4594282078102696e-06 Test RE 0.0015300557522863563\n",
      "254 Train Loss 0.001356173 Test MSE 4.382026279820865e-06 Test RE 0.00151671910236973\n",
      "255 Train Loss 0.0013453801 Test MSE 4.124331078058033e-06 Test RE 0.0014714463363737058\n",
      "256 Train Loss 0.0013314423 Test MSE 4.062277466977353e-06 Test RE 0.0014603348838205527\n",
      "257 Train Loss 0.0013210629 Test MSE 4.463487008016776e-06 Test RE 0.0015307518928998488\n",
      "258 Train Loss 0.0013171461 Test MSE 4.602469507096931e-06 Test RE 0.0015544012168236965\n",
      "259 Train Loss 0.0013207332 Test MSE 4.551165367642722e-06 Test RE 0.0015457134133129795\n",
      "260 Train Loss 0.0013096804 Test MSE 4.638061711924176e-06 Test RE 0.001560399954875833\n",
      "261 Train Loss 0.0013003176 Test MSE 4.816461214910562e-06 Test RE 0.001590126595411905\n",
      "262 Train Loss 0.0012932 Test MSE 4.454375299431908e-06 Test RE 0.0015291886654709927\n",
      "263 Train Loss 0.0012849285 Test MSE 4.67371125511426e-06 Test RE 0.0015663853282220272\n",
      "264 Train Loss 0.0012694634 Test MSE 4.459580540974874e-06 Test RE 0.0015300818852605248\n",
      "265 Train Loss 0.0012500706 Test MSE 3.989828378926968e-06 Test RE 0.0014472540553614362\n",
      "266 Train Loss 0.0012321356 Test MSE 3.7014761417210904e-06 Test RE 0.001393975512955635\n",
      "267 Train Loss 0.0012255003 Test MSE 3.455642018694378e-06 Test RE 0.0013468897277569174\n",
      "268 Train Loss 0.0012190727 Test MSE 3.5092119837122194e-06 Test RE 0.0013572894379155363\n",
      "269 Train Loss 0.0012089391 Test MSE 3.6300820651215546e-06 Test RE 0.001380466554836255\n",
      "270 Train Loss 0.0011977138 Test MSE 3.681768386975594e-06 Test RE 0.0013902595910389036\n",
      "271 Train Loss 0.0011854707 Test MSE 3.5435049149710694e-06 Test RE 0.0013639052069741935\n",
      "272 Train Loss 0.0011741917 Test MSE 3.4777124184235623e-06 Test RE 0.0013511840211993227\n",
      "273 Train Loss 0.0011618079 Test MSE 3.1544653999663053e-06 Test RE 0.0012868577776745124\n",
      "274 Train Loss 0.001143667 Test MSE 3.554929690639329e-06 Test RE 0.001366102152045963\n",
      "275 Train Loss 0.0011290024 Test MSE 3.4536424413906126e-06 Test RE 0.0013464999883352471\n",
      "276 Train Loss 0.0011207289 Test MSE 3.49018922258572e-06 Test RE 0.0013536056367481294\n",
      "277 Train Loss 0.0011069123 Test MSE 3.899363120718307e-06 Test RE 0.0014307524807843006\n",
      "278 Train Loss 0.0011067067 Test MSE 4.496272425134409e-06 Test RE 0.0015363634829375877\n",
      "279 Train Loss 0.0010918782 Test MSE 4.325097851251199e-06 Test RE 0.001506834781883557\n",
      "280 Train Loss 0.0010802775 Test MSE 4.480937164215853e-06 Test RE 0.0015337412376387896\n",
      "281 Train Loss 0.0010749082 Test MSE 4.449647112114374e-06 Test RE 0.0015283768557702194\n",
      "282 Train Loss 0.001066367 Test MSE 4.545308704610246e-06 Test RE 0.0015447185431948446\n",
      "283 Train Loss 0.0010476125 Test MSE 4.7197495965100254e-06 Test RE 0.0015740812532467937\n",
      "284 Train Loss 0.001039216 Test MSE 5.453351802042978e-06 Test RE 0.0016919963637400325\n",
      "285 Train Loss 0.0010271417 Test MSE 5.16691885222838e-06 Test RE 0.0016469616556379755\n",
      "286 Train Loss 0.0010191724 Test MSE 4.596165753914689e-06 Test RE 0.0015533363625056687\n",
      "287 Train Loss 0.0010079057 Test MSE 4.552116390422723e-06 Test RE 0.0015458749029274557\n",
      "288 Train Loss 0.0010056905 Test MSE 4.690807215379417e-06 Test RE 0.0015692475522629985\n",
      "289 Train Loss 0.0009943203 Test MSE 4.186168923518054e-06 Test RE 0.0014824363048888784\n",
      "290 Train Loss 0.0009875854 Test MSE 3.811657378972717e-06 Test RE 0.0014145704959356996\n",
      "291 Train Loss 0.0009796477 Test MSE 3.7596106947831273e-06 Test RE 0.0014048795986604274\n",
      "292 Train Loss 0.000968796 Test MSE 3.5804749929339023e-06 Test RE 0.0013710016897872854\n",
      "293 Train Loss 0.0009585913 Test MSE 3.1262412552088945e-06 Test RE 0.001281087850893961\n",
      "294 Train Loss 0.0009467469 Test MSE 3.0974813106500632e-06 Test RE 0.0012751815337758508\n",
      "295 Train Loss 0.0009357473 Test MSE 2.8139691870121263e-06 Test RE 0.0012154226809765508\n",
      "296 Train Loss 0.0009234754 Test MSE 2.830869605112659e-06 Test RE 0.0012190670708683215\n",
      "297 Train Loss 0.0009148687 Test MSE 2.4751881878729437e-06 Test RE 0.0011399131916337633\n",
      "298 Train Loss 0.00090783444 Test MSE 2.475729528395775e-06 Test RE 0.00114003783821011\n",
      "299 Train Loss 0.00090691505 Test MSE 2.548368595321986e-06 Test RE 0.0011566415512592285\n",
      "Training time: 247.38\n",
      "KG_tanhALR_medium\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 33516.48 Test MSE 8.866053143723278 Test RE 2.157410721755109\n",
      "1 Train Loss 10460.592 Test MSE 9.869403380558241 Test RE 2.276214143351811\n",
      "2 Train Loss 4545.2534 Test MSE 13.7576057342625 Test RE 2.6874419823218942\n",
      "3 Train Loss 2086.362 Test MSE 18.041184895894325 Test RE 3.077515127358478\n",
      "4 Train Loss 1460.6317 Test MSE 22.554234295829307 Test RE 3.4409765382100033\n",
      "5 Train Loss 1215.968 Test MSE 26.127275533959406 Test RE 3.703520306953792\n",
      "6 Train Loss 1013.00604 Test MSE 27.581810521732525 Test RE 3.805213711480261\n",
      "7 Train Loss 915.238 Test MSE 27.983594546687442 Test RE 3.8328287676547266\n",
      "8 Train Loss 825.82086 Test MSE 28.679480785507025 Test RE 3.8801928399857437\n",
      "9 Train Loss 779.91364 Test MSE 27.806051848492217 Test RE 3.8206506762059336\n",
      "10 Train Loss 708.81635 Test MSE 27.012591392332588 Test RE 3.7657439954428176\n",
      "11 Train Loss 667.46704 Test MSE 24.688902973761607 Test RE 3.60013315645412\n",
      "12 Train Loss 589.75244 Test MSE 22.976865791336053 Test RE 3.473066199578885\n",
      "13 Train Loss 539.7391 Test MSE 21.09018713542318 Test RE 3.3274220044141334\n",
      "14 Train Loss 465.05225 Test MSE 17.265620839246534 Test RE 3.0106395832062725\n",
      "15 Train Loss 378.67734 Test MSE 15.62752453095619 Test RE 2.8642621386739733\n",
      "16 Train Loss 317.08252 Test MSE 13.442521305981545 Test RE 2.6564890763015163\n",
      "17 Train Loss 291.17255 Test MSE 12.121435317451736 Test RE 2.522578511096631\n",
      "18 Train Loss 266.7981 Test MSE 11.075868969521597 Test RE 2.4113295721255725\n",
      "19 Train Loss 234.21909 Test MSE 10.266173590254297 Test RE 2.32151754048393\n",
      "20 Train Loss 200.91963 Test MSE 9.931132505706097 Test RE 2.2833214466224194\n",
      "21 Train Loss 173.67151 Test MSE 8.615041265504358 Test RE 2.1266516073163957\n",
      "22 Train Loss 116.28496 Test MSE 3.279074200614532 Test RE 1.3120285629449815\n",
      "23 Train Loss 50.205593 Test MSE 0.678570061135377 Test RE 0.5968497480406695\n",
      "24 Train Loss 24.421638 Test MSE 0.0727441264482082 Test RE 0.19541893141072347\n",
      "25 Train Loss 13.298017 Test MSE 0.03533132117035135 Test RE 0.13619074840929216\n",
      "26 Train Loss 7.566509 Test MSE 0.014018724215396218 Test RE 0.08578708554029656\n",
      "27 Train Loss 5.1962366 Test MSE 0.01142657047245048 Test RE 0.07745074843726861\n",
      "28 Train Loss 3.9016764 Test MSE 0.015673172662959436 Test RE 0.09070811179695851\n",
      "29 Train Loss 3.2391915 Test MSE 0.013564327639307806 Test RE 0.08438530090237187\n",
      "30 Train Loss 2.7481766 Test MSE 0.017135533536143298 Test RE 0.09484544604190193\n",
      "31 Train Loss 2.221376 Test MSE 0.013153664191507772 Test RE 0.08309809020989208\n",
      "32 Train Loss 1.7759542 Test MSE 0.00937918313578726 Test RE 0.070169789804083\n",
      "33 Train Loss 1.5214119 Test MSE 0.008361739190641319 Test RE 0.0662545908490508\n",
      "34 Train Loss 1.2378436 Test MSE 0.004382105984665558 Test RE 0.04796330553899927\n",
      "35 Train Loss 1.0813287 Test MSE 0.0028092816535276607 Test RE 0.03840301386826068\n",
      "36 Train Loss 0.9330658 Test MSE 0.0021439074565058804 Test RE 0.03354831290486262\n",
      "37 Train Loss 0.8243964 Test MSE 0.0024438893785725868 Test RE 0.03581858618657752\n",
      "38 Train Loss 0.6725656 Test MSE 0.0027898147997540267 Test RE 0.038269726154652677\n",
      "39 Train Loss 0.57192516 Test MSE 0.0027865326664024857 Test RE 0.03824720793778966\n",
      "40 Train Loss 0.49275315 Test MSE 0.00250830382826946 Test RE 0.036287557594885056\n",
      "41 Train Loss 0.45674777 Test MSE 0.0013438495767810555 Test RE 0.026560912863834926\n",
      "42 Train Loss 0.40528783 Test MSE 0.0006385275730787672 Test RE 0.01830869945316482\n",
      "43 Train Loss 0.3713619 Test MSE 0.0005410608048222017 Test RE 0.016853523259478077\n",
      "44 Train Loss 0.33559194 Test MSE 0.0003400974439480465 Test RE 0.013361934903095484\n",
      "45 Train Loss 0.28960133 Test MSE 0.0004296136435981861 Test RE 0.015017813276183484\n",
      "46 Train Loss 0.27168018 Test MSE 0.0004646081708185511 Test RE 0.01561748470416598\n",
      "47 Train Loss 0.25832385 Test MSE 0.0005048529699144531 Test RE 0.016279839740881277\n",
      "48 Train Loss 0.23728952 Test MSE 0.00030144191488884286 Test RE 0.012579676926441243\n",
      "49 Train Loss 0.21497358 Test MSE 0.0002125308509080568 Test RE 0.010562790304818532\n",
      "50 Train Loss 0.20325825 Test MSE 0.00032614472747859597 Test RE 0.013084973536970863\n",
      "51 Train Loss 0.1830556 Test MSE 0.000649345900986163 Test RE 0.018463146654238087\n",
      "52 Train Loss 0.17805576 Test MSE 0.0005677253064980325 Test RE 0.01726381583199666\n",
      "53 Train Loss 0.15829942 Test MSE 0.0008196131057758143 Test RE 0.020743026146183147\n",
      "54 Train Loss 0.14609212 Test MSE 0.0007259047760007005 Test RE 0.01952124421243135\n",
      "55 Train Loss 0.13956274 Test MSE 0.0007187932603299757 Test RE 0.019425386377566956\n",
      "56 Train Loss 0.13277067 Test MSE 0.00040185028664216875 Test RE 0.01452445377941149\n",
      "57 Train Loss 0.1145916 Test MSE 0.000319969094704602 Test RE 0.012960497837075927\n",
      "58 Train Loss 0.111125104 Test MSE 0.00031752239057674585 Test RE 0.012910850297583923\n",
      "59 Train Loss 0.10835479 Test MSE 0.0003895878704932291 Test RE 0.014301130878142184\n",
      "60 Train Loss 0.10218027 Test MSE 0.00029967457085843126 Test RE 0.012542745599083168\n",
      "61 Train Loss 0.09338497 Test MSE 0.00034419166776497145 Test RE 0.013442122348632242\n",
      "62 Train Loss 0.08978642 Test MSE 0.0002534291848777897 Test RE 0.011534425837519551\n",
      "63 Train Loss 0.08798716 Test MSE 0.00018505171530554 Test RE 0.009856307066609494\n",
      "64 Train Loss 0.081016906 Test MSE 0.00010262265592883118 Test RE 0.007339885629478131\n",
      "65 Train Loss 0.07698466 Test MSE 0.00013155090145241987 Test RE 0.008310259430924734\n",
      "66 Train Loss 0.07552455 Test MSE 0.0001221741714667457 Test RE 0.00800861412735425\n",
      "67 Train Loss 0.069002815 Test MSE 0.00012449551264517893 Test RE 0.008084339002219424\n",
      "68 Train Loss 0.06354763 Test MSE 0.00018149727701167418 Test RE 0.009761189060280532\n",
      "69 Train Loss 0.06255516 Test MSE 0.00024418019634304814 Test RE 0.011321993128132587\n",
      "70 Train Loss 0.061288167 Test MSE 0.0002401343489686434 Test RE 0.011227803691868961\n",
      "71 Train Loss 0.058747765 Test MSE 0.00020018119433453836 Test RE 0.01025130855704732\n",
      "72 Train Loss 0.05427069 Test MSE 0.00012269142369159382 Test RE 0.008025549368886884\n",
      "73 Train Loss 0.051992558 Test MSE 8.036394457042068e-05 Test RE 0.006495286175158225\n",
      "74 Train Loss 0.05067361 Test MSE 9.021921061242523e-05 Test RE 0.00688203978704424\n",
      "75 Train Loss 0.04863869 Test MSE 8.901376844203553e-05 Test RE 0.006835908821550129\n",
      "76 Train Loss 0.046366304 Test MSE 6.661823224346414e-05 Test RE 0.00591376713974271\n",
      "77 Train Loss 0.04470026 Test MSE 7.357289421892203e-05 Test RE 0.006214791856632257\n",
      "78 Train Loss 0.041698933 Test MSE 6.689263092572582e-05 Test RE 0.005925933946735701\n",
      "79 Train Loss 0.039701432 Test MSE 4.275375967569141e-05 Test RE 0.0047375610936051\n",
      "80 Train Loss 0.038144592 Test MSE 5.448589812362978e-05 Test RE 0.005348225676145004\n",
      "81 Train Loss 0.037325457 Test MSE 5.933264315801486e-05 Test RE 0.005581032037196821\n",
      "82 Train Loss 0.036873557 Test MSE 5.7568245936337595e-05 Test RE 0.005497423139899831\n",
      "83 Train Loss 0.03572806 Test MSE 5.323877986633534e-05 Test RE 0.005286664064505054\n",
      "84 Train Loss 0.033537958 Test MSE 6.095108540774033e-05 Test RE 0.005656638037725177\n",
      "85 Train Loss 0.031144653 Test MSE 5.662907001936747e-05 Test RE 0.005452395898469546\n",
      "86 Train Loss 0.030149866 Test MSE 3.787129591543409e-05 Test RE 0.004458848853931219\n",
      "87 Train Loss 0.029701995 Test MSE 3.6414697751189164e-05 Test RE 0.0043722604300652805\n",
      "88 Train Loss 0.029273598 Test MSE 3.393352598247374e-05 Test RE 0.004220677431085591\n",
      "89 Train Loss 0.027743546 Test MSE 3.3226112638500994e-05 Test RE 0.004176451420492309\n",
      "90 Train Loss 0.026592463 Test MSE 2.643878798017e-05 Test RE 0.0037255332065035934\n",
      "91 Train Loss 0.025454486 Test MSE 2.707299755869672e-05 Test RE 0.0037699521650007245\n",
      "92 Train Loss 0.024979573 Test MSE 2.4458483295791725e-05 Test RE 0.003583293888207637\n",
      "93 Train Loss 0.024731394 Test MSE 2.3585640242969344e-05 Test RE 0.0035187750390737534\n",
      "94 Train Loss 0.024489082 Test MSE 2.448060077854134e-05 Test RE 0.0035849136847203237\n",
      "95 Train Loss 0.02393481 Test MSE 2.781564255540756e-05 Test RE 0.0038213095180644223\n",
      "96 Train Loss 0.022704523 Test MSE 3.1539267445653207e-05 Test RE 0.0040690541425280275\n",
      "97 Train Loss 0.022018293 Test MSE 3.155577750314655e-05 Test RE 0.004070119029790034\n",
      "98 Train Loss 0.021696242 Test MSE 3.24192863718523e-05 Test RE 0.004125431620339478\n",
      "99 Train Loss 0.021339454 Test MSE 2.9813396392901705e-05 Test RE 0.003956155876121688\n",
      "100 Train Loss 0.02109266 Test MSE 2.644954174320909e-05 Test RE 0.0037262907947160162\n",
      "101 Train Loss 0.020917423 Test MSE 2.712437368425209e-05 Test RE 0.0037735275676452143\n",
      "102 Train Loss 0.020350242 Test MSE 2.9129606118884987e-05 Test RE 0.003910524163577004\n",
      "103 Train Loss 0.019274127 Test MSE 3.73173248870503e-05 Test RE 0.004426117301046921\n",
      "104 Train Loss 0.018815422 Test MSE 4.112483366121731e-05 Test RE 0.00464643370266639\n",
      "105 Train Loss 0.018612785 Test MSE 4.6156804175536664e-05 Test RE 0.004922497829446101\n",
      "106 Train Loss 0.018529348 Test MSE 4.857155754361748e-05 Test RE 0.005049619830835061\n",
      "107 Train Loss 0.018390844 Test MSE 5.019752172610215e-05 Test RE 0.005133443729344729\n",
      "108 Train Loss 0.017934382 Test MSE 4.867791496517365e-05 Test RE 0.00505514539857784\n",
      "109 Train Loss 0.01730672 Test MSE 4.290758557326051e-05 Test RE 0.004746076195662361\n",
      "110 Train Loss 0.017000727 Test MSE 4.756619432334048e-05 Test RE 0.004997086538566981\n",
      "111 Train Loss 0.016840907 Test MSE 4.87013684569111e-05 Test RE 0.0050563630609759104\n",
      "112 Train Loss 0.016660584 Test MSE 4.6058801357549605e-05 Test RE 0.004917269185321828\n",
      "113 Train Loss 0.016561765 Test MSE 4.4743347359808914e-05 Test RE 0.00484654113827998\n",
      "114 Train Loss 0.016341968 Test MSE 5.039711841178176e-05 Test RE 0.005143639470197321\n",
      "115 Train Loss 0.015934998 Test MSE 4.569203023880435e-05 Test RE 0.004897651685258431\n",
      "116 Train Loss 0.015102595 Test MSE 3.52160769286993e-05 Test RE 0.004299699997024512\n",
      "117 Train Loss 0.014660807 Test MSE 4.067354900732732e-05 Test RE 0.004620869483674207\n",
      "118 Train Loss 0.014530773 Test MSE 3.7661527386622516e-05 Test RE 0.004446482958726755\n",
      "119 Train Loss 0.014398116 Test MSE 3.8353287017007014e-05 Test RE 0.004487133212385738\n",
      "120 Train Loss 0.014328403 Test MSE 3.782214255689758e-05 Test RE 0.004455954332475049\n",
      "121 Train Loss 0.014297691 Test MSE 3.8891564867377764e-05 Test RE 0.004518511341304465\n",
      "122 Train Loss 0.014176443 Test MSE 4.270150442171001e-05 Test RE 0.004734664995678523\n",
      "123 Train Loss 0.013987099 Test MSE 4.0483923888855114e-05 Test RE 0.004610085367105904\n",
      "124 Train Loss 0.013637405 Test MSE 3.6575677705305545e-05 Test RE 0.004381914088628171\n",
      "125 Train Loss 0.013285376 Test MSE 3.243731154622793e-05 Test RE 0.004126578334213065\n",
      "126 Train Loss 0.012937606 Test MSE 3.409824852610817e-05 Test RE 0.004230909185995463\n",
      "127 Train Loss 0.012815535 Test MSE 3.0637211049039876e-05 Test RE 0.004010442387328508\n",
      "128 Train Loss 0.012750924 Test MSE 3.19409352015391e-05 Test RE 0.004094882849246876\n",
      "129 Train Loss 0.012586533 Test MSE 3.443294114148376e-05 Test RE 0.004251622803835037\n",
      "130 Train Loss 0.012490974 Test MSE 3.406311249148706e-05 Test RE 0.004228728785340672\n",
      "131 Train Loss 0.012180844 Test MSE 2.955407219499936e-05 Test RE 0.00393891249277393\n",
      "132 Train Loss 0.011508524 Test MSE 2.4763203579187995e-05 Test RE 0.0036055463399215035\n",
      "133 Train Loss 0.011235808 Test MSE 2.083610667902129e-05 Test RE 0.0033073179945958347\n",
      "134 Train Loss 0.011028137 Test MSE 2.1816770087394314e-05 Test RE 0.0033842535652335946\n",
      "135 Train Loss 0.010910648 Test MSE 2.0120355694996223e-05 Test RE 0.0032500159674031122\n",
      "136 Train Loss 0.010826634 Test MSE 2.0837273342857653e-05 Test RE 0.003307410585652997\n",
      "137 Train Loss 0.010772512 Test MSE 2.1175289450147955e-05 Test RE 0.0033341285885523015\n",
      "138 Train Loss 0.010662526 Test MSE 1.9475094714241386e-05 Test RE 0.0031974772037916756\n",
      "139 Train Loss 0.010393094 Test MSE 1.556127198722166e-05 Test RE 0.0028581842020993188\n",
      "140 Train Loss 0.010147879 Test MSE 1.6027446957115542e-05 Test RE 0.0029006801419209105\n",
      "141 Train Loss 0.009968086 Test MSE 1.611293588363824e-05 Test RE 0.002908405834004124\n",
      "142 Train Loss 0.009780402 Test MSE 1.4492303612067576e-05 Test RE 0.002758267482973767\n",
      "143 Train Loss 0.009648634 Test MSE 1.4378707574390258e-05 Test RE 0.002747436055505728\n",
      "144 Train Loss 0.009557952 Test MSE 1.482084826003534e-05 Test RE 0.002789357619384265\n",
      "145 Train Loss 0.009474526 Test MSE 1.5947421527982954e-05 Test RE 0.002893429496986939\n",
      "146 Train Loss 0.009377032 Test MSE 1.6232508594237756e-05 Test RE 0.0029191774019280644\n",
      "147 Train Loss 0.009329293 Test MSE 2.0342694892231172e-05 Test RE 0.003267923717751226\n",
      "148 Train Loss 0.009201385 Test MSE 2.2211131611684948e-05 Test RE 0.0034147035842259517\n",
      "149 Train Loss 0.008986353 Test MSE 2.2315535500161387e-05 Test RE 0.0034227196181777484\n",
      "150 Train Loss 0.008740625 Test MSE 1.946017262468233e-05 Test RE 0.0031962519932085954\n",
      "151 Train Loss 0.008596908 Test MSE 1.942687887185365e-05 Test RE 0.0031935166429004403\n",
      "152 Train Loss 0.00850933 Test MSE 2.2567527899551834e-05 Test RE 0.003441990455144743\n",
      "153 Train Loss 0.008382368 Test MSE 1.997255331610628e-05 Test RE 0.0032380567971808097\n",
      "154 Train Loss 0.008297373 Test MSE 1.8534191269021982e-05 Test RE 0.0031192809140938287\n",
      "155 Train Loss 0.00825128 Test MSE 1.8611192721793597e-05 Test RE 0.003125753821521311\n",
      "156 Train Loss 0.008248716 Test MSE 1.8157054967701952e-05 Test RE 0.003087382028465244\n",
      "157 Train Loss 0.008159717 Test MSE 1.7122616808745284e-05 Test RE 0.0029981457148114997\n",
      "158 Train Loss 0.007956526 Test MSE 1.6646940068247424e-05 Test RE 0.0029562072356937663\n",
      "159 Train Loss 0.007844532 Test MSE 1.5514245188366332e-05 Test RE 0.002853862159644167\n",
      "160 Train Loss 0.007794493 Test MSE 1.4492776844286213e-05 Test RE 0.0027583125168903835\n",
      "161 Train Loss 0.007775093 Test MSE 1.338421876262343e-05 Test RE 0.002650721989658422\n",
      "162 Train Loss 0.0077317636 Test MSE 1.3363023367169437e-05 Test RE 0.002648622301866428\n",
      "163 Train Loss 0.007698434 Test MSE 1.2730316220080311e-05 Test RE 0.0025851590235971902\n",
      "164 Train Loss 0.007645751 Test MSE 1.3552338070077587e-05 Test RE 0.002667317909795232\n",
      "165 Train Loss 0.0077064857 Test MSE 1.3180081504867257e-05 Test RE 0.0026304297977042556\n",
      "166 Train Loss 0.0076405886 Test MSE 1.317119624418807e-05 Test RE 0.002629543005206131\n",
      "167 Train Loss 0.007503378 Test MSE 1.3817418439126839e-05 Test RE 0.0026932776213070453\n",
      "168 Train Loss 0.007320867 Test MSE 1.363251721094036e-05 Test RE 0.002675196545642852\n",
      "169 Train Loss 0.0070942678 Test MSE 9.244264430193313e-06 Test RE 0.002202945979760228\n",
      "170 Train Loss 0.006848341 Test MSE 9.694605082000777e-06 Test RE 0.0022559669288626017\n",
      "171 Train Loss 0.006706527 Test MSE 9.719631957751259e-06 Test RE 0.0022588769707050393\n",
      "172 Train Loss 0.006618062 Test MSE 1.1392518068061539e-05 Test RE 0.0024455555417525654\n",
      "173 Train Loss 0.0065654325 Test MSE 1.1082575027999705e-05 Test RE 0.0024120594503063554\n",
      "174 Train Loss 0.0065008313 Test MSE 1.0517451172397388e-05 Test RE 0.0023497568259458123\n",
      "175 Train Loss 0.006495684 Test MSE 1.0291611341532317e-05 Test RE 0.0023243919147127364\n",
      "176 Train Loss 0.006420962 Test MSE 1.0180484300546927e-05 Test RE 0.002311808663443594\n",
      "177 Train Loss 0.0063500535 Test MSE 9.288425812438262e-06 Test RE 0.002208201629363336\n",
      "178 Train Loss 0.006325955 Test MSE 8.313050878397071e-06 Test RE 0.0020890454411774035\n",
      "179 Train Loss 0.006254927 Test MSE 8.824368131550533e-06 Test RE 0.0021523330594269666\n",
      "180 Train Loss 0.0061747837 Test MSE 7.190319250834177e-06 Test RE 0.0019428611067146167\n",
      "181 Train Loss 0.0061382484 Test MSE 7.346579917464445e-06 Test RE 0.001963858855058204\n",
      "182 Train Loss 0.0060894946 Test MSE 7.250303396572708e-06 Test RE 0.001950948287003837\n",
      "183 Train Loss 0.0060683885 Test MSE 7.325777797578925e-06 Test RE 0.001961076513641174\n",
      "184 Train Loss 0.0060134795 Test MSE 6.295924134973449e-06 Test RE 0.001818014784776015\n",
      "185 Train Loss 0.006008224 Test MSE 6.363239831327036e-06 Test RE 0.0018277080040031862\n",
      "186 Train Loss 0.005967019 Test MSE 6.124283956978639e-06 Test RE 0.0017930620840298842\n",
      "187 Train Loss 0.005909417 Test MSE 4.946645994537146e-06 Test RE 0.0016114731852773453\n",
      "188 Train Loss 0.005788395 Test MSE 4.497628512835242e-06 Test RE 0.0015365951511236867\n",
      "189 Train Loss 0.0056861644 Test MSE 3.4289840154177057e-06 Test RE 0.0013416844857808603\n",
      "190 Train Loss 0.0056195306 Test MSE 4.465320591254179e-06 Test RE 0.0015310662741015804\n",
      "191 Train Loss 0.0054709683 Test MSE 3.6485837581323136e-06 Test RE 0.001383980043858473\n",
      "192 Train Loss 0.0053838757 Test MSE 4.479932988792247e-06 Test RE 0.0015335693727479588\n",
      "193 Train Loss 0.0053247693 Test MSE 4.111586994449275e-06 Test RE 0.0014691712106388905\n",
      "194 Train Loss 0.005269267 Test MSE 3.849174341805681e-06 Test RE 0.0014215150391296775\n",
      "195 Train Loss 0.005248209 Test MSE 4.050120395482098e-06 Test RE 0.0014581480935068598\n",
      "196 Train Loss 0.0052006203 Test MSE 4.247489012739443e-06 Test RE 0.001493254388325502\n",
      "197 Train Loss 0.005135675 Test MSE 4.1695682901282575e-06 Test RE 0.0014794940170533837\n",
      "198 Train Loss 0.00508787 Test MSE 3.6525493629109766e-06 Test RE 0.001384731955799012\n",
      "199 Train Loss 0.0050640176 Test MSE 3.5553098108295725e-06 Test RE 0.0013661751871232265\n",
      "200 Train Loss 0.005021081 Test MSE 3.5314541390034823e-06 Test RE 0.0013615840427157336\n",
      "201 Train Loss 0.0049923803 Test MSE 4.19113444077001e-06 Test RE 0.0014833152566945584\n",
      "202 Train Loss 0.0049438505 Test MSE 4.860850628960169e-06 Test RE 0.0015974372431203756\n",
      "203 Train Loss 0.0048681255 Test MSE 4.8486596258289135e-06 Test RE 0.0015954328009279292\n",
      "204 Train Loss 0.0048388746 Test MSE 6.459291614553005e-06 Test RE 0.0018414507734830904\n",
      "205 Train Loss 0.0047491137 Test MSE 4.719965553616756e-06 Test RE 0.001574117264706495\n",
      "206 Train Loss 0.004668855 Test MSE 5.902653007800691e-06 Test RE 0.0017603186672388279\n",
      "207 Train Loss 0.0045648757 Test MSE 4.946709023478123e-06 Test RE 0.001611483451741213\n",
      "208 Train Loss 0.0044773733 Test MSE 3.853821111161804e-06 Test RE 0.0014223728153166955\n",
      "209 Train Loss 0.0044041397 Test MSE 3.420660246460469e-06 Test RE 0.0013400550443354536\n",
      "210 Train Loss 0.0043607997 Test MSE 3.402597670877878e-06 Test RE 0.0013365123242974658\n",
      "211 Train Loss 0.0043340917 Test MSE 4.277536517796549e-06 Test RE 0.0014985268558939363\n",
      "212 Train Loss 0.00430833 Test MSE 4.7084674711490415e-06 Test RE 0.0015721987796993057\n",
      "213 Train Loss 0.004281202 Test MSE 4.475098063679118e-06 Test RE 0.0015327416042600019\n",
      "214 Train Loss 0.0042531257 Test MSE 4.478893542269831e-06 Test RE 0.0015333914509095233\n",
      "215 Train Loss 0.0042238995 Test MSE 4.5787978938980014e-06 Test RE 0.0015503987331575112\n",
      "216 Train Loss 0.0041990047 Test MSE 5.637886985426473e-06 Test RE 0.0017203858054539128\n",
      "217 Train Loss 0.004162673 Test MSE 5.154746213069039e-06 Test RE 0.001645020489922142\n",
      "218 Train Loss 0.004128027 Test MSE 5.995825241663991e-06 Test RE 0.0017741574150869639\n",
      "219 Train Loss 0.004100471 Test MSE 5.897617353015728e-06 Test RE 0.001759567627960492\n",
      "220 Train Loss 0.0040791677 Test MSE 6.15593697451915e-06 Test RE 0.0017976897825555192\n",
      "221 Train Loss 0.004054167 Test MSE 6.930397318526997e-06 Test RE 0.001907421766757021\n",
      "222 Train Loss 0.004041172 Test MSE 7.777568995451267e-06 Test RE 0.002020643061352525\n",
      "223 Train Loss 0.0040279455 Test MSE 7.842696824933462e-06 Test RE 0.0020290856573607985\n",
      "224 Train Loss 0.004020083 Test MSE 9.954827960223087e-06 Test RE 0.0022860438000383318\n",
      "225 Train Loss 0.004038775 Test MSE 9.843880024180215e-06 Test RE 0.002273268968641894\n",
      "226 Train Loss 0.0039763707 Test MSE 9.42966631325926e-06 Test RE 0.0022249273261528723\n",
      "227 Train Loss 0.003912103 Test MSE 8.927768241385457e-06 Test RE 0.002164906386089575\n",
      "228 Train Loss 0.0038191713 Test MSE 9.554863234920472e-06 Test RE 0.0022396487142353184\n",
      "229 Train Loss 0.0037609637 Test MSE 8.776973013161845e-06 Test RE 0.002146545255692829\n",
      "230 Train Loss 0.0037116574 Test MSE 8.066692349883905e-06 Test RE 0.0020578580528390674\n",
      "231 Train Loss 0.0036753153 Test MSE 8.58652300201507e-06 Test RE 0.0021231287753773827\n",
      "232 Train Loss 0.0036478026 Test MSE 8.259972682722949e-06 Test RE 0.002082365563589025\n",
      "233 Train Loss 0.0036275166 Test MSE 9.237734142567715e-06 Test RE 0.0022021677451869496\n",
      "234 Train Loss 0.0036068764 Test MSE 9.65845679901481e-06 Test RE 0.002251757087895205\n",
      "235 Train Loss 0.003597627 Test MSE 9.933251247596104e-06 Test RE 0.002283564999449628\n",
      "236 Train Loss 0.0036218362 Test MSE 1.0080573898625557e-05 Test RE 0.0023004367476829744\n",
      "237 Train Loss 0.0036033448 Test MSE 9.320808171199125e-06 Test RE 0.002212047521200919\n",
      "238 Train Loss 0.0035780983 Test MSE 9.823747268006434e-06 Test RE 0.0022709431278897596\n",
      "239 Train Loss 0.0035639952 Test MSE 9.588866547479579e-06 Test RE 0.002243630343234817\n",
      "240 Train Loss 0.0035321235 Test MSE 7.421650776704031e-06 Test RE 0.0019738671760396545\n",
      "241 Train Loss 0.0034904904 Test MSE 6.013215601597857e-06 Test RE 0.0017767284453789238\n",
      "242 Train Loss 0.0034588627 Test MSE 5.817851698380007e-06 Test RE 0.0017476279866580988\n",
      "243 Train Loss 0.003400777 Test MSE 5.7635007781321465e-06 Test RE 0.0017394455787237782\n",
      "244 Train Loss 0.00334062 Test MSE 5.2223407355016765e-06 Test RE 0.0016557709920486682\n",
      "245 Train Loss 0.0033046377 Test MSE 5.897448697038017e-06 Test RE 0.0017595424683322421\n",
      "246 Train Loss 0.0032768792 Test MSE 6.498233414792045e-06 Test RE 0.001846993304811258\n",
      "247 Train Loss 0.0032576786 Test MSE 6.267097767624296e-06 Test RE 0.001813848050416177\n",
      "248 Train Loss 0.0032311128 Test MSE 6.04691264628637e-06 Test RE 0.0017816997336162399\n",
      "249 Train Loss 0.0031901624 Test MSE 5.925675798685974e-06 Test RE 0.0017637483120898697\n",
      "250 Train Loss 0.0031600192 Test MSE 6.015778370247234e-06 Test RE 0.001777107016447763\n",
      "251 Train Loss 0.003146701 Test MSE 6.49171240433199e-06 Test RE 0.0018460663385861174\n",
      "252 Train Loss 0.0031321764 Test MSE 6.908009136010475e-06 Test RE 0.0019043383756924734\n",
      "253 Train Loss 0.0031083494 Test MSE 7.824394886114329e-06 Test RE 0.0020267167086925005\n",
      "254 Train Loss 0.003084924 Test MSE 7.429302253285734e-06 Test RE 0.001974884409823582\n",
      "255 Train Loss 0.0030644585 Test MSE 7.969499506533637e-06 Test RE 0.002045423266432982\n",
      "256 Train Loss 0.0030470185 Test MSE 8.158865606801276e-06 Test RE 0.0020695816135055272\n",
      "257 Train Loss 0.0030238242 Test MSE 8.515255757424852e-06 Test RE 0.002114299543174329\n",
      "258 Train Loss 0.00301877 Test MSE 9.418166940830981e-06 Test RE 0.002223570275325423\n",
      "259 Train Loss 0.0030172165 Test MSE 8.85804391320985e-06 Test RE 0.0021564360431919954\n",
      "260 Train Loss 0.0030006093 Test MSE 9.764070976156393e-06 Test RE 0.002264034974531711\n",
      "261 Train Loss 0.0030388224 Test MSE 8.916449360327555e-06 Test RE 0.0021635335855771823\n",
      "262 Train Loss 0.0030253003 Test MSE 8.031411512913311e-06 Test RE 0.002053352952715265\n",
      "263 Train Loss 0.0029826425 Test MSE 6.926696143067312e-06 Test RE 0.001906912369884132\n",
      "264 Train Loss 0.0029558137 Test MSE 6.546560752906663e-06 Test RE 0.0018538486238981794\n",
      "265 Train Loss 0.002904162 Test MSE 4.984761274963002e-06 Test RE 0.0016176696958183619\n",
      "266 Train Loss 0.0028827717 Test MSE 4.99138613086512e-06 Test RE 0.0016187442979588447\n",
      "267 Train Loss 0.0028508906 Test MSE 5.209040027869041e-06 Test RE 0.0016536611176317317\n",
      "268 Train Loss 0.0028280392 Test MSE 5.026540281244543e-06 Test RE 0.0016244346747698194\n",
      "269 Train Loss 0.0027983882 Test MSE 5.46861433334892e-06 Test RE 0.0016943624410498573\n",
      "270 Train Loss 0.0027818948 Test MSE 5.570136054599623e-06 Test RE 0.001710017556601644\n",
      "271 Train Loss 0.002780861 Test MSE 5.119965629160605e-06 Test RE 0.0016394613790563272\n",
      "272 Train Loss 0.0027546308 Test MSE 4.922820122654511e-06 Test RE 0.0016075876133019203\n",
      "273 Train Loss 0.0027298804 Test MSE 5.102542413562605e-06 Test RE 0.0016366694626695365\n",
      "274 Train Loss 0.002690983 Test MSE 5.366064339145463e-06 Test RE 0.0016784005201045395\n",
      "275 Train Loss 0.0026616019 Test MSE 5.9002001829291256e-06 Test RE 0.0017599528823914992\n",
      "276 Train Loss 0.002633169 Test MSE 6.5059443746555206e-06 Test RE 0.00184808882322647\n",
      "277 Train Loss 0.002599196 Test MSE 5.9182956658431e-06 Test RE 0.0017626496397422742\n",
      "278 Train Loss 0.0025865913 Test MSE 6.466089632388973e-06 Test RE 0.0018424195270255054\n",
      "279 Train Loss 0.0025750003 Test MSE 5.901451835133583e-06 Test RE 0.0017601395482691395\n",
      "280 Train Loss 0.0025380643 Test MSE 6.7975323127510514e-06 Test RE 0.0018890493688078105\n",
      "281 Train Loss 0.0025137253 Test MSE 6.618612048216417e-06 Test RE 0.0018640224147817382\n",
      "282 Train Loss 0.0024825337 Test MSE 6.822317692801781e-06 Test RE 0.001892490191310788\n",
      "283 Train Loss 0.0024519137 Test MSE 8.240338666020397e-06 Test RE 0.0020798891918833774\n",
      "284 Train Loss 0.00241126 Test MSE 7.152743924282486e-06 Test RE 0.001937777934187228\n",
      "285 Train Loss 0.00241346 Test MSE 6.831725759618632e-06 Test RE 0.0018937946263268355\n",
      "286 Train Loss 0.002384689 Test MSE 6.465821730214058e-06 Test RE 0.0018423813591884402\n",
      "287 Train Loss 0.0023478088 Test MSE 6.549227137567814e-06 Test RE 0.001854226117554849\n",
      "288 Train Loss 0.0023181515 Test MSE 5.903220796014117e-06 Test RE 0.0017604033295216402\n",
      "289 Train Loss 0.0022893168 Test MSE 6.5926868641244344e-06 Test RE 0.0018603681335414562\n",
      "290 Train Loss 0.0022643611 Test MSE 6.153824848640873e-06 Test RE 0.001797381358925674\n",
      "291 Train Loss 0.002236045 Test MSE 5.801545329988195e-06 Test RE 0.0017451771282001557\n",
      "292 Train Loss 0.0022106622 Test MSE 5.505648430267753e-06 Test RE 0.0017000899710091137\n",
      "293 Train Loss 0.0021923764 Test MSE 5.236532620104119e-06 Test RE 0.0016580192720054593\n",
      "294 Train Loss 0.0021783821 Test MSE 5.288920469371322e-06 Test RE 0.0016662922940955157\n",
      "295 Train Loss 0.0021629764 Test MSE 5.56739106032013e-06 Test RE 0.0017095961515575676\n",
      "296 Train Loss 0.002146588 Test MSE 5.256364161063358e-06 Test RE 0.001661155889963825\n",
      "297 Train Loss 0.002130666 Test MSE 5.420362018740283e-06 Test RE 0.0016868707758734326\n",
      "298 Train Loss 0.002107133 Test MSE 4.6395752491049846e-06 Test RE 0.0015606545365148491\n",
      "299 Train Loss 0.0020828808 Test MSE 4.115551422152066e-06 Test RE 0.0014698793337726307\n",
      "Training time: 250.57\n",
      "KG_tanhALR_medium\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 20261.008 Test MSE 9.785996976115374 Test RE 2.26657558458006\n",
      "1 Train Loss 9993.971 Test MSE 9.464284696836799 Test RE 2.229007683933352\n",
      "2 Train Loss 7239.6045 Test MSE 10.386823722457615 Test RE 2.3351191649589196\n",
      "3 Train Loss 4918.38 Test MSE 10.271691943350728 Test RE 2.3221413966995472\n",
      "4 Train Loss 2374.5742 Test MSE 13.920884558400699 Test RE 2.7033425717628625\n",
      "5 Train Loss 1233.5748 Test MSE 17.14422022771132 Test RE 3.0000364824913563\n",
      "6 Train Loss 852.3802 Test MSE 18.95865226674542 Test RE 3.154796847157175\n",
      "7 Train Loss 669.3044 Test MSE 19.53225990021627 Test RE 3.2021665376967388\n",
      "8 Train Loss 522.6387 Test MSE 20.110050720659856 Test RE 3.2491835859823133\n",
      "9 Train Loss 433.25537 Test MSE 19.812244970317415 Test RE 3.2250355943584115\n",
      "10 Train Loss 372.30652 Test MSE 18.93743125592687 Test RE 3.153030721543024\n",
      "11 Train Loss 358.6289 Test MSE 17.85001490722351 Test RE 3.061166551149788\n",
      "12 Train Loss 309.92285 Test MSE 16.804631273243647 Test RE 2.970175842297753\n",
      "13 Train Loss 269.36087 Test MSE 15.067051197801817 Test RE 2.8124305036484905\n",
      "14 Train Loss 226.18764 Test MSE 13.177265361665546 Test RE 2.6301487651960467\n",
      "15 Train Loss 184.10428 Test MSE 11.421274865436901 Test RE 2.448640111008909\n",
      "16 Train Loss 154.99767 Test MSE 10.429883145160959 Test RE 2.3399543721849696\n",
      "17 Train Loss 113.91059 Test MSE 9.003488317734977 Test RE 2.1740677327904177\n",
      "18 Train Loss 92.08097 Test MSE 7.592337942263308 Test RE 1.9964361861097717\n",
      "19 Train Loss 66.940125 Test MSE 5.326700395894319 Test RE 1.672233050797806\n",
      "20 Train Loss 49.816387 Test MSE 3.7661732069828613 Test RE 1.4061051936110727\n",
      "21 Train Loss 32.98588 Test MSE 2.2750079160297876 Test RE 1.0928463943345972\n",
      "22 Train Loss 25.175508 Test MSE 1.3338999322251899 Test RE 0.8368146850059729\n",
      "23 Train Loss 18.042261 Test MSE 0.6734338766043572 Test RE 0.5945866410114096\n",
      "24 Train Loss 13.406873 Test MSE 0.325394132731306 Test RE 0.41330677706522967\n",
      "25 Train Loss 9.798938 Test MSE 0.1522388748262295 Test RE 0.28270302162041655\n",
      "26 Train Loss 7.808297 Test MSE 0.08254075599031398 Test RE 0.20816220940268862\n",
      "27 Train Loss 6.0426593 Test MSE 0.020937108606933683 Test RE 0.10483976060245612\n",
      "28 Train Loss 4.689459 Test MSE 0.016535098591943236 Test RE 0.0931689201703884\n",
      "29 Train Loss 3.7242851 Test MSE 0.006658452608000253 Test RE 0.059122708855277775\n",
      "30 Train Loss 3.0315382 Test MSE 0.007583735364085896 Test RE 0.06309707870345332\n",
      "31 Train Loss 2.5423567 Test MSE 0.007925651905217523 Test RE 0.06450377987824141\n",
      "32 Train Loss 2.130154 Test MSE 0.014964043147012399 Test RE 0.08863232534274954\n",
      "33 Train Loss 1.7235492 Test MSE 0.01378597477982021 Test RE 0.08507195387036451\n",
      "34 Train Loss 1.4798706 Test MSE 0.009842695882963461 Test RE 0.0718827528963643\n",
      "35 Train Loss 1.3150979 Test MSE 0.008420582286419455 Test RE 0.06648730502121947\n",
      "36 Train Loss 1.1100881 Test MSE 0.0029327989542899014 Test RE 0.03923817628753959\n",
      "37 Train Loss 0.969857 Test MSE 0.001703646528761336 Test RE 0.029905936993739717\n",
      "38 Train Loss 0.82083124 Test MSE 0.0019066740207357982 Test RE 0.03163777202016402\n",
      "39 Train Loss 0.7267958 Test MSE 0.000815265254944076 Test RE 0.020687934599321774\n",
      "40 Train Loss 0.66799587 Test MSE 0.0011024651029956593 Test RE 0.024057477779443788\n",
      "41 Train Loss 0.5802511 Test MSE 0.0013306629557589369 Test RE 0.026430276165460228\n",
      "42 Train Loss 0.52686006 Test MSE 0.0011403282070119505 Test RE 0.02446710587096339\n",
      "43 Train Loss 0.49335843 Test MSE 0.0008626520474361505 Test RE 0.021280679761139603\n",
      "44 Train Loss 0.4632589 Test MSE 0.0009641714933296885 Test RE 0.022498046556201596\n",
      "45 Train Loss 0.4139199 Test MSE 0.000997564960276084 Test RE 0.02288433310095792\n",
      "46 Train Loss 0.37597167 Test MSE 0.0011817631160563147 Test RE 0.02490765738576141\n",
      "47 Train Loss 0.34975523 Test MSE 0.001485280424368529 Test RE 0.027923631379828676\n",
      "48 Train Loss 0.32917464 Test MSE 0.001705695241357687 Test RE 0.02992391321717154\n",
      "49 Train Loss 0.29542267 Test MSE 0.0022776090778438255 Test RE 0.034578588406678275\n",
      "50 Train Loss 0.283217 Test MSE 0.002275837223812973 Test RE 0.03456513567409485\n",
      "51 Train Loss 0.265018 Test MSE 0.0028223360088710163 Test RE 0.038492137281454904\n",
      "52 Train Loss 0.25002807 Test MSE 0.0029238541975765238 Test RE 0.03917829424893226\n",
      "53 Train Loss 0.23936921 Test MSE 0.0030224797257053836 Test RE 0.03983358237749169\n",
      "54 Train Loss 0.21179017 Test MSE 0.0022442872084870794 Test RE 0.03432471063575096\n",
      "55 Train Loss 0.20260198 Test MSE 0.001994148067672889 Test RE 0.03235536985783062\n",
      "56 Train Loss 0.18723765 Test MSE 0.001747817334994583 Test RE 0.030291144926784874\n",
      "57 Train Loss 0.17551763 Test MSE 0.0015358539816871296 Test RE 0.028395049599358003\n",
      "58 Train Loss 0.14967501 Test MSE 0.0009171259343138398 Test RE 0.021942300322050072\n",
      "59 Train Loss 0.1375973 Test MSE 0.0009064665748204593 Test RE 0.021814414695906576\n",
      "60 Train Loss 0.12938552 Test MSE 0.0007115987401172592 Test RE 0.019327925942907238\n",
      "61 Train Loss 0.11332137 Test MSE 0.00047547424640261867 Test RE 0.015799057039623986\n",
      "62 Train Loss 0.10397595 Test MSE 0.0005342122254680308 Test RE 0.01674652025115149\n",
      "63 Train Loss 0.09911369 Test MSE 0.0004884457343769374 Test RE 0.016013115209166238\n",
      "64 Train Loss 0.09647131 Test MSE 0.000504273955741965 Test RE 0.016270501415879178\n",
      "65 Train Loss 0.084948 Test MSE 0.0003816233129729201 Test RE 0.014154193105029656\n",
      "66 Train Loss 0.08102318 Test MSE 0.00035173283698502626 Test RE 0.013588581551588458\n",
      "67 Train Loss 0.073191255 Test MSE 0.00028173083844293303 Test RE 0.012161436080204327\n",
      "68 Train Loss 0.07076949 Test MSE 0.0002974957530709001 Test RE 0.01249706569368322\n",
      "69 Train Loss 0.067712046 Test MSE 0.0002819876305006868 Test RE 0.012166977271414765\n",
      "70 Train Loss 0.06470462 Test MSE 0.0002688835532262349 Test RE 0.011880912213351033\n",
      "71 Train Loss 0.062325332 Test MSE 0.00027373353241365425 Test RE 0.011987584142571575\n",
      "72 Train Loss 0.05931219 Test MSE 0.00028337080279460864 Test RE 0.012196780776191594\n",
      "73 Train Loss 0.0558236 Test MSE 0.00030129655726352314 Test RE 0.012576643551910975\n",
      "74 Train Loss 0.05327416 Test MSE 0.00024766839438743063 Test RE 0.011402575643355846\n",
      "75 Train Loss 0.050716564 Test MSE 0.00025078772866239305 Test RE 0.011474157547273272\n",
      "76 Train Loss 0.048308004 Test MSE 0.0002880971904149366 Test RE 0.012298076185504764\n",
      "77 Train Loss 0.04545159 Test MSE 0.00023805606682010183 Test RE 0.011179111674443928\n",
      "78 Train Loss 0.043258693 Test MSE 0.00021254929050451376 Test RE 0.010563248519156111\n",
      "79 Train Loss 0.041548155 Test MSE 0.00021674372882618176 Test RE 0.010666966666768207\n",
      "80 Train Loss 0.03991663 Test MSE 0.0002456118753601374 Test RE 0.011355136212177373\n",
      "81 Train Loss 0.037426032 Test MSE 0.00026783094591121377 Test RE 0.011857634109652368\n",
      "82 Train Loss 0.035858173 Test MSE 0.0002764368875170815 Test RE 0.012046632586728537\n",
      "83 Train Loss 0.034361415 Test MSE 0.0002574266849309314 Test RE 0.011625039832563515\n",
      "84 Train Loss 0.033020545 Test MSE 0.00024706389243666743 Test RE 0.011388651601162869\n",
      "85 Train Loss 0.03229952 Test MSE 0.00023033417873275072 Test RE 0.010996307121565572\n",
      "86 Train Loss 0.03174691 Test MSE 0.00022613789902800854 Test RE 0.010895680109407599\n",
      "87 Train Loss 0.03070259 Test MSE 0.0002322514000646317 Test RE 0.011041976995219437\n",
      "88 Train Loss 0.029925557 Test MSE 0.00023960030144101464 Test RE 0.011215311688233094\n",
      "89 Train Loss 0.028862797 Test MSE 0.00021418092253353954 Test RE 0.010603715330913885\n",
      "90 Train Loss 0.028007017 Test MSE 0.00020629916434381868 Test RE 0.01040678068037234\n",
      "91 Train Loss 0.027988391 Test MSE 0.0001845855315371307 Test RE 0.00984388419373808\n",
      "92 Train Loss 0.027504202 Test MSE 0.00018593952341263272 Test RE 0.009879922192247268\n",
      "93 Train Loss 0.026836386 Test MSE 0.00018218378491505557 Test RE 0.009779632336109107\n",
      "94 Train Loss 0.02635939 Test MSE 0.00017951682943230865 Test RE 0.009707787300477767\n",
      "95 Train Loss 0.026029319 Test MSE 0.00015627818986668006 Test RE 0.009057677505717773\n",
      "96 Train Loss 0.02571546 Test MSE 0.00015616963034859236 Test RE 0.0090545309760312\n",
      "97 Train Loss 0.024700034 Test MSE 0.00014476093435205825 Test RE 0.008717528109756253\n",
      "98 Train Loss 0.023708537 Test MSE 0.0001262511923314001 Test RE 0.008141143535792619\n",
      "99 Train Loss 0.023087483 Test MSE 0.00012043472989582345 Test RE 0.007951398858901977\n",
      "100 Train Loss 0.022617012 Test MSE 0.00011964590443299913 Test RE 0.00792531597478478\n",
      "101 Train Loss 0.022020776 Test MSE 0.00011286191689691508 Test RE 0.007697352557710995\n",
      "102 Train Loss 0.021757307 Test MSE 0.00011256660910458688 Test RE 0.007687275743899488\n",
      "103 Train Loss 0.021093113 Test MSE 0.00012165956561383078 Test RE 0.007991729917725348\n",
      "104 Train Loss 0.020445602 Test MSE 9.729643387370645e-05 Test RE 0.007146874057424266\n",
      "105 Train Loss 0.019862115 Test MSE 8.674835580285838e-05 Test RE 0.006748360794835908\n",
      "106 Train Loss 0.019687088 Test MSE 8.327925272994789e-05 Test RE 0.006612049214508905\n",
      "107 Train Loss 0.019115865 Test MSE 7.438915074610429e-05 Test RE 0.006249171853010055\n",
      "108 Train Loss 0.01867301 Test MSE 7.795409111166475e-05 Test RE 0.006397158685898751\n",
      "109 Train Loss 0.017994141 Test MSE 8.246432390419332e-05 Test RE 0.006579618590213195\n",
      "110 Train Loss 0.017184893 Test MSE 7.027588709897899e-05 Test RE 0.006073944732067132\n",
      "111 Train Loss 0.016606513 Test MSE 6.867867201820418e-05 Test RE 0.006004524374774717\n",
      "112 Train Loss 0.016073544 Test MSE 6.388456549314767e-05 Test RE 0.005791161018510319\n",
      "113 Train Loss 0.015796004 Test MSE 6.085554632926915e-05 Test RE 0.0056522029901372745\n",
      "114 Train Loss 0.015461598 Test MSE 5.6969035134202706e-05 Test RE 0.005468737776585367\n",
      "115 Train Loss 0.015098786 Test MSE 5.111490831543747e-05 Test RE 0.005180139563960225\n",
      "116 Train Loss 0.014979624 Test MSE 5.0715867896351925e-05 Test RE 0.005159879964066227\n",
      "117 Train Loss 0.014700343 Test MSE 5.289990225594481e-05 Test RE 0.005269811761709304\n",
      "118 Train Loss 0.014503155 Test MSE 5.1860112421071734e-05 Test RE 0.005217763550277197\n",
      "119 Train Loss 0.014166948 Test MSE 5.5449479121195454e-05 Test RE 0.005395309999309971\n",
      "120 Train Loss 0.014024218 Test MSE 5.361336560483409e-05 Test RE 0.005305229833917267\n",
      "121 Train Loss 0.014107628 Test MSE 4.804771598888116e-05 Test RE 0.005022316078972222\n",
      "122 Train Loss 0.013526998 Test MSE 5.315310853876258e-05 Test RE 0.0052824087276665405\n",
      "123 Train Loss 0.012794363 Test MSE 4.955207841348709e-05 Test RE 0.005100333860032802\n",
      "124 Train Loss 0.012334148 Test MSE 5.1460074604674216e-05 Test RE 0.005197600235048516\n",
      "125 Train Loss 0.011852714 Test MSE 4.3982794633132116e-05 Test RE 0.004805173551412744\n",
      "126 Train Loss 0.011511648 Test MSE 3.909913162583429e-05 Test RE 0.00453055308718586\n",
      "127 Train Loss 0.011285822 Test MSE 4.159154302733835e-05 Test RE 0.004672724585123155\n",
      "128 Train Loss 0.011037234 Test MSE 4.0160027899396736e-05 Test RE 0.004591606590491847\n",
      "129 Train Loss 0.010835099 Test MSE 4.033672543292734e-05 Test RE 0.004601696661825415\n",
      "130 Train Loss 0.010581274 Test MSE 4.022109655976234e-05 Test RE 0.004595096338400792\n",
      "131 Train Loss 0.010366826 Test MSE 3.982537996526821e-05 Test RE 0.004572435960432801\n",
      "132 Train Loss 0.010035924 Test MSE 3.7469691611811905e-05 Test RE 0.004435144020048508\n",
      "133 Train Loss 0.009890469 Test MSE 3.572511790150377e-05 Test RE 0.004330664132275636\n",
      "134 Train Loss 0.009722065 Test MSE 3.791825154097033e-05 Test RE 0.004461612202461636\n",
      "135 Train Loss 0.009508873 Test MSE 3.6825513894527654e-05 Test RE 0.004396854311994056\n",
      "136 Train Loss 0.009362298 Test MSE 3.531697256343639e-05 Test RE 0.004305855007937228\n",
      "137 Train Loss 0.009154915 Test MSE 3.7459923755170205e-05 Test RE 0.004434565890461142\n",
      "138 Train Loss 0.008965129 Test MSE 3.3532051731745024e-05 Test RE 0.0041956353067973615\n",
      "139 Train Loss 0.008759696 Test MSE 3.159057081624122e-05 Test RE 0.004072362262613598\n",
      "140 Train Loss 0.008649452 Test MSE 2.939493718715814e-05 Test RE 0.0039282935681116725\n",
      "141 Train Loss 0.008489659 Test MSE 2.5340541455976624e-05 Test RE 0.0036473346524959704\n",
      "142 Train Loss 0.008294761 Test MSE 2.5035932724469905e-05 Test RE 0.003625346784619748\n",
      "143 Train Loss 0.008184117 Test MSE 2.2358453268858477e-05 Test RE 0.003426009365100866\n",
      "144 Train Loss 0.008073673 Test MSE 2.248496743822314e-05 Test RE 0.0034356886417649057\n",
      "145 Train Loss 0.0079768915 Test MSE 2.1589353139511404e-05 Test RE 0.0033665687108923067\n",
      "146 Train Loss 0.007924421 Test MSE 2.086611637831266e-05 Test RE 0.0033096988594172373\n",
      "147 Train Loss 0.007877966 Test MSE 1.8899843963648177e-05 Test RE 0.0031499000764425404\n",
      "148 Train Loss 0.0077127605 Test MSE 2.018868619753394e-05 Test RE 0.00325552996030643\n",
      "149 Train Loss 0.0076068817 Test MSE 1.9943706586649385e-05 Test RE 0.0032357175594582765\n",
      "150 Train Loss 0.007588329 Test MSE 2.0467794758163227e-05 Test RE 0.0032779565631822142\n",
      "151 Train Loss 0.0075947423 Test MSE 1.8948470785258907e-05 Test RE 0.0031539496134280164\n",
      "152 Train Loss 0.007427825 Test MSE 1.876916606830423e-05 Test RE 0.003138991618764949\n",
      "153 Train Loss 0.0073120007 Test MSE 1.7702665649281617e-05 Test RE 0.0030485056277857353\n",
      "154 Train Loss 0.0073022433 Test MSE 1.937368695943472e-05 Test RE 0.0031891416299065717\n",
      "155 Train Loss 0.00713377 Test MSE 1.735554420769703e-05 Test RE 0.0030184694570320534\n",
      "156 Train Loss 0.006967706 Test MSE 1.7122900178253457e-05 Test RE 0.0029981705235066635\n",
      "157 Train Loss 0.006838586 Test MSE 1.829531598307062e-05 Test RE 0.0030991145214225068\n",
      "158 Train Loss 0.0066844006 Test MSE 1.6218902771025405e-05 Test RE 0.0029179537420845995\n",
      "159 Train Loss 0.006559419 Test MSE 1.432232443523422e-05 Test RE 0.002742044012162653\n",
      "160 Train Loss 0.006457214 Test MSE 1.5035813996642633e-05 Test RE 0.0028095136077773753\n",
      "161 Train Loss 0.0063430686 Test MSE 1.4445816797749428e-05 Test RE 0.0027538400964809352\n",
      "162 Train Loss 0.006238959 Test MSE 1.4493056722302321e-05 Test RE 0.002758339150409835\n",
      "163 Train Loss 0.006157587 Test MSE 1.60030472620281e-05 Test RE 0.0028984713475815396\n",
      "164 Train Loss 0.0061458084 Test MSE 1.722978646343934e-05 Test RE 0.0030075137058552066\n",
      "165 Train Loss 0.00606331 Test MSE 1.6613277800844762e-05 Test RE 0.00295321680634627\n",
      "166 Train Loss 0.005986004 Test MSE 1.4499495327659553e-05 Test RE 0.0027589517846365245\n",
      "167 Train Loss 0.005905584 Test MSE 1.4142418020888066e-05 Test RE 0.0027247678267282712\n",
      "168 Train Loss 0.0058283834 Test MSE 1.3215049850146927e-05 Test RE 0.002633916909998626\n",
      "169 Train Loss 0.0058232853 Test MSE 1.245776098626407e-05 Test RE 0.0025573352491089787\n",
      "170 Train Loss 0.0058210534 Test MSE 1.3005542977795745e-05 Test RE 0.0026129548887956523\n",
      "171 Train Loss 0.0056850603 Test MSE 1.2092170145922197e-05 Test RE 0.0025195314996045892\n",
      "172 Train Loss 0.0055864225 Test MSE 1.2059518733373084e-05 Test RE 0.0025161275667040487\n",
      "173 Train Loss 0.0054439656 Test MSE 1.2146728045529205e-05 Test RE 0.002525208960477407\n",
      "174 Train Loss 0.0053503187 Test MSE 1.1434137319142711e-05 Test RE 0.0024500185323320656\n",
      "175 Train Loss 0.0052498938 Test MSE 1.0324021940144925e-05 Test RE 0.0023280490541253964\n",
      "176 Train Loss 0.00518133 Test MSE 8.495576465017585e-06 Test RE 0.002111854990269416\n",
      "177 Train Loss 0.0050954 Test MSE 7.202235022021962e-06 Test RE 0.0019444702915240612\n",
      "178 Train Loss 0.0050052735 Test MSE 7.815694190985674e-06 Test RE 0.0020255895449073536\n",
      "179 Train Loss 0.004946903 Test MSE 7.771990887955891e-06 Test RE 0.0020199183242331276\n",
      "180 Train Loss 0.0049073817 Test MSE 7.902839346184207e-06 Test RE 0.0020368509238629685\n",
      "181 Train Loss 0.0048636044 Test MSE 7.508572353355241e-06 Test RE 0.001985392388922315\n",
      "182 Train Loss 0.004830571 Test MSE 8.550392961248708e-06 Test RE 0.002118657256905126\n",
      "183 Train Loss 0.0047469866 Test MSE 8.499337250546501e-06 Test RE 0.00211232237202716\n",
      "184 Train Loss 0.0047220155 Test MSE 9.07693836608488e-06 Test RE 0.002182917692919212\n",
      "185 Train Loss 0.00465079 Test MSE 9.116341314586176e-06 Test RE 0.0021876505800498885\n",
      "186 Train Loss 0.0045987973 Test MSE 8.300540942542445e-06 Test RE 0.0020874729941806535\n",
      "187 Train Loss 0.004545113 Test MSE 8.257497113099964e-06 Test RE 0.0020820534906900432\n",
      "188 Train Loss 0.0044709863 Test MSE 1.0245979429912557e-05 Test RE 0.002319233136552899\n",
      "189 Train Loss 0.004441356 Test MSE 1.0481828476364448e-05 Test RE 0.0023457741276103005\n",
      "190 Train Loss 0.004379721 Test MSE 1.0133646147915383e-05 Test RE 0.002306484472805618\n",
      "191 Train Loss 0.0042846194 Test MSE 1.0378179565353653e-05 Test RE 0.0023341472923806518\n",
      "192 Train Loss 0.0042296406 Test MSE 8.139852414992564e-06 Test RE 0.002067168759471263\n",
      "193 Train Loss 0.0041919765 Test MSE 8.088471940257859e-06 Test RE 0.0020606342275027987\n",
      "194 Train Loss 0.0041283034 Test MSE 5.998301407667555e-06 Test RE 0.0017745237245293238\n",
      "195 Train Loss 0.004093581 Test MSE 5.629266301444819e-06 Test RE 0.0017190700132007184\n",
      "196 Train Loss 0.0040297383 Test MSE 5.130952715330014e-06 Test RE 0.0016412195207603849\n",
      "197 Train Loss 0.0039623342 Test MSE 5.404885456582228e-06 Test RE 0.001684460824052819\n",
      "198 Train Loss 0.0039211703 Test MSE 6.03109324920377e-06 Test RE 0.0017793676448780026\n",
      "199 Train Loss 0.003882963 Test MSE 5.436684978308698e-06 Test RE 0.0016894088005395705\n",
      "200 Train Loss 0.0038261197 Test MSE 4.971442717633163e-06 Test RE 0.001615507161250733\n",
      "201 Train Loss 0.0037785482 Test MSE 4.828071310702607e-06 Test RE 0.0015920419445935511\n",
      "202 Train Loss 0.0037527753 Test MSE 4.415174492702458e-06 Test RE 0.0015224449700549448\n",
      "203 Train Loss 0.003721178 Test MSE 4.298453656117648e-06 Test RE 0.001502186283194294\n",
      "204 Train Loss 0.003690395 Test MSE 4.3006604946323e-06 Test RE 0.0015025718471001848\n",
      "205 Train Loss 0.0036564004 Test MSE 3.971707510405496e-06 Test RE 0.0014439637702540415\n",
      "206 Train Loss 0.003625814 Test MSE 4.409325436207039e-06 Test RE 0.0015214361970360473\n",
      "207 Train Loss 0.003633134 Test MSE 4.762391599990983e-06 Test RE 0.0015811760206170405\n",
      "208 Train Loss 0.0035963801 Test MSE 4.867352462996515e-06 Test RE 0.0015985052455960345\n",
      "209 Train Loss 0.0035541842 Test MSE 5.380024345416518e-06 Test RE 0.0016805823111984597\n",
      "210 Train Loss 0.0035516904 Test MSE 5.242527436274083e-06 Test RE 0.001658968056094395\n",
      "211 Train Loss 0.003490341 Test MSE 4.497954494475445e-06 Test RE 0.0015366508352170293\n",
      "212 Train Loss 0.0034539788 Test MSE 4.5435585377447205e-06 Test RE 0.001544421118346149\n",
      "213 Train Loss 0.003424586 Test MSE 3.986915424352634e-06 Test RE 0.001446725642271634\n",
      "214 Train Loss 0.0034043184 Test MSE 3.833840079185755e-06 Test RE 0.0014186807120981648\n",
      "215 Train Loss 0.0033785529 Test MSE 3.7854692695891527e-06 Test RE 0.0014097026953578768\n",
      "216 Train Loss 0.0033407935 Test MSE 3.884575337038861e-06 Test RE 0.001428036940449523\n",
      "217 Train Loss 0.003310364 Test MSE 3.858469314198933e-06 Test RE 0.0014232303389378064\n",
      "218 Train Loss 0.0032999788 Test MSE 3.815392305294693e-06 Test RE 0.001415263373396615\n",
      "219 Train Loss 0.0032772701 Test MSE 3.8012069067981888e-06 Test RE 0.001412629991492456\n",
      "220 Train Loss 0.0032590635 Test MSE 3.7023504083181566e-06 Test RE 0.001394140127588711\n",
      "221 Train Loss 0.0032126263 Test MSE 3.651683954862683e-06 Test RE 0.0013845679020038203\n",
      "222 Train Loss 0.0031404614 Test MSE 4.564877948249492e-06 Test RE 0.001548040265502354\n",
      "223 Train Loss 0.0030698087 Test MSE 4.608264997807652e-06 Test RE 0.0015553795702567552\n",
      "224 Train Loss 0.0030127768 Test MSE 4.761075993525431e-06 Test RE 0.0015809576062935022\n",
      "225 Train Loss 0.0029292707 Test MSE 5.842079826563489e-06 Test RE 0.0017512631570041311\n",
      "226 Train Loss 0.002849141 Test MSE 5.275642317031663e-06 Test RE 0.0016641993162162425\n",
      "227 Train Loss 0.002800003 Test MSE 5.222150711533851e-06 Test RE 0.0016557408677182334\n",
      "228 Train Loss 0.0027622133 Test MSE 5.2031505425182e-06 Test RE 0.0016527260156466326\n",
      "229 Train Loss 0.0027354434 Test MSE 5.53599147947396e-06 Test RE 0.001704768351191205\n",
      "230 Train Loss 0.0027028704 Test MSE 5.6170969041130075e-06 Test RE 0.0017172108575458477\n",
      "231 Train Loss 0.0026582943 Test MSE 5.881911733433995e-06 Test RE 0.0017572231623013846\n",
      "232 Train Loss 0.0026236668 Test MSE 5.668293486938514e-06 Test RE 0.0017250187975575409\n",
      "233 Train Loss 0.002585843 Test MSE 5.8512615928027355e-06 Test RE 0.0017526388122857325\n",
      "234 Train Loss 0.0025552362 Test MSE 5.932362866297995e-06 Test RE 0.0017647432179074358\n",
      "235 Train Loss 0.0025356552 Test MSE 5.892177093807995e-06 Test RE 0.0017587558838293273\n",
      "236 Train Loss 0.0024918965 Test MSE 5.458943469447127e-06 Test RE 0.0016928635970709686\n",
      "237 Train Loss 0.002467508 Test MSE 5.363058882921075e-06 Test RE 0.0016779304301570825\n",
      "238 Train Loss 0.0024358034 Test MSE 5.6837055120813575e-06 Test RE 0.0017273623587976139\n",
      "239 Train Loss 0.0024158587 Test MSE 5.919206270189898e-06 Test RE 0.0017627852374530767\n",
      "240 Train Loss 0.0023896473 Test MSE 6.015545009766213e-06 Test RE 0.0017770725478765744\n",
      "241 Train Loss 0.0023688553 Test MSE 5.78818780149924e-06 Test RE 0.0017431669149415548\n",
      "242 Train Loss 0.0023502964 Test MSE 5.845576740265519e-06 Test RE 0.001751787208383709\n",
      "243 Train Loss 0.0023081824 Test MSE 6.462570919257514e-06 Test RE 0.0018419181553802338\n",
      "244 Train Loss 0.0022660175 Test MSE 6.741576225842277e-06 Test RE 0.0018812581410838105\n",
      "245 Train Loss 0.0022330787 Test MSE 7.95567419974306e-06 Test RE 0.002043648319394503\n",
      "246 Train Loss 0.0022323944 Test MSE 8.036116074121546e-06 Test RE 0.002053954261115017\n",
      "247 Train Loss 0.002210768 Test MSE 8.728017297689968e-06 Test RE 0.0021405504438156524\n",
      "248 Train Loss 0.002186704 Test MSE 8.839610381082046e-06 Test RE 0.0021541911099271674\n",
      "249 Train Loss 0.0021605594 Test MSE 8.770928109037644e-06 Test RE 0.0021458059407161046\n",
      "250 Train Loss 0.0021426287 Test MSE 8.832544659399133e-06 Test RE 0.002153329988395281\n",
      "251 Train Loss 0.0021328335 Test MSE 8.752560180728595e-06 Test RE 0.002143557908018421\n",
      "252 Train Loss 0.002121837 Test MSE 9.342422698330542e-06 Test RE 0.002214610854428531\n",
      "253 Train Loss 0.0021012109 Test MSE 9.707022767371142e-06 Test RE 0.0022574112848926906\n",
      "254 Train Loss 0.002100558 Test MSE 9.80264337478742e-06 Test RE 0.0022685025363921216\n",
      "255 Train Loss 0.002084259 Test MSE 1.003692421421568e-05 Test RE 0.0022954508076730713\n",
      "256 Train Loss 0.0020717562 Test MSE 1.1045515076824219e-05 Test RE 0.0024080231292890847\n",
      "257 Train Loss 0.0020549248 Test MSE 1.19927766638507e-05 Test RE 0.0025091552919581255\n",
      "258 Train Loss 0.0020415813 Test MSE 1.2626347711107917e-05 Test RE 0.0025745808828580206\n",
      "259 Train Loss 0.0020432645 Test MSE 1.2782728242625795e-05 Test RE 0.0025904752402941974\n",
      "260 Train Loss 0.002023013 Test MSE 1.2636326887715083e-05 Test RE 0.0025755980860700813\n",
      "261 Train Loss 0.0020095243 Test MSE 1.2635675107208069e-05 Test RE 0.0025755316606646214\n",
      "262 Train Loss 0.0019884226 Test MSE 1.3495071371933946e-05 Test RE 0.0026616764406271576\n",
      "263 Train Loss 0.001972487 Test MSE 1.3128459372024883e-05 Test RE 0.0026252734708154947\n",
      "264 Train Loss 0.0019619963 Test MSE 1.3445036825895844e-05 Test RE 0.0026567376211401785\n",
      "265 Train Loss 0.0019478905 Test MSE 1.3901506328778255e-05 Test RE 0.0027014603552899643\n",
      "266 Train Loss 0.0019343918 Test MSE 1.4142381377567798e-05 Test RE 0.0027247642967589037\n",
      "267 Train Loss 0.001924302 Test MSE 1.4231726600154913e-05 Test RE 0.0027333576652409496\n",
      "268 Train Loss 0.0019071306 Test MSE 1.4203300365170196e-05 Test RE 0.0027306265171868622\n",
      "269 Train Loss 0.0018917695 Test MSE 1.364798139699597e-05 Test RE 0.0026767134339430844\n",
      "270 Train Loss 0.0018895093 Test MSE 1.4212597255143215e-05 Test RE 0.0027315200482952795\n",
      "271 Train Loss 0.0018762785 Test MSE 1.3582473641260284e-05 Test RE 0.0026702818453602944\n",
      "272 Train Loss 0.001871215 Test MSE 1.362671763530295e-05 Test RE 0.002674627441091973\n",
      "273 Train Loss 0.0018653483 Test MSE 1.2991622098615833e-05 Test RE 0.0026115560864443154\n",
      "274 Train Loss 0.001859332 Test MSE 1.2708272119454416e-05 Test RE 0.0025829197941759567\n",
      "275 Train Loss 0.0018420425 Test MSE 1.2662154057033923e-05 Test RE 0.0025782288526358535\n",
      "276 Train Loss 0.0018284848 Test MSE 1.238647450906724e-05 Test RE 0.0025500078904202935\n",
      "277 Train Loss 0.0018094529 Test MSE 1.2023641048622637e-05 Test RE 0.002512381974725602\n",
      "278 Train Loss 0.0017942894 Test MSE 1.1572258367777885e-05 Test RE 0.002464771867230813\n",
      "279 Train Loss 0.0017781401 Test MSE 1.1158478730377276e-05 Test RE 0.0024203053601530807\n",
      "280 Train Loss 0.0017570291 Test MSE 1.0617016958659722e-05 Test RE 0.002360852874307335\n",
      "281 Train Loss 0.001734405 Test MSE 1.0852716468883212e-05 Test RE 0.0023869146838583705\n",
      "282 Train Loss 0.0017227688 Test MSE 1.0792696336720198e-05 Test RE 0.0023803052068189987\n",
      "283 Train Loss 0.0017131272 Test MSE 1.0962566871291924e-05 Test RE 0.002398964357084818\n",
      "284 Train Loss 0.0017005384 Test MSE 1.115930525539297e-05 Test RE 0.002420394996291283\n",
      "285 Train Loss 0.001693768 Test MSE 1.1523602938570901e-05 Test RE 0.002459584856609601\n",
      "286 Train Loss 0.0016877395 Test MSE 1.0944431840965975e-05 Test RE 0.002396979270054807\n",
      "287 Train Loss 0.0016966821 Test MSE 1.1062619348279526e-05 Test RE 0.002409886851729642\n",
      "288 Train Loss 0.0016832176 Test MSE 1.1023400664301434e-05 Test RE 0.0024056113496037715\n",
      "289 Train Loss 0.0016761124 Test MSE 1.1050006439096598e-05 Test RE 0.002408512658520807\n",
      "290 Train Loss 0.0016720946 Test MSE 1.1050006439096598e-05 Test RE 0.002408512658520807\n",
      "291 Train Loss 0.0016659759 Test MSE 1.130254510616176e-05 Test RE 0.0024358794530119393\n",
      "292 Train Loss 0.0016628591 Test MSE 1.1517279283882855e-05 Test RE 0.00245890990712728\n",
      "293 Train Loss 0.0016632847 Test MSE 1.1482241249740242e-05 Test RE 0.0024551667924213407\n",
      "294 Train Loss 0.0016493215 Test MSE 1.1209399709102772e-05 Test RE 0.0024258215257664537\n",
      "295 Train Loss 0.0016419953 Test MSE 1.1767980022235033e-05 Test RE 0.0024855278222936585\n",
      "296 Train Loss 0.0016288689 Test MSE 1.1920135089087836e-05 Test RE 0.0025015446342352777\n",
      "297 Train Loss 0.0016195155 Test MSE 1.2219103302107697e-05 Test RE 0.0025327209097796076\n",
      "298 Train Loss 0.0016208116 Test MSE 1.2449581606082897e-05 Test RE 0.002556495577685037\n",
      "299 Train Loss 0.0016155241 Test MSE 1.2327719984456754e-05 Test RE 0.0025439527939985513\n",
      "Training time: 250.60\n",
      "KG_tanhALR_medium\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 49160.81 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "1 Train Loss 49198.773 Test MSE 4.3572885277325994 Test RE 1.5124318934680134\n",
      "2 Train Loss 14488.244 Test MSE 9.480566309345477 Test RE 2.230924164975187\n",
      "3 Train Loss 3450.1687 Test MSE 9.261172086530124 Test RE 2.204959641229137\n",
      "4 Train Loss 617.52454 Test MSE 5.812537183469174 Test RE 1.7468295891131067\n",
      "5 Train Loss 238.14078 Test MSE 3.030537210919672 Test RE 1.2613263777907064\n",
      "6 Train Loss 122.08752 Test MSE 0.8317625574550148 Test RE 0.6607959169244904\n",
      "7 Train Loss 66.431046 Test MSE 0.3181517387736085 Test RE 0.40868134894527774\n",
      "8 Train Loss 28.546577 Test MSE 0.023990283997407907 Test RE 0.11222390129939394\n",
      "9 Train Loss 15.738912 Test MSE 0.010027734554259617 Test RE 0.07255528998787109\n",
      "10 Train Loss 10.986871 Test MSE 0.011174467296191481 Test RE 0.07659158942206351\n",
      "11 Train Loss 7.7882886 Test MSE 0.00966002075216848 Test RE 0.07121257622765245\n",
      "12 Train Loss 5.814371 Test MSE 0.011381901145991241 Test RE 0.077299213005801\n",
      "13 Train Loss 4.482937 Test MSE 0.01169941564923045 Test RE 0.07836998306813096\n",
      "14 Train Loss 3.4837835 Test MSE 0.009370626421895664 Test RE 0.0701377742323754\n",
      "15 Train Loss 2.3994179 Test MSE 0.009477553869184408 Test RE 0.07053680731409502\n",
      "16 Train Loss 1.7243682 Test MSE 0.009799611322028305 Test RE 0.07172525369608171\n",
      "17 Train Loss 1.3023747 Test MSE 0.009051062145871537 Test RE 0.06893145427281483\n",
      "18 Train Loss 1.0357137 Test MSE 0.0082866586629883 Test RE 0.06595646827174693\n",
      "19 Train Loss 0.89627606 Test MSE 0.007944016320537733 Test RE 0.06457846703466627\n",
      "20 Train Loss 0.7606108 Test MSE 0.00718578749377311 Test RE 0.061419298586249595\n",
      "21 Train Loss 0.66336435 Test MSE 0.005754243201781039 Test RE 0.054961904642935794\n",
      "22 Train Loss 0.56348574 Test MSE 0.005520847540146141 Test RE 0.053835722358344586\n",
      "23 Train Loss 0.5041118 Test MSE 0.004441690093374277 Test RE 0.04828828645702774\n",
      "24 Train Loss 0.42810154 Test MSE 0.002891277519601948 Test RE 0.03895942669201553\n",
      "25 Train Loss 0.37356344 Test MSE 0.0024380295915363364 Test RE 0.03577561876457418\n",
      "26 Train Loss 0.33311066 Test MSE 0.0020953841611609327 Test RE 0.0331664887285736\n",
      "27 Train Loss 0.30696023 Test MSE 0.0015302033926124607 Test RE 0.028342767087946117\n",
      "28 Train Loss 0.28237948 Test MSE 0.0017203230593166492 Test RE 0.03005195106548452\n",
      "29 Train Loss 0.2476011 Test MSE 0.0016438960721642673 Test RE 0.029376824350552427\n",
      "30 Train Loss 0.21419747 Test MSE 0.0014332499900318845 Test RE 0.02743017898044142\n",
      "31 Train Loss 0.20213996 Test MSE 0.001290250770054281 Test RE 0.026025838537090586\n",
      "32 Train Loss 0.18816409 Test MSE 0.001055852929398355 Test RE 0.023543410892957303\n",
      "33 Train Loss 0.16966759 Test MSE 0.0010624843574103659 Test RE 0.023617228966309776\n",
      "34 Train Loss 0.15876319 Test MSE 0.0009390269991255074 Test RE 0.022202746854945422\n",
      "35 Train Loss 0.1433919 Test MSE 0.000777450270843333 Test RE 0.020202447053631636\n",
      "36 Train Loss 0.1254196 Test MSE 0.0005210978464003096 Test RE 0.016539687768439493\n",
      "37 Train Loss 0.115757175 Test MSE 0.00047771677237261253 Test RE 0.01583627053640914\n",
      "38 Train Loss 0.10561188 Test MSE 0.0004543048147081397 Test RE 0.015443343713338076\n",
      "39 Train Loss 0.098477535 Test MSE 0.0005015511572083872 Test RE 0.016226516138168404\n",
      "40 Train Loss 0.094402 Test MSE 0.0005868830725618799 Test RE 0.017552680969083957\n",
      "41 Train Loss 0.08587193 Test MSE 0.0005924226859093618 Test RE 0.017635326640281786\n",
      "42 Train Loss 0.08274955 Test MSE 0.000597440857402051 Test RE 0.01770985997546299\n",
      "43 Train Loss 0.07818788 Test MSE 0.0006495121403815451 Test RE 0.018465509883076287\n",
      "44 Train Loss 0.07571166 Test MSE 0.0006706851452242017 Test RE 0.018764068570921635\n",
      "45 Train Loss 0.067724146 Test MSE 0.0007580180098000537 Test RE 0.019948370683397873\n",
      "46 Train Loss 0.06283486 Test MSE 0.00071080634941517 Test RE 0.01931716177635887\n",
      "47 Train Loss 0.059816092 Test MSE 0.0006188781442513457 Test RE 0.01802479111776753\n",
      "48 Train Loss 0.053896837 Test MSE 0.0005492439921696529 Test RE 0.016980494177787953\n",
      "49 Train Loss 0.05122858 Test MSE 0.000530508618570669 Test RE 0.016688368830012432\n",
      "50 Train Loss 0.044771466 Test MSE 0.0004114903306806854 Test RE 0.01469763591219222\n",
      "51 Train Loss 0.042613797 Test MSE 0.000403644904128187 Test RE 0.014556849926222797\n",
      "52 Train Loss 0.041673906 Test MSE 0.00038069494405357023 Test RE 0.014136966282397636\n",
      "53 Train Loss 0.03959656 Test MSE 0.0003832317017685481 Test RE 0.014183988859695676\n",
      "54 Train Loss 0.0383466 Test MSE 0.00036590164471726386 Test RE 0.013859572941747063\n",
      "55 Train Loss 0.037814822 Test MSE 0.0003695901649762754 Test RE 0.013929254409166284\n",
      "56 Train Loss 0.03721862 Test MSE 0.0003490219042857164 Test RE 0.013536114193574268\n",
      "57 Train Loss 0.035084575 Test MSE 0.000338649569344316 Test RE 0.013333462121189405\n",
      "58 Train Loss 0.033968654 Test MSE 0.00033899816274439096 Test RE 0.013340322843633085\n",
      "59 Train Loss 0.032977246 Test MSE 0.00032995024083764434 Test RE 0.013161091015518099\n",
      "60 Train Loss 0.03172013 Test MSE 0.0003164287677495341 Test RE 0.012888597096197543\n",
      "61 Train Loss 0.031088829 Test MSE 0.00033269657595643456 Test RE 0.013215750568391632\n",
      "62 Train Loss 0.030543443 Test MSE 0.00031538711464157323 Test RE 0.01286736559698516\n",
      "63 Train Loss 0.029606294 Test MSE 0.00032727384764835905 Test RE 0.013107604199017677\n",
      "64 Train Loss 0.028487852 Test MSE 0.0003010276557667419 Test RE 0.012571030090527827\n",
      "65 Train Loss 0.02693642 Test MSE 0.00029198744135136725 Test RE 0.012380829814394836\n",
      "66 Train Loss 0.026316652 Test MSE 0.0003008107370497983 Test RE 0.012566499969975508\n",
      "67 Train Loss 0.026008697 Test MSE 0.00029553063468160085 Test RE 0.012455722409144316\n",
      "68 Train Loss 0.025098965 Test MSE 0.00028603716701943257 Test RE 0.01225402894020376\n",
      "69 Train Loss 0.024412308 Test MSE 0.00028652354059400945 Test RE 0.012264442804391703\n",
      "70 Train Loss 0.023724625 Test MSE 0.00028371330461633357 Test RE 0.012204149492508755\n",
      "71 Train Loss 0.023059988 Test MSE 0.0002856740688959446 Test RE 0.01224624878371504\n",
      "72 Train Loss 0.0225416 Test MSE 0.000273377008669961 Test RE 0.011979774995359285\n",
      "73 Train Loss 0.022128174 Test MSE 0.0002596588428080805 Test RE 0.011675331657875496\n",
      "74 Train Loss 0.021859836 Test MSE 0.000263978832390755 Test RE 0.011772053291090899\n",
      "75 Train Loss 0.021604534 Test MSE 0.0002678417681576645 Test RE 0.011857873672974542\n",
      "76 Train Loss 0.021077767 Test MSE 0.00026258626316836995 Test RE 0.011740961638373019\n",
      "77 Train Loss 0.02057195 Test MSE 0.0002623256619172242 Test RE 0.011735134089023125\n",
      "78 Train Loss 0.020247944 Test MSE 0.0002595399872569141 Test RE 0.011672659234324263\n",
      "79 Train Loss 0.019953204 Test MSE 0.00025741029569459963 Test RE 0.011624669768834863\n",
      "80 Train Loss 0.019475674 Test MSE 0.0002445896845896413 Test RE 0.011331482597557556\n",
      "81 Train Loss 0.018801464 Test MSE 0.00023688073347820544 Test RE 0.01115148070340368\n",
      "82 Train Loss 0.018387599 Test MSE 0.0002485302281127751 Test RE 0.011422397692173021\n",
      "83 Train Loss 0.018052662 Test MSE 0.00024256437863007214 Test RE 0.01128447034244903\n",
      "84 Train Loss 0.01774411 Test MSE 0.0002495777507202172 Test RE 0.011446444341233803\n",
      "85 Train Loss 0.017143216 Test MSE 0.00025273378424567333 Test RE 0.011518589940499369\n",
      "86 Train Loss 0.016609877 Test MSE 0.00024768214728705245 Test RE 0.011402892228565855\n",
      "87 Train Loss 0.016312823 Test MSE 0.00024598943114522196 Test RE 0.011363860446400437\n",
      "88 Train Loss 0.015881948 Test MSE 0.000252092465078969 Test RE 0.0115039662828059\n",
      "89 Train Loss 0.015613093 Test MSE 0.00024734071819312197 Test RE 0.011395030091854715\n",
      "90 Train Loss 0.0152401915 Test MSE 0.0002392173058296706 Test RE 0.011206344393462056\n",
      "91 Train Loss 0.014935194 Test MSE 0.0002238308043356409 Test RE 0.010839957895536777\n",
      "92 Train Loss 0.014224214 Test MSE 0.0002248422243935643 Test RE 0.0108644214481639\n",
      "93 Train Loss 0.0139179025 Test MSE 0.0002327051237013811 Test RE 0.011052757471618288\n",
      "94 Train Loss 0.013661449 Test MSE 0.00023693552482130425 Test RE 0.011152770317101933\n",
      "95 Train Loss 0.013416899 Test MSE 0.00022774347890992542 Test RE 0.010934291379221934\n",
      "96 Train Loss 0.013221541 Test MSE 0.00023210537891767824 Test RE 0.01103850529245276\n",
      "97 Train Loss 0.013060004 Test MSE 0.00023186273752615617 Test RE 0.01103273399439418\n",
      "98 Train Loss 0.01277278 Test MSE 0.0002215438805492915 Test RE 0.01078443871737066\n",
      "99 Train Loss 0.012468083 Test MSE 0.00022524426791691892 Test RE 0.010874130521774574\n",
      "100 Train Loss 0.012155876 Test MSE 0.0002237954861705305 Test RE 0.010839102645680969\n",
      "101 Train Loss 0.0118890945 Test MSE 0.00021965476660042532 Test RE 0.010738360599238748\n",
      "102 Train Loss 0.011745268 Test MSE 0.00021859482881640363 Test RE 0.0107124204422942\n",
      "103 Train Loss 0.011487343 Test MSE 0.00020702549602065646 Test RE 0.010425084518388477\n",
      "104 Train Loss 0.011367958 Test MSE 0.00021356047337558388 Test RE 0.01058834552645226\n",
      "105 Train Loss 0.011120241 Test MSE 0.00021656235200090312 Test RE 0.010662502534196344\n",
      "106 Train Loss 0.010980224 Test MSE 0.0002138507940005257 Test RE 0.010595540142159462\n",
      "107 Train Loss 0.0108290585 Test MSE 0.0002078659198670854 Test RE 0.010446223498716321\n",
      "108 Train Loss 0.010631306 Test MSE 0.00021285076767164004 Test RE 0.010570737252218063\n",
      "109 Train Loss 0.010465868 Test MSE 0.00021605245296482352 Test RE 0.010649942632297075\n",
      "110 Train Loss 0.0102888085 Test MSE 0.00021089654088356786 Test RE 0.010522099296810312\n",
      "111 Train Loss 0.010199323 Test MSE 0.00020879859833739493 Test RE 0.010469632971568143\n",
      "112 Train Loss 0.010092733 Test MSE 0.00020962181635555084 Test RE 0.010490251673225082\n",
      "113 Train Loss 0.009801202 Test MSE 0.0002113051513867251 Test RE 0.010532287609410003\n",
      "114 Train Loss 0.009640504 Test MSE 0.00020947895770544574 Test RE 0.010486676476146846\n",
      "115 Train Loss 0.009561086 Test MSE 0.00020560498267152346 Test RE 0.010389256896626172\n",
      "116 Train Loss 0.009399102 Test MSE 0.00020407912155912707 Test RE 0.010350634086334834\n",
      "117 Train Loss 0.00921913 Test MSE 0.00020219760406744699 Test RE 0.01030280951098705\n",
      "118 Train Loss 0.009101535 Test MSE 0.0002012377180275012 Test RE 0.010278325323694684\n",
      "119 Train Loss 0.009019722 Test MSE 0.00019925969669576515 Test RE 0.010227686325371431\n",
      "120 Train Loss 0.0089270845 Test MSE 0.000193633933458736 Test RE 0.010082271810818584\n",
      "121 Train Loss 0.008804773 Test MSE 0.00019585624666259088 Test RE 0.010139963259878253\n",
      "122 Train Loss 0.008706036 Test MSE 0.0002087179829271418 Test RE 0.010467611657138031\n",
      "123 Train Loss 0.008554385 Test MSE 0.00020377287119501393 Test RE 0.010342864855594719\n",
      "124 Train Loss 0.00847929 Test MSE 0.00020462656407211653 Test RE 0.010364507583447632\n",
      "125 Train Loss 0.008369381 Test MSE 0.00020146488751985692 Test RE 0.010284125089737016\n",
      "126 Train Loss 0.0082233455 Test MSE 0.0001960206798548817 Test RE 0.01014421892377498\n",
      "127 Train Loss 0.008047128 Test MSE 0.00019338599350360671 Test RE 0.010075814784641642\n",
      "128 Train Loss 0.007866385 Test MSE 0.00019473761821663828 Test RE 0.010110964711036433\n",
      "129 Train Loss 0.0077366554 Test MSE 0.0001937412113710274 Test RE 0.010085064336085983\n",
      "130 Train Loss 0.0075652665 Test MSE 0.00019671289360413113 Test RE 0.010162114432349642\n",
      "131 Train Loss 0.0075437217 Test MSE 0.00019691690843697936 Test RE 0.010167382731679159\n",
      "132 Train Loss 0.0074018924 Test MSE 0.00019830880759827004 Test RE 0.010203253321579548\n",
      "133 Train Loss 0.007339211 Test MSE 0.0001953041766645132 Test RE 0.010125662158986725\n",
      "134 Train Loss 0.007209664 Test MSE 0.0001940574310214153 Test RE 0.010093291277752043\n",
      "135 Train Loss 0.0071575404 Test MSE 0.00018554447203160586 Test RE 0.009869421056765776\n",
      "136 Train Loss 0.0070509627 Test MSE 0.00018082633917572473 Test RE 0.009743130346346423\n",
      "137 Train Loss 0.006944011 Test MSE 0.00018112313982029005 Test RE 0.009751123047373722\n",
      "138 Train Loss 0.0069395136 Test MSE 0.0001770327337835096 Test RE 0.009640386715684613\n",
      "139 Train Loss 0.0067696227 Test MSE 0.00017295705273018977 Test RE 0.009528769152443588\n",
      "140 Train Loss 0.006645731 Test MSE 0.00017484115179002875 Test RE 0.009580529159631987\n",
      "141 Train Loss 0.006546539 Test MSE 0.00017452170829181503 Test RE 0.009571773106238125\n",
      "142 Train Loss 0.006462501 Test MSE 0.00017052901784128468 Test RE 0.009461648566284574\n",
      "143 Train Loss 0.006351591 Test MSE 0.0001698833162489462 Test RE 0.00944371849241345\n",
      "144 Train Loss 0.00624571 Test MSE 0.00017005999388185512 Test RE 0.009448627921677782\n",
      "145 Train Loss 0.0060909707 Test MSE 0.0001670639521681587 Test RE 0.009365027202715157\n",
      "146 Train Loss 0.005929142 Test MSE 0.00017119174636000704 Test RE 0.00948001618473433\n",
      "147 Train Loss 0.005808821 Test MSE 0.00017165757829226252 Test RE 0.00949290551573162\n",
      "148 Train Loss 0.0057536364 Test MSE 0.00017183518730598958 Test RE 0.009497815260201128\n",
      "149 Train Loss 0.005661831 Test MSE 0.00016578999084125101 Test RE 0.009329251937949288\n",
      "150 Train Loss 0.0055557205 Test MSE 0.00015880217795875425 Test RE 0.00913052804704425\n",
      "151 Train Loss 0.0054707117 Test MSE 0.00015455068469537702 Test RE 0.009007476429835359\n",
      "152 Train Loss 0.005456871 Test MSE 0.00015611910804911653 Test RE 0.009053066245890255\n",
      "153 Train Loss 0.0053635575 Test MSE 0.00015509164745741849 Test RE 0.00902322677375882\n",
      "154 Train Loss 0.0052769403 Test MSE 0.00015723083430995368 Test RE 0.009085242568535365\n",
      "155 Train Loss 0.005165492 Test MSE 0.00015393151429706669 Test RE 0.008989415170871073\n",
      "156 Train Loss 0.0051733404 Test MSE 0.00014691599666245774 Test RE 0.008782177498676231\n",
      "157 Train Loss 0.0050775413 Test MSE 0.00014510147805951517 Test RE 0.008727775886453402\n",
      "158 Train Loss 0.005006083 Test MSE 0.00014399053886353288 Test RE 0.008694300491342179\n",
      "159 Train Loss 0.0050787856 Test MSE 0.0001450372669812288 Test RE 0.008725844541845728\n",
      "160 Train Loss 0.0050459495 Test MSE 0.0001422098456068181 Test RE 0.008640373178653547\n",
      "161 Train Loss 0.0050861235 Test MSE 0.00014221845810367996 Test RE 0.00864063481335233\n",
      "162 Train Loss 0.005003755 Test MSE 0.0001369671628541876 Test RE 0.008479610375404454\n",
      "163 Train Loss 0.004948061 Test MSE 0.00013402914506408683 Test RE 0.008388171308616712\n",
      "164 Train Loss 0.004875522 Test MSE 0.00013266219352046148 Test RE 0.008345286570710769\n",
      "165 Train Loss 0.004867809 Test MSE 0.0001288394630890781 Test RE 0.008224170792707318\n",
      "166 Train Loss 0.0048502353 Test MSE 0.0001279265387456001 Test RE 0.008194981781410638\n",
      "167 Train Loss 0.0048030457 Test MSE 0.00012536918411583592 Test RE 0.008112656119411515\n",
      "168 Train Loss 0.004720366 Test MSE 0.00012469838410652205 Test RE 0.008090923231756171\n",
      "169 Train Loss 0.004718447 Test MSE 0.00011792195742515501 Test RE 0.007868011887977614\n",
      "170 Train Loss 0.0045602648 Test MSE 0.00011320752765606213 Test RE 0.007709129135823028\n",
      "171 Train Loss 0.0044526453 Test MSE 0.00011366123529680898 Test RE 0.007724561825684109\n",
      "172 Train Loss 0.0044246414 Test MSE 0.00010996263285517034 Test RE 0.007597841553847991\n",
      "173 Train Loss 0.0043945713 Test MSE 0.00011110706586503034 Test RE 0.007637276376408411\n",
      "174 Train Loss 0.0043005818 Test MSE 0.00011078421999387525 Test RE 0.00762617241617144\n",
      "175 Train Loss 0.0042348504 Test MSE 0.00011179131249406772 Test RE 0.007660757149594442\n",
      "176 Train Loss 0.004144158 Test MSE 0.0001140759308391227 Test RE 0.00773864061340657\n",
      "177 Train Loss 0.0040666787 Test MSE 0.00011481713459596647 Test RE 0.007763740660322759\n",
      "178 Train Loss 0.004018508 Test MSE 0.00011079759753759528 Test RE 0.0076266328444495515\n",
      "179 Train Loss 0.004010971 Test MSE 0.00010712428815082975 Test RE 0.007499143120622967\n",
      "180 Train Loss 0.003918125 Test MSE 0.00010589978578400568 Test RE 0.007456159821166723\n",
      "181 Train Loss 0.0038486836 Test MSE 0.00010445059703021073 Test RE 0.0074049670607439985\n",
      "182 Train Loss 0.003825859 Test MSE 0.0001026763472021283 Test RE 0.007341805460286417\n",
      "183 Train Loss 0.0037835033 Test MSE 0.0001058551063351582 Test RE 0.00745458676672581\n",
      "184 Train Loss 0.0037552686 Test MSE 0.00010614541586786079 Test RE 0.007464801936830633\n",
      "185 Train Loss 0.0037136737 Test MSE 0.00010772527752390692 Test RE 0.007520149569779501\n",
      "186 Train Loss 0.0038053277 Test MSE 0.00011050281906419098 Test RE 0.007616480708711932\n",
      "187 Train Loss 0.003766942 Test MSE 0.00011228729125301055 Test RE 0.007677732385503251\n",
      "188 Train Loss 0.0037185194 Test MSE 0.00010975350968759736 Test RE 0.007590613458303288\n",
      "189 Train Loss 0.0036585294 Test MSE 0.0001102822340160861 Test RE 0.007608874925176859\n",
      "190 Train Loss 0.0035835488 Test MSE 0.00011058265451160017 Test RE 0.007619231567748864\n",
      "191 Train Loss 0.0035311137 Test MSE 0.0001131193896796839 Test RE 0.007706127571539287\n",
      "192 Train Loss 0.0035082544 Test MSE 0.0001110992784593149 Test RE 0.0076370087264106\n",
      "193 Train Loss 0.0034214116 Test MSE 0.0001094908279095904 Test RE 0.007581524408102791\n",
      "194 Train Loss 0.0034232615 Test MSE 0.00010991920302313475 Test RE 0.007596341018797316\n",
      "195 Train Loss 0.0033864547 Test MSE 0.00010724942639193146 Test RE 0.007503521939363366\n",
      "196 Train Loss 0.0033664885 Test MSE 0.00010669854900974118 Test RE 0.00748422653515707\n",
      "197 Train Loss 0.0033881292 Test MSE 0.00010727256619025427 Test RE 0.007504331363831981\n",
      "198 Train Loss 0.0033096129 Test MSE 0.00010456588095592068 Test RE 0.007409052428722229\n",
      "199 Train Loss 0.003218134 Test MSE 0.000104713240134049 Test RE 0.007414271184047843\n",
      "200 Train Loss 0.0031597961 Test MSE 0.00010197392044485618 Test RE 0.007316649077322814\n",
      "201 Train Loss 0.0031171562 Test MSE 0.00010272044060175784 Test RE 0.007343381726014875\n",
      "202 Train Loss 0.0031059703 Test MSE 0.00010245493371899656 Test RE 0.007333885174524408\n",
      "203 Train Loss 0.0030703489 Test MSE 0.00010185042181246013 Test RE 0.007312217209358183\n",
      "204 Train Loss 0.0030629023 Test MSE 0.00010139149346508243 Test RE 0.007295724530921704\n",
      "205 Train Loss 0.003031158 Test MSE 0.00010303447901509514 Test RE 0.007354598305976143\n",
      "206 Train Loss 0.002972964 Test MSE 0.00010432872633765999 Test RE 0.007400645822365838\n",
      "207 Train Loss 0.0029340559 Test MSE 0.00010396506360634067 Test RE 0.007387736202020122\n",
      "208 Train Loss 0.0029298181 Test MSE 0.00010345336774213403 Test RE 0.007369533274733701\n",
      "209 Train Loss 0.0028837589 Test MSE 0.00010364322477034224 Test RE 0.007376292437698428\n",
      "210 Train Loss 0.002838849 Test MSE 0.00010382352334230164 Test RE 0.007382705578099091\n",
      "211 Train Loss 0.002797441 Test MSE 0.00010142554515487378 Test RE 0.007296949539475114\n",
      "212 Train Loss 0.0027836193 Test MSE 0.00010267536679813164 Test RE 0.007341770408627517\n",
      "213 Train Loss 0.0027597514 Test MSE 0.0001033883103035939 Test RE 0.00736721571674789\n",
      "214 Train Loss 0.002726867 Test MSE 0.00010488251627320453 Test RE 0.00742026160315012\n",
      "215 Train Loss 0.0026689447 Test MSE 0.0001061660029314976 Test RE 0.007465525806535409\n",
      "216 Train Loss 0.002637931 Test MSE 0.00010500796047217485 Test RE 0.007424697760119329\n",
      "217 Train Loss 0.00263421 Test MSE 0.00010432394641889628 Test RE 0.007400476286648016\n",
      "218 Train Loss 0.0026209438 Test MSE 0.00010325787800254497 Test RE 0.007362567095659654\n",
      "219 Train Loss 0.00266717 Test MSE 0.00010139748516058841 Test RE 0.007295940096905584\n",
      "220 Train Loss 0.0026862589 Test MSE 0.00010107373355125033 Test RE 0.007284283196228636\n",
      "221 Train Loss 0.0026325067 Test MSE 0.00010078350906424817 Test RE 0.00727381758335475\n",
      "222 Train Loss 0.002592258 Test MSE 0.00010094727363171202 Test RE 0.007279724849817634\n",
      "223 Train Loss 0.002584647 Test MSE 0.00010206155894992549 Test RE 0.0073197924421858065\n",
      "224 Train Loss 0.002539246 Test MSE 0.00010198586512174804 Test RE 0.007317077581246577\n",
      "225 Train Loss 0.0025020794 Test MSE 0.00010196917457134188 Test RE 0.0073164788166574365\n",
      "226 Train Loss 0.0025216881 Test MSE 0.00010275004005242805 Test RE 0.0073444396673932625\n",
      "227 Train Loss 0.002481781 Test MSE 0.00010111720517723844 Test RE 0.007285849506199646\n",
      "228 Train Loss 0.0024299568 Test MSE 0.00010079367666255304 Test RE 0.007274184485593056\n",
      "229 Train Loss 0.0024762193 Test MSE 0.00010199874629051632 Test RE 0.0073175396528051455\n",
      "230 Train Loss 0.002526381 Test MSE 9.879479354302548e-05 Test RE 0.007201694537174686\n",
      "231 Train Loss 0.0024815663 Test MSE 9.903493182658649e-05 Test RE 0.0072104417235050065\n",
      "232 Train Loss 0.0024247468 Test MSE 9.672103125757259e-05 Test RE 0.007125709725387393\n",
      "233 Train Loss 0.0023616941 Test MSE 9.589462068814674e-05 Test RE 0.007095202427366493\n",
      "234 Train Loss 0.0023629873 Test MSE 9.920804330485677e-05 Test RE 0.007216740840473405\n",
      "235 Train Loss 0.0023225877 Test MSE 0.00010005585374559113 Test RE 0.007247511591997879\n",
      "236 Train Loss 0.0022985789 Test MSE 0.00010147232249411043 Test RE 0.0072986320176766815\n",
      "237 Train Loss 0.0022507957 Test MSE 0.00010339003489063953 Test RE 0.007367277161565814\n",
      "238 Train Loss 0.0022342545 Test MSE 0.00010224027819184271 Test RE 0.007326198456267413\n",
      "239 Train Loss 0.0022318736 Test MSE 0.00010094579152252529 Test RE 0.007279671409113932\n",
      "240 Train Loss 0.002254648 Test MSE 0.00010190907417261972 Test RE 0.007314322340898709\n",
      "241 Train Loss 0.002301856 Test MSE 0.0001005464695843339 Test RE 0.007265258658627564\n",
      "242 Train Loss 0.0022656245 Test MSE 9.943429991522804e-05 Test RE 0.007224965503282286\n",
      "243 Train Loss 0.002213766 Test MSE 0.00010078368163518009 Test RE 0.007273823810806804\n",
      "244 Train Loss 0.002224125 Test MSE 0.00010118665968269657 Test RE 0.007288351297106533\n",
      "245 Train Loss 0.002208883 Test MSE 0.00010269140262335859 Test RE 0.0073423437046104935\n",
      "246 Train Loss 0.0021601296 Test MSE 0.00010313623275858366 Test RE 0.007358228999525973\n",
      "247 Train Loss 0.002202708 Test MSE 0.00010358194261153109 Test RE 0.0073741113884055656\n",
      "248 Train Loss 0.0021688608 Test MSE 0.00010385137996712233 Test RE 0.007383695929128595\n",
      "249 Train Loss 0.0021178643 Test MSE 0.00010553516284405578 Test RE 0.007443312622724376\n",
      "250 Train Loss 0.0020748428 Test MSE 0.00010580388897087544 Test RE 0.007452783119769896\n",
      "251 Train Loss 0.0020752843 Test MSE 0.00010580108837633759 Test RE 0.007452684482744251\n",
      "252 Train Loss 0.0020484405 Test MSE 0.00010600925474866911 Test RE 0.00746001255451764\n",
      "253 Train Loss 0.002051477 Test MSE 0.00010360336014526354 Test RE 0.007374873717785767\n",
      "254 Train Loss 0.0020905288 Test MSE 0.00010261717852584719 Test RE 0.007339689746573146\n",
      "255 Train Loss 0.0020825106 Test MSE 0.00010270002064134202 Test RE 0.0073426517884469305\n",
      "256 Train Loss 0.00206107 Test MSE 0.00010408778229075253 Test RE 0.007392095098441268\n",
      "257 Train Loss 0.0020235036 Test MSE 0.00010528281299988 Test RE 0.0074344082779198625\n",
      "258 Train Loss 0.0020866175 Test MSE 0.0001057715434618725 Test RE 0.007451643830407765\n",
      "259 Train Loss 0.0020612846 Test MSE 0.00010497383453420515 Test RE 0.0074234912070012754\n",
      "260 Train Loss 0.0020235502 Test MSE 0.00010319322672263773 Test RE 0.0073602618288546445\n",
      "261 Train Loss 0.0020340006 Test MSE 0.00010249159434085732 Test RE 0.0073351971696342\n",
      "262 Train Loss 0.0020035785 Test MSE 0.0001011856456905645 Test RE 0.007288314778708706\n",
      "263 Train Loss 0.0019854386 Test MSE 9.970235163360838e-05 Test RE 0.00723469736128936\n",
      "264 Train Loss 0.0019462304 Test MSE 9.937316015678993e-05 Test RE 0.007222743933011521\n",
      "265 Train Loss 0.0019169672 Test MSE 9.785426494459861e-05 Test RE 0.007167332414695157\n",
      "266 Train Loss 0.001902564 Test MSE 9.67287423355331e-05 Test RE 0.007125993768099643\n",
      "267 Train Loss 0.001901022 Test MSE 9.6354051523227e-05 Test RE 0.007112178664975573\n",
      "268 Train Loss 0.0018752086 Test MSE 9.604690790464481e-05 Test RE 0.007100834025783014\n",
      "269 Train Loss 0.0019114375 Test MSE 9.668755903849215e-05 Test RE 0.007124476622549984\n",
      "270 Train Loss 0.0018981361 Test MSE 9.480765813138277e-05 Test RE 0.007054875876711927\n",
      "271 Train Loss 0.0019035023 Test MSE 9.476295676819299e-05 Test RE 0.0070532125102877544\n",
      "272 Train Loss 0.0018801696 Test MSE 9.441759502496055e-05 Test RE 0.007040348131046115\n",
      "273 Train Loss 0.0019187344 Test MSE 9.3181427993404e-05 Test RE 0.006994108229824376\n",
      "274 Train Loss 0.0019084158 Test MSE 9.192490580827205e-05 Test RE 0.006946791503190292\n",
      "275 Train Loss 0.0019247247 Test MSE 9.024618815646341e-05 Test RE 0.0068830686513686335\n",
      "276 Train Loss 0.0019033769 Test MSE 8.919842445583473e-05 Test RE 0.006842995577502014\n",
      "277 Train Loss 0.0018836346 Test MSE 9.032220231532025e-05 Test RE 0.006885966837741709\n",
      "278 Train Loss 0.001857487 Test MSE 8.998723153040522e-05 Test RE 0.006873186257739598\n",
      "279 Train Loss 0.0018431699 Test MSE 8.998689342109969e-05 Test RE 0.006873173345405397\n",
      "280 Train Loss 0.0018409259 Test MSE 8.998689342109969e-05 Test RE 0.006873173345405397\n",
      "281 Train Loss 0.0018093542 Test MSE 9.00523912715073e-05 Test RE 0.006875674244012113\n",
      "282 Train Loss 0.0017923232 Test MSE 9.001463717507472e-05 Test RE 0.006874232793774312\n",
      "283 Train Loss 0.0017702461 Test MSE 8.996144310152379e-05 Test RE 0.0068722013325856176\n",
      "284 Train Loss 0.0017374684 Test MSE 9.008231365495678e-05 Test RE 0.006876816465061044\n",
      "285 Train Loss 0.0017289314 Test MSE 9.046812524792008e-05 Test RE 0.0068915270152728955\n",
      "286 Train Loss 0.0017230572 Test MSE 9.046812524792008e-05 Test RE 0.0068915270152728955\n",
      "287 Train Loss 0.0016896907 Test MSE 9.081121064842047e-05 Test RE 0.006904582137769816\n",
      "288 Train Loss 0.0016697084 Test MSE 9.121743078669632e-05 Test RE 0.006920007825161705\n",
      "289 Train Loss 0.0016660881 Test MSE 9.121743140419582e-05 Test RE 0.006920007848584321\n",
      "290 Train Loss 0.0016638403 Test MSE 9.121743140419582e-05 Test RE 0.006920007848584321\n",
      "291 Train Loss 0.0016447819 Test MSE 9.173651399581405e-05 Test RE 0.006939669440655936\n",
      "292 Train Loss 0.0016456035 Test MSE 9.190493930684519e-05 Test RE 0.00694603702509867\n",
      "293 Train Loss 0.0016564224 Test MSE 9.224882923757822e-05 Test RE 0.006959020233055637\n",
      "294 Train Loss 0.0016730587 Test MSE 9.22490192038721e-05 Test RE 0.006959027398342247\n",
      "295 Train Loss 0.0016930425 Test MSE 9.224895716249591e-05 Test RE 0.006959025058221381\n",
      "296 Train Loss 0.001687501 Test MSE 9.228617077708033e-05 Test RE 0.006960428566576321\n",
      "297 Train Loss 0.0016859114 Test MSE 9.228617110730807e-05 Test RE 0.006960428579029575\n",
      "298 Train Loss 0.0016847552 Test MSE 9.228617110730807e-05 Test RE 0.006960428579029575\n",
      "299 Train Loss 0.0017541553 Test MSE 9.240952972836881e-05 Test RE 0.006965079016474404\n",
      "Training time: 241.16\n",
      "KG_tanhALR_medium\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 33013.33 Test MSE 7.727017786897715 Test RE 2.0140656547225038\n",
      "1 Train Loss 12395.405 Test MSE 10.559599914127283 Test RE 2.3544604497214117\n",
      "2 Train Loss 8916.394 Test MSE 10.21023322149737 Test RE 2.3151839274558292\n",
      "3 Train Loss 6330.178 Test MSE 11.279600231196948 Test RE 2.4334057029266893\n",
      "4 Train Loss 2975.4329 Test MSE 13.058365542239798 Test RE 2.6182558253108943\n",
      "5 Train Loss 1439.8098 Test MSE 15.991944987809092 Test RE 2.897465751385993\n",
      "6 Train Loss 786.5268 Test MSE 17.21468590537357 Test RE 3.0061954918857476\n",
      "7 Train Loss 511.35403 Test MSE 16.772585087143614 Test RE 2.9673424498948315\n",
      "8 Train Loss 422.1391 Test MSE 16.217707186279874 Test RE 2.917846190873339\n",
      "9 Train Loss 358.15164 Test MSE 15.146753376103312 Test RE 2.819859335539988\n",
      "10 Train Loss 317.44827 Test MSE 14.410899538378755 Test RE 2.7505099031783122\n",
      "11 Train Loss 273.9273 Test MSE 13.163755972784903 Test RE 2.628800199579735\n",
      "12 Train Loss 227.52869 Test MSE 10.383500116850636 Test RE 2.334745536008225\n",
      "13 Train Loss 176.97647 Test MSE 7.30358384646268 Test RE 1.9581036517634167\n",
      "14 Train Loss 105.98138 Test MSE 4.7018335581708515 Test RE 1.5710908283037799\n",
      "15 Train Loss 67.59691 Test MSE 2.4737222016304496 Test RE 1.1395755719379503\n",
      "16 Train Loss 35.54264 Test MSE 0.36960472989664267 Test RE 0.44049037964123405\n",
      "17 Train Loss 21.541348 Test MSE 0.17598664109086265 Test RE 0.30395375910322736\n",
      "18 Train Loss 14.519328 Test MSE 0.10937638535704666 Test RE 0.23962352415057717\n",
      "19 Train Loss 10.625478 Test MSE 0.06182521157930937 Test RE 0.18015672289332682\n",
      "20 Train Loss 7.304095 Test MSE 0.039275340655962374 Test RE 0.14359114147914392\n",
      "21 Train Loss 5.2791963 Test MSE 0.0246672868548303 Test RE 0.11379635718268816\n",
      "22 Train Loss 3.795241 Test MSE 0.00931892711197788 Test RE 0.06994402572386234\n",
      "23 Train Loss 3.128126 Test MSE 0.004686499142102559 Test RE 0.04960117202881216\n",
      "24 Train Loss 2.3759909 Test MSE 0.0034436491373535673 Test RE 0.04251841981430602\n",
      "25 Train Loss 2.012022 Test MSE 0.00336464688333489 Test RE 0.042027873240213745\n",
      "26 Train Loss 1.7201816 Test MSE 0.003897275380689658 Test RE 0.04523225241179066\n",
      "27 Train Loss 1.4562569 Test MSE 0.0036458739829662613 Test RE 0.04374903665621947\n",
      "28 Train Loss 1.2436153 Test MSE 0.003463868117238647 Test RE 0.04264305807674068\n",
      "29 Train Loss 1.0726323 Test MSE 0.004493791028332614 Test RE 0.04857067109148512\n",
      "30 Train Loss 0.9934589 Test MSE 0.004662949487105934 Test RE 0.049476392148861584\n",
      "31 Train Loss 0.91313475 Test MSE 0.0044799778442097425 Test RE 0.048495964459170704\n",
      "32 Train Loss 0.83663917 Test MSE 0.004874941416241373 Test RE 0.05058856590945404\n",
      "33 Train Loss 0.7356644 Test MSE 0.004660255938584276 Test RE 0.049462100088197195\n",
      "34 Train Loss 0.6382653 Test MSE 0.0038494748142209397 Test RE 0.04495400700476217\n",
      "35 Train Loss 0.60076094 Test MSE 0.0046370346507412395 Test RE 0.049338715445507206\n",
      "36 Train Loss 0.50088465 Test MSE 0.005604974036248366 Test RE 0.05424434509589851\n",
      "37 Train Loss 0.47780836 Test MSE 0.004958897855024423 Test RE 0.051022325492355594\n",
      "38 Train Loss 0.44570667 Test MSE 0.004677227444394301 Test RE 0.04955208264004575\n",
      "39 Train Loss 0.4076529 Test MSE 0.004060828741327017 Test RE 0.04617160852635533\n",
      "40 Train Loss 0.3944319 Test MSE 0.003760840020716141 Test RE 0.04443345639526127\n",
      "41 Train Loss 0.3608222 Test MSE 0.0028915946743275148 Test RE 0.038961563433882636\n",
      "42 Train Loss 0.34391835 Test MSE 0.0018529704022116698 Test RE 0.031189032922511004\n",
      "43 Train Loss 0.3270142 Test MSE 0.0016495820078665732 Test RE 0.02942758502539842\n",
      "44 Train Loss 0.29816404 Test MSE 0.0014679528407563736 Test RE 0.027760272154214703\n",
      "45 Train Loss 0.28776518 Test MSE 0.0012074153423130755 Test RE 0.025176538125875687\n",
      "46 Train Loss 0.27227405 Test MSE 0.0014015088887313835 Test RE 0.027124740742691104\n",
      "47 Train Loss 0.25825474 Test MSE 0.001522472649778238 Test RE 0.02827108116429419\n",
      "48 Train Loss 0.23372324 Test MSE 0.0017579761197470082 Test RE 0.03037904752683665\n",
      "49 Train Loss 0.22532733 Test MSE 0.0015969521513427049 Test RE 0.02895433664597497\n",
      "50 Train Loss 0.21597813 Test MSE 0.0015888254063154972 Test RE 0.028880569678022962\n",
      "51 Train Loss 0.19907203 Test MSE 0.001721459202924611 Test RE 0.030061872950944313\n",
      "52 Train Loss 0.18830405 Test MSE 0.0012238076525040269 Test RE 0.025346864893234972\n",
      "53 Train Loss 0.17146738 Test MSE 0.0013143466075074117 Test RE 0.02626773473460543\n",
      "54 Train Loss 0.162613 Test MSE 0.0017536266016200648 Test RE 0.030341442906373157\n",
      "55 Train Loss 0.15860859 Test MSE 0.001667845180978615 Test RE 0.029590038816600724\n",
      "56 Train Loss 0.14121245 Test MSE 0.0017211514462979422 Test RE 0.030059185651085365\n",
      "57 Train Loss 0.13321823 Test MSE 0.0016560090215911518 Test RE 0.02948485639139477\n",
      "58 Train Loss 0.13166353 Test MSE 0.0015206753711549767 Test RE 0.028254389234132232\n",
      "59 Train Loss 0.12842892 Test MSE 0.0015644653460520261 Test RE 0.028658314309781184\n",
      "60 Train Loss 0.12635045 Test MSE 0.0015408624975982621 Test RE 0.028441310931293408\n",
      "61 Train Loss 0.122478075 Test MSE 0.0013581133701646476 Test RE 0.0267015012764936\n",
      "62 Train Loss 0.11685565 Test MSE 0.001290915363655154 Test RE 0.026032540481938204\n",
      "63 Train Loss 0.11434625 Test MSE 0.0012982456366324193 Test RE 0.026106346831282264\n",
      "64 Train Loss 0.11190269 Test MSE 0.0012326506928738029 Test RE 0.025438276276090004\n",
      "65 Train Loss 0.10953125 Test MSE 0.001159684631003475 Test RE 0.024673889670632502\n",
      "66 Train Loss 0.10393994 Test MSE 0.0010832193976734901 Test RE 0.023846567875154545\n",
      "67 Train Loss 0.10061182 Test MSE 0.0009531690214059352 Test RE 0.02236931201137144\n",
      "68 Train Loss 0.097494796 Test MSE 0.0007986634469869156 Test RE 0.020476209849875655\n",
      "69 Train Loss 0.095709346 Test MSE 0.0007906575890752187 Test RE 0.020373323891009754\n",
      "70 Train Loss 0.09254779 Test MSE 0.0007975651385411314 Test RE 0.020462125737655913\n",
      "71 Train Loss 0.08958872 Test MSE 0.0008109480986581757 Test RE 0.020633086439445687\n",
      "72 Train Loss 0.08677091 Test MSE 0.0008569706199956024 Test RE 0.021210486705852308\n",
      "73 Train Loss 0.08473626 Test MSE 0.0008319586002370828 Test RE 0.02089866408660307\n",
      "74 Train Loss 0.08282046 Test MSE 0.0008121780464041433 Test RE 0.02064872739295871\n",
      "75 Train Loss 0.079296984 Test MSE 0.0006651734115096224 Test RE 0.018686807347076978\n",
      "76 Train Loss 0.076001726 Test MSE 0.0006046717861895834 Test RE 0.017816710371464987\n",
      "77 Train Loss 0.073645666 Test MSE 0.0006022351029451787 Test RE 0.01778077558364415\n",
      "78 Train Loss 0.07197641 Test MSE 0.000593305437776405 Test RE 0.017648460693881086\n",
      "79 Train Loss 0.06891844 Test MSE 0.0005774460200108104 Test RE 0.01741098590071605\n",
      "80 Train Loss 0.066553645 Test MSE 0.000640745854302668 Test RE 0.018340474613218576\n",
      "81 Train Loss 0.06441272 Test MSE 0.0006795494539020878 Test RE 0.01888766196654767\n",
      "82 Train Loss 0.06254155 Test MSE 0.0006905082117358276 Test RE 0.01903934885742629\n",
      "83 Train Loss 0.06003693 Test MSE 0.0006579657049239314 Test RE 0.018585288044573132\n",
      "84 Train Loss 0.057158947 Test MSE 0.0006891052954038355 Test RE 0.019019997752036884\n",
      "85 Train Loss 0.05519023 Test MSE 0.0006717066555074381 Test RE 0.01877835276685647\n",
      "86 Train Loss 0.054350905 Test MSE 0.00069380371777134 Test RE 0.01908472819041449\n",
      "87 Train Loss 0.05276064 Test MSE 0.0007276499535874731 Test RE 0.0195446960393613\n",
      "88 Train Loss 0.050900605 Test MSE 0.0007151974998897418 Test RE 0.01937673775090638\n",
      "89 Train Loss 0.049119722 Test MSE 0.0006895066901481543 Test RE 0.019025536394502964\n",
      "90 Train Loss 0.048279516 Test MSE 0.0006679561733684569 Test RE 0.01872585480497716\n",
      "91 Train Loss 0.047542326 Test MSE 0.0006827162841881839 Test RE 0.018931620868523128\n",
      "92 Train Loss 0.046605185 Test MSE 0.000712255193792998 Test RE 0.01933683894577117\n",
      "93 Train Loss 0.045004167 Test MSE 0.0007001490476486307 Test RE 0.019171801283211207\n",
      "94 Train Loss 0.044081487 Test MSE 0.0007039492437488777 Test RE 0.01922376022768828\n",
      "95 Train Loss 0.042634036 Test MSE 0.0007076304178118803 Test RE 0.019273958260286325\n",
      "96 Train Loss 0.04223977 Test MSE 0.0006855370993749295 Test RE 0.018970690945625614\n",
      "97 Train Loss 0.041561496 Test MSE 0.0006674694349916485 Test RE 0.0187190308144316\n",
      "98 Train Loss 0.041025527 Test MSE 0.0006620545708721269 Test RE 0.018642946866172794\n",
      "99 Train Loss 0.039389707 Test MSE 0.0006780434114649899 Test RE 0.01886672059256706\n",
      "100 Train Loss 0.03812201 Test MSE 0.0006708745957854823 Test RE 0.01876671855679433\n",
      "101 Train Loss 0.037006676 Test MSE 0.0006409164554220633 Test RE 0.01834291606269117\n",
      "102 Train Loss 0.035719577 Test MSE 0.0005802270122315352 Test RE 0.017452861380774027\n",
      "103 Train Loss 0.035062306 Test MSE 0.0005575033800998312 Test RE 0.01710769189236725\n",
      "104 Train Loss 0.034719333 Test MSE 0.0005511484410524142 Test RE 0.017009907789500896\n",
      "105 Train Loss 0.033983894 Test MSE 0.0005643680473007788 Test RE 0.017212695119392277\n",
      "106 Train Loss 0.03311799 Test MSE 0.0005743857587465863 Test RE 0.017364788554337172\n",
      "107 Train Loss 0.031733524 Test MSE 0.0005361634573078718 Test RE 0.016777076047532046\n",
      "108 Train Loss 0.030451227 Test MSE 0.0005088092213390081 Test RE 0.016343503276878085\n",
      "109 Train Loss 0.02945693 Test MSE 0.000502156245535961 Test RE 0.016236301297489476\n",
      "110 Train Loss 0.027945336 Test MSE 0.0005280955861888349 Test RE 0.0166503718312651\n",
      "111 Train Loss 0.026625482 Test MSE 0.0005250320462806082 Test RE 0.016602006277199873\n",
      "112 Train Loss 0.02608607 Test MSE 0.0005439492208061456 Test RE 0.016898449069740876\n",
      "113 Train Loss 0.025422335 Test MSE 0.0005555983735621742 Test RE 0.01707843812080228\n",
      "114 Train Loss 0.025024198 Test MSE 0.0005648569328934216 Test RE 0.017220148781142922\n",
      "115 Train Loss 0.02442648 Test MSE 0.0005649358737944716 Test RE 0.01722135202969202\n",
      "116 Train Loss 0.023531104 Test MSE 0.0005417773927974355 Test RE 0.016864680079470975\n",
      "117 Train Loss 0.023172524 Test MSE 0.0004986365340844578 Test RE 0.01617929953020817\n",
      "118 Train Loss 0.022641266 Test MSE 0.0004702705989560475 Test RE 0.015712365805258803\n",
      "119 Train Loss 0.022178924 Test MSE 0.0004480424453504036 Test RE 0.015336534894704677\n",
      "120 Train Loss 0.021973345 Test MSE 0.00043349863025728943 Test RE 0.015085563331668054\n",
      "121 Train Loss 0.021639515 Test MSE 0.00042417305822795395 Test RE 0.014922418232653155\n",
      "122 Train Loss 0.02126458 Test MSE 0.000421752249636316 Test RE 0.014879775251603436\n",
      "123 Train Loss 0.020906717 Test MSE 0.00041842059331565775 Test RE 0.014820886899868616\n",
      "124 Train Loss 0.02050908 Test MSE 0.00042264534648569943 Test RE 0.014895521525219066\n",
      "125 Train Loss 0.019775916 Test MSE 0.00044436117337412164 Test RE 0.015273399799889023\n",
      "126 Train Loss 0.018884033 Test MSE 0.0004342481001710932 Test RE 0.015098598313219603\n",
      "127 Train Loss 0.018113945 Test MSE 0.00044239576182042195 Test RE 0.015239585208458258\n",
      "128 Train Loss 0.017671807 Test MSE 0.0004488927111202987 Test RE 0.015351080335623015\n",
      "129 Train Loss 0.017346894 Test MSE 0.00045724057967119156 Test RE 0.01549316160747496\n",
      "130 Train Loss 0.017397555 Test MSE 0.0004462808750743069 Test RE 0.015306355843893973\n",
      "131 Train Loss 0.016791124 Test MSE 0.0004115213408126792 Test RE 0.01469818971262094\n",
      "132 Train Loss 0.016392047 Test MSE 0.0004190046986887198 Test RE 0.014831228098041677\n",
      "133 Train Loss 0.016149549 Test MSE 0.0004167205690150759 Test RE 0.014790747952557035\n",
      "134 Train Loss 0.015874187 Test MSE 0.000398104749699776 Test RE 0.01445660607527823\n",
      "135 Train Loss 0.01556004 Test MSE 0.000368442041873099 Test RE 0.013907602130882742\n",
      "136 Train Loss 0.0150923785 Test MSE 0.0003827518113530743 Test RE 0.014175105340272358\n",
      "137 Train Loss 0.014947076 Test MSE 0.0003705914943289891 Test RE 0.0139481108861995\n",
      "138 Train Loss 0.014808268 Test MSE 0.0003629990750975185 Test RE 0.01380449192016968\n",
      "139 Train Loss 0.014672261 Test MSE 0.0003643263410832781 Test RE 0.013829706192156942\n",
      "140 Train Loss 0.014325125 Test MSE 0.00036848660967361813 Test RE 0.013908443257062747\n",
      "141 Train Loss 0.014072738 Test MSE 0.0003563417499793552 Test RE 0.013677320438270846\n",
      "142 Train Loss 0.01404891 Test MSE 0.00035419000802373515 Test RE 0.01363596319250439\n",
      "143 Train Loss 0.013708381 Test MSE 0.00032968133000584737 Test RE 0.013155726750099005\n",
      "144 Train Loss 0.013285801 Test MSE 0.0003419466342847152 Test RE 0.013398211660677457\n",
      "145 Train Loss 0.013714207 Test MSE 0.0003188121098539745 Test RE 0.012937044510236764\n",
      "146 Train Loss 0.013372281 Test MSE 0.00032197601410026725 Test RE 0.01300107990594075\n",
      "147 Train Loss 0.013457653 Test MSE 0.0003226640145561128 Test RE 0.013014962889935044\n",
      "148 Train Loss 0.013161544 Test MSE 0.0003280759287898306 Test RE 0.013123656395932685\n",
      "149 Train Loss 0.012873841 Test MSE 0.0003254160633586019 Test RE 0.013070348308747436\n",
      "150 Train Loss 0.012543015 Test MSE 0.0003098923964363671 Test RE 0.012754784574755667\n",
      "151 Train Loss 0.012493862 Test MSE 0.00030514100910518464 Test RE 0.012656626282803249\n",
      "152 Train Loss 0.012632098 Test MSE 0.0002963563688731696 Test RE 0.012473111370466267\n",
      "153 Train Loss 0.012366609 Test MSE 0.00031184651510937075 Test RE 0.012794935921474605\n",
      "154 Train Loss 0.011985378 Test MSE 0.00031382273864048456 Test RE 0.012835413718728213\n",
      "155 Train Loss 0.011932448 Test MSE 0.00030418003386319396 Test RE 0.012636680921153639\n",
      "156 Train Loss 0.011861281 Test MSE 0.00029848004361811504 Test RE 0.012517722435469437\n",
      "157 Train Loss 0.011473365 Test MSE 0.00030804799535008966 Test RE 0.012716771304712856\n",
      "158 Train Loss 0.011042492 Test MSE 0.00029213898541586235 Test RE 0.01238404227771161\n",
      "159 Train Loss 0.010923542 Test MSE 0.0002753162139354428 Test RE 0.012022189298076797\n",
      "160 Train Loss 0.010703089 Test MSE 0.0002651828712848912 Test RE 0.011798869616315856\n",
      "161 Train Loss 0.010471867 Test MSE 0.0002589132461382153 Test RE 0.011658557057888725\n",
      "162 Train Loss 0.010270889 Test MSE 0.00025532344341991164 Test RE 0.011577452666846993\n",
      "163 Train Loss 0.01010627 Test MSE 0.0002486824533928675 Test RE 0.01142589527782184\n",
      "164 Train Loss 0.010004391 Test MSE 0.0002452224515766341 Test RE 0.011346130714636764\n",
      "165 Train Loss 0.00988709 Test MSE 0.00024103350135205135 Test RE 0.011248804589515075\n",
      "166 Train Loss 0.009772689 Test MSE 0.0002470336958472713 Test RE 0.011387955609244752\n",
      "167 Train Loss 0.0097863935 Test MSE 0.00025048757564899205 Test RE 0.011467289120974148\n",
      "168 Train Loss 0.009523689 Test MSE 0.0002491698428532864 Test RE 0.011437086527836936\n",
      "169 Train Loss 0.009441944 Test MSE 0.00024184517309167776 Test RE 0.011267728645989624\n",
      "170 Train Loss 0.009316338 Test MSE 0.00023669548696043975 Test RE 0.011147119485487985\n",
      "171 Train Loss 0.0093822135 Test MSE 0.00023750325675143955 Test RE 0.011166124151214183\n",
      "172 Train Loss 0.009215378 Test MSE 0.00023810078398208028 Test RE 0.011180161583990053\n",
      "173 Train Loss 0.009101265 Test MSE 0.00023595699911477114 Test RE 0.011129716442980069\n",
      "174 Train Loss 0.008988749 Test MSE 0.00023280970872335884 Test RE 0.011055240921517145\n",
      "175 Train Loss 0.008890704 Test MSE 0.0002250547065049267 Test RE 0.01086955382504259\n",
      "176 Train Loss 0.008701021 Test MSE 0.00021654731698043903 Test RE 0.01066213240124192\n",
      "177 Train Loss 0.008666743 Test MSE 0.00021102780179909776 Test RE 0.010525373237540691\n",
      "178 Train Loss 0.008523391 Test MSE 0.00020475638268199525 Test RE 0.010367794773058858\n",
      "179 Train Loss 0.008403716 Test MSE 0.00019482129850702262 Test RE 0.010113136858353513\n",
      "180 Train Loss 0.00831003 Test MSE 0.00019876802836693553 Test RE 0.010215060251548643\n",
      "181 Train Loss 0.008198585 Test MSE 0.00019478043937277907 Test RE 0.01011207630776841\n",
      "182 Train Loss 0.008126406 Test MSE 0.00019098582000037429 Test RE 0.010013092530580234\n",
      "183 Train Loss 0.008118146 Test MSE 0.00018687779676731373 Test RE 0.009904818466345909\n",
      "184 Train Loss 0.008001524 Test MSE 0.00018833995413814844 Test RE 0.0099434912936829\n",
      "185 Train Loss 0.007827426 Test MSE 0.00020204031634346538 Test RE 0.010298801499287514\n",
      "186 Train Loss 0.0076507847 Test MSE 0.0002067659288013263 Test RE 0.01041854701702176\n",
      "187 Train Loss 0.007600166 Test MSE 0.00020581720713028882 Test RE 0.010394617383825166\n",
      "188 Train Loss 0.007485266 Test MSE 0.00020687041700635786 Test RE 0.01042117916678217\n",
      "189 Train Loss 0.007475 Test MSE 0.0002064392197826825 Test RE 0.010410312635887426\n",
      "190 Train Loss 0.0073712883 Test MSE 0.00020502760991645866 Test RE 0.010374659266502852\n",
      "191 Train Loss 0.0072202515 Test MSE 0.00020013570048575444 Test RE 0.010250143617495483\n",
      "192 Train Loss 0.007178675 Test MSE 0.0001928875569092247 Test RE 0.010062821612433845\n",
      "193 Train Loss 0.007100856 Test MSE 0.00018807627669528528 Test RE 0.009936528372104068\n",
      "194 Train Loss 0.00696977 Test MSE 0.00018168347912345345 Test RE 0.009766194887690377\n",
      "195 Train Loss 0.0069437693 Test MSE 0.00017663809685458583 Test RE 0.009629635666740775\n",
      "196 Train Loss 0.006823309 Test MSE 0.00017344870844286013 Test RE 0.009542303001103196\n",
      "197 Train Loss 0.006771569 Test MSE 0.00017312436714388735 Test RE 0.009533376987202085\n",
      "198 Train Loss 0.00682714 Test MSE 0.0001675295636325829 Test RE 0.009378068406455251\n",
      "199 Train Loss 0.0067121913 Test MSE 0.00016616734886111965 Test RE 0.009339863154719375\n",
      "200 Train Loss 0.0066255527 Test MSE 0.000165591439422783 Test RE 0.009323663871017058\n",
      "201 Train Loss 0.0065005855 Test MSE 0.0001662583327510545 Test RE 0.009342419796551855\n",
      "202 Train Loss 0.0064245244 Test MSE 0.00016593479463484885 Test RE 0.00933332521226691\n",
      "203 Train Loss 0.0063917898 Test MSE 0.00015739324653087073 Test RE 0.009089933676298385\n",
      "204 Train Loss 0.0062949043 Test MSE 0.0001558522975805198 Test RE 0.009045327008285696\n",
      "205 Train Loss 0.0062058466 Test MSE 0.00015704627732024287 Test RE 0.009079908890332505\n",
      "206 Train Loss 0.00610279 Test MSE 0.00015435629363492762 Test RE 0.009001809926866852\n",
      "207 Train Loss 0.006028402 Test MSE 0.0001524860931147623 Test RE 0.008947110196710637\n",
      "208 Train Loss 0.0060926285 Test MSE 0.00015154776887085056 Test RE 0.008919539664708312\n",
      "209 Train Loss 0.006061388 Test MSE 0.00015336160230884497 Test RE 0.008972758652312908\n",
      "210 Train Loss 0.005940877 Test MSE 0.00015156274961173455 Test RE 0.008919980509240399\n",
      "211 Train Loss 0.0058566593 Test MSE 0.00015269029224362186 Test RE 0.008953098876837472\n",
      "212 Train Loss 0.0059028594 Test MSE 0.00015021440404020109 Test RE 0.00888021452027409\n",
      "213 Train Loss 0.0058279 Test MSE 0.00015010636085828192 Test RE 0.008877020355160744\n",
      "214 Train Loss 0.005736752 Test MSE 0.00015028633939190796 Test RE 0.00888234056437458\n",
      "215 Train Loss 0.005688847 Test MSE 0.00014702185498627075 Test RE 0.008785340868241847\n",
      "216 Train Loss 0.005822041 Test MSE 0.00015265550960782482 Test RE 0.008952079067032413\n",
      "217 Train Loss 0.0057013617 Test MSE 0.0001499295165206669 Test RE 0.008871789685990096\n",
      "218 Train Loss 0.0056111556 Test MSE 0.00014959528899099718 Test RE 0.008861895534422163\n",
      "219 Train Loss 0.005531788 Test MSE 0.0001513258540553632 Test RE 0.008913006730714433\n",
      "220 Train Loss 0.0054437965 Test MSE 0.00014822538689254622 Test RE 0.008821226306574387\n",
      "221 Train Loss 0.005352514 Test MSE 0.00014719693597604503 Test RE 0.008790570323828361\n",
      "222 Train Loss 0.0052674264 Test MSE 0.0001405781332414989 Test RE 0.008590660449032122\n",
      "223 Train Loss 0.0052181673 Test MSE 0.00014158308368033846 Test RE 0.008621311780367596\n",
      "224 Train Loss 0.005173655 Test MSE 0.00014115766156242823 Test RE 0.008608349582135416\n",
      "225 Train Loss 0.0051165246 Test MSE 0.00014356175293772988 Test RE 0.008681345566559102\n",
      "226 Train Loss 0.005044687 Test MSE 0.0001414324150095337 Test RE 0.008616723282518083\n",
      "227 Train Loss 0.004962678 Test MSE 0.00014180627128332964 Test RE 0.008628104301607153\n",
      "228 Train Loss 0.0048771906 Test MSE 0.00014058262664244103 Test RE 0.008590797742693695\n",
      "229 Train Loss 0.004782131 Test MSE 0.00014333620222174614 Test RE 0.008674523229264791\n",
      "230 Train Loss 0.004743897 Test MSE 0.00014439567680062557 Test RE 0.008706523227590668\n",
      "231 Train Loss 0.0047145425 Test MSE 0.00014842340465026285 Test RE 0.008827116581159962\n",
      "232 Train Loss 0.0047814767 Test MSE 0.00014808883390159735 Test RE 0.008817162082435126\n",
      "233 Train Loss 0.0048095137 Test MSE 0.00014746535118091548 Test RE 0.008798581523397735\n",
      "234 Train Loss 0.0047572725 Test MSE 0.00014780755314548898 Test RE 0.00880878441900948\n",
      "235 Train Loss 0.0047807805 Test MSE 0.0001445378528715296 Test RE 0.008710808517612002\n",
      "236 Train Loss 0.004670998 Test MSE 0.00014195692405800461 Test RE 0.008632686266812907\n",
      "237 Train Loss 0.0046174894 Test MSE 0.00014146565030129305 Test RE 0.00861773564764721\n",
      "238 Train Loss 0.0046150708 Test MSE 0.00014394258109428165 Test RE 0.008692852500438907\n",
      "239 Train Loss 0.0046355724 Test MSE 0.0001415578683936609 Test RE 0.008620544038479675\n",
      "240 Train Loss 0.0045945267 Test MSE 0.00013946455656246878 Test RE 0.008556567738174951\n",
      "241 Train Loss 0.0045095673 Test MSE 0.0001356219425780047 Test RE 0.008437866463095644\n",
      "242 Train Loss 0.0044207876 Test MSE 0.00013705920456059817 Test RE 0.008482459038969051\n",
      "243 Train Loss 0.0043779914 Test MSE 0.00013608347191437794 Test RE 0.008452211543651701\n",
      "244 Train Loss 0.004368867 Test MSE 0.0001323282712606807 Test RE 0.008334777047750212\n",
      "245 Train Loss 0.0043028905 Test MSE 0.00013449927327566853 Test RE 0.008402869842658088\n",
      "246 Train Loss 0.0042796074 Test MSE 0.00013216034188814088 Test RE 0.008329486801752857\n",
      "247 Train Loss 0.0042445012 Test MSE 0.00013258999978344943 Test RE 0.008343015541579627\n",
      "248 Train Loss 0.0041739573 Test MSE 0.0001316071118242887 Test RE 0.008312034686279238\n",
      "249 Train Loss 0.004153432 Test MSE 0.00012414735706801195 Test RE 0.008073027035256461\n",
      "250 Train Loss 0.0040805005 Test MSE 0.00012340725857715735 Test RE 0.008048927583679682\n",
      "251 Train Loss 0.004061969 Test MSE 0.00012145196899877384 Test RE 0.0079849085699026\n",
      "252 Train Loss 0.0040347856 Test MSE 0.00012053442501550824 Test RE 0.007954689237342556\n",
      "253 Train Loss 0.0039982437 Test MSE 0.00011991821690588874 Test RE 0.007934329805262486\n",
      "254 Train Loss 0.0040725004 Test MSE 0.00011904316286664685 Test RE 0.007905328041340727\n",
      "255 Train Loss 0.004045191 Test MSE 0.0001185884222966793 Test RE 0.007890214560914918\n",
      "256 Train Loss 0.0040090582 Test MSE 0.0001189199349129552 Test RE 0.007901235367702354\n",
      "257 Train Loss 0.003935781 Test MSE 0.00011916007416344053 Test RE 0.00790920896706668\n",
      "258 Train Loss 0.004036132 Test MSE 0.00011979653833158978 Test RE 0.007930303382127937\n",
      "259 Train Loss 0.0039647645 Test MSE 0.00011751000165985666 Test RE 0.007854256567509148\n",
      "260 Train Loss 0.0038904077 Test MSE 0.00011788551036452312 Test RE 0.00786679588005905\n",
      "261 Train Loss 0.0038660788 Test MSE 0.000115192317508644 Test RE 0.007776414932322438\n",
      "262 Train Loss 0.0038265933 Test MSE 0.00011644271832563523 Test RE 0.007818507108165182\n",
      "263 Train Loss 0.003759027 Test MSE 0.00011851139249761039 Test RE 0.007887651577279761\n",
      "264 Train Loss 0.003699949 Test MSE 0.00011859852439978956 Test RE 0.007890550622657219\n",
      "265 Train Loss 0.003683139 Test MSE 0.00011849663723549703 Test RE 0.007887160535925579\n",
      "266 Train Loss 0.00362283 Test MSE 0.00011650258635772579 Test RE 0.007820516759313756\n",
      "267 Train Loss 0.003580278 Test MSE 0.00011799365610216613 Test RE 0.007870403471070993\n",
      "268 Train Loss 0.003567397 Test MSE 0.0001161699689251267 Test RE 0.0078093449064304335\n",
      "269 Train Loss 0.003576692 Test MSE 0.0001158618988595767 Test RE 0.007798983267641948\n",
      "270 Train Loss 0.0035676754 Test MSE 0.00011514707918647308 Test RE 0.007774887805699034\n",
      "271 Train Loss 0.003594545 Test MSE 0.00011125150394110577 Test RE 0.007642238955616965\n",
      "272 Train Loss 0.0035615303 Test MSE 0.00011194520396522574 Test RE 0.007666028219925154\n",
      "273 Train Loss 0.0036095735 Test MSE 0.00011245037398476392 Test RE 0.0076833058179760156\n",
      "274 Train Loss 0.003543481 Test MSE 0.00011296900553944494 Test RE 0.007701003495150832\n",
      "275 Train Loss 0.0034965074 Test MSE 0.00011391481938475081 Test RE 0.007733173973074576\n",
      "276 Train Loss 0.003710091 Test MSE 0.00011377870505289058 Test RE 0.0077285524917206794\n",
      "277 Train Loss 0.0036180113 Test MSE 0.00011391515838504482 Test RE 0.007733185479682383\n",
      "278 Train Loss 0.0035912204 Test MSE 0.00011216265111543422 Test RE 0.0076734700183426815\n",
      "279 Train Loss 0.00352366 Test MSE 0.00010922407091186568 Test RE 0.007572283186441338\n",
      "280 Train Loss 0.0035311712 Test MSE 0.00010608825699566129 Test RE 0.007462791783527278\n",
      "281 Train Loss 0.0034589572 Test MSE 0.00010425767255757615 Test RE 0.007398125263349742\n",
      "282 Train Loss 0.0033966885 Test MSE 0.0001015008912122799 Test RE 0.007299659381009939\n",
      "283 Train Loss 0.0034284873 Test MSE 0.00010045649208091501 Test RE 0.007262007146402843\n",
      "284 Train Loss 0.003398372 Test MSE 9.800119643215726e-05 Test RE 0.007172711392258148\n",
      "285 Train Loss 0.003343529 Test MSE 9.972183629506811e-05 Test RE 0.007235404259070824\n",
      "286 Train Loss 0.0032918733 Test MSE 9.863775998928447e-05 Test RE 0.007195968742346332\n",
      "287 Train Loss 0.0032721856 Test MSE 9.720047518160105e-05 Test RE 0.007143348882671276\n",
      "288 Train Loss 0.0034169962 Test MSE 9.600258579494243e-05 Test RE 0.007099195450068851\n",
      "289 Train Loss 0.0033276917 Test MSE 9.609853863975118e-05 Test RE 0.007102742322634264\n",
      "290 Train Loss 0.0032770687 Test MSE 9.59506455603783e-05 Test RE 0.007097274753030771\n",
      "291 Train Loss 0.0032358484 Test MSE 9.550864235051022e-05 Test RE 0.0070809088428734615\n",
      "292 Train Loss 0.0031858254 Test MSE 9.4979855391289e-05 Test RE 0.007061279785432208\n",
      "293 Train Loss 0.0031230862 Test MSE 9.443452667337506e-05 Test RE 0.007040979365910524\n",
      "294 Train Loss 0.003050229 Test MSE 9.214919977895412e-05 Test RE 0.006955261319669184\n",
      "295 Train Loss 0.0030824104 Test MSE 9.027229919339061e-05 Test RE 0.006884064322572794\n",
      "296 Train Loss 0.0030329654 Test MSE 8.924386567218588e-05 Test RE 0.006844738402285226\n",
      "297 Train Loss 0.0029704277 Test MSE 9.05770320002813e-05 Test RE 0.006895673824351501\n",
      "298 Train Loss 0.002930045 Test MSE 9.082901590326665e-05 Test RE 0.0069052589915316485\n",
      "299 Train Loss 0.002892211 Test MSE 8.87335071106322e-05 Test RE 0.00682513885116145\n",
      "Training time: 249.04\n",
      "KG_tanhALR_medium\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 32080.236 Test MSE 13.057330474551295 Test RE 2.618152055597079\n",
      "1 Train Loss 10545.712 Test MSE 9.001780023618762 Test RE 2.1738614725516063\n",
      "2 Train Loss 3642.0862 Test MSE 14.398701156159737 Test RE 2.7493455458060194\n",
      "3 Train Loss 1546.0469 Test MSE 20.210578463603145 Test RE 3.2572946025574154\n",
      "4 Train Loss 1022.02203 Test MSE 21.189238952462677 Test RE 3.335226608426329\n",
      "5 Train Loss 748.60913 Test MSE 18.640760608325863 Test RE 3.1282358025742933\n",
      "6 Train Loss 527.92596 Test MSE 16.51743295451582 Test RE 2.9446856772662877\n",
      "7 Train Loss 401.22018 Test MSE 15.781108491965968 Test RE 2.8783024039786715\n",
      "8 Train Loss 332.08093 Test MSE 15.350559036388905 Test RE 2.838767116016329\n",
      "9 Train Loss 299.20193 Test MSE 15.006783132851343 Test RE 2.8068000195798475\n",
      "10 Train Loss 266.8846 Test MSE 13.363828023771585 Test RE 2.6487020442750553\n",
      "11 Train Loss 212.07545 Test MSE 9.2967704927406 Test RE 2.2091933259245016\n",
      "12 Train Loss 136.65596 Test MSE 5.992807481732658 Test RE 1.773710883142552\n",
      "13 Train Loss 86.52584 Test MSE 3.6206529525764823 Test RE 1.3786725130091881\n",
      "14 Train Loss 49.121796 Test MSE 1.0220405950897167 Test RE 0.7324900686117158\n",
      "15 Train Loss 22.464724 Test MSE 0.23078582616870713 Test RE 0.34807452094341845\n",
      "16 Train Loss 13.76383 Test MSE 0.1905255943626348 Test RE 0.31626004632322313\n",
      "17 Train Loss 10.27498 Test MSE 0.1661795247236574 Test RE 0.2953632267631549\n",
      "18 Train Loss 8.056419 Test MSE 0.10051313328644203 Test RE 0.22970956180844862\n",
      "19 Train Loss 6.2902603 Test MSE 0.08818946480095949 Test RE 0.21516717660394427\n",
      "20 Train Loss 4.7481627 Test MSE 0.030580696543385445 Test RE 0.1267043001007457\n",
      "21 Train Loss 3.6957903 Test MSE 0.015366279784762361 Test RE 0.08981565384937654\n",
      "22 Train Loss 3.061398 Test MSE 0.0032875502854952192 Test RE 0.0415435753031243\n",
      "23 Train Loss 2.548227 Test MSE 0.001578485675862577 Test RE 0.028786442052025886\n",
      "24 Train Loss 2.0841088 Test MSE 0.0019119760032988852 Test RE 0.031681729839609214\n",
      "25 Train Loss 1.8450552 Test MSE 0.0034291725468603117 Test RE 0.04242895512418443\n",
      "26 Train Loss 1.6028244 Test MSE 0.0035260888313315454 Test RE 0.043024347459323486\n",
      "27 Train Loss 1.394351 Test MSE 0.004718171607518347 Test RE 0.04976849800146464\n",
      "28 Train Loss 1.236287 Test MSE 0.0046162951707348614 Test RE 0.04922825627319035\n",
      "29 Train Loss 1.1121765 Test MSE 0.003926644223994361 Test RE 0.045402361723471445\n",
      "30 Train Loss 1.0303953 Test MSE 0.005210329276212106 Test RE 0.05229982705510086\n",
      "31 Train Loss 0.9555087 Test MSE 0.004276033646087575 Test RE 0.04737925467682231\n",
      "32 Train Loss 0.8703235 Test MSE 0.004018051821701982 Test RE 0.04592777798340542\n",
      "33 Train Loss 0.7688671 Test MSE 0.002239202835245693 Test RE 0.03428580772837316\n",
      "34 Train Loss 0.6940304 Test MSE 0.0014773567723293621 Test RE 0.027849048488049033\n",
      "35 Train Loss 0.6485734 Test MSE 0.001201258406805316 Test RE 0.025112265115842237\n",
      "36 Train Loss 0.59805447 Test MSE 0.00097798686843206 Test RE 0.022658657738221243\n",
      "37 Train Loss 0.54954106 Test MSE 0.0015423439019113714 Test RE 0.028454979561297163\n",
      "38 Train Loss 0.5265599 Test MSE 0.0016276405313424107 Test RE 0.029231218260057184\n",
      "39 Train Loss 0.49112508 Test MSE 0.0015110982236070183 Test RE 0.02816527624597307\n",
      "40 Train Loss 0.4711877 Test MSE 0.0014666423362795892 Test RE 0.027747877994457357\n",
      "41 Train Loss 0.42039424 Test MSE 0.00095501085129713 Test RE 0.02239091394274072\n",
      "42 Train Loss 0.40743756 Test MSE 0.0009988451740742515 Test RE 0.02289901256883623\n",
      "43 Train Loss 0.38631988 Test MSE 0.0010534261337199944 Test RE 0.02351633898070801\n",
      "44 Train Loss 0.3512902 Test MSE 0.0012291937506206713 Test RE 0.025402580683358503\n",
      "45 Train Loss 0.3281442 Test MSE 0.0013393937507666092 Test RE 0.026516842055612055\n",
      "46 Train Loss 0.30198473 Test MSE 0.0012975095084256287 Test RE 0.026098944401922487\n",
      "47 Train Loss 0.2829682 Test MSE 0.0012800208701869292 Test RE 0.025922458805473916\n",
      "48 Train Loss 0.2528729 Test MSE 0.0010391875383928566 Test RE 0.023356869418797954\n",
      "49 Train Loss 0.23893057 Test MSE 0.0010342455866598028 Test RE 0.023301265364163846\n",
      "50 Train Loss 0.22698592 Test MSE 0.001040394695191525 Test RE 0.023370431561930128\n",
      "51 Train Loss 0.2161846 Test MSE 0.0009384764123998489 Test RE 0.022196236749189913\n",
      "52 Train Loss 0.20565116 Test MSE 0.0008499644887992512 Test RE 0.021123605999242543\n",
      "53 Train Loss 0.19468988 Test MSE 0.0008187036172850076 Test RE 0.020731514141383262\n",
      "54 Train Loss 0.1859838 Test MSE 0.0007361370718656238 Test RE 0.01965834770442081\n",
      "55 Train Loss 0.17737497 Test MSE 0.0007367577316936306 Test RE 0.019666633237417547\n",
      "56 Train Loss 0.16614354 Test MSE 0.0006314853863317871 Test RE 0.018207458132836144\n",
      "57 Train Loss 0.15842247 Test MSE 0.0006669376602346681 Test RE 0.018711572576655663\n",
      "58 Train Loss 0.15181306 Test MSE 0.0006859517036005235 Test RE 0.01897642669631085\n",
      "59 Train Loss 0.14304498 Test MSE 0.000636441703676346 Test RE 0.018278770600464362\n",
      "60 Train Loss 0.13671894 Test MSE 0.0006348218032051284 Test RE 0.01825549379914836\n",
      "61 Train Loss 0.12915994 Test MSE 0.0006992146155516689 Test RE 0.019159003488322168\n",
      "62 Train Loss 0.12003207 Test MSE 0.0006070501866845217 Test RE 0.01785171587860923\n",
      "63 Train Loss 0.1154124 Test MSE 0.0005811475435030996 Test RE 0.017466700393128896\n",
      "64 Train Loss 0.11402587 Test MSE 0.0005301061210358748 Test RE 0.01668203688589655\n",
      "65 Train Loss 0.110173695 Test MSE 0.000618071415919821 Test RE 0.018013039328181647\n",
      "66 Train Loss 0.1082105 Test MSE 0.0005409703542859598 Test RE 0.01685211447702883\n",
      "67 Train Loss 0.10359409 Test MSE 0.0005375252363433469 Test RE 0.01679836823156267\n",
      "68 Train Loss 0.10104862 Test MSE 0.0004889187813971498 Test RE 0.016020867475949833\n",
      "69 Train Loss 0.09380515 Test MSE 0.0004764701163212655 Test RE 0.01581559376675512\n",
      "70 Train Loss 0.089662746 Test MSE 0.00043555039355296397 Test RE 0.015121221422815257\n",
      "71 Train Loss 0.08793567 Test MSE 0.0004878156588737733 Test RE 0.016002783736531162\n",
      "72 Train Loss 0.08675664 Test MSE 0.0004286231571721807 Test RE 0.015000491289362539\n",
      "73 Train Loss 0.08217443 Test MSE 0.0003744725107318925 Test RE 0.01402095640317372\n",
      "74 Train Loss 0.07729154 Test MSE 0.0003707097197322545 Test RE 0.013950335558869572\n",
      "75 Train Loss 0.075513504 Test MSE 0.0003791739704786182 Test RE 0.014108697622753855\n",
      "76 Train Loss 0.075310126 Test MSE 0.00039229633955896974 Test RE 0.014350756502017403\n",
      "77 Train Loss 0.070445575 Test MSE 0.00038990883391313425 Test RE 0.014307020685308949\n",
      "78 Train Loss 0.06596681 Test MSE 0.00048136933604222843 Test RE 0.015896696342396332\n",
      "79 Train Loss 0.06324193 Test MSE 0.0004896927030345113 Test RE 0.016033542375861916\n",
      "80 Train Loss 0.061163213 Test MSE 0.0004890654602207472 Test RE 0.01602327047810708\n",
      "81 Train Loss 0.05856 Test MSE 0.0004433282314621684 Test RE 0.015255637543909078\n",
      "82 Train Loss 0.056982797 Test MSE 0.00041955209520860663 Test RE 0.014840912849593907\n",
      "83 Train Loss 0.054731254 Test MSE 0.0003677681003678101 Test RE 0.013894876655332832\n",
      "84 Train Loss 0.053063326 Test MSE 0.0003675757518185375 Test RE 0.013891242559666934\n",
      "85 Train Loss 0.05127122 Test MSE 0.00042255435016355587 Test RE 0.014893917922279407\n",
      "86 Train Loss 0.049737737 Test MSE 0.00036184416690314907 Test RE 0.013782514423478593\n",
      "87 Train Loss 0.04854041 Test MSE 0.00035957907768373586 Test RE 0.013739308484058889\n",
      "88 Train Loss 0.047391426 Test MSE 0.0003407740455394184 Test RE 0.013375219646297575\n",
      "89 Train Loss 0.047725927 Test MSE 0.00033447906430865746 Test RE 0.01325110628688915\n",
      "90 Train Loss 0.045801 Test MSE 0.00030129224307320587 Test RE 0.012576553510676255\n",
      "91 Train Loss 0.044227365 Test MSE 0.0003145443689446127 Test RE 0.01285016265782771\n",
      "92 Train Loss 0.04309491 Test MSE 0.00033345338945252 Test RE 0.013230773531584028\n",
      "93 Train Loss 0.041701786 Test MSE 0.0003026877222673377 Test RE 0.012605644939958303\n",
      "94 Train Loss 0.040536333 Test MSE 0.0003420758904302158 Test RE 0.0134007436896515\n",
      "95 Train Loss 0.03877739 Test MSE 0.0003962872895977826 Test RE 0.01442356909089761\n",
      "96 Train Loss 0.037119824 Test MSE 0.00048816366543886385 Test RE 0.01600849089333495\n",
      "97 Train Loss 0.036171243 Test MSE 0.00042925346184672443 Test RE 0.015011516599411958\n",
      "98 Train Loss 0.03500916 Test MSE 0.0004216371958613516 Test RE 0.01487774551603341\n",
      "99 Train Loss 0.034006063 Test MSE 0.0003617256519431528 Test RE 0.013780257142490392\n",
      "100 Train Loss 0.03394866 Test MSE 0.0003055823083022835 Test RE 0.012665775071236824\n",
      "101 Train Loss 0.033498213 Test MSE 0.00025690829538607685 Test RE 0.011613329049719304\n",
      "102 Train Loss 0.03246462 Test MSE 0.00022070733964203243 Test RE 0.010764058654136753\n",
      "103 Train Loss 0.031423427 Test MSE 0.00019103247014545075 Test RE 0.010014315353558716\n",
      "104 Train Loss 0.030759059 Test MSE 0.00016322673351214822 Test RE 0.009256851834709834\n",
      "105 Train Loss 0.030142423 Test MSE 0.00016387136055980714 Test RE 0.00927511274394389\n",
      "106 Train Loss 0.029596366 Test MSE 0.00016370426248853436 Test RE 0.009270382665608866\n",
      "107 Train Loss 0.029080343 Test MSE 0.00015498945282520476 Test RE 0.009020253443760515\n",
      "108 Train Loss 0.028484918 Test MSE 0.0001706714330353014 Test RE 0.009465598630963967\n",
      "109 Train Loss 0.02756156 Test MSE 0.00017303740067375114 Test RE 0.00953098221082127\n",
      "110 Train Loss 0.026835639 Test MSE 0.00016892852618059835 Test RE 0.009417142976583297\n",
      "111 Train Loss 0.026035555 Test MSE 0.00015399485399251865 Test RE 0.008991264461645219\n",
      "112 Train Loss 0.025067205 Test MSE 0.00014812848826156662 Test RE 0.0088183425074104\n",
      "113 Train Loss 0.02474183 Test MSE 0.00013263670149057932 Test RE 0.008344484727661952\n",
      "114 Train Loss 0.024086073 Test MSE 0.00011294983419694413 Test RE 0.00770035002015934\n",
      "115 Train Loss 0.023408737 Test MSE 0.00012646590884016017 Test RE 0.00814806345191594\n",
      "116 Train Loss 0.023298124 Test MSE 0.00012395698918236128 Test RE 0.008066835060145076\n",
      "117 Train Loss 0.02307375 Test MSE 0.00011126439731395997 Test RE 0.007642681787300538\n",
      "118 Train Loss 0.022631034 Test MSE 0.00011063364481842412 Test RE 0.007620988001349304\n",
      "119 Train Loss 0.022138543 Test MSE 0.00011035534368788648 Test RE 0.007611396592377626\n",
      "120 Train Loss 0.021761551 Test MSE 9.414844747783587e-05 Test RE 0.007030306333450573\n",
      "121 Train Loss 0.02140561 Test MSE 9.171428429450791e-05 Test RE 0.0069388285752318615\n",
      "122 Train Loss 0.020940622 Test MSE 9.109350916136791e-05 Test RE 0.006915305708167238\n",
      "123 Train Loss 0.020208385 Test MSE 8.020574791975148e-05 Test RE 0.006488890031358725\n",
      "124 Train Loss 0.019353308 Test MSE 8.081286183036078e-05 Test RE 0.006513402417484385\n",
      "125 Train Loss 0.01906427 Test MSE 7.642452378894604e-05 Test RE 0.006334087205322759\n",
      "126 Train Loss 0.01851787 Test MSE 7.837840895918045e-05 Test RE 0.00641454548886054\n",
      "127 Train Loss 0.018042183 Test MSE 7.74178413633062e-05 Test RE 0.006375117541784126\n",
      "128 Train Loss 0.0176417 Test MSE 7.703280250738587e-05 Test RE 0.0063592444070047415\n",
      "129 Train Loss 0.01728876 Test MSE 7.280085701136471e-05 Test RE 0.006182098402298293\n",
      "130 Train Loss 0.016823865 Test MSE 6.441702412934353e-05 Test RE 0.005815244732534902\n",
      "131 Train Loss 0.015734775 Test MSE 6.977545163990057e-05 Test RE 0.006052279776366647\n",
      "132 Train Loss 0.014902316 Test MSE 6.430914014224965e-05 Test RE 0.005810373080258889\n",
      "133 Train Loss 0.014321537 Test MSE 6.742860022598643e-05 Test RE 0.005949627004691538\n",
      "134 Train Loss 0.01401702 Test MSE 6.874117156445294e-05 Test RE 0.006007255897515202\n",
      "135 Train Loss 0.013706637 Test MSE 6.583328594842884e-05 Test RE 0.005878823668101386\n",
      "136 Train Loss 0.013458078 Test MSE 6.36865082118571e-05 Test RE 0.0057821770647389515\n",
      "137 Train Loss 0.01315898 Test MSE 5.5424376194640736e-05 Test RE 0.0053940885865478285\n",
      "138 Train Loss 0.012968385 Test MSE 4.985976283983415e-05 Test RE 0.0051161441431043205\n",
      "139 Train Loss 0.012743442 Test MSE 4.133152249329558e-05 Test RE 0.004658095297616197\n",
      "140 Train Loss 0.012559452 Test MSE 3.46171274455537e-05 Test RE 0.004262978880930149\n",
      "141 Train Loss 0.0123268 Test MSE 3.366493647438582e-05 Test RE 0.004203940564212591\n",
      "142 Train Loss 0.011924461 Test MSE 3.8424585974775636e-05 Test RE 0.004491302077656687\n",
      "143 Train Loss 0.011617594 Test MSE 3.641152192422497e-05 Test RE 0.004372069767418215\n",
      "144 Train Loss 0.011353065 Test MSE 3.024070847059548e-05 Test RE 0.003984406577691893\n",
      "145 Train Loss 0.011067921 Test MSE 2.6943550991039333e-05 Test RE 0.0037609285593929367\n",
      "146 Train Loss 0.010818282 Test MSE 2.172358809786163e-05 Test RE 0.0033770185591841134\n",
      "147 Train Loss 0.010520166 Test MSE 1.9710054799252737e-05 Test RE 0.0032167075878680807\n",
      "148 Train Loss 0.010276651 Test MSE 1.7739159268277007e-05 Test RE 0.0030516462205301934\n",
      "149 Train Loss 0.010057535 Test MSE 1.609124054126926e-05 Test RE 0.002906447155740054\n",
      "150 Train Loss 0.009888863 Test MSE 1.7023278755963224e-05 Test RE 0.0029894360885751124\n",
      "151 Train Loss 0.009647075 Test MSE 1.763350949878941e-05 Test RE 0.0030425452481942276\n",
      "152 Train Loss 0.009448274 Test MSE 1.8733698811577775e-05 Test RE 0.0031360244100605873\n",
      "153 Train Loss 0.00934378 Test MSE 1.919639474971027e-05 Test RE 0.003174515878401629\n",
      "154 Train Loss 0.009232334 Test MSE 2.0070632405734983e-05 Test RE 0.003245997612777441\n",
      "155 Train Loss 0.0091376025 Test MSE 1.81759808689759e-05 Test RE 0.0030889906667898293\n",
      "156 Train Loss 0.008976834 Test MSE 1.856953259390126e-05 Test RE 0.003122253447854556\n",
      "157 Train Loss 0.00884658 Test MSE 1.9248084947491796e-05 Test RE 0.0031787870199854345\n",
      "158 Train Loss 0.008696982 Test MSE 2.1051926732333992e-05 Test RE 0.0033244024413967444\n",
      "159 Train Loss 0.0085793715 Test MSE 2.4747670841727267e-05 Test RE 0.003604415371761126\n",
      "160 Train Loss 0.008523929 Test MSE 2.9805658757000548e-05 Test RE 0.0039556424612834104\n",
      "161 Train Loss 0.0083748875 Test MSE 2.8519183998306106e-05 Test RE 0.003869333961615395\n",
      "162 Train Loss 0.008216544 Test MSE 2.675142682511563e-05 Test RE 0.0037474956982234517\n",
      "163 Train Loss 0.008049663 Test MSE 3.0480691999456008e-05 Test RE 0.004000185017709877\n",
      "164 Train Loss 0.00797333 Test MSE 3.234479315515672e-05 Test RE 0.004120689174596892\n",
      "165 Train Loss 0.007977211 Test MSE 2.9667037730145396e-05 Test RE 0.003946433232516023\n",
      "166 Train Loss 0.007879791 Test MSE 3.165357140074098e-05 Test RE 0.004076420964460358\n",
      "167 Train Loss 0.007828945 Test MSE 2.7617627179605183e-05 Test RE 0.003807683560604348\n",
      "168 Train Loss 0.007746407 Test MSE 2.5169304489377877e-05 Test RE 0.00363499045681277\n",
      "169 Train Loss 0.0076500946 Test MSE 2.0786634600681005e-05 Test RE 0.0033033893063964146\n",
      "170 Train Loss 0.0075647896 Test MSE 1.912081985288061e-05 Test RE 0.003168260789618909\n",
      "171 Train Loss 0.0075092646 Test MSE 1.9974028851913475e-05 Test RE 0.003238176405836564\n",
      "172 Train Loss 0.00739757 Test MSE 2.4827035240928998e-05 Test RE 0.0036101903249450137\n",
      "173 Train Loss 0.0072820196 Test MSE 2.150197659831258e-05 Test RE 0.0033597492068024194\n",
      "174 Train Loss 0.0071734143 Test MSE 2.6846993051943336e-05 Test RE 0.003754183467603372\n",
      "175 Train Loss 0.0070916964 Test MSE 2.3827280486691938e-05 Test RE 0.0035367544306138714\n",
      "176 Train Loss 0.006958359 Test MSE 2.181750562215928e-05 Test RE 0.003384310613439182\n",
      "177 Train Loss 0.006883671 Test MSE 2.2012788239249556e-05 Test RE 0.003399422898705485\n",
      "178 Train Loss 0.0067619337 Test MSE 2.1781099407953017e-05 Test RE 0.003381485785950322\n",
      "179 Train Loss 0.006602091 Test MSE 1.8387358385047874e-05 Test RE 0.003106900450797406\n",
      "180 Train Loss 0.006565507 Test MSE 1.549684192135231e-05 Test RE 0.0028522610356163415\n",
      "181 Train Loss 0.0064382856 Test MSE 1.4863818218455964e-05 Test RE 0.0027933982730734643\n",
      "182 Train Loss 0.006315485 Test MSE 1.476937104047298e-05 Test RE 0.0027845092709502042\n",
      "183 Train Loss 0.006244377 Test MSE 1.3299008096190064e-05 Test RE 0.002642270602229945\n",
      "184 Train Loss 0.0061374754 Test MSE 1.1423346733762579e-05 Test RE 0.00244886219785516\n",
      "185 Train Loss 0.0060579046 Test MSE 1.162456927841708e-05 Test RE 0.002470336428497646\n",
      "186 Train Loss 0.005968032 Test MSE 1.118859256370338e-05 Test RE 0.0024235690471672575\n",
      "187 Train Loss 0.0057821283 Test MSE 1.2501689598644356e-05 Test RE 0.0025618401248090343\n",
      "188 Train Loss 0.0056927116 Test MSE 1.1482243845707731e-05 Test RE 0.0024551670699600498\n",
      "189 Train Loss 0.00566446 Test MSE 1.1968622852141575e-05 Test RE 0.00250662726144672\n",
      "190 Train Loss 0.0056117224 Test MSE 1.1565504390777978e-05 Test RE 0.0024640524984772504\n",
      "191 Train Loss 0.0055359127 Test MSE 1.2192638131947257e-05 Test RE 0.0025299766321612177\n",
      "192 Train Loss 0.0054877875 Test MSE 1.1347793628877427e-05 Test RE 0.0024407504733249675\n",
      "193 Train Loss 0.005499147 Test MSE 1.0799967620892374e-05 Test RE 0.0023811069045986803\n",
      "194 Train Loss 0.0054230634 Test MSE 1.071815859719054e-05 Test RE 0.0023720713994218033\n",
      "195 Train Loss 0.0053612487 Test MSE 1.0938118219560202e-05 Test RE 0.0023962877858805668\n",
      "196 Train Loss 0.0053212508 Test MSE 1.1150501791093349e-05 Test RE 0.002419440095224366\n",
      "197 Train Loss 0.0052751605 Test MSE 1.1748843528747682e-05 Test RE 0.0024835060802745864\n",
      "198 Train Loss 0.0051862346 Test MSE 1.2609965016848228e-05 Test RE 0.002572910080541303\n",
      "199 Train Loss 0.0050829384 Test MSE 1.4640416874435812e-05 Test RE 0.002772326582323155\n",
      "200 Train Loss 0.005021459 Test MSE 1.5950376812750153e-05 Test RE 0.0028936975814540036\n",
      "201 Train Loss 0.004948934 Test MSE 1.729395863974599e-05 Test RE 0.0030131092287192835\n",
      "202 Train Loss 0.0048897173 Test MSE 1.7104017645891866e-05 Test RE 0.0029965169289730633\n",
      "203 Train Loss 0.004824534 Test MSE 1.8429021692107674e-05 Test RE 0.0031104183706137266\n",
      "204 Train Loss 0.004802759 Test MSE 1.4978003264464121e-05 Test RE 0.002804107300524643\n",
      "205 Train Loss 0.0046802056 Test MSE 1.4888248942743824e-05 Test RE 0.002795692997169786\n",
      "206 Train Loss 0.004634065 Test MSE 1.5297323302736443e-05 Test RE 0.0028338404191518545\n",
      "207 Train Loss 0.0045640217 Test MSE 1.4832350368438297e-05 Test RE 0.0027904397865704763\n",
      "208 Train Loss 0.0044701276 Test MSE 1.5792347272723382e-05 Test RE 0.00287932713720122\n",
      "209 Train Loss 0.00440045 Test MSE 1.5964738418550005e-05 Test RE 0.0028950000207004674\n",
      "210 Train Loss 0.0043433434 Test MSE 1.5318160643313255e-05 Test RE 0.002835769828687922\n",
      "211 Train Loss 0.0043139155 Test MSE 1.4741905364144969e-05 Test RE 0.0027819189771998262\n",
      "212 Train Loss 0.0042826617 Test MSE 1.3942645431516668e-05 Test RE 0.002705454654620691\n",
      "213 Train Loss 0.0042473674 Test MSE 1.3657535691045865e-05 Test RE 0.0026776501890666948\n",
      "214 Train Loss 0.0042112735 Test MSE 1.4137740406016994e-05 Test RE 0.002724317180008921\n",
      "215 Train Loss 0.004187763 Test MSE 1.4108620882838921e-05 Test RE 0.002721510093920217\n",
      "216 Train Loss 0.0041115964 Test MSE 1.492172102608457e-05 Test RE 0.002798833901535428\n",
      "217 Train Loss 0.004013164 Test MSE 1.2330916856530483e-05 Test RE 0.002544282626460367\n",
      "218 Train Loss 0.003975107 Test MSE 1.060812965376417e-05 Test RE 0.002359864554704122\n",
      "219 Train Loss 0.003918342 Test MSE 1.0403537385343991e-05 Test RE 0.002336997155181228\n",
      "220 Train Loss 0.0038683482 Test MSE 1.0672330375969428e-05 Test RE 0.0023669947688165632\n",
      "221 Train Loss 0.0038211148 Test MSE 1.0503813581663271e-05 Test RE 0.0023482329103111654\n",
      "222 Train Loss 0.0037951851 Test MSE 1.0571979766683613e-05 Test RE 0.0023558402053641568\n",
      "223 Train Loss 0.0037487112 Test MSE 1.0828514928269244e-05 Test RE 0.002384251790477034\n",
      "224 Train Loss 0.0037218342 Test MSE 1.0638271741399968e-05 Test RE 0.0023632148525354886\n",
      "225 Train Loss 0.0036729765 Test MSE 1.1155235301391384e-05 Test RE 0.0024199535801623807\n",
      "226 Train Loss 0.003670424 Test MSE 1.1266360046706684e-05 Test RE 0.002431977097299547\n",
      "227 Train Loss 0.003614198 Test MSE 1.122611893713231e-05 Test RE 0.0024276299522739283\n",
      "228 Train Loss 0.0035788843 Test MSE 1.1258952633583533e-05 Test RE 0.002431177476967999\n",
      "229 Train Loss 0.003545672 Test MSE 1.2109415311325609e-05 Test RE 0.002521327465778407\n",
      "230 Train Loss 0.0035265218 Test MSE 1.2216233599640358e-05 Test RE 0.0025324234827895616\n",
      "231 Train Loss 0.0034849457 Test MSE 1.2066025850521777e-05 Test RE 0.00251680630559822\n",
      "232 Train Loss 0.0034461073 Test MSE 1.1966792536509444e-05 Test RE 0.0025064355896673575\n",
      "233 Train Loss 0.0034128013 Test MSE 1.257422624802981e-05 Test RE 0.0025692614628310233\n",
      "234 Train Loss 0.003389776 Test MSE 1.2387167985030815e-05 Test RE 0.00255007927249221\n",
      "235 Train Loss 0.0033305793 Test MSE 1.2900613160511572e-05 Test RE 0.00260239277146276\n",
      "236 Train Loss 0.0032860502 Test MSE 1.2245350182652016e-05 Test RE 0.0025354396184220124\n",
      "237 Train Loss 0.0032707946 Test MSE 1.1920919941496106e-05 Test RE 0.002501626986951881\n",
      "238 Train Loss 0.0032504825 Test MSE 1.1897491230315071e-05 Test RE 0.0024991674988445885\n",
      "239 Train Loss 0.003193189 Test MSE 1.2040624795862537e-05 Test RE 0.0025141557553487437\n",
      "240 Train Loss 0.0031557167 Test MSE 1.1853403752514052e-05 Test RE 0.002494532729549121\n",
      "241 Train Loss 0.003105182 Test MSE 1.143205995582221e-05 Test RE 0.0024497959615476573\n",
      "242 Train Loss 0.0030476563 Test MSE 1.172520980063896e-05 Test RE 0.0024810069383717917\n",
      "243 Train Loss 0.0030119235 Test MSE 1.1146714944131517e-05 Test RE 0.002419029224594337\n",
      "244 Train Loss 0.0029708724 Test MSE 1.0376524470257856e-05 Test RE 0.0023339611619639412\n",
      "245 Train Loss 0.0029639397 Test MSE 1.0470756167920993e-05 Test RE 0.002344534840140679\n",
      "246 Train Loss 0.0029116669 Test MSE 9.594869638126688e-06 Test RE 0.002244332543484777\n",
      "247 Train Loss 0.0028701134 Test MSE 9.647840422675813e-06 Test RE 0.0022505192051833125\n",
      "248 Train Loss 0.0028518366 Test MSE 1.0230821970428623e-05 Test RE 0.0023175170149572467\n",
      "249 Train Loss 0.0028045913 Test MSE 1.004775361892806e-05 Test RE 0.002296688819617979\n",
      "250 Train Loss 0.0027597472 Test MSE 1.037269948271397e-05 Test RE 0.0023335309507091905\n",
      "251 Train Loss 0.0027140577 Test MSE 1.0484957919760586e-05 Test RE 0.002346124277372958\n",
      "252 Train Loss 0.0026806595 Test MSE 1.034799805111611e-05 Test RE 0.002330750772178115\n",
      "253 Train Loss 0.0026965037 Test MSE 1.0108336190636374e-05 Test RE 0.0023036023157291916\n",
      "254 Train Loss 0.002633025 Test MSE 9.768920064513626e-06 Test RE 0.0022645970937004763\n",
      "255 Train Loss 0.0026209103 Test MSE 9.532548767118076e-06 Test RE 0.002237031943022193\n",
      "256 Train Loss 0.0025869764 Test MSE 9.423556521550817e-06 Test RE 0.002224206407471029\n",
      "257 Train Loss 0.002546354 Test MSE 9.463807869543749e-06 Test RE 0.002228951532564199\n",
      "258 Train Loss 0.0025041334 Test MSE 9.065537563985476e-06 Test RE 0.0021815463697284782\n",
      "259 Train Loss 0.0024646097 Test MSE 8.841230973449865e-06 Test RE 0.002154388568046294\n",
      "260 Train Loss 0.0024044104 Test MSE 8.878342986905e-06 Test RE 0.002158905471283532\n",
      "261 Train Loss 0.002374442 Test MSE 8.639483582267036e-06 Test RE 0.0021296663041493577\n",
      "262 Train Loss 0.0023333197 Test MSE 8.283812288479606e-06 Test RE 0.002085368418945087\n",
      "263 Train Loss 0.002331572 Test MSE 8.31938757536689e-06 Test RE 0.0020898414862421345\n",
      "264 Train Loss 0.0022989053 Test MSE 8.659567817731925e-06 Test RE 0.002132140288241671\n",
      "265 Train Loss 0.0022695356 Test MSE 8.454065159516543e-06 Test RE 0.0021066891719601134\n",
      "266 Train Loss 0.0022432872 Test MSE 8.571790521104523e-06 Test RE 0.0021213065952862256\n",
      "267 Train Loss 0.0022303872 Test MSE 8.600885325325267e-06 Test RE 0.002124903668510777\n",
      "268 Train Loss 0.0022182728 Test MSE 8.74693220206965e-06 Test RE 0.0021428686332328048\n",
      "269 Train Loss 0.0022025383 Test MSE 8.844614187764992e-06 Test RE 0.002154800731302408\n",
      "270 Train Loss 0.0021700962 Test MSE 8.61760464406177e-06 Test RE 0.0021269679730486586\n",
      "271 Train Loss 0.0021482382 Test MSE 8.644732288113647e-06 Test RE 0.0021303131191275017\n",
      "272 Train Loss 0.0021113562 Test MSE 9.084238186606186e-06 Test RE 0.002183795285353944\n",
      "273 Train Loss 0.0020981417 Test MSE 9.60063662256483e-06 Test RE 0.002245006918805989\n",
      "274 Train Loss 0.002079175 Test MSE 9.685206564978677e-06 Test RE 0.0022548731305753016\n",
      "275 Train Loss 0.0020596704 Test MSE 9.459377026754649e-06 Test RE 0.0022284296871186685\n",
      "276 Train Loss 0.0020482435 Test MSE 9.499049158340776e-06 Test RE 0.0022330977564999507\n",
      "277 Train Loss 0.002050951 Test MSE 8.883599281126064e-06 Test RE 0.0021595444510619033\n",
      "278 Train Loss 0.0020422752 Test MSE 8.847104451280194e-06 Test RE 0.0021551040596258734\n",
      "279 Train Loss 0.0020281246 Test MSE 8.862885007605053e-06 Test RE 0.002157025229957437\n",
      "280 Train Loss 0.0020106824 Test MSE 9.086547269918382e-06 Test RE 0.0021840728124701884\n",
      "281 Train Loss 0.0020013894 Test MSE 9.168701474153582e-06 Test RE 0.0021939240249204306\n",
      "282 Train Loss 0.0019854866 Test MSE 9.525217904387704e-06 Test RE 0.0022361715997585934\n",
      "283 Train Loss 0.001976671 Test MSE 9.155412229362905e-06 Test RE 0.0021923334962181676\n",
      "284 Train Loss 0.0019579667 Test MSE 8.782993535096621e-06 Test RE 0.0021472813356240125\n",
      "285 Train Loss 0.001954914 Test MSE 8.79379646559332e-06 Test RE 0.002148601489302826\n",
      "286 Train Loss 0.0019314459 Test MSE 8.841497272127026e-06 Test RE 0.0021544210129913195\n",
      "287 Train Loss 0.0019176883 Test MSE 8.907235392060862e-06 Test RE 0.002162415434078007\n",
      "288 Train Loss 0.0019010797 Test MSE 9.008324895109548e-06 Test RE 0.002174651597325626\n",
      "289 Train Loss 0.0018848572 Test MSE 9.107693358957976e-06 Test RE 0.0021866127078764832\n",
      "290 Train Loss 0.00186784 Test MSE 9.378654633415447e-06 Test RE 0.002218901068708654\n",
      "291 Train Loss 0.0018750939 Test MSE 9.287725828188767e-06 Test RE 0.002208118421750226\n",
      "292 Train Loss 0.0018611202 Test MSE 8.934356245317123e-06 Test RE 0.0021657050057013443\n",
      "293 Train Loss 0.0018356525 Test MSE 8.691602996492821e-06 Test RE 0.002136080464175087\n",
      "294 Train Loss 0.00182887 Test MSE 8.532629118258737e-06 Test RE 0.002116455307664859\n",
      "295 Train Loss 0.0018119076 Test MSE 8.653806740801536e-06 Test RE 0.0021314309302137313\n",
      "296 Train Loss 0.0018050757 Test MSE 8.62469414480624e-06 Test RE 0.0021278426964557082\n",
      "297 Train Loss 0.0017985766 Test MSE 8.845006044989492e-06 Test RE 0.0021548484645818812\n",
      "298 Train Loss 0.0018057624 Test MSE 9.015173416354636e-06 Test RE 0.00217547807274191\n",
      "299 Train Loss 0.0017906858 Test MSE 9.081877303023229e-06 Test RE 0.0021835114959293115\n",
      "Training time: 248.36\n",
      "KG_tanhALR_medium\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 25434.248 Test MSE 15.123331688084933 Test RE 2.8176782933159883\n",
      "1 Train Loss 10777.122 Test MSE 11.533792615224916 Test RE 2.460672052891015\n",
      "2 Train Loss 7817.952 Test MSE 10.359747384371973 Test RE 2.332073588365553\n",
      "3 Train Loss 5021.012 Test MSE 5.2353010419521 Test RE 1.6578242860733126\n",
      "4 Train Loss 1787.1063 Test MSE 6.148380389851084 Test RE 1.796586086524208\n",
      "5 Train Loss 934.555 Test MSE 7.617482670032845 Test RE 1.9997394077138657\n",
      "6 Train Loss 526.90765 Test MSE 5.672229317454554 Test RE 1.7256175847835176\n",
      "7 Train Loss 199.4008 Test MSE 1.3194464900779712 Test RE 0.8322686937985346\n",
      "8 Train Loss 84.646805 Test MSE 0.37062506091445807 Test RE 0.4410979695924208\n",
      "9 Train Loss 33.391644 Test MSE 0.09669122635648252 Test RE 0.22530000528395944\n",
      "10 Train Loss 18.830343 Test MSE 0.05746910827983918 Test RE 0.17369403208452963\n",
      "11 Train Loss 12.529797 Test MSE 0.04343294729425861 Test RE 0.15100012893085898\n",
      "12 Train Loss 8.935924 Test MSE 0.05919574104379209 Test RE 0.17628400085301402\n",
      "13 Train Loss 6.8803873 Test MSE 0.05245872696029206 Test RE 0.16594972659182378\n",
      "14 Train Loss 5.575932 Test MSE 0.061789300311174064 Test RE 0.18010439314008142\n",
      "15 Train Loss 4.7622933 Test MSE 0.039119861738818436 Test RE 0.14330664319740335\n",
      "16 Train Loss 4.0569725 Test MSE 0.03037098953449138 Test RE 0.12626911562309215\n",
      "17 Train Loss 3.674644 Test MSE 0.03062250973451738 Test RE 0.126790892330251\n",
      "18 Train Loss 3.1423461 Test MSE 0.019002257586501665 Test RE 0.0998780990824232\n",
      "19 Train Loss 2.7872632 Test MSE 0.014033551197074973 Test RE 0.08583244014528599\n",
      "20 Train Loss 2.4326618 Test MSE 0.00932146967264251 Test RE 0.06995356677927926\n",
      "21 Train Loss 2.08261 Test MSE 0.004227199384014331 Test RE 0.04710793140256286\n",
      "22 Train Loss 1.6666068 Test MSE 0.0025063627731908267 Test RE 0.03627351428417757\n",
      "23 Train Loss 1.4625281 Test MSE 0.001921072510207738 Test RE 0.03175700565547757\n",
      "24 Train Loss 1.2607597 Test MSE 0.0016142073393697431 Test RE 0.029110343254319083\n",
      "25 Train Loss 1.0498793 Test MSE 0.0014304493337650404 Test RE 0.02740336576960917\n",
      "26 Train Loss 0.92030096 Test MSE 0.001407091247967084 Test RE 0.027178707423606917\n",
      "27 Train Loss 0.84195757 Test MSE 0.0013946807134554606 Test RE 0.02705858396466035\n",
      "28 Train Loss 0.75451535 Test MSE 0.0016152292968968356 Test RE 0.02911955670123781\n",
      "29 Train Loss 0.6856481 Test MSE 0.0013890095198929415 Test RE 0.027003513731827414\n",
      "30 Train Loss 0.6086469 Test MSE 0.0008512384843337768 Test RE 0.021139430956274772\n",
      "31 Train Loss 0.49522373 Test MSE 0.0006060851173860764 Test RE 0.017837520186115296\n",
      "32 Train Loss 0.41621712 Test MSE 0.00045749348215674206 Test RE 0.01549744569510894\n",
      "33 Train Loss 0.37396216 Test MSE 0.000362017581407985 Test RE 0.013785816675991951\n",
      "34 Train Loss 0.3272516 Test MSE 0.00023886296764282338 Test RE 0.011198041676253132\n",
      "35 Train Loss 0.2848547 Test MSE 0.0002942792413070541 Test RE 0.012429323210413297\n",
      "36 Train Loss 0.25360593 Test MSE 0.0003773808336399533 Test RE 0.014075297642428375\n",
      "37 Train Loss 0.22555977 Test MSE 0.00039039595176096467 Test RE 0.014315954863249476\n",
      "38 Train Loss 0.20834266 Test MSE 0.0004321989722114847 Test RE 0.015062932590136597\n",
      "39 Train Loss 0.18909106 Test MSE 0.00024159825923451885 Test RE 0.011261975236100294\n",
      "40 Train Loss 0.1631785 Test MSE 0.0002801265237214462 Test RE 0.012126760028395005\n",
      "41 Train Loss 0.14723365 Test MSE 0.00017464452428220956 Test RE 0.009575140481156704\n",
      "42 Train Loss 0.13865502 Test MSE 0.00012630834454822418 Test RE 0.008142986020393676\n",
      "43 Train Loss 0.12631814 Test MSE 0.00017104402037895322 Test RE 0.009475925020960698\n",
      "44 Train Loss 0.11580491 Test MSE 0.0001770704820497259 Test RE 0.009641414459197525\n",
      "45 Train Loss 0.11070437 Test MSE 0.00015387282021985026 Test RE 0.008987701175734804\n",
      "46 Train Loss 0.10578261 Test MSE 0.0001430233016594317 Test RE 0.008665049885925428\n",
      "47 Train Loss 0.09824412 Test MSE 0.00010653063597997597 Test RE 0.007478335199354445\n",
      "48 Train Loss 0.08987949 Test MSE 7.67465061997412e-05 Test RE 0.006347416179945478\n",
      "49 Train Loss 0.08644848 Test MSE 8.853389789703593e-05 Test RE 0.006817457831465999\n",
      "50 Train Loss 0.081179105 Test MSE 9.987074422700534e-05 Test RE 0.007240804315965523\n",
      "51 Train Loss 0.077727504 Test MSE 0.00011038973860333002 Test RE 0.007612582638010188\n",
      "52 Train Loss 0.07457575 Test MSE 9.398063279675845e-05 Test RE 0.007024037962363339\n",
      "53 Train Loss 0.0679163 Test MSE 9.803835393118544e-05 Test RE 0.007174071042793428\n",
      "54 Train Loss 0.06523833 Test MSE 0.00011222255224830893 Test RE 0.007675518776059021\n",
      "55 Train Loss 0.06053674 Test MSE 8.988577575804654e-05 Test RE 0.006869310590779298\n",
      "56 Train Loss 0.056999866 Test MSE 8.542835382120565e-05 Test RE 0.006696820933967016\n",
      "57 Train Loss 0.054099433 Test MSE 9.36462787468292e-05 Test RE 0.007011532151236421\n",
      "58 Train Loss 0.051907472 Test MSE 9.093793469957136e-05 Test RE 0.006909398016648074\n",
      "59 Train Loss 0.050770655 Test MSE 8.916045716429846e-05 Test RE 0.006841539062644476\n",
      "60 Train Loss 0.047964185 Test MSE 8.67619597423812e-05 Test RE 0.006748889915488165\n",
      "61 Train Loss 0.046294253 Test MSE 6.549324878772571e-05 Test RE 0.005863621582540218\n",
      "62 Train Loss 0.04191981 Test MSE 6.337897721416133e-05 Test RE 0.005768199610308769\n",
      "63 Train Loss 0.038491655 Test MSE 6.772207997695819e-05 Test RE 0.0059625606798724895\n",
      "64 Train Loss 0.036149357 Test MSE 7.84584255442024e-05 Test RE 0.006417818961100374\n",
      "65 Train Loss 0.034808736 Test MSE 8.419969726905225e-05 Test RE 0.006648488665093387\n",
      "66 Train Loss 0.033546936 Test MSE 7.935519628174632e-05 Test RE 0.0064543922155640586\n",
      "67 Train Loss 0.031669844 Test MSE 7.212275857850317e-05 Test RE 0.00615323968533179\n",
      "68 Train Loss 0.030286642 Test MSE 5.891101399762247e-05 Test RE 0.0055611667397198064\n",
      "69 Train Loss 0.029179942 Test MSE 7.050984937362616e-05 Test RE 0.006084047010317665\n",
      "70 Train Loss 0.027026542 Test MSE 7.202255843161332e-05 Test RE 0.006148963851832745\n",
      "71 Train Loss 0.02628865 Test MSE 7.220341949014394e-05 Test RE 0.00615667956505348\n",
      "72 Train Loss 0.025530646 Test MSE 5.20996548819136e-05 Test RE 0.005229800122206087\n",
      "73 Train Loss 0.024394877 Test MSE 5.4300667519922155e-05 Test RE 0.005339127005677734\n",
      "74 Train Loss 0.023389915 Test MSE 4.6604972054615975e-05 Test RE 0.004946338042688906\n",
      "75 Train Loss 0.022794362 Test MSE 3.8249332445571417e-05 Test RE 0.004481048016657506\n",
      "76 Train Loss 0.02227919 Test MSE 3.804482031076807e-05 Test RE 0.004469052291279835\n",
      "77 Train Loss 0.021742295 Test MSE 3.977623874130095e-05 Test RE 0.0045696140858343505\n",
      "78 Train Loss 0.021034516 Test MSE 3.5706598172927315e-05 Test RE 0.0043295414890785165\n",
      "79 Train Loss 0.020336127 Test MSE 3.641908081705664e-05 Test RE 0.004372523556357762\n",
      "80 Train Loss 0.019976337 Test MSE 3.311150498779399e-05 Test RE 0.00416924222990986\n",
      "81 Train Loss 0.019656284 Test MSE 2.9770014778560074e-05 Test RE 0.0039532765177189245\n",
      "82 Train Loss 0.019193107 Test MSE 3.1715073056043545e-05 Test RE 0.004080379206228846\n",
      "83 Train Loss 0.018675096 Test MSE 3.267570699684664e-05 Test RE 0.00414171455473305\n",
      "84 Train Loss 0.01817102 Test MSE 3.276669051719353e-05 Test RE 0.0041474767226573\n",
      "85 Train Loss 0.017695343 Test MSE 2.8687899285108187e-05 Test RE 0.0038807622890169673\n",
      "86 Train Loss 0.017298978 Test MSE 3.158143424314493e-05 Test RE 0.004071773319058876\n",
      "87 Train Loss 0.017101126 Test MSE 3.181322365456471e-05 Test RE 0.004086688229741711\n",
      "88 Train Loss 0.016693033 Test MSE 2.8257077153206723e-05 Test RE 0.003851512275316342\n",
      "89 Train Loss 0.016305659 Test MSE 2.796345102384995e-05 Test RE 0.0038314490204483585\n",
      "90 Train Loss 0.015847066 Test MSE 2.6160544178404182e-05 Test RE 0.003705877458639566\n",
      "91 Train Loss 0.015453393 Test MSE 2.5745025590934592e-05 Test RE 0.0036763286739548854\n",
      "92 Train Loss 0.014821577 Test MSE 2.4486499432603996e-05 Test RE 0.003585345555086002\n",
      "93 Train Loss 0.014554753 Test MSE 2.412762761009451e-05 Test RE 0.0035589753357153\n",
      "94 Train Loss 0.014145139 Test MSE 2.450691623576305e-05 Test RE 0.0035868399712689876\n",
      "95 Train Loss 0.013710627 Test MSE 2.0741971363492635e-05 Test RE 0.0032998384815211943\n",
      "96 Train Loss 0.013295195 Test MSE 2.143110058337693e-05 Test RE 0.0033542073397860575\n",
      "97 Train Loss 0.012977811 Test MSE 2.0559891608927288e-05 Test RE 0.0032853230295388216\n",
      "98 Train Loss 0.012688383 Test MSE 2.2421056997276383e-05 Test RE 0.003430802429949386\n",
      "99 Train Loss 0.012346959 Test MSE 2.207632816734096e-05 Test RE 0.003404325581599806\n",
      "100 Train Loss 0.012023082 Test MSE 2.094690767011544e-05 Test RE 0.003316100062941455\n",
      "101 Train Loss 0.011650587 Test MSE 2.2550689170696703e-05 Test RE 0.003440706097377509\n",
      "102 Train Loss 0.01121554 Test MSE 2.69362881796135e-05 Test RE 0.0037604216337115593\n",
      "103 Train Loss 0.010923412 Test MSE 2.5544760136069707e-05 Test RE 0.003662002042254204\n",
      "104 Train Loss 0.010736106 Test MSE 2.7841586914207515e-05 Test RE 0.0038230912190958914\n",
      "105 Train Loss 0.010466102 Test MSE 3.920682934216104e-05 Test RE 0.004536788451816021\n",
      "106 Train Loss 0.010057764 Test MSE 3.8211611919862394e-05 Test RE 0.0044788379234437636\n",
      "107 Train Loss 0.009830742 Test MSE 3.53783772313635e-05 Test RE 0.0043095966192845565\n",
      "108 Train Loss 0.00971703 Test MSE 3.2064399637135304e-05 Test RE 0.004102789392667132\n",
      "109 Train Loss 0.009494206 Test MSE 2.9753414292458837e-05 Test RE 0.003952174142331568\n",
      "110 Train Loss 0.009284509 Test MSE 2.4069030569699444e-05 Test RE 0.0035546509943688398\n",
      "111 Train Loss 0.0091837 Test MSE 2.4634445821646376e-05 Test RE 0.003596160496576714\n",
      "112 Train Loss 0.009046067 Test MSE 2.3846936930268858e-05 Test RE 0.0035382129621935226\n",
      "113 Train Loss 0.008905186 Test MSE 2.7035786545559008e-05 Test RE 0.0037673604317372163\n",
      "114 Train Loss 0.008660713 Test MSE 2.2963518550152298e-05 Test RE 0.0034720573024862953\n",
      "115 Train Loss 0.008493206 Test MSE 2.243332143320042e-05 Test RE 0.003431740635139337\n",
      "116 Train Loss 0.008336228 Test MSE 2.1665607305539438e-05 Test RE 0.003372508875154379\n",
      "117 Train Loss 0.008219014 Test MSE 1.8801957614708933e-05 Test RE 0.0031417324829562383\n",
      "118 Train Loss 0.008122938 Test MSE 1.8675777983596446e-05 Test RE 0.003131172678719358\n",
      "119 Train Loss 0.008024352 Test MSE 1.7835334074836006e-05 Test RE 0.003059907456480644\n",
      "120 Train Loss 0.007924629 Test MSE 1.6792194589210926e-05 Test RE 0.002969076562735084\n",
      "121 Train Loss 0.0077756275 Test MSE 1.835513657706648e-05 Test RE 0.003104177007766218\n",
      "122 Train Loss 0.007642026 Test MSE 1.5739413561445577e-05 Test RE 0.0028744975383991197\n",
      "123 Train Loss 0.0074876253 Test MSE 1.6946572606765836e-05 Test RE 0.002982693350274345\n",
      "124 Train Loss 0.0073539796 Test MSE 1.912748510595301e-05 Test RE 0.003168812947427758\n",
      "125 Train Loss 0.0073060314 Test MSE 1.9154119790322637e-05 Test RE 0.0031710184378819476\n",
      "126 Train Loss 0.007219659 Test MSE 2.1155301241445976e-05 Test RE 0.00333255460788807\n",
      "127 Train Loss 0.0072059412 Test MSE 2.039794406877903e-05 Test RE 0.003272358421992012\n",
      "128 Train Loss 0.007155857 Test MSE 1.973629496563723e-05 Test RE 0.003218848091000542\n",
      "129 Train Loss 0.0070622987 Test MSE 1.914894794510598e-05 Test RE 0.003170590302214011\n",
      "130 Train Loss 0.0069977767 Test MSE 1.870389792084024e-05 Test RE 0.0031335290801724524\n",
      "131 Train Loss 0.0068607167 Test MSE 1.741757592114621e-05 Test RE 0.0030238589112816933\n",
      "132 Train Loss 0.0067591793 Test MSE 1.8062147776505924e-05 Test RE 0.003079302561308193\n",
      "133 Train Loss 0.0067035095 Test MSE 1.7676823030590964e-05 Test RE 0.0030462796878442714\n",
      "134 Train Loss 0.0065725907 Test MSE 1.828750555788617e-05 Test RE 0.0030984529317004614\n",
      "135 Train Loss 0.006466045 Test MSE 1.696084584222493e-05 Test RE 0.002983949171290494\n",
      "136 Train Loss 0.0063550756 Test MSE 1.660802096599835e-05 Test RE 0.0029527495354836875\n",
      "137 Train Loss 0.0062986296 Test MSE 1.6838260148559118e-05 Test RE 0.002973146266057723\n",
      "138 Train Loss 0.0062087784 Test MSE 1.6583984465369387e-05 Test RE 0.0029506120302208064\n",
      "139 Train Loss 0.006133728 Test MSE 1.6654596639229653e-05 Test RE 0.0029568869945093136\n",
      "140 Train Loss 0.0060894378 Test MSE 1.7563022596110297e-05 Test RE 0.0030364581350045476\n",
      "141 Train Loss 0.0059976503 Test MSE 1.638780128960846e-05 Test RE 0.0029331077153196463\n",
      "142 Train Loss 0.0059215706 Test MSE 1.4595569869098257e-05 Test RE 0.002768077184728694\n",
      "143 Train Loss 0.0058194394 Test MSE 1.5993823321493966e-05 Test RE 0.0028976359072902837\n",
      "144 Train Loss 0.0057497215 Test MSE 1.4731527297614255e-05 Test RE 0.002780939591480172\n",
      "145 Train Loss 0.005653389 Test MSE 1.3303363455033608e-05 Test RE 0.002642703232035842\n",
      "146 Train Loss 0.0055641704 Test MSE 1.3890000788417721e-05 Test RE 0.0027003421960682425\n",
      "147 Train Loss 0.0055346065 Test MSE 1.3669848625485566e-05 Test RE 0.0026788569332542537\n",
      "148 Train Loss 0.0054451628 Test MSE 1.4810938776486094e-05 Test RE 0.0027884249563263036\n",
      "149 Train Loss 0.0053726984 Test MSE 1.4522446748693902e-05 Test RE 0.0027611345097650576\n",
      "150 Train Loss 0.005319865 Test MSE 1.5103620402155663e-05 Test RE 0.0028158414569379895\n",
      "151 Train Loss 0.0052542393 Test MSE 1.5450846844138606e-05 Test RE 0.0028480250933556593\n",
      "152 Train Loss 0.005194119 Test MSE 1.4085161018455972e-05 Test RE 0.002719246484270303\n",
      "153 Train Loss 0.0051457095 Test MSE 1.5114317310834917e-05 Test RE 0.0028168384188205354\n",
      "154 Train Loss 0.0050683105 Test MSE 1.6457673546959494e-05 Test RE 0.0029393539732996818\n",
      "155 Train Loss 0.005006493 Test MSE 1.641119722101542e-05 Test RE 0.0029352006840761024\n",
      "156 Train Loss 0.004951011 Test MSE 1.75456527173291e-05 Test RE 0.003034956230744769\n",
      "157 Train Loss 0.004880567 Test MSE 1.848335450717466e-05 Test RE 0.003115000095339468\n",
      "158 Train Loss 0.0048199696 Test MSE 1.7287188780475294e-05 Test RE 0.0030125194180653553\n",
      "159 Train Loss 0.0047541987 Test MSE 1.7701269240347355e-05 Test RE 0.0030483853904008395\n",
      "160 Train Loss 0.004676627 Test MSE 1.7617835170769115e-05 Test RE 0.003041192696827082\n",
      "161 Train Loss 0.00460809 Test MSE 1.684333979055424e-05 Test RE 0.002973594690647471\n",
      "162 Train Loss 0.0045377025 Test MSE 2.047907325081734e-05 Test RE 0.0032788595749099264\n",
      "163 Train Loss 0.004540007 Test MSE 1.87476224911947e-05 Test RE 0.003137189606778796\n",
      "164 Train Loss 0.004460363 Test MSE 1.615305590403897e-05 Test RE 0.0029120244407582537\n",
      "165 Train Loss 0.0043540713 Test MSE 1.4541744597973206e-05 Test RE 0.0027629684386120514\n",
      "166 Train Loss 0.004268681 Test MSE 1.2753975676281812e-05 Test RE 0.0025875601840925615\n",
      "167 Train Loss 0.0042107035 Test MSE 1.170464483808959e-05 Test RE 0.0024788302521035494\n",
      "168 Train Loss 0.0041482463 Test MSE 9.957939245979034e-06 Test RE 0.0022864010126335235\n",
      "169 Train Loss 0.004093321 Test MSE 9.346012996317374e-06 Test RE 0.002215036351614407\n",
      "170 Train Loss 0.004037651 Test MSE 9.611935795191283e-06 Test RE 0.0022463276260915794\n",
      "171 Train Loss 0.0039911726 Test MSE 9.640941834171589e-06 Test RE 0.0022497144560607095\n",
      "172 Train Loss 0.003921434 Test MSE 8.828230803864204e-06 Test RE 0.0021528040760257004\n",
      "173 Train Loss 0.003869537 Test MSE 1.0058054963779197e-05 Test RE 0.0022978658450270636\n",
      "174 Train Loss 0.0038086018 Test MSE 1.0560854550795537e-05 Test RE 0.0023546003179313307\n",
      "175 Train Loss 0.003790026 Test MSE 1.0709661909891159e-05 Test RE 0.0023711309979204285\n",
      "176 Train Loss 0.0037620347 Test MSE 1.1725218365455735e-05 Test RE 0.0024810078445119087\n",
      "177 Train Loss 0.0037189173 Test MSE 1.179922927729798e-05 Test RE 0.002488825728915618\n",
      "178 Train Loss 0.0036892819 Test MSE 1.1933718530571573e-05 Test RE 0.0025029695304366432\n",
      "179 Train Loss 0.0036782443 Test MSE 1.2346831227989214e-05 Test RE 0.0025459239319416647\n",
      "180 Train Loss 0.0036402182 Test MSE 1.0412714049545057e-05 Test RE 0.0023380276273288984\n",
      "181 Train Loss 0.003594127 Test MSE 9.433791384216206e-06 Test RE 0.0022254139276542645\n",
      "182 Train Loss 0.0035155804 Test MSE 8.326050683136632e-06 Test RE 0.0020906782096119327\n",
      "183 Train Loss 0.003486311 Test MSE 9.64234998579079e-06 Test RE 0.0022498787462016546\n",
      "184 Train Loss 0.0034457599 Test MSE 9.926895680027875e-06 Test RE 0.0022828343386849864\n",
      "185 Train Loss 0.003440396 Test MSE 9.989660101974973e-06 Test RE 0.002290039764046494\n",
      "186 Train Loss 0.0033783708 Test MSE 8.858694112636985e-06 Test RE 0.0021565151852556996\n",
      "187 Train Loss 0.0033354205 Test MSE 8.83591423548778e-06 Test RE 0.0021537406920847015\n",
      "188 Train Loss 0.0032563868 Test MSE 9.001893274274439e-06 Test RE 0.0021738751470949825\n",
      "189 Train Loss 0.0032075485 Test MSE 8.138264120855807e-06 Test RE 0.0020669670707899918\n",
      "190 Train Loss 0.0031856084 Test MSE 8.610738573233954e-06 Test RE 0.0021261204740377015\n",
      "191 Train Loss 0.0031592317 Test MSE 7.813856264424904e-06 Test RE 0.002025351363651311\n",
      "192 Train Loss 0.0031399154 Test MSE 7.496901106685234e-06 Test RE 0.0019838487522093264\n",
      "193 Train Loss 0.003101721 Test MSE 7.233934746652933e-06 Test RE 0.0019487447630738665\n",
      "194 Train Loss 0.0030753126 Test MSE 7.793990334195248e-06 Test RE 0.0020227751008091896\n",
      "195 Train Loss 0.0030602044 Test MSE 8.47785125326259e-06 Test RE 0.0021096507477094233\n",
      "196 Train Loss 0.0030818754 Test MSE 8.63771180425959e-06 Test RE 0.002129447917867303\n",
      "197 Train Loss 0.0029978384 Test MSE 9.512534706991124e-06 Test RE 0.002234682329192848\n",
      "198 Train Loss 0.002934242 Test MSE 9.1655238199407e-06 Test RE 0.0021935438109890065\n",
      "199 Train Loss 0.002906075 Test MSE 9.614031798569398e-06 Test RE 0.002246572532723521\n",
      "200 Train Loss 0.0028528443 Test MSE 8.95476068887308e-06 Test RE 0.0021681766333498517\n",
      "201 Train Loss 0.0027954183 Test MSE 8.17112548339041e-06 Test RE 0.0020711359527953092\n",
      "202 Train Loss 0.0027527846 Test MSE 8.455026593689727e-06 Test RE 0.0021068089596209386\n",
      "203 Train Loss 0.0027262862 Test MSE 8.604256488748788e-06 Test RE 0.0021253200614435573\n",
      "204 Train Loss 0.0027007116 Test MSE 9.3738960083982e-06 Test RE 0.002218338074427576\n",
      "205 Train Loss 0.0026757705 Test MSE 9.681412566153022e-06 Test RE 0.0022544314350920838\n",
      "206 Train Loss 0.002643976 Test MSE 9.85267041456885e-06 Test RE 0.00227428373429049\n",
      "207 Train Loss 0.002669964 Test MSE 1.0319750067403845e-05 Test RE 0.002327567354341221\n",
      "208 Train Loss 0.0026150686 Test MSE 1.005294799157134e-05 Test RE 0.002297282400859382\n",
      "209 Train Loss 0.0025744282 Test MSE 1.0295792270577149e-05 Test RE 0.0023248640045808065\n",
      "210 Train Loss 0.0025935217 Test MSE 8.838550261525004e-06 Test RE 0.002154061931801607\n",
      "211 Train Loss 0.0025484518 Test MSE 7.686085877689068e-06 Test RE 0.002008724071426305\n",
      "212 Train Loss 0.0025045017 Test MSE 7.071672874371982e-06 Test RE 0.0019267650012155858\n",
      "213 Train Loss 0.0024484948 Test MSE 6.961558550279102e-06 Test RE 0.0019117051394310532\n",
      "214 Train Loss 0.0024153204 Test MSE 6.338815035336057e-06 Test RE 0.001824196874700492\n",
      "215 Train Loss 0.0023795418 Test MSE 6.375721152680742e-06 Test RE 0.0018294996255763312\n",
      "216 Train Loss 0.0023512624 Test MSE 7.1618619831163135e-06 Test RE 0.0019390126453768047\n",
      "217 Train Loss 0.0023123997 Test MSE 7.954038215359266e-06 Test RE 0.002043438183298486\n",
      "218 Train Loss 0.0022806711 Test MSE 8.664948974151863e-06 Test RE 0.0021328026537760854\n",
      "219 Train Loss 0.0022387013 Test MSE 9.129274701530263e-06 Test RE 0.0021892018440099084\n",
      "220 Train Loss 0.0021950253 Test MSE 7.748779465854266e-06 Test RE 0.0020168997774998782\n",
      "221 Train Loss 0.002179644 Test MSE 7.79920375163641e-06 Test RE 0.002023451507093942\n",
      "222 Train Loss 0.002164898 Test MSE 8.180742691635164e-06 Test RE 0.002072354431714887\n",
      "223 Train Loss 0.002135335 Test MSE 8.234925619495577e-06 Test RE 0.002079205944085661\n",
      "224 Train Loss 0.0021459146 Test MSE 8.999687008331813e-06 Test RE 0.002173608734215978\n",
      "225 Train Loss 0.0021358635 Test MSE 9.330936653671493e-06 Test RE 0.002213249058713088\n",
      "226 Train Loss 0.0021262122 Test MSE 7.870035692073438e-06 Test RE 0.0020326191768407506\n",
      "227 Train Loss 0.0020996716 Test MSE 8.755374170854392e-06 Test RE 0.002143902462406813\n",
      "228 Train Loss 0.002085482 Test MSE 9.651151275501203e-06 Test RE 0.002250905327797282\n",
      "229 Train Loss 0.0020751788 Test MSE 9.637468461920725e-06 Test RE 0.0022493091637237447\n",
      "230 Train Loss 0.0020568683 Test MSE 1.0090392918437983e-05 Test RE 0.002301556849396321\n",
      "231 Train Loss 0.0020214517 Test MSE 1.01525389934494e-05 Test RE 0.002308633539523367\n",
      "232 Train Loss 0.002002263 Test MSE 8.802421948546315e-06 Test RE 0.0021496549696350406\n",
      "233 Train Loss 0.0019787652 Test MSE 7.910116290213172e-06 Test RE 0.00203778847548516\n",
      "234 Train Loss 0.0019710655 Test MSE 7.664470168856142e-06 Test RE 0.0020058974984447434\n",
      "235 Train Loss 0.0019683302 Test MSE 6.838221881073306e-06 Test RE 0.0018946947939587904\n",
      "236 Train Loss 0.0019436737 Test MSE 5.766014571749432e-06 Test RE 0.0017398248734163092\n",
      "237 Train Loss 0.0019274625 Test MSE 5.171711342369946e-06 Test RE 0.0016477252846309762\n",
      "238 Train Loss 0.0019148642 Test MSE 4.699863054942043e-06 Test RE 0.001570761577603984\n",
      "239 Train Loss 0.0018878039 Test MSE 4.896247939737641e-06 Test RE 0.001603243059642585\n",
      "240 Train Loss 0.0018731938 Test MSE 4.681983989869669e-06 Test RE 0.0015677710108711832\n",
      "241 Train Loss 0.001878929 Test MSE 4.623083356059218e-06 Test RE 0.0015578783060042282\n",
      "242 Train Loss 0.0018676921 Test MSE 4.762035014700283e-06 Test RE 0.0015811168240291882\n",
      "243 Train Loss 0.00186503 Test MSE 5.152699955916577e-06 Test RE 0.001644693949203103\n",
      "244 Train Loss 0.0018510065 Test MSE 4.979818852749583e-06 Test RE 0.0016168675320832298\n",
      "245 Train Loss 0.0018354359 Test MSE 4.19657644073699e-06 Test RE 0.001484277953435018\n",
      "246 Train Loss 0.0018282684 Test MSE 4.105121365003791e-06 Test RE 0.0014680155918931415\n",
      "247 Train Loss 0.0018160158 Test MSE 3.787492301380204e-06 Test RE 0.0014100793319440643\n",
      "248 Train Loss 0.0017963678 Test MSE 3.4333337255957946e-06 Test RE 0.0013425351880689894\n",
      "249 Train Loss 0.0017943333 Test MSE 3.706332143136912e-06 Test RE 0.001394889598057579\n",
      "250 Train Loss 0.0017806257 Test MSE 4.046351450143031e-06 Test RE 0.0014574694766934784\n",
      "251 Train Loss 0.0017715185 Test MSE 3.803621951354381e-06 Test RE 0.0014130786677621172\n",
      "252 Train Loss 0.0017644349 Test MSE 3.896605362881453e-06 Test RE 0.0014302464536950288\n",
      "253 Train Loss 0.0017495289 Test MSE 3.630246213532373e-06 Test RE 0.0013804977660906409\n",
      "254 Train Loss 0.0017454776 Test MSE 3.598541096193427e-06 Test RE 0.0013744561885260847\n",
      "255 Train Loss 0.001740582 Test MSE 3.71285319630847e-06 Test RE 0.0013961161680706917\n",
      "256 Train Loss 0.0017220319 Test MSE 3.827614876871237e-06 Test RE 0.0014175284519290586\n",
      "257 Train Loss 0.001712643 Test MSE 4.257170903288387e-06 Test RE 0.0014949553104611577\n",
      "258 Train Loss 0.0016926747 Test MSE 4.122783752211417e-06 Test RE 0.001471170289119903\n",
      "259 Train Loss 0.0016960521 Test MSE 3.975317094513978e-06 Test RE 0.001444619775886355\n",
      "260 Train Loss 0.0016854343 Test MSE 4.0452734426636e-06 Test RE 0.0014572753181193354\n",
      "261 Train Loss 0.0016924996 Test MSE 3.947073279743027e-06 Test RE 0.0014394787641509204\n",
      "262 Train Loss 0.0016807746 Test MSE 3.679836410555502e-06 Test RE 0.0013898947797695662\n",
      "263 Train Loss 0.0016892682 Test MSE 3.6706292239949514e-06 Test RE 0.0013881548878451012\n",
      "264 Train Loss 0.0016969704 Test MSE 3.7409632919311465e-06 Test RE 0.0014013912160814712\n",
      "265 Train Loss 0.0016909505 Test MSE 3.6751834683758736e-06 Test RE 0.001389015780686852\n",
      "266 Train Loss 0.0016808371 Test MSE 3.6324555128770225e-06 Test RE 0.001380917774643615\n",
      "267 Train Loss 0.0016594846 Test MSE 3.5272295404662614e-06 Test RE 0.0013607693829397775\n",
      "268 Train Loss 0.0016536883 Test MSE 3.5496900214686457e-06 Test RE 0.0013650950206194772\n",
      "269 Train Loss 0.0016402986 Test MSE 3.696252399931005e-06 Test RE 0.0013929915353758445\n",
      "270 Train Loss 0.0016334568 Test MSE 4.035141615320372e-06 Test RE 0.0014554492217168829\n",
      "271 Train Loss 0.0016407121 Test MSE 4.151827749855213e-06 Test RE 0.0014763432110637387\n",
      "272 Train Loss 0.0016330339 Test MSE 4.206905550265645e-06 Test RE 0.001486103470922609\n",
      "273 Train Loss 0.0016187786 Test MSE 4.203971461811542e-06 Test RE 0.00148558514224524\n",
      "274 Train Loss 0.0016075982 Test MSE 4.200775017296806e-06 Test RE 0.0014850202605018108\n",
      "275 Train Loss 0.0016069779 Test MSE 4.351610095091091e-06 Test RE 0.0015114460690891117\n",
      "276 Train Loss 0.0015978992 Test MSE 4.319128107325254e-06 Test RE 0.0015057945136357919\n",
      "277 Train Loss 0.0015850841 Test MSE 4.544565618252291e-06 Test RE 0.0015445922694619708\n",
      "278 Train Loss 0.0015924163 Test MSE 4.114860022192099e-06 Test RE 0.0014697558609867737\n",
      "279 Train Loss 0.0015765732 Test MSE 3.7681580000191064e-06 Test RE 0.0014064756572149462\n",
      "280 Train Loss 0.0015651971 Test MSE 4.099800815490921e-06 Test RE 0.0014670639535141498\n",
      "281 Train Loss 0.0015726441 Test MSE 3.875842234790153e-06 Test RE 0.0014264308176823576\n",
      "282 Train Loss 0.0015493529 Test MSE 3.803042947243863e-06 Test RE 0.0014129711111349561\n",
      "283 Train Loss 0.0015397382 Test MSE 3.997543294227355e-06 Test RE 0.0014486526180443968\n",
      "284 Train Loss 0.0015233876 Test MSE 3.903708748702357e-06 Test RE 0.0014315495066728288\n",
      "285 Train Loss 0.0015145448 Test MSE 3.978741014821452e-06 Test RE 0.0014452417638033328\n",
      "286 Train Loss 0.0015069286 Test MSE 3.845932274304631e-06 Test RE 0.001420916258956499\n",
      "287 Train Loss 0.0015051176 Test MSE 3.7389757941280817e-06 Test RE 0.0014010189012814594\n",
      "288 Train Loss 0.0014872607 Test MSE 3.428797735078378e-06 Test RE 0.0013416480416279246\n",
      "289 Train Loss 0.0014769466 Test MSE 3.288529399588817e-06 Test RE 0.0013139188161745044\n",
      "290 Train Loss 0.0014720012 Test MSE 3.0871591910107515e-06 Test RE 0.0012730550382200048\n",
      "291 Train Loss 0.0014599392 Test MSE 3.229822907004017e-06 Test RE 0.0013021380294755745\n",
      "292 Train Loss 0.001456579 Test MSE 3.2627869170316047e-06 Test RE 0.0013087660593083437\n",
      "293 Train Loss 0.0014348625 Test MSE 2.9370024667473137e-06 Test RE 0.0012417089838697647\n",
      "294 Train Loss 0.0014188581 Test MSE 2.624321113703384e-06 Test RE 0.0011737514854774592\n",
      "295 Train Loss 0.0014096354 Test MSE 2.57412544954029e-06 Test RE 0.0011624720557092774\n",
      "296 Train Loss 0.0014005125 Test MSE 2.803427911860769e-06 Test RE 0.0012131440266482997\n",
      "297 Train Loss 0.001384945 Test MSE 2.5037641482671225e-06 Test RE 0.0011464744374516257\n",
      "298 Train Loss 0.0013704711 Test MSE 2.6096572161470026e-06 Test RE 0.0011704676109588748\n",
      "299 Train Loss 0.0013577864 Test MSE 2.5306237368288536e-06 Test RE 0.0011526075401090145\n",
      "Training time: 231.07\n",
      "KG_tanhALR_medium\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 34373.883 Test MSE 6.290258763443298 Test RE 1.8171966326611186\n",
      "1 Train Loss 10480.662 Test MSE 10.511061352436371 Test RE 2.3490429265411614\n",
      "2 Train Loss 8254.319 Test MSE 10.815399867330976 Test RE 2.382807498180644\n",
      "3 Train Loss 5422.8403 Test MSE 11.770407667386806 Test RE 2.4857841818556663\n",
      "4 Train Loss 2303.4385 Test MSE 16.803026025393002 Test RE 2.97003397717211\n",
      "5 Train Loss 1619.8947 Test MSE 18.847498739318944 Test RE 3.1455350523256915\n",
      "6 Train Loss 1223.7369 Test MSE 19.568264754573622 Test RE 3.205116540861775\n",
      "7 Train Loss 976.177 Test MSE 20.58310694973091 Test RE 3.2871773286083688\n",
      "8 Train Loss 766.7575 Test MSE 22.055881410111876 Test RE 3.4027486992721037\n",
      "9 Train Loss 647.58606 Test MSE 22.238296175080073 Test RE 3.4167910642682138\n",
      "10 Train Loss 567.1011 Test MSE 22.29589066464531 Test RE 3.4212127404163333\n",
      "11 Train Loss 500.55316 Test MSE 22.183911787046434 Test RE 3.41261057679254\n",
      "12 Train Loss 438.91766 Test MSE 21.99970190690069 Test RE 3.398412290896035\n",
      "13 Train Loss 397.55823 Test MSE 21.541981780974698 Test RE 3.3628732200944076\n",
      "14 Train Loss 362.58102 Test MSE 20.397015351148227 Test RE 3.27228392596575\n",
      "15 Train Loss 335.43774 Test MSE 19.266565061272225 Test RE 3.1803126328608324\n",
      "16 Train Loss 331.54407 Test MSE 18.23039607676657 Test RE 3.093611117613358\n",
      "17 Train Loss 322.33615 Test MSE 16.35511596428649 Test RE 2.9301812266262184\n",
      "18 Train Loss 279.3514 Test MSE 14.515609541231008 Test RE 2.760484458422728\n",
      "19 Train Loss 242.04721 Test MSE 12.761526043708615 Test RE 2.5883259899869153\n",
      "20 Train Loss 201.47856 Test MSE 11.012023899856446 Test RE 2.4043696665925487\n",
      "21 Train Loss 167.56786 Test MSE 9.919977676547882 Test RE 2.282038752188306\n",
      "22 Train Loss 122.2856 Test MSE 6.457354982938675 Test RE 1.8411746999332796\n",
      "23 Train Loss 78.74919 Test MSE 2.7444076889640616 Test RE 1.2003060119726132\n",
      "24 Train Loss 46.381264 Test MSE 1.0261256549519426 Test RE 0.7339524771299062\n",
      "25 Train Loss 25.029255 Test MSE 0.3621015447459945 Test RE 0.435996352901976\n",
      "26 Train Loss 13.859057 Test MSE 0.10971466902029972 Test RE 0.2399937966872956\n",
      "27 Train Loss 7.832464 Test MSE 0.08200236849325536 Test RE 0.2074822102886716\n",
      "28 Train Loss 4.915593 Test MSE 0.021884951263105305 Test RE 0.10718659121185044\n",
      "29 Train Loss 3.103497 Test MSE 0.007069453923310502 Test RE 0.060920099186493236\n",
      "30 Train Loss 2.2057078 Test MSE 0.003863802398006636 Test RE 0.04503758777016655\n",
      "31 Train Loss 1.5793172 Test MSE 0.004909163985424014 Test RE 0.050765823720865855\n",
      "32 Train Loss 1.2248459 Test MSE 0.0016543748819530897 Test RE 0.029470305062171943\n",
      "33 Train Loss 0.9911448 Test MSE 0.0013048200658550637 Test RE 0.026172365764957205\n",
      "34 Train Loss 0.80203265 Test MSE 0.0013373965840549795 Test RE 0.026497065081684455\n",
      "35 Train Loss 0.6578753 Test MSE 0.0010432059536678669 Test RE 0.02340198497221397\n",
      "36 Train Loss 0.55663484 Test MSE 0.0014248504822274755 Test RE 0.027349684105351654\n",
      "37 Train Loss 0.4721454 Test MSE 0.0011434181475176994 Test RE 0.024500232630342973\n",
      "38 Train Loss 0.41640747 Test MSE 0.000977875103002248 Test RE 0.02265736297289264\n",
      "39 Train Loss 0.3774095 Test MSE 0.0010053800424325264 Test RE 0.022973797970288527\n",
      "40 Train Loss 0.34154564 Test MSE 0.0010648585903762994 Test RE 0.023643601831468956\n",
      "41 Train Loss 0.3111913 Test MSE 0.0012527238021659227 Test RE 0.025644564739812383\n",
      "42 Train Loss 0.2625117 Test MSE 0.0010463488361826456 Test RE 0.0234372102200872\n",
      "43 Train Loss 0.2402089 Test MSE 0.0008879399519364223 Test RE 0.02159033923510215\n",
      "44 Train Loss 0.21297951 Test MSE 0.0008352348997977279 Test RE 0.02093977370816272\n",
      "45 Train Loss 0.18642777 Test MSE 0.0007484217484184303 Test RE 0.01982169855818341\n",
      "46 Train Loss 0.1710612 Test MSE 0.0006950702977108281 Test RE 0.019102140400314653\n",
      "47 Train Loss 0.16066657 Test MSE 0.00046192680162875153 Test RE 0.015572353301544183\n",
      "48 Train Loss 0.14565927 Test MSE 0.000391690610317266 Test RE 0.014339673004578139\n",
      "49 Train Loss 0.12887734 Test MSE 0.000329766754718948 Test RE 0.013157431049510365\n",
      "50 Train Loss 0.11657798 Test MSE 0.00021574208990593791 Test RE 0.010642290470454238\n",
      "51 Train Loss 0.10705104 Test MSE 0.00022053178552434175 Test RE 0.010759776851044676\n",
      "52 Train Loss 0.097295836 Test MSE 0.00019205426009997188 Test RE 0.010041061802523678\n",
      "53 Train Loss 0.08870214 Test MSE 0.00019222036954409354 Test RE 0.010045403166002765\n",
      "54 Train Loss 0.0830561 Test MSE 0.00019288352901346373 Test RE 0.010062716545500639\n",
      "55 Train Loss 0.07810325 Test MSE 0.000173849404905981 Test RE 0.009553318826383567\n",
      "56 Train Loss 0.07309698 Test MSE 0.00015860673792919487 Test RE 0.00912490778391048\n",
      "57 Train Loss 0.06802026 Test MSE 0.00020504311178822974 Test RE 0.010375051466357848\n",
      "58 Train Loss 0.062819675 Test MSE 0.0002196087450949904 Test RE 0.01073723560337208\n",
      "59 Train Loss 0.060471263 Test MSE 0.0002874861689527564 Test RE 0.012285027851010112\n",
      "60 Train Loss 0.058178477 Test MSE 0.0003075113393660629 Test RE 0.012705689417477763\n",
      "61 Train Loss 0.053016007 Test MSE 0.00022759901255742695 Test RE 0.010930822810581137\n",
      "62 Train Loss 0.05145763 Test MSE 0.00019705313283073606 Test RE 0.010170898951042154\n",
      "63 Train Loss 0.0468463 Test MSE 0.00019310999673110725 Test RE 0.010068622212862898\n",
      "64 Train Loss 0.044807147 Test MSE 0.00018302905159552616 Test RE 0.009802293055536555\n",
      "65 Train Loss 0.041712288 Test MSE 0.00016891225387336578 Test RE 0.009416689405070984\n",
      "66 Train Loss 0.039653458 Test MSE 0.00017852767853588681 Test RE 0.009681005046459938\n",
      "67 Train Loss 0.037067063 Test MSE 0.00019498314579459436 Test RE 0.010117336717364233\n",
      "68 Train Loss 0.035267822 Test MSE 0.00017931349616675537 Test RE 0.009702287884727058\n",
      "69 Train Loss 0.03437732 Test MSE 0.00016891407264838524 Test RE 0.009416740102379674\n",
      "70 Train Loss 0.032688152 Test MSE 0.00018021547190567747 Test RE 0.009726659309748325\n",
      "71 Train Loss 0.030486949 Test MSE 0.0001935396518144704 Test RE 0.010079816949510064\n",
      "72 Train Loss 0.029266916 Test MSE 0.0002011198545744466 Test RE 0.010275314913020112\n",
      "73 Train Loss 0.028747492 Test MSE 0.0002041509915394957 Test RE 0.01035245650300378\n",
      "74 Train Loss 0.027214464 Test MSE 0.00019809204507746948 Test RE 0.010197675436157601\n",
      "75 Train Loss 0.02590362 Test MSE 0.00021566580021870478 Test RE 0.010640408666121879\n",
      "76 Train Loss 0.025150087 Test MSE 0.00021354375345123734 Test RE 0.010587931030739179\n",
      "77 Train Loss 0.024161194 Test MSE 0.0002093180156112693 Test RE 0.010482647260064594\n",
      "78 Train Loss 0.02302074 Test MSE 0.00020839585321557393 Test RE 0.010459530823092108\n",
      "79 Train Loss 0.021833345 Test MSE 0.0001993078567929041 Test RE 0.010228922241655503\n",
      "80 Train Loss 0.020603359 Test MSE 0.00021129028971899415 Test RE 0.010531917220637614\n",
      "81 Train Loss 0.019794472 Test MSE 0.00021876085560609053 Test RE 0.010716487810226704\n",
      "82 Train Loss 0.019168815 Test MSE 0.0002109815873526747 Test RE 0.010524220662079784\n",
      "83 Train Loss 0.01858564 Test MSE 0.00020710343524695416 Test RE 0.010427046708018478\n",
      "84 Train Loss 0.017773602 Test MSE 0.00021514619277633351 Test RE 0.0106275828733319\n",
      "85 Train Loss 0.01687656 Test MSE 0.0001955744599142634 Test RE 0.010132666235156391\n",
      "86 Train Loss 0.01616603 Test MSE 0.00018153632068956046 Test RE 0.009762238916878115\n",
      "87 Train Loss 0.0159132 Test MSE 0.0001748018526144811 Test RE 0.009579452387794401\n",
      "88 Train Loss 0.015590255 Test MSE 0.0001707013887362326 Test RE 0.009466429280229305\n",
      "89 Train Loss 0.014586697 Test MSE 0.00017571984178071004 Test RE 0.009604573169339064\n",
      "90 Train Loss 0.01410941 Test MSE 0.00017342251768810244 Test RE 0.009541582530033782\n",
      "91 Train Loss 0.013839635 Test MSE 0.00017534603203152896 Test RE 0.009594351800790919\n",
      "92 Train Loss 0.013303733 Test MSE 0.00017341566924270081 Test RE 0.009541394129896926\n",
      "93 Train Loss 0.013010454 Test MSE 0.00015986383714440048 Test RE 0.009160997911288953\n",
      "94 Train Loss 0.0126287155 Test MSE 0.00016189240989327868 Test RE 0.009218938368896737\n",
      "95 Train Loss 0.012400838 Test MSE 0.00015214252607632055 Test RE 0.008937025127588323\n",
      "96 Train Loss 0.012069229 Test MSE 0.00015413467130283862 Test RE 0.008995345277208905\n",
      "97 Train Loss 0.011726591 Test MSE 0.0001497576350609912 Test RE 0.00886670285089502\n",
      "98 Train Loss 0.011376993 Test MSE 0.00015618370758970022 Test RE 0.009054939057753354\n",
      "99 Train Loss 0.011078961 Test MSE 0.00014811711487941023 Test RE 0.008818003962456158\n",
      "100 Train Loss 0.010886691 Test MSE 0.0001398544617668785 Test RE 0.008568520315286772\n",
      "101 Train Loss 0.010746627 Test MSE 0.0001364556441934167 Test RE 0.008463761553948984\n",
      "102 Train Loss 0.010570005 Test MSE 0.0001292624224001081 Test RE 0.008237659049233436\n",
      "103 Train Loss 0.010480559 Test MSE 0.00012247200363871342 Test RE 0.008018369753384033\n",
      "104 Train Loss 0.010256537 Test MSE 0.00012065176834305421 Test RE 0.007958560341534207\n",
      "105 Train Loss 0.01013034 Test MSE 0.00011719585888078884 Test RE 0.007843751039584181\n",
      "106 Train Loss 0.009935763 Test MSE 0.00012084381345434011 Test RE 0.007964891765058761\n",
      "107 Train Loss 0.009787176 Test MSE 0.00011641763214294458 Test RE 0.007817664861155434\n",
      "108 Train Loss 0.009713656 Test MSE 0.00012258724140724203 Test RE 0.00802214123483576\n",
      "109 Train Loss 0.009601972 Test MSE 0.00012221258465421622 Test RE 0.008009873035905519\n",
      "110 Train Loss 0.009442482 Test MSE 0.00012499180218684397 Test RE 0.008100436700146115\n",
      "111 Train Loss 0.009214262 Test MSE 0.00012394944486731257 Test RE 0.008066589573095207\n",
      "112 Train Loss 0.009037165 Test MSE 0.00012548535290814492 Test RE 0.008116413897898708\n",
      "113 Train Loss 0.008894065 Test MSE 0.00012346662381345602 Test RE 0.008050863324909598\n",
      "114 Train Loss 0.008636628 Test MSE 0.00012058859514428447 Test RE 0.007956476519843313\n",
      "115 Train Loss 0.008395375 Test MSE 0.00010575220479612877 Test RE 0.007450962591238937\n",
      "116 Train Loss 0.008191129 Test MSE 9.80580808893469e-05 Test RE 0.007174792778089726\n",
      "117 Train Loss 0.008009537 Test MSE 9.831132958501424e-05 Test RE 0.0071840517562392035\n",
      "118 Train Loss 0.007877656 Test MSE 9.582536944748755e-05 Test RE 0.007092640029664041\n",
      "119 Train Loss 0.00772054 Test MSE 9.196585438385547e-05 Test RE 0.0069483385787226905\n",
      "120 Train Loss 0.007467996 Test MSE 8.86893802078283e-05 Test RE 0.006823441579742577\n",
      "121 Train Loss 0.007318391 Test MSE 8.385330749859996e-05 Test RE 0.006634798937150614\n",
      "122 Train Loss 0.007179709 Test MSE 8.361043056070933e-05 Test RE 0.006625183286592857\n",
      "123 Train Loss 0.007057595 Test MSE 7.620433265614545e-05 Test RE 0.006324955870166952\n",
      "124 Train Loss 0.0068957047 Test MSE 7.22171845620579e-05 Test RE 0.006157266400821347\n",
      "125 Train Loss 0.0067739883 Test MSE 7.276838343256884e-05 Test RE 0.00618071945389009\n",
      "126 Train Loss 0.0066855107 Test MSE 6.734651898154235e-05 Test RE 0.005946004643437442\n",
      "127 Train Loss 0.006609968 Test MSE 6.522420741104816e-05 Test RE 0.005851565528597526\n",
      "128 Train Loss 0.00652696 Test MSE 6.650054083312728e-05 Test RE 0.0059085410384098185\n",
      "129 Train Loss 0.006396929 Test MSE 6.566972858014988e-05 Test RE 0.005871516400476649\n",
      "130 Train Loss 0.006257414 Test MSE 6.439703094979386e-05 Test RE 0.0058143422206882655\n",
      "131 Train Loss 0.006096548 Test MSE 5.9419459566260286e-05 Test RE 0.005585113669317324\n",
      "132 Train Loss 0.005933044 Test MSE 5.4026099191793757e-05 Test RE 0.005325611398292079\n",
      "133 Train Loss 0.0057858163 Test MSE 5.960622053638856e-05 Test RE 0.005593884052914025\n",
      "134 Train Loss 0.005691452 Test MSE 5.9276684392755114e-05 Test RE 0.005578399579607181\n",
      "135 Train Loss 0.005554853 Test MSE 5.4445535109432105e-05 Test RE 0.005346244333171597\n",
      "136 Train Loss 0.005431895 Test MSE 5.2509354195579396e-05 Test RE 0.005250322807941705\n",
      "137 Train Loss 0.0052689323 Test MSE 4.696454806978375e-05 Test RE 0.004965382867658797\n",
      "138 Train Loss 0.005169289 Test MSE 4.33898302156347e-05 Test RE 0.004772672597203701\n",
      "139 Train Loss 0.0050536217 Test MSE 4.137046016174278e-05 Test RE 0.004660288934117634\n",
      "140 Train Loss 0.004973599 Test MSE 4.127253368868959e-05 Test RE 0.004654770068258111\n",
      "141 Train Loss 0.004857018 Test MSE 3.801964652875115e-05 Test RE 0.004467573488595367\n",
      "142 Train Loss 0.0048107463 Test MSE 3.724910723801269e-05 Test RE 0.0044220698856267645\n",
      "143 Train Loss 0.0047485037 Test MSE 3.458443955955482e-05 Test RE 0.004260965705820731\n",
      "144 Train Loss 0.0047362465 Test MSE 3.47283800131864e-05 Test RE 0.0042698235694134355\n",
      "145 Train Loss 0.004671766 Test MSE 3.0469443837829376e-05 Test RE 0.00399944686387406\n",
      "146 Train Loss 0.004625844 Test MSE 3.2980618425682435e-05 Test RE 0.004160993765768027\n",
      "147 Train Loss 0.004434295 Test MSE 3.037261897167751e-05 Test RE 0.003993087147502604\n",
      "148 Train Loss 0.004316419 Test MSE 2.576862010971411e-05 Test RE 0.003678012908853494\n",
      "149 Train Loss 0.004195144 Test MSE 2.4146585547209026e-05 Test RE 0.0035603732680636823\n",
      "150 Train Loss 0.0041586896 Test MSE 2.2652097228918553e-05 Test RE 0.0034484336648657223\n",
      "151 Train Loss 0.004083569 Test MSE 2.2644712572065557e-05 Test RE 0.00344787151879079\n",
      "152 Train Loss 0.004025334 Test MSE 2.2305474853582274e-05 Test RE 0.00342194798860154\n",
      "153 Train Loss 0.003956181 Test MSE 2.364945294437106e-05 Test RE 0.0035235319772899667\n",
      "154 Train Loss 0.0038892762 Test MSE 2.2526534934141217e-05 Test RE 0.003438862918780735\n",
      "155 Train Loss 0.0037967686 Test MSE 2.321291904249984e-05 Test RE 0.003490860917351973\n",
      "156 Train Loss 0.0037295716 Test MSE 2.2262889216984044e-05 Test RE 0.003418679834574025\n",
      "157 Train Loss 0.003658149 Test MSE 2.2437508531525004e-05 Test RE 0.003432060881186874\n",
      "158 Train Loss 0.0036142867 Test MSE 2.3036619779890557e-05 Test RE 0.0034775793217959768\n",
      "159 Train Loss 0.003537257 Test MSE 2.413960351089907e-05 Test RE 0.003559858486115961\n",
      "160 Train Loss 0.003487809 Test MSE 2.2254135066713562e-05 Test RE 0.003418007626683564\n",
      "161 Train Loss 0.003426249 Test MSE 2.2005275394890662e-05 Test RE 0.003398842746969339\n",
      "162 Train Loss 0.003365951 Test MSE 2.306020498034088e-05 Test RE 0.0034793590625688767\n",
      "163 Train Loss 0.0033249988 Test MSE 2.3129641253172644e-05 Test RE 0.0034845934508525417\n",
      "164 Train Loss 0.0033061805 Test MSE 2.4578742448749572e-05 Test RE 0.003592092379139789\n",
      "165 Train Loss 0.003247678 Test MSE 2.6608921299888667e-05 Test RE 0.003737500867732755\n",
      "166 Train Loss 0.0031923263 Test MSE 2.67573412102972e-05 Test RE 0.0037479099360930245\n",
      "167 Train Loss 0.003162754 Test MSE 2.6421598234780066e-05 Test RE 0.003724321891898377\n",
      "168 Train Loss 0.0031529996 Test MSE 2.5952031337394863e-05 Test RE 0.0036910790479494525\n",
      "169 Train Loss 0.003080514 Test MSE 2.547525120087317e-05 Test RE 0.0036570163768287214\n",
      "170 Train Loss 0.0030510593 Test MSE 2.6007594557413092e-05 Test RE 0.0036950282297806055\n",
      "171 Train Loss 0.0030147347 Test MSE 2.562325767974189e-05 Test RE 0.0036676242846801024\n",
      "172 Train Loss 0.0029982289 Test MSE 2.6365366447971325e-05 Test RE 0.0037203566355411225\n",
      "173 Train Loss 0.0029442043 Test MSE 2.422260750062438e-05 Test RE 0.003565973517972999\n",
      "174 Train Loss 0.002889244 Test MSE 2.4037091563738173e-05 Test RE 0.003552291744636633\n",
      "175 Train Loss 0.0028451653 Test MSE 2.4236636684633668e-05 Test RE 0.0035670060339196173\n",
      "176 Train Loss 0.0028145364 Test MSE 2.3820393974444853e-05 Test RE 0.003536243300886065\n",
      "177 Train Loss 0.0027763057 Test MSE 2.3608595456314815e-05 Test RE 0.0035204869830079504\n",
      "178 Train Loss 0.0027391608 Test MSE 2.294976607638292e-05 Test RE 0.003471017467756815\n",
      "179 Train Loss 0.0027028802 Test MSE 2.263897890910291e-05 Test RE 0.003447434988967303\n",
      "180 Train Loss 0.0026806411 Test MSE 2.2742731205685302e-05 Test RE 0.0034553255928817484\n",
      "181 Train Loss 0.0026491818 Test MSE 2.300562032752198e-05 Test RE 0.003475238714828583\n",
      "182 Train Loss 0.0026218481 Test MSE 2.3776653908681523e-05 Test RE 0.003532995105548037\n",
      "183 Train Loss 0.0025803263 Test MSE 2.3488605164643823e-05 Test RE 0.0035115291784216037\n",
      "184 Train Loss 0.0025561403 Test MSE 2.2974130886161234e-05 Test RE 0.003472859496247948\n",
      "185 Train Loss 0.0025259398 Test MSE 2.2945074619259398e-05 Test RE 0.0034706626719417295\n",
      "186 Train Loss 0.0025123686 Test MSE 2.2348462634942024e-05 Test RE 0.0034252438418911923\n",
      "187 Train Loss 0.0025005708 Test MSE 2.130150022968137e-05 Test RE 0.0033440500067319703\n",
      "188 Train Loss 0.0024879086 Test MSE 2.1784091880468247e-05 Test RE 0.0033817180665976568\n",
      "189 Train Loss 0.002427068 Test MSE 2.3313072534808755e-05 Test RE 0.0034983835733075988\n",
      "190 Train Loss 0.0023869595 Test MSE 2.4278693684304e-05 Test RE 0.003570099543754931\n",
      "191 Train Loss 0.002360613 Test MSE 2.3828579731189615e-05 Test RE 0.003536850854670696\n",
      "192 Train Loss 0.0023184237 Test MSE 2.2883390949773254e-05 Test RE 0.0034659944089833767\n",
      "193 Train Loss 0.0022765365 Test MSE 2.115331162600217e-05 Test RE 0.0033323978940236975\n",
      "194 Train Loss 0.0022372408 Test MSE 1.9923328826980607e-05 Test RE 0.0032340640672642584\n",
      "195 Train Loss 0.0021874607 Test MSE 1.856340681643348e-05 Test RE 0.0031217384158434202\n",
      "196 Train Loss 0.0021711655 Test MSE 1.8437405579272047e-05 Test RE 0.003111125799144809\n",
      "197 Train Loss 0.0021506522 Test MSE 1.9086202422829536e-05 Test RE 0.0031653914897273355\n",
      "198 Train Loss 0.0021303573 Test MSE 1.963299683575718e-05 Test RE 0.0032104134480827043\n",
      "199 Train Loss 0.0020875738 Test MSE 1.8951825519420863e-05 Test RE 0.0031542287967552874\n",
      "200 Train Loss 0.0020584983 Test MSE 1.8107762166895668e-05 Test RE 0.0030831883655459713\n",
      "201 Train Loss 0.0020110384 Test MSE 1.7324163573753123e-05 Test RE 0.0030157393686147437\n",
      "202 Train Loss 0.0019996979 Test MSE 1.643108883584306e-05 Test RE 0.002936978988222624\n",
      "203 Train Loss 0.0019823832 Test MSE 1.6378034545028938e-05 Test RE 0.0029322335534089764\n",
      "204 Train Loss 0.001957191 Test MSE 1.6568116155674598e-05 Test RE 0.002949200052565106\n",
      "205 Train Loss 0.00195518 Test MSE 1.6154635892388545e-05 Test RE 0.002912166855054771\n",
      "206 Train Loss 0.0019368659 Test MSE 1.5769677231459772e-05 Test RE 0.0028772597463878847\n",
      "207 Train Loss 0.001906639 Test MSE 1.4677757643365157e-05 Test RE 0.0027758597768729543\n",
      "208 Train Loss 0.0018910246 Test MSE 1.5083194823221826e-05 Test RE 0.0028139367927274405\n",
      "209 Train Loss 0.001872379 Test MSE 1.4972016989154293e-05 Test RE 0.002803546884173621\n",
      "210 Train Loss 0.0018481942 Test MSE 1.4922583869579015e-05 Test RE 0.0027989148211796768\n",
      "211 Train Loss 0.0018291734 Test MSE 1.48415561015403e-05 Test RE 0.002791305598753799\n",
      "212 Train Loss 0.0018103358 Test MSE 1.4813208041159865e-05 Test RE 0.002788638563039171\n",
      "213 Train Loss 0.0017858975 Test MSE 1.4444075811728183e-05 Test RE 0.0027536741473469482\n",
      "214 Train Loss 0.0017601649 Test MSE 1.350608488468844e-05 Test RE 0.0026627623344355825\n",
      "215 Train Loss 0.00173596 Test MSE 1.3092935242831073e-05 Test RE 0.002621719217992137\n",
      "216 Train Loss 0.001712676 Test MSE 1.2077270330293149e-05 Test RE 0.002517978754078386\n",
      "217 Train Loss 0.0017019479 Test MSE 1.1849954429083065e-05 Test RE 0.002494169750423681\n",
      "218 Train Loss 0.0016811766 Test MSE 1.2568858996003059e-05 Test RE 0.0025687130654436945\n",
      "219 Train Loss 0.0016630504 Test MSE 1.2899988186290247e-05 Test RE 0.00260232973383523\n",
      "220 Train Loss 0.001658493 Test MSE 1.2864388646138832e-05 Test RE 0.0025987364846126225\n",
      "221 Train Loss 0.0016452597 Test MSE 1.258978897990204e-05 Test RE 0.002570850918999208\n",
      "222 Train Loss 0.0016365809 Test MSE 1.1893884912155569e-05 Test RE 0.0024987887014979934\n",
      "223 Train Loss 0.0016225225 Test MSE 1.1889727009055954e-05 Test RE 0.0024983518959655333\n",
      "224 Train Loss 0.0016113434 Test MSE 1.1786294045682555e-05 Test RE 0.0024874611327796808\n",
      "225 Train Loss 0.001596929 Test MSE 1.1403923693595979e-05 Test RE 0.002446779420124455\n",
      "226 Train Loss 0.0015843648 Test MSE 1.1946173918865926e-05 Test RE 0.002504275381877172\n",
      "227 Train Loss 0.0015639677 Test MSE 1.1575725453658617e-05 Test RE 0.002465141066374743\n",
      "228 Train Loss 0.0015295107 Test MSE 1.0608370759259676e-05 Test RE 0.002359891372489086\n",
      "229 Train Loss 0.0014920697 Test MSE 1.1438897710832406e-05 Test RE 0.0024505284892210053\n",
      "230 Train Loss 0.0014768798 Test MSE 1.1070513619513188e-05 Test RE 0.0024107465444991568\n",
      "231 Train Loss 0.0014618458 Test MSE 1.0638416607363908e-05 Test RE 0.002363230942941922\n",
      "232 Train Loss 0.0014470329 Test MSE 1.0333474257714762e-05 Test RE 0.002329114550912909\n",
      "233 Train Loss 0.001434121 Test MSE 1.0325709323267132e-05 Test RE 0.0023282392973370215\n",
      "234 Train Loss 0.0014073 Test MSE 1.0575458038424329e-05 Test RE 0.002356227719278715\n",
      "235 Train Loss 0.0013905577 Test MSE 1.0469448007437911e-05 Test RE 0.0023443883787208734\n",
      "236 Train Loss 0.0013723285 Test MSE 1.077401563477813e-05 Test RE 0.0023782443209918827\n",
      "237 Train Loss 0.0013884766 Test MSE 1.146691258003516e-05 Test RE 0.0024535274343553304\n",
      "238 Train Loss 0.0013862841 Test MSE 1.0930499302822368e-05 Test RE 0.002395453076605255\n",
      "239 Train Loss 0.0013574453 Test MSE 1.0561619542295385e-05 Test RE 0.002354685595907758\n",
      "240 Train Loss 0.0013403846 Test MSE 1.0262205502047636e-05 Test RE 0.002321068839874068\n",
      "241 Train Loss 0.001313914 Test MSE 9.976559525631994e-06 Test RE 0.0022885376767490507\n",
      "242 Train Loss 0.0012984523 Test MSE 9.94539426227291e-06 Test RE 0.002284960357991898\n",
      "243 Train Loss 0.0012924642 Test MSE 9.560900141066155e-06 Test RE 0.00224035612436813\n",
      "244 Train Loss 0.0012773244 Test MSE 9.168108115652037e-06 Test RE 0.0021938530331590714\n",
      "245 Train Loss 0.0012671971 Test MSE 8.489530342749896e-06 Test RE 0.0021111033752308126\n",
      "246 Train Loss 0.0012576565 Test MSE 7.889614162450357e-06 Test RE 0.00203514590330947\n",
      "247 Train Loss 0.0012538929 Test MSE 7.856740041848195e-06 Test RE 0.002030901496112089\n",
      "248 Train Loss 0.0012389697 Test MSE 7.726872497171549e-06 Test RE 0.0020140467195763016\n",
      "249 Train Loss 0.0012145946 Test MSE 7.589369187579386e-06 Test RE 0.001996045824878241\n",
      "250 Train Loss 0.0011974153 Test MSE 7.2879437828438895e-06 Test RE 0.0019560059638948886\n",
      "251 Train Loss 0.0011869994 Test MSE 7.445521071742333e-06 Test RE 0.0019770389075439445\n",
      "252 Train Loss 0.0011885297 Test MSE 7.4121560496514455e-06 Test RE 0.0019726041599968736\n",
      "253 Train Loss 0.0011705515 Test MSE 7.604762265289084e-06 Test RE 0.001998069031546312\n",
      "254 Train Loss 0.0011561522 Test MSE 7.553662005957144e-06 Test RE 0.001991344696232728\n",
      "255 Train Loss 0.0011399356 Test MSE 7.249804716755565e-06 Test RE 0.0019508811922071434\n",
      "256 Train Loss 0.0011233719 Test MSE 6.401063652470218e-06 Test RE 0.0018331320078269276\n",
      "257 Train Loss 0.0011098735 Test MSE 6.282341836028706e-06 Test RE 0.0018160527096538607\n",
      "258 Train Loss 0.0010978085 Test MSE 5.952831391996138e-06 Test RE 0.0017677850570990555\n",
      "259 Train Loss 0.0010872348 Test MSE 5.809538340356502e-06 Test RE 0.0017463789129662142\n",
      "260 Train Loss 0.0010732859 Test MSE 6.4397246101123586e-06 Test RE 0.001838659522790792\n",
      "261 Train Loss 0.001067595 Test MSE 6.0697450191911224e-06 Test RE 0.0017850603001063595\n",
      "262 Train Loss 0.0010566075 Test MSE 5.90512789741452e-06 Test RE 0.001760687665536173\n",
      "263 Train Loss 0.0010459141 Test MSE 5.717851867374031e-06 Test RE 0.0017325433806371596\n",
      "264 Train Loss 0.0010296023 Test MSE 5.513934514489186e-06 Test RE 0.0017013688205875525\n",
      "265 Train Loss 0.0010281287 Test MSE 5.23016835196453e-06 Test RE 0.0016570114211922535\n",
      "266 Train Loss 0.0010156151 Test MSE 5.479444547427634e-06 Test RE 0.0016960393952516488\n",
      "267 Train Loss 0.0010056881 Test MSE 5.435312230821827e-06 Test RE 0.001689195501616927\n",
      "268 Train Loss 0.0009997359 Test MSE 5.297101638514383e-06 Test RE 0.0016675805486174836\n",
      "269 Train Loss 0.0009918108 Test MSE 5.462448688142924e-06 Test RE 0.001693407008532172\n",
      "270 Train Loss 0.0009796964 Test MSE 5.62546978720249e-06 Test RE 0.0017184902240937935\n",
      "271 Train Loss 0.00096924073 Test MSE 5.630229341371037e-06 Test RE 0.0017192170538779604\n",
      "272 Train Loss 0.00096545304 Test MSE 5.466537117626087e-06 Test RE 0.0016940406144982387\n",
      "273 Train Loss 0.00096540165 Test MSE 5.307201099335801e-06 Test RE 0.0016691694972185208\n",
      "274 Train Loss 0.0009566156 Test MSE 5.567251012629167e-06 Test RE 0.0017095746489815308\n",
      "275 Train Loss 0.0009410341 Test MSE 5.121660898508065e-06 Test RE 0.0016397327772253868\n",
      "276 Train Loss 0.0009303853 Test MSE 5.1224603613661835e-06 Test RE 0.0016398607488274056\n",
      "277 Train Loss 0.0009233438 Test MSE 5.092387713053784e-06 Test RE 0.0016350400626535826\n",
      "278 Train Loss 0.0009173846 Test MSE 5.209264779618244e-06 Test RE 0.0016536967920763406\n",
      "279 Train Loss 0.00091039535 Test MSE 5.256334386347067e-06 Test RE 0.0016611511851418353\n",
      "280 Train Loss 0.00090235507 Test MSE 5.205913083210159e-06 Test RE 0.0016531647034154738\n",
      "281 Train Loss 0.0008986646 Test MSE 5.133838440870702e-06 Test RE 0.001641680979248114\n",
      "282 Train Loss 0.0008928202 Test MSE 4.830256672138507e-06 Test RE 0.001592402211999878\n",
      "283 Train Loss 0.00088585535 Test MSE 4.708215161806147e-06 Test RE 0.001572156654978498\n",
      "284 Train Loss 0.00087671704 Test MSE 4.838161530630452e-06 Test RE 0.0015937046860887275\n",
      "285 Train Loss 0.0008770229 Test MSE 4.399237759589688e-06 Test RE 0.001519694825844938\n",
      "286 Train Loss 0.00087735604 Test MSE 4.4591702110597294e-06 Test RE 0.001530011491553423\n",
      "287 Train Loss 0.0008773364 Test MSE 4.3759607472944025e-06 Test RE 0.0015156690293909342\n",
      "288 Train Loss 0.0008647829 Test MSE 4.5446602429622695e-06 Test RE 0.0015446083497485164\n",
      "289 Train Loss 0.00086016493 Test MSE 4.650572929759311e-06 Test RE 0.001562503134732752\n",
      "290 Train Loss 0.0008568514 Test MSE 4.60104248598746e-06 Test RE 0.0015541602227974803\n",
      "291 Train Loss 0.0008501064 Test MSE 4.497856786042908e-06 Test RE 0.0015366341449014592\n",
      "292 Train Loss 0.0008426835 Test MSE 4.7490759219804374e-06 Test RE 0.0015789639840784447\n",
      "293 Train Loss 0.0008330645 Test MSE 4.841569040883086e-06 Test RE 0.0015942658092731145\n",
      "294 Train Loss 0.0008326571 Test MSE 4.770725667745601e-06 Test RE 0.001582558925373944\n",
      "295 Train Loss 0.0008183053 Test MSE 4.578894143821628e-06 Test RE 0.0015504150283706774\n",
      "296 Train Loss 0.00081428146 Test MSE 4.578894143821628e-06 Test RE 0.0015504150283706774\n",
      "297 Train Loss 0.0008116576 Test MSE 4.601651954997677e-06 Test RE 0.0015542631539407982\n",
      "298 Train Loss 0.00081039756 Test MSE 4.596202619670836e-06 Test RE 0.0015533425921335576\n",
      "299 Train Loss 0.00080919673 Test MSE 4.596202701794419e-06 Test RE 0.0015533426060108891\n",
      "Training time: 161.69\n",
      "KG_tanhALR_medium\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 39551.28 Test MSE 12.80901219490119 Test RE 2.593137151018265\n",
      "1 Train Loss 24740.387 Test MSE 12.714124031910863 Test RE 2.583514417927032\n",
      "2 Train Loss 9636.514 Test MSE 9.744212697441808 Test RE 2.261731492670147\n",
      "3 Train Loss 6621.824 Test MSE 9.911949853810524 Test RE 2.2811151860754255\n",
      "4 Train Loss 1735.4879 Test MSE 4.122663285968786 Test RE 1.4711487954323497\n",
      "5 Train Loss 454.44238 Test MSE 1.8607966187615774 Test RE 0.9883644629282665\n",
      "6 Train Loss 222.6352 Test MSE 0.5559803997665368 Test RE 0.5402532751727039\n",
      "7 Train Loss 99.8752 Test MSE 0.2684151165149987 Test RE 0.3753800198732943\n",
      "8 Train Loss 54.76416 Test MSE 0.08464527843266059 Test RE 0.21079923797501832\n",
      "9 Train Loss 35.137356 Test MSE 0.07168525391464786 Test RE 0.19399144659633072\n",
      "10 Train Loss 22.404114 Test MSE 0.110711921901856 Test RE 0.2410820427107183\n",
      "11 Train Loss 14.503661 Test MSE 0.12346424162517178 Test RE 0.25458819630246965\n",
      "12 Train Loss 11.546392 Test MSE 0.12593757507877942 Test RE 0.2571256076303056\n",
      "13 Train Loss 8.815817 Test MSE 0.0934501785934472 Test RE 0.22149184230790397\n",
      "14 Train Loss 7.2567787 Test MSE 0.080626775074037 Test RE 0.20573458847883125\n",
      "15 Train Loss 5.917762 Test MSE 0.07896010476491964 Test RE 0.20359707088529902\n",
      "16 Train Loss 4.4840894 Test MSE 0.055259512624937904 Test RE 0.17032217436981034\n",
      "17 Train Loss 3.7921987 Test MSE 0.04365982556924258 Test RE 0.1513940007335442\n",
      "18 Train Loss 3.072817 Test MSE 0.02919567482493638 Test RE 0.12380179073976846\n",
      "19 Train Loss 2.5199618 Test MSE 0.02590154716740658 Test RE 0.11660858378205506\n",
      "20 Train Loss 2.0790162 Test MSE 0.019960010815181065 Test RE 0.10236418989167916\n",
      "21 Train Loss 1.6624457 Test MSE 0.011840640734171671 Test RE 0.07884157103931771\n",
      "22 Train Loss 1.3541806 Test MSE 0.010792472522295886 Test RE 0.07527107931683653\n",
      "23 Train Loss 1.1264511 Test MSE 0.006399027700349679 Test RE 0.0579595043305616\n",
      "24 Train Loss 0.9695589 Test MSE 0.006007102270100983 Test RE 0.05615651918259935\n",
      "25 Train Loss 0.8319939 Test MSE 0.005837611345631607 Test RE 0.055358620124214795\n",
      "26 Train Loss 0.700145 Test MSE 0.0030922857852806475 Test RE 0.04029094741744215\n",
      "27 Train Loss 0.6347095 Test MSE 0.003018126419358964 Test RE 0.03980488569663088\n",
      "28 Train Loss 0.57311213 Test MSE 0.0025265036672439877 Test RE 0.03641896791996971\n",
      "29 Train Loss 0.52399015 Test MSE 0.002840244446019011 Test RE 0.038614065353598466\n",
      "30 Train Loss 0.43992156 Test MSE 0.0024757087197526902 Test RE 0.036051010368865606\n",
      "31 Train Loss 0.3671962 Test MSE 0.0018200078015962182 Test RE 0.030910376321731388\n",
      "32 Train Loss 0.34307736 Test MSE 0.001524156905694829 Test RE 0.02828671447439597\n",
      "33 Train Loss 0.31883022 Test MSE 0.001460371226472091 Test RE 0.027688491873711724\n",
      "34 Train Loss 0.2865184 Test MSE 0.0015111978350798832 Test RE 0.028166204557042534\n",
      "35 Train Loss 0.26982528 Test MSE 0.0012720209596512816 Test RE 0.025841326383787798\n",
      "36 Train Loss 0.24502766 Test MSE 0.0012112519853558644 Test RE 0.025216506467812556\n",
      "37 Train Loss 0.2204214 Test MSE 0.000952211745583578 Test RE 0.022358076343699886\n",
      "38 Train Loss 0.20314443 Test MSE 0.0010590878277394436 Test RE 0.02357944919582029\n",
      "39 Train Loss 0.18105853 Test MSE 0.000854859002190906 Test RE 0.021184338746631674\n",
      "40 Train Loss 0.16843542 Test MSE 0.0008108159301590233 Test RE 0.02063140497845286\n",
      "41 Train Loss 0.15699933 Test MSE 0.0006220855844928595 Test RE 0.018071439013982074\n",
      "42 Train Loss 0.14839695 Test MSE 0.0005595425731738278 Test RE 0.01713895093539935\n",
      "43 Train Loss 0.13434257 Test MSE 0.0005178795350632395 Test RE 0.016488533933323134\n",
      "44 Train Loss 0.1238644 Test MSE 0.0005489508946008091 Test RE 0.016975962853111686\n",
      "45 Train Loss 0.11455827 Test MSE 0.0006152809459654964 Test RE 0.01797233067694613\n",
      "46 Train Loss 0.1099533 Test MSE 0.0005877427594102968 Test RE 0.01756553215504627\n",
      "47 Train Loss 0.104384184 Test MSE 0.0005751784383914146 Test RE 0.01737676653994903\n",
      "48 Train Loss 0.100156344 Test MSE 0.0005637268483534815 Test RE 0.017202914357846988\n",
      "49 Train Loss 0.09050256 Test MSE 0.0004920696371561665 Test RE 0.016072408116551574\n",
      "50 Train Loss 0.08611475 Test MSE 0.0005023752179386636 Test RE 0.01623984094718731\n",
      "51 Train Loss 0.076775454 Test MSE 0.0005108666243808448 Test RE 0.016376512948387312\n",
      "52 Train Loss 0.07438535 Test MSE 0.0005027949273102219 Test RE 0.016246623318390736\n",
      "53 Train Loss 0.070600875 Test MSE 0.0004430456766888702 Test RE 0.015250775186909954\n",
      "54 Train Loss 0.064898446 Test MSE 0.00041990529816116366 Test RE 0.014847158500060105\n",
      "55 Train Loss 0.061666243 Test MSE 0.0003980262934555464 Test RE 0.014455181491793213\n",
      "56 Train Loss 0.059183653 Test MSE 0.0004153634835595232 Test RE 0.014766644657844273\n",
      "57 Train Loss 0.054574884 Test MSE 0.00041387856600785144 Test RE 0.014740225770294577\n",
      "58 Train Loss 0.05352342 Test MSE 0.00041752189273830945 Test RE 0.01480496189572398\n",
      "59 Train Loss 0.049854327 Test MSE 0.00039386341638848906 Test RE 0.014379390881133674\n",
      "60 Train Loss 0.047132473 Test MSE 0.00040135194393661067 Test RE 0.014515444950411809\n",
      "61 Train Loss 0.04557842 Test MSE 0.00041183088955839094 Test RE 0.014703716705345985\n",
      "62 Train Loss 0.04403554 Test MSE 0.00042236545283223673 Test RE 0.014890588485671652\n",
      "63 Train Loss 0.042502943 Test MSE 0.0003833219951765824 Test RE 0.01418565970954817\n",
      "64 Train Loss 0.04183006 Test MSE 0.0003956117155494791 Test RE 0.014411269497101682\n",
      "65 Train Loss 0.04065845 Test MSE 0.00038905684824711674 Test RE 0.01429138107741751\n",
      "66 Train Loss 0.038257148 Test MSE 0.0003752623984727516 Test RE 0.014035736056155292\n",
      "67 Train Loss 0.037674647 Test MSE 0.0003335147076951766 Test RE 0.013231989969194816\n",
      "68 Train Loss 0.036357496 Test MSE 0.00033875745662790126 Test RE 0.013335585845220035\n",
      "69 Train Loss 0.035052523 Test MSE 0.00033242937878779955 Test RE 0.013210442547998639\n",
      "70 Train Loss 0.034416758 Test MSE 0.00030699260379055425 Test RE 0.01269496839010261\n",
      "71 Train Loss 0.033671834 Test MSE 0.00031600127869464353 Test RE 0.01287988803289954\n",
      "72 Train Loss 0.03253694 Test MSE 0.00033167764419088917 Test RE 0.013195497468105055\n",
      "73 Train Loss 0.030997556 Test MSE 0.0003112059557333509 Test RE 0.01278178822079676\n",
      "74 Train Loss 0.030021764 Test MSE 0.00031630276442662266 Test RE 0.012886030692742637\n",
      "75 Train Loss 0.029593641 Test MSE 0.00031572057664480815 Test RE 0.012874166198115808\n",
      "76 Train Loss 0.028343447 Test MSE 0.000293111534708902 Test RE 0.012404638783016191\n",
      "77 Train Loss 0.02703276 Test MSE 0.00029882592033012137 Test RE 0.012524973062809204\n",
      "78 Train Loss 0.026308699 Test MSE 0.0002813286835610992 Test RE 0.012152753098440485\n",
      "79 Train Loss 0.025968896 Test MSE 0.000281904705512963 Test RE 0.01216518814927136\n",
      "80 Train Loss 0.025685571 Test MSE 0.00027186704717151606 Test RE 0.011946644838664915\n",
      "81 Train Loss 0.024658818 Test MSE 0.00026692831000068207 Test RE 0.011837636122876527\n",
      "82 Train Loss 0.024029687 Test MSE 0.00025669211347887765 Test RE 0.011608441858374475\n",
      "83 Train Loss 0.023620898 Test MSE 0.00023714954985074737 Test RE 0.011157806356336052\n",
      "84 Train Loss 0.022992458 Test MSE 0.00021731786108985398 Test RE 0.010681085182410606\n",
      "85 Train Loss 0.022353062 Test MSE 0.00024041933369825654 Test RE 0.011234464138056068\n",
      "86 Train Loss 0.02165397 Test MSE 0.00021568853393075894 Test RE 0.010640969463457791\n",
      "87 Train Loss 0.021129726 Test MSE 0.00020922240603743345 Test RE 0.010480252922653786\n",
      "88 Train Loss 0.020361926 Test MSE 0.0001944283818697791 Test RE 0.01010293359699527\n",
      "89 Train Loss 0.01978993 Test MSE 0.0001794065455766533 Test RE 0.009704804915214775\n",
      "90 Train Loss 0.01933294 Test MSE 0.00017314587606923716 Test RE 0.009533969180920407\n",
      "91 Train Loss 0.01874456 Test MSE 0.00016631144964268996 Test RE 0.009343912054602468\n",
      "92 Train Loss 0.018405348 Test MSE 0.0001595112381658372 Test RE 0.009150889491345782\n",
      "93 Train Loss 0.018046621 Test MSE 0.00015914027915959984 Test RE 0.00914024265281973\n",
      "94 Train Loss 0.017556872 Test MSE 0.00016414903263686212 Test RE 0.009282967532436483\n",
      "95 Train Loss 0.017029712 Test MSE 0.00014825911781083447 Test RE 0.00882222995090289\n",
      "96 Train Loss 0.01664376 Test MSE 0.00014611385691304843 Test RE 0.008758169985241607\n",
      "97 Train Loss 0.016196096 Test MSE 0.00014255630455985356 Test RE 0.008650891837186937\n",
      "98 Train Loss 0.015834827 Test MSE 0.000118953993444386 Test RE 0.007902366739024858\n",
      "99 Train Loss 0.01529381 Test MSE 0.0001057765858994272 Test RE 0.007451821449073688\n",
      "100 Train Loss 0.01490386 Test MSE 0.00010822706673359024 Test RE 0.007537643819423232\n",
      "101 Train Loss 0.014524564 Test MSE 0.00011407625111839811 Test RE 0.007738651476892194\n",
      "102 Train Loss 0.014155367 Test MSE 0.00010719166665749635 Test RE 0.0075015011369334895\n",
      "103 Train Loss 0.013906318 Test MSE 0.00010725056982912798 Test RE 0.007503561938566675\n",
      "104 Train Loss 0.013943183 Test MSE 0.00010520691187470756 Test RE 0.007431727965364976\n",
      "105 Train Loss 0.013641429 Test MSE 0.0001076966146285331 Test RE 0.007519149045087479\n",
      "106 Train Loss 0.01345061 Test MSE 0.00010780066302505976 Test RE 0.007522780387316867\n",
      "107 Train Loss 0.0132301105 Test MSE 0.00010371835970773785 Test RE 0.007378965631555589\n",
      "108 Train Loss 0.013050173 Test MSE 0.000102642430020713 Test RE 0.007340592747124608\n",
      "109 Train Loss 0.012784098 Test MSE 0.00010128878277471603 Test RE 0.007292028270276373\n",
      "110 Train Loss 0.0124734575 Test MSE 0.00010458562768487423 Test RE 0.007409751976424654\n",
      "111 Train Loss 0.012324128 Test MSE 9.584016491485626e-05 Test RE 0.007093187561462687\n",
      "112 Train Loss 0.011981202 Test MSE 0.00010494618379581205 Test RE 0.007422513446528728\n",
      "113 Train Loss 0.011859609 Test MSE 9.79256719621946e-05 Test RE 0.007169947040117277\n",
      "114 Train Loss 0.011653325 Test MSE 9.692518000315077e-05 Test RE 0.007133225866819475\n",
      "115 Train Loss 0.011492835 Test MSE 9.336030681015817e-05 Test RE 0.007000818246933545\n",
      "116 Train Loss 0.011338149 Test MSE 9.531205503607184e-05 Test RE 0.0070736177021924924\n",
      "117 Train Loss 0.011095709 Test MSE 0.00010238698726631851 Test RE 0.007331452914264709\n",
      "118 Train Loss 0.010941017 Test MSE 0.00010164336265047347 Test RE 0.007304780657621531\n",
      "119 Train Loss 0.010722122 Test MSE 9.512625548991821e-05 Test RE 0.007066719749519685\n",
      "120 Train Loss 0.010494736 Test MSE 9.509654989113009e-05 Test RE 0.007065616281652624\n",
      "121 Train Loss 0.010266744 Test MSE 9.884327694937632e-05 Test RE 0.007203461431172204\n",
      "122 Train Loss 0.01012228 Test MSE 9.855170621412194e-05 Test RE 0.007192829095850957\n",
      "123 Train Loss 0.010064204 Test MSE 9.745265136442757e-05 Test RE 0.007152609205680735\n",
      "124 Train Loss 0.0099733295 Test MSE 9.037044359254227e-05 Test RE 0.006887805496913724\n",
      "125 Train Loss 0.009763822 Test MSE 9.150324307746813e-05 Test RE 0.006930840603566929\n",
      "126 Train Loss 0.009645451 Test MSE 8.058721024178242e-05 Test RE 0.006504302461136089\n",
      "127 Train Loss 0.009466657 Test MSE 7.176212012686816e-05 Test RE 0.006137836254486675\n",
      "128 Train Loss 0.009244931 Test MSE 6.58144295963544e-05 Test RE 0.00587798168439807\n",
      "129 Train Loss 0.009190583 Test MSE 6.246001796984781e-05 Test RE 0.005726229105293487\n",
      "130 Train Loss 0.00904502 Test MSE 6.199472137233338e-05 Test RE 0.005704860430699071\n",
      "131 Train Loss 0.008898421 Test MSE 5.9971834808831355e-05 Test RE 0.005611013785177811\n",
      "132 Train Loss 0.008876838 Test MSE 6.267532968511672e-05 Test RE 0.005736090321687121\n",
      "133 Train Loss 0.008803447 Test MSE 6.659191898896547e-05 Test RE 0.005912599097424803\n",
      "134 Train Loss 0.00868275 Test MSE 6.646883678263651e-05 Test RE 0.005907132425689621\n",
      "135 Train Loss 0.008533774 Test MSE 6.807007364304813e-05 Test RE 0.005977860524749767\n",
      "136 Train Loss 0.008457787 Test MSE 6.917710330560283e-05 Test RE 0.006026273720300838\n",
      "137 Train Loss 0.008282669 Test MSE 7.299785144585511e-05 Test RE 0.006190456931943184\n",
      "138 Train Loss 0.008180562 Test MSE 7.710106689584812e-05 Test RE 0.0063620614783358245\n",
      "139 Train Loss 0.007979767 Test MSE 7.630809049642456e-05 Test RE 0.006329260353272502\n",
      "140 Train Loss 0.007857271 Test MSE 7.852581270420199e-05 Test RE 0.006420574469939294\n",
      "141 Train Loss 0.007623419 Test MSE 7.48485357092808e-05 Test RE 0.006268437815298087\n",
      "142 Train Loss 0.0074404413 Test MSE 7.662795444806629e-05 Test RE 0.006342511799486882\n",
      "143 Train Loss 0.0072393 Test MSE 8.811456870055615e-05 Test RE 0.006801293671426222\n",
      "144 Train Loss 0.007118117 Test MSE 7.844299259385893e-05 Test RE 0.006417187730281188\n",
      "145 Train Loss 0.006848799 Test MSE 7.303266432668484e-05 Test RE 0.00619193287916122\n",
      "146 Train Loss 0.0067128497 Test MSE 6.80297748140434e-05 Test RE 0.005976090756984949\n",
      "147 Train Loss 0.0065815514 Test MSE 6.670902493790612e-05 Test RE 0.00591779564678656\n",
      "148 Train Loss 0.0064581092 Test MSE 6.957941238041373e-05 Test RE 0.00604377163367998\n",
      "149 Train Loss 0.0063211382 Test MSE 7.63940560092407e-05 Test RE 0.006332824490149549\n",
      "150 Train Loss 0.0062213056 Test MSE 7.26104325900923e-05 Test RE 0.006174007884003695\n",
      "151 Train Loss 0.006149473 Test MSE 7.403836847493147e-05 Test RE 0.006234420447754498\n",
      "152 Train Loss 0.0060559753 Test MSE 6.962236616106141e-05 Test RE 0.006045636860613235\n",
      "153 Train Loss 0.0059985113 Test MSE 6.806121490213824e-05 Test RE 0.0059774715282509\n",
      "154 Train Loss 0.005927049 Test MSE 7.194553971898549e-05 Test RE 0.006145675215832376\n",
      "155 Train Loss 0.0058365706 Test MSE 7.123991211549819e-05 Test RE 0.006115463172235567\n",
      "156 Train Loss 0.0057405885 Test MSE 7.680483963330123e-05 Test RE 0.006349827991681761\n",
      "157 Train Loss 0.0056830575 Test MSE 7.454731566857626e-05 Test RE 0.006255811765886482\n",
      "158 Train Loss 0.0056122225 Test MSE 7.132656368307552e-05 Test RE 0.006119181266588909\n",
      "159 Train Loss 0.0055730934 Test MSE 6.594307376584145e-05 Test RE 0.005883723578131799\n",
      "160 Train Loss 0.0054887393 Test MSE 6.612130852777229e-05 Test RE 0.005891669647039174\n",
      "161 Train Loss 0.005351671 Test MSE 5.457857744667268e-05 Test RE 0.0053527723510677855\n",
      "162 Train Loss 0.005278954 Test MSE 5.868038683109716e-05 Test RE 0.005550270527330334\n",
      "163 Train Loss 0.005253554 Test MSE 5.65259929512862e-05 Test RE 0.005447431372617691\n",
      "164 Train Loss 0.00515879 Test MSE 4.9918787528909536e-05 Test RE 0.005119171529129484\n",
      "165 Train Loss 0.0050487476 Test MSE 4.141292492131729e-05 Test RE 0.00466268010031731\n",
      "166 Train Loss 0.005034579 Test MSE 4.3107315486731024e-05 Test RE 0.004757109592261476\n",
      "167 Train Loss 0.0049926443 Test MSE 3.9767724405819375e-05 Test RE 0.004569124983409361\n",
      "168 Train Loss 0.004915109 Test MSE 3.611830168306057e-05 Test RE 0.004354430148721609\n",
      "169 Train Loss 0.0048306524 Test MSE 3.34965038223703e-05 Test RE 0.0041934107842137615\n",
      "170 Train Loss 0.00475495 Test MSE 3.085682401491856e-05 Test RE 0.004024790502159418\n",
      "171 Train Loss 0.004682588 Test MSE 3.32632850089695e-05 Test RE 0.004178787011230043\n",
      "172 Train Loss 0.0046269004 Test MSE 3.418468594309698e-05 Test RE 0.004236268367288549\n",
      "173 Train Loss 0.0045652385 Test MSE 3.230354369799139e-05 Test RE 0.004118060769799035\n",
      "174 Train Loss 0.0044760127 Test MSE 3.459517793343737e-05 Test RE 0.004261627163577716\n",
      "175 Train Loss 0.0043682135 Test MSE 3.497701413940417e-05 Test RE 0.004285080982484636\n",
      "176 Train Loss 0.004303135 Test MSE 3.636819695361394e-05 Test RE 0.004369467896307912\n",
      "177 Train Loss 0.004252128 Test MSE 3.080168846491311e-05 Test RE 0.004021193109013073\n",
      "178 Train Loss 0.0041735973 Test MSE 2.8340547215117084e-05 Test RE 0.0038571966725873476\n",
      "179 Train Loss 0.0041437303 Test MSE 2.869388490765517e-05 Test RE 0.0038811671211467567\n",
      "180 Train Loss 0.0040774066 Test MSE 2.864861612146866e-05 Test RE 0.003878104359233413\n",
      "181 Train Loss 0.003994656 Test MSE 2.654252254998769e-05 Test RE 0.0037328347561056984\n",
      "182 Train Loss 0.003928107 Test MSE 2.795727438374597e-05 Test RE 0.003831025846845365\n",
      "183 Train Loss 0.00387947 Test MSE 2.8580586310671248e-05 Test RE 0.003873497094548963\n",
      "184 Train Loss 0.0038185192 Test MSE 2.6388105828143492e-05 Test RE 0.0037219606407607507\n",
      "185 Train Loss 0.0038189215 Test MSE 2.584493653753897e-05 Test RE 0.003683455289693132\n",
      "186 Train Loss 0.0037692941 Test MSE 2.5005463079900515e-05 Test RE 0.003623140023261252\n",
      "187 Train Loss 0.003723356 Test MSE 2.4237671071870008e-05 Test RE 0.0035670821506307523\n",
      "188 Train Loss 0.003671662 Test MSE 2.3241889699385342e-05 Test RE 0.0034930386055391843\n",
      "189 Train Loss 0.0036350822 Test MSE 2.2073878657450503e-05 Test RE 0.0034041367105056976\n",
      "190 Train Loss 0.0035814506 Test MSE 2.0193766093279212e-05 Test RE 0.003255939514262836\n",
      "191 Train Loss 0.0035645156 Test MSE 1.9609420045257523e-05 Test RE 0.0032084852151308876\n",
      "192 Train Loss 0.0035382488 Test MSE 1.8847984369925837e-05 Test RE 0.0031455755764896076\n",
      "193 Train Loss 0.0035002674 Test MSE 1.674140314750136e-05 Test RE 0.0029645828711771386\n",
      "194 Train Loss 0.0034815646 Test MSE 1.671807027460074e-05 Test RE 0.002962516247690892\n",
      "195 Train Loss 0.0034538757 Test MSE 1.705092410015594e-05 Test RE 0.0029918624855433777\n",
      "196 Train Loss 0.0034028608 Test MSE 1.8743474315455215e-05 Test RE 0.0031368425138670387\n",
      "197 Train Loss 0.003373231 Test MSE 1.800285816284196e-05 Test RE 0.003074244449408123\n",
      "198 Train Loss 0.0033435286 Test MSE 1.8494516335451645e-05 Test RE 0.003115940504954516\n",
      "199 Train Loss 0.0033054508 Test MSE 1.8651460116419217e-05 Test RE 0.0031291334532514642\n",
      "200 Train Loss 0.0032766794 Test MSE 2.0938371739803777e-05 Test RE 0.003315424333526567\n",
      "201 Train Loss 0.0032287901 Test MSE 2.0850295086282837e-05 Test RE 0.003308443866851285\n",
      "202 Train Loss 0.0032094705 Test MSE 2.1498596711686335e-05 Test RE 0.003359485137644891\n",
      "203 Train Loss 0.0031807558 Test MSE 2.2580027198349713e-05 Test RE 0.003442943517258375\n",
      "204 Train Loss 0.003142461 Test MSE 2.1816457071114585e-05 Test RE 0.0033842292873442425\n",
      "205 Train Loss 0.003124959 Test MSE 2.307953514363882e-05 Test RE 0.0034808170394254444\n",
      "206 Train Loss 0.0031289612 Test MSE 2.333555327520009e-05 Test RE 0.003500069908352468\n",
      "207 Train Loss 0.0030899781 Test MSE 2.401792253531234e-05 Test RE 0.003550875026592529\n",
      "208 Train Loss 0.003062804 Test MSE 2.3800407726736145e-05 Test RE 0.0035347594659439637\n",
      "209 Train Loss 0.0030506134 Test MSE 2.3578538120996924e-05 Test RE 0.00351824521137233\n",
      "210 Train Loss 0.0030458309 Test MSE 2.3743536300309452e-05 Test RE 0.0035305337600644478\n",
      "211 Train Loss 0.0030138053 Test MSE 2.393809927715069e-05 Test RE 0.003544969471896826\n",
      "212 Train Loss 0.0029816288 Test MSE 2.1356735957788184e-05 Test RE 0.0033483828342086657\n",
      "213 Train Loss 0.0029509035 Test MSE 2.0898340375469504e-05 Test RE 0.0033122534934545895\n",
      "214 Train Loss 0.0029090834 Test MSE 2.17678845129347e-05 Test RE 0.0033804598331554714\n",
      "215 Train Loss 0.002869256 Test MSE 2.1995225444532527e-05 Test RE 0.0033980665216954598\n",
      "216 Train Loss 0.0028449649 Test MSE 2.1538541301531985e-05 Test RE 0.003362604666386233\n",
      "217 Train Loss 0.0028124144 Test MSE 2.2153581722439336e-05 Test RE 0.003410276901320072\n",
      "218 Train Loss 0.0027987685 Test MSE 2.1407288859971113e-05 Test RE 0.003352343421159133\n",
      "219 Train Loss 0.0027738656 Test MSE 2.0458470260411727e-05 Test RE 0.003277209810029035\n",
      "220 Train Loss 0.0027267048 Test MSE 1.9998654396135086e-05 Test RE 0.003240171929474058\n",
      "221 Train Loss 0.0027360814 Test MSE 1.8737550047680896e-05 Test RE 0.0031363467422890713\n",
      "222 Train Loss 0.002705816 Test MSE 1.885637917796825e-05 Test RE 0.003146276011160744\n",
      "223 Train Loss 0.002684248 Test MSE 1.8717073342197387e-05 Test RE 0.003134632547965476\n",
      "224 Train Loss 0.0026539834 Test MSE 1.919237988923469e-05 Test RE 0.003174183891459003\n",
      "225 Train Loss 0.002626658 Test MSE 2.001966542338792e-05 Test RE 0.0032418735806786555\n",
      "226 Train Loss 0.0025907462 Test MSE 1.932748461604691e-05 Test RE 0.0031853366296131433\n",
      "227 Train Loss 0.0025666698 Test MSE 1.7938940307757297e-05 Test RE 0.003068782154650816\n",
      "228 Train Loss 0.0025485558 Test MSE 1.7291742289359547e-05 Test RE 0.0030129161462701284\n",
      "229 Train Loss 0.002516018 Test MSE 1.6314644687335766e-05 Test RE 0.002926553565724848\n",
      "230 Train Loss 0.002493004 Test MSE 1.6636016797765888e-05 Test RE 0.0029552371850407686\n",
      "231 Train Loss 0.0024656032 Test MSE 1.6512460018041916e-05 Test RE 0.0029442423627022286\n",
      "232 Train Loss 0.0024380279 Test MSE 1.5952714838454498e-05 Test RE 0.0028939096545447652\n",
      "233 Train Loss 0.0024189583 Test MSE 1.5389449210114572e-05 Test RE 0.0028423608063382925\n",
      "234 Train Loss 0.0023865933 Test MSE 1.4774570456066302e-05 Test RE 0.002784999357728888\n",
      "235 Train Loss 0.0023600147 Test MSE 1.4626476880553167e-05 Test RE 0.0027710064211678956\n",
      "236 Train Loss 0.002340189 Test MSE 1.4417151484404142e-05 Test RE 0.0027511064715867108\n",
      "237 Train Loss 0.002330348 Test MSE 1.4214372602291375e-05 Test RE 0.0027316906450135054\n",
      "238 Train Loss 0.0023159871 Test MSE 1.4366033449657789e-05 Test RE 0.0027462249235666284\n",
      "239 Train Loss 0.0023041328 Test MSE 1.4529181150732614e-05 Test RE 0.00276177463725202\n",
      "240 Train Loss 0.0022952063 Test MSE 1.3877461690654477e-05 Test RE 0.0026991230636706793\n",
      "241 Train Loss 0.0022884808 Test MSE 1.3747833182147054e-05 Test RE 0.0026864873164837255\n",
      "242 Train Loss 0.0022612573 Test MSE 1.3765725443827801e-05 Test RE 0.0026882349266040494\n",
      "243 Train Loss 0.0022409738 Test MSE 1.40055924442009e-05 Test RE 0.0027115549498563213\n",
      "244 Train Loss 0.0022371956 Test MSE 1.4369461553090961e-05 Test RE 0.0027465525638148184\n",
      "245 Train Loss 0.0022184511 Test MSE 1.4017823892088916e-05 Test RE 0.0027127387271624753\n",
      "246 Train Loss 0.0021949518 Test MSE 1.3263016436880616e-05 Test RE 0.002638692736387738\n",
      "247 Train Loss 0.002176674 Test MSE 1.3806837564878155e-05 Test RE 0.0026922462170118795\n",
      "248 Train Loss 0.0021614716 Test MSE 1.3449503967288038e-05 Test RE 0.002657178937780632\n",
      "249 Train Loss 0.0021458582 Test MSE 1.3472098299588081e-05 Test RE 0.002659409949069899\n",
      "250 Train Loss 0.0021301662 Test MSE 1.3244734014140177e-05 Test RE 0.002636873454458393\n",
      "251 Train Loss 0.0021234264 Test MSE 1.29099531462638e-05 Test RE 0.002603334661328058\n",
      "252 Train Loss 0.0021070726 Test MSE 1.3092168996273873e-05 Test RE 0.002621642500560937\n",
      "253 Train Loss 0.0020893435 Test MSE 1.2541892218075228e-05 Test RE 0.002565955969124066\n",
      "254 Train Loss 0.0020743934 Test MSE 1.2381747481647849e-05 Test RE 0.0025495212665847243\n",
      "255 Train Loss 0.0020620227 Test MSE 1.2116199422088039e-05 Test RE 0.0025220336340503685\n",
      "256 Train Loss 0.0020516827 Test MSE 1.2219321427338069e-05 Test RE 0.0025327435156882743\n",
      "257 Train Loss 0.0020449937 Test MSE 1.194016140555416e-05 Test RE 0.0025036451012452323\n",
      "258 Train Loss 0.0020295884 Test MSE 1.2243204289247634e-05 Test RE 0.00253521745158085\n",
      "259 Train Loss 0.0020201704 Test MSE 1.2165337989663754e-05 Test RE 0.0025271426504168723\n",
      "260 Train Loss 0.0020098556 Test MSE 1.255826276728238e-05 Test RE 0.002567630055033172\n",
      "261 Train Loss 0.0019977181 Test MSE 1.2948193855337204e-05 Test RE 0.002607187492908618\n",
      "262 Train Loss 0.0019814058 Test MSE 1.3242617186964909e-05 Test RE 0.002636662728126528\n",
      "263 Train Loss 0.0019713915 Test MSE 1.2337634516707104e-05 Test RE 0.0025449755716447533\n",
      "264 Train Loss 0.0019583034 Test MSE 1.3031316489841378e-05 Test RE 0.002615542696643168\n",
      "265 Train Loss 0.0019368734 Test MSE 1.2357145052421098e-05 Test RE 0.002546987068329036\n",
      "266 Train Loss 0.001919893 Test MSE 1.2033917327666537e-05 Test RE 0.0025134553776996445\n",
      "267 Train Loss 0.0019018985 Test MSE 1.1731551865628189e-05 Test RE 0.0024816778253065556\n",
      "268 Train Loss 0.0018833365 Test MSE 1.144758464840398e-05 Test RE 0.0024514588038595103\n",
      "269 Train Loss 0.0018541374 Test MSE 1.0468947883813028e-05 Test RE 0.0023443323825491583\n",
      "270 Train Loss 0.0018313761 Test MSE 1.046176939551383e-05 Test RE 0.002343528498118907\n",
      "271 Train Loss 0.0018128348 Test MSE 1.1150831612331378e-05 Test RE 0.0024194758773282434\n",
      "272 Train Loss 0.0018018809 Test MSE 1.1799689376757243e-05 Test RE 0.002488874253110812\n",
      "273 Train Loss 0.0017886978 Test MSE 1.2027676433323961e-05 Test RE 0.002512803543251287\n",
      "274 Train Loss 0.0017801732 Test MSE 1.1367559454600777e-05 Test RE 0.002442875223760147\n",
      "275 Train Loss 0.0017722154 Test MSE 1.1189529004508329e-05 Test RE 0.002423670466601865\n",
      "276 Train Loss 0.0017679684 Test MSE 1.1680632231205216e-05 Test RE 0.0024762862305985544\n",
      "277 Train Loss 0.0017467923 Test MSE 1.1762782425249335e-05 Test RE 0.0024849788666243197\n",
      "278 Train Loss 0.0017436051 Test MSE 1.1880510963809719e-05 Test RE 0.002497383438589039\n",
      "279 Train Loss 0.0017331857 Test MSE 1.1922785263453453e-05 Test RE 0.0025018226999188363\n",
      "280 Train Loss 0.0017360683 Test MSE 1.242215315961413e-05 Test RE 0.002553677837750383\n",
      "281 Train Loss 0.0017283163 Test MSE 1.1652469987245878e-05 Test RE 0.0024732992406347114\n",
      "282 Train Loss 0.0017139864 Test MSE 1.2241563667683779e-05 Test RE 0.0025350475829879733\n",
      "283 Train Loss 0.0017005393 Test MSE 1.1836802528232943e-05 Test RE 0.002492785264926591\n",
      "284 Train Loss 0.001686056 Test MSE 1.195633560788584e-05 Test RE 0.002505340252459664\n",
      "285 Train Loss 0.0016783136 Test MSE 1.1768818883920162e-05 Test RE 0.002485616409158104\n",
      "286 Train Loss 0.0016655577 Test MSE 1.2048024263931222e-05 Test RE 0.0025149281636863614\n",
      "287 Train Loss 0.0016527842 Test MSE 1.175651177656552e-05 Test RE 0.0024843164167817626\n",
      "288 Train Loss 0.0016376297 Test MSE 1.1881360321463474e-05 Test RE 0.0024974727080587697\n",
      "289 Train Loss 0.0016279198 Test MSE 1.1486298016865327e-05 Test RE 0.002455600469093366\n",
      "290 Train Loss 0.0016175796 Test MSE 1.139449424137456e-05 Test RE 0.0024457676384991916\n",
      "291 Train Loss 0.0016103901 Test MSE 1.1005777172033993e-05 Test RE 0.0024036876133373486\n",
      "292 Train Loss 0.0016004407 Test MSE 1.1016227800337646e-05 Test RE 0.0024048285634494736\n",
      "293 Train Loss 0.0015963949 Test MSE 1.127874093717717e-05 Test RE 0.002433313011219943\n",
      "294 Train Loss 0.0016020393 Test MSE 1.1655912684467302e-05 Test RE 0.002473664579125364\n",
      "295 Train Loss 0.0015905484 Test MSE 1.1925256607833098e-05 Test RE 0.0025020819742817544\n",
      "296 Train Loss 0.0015804692 Test MSE 1.1711841105509427e-05 Test RE 0.0024795921540931103\n",
      "297 Train Loss 0.0015691852 Test MSE 1.1677461853754355e-05 Test RE 0.002475950148841116\n",
      "298 Train Loss 0.0015635481 Test MSE 1.1705215215504849e-05 Test RE 0.002478890649133415\n",
      "299 Train Loss 0.001552719 Test MSE 1.18173917489744e-05 Test RE 0.0024907405084265972\n",
      "Training time: 116.36\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcba8005c50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.0028849683869890926\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
