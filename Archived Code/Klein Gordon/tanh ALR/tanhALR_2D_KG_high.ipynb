{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"high\"\n",
    "label = \"KG_tanhALR_\" + level\n",
    "\n",
    "x = np.linspace(-2,2,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        self.lambdas = torch.ones((2,),device = device)\n",
    "        self.lambda_alpha = 0.1\n",
    "            \n",
    "\n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "                    \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "    \n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.lambdas[0]*self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.lambdas[1]*self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    def lambda_update(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "        loss_bc1 = self.lambdas[0]*self.loss_BC(xt_BC,y_BC)\n",
    "        loss_bc1.backward()\n",
    "        bc1_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc1_grads.append(param.grad.view(-1))\n",
    "        bc1_grads = torch.cat(bc1_grads)\n",
    "        bc1_grads = torch.mean(torch.abs(bc1_grads))      \n",
    "        \n",
    "        loss_bc2 = self.lambdas[1]*self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_bc2.backward()\n",
    "        bc2_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc2_grads.append(param.grad.view(-1))\n",
    "        bc2_grads = torch.cat(bc2_grads)\n",
    "        bc2_grads = torch.mean(torch.abs(bc2_grads))    \n",
    "    \n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        loss_f.backward()\n",
    "        f_grads = []\n",
    "        for param in self.parameters():\n",
    "            f_grads.append(param.grad.view(-1))   \n",
    "        f_grads = torch.cat(f_grads)\n",
    "        f_grads = torch.max(torch.abs(f_grads))\n",
    "    \n",
    "        self.lambdas[0] = (1.0-self.lambda_alpha)*self.lambdas[0] + self.lambda_alpha*f_grads/bc1_grads\n",
    "        self.lambdas[1] = (1.0-self.lambda_alpha)*self.lambdas[1] + self.lambda_alpha*f_grads/bc2_grads\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    PINN.lambda_update(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_tanhALR_high\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 64361.25 Test MSE 4.26261351533965 Test RE 1.4916737791321055\n",
      "1 Train Loss 46700.184 Test MSE 6.177626553180675 Test RE 1.7957534207408148\n",
      "2 Train Loss 32497.281 Test MSE 5.264384983944716 Test RE 1.6577143529597709\n",
      "3 Train Loss 21226.58 Test MSE 6.644902246091419 Test RE 1.862430928194742\n",
      "4 Train Loss 12781.24 Test MSE 6.823967111254793 Test RE 1.8873582307327823\n",
      "5 Train Loss 5929.088 Test MSE 11.301021319962699 Test RE 2.4288166087191256\n",
      "6 Train Loss 3357.2937 Test MSE 12.058243405994942 Test RE 2.5088685071350225\n",
      "7 Train Loss 2191.9758 Test MSE 14.116818007334857 Test RE 2.714590249525793\n",
      "8 Train Loss 1572.5193 Test MSE 16.218094332985704 Test RE 2.9096167486173283\n",
      "9 Train Loss 1262.0493 Test MSE 15.219012552642946 Test RE 2.818571878184492\n",
      "10 Train Loss 1053.9814 Test MSE 15.34453028419768 Test RE 2.83017099784895\n",
      "11 Train Loss 901.2682 Test MSE 15.614115175376917 Test RE 2.854924096285287\n",
      "12 Train Loss 790.1227 Test MSE 15.338422806261509 Test RE 2.8296077050362927\n",
      "13 Train Loss 698.5609 Test MSE 14.950499700072776 Test RE 2.7935968427410978\n",
      "14 Train Loss 624.01 Test MSE 13.163182345283715 Test RE 2.6212975743989197\n",
      "15 Train Loss 527.73645 Test MSE 11.469388604464553 Test RE 2.446842474378038\n",
      "16 Train Loss 420.81418 Test MSE 9.762504146864362 Test RE 2.257441436992588\n",
      "17 Train Loss 326.8543 Test MSE 9.08326431014569 Test RE 2.177493427206161\n",
      "18 Train Loss 273.2936 Test MSE 8.514252295524443 Test RE 2.108187016953298\n",
      "19 Train Loss 224.96678 Test MSE 7.888145689615218 Test RE 2.0291929205690304\n",
      "20 Train Loss 191.54628 Test MSE 7.504374301004513 Test RE 1.979215669672483\n",
      "21 Train Loss 172.51277 Test MSE 7.1350663337779086 Test RE 1.9299003479385386\n",
      "22 Train Loss 158.18057 Test MSE 6.649480392297502 Test RE 1.8630723983513395\n",
      "23 Train Loss 141.73433 Test MSE 5.9247653764287245 Test RE 1.7586177622469559\n",
      "24 Train Loss 131.83371 Test MSE 5.22320775892422 Test RE 1.651218429718785\n",
      "25 Train Loss 118.4234 Test MSE 4.795522189112793 Test RE 1.5821724912998463\n",
      "26 Train Loss 107.92151 Test MSE 4.055912038871902 Test RE 1.4550574496845472\n",
      "27 Train Loss 94.5972 Test MSE 2.9643491528699455 Test RE 1.2439432118677327\n",
      "28 Train Loss 79.15474 Test MSE 2.3116899123339514 Test RE 1.098501529172749\n",
      "29 Train Loss 65.34243 Test MSE 1.763863846237507 Test RE 0.9595517596773179\n",
      "30 Train Loss 55.34969 Test MSE 1.4352897930656827 Test RE 0.8655769346345386\n",
      "31 Train Loss 47.68416 Test MSE 1.220510669528286 Test RE 0.7981907067796555\n",
      "32 Train Loss 42.688347 Test MSE 1.0834045592413122 Test RE 0.7520231437240064\n",
      "33 Train Loss 38.371525 Test MSE 0.9482445055784428 Test RE 0.7035517447118733\n",
      "34 Train Loss 33.388344 Test MSE 0.7520203748637191 Test RE 0.6265427090421758\n",
      "35 Train Loss 29.173862 Test MSE 0.6672793287539642 Test RE 0.590187099813545\n",
      "36 Train Loss 24.626162 Test MSE 0.5701108750563076 Test RE 0.5455261074180533\n",
      "37 Train Loss 20.19092 Test MSE 0.46353586716368145 Test RE 0.4919008228613068\n",
      "38 Train Loss 16.295113 Test MSE 0.34971276103514093 Test RE 0.42725939078357245\n",
      "39 Train Loss 12.815914 Test MSE 0.3352570206766912 Test RE 0.4183355935288277\n",
      "40 Train Loss 9.957132 Test MSE 0.23806943789886054 Test RE 0.35252319709896757\n",
      "41 Train Loss 7.916664 Test MSE 0.19922488290032492 Test RE 0.32248362498796374\n",
      "42 Train Loss 6.843196 Test MSE 0.179722345831074 Test RE 0.3062928904095484\n",
      "43 Train Loss 5.858749 Test MSE 0.17359816381656376 Test RE 0.30102907251105643\n",
      "44 Train Loss 4.767783 Test MSE 0.16962896611085676 Test RE 0.29756776594124135\n",
      "45 Train Loss 3.950892 Test MSE 0.1353528781761083 Test RE 0.2658089650392112\n",
      "46 Train Loss 3.2301493 Test MSE 0.11144953753421555 Test RE 0.2411987274930361\n",
      "47 Train Loss 2.7344944 Test MSE 0.08121226974304267 Test RE 0.20589542709603134\n",
      "48 Train Loss 2.3724542 Test MSE 0.06072887603309217 Test RE 0.1780465236618403\n",
      "49 Train Loss 2.0257876 Test MSE 0.04843561350677822 Test RE 0.15900774530771114\n",
      "50 Train Loss 1.768804 Test MSE 0.03012158034910764 Test RE 0.12539342178328988\n",
      "51 Train Loss 1.5470837 Test MSE 0.027197646018712805 Test RE 0.11915205457843019\n",
      "52 Train Loss 1.3504264 Test MSE 0.029647754483489733 Test RE 0.12440326528000575\n",
      "53 Train Loss 1.2095101 Test MSE 0.029594832260474675 Test RE 0.12429218371382501\n",
      "54 Train Loss 1.0921544 Test MSE 0.025178738407546617 Test RE 0.11464440371008087\n",
      "55 Train Loss 0.9785444 Test MSE 0.02261468598955652 Test RE 0.10865035704080771\n",
      "56 Train Loss 0.88034314 Test MSE 0.011837934223025105 Test RE 0.0786092835571885\n",
      "57 Train Loss 0.7861417 Test MSE 0.011138863739942625 Test RE 0.07625289252372237\n",
      "58 Train Loss 0.72461367 Test MSE 0.011848883365129901 Test RE 0.07864562880423762\n",
      "59 Train Loss 0.6707875 Test MSE 0.011563558019738462 Test RE 0.07769295122960751\n",
      "60 Train Loss 0.61776805 Test MSE 0.008490360626537515 Test RE 0.06657312529332633\n",
      "61 Train Loss 0.5619924 Test MSE 0.00593295288767516 Test RE 0.055650789094765764\n",
      "62 Train Loss 0.518938 Test MSE 0.006519408816031617 Test RE 0.05833644832469967\n",
      "63 Train Loss 0.4737371 Test MSE 0.0048733938795469224 Test RE 0.05043727720350886\n",
      "64 Train Loss 0.44053602 Test MSE 0.00378388657002436 Test RE 0.04444316008325096\n",
      "65 Train Loss 0.40472 Test MSE 0.0036112054622558544 Test RE 0.04341721640460587\n",
      "66 Train Loss 0.3754672 Test MSE 0.0026511399146821454 Test RE 0.03720079328649011\n",
      "67 Train Loss 0.34647858 Test MSE 0.0023655759871106965 Test RE 0.035140208047758706\n",
      "68 Train Loss 0.32117698 Test MSE 0.002212244073466522 Test RE 0.03398227085114874\n",
      "69 Train Loss 0.30861428 Test MSE 0.0021934390518339886 Test RE 0.03383753068173696\n",
      "70 Train Loss 0.2885108 Test MSE 0.0022709861308991895 Test RE 0.034430483216076516\n",
      "71 Train Loss 0.27108783 Test MSE 0.0025475716588176595 Test RE 0.036466919747630125\n",
      "72 Train Loss 0.25183228 Test MSE 0.0027177539033322335 Test RE 0.037665257510946175\n",
      "73 Train Loss 0.23730904 Test MSE 0.0029544877406917393 Test RE 0.039271453275493924\n",
      "74 Train Loss 0.22508158 Test MSE 0.002765227414912694 Test RE 0.03799280020980005\n",
      "75 Train Loss 0.21935917 Test MSE 0.002953874977494023 Test RE 0.03926738059839077\n",
      "76 Train Loss 0.20887798 Test MSE 0.003297940505593396 Test RE 0.04149132321328397\n",
      "77 Train Loss 0.19801211 Test MSE 0.0027692992140278903 Test RE 0.03802076213125392\n",
      "78 Train Loss 0.19187172 Test MSE 0.002490078198357668 Test RE 0.03605307980027863\n",
      "79 Train Loss 0.1820471 Test MSE 0.0023212362439502436 Test RE 0.03480932072089843\n",
      "80 Train Loss 0.17607431 Test MSE 0.0024164114508399555 Test RE 0.035515776918598266\n",
      "81 Train Loss 0.16679418 Test MSE 0.002276087762174781 Test RE 0.03446913450738348\n",
      "82 Train Loss 0.16085005 Test MSE 0.0023614640179328373 Test RE 0.03510965348087413\n",
      "83 Train Loss 0.15309028 Test MSE 0.0021420333689755535 Test RE 0.03343866981359951\n",
      "84 Train Loss 0.14711924 Test MSE 0.001976905020795523 Test RE 0.03212393800426273\n",
      "85 Train Loss 0.14125617 Test MSE 0.0017718842908670926 Test RE 0.030412600409275844\n",
      "86 Train Loss 0.13340402 Test MSE 0.001968678787104229 Test RE 0.03205703178005842\n",
      "87 Train Loss 0.12619914 Test MSE 0.001759028315752946 Test RE 0.03030206965402264\n",
      "88 Train Loss 0.119386554 Test MSE 0.001563689861683706 Test RE 0.028570062278974493\n",
      "89 Train Loss 0.11381831 Test MSE 0.001493776804105936 Test RE 0.02792407093284835\n",
      "90 Train Loss 0.10957335 Test MSE 0.0014771822978618756 Test RE 0.027768532194832315\n",
      "91 Train Loss 0.1054827 Test MSE 0.0014163164863590606 Test RE 0.02719042727038895\n",
      "92 Train Loss 0.102622695 Test MSE 0.0013674590422598659 Test RE 0.026717329130642047\n",
      "93 Train Loss 0.09909339 Test MSE 0.0013643164313281377 Test RE 0.026686611404300526\n",
      "94 Train Loss 0.09561565 Test MSE 0.0012453284590371195 Test RE 0.025496339498517685\n",
      "95 Train Loss 0.094240844 Test MSE 0.001316626697609851 Test RE 0.026216046909235506\n",
      "96 Train Loss 0.093392804 Test MSE 0.0012896301228541036 Test RE 0.025945883352442068\n",
      "97 Train Loss 0.089410365 Test MSE 0.0012528560774019424 Test RE 0.0255732820718618\n",
      "98 Train Loss 0.08691804 Test MSE 0.001286379008013988 Test RE 0.02591315835833829\n",
      "99 Train Loss 0.0842001 Test MSE 0.0013495296779931704 Test RE 0.026541599815631464\n",
      "100 Train Loss 0.081543885 Test MSE 0.0013631246246564863 Test RE 0.0266749527341624\n",
      "101 Train Loss 0.078807525 Test MSE 0.0013235559897173778 Test RE 0.02628494277042942\n",
      "102 Train Loss 0.074061476 Test MSE 0.001214858581197883 Test RE 0.025182494034223048\n",
      "103 Train Loss 0.07166585 Test MSE 0.00120035331119839 Test RE 0.025031704557160306\n",
      "104 Train Loss 0.06957045 Test MSE 0.0011167605622264805 Test RE 0.02414437185767443\n",
      "105 Train Loss 0.06776797 Test MSE 0.001113612384202671 Test RE 0.024110316023236055\n",
      "106 Train Loss 0.06599435 Test MSE 0.0011587110035153104 Test RE 0.02459367572816298\n",
      "107 Train Loss 0.0637019 Test MSE 0.0011384376372357923 Test RE 0.024377574902879073\n",
      "108 Train Loss 0.06147757 Test MSE 0.001090928125346455 Test RE 0.023863489298805978\n",
      "109 Train Loss 0.05897627 Test MSE 0.0010930928128431569 Test RE 0.02388715327622489\n",
      "110 Train Loss 0.05707827 Test MSE 0.0010476919335076853 Test RE 0.023385824004593273\n",
      "111 Train Loss 0.055375095 Test MSE 0.0009134552260815695 Test RE 0.021836322980028553\n",
      "112 Train Loss 0.054218397 Test MSE 0.0008533004340286158 Test RE 0.021105073072623028\n",
      "113 Train Loss 0.053141437 Test MSE 0.000873030429565735 Test RE 0.02134767426987971\n",
      "114 Train Loss 0.05184392 Test MSE 0.0008116334461071551 Test RE 0.020583339842316445\n",
      "115 Train Loss 0.05058034 Test MSE 0.0008152235031058989 Test RE 0.02062881223470873\n",
      "116 Train Loss 0.049335167 Test MSE 0.0008118381671945687 Test RE 0.020585935581840725\n",
      "117 Train Loss 0.047630906 Test MSE 0.0007420106418649038 Test RE 0.019680718243500647\n",
      "118 Train Loss 0.04654327 Test MSE 0.0007296732257510529 Test RE 0.019516416700325924\n",
      "119 Train Loss 0.04580851 Test MSE 0.0007265234230904511 Test RE 0.019474247587431076\n",
      "120 Train Loss 0.04494702 Test MSE 0.0007252273933458951 Test RE 0.019456869985212864\n",
      "121 Train Loss 0.043765914 Test MSE 0.0007305474186302604 Test RE 0.01952810412758889\n",
      "122 Train Loss 0.042662796 Test MSE 0.000715219638042808 Test RE 0.019322156357605928\n",
      "123 Train Loss 0.0410341 Test MSE 0.000663512192870629 Test RE 0.018610598114831563\n",
      "124 Train Loss 0.03924711 Test MSE 0.0006472132663442369 Test RE 0.018380595693324467\n",
      "125 Train Loss 0.038137466 Test MSE 0.0006186533268260747 Test RE 0.01797047485951427\n",
      "126 Train Loss 0.036910623 Test MSE 0.0006270011272167432 Test RE 0.018091310926251554\n",
      "127 Train Loss 0.03531029 Test MSE 0.0006272050053488098 Test RE 0.018094252007799464\n",
      "128 Train Loss 0.034716986 Test MSE 0.0006245408780213859 Test RE 0.018055782377167554\n",
      "129 Train Loss 0.03394442 Test MSE 0.0005932864993190072 Test RE 0.01759819435571941\n",
      "130 Train Loss 0.032942653 Test MSE 0.0005716134229880338 Test RE 0.017273768151563233\n",
      "131 Train Loss 0.032348156 Test MSE 0.0004994560359906854 Test RE 0.016146727274005623\n",
      "132 Train Loss 0.03175024 Test MSE 0.0004556036730200471 Test RE 0.015421601806022733\n",
      "133 Train Loss 0.03085542 Test MSE 0.00046260283104990175 Test RE 0.015539606599831498\n",
      "134 Train Loss 0.029560093 Test MSE 0.00044575241447042293 Test RE 0.01525396441881257\n",
      "135 Train Loss 0.028964307 Test MSE 0.0004258580950989361 Test RE 0.014909680273892249\n",
      "136 Train Loss 0.02858528 Test MSE 0.0004215684557162633 Test RE 0.014834398122706677\n",
      "137 Train Loss 0.027916698 Test MSE 0.00040482030869494847 Test RE 0.01453673999695078\n",
      "138 Train Loss 0.027407441 Test MSE 0.0003883273138694427 Test RE 0.014237536361489576\n",
      "139 Train Loss 0.026758516 Test MSE 0.0003945101578320002 Test RE 0.014350431892050444\n",
      "140 Train Loss 0.026391022 Test MSE 0.0003760806319418091 Test RE 0.014011233181524496\n",
      "141 Train Loss 0.026122153 Test MSE 0.00037894737430287236 Test RE 0.014064533376167919\n",
      "142 Train Loss 0.025998214 Test MSE 0.00037514570145426 Test RE 0.013993806492409182\n",
      "143 Train Loss 0.025673164 Test MSE 0.0003462158593600267 Test RE 0.01344340727201089\n",
      "144 Train Loss 0.025202172 Test MSE 0.00031966016429722257 Test RE 0.012917549548384824\n",
      "145 Train Loss 0.024886211 Test MSE 0.00028964997177601215 Test RE 0.012296248237656715\n",
      "146 Train Loss 0.024503086 Test MSE 0.00028296345054874876 Test RE 0.012153491127615906\n",
      "147 Train Loss 0.02412519 Test MSE 0.0002699807065756512 Test RE 0.01187140828701625\n",
      "148 Train Loss 0.023810726 Test MSE 0.0002719973020901159 Test RE 0.011915661987791745\n",
      "149 Train Loss 0.023713676 Test MSE 0.00026180132412648296 Test RE 0.01169019609680793\n",
      "150 Train Loss 0.023112077 Test MSE 0.00025960469992032534 Test RE 0.011641049937348453\n",
      "151 Train Loss 0.022831088 Test MSE 0.00026470758223801045 Test RE 0.01175490348260084\n",
      "152 Train Loss 0.02242896 Test MSE 0.0002605565226365478 Test RE 0.011662370965316752\n",
      "153 Train Loss 0.022109658 Test MSE 0.0002656582793907054 Test RE 0.011775993428506595\n",
      "154 Train Loss 0.021778066 Test MSE 0.0002507571172003903 Test RE 0.011440961155546513\n",
      "155 Train Loss 0.021281548 Test MSE 0.00024719623632768126 Test RE 0.011359436913588648\n",
      "156 Train Loss 0.02100579 Test MSE 0.0002469025175923316 Test RE 0.011352686262395169\n",
      "157 Train Loss 0.020507483 Test MSE 0.00024468628880727425 Test RE 0.011301619822606588\n",
      "158 Train Loss 0.020256734 Test MSE 0.0002428702643493092 Test RE 0.011259602262846374\n",
      "159 Train Loss 0.019945085 Test MSE 0.0002374336827908419 Test RE 0.011132867526864234\n",
      "160 Train Loss 0.019788858 Test MSE 0.00022984813963228918 Test RE 0.010953587286271238\n",
      "161 Train Loss 0.019454608 Test MSE 0.00022413993795059427 Test RE 0.0108167178283665\n",
      "162 Train Loss 0.0192278 Test MSE 0.00021632998729013132 Test RE 0.010626597695988537\n",
      "163 Train Loss 0.018910661 Test MSE 0.00020812678656932862 Test RE 0.010423171085786368\n",
      "164 Train Loss 0.018797297 Test MSE 0.0001963444355110786 Test RE 0.010123837736637916\n",
      "165 Train Loss 0.018449247 Test MSE 0.00019100568438178603 Test RE 0.009985251844700397\n",
      "166 Train Loss 0.018160146 Test MSE 0.00018263977192842524 Test RE 0.009764130044415802\n",
      "167 Train Loss 0.017943224 Test MSE 0.00016853272140257225 Test RE 0.009379463414367618\n",
      "168 Train Loss 0.017567461 Test MSE 0.0001601627410817084 Test RE 0.009143587459563077\n",
      "169 Train Loss 0.01734687 Test MSE 0.0001531035403266097 Test RE 0.008939814216404692\n",
      "170 Train Loss 0.017013187 Test MSE 0.00014548513478646776 Test RE 0.008714554439470324\n",
      "171 Train Loss 0.016654467 Test MSE 0.00013721820000852606 Test RE 0.008463338980333515\n",
      "172 Train Loss 0.01632579 Test MSE 0.00013164667052616163 Test RE 0.008289738230492737\n",
      "173 Train Loss 0.015978841 Test MSE 0.00011869626747915343 Test RE 0.007871443963475312\n",
      "174 Train Loss 0.015632676 Test MSE 0.00011373238205034102 Test RE 0.0077050940561208085\n",
      "175 Train Loss 0.015303082 Test MSE 0.00011796910934959517 Test RE 0.007847295867577883\n",
      "176 Train Loss 0.015126839 Test MSE 0.00011664986691483323 Test RE 0.007803294554163123\n",
      "177 Train Loss 0.01487609 Test MSE 0.0001238720686944742 Test RE 0.00804123162741527\n",
      "178 Train Loss 0.014454931 Test MSE 0.0001161367694734217 Test RE 0.007786113810061652\n",
      "179 Train Loss 0.014223054 Test MSE 0.00011578699263076641 Test RE 0.007774379989781691\n",
      "180 Train Loss 0.0139956325 Test MSE 0.00010781279265278747 Test RE 0.0075018957503241845\n",
      "181 Train Loss 0.013794556 Test MSE 0.00010023568126263569 Test RE 0.007233476087730458\n",
      "182 Train Loss 0.013600146 Test MSE 9.646759964638108e-05 Test RE 0.007096212513955002\n",
      "183 Train Loss 0.013430641 Test MSE 9.527149954863137e-05 Test RE 0.007052082387067597\n",
      "184 Train Loss 0.013261892 Test MSE 9.359877232987872e-05 Test RE 0.006989899846997066\n",
      "185 Train Loss 0.013122616 Test MSE 8.814992628450077e-05 Test RE 0.006783391043103509\n",
      "186 Train Loss 0.012965381 Test MSE 8.259184648282323e-05 Test RE 0.006566054220858642\n",
      "187 Train Loss 0.012723316 Test MSE 7.726042545651879e-05 Test RE 0.006350595109149543\n",
      "188 Train Loss 0.012625518 Test MSE 7.494217416850151e-05 Test RE 0.006254592519324361\n",
      "189 Train Loss 0.012572893 Test MSE 7.297507802377596e-05 Test RE 0.006171960826021306\n",
      "190 Train Loss 0.012440445 Test MSE 7.47123161277483e-05 Test RE 0.006244993301833902\n",
      "191 Train Loss 0.012290775 Test MSE 7.534883329952157e-05 Test RE 0.006271539225783841\n",
      "192 Train Loss 0.012139509 Test MSE 7.768605787092913e-05 Test RE 0.0063680639915570155\n",
      "193 Train Loss 0.011989844 Test MSE 7.820181246207421e-05 Test RE 0.006389167682297887\n",
      "194 Train Loss 0.011817541 Test MSE 8.581127467363291e-05 Test RE 0.00669280317855632\n",
      "195 Train Loss 0.011864947 Test MSE 8.019092973532309e-05 Test RE 0.006469913900475168\n",
      "196 Train Loss 0.011726779 Test MSE 7.95078723520534e-05 Test RE 0.00644229996962248\n",
      "197 Train Loss 0.011670776 Test MSE 8.055415854489175e-05 Test RE 0.006484550243789376\n",
      "198 Train Loss 0.011580582 Test MSE 7.492497000512623e-05 Test RE 0.006253874557715553\n",
      "199 Train Loss 0.011440364 Test MSE 7.316994055636626e-05 Test RE 0.00618019570668331\n",
      "200 Train Loss 0.011243291 Test MSE 7.335014157534607e-05 Test RE 0.006187801239190343\n",
      "201 Train Loss 0.0111119235 Test MSE 7.288940522716412e-05 Test RE 0.006168336818730891\n",
      "202 Train Loss 0.010939314 Test MSE 6.817226849249386e-05 Test RE 0.005965402471095103\n",
      "203 Train Loss 0.010811375 Test MSE 6.975933542503177e-05 Test RE 0.00603444098213767\n",
      "204 Train Loss 0.010634609 Test MSE 6.479563883836803e-05 Test RE 0.0058157906501459\n",
      "205 Train Loss 0.010594275 Test MSE 6.126121664879729e-05 Test RE 0.005654948911332128\n",
      "206 Train Loss 0.0104357675 Test MSE 5.839505108032298e-05 Test RE 0.005521078196700961\n",
      "207 Train Loss 0.010272166 Test MSE 5.6889480548543826e-05 Test RE 0.005449439821949414\n",
      "208 Train Loss 0.010155087 Test MSE 5.807560000191073e-05 Test RE 0.005505955912545798\n",
      "209 Train Loss 0.010042839 Test MSE 5.9027004244593964e-05 Test RE 0.005550872449976142\n",
      "210 Train Loss 0.009907174 Test MSE 6.212030045594664e-05 Test RE 0.005694461364224085\n",
      "211 Train Loss 0.0097761955 Test MSE 6.105971277266188e-05 Test RE 0.00564564096126349\n",
      "212 Train Loss 0.009728016 Test MSE 5.8299792624787364e-05 Test RE 0.005516573157050229\n",
      "213 Train Loss 0.009600208 Test MSE 5.820152588906394e-05 Test RE 0.005511921989044014\n",
      "214 Train Loss 0.009466346 Test MSE 5.733451696938708e-05 Test RE 0.005470713303929267\n",
      "215 Train Loss 0.009349598 Test MSE 5.7194897761158825e-05 Test RE 0.005464048189501289\n",
      "216 Train Loss 0.0091182785 Test MSE 5.84397981900047e-05 Test RE 0.005523193144605089\n",
      "217 Train Loss 0.008983352 Test MSE 6.247009582953951e-05 Test RE 0.005710471428834307\n",
      "218 Train Loss 0.008886997 Test MSE 6.385907275272247e-05 Test RE 0.00577360649694794\n",
      "219 Train Loss 0.008809379 Test MSE 6.330298542674979e-05 Test RE 0.0057484131341987935\n",
      "220 Train Loss 0.008703716 Test MSE 6.15729293163948e-05 Test RE 0.005669317566593534\n",
      "221 Train Loss 0.008643411 Test MSE 6.134566365793602e-05 Test RE 0.0056588451697765245\n",
      "222 Train Loss 0.008507958 Test MSE 6.114317219336689e-05 Test RE 0.005649498013680124\n",
      "223 Train Loss 0.008400445 Test MSE 5.988324878986572e-05 Test RE 0.005590987917693972\n",
      "224 Train Loss 0.008317212 Test MSE 5.808339846051543e-05 Test RE 0.005506325573194321\n",
      "225 Train Loss 0.008216426 Test MSE 5.7877890303151814e-05 Test RE 0.005496575820537035\n",
      "226 Train Loss 0.008113782 Test MSE 5.660777038013042e-05 Test RE 0.005435930577336124\n",
      "227 Train Loss 0.008019307 Test MSE 5.6093741343027825e-05 Test RE 0.0054111937048554725\n",
      "228 Train Loss 0.007943022 Test MSE 5.635267881372539e-05 Test RE 0.005423668782333039\n",
      "229 Train Loss 0.007841727 Test MSE 5.406433765656256e-05 Test RE 0.005312406755526213\n",
      "230 Train Loss 0.0077687167 Test MSE 5.254275621024466e-05 Test RE 0.005237117311428312\n",
      "231 Train Loss 0.0076307766 Test MSE 5.139152282513687e-05 Test RE 0.005179425853884824\n",
      "232 Train Loss 0.007573554 Test MSE 5.038521671582668e-05 Test RE 0.00512846554770202\n",
      "233 Train Loss 0.0075227907 Test MSE 4.969989615948746e-05 Test RE 0.005093468416831294\n",
      "234 Train Loss 0.0074281 Test MSE 4.850662939488981e-05 Test RE 0.005031951258527877\n",
      "235 Train Loss 0.0073065795 Test MSE 4.8146759310821544e-05 Test RE 0.005013250516710082\n",
      "236 Train Loss 0.007232082 Test MSE 4.611630016841483e-05 Test RE 0.004906401738382086\n",
      "237 Train Loss 0.007136922 Test MSE 4.405551397059205e-05 Test RE 0.004795523383842815\n",
      "238 Train Loss 0.007038011 Test MSE 4.3114509824495996e-05 Test RE 0.0047440319292802995\n",
      "239 Train Loss 0.0069695613 Test MSE 4.540016318829138e-05 Test RE 0.004868157088482845\n",
      "240 Train Loss 0.0069876555 Test MSE 4.6631925738665624e-05 Test RE 0.004933754690015776\n",
      "241 Train Loss 0.006897303 Test MSE 4.725932745392602e-05 Test RE 0.004966833999626321\n",
      "242 Train Loss 0.0068160137 Test MSE 4.3320483126200035e-05 Test RE 0.0047553503886861295\n",
      "243 Train Loss 0.0066925636 Test MSE 4.000639925866992e-05 Test RE 0.004569835944318736\n",
      "244 Train Loss 0.0066212593 Test MSE 3.599386811202989e-05 Test RE 0.004334611086022385\n",
      "245 Train Loss 0.006553895 Test MSE 3.4206075727010136e-05 Test RE 0.004225591432492051\n",
      "246 Train Loss 0.0065114317 Test MSE 3.456894566733591e-05 Test RE 0.004247945575067196\n",
      "247 Train Loss 0.0064488975 Test MSE 3.4543731151729816e-05 Test RE 0.004246396071220807\n",
      "248 Train Loss 0.006328267 Test MSE 3.6195722154975875e-05 Test RE 0.004346748368717704\n",
      "249 Train Loss 0.006334668 Test MSE 3.7230607186614926e-05 Test RE 0.004408450172486324\n",
      "250 Train Loss 0.006286418 Test MSE 3.43432565023182e-05 Test RE 0.004234056155189295\n",
      "251 Train Loss 0.0061947606 Test MSE 3.226002124334921e-05 Test RE 0.004103630050115746\n",
      "252 Train Loss 0.0060980227 Test MSE 3.3069800324868875e-05 Test RE 0.004154814735481567\n",
      "253 Train Loss 0.0060362522 Test MSE 3.4192346466719566e-05 Test RE 0.0042247433365635596\n",
      "254 Train Loss 0.005949129 Test MSE 3.368398947414378e-05 Test RE 0.004193219901872321\n",
      "255 Train Loss 0.0058786627 Test MSE 3.315236450857543e-05 Test RE 0.004159998090648024\n",
      "256 Train Loss 0.0058151274 Test MSE 3.090568147069215e-05 Test RE 0.004016567214773563\n",
      "257 Train Loss 0.0057456116 Test MSE 2.8708014040179593e-05 Test RE 0.003871127289063133\n",
      "258 Train Loss 0.0056901514 Test MSE 2.918934262800634e-05 Test RE 0.0039034447267248863\n",
      "259 Train Loss 0.0056517706 Test MSE 2.873391879831877e-05 Test RE 0.0038728734565981783\n",
      "260 Train Loss 0.0055720643 Test MSE 2.966866637591109e-05 Test RE 0.003935363827095282\n",
      "261 Train Loss 0.005536612 Test MSE 2.736405435475925e-05 Test RE 0.003779428199060409\n",
      "262 Train Loss 0.005503782 Test MSE 2.5419764389235426e-05 Test RE 0.0036426851671309797\n",
      "263 Train Loss 0.0054319627 Test MSE 2.4819215036880203e-05 Test RE 0.0035993982222102933\n",
      "264 Train Loss 0.005373945 Test MSE 2.559255087792689e-05 Test RE 0.0036550444639836268\n",
      "265 Train Loss 0.005312013 Test MSE 2.409736831398037e-05 Test RE 0.0035466692103274075\n",
      "266 Train Loss 0.0052635074 Test MSE 2.4867703787017536e-05 Test RE 0.0036029125388384745\n",
      "267 Train Loss 0.0052129654 Test MSE 2.292378420444999e-05 Test RE 0.003459226765906299\n",
      "268 Train Loss 0.0052209557 Test MSE 2.0741639385233263e-05 Test RE 0.003290466067554995\n",
      "269 Train Loss 0.0051981397 Test MSE 1.917666683005382e-05 Test RE 0.0031638977409475795\n",
      "270 Train Loss 0.005137887 Test MSE 1.8210521524197668e-05 Test RE 0.0030831671399762523\n",
      "271 Train Loss 0.005074986 Test MSE 1.7045747230804434e-05 Test RE 0.0029829357486837673\n",
      "272 Train Loss 0.0050290567 Test MSE 1.6394320154910333e-05 Test RE 0.0029253819866496295\n",
      "273 Train Loss 0.004984374 Test MSE 1.6436218410540162e-05 Test RE 0.0029291177375179106\n",
      "274 Train Loss 0.00495383 Test MSE 1.6670959407835344e-05 Test RE 0.0029499603173154523\n",
      "275 Train Loss 0.0049113715 Test MSE 1.6285026238252098e-05 Test RE 0.0029156145456846415\n",
      "276 Train Loss 0.004850479 Test MSE 1.5885518096260166e-05 Test RE 0.0028796291997884222\n",
      "277 Train Loss 0.004804802 Test MSE 1.5518386864504444e-05 Test RE 0.0028461590386622063\n",
      "278 Train Loss 0.0047705267 Test MSE 1.5107784934826497e-05 Test RE 0.002808253273615915\n",
      "279 Train Loss 0.004749463 Test MSE 1.462761002670579e-05 Test RE 0.002763265174544138\n",
      "280 Train Loss 0.004706862 Test MSE 1.4218147386154522e-05 Test RE 0.0027243153838902895\n",
      "281 Train Loss 0.004647327 Test MSE 1.3936951350408338e-05 Test RE 0.002697241101106146\n",
      "282 Train Loss 0.0045755864 Test MSE 1.3804353799536043e-05 Test RE 0.0026843795254389764\n",
      "283 Train Loss 0.0045444528 Test MSE 1.3397310739330943e-05 Test RE 0.0026445068249537733\n",
      "284 Train Loss 0.0045068683 Test MSE 1.3325927558504712e-05 Test RE 0.002637452221277098\n",
      "285 Train Loss 0.0044890814 Test MSE 1.3257790146841433e-05 Test RE 0.002630700740904332\n",
      "286 Train Loss 0.00441847 Test MSE 1.5245090988582622e-05 Test RE 0.002820985716954069\n",
      "287 Train Loss 0.0043720193 Test MSE 1.4829970168570397e-05 Test RE 0.002782313196447638\n",
      "288 Train Loss 0.0043280334 Test MSE 1.3986101699450066e-05 Test RE 0.002701992989181856\n",
      "289 Train Loss 0.004302376 Test MSE 1.4019291185363078e-05 Test RE 0.0027051970492241446\n",
      "290 Train Loss 0.004284964 Test MSE 1.3148295666684388e-05 Test RE 0.0026198148989843594\n",
      "291 Train Loss 0.0042767455 Test MSE 1.1484318661506132e-05 Test RE 0.002448434521616159\n",
      "292 Train Loss 0.004237575 Test MSE 1.188475148324108e-05 Test RE 0.0024907545325847553\n",
      "293 Train Loss 0.0042148414 Test MSE 1.1560114377689087e-05 Test RE 0.002456500984009427\n",
      "294 Train Loss 0.004197275 Test MSE 1.143545961139507e-05 Test RE 0.0024432206427234286\n",
      "295 Train Loss 0.004175124 Test MSE 1.08576795847226e-05 Test RE 0.002380698440895419\n",
      "296 Train Loss 0.004147665 Test MSE 1.0777822843148946e-05 Test RE 0.0023719274287644474\n",
      "297 Train Loss 0.00411045 Test MSE 1.0515668763821803e-05 Test RE 0.0023429030931300223\n",
      "298 Train Loss 0.004060315 Test MSE 1.0324223675087691e-05 Test RE 0.0023214780377301923\n",
      "299 Train Loss 0.0040298323 Test MSE 1.0199460474127538e-05 Test RE 0.0023074084383124466\n",
      "Training time: 246.92\n",
      "KG_tanhALR_high\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 51663.527 Test MSE 10.080998007338028 Test RE 2.2939695105726314\n",
      "1 Train Loss 31000.664 Test MSE 11.386376407968067 Test RE 2.4379716165390666\n",
      "2 Train Loss 17262.805 Test MSE 11.156179558845277 Test RE 2.4132017117791587\n",
      "3 Train Loss 6590.406 Test MSE 6.5859743504910835 Test RE 1.8541543927628374\n",
      "4 Train Loss 2333.8855 Test MSE 7.962447425282656 Test RE 2.038727428228177\n",
      "5 Train Loss 1152.5072 Test MSE 9.166785778643066 Test RE 2.1874816473850602\n",
      "6 Train Loss 577.1827 Test MSE 8.906020900448242 Test RE 2.1561438493753466\n",
      "7 Train Loss 373.13593 Test MSE 9.52490396115783 Test RE 2.2298013784434128\n",
      "8 Train Loss 270.4832 Test MSE 10.270677701803265 Test RE 2.315450107670001\n",
      "9 Train Loss 218.93446 Test MSE 10.937556402565548 Test RE 2.38943945005547\n",
      "10 Train Loss 184.48036 Test MSE 10.662280265667901 Test RE 2.3591791640685553\n",
      "11 Train Loss 162.35106 Test MSE 9.977115547273952 Test RE 2.2821194787101335\n",
      "12 Train Loss 142.47688 Test MSE 8.76395637001274 Test RE 2.1388778367953445\n",
      "13 Train Loss 119.49668 Test MSE 6.7654195185987 Test RE 1.8792443054932513\n",
      "14 Train Loss 88.61203 Test MSE 5.20204250173147 Test RE 1.6478695356638087\n",
      "15 Train Loss 63.258606 Test MSE 3.6780260875138366 Test RE 1.3856172441067813\n",
      "16 Train Loss 41.481174 Test MSE 2.375721479079714 Test RE 1.1136113252388187\n",
      "17 Train Loss 31.929365 Test MSE 1.6410333726806392 Test RE 0.9255387013203938\n",
      "18 Train Loss 19.941643 Test MSE 0.8431478486817927 Test RE 0.6634187550759221\n",
      "19 Train Loss 13.290905 Test MSE 0.6339092152339725 Test RE 0.5752404396083506\n",
      "20 Train Loss 10.551343 Test MSE 0.40151075126771746 Test RE 0.45780914777492143\n",
      "21 Train Loss 8.695647 Test MSE 0.3704650469259593 Test RE 0.4397536940679423\n",
      "22 Train Loss 7.0441017 Test MSE 0.2377679068228038 Test RE 0.3522998791056549\n",
      "23 Train Loss 6.007907 Test MSE 0.16864125382486234 Test RE 0.2967001651989124\n",
      "24 Train Loss 4.75744 Test MSE 0.12889982123461602 Test RE 0.2593952591516237\n",
      "25 Train Loss 3.830183 Test MSE 0.107089680017285 Test RE 0.2364338680601494\n",
      "26 Train Loss 3.1788113 Test MSE 0.09463075723272478 Test RE 0.22225525312532965\n",
      "27 Train Loss 2.680387 Test MSE 0.08599327371405636 Test RE 0.2118693421890222\n",
      "28 Train Loss 2.257236 Test MSE 0.07005682118195178 Test RE 0.19123223049279656\n",
      "29 Train Loss 1.9578855 Test MSE 0.05022402133420034 Test RE 0.1619166904380742\n",
      "30 Train Loss 1.6924766 Test MSE 0.03789944499752894 Test RE 0.14065406949715878\n",
      "31 Train Loss 1.535295 Test MSE 0.031521606338907604 Test RE 0.12827441638134093\n",
      "32 Train Loss 1.4138086 Test MSE 0.027751325498919302 Test RE 0.12035877047943626\n",
      "33 Train Loss 1.3191724 Test MSE 0.026142090245849826 Test RE 0.11681699538132953\n",
      "34 Train Loss 1.1822773 Test MSE 0.022095542136080046 Test RE 0.10739602512713381\n",
      "35 Train Loss 1.0291294 Test MSE 0.018384403091583047 Test RE 0.09796267683467615\n",
      "36 Train Loss 0.95862657 Test MSE 0.014871351479486816 Test RE 0.08810713835800721\n",
      "37 Train Loss 0.8651353 Test MSE 0.013843415068749606 Test RE 0.08500754953443564\n",
      "38 Train Loss 0.7723589 Test MSE 0.012318264862237973 Test RE 0.08018823340842943\n",
      "39 Train Loss 0.68417686 Test MSE 0.01097839725622243 Test RE 0.07570165039475525\n",
      "40 Train Loss 0.61655194 Test MSE 0.009316662099728295 Test RE 0.06973744777789435\n",
      "41 Train Loss 0.5748922 Test MSE 0.007651953117786242 Test RE 0.06320072018026947\n",
      "42 Train Loss 0.5283405 Test MSE 0.007070666855580588 Test RE 0.06075276725003706\n",
      "43 Train Loss 0.47310656 Test MSE 0.0068916884799186855 Test RE 0.059978927527661915\n",
      "44 Train Loss 0.43296584 Test MSE 0.006240642582454297 Test RE 0.05707560608631703\n",
      "45 Train Loss 0.41070208 Test MSE 0.004755634120021361 Test RE 0.049824172448653586\n",
      "46 Train Loss 0.38961375 Test MSE 0.0042398624517781276 Test RE 0.04704481452793253\n",
      "47 Train Loss 0.3611235 Test MSE 0.003735751970241344 Test RE 0.04415957591207112\n",
      "48 Train Loss 0.3343224 Test MSE 0.003428152239400707 Test RE 0.042302489557882884\n",
      "49 Train Loss 0.3021873 Test MSE 0.002612802558605936 Test RE 0.036930838924083983\n",
      "50 Train Loss 0.28264216 Test MSE 0.0017511596122654657 Test RE 0.03023421820168492\n",
      "51 Train Loss 0.2559119 Test MSE 0.0014118693732647987 Test RE 0.027147705896178223\n",
      "52 Train Loss 0.24290733 Test MSE 0.0009683534102096042 Test RE 0.0224829254310017\n",
      "53 Train Loss 0.22273675 Test MSE 0.0006303842965737747 Test RE 0.018140053762899396\n",
      "54 Train Loss 0.21021783 Test MSE 0.00076189750005619 Test RE 0.019942708954740464\n",
      "55 Train Loss 0.19287594 Test MSE 0.000917469748645052 Test RE 0.021884254341915058\n",
      "56 Train Loss 0.1805129 Test MSE 0.0007986738227779371 Test RE 0.020418348028260157\n",
      "57 Train Loss 0.17101152 Test MSE 0.0009216751544110965 Test RE 0.02193435242339835\n",
      "58 Train Loss 0.16368008 Test MSE 0.0012076423630396934 Test RE 0.025107591064384503\n",
      "59 Train Loss 0.1544501 Test MSE 0.001323970797512264 Test RE 0.026289061351392813\n",
      "60 Train Loss 0.14916433 Test MSE 0.0013054810121819914 Test RE 0.026104847270146093\n",
      "61 Train Loss 0.13884673 Test MSE 0.0011185467464363945 Test RE 0.024163672801222825\n",
      "62 Train Loss 0.13230316 Test MSE 0.000740369128499491 Test RE 0.01965893685160745\n",
      "63 Train Loss 0.1284947 Test MSE 0.0005320228233024514 Test RE 0.016664834640590667\n",
      "64 Train Loss 0.12016465 Test MSE 0.00020380015616101245 Test RE 0.010314261384405917\n",
      "65 Train Loss 0.11280242 Test MSE 0.0001434078109270389 Test RE 0.008652114938028482\n",
      "66 Train Loss 0.10618432 Test MSE 0.00011415906661156567 Test RE 0.007719533949410289\n",
      "67 Train Loss 0.10121295 Test MSE 0.00011123646021922767 Test RE 0.007620078704678796\n",
      "68 Train Loss 0.09613412 Test MSE 0.00011664355898034452 Test RE 0.007803083566625791\n",
      "69 Train Loss 0.090782546 Test MSE 0.00018571523174992186 Test RE 0.009845995641613915\n",
      "70 Train Loss 0.08773364 Test MSE 0.00014707223908188828 Test RE 0.008761959250460362\n",
      "71 Train Loss 0.08385113 Test MSE 0.00017286377505087676 Test RE 0.00949921841295958\n",
      "72 Train Loss 0.0786458 Test MSE 0.00021624754320447265 Test RE 0.010624572586966969\n",
      "73 Train Loss 0.07592424 Test MSE 0.00028511742621251834 Test RE 0.012199660861014856\n",
      "74 Train Loss 0.07391672 Test MSE 0.00029154045131821475 Test RE 0.012336310383790667\n",
      "75 Train Loss 0.07023941 Test MSE 0.00025503817249672065 Test RE 0.011538210843258009\n",
      "76 Train Loss 0.06666035 Test MSE 0.00023998313625936326 Test RE 0.011192477737931068\n",
      "77 Train Loss 0.06410581 Test MSE 0.0002088084822377111 Test RE 0.01044022708791905\n",
      "78 Train Loss 0.061223004 Test MSE 0.00023770253534449539 Test RE 0.011139168766470128\n",
      "79 Train Loss 0.058451317 Test MSE 0.0002241495888037379 Test RE 0.010816950695013436\n",
      "80 Train Loss 0.05680401 Test MSE 0.0001690647484072549 Test RE 0.009394256374921093\n",
      "81 Train Loss 0.05419951 Test MSE 0.00014036864996476813 Test RE 0.008559944293599445\n",
      "82 Train Loss 0.05149109 Test MSE 0.00012711777544166018 Test RE 0.008145898961275962\n",
      "83 Train Loss 0.048962627 Test MSE 0.00013006925213840658 Test RE 0.00823992385645765\n",
      "84 Train Loss 0.047419857 Test MSE 0.00012753377070790536 Test RE 0.008159216876741126\n",
      "85 Train Loss 0.04614665 Test MSE 0.00011457768028008512 Test RE 0.007733674505718616\n",
      "86 Train Loss 0.04453054 Test MSE 8.159883541172355e-05 Test RE 0.006526462652866794\n",
      "87 Train Loss 0.042818632 Test MSE 7.032774898340602e-05 Test RE 0.0060589760437649515\n",
      "88 Train Loss 0.0409984 Test MSE 5.387773917145729e-05 Test RE 0.005303231170372126\n",
      "89 Train Loss 0.039418105 Test MSE 5.700403881338082e-05 Test RE 0.00545492382710501\n",
      "90 Train Loss 0.03854046 Test MSE 6.042301380522428e-05 Test RE 0.0056161289199315\n",
      "91 Train Loss 0.037443124 Test MSE 6.199535975186958e-05 Test RE 0.005688731931922862\n",
      "92 Train Loss 0.03635199 Test MSE 6.656538481883542e-05 Test RE 0.00589467818873392\n",
      "93 Train Loss 0.035251066 Test MSE 7.040964770918077e-05 Test RE 0.0060625029448980235\n",
      "94 Train Loss 0.03426355 Test MSE 7.260767421780934e-05 Test RE 0.006156404396957543\n",
      "95 Train Loss 0.03343915 Test MSE 7.335121069681864e-05 Test RE 0.006187846334447999\n",
      "96 Train Loss 0.03277955 Test MSE 8.920436340459677e-05 Test RE 0.006823841425881056\n",
      "97 Train Loss 0.032176908 Test MSE 7.517596178303293e-05 Test RE 0.006264340752948078\n",
      "98 Train Loss 0.03165588 Test MSE 5.7837933046141673e-05 Test RE 0.005494678152784021\n",
      "99 Train Loss 0.031193892 Test MSE 6.33779841428884e-05 Test RE 0.005751817365320753\n",
      "100 Train Loss 0.030471755 Test MSE 6.12313584090948e-05 Test RE 0.005653570654353171\n",
      "101 Train Loss 0.02951039 Test MSE 3.8717720722283166e-05 Test RE 0.004495632149610946\n",
      "102 Train Loss 0.028740335 Test MSE 3.587107825341691e-05 Test RE 0.00432721120079341\n",
      "103 Train Loss 0.028161086 Test MSE 3.842565361468748e-05 Test RE 0.004478643651303562\n",
      "104 Train Loss 0.027444484 Test MSE 4.408068360810432e-05 Test RE 0.004796893068810714\n",
      "105 Train Loss 0.02687739 Test MSE 4.549768834585419e-05 Test RE 0.004873382984848541\n",
      "106 Train Loss 0.026475012 Test MSE 4.410978104650865e-05 Test RE 0.00479847601017197\n",
      "107 Train Loss 0.02590481 Test MSE 4.034645214610959e-05 Test RE 0.004589216564563164\n",
      "108 Train Loss 0.025331678 Test MSE 4.0744848166262675e-05 Test RE 0.004611818729950566\n",
      "109 Train Loss 0.02503723 Test MSE 3.756880726498299e-05 Test RE 0.004428427923388533\n",
      "110 Train Loss 0.024484096 Test MSE 3.392316969125777e-05 Test RE 0.004208080985243893\n",
      "111 Train Loss 0.023791797 Test MSE 2.8133834878150154e-05 Test RE 0.003832219213763537\n",
      "112 Train Loss 0.023220181 Test MSE 2.804076935630089e-05 Test RE 0.0038258755546959353\n",
      "113 Train Loss 0.0228454 Test MSE 2.7697078290163207e-05 Test RE 0.003802356704308077\n",
      "114 Train Loss 0.02245496 Test MSE 3.576232047682541e-05 Test RE 0.004320646369860247\n",
      "115 Train Loss 0.02187977 Test MSE 3.339671233094845e-05 Test RE 0.00417530047359737\n",
      "116 Train Loss 0.021430707 Test MSE 3.646851047989718e-05 Test RE 0.004363097213753598\n",
      "117 Train Loss 0.02101855 Test MSE 3.967214740762271e-05 Test RE 0.00455070550455994\n",
      "118 Train Loss 0.02055394 Test MSE 4.247705330071991e-05 Test RE 0.004708830606666394\n",
      "119 Train Loss 0.020003479 Test MSE 3.9240697965073464e-05 Test RE 0.004525892545298379\n",
      "120 Train Loss 0.01938602 Test MSE 3.1751250444437136e-05 Test RE 0.004071142403098081\n",
      "121 Train Loss 0.018836126 Test MSE 2.9446808788300197e-05 Test RE 0.003920622202832108\n",
      "122 Train Loss 0.018409802 Test MSE 2.8806302365821063e-05 Test RE 0.003877748462945886\n",
      "123 Train Loss 0.018110221 Test MSE 2.7944896776137167e-05 Test RE 0.003819329539204651\n",
      "124 Train Loss 0.017945234 Test MSE 2.6128304303612935e-05 Test RE 0.0036931035901187972\n",
      "125 Train Loss 0.01764521 Test MSE 2.4411304808067662e-05 Test RE 0.0035696971593350826\n",
      "126 Train Loss 0.017321877 Test MSE 2.4159610253783738e-05 Test RE 0.0035512466647130143\n",
      "127 Train Loss 0.016997851 Test MSE 3.334032303023396e-05 Test RE 0.004171774052495497\n",
      "128 Train Loss 0.016732777 Test MSE 2.6451778025072788e-05 Test RE 0.003715893956540668\n",
      "129 Train Loss 0.016505472 Test MSE 3.0312066687484396e-05 Test RE 0.0039778064786423085\n",
      "130 Train Loss 0.016216021 Test MSE 2.5864566759107068e-05 Test RE 0.0036744173323967444\n",
      "131 Train Loss 0.015858805 Test MSE 2.6355135942528435e-05 Test RE 0.0037090996999106394\n",
      "132 Train Loss 0.015437412 Test MSE 2.4216786228648067e-05 Test RE 0.0035554463599486207\n",
      "133 Train Loss 0.0150711825 Test MSE 2.9946343987843805e-05 Test RE 0.0039537370401298635\n",
      "134 Train Loss 0.014667152 Test MSE 2.9900465307773e-05 Test RE 0.003950707258520257\n",
      "135 Train Loss 0.014466245 Test MSE 3.177983719253475e-05 Test RE 0.004072974685876037\n",
      "136 Train Loss 0.014312435 Test MSE 2.9314568981246756e-05 Test RE 0.003911808926730835\n",
      "137 Train Loss 0.014033214 Test MSE 3.3227115864302885e-05 Test RE 0.004164685394392345\n",
      "138 Train Loss 0.0138005335 Test MSE 3.199157706794969e-05 Test RE 0.00408652068697564\n",
      "139 Train Loss 0.013634139 Test MSE 3.1810963829867624e-05 Test RE 0.004074968827275867\n",
      "140 Train Loss 0.013311071 Test MSE 3.566475713360762e-05 Test RE 0.004314748757639512\n",
      "141 Train Loss 0.013022007 Test MSE 2.3667251563807433e-05 Test RE 0.003514874236336731\n",
      "142 Train Loss 0.012788697 Test MSE 2.1525549342129364e-05 Test RE 0.003352069378421025\n",
      "143 Train Loss 0.012524657 Test MSE 1.6852809604781623e-05 Test RE 0.0029660060603330586\n",
      "144 Train Loss 0.012249374 Test MSE 1.5411993986814476e-05 Test RE 0.002836385733861865\n",
      "145 Train Loss 0.012036458 Test MSE 1.6053325999432998e-05 Test RE 0.0028947988368814097\n",
      "146 Train Loss 0.011818723 Test MSE 1.5715683833333463e-05 Test RE 0.002864194579231714\n",
      "147 Train Loss 0.011625794 Test MSE 1.461567916402303e-05 Test RE 0.0027621380299672534\n",
      "148 Train Loss 0.011491306 Test MSE 1.8051712262874285e-05 Test RE 0.0030696939488925137\n",
      "149 Train Loss 0.011312622 Test MSE 1.7942605427130682e-05 Test RE 0.003060403079265823\n",
      "150 Train Loss 0.011118599 Test MSE 1.5696087701074908e-05 Test RE 0.0028624083176934877\n",
      "151 Train Loss 0.010944396 Test MSE 1.599482275618453e-05 Test RE 0.0028895192550113667\n",
      "152 Train Loss 0.010666138 Test MSE 1.909082332522473e-05 Test RE 0.0031568082736518396\n",
      "153 Train Loss 0.010400878 Test MSE 1.6020941178849885e-05 Test RE 0.0028918774837428307\n",
      "154 Train Loss 0.01018382 Test MSE 1.4043442150933407e-05 Test RE 0.00270752616154801\n",
      "155 Train Loss 0.009937565 Test MSE 1.2042707910453162e-05 Test RE 0.0025072518090661134\n",
      "156 Train Loss 0.009685554 Test MSE 1.495119742790979e-05 Test RE 0.002793662029443237\n",
      "157 Train Loss 0.009417449 Test MSE 1.5352149573440356e-05 Test RE 0.002830873567912334\n",
      "158 Train Loss 0.009053628 Test MSE 1.5618231275508193e-05 Test RE 0.0028553003705401947\n",
      "159 Train Loss 0.008848395 Test MSE 1.3632916035232274e-05 Test RE 0.0026676586486829054\n",
      "160 Train Loss 0.008663041 Test MSE 1.3746605652986125e-05 Test RE 0.002678758820289597\n",
      "161 Train Loss 0.008462321 Test MSE 2.1689474673430118e-05 Test RE 0.003364808818808219\n",
      "162 Train Loss 0.008284389 Test MSE 2.020641397836662e-05 Test RE 0.0032477343602421343\n",
      "163 Train Loss 0.008155665 Test MSE 1.9811024213098446e-05 Test RE 0.003215802298463781\n",
      "164 Train Loss 0.00805892 Test MSE 1.7269724806567684e-05 Test RE 0.0030024693690441214\n",
      "165 Train Loss 0.007962571 Test MSE 2.227834841817713e-05 Test RE 0.0034101805475943037\n",
      "166 Train Loss 0.007822489 Test MSE 2.449008416623509e-05 Test RE 0.003575452524193817\n",
      "167 Train Loss 0.0077440185 Test MSE 2.1700096080416632e-05 Test RE 0.00336563259693398\n",
      "168 Train Loss 0.00758173 Test MSE 1.5861984326926133e-05 Test RE 0.0028774953805873363\n",
      "169 Train Loss 0.00739306 Test MSE 1.3197192622278932e-05 Test RE 0.002624681769143005\n",
      "170 Train Loss 0.007259193 Test MSE 1.2814633530086335e-05 Test RE 0.002586359984227656\n",
      "171 Train Loss 0.007132631 Test MSE 1.2670249277580776e-05 Test RE 0.002571748271340193\n",
      "172 Train Loss 0.0070013655 Test MSE 1.3150606501594236e-05 Test RE 0.0026200451072906053\n",
      "173 Train Loss 0.006878958 Test MSE 1.348007556348888e-05 Test RE 0.002652662758411783\n",
      "174 Train Loss 0.0068136174 Test MSE 1.3719699335984242e-05 Test RE 0.0026761359605509244\n",
      "175 Train Loss 0.0067096506 Test MSE 1.5704107061556646e-05 Test RE 0.00286313944742978\n",
      "176 Train Loss 0.006626741 Test MSE 1.7223490579250997e-05 Test RE 0.0029984475943196196\n",
      "177 Train Loss 0.0065052137 Test MSE 1.689860013710973e-05 Test RE 0.002970032773665711\n",
      "178 Train Loss 0.0063987817 Test MSE 1.6752984102185153e-05 Test RE 0.002957208631040606\n",
      "179 Train Loss 0.0062432885 Test MSE 1.632981077572879e-05 Test RE 0.0029196208272477832\n",
      "180 Train Loss 0.006150073 Test MSE 1.4602684354268704e-05 Test RE 0.0027609098475617493\n",
      "181 Train Loss 0.00605 Test MSE 1.4536192345664511e-05 Test RE 0.0027546168985739306\n",
      "182 Train Loss 0.005941363 Test MSE 1.4136408116241341e-05 Test RE 0.0027164731342535194\n",
      "183 Train Loss 0.005825166 Test MSE 1.4569292613220865e-05 Test RE 0.0027577513751852025\n",
      "184 Train Loss 0.0057381005 Test MSE 1.6486471389485772e-05 Test RE 0.0029335921411813804\n",
      "185 Train Loss 0.0056198533 Test MSE 1.740334478180675e-05 Test RE 0.003014062398160506\n",
      "186 Train Loss 0.0054606088 Test MSE 1.468410717826048e-05 Test RE 0.0027685963994227977\n",
      "187 Train Loss 0.0053642695 Test MSE 1.2871220217290688e-05 Test RE 0.0025920641010218565\n",
      "188 Train Loss 0.0052728346 Test MSE 1.4170429732139728e-05 Test RE 0.00271973999194181\n",
      "189 Train Loss 0.0052027013 Test MSE 1.4911920895048467e-05 Test RE 0.0027899901658521306\n",
      "190 Train Loss 0.0051336475 Test MSE 1.509771241833893e-05 Test RE 0.0028073169717766355\n",
      "191 Train Loss 0.0050564976 Test MSE 1.2784402455134189e-05 Test RE 0.002583307434557521\n",
      "192 Train Loss 0.0049973074 Test MSE 1.2467115764582674e-05 Test RE 0.0025510494256224606\n",
      "193 Train Loss 0.0049512507 Test MSE 1.292826169097086e-05 Test RE 0.0025978013855609723\n",
      "194 Train Loss 0.004907302 Test MSE 1.3161546546417609e-05 Test RE 0.0026211346939984453\n",
      "195 Train Loss 0.0048435433 Test MSE 1.295581417419046e-05 Test RE 0.0026005681064884822\n",
      "196 Train Loss 0.0047408226 Test MSE 1.3629496460758543e-05 Test RE 0.0026673240603414666\n",
      "197 Train Loss 0.004662525 Test MSE 1.3137163300644511e-05 Test RE 0.0026187055949708055\n",
      "198 Train Loss 0.004613094 Test MSE 1.2726826183019858e-05 Test RE 0.0025774837343496967\n",
      "199 Train Loss 0.004565751 Test MSE 1.361223322464343e-05 Test RE 0.002665634297436752\n",
      "200 Train Loss 0.0045046424 Test MSE 1.4311356681225566e-05 Test RE 0.00273323063480887\n",
      "201 Train Loss 0.0044261846 Test MSE 1.2744006604953106e-05 Test RE 0.0025792228687950133\n",
      "202 Train Loss 0.0043833214 Test MSE 1.2361774876083372e-05 Test RE 0.0025402490172824178\n",
      "203 Train Loss 0.0043517584 Test MSE 1.1616698915976157e-05 Test RE 0.002462505695118977\n",
      "204 Train Loss 0.0043298653 Test MSE 1.2116250529298283e-05 Test RE 0.0025148958212349902\n",
      "205 Train Loss 0.0042646662 Test MSE 1.0820707350629048e-05 Test RE 0.0023766416441486494\n",
      "206 Train Loss 0.0042193276 Test MSE 1.0942845906152651e-05 Test RE 0.0023900171577430174\n",
      "207 Train Loss 0.004178742 Test MSE 1.1001275243586309e-05 Test RE 0.0023963894124887303\n",
      "208 Train Loss 0.0041384487 Test MSE 1.084144762412938e-05 Test RE 0.00237891823286328\n",
      "209 Train Loss 0.00412125 Test MSE 1.1022958139761666e-05 Test RE 0.0023987498245313806\n",
      "210 Train Loss 0.004076585 Test MSE 1.0827216217771075e-05 Test RE 0.002377356334909653\n",
      "211 Train Loss 0.004057925 Test MSE 1.052399408365041e-05 Test RE 0.002343830355052368\n",
      "212 Train Loss 0.00400353 Test MSE 1.0807030281960374e-05 Test RE 0.002375139165247938\n",
      "213 Train Loss 0.0039611026 Test MSE 1.1371967208571889e-05 Test RE 0.002436428529487938\n",
      "214 Train Loss 0.003953179 Test MSE 1.0857998233885397e-05 Test RE 0.0023807333747868347\n",
      "215 Train Loss 0.0039226194 Test MSE 1.0314918405114172e-05 Test RE 0.0023204316225107907\n",
      "216 Train Loss 0.0039093113 Test MSE 1.1335461303231935e-05 Test RE 0.002432514715645708\n",
      "217 Train Loss 0.0038887803 Test MSE 1.1119882452729909e-05 Test RE 0.002409272786085703\n",
      "218 Train Loss 0.0038604315 Test MSE 9.89565876335127e-06 Test RE 0.002272784360963394\n",
      "219 Train Loss 0.0038404304 Test MSE 9.4305740590575e-06 Test RE 0.0022187324842345797\n",
      "220 Train Loss 0.0038165243 Test MSE 9.261717029660515e-06 Test RE 0.0021987792552677146\n",
      "221 Train Loss 0.003781053 Test MSE 9.09305007970736e-06 Test RE 0.0021786660625137083\n",
      "222 Train Loss 0.0037491675 Test MSE 8.84953446416496e-06 Test RE 0.0021492953018462787\n",
      "223 Train Loss 0.003723572 Test MSE 8.340975222761095e-06 Test RE 0.0020866244525467635\n",
      "224 Train Loss 0.003677171 Test MSE 8.062280576407346e-06 Test RE 0.0020514683964381417\n",
      "225 Train Loss 0.0036251692 Test MSE 7.85638596245299e-06 Test RE 0.002025103771060075\n",
      "226 Train Loss 0.0035945487 Test MSE 7.566829342381178e-06 Test RE 0.0019874346008283135\n",
      "227 Train Loss 0.003544785 Test MSE 7.184213845731668e-06 Test RE 0.0019365356769501343\n",
      "228 Train Loss 0.003560297 Test MSE 6.884746143515846e-06 Test RE 0.00189574466564705\n",
      "229 Train Loss 0.0035272075 Test MSE 6.7878226813786585e-06 Test RE 0.0018823532198767833\n",
      "230 Train Loss 0.0034780141 Test MSE 6.661491920894236e-06 Test RE 0.0018647543531210866\n",
      "231 Train Loss 0.003434656 Test MSE 6.737475608687803e-06 Test RE 0.0018753592713783964\n",
      "232 Train Loss 0.0034025966 Test MSE 6.604013838868101e-06 Test RE 0.0018566919917570594\n",
      "233 Train Loss 0.0034104981 Test MSE 6.6314483180957874e-06 Test RE 0.0018605445417017555\n",
      "234 Train Loss 0.0033905446 Test MSE 6.740809500345408e-06 Test RE 0.0018758232041432624\n",
      "235 Train Loss 0.0033420806 Test MSE 6.691201151779602e-06 Test RE 0.001868907986143398\n",
      "236 Train Loss 0.003303938 Test MSE 7.264991412083414e-06 Test RE 0.0019473922150342465\n",
      "237 Train Loss 0.0032760308 Test MSE 7.235061637242329e-06 Test RE 0.0019433767137930341\n",
      "238 Train Loss 0.0032517214 Test MSE 7.129287995292421e-06 Test RE 0.001929118724080197\n",
      "239 Train Loss 0.0032156305 Test MSE 7.66628369914686e-06 Test RE 0.0020004528528109146\n",
      "240 Train Loss 0.0031671831 Test MSE 7.679748941791224e-06 Test RE 0.0020022089034921176\n",
      "241 Train Loss 0.0031464384 Test MSE 7.5653503466270726e-06 Test RE 0.0019872403615472526\n",
      "242 Train Loss 0.0031228946 Test MSE 7.66342824582342e-06 Test RE 0.0020000802647373046\n",
      "243 Train Loss 0.0030998802 Test MSE 8.113008456761065e-06 Test RE 0.002057912197201956\n",
      "244 Train Loss 0.0030898054 Test MSE 8.575954238308523e-06 Test RE 0.0021158121384814437\n",
      "245 Train Loss 0.0030676196 Test MSE 8.711179006339757e-06 Test RE 0.0021324278504916447\n",
      "246 Train Loss 0.0030336406 Test MSE 8.47028382788422e-06 Test RE 0.00210273652468415\n",
      "247 Train Loss 0.0030083598 Test MSE 8.868162365119624e-06 Test RE 0.002151556201181298\n",
      "248 Train Loss 0.00297834 Test MSE 7.698049328386018e-06 Test RE 0.002004593056592307\n",
      "249 Train Loss 0.0029657374 Test MSE 7.546213098338893e-06 Test RE 0.0019847253165577853\n",
      "250 Train Loss 0.0029545445 Test MSE 6.997052061550286e-06 Test RE 0.0019111440802257926\n",
      "251 Train Loss 0.0029349963 Test MSE 6.272517178040202e-06 Test RE 0.00180949257996158\n",
      "252 Train Loss 0.0029187265 Test MSE 5.769030393218026e-06 Test RE 0.0017353508401257356\n",
      "253 Train Loss 0.002901242 Test MSE 5.3131110876936845e-06 Test RE 0.0016653684203262096\n",
      "254 Train Loss 0.0028768426 Test MSE 4.813540600804094e-06 Test RE 0.0015851420851827156\n",
      "255 Train Loss 0.0028657746 Test MSE 4.696690064847034e-06 Test RE 0.001565783917013024\n",
      "256 Train Loss 0.0028525873 Test MSE 4.548736825346913e-06 Test RE 0.0015409242230970093\n",
      "257 Train Loss 0.0028468675 Test MSE 4.652911204265068e-06 Test RE 0.0015584693271721596\n",
      "258 Train Loss 0.0028443397 Test MSE 4.546391711906904e-06 Test RE 0.0015405269580847432\n",
      "259 Train Loss 0.0028297598 Test MSE 4.618281213674864e-06 Test RE 0.0015526589247436798\n",
      "260 Train Loss 0.002820931 Test MSE 4.630110109860083e-06 Test RE 0.001554646081324702\n",
      "261 Train Loss 0.0028161895 Test MSE 4.630110109860083e-06 Test RE 0.001554646081324702\n",
      "262 Train Loss 0.0028133788 Test MSE 4.6301098251189805e-06 Test RE 0.0015546460335211254\n",
      "263 Train Loss 0.0028117625 Test MSE 4.6301098251189805e-06 Test RE 0.0015546460335211254\n",
      "264 Train Loss 0.002810834 Test MSE 4.630109790555634e-06 Test RE 0.0015546460277184803\n",
      "265 Train Loss 0.0028102985 Test MSE 4.630109790555634e-06 Test RE 0.0015546460277184803\n",
      "266 Train Loss 0.00280998 Test MSE 4.630109790555634e-06 Test RE 0.0015546460277184803\n",
      "267 Train Loss 0.002810185 Test MSE 4.630183132839309e-06 Test RE 0.0015546583406919954\n",
      "268 Train Loss 0.002810283 Test MSE 4.630183132839309e-06 Test RE 0.0015546583406919954\n",
      "269 Train Loss 0.0028103124 Test MSE 4.630183132839309e-06 Test RE 0.0015546583406919954\n",
      "270 Train Loss 0.00281031 Test MSE 4.630183132839309e-06 Test RE 0.0015546583406919954\n",
      "271 Train Loss 0.0028102938 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "272 Train Loss 0.0028102729 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "273 Train Loss 0.0028102517 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "274 Train Loss 0.0028102314 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "275 Train Loss 0.0028102137 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "276 Train Loss 0.0028101976 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "277 Train Loss 0.002810184 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "278 Train Loss 0.0028101725 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "279 Train Loss 0.0028101609 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "280 Train Loss 0.0028101532 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "281 Train Loss 0.0028101467 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "282 Train Loss 0.002810139 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "283 Train Loss 0.0028101348 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "284 Train Loss 0.0028101304 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "285 Train Loss 0.0028101273 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "286 Train Loss 0.002810124 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "287 Train Loss 0.002810122 Test MSE 4.630182987718862e-06 Test RE 0.0015546583163287358\n",
      "288 Train Loss 0.0028101194 Test MSE 4.630182875554478e-06 Test RE 0.001554658297498239\n",
      "289 Train Loss 0.0028101162 Test MSE 4.630182800120577e-06 Test RE 0.0015546582848341664\n",
      "290 Train Loss 0.0028101031 Test MSE 4.630184346398009e-06 Test RE 0.0015546585444278934\n",
      "291 Train Loss 0.0028101006 Test MSE 4.630184346398009e-06 Test RE 0.0015546585444278934\n",
      "292 Train Loss 0.0028100982 Test MSE 4.630184346398009e-06 Test RE 0.0015546585444278934\n",
      "293 Train Loss 0.0028100964 Test MSE 4.630184346398009e-06 Test RE 0.0015546585444278934\n",
      "294 Train Loss 0.0028108673 Test MSE 4.615466737517218e-06 Test RE 0.0015521857413984554\n",
      "295 Train Loss 0.0027908094 Test MSE 4.5349501460413445e-06 Test RE 0.001538587272143816\n",
      "296 Train Loss 0.0027761583 Test MSE 4.72180520921898e-06 Test RE 0.0015699647823745912\n",
      "297 Train Loss 0.0027836566 Test MSE 4.715455938174737e-06 Test RE 0.0015689088848196426\n",
      "298 Train Loss 0.0027812868 Test MSE 5.20774538212965e-06 Test RE 0.0016487725491135287\n",
      "299 Train Loss 0.0027745152 Test MSE 4.74525295314433e-06 Test RE 0.0015738580544243765\n",
      "Training time: 232.37\n",
      "KG_tanhALR_high\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 46051.055 Test MSE 8.87190349658673 Test RE 2.152009982107863\n",
      "1 Train Loss 35578.723 Test MSE 9.05291225413646 Test RE 2.173852296421822\n",
      "2 Train Loss 30088.986 Test MSE 7.165714945837902 Test RE 1.9340408409713656\n",
      "3 Train Loss 19639.418 Test MSE 2.1039483948600246 Test RE 1.0479810232815772\n",
      "4 Train Loss 7149.611 Test MSE 11.391312107803346 Test RE 2.438499958126793\n",
      "5 Train Loss 2997.0237 Test MSE 14.606177602126875 Test RE 2.761240059646589\n",
      "6 Train Loss 1843.1919 Test MSE 15.212310728065038 Test RE 2.8179512185251507\n",
      "7 Train Loss 1423.898 Test MSE 16.268465746296286 Test RE 2.914131702121603\n",
      "8 Train Loss 1234.7738 Test MSE 17.877818075501573 Test RE 3.0548728144767496\n",
      "9 Train Loss 1088.8489 Test MSE 18.593701941862776 Test RE 3.1154358229816994\n",
      "10 Train Loss 988.0326 Test MSE 19.98654410346836 Test RE 3.2300164193780434\n",
      "11 Train Loss 847.9824 Test MSE 20.277519871533922 Test RE 3.2534436921253373\n",
      "12 Train Loss 708.04694 Test MSE 20.231086059875274 Test RE 3.249716501225377\n",
      "13 Train Loss 624.9984 Test MSE 19.533032874841986 Test RE 3.193160272568144\n",
      "14 Train Loss 556.26447 Test MSE 18.913857794682034 Test RE 3.142142931759527\n",
      "15 Train Loss 523.40015 Test MSE 18.662755698806958 Test RE 3.121215553603565\n",
      "16 Train Loss 484.3127 Test MSE 18.610805756012862 Test RE 3.116868393727525\n",
      "17 Train Loss 464.78888 Test MSE 17.65803220071399 Test RE 3.036036784290914\n",
      "18 Train Loss 457.74457 Test MSE 17.010266004313067 Test RE 2.9798295970080577\n",
      "19 Train Loss 461.04672 Test MSE 16.012509016245897 Test RE 2.8911163552203702\n",
      "20 Train Loss 426.20468 Test MSE 14.614777797090008 Test RE 2.762052856427126\n",
      "21 Train Loss 408.62372 Test MSE 12.655656552925509 Test RE 2.5702668629799432\n",
      "22 Train Loss 350.6137 Test MSE 9.583886648272511 Test RE 2.2366947128867647\n",
      "23 Train Loss 258.89783 Test MSE 9.015758339949226 Test RE 2.1693868736571886\n",
      "24 Train Loss 218.80334 Test MSE 8.379495226945334 Test RE 2.0914370911075935\n",
      "25 Train Loss 189.88089 Test MSE 8.223165940378333 Test RE 2.0718361381754455\n",
      "26 Train Loss 170.10551 Test MSE 7.703269612192568 Test RE 2.0052726294778966\n",
      "27 Train Loss 153.55711 Test MSE 6.937842179699354 Test RE 1.903040737357123\n",
      "28 Train Loss 140.76547 Test MSE 6.2705302063169315 Test RE 1.809205956962691\n",
      "29 Train Loss 129.18456 Test MSE 5.702869613637388 Test RE 1.725371412745377\n",
      "30 Train Loss 120.17173 Test MSE 4.893147379794162 Test RE 1.5981959481020287\n",
      "31 Train Loss 87.88798 Test MSE 2.501858540083999 Test RE 1.1427921592209036\n",
      "32 Train Loss 65.034424 Test MSE 1.44242910753369 Test RE 0.8677270092931025\n",
      "33 Train Loss 38.231644 Test MSE 0.44056031400035717 Test RE 0.47955515453314357\n",
      "34 Train Loss 24.756674 Test MSE 0.2002075008083499 Test RE 0.3232779244096606\n",
      "35 Train Loss 16.039732 Test MSE 0.1111331771949774 Test RE 0.24085615120143114\n",
      "36 Train Loss 11.297383 Test MSE 0.049287340742842294 Test RE 0.16039970687485708\n",
      "37 Train Loss 8.3558445 Test MSE 0.034676849968263354 Test RE 0.1345413238229751\n",
      "38 Train Loss 6.7585626 Test MSE 0.0287209033584614 Test RE 0.1224432714837772\n",
      "39 Train Loss 5.408011 Test MSE 0.033144830763442455 Test RE 0.1315357422448731\n",
      "40 Train Loss 4.287401 Test MSE 0.01923709638242429 Test RE 0.10020874828256952\n",
      "41 Train Loss 3.3613338 Test MSE 0.016638708755623458 Test RE 0.0931956596886152\n",
      "42 Train Loss 2.7693253 Test MSE 0.013416389461231179 Test RE 0.08368617250622497\n",
      "43 Train Loss 2.278723 Test MSE 0.015353059691010576 Test RE 0.08952273588449262\n",
      "44 Train Loss 1.9621959 Test MSE 0.012507112003946757 Test RE 0.08080056478172921\n",
      "45 Train Loss 1.7087111 Test MSE 0.011187180695922895 Test RE 0.0764180943356675\n",
      "46 Train Loss 1.509106 Test MSE 0.012899424931714224 Test RE 0.08205802341720055\n",
      "47 Train Loss 1.3440707 Test MSE 0.010875714459836643 Test RE 0.07534679355091854\n",
      "48 Train Loss 1.186423 Test MSE 0.01170854980140359 Test RE 0.07817851750176404\n",
      "49 Train Loss 1.0380723 Test MSE 0.010548073988363806 Test RE 0.07420317028083524\n",
      "50 Train Loss 0.9005287 Test MSE 0.010788930767061411 Test RE 0.07504557335584092\n",
      "51 Train Loss 0.78544813 Test MSE 0.010184157837764577 Test RE 0.07291190370583044\n",
      "52 Train Loss 0.71376854 Test MSE 0.008900611503163992 Test RE 0.06816254532868005\n",
      "53 Train Loss 0.6722273 Test MSE 0.008118244970612023 Test RE 0.06509789612188148\n",
      "54 Train Loss 0.61318684 Test MSE 0.008635154703065216 Test RE 0.06713839242154535\n",
      "55 Train Loss 0.5495128 Test MSE 0.007964781718097686 Test RE 0.06447967145518549\n",
      "56 Train Loss 0.51757574 Test MSE 0.0072271003288949765 Test RE 0.061421146495216086\n",
      "57 Train Loss 0.46353874 Test MSE 0.0061320889318570715 Test RE 0.05657702397007911\n",
      "58 Train Loss 0.4376247 Test MSE 0.0057016497940912065 Test RE 0.05455519924152064\n",
      "59 Train Loss 0.4040441 Test MSE 0.005131182720709731 Test RE 0.051754082876098575\n",
      "60 Train Loss 0.37507185 Test MSE 0.005119417429665357 Test RE 0.05169471534628247\n",
      "61 Train Loss 0.34617588 Test MSE 0.004653832526761418 Test RE 0.049288006405865524\n",
      "62 Train Loss 0.3344756 Test MSE 0.004478787115586566 Test RE 0.04835218307037417\n",
      "63 Train Loss 0.30921966 Test MSE 0.0038700646973156144 Test RE 0.0449464079787282\n",
      "64 Train Loss 0.29156122 Test MSE 0.0033590036242549474 Test RE 0.04187367838788246\n",
      "65 Train Loss 0.27768472 Test MSE 0.002864851489357066 Test RE 0.03867113632174439\n",
      "66 Train Loss 0.25611803 Test MSE 0.0025620305709509682 Test RE 0.03657025854093696\n",
      "67 Train Loss 0.24503854 Test MSE 0.0023647993085114415 Test RE 0.03513443886336181\n",
      "68 Train Loss 0.23328404 Test MSE 0.002103868488799876 Test RE 0.03313944046109974\n",
      "69 Train Loss 0.21864425 Test MSE 0.0018485556756891593 Test RE 0.031063625702707365\n",
      "70 Train Loss 0.20947084 Test MSE 0.0017711121479249685 Test RE 0.030405973161168012\n",
      "71 Train Loss 0.20228347 Test MSE 0.0016221573044714434 Test RE 0.02909928782047201\n",
      "72 Train Loss 0.19446844 Test MSE 0.0017395427619593313 Test RE 0.03013376738714746\n",
      "73 Train Loss 0.18393712 Test MSE 0.0018534762233098638 Test RE 0.031104941328563524\n",
      "74 Train Loss 0.17490418 Test MSE 0.001695893797449504 Test RE 0.029753304217304127\n",
      "75 Train Loss 0.17137393 Test MSE 0.0016917483017451572 Test RE 0.029716917014682206\n",
      "76 Train Loss 0.16768615 Test MSE 0.0014683921428650794 Test RE 0.027685788884049108\n",
      "77 Train Loss 0.16079362 Test MSE 0.0014568136992247705 Test RE 0.02757642002046412\n",
      "78 Train Loss 0.15723912 Test MSE 0.0015811198354617896 Test RE 0.02872885189388146\n",
      "79 Train Loss 0.14969742 Test MSE 0.0013840214519129524 Test RE 0.026878639820750228\n",
      "80 Train Loss 0.14165479 Test MSE 0.0012377703009576464 Test RE 0.025418850444962657\n",
      "81 Train Loss 0.13924426 Test MSE 0.001206749262608786 Test RE 0.025098305307106987\n",
      "82 Train Loss 0.135831 Test MSE 0.0012111181388630235 Test RE 0.025143696809768513\n",
      "83 Train Loss 0.13202183 Test MSE 0.001245081284746367 Test RE 0.02549380910088374\n",
      "84 Train Loss 0.12872396 Test MSE 0.001264924900976741 Test RE 0.02569616119145278\n",
      "85 Train Loss 0.12398529 Test MSE 0.001291092255076092 Test RE 0.025960587400067712\n",
      "86 Train Loss 0.120775715 Test MSE 0.0013089768792092938 Test RE 0.026139776181932677\n",
      "87 Train Loss 0.11799255 Test MSE 0.0011830638411970834 Test RE 0.02485077672233955\n",
      "88 Train Loss 0.116518974 Test MSE 0.0011722008901063558 Test RE 0.02473642308222899\n",
      "89 Train Loss 0.114087395 Test MSE 0.0012160832769564991 Test RE 0.02519518404002766\n",
      "90 Train Loss 0.11093198 Test MSE 0.0013027506094888625 Test RE 0.02607753394565902\n",
      "91 Train Loss 0.10832775 Test MSE 0.0012725282095134463 Test RE 0.02577327372422784\n",
      "92 Train Loss 0.10565345 Test MSE 0.0012399119821473958 Test RE 0.02544083172272863\n",
      "93 Train Loss 0.10374107 Test MSE 0.0012262115508740888 Test RE 0.025299886818373838\n",
      "94 Train Loss 0.101281404 Test MSE 0.0012065371590799065 Test RE 0.025096099516215793\n",
      "95 Train Loss 0.09899423 Test MSE 0.0011785874812943 Test RE 0.024803718211281044\n",
      "96 Train Loss 0.0975655 Test MSE 0.0011713864468273411 Test RE 0.02472782817570046\n",
      "97 Train Loss 0.09608953 Test MSE 0.001095011884319724 Test RE 0.023908112636461493\n",
      "98 Train Loss 0.09389115 Test MSE 0.0010904279685868409 Test RE 0.023858018336269708\n",
      "99 Train Loss 0.09153777 Test MSE 0.001115826043879202 Test RE 0.02413426759649943\n",
      "100 Train Loss 0.08744232 Test MSE 0.0010878660076183528 Test RE 0.023829974642383088\n",
      "101 Train Loss 0.08500698 Test MSE 0.001030169031249475 Test RE 0.023189432572863496\n",
      "102 Train Loss 0.08176747 Test MSE 0.0010039907017945836 Test RE 0.022892895310988072\n",
      "103 Train Loss 0.080099 Test MSE 0.0009828968219111572 Test RE 0.022651128420202806\n",
      "104 Train Loss 0.07878158 Test MSE 0.000986520520604969 Test RE 0.02269284457432559\n",
      "105 Train Loss 0.07637197 Test MSE 0.0009159407709391785 Test RE 0.02186601151194525\n",
      "106 Train Loss 0.07444334 Test MSE 0.0009235638615733933 Test RE 0.02195681498332605\n",
      "107 Train Loss 0.07292196 Test MSE 0.000818061316736943 Test RE 0.02066468575121809\n",
      "108 Train Loss 0.0692371 Test MSE 0.0007629148508266114 Test RE 0.01995601911918091\n",
      "109 Train Loss 0.066912405 Test MSE 0.000714100742718386 Test RE 0.019307036573909888\n",
      "110 Train Loss 0.06547938 Test MSE 0.0006991490250959293 Test RE 0.01910384364962207\n",
      "111 Train Loss 0.064973615 Test MSE 0.000697458117511502 Test RE 0.01908072812782709\n",
      "112 Train Loss 0.06347695 Test MSE 0.0006725881635979877 Test RE 0.01873745000143078\n",
      "113 Train Loss 0.06198938 Test MSE 0.000620107112502035 Test RE 0.01799157705663634\n",
      "114 Train Loss 0.059393052 Test MSE 0.0006160263990067312 Test RE 0.01793228112665695\n",
      "115 Train Loss 0.056857947 Test MSE 0.0005743339611150901 Test RE 0.017314825761361154\n",
      "116 Train Loss 0.0560372 Test MSE 0.0005481803753406327 Test RE 0.016915997755177166\n",
      "117 Train Loss 0.055347398 Test MSE 0.000550175982260314 Test RE 0.016946760453413954\n",
      "118 Train Loss 0.05451471 Test MSE 0.0005125277836902492 Test RE 0.016356658387706814\n",
      "119 Train Loss 0.05301265 Test MSE 0.00048711799608242083 Test RE 0.015946044220439028\n",
      "120 Train Loss 0.050812896 Test MSE 0.00045768965674099357 Test RE 0.01545686542937769\n",
      "121 Train Loss 0.04935006 Test MSE 0.00040362001412074346 Test RE 0.014515173239293784\n",
      "122 Train Loss 0.048014417 Test MSE 0.00037234718172224503 Test RE 0.013941513140245323\n",
      "123 Train Loss 0.047211215 Test MSE 0.00035830198767993756 Test RE 0.01367604388097066\n",
      "124 Train Loss 0.04645907 Test MSE 0.0003287418351031301 Test RE 0.013099760766857343\n",
      "125 Train Loss 0.04579312 Test MSE 0.0003069676166058086 Test RE 0.012658497436832372\n",
      "126 Train Loss 0.045219496 Test MSE 0.0003004427152542334 Test RE 0.012523240357165559\n",
      "127 Train Loss 0.044533774 Test MSE 0.000267656185321974 Test RE 0.011820191670525974\n",
      "128 Train Loss 0.04395571 Test MSE 0.00025465419787989757 Test RE 0.011529521852021182\n",
      "129 Train Loss 0.042958073 Test MSE 0.0002481150822779349 Test RE 0.011380529247851818\n",
      "130 Train Loss 0.042057697 Test MSE 0.0002490242467217293 Test RE 0.01140136093489256\n",
      "131 Train Loss 0.041534223 Test MSE 0.00023319489754397484 Test RE 0.011033045232360986\n",
      "132 Train Loss 0.040734358 Test MSE 0.000226454413416786 Test RE 0.01087242126903654\n",
      "133 Train Loss 0.03985387 Test MSE 0.0002106296353280715 Test RE 0.01048565621686971\n",
      "134 Train Loss 0.039098684 Test MSE 0.00019502837928598847 Test RE 0.010089851693148896\n",
      "135 Train Loss 0.038425855 Test MSE 0.0001845326586983027 Test RE 0.009814597559954973\n",
      "136 Train Loss 0.037973914 Test MSE 0.00018662131215379875 Test RE 0.009869985081432005\n",
      "137 Train Loss 0.037475426 Test MSE 0.00018221798815939793 Test RE 0.009752849007481265\n",
      "138 Train Loss 0.036903694 Test MSE 0.0001658336445320579 Test RE 0.009304053512169003\n",
      "139 Train Loss 0.036443193 Test MSE 0.00015922570942752034 Test RE 0.009116800957489147\n",
      "140 Train Loss 0.036108322 Test MSE 0.00015005467106133996 Test RE 0.00885035388466138\n",
      "141 Train Loss 0.035883714 Test MSE 0.0001408410062349465 Test RE 0.008574334784267024\n",
      "142 Train Loss 0.035520416 Test MSE 0.00014183776482640882 Test RE 0.008604622390084601\n",
      "143 Train Loss 0.03514159 Test MSE 0.000128634796948138 Test RE 0.008194361317049875\n",
      "144 Train Loss 0.034901448 Test MSE 0.00012581771854938763 Test RE 0.008104137106136989\n",
      "145 Train Loss 0.034267478 Test MSE 0.00013265995908229777 Test RE 0.008321580263372892\n",
      "146 Train Loss 0.033645883 Test MSE 0.0001264725896922764 Test RE 0.008125200425600394\n",
      "147 Train Loss 0.032976143 Test MSE 0.00012345469280775358 Test RE 0.0080276730903419\n",
      "148 Train Loss 0.032310426 Test MSE 0.00012678965839545603 Test RE 0.008135379050536764\n",
      "149 Train Loss 0.031809952 Test MSE 0.00012879292988259372 Test RE 0.008199396503638772\n",
      "150 Train Loss 0.03143721 Test MSE 0.00012795436410794958 Test RE 0.008172659935959252\n",
      "151 Train Loss 0.030781837 Test MSE 0.00013314730036864894 Test RE 0.008336851381900328\n",
      "152 Train Loss 0.030131007 Test MSE 0.00014668507137791058 Test RE 0.008750418720449323\n",
      "153 Train Loss 0.029700719 Test MSE 0.00013000721488901703 Test RE 0.008237958583458207\n",
      "154 Train Loss 0.029268617 Test MSE 0.00011894141323746268 Test RE 0.007879568295567812\n",
      "155 Train Loss 0.028679874 Test MSE 0.00010747294011036899 Test RE 0.007490062503788662\n",
      "156 Train Loss 0.028136397 Test MSE 0.0001005972036905361 Test RE 0.007246508922414932\n",
      "157 Train Loss 0.027599407 Test MSE 8.213611016124996e-05 Test RE 0.006547913636132343\n",
      "158 Train Loss 0.02723754 Test MSE 7.416131250479148e-05 Test RE 0.006221922260877025\n",
      "159 Train Loss 0.026816953 Test MSE 7.694697478835583e-05 Test RE 0.006337699623707049\n",
      "160 Train Loss 0.026444223 Test MSE 7.283543359155021e-05 Test RE 0.006166052694745691\n",
      "161 Train Loss 0.026081914 Test MSE 7.43528830135245e-05 Test RE 0.006229953187140305\n",
      "162 Train Loss 0.025795422 Test MSE 7.838689789156358e-05 Test RE 0.00639672404789886\n",
      "163 Train Loss 0.025436109 Test MSE 8.625240434311596e-05 Test RE 0.0067099839595598735\n",
      "164 Train Loss 0.025166677 Test MSE 9.193401891314024e-05 Test RE 0.006927459569333425\n",
      "165 Train Loss 0.024951901 Test MSE 0.00010598363697908857 Test RE 0.007437984796780556\n",
      "166 Train Loss 0.02464777 Test MSE 0.000116973818288823 Test RE 0.00781412240774853\n",
      "167 Train Loss 0.024347657 Test MSE 0.00011031168712676631 Test RE 0.007588337533409132\n",
      "168 Train Loss 0.024013067 Test MSE 0.0001079927317560113 Test RE 0.0075081534568182855\n",
      "169 Train Loss 0.023722084 Test MSE 0.00011077980610346495 Test RE 0.007604421432991786\n",
      "170 Train Loss 0.023432167 Test MSE 0.00012485601672130098 Test RE 0.00807310525355631\n",
      "171 Train Loss 0.023135802 Test MSE 0.0001261034928208028 Test RE 0.008113335493764168\n",
      "172 Train Loss 0.022808606 Test MSE 0.00012781739185772762 Test RE 0.008168284440951834\n",
      "173 Train Loss 0.022512693 Test MSE 0.00012060320436393669 Test RE 0.007934422095581144\n",
      "174 Train Loss 0.022327272 Test MSE 0.0001177507023659166 Test RE 0.007840028294558333\n",
      "175 Train Loss 0.02217419 Test MSE 0.00011535632673555609 Test RE 0.007759908245640678\n",
      "176 Train Loss 0.021929527 Test MSE 0.0001098154933234412 Test RE 0.007571251720134558\n",
      "177 Train Loss 0.021706793 Test MSE 0.00011763611876586937 Test RE 0.007836212787309154\n",
      "178 Train Loss 0.021567916 Test MSE 0.00011282261273813035 Test RE 0.007674214843549927\n",
      "179 Train Loss 0.02134914 Test MSE 0.00011170169838420116 Test RE 0.007635997281760045\n",
      "180 Train Loss 0.021132013 Test MSE 0.00011523084039466584 Test RE 0.007755686424950621\n",
      "181 Train Loss 0.020940728 Test MSE 0.00011926189891468139 Test RE 0.007890176837678512\n",
      "182 Train Loss 0.020571757 Test MSE 0.00010458691775607398 Test RE 0.00738881102092349\n",
      "183 Train Loss 0.020113138 Test MSE 8.602970799453026e-05 Test RE 0.00670131605796884\n",
      "184 Train Loss 0.01973613 Test MSE 8.162105531088961e-05 Test RE 0.006527351191718947\n",
      "185 Train Loss 0.019407636 Test MSE 7.25785881154211e-05 Test RE 0.006155171168188903\n",
      "186 Train Loss 0.019170085 Test MSE 7.322296604525784e-05 Test RE 0.006182434662641078\n",
      "187 Train Loss 0.018959047 Test MSE 6.657361709371384e-05 Test RE 0.005895042680812262\n",
      "188 Train Loss 0.018804202 Test MSE 6.660304857098828e-05 Test RE 0.005896345604184193\n",
      "189 Train Loss 0.018627541 Test MSE 6.47172561145327e-05 Test RE 0.0058122719298603995\n",
      "190 Train Loss 0.018267699 Test MSE 6.229578110834687e-05 Test RE 0.005702498697326328\n",
      "191 Train Loss 0.017920487 Test MSE 6.111105789718015e-05 Test RE 0.00564801417275896\n",
      "192 Train Loss 0.017730448 Test MSE 5.689403663806895e-05 Test RE 0.005449658031347448\n",
      "193 Train Loss 0.017524753 Test MSE 5.110678847019886e-05 Test RE 0.005165057639034434\n",
      "194 Train Loss 0.01732459 Test MSE 5.321703310007584e-05 Test RE 0.005270613938038979\n",
      "195 Train Loss 0.01696221 Test MSE 5.3066927457450964e-05 Test RE 0.005263175459048863\n",
      "196 Train Loss 0.016667834 Test MSE 5.063142573659009e-05 Test RE 0.0051409804855641755\n",
      "197 Train Loss 0.016376011 Test MSE 5.5130740181840044e-05 Test RE 0.005364543713827615\n",
      "198 Train Loss 0.016100956 Test MSE 5.4278685198720914e-05 Test RE 0.005322927322011242\n",
      "199 Train Loss 0.015794886 Test MSE 5.400513451511676e-05 Test RE 0.005309497283860385\n",
      "200 Train Loss 0.01556517 Test MSE 5.7351603279713735e-05 Test RE 0.0054715284092716225\n",
      "201 Train Loss 0.015324835 Test MSE 6.232513123918034e-05 Test RE 0.005703841881173429\n",
      "202 Train Loss 0.01488638 Test MSE 5.453362135846844e-05 Test RE 0.0053354130424990345\n",
      "203 Train Loss 0.014687662 Test MSE 5.2660504570921124e-05 Test RE 0.00524298221959184\n",
      "204 Train Loss 0.0145446025 Test MSE 5.096761038432274e-05 Test RE 0.005158019895704413\n",
      "205 Train Loss 0.014404179 Test MSE 5.0358562425759876e-05 Test RE 0.005127108863139156\n",
      "206 Train Loss 0.014247825 Test MSE 5.0047389943435544e-05 Test RE 0.005111243761639156\n",
      "207 Train Loss 0.014184201 Test MSE 5.0276199729316823e-05 Test RE 0.005122914389594471\n",
      "208 Train Loss 0.013972238 Test MSE 5.312662214949344e-05 Test RE 0.00526613488544724\n",
      "209 Train Loss 0.013829933 Test MSE 5.310798804129131e-05 Test RE 0.005265211258746289\n",
      "210 Train Loss 0.01365684 Test MSE 4.931861139949724e-05 Test RE 0.0050738929132694306\n",
      "211 Train Loss 0.013413776 Test MSE 4.963901328093166e-05 Test RE 0.005090347685484895\n",
      "212 Train Loss 0.013240575 Test MSE 5.248378015210936e-05 Test RE 0.005234177312878486\n",
      "213 Train Loss 0.012977141 Test MSE 5.239980793037396e-05 Test RE 0.005229988385901399\n",
      "214 Train Loss 0.012718781 Test MSE 5.241531151904543e-05 Test RE 0.0052307620298822485\n",
      "215 Train Loss 0.012570605 Test MSE 5.325536071603062e-05 Test RE 0.005272511579598497\n",
      "216 Train Loss 0.012390182 Test MSE 5.5675749321103374e-05 Test RE 0.005390994792023139\n",
      "217 Train Loss 0.012264889 Test MSE 5.9411798127455155e-05 Test RE 0.0055689359792738214\n",
      "218 Train Loss 0.012105538 Test MSE 6.68487841078458e-05 Test RE 0.005907213031849846\n",
      "219 Train Loss 0.012159248 Test MSE 6.443282770695878e-05 Test RE 0.005799485574625095\n",
      "220 Train Loss 0.012010049 Test MSE 6.0375033818621254e-05 Test RE 0.0056138986827473005\n",
      "221 Train Loss 0.011893124 Test MSE 5.884804280286388e-05 Test RE 0.005542451336211568\n",
      "222 Train Loss 0.011771674 Test MSE 6.134081496745195e-05 Test RE 0.005658621531060454\n",
      "223 Train Loss 0.011668018 Test MSE 6.38109759223063e-05 Test RE 0.005771431829608165\n",
      "224 Train Loss 0.011557075 Test MSE 6.186291878933813e-05 Test RE 0.005682652251521982\n",
      "225 Train Loss 0.011390199 Test MSE 6.346506354787127e-05 Test RE 0.0057557674192343965\n",
      "226 Train Loss 0.01123933 Test MSE 6.057092212198297e-05 Test RE 0.005622998524719878\n",
      "227 Train Loss 0.011182287 Test MSE 6.05534427097505e-05 Test RE 0.00562218713042694\n",
      "228 Train Loss 0.011025953 Test MSE 6.547637726246997e-05 Test RE 0.00584626097323038\n",
      "229 Train Loss 0.010857541 Test MSE 6.614161836195503e-05 Test RE 0.005875884973445304\n",
      "230 Train Loss 0.0107488865 Test MSE 6.388364953888779e-05 Test RE 0.005774717404421284\n",
      "231 Train Loss 0.010656092 Test MSE 6.444722588719748e-05 Test RE 0.005800133515878332\n",
      "232 Train Loss 0.010570644 Test MSE 6.564770486110795e-05 Test RE 0.0058539047336950015\n",
      "233 Train Loss 0.010482291 Test MSE 6.764322298825571e-05 Test RE 0.005942210371030039\n",
      "234 Train Loss 0.01034716 Test MSE 6.475551579367779e-05 Test RE 0.005813989731387203\n",
      "235 Train Loss 0.010258195 Test MSE 6.39597744788757e-05 Test RE 0.005778157010158582\n",
      "236 Train Loss 0.010191187 Test MSE 6.435681623447738e-05 Test RE 0.005796063735620483\n",
      "237 Train Loss 0.01012091 Test MSE 6.481228734998978e-05 Test RE 0.0058165377532016505\n",
      "238 Train Loss 0.0100036925 Test MSE 6.744389867333254e-05 Test RE 0.005933448954994571\n",
      "239 Train Loss 0.009926395 Test MSE 6.687491687876945e-05 Test RE 0.0059083675536789676\n",
      "240 Train Loss 0.00988244 Test MSE 6.760114713664124e-05 Test RE 0.005940361978514276\n",
      "241 Train Loss 0.009757843 Test MSE 6.431241956205409e-05 Test RE 0.00579406417790006\n",
      "242 Train Loss 0.009700562 Test MSE 6.35212319949757e-05 Test RE 0.005758313867630993\n",
      "243 Train Loss 0.009589945 Test MSE 7.090404973149973e-05 Test RE 0.00608375053366125\n",
      "244 Train Loss 0.009576515 Test MSE 7.234962884379794e-05 Test RE 0.00614545482659364\n",
      "245 Train Loss 0.009505231 Test MSE 7.36647814960168e-05 Test RE 0.006201058513458822\n",
      "246 Train Loss 0.009433414 Test MSE 7.674305629226786e-05 Test RE 0.0063292962293457905\n",
      "247 Train Loss 0.009396481 Test MSE 7.678008572976054e-05 Test RE 0.006330823025551373\n",
      "248 Train Loss 0.009325286 Test MSE 8.198618573768796e-05 Test RE 0.006541934898159304\n",
      "249 Train Loss 0.009276757 Test MSE 8.91222656511763e-05 Test RE 0.006820700598535354\n",
      "250 Train Loss 0.00926675 Test MSE 8.700627048835314e-05 Test RE 0.00673924357763648\n",
      "251 Train Loss 0.009203024 Test MSE 8.456140726150485e-05 Test RE 0.00664388303018142\n",
      "252 Train Loss 0.009140858 Test MSE 8.620645557720639e-05 Test RE 0.006708196435158064\n",
      "253 Train Loss 0.009024839 Test MSE 8.830900376889367e-05 Test RE 0.006789509019779299\n",
      "254 Train Loss 0.009011061 Test MSE 9.578875999393795e-05 Test RE 0.007071200515052584\n",
      "255 Train Loss 0.008943012 Test MSE 9.788268592181899e-05 Test RE 0.007148070313476747\n",
      "256 Train Loss 0.008887283 Test MSE 9.756030914583859e-05 Test RE 0.0071362895151955465\n",
      "257 Train Loss 0.008815573 Test MSE 9.078602180712942e-05 Test RE 0.006884071460228435\n",
      "258 Train Loss 0.008745689 Test MSE 8.997862163621012e-05 Test RE 0.006853391552106129\n",
      "259 Train Loss 0.008664777 Test MSE 9.30683407545209e-05 Test RE 0.006970065551432837\n",
      "260 Train Loss 0.0085607 Test MSE 9.838964004818064e-05 Test RE 0.007166557054996133\n",
      "261 Train Loss 0.008475231 Test MSE 9.807583590439827e-05 Test RE 0.007155119411141399\n",
      "262 Train Loss 0.008420792 Test MSE 9.636430363375632e-05 Test RE 0.007092412239099468\n",
      "263 Train Loss 0.0082918 Test MSE 8.805152949163085e-05 Test RE 0.00677960402751154\n",
      "264 Train Loss 0.0082300035 Test MSE 8.643118469467808e-05 Test RE 0.006716934445849658\n",
      "265 Train Loss 0.008151907 Test MSE 8.707448039516238e-05 Test RE 0.006741884727034025\n",
      "266 Train Loss 0.008057436 Test MSE 9.030304605623155e-05 Test RE 0.0068657356343996495\n",
      "267 Train Loss 0.00800117 Test MSE 8.221240901012425e-05 Test RE 0.006550954212942314\n",
      "268 Train Loss 0.008030612 Test MSE 8.054177652667784e-05 Test RE 0.006484051852977911\n",
      "269 Train Loss 0.007944543 Test MSE 7.539256575013465e-05 Test RE 0.006273358961952682\n",
      "270 Train Loss 0.007874071 Test MSE 7.746995018781248e-05 Test RE 0.006359200458004561\n",
      "271 Train Loss 0.007825431 Test MSE 7.089482827704748e-05 Test RE 0.0060833549084971265\n",
      "272 Train Loss 0.0077618123 Test MSE 6.813261170318003e-05 Test RE 0.005963667138473306\n",
      "273 Train Loss 0.007726256 Test MSE 6.687949761372352e-05 Test RE 0.0059085699031067584\n",
      "274 Train Loss 0.0076600662 Test MSE 6.756948615914188e-05 Test RE 0.005938970732199713\n",
      "275 Train Loss 0.0075903106 Test MSE 6.78964011840029e-05 Test RE 0.005953320375419159\n",
      "276 Train Loss 0.007527245 Test MSE 6.893818469812505e-05 Test RE 0.0059988195549585295\n",
      "277 Train Loss 0.0074410127 Test MSE 7.716098726933722e-05 Test RE 0.006346507020176658\n",
      "278 Train Loss 0.007347973 Test MSE 7.504413607211773e-05 Test RE 0.006258845888002338\n",
      "279 Train Loss 0.0072481805 Test MSE 7.407924278627366e-05 Test RE 0.006218478600425389\n",
      "280 Train Loss 0.007188734 Test MSE 7.534497020341763e-05 Test RE 0.00627137845442064\n",
      "281 Train Loss 0.007128771 Test MSE 7.59525799964315e-05 Test RE 0.006296615038573916\n",
      "282 Train Loss 0.0070465235 Test MSE 7.437165728874666e-05 Test RE 0.00623073967630253\n",
      "283 Train Loss 0.0069844127 Test MSE 7.723928280015536e-05 Test RE 0.006349726115506625\n",
      "284 Train Loss 0.0069654617 Test MSE 8.055048696269613e-05 Test RE 0.006484402462278459\n",
      "285 Train Loss 0.00688025 Test MSE 8.399085458915248e-05 Test RE 0.006621431292855435\n",
      "286 Train Loss 0.006824503 Test MSE 8.907408484937211e-05 Test RE 0.006818856663978537\n",
      "287 Train Loss 0.0067823064 Test MSE 9.567525008202007e-05 Test RE 0.007067009578273532\n",
      "288 Train Loss 0.0067432 Test MSE 9.89819744673062e-05 Test RE 0.0071880970694478095\n",
      "289 Train Loss 0.006723682 Test MSE 9.544449653814066e-05 Test RE 0.0070584821798028025\n",
      "290 Train Loss 0.006701906 Test MSE 9.617108194041485e-05 Test RE 0.00708529811334127\n",
      "291 Train Loss 0.0066487677 Test MSE 9.533304169619176e-05 Test RE 0.00705435972201142\n",
      "292 Train Loss 0.0066383802 Test MSE 8.50896121440415e-05 Test RE 0.006664600922899381\n",
      "293 Train Loss 0.006550309 Test MSE 9.050452018993148e-05 Test RE 0.0068733904008247216\n",
      "294 Train Loss 0.0064740665 Test MSE 9.201685522299455e-05 Test RE 0.006930579828775362\n",
      "295 Train Loss 0.006478703 Test MSE 9.112549760072964e-05 Test RE 0.00689693024063266\n",
      "296 Train Loss 0.0064167315 Test MSE 8.677494585268336e-05 Test RE 0.006730278760283654\n",
      "297 Train Loss 0.0063827 Test MSE 8.367286001458253e-05 Test RE 0.006608884831801193\n",
      "298 Train Loss 0.006313219 Test MSE 8.140751430510377e-05 Test RE 0.006518807011561282\n",
      "299 Train Loss 0.006283079 Test MSE 7.384221365235323e-05 Test RE 0.00620852208981303\n",
      "Training time: 250.04\n",
      "KG_tanhALR_high\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 50995.44 Test MSE 9.145020917746459 Test RE 2.1848832159951925\n",
      "1 Train Loss 35400.33 Test MSE 8.935178689747074 Test RE 2.1596705093713875\n",
      "2 Train Loss 15677.853 Test MSE 13.811111770606354 Test RE 2.6850365188679475\n",
      "3 Train Loss 5280.618 Test MSE 15.340062660218944 Test RE 2.829758959811218\n",
      "4 Train Loss 2325.4993 Test MSE 17.732157742313788 Test RE 3.0424025045548673\n",
      "5 Train Loss 1520.7207 Test MSE 19.55176154203765 Test RE 3.1946907391389185\n",
      "6 Train Loss 1287.2241 Test MSE 20.38911778902354 Test RE 3.2623841187901528\n",
      "7 Train Loss 1110.0688 Test MSE 21.052754104450024 Test RE 3.3150519291387774\n",
      "8 Train Loss 921.4259 Test MSE 20.12818436474769 Test RE 3.2414414230060045\n",
      "9 Train Loss 747.17896 Test MSE 18.99492726783976 Test RE 3.1488697322171317\n",
      "10 Train Loss 620.8523 Test MSE 18.230394240962983 Test RE 3.08484897540498\n",
      "11 Train Loss 533.5565 Test MSE 17.4101205159715 Test RE 3.0146490813070757\n",
      "12 Train Loss 471.79117 Test MSE 17.291859808628974 Test RE 3.0043929197762385\n",
      "13 Train Loss 424.1279 Test MSE 17.2008083387435 Test RE 2.9964725615690346\n",
      "14 Train Loss 386.57156 Test MSE 17.385626433671597 Test RE 3.0125276987342438\n",
      "15 Train Loss 356.27582 Test MSE 17.560502035521186 Test RE 3.027640742015411\n",
      "16 Train Loss 329.23422 Test MSE 17.544256165619704 Test RE 3.0262399267406543\n",
      "17 Train Loss 304.83014 Test MSE 17.50733100898735 Test RE 3.0230536063597215\n",
      "18 Train Loss 285.65637 Test MSE 17.502366877487948 Test RE 3.022624988783563\n",
      "19 Train Loss 274.77078 Test MSE 17.608430509653328 Test RE 3.03176964795538\n",
      "20 Train Loss 256.4428 Test MSE 17.58581099614803 Test RE 3.029821740335216\n",
      "21 Train Loss 249.43018 Test MSE 17.643186487572695 Test RE 3.034760265818201\n",
      "22 Train Loss 233.56744 Test MSE 17.514084385666173 Test RE 3.0236366150223435\n",
      "23 Train Loss 220.07814 Test MSE 17.46336482782986 Test RE 3.01925532114498\n",
      "24 Train Loss 222.20244 Test MSE 17.300650246247777 Test RE 3.0051564748036013\n",
      "25 Train Loss 208.98944 Test MSE 17.076677716448714 Test RE 2.985640876056979\n",
      "26 Train Loss 196.25168 Test MSE 16.946632324166092 Test RE 2.9742507544762686\n",
      "27 Train Loss 185.1516 Test MSE 16.75143690655534 Test RE 2.9570720736999747\n",
      "28 Train Loss 183.6101 Test MSE 16.543758131851497 Test RE 2.9386845044066927\n",
      "29 Train Loss 173.1945 Test MSE 16.446819044238485 Test RE 2.9300621609394892\n",
      "30 Train Loss 174.8274 Test MSE 16.120048802647442 Test RE 2.9008084579299385\n",
      "31 Train Loss 172.58855 Test MSE 15.701384300942602 Test RE 2.862891232704208\n",
      "32 Train Loss 165.42137 Test MSE 15.105824939172422 Test RE 2.808071104530021\n",
      "33 Train Loss 166.40157 Test MSE 14.681275110247828 Test RE 2.768329402209316\n",
      "34 Train Loss 164.64265 Test MSE 13.038862223694784 Test RE 2.6088897414761356\n",
      "35 Train Loss 157.35886 Test MSE 11.847155719925441 Test RE 2.4868118337783196\n",
      "36 Train Loss 142.00426 Test MSE 11.263679794646183 Test RE 2.4248005663221086\n",
      "37 Train Loss 138.28502 Test MSE 10.303841733409017 Test RE 2.3191853904906963\n",
      "38 Train Loss 125.32954 Test MSE 8.42167476613719 Test RE 2.0966942764577685\n",
      "39 Train Loss 102.60606 Test MSE 6.547957592804616 Test RE 1.8487952043251359\n",
      "40 Train Loss 77.51552 Test MSE 4.0143015741405135 Test RE 1.4475743354785708\n",
      "41 Train Loss 51.527782 Test MSE 2.0951452241414548 Test RE 1.0457862863934801\n",
      "42 Train Loss 27.839088 Test MSE 0.4905072484068338 Test RE 0.5060094081031367\n",
      "43 Train Loss 17.193378 Test MSE 0.21996949221208456 Test RE 0.33885750048245983\n",
      "44 Train Loss 13.06064 Test MSE 0.21570714280220743 Test RE 0.3355584194046074\n",
      "45 Train Loss 10.14485 Test MSE 0.20147514416233508 Test RE 0.32429975045804876\n",
      "46 Train Loss 8.316399 Test MSE 0.23359845774141078 Test RE 0.3491972882613649\n",
      "47 Train Loss 6.8128004 Test MSE 0.1888911422107481 Test RE 0.31400869448128826\n",
      "48 Train Loss 5.5560956 Test MSE 0.1619270557731942 Test RE 0.29073384142902314\n",
      "49 Train Loss 4.888282 Test MSE 0.1324780565155066 Test RE 0.26297099586536715\n",
      "50 Train Loss 4.009394 Test MSE 0.11020138523531797 Test RE 0.2398443010950724\n",
      "51 Train Loss 3.4208486 Test MSE 0.0822644272157165 Test RE 0.20722488914604137\n",
      "52 Train Loss 2.906723 Test MSE 0.07563979339511476 Test RE 0.1987060287657867\n",
      "53 Train Loss 2.5324507 Test MSE 0.06135956347370312 Test RE 0.17896866871111897\n",
      "54 Train Loss 2.1937785 Test MSE 0.06165911519196837 Test RE 0.17940499108861452\n",
      "55 Train Loss 1.8721145 Test MSE 0.05171171734237764 Test RE 0.16429727385220175\n",
      "56 Train Loss 1.616595 Test MSE 0.054766627005816804 Test RE 0.16908063647940738\n",
      "57 Train Loss 1.4344915 Test MSE 0.047017859990022344 Test RE 0.15666331287403593\n",
      "58 Train Loss 1.2743177 Test MSE 0.03996889154634989 Test RE 0.14444314270939954\n",
      "59 Train Loss 1.1584419 Test MSE 0.036313385408335105 Test RE 0.137679489307945\n",
      "60 Train Loss 1.0694001 Test MSE 0.02717128478069652 Test RE 0.11909429669125911\n",
      "61 Train Loss 0.9977873 Test MSE 0.02212259245248454 Test RE 0.10746174444395598\n",
      "62 Train Loss 0.9171503 Test MSE 0.018876862289631712 Test RE 0.09926605912572357\n",
      "63 Train Loss 0.8431887 Test MSE 0.015077687545168517 Test RE 0.08871626438328611\n",
      "64 Train Loss 0.7515768 Test MSE 0.012726714014043825 Test RE 0.08150683313970146\n",
      "65 Train Loss 0.6822542 Test MSE 0.009530413963409838 Test RE 0.07053290307911149\n",
      "66 Train Loss 0.6207595 Test MSE 0.009133299479017002 Test RE 0.06904778098461169\n",
      "67 Train Loss 0.5738254 Test MSE 0.007254054706073908 Test RE 0.06153557883206237\n",
      "68 Train Loss 0.5314963 Test MSE 0.006976166857635268 Test RE 0.06034541894410859\n",
      "69 Train Loss 0.50641155 Test MSE 0.0065973092094408275 Test RE 0.05868394435971506\n",
      "70 Train Loss 0.48269776 Test MSE 0.005982166653266047 Test RE 0.05588112370466172\n",
      "71 Train Loss 0.46846473 Test MSE 0.006240323592885777 Test RE 0.05707414736188441\n",
      "72 Train Loss 0.42456847 Test MSE 0.005659299971456367 Test RE 0.05435221332382521\n",
      "73 Train Loss 0.40261573 Test MSE 0.004607446411095894 Test RE 0.04904175724167228\n",
      "74 Train Loss 0.37296218 Test MSE 0.003899857728275416 Test RE 0.04511908240580312\n",
      "75 Train Loss 0.34849685 Test MSE 0.0031815542749945337 Test RE 0.0407526209542828\n",
      "76 Train Loss 0.3255064 Test MSE 0.0033711428258729956 Test RE 0.041949274406434145\n",
      "77 Train Loss 0.30259788 Test MSE 0.002877185786148665 Test RE 0.03875429403154355\n",
      "78 Train Loss 0.28889823 Test MSE 0.002524190458004941 Test RE 0.03629919026514152\n",
      "79 Train Loss 0.2721338 Test MSE 0.001895432320650951 Test RE 0.031455023779064804\n",
      "80 Train Loss 0.25378007 Test MSE 0.002078688059597936 Test RE 0.03294052659226199\n",
      "81 Train Loss 0.23885955 Test MSE 0.0018312587297581084 Test RE 0.030917952875602055\n",
      "82 Train Loss 0.22585332 Test MSE 0.0019160668235627743 Test RE 0.03162577686766092\n",
      "83 Train Loss 0.21395153 Test MSE 0.0021308296048457675 Test RE 0.033351105786519696\n",
      "84 Train Loss 0.20740841 Test MSE 0.0019340670492299609 Test RE 0.03177398160984221\n",
      "85 Train Loss 0.20068857 Test MSE 0.0020388965939929864 Test RE 0.032623719703735524\n",
      "86 Train Loss 0.18420506 Test MSE 0.001797015855755665 Test RE 0.03062751995034042\n",
      "87 Train Loss 0.17544031 Test MSE 0.001751627889446833 Test RE 0.030238260394073093\n",
      "88 Train Loss 0.16313861 Test MSE 0.0015179898480541367 Test RE 0.028149475711018106\n",
      "89 Train Loss 0.1534836 Test MSE 0.0013956400370952837 Test RE 0.026991224454366386\n",
      "90 Train Loss 0.146816 Test MSE 0.0011832131719623099 Test RE 0.02485234505207754\n",
      "91 Train Loss 0.1427546 Test MSE 0.001142161908019068 Test RE 0.024417416593353124\n",
      "92 Train Loss 0.1356589 Test MSE 0.0011791475484225016 Test RE 0.0248096108995597\n",
      "93 Train Loss 0.12823847 Test MSE 0.0012643910301313357 Test RE 0.025690737992381803\n",
      "94 Train Loss 0.1237703 Test MSE 0.0012420236219784582 Test RE 0.025462486090533542\n",
      "95 Train Loss 0.11992275 Test MSE 0.0013642760293961823 Test RE 0.026686216261863027\n",
      "96 Train Loss 0.11379736 Test MSE 0.0012766327423562268 Test RE 0.025814806037981218\n",
      "97 Train Loss 0.1104576 Test MSE 0.0012227345158956878 Test RE 0.025263991282781974\n",
      "98 Train Loss 0.10619321 Test MSE 0.0011465361126107914 Test RE 0.024464128320182243\n",
      "99 Train Loss 0.1015676 Test MSE 0.0009891729769931864 Test RE 0.022723331205983133\n",
      "100 Train Loss 0.09818054 Test MSE 0.0008500355445478077 Test RE 0.021064658368542197\n",
      "101 Train Loss 0.09617801 Test MSE 0.0007872828953409891 Test RE 0.02027221879706649\n",
      "102 Train Loss 0.093687624 Test MSE 0.000906394349175694 Test RE 0.0217517634440992\n",
      "103 Train Loss 0.0907192 Test MSE 0.0009422842009231458 Test RE 0.0221782273749827\n",
      "104 Train Loss 0.08743647 Test MSE 0.0010036630448725147 Test RE 0.022889159406014582\n",
      "105 Train Loss 0.08420726 Test MSE 0.0009572703672874574 Test RE 0.02235389386367749\n",
      "106 Train Loss 0.08199961 Test MSE 0.0009011513330056218 Test RE 0.021688760928301277\n",
      "107 Train Loss 0.08013135 Test MSE 0.0008503465159773128 Test RE 0.021068511094453398\n",
      "108 Train Loss 0.07822224 Test MSE 0.0008098085194893316 Test RE 0.02056018639570719\n",
      "109 Train Loss 0.07537197 Test MSE 0.0007551802780778428 Test RE 0.01985460250123954\n",
      "110 Train Loss 0.07208959 Test MSE 0.0007268478365481255 Test RE 0.019478595006036475\n",
      "111 Train Loss 0.07000359 Test MSE 0.0007172453106771012 Test RE 0.01934949948883007\n",
      "112 Train Loss 0.067654714 Test MSE 0.0007363299885088004 Test RE 0.01960523810077226\n",
      "113 Train Loss 0.06627368 Test MSE 0.0007011830194020965 Test RE 0.019131612328157247\n",
      "114 Train Loss 0.06355859 Test MSE 0.0006114843331435096 Test RE 0.017866049960648504\n",
      "115 Train Loss 0.061690077 Test MSE 0.0005915881569883871 Test RE 0.017572988002381124\n",
      "116 Train Loss 0.06029813 Test MSE 0.0005725761494836312 Test RE 0.01728830850118106\n",
      "117 Train Loss 0.05903797 Test MSE 0.0005447112009817701 Test RE 0.016862386124814395\n",
      "118 Train Loss 0.058210965 Test MSE 0.0005235516387156315 Test RE 0.01653162854979724\n",
      "119 Train Loss 0.057090603 Test MSE 0.0004931648548006716 Test RE 0.016044712388256503\n",
      "120 Train Loss 0.05612682 Test MSE 0.0004652105187935543 Test RE 0.015583343357574714\n",
      "121 Train Loss 0.055039357 Test MSE 0.0004149445966271696 Test RE 0.014717394581251656\n",
      "122 Train Loss 0.05387652 Test MSE 0.0003525766811574089 Test RE 0.013566339138549632\n",
      "123 Train Loss 0.052944425 Test MSE 0.0003208944908782554 Test RE 0.01294246524685086\n",
      "124 Train Loss 0.05160494 Test MSE 0.0002966949573172291 Test RE 0.012444887053159876\n",
      "125 Train Loss 0.050206807 Test MSE 0.000294820675629734 Test RE 0.012405516349885225\n",
      "126 Train Loss 0.049205374 Test MSE 0.0002895347812323689 Test RE 0.012293802954542524\n",
      "127 Train Loss 0.048214685 Test MSE 0.0002486073702588361 Test RE 0.011391813772500795\n",
      "128 Train Loss 0.047213014 Test MSE 0.00023946368769718623 Test RE 0.011180357998905746\n",
      "129 Train Loss 0.046102658 Test MSE 0.0002410891199920146 Test RE 0.011218238858450299\n",
      "130 Train Loss 0.045346774 Test MSE 0.00022310628251415027 Test RE 0.010791747536274992\n",
      "131 Train Loss 0.044772115 Test MSE 0.0002057111497812195 Test RE 0.010362505944439862\n",
      "132 Train Loss 0.044210523 Test MSE 0.00019194011568604493 Test RE 0.01000964679435416\n",
      "133 Train Loss 0.043783415 Test MSE 0.00018809684994542834 Test RE 0.009908927210007155\n",
      "134 Train Loss 0.042965747 Test MSE 0.0001757322905618879 Test RE 0.009577709531319955\n",
      "135 Train Loss 0.04247604 Test MSE 0.0001766856721770956 Test RE 0.00960365485129353\n",
      "136 Train Loss 0.04176897 Test MSE 0.0001906839231770753 Test RE 0.009976837904341394\n",
      "137 Train Loss 0.04135042 Test MSE 0.00018792710193755253 Test RE 0.009904455044974088\n",
      "138 Train Loss 0.040910535 Test MSE 0.00019761717555502267 Test RE 0.010156597005598338\n",
      "139 Train Loss 0.040298767 Test MSE 0.0001991098338661278 Test RE 0.010194882668111683\n",
      "140 Train Loss 0.039735336 Test MSE 0.00019120875629206896 Test RE 0.00999055845508925\n",
      "141 Train Loss 0.038889177 Test MSE 0.0001913136581500676 Test RE 0.009993298613177652\n",
      "142 Train Loss 0.038239922 Test MSE 0.0001937852925620062 Test RE 0.010057644557797056\n",
      "143 Train Loss 0.037465796 Test MSE 0.0001906046786525326 Test RE 0.009974764599155058\n",
      "144 Train Loss 0.036880612 Test MSE 0.0001952022424270275 Test RE 0.010094348122129778\n",
      "145 Train Loss 0.036425445 Test MSE 0.00017732194599850217 Test RE 0.0096209314722698\n",
      "146 Train Loss 0.036004595 Test MSE 0.00017174195578636032 Test RE 0.009468345109601156\n",
      "147 Train Loss 0.03518737 Test MSE 0.00016840417801648088 Test RE 0.009375885776857081\n",
      "148 Train Loss 0.03457652 Test MSE 0.00015734041501271837 Test RE 0.009062667001475217\n",
      "149 Train Loss 0.034016445 Test MSE 0.00014508791021600976 Test RE 0.008702649438850903\n",
      "150 Train Loss 0.033548295 Test MSE 0.00014539115943661062 Test RE 0.008711739424740933\n",
      "151 Train Loss 0.033135727 Test MSE 0.0001372405752233389 Test RE 0.008464028981035192\n",
      "152 Train Loss 0.032537334 Test MSE 0.00014417440414408225 Test RE 0.008675209260452212\n",
      "153 Train Loss 0.032145053 Test MSE 0.00014430647674559897 Test RE 0.008679181862893725\n",
      "154 Train Loss 0.031386044 Test MSE 0.00015349991597164643 Test RE 0.008951379050539932\n",
      "155 Train Loss 0.031023383 Test MSE 0.00015146969972141722 Test RE 0.008891985772122664\n",
      "156 Train Loss 0.030572858 Test MSE 0.0001456463842475264 Test RE 0.008719382520544924\n",
      "157 Train Loss 0.03033828 Test MSE 0.0001413203032016233 Test RE 0.008588912080692403\n",
      "158 Train Loss 0.029804546 Test MSE 0.00013859763883488401 Test RE 0.008505773088744917\n",
      "159 Train Loss 0.029315041 Test MSE 0.00013614349894701681 Test RE 0.008430131145257294\n",
      "160 Train Loss 0.028938074 Test MSE 0.00013149232651405858 Test RE 0.008284877314947809\n",
      "161 Train Loss 0.028166048 Test MSE 0.0001346227163990542 Test RE 0.008382914788418235\n",
      "162 Train Loss 0.027739223 Test MSE 0.0001351958649606832 Test RE 0.008400740726906976\n",
      "163 Train Loss 0.027397579 Test MSE 0.00014011143893600245 Test RE 0.008552098091452364\n",
      "164 Train Loss 0.026949499 Test MSE 0.0001400605948065082 Test RE 0.008550546243006288\n",
      "165 Train Loss 0.026652953 Test MSE 0.00014009126287629103 Test RE 0.008551482317839492\n",
      "166 Train Loss 0.02629641 Test MSE 0.00015084120070053567 Test RE 0.008873518667239996\n",
      "167 Train Loss 0.026019875 Test MSE 0.0001608006551272253 Test RE 0.00916177841477671\n",
      "168 Train Loss 0.025634762 Test MSE 0.00015216806900748844 Test RE 0.008912460983862874\n",
      "169 Train Loss 0.025217885 Test MSE 0.0001522861403706878 Test RE 0.008915918024408625\n",
      "170 Train Loss 0.024959432 Test MSE 0.00015604390144357576 Test RE 0.009025250752603952\n",
      "171 Train Loss 0.024643239 Test MSE 0.00014568664714556496 Test RE 0.008720587642635731\n",
      "172 Train Loss 0.024265587 Test MSE 0.00014578997836934784 Test RE 0.008723679721714464\n",
      "173 Train Loss 0.023959905 Test MSE 0.00014979335260401438 Test RE 0.008842644132619778\n",
      "174 Train Loss 0.023723796 Test MSE 0.00015014894617626514 Test RE 0.008853133661899803\n",
      "175 Train Loss 0.023464287 Test MSE 0.00014754231228100175 Test RE 0.008775950593717207\n",
      "176 Train Loss 0.023063894 Test MSE 0.00014686405929397288 Test RE 0.008755755806580149\n",
      "177 Train Loss 0.0227288 Test MSE 0.00014393394926419438 Test RE 0.008667971960259126\n",
      "178 Train Loss 0.022446282 Test MSE 0.00014119016535279298 Test RE 0.008584956527387158\n",
      "179 Train Loss 0.022250801 Test MSE 0.00014099699829645635 Test RE 0.008579081832184345\n",
      "180 Train Loss 0.021963282 Test MSE 0.0001385345502427826 Test RE 0.008503836986754505\n",
      "181 Train Loss 0.021705948 Test MSE 0.00013320687007261717 Test RE 0.00833871611454191\n",
      "182 Train Loss 0.021436598 Test MSE 0.00013802958145765168 Test RE 0.008488324277046313\n",
      "183 Train Loss 0.021158328 Test MSE 0.00012975947207840232 Test RE 0.008230105679952075\n",
      "184 Train Loss 0.020967528 Test MSE 0.00012661222921626819 Test RE 0.00812968474158945\n",
      "185 Train Loss 0.020794753 Test MSE 0.00012733063587643816 Test RE 0.008152716317539926\n",
      "186 Train Loss 0.020644333 Test MSE 0.00013109003287550762 Test RE 0.008272194040253865\n",
      "187 Train Loss 0.020459091 Test MSE 0.00012987607406631058 Test RE 0.008233802640102872\n",
      "188 Train Loss 0.020165611 Test MSE 0.0001283573178391554 Test RE 0.008185518485857626\n",
      "189 Train Loss 0.019820916 Test MSE 0.00013532940055062826 Test RE 0.008404888490599985\n",
      "190 Train Loss 0.01976939 Test MSE 0.0001521954103785328 Test RE 0.008913261637900441\n",
      "191 Train Loss 0.01946564 Test MSE 0.00015670405997658503 Test RE 0.009044321693420712\n",
      "192 Train Loss 0.019302556 Test MSE 0.00014801782271414983 Test RE 0.008790081113638444\n",
      "193 Train Loss 0.018956842 Test MSE 0.00014884073269384677 Test RE 0.008814481620089434\n",
      "194 Train Loss 0.018680664 Test MSE 0.000147248736059443 Test RE 0.008767215156157294\n",
      "195 Train Loss 0.018412171 Test MSE 0.00015200766002276936 Test RE 0.008907762180126856\n",
      "196 Train Loss 0.018323118 Test MSE 0.00015578317418821246 Test RE 0.009017707642638761\n",
      "197 Train Loss 0.018016383 Test MSE 0.00016170429095450212 Test RE 0.009187485128250175\n",
      "198 Train Loss 0.017927954 Test MSE 0.00016027018341369117 Test RE 0.009146653852065308\n",
      "199 Train Loss 0.01770159 Test MSE 0.00015978475004129112 Test RE 0.009132791453839061\n",
      "200 Train Loss 0.017529424 Test MSE 0.0001655702129772638 Test RE 0.009296660695629549\n",
      "201 Train Loss 0.017313981 Test MSE 0.00016461577205637953 Test RE 0.0092698263464895\n",
      "202 Train Loss 0.017009705 Test MSE 0.00016694993083042774 Test RE 0.009335315467795395\n",
      "203 Train Loss 0.016818585 Test MSE 0.00016720886590834697 Test RE 0.009342552080840248\n",
      "204 Train Loss 0.016535869 Test MSE 0.00018034279135722503 Test RE 0.009702536174261556\n",
      "205 Train Loss 0.016387919 Test MSE 0.00019970866162292538 Test RE 0.010210201839624919\n",
      "206 Train Loss 0.016200593 Test MSE 0.0002144495805528447 Test RE 0.010580312067635468\n",
      "207 Train Loss 0.01604263 Test MSE 0.00022473101366127902 Test RE 0.010830970731568463\n",
      "208 Train Loss 0.015807841 Test MSE 0.0002235566224529769 Test RE 0.01080263361462373\n",
      "209 Train Loss 0.015797585 Test MSE 0.0002361528964041424 Test RE 0.011102799959980265\n",
      "210 Train Loss 0.015667025 Test MSE 0.00024396932532044292 Test RE 0.011285050048481715\n",
      "211 Train Loss 0.01553554 Test MSE 0.00024223491792090077 Test RE 0.011244865109315301\n",
      "212 Train Loss 0.015420457 Test MSE 0.00024099146257112246 Test RE 0.01121596655508218\n",
      "213 Train Loss 0.015384709 Test MSE 0.0002359452551051682 Test RE 0.011097917727263469\n",
      "214 Train Loss 0.015270812 Test MSE 0.0002356646692509854 Test RE 0.01109131694810842\n",
      "215 Train Loss 0.015155196 Test MSE 0.00023820931959969179 Test RE 0.011151036855423235\n",
      "216 Train Loss 0.014907842 Test MSE 0.00022565686918265467 Test RE 0.010853258725478111\n",
      "217 Train Loss 0.014881629 Test MSE 0.00023405195285670138 Test RE 0.011053301373845262\n",
      "218 Train Loss 0.014742174 Test MSE 0.0002320517689269018 Test RE 0.011005969845617908\n",
      "219 Train Loss 0.0146795 Test MSE 0.0002311704211836552 Test RE 0.010985049266875057\n",
      "220 Train Loss 0.014614176 Test MSE 0.00022610276166836184 Test RE 0.010863976321313171\n",
      "221 Train Loss 0.014488299 Test MSE 0.00021963063475928968 Test RE 0.010707358289206007\n",
      "222 Train Loss 0.014346894 Test MSE 0.00021585081512918056 Test RE 0.010614822184285192\n",
      "223 Train Loss 0.014265252 Test MSE 0.00019853324045391335 Test RE 0.010180110509643151\n",
      "224 Train Loss 0.014128077 Test MSE 0.0001974517526841345 Test RE 0.01015234513532866\n",
      "225 Train Loss 0.013926617 Test MSE 0.00019142031903480986 Test RE 0.009996083948943508\n",
      "226 Train Loss 0.013734733 Test MSE 0.00018238537862171712 Test RE 0.009757327597027321\n",
      "227 Train Loss 0.013578962 Test MSE 0.00016855160365371552 Test RE 0.00937998883287953\n",
      "228 Train Loss 0.013428333 Test MSE 0.00016397194411837786 Test RE 0.009251681000905386\n",
      "229 Train Loss 0.013280745 Test MSE 0.00016119757370291335 Test RE 0.009173078862339432\n",
      "230 Train Loss 0.013122097 Test MSE 0.0001567208625718306 Test RE 0.009044806569189828\n",
      "231 Train Loss 0.012956747 Test MSE 0.0001524682922699479 Test RE 0.008921248667268082\n",
      "232 Train Loss 0.0128550595 Test MSE 0.00016608631537146077 Test RE 0.009311138830204065\n",
      "233 Train Loss 0.012734839 Test MSE 0.00017488764808306853 Test RE 0.009554664579281252\n",
      "234 Train Loss 0.012651888 Test MSE 0.00018932094965922773 Test RE 0.009941117660711736\n",
      "235 Train Loss 0.012569388 Test MSE 0.00019275650728015444 Test RE 0.010030911553154047\n",
      "236 Train Loss 0.012439635 Test MSE 0.00018739952250769316 Test RE 0.009890542577754357\n",
      "237 Train Loss 0.012332282 Test MSE 0.00019529573732350141 Test RE 0.010096765248695396\n",
      "238 Train Loss 0.012274396 Test MSE 0.00018857257978647162 Test RE 0.009921450002164461\n",
      "239 Train Loss 0.0121729495 Test MSE 0.0001793115698247752 Test RE 0.009674756277167596\n",
      "240 Train Loss 0.012058722 Test MSE 0.00018907669967486263 Test RE 0.009934702888615985\n",
      "241 Train Loss 0.012121248 Test MSE 0.00018451142697965535 Test RE 0.009814032926112529\n",
      "242 Train Loss 0.011987167 Test MSE 0.00019704424697746938 Test RE 0.010141863396600989\n",
      "243 Train Loss 0.011959896 Test MSE 0.00019941176443116535 Test RE 0.010202609510582623\n",
      "244 Train Loss 0.011707153 Test MSE 0.0001916521550324071 Test RE 0.010002135424678583\n",
      "245 Train Loss 0.011510528 Test MSE 0.00017941860751719818 Test RE 0.009677643455870716\n",
      "246 Train Loss 0.011355009 Test MSE 0.00017035937435975102 Test RE 0.00943015638954455\n",
      "247 Train Loss 0.01111459 Test MSE 0.00016324799387371213 Test RE 0.009231234924235398\n",
      "248 Train Loss 0.011074492 Test MSE 0.000160269907452817 Test RE 0.009146645977488686\n",
      "249 Train Loss 0.010863267 Test MSE 0.00014617652204358398 Test RE 0.008735236932455056\n",
      "250 Train Loss 0.010618843 Test MSE 0.00011101792803989589 Test RE 0.007612589923235745\n",
      "251 Train Loss 0.010524426 Test MSE 0.00011126067971698134 Test RE 0.007620908218823915\n",
      "252 Train Loss 0.010437587 Test MSE 0.0001004185658517907 Test RE 0.00724007198460436\n",
      "253 Train Loss 0.0102758175 Test MSE 9.893911400007129e-05 Test RE 0.007186540631727607\n",
      "254 Train Loss 0.010089822 Test MSE 9.697920020104759e-05 Test RE 0.007115004448479237\n",
      "255 Train Loss 0.009936366 Test MSE 9.650052849581592e-05 Test RE 0.00709742354323886\n",
      "256 Train Loss 0.009828412 Test MSE 9.54005361350697e-05 Test RE 0.007056856473395311\n",
      "257 Train Loss 0.009761827 Test MSE 9.471723348314102e-05 Test RE 0.007031538826923207\n",
      "258 Train Loss 0.009683131 Test MSE 9.190692431418995e-05 Test RE 0.00692643867101728\n",
      "259 Train Loss 0.009615168 Test MSE 9.121639763832659e-05 Test RE 0.0069003693162349306\n",
      "260 Train Loss 0.009501907 Test MSE 8.907230155223094e-05 Test RE 0.00681878840558173\n",
      "261 Train Loss 0.0094209295 Test MSE 9.141696474387185e-05 Test RE 0.006907951435198456\n",
      "262 Train Loss 0.009347058 Test MSE 9.151074460520834e-05 Test RE 0.006911493779181543\n",
      "263 Train Loss 0.009256336 Test MSE 8.772262916174364e-05 Test RE 0.006766930197895219\n",
      "264 Train Loss 0.009153715 Test MSE 8.319925452884016e-05 Test RE 0.006590154470453913\n",
      "265 Train Loss 0.009187629 Test MSE 7.974926415501215e-05 Test RE 0.00645207220841853\n",
      "266 Train Loss 0.009151997 Test MSE 7.61560327705405e-05 Test RE 0.006305042711825799\n",
      "267 Train Loss 0.009050656 Test MSE 7.546015089224154e-05 Test RE 0.006276170186610481\n",
      "268 Train Loss 0.008890392 Test MSE 8.074781389616549e-05 Test RE 0.00649234012115293\n",
      "269 Train Loss 0.008785394 Test MSE 8.652575218805607e-05 Test RE 0.006720608062039934\n",
      "270 Train Loss 0.008674779 Test MSE 8.422105453917577e-05 Test RE 0.00663049900731432\n",
      "271 Train Loss 0.008513797 Test MSE 8.357448861658033e-05 Test RE 0.006604998766265199\n",
      "272 Train Loss 0.008360651 Test MSE 7.448744517448532e-05 Test RE 0.006235588052804621\n",
      "273 Train Loss 0.008268024 Test MSE 7.832010296476072e-05 Test RE 0.006393998083574789\n",
      "274 Train Loss 0.00818935 Test MSE 8.053765393565712e-05 Test RE 0.006483885905334518\n",
      "275 Train Loss 0.008158495 Test MSE 8.026010228373921e-05 Test RE 0.006472703766883502\n",
      "276 Train Loss 0.008062836 Test MSE 7.599729135473177e-05 Test RE 0.006298468094723214\n",
      "277 Train Loss 0.008009431 Test MSE 7.12516247802263e-05 Test RE 0.006098643722484324\n",
      "278 Train Loss 0.0079273535 Test MSE 6.801592951448561e-05 Test RE 0.005958558337432789\n",
      "279 Train Loss 0.007888796 Test MSE 6.745574195290425e-05 Test RE 0.005933969894705195\n",
      "280 Train Loss 0.007850184 Test MSE 6.60183228398026e-05 Test RE 0.005870405758824198\n",
      "281 Train Loss 0.0077733058 Test MSE 6.340060688626098e-05 Test RE 0.005752843828060739\n",
      "282 Train Loss 0.0076606753 Test MSE 6.202347193677559e-05 Test RE 0.005690021581335448\n",
      "283 Train Loss 0.0075463336 Test MSE 6.0810903175438886e-05 Test RE 0.0056341266297172884\n",
      "284 Train Loss 0.0075372593 Test MSE 5.811158971079147e-05 Test RE 0.00550766168106213\n",
      "285 Train Loss 0.0075321114 Test MSE 5.840026985826451e-05 Test RE 0.005521324901146284\n",
      "286 Train Loss 0.007465129 Test MSE 6.234166039128184e-05 Test RE 0.005704598184594134\n",
      "287 Train Loss 0.0073888404 Test MSE 6.198013122711179e-05 Test RE 0.005688033199662335\n",
      "288 Train Loss 0.0072967 Test MSE 6.160094721967994e-05 Test RE 0.005670607291862356\n",
      "289 Train Loss 0.007247547 Test MSE 6.0442182102012636e-05 Test RE 0.005617019665715244\n",
      "290 Train Loss 0.0072181444 Test MSE 5.882474973128505e-05 Test RE 0.0055413543286719005\n",
      "291 Train Loss 0.0071437876 Test MSE 5.7575500307835596e-05 Test RE 0.005482198256060171\n",
      "292 Train Loss 0.00706945 Test MSE 5.5710561882309154e-05 Test RE 0.005392679951277163\n",
      "293 Train Loss 0.0070242444 Test MSE 5.418637416651191e-05 Test RE 0.00531839908034568\n",
      "294 Train Loss 0.006970703 Test MSE 5.3847038331427796e-05 Test RE 0.005301720000316499\n",
      "295 Train Loss 0.006951799 Test MSE 5.432740704049627e-05 Test RE 0.005325315779375729\n",
      "296 Train Loss 0.0069385064 Test MSE 5.501740493443845e-05 Test RE 0.005359026785530877\n",
      "297 Train Loss 0.006902644 Test MSE 5.490844803496444e-05 Test RE 0.005353717626351615\n",
      "298 Train Loss 0.006891765 Test MSE 5.545381172033078e-05 Test RE 0.005380239129105693\n",
      "299 Train Loss 0.006850565 Test MSE 5.7126582108979e-05 Test RE 0.005460783986210204\n",
      "Training time: 252.68\n",
      "KG_tanhALR_high\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 53130.805 Test MSE 6.465875019595121 Test RE 1.8371707816418905\n",
      "1 Train Loss 27281.023 Test MSE 12.196918929324374 Test RE 2.5232538551945938\n",
      "2 Train Loss 12865.672 Test MSE 11.04984768506456 Test RE 2.4016738129402047\n",
      "3 Train Loss 5155.124 Test MSE 12.702658379772704 Test RE 2.5750352951384503\n",
      "4 Train Loss 1954.9288 Test MSE 14.74068155959285 Test RE 2.7739246447957755\n",
      "5 Train Loss 1255.4333 Test MSE 14.57151040895608 Test RE 2.757961265145661\n",
      "6 Train Loss 1028.261 Test MSE 15.637318023347605 Test RE 2.857044542367838\n",
      "7 Train Loss 882.761 Test MSE 15.488943078896792 Test RE 2.8434576791304753\n",
      "8 Train Loss 727.0053 Test MSE 14.951947638673355 Test RE 2.7937321177771035\n",
      "9 Train Loss 553.5098 Test MSE 12.900378918139806 Test RE 2.5949984950836096\n",
      "10 Train Loss 385.678 Test MSE 11.138682834044214 Test RE 2.411308604281795\n",
      "11 Train Loss 258.00885 Test MSE 9.900628894170675 Test RE 2.2733550464455665\n",
      "12 Train Loss 207.05408 Test MSE 10.15246599934152 Test RE 2.3020865567364024\n",
      "13 Train Loss 173.05386 Test MSE 9.946370525408062 Test RE 2.27860052827885\n",
      "14 Train Loss 155.1343 Test MSE 8.307742557999168 Test RE 2.082463470267585\n",
      "15 Train Loss 97.857574 Test MSE 6.11646767651191 Test RE 1.786842276905266\n",
      "16 Train Loss 53.27366 Test MSE 3.3456308973122737 Test RE 1.3215234989070004\n",
      "17 Train Loss 32.40532 Test MSE 2.280174328870865 Test RE 1.0909878219517974\n",
      "18 Train Loss 19.72486 Test MSE 0.9949910033763939 Test RE 0.7206849517060602\n",
      "19 Train Loss 13.153978 Test MSE 0.5085444731134368 Test RE 0.5152290553749856\n",
      "20 Train Loss 7.504674 Test MSE 0.16193888554699506 Test RE 0.2907444611884896\n",
      "21 Train Loss 5.7801538 Test MSE 0.10413609484551997 Test RE 0.2331505909618319\n",
      "22 Train Loss 4.407149 Test MSE 0.07367603367995738 Test RE 0.19610966407669322\n",
      "23 Train Loss 3.493097 Test MSE 0.055418690546681686 Test RE 0.17008421379103517\n",
      "24 Train Loss 2.711206 Test MSE 0.03028924152021389 Test RE 0.1257419166781648\n",
      "25 Train Loss 2.1192434 Test MSE 0.022101519737545552 Test RE 0.10741055129762428\n",
      "26 Train Loss 1.7893995 Test MSE 0.02098627242235125 Test RE 0.10466549457621509\n",
      "27 Train Loss 1.4536726 Test MSE 0.012554330989486183 Test RE 0.0809529471389785\n",
      "28 Train Loss 1.2142949 Test MSE 0.008195020207551654 Test RE 0.06540499115969962\n",
      "29 Train Loss 1.0640384 Test MSE 0.006500458311701931 Test RE 0.058251600934140724\n",
      "30 Train Loss 0.9112854 Test MSE 0.00602417736330767 Test RE 0.056076997425821964\n",
      "31 Train Loss 0.760175 Test MSE 0.006317228487426953 Test RE 0.05742475744532269\n",
      "32 Train Loss 0.64547646 Test MSE 0.0036652549706786266 Test RE 0.043740925973031315\n",
      "33 Train Loss 0.55294305 Test MSE 0.003516562872048294 Test RE 0.04284449913293327\n",
      "34 Train Loss 0.48261136 Test MSE 0.0042321976129029715 Test RE 0.047002271397790396\n",
      "35 Train Loss 0.4217719 Test MSE 0.0028357946388327757 Test RE 0.038474524880207014\n",
      "36 Train Loss 0.3620738 Test MSE 0.002155718552214784 Test RE 0.03354531748438056\n",
      "37 Train Loss 0.33255544 Test MSE 0.002077940305210644 Test RE 0.03293460130715402\n",
      "38 Train Loss 0.30281892 Test MSE 0.0021108631227812645 Test RE 0.03319448332974437\n",
      "39 Train Loss 0.2793031 Test MSE 0.0017721794841852822 Test RE 0.03041513365103249\n",
      "40 Train Loss 0.24767202 Test MSE 0.001277630309984581 Test RE 0.025824889981959635\n",
      "41 Train Loss 0.22001636 Test MSE 0.001223306117619687 Test RE 0.025269895775324205\n",
      "42 Train Loss 0.20499273 Test MSE 0.0009776992888715795 Test RE 0.02259115974552821\n",
      "43 Train Loss 0.18507534 Test MSE 0.0009441081159688045 Test RE 0.02219968143673034\n",
      "44 Train Loss 0.17388736 Test MSE 0.0008202597427658526 Test RE 0.020692433856092526\n",
      "45 Train Loss 0.16315891 Test MSE 0.0007248235305878687 Test RE 0.01945145168501896\n",
      "46 Train Loss 0.15619576 Test MSE 0.0006863684453868624 Test RE 0.01892842730833599\n",
      "47 Train Loss 0.14906016 Test MSE 0.0006266693370210197 Test RE 0.018086523603206152\n",
      "48 Train Loss 0.14092332 Test MSE 0.00047774460083756346 Test RE 0.015791877655002694\n",
      "49 Train Loss 0.13162777 Test MSE 0.00047635382597777787 Test RE 0.015768874826787654\n",
      "50 Train Loss 0.120927885 Test MSE 0.0004669116227977647 Test RE 0.015611808641143329\n",
      "51 Train Loss 0.11455455 Test MSE 0.00043994524406805214 Test RE 0.015154275924964478\n",
      "52 Train Loss 0.10640743 Test MSE 0.00023763874578364334 Test RE 0.011137674019347071\n",
      "53 Train Loss 0.102397464 Test MSE 0.00018863307415141464 Test RE 0.009923041282535091\n",
      "54 Train Loss 0.09757824 Test MSE 0.00022482973775483084 Test RE 0.010833349487270631\n",
      "55 Train Loss 0.091990665 Test MSE 0.0002880762984055324 Test RE 0.012262799878365906\n",
      "56 Train Loss 0.08919393 Test MSE 0.0002633874033544423 Test RE 0.011725554167002238\n",
      "57 Train Loss 0.08627635 Test MSE 0.0002734167676630521 Test RE 0.011946713513363372\n",
      "58 Train Loss 0.08367349 Test MSE 0.00019571638518326101 Test RE 0.010107633120689165\n",
      "59 Train Loss 0.08036068 Test MSE 0.0001452646359688334 Test RE 0.008707947999626119\n",
      "60 Train Loss 0.077354416 Test MSE 0.0001320858601169144 Test RE 0.008303554513383783\n",
      "61 Train Loss 0.07433257 Test MSE 0.00012744685849097723 Test RE 0.00815643621527186\n",
      "62 Train Loss 0.07129609 Test MSE 0.00014210516392608742 Test RE 0.008612729486520568\n",
      "63 Train Loss 0.06773966 Test MSE 0.00013136436033218295 Test RE 0.008280844980098073\n",
      "64 Train Loss 0.06551362 Test MSE 0.00011117944798796278 Test RE 0.007618125687796685\n",
      "65 Train Loss 0.06376792 Test MSE 0.00010228527883946058 Test RE 0.0073070561328213565\n",
      "66 Train Loss 0.061770316 Test MSE 7.496502373382498e-05 Test RE 0.006255545946617193\n",
      "67 Train Loss 0.059041757 Test MSE 5.751241189712113e-05 Test RE 0.005479193870772428\n",
      "68 Train Loss 0.05727074 Test MSE 7.071807789577937e-05 Test RE 0.0060757668633671675\n",
      "69 Train Loss 0.054645155 Test MSE 6.993221126109305e-05 Test RE 0.006041913555590257\n",
      "70 Train Loss 0.05158467 Test MSE 5.609479013882336e-05 Test RE 0.0054112442916994154\n",
      "71 Train Loss 0.04873527 Test MSE 3.897604932301371e-05 Test RE 0.004510604875464469\n",
      "72 Train Loss 0.04623956 Test MSE 4.0057677284898344e-05 Test RE 0.0045727636900204345\n",
      "73 Train Loss 0.044119425 Test MSE 6.541986102894852e-05 Test RE 0.005843737315130862\n",
      "74 Train Loss 0.042828865 Test MSE 5.38185719869828e-05 Test RE 0.005300318432618916\n",
      "75 Train Loss 0.041088935 Test MSE 7.009226628300416e-05 Test RE 0.006048823718318049\n",
      "76 Train Loss 0.040188015 Test MSE 7.330534967013745e-05 Test RE 0.00618591163320874\n",
      "77 Train Loss 0.03958286 Test MSE 7.439187233058304e-05 Test RE 0.006231586410865222\n",
      "78 Train Loss 0.03864055 Test MSE 4.400687884615487e-05 Test RE 0.004792875641711329\n",
      "79 Train Loss 0.03760613 Test MSE 4.000130232412552e-05 Test RE 0.004569544829684101\n",
      "80 Train Loss 0.036846116 Test MSE 4.9278348847985246e-05 Test RE 0.005071821387125776\n",
      "81 Train Loss 0.03598803 Test MSE 6.225137494199048e-05 Test RE 0.005700465885119474\n",
      "82 Train Loss 0.03490211 Test MSE 7.220557743681336e-05 Test RE 0.0061393338380228675\n",
      "83 Train Loss 0.033277627 Test MSE 5.8286742288161165e-05 Test RE 0.005515955683446759\n",
      "84 Train Loss 0.03247262 Test MSE 6.34606841764907e-05 Test RE 0.005755568829045105\n",
      "85 Train Loss 0.031229086 Test MSE 5.610127955722575e-05 Test RE 0.0054115572870119056\n",
      "86 Train Loss 0.02965557 Test MSE 6.134598699570316e-05 Test RE 0.005658860082941054\n",
      "87 Train Loss 0.028653366 Test MSE 5.795511996648169e-05 Test RE 0.005500241790255805\n",
      "88 Train Loss 0.028013602 Test MSE 6.240539926956646e-05 Test RE 0.0057075136651578194\n",
      "89 Train Loss 0.02735692 Test MSE 7.776006517086634e-05 Test RE 0.006371096524335007\n",
      "90 Train Loss 0.026535243 Test MSE 5.219823789338437e-05 Test RE 0.005219919410711039\n",
      "91 Train Loss 0.025507223 Test MSE 4.9306593558859525e-05 Test RE 0.005073274678592263\n",
      "92 Train Loss 0.024920415 Test MSE 4.712813420094192e-05 Test RE 0.004959935171406227\n",
      "93 Train Loss 0.02392096 Test MSE 5.0854539001469466e-05 Test RE 0.0051522951985152705\n",
      "94 Train Loss 0.023324525 Test MSE 5.0131354869889935e-05 Test RE 0.005115529553109422\n",
      "95 Train Loss 0.022826035 Test MSE 5.3238961777011576e-05 Test RE 0.005271699734068551\n",
      "96 Train Loss 0.02176837 Test MSE 4.897923766818805e-05 Test RE 0.005056405412679394\n",
      "97 Train Loss 0.02120196 Test MSE 4.9714771056242596e-05 Test RE 0.0050942305828973545\n",
      "98 Train Loss 0.020493718 Test MSE 4.316462388668168e-05 Test RE 0.00474678823646395\n",
      "99 Train Loss 0.020051371 Test MSE 4.1698942858919154e-05 Test RE 0.004665502208965267\n",
      "100 Train Loss 0.019794162 Test MSE 4.180995137317803e-05 Test RE 0.004671708196494222\n",
      "101 Train Loss 0.01916072 Test MSE 4.409342605074967e-05 Test RE 0.004797586339798577\n",
      "102 Train Loss 0.018728718 Test MSE 4.533900182354526e-05 Test RE 0.004864876885780289\n",
      "103 Train Loss 0.018418951 Test MSE 4.371485084988485e-05 Test RE 0.004776946499996284\n",
      "104 Train Loss 0.018076736 Test MSE 4.4555689822899374e-05 Test RE 0.00482266908172682\n",
      "105 Train Loss 0.017812282 Test MSE 4.23164562145215e-05 Test RE 0.004699920612291617\n",
      "106 Train Loss 0.017576698 Test MSE 4.286300909110689e-05 Test RE 0.004730174963476487\n",
      "107 Train Loss 0.017251674 Test MSE 4.328239498374848e-05 Test RE 0.004753259434488773\n",
      "108 Train Loss 0.0170416 Test MSE 4.172079213644982e-05 Test RE 0.004666724356288748\n",
      "109 Train Loss 0.016865598 Test MSE 4.2478151454796325e-05 Test RE 0.004708891474684571\n",
      "110 Train Loss 0.01630457 Test MSE 4.521490201480589e-05 Test RE 0.004858214366108987\n",
      "111 Train Loss 0.01582742 Test MSE 4.019970984562976e-05 Test RE 0.004580863343846932\n",
      "112 Train Loss 0.01517965 Test MSE 3.6654579116472616e-05 Test RE 0.004374213689874937\n",
      "113 Train Loss 0.014768901 Test MSE 3.54525194616543e-05 Test RE 0.004301891265213182\n",
      "114 Train Loss 0.014386739 Test MSE 3.7253851486270006e-05 Test RE 0.004409826128393246\n",
      "115 Train Loss 0.013850603 Test MSE 3.380766629607108e-05 Test RE 0.004200910928886479\n",
      "116 Train Loss 0.013572318 Test MSE 3.574106393109949e-05 Test RE 0.004319362117785548\n",
      "117 Train Loss 0.013378617 Test MSE 3.799074863816549e-05 Test RE 0.004453226684527551\n",
      "118 Train Loss 0.013062558 Test MSE 3.6804821866359374e-05 Test RE 0.0043831692125678515\n",
      "119 Train Loss 0.012827196 Test MSE 3.4175799361733365e-05 Test RE 0.004223720947950842\n",
      "120 Train Loss 0.0126189245 Test MSE 3.946253501947979e-05 Test RE 0.004538667492501926\n",
      "121 Train Loss 0.012350902 Test MSE 3.772031845574956e-05 Test RE 0.004437348638771452\n",
      "122 Train Loss 0.012066342 Test MSE 4.021505525057494e-05 Test RE 0.004581737585180093\n",
      "123 Train Loss 0.011684454 Test MSE 3.3719511356888846e-05 Test RE 0.004195430326158932\n",
      "124 Train Loss 0.011455306 Test MSE 3.10784134730616e-05 Test RE 0.004027775882011455\n",
      "125 Train Loss 0.011302384 Test MSE 2.9413921676113317e-05 Test RE 0.003918432254784636\n",
      "126 Train Loss 0.011178379 Test MSE 2.8852269253196146e-05 Test RE 0.0038808411364283945\n",
      "127 Train Loss 0.011144474 Test MSE 2.968068534218193e-05 Test RE 0.003936160866894611\n",
      "128 Train Loss 0.010981517 Test MSE 3.160188780846335e-05 Test RE 0.004061555483527902\n",
      "129 Train Loss 0.010850502 Test MSE 3.2838720138466315e-05 Test RE 0.004140273092619673\n",
      "130 Train Loss 0.010673501 Test MSE 3.0085400698932907e-05 Test RE 0.003962906054240869\n",
      "131 Train Loss 0.010503929 Test MSE 2.74081168985473e-05 Test RE 0.003782469857904127\n",
      "132 Train Loss 0.010198667 Test MSE 2.7787739960851392e-05 Test RE 0.003808574803675919\n",
      "133 Train Loss 0.0099692745 Test MSE 2.7429764996255766e-05 Test RE 0.0037839633409300476\n",
      "134 Train Loss 0.009784831 Test MSE 2.7128333758531075e-05 Test RE 0.003763114535360761\n",
      "135 Train Loss 0.009659006 Test MSE 2.6114571865489622e-05 Test RE 0.0036921329572488126\n",
      "136 Train Loss 0.0094794305 Test MSE 2.611630914221185e-05 Test RE 0.0036922557651202417\n",
      "137 Train Loss 0.009260455 Test MSE 2.6677033213430997e-05 Test RE 0.003731682119798441\n",
      "138 Train Loss 0.009098716 Test MSE 2.5737445586371506e-05 Test RE 0.003665376554917348\n",
      "139 Train Loss 0.009009598 Test MSE 2.5153345688907066e-05 Test RE 0.0036235458138038175\n",
      "140 Train Loss 0.008853985 Test MSE 2.757132807164633e-05 Test RE 0.0037937151584798716\n",
      "141 Train Loss 0.008746313 Test MSE 2.7437992981267526e-05 Test RE 0.003784530827731284\n",
      "142 Train Loss 0.008610092 Test MSE 2.72194286714309e-05 Test RE 0.0037694273686765395\n",
      "143 Train Loss 0.008450078 Test MSE 2.768851457315366e-05 Test RE 0.003801768829590121\n",
      "144 Train Loss 0.008355779 Test MSE 3.023667006812492e-05 Test RE 0.00397285630659769\n",
      "145 Train Loss 0.008254437 Test MSE 2.9508619398644004e-05 Test RE 0.003924734855867924\n",
      "146 Train Loss 0.008141546 Test MSE 3.388788289364131e-05 Test RE 0.00420589179805732\n",
      "147 Train Loss 0.008019838 Test MSE 3.39238438472136e-05 Test RE 0.004208122798682765\n",
      "148 Train Loss 0.007895686 Test MSE 3.415855409402511e-05 Test RE 0.004222655158841272\n",
      "149 Train Loss 0.007769796 Test MSE 3.6891298294934356e-05 Test RE 0.0043883155278222705\n",
      "150 Train Loss 0.00765083 Test MSE 3.602055982460276e-05 Test RE 0.004336217981278051\n",
      "151 Train Loss 0.007552941 Test MSE 3.412738191188741e-05 Test RE 0.004220727978032838\n",
      "152 Train Loss 0.007436281 Test MSE 3.861584049293888e-05 Test RE 0.004489713442050924\n",
      "153 Train Loss 0.007312648 Test MSE 4.246891188061449e-05 Test RE 0.004708379322945794\n",
      "154 Train Loss 0.0071590827 Test MSE 4.1931935547794164e-05 Test RE 0.004678518290626842\n",
      "155 Train Loss 0.007029167 Test MSE 4.334517125190772e-05 Test RE 0.00475670522083432\n",
      "156 Train Loss 0.0069168387 Test MSE 4.2156347082977255e-05 Test RE 0.004691020843534176\n",
      "157 Train Loss 0.006817666 Test MSE 3.9478976440942124e-05 Test RE 0.004539612874928306\n",
      "158 Train Loss 0.006755331 Test MSE 4.103954440832892e-05 Test RE 0.0046284666877188275\n",
      "159 Train Loss 0.006671292 Test MSE 4.024624882323263e-05 Test RE 0.004583514196691784\n",
      "160 Train Loss 0.0065909876 Test MSE 4.0085669831184185e-05 Test RE 0.004574361148402476\n",
      "161 Train Loss 0.006473181 Test MSE 3.976473676863692e-05 Test RE 0.004556012771588646\n",
      "162 Train Loss 0.006376053 Test MSE 4.2689233242251926e-05 Test RE 0.004720576652353581\n",
      "163 Train Loss 0.0062994044 Test MSE 3.9774796150963667e-05 Test RE 0.004556589007972581\n",
      "164 Train Loss 0.006178842 Test MSE 3.982150922670484e-05 Test RE 0.004559263940960328\n",
      "165 Train Loss 0.006145581 Test MSE 4.094769079128133e-05 Test RE 0.004623284130694637\n",
      "166 Train Loss 0.006081648 Test MSE 4.227693306945789e-05 Test RE 0.004697725260240531\n",
      "167 Train Loss 0.0059540677 Test MSE 4.142919379647261e-05 Test RE 0.0046503872361047935\n",
      "168 Train Loss 0.0058650123 Test MSE 4.064511443750532e-05 Test RE 0.004606170952274074\n",
      "169 Train Loss 0.0058077765 Test MSE 3.967282311949768e-05 Test RE 0.004550744259112648\n",
      "170 Train Loss 0.0057464377 Test MSE 4.0017884712149074e-05 Test RE 0.004570491875276738\n",
      "171 Train Loss 0.005686968 Test MSE 3.994334861494983e-05 Test RE 0.004566233461746816\n",
      "172 Train Loss 0.0056168684 Test MSE 3.9544298194266784e-05 Test RE 0.004543366935176373\n",
      "173 Train Loss 0.00558316 Test MSE 3.843995503881736e-05 Test RE 0.004479477014145516\n",
      "174 Train Loss 0.005525328 Test MSE 3.795810493306487e-05 Test RE 0.004451313046804249\n",
      "175 Train Loss 0.005485667 Test MSE 3.748122903173099e-05 Test RE 0.004423263264064898\n",
      "176 Train Loss 0.0054136585 Test MSE 3.9053918969811225e-05 Test RE 0.004515108461073787\n",
      "177 Train Loss 0.0053479867 Test MSE 3.986154852389076e-05 Test RE 0.004561555464604874\n",
      "178 Train Loss 0.0052679954 Test MSE 4.4135537342835385e-05 Test RE 0.004799876753167739\n",
      "179 Train Loss 0.005173417 Test MSE 4.048776692354501e-05 Test RE 0.004597246480528593\n",
      "180 Train Loss 0.00512736 Test MSE 3.90334214432199e-05 Test RE 0.004513923423759398\n",
      "181 Train Loss 0.0050591757 Test MSE 3.571039929626537e-05 Test RE 0.004317508786218822\n",
      "182 Train Loss 0.0050054314 Test MSE 3.547736454942852e-05 Test RE 0.004303398381615081\n",
      "183 Train Loss 0.004959937 Test MSE 3.354759185046072e-05 Test RE 0.004184721422130463\n",
      "184 Train Loss 0.004906364 Test MSE 3.1811072594366585e-05 Test RE 0.004074975793609334\n",
      "185 Train Loss 0.0048868824 Test MSE 2.912081312238104e-05 Test RE 0.0038988598627847323\n",
      "186 Train Loss 0.004830994 Test MSE 2.7753496399134583e-05 Test RE 0.0038062273768782766\n",
      "187 Train Loss 0.004775985 Test MSE 2.6586977504067364e-05 Test RE 0.003725378132156157\n",
      "188 Train Loss 0.004730062 Test MSE 2.7242872745714867e-05 Test RE 0.0037710503218267195\n",
      "189 Train Loss 0.0046958295 Test MSE 2.8452992778749046e-05 Test RE 0.003853894784016265\n",
      "190 Train Loss 0.004645221 Test MSE 2.85237590350792e-05 Test RE 0.003858684374040061\n",
      "191 Train Loss 0.0046120016 Test MSE 2.8484758545214597e-05 Test RE 0.0038560454852243284\n",
      "192 Train Loss 0.0045817248 Test MSE 2.7687521131876246e-05 Test RE 0.003801700626798842\n",
      "193 Train Loss 0.004563479 Test MSE 2.8759927654563032e-05 Test RE 0.0038746258494057858\n",
      "194 Train Loss 0.004533052 Test MSE 2.7073943453881564e-05 Test RE 0.0037593402593336643\n",
      "195 Train Loss 0.0045338036 Test MSE 2.4569164022234313e-05 Test RE 0.0035812205400509597\n",
      "196 Train Loss 0.004486686 Test MSE 2.4696093453675922e-05 Test RE 0.0035904592896339907\n",
      "197 Train Loss 0.0044645015 Test MSE 2.4099186869213274e-05 Test RE 0.00354680303598184\n",
      "198 Train Loss 0.0044143996 Test MSE 2.441358169213535e-05 Test RE 0.0035698636313270175\n",
      "199 Train Loss 0.0043798927 Test MSE 2.4204291301206102e-05 Test RE 0.0035545290050247908\n",
      "200 Train Loss 0.004360418 Test MSE 2.4901129740789605e-05 Test RE 0.003605333155290998\n",
      "201 Train Loss 0.0043326626 Test MSE 2.578676430788856e-05 Test RE 0.0036688867161735346\n",
      "202 Train Loss 0.0043000397 Test MSE 2.6660296611127616e-05 Test RE 0.0037305113472095876\n",
      "203 Train Loss 0.0042414363 Test MSE 2.776566013423262e-05 Test RE 0.00380706137755955\n",
      "204 Train Loss 0.0042353864 Test MSE 2.791707912707589e-05 Test RE 0.003817428096822601\n",
      "205 Train Loss 0.004223698 Test MSE 2.7370717112450053e-05 Test RE 0.0037798882895377067\n",
      "206 Train Loss 0.0041848514 Test MSE 2.7533006380327787e-05 Test RE 0.0037910777785742505\n",
      "207 Train Loss 0.0041404488 Test MSE 2.7508064039006985e-05 Test RE 0.0037893602076778227\n",
      "208 Train Loss 0.0040964466 Test MSE 2.872107099943088e-05 Test RE 0.0038720075207168796\n",
      "209 Train Loss 0.004057237 Test MSE 2.743913211306426e-05 Test RE 0.0037846093873158027\n",
      "210 Train Loss 0.00402864 Test MSE 2.588933901410858e-05 Test RE 0.0036761765309857738\n",
      "211 Train Loss 0.0040051467 Test MSE 2.5795845242025585e-05 Test RE 0.0036695326674368606\n",
      "212 Train Loss 0.0039876266 Test MSE 2.4067756881305354e-05 Test RE 0.0035444894237549552\n",
      "213 Train Loss 0.003960101 Test MSE 2.451809266721449e-05 Test RE 0.003577496503475958\n",
      "214 Train Loss 0.0039504636 Test MSE 2.366008860199952e-05 Test RE 0.003514342302683579\n",
      "215 Train Loss 0.003948621 Test MSE 2.325531767728955e-05 Test RE 0.0034841513728893535\n",
      "216 Train Loss 0.0039055697 Test MSE 2.3637472184760256e-05 Test RE 0.0035126622406134174\n",
      "217 Train Loss 0.0038817483 Test MSE 2.2586946387284912e-05 Test RE 0.00343371809719522\n",
      "218 Train Loss 0.003849349 Test MSE 2.2658288462705707e-05 Test RE 0.0034391366128187044\n",
      "219 Train Loss 0.0038284657 Test MSE 2.357430083993557e-05 Test RE 0.0035079652905440815\n",
      "220 Train Loss 0.0038012003 Test MSE 2.3783144852819907e-05 Test RE 0.0035234695072272576\n",
      "221 Train Loss 0.00377278 Test MSE 2.402065405295067e-05 Test RE 0.003541019278102842\n",
      "222 Train Loss 0.003758126 Test MSE 2.3779844993313205e-05 Test RE 0.0035232250618909998\n",
      "223 Train Loss 0.003751897 Test MSE 2.4626440025658083e-05 Test RE 0.0035853924075863576\n",
      "224 Train Loss 0.0037215564 Test MSE 2.4247312733382837e-05 Test RE 0.003557686565710433\n",
      "225 Train Loss 0.003701519 Test MSE 2.424669105378321e-05 Test RE 0.003557640957453529\n",
      "226 Train Loss 0.00366972 Test MSE 2.459150526737432e-05 Test RE 0.0035828484087431656\n",
      "227 Train Loss 0.0036247019 Test MSE 2.4029881575124275e-05 Test RE 0.0035416993531838786\n",
      "228 Train Loss 0.0035947268 Test MSE 2.3152009326009137e-05 Test RE 0.0034764038422666482\n",
      "229 Train Loss 0.0035706507 Test MSE 2.4130134238000196e-05 Test RE 0.0035490796481739513\n",
      "230 Train Loss 0.0035378542 Test MSE 2.4627886127751075e-05 Test RE 0.0035854976758944476\n",
      "231 Train Loss 0.0035098223 Test MSE 2.513778062643116e-05 Test RE 0.0036224245028326657\n",
      "232 Train Loss 0.0034741114 Test MSE 2.5647065646803193e-05 Test RE 0.003658935203718071\n",
      "233 Train Loss 0.0034877819 Test MSE 2.634290634032084e-05 Test RE 0.0037082390312841284\n",
      "234 Train Loss 0.0034335502 Test MSE 2.5213001844963903e-05 Test RE 0.0036278402483961346\n",
      "235 Train Loss 0.0034077438 Test MSE 2.481529394897974e-05 Test RE 0.003599113883759679\n",
      "236 Train Loss 0.0033635448 Test MSE 2.639298219864171e-05 Test RE 0.0037117618978681484\n",
      "237 Train Loss 0.0033237627 Test MSE 2.5872743569488543e-05 Test RE 0.0036749981006702066\n",
      "238 Train Loss 0.0032967257 Test MSE 2.48229523230822e-05 Test RE 0.003599669211339654\n",
      "239 Train Loss 0.0032698228 Test MSE 2.4452078116395716e-05 Test RE 0.00357267708275043\n",
      "240 Train Loss 0.003249664 Test MSE 2.3379894911115835e-05 Test RE 0.0034934710951361036\n",
      "241 Train Loss 0.0032257051 Test MSE 2.267769392095636e-05 Test RE 0.003440609004233234\n",
      "242 Train Loss 0.0032100128 Test MSE 2.199810581734169e-05 Test RE 0.0033886640890242238\n",
      "243 Train Loss 0.0031870098 Test MSE 2.2488621607122345e-05 Test RE 0.0034262361693177595\n",
      "244 Train Loss 0.0031745094 Test MSE 2.2393286753271007e-05 Test RE 0.00341896612310008\n",
      "245 Train Loss 0.003158048 Test MSE 2.3280737898435118e-05 Test RE 0.003486055103245084\n",
      "246 Train Loss 0.003146714 Test MSE 2.2707720122700567e-05 Test RE 0.0034428860048601917\n",
      "247 Train Loss 0.0031116714 Test MSE 2.0359490945320417e-05 Test RE 0.003260013018621345\n",
      "248 Train Loss 0.00307537 Test MSE 2.0404511910977393e-05 Test RE 0.0032636154634603284\n",
      "249 Train Loss 0.0030433277 Test MSE 1.9904221781675393e-05 Test RE 0.0032233575187549076\n",
      "250 Train Loss 0.0030221983 Test MSE 2.0264696716131827e-05 Test RE 0.003252414818474441\n",
      "251 Train Loss 0.0030000338 Test MSE 1.9208195647239274e-05 Test RE 0.003166497592789849\n",
      "252 Train Loss 0.0029848774 Test MSE 1.8969297286757393e-05 Test RE 0.00314674461973267\n",
      "253 Train Loss 0.0029762522 Test MSE 1.8126403470877943e-05 Test RE 0.003076038013863735\n",
      "254 Train Loss 0.002969817 Test MSE 1.7846087734370463e-05 Test RE 0.0030521606489265587\n",
      "255 Train Loss 0.0029467451 Test MSE 1.7613056201814113e-05 Test RE 0.003032167841087562\n",
      "256 Train Loss 0.0029212392 Test MSE 1.7356517401959586e-05 Test RE 0.0030100046806151863\n",
      "257 Train Loss 0.002908834 Test MSE 1.6542146605406504e-05 Test RE 0.0029385413723840917\n",
      "258 Train Loss 0.0028875815 Test MSE 1.621998757935713e-05 Test RE 0.002909786573150449\n",
      "259 Train Loss 0.0028633354 Test MSE 1.565689324750198e-05 Test RE 0.0028588322464795832\n",
      "260 Train Loss 0.002855714 Test MSE 1.5438476983257837e-05 Test RE 0.0028388216208864977\n",
      "261 Train Loss 0.0028280409 Test MSE 1.4925812374646577e-05 Test RE 0.0027912893971757985\n",
      "262 Train Loss 0.002809257 Test MSE 1.4729488351957823e-05 Test RE 0.0027728712670789827\n",
      "263 Train Loss 0.0027856098 Test MSE 1.472739072561325e-05 Test RE 0.0027726738177590955\n",
      "264 Train Loss 0.002774516 Test MSE 1.433792093643384e-05 Test RE 0.002735766123814805\n",
      "265 Train Loss 0.0027451287 Test MSE 1.4319379403487107e-05 Test RE 0.0027339966306013344\n",
      "266 Train Loss 0.0027154884 Test MSE 1.456108855159414e-05 Test RE 0.0027569748121506065\n",
      "267 Train Loss 0.0026939926 Test MSE 1.4646118883177892e-05 Test RE 0.0027650128527283184\n",
      "268 Train Loss 0.0026675102 Test MSE 1.5349613231048553e-05 Test RE 0.0028306397126732848\n",
      "269 Train Loss 0.0026520928 Test MSE 1.5283231537460543e-05 Test RE 0.0028245123188106306\n",
      "270 Train Loss 0.002637762 Test MSE 1.537366777198954e-05 Test RE 0.0028328568070937667\n",
      "271 Train Loss 0.0026149235 Test MSE 1.562647003022212e-05 Test RE 0.002856053369311164\n",
      "272 Train Loss 0.0025902162 Test MSE 1.5831409210936083e-05 Test RE 0.002874720753184303\n",
      "273 Train Loss 0.002582193 Test MSE 1.5587425060540654e-05 Test RE 0.002852483008797837\n",
      "274 Train Loss 0.002577068 Test MSE 1.5471407242930474e-05 Test RE 0.0028418476103177254\n",
      "275 Train Loss 0.0025694065 Test MSE 1.5626590398521293e-05 Test RE 0.002856064369160257\n",
      "276 Train Loss 0.0025566432 Test MSE 1.64536494883425e-05 Test RE 0.0029306705323288154\n",
      "277 Train Loss 0.0025348754 Test MSE 1.5737865777079195e-05 Test RE 0.002866215204007468\n",
      "278 Train Loss 0.0025112669 Test MSE 1.5958747471223638e-05 Test RE 0.002886258853965956\n",
      "279 Train Loss 0.0024914937 Test MSE 1.5912665757737665e-05 Test RE 0.002882088730136307\n",
      "280 Train Loss 0.002465977 Test MSE 1.531907105607572e-05 Test RE 0.0028278221517115732\n",
      "281 Train Loss 0.0024475986 Test MSE 1.5090741346851022e-05 Test RE 0.002806668785273435\n",
      "282 Train Loss 0.0024317543 Test MSE 1.5181023145240357e-05 Test RE 0.002815051847607012\n",
      "283 Train Loss 0.0024195882 Test MSE 1.542575227604521e-05 Test RE 0.002837651472418263\n",
      "284 Train Loss 0.0024055676 Test MSE 1.531395845002543e-05 Test RE 0.002827350231871923\n",
      "285 Train Loss 0.0023904783 Test MSE 1.5058613388521427e-05 Test RE 0.0028036795158647436\n",
      "286 Train Loss 0.0023869951 Test MSE 1.535542763389154e-05 Test RE 0.0028311757822481473\n",
      "287 Train Loss 0.0023797737 Test MSE 1.494086180246756e-05 Test RE 0.0027926962460557087\n",
      "288 Train Loss 0.0023699007 Test MSE 1.4950632275002405e-05 Test RE 0.0027936092289519675\n",
      "289 Train Loss 0.0023640676 Test MSE 1.5426842060165978e-05 Test RE 0.002837751706521721\n",
      "290 Train Loss 0.0023400623 Test MSE 1.61301962717554e-05 Test RE 0.002901721334609469\n",
      "291 Train Loss 0.0023147808 Test MSE 1.5964066300433986e-05 Test RE 0.002886739788921218\n",
      "292 Train Loss 0.0022925506 Test MSE 1.5528126847864445e-05 Test RE 0.002847052082297657\n",
      "293 Train Loss 0.002273469 Test MSE 1.581542381968132e-05 Test RE 0.0028732690459686095\n",
      "294 Train Loss 0.00224829 Test MSE 1.6049323642579724e-05 Test RE 0.0028944379540275992\n",
      "295 Train Loss 0.002221453 Test MSE 1.6113310573706763e-05 Test RE 0.0029002021212254643\n",
      "296 Train Loss 0.0022075532 Test MSE 1.5902349167329433e-05 Test RE 0.002881154312541385\n",
      "297 Train Loss 0.0021816022 Test MSE 1.5399720065147244e-05 Test RE 0.0028352560776219848\n",
      "298 Train Loss 0.0021680114 Test MSE 1.5751706782917015e-05 Test RE 0.002867475304434069\n",
      "299 Train Loss 0.0021541761 Test MSE 1.6199818678792352e-05 Test RE 0.0029079769092739062\n",
      "Training time: 254.15\n",
      "KG_tanhALR_high\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 58870.56 Test MSE 4.076287406839724 Test RE 1.4587077001900326\n",
      "1 Train Loss 35867.086 Test MSE 6.346573833412287 Test RE 1.8201431488692854\n",
      "2 Train Loss 17131.605 Test MSE 10.697802722059274 Test RE 2.3631058173123307\n",
      "3 Train Loss 7206.661 Test MSE 10.438012836950334 Test RE 2.3342361476990017\n",
      "4 Train Loss 4659.1836 Test MSE 13.690202368206426 Test RE 2.673257604090661\n",
      "5 Train Loss 2900.5417 Test MSE 13.41299427212519 Test RE 2.646054265302216\n",
      "6 Train Loss 1605.4294 Test MSE 13.61582445184718 Test RE 2.6659859027516406\n",
      "7 Train Loss 1098.2578 Test MSE 15.331597014030951 Test RE 2.828978029358769\n",
      "8 Train Loss 878.8189 Test MSE 15.193224509337472 Test RE 2.816182883819459\n",
      "9 Train Loss 752.11975 Test MSE 13.995164011948134 Test RE 2.702868227334811\n",
      "10 Train Loss 629.58496 Test MSE 12.668409119388365 Test RE 2.571561511183112\n",
      "11 Train Loss 432.5461 Test MSE 10.673846196184728 Test RE 2.360458379487556\n",
      "12 Train Loss 310.1717 Test MSE 9.84864840530804 Test RE 2.2673793846347423\n",
      "13 Train Loss 236.58998 Test MSE 9.69022492985303 Test RE 2.2490691366669595\n",
      "14 Train Loss 193.87823 Test MSE 9.51952625889467 Test RE 2.229171823490067\n",
      "15 Train Loss 169.03207 Test MSE 9.428032981543328 Test RE 2.218433544263866\n",
      "16 Train Loss 150.20518 Test MSE 9.178807095788923 Test RE 2.1889155084811396\n",
      "17 Train Loss 136.25586 Test MSE 8.191047349065306 Test RE 2.0677860214484918\n",
      "18 Train Loss 117.264626 Test MSE 6.526504430477063 Test RE 1.8457641031692826\n",
      "19 Train Loss 82.94225 Test MSE 4.771908092446768 Test RE 1.5782722193161902\n",
      "20 Train Loss 53.418068 Test MSE 3.6059866558097964 Test RE 1.3719804865644654\n",
      "21 Train Loss 39.07395 Test MSE 2.5789558260946186 Test RE 1.1602667014014965\n",
      "22 Train Loss 27.228172 Test MSE 1.7847071595486153 Test RE 0.9652045484682144\n",
      "23 Train Loss 19.014877 Test MSE 1.0433440016641797 Test RE 0.737988575395915\n",
      "24 Train Loss 14.393985 Test MSE 0.7334321791558533 Test RE 0.6187509193118141\n",
      "25 Train Loss 10.544519 Test MSE 0.3697905308577942 Test RE 0.4393531757535876\n",
      "26 Train Loss 7.6350265 Test MSE 0.1784432042699076 Test RE 0.305200951665401\n",
      "27 Train Loss 5.9674582 Test MSE 0.12771983798688774 Test RE 0.2582052428612876\n",
      "28 Train Loss 4.5712028 Test MSE 0.08065877175733184 Test RE 0.20519259274739027\n",
      "29 Train Loss 3.7323194 Test MSE 0.06271187596375948 Test RE 0.1809300791275017\n",
      "30 Train Loss 2.898604 Test MSE 0.03163223483120231 Test RE 0.12849931570739406\n",
      "31 Train Loss 2.1860178 Test MSE 0.024229527171258737 Test RE 0.11246265873466266\n",
      "32 Train Loss 1.7655878 Test MSE 0.01003377097395012 Test RE 0.07237156577695418\n",
      "33 Train Loss 1.5110972 Test MSE 0.008647191527619369 Test RE 0.06718516932673943\n",
      "34 Train Loss 1.246363 Test MSE 0.008321484904857434 Test RE 0.06590772056989185\n",
      "35 Train Loss 1.0822998 Test MSE 0.00634219894179074 Test RE 0.057538138502841854\n",
      "36 Train Loss 0.9306841 Test MSE 0.006160236236131657 Test RE 0.056706724261399846\n",
      "37 Train Loss 0.7717465 Test MSE 0.005565784161398306 Test RE 0.053901277348112696\n",
      "38 Train Loss 0.6573965 Test MSE 0.005158186024011838 Test RE 0.05189008440218711\n",
      "39 Train Loss 0.5936273 Test MSE 0.005069628032537122 Test RE 0.051442720132003864\n",
      "40 Train Loss 0.54453856 Test MSE 0.004624062115884225 Test RE 0.04913010661733191\n",
      "41 Train Loss 0.5029571 Test MSE 0.004562763326540179 Test RE 0.04880337402308592\n",
      "42 Train Loss 0.46249965 Test MSE 0.004723731129637624 Test RE 0.049656769440333384\n",
      "43 Train Loss 0.42321756 Test MSE 0.004564450047573237 Test RE 0.048812393784286624\n",
      "44 Train Loss 0.39694893 Test MSE 0.004445926633927312 Test RE 0.04817447858402767\n",
      "45 Train Loss 0.36617184 Test MSE 0.0030463073991076795 Test RE 0.03987702398753679\n",
      "46 Train Loss 0.33165425 Test MSE 0.0026205166192293304 Test RE 0.036985316206289774\n",
      "47 Train Loss 0.30109453 Test MSE 0.0018339837783804902 Test RE 0.030940948425922984\n",
      "48 Train Loss 0.27665782 Test MSE 0.0015804551106428533 Test RE 0.028722812254125728\n",
      "49 Train Loss 0.25869456 Test MSE 0.001336345722979732 Test RE 0.026411635247283967\n",
      "50 Train Loss 0.24179086 Test MSE 0.0010679394503214355 Test RE 0.02361071787537117\n",
      "51 Train Loss 0.22872798 Test MSE 0.0009616281799306159 Test RE 0.022404717262660353\n",
      "52 Train Loss 0.21187134 Test MSE 0.0012685430183245676 Test RE 0.025732884849392762\n",
      "53 Train Loss 0.19924909 Test MSE 0.0012650654422293548 Test RE 0.025697588655791734\n",
      "54 Train Loss 0.186432 Test MSE 0.001321230278285209 Test RE 0.026261839074610157\n",
      "55 Train Loss 0.17425464 Test MSE 0.0009742850768931146 Test RE 0.022551680089570838\n",
      "56 Train Loss 0.16424283 Test MSE 0.0009310709098558097 Test RE 0.02204587069501691\n",
      "57 Train Loss 0.15635985 Test MSE 0.0008397370611918923 Test RE 0.020936666601659312\n",
      "58 Train Loss 0.14822108 Test MSE 0.000945753060796969 Test RE 0.022219012569544908\n",
      "59 Train Loss 0.14302988 Test MSE 0.0009525434955480573 Test RE 0.022298635310581013\n",
      "60 Train Loss 0.13518187 Test MSE 0.0008584899778006241 Test RE 0.0211691534798069\n",
      "61 Train Loss 0.1284551 Test MSE 0.0008900117832390988 Test RE 0.021554291658040348\n",
      "62 Train Loss 0.12492902 Test MSE 0.0009554372918998012 Test RE 0.022332480891302395\n",
      "63 Train Loss 0.1200771 Test MSE 0.0010730092033518638 Test RE 0.023666694262064535\n",
      "64 Train Loss 0.11589198 Test MSE 0.0010000011313975907 Test RE 0.022847365142938805\n",
      "65 Train Loss 0.10994476 Test MSE 0.0009415347156272801 Test RE 0.022169405428320046\n",
      "66 Train Loss 0.10545978 Test MSE 0.0008305005212605883 Test RE 0.020821203631366605\n",
      "67 Train Loss 0.100409 Test MSE 0.000811696271521968 Test RE 0.020584136465377278\n",
      "68 Train Loss 0.097145274 Test MSE 0.0007433431970800547 Test RE 0.0196983823296663\n",
      "69 Train Loss 0.09368686 Test MSE 0.0007000012872565919 Test RE 0.019115483889202194\n",
      "70 Train Loss 0.09097553 Test MSE 0.0006764969966859048 Test RE 0.018791818680066234\n",
      "71 Train Loss 0.08821193 Test MSE 0.0006532048532762249 Test RE 0.018465479019717002\n",
      "72 Train Loss 0.08464943 Test MSE 0.0006237247475681853 Test RE 0.018043981155169347\n",
      "73 Train Loss 0.08179041 Test MSE 0.0006068202669956782 Test RE 0.017797783335442092\n",
      "74 Train Loss 0.07848064 Test MSE 0.0006368334737094552 Test RE 0.018232608992716663\n",
      "75 Train Loss 0.07539656 Test MSE 0.0006701173503585725 Test RE 0.018703001479189477\n",
      "76 Train Loss 0.07316647 Test MSE 0.0006070900322422044 Test RE 0.017801738946507096\n",
      "77 Train Loss 0.07143902 Test MSE 0.0005801116607774959 Test RE 0.017401699889843244\n",
      "78 Train Loss 0.06944232 Test MSE 0.0005492014880459805 Test RE 0.016931745403840515\n",
      "79 Train Loss 0.06726506 Test MSE 0.0005376812405619313 Test RE 0.016753221060872164\n",
      "80 Train Loss 0.06549802 Test MSE 0.0005234077320197399 Test RE 0.016529356399959103\n",
      "81 Train Loss 0.064165846 Test MSE 0.0005515434310879682 Test RE 0.01696780776085204\n",
      "82 Train Loss 0.06258791 Test MSE 0.0005147610645346002 Test RE 0.016392255780409495\n",
      "83 Train Loss 0.060847916 Test MSE 0.000457290607966458 Test RE 0.01545012572251955\n",
      "84 Train Loss 0.059356555 Test MSE 0.0004338918170060699 Test RE 0.015049657164964945\n",
      "85 Train Loss 0.057074796 Test MSE 0.00038920386316338996 Test RE 0.014253596096914206\n",
      "86 Train Loss 0.055571157 Test MSE 0.00040421327297636997 Test RE 0.014525836849601582\n",
      "87 Train Loss 0.054084074 Test MSE 0.0004148680884507896 Test RE 0.014716037709830867\n",
      "88 Train Loss 0.052247066 Test MSE 0.0004334724207349821 Test RE 0.015042381968922321\n",
      "89 Train Loss 0.05072832 Test MSE 0.00043008508958213313 Test RE 0.014983493028820563\n",
      "90 Train Loss 0.049178846 Test MSE 0.0003904140303204036 Test RE 0.01427573853673688\n",
      "91 Train Loss 0.046822302 Test MSE 0.00036860767808032785 Test RE 0.013871328779776078\n",
      "92 Train Loss 0.045555394 Test MSE 0.0003499584864093052 Test RE 0.013515874223574385\n",
      "93 Train Loss 0.044057813 Test MSE 0.0003006395334651212 Test RE 0.012527341635212031\n",
      "94 Train Loss 0.042750515 Test MSE 0.0002901695733940975 Test RE 0.012307272384565027\n",
      "95 Train Loss 0.04205344 Test MSE 0.0002776904399185008 Test RE 0.012039718730630365\n",
      "96 Train Loss 0.04078069 Test MSE 0.0002363344701762683 Test RE 0.011107067512775928\n",
      "97 Train Loss 0.039679635 Test MSE 0.00021891699384167564 Test RE 0.010689948545318543\n",
      "98 Train Loss 0.038756944 Test MSE 0.00020972051284808794 Test RE 0.01046300258038137\n",
      "99 Train Loss 0.03754681 Test MSE 0.00017899447297525353 Test RE 0.009666198011132674\n",
      "100 Train Loss 0.03615253 Test MSE 0.00017197706558582854 Test RE 0.009474823839169293\n",
      "101 Train Loss 0.03525662 Test MSE 0.00015057248699580576 Test RE 0.00886561134835088\n",
      "102 Train Loss 0.034460884 Test MSE 0.00015296235880329318 Test RE 0.00893569142576053\n",
      "103 Train Loss 0.033555012 Test MSE 0.00013475096896193998 Test RE 0.008386906961479916\n",
      "104 Train Loss 0.032855418 Test MSE 0.00013191178946791288 Test RE 0.008298081249075743\n",
      "105 Train Loss 0.03210841 Test MSE 0.00012513316270464832 Test RE 0.0080820603224031\n",
      "106 Train Loss 0.03125268 Test MSE 0.00012894162988656813 Test RE 0.008204128512493665\n",
      "107 Train Loss 0.030647203 Test MSE 0.00014777379887710785 Test RE 0.008782832411844483\n",
      "108 Train Loss 0.029838854 Test MSE 0.0001442228085643737 Test RE 0.008676665424735375\n",
      "109 Train Loss 0.02906873 Test MSE 0.00013600635677452847 Test RE 0.008425884090469134\n",
      "110 Train Loss 0.028463766 Test MSE 0.00014315417686375616 Test RE 0.008644460396028933\n",
      "111 Train Loss 0.02786511 Test MSE 0.0001459973570798663 Test RE 0.008729882008693615\n",
      "112 Train Loss 0.027101751 Test MSE 0.00012234377717411254 Test RE 0.007991472681208799\n",
      "113 Train Loss 0.02647187 Test MSE 0.00010936278770993392 Test RE 0.00755562966262902\n",
      "114 Train Loss 0.026118297 Test MSE 0.00010486980443459705 Test RE 0.007398796900469467\n",
      "115 Train Loss 0.025659291 Test MSE 9.91949261685699e-05 Test RE 0.007195825219390193\n",
      "116 Train Loss 0.025267288 Test MSE 9.128421392684332e-05 Test RE 0.006902933934566962\n",
      "117 Train Loss 0.024468472 Test MSE 8.620339955753546e-05 Test RE 0.006708077531290527\n",
      "118 Train Loss 0.023884203 Test MSE 8.625245382774941e-05 Test RE 0.006709985884381863\n",
      "119 Train Loss 0.02348743 Test MSE 8.757106405963464e-05 Test RE 0.006761081798944961\n",
      "120 Train Loss 0.023082409 Test MSE 8.009762785185998e-05 Test RE 0.006466148943237044\n",
      "121 Train Loss 0.022750286 Test MSE 7.965373874739882e-05 Test RE 0.006448206834171903\n",
      "122 Train Loss 0.022526836 Test MSE 8.29856201570142e-05 Test RE 0.0065816881178901296\n",
      "123 Train Loss 0.021955421 Test MSE 8.85144951429498e-05 Test RE 0.006797403882060718\n",
      "124 Train Loss 0.021490287 Test MSE 9.257561142093596e-05 Test RE 0.006951590345984019\n",
      "125 Train Loss 0.020995557 Test MSE 9.40834248066629e-05 Test RE 0.00700797325854983\n",
      "126 Train Loss 0.020632448 Test MSE 9.669585891585993e-05 Test RE 0.0071046029955966405\n",
      "127 Train Loss 0.020064607 Test MSE 8.819063096541581e-05 Test RE 0.006784957033636198\n",
      "128 Train Loss 0.019646365 Test MSE 7.351226415678032e-05 Test RE 0.006194635776780314\n",
      "129 Train Loss 0.019201044 Test MSE 7.157070199095248e-05 Test RE 0.0061122838642762595\n",
      "130 Train Loss 0.018865835 Test MSE 6.922793459012193e-05 Test RE 0.006011412973018944\n",
      "131 Train Loss 0.018554624 Test MSE 6.418463217831978e-05 Test RE 0.005788304975655821\n",
      "132 Train Loss 0.018193807 Test MSE 6.228321308558883e-05 Test RE 0.005701923435669249\n",
      "133 Train Loss 0.017877301 Test MSE 6.1240661936705e-05 Test RE 0.005654000141418696\n",
      "134 Train Loss 0.017455805 Test MSE 6.557317554919479e-05 Test RE 0.0058505808445240655\n",
      "135 Train Loss 0.017053787 Test MSE 6.518479713153463e-05 Test RE 0.005833229131485546\n",
      "136 Train Loss 0.016820064 Test MSE 5.9643760341589174e-05 Test RE 0.0055797968211895145\n",
      "137 Train Loss 0.016509132 Test MSE 5.9330586852828075e-05 Test RE 0.005565128528057862\n",
      "138 Train Loss 0.016286207 Test MSE 5.172654287522676e-05 Test RE 0.005196280703128064\n",
      "139 Train Loss 0.016178627 Test MSE 5.233954407716796e-05 Test RE 0.005226980074066698\n",
      "140 Train Loss 0.015763596 Test MSE 5.1754948177522676e-05 Test RE 0.005197707259571628\n",
      "141 Train Loss 0.015353046 Test MSE 5.376757211394984e-05 Test RE 0.005297806477851401\n",
      "142 Train Loss 0.014953645 Test MSE 5.740774177471437e-05 Test RE 0.005474205651257036\n",
      "143 Train Loss 0.014615677 Test MSE 5.911871910527585e-05 Test RE 0.005555183187894231\n",
      "144 Train Loss 0.014178386 Test MSE 5.737960207032226e-05 Test RE 0.005472863833885968\n",
      "145 Train Loss 0.013803661 Test MSE 5.960028738867258e-05 Test RE 0.0055777629582994676\n",
      "146 Train Loss 0.013421392 Test MSE 6.075023546391034e-05 Test RE 0.005631315498448365\n",
      "147 Train Loss 0.013101668 Test MSE 5.8281345722807126e-05 Test RE 0.005515700326025761\n",
      "148 Train Loss 0.012876448 Test MSE 5.7075983286180565e-05 Test RE 0.005458365055809256\n",
      "149 Train Loss 0.012771277 Test MSE 5.4495793881413407e-05 Test RE 0.0053335622555827425\n",
      "150 Train Loss 0.012614929 Test MSE 5.355807405660155e-05 Test RE 0.005287475312081611\n",
      "151 Train Loss 0.012448015 Test MSE 5.137274267450842e-05 Test RE 0.005178479401236304\n",
      "152 Train Loss 0.012215665 Test MSE 4.974877277746461e-05 Test RE 0.005095972348955815\n",
      "153 Train Loss 0.012050457 Test MSE 5.1510137454764476e-05 Test RE 0.005185399617279217\n",
      "154 Train Loss 0.011890816 Test MSE 5.149338265274301e-05 Test RE 0.005184556216209379\n",
      "155 Train Loss 0.011714035 Test MSE 5.104500023233277e-05 Test RE 0.005161934410808648\n",
      "156 Train Loss 0.011527799 Test MSE 5.102638568252888e-05 Test RE 0.005160993125214177\n",
      "157 Train Loss 0.011359295 Test MSE 5.201762948947398e-05 Test RE 0.005210880999980037\n",
      "158 Train Loss 0.0111367665 Test MSE 5.436101794292946e-05 Test RE 0.0053269628393361555\n",
      "159 Train Loss 0.010977855 Test MSE 5.5457786387258765e-05 Test RE 0.00538043194069694\n",
      "160 Train Loss 0.010803423 Test MSE 5.802750794213439e-05 Test RE 0.005503675715682563\n",
      "161 Train Loss 0.0107392715 Test MSE 5.627992515788754e-05 Test RE 0.005420166560423208\n",
      "162 Train Loss 0.010594716 Test MSE 5.5072574428828476e-05 Test RE 0.005361713032888826\n",
      "163 Train Loss 0.010379618 Test MSE 5.390816176141862e-05 Test RE 0.005304728219626633\n",
      "164 Train Loss 0.010175275 Test MSE 5.3747997636577304e-05 Test RE 0.0052968420374925156\n",
      "165 Train Loss 0.010054972 Test MSE 5.0697649450836865e-05 Test RE 0.005144341476938338\n",
      "166 Train Loss 0.009896631 Test MSE 5.069033400579681e-05 Test RE 0.005143970310765731\n",
      "167 Train Loss 0.009715329 Test MSE 4.6959542524391584e-05 Test RE 0.004951055624403275\n",
      "168 Train Loss 0.009695749 Test MSE 4.6788450147894884e-05 Test RE 0.004942028057203496\n",
      "169 Train Loss 0.00959603 Test MSE 4.200299451378459e-05 Test RE 0.004682480782961717\n",
      "170 Train Loss 0.009566691 Test MSE 4.053768179476806e-05 Test RE 0.00460007943850453\n",
      "171 Train Loss 0.009417033 Test MSE 3.8685717964506904e-05 Test RE 0.004493773796815312\n",
      "172 Train Loss 0.009228287 Test MSE 3.7906865707918864e-05 Test RE 0.004448307643148265\n",
      "173 Train Loss 0.00904285 Test MSE 3.745493161311791e-05 Test RE 0.004421711276324463\n",
      "174 Train Loss 0.008829524 Test MSE 3.271439896388379e-05 Test RE 0.0041324285161919005\n",
      "175 Train Loss 0.008705118 Test MSE 3.269226882123448e-05 Test RE 0.004131030558311445\n",
      "176 Train Loss 0.008572382 Test MSE 3.29191442860177e-05 Test RE 0.004145339890455381\n",
      "177 Train Loss 0.008461228 Test MSE 3.3634765753923036e-05 Test RE 0.004190154924283916\n",
      "178 Train Loss 0.008373828 Test MSE 3.592613206598134e-05 Test RE 0.0043305305620902354\n",
      "179 Train Loss 0.008263438 Test MSE 3.588659277413361e-05 Test RE 0.004328146875905476\n",
      "180 Train Loss 0.008171999 Test MSE 3.7832924479959904e-05 Test RE 0.004443967085379311\n",
      "181 Train Loss 0.00802746 Test MSE 4.026329401887683e-05 Test RE 0.004584484704852538\n",
      "182 Train Loss 0.007953766 Test MSE 4.091909150349289e-05 Test RE 0.004621669317672088\n",
      "183 Train Loss 0.007840301 Test MSE 3.772133776299644e-05 Test RE 0.004437408593077961\n",
      "184 Train Loss 0.0077641956 Test MSE 3.5236492509491136e-05 Test RE 0.004288764631443061\n",
      "185 Train Loss 0.0076194815 Test MSE 3.4949138056738046e-05 Test RE 0.00427124134269838\n",
      "186 Train Loss 0.0075289593 Test MSE 3.429422802156392e-05 Test RE 0.00423103280354029\n",
      "187 Train Loss 0.0074504185 Test MSE 3.3829083172070126e-05 Test RE 0.004202241339322046\n",
      "188 Train Loss 0.0073887077 Test MSE 3.409926625960147e-05 Test RE 0.00421898900825628\n",
      "189 Train Loss 0.0073044687 Test MSE 3.39096397718854e-05 Test RE 0.0042072417258957415\n",
      "190 Train Loss 0.0072174706 Test MSE 3.336358667117935e-05 Test RE 0.004173229253302817\n",
      "191 Train Loss 0.007169079 Test MSE 3.2542277784228895e-05 Test RE 0.004121543148735919\n",
      "192 Train Loss 0.007076233 Test MSE 3.059370324226055e-05 Test RE 0.003996243121549243\n",
      "193 Train Loss 0.0070152762 Test MSE 3.0270456095207436e-05 Test RE 0.003975075293601806\n",
      "194 Train Loss 0.0069585326 Test MSE 3.0238663690055355e-05 Test RE 0.003972987277417072\n",
      "195 Train Loss 0.0068474766 Test MSE 2.6953214963726982e-05 Test RE 0.0037509490441866833\n",
      "196 Train Loss 0.0068220054 Test MSE 2.7555438968184416e-05 Test RE 0.003792621859319147\n",
      "197 Train Loss 0.006758093 Test MSE 2.7169694318463374e-05 Test RE 0.0037659821137000747\n",
      "198 Train Loss 0.006745639 Test MSE 2.6169279615806918e-05 Test RE 0.003695998282185101\n",
      "199 Train Loss 0.0066644624 Test MSE 2.498996168697475e-05 Test RE 0.003611758238046628\n",
      "200 Train Loss 0.006556538 Test MSE 2.411816932350257e-05 Test RE 0.003548199634424044\n",
      "201 Train Loss 0.00646908 Test MSE 2.4865532648719463e-05 Test RE 0.003602755254671603\n",
      "202 Train Loss 0.006416056 Test MSE 2.4434670795728856e-05 Test RE 0.0035714051702449194\n",
      "203 Train Loss 0.0063475785 Test MSE 2.3935267155365295e-05 Test RE 0.003534719994424898\n",
      "204 Train Loss 0.0063462 Test MSE 2.4228122870088526e-05 Test RE 0.003556278470866298\n",
      "205 Train Loss 0.006290239 Test MSE 2.405700459467361e-05 Test RE 0.0035436975837850712\n",
      "206 Train Loss 0.0062265513 Test MSE 2.19437908149025e-05 Test RE 0.003384478068375217\n",
      "207 Train Loss 0.006173761 Test MSE 2.2292979711069005e-05 Test RE 0.003411300180880685\n",
      "208 Train Loss 0.0061027785 Test MSE 2.2848777927767677e-05 Test RE 0.0034535628601157936\n",
      "209 Train Loss 0.006067063 Test MSE 2.2193798675941415e-05 Test RE 0.003403703317657528\n",
      "210 Train Loss 0.0060068476 Test MSE 2.1930039352130284e-05 Test RE 0.0033834174308045428\n",
      "211 Train Loss 0.0059584747 Test MSE 2.220816677542138e-05 Test RE 0.003404804905447911\n",
      "212 Train Loss 0.005987922 Test MSE 2.223222741222621e-05 Test RE 0.0034066488126524943\n",
      "213 Train Loss 0.005926585 Test MSE 2.2427702021166856e-05 Test RE 0.003421592344579781\n",
      "214 Train Loss 0.005885053 Test MSE 2.288451128266803e-05 Test RE 0.003456262329996105\n",
      "215 Train Loss 0.00583266 Test MSE 2.286217601103588e-05 Test RE 0.0034545752630938077\n",
      "216 Train Loss 0.005766555 Test MSE 2.2894600913185403e-05 Test RE 0.0034570241676981023\n",
      "217 Train Loss 0.0057898774 Test MSE 2.240080182480309e-05 Test RE 0.003419539768674109\n",
      "218 Train Loss 0.0057012797 Test MSE 2.2395355720332366e-05 Test RE 0.0034191240625081843\n",
      "219 Train Loss 0.0056754113 Test MSE 2.166946626087406e-05 Test RE 0.003363256452561264\n",
      "220 Train Loss 0.005610334 Test MSE 2.197779042308975e-05 Test RE 0.0033870990009004817\n",
      "221 Train Loss 0.005564553 Test MSE 2.175949157673792e-05 Test RE 0.0033702354985844078\n",
      "222 Train Loss 0.0055264714 Test MSE 2.2000429609479792e-05 Test RE 0.003388843066775447\n",
      "223 Train Loss 0.005465052 Test MSE 2.3468652459655426e-05 Test RE 0.003500095979587667\n",
      "224 Train Loss 0.005394315 Test MSE 2.3445106248949316e-05 Test RE 0.0034983397074809896\n",
      "225 Train Loss 0.005315163 Test MSE 2.2996204514427703e-05 Test RE 0.0034646866133384163\n",
      "226 Train Loss 0.0052387626 Test MSE 2.264519064466121e-05 Test RE 0.003438142457915297\n",
      "227 Train Loss 0.00516977 Test MSE 2.3391173069915912e-05 Test RE 0.0034943135961731436\n",
      "228 Train Loss 0.005125734 Test MSE 2.3115295232466066e-05 Test RE 0.0034736463352652166\n",
      "229 Train Loss 0.0050660977 Test MSE 2.210636514677073e-05 Test RE 0.0033969921755811613\n",
      "230 Train Loss 0.004978726 Test MSE 2.1699109824872714e-05 Test RE 0.0033655561131361216\n",
      "231 Train Loss 0.004938955 Test MSE 2.0766515083185492e-05 Test RE 0.0032924386240991057\n",
      "232 Train Loss 0.0049046325 Test MSE 1.9786314647042792e-05 Test RE 0.003213796196428132\n",
      "233 Train Loss 0.0048662443 Test MSE 1.908953728436081e-05 Test RE 0.0031567019436957175\n",
      "234 Train Loss 0.004807701 Test MSE 1.9128007811263918e-05 Test RE 0.0031598811424184458\n",
      "235 Train Loss 0.004764331 Test MSE 1.8649681623074532e-05 Test RE 0.003120122088135195\n",
      "236 Train Loss 0.0047023664 Test MSE 1.8844783744222307e-05 Test RE 0.003136400077385152\n",
      "237 Train Loss 0.004638129 Test MSE 1.928621079361803e-05 Test RE 0.003172921528944625\n",
      "238 Train Loss 0.004583761 Test MSE 1.9919348801992176e-05 Test RE 0.0032245821467379097\n",
      "239 Train Loss 0.0045287684 Test MSE 1.9762049700879773e-05 Test RE 0.0032118249724727094\n",
      "240 Train Loss 0.0044778707 Test MSE 1.9716543085028333e-05 Test RE 0.0032081248622693867\n",
      "241 Train Loss 0.0044361455 Test MSE 1.9493045938763757e-05 Test RE 0.003189890168259548\n",
      "242 Train Loss 0.0043711644 Test MSE 1.974724081391458e-05 Test RE 0.003210621340572577\n",
      "243 Train Loss 0.0043111136 Test MSE 1.9117387530027616e-05 Test RE 0.0031590038036444328\n",
      "244 Train Loss 0.0042880685 Test MSE 1.86693940528429e-05 Test RE 0.003121770613424946\n",
      "245 Train Loss 0.004253655 Test MSE 1.8448949923919405e-05 Test RE 0.003103285290806088\n",
      "246 Train Loss 0.0041996 Test MSE 1.8081634603525953e-05 Test RE 0.00307223704272184\n",
      "247 Train Loss 0.004147079 Test MSE 1.8225568441400727e-05 Test RE 0.0030844406504957475\n",
      "248 Train Loss 0.0041088453 Test MSE 1.7878110156509484e-05 Test RE 0.0030548977690512563\n",
      "249 Train Loss 0.0040718345 Test MSE 1.7426157064964014e-05 Test RE 0.0030160371659030947\n",
      "250 Train Loss 0.004044091 Test MSE 1.68145250357281e-05 Test RE 0.0029626352032152215\n",
      "251 Train Loss 0.004011777 Test MSE 1.7028011476950595e-05 Test RE 0.002981383502771867\n",
      "252 Train Loss 0.0039693816 Test MSE 1.7662522200988514e-05 Test RE 0.003036422754239108\n",
      "253 Train Loss 0.0039414917 Test MSE 1.7306419366282484e-05 Test RE 0.0030056574867049187\n",
      "254 Train Loss 0.0038997903 Test MSE 1.7276198089402773e-05 Test RE 0.0030030320303686318\n",
      "255 Train Loss 0.0038668436 Test MSE 1.7802879553071675e-05 Test RE 0.0030484635295931206\n",
      "256 Train Loss 0.0038333705 Test MSE 1.7626055179045788e-05 Test RE 0.0030332865512811328\n",
      "257 Train Loss 0.003817484 Test MSE 1.8073617528703504e-05 Test RE 0.0030715558796092545\n",
      "258 Train Loss 0.0037824183 Test MSE 1.8700347650636984e-05 Test RE 0.003124357467932759\n",
      "259 Train Loss 0.0037879054 Test MSE 1.9397579615470377e-05 Test RE 0.003182069408620322\n",
      "260 Train Loss 0.003769824 Test MSE 1.9047325229479133e-05 Test RE 0.003153209857466385\n",
      "261 Train Loss 0.003756169 Test MSE 1.7941426417510538e-05 Test RE 0.003060302527984041\n",
      "262 Train Loss 0.0037450423 Test MSE 1.7838038900220584e-05 Test RE 0.0030514722878192866\n",
      "263 Train Loss 0.003710718 Test MSE 1.7608401916859343e-05 Test RE 0.0030317671864412746\n",
      "264 Train Loss 0.0036903396 Test MSE 1.756473063938413e-05 Test RE 0.00302800525103331\n",
      "265 Train Loss 0.0036779868 Test MSE 1.7657911776149614e-05 Test RE 0.0030360264316642346\n",
      "266 Train Loss 0.0036438005 Test MSE 1.773718692895377e-05 Test RE 0.0030428339163859393\n",
      "267 Train Loss 0.003629952 Test MSE 1.7316338738498787e-05 Test RE 0.0030065187267992945\n",
      "268 Train Loss 0.0036095118 Test MSE 1.7296977694669644e-05 Test RE 0.0030048374932114003\n",
      "269 Train Loss 0.0035763788 Test MSE 1.7008932297793653e-05 Test RE 0.0029797127764932306\n",
      "270 Train Loss 0.0035547873 Test MSE 1.6858109153225477e-05 Test RE 0.0029664723700360625\n",
      "271 Train Loss 0.003531899 Test MSE 1.6878955722426594e-05 Test RE 0.0029683059583962617\n",
      "272 Train Loss 0.0035111555 Test MSE 1.6555436460105843e-05 Test RE 0.0029397215380620296\n",
      "273 Train Loss 0.0034833536 Test MSE 1.6576200279786687e-05 Test RE 0.0029415644589971452\n",
      "274 Train Loss 0.0034751624 Test MSE 1.650259145317635e-05 Test RE 0.0029350259876672774\n",
      "275 Train Loss 0.0034468449 Test MSE 1.6098752478678296e-05 Test RE 0.0028988916841561066\n",
      "276 Train Loss 0.0034158083 Test MSE 1.580237427457211e-05 Test RE 0.0028720834124996947\n",
      "277 Train Loss 0.0034002874 Test MSE 1.603823650385082e-05 Test RE 0.002893438018453266\n",
      "278 Train Loss 0.003371664 Test MSE 1.595387365798706e-05 Test RE 0.0028858180875204476\n",
      "279 Train Loss 0.0033522823 Test MSE 1.583252490598891e-05 Test RE 0.0028748220472376066\n",
      "280 Train Loss 0.0033248211 Test MSE 1.5982582901316937e-05 Test RE 0.002888413457668304\n",
      "281 Train Loss 0.003281694 Test MSE 1.575855422498937e-05 Test RE 0.0028680984984123807\n",
      "282 Train Loss 0.0032691332 Test MSE 1.575925315555368e-05 Test RE 0.0028681621013116904\n",
      "283 Train Loss 0.0032332262 Test MSE 1.5713228878109292e-05 Test RE 0.0028639708618249902\n",
      "284 Train Loss 0.0032055 Test MSE 1.581418371389763e-05 Test RE 0.0028731563955757657\n",
      "285 Train Loss 0.003191095 Test MSE 1.5847390674734827e-05 Test RE 0.0028761713712707982\n",
      "286 Train Loss 0.003195369 Test MSE 1.62213010280923e-05 Test RE 0.0029099043839104087\n",
      "287 Train Loss 0.003165805 Test MSE 1.6461196409825948e-05 Test RE 0.002931342571829629\n",
      "288 Train Loss 0.0031476407 Test MSE 1.579146159671713e-05 Test RE 0.0028710915509801587\n",
      "289 Train Loss 0.0031404514 Test MSE 1.564699790861031e-05 Test RE 0.002857928696054812\n",
      "290 Train Loss 0.0031149648 Test MSE 1.6126811425159307e-05 Test RE 0.00290141686227882\n",
      "291 Train Loss 0.0030806658 Test MSE 1.578845087379042e-05 Test RE 0.002870817843788706\n",
      "292 Train Loss 0.0030476935 Test MSE 1.568858048504843e-05 Test RE 0.002861723711183317\n",
      "293 Train Loss 0.003034238 Test MSE 1.5541639006741363e-05 Test RE 0.0028482905270641075\n",
      "294 Train Loss 0.003002111 Test MSE 1.568233967088524e-05 Test RE 0.0028611544671291863\n",
      "295 Train Loss 0.0029725325 Test MSE 1.582605520776496e-05 Test RE 0.002874234613089906\n",
      "296 Train Loss 0.0029570423 Test MSE 1.6114936612860913e-05 Test RE 0.0029003484512802437\n",
      "297 Train Loss 0.0029365732 Test MSE 1.6044214278285017e-05 Test RE 0.002893977189590876\n",
      "298 Train Loss 0.0029141158 Test MSE 1.600305641382541e-05 Test RE 0.00289026287848499\n",
      "299 Train Loss 0.0028897177 Test MSE 1.6803551175394342e-05 Test RE 0.0029616682757759956\n",
      "Training time: 254.02\n",
      "KG_tanhALR_high\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 53792.215 Test MSE 8.78294913642292 Test RE 2.1411942119653364\n",
      "1 Train Loss 38539.39 Test MSE 9.6444102804034 Test RE 2.2437461232541804\n",
      "2 Train Loss 18824.799 Test MSE 6.426787911020601 Test RE 1.8316093883467237\n",
      "3 Train Loss 9269.656 Test MSE 7.010866064552466 Test RE 1.9130296980750126\n",
      "4 Train Loss 2835.0208 Test MSE 7.974736983735697 Test RE 2.04030014816406\n",
      "5 Train Loss 1121.3672 Test MSE 7.788119781605279 Test RE 2.016286248162442\n",
      "6 Train Loss 511.90442 Test MSE 5.9979757634696975 Test RE 1.769449735310153\n",
      "7 Train Loss 261.33716 Test MSE 4.595362620326021 Test RE 1.5488015355114646\n",
      "8 Train Loss 97.74882 Test MSE 3.0679958915529024 Test RE 1.2655032468410004\n",
      "9 Train Loss 47.923874 Test MSE 1.4449413883598912 Test RE 0.8684823412280475\n",
      "10 Train Loss 28.600645 Test MSE 0.888263787444427 Test RE 0.6809368784602143\n",
      "11 Train Loss 17.973621 Test MSE 0.5496758853373163 Test RE 0.5356600027253788\n",
      "12 Train Loss 12.039275 Test MSE 0.4185120465003702 Test RE 0.4674012381854715\n",
      "13 Train Loss 8.445675 Test MSE 0.1601931299643716 Test RE 0.28917305315868463\n",
      "14 Train Loss 5.5821257 Test MSE 0.08800216707262445 Test RE 0.21432980080455144\n",
      "15 Train Loss 4.1621747 Test MSE 0.05174717459925661 Test RE 0.16435359118882087\n",
      "16 Train Loss 3.4270535 Test MSE 0.026194547894683055 Test RE 0.11693414121408892\n",
      "17 Train Loss 2.8361282 Test MSE 0.01744816550806133 Test RE 0.09543567795375425\n",
      "18 Train Loss 2.3549154 Test MSE 0.010730338228648568 Test RE 0.07484151713566699\n",
      "19 Train Loss 1.881251 Test MSE 0.010420089898795068 Test RE 0.07375162772822427\n",
      "20 Train Loss 1.644021 Test MSE 0.009122516491836263 Test RE 0.06900700923369735\n",
      "21 Train Loss 1.4327005 Test MSE 0.008833715401479513 Test RE 0.06790591078863875\n",
      "22 Train Loss 1.2215447 Test MSE 0.008209001180967289 Test RE 0.06546075891510968\n",
      "23 Train Loss 1.0278137 Test MSE 0.006224537402269226 Test RE 0.05700191121227042\n",
      "24 Train Loss 0.884601 Test MSE 0.0052014692527949 Test RE 0.052107338924206756\n",
      "25 Train Loss 0.7661811 Test MSE 0.0044788696558899985 Test RE 0.04835262861348347\n",
      "26 Train Loss 0.6739835 Test MSE 0.004118642993075828 Test RE 0.04636742212249492\n",
      "27 Train Loss 0.62585735 Test MSE 0.004014504836865449 Test RE 0.04577747874429329\n",
      "28 Train Loss 0.57401484 Test MSE 0.004600102575439614 Test RE 0.04900265768402705\n",
      "29 Train Loss 0.53639513 Test MSE 0.004556824255540636 Test RE 0.04877160149151097\n",
      "30 Train Loss 0.50142324 Test MSE 0.0043422462503202915 Test RE 0.047609443083580553\n",
      "31 Train Loss 0.47253656 Test MSE 0.003512762915706726 Test RE 0.04282134424593452\n",
      "32 Train Loss 0.44751608 Test MSE 0.0036675941449433964 Test RE 0.04375488152722038\n",
      "33 Train Loss 0.38676015 Test MSE 0.0027908354777950927 Test RE 0.038168315591667584\n",
      "34 Train Loss 0.36548626 Test MSE 0.0025175651885143615 Test RE 0.03625152153042051\n",
      "35 Train Loss 0.3355627 Test MSE 0.0022308012971045768 Test RE 0.03412450191341291\n",
      "36 Train Loss 0.3121491 Test MSE 0.0020690335523837647 Test RE 0.03286394110412345\n",
      "37 Train Loss 0.2925312 Test MSE 0.0020025993191812854 Test RE 0.03233202522712532\n",
      "38 Train Loss 0.27361307 Test MSE 0.0018287764427119314 Test RE 0.03089699099342872\n",
      "39 Train Loss 0.2590205 Test MSE 0.0017674527460792698 Test RE 0.03037454510956058\n",
      "40 Train Loss 0.24709466 Test MSE 0.0016769522916282055 Test RE 0.029586679728086797\n",
      "41 Train Loss 0.23794954 Test MSE 0.001734860124143545 Test RE 0.0300931818351445\n",
      "42 Train Loss 0.2232901 Test MSE 0.0016518534849360301 Test RE 0.029364434312718065\n",
      "43 Train Loss 0.21458565 Test MSE 0.0015490760871652068 Test RE 0.028436245292860245\n",
      "44 Train Loss 0.19793673 Test MSE 0.0012146273390131138 Test RE 0.025180097239994606\n",
      "45 Train Loss 0.19050482 Test MSE 0.001067947924741529 Test RE 0.023610811554252032\n",
      "46 Train Loss 0.18315277 Test MSE 0.0011274627810345223 Test RE 0.024259787029341343\n",
      "47 Train Loss 0.17274581 Test MSE 0.0010442149846350349 Test RE 0.023346986782775626\n",
      "48 Train Loss 0.16390224 Test MSE 0.0010206808853396644 Test RE 0.023082394949877686\n",
      "49 Train Loss 0.15453668 Test MSE 0.001167588608543895 Test RE 0.024687709674925274\n",
      "50 Train Loss 0.14658047 Test MSE 0.0010027637859796072 Test RE 0.022878903029208305\n",
      "51 Train Loss 0.13955933 Test MSE 0.0008954514573336356 Test RE 0.02162006028981261\n",
      "52 Train Loss 0.13407199 Test MSE 0.000988244550998677 Test RE 0.022712664778310195\n",
      "53 Train Loss 0.12637882 Test MSE 0.0009031098847356925 Test RE 0.021712317185242105\n",
      "54 Train Loss 0.12216485 Test MSE 0.0008900747633644264 Test RE 0.021555054270401917\n",
      "55 Train Loss 0.115232624 Test MSE 0.0008330853418348198 Test RE 0.020853580049587636\n",
      "56 Train Loss 0.1103077 Test MSE 0.0007182896547255461 Test RE 0.019363581270817984\n",
      "57 Train Loss 0.10496285 Test MSE 0.0007035886960962302 Test RE 0.01916440338559724\n",
      "58 Train Loss 0.097312875 Test MSE 0.000597817273574451 Test RE 0.017665262963072685\n",
      "59 Train Loss 0.092030324 Test MSE 0.0005768697772098847 Test RE 0.017353008124244132\n",
      "60 Train Loss 0.08732655 Test MSE 0.0005712232577208554 Test RE 0.017267871880979575\n",
      "61 Train Loss 0.0824733 Test MSE 0.0006682701398598734 Test RE 0.018677205831525677\n",
      "62 Train Loss 0.079828165 Test MSE 0.0006428966112520299 Test RE 0.01831919751500424\n",
      "63 Train Loss 0.07631844 Test MSE 0.0006031030976328149 Test RE 0.017743188091760575\n",
      "64 Train Loss 0.07301611 Test MSE 0.0005009341878039415 Test RE 0.016170602930313572\n",
      "65 Train Loss 0.07034472 Test MSE 0.0004158206268100298 Test RE 0.014732922056833056\n",
      "66 Train Loss 0.068435565 Test MSE 0.00039109640792120903 Test RE 0.014288208876649661\n",
      "67 Train Loss 0.065711446 Test MSE 0.0003864235409992935 Test RE 0.014202593754114742\n",
      "68 Train Loss 0.0633079 Test MSE 0.0002994344873981219 Test RE 0.012502209908120116\n",
      "69 Train Loss 0.060524043 Test MSE 0.00024021120755952615 Test RE 0.011197794938095904\n",
      "70 Train Loss 0.05888275 Test MSE 0.00024198245852428152 Test RE 0.011239003832285053\n",
      "71 Train Loss 0.05763499 Test MSE 0.00022153485162965423 Test RE 0.010753674981257668\n",
      "72 Train Loss 0.0560059 Test MSE 0.0002214835212539433 Test RE 0.010752429077619478\n",
      "73 Train Loss 0.054627337 Test MSE 0.0002341754161256784 Test RE 0.01105621631812024\n",
      "74 Train Loss 0.05365254 Test MSE 0.00021783821042567486 Test RE 0.010663576948499993\n",
      "75 Train Loss 0.05213166 Test MSE 0.00022027585221734848 Test RE 0.010723074466613788\n",
      "76 Train Loss 0.050880305 Test MSE 0.00019476637045773166 Test RE 0.010083071862656234\n",
      "77 Train Loss 0.049905904 Test MSE 0.0002050651015000638 Test RE 0.010346221110846696\n",
      "78 Train Loss 0.04909517 Test MSE 0.00018107385213583107 Test RE 0.009722182010143151\n",
      "79 Train Loss 0.048222132 Test MSE 0.00016969283281037474 Test RE 0.009411690275419497\n",
      "80 Train Loss 0.047117475 Test MSE 0.0001671439860489126 Test RE 0.009340739371112357\n",
      "81 Train Loss 0.04670019 Test MSE 0.0001602403860028776 Test RE 0.00914580354021775\n",
      "82 Train Loss 0.045746777 Test MSE 0.0001689443249308019 Test RE 0.00939091005185304\n",
      "83 Train Loss 0.04434929 Test MSE 0.00015741490446844608 Test RE 0.009064812010599221\n",
      "84 Train Loss 0.04352542 Test MSE 0.00016439752413919786 Test RE 0.009263679331301993\n",
      "85 Train Loss 0.04278655 Test MSE 0.00014443254324155116 Test RE 0.008682972112681042\n",
      "86 Train Loss 0.041594516 Test MSE 0.0001335774837058461 Test RE 0.00835030821662535\n",
      "87 Train Loss 0.040789396 Test MSE 0.00011128403011677397 Test RE 0.00762170788101553\n",
      "88 Train Loss 0.040176794 Test MSE 0.00010321060501772735 Test RE 0.0073400334457260855\n",
      "89 Train Loss 0.039166614 Test MSE 0.00010297222611765496 Test RE 0.007331552143998218\n",
      "90 Train Loss 0.038588166 Test MSE 9.769886971156057e-05 Test RE 0.00714135539434262\n",
      "91 Train Loss 0.037423078 Test MSE 9.937878390375774e-05 Test RE 0.0072024908609583565\n",
      "92 Train Loss 0.03662868 Test MSE 0.00010294919589991693 Test RE 0.007330732230267475\n",
      "93 Train Loss 0.035676476 Test MSE 0.00010868535086720825 Test RE 0.007532192014841984\n",
      "94 Train Loss 0.034768883 Test MSE 0.00010847123123707753 Test RE 0.007524768819014787\n",
      "95 Train Loss 0.0336837 Test MSE 0.00011201633693575494 Test RE 0.007646744162320348\n",
      "96 Train Loss 0.03278547 Test MSE 0.00010426936410969742 Test RE 0.007377585297514827\n",
      "97 Train Loss 0.032012496 Test MSE 0.00010159044385132158 Test RE 0.007282195027585442\n",
      "98 Train Loss 0.031270366 Test MSE 0.00010144624663073 Test RE 0.007277025027705869\n",
      "99 Train Loss 0.030542627 Test MSE 8.779771341874753e-05 Test RE 0.00676982558107834\n",
      "100 Train Loss 0.029765273 Test MSE 8.226498226304851e-05 Test RE 0.006553048482739228\n",
      "101 Train Loss 0.029391192 Test MSE 7.780096591516661e-05 Test RE 0.0063727718594351\n",
      "102 Train Loss 0.028862769 Test MSE 7.665686360626554e-05 Test RE 0.006325740908947896\n",
      "103 Train Loss 0.028402291 Test MSE 7.663162383346491e-05 Test RE 0.006324699427466096\n",
      "104 Train Loss 0.027837839 Test MSE 8.103806596814197e-05 Test RE 0.006503998175481286\n",
      "105 Train Loss 0.027320227 Test MSE 8.110387160557442e-05 Test RE 0.006506638372334424\n",
      "106 Train Loss 0.026778936 Test MSE 8.190278071307926e-05 Test RE 0.006538606477187559\n",
      "107 Train Loss 0.026282482 Test MSE 8.171999432418735e-05 Test RE 0.006531306139947773\n",
      "108 Train Loss 0.025702853 Test MSE 8.021290402794538e-05 Test RE 0.006470800297748837\n",
      "109 Train Loss 0.025112046 Test MSE 7.246790774240752e-05 Test RE 0.0061504761432425534\n",
      "110 Train Loss 0.024837421 Test MSE 7.288334701160916e-05 Test RE 0.006168080472212049\n",
      "111 Train Loss 0.024468703 Test MSE 7.266212264863633e-05 Test RE 0.006158712305476424\n",
      "112 Train Loss 0.023866776 Test MSE 7.565964830681992e-05 Test RE 0.006284461008044307\n",
      "113 Train Loss 0.023103757 Test MSE 8.107856446247055e-05 Test RE 0.006505623147830515\n",
      "114 Train Loss 0.022593161 Test MSE 7.05050970328718e-05 Test RE 0.006066610804012472\n",
      "115 Train Loss 0.022195585 Test MSE 6.672019149051928e-05 Test RE 0.005901528637911385\n",
      "116 Train Loss 0.021764701 Test MSE 6.852331362756888e-05 Test RE 0.005980741821079741\n",
      "117 Train Loss 0.021277558 Test MSE 5.896547633795643e-05 Test RE 0.0055479786675995185\n",
      "118 Train Loss 0.020820376 Test MSE 5.728520375143224e-05 Test RE 0.005468360127120338\n",
      "119 Train Loss 0.020483147 Test MSE 6.22632476524506e-05 Test RE 0.0057010094615006866\n",
      "120 Train Loss 0.020076338 Test MSE 6.27538799005768e-05 Test RE 0.005723427264432622\n",
      "121 Train Loss 0.019701304 Test MSE 6.0588872851707765e-05 Test RE 0.005623831675726533\n",
      "122 Train Loss 0.01946665 Test MSE 5.639698270146375e-05 Test RE 0.005425800379341199\n",
      "123 Train Loss 0.019218786 Test MSE 5.7397695195699563e-05 Test RE 0.005473726626614165\n",
      "124 Train Loss 0.0189983 Test MSE 6.007377740049481e-05 Test RE 0.005599875187625695\n",
      "125 Train Loss 0.018748833 Test MSE 6.344043436323146e-05 Test RE 0.005754650477041252\n",
      "126 Train Loss 0.018472511 Test MSE 7.570146822612974e-05 Test RE 0.006286197596510977\n",
      "127 Train Loss 0.018102368 Test MSE 7.730221820064943e-05 Test RE 0.006352312501414019\n",
      "128 Train Loss 0.017807381 Test MSE 7.357021126008552e-05 Test RE 0.006197076801364388\n",
      "129 Train Loss 0.01742008 Test MSE 7.092686167405027e-05 Test RE 0.006084729116742177\n",
      "130 Train Loss 0.01693667 Test MSE 5.791923110155043e-05 Test RE 0.005498538506714992\n",
      "131 Train Loss 0.016657714 Test MSE 6.243094708014847e-05 Test RE 0.0057086818297655394\n",
      "132 Train Loss 0.016368039 Test MSE 6.526452863620797e-05 Test RE 0.005836795530573101\n",
      "133 Train Loss 0.015994433 Test MSE 6.445549577278741e-05 Test RE 0.005800505641297654\n",
      "134 Train Loss 0.015712097 Test MSE 7.436647650650334e-05 Test RE 0.006230522653656822\n",
      "135 Train Loss 0.015463983 Test MSE 7.364277002416198e-05 Test RE 0.006200131987783829\n",
      "136 Train Loss 0.015168904 Test MSE 7.422470471034215e-05 Test RE 0.0062245809053298766\n",
      "137 Train Loss 0.014971814 Test MSE 6.869683020491002e-05 Test RE 0.005988309331075528\n",
      "138 Train Loss 0.014761255 Test MSE 6.5450469860757e-05 Test RE 0.005845104247528326\n",
      "139 Train Loss 0.014614286 Test MSE 6.855623914164046e-05 Test RE 0.00598217852443884\n",
      "140 Train Loss 0.014438907 Test MSE 7.05277330432942e-05 Test RE 0.0060675845835745845\n",
      "141 Train Loss 0.014270881 Test MSE 6.916171018083067e-05 Test RE 0.00600853698423915\n",
      "142 Train Loss 0.014064398 Test MSE 6.615475060059609e-05 Test RE 0.005876468264993334\n",
      "143 Train Loss 0.013864099 Test MSE 6.713945269821364e-05 Test RE 0.005920041827961611\n",
      "144 Train Loss 0.013709229 Test MSE 7.01162892037256e-05 Test RE 0.0060498601947498966\n",
      "145 Train Loss 0.013515445 Test MSE 7.111809940110773e-05 Test RE 0.006092926620693678\n",
      "146 Train Loss 0.013274041 Test MSE 7.159693861062341e-05 Test RE 0.006113404092026295\n",
      "147 Train Loss 0.013063639 Test MSE 7.545706842220851e-05 Test RE 0.006276041997732876\n",
      "148 Train Loss 0.01287913 Test MSE 7.741053375170548e-05 Test RE 0.0063567613606389135\n",
      "149 Train Loss 0.012701013 Test MSE 8.154470779787127e-05 Test RE 0.0065242976682137665\n",
      "150 Train Loss 0.012526213 Test MSE 8.694656273202831e-05 Test RE 0.006736930789324567\n",
      "151 Train Loss 0.012420937 Test MSE 8.696740918130379e-05 Test RE 0.006737738369661688\n",
      "152 Train Loss 0.012328477 Test MSE 8.910387122265136e-05 Test RE 0.006819996681488683\n",
      "153 Train Loss 0.012161822 Test MSE 8.564507687159448e-05 Test RE 0.006686318784231758\n",
      "154 Train Loss 0.012065718 Test MSE 8.72983850775585e-05 Test RE 0.006750547255848224\n",
      "155 Train Loss 0.011808488 Test MSE 9.213196661167684e-05 Test RE 0.006934913487634629\n",
      "156 Train Loss 0.011662816 Test MSE 9.489551205313663e-05 Test RE 0.007038153163727498\n",
      "157 Train Loss 0.011522814 Test MSE 9.082075164996872e-05 Test RE 0.0068853880718305225\n",
      "158 Train Loss 0.011402419 Test MSE 9.327413338561645e-05 Test RE 0.006977767397533959\n",
      "159 Train Loss 0.011287269 Test MSE 9.352781930083907e-05 Test RE 0.00698724998001512\n",
      "160 Train Loss 0.011128037 Test MSE 9.290549785927787e-05 Test RE 0.006963965074233108\n",
      "161 Train Loss 0.011042373 Test MSE 9.443384473331659e-05 Test RE 0.007021011958477088\n",
      "162 Train Loss 0.010945119 Test MSE 9.409610050166186e-05 Test RE 0.0070084453286299786\n",
      "163 Train Loss 0.01081652 Test MSE 9.642578888219396e-05 Test RE 0.007094674535272797\n",
      "164 Train Loss 0.01069305 Test MSE 9.833319559710395e-05 Test RE 0.007164501094577006\n",
      "165 Train Loss 0.010640126 Test MSE 9.801063367318847e-05 Test RE 0.007152740602382904\n",
      "166 Train Loss 0.010538766 Test MSE 9.766046494981458e-05 Test RE 0.0071399516472408905\n",
      "167 Train Loss 0.010471691 Test MSE 0.00010067406043910307 Test RE 0.007249276577765284\n",
      "168 Train Loss 0.010360625 Test MSE 9.513229689226035e-05 Test RE 0.007046928550658676\n",
      "169 Train Loss 0.010308476 Test MSE 9.230916398014019e-05 Test RE 0.006941579242053651\n",
      "170 Train Loss 0.010186446 Test MSE 9.286461912851347e-05 Test RE 0.006962432821666799\n",
      "171 Train Loss 0.010088234 Test MSE 9.359255504006737e-05 Test RE 0.006989667691415746\n",
      "172 Train Loss 0.009978691 Test MSE 9.817756333484571e-05 Test RE 0.007158829210095835\n",
      "173 Train Loss 0.009915788 Test MSE 9.566982492986073e-05 Test RE 0.007066809212213571\n",
      "174 Train Loss 0.009824779 Test MSE 9.661968610470265e-05 Test RE 0.0071018040949536\n",
      "175 Train Loss 0.009716664 Test MSE 9.888677999256045e-05 Test RE 0.007184639714061736\n",
      "176 Train Loss 0.009664055 Test MSE 0.00010122885225053483 Test RE 0.007269223690365334\n",
      "177 Train Loss 0.009552888 Test MSE 0.00010019238457436941 Test RE 0.007231913673115977\n",
      "178 Train Loss 0.009451242 Test MSE 0.00010347254782701134 Test RE 0.0073493418429560285\n",
      "179 Train Loss 0.009380055 Test MSE 0.00010353121086938851 Test RE 0.00735142487691592\n",
      "180 Train Loss 0.009369312 Test MSE 0.00010150440316221396 Test RE 0.007279110594758388\n",
      "181 Train Loss 0.009318378 Test MSE 0.00010239013275768593 Test RE 0.007310800450781805\n",
      "182 Train Loss 0.009187096 Test MSE 9.951370730475708e-05 Test RE 0.007207378498480009\n",
      "183 Train Loss 0.009056456 Test MSE 9.822938089235146e-05 Test RE 0.0071607181554814055\n",
      "184 Train Loss 0.008967743 Test MSE 9.834203470748764e-05 Test RE 0.007164823093636299\n",
      "185 Train Loss 0.008833151 Test MSE 9.983657558139401e-05 Test RE 0.007219061057100936\n",
      "186 Train Loss 0.008716223 Test MSE 9.5507941113859e-05 Test RE 0.007060827773462558\n",
      "187 Train Loss 0.00861602 Test MSE 9.378786000215924e-05 Test RE 0.006996956761353562\n",
      "188 Train Loss 0.008557754 Test MSE 8.970292323527937e-05 Test RE 0.006842883952451143\n",
      "189 Train Loss 0.008439481 Test MSE 8.581312569533703e-05 Test RE 0.006692875362876997\n",
      "190 Train Loss 0.008424469 Test MSE 8.108697595806174e-05 Test RE 0.006505960602012015\n",
      "191 Train Loss 0.008304523 Test MSE 8.176232959092528e-05 Test RE 0.006532997701408047\n",
      "192 Train Loss 0.008227665 Test MSE 8.009693041416675e-05 Test RE 0.006466120791680369\n",
      "193 Train Loss 0.008104856 Test MSE 7.603880308672428e-05 Test RE 0.006300188054872205\n",
      "194 Train Loss 0.008074129 Test MSE 7.039321278860709e-05 Test RE 0.00606179535316475\n",
      "195 Train Loss 0.007979628 Test MSE 6.66044652485656e-05 Test RE 0.005896408312846681\n",
      "196 Train Loss 0.00793558 Test MSE 6.31422918020043e-05 Test RE 0.005741112370240447\n",
      "197 Train Loss 0.007861964 Test MSE 6.118819266176432e-05 Test RE 0.0056515775283333194\n",
      "198 Train Loss 0.007743639 Test MSE 6.0526885343317074e-05 Test RE 0.0056209541133453635\n",
      "199 Train Loss 0.007618618 Test MSE 6.139233010712395e-05 Test RE 0.005660997139386026\n",
      "200 Train Loss 0.0074969493 Test MSE 6.161238970815182e-05 Test RE 0.005671133930238933\n",
      "201 Train Loss 0.0073251887 Test MSE 5.909362354174115e-05 Test RE 0.005554003990741216\n",
      "202 Train Loss 0.0072447006 Test MSE 5.7218011682210795e-05 Test RE 0.005465152158790322\n",
      "203 Train Loss 0.0071632536 Test MSE 5.7793459913439486e-05 Test RE 0.005492565244086892\n",
      "204 Train Loss 0.007057149 Test MSE 5.680594168071653e-05 Test RE 0.005445437260537602\n",
      "205 Train Loss 0.0069474145 Test MSE 5.550116755271382e-05 Test RE 0.005382535917395991\n",
      "206 Train Loss 0.0069096987 Test MSE 5.4344762982581656e-05 Test RE 0.005326166349066589\n",
      "207 Train Loss 0.0068783415 Test MSE 5.339104389193338e-05 Test RE 0.005279223918229397\n",
      "208 Train Loss 0.006742152 Test MSE 4.915859542015031e-05 Test RE 0.005065655013277282\n",
      "209 Train Loss 0.0066976473 Test MSE 4.852155376224128e-05 Test RE 0.0050327253064711185\n",
      "210 Train Loss 0.006669791 Test MSE 4.944318994615191e-05 Test RE 0.0050802971846112335\n",
      "211 Train Loss 0.0066583045 Test MSE 5.0276032438479526e-05 Test RE 0.00512290586650248\n",
      "212 Train Loss 0.0065812427 Test MSE 5.200980835404264e-05 Test RE 0.005210489243007765\n",
      "213 Train Loss 0.0065049506 Test MSE 5.085977342511175e-05 Test RE 0.00515256035283956\n",
      "214 Train Loss 0.006429666 Test MSE 5.250269314668902e-05 Test RE 0.005235120318985603\n",
      "215 Train Loss 0.006352987 Test MSE 5.118793926798881e-05 Test RE 0.005169156725520621\n",
      "216 Train Loss 0.0062871785 Test MSE 4.835444934109525e-05 Test RE 0.00502405167681768\n",
      "217 Train Loss 0.006264891 Test MSE 4.5959306334836266e-05 Test RE 0.004898043180827298\n",
      "218 Train Loss 0.006182097 Test MSE 4.420060758013638e-05 Test RE 0.0048034137451708975\n",
      "219 Train Loss 0.0060816007 Test MSE 4.4383544201235404e-05 Test RE 0.004813343619412011\n",
      "220 Train Loss 0.0060613607 Test MSE 4.3313244907079985e-05 Test RE 0.004754953097341219\n",
      "221 Train Loss 0.005985572 Test MSE 4.33305644967414e-05 Test RE 0.00475590367961296\n",
      "222 Train Loss 0.005907878 Test MSE 4.1175175910477304e-05 Test RE 0.004636108683729334\n",
      "223 Train Loss 0.00586723 Test MSE 4.212173204234053e-05 Test RE 0.004689094523596217\n",
      "224 Train Loss 0.00576195 Test MSE 4.152270431902811e-05 Test RE 0.004655632511172089\n",
      "225 Train Loss 0.0056914943 Test MSE 4.047578557258213e-05 Test RE 0.004596566209630548\n",
      "226 Train Loss 0.0056187613 Test MSE 4.112144217092881e-05 Test RE 0.004633082627638299\n",
      "227 Train Loss 0.0055519706 Test MSE 4.1199541824307036e-05 Test RE 0.0046374802178554865\n",
      "228 Train Loss 0.0055076736 Test MSE 4.117014345950701e-05 Test RE 0.004635825361289868\n",
      "229 Train Loss 0.0054538683 Test MSE 4.013551744167134e-05 Test RE 0.004577204435419986\n",
      "230 Train Loss 0.0053893635 Test MSE 3.95539371862748e-05 Test RE 0.0045439206282651134\n",
      "231 Train Loss 0.0053080227 Test MSE 3.741671588780988e-05 Test RE 0.004419454937558616\n",
      "232 Train Loss 0.0052490397 Test MSE 3.6393828066546615e-05 Test RE 0.004358627417504174\n",
      "233 Train Loss 0.005197643 Test MSE 3.5525238390745345e-05 Test RE 0.004306300947219947\n",
      "234 Train Loss 0.005146779 Test MSE 3.627076327195688e-05 Test RE 0.0043512518838639625\n",
      "235 Train Loss 0.0050968193 Test MSE 3.406907164689106e-05 Test RE 0.004217120654968078\n",
      "236 Train Loss 0.005050535 Test MSE 3.4247489404636614e-05 Test RE 0.004228148644067742\n",
      "237 Train Loss 0.005051244 Test MSE 3.3724306866047104e-05 Test RE 0.004195728647642046\n",
      "238 Train Loss 0.004980478 Test MSE 3.3987672728902625e-05 Test RE 0.004212079802306058\n",
      "239 Train Loss 0.0049434863 Test MSE 3.436149217928632e-05 Test RE 0.004235180111410721\n",
      "240 Train Loss 0.004876395 Test MSE 3.646447857120075e-05 Test RE 0.004362856018053239\n",
      "241 Train Loss 0.0048178607 Test MSE 3.5611479940180095e-05 Test RE 0.004311524795995785\n",
      "242 Train Loss 0.0048018317 Test MSE 3.823231468527756e-05 Test RE 0.0044673622803111865\n",
      "243 Train Loss 0.004776442 Test MSE 3.800686119004076e-05 Test RE 0.00445417093072218\n",
      "244 Train Loss 0.0047601243 Test MSE 3.719623086992766e-05 Test RE 0.004406414464652998\n",
      "245 Train Loss 0.0047013904 Test MSE 3.419595969067034e-05 Test RE 0.004224966552314061\n",
      "246 Train Loss 0.0046583666 Test MSE 3.24435082481716e-05 Test RE 0.004115283718114898\n",
      "247 Train Loss 0.0045894585 Test MSE 3.131876284718814e-05 Test RE 0.0040433205772414955\n",
      "248 Train Loss 0.004566557 Test MSE 3.14748784167901e-05 Test RE 0.004053385480358155\n",
      "249 Train Loss 0.004526936 Test MSE 2.9234415874276885e-05 Test RE 0.0039064573512214255\n",
      "250 Train Loss 0.004503901 Test MSE 2.8419728437291647e-05 Test RE 0.0038516413345505\n",
      "251 Train Loss 0.0044663446 Test MSE 2.8426627235243578e-05 Test RE 0.00385210879297566\n",
      "252 Train Loss 0.0044120573 Test MSE 2.5463484130998867e-05 Test RE 0.0036458163691777067\n",
      "253 Train Loss 0.004379767 Test MSE 2.3557474826105336e-05 Test RE 0.0035067131726371197\n",
      "254 Train Loss 0.0043515386 Test MSE 2.2901003636115656e-05 Test RE 0.0034575075310176993\n",
      "255 Train Loss 0.004308303 Test MSE 2.171060714944184e-05 Test RE 0.0033664476189862063\n",
      "256 Train Loss 0.004274579 Test MSE 2.1823916512439785e-05 Test RE 0.003375221063754232\n",
      "257 Train Loss 0.004240923 Test MSE 2.1452632809076475e-05 Test RE 0.00334638709325039\n",
      "258 Train Loss 0.0042079207 Test MSE 2.0910874735559368e-05 Test RE 0.0033038625953611773\n",
      "259 Train Loss 0.0041812574 Test MSE 2.1791959304048184e-05 Test RE 0.0033727489557311995\n",
      "260 Train Loss 0.004146305 Test MSE 1.9427407779090692e-05 Test RE 0.0031845150443246865\n",
      "261 Train Loss 0.004130308 Test MSE 1.8435285698362e-05 Test RE 0.003102135852900367\n",
      "262 Train Loss 0.0041114828 Test MSE 1.756936886894717e-05 Test RE 0.0030284050196580778\n",
      "263 Train Loss 0.00408662 Test MSE 1.701281810252882e-05 Test RE 0.0029800531247463715\n",
      "264 Train Loss 0.004077804 Test MSE 1.7050369227354015e-05 Test RE 0.0029833401364784233\n",
      "265 Train Loss 0.0040673846 Test MSE 1.693531092041638e-05 Test RE 0.0029732570963044713\n",
      "266 Train Loss 0.004047892 Test MSE 1.6843405041192282e-05 Test RE 0.002965178367923273\n",
      "267 Train Loss 0.004021024 Test MSE 1.655991936076784e-05 Test RE 0.0029401195217594244\n",
      "268 Train Loss 0.004008137 Test MSE 1.6384148925135134e-05 Test RE 0.0029244743750937896\n",
      "269 Train Loss 0.003994843 Test MSE 1.5983276005137554e-05 Test RE 0.002888476086741196\n",
      "270 Train Loss 0.0039690943 Test MSE 1.6239290148246824e-05 Test RE 0.0029115174516506368\n",
      "271 Train Loss 0.0039338027 Test MSE 1.6198225942036093e-05 Test RE 0.0029078339522553495\n",
      "272 Train Loss 0.0039059292 Test MSE 1.7012641035128868e-05 Test RE 0.0029800376166856735\n",
      "273 Train Loss 0.0038854957 Test MSE 1.5234056479584871e-05 Test RE 0.002819964607042602\n",
      "274 Train Loss 0.0038757245 Test MSE 1.4751384945839463e-05 Test RE 0.0027749315520778886\n",
      "275 Train Loss 0.0038462596 Test MSE 1.3996503752823423e-05 Test RE 0.002702997595464537\n",
      "276 Train Loss 0.0038196968 Test MSE 1.2952362894873149e-05 Test RE 0.0026002217027578356\n",
      "277 Train Loss 0.0038037905 Test MSE 1.2132325522639548e-05 Test RE 0.002516563562153008\n",
      "278 Train Loss 0.003802675 Test MSE 1.208793913091274e-05 Test RE 0.0025119558911623173\n",
      "279 Train Loss 0.003788464 Test MSE 1.171245467496752e-05 Test RE 0.0024726340102499043\n",
      "280 Train Loss 0.0037719125 Test MSE 1.1694520101717564e-05 Test RE 0.0024707401875643463\n",
      "281 Train Loss 0.0037570996 Test MSE 1.177214869320559e-05 Test RE 0.002478927049331585\n",
      "282 Train Loss 0.0037335278 Test MSE 1.144015464163804e-05 Test RE 0.0024437221449819424\n",
      "283 Train Loss 0.0037353663 Test MSE 1.195146948435376e-05 Test RE 0.0024977359825400012\n",
      "284 Train Loss 0.0037077658 Test MSE 1.1952311863839149e-05 Test RE 0.0024978240053760512\n",
      "285 Train Loss 0.0036895683 Test MSE 1.2027460121955582e-05 Test RE 0.0025056640368465778\n",
      "286 Train Loss 0.0036665688 Test MSE 1.2113304139996143e-05 Test RE 0.002514590020663398\n",
      "287 Train Loss 0.0036417155 Test MSE 1.241888398866686e-05 Test RE 0.0025461099961371996\n",
      "288 Train Loss 0.0036030672 Test MSE 1.2839380620919528e-05 Test RE 0.0025888561154752067\n",
      "289 Train Loss 0.0035754503 Test MSE 1.2529798019196687e-05 Test RE 0.0025574544772317387\n",
      "290 Train Loss 0.0035460757 Test MSE 1.2664138522549906e-05 Test RE 0.002571128030228823\n",
      "291 Train Loss 0.0035268208 Test MSE 1.3150521484577024e-05 Test RE 0.0026200366381458565\n",
      "292 Train Loss 0.003493073 Test MSE 1.3544156797930054e-05 Test RE 0.0026589603627323534\n",
      "293 Train Loss 0.0034765145 Test MSE 1.3668129955660364e-05 Test RE 0.0026711017175121195\n",
      "294 Train Loss 0.003426783 Test MSE 1.315340246934135e-05 Test RE 0.0026203236181061382\n",
      "295 Train Loss 0.0033800383 Test MSE 1.2967064007460791e-05 Test RE 0.002601696928230692\n",
      "296 Train Loss 0.0033568172 Test MSE 1.2808183345412584e-05 Test RE 0.0025857089863163796\n",
      "297 Train Loss 0.003346772 Test MSE 1.2735632831901852e-05 Test RE 0.002578375357622205\n",
      "298 Train Loss 0.003308523 Test MSE 1.2926290775448193e-05 Test RE 0.0025976033603990877\n",
      "299 Train Loss 0.0032777356 Test MSE 1.2958301381810737e-05 Test RE 0.002600817718065243\n",
      "Training time: 251.27\n",
      "KG_tanhALR_high\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 54608.2 Test MSE 9.775086230999793 Test RE 2.2588956833562612\n",
      "1 Train Loss 26536.97 Test MSE 2.486763045796988 Test RE 1.1393393034845403\n",
      "2 Train Loss 14888.662 Test MSE 5.5863530767207745 Test RE 1.7076547380777714\n",
      "3 Train Loss 5654.1064 Test MSE 12.755112102707775 Test RE 2.580346428958511\n",
      "4 Train Loss 2997.9355 Test MSE 14.610809384248801 Test RE 2.7616778349814965\n",
      "5 Train Loss 2188.0864 Test MSE 15.35791594733012 Test RE 2.8314051658751067\n",
      "6 Train Loss 1621.2375 Test MSE 15.255091548287567 Test RE 2.821910828226066\n",
      "7 Train Loss 1080.4526 Test MSE 14.63269651840871 Test RE 2.7637455709895433\n",
      "8 Train Loss 832.07324 Test MSE 14.857767947253798 Test RE 2.7849196048342457\n",
      "9 Train Loss 688.3058 Test MSE 14.864131600807003 Test RE 2.785515938226152\n",
      "10 Train Loss 581.16113 Test MSE 14.95280675127444 Test RE 2.793812378089961\n",
      "11 Train Loss 488.9433 Test MSE 15.154996785326288 Test RE 2.8126377487534566\n",
      "12 Train Loss 432.24747 Test MSE 14.982832167258534 Test RE 2.7966159758272306\n",
      "13 Train Loss 399.12027 Test MSE 15.112908752805074 Test RE 2.808729443976829\n",
      "14 Train Loss 377.65625 Test MSE 14.886136488445963 Test RE 2.787577017149704\n",
      "15 Train Loss 339.90332 Test MSE 14.841646557228025 Test RE 2.78340830917062\n",
      "16 Train Loss 321.4972 Test MSE 14.523010586339616 Test RE 2.7533676397684754\n",
      "17 Train Loss 302.55832 Test MSE 12.877244359257958 Test RE 2.592670614437892\n",
      "18 Train Loss 250.85281 Test MSE 11.699202376788456 Test RE 2.4712347579847127\n",
      "19 Train Loss 228.88419 Test MSE 10.901482298002142 Test RE 2.38549578676343\n",
      "20 Train Loss 204.69016 Test MSE 9.786187457546223 Test RE 2.2601779941482905\n",
      "21 Train Loss 175.62198 Test MSE 9.304401847250883 Test RE 2.2038402284080103\n",
      "22 Train Loss 150.97629 Test MSE 8.653991169394061 Test RE 2.1254167592948705\n",
      "23 Train Loss 129.84506 Test MSE 7.784840492472555 Test RE 2.015861711693456\n",
      "24 Train Loss 115.85421 Test MSE 7.354943578784485 Test RE 1.9594110353436707\n",
      "25 Train Loss 101.31433 Test MSE 7.206888471549032 Test RE 1.9395892907690635\n",
      "26 Train Loss 91.34887 Test MSE 6.566216303038458 Test RE 1.8513710545775346\n",
      "27 Train Loss 76.3138 Test MSE 5.367286644378938 Test RE 1.6738374166734822\n",
      "28 Train Loss 58.508858 Test MSE 3.8144373165475884 Test RE 1.4110783159697715\n",
      "29 Train Loss 44.032722 Test MSE 2.161980702067733 Test RE 1.06233571754203\n",
      "30 Train Loss 32.01425 Test MSE 1.2301712273045642 Test RE 0.801343390858218\n",
      "31 Train Loss 22.38225 Test MSE 0.42956781090455887 Test RE 0.473534627136551\n",
      "32 Train Loss 14.590872 Test MSE 0.32210400203431566 Test RE 0.4100472817953618\n",
      "33 Train Loss 10.934754 Test MSE 0.204392796013233 Test RE 0.3266394752623619\n",
      "34 Train Loss 8.645106 Test MSE 0.18548005007292126 Test RE 0.311160513217403\n",
      "35 Train Loss 6.897219 Test MSE 0.15840974802056876 Test RE 0.28755890982082843\n",
      "36 Train Loss 5.8209333 Test MSE 0.11877459811181351 Test RE 0.24899903368917206\n",
      "37 Train Loss 5.1600294 Test MSE 0.09676979495070871 Test RE 0.2247531500255026\n",
      "38 Train Loss 4.47428 Test MSE 0.08560606051288276 Test RE 0.21139179805864367\n",
      "39 Train Loss 3.8822427 Test MSE 0.0756459727335545 Test RE 0.19871414517297226\n",
      "40 Train Loss 3.3685956 Test MSE 0.06620357343394524 Test RE 0.1858988027446155\n",
      "41 Train Loss 2.750501 Test MSE 0.04279426611560854 Test RE 0.14946127006198826\n",
      "42 Train Loss 2.429594 Test MSE 0.03968681603113871 Test RE 0.14393254542583497\n",
      "43 Train Loss 2.0989637 Test MSE 0.02692665060583479 Test RE 0.11855695718653059\n",
      "44 Train Loss 1.823993 Test MSE 0.023850428565629234 Test RE 0.11157938684004313\n",
      "45 Train Loss 1.5524112 Test MSE 0.02088098814739562 Test RE 0.10440262068106441\n",
      "46 Train Loss 1.3477179 Test MSE 0.016667633112381005 Test RE 0.09327662913349744\n",
      "47 Train Loss 1.1716143 Test MSE 0.014865734931589516 Test RE 0.08809049882473599\n",
      "48 Train Loss 1.0306593 Test MSE 0.012482440209700123 Test RE 0.08072083098778476\n",
      "49 Train Loss 0.9751604 Test MSE 0.01143723680114571 Test RE 0.07726742395571058\n",
      "50 Train Loss 0.8937227 Test MSE 0.01139118445602746 Test RE 0.0771117073560523\n",
      "51 Train Loss 0.8318339 Test MSE 0.010382071173822633 Test RE 0.0736169597373475\n",
      "52 Train Loss 0.7935444 Test MSE 0.009635708214211905 Test RE 0.07092146483247268\n",
      "53 Train Loss 0.73997515 Test MSE 0.010381942980979891 Test RE 0.07361650524246319\n",
      "54 Train Loss 0.7037718 Test MSE 0.010000550423265468 Test RE 0.07225165988132999\n",
      "55 Train Loss 0.6599984 Test MSE 0.009490988744028681 Test RE 0.07038686236066466\n",
      "56 Train Loss 0.62486774 Test MSE 0.009314437913569633 Test RE 0.06972912299789748\n",
      "57 Train Loss 0.5918878 Test MSE 0.008879641227694544 Test RE 0.0680822008337197\n",
      "58 Train Loss 0.55712575 Test MSE 0.008331103850341368 Test RE 0.06594580149427651\n",
      "59 Train Loss 0.5422929 Test MSE 0.008060339668686316 Test RE 0.06486531758063144\n",
      "60 Train Loss 0.49703506 Test MSE 0.007405516829624501 Test RE 0.06217468068591937\n",
      "61 Train Loss 0.48014262 Test MSE 0.007140269228331151 Test RE 0.06105105463259444\n",
      "62 Train Loss 0.46008772 Test MSE 0.007567280088633382 Test RE 0.06285007225764257\n",
      "63 Train Loss 0.4485572 Test MSE 0.0067689445851959 Test RE 0.05944240279288915\n",
      "64 Train Loss 0.41040215 Test MSE 0.00630371881208324 Test RE 0.05736332187743753\n",
      "65 Train Loss 0.3960592 Test MSE 0.0064077122716515895 Test RE 0.057834552294032976\n",
      "66 Train Loss 0.3617619 Test MSE 0.005880378985517531 Test RE 0.0554036701934545\n",
      "67 Train Loss 0.34668803 Test MSE 0.005866556571793467 Test RE 0.055338515973603127\n",
      "68 Train Loss 0.32452723 Test MSE 0.005048890786970946 Test RE 0.051337399439571316\n",
      "69 Train Loss 0.29795536 Test MSE 0.004383077287070197 Test RE 0.04783276004264079\n",
      "70 Train Loss 0.2800123 Test MSE 0.004386822654805708 Test RE 0.04785319237925006\n",
      "71 Train Loss 0.269876 Test MSE 0.003825622864275713 Test RE 0.04468759208695781\n",
      "72 Train Loss 0.25240117 Test MSE 0.003487244077234274 Test RE 0.04266552063413275\n",
      "73 Train Loss 0.24296899 Test MSE 0.0031460806403767775 Test RE 0.040524792708199024\n",
      "74 Train Loss 0.2374564 Test MSE 0.0030958697786890622 Test RE 0.040200107944573134\n",
      "75 Train Loss 0.22795872 Test MSE 0.002787032563349895 Test RE 0.03814230181894511\n",
      "76 Train Loss 0.2148972 Test MSE 0.002566929019908742 Test RE 0.036605201918186156\n",
      "77 Train Loss 0.20913833 Test MSE 0.0024301063737918 Test RE 0.03561627690398341\n",
      "78 Train Loss 0.201065 Test MSE 0.002030125654154026 Test RE 0.03255347360153563\n",
      "79 Train Loss 0.19602047 Test MSE 0.0020749971653093533 Test RE 0.03291126919169252\n",
      "80 Train Loss 0.19205889 Test MSE 0.002015952813810627 Test RE 0.03243964240800765\n",
      "81 Train Loss 0.18542846 Test MSE 0.002033211245997101 Test RE 0.03257820325166492\n",
      "82 Train Loss 0.17785421 Test MSE 0.0017299935225807014 Test RE 0.030050943739438493\n",
      "83 Train Loss 0.17439939 Test MSE 0.0017491593198323088 Test RE 0.030216945487752084\n",
      "84 Train Loss 0.17109035 Test MSE 0.0017021156728661004 Test RE 0.029807833536987828\n",
      "85 Train Loss 0.16681145 Test MSE 0.0016608054425324688 Test RE 0.02944389474627126\n",
      "86 Train Loss 0.16102685 Test MSE 0.0016463659606919885 Test RE 0.029315618816608505\n",
      "87 Train Loss 0.15610677 Test MSE 0.001687124494211996 Test RE 0.029676278782452527\n",
      "88 Train Loss 0.1516835 Test MSE 0.001755907602959937 Test RE 0.030275178092748864\n",
      "89 Train Loss 0.1472513 Test MSE 0.0016472988894725936 Test RE 0.029323923626055164\n",
      "90 Train Loss 0.14131168 Test MSE 0.0015163273539382544 Test RE 0.028134056912883034\n",
      "91 Train Loss 0.13833329 Test MSE 0.0014592381649770412 Test RE 0.02759935716484429\n",
      "92 Train Loss 0.13555719 Test MSE 0.0013751954745776565 Test RE 0.026792799502399264\n",
      "93 Train Loss 0.13249385 Test MSE 0.0013531681017214514 Test RE 0.02657735471090451\n",
      "94 Train Loss 0.12863396 Test MSE 0.0013047101083804823 Test RE 0.026097138503182727\n",
      "95 Train Loss 0.12515546 Test MSE 0.0012558921009122896 Test RE 0.025604248959180925\n",
      "96 Train Loss 0.123907745 Test MSE 0.0012422930993449654 Test RE 0.025465248192410358\n",
      "97 Train Loss 0.12138051 Test MSE 0.0012183375149858987 Test RE 0.025218525223557286\n",
      "98 Train Loss 0.1173852 Test MSE 0.0011835475515199396 Test RE 0.024855856477283302\n",
      "99 Train Loss 0.11352442 Test MSE 0.0011778399042124237 Test RE 0.024795850474303157\n",
      "100 Train Loss 0.11033803 Test MSE 0.0011406050217203636 Test RE 0.02440076917035272\n",
      "101 Train Loss 0.10801152 Test MSE 0.0011009533223062268 Test RE 0.02397288654707531\n",
      "102 Train Loss 0.10673474 Test MSE 0.001056978995596356 Test RE 0.023489244873901614\n",
      "103 Train Loss 0.105218016 Test MSE 0.00103809759033615 Test RE 0.02327849872337759\n",
      "104 Train Loss 0.10349484 Test MSE 0.0010240049714194482 Test RE 0.023119951006720627\n",
      "105 Train Loss 0.10167206 Test MSE 0.001014530123185539 Test RE 0.023012741026021456\n",
      "106 Train Loss 0.09911195 Test MSE 0.0009844207907835393 Test RE 0.022668681760327675\n",
      "107 Train Loss 0.09702443 Test MSE 0.0009629955102255098 Test RE 0.022420640135582818\n",
      "108 Train Loss 0.09579305 Test MSE 0.0009786488594714284 Test RE 0.022602127685876484\n",
      "109 Train Loss 0.09430868 Test MSE 0.0009934559301497316 Test RE 0.022772472177685153\n",
      "110 Train Loss 0.093875974 Test MSE 0.0009622786220654653 Test RE 0.02241229322028441\n",
      "111 Train Loss 0.09201287 Test MSE 0.0009128532434034918 Test RE 0.021829126538300974\n",
      "112 Train Loss 0.089949235 Test MSE 0.0008945907689268572 Test RE 0.021609667426706253\n",
      "113 Train Loss 0.08804177 Test MSE 0.0009020322617250457 Test RE 0.021699359361993183\n",
      "114 Train Loss 0.08534819 Test MSE 0.000799310697621018 Test RE 0.02042648735903241\n",
      "115 Train Loss 0.08194241 Test MSE 0.000779072835928569 Test RE 0.020166238905655772\n",
      "116 Train Loss 0.080153435 Test MSE 0.0007247620945425741 Test RE 0.019450627314989637\n",
      "117 Train Loss 0.079026975 Test MSE 0.0007095996856814868 Test RE 0.019246093180856672\n",
      "118 Train Loss 0.07765828 Test MSE 0.0006946316853222276 Test RE 0.01904202678382843\n",
      "119 Train Loss 0.07540172 Test MSE 0.0006504455697331765 Test RE 0.018426436586325527\n",
      "120 Train Loss 0.07329642 Test MSE 0.0006909962095286578 Test RE 0.018992131534040124\n",
      "121 Train Loss 0.07131734 Test MSE 0.0006738433179335327 Test RE 0.018754925353257235\n",
      "122 Train Loss 0.070414305 Test MSE 0.0006412151677323547 Test RE 0.018295225649021456\n",
      "123 Train Loss 0.068994075 Test MSE 0.0005927519257520812 Test RE 0.01759026424975105\n",
      "124 Train Loss 0.06780253 Test MSE 0.000564307316230694 Test RE 0.017163020347326644\n",
      "125 Train Loss 0.067059 Test MSE 0.0005724612735227383 Test RE 0.017286574137396933\n",
      "126 Train Loss 0.06573833 Test MSE 0.0005532505939853181 Test RE 0.016994047246261502\n",
      "127 Train Loss 0.06441792 Test MSE 0.0005552442958019845 Test RE 0.017024639707017772\n",
      "128 Train Loss 0.06316135 Test MSE 0.0005186471557019987 Test RE 0.016454014555786566\n",
      "129 Train Loss 0.0618096 Test MSE 0.0005021579255726425 Test RE 0.016190342556131266\n",
      "130 Train Loss 0.060573142 Test MSE 0.00048072996251286466 Test RE 0.01584114147254623\n",
      "131 Train Loss 0.05925788 Test MSE 0.00045615226780612946 Test RE 0.015430883628833669\n",
      "132 Train Loss 0.05910313 Test MSE 0.00044657633698297214 Test RE 0.015268055517341497\n",
      "133 Train Loss 0.058005873 Test MSE 0.00041070315111992593 Test RE 0.014641982868756372\n",
      "134 Train Loss 0.056905277 Test MSE 0.00038873776228966423 Test RE 0.014245058663871999\n",
      "135 Train Loss 0.05593962 Test MSE 0.00036936092210183207 Test RE 0.013885494468267374\n",
      "136 Train Loss 0.054654587 Test MSE 0.0003398966160462937 Test RE 0.013320155576086203\n",
      "137 Train Loss 0.05327693 Test MSE 0.0003131820192593825 Test RE 0.012785987833800248\n",
      "138 Train Loss 0.052346945 Test MSE 0.0002906120595142598 Test RE 0.012316652628365711\n",
      "139 Train Loss 0.051632892 Test MSE 0.0002843039443586113 Test RE 0.012182244718156956\n",
      "140 Train Loss 0.05074217 Test MSE 0.0002946312725012939 Test RE 0.012401530840564742\n",
      "141 Train Loss 0.04952859 Test MSE 0.0002706198485779721 Test RE 0.011885451939372148\n",
      "142 Train Loss 0.048142843 Test MSE 0.00024365279196966936 Test RE 0.011277726885847267\n",
      "143 Train Loss 0.047282457 Test MSE 0.0002408218360087678 Test RE 0.01121201857134384\n",
      "144 Train Loss 0.046244502 Test MSE 0.0002250281374689677 Test RE 0.010838128346831713\n",
      "145 Train Loss 0.045275897 Test MSE 0.00022755333155147984 Test RE 0.010898769708999436\n",
      "146 Train Loss 0.04453316 Test MSE 0.00022359920795366888 Test RE 0.010803662467292382\n",
      "147 Train Loss 0.04375496 Test MSE 0.0002181563410958465 Test RE 0.010671360645422984\n",
      "148 Train Loss 0.04303914 Test MSE 0.00020745945166224263 Test RE 0.010406447312066391\n",
      "149 Train Loss 0.042433105 Test MSE 0.0002197575284551211 Test RE 0.010710450981794486\n",
      "150 Train Loss 0.041669566 Test MSE 0.00020566433850501852 Test RE 0.01036132684032307\n",
      "151 Train Loss 0.041106958 Test MSE 0.0002049728542656782 Test RE 0.010343893758130811\n",
      "152 Train Loss 0.03993069 Test MSE 0.00021414056996069751 Test RE 0.01057268648238897\n",
      "153 Train Loss 0.039000046 Test MSE 0.00019562381418635586 Test RE 0.01010524245641333\n",
      "154 Train Loss 0.038402643 Test MSE 0.0001727308443324016 Test RE 0.009495565302930649\n",
      "155 Train Loss 0.037954353 Test MSE 0.0001676859554517971 Test RE 0.009355870929108738\n",
      "156 Train Loss 0.037413035 Test MSE 0.00015309147453426385 Test RE 0.008939461944775389\n",
      "157 Train Loss 0.036792777 Test MSE 0.0001464877693555789 Test RE 0.008744531767391107\n",
      "158 Train Loss 0.03628555 Test MSE 0.00013874706397040278 Test RE 0.008510356983264643\n",
      "159 Train Loss 0.035525713 Test MSE 0.00014748259346256056 Test RE 0.008774174349211374\n",
      "160 Train Loss 0.03497501 Test MSE 0.00015163886482174194 Test RE 0.008896949781150921\n",
      "161 Train Loss 0.034720644 Test MSE 0.0001497684520279942 Test RE 0.008841909133102269\n",
      "162 Train Loss 0.03417873 Test MSE 0.0001784247220670116 Test RE 0.009650801684822298\n",
      "163 Train Loss 0.033369154 Test MSE 0.00020409899432527126 Test RE 0.01032182066676507\n",
      "164 Train Loss 0.03279872 Test MSE 0.0002001900913654335 Test RE 0.01022250109587878\n",
      "165 Train Loss 0.032188445 Test MSE 0.00020101983019469506 Test RE 0.010243664069635096\n",
      "166 Train Loss 0.031959984 Test MSE 0.00020654123661739685 Test RE 0.010383392317782032\n",
      "167 Train Loss 0.03153887 Test MSE 0.00022042107408510686 Test RE 0.010726608599638499\n",
      "168 Train Loss 0.031214267 Test MSE 0.00021005970801853943 Test RE 0.010471460422786466\n",
      "169 Train Loss 0.030646805 Test MSE 0.00020261215248602103 Test RE 0.0102841552011566\n",
      "170 Train Loss 0.029957477 Test MSE 0.00019842416659112072 Test RE 0.010177313656765687\n",
      "171 Train Loss 0.029410424 Test MSE 0.00020684211800871852 Test RE 0.010390952630225244\n",
      "172 Train Loss 0.028944548 Test MSE 0.00020110288159087017 Test RE 0.010245779937378833\n",
      "173 Train Loss 0.02863928 Test MSE 0.0001985493216864764 Test RE 0.010180522796797873\n",
      "174 Train Loss 0.028346747 Test MSE 0.0001970711910241791 Test RE 0.010142556777667289\n",
      "175 Train Loss 0.027908733 Test MSE 0.00017708062739779345 Test RE 0.00961438264901846\n",
      "176 Train Loss 0.027609253 Test MSE 0.00014966697726939314 Test RE 0.008838913233055978\n",
      "177 Train Loss 0.027229873 Test MSE 0.00014386901487759842 Test RE 0.008666016504508522\n",
      "178 Train Loss 0.026577054 Test MSE 0.00013580066393999298 Test RE 0.008419510124535637\n",
      "179 Train Loss 0.026229983 Test MSE 0.00012856384482588017 Test RE 0.008192101090677322\n",
      "180 Train Loss 0.025915204 Test MSE 0.00012769141113714915 Test RE 0.008164257993397596\n",
      "181 Train Loss 0.025525268 Test MSE 0.00011795547001253477 Test RE 0.007846842210650998\n",
      "182 Train Loss 0.025148658 Test MSE 0.0001078555107495916 Test RE 0.007503381821517913\n",
      "183 Train Loss 0.024924498 Test MSE 0.00010509556123100496 Test RE 0.00740675644000264\n",
      "184 Train Loss 0.024738766 Test MSE 0.00010387592104317328 Test RE 0.007363653098149414\n",
      "185 Train Loss 0.024513312 Test MSE 9.738769285117374e-05 Test RE 0.007129973497802522\n",
      "186 Train Loss 0.024185482 Test MSE 9.34162777001155e-05 Test RE 0.00698308222778121\n",
      "187 Train Loss 0.023898179 Test MSE 9.026014855272675e-05 Test RE 0.006864104693268034\n",
      "188 Train Loss 0.023613725 Test MSE 8.986302852174626e-05 Test RE 0.006848987953482524\n",
      "189 Train Loss 0.023392916 Test MSE 9.111351573727815e-05 Test RE 0.006896476795684754\n",
      "190 Train Loss 0.02307739 Test MSE 9.368896222188077e-05 Test RE 0.006993266699494928\n",
      "191 Train Loss 0.022883706 Test MSE 8.998935355328746e-05 Test RE 0.00685380024828038\n",
      "192 Train Loss 0.02271533 Test MSE 8.993588838189832e-05 Test RE 0.0068517639293458185\n",
      "193 Train Loss 0.02250179 Test MSE 7.982727843430614e-05 Test RE 0.006455227289083133\n",
      "194 Train Loss 0.02224073 Test MSE 7.573418932954095e-05 Test RE 0.006287556018641377\n",
      "195 Train Loss 0.021993654 Test MSE 7.334504419944343e-05 Test RE 0.00618758622871965\n",
      "196 Train Loss 0.021726912 Test MSE 6.953256122948145e-05 Test RE 0.00602462459377319\n",
      "197 Train Loss 0.02148143 Test MSE 7.188872344189703e-05 Test RE 0.0061258486524720145\n",
      "198 Train Loss 0.021143323 Test MSE 6.787659533533059e-05 Test RE 0.0059524519997727135\n",
      "199 Train Loss 0.02108525 Test MSE 6.401513258024426e-05 Test RE 0.0057806570081768045\n",
      "200 Train Loss 0.020805757 Test MSE 6.37092853910146e-05 Test RE 0.005766831257597199\n",
      "201 Train Loss 0.020619122 Test MSE 6.597320384646758e-05 Test RE 0.00586839940621668\n",
      "202 Train Loss 0.020320116 Test MSE 6.646185683401185e-05 Test RE 0.005890092459801903\n",
      "203 Train Loss 0.020241173 Test MSE 6.686085470489907e-05 Test RE 0.005907746327785682\n",
      "204 Train Loss 0.020085076 Test MSE 6.475889457594788e-05 Test RE 0.005814141409193659\n",
      "205 Train Loss 0.019859243 Test MSE 6.58212776478193e-05 Test RE 0.005861638498473489\n",
      "206 Train Loss 0.019665891 Test MSE 6.791412042845904e-05 Test RE 0.005954097157808714\n",
      "207 Train Loss 0.019431992 Test MSE 6.564678747074887e-05 Test RE 0.005853863831011968\n",
      "208 Train Loss 0.019600857 Test MSE 6.199136790233316e-05 Test RE 0.005688548781703426\n",
      "209 Train Loss 0.019205209 Test MSE 6.0083440007184585e-05 Test RE 0.005600325527342549\n",
      "210 Train Loss 0.018849539 Test MSE 5.4007203854105654e-05 Test RE 0.005309599006081724\n",
      "211 Train Loss 0.018587032 Test MSE 5.459815262896819e-05 Test RE 0.005338568886348187\n",
      "212 Train Loss 0.018399874 Test MSE 5.863464604898503e-05 Test RE 0.0055323930977409265\n",
      "213 Train Loss 0.01815865 Test MSE 5.5636026202408286e-05 Test RE 0.00538907128547607\n",
      "214 Train Loss 0.01829914 Test MSE 5.565503430692061e-05 Test RE 0.005389991797681568\n",
      "215 Train Loss 0.018110525 Test MSE 5.597724110805543e-05 Test RE 0.0054055715714129045\n",
      "216 Train Loss 0.01793065 Test MSE 5.781144042208671e-05 Test RE 0.005493419591938771\n",
      "217 Train Loss 0.017854912 Test MSE 5.720576576575493e-05 Test RE 0.005464567295946702\n",
      "218 Train Loss 0.017851772 Test MSE 5.764521463308919e-05 Test RE 0.00548551626570726\n",
      "219 Train Loss 0.017566 Test MSE 5.818829634835544e-05 Test RE 0.005511295507697625\n",
      "220 Train Loss 0.017326199 Test MSE 6.092219921349019e-05 Test RE 0.005639280058560036\n",
      "221 Train Loss 0.017126938 Test MSE 5.5016661453812536e-05 Test RE 0.00535899057566189\n",
      "222 Train Loss 0.016977277 Test MSE 5.854821214223188e-05 Test RE 0.005528313916436275\n",
      "223 Train Loss 0.016890634 Test MSE 5.5502544307139764e-05 Test RE 0.005382602676209534\n",
      "224 Train Loss 0.016840668 Test MSE 5.294247114437614e-05 Test RE 0.0052570000504283424\n",
      "225 Train Loss 0.016770558 Test MSE 5.706638265031038e-05 Test RE 0.005457905966222019\n",
      "226 Train Loss 0.016727153 Test MSE 5.8203027818746416e-05 Test RE 0.0055119931080199235\n",
      "227 Train Loss 0.016604971 Test MSE 5.6310682814517975e-05 Test RE 0.005421647451257929\n",
      "228 Train Loss 0.016586123 Test MSE 6.0423944068064853e-05 Test RE 0.005616172152266372\n",
      "229 Train Loss 0.016411062 Test MSE 6.718693025889107e-05 Test RE 0.005922134632281307\n",
      "230 Train Loss 0.016321825 Test MSE 6.593350562400082e-05 Test RE 0.005866633537138226\n",
      "231 Train Loss 0.016223889 Test MSE 6.577037549494985e-05 Test RE 0.005859371543643843\n",
      "232 Train Loss 0.016084993 Test MSE 6.919394215902034e-05 Test RE 0.0060099369241317134\n",
      "233 Train Loss 0.015984463 Test MSE 6.855499362338218e-05 Test RE 0.0059821241825838015\n",
      "234 Train Loss 0.015879106 Test MSE 6.859809045443422e-05 Test RE 0.005984004206754383\n",
      "235 Train Loss 0.01580225 Test MSE 5.917122670764916e-05 Test RE 0.005557649619977913\n",
      "236 Train Loss 0.015601957 Test MSE 5.9453412701608295e-05 Test RE 0.005570885998790596\n",
      "237 Train Loss 0.015273126 Test MSE 4.497492678215837e-05 Test RE 0.004845304881516842\n",
      "238 Train Loss 0.014961533 Test MSE 4.3280712611846565e-05 Test RE 0.004753167054806141\n",
      "239 Train Loss 0.0147991 Test MSE 4.0074390488236286e-05 Test RE 0.00457371753413326\n",
      "240 Train Loss 0.014618943 Test MSE 3.983944699055882e-05 Test RE 0.004560290695014982\n",
      "241 Train Loss 0.01445631 Test MSE 3.971701076928389e-05 Test RE 0.004553277866709444\n",
      "242 Train Loss 0.014264969 Test MSE 4.068686388145815e-05 Test RE 0.004608536005510021\n",
      "243 Train Loss 0.014106042 Test MSE 4.003713069887112e-05 Test RE 0.004571590797082967\n",
      "244 Train Loss 0.013995238 Test MSE 3.9299252775021364e-05 Test RE 0.004529268045767505\n",
      "245 Train Loss 0.013939116 Test MSE 3.758060633087649e-05 Test RE 0.004429123276990853\n",
      "246 Train Loss 0.013780229 Test MSE 3.8596657924688594e-05 Test RE 0.004488598162262618\n",
      "247 Train Loss 0.013660549 Test MSE 3.693822353282464e-05 Test RE 0.004391105580198614\n",
      "248 Train Loss 0.013583773 Test MSE 3.950050282940804e-05 Test RE 0.004540850345624312\n",
      "249 Train Loss 0.013535341 Test MSE 3.690504905796414e-05 Test RE 0.004389133296073415\n",
      "250 Train Loss 0.013426629 Test MSE 3.992947988586553e-05 Test RE 0.004565440672021081\n",
      "251 Train Loss 0.013317554 Test MSE 3.944035145729845e-05 Test RE 0.0045373916245663275\n",
      "252 Train Loss 0.013182901 Test MSE 3.67296109521353e-05 Test RE 0.004378688403586953\n",
      "253 Train Loss 0.01304168 Test MSE 3.6449350928538774e-05 Test RE 0.004361950937602482\n",
      "254 Train Loss 0.013222488 Test MSE 3.4552631380278345e-05 Test RE 0.004246943080188654\n",
      "255 Train Loss 0.013034439 Test MSE 3.508885036685435e-05 Test RE 0.004279770162461736\n",
      "256 Train Loss 0.012831762 Test MSE 3.43839812518833e-05 Test RE 0.004236565815114202\n",
      "257 Train Loss 0.0125928745 Test MSE 3.479281122201433e-05 Test RE 0.004261678045656533\n",
      "258 Train Loss 0.012385982 Test MSE 3.345261030616678e-05 Test RE 0.004178793231534973\n",
      "259 Train Loss 0.012302969 Test MSE 3.2198311185083295e-05 Test RE 0.0040997032630453\n",
      "260 Train Loss 0.012228262 Test MSE 3.151565528622118e-05 Test RE 0.004056010285924408\n",
      "261 Train Loss 0.012103724 Test MSE 3.233673397759232e-05 Test RE 0.004108506267588808\n",
      "262 Train Loss 0.012050196 Test MSE 3.324102178106674e-05 Test RE 0.004165556786759912\n",
      "263 Train Loss 0.0119421175 Test MSE 3.350400260023619e-05 Test RE 0.00418200188028282\n",
      "264 Train Loss 0.011860404 Test MSE 3.3987786799579405e-05 Test RE 0.004212086870668672\n",
      "265 Train Loss 0.011810442 Test MSE 3.221156183748718e-05 Test RE 0.004100546756897172\n",
      "266 Train Loss 0.011760171 Test MSE 3.307765582407364e-05 Test RE 0.004155308179734624\n",
      "267 Train Loss 0.011620526 Test MSE 3.444937773853031e-05 Test RE 0.004240592761647832\n",
      "268 Train Loss 0.011597902 Test MSE 3.293350517743379e-05 Test RE 0.0041462439887577475\n",
      "269 Train Loss 0.011520568 Test MSE 3.46458704492934e-05 Test RE 0.0042526693335553645\n",
      "270 Train Loss 0.01136557 Test MSE 3.3693734223033105e-05 Test RE 0.0041938264054474685\n",
      "271 Train Loss 0.011262851 Test MSE 3.2559434920284274e-05 Test RE 0.004122629497991136\n",
      "272 Train Loss 0.011204463 Test MSE 3.1838096245926765e-05 Test RE 0.004076706281453614\n",
      "273 Train Loss 0.011121166 Test MSE 3.330547901326945e-05 Test RE 0.0041695935192576404\n",
      "274 Train Loss 0.011032107 Test MSE 3.19006863409092e-05 Test RE 0.00408071148562614\n",
      "275 Train Loss 0.011045468 Test MSE 3.008596437998681e-05 Test RE 0.003962943178635861\n",
      "276 Train Loss 0.011052394 Test MSE 3.008596437998681e-05 Test RE 0.003962943178635861\n",
      "277 Train Loss 0.011024365 Test MSE 2.9927949855291857e-05 Test RE 0.003952522589138398\n",
      "278 Train Loss 0.011004893 Test MSE 2.801911229726421e-05 Test RE 0.003824397827455183\n",
      "279 Train Loss 0.0108953295 Test MSE 2.7378973078315114e-05 Test RE 0.0037804583198307756\n",
      "280 Train Loss 0.010810986 Test MSE 2.5733168840226806e-05 Test RE 0.00366507200767197\n",
      "281 Train Loss 0.01064554 Test MSE 2.4460004169736198e-05 Test RE 0.0035732560710603645\n",
      "282 Train Loss 0.010697822 Test MSE 2.52585442580623e-05 Test RE 0.0036311152661390395\n",
      "283 Train Loss 0.010410427 Test MSE 2.8047580973492982e-05 Test RE 0.003826340214151726\n",
      "284 Train Loss 0.01028511 Test MSE 2.9178402903267455e-05 Test RE 0.0039027131821126717\n",
      "285 Train Loss 0.010290982 Test MSE 2.932661753909137e-05 Test RE 0.003912612738894503\n",
      "286 Train Loss 0.010327501 Test MSE 2.8409871483032113e-05 Test RE 0.0038509733347656004\n",
      "287 Train Loss 0.010243215 Test MSE 2.6606051724304055e-05 Test RE 0.0037267142363195385\n",
      "288 Train Loss 0.010099277 Test MSE 2.6194206264899624e-05 Test RE 0.003697758111371798\n",
      "289 Train Loss 0.009986855 Test MSE 2.5159946515429298e-05 Test RE 0.003624021234223572\n",
      "290 Train Loss 0.009891218 Test MSE 2.339478622833816e-05 Test RE 0.0034945834633799866\n",
      "291 Train Loss 0.009764656 Test MSE 2.336836358166607e-05 Test RE 0.0034926094716189876\n",
      "292 Train Loss 0.009644398 Test MSE 2.21182199101502e-05 Test RE 0.003397902889322467\n",
      "293 Train Loss 0.009484614 Test MSE 2.322480411211932e-05 Test RE 0.0034818648253937584\n",
      "294 Train Loss 0.009412182 Test MSE 2.110804050675065e-05 Test RE 0.003319401885581847\n",
      "295 Train Loss 0.009274314 Test MSE 2.2855705197958714e-05 Test RE 0.0034540863443500145\n",
      "296 Train Loss 0.009272906 Test MSE 2.1340570780316473e-05 Test RE 0.0033376353950645755\n",
      "297 Train Loss 0.0091475425 Test MSE 2.3836787060463326e-05 Test RE 0.0035274408118911053\n",
      "298 Train Loss 0.009075704 Test MSE 2.3987464860147523e-05 Test RE 0.0035385721300203346\n",
      "299 Train Loss 0.009009551 Test MSE 2.5112006476298443e-05 Test RE 0.0036205669630052103\n",
      "Training time: 234.43\n",
      "KG_tanhALR_high\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 52068.883 Test MSE 14.924731359148778 Test RE 2.7911883145124774\n",
      "1 Train Loss 32092.805 Test MSE 8.407550289832367 Test RE 2.0949352951977165\n",
      "2 Train Loss 17315.621 Test MSE 14.361412363352148 Test RE 2.738006363100835\n",
      "3 Train Loss 10296.559 Test MSE 12.261306826476417 Test RE 2.529905254523863\n",
      "4 Train Loss 5827.418 Test MSE 11.327507993948824 Test RE 2.4316612022299204\n",
      "5 Train Loss 2923.027 Test MSE 10.164060721966072 Test RE 2.3034007418049938\n",
      "6 Train Loss 1567.5831 Test MSE 8.135900064165561 Test RE 2.0608134473728077\n",
      "7 Train Loss 1074.1813 Test MSE 6.783037673216711 Test RE 1.8816896298078107\n",
      "8 Train Loss 838.6735 Test MSE 5.517167653180912 Test RE 1.6970473798275132\n",
      "9 Train Loss 625.1543 Test MSE 4.3942922061571 Test RE 1.514538589115689\n",
      "10 Train Loss 483.43057 Test MSE 3.1517177636388958 Test RE 1.2826540495628922\n",
      "11 Train Loss 311.30792 Test MSE 1.6166507040785028 Test RE 0.9186370871976721\n",
      "12 Train Loss 161.8581 Test MSE 1.045292695824957 Test RE 0.7386774388706155\n",
      "13 Train Loss 95.799774 Test MSE 0.9107972856935969 Test RE 0.6895197984174912\n",
      "14 Train Loss 63.781612 Test MSE 0.7421793715115992 Test RE 0.6224297130675075\n",
      "15 Train Loss 49.51965 Test MSE 0.7388589204119718 Test RE 0.6210358019014544\n",
      "16 Train Loss 39.05513 Test MSE 0.6874717961178147 Test RE 0.5990503410459559\n",
      "17 Train Loss 26.710241 Test MSE 0.542409868627101 Test RE 0.5321078526703122\n",
      "18 Train Loss 19.84343 Test MSE 0.3409847692222375 Test RE 0.4218940176927074\n",
      "19 Train Loss 13.787476 Test MSE 0.20778442083504586 Test RE 0.32933839748132987\n",
      "20 Train Loss 11.019108 Test MSE 0.16905080992190943 Test RE 0.29706022441154994\n",
      "21 Train Loss 8.20798 Test MSE 0.11823165614949217 Test RE 0.24842927013047336\n",
      "22 Train Loss 5.9960704 Test MSE 0.06780596564255612 Test RE 0.18813510040337075\n",
      "23 Train Loss 4.445246 Test MSE 0.04241311217445543 Test RE 0.1487941810631051\n",
      "24 Train Loss 3.4256117 Test MSE 0.024957586376153147 Test RE 0.11413981605546897\n",
      "25 Train Loss 2.686877 Test MSE 0.01844104438154239 Test RE 0.09811346946840459\n",
      "26 Train Loss 2.1541572 Test MSE 0.0196262374284482 Test RE 0.10121721910530887\n",
      "27 Train Loss 1.8724107 Test MSE 0.016898387514282964 Test RE 0.0939200920315414\n",
      "28 Train Loss 1.5471116 Test MSE 0.014861865514613505 Test RE 0.0880790334966961\n",
      "29 Train Loss 1.2867516 Test MSE 0.013579872601777843 Test RE 0.08419450049667654\n",
      "30 Train Loss 1.1205459 Test MSE 0.00830941231650395 Test RE 0.06585989463587608\n",
      "31 Train Loss 0.9873901 Test MSE 0.0050982999994722685 Test RE 0.05158798565969389\n",
      "32 Train Loss 0.87699026 Test MSE 0.004551176630125544 Test RE 0.04874136890865428\n",
      "33 Train Loss 0.78188 Test MSE 0.003350099581970668 Test RE 0.04181814221451294\n",
      "34 Train Loss 0.7272352 Test MSE 0.002529091005440529 Test RE 0.036334409408076584\n",
      "35 Train Loss 0.67134124 Test MSE 0.0023165183379921426 Test RE 0.03477392780586368\n",
      "36 Train Loss 0.62240785 Test MSE 0.0020172285239655557 Test RE 0.03244990481000157\n",
      "37 Train Loss 0.5795111 Test MSE 0.0017128938081935237 Test RE 0.029902059176808583\n",
      "38 Train Loss 0.52890974 Test MSE 0.001600661362124852 Test RE 0.028905840887908874\n",
      "39 Train Loss 0.5009602 Test MSE 0.0014607800961256882 Test RE 0.027613935001921577\n",
      "40 Train Loss 0.4701333 Test MSE 0.0014408398856468189 Test RE 0.027424816981022785\n",
      "41 Train Loss 0.4429322 Test MSE 0.0013584537034333024 Test RE 0.02662921094341908\n",
      "42 Train Loss 0.40772894 Test MSE 0.0013294931474291088 Test RE 0.026343830809054673\n",
      "43 Train Loss 0.3782961 Test MSE 0.0011871650262863453 Test RE 0.02489381305637653\n",
      "44 Train Loss 0.35542005 Test MSE 0.0009899352668213143 Test RE 0.022732085199847017\n",
      "45 Train Loss 0.33768198 Test MSE 0.0008453889280966636 Test RE 0.021007005769748597\n",
      "46 Train Loss 0.31689712 Test MSE 0.000778415238180157 Test RE 0.02015772617600239\n",
      "47 Train Loss 0.30278125 Test MSE 0.0007616900994442812 Test RE 0.01993999440878223\n",
      "48 Train Loss 0.28370297 Test MSE 0.0007855464292882017 Test RE 0.02024984980354191\n",
      "49 Train Loss 0.2738335 Test MSE 0.0007250795918068381 Test RE 0.019454887226501395\n",
      "50 Train Loss 0.2646099 Test MSE 0.0007428698174343397 Test RE 0.019692109118095377\n",
      "51 Train Loss 0.2523434 Test MSE 0.000766373765668096 Test RE 0.02000120640942552\n",
      "52 Train Loss 0.23839693 Test MSE 0.0007460348918408312 Test RE 0.01973401467308374\n",
      "53 Train Loss 0.22483431 Test MSE 0.0008219593027612459 Test RE 0.02071385989528388\n",
      "54 Train Loss 0.2150428 Test MSE 0.0007896866457384521 Test RE 0.02030314301474948\n",
      "55 Train Loss 0.20533079 Test MSE 0.0008535046704740174 Test RE 0.02110759865859456\n",
      "56 Train Loss 0.19315092 Test MSE 0.0009662634351689006 Test RE 0.022458650133583318\n",
      "57 Train Loss 0.1833757 Test MSE 0.001120087272528074 Test RE 0.02418030686696127\n",
      "58 Train Loss 0.17259496 Test MSE 0.0011743447836104585 Test RE 0.024759033554144785\n",
      "59 Train Loss 0.16175415 Test MSE 0.0012580862648237786 Test RE 0.02562660573747886\n",
      "60 Train Loss 0.15711558 Test MSE 0.001353246574768293 Test RE 0.026578125337910197\n",
      "61 Train Loss 0.14859827 Test MSE 0.001322085319156473 Test RE 0.026270335441348585\n",
      "62 Train Loss 0.14199439 Test MSE 0.0011628502543439693 Test RE 0.024637564428682358\n",
      "63 Train Loss 0.1375944 Test MSE 0.0011743381892463597 Test RE 0.024758964038652628\n",
      "64 Train Loss 0.1328383 Test MSE 0.0011463441498492995 Test RE 0.024462080238938207\n",
      "65 Train Loss 0.12670086 Test MSE 0.001023472866783807 Test RE 0.02311394330557641\n",
      "66 Train Loss 0.12225476 Test MSE 0.0010418429384307147 Test RE 0.023320454115440148\n",
      "67 Train Loss 0.11489629 Test MSE 0.0009719843073758503 Test RE 0.02252503650863622\n",
      "68 Train Loss 0.11022553 Test MSE 0.0009782984787949716 Test RE 0.0225980812612221\n",
      "69 Train Loss 0.106164664 Test MSE 0.001011140367579027 Test RE 0.022974263688049477\n",
      "70 Train Loss 0.10312948 Test MSE 0.0010763668726950428 Test RE 0.023703694347907936\n",
      "71 Train Loss 0.096920766 Test MSE 0.000995507518329675 Test RE 0.022795973793582478\n",
      "72 Train Loss 0.09331991 Test MSE 0.000999668980487821 Test RE 0.022843570445543866\n",
      "73 Train Loss 0.08999663 Test MSE 0.0009578457095847009 Test RE 0.022360610466010976\n",
      "74 Train Loss 0.08630661 Test MSE 0.000822055474335413 Test RE 0.020715071650075162\n",
      "75 Train Loss 0.08310336 Test MSE 0.0007997823289027079 Test RE 0.02043251276928014\n",
      "76 Train Loss 0.07989975 Test MSE 0.0008770646353703595 Test RE 0.021396940394081035\n",
      "77 Train Loss 0.0781405 Test MSE 0.000852361487164935 Test RE 0.0210934581737163\n",
      "78 Train Loss 0.07500228 Test MSE 0.0007776312948081738 Test RE 0.020147573178126175\n",
      "79 Train Loss 0.07277228 Test MSE 0.0007365503810153226 Test RE 0.019608171924167528\n",
      "80 Train Loss 0.07024513 Test MSE 0.0007473446802602428 Test RE 0.01975133024992321\n",
      "81 Train Loss 0.06829496 Test MSE 0.0007148107855018784 Test RE 0.019316632850130574\n",
      "82 Train Loss 0.06626378 Test MSE 0.0006724301290729623 Test RE 0.018735248551766497\n",
      "83 Train Loss 0.06425178 Test MSE 0.0006368315519181265 Test RE 0.01823258148215249\n",
      "84 Train Loss 0.061950155 Test MSE 0.0006544849668337975 Test RE 0.018483563959073565\n",
      "85 Train Loss 0.060547464 Test MSE 0.0006337632839061 Test RE 0.018188605966051062\n",
      "86 Train Loss 0.058976844 Test MSE 0.0006445779510648093 Test RE 0.01834313657757874\n",
      "87 Train Loss 0.05699972 Test MSE 0.0006430154243937277 Test RE 0.018320890213969553\n",
      "88 Train Loss 0.05545596 Test MSE 0.0006487951903983272 Test RE 0.018403044986521427\n",
      "89 Train Loss 0.054117788 Test MSE 0.0006421200633505119 Test RE 0.018308130391214057\n",
      "90 Train Loss 0.05301832 Test MSE 0.0006032582088365566 Test RE 0.017745469617373867\n",
      "91 Train Loss 0.05244455 Test MSE 0.0005693665636421456 Test RE 0.017239785445228587\n",
      "92 Train Loss 0.051422767 Test MSE 0.0005571364653910865 Test RE 0.017053623442656818\n",
      "93 Train Loss 0.0508236 Test MSE 0.0005577365180553453 Test RE 0.017062804602901206\n",
      "94 Train Loss 0.04954609 Test MSE 0.0005841714973897824 Test RE 0.01746248550096106\n",
      "95 Train Loss 0.04888081 Test MSE 0.0006159802756720587 Test RE 0.01793160979821435\n",
      "96 Train Loss 0.047898475 Test MSE 0.0006068270539146825 Test RE 0.017797882863904452\n",
      "97 Train Loss 0.046703406 Test MSE 0.0005893317595296542 Test RE 0.017539443105929604\n",
      "98 Train Loss 0.045813587 Test MSE 0.0006023347224213909 Test RE 0.017731881756995464\n",
      "99 Train Loss 0.04504485 Test MSE 0.0006001576680224395 Test RE 0.01769980804909669\n",
      "100 Train Loss 0.043997396 Test MSE 0.0006141103156155907 Test RE 0.017904371197969317\n",
      "101 Train Loss 0.043787505 Test MSE 0.0006381565134961797 Test RE 0.018251538549914053\n",
      "102 Train Loss 0.04348719 Test MSE 0.000620447163784104 Test RE 0.017996509446705233\n",
      "103 Train Loss 0.04301104 Test MSE 0.000648793604820975 Test RE 0.01840302249909427\n",
      "104 Train Loss 0.041884214 Test MSE 0.0006399739177339493 Test RE 0.01827750932658414\n",
      "105 Train Loss 0.04107453 Test MSE 0.0006232251139397788 Test RE 0.018036752657364277\n",
      "106 Train Loss 0.040061582 Test MSE 0.0006247166056318509 Test RE 0.01805832238411096\n",
      "107 Train Loss 0.03926961 Test MSE 0.0006223474314988172 Test RE 0.018024047682728264\n",
      "108 Train Loss 0.038112942 Test MSE 0.0006075569244304169 Test RE 0.017808582985284153\n",
      "109 Train Loss 0.03691925 Test MSE 0.0006348312430772379 Test RE 0.018203924392315923\n",
      "110 Train Loss 0.036386598 Test MSE 0.000653956796298427 Test RE 0.0184761043192459\n",
      "111 Train Loss 0.03552761 Test MSE 0.0006503065440645159 Test RE 0.0184244672558483\n",
      "112 Train Loss 0.03484425 Test MSE 0.000625814257040123 Test RE 0.018074180009444194\n",
      "113 Train Loss 0.034709964 Test MSE 0.0005981460868045854 Test RE 0.017670120445400762\n",
      "114 Train Loss 0.033628847 Test MSE 0.0005502541222610785 Test RE 0.016947963861870502\n",
      "115 Train Loss 0.03292771 Test MSE 0.0005453113476607341 Test RE 0.016871672806541824\n",
      "116 Train Loss 0.032311242 Test MSE 0.0005404699690322532 Test RE 0.016796610859589712\n",
      "117 Train Loss 0.031656273 Test MSE 0.0005297148536179641 Test RE 0.01662864847043093\n",
      "118 Train Loss 0.030906651 Test MSE 0.0004948908903089298 Test RE 0.016072765435732453\n",
      "119 Train Loss 0.030760393 Test MSE 0.00048046474072128054 Test RE 0.015836771040186416\n",
      "120 Train Loss 0.030679079 Test MSE 0.0004635576426262471 Test RE 0.01555563519615406\n",
      "121 Train Loss 0.03000243 Test MSE 0.00043915371497610416 Test RE 0.015140637352304209\n",
      "122 Train Loss 0.029392343 Test MSE 0.00041955450589108286 Test RE 0.01479892167782775\n",
      "123 Train Loss 0.02888571 Test MSE 0.00041327399659066814 Test RE 0.014687737999081046\n",
      "124 Train Loss 0.028403439 Test MSE 0.00041087700150173215 Test RE 0.014645081511880424\n",
      "125 Train Loss 0.02795573 Test MSE 0.00040939687133780336 Test RE 0.014618679226210813\n",
      "126 Train Loss 0.027724545 Test MSE 0.000419284306774973 Test RE 0.014794155551489168\n",
      "127 Train Loss 0.027236719 Test MSE 0.00041663644335968974 Test RE 0.014747367554859602\n",
      "128 Train Loss 0.026793709 Test MSE 0.0004026971671078444 Test RE 0.014498569813556924\n",
      "129 Train Loss 0.026430987 Test MSE 0.0004002714612219296 Test RE 0.014454836717146624\n",
      "130 Train Loss 0.026310012 Test MSE 0.0004038139192845999 Test RE 0.014518659475094706\n",
      "131 Train Loss 0.025916228 Test MSE 0.0003964820283204981 Test RE 0.014386250896180425\n",
      "132 Train Loss 0.025777735 Test MSE 0.0004119323048510783 Test RE 0.014663876787006435\n",
      "133 Train Loss 0.025612809 Test MSE 0.00040655405358082397 Test RE 0.014567835363425102\n",
      "134 Train Loss 0.025159534 Test MSE 0.00039646997326368047 Test RE 0.014386032187162305\n",
      "135 Train Loss 0.024625868 Test MSE 0.0003925593677209095 Test RE 0.014314907618200106\n",
      "136 Train Loss 0.024324462 Test MSE 0.00040851276577416525 Test RE 0.01460288594372629\n",
      "137 Train Loss 0.023903942 Test MSE 0.00040572162677360226 Test RE 0.014552913767731622\n",
      "138 Train Loss 0.023455715 Test MSE 0.0003975023045121158 Test RE 0.014404749236059023\n",
      "139 Train Loss 0.023197677 Test MSE 0.0003940534599022258 Test RE 0.014342123220863921\n",
      "140 Train Loss 0.023032386 Test MSE 0.00039664717930916254 Test RE 0.014389246815320812\n",
      "141 Train Loss 0.022590281 Test MSE 0.000406632566476746 Test RE 0.014569241950958371\n",
      "142 Train Loss 0.022108268 Test MSE 0.00041168954406691996 Test RE 0.01465955527736817\n",
      "143 Train Loss 0.02168172 Test MSE 0.0004082837012227151 Test RE 0.014598791246033006\n",
      "144 Train Loss 0.021472378 Test MSE 0.000410421361083767 Test RE 0.014636958956915934\n",
      "145 Train Loss 0.021206863 Test MSE 0.00040166062528975907 Test RE 0.014479898143675724\n",
      "146 Train Loss 0.021027857 Test MSE 0.0003886656021243362 Test RE 0.014243736469844176\n",
      "147 Train Loss 0.020837793 Test MSE 0.00037902983242662006 Test RE 0.014066063498857945\n",
      "148 Train Loss 0.020488815 Test MSE 0.0003709568869360948 Test RE 0.013915460921978701\n",
      "149 Train Loss 0.02049499 Test MSE 0.0003722290102534428 Test RE 0.013939300662345337\n",
      "150 Train Loss 0.020329991 Test MSE 0.00036594329926087425 Test RE 0.013821105323645645\n",
      "151 Train Loss 0.019978385 Test MSE 0.0003655401384641315 Test RE 0.013813489849610817\n",
      "152 Train Loss 0.020121606 Test MSE 0.00037868321863242113 Test RE 0.01405963048704476\n",
      "153 Train Loss 0.02003312 Test MSE 0.00037143751141576305 Test RE 0.013924472678420036\n",
      "154 Train Loss 0.019840585 Test MSE 0.0003735842034368901 Test RE 0.013964652370696374\n",
      "155 Train Loss 0.019650457 Test MSE 0.00036732324082624276 Test RE 0.01384713991909556\n",
      "156 Train Loss 0.019422961 Test MSE 0.00036868059161838365 Test RE 0.013872700641660442\n",
      "157 Train Loss 0.019116394 Test MSE 0.00036848534686527293 Test RE 0.013869026823770825\n",
      "158 Train Loss 0.018837335 Test MSE 0.00035931255001917444 Test RE 0.01369531639994416\n",
      "159 Train Loss 0.018744944 Test MSE 0.0003585368844432144 Test RE 0.013680526038782484\n",
      "160 Train Loss 0.018862624 Test MSE 0.00035760367167640553 Test RE 0.013662710354485108\n",
      "161 Train Loss 0.018602507 Test MSE 0.00035534175599570274 Test RE 0.013619432104339043\n",
      "162 Train Loss 0.018319903 Test MSE 0.0003523049731561995 Test RE 0.013561110781828714\n",
      "163 Train Loss 0.018033355 Test MSE 0.0003401860952614968 Test RE 0.013325826546847842\n",
      "164 Train Loss 0.017813727 Test MSE 0.00033247752982064257 Test RE 0.01317398081096289\n",
      "165 Train Loss 0.017733203 Test MSE 0.0003342856083439956 Test RE 0.01320975359781719\n",
      "166 Train Loss 0.017451748 Test MSE 0.00033027133173127904 Test RE 0.013130199225000692\n",
      "167 Train Loss 0.017320124 Test MSE 0.00032922580930081966 Test RE 0.013109399963678266\n",
      "168 Train Loss 0.016920887 Test MSE 0.0003221946291733529 Test RE 0.012968657633332359\n",
      "169 Train Loss 0.01667655 Test MSE 0.0003203990272575755 Test RE 0.012932469752954211\n",
      "170 Train Loss 0.016358828 Test MSE 0.0003184687091392073 Test RE 0.012893453569594105\n",
      "171 Train Loss 0.016992798 Test MSE 0.0003193827752849601 Test RE 0.012911943651269315\n",
      "172 Train Loss 0.01677072 Test MSE 0.0003131922564442148 Test RE 0.012786196804052434\n",
      "173 Train Loss 0.016438957 Test MSE 0.0003183734618721161 Test RE 0.0128915253455386\n",
      "174 Train Loss 0.016156936 Test MSE 0.0003168513902232028 Test RE 0.012860672690247347\n",
      "175 Train Loss 0.01589419 Test MSE 0.00031664096288609543 Test RE 0.012856401466170496\n",
      "176 Train Loss 0.015650587 Test MSE 0.00031047859189005595 Test RE 0.012730683082027103\n",
      "177 Train Loss 0.015432255 Test MSE 0.0003111324295852071 Test RE 0.012744080821889391\n",
      "178 Train Loss 0.015167859 Test MSE 0.000314704346485378 Test RE 0.012817025473435682\n",
      "179 Train Loss 0.01485727 Test MSE 0.0003136993374931303 Test RE 0.012796543509160275\n",
      "180 Train Loss 0.014748835 Test MSE 0.0003116853969916292 Test RE 0.01275540065275581\n",
      "181 Train Loss 0.014642317 Test MSE 0.0003155498719875951 Test RE 0.012834231865211316\n",
      "182 Train Loss 0.014844734 Test MSE 0.0003056168426399685 Test RE 0.012630615634932122\n",
      "183 Train Loss 0.014644084 Test MSE 0.000301187103538121 Test RE 0.012538744787522819\n",
      "184 Train Loss 0.014500335 Test MSE 0.0002997478309910485 Test RE 0.012508749674259217\n",
      "185 Train Loss 0.014316266 Test MSE 0.00029449088436059025 Test RE 0.012398575900843362\n",
      "186 Train Loss 0.014017175 Test MSE 0.0002850811088222675 Test RE 0.012198883858430161\n",
      "187 Train Loss 0.01386909 Test MSE 0.00027744110499502604 Test RE 0.012034312357080976\n",
      "188 Train Loss 0.01364932 Test MSE 0.00027644728230888366 Test RE 0.012012738945449901\n",
      "189 Train Loss 0.013417077 Test MSE 0.0002775935107751297 Test RE 0.012037617287242949\n",
      "190 Train Loss 0.0132965185 Test MSE 0.00027485215649519096 Test RE 0.011978031511842646\n",
      "191 Train Loss 0.013350599 Test MSE 0.0002735108160880489 Test RE 0.011948768019742378\n",
      "192 Train Loss 0.013179904 Test MSE 0.0002727902213788802 Test RE 0.011933017458635595\n",
      "193 Train Loss 0.013036557 Test MSE 0.0002715759624231764 Test RE 0.01190642938364511\n",
      "194 Train Loss 0.012810524 Test MSE 0.00027356744130367975 Test RE 0.011950004838380062\n",
      "195 Train Loss 0.01313509 Test MSE 0.0002771738727529431 Test RE 0.012028515214924575\n",
      "196 Train Loss 0.012882312 Test MSE 0.0002773742998384501 Test RE 0.01203286339636686\n",
      "197 Train Loss 0.012671046 Test MSE 0.00027659856011893195 Test RE 0.012016025308553684\n",
      "198 Train Loss 0.012431263 Test MSE 0.0002731292742078742 Test RE 0.011940430970218923\n",
      "199 Train Loss 0.012300925 Test MSE 0.0002718025656353248 Test RE 0.011911395715244315\n",
      "200 Train Loss 0.012075828 Test MSE 0.0002708262446290125 Test RE 0.011889983467274486\n",
      "201 Train Loss 0.0121921385 Test MSE 0.0002725288691559431 Test RE 0.011927299753708553\n",
      "202 Train Loss 0.012218581 Test MSE 0.0002716695844470636 Test RE 0.011908481494504098\n",
      "203 Train Loss 0.012002311 Test MSE 0.0002641281798956148 Test RE 0.011742031638156441\n",
      "204 Train Loss 0.011912399 Test MSE 0.0002583203324173769 Test RE 0.011612217784575192\n",
      "205 Train Loss 0.0118349 Test MSE 0.00025935980096200166 Test RE 0.01163555783017808\n",
      "206 Train Loss 0.011659679 Test MSE 0.00025373583517857576 Test RE 0.011508713543463169\n",
      "207 Train Loss 0.011603437 Test MSE 0.00025394955990064663 Test RE 0.011513559486610724\n",
      "208 Train Loss 0.011341887 Test MSE 0.0002527344739227983 Test RE 0.011485981688325413\n",
      "209 Train Loss 0.011136799 Test MSE 0.0002607850772788935 Test RE 0.011667484836054978\n",
      "210 Train Loss 0.011017075 Test MSE 0.0002647072616944427 Test RE 0.011754896365389067\n",
      "211 Train Loss 0.010898713 Test MSE 0.0002656266547124802 Test RE 0.011775292484632934\n",
      "212 Train Loss 0.010777688 Test MSE 0.0002597351922140306 Test RE 0.011643975301302154\n",
      "213 Train Loss 0.010628359 Test MSE 0.0002603937120425101 Test RE 0.01165872673827673\n",
      "214 Train Loss 0.0105629945 Test MSE 0.00025499985347406736 Test RE 0.011537344013075258\n",
      "215 Train Loss 0.010525798 Test MSE 0.0002532437013354639 Test RE 0.01149754725232831\n",
      "216 Train Loss 0.010675089 Test MSE 0.00024553430216955587 Test RE 0.011321186990096686\n",
      "217 Train Loss 0.010474104 Test MSE 0.0002419731945501115 Test RE 0.0112387886951252\n",
      "218 Train Loss 0.010234894 Test MSE 0.00024437671001745556 Test RE 0.011294468115897852\n",
      "219 Train Loss 0.010176478 Test MSE 0.00024311415158532958 Test RE 0.01126525421911791\n",
      "220 Train Loss 0.00996979 Test MSE 0.00023970539614401684 Test RE 0.011185999157711474\n",
      "221 Train Loss 0.009873107 Test MSE 0.0002346138208275491 Test RE 0.011066560765953222\n",
      "222 Train Loss 0.009762336 Test MSE 0.00023690139706384413 Test RE 0.011120381532168114\n",
      "223 Train Loss 0.009602788 Test MSE 0.00023507858988715816 Test RE 0.011077516749451443\n",
      "224 Train Loss 0.00943238 Test MSE 0.00023460863677340107 Test RE 0.011066438501273852\n",
      "225 Train Loss 0.009366114 Test MSE 0.00023517710566267998 Test RE 0.011079837666559319\n",
      "226 Train Loss 0.009293255 Test MSE 0.0002381458294833221 Test RE 0.011149550709100899\n",
      "227 Train Loss 0.009208556 Test MSE 0.00023834375272829166 Test RE 0.01115418294839389\n",
      "228 Train Loss 0.009178358 Test MSE 0.0002360879081930516 Test RE 0.011101272134645027\n",
      "229 Train Loss 0.00906117 Test MSE 0.0002369069192014591 Test RE 0.011120511138662761\n",
      "230 Train Loss 0.009081931 Test MSE 0.00023583391015906253 Test RE 0.01109529880858769\n",
      "231 Train Loss 0.008940507 Test MSE 0.00023417106429435796 Test RE 0.01105611358527835\n",
      "232 Train Loss 0.009088419 Test MSE 0.00023339718223342536 Test RE 0.011037829497293757\n",
      "233 Train Loss 0.009222486 Test MSE 0.0002367783230755133 Test RE 0.011117492550663098\n",
      "234 Train Loss 0.009155133 Test MSE 0.0002335391967933143 Test RE 0.011041187065940533\n",
      "235 Train Loss 0.009006691 Test MSE 0.0002314297191818389 Test RE 0.010991208365805307\n",
      "236 Train Loss 0.008973978 Test MSE 0.00023183697619002253 Test RE 0.011000874970250494\n",
      "237 Train Loss 0.008935484 Test MSE 0.00022998771932555872 Test RE 0.010956912669529285\n",
      "238 Train Loss 0.008923568 Test MSE 0.00022560973709515953 Test RE 0.010852125226960689\n",
      "239 Train Loss 0.008685108 Test MSE 0.00022222528012590207 Test RE 0.010770419226545798\n",
      "240 Train Loss 0.008621174 Test MSE 0.00022223285298221966 Test RE 0.010770602738841036\n",
      "241 Train Loss 0.00848675 Test MSE 0.0002311674282662732 Test RE 0.010984978156022859\n",
      "242 Train Loss 0.008506546 Test MSE 0.00023813059900675929 Test RE 0.01114919417191885\n",
      "243 Train Loss 0.008387072 Test MSE 0.000233378571487883 Test RE 0.011037389418434776\n",
      "244 Train Loss 0.00844255 Test MSE 0.00022826900467699687 Test RE 0.010915894998453163\n",
      "245 Train Loss 0.008313224 Test MSE 0.00022279087010020497 Test RE 0.010784116520718428\n",
      "246 Train Loss 0.008172266 Test MSE 0.00021739493387948631 Test RE 0.010652721826512479\n",
      "247 Train Loss 0.008068276 Test MSE 0.00021539193913883666 Test RE 0.01060353318696966\n",
      "248 Train Loss 0.007958793 Test MSE 0.00021144015617798176 Test RE 0.010505811696416189\n",
      "249 Train Loss 0.007871365 Test MSE 0.0002098559608007814 Test RE 0.010466380799111191\n",
      "250 Train Loss 0.0078596035 Test MSE 0.00020740220773896823 Test RE 0.010405011496620513\n",
      "251 Train Loss 0.0077712787 Test MSE 0.00020746408014462865 Test RE 0.010406563396894176\n",
      "252 Train Loss 0.007647387 Test MSE 0.00020404718202883158 Test RE 0.01032051044184459\n",
      "253 Train Loss 0.0075547984 Test MSE 0.00020533971640945758 Test RE 0.010353146414017573\n",
      "254 Train Loss 0.007540885 Test MSE 0.00020889330945269606 Test RE 0.010442347512943087\n",
      "255 Train Loss 0.0075042243 Test MSE 0.00020697296164162796 Test RE 0.010394238651131302\n",
      "256 Train Loss 0.007414905 Test MSE 0.0002097533164648753 Test RE 0.010463820838219019\n",
      "257 Train Loss 0.007558248 Test MSE 0.00020952645598159946 Test RE 0.010458160690150936\n",
      "258 Train Loss 0.007433053 Test MSE 0.000205214085155296 Test RE 0.010349978790632408\n",
      "259 Train Loss 0.007261448 Test MSE 0.000199084975441803 Test RE 0.010194246243920865\n",
      "260 Train Loss 0.007188551 Test MSE 0.00019911601392295846 Test RE 0.010195040883464889\n",
      "261 Train Loss 0.0071009053 Test MSE 0.0001941401160988656 Test RE 0.010066848189511016\n",
      "262 Train Loss 0.0070404694 Test MSE 0.00019377236540267935 Test RE 0.01005730908615131\n",
      "263 Train Loss 0.0072311247 Test MSE 0.00018921586669285313 Test RE 0.009938358359290899\n",
      "264 Train Loss 0.0072281887 Test MSE 0.00018326026286039274 Test RE 0.009780702056784383\n",
      "265 Train Loss 0.0072008865 Test MSE 0.0001801463253033763 Test RE 0.009697249746055897\n",
      "266 Train Loss 0.007139239 Test MSE 0.00017848081338474683 Test RE 0.009652318525201778\n",
      "267 Train Loss 0.0070247226 Test MSE 0.00017418106716400456 Test RE 0.009535343670815346\n",
      "268 Train Loss 0.006864064 Test MSE 0.0001683376467056217 Test RE 0.00937403353185705\n",
      "269 Train Loss 0.006703747 Test MSE 0.00016963673834046903 Test RE 0.009410134560292091\n",
      "270 Train Loss 0.006561584 Test MSE 0.00016568240293891499 Test RE 0.009299809859255711\n",
      "271 Train Loss 0.0064829895 Test MSE 0.0001618214637950455 Test RE 0.009190813205627537\n",
      "272 Train Loss 0.00639807 Test MSE 0.00016270033991043072 Test RE 0.00921573773684215\n",
      "273 Train Loss 0.0062963795 Test MSE 0.00015924726584118113 Test RE 0.00911741806537429\n",
      "274 Train Loss 0.0062220087 Test MSE 0.00015677913911456339 Test RE 0.009046488065375313\n",
      "275 Train Loss 0.0062903105 Test MSE 0.00015626617101052094 Test RE 0.009031676267198686\n",
      "276 Train Loss 0.006399378 Test MSE 0.0001560550206367451 Test RE 0.009025572302238181\n",
      "277 Train Loss 0.006339538 Test MSE 0.00015413938600496307 Test RE 0.008970005085015572\n",
      "278 Train Loss 0.0061927135 Test MSE 0.00015257867151914238 Test RE 0.008924477347007742\n",
      "279 Train Loss 0.0061025023 Test MSE 0.00015018217909976942 Test RE 0.008854113353210161\n",
      "280 Train Loss 0.0059957323 Test MSE 0.00014812063730327784 Test RE 0.008793133420711747\n",
      "281 Train Loss 0.005905237 Test MSE 0.0001467512011387231 Test RE 0.008752390965773437\n",
      "282 Train Loss 0.005866404 Test MSE 0.0001439233174587803 Test RE 0.008667651820731415\n",
      "283 Train Loss 0.005763557 Test MSE 0.0001430030323347819 Test RE 0.008639895709275659\n",
      "284 Train Loss 0.0056763724 Test MSE 0.00014041126379405304 Test RE 0.008561243530730645\n",
      "285 Train Loss 0.005786736 Test MSE 0.0001395783031726398 Test RE 0.008535811859210603\n",
      "286 Train Loss 0.005781286 Test MSE 0.00013535521451304603 Test RE 0.008405690064867397\n",
      "287 Train Loss 0.00569486 Test MSE 0.00013362691940818532 Test RE 0.008351853256827657\n",
      "288 Train Loss 0.005684701 Test MSE 0.0001326238964618061 Test RE 0.00832044910672763\n",
      "289 Train Loss 0.005616461 Test MSE 0.00013115606009744232 Test RE 0.008274277040849294\n",
      "290 Train Loss 0.00552308 Test MSE 0.0001313099822588687 Test RE 0.00827913088122143\n",
      "291 Train Loss 0.005548383 Test MSE 0.00013243224313677456 Test RE 0.008314435038765396\n",
      "292 Train Loss 0.0054958183 Test MSE 0.00013353570081888163 Test RE 0.008349002130963299\n",
      "293 Train Loss 0.005418661 Test MSE 0.0001313924943420528 Test RE 0.008281731677606064\n",
      "294 Train Loss 0.0053584 Test MSE 0.0001306845930387456 Test RE 0.008259391868369622\n",
      "295 Train Loss 0.005328616 Test MSE 0.00013067474052001058 Test RE 0.008259080518175036\n",
      "296 Train Loss 0.005245727 Test MSE 0.0001310420774524072 Test RE 0.008270680832716117\n",
      "297 Train Loss 0.005249047 Test MSE 0.0001330044866694851 Test RE 0.008332379131930216\n",
      "298 Train Loss 0.0051761484 Test MSE 0.00013056155960235034 Test RE 0.008255503037158031\n",
      "299 Train Loss 0.005151937 Test MSE 0.0001248433603266488 Test RE 0.008072696066244698\n",
      "Training time: 164.10\n",
      "KG_tanhALR_high\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 53127.82 Test MSE 5.537102751742739 Test RE 1.7001105731095254\n",
      "1 Train Loss 27753.01 Test MSE 5.089547905191116 Test RE 1.6299544956998853\n",
      "2 Train Loss 13869.407 Test MSE 6.336948209777686 Test RE 1.8187623518116742\n",
      "3 Train Loss 5934.1196 Test MSE 10.09422823179434 Test RE 2.295474311007016\n",
      "4 Train Loss 3273.9285 Test MSE 13.00040350534234 Test RE 2.605039380581652\n",
      "5 Train Loss 2114.8677 Test MSE 13.71691411269322 Test RE 2.6758643068378194\n",
      "6 Train Loss 1629.7565 Test MSE 14.594560753123742 Test RE 2.7601417815671865\n",
      "7 Train Loss 1219.3005 Test MSE 16.023178243129074 Test RE 2.8920793785606365\n",
      "8 Train Loss 925.37866 Test MSE 17.217036530553948 Test RE 2.997885747115514\n",
      "9 Train Loss 647.06036 Test MSE 16.49904061948282 Test RE 2.9347102084798746\n",
      "10 Train Loss 488.7438 Test MSE 15.883564932540247 Test RE 2.879452165582188\n",
      "11 Train Loss 407.17316 Test MSE 15.763489716040164 Test RE 2.868547599455831\n",
      "12 Train Loss 345.8634 Test MSE 15.441257442340778 Test RE 2.839077244288016\n",
      "13 Train Loss 305.33487 Test MSE 15.176220995970262 Test RE 2.814606575629567\n",
      "14 Train Loss 272.24255 Test MSE 14.819535469613546 Test RE 2.781334175280605\n",
      "15 Train Loss 245.91684 Test MSE 14.381844521002034 Test RE 2.7399533684702138\n",
      "16 Train Loss 222.386 Test MSE 14.191012925731702 Test RE 2.7217145481786065\n",
      "17 Train Loss 211.42072 Test MSE 13.916369768526469 Test RE 2.6952487716001183\n",
      "18 Train Loss 193.74544 Test MSE 13.794294881383406 Test RE 2.68340132410303\n",
      "19 Train Loss 183.74156 Test MSE 13.511771601182657 Test RE 2.6557795633659533\n",
      "20 Train Loss 173.23859 Test MSE 13.064527439235983 Test RE 2.6114561003923815\n",
      "21 Train Loss 155.45702 Test MSE 11.1498714036842 Test RE 2.412519354379609\n",
      "22 Train Loss 125.316154 Test MSE 10.746793510196259 Test RE 2.368510580275045\n",
      "23 Train Loss 100.74368 Test MSE 9.520218731264285 Test RE 2.2292528995742087\n",
      "24 Train Loss 80.59321 Test MSE 8.32099379199155 Test RE 2.0841236213489407\n",
      "25 Train Loss 64.79998 Test MSE 6.628643393620679 Test RE 1.8601510199076066\n",
      "26 Train Loss 50.92431 Test MSE 4.847427440030381 Test RE 1.5907119196254373\n",
      "27 Train Loss 38.97469 Test MSE 3.6183410892729033 Test RE 1.3743287410058997\n",
      "28 Train Loss 28.631104 Test MSE 2.6280736959823097 Test RE 1.1712635998380043\n",
      "29 Train Loss 22.03718 Test MSE 1.6143937715660124 Test RE 0.9179956295159951\n",
      "30 Train Loss 16.46052 Test MSE 1.022406654519321 Test RE 0.7305462413348062\n",
      "31 Train Loss 12.336689 Test MSE 0.5952433359534762 Test RE 0.5574207712731409\n",
      "32 Train Loss 9.780905 Test MSE 0.4366170453981129 Test RE 0.47740418316211974\n",
      "33 Train Loss 7.1969585 Test MSE 0.19769183900038337 Test RE 0.32124046626297753\n",
      "34 Train Loss 5.113729 Test MSE 0.13517585779597072 Test RE 0.2656350899084216\n",
      "35 Train Loss 3.7948968 Test MSE 0.06938420606773846 Test RE 0.19031200665862427\n",
      "36 Train Loss 2.8261602 Test MSE 0.05542881700628499 Test RE 0.17009975252201703\n",
      "37 Train Loss 2.2742121 Test MSE 0.03815418048853328 Test RE 0.1411259705914577\n",
      "38 Train Loss 1.9788479 Test MSE 0.0324094536006533 Test RE 0.13006838010592678\n",
      "39 Train Loss 1.4666758 Test MSE 0.02094957323490975 Test RE 0.1045739390281646\n",
      "40 Train Loss 1.2453939 Test MSE 0.018125559306068715 Test RE 0.09727059785688186\n",
      "41 Train Loss 1.094484 Test MSE 0.014793340670594183 Test RE 0.08787574221658051\n",
      "42 Train Loss 0.91785806 Test MSE 0.013098027949227433 Test RE 0.08268730423019144\n",
      "43 Train Loss 0.81751615 Test MSE 0.013392397165354052 Test RE 0.08361131175997759\n",
      "44 Train Loss 0.7451221 Test MSE 0.015049297858860115 Test RE 0.08863270337291729\n",
      "45 Train Loss 0.6781004 Test MSE 0.013837416200571129 Test RE 0.0849891290674388\n",
      "46 Train Loss 0.60541934 Test MSE 0.010907457084607712 Test RE 0.07545666966051827\n",
      "47 Train Loss 0.5229191 Test MSE 0.008675529877330975 Test RE 0.06729516801833187\n",
      "48 Train Loss 0.46984315 Test MSE 0.00721281671900366 Test RE 0.061360420231202646\n",
      "49 Train Loss 0.4358329 Test MSE 0.006543862680215466 Test RE 0.05844575396902551\n",
      "50 Train Loss 0.3987424 Test MSE 0.0062492748051848806 Test RE 0.05711506669315316\n",
      "51 Train Loss 0.3747486 Test MSE 0.006381972446385111 Test RE 0.05771827450266773\n",
      "52 Train Loss 0.35204867 Test MSE 0.006198233450506949 Test RE 0.05688134298244655\n",
      "53 Train Loss 0.33356106 Test MSE 0.006177554313207223 Test RE 0.05678637722841273\n",
      "54 Train Loss 0.31560555 Test MSE 0.005791542656435844 Test RE 0.054983579126584366\n",
      "55 Train Loss 0.30004528 Test MSE 0.005802345539883253 Test RE 0.05503483528611481\n",
      "56 Train Loss 0.28486037 Test MSE 0.005951755877478702 Test RE 0.05573890486738731\n",
      "57 Train Loss 0.27000782 Test MSE 0.005607062625569815 Test RE 0.05410078668663752\n",
      "58 Train Loss 0.2566941 Test MSE 0.00519082776119242 Test RE 0.052054009405111304\n",
      "59 Train Loss 0.24730088 Test MSE 0.004951950870099728 Test RE 0.05084216556042283\n",
      "60 Train Loss 0.23192224 Test MSE 0.0041894008516309336 Test RE 0.04676401974624931\n",
      "61 Train Loss 0.22050875 Test MSE 0.0038903691657586627 Test RE 0.0450641604076117\n",
      "62 Train Loss 0.21240729 Test MSE 0.0033857275799276916 Test RE 0.04203992015655289\n",
      "63 Train Loss 0.20315677 Test MSE 0.0030170674432360932 Test RE 0.03968518289209147\n",
      "64 Train Loss 0.19454888 Test MSE 0.0030316257069212278 Test RE 0.039780814178559026\n",
      "65 Train Loss 0.18849947 Test MSE 0.0031001127096508107 Test RE 0.04022764590547299\n",
      "66 Train Loss 0.17847645 Test MSE 0.003047657781429198 Test RE 0.039885861451202986\n",
      "67 Train Loss 0.17318109 Test MSE 0.0025340473623635716 Test RE 0.03636999495186735\n",
      "68 Train Loss 0.16549438 Test MSE 0.002428539461653358 Test RE 0.03560479251462203\n",
      "69 Train Loss 0.16007866 Test MSE 0.0023695071793940377 Test RE 0.035169394506044026\n",
      "70 Train Loss 0.1544879 Test MSE 0.002271836986013826 Test RE 0.03443693253095474\n",
      "71 Train Loss 0.15103462 Test MSE 0.0020409584421667835 Test RE 0.0326402110157758\n",
      "72 Train Loss 0.14590664 Test MSE 0.0019596113130392174 Test RE 0.03198312135257984\n",
      "73 Train Loss 0.13842969 Test MSE 0.0018404409171939508 Test RE 0.030995369422928454\n",
      "74 Train Loss 0.13271475 Test MSE 0.0016412495732667724 Test RE 0.02927003151130581\n",
      "75 Train Loss 0.12534186 Test MSE 0.0015424557700291133 Test RE 0.028375415959203135\n",
      "76 Train Loss 0.11958424 Test MSE 0.0015302994889794812 Test RE 0.028263379731984277\n",
      "77 Train Loss 0.113658495 Test MSE 0.0013703650365781618 Test RE 0.026745702631974892\n",
      "78 Train Loss 0.10788794 Test MSE 0.001246878458258354 Test RE 0.02551220158566096\n",
      "79 Train Loss 0.10209893 Test MSE 0.0011402005626226994 Test RE 0.024396442524429615\n",
      "80 Train Loss 0.09846353 Test MSE 0.001111312921112207 Test RE 0.024085410844536494\n",
      "81 Train Loss 0.09286071 Test MSE 0.0009580494372506523 Test RE 0.022362988319108584\n",
      "82 Train Loss 0.08889719 Test MSE 0.0009401240984236759 Test RE 0.02215279198530619\n",
      "83 Train Loss 0.086909056 Test MSE 0.0009169555746985457 Test RE 0.021878121229405217\n",
      "84 Train Loss 0.08357301 Test MSE 0.0009625207149096125 Test RE 0.02241511231782275\n",
      "85 Train Loss 0.07881229 Test MSE 0.0009342723212502824 Test RE 0.02208373963490489\n",
      "86 Train Loss 0.07610572 Test MSE 0.0009514103214945108 Test RE 0.022285367803891946\n",
      "87 Train Loss 0.073498756 Test MSE 0.0009793822432146737 Test RE 0.02261059493567551\n",
      "88 Train Loss 0.071662106 Test MSE 0.0009369516629221962 Test RE 0.02211538325788379\n",
      "89 Train Loss 0.06982292 Test MSE 0.0007607733029316786 Test RE 0.019927990562633037\n",
      "90 Train Loss 0.06830243 Test MSE 0.0007201025009264191 Test RE 0.01938800113662653\n",
      "91 Train Loss 0.06630588 Test MSE 0.0007590046229374635 Test RE 0.01990481233893971\n",
      "92 Train Loss 0.06461682 Test MSE 0.0007641918276795694 Test RE 0.01997271345917084\n",
      "93 Train Loss 0.062674545 Test MSE 0.0007664901556178154 Test RE 0.020002725153367897\n",
      "94 Train Loss 0.06166332 Test MSE 0.0007723580562848431 Test RE 0.020079145064744928\n",
      "95 Train Loss 0.060416505 Test MSE 0.0007846617795784801 Test RE 0.02023844432231796\n",
      "96 Train Loss 0.05802138 Test MSE 0.0008329435460556022 Test RE 0.02085180527615377\n",
      "97 Train Loss 0.056963112 Test MSE 0.0008008027215972706 Test RE 0.020445542902730637\n",
      "98 Train Loss 0.056001086 Test MSE 0.0008160084374350161 Test RE 0.020638741025428974\n",
      "99 Train Loss 0.054564446 Test MSE 0.0009361615659889301 Test RE 0.02210605674597129\n",
      "100 Train Loss 0.05253639 Test MSE 0.0009286861071337131 Test RE 0.022017618946997834\n",
      "101 Train Loss 0.050810914 Test MSE 0.000744432969530886 Test RE 0.01971281637066072\n",
      "102 Train Loss 0.049332023 Test MSE 0.000666784407715928 Test RE 0.01865643222216971\n",
      "103 Train Loss 0.048118904 Test MSE 0.0006237447260435333 Test RE 0.01804427013548272\n",
      "104 Train Loss 0.04744022 Test MSE 0.0006492913521775869 Test RE 0.01841008044443659\n",
      "105 Train Loss 0.046262324 Test MSE 0.0006599947803333996 Test RE 0.018561203289639346\n",
      "106 Train Loss 0.044455852 Test MSE 0.0006948356900087293 Test RE 0.0190448227817717\n",
      "107 Train Loss 0.043079715 Test MSE 0.0006307467433517139 Test RE 0.018145267930892103\n",
      "108 Train Loss 0.04218792 Test MSE 0.0005991515045129978 Test RE 0.01768496497339731\n",
      "109 Train Loss 0.041421466 Test MSE 0.0005983071074016083 Test RE 0.017672498678701087\n",
      "110 Train Loss 0.04019894 Test MSE 0.0005241332239064317 Test RE 0.016540808047142516\n",
      "111 Train Loss 0.039112817 Test MSE 0.0004628837416692001 Test RE 0.015544324013707277\n",
      "112 Train Loss 0.037934277 Test MSE 0.00045321369502475693 Test RE 0.015381099770722786\n",
      "113 Train Loss 0.037269145 Test MSE 0.00045655934234364637 Test RE 0.015437767425608534\n",
      "114 Train Loss 0.036706816 Test MSE 0.00045243025750042347 Test RE 0.015367799926841168\n",
      "115 Train Loss 0.035630874 Test MSE 0.00044415181021424606 Test RE 0.015226552881803336\n",
      "116 Train Loss 0.034995597 Test MSE 0.00047438264787307184 Test RE 0.01573621477258124\n",
      "117 Train Loss 0.034499317 Test MSE 0.00045717564545865006 Test RE 0.015448183525571924\n",
      "118 Train Loss 0.034092326 Test MSE 0.00043048711963662977 Test RE 0.014990494442731601\n",
      "119 Train Loss 0.033311844 Test MSE 0.00038856866605150133 Test RE 0.014241960112520227\n",
      "120 Train Loss 0.032247577 Test MSE 0.00038461184362098403 Test RE 0.014169261116560222\n",
      "121 Train Loss 0.031545907 Test MSE 0.0003510229296937513 Test RE 0.013536413743020342\n",
      "122 Train Loss 0.030716458 Test MSE 0.0003025132689986991 Test RE 0.01256631931835204\n",
      "123 Train Loss 0.029910592 Test MSE 0.00026959449448142375 Test RE 0.011862914120199406\n",
      "124 Train Loss 0.029373627 Test MSE 0.00025058502507705366 Test RE 0.01143703457263385\n",
      "125 Train Loss 0.028685316 Test MSE 0.00024839739912284553 Test RE 0.011387002054038831\n",
      "126 Train Loss 0.028158609 Test MSE 0.00023832977123496095 Test RE 0.011153855785588355\n",
      "127 Train Loss 0.027689239 Test MSE 0.0002483645654091047 Test RE 0.011386249449698094\n",
      "128 Train Loss 0.02690039 Test MSE 0.0002361384851643808 Test RE 0.011102461180410252\n",
      "129 Train Loss 0.026639443 Test MSE 0.00022577908945624215 Test RE 0.01085619749860527\n",
      "130 Train Loss 0.025606647 Test MSE 0.00021391072011234347 Test RE 0.010567010811411957\n",
      "131 Train Loss 0.02524322 Test MSE 0.00021062209884514931 Test RE 0.01048546862295447\n",
      "132 Train Loss 0.024474155 Test MSE 0.00021657690396867068 Test RE 0.010632660507596247\n",
      "133 Train Loss 0.023691744 Test MSE 0.00023240904437139015 Test RE 0.011014439185078627\n",
      "134 Train Loss 0.022796053 Test MSE 0.00020731964935071244 Test RE 0.010402940384430669\n",
      "135 Train Loss 0.021952948 Test MSE 0.00020438365991079575 Test RE 0.010329016300716337\n",
      "136 Train Loss 0.021266608 Test MSE 0.00019143485375580023 Test RE 0.009996463447666594\n",
      "137 Train Loss 0.020752411 Test MSE 0.0001800935443202065 Test RE 0.009695829045770998\n",
      "138 Train Loss 0.020331034 Test MSE 0.00019133823016274904 Test RE 0.00999394035401949\n",
      "139 Train Loss 0.019787882 Test MSE 0.0001841511890355342 Test RE 0.009804447844035573\n",
      "140 Train Loss 0.019239195 Test MSE 0.0001651696093125993 Test RE 0.009285407065629777\n",
      "141 Train Loss 0.018966753 Test MSE 0.00016277103873868268 Test RE 0.009217739795030636\n",
      "142 Train Loss 0.018546574 Test MSE 0.00015598973050988364 Test RE 0.009023684050239747\n",
      "143 Train Loss 0.018009786 Test MSE 0.0001569242175951723 Test RE 0.009050672765157535\n",
      "144 Train Loss 0.017615428 Test MSE 0.00015923335433664366 Test RE 0.009117019817491384\n",
      "145 Train Loss 0.017226642 Test MSE 0.0001616999517753654 Test RE 0.00918736185875931\n",
      "146 Train Loss 0.016802374 Test MSE 0.00017111010351203898 Test RE 0.009450911663823553\n",
      "147 Train Loss 0.016433496 Test MSE 0.0001755334660327948 Test RE 0.009572289859967728\n",
      "148 Train Loss 0.01626346 Test MSE 0.00015692819256130276 Test RE 0.009050787393385194\n",
      "149 Train Loss 0.016025422 Test MSE 0.00015815264401433863 Test RE 0.009086028722140673\n",
      "150 Train Loss 0.015801612 Test MSE 0.00016047587365483994 Test RE 0.009152521363242598\n",
      "151 Train Loss 0.015534033 Test MSE 0.0001562714937050515 Test RE 0.009031830083102037\n",
      "152 Train Loss 0.0152509175 Test MSE 0.00015190586242744655 Test RE 0.008904778973107588\n",
      "153 Train Loss 0.0149964215 Test MSE 0.0001439686237256762 Test RE 0.008669015977887051\n",
      "154 Train Loss 0.01470279 Test MSE 0.0001425532005659605 Test RE 0.00862629613493332\n",
      "155 Train Loss 0.014525334 Test MSE 0.0001400046073388172 Test RE 0.008548837085328252\n",
      "156 Train Loss 0.014409029 Test MSE 0.00013899013995824494 Test RE 0.008517808521779024\n",
      "157 Train Loss 0.014197558 Test MSE 0.00014218285275780383 Test RE 0.008615083452580882\n",
      "158 Train Loss 0.014085682 Test MSE 0.00014260770399260396 Test RE 0.008627945055354313\n",
      "159 Train Loss 0.013989575 Test MSE 0.00014299937721646509 Test RE 0.008639785291886803\n",
      "160 Train Loss 0.013867551 Test MSE 0.00013486803384784275 Test RE 0.0083905492327353\n",
      "161 Train Loss 0.013814572 Test MSE 0.00012994473473320275 Test RE 0.00823597880567368\n",
      "162 Train Loss 0.013700532 Test MSE 0.00013018999280133497 Test RE 0.008243747446870751\n",
      "163 Train Loss 0.013472978 Test MSE 0.0001298904663122571 Test RE 0.008234258842797338\n",
      "164 Train Loss 0.013333656 Test MSE 0.00011860437040613505 Test RE 0.00786839625717082\n",
      "165 Train Loss 0.01321868 Test MSE 0.00011035880845362921 Test RE 0.007589958097671532\n",
      "166 Train Loss 0.013115275 Test MSE 0.00011259879950787548 Test RE 0.0076665991562290415\n",
      "167 Train Loss 0.013018425 Test MSE 0.00011124539022303761 Test RE 0.007620384566471254\n",
      "168 Train Loss 0.012790691 Test MSE 0.00010014123720596508 Test RE 0.007230067521966904\n",
      "169 Train Loss 0.012558717 Test MSE 9.458273812173231e-05 Test RE 0.00702654477632322\n",
      "170 Train Loss 0.012329948 Test MSE 9.49326200654221e-05 Test RE 0.0070395291315746384\n",
      "171 Train Loss 0.012172265 Test MSE 8.427530645559751e-05 Test RE 0.006632634217860184\n",
      "172 Train Loss 0.012021104 Test MSE 8.184748606652127e-05 Test RE 0.006536398914913834\n",
      "173 Train Loss 0.011857193 Test MSE 8.006411114430089e-05 Test RE 0.0064647959275132\n",
      "174 Train Loss 0.011640947 Test MSE 7.424857812902038e-05 Test RE 0.006225581852922523\n",
      "175 Train Loss 0.011474158 Test MSE 7.253405338568061e-05 Test RE 0.006153282450353357\n",
      "176 Train Loss 0.011422224 Test MSE 7.370120735846906e-05 Test RE 0.0062025914779471215\n",
      "177 Train Loss 0.011278161 Test MSE 6.95656181540848e-05 Test RE 0.0060260565264720995\n",
      "178 Train Loss 0.01114891 Test MSE 6.803106410390734e-05 Test RE 0.00595922123595198\n",
      "179 Train Loss 0.011002575 Test MSE 6.321682738654824e-05 Test RE 0.005744499885535329\n",
      "180 Train Loss 0.010844989 Test MSE 5.938341527689662e-05 Test RE 0.00556760559402232\n",
      "181 Train Loss 0.010717295 Test MSE 5.5092322217749045e-05 Test RE 0.005362674241696483\n",
      "182 Train Loss 0.010596469 Test MSE 5.588275437877611e-05 Test RE 0.0054010074799923915\n",
      "183 Train Loss 0.010420105 Test MSE 5.262977194370287e-05 Test RE 0.0052414520962558945\n",
      "184 Train Loss 0.010332402 Test MSE 5.0317380400156666e-05 Test RE 0.005125012020981299\n",
      "185 Train Loss 0.0101868035 Test MSE 4.912593030407665e-05 Test RE 0.005063971709423604\n",
      "186 Train Loss 0.01004405 Test MSE 5.111040853416254e-05 Test RE 0.005165240564908794\n",
      "187 Train Loss 0.009953598 Test MSE 5.447517970636644e-05 Test RE 0.005332553394370406\n",
      "188 Train Loss 0.009884017 Test MSE 5.30784295212128e-05 Test RE 0.005263745815226065\n",
      "189 Train Loss 0.009715843 Test MSE 5.0051605816703524e-05 Test RE 0.005111459036623414\n",
      "190 Train Loss 0.009530013 Test MSE 4.929773456167676e-05 Test RE 0.005072818896294009\n",
      "191 Train Loss 0.009431855 Test MSE 4.770742723254135e-05 Test RE 0.004990325514227206\n",
      "192 Train Loss 0.009358756 Test MSE 4.6594221614211054e-05 Test RE 0.004931759699296349\n",
      "193 Train Loss 0.009289209 Test MSE 4.685068169597686e-05 Test RE 0.004945313567393197\n",
      "194 Train Loss 0.009149826 Test MSE 4.871820332518683e-05 Test RE 0.005042913381954135\n",
      "195 Train Loss 0.00902942 Test MSE 4.747677129055459e-05 Test RE 0.004978247280867593\n",
      "196 Train Loss 0.008911654 Test MSE 4.952986584309245e-05 Test RE 0.0050847482172157645\n",
      "197 Train Loss 0.008805403 Test MSE 5.202598710105058e-05 Test RE 0.005211299596238989\n",
      "198 Train Loss 0.008612697 Test MSE 5.170821895576588e-05 Test RE 0.005195360240849004\n",
      "199 Train Loss 0.0084694335 Test MSE 5.055603296183551e-05 Test RE 0.005137151468585049\n",
      "200 Train Loss 0.008364201 Test MSE 4.8993939467884485e-05 Test RE 0.005057164230961602\n",
      "201 Train Loss 0.008253194 Test MSE 5.200343616219641e-05 Test RE 0.005210170041157587\n",
      "202 Train Loss 0.008206868 Test MSE 5.240077818635155e-05 Test RE 0.005230036805964417\n",
      "203 Train Loss 0.00816099 Test MSE 5.2460645820794096e-05 Test RE 0.005233023598926867\n",
      "204 Train Loss 0.0081347665 Test MSE 5.3977478821841716e-05 Test RE 0.005308137629513209\n",
      "205 Train Loss 0.008079563 Test MSE 5.5237109339873676e-05 Test RE 0.005369716390832441\n",
      "206 Train Loss 0.007996901 Test MSE 5.443588110173738e-05 Test RE 0.005330629585059732\n",
      "207 Train Loss 0.007929983 Test MSE 5.326088376105194e-05 Test RE 0.005272784975210409\n",
      "208 Train Loss 0.0077824043 Test MSE 5.4406540679843115e-05 Test RE 0.0053291928121222435\n",
      "209 Train Loss 0.007636292 Test MSE 5.5640403064731564e-05 Test RE 0.005389283259270712\n",
      "210 Train Loss 0.007518393 Test MSE 5.5828390839768496e-05 Test RE 0.00539837975228147\n",
      "211 Train Loss 0.0074182823 Test MSE 5.752953473445624e-05 Test RE 0.0054800094544025435\n",
      "212 Train Loss 0.0073628915 Test MSE 5.836542978264996e-05 Test RE 0.005519677716331745\n",
      "213 Train Loss 0.0072953766 Test MSE 6.0236495239299565e-05 Test RE 0.005607454063429261\n",
      "214 Train Loss 0.0072359047 Test MSE 6.279030116461545e-05 Test RE 0.005725087912498288\n",
      "215 Train Loss 0.00721852 Test MSE 6.579943429835405e-05 Test RE 0.005860665800532112\n",
      "216 Train Loss 0.0071311896 Test MSE 6.738785862614413e-05 Test RE 0.005930983351236464\n",
      "217 Train Loss 0.007045271 Test MSE 6.681712465642999e-05 Test RE 0.005905814044009622\n",
      "218 Train Loss 0.006954862 Test MSE 6.592978149428489e-05 Test RE 0.005866467851933091\n",
      "219 Train Loss 0.0068812324 Test MSE 6.715691107443984e-05 Test RE 0.005920811476770033\n",
      "220 Train Loss 0.006812537 Test MSE 6.905426114174367e-05 Test RE 0.006003867764285719\n",
      "221 Train Loss 0.006724662 Test MSE 6.875367497565832e-05 Test RE 0.005990786400835564\n",
      "222 Train Loss 0.00685116 Test MSE 6.875400174136931e-05 Test RE 0.005990800637029139\n",
      "223 Train Loss 0.006750819 Test MSE 7.045270171410246e-05 Test RE 0.006064356207561773\n",
      "224 Train Loss 0.0067053074 Test MSE 6.732821112186184e-05 Test RE 0.005928357902972433\n",
      "225 Train Loss 0.006623946 Test MSE 6.5092109261031e-05 Test RE 0.005829080450007813\n",
      "226 Train Loss 0.0065556895 Test MSE 6.335091321921909e-05 Test RE 0.0057505888342979285\n",
      "227 Train Loss 0.006510747 Test MSE 6.256203252665188e-05 Test RE 0.005714671909536163\n",
      "228 Train Loss 0.0064507644 Test MSE 6.111572780202785e-05 Test RE 0.005648229969914224\n",
      "229 Train Loss 0.0063657756 Test MSE 6.25620717128694e-05 Test RE 0.005714673699250566\n",
      "230 Train Loss 0.0063381046 Test MSE 6.234299907787136e-05 Test RE 0.0057046594327871125\n",
      "231 Train Loss 0.0063122404 Test MSE 6.119327560842276e-05 Test RE 0.005651812263739788\n",
      "232 Train Loss 0.0062126024 Test MSE 6.116064703327038e-05 Test RE 0.005650305274874683\n",
      "233 Train Loss 0.0061632455 Test MSE 6.140796015004015e-05 Test RE 0.0056617177179754345\n",
      "234 Train Loss 0.006117127 Test MSE 6.178628053056392e-05 Test RE 0.005679131212204117\n",
      "235 Train Loss 0.006055421 Test MSE 6.264415622661248e-05 Test RE 0.005718421436767715\n",
      "236 Train Loss 0.0059681395 Test MSE 6.102333437373876e-05 Test RE 0.005643958919461372\n",
      "237 Train Loss 0.0059184204 Test MSE 5.907282417823744e-05 Test RE 0.005553026474828927\n",
      "238 Train Loss 0.005867459 Test MSE 5.8403099350871615e-05 Test RE 0.005521458653599857\n",
      "239 Train Loss 0.005814753 Test MSE 5.7831642361657e-05 Test RE 0.005494379333093385\n",
      "240 Train Loss 0.0058057196 Test MSE 5.9580904980809016e-05 Test RE 0.00557685592183747\n",
      "241 Train Loss 0.005744427 Test MSE 5.937711022491048e-05 Test RE 0.005567310015076665\n",
      "242 Train Loss 0.005748745 Test MSE 5.866801923654918e-05 Test RE 0.005533967314866671\n",
      "243 Train Loss 0.005707725 Test MSE 5.782806398304118e-05 Test RE 0.005494209345930182\n",
      "244 Train Loss 0.0056427214 Test MSE 5.718591674402524e-05 Test RE 0.005463619177134023\n",
      "245 Train Loss 0.0056035575 Test MSE 5.9060933432246055e-05 Test RE 0.005552467563423234\n",
      "246 Train Loss 0.005575637 Test MSE 5.9383758698373966e-05 Test RE 0.005567621693067526\n",
      "247 Train Loss 0.005519236 Test MSE 6.025203150294467e-05 Test RE 0.005608177157191901\n",
      "248 Train Loss 0.0054060593 Test MSE 5.5739275620261494e-05 Test RE 0.005394069490772763\n",
      "249 Train Loss 0.005346659 Test MSE 5.658638985369457e-05 Test RE 0.005434903915864125\n",
      "250 Train Loss 0.005303738 Test MSE 5.577932381650954e-05 Test RE 0.005396006939389053\n",
      "251 Train Loss 0.0052545974 Test MSE 5.450477546821061e-05 Test RE 0.00533400175627903\n",
      "252 Train Loss 0.0052187927 Test MSE 5.499840345376075e-05 Test RE 0.005358101276250489\n",
      "253 Train Loss 0.0051880237 Test MSE 5.419476447709556e-05 Test RE 0.0053188108193994174\n",
      "254 Train Loss 0.0051396852 Test MSE 5.131239381168351e-05 Test RE 0.005175436861937997\n",
      "255 Train Loss 0.0050943084 Test MSE 4.844163081329656e-05 Test RE 0.005028578736670115\n",
      "256 Train Loss 0.0050336374 Test MSE 4.759567194660452e-05 Test RE 0.00498447713513433\n",
      "257 Train Loss 0.004978643 Test MSE 4.486705001059533e-05 Test RE 0.004839490423372576\n",
      "258 Train Loss 0.0049008513 Test MSE 4.420100216579256e-05 Test RE 0.004803435185531544\n",
      "259 Train Loss 0.004849477 Test MSE 4.3308416816006046e-05 Test RE 0.004754688074639154\n",
      "260 Train Loss 0.004824705 Test MSE 4.2906591228476826e-05 Test RE 0.004732579119922619\n",
      "261 Train Loss 0.0047836527 Test MSE 4.124261115653675e-05 Test RE 0.00463990355796051\n",
      "262 Train Loss 0.0047732773 Test MSE 4.092076674744312e-05 Test RE 0.004621763923197738\n",
      "263 Train Loss 0.0047581457 Test MSE 4.064077928200304e-05 Test RE 0.004605925301596181\n",
      "264 Train Loss 0.0047037792 Test MSE 4.04696495817967e-05 Test RE 0.004596217784559669\n",
      "265 Train Loss 0.004660251 Test MSE 3.997654345863765e-05 Test RE 0.004568130447511973\n",
      "266 Train Loss 0.0046249 Test MSE 4.0395975179161525e-05 Test RE 0.0045920322052623004\n",
      "267 Train Loss 0.0046042986 Test MSE 4.044496908675158e-05 Test RE 0.004594816064608548\n",
      "268 Train Loss 0.004610524 Test MSE 4.087043058518988e-05 Test RE 0.004618920459306633\n",
      "269 Train Loss 0.0045742076 Test MSE 3.9835587540291946e-05 Test RE 0.004560069800364759\n",
      "270 Train Loss 0.004519441 Test MSE 3.9713539763376184e-05 Test RE 0.004553078899070829\n",
      "271 Train Loss 0.0044986717 Test MSE 3.937846540457947e-05 Test RE 0.004533830405090918\n",
      "272 Train Loss 0.0044451323 Test MSE 3.941661387848306e-05 Test RE 0.0045360259812810095\n",
      "273 Train Loss 0.0044101872 Test MSE 3.894976306485793e-05 Test RE 0.004509083596063417\n",
      "274 Train Loss 0.0043670535 Test MSE 3.955208060761592e-05 Test RE 0.004543813985972812\n",
      "275 Train Loss 0.0043340703 Test MSE 3.9626965344307485e-05 Test RE 0.004548113398350531\n",
      "276 Train Loss 0.0043358016 Test MSE 4.008272345303693e-05 Test RE 0.004574193032895707\n",
      "277 Train Loss 0.0042964853 Test MSE 4.028311914966186e-05 Test RE 0.004585613236754865\n",
      "278 Train Loss 0.004270408 Test MSE 4.083698185185624e-05 Test RE 0.004617029989107171\n",
      "279 Train Loss 0.0042499043 Test MSE 4.109853399133434e-05 Test RE 0.0046317919351300425\n",
      "280 Train Loss 0.004242551 Test MSE 4.104581738251472e-05 Test RE 0.004628820409270441\n",
      "281 Train Loss 0.0042145164 Test MSE 4.112923397666371e-05 Test RE 0.004633521551566528\n",
      "282 Train Loss 0.00421441 Test MSE 4.165827866546667e-05 Test RE 0.004663226789653675\n",
      "283 Train Loss 0.004187292 Test MSE 4.174025186006393e-05 Test RE 0.0046678125736323885\n",
      "284 Train Loss 0.0041635656 Test MSE 4.2687476963018566e-05 Test RE 0.004720479546650486\n",
      "285 Train Loss 0.0041527655 Test MSE 4.265533570975056e-05 Test RE 0.004718702085088551\n",
      "286 Train Loss 0.004132386 Test MSE 4.321711685981799e-05 Test RE 0.004749673670130063\n",
      "287 Train Loss 0.00412586 Test MSE 4.265028131835902e-05 Test RE 0.004718422508414646\n",
      "288 Train Loss 0.0040916638 Test MSE 4.306532423579919e-05 Test RE 0.004741325130676699\n",
      "289 Train Loss 0.0040795887 Test MSE 4.258311097758033e-05 Test RE 0.004714705499715193\n",
      "290 Train Loss 0.0040481933 Test MSE 4.132081023315454e-05 Test RE 0.004644300276977393\n",
      "291 Train Loss 0.004031771 Test MSE 4.183814688419812e-05 Test RE 0.004673283168430139\n",
      "292 Train Loss 0.0040455293 Test MSE 4.1090233156196174e-05 Test RE 0.004631324160746497\n",
      "293 Train Loss 0.0040127086 Test MSE 4.057170450438565e-05 Test RE 0.004602009424818871\n",
      "294 Train Loss 0.0040046163 Test MSE 4.057073023695761e-05 Test RE 0.004601954169378436\n",
      "295 Train Loss 0.003982237 Test MSE 4.086310167480383e-05 Test RE 0.0046185063069310315\n",
      "296 Train Loss 0.0039758105 Test MSE 4.046387591989341e-05 Test RE 0.004595889909789948\n",
      "297 Train Loss 0.003946155 Test MSE 4.134586014401132e-05 Test RE 0.004645707820543513\n",
      "298 Train Loss 0.00393876 Test MSE 4.2111685001457416e-05 Test RE 0.004688535259627947\n",
      "299 Train Loss 0.0039086747 Test MSE 4.273266198363516e-05 Test RE 0.004722977217713192\n",
      "Training time: 117.30\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3e146e1e90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.00404372757188383\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
