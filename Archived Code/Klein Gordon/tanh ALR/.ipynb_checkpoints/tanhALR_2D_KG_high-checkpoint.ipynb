{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"high\"\n",
    "label = \"KG_tanhALR_\" + level\n",
    "\n",
    "x = np.linspace(-2,2,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        self.lambdas = torch.ones((2,),device = device)\n",
    "        self.lambda_alpha = 0.1\n",
    "            \n",
    "\n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "                    \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "    \n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.lambdas[0]*self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.lambdas[1]*self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    def lambda_update(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "        loss_bc1 = self.lambdas[0]*self.loss_BC(xt_BC,y_BC)\n",
    "        loss_bc1.backward()\n",
    "        bc1_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc1_grads.append(param.grad.view(-1))\n",
    "        bc1_grads = torch.cat(bc1_grads)\n",
    "        bc1_grads = torch.mean(torch.abs(bc1_grads))      \n",
    "        \n",
    "        loss_bc2 = self.lambdas[1]*self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_bc2.backward()\n",
    "        bc2_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc2_grads.append(param.grad.view(-1))\n",
    "        bc2_grads = torch.cat(bc2_grads)\n",
    "        bc2_grads = torch.mean(torch.abs(bc2_grads))    \n",
    "    \n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        loss_f.backward()\n",
    "        f_grads = []\n",
    "        for param in self.parameters():\n",
    "            f_grads.append(param.grad.view(-1))   \n",
    "        f_grads = torch.cat(f_grads)\n",
    "        f_grads = torch.max(torch.abs(f_grads))\n",
    "    \n",
    "        self.lambdas[0] = (1.0-self.lambda_alpha)*self.lambdas[0] + self.lambda_alpha*f_grads/bc1_grads\n",
    "        self.lambdas[1] = (1.0-self.lambda_alpha)*self.lambdas[1] + self.lambda_alpha*f_grads/bc2_grads\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    PINN.lambda_update(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_tanhALR_high\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 64366.652 Test MSE 4.26261351533965 Test RE 1.4916737791321055\n",
      "1 Train Loss 47031.63 Test MSE 6.518700572675437 Test RE 1.8446602665650031\n",
      "2 Train Loss 35576.82 Test MSE 4.5050985292663785 Test RE 1.5335149836789945\n",
      "3 Train Loss 22159.28 Test MSE 6.568776437212591 Test RE 1.8517319394597296\n",
      "4 Train Loss 13242.064 Test MSE 5.414819385831238 Test RE 1.6812328393040021\n",
      "5 Train Loss 4226.7896 Test MSE 11.087210276636755 Test RE 2.405730748178966\n",
      "6 Train Loss 2500.5334 Test MSE 14.50576421239129 Test RE 2.7517323137607845\n",
      "7 Train Loss 1722.935 Test MSE 16.185416589797324 Test RE 2.906683985706557\n",
      "8 Train Loss 1371.8324 Test MSE 16.06585169485615 Test RE 2.895927957987175\n",
      "9 Train Loss 1166.5054 Test MSE 16.392136587356223 Test RE 2.925187163630414\n",
      "10 Train Loss 1023.32526 Test MSE 16.197092144653578 Test RE 2.9077321833261682\n",
      "11 Train Loss 952.05835 Test MSE 16.237351186868437 Test RE 2.9113436297544286\n",
      "12 Train Loss 885.8731 Test MSE 15.892971047976332 Test RE 2.8803046332418707\n",
      "13 Train Loss 824.31 Test MSE 15.57159580977149 Test RE 2.8510342724669973\n",
      "14 Train Loss 758.16547 Test MSE 14.582687485266952 Test RE 2.7590188094106147\n",
      "15 Train Loss 635.81134 Test MSE 12.845716543214051 Test RE 2.589494805477787\n",
      "16 Train Loss 506.76968 Test MSE 11.051156660366347 Test RE 2.4018160609918\n",
      "17 Train Loss 372.86127 Test MSE 9.903438130461234 Test RE 2.2736775481071536\n",
      "18 Train Loss 294.75128 Test MSE 9.24776448316261 Test RE 2.197122427892381\n",
      "19 Train Loss 258.87845 Test MSE 8.777647203083196 Test RE 2.1405478355270833\n",
      "20 Train Loss 221.91518 Test MSE 8.474600147753428 Test RE 2.1032722167379068\n",
      "21 Train Loss 195.9855 Test MSE 8.280436046099467 Test RE 2.0790382547550945\n",
      "22 Train Loss 193.64668 Test MSE 7.792908114692401 Test RE 2.0169059848191138\n",
      "23 Train Loss 175.60649 Test MSE 6.801955414227198 Test RE 1.884311798024507\n",
      "24 Train Loss 152.36697 Test MSE 4.806640852481061 Test RE 1.5840056032791723\n",
      "25 Train Loss 93.585106 Test MSE 2.5182712069926336 Test RE 1.1465344983809325\n",
      "26 Train Loss 56.244774 Test MSE 1.5940912512003687 Test RE 0.912205037070684\n",
      "27 Train Loss 33.392548 Test MSE 0.6459003320987426 Test RE 0.5806556159992479\n",
      "28 Train Loss 19.88588 Test MSE 0.2512649702781267 Test RE 0.3621611412517921\n",
      "29 Train Loss 12.278217 Test MSE 0.14182859235675874 Test RE 0.27209325319272093\n",
      "30 Train Loss 8.915959 Test MSE 0.10106357890015061 Test RE 0.22968530672030113\n",
      "31 Train Loss 6.2165446 Test MSE 0.03665266701192231 Test RE 0.13832117438497774\n",
      "32 Train Loss 4.737827 Test MSE 0.025799301032380022 Test RE 0.11604858433064436\n",
      "33 Train Loss 3.5703096 Test MSE 0.015351116206726426 Test RE 0.08951706953719213\n",
      "34 Train Loss 2.5438235 Test MSE 0.022820383195573737 Test RE 0.10914336597282388\n",
      "35 Train Loss 1.9525995 Test MSE 0.013170266020751258 Test RE 0.08291500867028355\n",
      "36 Train Loss 1.5233442 Test MSE 0.015903384202887644 Test RE 0.09111306417190268\n",
      "37 Train Loss 1.272665 Test MSE 0.007180598417505747 Test RE 0.061223224099449455\n",
      "38 Train Loss 1.0669768 Test MSE 0.005586122945098023 Test RE 0.05399967199369278\n",
      "39 Train Loss 0.9401457 Test MSE 0.003226458028799926 Test RE 0.04103920006088602\n",
      "40 Train Loss 0.83449054 Test MSE 0.0033890702299264716 Test RE 0.042060667554069904\n",
      "41 Train Loss 0.7354117 Test MSE 0.0029914612268815057 Test RE 0.039516417572265955\n",
      "42 Train Loss 0.66487956 Test MSE 0.0025609158617813862 Test RE 0.03656230203212889\n",
      "43 Train Loss 0.578324 Test MSE 0.0022767636511152986 Test RE 0.0344742519676811\n",
      "44 Train Loss 0.5140585 Test MSE 0.0019514174174491694 Test RE 0.03191618438405937\n",
      "45 Train Loss 0.46608162 Test MSE 0.0018644932567395806 Test RE 0.031197248004696154\n",
      "46 Train Loss 0.4106385 Test MSE 0.0020456240084124502 Test RE 0.03267749696272261\n",
      "47 Train Loss 0.3656324 Test MSE 0.001749967806699262 Test RE 0.030223928036736004\n",
      "48 Train Loss 0.33468643 Test MSE 0.001309685455512944 Test RE 0.026146850225931658\n",
      "49 Train Loss 0.30735 Test MSE 0.0012070561000835079 Test RE 0.025101495949681037\n",
      "50 Train Loss 0.28899628 Test MSE 0.0010183940619855451 Test RE 0.02305652253470406\n",
      "51 Train Loss 0.2616234 Test MSE 0.0013339563291514605 Test RE 0.026388012605443403\n",
      "52 Train Loss 0.24385217 Test MSE 0.0012343517059813795 Test RE 0.025383724041722237\n",
      "53 Train Loss 0.22171453 Test MSE 0.001158760420171291 Test RE 0.024594200157572653\n",
      "54 Train Loss 0.20883478 Test MSE 0.0008292727014256068 Test RE 0.02080580680625218\n",
      "55 Train Loss 0.19588912 Test MSE 0.0006825675702603522 Test RE 0.018875944952154004\n",
      "56 Train Loss 0.18117017 Test MSE 0.000620949128036433 Test RE 0.01800378788921129\n",
      "57 Train Loss 0.16928111 Test MSE 0.000631682522293192 Test RE 0.01815872314613964\n",
      "58 Train Loss 0.15985012 Test MSE 0.0006973426694208309 Test RE 0.019079148875438837\n",
      "59 Train Loss 0.15046763 Test MSE 0.0005900366871790734 Test RE 0.01754992985054114\n",
      "60 Train Loss 0.14245155 Test MSE 0.0005652838918823648 Test RE 0.01717786486735439\n",
      "61 Train Loss 0.13513537 Test MSE 0.0005542179037506829 Test RE 0.017008897053010986\n",
      "62 Train Loss 0.12890384 Test MSE 0.0005623903792702486 Test RE 0.01713384438669572\n",
      "63 Train Loss 0.1245134 Test MSE 0.0005880261925323117 Test RE 0.01752000446720151\n",
      "64 Train Loss 0.11848488 Test MSE 0.0005608560381594338 Test RE 0.01711045572452575\n",
      "65 Train Loss 0.11239453 Test MSE 0.0005347994374632685 Test RE 0.016708264732296207\n",
      "66 Train Loss 0.10598735 Test MSE 0.0005172590902653903 Test RE 0.01643198170511797\n",
      "67 Train Loss 0.100488394 Test MSE 0.00047612481442307946 Test RE 0.015765083854107867\n",
      "68 Train Loss 0.09699289 Test MSE 0.00046067203238035396 Test RE 0.015507143304596491\n",
      "69 Train Loss 0.09239081 Test MSE 0.0004218340221175368 Test RE 0.01483906984024525\n",
      "70 Train Loss 0.08747368 Test MSE 0.0004099403228573925 Test RE 0.01462837874916729\n",
      "71 Train Loss 0.084001996 Test MSE 0.0004240082264683291 Test RE 0.014877262236831505\n",
      "72 Train Loss 0.078763284 Test MSE 0.0004862187773612952 Test RE 0.01593131924091344\n",
      "73 Train Loss 0.07488977 Test MSE 0.0004482838004039365 Test RE 0.015297216013161932\n",
      "74 Train Loss 0.07088554 Test MSE 0.0004270743096614003 Test RE 0.014930955485156832\n",
      "75 Train Loss 0.06722743 Test MSE 0.00037588018204220405 Test RE 0.014007498710266091\n",
      "76 Train Loss 0.06398778 Test MSE 0.00033843569762663294 Test RE 0.013291498898158807\n",
      "77 Train Loss 0.061183624 Test MSE 0.0002949191417402935 Test RE 0.012407587814116574\n",
      "78 Train Loss 0.05822628 Test MSE 0.00026612821901128244 Test RE 0.01178640447365825\n",
      "79 Train Loss 0.055256188 Test MSE 0.0002609657893325032 Test RE 0.011671526650924321\n",
      "80 Train Loss 0.054572057 Test MSE 0.0002512614425006533 Test RE 0.011452460466103162\n",
      "81 Train Loss 0.05200628 Test MSE 0.00026019655428608695 Test RE 0.011654312185305151\n",
      "82 Train Loss 0.049235784 Test MSE 0.00026950532135478655 Test RE 0.011860952024060312\n",
      "83 Train Loss 0.04846623 Test MSE 0.00025222326331486865 Test RE 0.011474359356350222\n",
      "84 Train Loss 0.04634526 Test MSE 0.00024394410663305344 Test RE 0.01128446677535126\n",
      "85 Train Loss 0.044677906 Test MSE 0.00023068433187215133 Test RE 0.010973493885007117\n",
      "86 Train Loss 0.043653898 Test MSE 0.00021979478344540178 Test RE 0.010711358802428269\n",
      "87 Train Loss 0.042205535 Test MSE 0.00023418403617264828 Test RE 0.011056419807087003\n",
      "88 Train Loss 0.041306548 Test MSE 0.00022929837840098233 Test RE 0.010940479799749126\n",
      "89 Train Loss 0.03971525 Test MSE 0.00021671938454754326 Test RE 0.010636157414506957\n",
      "90 Train Loss 0.03837979 Test MSE 0.00022100557054712468 Test RE 0.010740821201460077\n",
      "91 Train Loss 0.037376888 Test MSE 0.0002084321646694585 Test RE 0.010430815083728652\n",
      "92 Train Loss 0.035903957 Test MSE 0.00020714034971119417 Test RE 0.010398440938940505\n",
      "93 Train Loss 0.034726568 Test MSE 0.00021362070690093046 Test RE 0.010559845176712513\n",
      "94 Train Loss 0.03399235 Test MSE 0.00022332195452247756 Test RE 0.010796962350554069\n",
      "95 Train Loss 0.033001866 Test MSE 0.00022920587565424037 Test RE 0.01093827279216661\n",
      "96 Train Loss 0.03231233 Test MSE 0.00022825941858116468 Test RE 0.01091566579100051\n",
      "97 Train Loss 0.031573378 Test MSE 0.00022575646727650546 Test RE 0.010855653610763882\n",
      "98 Train Loss 0.030497566 Test MSE 0.00022298175912873456 Test RE 0.010788735490886039\n",
      "99 Train Loss 0.029848227 Test MSE 0.0002211013069439355 Test RE 0.010743147333291025\n",
      "100 Train Loss 0.029015547 Test MSE 0.00022159363906509494 Test RE 0.010755101707199574\n",
      "101 Train Loss 0.028083602 Test MSE 0.00021696231356844797 Test RE 0.010642116982081106\n",
      "102 Train Loss 0.027635807 Test MSE 0.00022135400761945947 Test RE 0.010749284848645863\n",
      "103 Train Loss 0.02702098 Test MSE 0.00020618257512494586 Test RE 0.010374372953904719\n",
      "104 Train Loss 0.026806524 Test MSE 0.00020522546823647437 Test RE 0.010350265839679138\n",
      "105 Train Loss 0.02627783 Test MSE 0.00019984982151561318 Test RE 0.010213809636079995\n",
      "106 Train Loss 0.025724253 Test MSE 0.0002008803295247467 Test RE 0.010240109082040923\n",
      "107 Train Loss 0.025168512 Test MSE 0.0002000698112970528 Test RE 0.010219429645470486\n",
      "108 Train Loss 0.024822231 Test MSE 0.0001959095624665216 Test RE 0.010112620141918422\n",
      "109 Train Loss 0.024160977 Test MSE 0.00019512540236428361 Test RE 0.010092361140113476\n",
      "110 Train Loss 0.023610387 Test MSE 0.00019251988254857759 Test RE 0.01002475277109508\n",
      "111 Train Loss 0.023103306 Test MSE 0.00020216280842606386 Test RE 0.010272745004459242\n",
      "112 Train Loss 0.022464361 Test MSE 0.00020698832829355967 Test RE 0.01039462450269764\n",
      "113 Train Loss 0.02183179 Test MSE 0.00021246088950255411 Test RE 0.010531139716599323\n",
      "114 Train Loss 0.021216054 Test MSE 0.00021035608744676842 Test RE 0.010478845064848068\n",
      "115 Train Loss 0.02076352 Test MSE 0.00021589257506916273 Test RE 0.010615848941815484\n",
      "116 Train Loss 0.02044242 Test MSE 0.00021882645951025638 Test RE 0.010687737873116524\n",
      "117 Train Loss 0.02003735 Test MSE 0.00020739552047022286 Test RE 0.010404843750891523\n",
      "118 Train Loss 0.019406576 Test MSE 0.00021018377215508102 Test RE 0.010474552260205397\n",
      "119 Train Loss 0.018885305 Test MSE 0.00021081852453377876 Test RE 0.010490356845585878\n",
      "120 Train Loss 0.018609397 Test MSE 0.00019920146863398113 Test RE 0.010197228353976663\n",
      "121 Train Loss 0.01826319 Test MSE 0.0002015156578452302 Test RE 0.010256289599583836\n",
      "122 Train Loss 0.017973829 Test MSE 0.0002028785006973108 Test RE 0.010290912611046364\n",
      "123 Train Loss 0.017777301 Test MSE 0.00020258767718045923 Test RE 0.010283534025575905\n",
      "124 Train Loss 0.017506992 Test MSE 0.00019386849073909466 Test RE 0.010059803359136981\n",
      "125 Train Loss 0.017219193 Test MSE 0.00019415242175588974 Test RE 0.010067167230265324\n",
      "126 Train Loss 0.016888456 Test MSE 0.00019521335099118885 Test RE 0.01009463534249443\n",
      "127 Train Loss 0.016575888 Test MSE 0.00019920576361073222 Test RE 0.01019733828444789\n",
      "128 Train Loss 0.016369868 Test MSE 0.00019733539963500394 Test RE 0.010149353441488875\n",
      "129 Train Loss 0.016073598 Test MSE 0.00019639564045769884 Test RE 0.010125157755654495\n",
      "130 Train Loss 0.01586317 Test MSE 0.0001899056293540152 Test RE 0.00995645639892988\n",
      "131 Train Loss 0.015607324 Test MSE 0.00017867015888435762 Test RE 0.009657437110714682\n",
      "132 Train Loss 0.015525017 Test MSE 0.0001745634084880896 Test RE 0.00954580335364899\n",
      "133 Train Loss 0.015165608 Test MSE 0.00017156755527850148 Test RE 0.009463536431335537\n",
      "134 Train Loss 0.015152599 Test MSE 0.00017265823232109263 Test RE 0.0094935692362332\n",
      "135 Train Loss 0.01477942 Test MSE 0.00016870907828227274 Test RE 0.00938436958446311\n",
      "136 Train Loss 0.014681785 Test MSE 0.00015718454787659998 Test RE 0.009058176985478141\n",
      "137 Train Loss 0.014387461 Test MSE 0.00015784661725768204 Test RE 0.00907723369273453\n",
      "138 Train Loss 0.01423333 Test MSE 0.00015837608864690617 Test RE 0.009092445016258747\n",
      "139 Train Loss 0.014022039 Test MSE 0.00015888435538632443 Test RE 0.009107023244495683\n",
      "140 Train Loss 0.013885521 Test MSE 0.00016072968474105563 Test RE 0.00915975638721861\n",
      "141 Train Loss 0.013570709 Test MSE 0.0001478913065591242 Test RE 0.008786323711383371\n",
      "142 Train Loss 0.01357259 Test MSE 0.0001454813400238891 Test RE 0.008714440785656924\n",
      "143 Train Loss 0.01319956 Test MSE 0.0001434847176847189 Test RE 0.008654434605679615\n",
      "144 Train Loss 0.012744222 Test MSE 0.0001437052206149201 Test RE 0.00866108198812656\n",
      "145 Train Loss 0.012523952 Test MSE 0.00014293510779899088 Test RE 0.008637843547863113\n",
      "146 Train Loss 0.01236106 Test MSE 0.00014076205130402036 Test RE 0.008571931077653883\n",
      "147 Train Loss 0.012061516 Test MSE 0.00014121754481611436 Test RE 0.00858578888036172\n",
      "148 Train Loss 0.0119398115 Test MSE 0.00014449104626350183 Test RE 0.008684730472214285\n",
      "149 Train Loss 0.011730242 Test MSE 0.00013800454810416086 Test RE 0.00848755451140886\n",
      "150 Train Loss 0.011656681 Test MSE 0.00013347077486798508 Test RE 0.00834697221385414\n",
      "151 Train Loss 0.011638851 Test MSE 0.00012636932089965996 Test RE 0.00812188250907254\n",
      "152 Train Loss 0.011380346 Test MSE 0.00012359788897431934 Test RE 0.008032327424826851\n",
      "153 Train Loss 0.01110426 Test MSE 0.00012363996789127897 Test RE 0.008033694611916685\n",
      "154 Train Loss 0.01102241 Test MSE 0.00012463034984478463 Test RE 0.008065806220471275\n",
      "155 Train Loss 0.010728873 Test MSE 0.00012469085054324518 Test RE 0.008067763719999817\n",
      "156 Train Loss 0.010483044 Test MSE 0.00011754350749339716 Test RE 0.007833127576168202\n",
      "157 Train Loss 0.01042584 Test MSE 0.00011699652830192119 Test RE 0.007814880911713038\n",
      "158 Train Loss 0.0101625305 Test MSE 0.00011646572745903034 Test RE 0.007797133115849091\n",
      "159 Train Loss 0.009942514 Test MSE 0.00011420777114059012 Test RE 0.007721180494812329\n",
      "160 Train Loss 0.009681831 Test MSE 0.00011648922894193198 Test RE 0.0077979197633520755\n",
      "161 Train Loss 0.009528452 Test MSE 0.00011621928216161488 Test RE 0.007788879252531641\n",
      "162 Train Loss 0.0092583215 Test MSE 0.00012063482270319157 Test RE 0.007935462104469519\n",
      "163 Train Loss 0.0090296995 Test MSE 0.00011826695472833909 Test RE 0.007857195948223837\n",
      "164 Train Loss 0.008832041 Test MSE 0.00011923009677650406 Test RE 0.007889124778193021\n",
      "165 Train Loss 0.008661777 Test MSE 0.00011819834386733041 Test RE 0.007854916498358854\n",
      "166 Train Loss 0.008531652 Test MSE 0.00012127854369206685 Test RE 0.007956606194567143\n",
      "167 Train Loss 0.008385233 Test MSE 0.00012461003272801392 Test RE 0.008065148753785905\n",
      "168 Train Loss 0.008325757 Test MSE 0.0001237604869502819 Test RE 0.00803760911263574\n",
      "169 Train Loss 0.008192779 Test MSE 0.00012397882331459205 Test RE 0.008044695902141878\n",
      "170 Train Loss 0.008312405 Test MSE 0.00012590132348314458 Test RE 0.008106829228260446\n",
      "171 Train Loss 0.008131533 Test MSE 0.0001281980082008775 Test RE 0.008180437213965545\n",
      "172 Train Loss 0.008122491 Test MSE 0.0001286993590885715 Test RE 0.00819641744475788\n",
      "173 Train Loss 0.008018259 Test MSE 0.00012592952936425268 Test RE 0.008107737270565725\n",
      "174 Train Loss 0.007913426 Test MSE 0.00012142371023072897 Test RE 0.007961366672051152\n",
      "175 Train Loss 0.00778722 Test MSE 0.0001170918624656524 Test RE 0.007818064225948025\n",
      "176 Train Loss 0.0076263146 Test MSE 0.00011195337927965467 Test RE 0.007644594972452528\n",
      "177 Train Loss 0.007599548 Test MSE 0.00010842043140876164 Test RE 0.007523006592637325\n",
      "178 Train Loss 0.007416215 Test MSE 0.00010755258071520417 Test RE 0.007492837167996861\n",
      "179 Train Loss 0.0071850275 Test MSE 0.00010943908967986588 Test RE 0.0075582649690133985\n",
      "180 Train Loss 0.0071226833 Test MSE 0.00010607636018373232 Test RE 0.007441237765947359\n",
      "181 Train Loss 0.0069340523 Test MSE 0.00010599105756689428 Test RE 0.007438245182509735\n",
      "182 Train Loss 0.0067575644 Test MSE 0.00010505164252392695 Test RE 0.00740520866217821\n",
      "183 Train Loss 0.006760609 Test MSE 0.00010325084250903833 Test RE 0.007341464092082332\n",
      "184 Train Loss 0.006529894 Test MSE 9.86480322128328e-05 Test RE 0.007175961337752997\n",
      "185 Train Loss 0.006499339 Test MSE 9.617440326568783e-05 Test RE 0.0070854204597682905\n",
      "186 Train Loss 0.0064460738 Test MSE 9.491792374444523e-05 Test RE 0.007038984223071097\n",
      "187 Train Loss 0.0062635243 Test MSE 9.488285412144499e-05 Test RE 0.007037683745147591\n",
      "188 Train Loss 0.0061848713 Test MSE 9.431881220097144e-05 Test RE 0.007016734408986569\n",
      "189 Train Loss 0.0060600033 Test MSE 9.374679018421581e-05 Test RE 0.006995424605664846\n",
      "190 Train Loss 0.005968614 Test MSE 9.719957380254201e-05 Test RE 0.007123083858355555\n",
      "191 Train Loss 0.0058351504 Test MSE 0.00010365360318796625 Test RE 0.007355768939766827\n",
      "192 Train Loss 0.005710018 Test MSE 0.00010379406097390198 Test RE 0.007360751039850401\n",
      "193 Train Loss 0.0056084236 Test MSE 0.00010445027480934193 Test RE 0.007383982697657105\n",
      "194 Train Loss 0.0055734715 Test MSE 0.00010718619587755452 Test RE 0.0074800638626983116\n",
      "195 Train Loss 0.005454147 Test MSE 0.00010505454538095053 Test RE 0.00740531097430281\n",
      "196 Train Loss 0.0053229933 Test MSE 0.00010128876833680765 Test RE 0.007271374653233037\n",
      "197 Train Loss 0.005262197 Test MSE 0.00010022345392695828 Test RE 0.007233034883377956\n",
      "198 Train Loss 0.0051664263 Test MSE 0.00010076547915487623 Test RE 0.007252567242570545\n",
      "199 Train Loss 0.005128254 Test MSE 0.00010093985872214692 Test RE 0.007258839990265797\n",
      "200 Train Loss 0.005109367 Test MSE 9.96009894791737e-05 Test RE 0.007210538554547503\n",
      "201 Train Loss 0.005034039 Test MSE 9.806486986446347e-05 Test RE 0.007154719386416235\n",
      "202 Train Loss 0.004939017 Test MSE 9.745475418055472e-05 Test RE 0.007132427931225251\n",
      "203 Train Loss 0.0048706615 Test MSE 9.755409726855769e-05 Test RE 0.007136062320034096\n",
      "204 Train Loss 0.004808558 Test MSE 9.790094522188046e-05 Test RE 0.007148736992538639\n",
      "205 Train Loss 0.0047424277 Test MSE 9.996823659390907e-05 Test RE 0.007223819612408739\n",
      "206 Train Loss 0.0046577663 Test MSE 9.826008397731497e-05 Test RE 0.007161837163657835\n",
      "207 Train Loss 0.00460051 Test MSE 9.684885024564458e-05 Test RE 0.007110221194111545\n",
      "208 Train Loss 0.0045778225 Test MSE 9.49790081886779e-05 Test RE 0.00704124882846549\n",
      "209 Train Loss 0.0045416644 Test MSE 9.425835730219099e-05 Test RE 0.007014485313849178\n",
      "210 Train Loss 0.0045315414 Test MSE 9.291258700747626e-05 Test RE 0.0069642307616244155\n",
      "211 Train Loss 0.004476029 Test MSE 9.378244439052262e-05 Test RE 0.006996754745082556\n",
      "212 Train Loss 0.00441692 Test MSE 9.30730690413843e-05 Test RE 0.006970242604394904\n",
      "213 Train Loss 0.004314458 Test MSE 9.478966056725613e-05 Test RE 0.007034226703861796\n",
      "214 Train Loss 0.0042527844 Test MSE 9.463631607070618e-05 Test RE 0.007028534645542252\n",
      "215 Train Loss 0.0042098346 Test MSE 9.320068012917188e-05 Test RE 0.006975019365119738\n",
      "216 Train Loss 0.004165396 Test MSE 9.558737468605244e-05 Test RE 0.007063763394296579\n",
      "217 Train Loss 0.0041280687 Test MSE 9.107206689409333e-05 Test RE 0.006894907964212595\n",
      "218 Train Loss 0.004077799 Test MSE 9.143697093657972e-05 Test RE 0.006908707280941271\n",
      "219 Train Loss 0.004040982 Test MSE 8.988803280546778e-05 Test RE 0.006849940748695743\n",
      "220 Train Loss 0.0039900253 Test MSE 9.054823378777235e-05 Test RE 0.006875050120976623\n",
      "221 Train Loss 0.0039802943 Test MSE 9.107693236523745e-05 Test RE 0.006895092139936505\n",
      "222 Train Loss 0.0039378637 Test MSE 9.17216075451912e-05 Test RE 0.006919452075948219\n",
      "223 Train Loss 0.0039179586 Test MSE 8.772962770832998e-05 Test RE 0.006767200126716055\n",
      "224 Train Loss 0.0038550552 Test MSE 8.266228934022573e-05 Test RE 0.00656885372867461\n",
      "225 Train Loss 0.0037724967 Test MSE 7.853042284689158e-05 Test RE 0.00640257751123888\n",
      "226 Train Loss 0.00373855 Test MSE 7.635478159559221e-05 Test RE 0.006313264669204068\n",
      "227 Train Loss 0.003739157 Test MSE 7.360045846152151e-05 Test RE 0.006198350584359635\n",
      "228 Train Loss 0.0037024766 Test MSE 7.277284014265544e-05 Test RE 0.006163402628415213\n",
      "229 Train Loss 0.0036480369 Test MSE 7.064015571167667e-05 Test RE 0.006072418585764819\n",
      "230 Train Loss 0.003597827 Test MSE 7.011813561256848e-05 Test RE 0.006049939851288696\n",
      "231 Train Loss 0.0035530413 Test MSE 6.986799119440452e-05 Test RE 0.006039138716892211\n",
      "232 Train Loss 0.0034859062 Test MSE 6.908062260383341e-05 Test RE 0.00600501364310452\n",
      "233 Train Loss 0.003469976 Test MSE 6.994153140691829e-05 Test RE 0.0060423161571832576\n",
      "234 Train Loss 0.0034159438 Test MSE 6.723099764170169e-05 Test RE 0.005924076454852938\n",
      "235 Train Loss 0.0033565813 Test MSE 6.673859155670297e-05 Test RE 0.005902342342350063\n",
      "236 Train Loss 0.0033323427 Test MSE 6.550835296207794e-05 Test RE 0.005847688323635561\n",
      "237 Train Loss 0.0032946912 Test MSE 6.448352041270818e-05 Test RE 0.005801766506754329\n",
      "238 Train Loss 0.0032573235 Test MSE 6.257945279335805e-05 Test RE 0.005715467473361356\n",
      "239 Train Loss 0.0032067245 Test MSE 6.354605904403079e-05 Test RE 0.005759439066010053\n",
      "240 Train Loss 0.0031663743 Test MSE 6.354690865930868e-05 Test RE 0.005759477567934012\n",
      "241 Train Loss 0.0031415673 Test MSE 6.43274340448309e-05 Test RE 0.005794740484284583\n",
      "242 Train Loss 0.0031023545 Test MSE 6.537331070440747e-05 Test RE 0.0058416578527725705\n",
      "243 Train Loss 0.0030690115 Test MSE 6.693520715519647e-05 Test RE 0.005911030262509293\n",
      "244 Train Loss 0.0030311395 Test MSE 6.606843331074989e-05 Test RE 0.005872633269190752\n",
      "245 Train Loss 0.0030058927 Test MSE 6.498846461453049e-05 Test RE 0.005824437846811688\n",
      "246 Train Loss 0.0029497757 Test MSE 6.246403328258578e-05 Test RE 0.005710194329522309\n",
      "247 Train Loss 0.002937938 Test MSE 6.165293903386693e-05 Test RE 0.005672999811712649\n",
      "248 Train Loss 0.0029218218 Test MSE 6.104470458632652e-05 Test RE 0.005644947082804765\n",
      "249 Train Loss 0.002891649 Test MSE 5.900840429128563e-05 Test RE 0.005549997815523384\n",
      "250 Train Loss 0.0028590162 Test MSE 5.813857930046497e-05 Test RE 0.005508940533299065\n",
      "251 Train Loss 0.0028210706 Test MSE 5.85893091975779e-05 Test RE 0.005530253835344112\n",
      "252 Train Loss 0.0027832924 Test MSE 5.853900089317338e-05 Test RE 0.005527879021180403\n",
      "253 Train Loss 0.0028259354 Test MSE 5.7202341859331146e-05 Test RE 0.005464403759572455\n",
      "254 Train Loss 0.0027729485 Test MSE 5.710122069770829e-05 Test RE 0.005459571691006408\n",
      "255 Train Loss 0.0027322501 Test MSE 5.639364840743724e-05 Test RE 0.005425639985288792\n",
      "256 Train Loss 0.0026798623 Test MSE 5.575087635450094e-05 Test RE 0.005394630781805081\n",
      "257 Train Loss 0.002659625 Test MSE 5.6059368315413934e-05 Test RE 0.005409535519744481\n",
      "258 Train Loss 0.002620604 Test MSE 5.572404079493543e-05 Test RE 0.005393332278801441\n",
      "259 Train Loss 0.0025883175 Test MSE 5.4744957287319065e-05 Test RE 0.005345741296270124\n",
      "260 Train Loss 0.002602722 Test MSE 5.509661875966902e-05 Test RE 0.005362883349831182\n",
      "261 Train Loss 0.0025597946 Test MSE 5.5247459080046345e-05 Test RE 0.005370219427351581\n",
      "262 Train Loss 0.0025459444 Test MSE 5.5011448550852466e-05 Test RE 0.005358736683851036\n",
      "263 Train Loss 0.0025251512 Test MSE 5.483813399247333e-05 Test RE 0.005350288626496577\n",
      "264 Train Loss 0.0024947433 Test MSE 5.424217383135769e-05 Test RE 0.00532113674760944\n",
      "265 Train Loss 0.002475617 Test MSE 5.371842522044206e-05 Test RE 0.00529538466255914\n",
      "266 Train Loss 0.0024835581 Test MSE 5.329169399729336e-05 Test RE 0.005274309849112229\n",
      "267 Train Loss 0.0024914853 Test MSE 5.162231975815903e-05 Test RE 0.005191043105379149\n",
      "268 Train Loss 0.0024761402 Test MSE 4.9977874498656065e-05 Test RE 0.005107692788746397\n",
      "269 Train Loss 0.0024567114 Test MSE 5.0070236655385636e-05 Test RE 0.00511241027391978\n",
      "270 Train Loss 0.0024216152 Test MSE 5.0378172836299185e-05 Test RE 0.005128107054095456\n",
      "271 Train Loss 0.0023822894 Test MSE 4.980765372066822e-05 Test RE 0.0050989871663101064\n",
      "272 Train Loss 0.0023632178 Test MSE 4.997984951061144e-05 Test RE 0.005107793709951669\n",
      "273 Train Loss 0.002338715 Test MSE 4.902261442337886e-05 Test RE 0.005058643931805734\n",
      "274 Train Loss 0.0023304254 Test MSE 4.82661810948811e-05 Test RE 0.0050194640245856655\n",
      "275 Train Loss 0.0022968375 Test MSE 4.763761236864051e-05 Test RE 0.004986672765886314\n",
      "276 Train Loss 0.0022661856 Test MSE 4.748779325011837e-05 Test RE 0.004978825109293167\n",
      "277 Train Loss 0.0022504253 Test MSE 4.6746296698185513e-05 Test RE 0.004939801327388123\n",
      "278 Train Loss 0.0022341467 Test MSE 4.6907543080082305e-05 Test RE 0.004948313652935791\n",
      "279 Train Loss 0.0022273327 Test MSE 4.722817972315296e-05 Test RE 0.004965196956572165\n",
      "280 Train Loss 0.0022008878 Test MSE 4.7227937199397936e-05 Test RE 0.004965184208041908\n",
      "281 Train Loss 0.0022121277 Test MSE 4.682134239404036e-05 Test RE 0.004943764873062245\n",
      "282 Train Loss 0.002189348 Test MSE 4.718606991900058e-05 Test RE 0.004962982917206018\n",
      "283 Train Loss 0.002172788 Test MSE 4.7629151000257505e-05 Test RE 0.00498622988108407\n",
      "284 Train Loss 0.0021967168 Test MSE 4.693309493002399e-05 Test RE 0.004949661211832032\n",
      "285 Train Loss 0.0021665676 Test MSE 4.571156333247947e-05 Test RE 0.004884823925339153\n",
      "286 Train Loss 0.0021385194 Test MSE 4.458635543709882e-05 Test RE 0.004824328405960574\n",
      "287 Train Loss 0.002154583 Test MSE 4.469112042488817e-05 Test RE 0.00482999296580089\n",
      "288 Train Loss 0.0021373723 Test MSE 4.446311053087544e-05 Test RE 0.004817656125360663\n",
      "289 Train Loss 0.0020996635 Test MSE 4.401483596095123e-05 Test RE 0.004793308934629197\n",
      "290 Train Loss 0.0020834482 Test MSE 4.286103124456719e-05 Test RE 0.004730065828953398\n",
      "291 Train Loss 0.002050842 Test MSE 4.2646238019026477e-05 Test RE 0.004718198846973679\n",
      "292 Train Loss 0.0020658115 Test MSE 4.352101569268907e-05 Test RE 0.004766344051824414\n",
      "293 Train Loss 0.0020929575 Test MSE 4.374457522021743e-05 Test RE 0.004778570291397574\n",
      "294 Train Loss 0.0020581456 Test MSE 4.3440362658761106e-05 Test RE 0.004761925515524065\n",
      "295 Train Loss 0.0020388337 Test MSE 4.30554208969225e-05 Test RE 0.004740779939736105\n",
      "296 Train Loss 0.0020077992 Test MSE 4.2217014262373325e-05 Test RE 0.0046943950529671945\n",
      "297 Train Loss 0.001979479 Test MSE 4.1574634231670016e-05 Test RE 0.004658542859258912\n",
      "298 Train Loss 0.0019536952 Test MSE 4.105680453543179e-05 Test RE 0.004629439889621552\n",
      "299 Train Loss 0.0019436071 Test MSE 4.145725353055558e-05 Test RE 0.0046519618086461375\n",
      "Training time: 174.14\n",
      "KG_tanhALR_high\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 51673.98 Test MSE 10.080998007338028 Test RE 2.2939695105726314\n",
      "1 Train Loss 30290.7 Test MSE 12.42216741821436 Test RE 2.546446556986779\n",
      "2 Train Loss 18548.8 Test MSE 12.937060590964174 Test RE 2.598685259481637\n",
      "3 Train Loss 6698.357 Test MSE 5.5910070626051045 Test RE 1.7083659128265842\n",
      "4 Train Loss 2031.3005 Test MSE 2.7365957547665736 Test RE 1.1952016976816684\n",
      "5 Train Loss 606.0195 Test MSE 1.4777881391467964 Test RE 0.8782981443205828\n",
      "6 Train Loss 195.8942 Test MSE 0.8558195448200113 Test RE 0.6683854344770357\n",
      "7 Train Loss 72.25922 Test MSE 0.4619218560349865 Test RE 0.4910436877671621\n",
      "8 Train Loss 41.856045 Test MSE 0.3382013985265105 Test RE 0.4201685834010575\n",
      "9 Train Loss 25.436987 Test MSE 0.28510540883168806 Test RE 0.3857790196899225\n",
      "10 Train Loss 17.271643 Test MSE 0.20027785603607517 Test RE 0.32333472121821655\n",
      "11 Train Loss 12.971816 Test MSE 0.1502439921008125 Test RE 0.2800492630787797\n",
      "12 Train Loss 9.869209 Test MSE 0.11217208032118346 Test RE 0.24197932673126446\n",
      "13 Train Loss 7.326176 Test MSE 0.07299501395852231 Test RE 0.19520119627156626\n",
      "14 Train Loss 5.3444533 Test MSE 0.06797007896626793 Test RE 0.18836263802965073\n",
      "15 Train Loss 4.452952 Test MSE 0.06500525975397885 Test RE 0.18420869501577267\n",
      "16 Train Loss 3.8017702 Test MSE 0.06040041680493333 Test RE 0.1775643781200698\n",
      "17 Train Loss 3.209859 Test MSE 0.055895387420437675 Test RE 0.17081415709967782\n",
      "18 Train Loss 2.7159822 Test MSE 0.05327630457120337 Test RE 0.16676423801549026\n",
      "19 Train Loss 2.2190318 Test MSE 0.044656088090297495 Test RE 0.15267791300107136\n",
      "20 Train Loss 1.8186398 Test MSE 0.04082467596420195 Test RE 0.14598130780500274\n",
      "21 Train Loss 1.5586616 Test MSE 0.03965625018625559 Test RE 0.14387710803244164\n",
      "22 Train Loss 1.3813256 Test MSE 0.03865969904155258 Test RE 0.14205780872604407\n",
      "23 Train Loss 1.2650049 Test MSE 0.035169362182704285 Test RE 0.1354933944235348\n",
      "24 Train Loss 1.1713303 Test MSE 0.031687272410895057 Test RE 0.12861105643221635\n",
      "25 Train Loss 1.084784 Test MSE 0.03082219334813556 Test RE 0.12684333354695723\n",
      "26 Train Loss 1.0065142 Test MSE 0.028604129796323766 Test RE 0.12219410279002291\n",
      "27 Train Loss 0.9106256 Test MSE 0.0248884519073395 Test RE 0.11398161830979565\n",
      "28 Train Loss 0.84530973 Test MSE 0.022566404534291696 Test RE 0.10853431297456675\n",
      "29 Train Loss 0.7980552 Test MSE 0.022417249470156712 Test RE 0.10817503374228957\n",
      "30 Train Loss 0.74804765 Test MSE 0.021360611878690636 Test RE 0.10559484605731778\n",
      "31 Train Loss 0.6958988 Test MSE 0.019430631551161807 Test RE 0.10071156279890581\n",
      "32 Train Loss 0.6397349 Test MSE 0.017915650864350343 Test RE 0.09670572209174258\n",
      "33 Train Loss 0.5888182 Test MSE 0.015151031208020947 Test RE 0.08893177760731955\n",
      "34 Train Loss 0.55361265 Test MSE 0.014902140880735198 Test RE 0.08819829898233278\n",
      "35 Train Loss 0.51018953 Test MSE 0.013881436633638026 Test RE 0.085124208024993\n",
      "36 Train Loss 0.47927493 Test MSE 0.012019230053974556 Test RE 0.07920893988488448\n",
      "37 Train Loss 0.45405483 Test MSE 0.011150891036401581 Test RE 0.07629404881815863\n",
      "38 Train Loss 0.4255901 Test MSE 0.010189503628658515 Test RE 0.07293103737704337\n",
      "39 Train Loss 0.40634266 Test MSE 0.009422583467755036 Test RE 0.07013275080819903\n",
      "40 Train Loss 0.38746345 Test MSE 0.007503767203820707 Test RE 0.06258576324879683\n",
      "41 Train Loss 0.36340466 Test MSE 0.007448085675418564 Test RE 0.06235312277583086\n",
      "42 Train Loss 0.3472597 Test MSE 0.007463768668175731 Test RE 0.062418734893416664\n",
      "43 Train Loss 0.31906977 Test MSE 0.006830585641228088 Test RE 0.05971244404402676\n",
      "44 Train Loss 0.30450085 Test MSE 0.00581850722565977 Test RE 0.05511142820905971\n",
      "45 Train Loss 0.28861427 Test MSE 0.005330082431073953 Test RE 0.05274761645969183\n",
      "46 Train Loss 0.26349455 Test MSE 0.005182932074900777 Test RE 0.0520144050723733\n",
      "47 Train Loss 0.25251186 Test MSE 0.0042715231263935295 Test RE 0.047220138645655683\n",
      "48 Train Loss 0.2345406 Test MSE 0.0035517807561996103 Test RE 0.043058505482946034\n",
      "49 Train Loss 0.22081546 Test MSE 0.002972177919035326 Test RE 0.039388847940245435\n",
      "50 Train Loss 0.194703 Test MSE 0.0031437132606138177 Test RE 0.04050954268128878\n",
      "51 Train Loss 0.18700367 Test MSE 0.002980969489000213 Test RE 0.03944706015406661\n",
      "52 Train Loss 0.17915262 Test MSE 0.0025716560310588155 Test RE 0.03663889073645692\n",
      "53 Train Loss 0.17062908 Test MSE 0.002310228432608794 Test RE 0.03472668591992576\n",
      "54 Train Loss 0.16267066 Test MSE 0.001979625109264276 Test RE 0.032146030597442976\n",
      "55 Train Loss 0.15308367 Test MSE 0.0020717869358895555 Test RE 0.0328858008147089\n",
      "56 Train Loss 0.14502952 Test MSE 0.0019147755577475039 Test RE 0.03161511853190238\n",
      "57 Train Loss 0.13952355 Test MSE 0.001657537732204932 Test RE 0.029414914382433696\n",
      "58 Train Loss 0.13506247 Test MSE 0.001534045352892417 Test RE 0.0282979501107123\n",
      "59 Train Loss 0.1313524 Test MSE 0.0015472481630348827 Test RE 0.028419462824121368\n",
      "60 Train Loss 0.12585545 Test MSE 0.0014802833514293446 Test RE 0.02779766419826908\n",
      "61 Train Loss 0.1216816 Test MSE 0.0015319239905071385 Test RE 0.02827837735999054\n",
      "62 Train Loss 0.11809113 Test MSE 0.0015599788236324475 Test RE 0.028536140089062693\n",
      "63 Train Loss 0.113282375 Test MSE 0.001369816699969073 Test RE 0.026740351096119216\n",
      "64 Train Loss 0.10872663 Test MSE 0.0013454938487980628 Test RE 0.02650188317584022\n",
      "65 Train Loss 0.104943104 Test MSE 0.0012902049627628875 Test RE 0.025951665269017342\n",
      "66 Train Loss 0.10151191 Test MSE 0.0011733001546398714 Test RE 0.024748019004399983\n",
      "67 Train Loss 0.09890873 Test MSE 0.0011212780042819585 Test RE 0.024193156138587385\n",
      "68 Train Loss 0.09685595 Test MSE 0.0011222526712688593 Test RE 0.024203668762783234\n",
      "69 Train Loss 0.09414426 Test MSE 0.0012240989441587489 Test RE 0.025278083177746304\n",
      "70 Train Loss 0.09132569 Test MSE 0.001181846550336886 Test RE 0.024837988566800154\n",
      "71 Train Loss 0.08853831 Test MSE 0.0011873749072278288 Test RE 0.02489601346908393\n",
      "72 Train Loss 0.08657555 Test MSE 0.0011750450268832762 Test RE 0.024766414164679007\n",
      "73 Train Loss 0.08451466 Test MSE 0.0011868499380919112 Test RE 0.024890509275115873\n",
      "74 Train Loss 0.08135394 Test MSE 0.0012056022079181487 Test RE 0.025086374090644882\n",
      "75 Train Loss 0.07930708 Test MSE 0.0011423796442740297 Test RE 0.024419743891895915\n",
      "76 Train Loss 0.07601176 Test MSE 0.0011965791019739505 Test RE 0.024992320623497898\n",
      "77 Train Loss 0.07442548 Test MSE 0.0011138443752659454 Test RE 0.024112827259036098\n",
      "78 Train Loss 0.07304703 Test MSE 0.001008148789205145 Test RE 0.022940252474621392\n",
      "79 Train Loss 0.070421934 Test MSE 0.0009502477057765665 Test RE 0.022271747371998444\n",
      "80 Train Loss 0.068825394 Test MSE 0.0009136621325307584 Test RE 0.021838795909245076\n",
      "81 Train Loss 0.06646605 Test MSE 0.0008445414541657465 Test RE 0.02099647372165702\n",
      "82 Train Loss 0.064773135 Test MSE 0.0007976514010872468 Test RE 0.02040527457652857\n",
      "83 Train Loss 0.0632684 Test MSE 0.0008150473266916343 Test RE 0.02062658308740839\n",
      "84 Train Loss 0.06161105 Test MSE 0.0007609692078688875 Test RE 0.019930556202377662\n",
      "85 Train Loss 0.06035276 Test MSE 0.0007451482289019936 Test RE 0.019722284242207257\n",
      "86 Train Loss 0.058877155 Test MSE 0.0007266010686844618 Test RE 0.01947528819333285\n",
      "87 Train Loss 0.057724487 Test MSE 0.0007128713298360015 Test RE 0.019290409687028696\n",
      "88 Train Loss 0.056499824 Test MSE 0.000679104264973227 Test RE 0.018827996368976516\n",
      "89 Train Loss 0.055091966 Test MSE 0.0006446540916971209 Test RE 0.01834421993512513\n",
      "90 Train Loss 0.053798154 Test MSE 0.0006243303438770813 Test RE 0.018052738798082522\n",
      "91 Train Loss 0.052609026 Test MSE 0.0006004477815042288 Test RE 0.017704085535506033\n",
      "92 Train Loss 0.05099149 Test MSE 0.000579132509368682 Test RE 0.017387007808956932\n",
      "93 Train Loss 0.049941808 Test MSE 0.000530901602398318 Test RE 0.01664726507870431\n",
      "94 Train Loss 0.049271964 Test MSE 0.0005491648085273986 Test RE 0.016931179984178053\n",
      "95 Train Loss 0.047470212 Test MSE 0.0005348173986509956 Test RE 0.016708545302673402\n",
      "96 Train Loss 0.04610019 Test MSE 0.0005115757247818843 Test RE 0.016341459464523464\n",
      "97 Train Loss 0.044537798 Test MSE 0.00047899564858389055 Test RE 0.015812540867139627\n",
      "98 Train Loss 0.043340646 Test MSE 0.0004475968782439703 Test RE 0.015285491269603603\n",
      "99 Train Loss 0.042119626 Test MSE 0.0004347958124772138 Test RE 0.015065326673456827\n",
      "100 Train Loss 0.040504865 Test MSE 0.0004076006409208204 Test RE 0.014586574215378997\n",
      "101 Train Loss 0.039241407 Test MSE 0.00038941558068753516 Test RE 0.01425747237626166\n",
      "102 Train Loss 0.037950497 Test MSE 0.0003682971663035814 Test RE 0.0138654850078302\n",
      "103 Train Loss 0.03630367 Test MSE 0.00034001973391788035 Test RE 0.013322567781220028\n",
      "104 Train Loss 0.035034165 Test MSE 0.00027730337001814824 Test RE 0.01203132478336418\n",
      "105 Train Loss 0.03415245 Test MSE 0.00022857929523273352 Test RE 0.0109233115745105\n",
      "106 Train Loss 0.033004355 Test MSE 0.00020788272100767785 Test RE 0.01041705778487703\n",
      "107 Train Loss 0.032499246 Test MSE 0.0001909167275395943 Test RE 0.009982926364384963\n",
      "108 Train Loss 0.03204574 Test MSE 0.00017235467377517663 Test RE 0.009485220019895184\n",
      "109 Train Loss 0.031562645 Test MSE 0.00015334944478723729 Test RE 0.008946990595835437\n",
      "110 Train Loss 0.030981317 Test MSE 0.00015527249351306348 Test RE 0.009002914808434478\n",
      "111 Train Loss 0.030303933 Test MSE 0.00014709680322694773 Test RE 0.008762690935287984\n",
      "112 Train Loss 0.029769327 Test MSE 0.0001474922334013753 Test RE 0.008774461098717838\n",
      "113 Train Loss 0.029157728 Test MSE 0.00015262875906782712 Test RE 0.008925942061932096\n",
      "114 Train Loss 0.028676683 Test MSE 0.00015225216865334302 Test RE 0.008914923495490473\n",
      "115 Train Loss 0.02834157 Test MSE 0.00015896953288736487 Test RE 0.009109464043476007\n",
      "116 Train Loss 0.027844006 Test MSE 0.00014128119248715395 Test RE 0.00858772349800065\n",
      "117 Train Loss 0.027323417 Test MSE 0.00014614299717586327 Test RE 0.008734235183161482\n",
      "118 Train Loss 0.027028084 Test MSE 0.00015242217355553066 Test RE 0.008919899312490731\n",
      "119 Train Loss 0.02660628 Test MSE 0.0001571476166577795 Test RE 0.009057112793186349\n",
      "120 Train Loss 0.026157329 Test MSE 0.00015688426949281496 Test RE 0.009049520679708762\n",
      "121 Train Loss 0.025777468 Test MSE 0.00015824852862898381 Test RE 0.009088782638646466\n",
      "122 Train Loss 0.025345847 Test MSE 0.00017395279566427926 Test RE 0.009529093391006408\n",
      "123 Train Loss 0.024970379 Test MSE 0.0001838287700189693 Test RE 0.009795861080836512\n",
      "124 Train Loss 0.024413118 Test MSE 0.00022885933116722362 Test RE 0.010930000683103378\n",
      "125 Train Loss 0.02385788 Test MSE 0.000272163593185797 Test RE 0.011919303872678552\n",
      "126 Train Loss 0.023477985 Test MSE 0.0002572373620584436 Test RE 0.011587850953516854\n",
      "127 Train Loss 0.022994569 Test MSE 0.0002670918774656085 Test RE 0.011807724657129235\n",
      "128 Train Loss 0.022518335 Test MSE 0.00026168928262155263 Test RE 0.011687694338397475\n",
      "129 Train Loss 0.02214119 Test MSE 0.00024947469899401693 Test RE 0.011411668060850302\n",
      "130 Train Loss 0.021804253 Test MSE 0.00023994410235740114 Test RE 0.011191567457625201\n",
      "131 Train Loss 0.02125036 Test MSE 0.00020107789633276406 Test RE 0.01024514344374449\n",
      "132 Train Loss 0.020976203 Test MSE 0.0002266523750931468 Test RE 0.010877172451702272\n",
      "133 Train Loss 0.020595258 Test MSE 0.0002296489279055258 Test RE 0.010948839464395337\n",
      "134 Train Loss 0.020352652 Test MSE 0.00021658092027383903 Test RE 0.01063275909569726\n",
      "135 Train Loss 0.020034144 Test MSE 0.0002066891833395057 Test RE 0.010387110495048004\n",
      "136 Train Loss 0.019664995 Test MSE 0.00017512605573876395 Test RE 0.009561174842939698\n",
      "137 Train Loss 0.019196754 Test MSE 0.0001752781781834559 Test RE 0.009565326576865556\n",
      "138 Train Loss 0.018775461 Test MSE 0.00017844765914097458 Test RE 0.00965142198574183\n",
      "139 Train Loss 0.018476268 Test MSE 0.00016208754240802818 Test RE 0.00919836620366534\n",
      "140 Train Loss 0.01817352 Test MSE 0.00016489582287759272 Test RE 0.009277708092183541\n",
      "141 Train Loss 0.017896231 Test MSE 0.000144869545848072 Test RE 0.008696098017339908\n",
      "142 Train Loss 0.01762537 Test MSE 0.00012898640757437224 Test RE 0.00820555291676699\n",
      "143 Train Loss 0.017301727 Test MSE 0.00011448492854085427 Test RE 0.00773054362985438\n",
      "144 Train Loss 0.017137952 Test MSE 0.00011895280574378003 Test RE 0.00787994564892058\n",
      "145 Train Loss 0.016874766 Test MSE 0.00012662065145616614 Test RE 0.008129955130228017\n",
      "146 Train Loss 0.016654195 Test MSE 0.00013020728927267853 Test RE 0.00824429504274517\n",
      "147 Train Loss 0.016369902 Test MSE 0.00011957619232742243 Test RE 0.007900566572328393\n",
      "148 Train Loss 0.016193742 Test MSE 0.00011035574889269651 Test RE 0.0075898528858603775\n",
      "149 Train Loss 0.015954066 Test MSE 0.0001095491458102456 Test RE 0.007562064454058159\n",
      "150 Train Loss 0.015684363 Test MSE 9.575642729400412e-05 Test RE 0.007070007001842785\n",
      "151 Train Loss 0.015503976 Test MSE 9.189340766644872e-05 Test RE 0.006925929320526017\n",
      "152 Train Loss 0.01534964 Test MSE 8.523734292064277e-05 Test RE 0.006670383883180425\n",
      "153 Train Loss 0.015087595 Test MSE 8.603569453535127e-05 Test RE 0.006701549215823134\n",
      "154 Train Loss 0.014996689 Test MSE 9.277691898888234e-05 Test RE 0.006959144429560917\n",
      "155 Train Loss 0.014725004 Test MSE 9.197495166972669e-05 Test RE 0.006929001590793946\n",
      "156 Train Loss 0.014565779 Test MSE 8.99358229352763e-05 Test RE 0.0068517614363205435\n",
      "157 Train Loss 0.014374942 Test MSE 8.658407189772234e-05 Test RE 0.006722872577974304\n",
      "158 Train Loss 0.014218534 Test MSE 9.009766672126163e-05 Test RE 0.006857923700351802\n",
      "159 Train Loss 0.014103469 Test MSE 8.698516163786421e-05 Test RE 0.006738426014064756\n",
      "160 Train Loss 0.013884815 Test MSE 8.673773625602298e-05 Test RE 0.006728835614408207\n",
      "161 Train Loss 0.013672958 Test MSE 8.05346407337119e-05 Test RE 0.006483764611508519\n",
      "162 Train Loss 0.013476741 Test MSE 7.977435125205062e-05 Test RE 0.00645308695780681\n",
      "163 Train Loss 0.0133511005 Test MSE 7.641207247878445e-05 Test RE 0.006315632724484291\n",
      "164 Train Loss 0.013218346 Test MSE 7.502843955920352e-05 Test RE 0.0062581912919328925\n",
      "165 Train Loss 0.012960395 Test MSE 6.472397338883947e-05 Test RE 0.0058125735620231\n",
      "166 Train Loss 0.012716863 Test MSE 6.0880851811276645e-05 Test RE 0.0056373660669461955\n",
      "167 Train Loss 0.012427854 Test MSE 5.57864858851847e-05 Test RE 0.005396353352084217\n",
      "168 Train Loss 0.012283388 Test MSE 5.74007198617291e-05 Test RE 0.005473870848231582\n",
      "169 Train Loss 0.012115454 Test MSE 5.844387121684565e-05 Test RE 0.00552338561380128\n",
      "170 Train Loss 0.011945855 Test MSE 5.897545353926987e-05 Test RE 0.0055484480181600794\n",
      "171 Train Loss 0.0118085835 Test MSE 5.7032902047410704e-05 Test RE 0.005456304666262148\n",
      "172 Train Loss 0.01168129 Test MSE 5.3894385431449685e-05 Test RE 0.005304050359786213\n",
      "173 Train Loss 0.011583658 Test MSE 5.190600765876682e-05 Test RE 0.005205287122965782\n",
      "174 Train Loss 0.011431364 Test MSE 5.1147967176711844e-05 Test RE 0.005167138062917917\n",
      "175 Train Loss 0.011382049 Test MSE 4.891874982983856e-05 Test RE 0.0050532821962382644\n",
      "176 Train Loss 0.011244138 Test MSE 4.8460714155193065e-05 Test RE 0.00502956913105391\n",
      "177 Train Loss 0.011084633 Test MSE 4.7665635680457564e-05 Test RE 0.004988139280827126\n",
      "178 Train Loss 0.010942662 Test MSE 4.653884216118963e-05 Test RE 0.0049288280122022805\n",
      "179 Train Loss 0.010805965 Test MSE 4.590354055099475e-05 Test RE 0.004895070702068171\n",
      "180 Train Loss 0.01071761 Test MSE 4.755107023778952e-05 Test RE 0.004982141121207031\n",
      "181 Train Loss 0.010582048 Test MSE 4.79989056756996e-05 Test RE 0.005005547015409957\n",
      "182 Train Loss 0.010481923 Test MSE 4.8950741313820975e-05 Test RE 0.005054934278262469\n",
      "183 Train Loss 0.010423815 Test MSE 5.016937582171372e-05 Test RE 0.005117469062216984\n",
      "184 Train Loss 0.010302728 Test MSE 5.153491743581596e-05 Test RE 0.0051866467373672285\n",
      "185 Train Loss 0.01023163 Test MSE 5.368708468421698e-05 Test RE 0.005293839713992126\n",
      "186 Train Loss 0.010152532 Test MSE 5.349339824009289e-05 Test RE 0.005284281815197073\n",
      "187 Train Loss 0.010066472 Test MSE 5.6307550516140684e-05 Test RE 0.005421496658789859\n",
      "188 Train Loss 0.009979053 Test MSE 5.649729297360838e-05 Test RE 0.005430623524911612\n",
      "189 Train Loss 0.009915466 Test MSE 5.5434067635751876e-05 Test RE 0.005379281238653251\n",
      "190 Train Loss 0.009810997 Test MSE 5.590962632999028e-05 Test RE 0.005402305896361887\n",
      "191 Train Loss 0.009686934 Test MSE 5.756716635073717e-05 Test RE 0.005481801472200051\n",
      "192 Train Loss 0.00958872 Test MSE 6.088878146931425e-05 Test RE 0.00563773318508187\n",
      "193 Train Loss 0.009495985 Test MSE 6.007604667600704e-05 Test RE 0.005599980953736799\n",
      "194 Train Loss 0.009386304 Test MSE 5.78101034890147e-05 Test RE 0.005493356071840167\n",
      "195 Train Loss 0.009331461 Test MSE 5.47062775432271e-05 Test RE 0.00534385246073292\n",
      "196 Train Loss 0.00924188 Test MSE 5.4045210217619084e-05 Test RE 0.005311466933369367\n",
      "197 Train Loss 0.009131366 Test MSE 5.649672251098529e-05 Test RE 0.005430596107885075\n",
      "198 Train Loss 0.009065612 Test MSE 5.8211739561591664e-05 Test RE 0.005512405606059975\n",
      "199 Train Loss 0.00893018 Test MSE 6.073518235773224e-05 Test RE 0.0056306177724126496\n",
      "200 Train Loss 0.008809747 Test MSE 6.36019913348031e-05 Test RE 0.005761973194570899\n",
      "201 Train Loss 0.008767791 Test MSE 6.433356593387974e-05 Test RE 0.005795016663954365\n",
      "202 Train Loss 0.008647371 Test MSE 6.160462601646714e-05 Test RE 0.0056707766131259395\n",
      "203 Train Loss 0.008564204 Test MSE 6.091814262240156e-05 Test RE 0.005639092305701868\n",
      "204 Train Loss 0.008472477 Test MSE 5.789976744099868e-05 Test RE 0.005497614541758832\n",
      "205 Train Loss 0.008349015 Test MSE 5.760074835508185e-05 Test RE 0.005483400152949739\n",
      "206 Train Loss 0.008226508 Test MSE 5.6176655199515565e-05 Test RE 0.005415191452682483\n",
      "207 Train Loss 0.008105895 Test MSE 5.588686034868314e-05 Test RE 0.005401205895112505\n",
      "208 Train Loss 0.0080215875 Test MSE 5.550301268714058e-05 Test RE 0.005382625387764099\n",
      "209 Train Loss 0.007939018 Test MSE 5.505471409306196e-05 Test RE 0.005360843546022292\n",
      "210 Train Loss 0.007906578 Test MSE 5.557462508983285e-05 Test RE 0.0053860967171848\n",
      "211 Train Loss 0.007838296 Test MSE 5.6715391383193624e-05 Test RE 0.005441095438145932\n",
      "212 Train Loss 0.0077662338 Test MSE 5.602065279499137e-05 Test RE 0.005407667240087202\n",
      "213 Train Loss 0.007672339 Test MSE 5.5484095411857925e-05 Test RE 0.005381708020588365\n",
      "214 Train Loss 0.0075946767 Test MSE 5.7618364397669485e-05 Test RE 0.005484238583256897\n",
      "215 Train Loss 0.00757496 Test MSE 5.904702179512436e-05 Test RE 0.005551813590834536\n",
      "216 Train Loss 0.007489703 Test MSE 5.99089025831975e-05 Test RE 0.005592185370182808\n",
      "217 Train Loss 0.0074679917 Test MSE 5.979039516696701e-05 Test RE 0.005586651605841573\n",
      "218 Train Loss 0.007405854 Test MSE 6.011036165481122e-05 Test RE 0.005601580058585189\n",
      "219 Train Loss 0.0073532993 Test MSE 5.959370787979784e-05 Test RE 0.005577455074265816\n",
      "220 Train Loss 0.0072673196 Test MSE 6.060087806149676e-05 Test RE 0.00562438880719171\n",
      "221 Train Loss 0.0072279987 Test MSE 6.036160144441889e-05 Test RE 0.005613274151564686\n",
      "222 Train Loss 0.007148172 Test MSE 6.16420177579037e-05 Test RE 0.005672497328445389\n",
      "223 Train Loss 0.0070223315 Test MSE 6.140776408254255e-05 Test RE 0.005661708679410169\n",
      "224 Train Loss 0.006955396 Test MSE 6.203881014267192e-05 Test RE 0.005690725099897221\n",
      "225 Train Loss 0.006897989 Test MSE 6.202271946166056e-05 Test RE 0.005689987065268414\n",
      "226 Train Loss 0.006724923 Test MSE 6.016597057649511e-05 Test RE 0.005604170508956682\n",
      "227 Train Loss 0.0066090757 Test MSE 5.638738667373307e-05 Test RE 0.005425338755834256\n",
      "228 Train Loss 0.006517016 Test MSE 5.5037000873651264e-05 Test RE 0.005359981081847837\n",
      "229 Train Loss 0.0064357608 Test MSE 5.4217456794714826e-05 Test RE 0.0053199242434900165\n",
      "230 Train Loss 0.0063285073 Test MSE 5.521437144389892e-05 Test RE 0.005368611077559258\n",
      "231 Train Loss 0.006276411 Test MSE 5.583370004171204e-05 Test RE 0.005398636435363919\n",
      "232 Train Loss 0.006224778 Test MSE 5.6670172166355883e-05 Test RE 0.00543892591122929\n",
      "233 Train Loss 0.0061857584 Test MSE 5.4800381375153575e-05 Test RE 0.005348446640270525\n",
      "234 Train Loss 0.0060972665 Test MSE 5.341721092840279e-05 Test RE 0.005280517437825717\n",
      "235 Train Loss 0.0060236887 Test MSE 5.117775703405007e-05 Test RE 0.005168642579205033\n",
      "236 Train Loss 0.0059455847 Test MSE 4.9528152222626774e-05 Test RE 0.005084660256105572\n",
      "237 Train Loss 0.005883548 Test MSE 4.9677574274618214e-05 Test RE 0.005092324464897908\n",
      "238 Train Loss 0.005798368 Test MSE 4.81499865602003e-05 Test RE 0.00501341853153329\n",
      "239 Train Loss 0.0057487474 Test MSE 4.686673873546485e-05 Test RE 0.004946160943458659\n",
      "240 Train Loss 0.00569343 Test MSE 4.616757200187065e-05 Test RE 0.004909128435124093\n",
      "241 Train Loss 0.005593564 Test MSE 4.0902668614778454e-05 Test RE 0.0046207417704642135\n",
      "242 Train Loss 0.0055065067 Test MSE 3.9587928827627616e-05 Test RE 0.00454587267352066\n",
      "243 Train Loss 0.0054542604 Test MSE 3.7492029444611835e-05 Test RE 0.004423900511425073\n",
      "244 Train Loss 0.005392808 Test MSE 3.5583654431786196e-05 Test RE 0.004309840032909859\n",
      "245 Train Loss 0.005319192 Test MSE 3.409137138776164e-05 Test RE 0.00421850057684219\n",
      "246 Train Loss 0.0052541527 Test MSE 3.503986781142838e-05 Test RE 0.004276781929900779\n",
      "247 Train Loss 0.0051834923 Test MSE 3.601453341517544e-05 Test RE 0.004335855231252309\n",
      "248 Train Loss 0.0051133647 Test MSE 3.452495109562161e-05 Test RE 0.004245241615757269\n",
      "249 Train Loss 0.005036814 Test MSE 3.2443283872512805e-05 Test RE 0.004115269487670325\n",
      "250 Train Loss 0.0049920934 Test MSE 3.1519771198098316e-05 Test RE 0.0040562751326447604\n",
      "251 Train Loss 0.004929804 Test MSE 2.9758233894793682e-05 Test RE 0.0039412996373177555\n",
      "252 Train Loss 0.0048884894 Test MSE 2.9218926920073307e-05 Test RE 0.003905422356100786\n",
      "253 Train Loss 0.0048134783 Test MSE 2.9304292523632493e-05 Test RE 0.003911123208609893\n",
      "254 Train Loss 0.004765873 Test MSE 2.793034967566177e-05 Test RE 0.003818335307529078\n",
      "255 Train Loss 0.0047361758 Test MSE 2.802416639826115e-05 Test RE 0.0038247427352650232\n",
      "256 Train Loss 0.0046946616 Test MSE 2.799861860212822e-05 Test RE 0.003822998954089976\n",
      "257 Train Loss 0.0046335896 Test MSE 2.8036833095990953e-05 Test RE 0.0038256070140855344\n",
      "258 Train Loss 0.004571088 Test MSE 2.5355121897639478e-05 Test RE 0.003638050542397744\n",
      "259 Train Loss 0.0045326543 Test MSE 2.516487087129528e-05 Test RE 0.0036243758672726786\n",
      "260 Train Loss 0.004471964 Test MSE 2.6514435004224306e-05 Test RE 0.0037202923182957045\n",
      "261 Train Loss 0.0043956502 Test MSE 2.591137540242663e-05 Test RE 0.003677740735125542\n",
      "262 Train Loss 0.00433117 Test MSE 2.514973955206535e-05 Test RE 0.0036232860576943665\n",
      "263 Train Loss 0.0043360153 Test MSE 2.5032177792980073e-05 Test RE 0.0036148076630575328\n",
      "264 Train Loss 0.004284231 Test MSE 2.497948991865532e-05 Test RE 0.0036110014249916673\n",
      "265 Train Loss 0.0042448323 Test MSE 2.6096580465480257e-05 Test RE 0.0036908609071800583\n",
      "266 Train Loss 0.00420712 Test MSE 2.6333562830182895e-05 Test RE 0.0037075813392021717\n",
      "267 Train Loss 0.0042021554 Test MSE 2.680654787651255e-05 Test RE 0.0037407296470156957\n",
      "268 Train Loss 0.0041470528 Test MSE 2.6083415249577976e-05 Test RE 0.003689929806060901\n",
      "269 Train Loss 0.0041163163 Test MSE 2.6675334843646186e-05 Test RE 0.0037315633307827456\n",
      "270 Train Loss 0.004090941 Test MSE 2.6237127333401906e-05 Test RE 0.003700786391093243\n",
      "271 Train Loss 0.0040576947 Test MSE 2.559864711322993e-05 Test RE 0.003655479760262738\n",
      "272 Train Loss 0.004025658 Test MSE 2.4795061859190813e-05 Test RE 0.0035976463927108334\n",
      "273 Train Loss 0.004003646 Test MSE 2.4469419123536664e-05 Test RE 0.0035739436998094803\n",
      "274 Train Loss 0.003974098 Test MSE 2.3977727848088174e-05 Test RE 0.0035378538670249224\n",
      "275 Train Loss 0.00393487 Test MSE 2.2959170962726782e-05 Test RE 0.003461895688634033\n",
      "276 Train Loss 0.0038957102 Test MSE 2.3389897664738382e-05 Test RE 0.003494218331040634\n",
      "277 Train Loss 0.003865565 Test MSE 2.389089223706106e-05 Test RE 0.003531441867696511\n",
      "278 Train Loss 0.0038404686 Test MSE 2.4038948675193245e-05 Test RE 0.003542367477861441\n",
      "279 Train Loss 0.0038245341 Test MSE 2.311435107722263e-05 Test RE 0.003473575393171274\n",
      "280 Train Loss 0.0038188824 Test MSE 2.25217121183224e-05 Test RE 0.0034287559820633776\n",
      "281 Train Loss 0.0037797992 Test MSE 2.2529633883220653e-05 Test RE 0.0034293589426774417\n",
      "282 Train Loss 0.0037599101 Test MSE 2.2429636184631032e-05 Test RE 0.0034217398803420254\n",
      "283 Train Loss 0.0037257562 Test MSE 2.212773774446071e-05 Test RE 0.0033986338974777808\n",
      "284 Train Loss 0.0037024617 Test MSE 2.1821168528934653e-05 Test RE 0.0033750085596468194\n",
      "285 Train Loss 0.0036990843 Test MSE 2.1747034306166893e-05 Test RE 0.003369270633527731\n",
      "286 Train Loss 0.0036876923 Test MSE 2.1405258790535607e-05 Test RE 0.0033426901245812704\n",
      "287 Train Loss 0.0036599317 Test MSE 2.1152127313318938e-05 Test RE 0.0033228665723005414\n",
      "288 Train Loss 0.0036529242 Test MSE 2.1708123260205285e-05 Test RE 0.003366255037495254\n",
      "289 Train Loss 0.0036342992 Test MSE 2.1772583483133982e-05 Test RE 0.003371249221095852\n",
      "290 Train Loss 0.0036130676 Test MSE 2.1266469654315627e-05 Test RE 0.003331835699912739\n",
      "291 Train Loss 0.0036148604 Test MSE 2.1033729631112852e-05 Test RE 0.0033135537552910843\n",
      "292 Train Loss 0.0036051567 Test MSE 2.097422091621759e-05 Test RE 0.003308863075221441\n",
      "293 Train Loss 0.0035876473 Test MSE 2.1029451380376677e-05 Test RE 0.0033132167505141455\n",
      "294 Train Loss 0.0035810114 Test MSE 2.122010535566813e-05 Test RE 0.003328201751338956\n",
      "295 Train Loss 0.0035688933 Test MSE 2.1129915296717715e-05 Test RE 0.0033211214297663573\n",
      "296 Train Loss 0.0035374581 Test MSE 2.133794184960608e-05 Test RE 0.00333742980819144\n",
      "297 Train Loss 0.0035160112 Test MSE 2.113594329870263e-05 Test RE 0.003321595125440766\n",
      "298 Train Loss 0.0035011026 Test MSE 2.1145577144273082e-05 Test RE 0.003322352037220469\n",
      "299 Train Loss 0.003491651 Test MSE 2.1648458133814265e-05 Test RE 0.0033616257512975017\n",
      "Training time: 173.03\n",
      "KG_tanhALR_high\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 46055.906 Test MSE 8.87190349658673 Test RE 2.152009982107863\n",
      "1 Train Loss 35473.56 Test MSE 8.869339758687671 Test RE 2.15169902357516\n",
      "2 Train Loss 29939.18 Test MSE 6.8872906354400305 Test RE 1.8960949517202499\n",
      "3 Train Loss 18793.246 Test MSE 2.3297420543586957 Test RE 1.1027823243374355\n",
      "4 Train Loss 7672.3496 Test MSE 10.680256123077184 Test RE 2.361167031949976\n",
      "5 Train Loss 3361.0764 Test MSE 15.025463509853948 Test RE 2.800591819808478\n",
      "6 Train Loss 1752.1534 Test MSE 16.891155663084085 Test RE 2.9693784955803713\n",
      "7 Train Loss 1278.3933 Test MSE 16.33400442935364 Test RE 2.919995696639957\n",
      "8 Train Loss 1062.2992 Test MSE 17.398887587541704 Test RE 3.013676405637779\n",
      "9 Train Loss 896.14655 Test MSE 17.962430493468098 Test RE 3.062093356188302\n",
      "10 Train Loss 800.80725 Test MSE 18.453223989155827 Test RE 3.1036447387889607\n",
      "11 Train Loss 715.80096 Test MSE 18.126720813694305 Test RE 3.0760649401730755\n",
      "12 Train Loss 625.3315 Test MSE 18.444120307959004 Test RE 3.1028790710147454\n",
      "13 Train Loss 554.5465 Test MSE 17.428174642333882 Test RE 3.0162117572426896\n",
      "14 Train Loss 457.20853 Test MSE 14.257012918790233 Test RE 2.7280363225893707\n",
      "15 Train Loss 338.37125 Test MSE 12.652766369606898 Test RE 2.569973359180089\n",
      "16 Train Loss 276.8243 Test MSE 12.418927401943765 Test RE 2.5461144464115484\n",
      "17 Train Loss 237.41219 Test MSE 12.051141154042197 Test RE 2.5081295420885215\n",
      "18 Train Loss 211.07196 Test MSE 11.47824551642416 Test RE 2.4477870446137047\n",
      "19 Train Loss 181.79514 Test MSE 10.453059037936196 Test RE 2.335917920809614\n",
      "20 Train Loss 163.03094 Test MSE 9.593132675319868 Test RE 2.2377733751822713\n",
      "21 Train Loss 145.50937 Test MSE 8.386220809610824 Test RE 2.0922762413990914\n",
      "22 Train Loss 110.63788 Test MSE 5.0913097025505305 Test RE 1.6302365837272021\n",
      "23 Train Loss 64.794304 Test MSE 3.906209821294251 Test RE 1.4279521698037076\n",
      "24 Train Loss 37.53743 Test MSE 1.9665915327571608 Test RE 1.0131948167260634\n",
      "25 Train Loss 23.82947 Test MSE 1.0010901084875021 Test RE 0.7228904077748295\n",
      "26 Train Loss 17.177176 Test MSE 0.7491580033046046 Test RE 0.6253491856529506\n",
      "27 Train Loss 13.212908 Test MSE 0.5635255402664098 Test RE 0.5423662777257476\n",
      "28 Train Loss 9.563324 Test MSE 0.36880060352564703 Test RE 0.4387647085729908\n",
      "29 Train Loss 6.890642 Test MSE 0.18358561450553945 Test RE 0.3095673864790688\n",
      "30 Train Loss 5.31429 Test MSE 0.1377755645065848 Test RE 0.2681772768188089\n",
      "31 Train Loss 4.09317 Test MSE 0.09656189579315458 Test RE 0.2245115916241088\n",
      "32 Train Loss 3.287377 Test MSE 0.053395491699519605 Test RE 0.16695067217909645\n",
      "33 Train Loss 2.763002 Test MSE 0.03138809920283609 Test RE 0.12800248033624928\n",
      "34 Train Loss 2.1994543 Test MSE 0.019067120844289694 Test RE 0.09976505272847147\n",
      "35 Train Loss 1.7764468 Test MSE 0.015128270118735103 Test RE 0.08886495229038208\n",
      "36 Train Loss 1.495744 Test MSE 0.020046104115207034 Test RE 0.10229416642761634\n",
      "37 Train Loss 1.253622 Test MSE 0.011042613853147233 Test RE 0.07592273067156285\n",
      "38 Train Loss 1.0905114 Test MSE 0.014600897788671343 Test RE 0.08730229433660795\n",
      "39 Train Loss 0.9588324 Test MSE 0.008460758457723686 Test RE 0.06645696829299916\n",
      "40 Train Loss 0.84313655 Test MSE 0.008528848816809749 Test RE 0.06672384809425747\n",
      "41 Train Loss 0.77869135 Test MSE 0.008531252539652843 Test RE 0.06673324996913725\n",
      "42 Train Loss 0.65586835 Test MSE 0.0075111671262668555 Test RE 0.06261661546327987\n",
      "43 Train Loss 0.5890127 Test MSE 0.006386339349634937 Test RE 0.05773801816504307\n",
      "44 Train Loss 0.5173819 Test MSE 0.004932814786784236 Test RE 0.05074383444925979\n",
      "45 Train Loss 0.4915063 Test MSE 0.003944962629346967 Test RE 0.045379251021925936\n",
      "46 Train Loss 0.43619466 Test MSE 0.002951083902448361 Test RE 0.039248824615381595\n",
      "47 Train Loss 0.41145307 Test MSE 0.0026990480936679613 Test RE 0.037535412114417126\n",
      "48 Train Loss 0.37106454 Test MSE 0.0023121959855309706 Test RE 0.03474147061603082\n",
      "49 Train Loss 0.34668896 Test MSE 0.002181867042187591 Test RE 0.03374815367105145\n",
      "50 Train Loss 0.30996314 Test MSE 0.0021660297866082337 Test RE 0.03362544876998683\n",
      "51 Train Loss 0.28519985 Test MSE 0.0024088858717779623 Test RE 0.03546042930574087\n",
      "52 Train Loss 0.26924685 Test MSE 0.002685815193218551 Test RE 0.037443284693926285\n",
      "53 Train Loss 0.25591755 Test MSE 0.0026896087147866557 Test RE 0.03746971834204366\n",
      "54 Train Loss 0.24150161 Test MSE 0.0029825840589674415 Test RE 0.039457741480586055\n",
      "55 Train Loss 0.22777312 Test MSE 0.003518532080589631 Test RE 0.04285649350764681\n",
      "56 Train Loss 0.21716745 Test MSE 0.003121192255170931 Test RE 0.04036418027841345\n",
      "57 Train Loss 0.20597607 Test MSE 0.0023491539573330987 Test RE 0.035018022465685444\n",
      "58 Train Loss 0.19459717 Test MSE 0.0019801097509853844 Test RE 0.03214996527025747\n",
      "59 Train Loss 0.17581388 Test MSE 0.0018383321013766948 Test RE 0.030977606760962693\n",
      "60 Train Loss 0.16910605 Test MSE 0.0017330066912184974 Test RE 0.030077102556426136\n",
      "61 Train Loss 0.1585985 Test MSE 0.0017257336019016643 Test RE 0.030013922346673487\n",
      "62 Train Loss 0.15261364 Test MSE 0.0016174366856292817 Test RE 0.02905691624254305\n",
      "63 Train Loss 0.1451352 Test MSE 0.0014621222518121635 Test RE 0.02762661784541249\n",
      "64 Train Loss 0.13884632 Test MSE 0.001274737175125733 Test RE 0.025795633774623745\n",
      "65 Train Loss 0.13305785 Test MSE 0.0013026138009711587 Test RE 0.026076164641969143\n",
      "66 Train Loss 0.12865126 Test MSE 0.0011753860978432676 Test RE 0.02477000827876907\n",
      "67 Train Loss 0.12198641 Test MSE 0.001041310162136834 Test RE 0.023314490561107622\n",
      "68 Train Loss 0.116902225 Test MSE 0.0009938612643654054 Test RE 0.022777117336339983\n",
      "69 Train Loss 0.112880416 Test MSE 0.0010084493184055125 Test RE 0.022943671464998264\n",
      "70 Train Loss 0.10554929 Test MSE 0.0010626870822999328 Test RE 0.023552584881214714\n",
      "71 Train Loss 0.10183088 Test MSE 0.000965474119051232 Test RE 0.022449475308403848\n",
      "72 Train Loss 0.099418245 Test MSE 0.0010230856366408854 Test RE 0.023109570320900386\n",
      "73 Train Loss 0.095129736 Test MSE 0.0010699607992025904 Test RE 0.02363305197694951\n",
      "74 Train Loss 0.09227823 Test MSE 0.0011137663635460207 Test RE 0.024111982834039845\n",
      "75 Train Loss 0.08702242 Test MSE 0.0012077160905308334 Test RE 0.025108357471518856\n",
      "76 Train Loss 0.08242584 Test MSE 0.0010678204675739404 Test RE 0.023609402563752067\n",
      "77 Train Loss 0.07875156 Test MSE 0.0009741563156022657 Test RE 0.022550189827913757\n",
      "78 Train Loss 0.07600051 Test MSE 0.0010392706229731357 Test RE 0.02329164716404395\n",
      "79 Train Loss 0.07441557 Test MSE 0.0010482212037292167 Test RE 0.023391730252915157\n",
      "80 Train Loss 0.07353711 Test MSE 0.0008896609912671156 Test RE 0.021550043502116596\n",
      "81 Train Loss 0.07076119 Test MSE 0.0007652524600197172 Test RE 0.019986568855064602\n",
      "82 Train Loss 0.06877121 Test MSE 0.000799483476817404 Test RE 0.020428694936999225\n",
      "83 Train Loss 0.067479916 Test MSE 0.0007027221944076875 Test RE 0.0191525988299705\n",
      "84 Train Loss 0.06637572 Test MSE 0.0006372038627356252 Test RE 0.018237910360284968\n",
      "85 Train Loss 0.064286426 Test MSE 0.0005538980244047887 Test RE 0.01700398781052456\n",
      "86 Train Loss 0.06348868 Test MSE 0.0005288290348036179 Test RE 0.016614738974788337\n",
      "87 Train Loss 0.062357314 Test MSE 0.0004990785341198291 Test RE 0.016140624062191647\n",
      "88 Train Loss 0.059785984 Test MSE 0.000462327444393167 Test RE 0.01553498056093729\n",
      "89 Train Loss 0.05847986 Test MSE 0.00042551492178003977 Test RE 0.01490367165772605\n",
      "90 Train Loss 0.057251167 Test MSE 0.00036834548763314254 Test RE 0.013866394567768527\n",
      "91 Train Loss 0.05586542 Test MSE 0.0003922548616258162 Test RE 0.014309354544429156\n",
      "92 Train Loss 0.054114733 Test MSE 0.0003413165875257322 Test RE 0.013347950097980177\n",
      "93 Train Loss 0.052797254 Test MSE 0.0003368430830183388 Test RE 0.013260188374978563\n",
      "94 Train Loss 0.051476702 Test MSE 0.0002973855161419068 Test RE 0.01245936140059204\n",
      "95 Train Loss 0.049695175 Test MSE 0.00025687608554916705 Test RE 0.011579710827129575\n",
      "96 Train Loss 0.048736535 Test MSE 0.00027166829165105376 Test RE 0.011908453159982024\n",
      "97 Train Loss 0.047456205 Test MSE 0.0002332482109694654 Test RE 0.011034306357337563\n",
      "98 Train Loss 0.04602263 Test MSE 0.00021153314906000324 Test RE 0.010508121707744655\n",
      "99 Train Loss 0.045019425 Test MSE 0.00021900056813588367 Test RE 0.010691988861235258\n",
      "100 Train Loss 0.043937437 Test MSE 0.00019836450817298376 Test RE 0.010175783580846854\n",
      "101 Train Loss 0.042867985 Test MSE 0.00017199447474442378 Test RE 0.009475303393045002\n",
      "102 Train Loss 0.04177527 Test MSE 0.00015142737028756942 Test RE 0.008890743216600397\n",
      "103 Train Loss 0.041143958 Test MSE 0.0001306207841091575 Test RE 0.008257375229339886\n",
      "104 Train Loss 0.040084064 Test MSE 0.00012042555402912161 Test RE 0.007928576180437207\n",
      "105 Train Loss 0.03951387 Test MSE 0.00011483091632207545 Test RE 0.007742216152693745\n",
      "106 Train Loss 0.03890188 Test MSE 0.0001031479244881915 Test RE 0.007337804280145864\n",
      "107 Train Loss 0.037967276 Test MSE 9.073562636376297e-05 Test RE 0.006882160516315405\n",
      "108 Train Loss 0.036857426 Test MSE 6.876889793964281e-05 Test RE 0.005991449583408193\n",
      "109 Train Loss 0.03584397 Test MSE 6.397052480709933e-05 Test RE 0.005778642584685382\n",
      "110 Train Loss 0.035049215 Test MSE 5.4787574841474743e-05 Test RE 0.005347821653158188\n",
      "111 Train Loss 0.03425344 Test MSE 5.71798360664049e-05 Test RE 0.005463328691364565\n",
      "112 Train Loss 0.033326425 Test MSE 5.096949393860943e-05 Test RE 0.005158115204476528\n",
      "113 Train Loss 0.03214067 Test MSE 4.856504630161779e-05 Test RE 0.0050349803556057\n",
      "114 Train Loss 0.030770047 Test MSE 4.4525544125065404e-05 Test RE 0.004821037333629963\n",
      "115 Train Loss 0.030074976 Test MSE 4.1335685703557e-05 Test RE 0.004645136174607363\n",
      "116 Train Loss 0.029420368 Test MSE 4.0311956561235014e-05 Test RE 0.004587254290890826\n",
      "117 Train Loss 0.029118996 Test MSE 4.491000085788269e-05 Test RE 0.004841806270883881\n",
      "118 Train Loss 0.028749147 Test MSE 4.4280602303502865e-05 Test RE 0.004807758414599965\n",
      "119 Train Loss 0.028405095 Test MSE 3.7395324778248644e-05 Test RE 0.004418191457345555\n",
      "120 Train Loss 0.027538916 Test MSE 3.5149301800202246e-05 Test RE 0.004283455192083495\n",
      "121 Train Loss 0.02686453 Test MSE 3.5525426696823324e-05 Test RE 0.004306312360254795\n",
      "122 Train Loss 0.026217612 Test MSE 3.6441210657074506e-05 Test RE 0.004361463830883946\n",
      "123 Train Loss 0.02592286 Test MSE 3.631115005388986e-05 Test RE 0.004353673726603261\n",
      "124 Train Loss 0.025565008 Test MSE 3.174950718686286e-05 Test RE 0.004071030641401346\n",
      "125 Train Loss 0.0252312 Test MSE 2.9299035504854914e-05 Test RE 0.003910772376554501\n",
      "126 Train Loss 0.024789741 Test MSE 3.141757562443391e-05 Test RE 0.004049694026543277\n",
      "127 Train Loss 0.024248783 Test MSE 3.345479783282529e-05 Test RE 0.004178929858723036\n",
      "128 Train Loss 0.023710264 Test MSE 3.1501539156114166e-05 Test RE 0.004055101823430182\n",
      "129 Train Loss 0.023144985 Test MSE 2.683378728942369e-05 Test RE 0.0037426297314258955\n",
      "130 Train Loss 0.022671154 Test MSE 2.411076130219031e-05 Test RE 0.0035476546685753985\n",
      "131 Train Loss 0.022323564 Test MSE 2.3680090581964323e-05 Test RE 0.003515827482121896\n",
      "132 Train Loss 0.021918261 Test MSE 2.2307107291893396e-05 Test RE 0.0034123809199012494\n",
      "133 Train Loss 0.021577643 Test MSE 2.1212161127414582e-05 Test RE 0.003327578699072965\n",
      "134 Train Loss 0.021127006 Test MSE 1.911803526593686e-05 Test RE 0.003159057319922894\n",
      "135 Train Loss 0.020763647 Test MSE 1.8859180659001437e-05 Test RE 0.003137597911871497\n",
      "136 Train Loss 0.020262536 Test MSE 2.025235984724746e-05 Test RE 0.003251424655028539\n",
      "137 Train Loss 0.019984538 Test MSE 2.3963478718197334e-05 Test RE 0.0035368024990375525\n",
      "138 Train Loss 0.019583257 Test MSE 3.975100450680536e-05 Test RE 0.004555226022225237\n",
      "139 Train Loss 0.019231401 Test MSE 4.950452841131033e-05 Test RE 0.005083447477352033\n",
      "140 Train Loss 0.018954426 Test MSE 6.100066513799556e-05 Test RE 0.005642910499859897\n",
      "141 Train Loss 0.018580984 Test MSE 4.624337180571225e-05 Test RE 0.004913156786029266\n",
      "142 Train Loss 0.018210188 Test MSE 5.72118106557549e-05 Test RE 0.005464856006666417\n",
      "143 Train Loss 0.017897394 Test MSE 6.110704812154609e-05 Test RE 0.0056478288737157115\n",
      "144 Train Loss 0.017586831 Test MSE 4.02882822149989e-05 Test RE 0.004585907095108821\n",
      "145 Train Loss 0.017333755 Test MSE 4.187023938916569e-05 Test RE 0.004675075176740248\n",
      "146 Train Loss 0.017115708 Test MSE 3.418051159331613e-05 Test RE 0.004224012125708123\n",
      "147 Train Loss 0.016817065 Test MSE 2.7640929206982923e-05 Test RE 0.0037985005727211446\n",
      "148 Train Loss 0.016711738 Test MSE 3.0622638620983e-05 Test RE 0.003998132488765689\n",
      "149 Train Loss 0.01644446 Test MSE 2.4861138339493508e-05 Test RE 0.0036024368959138723\n",
      "150 Train Loss 0.016111584 Test MSE 2.096976183433191e-05 Test RE 0.003308511327336792\n",
      "151 Train Loss 0.015822662 Test MSE 2.3541922293092433e-05 Test RE 0.003505555423828373\n",
      "152 Train Loss 0.015635474 Test MSE 2.3741805394079254e-05 Test RE 0.003520405957946983\n",
      "153 Train Loss 0.015357625 Test MSE 2.339754231085773e-05 Test RE 0.0034947893014812114\n",
      "154 Train Loss 0.01510419 Test MSE 2.8052459876590695e-05 Test RE 0.0038266729974204155\n",
      "155 Train Loss 0.014895926 Test MSE 3.3261947506613776e-05 Test RE 0.004166867720952576\n",
      "156 Train Loss 0.014705037 Test MSE 3.109279373391594e-05 Test RE 0.004028707618268937\n",
      "157 Train Loss 0.014571552 Test MSE 3.346692530697798e-05 Test RE 0.004179687227995279\n",
      "158 Train Loss 0.014408669 Test MSE 3.183638545098977e-05 Test RE 0.0040765967506873\n",
      "159 Train Loss 0.014231028 Test MSE 3.136499356390145e-05 Test RE 0.004046303719936425\n",
      "160 Train Loss 0.014053795 Test MSE 3.195265326285832e-05 Test RE 0.004084033917624185\n",
      "161 Train Loss 0.0139202485 Test MSE 3.531892096773855e-05 Test RE 0.00429377803839971\n",
      "162 Train Loss 0.013725515 Test MSE 4.088614233250674e-05 Test RE 0.004619808195707001\n",
      "163 Train Loss 0.013612601 Test MSE 4.113961605405911e-05 Test RE 0.004634106324723262\n",
      "164 Train Loss 0.013499219 Test MSE 3.9064494299354897e-05 Test RE 0.004515719738112703\n",
      "165 Train Loss 0.013326204 Test MSE 4.877770569247403e-05 Test RE 0.005045992043500553\n",
      "166 Train Loss 0.013146165 Test MSE 5.287875504247482e-05 Test RE 0.005253835706340785\n",
      "167 Train Loss 0.012917841 Test MSE 4.483033444052435e-05 Test RE 0.004837509894061224\n",
      "168 Train Loss 0.0127850715 Test MSE 4.38927769203882e-05 Test RE 0.004786658076374437\n",
      "169 Train Loss 0.012659928 Test MSE 3.2492820776587626e-05 Test RE 0.004118410044489305\n",
      "170 Train Loss 0.012534158 Test MSE 3.49197214141865e-05 Test RE 0.004269443415240382\n",
      "171 Train Loss 0.012386621 Test MSE 3.357374277633488e-05 Test RE 0.0041863521356258135\n",
      "172 Train Loss 0.012255726 Test MSE 3.819961224649633e-05 Test RE 0.004465451267379262\n",
      "173 Train Loss 0.012187353 Test MSE 4.115897161871342e-05 Test RE 0.004635196334858807\n",
      "174 Train Loss 0.011994836 Test MSE 3.759534675637069e-05 Test RE 0.004429991820201327\n",
      "175 Train Loss 0.01176866 Test MSE 3.624361066305987e-05 Test RE 0.004349622886431036\n",
      "176 Train Loss 0.011548001 Test MSE 3.3841949371063016e-05 Test RE 0.004203040381571923\n",
      "177 Train Loss 0.011370131 Test MSE 3.4487353754016725e-05 Test RE 0.004242929472347663\n",
      "178 Train Loss 0.011265128 Test MSE 3.147426018185326e-05 Test RE 0.004053345671517768\n",
      "179 Train Loss 0.011135477 Test MSE 2.7683509115563237e-05 Test RE 0.0038014251771218274\n",
      "180 Train Loss 0.010988376 Test MSE 2.4767352295884663e-05 Test RE 0.003595635567362375\n",
      "181 Train Loss 0.010875 Test MSE 2.5229659249584002e-05 Test RE 0.0036290384481480866\n",
      "182 Train Loss 0.010806125 Test MSE 2.0463422388382128e-05 Test RE 0.0032683233088401293\n",
      "183 Train Loss 0.010695287 Test MSE 2.2424604131121062e-05 Test RE 0.0034213560278383397\n",
      "184 Train Loss 0.010661419 Test MSE 2.2532594226989033e-05 Test RE 0.0034295842403445\n",
      "185 Train Loss 0.010557301 Test MSE 1.9468485240668177e-05 Test RE 0.0031878799482146273\n",
      "186 Train Loss 0.0104614785 Test MSE 1.79840172646601e-05 Test RE 0.003063932774887197\n",
      "187 Train Loss 0.01029413 Test MSE 1.9568946981478798e-05 Test RE 0.0031960944516651194\n",
      "188 Train Loss 0.010199065 Test MSE 1.879671786563476e-05 Test RE 0.003132397641510004\n",
      "189 Train Loss 0.010090931 Test MSE 1.803649580005385e-05 Test RE 0.003068399896264968\n",
      "190 Train Loss 0.010019777 Test MSE 1.8315691750423636e-05 Test RE 0.0030920573457215317\n",
      "191 Train Loss 0.00988251 Test MSE 1.7983428204870637e-05 Test RE 0.003063882595487672\n",
      "192 Train Loss 0.009734836 Test MSE 1.689095266503946e-05 Test RE 0.002969360652519439\n",
      "193 Train Loss 0.009636447 Test MSE 1.570239132279318e-05 Test RE 0.002862983038233822\n",
      "194 Train Loss 0.009487945 Test MSE 1.61213721631318e-05 Test RE 0.00290092752507887\n",
      "195 Train Loss 0.009416562 Test MSE 1.742952791482436e-05 Test RE 0.0030163288572043244\n",
      "196 Train Loss 0.00935099 Test MSE 1.672301860827272e-05 Test RE 0.0029545627180056835\n",
      "197 Train Loss 0.009246728 Test MSE 1.7459993321722344e-05 Test RE 0.0030189638558627183\n",
      "198 Train Loss 0.009170279 Test MSE 1.8800488822064386e-05 Test RE 0.0031327118331348144\n",
      "199 Train Loss 0.009107627 Test MSE 1.6980882315852734e-05 Test RE 0.0029772547921959845\n",
      "200 Train Loss 0.00892755 Test MSE 1.7295754375435464e-05 Test RE 0.003004731233593049\n",
      "201 Train Loss 0.008788122 Test MSE 1.9045537716292877e-05 Test RE 0.003153061896102364\n",
      "202 Train Loss 0.008737538 Test MSE 1.9283647455939592e-05 Test RE 0.003172710664828813\n",
      "203 Train Loss 0.008710551 Test MSE 1.8901311634945704e-05 Test RE 0.003141100617516462\n",
      "204 Train Loss 0.008622251 Test MSE 2.009389526669535e-05 Test RE 0.003238679289161897\n",
      "205 Train Loss 0.008578997 Test MSE 1.920379319873712e-05 Test RE 0.003166134697135803\n",
      "206 Train Loss 0.008497482 Test MSE 1.8274813208478914e-05 Test RE 0.003088604858002916\n",
      "207 Train Loss 0.008400234 Test MSE 1.8023917703794402e-05 Test RE 0.0030673298059129103\n",
      "208 Train Loss 0.008332577 Test MSE 1.8819845756948803e-05 Test RE 0.0031343241342550164\n",
      "209 Train Loss 0.008203553 Test MSE 1.9963491033974117e-05 Test RE 0.003228153083810949\n",
      "210 Train Loss 0.008107806 Test MSE 2.4683643814591632e-05 Test RE 0.0035895541756881793\n",
      "211 Train Loss 0.007999784 Test MSE 2.3793419592376876e-05 Test RE 0.0035242305256404424\n",
      "212 Train Loss 0.007952073 Test MSE 2.0861225571382576e-05 Test RE 0.003299938046491885\n",
      "213 Train Loss 0.007911753 Test MSE 2.1444635747881724e-05 Test RE 0.0033457633060194926\n",
      "214 Train Loss 0.007827271 Test MSE 1.91879657661107e-05 Test RE 0.003164829691591875\n",
      "215 Train Loss 0.0077512865 Test MSE 2.3055557875212675e-05 Test RE 0.003469154921909231\n",
      "216 Train Loss 0.0077119 Test MSE 2.2236772315924807e-05 Test RE 0.0034069970031260733\n",
      "217 Train Loss 0.0076805283 Test MSE 2.141757462416391e-05 Test RE 0.0033436516195086085\n",
      "218 Train Loss 0.0075906026 Test MSE 2.2927475864320228e-05 Test RE 0.003459505292663217\n",
      "219 Train Loss 0.007500988 Test MSE 2.0349352106168435e-05 Test RE 0.00325920118929482\n",
      "220 Train Loss 0.007397295 Test MSE 1.7639675770159295e-05 Test RE 0.0030344583159472153\n",
      "221 Train Loss 0.0072773388 Test MSE 1.6749847355028607e-05 Test RE 0.0029569317714092766\n",
      "222 Train Loss 0.007140878 Test MSE 1.6261524084111614e-05 Test RE 0.002913509914040755\n",
      "223 Train Loss 0.0070485095 Test MSE 1.5554921848552643e-05 Test RE 0.002849507429356488\n",
      "224 Train Loss 0.006901608 Test MSE 1.4771665640732173e-05 Test RE 0.002776838431011256\n",
      "225 Train Loss 0.006831884 Test MSE 1.4949785420638582e-05 Test RE 0.0027935301080952296\n",
      "226 Train Loss 0.0067288103 Test MSE 1.4791739833769181e-05 Test RE 0.0027787246050815445\n",
      "227 Train Loss 0.0066469796 Test MSE 1.4703275420717674e-05 Test RE 0.0027704028361010533\n",
      "228 Train Loss 0.0065900846 Test MSE 1.5009127112200258e-05 Test RE 0.0027990689375295965\n",
      "229 Train Loss 0.006537353 Test MSE 1.477436845158716e-05 Test RE 0.0027770924621392645\n",
      "230 Train Loss 0.0064869723 Test MSE 1.4324742523685228e-05 Test RE 0.0027345085724761764\n",
      "231 Train Loss 0.0064029275 Test MSE 1.516845876935265e-05 Test RE 0.0028138866859938045\n",
      "232 Train Loss 0.00633453 Test MSE 1.3732965923037574e-05 Test RE 0.00267742952432747\n",
      "233 Train Loss 0.006281065 Test MSE 1.292436458888661e-05 Test RE 0.0025974098147338418\n",
      "234 Train Loss 0.0061865686 Test MSE 1.2413711511622945e-05 Test RE 0.0025455797122927873\n",
      "235 Train Loss 0.0061024246 Test MSE 1.327143163662845e-05 Test RE 0.002632053811450634\n",
      "236 Train Loss 0.0060041468 Test MSE 1.3332981418760086e-05 Test RE 0.0026381501748720558\n",
      "237 Train Loss 0.005947049 Test MSE 1.2467269705715282e-05 Test RE 0.002551065175465209\n",
      "238 Train Loss 0.005925208 Test MSE 1.2777417934019396e-05 Test RE 0.0025826016671019604\n",
      "239 Train Loss 0.005853833 Test MSE 1.2781282180549452e-05 Test RE 0.0025829921628638276\n",
      "240 Train Loss 0.005806541 Test MSE 1.2459684244994868e-05 Test RE 0.002550288985109614\n",
      "241 Train Loss 0.0057697813 Test MSE 1.2815311810141338e-05 Test RE 0.0025864284314905187\n",
      "242 Train Loss 0.0057244105 Test MSE 1.3012461334671048e-05 Test RE 0.0026062471831003226\n",
      "243 Train Loss 0.0056688744 Test MSE 1.2414561521651966e-05 Test RE 0.002545666863151907\n",
      "244 Train Loss 0.005605165 Test MSE 1.2703346366139612e-05 Test RE 0.002575105027203085\n",
      "245 Train Loss 0.00553044 Test MSE 1.1925389392617275e-05 Test RE 0.002495009256772455\n",
      "246 Train Loss 0.0054696947 Test MSE 1.2458060449377124e-05 Test RE 0.0025501227977918588\n",
      "247 Train Loss 0.005423436 Test MSE 1.2709792264304528e-05 Test RE 0.002575758270812567\n",
      "248 Train Loss 0.005369361 Test MSE 1.2746398971887908e-05 Test RE 0.002579464949568377\n",
      "249 Train Loss 0.005339083 Test MSE 1.2485739708349411e-05 Test RE 0.002552954151294898\n",
      "250 Train Loss 0.005307466 Test MSE 1.3375975454606503e-05 Test RE 0.0026424002907443475\n",
      "251 Train Loss 0.0052754115 Test MSE 1.3313002110782651e-05 Test RE 0.002636172816106083\n",
      "252 Train Loss 0.0052459273 Test MSE 1.3373466608276201e-05 Test RE 0.0026421524700458976\n",
      "253 Train Loss 0.0052112816 Test MSE 1.3884140407644488e-05 Test RE 0.002692125956558954\n",
      "254 Train Loss 0.0052086012 Test MSE 1.3571979604018935e-05 Test RE 0.0026616900189895356\n",
      "255 Train Loss 0.005179932 Test MSE 1.3125081695622283e-05 Test RE 0.0026175011704193192\n",
      "256 Train Loss 0.0051548085 Test MSE 1.2906696267141752e-05 Test RE 0.00259563380606021\n",
      "257 Train Loss 0.005122615 Test MSE 1.3291949398245884e-05 Test RE 0.002634087616003344\n",
      "258 Train Loss 0.00508534 Test MSE 1.4760847033322654e-05 Test RE 0.002775821381610994\n",
      "259 Train Loss 0.005087525 Test MSE 1.5051431387574153e-05 Test RE 0.0028030108477114\n",
      "260 Train Loss 0.0050419276 Test MSE 1.42975237687283e-05 Test RE 0.00273190938757821\n",
      "261 Train Loss 0.0050033736 Test MSE 1.5572696249669348e-05 Test RE 0.002851135011545838\n",
      "262 Train Loss 0.004967558 Test MSE 1.585876722683677e-05 Test RE 0.002877203561484359\n",
      "263 Train Loss 0.004940093 Test MSE 1.5374671292022924e-05 Test RE 0.002832949263305573\n",
      "264 Train Loss 0.0049066576 Test MSE 1.6073173446268856e-05 Test RE 0.0028965877689268453\n",
      "265 Train Loss 0.0048636915 Test MSE 1.4596424590336875e-05 Test RE 0.002760318021565667\n",
      "266 Train Loss 0.0048354487 Test MSE 1.510331233080739e-05 Test RE 0.002807837556332718\n",
      "267 Train Loss 0.0047914986 Test MSE 1.566758675542925e-05 Test RE 0.0028598083573424947\n",
      "268 Train Loss 0.0047816886 Test MSE 1.6211474615728183e-05 Test RE 0.0029090228808784004\n",
      "269 Train Loss 0.0047605173 Test MSE 1.778427234827276e-05 Test RE 0.0030468700173096573\n",
      "270 Train Loss 0.004733905 Test MSE 1.7817818955191025e-05 Test RE 0.0030497423303658465\n",
      "271 Train Loss 0.0047204737 Test MSE 2.0388057243461617e-05 Test RE 0.0032622992707837927\n",
      "272 Train Loss 0.004687944 Test MSE 2.0027550113924513e-05 Test RE 0.0032333282030374863\n",
      "273 Train Loss 0.004640247 Test MSE 2.0212471526170518e-05 Test RE 0.0032482211322134203\n",
      "274 Train Loss 0.0045938753 Test MSE 1.8154436724167707e-05 Test RE 0.0030784157066739287\n",
      "275 Train Loss 0.0045376993 Test MSE 1.7442238867736443e-05 Test RE 0.00301742852630068\n",
      "276 Train Loss 0.0044912295 Test MSE 1.6626675694595e-05 Test RE 0.0029460396651859616\n",
      "277 Train Loss 0.0044546523 Test MSE 1.8817365939552924e-05 Test RE 0.0031341176286420218\n",
      "278 Train Loss 0.004438874 Test MSE 2.0794659474471893e-05 Test RE 0.0032946689527208837\n",
      "279 Train Loss 0.0044120015 Test MSE 2.235368538706775e-05 Test RE 0.003415941653221239\n",
      "280 Train Loss 0.0043942067 Test MSE 2.3459045074901057e-05 Test RE 0.003499379487429219\n",
      "281 Train Loss 0.004377722 Test MSE 2.4979788752398674e-05 Test RE 0.0036110230244288315\n",
      "282 Train Loss 0.0043513435 Test MSE 2.3157330453335562e-05 Test RE 0.0034768033178467833\n",
      "283 Train Loss 0.004324058 Test MSE 2.0931949154631844e-05 Test RE 0.0033055270271872632\n",
      "284 Train Loss 0.0042972444 Test MSE 2.020682632476052e-05 Test RE 0.003247767497856784\n",
      "285 Train Loss 0.004291654 Test MSE 1.8984325646670782e-05 Test RE 0.003147990871696531\n",
      "286 Train Loss 0.0042369673 Test MSE 1.9343289204944085e-05 Test RE 0.0031776132623973063\n",
      "287 Train Loss 0.004196627 Test MSE 1.8440551695329516e-05 Test RE 0.0031025788802516753\n",
      "288 Train Loss 0.0041665756 Test MSE 1.921007425452917e-05 Test RE 0.0031666524345076927\n",
      "289 Train Loss 0.004154401 Test MSE 1.8592095373119064e-05 Test RE 0.0031153012271397055\n",
      "290 Train Loss 0.004123943 Test MSE 1.7180088353989528e-05 Test RE 0.0029946672518068583\n",
      "291 Train Loss 0.00408815 Test MSE 1.514796496563174e-05 Test RE 0.002811985150256103\n",
      "292 Train Loss 0.0040653497 Test MSE 1.548019337732103e-05 Test RE 0.0028426544312718295\n",
      "293 Train Loss 0.004046971 Test MSE 1.4759857831994578e-05 Test RE 0.0027757283689201946\n",
      "294 Train Loss 0.0040142606 Test MSE 1.4582472964233869e-05 Test RE 0.0027589985158350096\n",
      "295 Train Loss 0.0039969804 Test MSE 1.4506718282168319e-05 Test RE 0.0027518228054242925\n",
      "296 Train Loss 0.0039637485 Test MSE 1.464700982674727e-05 Test RE 0.002765096951218065\n",
      "297 Train Loss 0.0039395615 Test MSE 1.5029467084981234e-05 Test RE 0.002800964907565518\n",
      "298 Train Loss 0.003918207 Test MSE 1.5721374682803183e-05 Test RE 0.0028647131129799115\n",
      "299 Train Loss 0.0038913144 Test MSE 1.5544703757646904e-05 Test RE 0.0028485713491403584\n",
      "Training time: 171.52\n",
      "KG_tanhALR_high\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 50995.543 Test MSE 9.145020917746459 Test RE 2.1848832159951925\n",
      "1 Train Loss 35437.32 Test MSE 8.943104399100186 Test RE 2.160628135808236\n",
      "2 Train Loss 16530.92 Test MSE 13.352149245263286 Test RE 2.640045829039474\n",
      "3 Train Loss 5509.593 Test MSE 15.18955568956066 Test RE 2.815842841083029\n",
      "4 Train Loss 2213.4602 Test MSE 17.437154729700683 Test RE 3.0169887277938288\n",
      "5 Train Loss 1422.7474 Test MSE 19.173996577188706 Test RE 3.163677454982287\n",
      "6 Train Loss 1151.4862 Test MSE 20.590879424497402 Test RE 3.2784859334114396\n",
      "7 Train Loss 989.8835 Test MSE 21.543190844374312 Test RE 3.3534427098791664\n",
      "8 Train Loss 875.531 Test MSE 20.549004057908196 Test RE 3.2751505326110384\n",
      "9 Train Loss 783.91516 Test MSE 19.52123011325462 Test RE 3.192195399253433\n",
      "10 Train Loss 651.99445 Test MSE 18.56675071991368 Test RE 3.1131771213251276\n",
      "11 Train Loss 517.2438 Test MSE 17.342370008765045 Test RE 3.0087776948137637\n",
      "12 Train Loss 452.85077 Test MSE 17.0348398589858 Test RE 2.981981223329266\n",
      "13 Train Loss 410.14032 Test MSE 17.137499666338083 Test RE 2.990953124016365\n",
      "14 Train Loss 375.8849 Test MSE 17.246149932953596 Test RE 3.0004193361227975\n",
      "15 Train Loss 338.26358 Test MSE 17.43070024218284 Test RE 3.016430296136003\n",
      "16 Train Loss 310.29785 Test MSE 17.483196719983123 Test RE 3.020969210664223\n",
      "17 Train Loss 293.45966 Test MSE 17.51394743402292 Test RE 3.0236247933135014\n",
      "18 Train Loss 280.1243 Test MSE 17.449890567266674 Test RE 3.0180903084552178\n",
      "19 Train Loss 258.2999 Test MSE 17.42705685110424 Test RE 3.016115030271009\n",
      "20 Train Loss 241.42166 Test MSE 17.322693653213683 Test RE 3.0070703566145416\n",
      "21 Train Loss 226.3756 Test MSE 17.283315526073377 Test RE 3.0036505602453554\n",
      "22 Train Loss 209.57945 Test MSE 17.273240451743973 Test RE 3.002774963948445\n",
      "23 Train Loss 198.3527 Test MSE 17.320734358018456 Test RE 3.006900293423848\n",
      "24 Train Loss 192.06993 Test MSE 17.410690540859644 Test RE 3.014698432227371\n",
      "25 Train Loss 180.87364 Test MSE 17.378222548447766 Test RE 3.011886169234044\n",
      "26 Train Loss 173.80336 Test MSE 17.33859876567724 Test RE 3.0084505351172663\n",
      "27 Train Loss 163.64351 Test MSE 17.29080949622999 Test RE 3.004301674557717\n",
      "28 Train Loss 167.35281 Test MSE 17.2194216411723 Test RE 2.9980933914884744\n",
      "29 Train Loss 158.42671 Test MSE 17.186802624404628 Test RE 2.9952523780635323\n",
      "30 Train Loss 156.85161 Test MSE 17.018654563387223 Test RE 2.98056425323346\n",
      "31 Train Loss 148.59204 Test MSE 16.926120375431875 Test RE 2.9724502152981587\n",
      "32 Train Loss 144.58806 Test MSE 16.745745716184597 Test RE 2.9565697081460285\n",
      "33 Train Loss 138.33974 Test MSE 16.68569706962916 Test RE 2.9512639589417637\n",
      "34 Train Loss 134.70036 Test MSE 16.55958269711641 Test RE 2.9400896352490147\n",
      "35 Train Loss 131.39778 Test MSE 16.37597815281179 Test RE 2.9237450667155693\n",
      "36 Train Loss 125.36951 Test MSE 16.251251243454515 Test RE 2.9125894974999054\n",
      "37 Train Loss 118.74785 Test MSE 16.141787570755355 Test RE 2.9027637484356013\n",
      "38 Train Loss 118.572624 Test MSE 15.941245346139869 Test RE 2.884675724668327\n",
      "39 Train Loss 114.028496 Test MSE 15.71682972153051 Test RE 2.8642989967986754\n",
      "40 Train Loss 144.52303 Test MSE 15.075141612098156 Test RE 2.8052177429274314\n",
      "41 Train Loss 152.79515 Test MSE 13.69024869767722 Test RE 2.673262127416978\n",
      "42 Train Loss 145.57495 Test MSE 12.571500449571687 Test RE 2.561706879106813\n",
      "43 Train Loss 151.28572 Test MSE 11.306450939060753 Test RE 2.42940000578782\n",
      "44 Train Loss 135.45866 Test MSE 10.485550567778489 Test RE 2.3395455029095746\n",
      "45 Train Loss 122.55975 Test MSE 8.830640183025414 Test RE 2.146999639352157\n",
      "46 Train Loss 102.26179 Test MSE 6.603714307716423 Test RE 1.8566498852889068\n",
      "47 Train Loss 73.27713 Test MSE 4.256116318059093 Test RE 1.490536519714303\n",
      "48 Train Loss 55.570045 Test MSE 3.28430589968995 Test RE 1.3093558023736547\n",
      "49 Train Loss 39.973167 Test MSE 1.4182431481276037 Test RE 0.8604214406243036\n",
      "50 Train Loss 24.229666 Test MSE 0.45519168668271803 Test RE 0.48745332574110567\n",
      "51 Train Loss 16.359507 Test MSE 0.19012237728220374 Test RE 0.3150304219724841\n",
      "52 Train Loss 11.401629 Test MSE 0.14609861700595378 Test RE 0.2761588269807117\n",
      "53 Train Loss 8.917633 Test MSE 0.15426164914892448 Test RE 0.28376894257504903\n",
      "54 Train Loss 7.470158 Test MSE 0.10114953652208428 Test RE 0.22978296310012944\n",
      "55 Train Loss 6.402986 Test MSE 0.08588962648476618 Test RE 0.21174162120399936\n",
      "56 Train Loss 5.2474403 Test MSE 0.07535036607159291 Test RE 0.1983255010579098\n",
      "57 Train Loss 4.265215 Test MSE 0.06959672882743843 Test RE 0.1906032451940387\n",
      "58 Train Loss 3.7268145 Test MSE 0.07153185442946929 Test RE 0.19323492322040264\n",
      "59 Train Loss 3.218096 Test MSE 0.06439770752308796 Test RE 0.18334584844360363\n",
      "60 Train Loss 2.9232776 Test MSE 0.06202621841216038 Test RE 0.1799382651365268\n",
      "61 Train Loss 2.6614316 Test MSE 0.058368347255416626 Test RE 0.17455189777639057\n",
      "62 Train Loss 2.4097776 Test MSE 0.052946387795254575 Test RE 0.16624708727628995\n",
      "63 Train Loss 2.136895 Test MSE 0.055103603650788785 Test RE 0.1696000116378593\n",
      "64 Train Loss 1.9238418 Test MSE 0.06216560690791793 Test RE 0.18014033491887047\n",
      "65 Train Loss 1.7382953 Test MSE 0.057711022167946324 Test RE 0.1735662419178001\n",
      "66 Train Loss 1.5913427 Test MSE 0.0534219968474911 Test RE 0.16699210361014272\n",
      "67 Train Loss 1.4455849 Test MSE 0.05396049811930404 Test RE 0.16783164523295643\n",
      "68 Train Loss 1.3302529 Test MSE 0.04843456644742969 Test RE 0.15900602661939534\n",
      "69 Train Loss 1.2043085 Test MSE 0.04574903747771906 Test RE 0.15453500037764542\n",
      "70 Train Loss 1.1159493 Test MSE 0.04404229179276363 Test RE 0.15162500627626962\n",
      "71 Train Loss 1.0583644 Test MSE 0.040180087933400166 Test RE 0.1448242600786118\n",
      "72 Train Loss 0.94966465 Test MSE 0.03759428037223602 Test RE 0.14008665487093763\n",
      "73 Train Loss 0.87665373 Test MSE 0.033315936140613664 Test RE 0.13187482228245875\n",
      "74 Train Loss 0.8044448 Test MSE 0.02884471829577723 Test RE 0.12270691225464918\n",
      "75 Train Loss 0.732167 Test MSE 0.02371657185737871 Test RE 0.11126583556804508\n",
      "76 Train Loss 0.6487317 Test MSE 0.017851555054541952 Test RE 0.09653257779736736\n",
      "77 Train Loss 0.6195717 Test MSE 0.016397336090040578 Test RE 0.09251720969898641\n",
      "78 Train Loss 0.5709636 Test MSE 0.014799052183356627 Test RE 0.08789270440920281\n",
      "79 Train Loss 0.5473838 Test MSE 0.013881339760936615 Test RE 0.08512391100147189\n",
      "80 Train Loss 0.49284536 Test MSE 0.01109352641555923 Test RE 0.07609755230457045\n",
      "81 Train Loss 0.47767535 Test MSE 0.010983755877744987 Test RE 0.07572012335555577\n",
      "82 Train Loss 0.45123658 Test MSE 0.01050573560437895 Test RE 0.0740541003566697\n",
      "83 Train Loss 0.43571004 Test MSE 0.010151251820856457 Test RE 0.0727940156311759\n",
      "84 Train Loss 0.40668398 Test MSE 0.010220550903190066 Test RE 0.07304206279174436\n",
      "85 Train Loss 0.3821265 Test MSE 0.009407832345877745 Test RE 0.07007783264434195\n",
      "86 Train Loss 0.3693636 Test MSE 0.009888838067066183 Test RE 0.07184697862627801\n",
      "87 Train Loss 0.356998 Test MSE 0.010199441159154698 Test RE 0.07296659248416786\n",
      "88 Train Loss 0.3430379 Test MSE 0.009381892653429886 Test RE 0.06998115510388002\n",
      "89 Train Loss 0.31645885 Test MSE 0.008008972387202896 Test RE 0.06465829897760306\n",
      "90 Train Loss 0.30695546 Test MSE 0.007544945639145163 Test RE 0.06275725429447018\n",
      "91 Train Loss 0.2952636 Test MSE 0.007378268244837347 Test RE 0.062060189462908234\n",
      "92 Train Loss 0.280147 Test MSE 0.00648141632504275 Test RE 0.05816621928341984\n",
      "93 Train Loss 0.2701823 Test MSE 0.006038959480844771 Test RE 0.05614575609850848\n",
      "94 Train Loss 0.25546524 Test MSE 0.005266187501687273 Test RE 0.05243050441279694\n",
      "95 Train Loss 0.23834583 Test MSE 0.0046910187947271816 Test RE 0.049484531555305154\n",
      "96 Train Loss 0.2302558 Test MSE 0.0042288292696744 Test RE 0.04698356346981697\n",
      "97 Train Loss 0.22369048 Test MSE 0.0038946975795825342 Test RE 0.04508922256777429\n",
      "98 Train Loss 0.21687528 Test MSE 0.003669453579331336 Test RE 0.04376597177039531\n",
      "99 Train Loss 0.21233469 Test MSE 0.003525079872779572 Test RE 0.042896351746249534\n",
      "100 Train Loss 0.20769942 Test MSE 0.003489359671238663 Test RE 0.04267846054196951\n",
      "101 Train Loss 0.20079772 Test MSE 0.0032412183556882316 Test RE 0.04113296554423903\n",
      "102 Train Loss 0.19593821 Test MSE 0.003241120395422379 Test RE 0.04113234395287374\n",
      "103 Train Loss 0.18919487 Test MSE 0.003285558207725545 Test RE 0.04141335924417189\n",
      "104 Train Loss 0.18295018 Test MSE 0.0032942122385376613 Test RE 0.04146786395488787\n",
      "105 Train Loss 0.17930566 Test MSE 0.0031479243463789046 Test RE 0.04053666539501504\n",
      "106 Train Loss 0.17156066 Test MSE 0.0026680483641009075 Test RE 0.037319234412841934\n",
      "107 Train Loss 0.16547482 Test MSE 0.0024702080703476073 Test RE 0.035908944935650555\n",
      "108 Train Loss 0.15853086 Test MSE 0.0025298633437593563 Test RE 0.03633995691793364\n",
      "109 Train Loss 0.15192428 Test MSE 0.002371765534598665 Test RE 0.03518615032557198\n",
      "110 Train Loss 0.14476565 Test MSE 0.002065735655692852 Test RE 0.03283773923193609\n",
      "111 Train Loss 0.1398681 Test MSE 0.0019528928466455593 Test RE 0.03192824771101487\n",
      "112 Train Loss 0.13629968 Test MSE 0.0018417390268824078 Test RE 0.031006298406497025\n",
      "113 Train Loss 0.13122684 Test MSE 0.0015439785198915462 Test RE 0.028389418954520133\n",
      "114 Train Loss 0.1276823 Test MSE 0.001470495870248535 Test RE 0.02770561414206532\n",
      "115 Train Loss 0.124253646 Test MSE 0.0014558059740537475 Test RE 0.027566880619518477\n",
      "116 Train Loss 0.120040886 Test MSE 0.001399734585249219 Test RE 0.02703078907168668\n",
      "117 Train Loss 0.11547453 Test MSE 0.0013052648860995835 Test RE 0.026102686314969908\n",
      "118 Train Loss 0.11221169 Test MSE 0.001291958597654029 Test RE 0.02596929591430393\n",
      "119 Train Loss 0.10963333 Test MSE 0.0012837030505863053 Test RE 0.025886191730420244\n",
      "120 Train Loss 0.1063153 Test MSE 0.0013155311847111554 Test RE 0.02620513797267898\n",
      "121 Train Loss 0.10112501 Test MSE 0.0013002714528576082 Test RE 0.026052709133569205\n",
      "122 Train Loss 0.09675818 Test MSE 0.0012313248586658606 Test RE 0.02535258226250521\n",
      "123 Train Loss 0.094506234 Test MSE 0.0011506290706824714 Test RE 0.02450775601178219\n",
      "124 Train Loss 0.090720974 Test MSE 0.0010309104417580844 Test RE 0.023197775765178456\n",
      "125 Train Loss 0.08633184 Test MSE 0.0010118061889086648 Test RE 0.022981826553672462\n",
      "126 Train Loss 0.08456091 Test MSE 0.0009310692482222219 Test RE 0.022045851022951566\n",
      "127 Train Loss 0.08321132 Test MSE 0.000917606311616222 Test RE 0.021885882988307445\n",
      "128 Train Loss 0.08169253 Test MSE 0.0008904841284790333 Test RE 0.021560010524237443\n",
      "129 Train Loss 0.08015462 Test MSE 0.0008899754495041659 Test RE 0.021553851688633496\n",
      "130 Train Loss 0.078389555 Test MSE 0.000822596709181794 Test RE 0.020721889847966145\n",
      "131 Train Loss 0.076798744 Test MSE 0.0008765625172307265 Test RE 0.021390814659663908\n",
      "132 Train Loss 0.074807666 Test MSE 0.0009220415292893707 Test RE 0.0219387115499316\n",
      "133 Train Loss 0.072919376 Test MSE 0.0009112124798934367 Test RE 0.021809499866026504\n",
      "134 Train Loss 0.07148942 Test MSE 0.0008851138142653514 Test RE 0.021494900365250487\n",
      "135 Train Loss 0.07028659 Test MSE 0.0009303580451500008 Test RE 0.02203742948379561\n",
      "136 Train Loss 0.06894116 Test MSE 0.0008675144012460492 Test RE 0.021280127388183138\n",
      "137 Train Loss 0.06714343 Test MSE 0.0008949965404909741 Test RE 0.021614567764805023\n",
      "138 Train Loss 0.0657651 Test MSE 0.0009080807972502416 Test RE 0.02177198983460956\n",
      "139 Train Loss 0.0648066 Test MSE 0.000926342428372288 Test RE 0.0219898190137683\n",
      "140 Train Loss 0.06377839 Test MSE 0.0008610942308088879 Test RE 0.02120123777134545\n",
      "141 Train Loss 0.062381588 Test MSE 0.000860850673578904 Test RE 0.021198239214541233\n",
      "142 Train Loss 0.061114483 Test MSE 0.0008364812859535074 Test RE 0.020896040027237717\n",
      "143 Train Loss 0.05976001 Test MSE 0.0008506483236499648 Test RE 0.021072249614029412\n",
      "144 Train Loss 0.058565628 Test MSE 0.0008598388985489894 Test RE 0.021185778194586394\n",
      "145 Train Loss 0.057851173 Test MSE 0.000867755946360334 Test RE 0.021283089732698435\n",
      "146 Train Loss 0.05688252 Test MSE 0.0009194775869178447 Test RE 0.021908187572197223\n",
      "147 Train Loss 0.0554448 Test MSE 0.0009226657656036668 Test RE 0.02194613671618837\n",
      "148 Train Loss 0.05448158 Test MSE 0.0008754366025728878 Test RE 0.02137707235942328\n",
      "149 Train Loss 0.05419495 Test MSE 0.0008771340294425084 Test RE 0.021397786849060914\n",
      "150 Train Loss 0.05311513 Test MSE 0.0008251996280586262 Test RE 0.020754648791009064\n",
      "151 Train Loss 0.051950622 Test MSE 0.000825949246814176 Test RE 0.02076407350582962\n",
      "152 Train Loss 0.050929442 Test MSE 0.0008214514916326353 Test RE 0.020707460336527997\n",
      "153 Train Loss 0.050060622 Test MSE 0.0007944734259891283 Test RE 0.02036458501331638\n",
      "154 Train Loss 0.049377635 Test MSE 0.0008160544153901068 Test RE 0.020639322461660524\n",
      "155 Train Loss 0.048676345 Test MSE 0.0008234024287939735 Test RE 0.020732035735067256\n",
      "156 Train Loss 0.04725175 Test MSE 0.0008040276430820642 Test RE 0.02048666977453278\n",
      "157 Train Loss 0.04707646 Test MSE 0.000826028442461466 Test RE 0.02076506895732452\n",
      "158 Train Loss 0.046012416 Test MSE 0.000805189510084249 Test RE 0.020501466649306518\n",
      "159 Train Loss 0.0453188 Test MSE 0.0007473929109837503 Test RE 0.01975196757671781\n",
      "160 Train Loss 0.044681206 Test MSE 0.000734756934079281 Test RE 0.019584285134026703\n",
      "161 Train Loss 0.043944 Test MSE 0.0007371073799549837 Test RE 0.019615584632928937\n",
      "162 Train Loss 0.043519255 Test MSE 0.0007134254546123434 Test RE 0.01929790558220562\n",
      "163 Train Loss 0.043038853 Test MSE 0.000707994164006593 Test RE 0.01922430799790225\n",
      "164 Train Loss 0.042528685 Test MSE 0.0006703488467105378 Test RE 0.018706231736357735\n",
      "165 Train Loss 0.041450705 Test MSE 0.000612694979673548 Test RE 0.017883727254270416\n",
      "166 Train Loss 0.040516574 Test MSE 0.000613929114961131 Test RE 0.017901729552773145\n",
      "167 Train Loss 0.039147943 Test MSE 0.0005378145587667315 Test RE 0.016755297914921856\n",
      "168 Train Loss 0.038464166 Test MSE 0.0005181824446920699 Test RE 0.016446641455209455\n",
      "169 Train Loss 0.037645604 Test MSE 0.0005201643897594492 Test RE 0.01647806400828112\n",
      "170 Train Loss 0.03670585 Test MSE 0.0005171582677398566 Test RE 0.016430380191810173\n",
      "171 Train Loss 0.036077503 Test MSE 0.00046487333566689703 Test RE 0.015577694954679188\n",
      "172 Train Loss 0.035538312 Test MSE 0.0004307661140854645 Test RE 0.014995351251614426\n",
      "173 Train Loss 0.034983106 Test MSE 0.0004175421759721579 Test RE 0.01476338862129889\n",
      "174 Train Loss 0.034487627 Test MSE 0.0004052686286790355 Test RE 0.014544787157075861\n",
      "175 Train Loss 0.034077674 Test MSE 0.0004082154940144802 Test RE 0.014597571769990028\n",
      "176 Train Loss 0.03396096 Test MSE 0.0003984555243105865 Test RE 0.014422010356451683\n",
      "177 Train Loss 0.033292312 Test MSE 0.0003699888186807318 Test RE 0.013897291807630684\n",
      "178 Train Loss 0.033656754 Test MSE 0.0003675626355261431 Test RE 0.0138516514658816\n",
      "179 Train Loss 0.032960527 Test MSE 0.0003731097614806282 Test RE 0.013955782185888358\n",
      "180 Train Loss 0.032450937 Test MSE 0.00037452867456162786 Test RE 0.013982293487887145\n",
      "181 Train Loss 0.03181248 Test MSE 0.0003589663217094378 Test RE 0.013688716506538625\n",
      "182 Train Loss 0.03114058 Test MSE 0.00037200913025228256 Test RE 0.013935183000739227\n",
      "183 Train Loss 0.030423366 Test MSE 0.00038562922958282374 Test RE 0.014187989201816692\n",
      "184 Train Loss 0.030131545 Test MSE 0.0003762096671954317 Test RE 0.014013636639482038\n",
      "185 Train Loss 0.029650213 Test MSE 0.00038067253359689245 Test RE 0.014096511441998544\n",
      "186 Train Loss 0.029359566 Test MSE 0.0003615008754487591 Test RE 0.013736957467311134\n",
      "187 Train Loss 0.028950159 Test MSE 0.0003628427733423838 Test RE 0.013762429770086907\n",
      "188 Train Loss 0.028882263 Test MSE 0.00035580557923725777 Test RE 0.013628317844624\n",
      "189 Train Loss 0.028001744 Test MSE 0.00033464250573055787 Test RE 0.013216803361152926\n",
      "190 Train Loss 0.027291492 Test MSE 0.0003413255035985492 Test RE 0.013348124438346527\n",
      "191 Train Loss 0.026845483 Test MSE 0.0003266131594946876 Test RE 0.013057279972531494\n",
      "192 Train Loss 0.02667002 Test MSE 0.00032292999597742554 Test RE 0.012983448824863677\n",
      "193 Train Loss 0.026202312 Test MSE 0.00031582049418447174 Test RE 0.012839734139133259\n",
      "194 Train Loss 0.025947835 Test MSE 0.0003315334752823188 Test RE 0.013155264061178604\n",
      "195 Train Loss 0.025881145 Test MSE 0.00033301474709842806 Test RE 0.013184619775870142\n",
      "196 Train Loss 0.025369376 Test MSE 0.00031247012683846824 Test RE 0.01277144768505604\n",
      "197 Train Loss 0.02503033 Test MSE 0.00031481606480645517 Test RE 0.012819300258526475\n",
      "198 Train Loss 0.024737654 Test MSE 0.0003253915857705822 Test RE 0.01303283917496857\n",
      "199 Train Loss 0.024229659 Test MSE 0.00032577469884720556 Test RE 0.013040509290766162\n",
      "200 Train Loss 0.02388429 Test MSE 0.0003224334327710729 Test RE 0.012973462785533128\n",
      "201 Train Loss 0.023619998 Test MSE 0.00031189963441534044 Test RE 0.012759783621581587\n",
      "202 Train Loss 0.023301134 Test MSE 0.00028650783527579967 Test RE 0.012229371232615709\n",
      "203 Train Loss 0.022866968 Test MSE 0.0002869927076801894 Test RE 0.012239715064868517\n",
      "204 Train Loss 0.022687884 Test MSE 0.0002753134199374957 Test RE 0.011988078207495747\n",
      "205 Train Loss 0.022374615 Test MSE 0.00023662270357166794 Test RE 0.01111383853576641\n",
      "206 Train Loss 0.02206785 Test MSE 0.00022683713640106207 Test RE 0.010881604947091658\n",
      "207 Train Loss 0.021788385 Test MSE 0.00021085431671638585 Test RE 0.010491247319592688\n",
      "208 Train Loss 0.021420904 Test MSE 0.0002185025561801432 Test RE 0.010679825036917947\n",
      "209 Train Loss 0.021114923 Test MSE 0.00022325919236441526 Test RE 0.010795445060691933\n",
      "210 Train Loss 0.020921635 Test MSE 0.00022086852975520353 Test RE 0.01073749060918456\n",
      "211 Train Loss 0.02083887 Test MSE 0.00022728818298124818 Test RE 0.010892418152895288\n",
      "212 Train Loss 0.020625684 Test MSE 0.00022901160782972372 Test RE 0.010933636338354938\n",
      "213 Train Loss 0.020375505 Test MSE 0.0002243153929950711 Test RE 0.010820950622542128\n",
      "214 Train Loss 0.02026589 Test MSE 0.00021538461594128216 Test RE 0.010603352928533212\n",
      "215 Train Loss 0.020208627 Test MSE 0.00021463811364396307 Test RE 0.01058496188021261\n",
      "216 Train Loss 0.019975169 Test MSE 0.00020931599641990555 Test RE 0.010452907003002207\n",
      "217 Train Loss 0.019792615 Test MSE 0.00020888793684335766 Test RE 0.01044221322665444\n",
      "218 Train Loss 0.019728653 Test MSE 0.00020274996421259346 Test RE 0.010287652119406597\n",
      "219 Train Loss 0.019642865 Test MSE 0.0002015812335932329 Test RE 0.010257958227131485\n",
      "220 Train Loss 0.019402683 Test MSE 0.00020139627623731732 Test RE 0.01025325114155138\n",
      "221 Train Loss 0.019164829 Test MSE 0.0002016143092751197 Test RE 0.010258799761436265\n",
      "222 Train Loss 0.019063383 Test MSE 0.00020057776428720662 Test RE 0.010232394368046486\n",
      "223 Train Loss 0.018848896 Test MSE 0.00019893591712438448 Test RE 0.010190429226284355\n",
      "224 Train Loss 0.018672206 Test MSE 0.0001989046228495427 Test RE 0.010189627675111376\n",
      "225 Train Loss 0.018506993 Test MSE 0.00019573670166918278 Test RE 0.010108157722287838\n",
      "226 Train Loss 0.018482832 Test MSE 0.00019315390171811828 Test RE 0.0100412462912356\n",
      "227 Train Loss 0.018419007 Test MSE 0.0001913302420495794 Test RE 0.009993731735073518\n",
      "228 Train Loss 0.01826763 Test MSE 0.00019064338279391007 Test RE 0.009975777284429683\n",
      "229 Train Loss 0.018073756 Test MSE 0.00018967349983628392 Test RE 0.009950369443721992\n",
      "230 Train Loss 0.018021269 Test MSE 0.00018815015030439823 Test RE 0.009910331039916547\n",
      "231 Train Loss 0.017888857 Test MSE 0.00019263740612659376 Test RE 0.010027812104641069\n",
      "232 Train Loss 0.01766205 Test MSE 0.00019071826664927242 Test RE 0.009977736312091109\n",
      "233 Train Loss 0.01780193 Test MSE 0.00018998961526097533 Test RE 0.009958657780719644\n",
      "234 Train Loss 0.017556608 Test MSE 0.00018917474986043602 Test RE 0.009937278492089831\n",
      "235 Train Loss 0.017443731 Test MSE 0.00019266308365893832 Test RE 0.010028480409138413\n",
      "236 Train Loss 0.017322047 Test MSE 0.00018878770393580076 Test RE 0.009927107598631793\n",
      "237 Train Loss 0.01720439 Test MSE 0.00018492891623469744 Test RE 0.009825129632406856\n",
      "238 Train Loss 0.017457105 Test MSE 0.00018512148245240678 Test RE 0.009830243748185717\n",
      "239 Train Loss 0.017153278 Test MSE 0.00018655356647132303 Test RE 0.009868193459777236\n",
      "240 Train Loss 0.017062318 Test MSE 0.00018853971600518856 Test RE 0.009920585426385511\n",
      "241 Train Loss 0.016922386 Test MSE 0.00019643588154948091 Test RE 0.01012619501527096\n",
      "242 Train Loss 0.016853485 Test MSE 0.00019463270570181545 Test RE 0.010079611350838489\n",
      "243 Train Loss 0.016795373 Test MSE 0.00019518908085205307 Test RE 0.010094007809033108\n",
      "244 Train Loss 0.016622238 Test MSE 0.0001949647387886014 Test RE 0.01008820532872064\n",
      "245 Train Loss 0.016468668 Test MSE 0.00019312333006068287 Test RE 0.010040451614848333\n",
      "246 Train Loss 0.016302574 Test MSE 0.00019026494453664063 Test RE 0.009965871115427426\n",
      "247 Train Loss 0.016285164 Test MSE 0.00019378471625881906 Test RE 0.010057629602438872\n",
      "248 Train Loss 0.016049344 Test MSE 0.00019785295388702212 Test RE 0.010162654150264985\n",
      "249 Train Loss 0.01596849 Test MSE 0.0001994429134430337 Test RE 0.010203406326146927\n",
      "250 Train Loss 0.015791135 Test MSE 0.00020365079679706742 Test RE 0.010310481176614568\n",
      "251 Train Loss 0.015720911 Test MSE 0.00020553125886206634 Test RE 0.010357974035413898\n",
      "252 Train Loss 0.015753292 Test MSE 0.00020550242724560357 Test RE 0.01035724750940953\n",
      "253 Train Loss 0.015599598 Test MSE 0.00020242565390436967 Test RE 0.010279420978901267\n",
      "254 Train Loss 0.015430001 Test MSE 0.00020218515159041724 Test RE 0.010273312663986484\n",
      "255 Train Loss 0.015333401 Test MSE 0.00019830234112089677 Test RE 0.010174188920478234\n",
      "256 Train Loss 0.015286402 Test MSE 0.00019831122946953388 Test RE 0.010174416932725592\n",
      "257 Train Loss 0.015167643 Test MSE 0.00019760161906406379 Test RE 0.010156197232353321\n",
      "258 Train Loss 0.015033099 Test MSE 0.00020342833107089538 Test RE 0.010304848113864182\n",
      "259 Train Loss 0.015037346 Test MSE 0.0002059681375712773 Test RE 0.010368976683420253\n",
      "260 Train Loss 0.014916829 Test MSE 0.00020664447150545512 Test RE 0.010385986943557314\n",
      "261 Train Loss 0.014793612 Test MSE 0.00020913121896723498 Test RE 0.010448292238702325\n",
      "262 Train Loss 0.014651643 Test MSE 0.00021000287980945282 Test RE 0.01047004388603054\n",
      "263 Train Loss 0.014523157 Test MSE 0.000204838062564321 Test RE 0.01034049208735955\n",
      "264 Train Loss 0.014437166 Test MSE 0.00019812096572697808 Test RE 0.010169534992381891\n",
      "265 Train Loss 0.014404904 Test MSE 0.00019161981410203193 Test RE 0.010001291468572126\n",
      "266 Train Loss 0.014234352 Test MSE 0.00019434286383789959 Test RE 0.010072103409677869\n",
      "267 Train Loss 0.014134177 Test MSE 0.0001940795683706357 Test RE 0.010065278260708879\n",
      "268 Train Loss 0.013973691 Test MSE 0.00019384094951700086 Test RE 0.010059088779067702\n",
      "269 Train Loss 0.01395832 Test MSE 0.0001880414079892394 Test RE 0.00990746676344357\n",
      "270 Train Loss 0.013800679 Test MSE 0.00018192000960960306 Test RE 0.009744871395342235\n",
      "271 Train Loss 0.013677478 Test MSE 0.0001829983737273354 Test RE 0.009773710973955107\n",
      "272 Train Loss 0.013577001 Test MSE 0.0001837211220637558 Test RE 0.009792992490581713\n",
      "273 Train Loss 0.013428515 Test MSE 0.00018276847780681447 Test RE 0.009767569819882364\n",
      "274 Train Loss 0.013349165 Test MSE 0.00017640915205139742 Test RE 0.009596136857165155\n",
      "275 Train Loss 0.0131324185 Test MSE 0.0001786453725372964 Test RE 0.00965676721460033\n",
      "276 Train Loss 0.0129909925 Test MSE 0.00017765188095943412 Test RE 0.009629877929638405\n",
      "277 Train Loss 0.012927617 Test MSE 0.00017855444609047582 Test RE 0.009654309363959815\n",
      "278 Train Loss 0.012994054 Test MSE 0.00018670117169408676 Test RE 0.009872096652068403\n",
      "279 Train Loss 0.012833554 Test MSE 0.00018360989620376175 Test RE 0.009790027673835138\n",
      "280 Train Loss 0.01279538 Test MSE 0.0001871123991271844 Test RE 0.00988296279695971\n",
      "281 Train Loss 0.012700445 Test MSE 0.0001884186427471988 Test RE 0.009917399597652721\n",
      "282 Train Loss 0.012652014 Test MSE 0.00019144800299189304 Test RE 0.009996806759237826\n",
      "283 Train Loss 0.012501921 Test MSE 0.00018825871175142864 Test RE 0.00991318972678788\n",
      "284 Train Loss 0.01246063 Test MSE 0.000193903613515607 Test RE 0.010060714575349315\n",
      "285 Train Loss 0.012416157 Test MSE 0.00018667771594377676 Test RE 0.009871476504092756\n",
      "286 Train Loss 0.012391081 Test MSE 0.0001808710640522589 Test RE 0.009716736455922751\n",
      "287 Train Loss 0.0123443585 Test MSE 0.00018363656565126778 Test RE 0.00979073865171318\n",
      "288 Train Loss 0.012206814 Test MSE 0.000176652680497873 Test RE 0.009602758186928401\n",
      "289 Train Loss 0.012133915 Test MSE 0.0001798138862822859 Test RE 0.009688298042927285\n",
      "290 Train Loss 0.012112514 Test MSE 0.00018396400716714855 Test RE 0.009799463674595173\n",
      "291 Train Loss 0.011957063 Test MSE 0.00018086016480460461 Test RE 0.009716443687388762\n",
      "292 Train Loss 0.011905756 Test MSE 0.00018091850641490092 Test RE 0.00971801071919976\n",
      "293 Train Loss 0.011825625 Test MSE 0.00017521000826469882 Test RE 0.009563466302654797\n",
      "294 Train Loss 0.011744145 Test MSE 0.00018012047575559074 Test RE 0.009696553982450432\n",
      "295 Train Loss 0.011663713 Test MSE 0.00018294560399983138 Test RE 0.009772301690252928\n",
      "296 Train Loss 0.01157621 Test MSE 0.00018155683322500373 Test RE 0.009735139438806467\n",
      "297 Train Loss 0.011472385 Test MSE 0.0001868048844815707 Test RE 0.009874838253802788\n",
      "298 Train Loss 0.0113997655 Test MSE 0.00018791374992133868 Test RE 0.009904103188344506\n",
      "299 Train Loss 0.011367097 Test MSE 0.00019121782985741088 Test RE 0.009990795496821307\n",
      "Training time: 173.52\n",
      "KG_tanhALR_high\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 53131.15 Test MSE 6.465875019595121 Test RE 1.8371707816418905\n",
      "1 Train Loss 27491.176 Test MSE 12.325447342671081 Test RE 2.536513757650224\n",
      "2 Train Loss 12660.838 Test MSE 11.557513688102498 Test RE 2.4562246478213776\n",
      "3 Train Loss 4389.7285 Test MSE 12.891115823320938 Test RE 2.5940666606825595\n",
      "4 Train Loss 1779.7687 Test MSE 15.430595235755625 Test RE 2.8380968819205585\n",
      "5 Train Loss 1250.893 Test MSE 15.612632043863627 Test RE 2.854788503316965\n",
      "6 Train Loss 1046.987 Test MSE 16.685440044939384 Test RE 2.951241228377332\n",
      "7 Train Loss 860.797 Test MSE 16.483264249234775 Test RE 2.9333067890639355\n",
      "8 Train Loss 714.0468 Test MSE 16.27249709526866 Test RE 2.914492742748624\n",
      "9 Train Loss 553.4793 Test MSE 14.16396580217034 Test RE 2.7191196079992226\n",
      "10 Train Loss 384.794 Test MSE 13.826161840464373 Test RE 2.686499072537793\n",
      "11 Train Loss 291.4582 Test MSE 12.629021235350182 Test RE 2.56756072393923\n",
      "12 Train Loss 229.91795 Test MSE 11.523371527419167 Test RE 2.452593986243909\n",
      "13 Train Loss 194.73466 Test MSE 10.685404840296487 Test RE 2.3617360967932957\n",
      "14 Train Loss 165.8164 Test MSE 9.944953854873244 Test RE 2.2784382509349865\n",
      "15 Train Loss 146.2203 Test MSE 9.26365831607138 Test RE 2.1990096788828866\n",
      "16 Train Loss 126.77216 Test MSE 8.218236928634928 Test RE 2.0712151100041476\n",
      "17 Train Loss 94.32959 Test MSE 5.88985955115263 Test RE 1.753429650832769\n",
      "18 Train Loss 66.70322 Test MSE 4.595664552087698 Test RE 1.548852415576185\n",
      "19 Train Loss 33.683186 Test MSE 1.697596077840799 Test RE 0.9413541866751771\n",
      "20 Train Loss 22.7058 Test MSE 0.8004239926588664 Test RE 0.6463919302653593\n",
      "21 Train Loss 14.5370865 Test MSE 0.3424213595474515 Test RE 0.4227818166317024\n",
      "22 Train Loss 8.069989 Test MSE 0.08468559269928103 Test RE 0.21025224541952017\n",
      "23 Train Loss 5.8612013 Test MSE 0.04315976359526768 Test RE 0.1500981728150198\n",
      "24 Train Loss 4.6134315 Test MSE 0.03700234339133019 Test RE 0.13897941890434015\n",
      "25 Train Loss 3.7292533 Test MSE 0.030716327614231875 Test RE 0.1266253102387123\n",
      "26 Train Loss 2.921357 Test MSE 0.02839519017869181 Test RE 0.12174699980754525\n",
      "27 Train Loss 2.4945073 Test MSE 0.02198657617039056 Test RE 0.10713088170644543\n",
      "28 Train Loss 2.1583722 Test MSE 0.018346229240461226 Test RE 0.09786091786274881\n",
      "29 Train Loss 1.8463826 Test MSE 0.01898396894371182 Test RE 0.09954727685277909\n",
      "30 Train Loss 1.544714 Test MSE 0.017082715751686572 Test RE 0.0944309446328582\n",
      "31 Train Loss 1.372082 Test MSE 0.014866137141705997 Test RE 0.08809169051321634\n",
      "32 Train Loss 1.2053256 Test MSE 0.012506098327890923 Test RE 0.0807972903544502\n",
      "33 Train Loss 1.007625 Test MSE 0.011242339946176537 Test RE 0.07660625531543025\n",
      "34 Train Loss 0.8897129 Test MSE 0.010960494430511104 Test RE 0.07563990065139974\n",
      "35 Train Loss 0.79520977 Test MSE 0.008674451951637725 Test RE 0.06729098721064439\n",
      "36 Train Loss 0.70768154 Test MSE 0.0074166338091534376 Test RE 0.06222133073491135\n",
      "37 Train Loss 0.59285235 Test MSE 0.006714645641486802 Test RE 0.05920350597341167\n",
      "38 Train Loss 0.5263213 Test MSE 0.006207843455416272 Test RE 0.05692542153113065\n",
      "39 Train Loss 0.4627705 Test MSE 0.005154509082689721 Test RE 0.05187158654184489\n",
      "40 Train Loss 0.39347333 Test MSE 0.0042368476184966395 Test RE 0.04702808550709015\n",
      "41 Train Loss 0.36996576 Test MSE 0.004068937120160543 Test RE 0.04608678003394098\n",
      "42 Train Loss 0.33376238 Test MSE 0.004272249395505445 Test RE 0.04722415279582291\n",
      "43 Train Loss 0.30252984 Test MSE 0.003736738438572622 Test RE 0.04416540594952048\n",
      "44 Train Loss 0.28862855 Test MSE 0.003139037623390046 Test RE 0.04047940659875182\n",
      "45 Train Loss 0.25589368 Test MSE 0.0027343089132936364 Test RE 0.03777980099807659\n",
      "46 Train Loss 0.24386448 Test MSE 0.0026987601708347362 Test RE 0.03753341000292045\n",
      "47 Train Loss 0.228484 Test MSE 0.002696738980138955 Test RE 0.0375193523646865\n",
      "48 Train Loss 0.21552664 Test MSE 0.0025549272206717094 Test RE 0.0365195269715551\n",
      "49 Train Loss 0.20119832 Test MSE 0.0021485641180466713 Test RE 0.033489605846236455\n",
      "50 Train Loss 0.19154866 Test MSE 0.001733710202660972 Test RE 0.030083206814108008\n",
      "51 Train Loss 0.1818904 Test MSE 0.0015603234594057363 Test RE 0.028539292065052832\n",
      "52 Train Loss 0.17296378 Test MSE 0.001368616977935167 Test RE 0.026728638574352846\n",
      "53 Train Loss 0.16414814 Test MSE 0.0012135318201221908 Test RE 0.025168739231585222\n",
      "54 Train Loss 0.15925007 Test MSE 0.0011879430403589429 Test RE 0.024901968857931125\n",
      "55 Train Loss 0.1532669 Test MSE 0.000998697848007988 Test RE 0.022832472009970087\n",
      "56 Train Loss 0.1460021 Test MSE 0.0009783631357059331 Test RE 0.02259882801592869\n",
      "57 Train Loss 0.13875602 Test MSE 0.0008860218573662481 Test RE 0.02150592340672334\n",
      "58 Train Loss 0.12973851 Test MSE 0.0008359873448529406 Test RE 0.020889869574098403\n",
      "59 Train Loss 0.12503558 Test MSE 0.0007544884985833412 Test RE 0.019845506558062147\n",
      "60 Train Loss 0.11927707 Test MSE 0.0006004874345603255 Test RE 0.017704670107161275\n",
      "61 Train Loss 0.10807384 Test MSE 0.0004073308775440673 Test RE 0.014581746481561677\n",
      "62 Train Loss 0.102782026 Test MSE 0.00034577339124059766 Test RE 0.01343481410580787\n",
      "63 Train Loss 0.09952797 Test MSE 0.0003730907742494326 Test RE 0.013955427082562888\n",
      "64 Train Loss 0.09318281 Test MSE 0.0003803959909251258 Test RE 0.01409139024880029\n",
      "65 Train Loss 0.08769201 Test MSE 0.00035844782126787306 Test RE 0.01367882676205753\n",
      "66 Train Loss 0.08048584 Test MSE 0.0003177822354855384 Test RE 0.012879549862942825\n",
      "67 Train Loss 0.07716454 Test MSE 0.0003320252667457722 Test RE 0.013165017599783568\n",
      "68 Train Loss 0.07471558 Test MSE 0.0003617866319282746 Test RE 0.013742385737950447\n",
      "69 Train Loss 0.07185266 Test MSE 0.0003759052346224839 Test RE 0.01400796550547851\n",
      "70 Train Loss 0.06702193 Test MSE 0.0003158904524229259 Test RE 0.012841156142235455\n",
      "71 Train Loss 0.06402267 Test MSE 0.0002905449335296949 Test RE 0.012315230087293091\n",
      "72 Train Loss 0.0622315 Test MSE 0.0002609731678434145 Test RE 0.011671691649329378\n",
      "73 Train Loss 0.05909113 Test MSE 0.0002863038213722529 Test RE 0.012225016367300544\n",
      "74 Train Loss 0.0553155 Test MSE 0.0002705081430640933 Test RE 0.011882998668557705\n",
      "75 Train Loss 0.05237227 Test MSE 0.00033820493307134934 Test RE 0.013286966678477487\n",
      "76 Train Loss 0.05078996 Test MSE 0.00032834456667213955 Test RE 0.013091843163996086\n",
      "77 Train Loss 0.04848746 Test MSE 0.0003400229545227894 Test RE 0.013322630875536796\n",
      "78 Train Loss 0.047229387 Test MSE 0.0002724197619749143 Test RE 0.011924911962035155\n",
      "79 Train Loss 0.045711566 Test MSE 0.0002472380932348594 Test RE 0.01136039860050141\n",
      "80 Train Loss 0.04494642 Test MSE 0.00024475907748449147 Test RE 0.011303300686687535\n",
      "81 Train Loss 0.04296416 Test MSE 0.00021912618644314097 Test RE 0.010695054873819942\n",
      "82 Train Loss 0.041722 Test MSE 0.00023163743593200114 Test RE 0.010996139767955439\n",
      "83 Train Loss 0.04084078 Test MSE 0.00020093291661454066 Test RE 0.010241449338449516\n",
      "84 Train Loss 0.040213637 Test MSE 0.00021080027970372573 Test RE 0.010489902903221451\n",
      "85 Train Loss 0.03902731 Test MSE 0.00018925384897301872 Test RE 0.00993935579829174\n",
      "86 Train Loss 0.037640765 Test MSE 0.0001827201601372331 Test RE 0.00976627863057958\n",
      "87 Train Loss 0.036719546 Test MSE 0.00016415949118652378 Test RE 0.009256970411211277\n",
      "88 Train Loss 0.035570256 Test MSE 0.00015771548363797706 Test RE 0.009073462380254011\n",
      "89 Train Loss 0.03489922 Test MSE 0.00015903172439451612 Test RE 0.00911124575563698\n",
      "90 Train Loss 0.034183536 Test MSE 0.00016235090382128934 Test RE 0.009205835968036157\n",
      "91 Train Loss 0.033481255 Test MSE 0.00016302564370983488 Test RE 0.009224946130281835\n",
      "92 Train Loss 0.032727472 Test MSE 0.000163328563120535 Test RE 0.009233512630326084\n",
      "93 Train Loss 0.031603143 Test MSE 0.0001669338711551976 Test RE 0.009334866453712442\n",
      "94 Train Loss 0.030583186 Test MSE 0.00017131046576286554 Test RE 0.009456443341634785\n",
      "95 Train Loss 0.029873088 Test MSE 0.0001798623759007991 Test RE 0.009689604255197992\n",
      "96 Train Loss 0.029600885 Test MSE 0.00017065696976038797 Test RE 0.009438389416515954\n",
      "97 Train Loss 0.0286868 Test MSE 0.00017834144155772554 Test RE 0.00964854914527148\n",
      "98 Train Loss 0.028255077 Test MSE 0.00018448765904741592 Test RE 0.009813400805962198\n",
      "99 Train Loss 0.02703045 Test MSE 0.0002066272260709154 Test RE 0.010385553555251004\n",
      "100 Train Loss 0.025946006 Test MSE 0.00021197426012618676 Test RE 0.010519072319576536\n",
      "101 Train Loss 0.02526685 Test MSE 0.00020969739657636236 Test RE 0.01046242592654657\n",
      "102 Train Loss 0.024658352 Test MSE 0.00021414220258098469 Test RE 0.010572726785703621\n",
      "103 Train Loss 0.0239657 Test MSE 0.00019809483825202856 Test RE 0.01016886440956297\n",
      "104 Train Loss 0.023435421 Test MSE 0.00018181588013722755 Test RE 0.009742082055219654\n",
      "105 Train Loss 0.022888223 Test MSE 0.00017552246917454617 Test RE 0.00957199001183676\n",
      "106 Train Loss 0.022262236 Test MSE 0.00018025507287004674 Test RE 0.009700176237093452\n",
      "107 Train Loss 0.021792544 Test MSE 0.00016490121473428026 Test RE 0.009277859774811478\n",
      "108 Train Loss 0.021261187 Test MSE 0.00016493143479202313 Test RE 0.009278709873502836\n",
      "109 Train Loss 0.021117106 Test MSE 0.00015539504480710463 Test RE 0.009006466954786426\n",
      "110 Train Loss 0.02062293 Test MSE 0.00015326472744261774 Test RE 0.008944518888163507\n",
      "111 Train Loss 0.020304093 Test MSE 0.00015949153594133823 Test RE 0.009124408010294538\n",
      "112 Train Loss 0.019917132 Test MSE 0.00015574897209319062 Test RE 0.009016717672362002\n",
      "113 Train Loss 0.01919979 Test MSE 0.0001344921382660867 Test RE 0.008378848272176973\n",
      "114 Train Loss 0.018893812 Test MSE 0.00012734292085879822 Test RE 0.008153109599014524\n",
      "115 Train Loss 0.018703537 Test MSE 0.00011928425942360021 Test RE 0.007890916470797957\n",
      "116 Train Loss 0.018348413 Test MSE 0.00011978228483545642 Test RE 0.007907372051625157\n",
      "117 Train Loss 0.018048095 Test MSE 0.00011488649425306245 Test RE 0.007744089534513537\n",
      "118 Train Loss 0.01758823 Test MSE 0.00010062975020648643 Test RE 0.007247681070031653\n",
      "119 Train Loss 0.017217051 Test MSE 9.706318562580062e-05 Test RE 0.007118084631406313\n",
      "120 Train Loss 0.016874216 Test MSE 0.00010233762931761884 Test RE 0.007308925800451366\n",
      "121 Train Loss 0.016548732 Test MSE 0.00011215681799139802 Test RE 0.0076515375975174365\n",
      "122 Train Loss 0.016312625 Test MSE 0.00011149046795479266 Test RE 0.00762877394378253\n",
      "123 Train Loss 0.015994603 Test MSE 0.00011685836348580425 Test RE 0.007810265131385042\n",
      "124 Train Loss 0.015705869 Test MSE 0.00011049204301892795 Test RE 0.007594538338029391\n",
      "125 Train Loss 0.015508373 Test MSE 0.00010456364755897454 Test RE 0.007387988983820323\n",
      "126 Train Loss 0.015184393 Test MSE 0.00011242404413306117 Test RE 0.00766064749573523\n",
      "127 Train Loss 0.015028927 Test MSE 0.00011514200060770985 Test RE 0.007752696138751477\n",
      "128 Train Loss 0.014599554 Test MSE 9.466577610227884e-05 Test RE 0.007029628542416618\n",
      "129 Train Loss 0.014344799 Test MSE 8.038829569206474e-05 Test RE 0.006477870885229009\n",
      "130 Train Loss 0.014269274 Test MSE 7.28495952409365e-05 Test RE 0.006166652109260798\n",
      "131 Train Loss 0.014014605 Test MSE 7.327473817542307e-05 Test RE 0.006184619914562698\n",
      "132 Train Loss 0.013794071 Test MSE 7.275876709870739e-05 Test RE 0.006162806650371038\n",
      "133 Train Loss 0.013539332 Test MSE 6.787088588171508e-05 Test RE 0.005952201648652992\n",
      "134 Train Loss 0.013256925 Test MSE 7.02808038981557e-05 Test RE 0.006056953466375687\n",
      "135 Train Loss 0.013033121 Test MSE 7.101493932248687e-05 Test RE 0.006088505981686183\n",
      "136 Train Loss 0.012861996 Test MSE 7.102669801120121e-05 Test RE 0.006089010029735139\n",
      "137 Train Loss 0.012817915 Test MSE 7.854315399454766e-05 Test RE 0.0064030964748032744\n",
      "138 Train Loss 0.012614292 Test MSE 8.035390899929463e-05 Test RE 0.006476485258253531\n",
      "139 Train Loss 0.0124721415 Test MSE 7.883441997054534e-05 Test RE 0.00641495796891869\n",
      "140 Train Loss 0.012285644 Test MSE 7.450872221648146e-05 Test RE 0.006236478574659683\n",
      "141 Train Loss 0.012144613 Test MSE 7.20707579359274e-05 Test RE 0.006133599595061999\n",
      "142 Train Loss 0.011984109 Test MSE 6.81561115134455e-05 Test RE 0.005964695522387893\n",
      "143 Train Loss 0.011706928 Test MSE 6.753473748744814e-05 Test RE 0.0059374434312303185\n",
      "144 Train Loss 0.0114987595 Test MSE 6.636668224405119e-05 Test RE 0.005885873589024137\n",
      "145 Train Loss 0.011343902 Test MSE 6.496161693174319e-05 Test RE 0.005823234642412673\n",
      "146 Train Loss 0.011174384 Test MSE 6.097572429044584e-05 Test RE 0.005641756796381111\n",
      "147 Train Loss 0.011075765 Test MSE 5.942992714546928e-05 Test RE 0.005569785571806936\n",
      "148 Train Loss 0.010887424 Test MSE 5.409041480670491e-05 Test RE 0.005313687782297601\n",
      "149 Train Loss 0.010733138 Test MSE 5.153448261414357e-05 Test RE 0.005186624856366172\n",
      "150 Train Loss 0.01052605 Test MSE 5.240959992432398e-05 Test RE 0.005230477029127128\n",
      "151 Train Loss 0.010359249 Test MSE 5.176473811331525e-05 Test RE 0.005198198833962141\n",
      "152 Train Loss 0.010168519 Test MSE 4.7680514535585096e-05 Test RE 0.00498891774533072\n",
      "153 Train Loss 0.0099441735 Test MSE 4.628847165153475e-05 Test RE 0.004915552033233616\n",
      "154 Train Loss 0.009795022 Test MSE 4.490857281361257e-05 Test RE 0.004841729290606256\n",
      "155 Train Loss 0.009690321 Test MSE 4.4798040841730314e-05 Test RE 0.004835767226409898\n",
      "156 Train Loss 0.009525135 Test MSE 4.464880522909139e-05 Test RE 0.004827705816831034\n",
      "157 Train Loss 0.009408979 Test MSE 4.341692491160406e-05 Test RE 0.004760640721178949\n",
      "158 Train Loss 0.009299333 Test MSE 4.42482394910086e-05 Test RE 0.0048060012002059515\n",
      "159 Train Loss 0.009296676 Test MSE 4.3312077610680416e-05 Test RE 0.004754889023672306\n",
      "160 Train Loss 0.00919467 Test MSE 4.2026297257224376e-05 Test RE 0.004683779494160066\n",
      "161 Train Loss 0.009102483 Test MSE 4.228318099113946e-05 Test RE 0.00469807237547622\n",
      "162 Train Loss 0.009066267 Test MSE 4.159272558063626e-05 Test RE 0.004659556339707762\n",
      "163 Train Loss 0.009043531 Test MSE 4.108237696520061e-05 Test RE 0.0046308813997341484\n",
      "164 Train Loss 0.008939995 Test MSE 3.883363979670742e-05 Test RE 0.004502356977821264\n",
      "165 Train Loss 0.008863626 Test MSE 3.8452313155617964e-05 Test RE 0.0044801970130572315\n",
      "166 Train Loss 0.008821256 Test MSE 3.748897110561841e-05 Test RE 0.004423720072228191\n",
      "167 Train Loss 0.008643742 Test MSE 3.651609924682846e-05 Test RE 0.004365943048706282\n",
      "168 Train Loss 0.008546959 Test MSE 3.6214105539881124e-05 Test RE 0.004347852059984083\n",
      "169 Train Loss 0.008449787 Test MSE 3.536828389775599e-05 Test RE 0.004296777556113906\n",
      "170 Train Loss 0.008310697 Test MSE 3.700991832111138e-05 Test RE 0.004395364945453546\n",
      "171 Train Loss 0.00821742 Test MSE 3.6402622460951416e-05 Test RE 0.004359154006423695\n",
      "172 Train Loss 0.008144178 Test MSE 3.747117493118551e-05 Test RE 0.0044226699682008985\n",
      "173 Train Loss 0.008028295 Test MSE 3.8201107324741104e-05 Test RE 0.004465538652215485\n",
      "174 Train Loss 0.007945599 Test MSE 3.830299974866257e-05 Test RE 0.004471490070759511\n",
      "175 Train Loss 0.007908456 Test MSE 3.738004449141968e-05 Test RE 0.0044172886956892875\n",
      "176 Train Loss 0.007889861 Test MSE 3.7600405361865e-05 Test RE 0.004430289846807288\n",
      "177 Train Loss 0.0077745616 Test MSE 3.580312291643446e-05 Test RE 0.004323110452926707\n",
      "178 Train Loss 0.0076968474 Test MSE 3.434041915971677e-05 Test RE 0.004233881248711729\n",
      "179 Train Loss 0.0075873043 Test MSE 3.4476084902529993e-05 Test RE 0.00424223622042655\n",
      "180 Train Loss 0.007578695 Test MSE 3.5085023840583635e-05 Test RE 0.004279536796317063\n",
      "181 Train Loss 0.0074910503 Test MSE 3.591270822379419e-05 Test RE 0.0043297214325398225\n",
      "182 Train Loss 0.007381637 Test MSE 3.533335463702152e-05 Test RE 0.00429465531097767\n",
      "183 Train Loss 0.0073661455 Test MSE 3.405989206221382e-05 Test RE 0.00421655248533164\n",
      "184 Train Loss 0.007341119 Test MSE 3.382282294247024e-05 Test RE 0.004201852499153732\n",
      "185 Train Loss 0.007225847 Test MSE 3.344064848594527e-05 Test RE 0.004178046048547534\n",
      "186 Train Loss 0.007118378 Test MSE 3.3588115841240664e-05 Test RE 0.004187248137494104\n",
      "187 Train Loss 0.00703518 Test MSE 3.503609856810253e-05 Test RE 0.004276551896708739\n",
      "188 Train Loss 0.0070875958 Test MSE 3.461600373487654e-05 Test RE 0.004250835916703385\n",
      "189 Train Loss 0.007015098 Test MSE 3.439779740368086e-05 Test RE 0.004237416896861052\n",
      "190 Train Loss 0.0069122715 Test MSE 3.569976001701516e-05 Test RE 0.00431686557577523\n",
      "191 Train Loss 0.006787711 Test MSE 3.555691942791106e-05 Test RE 0.004308220676457589\n",
      "192 Train Loss 0.006755742 Test MSE 3.658669915100627e-05 Test RE 0.00437016154857761\n",
      "193 Train Loss 0.006697434 Test MSE 3.774592016396487e-05 Test RE 0.004438854252189907\n",
      "194 Train Loss 0.0067120465 Test MSE 3.6221414171635814e-05 Test RE 0.0043482907736571\n",
      "195 Train Loss 0.006642216 Test MSE 3.435885781313804e-05 Test RE 0.004235017760647416\n",
      "196 Train Loss 0.0065312614 Test MSE 3.403000686588569e-05 Test RE 0.004214702212985426\n",
      "197 Train Loss 0.00646186 Test MSE 3.1499312605043506e-05 Test RE 0.004054958512165142\n",
      "198 Train Loss 0.0063527846 Test MSE 3.2069579646348356e-05 Test RE 0.004091499576960965\n",
      "199 Train Loss 0.0062364126 Test MSE 3.0415254617422377e-05 Test RE 0.003984571324005555\n",
      "200 Train Loss 0.0061750454 Test MSE 2.814578715928204e-05 Test RE 0.0038330331607042125\n",
      "201 Train Loss 0.00609288 Test MSE 2.8431267359660753e-05 Test RE 0.0038524231731264995\n",
      "202 Train Loss 0.0060140304 Test MSE 2.783990315488e-05 Test RE 0.003812147859265074\n",
      "203 Train Loss 0.0059784045 Test MSE 2.7362837844249752e-05 Test RE 0.0037793441880223312\n",
      "204 Train Loss 0.0059059956 Test MSE 2.7573576535622085e-05 Test RE 0.003793869845587168\n",
      "205 Train Loss 0.0058425027 Test MSE 2.6913285909649984e-05 Test RE 0.0037481696474183385\n",
      "206 Train Loss 0.005790192 Test MSE 2.6243381100388707e-05 Test RE 0.0037012274164484765\n",
      "207 Train Loss 0.005735425 Test MSE 2.5473053575538616e-05 Test RE 0.003646501372850476\n",
      "208 Train Loss 0.0057027065 Test MSE 2.5443730279577258e-05 Test RE 0.003644401934148375\n",
      "209 Train Loss 0.0056393025 Test MSE 2.4444852111856043e-05 Test RE 0.0035721491503543008\n",
      "210 Train Loss 0.005581707 Test MSE 2.4696062644655145e-05 Test RE 0.003590457050037483\n",
      "211 Train Loss 0.005531296 Test MSE 2.5063212814048526e-05 Test RE 0.003617047797383209\n",
      "212 Train Loss 0.005496587 Test MSE 2.55500801538742e-05 Test RE 0.0036520104397293374\n",
      "213 Train Loss 0.0054461192 Test MSE 2.585025041292315e-05 Test RE 0.0036734002747300285\n",
      "214 Train Loss 0.0053740013 Test MSE 2.7322598854257335e-05 Test RE 0.003776564269050308\n",
      "215 Train Loss 0.0053240634 Test MSE 2.8339488519127878e-05 Test RE 0.0038462001523718297\n",
      "216 Train Loss 0.005328321 Test MSE 2.8477078362701184e-05 Test RE 0.003855525608435335\n",
      "217 Train Loss 0.005271483 Test MSE 2.6400700772836557e-05 Test RE 0.003712304606817637\n",
      "218 Train Loss 0.005246992 Test MSE 2.6324789926413296e-05 Test RE 0.0037069637060326605\n",
      "219 Train Loss 0.005164312 Test MSE 2.5619533448534847e-05 Test RE 0.0036569707376625077\n",
      "220 Train Loss 0.0051327385 Test MSE 2.403109519387976e-05 Test RE 0.0035417887880501856\n",
      "221 Train Loss 0.005095147 Test MSE 2.3410632305344315e-05 Test RE 0.00349576676260714\n",
      "222 Train Loss 0.0050687967 Test MSE 2.3349853624581227e-05 Test RE 0.0034912259588598398\n",
      "223 Train Loss 0.005029295 Test MSE 2.264758945227438e-05 Test RE 0.003438324554503289\n",
      "224 Train Loss 0.0049920147 Test MSE 2.2526318340619704e-05 Test RE 0.0034291065949456144\n",
      "225 Train Loss 0.0049582026 Test MSE 2.289652841461354e-05 Test RE 0.0034571696884434272\n",
      "226 Train Loss 0.0049153757 Test MSE 2.2413829580328308e-05 Test RE 0.0034205339842652708\n",
      "227 Train Loss 0.0049143154 Test MSE 2.19982756134334e-05 Test RE 0.0033886771669867748\n",
      "228 Train Loss 0.004847821 Test MSE 2.2715394022043293e-05 Test RE 0.003443467704140101\n",
      "229 Train Loss 0.004800979 Test MSE 2.2149542874033956e-05 Test RE 0.0034003080271504393\n",
      "230 Train Loss 0.0047509675 Test MSE 2.1176125355208366e-05 Test RE 0.0033247510089113278\n",
      "231 Train Loss 0.004691849 Test MSE 2.0572708527334922e-05 Test RE 0.0032770390263071373\n",
      "232 Train Loss 0.004685405 Test MSE 2.007776552657649e-05 Test RE 0.003237379154417192\n",
      "233 Train Loss 0.004655753 Test MSE 1.9404547128851413e-05 Test RE 0.0031826408490021356\n",
      "234 Train Loss 0.004602271 Test MSE 1.9019674899640865e-05 Test RE 0.0031509203245208453\n",
      "235 Train Loss 0.0045734216 Test MSE 1.9226650940288388e-05 Test RE 0.003168018417853807\n",
      "236 Train Loss 0.0045227227 Test MSE 1.9103146898886325e-05 Test RE 0.003157827006119099\n",
      "237 Train Loss 0.0044676075 Test MSE 1.8686348876479992e-05 Test RE 0.0031231878275684486\n",
      "238 Train Loss 0.0044331187 Test MSE 1.883204687944996e-05 Test RE 0.0031353399788319647\n",
      "239 Train Loss 0.0043859 Test MSE 1.9899140894936025e-05 Test RE 0.003222946084438479\n",
      "240 Train Loss 0.004345646 Test MSE 2.0470032906482517e-05 Test RE 0.0032688511669230584\n",
      "241 Train Loss 0.0042974646 Test MSE 2.137172477617057e-05 Test RE 0.0033400707272541567\n",
      "242 Train Loss 0.0042458847 Test MSE 2.206736119426327e-05 Test RE 0.0033939940658629375\n",
      "243 Train Loss 0.0041912952 Test MSE 2.2113294131062947e-05 Test RE 0.003397524507811105\n",
      "244 Train Loss 0.0041560153 Test MSE 2.259221767760819e-05 Test RE 0.003434118750491816\n",
      "245 Train Loss 0.004098092 Test MSE 2.3333595169759188e-05 Test RE 0.0034900102804944592\n",
      "246 Train Loss 0.0040672673 Test MSE 2.293534806293872e-05 Test RE 0.003460099156018304\n",
      "247 Train Loss 0.004028903 Test MSE 2.1612576926491568e-05 Test RE 0.0033588387349827954\n",
      "248 Train Loss 0.003985564 Test MSE 2.1345019060432767e-05 Test RE 0.0033379832293311544\n",
      "249 Train Loss 0.0039817467 Test MSE 2.1397832451496206e-05 Test RE 0.0033421102179356597\n",
      "250 Train Loss 0.0039700703 Test MSE 2.07713132616835e-05 Test RE 0.003292818967062884\n",
      "251 Train Loss 0.0039246115 Test MSE 2.0283745602155505e-05 Test RE 0.003253943100082463\n",
      "252 Train Loss 0.003892642 Test MSE 1.9884647658792802e-05 Test RE 0.0032217721788080646\n",
      "253 Train Loss 0.00388719 Test MSE 1.950915126260966e-05 Test RE 0.003191207653666393\n",
      "254 Train Loss 0.0038534123 Test MSE 1.9284812090422632e-05 Test RE 0.0031728064711969944\n",
      "255 Train Loss 0.0038029829 Test MSE 1.848540962423554e-05 Test RE 0.0031063502079629332\n",
      "256 Train Loss 0.0037816083 Test MSE 1.923501814614973e-05 Test RE 0.0031687076845142523\n",
      "257 Train Loss 0.003745438 Test MSE 1.9452380142501176e-05 Test RE 0.0031865611054510746\n",
      "258 Train Loss 0.0037035025 Test MSE 1.8802417939936447e-05 Test RE 0.0031328725527688347\n",
      "259 Train Loss 0.0036626759 Test MSE 1.8678264725352753e-05 Test RE 0.003122512172471026\n",
      "260 Train Loss 0.003637038 Test MSE 1.836851649310512e-05 Test RE 0.003096513075109819\n",
      "261 Train Loss 0.003614007 Test MSE 1.7926470535500094e-05 Test RE 0.0030590267357268456\n",
      "262 Train Loss 0.003576006 Test MSE 1.7944686663070682e-05 Test RE 0.003060580568432941\n",
      "263 Train Loss 0.0035519523 Test MSE 1.802470063912062e-05 Test RE 0.003067396425579692\n",
      "264 Train Loss 0.0035368279 Test MSE 1.7961226273428725e-05 Test RE 0.0030619907115047858\n",
      "265 Train Loss 0.0035036546 Test MSE 1.85686388088514e-05 Test RE 0.003113335409814724\n",
      "266 Train Loss 0.0034789848 Test MSE 1.825338777638597e-05 Test RE 0.0030867937833804274\n",
      "267 Train Loss 0.0034430714 Test MSE 1.8137930576479938e-05 Test RE 0.003077015929303691\n",
      "268 Train Loss 0.0034097324 Test MSE 1.8051581312496187e-05 Test RE 0.003069682814815412\n",
      "269 Train Loss 0.0034030387 Test MSE 1.8080100314053837e-05 Test RE 0.003072106694967017\n",
      "270 Train Loss 0.0033666608 Test MSE 1.8080442550821963e-05 Test RE 0.003072135770659989\n",
      "271 Train Loss 0.0033473247 Test MSE 1.818718378462666e-05 Test RE 0.0030811908863112823\n",
      "272 Train Loss 0.0033163186 Test MSE 1.699447724464833e-05 Test RE 0.0029784463518626025\n",
      "273 Train Loss 0.0032820913 Test MSE 1.642786635017167e-05 Test RE 0.0029283734277194473\n",
      "274 Train Loss 0.0032645874 Test MSE 1.596585837768407e-05 Test RE 0.002886901812663472\n",
      "275 Train Loss 0.003239465 Test MSE 1.5884106628707683e-05 Test RE 0.002879501265860068\n",
      "276 Train Loss 0.0032147374 Test MSE 1.5711942256840603e-05 Test RE 0.0028638536064446505\n",
      "277 Train Loss 0.003178401 Test MSE 1.5747458556677788e-05 Test RE 0.0028670886001405096\n",
      "278 Train Loss 0.003171534 Test MSE 1.581797969169535e-05 Test RE 0.0028735012057688695\n",
      "279 Train Loss 0.0031491823 Test MSE 1.5515063999806336e-05 Test RE 0.002845854306353475\n",
      "280 Train Loss 0.0031424866 Test MSE 1.5866022925834303e-05 Test RE 0.002877861674925167\n",
      "281 Train Loss 0.0031304953 Test MSE 1.5806636982353095e-05 Test RE 0.0028724707602038437\n",
      "282 Train Loss 0.0031145262 Test MSE 1.5425986985977314e-05 Test RE 0.0028376730604237964\n",
      "283 Train Loss 0.0030940282 Test MSE 1.4973117067665936e-05 Test RE 0.00279570914432443\n",
      "284 Train Loss 0.003079164 Test MSE 1.4877634922863309e-05 Test RE 0.0027867809021388783\n",
      "285 Train Loss 0.0030718353 Test MSE 1.4715493093052044e-05 Test RE 0.0027715536288520823\n",
      "286 Train Loss 0.003047762 Test MSE 1.484030989079311e-05 Test RE 0.0027832829668705088\n",
      "287 Train Loss 0.0030349423 Test MSE 1.513178713418629e-05 Test RE 0.0028104831671662486\n",
      "288 Train Loss 0.0030190605 Test MSE 1.5325046537713394e-05 Test RE 0.002828373619610567\n",
      "289 Train Loss 0.0030083363 Test MSE 1.5102642932639569e-05 Test RE 0.002807775332162907\n",
      "290 Train Loss 0.0029870754 Test MSE 1.497154306984114e-05 Test RE 0.0027955621957717856\n",
      "291 Train Loss 0.0029942617 Test MSE 1.4910260033651532e-05 Test RE 0.002789834789625631\n",
      "292 Train Loss 0.0029886093 Test MSE 1.5044105430462109e-05 Test RE 0.002802328612379636\n",
      "293 Train Loss 0.0029894952 Test MSE 1.5183614291511359e-05 Test RE 0.0028152920784466763\n",
      "294 Train Loss 0.0029868155 Test MSE 1.4992903635851994e-05 Test RE 0.0027975557613744107\n",
      "295 Train Loss 0.0029568556 Test MSE 1.4912998492537782e-05 Test RE 0.0027900909721837145\n",
      "296 Train Loss 0.0029342326 Test MSE 1.469045080977188e-05 Test RE 0.0027691943608354292\n",
      "297 Train Loss 0.0029160515 Test MSE 1.4553025179548745e-05 Test RE 0.0027562113530175503\n",
      "298 Train Loss 0.0028809912 Test MSE 1.4448748231302715e-05 Test RE 0.0027463190453314345\n",
      "299 Train Loss 0.0028664232 Test MSE 1.4163315639919912e-05 Test RE 0.002719057200011372\n",
      "Training time: 170.89\n",
      "KG_tanhALR_high\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 58884.395 Test MSE 4.076287406839724 Test RE 1.4587077001900326\n",
      "1 Train Loss 35819.773 Test MSE 6.708511080395827 Test RE 1.8713238280510684\n",
      "2 Train Loss 23111.516 Test MSE 11.41221865721315 Test RE 2.4407366297916813\n",
      "3 Train Loss 10664.944 Test MSE 9.18239066174782 Test RE 2.1893427621291424\n",
      "4 Train Loss 4090.0347 Test MSE 12.22935350070268 Test RE 2.5266066003189844\n",
      "5 Train Loss 2022.8525 Test MSE 14.073996996930935 Test RE 2.710469994486797\n",
      "6 Train Loss 1415.428 Test MSE 15.503464003327615 Test RE 2.8447902413692088\n",
      "7 Train Loss 1015.5681 Test MSE 15.91909543333231 Test RE 2.8826709400667605\n",
      "8 Train Loss 687.3343 Test MSE 14.873115060849178 Test RE 2.7863575545431205\n",
      "9 Train Loss 503.9065 Test MSE 14.07550705556346 Test RE 2.7106153994784346\n",
      "10 Train Loss 439.09167 Test MSE 13.727699674215467 Test RE 2.6769161114868902\n",
      "11 Train Loss 377.9739 Test MSE 13.181538653089131 Test RE 2.623124662272203\n",
      "12 Train Loss 317.0948 Test MSE 11.884382455753682 Test RE 2.490715862696564\n",
      "13 Train Loss 248.89766 Test MSE 10.66249219254495 Test RE 2.3592026098501226\n",
      "14 Train Loss 203.58752 Test MSE 9.832490319518225 Test RE 2.2655186445475426\n",
      "15 Train Loss 177.42108 Test MSE 9.32322170655598 Test RE 2.2060679380291526\n",
      "16 Train Loss 156.90532 Test MSE 8.5979427805543 Test RE 2.118522847989827\n",
      "17 Train Loss 137.1854 Test MSE 7.877658996515285 Test RE 2.027843642720953\n",
      "18 Train Loss 100.295586 Test MSE 6.634365101445789 Test RE 1.860953668673656\n",
      "19 Train Loss 75.49986 Test MSE 5.460726813777278 Test RE 1.6883446349482387\n",
      "20 Train Loss 57.36324 Test MSE 4.633062082303084 Test RE 1.5551415923418184\n",
      "21 Train Loss 46.994835 Test MSE 4.0485464982312 Test RE 1.4537356563676969\n",
      "22 Train Loss 37.823532 Test MSE 3.299520447501516 Test RE 1.3123850936522008\n",
      "23 Train Loss 29.732311 Test MSE 2.578990714289137 Test RE 1.1602745494369415\n",
      "24 Train Loss 22.85205 Test MSE 1.7822340326777284 Test RE 0.964535558929306\n",
      "25 Train Loss 17.904684 Test MSE 1.2478396485687238 Test RE 0.8070775505082839\n",
      "26 Train Loss 14.960337 Test MSE 0.9780556694913095 Test RE 0.7145253878395437\n",
      "27 Train Loss 11.964483 Test MSE 0.8337816202832592 Test RE 0.6597236234071192\n",
      "28 Train Loss 9.33954 Test MSE 0.5799520095854329 Test RE 0.5502143408653543\n",
      "29 Train Loss 7.880907 Test MSE 0.41945727505205316 Test RE 0.46792876400402167\n",
      "30 Train Loss 6.455628 Test MSE 0.26651969157484284 Test RE 0.37299286814010696\n",
      "31 Train Loss 5.092478 Test MSE 0.17164169460304474 Test RE 0.29932795162845455\n",
      "32 Train Loss 4.050111 Test MSE 0.12823270157503813 Test RE 0.258723139678502\n",
      "33 Train Loss 3.5076272 Test MSE 0.1049297306202676 Test RE 0.23403734132272283\n",
      "34 Train Loss 2.9315152 Test MSE 0.07052587760736775 Test RE 0.1918713478831296\n",
      "35 Train Loss 2.4324267 Test MSE 0.05359171640285966 Test RE 0.16725715689080878\n",
      "36 Train Loss 2.0081282 Test MSE 0.03189562465323496 Test RE 0.1290331896077342\n",
      "37 Train Loss 1.7276286 Test MSE 0.02086751953095253 Test RE 0.10436894445687585\n",
      "38 Train Loss 1.4530044 Test MSE 0.011007123222537496 Test RE 0.07580062578958274\n",
      "39 Train Loss 1.2282103 Test MSE 0.007854412320940809 Test RE 0.06403135981474418\n",
      "40 Train Loss 1.0815165 Test MSE 0.006079520731694759 Test RE 0.05633399472606228\n",
      "41 Train Loss 0.9617408 Test MSE 0.0044701356394683265 Test RE 0.04830546060364989\n",
      "42 Train Loss 0.86407506 Test MSE 0.005074126820061423 Test RE 0.051465540203428944\n",
      "43 Train Loss 0.7890894 Test MSE 0.005289862947500497 Test RE 0.05254822938299728\n",
      "44 Train Loss 0.7107809 Test MSE 0.004054126137906245 Test RE 0.04600282533598922\n",
      "45 Train Loss 0.6457059 Test MSE 0.0037188256280715447 Test RE 0.0440594208844664\n",
      "46 Train Loss 0.60279083 Test MSE 0.00347462170586163 Test RE 0.04258823492643036\n",
      "47 Train Loss 0.5654589 Test MSE 0.003476920820748071 Test RE 0.04260232265470977\n",
      "48 Train Loss 0.5309168 Test MSE 0.003474451802486913 Test RE 0.04258719366584032\n",
      "49 Train Loss 0.4994269 Test MSE 0.0033511836956923403 Test RE 0.041824907976776016\n",
      "50 Train Loss 0.467218 Test MSE 0.0030139923941787544 Test RE 0.03966495381250102\n",
      "51 Train Loss 0.43784663 Test MSE 0.0030992106314201313 Test RE 0.04022179271120985\n",
      "52 Train Loss 0.419178 Test MSE 0.002940231355086515 Test RE 0.03917658979097797\n",
      "53 Train Loss 0.392526 Test MSE 0.0025342302866770442 Test RE 0.03637130764167678\n",
      "54 Train Loss 0.37000412 Test MSE 0.0022493322648577344 Test RE 0.03426594262332238\n",
      "55 Train Loss 0.34239665 Test MSE 0.002147131809344686 Test RE 0.033478441308408144\n",
      "56 Train Loss 0.32407373 Test MSE 0.002117590711489952 Test RE 0.03324733876491106\n",
      "57 Train Loss 0.3120731 Test MSE 0.001977157284921954 Test RE 0.032125987535871356\n",
      "58 Train Loss 0.2992317 Test MSE 0.002007937829230588 Test RE 0.032375091745955445\n",
      "59 Train Loss 0.2863334 Test MSE 0.0017779563260235712 Test RE 0.030464666010553355\n",
      "60 Train Loss 0.27572823 Test MSE 0.001549810188292409 Test RE 0.02844298240775309\n",
      "61 Train Loss 0.26619908 Test MSE 0.0013094470090269886 Test RE 0.02614446991838153\n",
      "62 Train Loss 0.2543632 Test MSE 0.0013121925628142015 Test RE 0.026171864483022653\n",
      "63 Train Loss 0.24348374 Test MSE 0.0011636020410802385 Test RE 0.024645527277460118\n",
      "64 Train Loss 0.23363538 Test MSE 0.0010154956907534641 Test RE 0.02302368947959484\n",
      "65 Train Loss 0.21798778 Test MSE 0.0009458452612369149 Test RE 0.02222009559686589\n",
      "66 Train Loss 0.20635264 Test MSE 0.0008881723897171268 Test RE 0.02153200693609595\n",
      "67 Train Loss 0.19299841 Test MSE 0.0006724410997916036 Test RE 0.018735401384226937\n",
      "68 Train Loss 0.18202674 Test MSE 0.000744079142778806 Test RE 0.019708131092695376\n",
      "69 Train Loss 0.17396799 Test MSE 0.0009121629648885466 Test RE 0.021820871637095545\n",
      "70 Train Loss 0.16657579 Test MSE 0.0008897833003178142 Test RE 0.021551524782517352\n",
      "71 Train Loss 0.16093989 Test MSE 0.0008091592188031655 Test RE 0.020551942212158357\n",
      "72 Train Loss 0.1531898 Test MSE 0.0007082019221932382 Test RE 0.019227128440928908\n",
      "73 Train Loss 0.14627042 Test MSE 0.0006701361314507889 Test RE 0.018703263567862588\n",
      "74 Train Loss 0.14072318 Test MSE 0.0006213779258266469 Test RE 0.018010003094137722\n",
      "75 Train Loss 0.13616644 Test MSE 0.0006772384765319176 Test RE 0.018802114319906516\n",
      "76 Train Loss 0.12923689 Test MSE 0.0004861687649758139 Test RE 0.015930499873371515\n",
      "77 Train Loss 0.12395418 Test MSE 0.0004980264306704517 Test RE 0.016123602126532088\n",
      "78 Train Loss 0.12098074 Test MSE 0.00047681583607628086 Test RE 0.01577651999868457\n",
      "79 Train Loss 0.11838064 Test MSE 0.0004784240851789125 Test RE 0.01580310386342769\n",
      "80 Train Loss 0.11444169 Test MSE 0.0003754742417534212 Test RE 0.013999932809734392\n",
      "81 Train Loss 0.109262444 Test MSE 0.000361522655295373 Test RE 0.01373737127588066\n",
      "82 Train Loss 0.105242394 Test MSE 0.00034443759729543377 Test RE 0.013408838264742698\n",
      "83 Train Loss 0.101972684 Test MSE 0.0003775494184095189 Test RE 0.01403856702129341\n",
      "84 Train Loss 0.098274276 Test MSE 0.0004256102547121324 Test RE 0.014905341083490202\n",
      "85 Train Loss 0.095817275 Test MSE 0.00038898130553534143 Test RE 0.014249520212187394\n",
      "86 Train Loss 0.093220375 Test MSE 0.0003382920804797381 Test RE 0.013288678436668035\n",
      "87 Train Loss 0.08980277 Test MSE 0.00029762160125978336 Test RE 0.012464305969327813\n",
      "88 Train Loss 0.08668081 Test MSE 0.00024456515138309315 Test RE 0.01129882191634135\n",
      "89 Train Loss 0.08311319 Test MSE 0.00018846849241812427 Test RE 0.009918711427533752\n",
      "90 Train Loss 0.07987436 Test MSE 0.00019498463525685113 Test RE 0.010088720074457703\n",
      "91 Train Loss 0.07647075 Test MSE 0.0001853985524924575 Test RE 0.009837597426515961\n",
      "92 Train Loss 0.074857935 Test MSE 0.00015791311159230842 Test RE 0.009079145425377676\n",
      "93 Train Loss 0.07241532 Test MSE 0.00014070402754446878 Test RE 0.008570164170558843\n",
      "94 Train Loss 0.07093518 Test MSE 0.00013160893755661976 Test RE 0.008288550130346375\n",
      "95 Train Loss 0.06888546 Test MSE 0.00013569159729038717 Test RE 0.00841612843189164\n",
      "96 Train Loss 0.066621296 Test MSE 0.00012977038188019739 Test RE 0.00823045165444267\n",
      "97 Train Loss 0.06376967 Test MSE 0.0001309066660209369 Test RE 0.008266406502577461\n",
      "98 Train Loss 0.06166525 Test MSE 0.00012491895754911843 Test RE 0.008075139852766849\n",
      "99 Train Loss 0.060708452 Test MSE 0.00013022356041524443 Test RE 0.008244810144127868\n",
      "100 Train Loss 0.059061337 Test MSE 0.00012317992789858854 Test RE 0.008018734784848434\n",
      "101 Train Loss 0.057054326 Test MSE 0.00012462771396549392 Test RE 0.008065720925821857\n",
      "102 Train Loss 0.055109784 Test MSE 0.00014807640947176097 Test RE 0.008791820537288886\n",
      "103 Train Loss 0.053748295 Test MSE 0.00015436726124282754 Test RE 0.008976633135087694\n",
      "104 Train Loss 0.0530446 Test MSE 0.0001311552960017932 Test RE 0.008274252938462068\n",
      "105 Train Loss 0.05178691 Test MSE 0.00013038353371041828 Test RE 0.008249872763461005\n",
      "106 Train Loss 0.050440177 Test MSE 0.00012460822208054418 Test RE 0.00806509015820611\n",
      "107 Train Loss 0.04901936 Test MSE 0.0001254765630962719 Test RE 0.008093142441329729\n",
      "108 Train Loss 0.04807455 Test MSE 0.00013365918897838522 Test RE 0.008352861640643918\n",
      "109 Train Loss 0.04716203 Test MSE 0.00013601603306614513 Test RE 0.008426183818597355\n",
      "110 Train Loss 0.04639102 Test MSE 0.00014932335451831087 Test RE 0.008828760702886356\n",
      "111 Train Loss 0.045559704 Test MSE 0.0001369307994754633 Test RE 0.008454471194918153\n",
      "112 Train Loss 0.04465494 Test MSE 0.00013791570787628974 Test RE 0.00848482214613997\n",
      "113 Train Loss 0.043962657 Test MSE 0.00013256685427516317 Test RE 0.008318659581354484\n",
      "114 Train Loss 0.043053508 Test MSE 0.00013364099600089295 Test RE 0.008352293147761198\n",
      "115 Train Loss 0.042243168 Test MSE 0.00012185862418215659 Test RE 0.007975611890214725\n",
      "116 Train Loss 0.041097786 Test MSE 0.00010844961079630994 Test RE 0.007524018864744607\n",
      "117 Train Loss 0.040219117 Test MSE 0.00010854694204753347 Test RE 0.00752739443210581\n",
      "118 Train Loss 0.039300792 Test MSE 0.00010593953880696406 Test RE 0.007436437219864982\n",
      "119 Train Loss 0.038657453 Test MSE 0.00012489228847660093 Test RE 0.008074277821935249\n",
      "120 Train Loss 0.03794455 Test MSE 0.0001254643468074449 Test RE 0.008092748461092748\n",
      "121 Train Loss 0.03713602 Test MSE 0.00010424360211158073 Test RE 0.007376673845328925\n",
      "122 Train Loss 0.0362564 Test MSE 9.68677859125026e-05 Test RE 0.007110916247275062\n",
      "123 Train Loss 0.035462793 Test MSE 0.00010055597540249378 Test RE 0.007245023832555638\n",
      "124 Train Loss 0.034939617 Test MSE 0.00010904229279342871 Test RE 0.007544550402148362\n",
      "125 Train Loss 0.034074526 Test MSE 0.00010114836391497297 Test RE 0.007266333190020981\n",
      "126 Train Loss 0.03343249 Test MSE 0.00010474725748438354 Test RE 0.007394472657475318\n",
      "127 Train Loss 0.032896925 Test MSE 9.935760702696761e-05 Test RE 0.007201723421561484\n",
      "128 Train Loss 0.0322783 Test MSE 0.0001027958558935487 Test RE 0.007325270733428852\n",
      "129 Train Loss 0.03148831 Test MSE 0.00011746393908445376 Test RE 0.00783047589840084\n",
      "130 Train Loss 0.031155858 Test MSE 0.0001234341818951694 Test RE 0.00802700619896327\n",
      "131 Train Loss 0.030693254 Test MSE 0.00012155261296061204 Test RE 0.007965591422213172\n",
      "132 Train Loss 0.030460976 Test MSE 0.00012276321185356273 Test RE 0.008005159657855098\n",
      "133 Train Loss 0.029912565 Test MSE 0.00013074199514441203 Test RE 0.008261205603345402\n",
      "134 Train Loss 0.02953684 Test MSE 0.00012456933081809302 Test RE 0.008063831469129612\n",
      "135 Train Loss 0.02916455 Test MSE 0.00012093030682141454 Test RE 0.007945174759903657\n",
      "136 Train Loss 0.028642716 Test MSE 0.00012043633120488484 Test RE 0.007928930946284427\n",
      "137 Train Loss 0.028309867 Test MSE 0.00011664390013927527 Test RE 0.007803094977841821\n",
      "138 Train Loss 0.028185617 Test MSE 0.0001158899742628207 Test RE 0.007777836511027422\n",
      "139 Train Loss 0.027774584 Test MSE 0.00010776480722014361 Test RE 0.007500226088642357\n",
      "140 Train Loss 0.02731635 Test MSE 0.00010417890073548397 Test RE 0.007374384232243826\n",
      "141 Train Loss 0.026835987 Test MSE 9.680897144021994e-05 Test RE 0.007108757179198639\n",
      "142 Train Loss 0.026399793 Test MSE 9.54056888456513e-05 Test RE 0.007057047045951402\n",
      "143 Train Loss 0.025902113 Test MSE 9.76893031689814e-05 Test RE 0.007141005749801486\n",
      "144 Train Loss 0.025406353 Test MSE 9.769994043540898e-05 Test RE 0.007141394526824925\n",
      "145 Train Loss 0.024991464 Test MSE 9.432572527684187e-05 Test RE 0.007016991549250535\n",
      "146 Train Loss 0.024552055 Test MSE 8.422772838845574e-05 Test RE 0.00663076170928753\n",
      "147 Train Loss 0.024094876 Test MSE 7.702501708466714e-05 Test RE 0.006340912766813505\n",
      "148 Train Loss 0.023834083 Test MSE 7.709976588619476e-05 Test RE 0.006343988784913793\n",
      "149 Train Loss 0.023336308 Test MSE 7.902912824241085e-05 Test RE 0.00642287503798948\n",
      "150 Train Loss 0.02308077 Test MSE 7.897489678255728e-05 Test RE 0.006420670903422334\n",
      "151 Train Loss 0.022676973 Test MSE 8.239292031250233e-05 Test RE 0.006558142135642208\n",
      "152 Train Loss 0.022243867 Test MSE 8.150774074050266e-05 Test RE 0.006522818654840675\n",
      "153 Train Loss 0.021710278 Test MSE 7.708635825212901e-05 Test RE 0.006343437151731927\n",
      "154 Train Loss 0.021414693 Test MSE 7.720200462375427e-05 Test RE 0.006348193638967082\n",
      "155 Train Loss 0.021029327 Test MSE 8.103995522071994e-05 Test RE 0.006504073989381572\n",
      "156 Train Loss 0.020745123 Test MSE 7.660925622974268e-05 Test RE 0.0063237763183891845\n",
      "157 Train Loss 0.020436166 Test MSE 7.284290091645878e-05 Test RE 0.006166368768506237\n",
      "158 Train Loss 0.020179687 Test MSE 7.039896422903254e-05 Test RE 0.0060620429860071484\n",
      "159 Train Loss 0.01997655 Test MSE 6.98680221732392e-05 Test RE 0.006039140055741778\n",
      "160 Train Loss 0.01958081 Test MSE 6.986824565412832e-05 Test RE 0.006039149714175405\n",
      "161 Train Loss 0.019230712 Test MSE 7.23539057257494e-05 Test RE 0.006145636465372119\n",
      "162 Train Loss 0.019077435 Test MSE 7.066204069832246e-05 Test RE 0.006073359159202808\n",
      "163 Train Loss 0.018908836 Test MSE 7.345325591381273e-05 Test RE 0.00619214906275887\n",
      "164 Train Loss 0.018556835 Test MSE 7.522996749745938e-05 Test RE 0.006266590471154792\n",
      "165 Train Loss 0.018277619 Test MSE 7.099323760606545e-05 Test RE 0.006087575606136687\n",
      "166 Train Loss 0.018005377 Test MSE 7.829543461905134e-05 Test RE 0.006392991051081787\n",
      "167 Train Loss 0.017729005 Test MSE 7.875092887800696e-05 Test RE 0.006411560127392491\n",
      "168 Train Loss 0.017551411 Test MSE 7.544102854614212e-05 Test RE 0.006275374914527904\n",
      "169 Train Loss 0.01726836 Test MSE 8.028636447761215e-05 Test RE 0.006473762658494034\n",
      "170 Train Loss 0.016983531 Test MSE 8.241210756451876e-05 Test RE 0.006558905704893471\n",
      "171 Train Loss 0.016779777 Test MSE 8.692078173579605e-05 Test RE 0.006735931913355223\n",
      "172 Train Loss 0.016506301 Test MSE 8.67059386514565e-05 Test RE 0.006727602123218982\n",
      "173 Train Loss 0.016203674 Test MSE 9.03428843469113e-05 Test RE 0.006867249918933504\n",
      "174 Train Loss 0.015885795 Test MSE 8.874897306522563e-05 Test RE 0.006806401205026951\n",
      "175 Train Loss 0.0156748 Test MSE 9.506981725349462e-05 Test RE 0.007044614079757796\n",
      "176 Train Loss 0.015442853 Test MSE 9.671688618850836e-05 Test RE 0.007105375429417877\n",
      "177 Train Loss 0.015257682 Test MSE 8.975844778389428e-05 Test RE 0.006845001437878962\n",
      "178 Train Loss 0.014947393 Test MSE 8.627954847900759e-05 Test RE 0.006711039712093368\n",
      "179 Train Loss 0.014542854 Test MSE 9.188232995389737e-05 Test RE 0.006925511848976662\n",
      "180 Train Loss 0.014360644 Test MSE 8.281483609093512e-05 Test RE 0.006574912086250957\n",
      "181 Train Loss 0.014230878 Test MSE 7.546231134718706e-05 Test RE 0.006276260030625547\n",
      "182 Train Loss 0.013983101 Test MSE 6.9812737356252e-05 Test RE 0.006036750272728133\n",
      "183 Train Loss 0.013747749 Test MSE 6.521166246356814e-05 Test RE 0.005834431064304556\n",
      "184 Train Loss 0.013485464 Test MSE 6.151973183424695e-05 Test RE 0.0056668679625723264\n",
      "185 Train Loss 0.013121742 Test MSE 5.9675361593043655e-05 Test RE 0.005581274806576421\n",
      "186 Train Loss 0.01300097 Test MSE 5.497664259455651e-05 Test RE 0.005357041168904492\n",
      "187 Train Loss 0.012616186 Test MSE 5.532240732993539e-05 Test RE 0.005373860790625524\n",
      "188 Train Loss 0.012293456 Test MSE 5.0599109504783294e-05 Test RE 0.005139339571517418\n",
      "189 Train Loss 0.012126654 Test MSE 5.253996424872692e-05 Test RE 0.005236978167374048\n",
      "190 Train Loss 0.011957536 Test MSE 4.9873084778588916e-05 Test RE 0.005102335272480411\n",
      "191 Train Loss 0.011823625 Test MSE 5.051140280568998e-05 Test RE 0.005134883465336026\n",
      "192 Train Loss 0.011598368 Test MSE 5.020572075984422e-05 Test RE 0.005119322388274884\n",
      "193 Train Loss 0.011522895 Test MSE 5.3406780166058895e-05 Test RE 0.005280001850147075\n",
      "194 Train Loss 0.011331584 Test MSE 5.142156785357172e-05 Test RE 0.005180939656655222\n",
      "195 Train Loss 0.011180497 Test MSE 5.2255688503863514e-05 Test RE 0.005222791203883063\n",
      "196 Train Loss 0.011075172 Test MSE 5.0617310802799404e-05 Test RE 0.005140263839171368\n",
      "197 Train Loss 0.010931763 Test MSE 4.951105188591027e-05 Test RE 0.005083782402753409\n",
      "198 Train Loss 0.010715901 Test MSE 4.905507172823158e-05 Test RE 0.005060318289467952\n",
      "199 Train Loss 0.010509175 Test MSE 4.815212096052423e-05 Test RE 0.005013529648112129\n",
      "200 Train Loss 0.010381578 Test MSE 4.8136173326089776e-05 Test RE 0.005012699356968173\n",
      "201 Train Loss 0.0102508655 Test MSE 4.75039233061166e-05 Test RE 0.004979670609830418\n",
      "202 Train Loss 0.010119579 Test MSE 4.7266752558675476e-05 Test RE 0.004967224164026222\n",
      "203 Train Loss 0.010016976 Test MSE 4.798101791829996e-05 Test RE 0.005004614219620205\n",
      "204 Train Loss 0.009865987 Test MSE 4.9354901931971704e-05 Test RE 0.005075759352829486\n",
      "205 Train Loss 0.009763391 Test MSE 5.178960634255756e-05 Test RE 0.005199447313941775\n",
      "206 Train Loss 0.009760772 Test MSE 5.0514270289995034e-05 Test RE 0.005135029214493281\n",
      "207 Train Loss 0.0096443035 Test MSE 4.896723518766924e-05 Test RE 0.005055785832538629\n",
      "208 Train Loss 0.009505511 Test MSE 4.792354029193756e-05 Test RE 0.005001615746921454\n",
      "209 Train Loss 0.009327946 Test MSE 4.778547121714875e-05 Test RE 0.004994405651851092\n",
      "210 Train Loss 0.009171595 Test MSE 4.688456313866136e-05 Test RE 0.004947101418392526\n",
      "211 Train Loss 0.0090744635 Test MSE 4.6366585267311086e-05 Test RE 0.0049196978785589155\n",
      "212 Train Loss 0.008956225 Test MSE 4.784848767366479e-05 Test RE 0.0049976977199788115\n",
      "213 Train Loss 0.008847223 Test MSE 4.5644618960089785e-05 Test RE 0.004881245713804554\n",
      "214 Train Loss 0.00871057 Test MSE 4.8813744310224635e-05 Test RE 0.005047855774060564\n",
      "215 Train Loss 0.0085904095 Test MSE 4.6175925910509936e-05 Test RE 0.00490957256239408\n",
      "216 Train Loss 0.0084415395 Test MSE 4.473874166186191e-05 Test RE 0.004832565613313424\n",
      "217 Train Loss 0.008357546 Test MSE 4.3709399719723607e-05 Test RE 0.004776648654201755\n",
      "218 Train Loss 0.008239226 Test MSE 4.271649840082037e-05 Test RE 0.004722083902739178\n",
      "219 Train Loss 0.008097916 Test MSE 4.066152530048597e-05 Test RE 0.004607100751744115\n",
      "220 Train Loss 0.008007524 Test MSE 4.096362346462614e-05 Test RE 0.004624183499015989\n",
      "221 Train Loss 0.007934889 Test MSE 4.051579367348557e-05 Test RE 0.004598837375721872\n",
      "222 Train Loss 0.007905548 Test MSE 4.036181304923596e-05 Test RE 0.0045900900961730814\n",
      "223 Train Loss 0.007846365 Test MSE 3.9903371216931876e-05 Test RE 0.004563947826751483\n",
      "224 Train Loss 0.0077804984 Test MSE 3.93805477768619e-05 Test RE 0.0045339502802290285\n",
      "225 Train Loss 0.007709016 Test MSE 3.995790389512843e-05 Test RE 0.004567065349358569\n",
      "226 Train Loss 0.007666531 Test MSE 4.091325957968042e-05 Test RE 0.004621339958162984\n",
      "227 Train Loss 0.007584675 Test MSE 4.1674474680899345e-05 Test RE 0.004664133192367943\n",
      "228 Train Loss 0.007549346 Test MSE 4.1361284280561466e-05 Test RE 0.004646574283956593\n",
      "229 Train Loss 0.007446787 Test MSE 4.271205668890706e-05 Test RE 0.004721838392428538\n",
      "230 Train Loss 0.0073818457 Test MSE 4.126621254896259e-05 Test RE 0.004641230977822893\n",
      "231 Train Loss 0.007318631 Test MSE 4.102660150725388e-05 Test RE 0.004627736775736449\n",
      "232 Train Loss 0.007220736 Test MSE 4.0170519909506936e-05 Test RE 0.004579199906584197\n",
      "233 Train Loss 0.007174514 Test MSE 4.116538790155719e-05 Test RE 0.004635557611763562\n",
      "234 Train Loss 0.0070801987 Test MSE 3.995693298501268e-05 Test RE 0.004567009863003544\n",
      "235 Train Loss 0.0070265764 Test MSE 3.95605331396338e-05 Test RE 0.004544299481057876\n",
      "236 Train Loss 0.0069853864 Test MSE 4.100180563400644e-05 Test RE 0.004626338096420401\n",
      "237 Train Loss 0.006954629 Test MSE 4.071869330803483e-05 Test RE 0.004610338287220053\n",
      "238 Train Loss 0.0069058184 Test MSE 4.020399175232514e-05 Test RE 0.004581107304651664\n",
      "239 Train Loss 0.0068432125 Test MSE 4.051319539269989e-05 Test RE 0.004598689911470452\n",
      "240 Train Loss 0.006801801 Test MSE 4.069744379343954e-05 Test RE 0.004609135151418563\n",
      "241 Train Loss 0.0067164944 Test MSE 4.205003458017909e-05 Test RE 0.0046851020552580265\n",
      "242 Train Loss 0.006646306 Test MSE 4.45485602087697e-05 Test RE 0.004822283214676381\n",
      "243 Train Loss 0.006595204 Test MSE 4.7054365977981516e-05 Test RE 0.004956051833997023\n",
      "244 Train Loss 0.006544433 Test MSE 4.7694839339281754e-05 Test RE 0.004989667107006346\n",
      "245 Train Loss 0.006464741 Test MSE 4.651328501996146e-05 Test RE 0.004927474475603763\n",
      "246 Train Loss 0.0063823704 Test MSE 4.488401333755389e-05 Test RE 0.004840405193792109\n",
      "247 Train Loss 0.0063453172 Test MSE 4.423046854264375e-05 Test RE 0.004805036011792008\n",
      "248 Train Loss 0.0063226237 Test MSE 4.420377331778196e-05 Test RE 0.004803585757234593\n",
      "249 Train Loss 0.0063216197 Test MSE 4.348655844273381e-05 Test RE 0.004764456829910715\n",
      "250 Train Loss 0.0062254383 Test MSE 4.1597881612521974e-05 Test RE 0.004659845141129332\n",
      "251 Train Loss 0.006172394 Test MSE 4.07445508447078e-05 Test RE 0.004611801903337156\n",
      "252 Train Loss 0.006098658 Test MSE 4.0247330127387344e-05 Test RE 0.0045835757693824045\n",
      "253 Train Loss 0.0060554976 Test MSE 3.7932025574423495e-05 Test RE 0.004449783632518736\n",
      "254 Train Loss 0.006009398 Test MSE 3.770990042771732e-05 Test RE 0.004436735817660516\n",
      "255 Train Loss 0.00598702 Test MSE 3.6739525404758236e-05 Test RE 0.004379279335105407\n",
      "256 Train Loss 0.005935553 Test MSE 3.5267406694929645e-05 Test RE 0.004290645559259319\n",
      "257 Train Loss 0.0058807484 Test MSE 3.483654527539236e-05 Test RE 0.00426435563789458\n",
      "258 Train Loss 0.005847514 Test MSE 3.427394030987148e-05 Test RE 0.004229781125381116\n",
      "259 Train Loss 0.005784523 Test MSE 3.403592098858611e-05 Test RE 0.004215068436583806\n",
      "260 Train Loss 0.005778821 Test MSE 3.411725614518973e-05 Test RE 0.004220101775918452\n",
      "261 Train Loss 0.0057243262 Test MSE 3.463470123144341e-05 Test RE 0.004251983785488006\n",
      "262 Train Loss 0.0056625265 Test MSE 3.5314659224319156e-05 Test RE 0.004293518977082983\n",
      "263 Train Loss 0.0056038867 Test MSE 3.526342800080145e-05 Test RE 0.0042904035277436655\n",
      "264 Train Loss 0.0055866055 Test MSE 3.463720166096079e-05 Test RE 0.004252137267306889\n",
      "265 Train Loss 0.0055522416 Test MSE 3.433628516134692e-05 Test RE 0.0042336263976440755\n",
      "266 Train Loss 0.0055313082 Test MSE 3.4986800728312134e-05 Test RE 0.004273542158299013\n",
      "267 Train Loss 0.005498202 Test MSE 3.556659639799571e-05 Test RE 0.004308806887061553\n",
      "268 Train Loss 0.0054974067 Test MSE 3.6365763883647785e-05 Test RE 0.0043569465705875585\n",
      "269 Train Loss 0.0054556993 Test MSE 3.6906693735469903e-05 Test RE 0.0043892310960840135\n",
      "270 Train Loss 0.005400205 Test MSE 3.7359587372328936e-05 Test RE 0.004416079797076147\n",
      "271 Train Loss 0.00537741 Test MSE 3.859007048231721e-05 Test RE 0.004488215102626658\n",
      "272 Train Loss 0.005327676 Test MSE 3.9394104579854924e-05 Test RE 0.0045347306221133294\n",
      "273 Train Loss 0.005266767 Test MSE 3.951267915589328e-05 Test RE 0.004541550167298324\n",
      "274 Train Loss 0.0052054776 Test MSE 4.060769490119369e-05 Test RE 0.0046040501503961575\n",
      "275 Train Loss 0.005135587 Test MSE 4.040678933248652e-05 Test RE 0.004592646816211716\n",
      "276 Train Loss 0.0051079663 Test MSE 3.963741977814674e-05 Test RE 0.004548713303170109\n",
      "277 Train Loss 0.005086465 Test MSE 3.9436000517918546e-05 Test RE 0.004537141342055285\n",
      "278 Train Loss 0.0050406316 Test MSE 3.97791404440982e-05 Test RE 0.004556837841653344\n",
      "279 Train Loss 0.0049892315 Test MSE 3.852085445811151e-05 Test RE 0.004484188214019615\n",
      "280 Train Loss 0.0049642767 Test MSE 3.8503089964699475e-05 Test RE 0.004483154118082993\n",
      "281 Train Loss 0.004952262 Test MSE 3.830052759749125e-05 Test RE 0.004471345769035637\n",
      "282 Train Loss 0.004911804 Test MSE 3.7531857382069174e-05 Test RE 0.004426249651591788\n",
      "283 Train Loss 0.004886746 Test MSE 3.696389499989455e-05 Test RE 0.004392631188804265\n",
      "284 Train Loss 0.0048486623 Test MSE 3.645831698557343e-05 Test RE 0.004362487395661183\n",
      "285 Train Loss 0.0048089665 Test MSE 3.5313341033779415e-05 Test RE 0.004293438844228273\n",
      "286 Train Loss 0.004791305 Test MSE 3.518759148815955e-05 Test RE 0.004285787635577019\n",
      "287 Train Loss 0.00473496 Test MSE 3.533102170114226e-05 Test RE 0.004294513528220914\n",
      "288 Train Loss 0.004714903 Test MSE 3.5273282738167134e-05 Test RE 0.004291002985153427\n",
      "289 Train Loss 0.004686586 Test MSE 3.523969479394577e-05 Test RE 0.0042889595079945095\n",
      "290 Train Loss 0.004642209 Test MSE 3.5128480424985736e-05 Test RE 0.004282186309984833\n",
      "291 Train Loss 0.0046089455 Test MSE 3.482412086417967e-05 Test RE 0.004263595131471983\n",
      "292 Train Loss 0.0045766328 Test MSE 3.409292812364408e-05 Test RE 0.004218596891774432\n",
      "293 Train Loss 0.0045296717 Test MSE 3.207934011494073e-05 Test RE 0.004092122159411997\n",
      "294 Train Loss 0.004478377 Test MSE 3.0507068938436873e-05 Test RE 0.003990580891259954\n",
      "295 Train Loss 0.004431834 Test MSE 2.9616194940563938e-05 Test RE 0.0039318822825046675\n",
      "296 Train Loss 0.0043834723 Test MSE 2.9426803095869096e-05 Test RE 0.003919290172443837\n",
      "297 Train Loss 0.0043376754 Test MSE 2.9809795280413147e-05 Test RE 0.003944712657714244\n",
      "298 Train Loss 0.004301503 Test MSE 3.0150944008443038e-05 Test RE 0.003967220450244725\n",
      "299 Train Loss 0.0042680516 Test MSE 3.123032849663148e-05 Test RE 0.0040376080080170235\n",
      "Training time: 173.33\n",
      "KG_tanhALR_high\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 53803.31 Test MSE 8.78294913642292 Test RE 2.1411942119653364\n",
      "1 Train Loss 38435.016 Test MSE 9.562696214671622 Test RE 2.2342206248395873\n",
      "2 Train Loss 18554.17 Test MSE 6.062826012382325 Test RE 1.7789896832799104\n",
      "3 Train Loss 9056.904 Test MSE 7.584474705214518 Test RE 1.9897505367498576\n",
      "4 Train Loss 2733.3757 Test MSE 8.764838630219403 Test RE 2.138985493613405\n",
      "5 Train Loss 1377.3906 Test MSE 9.59407907595367 Test RE 2.2378837550749373\n",
      "6 Train Loss 831.69763 Test MSE 10.821419670620779 Test RE 2.376719869233262\n",
      "7 Train Loss 593.63715 Test MSE 10.734765835365025 Test RE 2.3671848057409286\n",
      "8 Train Loss 400.97266 Test MSE 9.068237784172837 Test RE 2.175691558189618\n",
      "9 Train Loss 295.03748 Test MSE 8.038022478528886 Test RE 2.0483798031670535\n",
      "10 Train Loss 223.11325 Test MSE 7.961490197905307 Test RE 2.0386048789502644\n",
      "11 Train Loss 179.4861 Test MSE 6.875747371706497 Test RE 1.8945053351511467\n",
      "12 Train Loss 122.745834 Test MSE 5.018249775195669 Test RE 1.6184974287919673\n",
      "13 Train Loss 69.05955 Test MSE 3.669028918250396 Test RE 1.3839214613858546\n",
      "14 Train Loss 46.705624 Test MSE 2.5913296193040027 Test RE 1.163046842151667\n",
      "15 Train Loss 32.16733 Test MSE 2.0955985888251902 Test RE 1.0458994281742184\n",
      "16 Train Loss 24.589956 Test MSE 1.5342297315380973 Test RE 0.8949135301237766\n",
      "17 Train Loss 20.314758 Test MSE 1.1684106374462493 Test RE 0.7809686993191548\n",
      "18 Train Loss 15.930686 Test MSE 0.8826770925924413 Test RE 0.67879214000713\n",
      "19 Train Loss 12.317577 Test MSE 0.5391493582540348 Test RE 0.5305061503478281\n",
      "20 Train Loss 9.447239 Test MSE 0.3110451340068264 Test RE 0.4029466808049118\n",
      "21 Train Loss 6.999692 Test MSE 0.15907078801502816 Test RE 0.28815827332951544\n",
      "22 Train Loss 4.810942 Test MSE 0.08007517961601915 Test RE 0.20444892795822708\n",
      "23 Train Loss 3.4807355 Test MSE 0.030560890993992933 Test RE 0.1263045171148069\n",
      "24 Train Loss 2.6285734 Test MSE 0.01399542453891755 Test RE 0.08547299368692858\n",
      "25 Train Loss 2.0947552 Test MSE 0.010366290041181208 Test RE 0.0735609882071083\n",
      "26 Train Loss 1.714551 Test MSE 0.007264478211448561 Test RE 0.06157977385207792\n",
      "27 Train Loss 1.4105101 Test MSE 0.005315096601753105 Test RE 0.05267341280706825\n",
      "28 Train Loss 1.189827 Test MSE 0.0032397642269781494 Test RE 0.0411237376352245\n",
      "29 Train Loss 1.0509381 Test MSE 0.003996782372159599 Test RE 0.04567632216985194\n",
      "30 Train Loss 0.9308561 Test MSE 0.003391296845061629 Test RE 0.04207448218982615\n",
      "31 Train Loss 0.83614564 Test MSE 0.0029388003030730594 Test RE 0.03916705473159955\n",
      "32 Train Loss 0.7153047 Test MSE 0.0042813021256822474 Test RE 0.04727415939014934\n",
      "33 Train Loss 0.62428445 Test MSE 0.0038984264468613175 Test RE 0.04511080209984884\n",
      "34 Train Loss 0.5676195 Test MSE 0.003669150005713794 Test RE 0.04376416135518073\n",
      "35 Train Loss 0.52002215 Test MSE 0.004357144737580813 Test RE 0.04769104846275482\n",
      "36 Train Loss 0.47144634 Test MSE 0.0032372190428518084 Test RE 0.04110758089635586\n",
      "37 Train Loss 0.43400192 Test MSE 0.0032055860269017186 Test RE 0.04090624310869845\n",
      "38 Train Loss 0.40204224 Test MSE 0.002887970626977073 Test RE 0.03882685937607512\n",
      "39 Train Loss 0.3835406 Test MSE 0.002879200751002377 Test RE 0.03876786195505544\n",
      "40 Train Loss 0.36995324 Test MSE 0.0028843197357925673 Test RE 0.03880230970345079\n",
      "41 Train Loss 0.3359636 Test MSE 0.002614754169675104 Test RE 0.036944628940466594\n",
      "42 Train Loss 0.3239917 Test MSE 0.0025357851224249383 Test RE 0.03638246344275509\n",
      "43 Train Loss 0.29899505 Test MSE 0.0025040193021200344 Test RE 0.03615386342022164\n",
      "44 Train Loss 0.2880723 Test MSE 0.002842002346180428 Test RE 0.038516613263963224\n",
      "45 Train Loss 0.26399046 Test MSE 0.002672313828475847 Test RE 0.03734905401716346\n",
      "46 Train Loss 0.25363863 Test MSE 0.00252110334968294 Test RE 0.036276986351125584\n",
      "47 Train Loss 0.23690282 Test MSE 0.002386636498334592 Test RE 0.035296286492500384\n",
      "48 Train Loss 0.22341359 Test MSE 0.0023097113365558425 Test RE 0.034722799283239486\n",
      "49 Train Loss 0.21231474 Test MSE 0.002396386577577083 Test RE 0.03536831062099735\n",
      "50 Train Loss 0.20233832 Test MSE 0.002138306004528607 Test RE 0.03340956373642083\n",
      "51 Train Loss 0.1882892 Test MSE 0.0018907183612810645 Test RE 0.03141588494796165\n",
      "52 Train Loss 0.17770493 Test MSE 0.0016540275432104306 Test RE 0.029383751703851806\n",
      "53 Train Loss 0.17071895 Test MSE 0.0014947657796913919 Test RE 0.027933313161978536\n",
      "54 Train Loss 0.16476664 Test MSE 0.001469810794387271 Test RE 0.027699159632730713\n",
      "55 Train Loss 0.15674265 Test MSE 0.0012671655038751849 Test RE 0.025718909348154653\n",
      "56 Train Loss 0.15259513 Test MSE 0.001266374446718527 Test RE 0.025710880285076964\n",
      "57 Train Loss 0.14874327 Test MSE 0.0011944049757155934 Test RE 0.024969605382791096\n",
      "58 Train Loss 0.14433455 Test MSE 0.001112686574660036 Test RE 0.024100291798383088\n",
      "59 Train Loss 0.13770884 Test MSE 0.001139615472909434 Test RE 0.024390182248967704\n",
      "60 Train Loss 0.13293706 Test MSE 0.0010549939089312575 Test RE 0.023467177216755005\n",
      "61 Train Loss 0.1267964 Test MSE 0.0010342992101112758 Test RE 0.023235871892969395\n",
      "62 Train Loss 0.12023022 Test MSE 0.0009360559793809036 Test RE 0.022104810075817796\n",
      "63 Train Loss 0.11351111 Test MSE 0.0008370996491078035 Test RE 0.02090376222874964\n",
      "64 Train Loss 0.11001377 Test MSE 0.0009454551746101485 Test RE 0.0222155131052208\n",
      "65 Train Loss 0.10606582 Test MSE 0.00100269057547939 Test RE 0.02287806783425428\n",
      "66 Train Loss 0.100211106 Test MSE 0.001173793148993086 Test RE 0.024753217739026997\n",
      "67 Train Loss 0.09379072 Test MSE 0.0014266020825187832 Test RE 0.027288980043323016\n",
      "68 Train Loss 0.08909563 Test MSE 0.0014668682638760656 Test RE 0.027671419172295764\n",
      "69 Train Loss 0.08440983 Test MSE 0.001690028819097968 Test RE 0.0297018111287954\n",
      "70 Train Loss 0.082738176 Test MSE 0.0016585387917725312 Test RE 0.029423795518681264\n",
      "71 Train Loss 0.08032571 Test MSE 0.001745051390808978 Test RE 0.030181442137244024\n",
      "72 Train Loss 0.07705586 Test MSE 0.001691344132507418 Test RE 0.029713367024081717\n",
      "73 Train Loss 0.07487878 Test MSE 0.0015731841788464347 Test RE 0.028656666003864188\n",
      "74 Train Loss 0.07278539 Test MSE 0.0014209364976185822 Test RE 0.027234738624951592\n",
      "75 Train Loss 0.06989079 Test MSE 0.0010790835242928494 Test RE 0.023733588476192703\n",
      "76 Train Loss 0.06662233 Test MSE 0.0008999774091882359 Test RE 0.021674629422610087\n",
      "77 Train Loss 0.06398192 Test MSE 0.0008262371317515495 Test RE 0.0207676918535885\n",
      "78 Train Loss 0.062100705 Test MSE 0.0007746141549322332 Test RE 0.020108449801433958\n",
      "79 Train Loss 0.06007899 Test MSE 0.0006584683578069807 Test RE 0.018539726877862282\n",
      "80 Train Loss 0.058699127 Test MSE 0.0006190201815721894 Test RE 0.017975802218689146\n",
      "81 Train Loss 0.057043605 Test MSE 0.0005735154942126451 Test RE 0.01730248393129582\n",
      "82 Train Loss 0.05625837 Test MSE 0.0005978464474689065 Test RE 0.017665693996310274\n",
      "83 Train Loss 0.05515116 Test MSE 0.0005518838738680834 Test RE 0.016973043682624134\n",
      "84 Train Loss 0.054218233 Test MSE 0.0005625082523759928 Test RE 0.017135639859833404\n",
      "85 Train Loss 0.05312094 Test MSE 0.0005556420396659088 Test RE 0.017030736333132995\n",
      "86 Train Loss 0.0519924 Test MSE 0.0005889603767114975 Test RE 0.017533915765644954\n",
      "87 Train Loss 0.05101438 Test MSE 0.000577597486468755 Test RE 0.017363949904536106\n",
      "88 Train Loss 0.04979975 Test MSE 0.0006355685323437974 Test RE 0.01821449229011687\n",
      "89 Train Loss 0.04885449 Test MSE 0.0005780310838872947 Test RE 0.017370466165062475\n",
      "90 Train Loss 0.048010662 Test MSE 0.0005872059307407269 Test RE 0.017507780517312447\n",
      "91 Train Loss 0.047051307 Test MSE 0.0006286744675081703 Test RE 0.018115435881537773\n",
      "92 Train Loss 0.046559848 Test MSE 0.0006208084000885252 Test RE 0.01800174764180787\n",
      "93 Train Loss 0.04499168 Test MSE 0.0006483462425208852 Test RE 0.018396676691972546\n",
      "94 Train Loss 0.043489657 Test MSE 0.0006256606286394182 Test RE 0.01807196139763645\n",
      "95 Train Loss 0.04219067 Test MSE 0.0006120271304576111 Test RE 0.01787397779483856\n",
      "96 Train Loss 0.04109473 Test MSE 0.0006226493259638813 Test RE 0.018028418794611163\n",
      "97 Train Loss 0.03991552 Test MSE 0.0005956446574471459 Test RE 0.017633133773376157\n",
      "98 Train Loss 0.038595688 Test MSE 0.000580969907084834 Test RE 0.01741456760642865\n",
      "99 Train Loss 0.03774904 Test MSE 0.0005629151414201396 Test RE 0.017141836252241655\n",
      "100 Train Loss 0.03723503 Test MSE 0.0005021494346620247 Test RE 0.01619020567555482\n",
      "101 Train Loss 0.036811326 Test MSE 0.00045290491223957756 Test RE 0.015375859165550588\n",
      "102 Train Loss 0.036005203 Test MSE 0.000414428475926311 Test RE 0.014708238761948357\n",
      "103 Train Loss 0.03563938 Test MSE 0.00039677154211680005 Test RE 0.014391502405404792\n",
      "104 Train Loss 0.035201646 Test MSE 0.000349473067107706 Test RE 0.01350649719291706\n",
      "105 Train Loss 0.034601532 Test MSE 0.00033905556718261023 Test RE 0.013303665502404916\n",
      "106 Train Loss 0.03425064 Test MSE 0.00031821621706784787 Test RE 0.012888341387100084\n",
      "107 Train Loss 0.03392801 Test MSE 0.0002856763299612075 Test RE 0.012211612249037399\n",
      "108 Train Loss 0.03340083 Test MSE 0.00027763251668331087 Test RE 0.012038462987310372\n",
      "109 Train Loss 0.03300287 Test MSE 0.000279843543757461 Test RE 0.01208630425537806\n",
      "110 Train Loss 0.032502 Test MSE 0.0002454212352494203 Test RE 0.011318580024121436\n",
      "111 Train Loss 0.032050405 Test MSE 0.0002394560430520905 Test RE 0.011180179536459287\n",
      "112 Train Loss 0.031730413 Test MSE 0.00021546705437006122 Test RE 0.010605381950254934\n",
      "113 Train Loss 0.03108516 Test MSE 0.0001929566048518012 Test RE 0.010036116670327335\n",
      "114 Train Loss 0.030834196 Test MSE 0.0001723765319450809 Test RE 0.009485821462760703\n",
      "115 Train Loss 0.030553836 Test MSE 0.0001652946394226543 Test RE 0.009288920835052065\n",
      "116 Train Loss 0.030174794 Test MSE 0.00015693018961301404 Test RE 0.009050844982887291\n",
      "117 Train Loss 0.029732289 Test MSE 0.00015360191344781485 Test RE 0.008954352558524063\n",
      "118 Train Loss 0.029245384 Test MSE 0.00016524678082487055 Test RE 0.009287576003450596\n",
      "119 Train Loss 0.02881108 Test MSE 0.00016179544042248432 Test RE 0.009190074164071664\n",
      "120 Train Loss 0.028275015 Test MSE 0.00017664284163073285 Test RE 0.0096024907650662\n",
      "121 Train Loss 0.027685674 Test MSE 0.00016031904117455836 Test RE 0.009148047907292886\n",
      "122 Train Loss 0.02725184 Test MSE 0.00015942960169830153 Test RE 0.009122636229202117\n",
      "123 Train Loss 0.026868707 Test MSE 0.0001578843963785854 Test RE 0.009078319903507642\n",
      "124 Train Loss 0.026316129 Test MSE 0.00015882752112100787 Test RE 0.009105394269544055\n",
      "125 Train Loss 0.02590614 Test MSE 0.00013221428390830083 Test RE 0.00830759020227347\n",
      "126 Train Loss 0.025626618 Test MSE 0.00014373172150871356 Test RE 0.008661880552827518\n",
      "127 Train Loss 0.025072545 Test MSE 0.00013535872861768659 Test RE 0.008405799178811964\n",
      "128 Train Loss 0.024839118 Test MSE 0.00011143160318776376 Test RE 0.00762675975683316\n",
      "129 Train Loss 0.024186933 Test MSE 8.759205412450731e-05 Test RE 0.006761892038286659\n",
      "130 Train Loss 0.023644637 Test MSE 7.93051692834508e-05 Test RE 0.0064340824980759145\n",
      "131 Train Loss 0.023143811 Test MSE 7.223006579159478e-05 Test RE 0.006140374820212843\n",
      "132 Train Loss 0.022607625 Test MSE 6.914089826840629e-05 Test RE 0.006007632881709393\n",
      "133 Train Loss 0.022198975 Test MSE 6.874222826343355e-05 Test RE 0.005990287680858594\n",
      "134 Train Loss 0.02165534 Test MSE 7.146474050934834e-05 Test RE 0.006107757525049092\n",
      "135 Train Loss 0.021364167 Test MSE 7.260973738022117e-05 Test RE 0.006156491864102386\n",
      "136 Train Loss 0.021040032 Test MSE 7.386912258817422e-05 Test RE 0.006209653214524089\n",
      "137 Train Loss 0.020774983 Test MSE 7.365723524730401e-05 Test RE 0.006200740885907681\n",
      "138 Train Loss 0.020322027 Test MSE 7.340670812606853e-05 Test RE 0.00619018675002975\n",
      "139 Train Loss 0.019959345 Test MSE 7.503679061038421e-05 Test RE 0.00625853956667974\n",
      "140 Train Loss 0.01958572 Test MSE 7.991000611639369e-05 Test RE 0.006458571307041885\n",
      "141 Train Loss 0.01931279 Test MSE 8.520304355815981e-05 Test RE 0.006669041672550259\n",
      "142 Train Loss 0.019119775 Test MSE 8.55388721321633e-05 Test RE 0.006682171791470264\n",
      "143 Train Loss 0.018947702 Test MSE 8.373864553810331e-05 Test RE 0.006611482349835822\n",
      "144 Train Loss 0.018562917 Test MSE 8.377227564259303e-05 Test RE 0.0066128098284536484\n",
      "145 Train Loss 0.018301489 Test MSE 9.053490122929151e-05 Test RE 0.006874543952173825\n",
      "146 Train Loss 0.018002288 Test MSE 8.852927637948625e-05 Test RE 0.006797971415322958\n",
      "147 Train Loss 0.01781843 Test MSE 8.471304703359611e-05 Test RE 0.0066498374346849265\n",
      "148 Train Loss 0.017742986 Test MSE 8.350954517182201e-05 Test RE 0.006602431985758433\n",
      "149 Train Loss 0.017363407 Test MSE 7.727594415037329e-05 Test RE 0.006351232874165197\n",
      "150 Train Loss 0.017076708 Test MSE 7.963547815883502e-05 Test RE 0.006447467667354235\n",
      "151 Train Loss 0.016587302 Test MSE 9.211052800072083e-05 Test RE 0.006934106582237337\n",
      "152 Train Loss 0.016273448 Test MSE 9.65062177242947e-05 Test RE 0.007097632755922235\n",
      "153 Train Loss 0.01602294 Test MSE 0.00010156868640782595 Test RE 0.007281415178492134\n",
      "154 Train Loss 0.015747564 Test MSE 0.00011802508488832305 Test RE 0.00784915739099896\n",
      "155 Train Loss 0.015547585 Test MSE 0.0001164545167499765 Test RE 0.00779675784023657\n",
      "156 Train Loss 0.015346002 Test MSE 0.0001168803703151689 Test RE 0.007811000513413251\n",
      "157 Train Loss 0.015183191 Test MSE 0.00011424273019615106 Test RE 0.007722362132989494\n",
      "158 Train Loss 0.0149297 Test MSE 0.00010907528915276097 Test RE 0.007545691811870844\n",
      "159 Train Loss 0.014815511 Test MSE 0.00010449749274839085 Test RE 0.007385651515910409\n",
      "160 Train Loss 0.014621811 Test MSE 0.0001020768530941645 Test RE 0.007299607576836838\n",
      "161 Train Loss 0.0146260625 Test MSE 9.160562795846473e-05 Test RE 0.00691507595856409\n",
      "162 Train Loss 0.0144042615 Test MSE 9.256071087375584e-05 Test RE 0.006951030875370137\n",
      "163 Train Loss 0.014176322 Test MSE 8.759269627270819e-05 Test RE 0.006761916824375375\n",
      "164 Train Loss 0.013982095 Test MSE 7.846093254207675e-05 Test RE 0.006399744115496957\n",
      "165 Train Loss 0.013681106 Test MSE 7.971995214259642e-05 Test RE 0.006450886362981333\n",
      "166 Train Loss 0.01344823 Test MSE 7.994265228360312e-05 Test RE 0.006459890453909243\n",
      "167 Train Loss 0.013213195 Test MSE 8.344967285368222e-05 Test RE 0.0066000647486586074\n",
      "168 Train Loss 0.013030142 Test MSE 8.841212721164613e-05 Test RE 0.006793472110917609\n",
      "169 Train Loss 0.012859266 Test MSE 9.467718241808471e-05 Test RE 0.007030052030985055\n",
      "170 Train Loss 0.012774065 Test MSE 8.752891865137465e-05 Test RE 0.006759454647051966\n",
      "171 Train Loss 0.012657332 Test MSE 8.570571566921755e-05 Test RE 0.0066886854035672115\n",
      "172 Train Loss 0.012561373 Test MSE 8.415450254591173e-05 Test RE 0.006627878759109823\n",
      "173 Train Loss 0.012267471 Test MSE 8.293534197847671e-05 Test RE 0.006579694004768928\n",
      "174 Train Loss 0.012105901 Test MSE 8.541919025163182e-05 Test RE 0.006677495468299155\n",
      "175 Train Loss 0.011965754 Test MSE 8.207813549541863e-05 Test RE 0.006545602349938909\n",
      "176 Train Loss 0.011831755 Test MSE 7.904310913460684e-05 Test RE 0.00642344314214529\n",
      "177 Train Loss 0.011650263 Test MSE 7.801056458703737e-05 Test RE 0.006381350326869039\n",
      "178 Train Loss 0.011505356 Test MSE 6.570748878277306e-05 Test RE 0.005856569638292034\n",
      "179 Train Loss 0.011324786 Test MSE 5.4341270468743505e-05 Test RE 0.005325995200941813\n",
      "180 Train Loss 0.011098094 Test MSE 5.122325074885311e-05 Test RE 0.0051709393633161994\n",
      "181 Train Loss 0.010939743 Test MSE 4.453846291414589e-05 Test RE 0.004821736678788654\n",
      "182 Train Loss 0.010779922 Test MSE 3.9875265100682434e-05 Test RE 0.0045623402251885065\n",
      "183 Train Loss 0.010605862 Test MSE 3.93440315006426e-05 Test RE 0.004531847701821463\n",
      "184 Train Loss 0.010418194 Test MSE 3.733736447112451e-05 Test RE 0.004414766175722771\n",
      "185 Train Loss 0.010286199 Test MSE 3.71643499764368e-05 Test RE 0.00440452569069267\n",
      "186 Train Loss 0.0101921195 Test MSE 3.50347482273194e-05 Test RE 0.004276469483735882\n",
      "187 Train Loss 0.010106365 Test MSE 3.529329393595851e-05 Test RE 0.004292219995984272\n",
      "188 Train Loss 0.010053569 Test MSE 3.5616714183141404e-05 Test RE 0.004311841642405408\n",
      "189 Train Loss 0.010018214 Test MSE 3.5901865380857076e-05 Test RE 0.004329067763743203\n",
      "190 Train Loss 0.00993641 Test MSE 3.589919145489134e-05 Test RE 0.004328906548968979\n",
      "191 Train Loss 0.009859395 Test MSE 3.8097241347365864e-05 Test RE 0.004459463785937748\n",
      "192 Train Loss 0.009825441 Test MSE 3.802894081272876e-05 Test RE 0.004455464541024623\n",
      "193 Train Loss 0.009702943 Test MSE 3.7178074376691474e-05 Test RE 0.0044053388879333345\n",
      "194 Train Loss 0.009634618 Test MSE 3.8322993181651386e-05 Test RE 0.004472656934639507\n",
      "195 Train Loss 0.009580063 Test MSE 3.5931909709667465e-05 Test RE 0.0043308787662422205\n",
      "196 Train Loss 0.00949334 Test MSE 3.4163519117878185e-05 Test RE 0.004222962033976204\n",
      "197 Train Loss 0.009342481 Test MSE 3.283863588701616e-05 Test RE 0.004140267781446851\n",
      "198 Train Loss 0.009249243 Test MSE 3.322736250581529e-05 Test RE 0.004164700851382387\n",
      "199 Train Loss 0.009088378 Test MSE 3.2291507237686064e-05 Test RE 0.004105632146770131\n",
      "200 Train Loss 0.00896791 Test MSE 3.238843472351136e-05 Test RE 0.004111789345031225\n",
      "201 Train Loss 0.008917701 Test MSE 3.282257208615048e-05 Test RE 0.004139255002278175\n",
      "202 Train Loss 0.008798036 Test MSE 2.9857627683683806e-05 Test RE 0.003947876206056708\n",
      "203 Train Loss 0.008715413 Test MSE 3.184715202424414e-05 Test RE 0.004077286013408837\n",
      "204 Train Loss 0.008586338 Test MSE 3.1509259279177466e-05 Test RE 0.004055598687522243\n",
      "205 Train Loss 0.008464837 Test MSE 3.1721622358679854e-05 Test RE 0.004069242504569559\n",
      "206 Train Loss 0.008341681 Test MSE 3.134279637367505e-05 Test RE 0.0040448716700659726\n",
      "207 Train Loss 0.008316536 Test MSE 3.232982928694776e-05 Test RE 0.004108067610436769\n",
      "208 Train Loss 0.00821737 Test MSE 3.130840167534914e-05 Test RE 0.004042651696976595\n",
      "209 Train Loss 0.008177063 Test MSE 3.203836500176209e-05 Test RE 0.004089507879546162\n",
      "210 Train Loss 0.008072226 Test MSE 3.417883226302226e-05 Test RE 0.004223908358995395\n",
      "211 Train Loss 0.007980446 Test MSE 4.0881502890226224e-05 Test RE 0.0046195460782717905\n",
      "212 Train Loss 0.007861239 Test MSE 3.802754293858976e-05 Test RE 0.004455382652918339\n",
      "213 Train Loss 0.007795836 Test MSE 4.0664942290264665e-05 Test RE 0.004607294326448302\n",
      "214 Train Loss 0.007686286 Test MSE 4.026738624937295e-05 Test RE 0.004584717675004432\n",
      "215 Train Loss 0.0076427595 Test MSE 4.397932573113056e-05 Test RE 0.004791374974831776\n",
      "216 Train Loss 0.0075133215 Test MSE 4.879003702257967e-05 Test RE 0.005046629833455666\n",
      "217 Train Loss 0.0073977336 Test MSE 4.119738427380082e-05 Test RE 0.004637358787757649\n",
      "218 Train Loss 0.0072470214 Test MSE 4.040059867254938e-05 Test RE 0.004592294986677739\n",
      "219 Train Loss 0.007149561 Test MSE 3.2807347729141305e-05 Test RE 0.004138294919002036\n",
      "220 Train Loss 0.0070316303 Test MSE 3.334875740711997e-05 Test RE 0.00417230170319565\n",
      "221 Train Loss 0.0069631655 Test MSE 2.8234740155474766e-05 Test RE 0.0038390854130640546\n",
      "222 Train Loss 0.0068652523 Test MSE 2.740011057345765e-05 Test RE 0.003781917359253094\n",
      "223 Train Loss 0.006799032 Test MSE 2.4332232253725468e-05 Test RE 0.0035639110282275504\n",
      "224 Train Loss 0.0067386725 Test MSE 2.2769742685169828e-05 Test RE 0.0034475846491877214\n",
      "225 Train Loss 0.0066884435 Test MSE 2.195642730659171e-05 Test RE 0.0033854524162912256\n",
      "226 Train Loss 0.0066135204 Test MSE 2.0896305299355354e-05 Test RE 0.0033027114287240956\n",
      "227 Train Loss 0.0065598283 Test MSE 2.1267438246739877e-05 Test RE 0.0033319115741439836\n",
      "228 Train Loss 0.0064729876 Test MSE 2.1328113650083173e-05 Test RE 0.0033366611139997787\n",
      "229 Train Loss 0.006476224 Test MSE 2.054604804979934e-05 Test RE 0.003274914956237114\n",
      "230 Train Loss 0.0064317184 Test MSE 2.0222902430927634e-05 Test RE 0.003249059167162503\n",
      "231 Train Loss 0.0063824626 Test MSE 2.2211525959168957e-05 Test RE 0.0034050623993002733\n",
      "232 Train Loss 0.006348858 Test MSE 2.2766191670034535e-05 Test RE 0.003447315807708319\n",
      "233 Train Loss 0.006307216 Test MSE 2.2653697134606205e-05 Test RE 0.003438788153035839\n",
      "234 Train Loss 0.0062619415 Test MSE 2.260445795353965e-05 Test RE 0.003435048913031301\n",
      "235 Train Loss 0.0061879517 Test MSE 2.309770035939985e-05 Test RE 0.0034723240505904777\n",
      "236 Train Loss 0.006134904 Test MSE 2.3927613883140908e-05 Test RE 0.0035341548380596203\n",
      "237 Train Loss 0.0060968874 Test MSE 2.4502395705028986e-05 Test RE 0.0035763511285279753\n",
      "238 Train Loss 0.0060358746 Test MSE 2.6108068664430856e-05 Test RE 0.0036916732105203164\n",
      "239 Train Loss 0.0059911534 Test MSE 2.7817501834019423e-05 Test RE 0.0038106138321446705\n",
      "240 Train Loss 0.005932011 Test MSE 2.8189691348976874e-05 Test RE 0.0038360215411391615\n",
      "241 Train Loss 0.005900138 Test MSE 2.733097650407352e-05 Test RE 0.003777143209366882\n",
      "242 Train Loss 0.0058164075 Test MSE 2.8657126482245776e-05 Test RE 0.0038676948052275687\n",
      "243 Train Loss 0.005758741 Test MSE 3.088212716718913e-05 Test RE 0.0040150363396803945\n",
      "244 Train Loss 0.005714351 Test MSE 3.259620418583381e-05 Test RE 0.004124956677299996\n",
      "245 Train Loss 0.0056917556 Test MSE 3.370725001761972e-05 Test RE 0.004194667470029308\n",
      "246 Train Loss 0.0056402497 Test MSE 3.6251179756833634e-05 Test RE 0.00435007704902957\n",
      "247 Train Loss 0.00560796 Test MSE 3.623127846634074e-05 Test RE 0.004348882825385992\n",
      "248 Train Loss 0.005597465 Test MSE 3.666943268836313e-05 Test RE 0.004375099883608005\n",
      "249 Train Loss 0.005565298 Test MSE 3.662301024760621e-05 Test RE 0.004372329631635855\n",
      "250 Train Loss 0.005527509 Test MSE 3.7314017221923895e-05 Test RE 0.004413385671695061\n",
      "251 Train Loss 0.005525806 Test MSE 3.825499179141873e-05 Test RE 0.004468686969015087\n",
      "252 Train Loss 0.005502181 Test MSE 4.0107575240814334e-05 Test RE 0.004575610841491351\n",
      "253 Train Loss 0.0055043777 Test MSE 4.055522799688293e-05 Test RE 0.004601074872726456\n",
      "254 Train Loss 0.0054637147 Test MSE 3.767569265714191e-05 Test RE 0.004434723013677852\n",
      "255 Train Loss 0.0054685795 Test MSE 3.6525648631835715e-05 Test RE 0.004366513883852528\n",
      "256 Train Loss 0.005436738 Test MSE 3.814765702761566e-05 Test RE 0.0044624135082906346\n",
      "257 Train Loss 0.0054300027 Test MSE 3.6324937270450725e-05 Test RE 0.004354500185496352\n",
      "258 Train Loss 0.005417096 Test MSE 3.4703282595143985e-05 Test RE 0.004256191453284111\n",
      "259 Train Loss 0.0053282604 Test MSE 3.509358895115975e-05 Test RE 0.004280059134127599\n",
      "260 Train Loss 0.005268724 Test MSE 3.561609001256131e-05 Test RE 0.0043118038604741974\n",
      "261 Train Loss 0.005280161 Test MSE 3.5862492084003316e-05 Test RE 0.004326693285053812\n",
      "262 Train Loss 0.005197395 Test MSE 3.407692394206083e-05 Test RE 0.004217606611390165\n",
      "263 Train Loss 0.005203559 Test MSE 3.437745932103915e-05 Test RE 0.004236164001557144\n",
      "264 Train Loss 0.005183537 Test MSE 3.469370975612034e-05 Test RE 0.004255604381359564\n",
      "265 Train Loss 0.0051438953 Test MSE 3.679356676320165e-05 Test RE 0.004382498963517688\n",
      "266 Train Loss 0.005071516 Test MSE 3.73643474507754e-05 Test RE 0.004416361120000195\n",
      "267 Train Loss 0.005088263 Test MSE 3.6938170815721625e-05 Test RE 0.004391102446771697\n",
      "268 Train Loss 0.0050710496 Test MSE 3.751855231440946e-05 Test RE 0.004425465027869437\n",
      "269 Train Loss 0.0050301445 Test MSE 3.825080362877986e-05 Test RE 0.004468442346036405\n",
      "270 Train Loss 0.0050012157 Test MSE 3.719893148353352e-05 Test RE 0.0044065744245009066\n",
      "271 Train Loss 0.004923577 Test MSE 3.60170047744249e-05 Test RE 0.004336003994419475\n",
      "272 Train Loss 0.0048819175 Test MSE 3.644256330411188e-05 Test RE 0.004361544775867367\n",
      "273 Train Loss 0.0047953906 Test MSE 3.4843357843333705e-05 Test RE 0.004264772582113913\n",
      "274 Train Loss 0.0047488115 Test MSE 3.3578636681262185e-05 Test RE 0.004186657238082462\n",
      "275 Train Loss 0.004693963 Test MSE 3.3806279097846994e-05 Test RE 0.004200824741985721\n",
      "276 Train Loss 0.004640566 Test MSE 3.5490279775135866e-05 Test RE 0.004304181617697268\n",
      "277 Train Loss 0.004625116 Test MSE 3.5767570564840246e-05 Test RE 0.004320963504500261\n",
      "278 Train Loss 0.0045717256 Test MSE 3.565053776204939e-05 Test RE 0.004313888536833231\n",
      "279 Train Loss 0.0045293574 Test MSE 3.740593267330609e-05 Test RE 0.004418818064927426\n",
      "280 Train Loss 0.0044981297 Test MSE 3.504200808060829e-05 Test RE 0.004276912542904682\n",
      "281 Train Loss 0.004459708 Test MSE 3.507472248052103e-05 Test RE 0.004278908489976402\n",
      "282 Train Loss 0.0044316514 Test MSE 3.603622017769947e-05 Test RE 0.004337160489193257\n",
      "283 Train Loss 0.004386187 Test MSE 3.786354190690655e-05 Test RE 0.004445764928426891\n",
      "284 Train Loss 0.00433489 Test MSE 3.7919711960511936e-05 Test RE 0.004449061322487894\n",
      "285 Train Loss 0.0043455283 Test MSE 3.6575727217104956e-05 Test RE 0.004369506218633261\n",
      "286 Train Loss 0.004362326 Test MSE 3.5743516316576665e-05 Test RE 0.004319510302507312\n",
      "287 Train Loss 0.004361582 Test MSE 3.527922621223688e-05 Test RE 0.004291364482422271\n",
      "288 Train Loss 0.0043205386 Test MSE 3.2698059203794805e-05 Test RE 0.004131396381625058\n",
      "289 Train Loss 0.0042985836 Test MSE 3.250709273459751e-05 Test RE 0.004119314418454578\n",
      "290 Train Loss 0.004282992 Test MSE 3.165168171163313e-05 Test RE 0.004064754043984645\n",
      "291 Train Loss 0.0042468193 Test MSE 3.043547702927035e-05 Test RE 0.003985895729378037\n",
      "292 Train Loss 0.004234812 Test MSE 3.0178646489390163e-05 Test RE 0.003969042559300897\n",
      "293 Train Loss 0.004199592 Test MSE 3.0085851786655106e-05 Test RE 0.003962935763194765\n",
      "294 Train Loss 0.004173573 Test MSE 2.9883431564243626e-05 Test RE 0.003949581775681325\n",
      "295 Train Loss 0.0041336743 Test MSE 3.087290194314501e-05 Test RE 0.004014436601583596\n",
      "296 Train Loss 0.0040962 Test MSE 2.9110459121372005e-05 Test RE 0.003898166674930797\n",
      "297 Train Loss 0.0040613245 Test MSE 2.8420263889022354e-05 Test RE 0.0038516776184704727\n",
      "298 Train Loss 0.004044738 Test MSE 2.7732724252203046e-05 Test RE 0.003804802721899115\n",
      "299 Train Loss 0.0040379507 Test MSE 2.741165657909516e-05 Test RE 0.0037827140976448045\n",
      "Training time: 172.38\n",
      "KG_tanhALR_high\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 54618.43 Test MSE 9.775086230999793 Test RE 2.2588956833562612\n",
      "1 Train Loss 26660.979 Test MSE 3.8613607044425624 Test RE 1.4197309931198623\n",
      "2 Train Loss 13185.883 Test MSE 7.2908749598575895 Test RE 1.9508581932131837\n",
      "3 Train Loss 5203.467 Test MSE 13.950375405996173 Test RE 2.698539778230933\n",
      "4 Train Loss 3044.3274 Test MSE 13.938056252159866 Test RE 2.6973480157131533\n",
      "5 Train Loss 1987.6161 Test MSE 16.112732611697297 Test RE 2.900150107653542\n",
      "6 Train Loss 1385.5237 Test MSE 16.62760763962219 Test RE 2.9461222285496373\n",
      "7 Train Loss 997.3303 Test MSE 16.379035729894863 Test RE 2.9240180018217576\n",
      "8 Train Loss 734.3213 Test MSE 15.841772676350528 Test RE 2.875661515776002\n",
      "9 Train Loss 601.67926 Test MSE 16.105902032140868 Test RE 2.8995353203790106\n",
      "10 Train Loss 480.47833 Test MSE 16.082607393386834 Test RE 2.897437702121485\n",
      "11 Train Loss 448.87057 Test MSE 16.057121889961476 Test RE 2.8951410616017497\n",
      "12 Train Loss 411.46426 Test MSE 16.197248325243674 Test RE 2.907746202207749\n",
      "13 Train Loss 386.46964 Test MSE 16.282754726625736 Test RE 2.9154111968166596\n",
      "14 Train Loss 372.42435 Test MSE 16.028730045295564 Test RE 2.8925803672453196\n",
      "15 Train Loss 362.95364 Test MSE 15.951022955982253 Test RE 2.8855602512385636\n",
      "16 Train Loss 344.1222 Test MSE 16.05785754318697 Test RE 2.8952073809421983\n",
      "17 Train Loss 319.4333 Test MSE 16.030555041589782 Test RE 2.8927450340087564\n",
      "18 Train Loss 295.03952 Test MSE 15.513168434992052 Test RE 2.845680453829594\n",
      "19 Train Loss 287.9882 Test MSE 15.211676979778941 Test RE 2.817892519673039\n",
      "20 Train Loss 268.93005 Test MSE 13.596247099759594 Test RE 2.6640685851622683\n",
      "21 Train Loss 228.14568 Test MSE 12.524186752299741 Test RE 2.5568817558417862\n",
      "22 Train Loss 209.55197 Test MSE 12.08213663084991 Test RE 2.5113529193223507\n",
      "23 Train Loss 196.32808 Test MSE 11.193257547113001 Test RE 2.417208569269944\n",
      "24 Train Loss 167.27225 Test MSE 10.264209593534796 Test RE 2.3147208986979044\n",
      "25 Train Loss 152.6715 Test MSE 9.615907676976077 Test RE 2.2404281429625796\n",
      "26 Train Loss 129.22539 Test MSE 8.690586352398153 Test RE 2.1299058996200366\n",
      "27 Train Loss 113.75628 Test MSE 8.180011588237111 Test RE 2.066392592600565\n",
      "28 Train Loss 98.26949 Test MSE 7.322705827820385 Test RE 1.9551121325789964\n",
      "29 Train Loss 85.06486 Test MSE 6.429532037401045 Test RE 1.8320003792510333\n",
      "30 Train Loss 76.009056 Test MSE 5.071625448706771 Test RE 1.6270820842302682\n",
      "31 Train Loss 63.414238 Test MSE 3.0574252703702727 Test RE 1.2633212527366438\n",
      "32 Train Loss 43.93718 Test MSE 1.2687179621924243 Test RE 0.8138013784911747\n",
      "33 Train Loss 27.144642 Test MSE 0.5405289076775679 Test RE 0.5311844335350471\n",
      "34 Train Loss 18.7037 Test MSE 0.3791809457863199 Test RE 0.44489664390153405\n",
      "35 Train Loss 13.75214 Test MSE 0.30955121789261086 Test RE 0.4019778614726763\n",
      "36 Train Loss 11.058703 Test MSE 0.1987425565759886 Test RE 0.32209301966815834\n",
      "37 Train Loss 8.575057 Test MSE 0.12462546133179976 Test RE 0.25505818586170814\n",
      "38 Train Loss 6.152219 Test MSE 0.08415931052017377 Test RE 0.20959791653366253\n",
      "39 Train Loss 5.0216737 Test MSE 0.05265644892230234 Test RE 0.16579127088082762\n",
      "40 Train Loss 4.4021325 Test MSE 0.05142936198796153 Test RE 0.16384811343366693\n",
      "41 Train Loss 3.8088741 Test MSE 0.037487646641551325 Test RE 0.1398878404479832\n",
      "42 Train Loss 3.2450035 Test MSE 0.03514773245217951 Test RE 0.13545172269321587\n",
      "43 Train Loss 2.9898705 Test MSE 0.03020758569210741 Test RE 0.1255723104225885\n",
      "44 Train Loss 2.711261 Test MSE 0.025141616389912975 Test RE 0.11455986013009359\n",
      "45 Train Loss 2.5018902 Test MSE 0.022460869735447513 Test RE 0.10828022796986192\n",
      "46 Train Loss 2.233323 Test MSE 0.020027885125367465 Test RE 0.10224767060933215\n",
      "47 Train Loss 1.9301072 Test MSE 0.018520029007325894 Test RE 0.09832335930251132\n",
      "48 Train Loss 1.7908504 Test MSE 0.019477834813738205 Test RE 0.10083381900645953\n",
      "49 Train Loss 1.6495361 Test MSE 0.018910265587054224 Test RE 0.09935384776557055\n",
      "50 Train Loss 1.5108118 Test MSE 0.018070910274207173 Test RE 0.09712385047270858\n",
      "51 Train Loss 1.4118516 Test MSE 0.019636028151529344 Test RE 0.10124246251242447\n",
      "52 Train Loss 1.3686154 Test MSE 0.019084617483907648 Test RE 0.09981081613782862\n",
      "53 Train Loss 1.2371517 Test MSE 0.017368625271028237 Test RE 0.09521790011957802\n",
      "54 Train Loss 1.2040081 Test MSE 0.01720118102267228 Test RE 0.09475780893312806\n",
      "55 Train Loss 1.0773183 Test MSE 0.015938212756856578 Test RE 0.09121277882142236\n",
      "56 Train Loss 1.0124665 Test MSE 0.014842263428031386 Test RE 0.08802092832415934\n",
      "57 Train Loss 0.976719 Test MSE 0.014298040091934345 Test RE 0.08639212014661835\n",
      "58 Train Loss 0.90055364 Test MSE 0.015378307309500423 Test RE 0.08959631429391042\n",
      "59 Train Loss 0.8514569 Test MSE 0.014338143891034888 Test RE 0.08651319359987594\n",
      "60 Train Loss 0.8317163 Test MSE 0.014163827109495073 Test RE 0.08598569093064759\n",
      "61 Train Loss 0.7794916 Test MSE 0.0132869939050523 Test RE 0.08328163539391577\n",
      "62 Train Loss 0.75186056 Test MSE 0.013147346851605651 Test RE 0.08284283204986957\n",
      "63 Train Loss 0.7172775 Test MSE 0.012129069469099323 Test RE 0.07957004774105104\n",
      "64 Train Loss 0.6637453 Test MSE 0.011152182251140485 Test RE 0.07629846591578675\n",
      "65 Train Loss 0.6375212 Test MSE 0.011395128902148256 Test RE 0.07712505700594667\n",
      "66 Train Loss 0.55815005 Test MSE 0.01098702836964683 Test RE 0.0757314025135753\n",
      "67 Train Loss 0.50271183 Test MSE 0.01005948649742942 Test RE 0.0724642468733685\n",
      "68 Train Loss 0.49040616 Test MSE 0.009758112378046484 Test RE 0.07137050743497424\n",
      "69 Train Loss 0.4680912 Test MSE 0.009520716855354274 Test RE 0.07049701065849433\n",
      "70 Train Loss 0.44573247 Test MSE 0.00855109102712937 Test RE 0.06681079532329308\n",
      "71 Train Loss 0.42864117 Test MSE 0.008259811457360357 Test RE 0.06566303372832104\n",
      "72 Train Loss 0.41565752 Test MSE 0.007760248844556538 Test RE 0.06364637902888763\n",
      "73 Train Loss 0.39206898 Test MSE 0.006728324222549344 Test RE 0.05926377780248732\n",
      "74 Train Loss 0.37359226 Test MSE 0.00673175255654398 Test RE 0.05927887444040997\n",
      "75 Train Loss 0.35656086 Test MSE 0.006164369567035098 Test RE 0.05672574531378157\n",
      "76 Train Loss 0.34743026 Test MSE 0.005414861477898985 Test RE 0.05316545713220984\n",
      "77 Train Loss 0.33548823 Test MSE 0.005399667774833742 Test RE 0.05309081555443298\n",
      "78 Train Loss 0.31308094 Test MSE 0.0051484956041812505 Test RE 0.05184131986693738\n",
      "79 Train Loss 0.2941934 Test MSE 0.004723240663013917 Test RE 0.049654191433709756\n",
      "80 Train Loss 0.27515817 Test MSE 0.00424442643320569 Test RE 0.04707012831015199\n",
      "81 Train Loss 0.26502326 Test MSE 0.0039295469615073615 Test RE 0.045290500345249354\n",
      "82 Train Loss 0.25997174 Test MSE 0.0034761985886022618 Test RE 0.04259789770998203\n",
      "83 Train Loss 0.25106087 Test MSE 0.0034404983779294405 Test RE 0.04237859513560792\n",
      "84 Train Loss 0.24213998 Test MSE 0.0032398601664210343 Test RE 0.04112434653127268\n",
      "85 Train Loss 0.23720664 Test MSE 0.0029969852011596985 Test RE 0.039552885869725864\n",
      "86 Train Loss 0.23274584 Test MSE 0.0029188102363769826 Test RE 0.03903361796554383\n",
      "87 Train Loss 0.22770627 Test MSE 0.003043649825921562 Test RE 0.03985962600055449\n",
      "88 Train Loss 0.21853444 Test MSE 0.0028067265995249465 Test RE 0.038276827252772275\n",
      "89 Train Loss 0.210234 Test MSE 0.00260721973318077 Test RE 0.03689136240872072\n",
      "90 Train Loss 0.20659329 Test MSE 0.0026939526513149966 Test RE 0.03749996445372288\n",
      "91 Train Loss 0.20164917 Test MSE 0.0024557910690087108 Test RE 0.0358040029887497\n",
      "92 Train Loss 0.18564312 Test MSE 0.0022863717991317913 Test RE 0.03454691761127909\n",
      "93 Train Loss 0.1701152 Test MSE 0.0021631270218175893 Test RE 0.03360290995432275\n",
      "94 Train Loss 0.16716327 Test MSE 0.0021179085159513406 Test RE 0.03324983352372436\n",
      "95 Train Loss 0.16510217 Test MSE 0.0021028224375639988 Test RE 0.03313120091027535\n",
      "96 Train Loss 0.15882486 Test MSE 0.0018860442804045185 Test RE 0.03137702901517398\n",
      "97 Train Loss 0.15432692 Test MSE 0.0019011016956378421 Test RE 0.03150203077910907\n",
      "98 Train Loss 0.15276538 Test MSE 0.0018095180037801736 Test RE 0.03073387574603662\n",
      "99 Train Loss 0.15060657 Test MSE 0.0017231443975107357 Test RE 0.029991398200942782\n",
      "100 Train Loss 0.14491723 Test MSE 0.0017402436931453445 Test RE 0.030139837824307868\n",
      "101 Train Loss 0.14131573 Test MSE 0.0017580553830341891 Test RE 0.030293688335614688\n",
      "102 Train Loss 0.13757181 Test MSE 0.0017086567308668766 Test RE 0.029865052859134544\n",
      "103 Train Loss 0.13290974 Test MSE 0.0016750434941013525 Test RE 0.02956983635655953\n",
      "104 Train Loss 0.12892021 Test MSE 0.0016354382317309223 Test RE 0.029218165850279615\n",
      "105 Train Loss 0.12296357 Test MSE 0.0015490369187899924 Test RE 0.028435885785481858\n",
      "106 Train Loss 0.12195395 Test MSE 0.0015552751194253505 Test RE 0.028493086012487928\n",
      "107 Train Loss 0.119346514 Test MSE 0.0014737909922162436 Test RE 0.0277366384699009\n",
      "108 Train Loss 0.114867754 Test MSE 0.0013280444234594793 Test RE 0.02632947370544964\n",
      "109 Train Loss 0.11327404 Test MSE 0.0012136746742034694 Test RE 0.025170220590068914\n",
      "110 Train Loss 0.11134792 Test MSE 0.0011126991680779593 Test RE 0.024100428181887134\n",
      "111 Train Loss 0.11003402 Test MSE 0.001091875500587398 Test RE 0.023873848722279108\n",
      "112 Train Loss 0.107090145 Test MSE 0.0010399166415644599 Test RE 0.023298885172690156\n",
      "113 Train Loss 0.10370997 Test MSE 0.0009162313595895487 Test RE 0.02186947980983731\n",
      "114 Train Loss 0.10217444 Test MSE 0.0008907739624578676 Test RE 0.02156351890526944\n",
      "115 Train Loss 0.10007549 Test MSE 0.0008380324675122065 Test RE 0.020915405994758565\n",
      "116 Train Loss 0.09863357 Test MSE 0.0007820231377276279 Test RE 0.020204386988338163\n",
      "117 Train Loss 0.097504005 Test MSE 0.0007574007674642191 Test RE 0.019883770751046265\n",
      "118 Train Loss 0.09598841 Test MSE 0.0007426129193318782 Test RE 0.019688703876163956\n",
      "119 Train Loss 0.095118344 Test MSE 0.0006927318879065383 Test RE 0.01901596926083246\n",
      "120 Train Loss 0.09285937 Test MSE 0.0006465601460076721 Test RE 0.018371319175385325\n",
      "121 Train Loss 0.090466924 Test MSE 0.0006208404526443414 Test RE 0.018002212354087447\n",
      "122 Train Loss 0.087574236 Test MSE 0.0005780730389046561 Test RE 0.0173710965506993\n",
      "123 Train Loss 0.086382344 Test MSE 0.00055004701368453 Test RE 0.01694477406385068\n",
      "124 Train Loss 0.08529561 Test MSE 0.0005164043564798328 Test RE 0.01641839975260311\n",
      "125 Train Loss 0.08455739 Test MSE 0.0005215280944465083 Test RE 0.01649964997682756\n",
      "126 Train Loss 0.08343411 Test MSE 0.0005281277425782379 Test RE 0.01660371872817626\n",
      "127 Train Loss 0.0809753 Test MSE 0.0005118556685528954 Test RE 0.01634593002860327\n",
      "128 Train Loss 0.07985 Test MSE 0.0005127758736280827 Test RE 0.01636061664279996\n",
      "129 Train Loss 0.07834295 Test MSE 0.0005270964748470504 Test RE 0.016587499880883805\n",
      "130 Train Loss 0.0770287 Test MSE 0.0005421543898049653 Test RE 0.016822764533339137\n",
      "131 Train Loss 0.07512545 Test MSE 0.0005790261864359218 Test RE 0.017385411695383702\n",
      "132 Train Loss 0.07326776 Test MSE 0.0006251080923949946 Test RE 0.01806397973890025\n",
      "133 Train Loss 0.07187607 Test MSE 0.0005968167005411206 Test RE 0.017650473504324582\n",
      "134 Train Loss 0.07036213 Test MSE 0.0005774094786798875 Test RE 0.017361123694588507\n",
      "135 Train Loss 0.06911224 Test MSE 0.00054730551365188 Test RE 0.01690249392652982\n",
      "136 Train Loss 0.06764215 Test MSE 0.000540071470241756 Test RE 0.016790417487386994\n",
      "137 Train Loss 0.06605725 Test MSE 0.0005047025154012074 Test RE 0.01623131146275249\n",
      "138 Train Loss 0.06424964 Test MSE 0.0004894867360189864 Test RE 0.015984768127445856\n",
      "139 Train Loss 0.062794164 Test MSE 0.00047892546724416567 Test RE 0.015811382416161934\n",
      "140 Train Loss 0.06148191 Test MSE 0.00047040280618912037 Test RE 0.01567006611430063\n",
      "141 Train Loss 0.060746286 Test MSE 0.00046012778642390577 Test RE 0.015497980393000096\n",
      "142 Train Loss 0.06002829 Test MSE 0.0004486668491306292 Test RE 0.015303750186295534\n",
      "143 Train Loss 0.05958796 Test MSE 0.0004425290005411819 Test RE 0.01519871058916869\n",
      "144 Train Loss 0.058980882 Test MSE 0.00043267976713757145 Test RE 0.01502862232306903\n",
      "145 Train Loss 0.058047358 Test MSE 0.0004551229740156579 Test RE 0.015413464135636658\n",
      "146 Train Loss 0.056538004 Test MSE 0.0004218130113469319 Test RE 0.014838700282364125\n",
      "147 Train Loss 0.055793192 Test MSE 0.0004104309386804134 Test RE 0.01463712974002383\n",
      "148 Train Loss 0.054828726 Test MSE 0.0004237505507810415 Test RE 0.014872740990392569\n",
      "149 Train Loss 0.053856097 Test MSE 0.00044806186114441503 Test RE 0.015293428821758968\n",
      "150 Train Loss 0.053213175 Test MSE 0.00044375358061242524 Test RE 0.015219725234428877\n",
      "151 Train Loss 0.052300148 Test MSE 0.0004499559536538611 Test RE 0.015325719698065933\n",
      "152 Train Loss 0.051776946 Test MSE 0.00046688743482793595 Test RE 0.015611404257499168\n",
      "153 Train Loss 0.05183293 Test MSE 0.0004717945593123925 Test RE 0.01569323004512582\n",
      "154 Train Loss 0.050441004 Test MSE 0.00046610707770520154 Test RE 0.015598352326442041\n",
      "155 Train Loss 0.048612893 Test MSE 0.0004370194889180701 Test RE 0.01510380184665885\n",
      "156 Train Loss 0.047199823 Test MSE 0.00041394854383022903 Test RE 0.014699719800145965\n",
      "157 Train Loss 0.046302084 Test MSE 0.0004188626640353604 Test RE 0.014786714994808318\n",
      "158 Train Loss 0.04583362 Test MSE 0.0004219820606799924 Test RE 0.014841673425723826\n",
      "159 Train Loss 0.045087334 Test MSE 0.0004198332091658903 Test RE 0.014803836204002234\n",
      "160 Train Loss 0.04438837 Test MSE 0.00040402858845730194 Test RE 0.014522518052481045\n",
      "161 Train Loss 0.043689188 Test MSE 0.0003840275224128166 Test RE 0.014158493706610993\n",
      "162 Train Loss 0.04271977 Test MSE 0.0003763859888918334 Test RE 0.01401692020573829\n",
      "163 Train Loss 0.042247865 Test MSE 0.0003753266783848157 Test RE 0.013997181515463074\n",
      "164 Train Loss 0.04158092 Test MSE 0.0003576836598165941 Test RE 0.013664238294174538\n",
      "165 Train Loss 0.041267235 Test MSE 0.0003331308141430895 Test RE 0.013186917221476467\n",
      "166 Train Loss 0.040317606 Test MSE 0.00033172416128488517 Test RE 0.013159046732166857\n",
      "167 Train Loss 0.03934691 Test MSE 0.0003480491594912961 Test RE 0.01347895339059495\n",
      "168 Train Loss 0.038743928 Test MSE 0.00035531129908690463 Test RE 0.013618848420204988\n",
      "169 Train Loss 0.037917662 Test MSE 0.00034648449544092194 Test RE 0.013448621770250128\n",
      "170 Train Loss 0.03729613 Test MSE 0.00032306422406453165 Test RE 0.012986146874693806\n",
      "171 Train Loss 0.036624733 Test MSE 0.00030383819290289663 Test RE 0.012593807743516157\n",
      "172 Train Loss 0.036112532 Test MSE 0.0003004551271853748 Test RE 0.012523499035415615\n",
      "173 Train Loss 0.03558682 Test MSE 0.00029195195672408736 Test RE 0.012345013581431877\n",
      "174 Train Loss 0.034694746 Test MSE 0.0003000864437647816 Test RE 0.012515812989583762\n",
      "175 Train Loss 0.03414285 Test MSE 0.0002789961983398064 Test RE 0.012067992168197195\n",
      "176 Train Loss 0.033520292 Test MSE 0.0002628755050611706 Test RE 0.011714154209529435\n",
      "177 Train Loss 0.032805502 Test MSE 0.00024100879176318328 Test RE 0.011216369806181953\n",
      "178 Train Loss 0.032003947 Test MSE 0.0002441859062187291 Test RE 0.011290058022492474\n",
      "179 Train Loss 0.031552333 Test MSE 0.0002283771113275115 Test RE 0.010918479539356624\n",
      "180 Train Loss 0.030931534 Test MSE 0.00021734719520969504 Test RE 0.010651552124251881\n",
      "181 Train Loss 0.030561969 Test MSE 0.0002097008897146561 Test RE 0.010462513067705802\n",
      "182 Train Loss 0.03029838 Test MSE 0.0002082897745375699 Test RE 0.010427251576903109\n",
      "183 Train Loss 0.03007414 Test MSE 0.00021985046134414057 Test RE 0.010712715404658355\n",
      "184 Train Loss 0.029818986 Test MSE 0.00022724512388132563 Test RE 0.010891386335202187\n",
      "185 Train Loss 0.029517483 Test MSE 0.00022221095829556026 Test RE 0.010770072158466613\n",
      "186 Train Loss 0.029272005 Test MSE 0.00022239582910209242 Test RE 0.010774551365951126\n",
      "187 Train Loss 0.028832775 Test MSE 0.00024269556122210413 Test RE 0.01125555186663223\n",
      "188 Train Loss 0.028358007 Test MSE 0.00023246694275097962 Test RE 0.011015811073315701\n",
      "189 Train Loss 0.028342977 Test MSE 0.00023131201361776619 Test RE 0.010988412936322783\n",
      "190 Train Loss 0.028054854 Test MSE 0.00022992390632436732 Test RE 0.010955392497082614\n",
      "191 Train Loss 0.027727073 Test MSE 0.00022029722730424007 Test RE 0.010723594725838762\n",
      "192 Train Loss 0.027555082 Test MSE 0.00021704487370938474 Test RE 0.010644141598926033\n",
      "193 Train Loss 0.027278243 Test MSE 0.00020257028706841348 Test RE 0.010283092647182825\n",
      "194 Train Loss 0.027007842 Test MSE 0.00022186906933573282 Test RE 0.010761783669427554\n",
      "195 Train Loss 0.026633771 Test MSE 0.00022040712568280096 Test RE 0.010726269200559212\n",
      "196 Train Loss 0.026303252 Test MSE 0.00021174290186859102 Test RE 0.0105133302576394\n",
      "197 Train Loss 0.025988314 Test MSE 0.0001981897331317768 Test RE 0.010171299752242504\n",
      "198 Train Loss 0.025862742 Test MSE 0.00020874277330334062 Test RE 0.010438584266306977\n",
      "199 Train Loss 0.025681157 Test MSE 0.00020414282746578438 Test RE 0.010322928985617619\n",
      "200 Train Loss 0.025460405 Test MSE 0.00020863508681836913 Test RE 0.010435891383956732\n",
      "201 Train Loss 0.02528616 Test MSE 0.0002086759673708811 Test RE 0.010436913753002503\n",
      "202 Train Loss 0.025190394 Test MSE 0.00020196332015054956 Test RE 0.01026767533314705\n",
      "203 Train Loss 0.024942659 Test MSE 0.0002038343653931456 Test RE 0.010315127007286443\n",
      "204 Train Loss 0.02468849 Test MSE 0.0001935049409705259 Test RE 0.010050366664891192\n",
      "205 Train Loss 0.024462124 Test MSE 0.0001958788193483807 Test RE 0.010111826649070182\n",
      "206 Train Loss 0.024590624 Test MSE 0.00018972186794556097 Test RE 0.009951638070805967\n",
      "207 Train Loss 0.024417786 Test MSE 0.0001729189943748041 Test RE 0.009500735499276687\n",
      "208 Train Loss 0.024204092 Test MSE 0.00017040007678216536 Test RE 0.009431282853194445\n",
      "209 Train Loss 0.024027588 Test MSE 0.00017007197588086526 Test RE 0.00942219863371705\n",
      "210 Train Loss 0.023865933 Test MSE 0.00016785384758554657 Test RE 0.009360553444554737\n",
      "211 Train Loss 0.023659931 Test MSE 0.00017598250479641166 Test RE 0.009584525657168769\n",
      "212 Train Loss 0.023538865 Test MSE 0.00017593415084937898 Test RE 0.009583208817503712\n",
      "213 Train Loss 0.023277225 Test MSE 0.0001573497206109743 Test RE 0.009062934994575831\n",
      "214 Train Loss 0.02310057 Test MSE 0.0001464781608506892 Test RE 0.008744244974662738\n",
      "215 Train Loss 0.02299605 Test MSE 0.00014419512732331095 Test RE 0.008675832711812053\n",
      "216 Train Loss 0.02280428 Test MSE 0.00014551587137174416 Test RE 0.008715474951040539\n",
      "217 Train Loss 0.022705019 Test MSE 0.00014694093711615876 Test RE 0.008758047161509231\n",
      "218 Train Loss 0.022573855 Test MSE 0.000150972838180455 Test RE 0.008877389734616601\n",
      "219 Train Loss 0.022598095 Test MSE 0.00015262382524492253 Test RE 0.008925797792354195\n",
      "220 Train Loss 0.022197517 Test MSE 0.0001586528972274939 Test RE 0.009100387402133207\n",
      "221 Train Loss 0.021976715 Test MSE 0.00015683908575403756 Test RE 0.009048217424051342\n",
      "222 Train Loss 0.021701807 Test MSE 0.00016200238010885022 Test RE 0.009195949432686663\n",
      "223 Train Loss 0.021418758 Test MSE 0.00015988847527380315 Test RE 0.009135755276200534\n",
      "224 Train Loss 0.020991014 Test MSE 0.00018037191856029935 Test RE 0.00970331967198073\n",
      "225 Train Loss 0.02060399 Test MSE 0.00016669970170181257 Test RE 0.00932831683112942\n",
      "226 Train Loss 0.020225544 Test MSE 0.00013708565531904768 Test RE 0.008459250449588278\n",
      "227 Train Loss 0.019864015 Test MSE 0.00012539570254918787 Test RE 0.008090534299322277\n",
      "228 Train Loss 0.019583447 Test MSE 0.00012516940014390042 Test RE 0.008083230483707047\n",
      "229 Train Loss 0.019774782 Test MSE 0.00012326675762965684 Test RE 0.008021560496555159\n",
      "230 Train Loss 0.019697893 Test MSE 0.00012111117072475398 Test RE 0.007951113959368282\n",
      "231 Train Loss 0.019461682 Test MSE 0.00012180335578365884 Test RE 0.007973803034702394\n",
      "232 Train Loss 0.019200167 Test MSE 0.0001236872737290074 Test RE 0.008035231349248901\n",
      "233 Train Loss 0.019093955 Test MSE 0.00012590503692516314 Test RE 0.008106948782278954\n",
      "234 Train Loss 0.0189794 Test MSE 0.00012401438075369085 Test RE 0.008045849438971894\n",
      "235 Train Loss 0.018946508 Test MSE 0.00012040684001582814 Test RE 0.007927960110010816\n",
      "236 Train Loss 0.018746255 Test MSE 0.00011386580365353284 Test RE 0.007709612227026607\n",
      "237 Train Loss 0.01843708 Test MSE 0.00010978162057977038 Test RE 0.007570083948446055\n",
      "238 Train Loss 0.018278707 Test MSE 0.00010723049077811415 Test RE 0.007481609278405917\n",
      "239 Train Loss 0.018092414 Test MSE 0.00010882602639316449 Test RE 0.007537065037830561\n",
      "240 Train Loss 0.017923508 Test MSE 0.00010489740895953305 Test RE 0.007399770616574097\n",
      "241 Train Loss 0.017722106 Test MSE 0.00010497844266362231 Test RE 0.0074026282422713025\n",
      "242 Train Loss 0.017602565 Test MSE 0.00010598294391908154 Test RE 0.007437960477091357\n",
      "243 Train Loss 0.017371025 Test MSE 0.00010566310379384257 Test RE 0.007426728689844271\n",
      "244 Train Loss 0.017160859 Test MSE 9.606639111286086e-05 Test RE 0.007081440572760867\n",
      "245 Train Loss 0.016982304 Test MSE 9.69863732687335e-05 Test RE 0.007115267574307749\n",
      "246 Train Loss 0.016781159 Test MSE 9.664797602097952e-05 Test RE 0.00710284371093204\n",
      "247 Train Loss 0.016503746 Test MSE 9.097281581457785e-05 Test RE 0.0068911498766347215\n",
      "248 Train Loss 0.016316913 Test MSE 9.170264976083244e-05 Test RE 0.0069187369540551266\n",
      "249 Train Loss 0.01621799 Test MSE 8.929272737107934e-05 Test RE 0.006827220366219277\n",
      "250 Train Loss 0.01609267 Test MSE 9.568434152017844e-05 Test RE 0.007067345337805168\n",
      "251 Train Loss 0.016089534 Test MSE 9.508695997272682e-05 Test RE 0.0070452491835231125\n",
      "252 Train Loss 0.015941102 Test MSE 9.469258658351735e-05 Test RE 0.0070306239094316035\n",
      "253 Train Loss 0.016003996 Test MSE 9.562366869939775e-05 Test RE 0.0070651043035566295\n",
      "254 Train Loss 0.015735777 Test MSE 9.448475103902372e-05 Test RE 0.0070229041065067305\n",
      "255 Train Loss 0.015264817 Test MSE 9.268771640625748e-05 Test RE 0.006955798107280919\n",
      "256 Train Loss 0.015021287 Test MSE 8.468493069765733e-05 Test RE 0.006648733799612324\n",
      "257 Train Loss 0.014777441 Test MSE 8.143393738573498e-05 Test RE 0.006519864856098939\n",
      "258 Train Loss 0.0142678525 Test MSE 7.57692557138644e-05 Test RE 0.006289011479786666\n",
      "259 Train Loss 0.014040906 Test MSE 6.977755265496059e-05 Test RE 0.006035228859646748\n",
      "260 Train Loss 0.013829552 Test MSE 6.936015532988142e-05 Test RE 0.006017150933549314\n",
      "261 Train Loss 0.013789775 Test MSE 7.292112442066621e-05 Test RE 0.006169678806551062\n",
      "262 Train Loss 0.013600986 Test MSE 7.416832187804693e-05 Test RE 0.00622221628712585\n",
      "263 Train Loss 0.013380503 Test MSE 7.61645449802022e-05 Test RE 0.006305395069635855\n",
      "264 Train Loss 0.013233755 Test MSE 7.709993226910053e-05 Test RE 0.006343995630140279\n",
      "265 Train Loss 0.013093614 Test MSE 7.760465412017282e-05 Test RE 0.006364726712144772\n",
      "266 Train Loss 0.012946276 Test MSE 7.466418600594608e-05 Test RE 0.0062429814467137015\n",
      "267 Train Loss 0.012720011 Test MSE 7.664469352035176e-05 Test RE 0.006325238749959851\n",
      "268 Train Loss 0.012527916 Test MSE 7.089230349732747e-05 Test RE 0.00608324658417909\n",
      "269 Train Loss 0.012404631 Test MSE 6.752169661164117e-05 Test RE 0.0059368701469952505\n",
      "270 Train Loss 0.012278191 Test MSE 6.829158640793343e-05 Test RE 0.0059706206355275675\n",
      "271 Train Loss 0.012083699 Test MSE 7.044153921505078e-05 Test RE 0.006063875771394604\n",
      "272 Train Loss 0.01196062 Test MSE 7.552372143244985e-05 Test RE 0.006278813273928273\n",
      "273 Train Loss 0.011803152 Test MSE 6.975263934223659e-05 Test RE 0.006034151357201509\n",
      "274 Train Loss 0.01167618 Test MSE 6.761562439816403e-05 Test RE 0.0059409980296291805\n",
      "275 Train Loss 0.011641881 Test MSE 6.782541507403594e-05 Test RE 0.005950207444808863\n",
      "276 Train Loss 0.011509773 Test MSE 7.208957496511776e-05 Test RE 0.0061344002567546305\n",
      "277 Train Loss 0.011486696 Test MSE 7.207644338923926e-05 Test RE 0.006133841521242695\n",
      "278 Train Loss 0.01144215 Test MSE 7.13290619439127e-05 Test RE 0.0061019568639625365\n",
      "279 Train Loss 0.011401343 Test MSE 7.435703090779857e-05 Test RE 0.0062301269586587564\n",
      "280 Train Loss 0.011349198 Test MSE 7.176284053573163e-05 Test RE 0.006120482876924383\n",
      "281 Train Loss 0.011198457 Test MSE 6.677146521954776e-05 Test RE 0.005903795832151136\n",
      "282 Train Loss 0.011312336 Test MSE 6.450115500038809e-05 Test RE 0.005802559769634156\n",
      "283 Train Loss 0.011238225 Test MSE 6.222354445895125e-05 Test RE 0.005699191499978272\n",
      "284 Train Loss 0.011172265 Test MSE 5.982430218284425e-05 Test RE 0.005588235470908093\n",
      "285 Train Loss 0.011064902 Test MSE 6.107979874537654e-05 Test RE 0.0056465694692839925\n",
      "286 Train Loss 0.010968203 Test MSE 6.0793738333327215e-05 Test RE 0.005633331412787807\n",
      "287 Train Loss 0.010900704 Test MSE 6.115158467829648e-05 Test RE 0.005649886648098006\n",
      "288 Train Loss 0.010826044 Test MSE 6.113242622666849e-05 Test RE 0.005649001539723971\n",
      "289 Train Loss 0.010777747 Test MSE 6.108109392145806e-05 Test RE 0.005646629335746398\n",
      "290 Train Loss 0.010668792 Test MSE 5.616472476280687e-05 Test RE 0.005414616400384006\n",
      "291 Train Loss 0.01073255 Test MSE 5.33342300262963e-05 Test RE 0.005276414336983948\n",
      "292 Train Loss 0.010579635 Test MSE 5.026151769590635e-05 Test RE 0.005122166319010063\n",
      "293 Train Loss 0.010746665 Test MSE 5.1964762691902716e-05 Test RE 0.0052082323535093625\n",
      "294 Train Loss 0.010567788 Test MSE 4.813041685575466e-05 Test RE 0.005012399620658754\n",
      "295 Train Loss 0.010337592 Test MSE 4.286982734499471e-05 Test RE 0.004730551164915107\n",
      "296 Train Loss 0.010186328 Test MSE 4.48105710267321e-05 Test RE 0.004836443470508952\n",
      "297 Train Loss 0.010113087 Test MSE 4.6776021018031344e-05 Test RE 0.004941371600447797\n",
      "298 Train Loss 0.010036137 Test MSE 4.716969027938497e-05 Test RE 0.004962121445508415\n",
      "299 Train Loss 0.009952448 Test MSE 4.714659947369074e-05 Test RE 0.004960906752266948\n",
      "Training time: 171.89\n",
      "KG_tanhALR_high\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 52070.094 Test MSE 14.924731359148778 Test RE 2.7911883145124774\n",
      "1 Train Loss 32084.098 Test MSE 8.355956830360828 Test RE 2.088497552705351\n",
      "2 Train Loss 17834.48 Test MSE 12.986278703242526 Test RE 2.6036238219931342\n",
      "3 Train Loss 10942.992 Test MSE 12.211915905197845 Test RE 2.524804638324823\n",
      "4 Train Loss 6890.3804 Test MSE 11.086069469698856 Test RE 2.405606977416942\n",
      "5 Train Loss 3350.4546 Test MSE 11.001751878588877 Test RE 2.3964413242297398\n",
      "6 Train Loss 1669.7375 Test MSE 8.279687946616198 Test RE 2.0789443368402534\n",
      "7 Train Loss 984.6946 Test MSE 6.242931987916905 Test RE 1.805220175827249\n",
      "8 Train Loss 766.6597 Test MSE 5.623346809607644 Test RE 1.713299591041268\n",
      "9 Train Loss 639.9791 Test MSE 5.067949050838493 Test RE 1.626492245173286\n",
      "10 Train Loss 554.26306 Test MSE 4.0840816798646955 Test RE 1.4601016323634841\n",
      "11 Train Loss 460.11667 Test MSE 3.2428940381877385 Test RE 1.3010747723507252\n",
      "12 Train Loss 287.6479 Test MSE 1.3457822233657506 Test RE 0.8381529358200409\n",
      "13 Train Loss 115.32307 Test MSE 0.6793572194795426 Test RE 0.5955043995662644\n",
      "14 Train Loss 56.957 Test MSE 0.5308067206445105 Test RE 0.5263857009669969\n",
      "15 Train Loss 41.738445 Test MSE 0.4513603072403513 Test RE 0.48539752672125985\n",
      "16 Train Loss 29.31494 Test MSE 0.2723013740264316 Test RE 0.3770168784221718\n",
      "17 Train Loss 22.741959 Test MSE 0.1785813150791955 Test RE 0.3053190379710185\n",
      "18 Train Loss 16.235096 Test MSE 0.1364072097919586 Test RE 0.26684221664450924\n",
      "19 Train Loss 12.158426 Test MSE 0.08716631731080512 Test RE 0.21330951380715832\n",
      "20 Train Loss 8.816422 Test MSE 0.057524698916538775 Test RE 0.17328583126187277\n",
      "21 Train Loss 7.147436 Test MSE 0.052852269113706093 Test RE 0.16609925928367528\n",
      "22 Train Loss 5.704805 Test MSE 0.036510956118983855 Test RE 0.13805351855016132\n",
      "23 Train Loss 4.611326 Test MSE 0.028955320335312992 Test RE 0.12294194054912723\n",
      "24 Train Loss 3.8643978 Test MSE 0.025958581901169456 Test RE 0.11640626606035859\n",
      "25 Train Loss 3.1446733 Test MSE 0.026326362671260983 Test RE 0.11722798681636704\n",
      "26 Train Loss 2.855978 Test MSE 0.0242124913557922 Test RE 0.1124231154540039\n",
      "27 Train Loss 2.3573334 Test MSE 0.020276343999423557 Test RE 0.10287993998258722\n",
      "28 Train Loss 2.0899472 Test MSE 0.0183922976096499 Test RE 0.09798370784428695\n",
      "29 Train Loss 1.8050861 Test MSE 0.015134311551181527 Test RE 0.0888826945045632\n",
      "30 Train Loss 1.5758471 Test MSE 0.01580233963863518 Test RE 0.09082315260078094\n",
      "31 Train Loss 1.3660692 Test MSE 0.015274530263929687 Test RE 0.08929349226706584\n",
      "32 Train Loss 1.1761647 Test MSE 0.016096862334142117 Test RE 0.09166562244473078\n",
      "33 Train Loss 1.0211209 Test MSE 0.01338790690761669 Test RE 0.08359729381346434\n",
      "34 Train Loss 0.93212414 Test MSE 0.012765657823441018 Test RE 0.08163144354668704\n",
      "35 Train Loss 0.82387406 Test MSE 0.011503447992215891 Test RE 0.07749075522945278\n",
      "36 Train Loss 0.7431746 Test MSE 0.010564040213310052 Test RE 0.07425930832664639\n",
      "37 Train Loss 0.65478814 Test MSE 0.009422214532263128 Test RE 0.07013137779228004\n",
      "38 Train Loss 0.58035433 Test MSE 0.00963627106402884 Test RE 0.07092353616701778\n",
      "39 Train Loss 0.5131104 Test MSE 0.00859866145099956 Test RE 0.06699637456241785\n",
      "40 Train Loss 0.46103162 Test MSE 0.008504364973277204 Test RE 0.06662800688428965\n",
      "41 Train Loss 0.43798962 Test MSE 0.008450629531875016 Test RE 0.06641717639418308\n",
      "42 Train Loss 0.4075527 Test MSE 0.007964285584155748 Test RE 0.06447766317342069\n",
      "43 Train Loss 0.39035338 Test MSE 0.0074876552860179985 Test RE 0.06251853578035112\n",
      "44 Train Loss 0.35540354 Test MSE 0.0068384222244953306 Test RE 0.059746687623314476\n",
      "45 Train Loss 0.34595385 Test MSE 0.006561870874418503 Test RE 0.058526117771940674\n",
      "46 Train Loss 0.33047727 Test MSE 0.006062443978387048 Test RE 0.05625482086805074\n",
      "47 Train Loss 0.31582034 Test MSE 0.005959543799827683 Test RE 0.05577536035733033\n",
      "48 Train Loss 0.30605593 Test MSE 0.00593757543515807 Test RE 0.055672464500915\n",
      "49 Train Loss 0.291497 Test MSE 0.005746352752281261 Test RE 0.0547686477436034\n",
      "50 Train Loss 0.2779246 Test MSE 0.005550237629769025 Test RE 0.05382594529476727\n",
      "51 Train Loss 0.2630203 Test MSE 0.005121004680179335 Test RE 0.05170272857294588\n",
      "52 Train Loss 0.25336125 Test MSE 0.004892343327562125 Test RE 0.0505352408924289\n",
      "53 Train Loss 0.24775611 Test MSE 0.0047356195523639705 Test RE 0.049719216866182046\n",
      "54 Train Loss 0.2404269 Test MSE 0.004419863927467312 Test RE 0.04803306793125521\n",
      "55 Train Loss 0.230885 Test MSE 0.004179881197111712 Test RE 0.046710858147296655\n",
      "56 Train Loss 0.21985888 Test MSE 0.003970775735844562 Test RE 0.045527474163517025\n",
      "57 Train Loss 0.2100507 Test MSE 0.00359055540450935 Test RE 0.04329290148668422\n",
      "58 Train Loss 0.20104653 Test MSE 0.0033843935597229965 Test RE 0.042031637206001705\n",
      "59 Train Loss 0.193053 Test MSE 0.0031493289209933743 Test RE 0.04054570792830947\n",
      "60 Train Loss 0.1826221 Test MSE 0.003016081875357039 Test RE 0.03967870049868311\n",
      "61 Train Loss 0.1743253 Test MSE 0.00286603149905173 Test RE 0.03867909966958332\n",
      "62 Train Loss 0.16959219 Test MSE 0.0029888696669117592 Test RE 0.039499296950013855\n",
      "63 Train Loss 0.16559762 Test MSE 0.0029902575579389837 Test RE 0.03950846669700202\n",
      "64 Train Loss 0.15756553 Test MSE 0.003055284790252506 Test RE 0.03993573905384307\n",
      "65 Train Loss 0.14820617 Test MSE 0.0030481674874925646 Test RE 0.0398891966707268\n",
      "66 Train Loss 0.14252117 Test MSE 0.0029674007703091193 Test RE 0.03935718058045838\n",
      "67 Train Loss 0.13804664 Test MSE 0.0028480385395553216 Test RE 0.038557494723362354\n",
      "68 Train Loss 0.13369504 Test MSE 0.0027355212491527742 Test RE 0.03778817545999469\n",
      "69 Train Loss 0.13079488 Test MSE 0.002478984000483719 Test RE 0.03597267539558635\n",
      "70 Train Loss 0.12312694 Test MSE 0.0023270813047033935 Test RE 0.034853119509606054\n",
      "71 Train Loss 0.118460566 Test MSE 0.0019961608236026764 Test RE 0.0322800085333927\n",
      "72 Train Loss 0.11448635 Test MSE 0.0018349794650386287 Test RE 0.030949346348963055\n",
      "73 Train Loss 0.110884756 Test MSE 0.0017648234643979624 Test RE 0.030351943951290313\n",
      "74 Train Loss 0.10716448 Test MSE 0.00167795346709663 Test RE 0.029595510342483537\n",
      "75 Train Loss 0.10460995 Test MSE 0.0016168889280087557 Test RE 0.029051995649606546\n",
      "76 Train Loss 0.10187316 Test MSE 0.0014895850342241254 Test RE 0.02788486376661366\n",
      "77 Train Loss 0.098033875 Test MSE 0.001411289239859553 Test RE 0.02714212786270982\n",
      "78 Train Loss 0.093507685 Test MSE 0.001512193693343336 Test RE 0.028095682610186155\n",
      "79 Train Loss 0.088849545 Test MSE 0.0013891114893956945 Test RE 0.02692802045884342\n",
      "80 Train Loss 0.08657574 Test MSE 0.0013631333885667273 Test RE 0.026675038484398096\n",
      "81 Train Loss 0.08212019 Test MSE 0.0012536506677572783 Test RE 0.025581390370483535\n",
      "82 Train Loss 0.07936058 Test MSE 0.0011757822991062458 Test RE 0.02477418268652279\n",
      "83 Train Loss 0.0768111 Test MSE 0.0011051339668472998 Test RE 0.024018359480499425\n",
      "84 Train Loss 0.07394294 Test MSE 0.001128096270049856 Test RE 0.02426660151169462\n",
      "85 Train Loss 0.07192721 Test MSE 0.0010881880810763394 Test RE 0.023833501930809277\n",
      "86 Train Loss 0.069032624 Test MSE 0.000950423522535373 Test RE 0.02227380765865003\n",
      "87 Train Loss 0.068312645 Test MSE 0.0009054102308365845 Test RE 0.02173995174041395\n",
      "88 Train Loss 0.067021996 Test MSE 0.000858329447361013 Test RE 0.021167174160024407\n",
      "89 Train Loss 0.0660661 Test MSE 0.0008194751526072349 Test RE 0.020682535184218247\n",
      "90 Train Loss 0.06379765 Test MSE 0.0008465878086221556 Test RE 0.021021895938447957\n",
      "91 Train Loss 0.062066432 Test MSE 0.0007705989224783795 Test RE 0.02005626575510616\n",
      "92 Train Loss 0.061054755 Test MSE 0.0007326984313646492 Test RE 0.01955683212330418\n",
      "93 Train Loss 0.05902082 Test MSE 0.0006475916414052302 Test RE 0.018385967757834753\n",
      "94 Train Loss 0.057492424 Test MSE 0.0006329108895252368 Test RE 0.01817637026031275\n",
      "95 Train Loss 0.05481242 Test MSE 0.000614605178525431 Test RE 0.017911583603288095\n",
      "96 Train Loss 0.053728648 Test MSE 0.0005788142847386007 Test RE 0.017382230202520423\n",
      "97 Train Loss 0.05309903 Test MSE 0.000574997824422621 Test RE 0.017324829834398613\n",
      "98 Train Loss 0.051124338 Test MSE 0.0005557666427234517 Test RE 0.017032645802460052\n",
      "99 Train Loss 0.048893273 Test MSE 0.00051253691964157 Test RE 0.01635680416806608\n",
      "100 Train Loss 0.047240403 Test MSE 0.0005019153139724234 Test RE 0.016186430998364722\n",
      "101 Train Loss 0.044836577 Test MSE 0.0005358768561250745 Test RE 0.01672508668215891\n",
      "102 Train Loss 0.044063132 Test MSE 0.0005106222573488027 Test RE 0.01632622387440426\n",
      "103 Train Loss 0.043283246 Test MSE 0.0005104920063600579 Test RE 0.0163241414716127\n",
      "104 Train Loss 0.04236454 Test MSE 0.0005122665379640145 Test RE 0.01635248919737581\n",
      "105 Train Loss 0.04176688 Test MSE 0.0005249315898281065 Test RE 0.01655340083075919\n",
      "106 Train Loss 0.040920474 Test MSE 0.0005099747751117367 Test RE 0.016315869553781222\n",
      "107 Train Loss 0.03956575 Test MSE 0.0005097902690310541 Test RE 0.016312917790650003\n",
      "108 Train Loss 0.038741365 Test MSE 0.0005000087720323002 Test RE 0.016155659401764267\n",
      "109 Train Loss 0.038425535 Test MSE 0.0004951027044392763 Test RE 0.016076204653044032\n",
      "110 Train Loss 0.03760664 Test MSE 0.0005015851298271416 Test RE 0.016181106014256\n",
      "111 Train Loss 0.036870863 Test MSE 0.0004782626693243238 Test RE 0.015800437728098485\n",
      "112 Train Loss 0.03676559 Test MSE 0.0004676569470212427 Test RE 0.015624264123882488\n",
      "113 Train Loss 0.036291763 Test MSE 0.0004683120704227888 Test RE 0.015635204022121044\n",
      "114 Train Loss 0.035823625 Test MSE 0.0004474757320648283 Test RE 0.015283422550773333\n",
      "115 Train Loss 0.035460778 Test MSE 0.00044157107430472625 Test RE 0.015182251632671232\n",
      "116 Train Loss 0.03492839 Test MSE 0.00044958733848626873 Test RE 0.01531944080546131\n",
      "117 Train Loss 0.034295052 Test MSE 0.0004477861758066154 Test RE 0.015288723196049294\n",
      "118 Train Loss 0.033898704 Test MSE 0.00044850161240979266 Test RE 0.01530093186534238\n",
      "119 Train Loss 0.033638883 Test MSE 0.00043794601525437246 Test RE 0.015119804177422723\n",
      "120 Train Loss 0.032919955 Test MSE 0.0004299255491914706 Test RE 0.014980713701988236\n",
      "121 Train Loss 0.03208396 Test MSE 0.00040776022265210824 Test RE 0.014589429366647765\n",
      "122 Train Loss 0.031580362 Test MSE 0.0003894830182276256 Test RE 0.014258706850804392\n",
      "123 Train Loss 0.032109715 Test MSE 0.00038319205705808983 Test RE 0.014143084171033946\n",
      "124 Train Loss 0.031711355 Test MSE 0.0003592800482314087 Test RE 0.013694696977753948\n",
      "125 Train Loss 0.0311304 Test MSE 0.0003417572263779207 Test RE 0.013356563403864805\n",
      "126 Train Loss 0.030649967 Test MSE 0.0003379005630996945 Test RE 0.013280986481891412\n",
      "127 Train Loss 0.03031825 Test MSE 0.000336108266050755 Test RE 0.0132457170503573\n",
      "128 Train Loss 0.030153599 Test MSE 0.00033070000135026936 Test RE 0.013138717512519119\n",
      "129 Train Loss 0.029722823 Test MSE 0.0003155176276826446 Test RE 0.012833576118695286\n",
      "130 Train Loss 0.029613059 Test MSE 0.0003108363746791146 Test RE 0.012738016128455192\n",
      "131 Train Loss 0.028979115 Test MSE 0.0003061101254764068 Test RE 0.012640804788446258\n",
      "132 Train Loss 0.02861564 Test MSE 0.00030034344062634347 Test RE 0.01252117117279106\n",
      "133 Train Loss 0.028704686 Test MSE 0.00029544753482746016 Test RE 0.01241869789272984\n",
      "134 Train Loss 0.028231688 Test MSE 0.0002792617375137263 Test RE 0.012073733756368091\n",
      "135 Train Loss 0.027783323 Test MSE 0.0002627617242525619 Test RE 0.011711618807470058\n",
      "136 Train Loss 0.027382659 Test MSE 0.00025862084660276905 Test RE 0.011618970295726175\n",
      "137 Train Loss 0.026807075 Test MSE 0.00025604583087045235 Test RE 0.011560982166298053\n",
      "138 Train Loss 0.02631188 Test MSE 0.00025740554766380796 Test RE 0.011591638489004439\n",
      "139 Train Loss 0.025949422 Test MSE 0.0002538841483191932 Test RE 0.011512076576702676\n",
      "140 Train Loss 0.025439037 Test MSE 0.0002628320637918571 Test RE 0.011713186263214022\n",
      "141 Train Loss 0.025044743 Test MSE 0.00027351969003106094 Test RE 0.0119489618545383\n",
      "142 Train Loss 0.02486844 Test MSE 0.0002808417679442692 Test RE 0.012107841470708038\n",
      "143 Train Loss 0.024294302 Test MSE 0.0002724186814434403 Test RE 0.011924888312400888\n",
      "144 Train Loss 0.023891687 Test MSE 0.00026635949651950355 Test RE 0.011791524821822726\n",
      "145 Train Loss 0.023528222 Test MSE 0.00027009854475303275 Test RE 0.011873998754538723\n",
      "146 Train Loss 0.023219481 Test MSE 0.0002611104382267814 Test RE 0.011674760867080435\n",
      "147 Train Loss 0.022941206 Test MSE 0.0002580992431716688 Test RE 0.011607247432434738\n",
      "148 Train Loss 0.022753146 Test MSE 0.00025793699755387236 Test RE 0.011603598601354483\n",
      "149 Train Loss 0.0224487 Test MSE 0.00024620480711390395 Test RE 0.011336634397108797\n",
      "150 Train Loss 0.022148324 Test MSE 0.00023925991975430057 Test RE 0.011175600109666058\n",
      "151 Train Loss 0.021981167 Test MSE 0.0002347314003615226 Test RE 0.01106933348851847\n",
      "152 Train Loss 0.021656705 Test MSE 0.00023896911351939325 Test RE 0.011168806405312662\n",
      "153 Train Loss 0.021757945 Test MSE 0.00023905945972876646 Test RE 0.011170917481409973\n",
      "154 Train Loss 0.021458693 Test MSE 0.000244408866674301 Test RE 0.011295211190776838\n",
      "155 Train Loss 0.021376342 Test MSE 0.00023772167240551602 Test RE 0.011139617156012444\n",
      "156 Train Loss 0.021249766 Test MSE 0.00023368158676421264 Test RE 0.011044552485454906\n",
      "157 Train Loss 0.02103499 Test MSE 0.00023745860458400416 Test RE 0.011133451782093715\n",
      "158 Train Loss 0.020819131 Test MSE 0.0002341204622918216 Test RE 0.0110549189634831\n",
      "159 Train Loss 0.02050012 Test MSE 0.0002361861729057664 Test RE 0.011103582184827238\n",
      "160 Train Loss 0.020224575 Test MSE 0.00023064938861218503 Test RE 0.010972662740194516\n",
      "161 Train Loss 0.02015461 Test MSE 0.00022990279450919594 Test RE 0.010954889518652181\n",
      "162 Train Loss 0.019800534 Test MSE 0.00022292534821467033 Test RE 0.010787370713494334\n",
      "163 Train Loss 0.020381594 Test MSE 0.00021924239827667049 Test RE 0.010697890516631446\n",
      "164 Train Loss 0.019916363 Test MSE 0.00021592550964815788 Test RE 0.01061665863891242\n",
      "165 Train Loss 0.019752037 Test MSE 0.00020624821498945982 Test RE 0.010376024204610737\n",
      "166 Train Loss 0.019492654 Test MSE 0.00019629593921660437 Test RE 0.010122587385602058\n",
      "167 Train Loss 0.019573033 Test MSE 0.00019032900370693085 Test RE 0.009967548649116677\n",
      "168 Train Loss 0.01913114 Test MSE 0.00017800159933687104 Test RE 0.009639351765472601\n",
      "169 Train Loss 0.019020492 Test MSE 0.00017175069300540068 Test RE 0.0094685859533503\n",
      "170 Train Loss 0.01871423 Test MSE 0.00016329844605655132 Test RE 0.009232661281651912\n",
      "171 Train Loss 0.018481474 Test MSE 0.00016291670101915856 Test RE 0.009221863307286988\n",
      "172 Train Loss 0.018253 Test MSE 0.00015532555865769684 Test RE 0.009004453072408379\n",
      "173 Train Loss 0.017983308 Test MSE 0.00015366436872825932 Test RE 0.008956172815027226\n",
      "174 Train Loss 0.01773723 Test MSE 0.00015527591315187212 Test RE 0.00900301394559222\n",
      "175 Train Loss 0.01736821 Test MSE 0.0001496373488152974 Test RE 0.008838038302921708\n",
      "176 Train Loss 0.017163374 Test MSE 0.00015287679231634906 Test RE 0.008933191782425033\n",
      "177 Train Loss 0.017073134 Test MSE 0.00015596174762195168 Test RE 0.009022874637773801\n",
      "178 Train Loss 0.016893793 Test MSE 0.00015943583087833215 Test RE 0.009122814445755864\n",
      "179 Train Loss 0.016649976 Test MSE 0.0001603605744456866 Test RE 0.009149232806311967\n",
      "180 Train Loss 0.016561417 Test MSE 0.0001629805126240272 Test RE 0.00922366915126301\n",
      "181 Train Loss 0.016406668 Test MSE 0.00015529117514046214 Test RE 0.009003456385495327\n",
      "182 Train Loss 0.0161819 Test MSE 0.0001467207679678095 Test RE 0.008751483386077065\n",
      "183 Train Loss 0.015862703 Test MSE 0.00014607981729633905 Test RE 0.008732347006543007\n",
      "184 Train Loss 0.015773462 Test MSE 0.000142563290240415 Test RE 0.008626601406857708\n",
      "185 Train Loss 0.015640039 Test MSE 0.00014748619837118193 Test RE 0.00877428158187773\n",
      "186 Train Loss 0.015457298 Test MSE 0.0001473318388406379 Test RE 0.008769688784162939\n",
      "187 Train Loss 0.0152275115 Test MSE 0.00014416214596726956 Test RE 0.008674840455357716\n",
      "188 Train Loss 0.0151504185 Test MSE 0.0001392866417996065 Test RE 0.008526889023591082\n",
      "189 Train Loss 0.01490093 Test MSE 0.00013917460374194478 Test RE 0.008523458944941453\n",
      "190 Train Loss 0.014638066 Test MSE 0.00013869082587799212 Test RE 0.008508632064780773\n",
      "191 Train Loss 0.014492403 Test MSE 0.00013474530756012653 Test RE 0.008386730776665149\n",
      "192 Train Loss 0.014297852 Test MSE 0.00013261834249021778 Test RE 0.008320274884649292\n",
      "193 Train Loss 0.014059278 Test MSE 0.0001318743951667616 Test RE 0.008296904997337472\n",
      "194 Train Loss 0.014113553 Test MSE 0.0001313049955054783 Test RE 0.008278973671635123\n",
      "195 Train Loss 0.013940196 Test MSE 0.00012401941378055263 Test RE 0.00804601270457565\n",
      "196 Train Loss 0.013934216 Test MSE 0.00012689049265196873 Test RE 0.008138613391076188\n",
      "197 Train Loss 0.013702737 Test MSE 0.00012962600481734304 Test RE 0.008225871953310118\n",
      "198 Train Loss 0.013583483 Test MSE 0.00012240887149045953 Test RE 0.007993598372791908\n",
      "199 Train Loss 0.01364003 Test MSE 0.00011940201721345876 Test RE 0.007894810478564497\n",
      "200 Train Loss 0.013545823 Test MSE 0.00011686882569582244 Test RE 0.007810614746093117\n",
      "201 Train Loss 0.013408354 Test MSE 0.00011171807229217887 Test RE 0.007636556926496879\n",
      "202 Train Loss 0.013359064 Test MSE 0.00011286494144342973 Test RE 0.0076756543117029825\n",
      "203 Train Loss 0.013167416 Test MSE 0.00011184926492338295 Test RE 0.007641039487029814\n",
      "204 Train Loss 0.012989418 Test MSE 0.00010886246535824509 Test RE 0.00753832677581979\n",
      "205 Train Loss 0.012787734 Test MSE 0.00011055093906980879 Test RE 0.007596562143160641\n",
      "206 Train Loss 0.012654935 Test MSE 0.00010828071002106046 Test RE 0.007518157581377887\n",
      "207 Train Loss 0.0125299515 Test MSE 0.00010784887175357917 Test RE 0.007503150884367583\n",
      "208 Train Loss 0.01234001 Test MSE 0.00010899653226460985 Test RE 0.007542967168543024\n",
      "209 Train Loss 0.012251628 Test MSE 0.00011093355999575839 Test RE 0.0076096967806525044\n",
      "210 Train Loss 0.012071219 Test MSE 0.00011258764582920097 Test RE 0.007666219432370531\n",
      "211 Train Loss 0.011969978 Test MSE 0.00011220578549227502 Test RE 0.007653207740241841\n",
      "212 Train Loss 0.011823485 Test MSE 0.00011469190187253639 Test RE 0.007737528365271464\n",
      "213 Train Loss 0.011727997 Test MSE 0.00011540043823695576 Test RE 0.007761391772794961\n",
      "214 Train Loss 0.0115697775 Test MSE 0.00011714574829351156 Test RE 0.007819862960704737\n",
      "215 Train Loss 0.011405609 Test MSE 0.00011957534019224512 Test RE 0.007900538421395672\n",
      "216 Train Loss 0.011205563 Test MSE 0.0001160899484198884 Test RE 0.007784544148689656\n",
      "217 Train Loss 0.01113708 Test MSE 0.00011232503507927952 Test RE 0.007657273482055597\n",
      "218 Train Loss 0.010959717 Test MSE 0.00011699764968732681 Test RE 0.007814918363561093\n",
      "219 Train Loss 0.010860758 Test MSE 0.00011432069237828932 Test RE 0.0077249966530292605\n",
      "220 Train Loss 0.01100056 Test MSE 0.00010944073078046264 Test RE 0.007558321639014437\n",
      "221 Train Loss 0.010875385 Test MSE 0.00010311224220280791 Test RE 0.0073365349755257474\n",
      "222 Train Loss 0.01064511 Test MSE 9.978862795318567e-05 Test RE 0.007217327331647278\n",
      "223 Train Loss 0.010479202 Test MSE 9.942244176132797e-05 Test RE 0.00720407274182284\n",
      "224 Train Loss 0.010372606 Test MSE 0.00010023845470457937 Test RE 0.00723357615931653\n",
      "225 Train Loss 0.010243504 Test MSE 9.853053127178556e-05 Test RE 0.007171686374420603\n",
      "226 Train Loss 0.010105806 Test MSE 9.435504558659044e-05 Test RE 0.007018082049108708\n",
      "227 Train Loss 0.01015928 Test MSE 9.158530066364625e-05 Test RE 0.006914308688094285\n",
      "228 Train Loss 0.010049276 Test MSE 9.22451297652063e-05 Test RE 0.0069391711621235195\n",
      "229 Train Loss 0.009938899 Test MSE 9.470077507506232e-05 Test RE 0.007030927887609729\n",
      "230 Train Loss 0.009876684 Test MSE 9.460856426587365e-05 Test RE 0.007027504022036807\n",
      "231 Train Loss 0.00982604 Test MSE 9.168888532021207e-05 Test RE 0.00691821768815574\n",
      "232 Train Loss 0.009687572 Test MSE 9.000857154282703e-05 Test RE 0.006854532052792508\n",
      "233 Train Loss 0.009623656 Test MSE 8.84342664763007e-05 Test RE 0.006794322633732434\n",
      "234 Train Loss 0.009516627 Test MSE 9.15233579563148e-05 Test RE 0.006911970084419164\n",
      "235 Train Loss 0.009381926 Test MSE 8.761451400823988e-05 Test RE 0.006762758906727248\n",
      "236 Train Loss 0.0093369465 Test MSE 8.796038995309544e-05 Test RE 0.0067760944351239315\n",
      "237 Train Loss 0.0094042905 Test MSE 9.681725222571538e-05 Test RE 0.0071090612049191145\n",
      "238 Train Loss 0.009200692 Test MSE 0.00010075283155285218 Test RE 0.007252112074474343\n",
      "239 Train Loss 0.0090060625 Test MSE 8.736893501908116e-05 Test RE 0.006753274422750674\n",
      "240 Train Loss 0.008910249 Test MSE 8.176897237652033e-05 Test RE 0.006533263082921895\n",
      "241 Train Loss 0.008778166 Test MSE 8.028298881133938e-05 Test RE 0.006473626561336573\n",
      "242 Train Loss 0.008640942 Test MSE 7.572108128412512e-05 Test RE 0.006287011871162636\n",
      "243 Train Loss 0.008552314 Test MSE 7.316978189418724e-05 Test RE 0.006180189006091228\n",
      "244 Train Loss 0.008411192 Test MSE 6.914600732443277e-05 Test RE 0.006007854839817838\n",
      "245 Train Loss 0.008297542 Test MSE 6.879806562362805e-05 Test RE 0.005992720057320608\n",
      "246 Train Loss 0.008179493 Test MSE 6.817911525973749e-05 Test RE 0.00596570202616105\n",
      "247 Train Loss 0.008074742 Test MSE 6.74758108126676e-05 Test RE 0.005934852541237671\n",
      "248 Train Loss 0.007999555 Test MSE 6.658881166041772e-05 Test RE 0.005895715376038847\n",
      "249 Train Loss 0.007919553 Test MSE 6.369209214537266e-05 Test RE 0.005766053056773494\n",
      "250 Train Loss 0.007881341 Test MSE 6.268354973435187e-05 Test RE 0.005720219156531335\n",
      "251 Train Loss 0.007816496 Test MSE 5.858111269957008e-05 Test RE 0.005529866987465041\n",
      "252 Train Loss 0.0078084217 Test MSE 5.8189424141000595e-05 Test RE 0.005511348916791993\n",
      "253 Train Loss 0.007805861 Test MSE 5.74455283476085e-05 Test RE 0.0054760069539869045\n",
      "254 Train Loss 0.007735818 Test MSE 5.646327311224637e-05 Test RE 0.005428988252938806\n",
      "255 Train Loss 0.007631811 Test MSE 5.755004075326938e-05 Test RE 0.0054809860237908055\n",
      "256 Train Loss 0.0075373785 Test MSE 5.803841733887693e-05 Test RE 0.00550419304756788\n",
      "257 Train Loss 0.0074553373 Test MSE 5.612173298994312e-05 Test RE 0.005412543671254715\n",
      "258 Train Loss 0.007435576 Test MSE 5.520514248291741e-05 Test RE 0.005368162383030619\n",
      "259 Train Loss 0.007344927 Test MSE 5.375747018040943e-05 Test RE 0.005297308774488145\n",
      "260 Train Loss 0.0072679087 Test MSE 5.403033227027223e-05 Test RE 0.005310735793973737\n",
      "261 Train Loss 0.00716634 Test MSE 5.317355609405152e-05 Test RE 0.00526846051720457\n",
      "262 Train Loss 0.007136152 Test MSE 5.096161959424039e-05 Test RE 0.005157716747074535\n",
      "263 Train Loss 0.006998075 Test MSE 4.9800622323634835e-05 Test RE 0.005098627239009815\n",
      "264 Train Loss 0.0068728332 Test MSE 4.823894009575155e-05 Test RE 0.005018047354460741\n",
      "265 Train Loss 0.0068910564 Test MSE 4.860306117659161e-05 Test RE 0.005036950565890297\n",
      "266 Train Loss 0.0067708176 Test MSE 4.911104379188651e-05 Test RE 0.005063204389721911\n",
      "267 Train Loss 0.0067250314 Test MSE 4.916238796762939e-05 Test RE 0.005065850415184699\n",
      "268 Train Loss 0.006638454 Test MSE 4.84458123972909e-05 Test RE 0.0050287957707608666\n",
      "269 Train Loss 0.006564347 Test MSE 4.756278103045433e-05 Test RE 0.004982754579848267\n",
      "270 Train Loss 0.006398074 Test MSE 4.731768209939254e-05 Test RE 0.004969899515332975\n",
      "271 Train Loss 0.0063314294 Test MSE 4.7207475789813707e-05 Test RE 0.0049641085134417085\n",
      "272 Train Loss 0.006254491 Test MSE 4.8611155623978005e-05 Test RE 0.005037369980151085\n",
      "273 Train Loss 0.006187793 Test MSE 4.883494999149384e-05 Test RE 0.005048952100507527\n",
      "274 Train Loss 0.006130156 Test MSE 4.75094432975152e-05 Test RE 0.004979959922149734\n",
      "275 Train Loss 0.006092596 Test MSE 4.7641645274485077e-05 Test RE 0.004986883842335426\n",
      "276 Train Loss 0.0060261777 Test MSE 4.5725379612441565e-05 Test RE 0.004885562086441763\n",
      "277 Train Loss 0.0059474898 Test MSE 4.498882743778748e-05 Test RE 0.004846053606594477\n",
      "278 Train Loss 0.005933435 Test MSE 4.394195979409379e-05 Test RE 0.004789339106195726\n",
      "279 Train Loss 0.0059235482 Test MSE 4.4311225786302926e-05 Test RE 0.004809420596830479\n",
      "280 Train Loss 0.005883015 Test MSE 4.4103126790367005e-05 Test RE 0.0047981140553853135\n",
      "281 Train Loss 0.00581563 Test MSE 4.2502410455419965e-05 Test RE 0.0047102358916675455\n",
      "282 Train Loss 0.005740332 Test MSE 4.215720964195486e-05 Test RE 0.004691068834663926\n",
      "283 Train Loss 0.005697195 Test MSE 4.2171569602036646e-05 Test RE 0.0046918677232320165\n",
      "284 Train Loss 0.005702482 Test MSE 4.1735350421254554e-05 Test RE 0.004667538501623034\n",
      "285 Train Loss 0.0056310073 Test MSE 4.263085113945762e-05 Test RE 0.00471734760064556\n",
      "286 Train Loss 0.0055789114 Test MSE 4.386418575644953e-05 Test RE 0.004785098840103635\n",
      "287 Train Loss 0.0054969313 Test MSE 4.781307136302848e-05 Test RE 0.004995847789203045\n",
      "288 Train Loss 0.0054988083 Test MSE 4.944537392021398e-05 Test RE 0.005080409385247666\n",
      "289 Train Loss 0.0053941356 Test MSE 5.327884328595031e-05 Test RE 0.005273673889595531\n",
      "290 Train Loss 0.0054276884 Test MSE 4.92975065150601e-05 Test RE 0.005072807163092327\n",
      "291 Train Loss 0.0053068213 Test MSE 5.1561364190829834e-05 Test RE 0.0051879774116816435\n",
      "292 Train Loss 0.005244722 Test MSE 5.2057602348765484e-05 Test RE 0.005212882761831274\n",
      "293 Train Loss 0.0051881247 Test MSE 4.9433920516258324e-05 Test RE 0.005079820944445666\n",
      "294 Train Loss 0.0051097847 Test MSE 4.768711269004384e-05 Test RE 0.0049892629231403285\n",
      "295 Train Loss 0.0050853505 Test MSE 4.713046677217816e-05 Test RE 0.004960057914001065\n",
      "296 Train Loss 0.0050474857 Test MSE 4.4420549339059245e-05 Test RE 0.004815349783360629\n",
      "297 Train Loss 0.0049752933 Test MSE 4.4073373832238924e-05 Test RE 0.004796495324673331\n",
      "298 Train Loss 0.004894143 Test MSE 4.259497863511896e-05 Test RE 0.004715362434015175\n",
      "299 Train Loss 0.0048901057 Test MSE 4.430696838006732e-05 Test RE 0.004809189547601732\n",
      "Training time: 150.29\n",
      "KG_tanhALR_high\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 53158.016 Test MSE 5.537102751742739 Test RE 1.7001105731095254\n",
      "1 Train Loss 28359.479 Test MSE 5.532707790746826 Test RE 1.699435725336978\n",
      "2 Train Loss 14551.526 Test MSE 6.581812643917567 Test RE 1.8535684759710684\n",
      "3 Train Loss 6395.6367 Test MSE 8.374169795932362 Test RE 2.0907723986760622\n",
      "4 Train Loss 3862.7231 Test MSE 11.283609858034318 Test RE 2.4269448509364926\n",
      "5 Train Loss 2208.5947 Test MSE 14.14856687153266 Test RE 2.7176411053821066\n",
      "6 Train Loss 1628.2761 Test MSE 14.754582196308979 Test RE 2.775232258436972\n",
      "7 Train Loss 1198.3527 Test MSE 16.511372659280674 Test RE 2.9358067632373652\n",
      "8 Train Loss 973.72046 Test MSE 17.91100765949328 Test RE 3.057707135317156\n",
      "9 Train Loss 819.1306 Test MSE 18.418602041549715 Test RE 3.1007318419869754\n",
      "10 Train Loss 666.13074 Test MSE 18.229503469528545 Test RE 3.0847736087157527\n",
      "11 Train Loss 554.7273 Test MSE 17.220240081076863 Test RE 2.9981646404004363\n",
      "12 Train Loss 438.0482 Test MSE 16.22046360544224 Test RE 2.9098292712148446\n",
      "13 Train Loss 392.13712 Test MSE 15.752051367033852 Test RE 2.867506668687326\n",
      "14 Train Loss 350.63693 Test MSE 15.700517440210769 Test RE 2.86281220265832\n",
      "15 Train Loss 313.59116 Test MSE 15.76585741100314 Test RE 2.8687630210029607\n",
      "16 Train Loss 292.57538 Test MSE 15.594406102019875 Test RE 2.8531216990566137\n",
      "17 Train Loss 279.04648 Test MSE 15.474659108539692 Test RE 2.8421462522195053\n",
      "18 Train Loss 253.57672 Test MSE 15.02217753966357 Test RE 2.8002855675446217\n",
      "19 Train Loss 238.08765 Test MSE 14.71424810926329 Test RE 2.7714363846557486\n",
      "20 Train Loss 222.86182 Test MSE 14.263853634612655 Test RE 2.728690719248054\n",
      "21 Train Loss 201.9707 Test MSE 13.897603977015633 Test RE 2.693430929025489\n",
      "22 Train Loss 191.54015 Test MSE 13.510503884345328 Test RE 2.655654973654767\n",
      "23 Train Loss 165.19672 Test MSE 12.176211297212221 Test RE 2.5211109857878773\n",
      "24 Train Loss 138.13794 Test MSE 11.136569119697871 Test RE 2.411079804365028\n",
      "25 Train Loss 117.573074 Test MSE 10.564869392443224 Test RE 2.348377675312475\n",
      "26 Train Loss 101.61355 Test MSE 10.074757924710719 Test RE 2.2932594233806487\n",
      "27 Train Loss 91.23772 Test MSE 9.249706220631122 Test RE 2.197353078825852\n",
      "28 Train Loss 77.733055 Test MSE 8.632864588844084 Test RE 2.1228208341457058\n",
      "29 Train Loss 69.166565 Test MSE 7.976027256965832 Test RE 2.040465196753964\n",
      "30 Train Loss 61.427204 Test MSE 7.736935401034517 Test RE 2.009649698559748\n",
      "31 Train Loss 55.486816 Test MSE 6.755804524141483 Test RE 1.8779084424345927\n",
      "32 Train Loss 50.627678 Test MSE 5.95021559743139 Test RE 1.762390844085195\n",
      "33 Train Loss 42.118057 Test MSE 5.011870693880972 Test RE 1.617468403700589\n",
      "34 Train Loss 36.06393 Test MSE 4.560932271381015 Test RE 1.5429884971999486\n",
      "35 Train Loss 32.99763 Test MSE 4.177835325975491 Test RE 1.4767654929094305\n",
      "36 Train Loss 29.769567 Test MSE 3.4544623957958875 Test RE 1.3428456962686848\n",
      "37 Train Loss 25.660452 Test MSE 2.5997230622423655 Test RE 1.1649289020671405\n",
      "38 Train Loss 21.507215 Test MSE 1.8415118564571975 Test RE 0.9804447753796519\n",
      "39 Train Loss 17.892748 Test MSE 1.1589465050159622 Test RE 0.7777993429924084\n",
      "40 Train Loss 15.621329 Test MSE 0.9189191107945736 Test RE 0.692587292204113\n",
      "41 Train Loss 13.092769 Test MSE 0.6478192279772288 Test RE 0.5815175069805486\n",
      "42 Train Loss 9.901042 Test MSE 0.36690483922185685 Test RE 0.4376355534831491\n",
      "43 Train Loss 8.131737 Test MSE 0.24759272215480777 Test RE 0.35950490009404706\n",
      "44 Train Loss 6.6895475 Test MSE 0.19371583364222314 Test RE 0.31799364205976605\n",
      "45 Train Loss 5.676871 Test MSE 0.18177014946506573 Test RE 0.3080329386461999\n",
      "46 Train Loss 4.319945 Test MSE 0.13287829817544547 Test RE 0.26336793923070384\n",
      "47 Train Loss 3.7802854 Test MSE 0.11581677327554137 Test RE 0.24587909583139075\n",
      "48 Train Loss 3.19948 Test MSE 0.09569307126043536 Test RE 0.22349927754096813\n",
      "49 Train Loss 2.6592393 Test MSE 0.06904304530695564 Test RE 0.18984354992574318\n",
      "50 Train Loss 2.387299 Test MSE 0.04676260414301661 Test RE 0.15623747842558022\n",
      "51 Train Loss 2.1132655 Test MSE 0.04058296629552254 Test RE 0.145548512249442\n",
      "52 Train Loss 1.8776393 Test MSE 0.03350518873963751 Test RE 0.13224885214337306\n",
      "53 Train Loss 1.6271772 Test MSE 0.026852249530141436 Test RE 0.1183930514175708\n",
      "54 Train Loss 1.4255421 Test MSE 0.02190062717601454 Test RE 0.10692128090759957\n",
      "55 Train Loss 1.3083782 Test MSE 0.017786974839260956 Test RE 0.09635781030481792\n",
      "56 Train Loss 1.1301368 Test MSE 0.010427022841104786 Test RE 0.0737761587429918\n",
      "57 Train Loss 0.96099097 Test MSE 0.008634690359045127 Test RE 0.06713658725816234\n",
      "58 Train Loss 0.833759 Test MSE 0.007648499962172655 Test RE 0.06318645803400448\n",
      "59 Train Loss 0.7258472 Test MSE 0.007501578047977471 Test RE 0.06257663316920413\n",
      "60 Train Loss 0.6718425 Test MSE 0.0063620595734289785 Test RE 0.05762815858541306\n",
      "61 Train Loss 0.57753366 Test MSE 0.005522743827794205 Test RE 0.053692462980484475\n",
      "62 Train Loss 0.52991647 Test MSE 0.005372376733182349 Test RE 0.05295647959847684\n",
      "63 Train Loss 0.4801665 Test MSE 0.006867093401348785 Test RE 0.0598718053793202\n",
      "64 Train Loss 0.44141862 Test MSE 0.005614401786262946 Test RE 0.05413618173669476\n",
      "65 Train Loss 0.41680038 Test MSE 0.004899233646303005 Test RE 0.050570814990440395\n",
      "66 Train Loss 0.3950191 Test MSE 0.004465935717927709 Test RE 0.048282762542883516\n",
      "67 Train Loss 0.37627417 Test MSE 0.004363749119474687 Test RE 0.04772717884763721\n",
      "68 Train Loss 0.3416262 Test MSE 0.0032920984711852725 Test RE 0.04145455766553707\n",
      "69 Train Loss 0.31773594 Test MSE 0.00270047391418688 Test RE 0.03754532518241867\n",
      "70 Train Loss 0.2977538 Test MSE 0.0024880103883049 Test RE 0.03603810709691897\n",
      "71 Train Loss 0.2812879 Test MSE 0.0023589187167950814 Test RE 0.03509072693072322\n",
      "72 Train Loss 0.26635242 Test MSE 0.0023489528591845534 Test RE 0.035016523583465305\n",
      "73 Train Loss 0.25163475 Test MSE 0.002321201993066484 Test RE 0.034809063906367184\n",
      "74 Train Loss 0.23756544 Test MSE 0.0020662662431471424 Test RE 0.03284195617367288\n",
      "75 Train Loss 0.22800171 Test MSE 0.0018879231738858856 Test RE 0.03139265415731905\n",
      "76 Train Loss 0.21697333 Test MSE 0.0021309219999410363 Test RE 0.03335182884883921\n",
      "77 Train Loss 0.20123447 Test MSE 0.0019301303248185331 Test RE 0.03174162773522207\n",
      "78 Train Loss 0.19160637 Test MSE 0.001629730914864912 Test RE 0.029167138832427532\n",
      "79 Train Loss 0.18469098 Test MSE 0.0016425302031001317 Test RE 0.02928144865561003\n",
      "80 Train Loss 0.1772909 Test MSE 0.0015027142403839112 Test RE 0.028007482797214097\n",
      "81 Train Loss 0.16823986 Test MSE 0.0013303669510121338 Test RE 0.02635248657110177\n",
      "82 Train Loss 0.16170816 Test MSE 0.0012723963157258672 Test RE 0.025771938027796235\n",
      "83 Train Loss 0.15366074 Test MSE 0.0011881409635058563 Test RE 0.02490404322959658\n",
      "84 Train Loss 0.14777711 Test MSE 0.0011699575876927034 Test RE 0.024712742050823935\n",
      "85 Train Loss 0.14076573 Test MSE 0.0011136362210179076 Test RE 0.024110574061886263\n",
      "86 Train Loss 0.13676456 Test MSE 0.0010169651390530437 Test RE 0.023040341392312987\n",
      "87 Train Loss 0.13163754 Test MSE 0.0009616935624443367 Test RE 0.022405478914546948\n",
      "88 Train Loss 0.12477393 Test MSE 0.0008328906749844781 Test RE 0.02085114348173793\n",
      "89 Train Loss 0.11921801 Test MSE 0.0007436138639528606 Test RE 0.019701968300660476\n",
      "90 Train Loss 0.11590383 Test MSE 0.000701237182678746 Test RE 0.01913235122996485\n",
      "91 Train Loss 0.1114505 Test MSE 0.0007217567397899177 Test RE 0.019410257681121437\n",
      "92 Train Loss 0.10724925 Test MSE 0.0006498749150666382 Test RE 0.01841835179042984\n",
      "93 Train Loss 0.103598066 Test MSE 0.0006240325741303658 Test RE 0.018048433224419954\n",
      "94 Train Loss 0.10100415 Test MSE 0.0005774850692784037 Test RE 0.017362260058669487\n",
      "95 Train Loss 0.096395575 Test MSE 0.00048692909925018244 Test RE 0.0159429521058612\n",
      "96 Train Loss 0.091982424 Test MSE 0.0005208945489484488 Test RE 0.01648962515205779\n",
      "97 Train Loss 0.08849745 Test MSE 0.000498495571794301 Test RE 0.01613119455919674\n",
      "98 Train Loss 0.08456273 Test MSE 0.0004883900283451451 Test RE 0.01596685094292833\n",
      "99 Train Loss 0.0817153 Test MSE 0.00044041718630711163 Test RE 0.01516240196566023\n",
      "100 Train Loss 0.07948805 Test MSE 0.00039666111486690166 Test RE 0.014389499584568963\n",
      "101 Train Loss 0.076993965 Test MSE 0.0003959162608249199 Test RE 0.014375982866037182\n",
      "102 Train Loss 0.07457759 Test MSE 0.00037161323917272066 Test RE 0.013927766135507304\n",
      "103 Train Loss 0.07295357 Test MSE 0.0003403511663695906 Test RE 0.013329059251247437\n",
      "104 Train Loss 0.0708121 Test MSE 0.00030687522129462544 Test RE 0.012656592229622808\n",
      "105 Train Loss 0.0693581 Test MSE 0.0003072224178078486 Test RE 0.012663749996301274\n",
      "106 Train Loss 0.06874638 Test MSE 0.0003008518023399528 Test RE 0.01253176336822159\n",
      "107 Train Loss 0.06774175 Test MSE 0.0002977492211409574 Test RE 0.012466978024639952\n",
      "108 Train Loss 0.06582797 Test MSE 0.0002837791019921272 Test RE 0.012170994941610933\n",
      "109 Train Loss 0.06403952 Test MSE 0.00026750038264347474 Test RE 0.011816750902662022\n",
      "110 Train Loss 0.062327307 Test MSE 0.00027071829530191316 Test RE 0.011887613601603375\n",
      "111 Train Loss 0.06070718 Test MSE 0.00025520349828297165 Test RE 0.011541949998698129\n",
      "112 Train Loss 0.058283802 Test MSE 0.00023545151900427857 Test RE 0.011086299964107484\n",
      "113 Train Loss 0.056912545 Test MSE 0.00022813287983430985 Test RE 0.010912639746858886\n",
      "114 Train Loss 0.055589724 Test MSE 0.000242115714078408 Test RE 0.01124209796887157\n",
      "115 Train Loss 0.053948343 Test MSE 0.0002881108346511348 Test RE 0.012263534923869893\n",
      "116 Train Loss 0.052952573 Test MSE 0.00026904655735902867 Test RE 0.011850852603149557\n",
      "117 Train Loss 0.051689487 Test MSE 0.0002660825015892493 Test RE 0.011785392053454953\n",
      "118 Train Loss 0.050750323 Test MSE 0.000261113460912712 Test RE 0.011674828441999168\n",
      "119 Train Loss 0.049116567 Test MSE 0.00022723642514313033 Test RE 0.010891177876988943\n",
      "120 Train Loss 0.048068985 Test MSE 0.00021659803602826173 Test RE 0.010633179225268095\n",
      "121 Train Loss 0.04667574 Test MSE 0.00020625907045010612 Test RE 0.010376297261617226\n",
      "122 Train Loss 0.045340594 Test MSE 0.00019229529928889766 Test RE 0.010018903898251086\n",
      "123 Train Loss 0.044464573 Test MSE 0.00019001506746596863 Test RE 0.00995932482062709\n",
      "124 Train Loss 0.04396473 Test MSE 0.00019848181244877896 Test RE 0.010178791897497014\n",
      "125 Train Loss 0.042772382 Test MSE 0.00020791458536116662 Test RE 0.010417856119849833\n",
      "126 Train Loss 0.041884955 Test MSE 0.00021081690766708172 Test RE 0.010490316617761536\n",
      "127 Train Loss 0.041152727 Test MSE 0.00019634096603100414 Test RE 0.010123748290231199\n",
      "128 Train Loss 0.039909247 Test MSE 0.0001896412231017555 Test RE 0.009949522780646723\n",
      "129 Train Loss 0.038858447 Test MSE 0.0001816869086334372 Test RE 0.00973862615833263\n",
      "130 Train Loss 0.037977077 Test MSE 0.00017644227040802094 Test RE 0.00959703758528592\n",
      "131 Train Loss 0.03730292 Test MSE 0.00017872773365246324 Test RE 0.009658992994247238\n",
      "132 Train Loss 0.036393367 Test MSE 0.00018238509172614466 Test RE 0.009757319922795955\n",
      "133 Train Loss 0.035325628 Test MSE 0.00018194144745119952 Test RE 0.00974544555663321\n",
      "134 Train Loss 0.03494184 Test MSE 0.00018012121323544058 Test RE 0.009696573833069374\n",
      "135 Train Loss 0.034402758 Test MSE 0.00017615968660499674 Test RE 0.009589349364966327\n",
      "136 Train Loss 0.033400066 Test MSE 0.00016640824042362184 Test RE 0.009320158350400428\n",
      "137 Train Loss 0.03295019 Test MSE 0.0001659801249917261 Test RE 0.009308161729228147\n",
      "138 Train Loss 0.032743827 Test MSE 0.00016295343366916516 Test RE 0.00922290287039893\n",
      "139 Train Loss 0.032495312 Test MSE 0.00016489454592664881 Test RE 0.009277672168893202\n",
      "140 Train Loss 0.03197284 Test MSE 0.00016670050250217291 Test RE 0.009328339237019867\n",
      "141 Train Loss 0.03127948 Test MSE 0.0001738777910709469 Test RE 0.009527038802484324\n",
      "142 Train Loss 0.030888189 Test MSE 0.00018124032235098582 Test RE 0.009726650026650002\n",
      "143 Train Loss 0.030388284 Test MSE 0.00019366664214909976 Test RE 0.01005456505061609\n",
      "144 Train Loss 0.029286154 Test MSE 0.00019060756606668235 Test RE 0.009974840151254757\n",
      "145 Train Loss 0.028303813 Test MSE 0.0001965858769716169 Test RE 0.010130060381022122\n",
      "146 Train Loss 0.027343467 Test MSE 0.0001795778226288644 Test RE 0.009681936448180623\n",
      "147 Train Loss 0.026762098 Test MSE 0.00018619865154702745 Test RE 0.009858801957415246\n",
      "148 Train Loss 0.026153885 Test MSE 0.0001696339834968438 Test RE 0.009410058151270356\n",
      "149 Train Loss 0.025600415 Test MSE 0.00016119410894680113 Test RE 0.009172980279429309\n",
      "150 Train Loss 0.02522527 Test MSE 0.00016890912740484732 Test RE 0.009389931759098722\n",
      "151 Train Loss 0.024717513 Test MSE 0.00015607423506379256 Test RE 0.00902612792634441\n",
      "152 Train Loss 0.023978475 Test MSE 0.00013527043767444576 Test RE 0.008403057290618042\n",
      "153 Train Loss 0.023582691 Test MSE 0.0001177665472376173 Test RE 0.007840555765143434\n",
      "154 Train Loss 0.023240725 Test MSE 0.00011194257251912447 Test RE 0.007644226000557741\n",
      "155 Train Loss 0.022781784 Test MSE 0.00010358630600233962 Test RE 0.007353380682595442\n",
      "156 Train Loss 0.022317683 Test MSE 8.814307589561323e-05 Test RE 0.006783127459392079\n",
      "157 Train Loss 0.021971803 Test MSE 8.682110902363662e-05 Test RE 0.006732068733737334\n",
      "158 Train Loss 0.021533089 Test MSE 8.289284634558093e-05 Test RE 0.006578008088481904\n",
      "159 Train Loss 0.02114269 Test MSE 8.582965440750221e-05 Test RE 0.006693519898798022\n",
      "160 Train Loss 0.020895686 Test MSE 8.058899271598551e-05 Test RE 0.006485952154765632\n",
      "161 Train Loss 0.02052481 Test MSE 8.238475257783419e-05 Test RE 0.006557817068317\n",
      "162 Train Loss 0.020039309 Test MSE 8.209981672134394e-05 Test RE 0.0065464668147065365\n",
      "163 Train Loss 0.019660903 Test MSE 8.235656063221236e-05 Test RE 0.006556694934455304\n",
      "164 Train Loss 0.019369029 Test MSE 7.78642741652678e-05 Test RE 0.006375364160119582\n",
      "165 Train Loss 0.019135306 Test MSE 7.582715144547827e-05 Test RE 0.006291413756210156\n",
      "166 Train Loss 0.018833796 Test MSE 7.363876186247808e-05 Test RE 0.006199963257916568\n",
      "167 Train Loss 0.01857723 Test MSE 7.577061857741744e-05 Test RE 0.00628906803983802\n",
      "168 Train Loss 0.018180981 Test MSE 6.927830355033494e-05 Test RE 0.006013599471625583\n",
      "169 Train Loss 0.017867433 Test MSE 6.731183274041966e-05 Test RE 0.0059276367876245515\n",
      "170 Train Loss 0.01755864 Test MSE 7.246651246699238e-05 Test RE 0.006150416933243752\n",
      "171 Train Loss 0.017457759 Test MSE 7.616714937419908e-05 Test RE 0.006305502873028443\n",
      "172 Train Loss 0.017232928 Test MSE 7.336461240823951e-05 Test RE 0.006188411587172522\n",
      "173 Train Loss 0.016932901 Test MSE 7.457647759084132e-05 Test RE 0.006239313537518967\n",
      "174 Train Loss 0.016625741 Test MSE 8.099088620035658e-05 Test RE 0.00650210460981294\n",
      "175 Train Loss 0.016415017 Test MSE 9.184808931961483e-05 Test RE 0.006924221306958915\n",
      "176 Train Loss 0.016362168 Test MSE 9.412291385698549e-05 Test RE 0.007009443810758816\n",
      "177 Train Loss 0.016186642 Test MSE 9.938048024437653e-05 Test RE 0.00720255233195441\n",
      "178 Train Loss 0.015985413 Test MSE 9.844672253957983e-05 Test RE 0.007168635656025635\n",
      "179 Train Loss 0.015786164 Test MSE 9.30813079549497e-05 Test RE 0.006970551103706882\n",
      "180 Train Loss 0.01566376 Test MSE 7.938831719189508e-05 Test RE 0.006437454537723579\n",
      "181 Train Loss 0.015391402 Test MSE 8.617471475935516e-05 Test RE 0.006706961358024244\n",
      "182 Train Loss 0.015090351 Test MSE 8.203269122448335e-05 Test RE 0.0065437900444449875\n",
      "183 Train Loss 0.0148703465 Test MSE 9.62643067116075e-05 Test RE 0.007088731397480973\n",
      "184 Train Loss 0.014778893 Test MSE 9.21491772701541e-05 Test RE 0.006935561193629253\n",
      "185 Train Loss 0.014570923 Test MSE 9.261347486746598e-05 Test RE 0.006953011801686386\n",
      "186 Train Loss 0.0144175235 Test MSE 9.127956532058076e-05 Test RE 0.0069027581679744834\n",
      "187 Train Loss 0.01418465 Test MSE 9.326520615137514e-05 Test RE 0.006977433469721715\n",
      "188 Train Loss 0.013939854 Test MSE 9.60820347875274e-05 Test RE 0.007082017128420271\n",
      "189 Train Loss 0.013679742 Test MSE 8.894172723537916e-05 Test RE 0.006813788617971352\n",
      "190 Train Loss 0.0135683445 Test MSE 9.418410758801195e-05 Test RE 0.007011722024993472\n",
      "191 Train Loss 0.013477203 Test MSE 8.699707251583e-05 Test RE 0.006738887344601437\n",
      "192 Train Loss 0.013352257 Test MSE 8.226584009721875e-05 Test RE 0.006553082649246644\n",
      "193 Train Loss 0.013128613 Test MSE 7.934264570171409e-05 Test RE 0.006435602562209825\n",
      "194 Train Loss 0.013173752 Test MSE 8.296951738520789e-05 Test RE 0.006581049521929204\n",
      "195 Train Loss 0.012902283 Test MSE 7.655082782726579e-05 Test RE 0.006321364347281893\n",
      "196 Train Loss 0.012678683 Test MSE 7.548345473052745e-05 Test RE 0.006277139224990799\n",
      "197 Train Loss 0.012445938 Test MSE 7.184118901604318e-05 Test RE 0.006123823043755836\n",
      "198 Train Loss 0.0122124255 Test MSE 6.919984813364521e-05 Test RE 0.00601019340451494\n",
      "199 Train Loss 0.012052226 Test MSE 6.830862532674984e-05 Test RE 0.005971365431341966\n",
      "200 Train Loss 0.011862196 Test MSE 7.262865700065953e-05 Test RE 0.0061572938977339006\n",
      "201 Train Loss 0.0117206955 Test MSE 7.509256666771426e-05 Test RE 0.006260865171322166\n",
      "202 Train Loss 0.011553634 Test MSE 7.546276778726049e-05 Test RE 0.006276279011837535\n",
      "203 Train Loss 0.011398243 Test MSE 7.279741589952817e-05 Test RE 0.006164443246716603\n",
      "204 Train Loss 0.011210557 Test MSE 7.018509296892465e-05 Test RE 0.006052827772611048\n",
      "205 Train Loss 0.011095625 Test MSE 7.327248968565967e-05 Test RE 0.006184525024006991\n",
      "206 Train Loss 0.010935789 Test MSE 7.375463159379908e-05 Test RE 0.006204839125510158\n",
      "207 Train Loss 0.0108200945 Test MSE 7.135223270446325e-05 Test RE 0.006102947873077519\n",
      "208 Train Loss 0.010765862 Test MSE 7.104925124349823e-05 Test RE 0.006089976680035839\n",
      "209 Train Loss 0.010617296 Test MSE 7.075435941721366e-05 Test RE 0.00607732523292314\n",
      "210 Train Loss 0.010487679 Test MSE 7.113488651290528e-05 Test RE 0.006093645682409954\n",
      "211 Train Loss 0.010429764 Test MSE 7.483666491236115e-05 Test RE 0.006250188124565702\n",
      "212 Train Loss 0.010298878 Test MSE 7.594972781233735e-05 Test RE 0.006296496811689031\n",
      "213 Train Loss 0.010189072 Test MSE 7.242579208892949e-05 Test RE 0.0061486886694777695\n",
      "214 Train Loss 0.010042349 Test MSE 7.048159134309087e-05 Test RE 0.006065599446217757\n",
      "215 Train Loss 0.009969156 Test MSE 6.603859463600612e-05 Test RE 0.0058713069823788655\n",
      "216 Train Loss 0.009810211 Test MSE 5.7876184237564454e-05 Test RE 0.005496494808704081\n",
      "217 Train Loss 0.009724484 Test MSE 5.720691634969225e-05 Test RE 0.005464622250300134\n",
      "218 Train Loss 0.00962189 Test MSE 5.483205620120388e-05 Test RE 0.0053499921280912854\n",
      "219 Train Loss 0.009520228 Test MSE 5.101326084282652e-05 Test RE 0.005160329335657919\n",
      "220 Train Loss 0.009447367 Test MSE 4.737190316510191e-05 Test RE 0.004972746190016366\n",
      "221 Train Loss 0.009362836 Test MSE 4.559522315934118e-05 Test RE 0.004878603799888214\n",
      "222 Train Loss 0.009274781 Test MSE 4.2033210406427926e-05 Test RE 0.004684164709336307\n",
      "223 Train Loss 0.009131204 Test MSE 3.903086127868991e-05 Test RE 0.004513775389386385\n",
      "224 Train Loss 0.009041172 Test MSE 3.825433649569701e-05 Test RE 0.004468648695264973\n",
      "225 Train Loss 0.008913879 Test MSE 3.939509966059803e-05 Test RE 0.004534787894574148\n",
      "226 Train Loss 0.008812451 Test MSE 4.266927769686129e-05 Test RE 0.004719473180986517\n",
      "227 Train Loss 0.008690128 Test MSE 4.00622670589345e-05 Test RE 0.00457302565417212\n",
      "228 Train Loss 0.008598641 Test MSE 4.152830588735435e-05 Test RE 0.004655946531712982\n",
      "229 Train Loss 0.008527092 Test MSE 4.5915394315273464e-05 Test RE 0.004895702693283204\n",
      "230 Train Loss 0.008505685 Test MSE 4.54711315173686e-05 Test RE 0.004871960489640355\n",
      "231 Train Loss 0.008387275 Test MSE 4.8811183892054454e-05 Test RE 0.005047723385208668\n",
      "232 Train Loss 0.008277113 Test MSE 4.661759910707849e-05 Test RE 0.004932996738091944\n",
      "233 Train Loss 0.00823915 Test MSE 4.0530673087919554e-05 Test RE 0.004599681759104694\n",
      "234 Train Loss 0.008133117 Test MSE 3.5554537244162446e-05 Test RE 0.004308076356514421\n",
      "235 Train Loss 0.008038297 Test MSE 3.367283160652071e-05 Test RE 0.004192525339432585\n",
      "236 Train Loss 0.007961419 Test MSE 3.343220407670118e-05 Test RE 0.0041775184966033425\n",
      "237 Train Loss 0.007883845 Test MSE 2.929176058857068e-05 Test RE 0.003910286826306274\n",
      "238 Train Loss 0.007801219 Test MSE 2.939835711147211e-05 Test RE 0.003917395385864744\n",
      "239 Train Loss 0.0077564577 Test MSE 2.7882936106297304e-05 Test RE 0.003815092995751762\n",
      "240 Train Loss 0.0076932106 Test MSE 2.6744245985744764e-05 Test RE 0.0037363801481404093\n",
      "241 Train Loss 0.0076678055 Test MSE 2.609169206081019e-05 Test RE 0.0036905152054371856\n",
      "242 Train Loss 0.0075939507 Test MSE 2.4446094260768532e-05 Test RE 0.003572239907393777\n",
      "243 Train Loss 0.007543225 Test MSE 2.4330757325476232e-05 Test RE 0.003563803011160756\n",
      "244 Train Loss 0.007553253 Test MSE 2.4828530125776583e-05 Test RE 0.0036000736176443238\n",
      "245 Train Loss 0.007511849 Test MSE 2.5304326379471806e-05 Test RE 0.0036344045471289857\n",
      "246 Train Loss 0.0074443235 Test MSE 2.4218313676022186e-05 Test RE 0.0035555584861309097\n",
      "247 Train Loss 0.007381654 Test MSE 2.4454414407516115e-05 Test RE 0.0035728477556547676\n",
      "248 Train Loss 0.0073273717 Test MSE 2.393553223480797e-05 Test RE 0.0035347395676138212\n",
      "249 Train Loss 0.007251811 Test MSE 2.4655476518434487e-05 Test RE 0.0035875055134815008\n",
      "250 Train Loss 0.0071695494 Test MSE 2.4065280066779874e-05 Test RE 0.0035443070372365923\n",
      "251 Train Loss 0.007135486 Test MSE 2.4715014889128013e-05 Test RE 0.003591834479520346\n",
      "252 Train Loss 0.0070798676 Test MSE 2.607948569459158e-05 Test RE 0.0036896518453705244\n",
      "253 Train Loss 0.006984313 Test MSE 2.6272016482322606e-05 Test RE 0.0037032461571828196\n",
      "254 Train Loss 0.006930203 Test MSE 2.532415567373092e-05 Test RE 0.003635828287145329\n",
      "255 Train Loss 0.0068844296 Test MSE 2.4741823037902275e-05 Test RE 0.0035937819664295556\n",
      "256 Train Loss 0.0068673384 Test MSE 2.5387748492076685e-05 Test RE 0.003640390484602856\n",
      "257 Train Loss 0.0068022055 Test MSE 2.5510153828973348e-05 Test RE 0.0036491558818813495\n",
      "258 Train Loss 0.0067313705 Test MSE 2.4852271216720217e-05 Test RE 0.0036017944052407027\n",
      "259 Train Loss 0.006645567 Test MSE 2.5530277693855677e-05 Test RE 0.0036505949293220287\n",
      "260 Train Loss 0.006567928 Test MSE 2.50393561621898e-05 Test RE 0.003615325927273885\n",
      "261 Train Loss 0.0064857723 Test MSE 2.5608800397775862e-05 Test RE 0.003656204631511725\n",
      "262 Train Loss 0.0063900854 Test MSE 2.650209469829444e-05 Test RE 0.003719426471288608\n",
      "263 Train Loss 0.006291667 Test MSE 2.5971817086782077e-05 Test RE 0.003682027643147502\n",
      "264 Train Loss 0.0062462753 Test MSE 2.4559852981882446e-05 Test RE 0.0035805418834893065\n",
      "265 Train Loss 0.006193394 Test MSE 2.4345075285725308e-05 Test RE 0.00356485145540931\n",
      "266 Train Loss 0.0061430107 Test MSE 2.426511294474486e-05 Test RE 0.003558992193996499\n",
      "267 Train Loss 0.006091721 Test MSE 2.3606024393328697e-05 Test RE 0.0035103248029528405\n",
      "268 Train Loss 0.0060101277 Test MSE 2.323774808029707e-05 Test RE 0.0034828349707045924\n",
      "269 Train Loss 0.0059125964 Test MSE 2.111482625348254e-05 Test RE 0.0033199353981666494\n",
      "270 Train Loss 0.005866876 Test MSE 2.072550989732334e-05 Test RE 0.003289186422930912\n",
      "271 Train Loss 0.005797233 Test MSE 1.960554818842492e-05 Test RE 0.003199081997857523\n",
      "272 Train Loss 0.005766051 Test MSE 1.994433847819221e-05 Test RE 0.0032266042009528153\n",
      "273 Train Loss 0.0056948783 Test MSE 1.9171512703933287e-05 Test RE 0.003163472530873258\n",
      "274 Train Loss 0.005648437 Test MSE 1.9161572505004343e-05 Test RE 0.0031626523132973075\n",
      "275 Train Loss 0.0055738385 Test MSE 1.969945450088945e-05 Test RE 0.003206734299142942\n",
      "276 Train Loss 0.0055242074 Test MSE 1.9260859180899697e-05 Test RE 0.003170835449670661\n",
      "277 Train Loss 0.0054962747 Test MSE 1.875899151144568e-05 Test RE 0.0031292525898261314\n",
      "278 Train Loss 0.0054731444 Test MSE 1.875960631690443e-05 Test RE 0.0031293038683239617\n",
      "279 Train Loss 0.005462088 Test MSE 1.8706494265115724e-05 Test RE 0.003124870898041361\n",
      "280 Train Loss 0.005427052 Test MSE 1.792362877785776e-05 Test RE 0.003058784263090499\n",
      "281 Train Loss 0.0053884853 Test MSE 1.6561315981572545e-05 Test RE 0.0029402435001867756\n",
      "282 Train Loss 0.0053769937 Test MSE 1.6354720914188998e-05 Test RE 0.0029218468311369007\n",
      "283 Train Loss 0.0053398493 Test MSE 1.5417312689160817e-05 Test RE 0.0028368751121394015\n",
      "284 Train Loss 0.005290228 Test MSE 1.508249686664494e-05 Test RE 0.0028059020009911367\n",
      "285 Train Loss 0.0052435137 Test MSE 1.5329613885251604e-05 Test RE 0.0028287950605143525\n",
      "286 Train Loss 0.005209383 Test MSE 1.5552777105973246e-05 Test RE 0.0028493109747984705\n",
      "287 Train Loss 0.0051635858 Test MSE 1.611002910447866e-05 Test RE 0.0028999067936901542\n",
      "288 Train Loss 0.0051350906 Test MSE 1.59951200115228e-05 Test RE 0.0028895461049816998\n",
      "289 Train Loss 0.0050603645 Test MSE 1.534500459267088e-05 Test RE 0.0028302147386375823\n",
      "290 Train Loss 0.00505415 Test MSE 1.5683305328706304e-05 Test RE 0.0028612425551860585\n",
      "291 Train Loss 0.00501348 Test MSE 1.5851139396077463e-05 Test RE 0.0028765115322373323\n",
      "292 Train Loss 0.004977703 Test MSE 1.6369533879079626e-05 Test RE 0.002923169734135741\n",
      "293 Train Loss 0.004943089 Test MSE 1.8165305592418944e-05 Test RE 0.0030793370761681748\n",
      "294 Train Loss 0.0048939865 Test MSE 1.785750784088313e-05 Test RE 0.003053137065318916\n",
      "295 Train Loss 0.004840521 Test MSE 1.6579919047447325e-05 Test RE 0.002941894401358546\n",
      "296 Train Loss 0.0047781765 Test MSE 1.686928877600608e-05 Test RE 0.0029674558298458486\n",
      "297 Train Loss 0.004752008 Test MSE 1.6810510325691356e-05 Test RE 0.00296228149618757\n",
      "298 Train Loss 0.00473482 Test MSE 1.671511850175006e-05 Test RE 0.002953864754376446\n",
      "299 Train Loss 0.0047100964 Test MSE 1.6937700197684305e-05 Test RE 0.0029734668262906094\n",
      "Training time: 108.21\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f67fc5ed850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.004413589683773779\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
