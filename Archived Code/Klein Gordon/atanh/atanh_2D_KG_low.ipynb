{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"low\"\n",
    "label = \"KG_atanh_\" + level\n",
    "\n",
    "x = np.linspace(0,1,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "        \n",
    "        self.alpha = Parameter(torch.ones((50,len(layers)-2)))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(1.0)\n",
    "            \n",
    "\n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.n*self.alpha[:,i]*z)\n",
    "                    \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_atanh_low\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 10071.602 Test MSE 4.923071604768311 Test RE 5.1925410707119815\n",
      "1 Train Loss 4126.838 Test MSE 9.92866105064444 Test RE 7.374069159727835\n",
      "2 Train Loss 1817.031 Test MSE 10.922881809262394 Test RE 7.734468610214952\n",
      "3 Train Loss 346.54013 Test MSE 14.179986879363017 Test RE 8.812513159876984\n",
      "4 Train Loss 138.44304 Test MSE 15.079086522532982 Test RE 9.087603719402788\n",
      "5 Train Loss 87.15109 Test MSE 15.600328341428941 Test RE 9.243335860201386\n",
      "6 Train Loss 59.91701 Test MSE 16.531484368327895 Test RE 9.515197114084685\n",
      "7 Train Loss 45.501766 Test MSE 16.625853403829304 Test RE 9.542316946129898\n",
      "8 Train Loss 39.06377 Test MSE 16.668460716817773 Test RE 9.554536238753336\n",
      "9 Train Loss 36.066105 Test MSE 16.63656848419777 Test RE 9.545391381520911\n",
      "10 Train Loss 33.935886 Test MSE 16.65729250498102 Test RE 9.55133483442135\n",
      "11 Train Loss 32.483616 Test MSE 16.698945618983608 Test RE 9.563269380155877\n",
      "12 Train Loss 30.980915 Test MSE 16.564041314527582 Test RE 9.52456207434335\n",
      "13 Train Loss 29.755976 Test MSE 16.501413560445005 Test RE 9.506539092393686\n",
      "14 Train Loss 29.066496 Test MSE 16.46516888575795 Test RE 9.496092992507977\n",
      "15 Train Loss 27.455935 Test MSE 16.490961605238738 Test RE 9.503527906131344\n",
      "16 Train Loss 26.472446 Test MSE 16.36295234221385 Test RE 9.466571006541887\n",
      "17 Train Loss 25.789986 Test MSE 16.251684208024834 Test RE 9.434329744596791\n",
      "18 Train Loss 25.35132 Test MSE 16.18413802726925 Test RE 9.414703579687462\n",
      "19 Train Loss 24.818283 Test MSE 16.10391248446387 Test RE 9.391340023189915\n",
      "20 Train Loss 24.482891 Test MSE 16.063268429618933 Test RE 9.379481312313395\n",
      "21 Train Loss 24.086512 Test MSE 16.00120773732559 Test RE 9.361344890381972\n",
      "22 Train Loss 23.84167 Test MSE 15.93445828743344 Test RE 9.341798939400437\n",
      "23 Train Loss 23.563011 Test MSE 15.954963246347157 Test RE 9.347807666381751\n",
      "24 Train Loss 23.318241 Test MSE 15.964540166635961 Test RE 9.350612742693517\n",
      "25 Train Loss 23.058159 Test MSE 15.988894778614666 Test RE 9.357742411185914\n",
      "26 Train Loss 22.550816 Test MSE 15.841847890698807 Test RE 9.314612310049544\n",
      "27 Train Loss 22.08021 Test MSE 15.678536729753855 Test RE 9.266476483284304\n",
      "28 Train Loss 21.697334 Test MSE 15.565399638845692 Test RE 9.232982275262724\n",
      "29 Train Loss 21.435514 Test MSE 15.41543071543504 Test RE 9.18839582625542\n",
      "30 Train Loss 21.317137 Test MSE 15.379764398058429 Test RE 9.177760183803773\n",
      "31 Train Loss 21.121115 Test MSE 15.33600099848585 Test RE 9.1646931397148\n",
      "32 Train Loss 20.83172 Test MSE 15.326589921483713 Test RE 9.16188070937923\n",
      "33 Train Loss 20.48436 Test MSE 15.302405320944613 Test RE 9.154649358358899\n",
      "34 Train Loss 20.335077 Test MSE 15.297280756148208 Test RE 9.15311634700617\n",
      "35 Train Loss 19.963114 Test MSE 15.23165056690352 Test RE 9.133460354736\n",
      "36 Train Loss 19.887005 Test MSE 15.174617837037896 Test RE 9.116344852233123\n",
      "37 Train Loss 19.58367 Test MSE 15.093114501472874 Test RE 9.091829806923295\n",
      "38 Train Loss 19.429174 Test MSE 15.024233303829657 Test RE 9.071059664353411\n",
      "39 Train Loss 19.155777 Test MSE 14.88715617762828 Test RE 9.029583870873115\n",
      "40 Train Loss 18.932081 Test MSE 14.798998780725649 Test RE 9.002808892554379\n",
      "41 Train Loss 18.683594 Test MSE 14.63944308886243 Test RE 8.954145391286655\n",
      "42 Train Loss 18.556438 Test MSE 14.568621056648038 Test RE 8.932460153782353\n",
      "43 Train Loss 18.088873 Test MSE 14.413044732013011 Test RE 8.884637875092402\n",
      "44 Train Loss 17.851095 Test MSE 14.213187124878525 Test RE 8.822823696371113\n",
      "45 Train Loss 17.589287 Test MSE 14.048592864653443 Test RE 8.771589062357773\n",
      "46 Train Loss 17.360844 Test MSE 13.956119170651851 Test RE 8.742672270496554\n",
      "47 Train Loss 17.094416 Test MSE 13.817077304607087 Test RE 8.699012557017415\n",
      "48 Train Loss 16.91241 Test MSE 13.703152189205445 Test RE 8.663075604310263\n",
      "49 Train Loss 16.52521 Test MSE 13.608535554425973 Test RE 8.633115677645264\n",
      "50 Train Loss 16.145878 Test MSE 13.406141342970697 Test RE 8.56867677857346\n",
      "51 Train Loss 16.003231 Test MSE 13.278634222214524 Test RE 8.527830662469386\n",
      "52 Train Loss 15.671636 Test MSE 13.031983809282684 Test RE 8.448257254349297\n",
      "53 Train Loss 15.176337 Test MSE 12.823573987413454 Test RE 8.380431970480695\n",
      "54 Train Loss 14.944638 Test MSE 12.647654216938182 Test RE 8.322750122968188\n",
      "55 Train Loss 14.567042 Test MSE 12.605153567948443 Test RE 8.308754644666084\n",
      "56 Train Loss 14.247534 Test MSE 12.52552395234459 Test RE 8.282468921369157\n",
      "57 Train Loss 13.6274805 Test MSE 12.142970959973038 Test RE 8.155007076589367\n",
      "58 Train Loss 13.203466 Test MSE 11.880636049280335 Test RE 8.066436326754326\n",
      "59 Train Loss 12.870918 Test MSE 11.692254378744884 Test RE 8.002229300167713\n",
      "60 Train Loss 12.728256 Test MSE 11.693961159723932 Test RE 8.00281334298438\n",
      "61 Train Loss 12.354732 Test MSE 11.567627588243491 Test RE 7.959467489897692\n",
      "62 Train Loss 12.029558 Test MSE 11.372887659633374 Test RE 7.892184667547265\n",
      "63 Train Loss 11.673506 Test MSE 11.03337992539146 Test RE 7.773491903271627\n",
      "64 Train Loss 11.401396 Test MSE 10.9291487545662 Test RE 7.736687097149498\n",
      "65 Train Loss 11.23642 Test MSE 10.804804815236515 Test RE 7.692549986676927\n",
      "66 Train Loss 10.90191 Test MSE 10.751058721975948 Test RE 7.673393697150763\n",
      "67 Train Loss 10.62521 Test MSE 10.754843345919774 Test RE 7.674744185272334\n",
      "68 Train Loss 10.313912 Test MSE 10.550560550238794 Test RE 7.601505799409353\n",
      "69 Train Loss 10.099679 Test MSE 10.294743418806286 Test RE 7.508784277567762\n",
      "70 Train Loss 9.744011 Test MSE 10.04780541236145 Test RE 7.4181817903208005\n",
      "71 Train Loss 9.519957 Test MSE 9.861892582971613 Test RE 7.349232686758989\n",
      "72 Train Loss 9.215432 Test MSE 9.51253850831544 Test RE 7.2178869887317525\n",
      "73 Train Loss 8.981716 Test MSE 9.369468449461175 Test RE 7.163402276416237\n",
      "74 Train Loss 8.663437 Test MSE 8.76170709444764 Test RE 6.927176116984238\n",
      "75 Train Loss 8.334454 Test MSE 8.53536063328822 Test RE 6.83711369359866\n",
      "76 Train Loss 8.097578 Test MSE 8.521713511122242 Test RE 6.831645602874257\n",
      "77 Train Loss 7.737308 Test MSE 8.23640346298882 Test RE 6.716309024950539\n",
      "78 Train Loss 7.5633945 Test MSE 7.992815813909269 Test RE 6.6162478618778\n",
      "79 Train Loss 7.2489705 Test MSE 7.945037544138345 Test RE 6.596443408541909\n",
      "80 Train Loss 7.1057153 Test MSE 7.9151856186068255 Test RE 6.584039322754438\n",
      "81 Train Loss 6.9330854 Test MSE 7.783800008353152 Test RE 6.52916582103993\n",
      "82 Train Loss 6.6593547 Test MSE 7.414339894879247 Test RE 6.372327821357476\n",
      "83 Train Loss 6.3544183 Test MSE 7.101944743765718 Test RE 6.236637597568041\n",
      "84 Train Loss 6.0337787 Test MSE 6.785926003816012 Test RE 6.096301309542262\n",
      "85 Train Loss 5.7769117 Test MSE 6.541142786348701 Test RE 5.9853379742918165\n",
      "86 Train Loss 5.3362527 Test MSE 6.108007478116676 Test RE 5.783778387565125\n",
      "87 Train Loss 4.3462615 Test MSE 4.995052141921505 Test RE 5.230363554686765\n",
      "88 Train Loss 3.151767 Test MSE 4.721756132787095 Test RE 5.085265597836521\n",
      "89 Train Loss 2.6494496 Test MSE 4.3951341814467435 Test RE 4.906230333710374\n",
      "90 Train Loss 2.276798 Test MSE 4.05407062967709 Test RE 4.712024277465178\n",
      "91 Train Loss 2.019904 Test MSE 3.6089558676791786 Test RE 4.445827928005444\n",
      "92 Train Loss 1.7796661 Test MSE 3.264571733759901 Test RE 4.228389366789604\n",
      "93 Train Loss 1.54347 Test MSE 2.5933910643982165 Test RE 3.7687373270817064\n",
      "94 Train Loss 1.2720445 Test MSE 2.0497218745479464 Test RE 3.3504977605822837\n",
      "95 Train Loss 1.1314905 Test MSE 1.512210467084162 Test RE 2.8778488745015527\n",
      "96 Train Loss 1.0008336 Test MSE 1.4023295653796728 Test RE 2.7713214883975845\n",
      "97 Train Loss 0.862019 Test MSE 1.1966362264914743 Test RE 2.560017518338056\n",
      "98 Train Loss 0.70479196 Test MSE 0.9662719087538698 Test RE 2.300443340002259\n",
      "99 Train Loss 0.5983693 Test MSE 0.7013243114151481 Test RE 1.9598431306115596\n",
      "100 Train Loss 0.5206425 Test MSE 0.5043309087351402 Test RE 1.6619565166909125\n",
      "101 Train Loss 0.44169763 Test MSE 0.43062395046637236 Test RE 1.535716160526332\n",
      "102 Train Loss 0.36692902 Test MSE 0.3538304274802222 Test RE 1.3920648020630144\n",
      "103 Train Loss 0.32378635 Test MSE 0.25412298331576166 Test RE 1.1797332954430297\n",
      "104 Train Loss 0.2727511 Test MSE 0.17013202759874238 Test RE 0.9652835451225344\n",
      "105 Train Loss 0.22584188 Test MSE 0.16285548437368655 Test RE 0.9444153958627005\n",
      "106 Train Loss 0.19221967 Test MSE 0.11563378434422611 Test RE 0.7958005474117485\n",
      "107 Train Loss 0.16217439 Test MSE 0.10878430615387126 Test RE 0.7718714669660945\n",
      "108 Train Loss 0.14009938 Test MSE 0.08982247397864025 Test RE 0.7013816031122232\n",
      "109 Train Loss 0.12726782 Test MSE 0.06277263601075263 Test RE 0.5863366578958874\n",
      "110 Train Loss 0.10955922 Test MSE 0.04729515887355718 Test RE 0.5089442456276548\n",
      "111 Train Loss 0.10181994 Test MSE 0.04121514112480273 Test RE 0.4751057206113574\n",
      "112 Train Loss 0.08655084 Test MSE 0.029996013699660942 Test RE 0.4053158951584329\n",
      "113 Train Loss 0.07598033 Test MSE 0.021954256916848148 Test RE 0.34675380480422224\n",
      "114 Train Loss 0.06830449 Test MSE 0.013167244560257599 Test RE 0.26854020432179476\n",
      "115 Train Loss 0.06284471 Test MSE 0.015379666284848844 Test RE 0.29022533426441205\n",
      "116 Train Loss 0.05773736 Test MSE 0.01635519325112327 Test RE 0.2992882756480765\n",
      "117 Train Loss 0.049580593 Test MSE 0.01031586641290076 Test RE 0.23769208422038232\n",
      "118 Train Loss 0.047027428 Test MSE 0.00981255034290581 Test RE 0.2318210203284193\n",
      "119 Train Loss 0.042234536 Test MSE 0.007025273418529753 Test RE 0.19615233380874822\n",
      "120 Train Loss 0.038563956 Test MSE 0.006326541472283374 Test RE 0.1861422862341317\n",
      "121 Train Loss 0.036001094 Test MSE 0.004999913207613991 Test RE 0.16547907966100198\n",
      "122 Train Loss 0.034720123 Test MSE 0.004556158710745494 Test RE 0.1579651506675642\n",
      "123 Train Loss 0.031765312 Test MSE 0.0035756287145970777 Test RE 0.13993877639481153\n",
      "124 Train Loss 0.029818842 Test MSE 0.003998213863707556 Test RE 0.14797722350761122\n",
      "125 Train Loss 0.029050961 Test MSE 0.0027380335641170373 Test RE 0.1224563323412338\n",
      "126 Train Loss 0.027428351 Test MSE 0.001767412427799485 Test RE 0.09838543638850707\n",
      "127 Train Loss 0.026580013 Test MSE 0.001514080021815678 Test RE 0.0910618100384016\n",
      "128 Train Loss 0.025157081 Test MSE 0.0012098387533541397 Test RE 0.08140022584886086\n",
      "129 Train Loss 0.022763098 Test MSE 0.0010305228474169743 Test RE 0.07512607101483845\n",
      "130 Train Loss 0.021545254 Test MSE 0.0009130649797793372 Test RE 0.07071518908996434\n",
      "131 Train Loss 0.020932464 Test MSE 0.0010356989877349913 Test RE 0.07531450740436123\n",
      "132 Train Loss 0.018587634 Test MSE 0.0009066550465488675 Test RE 0.07046653319583884\n",
      "133 Train Loss 0.017854132 Test MSE 0.000935212410263931 Test RE 0.07156768917946701\n",
      "134 Train Loss 0.017603813 Test MSE 0.0008050347952349533 Test RE 0.0664001698021317\n",
      "135 Train Loss 0.01632055 Test MSE 0.000773427199779879 Test RE 0.06508360260479988\n",
      "136 Train Loss 0.015194935 Test MSE 0.0007755238165125496 Test RE 0.0651717576497451\n",
      "137 Train Loss 0.01467691 Test MSE 0.0009401953719597064 Test RE 0.07175809794670136\n",
      "138 Train Loss 0.014409973 Test MSE 0.000815208217276177 Test RE 0.06681841020993588\n",
      "139 Train Loss 0.013946382 Test MSE 0.0007665290125283381 Test RE 0.06479271263364388\n",
      "140 Train Loss 0.012666998 Test MSE 0.0005204342939512684 Test RE 0.05338814328182158\n",
      "141 Train Loss 0.012300971 Test MSE 0.0005393835957781592 Test RE 0.05435139948243262\n",
      "142 Train Loss 0.012095316 Test MSE 0.0004912935157121288 Test RE 0.05187192677903054\n",
      "143 Train Loss 0.011864646 Test MSE 0.00041655823070863403 Test RE 0.04776389380207569\n",
      "144 Train Loss 0.011582661 Test MSE 0.0003236979433495209 Test RE 0.042104821843174434\n",
      "145 Train Loss 0.011206651 Test MSE 0.0002501899299336143 Test RE 0.0370166213751847\n",
      "146 Train Loss 0.010809961 Test MSE 0.0002716460530924728 Test RE 0.03857123669297307\n",
      "147 Train Loss 0.010404064 Test MSE 0.0002658589233832717 Test RE 0.03815816528860045\n",
      "148 Train Loss 0.009759373 Test MSE 0.00042773958008855174 Test RE 0.04840069339100314\n",
      "149 Train Loss 0.009508704 Test MSE 0.0007220061719458255 Test RE 0.06288286481886644\n",
      "150 Train Loss 0.009279421 Test MSE 0.0006884252806063736 Test RE 0.06140309599421847\n",
      "151 Train Loss 0.009097362 Test MSE 0.0007686869470098121 Test RE 0.06488385084265225\n",
      "152 Train Loss 0.008528023 Test MSE 0.0003760720635802306 Test RE 0.04538343884248974\n",
      "153 Train Loss 0.008392813 Test MSE 0.00035561956108971034 Test RE 0.044132109273635464\n",
      "154 Train Loss 0.008046728 Test MSE 0.0003033625107488727 Test RE 0.04076081125213843\n",
      "155 Train Loss 0.0078726355 Test MSE 0.00029337590186556277 Test RE 0.04008427960653264\n",
      "156 Train Loss 0.0075740623 Test MSE 0.0002755392509029257 Test RE 0.03884665250647047\n",
      "157 Train Loss 0.007270192 Test MSE 0.00015087660913399242 Test RE 0.028745695546253558\n",
      "158 Train Loss 0.007156118 Test MSE 0.000105416230157517 Test RE 0.024027888314420612\n",
      "159 Train Loss 0.0070405803 Test MSE 9.726968877289341e-05 Test RE 0.023080787746274006\n",
      "160 Train Loss 0.0067084315 Test MSE 8.941263558257898e-05 Test RE 0.022128975723161713\n",
      "161 Train Loss 0.006427355 Test MSE 8.789845788664409e-05 Test RE 0.021940801680227613\n",
      "162 Train Loss 0.0063365772 Test MSE 0.00012171099852194632 Test RE 0.025818248510973085\n",
      "163 Train Loss 0.00624631 Test MSE 0.00011212866736482607 Test RE 0.02478107798278736\n",
      "164 Train Loss 0.00607195 Test MSE 9.740319801073299e-05 Test RE 0.023096622287092052\n",
      "165 Train Loss 0.0059038308 Test MSE 0.00011152320300720406 Test RE 0.024714081874002536\n",
      "166 Train Loss 0.0058341613 Test MSE 0.0001031181078816645 Test RE 0.023764535597562066\n",
      "167 Train Loss 0.005786173 Test MSE 0.00010060145259921616 Test RE 0.023472750895581106\n",
      "168 Train Loss 0.0057073133 Test MSE 0.00013590156693764588 Test RE 0.02728186754796565\n",
      "169 Train Loss 0.00558745 Test MSE 0.0001089481647076284 Test RE 0.024427095110283577\n",
      "170 Train Loss 0.0053391764 Test MSE 0.00013522517840632443 Test RE 0.027213891289134682\n",
      "171 Train Loss 0.005187256 Test MSE 0.0001489551332590797 Test RE 0.02856206487256489\n",
      "172 Train Loss 0.0050649927 Test MSE 0.00014755047106491427 Test RE 0.028427074273375146\n",
      "173 Train Loss 0.0050044 Test MSE 0.00013044496209022299 Test RE 0.026728557396337844\n",
      "174 Train Loss 0.0048188423 Test MSE 0.0001525708679931551 Test RE 0.028906643907169807\n",
      "175 Train Loss 0.004403892 Test MSE 0.0001471290309980163 Test RE 0.028386447920558208\n",
      "176 Train Loss 0.0042493045 Test MSE 0.00013767441377979988 Test RE 0.027459238044463374\n",
      "177 Train Loss 0.004157379 Test MSE 0.0001522019469486337 Test RE 0.028871674178535745\n",
      "178 Train Loss 0.004124039 Test MSE 0.0001450799988009013 Test RE 0.028188089106940758\n",
      "179 Train Loss 0.0040724487 Test MSE 0.0001542112134174277 Test RE 0.029061621437178976\n",
      "180 Train Loss 0.0040350836 Test MSE 0.00015658904822757395 Test RE 0.02928481981638224\n",
      "181 Train Loss 0.0040037967 Test MSE 0.000171942414977558 Test RE 0.03068692523014104\n",
      "182 Train Loss 0.003833471 Test MSE 0.00021286235445752962 Test RE 0.034143756050116505\n",
      "183 Train Loss 0.0037240556 Test MSE 0.0002053715082620228 Test RE 0.03353759843343664\n",
      "184 Train Loss 0.0036134995 Test MSE 0.00023413399407353852 Test RE 0.03580915730746811\n",
      "185 Train Loss 0.003494951 Test MSE 0.00022442976120657884 Test RE 0.0350592069284131\n",
      "186 Train Loss 0.0034192668 Test MSE 0.0002030649884574414 Test RE 0.03334873689884833\n",
      "187 Train Loss 0.00337485 Test MSE 0.00015654795636868755 Test RE 0.029280977125421825\n",
      "188 Train Loss 0.0033486167 Test MSE 0.00015733416043961596 Test RE 0.02935441146756748\n",
      "189 Train Loss 0.0032797589 Test MSE 0.0001603120419303041 Test RE 0.029630906424256587\n",
      "190 Train Loss 0.0031935326 Test MSE 0.0001307963623601918 Test RE 0.026764534658993415\n",
      "191 Train Loss 0.0031174985 Test MSE 0.00012815001715111316 Test RE 0.02649239357472929\n",
      "192 Train Loss 0.0030763722 Test MSE 8.879154412125654e-05 Test RE 0.022051983981994608\n",
      "193 Train Loss 0.0030587176 Test MSE 0.00010300959883266838 Test RE 0.02375202884226383\n",
      "194 Train Loss 0.0030419135 Test MSE 9.781012591173742e-05 Test RE 0.02314481815908291\n",
      "195 Train Loss 0.0030102497 Test MSE 9.086849988145986e-05 Test RE 0.022308406179009307\n",
      "196 Train Loss 0.0029502863 Test MSE 0.0001064372602740129 Test RE 0.024143971379729994\n",
      "197 Train Loss 0.0028760526 Test MSE 0.00011402231137205534 Test RE 0.02498945497957587\n",
      "198 Train Loss 0.0028380442 Test MSE 0.00010915449856269749 Test RE 0.024450215062003892\n",
      "199 Train Loss 0.0027877272 Test MSE 9.41263878388472e-05 Test RE 0.022704793710673115\n",
      "200 Train Loss 0.0027576743 Test MSE 0.00011881803804301066 Test RE 0.025509564976266625\n",
      "201 Train Loss 0.0027327326 Test MSE 0.00012830108962698546 Test RE 0.026508004546663983\n",
      "202 Train Loss 0.0026989751 Test MSE 0.00013711971003386387 Test RE 0.02740386422692454\n",
      "203 Train Loss 0.0026507082 Test MSE 0.00017188585402282992 Test RE 0.030681877538587497\n",
      "204 Train Loss 0.0026326706 Test MSE 0.00017211452355708968 Test RE 0.03070227967926435\n",
      "205 Train Loss 0.0025823803 Test MSE 0.0001339158537673013 Test RE 0.027081820876495466\n",
      "206 Train Loss 0.0025255312 Test MSE 8.462453100982873e-05 Test RE 0.021528313121526123\n",
      "207 Train Loss 0.0024855083 Test MSE 7.194247300059573e-05 Test RE 0.01984972732628157\n",
      "208 Train Loss 0.002453761 Test MSE 5.618841876973881e-05 Test RE 0.01754224892269547\n",
      "209 Train Loss 0.0024354155 Test MSE 4.657343931704262e-05 Test RE 0.015970959902074446\n",
      "210 Train Loss 0.0024094523 Test MSE 4.79907537158494e-05 Test RE 0.01621215134784648\n",
      "211 Train Loss 0.0023927924 Test MSE 5.173864793398025e-05 Test RE 0.016833305359405592\n",
      "212 Train Loss 0.0023747156 Test MSE 5.353332977582012e-05 Test RE 0.01712276880234744\n",
      "213 Train Loss 0.002349538 Test MSE 5.5254431941175776e-05 Test RE 0.017395840748536378\n",
      "214 Train Loss 0.0023307034 Test MSE 5.098840467718626e-05 Test RE 0.016710812873462412\n",
      "215 Train Loss 0.0023013842 Test MSE 5.0540292259586304e-05 Test RE 0.01663721919747728\n",
      "216 Train Loss 0.002273986 Test MSE 5.689364625655664e-05 Test RE 0.017651993063623975\n",
      "217 Train Loss 0.0022242977 Test MSE 7.330874873065878e-05 Test RE 0.020037326156660904\n",
      "218 Train Loss 0.0021727583 Test MSE 7.21310769673042e-05 Test RE 0.019875729260374016\n",
      "219 Train Loss 0.0021305326 Test MSE 9.698699877885264e-05 Test RE 0.023047224077358347\n",
      "220 Train Loss 0.0020873842 Test MSE 6.354120942181471e-05 Test RE 0.01865475726680804\n",
      "221 Train Loss 0.002040291 Test MSE 7.450805200923618e-05 Test RE 0.020200562764621156\n",
      "222 Train Loss 0.0020006772 Test MSE 7.60532267197938e-05 Test RE 0.020408951158977114\n",
      "223 Train Loss 0.0019762865 Test MSE 6.773744724620496e-05 Test RE 0.01926088671668223\n",
      "224 Train Loss 0.0019559083 Test MSE 6.374696401313692e-05 Test RE 0.01868493610495573\n",
      "225 Train Loss 0.0019392966 Test MSE 6.636617843087731e-05 Test RE 0.019064932378620943\n",
      "226 Train Loss 0.0019335531 Test MSE 7.013174224314336e-05 Test RE 0.01959833504993037\n",
      "227 Train Loss 0.0019241354 Test MSE 7.246016112609999e-05 Test RE 0.019921017259785605\n",
      "228 Train Loss 0.001910245 Test MSE 8.51118443087427e-05 Test RE 0.02159020990989154\n",
      "229 Train Loss 0.0018608228 Test MSE 5.291055664491141e-05 Test RE 0.017022879672470233\n",
      "230 Train Loss 0.001793621 Test MSE 2.9690712045967932e-05 Test RE 0.012751819905926914\n",
      "231 Train Loss 0.0017408021 Test MSE 3.027254592519642e-05 Test RE 0.012876159192982064\n",
      "232 Train Loss 0.0017027803 Test MSE 3.360387176491224e-05 Test RE 0.013566147147692241\n",
      "233 Train Loss 0.0016743982 Test MSE 3.977141121157869e-05 Test RE 0.014758674845223384\n",
      "234 Train Loss 0.0016517959 Test MSE 3.2919853677989485e-05 Test RE 0.013427365541246445\n",
      "235 Train Loss 0.001629411 Test MSE 3.066271881887342e-05 Test RE 0.012958871823953685\n",
      "236 Train Loss 0.0016027291 Test MSE 3.372108536013659e-05 Test RE 0.01358978657630418\n",
      "237 Train Loss 0.0015919219 Test MSE 3.897331483146648e-05 Test RE 0.014609842595773451\n",
      "238 Train Loss 0.0015777597 Test MSE 3.781323484560563e-05 Test RE 0.014390761645719015\n",
      "239 Train Loss 0.0015590416 Test MSE 3.4354124520966905e-05 Test RE 0.013716752636434296\n",
      "240 Train Loss 0.001532712 Test MSE 3.7783963815241126e-05 Test RE 0.014385190660152064\n",
      "241 Train Loss 0.001514193 Test MSE 3.713572966006107e-05 Test RE 0.014261258264562668\n",
      "242 Train Loss 0.0014730708 Test MSE 3.787787136433504e-05 Test RE 0.0144030559069607\n",
      "243 Train Loss 0.0013954795 Test MSE 3.5930749602904166e-05 Test RE 0.014027975635650738\n",
      "244 Train Loss 0.0013486784 Test MSE 4.312516166781852e-05 Test RE 0.015368349628531603\n",
      "245 Train Loss 0.0013279375 Test MSE 5.487935459877902e-05 Test RE 0.01733669710979244\n",
      "246 Train Loss 0.0013201437 Test MSE 5.426325791099549e-05 Test RE 0.017239108237946194\n",
      "247 Train Loss 0.001312279 Test MSE 5.21827855661856e-05 Test RE 0.016905401640996118\n",
      "248 Train Loss 0.0013074533 Test MSE 4.750104969409732e-05 Test RE 0.01612922378216064\n",
      "249 Train Loss 0.0012988411 Test MSE 4.040252152911129e-05 Test RE 0.01487531253703256\n",
      "250 Train Loss 0.0012889364 Test MSE 4.0268622860780674e-05 Test RE 0.014850642820192248\n",
      "251 Train Loss 0.0012721965 Test MSE 4.6140208869167386e-05 Test RE 0.015896504675765092\n",
      "252 Train Loss 0.0012491944 Test MSE 5.081803049454066e-05 Test RE 0.016682870506728238\n",
      "253 Train Loss 0.0012054638 Test MSE 4.538337596191379e-05 Test RE 0.015765591284184158\n",
      "254 Train Loss 0.0011734107 Test MSE 3.704151359762458e-05 Test RE 0.014243155847804338\n",
      "255 Train Loss 0.0011489931 Test MSE 3.663793978300618e-05 Test RE 0.014165352501344632\n",
      "256 Train Loss 0.0011270317 Test MSE 5.0412606515026426e-05 Test RE 0.016616189647968377\n",
      "257 Train Loss 0.0011129391 Test MSE 5.664857091642071e-05 Test RE 0.017613933128128662\n",
      "258 Train Loss 0.0011031864 Test MSE 4.831440020334951e-05 Test RE 0.01626672633127441\n",
      "259 Train Loss 0.0010951703 Test MSE 4.337085203952887e-05 Test RE 0.015412065324326086\n",
      "260 Train Loss 0.0010881555 Test MSE 4.201687067968564e-05 Test RE 0.015169585567789284\n",
      "261 Train Loss 0.0010792679 Test MSE 4.5251164606711546e-05 Test RE 0.015742610286985727\n",
      "262 Train Loss 0.0010768751 Test MSE 4.33668386396306e-05 Test RE 0.015411352216218649\n",
      "263 Train Loss 0.0010628125 Test MSE 4.272667975869435e-05 Test RE 0.015297182107590845\n",
      "264 Train Loss 0.0010486811 Test MSE 3.83178270161884e-05 Test RE 0.014486460957589518\n",
      "265 Train Loss 0.0010330862 Test MSE 3.153793143192694e-05 Test RE 0.013142514545589101\n",
      "266 Train Loss 0.0010052187 Test MSE 3.7159204059764354e-05 Test RE 0.014265764996916877\n",
      "267 Train Loss 0.0009864747 Test MSE 3.616445177233076e-05 Test RE 0.014073522344510248\n",
      "268 Train Loss 0.00095811934 Test MSE 3.4699243409823236e-05 Test RE 0.013785479182603652\n",
      "269 Train Loss 0.00094509975 Test MSE 3.3898016938017205e-05 Test RE 0.01362539214182632\n",
      "270 Train Loss 0.0009262635 Test MSE 3.538206880253641e-05 Test RE 0.013920456431036005\n",
      "271 Train Loss 0.00090768334 Test MSE 4.1074901647832304e-05 Test RE 0.014998579524994586\n",
      "272 Train Loss 0.00088833034 Test MSE 4.816871861205809e-05 Test RE 0.01624218342438137\n",
      "273 Train Loss 0.0008738511 Test MSE 4.766411448518836e-05 Test RE 0.01615688480424566\n",
      "274 Train Loss 0.00086428144 Test MSE 4.5346084010424976e-05 Test RE 0.015759112584887394\n",
      "275 Train Loss 0.00085697306 Test MSE 5.060160493941817e-05 Test RE 0.016647307814519497\n",
      "276 Train Loss 0.00085009437 Test MSE 4.301752026672649e-05 Test RE 0.015349157767130403\n",
      "277 Train Loss 0.0008430579 Test MSE 3.978357483952475e-05 Test RE 0.014760931558028738\n",
      "278 Train Loss 0.00083879876 Test MSE 3.688428468675954e-05 Test RE 0.014212894971078893\n",
      "279 Train Loss 0.00083098834 Test MSE 4.174098278637054e-05 Test RE 0.01511970087192948\n",
      "280 Train Loss 0.00082147436 Test MSE 3.9390104185853006e-05 Test RE 0.014687755309555621\n",
      "281 Train Loss 0.00081706804 Test MSE 3.990731170318767e-05 Test RE 0.01478386883040488\n",
      "282 Train Loss 0.0008134177 Test MSE 4.737376059203098e-05 Test RE 0.016107598453003334\n",
      "283 Train Loss 0.00080981234 Test MSE 5.047039138562209e-05 Test RE 0.01662570997877641\n",
      "284 Train Loss 0.00080264965 Test MSE 5.394194065751954e-05 Test RE 0.017187992183056076\n",
      "285 Train Loss 0.0007855158 Test MSE 4.449689605084127e-05 Test RE 0.015610856178278657\n",
      "286 Train Loss 0.0007638677 Test MSE 4.006838735361228e-05 Test RE 0.014813674436505359\n",
      "287 Train Loss 0.000742389 Test MSE 3.131071399122997e-05 Test RE 0.013095085839291268\n",
      "288 Train Loss 0.0007210054 Test MSE 3.210174088993684e-05 Test RE 0.013259469740436732\n",
      "289 Train Loss 0.00070905697 Test MSE 3.3502812266859275e-05 Test RE 0.013545732530694231\n",
      "290 Train Loss 0.0006869631 Test MSE 3.20224202547215e-05 Test RE 0.013243078105079896\n",
      "291 Train Loss 0.0006688786 Test MSE 2.7496240631151282e-05 Test RE 0.012271524646276549\n",
      "292 Train Loss 0.00065856794 Test MSE 2.7800673744989322e-05 Test RE 0.012339271628200966\n",
      "293 Train Loss 0.0006478463 Test MSE 2.7419254158419655e-05 Test RE 0.012254333139429556\n",
      "294 Train Loss 0.0006412149 Test MSE 2.606974187442929e-05 Test RE 0.01194896336450156\n",
      "295 Train Loss 0.0006350838 Test MSE 2.8561469941757342e-05 Test RE 0.01250697096293076\n",
      "296 Train Loss 0.0006217967 Test MSE 2.5656103337950582e-05 Test RE 0.011853789537540503\n",
      "297 Train Loss 0.00061340973 Test MSE 2.2590526649112546e-05 Test RE 0.011123079515627975\n",
      "298 Train Loss 0.00060644624 Test MSE 2.1967009865676908e-05 Test RE 0.010968502449703713\n",
      "299 Train Loss 0.0005994161 Test MSE 2.1200318255624284e-05 Test RE 0.010775391402221824\n",
      "Training time: 162.38\n",
      "KG_atanh_low\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 5353.9395 Test MSE 7.805972112852773 Test RE 6.5384583518410215\n",
      "1 Train Loss 1675.3489 Test MSE 8.129747503946406 Test RE 6.6726814553019\n",
      "2 Train Loss 893.01196 Test MSE 8.109299504621532 Test RE 6.664284583843827\n",
      "3 Train Loss 272.45776 Test MSE 10.128869604476245 Test RE 7.448046067099909\n",
      "4 Train Loss 69.28346 Test MSE 12.240922097469058 Test RE 8.18783214981086\n",
      "5 Train Loss 37.428787 Test MSE 12.667332691889559 Test RE 8.329222286525564\n",
      "6 Train Loss 28.101143 Test MSE 13.372176242863832 Test RE 8.557815318538621\n",
      "7 Train Loss 24.10617 Test MSE 13.726085761812167 Test RE 8.67032182818862\n",
      "8 Train Loss 21.5779 Test MSE 13.424614311139297 Test RE 8.574578342580297\n",
      "9 Train Loss 19.97203 Test MSE 13.382331023274872 Test RE 8.56106408828405\n",
      "10 Train Loss 18.90447 Test MSE 13.202320378760822 Test RE 8.503290138821573\n",
      "11 Train Loss 18.149221 Test MSE 13.162340829137733 Test RE 8.49040545425357\n",
      "12 Train Loss 17.333117 Test MSE 13.039283564627885 Test RE 8.450623032973592\n",
      "13 Train Loss 16.520227 Test MSE 12.85867197933502 Test RE 8.391892712501726\n",
      "14 Train Loss 15.664044 Test MSE 12.47754710784418 Test RE 8.266591423286771\n",
      "15 Train Loss 14.452082 Test MSE 12.172915077628792 Test RE 8.165055858467925\n",
      "16 Train Loss 13.428048 Test MSE 11.777640915005337 Test RE 8.03139560464881\n",
      "17 Train Loss 12.443482 Test MSE 11.17208243840664 Test RE 7.822200251669353\n",
      "18 Train Loss 11.47586 Test MSE 10.906939869099896 Test RE 7.728822322873029\n",
      "19 Train Loss 10.673329 Test MSE 10.40676612032652 Test RE 7.549527323184841\n",
      "20 Train Loss 9.863485 Test MSE 9.921517760067896 Test RE 7.371416002554266\n",
      "21 Train Loss 9.032837 Test MSE 9.40181418053203 Test RE 7.175756544593892\n",
      "22 Train Loss 8.598761 Test MSE 8.92045041686704 Test RE 6.98964720644838\n",
      "23 Train Loss 8.226201 Test MSE 8.633129071631334 Test RE 6.876160116954332\n",
      "24 Train Loss 7.889316 Test MSE 8.308014386613658 Test RE 6.7454431119923175\n",
      "25 Train Loss 7.5991163 Test MSE 8.129163470425214 Test RE 6.6724417713733875\n",
      "26 Train Loss 7.3879323 Test MSE 7.985188759976855 Test RE 6.613090368667188\n",
      "27 Train Loss 7.138543 Test MSE 7.733368322465491 Test RE 6.507980029707341\n",
      "28 Train Loss 6.767297 Test MSE 7.338937914855055 Test RE 6.339842529388167\n",
      "29 Train Loss 6.3681536 Test MSE 6.934166037170499 Test RE 6.162529089245246\n",
      "30 Train Loss 5.9795365 Test MSE 6.680991564449224 Test RE 6.048982467532694\n",
      "31 Train Loss 5.525978 Test MSE 6.355575879622034 Test RE 5.899827557807375\n",
      "32 Train Loss 5.059873 Test MSE 5.784433408244752 Test RE 5.628494900002622\n",
      "33 Train Loss 4.506369 Test MSE 5.109771964597218 Test RE 5.290084675743781\n",
      "34 Train Loss 3.816449 Test MSE 4.255067090137498 Test RE 4.827419829712605\n",
      "35 Train Loss 3.168 Test MSE 3.4664090414106696 Test RE 4.357142547187517\n",
      "36 Train Loss 2.4423602 Test MSE 2.851890836278188 Test RE 3.952103529825147\n",
      "37 Train Loss 1.97773 Test MSE 2.3238850729480642 Test RE 3.5675427600807446\n",
      "38 Train Loss 1.4713273 Test MSE 1.5727852433482103 Test RE 2.934922089257571\n",
      "39 Train Loss 1.0222757 Test MSE 1.1570389162741697 Test RE 2.5173050511235293\n",
      "40 Train Loss 0.82873785 Test MSE 0.8823411440163447 Test RE 2.1982654267014397\n",
      "41 Train Loss 0.6415166 Test MSE 0.6486135268555019 Test RE 1.8847548296989256\n",
      "42 Train Loss 0.4900859 Test MSE 0.5021522597975852 Test RE 1.6583629052522153\n",
      "43 Train Loss 0.3970867 Test MSE 0.43671392252800645 Test RE 1.546537242515192\n",
      "44 Train Loss 0.32262242 Test MSE 0.39210348200563605 Test RE 1.465420334246002\n",
      "45 Train Loss 0.27018434 Test MSE 0.2931325926268059 Test RE 1.2670504825035351\n",
      "46 Train Loss 0.2183 Test MSE 0.23623860658185822 Test RE 1.137463056610924\n",
      "47 Train Loss 0.1943761 Test MSE 0.2157311974432547 Test RE 1.086971960253904\n",
      "48 Train Loss 0.16846143 Test MSE 0.16111081319415846 Test RE 0.939343012010651\n",
      "49 Train Loss 0.14464971 Test MSE 0.13513023269093516 Test RE 0.8602766323566233\n",
      "50 Train Loss 0.12891132 Test MSE 0.12294519577122587 Test RE 0.820573798377903\n",
      "51 Train Loss 0.117828675 Test MSE 0.09591784080998485 Test RE 0.7247889457140082\n",
      "52 Train Loss 0.10382705 Test MSE 0.08362987000515584 Test RE 0.6767722999845944\n",
      "53 Train Loss 0.09298174 Test MSE 0.07792791412726885 Test RE 0.653293579369304\n",
      "54 Train Loss 0.07918065 Test MSE 0.07125417362800117 Test RE 0.624693544306363\n",
      "55 Train Loss 0.06809695 Test MSE 0.045431915370135474 Test RE 0.4988183108512017\n",
      "56 Train Loss 0.059868187 Test MSE 0.03476500253082228 Test RE 0.436348007022606\n",
      "57 Train Loss 0.05383123 Test MSE 0.035557855515226264 Test RE 0.4412956479790758\n",
      "58 Train Loss 0.048851997 Test MSE 0.024481795018581037 Test RE 0.36617061774511067\n",
      "59 Train Loss 0.043228343 Test MSE 0.016012301457146605 Test RE 0.29613432053747424\n",
      "60 Train Loss 0.03886021 Test MSE 0.015580309731935056 Test RE 0.29211234260154556\n",
      "61 Train Loss 0.03477193 Test MSE 0.010960140773231984 Test RE 0.2450021695709127\n",
      "62 Train Loss 0.0302299 Test MSE 0.009067151616387315 Test RE 0.2228421310384013\n",
      "63 Train Loss 0.027092936 Test MSE 0.006396702763981431 Test RE 0.18717159853054163\n",
      "64 Train Loss 0.022786262 Test MSE 0.003981725579967762 Test RE 0.14767178572898035\n",
      "65 Train Loss 0.020942075 Test MSE 0.00303341605105404 Test RE 0.1288925614120434\n",
      "66 Train Loss 0.01848225 Test MSE 0.002759765702625604 Test RE 0.12294134797678215\n",
      "67 Train Loss 0.016432278 Test MSE 0.001917447284881318 Test RE 0.10247633400757789\n",
      "68 Train Loss 0.01471727 Test MSE 0.001389221867739465 Test RE 0.0872263439272822\n",
      "69 Train Loss 0.013689429 Test MSE 0.0013387194412690297 Test RE 0.08562619572387696\n",
      "70 Train Loss 0.012959476 Test MSE 0.0013455874041591223 Test RE 0.08584555655452708\n",
      "71 Train Loss 0.011944146 Test MSE 0.00139754075981082 Test RE 0.08748711706399304\n",
      "72 Train Loss 0.010898762 Test MSE 0.0014460992383190637 Test RE 0.08899403798040902\n",
      "73 Train Loss 0.010441948 Test MSE 0.0013239228740639939 Test RE 0.08515167727851791\n",
      "74 Train Loss 0.009722422 Test MSE 0.001280670152250179 Test RE 0.08374916928964514\n",
      "75 Train Loss 0.009288734 Test MSE 0.0011157196534196511 Test RE 0.07816987287252095\n",
      "76 Train Loss 0.008767879 Test MSE 0.0009541219515751063 Test RE 0.07228760030804939\n",
      "77 Train Loss 0.008122016 Test MSE 0.0007993598905894786 Test RE 0.06616571965666566\n",
      "78 Train Loss 0.007730601 Test MSE 0.0006828749961782823 Test RE 0.0611550702775991\n",
      "79 Train Loss 0.0074224495 Test MSE 0.0006763267468012384 Test RE 0.0608611487642018\n",
      "80 Train Loss 0.0071977903 Test MSE 0.0006737770916360262 Test RE 0.060746321525595434\n",
      "81 Train Loss 0.0068215327 Test MSE 0.0006733043738766194 Test RE 0.060725008168518294\n",
      "82 Train Loss 0.006552207 Test MSE 0.0006759245510161769 Test RE 0.06084304971825691\n",
      "83 Train Loss 0.0063101077 Test MSE 0.0006060379345041563 Test RE 0.05761184302853317\n",
      "84 Train Loss 0.0061658346 Test MSE 0.0005768596446223566 Test RE 0.05620784606761305\n",
      "85 Train Loss 0.0058712596 Test MSE 0.0005754885428976759 Test RE 0.056141007865591605\n",
      "86 Train Loss 0.0056987614 Test MSE 0.0006397011655339207 Test RE 0.059190285537731334\n",
      "87 Train Loss 0.005570168 Test MSE 0.0006778422565402099 Test RE 0.06092929929322863\n",
      "88 Train Loss 0.005277275 Test MSE 0.000678610103865854 Test RE 0.06096379932434575\n",
      "89 Train Loss 0.005112067 Test MSE 0.0007012053980355504 Test RE 0.06197042711275441\n",
      "90 Train Loss 0.0046673343 Test MSE 0.0007123320473130884 Test RE 0.06246016191770468\n",
      "91 Train Loss 0.0045242966 Test MSE 0.0007536336335372894 Test RE 0.06424539447793848\n",
      "92 Train Loss 0.0044254144 Test MSE 0.0008408017392049274 Test RE 0.06785918895780117\n",
      "93 Train Loss 0.004287138 Test MSE 0.000794459909108455 Test RE 0.0659626139111001\n",
      "94 Train Loss 0.0040364154 Test MSE 0.0007828121780047195 Test RE 0.06547728311036005\n",
      "95 Train Loss 0.0038843798 Test MSE 0.0006528152836143287 Test RE 0.05979391927598822\n",
      "96 Train Loss 0.0037995586 Test MSE 0.0005758947685261708 Test RE 0.05616081876656256\n",
      "97 Train Loss 0.0035744444 Test MSE 0.00043345703068733445 Test RE 0.048723097467036534\n",
      "98 Train Loss 0.003384999 Test MSE 0.0003107626537965748 Test RE 0.04125496991960242\n",
      "99 Train Loss 0.003306512 Test MSE 0.000299807384431871 Test RE 0.040521267989900474\n",
      "100 Train Loss 0.0030767648 Test MSE 0.00026354849969105704 Test RE 0.03799199838915794\n",
      "101 Train Loss 0.0029730585 Test MSE 0.0002462360326465629 Test RE 0.03672295890340657\n",
      "102 Train Loss 0.00278689 Test MSE 0.0002094810316423365 Test RE 0.033871483328799835\n",
      "103 Train Loss 0.0026998147 Test MSE 0.0001878677854593374 Test RE 0.032076577369973124\n",
      "104 Train Loss 0.0026515794 Test MSE 0.00017616030453198483 Test RE 0.03106103265900162\n",
      "105 Train Loss 0.0025799987 Test MSE 0.00016366543129574232 Test RE 0.02993921049448476\n",
      "106 Train Loss 0.002430714 Test MSE 0.00012187033262119061 Test RE 0.025835142554905276\n",
      "107 Train Loss 0.0023780304 Test MSE 0.00012367533551418172 Test RE 0.026025759525716008\n",
      "108 Train Loss 0.0023361202 Test MSE 0.00012695603971996544 Test RE 0.026368689561841276\n",
      "109 Train Loss 0.002305141 Test MSE 0.0001251104287885846 Test RE 0.02617632175575847\n",
      "110 Train Loss 0.0021877575 Test MSE 0.0001234644314411757 Test RE 0.026003559138147964\n",
      "111 Train Loss 0.0020289794 Test MSE 0.000121492264972588 Test RE 0.02579503837892905\n",
      "112 Train Loss 0.0019913134 Test MSE 0.00012745338103753247 Test RE 0.026420287817455725\n",
      "113 Train Loss 0.001953129 Test MSE 0.0001228756436252717 Test RE 0.025941481032460627\n",
      "114 Train Loss 0.0019203713 Test MSE 0.00011768977187851425 Test RE 0.02538815987858477\n",
      "115 Train Loss 0.0018693889 Test MSE 0.00011953148434279924 Test RE 0.025586036809142558\n",
      "116 Train Loss 0.0018359952 Test MSE 0.00011466621087365606 Test RE 0.025059915070851445\n",
      "117 Train Loss 0.0018032985 Test MSE 0.00010270307136373576 Test RE 0.02371666284856898\n",
      "118 Train Loss 0.0017785378 Test MSE 0.00010068471508457855 Test RE 0.023482462461897596\n",
      "119 Train Loss 0.0017649906 Test MSE 0.00010131787669902688 Test RE 0.023556182152954346\n",
      "120 Train Loss 0.0017437176 Test MSE 0.00011114165931606064 Test RE 0.02467176968848208\n",
      "121 Train Loss 0.0017037725 Test MSE 0.00012040769937614836 Test RE 0.02567964367443143\n",
      "122 Train Loss 0.0016683788 Test MSE 0.00012016825306784137 Test RE 0.025654097318505986\n",
      "123 Train Loss 0.0016457542 Test MSE 0.00012265172289837927 Test RE 0.025917833204686543\n",
      "124 Train Loss 0.0016224924 Test MSE 0.00011564589773646077 Test RE 0.025166741016779896\n",
      "125 Train Loss 0.0015901224 Test MSE 0.00010793340678736596 Test RE 0.02431307034717686\n",
      "126 Train Loss 0.0015675528 Test MSE 0.00010447630373438962 Test RE 0.023920528112849237\n",
      "127 Train Loss 0.0015540237 Test MSE 0.00010191142330635388 Test RE 0.02362508053058051\n",
      "128 Train Loss 0.0015326742 Test MSE 0.00010423114475599731 Test RE 0.023892446259328362\n",
      "129 Train Loss 0.0015047153 Test MSE 9.802774492473526e-05 Test RE 0.023170551455943853\n",
      "130 Train Loss 0.0014683475 Test MSE 9.854935611725452e-05 Test RE 0.023232115577512376\n",
      "131 Train Loss 0.0014490503 Test MSE 0.0001053084906994279 Test RE 0.024015606460613917\n",
      "132 Train Loss 0.0014254105 Test MSE 0.00010829114122487622 Test RE 0.024353328631765734\n",
      "133 Train Loss 0.0014152805 Test MSE 0.00011429825239403451 Test RE 0.02501967471793068\n",
      "134 Train Loss 0.001406964 Test MSE 0.00012021332359415056 Test RE 0.025658907803984565\n",
      "135 Train Loss 0.0013911393 Test MSE 0.00012417862496703842 Test RE 0.02607866090407314\n",
      "136 Train Loss 0.0013745467 Test MSE 0.00012752216566503443 Test RE 0.026427416167107413\n",
      "137 Train Loss 0.0013612644 Test MSE 0.00012126602050599817 Test RE 0.02577100925989711\n",
      "138 Train Loss 0.0013437328 Test MSE 0.00012096013189428374 Test RE 0.02573848557492198\n",
      "139 Train Loss 0.0013316754 Test MSE 0.00012437269069278832 Test RE 0.026099030748253694\n",
      "140 Train Loss 0.0013165233 Test MSE 0.00012433906718790986 Test RE 0.02609550264171977\n",
      "141 Train Loss 0.0013008588 Test MSE 0.00012763856933527588 Test RE 0.026439475037549703\n",
      "142 Train Loss 0.0012655198 Test MSE 0.00013749028013155607 Test RE 0.027440869121456882\n",
      "143 Train Loss 0.0012336051 Test MSE 0.00015830541930440966 Test RE 0.029444877729926513\n",
      "144 Train Loss 0.001209498 Test MSE 0.00018027867082048493 Test RE 0.03142201544366855\n",
      "145 Train Loss 0.0011845306 Test MSE 0.00019584228707882653 Test RE 0.03275028624439858\n",
      "146 Train Loss 0.0011733655 Test MSE 0.0001933249432391008 Test RE 0.03253912046237788\n",
      "147 Train Loss 0.001162811 Test MSE 0.00019530974499590813 Test RE 0.03270572799663512\n",
      "148 Train Loss 0.0011519036 Test MSE 0.0002027462041569199 Test RE 0.03332255013605328\n",
      "149 Train Loss 0.0011407054 Test MSE 0.00020127093170463662 Test RE 0.0332010938686623\n",
      "150 Train Loss 0.0011083799 Test MSE 0.00018133224061786768 Test RE 0.03151369866751999\n",
      "151 Train Loss 0.001088417 Test MSE 0.0001935005311356392 Test RE 0.032553893980193045\n",
      "152 Train Loss 0.0010709676 Test MSE 0.00017971832689658935 Test RE 0.0313731443311795\n",
      "153 Train Loss 0.0010573055 Test MSE 0.0001771953560198829 Test RE 0.031152150466184057\n",
      "154 Train Loss 0.0010496746 Test MSE 0.00017465565094073834 Test RE 0.03092809601149319\n",
      "155 Train Loss 0.0010385469 Test MSE 0.0001728061777134146 Test RE 0.030763907448169914\n",
      "156 Train Loss 0.001024914 Test MSE 0.00017586953438256787 Test RE 0.031035387406207263\n",
      "157 Train Loss 0.001005739 Test MSE 0.00016701916692903832 Test RE 0.030244403299934948\n",
      "158 Train Loss 0.0009632901 Test MSE 0.00014126258727018245 Test RE 0.02781476801719708\n",
      "159 Train Loss 0.00094066415 Test MSE 0.00012907737245645938 Test RE 0.026588076650504753\n",
      "160 Train Loss 0.0009174929 Test MSE 0.00013820609354964582 Test RE 0.027512208864442802\n",
      "161 Train Loss 0.0009043948 Test MSE 0.0001423495059287064 Test RE 0.027921570742563656\n",
      "162 Train Loss 0.00088962755 Test MSE 0.0001378413160394621 Test RE 0.027475877377081237\n",
      "163 Train Loss 0.0008822554 Test MSE 0.00013266262651056895 Test RE 0.026954802851971084\n",
      "164 Train Loss 0.0008712509 Test MSE 0.00012085319080389558 Test RE 0.025727105336196487\n",
      "165 Train Loss 0.0008586931 Test MSE 0.00012722902769876158 Test RE 0.026397024054126004\n",
      "166 Train Loss 0.0008424455 Test MSE 0.0001287600057831567 Test RE 0.026555370055765824\n",
      "167 Train Loss 0.00083038356 Test MSE 0.00013144654502975008 Test RE 0.0268309748257286\n",
      "168 Train Loss 0.0008173229 Test MSE 0.0001331510133495316 Test RE 0.02700437324591662\n",
      "169 Train Loss 0.00080159435 Test MSE 0.00011749707875480298 Test RE 0.02536736738379011\n",
      "170 Train Loss 0.0007838447 Test MSE 0.00011599792063047234 Test RE 0.025205015342018737\n",
      "171 Train Loss 0.0007700343 Test MSE 0.00010519988670096217 Test RE 0.024003219692606662\n",
      "172 Train Loss 0.0007539867 Test MSE 9.91820407468674e-05 Test RE 0.023306571095381055\n",
      "173 Train Loss 0.0007403621 Test MSE 9.072037004540892e-05 Test RE 0.022290215670845416\n",
      "174 Train Loss 0.0007251256 Test MSE 9.314442815138377e-05 Test RE 0.02258605099793095\n",
      "175 Train Loss 0.00071246317 Test MSE 7.920242040480028e-05 Test RE 0.020827209754019974\n",
      "176 Train Loss 0.0006998056 Test MSE 7.600459958758393e-05 Test RE 0.020402425548590074\n",
      "177 Train Loss 0.00068250176 Test MSE 6.843256858729903e-05 Test RE 0.019359462028380674\n",
      "178 Train Loss 0.0006658342 Test MSE 6.201472315170336e-05 Test RE 0.018429318201951924\n",
      "179 Train Loss 0.0006354678 Test MSE 4.7573855625760103e-05 Test RE 0.016141579862145\n",
      "180 Train Loss 0.00061444 Test MSE 4.125366644384824e-05 Test RE 0.015031182245346079\n",
      "181 Train Loss 0.00060212694 Test MSE 3.859589265864976e-05 Test RE 0.014538928775103566\n",
      "182 Train Loss 0.0005874065 Test MSE 3.93045523057131e-05 Test RE 0.014671796375995905\n",
      "183 Train Loss 0.0005771044 Test MSE 3.665120574562051e-05 Test RE 0.014167916783486563\n",
      "184 Train Loss 0.00057091773 Test MSE 3.722009742978847e-05 Test RE 0.014277448978526784\n",
      "185 Train Loss 0.0005639828 Test MSE 3.653772150360447e-05 Test RE 0.014145965502590256\n",
      "186 Train Loss 0.00055270846 Test MSE 3.1507951194139657e-05 Test RE 0.013136266364802536\n",
      "187 Train Loss 0.00054005906 Test MSE 3.0194930952804702e-05 Test RE 0.01285964217888751\n",
      "188 Train Loss 0.0005297349 Test MSE 2.9365099429411896e-05 Test RE 0.012681703698032017\n",
      "189 Train Loss 0.000520315 Test MSE 3.210213739996294e-05 Test RE 0.013259551628463867\n",
      "190 Train Loss 0.0005114699 Test MSE 3.219999229088838e-05 Test RE 0.013279745372662934\n",
      "191 Train Loss 0.00050023076 Test MSE 3.1916993173677174e-05 Test RE 0.013221260108351665\n",
      "192 Train Loss 0.0004852319 Test MSE 2.9624551411661197e-05 Test RE 0.012737604365911079\n",
      "193 Train Loss 0.00047675843 Test MSE 2.9092628121933567e-05 Test RE 0.012622731426448638\n",
      "194 Train Loss 0.00046971964 Test MSE 2.677240553669187e-05 Test RE 0.012108924224978038\n",
      "195 Train Loss 0.00046537805 Test MSE 2.7177882229092316e-05 Test RE 0.012200276411176521\n",
      "196 Train Loss 0.0004613737 Test MSE 2.685779846748401e-05 Test RE 0.012128220087609169\n",
      "197 Train Loss 0.0004575705 Test MSE 2.6834679730689806e-05 Test RE 0.012122999080890018\n",
      "198 Train Loss 0.00045349862 Test MSE 2.6123861601663822e-05 Test RE 0.011961359716016386\n",
      "199 Train Loss 0.00045081953 Test MSE 2.5230357380950843e-05 Test RE 0.011755025217974642\n",
      "200 Train Loss 0.00044758443 Test MSE 2.5781353389363646e-05 Test RE 0.011882688706711225\n",
      "201 Train Loss 0.0004422568 Test MSE 2.6692548664954725e-05 Test RE 0.012090851456663138\n",
      "202 Train Loss 0.00043489822 Test MSE 2.4558750415183773e-05 Test RE 0.01159751643910801\n",
      "203 Train Loss 0.00042452285 Test MSE 2.2411506403015712e-05 Test RE 0.01107891903332264\n",
      "204 Train Loss 0.00041639226 Test MSE 1.984935245509078e-05 Test RE 0.010426415688219939\n",
      "205 Train Loss 0.00040774455 Test MSE 2.1011710796722773e-05 Test RE 0.010727352983901173\n",
      "206 Train Loss 0.00040182893 Test MSE 2.0801054625207145e-05 Test RE 0.01067344315106415\n",
      "207 Train Loss 0.00039719875 Test MSE 2.0647123947111124e-05 Test RE 0.010633877340045424\n",
      "208 Train Loss 0.0003931596 Test MSE 2.106492281799891e-05 Test RE 0.010740927870675772\n",
      "209 Train Loss 0.00038499208 Test MSE 2.701212428013412e-05 Test RE 0.012163014756488802\n",
      "210 Train Loss 0.00037674818 Test MSE 3.133043489160284e-05 Test RE 0.013099209128083078\n",
      "211 Train Loss 0.00037146753 Test MSE 3.528322057881453e-05 Test RE 0.013900997778143626\n",
      "212 Train Loss 0.00036576102 Test MSE 4.2106815078285816e-05 Test RE 0.015185813452152743\n",
      "213 Train Loss 0.00035760854 Test MSE 4.6329608613382866e-05 Test RE 0.015929097836763443\n",
      "214 Train Loss 0.00034845358 Test MSE 4.5615783166209824e-05 Test RE 0.015805907347363406\n",
      "215 Train Loss 0.00034389776 Test MSE 4.649006699629416e-05 Test RE 0.015956658484255707\n",
      "216 Train Loss 0.00033750595 Test MSE 4.2134442430658414e-05 Test RE 0.015190794534463915\n",
      "217 Train Loss 0.00033438968 Test MSE 4.330073949504328e-05 Test RE 0.015399602850920555\n",
      "218 Train Loss 0.00032995886 Test MSE 4.760135847340699e-05 Test RE 0.01614624497981466\n",
      "219 Train Loss 0.00032655365 Test MSE 4.6413183608797346e-05 Test RE 0.015943458787359553\n",
      "220 Train Loss 0.0003236053 Test MSE 4.2489565767640486e-05 Test RE 0.015254676789653107\n",
      "221 Train Loss 0.0003212514 Test MSE 4.077928806204044e-05 Test RE 0.014944510130401684\n",
      "222 Train Loss 0.00031849957 Test MSE 4.097979767994751e-05 Test RE 0.014981205763843777\n",
      "223 Train Loss 0.00031480938 Test MSE 4.5086830690667045e-05 Test RE 0.015713998892458593\n",
      "224 Train Loss 0.00031093476 Test MSE 4.466780376299173e-05 Test RE 0.0156408072419453\n",
      "225 Train Loss 0.00030843072 Test MSE 3.833878834859399e-05 Test RE 0.014490422742882198\n",
      "226 Train Loss 0.0003059838 Test MSE 3.9482454436924884e-05 Test RE 0.014704962979063103\n",
      "227 Train Loss 0.00030340345 Test MSE 3.818382359567643e-05 Test RE 0.014461108065141972\n",
      "228 Train Loss 0.00030143867 Test MSE 3.448252786227991e-05 Test RE 0.013742362868231236\n",
      "229 Train Loss 0.00029863117 Test MSE 3.737079300450694e-05 Test RE 0.01430632282820384\n",
      "230 Train Loss 0.00029540685 Test MSE 3.5185395747195034e-05 Test RE 0.013881713729965101\n",
      "231 Train Loss 0.00029149407 Test MSE 3.401279267710476e-05 Test RE 0.013648439845699096\n",
      "232 Train Loss 0.00028718062 Test MSE 2.8937430155682803e-05 Test RE 0.012589017698574512\n",
      "233 Train Loss 0.00028105732 Test MSE 2.2087903231826288e-05 Test RE 0.010998643096712906\n",
      "234 Train Loss 0.0002764336 Test MSE 1.7893583850293886e-05 Test RE 0.00989943778156507\n",
      "235 Train Loss 0.0002730137 Test MSE 1.769944828300277e-05 Test RE 0.009845589593165248\n",
      "236 Train Loss 0.00026802023 Test MSE 1.501291202156081e-05 Test RE 0.009067641340822023\n",
      "237 Train Loss 0.00026353012 Test MSE 1.568448375995862e-05 Test RE 0.009268233751571493\n",
      "238 Train Loss 0.0002597401 Test MSE 1.4901646982602983e-05 Test RE 0.009033977393457878\n",
      "239 Train Loss 0.0002563813 Test MSE 1.4318594728074174e-05 Test RE 0.0088554791031483\n",
      "240 Train Loss 0.00025251126 Test MSE 1.3415038253243026e-05 Test RE 0.008571519584064848\n",
      "241 Train Loss 0.0002486328 Test MSE 1.3506949077989012e-05 Test RE 0.008600832606766569\n",
      "242 Train Loss 0.00024468772 Test MSE 1.2219532369199364e-05 Test RE 0.0081806753327811\n",
      "243 Train Loss 0.00024165424 Test MSE 1.1483485215098516e-05 Test RE 0.0079304662611916\n",
      "244 Train Loss 0.00023942026 Test MSE 1.1025799011698935e-05 Test RE 0.007770820904101218\n",
      "245 Train Loss 0.0002372279 Test MSE 1.1436156967453912e-05 Test RE 0.007914107003034231\n",
      "246 Train Loss 0.0002350036 Test MSE 1.0909858878422791e-05 Test RE 0.007729856480731646\n",
      "247 Train Loss 0.00023176066 Test MSE 1.0656269563379457e-05 Test RE 0.007639491693660137\n",
      "248 Train Loss 0.00022800418 Test MSE 1.0363705526573892e-05 Test RE 0.007533892105425964\n",
      "249 Train Loss 0.00022350272 Test MSE 1.0794309456140997e-05 Test RE 0.007688812959894172\n",
      "250 Train Loss 0.00022136435 Test MSE 1.0715621843383818e-05 Test RE 0.007660737010506812\n",
      "251 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "252 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "253 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "254 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "255 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "256 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "257 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "258 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "259 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "260 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "261 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "262 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "263 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "264 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "265 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "266 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "267 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "268 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "269 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "270 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "271 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "272 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "273 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "274 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "275 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "276 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "277 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "278 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "279 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "280 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "281 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "282 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "283 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "284 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "285 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "286 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "287 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "288 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "289 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "290 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "291 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "292 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "293 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "294 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "295 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "296 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "297 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "298 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "299 Train Loss 0.00021976727 Test MSE 9.478659373854567e-06 Test RE 0.007205022184968233\n",
      "Training time: 144.56\n",
      "KG_atanh_low\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 8269.216 Test MSE 7.844256217581438 Test RE 6.554472555511406\n",
      "1 Train Loss 2008.5037 Test MSE 6.938443701192036 Test RE 6.164429618057241\n",
      "2 Train Loss 854.228 Test MSE 9.1646139818263 Test RE 7.0846590159743466\n",
      "3 Train Loss 467.11316 Test MSE 9.812883148094782 Test RE 7.330948653505387\n",
      "4 Train Loss 278.45978 Test MSE 8.640793933084428 Test RE 6.879211914337489\n",
      "5 Train Loss 164.43289 Test MSE 7.214182963559688 Test RE 6.285725920033041\n",
      "6 Train Loss 96.28446 Test MSE 6.084081976111982 Test RE 5.772439536159724\n",
      "7 Train Loss 51.276558 Test MSE 4.071555870053026 Test RE 4.722174844339425\n",
      "8 Train Loss 29.004448 Test MSE 3.4640719894580783 Test RE 4.355673507429584\n",
      "9 Train Loss 17.475792 Test MSE 2.4300573401403325 Test RE 3.648128478469284\n",
      "10 Train Loss 9.957036 Test MSE 1.143208979451692 Test RE 2.50221531296746\n",
      "11 Train Loss 6.1569176 Test MSE 0.6073299623103829 Test RE 1.8237874283064481\n",
      "12 Train Loss 4.467174 Test MSE 0.45495479026248103 Test RE 1.5785050843892552\n",
      "13 Train Loss 3.2686555 Test MSE 0.4023543605703634 Test RE 1.4844522087492167\n",
      "14 Train Loss 2.3736658 Test MSE 0.27097673708554204 Test RE 1.2182260121741588\n",
      "15 Train Loss 1.6490005 Test MSE 0.19071306584879072 Test RE 1.0220028054022452\n",
      "16 Train Loss 1.2169116 Test MSE 0.16806483057381957 Test RE 0.959401261220813\n",
      "17 Train Loss 0.84394735 Test MSE 0.0542400147134783 Test RE 0.5450317012980622\n",
      "18 Train Loss 0.6682294 Test MSE 0.03551021928521521 Test RE 0.4409999509243438\n",
      "19 Train Loss 0.53961056 Test MSE 0.018182799678275456 Test RE 0.3155674795276816\n",
      "20 Train Loss 0.46311924 Test MSE 0.015710805591552548 Test RE 0.29333311308852467\n",
      "21 Train Loss 0.39526904 Test MSE 0.012809316716218612 Test RE 0.2648651663696014\n",
      "22 Train Loss 0.33906475 Test MSE 0.01802219794206842 Test RE 0.31417074487265256\n",
      "23 Train Loss 0.29975137 Test MSE 0.02084494705044277 Test RE 0.337879826251726\n",
      "24 Train Loss 0.2691283 Test MSE 0.021523405645732088 Test RE 0.34333443177142803\n",
      "25 Train Loss 0.2441024 Test MSE 0.02314238007365187 Test RE 0.3560130149290993\n",
      "26 Train Loss 0.22590029 Test MSE 0.020063145504576822 Test RE 0.331483087614265\n",
      "27 Train Loss 0.20372742 Test MSE 0.02148397402208862 Test RE 0.3430197873179648\n",
      "28 Train Loss 0.17198198 Test MSE 0.015016278024279918 Test RE 0.2867761396553214\n",
      "29 Train Loss 0.16523576 Test MSE 0.011434968149675514 Test RE 0.2502530295232145\n",
      "30 Train Loss 0.1518296 Test MSE 0.008695856506756356 Test RE 0.21823180583034327\n",
      "31 Train Loss 0.13838272 Test MSE 0.007450483740646134 Test RE 0.20200126989669362\n",
      "32 Train Loss 0.13304116 Test MSE 0.006816959542100506 Test RE 0.19322228884105971\n",
      "33 Train Loss 0.12205251 Test MSE 0.00724552597251154 Test RE 0.19920343492688466\n",
      "34 Train Loss 0.11257331 Test MSE 0.007970095266023696 Test RE 0.20892654397360516\n",
      "35 Train Loss 0.10683348 Test MSE 0.008043679382284147 Test RE 0.2098887880240361\n",
      "36 Train Loss 0.100329995 Test MSE 0.009387535196194471 Test RE 0.22674496557530716\n",
      "37 Train Loss 0.092728235 Test MSE 0.00852095234978493 Test RE 0.21602595433218405\n",
      "38 Train Loss 0.0872157 Test MSE 0.008489576746364183 Test RE 0.21562786528680752\n",
      "39 Train Loss 0.08185973 Test MSE 0.007639883473576287 Test RE 0.2045527070576928\n",
      "40 Train Loss 0.07239438 Test MSE 0.0087096424600591 Test RE 0.21840472393413154\n",
      "41 Train Loss 0.069864914 Test MSE 0.009749331084360525 Test RE 0.23107303768545176\n",
      "42 Train Loss 0.064338565 Test MSE 0.009855376443634288 Test RE 0.23232635182293776\n",
      "43 Train Loss 0.06342592 Test MSE 0.0092853252525083 Test RE 0.22550720622438425\n",
      "44 Train Loss 0.057711262 Test MSE 0.007959792888866122 Test RE 0.20879146804232881\n",
      "45 Train Loss 0.05581756 Test MSE 0.007823423418363305 Test RE 0.2069952034099563\n",
      "46 Train Loss 0.054256685 Test MSE 0.006247774496222886 Test RE 0.1849798985906266\n",
      "47 Train Loss 0.046690967 Test MSE 0.004557735279541418 Test RE 0.1579924786649875\n",
      "48 Train Loss 0.04447634 Test MSE 0.0033565316403345756 Test RE 0.13558362362836612\n",
      "49 Train Loss 0.042157132 Test MSE 0.002939075779348509 Test RE 0.12687242938975518\n",
      "50 Train Loss 0.038454868 Test MSE 0.0024646819340856697 Test RE 0.11618292471139804\n",
      "51 Train Loss 0.03789214 Test MSE 0.0024288111229704146 Test RE 0.11533436678971853\n",
      "52 Train Loss 0.03563796 Test MSE 0.0021230745834251424 Test RE 0.10783121274639143\n",
      "53 Train Loss 0.0340926 Test MSE 0.0021569592942575623 Test RE 0.10868831068254824\n",
      "54 Train Loss 0.033482548 Test MSE 0.002281687374888982 Test RE 0.11178664799745185\n",
      "55 Train Loss 0.03279865 Test MSE 0.0029352885247342364 Test RE 0.12679065996282496\n",
      "56 Train Loss 0.030578664 Test MSE 0.003290221374962785 Test RE 0.13423767568017317\n",
      "57 Train Loss 0.027685879 Test MSE 0.002484145602492893 Test RE 0.11664077262922906\n",
      "58 Train Loss 0.02604946 Test MSE 0.002532830448825989 Test RE 0.11777820286330817\n",
      "59 Train Loss 0.025451493 Test MSE 0.0023122840138122694 Test RE 0.11253366218919461\n",
      "60 Train Loss 0.025044136 Test MSE 0.0021435538265237313 Test RE 0.10835003620897508\n",
      "61 Train Loss 0.02373891 Test MSE 0.00207445241873974 Test RE 0.10658929826462718\n",
      "62 Train Loss 0.022796737 Test MSE 0.0017118989548061548 Test RE 0.09682799240031947\n",
      "63 Train Loss 0.02202742 Test MSE 0.0015183192377164676 Test RE 0.0911892012056188\n",
      "64 Train Loss 0.021485412 Test MSE 0.0014966772078500112 Test RE 0.09053696597558772\n",
      "65 Train Loss 0.020513287 Test MSE 0.0014017117211227875 Test RE 0.08761757247949858\n",
      "66 Train Loss 0.019254437 Test MSE 0.0019833651696191867 Test RE 0.10422291245769871\n",
      "67 Train Loss 0.018215613 Test MSE 0.002335707173721068 Test RE 0.11310220226125133\n",
      "68 Train Loss 0.017428115 Test MSE 0.0022564378996438694 Test RE 0.11116640386678377\n",
      "69 Train Loss 0.01677999 Test MSE 0.0024650836918895243 Test RE 0.11619239357916833\n",
      "70 Train Loss 0.016149862 Test MSE 0.002569324349316282 Test RE 0.11862366295359514\n",
      "71 Train Loss 0.015753679 Test MSE 0.0029292691118828203 Test RE 0.1266605880805086\n",
      "72 Train Loss 0.014676694 Test MSE 0.0026415230924682733 Test RE 0.12027879537819203\n",
      "73 Train Loss 0.0137890875 Test MSE 0.0025024367411116354 Test RE 0.11706940684943867\n",
      "74 Train Loss 0.013251083 Test MSE 0.00188388850008113 Test RE 0.10157561525137362\n",
      "75 Train Loss 0.012840124 Test MSE 0.001740204135931527 Test RE 0.0976252057746724\n",
      "76 Train Loss 0.012318504 Test MSE 0.002051158500164361 Test RE 0.10598916594495528\n",
      "77 Train Loss 0.011788307 Test MSE 0.001945939678085508 Test RE 0.10323490222580334\n",
      "78 Train Loss 0.011087006 Test MSE 0.0021170565925332186 Test RE 0.10767827705336068\n",
      "79 Train Loss 0.010164525 Test MSE 0.0025649534538006447 Test RE 0.11852271961865218\n",
      "80 Train Loss 0.00949076 Test MSE 0.00223250665348785 Test RE 0.11057533021197731\n",
      "81 Train Loss 0.009261277 Test MSE 0.002195572407534231 Test RE 0.10965684493979189\n",
      "82 Train Loss 0.008921177 Test MSE 0.002070297911031481 Test RE 0.1064825115310336\n",
      "83 Train Loss 0.008792159 Test MSE 0.001971242287411984 Test RE 0.10390390445997753\n",
      "84 Train Loss 0.008658119 Test MSE 0.002040917124876753 Test RE 0.10572423440649115\n",
      "85 Train Loss 0.008405267 Test MSE 0.0021039430412811374 Test RE 0.10734426660617656\n",
      "86 Train Loss 0.008195488 Test MSE 0.002038732654756629 Test RE 0.10566763895234284\n",
      "87 Train Loss 0.007866361 Test MSE 0.0020667225659621617 Test RE 0.1063905256790989\n",
      "88 Train Loss 0.0076270676 Test MSE 0.001914206339577196 Test RE 0.10238969260275023\n",
      "89 Train Loss 0.0075789746 Test MSE 0.0018597797417703342 Test RE 0.10092357368326055\n",
      "90 Train Loss 0.0074473256 Test MSE 0.0018291207019074298 Test RE 0.10008823864376172\n",
      "91 Train Loss 0.0072762575 Test MSE 0.0017304912227006557 Test RE 0.0973523780174556\n",
      "92 Train Loss 0.0072323256 Test MSE 0.0016543748597837948 Test RE 0.09518725984306375\n",
      "93 Train Loss 0.0070711696 Test MSE 0.0016058739746361301 Test RE 0.09378159050457593\n",
      "94 Train Loss 0.0069683176 Test MSE 0.001449978457098448 Test RE 0.08911332306221217\n",
      "95 Train Loss 0.0068328427 Test MSE 0.00151677006942982 Test RE 0.09114266834615946\n",
      "96 Train Loss 0.006720051 Test MSE 0.0016268406424919599 Test RE 0.09439182236942924\n",
      "97 Train Loss 0.006604619 Test MSE 0.0016212774923154785 Test RE 0.09423029284994108\n",
      "98 Train Loss 0.006440571 Test MSE 0.0015326010622711923 Test RE 0.0916170756204437\n",
      "99 Train Loss 0.0063105165 Test MSE 0.001455712871450982 Test RE 0.08928936308236568\n",
      "100 Train Loss 0.006232032 Test MSE 0.00141476176212607 Test RE 0.08802449064185378\n",
      "101 Train Loss 0.006155172 Test MSE 0.0012998962894972663 Test RE 0.08437547215004904\n",
      "102 Train Loss 0.0059987525 Test MSE 0.0012205590019126109 Test RE 0.08176006971131378\n",
      "103 Train Loss 0.0055756364 Test MSE 0.0009762399525857407 Test RE 0.07312066839535275\n",
      "104 Train Loss 0.005066187 Test MSE 0.0006857038227608839 Test RE 0.061281607563618036\n",
      "105 Train Loss 0.004942824 Test MSE 0.0007062067363247988 Test RE 0.06219103606769291\n",
      "106 Train Loss 0.0048825555 Test MSE 0.0006259130695409232 Test RE 0.05854891806229932\n",
      "107 Train Loss 0.004805888 Test MSE 0.0005890896288512633 Test RE 0.05680055150075943\n",
      "108 Train Loss 0.0046655154 Test MSE 0.0004580532827483912 Test RE 0.050086405359741806\n",
      "109 Train Loss 0.0045708823 Test MSE 0.0004590828533066535 Test RE 0.050142663600442415\n",
      "110 Train Loss 0.004429755 Test MSE 0.0004800709409928278 Test RE 0.05127605129956868\n",
      "111 Train Loss 0.004054711 Test MSE 0.0004813114220173631 Test RE 0.05134225602772424\n",
      "112 Train Loss 0.0038486815 Test MSE 0.0004702433243977506 Test RE 0.05074849689556522\n",
      "113 Train Loss 0.003701606 Test MSE 0.00041575877779979106 Test RE 0.04771803788128352\n",
      "114 Train Loss 0.0036408629 Test MSE 0.00041787281611893763 Test RE 0.047839201709781315\n",
      "115 Train Loss 0.0035753744 Test MSE 0.0003730510542105025 Test RE 0.04520078735156628\n",
      "116 Train Loss 0.0035369985 Test MSE 0.0003566599308778303 Test RE 0.044196616667109834\n",
      "117 Train Loss 0.0035135665 Test MSE 0.000367442294571901 Test RE 0.04485970737172806\n",
      "118 Train Loss 0.0034853707 Test MSE 0.0003636956454099143 Test RE 0.044630413916448654\n",
      "119 Train Loss 0.0033191629 Test MSE 0.0003405833896441989 Test RE 0.04318904448082023\n",
      "120 Train Loss 0.0032391923 Test MSE 0.00031703856193019043 Test RE 0.04166946348510233\n",
      "121 Train Loss 0.0031776426 Test MSE 0.00029571049442376064 Test RE 0.04024345257615288\n",
      "122 Train Loss 0.0030530817 Test MSE 0.0002917310828634883 Test RE 0.039971754931197576\n",
      "123 Train Loss 0.0029902102 Test MSE 0.00028824950127009517 Test RE 0.03973252326084931\n",
      "124 Train Loss 0.0029144392 Test MSE 0.0002805812588264491 Test RE 0.039200462745098794\n",
      "125 Train Loss 0.002836299 Test MSE 0.0002997390734868777 Test RE 0.04051665135277801\n",
      "126 Train Loss 0.0027488722 Test MSE 0.0003184011630686132 Test RE 0.04175891314270045\n",
      "127 Train Loss 0.002681354 Test MSE 0.00033179590605377917 Test RE 0.042628237384655716\n",
      "128 Train Loss 0.002642958 Test MSE 0.0003517583612135179 Test RE 0.04389186944094273\n",
      "129 Train Loss 0.0026264046 Test MSE 0.00037287987054947024 Test RE 0.04519041541449762\n",
      "130 Train Loss 0.0026192688 Test MSE 0.00037786249924522754 Test RE 0.04549134322058644\n",
      "131 Train Loss 0.002593755 Test MSE 0.00038504894943109947 Test RE 0.045921898616902636\n",
      "132 Train Loss 0.0025521964 Test MSE 0.0003873336342842711 Test RE 0.04605793573013707\n",
      "133 Train Loss 0.002517773 Test MSE 0.0004437352839788569 Test RE 0.04929738081922921\n",
      "134 Train Loss 0.002495391 Test MSE 0.00044045346994246075 Test RE 0.049114743682947055\n",
      "135 Train Loss 0.0024472515 Test MSE 0.0004248122126700359 Test RE 0.04823478652669249\n",
      "136 Train Loss 0.0023761115 Test MSE 0.00043168650602350443 Test RE 0.04862348699670221\n",
      "137 Train Loss 0.0023268347 Test MSE 0.00045888105095385844 Test RE 0.05013164160335429\n",
      "138 Train Loss 0.0022906319 Test MSE 0.00044861666431620864 Test RE 0.04956779100718371\n",
      "139 Train Loss 0.002272937 Test MSE 0.00044292703660857985 Test RE 0.04925246368033917\n",
      "140 Train Loss 0.002255052 Test MSE 0.0004446056559049686 Test RE 0.049345704716679664\n",
      "141 Train Loss 0.002223734 Test MSE 0.00045662463358811837 Test RE 0.050008235651318046\n",
      "142 Train Loss 0.0022095859 Test MSE 0.00044774662428957946 Test RE 0.0495197021872718\n",
      "143 Train Loss 0.0021933436 Test MSE 0.0004243628061075039 Test RE 0.048209266114380235\n",
      "144 Train Loss 0.00217007 Test MSE 0.00039404156604980694 Test RE 0.04645504469523018\n",
      "145 Train Loss 0.0021433674 Test MSE 0.0003668594610960481 Test RE 0.04482411523138199\n",
      "146 Train Loss 0.0021224548 Test MSE 0.00035676036880707816 Test RE 0.044202839267131595\n",
      "147 Train Loss 0.0020907314 Test MSE 0.00034633095812408376 Test RE 0.04355194160576684\n",
      "148 Train Loss 0.002052278 Test MSE 0.00032266168761416235 Test RE 0.04203737263729329\n",
      "149 Train Loss 0.0019790665 Test MSE 0.0003092458014955557 Test RE 0.04115416268995574\n",
      "150 Train Loss 0.0018996606 Test MSE 0.0002762997684627639 Test RE 0.03890022600556303\n",
      "151 Train Loss 0.0017875426 Test MSE 0.00028445394905230365 Test RE 0.039470065559095144\n",
      "152 Train Loss 0.0017305557 Test MSE 0.00030881658086790153 Test RE 0.04112559261880866\n",
      "153 Train Loss 0.0017027508 Test MSE 0.00031668085531135376 Test RE 0.04164594954797492\n",
      "154 Train Loss 0.0016915806 Test MSE 0.0002999395653445005 Test RE 0.04053019963773551\n",
      "155 Train Loss 0.0016857174 Test MSE 0.0002928869520639871 Test RE 0.04005086279654026\n",
      "156 Train Loss 0.0016785978 Test MSE 0.00030691362523547664 Test RE 0.04099868700973736\n",
      "157 Train Loss 0.0016626914 Test MSE 0.0002955386855926143 Test RE 0.04023176008423692\n",
      "158 Train Loss 0.0016434797 Test MSE 0.0002900492391078239 Test RE 0.039856368842216224\n",
      "159 Train Loss 0.0016078308 Test MSE 0.00029177149736528917 Test RE 0.03997452354707769\n",
      "160 Train Loss 0.0015640996 Test MSE 0.00029608519852952476 Test RE 0.04026894137909851\n",
      "161 Train Loss 0.0015315268 Test MSE 0.00027899879113664337 Test RE 0.03908976187343926\n",
      "162 Train Loss 0.0014982062 Test MSE 0.00025176914033104284 Test RE 0.03713326291523716\n",
      "163 Train Loss 0.0014559991 Test MSE 0.00024873612738117304 Test RE 0.036908916673797185\n",
      "164 Train Loss 0.001425004 Test MSE 0.00024581157361180846 Test RE 0.03669129393004252\n",
      "165 Train Loss 0.0014145208 Test MSE 0.00022623826971365126 Test RE 0.03520018121991971\n",
      "166 Train Loss 0.0014051158 Test MSE 0.00022747893423836604 Test RE 0.035296566122528954\n",
      "167 Train Loss 0.0013958234 Test MSE 0.00023697570824164345 Test RE 0.03602581205483001\n",
      "168 Train Loss 0.0013932844 Test MSE 0.0002355377806463803 Test RE 0.03591634655061081\n",
      "169 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "170 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "171 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "172 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "173 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "174 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "175 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "176 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "177 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "178 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "179 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "180 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "181 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "182 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "183 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "184 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "185 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "186 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "187 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "188 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "189 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "190 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "191 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "192 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "193 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "194 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "195 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "196 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "197 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "198 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "199 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "200 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "201 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "202 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "203 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "204 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "205 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "206 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "207 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "208 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "209 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "210 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "211 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "212 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "213 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "214 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "215 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "216 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "217 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "218 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "219 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "220 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "221 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "222 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "223 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "224 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "225 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "226 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "227 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "228 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "229 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "230 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "231 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "232 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "233 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "234 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "235 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "236 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "237 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "238 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "239 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "240 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "241 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "242 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "243 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "244 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "245 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "246 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "247 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "248 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "249 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "250 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "251 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "252 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "253 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "254 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "255 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "256 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "257 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "258 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "259 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "260 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "261 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "262 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "263 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "264 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "265 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "266 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "267 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "268 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "269 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "270 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "271 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "272 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "273 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "274 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "275 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "276 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "277 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "278 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "279 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "280 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "281 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "282 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "283 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "284 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "285 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "286 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "287 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "288 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "289 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "290 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "291 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "292 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "293 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "294 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "295 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "296 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "297 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "298 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "299 Train Loss 0.0013930572 Test MSE 0.00023601420515897644 Test RE 0.035952652369003704\n",
      "Training time: 115.15\n",
      "KG_atanh_low\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 6151.2773 Test MSE 8.957205744167911 Test RE 7.00403228043591\n",
      "1 Train Loss 2477.448 Test MSE 8.399960037728421 Test RE 6.782666663076388\n",
      "2 Train Loss 1419.518 Test MSE 8.738245751128861 Test RE 6.9178954027726105\n",
      "3 Train Loss 747.8833 Test MSE 9.520578809506043 Test RE 7.220936738671477\n",
      "4 Train Loss 215.34238 Test MSE 11.372579926006082 Test RE 7.892077891365299\n",
      "5 Train Loss 73.63027 Test MSE 12.081282983532875 Test RE 8.134266418259774\n",
      "6 Train Loss 32.452766 Test MSE 12.242851963780218 Test RE 8.188477558651373\n",
      "7 Train Loss 22.886543 Test MSE 11.765958278872628 Test RE 8.02741131133986\n",
      "8 Train Loss 18.459753 Test MSE 11.269975032554386 Test RE 7.856395550351847\n",
      "9 Train Loss 15.934316 Test MSE 10.494494466333078 Test RE 7.581281548650345\n",
      "10 Train Loss 13.601852 Test MSE 9.543738128246995 Test RE 7.229714062099119\n",
      "11 Train Loss 12.228682 Test MSE 8.737302235655704 Test RE 6.917521911471136\n",
      "12 Train Loss 10.636536 Test MSE 8.130498240712665 Test RE 6.672989540617759\n",
      "13 Train Loss 9.292116 Test MSE 7.457866652640125 Test RE 6.391005200957204\n",
      "14 Train Loss 7.89517 Test MSE 5.970848689499029 Test RE 5.718470655504341\n",
      "15 Train Loss 6.866609 Test MSE 4.9121069195181315 Test RE 5.186755423087315\n",
      "16 Train Loss 5.571227 Test MSE 3.640933762118752 Test RE 4.46548107441033\n",
      "17 Train Loss 4.293794 Test MSE 2.800105424303477 Test RE 3.916057459447571\n",
      "18 Train Loss 3.4556754 Test MSE 1.9245141739990108 Test RE 3.2465524312564815\n",
      "19 Train Loss 2.4690304 Test MSE 0.9093250472789898 Test RE 2.2316261457625943\n",
      "20 Train Loss 1.7791251 Test MSE 0.39465497026015306 Test RE 1.4701804805599716\n",
      "21 Train Loss 1.1231732 Test MSE 0.13893406683350906 Test RE 0.8723007346837364\n",
      "22 Train Loss 0.75528276 Test MSE 0.10495430411077082 Test RE 0.7581619606974289\n",
      "23 Train Loss 0.5638505 Test MSE 0.13134987013406865 Test RE 0.8481578537483699\n",
      "24 Train Loss 0.43673757 Test MSE 0.10841966686647941 Test RE 0.7705767447627521\n",
      "25 Train Loss 0.32855135 Test MSE 0.060229166230141684 Test RE 0.574335008730638\n",
      "26 Train Loss 0.26491687 Test MSE 0.05365325086259609 Test RE 0.5420756317132812\n",
      "27 Train Loss 0.21189208 Test MSE 0.04619631310957987 Test RE 0.5029971474861543\n",
      "28 Train Loss 0.17673466 Test MSE 0.042546037754486773 Test RE 0.48271570047846063\n",
      "29 Train Loss 0.14285704 Test MSE 0.03485503494901006 Test RE 0.4369126562596689\n",
      "30 Train Loss 0.12254282 Test MSE 0.03491072130841858 Test RE 0.4372615350547121\n",
      "31 Train Loss 0.09921958 Test MSE 0.030355762745675308 Test RE 0.40773917414914246\n",
      "32 Train Loss 0.084072344 Test MSE 0.02206837898358188 Test RE 0.3476538800913609\n",
      "33 Train Loss 0.07250883 Test MSE 0.019793011734471004 Test RE 0.329243951327246\n",
      "34 Train Loss 0.06215792 Test MSE 0.014538376127874963 Test RE 0.28217583201944635\n",
      "35 Train Loss 0.057009812 Test MSE 0.012948562392985362 Test RE 0.26630090413030105\n",
      "36 Train Loss 0.051742952 Test MSE 0.011244014991736492 Test RE 0.24815473826724654\n",
      "37 Train Loss 0.047260083 Test MSE 0.011048467560721503 Test RE 0.24598741376615066\n",
      "38 Train Loss 0.043335546 Test MSE 0.012054584682947086 Test RE 0.25694370973501246\n",
      "39 Train Loss 0.039360296 Test MSE 0.010777878962100815 Test RE 0.24295649580928974\n",
      "40 Train Loss 0.036763474 Test MSE 0.010319091598225317 Test RE 0.23772923772171364\n",
      "41 Train Loss 0.033137284 Test MSE 0.009711103237560205 Test RE 0.23061956550599552\n",
      "42 Train Loss 0.030915363 Test MSE 0.011221448664413505 Test RE 0.24790559445176213\n",
      "43 Train Loss 0.028838545 Test MSE 0.010681897964035415 Test RE 0.24187226782530397\n",
      "44 Train Loss 0.026727427 Test MSE 0.011557793788196356 Test RE 0.25159345253352117\n",
      "45 Train Loss 0.024624152 Test MSE 0.011295412547318718 Test RE 0.24872126208424977\n",
      "46 Train Loss 0.022182643 Test MSE 0.009060661460067922 Test RE 0.22276236292453894\n",
      "47 Train Loss 0.020855663 Test MSE 0.009336913409891822 Test RE 0.22613278406234766\n",
      "48 Train Loss 0.018655486 Test MSE 0.008334726360502791 Test RE 0.2136522825840317\n",
      "49 Train Loss 0.017879171 Test MSE 0.007879556916686006 Test RE 0.20773647716728735\n",
      "50 Train Loss 0.0154137295 Test MSE 0.005756592941847628 Test RE 0.17755979071914446\n",
      "51 Train Loss 0.014541713 Test MSE 0.005363577121626691 Test RE 0.17139144047049576\n",
      "52 Train Loss 0.013540323 Test MSE 0.004493077878790521 Test RE 0.1568678113372644\n",
      "53 Train Loss 0.012760936 Test MSE 0.003831080731288153 Test RE 0.14485133960163182\n",
      "54 Train Loss 0.01181375 Test MSE 0.004138386965043072 Test RE 0.15054883972862315\n",
      "55 Train Loss 0.010988975 Test MSE 0.0036245629409284857 Test RE 0.1408930877066042\n",
      "56 Train Loss 0.010534865 Test MSE 0.0033399496683510998 Test RE 0.1352483031742574\n",
      "57 Train Loss 0.010012988 Test MSE 0.0030080619489304553 Test RE 0.12835277187967978\n",
      "58 Train Loss 0.009224025 Test MSE 0.0026797007564316974 Test RE 0.12114486588077826\n",
      "59 Train Loss 0.008813958 Test MSE 0.0027076359926785586 Test RE 0.12177468176983623\n",
      "60 Train Loss 0.00810605 Test MSE 0.0023096679688904094 Test RE 0.11246998566251193\n",
      "61 Train Loss 0.007615804 Test MSE 0.002177502056251393 Test RE 0.10920465494160073\n",
      "62 Train Loss 0.007453477 Test MSE 0.002099412787529626 Test RE 0.10722863637873493\n",
      "63 Train Loss 0.007273572 Test MSE 0.0021268368717534815 Test RE 0.10792671399354918\n",
      "64 Train Loss 0.006872324 Test MSE 0.001983858755710699 Test RE 0.10423588026126544\n",
      "65 Train Loss 0.006353169 Test MSE 0.0022300948774753335 Test RE 0.11051558683072929\n",
      "66 Train Loss 0.0060786745 Test MSE 0.002103746807791295 Test RE 0.10733926052216441\n",
      "67 Train Loss 0.006001422 Test MSE 0.00206567114323683 Test RE 0.10636345972235352\n",
      "68 Train Loss 0.005756398 Test MSE 0.002230840033217611 Test RE 0.11053404892554335\n",
      "69 Train Loss 0.0055447207 Test MSE 0.002164774742845658 Test RE 0.10888504129138957\n",
      "70 Train Loss 0.0054472527 Test MSE 0.00205126758607976 Test RE 0.1059919842965038\n",
      "71 Train Loss 0.0052188886 Test MSE 0.0017525724433664403 Test RE 0.09797152166221834\n",
      "72 Train Loss 0.004932995 Test MSE 0.0017413449280007805 Test RE 0.09765719966895386\n",
      "73 Train Loss 0.0047213957 Test MSE 0.0018990073988722894 Test RE 0.1019823916041659\n",
      "74 Train Loss 0.004603255 Test MSE 0.001920203304056338 Test RE 0.10254995410940769\n",
      "75 Train Loss 0.0045282836 Test MSE 0.0019509165900902423 Test RE 0.10336683409732288\n",
      "76 Train Loss 0.004330742 Test MSE 0.0018082796387172784 Test RE 0.09951640070256901\n",
      "77 Train Loss 0.00407562 Test MSE 0.0015852797793084867 Test RE 0.09317830889022898\n",
      "78 Train Loss 0.0040133903 Test MSE 0.0015592287036897373 Test RE 0.09240953280243043\n",
      "79 Train Loss 0.003976227 Test MSE 0.0015360541157885656 Test RE 0.09172022727520754\n",
      "80 Train Loss 0.0038241183 Test MSE 0.0014930399101083147 Test RE 0.09042688538510461\n",
      "81 Train Loss 0.0036249903 Test MSE 0.0013343936584066713 Test RE 0.0854877425050077\n",
      "82 Train Loss 0.003475572 Test MSE 0.0012729342893378886 Test RE 0.08349584355145007\n",
      "83 Train Loss 0.00340374 Test MSE 0.0012202047686185496 Test RE 0.08174820455754411\n",
      "84 Train Loss 0.0033505398 Test MSE 0.0010922103403701111 Test RE 0.07734193011670971\n",
      "85 Train Loss 0.003297955 Test MSE 0.0010840517008541312 Test RE 0.07705252261770298\n",
      "86 Train Loss 0.0032194469 Test MSE 0.0010710013263885278 Test RE 0.07658731924999618\n",
      "87 Train Loss 0.0030913944 Test MSE 0.0009559265122319785 Test RE 0.07235592791425755\n",
      "88 Train Loss 0.0029584237 Test MSE 0.0008520644033289155 Test RE 0.06831216902544436\n",
      "89 Train Loss 0.002865424 Test MSE 0.0008580273587798847 Test RE 0.06855078492784661\n",
      "90 Train Loss 0.0027971056 Test MSE 0.0008119382671167571 Test RE 0.06668426508553824\n",
      "91 Train Loss 0.002658913 Test MSE 0.0007141512306960957 Test RE 0.06253986774840317\n",
      "92 Train Loss 0.0025370307 Test MSE 0.0005910015177778453 Test RE 0.05689264985941843\n",
      "93 Train Loss 0.0024069212 Test MSE 0.0006576969205451099 Test RE 0.060017067050796645\n",
      "94 Train Loss 0.002321656 Test MSE 0.0005947757296535498 Test RE 0.057074022650626464\n",
      "95 Train Loss 0.002264982 Test MSE 0.0005543623072866818 Test RE 0.05510090232632434\n",
      "96 Train Loss 0.0022314002 Test MSE 0.0005454380474035841 Test RE 0.05465558896921135\n",
      "97 Train Loss 0.002208971 Test MSE 0.0005504977483905593 Test RE 0.054908507307238216\n",
      "98 Train Loss 0.002161755 Test MSE 0.0005091191947272127 Test RE 0.052804580839727604\n",
      "99 Train Loss 0.0021035217 Test MSE 0.0004758982556888987 Test RE 0.05105272411883643\n",
      "100 Train Loss 0.002031819 Test MSE 0.0004434200862253024 Test RE 0.049279869045230545\n",
      "101 Train Loss 0.0019757652 Test MSE 0.0004200973350338165 Test RE 0.047966367143567334\n",
      "102 Train Loss 0.0019104317 Test MSE 0.0003697356637534767 Test RE 0.04499948420373112\n",
      "103 Train Loss 0.0018550053 Test MSE 0.00031192362923522765 Test RE 0.04133196011776985\n",
      "104 Train Loss 0.0018336934 Test MSE 0.00030036422390478535 Test RE 0.04055888109636038\n",
      "105 Train Loss 0.0017971674 Test MSE 0.00030845341269884795 Test RE 0.041101403665366305\n",
      "106 Train Loss 0.0017609802 Test MSE 0.00029481389265384727 Test RE 0.04018239667234991\n",
      "107 Train Loss 0.0017248496 Test MSE 0.0002502792479976238 Test RE 0.03702322827164734\n",
      "108 Train Loss 0.0016537321 Test MSE 0.00020837089445657064 Test RE 0.03378161375223343\n",
      "109 Train Loss 0.0015639842 Test MSE 0.00019192472325222713 Test RE 0.03242106863335549\n",
      "110 Train Loss 0.001505166 Test MSE 0.0001733133194242514 Test RE 0.030809016456746854\n",
      "111 Train Loss 0.0014594398 Test MSE 0.00014878143328777812 Test RE 0.02854540657776569\n",
      "112 Train Loss 0.0014184328 Test MSE 0.00014266806550115497 Test RE 0.0279527956943315\n",
      "113 Train Loss 0.0013798109 Test MSE 0.0001305738197395126 Test RE 0.02674175579385538\n",
      "114 Train Loss 0.0013469224 Test MSE 0.00014015285025556547 Test RE 0.027705298343527068\n",
      "115 Train Loss 0.001319384 Test MSE 0.00014580374360211542 Test RE 0.028258311064964417\n",
      "116 Train Loss 0.0013033989 Test MSE 0.00014675843703240393 Test RE 0.02835067496999809\n",
      "117 Train Loss 0.0012895169 Test MSE 0.00013877240283035843 Test RE 0.027568517855460054\n",
      "118 Train Loss 0.0012589435 Test MSE 0.00012893930691269153 Test RE 0.02657385309084797\n",
      "119 Train Loss 0.0012288628 Test MSE 0.00010514742931334156 Test RE 0.023997234404766022\n",
      "120 Train Loss 0.0012028655 Test MSE 9.939510166965871e-05 Test RE 0.0233315910261691\n",
      "121 Train Loss 0.0011290243 Test MSE 8.136864395861085e-05 Test RE 0.021110105474517294\n",
      "122 Train Loss 0.0010854126 Test MSE 5.843895599346236e-05 Test RE 0.017890113192131477\n",
      "123 Train Loss 0.0010743204 Test MSE 5.370826406215338e-05 Test RE 0.017150722567891276\n",
      "124 Train Loss 0.0010621893 Test MSE 5.0099068414962595e-05 Test RE 0.016564437371080525\n",
      "125 Train Loss 0.0010417986 Test MSE 4.56103070283907e-05 Test RE 0.015804958575700807\n",
      "126 Train Loss 0.0010166005 Test MSE 4.138384053123155e-05 Test RE 0.015054878676278811\n",
      "127 Train Loss 0.00098802 Test MSE 4.5439445492860995e-05 Test RE 0.01577532718890835\n",
      "128 Train Loss 0.00096035434 Test MSE 3.7335760632412416e-05 Test RE 0.014299615692827578\n",
      "129 Train Loss 0.0009284911 Test MSE 3.585459024383199e-05 Test RE 0.014013100794811781\n",
      "130 Train Loss 0.0008844057 Test MSE 4.121760262318063e-05 Test RE 0.015024610703577575\n",
      "131 Train Loss 0.0008398305 Test MSE 4.245979634296356e-05 Test RE 0.015249331918338629\n",
      "132 Train Loss 0.0008238891 Test MSE 3.900478423062351e-05 Test RE 0.01461573983851039\n",
      "133 Train Loss 0.00080622075 Test MSE 4.6944817686978765e-05 Test RE 0.016034509985657846\n",
      "134 Train Loss 0.00078469084 Test MSE 4.9355307303039505e-05 Test RE 0.016441021383799815\n",
      "135 Train Loss 0.00076853484 Test MSE 5.208265412998562e-05 Test RE 0.016889174307109\n",
      "136 Train Loss 0.0007585827 Test MSE 5.4861353552336606e-05 Test RE 0.01733385356063227\n",
      "137 Train Loss 0.00074968353 Test MSE 5.6074505277133304e-05 Test RE 0.01752445777705909\n",
      "138 Train Loss 0.00072578783 Test MSE 5.235546436798933e-05 Test RE 0.01693334949257109\n",
      "139 Train Loss 0.00070785446 Test MSE 5.5942057137949775e-05 Test RE 0.017503749132080262\n",
      "140 Train Loss 0.0006973495 Test MSE 5.0477529096623385e-05 Test RE 0.016626885572172734\n",
      "141 Train Loss 0.00068409723 Test MSE 4.7618900076631876e-05 Test RE 0.016149219736665003\n",
      "142 Train Loss 0.0006790995 Test MSE 4.722428659304465e-05 Test RE 0.016082166976817247\n",
      "143 Train Loss 0.0006673486 Test MSE 4.786095416110182e-05 Test RE 0.016190212175455177\n",
      "144 Train Loss 0.00064147107 Test MSE 4.7657594747181335e-05 Test RE 0.016155779756354748\n",
      "145 Train Loss 0.00062699325 Test MSE 4.977652520748411e-05 Test RE 0.01651102945335322\n",
      "146 Train Loss 0.0006192824 Test MSE 4.788932986458638e-05 Test RE 0.01619501087404945\n",
      "147 Train Loss 0.0006109446 Test MSE 4.579055081931124e-05 Test RE 0.015836156970847184\n",
      "148 Train Loss 0.0005957016 Test MSE 4.5637765649256354e-05 Test RE 0.015809715363102755\n",
      "149 Train Loss 0.00058241346 Test MSE 4.079742067044717e-05 Test RE 0.014947832317304547\n",
      "150 Train Loss 0.0005716943 Test MSE 4.106010614713838e-05 Test RE 0.014995877978891849\n",
      "151 Train Loss 0.00056455226 Test MSE 4.006085113414417e-05 Test RE 0.01481228126399543\n",
      "152 Train Loss 0.0005542209 Test MSE 3.775669497171699e-05 Test RE 0.014379998797330063\n",
      "153 Train Loss 0.0005455841 Test MSE 3.345078763461224e-05 Test RE 0.013535211241656816\n",
      "154 Train Loss 0.0005351945 Test MSE 2.921742201176745e-05 Test RE 0.012649775289583488\n",
      "155 Train Loss 0.00053072313 Test MSE 2.8438588973989457e-05 Test RE 0.012480037382571545\n",
      "156 Train Loss 0.0005199683 Test MSE 2.7278784294584486e-05 Test RE 0.012222903130126358\n",
      "157 Train Loss 0.0005138542 Test MSE 2.690429364028357e-05 Test RE 0.012138713498832152\n",
      "158 Train Loss 0.0005064377 Test MSE 2.6906912289089632e-05 Test RE 0.01213930422711143\n",
      "159 Train Loss 0.00050140143 Test MSE 2.660525305422151e-05 Test RE 0.012071064237176283\n",
      "160 Train Loss 0.00049762253 Test MSE 2.666510523874584e-05 Test RE 0.012084634371046413\n",
      "161 Train Loss 0.00048910413 Test MSE 2.3738867780684444e-05 Test RE 0.011402284286495153\n",
      "162 Train Loss 0.0004819812 Test MSE 2.2123688729197806e-05 Test RE 0.011007549162173239\n",
      "163 Train Loss 0.00047801583 Test MSE 2.2851808840108835e-05 Test RE 0.011187219396403098\n",
      "164 Train Loss 0.00047426834 Test MSE 2.2019025137746475e-05 Test RE 0.010981480827399536\n",
      "165 Train Loss 0.00046956763 Test MSE 2.4594193703949377e-05 Test RE 0.01160588221332992\n",
      "166 Train Loss 0.00046454158 Test MSE 2.472188054555087e-05 Test RE 0.011635970615534265\n",
      "167 Train Loss 0.000457007 Test MSE 2.4322397262629058e-05 Test RE 0.011541574329760966\n",
      "168 Train Loss 0.00045222914 Test MSE 2.6244044404399708e-05 Test RE 0.011988842256457051\n",
      "169 Train Loss 0.00044784372 Test MSE 2.4986166506586013e-05 Test RE 0.011698001667213876\n",
      "170 Train Loss 0.00044523005 Test MSE 2.4590293157330103e-05 Test RE 0.011604961852203171\n",
      "171 Train Loss 0.00044100988 Test MSE 2.5503579708446072e-05 Test RE 0.011818502064652887\n",
      "172 Train Loss 0.00043767772 Test MSE 2.637678696040058e-05 Test RE 0.012019123836688449\n",
      "173 Train Loss 0.00043029725 Test MSE 2.606034202515091e-05 Test RE 0.011946808978363687\n",
      "174 Train Loss 0.0004252806 Test MSE 2.3711125548316742e-05 Test RE 0.011395619745987955\n",
      "175 Train Loss 0.0004216398 Test MSE 2.4645475025613915e-05 Test RE 0.011617975617666209\n",
      "176 Train Loss 0.00041842173 Test MSE 2.4909094437136908e-05 Test RE 0.011679945965687909\n",
      "177 Train Loss 0.00041553518 Test MSE 2.3292399452821704e-05 Test RE 0.011294551207036515\n",
      "178 Train Loss 0.0004120914 Test MSE 2.408303467196478e-05 Test RE 0.011484642201325342\n",
      "179 Train Loss 0.00040513024 Test MSE 2.1502859901224535e-05 Test RE 0.010852004788213509\n",
      "180 Train Loss 0.00040141205 Test MSE 2.0387433119350714e-05 Test RE 0.010566791513308913\n",
      "181 Train Loss 0.00039738105 Test MSE 2.0285800204742505e-05 Test RE 0.010540420474583654\n",
      "182 Train Loss 0.00039211917 Test MSE 2.082055537627658e-05 Test RE 0.010678445094530241\n",
      "183 Train Loss 0.00038941138 Test MSE 2.2561395530171576e-05 Test RE 0.011115905440283829\n",
      "184 Train Loss 0.00038677157 Test MSE 2.1232060992726402e-05 Test RE 0.01078345525475051\n",
      "185 Train Loss 0.00038293045 Test MSE 2.147255747522525e-05 Test RE 0.01084435561948447\n",
      "186 Train Loss 0.00037772552 Test MSE 2.1658962473753852e-05 Test RE 0.010891324266788228\n",
      "187 Train Loss 0.00037204302 Test MSE 1.7999624779289212e-05 Test RE 0.009928727467992986\n",
      "188 Train Loss 0.0003672043 Test MSE 1.8362323467017987e-05 Test RE 0.010028262206476934\n",
      "189 Train Loss 0.0003622115 Test MSE 1.9502705574891333e-05 Test RE 0.010334971807241121\n",
      "190 Train Loss 0.00035917704 Test MSE 2.0617808002093953e-05 Test RE 0.0106263253705774\n",
      "191 Train Loss 0.0003569034 Test MSE 2.083730315098365e-05 Test RE 0.010682739030012019\n",
      "192 Train Loss 0.0003550649 Test MSE 2.1640357452324846e-05 Test RE 0.010886645444897263\n",
      "193 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "194 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "195 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "196 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "197 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "198 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "199 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "200 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "201 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "202 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "203 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "204 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "205 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "206 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "207 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "208 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "209 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "210 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "211 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "212 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "213 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "214 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "215 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "216 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "217 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "218 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "219 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "220 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "221 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "222 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "223 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "224 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "225 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "226 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "227 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "228 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "229 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "230 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "231 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "232 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "233 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "234 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "235 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "236 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "237 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "238 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "239 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "240 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "241 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "242 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "243 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "244 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "245 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "246 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "247 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "248 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "249 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "250 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "251 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "252 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "253 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "254 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "255 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "256 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "257 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "258 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "259 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "260 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "261 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "262 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "263 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "264 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "265 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "266 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "267 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "268 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "269 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "270 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "271 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "272 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "273 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "274 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "275 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "276 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "277 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "278 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "279 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "280 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "281 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "282 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "283 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "284 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "285 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "286 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "287 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "288 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "289 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "290 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "291 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "292 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "293 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "294 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "295 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "296 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "297 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "298 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "299 Train Loss 0.00035432677 Test MSE 2.1480209908505617e-05 Test RE 0.01084628781399847\n",
      "Training time: 174.40\n",
      "KG_atanh_low\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 7128.634 Test MSE 8.161212421388717 Test RE 6.685581770676088\n",
      "1 Train Loss 4640.2803 Test MSE 9.207352766346473 Test RE 7.101159303095208\n",
      "2 Train Loss 698.2426 Test MSE 11.769433555917233 Test RE 8.028596740435459\n",
      "3 Train Loss 222.95468 Test MSE 13.942428295659578 Test RE 8.738382961947094\n",
      "4 Train Loss 122.49493 Test MSE 15.245435920783589 Test RE 9.137592523712774\n",
      "5 Train Loss 85.52533 Test MSE 15.498692503783174 Test RE 9.213176580908137\n",
      "6 Train Loss 58.594166 Test MSE 15.376356096020507 Test RE 9.176743187992304\n",
      "7 Train Loss 40.572918 Test MSE 15.39143198937714 Test RE 9.181240798035963\n",
      "8 Train Loss 28.258202 Test MSE 15.319311409307284 Test RE 9.1597049879829\n",
      "9 Train Loss 24.347113 Test MSE 15.284366028020868 Test RE 9.149251772273589\n",
      "10 Train Loss 21.743862 Test MSE 15.078300152480674 Test RE 9.08736675834509\n",
      "11 Train Loss 20.556871 Test MSE 14.880304809336884 Test RE 9.02750583382571\n",
      "12 Train Loss 19.569525 Test MSE 14.738801238223244 Test RE 8.984479976558296\n",
      "13 Train Loss 18.425135 Test MSE 14.370221937698185 Test RE 8.871429422292394\n",
      "14 Train Loss 17.134277 Test MSE 13.723013385577413 Test RE 8.669351413825149\n",
      "15 Train Loss 16.09815 Test MSE 13.226207575819352 Test RE 8.510979240711373\n",
      "16 Train Loss 15.34196 Test MSE 12.740818081821448 Test RE 8.353346979466872\n",
      "17 Train Loss 14.30407 Test MSE 11.998887309895045 Test RE 8.10648066763759\n",
      "18 Train Loss 13.351919 Test MSE 11.294695006190656 Test RE 7.86500708277297\n",
      "19 Train Loss 12.501281 Test MSE 10.631160916279706 Test RE 7.630486177017463\n",
      "20 Train Loss 11.887609 Test MSE 10.31416613935656 Test RE 7.515864215810684\n",
      "21 Train Loss 11.368578 Test MSE 9.786088501066985 Test RE 7.320933021352693\n",
      "22 Train Loss 10.957184 Test MSE 9.734882558676526 Test RE 7.301754421667713\n",
      "23 Train Loss 10.58915 Test MSE 9.125201582491812 Test RE 7.069408823332387\n",
      "24 Train Loss 10.065313 Test MSE 8.856877415090839 Test RE 6.964696259193647\n",
      "25 Train Loss 9.372085 Test MSE 8.1170222299993 Test RE 6.6674571261965605\n",
      "26 Train Loss 8.583468 Test MSE 7.103713282028941 Test RE 6.237414078239739\n",
      "27 Train Loss 7.809498 Test MSE 6.289725932649361 Test RE 5.8691840013055785\n",
      "28 Train Loss 6.632122 Test MSE 5.405337367910254 Test RE 5.440931604290152\n",
      "29 Train Loss 5.7323647 Test MSE 4.388524940995446 Test RE 4.902540041873216\n",
      "30 Train Loss 4.869017 Test MSE 3.5939797820502757 Test RE 4.436593911467454\n",
      "31 Train Loss 3.7188764 Test MSE 2.802329951035153 Test RE 3.9176126946430054\n",
      "32 Train Loss 2.9078245 Test MSE 2.1393454160250585 Test RE 3.4229639044603553\n",
      "33 Train Loss 2.0098202 Test MSE 1.3846856311090712 Test RE 2.7538320926578748\n",
      "34 Train Loss 1.3858073 Test MSE 0.9038415258375567 Test RE 2.22488726058293\n",
      "35 Train Loss 1.1182449 Test MSE 0.9271577091560567 Test RE 2.253401976523991\n",
      "36 Train Loss 0.8591293 Test MSE 0.8837871513084482 Test RE 2.2000659811604613\n",
      "37 Train Loss 0.698964 Test MSE 0.818185459151614 Test RE 2.116838582150205\n",
      "38 Train Loss 0.57885754 Test MSE 0.6101591081539521 Test RE 1.8280303982941917\n",
      "39 Train Loss 0.49158746 Test MSE 0.47456528539303283 Test RE 1.6121663317569859\n",
      "40 Train Loss 0.4383761 Test MSE 0.44983458251997466 Test RE 1.5695974488106108\n",
      "41 Train Loss 0.38980895 Test MSE 0.41671646076661734 Test RE 1.5107137846808079\n",
      "42 Train Loss 0.35514614 Test MSE 0.35853651381013724 Test RE 1.4012917325061574\n",
      "43 Train Loss 0.31512418 Test MSE 0.3271724592804154 Test RE 1.3385981895669363\n",
      "44 Train Loss 0.2712768 Test MSE 0.30001769568981784 Test RE 1.2818443680270366\n",
      "45 Train Loss 0.23751067 Test MSE 0.27466213016575936 Test RE 1.2264822179668387\n",
      "46 Train Loss 0.20268542 Test MSE 0.21452735059339206 Test RE 1.0839348974125291\n",
      "47 Train Loss 0.16448897 Test MSE 0.1586515495218253 Test RE 0.9321461777742942\n",
      "48 Train Loss 0.14465591 Test MSE 0.12509382910824426 Test RE 0.827713059092272\n",
      "49 Train Loss 0.13471319 Test MSE 0.11103644393323042 Test RE 0.7798204794292766\n",
      "50 Train Loss 0.12404823 Test MSE 0.10560872812576834 Test RE 0.7605219800025588\n",
      "51 Train Loss 0.11302893 Test MSE 0.10065585247768301 Test RE 0.7424742215706013\n",
      "52 Train Loss 0.10348925 Test MSE 0.07316869795461885 Test RE 0.6330303428652596\n",
      "53 Train Loss 0.09507877 Test MSE 0.06362081402766598 Test RE 0.5902846296685382\n",
      "54 Train Loss 0.08273953 Test MSE 0.05457292965967171 Test RE 0.5467017932629401\n",
      "55 Train Loss 0.0752893 Test MSE 0.044173811898926024 Test RE 0.4918631681524567\n",
      "56 Train Loss 0.06823467 Test MSE 0.047674822952121415 Test RE 0.5109829491122773\n",
      "57 Train Loss 0.059475515 Test MSE 0.03840924453215274 Test RE 0.45864825617401067\n",
      "58 Train Loss 0.05176257 Test MSE 0.02545032150682921 Test RE 0.373343419188962\n",
      "59 Train Loss 0.046267916 Test MSE 0.019495246371068198 Test RE 0.3267579991149841\n",
      "60 Train Loss 0.04247283 Test MSE 0.014164447435266573 Test RE 0.27852339647432145\n",
      "61 Train Loss 0.038163755 Test MSE 0.016590111503221934 Test RE 0.30143002982554923\n",
      "62 Train Loss 0.033289433 Test MSE 0.016926224806106727 Test RE 0.3044681836422523\n",
      "63 Train Loss 0.030743323 Test MSE 0.014375020899553727 Test RE 0.28058607014274173\n",
      "64 Train Loss 0.0275721 Test MSE 0.018751294053637162 Test RE 0.3204626991102399\n",
      "65 Train Loss 0.02469778 Test MSE 0.015151543394477319 Test RE 0.28806487164440603\n",
      "66 Train Loss 0.023331689 Test MSE 0.011786721908252801 Test RE 0.25407292217202637\n",
      "67 Train Loss 0.021226851 Test MSE 0.007117864372570811 Test RE 0.19744071645257052\n",
      "68 Train Loss 0.019660536 Test MSE 0.005983702088276325 Test RE 0.18102845528010006\n",
      "69 Train Loss 0.018657615 Test MSE 0.005722390524568236 Test RE 0.17703152499350058\n",
      "70 Train Loss 0.01723613 Test MSE 0.006487654323454784 Test RE 0.18849755218621653\n",
      "71 Train Loss 0.016011836 Test MSE 0.006612645830177478 Test RE 0.19030469172675585\n",
      "72 Train Loss 0.014832558 Test MSE 0.00431107510151605 Test RE 0.15365781679284385\n",
      "73 Train Loss 0.014047502 Test MSE 0.0025416548996269844 Test RE 0.11798319571406325\n",
      "74 Train Loss 0.013098547 Test MSE 0.001289524317346052 Test RE 0.08403817879967677\n",
      "75 Train Loss 0.012638205 Test MSE 0.001325631183862016 Test RE 0.08520659684851872\n",
      "76 Train Loss 0.0117834825 Test MSE 0.0017831709454642455 Test RE 0.09882307279262355\n",
      "77 Train Loss 0.010955849 Test MSE 0.0010062044873522641 Test RE 0.07423436346384435\n",
      "78 Train Loss 0.00979628 Test MSE 0.0006093911469713692 Test RE 0.057771006550216865\n",
      "79 Train Loss 0.009444349 Test MSE 0.0005816624779216396 Test RE 0.056441349434275506\n",
      "80 Train Loss 0.008228398 Test MSE 0.0004106394781182875 Test RE 0.047423348282697654\n",
      "81 Train Loss 0.007173282 Test MSE 0.0003238778807666983 Test RE 0.04211652284478884\n",
      "82 Train Loss 0.0068411636 Test MSE 0.0004671568421118833 Test RE 0.0505816766599081\n",
      "83 Train Loss 0.0063160732 Test MSE 0.00039429618952418875 Test RE 0.04647005153164538\n",
      "84 Train Loss 0.005723657 Test MSE 0.00022282720347641355 Test RE 0.03493381121503277\n",
      "85 Train Loss 0.0053408192 Test MSE 0.00022401449020651207 Test RE 0.035026756212240634\n",
      "86 Train Loss 0.0052007055 Test MSE 0.0002181279549065875 Test RE 0.034563485187878454\n",
      "87 Train Loss 0.0050401976 Test MSE 0.00021924269118998583 Test RE 0.034651690459135985\n",
      "88 Train Loss 0.0048002433 Test MSE 0.0002762439057272256 Test RE 0.03889629335136686\n",
      "89 Train Loss 0.004600515 Test MSE 0.0002756562138237279 Test RE 0.03885489658757854\n",
      "90 Train Loss 0.0044886107 Test MSE 0.00025034140117054476 Test RE 0.03702782507358601\n",
      "91 Train Loss 0.0043346887 Test MSE 0.00025643658471280104 Test RE 0.03747588142385243\n",
      "92 Train Loss 0.0042054225 Test MSE 0.0002134150606234432 Test RE 0.03418805517074399\n",
      "93 Train Loss 0.0040856353 Test MSE 0.0002782935308126921 Test RE 0.03904032455844418\n",
      "94 Train Loss 0.003933879 Test MSE 0.00032075005894234966 Test RE 0.0419126611701484\n",
      "95 Train Loss 0.0037155962 Test MSE 0.0004277432250497353 Test RE 0.04840089961259339\n",
      "96 Train Loss 0.0035851977 Test MSE 0.00042408274219819786 Test RE 0.048193355313849856\n",
      "97 Train Loss 0.0035356418 Test MSE 0.0004271321065212878 Test RE 0.04836631197079585\n",
      "98 Train Loss 0.0034604268 Test MSE 0.0005280602865418106 Test RE 0.053777872550047845\n",
      "99 Train Loss 0.0033575685 Test MSE 0.00047513091085251157 Test RE 0.051011548459853034\n",
      "100 Train Loss 0.003226762 Test MSE 0.00029707781714528175 Test RE 0.04033638523654445\n",
      "101 Train Loss 0.003151462 Test MSE 0.0002769114308236552 Test RE 0.03894326015340493\n",
      "102 Train Loss 0.0030856482 Test MSE 0.00025688769865034436 Test RE 0.03750883004529294\n",
      "103 Train Loss 0.0030048762 Test MSE 0.00025537650672459363 Test RE 0.037398340812512906\n",
      "104 Train Loss 0.002873745 Test MSE 0.0002282421633386671 Test RE 0.035355729420059184\n",
      "105 Train Loss 0.0027168007 Test MSE 0.00019365238252506481 Test RE 0.03256666496471538\n",
      "106 Train Loss 0.002611222 Test MSE 0.00011417108401796488 Test RE 0.02500575238393309\n",
      "107 Train Loss 0.0025837445 Test MSE 0.0001086308073699083 Test RE 0.02439149207164529\n",
      "108 Train Loss 0.0025478562 Test MSE 0.00010953083133024933 Test RE 0.0244923273886447\n",
      "109 Train Loss 0.002442929 Test MSE 8.502403532807754e-05 Test RE 0.021579069841401777\n",
      "110 Train Loss 0.0023728886 Test MSE 6.689306828301429e-05 Test RE 0.01914046227207689\n",
      "111 Train Loss 0.0023397005 Test MSE 6.227169483103922e-05 Test RE 0.018467461700576015\n",
      "112 Train Loss 0.0023270948 Test MSE 5.447193141504062e-05 Test RE 0.017272223585499617\n",
      "113 Train Loss 0.002243386 Test MSE 4.5786405665308574e-05 Test RE 0.015835440176727823\n",
      "114 Train Loss 0.002143823 Test MSE 3.1579317574818483e-05 Test RE 0.013151134953396754\n",
      "115 Train Loss 0.0020833998 Test MSE 3.8749151102304766e-05 Test RE 0.014567766118267756\n",
      "116 Train Loss 0.002056397 Test MSE 4.49892703927463e-05 Test RE 0.01569698846379706\n",
      "117 Train Loss 0.0020179923 Test MSE 7.839910139054699e-05 Test RE 0.020721319468345527\n",
      "118 Train Loss 0.0019534242 Test MSE 8.816848563001786e-05 Test RE 0.021974477367546156\n",
      "119 Train Loss 0.0018582682 Test MSE 7.562052351841076e-05 Test RE 0.020350810198247252\n",
      "120 Train Loss 0.001766102 Test MSE 6.898901112685757e-05 Test RE 0.019438011019619842\n",
      "121 Train Loss 0.0017166262 Test MSE 8.518523861785301e-05 Test RE 0.02159951682298407\n",
      "122 Train Loss 0.0016950254 Test MSE 7.912533509974492e-05 Test RE 0.020817072042075314\n",
      "123 Train Loss 0.0016762204 Test MSE 8.433318158274149e-05 Test RE 0.021491221810389725\n",
      "124 Train Loss 0.001635934 Test MSE 5.86715844567911e-05 Test RE 0.017925685491591126\n",
      "125 Train Loss 0.0015481706 Test MSE 7.188545827092326e-05 Test RE 0.0198418602687292\n",
      "126 Train Loss 0.0014708646 Test MSE 7.059867532283405e-05 Test RE 0.01966346910516879\n",
      "127 Train Loss 0.0014265805 Test MSE 8.683269425591073e-05 Test RE 0.021807380551190362\n",
      "128 Train Loss 0.0013741546 Test MSE 6.834487028312804e-05 Test RE 0.019347053197938224\n",
      "129 Train Loss 0.0013523505 Test MSE 6.702718582959628e-05 Test RE 0.01915964054031211\n",
      "130 Train Loss 0.0013303529 Test MSE 6.942754807319203e-05 Test RE 0.01949969317978181\n",
      "131 Train Loss 0.001311332 Test MSE 6.122660564912434e-05 Test RE 0.018311838760611952\n",
      "132 Train Loss 0.0012736737 Test MSE 4.030621672415605e-05 Test RE 0.014857573312917826\n",
      "133 Train Loss 0.0012293737 Test MSE 2.4252407805763477e-05 Test RE 0.011524956509053082\n",
      "134 Train Loss 0.0011927836 Test MSE 2.7188121401396217e-05 Test RE 0.012202574400542093\n",
      "135 Train Loss 0.0011698132 Test MSE 2.3669512500818046e-05 Test RE 0.011385615693127425\n",
      "136 Train Loss 0.0011334307 Test MSE 3.066878732526635e-05 Test RE 0.012960154115755136\n",
      "137 Train Loss 0.0011030016 Test MSE 2.748513742743358e-05 Test RE 0.012269046725790628\n",
      "138 Train Loss 0.0010872467 Test MSE 3.0080257196732966e-05 Test RE 0.012835199893356693\n",
      "139 Train Loss 0.0010774106 Test MSE 2.8597648576039684e-05 Test RE 0.012514889706784535\n",
      "140 Train Loss 0.001070036 Test MSE 2.5070053274269608e-05 Test RE 0.011717622229750936\n",
      "141 Train Loss 0.0010615559 Test MSE 2.3572971454781588e-05 Test RE 0.011362372663760029\n",
      "142 Train Loss 0.0010446376 Test MSE 2.4040355390318198e-05 Test RE 0.011474461307622488\n",
      "143 Train Loss 0.0010167375 Test MSE 2.8321597576795442e-05 Test RE 0.012454340578250615\n",
      "144 Train Loss 0.0009952611 Test MSE 2.7988753445039445e-05 Test RE 0.01238094066441238\n",
      "145 Train Loss 0.0009807963 Test MSE 2.193339745571106e-05 Test RE 0.010960107612566775\n",
      "146 Train Loss 0.0009624876 Test MSE 2.503040562324992e-05 Test RE 0.011708353002914765\n",
      "147 Train Loss 0.0009375891 Test MSE 2.819906748806868e-05 Test RE 0.012427370249663748\n",
      "148 Train Loss 0.00092670583 Test MSE 2.747196407424894e-05 Test RE 0.012266106157327416\n",
      "149 Train Loss 0.0009187134 Test MSE 2.9642340517967032e-05 Test RE 0.012741428163765934\n",
      "150 Train Loss 0.0008986621 Test MSE 3.300117948534951e-05 Test RE 0.013443940914985391\n",
      "151 Train Loss 0.0008838274 Test MSE 4.914238630826789e-05 Test RE 0.01640551940373766\n",
      "152 Train Loss 0.00086859043 Test MSE 6.428571022517968e-05 Test RE 0.01876372620441059\n",
      "153 Train Loss 0.0008535553 Test MSE 6.612273062306476e-05 Test RE 0.019029932772599307\n",
      "154 Train Loss 0.00083834014 Test MSE 6.19437805215763e-05 Test RE 0.018418773944363243\n",
      "155 Train Loss 0.00082480797 Test MSE 5.977813525380034e-05 Test RE 0.01809393582779075\n",
      "156 Train Loss 0.0008188331 Test MSE 4.675919858046603e-05 Test RE 0.01600277848187035\n",
      "157 Train Loss 0.000812273 Test MSE 4.211543533657969e-05 Test RE 0.015187367819716935\n",
      "158 Train Loss 0.0008064901 Test MSE 4.01300904506999e-05 Test RE 0.014825076167727672\n",
      "159 Train Loss 0.0008025425 Test MSE 3.8013141771073725e-05 Test RE 0.01442875126415534\n",
      "160 Train Loss 0.0007965392 Test MSE 4.1367273269286376e-05 Test RE 0.015051864902268577\n",
      "161 Train Loss 0.0007894527 Test MSE 4.00035722599736e-05 Test RE 0.014801688200461231\n",
      "162 Train Loss 0.0007737121 Test MSE 3.224766979824072e-05 Test RE 0.013289573184977104\n",
      "163 Train Loss 0.0007616234 Test MSE 2.6447061129992415e-05 Test RE 0.012035124119792892\n",
      "164 Train Loss 0.00074798975 Test MSE 2.6086346007710684e-05 Test RE 0.01195276797829683\n",
      "165 Train Loss 0.0007283429 Test MSE 3.720283272985633e-05 Test RE 0.014274137266835997\n",
      "166 Train Loss 0.00071697874 Test MSE 4.098299843173192e-05 Test RE 0.014981790810470645\n",
      "167 Train Loss 0.00071133603 Test MSE 3.80148355769328e-05 Test RE 0.014429072721815126\n",
      "168 Train Loss 0.0007079933 Test MSE 3.988316308613465e-05 Test RE 0.014779395163847141\n",
      "169 Train Loss 0.0007047727 Test MSE 3.8353275201942225e-05 Test RE 0.014493160189886226\n",
      "170 Train Loss 0.00069754454 Test MSE 4.260488581183971e-05 Test RE 0.015275363962554005\n",
      "171 Train Loss 0.00068701943 Test MSE 4.330504985098038e-05 Test RE 0.015400369305703378\n",
      "172 Train Loss 0.0006792294 Test MSE 4.577053549466087e-05 Test RE 0.015832695552914864\n",
      "173 Train Loss 0.00066402555 Test MSE 3.724637845324609e-05 Test RE 0.014282488725656102\n",
      "174 Train Loss 0.00064764277 Test MSE 3.8390559261662625e-05 Test RE 0.014500203038066978\n",
      "175 Train Loss 0.000633768 Test MSE 3.625494142354223e-05 Test RE 0.014091118525665313\n",
      "176 Train Loss 0.0006270648 Test MSE 3.411283780583898e-05 Test RE 0.013668497847380827\n",
      "177 Train Loss 0.00062021334 Test MSE 2.867981212365165e-05 Test RE 0.012532854998875619\n",
      "178 Train Loss 0.0006151836 Test MSE 2.982141144772226e-05 Test RE 0.012779856032002723\n",
      "179 Train Loss 0.0006072424 Test MSE 2.7197471089100428e-05 Test RE 0.012204672383908557\n",
      "180 Train Loss 0.000600336 Test MSE 2.2041943021391103e-05 Test RE 0.01098719422401499\n",
      "181 Train Loss 0.000593588 Test MSE 2.1144787831417223e-05 Test RE 0.0107612700482918\n",
      "182 Train Loss 0.00058218895 Test MSE 3.092391849419838e-05 Test RE 0.01301394970573456\n",
      "183 Train Loss 0.0005716518 Test MSE 2.8558378422063237e-05 Test RE 0.012506294061610915\n",
      "184 Train Loss 0.0005566996 Test MSE 2.7317683122480786e-05 Test RE 0.012231614794541311\n",
      "185 Train Loss 0.00054402504 Test MSE 3.092880970317355e-05 Test RE 0.013014978867527104\n",
      "186 Train Loss 0.00053290377 Test MSE 3.1101189358779714e-05 Test RE 0.013051197529895206\n",
      "187 Train Loss 0.00051950663 Test MSE 3.261939377095537e-05 Test RE 0.0133659492184022\n",
      "188 Train Loss 0.0005048829 Test MSE 4.179001826410325e-05 Test RE 0.01512857924627745\n",
      "189 Train Loss 0.0004952017 Test MSE 4.331512116763178e-05 Test RE 0.015402160008860579\n",
      "190 Train Loss 0.0004892748 Test MSE 4.07651238251008e-05 Test RE 0.014941914499425068\n",
      "191 Train Loss 0.00048331002 Test MSE 3.586657353946346e-05 Test RE 0.014015442323468963\n",
      "192 Train Loss 0.00047658986 Test MSE 3.0380651056666428e-05 Test RE 0.012899129484102238\n",
      "193 Train Loss 0.00046966822 Test MSE 2.5222880125078076e-05 Test RE 0.011753283232256063\n",
      "194 Train Loss 0.00046482345 Test MSE 2.293167826642195e-05 Test RE 0.01120675258586657\n",
      "195 Train Loss 0.0004617804 Test MSE 1.8454570609601056e-05 Test RE 0.010053420232120998\n",
      "196 Train Loss 0.00045912375 Test MSE 1.983398114901632e-05 Test RE 0.010422377806708877\n",
      "197 Train Loss 0.000458393 Test MSE 2.046323207642959e-05 Test RE 0.010586416560824059\n",
      "198 Train Loss 0.00045493685 Test MSE 2.2600844436506052e-05 Test RE 0.011125619351687072\n",
      "199 Train Loss 0.00045257833 Test MSE 2.1441239628792185e-05 Test RE 0.010836444456833258\n",
      "200 Train Loss 0.00044700236 Test MSE 1.848418021925636e-05 Test RE 0.010061482152058184\n",
      "201 Train Loss 0.00043275653 Test MSE 2.1280376513942717e-05 Test RE 0.010795717658231991\n",
      "202 Train Loss 0.00042543354 Test MSE 2.2924526723083748e-05 Test RE 0.011205004963528314\n",
      "203 Train Loss 0.00041531434 Test MSE 1.6105460018417933e-05 Test RE 0.009391791251065046\n",
      "204 Train Loss 0.0004072611 Test MSE 1.7977001734021148e-05 Test RE 0.009922485985834822\n",
      "205 Train Loss 0.00039947778 Test MSE 1.2289768609274217e-05 Test RE 0.00820415236003521\n",
      "206 Train Loss 0.00039360445 Test MSE 9.354331933699965e-06 Test RE 0.007157613646057882\n",
      "207 Train Loss 0.00039070332 Test MSE 8.69693132896424e-06 Test RE 0.006901522123379333\n",
      "208 Train Loss 0.0003871352 Test MSE 8.460449152654077e-06 Test RE 0.006807044251460295\n",
      "209 Train Loss 0.00038458183 Test MSE 8.577266274143401e-06 Test RE 0.006853877063853249\n",
      "210 Train Loss 0.00038314477 Test MSE 8.600618090874461e-06 Test RE 0.006863200646022843\n",
      "211 Train Loss 0.00038149345 Test MSE 8.397386636901598e-06 Test RE 0.006781627619023722\n",
      "212 Train Loss 0.00038045595 Test MSE 8.438616629659151e-06 Test RE 0.006798255654776052\n",
      "213 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "214 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "215 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "216 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "217 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "218 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "219 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "220 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "221 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "222 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "223 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "224 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "225 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "226 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "227 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "228 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "229 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "230 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "231 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "232 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "233 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "234 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "235 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "236 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "237 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "238 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "239 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "240 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "241 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "242 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "243 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "244 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "245 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "246 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "247 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "248 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "249 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "250 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "251 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "252 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "253 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "254 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "255 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "256 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "257 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "258 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "259 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "260 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "261 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "262 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "263 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "264 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "265 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "266 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "267 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "268 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "269 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "270 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "271 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "272 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "273 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "274 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "275 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "276 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "277 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "278 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "279 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "280 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "281 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "282 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "283 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "284 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "285 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "286 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "287 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "288 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "289 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "290 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "291 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "292 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "293 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "294 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "295 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "296 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "297 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "298 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "299 Train Loss 0.00037900486 Test MSE 8.637351351546504e-06 Test RE 0.0068778414032827076\n",
      "Training time: 197.98\n",
      "KG_atanh_low\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 5639.263 Test MSE 8.840481208618288 Test RE 6.9582466104116785\n",
      "1 Train Loss 2579.0999 Test MSE 8.236475904631687 Test RE 6.7163385608634005\n",
      "2 Train Loss 503.1679 Test MSE 10.761118658227216 Test RE 7.676982915849387\n",
      "3 Train Loss 113.75569 Test MSE 12.827605640686013 Test RE 8.381749245244482\n",
      "4 Train Loss 56.450626 Test MSE 14.056534090693646 Test RE 8.774067863301688\n",
      "5 Train Loss 40.51929 Test MSE 14.301882139010827 Test RE 8.850309559737745\n",
      "6 Train Loss 32.064053 Test MSE 14.372086752132248 Test RE 8.872005023456799\n",
      "7 Train Loss 28.040695 Test MSE 14.694101632299331 Test RE 8.97084563601376\n",
      "8 Train Loss 25.33326 Test MSE 14.498560246868225 Test RE 8.91095607341178\n",
      "9 Train Loss 22.591677 Test MSE 14.305420743138148 Test RE 8.851404373857127\n",
      "10 Train Loss 20.573128 Test MSE 14.03794943184514 Test RE 8.76826568651787\n",
      "11 Train Loss 19.255869 Test MSE 13.83834984528139 Test RE 8.705706408551118\n",
      "12 Train Loss 17.90731 Test MSE 13.17479284481818 Test RE 8.494420608956927\n",
      "13 Train Loss 16.227333 Test MSE 12.18523932684339 Test RE 8.169188094900006\n",
      "14 Train Loss 14.500712 Test MSE 11.373285506810825 Test RE 7.892322708827037\n",
      "15 Train Loss 12.842367 Test MSE 10.829108890182823 Test RE 7.701196847802249\n",
      "16 Train Loss 11.925774 Test MSE 10.271397077728643 Test RE 7.500265262958033\n",
      "17 Train Loss 10.804528 Test MSE 9.355198933205518 Test RE 7.15794533750048\n",
      "18 Train Loss 9.937252 Test MSE 8.759723524284391 Test RE 6.926391948015555\n",
      "19 Train Loss 9.266591 Test MSE 8.419819686315481 Test RE 6.790679906751417\n",
      "20 Train Loss 8.845185 Test MSE 8.25944818309871 Test RE 6.725698277890962\n",
      "21 Train Loss 7.788712 Test MSE 7.36070295514025 Test RE 6.349236584382582\n",
      "22 Train Loss 6.9077697 Test MSE 6.713140242066933 Test RE 6.063518738448775\n",
      "23 Train Loss 6.2473116 Test MSE 6.209636258911461 Test RE 5.831696914387389\n",
      "24 Train Loss 5.8432846 Test MSE 5.64412830569653 Test RE 5.559814514329633\n",
      "25 Train Loss 5.274159 Test MSE 4.604661923969481 Test RE 5.021815338560851\n",
      "26 Train Loss 4.4840755 Test MSE 3.4735193443788233 Test RE 4.3616089463667\n",
      "27 Train Loss 3.9996104 Test MSE 2.7527701343068007 Test RE 3.8828162449436614\n",
      "28 Train Loss 3.2146897 Test MSE 1.8919094106193115 Test RE 3.218933708160737\n",
      "29 Train Loss 2.6346867 Test MSE 1.0830535486468873 Test RE 2.435492681458969\n",
      "30 Train Loss 2.2492828 Test MSE 0.7320137879462724 Test RE 2.00226471804536\n",
      "31 Train Loss 1.8530523 Test MSE 0.5885074960962563 Test RE 1.795303442114905\n",
      "32 Train Loss 1.4876734 Test MSE 0.4820843875729661 Test RE 1.624887873371556\n",
      "33 Train Loss 1.2247844 Test MSE 0.432058157879422 Test RE 1.5382714116247844\n",
      "34 Train Loss 0.9510028 Test MSE 0.3235964112181771 Test RE 1.331262541840083\n",
      "35 Train Loss 0.7641667 Test MSE 0.29071394477140694 Test RE 1.2618124150717853\n",
      "36 Train Loss 0.56989443 Test MSE 0.2576222423723119 Test RE 1.1878279552232434\n",
      "37 Train Loss 0.4968869 Test MSE 0.2359228541286414 Test RE 1.136702645671498\n",
      "38 Train Loss 0.39932498 Test MSE 0.19622192197338684 Test RE 1.0366582939340367\n",
      "39 Train Loss 0.30778438 Test MSE 0.1606994330821267 Test RE 0.938142986956966\n",
      "40 Train Loss 0.26944953 Test MSE 0.1295099472338352 Test RE 0.8421964903216173\n",
      "41 Train Loss 0.23502256 Test MSE 0.11762485989261415 Test RE 0.8026226726412592\n",
      "42 Train Loss 0.18021388 Test MSE 0.0941594308005395 Test RE 0.7181146327869083\n",
      "43 Train Loss 0.15626265 Test MSE 0.09310166038698499 Test RE 0.7140696540884385\n",
      "44 Train Loss 0.14064011 Test MSE 0.07739506468289396 Test RE 0.6510562281400862\n",
      "45 Train Loss 0.12197352 Test MSE 0.08149429025379502 Test RE 0.6680753608521044\n",
      "46 Train Loss 0.11297843 Test MSE 0.0830238581383361 Test RE 0.6743157749420896\n",
      "47 Train Loss 0.104261264 Test MSE 0.07280130795414833 Test RE 0.6314390770651479\n",
      "48 Train Loss 0.090609066 Test MSE 0.0682133977148845 Test RE 0.6112188018302862\n",
      "49 Train Loss 0.082614146 Test MSE 0.060771527362866284 Test RE 0.5769151446575577\n",
      "50 Train Loss 0.07109264 Test MSE 0.05141411970403281 Test RE 0.5306437656469065\n",
      "51 Train Loss 0.0658912 Test MSE 0.046951783738429814 Test RE 0.5070933463118046\n",
      "52 Train Loss 0.05979625 Test MSE 0.036997448959040655 Test RE 0.45014015266884094\n",
      "53 Train Loss 0.057128616 Test MSE 0.03662268841103825 Test RE 0.44785453372709555\n",
      "54 Train Loss 0.05269831 Test MSE 0.03108508303712683 Test RE 0.4126082239879299\n",
      "55 Train Loss 0.049747672 Test MSE 0.028583056586364307 Test RE 0.3956545810985397\n",
      "56 Train Loss 0.042296547 Test MSE 0.02516758681348246 Test RE 0.37126383951004155\n",
      "57 Train Loss 0.0397923 Test MSE 0.019210515708400128 Test RE 0.32436305032519186\n",
      "58 Train Loss 0.037634738 Test MSE 0.014207703887179275 Test RE 0.2789483600939223\n",
      "59 Train Loss 0.035100643 Test MSE 0.012073038501398426 Test RE 0.2571403062753163\n",
      "60 Train Loss 0.032557875 Test MSE 0.010577195049010005 Test RE 0.24068394458719464\n",
      "61 Train Loss 0.03085895 Test MSE 0.010338097297171953 Test RE 0.23794806181994457\n",
      "62 Train Loss 0.027335975 Test MSE 0.011075620400652358 Test RE 0.24628949901529593\n",
      "63 Train Loss 0.02437235 Test MSE 0.007930898613065493 Test RE 0.20841216400851292\n",
      "64 Train Loss 0.023036776 Test MSE 0.0057125013409134884 Test RE 0.17687848979959028\n",
      "65 Train Loss 0.021746352 Test MSE 0.0044155772775070455 Test RE 0.15550902875038092\n",
      "66 Train Loss 0.019488594 Test MSE 0.005480154416134683 Test RE 0.17324402372593747\n",
      "67 Train Loss 0.018098552 Test MSE 0.004064692376648523 Test RE 0.14920236443434853\n",
      "68 Train Loss 0.01730634 Test MSE 0.003445710315823963 Test RE 0.13737295665239604\n",
      "69 Train Loss 0.016586281 Test MSE 0.002738498862733234 Test RE 0.1224667369509886\n",
      "70 Train Loss 0.015241176 Test MSE 0.0027987599213944564 Test RE 0.12380685372334771\n",
      "71 Train Loss 0.014477441 Test MSE 0.002544162041226591 Test RE 0.1180413719180903\n",
      "72 Train Loss 0.0140903825 Test MSE 0.002650520757219209 Test RE 0.12048347052643182\n",
      "73 Train Loss 0.012614112 Test MSE 0.001699511188328563 Test RE 0.09647701946837857\n",
      "74 Train Loss 0.011668476 Test MSE 0.0013214755810790969 Test RE 0.08507293874350241\n",
      "75 Train Loss 0.010856991 Test MSE 0.0007585927227041018 Test RE 0.06445642290686257\n",
      "76 Train Loss 0.010309798 Test MSE 0.0005740071793514255 Test RE 0.05606870509659704\n",
      "77 Train Loss 0.009858206 Test MSE 0.0004693863184431129 Test RE 0.05070223191369936\n",
      "78 Train Loss 0.00922141 Test MSE 0.0004952013413680542 Test RE 0.052077816888811176\n",
      "79 Train Loss 0.008629018 Test MSE 0.0005214737854031926 Test RE 0.05344143419223433\n",
      "80 Train Loss 0.007923321 Test MSE 0.0004229268812337855 Test RE 0.04812763367387261\n",
      "81 Train Loss 0.0077151298 Test MSE 0.0004386073568938394 Test RE 0.04901170603557984\n",
      "82 Train Loss 0.0073860865 Test MSE 0.00041242169614905935 Test RE 0.047526147994266556\n",
      "83 Train Loss 0.007261314 Test MSE 0.0003869550028606956 Test RE 0.046035418649114423\n",
      "84 Train Loss 0.0067825303 Test MSE 0.00033833651940537625 Test RE 0.04304634704132126\n",
      "85 Train Loss 0.006415472 Test MSE 0.0003056093304910763 Test RE 0.04091147793638089\n",
      "86 Train Loss 0.0061607915 Test MSE 0.00029702913072992095 Test RE 0.04033307984926972\n",
      "87 Train Loss 0.0060720574 Test MSE 0.00028228706328232983 Test RE 0.03931944253715739\n",
      "88 Train Loss 0.0059329118 Test MSE 0.0003013447186992948 Test RE 0.04062502640841373\n",
      "89 Train Loss 0.0057532606 Test MSE 0.00029299872215392936 Test RE 0.04005850407504895\n",
      "90 Train Loss 0.005526256 Test MSE 0.0002953284444885206 Test RE 0.04021744744956016\n",
      "91 Train Loss 0.0053504203 Test MSE 0.0002984020278291297 Test RE 0.04042618406873749\n",
      "92 Train Loss 0.0051646507 Test MSE 0.00034247136789856904 Test RE 0.04330858537730827\n",
      "93 Train Loss 0.0050882087 Test MSE 0.00030786704405708006 Test RE 0.041062318283390166\n",
      "94 Train Loss 0.004973858 Test MSE 0.00033134579518321266 Test RE 0.04259931306028142\n",
      "95 Train Loss 0.004492691 Test MSE 0.0004008296861210299 Test RE 0.04685347461686994\n",
      "96 Train Loss 0.0042120707 Test MSE 0.00031846800299716705 Test RE 0.041763296004051625\n",
      "97 Train Loss 0.004125112 Test MSE 0.00028967505164611174 Test RE 0.03983065154222529\n",
      "98 Train Loss 0.004098811 Test MSE 0.00029508315403260283 Test RE 0.04020074231086453\n",
      "99 Train Loss 0.00400885 Test MSE 0.00029286157052343974 Test RE 0.04004912735797702\n",
      "100 Train Loss 0.0037018135 Test MSE 0.0002611691591230915 Test RE 0.03782011189575154\n",
      "101 Train Loss 0.0035724803 Test MSE 0.00024273318617470577 Test RE 0.03646082089551536\n",
      "102 Train Loss 0.0035316467 Test MSE 0.0002253323034033391 Test RE 0.03512963133392916\n",
      "103 Train Loss 0.003511937 Test MSE 0.00022502536049011634 Test RE 0.03510569675875941\n",
      "104 Train Loss 0.0033684897 Test MSE 0.00019630428068570394 Test RE 0.032788892590363335\n",
      "105 Train Loss 0.0031253444 Test MSE 0.00020746953193606177 Test RE 0.03370846898482004\n",
      "106 Train Loss 0.0029950584 Test MSE 0.00020021896120688852 Test RE 0.033114215133251364\n",
      "107 Train Loss 0.0029168162 Test MSE 0.0001875530573642611 Test RE 0.03204969774362485\n",
      "108 Train Loss 0.0028828264 Test MSE 0.00019172965165002652 Test RE 0.03240458811551147\n",
      "109 Train Loss 0.0027711838 Test MSE 0.00017942453090400852 Test RE 0.03134749009119109\n",
      "110 Train Loss 0.002639134 Test MSE 0.00018320360505971926 Test RE 0.03167589332689649\n",
      "111 Train Loss 0.0024967508 Test MSE 0.00018383318700118258 Test RE 0.03173027398865352\n",
      "112 Train Loss 0.0024211968 Test MSE 0.0001714709977775484 Test RE 0.03064482894564502\n",
      "113 Train Loss 0.0023979363 Test MSE 0.00016620514913663235 Test RE 0.03017061071138133\n",
      "114 Train Loss 0.0023700052 Test MSE 0.00016828769476948276 Test RE 0.030359040725876564\n",
      "115 Train Loss 0.0023100658 Test MSE 0.00016314274625534066 Test RE 0.02989136504730658\n",
      "116 Train Loss 0.0022320796 Test MSE 0.00016967181846456043 Test RE 0.030483632778936894\n",
      "117 Train Loss 0.002126696 Test MSE 0.0001709499363089845 Test RE 0.03059823217736258\n",
      "118 Train Loss 0.002033861 Test MSE 0.00016019441288814092 Test RE 0.02962003358308561\n",
      "119 Train Loss 0.002004451 Test MSE 0.00017006697572616184 Test RE 0.030519109570492663\n",
      "120 Train Loss 0.001961036 Test MSE 0.00017014970103893502 Test RE 0.030526531340437115\n",
      "121 Train Loss 0.0019447455 Test MSE 0.00017444430866450932 Test RE 0.030909378057847072\n",
      "122 Train Loss 0.001930638 Test MSE 0.00017552194087423403 Test RE 0.03100470262961669\n",
      "123 Train Loss 0.0018777177 Test MSE 0.00018130187247808853 Test RE 0.03151105972015335\n",
      "124 Train Loss 0.0018142771 Test MSE 0.0001838668887339686 Test RE 0.031733182375942116\n",
      "125 Train Loss 0.0017519925 Test MSE 0.00016458340986738246 Test RE 0.03002305570000467\n",
      "126 Train Loss 0.0016724237 Test MSE 0.00015707584537406725 Test RE 0.029330304173834077\n",
      "127 Train Loss 0.0016502198 Test MSE 0.00015544247650149844 Test RE 0.02917740861091941\n",
      "128 Train Loss 0.0016333098 Test MSE 0.00015241495050219794 Test RE 0.02889186977788715\n",
      "129 Train Loss 0.0016160442 Test MSE 0.00015047661866624684 Test RE 0.028707566259647484\n",
      "130 Train Loss 0.0015940384 Test MSE 0.00015468754395741593 Test RE 0.02910646987725088\n",
      "131 Train Loss 0.0015657484 Test MSE 0.0001612037454643408 Test RE 0.029713200130154205\n",
      "132 Train Loss 0.0015246933 Test MSE 0.00015822298151576847 Test RE 0.029437209999048822\n",
      "133 Train Loss 0.001461548 Test MSE 0.00013953432853505932 Test RE 0.027644096316284467\n",
      "134 Train Loss 0.0014364782 Test MSE 0.0001431609289355856 Test RE 0.028001037159098376\n",
      "135 Train Loss 0.001421071 Test MSE 0.00015074849866135966 Test RE 0.02873348886049915\n",
      "136 Train Loss 0.0014162499 Test MSE 0.0001555239457627443 Test RE 0.029185053723754847\n",
      "137 Train Loss 0.0014116822 Test MSE 0.00015295972991790602 Test RE 0.02894345807777788\n",
      "138 Train Loss 0.0014017748 Test MSE 0.00016067597496388004 Test RE 0.029664520718991408\n",
      "139 Train Loss 0.0013769803 Test MSE 0.00014955727956328613 Test RE 0.02861973725797823\n",
      "140 Train Loss 0.0013267015 Test MSE 0.00014448314841729597 Test RE 0.02813004729923246\n",
      "141 Train Loss 0.0012822462 Test MSE 0.00016175348003148247 Test RE 0.029763820762606964\n",
      "142 Train Loss 0.0012556752 Test MSE 0.00015787072216117372 Test RE 0.029404423009208216\n",
      "143 Train Loss 0.0012183624 Test MSE 0.00014508299843071933 Test RE 0.02818838050960222\n",
      "144 Train Loss 0.0011850883 Test MSE 0.00013620553786348845 Test RE 0.0273123611718625\n",
      "145 Train Loss 0.0011703831 Test MSE 0.0001264616239544115 Test RE 0.02631729455333941\n",
      "146 Train Loss 0.0011539924 Test MSE 0.00012719486274265207 Test RE 0.02639347960465331\n",
      "147 Train Loss 0.0011491679 Test MSE 0.00012531281858724525 Test RE 0.026197485777477127\n",
      "148 Train Loss 0.0011400619 Test MSE 0.00012301372110075015 Test RE 0.025956052384439703\n",
      "149 Train Loss 0.0011222145 Test MSE 0.00012075830995452434 Test RE 0.02571700428349676\n",
      "150 Train Loss 0.0010982505 Test MSE 0.00012184443287002686 Test RE 0.025832397180771953\n",
      "151 Train Loss 0.0010737273 Test MSE 0.00011840259518516462 Test RE 0.02546492930202178\n",
      "152 Train Loss 0.0010420419 Test MSE 0.00012030150704022931 Test RE 0.02566831722734756\n",
      "153 Train Loss 0.001009296 Test MSE 0.0001113773800018682 Test RE 0.024697919046728592\n",
      "154 Train Loss 0.0009970347 Test MSE 0.00011340160336370411 Test RE 0.02492134408979777\n",
      "155 Train Loss 0.00097365037 Test MSE 0.00011000314053845983 Test RE 0.024545077412793354\n",
      "156 Train Loss 0.0009671466 Test MSE 0.00011211405884965311 Test RE 0.02477946364742546\n",
      "157 Train Loss 0.0009620245 Test MSE 0.00010972629719042056 Test RE 0.02451417183103946\n",
      "158 Train Loss 0.00095656037 Test MSE 0.00010814058112506587 Test RE 0.024336393197842993\n",
      "159 Train Loss 0.00095182913 Test MSE 0.00010384124605318439 Test RE 0.0238477170090948\n",
      "160 Train Loss 0.00094572053 Test MSE 0.00010337662893277939 Test RE 0.02379430625126481\n",
      "161 Train Loss 0.0009392305 Test MSE 0.000102529244791606 Test RE 0.023696583935572967\n",
      "162 Train Loss 0.0009248517 Test MSE 0.00010368985033638543 Test RE 0.02383032623581174\n",
      "163 Train Loss 0.00090527494 Test MSE 0.00011159966876616391 Test RE 0.02472255301344252\n",
      "164 Train Loss 0.0008865411 Test MSE 0.00012463136773726479 Test RE 0.026126157737939863\n",
      "165 Train Loss 0.00086380367 Test MSE 0.000124120227719098 Test RE 0.026072528201626553\n",
      "166 Train Loss 0.0008444478 Test MSE 0.00013277915435827895 Test RE 0.026966638497791563\n",
      "167 Train Loss 0.00082593114 Test MSE 0.00013406620446590752 Test RE 0.027097019332634364\n",
      "168 Train Loss 0.00081767153 Test MSE 0.00013889582537249937 Test RE 0.027580774688485767\n",
      "169 Train Loss 0.0008130779 Test MSE 0.0001332860993164431 Test RE 0.027018068174018202\n",
      "170 Train Loss 0.00080798747 Test MSE 0.0001324083550334566 Test RE 0.026928958629611595\n",
      "171 Train Loss 0.00080264226 Test MSE 0.00013259106476046936 Test RE 0.02694753180240713\n",
      "172 Train Loss 0.0007986022 Test MSE 0.00013255163746826737 Test RE 0.026943524944146834\n",
      "173 Train Loss 0.0007921535 Test MSE 0.00013391138585168685 Test RE 0.027081369099143413\n",
      "174 Train Loss 0.00078238506 Test MSE 0.00013192976684046925 Test RE 0.02688024739643895\n",
      "175 Train Loss 0.00077315094 Test MSE 0.00013122279159989575 Test RE 0.026808128733894956\n",
      "176 Train Loss 0.0007613882 Test MSE 0.00013398351550549548 Test RE 0.0270886616336683\n",
      "177 Train Loss 0.00075073226 Test MSE 0.000138126684133831 Test RE 0.0275043038499497\n",
      "178 Train Loss 0.0007411664 Test MSE 0.0001423578714350285 Test RE 0.02792239116917298\n",
      "179 Train Loss 0.0007272552 Test MSE 0.000151257152432805 Test RE 0.0287819241337748\n",
      "180 Train Loss 0.000720264 Test MSE 0.0001533706345381712 Test RE 0.02898230825145561\n",
      "181 Train Loss 0.0007138823 Test MSE 0.00015004661030704249 Test RE 0.028666518935372854\n",
      "182 Train Loss 0.0007089106 Test MSE 0.00015163357409626426 Test RE 0.02881771552427868\n",
      "183 Train Loss 0.00070455647 Test MSE 0.00015492268894898336 Test RE 0.029128584267918863\n",
      "184 Train Loss 0.00070211565 Test MSE 0.00015760672579527717 Test RE 0.029379827223913853\n",
      "185 Train Loss 0.0007001747 Test MSE 0.00015713045001993373 Test RE 0.02933540181218669\n",
      "186 Train Loss 0.0006960791 Test MSE 0.0001658552325409267 Test RE 0.030138834440017442\n",
      "187 Train Loss 0.0006873292 Test MSE 0.00016267937966975757 Test RE 0.029848885351112006\n",
      "188 Train Loss 0.0006799679 Test MSE 0.00016819873570953926 Test RE 0.030351015573682152\n",
      "189 Train Loss 0.0006743868 Test MSE 0.0001667376945954647 Test RE 0.0302189075660744\n",
      "190 Train Loss 0.0006691381 Test MSE 0.00016854344333024727 Test RE 0.030382100443217052\n",
      "191 Train Loss 0.00066377857 Test MSE 0.0001775290205520874 Test RE 0.03118146692039487\n",
      "192 Train Loss 0.0006576058 Test MSE 0.00017946648936165786 Test RE 0.03135115518492834\n",
      "193 Train Loss 0.0006509816 Test MSE 0.0001735418402781135 Test RE 0.03082932125357446\n",
      "194 Train Loss 0.00063983153 Test MSE 0.00018403637275721499 Test RE 0.03174780444476158\n",
      "195 Train Loss 0.00063153275 Test MSE 0.00018842185665322032 Test RE 0.03212384365001696\n",
      "196 Train Loss 0.00062523154 Test MSE 0.00017717333731583754 Test RE 0.031150214886981994\n",
      "197 Train Loss 0.00061954925 Test MSE 0.00016640573484583067 Test RE 0.03018881101554717\n",
      "198 Train Loss 0.00061716716 Test MSE 0.0001690638968421589 Test RE 0.03042897346998368\n",
      "199 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "200 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "201 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "202 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "203 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "204 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "205 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "206 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "207 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "208 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "209 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "210 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "211 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "212 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "213 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "214 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "215 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "216 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "217 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "218 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "219 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "220 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "221 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "222 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "223 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "224 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "225 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "226 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "227 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "228 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "229 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "230 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "231 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "232 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "233 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "234 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "235 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "236 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "237 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "238 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "239 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "240 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "241 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "242 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "243 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "244 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "245 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "246 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "247 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "248 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "249 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "250 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "251 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "252 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "253 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "254 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "255 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "256 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "257 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "258 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "259 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "260 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "261 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "262 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "263 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "264 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "265 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "266 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "267 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "268 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "269 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "270 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "271 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "272 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "273 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "274 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "275 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "276 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "277 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "278 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "279 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "280 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "281 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "282 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "283 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "284 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "285 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "286 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "287 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "288 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "289 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "290 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "291 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "292 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "293 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "294 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "295 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "296 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "297 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "298 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "299 Train Loss 0.0006161798 Test MSE 0.0001670290241720828 Test RE 0.030245295778447798\n",
      "Training time: 188.90\n",
      "KG_atanh_low\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 10372.547 Test MSE 2.643154441530206 Test RE 3.8047237909329907\n",
      "1 Train Loss 7333.598 Test MSE 1.782169774309953 Test RE 3.124182539771902\n",
      "2 Train Loss 2482.0723 Test MSE 8.006209076787803 Test RE 6.6217888413386\n",
      "3 Train Loss 1745.4269 Test MSE 9.071914029225328 Test RE 7.048737330824777\n",
      "4 Train Loss 753.5279 Test MSE 10.96646757365302 Test RE 7.749884738715729\n",
      "5 Train Loss 220.47656 Test MSE 13.126432690656653 Test RE 8.47881622119958\n",
      "6 Train Loss 65.414246 Test MSE 13.71761179716824 Test RE 8.66764505109765\n",
      "7 Train Loss 32.66145 Test MSE 14.102021633655239 Test RE 8.788253025263007\n",
      "8 Train Loss 25.010242 Test MSE 13.949733978419696 Test RE 8.740672071553528\n",
      "9 Train Loss 21.73913 Test MSE 13.659698534412984 Test RE 8.649329088294083\n",
      "10 Train Loss 19.019854 Test MSE 13.197324509969631 Test RE 8.50168112842829\n",
      "11 Train Loss 16.441244 Test MSE 12.204029127745036 Test RE 8.175484166956155\n",
      "12 Train Loss 15.091854 Test MSE 11.662458783912173 Test RE 7.992026679364519\n",
      "13 Train Loss 13.645375 Test MSE 11.003145128208637 Test RE 7.76283373746195\n",
      "14 Train Loss 12.51378 Test MSE 10.318537822905544 Test RE 7.517456855419906\n",
      "15 Train Loss 11.395198 Test MSE 9.821191646505728 Test RE 7.334051527906987\n",
      "16 Train Loss 10.541524 Test MSE 8.858503222460655 Test RE 6.96533546499876\n",
      "17 Train Loss 9.693073 Test MSE 8.244364093252562 Test RE 6.719553957061492\n",
      "18 Train Loss 9.074134 Test MSE 7.730570350631302 Test RE 6.506802613127689\n",
      "19 Train Loss 8.049908 Test MSE 6.9156011409145925 Test RE 6.154274066883784\n",
      "20 Train Loss 7.2693963 Test MSE 6.108750816213041 Test RE 5.7841303167363485\n",
      "21 Train Loss 6.3553576 Test MSE 5.095836879760358 Test RE 5.282866339224631\n",
      "22 Train Loss 5.3351235 Test MSE 4.555170134378997 Test RE 4.9947547116648865\n",
      "23 Train Loss 4.5228977 Test MSE 3.8029485389337125 Test RE 4.563752547206874\n",
      "24 Train Loss 3.4697986 Test MSE 2.7866176743311244 Test RE 3.906614500186002\n",
      "25 Train Loss 2.6746607 Test MSE 2.0989692877063155 Test RE 3.390509035152236\n",
      "26 Train Loss 1.9621682 Test MSE 1.5223854700416444 Test RE 2.8875145360673917\n",
      "27 Train Loss 1.372744 Test MSE 1.0002471776343183 Test RE 2.3405371097133316\n",
      "28 Train Loss 0.992738 Test MSE 0.7723976477109394 Test RE 2.056753927477555\n",
      "29 Train Loss 0.7595029 Test MSE 0.5028658053906748 Test RE 1.6595407327458396\n",
      "30 Train Loss 0.57761973 Test MSE 0.29592829921051167 Test RE 1.273078292895962\n",
      "31 Train Loss 0.46375215 Test MSE 0.2748557535182802 Test RE 1.2269144467587814\n",
      "32 Train Loss 0.3805357 Test MSE 0.19215762868599048 Test RE 1.025866101665111\n",
      "33 Train Loss 0.3065493 Test MSE 0.13027308729443657 Test RE 0.8446741759065108\n",
      "34 Train Loss 0.24767672 Test MSE 0.12677855548072234 Test RE 0.8332681144661312\n",
      "35 Train Loss 0.20676701 Test MSE 0.11379810687172537 Test RE 0.7894586410228276\n",
      "36 Train Loss 0.1804677 Test MSE 0.0943968491436136 Test RE 0.7190194080563699\n",
      "37 Train Loss 0.14997265 Test MSE 0.07913472536463713 Test RE 0.6583326792999552\n",
      "38 Train Loss 0.12912829 Test MSE 0.08266552784526235 Test RE 0.6728590307320607\n",
      "39 Train Loss 0.10970945 Test MSE 0.0695460949624666 Test RE 0.6171606654625004\n",
      "40 Train Loss 0.09881684 Test MSE 0.06173154283275129 Test RE 0.5814540899161663\n",
      "41 Train Loss 0.08691564 Test MSE 0.050300216371870314 Test RE 0.5248640057682064\n",
      "42 Train Loss 0.07690336 Test MSE 0.051900951854514585 Test RE 0.5331501373722378\n",
      "43 Train Loss 0.06956382 Test MSE 0.0438850633034952 Test RE 0.4902529646633946\n",
      "44 Train Loss 0.060661625 Test MSE 0.04322793054605487 Test RE 0.48656860853318834\n",
      "45 Train Loss 0.053370982 Test MSE 0.034865252556306923 Test RE 0.4369766911234075\n",
      "46 Train Loss 0.04794328 Test MSE 0.02710715841598754 Test RE 0.3853043045986288\n",
      "47 Train Loss 0.043728862 Test MSE 0.02767074633042848 Test RE 0.389289150911969\n",
      "48 Train Loss 0.04045246 Test MSE 0.028212613105267362 Test RE 0.3930823290606978\n",
      "49 Train Loss 0.038217083 Test MSE 0.026687983753325612 Test RE 0.38231359905270496\n",
      "50 Train Loss 0.03540474 Test MSE 0.025432244319760666 Test RE 0.37321080401364354\n",
      "51 Train Loss 0.03326943 Test MSE 0.026255825630303476 Test RE 0.3792055664144349\n",
      "52 Train Loss 0.03106806 Test MSE 0.02401663676298161 Test RE 0.3626752832289991\n",
      "53 Train Loss 0.028097453 Test MSE 0.020101162979225085 Test RE 0.33179700114295607\n",
      "54 Train Loss 0.027151909 Test MSE 0.018880870921899627 Test RE 0.3215680378392079\n",
      "55 Train Loss 0.024965258 Test MSE 0.018113150158836407 Test RE 0.31496250636766215\n",
      "56 Train Loss 0.023439908 Test MSE 0.01638772171966684 Test RE 0.2995857516025065\n",
      "57 Train Loss 0.022314027 Test MSE 0.013491832858078914 Test RE 0.2718299718897787\n",
      "58 Train Loss 0.020643499 Test MSE 0.01198187379481667 Test RE 0.2561676206549922\n",
      "59 Train Loss 0.018757276 Test MSE 0.010850683640974934 Test RE 0.24377570146693192\n",
      "60 Train Loss 0.017778749 Test MSE 0.009026443310465745 Test RE 0.2223413270961165\n",
      "61 Train Loss 0.016767433 Test MSE 0.007684334534034905 Test RE 0.20514691751206154\n",
      "62 Train Loss 0.015946718 Test MSE 0.00678916939528359 Test RE 0.19282803980262933\n",
      "63 Train Loss 0.014632917 Test MSE 0.006547541981854704 Test RE 0.18936556584011385\n",
      "64 Train Loss 0.013657344 Test MSE 0.006417303253916159 Test RE 0.18747274799409386\n",
      "65 Train Loss 0.012655523 Test MSE 0.007416011000849546 Test RE 0.20153340693186234\n",
      "66 Train Loss 0.011211986 Test MSE 0.007577695910456435 Test RE 0.20371849104138265\n",
      "67 Train Loss 0.010889209 Test MSE 0.006870539787892956 Test RE 0.19398015121194886\n",
      "68 Train Loss 0.010579608 Test MSE 0.006031341864170921 Test RE 0.18174766367425976\n",
      "69 Train Loss 0.010112137 Test MSE 0.005070128582145251 Test RE 0.16663696641553158\n",
      "70 Train Loss 0.009599365 Test MSE 0.005112798590162507 Test RE 0.16733670242676638\n",
      "71 Train Loss 0.009156756 Test MSE 0.005193430752396897 Test RE 0.16865104505573805\n",
      "72 Train Loss 0.00895712 Test MSE 0.00488864391998342 Test RE 0.16362741395076094\n",
      "73 Train Loss 0.008746218 Test MSE 0.0046394237087527485 Test RE 0.15940204281942502\n",
      "74 Train Loss 0.008107483 Test MSE 0.004521474969158052 Test RE 0.15736274746234113\n",
      "75 Train Loss 0.0077968864 Test MSE 0.004264862286912679 Test RE 0.15283202595149695\n",
      "76 Train Loss 0.007664987 Test MSE 0.004037333172863252 Test RE 0.1486993804748475\n",
      "77 Train Loss 0.0074106436 Test MSE 0.004050837669342424 Test RE 0.14894786551957503\n",
      "78 Train Loss 0.007124229 Test MSE 0.0034192724819300815 Test RE 0.13684493246811158\n",
      "79 Train Loss 0.006935103 Test MSE 0.003610864380790971 Test RE 0.14062659220126525\n",
      "80 Train Loss 0.0066841943 Test MSE 0.0038381024839054473 Test RE 0.14498402339520622\n",
      "81 Train Loss 0.0063839247 Test MSE 0.003341900932866116 Test RE 0.13528780476971505\n",
      "82 Train Loss 0.006300324 Test MSE 0.0032585058108091742 Test RE 0.1335891276699148\n",
      "83 Train Loss 0.006168041 Test MSE 0.0030623926373904153 Test RE 0.12950671875615394\n",
      "84 Train Loss 0.005873565 Test MSE 0.002984383226765638 Test RE 0.12784659309251853\n",
      "85 Train Loss 0.0056449305 Test MSE 0.0030310488127799073 Test RE 0.12884225856031986\n",
      "86 Train Loss 0.0055487305 Test MSE 0.0030009075876699857 Test RE 0.12820004418088035\n",
      "87 Train Loss 0.0053770817 Test MSE 0.0031639685896462906 Test RE 0.1316369907683802\n",
      "88 Train Loss 0.005255809 Test MSE 0.003422537715837063 Test RE 0.13691025690357594\n",
      "89 Train Loss 0.0052178856 Test MSE 0.003446405428663501 Test RE 0.13738681227023047\n",
      "90 Train Loss 0.0050984994 Test MSE 0.003443883445387767 Test RE 0.13733653515387673\n",
      "91 Train Loss 0.004767646 Test MSE 0.002982989741541758 Test RE 0.12781674217765734\n",
      "92 Train Loss 0.0045424295 Test MSE 0.0027305030905405976 Test RE 0.12228781923100682\n",
      "93 Train Loss 0.004490002 Test MSE 0.0025249077055872517 Test RE 0.11759385232499886\n",
      "94 Train Loss 0.0043799207 Test MSE 0.002311331933341433 Test RE 0.11251049199632\n",
      "95 Train Loss 0.0041324957 Test MSE 0.002098382338710082 Test RE 0.10720231778525005\n",
      "96 Train Loss 0.0039762454 Test MSE 0.001955932366161966 Test RE 0.10349962605832061\n",
      "97 Train Loss 0.0039080074 Test MSE 0.0018123955136484012 Test RE 0.09962959233543946\n",
      "98 Train Loss 0.0038702458 Test MSE 0.0018543555360742007 Test RE 0.10077629012306591\n",
      "99 Train Loss 0.0038198563 Test MSE 0.001783065196645088 Test RE 0.09882014245713835\n",
      "100 Train Loss 0.0037162069 Test MSE 0.0016573073423590127 Test RE 0.09527158516772996\n",
      "101 Train Loss 0.0035211055 Test MSE 0.0016278206682970055 Test RE 0.09442024939902804\n",
      "102 Train Loss 0.00342978 Test MSE 0.0016372824462527477 Test RE 0.09469426268671828\n",
      "103 Train Loss 0.0032949913 Test MSE 0.0015550547247959313 Test RE 0.09228576201755012\n",
      "104 Train Loss 0.003204769 Test MSE 0.0014022035730898315 Test RE 0.0876329433631668\n",
      "105 Train Loss 0.0031103492 Test MSE 0.0013442070294799665 Test RE 0.08580151280141955\n",
      "106 Train Loss 0.003049893 Test MSE 0.0012193987321118026 Test RE 0.08172119969566378\n",
      "107 Train Loss 0.003002044 Test MSE 0.0011327943529914214 Test RE 0.07876574801554374\n",
      "108 Train Loss 0.0029474904 Test MSE 0.001073260444184104 Test RE 0.07666805147124173\n",
      "109 Train Loss 0.0028845288 Test MSE 0.0009389887190327922 Test RE 0.07171203575528787\n",
      "110 Train Loss 0.002781742 Test MSE 0.0007346026457044671 Test RE 0.06342903557786986\n",
      "111 Train Loss 0.0026699316 Test MSE 0.0006721918189461472 Test RE 0.06067481702049442\n",
      "112 Train Loss 0.0025833403 Test MSE 0.000628859766622908 Test RE 0.058686575634060205\n",
      "113 Train Loss 0.0025238383 Test MSE 0.0006919491267529098 Test RE 0.0615600475804296\n",
      "114 Train Loss 0.0024507614 Test MSE 0.0006645652298293066 Test RE 0.060329631363949976\n",
      "115 Train Loss 0.0024299605 Test MSE 0.0006196794134087931 Test RE 0.05825663538411918\n",
      "116 Train Loss 0.0023822768 Test MSE 0.0005973582696676599 Test RE 0.05719779728244874\n",
      "117 Train Loss 0.0023406823 Test MSE 0.0005561423751532169 Test RE 0.05518929644480027\n",
      "118 Train Loss 0.0022917725 Test MSE 0.0006149032649615637 Test RE 0.058031696049772215\n",
      "119 Train Loss 0.0022369018 Test MSE 0.0006185828670863122 Test RE 0.05820506889429519\n",
      "120 Train Loss 0.0021928013 Test MSE 0.0005896582645915269 Test RE 0.05682795907295689\n",
      "121 Train Loss 0.0021416768 Test MSE 0.0006107494098465516 Test RE 0.05783535318402527\n",
      "122 Train Loss 0.0021187647 Test MSE 0.0006156577416775443 Test RE 0.0580672871286852\n",
      "123 Train Loss 0.0020741308 Test MSE 0.0006427803512252586 Test RE 0.05933257000814259\n",
      "124 Train Loss 0.0020259155 Test MSE 0.0006611283781198914 Test RE 0.06017342941659501\n",
      "125 Train Loss 0.0019382992 Test MSE 0.0006311640226801582 Test RE 0.05879399644168409\n",
      "126 Train Loss 0.0018363029 Test MSE 0.0005175939362531175 Test RE 0.053242256573158765\n",
      "127 Train Loss 0.0017503449 Test MSE 0.00042643264517948874 Test RE 0.04832669398580506\n",
      "128 Train Loss 0.0017095082 Test MSE 0.00038581712072267344 Test RE 0.045967682806076625\n",
      "129 Train Loss 0.001664905 Test MSE 0.00035624944065251854 Test RE 0.04417117576292196\n",
      "130 Train Loss 0.0016449474 Test MSE 0.00034204644796961527 Test RE 0.04328170956438835\n",
      "131 Train Loss 0.0016308562 Test MSE 0.0003351213371589737 Test RE 0.04284132597556702\n",
      "132 Train Loss 0.0016046689 Test MSE 0.00032863272514723233 Test RE 0.042424552315086114\n",
      "133 Train Loss 0.0015793925 Test MSE 0.0003449376322130703 Test RE 0.04346424629159261\n",
      "134 Train Loss 0.0015528962 Test MSE 0.0003310463789941754 Test RE 0.04258006156091995\n",
      "135 Train Loss 0.0015236965 Test MSE 0.00031460105410685855 Test RE 0.04150896940699475\n",
      "136 Train Loss 0.0014911307 Test MSE 0.0002807639915481756 Test RE 0.0392132256098988\n",
      "137 Train Loss 0.0014566629 Test MSE 0.00026385610508171766 Test RE 0.038014163446953166\n",
      "138 Train Loss 0.0014204562 Test MSE 0.00025838358925893835 Test RE 0.03761788092861179\n",
      "139 Train Loss 0.0013919539 Test MSE 0.0002748354982446491 Test RE 0.038797011822927156\n",
      "140 Train Loss 0.001324915 Test MSE 0.00025965938302612446 Test RE 0.037710637519460445\n",
      "141 Train Loss 0.001280533 Test MSE 0.00024119402854937683 Test RE 0.03634503904394397\n",
      "142 Train Loss 0.0012535584 Test MSE 0.00023598276308250518 Test RE 0.03595025746295127\n",
      "143 Train Loss 0.0012376247 Test MSE 0.00022415275416593156 Test RE 0.035037563975051596\n",
      "144 Train Loss 0.0012103133 Test MSE 0.0002184373820509197 Test RE 0.03458799165332732\n",
      "145 Train Loss 0.0011759576 Test MSE 0.0002201680396287428 Test RE 0.03472473992996077\n",
      "146 Train Loss 0.001154615 Test MSE 0.00019159771049106716 Test RE 0.03239343638523011\n",
      "147 Train Loss 0.0011257465 Test MSE 0.00017279367473572793 Test RE 0.030762794503565866\n",
      "148 Train Loss 0.0011075845 Test MSE 0.0001594551509774536 Test RE 0.029551609587831675\n",
      "149 Train Loss 0.0010917409 Test MSE 0.000163634949557092 Test RE 0.029936422362385036\n",
      "150 Train Loss 0.0010751105 Test MSE 0.00014709183411196607 Test RE 0.028382859389434145\n",
      "151 Train Loss 0.0010630819 Test MSE 0.0001415943964627645 Test RE 0.027847415665374436\n",
      "152 Train Loss 0.0010473105 Test MSE 0.00014668361405891547 Test RE 0.028343446928153188\n",
      "153 Train Loss 0.0010302252 Test MSE 0.00014348406324124125 Test RE 0.028032620482201582\n",
      "154 Train Loss 0.0010204555 Test MSE 0.00014411801935404077 Test RE 0.02809448053844127\n",
      "155 Train Loss 0.0010138375 Test MSE 0.00014222883742515368 Test RE 0.027909733790754777\n",
      "156 Train Loss 0.0010064987 Test MSE 0.00013613478982953649 Test RE 0.027305266941812022\n",
      "157 Train Loss 0.0009954891 Test MSE 0.0001321048065089674 Test RE 0.02689807335830477\n",
      "158 Train Loss 0.0009707995 Test MSE 0.00012148329003952746 Test RE 0.025794085589800928\n",
      "159 Train Loss 0.0009518264 Test MSE 0.0001182544697177921 Test RE 0.025448995592917103\n",
      "160 Train Loss 0.0009363725 Test MSE 0.00011331645529855565 Test RE 0.024911986185474865\n",
      "161 Train Loss 0.00092080707 Test MSE 0.0001072242452358149 Test RE 0.02423306587960099\n",
      "162 Train Loss 0.00090575643 Test MSE 0.00010446527759418775 Test RE 0.023919265826347395\n",
      "163 Train Loss 0.00089806167 Test MSE 0.00010422139090370021 Test RE 0.023891328316871602\n",
      "164 Train Loss 0.0008907387 Test MSE 0.00011106604817016127 Test RE 0.024663375994473033\n",
      "165 Train Loss 0.0008819401 Test MSE 0.00011606169282223721 Test RE 0.02521194287227769\n",
      "166 Train Loss 0.00086979487 Test MSE 0.00012510248590146447 Test RE 0.026175490814361217\n",
      "167 Train Loss 0.00086531654 Test MSE 0.0001233221988375922 Test RE 0.025988576605588495\n",
      "168 Train Loss 0.0008592379 Test MSE 0.00012678351345755173 Test RE 0.026350766672646516\n",
      "169 Train Loss 0.0008473734 Test MSE 0.0001304593238067177 Test RE 0.026730028734871375\n",
      "170 Train Loss 0.00083850365 Test MSE 0.00012765054618875106 Test RE 0.026440715470954994\n",
      "171 Train Loss 0.00083087425 Test MSE 0.00012363042298458576 Test RE 0.02602103348705635\n",
      "172 Train Loss 0.0008224972 Test MSE 0.00012258423278377906 Test RE 0.025910701473530938\n",
      "173 Train Loss 0.0008132423 Test MSE 0.00012364560745604833 Test RE 0.026022631408908627\n",
      "174 Train Loss 0.000796318 Test MSE 0.0001221370363847033 Test RE 0.025863396207715852\n",
      "175 Train Loss 0.0007806049 Test MSE 0.00012893057626129755 Test RE 0.02657295340020827\n",
      "176 Train Loss 0.00076935167 Test MSE 0.00012808028407000502 Test RE 0.026485184650160132\n",
      "177 Train Loss 0.00076430535 Test MSE 0.0001244951748644384 Test RE 0.026111878952658783\n",
      "178 Train Loss 0.00075833435 Test MSE 0.00011901225912681026 Test RE 0.02553040555075097\n",
      "179 Train Loss 0.00075233664 Test MSE 0.0001132950604106477 Test RE 0.024909634301492383\n",
      "180 Train Loss 0.0007497909 Test MSE 0.000111566683117483 Test RE 0.024718899106020927\n",
      "181 Train Loss 0.0007433943 Test MSE 0.00011244573182758121 Test RE 0.0248160897812031\n",
      "182 Train Loss 0.0007359715 Test MSE 0.00011570065478269411 Test RE 0.02517269839764415\n",
      "183 Train Loss 0.000727627 Test MSE 0.00012469441601681665 Test RE 0.026132765227922045\n",
      "184 Train Loss 0.0007181729 Test MSE 0.00012039812470207685 Test RE 0.025678622647089217\n",
      "185 Train Loss 0.0007112311 Test MSE 0.0001175830575828264 Test RE 0.025376647008816183\n",
      "186 Train Loss 0.0007035926 Test MSE 0.0001175478301104147 Test RE 0.025372845346751625\n",
      "187 Train Loss 0.0006987679 Test MSE 0.00011659948879050693 Test RE 0.0252702877499544\n",
      "188 Train Loss 0.0006905184 Test MSE 0.00010669495579800116 Test RE 0.02417318122594274\n",
      "189 Train Loss 0.00068299496 Test MSE 9.327382618576778e-05 Test RE 0.022601734041652697\n",
      "190 Train Loss 0.0006762843 Test MSE 7.983762977083341e-05 Test RE 0.020910560861227973\n",
      "191 Train Loss 0.0006723148 Test MSE 8.143091652965543e-05 Test RE 0.021118181860324024\n",
      "192 Train Loss 0.0006684421 Test MSE 7.913046250247871e-05 Test RE 0.020817746514940696\n",
      "193 Train Loss 0.00066229876 Test MSE 7.832994246593113e-05 Test RE 0.020712177907245714\n",
      "194 Train Loss 0.000657472 Test MSE 7.137521860028037e-05 Test RE 0.019771316561832255\n",
      "195 Train Loss 0.000653978 Test MSE 6.979694212995851e-05 Test RE 0.0195514990930279\n",
      "196 Train Loss 0.0006480408 Test MSE 7.973673415352218e-05 Test RE 0.020897343717011435\n",
      "197 Train Loss 0.00064127403 Test MSE 8.185292725138917e-05 Test RE 0.02117283298528687\n",
      "198 Train Loss 0.0006309502 Test MSE 7.862742408125207e-05 Test RE 0.020751471011500308\n",
      "199 Train Loss 0.0006207799 Test MSE 7.312241402314827e-05 Test RE 0.020011844717391095\n",
      "200 Train Loss 0.00061178353 Test MSE 7.062891759858184e-05 Test RE 0.01966768026339118\n",
      "201 Train Loss 0.0006074372 Test MSE 6.766071564832515e-05 Test RE 0.019249974455808158\n",
      "202 Train Loss 0.0006047282 Test MSE 6.321244008563336e-05 Test RE 0.018606433775941945\n",
      "203 Train Loss 0.0006019388 Test MSE 5.952788072801374e-05 Test RE 0.01805602197900128\n",
      "204 Train Loss 0.00059866626 Test MSE 5.6210670330426196e-05 Test RE 0.017545722091963697\n",
      "205 Train Loss 0.00059489196 Test MSE 5.601011400950179e-05 Test RE 0.017514393076731145\n",
      "206 Train Loss 0.000589843 Test MSE 5.499274397140371e-05 Test RE 0.01735459803864966\n",
      "207 Train Loss 0.00058413186 Test MSE 5.2386929262581234e-05 Test RE 0.016938437080229036\n",
      "208 Train Loss 0.0005772866 Test MSE 5.231080958806733e-05 Test RE 0.016926126595143736\n",
      "209 Train Loss 0.00057016825 Test MSE 4.685266563292687e-05 Test RE 0.01601876448966901\n",
      "210 Train Loss 0.0005676932 Test MSE 4.681127154061778e-05 Test RE 0.016011686677455134\n",
      "211 Train Loss 0.00056411413 Test MSE 4.6031159635405345e-05 Test RE 0.01587770841148423\n",
      "212 Train Loss 0.00056042976 Test MSE 4.617470798833333e-05 Test RE 0.01590244648821104\n",
      "213 Train Loss 0.00055837707 Test MSE 4.420381948382137e-05 Test RE 0.015559361186517401\n",
      "214 Train Loss 0.0005565187 Test MSE 4.166589094947387e-05 Test RE 0.01510609461345863\n",
      "215 Train Loss 0.00055427366 Test MSE 4.520610833304514e-05 Test RE 0.015734770930655832\n",
      "216 Train Loss 0.00054620544 Test MSE 4.191057343930583e-05 Test RE 0.015150384872995255\n",
      "217 Train Loss 0.0005401581 Test MSE 4.187452597824903e-05 Test RE 0.015143868016421702\n",
      "218 Train Loss 0.00053273793 Test MSE 4.019079967739346e-05 Test RE 0.014836285696131444\n",
      "219 Train Loss 0.0005187861 Test MSE 3.309857676353696e-05 Test RE 0.01346376503305216\n",
      "220 Train Loss 0.000508502 Test MSE 3.0020650101356625e-05 Test RE 0.012822476458667492\n",
      "221 Train Loss 0.0005024434 Test MSE 2.7280988994910343e-05 Test RE 0.012223397054154582\n",
      "222 Train Loss 0.00049665285 Test MSE 2.5740919518161687e-05 Test RE 0.01187336701542097\n",
      "223 Train Loss 0.0004918591 Test MSE 2.3355582338035573e-05 Test RE 0.011309859613685849\n",
      "224 Train Loss 0.0004895977 Test MSE 2.217262779051821e-05 Test RE 0.011019717149834655\n",
      "225 Train Loss 0.000489028 Test MSE 2.1943492240040036e-05 Test RE 0.010962629501738194\n",
      "226 Train Loss 0.0004872093 Test MSE 2.1866898077073727e-05 Test RE 0.010943480146957346\n",
      "227 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "228 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "229 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "230 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "231 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "232 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "233 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "234 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "235 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "236 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "237 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "238 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "239 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "240 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "241 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "242 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "243 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "244 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "245 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "246 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "247 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "248 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "249 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "250 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "251 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "252 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "253 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "254 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "255 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "256 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "257 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "258 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "259 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "260 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "261 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "262 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "263 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "264 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "265 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "266 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "267 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "268 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "269 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "270 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "271 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "272 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "273 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "274 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "275 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "276 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "277 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "278 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "279 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "280 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "281 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "282 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "283 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "284 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "285 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "286 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "287 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "288 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "289 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "290 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "291 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "292 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "293 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "294 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "295 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "296 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "297 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "298 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "299 Train Loss 0.0004871536 Test MSE 2.1847341142999997e-05 Test RE 0.010938585333035867\n",
      "Training time: 209.14\n",
      "KG_atanh_low\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 10699.666 Test MSE 6.55527413506974 Test RE 5.991799785970951\n",
      "1 Train Loss 4738.262 Test MSE 6.464638230345339 Test RE 5.950233067436903\n",
      "2 Train Loss 1617.204 Test MSE 7.457524639515459 Test RE 6.3908586555159355\n",
      "3 Train Loss 940.65784 Test MSE 8.823343582829448 Test RE 6.951498919223143\n",
      "4 Train Loss 503.7065 Test MSE 11.336135239952434 Test RE 7.8794222273101155\n",
      "5 Train Loss 276.9686 Test MSE 12.61986201237504 Test RE 8.313600806433442\n",
      "6 Train Loss 134.36154 Test MSE 14.4227016317631 Test RE 8.887613779638274\n",
      "7 Train Loss 88.15967 Test MSE 14.863000748871055 Test RE 9.022255338306074\n",
      "8 Train Loss 63.798164 Test MSE 15.454657769423804 Test RE 9.20007907733116\n",
      "9 Train Loss 51.78961 Test MSE 15.605170673330703 Test RE 9.24477031165521\n",
      "10 Train Loss 43.43371 Test MSE 15.547594601729529 Test RE 9.227700026342234\n",
      "11 Train Loss 39.24524 Test MSE 15.446054983950777 Test RE 9.197518123700908\n",
      "12 Train Loss 35.292557 Test MSE 15.295462707681816 Test RE 9.152572416883455\n",
      "13 Train Loss 32.699554 Test MSE 15.25770362172377 Test RE 9.14126820446845\n",
      "14 Train Loss 31.12477 Test MSE 15.30272612026554 Test RE 9.154745316799557\n",
      "15 Train Loss 29.612421 Test MSE 15.286142976794695 Test RE 9.149783599344053\n",
      "16 Train Loss 28.188135 Test MSE 15.260315627804552 Test RE 9.142050629757403\n",
      "17 Train Loss 27.012611 Test MSE 15.239363297938294 Test RE 9.135772481302544\n",
      "18 Train Loss 26.21506 Test MSE 15.26069417307408 Test RE 9.142164017273203\n",
      "19 Train Loss 24.825254 Test MSE 15.017817592404647 Test RE 9.069122676482229\n",
      "20 Train Loss 23.987564 Test MSE 14.908236106327193 Test RE 9.035974468548853\n",
      "21 Train Loss 23.173275 Test MSE 14.803882988036456 Test RE 9.00429439702011\n",
      "22 Train Loss 22.358809 Test MSE 14.71009557798614 Test RE 8.97572651270271\n",
      "23 Train Loss 21.686232 Test MSE 14.471934839885183 Test RE 8.902770196529865\n",
      "24 Train Loss 20.936739 Test MSE 14.343882961763994 Test RE 8.863295534892092\n",
      "25 Train Loss 20.02907 Test MSE 13.977843528306291 Test RE 8.749474128615873\n",
      "26 Train Loss 19.098375 Test MSE 13.721026405137433 Test RE 8.668723765407568\n",
      "27 Train Loss 18.30884 Test MSE 13.409576479698364 Test RE 8.569774510211827\n",
      "28 Train Loss 17.504599 Test MSE 13.268428180427355 Test RE 8.524552760350213\n",
      "29 Train Loss 16.651133 Test MSE 13.044942791236197 Test RE 8.452456676768053\n",
      "30 Train Loss 15.827687 Test MSE 12.657088007062894 Test RE 8.325853482732787\n",
      "31 Train Loss 14.972282 Test MSE 12.158191243504985 Test RE 8.160116314290454\n",
      "32 Train Loss 14.366551 Test MSE 11.854321302473183 Test RE 8.057498089036327\n",
      "33 Train Loss 13.849936 Test MSE 11.495552639443183 Test RE 7.934632033662262\n",
      "34 Train Loss 13.179905 Test MSE 11.31261109659962 Test RE 7.871242503155741\n",
      "35 Train Loss 12.462265 Test MSE 11.10534081236683 Test RE 7.798800477899274\n",
      "36 Train Loss 11.777282 Test MSE 10.624094037130538 Test RE 7.627949638991144\n",
      "37 Train Loss 10.775412 Test MSE 10.268141509933962 Test RE 7.4990765465164575\n",
      "38 Train Loss 9.663307 Test MSE 9.697766002489901 Test RE 7.287821290040817\n",
      "39 Train Loss 8.685811 Test MSE 8.897714780547478 Test RE 6.980734233719877\n",
      "40 Train Loss 8.145052 Test MSE 8.541858638644287 Test RE 6.839715759920016\n",
      "41 Train Loss 7.315174 Test MSE 7.565846709007747 Test RE 6.43710558845625\n",
      "42 Train Loss 6.8544664 Test MSE 7.176932780684815 Test RE 6.269476853906687\n",
      "43 Train Loss 6.219342 Test MSE 6.727897686136647 Test RE 6.070179772814531\n",
      "44 Train Loss 5.4209657 Test MSE 5.700218043883804 Test RE 5.587372144499309\n",
      "45 Train Loss 4.290869 Test MSE 5.497877480092578 Test RE 5.487308696308169\n",
      "46 Train Loss 3.7602308 Test MSE 5.479056799880563 Test RE 5.477908394241873\n",
      "47 Train Loss 3.4433515 Test MSE 5.074152520509913 Test RE 5.271614242504072\n",
      "48 Train Loss 2.9393094 Test MSE 4.371818505825143 Test RE 4.893199538385492\n",
      "49 Train Loss 2.5885303 Test MSE 4.085543874187961 Test RE 4.73027950603827\n",
      "50 Train Loss 2.1742184 Test MSE 3.642660641793306 Test RE 4.466539928382957\n",
      "51 Train Loss 1.739755 Test MSE 2.790820723447887 Test RE 3.9095595589922976\n",
      "52 Train Loss 1.4921957 Test MSE 2.1487432093277437 Test RE 3.430473925253169\n",
      "53 Train Loss 1.2575647 Test MSE 1.9517190589897915 Test RE 3.269418498916555\n",
      "54 Train Loss 1.0806562 Test MSE 1.6896503683865174 Test RE 3.0420075507820385\n",
      "55 Train Loss 0.95023996 Test MSE 1.4198124517513881 Test RE 2.7885430548636547\n",
      "56 Train Loss 0.83781534 Test MSE 1.129298876032476 Test RE 2.486945751570975\n",
      "57 Train Loss 0.7735323 Test MSE 1.0139435863781072 Test RE 2.356507141647902\n",
      "58 Train Loss 0.6874023 Test MSE 0.915043844331102 Test RE 2.2386325591096243\n",
      "59 Train Loss 0.6131307 Test MSE 0.8415504930645595 Test RE 2.146851245748187\n",
      "60 Train Loss 0.5474183 Test MSE 0.7248218107159968 Test RE 1.9924043932556466\n",
      "61 Train Loss 0.49451792 Test MSE 0.7071563219849749 Test RE 1.96797500496095\n",
      "62 Train Loss 0.44024596 Test MSE 0.6918678127241558 Test RE 1.9465852461852242\n",
      "63 Train Loss 0.38130784 Test MSE 0.5540712999862384 Test RE 1.7419861250783915\n",
      "64 Train Loss 0.3578432 Test MSE 0.5162738909259557 Test RE 1.6815196440283964\n",
      "65 Train Loss 0.325942 Test MSE 0.42672858542125924 Test RE 1.528754442460929\n",
      "66 Train Loss 0.2764528 Test MSE 0.3361758843849455 Test RE 1.3568915629673297\n",
      "67 Train Loss 0.2488164 Test MSE 0.2834599020307754 Test RE 1.2459702717343222\n",
      "68 Train Loss 0.20635054 Test MSE 0.24147417424530399 Test RE 1.1499983277864703\n",
      "69 Train Loss 0.19186205 Test MSE 0.20021590893193073 Test RE 1.047155445630283\n",
      "70 Train Loss 0.1721336 Test MSE 0.21978227945934173 Test RE 1.097130278157332\n",
      "71 Train Loss 0.1501601 Test MSE 0.18415155291661625 Test RE 1.004267843346105\n",
      "72 Train Loss 0.14011718 Test MSE 0.16093919709277632 Test RE 0.9388425821054793\n",
      "73 Train Loss 0.12802303 Test MSE 0.1219554160328755 Test RE 0.8172640774422714\n",
      "74 Train Loss 0.11453172 Test MSE 0.09743604172431339 Test RE 0.7305024559964991\n",
      "75 Train Loss 0.10816709 Test MSE 0.07375270648496586 Test RE 0.6355516420250122\n",
      "76 Train Loss 0.096225135 Test MSE 0.05970518218663156 Test RE 0.5718312402128216\n",
      "77 Train Loss 0.09055665 Test MSE 0.05529361917469564 Test RE 0.5502998223064194\n",
      "78 Train Loss 0.08281538 Test MSE 0.062367673413642424 Test RE 0.5844422925715664\n",
      "79 Train Loss 0.07397751 Test MSE 0.0490051226707214 Test RE 0.518063033689307\n",
      "80 Train Loss 0.0660944 Test MSE 0.028593297810497416 Test RE 0.39572545568018813\n",
      "81 Train Loss 0.061536066 Test MSE 0.022444689163114994 Test RE 0.350605449141523\n",
      "82 Train Loss 0.05595354 Test MSE 0.02035172995006557 Test RE 0.3338585706375324\n",
      "83 Train Loss 0.05047568 Test MSE 0.025088329716581117 Test RE 0.37067879142397425\n",
      "84 Train Loss 0.046681296 Test MSE 0.019861592450632164 Test RE 0.3298138560223733\n",
      "85 Train Loss 0.041433096 Test MSE 0.013246602123496142 Test RE 0.2693482201230053\n",
      "86 Train Loss 0.038709383 Test MSE 0.013524964057239007 Test RE 0.2721635266737759\n",
      "87 Train Loss 0.034421634 Test MSE 0.010964144741143662 Test RE 0.24504691768449646\n",
      "88 Train Loss 0.03243843 Test MSE 0.01053752492002695 Test RE 0.2402321739429294\n",
      "89 Train Loss 0.02994734 Test MSE 0.007499157460713061 Test RE 0.2026600289503381\n",
      "90 Train Loss 0.028225308 Test MSE 0.006268459930438955 Test RE 0.1852858657481434\n",
      "91 Train Loss 0.026382564 Test MSE 0.004509868143095633 Test RE 0.1571606391102092\n",
      "92 Train Loss 0.025716498 Test MSE 0.004064721261173653 Test RE 0.14920289456447763\n",
      "93 Train Loss 0.024676828 Test MSE 0.0035028544648170114 Test RE 0.13850737894409762\n",
      "94 Train Loss 0.023806274 Test MSE 0.002360469277521917 Test RE 0.11370015066672289\n",
      "95 Train Loss 0.023308363 Test MSE 0.002175199385636418 Test RE 0.10914689865529296\n",
      "96 Train Loss 0.022331098 Test MSE 0.0023924142487886093 Test RE 0.11446693500655679\n",
      "97 Train Loss 0.021281723 Test MSE 0.002696665234542474 Test RE 0.12152772896874121\n",
      "98 Train Loss 0.0205832 Test MSE 0.002269527391644766 Test RE 0.1114883731959761\n",
      "99 Train Loss 0.01986615 Test MSE 0.0021798685817361048 Test RE 0.10926398104393963\n",
      "100 Train Loss 0.019579226 Test MSE 0.0019711183439983853 Test RE 0.10390063788865712\n",
      "101 Train Loss 0.018669412 Test MSE 0.0016521105823276208 Test RE 0.09512209801991775\n",
      "102 Train Loss 0.01749167 Test MSE 0.0015461104050220826 Test RE 0.09201997596361493\n",
      "103 Train Loss 0.016561162 Test MSE 0.0015282232443441202 Test RE 0.09148613166009353\n",
      "104 Train Loss 0.016304787 Test MSE 0.001188362277374642 Test RE 0.08067450191191362\n",
      "105 Train Loss 0.01603868 Test MSE 0.0009493446252396279 Test RE 0.07210639976742513\n",
      "106 Train Loss 0.015383421 Test MSE 0.0009041834033323454 Test RE 0.07037041781438397\n",
      "107 Train Loss 0.014547883 Test MSE 0.0008100809825584973 Test RE 0.06660795228645862\n",
      "108 Train Loss 0.0140772825 Test MSE 0.0009615858292748337 Test RE 0.072569794176631\n",
      "109 Train Loss 0.013463739 Test MSE 0.0008716567443361364 Test RE 0.06909308931425971\n",
      "110 Train Loss 0.013043988 Test MSE 0.0008498008428917566 Test RE 0.06822137098579897\n",
      "111 Train Loss 0.012791135 Test MSE 0.0007230110475105546 Test RE 0.06292660923930465\n",
      "112 Train Loss 0.012306628 Test MSE 0.0006389682771645755 Test RE 0.05915636946402659\n",
      "113 Train Loss 0.011819019 Test MSE 0.0007003355938299539 Test RE 0.061931979844477056\n",
      "114 Train Loss 0.011310161 Test MSE 0.0008599241997810281 Test RE 0.06862651570333633\n",
      "115 Train Loss 0.010998633 Test MSE 0.0009482832327935896 Test RE 0.07206608006186806\n",
      "116 Train Loss 0.010814084 Test MSE 0.0008852908039626914 Test RE 0.06963135404769175\n",
      "117 Train Loss 0.0103738 Test MSE 0.0009507275880824704 Test RE 0.07215890134499012\n",
      "118 Train Loss 0.0098372195 Test MSE 0.0008080242130309635 Test RE 0.06652334082294652\n",
      "119 Train Loss 0.009463206 Test MSE 0.0007811442356880174 Test RE 0.06540748950517326\n",
      "120 Train Loss 0.009229735 Test MSE 0.0008219826817226744 Test RE 0.06709546974601713\n",
      "121 Train Loss 0.008982925 Test MSE 0.0007959536138810457 Test RE 0.0660245946362241\n",
      "122 Train Loss 0.008829142 Test MSE 0.0009454469660278753 Test RE 0.07195822637100921\n",
      "123 Train Loss 0.008582525 Test MSE 0.0010670609635734611 Test RE 0.07644630172576194\n",
      "124 Train Loss 0.007872232 Test MSE 0.001355233223677344 Test RE 0.0861526982796998\n",
      "125 Train Loss 0.007311422 Test MSE 0.001348643234429369 Test RE 0.08594297894446126\n",
      "126 Train Loss 0.0070604095 Test MSE 0.0013763068595469689 Test RE 0.08681994397424285\n",
      "127 Train Loss 0.006972651 Test MSE 0.001455051627957727 Test RE 0.08926908136409145\n",
      "128 Train Loss 0.0068767294 Test MSE 0.0015247591570137615 Test RE 0.09138238512101883\n",
      "129 Train Loss 0.006656636 Test MSE 0.0013533772078374595 Test RE 0.0860936842465006\n",
      "130 Train Loss 0.0063700005 Test MSE 0.0012618909149423412 Test RE 0.08313286941205227\n",
      "131 Train Loss 0.0061493525 Test MSE 0.0011740479212711916 Test RE 0.08018714960964643\n",
      "132 Train Loss 0.0061013135 Test MSE 0.0011210961723359513 Test RE 0.07835799212511124\n",
      "133 Train Loss 0.0059928573 Test MSE 0.001217878106810574 Test RE 0.08167022945679231\n",
      "134 Train Loss 0.005733032 Test MSE 0.0011556387379304772 Test RE 0.07955599461602725\n",
      "135 Train Loss 0.0053387526 Test MSE 0.0009012618261821089 Test RE 0.07025663616931642\n",
      "136 Train Loss 0.0051483754 Test MSE 0.0009766057835495399 Test RE 0.07313436753713214\n",
      "137 Train Loss 0.005001914 Test MSE 0.0009057577686646749 Test RE 0.07043165570117936\n",
      "138 Train Loss 0.0049351905 Test MSE 0.0008628412365709553 Test RE 0.06874281466930757\n",
      "139 Train Loss 0.0048881606 Test MSE 0.000823515187305701 Test RE 0.0671579870608628\n",
      "140 Train Loss 0.004831005 Test MSE 0.0007229196300891019 Test RE 0.0629226308974606\n",
      "141 Train Loss 0.0047468743 Test MSE 0.0006293438117490143 Test RE 0.058709157367042145\n",
      "142 Train Loss 0.0044820304 Test MSE 0.0005994658981617839 Test RE 0.05729861246032816\n",
      "143 Train Loss 0.00430574 Test MSE 0.0005885499649227973 Test RE 0.056774528098873824\n",
      "144 Train Loss 0.004230862 Test MSE 0.0005301719261016469 Test RE 0.0538852903821547\n",
      "145 Train Loss 0.004163186 Test MSE 0.0005823664870166115 Test RE 0.05647549570366255\n",
      "146 Train Loss 0.0041027204 Test MSE 0.0005437754595877473 Test RE 0.05457222563487647\n",
      "147 Train Loss 0.0040685525 Test MSE 0.0005382757182509517 Test RE 0.05429555272873668\n",
      "148 Train Loss 0.0039973245 Test MSE 0.0005513641590819944 Test RE 0.05495169968550683\n",
      "149 Train Loss 0.0038123631 Test MSE 0.00035189654538428876 Test RE 0.04390048979899382\n",
      "150 Train Loss 0.0036429665 Test MSE 0.000256746569639296 Test RE 0.03749852532582795\n",
      "151 Train Loss 0.003569255 Test MSE 0.00021647387585281073 Test RE 0.03443218717936514\n",
      "152 Train Loss 0.003513143 Test MSE 0.00020175149516935792 Test RE 0.033240706444763936\n",
      "153 Train Loss 0.0034612298 Test MSE 0.00017653985220093078 Test RE 0.031094476059615076\n",
      "154 Train Loss 0.0034131764 Test MSE 0.00018792930983063447 Test RE 0.03208182928078954\n",
      "155 Train Loss 0.003357549 Test MSE 0.00014809963460914072 Test RE 0.02847992606736177\n",
      "156 Train Loss 0.0033212865 Test MSE 0.00016277002509384016 Test RE 0.029857200135937283\n",
      "157 Train Loss 0.0032881831 Test MSE 0.0001602858848815389 Test RE 0.029628488986761663\n",
      "158 Train Loss 0.0032679592 Test MSE 0.00013857922703731086 Test RE 0.02754932302700362\n",
      "159 Train Loss 0.0032455677 Test MSE 0.00013848917128243024 Test RE 0.027540370104075243\n",
      "160 Train Loss 0.0032039818 Test MSE 0.00013432566849202738 Test RE 0.02712322766509086\n",
      "161 Train Loss 0.0031693608 Test MSE 0.00011952257803046874 Test RE 0.02558508358129081\n",
      "162 Train Loss 0.0031143997 Test MSE 0.00011423031920213457 Test RE 0.025012238388185323\n",
      "163 Train Loss 0.0030585437 Test MSE 0.00010942451916547287 Test RE 0.024480438204342172\n",
      "164 Train Loss 0.003000726 Test MSE 0.00010495083017971779 Test RE 0.023974789524855877\n",
      "165 Train Loss 0.0029670266 Test MSE 9.193088265596997e-05 Test RE 0.022438435818376453\n",
      "166 Train Loss 0.0029289355 Test MSE 0.00012470193633086425 Test RE 0.026133553248928455\n",
      "167 Train Loss 0.002892685 Test MSE 0.00013357979300827655 Test RE 0.02704781872511954\n",
      "168 Train Loss 0.0028548883 Test MSE 0.00012696718001815332 Test RE 0.026369846452924502\n",
      "169 Train Loss 0.0028217689 Test MSE 0.00012533893947885998 Test RE 0.026200216009061188\n",
      "170 Train Loss 0.0027871584 Test MSE 0.0001137019276085897 Test RE 0.024954322173170413\n",
      "171 Train Loss 0.002744793 Test MSE 0.00010594785764062147 Test RE 0.024088399969830792\n",
      "172 Train Loss 0.0027094863 Test MSE 0.00010382380060859136 Test RE 0.023845713703488505\n",
      "173 Train Loss 0.0026874016 Test MSE 9.69633979928118e-05 Test RE 0.023044419754586952\n",
      "174 Train Loss 0.002665021 Test MSE 8.179297176950375e-05 Test RE 0.02116507724588153\n",
      "175 Train Loss 0.0026448118 Test MSE 9.458334837994058e-05 Test RE 0.022759840086477863\n",
      "176 Train Loss 0.0025881133 Test MSE 7.846136074785109e-05 Test RE 0.020729545583085533\n",
      "177 Train Loss 0.0025404699 Test MSE 7.09497363017438e-05 Test RE 0.01971229804100178\n",
      "178 Train Loss 0.0025181647 Test MSE 6.668782222264879e-05 Test RE 0.019111075650736324\n",
      "179 Train Loss 0.0024777553 Test MSE 5.96629670266984e-05 Test RE 0.018076497585935665\n",
      "180 Train Loss 0.0024240995 Test MSE 6.572576776239947e-05 Test RE 0.01897272439376709\n",
      "181 Train Loss 0.0023901407 Test MSE 6.253257092927093e-05 Test RE 0.018506104330782702\n",
      "182 Train Loss 0.0023723347 Test MSE 6.410716942437069e-05 Test RE 0.018737651825052815\n",
      "183 Train Loss 0.0023524384 Test MSE 6.204918690150953e-05 Test RE 0.018434438398906756\n",
      "184 Train Loss 0.0023424823 Test MSE 6.333797051220767e-05 Test RE 0.01862489940661005\n",
      "185 Train Loss 0.0023320457 Test MSE 6.672380313894413e-05 Test RE 0.019116230574554898\n",
      "186 Train Loss 0.0023117762 Test MSE 6.326731391964347e-05 Test RE 0.01861450801633633\n",
      "187 Train Loss 0.002269143 Test MSE 6.161140114012794e-05 Test RE 0.018369291533322563\n",
      "188 Train Loss 0.0022367446 Test MSE 5.805694430417113e-05 Test RE 0.017831544061023868\n",
      "189 Train Loss 0.0021986915 Test MSE 5.6102675864579186e-05 Test RE 0.017528859173742216\n",
      "190 Train Loss 0.0021653883 Test MSE 5.539289715207995e-05 Test RE 0.017417623721640713\n",
      "191 Train Loss 0.0021304903 Test MSE 5.4937367386672285e-05 Test RE 0.017345857972617288\n",
      "192 Train Loss 0.0021149146 Test MSE 6.341846437788584e-05 Test RE 0.01863673049406985\n",
      "193 Train Loss 0.0021041734 Test MSE 6.107798244545696e-05 Test RE 0.01828959991753927\n",
      "194 Train Loss 0.0020968502 Test MSE 5.877955165409765e-05 Test RE 0.017942171295462512\n",
      "195 Train Loss 0.002083629 Test MSE 5.826333974872239e-05 Test RE 0.017863211972164034\n",
      "196 Train Loss 0.0020737748 Test MSE 5.8879340778896994e-05 Test RE 0.01795739490866471\n",
      "197 Train Loss 0.0020542028 Test MSE 5.451536579956734e-05 Test RE 0.01727910840573811\n",
      "198 Train Loss 0.002022355 Test MSE 5.8108790341417725e-05 Test RE 0.017839504250821408\n",
      "199 Train Loss 0.0019895355 Test MSE 5.9525172284722164e-05 Test RE 0.01805561121124608\n",
      "200 Train Loss 0.0019565446 Test MSE 5.597501118066665e-05 Test RE 0.01750890387972209\n",
      "201 Train Loss 0.0019193903 Test MSE 5.538176955346261e-05 Test RE 0.01741587416465525\n",
      "202 Train Loss 0.0018882971 Test MSE 5.397928293874118e-05 Test RE 0.017193940502556796\n",
      "203 Train Loss 0.0018650776 Test MSE 5.907151468757007e-05 Test RE 0.017986676244539142\n",
      "204 Train Loss 0.0018295444 Test MSE 5.8813804101146176e-05 Test RE 0.01794739823025807\n",
      "205 Train Loss 0.0017973067 Test MSE 5.691768065310598e-05 Test RE 0.017655721161860986\n",
      "206 Train Loss 0.0017848687 Test MSE 5.364501193834632e-05 Test RE 0.01714062040547802\n",
      "207 Train Loss 0.0017774687 Test MSE 5.193886830132544e-05 Test RE 0.01686584502086885\n",
      "208 Train Loss 0.0017727292 Test MSE 5.352979746894214e-05 Test RE 0.01712220388445412\n",
      "209 Train Loss 0.0017594137 Test MSE 5.3294716544736945e-05 Test RE 0.017084565666251512\n",
      "210 Train Loss 0.0017438411 Test MSE 6.0413900607023323e-05 Test RE 0.01818989961879706\n",
      "211 Train Loss 0.0017189834 Test MSE 5.639450378845946e-05 Test RE 0.017574389761815218\n",
      "212 Train Loss 0.0016938869 Test MSE 6.010218841522469e-05 Test RE 0.018142912533738353\n",
      "213 Train Loss 0.0016602424 Test MSE 5.159125374929449e-05 Test RE 0.016809310715025606\n",
      "214 Train Loss 0.0016319171 Test MSE 4.771754755375211e-05 Test RE 0.0161659384720623\n",
      "215 Train Loss 0.0015835119 Test MSE 4.117607363221448e-05 Test RE 0.015017039737177605\n",
      "216 Train Loss 0.0015093485 Test MSE 4.186599945321251e-05 Test RE 0.015142326134566836\n",
      "217 Train Loss 0.0014593224 Test MSE 4.258443684311811e-05 Test RE 0.015271697681982471\n",
      "218 Train Loss 0.0014396273 Test MSE 4.108740587022317e-05 Test RE 0.015000862321729223\n",
      "219 Train Loss 0.0014165364 Test MSE 3.635946950734456e-05 Test RE 0.014111417241246985\n",
      "220 Train Loss 0.0014005385 Test MSE 3.749993437600355e-05 Test RE 0.014331020521657111\n",
      "221 Train Loss 0.0013838443 Test MSE 3.441645307779292e-05 Test RE 0.013729190123612612\n",
      "222 Train Loss 0.0013658514 Test MSE 3.434208021565598e-05 Test RE 0.013714347928968796\n",
      "223 Train Loss 0.00134243 Test MSE 3.9299937952145807e-05 Test RE 0.014670935116432946\n",
      "224 Train Loss 0.0013249137 Test MSE 4.089730889405558e-05 Test RE 0.014966120233269844\n",
      "225 Train Loss 0.0013141118 Test MSE 4.7259776111198376e-05 Test RE 0.016088208795630818\n",
      "226 Train Loss 0.0013080257 Test MSE 4.724628758213938e-05 Test RE 0.016085912744147\n",
      "227 Train Loss 0.0013005268 Test MSE 4.9202084009333785e-05 Test RE 0.016415481013402917\n",
      "228 Train Loss 0.0012927679 Test MSE 5.662254653121226e-05 Test RE 0.017609886737974395\n",
      "229 Train Loss 0.0012818505 Test MSE 5.816457125241877e-05 Test RE 0.017848064617487242\n",
      "230 Train Loss 0.0012746856 Test MSE 5.82992912971318e-05 Test RE 0.01786872239341624\n",
      "231 Train Loss 0.0012654022 Test MSE 6.311811806563283e-05 Test RE 0.01859254686078877\n",
      "232 Train Loss 0.0012523135 Test MSE 6.883858159406722e-05 Test RE 0.019416807304919185\n",
      "233 Train Loss 0.001240569 Test MSE 7.712170785729749e-05 Test RE 0.02055181506361809\n",
      "234 Train Loss 0.0012199479 Test MSE 8.752846569370207e-05 Test RE 0.02189457512361497\n",
      "235 Train Loss 0.001201776 Test MSE 6.854471202453415e-05 Test RE 0.019375318132751784\n",
      "236 Train Loss 0.001161589 Test MSE 6.939660242866724e-05 Test RE 0.01949534693793433\n",
      "237 Train Loss 0.0011389519 Test MSE 8.797499484787608e-05 Test RE 0.021950352000740813\n",
      "238 Train Loss 0.0011115561 Test MSE 0.00010365830880945116 Test RE 0.023826701473870275\n",
      "239 Train Loss 0.0010846092 Test MSE 0.00011857853145028557 Test RE 0.025483841647143294\n",
      "240 Train Loss 0.0010593892 Test MSE 0.00011434954114583021 Test RE 0.02502528759449339\n",
      "241 Train Loss 0.0010383149 Test MSE 0.00011798628602793448 Test RE 0.025420121929714518\n",
      "242 Train Loss 0.0010179904 Test MSE 0.00010237118853454744 Test RE 0.023678311890694477\n",
      "243 Train Loss 0.0009940984 Test MSE 9.982672115474266e-05 Test RE 0.023382194427438087\n",
      "244 Train Loss 0.0009832634 Test MSE 9.276324975017381e-05 Test RE 0.022539788751741213\n",
      "245 Train Loss 0.0009744179 Test MSE 8.527656990677721e-05 Test RE 0.021611092673838667\n",
      "246 Train Loss 0.0009598856 Test MSE 8.868943218888551e-05 Test RE 0.022039300237802456\n",
      "247 Train Loss 0.0009409332 Test MSE 9.092432218933673e-05 Test RE 0.02231525737345077\n",
      "248 Train Loss 0.00092955795 Test MSE 8.030588360639439e-05 Test RE 0.020971792234211657\n",
      "249 Train Loss 0.0009162622 Test MSE 8.36455263727076e-05 Test RE 0.021403422441226085\n",
      "250 Train Loss 0.00090847124 Test MSE 8.485509863162388e-05 Test RE 0.02155762114519336\n",
      "251 Train Loss 0.00089672324 Test MSE 8.669966587910295e-05 Test RE 0.021790669608365988\n",
      "252 Train Loss 0.00089101715 Test MSE 7.880217217185744e-05 Test RE 0.0207745181059372\n",
      "253 Train Loss 0.0008832666 Test MSE 7.268614419557937e-05 Test RE 0.01995205713083484\n",
      "254 Train Loss 0.0008799425 Test MSE 7.083997101245976e-05 Test RE 0.019697043836230173\n",
      "255 Train Loss 0.0008724801 Test MSE 6.843841978340964e-05 Test RE 0.019360289657607544\n",
      "256 Train Loss 0.0008632532 Test MSE 6.754603326583355e-05 Test RE 0.01923365354366752\n",
      "257 Train Loss 0.0008545397 Test MSE 6.939628927709903e-05 Test RE 0.019495302951592495\n",
      "258 Train Loss 0.0008497839 Test MSE 6.74492095580097e-05 Test RE 0.01921986338155322\n",
      "259 Train Loss 0.0008461056 Test MSE 6.232586666751841e-05 Test RE 0.018475492627310904\n",
      "260 Train Loss 0.00084311824 Test MSE 6.036816215425761e-05 Test RE 0.01818301266575086\n",
      "261 Train Loss 0.0008379762 Test MSE 5.7283361444659786e-05 Test RE 0.017712346986246335\n",
      "262 Train Loss 0.00083451153 Test MSE 5.6519798383727665e-05 Test RE 0.01759390189686494\n",
      "263 Train Loss 0.00083068217 Test MSE 5.40155852043569e-05 Test RE 0.017199721184077987\n",
      "264 Train Loss 0.0008230014 Test MSE 5.4765621768039746e-05 Test RE 0.017318723371903776\n",
      "265 Train Loss 0.0008133996 Test MSE 6.43406107326774e-05 Test RE 0.018771736680182706\n",
      "266 Train Loss 0.0007934919 Test MSE 5.698803344251557e-05 Test RE 0.01766662942115573\n",
      "267 Train Loss 0.0007797714 Test MSE 5.111277022071606e-05 Test RE 0.016731180088522663\n",
      "268 Train Loss 0.0007728318 Test MSE 5.3643918861335775e-05 Test RE 0.01714044577494969\n",
      "269 Train Loss 0.0007683949 Test MSE 5.320691269504715e-05 Test RE 0.01707048632501425\n",
      "270 Train Loss 0.00076367956 Test MSE 5.150481306047896e-05 Test RE 0.016795222885915388\n",
      "271 Train Loss 0.0007592873 Test MSE 4.757876969649584e-05 Test RE 0.01614241350087323\n",
      "272 Train Loss 0.0007524939 Test MSE 4.660423488683713e-05 Test RE 0.01597623923661508\n",
      "273 Train Loss 0.00074348686 Test MSE 4.452001964425678e-05 Test RE 0.015614911879215895\n",
      "274 Train Loss 0.00073863176 Test MSE 4.4779339428838185e-05 Test RE 0.015660322642862306\n",
      "275 Train Loss 0.000734284 Test MSE 4.659386621129476e-05 Test RE 0.015974461912556494\n",
      "276 Train Loss 0.0007291233 Test MSE 5.045500653392839e-05 Test RE 0.01662317578426263\n",
      "277 Train Loss 0.000726711 Test MSE 5.0953633720781246e-05 Test RE 0.01670511402836578\n",
      "278 Train Loss 0.00072118593 Test MSE 5.0044763566404634e-05 Test RE 0.0165554574320859\n",
      "279 Train Loss 0.00071300054 Test MSE 4.7038218220624e-05 Test RE 0.016050453040591273\n",
      "280 Train Loss 0.00070633885 Test MSE 4.824703372979885e-05 Test RE 0.016255381740009844\n",
      "281 Train Loss 0.0007011541 Test MSE 4.839115597809746e-05 Test RE 0.016279642456487962\n",
      "282 Train Loss 0.0006964136 Test MSE 4.472890270638808e-05 Test RE 0.015651500740917288\n",
      "283 Train Loss 0.0006916271 Test MSE 4.5113275461168944e-05 Test RE 0.015718606581359172\n",
      "284 Train Loss 0.00068817835 Test MSE 4.5583331737482604e-05 Test RE 0.015800284123369396\n",
      "285 Train Loss 0.00068056746 Test MSE 4.7471471402681925e-05 Test RE 0.01612420127029372\n",
      "286 Train Loss 0.0006743581 Test MSE 5.124826498875671e-05 Test RE 0.016753341741618646\n",
      "287 Train Loss 0.00066604814 Test MSE 5.6159316199981626e-05 Test RE 0.017537705364989838\n",
      "288 Train Loss 0.0006594111 Test MSE 6.324177384338062e-05 Test RE 0.018610750436678248\n",
      "289 Train Loss 0.0006493029 Test MSE 7.175164545455065e-05 Test RE 0.019823384126149923\n",
      "290 Train Loss 0.0006417988 Test MSE 7.005382386069488e-05 Test RE 0.019587444867343047\n",
      "291 Train Loss 0.0006369872 Test MSE 7.146201643047088e-05 Test RE 0.01978333464036231\n",
      "292 Train Loss 0.00062467443 Test MSE 7.102419425600954e-05 Test RE 0.019722638830033896\n",
      "293 Train Loss 0.00061841897 Test MSE 6.511955616812253e-05 Test RE 0.018885025691583367\n",
      "294 Train Loss 0.0006080914 Test MSE 6.92449114620047e-05 Test RE 0.019474028272986124\n",
      "295 Train Loss 0.00060157146 Test MSE 6.86611790988245e-05 Test RE 0.019391771837195215\n",
      "296 Train Loss 0.00058603025 Test MSE 6.128963087828008e-05 Test RE 0.018321261224684658\n",
      "297 Train Loss 0.0005718127 Test MSE 4.779191542737694e-05 Test RE 0.016178530888035256\n",
      "298 Train Loss 0.00055851496 Test MSE 4.936282440607006e-05 Test RE 0.016442273368165367\n",
      "299 Train Loss 0.00055176154 Test MSE 5.287315882697674e-05 Test RE 0.01701686262098489\n",
      "Training time: 246.31\n",
      "KG_atanh_low\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 11572.292 Test MSE 6.944376949893147 Test RE 6.167064739120076\n",
      "1 Train Loss 5393.5747 Test MSE 10.601230608629475 Test RE 7.6197374087999155\n",
      "2 Train Loss 2551.4739 Test MSE 13.733240915578632 Test RE 8.672581372690994\n",
      "3 Train Loss 867.25793 Test MSE 17.57895639894382 Test RE 9.81201963300499\n",
      "4 Train Loss 465.33313 Test MSE 14.918373667585044 Test RE 9.039046165862077\n",
      "5 Train Loss 296.01636 Test MSE 13.786958215052513 Test RE 8.689526134107153\n",
      "6 Train Loss 169.54802 Test MSE 12.851887491056948 Test RE 8.389678556569496\n",
      "7 Train Loss 77.36154 Test MSE 11.348137615860942 Test RE 7.883592377289788\n",
      "8 Train Loss 38.578594 Test MSE 10.769744910758247 Test RE 7.680059284083248\n",
      "9 Train Loss 26.858755 Test MSE 10.713005833249186 Test RE 7.6598018436434785\n",
      "10 Train Loss 20.551613 Test MSE 9.949689607463355 Test RE 7.38187403957252\n",
      "11 Train Loss 16.487183 Test MSE 9.051806219673493 Test RE 7.040921268364731\n",
      "12 Train Loss 14.666016 Test MSE 8.676956840453954 Test RE 6.893592106820685\n",
      "13 Train Loss 12.770426 Test MSE 7.6915262232043835 Test RE 6.490350138623151\n",
      "14 Train Loss 11.128963 Test MSE 6.627411562013316 Test RE 6.02467792218727\n",
      "15 Train Loss 8.516293 Test MSE 3.999469627433333 Test RE 4.680185487120385\n",
      "16 Train Loss 6.143579 Test MSE 2.7796437960348253 Test RE 3.901723028838199\n",
      "17 Train Loss 4.70056 Test MSE 1.9897958530430564 Test RE 3.301156584045697\n",
      "18 Train Loss 3.3684158 Test MSE 1.4368459287642958 Test RE 2.8052202477344714\n",
      "19 Train Loss 2.5552735 Test MSE 0.9250517499840968 Test RE 2.2508413170111954\n",
      "20 Train Loss 1.9572 Test MSE 0.6537636879793598 Test RE 1.8922227579466162\n",
      "21 Train Loss 1.5257974 Test MSE 0.5571194392319901 Test RE 1.7467711892976003\n",
      "22 Train Loss 1.2220792 Test MSE 0.39841515790121135 Test RE 1.4771676585773308\n",
      "23 Train Loss 0.9984846 Test MSE 0.2752611357443147 Test RE 1.2278188958142895\n",
      "24 Train Loss 0.8518415 Test MSE 0.1205993781358078 Test RE 0.8127077444281384\n",
      "25 Train Loss 0.6289341 Test MSE 0.09724352658360967 Test RE 0.7297804320141581\n",
      "26 Train Loss 0.49036732 Test MSE 0.0485370463711198 Test RE 0.5155829372791816\n",
      "27 Train Loss 0.3862702 Test MSE 0.024708762509434615 Test RE 0.3678640616139183\n",
      "28 Train Loss 0.30467883 Test MSE 0.021903569346764996 Test RE 0.34635328420307065\n",
      "29 Train Loss 0.26136395 Test MSE 0.02400984830840069 Test RE 0.36262402337292476\n",
      "30 Train Loss 0.22209696 Test MSE 0.025864498722405916 Test RE 0.376369044893255\n",
      "31 Train Loss 0.19660957 Test MSE 0.027846105484063674 Test RE 0.39052073319637726\n",
      "32 Train Loss 0.17896569 Test MSE 0.022839038726514726 Test RE 0.35367207830559894\n",
      "33 Train Loss 0.17071375 Test MSE 0.024291357624910435 Test RE 0.3647436652719383\n",
      "34 Train Loss 0.15455803 Test MSE 0.01832466903874068 Test RE 0.31679617833333645\n",
      "35 Train Loss 0.14564392 Test MSE 0.013940194532902619 Test RE 0.27630979535046934\n",
      "36 Train Loss 0.12892044 Test MSE 0.013678309172529247 Test RE 0.2737020637121455\n",
      "37 Train Loss 0.11955884 Test MSE 0.014966877417656003 Test RE 0.2863040324514253\n",
      "38 Train Loss 0.10537107 Test MSE 0.01381537826043665 Test RE 0.27507001692224864\n",
      "39 Train Loss 0.09654325 Test MSE 0.010888813171898054 Test RE 0.24420364232381273\n",
      "40 Train Loss 0.09106006 Test MSE 0.010731783148518298 Test RE 0.2424363898785888\n",
      "41 Train Loss 0.07769879 Test MSE 0.006794530359821839 Test RE 0.19290415664650215\n",
      "42 Train Loss 0.073137574 Test MSE 0.0063133077858367 Test RE 0.18594750064695992\n",
      "43 Train Loss 0.060741372 Test MSE 0.006344091795024162 Test RE 0.18640029408256767\n",
      "44 Train Loss 0.05870045 Test MSE 0.007214578777121893 Test RE 0.19877755939177572\n",
      "45 Train Loss 0.050881676 Test MSE 0.008127466169173756 Test RE 0.21097910673897854\n",
      "46 Train Loss 0.04834052 Test MSE 0.008081361795488236 Test RE 0.2103798490354513\n",
      "47 Train Loss 0.045841828 Test MSE 0.00938644397577259 Test RE 0.226731786613918\n",
      "48 Train Loss 0.043624498 Test MSE 0.008202529823382852 Test RE 0.21195114794786138\n",
      "49 Train Loss 0.042664897 Test MSE 0.007993677562359509 Test RE 0.2092354065626621\n",
      "50 Train Loss 0.03840667 Test MSE 0.009736624996350501 Test RE 0.23092241239797168\n",
      "51 Train Loss 0.037414063 Test MSE 0.01044251098877692 Test RE 0.23914666812950894\n",
      "52 Train Loss 0.03454719 Test MSE 0.009926468500200283 Test RE 0.2331627926993838\n",
      "53 Train Loss 0.032863017 Test MSE 0.009916295474495369 Test RE 0.23304328498539365\n",
      "54 Train Loss 0.031525515 Test MSE 0.010612375393966127 Test RE 0.24108387647489168\n",
      "55 Train Loss 0.028588332 Test MSE 0.01079375501393014 Test RE 0.24313537008256675\n",
      "56 Train Loss 0.027368095 Test MSE 0.00926140894721842 Test RE 0.22521659838804808\n",
      "57 Train Loss 0.026347285 Test MSE 0.008326932171168219 Test RE 0.21355236113702808\n",
      "58 Train Loss 0.023148656 Test MSE 0.00669552155397751 Test RE 0.1914935146716429\n",
      "59 Train Loss 0.020243194 Test MSE 0.005976800817538353 Test RE 0.18092403106273572\n",
      "60 Train Loss 0.018954845 Test MSE 0.006317832377438499 Test RE 0.18601412070106332\n",
      "61 Train Loss 0.018075673 Test MSE 0.007003773342524695 Test RE 0.1958519524983782\n",
      "62 Train Loss 0.01757389 Test MSE 0.006624060301966804 Test RE 0.19046886889554926\n",
      "63 Train Loss 0.016233616 Test MSE 0.004758671947665306 Test RE 0.1614376203593732\n",
      "64 Train Loss 0.015063186 Test MSE 0.0041535675948856324 Test RE 0.1508247122106064\n",
      "65 Train Loss 0.014076657 Test MSE 0.004293524758330572 Test RE 0.15334472811275332\n",
      "66 Train Loss 0.013481681 Test MSE 0.003875169585208802 Test RE 0.1456824446050232\n",
      "67 Train Loss 0.013149297 Test MSE 0.0035673251197213805 Test RE 0.13977619375523695\n",
      "68 Train Loss 0.011384842 Test MSE 0.0029196301852244936 Test RE 0.12645202443110481\n",
      "69 Train Loss 0.011144595 Test MSE 0.003007783796451173 Test RE 0.12834683741627956\n",
      "70 Train Loss 0.010971194 Test MSE 0.002889182815266032 Test RE 0.12579094378312455\n",
      "71 Train Loss 0.010390671 Test MSE 0.0025171243045735477 Test RE 0.11741246221552905\n",
      "72 Train Loss 0.009878465 Test MSE 0.0020813394834584774 Test RE 0.10676608687543954\n",
      "73 Train Loss 0.009397403 Test MSE 0.00197297656749668 Test RE 0.10394960124128654\n",
      "74 Train Loss 0.00902129 Test MSE 0.001646842670643043 Test RE 0.0949703240096886\n",
      "75 Train Loss 0.008716823 Test MSE 0.0015676647459041994 Test RE 0.09265918159176884\n",
      "76 Train Loss 0.008589226 Test MSE 0.0016838039259390307 Test RE 0.09603015347033245\n",
      "77 Train Loss 0.008514448 Test MSE 0.0018674604697687537 Test RE 0.10113176173010335\n",
      "78 Train Loss 0.008414381 Test MSE 0.0018173479401172017 Test RE 0.0997656199361722\n",
      "79 Train Loss 0.008187389 Test MSE 0.0016175563942058442 Test RE 0.094122093731756\n",
      "80 Train Loss 0.007946963 Test MSE 0.0015375312306430816 Test RE 0.0917643171134895\n",
      "81 Train Loss 0.007866021 Test MSE 0.001590037231487208 Test RE 0.09331801901309403\n",
      "82 Train Loss 0.007814005 Test MSE 0.0016201610905503877 Test RE 0.09419784406130899\n",
      "83 Train Loss 0.00763248 Test MSE 0.0015612067273768249 Test RE 0.09246812918095366\n",
      "84 Train Loss 0.0072305794 Test MSE 0.0018815309517027532 Test RE 0.10151203813586701\n",
      "85 Train Loss 0.0069307783 Test MSE 0.0020174007899751846 Test RE 0.10511336933573526\n",
      "86 Train Loss 0.0068612406 Test MSE 0.001918432812285283 Test RE 0.10250266596007925\n",
      "87 Train Loss 0.006814585 Test MSE 0.0018260446105287757 Test RE 0.10000404241772562\n",
      "88 Train Loss 0.0066844234 Test MSE 0.0017155493840468913 Test RE 0.09693117474766261\n",
      "89 Train Loss 0.0064361915 Test MSE 0.0016968734292825884 Test RE 0.09640212088779174\n",
      "90 Train Loss 0.006183604 Test MSE 0.0015496748679321572 Test RE 0.09212598810894246\n",
      "91 Train Loss 0.0060440307 Test MSE 0.001572242312293519 Test RE 0.09279436495178162\n",
      "92 Train Loss 0.0060031423 Test MSE 0.0015577552663873524 Test RE 0.09236585998054357\n",
      "93 Train Loss 0.005919744 Test MSE 0.0014376010621019591 Test RE 0.08873216058752874\n",
      "94 Train Loss 0.0057426994 Test MSE 0.001504863139436254 Test RE 0.09078421995377885\n",
      "95 Train Loss 0.0054871934 Test MSE 0.001505673971614186 Test RE 0.0908086742885328\n",
      "96 Train Loss 0.0053246953 Test MSE 0.001492300161739108 Test RE 0.09040448095090575\n",
      "97 Train Loss 0.0052690594 Test MSE 0.0014184689919316056 Test RE 0.0881397445056296\n",
      "98 Train Loss 0.005233334 Test MSE 0.0014400201880117656 Test RE 0.0888067863122155\n",
      "99 Train Loss 0.00514073 Test MSE 0.0014485109759737572 Test RE 0.0890682171424197\n",
      "100 Train Loss 0.0049356776 Test MSE 0.0012074026279034204 Test RE 0.08131823100180827\n",
      "101 Train Loss 0.0047443984 Test MSE 0.001306763618005186 Test RE 0.08459805560530023\n",
      "102 Train Loss 0.004613431 Test MSE 0.0013310447742774806 Test RE 0.08538040221966155\n",
      "103 Train Loss 0.0045855 Test MSE 0.001338818682132393 Test RE 0.08562936945089153\n",
      "104 Train Loss 0.0045543895 Test MSE 0.00133315107397455 Test RE 0.08544793023592262\n",
      "105 Train Loss 0.004490227 Test MSE 0.001334393379256997 Test RE 0.08548773356316486\n",
      "106 Train Loss 0.0043502864 Test MSE 0.001368174068965474 Test RE 0.0865630482808955\n",
      "107 Train Loss 0.0039578066 Test MSE 0.0014322246226487903 Test RE 0.08856608184151873\n",
      "108 Train Loss 0.0037625507 Test MSE 0.0013432070884467297 Test RE 0.08576959345671215\n",
      "109 Train Loss 0.0036260658 Test MSE 0.0014524789400925501 Test RE 0.08919012777772187\n",
      "110 Train Loss 0.0035568338 Test MSE 0.0014775533572260531 Test RE 0.08995668659714076\n",
      "111 Train Loss 0.0034939325 Test MSE 0.001465230762587111 Test RE 0.08958078793634137\n",
      "112 Train Loss 0.0034446043 Test MSE 0.001510376144345458 Test RE 0.09095036007980838\n",
      "113 Train Loss 0.0033833466 Test MSE 0.001607960529988389 Test RE 0.0938424972010947\n",
      "114 Train Loss 0.0033084997 Test MSE 0.0015654821757456736 Test RE 0.09259465708027921\n",
      "115 Train Loss 0.0032002705 Test MSE 0.001479094940782338 Test RE 0.09000360185596697\n",
      "116 Train Loss 0.0031220266 Test MSE 0.0014717935104409635 Test RE 0.08978117934030895\n",
      "117 Train Loss 0.0030282792 Test MSE 0.0014082287618124368 Test RE 0.08782101842077464\n",
      "118 Train Loss 0.0029916305 Test MSE 0.0013749106547549985 Test RE 0.08677589522911323\n",
      "119 Train Loss 0.0029645897 Test MSE 0.0013305221653041237 Test RE 0.08536363909270989\n",
      "120 Train Loss 0.0029537873 Test MSE 0.0013258304505183813 Test RE 0.08521300066424499\n",
      "121 Train Loss 0.002899804 Test MSE 0.0012773676617468964 Test RE 0.08364111673130381\n",
      "122 Train Loss 0.0027345484 Test MSE 0.001082186609293469 Test RE 0.07698621033969769\n",
      "123 Train Loss 0.0026080552 Test MSE 0.0009971680586877269 Test RE 0.07390027311016677\n",
      "124 Train Loss 0.0025024156 Test MSE 0.0009208928684105919 Test RE 0.07101766989393922\n",
      "125 Train Loss 0.0024337764 Test MSE 0.0009085474013194418 Test RE 0.0705400331300424\n",
      "126 Train Loss 0.0024061222 Test MSE 0.0008914525574595009 Test RE 0.06987325606417039\n",
      "127 Train Loss 0.0023805855 Test MSE 0.0008973742300251285 Test RE 0.07010494628631804\n",
      "128 Train Loss 0.0023564561 Test MSE 0.0007982020220485292 Test RE 0.06611778194486438\n",
      "129 Train Loss 0.0023201182 Test MSE 0.0007615328424118698 Test RE 0.0645812107708831\n",
      "130 Train Loss 0.0022732697 Test MSE 0.0007521143606563175 Test RE 0.06418060468968763\n",
      "131 Train Loss 0.0022263827 Test MSE 0.0007686799614139254 Test RE 0.06488355601951712\n",
      "132 Train Loss 0.0021871154 Test MSE 0.0007310682179153734 Test RE 0.06327626206398425\n",
      "133 Train Loss 0.0021645718 Test MSE 0.0006874208360348115 Test RE 0.06135828465328159\n",
      "134 Train Loss 0.0021356242 Test MSE 0.0006764174263651829 Test RE 0.060865228654197336\n",
      "135 Train Loss 0.0021078582 Test MSE 0.0006233708345133322 Test RE 0.05842989469931613\n",
      "136 Train Loss 0.0020833379 Test MSE 0.0005949115922485284 Test RE 0.05708054089075413\n",
      "137 Train Loss 0.0020646094 Test MSE 0.0005462433421420112 Test RE 0.05469592134490161\n",
      "138 Train Loss 0.002037079 Test MSE 0.0005335721022205484 Test RE 0.05405780673417834\n",
      "139 Train Loss 0.0019965242 Test MSE 0.0005376854189369724 Test RE 0.05426577299101927\n",
      "140 Train Loss 0.001974738 Test MSE 0.0005331097931966401 Test RE 0.054034382695039504\n",
      "141 Train Loss 0.001959298 Test MSE 0.000535959475060113 Test RE 0.05417860774816972\n",
      "142 Train Loss 0.0019472898 Test MSE 0.0005236358984400303 Test RE 0.05355210792503256\n",
      "143 Train Loss 0.0019321591 Test MSE 0.0005151932108540487 Test RE 0.053118637855417164\n",
      "144 Train Loss 0.0019194024 Test MSE 0.0005008159248245305 Test RE 0.05237221342738063\n",
      "145 Train Loss 0.0019072891 Test MSE 0.00048003580648452675 Test RE 0.051274174918746966\n",
      "146 Train Loss 0.0018953705 Test MSE 0.0004526651688525865 Test RE 0.04979094891609165\n",
      "147 Train Loss 0.001880081 Test MSE 0.0004475243225171181 Test RE 0.04950740763976409\n",
      "148 Train Loss 0.0018495817 Test MSE 0.0004720143826162078 Test RE 0.05084397307817151\n",
      "149 Train Loss 0.0018206687 Test MSE 0.000500834037913138 Test RE 0.052373160495872526\n",
      "150 Train Loss 0.0017717244 Test MSE 0.00046947795764109093 Test RE 0.050707181019511285\n",
      "151 Train Loss 0.0017343092 Test MSE 0.00043908620229192376 Test RE 0.04903845276872331\n",
      "152 Train Loss 0.0017224594 Test MSE 0.0004248863056475452 Test RE 0.04823899274184827\n",
      "153 Train Loss 0.0017137652 Test MSE 0.0004261629696419464 Test RE 0.04831141069497781\n",
      "154 Train Loss 0.0017072 Test MSE 0.0004259454872353319 Test RE 0.048299081816776765\n",
      "155 Train Loss 0.001702175 Test MSE 0.0004311330203489342 Test RE 0.048592305763242916\n",
      "156 Train Loss 0.0016912676 Test MSE 0.0004396093086537212 Test RE 0.04906765511075802\n",
      "157 Train Loss 0.0016775146 Test MSE 0.00042586291979819957 Test RE 0.04829440032020042\n",
      "158 Train Loss 0.0016647431 Test MSE 0.00043351536042839724 Test RE 0.0487263756582447\n",
      "159 Train Loss 0.0016383111 Test MSE 0.0004374032877120211 Test RE 0.04894438609595358\n",
      "160 Train Loss 0.0015959189 Test MSE 0.00043531462717146674 Test RE 0.04882738818868709\n",
      "161 Train Loss 0.0015607902 Test MSE 0.0004567176382816409 Test RE 0.0500133281972354\n",
      "162 Train Loss 0.0015254446 Test MSE 0.0004501434895373101 Test RE 0.04965206905034143\n",
      "163 Train Loss 0.0014938331 Test MSE 0.0004389410192405892 Test RE 0.04903034486100205\n",
      "164 Train Loss 0.0014688665 Test MSE 0.00043081761802152773 Test RE 0.048574528268069884\n",
      "165 Train Loss 0.0014536283 Test MSE 0.0004443631093429481 Test RE 0.049332243052805855\n",
      "166 Train Loss 0.0014387013 Test MSE 0.0004530266498555368 Test RE 0.049810825517606676\n",
      "167 Train Loss 0.00143081 Test MSE 0.00045995001241307435 Test RE 0.05018999836076567\n",
      "168 Train Loss 0.001424498 Test MSE 0.000471764651707507 Test RE 0.05083052116656908\n",
      "169 Train Loss 0.0014214542 Test MSE 0.00045858466854350257 Test RE 0.05011544945871941\n",
      "170 Train Loss 0.0014143136 Test MSE 0.00046504316377047645 Test RE 0.05046711705902889\n",
      "171 Train Loss 0.0014028726 Test MSE 0.0004680734359074345 Test RE 0.05063127470421219\n",
      "172 Train Loss 0.0013881141 Test MSE 0.0004590521892487679 Test RE 0.0501409889536937\n",
      "173 Train Loss 0.0013767265 Test MSE 0.0004779594011186422 Test RE 0.05116316095854968\n",
      "174 Train Loss 0.0013642217 Test MSE 0.0004935990901409901 Test RE 0.05199349830610364\n",
      "175 Train Loss 0.0013510267 Test MSE 0.0005343295660771691 Test RE 0.05409616360551694\n",
      "176 Train Loss 0.001338296 Test MSE 0.0005396634588281307 Test RE 0.05436549796075371\n",
      "177 Train Loss 0.0013289414 Test MSE 0.0005342705359506211 Test RE 0.054093175382717615\n",
      "178 Train Loss 0.0013265448 Test MSE 0.0005395658549029019 Test RE 0.05436058144671376\n",
      "179 Train Loss 0.0013240393 Test MSE 0.0005274192035610324 Test RE 0.053745218561620685\n",
      "180 Train Loss 0.0013200018 Test MSE 0.0005213014678319733 Test RE 0.05343260377804968\n",
      "181 Train Loss 0.0013144875 Test MSE 0.0005061444270948284 Test RE 0.05265008707114218\n",
      "182 Train Loss 0.0013100655 Test MSE 0.0004980517265224196 Test RE 0.05222748211388509\n",
      "183 Train Loss 0.0013020617 Test MSE 0.00048710511165305295 Test RE 0.051650342719038046\n",
      "184 Train Loss 0.0012887047 Test MSE 0.0004701178634381469 Test RE 0.05074172659227616\n",
      "185 Train Loss 0.0012731957 Test MSE 0.0004341341257064543 Test RE 0.04876113733142943\n",
      "186 Train Loss 0.0012507265 Test MSE 0.0004093332088092437 Test RE 0.04734785991511659\n",
      "187 Train Loss 0.0012334103 Test MSE 0.0003903715871592832 Test RE 0.04623820480085505\n",
      "188 Train Loss 0.001225036 Test MSE 0.0003800988022054153 Test RE 0.04562576030189784\n",
      "189 Train Loss 0.0012181905 Test MSE 0.0003780486326429261 Test RE 0.045502546258457434\n",
      "190 Train Loss 0.0012123091 Test MSE 0.00038009216737760435 Test RE 0.045625362089140226\n",
      "191 Train Loss 0.0012071333 Test MSE 0.0003792879391004411 Test RE 0.04557706770209662\n",
      "192 Train Loss 0.0012049186 Test MSE 0.00037330986354225257 Test RE 0.045216463968963956\n",
      "193 Train Loss 0.0012019611 Test MSE 0.00036982081650984865 Test RE 0.04500466575624533\n",
      "194 Train Loss 0.0011976261 Test MSE 0.0003612160193327078 Test RE 0.04447801174592154\n",
      "195 Train Loss 0.001192988 Test MSE 0.0003608433460420271 Test RE 0.044455061428519106\n",
      "196 Train Loss 0.0011864984 Test MSE 0.00037269633786977165 Test RE 0.04517929261126068\n",
      "197 Train Loss 0.0011770419 Test MSE 0.0003606854437993216 Test RE 0.04444533376959205\n",
      "198 Train Loss 0.0011701763 Test MSE 0.00036763109052309 Test RE 0.04487123060084265\n",
      "199 Train Loss 0.0011592397 Test MSE 0.00037831374632993825 Test RE 0.045518498218859685\n",
      "200 Train Loss 0.0011434839 Test MSE 0.000390263292209882 Test RE 0.04623179076927368\n",
      "201 Train Loss 0.0011179097 Test MSE 0.0003932302655525696 Test RE 0.04640719641756597\n",
      "202 Train Loss 0.0010993788 Test MSE 0.0003882028119096206 Test RE 0.04610958383212924\n",
      "203 Train Loss 0.0010844653 Test MSE 0.0003765184182916945 Test RE 0.045410363342544585\n",
      "204 Train Loss 0.0010752277 Test MSE 0.0003738151012776041 Test RE 0.045247051614353107\n",
      "205 Train Loss 0.0010637915 Test MSE 0.0003907135574532399 Test RE 0.04625845298441531\n",
      "206 Train Loss 0.0010590723 Test MSE 0.00037907845978132833 Test RE 0.04556447994126259\n",
      "207 Train Loss 0.0010548973 Test MSE 0.0003616867066285947 Test RE 0.044506981141534264\n",
      "208 Train Loss 0.0010490281 Test MSE 0.0003567806034252505 Test RE 0.04420409279046377\n",
      "209 Train Loss 0.0010430054 Test MSE 0.00035716143233006556 Test RE 0.04422767830248377\n",
      "210 Train Loss 0.0010325077 Test MSE 0.0003398189627322428 Test RE 0.04314054914180687\n",
      "211 Train Loss 0.0010240992 Test MSE 0.0003381636668177707 Test RE 0.04303534967238605\n",
      "212 Train Loss 0.0010135842 Test MSE 0.00031589988038134955 Test RE 0.04159456576664479\n",
      "213 Train Loss 0.0010056704 Test MSE 0.00030788756421395015 Test RE 0.04106368671692161\n",
      "214 Train Loss 0.0009999588 Test MSE 0.0002893439570342008 Test RE 0.03980788208980129\n",
      "215 Train Loss 0.0009932305 Test MSE 0.0002817094212988102 Test RE 0.0392791923897463\n",
      "216 Train Loss 0.0009886603 Test MSE 0.00028849833130557096 Test RE 0.03974966901895011\n",
      "217 Train Loss 0.0009846732 Test MSE 0.0002875764450713765 Test RE 0.03968610887014119\n",
      "218 Train Loss 0.000980673 Test MSE 0.0002768090711647106 Test RE 0.03893606184588501\n",
      "219 Train Loss 0.0009757743 Test MSE 0.0002622122607694685 Test RE 0.03789556281966492\n",
      "220 Train Loss 0.00096937077 Test MSE 0.0002531454575398457 Test RE 0.03723462063838185\n",
      "221 Train Loss 0.00096546387 Test MSE 0.0002550874945469286 Test RE 0.03737717278137082\n",
      "222 Train Loss 0.00096093275 Test MSE 0.00024866132163470765 Test RE 0.03690336620006552\n",
      "223 Train Loss 0.00095661194 Test MSE 0.00023960565982854642 Test RE 0.03622516733523933\n",
      "224 Train Loss 0.0009536698 Test MSE 0.00023993200657475563 Test RE 0.03624982856989387\n",
      "225 Train Loss 0.0009494832 Test MSE 0.00023569751261390262 Test RE 0.035928522975912175\n",
      "226 Train Loss 0.0009413556 Test MSE 0.0002304448512926776 Test RE 0.03552592288186951\n",
      "227 Train Loss 0.00093543605 Test MSE 0.0002337173207317214 Test RE 0.03577727948131217\n",
      "228 Train Loss 0.00092898146 Test MSE 0.00023278661180804204 Test RE 0.0357059722940806\n",
      "229 Train Loss 0.00092162896 Test MSE 0.00023487681546395005 Test RE 0.035865916992591756\n",
      "230 Train Loss 0.0009120251 Test MSE 0.00022556645764117053 Test RE 0.03514787908644072\n",
      "231 Train Loss 0.00089473237 Test MSE 0.00021677746743273531 Test RE 0.03445632325489359\n",
      "232 Train Loss 0.0008807774 Test MSE 0.00020669498728036 Test RE 0.03364548834441854\n",
      "233 Train Loss 0.00086080097 Test MSE 0.00020566771029826506 Test RE 0.033561774926460355\n",
      "234 Train Loss 0.00084627705 Test MSE 0.0001925823544212706 Test RE 0.03247656662211875\n",
      "235 Train Loss 0.00082666107 Test MSE 0.000187550351645369 Test RE 0.03204946656161522\n",
      "236 Train Loss 0.0008176545 Test MSE 0.00019124398963519642 Test RE 0.03236352076842445\n",
      "237 Train Loss 0.0008079364 Test MSE 0.0001939863408966648 Test RE 0.03259473388220623\n",
      "238 Train Loss 0.00079642184 Test MSE 0.00019158304351510287 Test RE 0.03239219648824859\n",
      "239 Train Loss 0.0007854765 Test MSE 0.0001804751355392555 Test RE 0.03143913237830157\n",
      "240 Train Loss 0.0007778991 Test MSE 0.00017577659801559542 Test RE 0.031027186163989754\n",
      "241 Train Loss 0.00077232334 Test MSE 0.0001784571092997654 Test RE 0.03126286613300564\n",
      "242 Train Loss 0.000766232 Test MSE 0.0001713795632055849 Test RE 0.030636657387524\n",
      "243 Train Loss 0.000760411 Test MSE 0.0001640174899620721 Test RE 0.02997139412732089\n",
      "244 Train Loss 0.0007558817 Test MSE 0.00016249648599185568 Test RE 0.029832101700726754\n",
      "245 Train Loss 0.0007529168 Test MSE 0.00015867376858733062 Test RE 0.029479114390251245\n",
      "246 Train Loss 0.0007504388 Test MSE 0.0001604962938349249 Test RE 0.02964792942224553\n",
      "247 Train Loss 0.0007501562 Test MSE 0.0001616733651735992 Test RE 0.029756448990448464\n",
      "248 Train Loss 0.0007481494 Test MSE 0.00016592305442479508 Test RE 0.030144996029175874\n",
      "249 Train Loss 0.0007480178 Test MSE 0.00016585280271787516 Test RE 0.03013861366825835\n",
      "250 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "251 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "252 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "253 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "254 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "255 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "256 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "257 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "258 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "259 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "260 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "261 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "262 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "263 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "264 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "265 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "266 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "267 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "268 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "269 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "270 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "271 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "272 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "273 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "274 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "275 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "276 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "277 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "278 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "279 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "280 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "281 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "282 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "283 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "284 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "285 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "286 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "287 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "288 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "289 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "290 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "291 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "292 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "293 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "294 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "295 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "296 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "297 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "298 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "299 Train Loss 0.0007479679 Test MSE 0.0001658520817916751 Test RE 0.030138548165175246\n",
      "Training time: 218.11\n",
      "KG_atanh_low\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 9607.37 Test MSE 5.918072762153272 Test RE 5.69314197415734\n",
      "1 Train Loss 3769.5737 Test MSE 7.448059126337479 Test RE 6.386801547618322\n",
      "2 Train Loss 1637.1655 Test MSE 9.553258340483232 Test RE 7.233319109472757\n",
      "3 Train Loss 351.1141 Test MSE 11.253628861935752 Test RE 7.8506959555470415\n",
      "4 Train Loss 111.182014 Test MSE 12.511638771825238 Test RE 8.277876879309137\n",
      "5 Train Loss 49.43802 Test MSE 12.467828710789064 Test RE 8.263371492863813\n",
      "6 Train Loss 33.127785 Test MSE 12.484368055814175 Test RE 8.268850612759108\n",
      "7 Train Loss 25.08031 Test MSE 12.455972605209684 Test RE 8.259441590178037\n",
      "8 Train Loss 21.754461 Test MSE 12.2953582869065 Test RE 8.206017869272673\n",
      "9 Train Loss 19.395878 Test MSE 12.125139663463605 Test RE 8.149017283308632\n",
      "10 Train Loss 17.67674 Test MSE 11.897466791593573 Test RE 8.072147976450422\n",
      "11 Train Loss 15.597185 Test MSE 11.204125330201883 Test RE 7.833409730930224\n",
      "12 Train Loss 14.294812 Test MSE 10.716014461959237 Test RE 7.660877353276714\n",
      "13 Train Loss 13.197658 Test MSE 10.187147471480147 Test RE 7.469442022125768\n",
      "14 Train Loss 12.258052 Test MSE 9.669810211338387 Test RE 7.277309392242073\n",
      "15 Train Loss 11.557331 Test MSE 9.518542846196297 Test RE 7.220164603456928\n",
      "16 Train Loss 11.02629 Test MSE 9.063391481200874 Test RE 7.045425608640697\n",
      "17 Train Loss 10.395376 Test MSE 8.58753011584505 Test RE 6.857976626268504\n",
      "18 Train Loss 9.632662 Test MSE 7.719558575876434 Test RE 6.502166669362895\n",
      "19 Train Loss 8.594073 Test MSE 6.404088601520642 Test RE 5.92230172802544\n",
      "20 Train Loss 7.5874333 Test MSE 5.547014881641507 Test RE 5.51177562090058\n",
      "21 Train Loss 6.2458115 Test MSE 4.392989599205042 Test RE 4.905033203219931\n",
      "22 Train Loss 5.174217 Test MSE 3.002674065877125 Test RE 4.055234383555465\n",
      "23 Train Loss 3.7594972 Test MSE 1.5720943143265882 Test RE 2.934277358639624\n",
      "24 Train Loss 2.5558949 Test MSE 1.1423686983872865 Test RE 2.501295555214111\n",
      "25 Train Loss 1.3035916 Test MSE 0.17548255298263502 Test RE 0.9803447695136308\n",
      "26 Train Loss 0.88484305 Test MSE 0.04480736455480121 Test RE 0.4953778276970432\n",
      "27 Train Loss 0.6242382 Test MSE 0.04198724184144699 Test RE 0.4795352502742367\n",
      "28 Train Loss 0.44631928 Test MSE 0.02061531530466809 Test RE 0.33601359939033915\n",
      "29 Train Loss 0.32353002 Test MSE 0.017020712635307647 Test RE 0.3053168223919762\n",
      "30 Train Loss 0.25447845 Test MSE 0.012943834030931382 Test RE 0.2662522778031557\n",
      "31 Train Loss 0.22594488 Test MSE 0.010104178228395468 Test RE 0.23524064587378674\n",
      "32 Train Loss 0.17898265 Test MSE 0.009915091466447508 Test RE 0.23302913683355375\n",
      "33 Train Loss 0.15042742 Test MSE 0.008275694850451073 Test RE 0.21289433159865884\n",
      "34 Train Loss 0.122831255 Test MSE 0.009375263290867871 Test RE 0.2265967103263343\n",
      "35 Train Loss 0.10321138 Test MSE 0.008602693072109835 Test RE 0.21705963992017227\n",
      "36 Train Loss 0.0900286 Test MSE 0.006391411591561636 Test RE 0.18709417097762052\n",
      "37 Train Loss 0.07662815 Test MSE 0.00569091201873111 Test RE 0.1765439339447199\n",
      "38 Train Loss 0.066984706 Test MSE 0.004349494378198211 Test RE 0.15434097909536143\n",
      "39 Train Loss 0.061197504 Test MSE 0.003453198858970543 Test RE 0.13752215157821565\n",
      "40 Train Loss 0.05460182 Test MSE 0.0035665658629106005 Test RE 0.1397613182293171\n",
      "41 Train Loss 0.048526864 Test MSE 0.00347483920905545 Test RE 0.13795238737838156\n",
      "42 Train Loss 0.04509491 Test MSE 0.0036937743974422834 Test RE 0.14223191173554592\n",
      "43 Train Loss 0.03817815 Test MSE 0.003640187391966359 Test RE 0.14119643598742096\n",
      "44 Train Loss 0.03602051 Test MSE 0.003468218695636142 Test RE 0.13782090631976915\n",
      "45 Train Loss 0.033763487 Test MSE 0.003067839567113293 Test RE 0.12962184125780515\n",
      "46 Train Loss 0.031432718 Test MSE 0.002843138300148536 Test RE 0.12478456141957596\n",
      "47 Train Loss 0.029731382 Test MSE 0.0023336175842724105 Test RE 0.11305159873242403\n",
      "48 Train Loss 0.028130455 Test MSE 0.002194141817952381 Test RE 0.1096211140520986\n",
      "49 Train Loss 0.025466349 Test MSE 0.002550744617922419 Test RE 0.11819397902837103\n",
      "50 Train Loss 0.024279311 Test MSE 0.002676043549271138 Test RE 0.12106216949379549\n",
      "51 Train Loss 0.02323607 Test MSE 0.0025928989733169576 Test RE 0.1191666311333669\n",
      "52 Train Loss 0.021766158 Test MSE 0.0024507562675797046 Test RE 0.11585423798035144\n",
      "53 Train Loss 0.021276897 Test MSE 0.002481213889096426 Test RE 0.11657192435663914\n",
      "54 Train Loss 0.018898834 Test MSE 0.002362933419641536 Test RE 0.11375948214191021\n",
      "55 Train Loss 0.018427178 Test MSE 0.002328297222963006 Test RE 0.11292265331957144\n",
      "56 Train Loss 0.016493097 Test MSE 0.002128253563040447 Test RE 0.10796265313497543\n",
      "57 Train Loss 0.015926706 Test MSE 0.002209708894210962 Test RE 0.11000929865317212\n",
      "58 Train Loss 0.015711889 Test MSE 0.002209845778957402 Test RE 0.11001270597116551\n",
      "59 Train Loss 0.014792656 Test MSE 0.002033391066449325 Test RE 0.10552912073622094\n",
      "60 Train Loss 0.014141546 Test MSE 0.0021251920027193848 Test RE 0.1078849713358492\n",
      "61 Train Loss 0.013767904 Test MSE 0.00214626375947689 Test RE 0.10841850395346801\n",
      "62 Train Loss 0.0128898015 Test MSE 0.002186612337046925 Test RE 0.10943286290896752\n",
      "63 Train Loss 0.012036797 Test MSE 0.001933908049827093 Test RE 0.10291525977439725\n",
      "64 Train Loss 0.011715308 Test MSE 0.002021609795814334 Test RE 0.10522296388571967\n",
      "65 Train Loss 0.011538204 Test MSE 0.001945956442155902 Test RE 0.1032353469038836\n",
      "66 Train Loss 0.011257592 Test MSE 0.0017447052691741934 Test RE 0.09775138070675718\n",
      "67 Train Loss 0.01076081 Test MSE 0.0016602746202149996 Test RE 0.09535683514946898\n",
      "68 Train Loss 0.010419218 Test MSE 0.0017230378784250855 Test RE 0.09714250010242576\n",
      "69 Train Loss 0.0098820925 Test MSE 0.0017611152884353773 Test RE 0.09821001054337186\n",
      "70 Train Loss 0.009664517 Test MSE 0.001706714031327048 Test RE 0.09668124704188477\n",
      "71 Train Loss 0.009414533 Test MSE 0.0016978229546714774 Test RE 0.09642908915130845\n",
      "72 Train Loss 0.00853001 Test MSE 0.0018096157634015222 Test RE 0.09955315988619516\n",
      "73 Train Loss 0.008039628 Test MSE 0.001788371759539429 Test RE 0.0989670820417737\n",
      "74 Train Loss 0.007770092 Test MSE 0.0019712150794131606 Test RE 0.10390318739260247\n",
      "75 Train Loss 0.007658024 Test MSE 0.0020308671048826932 Test RE 0.10546360600240952\n",
      "76 Train Loss 0.007476946 Test MSE 0.0020992261263467083 Test RE 0.10722386936265636\n",
      "77 Train Loss 0.00715423 Test MSE 0.001816129196126893 Test RE 0.09973216207740072\n",
      "78 Train Loss 0.007038114 Test MSE 0.001791276103124014 Test RE 0.09904741148207491\n",
      "79 Train Loss 0.006930936 Test MSE 0.0017338432255666954 Test RE 0.09744661934433037\n",
      "80 Train Loss 0.00669817 Test MSE 0.0016291813766032418 Test RE 0.09445970447608831\n",
      "81 Train Loss 0.0063638347 Test MSE 0.001565657589311866 Test RE 0.09259984458873302\n",
      "82 Train Loss 0.006189713 Test MSE 0.0015831359404226606 Test RE 0.09311528314994798\n",
      "83 Train Loss 0.0060062665 Test MSE 0.0015086241891856887 Test RE 0.09089759600948888\n",
      "84 Train Loss 0.0059220595 Test MSE 0.0014681717397269924 Test RE 0.08967064510714065\n",
      "85 Train Loss 0.00566731 Test MSE 0.0013151023445875042 Test RE 0.08486754514127638\n",
      "86 Train Loss 0.005557746 Test MSE 0.0013057788463652538 Test RE 0.08456617322573451\n",
      "87 Train Loss 0.005398577 Test MSE 0.0011944397242915825 Test RE 0.08088052904318681\n",
      "88 Train Loss 0.005335328 Test MSE 0.0011960922994235562 Test RE 0.08093646110415577\n",
      "89 Train Loss 0.00526005 Test MSE 0.0012019956884781935 Test RE 0.0811359487678371\n",
      "90 Train Loss 0.005060203 Test MSE 0.0012183480721264669 Test RE 0.08168598574343298\n",
      "91 Train Loss 0.0048720953 Test MSE 0.0013197937504761355 Test RE 0.08501878570937711\n",
      "92 Train Loss 0.004700482 Test MSE 0.0012812784144567817 Test RE 0.08376905552152152\n",
      "93 Train Loss 0.004633774 Test MSE 0.0012832034468786926 Test RE 0.08383196051611937\n",
      "94 Train Loss 0.004553321 Test MSE 0.0012817055522169505 Test RE 0.08378301733683907\n",
      "95 Train Loss 0.0044222367 Test MSE 0.0013558761727956912 Test RE 0.08617313211804375\n",
      "96 Train Loss 0.0043465453 Test MSE 0.0014072479135759479 Test RE 0.0877904288966027\n",
      "97 Train Loss 0.0042907805 Test MSE 0.0014218395305232263 Test RE 0.08824440035054694\n",
      "98 Train Loss 0.0042099385 Test MSE 0.00139825378541818 Test RE 0.08750943219137973\n",
      "99 Train Loss 0.004023353 Test MSE 0.0013393862796026996 Test RE 0.08564751898221515\n",
      "100 Train Loss 0.003948167 Test MSE 0.0013511738932484724 Test RE 0.08602357491654554\n",
      "101 Train Loss 0.0039222636 Test MSE 0.0013401699171069334 Test RE 0.08567257030418945\n",
      "102 Train Loss 0.0039057725 Test MSE 0.0013440639652406024 Test RE 0.08579694674331817\n",
      "103 Train Loss 0.0038271938 Test MSE 0.0013526666687279302 Test RE 0.08607108117596586\n",
      "104 Train Loss 0.0036497295 Test MSE 0.0014029059682571334 Test RE 0.08765488926699717\n",
      "105 Train Loss 0.0033795808 Test MSE 0.0013862690001148828 Test RE 0.08713359241390084\n",
      "106 Train Loss 0.0032751297 Test MSE 0.0013676755082281337 Test RE 0.08654727511633445\n",
      "107 Train Loss 0.0032457758 Test MSE 0.0013688277312693632 Test RE 0.08658372410210814\n",
      "108 Train Loss 0.0032122524 Test MSE 0.0013564897258537196 Test RE 0.08619262719061649\n",
      "109 Train Loss 0.0031869845 Test MSE 0.001400062027059114 Test RE 0.08756599812919247\n",
      "110 Train Loss 0.0031402765 Test MSE 0.0013682230449070887 Test RE 0.0865645975972272\n",
      "111 Train Loss 0.0030497622 Test MSE 0.001364705247686158 Test RE 0.08645324415691703\n",
      "112 Train Loss 0.002943104 Test MSE 0.0013842297483792284 Test RE 0.08706948049775201\n",
      "113 Train Loss 0.0028807635 Test MSE 0.0013990849092823244 Test RE 0.08753543618776606\n",
      "114 Train Loss 0.0028512592 Test MSE 0.0013527794197108248 Test RE 0.08607466831129026\n",
      "115 Train Loss 0.002823467 Test MSE 0.0013833435349484757 Test RE 0.08704160416534264\n",
      "116 Train Loss 0.00278007 Test MSE 0.0013632388816246684 Test RE 0.08640678497622938\n",
      "117 Train Loss 0.0026368385 Test MSE 0.0013333794415177009 Test RE 0.08545524849815307\n",
      "118 Train Loss 0.0025100796 Test MSE 0.0013279631077829249 Test RE 0.08528150757751539\n",
      "119 Train Loss 0.0024469602 Test MSE 0.0013505152966142942 Test RE 0.08600260731843716\n",
      "120 Train Loss 0.0024083145 Test MSE 0.0012798253714979431 Test RE 0.08372154259854096\n",
      "121 Train Loss 0.0023905034 Test MSE 0.0012735291969351256 Test RE 0.08351535222123466\n",
      "122 Train Loss 0.0023652494 Test MSE 0.0012944292979741897 Test RE 0.0841978556662588\n",
      "123 Train Loss 0.002312813 Test MSE 0.001338284024811407 Test RE 0.08561226969661176\n",
      "124 Train Loss 0.0022431966 Test MSE 0.0013407325593130784 Test RE 0.08569055233212254\n",
      "125 Train Loss 0.0021420503 Test MSE 0.0012698093468759511 Test RE 0.0833932930742863\n",
      "126 Train Loss 0.0020466694 Test MSE 0.0012450121906601996 Test RE 0.0825750158995531\n",
      "127 Train Loss 0.0019874857 Test MSE 0.0012275213383052914 Test RE 0.0819929268062641\n",
      "128 Train Loss 0.0019636583 Test MSE 0.0012379971965338957 Test RE 0.08234205371480405\n",
      "129 Train Loss 0.0019519292 Test MSE 0.0012242594658951021 Test RE 0.08188391510649806\n",
      "130 Train Loss 0.0019333146 Test MSE 0.0012028607120777757 Test RE 0.08116513850973642\n",
      "131 Train Loss 0.0019019627 Test MSE 0.0011700466795871087 Test RE 0.08005039113706186\n",
      "132 Train Loss 0.0018163178 Test MSE 0.0012349195727054045 Test RE 0.08223964009033005\n",
      "133 Train Loss 0.0017784011 Test MSE 0.001176750657301621 Test RE 0.08027939461481756\n",
      "134 Train Loss 0.0017650063 Test MSE 0.0011669454326608132 Test RE 0.07994423265858139\n",
      "135 Train Loss 0.0017488986 Test MSE 0.0011738896649681647 Test RE 0.08018174499655994\n",
      "136 Train Loss 0.0017326142 Test MSE 0.0011820178703077745 Test RE 0.08045886192603642\n",
      "137 Train Loss 0.0017024179 Test MSE 0.0011641821738655389 Test RE 0.07984952491715995\n",
      "138 Train Loss 0.001682722 Test MSE 0.0011912344499159242 Test RE 0.08077193484794801\n",
      "139 Train Loss 0.0016653496 Test MSE 0.0011749403476192276 Test RE 0.08021762005725636\n",
      "140 Train Loss 0.0016528722 Test MSE 0.0011748847368162087 Test RE 0.0802157216548978\n",
      "141 Train Loss 0.0016382405 Test MSE 0.0011775379497978404 Test RE 0.08030624516159204\n",
      "142 Train Loss 0.001613578 Test MSE 0.0011551638016521826 Test RE 0.07953964525458322\n",
      "143 Train Loss 0.0015883426 Test MSE 0.0011647106034346644 Test RE 0.0798676449605491\n",
      "144 Train Loss 0.0015621951 Test MSE 0.0011812200105523433 Test RE 0.08043170255475064\n",
      "145 Train Loss 0.0015285976 Test MSE 0.0011708937925742188 Test RE 0.0800793641078282\n",
      "146 Train Loss 0.0014925321 Test MSE 0.001173970466343924 Test RE 0.08018450449092145\n",
      "147 Train Loss 0.001434628 Test MSE 0.0011022675451535168 Test RE 0.07769720106512054\n",
      "148 Train Loss 0.0014048743 Test MSE 0.0010826796440134 Test RE 0.07700374546354197\n",
      "149 Train Loss 0.0013826209 Test MSE 0.0010632068734273666 Test RE 0.07630811961982772\n",
      "150 Train Loss 0.0013773779 Test MSE 0.0010543510365844063 Test RE 0.07598965603880024\n",
      "151 Train Loss 0.0013719572 Test MSE 0.0010346921949686853 Test RE 0.07527789225914819\n",
      "152 Train Loss 0.001366264 Test MSE 0.0010263333430311202 Test RE 0.07497320611475534\n",
      "153 Train Loss 0.0013588313 Test MSE 0.0010283253242135192 Test RE 0.07504592752736745\n",
      "154 Train Loss 0.0013528644 Test MSE 0.00100503213096818 Test RE 0.07419110461546737\n",
      "155 Train Loss 0.0013408822 Test MSE 0.0009879466575680416 Test RE 0.07355777975745628\n",
      "156 Train Loss 0.0013290044 Test MSE 0.000981973687434325 Test RE 0.0733350832655644\n",
      "157 Train Loss 0.001319605 Test MSE 0.0009677285842717108 Test RE 0.07280121855507549\n",
      "158 Train Loss 0.0013027594 Test MSE 0.0009171993965803331 Test RE 0.07087510971798554\n",
      "159 Train Loss 0.001283998 Test MSE 0.0009245429054548942 Test RE 0.0711582729897533\n",
      "160 Train Loss 0.0012681833 Test MSE 0.0008998860609642897 Test RE 0.07020299273961103\n",
      "161 Train Loss 0.0012476963 Test MSE 0.0008595688852293855 Test RE 0.06861233624483964\n",
      "162 Train Loss 0.0012277197 Test MSE 0.0008846050480441781 Test RE 0.06960438021973525\n",
      "163 Train Loss 0.0012071034 Test MSE 0.0008425709931924254 Test RE 0.06793054766366043\n",
      "164 Train Loss 0.0011955687 Test MSE 0.0008071544239148169 Test RE 0.06648752700925717\n",
      "165 Train Loss 0.0011880295 Test MSE 0.0008043352300465999 Test RE 0.06637131307236992\n",
      "166 Train Loss 0.0011764049 Test MSE 0.0007653607094697607 Test RE 0.06474331698869745\n",
      "167 Train Loss 0.0011623472 Test MSE 0.0007448395096580487 Test RE 0.06386945595284568\n",
      "168 Train Loss 0.0011504905 Test MSE 0.000717435283112363 Test RE 0.06268349883065029\n",
      "169 Train Loss 0.001134327 Test MSE 0.0007356651047767177 Test RE 0.06347488785284186\n",
      "170 Train Loss 0.001120625 Test MSE 0.0007015336143585051 Test RE 0.06198492880242242\n",
      "171 Train Loss 0.0011141399 Test MSE 0.000685281817968188 Test RE 0.061262747298142566\n",
      "172 Train Loss 0.001106662 Test MSE 0.0006665166478320528 Test RE 0.06041814188650866\n",
      "173 Train Loss 0.001100326 Test MSE 0.0006645438040401939 Test RE 0.060328658833098577\n",
      "174 Train Loss 0.0010904928 Test MSE 0.0006517978204607871 Test RE 0.059747304379773436\n",
      "175 Train Loss 0.0010802856 Test MSE 0.0006539061552916527 Test RE 0.05984385703646652\n",
      "176 Train Loss 0.0010652149 Test MSE 0.0006365828749043865 Test RE 0.0590458446627272\n",
      "177 Train Loss 0.0010443135 Test MSE 0.0005958964814734843 Test RE 0.05712777039687938\n",
      "178 Train Loss 0.0010321571 Test MSE 0.0005692751707097446 Test RE 0.05583711681736145\n",
      "179 Train Loss 0.0010151422 Test MSE 0.0005538204519509439 Test RE 0.05507396685751197\n",
      "180 Train Loss 0.0009976092 Test MSE 0.000530051410052989 Test RE 0.05387916556579965\n",
      "181 Train Loss 0.0009824826 Test MSE 0.0005522784798974508 Test RE 0.05499724369643492\n",
      "182 Train Loss 0.00096738304 Test MSE 0.0005316218880769901 Test RE 0.053958925245502276\n",
      "183 Train Loss 0.0009534537 Test MSE 0.0005444367732183124 Test RE 0.05460539961336103\n",
      "184 Train Loss 0.00094335777 Test MSE 0.0005397547002391918 Test RE 0.054370093579578116\n",
      "185 Train Loss 0.0009350261 Test MSE 0.000533637033174776 Test RE 0.05406109580999577\n",
      "186 Train Loss 0.0009263145 Test MSE 0.000512764874580004 Test RE 0.05299330403065923\n",
      "187 Train Loss 0.00091866957 Test MSE 0.0005013919780210483 Test RE 0.05240232480071625\n",
      "188 Train Loss 0.0009146627 Test MSE 0.00049669575069104 Test RE 0.052156337423662935\n",
      "189 Train Loss 0.0009000736 Test MSE 0.0004463613303069707 Test RE 0.04944303774775819\n",
      "190 Train Loss 0.00088757544 Test MSE 0.00044489379733464484 Test RE 0.04936169218643349\n",
      "191 Train Loss 0.00087452075 Test MSE 0.00043633375608934647 Test RE 0.04888451045121269\n",
      "192 Train Loss 0.0008643264 Test MSE 0.00040444380808387894 Test RE 0.04706423018709301\n",
      "193 Train Loss 0.0008553958 Test MSE 0.0004025548943180744 Test RE 0.0469541972065813\n",
      "194 Train Loss 0.0008485965 Test MSE 0.0003987394659460229 Test RE 0.04673115073426612\n",
      "195 Train Loss 0.0008426547 Test MSE 0.00039433537181263916 Test RE 0.04647236040220958\n",
      "196 Train Loss 0.0008342053 Test MSE 0.00040345074690265677 Test RE 0.04700641451037389\n",
      "197 Train Loss 0.00083133904 Test MSE 0.0004095393515326479 Test RE 0.04735978075129365\n",
      "198 Train Loss 0.0008259259 Test MSE 0.00039815034926745675 Test RE 0.04669661656001544\n",
      "199 Train Loss 0.0008172401 Test MSE 0.00040007019737711295 Test RE 0.04680906478371881\n",
      "200 Train Loss 0.00080685003 Test MSE 0.0004048309012350091 Test RE 0.047086747386911584\n",
      "201 Train Loss 0.000796928 Test MSE 0.00038718145506706975 Test RE 0.04604888700758076\n",
      "202 Train Loss 0.00078725803 Test MSE 0.0003706815994581962 Test RE 0.04505701101547835\n",
      "203 Train Loss 0.00076958153 Test MSE 0.0003322757325250284 Test RE 0.042659049650188734\n",
      "204 Train Loss 0.00076166505 Test MSE 0.0003183450732493422 Test RE 0.04175523483789964\n",
      "205 Train Loss 0.00074669934 Test MSE 0.00031187533066651883 Test RE 0.04132876005273664\n",
      "206 Train Loss 0.00073779305 Test MSE 0.0002911639311773191 Test RE 0.03993288167013397\n",
      "207 Train Loss 0.0007274229 Test MSE 0.00029711506220273225 Test RE 0.04033891367154432\n",
      "208 Train Loss 0.00071143615 Test MSE 0.0002777546047658943 Test RE 0.03900250470019868\n",
      "209 Train Loss 0.0007000877 Test MSE 0.000267075180171168 Test RE 0.03824534906360156\n",
      "210 Train Loss 0.00069230876 Test MSE 0.0002608890626035996 Test RE 0.03779982595633008\n",
      "211 Train Loss 0.0006883015 Test MSE 0.00025082139558892824 Test RE 0.037063305897086105\n",
      "212 Train Loss 0.0006858383 Test MSE 0.00023630835515725895 Test RE 0.03597504970640724\n",
      "213 Train Loss 0.0006831277 Test MSE 0.00023100384169951304 Test RE 0.03556898442515981\n",
      "214 Train Loss 0.0006806182 Test MSE 0.00022127355224509126 Test RE 0.03481181108091947\n",
      "215 Train Loss 0.00067782844 Test MSE 0.00022070328774570448 Test RE 0.034766923775381674\n",
      "216 Train Loss 0.0006756433 Test MSE 0.0002229222759268697 Test RE 0.034941262928278795\n",
      "217 Train Loss 0.0006749474 Test MSE 0.00021838613096920843 Test RE 0.03458393379482176\n",
      "218 Train Loss 0.0006749125 Test MSE 0.00021816412279821368 Test RE 0.03456635056240578\n",
      "219 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "220 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "221 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "222 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "223 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "224 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "225 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "226 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "227 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "228 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "229 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "230 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "231 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "232 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "233 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "234 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "235 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "236 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "237 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "238 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "239 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "240 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "241 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "242 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "243 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "244 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "245 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "246 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "247 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "248 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "249 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "250 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "251 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "252 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "253 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "254 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "255 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "256 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "257 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "258 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "259 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "260 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "261 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "262 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "263 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "264 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "265 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "266 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "267 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "268 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "269 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "270 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "271 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "272 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "273 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "274 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "275 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "276 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "277 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "278 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "279 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "280 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "281 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "282 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "283 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "284 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "285 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "286 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "287 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "288 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "289 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "290 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "291 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "292 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "293 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "294 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "295 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "296 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "297 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "298 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "299 Train Loss 0.0006748583 Test MSE 0.00021783066097621836 Test RE 0.034539923288253456\n",
      "Training time: 201.21\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3340158910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.01945364103593722\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
