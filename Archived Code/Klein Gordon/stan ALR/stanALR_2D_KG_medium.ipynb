{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"medium\"\n",
    "label = \"KG_stanALR_\" + level\n",
    "\n",
    "x = np.linspace(0,2,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "        \n",
    "        beta_mean = 1.0*torch.ones((50,len(layers)-2))\n",
    "        beta_std = 0.01*torch.ones((50,len(layers)-2))\n",
    "        \n",
    "        self.beta = Parameter(torch.normal(beta_mean,beta_std))\n",
    "        self.beta.requiresGrad = True\n",
    "        \n",
    "        self.lambdas = torch.ones((2,),device = device)\n",
    "        self.lambda_alpha = 0.1\n",
    "\n",
    "            \n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            z1 = self.activation(z)\n",
    "            a = z1 + self.beta[:,i]*z*z1            \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.lambdas[0]*self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.lambdas[1]*self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    def lambda_update(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "        loss_bc1 = self.lambdas[0]*self.loss_BC(xt_BC,y_BC)\n",
    "        loss_bc1.backward()\n",
    "        bc1_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc1_grads.append(param.grad.view(-1))\n",
    "        bc1_grads = torch.cat(bc1_grads)\n",
    "        bc1_grads = torch.mean(torch.abs(bc1_grads))      \n",
    "        \n",
    "        loss_bc2 = self.lambdas[1]*self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_bc2.backward()\n",
    "        bc2_grads = []\n",
    "        for param in self.parameters():\n",
    "            bc2_grads.append(param.grad.view(-1))\n",
    "        bc2_grads = torch.cat(bc2_grads)\n",
    "        bc2_grads = torch.mean(torch.abs(bc2_grads))    \n",
    "    \n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        loss_f.backward()\n",
    "        f_grads = []\n",
    "        for param in self.parameters():\n",
    "            f_grads.append(param.grad.view(-1))   \n",
    "        f_grads = torch.cat(f_grads)\n",
    "        f_grads = torch.max(torch.abs(f_grads))\n",
    "    \n",
    "        self.lambdas[0] = (1.0-self.lambda_alpha)*self.lambdas[0] + self.lambda_alpha*f_grads/bc1_grads\n",
    "        self.lambdas[1] = (1.0-self.lambda_alpha)*self.lambdas[1] + self.lambda_alpha*f_grads/bc2_grads\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    PINN.lambda_update(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_stanALR_medium\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 22130.084 Test MSE 15.775488376484642 Test RE 2.877789834396277\n",
      "1 Train Loss 3799.4766 Test MSE 6.606810458430139 Test RE 1.8623598122009095\n",
      "2 Train Loss 659.9066 Test MSE 7.279125018184339 Test RE 1.9548221747397176\n",
      "3 Train Loss 354.65375 Test MSE 6.701154727389344 Test RE 1.8756097882681524\n",
      "4 Train Loss 236.15079 Test MSE 7.00257555758825 Test RE 1.9173286834994192\n",
      "5 Train Loss 136.81723 Test MSE 3.7050149983032408 Test RE 1.3946417202613306\n",
      "6 Train Loss 42.641605 Test MSE 0.3853746568907114 Test RE 0.4497894277579186\n",
      "7 Train Loss 17.409985 Test MSE 0.10311643925300479 Test RE 0.23266530251096257\n",
      "8 Train Loss 8.091065 Test MSE 0.03429007140023678 Test RE 0.13416890098428894\n",
      "9 Train Loss 4.797705 Test MSE 0.025958990639966647 Test RE 0.11673781722487454\n",
      "10 Train Loss 2.7200105 Test MSE 0.0070469288788200584 Test RE 0.06082296843428286\n",
      "11 Train Loss 1.5923812 Test MSE 0.003283620059877171 Test RE 0.041518735462296744\n",
      "12 Train Loss 1.0928798 Test MSE 0.001502488273256117 Test RE 0.0280849214265545\n",
      "13 Train Loss 0.77916455 Test MSE 0.0005561884492308509 Test RE 0.01708750482884307\n",
      "14 Train Loss 0.5552632 Test MSE 0.0003088143685124242 Test RE 0.01273258010468796\n",
      "15 Train Loss 0.4739407 Test MSE 0.00030074868605775226 Test RE 0.012565203799476846\n",
      "16 Train Loss 0.39442623 Test MSE 0.00038776670909173834 Test RE 0.014267665801485528\n",
      "17 Train Loss 0.32942247 Test MSE 0.00038567191445865374 Test RE 0.014229075196001197\n",
      "18 Train Loss 0.27328315 Test MSE 0.0005824456952604648 Test RE 0.01748619783384339\n",
      "19 Train Loss 0.24622253 Test MSE 0.0005421645248967408 Test RE 0.016870704410858972\n",
      "20 Train Loss 0.21425281 Test MSE 0.00044364265633646934 Test RE 0.015261046517858302\n",
      "21 Train Loss 0.17813912 Test MSE 0.00026382072185853557 Test RE 0.01176852731822636\n",
      "22 Train Loss 0.16025798 Test MSE 0.00014911526750594457 Test RE 0.008847666081579202\n",
      "23 Train Loss 0.13842934 Test MSE 0.0001114302789347766 Test RE 0.007648376817779008\n",
      "24 Train Loss 0.12502134 Test MSE 0.00010477118160774775 Test RE 0.007416322187280094\n",
      "25 Train Loss 0.10575085 Test MSE 7.89730224252476e-05 Test RE 0.006438831312472741\n",
      "26 Train Loss 0.09490118 Test MSE 7.63930098145025e-05 Test RE 0.006332781126891403\n",
      "27 Train Loss 0.08280889 Test MSE 9.881657110596231e-05 Test RE 0.00720248823646019\n",
      "28 Train Loss 0.074506916 Test MSE 8.969472559046769e-05 Test RE 0.006862006425962621\n",
      "29 Train Loss 0.06584386 Test MSE 6.913066733528805e-05 Test RE 0.006024250776069405\n",
      "30 Train Loss 0.059083197 Test MSE 5.845563457072085e-05 Test RE 0.00553963126044062\n",
      "31 Train Loss 0.05088234 Test MSE 3.7894735398792785e-05 Test RE 0.004460228486507136\n",
      "32 Train Loss 0.046849325 Test MSE 3.1770635102266014e-05 Test RE 0.004083951876685149\n",
      "33 Train Loss 0.041930582 Test MSE 2.737235301117937e-05 Test RE 0.0037907376941243983\n",
      "34 Train Loss 0.039604492 Test MSE 2.3723895457458068e-05 Test RE 0.003529073215097173\n",
      "35 Train Loss 0.035149824 Test MSE 3.7290622034639485e-05 Test RE 0.004424533437412224\n",
      "36 Train Loss 0.030425614 Test MSE 3.866692676406108e-05 Test RE 0.00450544295777286\n",
      "37 Train Loss 0.028837923 Test MSE 3.7402443958055775e-05 Test RE 0.004431162309003266\n",
      "38 Train Loss 0.027029376 Test MSE 3.435131258625411e-05 Test RE 0.004246580252348547\n",
      "39 Train Loss 0.026223803 Test MSE 3.0693333497244136e-05 Test RE 0.004014113949720457\n",
      "40 Train Loss 0.023777228 Test MSE 2.681331901496911e-05 Test RE 0.0037518283029291596\n",
      "41 Train Loss 0.023071874 Test MSE 2.5595777620015148e-05 Test RE 0.0036656570568459512\n",
      "42 Train Loss 0.021162404 Test MSE 2.8331798302728606e-05 Test RE 0.003856601255704189\n",
      "43 Train Loss 0.02039978 Test MSE 2.3090125031775404e-05 Test RE 0.003481615522484218\n",
      "44 Train Loss 0.01886512 Test MSE 3.232463073629216e-05 Test RE 0.0041194046399821325\n",
      "45 Train Loss 0.018467546 Test MSE 3.5629522669181665e-05 Test RE 0.004324866136577099\n",
      "46 Train Loss 0.017782042 Test MSE 2.9106734417612776e-05 Test RE 0.003908988648412598\n",
      "47 Train Loss 0.016944962 Test MSE 2.41754868179861e-05 Test RE 0.003562503352663342\n",
      "48 Train Loss 0.016516076 Test MSE 2.2548710721186305e-05 Test RE 0.0034405551615778315\n",
      "49 Train Loss 0.015972722 Test MSE 2.3313130913861855e-05 Test RE 0.003498387953515146\n",
      "50 Train Loss 0.01500697 Test MSE 1.963889043641832e-05 Test RE 0.0032108952765888803\n",
      "51 Train Loss 0.014981778 Test MSE 2.127628884180967e-05 Test RE 0.003342070495867277\n",
      "52 Train Loss 0.014153564 Test MSE 2.2318039147685902e-05 Test RE 0.0034229116154336305\n",
      "53 Train Loss 0.013274639 Test MSE 1.6568976440849347e-05 Test RE 0.0029492766189086997\n",
      "54 Train Loss 0.012890404 Test MSE 1.677479345126923e-05 Test RE 0.0029675377911882422\n",
      "55 Train Loss 0.01193447 Test MSE 9.884716977771101e-06 Test RE 0.002277979372436753\n",
      "56 Train Loss 0.010975574 Test MSE 8.479750306118264e-06 Test RE 0.002109887017126386\n",
      "57 Train Loss 0.010656826 Test MSE 6.916667954158311e-06 Test RE 0.0019055314948299372\n",
      "58 Train Loss 0.010262522 Test MSE 6.0859539311049894e-06 Test RE 0.0017874421624618254\n",
      "59 Train Loss 0.009906241 Test MSE 6.7087008129108025e-06 Test RE 0.0018766655413556435\n",
      "60 Train Loss 0.0096100215 Test MSE 7.477225187579237e-06 Test RE 0.001981243696314664\n",
      "61 Train Loss 0.009236154 Test MSE 7.598651439239303e-06 Test RE 0.0019972660934884437\n",
      "62 Train Loss 0.009173136 Test MSE 5.151487019107826e-06 Test RE 0.001644500358730089\n",
      "63 Train Loss 0.008721807 Test MSE 6.089664776835822e-06 Test RE 0.0017879870163509987\n",
      "64 Train Loss 0.008258549 Test MSE 6.449875818157555e-06 Test RE 0.001840108130208604\n",
      "65 Train Loss 0.008018456 Test MSE 8.389891375782426e-06 Test RE 0.0020986781292315288\n",
      "66 Train Loss 0.0078505045 Test MSE 7.320290548237924e-06 Test RE 0.001960341920541997\n",
      "67 Train Loss 0.00765873 Test MSE 6.217151355387566e-06 Test RE 0.0018066057485468946\n",
      "68 Train Loss 0.007247018 Test MSE 4.881665633114761e-06 Test RE 0.0016008538408647701\n",
      "69 Train Loss 0.0070879697 Test MSE 6.281335357441102e-06 Test RE 0.0018159072311501937\n",
      "70 Train Loss 0.0068735904 Test MSE 7.0176295765980545e-06 Test RE 0.0019193884975132974\n",
      "71 Train Loss 0.0066346256 Test MSE 8.992090599819623e-06 Test RE 0.0021726911964389927\n",
      "72 Train Loss 0.0064278864 Test MSE 8.158978878177602e-06 Test RE 0.0020695959796904508\n",
      "73 Train Loss 0.006147865 Test MSE 6.961041546777824e-06 Test RE 0.0019116341512612149\n",
      "74 Train Loss 0.0057532266 Test MSE 9.84677389245601e-06 Test RE 0.0022736030877860565\n",
      "75 Train Loss 0.0055313385 Test MSE 1.0225000966020664e-05 Test RE 0.002316857625309637\n",
      "76 Train Loss 0.0054338453 Test MSE 1.0684864327425453e-05 Test RE 0.0023683843009466286\n",
      "77 Train Loss 0.0053401412 Test MSE 9.797721281767834e-06 Test RE 0.00226793293582308\n",
      "78 Train Loss 0.005174037 Test MSE 1.0904259568143258e-05 Test RE 0.0023925760890221785\n",
      "79 Train Loss 0.0049215583 Test MSE 1.0062497119401666e-05 Test RE 0.002298373217025508\n",
      "80 Train Loss 0.00466343 Test MSE 7.262992738809616e-06 Test RE 0.0019526547968308362\n",
      "81 Train Loss 0.0045898147 Test MSE 7.015976888666665e-06 Test RE 0.001919162471263459\n",
      "82 Train Loss 0.0046314206 Test MSE 7.363654168536555e-06 Test RE 0.0019661396414566643\n",
      "83 Train Loss 0.0045457454 Test MSE 6.9043007877193255e-06 Test RE 0.0019038271648773653\n",
      "84 Train Loss 0.004465496 Test MSE 7.432418546955618e-06 Test RE 0.0019752985587125466\n",
      "85 Train Loss 0.004310151 Test MSE 8.230806826648175e-06 Test RE 0.002078685909658059\n",
      "86 Train Loss 0.0042233933 Test MSE 8.781538052636692e-06 Test RE 0.0021471034088272954\n",
      "87 Train Loss 0.0041332105 Test MSE 8.932654980549833e-06 Test RE 0.002165498800971303\n",
      "88 Train Loss 0.0040294607 Test MSE 7.031374334929131e-06 Test RE 0.001921267239162803\n",
      "89 Train Loss 0.0039476915 Test MSE 6.779237527839178e-06 Test RE 0.0018865055753358607\n",
      "90 Train Loss 0.0038622918 Test MSE 6.1708196557750615e-06 Test RE 0.001799861530997499\n",
      "91 Train Loss 0.003819819 Test MSE 6.184622747470385e-06 Test RE 0.0018018734012090552\n",
      "92 Train Loss 0.0037519843 Test MSE 6.187512833828118e-06 Test RE 0.0018022943615257163\n",
      "93 Train Loss 0.003717472 Test MSE 6.11748869955285e-06 Test RE 0.001792067053409984\n",
      "94 Train Loss 0.0037100073 Test MSE 6.241918103264375e-06 Test RE 0.0018102005843954336\n",
      "95 Train Loss 0.0036176804 Test MSE 6.410118123347425e-06 Test RE 0.0018344280560962142\n",
      "96 Train Loss 0.0035212594 Test MSE 6.378834137962235e-06 Test RE 0.0018299462033249806\n",
      "97 Train Loss 0.0034315903 Test MSE 6.502659589160103e-06 Test RE 0.0018476222236486323\n",
      "98 Train Loss 0.003381905 Test MSE 6.533926915189534e-06 Test RE 0.0018520589411707834\n",
      "99 Train Loss 0.0033335353 Test MSE 6.011670668961768e-06 Test RE 0.0017765001896274417\n",
      "100 Train Loss 0.0032605508 Test MSE 5.946480089649212e-06 Test RE 0.0017668417468432928\n",
      "101 Train Loss 0.0032283429 Test MSE 6.294645467199589e-06 Test RE 0.0018178301609693974\n",
      "102 Train Loss 0.0031721636 Test MSE 6.204945440651158e-06 Test RE 0.0018048314544828635\n",
      "103 Train Loss 0.0030884081 Test MSE 5.98860038913008e-06 Test RE 0.0017730881803381911\n",
      "104 Train Loss 0.0030400567 Test MSE 5.877064504966132e-06 Test RE 0.0017564989574783891\n",
      "105 Train Loss 0.002965271 Test MSE 6.3796255286090024e-06 Test RE 0.0018300597160267552\n",
      "106 Train Loss 0.002927608 Test MSE 6.588713353779261e-06 Test RE 0.0018598074132798524\n",
      "107 Train Loss 0.0029247324 Test MSE 7.718419519324952e-06 Test RE 0.0020129447633197954\n",
      "108 Train Loss 0.002834888 Test MSE 7.6485830456256e-06 Test RE 0.002003817480428785\n",
      "109 Train Loss 0.0027420323 Test MSE 7.945950370145823e-06 Test RE 0.002042399012082625\n",
      "110 Train Loss 0.0026721004 Test MSE 7.482993831398353e-06 Test RE 0.0019820078090298844\n",
      "111 Train Loss 0.0026006098 Test MSE 6.24792888129422e-06 Test RE 0.0018110719588298092\n",
      "112 Train Loss 0.0025639536 Test MSE 5.40808999304249e-06 Test RE 0.0016849601053332392\n",
      "113 Train Loss 0.002530368 Test MSE 5.460217876638412e-06 Test RE 0.001693061187653832\n",
      "114 Train Loss 0.0024821288 Test MSE 5.140556460168707e-06 Test RE 0.0016427547604903926\n",
      "115 Train Loss 0.0024613144 Test MSE 4.2515616592678835e-06 Test RE 0.0014939701100367157\n",
      "116 Train Loss 0.0024056826 Test MSE 3.3399324432493327e-06 Test RE 0.0013241479389054206\n",
      "117 Train Loss 0.0023612983 Test MSE 3.1644320456800893e-06 Test RE 0.0012888891108994987\n",
      "118 Train Loss 0.002389655 Test MSE 3.2989661175903675e-06 Test RE 0.001316002139079908\n",
      "119 Train Loss 0.0023174046 Test MSE 2.926590644850373e-06 Test RE 0.0012395060692836476\n",
      "120 Train Loss 0.0022616957 Test MSE 2.9291889269806614e-06 Test RE 0.001240056175593993\n",
      "121 Train Loss 0.00227609 Test MSE 2.7727620668303805e-06 Test RE 0.00120649067515658\n",
      "122 Train Loss 0.0022284589 Test MSE 3.025317663227847e-06 Test RE 0.001260239707357105\n",
      "123 Train Loss 0.0021801568 Test MSE 3.2009578156318988e-06 Test RE 0.001296306333838889\n",
      "124 Train Loss 0.0021367383 Test MSE 3.8056705726653544e-06 Test RE 0.0014134591568621517\n",
      "125 Train Loss 0.002110094 Test MSE 3.855286457636443e-06 Test RE 0.0014226432055140605\n",
      "126 Train Loss 0.0020679338 Test MSE 3.605979621459329e-06 Test RE 0.001375876020731599\n",
      "127 Train Loss 0.002024871 Test MSE 3.187454943336876e-06 Test RE 0.001293569284738018\n",
      "128 Train Loss 0.0020116912 Test MSE 2.969443282722442e-06 Test RE 0.0012485478321213482\n",
      "129 Train Loss 0.0019720164 Test MSE 3.158316973612366e-06 Test RE 0.001287643158849949\n",
      "130 Train Loss 0.001933386 Test MSE 3.2321287861073237e-06 Test RE 0.0013026027665896554\n",
      "131 Train Loss 0.0019106147 Test MSE 3.476408910816273e-06 Test RE 0.0013509307737324507\n",
      "132 Train Loss 0.0018745761 Test MSE 3.5681442764567594e-06 Test RE 0.0013686388729353177\n",
      "133 Train Loss 0.0018534525 Test MSE 3.624469210273667e-06 Test RE 0.001379398899103815\n",
      "134 Train Loss 0.0018278237 Test MSE 3.539245101288186e-06 Test RE 0.0013630851531904835\n",
      "135 Train Loss 0.0017976315 Test MSE 3.0330455438265434e-06 Test RE 0.001261848260850824\n",
      "136 Train Loss 0.0017673658 Test MSE 2.9235526246789773e-06 Test RE 0.001238862552191422\n",
      "137 Train Loss 0.0017437781 Test MSE 3.0322994497194247e-06 Test RE 0.0012616930512699038\n",
      "138 Train Loss 0.0017137979 Test MSE 3.0314541848216426e-06 Test RE 0.001261517188167276\n",
      "139 Train Loss 0.0016881279 Test MSE 2.8104413316107462e-06 Test RE 0.0012146605581642277\n",
      "140 Train Loss 0.0016817315 Test MSE 2.9924004899375858e-06 Test RE 0.0012533648940905623\n",
      "141 Train Loss 0.0016565991 Test MSE 2.571140487200726e-06 Test RE 0.0011617978574436489\n",
      "142 Train Loss 0.0016362264 Test MSE 2.5205580792614737e-06 Test RE 0.0011503129847688382\n",
      "143 Train Loss 0.0016119418 Test MSE 2.621376509270557e-06 Test RE 0.0011730928001006489\n",
      "144 Train Loss 0.0015952494 Test MSE 2.6695751387269513e-06 Test RE 0.001183828366632207\n",
      "145 Train Loss 0.0016196814 Test MSE 2.399591013810492e-06 Test RE 0.0011223705976064517\n",
      "146 Train Loss 0.0015914182 Test MSE 2.2226828343970917e-06 Test RE 0.0010802055775541437\n",
      "147 Train Loss 0.0015877426 Test MSE 1.9245533539860313e-06 Test RE 0.0010051540928307386\n",
      "148 Train Loss 0.00156495 Test MSE 1.8924537040177353e-06 Test RE 0.000996736356380793\n",
      "149 Train Loss 0.001550316 Test MSE 1.651041605023343e-06 Test RE 0.0009309935588633937\n",
      "150 Train Loss 0.0015457937 Test MSE 1.5241545806846493e-06 Test RE 0.0008945037703626636\n",
      "151 Train Loss 0.0015116457 Test MSE 1.4514377696363217e-06 Test RE 0.000872904792192616\n",
      "152 Train Loss 0.0014752444 Test MSE 1.7577870635932834e-06 Test RE 0.000960618175777796\n",
      "153 Train Loss 0.0014754429 Test MSE 1.7749208957991845e-06 Test RE 0.0009652885812649313\n",
      "154 Train Loss 0.0014480081 Test MSE 1.9026848221082627e-06 Test RE 0.0009994270382075658\n",
      "155 Train Loss 0.0014296194 Test MSE 1.7921275379308157e-06 Test RE 0.000969956201953334\n",
      "156 Train Loss 0.00140629 Test MSE 1.7134614258339913e-06 Test RE 0.0009484290189927228\n",
      "157 Train Loss 0.0013901143 Test MSE 1.653877427673689e-06 Test RE 0.0009317927512991527\n",
      "158 Train Loss 0.0013909518 Test MSE 1.663707109380048e-06 Test RE 0.0009345576651400116\n",
      "159 Train Loss 0.001383067 Test MSE 1.6436019813930005e-06 Test RE 0.000928893653648819\n",
      "160 Train Loss 0.0013637398 Test MSE 1.6225355158637607e-06 Test RE 0.0009229215219884882\n",
      "161 Train Loss 0.0013487223 Test MSE 1.7924467067485018e-06 Test RE 0.0009700425702461071\n",
      "162 Train Loss 0.0013457497 Test MSE 1.7247555435926596e-06 Test RE 0.000951549624908674\n",
      "163 Train Loss 0.0013268928 Test MSE 1.8785574967112246e-06 Test RE 0.0009930701173196264\n",
      "164 Train Loss 0.0013071261 Test MSE 1.8522960060140516e-06 Test RE 0.000986104323171314\n",
      "165 Train Loss 0.0012934222 Test MSE 1.8173904339040358e-06 Test RE 0.0009767688171446853\n",
      "166 Train Loss 0.0012800314 Test MSE 1.7255751836517223e-06 Test RE 0.000951775696236899\n",
      "167 Train Loss 0.0012721232 Test MSE 1.711313723212114e-06 Test RE 0.0009478344382944071\n",
      "168 Train Loss 0.0012598282 Test MSE 1.5693782415072382e-06 Test RE 0.0009076773142751741\n",
      "169 Train Loss 0.0012507845 Test MSE 1.6878645525006292e-06 Test RE 0.0009413182178154919\n",
      "170 Train Loss 0.001233072 Test MSE 1.6654391554426156e-06 Test RE 0.0009350440115159528\n",
      "171 Train Loss 0.0012294725 Test MSE 1.5640928602906396e-06 Test RE 0.0009061475789547712\n",
      "172 Train Loss 0.0012257148 Test MSE 1.4766248554969257e-06 Test RE 0.000880446061129621\n",
      "173 Train Loss 0.0012152381 Test MSE 1.3921340329166836e-06 Test RE 0.0008548859764174707\n",
      "174 Train Loss 0.0012035293 Test MSE 1.3531918200093703e-06 Test RE 0.0008428442911832681\n",
      "175 Train Loss 0.001186101 Test MSE 1.3856083448147656e-06 Test RE 0.0008528799654652136\n",
      "176 Train Loss 0.0011710466 Test MSE 1.4879678762058431e-06 Test RE 0.0008838212623528631\n",
      "177 Train Loss 0.0011572631 Test MSE 1.300966634124399e-06 Test RE 0.0008264198628556982\n",
      "178 Train Loss 0.001157621 Test MSE 1.2587689143439373e-06 Test RE 0.0008129066425128531\n",
      "179 Train Loss 0.001137112 Test MSE 1.231131644012145e-06 Test RE 0.0008039331086962709\n",
      "180 Train Loss 0.0011242282 Test MSE 1.2520288587447305e-06 Test RE 0.0008107273743577749\n",
      "181 Train Loss 0.0011296566 Test MSE 1.158621949337675e-06 Test RE 0.0007798993232419876\n",
      "182 Train Loss 0.0011166509 Test MSE 1.1463550780955547e-06 Test RE 0.000775759758173856\n",
      "183 Train Loss 0.0011025334 Test MSE 1.182957667542071e-06 Test RE 0.0007880472710228071\n",
      "184 Train Loss 0.001094131 Test MSE 1.1855062852207143e-06 Test RE 0.0007888957166863816\n",
      "185 Train Loss 0.00109671 Test MSE 1.2228736852040366e-06 Test RE 0.0008012323346841741\n",
      "186 Train Loss 0.0010930152 Test MSE 1.328921547559179e-06 Test RE 0.0008352516443155473\n",
      "187 Train Loss 0.0010803529 Test MSE 1.3976090892784998e-06 Test RE 0.0008565653965898878\n",
      "188 Train Loss 0.0010761975 Test MSE 1.3627028297803804e-06 Test RE 0.000845801101764135\n",
      "189 Train Loss 0.0010654866 Test MSE 1.3714686300678758e-06 Test RE 0.0008485171152798847\n",
      "190 Train Loss 0.0010575145 Test MSE 1.3674255702180602e-06 Test RE 0.0008472654871067319\n",
      "191 Train Loss 0.001051779 Test MSE 1.3986249763857403e-06 Test RE 0.0008568766480264076\n",
      "192 Train Loss 0.001042049 Test MSE 1.4929163353445842e-06 Test RE 0.0008852896822295235\n",
      "193 Train Loss 0.0010323493 Test MSE 1.5489381501012336e-06 Test RE 0.0009017469994831765\n",
      "194 Train Loss 0.0010262432 Test MSE 1.5440444791576473e-06 Test RE 0.0009003213957342874\n",
      "195 Train Loss 0.0010145257 Test MSE 1.5139909754478572e-06 Test RE 0.0008915163469707545\n",
      "196 Train Loss 0.0009992225 Test MSE 1.4099657927425858e-06 Test RE 0.0008603436464229543\n",
      "197 Train Loss 0.000986665 Test MSE 1.289711069766849e-06 Test RE 0.000822837131238414\n",
      "198 Train Loss 0.0009737975 Test MSE 1.3192285814983364e-06 Test RE 0.0008321999657452073\n",
      "199 Train Loss 0.0009690777 Test MSE 1.4983489075784555e-06 Test RE 0.0008868989595696463\n",
      "200 Train Loss 0.00097142445 Test MSE 1.7651380468838683e-06 Test RE 0.0009626247103002079\n",
      "201 Train Loss 0.00095331063 Test MSE 1.7227014240526949e-06 Test RE 0.0009509828260383121\n",
      "202 Train Loss 0.00094330014 Test MSE 1.8062873619253538e-06 Test RE 0.000973780535361623\n",
      "203 Train Loss 0.0009372532 Test MSE 1.7631063966183444e-06 Test RE 0.0009620705667229458\n",
      "204 Train Loss 0.0009245111 Test MSE 1.7039019211613396e-06 Test RE 0.0009457796472138698\n",
      "205 Train Loss 0.00091118313 Test MSE 2.0334665794628485e-06 Test RE 0.0010332042577064998\n",
      "206 Train Loss 0.00090291834 Test MSE 2.0452509494024224e-06 Test RE 0.0010361937516362321\n",
      "207 Train Loss 0.0008899806 Test MSE 2.0495680731232864e-06 Test RE 0.0010372867760665065\n",
      "208 Train Loss 0.0008791997 Test MSE 2.12731518085786e-06 Test RE 0.0010567775710995282\n",
      "209 Train Loss 0.0008797746 Test MSE 1.8540918605013936e-06 Test RE 0.0009865822356759331\n",
      "210 Train Loss 0.00086532 Test MSE 1.7011822964220903e-06 Test RE 0.0009450245588830865\n",
      "211 Train Loss 0.00086542324 Test MSE 1.778970984922897e-06 Test RE 0.0009663892717566191\n",
      "212 Train Loss 0.00085414905 Test MSE 1.7303264847978372e-06 Test RE 0.0009530851333372321\n",
      "213 Train Loss 0.00084213656 Test MSE 1.7923863538155408e-06 Test RE 0.0009700262391030913\n",
      "214 Train Loss 0.0008312766 Test MSE 1.940100554754693e-06 Test RE 0.001009205915700785\n",
      "215 Train Loss 0.00081977755 Test MSE 2.05271115953938e-06 Test RE 0.0010380818296770063\n",
      "216 Train Loss 0.0008125143 Test MSE 2.3229884564066034e-06 Test RE 0.0011043104795107176\n",
      "217 Train Loss 0.0008062409 Test MSE 2.449391925572653e-06 Test RE 0.0011339575804031696\n",
      "218 Train Loss 0.0008017795 Test MSE 2.304661549211933e-06 Test RE 0.0010999456986003943\n",
      "219 Train Loss 0.0007990419 Test MSE 2.3359175632492825e-06 Test RE 0.0011073793576059372\n",
      "220 Train Loss 0.00079823966 Test MSE 2.3359175632492825e-06 Test RE 0.0011073793576059372\n",
      "221 Train Loss 0.00079637876 Test MSE 2.348411711725008e-06 Test RE 0.0011103369342707545\n",
      "222 Train Loss 0.00079805637 Test MSE 2.3696533654841993e-06 Test RE 0.0011153471927566945\n",
      "223 Train Loss 0.00079503213 Test MSE 2.3742633941699697e-06 Test RE 0.0011164315885368397\n",
      "224 Train Loss 0.00079527433 Test MSE 2.436047476524495e-06 Test RE 0.0011308644238082607\n",
      "225 Train Loss 0.00079391856 Test MSE 2.4103793808442983e-06 Test RE 0.001124890811808185\n",
      "226 Train Loss 0.00079597556 Test MSE 2.2584597237050234e-06 Test RE 0.0010888645095208356\n",
      "227 Train Loss 0.00079079525 Test MSE 2.1002196386010348e-06 Test RE 0.001050025933079417\n",
      "228 Train Loss 0.0007810249 Test MSE 2.118496792976046e-06 Test RE 0.0010545849594215543\n",
      "229 Train Loss 0.0007712718 Test MSE 1.8156833621419348e-06 Test RE 0.0009763099707216406\n",
      "230 Train Loss 0.0007634884 Test MSE 1.838096307144155e-06 Test RE 0.0009823173141513203\n",
      "231 Train Loss 0.0007612226 Test MSE 1.8220723146797383e-06 Test RE 0.0009780261621778366\n",
      "232 Train Loss 0.00075554586 Test MSE 1.925401857634702e-06 Test RE 0.0010053756462964744\n",
      "233 Train Loss 0.00074700307 Test MSE 1.7405612344217702e-06 Test RE 0.0009558996905572044\n",
      "234 Train Loss 0.0007472066 Test MSE 1.8063695923544827e-06 Test RE 0.0009738027005723397\n",
      "235 Train Loss 0.0007423398 Test MSE 1.8212929656618479e-06 Test RE 0.0009778169758447469\n",
      "236 Train Loss 0.00074563257 Test MSE 1.6130241686485901e-06 Test RE 0.0009202124504895276\n",
      "237 Train Loss 0.0007394176 Test MSE 1.5095258813288998e-06 Test RE 0.0008902007368407319\n",
      "238 Train Loss 0.0007325463 Test MSE 1.5353556018768374e-06 Test RE 0.0008977846104658208\n",
      "239 Train Loss 0.00072417286 Test MSE 1.6443275968540214e-06 Test RE 0.0009290986744596463\n",
      "240 Train Loss 0.00071664125 Test MSE 1.6364803269706501e-06 Test RE 0.0009268790414906252\n",
      "241 Train Loss 0.00070225686 Test MSE 1.557853392369881e-06 Test RE 0.0009043383741524371\n",
      "242 Train Loss 0.00068945566 Test MSE 1.4815965004723974e-06 Test RE 0.0008819270015858579\n",
      "243 Train Loss 0.00068058993 Test MSE 1.538336632595122e-06 Test RE 0.0008986557525250175\n",
      "244 Train Loss 0.000676728 Test MSE 1.4335734072830919e-06 Test RE 0.0008675162843344754\n",
      "245 Train Loss 0.00066920393 Test MSE 1.4703172437644435e-06 Test RE 0.0008785635737673942\n",
      "246 Train Loss 0.0006638756 Test MSE 1.3250935310091399e-06 Test RE 0.0008340477873317701\n",
      "247 Train Loss 0.000667235 Test MSE 1.317727732818876e-06 Test RE 0.00083172644596287\n",
      "248 Train Loss 0.0006633415 Test MSE 1.3186953483146554e-06 Test RE 0.0008320317608206877\n",
      "249 Train Loss 0.0006667226 Test MSE 1.1358912162262274e-06 Test RE 0.0007722110968461527\n",
      "250 Train Loss 0.0006618356 Test MSE 1.1058698680114248e-06 Test RE 0.0007619380815359619\n",
      "251 Train Loss 0.0006489229 Test MSE 9.842153875416192e-07 Test RE 0.0007188077368602231\n",
      "252 Train Loss 0.0006427289 Test MSE 9.413937235613313e-07 Test RE 0.0007029967493964451\n",
      "253 Train Loss 0.0006351459 Test MSE 9.128572184075509e-07 Test RE 0.0006922597715097154\n",
      "254 Train Loss 0.0006253163 Test MSE 9.631002399071018e-07 Test RE 0.0007110553577857479\n",
      "255 Train Loss 0.0006223271 Test MSE 1.0817242993368797e-06 Test RE 0.0007535740946419576\n",
      "256 Train Loss 0.0006138829 Test MSE 1.0396807310714755e-06 Test RE 0.000738784312850289\n",
      "257 Train Loss 0.00060936983 Test MSE 1.106774173873023e-06 Test RE 0.0007622495486855914\n",
      "258 Train Loss 0.0006013195 Test MSE 1.0194386124682606e-06 Test RE 0.0007315570621122782\n",
      "259 Train Loss 0.00059604814 Test MSE 1.0553106166273419e-06 Test RE 0.000744316799476128\n",
      "260 Train Loss 0.0005868143 Test MSE 1.0226335264768808e-06 Test RE 0.0007327025129026961\n",
      "261 Train Loss 0.0005895973 Test MSE 1.0303893858060137e-06 Test RE 0.000735475746608615\n",
      "262 Train Loss 0.0005882206 Test MSE 1.031072253654801e-06 Test RE 0.0007357194164117406\n",
      "263 Train Loss 0.000587414 Test MSE 1.0286163733047862e-06 Test RE 0.0007348426999407674\n",
      "264 Train Loss 0.000584335 Test MSE 1.0201179099826995e-06 Test RE 0.0007318007561078297\n",
      "265 Train Loss 0.0005790483 Test MSE 1.0195091558256219e-06 Test RE 0.000731582372904852\n",
      "266 Train Loss 0.00057308684 Test MSE 9.835177704513261e-07 Test RE 0.0007185529443332101\n",
      "267 Train Loss 0.00056730874 Test MSE 9.507835736244079e-07 Test RE 0.0007064940402373461\n",
      "268 Train Loss 0.0005659551 Test MSE 9.439993505970012e-07 Test RE 0.0007039689683233833\n",
      "269 Train Loss 0.0005661271 Test MSE 9.097701761538662e-07 Test RE 0.0006910882602888393\n",
      "270 Train Loss 0.0005637587 Test MSE 9.337825884065507e-07 Test RE 0.0007001491299893215\n",
      "271 Train Loss 0.0005581675 Test MSE 9.623836349044817e-07 Test RE 0.0007107907743997503\n",
      "272 Train Loss 0.00055400416 Test MSE 8.284251295461511e-07 Test RE 0.000659468870279681\n",
      "273 Train Loss 0.00055300706 Test MSE 8.340589652387065e-07 Test RE 0.0006617074817290397\n",
      "274 Train Loss 0.0005526228 Test MSE 8.340589652387065e-07 Test RE 0.0006617074817290397\n",
      "275 Train Loss 0.0005523568 Test MSE 8.340589652387065e-07 Test RE 0.0006617074817290397\n",
      "276 Train Loss 0.0005514451 Test MSE 8.679334541096267e-07 Test RE 0.0006750110492283757\n",
      "277 Train Loss 0.0005488243 Test MSE 8.818131344987308e-07 Test RE 0.0006803869095196018\n",
      "278 Train Loss 0.0005462401 Test MSE 8.275463204444405e-07 Test RE 0.0006591189889173959\n",
      "279 Train Loss 0.0005486337 Test MSE 8.118210836673792e-07 Test RE 0.0006528265832932068\n",
      "280 Train Loss 0.00054333836 Test MSE 8.164963530885447e-07 Test RE 0.000654703695455267\n",
      "281 Train Loss 0.000541794 Test MSE 8.131869580951212e-07 Test RE 0.0006533755370038476\n",
      "282 Train Loss 0.00054314116 Test MSE 8.123811074148185e-07 Test RE 0.0006530517162491776\n",
      "283 Train Loss 0.00054261636 Test MSE 8.183210144031595e-07 Test RE 0.0006554348351793958\n",
      "284 Train Loss 0.0005436452 Test MSE 8.198985679204028e-07 Test RE 0.0006560663023326141\n",
      "285 Train Loss 0.00054460386 Test MSE 8.215535000582306e-07 Test RE 0.000656728090216975\n",
      "286 Train Loss 0.00054286973 Test MSE 8.231710282936741e-07 Test RE 0.0006573742769067261\n",
      "287 Train Loss 0.0005419055 Test MSE 8.210683093508258e-07 Test RE 0.0006565341372816684\n",
      "288 Train Loss 0.0005417803 Test MSE 8.190014117231017e-07 Test RE 0.0006557072609376154\n",
      "289 Train Loss 0.00054163265 Test MSE 8.150031655906888e-07 Test RE 0.0006541047688779368\n",
      "290 Train Loss 0.00054357864 Test MSE 8.163273221379783e-07 Test RE 0.0006546359236179352\n",
      "291 Train Loss 0.0005429078 Test MSE 8.773840937759859e-07 Test RE 0.0006786760851759595\n",
      "292 Train Loss 0.0005410173 Test MSE 8.763519730293086e-07 Test RE 0.0006782767835490333\n",
      "293 Train Loss 0.0005391665 Test MSE 7.774685661848734e-07 Test RE 0.0006388649868939627\n",
      "294 Train Loss 0.00054020743 Test MSE 7.64585173310035e-07 Test RE 0.0006335495746136309\n",
      "295 Train Loss 0.0005413158 Test MSE 7.64585173310035e-07 Test RE 0.0006335495746136309\n",
      "296 Train Loss 0.0005359564 Test MSE 7.442485477833321e-07 Test RE 0.0006250671358415231\n",
      "297 Train Loss 0.00053133327 Test MSE 7.203487090494143e-07 Test RE 0.000614948942131874\n",
      "298 Train Loss 0.000526493 Test MSE 6.896241685355111e-07 Test RE 0.0006016915387872696\n",
      "299 Train Loss 0.0005253122 Test MSE 6.907004388678567e-07 Test RE 0.0006021608743431079\n",
      "Training time: 162.23\n",
      "KG_stanALR_medium\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "200 Train Loss nan Test MSE nan Test RE nan\n",
      "201 Train Loss nan Test MSE nan Test RE nan\n",
      "202 Train Loss nan Test MSE nan Test RE nan\n",
      "203 Train Loss nan Test MSE nan Test RE nan\n",
      "204 Train Loss nan Test MSE nan Test RE nan\n",
      "205 Train Loss nan Test MSE nan Test RE nan\n",
      "206 Train Loss nan Test MSE nan Test RE nan\n",
      "207 Train Loss nan Test MSE nan Test RE nan\n",
      "208 Train Loss nan Test MSE nan Test RE nan\n",
      "209 Train Loss nan Test MSE nan Test RE nan\n",
      "210 Train Loss nan Test MSE nan Test RE nan\n",
      "211 Train Loss nan Test MSE nan Test RE nan\n",
      "212 Train Loss nan Test MSE nan Test RE nan\n",
      "213 Train Loss nan Test MSE nan Test RE nan\n",
      "214 Train Loss nan Test MSE nan Test RE nan\n",
      "215 Train Loss nan Test MSE nan Test RE nan\n",
      "216 Train Loss nan Test MSE nan Test RE nan\n",
      "217 Train Loss nan Test MSE nan Test RE nan\n",
      "218 Train Loss nan Test MSE nan Test RE nan\n",
      "219 Train Loss nan Test MSE nan Test RE nan\n",
      "220 Train Loss nan Test MSE nan Test RE nan\n",
      "221 Train Loss nan Test MSE nan Test RE nan\n",
      "222 Train Loss nan Test MSE nan Test RE nan\n",
      "223 Train Loss nan Test MSE nan Test RE nan\n",
      "224 Train Loss nan Test MSE nan Test RE nan\n",
      "225 Train Loss nan Test MSE nan Test RE nan\n",
      "226 Train Loss nan Test MSE nan Test RE nan\n",
      "227 Train Loss nan Test MSE nan Test RE nan\n",
      "228 Train Loss nan Test MSE nan Test RE nan\n",
      "229 Train Loss nan Test MSE nan Test RE nan\n",
      "230 Train Loss nan Test MSE nan Test RE nan\n",
      "231 Train Loss nan Test MSE nan Test RE nan\n",
      "232 Train Loss nan Test MSE nan Test RE nan\n",
      "233 Train Loss nan Test MSE nan Test RE nan\n",
      "234 Train Loss nan Test MSE nan Test RE nan\n",
      "235 Train Loss nan Test MSE nan Test RE nan\n",
      "236 Train Loss nan Test MSE nan Test RE nan\n",
      "237 Train Loss nan Test MSE nan Test RE nan\n",
      "238 Train Loss nan Test MSE nan Test RE nan\n",
      "239 Train Loss nan Test MSE nan Test RE nan\n",
      "240 Train Loss nan Test MSE nan Test RE nan\n",
      "241 Train Loss nan Test MSE nan Test RE nan\n",
      "242 Train Loss nan Test MSE nan Test RE nan\n",
      "243 Train Loss nan Test MSE nan Test RE nan\n",
      "244 Train Loss nan Test MSE nan Test RE nan\n",
      "245 Train Loss nan Test MSE nan Test RE nan\n",
      "246 Train Loss nan Test MSE nan Test RE nan\n",
      "247 Train Loss nan Test MSE nan Test RE nan\n",
      "248 Train Loss nan Test MSE nan Test RE nan\n",
      "249 Train Loss nan Test MSE nan Test RE nan\n",
      "250 Train Loss nan Test MSE nan Test RE nan\n",
      "251 Train Loss nan Test MSE nan Test RE nan\n",
      "252 Train Loss nan Test MSE nan Test RE nan\n",
      "253 Train Loss nan Test MSE nan Test RE nan\n",
      "254 Train Loss nan Test MSE nan Test RE nan\n",
      "255 Train Loss nan Test MSE nan Test RE nan\n",
      "256 Train Loss nan Test MSE nan Test RE nan\n",
      "257 Train Loss nan Test MSE nan Test RE nan\n",
      "258 Train Loss nan Test MSE nan Test RE nan\n",
      "259 Train Loss nan Test MSE nan Test RE nan\n",
      "260 Train Loss nan Test MSE nan Test RE nan\n",
      "261 Train Loss nan Test MSE nan Test RE nan\n",
      "262 Train Loss nan Test MSE nan Test RE nan\n",
      "263 Train Loss nan Test MSE nan Test RE nan\n",
      "264 Train Loss nan Test MSE nan Test RE nan\n",
      "265 Train Loss nan Test MSE nan Test RE nan\n",
      "266 Train Loss nan Test MSE nan Test RE nan\n",
      "267 Train Loss nan Test MSE nan Test RE nan\n",
      "268 Train Loss nan Test MSE nan Test RE nan\n",
      "269 Train Loss nan Test MSE nan Test RE nan\n",
      "270 Train Loss nan Test MSE nan Test RE nan\n",
      "271 Train Loss nan Test MSE nan Test RE nan\n",
      "272 Train Loss nan Test MSE nan Test RE nan\n",
      "273 Train Loss nan Test MSE nan Test RE nan\n",
      "274 Train Loss nan Test MSE nan Test RE nan\n",
      "275 Train Loss nan Test MSE nan Test RE nan\n",
      "276 Train Loss nan Test MSE nan Test RE nan\n",
      "277 Train Loss nan Test MSE nan Test RE nan\n",
      "278 Train Loss nan Test MSE nan Test RE nan\n",
      "279 Train Loss nan Test MSE nan Test RE nan\n",
      "280 Train Loss nan Test MSE nan Test RE nan\n",
      "281 Train Loss nan Test MSE nan Test RE nan\n",
      "282 Train Loss nan Test MSE nan Test RE nan\n",
      "283 Train Loss nan Test MSE nan Test RE nan\n",
      "284 Train Loss nan Test MSE nan Test RE nan\n",
      "285 Train Loss nan Test MSE nan Test RE nan\n",
      "286 Train Loss nan Test MSE nan Test RE nan\n",
      "287 Train Loss nan Test MSE nan Test RE nan\n",
      "288 Train Loss nan Test MSE nan Test RE nan\n",
      "289 Train Loss nan Test MSE nan Test RE nan\n",
      "290 Train Loss nan Test MSE nan Test RE nan\n",
      "291 Train Loss nan Test MSE nan Test RE nan\n",
      "292 Train Loss nan Test MSE nan Test RE nan\n",
      "293 Train Loss nan Test MSE nan Test RE nan\n",
      "294 Train Loss nan Test MSE nan Test RE nan\n",
      "295 Train Loss nan Test MSE nan Test RE nan\n",
      "296 Train Loss nan Test MSE nan Test RE nan\n",
      "297 Train Loss nan Test MSE nan Test RE nan\n",
      "298 Train Loss nan Test MSE nan Test RE nan\n",
      "299 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 16.54\n",
      "KG_stanALR_medium\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 26827.766 Test MSE 5.502554717386534 Test RE 1.6996122498669974\n",
      "1 Train Loss 2701.2854 Test MSE 5.656519088434592 Test RE 1.7232262282865087\n",
      "2 Train Loss 571.62256 Test MSE 4.849409716400535 Test RE 1.5955562033643\n",
      "3 Train Loss 160.01036 Test MSE 1.4664832354124941 Test RE 0.8774173521476143\n",
      "4 Train Loss 40.127983 Test MSE 0.3166064398711759 Test RE 0.40768763511325723\n",
      "5 Train Loss 11.074918 Test MSE 0.01151470976395864 Test RE 0.07774888428688696\n",
      "6 Train Loss 5.65816 Test MSE 0.01603777742881841 Test RE 0.09175711680339176\n",
      "7 Train Loss 3.0886323 Test MSE 0.01016279134574023 Test RE 0.07304225494685401\n",
      "8 Train Loss 1.8630517 Test MSE 0.009943879798425056 Test RE 0.07225128917848618\n",
      "9 Train Loss 1.2193273 Test MSE 0.005529115356785591 Test RE 0.053876018468658235\n",
      "10 Train Loss 0.86535716 Test MSE 0.0010335971419107059 Test RE 0.023293959578943178\n",
      "11 Train Loss 0.648659 Test MSE 0.0007139495138630046 Test RE 0.019359824621146174\n",
      "12 Train Loss 0.51127607 Test MSE 0.001018581954355914 Test RE 0.023124143539545623\n",
      "13 Train Loss 0.3610139 Test MSE 0.00027551892208038816 Test RE 0.01202661429587649\n",
      "14 Train Loss 0.2921271 Test MSE 0.0002898500822655991 Test RE 0.01233543251366386\n",
      "15 Train Loss 0.23545314 Test MSE 0.00012489243524145213 Test RE 0.008097216186179281\n",
      "16 Train Loss 0.18401052 Test MSE 0.00019195649223437977 Test RE 0.010038505706792924\n",
      "17 Train Loss 0.15524632 Test MSE 0.0001402142698332659 Test RE 0.00857953548879758\n",
      "18 Train Loss 0.13572416 Test MSE 0.0002172924494780919 Test RE 0.0106804606789217\n",
      "19 Train Loss 0.116705336 Test MSE 0.00033947869270825186 Test RE 0.013349774450562272\n",
      "20 Train Loss 0.10209601 Test MSE 0.0002980478399774449 Test RE 0.012508656226087376\n",
      "21 Train Loss 0.09408754 Test MSE 0.0002914237983722378 Test RE 0.012368874268077803\n",
      "22 Train Loss 0.08584285 Test MSE 0.00029271044761645357 Test RE 0.012396148766224073\n",
      "23 Train Loss 0.079630144 Test MSE 0.0003672847027569696 Test RE 0.013885741878877322\n",
      "24 Train Loss 0.07218306 Test MSE 0.0003194208116886521 Test RE 0.012949388846080753\n",
      "25 Train Loss 0.06505539 Test MSE 0.000292545936882994 Test RE 0.012392664800828679\n",
      "26 Train Loss 0.06014024 Test MSE 0.00027091501420321406 Test RE 0.011925708917137857\n",
      "27 Train Loss 0.056913916 Test MSE 0.0002930752595012362 Test RE 0.012403871166055153\n",
      "28 Train Loss 0.05288698 Test MSE 0.0002776505822456237 Test RE 0.012073048962357018\n",
      "29 Train Loss 0.044095356 Test MSE 0.0002137463010884269 Test RE 0.01059295120128271\n",
      "30 Train Loss 0.041059103 Test MSE 0.00022266833317905317 Test RE 0.010811772449526233\n",
      "31 Train Loss 0.03564006 Test MSE 0.00018690699164760943 Test RE 0.00990559212352056\n",
      "32 Train Loss 0.03226817 Test MSE 0.00019399865197284433 Test RE 0.01009176255765384\n",
      "33 Train Loss 0.031220071 Test MSE 0.00017824382753845185 Test RE 0.009673305803085463\n",
      "34 Train Loss 0.028387744 Test MSE 0.0001574460114721596 Test RE 0.009091457215700345\n",
      "35 Train Loss 0.026184598 Test MSE 0.00015240628836788163 Test RE 0.008944768621500038\n",
      "36 Train Loss 0.02176354 Test MSE 0.00010707422112483356 Test RE 0.007497390466391742\n",
      "37 Train Loss 0.020356793 Test MSE 0.00010566705076243473 Test RE 0.0074479621464894185\n",
      "38 Train Loss 0.019080203 Test MSE 7.641029105934195e-05 Test RE 0.006333497371433839\n",
      "39 Train Loss 0.01749868 Test MSE 7.934720589455572e-05 Test RE 0.006454067256433428\n",
      "40 Train Loss 0.016929854 Test MSE 6.99235181773666e-05 Test RE 0.006058697973461127\n",
      "41 Train Loss 0.015923189 Test MSE 6.235269894846292e-05 Test RE 0.005721307576897158\n",
      "42 Train Loss 0.015432056 Test MSE 5.774002375436433e-05 Test RE 0.005505618907680915\n",
      "43 Train Loss 0.01484139 Test MSE 5.2034741272932085e-05 Test RE 0.005226541069796334\n",
      "44 Train Loss 0.014091242 Test MSE 4.488265190752741e-05 Test RE 0.0048540799186345355\n",
      "45 Train Loss 0.013549225 Test MSE 4.235155719878435e-05 Test RE 0.004715224328530457\n",
      "46 Train Loss 0.012362647 Test MSE 3.659373037499793e-05 Test RE 0.004382995346639395\n",
      "47 Train Loss 0.0120703345 Test MSE 3.677397362435326e-05 Test RE 0.004393776358936213\n",
      "48 Train Loss 0.011416049 Test MSE 3.6817565869136505e-05 Test RE 0.0043963798013650105\n",
      "49 Train Loss 0.010556136 Test MSE 3.780365494807973e-05 Test RE 0.004454865155548409\n",
      "50 Train Loss 0.010154361 Test MSE 2.695124877820373e-05 Test RE 0.003761465770692199\n",
      "51 Train Loss 0.009787012 Test MSE 2.581546270371569e-05 Test RE 0.0036813543652252467\n",
      "52 Train Loss 0.009243596 Test MSE 2.3227224523968133e-05 Test RE 0.0034919364123062804\n",
      "53 Train Loss 0.008722274 Test MSE 1.943298578671621e-05 Test RE 0.0031940185506424265\n",
      "54 Train Loss 0.008332145 Test MSE 1.775888472467715e-05 Test RE 0.003053342422391616\n",
      "55 Train Loss 0.008122716 Test MSE 1.560839453185685e-05 Test RE 0.002862508498462795\n",
      "56 Train Loss 0.00781979 Test MSE 1.3626806415359055e-05 Test RE 0.0026746361538720373\n",
      "57 Train Loss 0.0071278946 Test MSE 1.3267422706797601e-05 Test RE 0.0026391310162832008\n",
      "58 Train Loss 0.0068714553 Test MSE 1.2162228495813841e-05 Test RE 0.0025268196574700095\n",
      "59 Train Loss 0.0066677625 Test MSE 1.328843250674302e-05 Test RE 0.002641219804817043\n",
      "60 Train Loss 0.006444367 Test MSE 1.2977907974339494e-05 Test RE 0.0026101773263021064\n",
      "61 Train Loss 0.0060037314 Test MSE 9.988170749323665e-06 Test RE 0.0022898690473307694\n",
      "62 Train Loss 0.005853808 Test MSE 9.423885641144996e-06 Test RE 0.002224245247558477\n",
      "63 Train Loss 0.0057843025 Test MSE 8.257079971690242e-06 Test RE 0.002082000900802019\n",
      "64 Train Loss 0.005516209 Test MSE 8.450011803027418e-06 Test RE 0.002106184078502158\n",
      "65 Train Loss 0.005313025 Test MSE 8.762897146497547e-06 Test RE 0.002144823328985822\n",
      "66 Train Loss 0.0051965374 Test MSE 9.436286180440084e-06 Test RE 0.002225708167108355\n",
      "67 Train Loss 0.0051103937 Test MSE 1.028766333647616e-05 Test RE 0.0023239460374358703\n",
      "68 Train Loss 0.005002906 Test MSE 1.067928863770721e-05 Test RE 0.0023677662725476224\n",
      "69 Train Loss 0.0047767567 Test MSE 1.2473077719565049e-05 Test RE 0.0025589068794200404\n",
      "70 Train Loss 0.004573752 Test MSE 1.2589525403449317e-05 Test RE 0.0025708240075349486\n",
      "71 Train Loss 0.004449553 Test MSE 1.1856572166579337e-05 Test RE 0.002494866101492604\n",
      "72 Train Loss 0.004396313 Test MSE 1.141498659566267e-05 Test RE 0.002447965938039514\n",
      "73 Train Loss 0.0043525305 Test MSE 1.155735581206122e-05 Test RE 0.0024631843105046456\n",
      "74 Train Loss 0.0042887786 Test MSE 1.1956468331483466e-05 Test RE 0.0025053541579261765\n",
      "75 Train Loss 0.0042082686 Test MSE 1.1818914256925618e-05 Test RE 0.0024909009520411715\n",
      "76 Train Loss 0.0041143754 Test MSE 1.1876209279671132e-05 Test RE 0.002496931272542297\n",
      "77 Train Loss 0.0040311934 Test MSE 1.2053765711962675e-05 Test RE 0.0025155273328610695\n",
      "78 Train Loss 0.0040202476 Test MSE 1.266104728231753e-05 Test RE 0.00257811617114216\n",
      "79 Train Loss 0.0039542546 Test MSE 1.2435704253551386e-05 Test RE 0.0025550703377237387\n",
      "80 Train Loss 0.0039134035 Test MSE 1.3130521660362706e-05 Test RE 0.0026254796586897894\n",
      "81 Train Loss 0.0038348704 Test MSE 1.1710079876392814e-05 Test RE 0.002479405706289791\n",
      "82 Train Loss 0.0038095275 Test MSE 1.0639651119419628e-05 Test RE 0.002363368056977082\n",
      "83 Train Loss 0.0037061626 Test MSE 9.734064694602384e-06 Test RE 0.002260553458218928\n",
      "84 Train Loss 0.0035598571 Test MSE 8.605860785977258e-06 Test RE 0.0021255181893217803\n",
      "85 Train Loss 0.0034508847 Test MSE 7.874494573363164e-06 Test RE 0.002033194900040261\n",
      "86 Train Loss 0.0033924081 Test MSE 8.170848406071265e-06 Test RE 0.0020711008370904115\n",
      "87 Train Loss 0.0032760685 Test MSE 7.642572484185526e-06 Test RE 0.002003029985861731\n",
      "88 Train Loss 0.0031715601 Test MSE 6.3101765598625645e-06 Test RE 0.0018200713908504576\n",
      "89 Train Loss 0.0030893637 Test MSE 6.117714201648233e-06 Test RE 0.001792100082580238\n",
      "90 Train Loss 0.0029935562 Test MSE 6.368202193551942e-06 Test RE 0.0018284205326701444\n",
      "91 Train Loss 0.0029509098 Test MSE 5.326446613618997e-06 Test RE 0.0016721932148645033\n",
      "92 Train Loss 0.0028993015 Test MSE 5.313667588076706e-06 Test RE 0.00167018607636356\n",
      "93 Train Loss 0.00282035 Test MSE 4.561996607770596e-06 Test RE 0.001547551628653109\n",
      "94 Train Loss 0.0027373363 Test MSE 3.9154763810071776e-06 Test RE 0.001433705568123751\n",
      "95 Train Loss 0.0026455722 Test MSE 3.606729993594016e-06 Test RE 0.001376019167037376\n",
      "96 Train Loss 0.002573622 Test MSE 3.4578891273993985e-06 Test RE 0.0013473275792105135\n",
      "97 Train Loss 0.0025188883 Test MSE 3.3755967948016014e-06 Test RE 0.0013311989015024391\n",
      "98 Train Loss 0.0024618006 Test MSE 4.092173693031665e-06 Test RE 0.0014656986816504129\n",
      "99 Train Loss 0.0023980387 Test MSE 4.457907624827602e-06 Test RE 0.0015297948696131947\n",
      "100 Train Loss 0.0023360476 Test MSE 4.186179861939775e-06 Test RE 0.001482438241683975\n",
      "101 Train Loss 0.002296194 Test MSE 4.502703468399787e-06 Test RE 0.001537461824921323\n",
      "102 Train Loss 0.0022377048 Test MSE 5.1866036256027244e-06 Test RE 0.0016500959459473975\n",
      "103 Train Loss 0.0021901154 Test MSE 6.308517784960289e-06 Test RE 0.0018198321513339289\n",
      "104 Train Loss 0.0021571324 Test MSE 5.920267127539366e-06 Test RE 0.0017629431961224712\n",
      "105 Train Loss 0.0021278358 Test MSE 5.736380140114229e-06 Test RE 0.0017353481991100553\n",
      "106 Train Loss 0.0021151046 Test MSE 5.814679035651093e-06 Test RE 0.0017471514026380823\n",
      "107 Train Loss 0.0020933095 Test MSE 5.8306816310860246e-06 Test RE 0.0017495539210601184\n",
      "108 Train Loss 0.002065029 Test MSE 6.1366883846199555e-06 Test RE 0.0017948770437835205\n",
      "109 Train Loss 0.0020487614 Test MSE 6.407190401426754e-06 Test RE 0.0018340090849857083\n",
      "110 Train Loss 0.0020121722 Test MSE 5.9818366422893945e-06 Test RE 0.0017720866017582686\n",
      "111 Train Loss 0.0019594533 Test MSE 6.156336540576391e-06 Test RE 0.00179774812332202\n",
      "112 Train Loss 0.0019339242 Test MSE 6.910302937095808e-06 Test RE 0.001904654516768341\n",
      "113 Train Loss 0.001906264 Test MSE 7.014592990702093e-06 Test RE 0.0019189731850056287\n",
      "114 Train Loss 0.0018835196 Test MSE 6.518828388374105e-06 Test RE 0.0018499178447827047\n",
      "115 Train Loss 0.0018546096 Test MSE 6.106251233431386e-06 Test RE 0.0017904203360633933\n",
      "116 Train Loss 0.0018189807 Test MSE 5.6310625022463535e-06 Test RE 0.0017193442539715543\n",
      "117 Train Loss 0.0017540975 Test MSE 5.138683444667059e-06 Test RE 0.0016424554557864794\n",
      "118 Train Loss 0.0017234593 Test MSE 5.328758449801951e-06 Test RE 0.0016725560662810663\n",
      "119 Train Loss 0.0016966572 Test MSE 5.671756055388258e-06 Test RE 0.0017255455948891126\n",
      "120 Train Loss 0.0016784914 Test MSE 5.508960824225743e-06 Test RE 0.0017006013114139937\n",
      "121 Train Loss 0.0016412947 Test MSE 4.860046579465298e-06 Test RE 0.0015973051189485128\n",
      "122 Train Loss 0.0016259656 Test MSE 4.822618458073036e-06 Test RE 0.0015911426597578836\n",
      "123 Train Loss 0.0015761309 Test MSE 4.248663483948172e-06 Test RE 0.0014934608235938893\n",
      "124 Train Loss 0.0015441148 Test MSE 4.335053709409226e-06 Test RE 0.0015085680617637903\n",
      "125 Train Loss 0.001516521 Test MSE 4.226037859241352e-06 Test RE 0.0014894789136392183\n",
      "126 Train Loss 0.0014709653 Test MSE 4.018716062982897e-06 Test RE 0.0014524839062517185\n",
      "127 Train Loss 0.0014465703 Test MSE 3.849561354276325e-06 Test RE 0.0014215864999379882\n",
      "128 Train Loss 0.0014105263 Test MSE 3.969263878072407e-06 Test RE 0.0014435194954108836\n",
      "129 Train Loss 0.0013942583 Test MSE 3.697339378811511e-06 Test RE 0.001393196342963812\n",
      "130 Train Loss 0.0013832729 Test MSE 3.9622784348767795e-06 Test RE 0.0014422487227743943\n",
      "131 Train Loss 0.0013523151 Test MSE 3.8933444987965615e-06 Test RE 0.0014296478794235917\n",
      "132 Train Loss 0.0013324816 Test MSE 3.8755228320359085e-06 Test RE 0.0014263720413840518\n",
      "133 Train Loss 0.0013122031 Test MSE 3.859156438866065e-06 Test RE 0.0014233570592845116\n",
      "134 Train Loss 0.0012862431 Test MSE 3.948065871674945e-06 Test RE 0.0014396597495405414\n",
      "135 Train Loss 0.0012718544 Test MSE 3.899062800148298e-06 Test RE 0.0014306973829823098\n",
      "136 Train Loss 0.0012508779 Test MSE 3.840916431162022e-06 Test RE 0.0014199893811723354\n",
      "137 Train Loss 0.0012195444 Test MSE 3.982162790022338e-06 Test RE 0.001445863094723006\n",
      "138 Train Loss 0.0012032625 Test MSE 4.374504099192864e-06 Test RE 0.0015154167442011902\n",
      "139 Train Loss 0.0011777676 Test MSE 3.864677547342483e-06 Test RE 0.0014243748594386524\n",
      "140 Train Loss 0.0011502932 Test MSE 3.898879474203502e-06 Test RE 0.0014306637483570187\n",
      "141 Train Loss 0.0011381677 Test MSE 3.8839094217462855e-06 Test RE 0.0014279145342258914\n",
      "142 Train Loss 0.0011141162 Test MSE 3.5567355807587705e-06 Test RE 0.0013664490952153563\n",
      "143 Train Loss 0.0010969181 Test MSE 3.9722720473007975e-06 Test RE 0.0014440663888200729\n",
      "144 Train Loss 0.001079781 Test MSE 4.1933141114794285e-06 Test RE 0.001483700918215396\n",
      "145 Train Loss 0.0010652861 Test MSE 4.210573412011098e-06 Test RE 0.001486751171997123\n",
      "146 Train Loss 0.0010516002 Test MSE 4.010048163162539e-06 Test RE 0.0014509166418686962\n",
      "147 Train Loss 0.0010319349 Test MSE 3.722832401608476e-06 Test RE 0.0013979911117032121\n",
      "148 Train Loss 0.0010159455 Test MSE 3.7921398159917763e-06 Test RE 0.001410944199071469\n",
      "149 Train Loss 0.0010108354 Test MSE 3.53188738169995e-06 Test RE 0.0013616675604718393\n",
      "150 Train Loss 0.0010014911 Test MSE 3.701018283700571e-06 Test RE 0.0013938892956489673\n",
      "151 Train Loss 0.0009894972 Test MSE 3.6341714779681668e-06 Test RE 0.001381243907600135\n",
      "152 Train Loss 0.0009776534 Test MSE 3.7066761400518052e-06 Test RE 0.0013949543287085978\n",
      "153 Train Loss 0.0009713371 Test MSE 3.7423026331764737e-06 Test RE 0.001401642056967139\n",
      "154 Train Loss 0.0009507252 Test MSE 3.9137401421026515e-06 Test RE 0.0014333876589913155\n",
      "155 Train Loss 0.0009397747 Test MSE 3.9073917581234585e-06 Test RE 0.0014322246553151688\n",
      "156 Train Loss 0.0009326559 Test MSE 3.8762145969387415e-06 Test RE 0.0014264993364784425\n",
      "157 Train Loss 0.0009238375 Test MSE 3.766029136729728e-06 Test RE 0.001406078298954691\n",
      "158 Train Loss 0.00091024215 Test MSE 3.847174096974639e-06 Test RE 0.0014211456420399303\n",
      "159 Train Loss 0.00090172753 Test MSE 4.00677039403746e-06 Test RE 0.0014503235390175516\n",
      "160 Train Loss 0.00089663436 Test MSE 4.016938330945514e-06 Test RE 0.0014521626080116674\n",
      "161 Train Loss 0.0008902808 Test MSE 4.272082323493411e-06 Test RE 0.001497571181564266\n",
      "162 Train Loss 0.00088531704 Test MSE 4.198654858347295e-06 Test RE 0.001484645463428964\n",
      "163 Train Loss 0.00087977486 Test MSE 4.10026191550818e-06 Test RE 0.0014671464507165178\n",
      "164 Train Loss 0.00087303144 Test MSE 4.000429468932331e-06 Test RE 0.0014491754779408952\n",
      "165 Train Loss 0.0008688972 Test MSE 4.068785583893424e-06 Test RE 0.0014615042065362037\n",
      "166 Train Loss 0.0008606349 Test MSE 4.105023905721517e-06 Test RE 0.0014679981657828756\n",
      "167 Train Loss 0.00085311633 Test MSE 4.163733342522373e-06 Test RE 0.0014784584431294949\n",
      "168 Train Loss 0.0008433716 Test MSE 4.470652397021241e-06 Test RE 0.0015319800844787181\n",
      "169 Train Loss 0.00083269464 Test MSE 4.259671747559452e-06 Test RE 0.0014953943463383874\n",
      "170 Train Loss 0.00082604465 Test MSE 4.0557344503612615e-06 Test RE 0.00145915834601732\n",
      "171 Train Loss 0.00082122034 Test MSE 4.018932291676585e-06 Test RE 0.0014525229814772622\n",
      "172 Train Loss 0.000819603 Test MSE 3.726130317263566e-06 Test RE 0.0013986101882114497\n",
      "173 Train Loss 0.0008151231 Test MSE 3.6719631579083427e-06 Test RE 0.0013884070978298889\n",
      "174 Train Loss 0.00080329867 Test MSE 3.51282112003924e-06 Test RE 0.0013579872275836975\n",
      "175 Train Loss 0.0008031873 Test MSE 3.464505709778756e-06 Test RE 0.0013486160015907889\n",
      "176 Train Loss 0.0007928429 Test MSE 3.280844894638327e-06 Test RE 0.0013123827616374948\n",
      "177 Train Loss 0.00078492484 Test MSE 3.3974873922383268e-06 Test RE 0.0013355083095115807\n",
      "178 Train Loss 0.00077857805 Test MSE 3.4687355118190636e-06 Test RE 0.0013494390105769519\n",
      "179 Train Loss 0.0007690424 Test MSE 3.5274844087247907e-06 Test RE 0.0013608185448463277\n",
      "180 Train Loss 0.0007628823 Test MSE 3.422005561987914e-06 Test RE 0.0013403185343502043\n",
      "181 Train Loss 0.00075484934 Test MSE 3.5411139819984054e-06 Test RE 0.0013634449908499044\n",
      "182 Train Loss 0.00075041637 Test MSE 3.4956765016997013e-06 Test RE 0.0013546692889362343\n",
      "183 Train Loss 0.0007433993 Test MSE 3.407061684353695e-06 Test RE 0.0013373887507890044\n",
      "184 Train Loss 0.00073941716 Test MSE 3.5125436817064083e-06 Test RE 0.0013579336004363397\n",
      "185 Train Loss 0.00073362904 Test MSE 3.3914124019562212e-06 Test RE 0.0013343137752749186\n",
      "186 Train Loss 0.0007289218 Test MSE 3.3063550657311103e-06 Test RE 0.0013174750903736897\n",
      "187 Train Loss 0.0007246954 Test MSE 3.0226071925471332e-06 Test RE 0.0012596750380249701\n",
      "188 Train Loss 0.0007194638 Test MSE 2.944382744218549e-06 Test RE 0.0012432681257334949\n",
      "189 Train Loss 0.0007113224 Test MSE 2.738546226926343e-06 Test RE 0.0011990235296411942\n",
      "190 Train Loss 0.00070636487 Test MSE 2.706336238729687e-06 Test RE 0.0011919513891334103\n",
      "191 Train Loss 0.0007002927 Test MSE 2.588006168330978e-06 Test RE 0.0011656020999899325\n",
      "192 Train Loss 0.0006949894 Test MSE 2.5697965947133352e-06 Test RE 0.0011614941915229994\n",
      "193 Train Loss 0.0006904441 Test MSE 2.5607836212206655e-06 Test RE 0.0011594555649065991\n",
      "194 Train Loss 0.0006890174 Test MSE 2.5607836212206655e-06 Test RE 0.0011594555649065991\n",
      "195 Train Loss 0.00068900886 Test MSE 2.5700970024579006e-06 Test RE 0.0011615620785406964\n",
      "196 Train Loss 0.00068732054 Test MSE 2.5729651489042297e-06 Test RE 0.001162210030970593\n",
      "197 Train Loss 0.00068306475 Test MSE 2.5500603397328336e-06 Test RE 0.0011570254080614504\n",
      "198 Train Loss 0.0006769686 Test MSE 2.5350762424993264e-06 Test RE 0.0011536210720985139\n",
      "199 Train Loss 0.0006755526 Test MSE 2.5707846835647876e-06 Test RE 0.0011617174677866226\n",
      "200 Train Loss 0.0006698171 Test MSE 2.423125095299759e-06 Test RE 0.0011278610150613421\n",
      "201 Train Loss 0.00065935985 Test MSE 2.205134825141388e-06 Test RE 0.001075933033855813\n",
      "202 Train Loss 0.00064996845 Test MSE 2.016516289453251e-06 Test RE 0.0010288890255961947\n",
      "203 Train Loss 0.0006370288 Test MSE 2.0191966400799038e-06 Test RE 0.0010295725974465767\n",
      "204 Train Loss 0.00062624365 Test MSE 1.8285243488186482e-06 Test RE 0.0009797562476917558\n",
      "205 Train Loss 0.00062049966 Test MSE 1.7846570481015297e-06 Test RE 0.0009679324578665133\n",
      "206 Train Loss 0.00061557925 Test MSE 1.663281588066649e-06 Test RE 0.0009344381430095508\n",
      "207 Train Loss 0.00061566714 Test MSE 1.6617385259579045e-06 Test RE 0.0009340045932496937\n",
      "208 Train Loss 0.0006144409 Test MSE 1.6670681871222012e-06 Test RE 0.0009355012014451583\n",
      "209 Train Loss 0.0006130988 Test MSE 1.6624852654495703e-06 Test RE 0.0009342144276391807\n",
      "210 Train Loss 0.0006119781 Test MSE 1.6819676637644687e-06 Test RE 0.0009396724383830285\n",
      "211 Train Loss 0.00060898054 Test MSE 1.678536182425192e-06 Test RE 0.0009387134084344647\n",
      "212 Train Loss 0.00060654944 Test MSE 1.6550179692503521e-06 Test RE 0.0009321139858709506\n",
      "213 Train Loss 0.0006020101 Test MSE 1.6779826381243635e-06 Test RE 0.0009385586121573211\n",
      "214 Train Loss 0.000601602 Test MSE 1.6779826381243635e-06 Test RE 0.0009385586121573211\n",
      "215 Train Loss 0.00060002797 Test MSE 1.6780428661654079e-06 Test RE 0.000938575455907102\n",
      "216 Train Loss 0.00060256943 Test MSE 1.6883489582368528e-06 Test RE 0.0009414532841134802\n",
      "217 Train Loss 0.0006038859 Test MSE 1.6893320312874484e-06 Test RE 0.0009417273336995307\n",
      "218 Train Loss 0.00060542324 Test MSE 1.6855091735348657e-06 Test RE 0.0009406611937766019\n",
      "219 Train Loss 0.0006073892 Test MSE 1.6892132593176505e-06 Test RE 0.0009416942280771875\n",
      "220 Train Loss 0.0006047448 Test MSE 1.726822838369315e-06 Test RE 0.0009521197185886844\n",
      "221 Train Loss 0.0006025558 Test MSE 1.703574527501874e-06 Test RE 0.0009456887801483218\n",
      "222 Train Loss 0.000595397 Test MSE 1.6993342716387102e-06 Test RE 0.000944511120857837\n",
      "223 Train Loss 0.0005937206 Test MSE 1.6984277982819552e-06 Test RE 0.0009442591726720387\n",
      "224 Train Loss 0.00058927236 Test MSE 1.735856581038971e-06 Test RE 0.0009546069409397507\n",
      "225 Train Loss 0.0005857303 Test MSE 1.7034976043102797e-06 Test RE 0.0009456674290952113\n",
      "226 Train Loss 0.00058212655 Test MSE 1.689085953802307e-06 Test RE 0.0009416587425850118\n",
      "227 Train Loss 0.000578562 Test MSE 1.6979508868286642e-06 Test RE 0.0009441265913424777\n",
      "228 Train Loss 0.000577086 Test MSE 1.6979508868286642e-06 Test RE 0.0009441265913424777\n",
      "229 Train Loss 0.00057580345 Test MSE 1.6979508868286642e-06 Test RE 0.0009441265913424777\n",
      "230 Train Loss 0.0005749467 Test MSE 1.6979508868286642e-06 Test RE 0.0009441265913424777\n",
      "231 Train Loss 0.000579481 Test MSE 1.6595941943506488e-06 Test RE 0.0009334017721463296\n",
      "232 Train Loss 0.00057273643 Test MSE 1.6000936160951342e-06 Test RE 0.0009165166602878119\n",
      "233 Train Loss 0.00056911877 Test MSE 1.5373991215588088e-06 Test RE 0.0008983818761612205\n",
      "234 Train Loss 0.0005637681 Test MSE 1.4958453415615436e-06 Test RE 0.0008861576975139425\n",
      "235 Train Loss 0.0005608779 Test MSE 1.5021672342070923e-06 Test RE 0.000888028307733789\n",
      "236 Train Loss 0.00056150375 Test MSE 1.5038777267669178e-06 Test RE 0.000888533755336266\n",
      "237 Train Loss 0.000561783 Test MSE 1.5038777267669178e-06 Test RE 0.000888533755336266\n",
      "238 Train Loss 0.0005619533 Test MSE 1.5038777267669178e-06 Test RE 0.000888533755336266\n",
      "239 Train Loss 0.00056207017 Test MSE 1.5038777787742313e-06 Test RE 0.0008885337706999661\n",
      "240 Train Loss 0.00056216045 Test MSE 1.5038777787742313e-06 Test RE 0.0008885337706999661\n",
      "241 Train Loss 0.00056222983 Test MSE 1.5038777787742313e-06 Test RE 0.0008885337706999661\n",
      "242 Train Loss 0.0005622803 Test MSE 1.5038792764297391e-06 Test RE 0.000888534213128594\n",
      "243 Train Loss 0.0005623192 Test MSE 1.5038792764297391e-06 Test RE 0.000888534213128594\n",
      "244 Train Loss 0.0005623514 Test MSE 1.5038792764297391e-06 Test RE 0.000888534213128594\n",
      "245 Train Loss 0.0005623771 Test MSE 1.5038792764297391e-06 Test RE 0.000888534213128594\n",
      "246 Train Loss 0.00056239165 Test MSE 1.5038810452421827e-06 Test RE 0.0008885347356605339\n",
      "247 Train Loss 0.0005624055 Test MSE 1.5038810452421827e-06 Test RE 0.0008885347356605339\n",
      "248 Train Loss 0.0005624174 Test MSE 1.5038810452421827e-06 Test RE 0.0008885347356605339\n",
      "249 Train Loss 0.000562427 Test MSE 1.5038810452421827e-06 Test RE 0.0008885347356605339\n",
      "250 Train Loss 0.000562442 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "251 Train Loss 0.0005624486 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "252 Train Loss 0.00056245585 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "253 Train Loss 0.000562461 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "254 Train Loss 0.00056246435 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "255 Train Loss 0.00056246406 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "256 Train Loss 0.0005624682 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "257 Train Loss 0.0005624703 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "258 Train Loss 0.0005624716 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "259 Train Loss 0.0005624725 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "260 Train Loss 0.00056247314 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "261 Train Loss 0.00056247367 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "262 Train Loss 0.00056247256 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "263 Train Loss 0.0005624743 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "264 Train Loss 0.00056247495 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "265 Train Loss 0.0005624752 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "266 Train Loss 0.0005624753 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "267 Train Loss 0.00056247535 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "268 Train Loss 0.0005624754 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "269 Train Loss 0.00056247547 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "270 Train Loss 0.00056247547 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "271 Train Loss 0.00056247547 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "272 Train Loss 0.0005624755 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "273 Train Loss 0.0005624755 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "274 Train Loss 0.0005624763 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "275 Train Loss 0.00056247605 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "276 Train Loss 0.00056247594 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "277 Train Loss 0.0005624758 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "278 Train Loss 0.00056247576 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "279 Train Loss 0.0005624757 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "280 Train Loss 0.0005624757 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "281 Train Loss 0.00056247564 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "282 Train Loss 0.00056247564 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "283 Train Loss 0.00056247564 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "284 Train Loss 0.00056247564 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "285 Train Loss 0.00056247564 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "286 Train Loss 0.00056247564 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "287 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "288 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "289 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "290 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "291 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "292 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "293 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "294 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "295 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "296 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "297 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "298 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "299 Train Loss 0.0005624756 Test MSE 1.5038808096569762e-06 Test RE 0.000888534666065386\n",
      "Training time: 136.15\n",
      "KG_stanALR_medium\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "200 Train Loss nan Test MSE nan Test RE nan\n",
      "201 Train Loss nan Test MSE nan Test RE nan\n",
      "202 Train Loss nan Test MSE nan Test RE nan\n",
      "203 Train Loss nan Test MSE nan Test RE nan\n",
      "204 Train Loss nan Test MSE nan Test RE nan\n",
      "205 Train Loss nan Test MSE nan Test RE nan\n",
      "206 Train Loss nan Test MSE nan Test RE nan\n",
      "207 Train Loss nan Test MSE nan Test RE nan\n",
      "208 Train Loss nan Test MSE nan Test RE nan\n",
      "209 Train Loss nan Test MSE nan Test RE nan\n",
      "210 Train Loss nan Test MSE nan Test RE nan\n",
      "211 Train Loss nan Test MSE nan Test RE nan\n",
      "212 Train Loss nan Test MSE nan Test RE nan\n",
      "213 Train Loss nan Test MSE nan Test RE nan\n",
      "214 Train Loss nan Test MSE nan Test RE nan\n",
      "215 Train Loss nan Test MSE nan Test RE nan\n",
      "216 Train Loss nan Test MSE nan Test RE nan\n",
      "217 Train Loss nan Test MSE nan Test RE nan\n",
      "218 Train Loss nan Test MSE nan Test RE nan\n",
      "219 Train Loss nan Test MSE nan Test RE nan\n",
      "220 Train Loss nan Test MSE nan Test RE nan\n",
      "221 Train Loss nan Test MSE nan Test RE nan\n",
      "222 Train Loss nan Test MSE nan Test RE nan\n",
      "223 Train Loss nan Test MSE nan Test RE nan\n",
      "224 Train Loss nan Test MSE nan Test RE nan\n",
      "225 Train Loss nan Test MSE nan Test RE nan\n",
      "226 Train Loss nan Test MSE nan Test RE nan\n",
      "227 Train Loss nan Test MSE nan Test RE nan\n",
      "228 Train Loss nan Test MSE nan Test RE nan\n",
      "229 Train Loss nan Test MSE nan Test RE nan\n",
      "230 Train Loss nan Test MSE nan Test RE nan\n",
      "231 Train Loss nan Test MSE nan Test RE nan\n",
      "232 Train Loss nan Test MSE nan Test RE nan\n",
      "233 Train Loss nan Test MSE nan Test RE nan\n",
      "234 Train Loss nan Test MSE nan Test RE nan\n",
      "235 Train Loss nan Test MSE nan Test RE nan\n",
      "236 Train Loss nan Test MSE nan Test RE nan\n",
      "237 Train Loss nan Test MSE nan Test RE nan\n",
      "238 Train Loss nan Test MSE nan Test RE nan\n",
      "239 Train Loss nan Test MSE nan Test RE nan\n",
      "240 Train Loss nan Test MSE nan Test RE nan\n",
      "241 Train Loss nan Test MSE nan Test RE nan\n",
      "242 Train Loss nan Test MSE nan Test RE nan\n",
      "243 Train Loss nan Test MSE nan Test RE nan\n",
      "244 Train Loss nan Test MSE nan Test RE nan\n",
      "245 Train Loss nan Test MSE nan Test RE nan\n",
      "246 Train Loss nan Test MSE nan Test RE nan\n",
      "247 Train Loss nan Test MSE nan Test RE nan\n",
      "248 Train Loss nan Test MSE nan Test RE nan\n",
      "249 Train Loss nan Test MSE nan Test RE nan\n",
      "250 Train Loss nan Test MSE nan Test RE nan\n",
      "251 Train Loss nan Test MSE nan Test RE nan\n",
      "252 Train Loss nan Test MSE nan Test RE nan\n",
      "253 Train Loss nan Test MSE nan Test RE nan\n",
      "254 Train Loss nan Test MSE nan Test RE nan\n",
      "255 Train Loss nan Test MSE nan Test RE nan\n",
      "256 Train Loss nan Test MSE nan Test RE nan\n",
      "257 Train Loss nan Test MSE nan Test RE nan\n",
      "258 Train Loss nan Test MSE nan Test RE nan\n",
      "259 Train Loss nan Test MSE nan Test RE nan\n",
      "260 Train Loss nan Test MSE nan Test RE nan\n",
      "261 Train Loss nan Test MSE nan Test RE nan\n",
      "262 Train Loss nan Test MSE nan Test RE nan\n",
      "263 Train Loss nan Test MSE nan Test RE nan\n",
      "264 Train Loss nan Test MSE nan Test RE nan\n",
      "265 Train Loss nan Test MSE nan Test RE nan\n",
      "266 Train Loss nan Test MSE nan Test RE nan\n",
      "267 Train Loss nan Test MSE nan Test RE nan\n",
      "268 Train Loss nan Test MSE nan Test RE nan\n",
      "269 Train Loss nan Test MSE nan Test RE nan\n",
      "270 Train Loss nan Test MSE nan Test RE nan\n",
      "271 Train Loss nan Test MSE nan Test RE nan\n",
      "272 Train Loss nan Test MSE nan Test RE nan\n",
      "273 Train Loss nan Test MSE nan Test RE nan\n",
      "274 Train Loss nan Test MSE nan Test RE nan\n",
      "275 Train Loss nan Test MSE nan Test RE nan\n",
      "276 Train Loss nan Test MSE nan Test RE nan\n",
      "277 Train Loss nan Test MSE nan Test RE nan\n",
      "278 Train Loss nan Test MSE nan Test RE nan\n",
      "279 Train Loss nan Test MSE nan Test RE nan\n",
      "280 Train Loss nan Test MSE nan Test RE nan\n",
      "281 Train Loss nan Test MSE nan Test RE nan\n",
      "282 Train Loss nan Test MSE nan Test RE nan\n",
      "283 Train Loss nan Test MSE nan Test RE nan\n",
      "284 Train Loss nan Test MSE nan Test RE nan\n",
      "285 Train Loss nan Test MSE nan Test RE nan\n",
      "286 Train Loss nan Test MSE nan Test RE nan\n",
      "287 Train Loss nan Test MSE nan Test RE nan\n",
      "288 Train Loss nan Test MSE nan Test RE nan\n",
      "289 Train Loss nan Test MSE nan Test RE nan\n",
      "290 Train Loss nan Test MSE nan Test RE nan\n",
      "291 Train Loss nan Test MSE nan Test RE nan\n",
      "292 Train Loss nan Test MSE nan Test RE nan\n",
      "293 Train Loss nan Test MSE nan Test RE nan\n",
      "294 Train Loss nan Test MSE nan Test RE nan\n",
      "295 Train Loss nan Test MSE nan Test RE nan\n",
      "296 Train Loss nan Test MSE nan Test RE nan\n",
      "297 Train Loss nan Test MSE nan Test RE nan\n",
      "298 Train Loss nan Test MSE nan Test RE nan\n",
      "299 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 16.39\n",
      "KG_stanALR_medium\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 30520.855 Test MSE 4.979550223130375 Test RE 1.6168239216247067\n",
      "1 Train Loss 9824.584 Test MSE 3.8356145314190746 Test RE 1.4190089847813698\n",
      "2 Train Loss 1291.4082 Test MSE 3.264719318097912 Test RE 1.3091535634024838\n",
      "3 Train Loss 234.92064 Test MSE 0.3206047832417887 Test RE 0.41025385098610434\n",
      "4 Train Loss 76.54857 Test MSE 0.2845084945984155 Test RE 0.3864695544760031\n",
      "5 Train Loss 29.764296 Test MSE 0.07254523164590924 Test RE 0.19515159426744377\n",
      "6 Train Loss 15.217011 Test MSE 0.012046916559035684 Test RE 0.07952535542533887\n",
      "7 Train Loss 7.527864 Test MSE 0.005525000336318309 Test RE 0.05385596623880474\n",
      "8 Train Loss 4.3148775 Test MSE 0.008932676265280503 Test RE 0.06847916640026415\n",
      "9 Train Loss 2.7214127 Test MSE 0.013658920042527589 Test RE 0.08467902502643553\n",
      "10 Train Loss 2.0908253 Test MSE 0.015185727285186218 Test RE 0.08928643147366172\n",
      "11 Train Loss 1.5088395 Test MSE 0.009981308297315384 Test RE 0.07238713743094495\n",
      "12 Train Loss 1.1736758 Test MSE 0.004226042378856531 Test RE 0.04710148412569276\n",
      "13 Train Loss 0.92156833 Test MSE 0.002000045916836468 Test RE 0.03240318130320249\n",
      "14 Train Loss 0.7354104 Test MSE 0.0009666060329630133 Test RE 0.02252643250974412\n",
      "15 Train Loss 0.5977469 Test MSE 0.00019157212019146674 Test RE 0.010028450161379905\n",
      "16 Train Loss 0.5005495 Test MSE 0.0007210297567619528 Test RE 0.01945558356220774\n",
      "17 Train Loss 0.43460342 Test MSE 0.0012125996009000625 Test RE 0.025230530267062845\n",
      "18 Train Loss 0.39842376 Test MSE 0.0011155915438318073 Test RE 0.024200273515647453\n",
      "19 Train Loss 0.33909637 Test MSE 0.001279731738214403 Test RE 0.025919530948938882\n",
      "20 Train Loss 0.31254715 Test MSE 0.0011443687068649986 Test RE 0.02451041442035383\n",
      "21 Train Loss 0.28174457 Test MSE 0.0011469001444824787 Test RE 0.024537508970202463\n",
      "22 Train Loss 0.24972804 Test MSE 0.0009399124867978764 Test RE 0.022213212808537032\n",
      "23 Train Loss 0.20623578 Test MSE 0.0005336903343838934 Test RE 0.016738338114159364\n",
      "24 Train Loss 0.18074973 Test MSE 0.0004775314507297995 Test RE 0.015833198540068524\n",
      "25 Train Loss 0.16659212 Test MSE 0.00029613421926293147 Test RE 0.012468435553471392\n",
      "26 Train Loss 0.14548072 Test MSE 0.00016170981537302534 Test RE 0.009213737993709975\n",
      "27 Train Loss 0.1378894 Test MSE 0.0001818126855213863 Test RE 0.009769666944156229\n",
      "28 Train Loss 0.13039882 Test MSE 0.00019896904725952023 Test RE 0.01022022431442732\n",
      "29 Train Loss 0.1213583 Test MSE 0.00022577336459199507 Test RE 0.010886894645828527\n",
      "30 Train Loss 0.11596877 Test MSE 0.0002779557858961167 Test RE 0.01207968270780512\n",
      "31 Train Loss 0.10471876 Test MSE 0.00019866986447509205 Test RE 0.010212537527161171\n",
      "32 Train Loss 0.09584636 Test MSE 0.00019772039201937922 Test RE 0.010188104691928752\n",
      "33 Train Loss 0.09260539 Test MSE 0.00020317091952010111 Test RE 0.010327576977793271\n",
      "34 Train Loss 0.08707521 Test MSE 0.00018884205289197798 Test RE 0.009956736734788677\n",
      "35 Train Loss 0.08238021 Test MSE 0.0002207346587129479 Test RE 0.010764724819074818\n",
      "36 Train Loss 0.07435973 Test MSE 0.00019396038833479669 Test RE 0.010090767276015726\n",
      "37 Train Loss 0.06900198 Test MSE 0.00016498172821104477 Test RE 0.009306483076804227\n",
      "38 Train Loss 0.06236974 Test MSE 0.00012290928009366228 Test RE 0.008032671471654063\n",
      "39 Train Loss 0.05907978 Test MSE 0.00013189832008993812 Test RE 0.008321225662613283\n",
      "40 Train Loss 0.053882007 Test MSE 0.0001587539085405819 Test RE 0.009129140286568154\n",
      "41 Train Loss 0.05183782 Test MSE 0.00014214436308413687 Test RE 0.008638383658950758\n",
      "42 Train Loss 0.0447338 Test MSE 0.00011923114539952903 Test RE 0.00791156727990806\n",
      "43 Train Loss 0.04114593 Test MSE 9.742722137259491e-05 Test RE 0.007151675918291138\n",
      "44 Train Loss 0.04003062 Test MSE 9.571864452589921e-05 Test RE 0.007088689236997453\n",
      "45 Train Loss 0.036888633 Test MSE 9.200052316481507e-05 Test RE 0.006949648128510077\n",
      "46 Train Loss 0.036057826 Test MSE 8.853875918506682e-05 Test RE 0.0068176449980316646\n",
      "47 Train Loss 0.034250993 Test MSE 8.879799514298977e-05 Test RE 0.006827618522310336\n",
      "48 Train Loss 0.03307305 Test MSE 8.568921490123771e-05 Test RE 0.006707037731416913\n",
      "49 Train Loss 0.03196761 Test MSE 9.707621586715651e-05 Test RE 0.007138781459021566\n",
      "50 Train Loss 0.02871598 Test MSE 0.00011110199210136915 Test RE 0.00763710199425981\n",
      "51 Train Loss 0.02853858 Test MSE 0.0001153402328197801 Test RE 0.007781406071682094\n",
      "52 Train Loss 0.027397517 Test MSE 0.00010701252179761081 Test RE 0.007495230046261291\n",
      "53 Train Loss 0.025325231 Test MSE 0.00011881873838157615 Test RE 0.007897872820503377\n",
      "54 Train Loss 0.024702208 Test MSE 0.0001183529118266202 Test RE 0.007882375888270584\n",
      "55 Train Loss 0.023949556 Test MSE 0.00011517655672645921 Test RE 0.007775882923864082\n",
      "56 Train Loss 0.022297543 Test MSE 0.00011001408041255577 Test RE 0.007599618724278552\n",
      "57 Train Loss 0.021599302 Test MSE 0.00010532192350554765 Test RE 0.007435789018330305\n",
      "58 Train Loss 0.020006295 Test MSE 9.681521933110433e-05 Test RE 0.0071291784309380855\n",
      "59 Train Loss 0.018955298 Test MSE 9.715918157101919e-05 Test RE 0.007141831369502809\n",
      "60 Train Loss 0.018450815 Test MSE 8.99726776748403e-05 Test RE 0.006872630426632945\n",
      "61 Train Loss 0.0177377 Test MSE 8.817866845433234e-05 Test RE 0.006803767053518116\n",
      "62 Train Loss 0.016412036 Test MSE 8.012085097228819e-05 Test RE 0.006485454910905354\n",
      "63 Train Loss 0.015765902 Test MSE 8.224911823787223e-05 Test RE 0.006571027625346106\n",
      "64 Train Loss 0.0153821735 Test MSE 8.298711528256283e-05 Test RE 0.006600441736685001\n",
      "65 Train Loss 0.014888321 Test MSE 7.586223574067394e-05 Test RE 0.0063107428873775346\n",
      "66 Train Loss 0.0142785385 Test MSE 7.344294729045716e-05 Test RE 0.006209301043499141\n",
      "67 Train Loss 0.013748002 Test MSE 7.278038025442723e-05 Test RE 0.006181228919202434\n",
      "68 Train Loss 0.0134243285 Test MSE 7.267864989126129e-05 Test RE 0.006176907434823564\n",
      "69 Train Loss 0.013177478 Test MSE 6.973054370218371e-05 Test RE 0.006050331819432959\n",
      "70 Train Loss 0.012976488 Test MSE 7.27101794834886e-05 Test RE 0.006178247128497221\n",
      "71 Train Loss 0.012546768 Test MSE 6.11562142393277e-05 Test RE 0.0056661486552313355\n",
      "72 Train Loss 0.011545013 Test MSE 5.345007389817804e-05 Test RE 0.0052971445303840806\n",
      "73 Train Loss 0.01130335 Test MSE 5.089130899624922e-05 Test RE 0.005168797030056854\n",
      "74 Train Loss 0.011012018 Test MSE 5.392264117865009e-05 Test RE 0.0053205097787928065\n",
      "75 Train Loss 0.0107352305 Test MSE 5.0263424460851514e-05 Test RE 0.005136812391812424\n",
      "76 Train Loss 0.010469593 Test MSE 4.824102598969736e-05 Test RE 0.005032409059955099\n",
      "77 Train Loss 0.010177503 Test MSE 4.577970186682632e-05 Test RE 0.004902348120512953\n",
      "78 Train Loss 0.009857377 Test MSE 4.600099292001204e-05 Test RE 0.0049141823822590235\n",
      "79 Train Loss 0.009626645 Test MSE 4.4051765862574296e-05 Test RE 0.0048089396706899\n",
      "80 Train Loss 0.009382613 Test MSE 4.5844549132608245e-05 Test RE 0.0049058189969054386\n",
      "81 Train Loss 0.009115332 Test MSE 4.267163396079745e-05 Test RE 0.004733008714841739\n",
      "82 Train Loss 0.009089926 Test MSE 4.381154187553896e-05 Test RE 0.0047958096420942335\n",
      "83 Train Loss 0.008895173 Test MSE 4.071948802559448e-05 Test RE 0.004623478283580502\n",
      "84 Train Loss 0.00856287 Test MSE 4.099246432487027e-05 Test RE 0.00463894989053103\n",
      "85 Train Loss 0.00821001 Test MSE 4.2946808835834754e-05 Test RE 0.004748244973825609\n",
      "86 Train Loss 0.007814079 Test MSE 4.4116733080079566e-05 Test RE 0.004812484458490836\n",
      "87 Train Loss 0.0074861003 Test MSE 4.42615069346919e-05 Test RE 0.004820374336327267\n",
      "88 Train Loss 0.0072521213 Test MSE 4.7345892984692804e-05 Test RE 0.0049855011838306216\n",
      "89 Train Loss 0.007197956 Test MSE 4.3368568632266553e-05 Test RE 0.004771503117975231\n",
      "90 Train Loss 0.006998707 Test MSE 4.0052489483989435e-05 Test RE 0.004585454887957523\n",
      "91 Train Loss 0.0068476847 Test MSE 3.623484191618974e-05 Test RE 0.004361449548709999\n",
      "92 Train Loss 0.0067027416 Test MSE 3.487023957738441e-05 Test RE 0.00427853543575299\n",
      "93 Train Loss 0.006594136 Test MSE 3.1934527733554254e-05 Test RE 0.00409447210443656\n",
      "94 Train Loss 0.0064367577 Test MSE 3.153902054023063e-05 Test RE 0.004069038215184429\n",
      "95 Train Loss 0.0063542887 Test MSE 2.9034228612140097e-05 Test RE 0.0039041169047906435\n",
      "96 Train Loss 0.006291036 Test MSE 2.5064454988624904e-05 Test RE 0.0036274112905834485\n",
      "97 Train Loss 0.0062214388 Test MSE 2.3202131050835496e-05 Test RE 0.0034900496502534946\n",
      "98 Train Loss 0.0059572323 Test MSE 2.252519020460201e-05 Test RE 0.0034387602751745024\n",
      "99 Train Loss 0.0058138226 Test MSE 2.0741410115284435e-05 Test RE 0.0032997938367540424\n",
      "100 Train Loss 0.00569847 Test MSE 2.0849079127005237e-05 Test RE 0.003308347393596295\n",
      "101 Train Loss 0.005624681 Test MSE 2.0015020383321123e-05 Test RE 0.0032414974628478333\n",
      "102 Train Loss 0.0055728294 Test MSE 1.9449548289315215e-05 Test RE 0.003195379372757387\n",
      "103 Train Loss 0.005446987 Test MSE 1.8330019980432208e-05 Test RE 0.0031020524512039003\n",
      "104 Train Loss 0.005306341 Test MSE 1.7328204868345925e-05 Test RE 0.0030160910964333884\n",
      "105 Train Loss 0.0051706866 Test MSE 1.6902899707335328e-05 Test RE 0.002978847531330584\n",
      "106 Train Loss 0.0050086724 Test MSE 1.6445851618879575e-05 Test RE 0.002938298080629329\n",
      "107 Train Loss 0.004890523 Test MSE 1.644481556575196e-05 Test RE 0.00293820552595556\n",
      "108 Train Loss 0.0047806296 Test MSE 1.5383965036537466e-05 Test RE 0.0028418543103358156\n",
      "109 Train Loss 0.0047289454 Test MSE 1.538605522977119e-05 Test RE 0.00284204736274087\n",
      "110 Train Loss 0.0046013077 Test MSE 1.5175428690446432e-05 Test RE 0.0028225273039327644\n",
      "111 Train Loss 0.004509716 Test MSE 1.590082893927726e-05 Test RE 0.0028891996287728084\n",
      "112 Train Loss 0.0043881633 Test MSE 1.7874094179714512e-05 Test RE 0.0030632305780469733\n",
      "113 Train Loss 0.004250923 Test MSE 1.694421862717696e-05 Test RE 0.0029824861861690167\n",
      "114 Train Loss 0.0041363016 Test MSE 1.5576076808508865e-05 Test RE 0.0028595435012187796\n",
      "115 Train Loss 0.004078295 Test MSE 1.6165850453871614e-05 Test RE 0.002913177493997962\n",
      "116 Train Loss 0.004016716 Test MSE 1.583092227743042e-05 Test RE 0.002882841570890162\n",
      "117 Train Loss 0.003930988 Test MSE 1.544077430225176e-05 Test RE 0.002847096615804755\n",
      "118 Train Loss 0.0038205257 Test MSE 1.4824851842042714e-05 Test RE 0.0027897343410035057\n",
      "119 Train Loss 0.0037953132 Test MSE 1.5680333527135237e-05 Test RE 0.0028690975570706064\n",
      "120 Train Loss 0.0037415582 Test MSE 1.5878653028350497e-05 Test RE 0.002887184231075658\n",
      "121 Train Loss 0.003641345 Test MSE 1.678613075381396e-05 Test RE 0.002968540432180133\n",
      "122 Train Loss 0.0035540976 Test MSE 1.7587551511748345e-05 Test RE 0.0030385777883186723\n",
      "123 Train Loss 0.0034967815 Test MSE 1.7084252822842005e-05 Test RE 0.002994785091817367\n",
      "124 Train Loss 0.0034889458 Test MSE 1.6981655471970055e-05 Test RE 0.0029857791461424983\n",
      "125 Train Loss 0.0034387875 Test MSE 1.702841237978334e-05 Test RE 0.002989886809135625\n",
      "126 Train Loss 0.0034045458 Test MSE 1.7310257995034508e-05 Test RE 0.0030145288045522107\n",
      "127 Train Loss 0.0033247632 Test MSE 1.5998082924115554e-05 Test RE 0.002898021742358038\n",
      "128 Train Loss 0.0032979369 Test MSE 1.5340589389149152e-05 Test RE 0.0028378451266810843\n",
      "129 Train Loss 0.0032619915 Test MSE 1.4201850957846456e-05 Test RE 0.0027304871872091043\n",
      "130 Train Loss 0.0032391595 Test MSE 1.3805696568017714e-05 Test RE 0.002692134971118907\n",
      "131 Train Loss 0.0031747904 Test MSE 1.3679639963893279e-05 Test RE 0.0026798161574671177\n",
      "132 Train Loss 0.0031504922 Test MSE 1.3394443000123271e-05 Test RE 0.002651734242890308\n",
      "133 Train Loss 0.0031080786 Test MSE 1.3390580997214815e-05 Test RE 0.0026513519297303324\n",
      "134 Train Loss 0.0030813904 Test MSE 1.2713974554916249e-05 Test RE 0.002583499230993791\n",
      "135 Train Loss 0.0030445307 Test MSE 1.1743755167911683e-05 Test RE 0.002482968225480975\n",
      "136 Train Loss 0.0029932184 Test MSE 1.1140890543001136e-05 Test RE 0.0024183971443085366\n",
      "137 Train Loss 0.0029488483 Test MSE 1.0695988205262578e-05 Test RE 0.0023696168277889105\n",
      "138 Train Loss 0.002923049 Test MSE 1.038387690026823e-05 Test RE 0.0023347878957815293\n",
      "139 Train Loss 0.0028683585 Test MSE 1.0468508563558853e-05 Test RE 0.0023442831931026796\n",
      "140 Train Loss 0.002833084 Test MSE 1.0782756362055322e-05 Test RE 0.0023792088346556825\n",
      "141 Train Loss 0.0027872452 Test MSE 1.089205128719812e-05 Test RE 0.0023912363638874507\n",
      "142 Train Loss 0.0027472337 Test MSE 1.0171272439797176e-05 Test RE 0.002310762501075458\n",
      "143 Train Loss 0.0027537267 Test MSE 1.0442053941601026e-05 Test RE 0.0023413192391067536\n",
      "144 Train Loss 0.0027180705 Test MSE 1.0922638687491671e-05 Test RE 0.002394591582486731\n",
      "145 Train Loss 0.0026666343 Test MSE 1.2443550987055846e-05 Test RE 0.0025558763151726266\n",
      "146 Train Loss 0.0025920118 Test MSE 1.1072439384725373e-05 Test RE 0.002410956215437227\n",
      "147 Train Loss 0.0025328905 Test MSE 9.99310587357217e-06 Test RE 0.0022904346860732677\n",
      "148 Train Loss 0.0025018048 Test MSE 8.913306755584266e-06 Test RE 0.0021631522830077433\n",
      "149 Train Loss 0.002454585 Test MSE 8.572922817006123e-06 Test RE 0.0021214466983044676\n",
      "150 Train Loss 0.0024200212 Test MSE 7.99967198747361e-06 Test RE 0.002049291589102175\n",
      "151 Train Loss 0.0024147152 Test MSE 7.981689553364099e-06 Test RE 0.0020469869956270966\n",
      "152 Train Loss 0.0023674862 Test MSE 8.045907578033059e-06 Test RE 0.0020552051874726954\n",
      "153 Train Loss 0.0023425403 Test MSE 8.448908446391423e-06 Test RE 0.002106046566975641\n",
      "154 Train Loss 0.002312452 Test MSE 8.362608647275428e-06 Test RE 0.002095263049862016\n",
      "155 Train Loss 0.0022714715 Test MSE 8.720418218859835e-06 Test RE 0.0021396184020295193\n",
      "156 Train Loss 0.0022421128 Test MSE 8.713435656025731e-06 Test RE 0.0021387616190503274\n",
      "157 Train Loss 0.0022297888 Test MSE 8.906313971991083e-06 Test RE 0.002162303584305092\n",
      "158 Train Loss 0.0021996386 Test MSE 9.374564476045493e-06 Test RE 0.0022184171696509685\n",
      "159 Train Loss 0.0021705127 Test MSE 9.804695900582342e-06 Test RE 0.0022687400190836192\n",
      "160 Train Loss 0.002159921 Test MSE 9.450446000981646e-06 Test RE 0.0022273774580572445\n",
      "161 Train Loss 0.0021168664 Test MSE 9.316313813321254e-06 Test RE 0.0022115141483565665\n",
      "162 Train Loss 0.002077346 Test MSE 8.424006517201127e-06 Test RE 0.0021029406437020654\n",
      "163 Train Loss 0.0020505919 Test MSE 8.21390886128051e-06 Test RE 0.0020765510272520156\n",
      "164 Train Loss 0.0020324416 Test MSE 7.934448153531413e-06 Test RE 0.002040920232172187\n",
      "165 Train Loss 0.0020036104 Test MSE 8.103456531533006e-06 Test RE 0.002062542095527663\n",
      "166 Train Loss 0.0019858943 Test MSE 8.12875904088329e-06 Test RE 0.0020657596617557825\n",
      "167 Train Loss 0.0019668548 Test MSE 7.934049191118847e-06 Test RE 0.002040868920431296\n",
      "168 Train Loss 0.0019569392 Test MSE 7.70857709678183e-06 Test RE 0.0020116609141473435\n",
      "169 Train Loss 0.0019292827 Test MSE 7.5314802448835415e-06 Test RE 0.0019884186976911146\n",
      "170 Train Loss 0.0019055463 Test MSE 7.985998340525592e-06 Test RE 0.0020475394376389417\n",
      "171 Train Loss 0.0018866514 Test MSE 8.070582384145838e-06 Test RE 0.002058354177714636\n",
      "172 Train Loss 0.0018396043 Test MSE 7.718654672230352e-06 Test RE 0.0020129754267349583\n",
      "173 Train Loss 0.0018404083 Test MSE 7.430377762405438e-06 Test RE 0.001975027352542521\n",
      "174 Train Loss 0.001804084 Test MSE 7.270687745985374e-06 Test RE 0.001953688923908975\n",
      "175 Train Loss 0.0017822956 Test MSE 7.012210404812269e-06 Test RE 0.0019186472568478228\n",
      "176 Train Loss 0.0017404945 Test MSE 6.871556486706245e-06 Test RE 0.0018993072590818387\n",
      "177 Train Loss 0.0017141046 Test MSE 7.000877837862543e-06 Test RE 0.001917096248731927\n",
      "178 Train Loss 0.0017016117 Test MSE 7.315589032041216e-06 Test RE 0.0019597122966520043\n",
      "179 Train Loss 0.0016920267 Test MSE 7.240949879262789e-06 Test RE 0.0019496894350067694\n",
      "180 Train Loss 0.0016805414 Test MSE 6.994726278947507e-06 Test RE 0.001916253802788687\n",
      "181 Train Loss 0.0016680242 Test MSE 7.004968142194715e-06 Test RE 0.0019176562043721835\n",
      "182 Train Loss 0.0016533314 Test MSE 6.642510764363268e-06 Test RE 0.0018673847210371709\n",
      "183 Train Loss 0.0016229416 Test MSE 6.216153574090281e-06 Test RE 0.0018064607730063082\n",
      "184 Train Loss 0.001593777 Test MSE 5.6334607020635515e-06 Test RE 0.001719710338715639\n",
      "185 Train Loss 0.0015843152 Test MSE 5.172652161287327e-06 Test RE 0.0016478751519108795\n",
      "186 Train Loss 0.0015675763 Test MSE 5.0558903880510545e-06 Test RE 0.0016291703312732021\n",
      "187 Train Loss 0.0015476146 Test MSE 4.985576871383213e-06 Test RE 0.001617802030305077\n",
      "188 Train Loss 0.0015315893 Test MSE 4.6956250981440386e-06 Test RE 0.0015700532249402438\n",
      "189 Train Loss 0.0015111935 Test MSE 4.592403381725252e-06 Test RE 0.001552700460066566\n",
      "190 Train Loss 0.0014948837 Test MSE 4.306434304918584e-06 Test RE 0.0015035801404689017\n",
      "191 Train Loss 0.0014809297 Test MSE 4.034814744673371e-06 Test RE 0.0014553902704694363\n",
      "192 Train Loss 0.0014616011 Test MSE 3.990380252651978e-06 Test RE 0.0014473541441113141\n",
      "193 Train Loss 0.0014481666 Test MSE 4.022054358103325e-06 Test RE 0.001453087060756277\n",
      "194 Train Loss 0.0014187146 Test MSE 3.977001524133039e-06 Test RE 0.0014449258021187801\n",
      "195 Train Loss 0.0013966004 Test MSE 3.7603950689011375e-06 Test RE 0.0014050261422544404\n",
      "196 Train Loss 0.0013777025 Test MSE 3.5508593560213174e-06 Test RE 0.0013653198460730205\n",
      "197 Train Loss 0.0013571561 Test MSE 3.466991774145946e-06 Test RE 0.0013490997856015735\n",
      "198 Train Loss 0.0013599487 Test MSE 3.3907235640435865e-06 Test RE 0.0013341782605567087\n",
      "199 Train Loss 0.001335418 Test MSE 3.307734072541573e-06 Test RE 0.0013177498064414152\n",
      "200 Train Loss 0.0013176525 Test MSE 3.49860615925839e-06 Test RE 0.001355236830861566\n",
      "201 Train Loss 0.0013079913 Test MSE 3.4158491987676015e-06 Test RE 0.0013391123407696915\n",
      "202 Train Loss 0.0012939409 Test MSE 3.4122466077991988e-06 Test RE 0.0013384059942042749\n",
      "203 Train Loss 0.0012796108 Test MSE 3.4170626992647878e-06 Test RE 0.0013393501834112276\n",
      "204 Train Loss 0.0012681261 Test MSE 3.3870644127882664e-06 Test RE 0.0013334581667793245\n",
      "205 Train Loss 0.001261473 Test MSE 3.3270954656217745e-06 Test RE 0.0013216008182433854\n",
      "206 Train Loss 0.0012506213 Test MSE 3.319974723822327e-06 Test RE 0.0013201857973966\n",
      "207 Train Loss 0.0012372459 Test MSE 3.192869890967573e-06 Test RE 0.0012946675963486814\n",
      "208 Train Loss 0.0012319344 Test MSE 3.2483705483340046e-06 Test RE 0.0013058715182282968\n",
      "209 Train Loss 0.0012225434 Test MSE 3.1964118297176576e-06 Test RE 0.0012953855025658175\n",
      "210 Train Loss 0.0012148088 Test MSE 3.1278615132221206e-06 Test RE 0.0012814197868852184\n",
      "211 Train Loss 0.0012115537 Test MSE 3.1242267640171314e-06 Test RE 0.0012806750298958475\n",
      "212 Train Loss 0.001207215 Test MSE 3.2219207518353515e-06 Test RE 0.0013005441343121981\n",
      "213 Train Loss 0.0012047822 Test MSE 3.3314212428370034e-06 Test RE 0.001322459689551211\n",
      "214 Train Loss 0.0012084909 Test MSE 3.3663178147935956e-06 Test RE 0.0013293680151481866\n",
      "215 Train Loss 0.0011943192 Test MSE 3.662436129066232e-06 Test RE 0.001386604794161268\n",
      "216 Train Loss 0.001186185 Test MSE 3.6346950970453108e-06 Test RE 0.0013813434102811148\n",
      "217 Train Loss 0.0011727347 Test MSE 3.6362114008137e-06 Test RE 0.0013816315111755601\n",
      "218 Train Loss 0.001169953 Test MSE 3.6246091980071995e-06 Test RE 0.0013794255370816603\n",
      "219 Train Loss 0.0011638479 Test MSE 3.4628743624400225e-06 Test RE 0.0013482984497726303\n",
      "220 Train Loss 0.0011565958 Test MSE 3.21353408373808e-06 Test RE 0.0012988503714945689\n",
      "221 Train Loss 0.0011542633 Test MSE 3.1238275194683013e-06 Test RE 0.0012805931986302262\n",
      "222 Train Loss 0.0011484817 Test MSE 3.195951425935797e-06 Test RE 0.0012952922070373154\n",
      "223 Train Loss 0.0011419004 Test MSE 3.0517196108748687e-06 Test RE 0.001265726817905334\n",
      "224 Train Loss 0.0011352189 Test MSE 2.933157725101235e-06 Test RE 0.0012408959757583382\n",
      "225 Train Loss 0.0011218275 Test MSE 2.9287763911673837e-06 Test RE 0.0012399688501245991\n",
      "226 Train Loss 0.0011123542 Test MSE 2.921580747483123e-06 Test RE 0.0012384446878347262\n",
      "227 Train Loss 0.0010961017 Test MSE 2.9090766419314797e-06 Test RE 0.001235791629562057\n",
      "228 Train Loss 0.0010894384 Test MSE 2.9746420790053597e-06 Test RE 0.00124964031085652\n",
      "229 Train Loss 0.0010766925 Test MSE 2.7656302887010515e-06 Test RE 0.001204938078223301\n",
      "230 Train Loss 0.0010687123 Test MSE 2.827066235039767e-06 Test RE 0.0012182478664800034\n",
      "231 Train Loss 0.0010563696 Test MSE 2.8253632837784466e-06 Test RE 0.001217880890773342\n",
      "232 Train Loss 0.0010515556 Test MSE 2.9036052753407624e-06 Test RE 0.001234628949425141\n",
      "233 Train Loss 0.0010429721 Test MSE 3.037459178670025e-06 Test RE 0.0012627660368523788\n",
      "234 Train Loss 0.0010381135 Test MSE 3.0586845112868658e-06 Test RE 0.0012671703707416244\n",
      "235 Train Loss 0.0010320726 Test MSE 3.0676495330960413e-06 Test RE 0.0012690260537868132\n",
      "236 Train Loss 0.0010260548 Test MSE 3.0850887112659266e-06 Test RE 0.0012726280636775897\n",
      "237 Train Loss 0.0010254895 Test MSE 3.073204643240806e-06 Test RE 0.0012701745537784576\n",
      "238 Train Loss 0.0010228878 Test MSE 3.0283752798045135e-06 Test RE 0.001260876393669606\n",
      "239 Train Loss 0.0010174932 Test MSE 2.9100819489023976e-06 Test RE 0.0012360051410606658\n",
      "240 Train Loss 0.0010081746 Test MSE 2.801437632938804e-06 Test RE 0.0012127133175747714\n",
      "241 Train Loss 0.0010074036 Test MSE 2.690692999852745e-06 Test RE 0.0011885015216152137\n",
      "242 Train Loss 0.0010047941 Test MSE 2.6183331083825516e-06 Test RE 0.0011724116258204293\n",
      "243 Train Loss 0.0010026465 Test MSE 2.6284687363784874e-06 Test RE 0.001174678650267802\n",
      "244 Train Loss 0.0009945951 Test MSE 2.535840827601336e-06 Test RE 0.0011537950264305127\n",
      "245 Train Loss 0.0009831232 Test MSE 2.3832518267146913e-06 Test RE 0.0011185428729132535\n",
      "246 Train Loss 0.0009822818 Test MSE 2.362936635521278e-06 Test RE 0.0011137653575888425\n",
      "247 Train Loss 0.00097129296 Test MSE 2.451443427736343e-06 Test RE 0.0011344323573272775\n",
      "248 Train Loss 0.00096397905 Test MSE 2.48342773079862e-06 Test RE 0.0011418089182391952\n",
      "249 Train Loss 0.00095836923 Test MSE 2.4760875470600963e-06 Test RE 0.0011401202664528844\n",
      "250 Train Loss 0.000954001 Test MSE 2.4721864433709546e-06 Test RE 0.0011392217762873627\n",
      "251 Train Loss 0.0009504784 Test MSE 2.426450110504314e-06 Test RE 0.0011286345759107302\n",
      "252 Train Loss 0.0009489821 Test MSE 2.5179340325517597e-06 Test RE 0.0011497140576822908\n",
      "253 Train Loss 0.00093704445 Test MSE 2.2881454723886767e-06 Test RE 0.0010959972983822688\n",
      "254 Train Loss 0.00092691457 Test MSE 2.430663149900395e-06 Test RE 0.001129613973691375\n",
      "255 Train Loss 0.0009196748 Test MSE 2.393854724204127e-06 Test RE 0.0011210282657127357\n",
      "256 Train Loss 0.0009185548 Test MSE 2.2368775744818083e-06 Test RE 0.0010836493515230035\n",
      "257 Train Loss 0.0009085403 Test MSE 2.1709681900125777e-06 Test RE 0.001067565173568806\n",
      "258 Train Loss 0.0009015377 Test MSE 2.071146568556192e-06 Test RE 0.0010427329191630137\n",
      "259 Train Loss 0.00089225406 Test MSE 1.9864742106963947e-06 Test RE 0.0010211960664146251\n",
      "260 Train Loss 0.000881166 Test MSE 2.0629304148240785e-06 Test RE 0.0010406626245067579\n",
      "261 Train Loss 0.0008753645 Test MSE 1.9720178200165775e-06 Test RE 0.0010174734491877374\n",
      "262 Train Loss 0.00086778164 Test MSE 1.9837373262069757e-06 Test RE 0.0010204923424505033\n",
      "263 Train Loss 0.00086374156 Test MSE 1.947385149265335e-06 Test RE 0.0010110987990030375\n",
      "264 Train Loss 0.0008622454 Test MSE 1.982033840657561e-06 Test RE 0.0010200540870180048\n",
      "265 Train Loss 0.00085512135 Test MSE 2.026474622555825e-06 Test RE 0.0010314264216831756\n",
      "266 Train Loss 0.0008496721 Test MSE 1.931245931855992e-06 Test RE 0.0010069002730214056\n",
      "267 Train Loss 0.00084793125 Test MSE 1.8733835781970934e-06 Test RE 0.000991701618733366\n",
      "268 Train Loss 0.00083779934 Test MSE 1.8533420804895684e-06 Test RE 0.0009863827324972064\n",
      "269 Train Loss 0.00082288316 Test MSE 1.7794490350214218e-06 Test RE 0.0009665191084595083\n",
      "270 Train Loss 0.0008185662 Test MSE 1.7801630262326986e-06 Test RE 0.0009667129934559989\n",
      "271 Train Loss 0.00081488607 Test MSE 1.8864143684062015e-06 Test RE 0.0009951446567782018\n",
      "272 Train Loss 0.00080785295 Test MSE 1.9054342711116693e-06 Test RE 0.0010001488818004768\n",
      "273 Train Loss 0.0008024317 Test MSE 1.8785111112130765e-06 Test RE 0.000993057856758923\n",
      "274 Train Loss 0.00079740613 Test MSE 1.904769069477127e-06 Test RE 0.0009999742867602363\n",
      "275 Train Loss 0.0007916121 Test MSE 1.8512475033102733e-06 Test RE 0.0009858251886801087\n",
      "276 Train Loss 0.00078928174 Test MSE 1.9440427551274362e-06 Test RE 0.0010102307267465733\n",
      "277 Train Loss 0.0007827049 Test MSE 1.9051431095000196e-06 Test RE 0.0010000724645527035\n",
      "278 Train Loss 0.0007724057 Test MSE 1.846259322726346e-06 Test RE 0.0009844961413602719\n",
      "279 Train Loss 0.00076594844 Test MSE 1.8657090423703535e-06 Test RE 0.0009896682230148431\n",
      "280 Train Loss 0.0007571548 Test MSE 2.1411424577888285e-06 Test RE 0.0010602064678858721\n",
      "281 Train Loss 0.00074628403 Test MSE 2.0334663026817523e-06 Test RE 0.0010332041873902676\n",
      "282 Train Loss 0.0007365139 Test MSE 2.09829596090585e-06 Test RE 0.001049544941907904\n",
      "283 Train Loss 0.0007359247 Test MSE 2.060388335514358e-06 Test RE 0.001040021240196523\n",
      "284 Train Loss 0.0007302213 Test MSE 1.9718700160872586e-06 Test RE 0.0010174353183477832\n",
      "285 Train Loss 0.0007214213 Test MSE 2.042496683837314e-06 Test RE 0.001035495814239841\n",
      "286 Train Loss 0.0007087484 Test MSE 2.1058983627716854e-06 Test RE 0.0010514445424262592\n",
      "287 Train Loss 0.0006900834 Test MSE 2.105399640268933e-06 Test RE 0.00105132003259408\n",
      "288 Train Loss 0.0006901595 Test MSE 2.0548911950705866e-06 Test RE 0.0010386329190800736\n",
      "289 Train Loss 0.00067595433 Test MSE 2.0794725817809586e-06 Test RE 0.0010448267111908115\n",
      "290 Train Loss 0.0006652165 Test MSE 1.9490742896913546e-06 Test RE 0.0010115372119349872\n",
      "291 Train Loss 0.00065526174 Test MSE 1.8911468516128095e-06 Test RE 0.0009963921439284811\n",
      "292 Train Loss 0.0006476644 Test MSE 1.8400314130097605e-06 Test RE 0.0009828342587611901\n",
      "293 Train Loss 0.00064118725 Test MSE 1.814739524962042e-06 Test RE 0.0009760561826847103\n",
      "294 Train Loss 0.0006365307 Test MSE 1.7730797974489758e-06 Test RE 0.0009647878118162314\n",
      "295 Train Loss 0.00062943174 Test MSE 1.746720126765176e-06 Test RE 0.0009575893997140438\n",
      "296 Train Loss 0.00062647945 Test MSE 1.7219169952720686e-06 Test RE 0.0009507662872848477\n",
      "297 Train Loss 0.00062188663 Test MSE 1.7207537750506628e-06 Test RE 0.000950445093692114\n",
      "298 Train Loss 0.00061931007 Test MSE 1.7388570114921981e-06 Test RE 0.0009554316044312959\n",
      "299 Train Loss 0.0006143412 Test MSE 1.8001082721655993e-06 Test RE 0.0009721135159812498\n",
      "Training time: 169.09\n",
      "KG_stanALR_medium\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 17874.281 Test MSE 25.72651111949061 Test RE 3.675006524872935\n",
      "1 Train Loss 2126.8533 Test MSE 16.107199924107835 Test RE 2.907888113855996\n",
      "2 Train Loss 435.6454 Test MSE 5.6274795394084025 Test RE 1.7187971701120082\n",
      "3 Train Loss 118.80342 Test MSE 1.5290721190731227 Test RE 0.8959456235565006\n",
      "4 Train Loss 26.631931 Test MSE 0.08742833077455367 Test RE 0.21423664620310345\n",
      "5 Train Loss 9.842139 Test MSE 0.08343755179766169 Test RE 0.20928998360935436\n",
      "6 Train Loss 4.3138385 Test MSE 0.044108933190673175 Test RE 0.15217066717099387\n",
      "7 Train Loss 2.555819 Test MSE 0.02037818062850928 Test RE 0.10343091611530347\n",
      "8 Train Loss 1.8244697 Test MSE 0.011260065534078056 Test RE 0.07688438180171445\n",
      "9 Train Loss 1.3800983 Test MSE 0.007373329699634775 Test RE 0.06221562876964768\n",
      "10 Train Loss 1.0504607 Test MSE 0.007160904379096591 Test RE 0.061312864266527864\n",
      "11 Train Loss 0.73177856 Test MSE 0.002503683342354547 Test RE 0.03625411997231662\n",
      "12 Train Loss 0.53055376 Test MSE 0.000532814483245822 Test RE 0.01672459764396922\n",
      "13 Train Loss 0.3970123 Test MSE 0.0007932568507961878 Test RE 0.020406784740926616\n",
      "14 Train Loss 0.3291221 Test MSE 0.0009948451050462933 Test RE 0.022853114804833995\n",
      "15 Train Loss 0.27816 Test MSE 0.000408601107114472 Test RE 0.014645946290534161\n",
      "16 Train Loss 0.24044372 Test MSE 0.0001938099667054178 Test RE 0.010086853682962041\n",
      "17 Train Loss 0.210769 Test MSE 0.0002642709524996053 Test RE 0.011778564992467046\n",
      "18 Train Loss 0.18659687 Test MSE 0.00020189901452369134 Test RE 0.010295199510466717\n",
      "19 Train Loss 0.15267034 Test MSE 0.00017672404391219144 Test RE 0.009631978134799\n",
      "20 Train Loss 0.14022888 Test MSE 0.00019766245657403838 Test RE 0.010186611938396055\n",
      "21 Train Loss 0.12754221 Test MSE 0.0001134555509173296 Test RE 0.007717569375064168\n",
      "22 Train Loss 0.113503665 Test MSE 0.00010515150255293732 Test RE 0.007429770673624117\n",
      "23 Train Loss 0.101356715 Test MSE 9.050554748143413e-05 Test RE 0.006892952211541032\n",
      "24 Train Loss 0.08714928 Test MSE 6.826830939938342e-05 Test RE 0.005986558651003876\n",
      "25 Train Loss 0.079119086 Test MSE 5.9719443259094857e-05 Test RE 0.005599194356908837\n",
      "26 Train Loss 0.071178444 Test MSE 0.00012221023972280715 Test RE 0.008009796191556735\n",
      "27 Train Loss 0.06310133 Test MSE 8.668565348047374e-05 Test RE 0.006745921472616961\n",
      "28 Train Loss 0.05672356 Test MSE 0.00014027775970136696 Test RE 0.008581477701700582\n",
      "29 Train Loss 0.051687576 Test MSE 0.00010796316441283888 Test RE 0.007528448264828209\n",
      "30 Train Loss 0.0428729 Test MSE 0.00010307397480256149 Test RE 0.007356007775034418\n",
      "31 Train Loss 0.040502068 Test MSE 8.211244710536113e-05 Test RE 0.0065655659061726115\n",
      "32 Train Loss 0.03475418 Test MSE 5.805726656520395e-05 Test RE 0.005520723036048679\n",
      "33 Train Loss 0.031900343 Test MSE 7.855430106600548e-05 Test RE 0.00642173902370561\n",
      "34 Train Loss 0.028641658 Test MSE 6.085740500236643e-05 Test RE 0.005652289305338243\n",
      "35 Train Loss 0.02673746 Test MSE 5.344038539690882e-05 Test RE 0.005296664421437205\n",
      "36 Train Loss 0.024755146 Test MSE 5.5263865395410405e-05 Test RE 0.0053862721951684145\n",
      "37 Train Loss 0.022919448 Test MSE 6.261792025032175e-05 Test RE 0.005733462643867274\n",
      "38 Train Loss 0.020945234 Test MSE 5.956376053740586e-05 Test RE 0.005591891319418039\n",
      "39 Train Loss 0.02004686 Test MSE 5.7696813093686515e-05 Test RE 0.005503558413582045\n",
      "40 Train Loss 0.019130962 Test MSE 5.785677519344639e-05 Test RE 0.0055111823304502\n",
      "41 Train Loss 0.018603828 Test MSE 5.183141096632907e-05 Test RE 0.005216319491215523\n",
      "42 Train Loss 0.017616114 Test MSE 5.504561293809995e-05 Test RE 0.005375625725795362\n",
      "43 Train Loss 0.016970584 Test MSE 5.271198392118046e-05 Test RE 0.005260443357997285\n",
      "44 Train Loss 0.015758067 Test MSE 4.043859617834421e-05 Test RE 0.004607503809795004\n",
      "45 Train Loss 0.014864521 Test MSE 3.605595125211716e-05 Test RE 0.004350670034643305\n",
      "46 Train Loss 0.014413987 Test MSE 3.5528925961501535e-05 Test RE 0.0043187563884050945\n",
      "47 Train Loss 0.013026172 Test MSE 2.1006772336785596e-05 Test RE 0.0033208352628472815\n",
      "48 Train Loss 0.01247297 Test MSE 2.3446325767207005e-05 Test RE 0.0035083673855829684\n",
      "49 Train Loss 0.011867698 Test MSE 1.7529013754377148e-05 Test RE 0.0030335168285458808\n",
      "50 Train Loss 0.011140308 Test MSE 1.6984992164995437e-05 Test RE 0.0029860724667534464\n",
      "51 Train Loss 0.010859842 Test MSE 1.8010012330558414e-05 Test RE 0.0030748552267527195\n",
      "52 Train Loss 0.010403195 Test MSE 1.7241025752623737e-05 Test RE 0.00300849447267073\n",
      "53 Train Loss 0.009521712 Test MSE 1.2733858619468353e-05 Test RE 0.0025855186780083376\n",
      "54 Train Loss 0.009141006 Test MSE 1.3376398020410532e-05 Test RE 0.002649947434080348\n",
      "55 Train Loss 0.008572502 Test MSE 1.4717460673127683e-05 Test RE 0.0027796115629997414\n",
      "56 Train Loss 0.00786138 Test MSE 1.7063176465762283e-05 Test RE 0.002992937231108371\n",
      "57 Train Loss 0.0076513872 Test MSE 1.5988617610435545e-05 Test RE 0.0028971643038907084\n",
      "58 Train Loss 0.0073182224 Test MSE 1.5502203828363464e-05 Test RE 0.002852754434073207\n",
      "59 Train Loss 0.0068136104 Test MSE 7.1591832384290454e-06 Test RE 0.0019386499878993621\n",
      "60 Train Loss 0.0066623753 Test MSE 5.023896342795595e-06 Test RE 0.0016240073957689482\n",
      "61 Train Loss 0.006521221 Test MSE 6.241270859257885e-06 Test RE 0.0018101067292828079\n",
      "62 Train Loss 0.006294784 Test MSE 5.551987254047864e-06 Test RE 0.0017072294659551122\n",
      "63 Train Loss 0.0057395333 Test MSE 6.087742165986336e-06 Test RE 0.0017877047450985833\n",
      "64 Train Loss 0.005449092 Test MSE 5.164097877935355e-06 Test RE 0.0016465119997651557\n",
      "65 Train Loss 0.0053246077 Test MSE 4.7373197727504785e-06 Test RE 0.0015770084417290379\n",
      "66 Train Loss 0.005047622 Test MSE 4.2143553145328635e-06 Test RE 0.0014874187159925252\n",
      "67 Train Loss 0.0047494844 Test MSE 1.7141799865024632e-06 Test RE 0.000948627865708904\n",
      "68 Train Loss 0.0046212287 Test MSE 1.4767278341880495e-06 Test RE 0.0008804767614127475\n",
      "69 Train Loss 0.004544916 Test MSE 1.065492097658373e-06 Test RE 0.0007478987100760266\n",
      "70 Train Loss 0.0043447735 Test MSE 1.3836208629317213e-06 Test RE 0.0008522680711414083\n",
      "71 Train Loss 0.0042402674 Test MSE 1.5020381671723465e-06 Test RE 0.0008879901569740414\n",
      "72 Train Loss 0.0041896896 Test MSE 2.0711232953465833e-06 Test RE 0.0010427270606182023\n",
      "73 Train Loss 0.004084391 Test MSE 9.908424288350888e-07 Test RE 0.000721223659652441\n",
      "74 Train Loss 0.00393062 Test MSE 7.249287549415808e-07 Test RE 0.0006169007965822541\n",
      "75 Train Loss 0.0037544407 Test MSE 1.0570571639521692e-06 Test RE 0.0007449324699090652\n",
      "76 Train Loss 0.0037033297 Test MSE 1.2767241082474528e-06 Test RE 0.0008186838010007753\n",
      "77 Train Loss 0.0036571375 Test MSE 1.2989212581233216e-06 Test RE 0.0008257699598453526\n",
      "78 Train Loss 0.0036224795 Test MSE 1.5960181156492518e-06 Test RE 0.0009153487143878056\n",
      "79 Train Loss 0.0035143986 Test MSE 1.4797779630649105e-06 Test RE 0.0008813855891017146\n",
      "80 Train Loss 0.003407509 Test MSE 1.252035147640873e-06 Test RE 0.0008107294104825093\n",
      "81 Train Loss 0.0033348734 Test MSE 1.2736493227497833e-06 Test RE 0.0008176973723335781\n",
      "82 Train Loss 0.0032939082 Test MSE 1.5360017739592832e-06 Test RE 0.0008979735120875577\n",
      "83 Train Loss 0.0032283415 Test MSE 1.7953466119288474e-06 Test RE 0.0009708269435330705\n",
      "84 Train Loss 0.0031664346 Test MSE 1.5192666415584097e-06 Test RE 0.0008930682889740754\n",
      "85 Train Loss 0.0030848891 Test MSE 1.6516839113594424e-06 Test RE 0.0009311746339231416\n",
      "86 Train Loss 0.0030444786 Test MSE 1.717134663335022e-06 Test RE 0.0009494450733612878\n",
      "87 Train Loss 0.0029756336 Test MSE 1.483799232890874e-06 Test RE 0.0008825823512996792\n",
      "88 Train Loss 0.0028957964 Test MSE 1.836328628343571e-06 Test RE 0.0009818448581759259\n",
      "89 Train Loss 0.0028219742 Test MSE 1.6528531893566797e-06 Test RE 0.0009315041792352286\n",
      "90 Train Loss 0.0027799073 Test MSE 1.6458673395175174e-06 Test RE 0.0009295335750631619\n",
      "91 Train Loss 0.00273177 Test MSE 1.6689790508383172e-06 Test RE 0.0009360372033164173\n",
      "92 Train Loss 0.0026714797 Test MSE 1.3302905821153889e-06 Test RE 0.0008356817652722214\n",
      "93 Train Loss 0.0025359844 Test MSE 9.98099348371054e-07 Test RE 0.0007238599586539605\n",
      "94 Train Loss 0.0024591102 Test MSE 9.236384052253487e-07 Test RE 0.0006963356963163145\n",
      "95 Train Loss 0.0024018593 Test MSE 8.072974206671217e-07 Test RE 0.0006510051887997758\n",
      "96 Train Loss 0.0023561062 Test MSE 6.316592424036117e-07 Test RE 0.0005758496340708387\n",
      "97 Train Loss 0.0022766956 Test MSE 9.216434692144787e-07 Test RE 0.0006955832936164729\n",
      "98 Train Loss 0.0021817416 Test MSE 1.027574458104981e-06 Test RE 0.000734470433961761\n",
      "99 Train Loss 0.0021315983 Test MSE 6.685699841733109e-07 Test RE 0.0005924355416967812\n",
      "100 Train Loss 0.0020410696 Test MSE 8.095484528997685e-07 Test RE 0.0006519121739519202\n",
      "101 Train Loss 0.0019698113 Test MSE 8.481445562168428e-07 Test RE 0.000667271547823507\n",
      "102 Train Loss 0.0019238134 Test MSE 9.495153576408097e-07 Test RE 0.0007060226995244565\n",
      "103 Train Loss 0.0018870139 Test MSE 8.82896842801194e-07 Test RE 0.0006808048634564154\n",
      "104 Train Loss 0.001848559 Test MSE 7.198169738698148e-07 Test RE 0.0006147219337764854\n",
      "105 Train Loss 0.0018036137 Test MSE 7.910165859173862e-07 Test RE 0.0006444073163061017\n",
      "106 Train Loss 0.0017769942 Test MSE 1.0031497463674357e-06 Test RE 0.0007256890190462578\n",
      "107 Train Loss 0.0017287101 Test MSE 1.4945682148342158e-06 Test RE 0.0008857793237222458\n",
      "108 Train Loss 0.0016844176 Test MSE 1.2507608813554498e-06 Test RE 0.0008103167430956042\n",
      "109 Train Loss 0.0016481713 Test MSE 1.1544323479555568e-06 Test RE 0.0007784879800317676\n",
      "110 Train Loss 0.0016332146 Test MSE 8.923612446350059e-07 Test RE 0.0006844441532035031\n",
      "111 Train Loss 0.0016153302 Test MSE 1.024548242637984e-06 Test RE 0.0007333881257035811\n",
      "112 Train Loss 0.0015816271 Test MSE 9.84720777546418e-07 Test RE 0.0007189922653824998\n",
      "113 Train Loss 0.0015387487 Test MSE 8.486233300826777e-07 Test RE 0.0006674598571769852\n",
      "114 Train Loss 0.0015057261 Test MSE 9.173565651730758e-07 Test RE 0.000693963700738028\n",
      "115 Train Loss 0.0014766393 Test MSE 1.166619784688742e-06 Test RE 0.0007825864720461085\n",
      "116 Train Loss 0.0014644009 Test MSE 1.2752797426012366e-06 Test RE 0.0008182205790034478\n",
      "117 Train Loss 0.0014508378 Test MSE 1.3034551211019765e-06 Test RE 0.0008272098725753808\n",
      "118 Train Loss 0.0014276201 Test MSE 1.1856246312566974e-06 Test RE 0.0007889350924164455\n",
      "119 Train Loss 0.0014057432 Test MSE 1.1544333511098012e-06 Test RE 0.0007784883182687174\n",
      "120 Train Loss 0.001390595 Test MSE 1.2084852370612372e-06 Test RE 0.0007965046991375263\n",
      "121 Train Loss 0.0013808004 Test MSE 1.199288417829818e-06 Test RE 0.0007934681292359102\n",
      "122 Train Loss 0.0013706698 Test MSE 1.1960747057174379e-06 Test RE 0.0007924042947673398\n",
      "123 Train Loss 0.0013446911 Test MSE 1.3550803666000524e-06 Test RE 0.0008434322328575412\n",
      "124 Train Loss 0.0013096273 Test MSE 1.332491140971451e-06 Test RE 0.0008363726695981\n",
      "125 Train Loss 0.0012633612 Test MSE 1.4120276286350814e-06 Test RE 0.0008609724699697898\n",
      "126 Train Loss 0.0012424034 Test MSE 1.337146970918999e-06 Test RE 0.0008378325717461265\n",
      "127 Train Loss 0.0012233516 Test MSE 1.235198701559431e-06 Test RE 0.0008052599149557993\n",
      "128 Train Loss 0.0011978471 Test MSE 1.079259434577713e-06 Test RE 0.0007527150413881424\n",
      "129 Train Loss 0.001178668 Test MSE 1.0352393925820787e-06 Test RE 0.0007372046438314257\n",
      "130 Train Loss 0.0011689765 Test MSE 9.527508818310209e-07 Test RE 0.0007072245815157351\n",
      "131 Train Loss 0.0011555257 Test MSE 1.037018837414653e-06 Test RE 0.0007378379523089561\n",
      "132 Train Loss 0.0011429829 Test MSE 1.084938724637424e-06 Test RE 0.0007546929152085497\n",
      "133 Train Loss 0.0011277602 Test MSE 1.018341498091366e-06 Test RE 0.0007311633072477134\n",
      "134 Train Loss 0.001110269 Test MSE 9.939622246242778e-07 Test RE 0.000722358200369632\n",
      "135 Train Loss 0.0010920308 Test MSE 8.981677039030241e-07 Test RE 0.0006866673297444306\n",
      "136 Train Loss 0.0010722403 Test MSE 8.391795825506479e-07 Test RE 0.0006637356153651719\n",
      "137 Train Loss 0.0010574731 Test MSE 7.866239374728086e-07 Test RE 0.0006426155741534748\n",
      "138 Train Loss 0.0010451509 Test MSE 8.994309633870252e-07 Test RE 0.000687150053748635\n",
      "139 Train Loss 0.0010346206 Test MSE 9.501532643442087e-07 Test RE 0.0007062598210155199\n",
      "140 Train Loss 0.0010254306 Test MSE 8.616620372984983e-07 Test RE 0.0006725679181002398\n",
      "141 Train Loss 0.0010186571 Test MSE 8.580148435171004e-07 Test RE 0.0006711430051735663\n",
      "142 Train Loss 0.0010094134 Test MSE 8.151807275514248e-07 Test RE 0.0006541760187852378\n",
      "143 Train Loss 0.0009988301 Test MSE 7.594243195165417e-07 Test RE 0.0006314077642681333\n",
      "144 Train Loss 0.0009927873 Test MSE 7.806059177755007e-07 Test RE 0.0006401527084726921\n",
      "145 Train Loss 0.0009817753 Test MSE 9.080962606771658e-07 Test RE 0.0006904521897876118\n",
      "146 Train Loss 0.00095564045 Test MSE 9.268661622616189e-07 Test RE 0.0006975513464182067\n",
      "147 Train Loss 0.0009389524 Test MSE 9.34555340829036e-07 Test RE 0.0007004387745245707\n",
      "148 Train Loss 0.00092136837 Test MSE 1.1101084036122768e-06 Test RE 0.0007633968486188054\n",
      "149 Train Loss 0.0008973616 Test MSE 9.644644715550596e-07 Test RE 0.0007115587845883231\n",
      "150 Train Loss 0.000861972 Test MSE 7.897246561469241e-07 Test RE 0.0006438808613483596\n",
      "151 Train Loss 0.0008412118 Test MSE 6.880473612274754e-07 Test RE 0.0006010032692894932\n",
      "152 Train Loss 0.0008298105 Test MSE 5.544842174040373e-07 Test RE 0.000539525855676762\n",
      "153 Train Loss 0.00082360365 Test MSE 5.359240440669155e-07 Test RE 0.0005304192640635746\n",
      "154 Train Loss 0.0008195188 Test MSE 5.106327032089074e-07 Test RE 0.0005177522327435006\n",
      "155 Train Loss 0.00081538875 Test MSE 5.043728115862702e-07 Test RE 0.0005145688610654692\n",
      "156 Train Loss 0.0008128971 Test MSE 4.920060773447122e-07 Test RE 0.0005082213450904161\n",
      "157 Train Loss 0.0008093136 Test MSE 4.923598074714552e-07 Test RE 0.0005084040063506098\n",
      "158 Train Loss 0.0008057944 Test MSE 4.925434940998338e-07 Test RE 0.000508498833657715\n",
      "159 Train Loss 0.0007977182 Test MSE 4.910221024788164e-07 Test RE 0.0005077128886583803\n",
      "160 Train Loss 0.0007862082 Test MSE 4.409496515963654e-07 Test RE 0.000481129703257552\n",
      "161 Train Loss 0.00077692216 Test MSE 3.988563487517975e-07 Test RE 0.0004575893649789491\n",
      "162 Train Loss 0.00076662283 Test MSE 4.35488382645455e-07 Test RE 0.0004781409660215495\n",
      "163 Train Loss 0.0007580775 Test MSE 4.2746767388225097e-07 Test RE 0.0004737173668687905\n",
      "164 Train Loss 0.0007520432 Test MSE 4.1614069250481844e-07 Test RE 0.00046739898013268573\n",
      "165 Train Loss 0.0007462687 Test MSE 4.3843246419959673e-07 Test RE 0.00047975445897294314\n",
      "166 Train Loss 0.0007419312 Test MSE 4.809624841613911e-07 Test RE 0.000502485192968635\n",
      "167 Train Loss 0.0007364106 Test MSE 5.756920634193144e-07 Test RE 0.0005497468996203328\n",
      "168 Train Loss 0.00073303835 Test MSE 5.59048743247583e-07 Test RE 0.0005417419983373921\n",
      "169 Train Loss 0.0007180779 Test MSE 5.705801014534211e-07 Test RE 0.0005473006684812969\n",
      "170 Train Loss 0.0007014031 Test MSE 4.781963828222721e-07 Test RE 0.000501038168299135\n",
      "171 Train Loss 0.00069202605 Test MSE 3.426353131411793e-07 Test RE 0.0004241150930475276\n",
      "172 Train Loss 0.000680265 Test MSE 3.1739998187285957e-07 Test RE 0.000408198229275504\n",
      "173 Train Loss 0.0006736696 Test MSE 2.6480173901600664e-07 Test RE 0.0003728447945516824\n",
      "174 Train Loss 0.000657012 Test MSE 2.481632473245246e-07 Test RE 0.0003609411513764303\n",
      "175 Train Loss 0.00064134935 Test MSE 2.5733114872646667e-07 Test RE 0.00036754781643935245\n",
      "176 Train Loss 0.0006328351 Test MSE 3.074598475582126e-07 Test RE 0.00040175553744306803\n",
      "177 Train Loss 0.00062665984 Test MSE 3.0529606052624777e-07 Test RE 0.00040033933901911925\n",
      "178 Train Loss 0.00061448035 Test MSE 2.551275539143133e-07 Test RE 0.0003659707282532215\n",
      "179 Train Loss 0.000606932 Test MSE 2.7179584149538747e-07 Test RE 0.00037773660397728116\n",
      "180 Train Loss 0.00060147536 Test MSE 2.5535259135184536e-07 Test RE 0.00036613209647999773\n",
      "181 Train Loss 0.00059608545 Test MSE 2.4431351312563074e-07 Test RE 0.0003581305849012633\n",
      "182 Train Loss 0.0005868573 Test MSE 2.868512841780593e-07 Test RE 0.00038805748696299453\n",
      "183 Train Loss 0.00057690556 Test MSE 3.1158926488896836e-07 Test RE 0.00040444447866462124\n",
      "184 Train Loss 0.0005650547 Test MSE 2.398919225210668e-07 Test RE 0.00035487506094686826\n",
      "185 Train Loss 0.00055802823 Test MSE 2.3122027106144277e-07 Test RE 0.00034840198494183255\n",
      "186 Train Loss 0.00055332616 Test MSE 2.623087805380677e-07 Test RE 0.0003710855829217883\n",
      "187 Train Loss 0.0005484754 Test MSE 2.6962048696349047e-07 Test RE 0.00037622193434470224\n",
      "188 Train Loss 0.00054549304 Test MSE 2.616614549119627e-07 Test RE 0.0003706274175689196\n",
      "189 Train Loss 0.0005428707 Test MSE 2.608382777256456e-07 Test RE 0.0003700439683079346\n",
      "190 Train Loss 0.0005415678 Test MSE 2.5409153614225673e-07 Test RE 0.0003652269084071364\n",
      "191 Train Loss 0.0005410214 Test MSE 2.5740105679528573e-07 Test RE 0.0003675977381323286\n",
      "192 Train Loss 0.0005377752 Test MSE 2.4415608969800696e-07 Test RE 0.0003580151855763692\n",
      "193 Train Loss 0.0005328095 Test MSE 2.3133701433101362e-07 Test RE 0.00034848992804025934\n",
      "194 Train Loss 0.00052793836 Test MSE 2.0909400386306018e-07 Test RE 0.0003313129848066201\n",
      "195 Train Loss 0.00052342704 Test MSE 2.175198957018321e-07 Test RE 0.00033792253992831933\n",
      "196 Train Loss 0.00051992055 Test MSE 2.2073675992870161e-07 Test RE 0.00034041210834486656\n",
      "197 Train Loss 0.0005148544 Test MSE 2.689038517730327e-07 Test RE 0.00037572161392486903\n",
      "198 Train Loss 0.0005082808 Test MSE 2.5631289359825716e-07 Test RE 0.00036681990530661786\n",
      "199 Train Loss 0.00050179765 Test MSE 2.1355545008494195e-07 Test RE 0.0003348289472335023\n",
      "200 Train Loss 0.0004970601 Test MSE 1.951165767559681e-07 Test RE 0.0003200477302549153\n",
      "201 Train Loss 0.0004923928 Test MSE 1.9537902848717014e-07 Test RE 0.0003202629063693331\n",
      "202 Train Loss 0.0004837602 Test MSE 1.9349045291040424e-07 Test RE 0.0003187112827253631\n",
      "203 Train Loss 0.0004805796 Test MSE 2.1783900052329759e-07 Test RE 0.00033817031770600695\n",
      "204 Train Loss 0.00047746886 Test MSE 2.0231156015581654e-07 Test RE 0.0003258952400149539\n",
      "205 Train Loss 0.0004732749 Test MSE 1.7984729751272326e-07 Test RE 0.0003072696217311608\n",
      "206 Train Loss 0.00046623257 Test MSE 1.6987110661089508e-07 Test RE 0.0002986258683666361\n",
      "207 Train Loss 0.0004629555 Test MSE 1.848611249506974e-07 Test RE 0.00031152324885475274\n",
      "208 Train Loss 0.00046127703 Test MSE 1.8599833761447492e-07 Test RE 0.0003124799806016225\n",
      "209 Train Loss 0.00045596095 Test MSE 2.0665937253338842e-07 Test RE 0.0003293784798563863\n",
      "210 Train Loss 0.0004498966 Test MSE 2.117665902357088e-07 Test RE 0.00033342364090399845\n",
      "211 Train Loss 0.0004478856 Test MSE 2.169313677138806e-07 Test RE 0.000337465083896813\n",
      "212 Train Loss 0.00044457926 Test MSE 2.3274653598314142e-07 Test RE 0.0003495499792225582\n",
      "213 Train Loss 0.0004423974 Test MSE 2.2612088455536967e-07 Test RE 0.0003445386958548619\n",
      "214 Train Loss 0.00043944668 Test MSE 2.2114675701971173e-07 Test RE 0.0003407281028938492\n",
      "215 Train Loss 0.0004369297 Test MSE 2.4136658198887267e-07 Test RE 0.00035596413074495014\n",
      "216 Train Loss 0.00043520224 Test MSE 2.3293047477218174e-07 Test RE 0.0003496880760183824\n",
      "217 Train Loss 0.0004327669 Test MSE 2.1690825915348064e-07 Test RE 0.00033744710922573116\n",
      "218 Train Loss 0.00042963205 Test MSE 2.276659363287761e-07 Test RE 0.00034571378386937657\n",
      "219 Train Loss 0.00042887483 Test MSE 2.315123693349668e-07 Test RE 0.0003486219818685869\n",
      "220 Train Loss 0.00042865548 Test MSE 2.315123693349668e-07 Test RE 0.0003486219818685869\n",
      "221 Train Loss 0.00042839634 Test MSE 2.315123693349668e-07 Test RE 0.0003486219818685869\n",
      "222 Train Loss 0.000428107 Test MSE 2.315123693349668e-07 Test RE 0.0003486219818685869\n",
      "223 Train Loss 0.00042779458 Test MSE 2.315123693349668e-07 Test RE 0.0003486219818685869\n",
      "224 Train Loss 0.00042746373 Test MSE 2.315123693349668e-07 Test RE 0.0003486219818685869\n",
      "225 Train Loss 0.00042711798 Test MSE 2.315123693349668e-07 Test RE 0.0003486219818685869\n",
      "226 Train Loss 0.0004267593 Test MSE 2.315123693349668e-07 Test RE 0.0003486219818685869\n",
      "227 Train Loss 0.00042638893 Test MSE 2.315123693349668e-07 Test RE 0.0003486219818685869\n",
      "228 Train Loss 0.00042559244 Test MSE 2.3147375583703344e-07 Test RE 0.0003485929076649778\n",
      "229 Train Loss 0.0004245642 Test MSE 2.407115023688063e-07 Test RE 0.0003554807513160722\n",
      "230 Train Loss 0.00042265008 Test MSE 2.4892552957642384e-07 Test RE 0.0003614950772187897\n",
      "231 Train Loss 0.00041881113 Test MSE 2.2710828289042834e-07 Test RE 0.00034529012215695577\n",
      "232 Train Loss 0.00041559074 Test MSE 2.1528981428192478e-07 Test RE 0.0003361858338163515\n",
      "233 Train Loss 0.00041160875 Test MSE 2.0876243077247973e-07 Test RE 0.00033105018899806893\n",
      "234 Train Loss 0.00040840099 Test MSE 2.139564643729715e-07 Test RE 0.0003351431705824179\n",
      "235 Train Loss 0.00040334865 Test MSE 1.9093470920994022e-07 Test RE 0.0003165994162057599\n",
      "236 Train Loss 0.00039844544 Test MSE 2.0040040090879596e-07 Test RE 0.0003243522841482027\n",
      "237 Train Loss 0.00039122172 Test MSE 1.8974627568152523e-07 Test RE 0.00031561257448358505\n",
      "238 Train Loss 0.00038787245 Test MSE 2.0861683901666957e-07 Test RE 0.00033093473100011554\n",
      "239 Train Loss 0.00038633498 Test MSE 2.0239304645889022e-07 Test RE 0.0003259608648482168\n",
      "240 Train Loss 0.00038566967 Test MSE 2.0324599610247754e-07 Test RE 0.0003266469948779308\n",
      "241 Train Loss 0.00038162642 Test MSE 2.0687373383251786e-07 Test RE 0.00032954926257512657\n",
      "242 Train Loss 0.000375017 Test MSE 2.0766150253648758e-07 Test RE 0.0003301761230149714\n",
      "243 Train Loss 0.0003705973 Test MSE 2.3787255552780002e-07 Test RE 0.00035337826718425\n",
      "244 Train Loss 0.00036790426 Test MSE 2.8692956211179516e-07 Test RE 0.00038811043123740207\n",
      "245 Train Loss 0.00036389 Test MSE 2.7415523204366765e-07 Test RE 0.00037937257895503506\n",
      "246 Train Loss 0.0003592327 Test MSE 2.5694416036531194e-07 Test RE 0.00036727134341250846\n",
      "247 Train Loss 0.00035390336 Test MSE 2.0285432536495906e-07 Test RE 0.00032633210610289067\n",
      "248 Train Loss 0.0003466937 Test MSE 1.655460512094016e-07 Test RE 0.00029479972944819043\n",
      "249 Train Loss 0.00034454948 Test MSE 1.3979917132978408e-07 Test RE 0.00027090683733702547\n",
      "250 Train Loss 0.00033880936 Test MSE 1.246735449357065e-07 Test RE 0.0002558319739539301\n",
      "251 Train Loss 0.00033529868 Test MSE 1.2373377669994295e-07 Test RE 0.00025486594084243695\n",
      "252 Train Loss 0.00033188402 Test MSE 1.2789395827737491e-07 Test RE 0.0002591150759716522\n",
      "253 Train Loss 0.00032876834 Test MSE 1.3066407571576128e-07 Test RE 0.00026190619311449126\n",
      "254 Train Loss 0.00032741146 Test MSE 1.305536108156894e-07 Test RE 0.0002617954604642932\n",
      "255 Train Loss 0.00032544692 Test MSE 1.4109091793653163e-07 Test RE 0.0002721555512173747\n",
      "256 Train Loss 0.00032343876 Test MSE 1.408472467488485e-07 Test RE 0.0002719204364236687\n",
      "257 Train Loss 0.00032092643 Test MSE 1.385541643832257e-07 Test RE 0.00026969783451275046\n",
      "258 Train Loss 0.00032079752 Test MSE 1.3365501823458432e-07 Test RE 0.00026488679120875545\n",
      "259 Train Loss 0.00032077357 Test MSE 1.3429498989044366e-07 Test RE 0.0002655202040036826\n",
      "260 Train Loss 0.00032013992 Test MSE 1.3540962600379078e-07 Test RE 0.00026661982371734255\n",
      "261 Train Loss 0.00031957755 Test MSE 1.374723844599021e-07 Test RE 0.0002686429206656488\n",
      "262 Train Loss 0.00031952513 Test MSE 1.3750311523395498e-07 Test RE 0.0002686729453997524\n",
      "263 Train Loss 0.00031884687 Test MSE 1.5293409692670377e-07 Test RE 0.00028334778963888107\n",
      "264 Train Loss 0.0003177956 Test MSE 1.4793352398452174e-07 Test RE 0.0002786768989013899\n",
      "265 Train Loss 0.00031831866 Test MSE 1.49211073301218e-07 Test RE 0.0002798776346152783\n",
      "266 Train Loss 0.00031863106 Test MSE 1.4741843261721563e-07 Test RE 0.00027819131175742246\n",
      "267 Train Loss 0.0003164906 Test MSE 1.749188306393949e-07 Test RE 0.00030303022641952666\n",
      "268 Train Loss 0.00031487359 Test MSE 1.816121661977095e-07 Test RE 0.00030877358268559707\n",
      "269 Train Loss 0.00031252264 Test MSE 1.939159936601982e-07 Test RE 0.0003190615587951678\n",
      "270 Train Loss 0.00031168718 Test MSE 2.1070408404324015e-07 Test RE 0.00033258613823618455\n",
      "271 Train Loss 0.000311168 Test MSE 2.116156707697891e-07 Test RE 0.0003333048093962847\n",
      "272 Train Loss 0.00031048426 Test MSE 2.1163717648578005e-07 Test RE 0.00033332174523198894\n",
      "273 Train Loss 0.00031035824 Test MSE 2.1388470316002392e-07 Test RE 0.00033508696219099833\n",
      "274 Train Loss 0.0003099437 Test MSE 2.1426418418379397e-07 Test RE 0.0003353840914132386\n",
      "275 Train Loss 0.00030936868 Test MSE 2.2244133661211739e-07 Test RE 0.00034172394835526925\n",
      "276 Train Loss 0.00030722693 Test MSE 2.3974350102822684e-07 Test RE 0.00035476526309455823\n",
      "277 Train Loss 0.0003064519 Test MSE 2.293078842431912e-07 Test RE 0.00034695820416850114\n",
      "278 Train Loss 0.00030614578 Test MSE 2.30393579977215e-07 Test RE 0.00034777859946249167\n",
      "279 Train Loss 0.00030549258 Test MSE 2.316793338184454e-07 Test RE 0.0003487476706134521\n",
      "280 Train Loss 0.00030658024 Test MSE 2.3286490968579965e-07 Test RE 0.00034963885759268674\n",
      "281 Train Loss 0.0003050011 Test MSE 2.1383595416482732e-07 Test RE 0.00033504877319627475\n",
      "282 Train Loss 0.00030255012 Test MSE 2.1953230222786043e-07 Test RE 0.00033948210278580797\n",
      "283 Train Loss 0.00030012114 Test MSE 2.1392221438972492e-07 Test RE 0.0003351163447806798\n",
      "284 Train Loss 0.0002995132 Test MSE 2.1711120028665562e-07 Test RE 0.0003376049314507435\n",
      "285 Train Loss 0.00029629463 Test MSE 1.8218214648278727e-07 Test RE 0.00030925773797918244\n",
      "286 Train Loss 0.0002944441 Test MSE 1.764648861083803e-07 Test RE 0.0003043664772127201\n",
      "287 Train Loss 0.00029192783 Test MSE 1.8756369973440268e-07 Test RE 0.000313792141450628\n",
      "288 Train Loss 0.00028950296 Test MSE 2.1020303575599995e-07 Test RE 0.0003321904627063212\n",
      "289 Train Loss 0.00028786893 Test MSE 2.0657056905613163e-07 Test RE 0.00032930770373598424\n",
      "290 Train Loss 0.00028782425 Test MSE 2.042387087093454e-07 Test RE 0.0003274437426785057\n",
      "291 Train Loss 0.00028435473 Test MSE 2.123950567294544e-07 Test RE 0.0003339180303820037\n",
      "292 Train Loss 0.00028246344 Test MSE 2.1484183091730418e-07 Test RE 0.0003358358774340382\n",
      "293 Train Loss 0.00027884857 Test MSE 2.042421431068308e-07 Test RE 0.0003274464957492777\n",
      "294 Train Loss 0.0002796117 Test MSE 2.0463336474716406e-07 Test RE 0.00032775995424198177\n",
      "295 Train Loss 0.00027771448 Test MSE 1.9303092787340074e-07 Test RE 0.0003183326002877174\n",
      "296 Train Loss 0.0002753298 Test MSE 2.000228456173958e-07 Test RE 0.00032404659949328887\n",
      "297 Train Loss 0.00027458195 Test MSE 2.301463791980638e-07 Test RE 0.0003475919748746228\n",
      "298 Train Loss 0.0002716133 Test MSE 2.2204849838445257e-07 Test RE 0.00034142206752314525\n",
      "299 Train Loss 0.00027178653 Test MSE 2.304372134150896e-07 Test RE 0.00034781153019239477\n",
      "Training time: 157.66\n",
      "KG_stanALR_medium\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 23220.68 Test MSE 5.146391409740791 Test RE 1.6436868261873703\n",
      "1 Train Loss 2119.425 Test MSE 3.915249732895433 Test RE 1.4336640723604352\n",
      "2 Train Loss 327.93997 Test MSE 2.6960642049107877 Test RE 1.1896871832192035\n",
      "3 Train Loss 59.870026 Test MSE 0.25030298209105406 Test RE 0.362493880657818\n",
      "4 Train Loss 18.081085 Test MSE 0.10801054936691859 Test RE 0.23812267637541776\n",
      "5 Train Loss 8.077774 Test MSE 0.012881155367872947 Test RE 0.082232799779536\n",
      "6 Train Loss 4.5180492 Test MSE 0.00688476121582213 Test RE 0.06011904993097679\n",
      "7 Train Loss 3.0085008 Test MSE 0.00695903838534351 Test RE 0.06044248114160445\n",
      "8 Train Loss 2.2065678 Test MSE 0.002195592615843664 Test RE 0.03395029469576665\n",
      "9 Train Loss 1.4875002 Test MSE 0.0018538365608209303 Test RE 0.03119632162316469\n",
      "10 Train Loss 1.0943949 Test MSE 0.0029276960018642557 Test RE 0.039204024999960584\n",
      "11 Train Loss 0.922158 Test MSE 0.0022576370962189077 Test RE 0.03442664759307834\n",
      "12 Train Loss 0.72217685 Test MSE 0.0010157323028845736 Test RE 0.023091774076034865\n",
      "13 Train Loss 0.5856874 Test MSE 0.000570355957641639 Test RE 0.017303767009326523\n",
      "14 Train Loss 0.4809285 Test MSE 0.000533191785911438 Test RE 0.016730518202387988\n",
      "15 Train Loss 0.38483104 Test MSE 0.000538285586434538 Test RE 0.016810245001523883\n",
      "16 Train Loss 0.3183827 Test MSE 0.0005807443059210198 Test RE 0.017460639580949743\n",
      "17 Train Loss 0.2666082 Test MSE 0.0005758772833361652 Test RE 0.01738731976850077\n",
      "18 Train Loss 0.22410575 Test MSE 0.00026501579739085876 Test RE 0.011795152193554906\n",
      "19 Train Loss 0.18545116 Test MSE 0.0002560100872340027 Test RE 0.011593009892223758\n",
      "20 Train Loss 0.16260527 Test MSE 0.00023345704338149676 Test RE 0.01107059997348563\n",
      "21 Train Loss 0.14609936 Test MSE 0.00034750642359852293 Test RE 0.013506694784774769\n",
      "22 Train Loss 0.13360791 Test MSE 0.0002708518081877819 Test RE 0.01192431766808824\n",
      "23 Train Loss 0.11840961 Test MSE 0.00022678976782322335 Test RE 0.01091137284109062\n",
      "24 Train Loss 0.10958953 Test MSE 0.00018131176229775603 Test RE 0.009756199158519262\n",
      "25 Train Loss 0.10221578 Test MSE 0.00020474547731863418 Test RE 0.010367518674035054\n",
      "26 Train Loss 0.09227312 Test MSE 0.0001511959514292103 Test RE 0.008909180313964237\n",
      "27 Train Loss 0.08292808 Test MSE 0.0001045237719242582 Test RE 0.007407560453345367\n",
      "28 Train Loss 0.07625313 Test MSE 6.810148059777202e-05 Test RE 0.005979239432790009\n",
      "29 Train Loss 0.07240585 Test MSE 7.068933703110962e-05 Test RE 0.006091785768032122\n",
      "30 Train Loss 0.06522558 Test MSE 6.384154855095988e-05 Test RE 0.0057892109388071366\n",
      "31 Train Loss 0.05581272 Test MSE 5.140614191590631e-05 Test RE 0.005194875850718369\n",
      "32 Train Loss 0.051467188 Test MSE 5.34097481466119e-05 Test RE 0.005295145920989586\n",
      "33 Train Loss 0.04472362 Test MSE 6.422157033070493e-05 Test RE 0.005806415737605743\n",
      "34 Train Loss 0.04113446 Test MSE 6.26870183143275e-05 Test RE 0.005736625172541004\n",
      "35 Train Loss 0.037655335 Test MSE 5.467819501631217e-05 Test RE 0.005357655100897659\n",
      "36 Train Loss 0.03529368 Test MSE 4.648670199727849e-05 Test RE 0.0049400578619196115\n",
      "37 Train Loss 0.03298807 Test MSE 4.171166444736251e-05 Test RE 0.0046794674177327794\n",
      "38 Train Loss 0.031883117 Test MSE 4.446489688896081e-05 Test RE 0.0048314369058750795\n",
      "39 Train Loss 0.02972291 Test MSE 5.201824311031989e-05 Test RE 0.0052257124391705\n",
      "40 Train Loss 0.028153827 Test MSE 5.889788272728708e-05 Test RE 0.005560546912893994\n",
      "41 Train Loss 0.026938144 Test MSE 5.052914068555454e-05 Test RE 0.005150372303823488\n",
      "42 Train Loss 0.025375929 Test MSE 4.7723216189666596e-05 Test RE 0.005005327741948516\n",
      "43 Train Loss 0.024684863 Test MSE 4.831410468530406e-05 Test RE 0.005036219330468694\n",
      "44 Train Loss 0.023056334 Test MSE 5.2665899834625355e-05 Test RE 0.005258143352216705\n",
      "45 Train Loss 0.021724029 Test MSE 5.2867549732542156e-05 Test RE 0.005268200059452956\n",
      "46 Train Loss 0.020593334 Test MSE 5.0516592600379225e-05 Test RE 0.005149732758778213\n",
      "47 Train Loss 0.018984582 Test MSE 5.3030641403289976e-05 Test RE 0.005276319765544146\n",
      "48 Train Loss 0.018451964 Test MSE 5.098057522275623e-05 Test RE 0.00517332822470319\n",
      "49 Train Loss 0.017580317 Test MSE 5.459491096215222e-05 Test RE 0.005353573242680814\n",
      "50 Train Loss 0.016519904 Test MSE 5.484551244836562e-05 Test RE 0.0053658461573434955\n",
      "51 Train Loss 0.015920382 Test MSE 5.249639268541099e-05 Test RE 0.005249674768049079\n",
      "52 Train Loss 0.01494458 Test MSE 5.1068614751920464e-05 Test RE 0.005177793267651115\n",
      "53 Train Loss 0.013508124 Test MSE 4.44999188388754e-05 Test RE 0.004833339227124271\n",
      "54 Train Loss 0.012945013 Test MSE 4.666100900959203e-05 Test RE 0.00494931084196001\n",
      "55 Train Loss 0.0122729065 Test MSE 5.1320126481230806e-05 Test RE 0.005190527862685684\n",
      "56 Train Loss 0.011887289 Test MSE 5.00803683883653e-05 Test RE 0.005127449893889392\n",
      "57 Train Loss 0.010979213 Test MSE 5.114216913846611e-05 Test RE 0.005181520727003053\n",
      "58 Train Loss 0.010539992 Test MSE 4.710287001428907e-05 Test RE 0.004972689617870054\n",
      "59 Train Loss 0.010276973 Test MSE 4.619904911790614e-05 Test RE 0.004924749968442409\n",
      "60 Train Loss 0.00975717 Test MSE 3.944250696511762e-05 Test RE 0.004550403650253867\n",
      "61 Train Loss 0.00926723 Test MSE 3.806230038656709e-05 Test RE 0.004470078848916866\n",
      "62 Train Loss 0.0089445915 Test MSE 4.256370692726228e-05 Test RE 0.004727019455127681\n",
      "63 Train Loss 0.0086396495 Test MSE 3.7921462062301064e-05 Test RE 0.004461801079814526\n",
      "64 Train Loss 0.0082787555 Test MSE 3.5409288768738514e-05 Test RE 0.004311478943757463\n",
      "65 Train Loss 0.007846018 Test MSE 3.880679890849223e-05 Test RE 0.004513584503365917\n",
      "66 Train Loss 0.007646059 Test MSE 3.6172701881675534e-05 Test RE 0.004357708164645678\n",
      "67 Train Loss 0.007496228 Test MSE 3.577234728108172e-05 Test RE 0.004333525802677295\n",
      "68 Train Loss 0.0072915964 Test MSE 3.723272153950352e-05 Test RE 0.004421097155276758\n",
      "69 Train Loss 0.0070885937 Test MSE 3.944880144132844e-05 Test RE 0.004550766726375145\n",
      "70 Train Loss 0.006794502 Test MSE 4.234537993533501e-05 Test RE 0.004714880442177703\n",
      "71 Train Loss 0.006524021 Test MSE 4.228517855617884e-05 Test RE 0.004711527735692601\n",
      "72 Train Loss 0.006362304 Test MSE 4.1348663725877764e-05 Test RE 0.004659061112728943\n",
      "73 Train Loss 0.006194718 Test MSE 4.149774269358187e-05 Test RE 0.004667452473340243\n",
      "74 Train Loss 0.006001432 Test MSE 4.318082485612759e-05 Test RE 0.004761163929326126\n",
      "75 Train Loss 0.0059141144 Test MSE 4.489816458030816e-05 Test RE 0.004854918697594106\n",
      "76 Train Loss 0.0057724365 Test MSE 4.260904115006479e-05 Test RE 0.004729536138211495\n",
      "77 Train Loss 0.005488762 Test MSE 4.308212104817008e-05 Test RE 0.004755719222421112\n",
      "78 Train Loss 0.0053626797 Test MSE 3.719840908352383e-05 Test RE 0.004419059516588259\n",
      "79 Train Loss 0.005094165 Test MSE 3.529919387258876e-05 Test RE 0.004304771080067909\n",
      "80 Train Loss 0.0048515443 Test MSE 3.1215237235275436e-05 Test RE 0.004048097719000226\n",
      "81 Train Loss 0.0046806945 Test MSE 3.0090083635140193e-05 Test RE 0.003974471298402713\n",
      "82 Train Loss 0.0045906445 Test MSE 3.067264342682219e-05 Test RE 0.0040127607845256395\n",
      "83 Train Loss 0.0045488365 Test MSE 3.09299150338261e-05 Test RE 0.004029554473327905\n",
      "84 Train Loss 0.004436764 Test MSE 3.041279412957665e-05 Test RE 0.003995727188065252\n",
      "85 Train Loss 0.0042610522 Test MSE 3.0784591255995676e-05 Test RE 0.004020076924718453\n",
      "86 Train Loss 0.0041891523 Test MSE 3.058472059007052e-05 Test RE 0.004007005387061503\n",
      "87 Train Loss 0.004171107 Test MSE 3.174718829630287e-05 Test RE 0.004082444615335151\n",
      "88 Train Loss 0.0040862607 Test MSE 3.07789723584643e-05 Test RE 0.004019710029622455\n",
      "89 Train Loss 0.003945442 Test MSE 3.295901514198012e-05 Test RE 0.004159630755335546\n",
      "90 Train Loss 0.0038058625 Test MSE 3.283863140440545e-05 Test RE 0.0041520272212994\n",
      "91 Train Loss 0.0036738338 Test MSE 3.329010897550752e-05 Test RE 0.004180471587091662\n",
      "92 Train Loss 0.003507072 Test MSE 3.515466427598897e-05 Test RE 0.004295949278222681\n",
      "93 Train Loss 0.003504854 Test MSE 3.631637390917309e-05 Test RE 0.004366353638909076\n",
      "94 Train Loss 0.003409435 Test MSE 3.786870514072262e-05 Test RE 0.004458696336435495\n",
      "95 Train Loss 0.0032868134 Test MSE 3.905894316123787e-05 Test RE 0.00452822409960963\n",
      "96 Train Loss 0.003185311 Test MSE 4.0007453377840816e-05 Test RE 0.004582876157895448\n",
      "97 Train Loss 0.003113543 Test MSE 4.076831654953773e-05 Test RE 0.0046262495608312285\n",
      "98 Train Loss 0.0030095936 Test MSE 4.3196352266044044e-05 Test RE 0.004762019886796281\n",
      "99 Train Loss 0.0028889042 Test MSE 4.36532067766163e-05 Test RE 0.0047871357599035495\n",
      "100 Train Loss 0.0028390626 Test MSE 4.581445916258822e-05 Test RE 0.00490420877083563\n",
      "101 Train Loss 0.0027233216 Test MSE 4.3690768045878683e-05 Test RE 0.004789194855279866\n",
      "102 Train Loss 0.0026484122 Test MSE 4.4231718829092255e-05 Test RE 0.004818752001290383\n",
      "103 Train Loss 0.0025729109 Test MSE 4.6098655472295675e-05 Test RE 0.004919396151607963\n",
      "104 Train Loss 0.0025290193 Test MSE 4.6065172452197515e-05 Test RE 0.004917609264776392\n",
      "105 Train Loss 0.0024766007 Test MSE 4.5579390875023306e-05 Test RE 0.004891611148451481\n",
      "106 Train Loss 0.0024183302 Test MSE 4.4286704954787676e-05 Test RE 0.0048217462576130065\n",
      "107 Train Loss 0.002368735 Test MSE 4.453008947162969e-05 Test RE 0.004834977434540298\n",
      "108 Train Loss 0.0023215814 Test MSE 4.3012460665914405e-05 Test RE 0.004751872856054446\n",
      "109 Train Loss 0.0022967733 Test MSE 4.314930362475117e-05 Test RE 0.004759425829731477\n",
      "110 Train Loss 0.002291354 Test MSE 4.37184497318123e-05 Test RE 0.004790711788964842\n",
      "111 Train Loss 0.0022934384 Test MSE 4.3805947241665305e-05 Test RE 0.0047955034253470115\n",
      "112 Train Loss 0.0022993593 Test MSE 4.229231239559051e-05 Test RE 0.004711925154668893\n",
      "113 Train Loss 0.0022501512 Test MSE 4.258140082907347e-05 Test RE 0.004728001873408804\n",
      "114 Train Loss 0.0022089395 Test MSE 4.09917772579216e-05 Test RE 0.004638911014086855\n",
      "115 Train Loss 0.0021667161 Test MSE 3.849371532490021e-05 Test RE 0.004495340394083498\n",
      "116 Train Loss 0.002091195 Test MSE 3.487358387525898e-05 Test RE 0.00427874060144841\n",
      "117 Train Loss 0.0020208075 Test MSE 3.530838842663988e-05 Test RE 0.004305331685976124\n",
      "118 Train Loss 0.0019449128 Test MSE 3.6138438014397687e-05 Test RE 0.004355643799788192\n",
      "119 Train Loss 0.001914178 Test MSE 3.450064680752003e-05 Test RE 0.004255800744760963\n",
      "120 Train Loss 0.0018644613 Test MSE 3.41441527961432e-05 Test RE 0.004233756128063432\n",
      "121 Train Loss 0.0018354465 Test MSE 3.15854364636521e-05 Test RE 0.004072031312699938\n",
      "122 Train Loss 0.0018170722 Test MSE 3.114642576729783e-05 Test RE 0.00404363340519098\n",
      "123 Train Loss 0.0018247382 Test MSE 2.8578593933067824e-05 Test RE 0.0038733620797652066\n",
      "124 Train Loss 0.0017937031 Test MSE 2.7185531831339338e-05 Test RE 0.003777779315821763\n",
      "125 Train Loss 0.0017639453 Test MSE 2.5415813501086803e-05 Test RE 0.0036527476931903194\n",
      "126 Train Loss 0.0017582928 Test MSE 2.4658886517302937e-05 Test RE 0.0035979439926481496\n",
      "127 Train Loss 0.0017024064 Test MSE 2.3397979040290313e-05 Test RE 0.0035047483620584486\n",
      "128 Train Loss 0.0016580153 Test MSE 2.1981592653675418e-05 Test RE 0.0033970132860578197\n",
      "129 Train Loss 0.001628806 Test MSE 2.101975878453752e-05 Test RE 0.003321861579262527\n",
      "130 Train Loss 0.0016019667 Test MSE 2.0060805478356155e-05 Test RE 0.0032452028673105615\n",
      "131 Train Loss 0.0015778857 Test MSE 2.0430373200697714e-05 Test RE 0.003274958625183375\n",
      "132 Train Loss 0.0015750665 Test MSE 1.9789638224393856e-05 Test RE 0.00322319510707296\n",
      "133 Train Loss 0.0015490368 Test MSE 1.9701284225814156e-05 Test RE 0.00321599182351333\n",
      "134 Train Loss 0.0015276432 Test MSE 1.9854494051566307e-05 Test RE 0.0032284724140748734\n",
      "135 Train Loss 0.0015169132 Test MSE 1.9318737982393467e-05 Test RE 0.0031846157876116413\n",
      "136 Train Loss 0.0015009707 Test MSE 1.772244805394064e-05 Test RE 0.0030502084767974986\n",
      "137 Train Loss 0.001465212 Test MSE 1.7683835904671673e-05 Test RE 0.0030468838987200387\n",
      "138 Train Loss 0.0014332155 Test MSE 1.790268570945302e-05 Test RE 0.003065679581920789\n",
      "139 Train Loss 0.0014142257 Test MSE 1.752182765340876e-05 Test RE 0.0030328949626169284\n",
      "140 Train Loss 0.0013938311 Test MSE 1.7469684203056203e-05 Test RE 0.00302837878304477\n",
      "141 Train Loss 0.0013747258 Test MSE 1.6056045051078235e-05 Test RE 0.0029032668593303385\n",
      "142 Train Loss 0.0013625971 Test MSE 1.5552416837246794e-05 Test RE 0.002857370860766156\n",
      "143 Train Loss 0.0013389734 Test MSE 1.4429283935704435e-05 Test RE 0.002752263796118162\n",
      "144 Train Loss 0.0013261489 Test MSE 1.4747174061451948e-05 Test RE 0.0027824160560813976\n",
      "145 Train Loss 0.0013031471 Test MSE 1.4811634885401202e-05 Test RE 0.002788490483052662\n",
      "146 Train Loss 0.0012754538 Test MSE 1.4559566523266276e-05 Test RE 0.0027646610257293053\n",
      "147 Train Loss 0.0012598368 Test MSE 1.4120445037249095e-05 Test RE 0.002722650276805881\n",
      "148 Train Loss 0.0012447772 Test MSE 1.3497551212124264e-05 Test RE 0.0026619209828318753\n",
      "149 Train Loss 0.0012460939 Test MSE 1.2579895734663257e-05 Test RE 0.002569840613852907\n",
      "150 Train Loss 0.0012293502 Test MSE 1.2242858903805855e-05 Test RE 0.0025351816916051786\n",
      "151 Train Loss 0.001217894 Test MSE 1.1945836766016438e-05 Test RE 0.002504240042966824\n",
      "152 Train Loss 0.0011904242 Test MSE 1.136154669705538e-05 Test RE 0.00244222907102483\n",
      "153 Train Loss 0.0011626618 Test MSE 1.1392206136099972e-05 Test RE 0.002445522061351018\n",
      "154 Train Loss 0.0011473597 Test MSE 1.1524052974227205e-05 Test RE 0.0024596328836929806\n",
      "155 Train Loss 0.0011400674 Test MSE 1.0913788982066712e-05 Test RE 0.002393621316744289\n",
      "156 Train Loss 0.0011218366 Test MSE 1.0683800419743783e-05 Test RE 0.0023682663862543856\n",
      "157 Train Loss 0.0011007605 Test MSE 1.0351966330014106e-05 Test RE 0.0023311976307161322\n",
      "158 Train Loss 0.0010860616 Test MSE 1.0009451648687571e-05 Test RE 0.002292307158631537\n",
      "159 Train Loss 0.0010762626 Test MSE 9.231032920423933e-06 Test RE 0.0022013688537980804\n",
      "160 Train Loss 0.0010726269 Test MSE 8.672424729991123e-06 Test RE 0.0021337225019137803\n",
      "161 Train Loss 0.0010584403 Test MSE 8.412417378677805e-06 Test RE 0.0021014936090752163\n",
      "162 Train Loss 0.0010432268 Test MSE 8.568375028742436e-06 Test RE 0.0021208839281470727\n",
      "163 Train Loss 0.0010257635 Test MSE 8.473649875664421e-06 Test RE 0.0021091279420175834\n",
      "164 Train Loss 0.0010225824 Test MSE 7.703367241010728e-06 Test RE 0.00201098100691543\n",
      "165 Train Loss 0.0010183204 Test MSE 6.760771835768523e-06 Test RE 0.0018839345350746021\n",
      "166 Train Loss 0.0010025707 Test MSE 6.386214750935988e-06 Test RE 0.001831004564449419\n",
      "167 Train Loss 0.0009879515 Test MSE 6.27545970860398e-06 Test RE 0.001815057719947369\n",
      "168 Train Loss 0.000975354 Test MSE 6.0923607120255585e-06 Test RE 0.001788382749442756\n",
      "169 Train Loss 0.0009576861 Test MSE 5.998181428368023e-06 Test RE 0.001774505977240245\n",
      "170 Train Loss 0.000939162 Test MSE 5.230478485567008e-06 Test RE 0.0016570605484161715\n",
      "171 Train Loss 0.0009220403 Test MSE 4.855509002801827e-06 Test RE 0.0015965592838159846\n",
      "172 Train Loss 0.0009017899 Test MSE 4.5759117971847235e-06 Test RE 0.001549910034363756\n",
      "173 Train Loss 0.0008812678 Test MSE 4.294913245623922e-06 Test RE 0.0015015675197888954\n",
      "174 Train Loss 0.0008692476 Test MSE 3.8413358058730785e-06 Test RE 0.0014200669006123835\n",
      "175 Train Loss 0.0008653811 Test MSE 3.435385040391537e-06 Test RE 0.001342936190605498\n",
      "176 Train Loss 0.00085731194 Test MSE 3.4524028023495696e-06 Test RE 0.0013462583125116103\n",
      "177 Train Loss 0.00084541715 Test MSE 3.2942993664546445e-06 Test RE 0.0013150709946339204\n",
      "178 Train Loss 0.0008278884 Test MSE 3.359136131632436e-06 Test RE 0.0013279492249765833\n",
      "179 Train Loss 0.00081601815 Test MSE 3.4194011290437425e-06 Test RE 0.0013398083899146922\n",
      "180 Train Loss 0.0008052684 Test MSE 2.97900172171732e-06 Test RE 0.0012505557135243795\n",
      "181 Train Loss 0.0007906535 Test MSE 2.652833109896861e-06 Test RE 0.0011801103853359529\n",
      "182 Train Loss 0.00077684515 Test MSE 2.457332309936434e-06 Test RE 0.0011357941124544935\n",
      "183 Train Loss 0.00076871255 Test MSE 2.1201053458690237e-06 Test RE 0.0010549852512248773\n",
      "184 Train Loss 0.0007610705 Test MSE 1.8568904621065691e-06 Test RE 0.000987326537934405\n",
      "185 Train Loss 0.0007551724 Test MSE 1.8784319468300118e-06 Test RE 0.0009930369317720082\n",
      "186 Train Loss 0.0007513363 Test MSE 1.5212785183874512e-06 Test RE 0.0008936594126487893\n",
      "187 Train Loss 0.00074177614 Test MSE 1.5068543318055092e-06 Test RE 0.0008894126521336394\n",
      "188 Train Loss 0.0007345999 Test MSE 1.5471665963682348e-06 Test RE 0.0009012311782748663\n",
      "189 Train Loss 0.0007188664 Test MSE 1.4096473845244938e-06 Test RE 0.0008602464965643036\n",
      "190 Train Loss 0.0007043931 Test MSE 1.4993499481193358e-06 Test RE 0.0008871951768164182\n",
      "191 Train Loss 0.0006901161 Test MSE 1.3281694987790185e-06 Test RE 0.0008350152726217144\n",
      "192 Train Loss 0.0006768618 Test MSE 1.222947599073591e-06 Test RE 0.0008012565486680568\n",
      "193 Train Loss 0.00066464365 Test MSE 1.0333254995130531e-06 Test RE 0.0007365228770900643\n",
      "194 Train Loss 0.00065141695 Test MSE 9.936120543675378e-07 Test RE 0.0007222309467213552\n",
      "195 Train Loss 0.00064113416 Test MSE 9.461621630203314e-07 Test RE 0.0007047749443764984\n",
      "196 Train Loss 0.0006310474 Test MSE 9.513344950087466e-07 Test RE 0.0007066986958072727\n",
      "197 Train Loss 0.0006237576 Test MSE 8.375577220383921e-07 Test RE 0.0006630939129005567\n",
      "198 Train Loss 0.00061636226 Test MSE 8.733124864705056e-07 Test RE 0.000677099514637224\n",
      "199 Train Loss 0.00061014714 Test MSE 9.512497728157499e-07 Test RE 0.0007066672271720625\n",
      "200 Train Loss 0.0006030139 Test MSE 1.0638101750158277e-06 Test RE 0.0007473081826641296\n",
      "201 Train Loss 0.00059450534 Test MSE 8.164735877235321e-07 Test RE 0.0006546945682421213\n",
      "202 Train Loss 0.00058541534 Test MSE 6.341520781183322e-07 Test RE 0.0005769848070653758\n",
      "203 Train Loss 0.0005807522 Test MSE 6.060737094975239e-07 Test RE 0.0005640666073958852\n",
      "204 Train Loss 0.0005738154 Test MSE 5.542160329831939e-07 Test RE 0.0005393953651014865\n",
      "205 Train Loss 0.00057009194 Test MSE 5.510969517249073e-07 Test RE 0.0005378753876151926\n",
      "206 Train Loss 0.00056612346 Test MSE 5.302182717950724e-07 Test RE 0.0005275881258724682\n",
      "207 Train Loss 0.00056022825 Test MSE 5.64418406353182e-07 Test RE 0.0005443374967027336\n",
      "208 Train Loss 0.0005586245 Test MSE 5.685162738879485e-07 Test RE 0.0005463099596785072\n",
      "209 Train Loss 0.00055362406 Test MSE 6.026702334420225e-07 Test RE 0.0005624805874513599\n",
      "210 Train Loss 0.00054766017 Test MSE 7.035926713210816e-07 Test RE 0.0006077546931929923\n",
      "211 Train Loss 0.0005398243 Test MSE 8.299455759907359e-07 Test RE 0.0006600737695130264\n",
      "212 Train Loss 0.00052880094 Test MSE 7.349325861461948e-07 Test RE 0.0006211427487808552\n",
      "213 Train Loss 0.0005172138 Test MSE 4.5574161778513487e-07 Test RE 0.0004891330545310847\n",
      "214 Train Loss 0.0005045495 Test MSE 4.3145869818716465e-07 Test RE 0.00047592364492673984\n",
      "215 Train Loss 0.00049808144 Test MSE 4.4295500587414317e-07 Test RE 0.0004822225049196295\n",
      "216 Train Loss 0.0004926589 Test MSE 4.943413046975781e-07 Test RE 0.0005094260125933009\n",
      "217 Train Loss 0.0004870668 Test MSE 6.172019334017683e-07 Test RE 0.0005692215146218118\n",
      "218 Train Loss 0.0004838709 Test MSE 5.947245179859242e-07 Test RE 0.000558760360850821\n",
      "219 Train Loss 0.00048006466 Test MSE 5.373712810896234e-07 Test RE 0.0005311349670239652\n",
      "220 Train Loss 0.00047693256 Test MSE 4.973073527701992e-07 Test RE 0.0005109520051911644\n",
      "221 Train Loss 0.0004763087 Test MSE 4.981267634018627e-07 Test RE 0.0005113727783618623\n",
      "222 Train Loss 0.00047315675 Test MSE 4.178509703522912e-07 Test RE 0.00046835846629130254\n",
      "223 Train Loss 0.00047097524 Test MSE 3.789524114673353e-07 Test RE 0.00044602582497951256\n",
      "224 Train Loss 0.00046760507 Test MSE 3.2815164531905833e-07 Test RE 0.0004150543412405148\n",
      "225 Train Loss 0.0004667838 Test MSE 3.04855794060568e-07 Test RE 0.0004000505708378889\n",
      "226 Train Loss 0.00046290373 Test MSE 3.0918476618473587e-07 Test RE 0.00040288093051005263\n",
      "227 Train Loss 0.0004624598 Test MSE 3.1312663791074134e-07 Test RE 0.0004054410100323856\n",
      "228 Train Loss 0.00045989576 Test MSE 2.9095146389067416e-07 Test RE 0.0003908210443946787\n",
      "229 Train Loss 0.00046163384 Test MSE 3.16971543771692e-07 Test RE 0.000407922635794798\n",
      "230 Train Loss 0.00045780322 Test MSE 3.231572985340934e-07 Test RE 0.0004118837443051143\n",
      "231 Train Loss 0.00045489005 Test MSE 3.2151257980148725e-07 Test RE 0.0004108342599406489\n",
      "232 Train Loss 0.00044881023 Test MSE 3.4602203920750455e-07 Test RE 0.0004262059891779717\n",
      "233 Train Loss 0.00044332686 Test MSE 4.242845822845683e-07 Test RE 0.0004719503287515868\n",
      "234 Train Loss 0.00043840302 Test MSE 4.3060840610353994e-07 Test RE 0.0004754544532257011\n",
      "235 Train Loss 0.00043235125 Test MSE 4.0308614144520266e-07 Test RE 0.0004600092885531335\n",
      "236 Train Loss 0.00042811845 Test MSE 3.9158547367452274e-07 Test RE 0.00045339941352733797\n",
      "237 Train Loss 0.00042432587 Test MSE 4.0727565378031395e-07 Test RE 0.0004623936830747472\n",
      "238 Train Loss 0.000421213 Test MSE 4.8467617040311e-07 Test RE 0.0005044213980712744\n",
      "239 Train Loss 0.00042015058 Test MSE 4.958329621291598e-07 Test RE 0.0005101940211725053\n",
      "240 Train Loss 0.0004183927 Test MSE 4.5911587147783924e-07 Test RE 0.0004909404551069136\n",
      "241 Train Loss 0.00041298784 Test MSE 4.7119253073332205e-07 Test RE 0.000497355432935042\n",
      "242 Train Loss 0.00041141672 Test MSE 4.549557451480495e-07 Test RE 0.0004887111464553478\n",
      "243 Train Loss 0.00041057586 Test MSE 4.4765496046617004e-07 Test RE 0.0004847740548327194\n",
      "244 Train Loss 0.0004081011 Test MSE 4.96209084771073e-07 Test RE 0.0005103874927245878\n",
      "245 Train Loss 0.00040700336 Test MSE 4.930692865189025e-07 Test RE 0.0005087701736711461\n",
      "246 Train Loss 0.00040359987 Test MSE 4.698029006032347e-07 Test RE 0.0004966214968300978\n",
      "247 Train Loss 0.0003989167 Test MSE 5.109025280748589e-07 Test RE 0.0005178890081357289\n",
      "248 Train Loss 0.0003951944 Test MSE 4.5644083136597935e-07 Test RE 0.0004895081326253767\n",
      "249 Train Loss 0.00039197618 Test MSE 4.2003141376731203e-07 Test RE 0.0004695788778950344\n",
      "250 Train Loss 0.00039107926 Test MSE 4.162410301805019e-07 Test RE 0.0004674553251399571\n",
      "251 Train Loss 0.00038860244 Test MSE 4.501605511964129e-07 Test RE 0.0004861288376318584\n",
      "252 Train Loss 0.0003880853 Test MSE 4.483748451146156e-07 Test RE 0.0004851636866275278\n",
      "253 Train Loss 0.00038708976 Test MSE 4.5327045017334595e-07 Test RE 0.00048780513900163405\n",
      "254 Train Loss 0.0003847997 Test MSE 4.7122602182551925e-07 Test RE 0.0004973731079612787\n",
      "255 Train Loss 0.0003843518 Test MSE 4.7122602182551925e-07 Test RE 0.0004973731079612787\n",
      "256 Train Loss 0.00038405284 Test MSE 4.7122602182551925e-07 Test RE 0.0004973731079612787\n",
      "257 Train Loss 0.00038227328 Test MSE 4.315480233249277e-07 Test RE 0.0004759729077475336\n",
      "258 Train Loss 0.00038225038 Test MSE 4.3118083690228876e-07 Test RE 0.00047577037179329475\n",
      "259 Train Loss 0.0003816969 Test MSE 4.2903845138272647e-07 Test RE 0.00047458693234260816\n",
      "260 Train Loss 0.00038134595 Test MSE 4.171671027926174e-07 Test RE 0.00046797504451814295\n",
      "261 Train Loss 0.0003807006 Test MSE 4.132504062353064e-07 Test RE 0.0004657730027368286\n",
      "262 Train Loss 0.00037991072 Test MSE 3.8945787688460274e-07 Test RE 0.00045216601101316363\n",
      "263 Train Loss 0.00037792075 Test MSE 3.865925931709675e-07 Test RE 0.00045049962328773835\n",
      "264 Train Loss 0.00037825818 Test MSE 3.8886545719930897e-07 Test RE 0.0004518219763857035\n",
      "265 Train Loss 0.00037676457 Test MSE 4.077026298815766e-07 Test RE 0.0004626359997122144\n",
      "266 Train Loss 0.0003754838 Test MSE 4.2312800188893816e-07 Test RE 0.0004713066322585368\n",
      "267 Train Loss 0.00037164066 Test MSE 4.3313973028632874e-07 Test RE 0.00047684988093476687\n",
      "268 Train Loss 0.00036904772 Test MSE 4.2907390277883873e-07 Test RE 0.00047460653946841604\n",
      "269 Train Loss 0.0003683297 Test MSE 4.203595429438967e-07 Test RE 0.0004697622599527423\n",
      "270 Train Loss 0.00036575773 Test MSE 4.1510778922306215e-07 Test RE 0.0004668185539721907\n",
      "271 Train Loss 0.00036340012 Test MSE 4.1156939353958073e-07 Test RE 0.0004648247057951813\n",
      "272 Train Loss 0.00036237104 Test MSE 4.210984807927997e-07 Test RE 0.0004701749693860496\n",
      "273 Train Loss 0.0003613342 Test MSE 4.3234565335429925e-07 Test RE 0.00047641257494439814\n",
      "274 Train Loss 0.0003602292 Test MSE 4.397448523540622e-07 Test RE 0.00048047196240925933\n",
      "275 Train Loss 0.00035984244 Test MSE 4.418010219560091e-07 Test RE 0.0004815939535839003\n",
      "276 Train Loss 0.00035981904 Test MSE 4.374170198285923e-07 Test RE 0.0004791985622164757\n",
      "277 Train Loss 0.00036007486 Test MSE 4.4051683993736594e-07 Test RE 0.00048089352020553667\n",
      "278 Train Loss 0.00035935114 Test MSE 4.4167591492562333e-07 Test RE 0.0004815257610578826\n",
      "279 Train Loss 0.00035888664 Test MSE 4.439104460068621e-07 Test RE 0.00048274229423001907\n",
      "280 Train Loss 0.00035798608 Test MSE 4.5898993229921934e-07 Test RE 0.0004908731160296635\n",
      "281 Train Loss 0.0003581394 Test MSE 4.7519628305637696e-07 Test RE 0.0004994639933348635\n",
      "282 Train Loss 0.00035854313 Test MSE 4.7447421719813465e-07 Test RE 0.000499084378620494\n",
      "283 Train Loss 0.00035861955 Test MSE 4.7338792677781715e-07 Test RE 0.000498512734025591\n",
      "284 Train Loss 0.0003588585 Test MSE 4.7338792677781715e-07 Test RE 0.000498512734025591\n",
      "285 Train Loss 0.00035903958 Test MSE 4.7338792677781715e-07 Test RE 0.000498512734025591\n",
      "286 Train Loss 0.00035917258 Test MSE 4.73387968275467e-07 Test RE 0.0004985127558756481\n",
      "287 Train Loss 0.00035927247 Test MSE 4.73387968275467e-07 Test RE 0.0004985127558756481\n",
      "288 Train Loss 0.0003593466 Test MSE 4.73387968275467e-07 Test RE 0.0004985127558756481\n",
      "289 Train Loss 0.00035946118 Test MSE 4.7072130957153723e-07 Test RE 0.0004971066779000865\n",
      "290 Train Loss 0.0003591995 Test MSE 4.69711239130771e-07 Test RE 0.000496573047492966\n",
      "291 Train Loss 0.0003590114 Test MSE 4.7074510387053046e-07 Test RE 0.000497119241762411\n",
      "292 Train Loss 0.00035808072 Test MSE 4.7443256661605213e-07 Test RE 0.0004990624726766809\n",
      "293 Train Loss 0.00035718063 Test MSE 4.857847810194968e-07 Test RE 0.0005049979557243402\n",
      "294 Train Loss 0.0003548805 Test MSE 4.99140235446538e-07 Test RE 0.0005118927250014753\n",
      "295 Train Loss 0.0003527874 Test MSE 4.841826912280525e-07 Test RE 0.0005041645411598823\n",
      "296 Train Loss 0.0003525614 Test MSE 4.7598540889949556e-07 Test RE 0.0004998785340881613\n",
      "297 Train Loss 0.00035129033 Test MSE 4.5649521407348603e-07 Test RE 0.0004895372930147225\n",
      "298 Train Loss 0.0003481011 Test MSE 4.626736348715715e-07 Test RE 0.0004928389728526247\n",
      "299 Train Loss 0.00034553732 Test MSE 4.243050708660457e-07 Test RE 0.000471961723787413\n",
      "Training time: 157.19\n",
      "KG_stanALR_medium\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 23134.871 Test MSE 8.482474984442662 Test RE 2.110225959990086\n",
      "1 Train Loss 1948.5948 Test MSE 7.335018888625311 Test RE 1.9623130222801375\n",
      "2 Train Loss 358.84702 Test MSE 1.3960121382484014 Test RE 0.8560758877653335\n",
      "3 Train Loss 82.06149 Test MSE 0.15088315532151647 Test RE 0.28144144146322736\n",
      "4 Train Loss 25.297846 Test MSE 0.11690552285314204 Test RE 0.24773375298580744\n",
      "5 Train Loss 7.8999434 Test MSE 0.02595976901389073 Test RE 0.11673956738906634\n",
      "6 Train Loss 3.352831 Test MSE 0.014557693620361334 Test RE 0.08742063467754939\n",
      "7 Train Loss 2.1820602 Test MSE 0.006807811391337277 Test RE 0.05978213559444784\n",
      "8 Train Loss 1.5296482 Test MSE 0.0016947734138657675 Test RE 0.02982795566638903\n",
      "9 Train Loss 1.1307083 Test MSE 0.001938958990368556 Test RE 0.03190450269252812\n",
      "10 Train Loss 0.7860554 Test MSE 0.0015536886130061323 Test RE 0.02855943813287956\n",
      "11 Train Loss 0.6245641 Test MSE 0.0011972914494207713 Test RE 0.0250707662738296\n",
      "12 Train Loss 0.49551144 Test MSE 0.0014507828491512281 Test RE 0.02759744484464668\n",
      "13 Train Loss 0.39747947 Test MSE 0.002235100049880334 Test RE 0.03425438319603878\n",
      "14 Train Loss 0.3313103 Test MSE 0.0015941338273179283 Test RE 0.028928775849512967\n",
      "15 Train Loss 0.27660853 Test MSE 0.0009774808566797742 Test RE 0.02265279516944196\n",
      "16 Train Loss 0.22297229 Test MSE 0.0006003110925832388 Test RE 0.01775235000389169\n",
      "17 Train Loss 0.19253719 Test MSE 0.0006452470939858358 Test RE 0.018404782787535674\n",
      "18 Train Loss 0.17641744 Test MSE 0.0006911744293238023 Test RE 0.019048531435415114\n",
      "19 Train Loss 0.1556342 Test MSE 0.0007647681930364543 Test RE 0.020036994374077466\n",
      "20 Train Loss 0.14058731 Test MSE 0.0007035468900927742 Test RE 0.019218265615806137\n",
      "21 Train Loss 0.12446715 Test MSE 0.0006285159831049561 Test RE 0.018164599665229857\n",
      "22 Train Loss 0.11263996 Test MSE 0.0005305392561312086 Test RE 0.016688850710523628\n",
      "23 Train Loss 0.10162522 Test MSE 0.0005289335351173918 Test RE 0.016663576477719298\n",
      "24 Train Loss 0.08986869 Test MSE 0.00045897710622428003 Test RE 0.015522554001289256\n",
      "25 Train Loss 0.08218295 Test MSE 0.00040188868509094294 Test RE 0.014525147698503464\n",
      "26 Train Loss 0.0764889 Test MSE 0.0004041357260606745 Test RE 0.014565697616950467\n",
      "27 Train Loss 0.06720689 Test MSE 0.00035116267092341803 Test RE 0.013577563401486026\n",
      "28 Train Loss 0.061702747 Test MSE 0.0003753564584795894 Test RE 0.014037494983665223\n",
      "29 Train Loss 0.05913005 Test MSE 0.0003280180117086078 Test RE 0.013122497948519834\n",
      "30 Train Loss 0.05535052 Test MSE 0.00033595682395260476 Test RE 0.013280346336750773\n",
      "31 Train Loss 0.04922804 Test MSE 0.0002758090123395222 Test RE 0.012032943962429857\n",
      "32 Train Loss 0.047300998 Test MSE 0.0002551413653490894 Test RE 0.011573323832905092\n",
      "33 Train Loss 0.042560812 Test MSE 0.00022365735388812143 Test RE 0.010835757044040824\n",
      "34 Train Loss 0.04110175 Test MSE 0.0002016808441419738 Test RE 0.010289635553847909\n",
      "35 Train Loss 0.037690863 Test MSE 0.00018183362669050998 Test RE 0.00977022956264569\n",
      "36 Train Loss 0.035961982 Test MSE 0.00016264429764241222 Test RE 0.00924032163580912\n",
      "37 Train Loss 0.033517223 Test MSE 0.00012513972935267428 Test RE 0.008105228695675938\n",
      "38 Train Loss 0.032722317 Test MSE 0.00010820991933751003 Test RE 0.007537046667121175\n",
      "39 Train Loss 0.031042425 Test MSE 0.00012474293443061183 Test RE 0.008092368403103787\n",
      "40 Train Loss 0.029194321 Test MSE 0.00010305352648372358 Test RE 0.007355278078457032\n",
      "41 Train Loss 0.028668711 Test MSE 9.038431640834665e-05 Test RE 0.006888334152004539\n",
      "42 Train Loss 0.02671397 Test MSE 9.317710686070394e-05 Test RE 0.0069939460579151345\n",
      "43 Train Loss 0.026146874 Test MSE 9.415215904702359e-05 Test RE 0.0070304449082858695\n",
      "44 Train Loss 0.02478974 Test MSE 8.880627714463061e-05 Test RE 0.0068279369136731455\n",
      "45 Train Loss 0.02346651 Test MSE 6.99783461668813e-05 Test RE 0.006061072862090817\n",
      "46 Train Loss 0.02270013 Test MSE 6.687735589064282e-05 Test RE 0.005925257310043418\n",
      "47 Train Loss 0.022050718 Test MSE 5.770887315414359e-05 Test RE 0.005504133573418337\n",
      "48 Train Loss 0.02104343 Test MSE 5.1276192329417835e-05 Test RE 0.005188305632528646\n",
      "49 Train Loss 0.019247267 Test MSE 5.8846525775925997e-05 Test RE 0.005558122080253963\n",
      "50 Train Loss 0.01867511 Test MSE 5.567658847066804e-05 Test RE 0.005406347733640341\n",
      "51 Train Loss 0.018329237 Test MSE 5.204382667196713e-05 Test RE 0.005226997333606354\n",
      "52 Train Loss 0.018001102 Test MSE 4.645408246143605e-05 Test RE 0.004938324348186284\n",
      "53 Train Loss 0.016943026 Test MSE 3.159157008822937e-05 Test RE 0.0040724266705247135\n",
      "54 Train Loss 0.016413122 Test MSE 3.0435493963119017e-05 Test RE 0.00399721809717287\n",
      "55 Train Loss 0.01577283 Test MSE 2.9857557512757435e-05 Test RE 0.00395908482159786\n",
      "56 Train Loss 0.014966371 Test MSE 3.102651750328365e-05 Test RE 0.0040358422604330705\n",
      "57 Train Loss 0.0146448035 Test MSE 2.810163676904226e-05 Test RE 0.0038409042045896716\n",
      "58 Train Loss 0.014161981 Test MSE 2.407336473007126e-05 Test RE 0.003554971026659431\n",
      "59 Train Loss 0.013701935 Test MSE 2.085916469331611e-05 Test RE 0.003309147489432477\n",
      "60 Train Loss 0.013196135 Test MSE 2.0064774758532404e-05 Test RE 0.0032455239033306158\n",
      "61 Train Loss 0.0122826155 Test MSE 2.9073491342657185e-05 Test RE 0.003906755764342813\n",
      "62 Train Loss 0.0114329485 Test MSE 3.360711387688252e-05 Test RE 0.004200328687025541\n",
      "63 Train Loss 0.010909557 Test MSE 2.7518369264461236e-05 Test RE 0.0038008349830093214\n",
      "64 Train Loss 0.010345208 Test MSE 2.9763776695162005e-05 Test RE 0.0039528623062916384\n",
      "65 Train Loss 0.009850769 Test MSE 2.420286545722468e-05 Test RE 0.003564520042037982\n",
      "66 Train Loss 0.009342993 Test MSE 1.7165738380271648e-05 Test RE 0.0030019186036471927\n",
      "67 Train Loss 0.009007855 Test MSE 1.7377495113007924e-05 Test RE 0.0030203777002777636\n",
      "68 Train Loss 0.008562148 Test MSE 1.518074697361681e-05 Test RE 0.0028230218429942436\n",
      "69 Train Loss 0.008367497 Test MSE 1.5146944578033885e-05 Test RE 0.0028198771334414265\n",
      "70 Train Loss 0.008012506 Test MSE 8.904029976555234e-06 Test RE 0.0021620263086441697\n",
      "71 Train Loss 0.007615561 Test MSE 7.0697504033355185e-06 Test RE 0.001926503082872002\n",
      "72 Train Loss 0.0072841602 Test MSE 9.102546274453944e-06 Test RE 0.0021859947538843565\n",
      "73 Train Loss 0.007038823 Test MSE 7.965272023467388e-06 Test RE 0.002044880689120856\n",
      "74 Train Loss 0.006959838 Test MSE 7.368535559643232e-06 Test RE 0.0019667912137816576\n",
      "75 Train Loss 0.006820597 Test MSE 5.805367027466417e-06 Test RE 0.0017457518406812946\n",
      "76 Train Loss 0.0066514947 Test MSE 6.1281758892107885e-06 Test RE 0.001793631731667808\n",
      "77 Train Loss 0.0064399675 Test MSE 5.411863648768285e-06 Test RE 0.001685547868345982\n",
      "78 Train Loss 0.006285964 Test MSE 5.58725070081583e-06 Test RE 0.0017126426180855568\n",
      "79 Train Loss 0.0061885067 Test MSE 5.211421242134023e-06 Test RE 0.0016540390444196586\n",
      "80 Train Loss 0.0061258525 Test MSE 4.871322435275789e-06 Test RE 0.0015991570093714302\n",
      "81 Train Loss 0.006060965 Test MSE 4.994842395093795e-06 Test RE 0.0016193046472962466\n",
      "82 Train Loss 0.0058709597 Test MSE 4.7543932798361965e-06 Test RE 0.0015798476894403992\n",
      "83 Train Loss 0.00565305 Test MSE 4.942311947422412e-06 Test RE 0.0016107670774211833\n",
      "84 Train Loss 0.0054182713 Test MSE 4.4427236699909845e-06 Test RE 0.0015271873515498014\n",
      "85 Train Loss 0.0052929274 Test MSE 4.71637999082217e-06 Test RE 0.0015735192551936577\n",
      "86 Train Loss 0.0051884945 Test MSE 5.353527701522393e-06 Test RE 0.0016764387654673945\n",
      "87 Train Loss 0.0051295925 Test MSE 5.096802709617434e-06 Test RE 0.0016357486823352426\n",
      "88 Train Loss 0.005023303 Test MSE 5.246100299101371e-06 Test RE 0.0016595332658939379\n",
      "89 Train Loss 0.0049548424 Test MSE 5.8220635961769064e-06 Test RE 0.0017482604794657377\n",
      "90 Train Loss 0.0048557515 Test MSE 5.88408079970443e-06 Test RE 0.0017575471370849833\n",
      "91 Train Loss 0.004765128 Test MSE 6.147851071450378e-06 Test RE 0.0017965087501785391\n",
      "92 Train Loss 0.004681193 Test MSE 5.11547739879671e-06 Test RE 0.0016387426346179915\n",
      "93 Train Loss 0.004627788 Test MSE 4.480636593666344e-06 Test RE 0.0015336897969288868\n",
      "94 Train Loss 0.0045522433 Test MSE 4.212434102807322e-06 Test RE 0.0014870796401647874\n",
      "95 Train Loss 0.004467844 Test MSE 3.799630976019838e-06 Test RE 0.001412337132155468\n",
      "96 Train Loss 0.00442402 Test MSE 4.017525280726953e-06 Test RE 0.0014522686981880031\n",
      "97 Train Loss 0.0043673553 Test MSE 4.1906931303679645e-06 Test RE 0.0014832371609314388\n",
      "98 Train Loss 0.004304329 Test MSE 4.1951391271355075e-06 Test RE 0.0014840237515134555\n",
      "99 Train Loss 0.0042526852 Test MSE 4.691221017120264e-06 Test RE 0.0015693167666880354\n",
      "100 Train Loss 0.004194937 Test MSE 4.811348831288654e-06 Test RE 0.0015892824595259867\n",
      "101 Train Loss 0.004125989 Test MSE 5.2168027969469584e-06 Test RE 0.0016548928427002505\n",
      "102 Train Loss 0.0040583094 Test MSE 5.41291066110931e-06 Test RE 0.0016857109086760406\n",
      "103 Train Loss 0.004000547 Test MSE 6.388450570124852e-06 Test RE 0.0018313250545246948\n",
      "104 Train Loss 0.003924014 Test MSE 5.9944331260395715e-06 Test RE 0.0017739514404682306\n",
      "105 Train Loss 0.0038828712 Test MSE 5.69064640926195e-06 Test RE 0.0017284167577614274\n",
      "106 Train Loss 0.0038174116 Test MSE 5.603089616452817e-06 Test RE 0.0017150684269404463\n",
      "107 Train Loss 0.003735015 Test MSE 5.314537163467306e-06 Test RE 0.0016703227327568672\n",
      "108 Train Loss 0.0036532087 Test MSE 5.614808378084089e-06 Test RE 0.0017168610075990805\n",
      "109 Train Loss 0.0035899568 Test MSE 6.13645674461875e-06 Test RE 0.0017948431680823236\n",
      "110 Train Loss 0.0035540636 Test MSE 5.846767995794919e-06 Test RE 0.001751965695467584\n",
      "111 Train Loss 0.0035082446 Test MSE 6.1260077094476605e-06 Test RE 0.0017933144055879236\n",
      "112 Train Loss 0.00344729 Test MSE 6.288466351004561e-06 Test RE 0.0018169377086616177\n",
      "113 Train Loss 0.0033941888 Test MSE 5.476000263017036e-06 Test RE 0.001695506260891426\n",
      "114 Train Loss 0.003355419 Test MSE 5.622493366105467e-06 Test RE 0.0017180355396401157\n",
      "115 Train Loss 0.0033245215 Test MSE 5.462483433378698e-06 Test RE 0.0016934123941875416\n",
      "116 Train Loss 0.003286845 Test MSE 5.280849717441316e-06 Test RE 0.0016650204498547512\n",
      "117 Train Loss 0.0032500823 Test MSE 4.813943219333147e-06 Test RE 0.0015897108902918648\n",
      "118 Train Loss 0.0032124047 Test MSE 4.7778711360509405e-06 Test RE 0.001583743639644311\n",
      "119 Train Loss 0.0031812792 Test MSE 4.816256683355206e-06 Test RE 0.0015900928326030629\n",
      "120 Train Loss 0.0031464384 Test MSE 4.54202439771824e-06 Test RE 0.0015441603581651247\n",
      "121 Train Loss 0.0031261314 Test MSE 4.577347355076974e-06 Test RE 0.001550153134668365\n",
      "122 Train Loss 0.0030975041 Test MSE 4.5850203753220945e-06 Test RE 0.0015514518536644116\n",
      "123 Train Loss 0.0030562268 Test MSE 4.688430435757174e-06 Test RE 0.0015688499417868791\n",
      "124 Train Loss 0.0030013546 Test MSE 4.604296851054722e-06 Test RE 0.001554709762462689\n",
      "125 Train Loss 0.002939857 Test MSE 4.541740482663125e-06 Test RE 0.0015441120958501178\n",
      "126 Train Loss 0.0028891503 Test MSE 4.844096752414817e-06 Test RE 0.001594681926258485\n",
      "127 Train Loss 0.002841017 Test MSE 4.76648360709462e-06 Test RE 0.0015818551745798751\n",
      "128 Train Loss 0.0028181057 Test MSE 4.724862290041378e-06 Test RE 0.0015749335883762721\n",
      "129 Train Loss 0.0027729524 Test MSE 4.7701186840926035e-06 Test RE 0.0015824582469844758\n",
      "130 Train Loss 0.0027147841 Test MSE 4.90564377763892e-06 Test RE 0.0016047806239366821\n",
      "131 Train Loss 0.0026756884 Test MSE 4.904760086033693e-06 Test RE 0.001604636076645809\n",
      "132 Train Loss 0.0026529678 Test MSE 4.8542136361891416e-06 Test RE 0.0015963463022785165\n",
      "133 Train Loss 0.002621375 Test MSE 4.948681805993136e-06 Test RE 0.0016118047552040207\n",
      "134 Train Loss 0.002605722 Test MSE 5.03817409569079e-06 Test RE 0.0016263134470666284\n",
      "135 Train Loss 0.002567352 Test MSE 5.523476841530642e-06 Test RE 0.0017028403650642947\n",
      "136 Train Loss 0.002543006 Test MSE 5.8911635839044475e-06 Test RE 0.0017586046160435159\n",
      "137 Train Loss 0.0025183274 Test MSE 6.2730403552871025e-06 Test RE 0.0018147078101847798\n",
      "138 Train Loss 0.0024827544 Test MSE 6.751080085108267e-06 Test RE 0.0018825837150446593\n",
      "139 Train Loss 0.0024622658 Test MSE 6.876430751850346e-06 Test RE 0.0018999807663180335\n",
      "140 Train Loss 0.0024232622 Test MSE 7.176295701640366e-06 Test RE 0.0019409655646005094\n",
      "141 Train Loss 0.0023723906 Test MSE 7.025591582858778e-06 Test RE 0.001920477031101459\n",
      "142 Train Loss 0.002305153 Test MSE 6.601403805190039e-06 Test RE 0.001861597629402796\n",
      "143 Train Loss 0.0022480749 Test MSE 6.9909576095699265e-06 Test RE 0.0019157375066718725\n",
      "144 Train Loss 0.002217185 Test MSE 7.349154771033874e-06 Test RE 0.001964202974774417\n",
      "145 Train Loss 0.0021717327 Test MSE 6.860451365192831e-06 Test RE 0.0018977719034060847\n",
      "146 Train Loss 0.0021272472 Test MSE 7.059297029731776e-06 Test RE 0.0019250782867305056\n",
      "147 Train Loss 0.0021040554 Test MSE 7.795321470439089e-06 Test RE 0.0020229478283965555\n",
      "148 Train Loss 0.002073245 Test MSE 7.820166479843884e-06 Test RE 0.002026169002455601\n",
      "149 Train Loss 0.0020299973 Test MSE 7.1650446996844565e-06 Test RE 0.0019394434441137697\n",
      "150 Train Loss 0.001995511 Test MSE 6.488228755605995e-06 Test RE 0.0018455709446705457\n",
      "151 Train Loss 0.0019756516 Test MSE 5.705140265871971e-06 Test RE 0.0017306164633728311\n",
      "152 Train Loss 0.0019415525 Test MSE 5.222330852282615e-06 Test RE 0.0016557694252842604\n",
      "153 Train Loss 0.0019318984 Test MSE 5.096857557838986e-06 Test RE 0.0016357574837024792\n",
      "154 Train Loss 0.0019080527 Test MSE 5.062998503730286e-06 Test RE 0.001630315160662941\n",
      "155 Train Loss 0.0018887168 Test MSE 5.415840052095227e-06 Test RE 0.0016861669884750794\n",
      "156 Train Loss 0.0018654512 Test MSE 5.489082748225178e-06 Test RE 0.0016975303845335353\n",
      "157 Train Loss 0.0018473811 Test MSE 5.414705844576727e-06 Test RE 0.0016859904172140333\n",
      "158 Train Loss 0.0018290359 Test MSE 5.248017773740026e-06 Test RE 0.0016598365218413766\n",
      "159 Train Loss 0.0018053352 Test MSE 5.174437101580687e-06 Test RE 0.001648159445631353\n",
      "160 Train Loss 0.0017636836 Test MSE 5.119636698888623e-06 Test RE 0.0016394087149196974\n",
      "161 Train Loss 0.001730397 Test MSE 5.474220508778246e-06 Test RE 0.0016952307103494419\n",
      "162 Train Loss 0.0017055328 Test MSE 5.4203747274693335e-06 Test RE 0.0016868727534139543\n",
      "163 Train Loss 0.0016917319 Test MSE 5.202886063297695e-06 Test RE 0.0016526840105922376\n",
      "164 Train Loss 0.0016697531 Test MSE 5.399168669035932e-06 Test RE 0.001683569754996995\n",
      "165 Train Loss 0.0016543549 Test MSE 4.909630927793904e-06 Test RE 0.00160543264862572\n",
      "166 Train Loss 0.0016325563 Test MSE 4.511584266018754e-06 Test RE 0.001538977265762902\n",
      "167 Train Loss 0.0015980741 Test MSE 4.98621542268528e-06 Test RE 0.0016179056308054328\n",
      "168 Train Loss 0.0015746277 Test MSE 4.520814483152333e-06 Test RE 0.0015405507525236132\n",
      "169 Train Loss 0.0015554584 Test MSE 3.991757914086782e-06 Test RE 0.0014476039689135208\n",
      "170 Train Loss 0.001533238 Test MSE 3.264616514981784e-06 Test RE 0.0013091329511978496\n",
      "171 Train Loss 0.0014963098 Test MSE 2.7563428584041855e-06 Test RE 0.0012029131891094095\n",
      "172 Train Loss 0.0014807597 Test MSE 2.4077868807317644e-06 Test RE 0.0011242857070355705\n",
      "173 Train Loss 0.0014714485 Test MSE 2.437526884371029e-06 Test RE 0.001131207757793152\n",
      "174 Train Loss 0.0014597155 Test MSE 2.596943961039359e-06 Test RE 0.0011676130941866846\n",
      "175 Train Loss 0.001436572 Test MSE 2.460101383250803e-06 Test RE 0.001136433873636017\n",
      "176 Train Loss 0.001419491 Test MSE 2.302897407696157e-06 Test RE 0.0010995246321418121\n",
      "177 Train Loss 0.001405544 Test MSE 2.3475383312178363e-06 Test RE 0.0011101304464540003\n",
      "178 Train Loss 0.0013881471 Test MSE 2.0786388727853777e-06 Test RE 0.0010446172425105581\n",
      "179 Train Loss 0.0013651415 Test MSE 2.268515973301917e-06 Test RE 0.00109128601190086\n",
      "180 Train Loss 0.0013539522 Test MSE 2.0573582022551625e-06 Test RE 0.0010392561993519955\n",
      "181 Train Loss 0.0013278725 Test MSE 1.925234132820465e-06 Test RE 0.0010053318554080078\n",
      "182 Train Loss 0.0013055644 Test MSE 1.8167276421598106e-06 Test RE 0.0009765906899431923\n",
      "183 Train Loss 0.001279729 Test MSE 1.6559252429723277e-06 Test RE 0.0009323694413019048\n",
      "184 Train Loss 0.0012536523 Test MSE 1.6230061817483975e-06 Test RE 0.0009230553730423085\n",
      "185 Train Loss 0.0012169826 Test MSE 1.7426649118269665e-06 Test RE 0.0009564771759403242\n",
      "186 Train Loss 0.0011923639 Test MSE 1.638320211367e-06 Test RE 0.0009273999372197996\n",
      "187 Train Loss 0.0011746297 Test MSE 1.6729783282706694e-06 Test RE 0.000937158018037758\n",
      "188 Train Loss 0.0011635637 Test MSE 1.7480344622052044e-06 Test RE 0.0009579496053917382\n",
      "189 Train Loss 0.0011537797 Test MSE 1.7635803639664455e-06 Test RE 0.0009621998724173697\n",
      "190 Train Loss 0.0011419195 Test MSE 1.7187171033150398e-06 Test RE 0.0009498824571867553\n",
      "191 Train Loss 0.0011328483 Test MSE 1.7574678892142453e-06 Test RE 0.0009605309585501004\n",
      "192 Train Loss 0.0011196821 Test MSE 1.9619919150360074e-06 Test RE 0.0010148836929273943\n",
      "193 Train Loss 0.0011092747 Test MSE 1.8396606205580048e-06 Test RE 0.0009827352262438429\n",
      "194 Train Loss 0.0011082266 Test MSE 1.8561830961860463e-06 Test RE 0.0009871384633859288\n",
      "195 Train Loss 0.0011006624 Test MSE 1.915489674101554e-06 Test RE 0.0010027844140188\n",
      "196 Train Loss 0.0010930572 Test MSE 2.053523786994833e-06 Test RE 0.0010382872873031044\n",
      "197 Train Loss 0.0010856999 Test MSE 2.085728042900805e-06 Test RE 0.0010463970528747078\n",
      "198 Train Loss 0.0010782984 Test MSE 2.076707279235762e-06 Test RE 0.001044131769797902\n",
      "199 Train Loss 0.0010747071 Test MSE 2.0069344548549163e-06 Test RE 0.0010264416405450269\n",
      "200 Train Loss 0.0010705339 Test MSE 1.97973785360394e-06 Test RE 0.001019463100735442\n",
      "201 Train Loss 0.0010595785 Test MSE 1.9265178549940633e-06 Test RE 0.0010056669709430062\n",
      "202 Train Loss 0.0010409915 Test MSE 1.888892540228023e-06 Test RE 0.0009957981001789686\n",
      "203 Train Loss 0.0010185357 Test MSE 2.07199327125798e-06 Test RE 0.0010429460365200852\n",
      "204 Train Loss 0.0010082957 Test MSE 2.0755228217285554e-06 Test RE 0.0010438339651628339\n",
      "205 Train Loss 0.0009987807 Test MSE 2.0054784938406352e-06 Test RE 0.0010260692491718814\n",
      "206 Train Loss 0.0009910733 Test MSE 1.9472691902648175e-06 Test RE 0.0010110686951091993\n",
      "207 Train Loss 0.0009798773 Test MSE 1.7743979667508578e-06 Test RE 0.0009651463736247628\n",
      "208 Train Loss 0.00097210763 Test MSE 1.8292043734880526e-06 Test RE 0.000979938415483321\n",
      "209 Train Loss 0.00096344104 Test MSE 1.8588147229728342e-06 Test RE 0.0009878379794846389\n",
      "210 Train Loss 0.000955634 Test MSE 1.6262423067017517e-06 Test RE 0.0009239751585090507\n",
      "211 Train Loss 0.000944964 Test MSE 1.6611443132150394e-06 Test RE 0.0009338375853100892\n",
      "212 Train Loss 0.0009398526 Test MSE 1.6229798767138383e-06 Test RE 0.0009230478927559899\n",
      "213 Train Loss 0.000924596 Test MSE 1.5032905116052743e-06 Test RE 0.0008883602666855484\n",
      "214 Train Loss 0.00091501273 Test MSE 1.4570076699823623e-06 Test RE 0.0008745780768671008\n",
      "215 Train Loss 0.0008981866 Test MSE 1.4052757324977021e-06 Test RE 0.0008589115462013125\n",
      "216 Train Loss 0.00089334924 Test MSE 1.3896241427077542e-06 Test RE 0.0008541149881808457\n",
      "217 Train Loss 0.00088723295 Test MSE 1.442570634741288e-06 Test RE 0.0008702343289726017\n",
      "218 Train Loss 0.00087697856 Test MSE 1.563517735396405e-06 Test RE 0.0009059809661021251\n",
      "219 Train Loss 0.0008654174 Test MSE 1.6159643763357846e-06 Test RE 0.0009210507466390944\n",
      "220 Train Loss 0.00085666927 Test MSE 1.5704962562561703e-06 Test RE 0.000908000568392165\n",
      "221 Train Loss 0.00084981887 Test MSE 1.5744761241090622e-06 Test RE 0.0009091503437351136\n",
      "222 Train Loss 0.0008356038 Test MSE 1.6353275334488286e-06 Test RE 0.0009265525210994599\n",
      "223 Train Loss 0.0008291176 Test MSE 1.6817740896075344e-06 Test RE 0.0009396183643547958\n",
      "224 Train Loss 0.0008250025 Test MSE 1.7567197059750953e-06 Test RE 0.0009603264798025192\n",
      "225 Train Loss 0.000822761 Test MSE 1.7925018564050176e-06 Test RE 0.0009700574931732043\n",
      "226 Train Loss 0.0008140279 Test MSE 1.732077510592968e-06 Test RE 0.0009535672546800447\n",
      "227 Train Loss 0.0008066608 Test MSE 1.4975514595235789e-06 Test RE 0.00088666291642402\n",
      "228 Train Loss 0.0007962087 Test MSE 1.3515675395206688e-06 Test RE 0.0008423382924836637\n",
      "229 Train Loss 0.0007894827 Test MSE 1.3565618427443104e-06 Test RE 0.0008438931588036831\n",
      "230 Train Loss 0.0007789814 Test MSE 1.475245320797538e-06 Test RE 0.0008800346872771827\n",
      "231 Train Loss 0.00077286136 Test MSE 1.4471120167625095e-06 Test RE 0.0008716030526019709\n",
      "232 Train Loss 0.00076120725 Test MSE 1.5162321157155526e-06 Test RE 0.000892175952726573\n",
      "233 Train Loss 0.00075020007 Test MSE 1.6987643192684033e-06 Test RE 0.0009443527142667995\n",
      "234 Train Loss 0.0007382381 Test MSE 1.7057357603553718e-06 Test RE 0.0009462884621132348\n",
      "235 Train Loss 0.00072420377 Test MSE 1.476387511079592e-06 Test RE 0.000880375299299223\n",
      "236 Train Loss 0.0007185168 Test MSE 1.32485258423235e-06 Test RE 0.0008339719548499286\n",
      "237 Train Loss 0.000708852 Test MSE 1.284788215032351e-06 Test RE 0.0008212652363518174\n",
      "238 Train Loss 0.00070238684 Test MSE 1.182073594994789e-06 Test RE 0.0007877527460400242\n",
      "239 Train Loss 0.0006986818 Test MSE 1.1790438551894906e-06 Test RE 0.0007867425648057544\n",
      "240 Train Loss 0.0006976635 Test MSE 1.1979692592083803e-06 Test RE 0.000793031621095372\n",
      "241 Train Loss 0.0006906092 Test MSE 1.1519837752303566e-06 Test RE 0.0007776619479672699\n",
      "242 Train Loss 0.00068030873 Test MSE 1.207376229373926e-06 Test RE 0.0007961391454035197\n",
      "243 Train Loss 0.0006704309 Test MSE 1.2649771518276306e-06 Test RE 0.0008149088011844185\n",
      "244 Train Loss 0.0006619898 Test MSE 1.1144345885948172e-06 Test RE 0.0007648829127738745\n",
      "245 Train Loss 0.00065846083 Test MSE 1.0997762851322643e-06 Test RE 0.0007598359596872616\n",
      "246 Train Loss 0.0006519201 Test MSE 1.0987709753021278e-06 Test RE 0.0007594885957669826\n",
      "247 Train Loss 0.0006458948 Test MSE 1.0250356234342379e-06 Test RE 0.0007335625424734102\n",
      "248 Train Loss 0.0006393308 Test MSE 9.083383810711021e-07 Test RE 0.0006905442292672626\n",
      "249 Train Loss 0.00063140754 Test MSE 8.544574080603545e-07 Test RE 0.000669750239155594\n",
      "250 Train Loss 0.0006276276 Test MSE 8.110075604737275e-07 Test RE 0.000652499403638043\n",
      "251 Train Loss 0.0006228073 Test MSE 9.000578229339838e-07 Test RE 0.0006873894670903573\n",
      "252 Train Loss 0.00061649707 Test MSE 9.429553336285362e-07 Test RE 0.0007035795830624836\n",
      "253 Train Loss 0.0006082241 Test MSE 9.979781243806095e-07 Test RE 0.0007238159991736707\n",
      "254 Train Loss 0.00059905805 Test MSE 9.922731306745855e-07 Test RE 0.0007217441681483517\n",
      "255 Train Loss 0.00059218315 Test MSE 8.361172097228445e-07 Test RE 0.0006625234411674724\n",
      "256 Train Loss 0.00058348215 Test MSE 8.98157628901387e-07 Test RE 0.0006866634784626253\n",
      "257 Train Loss 0.00058113295 Test MSE 9.547901626555993e-07 Test RE 0.0007079810534530409\n",
      "258 Train Loss 0.00057888 Test MSE 9.877062537927328e-07 Test RE 0.0007200813608268954\n",
      "259 Train Loss 0.0005745365 Test MSE 9.403109531965689e-07 Test RE 0.0007025923473763517\n",
      "260 Train Loss 0.00057367794 Test MSE 9.283518243601432e-07 Test RE 0.0006981101707088667\n",
      "261 Train Loss 0.00056999945 Test MSE 9.036108376894294e-07 Test RE 0.0006887448796696025\n",
      "262 Train Loss 0.00056636106 Test MSE 8.66236244459581e-07 Test RE 0.0006743507475251638\n",
      "263 Train Loss 0.00056473335 Test MSE 9.100201747455016e-07 Test RE 0.0006911832069186856\n",
      "264 Train Loss 0.0005616543 Test MSE 8.395716617406339e-07 Test RE 0.0006638906516280594\n",
      "265 Train Loss 0.00055846514 Test MSE 8.288452004982072e-07 Test RE 0.0006596360480954477\n",
      "266 Train Loss 0.0005571581 Test MSE 8.393783427423998e-07 Test RE 0.0006638142138024239\n",
      "267 Train Loss 0.0005563278 Test MSE 8.39377274174817e-07 Test RE 0.0006638137912691397\n",
      "268 Train Loss 0.0005556502 Test MSE 8.39377274174817e-07 Test RE 0.0006638137912691397\n",
      "269 Train Loss 0.0005551026 Test MSE 8.39377274174817e-07 Test RE 0.0006638137912691397\n",
      "270 Train Loss 0.00055470824 Test MSE 8.39377274174817e-07 Test RE 0.0006638137912691397\n",
      "271 Train Loss 0.00055443315 Test MSE 8.39377274174817e-07 Test RE 0.0006638137912691397\n",
      "272 Train Loss 0.0005542478 Test MSE 8.39377274174817e-07 Test RE 0.0006638137912691397\n",
      "273 Train Loss 0.00055412605 Test MSE 8.39377274174817e-07 Test RE 0.0006638137912691397\n",
      "274 Train Loss 0.0005537982 Test MSE 8.415709602916892e-07 Test RE 0.0006646806534963358\n",
      "275 Train Loss 0.0005536465 Test MSE 8.415357972153668e-07 Test RE 0.0006646667672872129\n",
      "276 Train Loss 0.0005535373 Test MSE 8.415357972153668e-07 Test RE 0.0006646667672872129\n",
      "277 Train Loss 0.0005534574 Test MSE 8.415357972153668e-07 Test RE 0.0006646667672872129\n",
      "278 Train Loss 0.0005534051 Test MSE 8.415357972153668e-07 Test RE 0.0006646667672872129\n",
      "279 Train Loss 0.0005535033 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "280 Train Loss 0.0005535755 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "281 Train Loss 0.00055362185 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "282 Train Loss 0.0005536523 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "283 Train Loss 0.0005536726 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "284 Train Loss 0.0005536865 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "285 Train Loss 0.00055369624 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "286 Train Loss 0.0005537033 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "287 Train Loss 0.0005537085 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "288 Train Loss 0.00055371254 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "289 Train Loss 0.0005537156 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "290 Train Loss 0.0005537181 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "291 Train Loss 0.00055372017 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "292 Train Loss 0.0005537218 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "293 Train Loss 0.00055372325 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "294 Train Loss 0.0005537244 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "295 Train Loss 0.00055372546 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "296 Train Loss 0.0005537264 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "297 Train Loss 0.0005537271 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "298 Train Loss 0.0005537278 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "299 Train Loss 0.0005537283 Test MSE 8.414740356561839e-07 Test RE 0.0006646423764001918\n",
      "Training time: 157.00\n",
      "KG_stanALR_medium\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 18782.387 Test MSE 6.97678708721313 Test RE 1.9137949422019356\n",
      "1 Train Loss 2064.0544 Test MSE 10.062954937690408 Test RE 2.298425501528667\n",
      "2 Train Loss 802.7318 Test MSE 11.901979118036113 Test RE 2.4996388135700935\n",
      "3 Train Loss 467.18906 Test MSE 11.115946972338827 Test RE 2.4156883275161016\n",
      "4 Train Loss 339.9097 Test MSE 10.043597180772647 Test RE 2.296213736687426\n",
      "5 Train Loss 236.81393 Test MSE 9.055264430518461 Test RE 2.180309947198122\n",
      "6 Train Loss 184.81023 Test MSE 7.222192980866007 Test RE 1.9471625676266615\n",
      "7 Train Loss 78.28768 Test MSE 1.6448332446520384 Test RE 0.9292415172205694\n",
      "8 Train Loss 20.3513 Test MSE 0.3135002940650529 Test RE 0.4056828456702013\n",
      "9 Train Loss 7.252784 Test MSE 0.12027582172156787 Test RE 0.25127936967834236\n",
      "10 Train Loss 3.9030032 Test MSE 0.03528580440443475 Test RE 0.13610299397494596\n",
      "11 Train Loss 2.3071573 Test MSE 0.023480249543920327 Test RE 0.11102455004239248\n",
      "12 Train Loss 1.557121 Test MSE 0.01278534770272585 Test RE 0.08192641278144441\n",
      "13 Train Loss 1.2542328 Test MSE 0.007550918171682377 Test RE 0.06296041030455313\n",
      "14 Train Loss 0.958312 Test MSE 0.0035893733794027712 Test RE 0.04340872065012786\n",
      "15 Train Loss 0.75432867 Test MSE 0.0013853508707791448 Test RE 0.026967926673793358\n",
      "16 Train Loss 0.61507916 Test MSE 0.0013849885452682092 Test RE 0.026964399839187796\n",
      "17 Train Loss 0.46793374 Test MSE 0.001464061560102444 Test RE 0.027723453978097428\n",
      "18 Train Loss 0.38666204 Test MSE 0.00132114642692574 Test RE 0.026335595612583987\n",
      "19 Train Loss 0.32613245 Test MSE 0.002011913527263585 Test RE 0.03249917399257334\n",
      "20 Train Loss 0.2822859 Test MSE 0.0014505863743533227 Test RE 0.027595576065321103\n",
      "21 Train Loss 0.21836737 Test MSE 0.00038940554313314176 Test RE 0.014297784017543306\n",
      "22 Train Loss 0.19073142 Test MSE 0.0003102437360025994 Test RE 0.012762012875767616\n",
      "23 Train Loss 0.15976869 Test MSE 0.00019831166418554164 Test RE 0.01020332680893233\n",
      "24 Train Loss 0.13009457 Test MSE 0.0002315626441320083 Test RE 0.011025592004686433\n",
      "25 Train Loss 0.11285949 Test MSE 0.00020390314100371686 Test RE 0.010346170368611254\n",
      "26 Train Loss 0.09678556 Test MSE 0.00021152955013126976 Test RE 0.010537878587584084\n",
      "27 Train Loss 0.08955269 Test MSE 0.0002482362789660691 Test RE 0.011415640772764015\n",
      "28 Train Loss 0.08178425 Test MSE 0.00017627831544168862 Test RE 0.009619823712335959\n",
      "29 Train Loss 0.07291409 Test MSE 0.00013559566891508632 Test RE 0.00843704910126963\n",
      "30 Train Loss 0.068578064 Test MSE 0.0001285702568849997 Test RE 0.008215574220360353\n",
      "31 Train Loss 0.059420004 Test MSE 0.00013979958988504066 Test RE 0.008566839221400878\n",
      "32 Train Loss 0.049461935 Test MSE 9.547746360713557e-05 Test RE 0.007079752969148044\n",
      "33 Train Loss 0.044831946 Test MSE 0.00010805465533703322 Test RE 0.007531637495300091\n",
      "34 Train Loss 0.039000284 Test MSE 8.857632029316874e-05 Test RE 0.006819090981404588\n",
      "35 Train Loss 0.03646428 Test MSE 7.114428050967881e-05 Test RE 0.0061113571314945995\n",
      "36 Train Loss 0.034581874 Test MSE 7.836157682424267e-05 Test RE 0.0064138566748486\n",
      "37 Train Loss 0.032920778 Test MSE 7.275205043787276e-05 Test RE 0.006180025778158166\n",
      "38 Train Loss 0.03066703 Test MSE 8.602484869415962e-05 Test RE 0.006720160202520643\n",
      "39 Train Loss 0.02974909 Test MSE 8.025991382060579e-05 Test RE 0.006491080754978679\n",
      "40 Train Loss 0.027346773 Test MSE 7.063842844004783e-05 Test RE 0.006089591801449185\n",
      "41 Train Loss 0.025743706 Test MSE 8.602699539249727e-05 Test RE 0.006720244050774706\n",
      "42 Train Loss 0.02484724 Test MSE 7.352475268700708e-05 Test RE 0.006212758237033087\n",
      "43 Train Loss 0.023233294 Test MSE 8.113415263174238e-05 Test RE 0.0065263373659341\n",
      "44 Train Loss 0.022521552 Test MSE 7.49135564725222e-05 Test RE 0.006271159913532734\n",
      "45 Train Loss 0.021210274 Test MSE 7.145635105158872e-05 Test RE 0.006124746034039618\n",
      "46 Train Loss 0.020665862 Test MSE 7.694619088216423e-05 Test RE 0.006355668401843934\n",
      "47 Train Loss 0.019162267 Test MSE 9.202672482882184e-05 Test RE 0.0069506376847423565\n",
      "48 Train Loss 0.017394485 Test MSE 7.179566793541584e-05 Test RE 0.006139270764055815\n",
      "49 Train Loss 0.016915897 Test MSE 6.058460118462834e-05 Test RE 0.005639606395036242\n",
      "50 Train Loss 0.0155158965 Test MSE 6.441291842838923e-05 Test RE 0.00581505940857265\n",
      "51 Train Loss 0.014843416 Test MSE 6.445039307179878e-05 Test RE 0.005816750727619175\n",
      "52 Train Loss 0.014310255 Test MSE 6.423029090586183e-05 Test RE 0.005806809947571029\n",
      "53 Train Loss 0.01288811 Test MSE 5.64724752633441e-05 Test RE 0.005444852002009753\n",
      "54 Train Loss 0.0121913925 Test MSE 4.770614564202698e-05 Test RE 0.005004432461468271\n",
      "55 Train Loss 0.011693811 Test MSE 5.232629872709113e-05 Test RE 0.005241163112358073\n",
      "56 Train Loss 0.011452359 Test MSE 4.702332327548131e-05 Test RE 0.004968488935533996\n",
      "57 Train Loss 0.010853391 Test MSE 4.705666074569794e-05 Test RE 0.00497024984366919\n",
      "58 Train Loss 0.01031775 Test MSE 4.997869392953199e-05 Test RE 0.005122242308725285\n",
      "59 Train Loss 0.010020217 Test MSE 4.93113926948725e-05 Test RE 0.005087932041111082\n",
      "60 Train Loss 0.009818533 Test MSE 5.0416736208840384e-05 Test RE 0.005144640490300251\n",
      "61 Train Loss 0.009331833 Test MSE 4.3214590463549565e-05 Test RE 0.004763025081554194\n",
      "62 Train Loss 0.009094816 Test MSE 3.745270834992535e-05 Test RE 0.004434138784267063\n",
      "63 Train Loss 0.008998513 Test MSE 3.7502623719646644e-05 Test RE 0.0044370926157830054\n",
      "64 Train Loss 0.008617198 Test MSE 3.563744494107938e-05 Test RE 0.0043253469297299\n",
      "65 Train Loss 0.0081822425 Test MSE 3.570407192819111e-05 Test RE 0.004329388328662511\n",
      "66 Train Loss 0.008053838 Test MSE 3.2852836515124784e-05 Test RE 0.004152925151982764\n",
      "67 Train Loss 0.007814351 Test MSE 3.203964931048405e-05 Test RE 0.004101205627152421\n",
      "68 Train Loss 0.007640704 Test MSE 3.0251118582316664e-05 Test RE 0.003985092318051565\n",
      "69 Train Loss 0.007341282 Test MSE 2.9222935732583658e-05 Test RE 0.003916783703123261\n",
      "70 Train Loss 0.0071838573 Test MSE 2.6645531633065627e-05 Test RE 0.003740071135754204\n",
      "71 Train Loss 0.0069943704 Test MSE 2.4356255811597113e-05 Test RE 0.0035757976203811444\n",
      "72 Train Loss 0.0068740905 Test MSE 2.4260142023892123e-05 Test RE 0.0035687353037321618\n",
      "73 Train Loss 0.006759415 Test MSE 2.2957436721156177e-05 Test RE 0.0034715974893031036\n",
      "74 Train Loss 0.006498673 Test MSE 2.320754233193254e-05 Test RE 0.003490456607240413\n",
      "75 Train Loss 0.0063409023 Test MSE 2.349246377332516e-05 Test RE 0.003511817596155542\n",
      "76 Train Loss 0.006238773 Test MSE 2.2901341911426648e-05 Test RE 0.003467353598621706\n",
      "77 Train Loss 0.00615967 Test MSE 2.110782730132639e-05 Test RE 0.0033288132677376393\n",
      "78 Train Loss 0.0059755216 Test MSE 1.932044048874117e-05 Test RE 0.003184756110161462\n",
      "79 Train Loss 0.005577281 Test MSE 1.8849481042526496e-05 Test RE 0.0031457004652636344\n",
      "80 Train Loss 0.005225891 Test MSE 1.8577440619051775e-05 Test RE 0.0031229181988522738\n",
      "81 Train Loss 0.0051176115 Test MSE 1.973918866381766e-05 Test RE 0.0032190840530565215\n",
      "82 Train Loss 0.0050285184 Test MSE 1.8478695607317625e-05 Test RE 0.003114607488356001\n",
      "83 Train Loss 0.0048418874 Test MSE 1.970867388153902e-05 Test RE 0.0032165949020754887\n",
      "84 Train Loss 0.0045337556 Test MSE 2.412616652537705e-05 Test RE 0.003558867574536245\n",
      "85 Train Loss 0.004378162 Test MSE 2.2830331438650607e-05 Test RE 0.0034619737920829987\n",
      "86 Train Loss 0.004257392 Test MSE 2.4638350271004476e-05 Test RE 0.003596445472953455\n",
      "87 Train Loss 0.0041342685 Test MSE 2.5560373469067876e-05 Test RE 0.0036631210060451814\n",
      "88 Train Loss 0.003988552 Test MSE 2.5168280014855836e-05 Test RE 0.0036349164779507876\n",
      "89 Train Loss 0.0037696129 Test MSE 2.2397426665496905e-05 Test RE 0.0034289940323379395\n",
      "90 Train Loss 0.0035439176 Test MSE 2.0099089079620865e-05 Test RE 0.003248297928371942\n",
      "91 Train Loss 0.0034277933 Test MSE 1.8487270610962168e-05 Test RE 0.003115330068386206\n",
      "92 Train Loss 0.0033239648 Test MSE 1.7778462175460654e-05 Test RE 0.0030550249659889598\n",
      "93 Train Loss 0.003224656 Test MSE 1.690037551053286e-05 Test RE 0.0029786250997275777\n",
      "94 Train Loss 0.0031540564 Test MSE 1.652845376270775e-05 Test RE 0.0029456678941947394\n",
      "95 Train Loss 0.003057212 Test MSE 1.5422761528508244e-05 Test RE 0.0028454354597143134\n",
      "96 Train Loss 0.0029841817 Test MSE 1.5070712537127079e-05 Test RE 0.0028127721974801788\n",
      "97 Train Loss 0.0028570057 Test MSE 1.574979221967359e-05 Test RE 0.0028754451121746627\n",
      "98 Train Loss 0.0028158424 Test MSE 1.5056088786945086e-05 Test RE 0.0028114071903175227\n",
      "99 Train Loss 0.0027717617 Test MSE 1.4865236968121467e-05 Test RE 0.0027935315846573947\n",
      "100 Train Loss 0.0027360246 Test MSE 1.5089202293463431e-05 Test RE 0.002814497116944033\n",
      "101 Train Loss 0.002717553 Test MSE 1.578038068219903e-05 Test RE 0.0028782360309239324\n",
      "102 Train Loss 0.0026723428 Test MSE 1.60691548198918e-05 Test RE 0.0029044518769090924\n",
      "103 Train Loss 0.0026578598 Test MSE 1.6548804928478578e-05 Test RE 0.00294748080829724\n",
      "104 Train Loss 0.0025962037 Test MSE 1.6332859632242683e-05 Test RE 0.002928186826585241\n",
      "105 Train Loss 0.0025632142 Test MSE 1.5527117917458196e-05 Test RE 0.0028550458903593284\n",
      "106 Train Loss 0.0025091756 Test MSE 1.5649387368790712e-05 Test RE 0.002866264983470215\n",
      "107 Train Loss 0.0024599582 Test MSE 1.577168184627139e-05 Test RE 0.0028774426167831792\n",
      "108 Train Loss 0.002399276 Test MSE 1.6367944729726484e-05 Test RE 0.0029313302016385125\n",
      "109 Train Loss 0.0023445329 Test MSE 1.642933979667387e-05 Test RE 0.0029368226678457552\n",
      "110 Train Loss 0.0022914582 Test MSE 1.6736978768836986e-05 Test RE 0.0029641911087962226\n",
      "111 Train Loss 0.0022440748 Test MSE 1.6379134206204875e-05 Test RE 0.00293233199041208\n",
      "112 Train Loss 0.0022115298 Test MSE 1.5870787055265378e-05 Test RE 0.002886469015285774\n",
      "113 Train Loss 0.0021749255 Test MSE 1.6716167992954465e-05 Test RE 0.0029623476965210307\n",
      "114 Train Loss 0.0021209915 Test MSE 1.628538896182902e-05 Test RE 0.002923928413076894\n",
      "115 Train Loss 0.0020950108 Test MSE 1.6224047408887857e-05 Test RE 0.0029184164930260693\n",
      "116 Train Loss 0.0020464421 Test MSE 1.614038455593031e-05 Test RE 0.002910882040369574\n",
      "117 Train Loss 0.0020646204 Test MSE 1.6100195028878706e-05 Test RE 0.002907255736199357\n",
      "118 Train Loss 0.0020205698 Test MSE 1.595092365707962e-05 Test RE 0.0028937471849389117\n",
      "119 Train Loss 0.0019751706 Test MSE 1.616325929825971e-05 Test RE 0.002912944014208669\n",
      "120 Train Loss 0.0019223897 Test MSE 1.4954460939441765e-05 Test RE 0.002801902695368958\n",
      "121 Train Loss 0.001866485 Test MSE 1.511810137048213e-05 Test RE 0.0028171910122357286\n",
      "122 Train Loss 0.00183026 Test MSE 1.6475130834335757e-05 Test RE 0.002940912503022036\n",
      "123 Train Loss 0.0017490265 Test MSE 1.2957343286543185e-05 Test RE 0.0026081084734868253\n",
      "124 Train Loss 0.0017149576 Test MSE 1.2878795640394319e-05 Test RE 0.0026001912566239976\n",
      "125 Train Loss 0.0016586336 Test MSE 1.3176845627691743e-05 Test RE 0.002630106875943844\n",
      "126 Train Loss 0.0016162948 Test MSE 1.2797763516386108e-05 Test RE 0.002591998274243474\n",
      "127 Train Loss 0.0015774362 Test MSE 1.2242350675764903e-05 Test RE 0.0025351290705708843\n",
      "128 Train Loss 0.0015474749 Test MSE 1.2130441898139387e-05 Test RE 0.0025235155118520404\n",
      "129 Train Loss 0.0015330629 Test MSE 1.180402356126548e-05 Test RE 0.002489331309627035\n",
      "130 Train Loss 0.0015480209 Test MSE 1.162937140184636e-05 Test RE 0.002470846625274401\n",
      "131 Train Loss 0.0015277159 Test MSE 1.1556902586563789e-05 Test RE 0.0024631360127409727\n",
      "132 Train Loss 0.0015096383 Test MSE 1.1141290004816953e-05 Test RE 0.0024184405002975157\n",
      "133 Train Loss 0.0014985728 Test MSE 1.103624439858097e-05 Test RE 0.0024070123709102314\n",
      "134 Train Loss 0.0014869539 Test MSE 1.1035964513406919e-05 Test RE 0.002406981849143797\n",
      "135 Train Loss 0.0014641718 Test MSE 1.0791743732502764e-05 Test RE 0.002380200157128701\n",
      "136 Train Loss 0.0014445231 Test MSE 1.0828415125283488e-05 Test RE 0.0023842408030056513\n",
      "137 Train Loss 0.0014161307 Test MSE 1.1228552478699737e-05 Test RE 0.00242789306271773\n",
      "138 Train Loss 0.0014066326 Test MSE 1.106367174112452e-05 Test RE 0.002410001475910714\n",
      "139 Train Loss 0.0014060138 Test MSE 1.106367174112452e-05 Test RE 0.002410001475910714\n",
      "140 Train Loss 0.0014057651 Test MSE 1.106367174112452e-05 Test RE 0.002410001475910714\n",
      "141 Train Loss 0.0014129723 Test MSE 1.1052896748434299e-05 Test RE 0.0024088276308021064\n",
      "142 Train Loss 0.0014012817 Test MSE 1.076537908497472e-05 Test RE 0.002377290918653418\n",
      "143 Train Loss 0.0013906864 Test MSE 1.045430138092329e-05 Test RE 0.002342691898267431\n",
      "144 Train Loss 0.0013520041 Test MSE 1.028037888454375e-05 Test RE 0.002323123126031722\n",
      "145 Train Loss 0.0013235207 Test MSE 9.822142657857034e-06 Test RE 0.0022707576524746125\n",
      "146 Train Loss 0.0013014536 Test MSE 9.83921774193537e-06 Test RE 0.0022727305693136988\n",
      "147 Train Loss 0.0012750895 Test MSE 1.017313531541547e-05 Test RE 0.0023109741002665094\n",
      "148 Train Loss 0.0012574175 Test MSE 1.0505544468153877e-05 Test RE 0.002348426380861589\n",
      "149 Train Loss 0.001239157 Test MSE 1.0520509467657881e-05 Test RE 0.002350098435700521\n",
      "150 Train Loss 0.0012254292 Test MSE 1.0595472402869577e-05 Test RE 0.002358456280398375\n",
      "151 Train Loss 0.0012149861 Test MSE 1.0672574479547116e-05 Test RE 0.002367021838283457\n",
      "152 Train Loss 0.001217596 Test MSE 1.0275493948953252e-05 Test RE 0.0023225711203428635\n",
      "153 Train Loss 0.0011945011 Test MSE 1.0239433426845595e-05 Test RE 0.0023184921564960346\n",
      "154 Train Loss 0.0011900815 Test MSE 1.047932394964146e-05 Test RE 0.0023454938613862333\n",
      "155 Train Loss 0.0011822503 Test MSE 1.066596970349437e-05 Test RE 0.002366289303285787\n",
      "156 Train Loss 0.0011916893 Test MSE 1.0344677049168926e-05 Test RE 0.0023303767361108657\n",
      "157 Train Loss 0.0011561636 Test MSE 9.686087597236751e-06 Test RE 0.00225497568754069\n",
      "158 Train Loss 0.0011407632 Test MSE 9.312984834422087e-06 Test RE 0.0022111189951946157\n",
      "159 Train Loss 0.0011219806 Test MSE 8.990642934688521e-06 Test RE 0.002172516295182431\n",
      "160 Train Loss 0.0010992048 Test MSE 8.918423713343254e-06 Test RE 0.00216377310595412\n",
      "161 Train Loss 0.0010966152 Test MSE 8.83480122548847e-06 Test RE 0.0021536050405632262\n",
      "162 Train Loss 0.0010814352 Test MSE 8.703532597793064e-06 Test RE 0.0021375458929515675\n",
      "163 Train Loss 0.001069221 Test MSE 8.892806576800444e-06 Test RE 0.0021606632776942137\n",
      "164 Train Loss 0.0010692676 Test MSE 8.877596857609536e-06 Test RE 0.0021588147529780365\n",
      "165 Train Loss 0.0010484769 Test MSE 8.935548964551065e-06 Test RE 0.0021658495595864367\n",
      "166 Train Loss 0.0010502455 Test MSE 8.565792805083898e-06 Test RE 0.0021205643220773007\n",
      "167 Train Loss 0.0010350199 Test MSE 8.568560321720452e-06 Test RE 0.0021209068603117586\n",
      "168 Train Loss 0.0010352122 Test MSE 8.632048671057839e-06 Test RE 0.002128749739649468\n",
      "169 Train Loss 0.001014765 Test MSE 7.788125411757282e-06 Test RE 0.0020220138956247025\n",
      "170 Train Loss 0.0010046047 Test MSE 7.389727281007246e-06 Test RE 0.001969617404048923\n",
      "171 Train Loss 0.0010092726 Test MSE 6.911230103105397e-06 Test RE 0.0019047822877006424\n",
      "172 Train Loss 0.0009871683 Test MSE 7.058566188181599e-06 Test RE 0.0019249786334923954\n",
      "173 Train Loss 0.0009663458 Test MSE 7.2731856054531e-06 Test RE 0.001954024491979088\n",
      "174 Train Loss 0.0009522043 Test MSE 7.10329649552726e-06 Test RE 0.0019310683195520747\n",
      "175 Train Loss 0.0009358993 Test MSE 6.945150370856895e-06 Test RE 0.0019094508952387957\n",
      "176 Train Loss 0.0009299606 Test MSE 6.798058730928318e-06 Test RE 0.0018891225137836407\n",
      "177 Train Loss 0.00091054116 Test MSE 6.783825826609446e-06 Test RE 0.001887143876255832\n",
      "178 Train Loss 0.00089738413 Test MSE 6.8097732800266604e-06 Test RE 0.0018907494997890753\n",
      "179 Train Loss 0.00088947115 Test MSE 6.679441620885033e-06 Test RE 0.0018725686438769492\n",
      "180 Train Loss 0.00087099185 Test MSE 6.650691761801462e-06 Test RE 0.0018685343141051178\n",
      "181 Train Loss 0.00086710445 Test MSE 6.571072035265942e-06 Test RE 0.001857315921806791\n",
      "182 Train Loss 0.00085871987 Test MSE 6.429102088453077e-06 Test RE 0.0018371424345016917\n",
      "183 Train Loss 0.0008379822 Test MSE 5.9100149001288545e-06 Test RE 0.001761416075322364\n",
      "184 Train Loss 0.00082580565 Test MSE 5.932351759739413e-06 Test RE 0.001764741565932199\n",
      "185 Train Loss 0.00082221633 Test MSE 5.979708598376305e-06 Test RE 0.0017717713629961062\n",
      "186 Train Loss 0.00081535085 Test MSE 5.848253597480553e-06 Test RE 0.00175218825927396\n",
      "187 Train Loss 0.0007985099 Test MSE 5.598133027824916e-06 Test RE 0.0017143096697115909\n",
      "188 Train Loss 0.0007850813 Test MSE 5.588948384933605e-06 Test RE 0.0017129027912457279\n",
      "189 Train Loss 0.0007812732 Test MSE 5.34052077052359e-06 Test RE 0.0016744009891421303\n",
      "190 Train Loss 0.00076841033 Test MSE 4.895840015292914e-06 Test RE 0.0016031762722101145\n",
      "191 Train Loss 0.0007645603 Test MSE 4.923029212953452e-06 Test RE 0.0016076217530223613\n",
      "192 Train Loss 0.00075862644 Test MSE 5.049653461811252e-06 Test RE 0.0016281651521663212\n",
      "193 Train Loss 0.00074456853 Test MSE 4.796078692471731e-06 Test RE 0.001586758442770411\n",
      "194 Train Loss 0.0007386756 Test MSE 4.79606879278086e-06 Test RE 0.0015867568051381729\n",
      "195 Train Loss 0.0007351102 Test MSE 4.677198824176839e-06 Test RE 0.001566969645264699\n",
      "196 Train Loss 0.0007302828 Test MSE 4.508457526351918e-06 Test RE 0.001538443881589993\n",
      "197 Train Loss 0.00073013484 Test MSE 4.259905809539845e-06 Test RE 0.001495435430508115\n",
      "198 Train Loss 0.0007179064 Test MSE 4.140256441965024e-06 Test RE 0.0014742844621950318\n",
      "199 Train Loss 0.00071016076 Test MSE 4.157524235234598e-06 Test RE 0.0014773556669376\n",
      "200 Train Loss 0.00070057856 Test MSE 4.072494012278695e-06 Test RE 0.0014621700869530102\n",
      "201 Train Loss 0.00068748574 Test MSE 4.093938191675794e-06 Test RE 0.001466014643875264\n",
      "202 Train Loss 0.0006801223 Test MSE 4.052444427721344e-06 Test RE 0.001458566389366146\n",
      "203 Train Loss 0.0006732399 Test MSE 4.019545515489928e-06 Test RE 0.001452633792961782\n",
      "204 Train Loss 0.0006751093 Test MSE 3.976951673215878e-06 Test RE 0.0014449167461627094\n",
      "205 Train Loss 0.0006700687 Test MSE 3.845014848770004e-06 Test RE 0.0014207467730535327\n",
      "206 Train Loss 0.00066266203 Test MSE 3.855077130094675e-06 Test RE 0.0014226045829044643\n",
      "207 Train Loss 0.0006538507 Test MSE 3.852764443911986e-06 Test RE 0.0014221778039544986\n",
      "208 Train Loss 0.00064799766 Test MSE 3.845888996268382e-06 Test RE 0.0014209082641929449\n",
      "209 Train Loss 0.00064410246 Test MSE 3.93346895806764e-06 Test RE 0.0014369959073438211\n",
      "210 Train Loss 0.0006467613 Test MSE 3.8304245447491175e-06 Test RE 0.0014180486261969837\n",
      "211 Train Loss 0.00064818293 Test MSE 3.6571442975039e-06 Test RE 0.0013856026836514823\n",
      "212 Train Loss 0.0006406542 Test MSE 3.4568558809721295e-06 Test RE 0.001347126267750512\n",
      "213 Train Loss 0.0006373951 Test MSE 3.105717770512016e-06 Test RE 0.0012768758149772003\n",
      "214 Train Loss 0.0006337132 Test MSE 3.051016224891582e-06 Test RE 0.0012655809418219337\n",
      "215 Train Loss 0.00062398385 Test MSE 3.030790095784698e-06 Test RE 0.0012613790027338628\n",
      "216 Train Loss 0.00063008576 Test MSE 3.0088258343574426e-06 Test RE 0.001256800058746\n",
      "217 Train Loss 0.0006258307 Test MSE 2.908063716072001e-06 Test RE 0.0012355764626145736\n",
      "218 Train Loss 0.0006186823 Test MSE 2.841867249018632e-06 Test RE 0.0012214327520125474\n",
      "219 Train Loss 0.00061177113 Test MSE 2.8287226311463763e-06 Test RE 0.0012186047038100255\n",
      "220 Train Loss 0.0006060826 Test MSE 2.840088937526116e-06 Test RE 0.0012210505336302776\n",
      "221 Train Loss 0.00060175115 Test MSE 2.789184667959807e-06 Test RE 0.0012100583205023998\n",
      "222 Train Loss 0.0005904132 Test MSE 2.6967032590434367e-06 Test RE 0.0011898281719728394\n",
      "223 Train Loss 0.000585291 Test MSE 2.7559143046303886e-06 Test RE 0.0012028196715296563\n",
      "224 Train Loss 0.0005748069 Test MSE 2.6423665537420106e-06 Test RE 0.0011777800655667046\n",
      "225 Train Loss 0.0005702922 Test MSE 2.772544997825489e-06 Test RE 0.0012064434484472947\n",
      "226 Train Loss 0.00057285355 Test MSE 2.4987132537183187e-06 Test RE 0.0011453174505055704\n",
      "227 Train Loss 0.00056484673 Test MSE 2.4079038510915125e-06 Test RE 0.0011243130156207985\n",
      "228 Train Loss 0.00056462013 Test MSE 2.35009879861332e-06 Test RE 0.00111073569283687\n",
      "229 Train Loss 0.0005589292 Test MSE 2.291626482501158e-06 Test RE 0.0010968306649224446\n",
      "230 Train Loss 0.0005555575 Test MSE 2.1820995738142924e-06 Test RE 0.001070298581612094\n",
      "231 Train Loss 0.00055341015 Test MSE 2.191244688611068e-06 Test RE 0.001072539031506892\n",
      "232 Train Loss 0.00055171025 Test MSE 2.183028874595591e-06 Test RE 0.0010705264638420694\n",
      "233 Train Loss 0.00054527493 Test MSE 2.1891904056634135e-06 Test RE 0.001072036163138826\n",
      "234 Train Loss 0.0005435053 Test MSE 2.2519652214571697e-06 Test RE 0.0010872977948016686\n",
      "235 Train Loss 0.0005438029 Test MSE 2.189833989065165e-06 Test RE 0.00107219373142947\n",
      "236 Train Loss 0.0005377841 Test MSE 2.2061536447586947e-06 Test RE 0.0010761815572303656\n",
      "237 Train Loss 0.0005334579 Test MSE 2.1595841867968865e-06 Test RE 0.0010647624749022622\n",
      "238 Train Loss 0.00053593784 Test MSE 2.19080478356847e-06 Test RE 0.0010724313668966623\n",
      "239 Train Loss 0.00053023914 Test MSE 2.105286234177504e-06 Test RE 0.0010512917178506437\n",
      "240 Train Loss 0.00052409683 Test MSE 2.083194118730081e-06 Test RE 0.0010457612325436372\n",
      "241 Train Loss 0.00051771285 Test MSE 2.0746602610427633e-06 Test RE 0.0010436170406134062\n",
      "242 Train Loss 0.0005190094 Test MSE 2.0852846631302158e-06 Test RE 0.001046285826498407\n",
      "243 Train Loss 0.0005179894 Test MSE 2.128983712490532e-06 Test RE 0.0010571919246491802\n",
      "244 Train Loss 0.0005122231 Test MSE 2.0823835823558247e-06 Test RE 0.0010455577685515765\n",
      "245 Train Loss 0.0005121621 Test MSE 2.0906350987930405e-06 Test RE 0.0010476272497577973\n",
      "246 Train Loss 0.00052166195 Test MSE 2.0884334380965064e-06 Test RE 0.0010470754730957108\n",
      "247 Train Loss 0.00051231025 Test MSE 2.0843801308310897e-06 Test RE 0.0010460588785922269\n",
      "248 Train Loss 0.00050849 Test MSE 2.044614271538646e-06 Test RE 0.0010360324577435279\n",
      "249 Train Loss 0.00050422346 Test MSE 1.9974339451157957e-06 Test RE 0.001024009252444571\n",
      "250 Train Loss 0.00049533613 Test MSE 1.93210473256208e-06 Test RE 0.0010071241260634438\n",
      "251 Train Loss 0.00049563695 Test MSE 1.9741219079931807e-06 Test RE 0.001018016112361442\n",
      "252 Train Loss 0.0004904927 Test MSE 1.9872842385138985e-06 Test RE 0.0010214042525835592\n",
      "253 Train Loss 0.00048492567 Test MSE 1.8341472185275318e-06 Test RE 0.0009812615087608147\n",
      "254 Train Loss 0.00047781944 Test MSE 1.8641887838369615e-06 Test RE 0.0009892649291075228\n",
      "255 Train Loss 0.00047410105 Test MSE 1.8213950122048271e-06 Test RE 0.000977844368868898\n",
      "256 Train Loss 0.00046837266 Test MSE 1.8712686568351266e-06 Test RE 0.0009911416791556233\n",
      "257 Train Loss 0.0004638875 Test MSE 1.713203475724582e-06 Test RE 0.0009483576264963046\n",
      "258 Train Loss 0.00045916322 Test MSE 1.6215916872805967e-06 Test RE 0.0009226530513086377\n",
      "259 Train Loss 0.00045378663 Test MSE 1.5490384300268994e-06 Test RE 0.0009017761890471794\n",
      "260 Train Loss 0.000453685 Test MSE 1.5530327638498059e-06 Test RE 0.0009029380956969121\n",
      "261 Train Loss 0.00044887894 Test MSE 1.4823183524302564e-06 Test RE 0.0008821418182411047\n",
      "262 Train Loss 0.00044727285 Test MSE 1.438644625892518e-06 Test RE 0.0008690493348630498\n",
      "263 Train Loss 0.00044429078 Test MSE 1.4137494559662336e-06 Test RE 0.0008614972452119927\n",
      "264 Train Loss 0.00044092507 Test MSE 1.4033760909203463e-06 Test RE 0.0008583308146679532\n",
      "265 Train Loss 0.00043655428 Test MSE 1.3902661272876665e-06 Test RE 0.000854312259270145\n",
      "266 Train Loss 0.00043265903 Test MSE 1.3916646069920396e-06 Test RE 0.0008547418310025518\n",
      "267 Train Loss 0.00042867713 Test MSE 1.3832357448579031e-06 Test RE 0.0008521494524180913\n",
      "268 Train Loss 0.00042767535 Test MSE 1.397371463633565e-06 Test RE 0.0008564925755991004\n",
      "269 Train Loss 0.00042559297 Test MSE 1.3977044495037658e-06 Test RE 0.0008565946182358163\n",
      "270 Train Loss 0.0004236217 Test MSE 1.401952651385466e-06 Test RE 0.0008578954032365294\n",
      "271 Train Loss 0.00042246273 Test MSE 1.3725558158424466e-06 Test RE 0.0008488533654025729\n",
      "272 Train Loss 0.000423996 Test MSE 1.3804938432903823e-06 Test RE 0.0008513044522233056\n",
      "273 Train Loss 0.00042440227 Test MSE 1.381467932528259e-06 Test RE 0.0008516047434124624\n",
      "274 Train Loss 0.00042323783 Test MSE 1.3761391320449225e-06 Test RE 0.0008499606891741315\n",
      "275 Train Loss 0.00042064342 Test MSE 1.3737332180962146e-06 Test RE 0.0008492173679484937\n",
      "276 Train Loss 0.00041705754 Test MSE 1.363857609628151e-06 Test RE 0.0008461593997042243\n",
      "277 Train Loss 0.00041504583 Test MSE 1.3625241257430783e-06 Test RE 0.0008457456410194928\n",
      "278 Train Loss 0.00041588774 Test MSE 1.318821926195439e-06 Test RE 0.0008320716920641012\n",
      "279 Train Loss 0.00041541585 Test MSE 1.305058826860239e-06 Test RE 0.0008277185949009153\n",
      "280 Train Loss 0.0004171471 Test MSE 1.305196712822584e-06 Test RE 0.0008277623200411918\n",
      "281 Train Loss 0.0004160149 Test MSE 1.3011239086354717e-06 Test RE 0.00082646981450262\n",
      "282 Train Loss 0.0004162397 Test MSE 1.26974018934822e-06 Test RE 0.0008164415539067084\n",
      "283 Train Loss 0.00041228946 Test MSE 1.192723925376479e-06 Test RE 0.0007912935635840966\n",
      "284 Train Loss 0.0004123823 Test MSE 1.1833969929580765e-06 Test RE 0.0007881935894697601\n",
      "285 Train Loss 0.00041127403 Test MSE 1.1740851441158718e-06 Test RE 0.0007850864179396527\n",
      "286 Train Loss 0.00041189368 Test MSE 1.1663221496931422e-06 Test RE 0.0007824866366145362\n",
      "287 Train Loss 0.00041067484 Test MSE 1.1617240149790597e-06 Test RE 0.0007809426668957242\n",
      "288 Train Loss 0.00041012673 Test MSE 1.1617240149790597e-06 Test RE 0.0007809426668957242\n",
      "289 Train Loss 0.00041134265 Test MSE 1.1617674476393333e-06 Test RE 0.000780957265070545\n",
      "290 Train Loss 0.00041214784 Test MSE 1.1611747804087523e-06 Test RE 0.0007807580398189243\n",
      "291 Train Loss 0.00041220651 Test MSE 1.1796046296274306e-06 Test RE 0.0007869296370131282\n",
      "292 Train Loss 0.00041115127 Test MSE 1.1754650144753942e-06 Test RE 0.000785547627832187\n",
      "293 Train Loss 0.00041066422 Test MSE 1.169132935714643e-06 Test RE 0.0007834289487273844\n",
      "294 Train Loss 0.0004085952 Test MSE 1.16816529263079e-06 Test RE 0.000783104675711241\n",
      "295 Train Loss 0.00040850719 Test MSE 1.1749089574942496e-06 Test RE 0.0007853618031127033\n",
      "296 Train Loss 0.00040562593 Test MSE 1.1639883757212696e-06 Test RE 0.0007817033790140886\n",
      "297 Train Loss 0.0004038972 Test MSE 1.1639883757212696e-06 Test RE 0.0007817033790140886\n",
      "298 Train Loss 0.00040471114 Test MSE 1.1668824416237033e-06 Test RE 0.0007826745642413664\n",
      "299 Train Loss 0.0004038808 Test MSE 1.1638768006901731e-06 Test RE 0.0007816659127168113\n",
      "Training time: 160.25\n",
      "KG_stanALR_medium\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "200 Train Loss nan Test MSE nan Test RE nan\n",
      "201 Train Loss nan Test MSE nan Test RE nan\n",
      "202 Train Loss nan Test MSE nan Test RE nan\n",
      "203 Train Loss nan Test MSE nan Test RE nan\n",
      "204 Train Loss nan Test MSE nan Test RE nan\n",
      "205 Train Loss nan Test MSE nan Test RE nan\n",
      "206 Train Loss nan Test MSE nan Test RE nan\n",
      "207 Train Loss nan Test MSE nan Test RE nan\n",
      "208 Train Loss nan Test MSE nan Test RE nan\n",
      "209 Train Loss nan Test MSE nan Test RE nan\n",
      "210 Train Loss nan Test MSE nan Test RE nan\n",
      "211 Train Loss nan Test MSE nan Test RE nan\n",
      "212 Train Loss nan Test MSE nan Test RE nan\n",
      "213 Train Loss nan Test MSE nan Test RE nan\n",
      "214 Train Loss nan Test MSE nan Test RE nan\n",
      "215 Train Loss nan Test MSE nan Test RE nan\n",
      "216 Train Loss nan Test MSE nan Test RE nan\n",
      "217 Train Loss nan Test MSE nan Test RE nan\n",
      "218 Train Loss nan Test MSE nan Test RE nan\n",
      "219 Train Loss nan Test MSE nan Test RE nan\n",
      "220 Train Loss nan Test MSE nan Test RE nan\n",
      "221 Train Loss nan Test MSE nan Test RE nan\n",
      "222 Train Loss nan Test MSE nan Test RE nan\n",
      "223 Train Loss nan Test MSE nan Test RE nan\n",
      "224 Train Loss nan Test MSE nan Test RE nan\n",
      "225 Train Loss nan Test MSE nan Test RE nan\n",
      "226 Train Loss nan Test MSE nan Test RE nan\n",
      "227 Train Loss nan Test MSE nan Test RE nan\n",
      "228 Train Loss nan Test MSE nan Test RE nan\n",
      "229 Train Loss nan Test MSE nan Test RE nan\n",
      "230 Train Loss nan Test MSE nan Test RE nan\n",
      "231 Train Loss nan Test MSE nan Test RE nan\n",
      "232 Train Loss nan Test MSE nan Test RE nan\n",
      "233 Train Loss nan Test MSE nan Test RE nan\n",
      "234 Train Loss nan Test MSE nan Test RE nan\n",
      "235 Train Loss nan Test MSE nan Test RE nan\n",
      "236 Train Loss nan Test MSE nan Test RE nan\n",
      "237 Train Loss nan Test MSE nan Test RE nan\n",
      "238 Train Loss nan Test MSE nan Test RE nan\n",
      "239 Train Loss nan Test MSE nan Test RE nan\n",
      "240 Train Loss nan Test MSE nan Test RE nan\n",
      "241 Train Loss nan Test MSE nan Test RE nan\n",
      "242 Train Loss nan Test MSE nan Test RE nan\n",
      "243 Train Loss nan Test MSE nan Test RE nan\n",
      "244 Train Loss nan Test MSE nan Test RE nan\n",
      "245 Train Loss nan Test MSE nan Test RE nan\n",
      "246 Train Loss nan Test MSE nan Test RE nan\n",
      "247 Train Loss nan Test MSE nan Test RE nan\n",
      "248 Train Loss nan Test MSE nan Test RE nan\n",
      "249 Train Loss nan Test MSE nan Test RE nan\n",
      "250 Train Loss nan Test MSE nan Test RE nan\n",
      "251 Train Loss nan Test MSE nan Test RE nan\n",
      "252 Train Loss nan Test MSE nan Test RE nan\n",
      "253 Train Loss nan Test MSE nan Test RE nan\n",
      "254 Train Loss nan Test MSE nan Test RE nan\n",
      "255 Train Loss nan Test MSE nan Test RE nan\n",
      "256 Train Loss nan Test MSE nan Test RE nan\n",
      "257 Train Loss nan Test MSE nan Test RE nan\n",
      "258 Train Loss nan Test MSE nan Test RE nan\n",
      "259 Train Loss nan Test MSE nan Test RE nan\n",
      "260 Train Loss nan Test MSE nan Test RE nan\n",
      "261 Train Loss nan Test MSE nan Test RE nan\n",
      "262 Train Loss nan Test MSE nan Test RE nan\n",
      "263 Train Loss nan Test MSE nan Test RE nan\n",
      "264 Train Loss nan Test MSE nan Test RE nan\n",
      "265 Train Loss nan Test MSE nan Test RE nan\n",
      "266 Train Loss nan Test MSE nan Test RE nan\n",
      "267 Train Loss nan Test MSE nan Test RE nan\n",
      "268 Train Loss nan Test MSE nan Test RE nan\n",
      "269 Train Loss nan Test MSE nan Test RE nan\n",
      "270 Train Loss nan Test MSE nan Test RE nan\n",
      "271 Train Loss nan Test MSE nan Test RE nan\n",
      "272 Train Loss nan Test MSE nan Test RE nan\n",
      "273 Train Loss nan Test MSE nan Test RE nan\n",
      "274 Train Loss nan Test MSE nan Test RE nan\n",
      "275 Train Loss nan Test MSE nan Test RE nan\n",
      "276 Train Loss nan Test MSE nan Test RE nan\n",
      "277 Train Loss nan Test MSE nan Test RE nan\n",
      "278 Train Loss nan Test MSE nan Test RE nan\n",
      "279 Train Loss nan Test MSE nan Test RE nan\n",
      "280 Train Loss nan Test MSE nan Test RE nan\n",
      "281 Train Loss nan Test MSE nan Test RE nan\n",
      "282 Train Loss nan Test MSE nan Test RE nan\n",
      "283 Train Loss nan Test MSE nan Test RE nan\n",
      "284 Train Loss nan Test MSE nan Test RE nan\n",
      "285 Train Loss nan Test MSE nan Test RE nan\n",
      "286 Train Loss nan Test MSE nan Test RE nan\n",
      "287 Train Loss nan Test MSE nan Test RE nan\n",
      "288 Train Loss nan Test MSE nan Test RE nan\n",
      "289 Train Loss nan Test MSE nan Test RE nan\n",
      "290 Train Loss nan Test MSE nan Test RE nan\n",
      "291 Train Loss nan Test MSE nan Test RE nan\n",
      "292 Train Loss nan Test MSE nan Test RE nan\n",
      "293 Train Loss nan Test MSE nan Test RE nan\n",
      "294 Train Loss nan Test MSE nan Test RE nan\n",
      "295 Train Loss nan Test MSE nan Test RE nan\n",
      "296 Train Loss nan Test MSE nan Test RE nan\n",
      "297 Train Loss nan Test MSE nan Test RE nan\n",
      "298 Train Loss nan Test MSE nan Test RE nan\n",
      "299 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 16.34\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd2303e9610>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.0006755557999266505\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
