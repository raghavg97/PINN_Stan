{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"medium\"\n",
    "label = \"KG_rowdy_\" + level\n",
    "\n",
    "x = np.linspace(0,2,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,rowdy_terms,n_val):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "        \n",
    "        self.omega1 = Parameter(torch.ones((len(layers)-2,1))) \n",
    "        self.omega1.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.alpha = Parameter(torch.zeros(rowdy_terms,len(layers)-2))\n",
    "        self.alpha.requiresGrad = True\n",
    "        \n",
    "        \n",
    "        self.omega = Parameter((1/n_val)*torch.ones(rowdy_terms,len(layers)-2))\n",
    "        self.omega.requiresGrad = True\n",
    "        \n",
    "        self.n = torch.tensor(n_val)\n",
    "            \n",
    "\n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(self.omega1[i,0]*z)\n",
    "            for j in range(rowdy_terms):\n",
    "                a = a + self.alpha[j,i]*self.n*torch.sin((j+1)*self.n*self.omega[j,i]*z)\n",
    "                    \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_rowdy_medium\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 27277.727 Test MSE 2.6953268203578835 Test RE 1.1895244799457358\n",
      "1 Train Loss 3232.7952 Test MSE 2.455255913407958 Test RE 1.135314149418008\n",
      "2 Train Loss 511.49222 Test MSE 3.1922280863634667 Test RE 1.2945374680607984\n",
      "3 Train Loss 147.30666 Test MSE 3.1790098429177025 Test RE 1.291854504725403\n",
      "4 Train Loss 62.119507 Test MSE 2.2309809055807857 Test RE 1.0822200962506083\n",
      "5 Train Loss 29.840477 Test MSE 1.147433685505059 Test RE 0.7761246291938039\n",
      "6 Train Loss 16.568604 Test MSE 0.6818931452932969 Test RE 0.5983094054405874\n",
      "7 Train Loss 10.526774 Test MSE 0.4392068490367819 Test RE 0.4801779571237327\n",
      "8 Train Loss 7.1587725 Test MSE 0.36583864516807885 Test RE 0.43824044677503804\n",
      "9 Train Loss 5.178589 Test MSE 0.3332538898682598 Test RE 0.4182686179268932\n",
      "10 Train Loss 3.8085072 Test MSE 0.3127708171168608 Test RE 0.40521058353474415\n",
      "11 Train Loss 3.077721 Test MSE 0.2910468484318733 Test RE 0.3908851018679013\n",
      "12 Train Loss 2.377777 Test MSE 0.2840109368124824 Test RE 0.3861314712829256\n",
      "13 Train Loss 1.8890021 Test MSE 0.28752293159844333 Test RE 0.3885115295894674\n",
      "14 Train Loss 1.4989719 Test MSE 0.2573963265458441 Test RE 0.36759436045197663\n",
      "15 Train Loss 1.2323219 Test MSE 0.18811052924216898 Test RE 0.3142492286137492\n",
      "16 Train Loss 1.0435897 Test MSE 0.15971913611308636 Test RE 0.2895650512089736\n",
      "17 Train Loss 0.8717374 Test MSE 0.13429740236054805 Test RE 0.26552258889040864\n",
      "18 Train Loss 0.7309941 Test MSE 0.11111183803255394 Test RE 0.24151707123789581\n",
      "19 Train Loss 0.6296318 Test MSE 0.10422178236699735 Test RE 0.23390899106706914\n",
      "20 Train Loss 0.56468236 Test MSE 0.09702264737934309 Test RE 0.2256857966634579\n",
      "21 Train Loss 0.51615024 Test MSE 0.08998293511742077 Test RE 0.217344044871822\n",
      "22 Train Loss 0.46583784 Test MSE 0.08574267762640445 Test RE 0.21216131012127384\n",
      "23 Train Loss 0.41694105 Test MSE 0.07479415080140035 Test RE 0.19815338034797123\n",
      "24 Train Loss 0.37560955 Test MSE 0.06576192135550239 Test RE 0.1858039380018753\n",
      "25 Train Loss 0.34475282 Test MSE 0.056100793648565815 Test RE 0.1716137851247513\n",
      "26 Train Loss 0.31289577 Test MSE 0.045688588097395295 Test RE 0.15487151127823648\n",
      "27 Train Loss 0.2859211 Test MSE 0.03769584766654741 Test RE 0.14067419043605336\n",
      "28 Train Loss 0.26607254 Test MSE 0.03182559745656486 Test RE 0.12925755906193895\n",
      "29 Train Loss 0.2513213 Test MSE 0.02711350800751871 Test RE 0.1193055159592675\n",
      "30 Train Loss 0.21896109 Test MSE 0.02172111926633124 Test RE 0.10678463505603455\n",
      "31 Train Loss 0.20339109 Test MSE 0.02049280747509506 Test RE 0.10372140657453312\n",
      "32 Train Loss 0.18563683 Test MSE 0.018930273980787192 Test RE 0.09968874243822674\n",
      "33 Train Loss 0.1772304 Test MSE 0.016505318207612335 Test RE 0.09308498185408921\n",
      "34 Train Loss 0.15621792 Test MSE 0.017336354396262296 Test RE 0.09539960046049871\n",
      "35 Train Loss 0.1444769 Test MSE 0.01506007147207555 Test RE 0.08891625939090861\n",
      "36 Train Loss 0.12583463 Test MSE 0.013532712695993186 Test RE 0.0842869033665989\n",
      "37 Train Loss 0.11734319 Test MSE 0.011823001413766994 Test RE 0.07878282294893502\n",
      "38 Train Loss 0.10875216 Test MSE 0.010975529418743508 Test RE 0.07590675166550544\n",
      "39 Train Loss 0.103283785 Test MSE 0.010858171940885153 Test RE 0.07549983889225946\n",
      "40 Train Loss 0.098422915 Test MSE 0.010716090199964902 Test RE 0.07500424571542319\n",
      "41 Train Loss 0.0960554 Test MSE 0.010661551886322602 Test RE 0.07481313949319293\n",
      "42 Train Loss 0.09205647 Test MSE 0.010304458319821644 Test RE 0.07354958915293484\n",
      "43 Train Loss 0.08875342 Test MSE 0.009826233066042316 Test RE 0.07182261247028675\n",
      "44 Train Loss 0.08493318 Test MSE 0.009811871276313862 Test RE 0.07177010616236294\n",
      "45 Train Loss 0.08208803 Test MSE 0.009923824301485256 Test RE 0.07217839173279057\n",
      "46 Train Loss 0.08041247 Test MSE 0.009622215979963896 Test RE 0.0710730933820795\n",
      "47 Train Loss 0.076491885 Test MSE 0.009091499892478944 Test RE 0.06908526639973468\n",
      "48 Train Loss 0.073217034 Test MSE 0.008538197782404828 Test RE 0.06695002954948803\n",
      "49 Train Loss 0.06908601 Test MSE 0.008763524741014538 Test RE 0.067827697745831\n",
      "50 Train Loss 0.06795911 Test MSE 0.008864008831348715 Test RE 0.0682154514576981\n",
      "51 Train Loss 0.06679256 Test MSE 0.00896212397806689 Test RE 0.06859194870313023\n",
      "52 Train Loss 0.06422347 Test MSE 0.00885880895727067 Test RE 0.06819543998203757\n",
      "53 Train Loss 0.0628515 Test MSE 0.009703223661528664 Test RE 0.0713716420482666\n",
      "54 Train Loss 0.061311882 Test MSE 0.01019317726296823 Test RE 0.07315136863988289\n",
      "55 Train Loss 0.060525775 Test MSE 0.01063381823984885 Test RE 0.07471577129336401\n",
      "56 Train Loss 0.059407383 Test MSE 0.01058001453188361 Test RE 0.0745265126793627\n",
      "57 Train Loss 0.05709789 Test MSE 0.010386487063811503 Test RE 0.07384175497997943\n",
      "58 Train Loss 0.05592517 Test MSE 0.010705358945143347 Test RE 0.07496668111552805\n",
      "59 Train Loss 0.054762688 Test MSE 0.010465465718447264 Test RE 0.07412196896967277\n",
      "60 Train Loss 0.05245763 Test MSE 0.0101259610557573 Test RE 0.07290978104871995\n",
      "61 Train Loss 0.049956 Test MSE 0.009211405484693064 Test RE 0.06953934854011493\n",
      "62 Train Loss 0.04853277 Test MSE 0.008450904562316234 Test RE 0.06660690688882424\n",
      "63 Train Loss 0.047343124 Test MSE 0.007982141176015123 Test RE 0.06473324377067223\n",
      "64 Train Loss 0.04601166 Test MSE 0.0076026512066302825 Test RE 0.06317572010031\n",
      "65 Train Loss 0.04384471 Test MSE 0.0070574601673300385 Test RE 0.06086839993379294\n",
      "66 Train Loss 0.042115394 Test MSE 0.007386631678593394 Test RE 0.06227172405478041\n",
      "67 Train Loss 0.041247204 Test MSE 0.007179584137032588 Test RE 0.06139278179288936\n",
      "68 Train Loss 0.040450335 Test MSE 0.007208322936475242 Test RE 0.0615155321306835\n",
      "69 Train Loss 0.039001383 Test MSE 0.00702461773889046 Test RE 0.060726606912623576\n",
      "70 Train Loss 0.037667114 Test MSE 0.007100969902077911 Test RE 0.06105574060336726\n",
      "71 Train Loss 0.03710332 Test MSE 0.007290804945774553 Test RE 0.06186648008763604\n",
      "72 Train Loss 0.036212694 Test MSE 0.0071548657369742445 Test RE 0.061287006880825466\n",
      "73 Train Loss 0.035501167 Test MSE 0.007168206032183907 Test RE 0.0613441152913962\n",
      "74 Train Loss 0.034593705 Test MSE 0.007047018921706569 Test RE 0.06082335701902973\n",
      "75 Train Loss 0.034166258 Test MSE 0.007086158991184553 Test RE 0.060992033590678375\n",
      "76 Train Loss 0.03348971 Test MSE 0.007111913617483761 Test RE 0.06110277075664461\n",
      "77 Train Loss 0.032611176 Test MSE 0.006843359430146041 Test RE 0.05993801320252774\n",
      "78 Train Loss 0.032008894 Test MSE 0.006845847137532387 Test RE 0.05994890658692056\n",
      "79 Train Loss 0.031404953 Test MSE 0.007069500723604849 Test RE 0.060920300833882564\n",
      "80 Train Loss 0.030855834 Test MSE 0.007327884549111257 Test RE 0.062023600958587694\n",
      "81 Train Loss 0.030143574 Test MSE 0.007203431635581477 Test RE 0.0614946575083451\n",
      "82 Train Loss 0.029445978 Test MSE 0.0070463818154129 Test RE 0.06082060750041222\n",
      "83 Train Loss 0.028825998 Test MSE 0.006840506830340229 Test RE 0.05992551955901041\n",
      "84 Train Loss 0.02834475 Test MSE 0.006708438357383351 Test RE 0.059344214314151475\n",
      "85 Train Loss 0.027854009 Test MSE 0.006778806166776736 Test RE 0.05965464637153943\n",
      "86 Train Loss 0.027226582 Test MSE 0.006695171460775538 Test RE 0.05928550443598802\n",
      "87 Train Loss 0.026243621 Test MSE 0.007085494616402022 Test RE 0.060989174318191015\n",
      "88 Train Loss 0.025653152 Test MSE 0.007201395338910761 Test RE 0.061485965108426265\n",
      "89 Train Loss 0.025107775 Test MSE 0.007164309435782795 Test RE 0.06132743986724433\n",
      "90 Train Loss 0.02476638 Test MSE 0.007163109335681786 Test RE 0.06132230314402914\n",
      "91 Train Loss 0.02425127 Test MSE 0.00721856399739196 Test RE 0.0615592150176228\n",
      "92 Train Loss 0.023688229 Test MSE 0.007046516668524112 Test RE 0.06082118948767323\n",
      "93 Train Loss 0.023245532 Test MSE 0.006954921271867237 Test RE 0.060424598974790064\n",
      "94 Train Loss 0.02292639 Test MSE 0.00696429700104792 Test RE 0.060465313589189246\n",
      "95 Train Loss 0.021950524 Test MSE 0.006873166435329793 Test RE 0.06006840467985588\n",
      "96 Train Loss 0.020890774 Test MSE 0.006587535078388788 Test RE 0.05880701534722819\n",
      "97 Train Loss 0.02030544 Test MSE 0.0065112347781453375 Test RE 0.05846545652850686\n",
      "98 Train Loss 0.019543033 Test MSE 0.006238444713710728 Test RE 0.057227639536024784\n",
      "99 Train Loss 0.019290296 Test MSE 0.005971880809851791 Test RE 0.05599164581037023\n",
      "100 Train Loss 0.018876543 Test MSE 0.005791482360738934 Test RE 0.05513946355826929\n",
      "101 Train Loss 0.018460177 Test MSE 0.005357460375718087 Test RE 0.05303311677030065\n",
      "102 Train Loss 0.018131543 Test MSE 0.005136906560030468 Test RE 0.051930021291066615\n",
      "103 Train Loss 0.017870642 Test MSE 0.00507373496540475 Test RE 0.05160972635459964\n",
      "104 Train Loss 0.017554874 Test MSE 0.004850093513896665 Test RE 0.050459474551048905\n",
      "105 Train Loss 0.017081898 Test MSE 0.004535449720785941 Test RE 0.048795283551064154\n",
      "106 Train Loss 0.016761098 Test MSE 0.004348207452704511 Test RE 0.04777743118981471\n",
      "107 Train Loss 0.01629856 Test MSE 0.00417941940477393 Test RE 0.04684094465600819\n",
      "108 Train Loss 0.016022647 Test MSE 0.004044791611725345 Test RE 0.04608034728078142\n",
      "109 Train Loss 0.015503007 Test MSE 0.0035874766136490066 Test RE 0.04339724969874844\n",
      "110 Train Loss 0.015036798 Test MSE 0.0032827423536995293 Test RE 0.04151318614699297\n",
      "111 Train Loss 0.014663039 Test MSE 0.0031267725242297498 Test RE 0.0405149970079165\n",
      "112 Train Loss 0.014453645 Test MSE 0.00293518908820164 Test RE 0.03925416193763178\n",
      "113 Train Loss 0.014229023 Test MSE 0.0026794314444947166 Test RE 0.037504984690068036\n",
      "114 Train Loss 0.014002827 Test MSE 0.0025820897222884774 Test RE 0.0368174183335432\n",
      "115 Train Loss 0.013865773 Test MSE 0.0025809254615621617 Test RE 0.036809116935865076\n",
      "116 Train Loss 0.013738504 Test MSE 0.0024614875950940587 Test RE 0.03594731798343307\n",
      "117 Train Loss 0.013621182 Test MSE 0.0024549570716165627 Test RE 0.03589960075803993\n",
      "118 Train Loss 0.01339826 Test MSE 0.002496501218187151 Test RE 0.03620208292168436\n",
      "119 Train Loss 0.013242097 Test MSE 0.002438333287012296 Test RE 0.03577784690718538\n",
      "120 Train Loss 0.0131854685 Test MSE 0.002433643197858876 Test RE 0.035743421330301256\n",
      "121 Train Loss 0.013126143 Test MSE 0.00235273229975384 Test RE 0.03514422130506758\n",
      "122 Train Loss 0.013033427 Test MSE 0.0023029029409647 Test RE 0.03477006358194152\n",
      "123 Train Loss 0.012917718 Test MSE 0.002269396540740388 Test RE 0.034516190869833936\n",
      "124 Train Loss 0.012707354 Test MSE 0.002194072125466602 Test RE 0.03393853704176045\n",
      "125 Train Loss 0.012478204 Test MSE 0.002120576819644157 Test RE 0.03336527222088632\n",
      "126 Train Loss 0.012339914 Test MSE 0.00201533045785198 Test RE 0.03252675974884341\n",
      "127 Train Loss 0.012226695 Test MSE 0.0019267520164376315 Test RE 0.0318039146084117\n",
      "128 Train Loss 0.012113257 Test MSE 0.001817902218816317 Test RE 0.030892490906320874\n",
      "129 Train Loss 0.011959789 Test MSE 0.0017217100719383012 Test RE 0.030064063336189627\n",
      "130 Train Loss 0.011864745 Test MSE 0.0016440187646495608 Test RE 0.029377920602438715\n",
      "131 Train Loss 0.011696847 Test MSE 0.001618836253193722 Test RE 0.029152051900806747\n",
      "132 Train Loss 0.011306971 Test MSE 0.0016104690985978942 Test RE 0.029076616314281364\n",
      "133 Train Loss 0.011065922 Test MSE 0.001529830186521226 Test RE 0.02833931057412381\n",
      "134 Train Loss 0.010898671 Test MSE 0.0015153238705781266 Test RE 0.02820462955334117\n",
      "135 Train Loss 0.010659123 Test MSE 0.001740681253531332 Test RE 0.030229244531786423\n",
      "136 Train Loss 0.010532611 Test MSE 0.0016652127865245117 Test RE 0.029566678311039228\n",
      "137 Train Loss 0.010360258 Test MSE 0.0015843642972821165 Test RE 0.02883999569932889\n",
      "138 Train Loss 0.010114735 Test MSE 0.001377499682055298 Test RE 0.026891400530230775\n",
      "139 Train Loss 0.009999578 Test MSE 0.0013194350884631028 Test RE 0.026318533263836246\n",
      "140 Train Loss 0.009886886 Test MSE 0.0011640632876061489 Test RE 0.02472042676272331\n",
      "141 Train Loss 0.00981643 Test MSE 0.0011440522138933757 Test RE 0.024507024817737623\n",
      "142 Train Loss 0.009722896 Test MSE 0.0010410444363367847 Test RE 0.02337772800481321\n",
      "143 Train Loss 0.009641511 Test MSE 0.0010390841769569814 Test RE 0.0233557078096053\n",
      "144 Train Loss 0.0095215915 Test MSE 0.0010893141355849394 Test RE 0.02391356017500697\n",
      "145 Train Loss 0.009423391 Test MSE 0.0011307289146387383 Test RE 0.024363906076969827\n",
      "146 Train Loss 0.009302866 Test MSE 0.0010911523931285167 Test RE 0.023933729174406084\n",
      "147 Train Loss 0.009233766 Test MSE 0.0010113523670695424 Test RE 0.023041933308136045\n",
      "148 Train Loss 0.009088458 Test MSE 0.0009238715304971056 Test RE 0.02202284690900814\n",
      "149 Train Loss 0.008956142 Test MSE 0.0008434474853806464 Test RE 0.021042468781847908\n",
      "150 Train Loss 0.008864491 Test MSE 0.0007935209171664144 Test RE 0.020410181053974776\n",
      "151 Train Loss 0.008820069 Test MSE 0.0007238054506791517 Test RE 0.019492995937817927\n",
      "152 Train Loss 0.008777342 Test MSE 0.0007142246539708677 Test RE 0.019363554682611108\n",
      "153 Train Loss 0.008696381 Test MSE 0.0007152938666963691 Test RE 0.019378043132597857\n",
      "154 Train Loss 0.008643286 Test MSE 0.0007160421047214198 Test RE 0.019388175750521486\n",
      "155 Train Loss 0.008588831 Test MSE 0.0007179016608268172 Test RE 0.019413334901842973\n",
      "156 Train Loss 0.0084983185 Test MSE 0.0007218712652432856 Test RE 0.019466933485208636\n",
      "157 Train Loss 0.008429871 Test MSE 0.0006815941007011407 Test RE 0.018916055479197346\n",
      "158 Train Loss 0.008286338 Test MSE 0.0006928370134619782 Test RE 0.01907142780045908\n",
      "159 Train Loss 0.008166319 Test MSE 0.0006648540541548616 Test RE 0.018682320933661636\n",
      "160 Train Loss 0.0080679245 Test MSE 0.0006984392063545987 Test RE 0.01914837714541837\n",
      "161 Train Loss 0.007942559 Test MSE 0.0007271721624017196 Test RE 0.01953827824404325\n",
      "162 Train Loss 0.007810461 Test MSE 0.0007407220494401345 Test RE 0.019719472986187023\n",
      "163 Train Loss 0.0074953716 Test MSE 0.0007269079074440009 Test RE 0.019534727808320468\n",
      "164 Train Loss 0.0073498692 Test MSE 0.0007234629382579227 Test RE 0.019488383245778205\n",
      "165 Train Loss 0.0072233733 Test MSE 0.0006565503493843476 Test RE 0.018565287798708627\n",
      "166 Train Loss 0.0071081095 Test MSE 0.0006402666641128036 Test RE 0.018333615248284203\n",
      "167 Train Loss 0.00704738 Test MSE 0.0006315604044534587 Test RE 0.018208539589965534\n",
      "168 Train Loss 0.0070044897 Test MSE 0.0006235194248835028 Test RE 0.01809225338917703\n",
      "169 Train Loss 0.006961243 Test MSE 0.0006110699073461652 Test RE 0.017910722952848655\n",
      "170 Train Loss 0.006901756 Test MSE 0.0006095461448209427 Test RE 0.017888377945366234\n",
      "171 Train Loss 0.0068622944 Test MSE 0.0005940807852416155 Test RE 0.017659988669826158\n",
      "172 Train Loss 0.006819437 Test MSE 0.000596958174929004 Test RE 0.01770270448369463\n",
      "173 Train Loss 0.0067566494 Test MSE 0.0005747674353187039 Test RE 0.01737055700542736\n",
      "174 Train Loss 0.0067068157 Test MSE 0.0005502636811170406 Test RE 0.01699624928257987\n",
      "175 Train Loss 0.006628003 Test MSE 0.0005407460536680227 Test RE 0.01684862044860584\n",
      "176 Train Loss 0.006550775 Test MSE 0.000526917757844648 Test RE 0.016631793540209917\n",
      "177 Train Loss 0.0064630103 Test MSE 0.0005367900892940858 Test RE 0.016786877146803967\n",
      "178 Train Loss 0.0063977772 Test MSE 0.0005553382049419797 Test RE 0.01707443901445646\n",
      "179 Train Loss 0.0063374406 Test MSE 0.0005503987209154164 Test RE 0.016998334673055657\n",
      "180 Train Loss 0.0062713786 Test MSE 0.000548486090151065 Test RE 0.016968774437801745\n",
      "181 Train Loss 0.0061769728 Test MSE 0.0005008397464958191 Test RE 0.016215004038544072\n",
      "182 Train Loss 0.0060847094 Test MSE 0.0004984927785077728 Test RE 0.016176967137739286\n",
      "183 Train Loss 0.006041992 Test MSE 0.0004963276705591047 Test RE 0.01614179812885156\n",
      "184 Train Loss 0.0059748 Test MSE 0.0005373618740330044 Test RE 0.01679581539441823\n",
      "185 Train Loss 0.0058948635 Test MSE 0.0006104571823849989 Test RE 0.0179017410840874\n",
      "186 Train Loss 0.0058191577 Test MSE 0.0006353069037202306 Test RE 0.018262467455583565\n",
      "187 Train Loss 0.005769846 Test MSE 0.0006333331841223011 Test RE 0.01823407721718729\n",
      "188 Train Loss 0.0057236804 Test MSE 0.0006548039898258469 Test RE 0.018540580435313418\n",
      "189 Train Loss 0.0056872456 Test MSE 0.0006861923665345976 Test RE 0.018979755299478124\n",
      "190 Train Loss 0.0056504137 Test MSE 0.0006819416032528233 Test RE 0.01892087692638577\n",
      "191 Train Loss 0.005633221 Test MSE 0.0006900325112382293 Test RE 0.019032789494346756\n",
      "192 Train Loss 0.0056042317 Test MSE 0.0007268041856096957 Test RE 0.019533334062246367\n",
      "193 Train Loss 0.005583808 Test MSE 0.0007093436703792444 Test RE 0.01929727636167035\n",
      "194 Train Loss 0.0055500986 Test MSE 0.000717928898151315 Test RE 0.019413703171144932\n",
      "195 Train Loss 0.005515354 Test MSE 0.0007022597849921104 Test RE 0.019200678123269702\n",
      "196 Train Loss 0.005467554 Test MSE 0.0007165112094804114 Test RE 0.01939452565390824\n",
      "197 Train Loss 0.005398914 Test MSE 0.000701441761470416 Test RE 0.019189491961625612\n",
      "198 Train Loss 0.0053818775 Test MSE 0.0007107733691690376 Test RE 0.01931671362888482\n",
      "199 Train Loss 0.0053431746 Test MSE 0.0006717750237977937 Test RE 0.018779308400686458\n",
      "200 Train Loss 0.0052913222 Test MSE 0.0006401429545074469 Test RE 0.018331843991087553\n",
      "201 Train Loss 0.0052190293 Test MSE 0.0006217872568707693 Test RE 0.01806710532094137\n",
      "202 Train Loss 0.0051578847 Test MSE 0.0005981481767805206 Test RE 0.017720340361598096\n",
      "203 Train Loss 0.005130898 Test MSE 0.0006113623035390813 Test RE 0.01791500756972548\n",
      "204 Train Loss 0.005090943 Test MSE 0.000566653506834653 Test RE 0.017247512090481695\n",
      "205 Train Loss 0.005032881 Test MSE 0.0005556974319492304 Test RE 0.01707996052188753\n",
      "206 Train Loss 0.0049444335 Test MSE 0.0005528189001088581 Test RE 0.017035665693285313\n",
      "207 Train Loss 0.004834748 Test MSE 0.00047316058131372906 Test RE 0.01576057093521531\n",
      "208 Train Loss 0.0047971387 Test MSE 0.0004647734157543869 Test RE 0.015620261754800854\n",
      "209 Train Loss 0.0047711474 Test MSE 0.00046200911566603896 Test RE 0.015573740714188964\n",
      "210 Train Loss 0.0047527743 Test MSE 0.0004727456411769628 Test RE 0.015753658770403255\n",
      "211 Train Loss 0.0047270604 Test MSE 0.00047664105148668854 Test RE 0.015818430459572413\n",
      "212 Train Loss 0.0046959235 Test MSE 0.00048462537994376924 Test RE 0.015950369378562628\n",
      "213 Train Loss 0.004645151 Test MSE 0.0004587916682340272 Test RE 0.015519417938530877\n",
      "214 Train Loss 0.0046166624 Test MSE 0.00045407332755355024 Test RE 0.015439408699787294\n",
      "215 Train Loss 0.0045657395 Test MSE 0.00044654183242672754 Test RE 0.015310830293264735\n",
      "216 Train Loss 0.00452386 Test MSE 0.0004280956708985886 Test RE 0.014991258249779486\n",
      "217 Train Loss 0.004502956 Test MSE 0.0004332742999948702 Test RE 0.015081659528896939\n",
      "218 Train Loss 0.004484161 Test MSE 0.0004256224763701224 Test RE 0.014947891772438902\n",
      "219 Train Loss 0.0044652936 Test MSE 0.0004235894307634003 Test RE 0.014912148684911098\n",
      "220 Train Loss 0.004430907 Test MSE 0.0003967558490986896 Test RE 0.014432093593176128\n",
      "221 Train Loss 0.004402214 Test MSE 0.0003805259289788007 Test RE 0.0141338277777927\n",
      "222 Train Loss 0.004397771 Test MSE 0.0003809162526056605 Test RE 0.014141074791099637\n",
      "223 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "224 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "225 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "226 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "227 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "228 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "229 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "230 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "231 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "232 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "233 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "234 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "235 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "236 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "237 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "238 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "239 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "240 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "241 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "242 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "243 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "244 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "245 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "246 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "247 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "248 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "249 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "250 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "251 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "252 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "253 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "254 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "255 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "256 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "257 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "258 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "259 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "260 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "261 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "262 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "263 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "264 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "265 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "266 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "267 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "268 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "269 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "270 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "271 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "272 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "273 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "274 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "275 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "276 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "277 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "278 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "279 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "280 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "281 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "282 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "283 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "284 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "285 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "286 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "287 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "288 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "289 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "290 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "291 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "292 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "293 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "294 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "295 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "296 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "297 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "298 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "299 Train Loss 0.00438597 Test MSE 0.0003811476714905042 Test RE 0.014145369717934776\n",
      "Training time: 424.48\n",
      "KG_rowdy_medium\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 26362.287 Test MSE 1.9030811285600737 Test RE 0.9995311171270629\n",
      "1 Train Loss 1539.13 Test MSE 2.3942676006278902 Test RE 1.1211249353604709\n",
      "2 Train Loss 298.7628 Test MSE 2.9691529151332032 Test RE 1.2484867858825945\n",
      "3 Train Loss 98.735916 Test MSE 2.5980042661411713 Test RE 1.1678514319784865\n",
      "4 Train Loss 50.2803 Test MSE 2.5953155645255084 Test RE 1.1672469647535277\n",
      "5 Train Loss 28.400309 Test MSE 2.077605388379881 Test RE 1.0443575221067007\n",
      "6 Train Loss 18.75068 Test MSE 1.7880417827947703 Test RE 0.968849900985079\n",
      "7 Train Loss 12.839389 Test MSE 1.5677358427834227 Test RE 0.9072022349539104\n",
      "8 Train Loss 9.562238 Test MSE 1.5415005930631511 Test RE 0.8995794290233058\n",
      "9 Train Loss 7.0402746 Test MSE 1.4092545736599538 Test RE 0.8601266305191758\n",
      "10 Train Loss 5.208495 Test MSE 1.303892256979066 Test RE 0.8273485704081539\n",
      "11 Train Loss 4.2482452 Test MSE 1.2619675080994246 Test RE 0.813938805125784\n",
      "12 Train Loss 3.6260917 Test MSE 1.2125801541075123 Test RE 0.7978530244064513\n",
      "13 Train Loss 2.8165562 Test MSE 1.2507892182182605 Test RE 0.8103259221899748\n",
      "14 Train Loss 2.3460636 Test MSE 1.2769066623783734 Test RE 0.8187423292163594\n",
      "15 Train Loss 2.0898964 Test MSE 1.2422779187163882 Test RE 0.8075641860151461\n",
      "16 Train Loss 1.8650633 Test MSE 1.2280063192359048 Test RE 0.8029120364655441\n",
      "17 Train Loss 1.623371 Test MSE 1.2191646018076794 Test RE 0.8000163078490684\n",
      "18 Train Loss 1.4812547 Test MSE 1.1829496943545335 Test RE 0.7880446152814227\n",
      "19 Train Loss 1.3538482 Test MSE 1.1530728185403694 Test RE 0.7780294477080633\n",
      "20 Train Loss 1.2511337 Test MSE 1.1464208340142694 Test RE 0.7757820069801336\n",
      "21 Train Loss 1.1342211 Test MSE 1.1174541191220533 Test RE 0.7659184266582979\n",
      "22 Train Loss 1.0828886 Test MSE 1.0700897339573212 Test RE 0.7495105778986735\n",
      "23 Train Loss 1.0045336 Test MSE 1.024719943141644 Test RE 0.7334495761214376\n",
      "24 Train Loss 0.88362867 Test MSE 0.8571030630155052 Test RE 0.6707863110166199\n",
      "25 Train Loss 0.8563821 Test MSE 0.7692940978741557 Test RE 0.6354975314323161\n",
      "26 Train Loss 0.7888107 Test MSE 0.6489963025881086 Test RE 0.5836987710676764\n",
      "27 Train Loss 0.7293655 Test MSE 0.6106942776429886 Test RE 0.566212682640308\n",
      "28 Train Loss 0.67283565 Test MSE 0.5508892844662937 Test RE 0.5377740355467255\n",
      "29 Train Loss 0.6335529 Test MSE 0.5041998306988504 Test RE 0.5144806146242366\n",
      "30 Train Loss 0.60202837 Test MSE 0.4151526282624634 Test RE 0.4668437656531801\n",
      "31 Train Loss 0.5568695 Test MSE 0.3832756560787133 Test RE 0.4485628325121352\n",
      "32 Train Loss 0.5381285 Test MSE 0.3979052602858614 Test RE 0.45704346954454683\n",
      "33 Train Loss 0.49148354 Test MSE 0.36820008920374786 Test RE 0.4396525661129171\n",
      "34 Train Loss 0.47535518 Test MSE 0.34779355158652936 Test RE 0.4272956094833446\n",
      "35 Train Loss 0.43794557 Test MSE 0.2850836048873053 Test RE 0.38685996533080325\n",
      "36 Train Loss 0.414971 Test MSE 0.2734006643021875 Test RE 0.37885013852574295\n",
      "37 Train Loss 0.3993085 Test MSE 0.2572473575229305 Test RE 0.3674879717966023\n",
      "38 Train Loss 0.37706646 Test MSE 0.244621859500083 Test RE 0.3583565106908495\n",
      "39 Train Loss 0.33631057 Test MSE 0.21029356692528509 Test RE 0.3322619896315781\n",
      "40 Train Loss 0.3246398 Test MSE 0.2095329120712328 Test RE 0.33166053125775785\n",
      "41 Train Loss 0.3083491 Test MSE 0.1985249130932358 Test RE 0.3228309580382728\n",
      "42 Train Loss 0.28939626 Test MSE 0.1756179092018768 Test RE 0.303635166136295\n",
      "43 Train Loss 0.28425324 Test MSE 0.1744595883746696 Test RE 0.30263216821847627\n",
      "44 Train Loss 0.26075074 Test MSE 0.14532245926832252 Test RE 0.27620659053730795\n",
      "45 Train Loss 0.25460145 Test MSE 0.1501012760805594 Test RE 0.28071127698216225\n",
      "46 Train Loss 0.24298716 Test MSE 0.13818854377789377 Test RE 0.2693417563547732\n",
      "47 Train Loss 0.22595076 Test MSE 0.12881732908121438 Test RE 0.26004877526107506\n",
      "48 Train Loss 0.2128615 Test MSE 0.11807872643143888 Test RE 0.24897371398513773\n",
      "49 Train Loss 0.20759846 Test MSE 0.11921838847548732 Test RE 0.2501723402156984\n",
      "50 Train Loss 0.1956607 Test MSE 0.11515402228623639 Test RE 0.2458709525694715\n",
      "51 Train Loss 0.18287304 Test MSE 0.1111975562799632 Test RE 0.24161021355829942\n",
      "52 Train Loss 0.17979747 Test MSE 0.10991991666505263 Test RE 0.24021817482279104\n",
      "53 Train Loss 0.1783712 Test MSE 0.1064850917547834 Test RE 0.23643516649441226\n",
      "54 Train Loss 0.16898987 Test MSE 0.10467008390209691 Test RE 0.23441152151548006\n",
      "55 Train Loss 0.16272397 Test MSE 0.10404911921463385 Test RE 0.23371515344459579\n",
      "56 Train Loss 0.15582147 Test MSE 0.0980939629406301 Test RE 0.22692837734808222\n",
      "57 Train Loss 0.15385103 Test MSE 0.09925285017268623 Test RE 0.2282649133484337\n",
      "58 Train Loss 0.15152325 Test MSE 0.09572815260118343 Test RE 0.22417516937156126\n",
      "59 Train Loss 0.14738466 Test MSE 0.0899370869417301 Test RE 0.21728866716277737\n",
      "60 Train Loss 0.14156617 Test MSE 0.08559478975640986 Test RE 0.21197826460610536\n",
      "61 Train Loss 0.13704728 Test MSE 0.0862123273421222 Test RE 0.21274156623909324\n",
      "62 Train Loss 0.1345943 Test MSE 0.08352945811506558 Test RE 0.20940521816091145\n",
      "63 Train Loss 0.13038845 Test MSE 0.07928044568377625 Test RE 0.20400964921827883\n",
      "64 Train Loss 0.11910414 Test MSE 0.06515583400082212 Test RE 0.1849457354904406\n",
      "65 Train Loss 0.11564038 Test MSE 0.060692570702866974 Test RE 0.17849885478563812\n",
      "66 Train Loss 0.11364607 Test MSE 0.056695536793208115 Test RE 0.17252105426340686\n",
      "67 Train Loss 0.11118473 Test MSE 0.0523666894986334 Test RE 0.16580408545977365\n",
      "68 Train Loss 0.10598936 Test MSE 0.047493006927195984 Test RE 0.15790013493162708\n",
      "69 Train Loss 0.100524195 Test MSE 0.043056016922655434 Test RE 0.1503434781190427\n",
      "70 Train Loss 0.0988369 Test MSE 0.043996920197163114 Test RE 0.1519773284771441\n",
      "71 Train Loss 0.090548374 Test MSE 0.0342005744699372 Test RE 0.13399369647837517\n",
      "72 Train Loss 0.082608245 Test MSE 0.02303064233287268 Test RE 0.10995644570867347\n",
      "73 Train Loss 0.0790151 Test MSE 0.020379012983862743 Test RE 0.10343302843335632\n",
      "74 Train Loss 0.077870406 Test MSE 0.0205844733281155 Test RE 0.10395312452629973\n",
      "75 Train Loss 0.0770579 Test MSE 0.01911326467018791 Test RE 0.10016940740076748\n",
      "76 Train Loss 0.074678645 Test MSE 0.016661326238156724 Test RE 0.09352386616664692\n",
      "77 Train Loss 0.07161466 Test MSE 0.015028622212348963 Test RE 0.08882337098929097\n",
      "78 Train Loss 0.066948555 Test MSE 0.013077654313248473 Test RE 0.08285764667606833\n",
      "79 Train Loss 0.06471726 Test MSE 0.012223479351764517 Test RE 0.08010600792772302\n",
      "80 Train Loss 0.06362553 Test MSE 0.011460481199048906 Test RE 0.07756558890677157\n",
      "81 Train Loss 0.061523 Test MSE 0.009678233168937959 Test RE 0.07127967455110061\n",
      "82 Train Loss 0.060325604 Test MSE 0.00945966984240969 Test RE 0.07047022484827821\n",
      "83 Train Loss 0.05966627 Test MSE 0.008810492144932878 Test RE 0.06800921340347937\n",
      "84 Train Loss 0.059303973 Test MSE 0.008877226193739745 Test RE 0.06826629146133034\n",
      "85 Train Loss 0.058037747 Test MSE 0.009751943655792723 Test RE 0.07155059660184113\n",
      "86 Train Loss 0.056979205 Test MSE 0.009627701333709262 Test RE 0.07109334887797697\n",
      "87 Train Loss 0.05421416 Test MSE 0.0070936715703193275 Test RE 0.06102435618594092\n",
      "88 Train Loss 0.053004157 Test MSE 0.006565883816192687 Test RE 0.05871029525307266\n",
      "89 Train Loss 0.051281653 Test MSE 0.0066032996688617325 Test RE 0.05887733865670622\n",
      "90 Train Loss 0.049305893 Test MSE 0.00584168249210528 Test RE 0.05537792029321409\n",
      "91 Train Loss 0.047671944 Test MSE 0.005817729918352511 Test RE 0.055264270996409286\n",
      "92 Train Loss 0.044627782 Test MSE 0.00536237133631122 Test RE 0.053057417826326544\n",
      "93 Train Loss 0.042239092 Test MSE 0.005119827395078967 Test RE 0.05184362105919591\n",
      "94 Train Loss 0.041338626 Test MSE 0.004620663178458915 Test RE 0.049251541023594206\n",
      "95 Train Loss 0.039055396 Test MSE 0.0035474492650181466 Test RE 0.04315446770735923\n",
      "96 Train Loss 0.03841706 Test MSE 0.003110827898462251 Test RE 0.040411564136898975\n",
      "97 Train Loss 0.037651468 Test MSE 0.0026707462312563993 Test RE 0.03744415029468179\n",
      "98 Train Loss 0.03657659 Test MSE 0.001989761059656991 Test RE 0.03231976031059664\n",
      "99 Train Loss 0.036098372 Test MSE 0.0018996026034539457 Test RE 0.03157904889651732\n",
      "100 Train Loss 0.03529873 Test MSE 0.0017256989069388145 Test RE 0.030098869199494782\n",
      "101 Train Loss 0.03488967 Test MSE 0.001760062791241144 Test RE 0.030397071745722953\n",
      "102 Train Loss 0.03439427 Test MSE 0.001410918907390313 Test RE 0.027215648945332932\n",
      "103 Train Loss 0.033532944 Test MSE 0.0011942332219003942 Test RE 0.025038726818979694\n",
      "104 Train Loss 0.032676075 Test MSE 0.0013937029999718672 Test RE 0.027049097857806566\n",
      "105 Train Loss 0.032130986 Test MSE 0.0013318269567929425 Test RE 0.026441833616458788\n",
      "106 Train Loss 0.031537835 Test MSE 0.0015824475787129231 Test RE 0.028822545519471245\n",
      "107 Train Loss 0.030326135 Test MSE 0.0015849132894874079 Test RE 0.028844991886617245\n",
      "108 Train Loss 0.029204318 Test MSE 0.002219288693149897 Test RE 0.034133008422398185\n",
      "109 Train Loss 0.028581306 Test MSE 0.002377179316555278 Test RE 0.035326339559194606\n",
      "110 Train Loss 0.028209258 Test MSE 0.0020185045110220306 Test RE 0.032552363749975444\n",
      "111 Train Loss 0.02788954 Test MSE 0.0019661761334015945 Test RE 0.03212764391581801\n",
      "112 Train Loss 0.027404323 Test MSE 0.001823199854189765 Test RE 0.03093747079964071\n",
      "113 Train Loss 0.026925046 Test MSE 0.0018341028342292508 Test RE 0.031029838028982827\n",
      "114 Train Loss 0.026492037 Test MSE 0.0022247149908450467 Test RE 0.03417471160136016\n",
      "115 Train Loss 0.02610317 Test MSE 0.002249229400439643 Test RE 0.03436248343487291\n",
      "116 Train Loss 0.025919888 Test MSE 0.0022367276544589857 Test RE 0.03426685298342861\n",
      "117 Train Loss 0.025714468 Test MSE 0.0021493430284681963 Test RE 0.033590814467005174\n",
      "118 Train Loss 0.025268486 Test MSE 0.0018083034721655773 Test RE 0.030810824891782447\n",
      "119 Train Loss 0.02490448 Test MSE 0.0015269761914692337 Test RE 0.028312863844969432\n",
      "120 Train Loss 0.024486665 Test MSE 0.0013279392965202474 Test RE 0.026403212986213676\n",
      "121 Train Loss 0.023897287 Test MSE 0.0010435120071128716 Test RE 0.023405417531652834\n",
      "122 Train Loss 0.023048608 Test MSE 0.0009084614727551081 Test RE 0.021838405439547508\n",
      "123 Train Loss 0.022564428 Test MSE 0.0008187575541482 Test RE 0.02073219703468077\n",
      "124 Train Loss 0.02221144 Test MSE 0.000854180473558834 Test RE 0.0211759297377792\n",
      "125 Train Loss 0.021239694 Test MSE 0.0008331003066118564 Test RE 0.020912998909111975\n",
      "126 Train Loss 0.020487275 Test MSE 0.0007497818079021303 Test RE 0.019839700742580013\n",
      "127 Train Loss 0.020133225 Test MSE 0.0008802033716054821 Test RE 0.021496075636420104\n",
      "128 Train Loss 0.019718096 Test MSE 0.0010621815127832932 Test RE 0.02361386286468762\n",
      "129 Train Loss 0.01953895 Test MSE 0.0011081682100826315 Test RE 0.024119622780875205\n",
      "130 Train Loss 0.019269185 Test MSE 0.001024098095062792 Test RE 0.023186673510623743\n",
      "131 Train Loss 0.019092413 Test MSE 0.0009483003958092319 Test RE 0.022312109548036453\n",
      "132 Train Loss 0.01878163 Test MSE 0.0007162413877860248 Test RE 0.01939087354319436\n",
      "133 Train Loss 0.01872495 Test MSE 0.0007345490513849465 Test RE 0.019637132421145877\n",
      "134 Train Loss 0.018549837 Test MSE 0.0006170247624172576 Test RE 0.017997781059749984\n",
      "135 Train Loss 0.018268976 Test MSE 0.0005561152036463654 Test RE 0.017086379647720605\n",
      "136 Train Loss 0.017957168 Test MSE 0.0005867168292762669 Test RE 0.01755019476513291\n",
      "137 Train Loss 0.01767878 Test MSE 0.0005537345128964613 Test RE 0.017049767617144194\n",
      "138 Train Loss 0.017364096 Test MSE 0.00039932700226582776 Test RE 0.014478781247064818\n",
      "139 Train Loss 0.017140783 Test MSE 0.0003695092127526575 Test RE 0.013927728846560933\n",
      "140 Train Loss 0.016883716 Test MSE 0.00035911288494599596 Test RE 0.013730399118012698\n",
      "141 Train Loss 0.016586257 Test MSE 0.0003188673694537302 Test RE 0.012938165648524926\n",
      "142 Train Loss 0.016365027 Test MSE 0.00033343340246895563 Test RE 0.013230377003577048\n",
      "143 Train Loss 0.016173188 Test MSE 0.00034164693845662727 Test RE 0.013392339006974117\n",
      "144 Train Loss 0.016024217 Test MSE 0.000337021477048615 Test RE 0.01330137251763992\n",
      "145 Train Loss 0.015926594 Test MSE 0.0003547284076203937 Test RE 0.013646323181590345\n",
      "146 Train Loss 0.015788393 Test MSE 0.0003634686265793907 Test RE 0.013813417321488344\n",
      "147 Train Loss 0.015645243 Test MSE 0.000405971179021794 Test RE 0.014598736475943432\n",
      "148 Train Loss 0.015526778 Test MSE 0.0004124940013999542 Test RE 0.014715549580474588\n",
      "149 Train Loss 0.015319204 Test MSE 0.0003585613504651115 Test RE 0.013719851322707168\n",
      "150 Train Loss 0.015064273 Test MSE 0.0002655760665912386 Test RE 0.011807613660961284\n",
      "151 Train Loss 0.014892742 Test MSE 0.00029776905988890284 Test RE 0.012502804849836967\n",
      "152 Train Loss 0.014624293 Test MSE 0.0003335819769225743 Test RE 0.013233324334431232\n",
      "153 Train Loss 0.014362615 Test MSE 0.0003049211023588919 Test RE 0.012652064819315027\n",
      "154 Train Loss 0.014203765 Test MSE 0.0003484048129211971 Test RE 0.013524142574456775\n",
      "155 Train Loss 0.014007198 Test MSE 0.000378096988767861 Test RE 0.014088646649546618\n",
      "156 Train Loss 0.013810227 Test MSE 0.0004180085590138993 Test RE 0.014813587763544467\n",
      "157 Train Loss 0.013542808 Test MSE 0.00046396278492976035 Test RE 0.015606633832833743\n",
      "158 Train Loss 0.013381468 Test MSE 0.00048432545344310866 Test RE 0.015945432906935397\n",
      "159 Train Loss 0.013315064 Test MSE 0.0004442972272988949 Test RE 0.015272300796228436\n",
      "160 Train Loss 0.013193092 Test MSE 0.0004102340410723896 Test RE 0.014675182648327161\n",
      "161 Train Loss 0.012895966 Test MSE 0.0005177018105663565 Test RE 0.016485704445328868\n",
      "162 Train Loss 0.012597249 Test MSE 0.0006270203912740235 Test RE 0.018142974910938414\n",
      "163 Train Loss 0.012430609 Test MSE 0.0005152236330658889 Test RE 0.016446199551014\n",
      "164 Train Loss 0.012279238 Test MSE 0.0005237954681198819 Test RE 0.016582443870595615\n",
      "165 Train Loss 0.012105105 Test MSE 0.0005273205822780331 Test RE 0.01663814976253593\n",
      "166 Train Loss 0.012036051 Test MSE 0.00045671023848946584 Test RE 0.015484173947635113\n",
      "167 Train Loss 0.011970189 Test MSE 0.00042392397037618505 Test RE 0.014918036130969713\n",
      "168 Train Loss 0.01188611 Test MSE 0.00039943507067257105 Test RE 0.014480740284350325\n",
      "169 Train Loss 0.011821516 Test MSE 0.0003675078882534638 Test RE 0.013889960167187826\n",
      "170 Train Loss 0.011692272 Test MSE 0.0003970755279170082 Test RE 0.014437906621102928\n",
      "171 Train Loss 0.011632046 Test MSE 0.00043268628240622785 Test RE 0.015071422028073319\n",
      "172 Train Loss 0.011557975 Test MSE 0.00042051160949422976 Test RE 0.014857873717627796\n",
      "173 Train Loss 0.011463375 Test MSE 0.00044686575473270343 Test RE 0.015316382539448347\n",
      "174 Train Loss 0.011407906 Test MSE 0.00042985174647315486 Test RE 0.015021974327932544\n",
      "175 Train Loss 0.011337818 Test MSE 0.00046656065649856876 Test RE 0.015650266032789024\n",
      "176 Train Loss 0.011249916 Test MSE 0.0004790204163763766 Test RE 0.01585786365919292\n",
      "177 Train Loss 0.011189711 Test MSE 0.0004863424056344938 Test RE 0.015978600440979023\n",
      "178 Train Loss 0.011082925 Test MSE 0.0004501524320135217 Test RE 0.01537260499855255\n",
      "179 Train Loss 0.010972045 Test MSE 0.0004511633389822405 Test RE 0.015389856442178721\n",
      "180 Train Loss 0.010843745 Test MSE 0.00046602124334482465 Test RE 0.015641216404739446\n",
      "181 Train Loss 0.010770401 Test MSE 0.000476387638996667 Test RE 0.015814224862105725\n",
      "182 Train Loss 0.010668387 Test MSE 0.0004099522307995086 Test RE 0.014670141224045915\n",
      "183 Train Loss 0.010597678 Test MSE 0.000438379701965901 Test RE 0.015170255181124111\n",
      "184 Train Loss 0.010505607 Test MSE 0.0004659662694618983 Test RE 0.015640293824737583\n",
      "185 Train Loss 0.010432036 Test MSE 0.00046090601554920073 Test RE 0.01555513755104113\n",
      "186 Train Loss 0.010362098 Test MSE 0.0004951409069727617 Test RE 0.016122488341882228\n",
      "187 Train Loss 0.01026273 Test MSE 0.0005319480832984855 Test RE 0.01671099432956356\n",
      "188 Train Loss 0.01019405 Test MSE 0.0005348915942782041 Test RE 0.01675716531708349\n",
      "189 Train Loss 0.010139796 Test MSE 0.0005277944688316989 Test RE 0.01664562417667867\n",
      "190 Train Loss 0.010068956 Test MSE 0.0005652191616732287 Test RE 0.017225669323981656\n",
      "191 Train Loss 0.009987762 Test MSE 0.0005463491565004675 Test RE 0.016935686513049296\n",
      "192 Train Loss 0.009902324 Test MSE 0.000596301944374321 Test RE 0.01769297159916688\n",
      "193 Train Loss 0.009828406 Test MSE 0.0005978850979447513 Test RE 0.01771644303364376\n",
      "194 Train Loss 0.009784862 Test MSE 0.000606807549943131 Test RE 0.01784814787453664\n",
      "195 Train Loss 0.009720505 Test MSE 0.0006712806817059503 Test RE 0.018772397522228146\n",
      "196 Train Loss 0.009677622 Test MSE 0.0007305945142927221 Test RE 0.019584201600470592\n",
      "197 Train Loss 0.009666282 Test MSE 0.000750512346680676 Test RE 0.019849363648434818\n",
      "198 Train Loss 0.009638973 Test MSE 0.0007716442596356932 Test RE 0.020126869584950868\n",
      "199 Train Loss 0.009582683 Test MSE 0.0007375680600095117 Test RE 0.019677445509595836\n",
      "200 Train Loss 0.009506509 Test MSE 0.0007240966564182955 Test RE 0.019496916812862204\n",
      "201 Train Loss 0.009437245 Test MSE 0.0007557047596472725 Test RE 0.019917909117533997\n",
      "202 Train Loss 0.00936825 Test MSE 0.0007812705544105781 Test RE 0.020252022248202165\n",
      "203 Train Loss 0.009293507 Test MSE 0.0008160013437253002 Test RE 0.02069727187986608\n",
      "204 Train Loss 0.009183607 Test MSE 0.0008587103354778056 Test RE 0.021232005240253086\n",
      "205 Train Loss 0.008853361 Test MSE 0.0006914627813871761 Test RE 0.019052504463318756\n",
      "206 Train Loss 0.008586148 Test MSE 0.0006108605818333338 Test RE 0.01790765497948565\n",
      "207 Train Loss 0.008382894 Test MSE 0.0005154380704402615 Test RE 0.01644962166982503\n",
      "208 Train Loss 0.008113052 Test MSE 0.0003801611638143493 Test RE 0.014127051939785211\n",
      "209 Train Loss 0.007894309 Test MSE 0.0003360403726214111 Test RE 0.013281997570188721\n",
      "210 Train Loss 0.0077552907 Test MSE 0.00031641311570254816 Test RE 0.012888278327105387\n",
      "211 Train Loss 0.007665743 Test MSE 0.00030554203413913744 Test RE 0.012664940402006825\n",
      "212 Train Loss 0.0076221307 Test MSE 0.00029039399463716236 Test RE 0.012347000993574643\n",
      "213 Train Loss 0.0075605037 Test MSE 0.0002879801144880383 Test RE 0.012295577107030171\n",
      "214 Train Loss 0.007455427 Test MSE 0.00027596638786718406 Test RE 0.012036376447890108\n",
      "215 Train Loss 0.007422438 Test MSE 0.00027878739767067424 Test RE 0.012097739723122565\n",
      "216 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "217 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "218 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "219 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "220 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "221 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "222 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "223 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "224 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "225 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "226 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "227 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "228 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "229 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "230 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "231 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "232 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "233 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "234 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "235 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "236 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "237 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "238 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "239 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "240 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "241 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "242 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "243 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "244 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "245 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "246 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "247 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "248 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "249 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "250 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "251 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "252 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "253 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "254 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "255 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "256 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "257 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "258 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "259 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "260 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "261 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "262 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "263 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "264 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "265 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "266 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "267 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "268 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "269 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "270 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "271 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "272 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "273 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "274 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "275 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "276 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "277 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "278 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "279 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "280 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "281 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "282 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "283 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "284 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "285 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "286 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "287 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "288 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "289 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "290 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "291 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "292 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "293 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "294 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "295 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "296 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "297 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "298 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "299 Train Loss 0.0073967725 Test MSE 0.000272684576980832 Test RE 0.011964593698267346\n",
      "Training time: 390.69\n",
      "KG_rowdy_medium\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 41345.0 Test MSE 3.2408174298763996 Test RE 1.304352426979687\n",
      "1 Train Loss 18399.215 Test MSE 2.984494999354562 Test RE 1.2517081945206237\n",
      "2 Train Loss 4986.0522 Test MSE 2.8381517176208653 Test RE 1.220634024331629\n",
      "3 Train Loss 838.1808 Test MSE 2.3955923264673498 Test RE 1.1214350464343277\n",
      "4 Train Loss 268.152 Test MSE 1.7013598387064894 Test RE 0.9450738708944979\n",
      "5 Train Loss 126.668816 Test MSE 1.3544177575757939 Test RE 0.8432259963279353\n",
      "6 Train Loss 64.12775 Test MSE 0.9863955860346562 Test RE 0.7196034349637229\n",
      "7 Train Loss 40.47113 Test MSE 0.8778193806566971 Test RE 0.6788444163359355\n",
      "8 Train Loss 27.461315 Test MSE 0.6933251137087871 Test RE 0.6033039008956119\n",
      "9 Train Loss 21.07014 Test MSE 0.5492496135607916 Test RE 0.5369731218500313\n",
      "10 Train Loss 16.855913 Test MSE 0.4952496576179884 Test RE 0.5098938333339756\n",
      "11 Train Loss 13.066409 Test MSE 0.4394890741129569 Test RE 0.48033220847195296\n",
      "12 Train Loss 11.423816 Test MSE 0.412133090837723 Test RE 0.46514291552916887\n",
      "13 Train Loss 9.146785 Test MSE 0.3657372231902391 Test RE 0.4381796955470898\n",
      "14 Train Loss 7.6557255 Test MSE 0.34113370934469184 Test RE 0.42318472758814735\n",
      "15 Train Loss 6.4413166 Test MSE 0.3177268485938063 Test RE 0.4084083617432097\n",
      "16 Train Loss 5.3845396 Test MSE 0.30812616922416264 Test RE 0.4021906406610028\n",
      "17 Train Loss 4.238686 Test MSE 0.29639783440946643 Test RE 0.39446200763219325\n",
      "18 Train Loss 3.885738 Test MSE 0.28239294171387846 Test RE 0.38503001515060875\n",
      "19 Train Loss 3.3825948 Test MSE 0.2530894636213728 Test RE 0.36450601584121844\n",
      "20 Train Loss 2.977508 Test MSE 0.25183224933850645 Test RE 0.3635995524082505\n",
      "21 Train Loss 2.615118 Test MSE 0.2549717101672323 Test RE 0.36585893522814367\n",
      "22 Train Loss 2.4081655 Test MSE 0.25314508926017854 Test RE 0.3645460703850169\n",
      "23 Train Loss 2.30256 Test MSE 0.2446758403373683 Test RE 0.35839604787176016\n",
      "24 Train Loss 2.0610442 Test MSE 0.25105460901655463 Test RE 0.3630377334013639\n",
      "25 Train Loss 1.9076408 Test MSE 0.25599671641804167 Test RE 0.36659358841940204\n",
      "26 Train Loss 1.7165805 Test MSE 0.26455535449381523 Test RE 0.3726712976453765\n",
      "27 Train Loss 1.6062862 Test MSE 0.2650553954058589 Test RE 0.37302332779561687\n",
      "28 Train Loss 1.5006722 Test MSE 0.28454178923445467 Test RE 0.38649216713427453\n",
      "29 Train Loss 1.3535868 Test MSE 0.2888057390005283 Test RE 0.3893772532428939\n",
      "30 Train Loss 1.3119886 Test MSE 0.2938525431289592 Test RE 0.39276465127126603\n",
      "31 Train Loss 1.2024666 Test MSE 0.29402848682035704 Test RE 0.39288221724655303\n",
      "32 Train Loss 1.142691 Test MSE 0.31598613189906904 Test RE 0.4072880603592544\n",
      "33 Train Loss 1.104297 Test MSE 0.31677394148524524 Test RE 0.4077954650539477\n",
      "34 Train Loss 0.9997956 Test MSE 0.344552889260685 Test RE 0.4253002281390148\n",
      "35 Train Loss 0.96983397 Test MSE 0.35528264701945694 Test RE 0.43187161981637345\n",
      "36 Train Loss 0.85703164 Test MSE 0.35664919056725986 Test RE 0.4327013886876808\n",
      "37 Train Loss 0.83047014 Test MSE 0.349782865767502 Test RE 0.4285158925779948\n",
      "38 Train Loss 0.80517524 Test MSE 0.3326599388198188 Test RE 0.4178957162387721\n",
      "39 Train Loss 0.765203 Test MSE 0.31726753524886986 Test RE 0.4081130526502032\n",
      "40 Train Loss 0.73169816 Test MSE 0.30804840049815074 Test RE 0.4021398825127421\n",
      "41 Train Loss 0.70375276 Test MSE 0.3212514933343009 Test RE 0.410667415690877\n",
      "42 Train Loss 0.6816484 Test MSE 0.31172300602129416 Test RE 0.40453126769368153\n",
      "43 Train Loss 0.6663503 Test MSE 0.3069713004513048 Test RE 0.4014362200771435\n",
      "44 Train Loss 0.63485813 Test MSE 0.3131413784189374 Test RE 0.40545055303428035\n",
      "45 Train Loss 0.60467917 Test MSE 0.30058165911981055 Test RE 0.39723628008941503\n",
      "46 Train Loss 0.59055823 Test MSE 0.29344146661326814 Test RE 0.3924898317507243\n",
      "47 Train Loss 0.584041 Test MSE 0.28740954377913197 Test RE 0.3884349151454068\n",
      "48 Train Loss 0.5643165 Test MSE 0.2793428897793907 Test RE 0.38294506612711254\n",
      "49 Train Loss 0.52824104 Test MSE 0.2648808283187902 Test RE 0.3729004698532517\n",
      "50 Train Loss 0.5060243 Test MSE 0.24352852840559752 Test RE 0.3575547812674845\n",
      "51 Train Loss 0.49568313 Test MSE 0.23905514921716284 Test RE 0.3542555957800965\n",
      "52 Train Loss 0.47076255 Test MSE 0.22933885508624996 Test RE 0.3469816338584972\n",
      "53 Train Loss 0.43725392 Test MSE 0.21744052453518806 Test RE 0.3378608817675653\n",
      "54 Train Loss 0.39960036 Test MSE 0.21168845834333377 Test RE 0.3333621264239748\n",
      "55 Train Loss 0.3834976 Test MSE 0.2016206084841899 Test RE 0.3253382514490041\n",
      "56 Train Loss 0.37294185 Test MSE 0.18824631797018482 Test RE 0.31436262950978755\n",
      "57 Train Loss 0.3662645 Test MSE 0.18325569708483705 Test RE 0.3101675860915494\n",
      "58 Train Loss 0.35566416 Test MSE 0.16736389682462727 Test RE 0.29641389434687154\n",
      "59 Train Loss 0.34516385 Test MSE 0.15473436120237272 Test RE 0.2850106252028376\n",
      "60 Train Loss 0.33053112 Test MSE 0.1349138690795537 Test RE 0.26613130664676965\n",
      "61 Train Loss 0.3142501 Test MSE 0.11918779502351574 Test RE 0.2501402389322935\n",
      "62 Train Loss 0.2964468 Test MSE 0.12442662886422967 Test RE 0.2555785106647128\n",
      "63 Train Loss 0.2879393 Test MSE 0.11777903158050154 Test RE 0.24865755396113745\n",
      "64 Train Loss 0.2845565 Test MSE 0.12005285186138437 Test RE 0.25104634813018806\n",
      "65 Train Loss 0.2822848 Test MSE 0.12376882769759583 Test RE 0.2549020371823813\n",
      "66 Train Loss 0.27784106 Test MSE 0.12123730047698315 Test RE 0.25228172766849816\n",
      "67 Train Loss 0.26843295 Test MSE 0.11887314564503938 Test RE 0.24980984233174341\n",
      "68 Train Loss 0.2608663 Test MSE 0.10981000938849779 Test RE 0.24009804951179725\n",
      "69 Train Loss 0.25129297 Test MSE 0.09726899744431464 Test RE 0.22597213426034415\n",
      "70 Train Loss 0.2372321 Test MSE 0.08626320399367038 Test RE 0.2128043297817619\n",
      "71 Train Loss 0.22687338 Test MSE 0.08160228641636279 Test RE 0.20697544803084758\n",
      "72 Train Loss 0.22361422 Test MSE 0.08063681574845792 Test RE 0.20574739842757278\n",
      "73 Train Loss 0.22115463 Test MSE 0.07573348031082333 Test RE 0.19939378857019094\n",
      "74 Train Loss 0.21607438 Test MSE 0.06902611252883285 Test RE 0.1903594210142311\n",
      "75 Train Loss 0.21408227 Test MSE 0.06942363079389424 Test RE 0.19090676976117496\n",
      "76 Train Loss 0.21072884 Test MSE 0.06286367280260455 Test RE 0.1816634439239969\n",
      "77 Train Loss 0.19838044 Test MSE 0.05233670472384472 Test RE 0.16575660957302227\n",
      "78 Train Loss 0.18842466 Test MSE 0.04489069268395999 Test RE 0.15351323405866665\n",
      "79 Train Loss 0.18417877 Test MSE 0.04461834427864393 Test RE 0.1530468490664554\n",
      "80 Train Loss 0.18182065 Test MSE 0.0473889730032569 Test RE 0.15772709917942385\n",
      "81 Train Loss 0.17934482 Test MSE 0.050849241097769685 Test RE 0.1633841433862701\n",
      "82 Train Loss 0.1774398 Test MSE 0.05379858558447711 Test RE 0.16805564171898293\n",
      "83 Train Loss 0.17281942 Test MSE 0.05008275801829787 Test RE 0.16214807091305675\n",
      "84 Train Loss 0.16448724 Test MSE 0.04660181337438766 Test RE 0.15641164220398934\n",
      "85 Train Loss 0.15779787 Test MSE 0.045476880334366324 Test RE 0.15451227965398204\n",
      "86 Train Loss 0.14679623 Test MSE 0.047151145345080685 Test RE 0.15733081448224448\n",
      "87 Train Loss 0.14363424 Test MSE 0.04532433840992554 Test RE 0.15425292371028088\n",
      "88 Train Loss 0.14025901 Test MSE 0.03991747062133452 Test RE 0.14476020011913132\n",
      "89 Train Loss 0.13853967 Test MSE 0.038987083560129254 Test RE 0.1430632352762493\n",
      "90 Train Loss 0.13604835 Test MSE 0.0362641570122898 Test RE 0.13797692467236125\n",
      "91 Train Loss 0.13480526 Test MSE 0.0331745855925308 Test RE 0.1319685426967439\n",
      "92 Train Loss 0.13334242 Test MSE 0.0314849435142935 Test RE 0.12856392621882656\n",
      "93 Train Loss 0.13234006 Test MSE 0.03149994749229529 Test RE 0.12859455578887183\n",
      "94 Train Loss 0.13189888 Test MSE 0.03175616357675883 Test RE 0.12911648151756444\n",
      "95 Train Loss 0.13049048 Test MSE 0.03401720159534712 Test RE 0.13363399735726617\n",
      "96 Train Loss 0.12258741 Test MSE 0.03605881896632269 Test RE 0.13758573769549723\n",
      "97 Train Loss 0.11746935 Test MSE 0.03231869579934821 Test RE 0.13025505332986118\n",
      "98 Train Loss 0.11418137 Test MSE 0.030966168718407894 Test RE 0.12750035838199195\n",
      "99 Train Loss 0.11136589 Test MSE 0.030335693144886988 Test RE 0.12619572091931477\n",
      "100 Train Loss 0.10979995 Test MSE 0.031067315070999912 Test RE 0.127708419033796\n",
      "101 Train Loss 0.10904409 Test MSE 0.031083768399664275 Test RE 0.12774223190845896\n",
      "102 Train Loss 0.10806873 Test MSE 0.03049262378374195 Test RE 0.12652171361848713\n",
      "103 Train Loss 0.10613778 Test MSE 0.03251789182213957 Test RE 0.1306558496913942\n",
      "104 Train Loss 0.104008526 Test MSE 0.031629454077987985 Test RE 0.12885863177840703\n",
      "105 Train Loss 0.102352835 Test MSE 0.03134337902834152 Test RE 0.12827457219283223\n",
      "106 Train Loss 0.10011407 Test MSE 0.030555353474899665 Test RE 0.12665178754101777\n",
      "107 Train Loss 0.09759463 Test MSE 0.027806073477513703 Test RE 0.12081962979666207\n",
      "108 Train Loss 0.09539649 Test MSE 0.02387177690195019 Test RE 0.111946376588405\n",
      "109 Train Loss 0.09298342 Test MSE 0.02320020571958922 Test RE 0.11036048123360685\n",
      "110 Train Loss 0.091313064 Test MSE 0.021555176218072625 Test RE 0.10637595119019716\n",
      "111 Train Loss 0.09007207 Test MSE 0.021058158681426218 Test RE 0.10514239480380129\n",
      "112 Train Loss 0.08806198 Test MSE 0.01891950800507034 Test RE 0.09966039104673806\n",
      "113 Train Loss 0.08711264 Test MSE 0.01813060514225903 Test RE 0.09756045509154433\n",
      "114 Train Loss 0.08643818 Test MSE 0.018245148024006983 Test RE 0.0978681464620168\n",
      "115 Train Loss 0.08583329 Test MSE 0.018653226426341814 Test RE 0.09895657345417291\n",
      "116 Train Loss 0.08549249 Test MSE 0.01802797312129404 Test RE 0.09728393269313682\n",
      "117 Train Loss 0.084507056 Test MSE 0.017805714359939526 Test RE 0.0966823880036261\n",
      "118 Train Loss 0.083231546 Test MSE 0.016635198381524222 Test RE 0.0934505065531106\n",
      "119 Train Loss 0.08203065 Test MSE 0.01686712144765713 Test RE 0.09409968153609585\n",
      "120 Train Loss 0.080980144 Test MSE 0.01630072631341314 Test RE 0.09250626481491704\n",
      "121 Train Loss 0.08003954 Test MSE 0.01582343591961074 Test RE 0.09114189707209862\n",
      "122 Train Loss 0.07839108 Test MSE 0.01597276937239124 Test RE 0.09157096230759922\n",
      "123 Train Loss 0.07694621 Test MSE 0.015746348614944426 Test RE 0.09091961724742721\n",
      "124 Train Loss 0.07545071 Test MSE 0.016083595241022437 Test RE 0.09188809230792004\n",
      "125 Train Loss 0.073909506 Test MSE 0.016607417520435933 Test RE 0.09337244255058676\n",
      "126 Train Loss 0.07315359 Test MSE 0.017332223587898418 Test RE 0.09538823414506933\n",
      "127 Train Loss 0.07251982 Test MSE 0.01727472296836501 Test RE 0.09522987479797315\n",
      "128 Train Loss 0.07179087 Test MSE 0.017270045928760844 Test RE 0.0952169824335678\n",
      "129 Train Loss 0.07134792 Test MSE 0.017068389619979876 Test RE 0.09465944234083044\n",
      "130 Train Loss 0.07094341 Test MSE 0.01641203226309485 Test RE 0.09282155691809232\n",
      "131 Train Loss 0.07069344 Test MSE 0.0159944454124669 Test RE 0.09163307498362584\n",
      "132 Train Loss 0.07018553 Test MSE 0.01587295448527537 Test RE 0.09128439743002437\n",
      "133 Train Loss 0.0691772 Test MSE 0.015217282145884616 Test RE 0.08937914875921352\n",
      "134 Train Loss 0.06800891 Test MSE 0.01470332694417532 Test RE 0.0878568189895441\n",
      "135 Train Loss 0.065551385 Test MSE 0.013128041994682357 Test RE 0.08301711682271057\n",
      "136 Train Loss 0.06158662 Test MSE 0.01182974744361029 Test RE 0.07880529590082613\n",
      "137 Train Loss 0.059701014 Test MSE 0.012298359117241673 Test RE 0.08035099385498592\n",
      "138 Train Loss 0.05830584 Test MSE 0.011399320499459381 Test RE 0.07735834141960522\n",
      "139 Train Loss 0.057535764 Test MSE 0.011057992273047967 Test RE 0.07619137456237489\n",
      "140 Train Loss 0.057069756 Test MSE 0.010448150573059315 Test RE 0.0740606260727519\n",
      "141 Train Loss 0.056776483 Test MSE 0.010323805943016493 Test RE 0.07361860502739682\n",
      "142 Train Loss 0.056571722 Test MSE 0.010437514237107277 Test RE 0.07402291919454453\n",
      "143 Train Loss 0.05621497 Test MSE 0.010599826646890879 Test RE 0.07459625914551783\n",
      "144 Train Loss 0.05602482 Test MSE 0.010466897081099017 Test RE 0.0741270376304228\n",
      "145 Train Loss 0.055788405 Test MSE 0.010298835652419224 Test RE 0.07352952010645807\n",
      "146 Train Loss 0.055419464 Test MSE 0.010137896601964274 Test RE 0.07295273804676378\n",
      "147 Train Loss 0.05495764 Test MSE 0.009934158441782559 Test RE 0.0722159633140411\n",
      "148 Train Loss 0.054086663 Test MSE 0.009583486020390818 Test RE 0.07092991256341417\n",
      "149 Train Loss 0.0530815 Test MSE 0.009446941271270578 Test RE 0.07042279786480049\n",
      "150 Train Loss 0.05213224 Test MSE 0.009167095316431987 Test RE 0.06937189229691508\n",
      "151 Train Loss 0.05114803 Test MSE 0.009926079656269992 Test RE 0.07218659313923373\n",
      "152 Train Loss 0.04998667 Test MSE 0.009646571399317943 Test RE 0.0711629854095775\n",
      "153 Train Loss 0.04879374 Test MSE 0.00930947820932953 Test RE 0.06990855694645023\n",
      "154 Train Loss 0.047990765 Test MSE 0.008906295207185173 Test RE 0.06837797115825552\n",
      "155 Train Loss 0.04752269 Test MSE 0.008835220860822007 Test RE 0.06810458844403404\n",
      "156 Train Loss 0.04709262 Test MSE 0.00872622067684223 Test RE 0.0676831812833012\n",
      "157 Train Loss 0.04688052 Test MSE 0.008785242623518498 Test RE 0.06791169148664605\n",
      "158 Train Loss 0.046718296 Test MSE 0.008957807647758283 Test RE 0.06857542911669472\n",
      "159 Train Loss 0.046558343 Test MSE 0.009025265312350032 Test RE 0.06883315188180555\n",
      "160 Train Loss 0.046272848 Test MSE 0.008815556949936576 Test RE 0.0680287585043504\n",
      "161 Train Loss 0.046148233 Test MSE 0.008619796221847352 Test RE 0.06726918516835982\n",
      "162 Train Loss 0.046102174 Test MSE 0.008632084725039842 Test RE 0.0673171180410572\n",
      "163 Train Loss 0.045902524 Test MSE 0.00850735249730598 Test RE 0.06682898754049522\n",
      "164 Train Loss 0.045317907 Test MSE 0.008323017426896326 Test RE 0.06610100607784421\n",
      "165 Train Loss 0.045041054 Test MSE 0.008305326437523628 Test RE 0.06603071821241584\n",
      "166 Train Loss 0.044732213 Test MSE 0.00805555637476544 Test RE 0.06503025220112915\n",
      "167 Train Loss 0.04428215 Test MSE 0.007808231639573534 Test RE 0.06402417809828369\n",
      "168 Train Loss 0.043628212 Test MSE 0.007583865153539346 Test RE 0.0630976186286965\n",
      "169 Train Loss 0.042477794 Test MSE 0.007504953595937209 Test RE 0.06276848887135365\n",
      "170 Train Loss 0.04076657 Test MSE 0.007518042306301504 Test RE 0.06282319944823259\n",
      "171 Train Loss 0.038372256 Test MSE 0.007223497016211668 Test RE 0.06158024557876351\n",
      "172 Train Loss 0.036779035 Test MSE 0.006636795163909371 Test RE 0.059026478564489414\n",
      "173 Train Loss 0.035700124 Test MSE 0.00665874651790913 Test RE 0.059124013704860943\n",
      "174 Train Loss 0.03425778 Test MSE 0.0060356151700607895 Test RE 0.05628963575183283\n",
      "175 Train Loss 0.033248354 Test MSE 0.005851186923314007 Test RE 0.05542295198753109\n",
      "176 Train Loss 0.032364994 Test MSE 0.005919392097977647 Test RE 0.05574503877106049\n",
      "177 Train Loss 0.030909559 Test MSE 0.005520010604600534 Test RE 0.053831641577533576\n",
      "178 Train Loss 0.029929845 Test MSE 0.0051413698740205615 Test RE 0.05195257666197945\n",
      "179 Train Loss 0.029336466 Test MSE 0.004848422140001183 Test RE 0.050450779469676264\n",
      "180 Train Loss 0.028936144 Test MSE 0.0046407307165564566 Test RE 0.049358374864644707\n",
      "181 Train Loss 0.028595597 Test MSE 0.0042201388972832815 Test RE 0.04706857391147308\n",
      "182 Train Loss 0.02826396 Test MSE 0.003874719861643753 Test RE 0.04510117142880951\n",
      "183 Train Loss 0.027953606 Test MSE 0.003787702804162663 Test RE 0.044591862825381794\n",
      "184 Train Loss 0.027738065 Test MSE 0.0038188319597944466 Test RE 0.044774726521023746\n",
      "185 Train Loss 0.027571892 Test MSE 0.0037600562983473055 Test RE 0.044428826404631805\n",
      "186 Train Loss 0.02746615 Test MSE 0.003846214400949542 Test RE 0.044934965486594\n",
      "187 Train Loss 0.02730803 Test MSE 0.0037416856993329676 Test RE 0.04432016001173498\n",
      "188 Train Loss 0.027233763 Test MSE 0.00374986371697007 Test RE 0.04436856776797921\n",
      "189 Train Loss 0.027174251 Test MSE 0.0037487778087412645 Test RE 0.0443621430436346\n",
      "190 Train Loss 0.027134137 Test MSE 0.0037455894518151605 Test RE 0.04434327390275398\n",
      "191 Train Loss 0.026988773 Test MSE 0.0036414935958175923 Test RE 0.04372274730627189\n",
      "192 Train Loss 0.02684874 Test MSE 0.003588744255584987 Test RE 0.043404916273438905\n",
      "193 Train Loss 0.026666895 Test MSE 0.0035910521395459325 Test RE 0.04341887065455421\n",
      "194 Train Loss 0.026440192 Test MSE 0.003652199415834748 Test RE 0.043786971547882025\n",
      "195 Train Loss 0.026295478 Test MSE 0.003727162481205182 Test RE 0.04423406283321828\n",
      "196 Train Loss 0.026215706 Test MSE 0.0036944743006797854 Test RE 0.04403966356637076\n",
      "197 Train Loss 0.02609205 Test MSE 0.003650027139943519 Test RE 0.04377394767929851\n",
      "198 Train Loss 0.025936248 Test MSE 0.00360691842117548 Test RE 0.04351468335028014\n",
      "199 Train Loss 0.025594901 Test MSE 0.0036358702094981764 Test RE 0.043688974777602904\n",
      "200 Train Loss 0.025001124 Test MSE 0.0036826135581956203 Test RE 0.043968914256311144\n",
      "201 Train Loss 0.024892164 Test MSE 0.003719988055375212 Test RE 0.044191469188505014\n",
      "202 Train Loss 0.024727095 Test MSE 0.00377495050162924 Test RE 0.04451673439149473\n",
      "203 Train Loss 0.024437737 Test MSE 0.0037710418576054625 Test RE 0.04449368175388963\n",
      "204 Train Loss 0.02416169 Test MSE 0.0036652138074159384 Test RE 0.04386491828154158\n",
      "205 Train Loss 0.024023622 Test MSE 0.00366746164370471 Test RE 0.04387836716163068\n",
      "206 Train Loss 0.023816437 Test MSE 0.003684301708991637 Test RE 0.043978991019981185\n",
      "207 Train Loss 0.023522722 Test MSE 0.0037316898032733734 Test RE 0.044260919868974735\n",
      "208 Train Loss 0.023418268 Test MSE 0.003682594836212195 Test RE 0.043968802489719676\n",
      "209 Train Loss 0.023385612 Test MSE 0.0037099568505906183 Test RE 0.04413184629225228\n",
      "210 Train Loss 0.02335637 Test MSE 0.0036982809695810487 Test RE 0.044062346259826315\n",
      "211 Train Loss 0.023303041 Test MSE 0.003676242559099208 Test RE 0.04393086421801403\n",
      "212 Train Loss 0.02327571 Test MSE 0.003723032117455752 Test RE 0.04420954640611674\n",
      "213 Train Loss 0.023268148 Test MSE 0.003718215391755887 Test RE 0.04418093878584084\n",
      "214 Train Loss 0.023266204 Test MSE 0.003714672081958321 Test RE 0.04415988243887871\n",
      "215 Train Loss 0.023238333 Test MSE 0.003681925361235364 Test RE 0.04396480566787472\n",
      "216 Train Loss 0.023177851 Test MSE 0.0037591066117841146 Test RE 0.044423215301942175\n",
      "217 Train Loss 0.023110945 Test MSE 0.003762288835454529 Test RE 0.044442014276925054\n",
      "218 Train Loss 0.023050122 Test MSE 0.0037635330863353676 Test RE 0.04444936252245802\n",
      "219 Train Loss 0.022996452 Test MSE 0.0037287732419083877 Test RE 0.044243620076044404\n",
      "220 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "221 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "222 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "223 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "224 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "225 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "226 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "227 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "228 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "229 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "230 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "231 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "232 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "233 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "234 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "235 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "236 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "237 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "238 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "239 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "240 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "241 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "242 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "243 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "244 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "245 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "246 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "247 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "248 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "249 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "250 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "251 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "252 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "253 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "254 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "255 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "256 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "257 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "258 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "259 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "260 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "261 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "262 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "263 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "264 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "265 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "266 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "267 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "268 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "269 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "270 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "271 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "272 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "273 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "274 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "275 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "276 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "277 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "278 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "279 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "280 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "281 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "282 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "283 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "284 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "285 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "286 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "287 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "288 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "289 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "290 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "291 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "292 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "293 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "294 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "295 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "296 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "297 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "298 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "299 Train Loss 0.022993611 Test MSE 0.0037303056702932603 Test RE 0.04425271062811897\n",
      "Training time: 386.54\n",
      "KG_rowdy_medium\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 14322.902 Test MSE 3.33024045818653 Test RE 1.3222253033267513\n",
      "1 Train Loss 2128.0034 Test MSE 4.893473891522195 Test RE 1.6027888236920416\n",
      "2 Train Loss 426.92722 Test MSE 7.212834374267603 Test RE 1.9459005800531695\n",
      "3 Train Loss 177.33658 Test MSE 8.07602270207587 Test RE 2.0590478212525882\n",
      "4 Train Loss 82.18081 Test MSE 5.534808118954301 Test RE 1.7045861378164855\n",
      "5 Train Loss 44.563812 Test MSE 4.187626712426935 Test RE 1.4826944037774323\n",
      "6 Train Loss 28.852615 Test MSE 3.424040159722653 Test RE 1.3407169270150088\n",
      "7 Train Loss 21.255398 Test MSE 2.9090215523965766 Test RE 1.2357799283391608\n",
      "8 Train Loss 16.69388 Test MSE 2.5705489614194796 Test RE 1.1616642060698545\n",
      "9 Train Loss 13.58853 Test MSE 2.172917163530623 Test RE 1.0680442661453364\n",
      "10 Train Loss 10.483247 Test MSE 1.5825387884749824 Test RE 0.9114751849087458\n",
      "11 Train Loss 8.408688 Test MSE 1.174624103424106 Test RE 0.7852665927280691\n",
      "12 Train Loss 6.9302845 Test MSE 0.9453972488212399 Test RE 0.7044900030720102\n",
      "13 Train Loss 5.896908 Test MSE 0.7744357805840384 Test RE 0.6376177121976381\n",
      "14 Train Loss 4.8090916 Test MSE 0.6945268394498058 Test RE 0.603826521471219\n",
      "15 Train Loss 4.0408287 Test MSE 0.5414120991950837 Test RE 0.5331281887364447\n",
      "16 Train Loss 3.6103306 Test MSE 0.40301670968542974 Test RE 0.4599696684488456\n",
      "17 Train Loss 3.101965 Test MSE 0.35092097287856094 Test RE 0.42921246888993514\n",
      "18 Train Loss 2.6141694 Test MSE 0.2998884443776806 Test RE 0.39677795372767555\n",
      "19 Train Loss 2.2862942 Test MSE 0.238057637747232 Test RE 0.35351571750194793\n",
      "20 Train Loss 2.0721781 Test MSE 0.19103846954756937 Test RE 0.31668542990294346\n",
      "21 Train Loss 1.8457714 Test MSE 0.16768527331628538 Test RE 0.29669834867873285\n",
      "22 Train Loss 1.5931342 Test MSE 0.1824507553362951 Test RE 0.3094856383834778\n",
      "23 Train Loss 1.5043635 Test MSE 0.1518964242169148 Test RE 0.2823848823597333\n",
      "24 Train Loss 1.3637936 Test MSE 0.13639394285900952 Test RE 0.26758712268946633\n",
      "25 Train Loss 1.2387125 Test MSE 0.11543388316165647 Test RE 0.24616954354376186\n",
      "26 Train Loss 1.1396561 Test MSE 0.10511449655733734 Test RE 0.2349086315722303\n",
      "27 Train Loss 1.0063639 Test MSE 0.08153376875269884 Test RE 0.20688853593015702\n",
      "28 Train Loss 0.91152763 Test MSE 0.06280284958607904 Test RE 0.18157553918932945\n",
      "29 Train Loss 0.8690908 Test MSE 0.0567463185402026 Test RE 0.17259829984683725\n",
      "30 Train Loss 0.8162752 Test MSE 0.06201864744838961 Test RE 0.18043833581162852\n",
      "31 Train Loss 0.7608229 Test MSE 0.05867100145116011 Test RE 0.1755009284135257\n",
      "32 Train Loss 0.7229865 Test MSE 0.05583169093892866 Test RE 0.171201694264563\n",
      "33 Train Loss 0.65291256 Test MSE 0.05368621096309341 Test RE 0.16788003244343075\n",
      "34 Train Loss 0.6039346 Test MSE 0.054179162259234526 Test RE 0.16864901553609776\n",
      "35 Train Loss 0.55760944 Test MSE 0.06054737364803866 Test RE 0.1782852122662609\n",
      "36 Train Loss 0.5342233 Test MSE 0.06424989819063406 Test RE 0.18365547915493594\n",
      "37 Train Loss 0.5091591 Test MSE 0.06051507066361095 Test RE 0.17823764692657565\n",
      "38 Train Loss 0.49389157 Test MSE 0.06437010219064064 Test RE 0.18382719777262446\n",
      "39 Train Loss 0.42106774 Test MSE 0.0642458452894168 Test RE 0.18364968654456135\n",
      "40 Train Loss 0.40744257 Test MSE 0.06581186841534377 Test RE 0.18587448489853117\n",
      "41 Train Loss 0.3756772 Test MSE 0.062209396525949895 Test RE 0.1807156074321588\n",
      "42 Train Loss 0.35804465 Test MSE 0.05621133853539136 Test RE 0.17178278175529227\n",
      "43 Train Loss 0.35341385 Test MSE 0.05268551158950537 Test RE 0.1663080488598103\n",
      "44 Train Loss 0.30479956 Test MSE 0.04231514303615605 Test RE 0.14904436952807443\n",
      "45 Train Loss 0.28984293 Test MSE 0.03987949111118252 Test RE 0.14469131762510795\n",
      "46 Train Loss 0.2832166 Test MSE 0.03914446059754811 Test RE 0.14335169225590882\n",
      "47 Train Loss 0.26331568 Test MSE 0.03247190252481812 Test RE 0.13056342523825146\n",
      "48 Train Loss 0.24006721 Test MSE 0.028332722776855817 Test RE 0.12195842967024018\n",
      "49 Train Loss 0.23235087 Test MSE 0.025106679470136 Test RE 0.11480539752322796\n",
      "50 Train Loss 0.22942185 Test MSE 0.023149049140115768 Test RE 0.11023874135738566\n",
      "51 Train Loss 0.22318688 Test MSE 0.020767550361500298 Test RE 0.10441437753957153\n",
      "52 Train Loss 0.21099006 Test MSE 0.018247053499003355 Test RE 0.09787325687375548\n",
      "53 Train Loss 0.18721873 Test MSE 0.012623995159749313 Test RE 0.08140781105689866\n",
      "54 Train Loss 0.17915931 Test MSE 0.010407226842527284 Test RE 0.07391544196885333\n",
      "55 Train Loss 0.17427334 Test MSE 0.011775763614405516 Test RE 0.0786252803859524\n",
      "56 Train Loss 0.16759509 Test MSE 0.011007858607377023 Test RE 0.07601846378190369\n",
      "57 Train Loss 0.15947454 Test MSE 0.010615001242336736 Test RE 0.07464963564182635\n",
      "58 Train Loss 0.15446761 Test MSE 0.009262446796548036 Test RE 0.06973174460227043\n",
      "59 Train Loss 0.15066424 Test MSE 0.00879003828248957 Test RE 0.06793022466171832\n",
      "60 Train Loss 0.1482657 Test MSE 0.008605304783692844 Test RE 0.06721261554237863\n",
      "61 Train Loss 0.14549734 Test MSE 0.008603272690207941 Test RE 0.0672046791365327\n",
      "62 Train Loss 0.14127684 Test MSE 0.007791558477569875 Test RE 0.06395578515024285\n",
      "63 Train Loss 0.13715681 Test MSE 0.008332329013063423 Test RE 0.06613797182749323\n",
      "64 Train Loss 0.13342173 Test MSE 0.008092836311711673 Test RE 0.06518055375738542\n",
      "65 Train Loss 0.12615693 Test MSE 0.008135672789575485 Test RE 0.06535283083300374\n",
      "66 Train Loss 0.12505695 Test MSE 0.007930309842792152 Test RE 0.064522731659872\n",
      "67 Train Loss 0.11707663 Test MSE 0.007700737613663768 Test RE 0.06358194816145708\n",
      "68 Train Loss 0.11405203 Test MSE 0.008153938456352199 Test RE 0.06542615259764088\n",
      "69 Train Loss 0.10998157 Test MSE 0.00772620336710135 Test RE 0.06368699172308315\n",
      "70 Train Loss 0.10662864 Test MSE 0.0074198663612583225 Test RE 0.0624116564612575\n",
      "71 Train Loss 0.10406196 Test MSE 0.0074405005142081475 Test RE 0.06249837753653147\n",
      "72 Train Loss 0.103023045 Test MSE 0.007599257164343367 Test RE 0.06316161679634569\n",
      "73 Train Loss 0.10161011 Test MSE 0.0076032034227647705 Test RE 0.06317801443274265\n",
      "74 Train Loss 0.10047408 Test MSE 0.0077447599258941265 Test RE 0.0637634265896917\n",
      "75 Train Loss 0.09856002 Test MSE 0.007956548361986332 Test RE 0.0646293846730293\n",
      "76 Train Loss 0.097231135 Test MSE 0.007972760836894386 Test RE 0.06469519644311715\n",
      "77 Train Loss 0.09516446 Test MSE 0.007644944639422603 Test RE 0.06335119917595669\n",
      "78 Train Loss 0.0918297 Test MSE 0.007424316982707751 Test RE 0.06243037169159045\n",
      "79 Train Loss 0.09041374 Test MSE 0.006988069826153076 Test RE 0.06056842570055705\n",
      "80 Train Loss 0.08943945 Test MSE 0.006989043300523696 Test RE 0.06057264430156395\n",
      "81 Train Loss 0.088587046 Test MSE 0.007150613451106693 Test RE 0.061268792101136595\n",
      "82 Train Loss 0.08771124 Test MSE 0.007047318607943765 Test RE 0.06082465031264879\n",
      "83 Train Loss 0.086573154 Test MSE 0.007036776713172843 Test RE 0.060779140305979244\n",
      "84 Train Loss 0.085161656 Test MSE 0.006876332584717362 Test RE 0.06008223845262309\n",
      "85 Train Loss 0.08264907 Test MSE 0.006480717149924448 Test RE 0.05832828418927411\n",
      "86 Train Loss 0.080373906 Test MSE 0.00639862295595633 Test RE 0.05795767130557117\n",
      "87 Train Loss 0.079819515 Test MSE 0.0064656472767089775 Test RE 0.05826042816225571\n",
      "88 Train Loss 0.07938455 Test MSE 0.006454945335411728 Test RE 0.0582121918547825\n",
      "89 Train Loss 0.07823076 Test MSE 0.00616308236080451 Test RE 0.05688092540632117\n",
      "90 Train Loss 0.076124124 Test MSE 0.006240182454871406 Test RE 0.05723560946322301\n",
      "91 Train Loss 0.07405411 Test MSE 0.006469219995555972 Test RE 0.05827652240423119\n",
      "92 Train Loss 0.07220215 Test MSE 0.007192154702177827 Test RE 0.06144650387744469\n",
      "93 Train Loss 0.071290195 Test MSE 0.007162891400415686 Test RE 0.061321370281393665\n",
      "94 Train Loss 0.070264935 Test MSE 0.00755695547902538 Test RE 0.06298557515139892\n",
      "95 Train Loss 0.06900065 Test MSE 0.008224003360576852 Test RE 0.0657066472165627\n",
      "96 Train Loss 0.06820591 Test MSE 0.007898661745862528 Test RE 0.06439385503998873\n",
      "97 Train Loss 0.067469954 Test MSE 0.008284568168330614 Test RE 0.06594814825114528\n",
      "98 Train Loss 0.065966494 Test MSE 0.008189370431744593 Test RE 0.0655681493122413\n",
      "99 Train Loss 0.06536558 Test MSE 0.008724778240363983 Test RE 0.06767758706742705\n",
      "100 Train Loss 0.06490052 Test MSE 0.008915172526539008 Test RE 0.068412040425465\n",
      "101 Train Loss 0.06392556 Test MSE 0.008968855504137067 Test RE 0.06861770386019707\n",
      "102 Train Loss 0.063189246 Test MSE 0.008514122234116767 Test RE 0.06685557187977866\n",
      "103 Train Loss 0.06284791 Test MSE 0.008497408044782148 Test RE 0.06678991710007931\n",
      "104 Train Loss 0.062210675 Test MSE 0.008767590990387512 Test RE 0.06784343184574525\n",
      "105 Train Loss 0.061165795 Test MSE 0.008445925095812719 Test RE 0.06658728083991221\n",
      "106 Train Loss 0.060751777 Test MSE 0.00811195371194307 Test RE 0.06525749512008754\n",
      "107 Train Loss 0.060044624 Test MSE 0.007880292934257163 Test RE 0.06431893557127552\n",
      "108 Train Loss 0.058608286 Test MSE 0.007726072074480033 Test RE 0.06368645059911754\n",
      "109 Train Loss 0.055882193 Test MSE 0.006567733038289567 Test RE 0.05871856228422074\n",
      "110 Train Loss 0.05350671 Test MSE 0.005568575809211394 Test RE 0.05406792912866525\n",
      "111 Train Loss 0.05221258 Test MSE 0.005157128542649571 Test RE 0.05203213493860982\n",
      "112 Train Loss 0.050777055 Test MSE 0.005022368412030552 Test RE 0.05134781302187728\n",
      "113 Train Loss 0.0490121 Test MSE 0.005213012272089212 Test RE 0.052313290902923616\n",
      "114 Train Loss 0.04816513 Test MSE 0.005522852117443005 Test RE 0.053845495139765956\n",
      "115 Train Loss 0.047501437 Test MSE 0.005333749166500266 Test RE 0.05291562884935863\n",
      "116 Train Loss 0.046788175 Test MSE 0.00519426953474595 Test RE 0.052219163254749255\n",
      "117 Train Loss 0.046381526 Test MSE 0.0052802331823571975 Test RE 0.05264949606006085\n",
      "118 Train Loss 0.045661625 Test MSE 0.005211444797242576 Test RE 0.05230542539941934\n",
      "119 Train Loss 0.044584446 Test MSE 0.0048662490071795855 Test RE 0.05054344406413969\n",
      "120 Train Loss 0.04324091 Test MSE 0.0047107903248728555 Test RE 0.049729552921702745\n",
      "121 Train Loss 0.04238971 Test MSE 0.0046574186023713 Test RE 0.049447040617511075\n",
      "122 Train Loss 0.041977357 Test MSE 0.004762781467128382 Test RE 0.050003222667401814\n",
      "123 Train Loss 0.04092023 Test MSE 0.004506974296242334 Test RE 0.04864186390310415\n",
      "124 Train Loss 0.04032798 Test MSE 0.00414758913697782 Test RE 0.046662234493213293\n",
      "125 Train Loss 0.039595626 Test MSE 0.0037992349462262582 Test RE 0.04465969402825955\n",
      "126 Train Loss 0.039131004 Test MSE 0.0035914375200825632 Test RE 0.04342120038106875\n",
      "127 Train Loss 0.037898373 Test MSE 0.0036962043958974223 Test RE 0.04404997408514508\n",
      "128 Train Loss 0.037004333 Test MSE 0.0037523192461187686 Test RE 0.044383092360044535\n",
      "129 Train Loss 0.03628944 Test MSE 0.004034492029331041 Test RE 0.0460216408135616\n",
      "130 Train Loss 0.03579157 Test MSE 0.003922910411955197 Test RE 0.045380770232874415\n",
      "131 Train Loss 0.03529163 Test MSE 0.00353793675983725 Test RE 0.04309656939355438\n",
      "132 Train Loss 0.034734037 Test MSE 0.0032410176520854036 Test RE 0.04124851954466299\n",
      "133 Train Loss 0.034430496 Test MSE 0.0032211978285600104 Test RE 0.04112220241572339\n",
      "134 Train Loss 0.03419437 Test MSE 0.0030859318035838276 Test RE 0.04024953151900739\n",
      "135 Train Loss 0.03388236 Test MSE 0.0028808941906757336 Test RE 0.038889407057999044\n",
      "136 Train Loss 0.033716604 Test MSE 0.0028409747134292003 Test RE 0.03861902914838906\n",
      "137 Train Loss 0.033485793 Test MSE 0.002831589452998988 Test RE 0.038555186714104774\n",
      "138 Train Loss 0.0331957 Test MSE 0.0025407242691415253 Test RE 0.036521317450707594\n",
      "139 Train Loss 0.03280549 Test MSE 0.002480579394121203 Test RE 0.036086456067898974\n",
      "140 Train Loss 0.032036107 Test MSE 0.0023631736595676584 Test RE 0.035222119506384084\n",
      "141 Train Loss 0.031087356 Test MSE 0.0019988347844902762 Test RE 0.032393368907491914\n",
      "142 Train Loss 0.030219305 Test MSE 0.001873842054114657 Test RE 0.03136419594332964\n",
      "143 Train Loss 0.029888045 Test MSE 0.0018724710619357023 Test RE 0.031352720073379324\n",
      "144 Train Loss 0.02963997 Test MSE 0.0018776946023295567 Test RE 0.03139642118719376\n",
      "145 Train Loss 0.029262275 Test MSE 0.0017543282522963224 Test RE 0.030347512318420058\n",
      "146 Train Loss 0.028841307 Test MSE 0.0017828803670725602 Test RE 0.030593472129319857\n",
      "147 Train Loss 0.028658383 Test MSE 0.001768082800600644 Test RE 0.030466247607194238\n",
      "148 Train Loss 0.028348103 Test MSE 0.0016966831226679494 Test RE 0.029844756340550022\n",
      "149 Train Loss 0.028242141 Test MSE 0.0016890598525682566 Test RE 0.02977763397409448\n",
      "150 Train Loss 0.028103633 Test MSE 0.0016633034849145726 Test RE 0.02954972315135754\n",
      "151 Train Loss 0.02799308 Test MSE 0.0016041947486383362 Test RE 0.029019920129926078\n",
      "152 Train Loss 0.027847277 Test MSE 0.0015961367424759763 Test RE 0.028946943613764087\n",
      "153 Train Loss 0.027690088 Test MSE 0.0016151722935994442 Test RE 0.02911904286540068\n",
      "154 Train Loss 0.027559428 Test MSE 0.0016139703273105278 Test RE 0.029108206058089444\n",
      "155 Train Loss 0.027195515 Test MSE 0.0016326300116076067 Test RE 0.029275987661307314\n",
      "156 Train Loss 0.026860379 Test MSE 0.0016833361561213048 Test RE 0.029727137606813312\n",
      "157 Train Loss 0.026403904 Test MSE 0.0017710299021431058 Test RE 0.030491628132745523\n",
      "158 Train Loss 0.026102036 Test MSE 0.0017275622119659012 Test RE 0.030115114282392646\n",
      "159 Train Loss 0.02593972 Test MSE 0.0017385899967294356 Test RE 0.030211080346985067\n",
      "160 Train Loss 0.025657648 Test MSE 0.001643884686600084 Test RE 0.029376722618969776\n",
      "161 Train Loss 0.025382908 Test MSE 0.0016954723348313328 Test RE 0.0298341055252709\n",
      "162 Train Loss 0.024974396 Test MSE 0.0016916372141061733 Test RE 0.029800344381031716\n",
      "163 Train Loss 0.024774753 Test MSE 0.001672902283244308 Test RE 0.02963486509732899\n",
      "164 Train Loss 0.024615541 Test MSE 0.0017091763920185955 Test RE 0.029954433485974076\n",
      "165 Train Loss 0.024475789 Test MSE 0.0017019476939690405 Test RE 0.029891022539021466\n",
      "166 Train Loss 0.02434685 Test MSE 0.0017420731801926093 Test RE 0.03024132844521073\n",
      "167 Train Loss 0.024247658 Test MSE 0.001721016087955162 Test RE 0.03005800363960028\n",
      "168 Train Loss 0.024049344 Test MSE 0.0016527370767926808 Test RE 0.02945571388034506\n",
      "169 Train Loss 0.023898179 Test MSE 0.0015887631226294092 Test RE 0.02888000359758465\n",
      "170 Train Loss 0.02379102 Test MSE 0.001535078900543509 Test RE 0.028387883799364067\n",
      "171 Train Loss 0.023666378 Test MSE 0.0015119823311253683 Test RE 0.028173514456731635\n",
      "172 Train Loss 0.02355309 Test MSE 0.0015121516888973237 Test RE 0.028175092276106272\n",
      "173 Train Loss 0.023454135 Test MSE 0.001557061430205558 Test RE 0.028590420384703996\n",
      "174 Train Loss 0.023305776 Test MSE 0.0015924798843472035 Test RE 0.02891376488822906\n",
      "175 Train Loss 0.023114774 Test MSE 0.0015979789843299892 Test RE 0.028963643903627087\n",
      "176 Train Loss 0.023007521 Test MSE 0.00160222615255616 Test RE 0.029002108689554183\n",
      "177 Train Loss 0.022887303 Test MSE 0.0016218461242702119 Test RE 0.029179140239849927\n",
      "178 Train Loss 0.02266033 Test MSE 0.0016390369016264642 Test RE 0.029333374936694245\n",
      "179 Train Loss 0.022403894 Test MSE 0.001709880575318233 Test RE 0.029960603486837458\n",
      "180 Train Loss 0.022242084 Test MSE 0.0017224597087380526 Test RE 0.030070607607477748\n",
      "181 Train Loss 0.0219749 Test MSE 0.0016652908000996977 Test RE 0.029567370887773326\n",
      "182 Train Loss 0.021843528 Test MSE 0.0016990783140249097 Test RE 0.02986581468992262\n",
      "183 Train Loss 0.021538982 Test MSE 0.0017851462244785105 Test RE 0.030612906533297502\n",
      "184 Train Loss 0.021339793 Test MSE 0.0017808121340149201 Test RE 0.030575721978321004\n",
      "185 Train Loss 0.021144142 Test MSE 0.001868580113511213 Test RE 0.031320128045877006\n",
      "186 Train Loss 0.02088711 Test MSE 0.0018651102050625287 Test RE 0.03129103416969459\n",
      "187 Train Loss 0.020755729 Test MSE 0.001818160273467099 Test RE 0.030894683452207503\n",
      "188 Train Loss 0.020627907 Test MSE 0.001813968879518782 Test RE 0.030859052241237386\n",
      "189 Train Loss 0.02045478 Test MSE 0.0018689040939199096 Test RE 0.0313228431202843\n",
      "190 Train Loss 0.020369105 Test MSE 0.001921101871681917 Test RE 0.031757248339950396\n",
      "191 Train Loss 0.020310117 Test MSE 0.0019201954555191907 Test RE 0.031749755588061555\n",
      "192 Train Loss 0.020233002 Test MSE 0.0019039426961679406 Test RE 0.03161510322831505\n",
      "193 Train Loss 0.020141566 Test MSE 0.0019673779545963553 Test RE 0.03213746139458152\n",
      "194 Train Loss 0.01998501 Test MSE 0.0019955708934090333 Test RE 0.03236691058665697\n",
      "195 Train Loss 0.019821078 Test MSE 0.002027491991723081 Test RE 0.03262475368002812\n",
      "196 Train Loss 0.01962547 Test MSE 0.0019431497257467235 Test RE 0.03193896220467993\n",
      "197 Train Loss 0.019492742 Test MSE 0.001850684568960594 Test RE 0.031169789515051446\n",
      "198 Train Loss 0.019389985 Test MSE 0.0018343713759596033 Test RE 0.031032109575934816\n",
      "199 Train Loss 0.019284397 Test MSE 0.0019246269951173178 Test RE 0.031786371447440946\n",
      "200 Train Loss 0.019179342 Test MSE 0.001955828373657282 Test RE 0.03204299033367137\n",
      "201 Train Loss 0.019019883 Test MSE 0.0021471310291092073 Test RE 0.03357352500084016\n",
      "202 Train Loss 0.018830208 Test MSE 0.002155167879410313 Test RE 0.03363630025042419\n",
      "203 Train Loss 0.018599754 Test MSE 0.0020875578135238575 Test RE 0.03310449167148816\n",
      "204 Train Loss 0.01852382 Test MSE 0.002070255925504176 Test RE 0.032967019563629185\n",
      "205 Train Loss 0.01844372 Test MSE 0.0020103681287484527 Test RE 0.03248668990147015\n",
      "206 Train Loss 0.018390834 Test MSE 0.001993276013318053 Test RE 0.03234829447385053\n",
      "207 Train Loss 0.018366437 Test MSE 0.0020182479992574202 Test RE 0.03255029530536193\n",
      "208 Train Loss 0.018313173 Test MSE 0.0020214293204026254 Test RE 0.03257593937086666\n",
      "209 Train Loss 0.018254835 Test MSE 0.0019762881079831863 Test RE 0.032210153636089145\n",
      "210 Train Loss 0.018170567 Test MSE 0.0019246994814130984 Test RE 0.031786970019173154\n",
      "211 Train Loss 0.018082092 Test MSE 0.0018676789711689014 Test RE 0.03131257490513059\n",
      "212 Train Loss 0.01785429 Test MSE 0.0017443746588922263 Test RE 0.030261297985498925\n",
      "213 Train Loss 0.017593576 Test MSE 0.0015726198835581092 Test RE 0.028732905787714737\n",
      "214 Train Loss 0.017358292 Test MSE 0.0015232352925793672 Test RE 0.028278161106629354\n",
      "215 Train Loss 0.017288875 Test MSE 0.001519527647563461 Test RE 0.028243724778462743\n",
      "216 Train Loss 0.017126117 Test MSE 0.0014938358524442252 Test RE 0.028003937960543877\n",
      "217 Train Loss 0.017039945 Test MSE 0.0014285295491392033 Test RE 0.02738497077224597\n",
      "218 Train Loss 0.016889455 Test MSE 0.001408712126130243 Test RE 0.027194356975145127\n",
      "219 Train Loss 0.016776819 Test MSE 0.0014557597688937684 Test RE 0.027644740921570543\n",
      "220 Train Loss 0.016673107 Test MSE 0.001488604273649434 Test RE 0.02795485850449632\n",
      "221 Train Loss 0.016441733 Test MSE 0.0015774976710526334 Test RE 0.028777431645563935\n",
      "222 Train Loss 0.016251577 Test MSE 0.001585900054674849 Test RE 0.028853969918759118\n",
      "223 Train Loss 0.016033275 Test MSE 0.0016596086125422638 Test RE 0.029516883937481683\n",
      "224 Train Loss 0.015850732 Test MSE 0.0016880542133461637 Test RE 0.029768768090738213\n",
      "225 Train Loss 0.015749378 Test MSE 0.0017240375582332885 Test RE 0.030084377459946163\n",
      "226 Train Loss 0.015667967 Test MSE 0.0016174311994526555 Test RE 0.029139398029509822\n",
      "227 Train Loss 0.015619715 Test MSE 0.0016518978671359883 Test RE 0.029448234572646205\n",
      "228 Train Loss 0.015511742 Test MSE 0.0015599290397447622 Test RE 0.028616735482900515\n",
      "229 Train Loss 0.015438186 Test MSE 0.00165012009460897 Test RE 0.029432384211556938\n",
      "230 Train Loss 0.015412969 Test MSE 0.001631140929944387 Test RE 0.029262633661639524\n",
      "231 Train Loss 0.015341153 Test MSE 0.001568269634285781 Test RE 0.02869313716167072\n",
      "232 Train Loss 0.015242835 Test MSE 0.0014848575117574535 Test RE 0.02791965566709013\n",
      "233 Train Loss 0.015159824 Test MSE 0.0014990309674605719 Test RE 0.028052590364569915\n",
      "234 Train Loss 0.015087368 Test MSE 0.0015618425420282152 Test RE 0.028634281603644028\n",
      "235 Train Loss 0.015063298 Test MSE 0.001598933369040623 Test RE 0.028972291806096385\n",
      "236 Train Loss 0.015019781 Test MSE 0.00165161020058008 Test RE 0.029445670358108165\n",
      "237 Train Loss 0.014955695 Test MSE 0.00164615647141402 Test RE 0.029397014355853988\n",
      "238 Train Loss 0.014897495 Test MSE 0.0016579888791558332 Test RE 0.029502476578751508\n",
      "239 Train Loss 0.014664781 Test MSE 0.0014396495949261035 Test RE 0.027491350022349804\n",
      "240 Train Loss 0.014541897 Test MSE 0.0013641804839654532 Test RE 0.026761076760477856\n",
      "241 Train Loss 0.014311463 Test MSE 0.0013514844931654933 Test RE 0.026636257283145975\n",
      "242 Train Loss 0.014119053 Test MSE 0.0014475332181948515 Test RE 0.02756651954551919\n",
      "243 Train Loss 0.013925974 Test MSE 0.0012883927204805409 Test RE 0.026007092289723123\n",
      "244 Train Loss 0.013712875 Test MSE 0.0013493288428031507 Test RE 0.02661500606931831\n",
      "245 Train Loss 0.013607321 Test MSE 0.001277924220548592 Test RE 0.025901219859459455\n",
      "246 Train Loss 0.0135536315 Test MSE 0.0012956790159897827 Test RE 0.02608052805065654\n",
      "247 Train Loss 0.013474848 Test MSE 0.0012244529414766653 Test RE 0.025353546456668406\n",
      "248 Train Loss 0.013330442 Test MSE 0.001105427709027945 Test RE 0.02408978039416601\n",
      "249 Train Loss 0.013280231 Test MSE 0.0010957990234462863 Test RE 0.023984635466956814\n",
      "250 Train Loss 0.013210663 Test MSE 0.0011030766696230306 Test RE 0.024064149514760474\n",
      "251 Train Loss 0.013098067 Test MSE 0.0010459325456030999 Test RE 0.023432547501447146\n",
      "252 Train Loss 0.013003267 Test MSE 0.001117625940988432 Test RE 0.02422232932226664\n",
      "253 Train Loss 0.012890224 Test MSE 0.0010578107140109577 Test RE 0.02356522812690156\n",
      "254 Train Loss 0.01268971 Test MSE 0.0009544129309379814 Test RE 0.022383903509583535\n",
      "255 Train Loss 0.012593 Test MSE 0.0008986618152895595 Test RE 0.021720299627313606\n",
      "256 Train Loss 0.012371444 Test MSE 0.0007211427906228505 Test RE 0.019457108501729246\n",
      "257 Train Loss 0.012325833 Test MSE 0.0007279866237800767 Test RE 0.019549217001397334\n",
      "258 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "259 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "260 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "261 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "262 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "263 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "264 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "265 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "266 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "267 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "268 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "269 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "270 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "271 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "272 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "273 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "274 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "275 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "276 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "277 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "278 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "279 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "280 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "281 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "282 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "283 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "284 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "285 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "286 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "287 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "288 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "289 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "290 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "291 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "292 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "293 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "294 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "295 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "296 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "297 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "298 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "299 Train Loss 0.012320925 Test MSE 0.0007292589755710444 Test RE 0.019566293292135127\n",
      "Training time: 440.42\n",
      "KG_rowdy_medium\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 46256.6 Test MSE 2.1674556720241656 Test RE 1.0667011904193395\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "200 Train Loss nan Test MSE nan Test RE nan\n",
      "201 Train Loss nan Test MSE nan Test RE nan\n",
      "202 Train Loss nan Test MSE nan Test RE nan\n",
      "203 Train Loss nan Test MSE nan Test RE nan\n",
      "204 Train Loss nan Test MSE nan Test RE nan\n",
      "205 Train Loss nan Test MSE nan Test RE nan\n",
      "206 Train Loss nan Test MSE nan Test RE nan\n",
      "207 Train Loss nan Test MSE nan Test RE nan\n",
      "208 Train Loss nan Test MSE nan Test RE nan\n",
      "209 Train Loss nan Test MSE nan Test RE nan\n",
      "210 Train Loss nan Test MSE nan Test RE nan\n",
      "211 Train Loss nan Test MSE nan Test RE nan\n",
      "212 Train Loss nan Test MSE nan Test RE nan\n",
      "213 Train Loss nan Test MSE nan Test RE nan\n",
      "214 Train Loss nan Test MSE nan Test RE nan\n",
      "215 Train Loss nan Test MSE nan Test RE nan\n",
      "216 Train Loss nan Test MSE nan Test RE nan\n",
      "217 Train Loss nan Test MSE nan Test RE nan\n",
      "218 Train Loss nan Test MSE nan Test RE nan\n",
      "219 Train Loss nan Test MSE nan Test RE nan\n",
      "220 Train Loss nan Test MSE nan Test RE nan\n",
      "221 Train Loss nan Test MSE nan Test RE nan\n",
      "222 Train Loss nan Test MSE nan Test RE nan\n",
      "223 Train Loss nan Test MSE nan Test RE nan\n",
      "224 Train Loss nan Test MSE nan Test RE nan\n",
      "225 Train Loss nan Test MSE nan Test RE nan\n",
      "226 Train Loss nan Test MSE nan Test RE nan\n",
      "227 Train Loss nan Test MSE nan Test RE nan\n",
      "228 Train Loss nan Test MSE nan Test RE nan\n",
      "229 Train Loss nan Test MSE nan Test RE nan\n",
      "230 Train Loss nan Test MSE nan Test RE nan\n",
      "231 Train Loss nan Test MSE nan Test RE nan\n",
      "232 Train Loss nan Test MSE nan Test RE nan\n",
      "233 Train Loss nan Test MSE nan Test RE nan\n",
      "234 Train Loss nan Test MSE nan Test RE nan\n",
      "235 Train Loss nan Test MSE nan Test RE nan\n",
      "236 Train Loss nan Test MSE nan Test RE nan\n",
      "237 Train Loss nan Test MSE nan Test RE nan\n",
      "238 Train Loss nan Test MSE nan Test RE nan\n",
      "239 Train Loss nan Test MSE nan Test RE nan\n",
      "240 Train Loss nan Test MSE nan Test RE nan\n",
      "241 Train Loss nan Test MSE nan Test RE nan\n",
      "242 Train Loss nan Test MSE nan Test RE nan\n",
      "243 Train Loss nan Test MSE nan Test RE nan\n",
      "244 Train Loss nan Test MSE nan Test RE nan\n",
      "245 Train Loss nan Test MSE nan Test RE nan\n",
      "246 Train Loss nan Test MSE nan Test RE nan\n",
      "247 Train Loss nan Test MSE nan Test RE nan\n",
      "248 Train Loss nan Test MSE nan Test RE nan\n",
      "249 Train Loss nan Test MSE nan Test RE nan\n",
      "250 Train Loss nan Test MSE nan Test RE nan\n",
      "251 Train Loss nan Test MSE nan Test RE nan\n",
      "252 Train Loss nan Test MSE nan Test RE nan\n",
      "253 Train Loss nan Test MSE nan Test RE nan\n",
      "254 Train Loss nan Test MSE nan Test RE nan\n",
      "255 Train Loss nan Test MSE nan Test RE nan\n",
      "256 Train Loss nan Test MSE nan Test RE nan\n",
      "257 Train Loss nan Test MSE nan Test RE nan\n",
      "258 Train Loss nan Test MSE nan Test RE nan\n",
      "259 Train Loss nan Test MSE nan Test RE nan\n",
      "260 Train Loss nan Test MSE nan Test RE nan\n",
      "261 Train Loss nan Test MSE nan Test RE nan\n",
      "262 Train Loss nan Test MSE nan Test RE nan\n",
      "263 Train Loss nan Test MSE nan Test RE nan\n",
      "264 Train Loss nan Test MSE nan Test RE nan\n",
      "265 Train Loss nan Test MSE nan Test RE nan\n",
      "266 Train Loss nan Test MSE nan Test RE nan\n",
      "267 Train Loss nan Test MSE nan Test RE nan\n",
      "268 Train Loss nan Test MSE nan Test RE nan\n",
      "269 Train Loss nan Test MSE nan Test RE nan\n",
      "270 Train Loss nan Test MSE nan Test RE nan\n",
      "271 Train Loss nan Test MSE nan Test RE nan\n",
      "272 Train Loss nan Test MSE nan Test RE nan\n",
      "273 Train Loss nan Test MSE nan Test RE nan\n",
      "274 Train Loss nan Test MSE nan Test RE nan\n",
      "275 Train Loss nan Test MSE nan Test RE nan\n",
      "276 Train Loss nan Test MSE nan Test RE nan\n",
      "277 Train Loss nan Test MSE nan Test RE nan\n",
      "278 Train Loss nan Test MSE nan Test RE nan\n",
      "279 Train Loss nan Test MSE nan Test RE nan\n",
      "280 Train Loss nan Test MSE nan Test RE nan\n",
      "281 Train Loss nan Test MSE nan Test RE nan\n",
      "282 Train Loss nan Test MSE nan Test RE nan\n",
      "283 Train Loss nan Test MSE nan Test RE nan\n",
      "284 Train Loss nan Test MSE nan Test RE nan\n",
      "285 Train Loss nan Test MSE nan Test RE nan\n",
      "286 Train Loss nan Test MSE nan Test RE nan\n",
      "287 Train Loss nan Test MSE nan Test RE nan\n",
      "288 Train Loss nan Test MSE nan Test RE nan\n",
      "289 Train Loss nan Test MSE nan Test RE nan\n",
      "290 Train Loss nan Test MSE nan Test RE nan\n",
      "291 Train Loss nan Test MSE nan Test RE nan\n",
      "292 Train Loss nan Test MSE nan Test RE nan\n",
      "293 Train Loss nan Test MSE nan Test RE nan\n",
      "294 Train Loss nan Test MSE nan Test RE nan\n",
      "295 Train Loss nan Test MSE nan Test RE nan\n",
      "296 Train Loss nan Test MSE nan Test RE nan\n",
      "297 Train Loss nan Test MSE nan Test RE nan\n",
      "298 Train Loss nan Test MSE nan Test RE nan\n",
      "299 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 28.43\n",
      "KG_rowdy_medium\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 18987.16 Test MSE 3.7127128949662698 Test RE 1.3960897895940356\n",
      "1 Train Loss 4050.1458 Test MSE 5.941918274282035 Test RE 1.7661639044808306\n",
      "2 Train Loss 1457.858 Test MSE 5.0301030439737175 Test RE 1.6250102645222386\n",
      "3 Train Loss 619.91235 Test MSE 3.7651235154651177 Test RE 1.4059092281744792\n",
      "4 Train Loss 415.09772 Test MSE 3.312421780864086 Test RE 1.3186832308889422\n",
      "5 Train Loss 309.35138 Test MSE 2.899455961045953 Test RE 1.2337464784034238\n",
      "6 Train Loss 244.06206 Test MSE 2.895508969557128 Test RE 1.2329064509516812\n",
      "7 Train Loss 139.90314 Test MSE 1.365599131910063 Test RE 0.8466994617030937\n",
      "8 Train Loss 71.10866 Test MSE 0.5795641000215687 Test RE 0.5515925676375474\n",
      "9 Train Loss 43.629322 Test MSE 0.7160769494766647 Test RE 0.6131228681268123\n",
      "10 Train Loss 24.600769 Test MSE 0.553350917742772 Test RE 0.538974210382017\n",
      "11 Train Loss 16.639227 Test MSE 0.42925271158103795 Test RE 0.4747054210209453\n",
      "12 Train Loss 12.735525 Test MSE 0.41695547930846266 Test RE 0.4678563306122838\n",
      "13 Train Loss 8.954179 Test MSE 0.3809396628144101 Test RE 0.44719379012772303\n",
      "14 Train Loss 5.8575606 Test MSE 0.24252361733534245 Test RE 0.3568163006518405\n",
      "15 Train Loss 4.9269395 Test MSE 0.1842757669422043 Test RE 0.3110296426102627\n",
      "16 Train Loss 3.9620006 Test MSE 0.2159213730056923 Test RE 0.3366785780094767\n",
      "17 Train Loss 3.3376977 Test MSE 0.19860500192349842 Test RE 0.3228960696313375\n",
      "18 Train Loss 3.250491 Test MSE 0.1835925301088007 Test RE 0.3104525068996903\n",
      "19 Train Loss 2.4707773 Test MSE 0.10533657887631359 Test RE 0.2351566541056417\n",
      "20 Train Loss 2.0172832 Test MSE 0.08271938526717658 Test RE 0.20838733315222457\n",
      "21 Train Loss 1.821889 Test MSE 0.07624234879304374 Test RE 0.2000625505435265\n",
      "22 Train Loss 1.6860859 Test MSE 0.09969678027791032 Test RE 0.22877482621373765\n",
      "23 Train Loss 1.6380752 Test MSE 0.09586140461078413 Test RE 0.2243311391828356\n",
      "24 Train Loss 1.4574391 Test MSE 0.10002085710386048 Test RE 0.2291463550947308\n",
      "25 Train Loss 1.1977208 Test MSE 0.06244698890819499 Test RE 0.1810603763567181\n",
      "26 Train Loss 1.1536243 Test MSE 0.06182619515007572 Test RE 0.18015815593477325\n",
      "27 Train Loss 1.1181636 Test MSE 0.05033352358669094 Test RE 0.16255350368031438\n",
      "28 Train Loss 1.0685775 Test MSE 0.04140744866535308 Test RE 0.14743714200356234\n",
      "29 Train Loss 0.90862423 Test MSE 0.03522932740273318 Test RE 0.13599402994018328\n",
      "30 Train Loss 0.7468732 Test MSE 0.043317133408949014 Test RE 0.1507986737436696\n",
      "31 Train Loss 0.72271824 Test MSE 0.053173299778041985 Test RE 0.16707615563492031\n",
      "32 Train Loss 0.7034177 Test MSE 0.04563903314742009 Test RE 0.1547874997945067\n",
      "33 Train Loss 0.6821014 Test MSE 0.04189917095394586 Test RE 0.14830998212160776\n",
      "34 Train Loss 0.6674273 Test MSE 0.04043918689519389 Test RE 0.14570312785423173\n",
      "35 Train Loss 0.65452754 Test MSE 0.04208204639335363 Test RE 0.1486332906993259\n",
      "36 Train Loss 0.609272 Test MSE 0.03700928808929795 Test RE 0.1393872446410535\n",
      "37 Train Loss 0.5855069 Test MSE 0.037155105908343596 Test RE 0.13966156987092787\n",
      "38 Train Loss 0.5822144 Test MSE 0.03818504461944821 Test RE 0.14158404599919028\n",
      "39 Train Loss 0.56205505 Test MSE 0.03187081488578975 Test RE 0.1293493502685621\n",
      "40 Train Loss 0.51099515 Test MSE 0.0255894198413653 Test RE 0.11590385674695501\n",
      "41 Train Loss 0.48744574 Test MSE 0.02021722570910163 Test RE 0.10302163723773888\n",
      "42 Train Loss 0.45224315 Test MSE 0.01704412901546321 Test RE 0.09459214507459696\n",
      "43 Train Loss 0.42178106 Test MSE 0.017405786974796146 Test RE 0.09559044858178908\n",
      "44 Train Loss 0.41300407 Test MSE 0.016939350459810817 Test RE 0.09430094487261652\n",
      "45 Train Loss 0.41001698 Test MSE 0.017588807765818587 Test RE 0.09609169825043551\n",
      "46 Train Loss 0.3933263 Test MSE 0.015370046424295193 Test RE 0.08982666114809167\n",
      "47 Train Loss 0.37712497 Test MSE 0.011930759855760722 Test RE 0.07914103393146231\n",
      "48 Train Loss 0.351484 Test MSE 0.011066679677867812 Test RE 0.07622129750622482\n",
      "49 Train Loss 0.3316863 Test MSE 0.01023317981258372 Test RE 0.07329476729912915\n",
      "50 Train Loss 0.31921232 Test MSE 0.009550348696046068 Test RE 0.07080717732735563\n",
      "51 Train Loss 0.3086626 Test MSE 0.010176311951756325 Test RE 0.0730908266073395\n",
      "52 Train Loss 0.30530894 Test MSE 0.012392980711186505 Test RE 0.08065950538413151\n",
      "53 Train Loss 0.29848367 Test MSE 0.009979977194978664 Test RE 0.07238231051359202\n",
      "54 Train Loss 0.29383025 Test MSE 0.010466288710436528 Test RE 0.07412488334487125\n",
      "55 Train Loss 0.2923263 Test MSE 0.011905647266326204 Test RE 0.07905769962426387\n",
      "56 Train Loss 0.28853074 Test MSE 0.01227131190517291 Test RE 0.08026258911094708\n",
      "57 Train Loss 0.28392443 Test MSE 0.01050264189792242 Test RE 0.07425350295475594\n",
      "58 Train Loss 0.27651605 Test MSE 0.007996504337966538 Test RE 0.06479145848760244\n",
      "59 Train Loss 0.27060923 Test MSE 0.006145369832893147 Test RE 0.05679912949258095\n",
      "60 Train Loss 0.26684812 Test MSE 0.004333763208631192 Test RE 0.04769800961733367\n",
      "61 Train Loss 0.26312727 Test MSE 0.003982320716046956 Test RE 0.045723112265781816\n",
      "62 Train Loss 0.2597811 Test MSE 0.004116654367363341 Test RE 0.04648789380184822\n",
      "63 Train Loss 0.25796574 Test MSE 0.004438379850252682 Test RE 0.048270289280524646\n",
      "64 Train Loss 0.2551221 Test MSE 0.0033916942565236107 Test RE 0.04219645976109905\n",
      "65 Train Loss 0.24786492 Test MSE 0.0029532914196971198 Test RE 0.039375022907651866\n",
      "66 Train Loss 0.23376697 Test MSE 0.0020885409344381617 Test RE 0.033112285919632\n",
      "67 Train Loss 0.21386503 Test MSE 0.0033365505507388263 Test RE 0.04185202944331104\n",
      "68 Train Loss 0.19690762 Test MSE 0.007627074260520495 Test RE 0.06327711281237913\n",
      "69 Train Loss 0.18476465 Test MSE 0.00877509207273859 Test RE 0.067872447248586\n",
      "70 Train Loss 0.17273748 Test MSE 0.005368999024376401 Test RE 0.05309019618165061\n",
      "71 Train Loss 0.15952884 Test MSE 0.00599385435352812 Test RE 0.056094561896316675\n",
      "72 Train Loss 0.15580891 Test MSE 0.007549409546732159 Test RE 0.06295412044758104\n",
      "73 Train Loss 0.15397108 Test MSE 0.007926649270639958 Test RE 0.06450783833403902\n",
      "74 Train Loss 0.15240029 Test MSE 0.009171275936751455 Test RE 0.06938770889283256\n",
      "75 Train Loss 0.14525083 Test MSE 0.009446896678860128 Test RE 0.07042263165618738\n",
      "76 Train Loss 0.14372748 Test MSE 0.010812077467823594 Test RE 0.07533941471703332\n",
      "77 Train Loss 0.14143915 Test MSE 0.008826945303306435 Test RE 0.0680726857058331\n",
      "78 Train Loss 0.13928562 Test MSE 0.009712781791115947 Test RE 0.0714067856003155\n",
      "79 Train Loss 0.134539 Test MSE 0.007360183833986698 Test RE 0.062160142089730065\n",
      "80 Train Loss 0.13007027 Test MSE 0.005282943065550006 Test RE 0.05266300452443389\n",
      "81 Train Loss 0.12559627 Test MSE 0.0037261997085732677 Test RE 0.04422834935870851\n",
      "82 Train Loss 0.113734156 Test MSE 0.004745580880554062 Test RE 0.04991284872185351\n",
      "83 Train Loss 0.108646356 Test MSE 0.00471619730397749 Test RE 0.049758084179003216\n",
      "84 Train Loss 0.105945095 Test MSE 0.005746795456560737 Test RE 0.054926324394807914\n",
      "85 Train Loss 0.105324574 Test MSE 0.006011019463888511 Test RE 0.056174825855986266\n",
      "86 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "87 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "88 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "89 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "90 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "91 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "92 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "93 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "94 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "95 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "96 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "97 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "98 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "99 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "100 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "101 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "102 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "103 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "104 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "105 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "106 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "107 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "108 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "109 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "110 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "111 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "112 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "113 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "114 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "115 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "116 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "117 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "118 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "119 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "120 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "121 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "122 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "123 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "124 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "125 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "126 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "127 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "128 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "129 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "130 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "131 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "132 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "133 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "134 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "135 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "136 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "137 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "138 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "139 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "140 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "141 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "142 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "143 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "144 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "145 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "146 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "147 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "148 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "149 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "150 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "151 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "152 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "153 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "154 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "155 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "156 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "157 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "158 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "159 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "160 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "161 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "162 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "163 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "164 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "165 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "166 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "167 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "168 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "169 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "170 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "171 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "172 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "173 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "174 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "175 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "176 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "177 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "178 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "179 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "180 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "181 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "182 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "183 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "184 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "185 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "186 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "187 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "188 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "189 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "190 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "191 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "192 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "193 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "194 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "195 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "196 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "197 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "198 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "199 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "200 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "201 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "202 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "203 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "204 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "205 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "206 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "207 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "208 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "209 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "210 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "211 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "212 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "213 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "214 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "215 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "216 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "217 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "218 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "219 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "220 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "221 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "222 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "223 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "224 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "225 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "226 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "227 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "228 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "229 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "230 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "231 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "232 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "233 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "234 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "235 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "236 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "237 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "238 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "239 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "240 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "241 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "242 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "243 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "244 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "245 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "246 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "247 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "248 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "249 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "250 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "251 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "252 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "253 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "254 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "255 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "256 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "257 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "258 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "259 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "260 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "261 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "262 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "263 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "264 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "265 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "266 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "267 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "268 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "269 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "270 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "271 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "272 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "273 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "274 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "275 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "276 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "277 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "278 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "279 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "280 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "281 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "282 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "283 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "284 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "285 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "286 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "287 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "288 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "289 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "290 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "291 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "292 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "293 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "294 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "295 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "296 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "297 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "298 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "299 Train Loss 0.10524644 Test MSE 0.005797773321002484 Test RE 0.05516940287299375\n",
      "Training time: 237.58\n",
      "KG_rowdy_medium\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 48224.914 Test MSE 2.4652128964777225 Test RE 1.1376138824286988\n",
      "1 Train Loss 10797.217 Test MSE 4.347119250610479 Test RE 1.5106659645755025\n",
      "2 Train Loss 1273.5579 Test MSE 3.6243402906536732 Test RE 1.379374366799506\n",
      "3 Train Loss 250.3717 Test MSE 2.4432713118697476 Test RE 1.1325399106846852\n",
      "4 Train Loss 85.87355 Test MSE 2.7844513809243905 Test RE 1.2090311412292338\n",
      "5 Train Loss 52.50988 Test MSE 2.0131670276702396 Test RE 1.0280342219960903\n",
      "6 Train Loss 32.47881 Test MSE 1.746261772785583 Test RE 0.9574637517344492\n",
      "7 Train Loss 20.813917 Test MSE 1.3283570167480783 Test RE 0.835074216469574\n",
      "8 Train Loss 16.134394 Test MSE 1.3345800495424645 Test RE 0.8370279917231117\n",
      "9 Train Loss 11.465035 Test MSE 1.3027991049192145 Test RE 0.8270016830678939\n",
      "10 Train Loss 8.573029 Test MSE 1.3737842204823068 Test RE 0.8492331321847743\n",
      "11 Train Loss 7.345214 Test MSE 1.4379780340157788 Test RE 0.8688479757724789\n",
      "12 Train Loss 6.077844 Test MSE 1.4114344428657344 Test RE 0.8607916058509602\n",
      "13 Train Loss 5.2097135 Test MSE 1.3433422046677137 Test RE 0.8397712405774153\n",
      "14 Train Loss 4.7063437 Test MSE 1.3522819125325318 Test RE 0.8425608726482828\n",
      "15 Train Loss 3.7407014 Test MSE 1.3128281398266872 Test RE 0.8301787377126175\n",
      "16 Train Loss 3.465652 Test MSE 1.356395374310498 Test RE 0.8438413786790936\n",
      "17 Train Loss 3.1184149 Test MSE 1.395017956277672 Test RE 0.8557710025954515\n",
      "18 Train Loss 2.8447495 Test MSE 1.4026496763118506 Test RE 0.8581086415982897\n",
      "19 Train Loss 2.6548645 Test MSE 1.4039968186062226 Test RE 0.8585206179580999\n",
      "20 Train Loss 2.4592645 Test MSE 1.3759514105813757 Test RE 0.849902714910299\n",
      "21 Train Loss 2.3616345 Test MSE 1.3852443151789051 Test RE 0.8527679229897358\n",
      "22 Train Loss 2.2619834 Test MSE 1.3656939143753972 Test RE 0.8467288447292056\n",
      "23 Train Loss 2.1491823 Test MSE 1.353696282702959 Test RE 0.8430013804724469\n",
      "24 Train Loss 2.0972917 Test MSE 1.3509003135063957 Test RE 0.8421303489712784\n",
      "25 Train Loss 1.9917734 Test MSE 1.3034444974233508 Test RE 0.8272065015234719\n",
      "26 Train Loss 1.8850915 Test MSE 1.220808469603977 Test RE 0.8005554795199193\n",
      "27 Train Loss 1.7131861 Test MSE 1.1096972991953642 Test RE 0.7632554818494678\n",
      "28 Train Loss 1.6181579 Test MSE 1.0210579658672851 Test RE 0.7321378618422575\n",
      "29 Train Loss 1.5668072 Test MSE 0.9774924145894524 Test RE 0.7163485161263367\n",
      "30 Train Loss 1.5075647 Test MSE 0.8696825804255212 Test RE 0.6756908740085328\n",
      "31 Train Loss 1.4599851 Test MSE 0.8125085270973926 Test RE 0.6531029288998705\n",
      "32 Train Loss 1.4098676 Test MSE 0.7517826543991408 Test RE 0.6282229795184939\n",
      "33 Train Loss 1.2841177 Test MSE 0.7877808813834842 Test RE 0.6430879707919547\n",
      "34 Train Loss 1.2675368 Test MSE 0.7902121373380029 Test RE 0.6440795580610533\n",
      "35 Train Loss 1.2047828 Test MSE 0.7072821108295166 Test RE 0.6093460559855075\n",
      "36 Train Loss 1.1131284 Test MSE 0.631519931400752 Test RE 0.575786129408573\n",
      "37 Train Loss 0.9588784 Test MSE 0.4155794746541213 Test RE 0.46708370076223726\n",
      "38 Train Loss 0.90808463 Test MSE 0.37210313842454007 Test RE 0.44197665848626433\n",
      "39 Train Loss 0.89443535 Test MSE 0.39288400771265275 Test RE 0.45415054875474886\n",
      "40 Train Loss 0.8846474 Test MSE 0.41603450669378494 Test RE 0.4673393436838237\n",
      "41 Train Loss 0.81950676 Test MSE 0.39547882989540384 Test RE 0.45564781070452776\n",
      "42 Train Loss 0.74629974 Test MSE 0.3716911085029548 Test RE 0.4417318902634101\n",
      "43 Train Loss 0.7269604 Test MSE 0.35689812288702616 Test RE 0.4328523697841492\n",
      "44 Train Loss 0.6810269 Test MSE 0.35447284956522757 Test RE 0.43137915550219597\n",
      "45 Train Loss 0.624406 Test MSE 0.2873207291941546 Test RE 0.38837489391070434\n",
      "46 Train Loss 0.5967464 Test MSE 0.25215612434227647 Test RE 0.3638332853172694\n",
      "47 Train Loss 0.57640254 Test MSE 0.23737363441859818 Test RE 0.35300747951164346\n",
      "48 Train Loss 0.5705067 Test MSE 0.24607336061583868 Test RE 0.3594181197235763\n",
      "49 Train Loss 0.47892216 Test MSE 0.22246100036902053 Test RE 0.34173905217602296\n",
      "50 Train Loss 0.4601001 Test MSE 0.20664997949743683 Test RE 0.3293709943525322\n",
      "51 Train Loss 0.45439357 Test MSE 0.20755250763929692 Test RE 0.3300894621857923\n",
      "52 Train Loss 0.4515662 Test MSE 0.2049744866868402 Test RE 0.32803302690374764\n",
      "53 Train Loss 0.422553 Test MSE 0.18568240041713654 Test RE 0.31221447820673814\n",
      "54 Train Loss 0.3644973 Test MSE 0.1587788562824346 Test RE 0.2887114462807078\n",
      "55 Train Loss 0.3515056 Test MSE 0.14442890551059537 Test RE 0.27535611637035984\n",
      "56 Train Loss 0.3356679 Test MSE 0.14005515666960913 Test RE 0.27115475176112636\n",
      "57 Train Loss 0.33266276 Test MSE 0.13530923486030003 Test RE 0.26652097095236027\n",
      "58 Train Loss 0.3258832 Test MSE 0.12617545300230043 Test RE 0.25736832966978057\n",
      "59 Train Loss 0.3044988 Test MSE 0.13160260962409934 Test RE 0.2628451199875185\n",
      "60 Train Loss 0.28436148 Test MSE 0.11328602619583468 Test RE 0.24386857421943614\n",
      "61 Train Loss 0.27609512 Test MSE 0.11302582634552116 Test RE 0.2435883496993106\n",
      "62 Train Loss 0.2741644 Test MSE 0.11142641825839526 Test RE 0.2418587215783118\n",
      "63 Train Loss 0.27259517 Test MSE 0.11231449282466482 Test RE 0.24282062231286464\n",
      "64 Train Loss 0.26930332 Test MSE 0.11138556818126608 Test RE 0.24181438356012003\n",
      "65 Train Loss 0.24875137 Test MSE 0.10583442944954267 Test RE 0.23571170759377097\n",
      "66 Train Loss 0.23571806 Test MSE 0.095101506055476 Test RE 0.22344022753801565\n",
      "67 Train Loss 0.23343694 Test MSE 0.09094879778856116 Test RE 0.2185073997818869\n",
      "68 Train Loss 0.23108041 Test MSE 0.08981082400781634 Test RE 0.217136087501169\n",
      "69 Train Loss 0.22396001 Test MSE 0.0781334707152939 Test RE 0.20252853711827967\n",
      "70 Train Loss 0.21614891 Test MSE 0.07674869714638068 Test RE 0.20072578893839374\n",
      "71 Train Loss 0.20671855 Test MSE 0.07118037780871322 Test RE 0.19330710288245484\n",
      "72 Train Loss 0.19685856 Test MSE 0.06203619561588311 Test RE 0.18046386150688787\n",
      "73 Train Loss 0.19318159 Test MSE 0.059667877263814575 Test RE 0.17698561182466374\n",
      "74 Train Loss 0.18922116 Test MSE 0.057342456392861965 Test RE 0.17350253084791467\n",
      "75 Train Loss 0.18399952 Test MSE 0.04366466487478071 Test RE 0.15140239084408685\n",
      "76 Train Loss 0.18201774 Test MSE 0.040314917647260036 Test RE 0.14547908341690097\n",
      "77 Train Loss 0.18106468 Test MSE 0.040118688244754216 Test RE 0.14512459805595937\n",
      "78 Train Loss 0.17739321 Test MSE 0.037702264485726826 Test RE 0.1406861631397781\n",
      "79 Train Loss 0.17427206 Test MSE 0.03394081414808951 Test RE 0.13348387188369204\n",
      "80 Train Loss 0.17090784 Test MSE 0.028229996117338337 Test RE 0.12173713503983237\n",
      "81 Train Loss 0.16652507 Test MSE 0.02776656592090198 Test RE 0.12073376752856865\n",
      "82 Train Loss 0.1625926 Test MSE 0.02896466110484428 Test RE 0.12331102092082637\n",
      "83 Train Loss 0.16093966 Test MSE 0.029192008101235085 Test RE 0.12379401627973398\n",
      "84 Train Loss 0.15702131 Test MSE 0.03109391514239091 Test RE 0.12776307979577742\n",
      "85 Train Loss 0.15575378 Test MSE 0.03215062298714947 Test RE 0.1299159172741018\n",
      "86 Train Loss 0.15451244 Test MSE 0.0345174047322162 Test RE 0.13461291692866037\n",
      "87 Train Loss 0.15291238 Test MSE 0.03421497172394515 Test RE 0.13402189685703708\n",
      "88 Train Loss 0.15160283 Test MSE 0.03294293253817185 Test RE 0.13150697745632678\n",
      "89 Train Loss 0.15053883 Test MSE 0.02973637557525984 Test RE 0.12494292944561247\n",
      "90 Train Loss 0.14677231 Test MSE 0.02750440023950336 Test RE 0.12016244519271498\n",
      "91 Train Loss 0.14552975 Test MSE 0.027185033749563287 Test RE 0.11946277696650681\n",
      "92 Train Loss 0.14303818 Test MSE 0.02728073016067579 Test RE 0.11967285792421864\n",
      "93 Train Loss 0.14249942 Test MSE 0.026725225584012056 Test RE 0.11844817058848242\n",
      "94 Train Loss 0.14162287 Test MSE 0.023800462086829587 Test RE 0.11177903658358539\n",
      "95 Train Loss 0.1410655 Test MSE 0.02282501170624633 Test RE 0.10946446835246165\n",
      "96 Train Loss 0.14076962 Test MSE 0.021506926349701968 Test RE 0.10625682664506163\n",
      "97 Train Loss 0.140294 Test MSE 0.02053608712632198 Test RE 0.10383087568128695\n",
      "98 Train Loss 0.13912669 Test MSE 0.019704533103298446 Test RE 0.10170697604124018\n",
      "99 Train Loss 0.13750336 Test MSE 0.018800925369964014 Test RE 0.099347577201856\n",
      "100 Train Loss 0.13387087 Test MSE 0.017077041771264793 Test RE 0.09468343124866622\n",
      "101 Train Loss 0.12763926 Test MSE 0.015664696545603114 Test RE 0.090683580816694\n",
      "102 Train Loss 0.12126126 Test MSE 0.015111446480803647 Test RE 0.08906779201908034\n",
      "103 Train Loss 0.11757488 Test MSE 0.015925914094405393 Test RE 0.0914365543671976\n",
      "104 Train Loss 0.11681072 Test MSE 0.015669256416700573 Test RE 0.0906967784981908\n",
      "105 Train Loss 0.116264686 Test MSE 0.016053357911547782 Test RE 0.09180167637950543\n",
      "106 Train Loss 0.11587105 Test MSE 0.016955572241678325 Test RE 0.09434608719682785\n",
      "107 Train Loss 0.1153812 Test MSE 0.017324731284286077 Test RE 0.09536761489622274\n",
      "108 Train Loss 0.115037 Test MSE 0.018050245076421063 Test RE 0.09734400696187825\n",
      "109 Train Loss 0.114742585 Test MSE 0.01853915099338994 Test RE 0.09865352062964619\n",
      "110 Train Loss 0.11398931 Test MSE 0.01918328906392561 Test RE 0.10035273268277772\n",
      "111 Train Loss 0.112767726 Test MSE 0.01989812498731359 Test RE 0.10220537708741677\n",
      "112 Train Loss 0.11003195 Test MSE 0.023281173988914595 Test RE 0.11055289147551772\n",
      "113 Train Loss 0.108545475 Test MSE 0.02493917365428003 Test RE 0.11442177939677799\n",
      "114 Train Loss 0.107187636 Test MSE 0.025406908641067438 Test RE 0.11548978706621418\n",
      "115 Train Loss 0.10426601 Test MSE 0.02507380762471103 Test RE 0.11473021630774305\n",
      "116 Train Loss 0.10231908 Test MSE 0.020976571608512583 Test RE 0.10493851693081523\n",
      "117 Train Loss 0.09953554 Test MSE 0.020078772359962128 Test RE 0.10266827037739272\n",
      "118 Train Loss 0.09759704 Test MSE 0.017104982026160183 Test RE 0.0947608567781118\n",
      "119 Train Loss 0.09617144 Test MSE 0.017632908800983695 Test RE 0.09621208987630102\n",
      "120 Train Loss 0.09483676 Test MSE 0.018097341275551203 Test RE 0.0974709178750717\n",
      "121 Train Loss 0.094084024 Test MSE 0.018097566831376425 Test RE 0.09747152528652729\n",
      "122 Train Loss 0.092683606 Test MSE 0.016607467702916136 Test RE 0.093372583621804\n",
      "123 Train Loss 0.090939194 Test MSE 0.014997400844433156 Test RE 0.0887310595018959\n",
      "124 Train Loss 0.0903783 Test MSE 0.01501527056483554 Test RE 0.08878390623191172\n",
      "125 Train Loss 0.0897364 Test MSE 0.013949022540004173 Test RE 0.08557355131931435\n",
      "126 Train Loss 0.08853163 Test MSE 0.01223902488314615 Test RE 0.08015693020374268\n",
      "127 Train Loss 0.08743298 Test MSE 0.011367250770598036 Test RE 0.07724944859805352\n",
      "128 Train Loss 0.086024664 Test MSE 0.010578284452088796 Test RE 0.07452041901640727\n",
      "129 Train Loss 0.08442587 Test MSE 0.01091626622569496 Test RE 0.07570154218444808\n",
      "130 Train Loss 0.08314641 Test MSE 0.010442418339715272 Test RE 0.07404030711621622\n",
      "131 Train Loss 0.08172179 Test MSE 0.009922127730648052 Test RE 0.07217222168256811\n",
      "132 Train Loss 0.0811852 Test MSE 0.009253440217351099 Test RE 0.0696978336259276\n",
      "133 Train Loss 0.08041211 Test MSE 0.008988496858877926 Test RE 0.0686927974769652\n",
      "134 Train Loss 0.07966049 Test MSE 0.008304071116978355 Test RE 0.06602572786976207\n",
      "135 Train Loss 0.078020446 Test MSE 0.008196885492216255 Test RE 0.06559822705869794\n",
      "136 Train Loss 0.076872915 Test MSE 0.007854406542306517 Test RE 0.06421320633062903\n",
      "137 Train Loss 0.07592273 Test MSE 0.0073697212673077975 Test RE 0.062200403059617305\n",
      "138 Train Loss 0.0753958 Test MSE 0.007656508701854166 Test RE 0.06339909490489734\n",
      "139 Train Loss 0.07507065 Test MSE 0.007871731243593036 Test RE 0.064283985824488\n",
      "140 Train Loss 0.07462929 Test MSE 0.008331218223627266 Test RE 0.0661335632276339\n",
      "141 Train Loss 0.07418242 Test MSE 0.008649068100710224 Test RE 0.06738330773654183\n",
      "142 Train Loss 0.072945684 Test MSE 0.009195294686509805 Test RE 0.0694785095775599\n",
      "143 Train Loss 0.071784645 Test MSE 0.010245592594200516 Test RE 0.07333920686879598\n",
      "144 Train Loss 0.070424825 Test MSE 0.009254514685473164 Test RE 0.06970188000894069\n",
      "145 Train Loss 0.06912482 Test MSE 0.00917900511702382 Test RE 0.06941694131190328\n",
      "146 Train Loss 0.06870291 Test MSE 0.008674291318514857 Test RE 0.06748149094431066\n",
      "147 Train Loss 0.06785184 Test MSE 0.009382862010554067 Test RE 0.07018355009411337\n",
      "148 Train Loss 0.066521876 Test MSE 0.00937470998052226 Test RE 0.07015305498862312\n",
      "149 Train Loss 0.06572278 Test MSE 0.009479715441969372 Test RE 0.07054485062107756\n",
      "150 Train Loss 0.06527564 Test MSE 0.009367317720287812 Test RE 0.0701253905642691\n",
      "151 Train Loss 0.06488628 Test MSE 0.00926834680034887 Test RE 0.06975394996937166\n",
      "152 Train Loss 0.06407345 Test MSE 0.009512282455590071 Test RE 0.0706659231010942\n",
      "153 Train Loss 0.06341041 Test MSE 0.009867053038956694 Test RE 0.07197164000598409\n",
      "154 Train Loss 0.06194784 Test MSE 0.012436833599155544 Test RE 0.08080208725297326\n",
      "155 Train Loss 0.061708156 Test MSE 0.01240596534958351 Test RE 0.08070174947152249\n",
      "156 Train Loss 0.06130216 Test MSE 0.012131324544956508 Test RE 0.07980347049197632\n",
      "157 Train Loss 0.059766416 Test MSE 0.009731765929819395 Test RE 0.07147653567820074\n",
      "158 Train Loss 0.05828334 Test MSE 0.010022478876030408 Test RE 0.07253627386644322\n",
      "159 Train Loss 0.056749485 Test MSE 0.0075093913103311235 Test RE 0.0627870437803467\n",
      "160 Train Loss 0.054194756 Test MSE 0.007160538705899413 Test RE 0.061311298768920885\n",
      "161 Train Loss 0.052892134 Test MSE 0.007339235968911804 Test RE 0.06207162187649217\n",
      "162 Train Loss 0.052633155 Test MSE 0.007040450689733983 Test RE 0.06079500495584796\n",
      "163 Train Loss 0.05241426 Test MSE 0.006530363368075343 Test RE 0.05855127293734209\n",
      "164 Train Loss 0.052189503 Test MSE 0.006514943494616632 Test RE 0.05848210474821076\n",
      "165 Train Loss 0.051796984 Test MSE 0.006940084699548575 Test RE 0.060360114236639596\n",
      "166 Train Loss 0.051308066 Test MSE 0.006798493698708911 Test RE 0.059741210379156334\n",
      "167 Train Loss 0.050965536 Test MSE 0.006336764547845749 Test RE 0.05767683929571607\n",
      "168 Train Loss 0.05076494 Test MSE 0.006095262552781122 Test RE 0.05656709503612\n",
      "169 Train Loss 0.05060307 Test MSE 0.005692231240300636 Test RE 0.05466494744247155\n",
      "170 Train Loss 0.05043338 Test MSE 0.005568011070562129 Test RE 0.05406518740218886\n",
      "171 Train Loss 0.05028369 Test MSE 0.005420566067899702 Test RE 0.05334454174882909\n",
      "172 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "173 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "174 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "175 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "176 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "177 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "178 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "179 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "180 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "181 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "182 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "183 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "184 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "185 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "186 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "187 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "188 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "189 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "190 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "191 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "192 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "193 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "194 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "195 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "196 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "197 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "198 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "199 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "200 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "201 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "202 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "203 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "204 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "205 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "206 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "207 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "208 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "209 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "210 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "211 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "212 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "213 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "214 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "215 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "216 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "217 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "218 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "219 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "220 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "221 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "222 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "223 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "224 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "225 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "226 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "227 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "228 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "229 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "230 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "231 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "232 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "233 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "234 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "235 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "236 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "237 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "238 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "239 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "240 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "241 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "242 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "243 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "244 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "245 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "246 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "247 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "248 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "249 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "250 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "251 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "252 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "253 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "254 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "255 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "256 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "257 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "258 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "259 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "260 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "261 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "262 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "263 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "264 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "265 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "266 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "267 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "268 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "269 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "270 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "271 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "272 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "273 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "274 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "275 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "276 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "277 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "278 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "279 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "280 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "281 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "282 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "283 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "284 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "285 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "286 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "287 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "288 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "289 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "290 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "291 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "292 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "293 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "294 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "295 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "296 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "297 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "298 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "299 Train Loss 0.050269037 Test MSE 0.005384956981667941 Test RE 0.05316903606264454\n",
      "Training time: 331.61\n",
      "KG_rowdy_medium\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss nan Test MSE nan Test RE nan\n",
      "1 Train Loss nan Test MSE nan Test RE nan\n",
      "2 Train Loss nan Test MSE nan Test RE nan\n",
      "3 Train Loss nan Test MSE nan Test RE nan\n",
      "4 Train Loss nan Test MSE nan Test RE nan\n",
      "5 Train Loss nan Test MSE nan Test RE nan\n",
      "6 Train Loss nan Test MSE nan Test RE nan\n",
      "7 Train Loss nan Test MSE nan Test RE nan\n",
      "8 Train Loss nan Test MSE nan Test RE nan\n",
      "9 Train Loss nan Test MSE nan Test RE nan\n",
      "10 Train Loss nan Test MSE nan Test RE nan\n",
      "11 Train Loss nan Test MSE nan Test RE nan\n",
      "12 Train Loss nan Test MSE nan Test RE nan\n",
      "13 Train Loss nan Test MSE nan Test RE nan\n",
      "14 Train Loss nan Test MSE nan Test RE nan\n",
      "15 Train Loss nan Test MSE nan Test RE nan\n",
      "16 Train Loss nan Test MSE nan Test RE nan\n",
      "17 Train Loss nan Test MSE nan Test RE nan\n",
      "18 Train Loss nan Test MSE nan Test RE nan\n",
      "19 Train Loss nan Test MSE nan Test RE nan\n",
      "20 Train Loss nan Test MSE nan Test RE nan\n",
      "21 Train Loss nan Test MSE nan Test RE nan\n",
      "22 Train Loss nan Test MSE nan Test RE nan\n",
      "23 Train Loss nan Test MSE nan Test RE nan\n",
      "24 Train Loss nan Test MSE nan Test RE nan\n",
      "25 Train Loss nan Test MSE nan Test RE nan\n",
      "26 Train Loss nan Test MSE nan Test RE nan\n",
      "27 Train Loss nan Test MSE nan Test RE nan\n",
      "28 Train Loss nan Test MSE nan Test RE nan\n",
      "29 Train Loss nan Test MSE nan Test RE nan\n",
      "30 Train Loss nan Test MSE nan Test RE nan\n",
      "31 Train Loss nan Test MSE nan Test RE nan\n",
      "32 Train Loss nan Test MSE nan Test RE nan\n",
      "33 Train Loss nan Test MSE nan Test RE nan\n",
      "34 Train Loss nan Test MSE nan Test RE nan\n",
      "35 Train Loss nan Test MSE nan Test RE nan\n",
      "36 Train Loss nan Test MSE nan Test RE nan\n",
      "37 Train Loss nan Test MSE nan Test RE nan\n",
      "38 Train Loss nan Test MSE nan Test RE nan\n",
      "39 Train Loss nan Test MSE nan Test RE nan\n",
      "40 Train Loss nan Test MSE nan Test RE nan\n",
      "41 Train Loss nan Test MSE nan Test RE nan\n",
      "42 Train Loss nan Test MSE nan Test RE nan\n",
      "43 Train Loss nan Test MSE nan Test RE nan\n",
      "44 Train Loss nan Test MSE nan Test RE nan\n",
      "45 Train Loss nan Test MSE nan Test RE nan\n",
      "46 Train Loss nan Test MSE nan Test RE nan\n",
      "47 Train Loss nan Test MSE nan Test RE nan\n",
      "48 Train Loss nan Test MSE nan Test RE nan\n",
      "49 Train Loss nan Test MSE nan Test RE nan\n",
      "50 Train Loss nan Test MSE nan Test RE nan\n",
      "51 Train Loss nan Test MSE nan Test RE nan\n",
      "52 Train Loss nan Test MSE nan Test RE nan\n",
      "53 Train Loss nan Test MSE nan Test RE nan\n",
      "54 Train Loss nan Test MSE nan Test RE nan\n",
      "55 Train Loss nan Test MSE nan Test RE nan\n",
      "56 Train Loss nan Test MSE nan Test RE nan\n",
      "57 Train Loss nan Test MSE nan Test RE nan\n",
      "58 Train Loss nan Test MSE nan Test RE nan\n",
      "59 Train Loss nan Test MSE nan Test RE nan\n",
      "60 Train Loss nan Test MSE nan Test RE nan\n",
      "61 Train Loss nan Test MSE nan Test RE nan\n",
      "62 Train Loss nan Test MSE nan Test RE nan\n",
      "63 Train Loss nan Test MSE nan Test RE nan\n",
      "64 Train Loss nan Test MSE nan Test RE nan\n",
      "65 Train Loss nan Test MSE nan Test RE nan\n",
      "66 Train Loss nan Test MSE nan Test RE nan\n",
      "67 Train Loss nan Test MSE nan Test RE nan\n",
      "68 Train Loss nan Test MSE nan Test RE nan\n",
      "69 Train Loss nan Test MSE nan Test RE nan\n",
      "70 Train Loss nan Test MSE nan Test RE nan\n",
      "71 Train Loss nan Test MSE nan Test RE nan\n",
      "72 Train Loss nan Test MSE nan Test RE nan\n",
      "73 Train Loss nan Test MSE nan Test RE nan\n",
      "74 Train Loss nan Test MSE nan Test RE nan\n",
      "75 Train Loss nan Test MSE nan Test RE nan\n",
      "76 Train Loss nan Test MSE nan Test RE nan\n",
      "77 Train Loss nan Test MSE nan Test RE nan\n",
      "78 Train Loss nan Test MSE nan Test RE nan\n",
      "79 Train Loss nan Test MSE nan Test RE nan\n",
      "80 Train Loss nan Test MSE nan Test RE nan\n",
      "81 Train Loss nan Test MSE nan Test RE nan\n",
      "82 Train Loss nan Test MSE nan Test RE nan\n",
      "83 Train Loss nan Test MSE nan Test RE nan\n",
      "84 Train Loss nan Test MSE nan Test RE nan\n",
      "85 Train Loss nan Test MSE nan Test RE nan\n",
      "86 Train Loss nan Test MSE nan Test RE nan\n",
      "87 Train Loss nan Test MSE nan Test RE nan\n",
      "88 Train Loss nan Test MSE nan Test RE nan\n",
      "89 Train Loss nan Test MSE nan Test RE nan\n",
      "90 Train Loss nan Test MSE nan Test RE nan\n",
      "91 Train Loss nan Test MSE nan Test RE nan\n",
      "92 Train Loss nan Test MSE nan Test RE nan\n",
      "93 Train Loss nan Test MSE nan Test RE nan\n",
      "94 Train Loss nan Test MSE nan Test RE nan\n",
      "95 Train Loss nan Test MSE nan Test RE nan\n",
      "96 Train Loss nan Test MSE nan Test RE nan\n",
      "97 Train Loss nan Test MSE nan Test RE nan\n",
      "98 Train Loss nan Test MSE nan Test RE nan\n",
      "99 Train Loss nan Test MSE nan Test RE nan\n",
      "100 Train Loss nan Test MSE nan Test RE nan\n",
      "101 Train Loss nan Test MSE nan Test RE nan\n",
      "102 Train Loss nan Test MSE nan Test RE nan\n",
      "103 Train Loss nan Test MSE nan Test RE nan\n",
      "104 Train Loss nan Test MSE nan Test RE nan\n",
      "105 Train Loss nan Test MSE nan Test RE nan\n",
      "106 Train Loss nan Test MSE nan Test RE nan\n",
      "107 Train Loss nan Test MSE nan Test RE nan\n",
      "108 Train Loss nan Test MSE nan Test RE nan\n",
      "109 Train Loss nan Test MSE nan Test RE nan\n",
      "110 Train Loss nan Test MSE nan Test RE nan\n",
      "111 Train Loss nan Test MSE nan Test RE nan\n",
      "112 Train Loss nan Test MSE nan Test RE nan\n",
      "113 Train Loss nan Test MSE nan Test RE nan\n",
      "114 Train Loss nan Test MSE nan Test RE nan\n",
      "115 Train Loss nan Test MSE nan Test RE nan\n",
      "116 Train Loss nan Test MSE nan Test RE nan\n",
      "117 Train Loss nan Test MSE nan Test RE nan\n",
      "118 Train Loss nan Test MSE nan Test RE nan\n",
      "119 Train Loss nan Test MSE nan Test RE nan\n",
      "120 Train Loss nan Test MSE nan Test RE nan\n",
      "121 Train Loss nan Test MSE nan Test RE nan\n",
      "122 Train Loss nan Test MSE nan Test RE nan\n",
      "123 Train Loss nan Test MSE nan Test RE nan\n",
      "124 Train Loss nan Test MSE nan Test RE nan\n",
      "125 Train Loss nan Test MSE nan Test RE nan\n",
      "126 Train Loss nan Test MSE nan Test RE nan\n",
      "127 Train Loss nan Test MSE nan Test RE nan\n",
      "128 Train Loss nan Test MSE nan Test RE nan\n",
      "129 Train Loss nan Test MSE nan Test RE nan\n",
      "130 Train Loss nan Test MSE nan Test RE nan\n",
      "131 Train Loss nan Test MSE nan Test RE nan\n",
      "132 Train Loss nan Test MSE nan Test RE nan\n",
      "133 Train Loss nan Test MSE nan Test RE nan\n",
      "134 Train Loss nan Test MSE nan Test RE nan\n",
      "135 Train Loss nan Test MSE nan Test RE nan\n",
      "136 Train Loss nan Test MSE nan Test RE nan\n",
      "137 Train Loss nan Test MSE nan Test RE nan\n",
      "138 Train Loss nan Test MSE nan Test RE nan\n",
      "139 Train Loss nan Test MSE nan Test RE nan\n",
      "140 Train Loss nan Test MSE nan Test RE nan\n",
      "141 Train Loss nan Test MSE nan Test RE nan\n",
      "142 Train Loss nan Test MSE nan Test RE nan\n",
      "143 Train Loss nan Test MSE nan Test RE nan\n",
      "144 Train Loss nan Test MSE nan Test RE nan\n",
      "145 Train Loss nan Test MSE nan Test RE nan\n",
      "146 Train Loss nan Test MSE nan Test RE nan\n",
      "147 Train Loss nan Test MSE nan Test RE nan\n",
      "148 Train Loss nan Test MSE nan Test RE nan\n",
      "149 Train Loss nan Test MSE nan Test RE nan\n",
      "150 Train Loss nan Test MSE nan Test RE nan\n",
      "151 Train Loss nan Test MSE nan Test RE nan\n",
      "152 Train Loss nan Test MSE nan Test RE nan\n",
      "153 Train Loss nan Test MSE nan Test RE nan\n",
      "154 Train Loss nan Test MSE nan Test RE nan\n",
      "155 Train Loss nan Test MSE nan Test RE nan\n",
      "156 Train Loss nan Test MSE nan Test RE nan\n",
      "157 Train Loss nan Test MSE nan Test RE nan\n",
      "158 Train Loss nan Test MSE nan Test RE nan\n",
      "159 Train Loss nan Test MSE nan Test RE nan\n",
      "160 Train Loss nan Test MSE nan Test RE nan\n",
      "161 Train Loss nan Test MSE nan Test RE nan\n",
      "162 Train Loss nan Test MSE nan Test RE nan\n",
      "163 Train Loss nan Test MSE nan Test RE nan\n",
      "164 Train Loss nan Test MSE nan Test RE nan\n",
      "165 Train Loss nan Test MSE nan Test RE nan\n",
      "166 Train Loss nan Test MSE nan Test RE nan\n",
      "167 Train Loss nan Test MSE nan Test RE nan\n",
      "168 Train Loss nan Test MSE nan Test RE nan\n",
      "169 Train Loss nan Test MSE nan Test RE nan\n",
      "170 Train Loss nan Test MSE nan Test RE nan\n",
      "171 Train Loss nan Test MSE nan Test RE nan\n",
      "172 Train Loss nan Test MSE nan Test RE nan\n",
      "173 Train Loss nan Test MSE nan Test RE nan\n",
      "174 Train Loss nan Test MSE nan Test RE nan\n",
      "175 Train Loss nan Test MSE nan Test RE nan\n",
      "176 Train Loss nan Test MSE nan Test RE nan\n",
      "177 Train Loss nan Test MSE nan Test RE nan\n",
      "178 Train Loss nan Test MSE nan Test RE nan\n",
      "179 Train Loss nan Test MSE nan Test RE nan\n",
      "180 Train Loss nan Test MSE nan Test RE nan\n",
      "181 Train Loss nan Test MSE nan Test RE nan\n",
      "182 Train Loss nan Test MSE nan Test RE nan\n",
      "183 Train Loss nan Test MSE nan Test RE nan\n",
      "184 Train Loss nan Test MSE nan Test RE nan\n",
      "185 Train Loss nan Test MSE nan Test RE nan\n",
      "186 Train Loss nan Test MSE nan Test RE nan\n",
      "187 Train Loss nan Test MSE nan Test RE nan\n",
      "188 Train Loss nan Test MSE nan Test RE nan\n",
      "189 Train Loss nan Test MSE nan Test RE nan\n",
      "190 Train Loss nan Test MSE nan Test RE nan\n",
      "191 Train Loss nan Test MSE nan Test RE nan\n",
      "192 Train Loss nan Test MSE nan Test RE nan\n",
      "193 Train Loss nan Test MSE nan Test RE nan\n",
      "194 Train Loss nan Test MSE nan Test RE nan\n",
      "195 Train Loss nan Test MSE nan Test RE nan\n",
      "196 Train Loss nan Test MSE nan Test RE nan\n",
      "197 Train Loss nan Test MSE nan Test RE nan\n",
      "198 Train Loss nan Test MSE nan Test RE nan\n",
      "199 Train Loss nan Test MSE nan Test RE nan\n",
      "200 Train Loss nan Test MSE nan Test RE nan\n",
      "201 Train Loss nan Test MSE nan Test RE nan\n",
      "202 Train Loss nan Test MSE nan Test RE nan\n",
      "203 Train Loss nan Test MSE nan Test RE nan\n",
      "204 Train Loss nan Test MSE nan Test RE nan\n",
      "205 Train Loss nan Test MSE nan Test RE nan\n",
      "206 Train Loss nan Test MSE nan Test RE nan\n",
      "207 Train Loss nan Test MSE nan Test RE nan\n",
      "208 Train Loss nan Test MSE nan Test RE nan\n",
      "209 Train Loss nan Test MSE nan Test RE nan\n",
      "210 Train Loss nan Test MSE nan Test RE nan\n",
      "211 Train Loss nan Test MSE nan Test RE nan\n",
      "212 Train Loss nan Test MSE nan Test RE nan\n",
      "213 Train Loss nan Test MSE nan Test RE nan\n",
      "214 Train Loss nan Test MSE nan Test RE nan\n",
      "215 Train Loss nan Test MSE nan Test RE nan\n",
      "216 Train Loss nan Test MSE nan Test RE nan\n",
      "217 Train Loss nan Test MSE nan Test RE nan\n",
      "218 Train Loss nan Test MSE nan Test RE nan\n",
      "219 Train Loss nan Test MSE nan Test RE nan\n",
      "220 Train Loss nan Test MSE nan Test RE nan\n",
      "221 Train Loss nan Test MSE nan Test RE nan\n",
      "222 Train Loss nan Test MSE nan Test RE nan\n",
      "223 Train Loss nan Test MSE nan Test RE nan\n",
      "224 Train Loss nan Test MSE nan Test RE nan\n",
      "225 Train Loss nan Test MSE nan Test RE nan\n",
      "226 Train Loss nan Test MSE nan Test RE nan\n",
      "227 Train Loss nan Test MSE nan Test RE nan\n",
      "228 Train Loss nan Test MSE nan Test RE nan\n",
      "229 Train Loss nan Test MSE nan Test RE nan\n",
      "230 Train Loss nan Test MSE nan Test RE nan\n",
      "231 Train Loss nan Test MSE nan Test RE nan\n",
      "232 Train Loss nan Test MSE nan Test RE nan\n",
      "233 Train Loss nan Test MSE nan Test RE nan\n",
      "234 Train Loss nan Test MSE nan Test RE nan\n",
      "235 Train Loss nan Test MSE nan Test RE nan\n",
      "236 Train Loss nan Test MSE nan Test RE nan\n",
      "237 Train Loss nan Test MSE nan Test RE nan\n",
      "238 Train Loss nan Test MSE nan Test RE nan\n",
      "239 Train Loss nan Test MSE nan Test RE nan\n",
      "240 Train Loss nan Test MSE nan Test RE nan\n",
      "241 Train Loss nan Test MSE nan Test RE nan\n",
      "242 Train Loss nan Test MSE nan Test RE nan\n",
      "243 Train Loss nan Test MSE nan Test RE nan\n",
      "244 Train Loss nan Test MSE nan Test RE nan\n",
      "245 Train Loss nan Test MSE nan Test RE nan\n",
      "246 Train Loss nan Test MSE nan Test RE nan\n",
      "247 Train Loss nan Test MSE nan Test RE nan\n",
      "248 Train Loss nan Test MSE nan Test RE nan\n",
      "249 Train Loss nan Test MSE nan Test RE nan\n",
      "250 Train Loss nan Test MSE nan Test RE nan\n",
      "251 Train Loss nan Test MSE nan Test RE nan\n",
      "252 Train Loss nan Test MSE nan Test RE nan\n",
      "253 Train Loss nan Test MSE nan Test RE nan\n",
      "254 Train Loss nan Test MSE nan Test RE nan\n",
      "255 Train Loss nan Test MSE nan Test RE nan\n",
      "256 Train Loss nan Test MSE nan Test RE nan\n",
      "257 Train Loss nan Test MSE nan Test RE nan\n",
      "258 Train Loss nan Test MSE nan Test RE nan\n",
      "259 Train Loss nan Test MSE nan Test RE nan\n",
      "260 Train Loss nan Test MSE nan Test RE nan\n",
      "261 Train Loss nan Test MSE nan Test RE nan\n",
      "262 Train Loss nan Test MSE nan Test RE nan\n",
      "263 Train Loss nan Test MSE nan Test RE nan\n",
      "264 Train Loss nan Test MSE nan Test RE nan\n",
      "265 Train Loss nan Test MSE nan Test RE nan\n",
      "266 Train Loss nan Test MSE nan Test RE nan\n",
      "267 Train Loss nan Test MSE nan Test RE nan\n",
      "268 Train Loss nan Test MSE nan Test RE nan\n",
      "269 Train Loss nan Test MSE nan Test RE nan\n",
      "270 Train Loss nan Test MSE nan Test RE nan\n",
      "271 Train Loss nan Test MSE nan Test RE nan\n",
      "272 Train Loss nan Test MSE nan Test RE nan\n",
      "273 Train Loss nan Test MSE nan Test RE nan\n",
      "274 Train Loss nan Test MSE nan Test RE nan\n",
      "275 Train Loss nan Test MSE nan Test RE nan\n",
      "276 Train Loss nan Test MSE nan Test RE nan\n",
      "277 Train Loss nan Test MSE nan Test RE nan\n",
      "278 Train Loss nan Test MSE nan Test RE nan\n",
      "279 Train Loss nan Test MSE nan Test RE nan\n",
      "280 Train Loss nan Test MSE nan Test RE nan\n",
      "281 Train Loss nan Test MSE nan Test RE nan\n",
      "282 Train Loss nan Test MSE nan Test RE nan\n",
      "283 Train Loss nan Test MSE nan Test RE nan\n",
      "284 Train Loss nan Test MSE nan Test RE nan\n",
      "285 Train Loss nan Test MSE nan Test RE nan\n",
      "286 Train Loss nan Test MSE nan Test RE nan\n",
      "287 Train Loss nan Test MSE nan Test RE nan\n",
      "288 Train Loss nan Test MSE nan Test RE nan\n",
      "289 Train Loss nan Test MSE nan Test RE nan\n",
      "290 Train Loss nan Test MSE nan Test RE nan\n",
      "291 Train Loss nan Test MSE nan Test RE nan\n",
      "292 Train Loss nan Test MSE nan Test RE nan\n",
      "293 Train Loss nan Test MSE nan Test RE nan\n",
      "294 Train Loss nan Test MSE nan Test RE nan\n",
      "295 Train Loss nan Test MSE nan Test RE nan\n",
      "296 Train Loss nan Test MSE nan Test RE nan\n",
      "297 Train Loss nan Test MSE nan Test RE nan\n",
      "298 Train Loss nan Test MSE nan Test RE nan\n",
      "299 Train Loss nan Test MSE nan Test RE nan\n",
      "Training time: 25.67\n",
      "KG_rowdy_medium\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 17915.543 Test MSE 1.214387938357674 Test RE 0.7984475454959613\n",
      "1 Train Loss 3859.3967 Test MSE 1.2052667445081502 Test RE 0.7954433483334209\n",
      "2 Train Loss 1394.9655 Test MSE 2.3530824974411884 Test RE 1.1114405673624972\n",
      "3 Train Loss 487.41245 Test MSE 3.178432432535848 Test RE 1.2917371782441973\n",
      "4 Train Loss 275.344 Test MSE 2.995722859084632 Test RE 1.254060487090281\n",
      "5 Train Loss 125.73967 Test MSE 3.2618634510558926 Test RE 1.3085808362940463\n",
      "6 Train Loss 81.616104 Test MSE 4.091218203531225 Test RE 1.4655275572597177\n",
      "7 Train Loss 65.84552 Test MSE 4.328459299826498 Test RE 1.507420221107608\n",
      "8 Train Loss 54.716686 Test MSE 4.300675013045229 Test RE 1.502574383331555\n",
      "9 Train Loss 43.814003 Test MSE 4.441027580108639 Test RE 1.5268958080650592\n",
      "10 Train Loss 40.954536 Test MSE 4.20083537714956 Test RE 1.4850309294000383\n",
      "11 Train Loss 36.720314 Test MSE 4.217981690834003 Test RE 1.4880585267976358\n",
      "12 Train Loss 32.09475 Test MSE 3.893271975581233 Test RE 1.4296345639895378\n",
      "13 Train Loss 27.070116 Test MSE 3.7824619986953847 Test RE 1.4091426326707863\n",
      "14 Train Loss 23.433048 Test MSE 3.589285280815868 Test RE 1.3726874295611553\n",
      "15 Train Loss 20.737461 Test MSE 3.437762731590877 Test RE 1.3434008452536752\n",
      "16 Train Loss 17.643223 Test MSE 3.2861475568994107 Test RE 1.3134429021069491\n",
      "17 Train Loss 15.375527 Test MSE 3.191718312235064 Test RE 1.294434100124703\n",
      "18 Train Loss 12.973111 Test MSE 2.87108225651973 Test RE 1.2276949947662785\n",
      "19 Train Loss 10.018144 Test MSE 2.5667078132177785 Test RE 1.160795949402153\n",
      "20 Train Loss 8.951923 Test MSE 2.5286254010797022 Test RE 1.1521523654213761\n",
      "21 Train Loss 8.064841 Test MSE 2.3267793885624672 Test RE 1.105211185567495\n",
      "22 Train Loss 7.636889 Test MSE 2.4057995548759106 Test RE 1.1238216328890362\n",
      "23 Train Loss 7.336412 Test MSE 2.3013120635966438 Test RE 1.0991461035580607\n",
      "24 Train Loss 7.028486 Test MSE 2.209117959456107 Test RE 1.076904324187239\n",
      "25 Train Loss 6.2803025 Test MSE 1.939695332985584 Test RE 1.0091005156064765\n",
      "26 Train Loss 6.1485014 Test MSE 1.9566727872210112 Test RE 1.0135070410112281\n",
      "27 Train Loss 5.7789288 Test MSE 1.7133174358090242 Test RE 0.9483891677345571\n",
      "28 Train Loss 5.470789 Test MSE 1.6338955998382352 Test RE 0.9261467760014777\n",
      "29 Train Loss 5.2426043 Test MSE 1.6014932990609523 Test RE 0.9169174344448119\n",
      "30 Train Loss 4.715879 Test MSE 1.6106594521424669 Test RE 0.9195376807851208\n",
      "31 Train Loss 4.6096034 Test MSE 1.5180213905343622 Test RE 0.8927022169023607\n",
      "32 Train Loss 4.362744 Test MSE 1.4403609740135068 Test RE 0.8695675818826827\n",
      "33 Train Loss 4.028459 Test MSE 1.3151137296868858 Test RE 0.8309010801568504\n",
      "34 Train Loss 3.9327378 Test MSE 1.242572419877123 Test RE 0.8076599031220038\n",
      "35 Train Loss 3.7474544 Test MSE 1.22889651920572 Test RE 0.8032030051571274\n",
      "36 Train Loss 3.6300852 Test MSE 1.1846224984512217 Test RE 0.7886016037000464\n",
      "37 Train Loss 3.5797954 Test MSE 1.1668819447043923 Test RE 0.782674397589554\n",
      "38 Train Loss 3.5475929 Test MSE 1.1386426519447637 Test RE 0.773145783230185\n",
      "39 Train Loss 3.4414437 Test MSE 1.0783949611234476 Test RE 0.7524135232802794\n",
      "40 Train Loss 3.1903112 Test MSE 1.068608299086243 Test RE 0.7489915860653084\n",
      "41 Train Loss 3.1708329 Test MSE 1.0918241361464693 Test RE 0.7570839040791209\n",
      "42 Train Loss 3.000922 Test MSE 1.009051595647532 Test RE 0.7278206181751044\n",
      "43 Train Loss 2.7250745 Test MSE 0.8714325579520258 Test RE 0.6763703458293729\n",
      "44 Train Loss 2.6875124 Test MSE 0.8319686148864891 Test RE 0.6608777632856582\n",
      "45 Train Loss 2.6494026 Test MSE 0.7858705071976844 Test RE 0.6423077510659988\n",
      "46 Train Loss 2.5660787 Test MSE 0.8428467697106131 Test RE 0.6651842858283288\n",
      "47 Train Loss 2.4629984 Test MSE 0.759484611296587 Test RE 0.6314328279522371\n",
      "48 Train Loss 2.3578405 Test MSE 0.6529210877912127 Test RE 0.5854610609288028\n",
      "49 Train Loss 2.3415763 Test MSE 0.6689654457871709 Test RE 0.5926107296995548\n",
      "50 Train Loss 2.2201114 Test MSE 0.7238706487892794 Test RE 0.6164504179174543\n",
      "51 Train Loss 2.0966563 Test MSE 0.6554889142066173 Test RE 0.5866111900857042\n",
      "52 Train Loss 2.071075 Test MSE 0.6724051578286202 Test RE 0.5941323304763552\n",
      "53 Train Loss 1.9103637 Test MSE 0.6989825819500887 Test RE 0.6057603517460284\n",
      "54 Train Loss 1.8681986 Test MSE 0.6883444546098129 Test RE 0.6011330095034159\n",
      "55 Train Loss 1.8040243 Test MSE 0.6270377656763899 Test RE 0.5737391913376587\n",
      "56 Train Loss 1.7829663 Test MSE 0.5866443441288226 Test RE 0.5549516048195721\n",
      "57 Train Loss 1.7636621 Test MSE 0.555958687418052 Test RE 0.5402427259861585\n",
      "58 Train Loss 1.7458496 Test MSE 0.5347752324766079 Test RE 0.5298504533258453\n",
      "59 Train Loss 1.6600817 Test MSE 0.49709373391655015 Test RE 0.5108422534402691\n",
      "60 Train Loss 1.6138617 Test MSE 0.47693723974597524 Test RE 0.5003780895072507\n",
      "61 Train Loss 1.5969592 Test MSE 0.4889333668050587 Test RE 0.5066318699001406\n",
      "62 Train Loss 1.530142 Test MSE 0.5536150478964764 Test RE 0.5391028289064271\n",
      "63 Train Loss 1.4877394 Test MSE 0.5838449882204706 Test RE 0.5536259594223244\n",
      "64 Train Loss 1.4051708 Test MSE 0.5578966322844319 Test RE 0.5411834881879726\n",
      "65 Train Loss 1.3607184 Test MSE 0.5243241126395753 Test RE 0.5246474700003414\n",
      "66 Train Loss 1.3423426 Test MSE 0.4980151197580954 Test RE 0.5113154689340313\n",
      "67 Train Loss 1.3371954 Test MSE 0.4877817295265281 Test RE 0.5060348559080937\n",
      "68 Train Loss 1.3242674 Test MSE 0.46423515795340803 Test RE 0.49366993785123486\n",
      "69 Train Loss 1.2932049 Test MSE 0.4246833418647801 Test RE 0.4721720555422491\n",
      "70 Train Loss 1.2134751 Test MSE 0.39233116514756017 Test RE 0.4538309097066828\n",
      "71 Train Loss 1.1835238 Test MSE 0.40159520984021585 Test RE 0.4591577611884961\n",
      "72 Train Loss 1.1747828 Test MSE 0.37824346553958965 Test RE 0.4456084160751845\n",
      "73 Train Loss 1.1699136 Test MSE 0.3584176510539646 Test RE 0.43377284641822855\n",
      "74 Train Loss 1.1593825 Test MSE 0.34147205737681663 Test RE 0.4233945400896048\n",
      "75 Train Loss 1.1424301 Test MSE 0.34158690753072696 Test RE 0.4234657360175817\n",
      "76 Train Loss 1.1083856 Test MSE 0.332670244904323 Test RE 0.41790218956889974\n",
      "77 Train Loss 1.040135 Test MSE 0.35252337313017584 Test RE 0.43019130297577585\n",
      "78 Train Loss 1.0315967 Test MSE 0.35595398008126733 Test RE 0.43227945406830054\n",
      "79 Train Loss 1.026471 Test MSE 0.34884167485515805 Test RE 0.4279389819031056\n",
      "80 Train Loss 1.0038903 Test MSE 0.34077122412430055 Test RE 0.42295983192912445\n",
      "81 Train Loss 0.9633771 Test MSE 0.3214767613563358 Test RE 0.41081137459307504\n",
      "82 Train Loss 0.9473614 Test MSE 0.31438560049510245 Test RE 0.40625525411577146\n",
      "83 Train Loss 0.93789434 Test MSE 0.3013538178235451 Test RE 0.3977461793239661\n",
      "84 Train Loss 0.92246187 Test MSE 0.28246322811462365 Test RE 0.3850779283350915\n",
      "85 Train Loss 0.9131178 Test MSE 0.279414310611181 Test RE 0.38299401762755647\n",
      "86 Train Loss 0.8867141 Test MSE 0.2342096650502402 Test RE 0.35064695684285774\n",
      "87 Train Loss 0.86572206 Test MSE 0.20158797944019602 Test RE 0.3253119250091628\n",
      "88 Train Loss 0.8456161 Test MSE 0.20508715236650835 Test RE 0.3281231673581936\n",
      "89 Train Loss 0.8312988 Test MSE 0.19472530641327188 Test RE 0.31972667084209494\n",
      "90 Train Loss 0.8137812 Test MSE 0.19043994811885345 Test RE 0.3161889547467297\n",
      "91 Train Loss 0.79823214 Test MSE 0.19064464384106766 Test RE 0.31635883807363074\n",
      "92 Train Loss 0.78946215 Test MSE 0.18931429358581697 Test RE 0.31525310321679956\n",
      "93 Train Loss 0.7813433 Test MSE 0.18643268032241642 Test RE 0.31284461896307675\n",
      "94 Train Loss 0.7735868 Test MSE 0.18119076419823682 Test RE 0.30841514477105203\n",
      "95 Train Loss 0.76985663 Test MSE 0.17328426208738623 Test RE 0.30161103592670446\n",
      "96 Train Loss 0.76112896 Test MSE 0.179516073490306 Test RE 0.3069865427403425\n",
      "97 Train Loss 0.74198776 Test MSE 0.15865535602636907 Test RE 0.28859914268282866\n",
      "98 Train Loss 0.72823983 Test MSE 0.15401574949538713 Test RE 0.28434803701246164\n",
      "99 Train Loss 0.7068237 Test MSE 0.14704265717891388 Test RE 0.2778365251719644\n",
      "100 Train Loss 0.68625265 Test MSE 0.13252207926264406 Test RE 0.26376173342904113\n",
      "101 Train Loss 0.67628527 Test MSE 0.13186582764036883 Test RE 0.2631078465829571\n",
      "102 Train Loss 0.6705816 Test MSE 0.13735541910473062 Test RE 0.2685286118855271\n",
      "103 Train Loss 0.6655122 Test MSE 0.14331675871448207 Test RE 0.2742939043746358\n",
      "104 Train Loss 0.6589998 Test MSE 0.13813658449370173 Test RE 0.2692911149620444\n",
      "105 Train Loss 0.6166494 Test MSE 0.12327773627527083 Test RE 0.25439583288943124\n",
      "106 Train Loss 0.59066284 Test MSE 0.11661226376271087 Test RE 0.24742283613809146\n",
      "107 Train Loss 0.5767221 Test MSE 0.09793583387035901 Test RE 0.22674539745152406\n",
      "108 Train Loss 0.5590508 Test MSE 0.09773545483945349 Test RE 0.22651331545816472\n",
      "109 Train Loss 0.5550475 Test MSE 0.09677648541737804 Test RE 0.2253993143682845\n",
      "110 Train Loss 0.5521504 Test MSE 0.09251390325245434 Test RE 0.22037948811502364\n",
      "111 Train Loss 0.54940736 Test MSE 0.0926622040781149 Test RE 0.2205560527815076\n",
      "112 Train Loss 0.53838634 Test MSE 0.08851754164407824 Test RE 0.21556703070021552\n",
      "113 Train Loss 0.5323667 Test MSE 0.09098289795360552 Test RE 0.2185483593122996\n",
      "114 Train Loss 0.52417874 Test MSE 0.08315416363290874 Test RE 0.2089342639764389\n",
      "115 Train Loss 0.5163646 Test MSE 0.08261657766869512 Test RE 0.20825779603117064\n",
      "116 Train Loss 0.50727403 Test MSE 0.08272412809249907 Test RE 0.20839330714822785\n",
      "117 Train Loss 0.5021872 Test MSE 0.0792666027009065 Test RE 0.2039918376044354\n",
      "118 Train Loss 0.4980687 Test MSE 0.07831577436935339 Test RE 0.20276467267186277\n",
      "119 Train Loss 0.49252656 Test MSE 0.07895251400699008 Test RE 0.2035872843403761\n",
      "120 Train Loss 0.4833951 Test MSE 0.07800512701292779 Test RE 0.20236212991085692\n",
      "121 Train Loss 0.47975045 Test MSE 0.07671474744679893 Test RE 0.20068138861462037\n",
      "122 Train Loss 0.46717447 Test MSE 0.07163212794221807 Test RE 0.19391954970100847\n",
      "123 Train Loss 0.4547262 Test MSE 0.07007517554068268 Test RE 0.1918005131780432\n",
      "124 Train Loss 0.44571137 Test MSE 0.07309357043680527 Test RE 0.1958877401043894\n",
      "125 Train Loss 0.4368982 Test MSE 0.07475916461787924 Test RE 0.19810703018984852\n",
      "126 Train Loss 0.43214145 Test MSE 0.07545457278718153 Test RE 0.1990262911057511\n",
      "127 Train Loss 0.4281094 Test MSE 0.07207911821762969 Test RE 0.1945236456066081\n",
      "128 Train Loss 0.4215677 Test MSE 0.06909534651712175 Test RE 0.190454863436966\n",
      "129 Train Loss 0.41557673 Test MSE 0.06808525369813072 Test RE 0.18905762492548364\n",
      "130 Train Loss 0.4055386 Test MSE 0.06653372293239088 Test RE 0.1868910828351478\n",
      "131 Train Loss 0.4023715 Test MSE 0.06541691360615443 Test RE 0.18531590407890677\n",
      "132 Train Loss 0.39988983 Test MSE 0.06503821435418565 Test RE 0.1847787275890702\n",
      "133 Train Loss 0.3974862 Test MSE 0.06384332908509763 Test RE 0.18307347711462396\n",
      "134 Train Loss 0.39592195 Test MSE 0.06336077055023143 Test RE 0.18238028614219445\n",
      "135 Train Loss 0.39476806 Test MSE 0.06051661304968215 Test RE 0.1782399183402027\n",
      "136 Train Loss 0.3932336 Test MSE 0.06111939094149132 Test RE 0.17912540137765304\n",
      "137 Train Loss 0.39102775 Test MSE 0.06136282790839654 Test RE 0.17948177281600955\n",
      "138 Train Loss 0.38836774 Test MSE 0.06333510167131402 Test RE 0.18234333921365803\n",
      "139 Train Loss 0.37664968 Test MSE 0.06287307495441158 Test RE 0.1816770285853862\n",
      "140 Train Loss 0.35616443 Test MSE 0.058683033411568865 Test RE 0.17551892292462207\n",
      "141 Train Loss 0.35107198 Test MSE 0.057169123649184986 Test RE 0.17324010373527526\n",
      "142 Train Loss 0.34777012 Test MSE 0.05631702864679394 Test RE 0.1719442012802114\n",
      "143 Train Loss 0.3448577 Test MSE 0.05513054756843751 Test RE 0.17012330870263004\n",
      "144 Train Loss 0.34317976 Test MSE 0.05683058448273278 Test RE 0.17272640298573746\n",
      "145 Train Loss 0.34223488 Test MSE 0.05700367366005206 Test RE 0.17298923981431077\n",
      "146 Train Loss 0.34118223 Test MSE 0.05720578734842324 Test RE 0.17329564599851777\n",
      "147 Train Loss 0.33921278 Test MSE 0.056696645706067327 Test RE 0.17252274143219404\n",
      "148 Train Loss 0.33594295 Test MSE 0.05380274128902298 Test RE 0.1680621323738979\n",
      "149 Train Loss 0.33323067 Test MSE 0.05192221115325462 Test RE 0.1650989294386765\n",
      "150 Train Loss 0.32989767 Test MSE 0.048409065899612524 Test RE 0.1594156737299263\n",
      "151 Train Loss 0.32837918 Test MSE 0.04739559089605329 Test RE 0.15773811212745087\n",
      "152 Train Loss 0.32304725 Test MSE 0.04964961751829961 Test RE 0.16144537988992344\n",
      "153 Train Loss 0.31889495 Test MSE 0.04355476483432151 Test RE 0.1512117376932844\n",
      "154 Train Loss 0.31537005 Test MSE 0.04416274763844114 Test RE 0.15226346565465312\n",
      "155 Train Loss 0.31271785 Test MSE 0.04237331033630017 Test RE 0.14914677413642868\n",
      "156 Train Loss 0.3104023 Test MSE 0.04142732334889772 Test RE 0.14747252108513628\n",
      "157 Train Loss 0.30828518 Test MSE 0.04085075176463391 Test RE 0.1464426887850772\n",
      "158 Train Loss 0.30660146 Test MSE 0.04000038520551318 Test RE 0.144910466471274\n",
      "159 Train Loss 0.30543113 Test MSE 0.03850056279578102 Test RE 0.14216778813253694\n",
      "160 Train Loss 0.30456674 Test MSE 0.03579562613266964 Test RE 0.1370826998752587\n",
      "161 Train Loss 0.30381063 Test MSE 0.03482148317403114 Test RE 0.13520454791116893\n",
      "162 Train Loss 0.30284134 Test MSE 0.035712060893677705 Test RE 0.13692259592840608\n",
      "163 Train Loss 0.30159074 Test MSE 0.03563125089905851 Test RE 0.13676759254269363\n",
      "164 Train Loss 0.3003113 Test MSE 0.03524982985842019 Test RE 0.13603359649213495\n",
      "165 Train Loss 0.29876283 Test MSE 0.03608957354539089 Test RE 0.13764439865161887\n",
      "166 Train Loss 0.2972874 Test MSE 0.03631267318080433 Test RE 0.13806919035339835\n",
      "167 Train Loss 0.29542297 Test MSE 0.033923555905919466 Test RE 0.13344993059552146\n",
      "168 Train Loss 0.29103982 Test MSE 0.03154445825003246 Test RE 0.12868537848850306\n",
      "169 Train Loss 0.2830651 Test MSE 0.027273608907679173 Test RE 0.1196572374420061\n",
      "170 Train Loss 0.27790385 Test MSE 0.023586115094869624 Test RE 0.11127455710582793\n",
      "171 Train Loss 0.27322936 Test MSE 0.02111100590844752 Test RE 0.10527424399210976\n",
      "172 Train Loss 0.270071 Test MSE 0.019545975673344686 Test RE 0.10129694427102441\n",
      "173 Train Loss 0.26890823 Test MSE 0.019351414849959194 Test RE 0.10079152803397334\n",
      "174 Train Loss 0.26665986 Test MSE 0.018701640038027052 Test RE 0.0990849089076012\n",
      "175 Train Loss 0.26565453 Test MSE 0.017227630801601734 Test RE 0.09509998438958149\n",
      "176 Train Loss 0.26482084 Test MSE 0.017519543075499754 Test RE 0.09590230715189545\n",
      "177 Train Loss 0.26342252 Test MSE 0.01790222385499069 Test RE 0.09694405004328377\n",
      "178 Train Loss 0.26254836 Test MSE 0.017397705023492253 Test RE 0.09556825346208477\n",
      "179 Train Loss 0.26121333 Test MSE 0.018118873889554684 Test RE 0.09752888715601976\n",
      "180 Train Loss 0.25884423 Test MSE 0.015893046499575018 Test RE 0.09134215313610472\n",
      "181 Train Loss 0.25631055 Test MSE 0.01662638320382125 Test RE 0.09342574303768203\n",
      "182 Train Loss 0.2549587 Test MSE 0.016065920570575175 Test RE 0.09183758935259645\n",
      "183 Train Loss 0.25335395 Test MSE 0.015383865883248525 Test RE 0.08986703438174844\n",
      "184 Train Loss 0.25171563 Test MSE 0.014646661229103889 Test RE 0.08768735817857247\n",
      "185 Train Loss 0.24928984 Test MSE 0.013992184472633696 Test RE 0.08570584256332615\n",
      "186 Train Loss 0.24803968 Test MSE 0.012675213321063472 Test RE 0.08157278805956415\n",
      "187 Train Loss 0.24644634 Test MSE 0.012533211863093988 Test RE 0.08111456774597345\n",
      "188 Train Loss 0.24486889 Test MSE 0.013079870894686735 Test RE 0.08286466830760719\n",
      "189 Train Loss 0.24333599 Test MSE 0.013418923821908122 Test RE 0.08393179503064281\n",
      "190 Train Loss 0.24187881 Test MSE 0.013325045978310315 Test RE 0.0836376892861133\n",
      "191 Train Loss 0.2401211 Test MSE 0.013100603147111747 Test RE 0.08293031463567938\n",
      "192 Train Loss 0.23639119 Test MSE 0.010510972797803412 Test RE 0.07428294677862796\n",
      "193 Train Loss 0.23527783 Test MSE 0.010126421401898804 Test RE 0.07291143834103715\n",
      "194 Train Loss 0.23452753 Test MSE 0.009923688606818382 Test RE 0.072177898260919\n",
      "195 Train Loss 0.23145935 Test MSE 0.009502355683944617 Test RE 0.07062904091254839\n",
      "196 Train Loss 0.2298611 Test MSE 0.008985209132107656 Test RE 0.0686802334293718\n",
      "197 Train Loss 0.22815949 Test MSE 0.008517566294679021 Test RE 0.06686909243725316\n",
      "198 Train Loss 0.22500877 Test MSE 0.00852098576073028 Test RE 0.06688251373853912\n",
      "199 Train Loss 0.22209935 Test MSE 0.009053133211782848 Test RE 0.0689393402765297\n",
      "200 Train Loss 0.22015601 Test MSE 0.009168573654920253 Test RE 0.06937748572648694\n",
      "201 Train Loss 0.2183341 Test MSE 0.009001124597050655 Test RE 0.06874103302893986\n",
      "202 Train Loss 0.21532844 Test MSE 0.009142041378979643 Test RE 0.0692770297399185\n",
      "203 Train Loss 0.21363786 Test MSE 0.009742439131616834 Test RE 0.07151572046944456\n",
      "204 Train Loss 0.21271846 Test MSE 0.0091737587948625 Test RE 0.06939710061644057\n",
      "205 Train Loss 0.21160758 Test MSE 0.009007136275491283 Test RE 0.06876398460596539\n",
      "206 Train Loss 0.21054138 Test MSE 0.008700546035367152 Test RE 0.06758353783082716\n",
      "207 Train Loss 0.20942605 Test MSE 0.008670899315929256 Test RE 0.06746829564311581\n",
      "208 Train Loss 0.20851521 Test MSE 0.009221962656146929 Test RE 0.06957918657559609\n",
      "209 Train Loss 0.20627727 Test MSE 0.009254710509937583 Test RE 0.0697026174469146\n",
      "210 Train Loss 0.20543987 Test MSE 0.009580339546470477 Test RE 0.07091826766503032\n",
      "211 Train Loss 0.20453033 Test MSE 0.008967226252856854 Test RE 0.06861147114971554\n",
      "212 Train Loss 0.20276667 Test MSE 0.00847021528241747 Test RE 0.06668296344536515\n",
      "213 Train Loss 0.19943276 Test MSE 0.006860959138044227 Test RE 0.06001503781047483\n",
      "214 Train Loss 0.19098067 Test MSE 0.006135610744513528 Test RE 0.05675401195041543\n",
      "215 Train Loss 0.18842204 Test MSE 0.005900549951311394 Test RE 0.05565624642845509\n",
      "216 Train Loss 0.18486527 Test MSE 0.006400588238973962 Test RE 0.057966571226943445\n",
      "217 Train Loss 0.18210222 Test MSE 0.006768796212002908 Test RE 0.05961058544820533\n",
      "218 Train Loss 0.17877194 Test MSE 0.006464730359061527 Test RE 0.05825629695106359\n",
      "219 Train Loss 0.1762137 Test MSE 0.0058778734597456535 Test RE 0.05554919680286919\n",
      "220 Train Loss 0.17381164 Test MSE 0.005878695468888059 Test RE 0.05555308089050871\n",
      "221 Train Loss 0.17205779 Test MSE 0.004991218411601123 Test RE 0.05118832927943677\n",
      "222 Train Loss 0.17032251 Test MSE 0.00449765336326978 Test RE 0.04859153943038808\n",
      "223 Train Loss 0.16918807 Test MSE 0.00411560175405252 Test RE 0.04648195003053694\n",
      "224 Train Loss 0.16850185 Test MSE 0.004232021080315166 Test RE 0.04713479024973418\n",
      "225 Train Loss 0.16785422 Test MSE 0.0039350612416601816 Test RE 0.04545099713400567\n",
      "226 Train Loss 0.16715938 Test MSE 0.0040889545456109224 Test RE 0.04633122776556796\n",
      "227 Train Loss 0.16638193 Test MSE 0.004061175292786107 Test RE 0.04617357862876039\n",
      "228 Train Loss 0.16572332 Test MSE 0.004037022715172355 Test RE 0.04603607237718104\n",
      "229 Train Loss 0.16521636 Test MSE 0.0039992797736109345 Test RE 0.04582036675029855\n",
      "230 Train Loss 0.1649133 Test MSE 0.004021720483701252 Test RE 0.04594874026292391\n",
      "231 Train Loss 0.16433142 Test MSE 0.004132795684058749 Test RE 0.046578943673414086\n",
      "232 Train Loss 0.16357587 Test MSE 0.004124779444393037 Test RE 0.04653374797029422\n",
      "233 Train Loss 0.16315505 Test MSE 0.004073301075161921 Test RE 0.04624245936161545\n",
      "234 Train Loss 0.1626689 Test MSE 0.004124852929077376 Test RE 0.04653416247761477\n",
      "235 Train Loss 0.16208178 Test MSE 0.004178846533400496 Test RE 0.04683773431106694\n",
      "236 Train Loss 0.16111168 Test MSE 0.004453019005411726 Test RE 0.04834982895047886\n",
      "237 Train Loss 0.15979485 Test MSE 0.004559329756366575 Test RE 0.04892357329168684\n",
      "238 Train Loss 0.15899907 Test MSE 0.004470130587559226 Test RE 0.04844263663747425\n",
      "239 Train Loss 0.15783864 Test MSE 0.0042563778919429635 Test RE 0.04727023452761539\n",
      "240 Train Loss 0.15671024 Test MSE 0.003908732524472294 Test RE 0.045298690122115834\n",
      "241 Train Loss 0.15452974 Test MSE 0.0038675822033831723 Test RE 0.04505961163242537\n",
      "242 Train Loss 0.1539783 Test MSE 0.0038999066082713012 Test RE 0.04524751900921383\n",
      "243 Train Loss 0.15356366 Test MSE 0.004029912242499534 Test RE 0.04599551247433939\n",
      "244 Train Loss 0.15234563 Test MSE 0.004027541036939204 Test RE 0.04598197857377821\n",
      "245 Train Loss 0.15202565 Test MSE 0.0038985881821781017 Test RE 0.0452398700372723\n",
      "246 Train Loss 0.15157038 Test MSE 0.003794156690339971 Test RE 0.0446298368078003\n",
      "247 Train Loss 0.15058374 Test MSE 0.0037016404799136127 Test RE 0.04408235478634953\n",
      "248 Train Loss 0.14947976 Test MSE 0.0037276158593683105 Test RE 0.044236753103419776\n",
      "249 Train Loss 0.14779781 Test MSE 0.0037899847868510203 Test RE 0.04460529346425899\n",
      "250 Train Loss 0.14662428 Test MSE 0.0038778656885478133 Test RE 0.04511947619632523\n",
      "251 Train Loss 0.14527702 Test MSE 0.003814436572925034 Test RE 0.04474895176732679\n",
      "252 Train Loss 0.1439181 Test MSE 0.003594417963806214 Test RE 0.04343921372601936\n",
      "253 Train Loss 0.1419429 Test MSE 0.0037262118379113446 Test RE 0.044228421343600256\n",
      "254 Train Loss 0.14090034 Test MSE 0.0038197716870695536 Test RE 0.04478023520064377\n",
      "255 Train Loss 0.13984196 Test MSE 0.003669031918454555 Test RE 0.0438877597231691\n",
      "256 Train Loss 0.13862489 Test MSE 0.0037509374296644154 Test RE 0.044374919423446624\n",
      "257 Train Loss 0.13810149 Test MSE 0.003726166172616766 Test RE 0.0442281503297442\n",
      "258 Train Loss 0.13744062 Test MSE 0.003930335568668933 Test RE 0.04542369754954952\n",
      "259 Train Loss 0.1360986 Test MSE 0.0035615348662244107 Test RE 0.04324005799757409\n",
      "260 Train Loss 0.13528493 Test MSE 0.004034405358349353 Test RE 0.046021146480919296\n",
      "261 Train Loss 0.13482636 Test MSE 0.003981853326510146 Test RE 0.0457204290148752\n",
      "262 Train Loss 0.13457297 Test MSE 0.004165845476373256 Test RE 0.046764817728045145\n",
      "263 Train Loss 0.13430719 Test MSE 0.004202010820264026 Test RE 0.046967370959565796\n",
      "264 Train Loss 0.13403311 Test MSE 0.004253970268200452 Test RE 0.047256863412498684\n",
      "265 Train Loss 0.1336295 Test MSE 0.003916858558146698 Test RE 0.04534575238124484\n",
      "266 Train Loss 0.13353153 Test MSE 0.003927776064092565 Test RE 0.04540890478009184\n",
      "267 Train Loss 0.13337217 Test MSE 0.003910596336461232 Test RE 0.045309488786268955\n",
      "268 Train Loss 0.13327125 Test MSE 0.003947348042837621 Test RE 0.04552189973084769\n",
      "269 Train Loss 0.1331647 Test MSE 0.004162245580530542 Test RE 0.04674460756194703\n",
      "270 Train Loss 0.13291135 Test MSE 0.00411555503806417 Test RE 0.04648168622265077\n",
      "271 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "272 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "273 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "274 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "275 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "276 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "277 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "278 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "279 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "280 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "281 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "282 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "283 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "284 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "285 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "286 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "287 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "288 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "289 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "290 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "291 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "292 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "293 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "294 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "295 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "296 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "297 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "298 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "299 Train Loss 0.13279249 Test MSE 0.003985651039386043 Test RE 0.045742226864595434\n",
      "Training time: 453.89\n",
      "KG_rowdy_medium\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 6330.0347 Test MSE 3.647619525180803 Test RE 1.383797155451582\n",
      "1 Train Loss 631.78186 Test MSE 1.3772529629021628 Test RE 0.850304593701662\n",
      "2 Train Loss 206.75804 Test MSE 1.0475600838084826 Test RE 0.7415785142588611\n",
      "3 Train Loss 71.46689 Test MSE 1.3010540198414111 Test RE 0.826447617633457\n",
      "4 Train Loss 27.9407 Test MSE 1.1225487291934315 Test RE 0.767662399088907\n",
      "5 Train Loss 16.231762 Test MSE 1.057568150776246 Test RE 0.7451125002323654\n",
      "6 Train Loss 12.614674 Test MSE 0.9784138815059812 Test RE 0.71668608190038\n",
      "7 Train Loss 9.620664 Test MSE 0.9075195373914193 Test RE 0.6902329051610204\n",
      "8 Train Loss 7.981714 Test MSE 0.8798218768904195 Test RE 0.6796182708656504\n",
      "9 Train Loss 5.8548594 Test MSE 0.8297519072320203 Test RE 0.6599967505314082\n",
      "10 Train Loss 5.237756 Test MSE 0.8042467488444729 Test RE 0.6497739926506199\n",
      "11 Train Loss 4.5440855 Test MSE 0.7644664914380123 Test RE 0.6335004016959239\n",
      "12 Train Loss 3.8312078 Test MSE 0.7445772915088655 Test RE 0.62520517051626\n",
      "13 Train Loss 3.3210218 Test MSE 0.7225298004150442 Test RE 0.6158792180312841\n",
      "14 Train Loss 2.8612018 Test MSE 0.688412252828334 Test RE 0.6011626129551181\n",
      "15 Train Loss 2.5588226 Test MSE 0.64157552656796 Test RE 0.5803521025542304\n",
      "16 Train Loss 2.2114646 Test MSE 0.5641173577279791 Test RE 0.5441923083898881\n",
      "17 Train Loss 1.873312 Test MSE 0.4488745404092736 Test RE 0.48543395881821827\n",
      "18 Train Loss 1.5436308 Test MSE 0.39082071992217227 Test RE 0.4529564599653358\n",
      "19 Train Loss 1.3749121 Test MSE 0.3575795758466143 Test RE 0.43326541182934386\n",
      "20 Train Loss 1.2127404 Test MSE 0.32427845761656887 Test RE 0.4125976185795446\n",
      "21 Train Loss 0.98046345 Test MSE 0.28649483624492167 Test RE 0.3878163074840739\n",
      "22 Train Loss 0.8942908 Test MSE 0.26113909607247066 Test RE 0.3702572881085404\n",
      "23 Train Loss 0.83596367 Test MSE 0.2241983327774714 Test RE 0.34307088037385025\n",
      "24 Train Loss 0.7357381 Test MSE 0.1887761806832739 Test RE 0.3148047417127809\n",
      "25 Train Loss 0.6781565 Test MSE 0.16475317382245022 Test RE 0.2940929152951292\n",
      "26 Train Loss 0.64754117 Test MSE 0.15485121758215536 Test RE 0.2851182258155249\n",
      "27 Train Loss 0.5972294 Test MSE 0.13539582635830608 Test RE 0.2666062377083617\n",
      "28 Train Loss 0.55563945 Test MSE 0.10389064732207581 Test RE 0.2335371058257746\n",
      "29 Train Loss 0.49999687 Test MSE 0.08265149729193051 Test RE 0.20830180363651513\n",
      "30 Train Loss 0.4139359 Test MSE 0.06002732245167352 Test RE 0.1775179007939534\n",
      "31 Train Loss 0.39688167 Test MSE 0.05140989279465217 Test RE 0.16428239165243316\n",
      "32 Train Loss 0.3722143 Test MSE 0.046217103633034815 Test RE 0.15576469545124347\n",
      "33 Train Loss 0.35054094 Test MSE 0.05578935591296513 Test RE 0.17113677412236122\n",
      "34 Train Loss 0.31653005 Test MSE 0.06165280396431964 Test RE 0.1799053523411607\n",
      "35 Train Loss 0.29526022 Test MSE 0.059890887289328065 Test RE 0.17731604720111077\n",
      "36 Train Loss 0.28777698 Test MSE 0.05769388240816017 Test RE 0.17403337808225117\n",
      "37 Train Loss 0.27480233 Test MSE 0.051204725704933535 Test RE 0.1639542540750085\n",
      "38 Train Loss 0.26916018 Test MSE 0.04833216966680158 Test RE 0.1592890100932015\n",
      "39 Train Loss 0.24187943 Test MSE 0.043334074384875104 Test RE 0.15082815892391008\n",
      "40 Train Loss 0.23292413 Test MSE 0.0404790968298074 Test RE 0.14577500823481152\n",
      "41 Train Loss 0.21872522 Test MSE 0.03866784121469271 Test RE 0.14247630085678134\n",
      "42 Train Loss 0.19473074 Test MSE 0.04033730150993132 Test RE 0.14551946464714427\n",
      "43 Train Loss 0.1894595 Test MSE 0.038242703334049256 Test RE 0.14169090032922985\n",
      "44 Train Loss 0.18000473 Test MSE 0.03562175929606924 Test RE 0.1367493749651427\n",
      "45 Train Loss 0.15179066 Test MSE 0.020906803607036294 Test RE 0.10476385901763845\n",
      "46 Train Loss 0.1419865 Test MSE 0.01946267557640596 Test RE 0.10108086258647704\n",
      "47 Train Loss 0.13861553 Test MSE 0.019222140235298703 Test RE 0.10045430153173315\n",
      "48 Train Loss 0.133991 Test MSE 0.01990892552694353 Test RE 0.1022331114461472\n",
      "49 Train Loss 0.122584954 Test MSE 0.01587454376953585 Test RE 0.09128896725427837\n",
      "50 Train Loss 0.112992905 Test MSE 0.014392897630049884 Test RE 0.08692441686420774\n",
      "51 Train Loss 0.11067666 Test MSE 0.012737198869929666 Test RE 0.08177200235437776\n",
      "52 Train Loss 0.10403894 Test MSE 0.010677110061870542 Test RE 0.07486770620381104\n",
      "53 Train Loss 0.091740154 Test MSE 0.0064214461909031005 Test RE 0.0580609438456616\n",
      "54 Train Loss 0.08741014 Test MSE 0.0068380330858491024 Test RE 0.059914683093811365\n",
      "55 Train Loss 0.08605078 Test MSE 0.007276696794608307 Test RE 0.06180659340094839\n",
      "56 Train Loss 0.08516552 Test MSE 0.006970227533123057 Test RE 0.06049105309838661\n",
      "57 Train Loss 0.082228124 Test MSE 0.0053832162901136914 Test RE 0.05316044190183388\n",
      "58 Train Loss 0.077941954 Test MSE 0.0041784261719555625 Test RE 0.046835378484802834\n",
      "59 Train Loss 0.075102635 Test MSE 0.003977260557863538 Test RE 0.045694053867347664\n",
      "60 Train Loss 0.073772706 Test MSE 0.004081684518468243 Test RE 0.04629002173958364\n",
      "61 Train Loss 0.07215658 Test MSE 0.003870512071498989 Test RE 0.04507667574631133\n",
      "62 Train Loss 0.070674844 Test MSE 0.004254970014172135 Test RE 0.04726241611742708\n",
      "63 Train Loss 0.06625937 Test MSE 0.004622122318038473 Test RE 0.04925931687713583\n",
      "64 Train Loss 0.06410022 Test MSE 0.004560625226897931 Test RE 0.04893052327660171\n",
      "65 Train Loss 0.063376464 Test MSE 0.004046319837649072 Test RE 0.04608905162671227\n",
      "66 Train Loss 0.06137723 Test MSE 0.004738942961445181 Test RE 0.0498779285087138\n",
      "67 Train Loss 0.05866883 Test MSE 0.005672524793914988 Test RE 0.0545702406582097\n",
      "68 Train Loss 0.055874236 Test MSE 0.006676193098587256 Test RE 0.059201418445379975\n",
      "69 Train Loss 0.054088846 Test MSE 0.006560794591616993 Test RE 0.05868753763152747\n",
      "70 Train Loss 0.05241743 Test MSE 0.005551996515100537 Test RE 0.05398738103677294\n",
      "71 Train Loss 0.05157379 Test MSE 0.005772987831411593 Test RE 0.05505135193110996\n",
      "72 Train Loss 0.05126102 Test MSE 0.005815564440787343 Test RE 0.05525398479552141\n",
      "73 Train Loss 0.050491042 Test MSE 0.005549251878353787 Test RE 0.05397403502091198\n",
      "74 Train Loss 0.04913611 Test MSE 0.006305755541854587 Test RE 0.05753554519972206\n",
      "75 Train Loss 0.04698687 Test MSE 0.0059880821886177495 Test RE 0.05606754546972751\n",
      "76 Train Loss 0.04443397 Test MSE 0.006495746971181554 Test RE 0.0583958813373202\n",
      "77 Train Loss 0.042580824 Test MSE 0.006193421472758855 Test RE 0.057020757885472985\n",
      "78 Train Loss 0.041156616 Test MSE 0.006496282938608311 Test RE 0.05839829042474383\n",
      "79 Train Loss 0.040777527 Test MSE 0.006769117596237261 Test RE 0.05961200059458908\n",
      "80 Train Loss 0.04033532 Test MSE 0.00652576703010024 Test RE 0.05853066391488237\n",
      "81 Train Loss 0.039882857 Test MSE 0.007012050987817903 Test RE 0.06067226390127912\n",
      "82 Train Loss 0.039261166 Test MSE 0.0067477764882398405 Test RE 0.05951795654683774\n",
      "83 Train Loss 0.03844276 Test MSE 0.006265004544759673 Test RE 0.0573493318935979\n",
      "84 Train Loss 0.037221465 Test MSE 0.006359593084024578 Test RE 0.05778063785751708\n",
      "85 Train Loss 0.035627853 Test MSE 0.0061567343520794295 Test RE 0.05685162402624097\n",
      "86 Train Loss 0.03526321 Test MSE 0.006537511656443717 Test RE 0.05858330996851912\n",
      "87 Train Loss 0.03513608 Test MSE 0.006857818923986194 Test RE 0.06000130200249299\n",
      "88 Train Loss 0.035043903 Test MSE 0.006772090664421685 Test RE 0.05962509026866753\n",
      "89 Train Loss 0.03487294 Test MSE 0.006702742676623015 Test RE 0.05931901638755464\n",
      "90 Train Loss 0.034517117 Test MSE 0.006657467873049476 Test RE 0.05911833679213012\n",
      "91 Train Loss 0.03430998 Test MSE 0.00652242954486577 Test RE 0.05851569477726904\n",
      "92 Train Loss 0.03403947 Test MSE 0.006185120407643475 Test RE 0.05698253250915358\n",
      "93 Train Loss 0.033595115 Test MSE 0.006215562244221531 Test RE 0.057122588293618014\n",
      "94 Train Loss 0.03198233 Test MSE 0.005429084884070951 Test RE 0.053386442717837435\n",
      "95 Train Loss 0.030684587 Test MSE 0.005635656723567413 Test RE 0.05439261435846938\n",
      "96 Train Loss 0.030127758 Test MSE 0.005637095083500825 Test RE 0.05439955509046276\n",
      "97 Train Loss 0.029877923 Test MSE 0.0055710715177947736 Test RE 0.05408004377734847\n",
      "98 Train Loss 0.029599098 Test MSE 0.0054271990536980275 Test RE 0.053377169836529674\n",
      "99 Train Loss 0.029322593 Test MSE 0.005310451824628009 Test RE 0.0527999369984393\n",
      "100 Train Loss 0.028892355 Test MSE 0.004967088195098465 Test RE 0.0510644434992317\n",
      "101 Train Loss 0.028218782 Test MSE 0.004623290679794152 Test RE 0.04926554227117172\n",
      "102 Train Loss 0.027417846 Test MSE 0.003738909404143667 Test RE 0.044303714392019335\n",
      "103 Train Loss 0.02694034 Test MSE 0.003526387068543406 Test RE 0.0430261669242791\n",
      "104 Train Loss 0.026102558 Test MSE 0.0033796825170925786 Test RE 0.042121673770014544\n",
      "105 Train Loss 0.025711743 Test MSE 0.003841004829684544 Test RE 0.04490452370647445\n",
      "106 Train Loss 0.025628569 Test MSE 0.0039149730826856955 Test RE 0.045334836925177556\n",
      "107 Train Loss 0.025522156 Test MSE 0.0037816307356050814 Test RE 0.04455610586858232\n",
      "108 Train Loss 0.025462497 Test MSE 0.0038748258844159117 Test RE 0.045101788469354795\n",
      "109 Train Loss 0.025406819 Test MSE 0.004028217181573103 Test RE 0.045985838145043166\n",
      "110 Train Loss 0.025094392 Test MSE 0.003935598592578638 Test RE 0.04545410030061971\n",
      "111 Train Loss 0.024608076 Test MSE 0.0038493858836264622 Test RE 0.044953487737868704\n",
      "112 Train Loss 0.023911182 Test MSE 0.004283667409393556 Test RE 0.04742152758286179\n",
      "113 Train Loss 0.02304848 Test MSE 0.003862772464725294 Test RE 0.04503158477139391\n",
      "114 Train Loss 0.022415843 Test MSE 0.0037969677363019687 Test RE 0.04464636660665549\n",
      "115 Train Loss 0.021944635 Test MSE 0.003884013106076049 Test RE 0.045155225038998534\n",
      "116 Train Loss 0.0213573 Test MSE 0.003798458693857991 Test RE 0.044655131403848226\n",
      "117 Train Loss 0.02115731 Test MSE 0.0034819682984817127 Test RE 0.042754326949074405\n",
      "118 Train Loss 0.020779815 Test MSE 0.0034724429199536823 Test RE 0.04269580687985677\n",
      "119 Train Loss 0.020436948 Test MSE 0.0034369235059006917 Test RE 0.04247687914449474\n",
      "120 Train Loss 0.020076675 Test MSE 0.0036178786743656884 Test RE 0.04358074669445417\n",
      "121 Train Loss 0.019692846 Test MSE 0.003512248487799877 Test RE 0.042939826442893216\n",
      "122 Train Loss 0.019351862 Test MSE 0.0035831517298731586 Test RE 0.04337108302474141\n",
      "123 Train Loss 0.019162634 Test MSE 0.0036104634441680864 Test RE 0.04353606208002205\n",
      "124 Train Loss 0.018885981 Test MSE 0.003471460838170465 Test RE 0.04268976880518221\n",
      "125 Train Loss 0.018669825 Test MSE 0.0037926229023514586 Test RE 0.04462081508932457\n",
      "126 Train Loss 0.018317519 Test MSE 0.003680511527834559 Test RE 0.04395636376955985\n",
      "127 Train Loss 0.017931048 Test MSE 0.0037146013346765535 Test RE 0.04415946191635987\n",
      "128 Train Loss 0.017347362 Test MSE 0.003736439801742708 Test RE 0.04428908036098121\n",
      "129 Train Loss 0.0167588 Test MSE 0.003233980962550786 Test RE 0.041203717144164625\n",
      "130 Train Loss 0.0163541 Test MSE 0.0035357277300980482 Test RE 0.04308311289685404\n",
      "131 Train Loss 0.0162331 Test MSE 0.0034265210028483106 Test RE 0.04241254825104859\n",
      "132 Train Loss 0.016152786 Test MSE 0.0036035737813241322 Test RE 0.04349450342351523\n",
      "133 Train Loss 0.015974138 Test MSE 0.0038326128340083307 Test RE 0.044855442197334915\n",
      "134 Train Loss 0.015802434 Test MSE 0.003802981172177403 Test RE 0.04468170689199197\n",
      "135 Train Loss 0.01562763 Test MSE 0.003387424328482748 Test RE 0.04216989006224896\n",
      "136 Train Loss 0.015448122 Test MSE 0.003147553589463116 Test RE 0.040649408848156925\n",
      "137 Train Loss 0.015246822 Test MSE 0.0032639028737688385 Test RE 0.041393893788234985\n",
      "138 Train Loss 0.015096741 Test MSE 0.003128986495827402 Test RE 0.04052933818228917\n",
      "139 Train Loss 0.01499447 Test MSE 0.0029032110384539884 Test RE 0.03903974487385109\n",
      "140 Train Loss 0.014735039 Test MSE 0.0028939385787014288 Test RE 0.03897735120680096\n",
      "141 Train Loss 0.014350741 Test MSE 0.0024564103642723324 Test RE 0.03591022516114834\n",
      "142 Train Loss 0.014010455 Test MSE 0.002653797006443722 Test RE 0.03732514620651453\n",
      "143 Train Loss 0.013861159 Test MSE 0.0025865049045498212 Test RE 0.03684888241876921\n",
      "144 Train Loss 0.013740282 Test MSE 0.0026887229853383354 Test RE 0.03756995696483133\n",
      "145 Train Loss 0.0136303585 Test MSE 0.0026905429501841126 Test RE 0.037582670144004786\n",
      "146 Train Loss 0.013510198 Test MSE 0.002847756298716371 Test RE 0.03866509469994254\n",
      "147 Train Loss 0.013384412 Test MSE 0.0030583468495553874 Test RE 0.04006923365700408\n",
      "148 Train Loss 0.013252505 Test MSE 0.0030170525677208184 Test RE 0.03979780376257921\n",
      "149 Train Loss 0.013150062 Test MSE 0.0030495583743408495 Test RE 0.04001162069952159\n",
      "150 Train Loss 0.013011185 Test MSE 0.0029299748305752346 Test RE 0.03921927963700751\n",
      "151 Train Loss 0.012886591 Test MSE 0.00304237309753473 Test RE 0.03996445581838666\n",
      "152 Train Loss 0.012815255 Test MSE 0.0030603234519610474 Test RE 0.04008217989149321\n",
      "153 Train Loss 0.012782749 Test MSE 0.0030775740072820908 Test RE 0.04019498957075908\n",
      "154 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "155 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "156 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "157 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "158 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "159 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "160 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "161 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "162 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "163 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "164 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "165 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "166 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "167 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "168 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "169 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "170 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "171 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "172 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "173 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "174 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "175 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "176 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "177 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "178 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "179 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "180 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "181 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "182 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "183 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "184 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "185 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "186 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "187 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "188 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "189 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "190 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "191 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "192 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "193 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "194 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "195 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "196 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "197 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "198 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "199 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "200 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "201 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "202 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "203 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "204 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "205 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "206 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "207 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "208 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "209 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "210 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "211 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "212 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "213 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "214 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "215 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "216 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "217 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "218 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "219 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "220 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "221 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "222 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "223 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "224 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "225 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "226 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "227 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "228 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "229 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "230 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "231 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "232 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "233 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "234 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "235 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "236 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "237 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "238 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "239 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "240 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "241 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "242 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "243 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "244 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "245 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "246 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "247 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "248 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "249 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "250 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "251 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "252 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "253 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "254 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "255 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "256 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "257 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "258 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "259 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "260 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "261 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "262 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "263 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "264 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "265 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "266 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "267 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "268 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "269 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "270 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "271 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "272 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "273 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "274 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "275 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "276 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "277 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "278 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "279 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "280 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "281 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "282 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "283 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "284 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "285 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "286 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "287 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "288 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "289 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "290 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "291 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "292 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "293 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "294 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "295 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "296 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "297 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "298 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "299 Train Loss 0.012763966 Test MSE 0.0031693136704528204 Test RE 0.04078967825031957\n",
      "Training time: 310.64\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "n_val = 5.0\n",
    "rowdy_terms = 6\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,rowdy_terms,n_val)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9278134ed0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.03559991392337619\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
