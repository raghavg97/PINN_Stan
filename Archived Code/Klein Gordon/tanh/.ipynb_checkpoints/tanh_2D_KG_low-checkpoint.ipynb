{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1660687093981,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "iAtv2UvNSq_u",
    "outputId": "68a82578-1b95-4343-a8ec-7635a4df93ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1660687410736,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "mTLFQRt5Sq_y"
   },
   "outputs": [],
   "source": [
    "def true_2D_1(xt): #True function for 2D_1 Klein Gordon Equation x \\in [-50,50] , t \\in [0,10]\n",
    "    x = xt[:,0].reshape(-1,1)\n",
    "    t = xt[:,1].reshape(-1,1)\n",
    "    y = x*np.cos(5*np.pi*t) + np.power(x*t,3)\n",
    "    return y.reshape(-1,1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4312,
     "status": "ok",
     "timestamp": 1660687098957,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "81bNHCY3Sq_y"
   },
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "loss_thresh = 0.1\n",
    "level = \"low\"\n",
    "label = \"KG_tanh_\" + level\n",
    "\n",
    "x = np.linspace(0,1,500).reshape(-1,1)\n",
    "t = np.linspace(0,1,500).reshape(-1,1)\n",
    "\n",
    "X,T = np.meshgrid(x,t)\n",
    "\n",
    "X = X.flatten('F').reshape(-1,1)\n",
    "T = T.flatten('F').reshape(-1,1)\n",
    "  \n",
    "xt = np.hstack((X,T))\n",
    "\n",
    "y_true = true_2D_1(xt)\n",
    "y_true_norm = np.linalg.norm(y_true,2)\n",
    "\n",
    "#bound_pts_idx = ((X == -5) + (X == 5) + (T == 0)).reshape(-1,)\n",
    "\n",
    "#xt_bound = xt[bound_pts_idx,:]\n",
    "#y_bound = y_true[bound_pts_idx,:]\n",
    "\n",
    "\n",
    "xt_test_tensor = torch.from_numpy(xt).float().to(device)\n",
    "\n",
    "\n",
    "lb_xt = xt[0]\n",
    "ub_xt = xt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "YQgCA-PuSq_z"
   },
   "outputs": [],
   "source": [
    "def trainingdata(N_I,N_B,N_f,seed):\n",
    "    '''Boundary Conditions''' \n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    x_BC1 = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_BC1 = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_BC1,t_BC1))\n",
    "    xt_BC1 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC1 = true_2D_1(xt_BC1)\n",
    "    \n",
    "    x_BC2 = np.zeros((int(N_B/2),1))\n",
    "    t_BC2 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC2,t_BC2))\n",
    "    xt_BC2 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC2 = true_2D_1(xt_BC2)\n",
    "    \n",
    "    x_BC3 = np.ones((int(N_B/2),1))\n",
    "    t_BC3 = np.random.uniform(size = int(N_B/2)).reshape(-1,1)\n",
    "    samples = np.hstack((x_BC3,t_BC3))\n",
    "    xt_BC3 = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    y_BC3 = true_2D_1(xt_BC3)\n",
    "    \n",
    "    x_NBC = np.random.uniform(size = N_I).reshape(-1,1)\n",
    "    t_NBC = np.zeros((N_I,1))\n",
    "    samples = np.hstack((x_NBC,t_NBC))\n",
    "    xt_NBC = lb_xt + (ub_xt - lb_xt)*samples\n",
    "\n",
    "    \n",
    "    xt_BC = np.vstack((xt_BC1,xt_BC2,xt_BC3))\n",
    "    y_BC = np.vstack((y_BC1,y_BC2,y_BC3))\n",
    "\n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # Latin Hypercube sampling for collocation points \n",
    "    # N_f sets of tuples(x,t)\n",
    "    x01 = np.array([[0.0,1.0],[0.0,1.0]])\n",
    "    sampling = LHS(xlimits=x01,random_state =seed)\n",
    "    samples = sampling(N_f)\n",
    "    xt_coll = lb_xt + (ub_xt - lb_xt)*samples\n",
    "    \n",
    "    xt_coll = np.vstack((xt_coll, xt_BC,xt_NBC)) # append training points to collocation points \n",
    "\n",
    "    return xt_coll, xt_BC, y_BC,xt_NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "gTJxct8bSq_0"
   },
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers,beta_init):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "\n",
    "    'foward pass'\n",
    "    def forward(self,xt):\n",
    "        if torch.is_tensor(xt) != True:         \n",
    "            xt = torch.from_numpy(xt)                \n",
    "        \n",
    "        ubxt = torch.from_numpy(ub_xt).float().to(device)\n",
    "        lbxt = torch.from_numpy(lb_xt).float().to(device)\n",
    "    \n",
    "                      \n",
    "        #preprocessing input \n",
    "        xt = 2.0*(xt - lbxt)/(ubxt - lbxt) - 1.0\n",
    "        \n",
    "        #convert to float\n",
    "        a = xt.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "                    \n",
    "        \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,xt,y):\n",
    "                \n",
    "        loss_bc = self.loss_function(self.forward(xt), y)\n",
    "                \n",
    "        return loss_bc\n",
    "    \n",
    "    def loss_NBC(self,xt_NBC,N_hat):\n",
    "        g = xt_NBC.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_NBC.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]        \n",
    "        dy_dt = y_x_t[:,[1]]\n",
    "        \n",
    "        loss_nbc = self.loss_function(dy_dt, N_hat)\n",
    "                \n",
    "        return loss_nbc\n",
    "    \n",
    "    def loss_PDE(self, xt_coll, f_hat):\n",
    "        \n",
    "        g = xt_coll.clone()             \n",
    "        g.requires_grad = True\n",
    "        y = self.forward(g) \n",
    "        \n",
    "        \n",
    "        y_x_t = autograd.grad(y,g,torch.ones([xt_coll.shape[0], 1]).to(device), retain_graph=True, create_graph=True,allow_unused = True)[0]\n",
    "        \n",
    "        y_xx_tt = autograd.grad(y_x_t,g,torch.ones(xt_coll.shape).to(device), create_graph=True,allow_unused = True)[0]\n",
    "\n",
    "        #du_dx = u_x_t[:,[0]]\n",
    "        \n",
    "        d2y_dx2 = y_xx_tt[:,[0]]\n",
    "        d2y_dt2 = y_xx_tt[:,[1]]    \n",
    "        \n",
    "\n",
    "        term1 = -25.0*(pi**2)*(g[:,0].reshape(-1,1))*torch.cos(5.0*pi*g[:,1].reshape(-1,1)) + 6*torch.pow(g[:,0].reshape(-1,1),3)*g[:,1].reshape(-1,1)  \n",
    "        term1 = term1.reshape(-1,1)\n",
    "        term2 = 6*torch.pow(g[:,1].reshape(-1,1),3)*g[:,0].reshape(-1,1)\n",
    "        term2 = term2.reshape(-1,1)\n",
    "        term3 = torch.pow(g[:,0]*torch.cos(5.0*pi*g[:,1]) + torch.pow(g[:,0]*g[:,1],3),3)\n",
    "        term3 = term3.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        f = d2y_dt2 - d2y_dx2 + torch.pow(y,3) - (term1 - term2 + term3)\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat):\n",
    "\n",
    "        loss_BC = self.loss_BC(xt_BC,y_BC)\n",
    "        loss_NBC = self.loss_NBC(xt_NBC,N_hat)\n",
    "        loss_f = self.loss_PDE(xt_coll,f_hat)\n",
    "        \n",
    "        loss_val = loss_BC + loss_f + loss_NBC\n",
    "        \n",
    "        return loss_val\n",
    "         \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "        y_pred = self.forward(xt_test_tensor)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "   \n",
    "        return y_pred\n",
    "    \n",
    "    def test_loss(self):\n",
    "        y_pred = self.test()\n",
    "        \n",
    "        test_mse = np.mean(np.square(y_pred.reshape(-1,1) - y_true.reshape(-1,1)))\n",
    "        test_re = np.linalg.norm(y_pred.reshape(-1,1) - y_true.reshape(-1,1),2)/y_true_norm\n",
    "        \n",
    "        return test_mse, test_re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660687098958,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "VoQzfzYsYKVs"
   },
   "outputs": [],
   "source": [
    "def data_update(loss_np):\n",
    "    train_loss.append(loss_np)\n",
    "    # beta_val.append(PINN.beta.cpu().detach().numpy())\n",
    "    \n",
    "    test_mse, test_re = PINN.test_loss()\n",
    "    test_mse_loss.append(test_mse)\n",
    "    test_re_loss.append(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660687098959,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "_IUDZDkxXmyF"
   },
   "outputs": [],
   "source": [
    "def train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,seed):\n",
    "    # x_coll_np_array = colloc_pts(N_f,seed*123)\n",
    "    # x_coll_train = torch.from_numpy(x_coll_np_array).float().to(device)        \n",
    "    \n",
    "    # f_hat = torch.zeros(x_coll_train.shape[0],1).to(device)\n",
    "#     xt_coll, xt_BC, y_BC = trainingdata(N_I,N_B,N_f,seed*123)\n",
    "#     xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "#     xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "#     y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "\n",
    "#     f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat)\n",
    "        loss.backward()\n",
    "        #print(loss.cpu().detach().numpy())\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1660690085956,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "Vt9Dlr8MYIwW"
   },
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*9)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    xt_coll, xt_BC, y_BC, xt_NBC = trainingdata(N_I,N_B,N_f,rep*11)\n",
    "    xt_coll = torch.from_numpy(xt_coll).float().to(device)\n",
    "    xt_BC = torch.from_numpy(xt_BC).float().to(device)\n",
    "    y_BC = torch.from_numpy(y_BC).float().to(device)\n",
    "    xt_NBC = torch.from_numpy(xt_NBC).float().to(device)\n",
    "    \n",
    "    f_hat = torch.zeros(xt_coll.shape[0],1).to(device)\n",
    "    N_hat = torch.zeros(xt_NBC.shape[0],1).to(device)\n",
    "    \n",
    "    loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "    data_update(loss_np)\n",
    "    for i in range(max_iter):\n",
    "        if(np.isnan(loss_np) == False):\n",
    "            train_step(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat,i)\n",
    "            loss_np = PINN.loss(xt_BC,y_BC,xt_coll,f_hat,xt_NBC,N_hat).cpu().detach().numpy()\n",
    "        \n",
    "        if(thresh_flag == 0):\n",
    "            if(loss_np < loss_thresh):\n",
    "                time_threshold[rep] = time.time() - start_time\n",
    "                epoch_threshold[rep] = i+1          \n",
    "                thresh_flag = 1       \n",
    "        data_update(loss_np)\n",
    "        \n",
    "        print(i,\"Train Loss\",train_loss[-1],\"Test MSE\",test_mse_loss[-1],\"Test RE\",test_re_loss[-1])   \n",
    "        \n",
    "      \n",
    "         \n",
    "\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP4Re5lSSq_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KG_stan_high\n",
      "0\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0 Train Loss 27645.422 Test MSE 6.098316267741893 Test RE 1.7841889641709807\n",
      "1 Train Loss 2268.8298 Test MSE 6.12897694983574 Test RE 1.7886685500721675\n",
      "2 Train Loss 611.05865 Test MSE 8.190027078473634 Test RE 2.0676572365155375\n",
      "3 Train Loss 274.66272 Test MSE 8.526598866164026 Test RE 2.109715010821589\n",
      "4 Train Loss 177.7746 Test MSE 9.42756691029141 Test RE 2.2183787098737118\n",
      "5 Train Loss 104.00608 Test MSE 9.863452400200224 Test RE 2.269082850284762\n",
      "6 Train Loss 63.51201 Test MSE 10.679037954247502 Test RE 2.3610323730959286\n",
      "7 Train Loss 44.14301 Test MSE 11.136152651761531 Test RE 2.4110347210540177\n",
      "8 Train Loss 33.908905 Test MSE 11.014759321335728 Test RE 2.397857569820405\n",
      "9 Train Loss 27.386044 Test MSE 11.076528809722966 Test RE 2.404571623168332\n",
      "10 Train Loss 23.024755 Test MSE 11.071225421299475 Test RE 2.4039959056155444\n",
      "11 Train Loss 20.406183 Test MSE 11.042242167935669 Test RE 2.4008471447360926\n",
      "12 Train Loss 18.181232 Test MSE 10.946697804614749 Test RE 2.390437765576444\n",
      "13 Train Loss 16.615469 Test MSE 10.83288388784469 Test RE 2.377978485065448\n",
      "14 Train Loss 15.383166 Test MSE 10.779962667910112 Test RE 2.372162877853758\n",
      "15 Train Loss 14.574055 Test MSE 10.765170887917183 Test RE 2.3705348315672135\n",
      "16 Train Loss 14.049975 Test MSE 10.74118491346074 Test RE 2.36789245383886\n",
      "17 Train Loss 13.587335 Test MSE 10.682793131962153 Test RE 2.3614474534106216\n",
      "18 Train Loss 13.188657 Test MSE 10.575099335138866 Test RE 2.3495143650066654\n",
      "19 Train Loss 12.9017935 Test MSE 10.5055070793929 Test RE 2.3417708020319647\n",
      "20 Train Loss 12.548183 Test MSE 10.40597363086202 Test RE 2.3306509561664024\n",
      "21 Train Loss 12.270104 Test MSE 10.308946188860103 Test RE 2.3197597739604214\n",
      "22 Train Loss 11.99974 Test MSE 10.285038020016536 Test RE 2.3170682572607593\n",
      "23 Train Loss 11.802517 Test MSE 10.211073805808287 Test RE 2.3087216977782585\n",
      "24 Train Loss 11.581741 Test MSE 10.158068502851059 Test RE 2.3027216570747653\n",
      "25 Train Loss 11.393586 Test MSE 10.09183088140645 Test RE 2.295201710522742\n",
      "26 Train Loss 11.209669 Test MSE 9.999170605944213 Test RE 2.284640472567029\n",
      "27 Train Loss 10.990725 Test MSE 9.855440506101909 Test RE 2.268161096723985\n",
      "28 Train Loss 10.877813 Test MSE 9.771605682882086 Test RE 2.2584934927813074\n",
      "29 Train Loss 10.684612 Test MSE 9.601059853428747 Test RE 2.2386977637825693\n",
      "30 Train Loss 10.528939 Test MSE 9.555164867041688 Test RE 2.2333406425517053\n",
      "31 Train Loss 10.382868 Test MSE 9.439157117892167 Test RE 2.2197419233354756\n",
      "32 Train Loss 10.190134 Test MSE 9.24616929876203 Test RE 2.1969329244408984\n",
      "33 Train Loss 10.029667 Test MSE 9.172346085108865 Test RE 2.188144978282033\n",
      "34 Train Loss 9.894758 Test MSE 9.070511120388419 Test RE 2.1759642555197907\n",
      "35 Train Loss 9.722199 Test MSE 8.980428947105176 Test RE 2.165132192596537\n",
      "36 Train Loss 9.556287 Test MSE 8.894480287013145 Test RE 2.1547464077324854\n",
      "37 Train Loss 9.408027 Test MSE 8.740587469724225 Test RE 2.1360242975329897\n",
      "38 Train Loss 9.283576 Test MSE 8.624348311283468 Test RE 2.121773499738649\n",
      "39 Train Loss 9.14659 Test MSE 8.476208564228742 Test RE 2.1034718000296007\n",
      "40 Train Loss 8.970055 Test MSE 8.315310956125796 Test RE 2.083411822035964\n",
      "41 Train Loss 8.73163 Test MSE 8.122081882951154 Test RE 2.059062639529125\n",
      "42 Train Loss 8.539894 Test MSE 7.910097641207377 Test RE 2.032014483368851\n",
      "43 Train Loss 8.334719 Test MSE 7.748865824985343 Test RE 2.011198550655709\n",
      "44 Train Loss 8.093085 Test MSE 7.494062709060125 Test RE 1.9778554043660141\n",
      "45 Train Loss 7.674471 Test MSE 7.172192410772907 Test RE 1.934914783906365\n",
      "46 Train Loss 7.2352314 Test MSE 6.892099272383538 Test RE 1.8967567534222074\n",
      "47 Train Loss 6.7546315 Test MSE 6.720152830564897 Test RE 1.8729468440193315\n",
      "48 Train Loss 6.3661013 Test MSE 6.50111387733998 Test RE 1.8421702466490468\n",
      "49 Train Loss 6.148704 Test MSE 6.291013193736958 Test RE 1.81215847677192\n",
      "50 Train Loss 5.879213 Test MSE 6.013887249055669 Test RE 1.7717951871438495\n",
      "51 Train Loss 5.6757245 Test MSE 5.76473996038004 Test RE 1.7347054291531754\n",
      "52 Train Loss 5.4570336 Test MSE 5.4794753609060205 Test RE 1.691240484421409\n",
      "53 Train Loss 5.1512103 Test MSE 5.134363991496002 Test RE 1.6371150608552791\n",
      "54 Train Loss 4.7051005 Test MSE 4.406629780106534 Test RE 1.5166632355504146\n",
      "55 Train Loss 4.3791633 Test MSE 4.172743626101544 Test RE 1.4758653211113322\n",
      "56 Train Loss 3.905297 Test MSE 3.573383020617223 Test RE 1.3657640019151827\n",
      "57 Train Loss 3.5011158 Test MSE 3.3328301202522668 Test RE 1.3189929238982292\n",
      "58 Train Loss 3.0857856 Test MSE 2.9009110847895148 Test RE 1.2305608263885532\n",
      "59 Train Loss 2.676021 Test MSE 2.1922589507151398 Test RE 1.0697487873698697\n",
      "60 Train Loss 2.2265992 Test MSE 1.4852657303741141 Test RE 0.8805174297987105\n",
      "61 Train Loss 1.7674065 Test MSE 1.0650717603446176 Test RE 0.7456333281923728\n",
      "62 Train Loss 1.4556037 Test MSE 0.7710127132352367 Test RE 0.6344050720451481\n",
      "63 Train Loss 1.1523478 Test MSE 0.5775503177832793 Test RE 0.5490738877077549\n",
      "64 Train Loss 0.9422748 Test MSE 0.38854531640788564 Test RE 0.45035679110850135\n",
      "65 Train Loss 0.80868226 Test MSE 0.36584731323719394 Test RE 0.4370044021730685\n",
      "66 Train Loss 0.67569685 Test MSE 0.3335554963146415 Test RE 0.41727265730944185\n",
      "67 Train Loss 0.5862968 Test MSE 0.26149648236699086 Test RE 0.36946117106547804\n",
      "68 Train Loss 0.510538 Test MSE 0.2818773080541237 Test RE 0.3835888144536484\n",
      "69 Train Loss 0.41643623 Test MSE 0.2360056938714121 Test RE 0.3509919187217146\n",
      "70 Train Loss 0.37277395 Test MSE 0.19594881008163265 Test RE 0.31982115853837184\n",
      "71 Train Loss 0.30626822 Test MSE 0.13088754588797483 Test RE 0.2613876349938991\n",
      "72 Train Loss 0.2698694 Test MSE 0.10416793403507117 Test RE 0.23318623066266947\n",
      "73 Train Loss 0.23409674 Test MSE 0.0894101950188449 Test RE 0.21603762685618397\n",
      "74 Train Loss 0.20361796 Test MSE 0.07885979954406293 Test RE 0.20289143382243816\n",
      "75 Train Loss 0.18565063 Test MSE 0.060340189722623526 Test RE 0.17747582863493558\n",
      "76 Train Loss 0.16728802 Test MSE 0.04949679834915165 Test RE 0.16074017279737093\n",
      "77 Train Loss 0.14824553 Test MSE 0.032638776000722174 Test RE 0.1305277370560576\n",
      "78 Train Loss 0.1323675 Test MSE 0.027150557489047104 Test RE 0.11904886319063948\n",
      "79 Train Loss 0.1186745 Test MSE 0.018595155670608023 Test RE 0.09852258226268837\n",
      "80 Train Loss 0.11093481 Test MSE 0.01957291103093336 Test RE 0.10107961705378253\n",
      "81 Train Loss 0.10055076 Test MSE 0.014063598096899835 Test RE 0.08568091590058717\n",
      "82 Train Loss 0.09496871 Test MSE 0.008940149281863867 Test RE 0.0683137714198692\n",
      "83 Train Loss 0.08629367 Test MSE 0.007922018864627014 Test RE 0.06430634305547162\n",
      "84 Train Loss 0.07702297 Test MSE 0.007287939740861035 Test RE 0.06167913343504469\n",
      "85 Train Loss 0.06901092 Test MSE 0.006738340702621107 Test RE 0.05930787449469642\n",
      "86 Train Loss 0.06544999 Test MSE 0.006041065876746604 Test RE 0.05615554709644168\n",
      "87 Train Loss 0.05900757 Test MSE 0.005357516647480492 Test RE 0.052883189620021157\n",
      "88 Train Loss 0.055128798 Test MSE 0.0062751349967541835 Test RE 0.05723311892811973\n",
      "89 Train Loss 0.050311886 Test MSE 0.005865664095749387 Test RE 0.055334306504409944\n",
      "90 Train Loss 0.047878344 Test MSE 0.006380723164125171 Test RE 0.05771262499962608\n",
      "91 Train Loss 0.045349043 Test MSE 0.006224519739160972 Test RE 0.05700183033624882\n",
      "92 Train Loss 0.042351652 Test MSE 0.00489323248850182 Test RE 0.05053983295780754\n",
      "93 Train Loss 0.03978077 Test MSE 0.004692896176007069 Test RE 0.04949443260709752\n",
      "94 Train Loss 0.03824967 Test MSE 0.004246599096732802 Test RE 0.04708217404455396\n",
      "95 Train Loss 0.035906423 Test MSE 0.002882180313403362 Test RE 0.03878791637377514\n",
      "96 Train Loss 0.034101196 Test MSE 0.0025790284927674338 Test RE 0.0366913716082346\n",
      "97 Train Loss 0.03318417 Test MSE 0.002189124636005217 Test RE 0.033804235697448476\n",
      "98 Train Loss 0.030651947 Test MSE 0.0011251914038703384 Test RE 0.024235337926559703\n",
      "99 Train Loss 0.028353693 Test MSE 0.0009892740296095612 Test RE 0.022724491869225052\n",
      "100 Train Loss 0.027027113 Test MSE 0.0009310186942234077 Test RE 0.02204525250621529\n",
      "101 Train Loss 0.025938831 Test MSE 0.0007668921442905928 Test RE 0.02000796971840746\n",
      "102 Train Loss 0.02471445 Test MSE 0.0006951637027525433 Test RE 0.01904931751886377\n",
      "103 Train Loss 0.023947947 Test MSE 0.0006145505890219673 Test RE 0.01791078812823997\n",
      "104 Train Loss 0.02306154 Test MSE 0.0005231656351712675 Test RE 0.01652553321614773\n",
      "105 Train Loss 0.022612045 Test MSE 0.0005167886034205549 Test RE 0.016424506930711964\n",
      "106 Train Loss 0.022065978 Test MSE 0.0004735123972701702 Test RE 0.015721774176147205\n",
      "107 Train Loss 0.021486076 Test MSE 0.0004411293247094279 Test RE 0.015174655537602277\n",
      "108 Train Loss 0.021019932 Test MSE 0.00046293167807599924 Test RE 0.015545128880763025\n",
      "109 Train Loss 0.020386448 Test MSE 0.0004836056821017693 Test RE 0.015888451564011575\n",
      "110 Train Loss 0.019853061 Test MSE 0.00045015477030401103 Test RE 0.015329105220265211\n",
      "111 Train Loss 0.019372208 Test MSE 0.0003503688116444031 Test RE 0.013523795562529032\n",
      "112 Train Loss 0.018622609 Test MSE 0.0003090499006404464 Test RE 0.012701358697196298\n",
      "113 Train Loss 0.018232657 Test MSE 0.00028834161505740394 Test RE 0.0122684455636401\n",
      "114 Train Loss 0.017531881 Test MSE 0.0003171115401011505 Test RE 0.012865951215245128\n",
      "115 Train Loss 0.016915739 Test MSE 0.00036181952537809014 Test RE 0.013743010448983843\n",
      "116 Train Loss 0.016319254 Test MSE 0.0002743301352630857 Test RE 0.011966651287254024\n",
      "117 Train Loss 0.015876336 Test MSE 0.00028382868413859253 Test RE 0.012172058158902908\n",
      "118 Train Loss 0.015486373 Test MSE 0.00027853442937478745 Test RE 0.012058001114517828\n",
      "119 Train Loss 0.01503632 Test MSE 0.0002813989530694345 Test RE 0.012119846391468693\n",
      "120 Train Loss 0.01458641 Test MSE 0.0002642816640016829 Test RE 0.011745442772649306\n",
      "121 Train Loss 0.014240544 Test MSE 0.00025841647499771214 Test RE 0.01161437852180988\n",
      "122 Train Loss 0.013964325 Test MSE 0.0002520262124510613 Test RE 0.011469876276207661\n",
      "123 Train Loss 0.013685168 Test MSE 0.0002435771652857289 Test RE 0.011275976519532552\n",
      "124 Train Loss 0.0132757705 Test MSE 0.00025758549148964814 Test RE 0.011595689449419652\n",
      "125 Train Loss 0.012992417 Test MSE 0.0002475535808872808 Test RE 0.011367644496162664\n",
      "126 Train Loss 0.012726546 Test MSE 0.00024203082892971422 Test RE 0.011240127070744049\n",
      "127 Train Loss 0.012298387 Test MSE 0.00024192122250367264 Test RE 0.011237581672552994\n",
      "128 Train Loss 0.012030972 Test MSE 0.00024609550210816884 Test RE 0.011334117613488457\n",
      "129 Train Loss 0.01173359 Test MSE 0.00024662310218788084 Test RE 0.011346260622389394\n",
      "130 Train Loss 0.011370881 Test MSE 0.0002488804190043227 Test RE 0.011398067945181754\n",
      "131 Train Loss 0.01106406 Test MSE 0.00025096641604108763 Test RE 0.011445734859423604\n",
      "132 Train Loss 0.010871249 Test MSE 0.00025247136695161383 Test RE 0.011480001442074724\n",
      "133 Train Loss 0.010621074 Test MSE 0.0002561216923688398 Test RE 0.01156269468876822\n",
      "134 Train Loss 0.01041155 Test MSE 0.00027354601493404456 Test RE 0.011949536854629354\n",
      "135 Train Loss 0.010200018 Test MSE 0.00027637450055791827 Test RE 0.012011157512417612\n",
      "136 Train Loss 0.01000899 Test MSE 0.00028732418065287893 Test RE 0.012246781383663391\n",
      "137 Train Loss 0.009762196 Test MSE 0.0003118572457238179 Test RE 0.012758916533502382\n",
      "138 Train Loss 0.009567723 Test MSE 0.0003058635182129968 Test RE 0.01263571194422224\n",
      "139 Train Loss 0.009399354 Test MSE 0.0003228176635956148 Test RE 0.012981190458338943\n",
      "140 Train Loss 0.009220432 Test MSE 0.00034056636093760483 Test RE 0.013333272381950659\n",
      "141 Train Loss 0.008927716 Test MSE 0.00037419969770236536 Test RE 0.013976151285897626\n",
      "142 Train Loss 0.0087021785 Test MSE 0.00037216792642106385 Test RE 0.013938156876105494\n",
      "143 Train Loss 0.008555478 Test MSE 0.00037340935181545855 Test RE 0.013961383993900442\n",
      "144 Train Loss 0.008371178 Test MSE 0.0003955571744842533 Test RE 0.014369462055168323\n",
      "145 Train Loss 0.008164519 Test MSE 0.00040405799311062687 Test RE 0.014523046507461168\n",
      "146 Train Loss 0.007984038 Test MSE 0.00043358673071731664 Test RE 0.01504436523358795\n",
      "147 Train Loss 0.007828598 Test MSE 0.00046667124219966293 Test RE 0.015607789401900716\n",
      "148 Train Loss 0.0076784166 Test MSE 0.0004778318000930151 Test RE 0.01579331877766713\n",
      "149 Train Loss 0.007493692 Test MSE 0.000500272402609842 Test RE 0.016159917891611607\n",
      "150 Train Loss 0.0073491004 Test MSE 0.00053090778028072 Test RE 0.016647361937092302\n",
      "151 Train Loss 0.007172202 Test MSE 0.0006142233639653742 Test RE 0.017906019083068565\n",
      "152 Train Loss 0.0070333667 Test MSE 0.0007047804412324875 Test RE 0.019180626941752116\n",
      "153 Train Loss 0.0069484315 Test MSE 0.0007655470392799894 Test RE 0.019990415338730864\n",
      "154 Train Loss 0.0068135466 Test MSE 0.0008027609816260463 Test RE 0.020470526111129532\n",
      "155 Train Loss 0.0066779954 Test MSE 0.0008636226541060816 Test RE 0.02123234145824361\n",
      "156 Train Loss 0.00652336 Test MSE 0.0009566383724318453 Test RE 0.022346513567082404\n",
      "157 Train Loss 0.0064187744 Test MSE 0.0009689352131531945 Test RE 0.022489678475852214\n",
      "158 Train Loss 0.006290502 Test MSE 0.0010463368461210393 Test RE 0.023370695469342923\n",
      "159 Train Loss 0.0061760317 Test MSE 0.001043404852137155 Test RE 0.023337928388211027\n",
      "160 Train Loss 0.0060686115 Test MSE 0.0009835151961083421 Test RE 0.02265825260184694\n",
      "161 Train Loss 0.0059944717 Test MSE 0.0009456248064050186 Test RE 0.022217505948692366\n",
      "162 Train Loss 0.005871184 Test MSE 0.0008298487725461191 Test RE 0.020813032139744864\n",
      "163 Train Loss 0.005779109 Test MSE 0.0007846312292650405 Test RE 0.020238050332925347\n",
      "164 Train Loss 0.00565632 Test MSE 0.0006804900161835083 Test RE 0.018847196382626122\n",
      "165 Train Loss 0.00550071 Test MSE 0.0005569635568763822 Test RE 0.0170509769227253\n",
      "166 Train Loss 0.0053466987 Test MSE 0.0004901515207765803 Test RE 0.015995619110590855\n",
      "167 Train Loss 0.005217713 Test MSE 0.0004474168951472175 Test RE 0.01528241773758457\n",
      "168 Train Loss 0.0050903587 Test MSE 0.0004365872740696058 Test RE 0.01509633112456309\n",
      "169 Train Loss 0.0049585295 Test MSE 0.0003673359528989259 Test RE 0.01384737952321888\n",
      "170 Train Loss 0.004846898 Test MSE 0.00033151877984055275 Test RE 0.013154972500033689\n",
      "171 Train Loss 0.0047716773 Test MSE 0.0002927782750777541 Test RE 0.012362471425593864\n",
      "172 Train Loss 0.004708174 Test MSE 0.00027706268829514485 Test RE 0.01202610243684746\n",
      "173 Train Loss 0.0046322895 Test MSE 0.00027810552041586926 Test RE 0.012048713614172396\n",
      "174 Train Loss 0.0045584883 Test MSE 0.00027824004569890903 Test RE 0.012051627365477784\n",
      "175 Train Loss 0.0044694883 Test MSE 0.00025270846689131357 Test RE 0.011485390704499918\n",
      "176 Train Loss 0.004353578 Test MSE 0.000258246486118744 Test RE 0.011610557867626289\n",
      "177 Train Loss 0.0042423266 Test MSE 0.0002559228469546515 Test RE 0.01155820534773983\n",
      "178 Train Loss 0.004173557 Test MSE 0.0002540090897795998 Test RE 0.011514908889697459\n",
      "179 Train Loss 0.004117804 Test MSE 0.0002607562107580313 Test RE 0.011666839076300204\n",
      "180 Train Loss 0.0040421514 Test MSE 0.000248110824348963 Test RE 0.011380431596204343\n",
      "181 Train Loss 0.0039845346 Test MSE 0.00026026737440249675 Test RE 0.011655898108673903\n",
      "182 Train Loss 0.0039333226 Test MSE 0.00028069898088493856 Test RE 0.01210476311293051\n",
      "183 Train Loss 0.003898588 Test MSE 0.0002810360325571171 Test RE 0.012112028380901288\n",
      "184 Train Loss 0.0038368187 Test MSE 0.0002799431687103667 Test RE 0.01208845544016112\n",
      "185 Train Loss 0.003753973 Test MSE 0.0002992180839508453 Test RE 0.012497691373284952\n",
      "186 Train Loss 0.0036695083 Test MSE 0.0002882077997180502 Test RE 0.01226559842566526\n",
      "187 Train Loss 0.0036036416 Test MSE 0.00028967549101970887 Test RE 0.012296789898410512\n",
      "188 Train Loss 0.0035387743 Test MSE 0.00029222098953369537 Test RE 0.012350700217267531\n",
      "189 Train Loss 0.003479505 Test MSE 0.0003220730016373477 Test RE 0.012966209586997356\n",
      "190 Train Loss 0.003390261 Test MSE 0.00031783781435450604 Test RE 0.012880676105126936\n",
      "191 Train Loss 0.0033088198 Test MSE 0.00027667675201984283 Test RE 0.012017723599152652\n",
      "192 Train Loss 0.0032488422 Test MSE 0.0002428993623034174 Test RE 0.011260276741416483\n",
      "193 Train Loss 0.0031901635 Test MSE 0.0002328753619216957 Test RE 0.011025483618604183\n",
      "194 Train Loss 0.003143845 Test MSE 0.00022547935873203288 Test RE 0.01084898908839325\n",
      "195 Train Loss 0.003108165 Test MSE 0.00020813135368541162 Test RE 0.01042328544773837\n",
      "196 Train Loss 0.0030752372 Test MSE 0.0001969856727130121 Test RE 0.010140355876457624\n",
      "197 Train Loss 0.0030441561 Test MSE 0.00020143943413535005 Test RE 0.010254349684859623\n",
      "198 Train Loss 0.0030149496 Test MSE 0.00020113409782355059 Test RE 0.01024657510808288\n",
      "199 Train Loss 0.002978325 Test MSE 0.00019728251722627498 Test RE 0.010147993426456435\n",
      "200 Train Loss 0.0029289464 Test MSE 0.00018842038613476114 Test RE 0.009917445479076296\n",
      "201 Train Loss 0.0028956486 Test MSE 0.00019192193900314524 Test RE 0.010009172827557946\n",
      "202 Train Loss 0.0028703013 Test MSE 0.00019316767342101134 Test RE 0.010041604250858874\n",
      "203 Train Loss 0.0028265305 Test MSE 0.00019025354382491843 Test RE 0.009965572532506703\n",
      "204 Train Loss 0.0028019927 Test MSE 0.000185490524811191 Test RE 0.009840037236456071\n",
      "205 Train Loss 0.0027707887 Test MSE 0.0001773545377816766 Test RE 0.009621815595506211\n",
      "206 Train Loss 0.002736042 Test MSE 0.00018167520105992095 Test RE 0.009738312383610628\n",
      "207 Train Loss 0.0027157955 Test MSE 0.00018153686848371514 Test RE 0.009734604165965752\n",
      "208 Train Loss 0.002688535 Test MSE 0.00017321205683504221 Test RE 0.009508782996369503\n",
      "209 Train Loss 0.002661538 Test MSE 0.0001855931440047537 Test RE 0.00984275876917431\n",
      "210 Train Loss 0.0026305509 Test MSE 0.0001878093286051009 Test RE 0.009901351012933253\n",
      "211 Train Loss 0.0026062464 Test MSE 0.00019138200328679264 Test RE 0.00999508346319618\n",
      "212 Train Loss 0.0025820583 Test MSE 0.00019556136173505125 Test RE 0.01010362928998424\n",
      "213 Train Loss 0.0025396124 Test MSE 0.0001989490467250268 Test RE 0.010190765500549231\n",
      "214 Train Loss 0.0025105688 Test MSE 0.00019939372899250446 Test RE 0.01020214812180924\n",
      "215 Train Loss 0.0024838378 Test MSE 0.00020661668591034725 Test RE 0.010385288665671467\n",
      "216 Train Loss 0.002468769 Test MSE 0.00020384858823579787 Test RE 0.010315486877588327\n",
      "217 Train Loss 0.002448226 Test MSE 0.00020671206483563587 Test RE 0.010387685430918477\n",
      "218 Train Loss 0.0024301244 Test MSE 0.00020752438476407463 Test RE 0.010408075750857575\n",
      "219 Train Loss 0.0024095364 Test MSE 0.00021487891466089455 Test RE 0.010590897813613753\n",
      "220 Train Loss 0.0023814554 Test MSE 0.00021282430700005233 Test RE 0.010540142703520935\n",
      "221 Train Loss 0.0023608361 Test MSE 0.0002041665674905483 Test RE 0.0103235292013304\n",
      "222 Train Loss 0.0023347007 Test MSE 0.0002022270800177183 Test RE 0.010274377830025072\n",
      "223 Train Loss 0.0023177285 Test MSE 0.00020201816780692159 Test RE 0.010269069446936256\n",
      "224 Train Loss 0.0022986808 Test MSE 0.0002098856158165114 Test RE 0.010467120281853901\n",
      "225 Train Loss 0.0022844065 Test MSE 0.0002087562604254789 Test RE 0.0104389214856145\n",
      "226 Train Loss 0.0022640945 Test MSE 0.0002086325654647612 Test RE 0.01043582832492795\n",
      "227 Train Loss 0.002243414 Test MSE 0.00021657947476584746 Test RE 0.010632723612968976\n",
      "228 Train Loss 0.0022275103 Test MSE 0.00022042545800716917 Test RE 0.010726715269072162\n",
      "229 Train Loss 0.0022132038 Test MSE 0.00022816689635898603 Test RE 0.010913453299563123\n",
      "230 Train Loss 0.002184586 Test MSE 0.00022806819278193438 Test RE 0.010911092498285169\n",
      "231 Train Loss 0.0021658302 Test MSE 0.00023734659673831419 Test RE 0.011130825680081637\n",
      "232 Train Loss 0.0021467358 Test MSE 0.0002380127081455845 Test RE 0.011146434025121258\n",
      "233 Train Loss 0.0021123702 Test MSE 0.00025618679662573553 Test RE 0.011564164171510408\n",
      "234 Train Loss 0.002078333 Test MSE 0.0002673454827672046 Test RE 0.011813329078937777\n",
      "235 Train Loss 0.0020597952 Test MSE 0.0002826179517199809 Test RE 0.012146069145242194\n",
      "236 Train Loss 0.0020372926 Test MSE 0.0002758144693871945 Test RE 0.011998981943275299\n",
      "237 Train Loss 0.002018314 Test MSE 0.0002524505428798791 Test RE 0.01147952799174625\n",
      "238 Train Loss 0.002010092 Test MSE 0.00025304276584089627 Test RE 0.011492984999088567\n",
      "239 Train Loss 0.00199612 Test MSE 0.00025293379788882413 Test RE 0.011490510117243382\n",
      "240 Train Loss 0.0019811532 Test MSE 0.00024183592107926774 Test RE 0.01123560031220045\n",
      "241 Train Loss 0.0019601188 Test MSE 0.00023474913084846206 Test RE 0.011069751542870083\n",
      "242 Train Loss 0.0019297953 Test MSE 0.000234139730565383 Test RE 0.011055373867804967\n",
      "243 Train Loss 0.0019174605 Test MSE 0.00023927149218238097 Test RE 0.011175870374875677\n",
      "244 Train Loss 0.0018990439 Test MSE 0.0002493213291297469 Test RE 0.011408159739033644\n",
      "245 Train Loss 0.0018801459 Test MSE 0.00023391328203039893 Test RE 0.01105002646518298\n",
      "246 Train Loss 0.0018591443 Test MSE 0.00022492705638505866 Test RE 0.010835693867244178\n",
      "247 Train Loss 0.001846688 Test MSE 0.0002196506902559284 Test RE 0.01070784714743468\n",
      "248 Train Loss 0.0018331292 Test MSE 0.00021726124116130596 Test RE 0.010649445737369327\n",
      "249 Train Loss 0.001821731 Test MSE 0.00022700752827753176 Test RE 0.010885691114497562\n",
      "250 Train Loss 0.0018012719 Test MSE 0.00022794248745038674 Test RE 0.01090808512682605\n",
      "251 Train Loss 0.0017843923 Test MSE 0.00021512068852702615 Test RE 0.010596854383259597\n",
      "252 Train Loss 0.0017725939 Test MSE 0.0001994724997057403 Test RE 0.010204163107774566\n",
      "253 Train Loss 0.0017561204 Test MSE 0.00019081818246781399 Test RE 0.009980349599142907\n",
      "254 Train Loss 0.0017411051 Test MSE 0.00018209024900673506 Test RE 0.009749429918359196\n",
      "255 Train Loss 0.0017236343 Test MSE 0.00016900552191867835 Test RE 0.009392610740452757\n",
      "256 Train Loss 0.0017043242 Test MSE 0.00017815773876830312 Test RE 0.009643578561740694\n",
      "257 Train Loss 0.0016903093 Test MSE 0.00018368439822822154 Test RE 0.009792013685817183\n",
      "258 Train Loss 0.0016743803 Test MSE 0.00018360692690212822 Test RE 0.009789948512353944\n",
      "259 Train Loss 0.0016581906 Test MSE 0.00018126119178877095 Test RE 0.009727210012065595\n",
      "260 Train Loss 0.0016445942 Test MSE 0.00018503836507370572 Test RE 0.009828036668231616\n",
      "261 Train Loss 0.0016309961 Test MSE 0.00017179776540760027 Test RE 0.009469883411146024\n",
      "262 Train Loss 0.0016197134 Test MSE 0.00016258363102975866 Test RE 0.009212431808327672\n",
      "263 Train Loss 0.0016096934 Test MSE 0.00015771616675251798 Test RE 0.009073482030218724\n",
      "264 Train Loss 0.0015963838 Test MSE 0.00015599655038461512 Test RE 0.009023881305924518\n",
      "265 Train Loss 0.0015835703 Test MSE 0.00014283796565608826 Test RE 0.008634907805687524\n",
      "266 Train Loss 0.0015703811 Test MSE 0.0001357166354154697 Test RE 0.008416904877746325\n",
      "267 Train Loss 0.0015601988 Test MSE 0.00012823736496248172 Test RE 0.008181692813859371\n",
      "268 Train Loss 0.0015448864 Test MSE 0.00012462701397663684 Test RE 0.008065698274669394\n",
      "269 Train Loss 0.0015378952 Test MSE 0.00011816223878287837 Test RE 0.007853716718078543\n",
      "270 Train Loss 0.0015261627 Test MSE 0.00010557223766933213 Test RE 0.007423534655334674\n",
      "271 Train Loss 0.001499746 Test MSE 8.943601758081867e-05 Test RE 0.00683269607357325\n",
      "272 Train Loss 0.0014830545 Test MSE 7.834807821080692e-05 Test RE 0.006395139921319291\n",
      "273 Train Loss 0.0014639024 Test MSE 7.814713774604337e-05 Test RE 0.006386933801798369\n",
      "274 Train Loss 0.0014450643 Test MSE 7.569072187030531e-05 Test RE 0.006285751395695199\n",
      "275 Train Loss 0.0014276957 Test MSE 7.370250413572037e-05 Test RE 0.0062026460451953085\n",
      "276 Train Loss 0.0014139493 Test MSE 7.304091986839954e-05 Test RE 0.006174744527494286\n",
      "277 Train Loss 0.0013937923 Test MSE 7.386101506643927e-05 Test RE 0.006209312434248658\n",
      "278 Train Loss 0.001380785 Test MSE 7.74482504521315e-05 Test RE 0.0063583097730793925\n",
      "279 Train Loss 0.001365251 Test MSE 7.895990769820455e-05 Test RE 0.006420061567110371\n",
      "280 Train Loss 0.0013535521 Test MSE 7.578792075252256e-05 Test RE 0.0062897860513000566\n",
      "281 Train Loss 0.0013390396 Test MSE 7.62326388176636e-05 Test RE 0.006308213064704946\n",
      "282 Train Loss 0.0013238733 Test MSE 7.471721963388178e-05 Test RE 0.006245198233645097\n",
      "283 Train Loss 0.0013108188 Test MSE 7.22298186433259e-05 Test RE 0.006140364315000861\n",
      "284 Train Loss 0.0012995541 Test MSE 7.083573955947208e-05 Test RE 0.006080819232910047\n",
      "285 Train Loss 0.0012868623 Test MSE 7.050893916554478e-05 Test RE 0.006066776099906141\n",
      "286 Train Loss 0.0012719898 Test MSE 7.009058749595549e-05 Test RE 0.006048751279886099\n",
      "287 Train Loss 0.0012622621 Test MSE 6.637410073127068e-05 Test RE 0.0058862025421704\n",
      "288 Train Loss 0.0012527329 Test MSE 6.445267976706898e-05 Test RE 0.005800378930337857\n",
      "289 Train Loss 0.0012411847 Test MSE 6.478808448467489e-05 Test RE 0.005815451616369923\n",
      "290 Train Loss 0.0012254363 Test MSE 6.353072505900777e-05 Test RE 0.005758744133215841\n",
      "291 Train Loss 0.0012154953 Test MSE 6.272713375398052e-05 Test RE 0.005722207451894566\n",
      "292 Train Loss 0.0012100218 Test MSE 6.10269278612372e-05 Test RE 0.005644125095215747\n",
      "293 Train Loss 0.0012019917 Test MSE 6.35776167123842e-05 Test RE 0.005760868988738288\n",
      "294 Train Loss 0.001193465 Test MSE 6.09601208042584e-05 Test RE 0.005641034896742317\n",
      "295 Train Loss 0.0011844871 Test MSE 6.103792274845079e-05 Test RE 0.005644633507863836\n",
      "296 Train Loss 0.0011789543 Test MSE 6.342608973421725e-05 Test RE 0.005753999843152604\n",
      "297 Train Loss 0.0011735325 Test MSE 6.482311623462667e-05 Test RE 0.00581702364860936\n",
      "298 Train Loss 0.0011651645 Test MSE 6.560466535127663e-05 Test RE 0.005851985470106697\n",
      "299 Train Loss 0.0011581465 Test MSE 6.657690110624047e-05 Test RE 0.005895188077413157\n",
      "Training time: 188.21\n",
      "KG_stan_high\n",
      "1\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "0 Train Loss 18915.414 Test MSE 8.623811503736965 Test RE 2.121707465662242\n",
      "1 Train Loss 1585.6544 Test MSE 8.181179253640563 Test RE 2.0665400721618092\n",
      "2 Train Loss 611.06714 Test MSE 9.21829620903361 Test RE 2.1936190370595927\n",
      "3 Train Loss 306.83243 Test MSE 7.753357307894589 Test RE 2.0117813427384865\n",
      "4 Train Loss 189.56387 Test MSE 6.3969057030898 Test RE 1.8273462709666068\n",
      "5 Train Loss 135.28883 Test MSE 5.6702213137403765 Test RE 1.720425543372866\n",
      "6 Train Loss 103.01616 Test MSE 5.051746356655036 Test RE 1.6238901418772784\n",
      "7 Train Loss 68.95319 Test MSE 4.066452247907018 Test RE 1.4569468716616973\n",
      "8 Train Loss 46.930458 Test MSE 3.193919485674802 Test RE 1.291212907776329\n",
      "9 Train Loss 29.937319 Test MSE 1.830636789485107 Test RE 0.9775454752902433\n",
      "10 Train Loss 14.029831 Test MSE 0.5533821918664914 Test RE 0.5374628695081944\n",
      "11 Train Loss 7.8301435 Test MSE 0.3416775064389773 Test RE 0.4223223555928368\n",
      "12 Train Loss 4.2927938 Test MSE 0.28938482847424446 Test RE 0.3886634990836431\n",
      "13 Train Loss 2.5109575 Test MSE 0.20101160689792366 Test RE 0.32392647467944885\n",
      "14 Train Loss 1.6584927 Test MSE 0.14248120107562862 Test RE 0.27271853836028354\n",
      "15 Train Loss 1.2085706 Test MSE 0.12378625300965929 Test RE 0.2541979743610408\n",
      "16 Train Loss 0.9571586 Test MSE 0.1155120020938029 Test RE 0.24555536799631722\n",
      "17 Train Loss 0.817016 Test MSE 0.10871744604197081 Test RE 0.23822399181847065\n",
      "18 Train Loss 0.7117151 Test MSE 0.09005426384601165 Test RE 0.21681434711225941\n",
      "19 Train Loss 0.5842336 Test MSE 0.0634411738877727 Test RE 0.18197908711122113\n",
      "20 Train Loss 0.49168026 Test MSE 0.04756553285237514 Test RE 0.15757309306534095\n",
      "21 Train Loss 0.39421862 Test MSE 0.033213803997132786 Test RE 0.13167253175810537\n",
      "22 Train Loss 0.3538762 Test MSE 0.03365042915241569 Test RE 0.13253518252547894\n",
      "23 Train Loss 0.30561996 Test MSE 0.038397196866410695 Test RE 0.14157469579688248\n",
      "24 Train Loss 0.27853715 Test MSE 0.042782542608361306 Test RE 0.1494407961707063\n",
      "25 Train Loss 0.2578243 Test MSE 0.04526054331702091 Test RE 0.15370774754526972\n",
      "26 Train Loss 0.23647717 Test MSE 0.04604514978845152 Test RE 0.15503431043834004\n",
      "27 Train Loss 0.21883532 Test MSE 0.049315409683223385 Test RE 0.160445373864806\n",
      "28 Train Loss 0.20284276 Test MSE 0.04031870386053838 Test RE 0.145073857154473\n",
      "29 Train Loss 0.1843572 Test MSE 0.03482899933096024 Test RE 0.13483615988341285\n",
      "30 Train Loss 0.15915531 Test MSE 0.03316781249960765 Test RE 0.1315813360197345\n",
      "31 Train Loss 0.1448457 Test MSE 0.02729961436657582 Test RE 0.11937520572188864\n",
      "32 Train Loss 0.13131997 Test MSE 0.023671939063386917 Test RE 0.11116108932126981\n",
      "33 Train Loss 0.12163792 Test MSE 0.01940546646506203 Test RE 0.10064632466524093\n",
      "34 Train Loss 0.11244726 Test MSE 0.01611200713488876 Test RE 0.09170873430016425\n",
      "35 Train Loss 0.10242678 Test MSE 0.011609543157049988 Test RE 0.07784727985983897\n",
      "36 Train Loss 0.09640965 Test MSE 0.010076662131645424 Test RE 0.07252608345834494\n",
      "37 Train Loss 0.0905712 Test MSE 0.00902726404545296 Test RE 0.06864579668972128\n",
      "38 Train Loss 0.085861996 Test MSE 0.008334813739250218 Test RE 0.06596048288415064\n",
      "39 Train Loss 0.07839276 Test MSE 0.006472182053184285 Test RE 0.05812476891940397\n",
      "40 Train Loss 0.07361161 Test MSE 0.005074917359905807 Test RE 0.051469549166648185\n",
      "41 Train Loss 0.06975331 Test MSE 0.004440282363731797 Test RE 0.048143889220911305\n",
      "42 Train Loss 0.066598095 Test MSE 0.003971827678589636 Test RE 0.04553350436111976\n",
      "43 Train Loss 0.06292988 Test MSE 0.0035661971144680493 Test RE 0.043145802288453675\n",
      "44 Train Loss 0.06054495 Test MSE 0.0031301172522316973 Test RE 0.04042184943111429\n",
      "45 Train Loss 0.05820607 Test MSE 0.003350312275694207 Test RE 0.04181946968478531\n",
      "46 Train Loss 0.05569487 Test MSE 0.002791504582772949 Test RE 0.03817289075914343\n",
      "47 Train Loss 0.05231034 Test MSE 0.0026639111876666233 Test RE 0.037290288881184436\n",
      "48 Train Loss 0.05054576 Test MSE 0.002483556669347293 Test RE 0.03600583723700205\n",
      "49 Train Loss 0.04873119 Test MSE 0.0023486015415125103 Test RE 0.0350139048881785\n",
      "50 Train Loss 0.045824982 Test MSE 0.001923180387570987 Test RE 0.03168442919779017\n",
      "51 Train Loss 0.044531208 Test MSE 0.0018691567553471703 Test RE 0.031236239151836234\n",
      "52 Train Loss 0.0429761 Test MSE 0.0018931804810968953 Test RE 0.03143633339479872\n",
      "53 Train Loss 0.041961476 Test MSE 0.0018119988616902719 Test RE 0.0307549366757854\n",
      "54 Train Loss 0.04028491 Test MSE 0.0015328012981734433 Test RE 0.028286473481768045\n",
      "55 Train Loss 0.038674295 Test MSE 0.001447267768719703 Test RE 0.027485922780038044\n",
      "56 Train Loss 0.037027933 Test MSE 0.001745610084930263 Test RE 0.03018627318260821\n",
      "57 Train Loss 0.035916105 Test MSE 0.0018738190087352119 Test RE 0.03127517129654799\n",
      "58 Train Loss 0.035094116 Test MSE 0.0018093184563213933 Test RE 0.03073218108594537\n",
      "59 Train Loss 0.03388952 Test MSE 0.0018940418410723697 Test RE 0.03144348403900384\n",
      "60 Train Loss 0.03281332 Test MSE 0.0020699605397145886 Test RE 0.03287130228140653\n",
      "61 Train Loss 0.031852886 Test MSE 0.0018960226793363676 Test RE 0.03145992194940819\n",
      "62 Train Loss 0.030410934 Test MSE 0.0016923852892125374 Test RE 0.029722511086264527\n",
      "63 Train Loss 0.029935151 Test MSE 0.0016399026707420827 Test RE 0.02925801872188265\n",
      "64 Train Loss 0.02900068 Test MSE 0.0018425116463823734 Test RE 0.031012801379644264\n",
      "65 Train Loss 0.027885912 Test MSE 0.0019611336857917904 Test RE 0.031995542382016295\n",
      "66 Train Loss 0.026875274 Test MSE 0.001734162165365958 Test RE 0.03008712776972689\n",
      "67 Train Loss 0.025932861 Test MSE 0.0015554323526366575 Test RE 0.028494526254839184\n",
      "68 Train Loss 0.024972398 Test MSE 0.0014776673862600706 Test RE 0.027773091241858026\n",
      "69 Train Loss 0.024023723 Test MSE 0.0014169632200097995 Test RE 0.027196634554376122\n",
      "70 Train Loss 0.023023905 Test MSE 0.0011902277666402616 Test RE 0.0249259038663604\n",
      "71 Train Loss 0.022325838 Test MSE 0.000977925788345573 Test RE 0.022593776393376883\n",
      "72 Train Loss 0.02182167 Test MSE 0.0009734592808399068 Test RE 0.022542120753848406\n",
      "73 Train Loss 0.020999268 Test MSE 0.0011813997823604586 Test RE 0.02483329342816085\n",
      "74 Train Loss 0.020460567 Test MSE 0.0011570325732190745 Test RE 0.02457585690640457\n",
      "75 Train Loss 0.019811824 Test MSE 0.001230660034510673 Test RE 0.025345737080791325\n",
      "76 Train Loss 0.019044017 Test MSE 0.0013643725593742511 Test RE 0.026687160342917637\n",
      "77 Train Loss 0.018532885 Test MSE 0.0013516061184342917 Test RE 0.026562010951828936\n",
      "78 Train Loss 0.01803536 Test MSE 0.0012361457152864218 Test RE 0.025402163722419855\n",
      "79 Train Loss 0.017291756 Test MSE 0.0010103204032176265 Test RE 0.022964946535506174\n",
      "80 Train Loss 0.016910922 Test MSE 0.0010437957019767078 Test RE 0.02334229906536866\n",
      "81 Train Loss 0.01656194 Test MSE 0.0009734912392571587 Test RE 0.022542490776818212\n",
      "82 Train Loss 0.01615608 Test MSE 0.0008081208358065697 Test RE 0.02053875096510461\n",
      "83 Train Loss 0.015557694 Test MSE 0.0007391290670453668 Test RE 0.019642466346977628\n",
      "84 Train Loss 0.0151348375 Test MSE 0.0006712072072197567 Test RE 0.01871820427419721\n",
      "85 Train Loss 0.014847562 Test MSE 0.0005835698387963626 Test RE 0.017453490572976706\n",
      "86 Train Loss 0.014492236 Test MSE 0.0004838752779224781 Test RE 0.015892879617163718\n",
      "87 Train Loss 0.014218388 Test MSE 0.00046318496772113457 Test RE 0.015549381000383422\n",
      "88 Train Loss 0.013796717 Test MSE 0.0004474787718458545 Test RE 0.015283474462168363\n",
      "89 Train Loss 0.013488116 Test MSE 0.0004472549450660519 Test RE 0.015279651622998417\n",
      "90 Train Loss 0.013055775 Test MSE 0.0005006362318517259 Test RE 0.016165793072870478\n",
      "91 Train Loss 0.012719033 Test MSE 0.0005308013243031587 Test RE 0.016645692814786006\n",
      "92 Train Loss 0.012360439 Test MSE 0.0005771247160029075 Test RE 0.017356842149230705\n",
      "93 Train Loss 0.012139748 Test MSE 0.0006355403019470374 Test RE 0.01821408776406815\n",
      "94 Train Loss 0.01184959 Test MSE 0.0005884887443294744 Test RE 0.017526893885234558\n",
      "95 Train Loss 0.011490516 Test MSE 0.0006191661433174548 Test RE 0.017977921394196128\n",
      "96 Train Loss 0.011202014 Test MSE 0.0006182261505627704 Test RE 0.01796426953774575\n",
      "97 Train Loss 0.010890015 Test MSE 0.0005087439880730148 Test RE 0.016296169077775525\n",
      "98 Train Loss 0.010654718 Test MSE 0.0004440151375127386 Test RE 0.015224209973154441\n",
      "99 Train Loss 0.010456973 Test MSE 0.00040444305139763923 Test RE 0.014529964929847237\n",
      "100 Train Loss 0.010354336 Test MSE 0.00039696628992222605 Test RE 0.01439503387047022\n",
      "101 Train Loss 0.010186405 Test MSE 0.0003892992176320039 Test RE 0.014255342046753517\n",
      "102 Train Loss 0.009971798 Test MSE 0.00037311712262318413 Test RE 0.01395591985314618\n",
      "103 Train Loss 0.009721949 Test MSE 0.0004070718139236162 Test RE 0.014577108727494242\n",
      "104 Train Loss 0.009459137 Test MSE 0.00040979733215904007 Test RE 0.014625827274707555\n",
      "105 Train Loss 0.009316377 Test MSE 0.00038581983684338834 Test RE 0.014191495159687638\n",
      "106 Train Loss 0.009191497 Test MSE 0.0003989903937295559 Test RE 0.014431686850899147\n",
      "107 Train Loss 0.009029359 Test MSE 0.00045661655375898075 Test RE 0.01543873464802071\n",
      "108 Train Loss 0.008825941 Test MSE 0.00046809050973879886 Test RE 0.015631505039605646\n",
      "109 Train Loss 0.0085847415 Test MSE 0.0004196565738989237 Test RE 0.01480072168781037\n",
      "110 Train Loss 0.008397242 Test MSE 0.000519050245391883 Test RE 0.01646040729830687\n",
      "111 Train Loss 0.00825518 Test MSE 0.0005324653415833746 Test RE 0.016671763818089175\n",
      "112 Train Loss 0.008026443 Test MSE 0.0005066181860208333 Test RE 0.016262086420392455\n",
      "113 Train Loss 0.007798525 Test MSE 0.0004728942138500123 Test RE 0.015711508220762255\n",
      "114 Train Loss 0.0076624863 Test MSE 0.0005020777247578865 Test RE 0.016189049605798353\n",
      "115 Train Loss 0.0075478638 Test MSE 0.0004915608461316697 Test RE 0.01601859858680567\n",
      "116 Train Loss 0.007455757 Test MSE 0.00047832811925792827 Test RE 0.015801518830899006\n",
      "117 Train Loss 0.007308425 Test MSE 0.000477055482398665 Test RE 0.01578048411834881\n",
      "118 Train Loss 0.0071645672 Test MSE 0.0004615925847433221 Test RE 0.015522629390238765\n",
      "119 Train Loss 0.007009938 Test MSE 0.00043872714732666327 Test RE 0.01513328221106335\n",
      "120 Train Loss 0.0068249544 Test MSE 0.0004276747869340811 Test RE 0.014941448448487916\n",
      "121 Train Loss 0.0066686366 Test MSE 0.00041479813156436164 Test RE 0.01471479691593726\n",
      "122 Train Loss 0.0065607107 Test MSE 0.0003996123720471556 Test RE 0.014442931107613664\n",
      "123 Train Loss 0.0063327607 Test MSE 0.0003418366721902355 Test RE 0.013358115765141673\n",
      "124 Train Loss 0.006138756 Test MSE 0.00023064633215042347 Test RE 0.010972590037562619\n",
      "125 Train Loss 0.0060277195 Test MSE 0.0002061083601788995 Test RE 0.010372505669957476\n",
      "126 Train Loss 0.0059700315 Test MSE 0.00020800586154183683 Test RE 0.01042014263037822\n",
      "127 Train Loss 0.005897674 Test MSE 0.00019373643886641 Test RE 0.010056376700802219\n",
      "128 Train Loss 0.005802098 Test MSE 0.00017492721371286732 Test RE 0.009555745315819647\n",
      "129 Train Loss 0.0057242434 Test MSE 0.00017302152053718246 Test RE 0.009503551643365433\n",
      "130 Train Loss 0.0056585046 Test MSE 0.00015627771710880007 Test RE 0.009032009924492993\n",
      "131 Train Loss 0.0056065666 Test MSE 0.00015700015851873185 Test RE 0.009052862463233984\n",
      "132 Train Loss 0.005495078 Test MSE 0.0001448778112603507 Test RE 0.008696346088146366\n",
      "133 Train Loss 0.0054275054 Test MSE 0.00014049620153756582 Test RE 0.008563832577899045\n",
      "134 Train Loss 0.00536541 Test MSE 0.00011801548736731561 Test RE 0.007848838247045159\n",
      "135 Train Loss 0.0053215874 Test MSE 0.00012082608174726977 Test RE 0.007941750205088067\n",
      "136 Train Loss 0.0052747703 Test MSE 0.00011782971239005404 Test RE 0.007842658159760462\n",
      "137 Train Loss 0.0052238815 Test MSE 0.00011374570378843002 Test RE 0.0077055453006895204\n",
      "138 Train Loss 0.005142206 Test MSE 0.00011432672949515716 Test RE 0.007725200623504504\n",
      "139 Train Loss 0.0050655315 Test MSE 0.00010853604282820879 Test RE 0.007527016509057515\n",
      "140 Train Loss 0.004970008 Test MSE 9.362963736974597e-05 Test RE 0.006991052243279426\n",
      "141 Train Loss 0.0048971926 Test MSE 8.82471699006286e-05 Test RE 0.0067871316001290325\n",
      "142 Train Loss 0.00473261 Test MSE 0.00010801926959247376 Test RE 0.007509075916626647\n",
      "143 Train Loss 0.0046230573 Test MSE 0.00012080035349906605 Test RE 0.007940904616967425\n",
      "144 Train Loss 0.0045317095 Test MSE 0.0001383598437192921 Test RE 0.008498473182247562\n",
      "145 Train Loss 0.004480416 Test MSE 0.00014357944526637413 Test RE 0.00865729093215775\n",
      "146 Train Loss 0.004445581 Test MSE 0.00014556882232594695 Test RE 0.008717060519459214\n",
      "147 Train Loss 0.004392465 Test MSE 0.00013024657821158656 Test RE 0.008245538771784956\n",
      "148 Train Loss 0.0043355995 Test MSE 0.00012330918097942128 Test RE 0.008022940723466047\n",
      "149 Train Loss 0.004302834 Test MSE 0.00012003518966102042 Test RE 0.007915715347457868\n",
      "150 Train Loss 0.0042355955 Test MSE 0.00011198860628383302 Test RE 0.007645797593579578\n",
      "151 Train Loss 0.0042000697 Test MSE 0.00012029143891803624 Test RE 0.007924160016013258\n",
      "152 Train Loss 0.004163217 Test MSE 0.00011210389506757443 Test RE 0.007649732136514554\n",
      "153 Train Loss 0.004117066 Test MSE 0.00011352273145424287 Test RE 0.007697989119719495\n",
      "154 Train Loss 0.0040722913 Test MSE 0.0001030744776479529 Test RE 0.0073351913603329835\n",
      "155 Train Loss 0.0040303627 Test MSE 0.00010639796374527632 Test RE 0.007452509445279539\n",
      "156 Train Loss 0.003959221 Test MSE 9.208221115073281e-05 Test RE 0.006933040650072833\n",
      "157 Train Loss 0.0039055275 Test MSE 7.492790976971016e-05 Test RE 0.006253997245376296\n",
      "158 Train Loss 0.003850111 Test MSE 6.631426091941475e-05 Test RE 0.005883548580210951\n",
      "159 Train Loss 0.0038090905 Test MSE 5.534295486229658e-05 Test RE 0.005374858662309713\n",
      "160 Train Loss 0.003770286 Test MSE 5.2948723546226414e-05 Test RE 0.00525731046195383\n",
      "161 Train Loss 0.0037358338 Test MSE 4.924196894110355e-05 Test RE 0.005069948896864862\n",
      "162 Train Loss 0.0036813442 Test MSE 4.617100244693065e-05 Test RE 0.004909310816196355\n",
      "163 Train Loss 0.0036263673 Test MSE 4.616821367171872e-05 Test RE 0.004909162550289947\n",
      "164 Train Loss 0.003582205 Test MSE 4.437562358256409e-05 Test RE 0.0048129141093188185\n",
      "165 Train Loss 0.0035403732 Test MSE 4.668850220970413e-05 Test RE 0.00493674673688968\n",
      "166 Train Loss 0.0034970604 Test MSE 4.4791195295870776e-05 Test RE 0.0048353977378070906\n",
      "167 Train Loss 0.003462952 Test MSE 4.0923070167766604e-05 Test RE 0.004621894000368672\n",
      "168 Train Loss 0.0034258303 Test MSE 4.236958136301947e-05 Test RE 0.004702869886487084\n",
      "169 Train Loss 0.0033729572 Test MSE 4.603750644047824e-05 Test RE 0.004902208438444725\n",
      "170 Train Loss 0.003342038 Test MSE 4.878676855782566e-05 Test RE 0.005046460792714971\n",
      "171 Train Loss 0.0032989427 Test MSE 5.458480945539266e-05 Test RE 0.005337916503432644\n",
      "172 Train Loss 0.0032651112 Test MSE 5.988710781111821e-05 Test RE 0.005591168063177439\n",
      "173 Train Loss 0.0032329303 Test MSE 6.696552550539395e-05 Test RE 0.0059123688136553075\n",
      "174 Train Loss 0.0031987368 Test MSE 6.492493504437621e-05 Test RE 0.00582159030680127\n",
      "175 Train Loss 0.0031690206 Test MSE 6.383636131644244e-05 Test RE 0.005772579716012355\n",
      "176 Train Loss 0.00313652 Test MSE 6.205788023888282e-05 Test RE 0.0056915996680627495\n",
      "177 Train Loss 0.0031060758 Test MSE 6.54195620085844e-05 Test RE 0.005843723959871241\n",
      "178 Train Loss 0.0030619092 Test MSE 7.469582155020367e-05 Test RE 0.006244303896005891\n",
      "179 Train Loss 0.0030166535 Test MSE 6.564510450819424e-05 Test RE 0.0058537887938536395\n",
      "180 Train Loss 0.0029801573 Test MSE 6.069236677187005e-05 Test RE 0.005628632755725041\n",
      "181 Train Loss 0.0029509913 Test MSE 5.2536938492348965e-05 Test RE 0.005236827367421452\n",
      "182 Train Loss 0.0029195384 Test MSE 5.2340717483151705e-05 Test RE 0.005227038665858317\n",
      "183 Train Loss 0.002888283 Test MSE 5.0600419688513865e-05 Test RE 0.0051394061086123466\n",
      "184 Train Loss 0.0028580953 Test MSE 5.022182761721415e-05 Test RE 0.0051201435056894996\n",
      "185 Train Loss 0.0028180622 Test MSE 5.187782794310262e-05 Test RE 0.005203873958751477\n",
      "186 Train Loss 0.0027853006 Test MSE 4.701830098412154e-05 Test RE 0.004954152177744525\n",
      "187 Train Loss 0.0027580908 Test MSE 4.660183262830774e-05 Test RE 0.004932162476277962\n",
      "188 Train Loss 0.0027343468 Test MSE 4.5008865306477804e-05 Test RE 0.004847132694239791\n",
      "189 Train Loss 0.002693217 Test MSE 4.362111098316349e-05 Test RE 0.004771822032774403\n",
      "190 Train Loss 0.0026376084 Test MSE 4.358781510628962e-05 Test RE 0.004770000525648462\n",
      "191 Train Loss 0.0025859883 Test MSE 4.536459682464381e-05 Test RE 0.0048662498644081\n",
      "192 Train Loss 0.0025506313 Test MSE 4.5798159758551485e-05 Test RE 0.004889448664845868\n",
      "193 Train Loss 0.0024841493 Test MSE 4.6943742594056526e-05 Test RE 0.004950222642320954\n",
      "194 Train Loss 0.0024493972 Test MSE 4.7372315330577825e-05 Test RE 0.00497276782298554\n",
      "195 Train Loss 0.0024194135 Test MSE 4.8957831177643645e-05 Test RE 0.00505530033500752\n",
      "196 Train Loss 0.0023951733 Test MSE 4.88557439091509e-05 Test RE 0.005050026907799363\n",
      "197 Train Loss 0.0023544636 Test MSE 4.4425558895676744e-05 Test RE 0.004815621302822398\n",
      "198 Train Loss 0.0023207264 Test MSE 4.365278422643068e-05 Test RE 0.004773554125918521\n",
      "199 Train Loss 0.002289224 Test MSE 4.777912239784054e-05 Test RE 0.004994073860288666\n",
      "200 Train Loss 0.0022679667 Test MSE 4.891339439360595e-05 Test RE 0.005053005581735877\n",
      "201 Train Loss 0.0022440164 Test MSE 4.6812848746296564e-05 Test RE 0.004943316439722697\n",
      "202 Train Loss 0.0022208674 Test MSE 4.654626707618179e-05 Test RE 0.004929221174856967\n",
      "203 Train Loss 0.002202126 Test MSE 4.775789560570273e-05 Test RE 0.004992964380466838\n",
      "204 Train Loss 0.0021834024 Test MSE 4.836912067570529e-05 Test RE 0.0050248137985459355\n",
      "205 Train Loss 0.00216316 Test MSE 4.8549503338450074e-05 Test RE 0.005034174582907781\n",
      "206 Train Loss 0.0021462806 Test MSE 4.873386414890161e-05 Test RE 0.0050437238575694685\n",
      "207 Train Loss 0.0021293901 Test MSE 5.0050247575015776e-05 Test RE 0.005111389681767201\n",
      "208 Train Loss 0.002109125 Test MSE 5.225388788582305e-05 Test RE 0.005222701220061717\n",
      "209 Train Loss 0.0020941405 Test MSE 5.183784503992186e-05 Test RE 0.005201868226224284\n",
      "210 Train Loss 0.0020705517 Test MSE 5.5786690931416936e-05 Test RE 0.0053963632693687395\n",
      "211 Train Loss 0.0020477744 Test MSE 5.89086571636037e-05 Test RE 0.005545305005291071\n",
      "212 Train Loss 0.0020314874 Test MSE 5.969329335885552e-05 Test RE 0.00558211329831604\n",
      "213 Train Loss 0.002019192 Test MSE 6.03205063403828e-05 Test RE 0.005611363024661271\n",
      "214 Train Loss 0.0019998003 Test MSE 6.241175573549301e-05 Test RE 0.005707804334657339\n",
      "215 Train Loss 0.0019772183 Test MSE 6.744791936697726e-05 Test RE 0.005933625814765652\n",
      "216 Train Loss 0.0019511398 Test MSE 7.319089000331824e-05 Test RE 0.006181080376092099\n",
      "217 Train Loss 0.0019270143 Test MSE 7.227525311650373e-05 Test RE 0.006142295237469478\n",
      "218 Train Loss 0.0019100276 Test MSE 7.515234893622436e-05 Test RE 0.006263356857749115\n",
      "219 Train Loss 0.001892221 Test MSE 7.458059216719537e-05 Test RE 0.006239485654644141\n",
      "220 Train Loss 0.0018728641 Test MSE 7.822682516373394e-05 Test RE 0.006390189382200641\n",
      "221 Train Loss 0.0018594149 Test MSE 7.44424340454977e-05 Test RE 0.0062337037535705195\n",
      "222 Train Loss 0.0018377693 Test MSE 7.951107796630795e-05 Test RE 0.00644242983928098\n",
      "223 Train Loss 0.0018150501 Test MSE 7.64055924954749e-05 Test RE 0.006315364926078887\n",
      "224 Train Loss 0.0018014493 Test MSE 7.509039761496558e-05 Test RE 0.00626077474795885\n",
      "225 Train Loss 0.0017741302 Test MSE 6.503434043902287e-05 Test RE 0.005826493240425698\n",
      "226 Train Loss 0.001753368 Test MSE 5.8072070667374956e-05 Test RE 0.005505788607725911\n",
      "227 Train Loss 0.0017263152 Test MSE 5.9385370197994324e-05 Test RE 0.005567697236949995\n",
      "228 Train Loss 0.0017057975 Test MSE 5.7832380817201406e-05 Test RE 0.005494414412003161\n",
      "229 Train Loss 0.0016767783 Test MSE 5.61571428341749e-05 Test RE 0.005414250916346878\n",
      "230 Train Loss 0.0016547962 Test MSE 5.556381645793915e-05 Test RE 0.005385572924468748\n",
      "231 Train Loss 0.0016367878 Test MSE 5.4345966977565425e-05 Test RE 0.005326225348698731\n",
      "232 Train Loss 0.0016200335 Test MSE 5.370228719512392e-05 Test RE 0.005294589186234271\n",
      "233 Train Loss 0.0016046034 Test MSE 5.382099231971139e-05 Test RE 0.005300437614431742\n",
      "234 Train Loss 0.0015875066 Test MSE 5.343404671706091e-05 Test RE 0.005281349516759107\n",
      "235 Train Loss 0.0015709429 Test MSE 5.3290262047026615e-05 Test RE 0.005274238988162202\n",
      "236 Train Loss 0.0015499803 Test MSE 5.191573945096528e-05 Test RE 0.005205775066469123\n",
      "237 Train Loss 0.0015260997 Test MSE 4.933877670316956e-05 Test RE 0.005074930109288096\n",
      "238 Train Loss 0.0014960965 Test MSE 4.966028935061982e-05 Test RE 0.005091438470558662\n",
      "239 Train Loss 0.0014739532 Test MSE 5.313615388727679e-05 Test RE 0.005266607277287455\n",
      "240 Train Loss 0.0014430899 Test MSE 5.304520108599945e-05 Test RE 0.005262097938481709\n",
      "241 Train Loss 0.0014148137 Test MSE 5.189367770030251e-05 Test RE 0.005204668843995588\n",
      "242 Train Loss 0.0013927672 Test MSE 5.300149847367143e-05 Test RE 0.005259929836493682\n",
      "243 Train Loss 0.0013728492 Test MSE 4.985518332451913e-05 Test RE 0.005101419473721071\n",
      "244 Train Loss 0.0013511883 Test MSE 4.973553633612254e-05 Test RE 0.005095294372167542\n",
      "245 Train Loss 0.0013275401 Test MSE 4.7612794812418495e-05 Test RE 0.004985373654238373\n",
      "246 Train Loss 0.0013083045 Test MSE 4.840239320142099e-05 Test RE 0.005026541755372433\n",
      "247 Train Loss 0.0012967531 Test MSE 4.58933601604682e-05 Test RE 0.004894527862734696\n",
      "248 Train Loss 0.0012810238 Test MSE 4.4901684910844175e-05 Test RE 0.004841357973535348\n",
      "249 Train Loss 0.0012616463 Test MSE 4.135827947119822e-05 Test RE 0.004646405499019832\n",
      "250 Train Loss 0.0012496437 Test MSE 3.789426669222428e-05 Test RE 0.004447568344945086\n",
      "251 Train Loss 0.0012381016 Test MSE 3.483465602446673e-05 Test RE 0.004264240004340731\n",
      "252 Train Loss 0.001222026 Test MSE 3.4900656232073796e-05 Test RE 0.004268277758325287\n",
      "253 Train Loss 0.0012103838 Test MSE 3.443986599537864e-05 Test RE 0.004240007290785599\n",
      "254 Train Loss 0.0012004504 Test MSE 3.4071261839275955e-05 Test RE 0.004217256205434524\n",
      "255 Train Loss 0.001195305 Test MSE 3.420992249102937e-05 Test RE 0.0042258290276526115\n",
      "256 Train Loss 0.0011883054 Test MSE 3.4062885616455333e-05 Test RE 0.0042167377795365646\n",
      "257 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "258 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "259 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "260 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "261 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "262 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "263 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "264 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "265 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "266 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "267 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "268 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "269 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "270 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "271 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "272 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "273 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "274 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "275 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "276 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "277 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "278 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "279 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "280 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "281 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "282 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "283 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "284 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "285 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "286 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "287 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "288 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "289 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "290 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "291 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "292 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "293 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "294 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "295 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "296 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "297 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "298 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "299 Train Loss 0.0011875706 Test MSE 3.4110776274261164e-05 Test RE 0.00421970099613037\n",
      "Training time: 168.47\n",
      "KG_stan_high\n",
      "2\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "0 Train Loss 44120.22 Test MSE 5.116614787734735 Test RE 1.6342829043442697\n",
      "1 Train Loss 11759.926 Test MSE 12.408648782819277 Test RE 2.54506057287246\n",
      "2 Train Loss 4879.4614 Test MSE 10.823958448717814 Test RE 2.3769986501450897\n",
      "3 Train Loss 1627.8862 Test MSE 9.936736985911036 Test RE 2.2774967937128485\n",
      "4 Train Loss 429.26895 Test MSE 8.376654900346358 Test RE 2.091082602697901\n",
      "5 Train Loss 232.28809 Test MSE 8.786233042460145 Test RE 2.1415944661028283\n",
      "6 Train Loss 165.23058 Test MSE 7.829156073711291 Test RE 2.0215912644997265\n",
      "7 Train Loss 124.67589 Test MSE 6.97209999867901 Test RE 1.9077333883566543\n",
      "8 Train Loss 90.23612 Test MSE 6.624415165771664 Test RE 1.8595576558874092\n",
      "9 Train Loss 75.00429 Test MSE 5.974156599035204 Test RE 1.7659328203940894\n",
      "10 Train Loss 64.515945 Test MSE 5.7664557816487205 Test RE 1.7349635694202028\n",
      "11 Train Loss 53.719994 Test MSE 5.473162563166204 Test RE 1.6902659809140161\n",
      "12 Train Loss 44.22049 Test MSE 5.594212002669497 Test RE 1.7088554870554957\n",
      "13 Train Loss 36.644665 Test MSE 5.385463538095581 Test RE 1.6766693363042955\n",
      "14 Train Loss 30.774715 Test MSE 4.936469075919533 Test RE 1.6052552068242325\n",
      "15 Train Loss 27.762531 Test MSE 4.689663542318652 Test RE 1.5646122265447355\n",
      "16 Train Loss 24.072628 Test MSE 4.388127844333376 Test RE 1.5134759105387698\n",
      "17 Train Loss 20.892227 Test MSE 4.08358421975477 Test RE 1.460012706076648\n",
      "18 Train Loss 18.80934 Test MSE 3.723165203209968 Test RE 1.3940939112631026\n",
      "19 Train Loss 15.76078 Test MSE 3.3509045080132633 Test RE 1.3225646263519892\n",
      "20 Train Loss 11.551168 Test MSE 3.2812108417599197 Test RE 1.3087387028421762\n",
      "21 Train Loss 9.048274 Test MSE 3.027238483420866 Test RE 1.2570692261948724\n",
      "22 Train Loss 7.292529 Test MSE 2.7680889451666157 Test RE 1.2020593125450623\n",
      "23 Train Loss 6.197219 Test MSE 2.541155158889039 Test RE 1.1517320926634351\n",
      "24 Train Loss 5.620848 Test MSE 2.496035023117595 Test RE 1.141461359208157\n",
      "25 Train Loss 5.1112576 Test MSE 2.390381746079104 Test RE 1.1170420158229697\n",
      "26 Train Loss 4.743012 Test MSE 2.231291490806675 Test RE 1.0792300554969576\n",
      "27 Train Loss 4.4029107 Test MSE 2.0934906284701307 Test RE 1.0453732612711797\n",
      "28 Train Loss 3.983218 Test MSE 1.8221570131613265 Test RE 0.9752787807960647\n",
      "29 Train Loss 3.6273718 Test MSE 1.493374145068293 Test RE 0.8829176342330836\n",
      "30 Train Loss 3.2472615 Test MSE 1.3359834243799844 Test RE 0.8350960160495502\n",
      "31 Train Loss 2.6914454 Test MSE 1.019413847386321 Test RE 0.7294762236739796\n",
      "32 Train Loss 2.239842 Test MSE 0.7134331720281624 Test RE 0.6102566577780062\n",
      "33 Train Loss 1.6806132 Test MSE 0.5618275550672412 Test RE 0.5415485466580018\n",
      "34 Train Loss 1.34844 Test MSE 0.5165458724065516 Test RE 0.5192665230522548\n",
      "35 Train Loss 1.0935403 Test MSE 0.3064643100774136 Test RE 0.3999685370048583\n",
      "36 Train Loss 0.899721 Test MSE 0.21134851165133914 Test RE 0.33215093078278574\n",
      "37 Train Loss 0.75343955 Test MSE 0.16005837835408318 Test RE 0.2890514039577763\n",
      "38 Train Loss 0.6349424 Test MSE 0.11955342593061465 Test RE 0.24981406699870318\n",
      "39 Train Loss 0.55175686 Test MSE 0.10393239306013964 Test RE 0.23292244509201132\n",
      "40 Train Loss 0.454238 Test MSE 0.08143860962376576 Test RE 0.20618214437014246\n",
      "41 Train Loss 0.3967686 Test MSE 0.05845714938973216 Test RE 0.17468462973300167\n",
      "42 Train Loss 0.35036746 Test MSE 0.03128711251753985 Test RE 0.1277963996781033\n",
      "43 Train Loss 0.31388474 Test MSE 0.02983919473451941 Test RE 0.12480426479561144\n",
      "44 Train Loss 0.2903025 Test MSE 0.0322836540310403 Test RE 0.12981569989379887\n",
      "45 Train Loss 0.26438767 Test MSE 0.02364171096978812 Test RE 0.11109009257709859\n",
      "46 Train Loss 0.25031224 Test MSE 0.02874030015915735 Test RE 0.12248461083243924\n",
      "47 Train Loss 0.22371078 Test MSE 0.027190732935512094 Test RE 0.1191369106131153\n",
      "48 Train Loss 0.20823349 Test MSE 0.023406562645686156 Test RE 0.11053624242794301\n",
      "49 Train Loss 0.19409628 Test MSE 0.023847327152889373 Test RE 0.11157213193932958\n",
      "50 Train Loss 0.18022409 Test MSE 0.02195986868812979 Test RE 0.1070657950482258\n",
      "51 Train Loss 0.17201366 Test MSE 0.01875301239268819 Test RE 0.09893988408095714\n",
      "52 Train Loss 0.165134 Test MSE 0.016571056033459815 Test RE 0.09300600067801415\n",
      "53 Train Loss 0.15724568 Test MSE 0.011927337911546933 Test RE 0.07890556584418422\n",
      "54 Train Loss 0.14733216 Test MSE 0.008094894104498387 Test RE 0.06500420672755454\n",
      "55 Train Loss 0.14369838 Test MSE 0.007787083294043775 Test RE 0.06375632663872376\n",
      "56 Train Loss 0.1364848 Test MSE 0.008340464448419434 Test RE 0.06598283853390852\n",
      "57 Train Loss 0.12670258 Test MSE 0.008512743751610171 Test RE 0.06666082084897601\n",
      "58 Train Loss 0.12236056 Test MSE 0.009131422823421128 Test RE 0.06904068685823253\n",
      "59 Train Loss 0.11432159 Test MSE 0.008403599134440892 Test RE 0.06623210235233888\n",
      "60 Train Loss 0.10992778 Test MSE 0.008940107737946556 Test RE 0.06831361269629097\n",
      "61 Train Loss 0.10499567 Test MSE 0.011578542040020927 Test RE 0.07774327206826548\n",
      "62 Train Loss 0.10074362 Test MSE 0.009635529986931285 Test RE 0.07092080892851711\n",
      "63 Train Loss 0.09799144 Test MSE 0.008900435741808469 Test RE 0.06816187231871303\n",
      "64 Train Loss 0.09307589 Test MSE 0.00805193374832387 Test RE 0.06483148557429218\n",
      "65 Train Loss 0.08960158 Test MSE 0.008419596445450163 Test RE 0.06629511296021467\n",
      "66 Train Loss 0.086509556 Test MSE 0.007924006589524963 Test RE 0.06431441014697284\n",
      "67 Train Loss 0.081143685 Test MSE 0.00793177530892593 Test RE 0.06434592944203783\n",
      "68 Train Loss 0.07687793 Test MSE 0.006218764373005706 Test RE 0.05697547149341481\n",
      "69 Train Loss 0.07411528 Test MSE 0.006393593130743239 Test RE 0.057770799079384316\n",
      "70 Train Loss 0.06958243 Test MSE 0.004754492222141049 Test RE 0.049818190330269296\n",
      "71 Train Loss 0.06489205 Test MSE 0.004374507819799029 Test RE 0.04778597763463784\n",
      "72 Train Loss 0.06280564 Test MSE 0.0039320440695869326 Test RE 0.0453048884304407\n",
      "73 Train Loss 0.06049144 Test MSE 0.004315932402474204 Test RE 0.047464968161721466\n",
      "74 Train Loss 0.057934847 Test MSE 0.0038574078642917803 Test RE 0.04487285041451866\n",
      "75 Train Loss 0.055550583 Test MSE 0.0031370173892051557 Test RE 0.040466378554367494\n",
      "76 Train Loss 0.05305526 Test MSE 0.0027782797587573823 Test RE 0.038082360889149056\n",
      "77 Train Loss 0.050849974 Test MSE 0.0023387720657473392 Test RE 0.03494055715628357\n",
      "78 Train Loss 0.04923047 Test MSE 0.0020626092030621803 Test RE 0.03281288016756783\n",
      "79 Train Loss 0.046613332 Test MSE 0.0018980585620516196 Test RE 0.031476807698699844\n",
      "80 Train Loss 0.044809397 Test MSE 0.001879954561549356 Test RE 0.03132633249235365\n",
      "81 Train Loss 0.043155476 Test MSE 0.002027361834684093 Test RE 0.032531306853667764\n",
      "82 Train Loss 0.04228328 Test MSE 0.002051100935006578 Test RE 0.03272121286970886\n",
      "83 Train Loss 0.040967625 Test MSE 0.002138951645028963 Test RE 0.03341460720059113\n",
      "84 Train Loss 0.03934585 Test MSE 0.0026581722731569097 Test RE 0.037250099635307385\n",
      "85 Train Loss 0.038355835 Test MSE 0.003003522611840544 Test RE 0.039596001298454316\n",
      "86 Train Loss 0.03746851 Test MSE 0.0027785420968535948 Test RE 0.03808415880352365\n",
      "87 Train Loss 0.036551148 Test MSE 0.0023668522176816956 Test RE 0.03514968585800577\n",
      "88 Train Loss 0.03570532 Test MSE 0.002131691392022084 Test RE 0.03335784932194012\n",
      "89 Train Loss 0.034387216 Test MSE 0.0018507392871924787 Test RE 0.03108196728467231\n",
      "90 Train Loss 0.033185918 Test MSE 0.0016923883897202565 Test RE 0.029722538312580378\n",
      "91 Train Loss 0.03194722 Test MSE 0.0016829314249118838 Test RE 0.029639378095624627\n",
      "92 Train Loss 0.030865978 Test MSE 0.0014477461757875217 Test RE 0.027490465261229124\n",
      "93 Train Loss 0.029617071 Test MSE 0.0013929472130768373 Test RE 0.02696517271148119\n",
      "94 Train Loss 0.028106531 Test MSE 0.0013093126638157983 Test RE 0.026143128713123517\n",
      "95 Train Loss 0.027055651 Test MSE 0.001275171404366038 Test RE 0.025800026940892163\n",
      "96 Train Loss 0.025916316 Test MSE 0.0012623989014762763 Test RE 0.02567049131669153\n",
      "97 Train Loss 0.025016252 Test MSE 0.0012113524667928955 Test RE 0.025146129101578263\n",
      "98 Train Loss 0.024244219 Test MSE 0.0011907114881923734 Test RE 0.024930968431500233\n",
      "99 Train Loss 0.023803938 Test MSE 0.001135604116825979 Test RE 0.024347218654944738\n",
      "100 Train Loss 0.023471959 Test MSE 0.0010931220426301754 Test RE 0.023887472650630678\n",
      "101 Train Loss 0.022893088 Test MSE 0.0011301773906318155 Test RE 0.02428897480339351\n",
      "102 Train Loss 0.02251629 Test MSE 0.0011071176249987562 Test RE 0.0240399056710245\n",
      "103 Train Loss 0.02205786 Test MSE 0.0010989184587998986 Test RE 0.0239507220682271\n",
      "104 Train Loss 0.021506326 Test MSE 0.0012132864112418646 Test RE 0.025166194203793773\n",
      "105 Train Loss 0.021109598 Test MSE 0.0012804699039639907 Test RE 0.02585357257530513\n",
      "106 Train Loss 0.020862749 Test MSE 0.0012104064752196774 Test RE 0.025136308395821236\n",
      "107 Train Loss 0.020536954 Test MSE 0.0012164821904292668 Test RE 0.025199316106659896\n",
      "108 Train Loss 0.019849679 Test MSE 0.0013503537853481631 Test RE 0.026549702560506847\n",
      "109 Train Loss 0.019375108 Test MSE 0.0013443474900349556 Test RE 0.026490590987520914\n",
      "110 Train Loss 0.01882 Test MSE 0.0012825894520879697 Test RE 0.025874961298788073\n",
      "111 Train Loss 0.018343966 Test MSE 0.0012755311522891877 Test RE 0.025803666001316252\n",
      "112 Train Loss 0.018029183 Test MSE 0.0011776199117223783 Test RE 0.024793534728502577\n",
      "113 Train Loss 0.0176436 Test MSE 0.0011098708831811773 Test RE 0.024069779176016194\n",
      "114 Train Loss 0.017320571 Test MSE 0.0011962718076269799 Test RE 0.024989111269443306\n",
      "115 Train Loss 0.016982185 Test MSE 0.0011905387671605641 Test RE 0.02492916016022583\n",
      "116 Train Loss 0.016572433 Test MSE 0.001010688290204097 Test RE 0.022969127256791226\n",
      "117 Train Loss 0.016275326 Test MSE 0.0010415904569348541 Test RE 0.02331762819048999\n",
      "118 Train Loss 0.015991898 Test MSE 0.0010127173507816119 Test RE 0.02299217213772089\n",
      "119 Train Loss 0.015733361 Test MSE 0.001021459180273107 Test RE 0.02309119372720847\n",
      "120 Train Loss 0.015442479 Test MSE 0.0009895891181263819 Test RE 0.022728110510861974\n",
      "121 Train Loss 0.015081764 Test MSE 0.0010108742414184071 Test RE 0.02297124014397341\n",
      "122 Train Loss 0.014735319 Test MSE 0.000929321056491867 Test RE 0.02202514446297065\n",
      "123 Train Loss 0.014496747 Test MSE 0.0009249379451115762 Test RE 0.02197314264925974\n",
      "124 Train Loss 0.014163249 Test MSE 0.0008954688160803683 Test RE 0.021620269846304496\n",
      "125 Train Loss 0.013854838 Test MSE 0.0008317861665383398 Test RE 0.020837313392725033\n",
      "126 Train Loss 0.013710004 Test MSE 0.0008473209369548877 Test RE 0.02103099624218487\n",
      "127 Train Loss 0.013529672 Test MSE 0.00081380983427155 Test RE 0.02061091839191189\n",
      "128 Train Loss 0.013288035 Test MSE 0.000730435315023683 Test RE 0.019526605761544583\n",
      "129 Train Loss 0.01303141 Test MSE 0.000740406080603526 Test RE 0.019659427437983764\n",
      "130 Train Loss 0.012817329 Test MSE 0.0007773417367466255 Test RE 0.020143821763123904\n",
      "131 Train Loss 0.0126729505 Test MSE 0.0007526926345877839 Test RE 0.019821873948760102\n",
      "132 Train Loss 0.012477686 Test MSE 0.0008824887028921646 Test RE 0.021463001412400193\n",
      "133 Train Loss 0.012233944 Test MSE 0.0008766160648286041 Test RE 0.021391468012520475\n",
      "134 Train Loss 0.011972445 Test MSE 0.0009230235158796026 Test RE 0.02195039095204242\n",
      "135 Train Loss 0.011702159 Test MSE 0.0009514059758181622 Test RE 0.022285316908340267\n",
      "136 Train Loss 0.01149761 Test MSE 0.0009024882609769044 Test RE 0.02170484344601299\n",
      "137 Train Loss 0.011362681 Test MSE 0.0008951362378340339 Test RE 0.021616254575722513\n",
      "138 Train Loss 0.011185018 Test MSE 0.0009156720688862967 Test RE 0.021862803950201713\n",
      "139 Train Loss 0.010984195 Test MSE 0.0008959738779977838 Test RE 0.021626366114241572\n",
      "140 Train Loss 0.010771123 Test MSE 0.000835545132002172 Test RE 0.020884343778292996\n",
      "141 Train Loss 0.010500953 Test MSE 0.0008481499614965883 Test RE 0.02104128216140603\n",
      "142 Train Loss 0.010300329 Test MSE 0.0008269662275638242 Test RE 0.020776852842423563\n",
      "143 Train Loss 0.010193946 Test MSE 0.0008634594695166525 Test RE 0.021230335400045836\n",
      "144 Train Loss 0.0100799175 Test MSE 0.0008237097852749316 Test RE 0.02073590476119237\n",
      "145 Train Loss 0.009918111 Test MSE 0.0008574089325223867 Test RE 0.021155820754372896\n",
      "146 Train Loss 0.009722593 Test MSE 0.0007935973715701681 Test RE 0.020353354048923897\n",
      "147 Train Loss 0.009508223 Test MSE 0.0007711417700193515 Test RE 0.02006332881831774\n",
      "148 Train Loss 0.009346052 Test MSE 0.0007516897604682754 Test RE 0.01980866439320043\n",
      "149 Train Loss 0.0091663 Test MSE 0.0007636469585462959 Test RE 0.019965591912473515\n",
      "150 Train Loss 0.008927664 Test MSE 0.0008122113084103475 Test RE 0.020590665944920452\n",
      "151 Train Loss 0.008661798 Test MSE 0.000792630858851877 Test RE 0.020340956220120523\n",
      "152 Train Loss 0.00846119 Test MSE 0.0007539802434450801 Test RE 0.01983882104863625\n",
      "153 Train Loss 0.008319208 Test MSE 0.0006905205380693752 Test RE 0.01898559345897355\n",
      "154 Train Loss 0.008238337 Test MSE 0.0006814892063044584 Test RE 0.018861028344991614\n",
      "155 Train Loss 0.0080499565 Test MSE 0.0007399434968625626 Test RE 0.01965328516510981\n",
      "156 Train Loss 0.007921606 Test MSE 0.0007417399200452057 Test RE 0.019677127671059565\n",
      "157 Train Loss 0.007788658 Test MSE 0.0008311622163371331 Test RE 0.020829496548970445\n",
      "158 Train Loss 0.007669443 Test MSE 0.000862005197119095 Test RE 0.021212449382864425\n",
      "159 Train Loss 0.0075083408 Test MSE 0.0008644028305944403 Test RE 0.02124192969339835\n",
      "160 Train Loss 0.0073356093 Test MSE 0.0008565972000298261 Test RE 0.021145803985890277\n",
      "161 Train Loss 0.0071336976 Test MSE 0.0009441695982843164 Test RE 0.022200404270045136\n",
      "162 Train Loss 0.006954406 Test MSE 0.0008972766431080014 Test RE 0.02164208300171925\n",
      "163 Train Loss 0.006832332 Test MSE 0.0008513886866222209 Test RE 0.021081417750723738\n",
      "164 Train Loss 0.0066748355 Test MSE 0.000771013449684386 Test RE 0.020061659449411764\n",
      "165 Train Loss 0.0065245316 Test MSE 0.0007660594191177112 Test RE 0.019997104001843874\n",
      "166 Train Loss 0.0063103247 Test MSE 0.0007746404305785011 Test RE 0.02010879084737926\n",
      "167 Train Loss 0.006120191 Test MSE 0.0006637385083987917 Test RE 0.018613771762802732\n",
      "168 Train Loss 0.005981832 Test MSE 0.0006586863428952715 Test RE 0.018542795400088203\n",
      "169 Train Loss 0.0058920197 Test MSE 0.0006383056444659841 Test RE 0.018253671028848905\n",
      "170 Train Loss 0.005793089 Test MSE 0.0005856477952893065 Test RE 0.017484536871026034\n",
      "171 Train Loss 0.005717033 Test MSE 0.0005873287671214069 Test RE 0.017509611629552797\n",
      "172 Train Loss 0.0056687547 Test MSE 0.000587593556723871 Test RE 0.01751355817611993\n",
      "173 Train Loss 0.005622969 Test MSE 0.0005924679146331968 Test RE 0.017586049645814\n",
      "174 Train Loss 0.0055478 Test MSE 0.0006036183618898963 Test RE 0.0177507659659078\n",
      "175 Train Loss 0.0054721558 Test MSE 0.0006001905263112745 Test RE 0.017700292569645244\n",
      "176 Train Loss 0.0054164017 Test MSE 0.0006091799808506194 Test RE 0.01783235446695625\n",
      "177 Train Loss 0.0053053587 Test MSE 0.0006673749290635713 Test RE 0.01866469170095403\n",
      "178 Train Loss 0.0052440115 Test MSE 0.0007058509682011076 Test RE 0.019195188630636052\n",
      "179 Train Loss 0.0051757973 Test MSE 0.0007082810295422729 Test RE 0.019228202262278764\n",
      "180 Train Loss 0.0051158136 Test MSE 0.0007256503189358317 Test RE 0.019462542419099397\n",
      "181 Train Loss 0.005049693 Test MSE 0.0007276112046406358 Test RE 0.01948882096744476\n",
      "182 Train Loss 0.004956552 Test MSE 0.0007331240531573747 Test RE 0.01956251154414427\n",
      "183 Train Loss 0.004910511 Test MSE 0.0007096178998810187 Test RE 0.01924634018627324\n",
      "184 Train Loss 0.004867511 Test MSE 0.0007378014894189342 Test RE 0.019624818131011874\n",
      "185 Train Loss 0.0048394524 Test MSE 0.0007455474840376232 Test RE 0.019727567196982224\n",
      "186 Train Loss 0.004790188 Test MSE 0.0007457457752791518 Test RE 0.019730190466329373\n",
      "187 Train Loss 0.00472905 Test MSE 0.0007025174201372315 Test RE 0.019149808079058\n",
      "188 Train Loss 0.0046502487 Test MSE 0.0007121758291677881 Test RE 0.019280997212255353\n",
      "189 Train Loss 0.004585863 Test MSE 0.0006602658095654212 Test RE 0.018565014010926424\n",
      "190 Train Loss 0.004517282 Test MSE 0.000647250482657735 Test RE 0.018381124149873265\n",
      "191 Train Loss 0.004459596 Test MSE 0.0006556619836217281 Test RE 0.01850017678731667\n",
      "192 Train Loss 0.0044182343 Test MSE 0.0006344179413323818 Test RE 0.01819799766867192\n",
      "193 Train Loss 0.004390287 Test MSE 0.0006078636512901129 Test RE 0.017813077775208914\n",
      "194 Train Loss 0.0043625436 Test MSE 0.0005953510872712142 Test RE 0.01762878789357323\n",
      "195 Train Loss 0.004331263 Test MSE 0.0005857151273596469 Test RE 0.017485541942879903\n",
      "196 Train Loss 0.0042637177 Test MSE 0.000589112767303105 Test RE 0.01753618402602612\n",
      "197 Train Loss 0.004224502 Test MSE 0.0005823101662433091 Test RE 0.017434643162810116\n",
      "198 Train Loss 0.004202175 Test MSE 0.0005740298092647157 Test RE 0.017310240420720432\n",
      "199 Train Loss 0.004182893 Test MSE 0.0005778282276826105 Test RE 0.01736741787220438\n",
      "200 Train Loss 0.004157155 Test MSE 0.0005744841421907337 Test RE 0.017317089417496278\n",
      "201 Train Loss 0.0041307793 Test MSE 0.000577753607217299 Test RE 0.017366296425913287\n",
      "202 Train Loss 0.004086776 Test MSE 0.0005975394221211643 Test RE 0.017661157285924798\n",
      "203 Train Loss 0.0040463717 Test MSE 0.0005866891074162436 Test RE 0.017500074173843423\n",
      "204 Train Loss 0.004003178 Test MSE 0.0005871540920643856 Test RE 0.017507007704785013\n",
      "205 Train Loss 0.0039709993 Test MSE 0.0005799527346422838 Test RE 0.017399316060542798\n",
      "206 Train Loss 0.0039495234 Test MSE 0.0005803043240916601 Test RE 0.017404589325686795\n",
      "207 Train Loss 0.0039335056 Test MSE 0.0005903336577174307 Test RE 0.017554345810265846\n",
      "208 Train Loss 0.0039206054 Test MSE 0.0005959115304350151 Test RE 0.017637083510905625\n",
      "209 Train Loss 0.0039068824 Test MSE 0.0006018521606548724 Test RE 0.017724777366062185\n",
      "210 Train Loss 0.0038900024 Test MSE 0.0006028216717079734 Test RE 0.01773904785786813\n",
      "211 Train Loss 0.0038704043 Test MSE 0.0006281688794866467 Test RE 0.018108150084168675\n",
      "212 Train Loss 0.0038433315 Test MSE 0.0006402940660986315 Test RE 0.01828208043716688\n",
      "213 Train Loss 0.0038221898 Test MSE 0.0006353786048428413 Test RE 0.018211770560428605\n",
      "214 Train Loss 0.0037978059 Test MSE 0.0006306479492502648 Test RE 0.018143846825146522\n",
      "215 Train Loss 0.0037763938 Test MSE 0.0006203340789146766 Test RE 0.017994869318600223\n",
      "216 Train Loss 0.0037495403 Test MSE 0.0006522631417872459 Test RE 0.018452163575434947\n",
      "217 Train Loss 0.0037059693 Test MSE 0.0007137061787897971 Test RE 0.019301701953516687\n",
      "218 Train Loss 0.003684867 Test MSE 0.0007238457567893525 Test RE 0.01943832742963839\n",
      "219 Train Loss 0.003667076 Test MSE 0.0007322341639885851 Test RE 0.019550635141366252\n",
      "220 Train Loss 0.0036522602 Test MSE 0.0007208640945080971 Test RE 0.01939825097962275\n",
      "221 Train Loss 0.0036316626 Test MSE 0.000680609306602279 Test RE 0.018848848274184093\n",
      "222 Train Loss 0.0035942688 Test MSE 0.0006799299109758071 Test RE 0.018839438307040955\n",
      "223 Train Loss 0.0035672816 Test MSE 0.0006624110261372828 Test RE 0.01859514860122095\n",
      "224 Train Loss 0.0035436035 Test MSE 0.0006530518594254276 Test RE 0.018463316397859947\n",
      "225 Train Loss 0.0035178522 Test MSE 0.0006306237766941545 Test RE 0.01814349909757622\n",
      "226 Train Loss 0.0034966166 Test MSE 0.0006059280824349749 Test RE 0.017784694823734182\n",
      "227 Train Loss 0.0034775322 Test MSE 0.0005865914248899497 Test RE 0.01749861725006984\n",
      "228 Train Loss 0.0034591912 Test MSE 0.0005712725498170697 Test RE 0.01726861690600188\n",
      "229 Train Loss 0.0034209236 Test MSE 0.0005583929408629595 Test RE 0.017072842604827592\n",
      "230 Train Loss 0.003388109 Test MSE 0.0005452347097991884 Test RE 0.016870487195456446\n",
      "231 Train Loss 0.0033442979 Test MSE 0.0005352772378781582 Test RE 0.016715726813374972\n",
      "232 Train Loss 0.0033126192 Test MSE 0.0004927371043851566 Test RE 0.016037752625037587\n",
      "233 Train Loss 0.003283483 Test MSE 0.0004640006592028305 Test RE 0.015563066589680433\n",
      "234 Train Loss 0.0032583326 Test MSE 0.0004480443714267591 Test RE 0.015293130335784683\n",
      "235 Train Loss 0.0032277228 Test MSE 0.00042200214261448857 Test RE 0.014842026575769045\n",
      "236 Train Loss 0.0032013413 Test MSE 0.00041487818551548685 Test RE 0.014716216788295688\n",
      "237 Train Loss 0.0031759078 Test MSE 0.00041008438749217535 Test RE 0.014630948936587479\n",
      "238 Train Loss 0.0031513127 Test MSE 0.0004043979764368388 Test RE 0.014529155228893656\n",
      "239 Train Loss 0.0031356516 Test MSE 0.0003988612459960909 Test RE 0.014429350992036617\n",
      "240 Train Loss 0.003109671 Test MSE 0.0004089199229168843 Test RE 0.01461016134497123\n",
      "241 Train Loss 0.0030776279 Test MSE 0.00038331366277295027 Test RE 0.014145328141649031\n",
      "242 Train Loss 0.0030341581 Test MSE 0.0003470734886586023 Test RE 0.013460047654609453\n",
      "243 Train Loss 0.0029950547 Test MSE 0.0003360427726919195 Test RE 0.013244426471023666\n",
      "244 Train Loss 0.0029699889 Test MSE 0.0003317254194848177 Test RE 0.013159071687684034\n",
      "245 Train Loss 0.002953307 Test MSE 0.0003225383761652375 Test RE 0.012975573870050487\n",
      "246 Train Loss 0.0029360158 Test MSE 0.00031529067478942846 Test RE 0.012828959671106997\n",
      "247 Train Loss 0.0029239485 Test MSE 0.0003222932561658994 Test RE 0.012970642399240416\n",
      "248 Train Loss 0.002912745 Test MSE 0.0003138980148790851 Test RE 0.012800595129758173\n",
      "249 Train Loss 0.0028988987 Test MSE 0.0003113776881791788 Test RE 0.012749102766454582\n",
      "250 Train Loss 0.0028883836 Test MSE 0.00030743016361942224 Test RE 0.01266803092807969\n",
      "251 Train Loss 0.0028712382 Test MSE 0.0003067395008847321 Test RE 0.012653793131268755\n",
      "252 Train Loss 0.0028446892 Test MSE 0.0002975098814773751 Test RE 0.01246196635377604\n",
      "253 Train Loss 0.0028277389 Test MSE 0.00029444220041686915 Test RE 0.012397551019340914\n",
      "254 Train Loss 0.0028125783 Test MSE 0.0002926982623652273 Test RE 0.012360782054238966\n",
      "255 Train Loss 0.0027983328 Test MSE 0.0002988453039297652 Test RE 0.012489903839919901\n",
      "256 Train Loss 0.0027786875 Test MSE 0.0002713414689407183 Test RE 0.011901287943636636\n",
      "257 Train Loss 0.002766953 Test MSE 0.00026415402585586975 Test RE 0.01174260612562545\n",
      "258 Train Loss 0.0027526498 Test MSE 0.0002577343497669772 Test RE 0.011599039531441348\n",
      "259 Train Loss 0.0027343803 Test MSE 0.00024884699477922443 Test RE 0.011397302548727442\n",
      "260 Train Loss 0.0027199907 Test MSE 0.00025052735826144634 Test RE 0.01143571850174617\n",
      "261 Train Loss 0.0026883078 Test MSE 0.00025847287298678083 Test RE 0.011615645840114113\n",
      "262 Train Loss 0.0026592617 Test MSE 0.000261883396966805 Test RE 0.011692028349600357\n",
      "263 Train Loss 0.0026339116 Test MSE 0.00025727129852150775 Test RE 0.011588615301478448\n",
      "264 Train Loss 0.0026012647 Test MSE 0.0002592635325098839 Test RE 0.01163339820270434\n",
      "265 Train Loss 0.0025708003 Test MSE 0.0002521034425461288 Test RE 0.011471633537436726\n",
      "266 Train Loss 0.0025487004 Test MSE 0.0002748455278677421 Test RE 0.011977887073486782\n",
      "267 Train Loss 0.0025278488 Test MSE 0.0002907181155895294 Test RE 0.012318899845301191\n",
      "268 Train Loss 0.0025121632 Test MSE 0.0003046669707449886 Test RE 0.012610972078320945\n",
      "269 Train Loss 0.0024903412 Test MSE 0.00031677710286169103 Test RE 0.012859164977994582\n",
      "270 Train Loss 0.002470408 Test MSE 0.000350012214981296 Test RE 0.013516911719133055\n",
      "271 Train Loss 0.0024524839 Test MSE 0.0003715914129553755 Test RE 0.013927357114941682\n",
      "272 Train Loss 0.002422068 Test MSE 0.000371436998020629 Test RE 0.013924463055322252\n",
      "273 Train Loss 0.0023936054 Test MSE 0.0003658312573083747 Test RE 0.013818989337128067\n",
      "274 Train Loss 0.002375673 Test MSE 0.00036895977842101946 Test RE 0.0138779522633502\n",
      "275 Train Loss 0.002354384 Test MSE 0.0003618147024389844 Test RE 0.01374291885370117\n",
      "276 Train Loss 0.0023345065 Test MSE 0.00033641134101852034 Test RE 0.013251687657311337\n",
      "277 Train Loss 0.0023133392 Test MSE 0.0003272710559505056 Test RE 0.01307042398777024\n",
      "278 Train Loss 0.0022938591 Test MSE 0.0003068031626881984 Test RE 0.012655106169687467\n",
      "279 Train Loss 0.0022784884 Test MSE 0.0002830382445148962 Test RE 0.012155097249788313\n",
      "280 Train Loss 0.0022521664 Test MSE 0.00024393782882363698 Test RE 0.011284321573672608\n",
      "281 Train Loss 0.0022307963 Test MSE 0.0002183766679344695 Test RE 0.010676748051990335\n",
      "282 Train Loss 0.002216885 Test MSE 0.00020831622111459116 Test RE 0.010427913530567502\n",
      "283 Train Loss 0.0022028005 Test MSE 0.00021323618924388256 Test RE 0.010550337025947652\n",
      "284 Train Loss 0.0021834553 Test MSE 0.00022160208305174855 Test RE 0.010755306620730766\n",
      "285 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "286 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "287 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "288 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "289 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "290 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "291 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "292 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "293 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "294 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "295 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "296 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "297 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "298 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "299 Train Loss 0.0021829063 Test MSE 0.0002222918506694354 Test RE 0.010772032317039939\n",
      "Training time: 178.53\n",
      "KG_stan_high\n",
      "3\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "3\n",
      "0 Train Loss 40951.957 Test MSE 9.774611562714066 Test RE 2.258840837847323\n",
      "1 Train Loss 20386.248 Test MSE 12.763883041810573 Test RE 2.581233452602977\n",
      "2 Train Loss 6553.956 Test MSE 12.821225395629112 Test RE 2.5870251123128885\n",
      "3 Train Loss 971.38385 Test MSE 8.021739827172935 Test RE 2.0463040462100994\n",
      "4 Train Loss 302.02658 Test MSE 4.702859603631662 Test RE 1.5668119808379712\n",
      "5 Train Loss 153.59988 Test MSE 3.468755810143046 Test RE 1.3456209524844025\n",
      "6 Train Loss 77.62623 Test MSE 2.4939317953013664 Test RE 1.1409803444771973\n",
      "7 Train Loss 48.377357 Test MSE 2.600853134506107 Test RE 1.1651820657270515\n",
      "8 Train Loss 31.815529 Test MSE 2.0015098385505805 Test RE 1.0221502554714417\n",
      "9 Train Loss 21.880371 Test MSE 1.3732273566813507 Test RE 0.8466562139824279\n",
      "10 Train Loss 13.142647 Test MSE 0.7405128685181479 Test RE 0.6217305128762176\n",
      "11 Train Loss 7.989834 Test MSE 0.49656481639061684 Test RE 0.5091243273339718\n",
      "12 Train Loss 5.71034 Test MSE 0.5159479600120118 Test RE 0.5189659052326427\n",
      "13 Train Loss 3.7103484 Test MSE 0.3828145077117292 Test RE 0.4470232080580932\n",
      "14 Train Loss 2.5944238 Test MSE 0.2533779338183641 Test RE 0.36368071488243525\n",
      "15 Train Loss 1.9294571 Test MSE 0.16708935113351198 Test RE 0.29533183453713907\n",
      "16 Train Loss 1.5464653 Test MSE 0.12788014237205675 Test RE 0.2583672319995585\n",
      "17 Train Loss 1.2024683 Test MSE 0.0951608868102343 Test RE 0.22287693011671808\n",
      "18 Train Loss 0.98094213 Test MSE 0.06279383748549298 Test RE 0.18104827414435223\n",
      "19 Train Loss 0.8064274 Test MSE 0.04696553761465237 Test RE 0.15657611964173962\n",
      "20 Train Loss 0.6699507 Test MSE 0.029672216196774202 Test RE 0.12445457590397115\n",
      "21 Train Loss 0.54061383 Test MSE 0.022170527101723667 Test RE 0.10757810408212765\n",
      "22 Train Loss 0.45041364 Test MSE 0.023741991287726392 Test RE 0.1113254469809661\n",
      "23 Train Loss 0.38984063 Test MSE 0.02539825613524929 Test RE 0.11514307571851698\n",
      "24 Train Loss 0.34122366 Test MSE 0.029627629540195054 Test RE 0.12436103554438648\n",
      "25 Train Loss 0.30813563 Test MSE 0.029494542783811896 Test RE 0.12408140744994677\n",
      "26 Train Loss 0.27456325 Test MSE 0.027966789416475072 Test RE 0.12082510550465347\n",
      "27 Train Loss 0.2444453 Test MSE 0.029197370813670645 Test RE 0.12345473445592325\n",
      "28 Train Loss 0.22280161 Test MSE 0.026226572169874597 Test RE 0.11700559858943174\n",
      "29 Train Loss 0.20314236 Test MSE 0.025519227002029306 Test RE 0.11541696088636591\n",
      "30 Train Loss 0.18962741 Test MSE 0.025228244655559475 Test RE 0.1147570548503646\n",
      "31 Train Loss 0.17930795 Test MSE 0.02569441123821843 Test RE 0.11581244015607621\n",
      "32 Train Loss 0.16401055 Test MSE 0.028303483530165065 Test RE 0.1215502404511698\n",
      "33 Train Loss 0.15038021 Test MSE 0.03267047290190468 Test RE 0.13059110218941095\n",
      "34 Train Loss 0.13844645 Test MSE 0.029973573960212007 Test RE 0.12508497379385003\n",
      "35 Train Loss 0.1304106 Test MSE 0.0304286834198807 Test RE 0.12603102193967672\n",
      "36 Train Loss 0.11949978 Test MSE 0.029279822112629614 Test RE 0.1236289252626384\n",
      "37 Train Loss 0.11186652 Test MSE 0.028606050439839603 Test RE 0.12219820512373088\n",
      "38 Train Loss 0.1011569 Test MSE 0.028583277430222563 Test RE 0.12214955501435423\n",
      "39 Train Loss 0.09560375 Test MSE 0.027715043973889745 Test RE 0.12028006742894327\n",
      "40 Train Loss 0.08962718 Test MSE 0.02473023272013502 Test RE 0.11361874255128455\n",
      "41 Train Loss 0.08457879 Test MSE 0.024271069614136487 Test RE 0.11255902819101452\n",
      "42 Train Loss 0.07802671 Test MSE 0.02199137240365312 Test RE 0.10714256603317864\n",
      "43 Train Loss 0.07509254 Test MSE 0.022169403636047337 Test RE 0.1075753783499414\n",
      "44 Train Loss 0.07216546 Test MSE 0.021562444754683968 Test RE 0.10609254723386265\n",
      "45 Train Loss 0.06914047 Test MSE 0.020647708546096318 Test RE 0.10381779665590708\n",
      "46 Train Loss 0.06544578 Test MSE 0.019444870042425646 Test RE 0.10074845604396912\n",
      "47 Train Loss 0.063730866 Test MSE 0.018750252201649793 Test RE 0.09893260250332835\n",
      "48 Train Loss 0.061662585 Test MSE 0.018242624289226676 Test RE 0.09758420622537876\n",
      "49 Train Loss 0.05942546 Test MSE 0.017490878023455066 Test RE 0.09555241819933977\n",
      "50 Train Loss 0.05624821 Test MSE 0.015650752690291668 Test RE 0.09038648368764052\n",
      "51 Train Loss 0.052637193 Test MSE 0.014453420971024466 Test RE 0.08686027559195189\n",
      "52 Train Loss 0.04992609 Test MSE 0.013415800788708798 Test RE 0.08368433653199366\n",
      "53 Train Loss 0.048235424 Test MSE 0.013084247791171809 Test RE 0.08264379600208557\n",
      "54 Train Loss 0.044484716 Test MSE 0.011408138397406899 Test RE 0.07716907019171473\n",
      "55 Train Loss 0.042882137 Test MSE 0.010591971243963634 Test RE 0.0743574133032084\n",
      "56 Train Loss 0.04134174 Test MSE 0.010009838106357312 Test RE 0.07228520277445642\n",
      "57 Train Loss 0.04005999 Test MSE 0.009544324979673863 Test RE 0.07058436079026821\n",
      "58 Train Loss 0.038735874 Test MSE 0.00841584296114992 Test RE 0.06628033402118588\n",
      "59 Train Loss 0.0373352 Test MSE 0.007584890660293606 Test RE 0.06292316209213401\n",
      "60 Train Loss 0.036255196 Test MSE 0.007377455817689677 Test RE 0.06205677261975193\n",
      "61 Train Loss 0.0353953 Test MSE 0.00717552823873729 Test RE 0.06120160560142072\n",
      "62 Train Loss 0.034070507 Test MSE 0.006184912142572868 Test RE 0.05682018511689396\n",
      "63 Train Loss 0.032798484 Test MSE 0.006049451445547869 Test RE 0.056194508176704135\n",
      "64 Train Loss 0.03209517 Test MSE 0.005741635448132133 Test RE 0.05474616274959507\n",
      "65 Train Loss 0.031249693 Test MSE 0.005281971305623514 Test RE 0.05250901791467966\n",
      "66 Train Loss 0.030132651 Test MSE 0.004783572455001025 Test RE 0.04997031131636651\n",
      "67 Train Loss 0.028918447 Test MSE 0.004725074424346211 Test RE 0.04966382942451979\n",
      "68 Train Loss 0.028188188 Test MSE 0.0043983398735039925 Test RE 0.04791596838592347\n",
      "69 Train Loss 0.027532449 Test MSE 0.004161648722861111 Test RE 0.04660887136466248\n",
      "70 Train Loss 0.026685752 Test MSE 0.004109114298618759 Test RE 0.04631375434418763\n",
      "71 Train Loss 0.025385069 Test MSE 0.004022871233485503 Test RE 0.04582515501117038\n",
      "72 Train Loss 0.024600184 Test MSE 0.003683122913050285 Test RE 0.0438474138092383\n",
      "73 Train Loss 0.023448817 Test MSE 0.0038488072601064304 Test RE 0.044822797503156896\n",
      "74 Train Loss 0.022027688 Test MSE 0.003636151654526451 Test RE 0.04356692128431068\n",
      "75 Train Loss 0.021524137 Test MSE 0.0035881467243999636 Test RE 0.043278377794199685\n",
      "76 Train Loss 0.020992933 Test MSE 0.003402517326901399 Test RE 0.04214402875771425\n",
      "77 Train Loss 0.020593261 Test MSE 0.003326671045544341 Test RE 0.04167166047851479\n",
      "78 Train Loss 0.020005407 Test MSE 0.0029970077223688578 Test RE 0.03955303448192816\n",
      "79 Train Loss 0.0194368 Test MSE 0.0025823981353700525 Test RE 0.036715333431660356\n",
      "80 Train Loss 0.018957905 Test MSE 0.0025480447445120754 Test RE 0.036470305555668305\n",
      "81 Train Loss 0.018545812 Test MSE 0.0024141691934270386 Test RE 0.03549929504076274\n",
      "82 Train Loss 0.017929913 Test MSE 0.0024367853533033453 Test RE 0.03566518775847559\n",
      "83 Train Loss 0.017325435 Test MSE 0.0023281173567967256 Test RE 0.03486087721646122\n",
      "84 Train Loss 0.01692999 Test MSE 0.002264730650724901 Test RE 0.03438303076282198\n",
      "85 Train Loss 0.016596815 Test MSE 0.0023142244896149646 Test RE 0.03475670673044266\n",
      "86 Train Loss 0.01637492 Test MSE 0.002412101774523426 Test RE 0.03548409154276481\n",
      "87 Train Loss 0.01597254 Test MSE 0.002344702907758684 Test RE 0.03498483161082488\n",
      "88 Train Loss 0.015530938 Test MSE 0.002410468862026564 Test RE 0.03547207873577551\n",
      "89 Train Loss 0.015083599 Test MSE 0.002500000573771614 Test RE 0.03612483990232309\n",
      "90 Train Loss 0.014744692 Test MSE 0.0023743687427785526 Test RE 0.0352054548801357\n",
      "91 Train Loss 0.014318891 Test MSE 0.0023732415294363666 Test RE 0.035197097128286246\n",
      "92 Train Loss 0.01404719 Test MSE 0.0024141142365370037 Test RE 0.035498890980027856\n",
      "93 Train Loss 0.013640163 Test MSE 0.002327758942504416 Test RE 0.034858193692470146\n",
      "94 Train Loss 0.013269283 Test MSE 0.002101095199587923 Test RE 0.03311759129128834\n",
      "95 Train Loss 0.013012117 Test MSE 0.001981477146907939 Test RE 0.03216106418646708\n",
      "96 Train Loss 0.012774907 Test MSE 0.0019149943071514026 Test RE 0.031616924380842876\n",
      "97 Train Loss 0.012534337 Test MSE 0.0018898226270517657 Test RE 0.031408442375406596\n",
      "98 Train Loss 0.012331926 Test MSE 0.001828552908329918 Test RE 0.030895102640459807\n",
      "99 Train Loss 0.012128229 Test MSE 0.0016694869670350128 Test RE 0.029520750442214187\n",
      "100 Train Loss 0.011889398 Test MSE 0.0014774232060979849 Test RE 0.027770796436488193\n",
      "101 Train Loss 0.011715463 Test MSE 0.0014213570218574632 Test RE 0.027238768368895373\n",
      "102 Train Loss 0.011428519 Test MSE 0.0014101432022077674 Test RE 0.027131105239899877\n",
      "103 Train Loss 0.01116937 Test MSE 0.0012076466600118609 Test RE 0.025107635732627073\n",
      "104 Train Loss 0.010966644 Test MSE 0.0010820388776066848 Test RE 0.023766066583053216\n",
      "105 Train Loss 0.01071539 Test MSE 0.0009941435289100237 Test RE 0.02278035154842966\n",
      "106 Train Loss 0.010486902 Test MSE 0.0009497380541017493 Test RE 0.02226577400544753\n",
      "107 Train Loss 0.010312938 Test MSE 0.0009429599560523989 Test RE 0.022186178460695326\n",
      "108 Train Loss 0.010201622 Test MSE 0.0009239566537042126 Test RE 0.02196148360869129\n",
      "109 Train Loss 0.010024159 Test MSE 0.0008856430358348697 Test RE 0.021501325451398504\n",
      "110 Train Loss 0.0098042935 Test MSE 0.0008857265354427474 Test RE 0.021502339014344486\n",
      "111 Train Loss 0.009618342 Test MSE 0.0008263956475498702 Test RE 0.020769683926594534\n",
      "112 Train Loss 0.009417228 Test MSE 0.0008025372672573871 Test RE 0.020467673537304314\n",
      "113 Train Loss 0.009270679 Test MSE 0.0007907963685917965 Test RE 0.020317403704094558\n",
      "114 Train Loss 0.009135684 Test MSE 0.000776171096066464 Test RE 0.020128648216647282\n",
      "115 Train Loss 0.008970848 Test MSE 0.000740647839280411 Test RE 0.019662636791186957\n",
      "116 Train Loss 0.008840249 Test MSE 0.0006924072844955069 Test RE 0.019011513444761926\n",
      "117 Train Loss 0.008582812 Test MSE 0.0006681819377655736 Test RE 0.018675973228920388\n",
      "118 Train Loss 0.008421469 Test MSE 0.0006565958500362067 Test RE 0.01851334709970857\n",
      "119 Train Loss 0.008266942 Test MSE 0.0006548257185059691 Test RE 0.018488374983062123\n",
      "120 Train Loss 0.008116725 Test MSE 0.000633169501167706 Test RE 0.018180083374565236\n",
      "121 Train Loss 0.008020359 Test MSE 0.0006112959007896429 Test RE 0.017863296986401586\n",
      "122 Train Loss 0.0078501 Test MSE 0.000615820624608662 Test RE 0.01792928587145364\n",
      "123 Train Loss 0.007672357 Test MSE 0.000600891449031194 Test RE 0.017710625052905164\n",
      "124 Train Loss 0.007529345 Test MSE 0.0005874901785850589 Test RE 0.01751201748641373\n",
      "125 Train Loss 0.007337974 Test MSE 0.0005841621615289777 Test RE 0.01746234596318318\n",
      "126 Train Loss 0.00718488 Test MSE 0.0005733511036510747 Test RE 0.017300003990533306\n",
      "127 Train Loss 0.0070650955 Test MSE 0.0005731620196138512 Test RE 0.01729715109261556\n",
      "128 Train Loss 0.0069847056 Test MSE 0.0005927054723169442 Test RE 0.017589574969654357\n",
      "129 Train Loss 0.0067993165 Test MSE 0.0006547381105605159 Test RE 0.018487138178611702\n",
      "130 Train Loss 0.00660273 Test MSE 0.0007141222865718208 Test RE 0.01930732781070896\n",
      "131 Train Loss 0.006367203 Test MSE 0.0007537409154015495 Test RE 0.01983567218425653\n",
      "132 Train Loss 0.006238122 Test MSE 0.000750744537279146 Test RE 0.019796206129374584\n",
      "133 Train Loss 0.006140425 Test MSE 0.0007579524307485802 Test RE 0.01989101074214081\n",
      "134 Train Loss 0.0060080453 Test MSE 0.0006801620061817327 Test RE 0.01884265346948841\n",
      "135 Train Loss 0.0058989883 Test MSE 0.0006432301023775167 Test RE 0.01832394827712103\n",
      "136 Train Loss 0.0057768477 Test MSE 0.00064216123040281 Test RE 0.018308717259406387\n",
      "137 Train Loss 0.0056793396 Test MSE 0.000630839459369372 Test RE 0.018146601505088122\n",
      "138 Train Loss 0.0056146774 Test MSE 0.0006614041515838048 Test RE 0.018581010776350555\n",
      "139 Train Loss 0.0055004684 Test MSE 0.0006361200929990912 Test RE 0.018222394049026536\n",
      "140 Train Loss 0.0054109306 Test MSE 0.0006046750358139304 Test RE 0.017766296118025347\n",
      "141 Train Loss 0.005253214 Test MSE 0.000571361475864459 Test RE 0.017269960896790736\n",
      "142 Train Loss 0.00508932 Test MSE 0.0005032809734211091 Test RE 0.016208436838577193\n",
      "143 Train Loss 0.004995329 Test MSE 0.0004833724685048811 Test RE 0.01588462008528239\n",
      "144 Train Loss 0.004878523 Test MSE 0.0004302966168022673 Test RE 0.014987177214927134\n",
      "145 Train Loss 0.0047888984 Test MSE 0.00038524479329040393 Test RE 0.01418091538893977\n",
      "146 Train Loss 0.0046974346 Test MSE 0.0003682285310438364 Test RE 0.013864192973036406\n",
      "147 Train Loss 0.004636217 Test MSE 0.0003511358260145177 Test RE 0.013538590365004639\n",
      "148 Train Loss 0.004531184 Test MSE 0.00034631479051014087 Test RE 0.013445327861017238\n",
      "149 Train Loss 0.004474117 Test MSE 0.00033382354321169407 Test RE 0.013200620872569657\n",
      "150 Train Loss 0.0043511223 Test MSE 0.0002957537407517351 Test RE 0.012425131681544029\n",
      "151 Train Loss 0.0042934925 Test MSE 0.00028963031439737297 Test RE 0.012295830982120469\n",
      "152 Train Loss 0.00420628 Test MSE 0.00027698888171320645 Test RE 0.012024500516645878\n",
      "153 Train Loss 0.004100762 Test MSE 0.00026295744363309816 Test RE 0.011715979724392133\n",
      "154 Train Loss 0.004018593 Test MSE 0.00026220216413470757 Test RE 0.011699142014213387\n",
      "155 Train Loss 0.003936783 Test MSE 0.00025454779053408686 Test RE 0.011527112792965534\n",
      "156 Train Loss 0.003880005 Test MSE 0.0002484249396574045 Test RE 0.011387633291387998\n",
      "157 Train Loss 0.0038377712 Test MSE 0.00025142043145936013 Test RE 0.011456083240057318\n",
      "158 Train Loss 0.003777915 Test MSE 0.0002490234244274113 Test RE 0.011401342110858002\n",
      "159 Train Loss 0.003707836 Test MSE 0.0002465296853985737 Test RE 0.011344111530072535\n",
      "160 Train Loss 0.0036241154 Test MSE 0.00023689087690940554 Test RE 0.011120134616296372\n",
      "161 Train Loss 0.0035398745 Test MSE 0.00022814568933752428 Test RE 0.010912946111140652\n",
      "162 Train Loss 0.0034810253 Test MSE 0.00022698463261749523 Test RE 0.010885142142907051\n",
      "163 Train Loss 0.0034003542 Test MSE 0.0002195408296319387 Test RE 0.01070516899081653\n",
      "164 Train Loss 0.0033176434 Test MSE 0.000224957129608996 Test RE 0.0108364182206456\n",
      "165 Train Loss 0.0032148175 Test MSE 0.00022300180385502195 Test RE 0.010789220401380303\n",
      "166 Train Loss 0.0031344602 Test MSE 0.00022504352856174425 Test RE 0.01083849898445192\n",
      "167 Train Loss 0.0030753252 Test MSE 0.00021935309887840008 Test RE 0.010700590983042072\n",
      "168 Train Loss 0.003008008 Test MSE 0.0002151685892863718 Test RE 0.010598034114325156\n",
      "169 Train Loss 0.0029449267 Test MSE 0.0002239913918463139 Test RE 0.010813132908123605\n",
      "170 Train Loss 0.0029076375 Test MSE 0.00022529761412245727 Test RE 0.010844615865979094\n",
      "171 Train Loss 0.0028783444 Test MSE 0.0002301594264221408 Test RE 0.010961002080569498\n",
      "172 Train Loss 0.0028312472 Test MSE 0.00022178546043899068 Test RE 0.0107597557489825\n",
      "173 Train Loss 0.0027886503 Test MSE 0.000218939880099944 Test RE 0.010690507310823981\n",
      "174 Train Loss 0.0027391254 Test MSE 0.00021585258455147422 Test RE 0.010614865691335452\n",
      "175 Train Loss 0.0026802043 Test MSE 0.00021048009863684793 Test RE 0.010481933405662749\n",
      "176 Train Loss 0.0026248738 Test MSE 0.00020825114658189154 Test RE 0.010426284649725021\n",
      "177 Train Loss 0.0025811768 Test MSE 0.00019462940187922327 Test RE 0.010079525801524204\n",
      "178 Train Loss 0.0025340405 Test MSE 0.00018745522547272518 Test RE 0.009892012409710244\n",
      "179 Train Loss 0.0024889177 Test MSE 0.00018341508900578913 Test RE 0.009784832763223204\n",
      "180 Train Loss 0.0024414929 Test MSE 0.00018347607532446923 Test RE 0.009786459377848711\n",
      "181 Train Loss 0.0024048355 Test MSE 0.00017816323162749023 Test RE 0.00964372722328967\n",
      "182 Train Loss 0.002374903 Test MSE 0.00016879344999373637 Test RE 0.00938671586115311\n",
      "183 Train Loss 0.0023382788 Test MSE 0.00016641319911587133 Test RE 0.009320297212071503\n",
      "184 Train Loss 0.0023160495 Test MSE 0.000166254779548391 Test RE 0.009315859856661527\n",
      "185 Train Loss 0.002286002 Test MSE 0.00016872400507469414 Test RE 0.009384784723470272\n",
      "186 Train Loss 0.0022416357 Test MSE 0.0001618817216041487 Test RE 0.00919252424787011\n",
      "187 Train Loss 0.0022081058 Test MSE 0.0001629866695434085 Test RE 0.009223843371021329\n",
      "188 Train Loss 0.0021744464 Test MSE 0.0001762387360027835 Test RE 0.00959150067235917\n",
      "189 Train Loss 0.0021449742 Test MSE 0.00018485567580064317 Test RE 0.009823183836054095\n",
      "190 Train Loss 0.0021285075 Test MSE 0.00018189770870718046 Test RE 0.009744274083130458\n",
      "191 Train Loss 0.0021059776 Test MSE 0.00018059045221407988 Test RE 0.009709196030179919\n",
      "192 Train Loss 0.0020731986 Test MSE 0.00017335447475037418 Test RE 0.009512691335156304\n",
      "193 Train Loss 0.0020564129 Test MSE 0.00017797420033755483 Test RE 0.009638609865519275\n",
      "194 Train Loss 0.0020334707 Test MSE 0.00017816307442002012 Test RE 0.009643722968578192\n",
      "195 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "196 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "197 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "198 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "199 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "200 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "201 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "202 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "203 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "204 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "205 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "206 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "207 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "208 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "209 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "210 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "211 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "212 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "213 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "214 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "215 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "216 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "217 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "218 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "219 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "220 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "221 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "222 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "223 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "224 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "225 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "226 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "227 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "228 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "229 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "230 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "231 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "232 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "233 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "234 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "235 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "236 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "237 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "238 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "239 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "240 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "241 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "242 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "243 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "244 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "245 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "246 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "247 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "248 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "249 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "250 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "251 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "252 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "253 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "254 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "255 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "256 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "257 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "258 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "259 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "260 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "261 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "262 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "263 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "264 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "265 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "266 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "267 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "268 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "269 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "270 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "271 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "272 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "273 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "274 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "275 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "276 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "277 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "278 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "279 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "280 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "281 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "282 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "283 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "284 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "285 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "286 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "287 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "288 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "289 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "290 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "291 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "292 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "293 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "294 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "295 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "296 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "297 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "298 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "299 Train Loss 0.0020260736 Test MSE 0.0001725364977359464 Test RE 0.009490221873417576\n",
      "Training time: 139.68\n",
      "KG_stan_high\n",
      "4\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "4\n",
      "0 Train Loss 39747.617 Test MSE 11.128917238561751 Test RE 2.41025134157418\n",
      "1 Train Loss 10733.442 Test MSE 17.723862438205707 Test RE 3.0416907861428464\n",
      "2 Train Loss 1318.9086 Test MSE 16.132251113312325 Test RE 2.901906155289948\n",
      "3 Train Loss 539.5431 Test MSE 13.304063540117538 Test RE 2.635287682408011\n",
      "4 Train Loss 254.7901 Test MSE 9.691219002214632 Test RE 2.2491844941611814\n",
      "5 Train Loss 137.35492 Test MSE 6.27617705099512 Test RE 1.8100204021282948\n",
      "6 Train Loss 87.09992 Test MSE 4.880375528789935 Test RE 1.5961088193179516\n",
      "7 Train Loss 63.836796 Test MSE 3.5446678360074424 Test RE 1.360265392999151\n",
      "8 Train Loss 41.533905 Test MSE 2.513499185889671 Test RE 1.1454476652329826\n",
      "9 Train Loss 20.420366 Test MSE 1.4220830367265322 Test RE 0.861585447362865\n",
      "10 Train Loss 9.808826 Test MSE 0.571203084539393 Test RE 0.5460484125669386\n",
      "11 Train Loss 5.292413 Test MSE 0.24068752574119578 Test RE 0.35445627414755504\n",
      "12 Train Loss 3.319902 Test MSE 0.19920358661971813 Test RE 0.3224663884731002\n",
      "13 Train Loss 2.436451 Test MSE 0.1545027858419483 Test RE 0.2839906450685319\n",
      "14 Train Loss 1.8513341 Test MSE 0.13313564379095494 Test RE 0.2636228484270907\n",
      "15 Train Loss 1.3169464 Test MSE 0.10729008830398223 Test RE 0.23665499655158478\n",
      "16 Train Loss 0.96409655 Test MSE 0.06757370525835854 Test RE 0.18781260802741337\n",
      "17 Train Loss 0.7711874 Test MSE 0.04222298869844469 Test RE 0.14846030977313093\n",
      "18 Train Loss 0.67096394 Test MSE 0.030576555820575294 Test RE 0.1263368833976475\n",
      "19 Train Loss 0.5586719 Test MSE 0.02276521333930413 Test RE 0.10901135531660722\n",
      "20 Train Loss 0.47983795 Test MSE 0.021623734194387872 Test RE 0.10624321982242609\n",
      "21 Train Loss 0.42341563 Test MSE 0.020185404513051643 Test RE 0.10264897224140963\n",
      "22 Train Loss 0.3681568 Test MSE 0.018311826064906327 Test RE 0.09776911953975473\n",
      "23 Train Loss 0.3208424 Test MSE 0.017742017905856704 Test RE 0.0962359601184232\n",
      "24 Train Loss 0.29515582 Test MSE 0.017661219449046094 Test RE 0.09601657723533229\n",
      "25 Train Loss 0.26182318 Test MSE 0.015000919977898725 Test RE 0.08849012815336631\n",
      "26 Train Loss 0.23298329 Test MSE 0.01622184650707321 Test RE 0.0920208034324256\n",
      "27 Train Loss 0.21153577 Test MSE 0.01609914268025556 Test RE 0.09167211507475641\n",
      "28 Train Loss 0.18273798 Test MSE 0.011908543286401682 Test RE 0.07884337320669088\n",
      "29 Train Loss 0.15924217 Test MSE 0.011543650092558828 Test RE 0.07762604397268454\n",
      "30 Train Loss 0.14216395 Test MSE 0.011856229026023278 Test RE 0.0786700030255727\n",
      "31 Train Loss 0.12519494 Test MSE 0.011168258464492325 Test RE 0.07635343940282485\n",
      "32 Train Loss 0.113007724 Test MSE 0.00873520414858558 Test RE 0.06752621489409677\n",
      "33 Train Loss 0.104303665 Test MSE 0.007531958809377574 Test RE 0.06270322018778564\n",
      "34 Train Loss 0.09819515 Test MSE 0.0077017504171552 Test RE 0.06340603517363119\n",
      "35 Train Loss 0.09211657 Test MSE 0.006983563236879845 Test RE 0.060377400644821076\n",
      "36 Train Loss 0.084954806 Test MSE 0.005773218378613924 Test RE 0.05489652696662973\n",
      "37 Train Loss 0.07655506 Test MSE 0.003907275369744375 Test RE 0.04516197091735489\n",
      "38 Train Loss 0.069636375 Test MSE 0.0030625576871097467 Test RE 0.03998324295089232\n",
      "39 Train Loss 0.063529074 Test MSE 0.0027691280922430327 Test RE 0.038019587415073754\n",
      "40 Train Loss 0.05741512 Test MSE 0.0024511988004200075 Test RE 0.035770511023902815\n",
      "41 Train Loss 0.053780396 Test MSE 0.0025658527780378112 Test RE 0.0365975273426573\n",
      "42 Train Loss 0.049820777 Test MSE 0.0018408940186576874 Test RE 0.030999184591035036\n",
      "43 Train Loss 0.04616469 Test MSE 0.0016151654184839862 Test RE 0.02903650765263846\n",
      "44 Train Loss 0.04304888 Test MSE 0.001574692272822739 Test RE 0.028670398214533058\n",
      "45 Train Loss 0.041026365 Test MSE 0.001690757413668322 Test RE 0.02970821286768553\n",
      "46 Train Loss 0.039264258 Test MSE 0.0016480464939274079 Test RE 0.029330577005508535\n",
      "47 Train Loss 0.037641484 Test MSE 0.0016631134595504176 Test RE 0.029464346695331704\n",
      "48 Train Loss 0.036460225 Test MSE 0.001773155343087275 Test RE 0.030423506616169337\n",
      "49 Train Loss 0.034489676 Test MSE 0.0016651048966302249 Test RE 0.029481981943761136\n",
      "50 Train Loss 0.032510895 Test MSE 0.0018412092604126492 Test RE 0.03100183868706958\n",
      "51 Train Loss 0.031047795 Test MSE 0.001739174546330024 Test RE 0.030130577953810384\n",
      "52 Train Loss 0.029645003 Test MSE 0.0017041275902130492 Test RE 0.029825444909482354\n",
      "53 Train Loss 0.028614212 Test MSE 0.0015855378116389613 Test RE 0.028768961075210424\n",
      "54 Train Loss 0.026807453 Test MSE 0.0014051357491762719 Test RE 0.027082890789721082\n",
      "55 Train Loss 0.025700435 Test MSE 0.0012575435513634513 Test RE 0.025621077736543152\n",
      "56 Train Loss 0.024580857 Test MSE 0.0011145501758761966 Test RE 0.02412046573770404\n",
      "57 Train Loss 0.02247313 Test MSE 0.001209387157599128 Test RE 0.025125722167521493\n",
      "58 Train Loss 0.020935304 Test MSE 0.0011768951425294117 Test RE 0.024785903931975703\n",
      "59 Train Loss 0.019787217 Test MSE 0.0011476614821321314 Test RE 0.024476131619362254\n",
      "60 Train Loss 0.018366577 Test MSE 0.0010427602274977231 Test RE 0.023330718086299124\n",
      "61 Train Loss 0.017532822 Test MSE 0.0010327641634123768 Test RE 0.023218622826125933\n",
      "62 Train Loss 0.017021505 Test MSE 0.0009958402344375362 Test RE 0.022799782882874185\n",
      "63 Train Loss 0.01636722 Test MSE 0.0008884457751235235 Test RE 0.02153532052905706\n",
      "64 Train Loss 0.015657699 Test MSE 0.000939277749789572 Test RE 0.022142818192020124\n",
      "65 Train Loss 0.014856129 Test MSE 0.000989217394442032 Test RE 0.022723841380186596\n",
      "66 Train Loss 0.014205845 Test MSE 0.0010567407129964453 Test RE 0.02348659704748071\n",
      "67 Train Loss 0.013615185 Test MSE 0.001046242070214415 Test RE 0.02336963700092544\n",
      "68 Train Loss 0.013095852 Test MSE 0.0010218141904780873 Test RE 0.023095206074165868\n",
      "69 Train Loss 0.012622429 Test MSE 0.0009979905992426646 Test RE 0.02282438593187783\n",
      "70 Train Loss 0.012065416 Test MSE 0.0010302193444533233 Test RE 0.023189998849060586\n",
      "71 Train Loss 0.0117466105 Test MSE 0.0010366296114515978 Test RE 0.02326203378102655\n",
      "72 Train Loss 0.011373984 Test MSE 0.0010985843839401532 Test RE 0.023947081241989198\n",
      "73 Train Loss 0.010895579 Test MSE 0.001095650193535597 Test RE 0.023915079933130873\n",
      "74 Train Loss 0.010481656 Test MSE 0.0011591632567346545 Test RE 0.024598474803988166\n",
      "75 Train Loss 0.010019566 Test MSE 0.0011910104506388383 Test RE 0.02493409805425035\n",
      "76 Train Loss 0.009597972 Test MSE 0.0011359607544014412 Test RE 0.024351041488655946\n",
      "77 Train Loss 0.009175578 Test MSE 0.0011323907302322467 Test RE 0.024312746936510653\n",
      "78 Train Loss 0.008845102 Test MSE 0.0010875493880195674 Test RE 0.023826506574612532\n",
      "79 Train Loss 0.008439792 Test MSE 0.0009642489701588014 Test RE 0.02243522703381707\n",
      "80 Train Loss 0.008119501 Test MSE 0.0008527526522280376 Test RE 0.02109829771515536\n",
      "81 Train Loss 0.007855856 Test MSE 0.0007875280345424761 Test RE 0.020275374669481462\n",
      "82 Train Loss 0.007656848 Test MSE 0.0006886816239499181 Test RE 0.01896029649173423\n",
      "83 Train Loss 0.0073925913 Test MSE 0.000617354987102764 Test RE 0.017951608044656155\n",
      "84 Train Loss 0.0072433488 Test MSE 0.0005632084633113063 Test RE 0.017146301775217608\n",
      "85 Train Loss 0.007081827 Test MSE 0.0005333549445527065 Test RE 0.016685684969264914\n",
      "86 Train Loss 0.0069410875 Test MSE 0.00048573589156873046 Test RE 0.015923406219971202\n",
      "87 Train Loss 0.00682076 Test MSE 0.0004422979944167004 Test RE 0.015194743105068888\n",
      "88 Train Loss 0.0066457633 Test MSE 0.0004099149581163877 Test RE 0.014627926182345595\n",
      "89 Train Loss 0.006540588 Test MSE 0.00038813021602035166 Test RE 0.014233922729563994\n",
      "90 Train Loss 0.0064388765 Test MSE 0.0003842153011389032 Test RE 0.014161954837432008\n",
      "91 Train Loss 0.006330039 Test MSE 0.000356663629104486 Test RE 0.013644740766858418\n",
      "92 Train Loss 0.0062041585 Test MSE 0.0003418655726311558 Test RE 0.013358680431409958\n",
      "93 Train Loss 0.0061120936 Test MSE 0.0003311005894893004 Test RE 0.013146672791417166\n",
      "94 Train Loss 0.0060368315 Test MSE 0.0003246582814256153 Test RE 0.013018145451257065\n",
      "95 Train Loss 0.0059464304 Test MSE 0.00031131106868417915 Test RE 0.012747738853344752\n",
      "96 Train Loss 0.005856473 Test MSE 0.00030889838243133974 Test RE 0.012698244761458194\n",
      "97 Train Loss 0.0057447613 Test MSE 0.00029602228611525 Test RE 0.012430771431700871\n",
      "98 Train Loss 0.0056484635 Test MSE 0.0002948191912554529 Test RE 0.012405485119964612\n",
      "99 Train Loss 0.0055610836 Test MSE 0.0002973868742502501 Test RE 0.01245938985043649\n",
      "100 Train Loss 0.005450027 Test MSE 0.0002971468569432882 Test RE 0.012454360924996822\n",
      "101 Train Loss 0.0053333524 Test MSE 0.0002935171738252628 Test RE 0.0123780614801217\n",
      "102 Train Loss 0.0051867426 Test MSE 0.0002919180581733458 Test RE 0.012344296870672214\n",
      "103 Train Loss 0.0050766547 Test MSE 0.00029025456192719666 Test RE 0.012309074607375042\n",
      "104 Train Loss 0.0049867975 Test MSE 0.0002893698986299207 Test RE 0.012290301953929316\n",
      "105 Train Loss 0.0048562055 Test MSE 0.0003022483602496214 Test RE 0.012560815994413324\n",
      "106 Train Loss 0.0047519454 Test MSE 0.0003144762426154961 Test RE 0.012812379615968813\n",
      "107 Train Loss 0.0046170345 Test MSE 0.0002971136197909416 Test RE 0.01245366436863442\n",
      "108 Train Loss 0.004528161 Test MSE 0.00029856688490316463 Test RE 0.012484084378919819\n",
      "109 Train Loss 0.004450256 Test MSE 0.0003138751080655013 Test RE 0.012800128057361774\n",
      "110 Train Loss 0.004366943 Test MSE 0.00031990330006161647 Test RE 0.012922461204024443\n",
      "111 Train Loss 0.0042877 Test MSE 0.0003296793234274524 Test RE 0.013118426066552185\n",
      "112 Train Loss 0.004223307 Test MSE 0.0003643718769226559 Test RE 0.013791398317223152\n",
      "113 Train Loss 0.004145651 Test MSE 0.0003571250549367445 Test RE 0.013653564207667791\n",
      "114 Train Loss 0.0040737614 Test MSE 0.0003879130761197247 Test RE 0.014229940580221223\n",
      "115 Train Loss 0.0040083234 Test MSE 0.00040662057387562135 Test RE 0.014569027107866495\n",
      "116 Train Loss 0.003948478 Test MSE 0.0003976173280214181 Test RE 0.0144068332050636\n",
      "117 Train Loss 0.0038718455 Test MSE 0.00038707842908304824 Test RE 0.014214623523283584\n",
      "118 Train Loss 0.0038023973 Test MSE 0.00038081377586348097 Test RE 0.014099126338532336\n",
      "119 Train Loss 0.003738794 Test MSE 0.00040281387245552565 Test RE 0.014500670570891768\n",
      "120 Train Loss 0.0037012012 Test MSE 0.00040721004202753794 Test RE 0.014579583469058568\n",
      "121 Train Loss 0.003657562 Test MSE 0.0004202987837868209 Test RE 0.01481204229696197\n",
      "122 Train Loss 0.0035996367 Test MSE 0.0004367684087217102 Test RE 0.015099462440205132\n",
      "123 Train Loss 0.0035372612 Test MSE 0.0004196288012506518 Test RE 0.014800231927772939\n",
      "124 Train Loss 0.0034986786 Test MSE 0.0004343045540420515 Test RE 0.0150568134124145\n",
      "125 Train Loss 0.0034431769 Test MSE 0.00043602830702010246 Test RE 0.015086664037562106\n",
      "126 Train Loss 0.0034084555 Test MSE 0.00042022779989033394 Test RE 0.014810791447667754\n",
      "127 Train Loss 0.0033747994 Test MSE 0.00039741821425744503 Test RE 0.014403225517722922\n",
      "128 Train Loss 0.0033275448 Test MSE 0.00039451076649331656 Test RE 0.014350442962170216\n",
      "129 Train Loss 0.0032858218 Test MSE 0.0004076640600171108 Test RE 0.014587708942954893\n",
      "130 Train Loss 0.003250041 Test MSE 0.00042728403099546444 Test RE 0.014934621071570849\n",
      "131 Train Loss 0.0032035017 Test MSE 0.00043906541619655366 Test RE 0.015139115143835752\n",
      "132 Train Loss 0.0031492552 Test MSE 0.00041829669492609764 Test RE 0.014776721680121932\n",
      "133 Train Loss 0.0030772162 Test MSE 0.00040934060889403996 Test RE 0.014617674686441044\n",
      "134 Train Loss 0.0030353258 Test MSE 0.00041612699707750797 Test RE 0.014738348553109121\n",
      "135 Train Loss 0.0029592195 Test MSE 0.0004052046190612478 Test RE 0.014543638483128035\n",
      "136 Train Loss 0.0029115083 Test MSE 0.0003851671359221617 Test RE 0.014179486027543362\n",
      "137 Train Loss 0.002882261 Test MSE 0.00036490245966294037 Test RE 0.013801435886617142\n",
      "138 Train Loss 0.0028554364 Test MSE 0.0003556435957782607 Test RE 0.013625215288756987\n",
      "139 Train Loss 0.002829934 Test MSE 0.00035810937381658474 Test RE 0.0136723674434237\n",
      "140 Train Loss 0.0028042474 Test MSE 0.0003593173841852987 Test RE 0.01369540852755273\n",
      "141 Train Loss 0.0027682018 Test MSE 0.0003558955496111878 Test RE 0.013630040790274564\n",
      "142 Train Loss 0.0026863988 Test MSE 0.0003188971604009605 Test RE 0.01290212374588155\n",
      "143 Train Loss 0.0026236393 Test MSE 0.00030015233160039627 Test RE 0.012517186917973194\n",
      "144 Train Loss 0.0025811703 Test MSE 0.0002777566040195139 Test RE 0.012041152971077588\n",
      "145 Train Loss 0.0025471593 Test MSE 0.00026019278776639147 Test RE 0.011654227833005864\n",
      "146 Train Loss 0.0025191207 Test MSE 0.00024083525029291428 Test RE 0.01121233083353548\n",
      "147 Train Loss 0.0024895943 Test MSE 0.0002243863673136761 Test RE 0.01082266238392884\n",
      "148 Train Loss 0.0024502845 Test MSE 0.00023072375155485208 Test RE 0.01097443142845775\n",
      "149 Train Loss 0.0024044856 Test MSE 0.00021709772145619882 Test RE 0.010645437378580317\n",
      "150 Train Loss 0.002363729 Test MSE 0.00020966139258456255 Test RE 0.010461527714948064\n",
      "151 Train Loss 0.0023292901 Test MSE 0.00019485662617052665 Test RE 0.010085407865091909\n",
      "152 Train Loss 0.002284464 Test MSE 0.0001731740440913703 Test RE 0.009507739550634595\n",
      "153 Train Loss 0.002221342 Test MSE 0.00016072869532924816 Test RE 0.009159728194588592\n",
      "154 Train Loss 0.0021789805 Test MSE 0.00015328630531046098 Test RE 0.00894514850744065\n",
      "155 Train Loss 0.002145708 Test MSE 0.0001562766757841446 Test RE 0.009031979832965982\n",
      "156 Train Loss 0.002102266 Test MSE 0.00014898713634530237 Test RE 0.008818815632331537\n",
      "157 Train Loss 0.002041145 Test MSE 0.0001407803531232776 Test RE 0.00857248831887308\n",
      "158 Train Loss 0.0019910622 Test MSE 0.00012829738045687868 Test RE 0.008183607119031287\n",
      "159 Train Loss 0.0019610734 Test MSE 0.00012438622091727792 Test RE 0.008057902600491966\n",
      "160 Train Loss 0.0019290077 Test MSE 0.0001217302082891586 Test RE 0.007971408390876185\n",
      "161 Train Loss 0.0018958818 Test MSE 0.00011604556150529089 Test RE 0.0077830557987687565\n",
      "162 Train Loss 0.0018750963 Test MSE 0.00011467354953290404 Test RE 0.007736909283073043\n",
      "163 Train Loss 0.0018412193 Test MSE 0.00010488389001216055 Test RE 0.007399293768128199\n",
      "164 Train Loss 0.0018074748 Test MSE 0.00010002766483028225 Test RE 0.007225966469708487\n",
      "165 Train Loss 0.0017790861 Test MSE 9.812583266752975e-05 Test RE 0.007156942934885775\n",
      "166 Train Loss 0.0017487183 Test MSE 9.653000809597346e-05 Test RE 0.007098507543682873\n",
      "167 Train Loss 0.0017191049 Test MSE 9.226086862920783e-05 Test RE 0.00693976311756511\n",
      "168 Train Loss 0.0016927302 Test MSE 8.993489697924106e-05 Test RE 0.006851726164245538\n",
      "169 Train Loss 0.0016762478 Test MSE 9.270520517346813e-05 Test RE 0.006956454303165453\n",
      "170 Train Loss 0.0016615452 Test MSE 9.096421640276723e-05 Test RE 0.0068908241681492205\n",
      "171 Train Loss 0.0016319522 Test MSE 8.026427925161199e-05 Test RE 0.006472872193805243\n",
      "172 Train Loss 0.0016089018 Test MSE 7.940202853445091e-05 Test RE 0.006438010427662063\n",
      "173 Train Loss 0.0015847184 Test MSE 7.906733223907427e-05 Test RE 0.006424427312789986\n",
      "174 Train Loss 0.0015533626 Test MSE 8.590124578138934e-05 Test RE 0.006696310882896904\n",
      "175 Train Loss 0.0015223915 Test MSE 8.511680283261152e-05 Test RE 0.006665665686322925\n",
      "176 Train Loss 0.0015031851 Test MSE 8.8670854649251e-05 Test RE 0.006803404988181406\n",
      "177 Train Loss 0.0014795028 Test MSE 8.86313131881695e-05 Test RE 0.006801887879925772\n",
      "178 Train Loss 0.0014525721 Test MSE 9.217176129769312e-05 Test RE 0.006936411029264619\n",
      "179 Train Loss 0.0014328278 Test MSE 8.826129688844737e-05 Test RE 0.006787674835048432\n",
      "180 Train Loss 0.0014191744 Test MSE 8.302094224518997e-05 Test RE 0.006583088687258171\n",
      "181 Train Loss 0.0014048788 Test MSE 7.54148509508409e-05 Test RE 0.0062742860608824575\n",
      "182 Train Loss 0.0013835884 Test MSE 7.220608396421135e-05 Test RE 0.006139355371922677\n",
      "183 Train Loss 0.0013659751 Test MSE 7.335458798411736e-05 Test RE 0.006187988785363852\n",
      "184 Train Loss 0.0013432085 Test MSE 6.800268952496831e-05 Test RE 0.005957978362343808\n",
      "185 Train Loss 0.0013246416 Test MSE 6.379673342613396e-05 Test RE 0.005770787707011958\n",
      "186 Train Loss 0.0012975044 Test MSE 6.307043656998852e-05 Test RE 0.0057378447790603125\n",
      "187 Train Loss 0.0012662761 Test MSE 5.554929461191824e-05 Test RE 0.005384869106980786\n",
      "188 Train Loss 0.0012265488 Test MSE 5.226131185559484e-05 Test RE 0.005223072214455405\n",
      "189 Train Loss 0.0011986238 Test MSE 5.0622908346360955e-05 Test RE 0.005140548050786722\n",
      "190 Train Loss 0.0011720028 Test MSE 4.927264453093348e-05 Test RE 0.005071527829050101\n",
      "191 Train Loss 0.0011479348 Test MSE 4.6819549989802385e-05 Test RE 0.004943670244101771\n",
      "192 Train Loss 0.0011237271 Test MSE 4.366722801496131e-05 Test RE 0.0047743437949524835\n",
      "193 Train Loss 0.0011055378 Test MSE 4.166601620262053e-05 Test RE 0.004663659839414803\n",
      "194 Train Loss 0.0010886596 Test MSE 4.011169916342131e-05 Test RE 0.004575846071118857\n",
      "195 Train Loss 0.0010758507 Test MSE 4.044412734322692e-05 Test RE 0.004594768250543161\n",
      "196 Train Loss 0.0010634396 Test MSE 4.142153091799622e-05 Test RE 0.0046499571408392\n",
      "197 Train Loss 0.0010438114 Test MSE 4.348538656155469e-05 Test RE 0.004764392632890952\n",
      "198 Train Loss 0.001036001 Test MSE 4.371794369273905e-05 Test RE 0.0047771154824272745\n",
      "199 Train Loss 0.0010285106 Test MSE 4.3269895307342907e-05 Test RE 0.004752573029599968\n",
      "200 Train Loss 0.0010217263 Test MSE 4.195423617819229e-05 Test RE 0.004679762211728726\n",
      "201 Train Loss 0.0010153741 Test MSE 4.2263992611896003e-05 Test RE 0.004697006246791693\n",
      "202 Train Loss 0.0010054947 Test MSE 4.149347982466386e-05 Test RE 0.004653993860018379\n",
      "203 Train Loss 0.0009930329 Test MSE 4.253740849872824e-05 Test RE 0.004712174783088545\n",
      "204 Train Loss 0.0009841952 Test MSE 4.094986502532182e-05 Test RE 0.004623406872271864\n",
      "205 Train Loss 0.0009655717 Test MSE 3.788726294334522e-05 Test RE 0.004447157318502841\n",
      "206 Train Loss 0.0009528491 Test MSE 3.913076957276152e-05 Test RE 0.004519548710384266\n",
      "207 Train Loss 0.00093788904 Test MSE 4.179845606908134e-05 Test RE 0.00467106592836913\n",
      "208 Train Loss 0.0009283451 Test MSE 4.305392864598173e-05 Test RE 0.004740697784057719\n",
      "209 Train Loss 0.0009159009 Test MSE 4.191038006160998e-05 Test RE 0.004677315618978005\n",
      "210 Train Loss 0.0009061548 Test MSE 3.843674435472518e-05 Test RE 0.004479289936846578\n",
      "211 Train Loss 0.0008950334 Test MSE 3.686619386861443e-05 Test RE 0.004386822155438431\n",
      "212 Train Loss 0.0008816609 Test MSE 3.464355666279231e-05 Test RE 0.004252527326253196\n",
      "213 Train Loss 0.0008696291 Test MSE 3.269533732288545e-05 Test RE 0.00413122442336142\n",
      "214 Train Loss 0.00086037576 Test MSE 3.243805184339113e-05 Test RE 0.004114937645831722\n",
      "215 Train Loss 0.0008544937 Test MSE 3.394703979963595e-05 Test RE 0.004209561237329913\n",
      "216 Train Loss 0.000848016 Test MSE 3.4912960460023234e-05 Test RE 0.004269030082782496\n",
      "217 Train Loss 0.00084098475 Test MSE 3.508466686065105e-05 Test RE 0.004279515024739395\n",
      "218 Train Loss 0.00083387754 Test MSE 3.453049399120081e-05 Test RE 0.0042455823836056745\n",
      "219 Train Loss 0.0008252167 Test MSE 3.5289324614989417e-05 Test RE 0.004291978623247551\n",
      "220 Train Loss 0.0008181709 Test MSE 3.654886094408031e-05 Test RE 0.004367901138964294\n",
      "221 Train Loss 0.000811649 Test MSE 3.7170619894163546e-05 Test RE 0.004404897214062002\n",
      "222 Train Loss 0.00080228614 Test MSE 3.891827480226187e-05 Test RE 0.004507260582202244\n",
      "223 Train Loss 0.0007926202 Test MSE 4.280230277064096e-05 Test RE 0.004726824134083232\n",
      "224 Train Loss 0.00078217854 Test MSE 4.371745010515362e-05 Test RE 0.00477708851487857\n",
      "225 Train Loss 0.0007707034 Test MSE 4.918367403997048e-05 Test RE 0.005066946989143479\n",
      "226 Train Loss 0.00076449616 Test MSE 4.7701495172996204e-05 Test RE 0.004990015249871116\n",
      "227 Train Loss 0.00075941446 Test MSE 4.7377715801472834e-05 Test RE 0.004973051264087928\n",
      "228 Train Loss 0.00075554755 Test MSE 4.623361585259899e-05 Test RE 0.004912638494934608\n",
      "229 Train Loss 0.00075238466 Test MSE 4.788017431768895e-05 Test RE 0.004999352255652645\n",
      "230 Train Loss 0.0007492575 Test MSE 4.5762916380286066e-05 Test RE 0.0048875669969550475\n",
      "231 Train Loss 0.0007481439 Test MSE 4.561057030050109e-05 Test RE 0.004879424788542379\n",
      "232 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "233 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "234 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "235 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "236 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "237 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "238 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "239 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "240 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "241 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "242 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "243 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "244 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "245 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "246 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "247 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "248 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "249 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "250 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "251 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "252 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "253 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "254 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "255 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "256 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "257 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "258 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "259 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "260 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "261 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "262 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "263 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "264 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "265 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "266 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "267 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "268 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "269 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "270 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "271 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "272 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "273 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "274 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "275 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "276 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "277 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "278 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "279 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "280 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "281 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "282 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "283 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "284 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "285 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "286 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "287 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "288 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "289 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "290 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "291 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "292 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "293 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "294 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "295 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "296 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "297 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "298 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "299 Train Loss 0.0007473954 Test MSE 4.4861804344152904e-05 Test RE 0.004839207508688345\n",
      "Training time: 156.38\n",
      "KG_stan_high\n",
      "5\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "5\n",
      "0 Train Loss 28348.246 Test MSE 9.733051715902565 Test RE 2.2540336351107992\n",
      "1 Train Loss 3109.025 Test MSE 11.748475874213463 Test RE 2.4764333362326916\n",
      "2 Train Loss 760.5227 Test MSE 7.858296249107626 Test RE 2.02534995891262\n",
      "3 Train Loss 198.67865 Test MSE 6.841230943466381 Test RE 1.8897441195789946\n",
      "4 Train Loss 93.313835 Test MSE 6.261188166348117 Test RE 1.807857747667359\n",
      "5 Train Loss 51.52391 Test MSE 5.380960261985596 Test RE 1.6759681817992618\n",
      "6 Train Loss 34.06393 Test MSE 5.163414587525657 Test RE 1.641739984675055\n",
      "7 Train Loss 23.6779 Test MSE 4.886901639109949 Test RE 1.5971756329542595\n",
      "8 Train Loss 18.302427 Test MSE 4.942429242320363 Test RE 1.6062239865155665\n",
      "9 Train Loss 14.9305105 Test MSE 4.936611314503019 Test RE 1.6052783334334044\n",
      "10 Train Loss 12.6661 Test MSE 4.826550955105458 Test RE 1.587282852777749\n",
      "11 Train Loss 11.133707 Test MSE 4.672889373872534 Test RE 1.5618115373841985\n",
      "12 Train Loss 10.204925 Test MSE 4.6425536092820545 Test RE 1.556733748456644\n",
      "13 Train Loss 9.470606 Test MSE 4.6788868911469725 Test RE 1.5628134857814024\n",
      "14 Train Loss 8.929893 Test MSE 4.612345902133048 Test RE 1.5516608827441396\n",
      "15 Train Loss 8.349427 Test MSE 4.476024146769664 Test RE 1.5285585804262634\n",
      "16 Train Loss 7.817069 Test MSE 4.347809864655753 Test RE 1.5065069816552632\n",
      "17 Train Loss 7.5578446 Test MSE 4.298982472595064 Test RE 1.498023802786216\n",
      "18 Train Loss 7.154276 Test MSE 4.153186239825394 Test RE 1.4724026151228655\n",
      "19 Train Loss 6.67852 Test MSE 3.8284382868879407 Test RE 1.4136656398761973\n",
      "20 Train Loss 6.0104027 Test MSE 3.5682539701061797 Test RE 1.3647834761784308\n",
      "21 Train Loss 5.43111 Test MSE 3.4505072673462047 Test RE 1.3420767418409878\n",
      "22 Train Loss 4.857468 Test MSE 3.1714825529135044 Test RE 1.2866696003930034\n",
      "23 Train Loss 4.322065 Test MSE 2.9081019340214036 Test RE 1.2320850545119557\n",
      "24 Train Loss 3.7585957 Test MSE 2.5160351554085687 Test RE 1.1460253634580215\n",
      "25 Train Loss 3.3836412 Test MSE 2.07646715667985 Test RE 1.0411142960854056\n",
      "26 Train Loss 2.9775097 Test MSE 1.7685714238425958 Test RE 0.9608313806735231\n",
      "27 Train Loss 2.4290586 Test MSE 1.246344374837826 Test RE 0.8065938490956607\n",
      "28 Train Loss 2.0398743 Test MSE 1.0210194404223987 Test RE 0.7300504659845813\n",
      "29 Train Loss 1.5302329 Test MSE 0.8110860295984931 Test RE 0.6506828158356366\n",
      "30 Train Loss 1.280224 Test MSE 0.6737482634834657 Test RE 0.5930409820918053\n",
      "31 Train Loss 0.99667335 Test MSE 0.4254900176667619 Test RE 0.4712816874192496\n",
      "32 Train Loss 0.8153818 Test MSE 0.2815101259155073 Test RE 0.3833388956857654\n",
      "33 Train Loss 0.6876791 Test MSE 0.22268778303162726 Test RE 0.3409448012914336\n",
      "34 Train Loss 0.5732238 Test MSE 0.13028024734365903 Test RE 0.2607805302827808\n",
      "35 Train Loss 0.46271357 Test MSE 0.10878423854941903 Test RE 0.23829715916735028\n",
      "36 Train Loss 0.38377395 Test MSE 0.08285894322156362 Test RE 0.2079723369355331\n",
      "37 Train Loss 0.31102246 Test MSE 0.07491522450346373 Test RE 0.19775201596222183\n",
      "38 Train Loss 0.27102223 Test MSE 0.06186555808889888 Test RE 0.17970507597190025\n",
      "39 Train Loss 0.23879315 Test MSE 0.05393818642117735 Test RE 0.1677969439579749\n",
      "40 Train Loss 0.21306868 Test MSE 0.04577776299248349 Test RE 0.15458350851113253\n",
      "41 Train Loss 0.19370799 Test MSE 0.03950911782560459 Test RE 0.1436099540502771\n",
      "42 Train Loss 0.17764816 Test MSE 0.037123012677721855 Test RE 0.1392058491152463\n",
      "43 Train Loss 0.1642795 Test MSE 0.033482859730835604 Test RE 0.13220477720973664\n",
      "44 Train Loss 0.15043893 Test MSE 0.031315258719987 Test RE 0.12785387022173975\n",
      "45 Train Loss 0.13171376 Test MSE 0.027963640392408083 Test RE 0.12081830293839371\n",
      "46 Train Loss 0.12173598 Test MSE 0.024631634753304175 Test RE 0.11339202075992307\n",
      "47 Train Loss 0.113303006 Test MSE 0.023029463354853834 Test RE 0.10964221127535533\n",
      "48 Train Loss 0.10179923 Test MSE 0.02327126154751635 Test RE 0.11021630330143953\n",
      "49 Train Loss 0.09360316 Test MSE 0.022951028524857538 Test RE 0.10945533972435495\n",
      "50 Train Loss 0.08898686 Test MSE 0.02274398255195617 Test RE 0.10896051158584896\n",
      "51 Train Loss 0.083602756 Test MSE 0.021556670824892158 Test RE 0.10607834170337327\n",
      "52 Train Loss 0.0798862 Test MSE 0.02026378655395635 Test RE 0.10284807749981624\n",
      "53 Train Loss 0.075811036 Test MSE 0.018523940398512653 Test RE 0.09833374159773715\n",
      "54 Train Loss 0.07184091 Test MSE 0.016851101942165173 Test RE 0.09378859497550526\n",
      "55 Train Loss 0.06921392 Test MSE 0.015433717617727294 Test RE 0.08975758351944725\n",
      "56 Train Loss 0.06603156 Test MSE 0.013257511906129475 Test RE 0.08318918887767002\n",
      "57 Train Loss 0.06314569 Test MSE 0.012370823019749691 Test RE 0.0803591202938468\n",
      "58 Train Loss 0.06038237 Test MSE 0.011128437234157127 Test RE 0.076217196002866\n",
      "59 Train Loss 0.056623567 Test MSE 0.00974746020029614 Test RE 0.07133154196234459\n",
      "60 Train Loss 0.054704778 Test MSE 0.009543304345272853 Test RE 0.07058058667565054\n",
      "61 Train Loss 0.053126704 Test MSE 0.009983558836798459 Test RE 0.072190253649137\n",
      "62 Train Loss 0.05102155 Test MSE 0.009864430198526184 Test RE 0.0717582566235592\n",
      "63 Train Loss 0.049255468 Test MSE 0.009326665161082695 Test RE 0.06977487538964133\n",
      "64 Train Loss 0.04778 Test MSE 0.009327281909955567 Test RE 0.06977718236987525\n",
      "65 Train Loss 0.046348408 Test MSE 0.008953718757162414 Test RE 0.06836559552956521\n",
      "66 Train Loss 0.044632666 Test MSE 0.008068713248168716 Test RE 0.06489900188689107\n",
      "67 Train Loss 0.043147467 Test MSE 0.008103636789959437 Test RE 0.06503930032859305\n",
      "68 Train Loss 0.041972145 Test MSE 0.007743415591038313 Test RE 0.06357731183248846\n",
      "69 Train Loss 0.040206794 Test MSE 0.007249126198583466 Test RE 0.061514671208399666\n",
      "70 Train Loss 0.03913508 Test MSE 0.006564718466347658 Test RE 0.058538815402458484\n",
      "71 Train Loss 0.03804423 Test MSE 0.006319935307637731 Test RE 0.05743705887206934\n",
      "72 Train Loss 0.036473744 Test MSE 0.006567204912530473 Test RE 0.05854990040442957\n",
      "73 Train Loss 0.035355106 Test MSE 0.006686421500255999 Test RE 0.05907894781891092\n",
      "74 Train Loss 0.034121774 Test MSE 0.006606210360814915 Test RE 0.05872351947910863\n",
      "75 Train Loss 0.033382945 Test MSE 0.0064238105250639796 Test RE 0.05790715630674979\n",
      "76 Train Loss 0.03237337 Test MSE 0.006201328956131745 Test RE 0.05689554497565338\n",
      "77 Train Loss 0.03157654 Test MSE 0.006251352637745804 Test RE 0.05712456104937627\n",
      "78 Train Loss 0.030852567 Test MSE 0.005945818548565075 Test RE 0.05571109603298661\n",
      "79 Train Loss 0.030100137 Test MSE 0.00581893540701153 Test RE 0.0551134559844661\n",
      "80 Train Loss 0.028815422 Test MSE 0.005369694965088664 Test RE 0.0529432606144282\n",
      "81 Train Loss 0.027563063 Test MSE 0.004953708107122321 Test RE 0.050851185622766366\n",
      "82 Train Loss 0.026555296 Test MSE 0.00466681666351097 Test RE 0.04935671498760877\n",
      "83 Train Loss 0.025938844 Test MSE 0.004539865542695329 Test RE 0.0486807625088808\n",
      "84 Train Loss 0.024994042 Test MSE 0.004516801926142626 Test RE 0.048556950027077314\n",
      "85 Train Loss 0.024042172 Test MSE 0.004591516930991676 Test RE 0.04895690697734686\n",
      "86 Train Loss 0.02287451 Test MSE 0.0041300051636839535 Test RE 0.04643133537197452\n",
      "87 Train Loss 0.021479307 Test MSE 0.0035594701037263304 Test RE 0.04310508955325207\n",
      "88 Train Loss 0.020206017 Test MSE 0.0031013560048842375 Test RE 0.04023571171331652\n",
      "89 Train Loss 0.0193558 Test MSE 0.0029718426558721692 Test RE 0.039386626336671435\n",
      "90 Train Loss 0.018618481 Test MSE 0.002835688061635002 Test RE 0.03847380188258245\n",
      "91 Train Loss 0.01789132 Test MSE 0.00266697009469963 Test RE 0.037311692522748505\n",
      "92 Train Loss 0.017234888 Test MSE 0.002694411367669043 Test RE 0.037503156995870604\n",
      "93 Train Loss 0.016141195 Test MSE 0.0024238457545277866 Test RE 0.035570368677219175\n",
      "94 Train Loss 0.015645703 Test MSE 0.0022842666398549564 Test RE 0.03453100954407698\n",
      "95 Train Loss 0.015003587 Test MSE 0.002219170410305443 Test RE 0.034035426990764936\n",
      "96 Train Loss 0.014469965 Test MSE 0.002251541870367194 Test RE 0.034282768868086545\n",
      "97 Train Loss 0.0140106585 Test MSE 0.002045774843833165 Test RE 0.032678701688793\n",
      "98 Train Loss 0.013493698 Test MSE 0.001805791220795947 Test RE 0.030702210540159272\n",
      "99 Train Loss 0.013178932 Test MSE 0.001543813799307312 Test RE 0.02838790454018504\n",
      "100 Train Loss 0.012694286 Test MSE 0.0014614398319587258 Test RE 0.02762016997389826\n",
      "101 Train Loss 0.012380058 Test MSE 0.0014296367109474936 Test RE 0.02731798880603913\n",
      "102 Train Loss 0.011983558 Test MSE 0.0013292228438895924 Test RE 0.0263411526483201\n",
      "103 Train Loss 0.01156818 Test MSE 0.0012415735119866893 Test RE 0.025457871863496823\n",
      "104 Train Loss 0.011154647 Test MSE 0.0011111631302279342 Test RE 0.024083787585912078\n",
      "105 Train Loss 0.010880273 Test MSE 0.0010501990803187243 Test RE 0.023413788646401854\n",
      "106 Train Loss 0.010603254 Test MSE 0.0010550763038245643 Test RE 0.023468093590676736\n",
      "107 Train Loss 0.01021398 Test MSE 0.0010293556010445787 Test RE 0.023180275478551348\n",
      "108 Train Loss 0.009969776 Test MSE 0.0009618674513761159 Test RE 0.02240750444993861\n",
      "109 Train Loss 0.009741537 Test MSE 0.0009347447362357477 Test RE 0.02208932225295523\n",
      "110 Train Loss 0.009469886 Test MSE 0.0009194504660141392 Test RE 0.02190786446795008\n",
      "111 Train Loss 0.00904432 Test MSE 0.0008615853965321677 Test RE 0.02120728347250274\n",
      "112 Train Loss 0.008776443 Test MSE 0.0008682679827031024 Test RE 0.02128936805804263\n",
      "113 Train Loss 0.008661777 Test MSE 0.0008548278340101101 Test RE 0.021123953571416637\n",
      "114 Train Loss 0.0084305275 Test MSE 0.0008235068768485122 Test RE 0.0207333506158942\n",
      "115 Train Loss 0.008212804 Test MSE 0.000810042197172062 Test RE 0.020563152597009908\n",
      "116 Train Loss 0.008040657 Test MSE 0.0007297720108927631 Test RE 0.0195177377483469\n",
      "117 Train Loss 0.007865863 Test MSE 0.0007002160001701559 Test RE 0.01911841533135068\n",
      "118 Train Loss 0.0076735537 Test MSE 0.000669174977062383 Test RE 0.018689846014700178\n",
      "119 Train Loss 0.007542639 Test MSE 0.0006244525200820637 Test RE 0.01805450509635953\n",
      "120 Train Loss 0.0074118515 Test MSE 0.0006061303617476999 Test RE 0.01778766314271504\n",
      "121 Train Loss 0.0072311196 Test MSE 0.0005759851971007833 Test RE 0.017339698348393166\n",
      "122 Train Loss 0.007068999 Test MSE 0.000582420226108532 Test RE 0.017436290707304413\n",
      "123 Train Loss 0.006927043 Test MSE 0.0005793942583108437 Test RE 0.017390936544362606\n",
      "124 Train Loss 0.0067746253 Test MSE 0.0005633394948838755 Test RE 0.01714829621987859\n",
      "125 Train Loss 0.0066461023 Test MSE 0.0005569313382884178 Test RE 0.017050483742931062\n",
      "126 Train Loss 0.0065037864 Test MSE 0.0005201782769991899 Test RE 0.016478283970760805\n",
      "127 Train Loss 0.006349122 Test MSE 0.0004775802103335664 Test RE 0.015789160452042563\n",
      "128 Train Loss 0.006130633 Test MSE 0.000464664640328136 Test RE 0.015574197919008704\n",
      "129 Train Loss 0.006009782 Test MSE 0.00047738572350050466 Test RE 0.01578594518428017\n",
      "130 Train Loss 0.005845358 Test MSE 0.00047996741950019406 Test RE 0.015828572726377305\n",
      "131 Train Loss 0.0056920457 Test MSE 0.0005026460040112828 Test RE 0.016198208844301717\n",
      "132 Train Loss 0.005617198 Test MSE 0.0005066719180350805 Test RE 0.016262948777405944\n",
      "133 Train Loss 0.0055339327 Test MSE 0.0005576720456982075 Test RE 0.01706181837464676\n",
      "134 Train Loss 0.00546944 Test MSE 0.0005396179358798155 Test RE 0.016783365984866738\n",
      "135 Train Loss 0.0053252755 Test MSE 0.0005394786817070024 Test RE 0.016781200281696808\n",
      "136 Train Loss 0.005199238 Test MSE 0.0005627425196920741 Test RE 0.01713920772081077\n",
      "137 Train Loss 0.0050954996 Test MSE 0.0005527700179066821 Test RE 0.01698666478072225\n",
      "138 Train Loss 0.004989361 Test MSE 0.000499932910941913 Test RE 0.016154433790838474\n",
      "139 Train Loss 0.004870462 Test MSE 0.0004816240421691086 Test RE 0.015855865604814147\n",
      "140 Train Loss 0.00474756 Test MSE 0.00047023147844965033 Test RE 0.01566721221816371\n",
      "141 Train Loss 0.004652842 Test MSE 0.00044551184583037015 Test RE 0.015249847648374244\n",
      "142 Train Loss 0.0045222924 Test MSE 0.0004184414329321219 Test RE 0.014779277961677521\n",
      "143 Train Loss 0.0044164234 Test MSE 0.0003867825755135118 Test RE 0.014209190191584021\n",
      "144 Train Loss 0.004301724 Test MSE 0.00038060377087971415 Test RE 0.014095238224047582\n",
      "145 Train Loss 0.004214143 Test MSE 0.0003822676994725968 Test RE 0.01412601549693542\n",
      "146 Train Loss 0.0041291625 Test MSE 0.00037758430427409256 Test RE 0.014039215593654127\n",
      "147 Train Loss 0.0040528616 Test MSE 0.00034204255192911366 Test RE 0.013362137790343913\n",
      "148 Train Loss 0.0039637764 Test MSE 0.00029890201865968294 Test RE 0.012491088947915105\n",
      "149 Train Loss 0.003904657 Test MSE 0.0002723199854118317 Test RE 0.01192272795069809\n",
      "150 Train Loss 0.0038313258 Test MSE 0.0002651357170033036 Test RE 0.01176440575959513\n",
      "151 Train Loss 0.0037703353 Test MSE 0.00025097122161135227 Test RE 0.011445844441854317\n",
      "152 Train Loss 0.0036976878 Test MSE 0.00023250362484328687 Test RE 0.011016680158301607\n",
      "153 Train Loss 0.0036558039 Test MSE 0.00021773780917985644 Test RE 0.010661119253404945\n",
      "154 Train Loss 0.0036107032 Test MSE 0.0002379991280728375 Test RE 0.011146116034654891\n",
      "155 Train Loss 0.0035684044 Test MSE 0.00023335934242301782 Test RE 0.011036934700060869\n",
      "156 Train Loss 0.003502282 Test MSE 0.0002217728842529213 Test RE 0.010759450682526822\n",
      "157 Train Loss 0.0034548086 Test MSE 0.0002186096049603785 Test RE 0.010682440846707159\n",
      "158 Train Loss 0.0033924952 Test MSE 0.00021519701492565225 Test RE 0.010598734137378801\n",
      "159 Train Loss 0.0033200923 Test MSE 0.00020466350409463501 Test RE 0.010336085178883786\n",
      "160 Train Loss 0.0032786094 Test MSE 0.00021331738763810437 Test RE 0.010552345570769471\n",
      "161 Train Loss 0.0032346346 Test MSE 0.00020334231286052302 Test RE 0.010302669217958882\n",
      "162 Train Loss 0.00318515 Test MSE 0.00018608628782327514 Test RE 0.009855826804627314\n",
      "163 Train Loss 0.0031515404 Test MSE 0.00017320234979755205 Test RE 0.009508516550118768\n",
      "164 Train Loss 0.003103246 Test MSE 0.00017904291546944157 Test RE 0.009667505937170097\n",
      "165 Train Loss 0.0030417182 Test MSE 0.0001757979992108585 Test RE 0.009579499980681928\n",
      "166 Train Loss 0.0029952629 Test MSE 0.0001705213604521788 Test RE 0.009434638653125113\n",
      "167 Train Loss 0.0029607979 Test MSE 0.0001704063516557795 Test RE 0.009431456502069004\n",
      "168 Train Loss 0.0029291576 Test MSE 0.00017354597663871564 Test RE 0.009517944143121078\n",
      "169 Train Loss 0.002899291 Test MSE 0.00017102363704863026 Test RE 0.00944852346419823\n",
      "170 Train Loss 0.0028716412 Test MSE 0.00016600511061951064 Test RE 0.009308862299590322\n",
      "171 Train Loss 0.0028392621 Test MSE 0.00015577977602772053 Test RE 0.009017609288676239\n",
      "172 Train Loss 0.002808288 Test MSE 0.0001454470597943853 Test RE 0.008713414019509435\n",
      "173 Train Loss 0.002769716 Test MSE 0.00014375087013555074 Test RE 0.008662457522172812\n",
      "174 Train Loss 0.0027219693 Test MSE 0.00012936125096283963 Test RE 0.008217467218199086\n",
      "175 Train Loss 0.0026913742 Test MSE 0.00012671325888206228 Test RE 0.008132927617719414\n",
      "176 Train Loss 0.0026536419 Test MSE 0.00012311812649973874 Test RE 0.008016722966813028\n",
      "177 Train Loss 0.0026278945 Test MSE 0.00012064857651268697 Test RE 0.007935914460268938\n",
      "178 Train Loss 0.002595824 Test MSE 0.00010887433837998457 Test RE 0.007538737846233897\n",
      "179 Train Loss 0.002567169 Test MSE 0.00011183608042211355 Test RE 0.007640589120798528\n",
      "180 Train Loss 0.0025458736 Test MSE 0.00011270363033944414 Test RE 0.007670167173795606\n",
      "181 Train Loss 0.0025234944 Test MSE 0.00010864508912030158 Test RE 0.007530796761036326\n",
      "182 Train Loss 0.0025011823 Test MSE 0.00010599465233460108 Test RE 0.0074383713183247685\n",
      "183 Train Loss 0.0024848168 Test MSE 0.00010236135752092628 Test RE 0.007309773082271616\n",
      "184 Train Loss 0.0024621207 Test MSE 9.995273813133711e-05 Test RE 0.007223259622349072\n",
      "185 Train Loss 0.002446837 Test MSE 9.358634036396239e-05 Test RE 0.006989435625724817\n",
      "186 Train Loss 0.0024205649 Test MSE 8.422606609566452e-05 Test RE 0.006630696277618027\n",
      "187 Train Loss 0.0023970224 Test MSE 7.993824400841993e-05 Test RE 0.006459712342684838\n",
      "188 Train Loss 0.0023777406 Test MSE 7.169959066684358e-05 Test RE 0.006117785066515183\n",
      "189 Train Loss 0.0023500805 Test MSE 6.846342268771572e-05 Test RE 0.005978127597314213\n",
      "190 Train Loss 0.0023316224 Test MSE 5.9088683736240254e-05 Test RE 0.005553771848327177\n",
      "191 Train Loss 0.0023172866 Test MSE 5.771745774093245e-05 Test RE 0.005488952515028911\n",
      "192 Train Loss 0.0022898996 Test MSE 5.325400339051884e-05 Test RE 0.005272444388615449\n",
      "193 Train Loss 0.0022764055 Test MSE 5.2477182289870826e-05 Test RE 0.005233848302028271\n",
      "194 Train Loss 0.0022628645 Test MSE 5.276041893686143e-05 Test RE 0.005247953696840953\n",
      "195 Train Loss 0.0022477175 Test MSE 5.232961184270282e-05 Test RE 0.005226484100556275\n",
      "196 Train Loss 0.002237406 Test MSE 5.1556382092106075e-05 Test RE 0.0051877267623782145\n",
      "197 Train Loss 0.0022196278 Test MSE 4.387177249710076e-05 Test RE 0.004785512637073157\n",
      "198 Train Loss 0.0021913825 Test MSE 3.23036224305016e-05 Test RE 0.004106402254219113\n",
      "199 Train Loss 0.0021615967 Test MSE 2.9424934920355836e-05 Test RE 0.003919165761407436\n",
      "200 Train Loss 0.0021316237 Test MSE 2.584441158142073e-05 Test RE 0.003672985393323036\n",
      "201 Train Loss 0.0021080119 Test MSE 2.6496590233842967e-05 Test RE 0.003719040190237723\n",
      "202 Train Loss 0.0020810962 Test MSE 2.7004165613949866e-05 Test RE 0.0037544926485611483\n",
      "203 Train Loss 0.002058829 Test MSE 3.203489008783008e-05 Test RE 0.004089286097422568\n",
      "204 Train Loss 0.0020412714 Test MSE 3.4115126425981616e-05 Test RE 0.004219970057059843\n",
      "205 Train Loss 0.00202811 Test MSE 4.099546518840144e-05 Test RE 0.0046259803782822935\n",
      "206 Train Loss 0.0020099794 Test MSE 4.5953041924164924e-05 Test RE 0.004897709359431258\n",
      "207 Train Loss 0.0019971048 Test MSE 4.8348435014137476e-05 Test RE 0.005023739221299285\n",
      "208 Train Loss 0.0019708495 Test MSE 4.8351319482380084e-05 Test RE 0.005023889077236863\n",
      "209 Train Loss 0.0019506658 Test MSE 4.9194201559003514e-05 Test RE 0.005067489237438232\n",
      "210 Train Loss 0.0019273246 Test MSE 4.635867937559439e-05 Test RE 0.004919278435800865\n",
      "211 Train Loss 0.0018992705 Test MSE 5.3295972489287704e-05 Test RE 0.0052745215672794\n",
      "212 Train Loss 0.0018835762 Test MSE 5.7479576529158117e-05 Test RE 0.005477629538593251\n",
      "213 Train Loss 0.0018709155 Test MSE 5.705840316161041e-05 Test RE 0.005457524368339944\n",
      "214 Train Loss 0.0018546359 Test MSE 5.8290121576827286e-05 Test RE 0.005516115580325768\n",
      "215 Train Loss 0.0018372658 Test MSE 5.9490903250867135e-05 Test RE 0.0055726421861265136\n",
      "216 Train Loss 0.0018209857 Test MSE 5.5130058414388644e-05 Test RE 0.005364510543743278\n",
      "217 Train Loss 0.0017979709 Test MSE 5.387411955008161e-05 Test RE 0.005303053026192245\n",
      "218 Train Loss 0.0017757867 Test MSE 5.2748252019925244e-05 Test RE 0.005247348554770721\n",
      "219 Train Loss 0.0017584492 Test MSE 5.538585452754495e-05 Test RE 0.005376941447473652\n",
      "220 Train Loss 0.001739952 Test MSE 5.2762143965898895e-05 Test RE 0.00524803948841256\n",
      "221 Train Loss 0.001727382 Test MSE 5.6219356296718784e-05 Test RE 0.0054172491641184106\n",
      "222 Train Loss 0.0017067813 Test MSE 4.570281678075191e-05 Test RE 0.004884356566469589\n",
      "223 Train Loss 0.0016807264 Test MSE 4.386902252080776e-05 Test RE 0.004785362651652188\n",
      "224 Train Loss 0.0016493311 Test MSE 4.7973905337351625e-05 Test RE 0.005004243270393315\n",
      "225 Train Loss 0.0016312972 Test MSE 5.370562255062688e-05 Test RE 0.005294753602536735\n",
      "226 Train Loss 0.0016109003 Test MSE 5.064847707258563e-05 Test RE 0.005141846086375597\n",
      "227 Train Loss 0.001589816 Test MSE 4.679802319763688e-05 Test RE 0.004942533607831498\n",
      "228 Train Loss 0.0015713109 Test MSE 4.809668306619058e-05 Test RE 0.005010642759997237\n",
      "229 Train Loss 0.0015596249 Test MSE 4.7092609328289176e-05 Test RE 0.004958065435996209\n",
      "230 Train Loss 0.00154835 Test MSE 4.342339726640385e-05 Test RE 0.004760995552936711\n",
      "231 Train Loss 0.0015322786 Test MSE 4.421559613770131e-05 Test RE 0.0048042281020866575\n",
      "232 Train Loss 0.0015188967 Test MSE 4.709793141871196e-05 Test RE 0.004958345591709206\n",
      "233 Train Loss 0.0015071171 Test MSE 5.012989416564473e-05 Test RE 0.0051154550255987875\n",
      "234 Train Loss 0.0014971275 Test MSE 4.8108687299713616e-05 Test RE 0.005011268012814593\n",
      "235 Train Loss 0.001487138 Test MSE 4.259289389376882e-05 Test RE 0.004715247039763937\n",
      "236 Train Loss 0.0014692649 Test MSE 3.488249212155269e-05 Test RE 0.0042671668972767765\n",
      "237 Train Loss 0.0014573596 Test MSE 3.09416750162084e-05 Test RE 0.00401890543253576\n",
      "238 Train Loss 0.0014498429 Test MSE 3.097370176049369e-05 Test RE 0.004020984815232564\n",
      "239 Train Loss 0.0014402969 Test MSE 2.849781784761926e-05 Test RE 0.0038569293174243275\n",
      "240 Train Loss 0.0014334457 Test MSE 3.054808257357369e-05 Test RE 0.003993262454295953\n",
      "241 Train Loss 0.0014248207 Test MSE 2.9249342813222756e-05 Test RE 0.003907454532234837\n",
      "242 Train Loss 0.0014154302 Test MSE 2.8905229857048487e-05 Test RE 0.003884401297629514\n",
      "243 Train Loss 0.0014064567 Test MSE 2.9066743222037434e-05 Test RE 0.0038952385883751226\n",
      "244 Train Loss 0.0013988445 Test MSE 3.131993185292317e-05 Test RE 0.00404339603713211\n",
      "245 Train Loss 0.0013920807 Test MSE 3.067578969134866e-05 Test RE 0.004001600721756364\n",
      "246 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "247 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "248 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "249 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "250 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "251 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "252 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "253 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "254 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "255 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "256 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "257 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "258 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "259 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "260 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "261 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "262 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "263 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "264 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "265 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "266 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "267 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "268 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "269 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "270 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "271 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "272 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "273 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "274 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "275 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "276 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "277 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "278 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "279 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "280 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "281 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "282 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "283 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "284 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "285 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "286 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "287 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "288 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "289 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "290 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "291 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "292 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "293 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "294 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "295 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "296 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "297 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "298 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "299 Train Loss 0.0013908934 Test MSE 3.01077560051992e-05 Test RE 0.00396437812250781\n",
      "Training time: 163.12\n",
      "KG_stan_high\n",
      "6\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "6\n",
      "0 Train Loss 18866.021 Test MSE 12.398334052547876 Test RE 2.5440025579549297\n",
      "1 Train Loss 7208.5283 Test MSE 16.148206976485692 Test RE 2.9033408891609627\n",
      "2 Train Loss 2548.6567 Test MSE 18.294369717339173 Test RE 3.0902570274825374\n",
      "3 Train Loss 1159.9109 Test MSE 15.40277411783703 Test RE 2.835537205854983\n",
      "4 Train Loss 371.2787 Test MSE 11.07759775096745 Test RE 2.4046876470517002\n",
      "5 Train Loss 141.21088 Test MSE 11.846607992104532 Test RE 2.4867543469096276\n",
      "6 Train Loss 69.44968 Test MSE 11.317217505863264 Test RE 2.430556428511597\n",
      "7 Train Loss 40.36873 Test MSE 10.841363530002663 Test RE 2.378909006538245\n",
      "8 Train Loss 27.405333 Test MSE 10.40399179413069 Test RE 2.3304290072272416\n",
      "9 Train Loss 22.266314 Test MSE 10.146025111273778 Test RE 2.301356200472229\n",
      "10 Train Loss 19.18783 Test MSE 10.133076064718232 Test RE 2.299887158032454\n",
      "11 Train Loss 17.184471 Test MSE 10.070157827322097 Test RE 2.292735816698378\n",
      "12 Train Loss 15.463783 Test MSE 9.846628403588827 Test RE 2.267146847897673\n",
      "13 Train Loss 14.136668 Test MSE 9.710595816369958 Test RE 2.2514319032329073\n",
      "14 Train Loss 13.502602 Test MSE 9.600281617868035 Test RE 2.238607030595678\n",
      "15 Train Loss 12.932554 Test MSE 9.523686199343178 Test RE 2.229658833501245\n",
      "16 Train Loss 12.338644 Test MSE 9.420610993681867 Test RE 2.217560168629785\n",
      "17 Train Loss 11.820379 Test MSE 9.356349671657304 Test RE 2.2099838449154157\n",
      "18 Train Loss 11.457611 Test MSE 9.310941944612818 Test RE 2.204614635940866\n",
      "19 Train Loss 11.207738 Test MSE 9.276700018427514 Test RE 2.200557055851358\n",
      "20 Train Loss 10.871826 Test MSE 9.231090827290515 Test RE 2.1951408359637377\n",
      "21 Train Loss 10.50872 Test MSE 9.149778707953859 Test RE 2.185451495956509\n",
      "22 Train Loss 10.288723 Test MSE 9.065177364112365 Test RE 2.175324392476905\n",
      "23 Train Loss 10.147269 Test MSE 9.069720938861241 Test RE 2.1758694734185373\n",
      "24 Train Loss 10.003917 Test MSE 9.107962638595929 Test RE 2.1804518316413484\n",
      "25 Train Loss 9.808314 Test MSE 9.031005255612111 Test RE 2.1712204679613034\n",
      "26 Train Loss 9.597786 Test MSE 8.937979054428263 Test RE 2.160008912857091\n",
      "27 Train Loss 9.336945 Test MSE 8.831209066206725 Test RE 2.147068794718555\n",
      "28 Train Loss 9.103989 Test MSE 8.724944082872504 Test RE 2.134111976489682\n",
      "29 Train Loss 8.915882 Test MSE 8.635455239317087 Test RE 2.123139330643355\n",
      "30 Train Loss 8.669875 Test MSE 8.515346627718497 Test RE 2.1083224946627457\n",
      "31 Train Loss 8.497023 Test MSE 8.335866446903173 Test RE 2.0859853348688233\n",
      "32 Train Loss 8.197324 Test MSE 8.080068928119626 Test RE 2.0537302958083385\n",
      "33 Train Loss 7.9787045 Test MSE 8.007186291681563 Test RE 2.044446937958963\n",
      "34 Train Loss 7.7053447 Test MSE 7.723568248613301 Test RE 2.00791290579583\n",
      "35 Train Loss 7.3957653 Test MSE 7.424786400209801 Test RE 1.968692373940407\n",
      "36 Train Loss 7.1004634 Test MSE 7.139272729903209 Test RE 1.9304691393737754\n",
      "37 Train Loss 6.887988 Test MSE 7.04368622624995 Test RE 1.917502229324479\n",
      "38 Train Loss 6.5558925 Test MSE 6.679570763567924 Test RE 1.8672830477833675\n",
      "39 Train Loss 6.3204365 Test MSE 6.405447642574898 Test RE 1.8285659132961538\n",
      "40 Train Loss 6.097093 Test MSE 6.134242860151193 Test RE 1.7894367815373133\n",
      "41 Train Loss 5.718363 Test MSE 5.745912018804212 Test RE 1.7318702931008731\n",
      "42 Train Loss 5.351535 Test MSE 4.983504658259523 Test RE 1.612884659152757\n",
      "43 Train Loss 4.752556 Test MSE 3.968638118881929 Test RE 1.4393175690032964\n",
      "44 Train Loss 4.302144 Test MSE 3.424268415682977 Test RE 1.3369641958464173\n",
      "45 Train Loss 3.703476 Test MSE 2.9406050288593533 Test RE 1.2389512685823265\n",
      "46 Train Loss 3.3022666 Test MSE 2.582184179675694 Test RE 1.1609926889536746\n",
      "47 Train Loss 2.7498705 Test MSE 2.1757102787164913 Test RE 1.0657035405857536\n",
      "48 Train Loss 2.4251726 Test MSE 1.7620707800507611 Test RE 0.9590639166680652\n",
      "49 Train Loss 2.1174786 Test MSE 1.5757625122332792 Test RE 0.9069456435537814\n",
      "50 Train Loss 1.9452504 Test MSE 1.5695114575453772 Test RE 0.90514492785209\n",
      "51 Train Loss 1.8084109 Test MSE 1.3779198284093526 Test RE 0.8481015398946403\n",
      "52 Train Loss 1.5601094 Test MSE 1.2127141676608069 Test RE 0.7956372406401359\n",
      "53 Train Loss 1.3564042 Test MSE 1.0277926500474817 Test RE 0.7324679573137172\n",
      "54 Train Loss 1.1805022 Test MSE 0.8441612287234072 Test RE 0.6638173171074312\n",
      "55 Train Loss 1.0398545 Test MSE 0.7080561426617362 Test RE 0.6079526058414181\n",
      "56 Train Loss 0.8841714 Test MSE 0.5927556356686953 Test RE 0.5562547374702708\n",
      "57 Train Loss 0.78237075 Test MSE 0.4727417567592056 Test RE 0.4967614193357585\n",
      "58 Train Loss 0.71225977 Test MSE 0.4467092202336823 Test RE 0.4828901371298313\n",
      "59 Train Loss 0.644976 Test MSE 0.40000455472987373 Test RE 0.4569496459449927\n",
      "60 Train Loss 0.58787274 Test MSE 0.34435660374513066 Test RE 0.42397483988440304\n",
      "61 Train Loss 0.54299206 Test MSE 0.3294282762959649 Test RE 0.414683078366527\n",
      "62 Train Loss 0.47545004 Test MSE 0.27029914596492916 Test RE 0.3756282211934797\n",
      "63 Train Loss 0.43667117 Test MSE 0.2593580095151292 Test RE 0.367947375152287\n",
      "64 Train Loss 0.39850336 Test MSE 0.2574761291704901 Test RE 0.366610046933207\n",
      "65 Train Loss 0.37195978 Test MSE 0.2396838307190561 Test RE 0.3537164400647378\n",
      "66 Train Loss 0.35026732 Test MSE 0.21636732321144903 Test RE 0.3360715221488529\n",
      "67 Train Loss 0.32676572 Test MSE 0.20166683812640215 Test RE 0.3244539916299155\n",
      "68 Train Loss 0.30110022 Test MSE 0.18407757085906146 Test RE 0.30998188451523856\n",
      "69 Train Loss 0.29033822 Test MSE 0.17277498177984468 Test RE 0.30031450220750433\n",
      "70 Train Loss 0.27839977 Test MSE 0.17032588358449213 Test RE 0.29817841520846755\n",
      "71 Train Loss 0.26586488 Test MSE 0.14956139498590096 Test RE 0.27941237093367666\n",
      "72 Train Loss 0.25282216 Test MSE 0.11589488755640454 Test RE 0.24596200019293335\n",
      "73 Train Loss 0.23697829 Test MSE 0.1062664998025901 Test RE 0.23552340150451678\n",
      "74 Train Loss 0.21753916 Test MSE 0.08871543614481751 Test RE 0.2151966334330546\n",
      "75 Train Loss 0.20719822 Test MSE 0.08051441403761884 Test RE 0.20500889046985543\n",
      "76 Train Loss 0.20166275 Test MSE 0.07684124013825269 Test RE 0.20027791409444745\n",
      "77 Train Loss 0.19332069 Test MSE 0.06829279273145443 Test RE 0.18880927010101792\n",
      "78 Train Loss 0.1873444 Test MSE 0.05901510924206416 Test RE 0.17551631191060518\n",
      "79 Train Loss 0.18368395 Test MSE 0.05678513772834122 Test RE 0.1721683108589819\n",
      "80 Train Loss 0.18010579 Test MSE 0.0571403467071801 Test RE 0.17270595497840907\n",
      "81 Train Loss 0.16914673 Test MSE 0.052553862882248434 Test RE 0.16562969369393177\n",
      "82 Train Loss 0.1613678 Test MSE 0.0484568074744021 Test RE 0.1590425300062982\n",
      "83 Train Loss 0.15260348 Test MSE 0.03823462371943417 Test RE 0.14127466532555755\n",
      "84 Train Loss 0.14012522 Test MSE 0.029220210029634045 Test RE 0.12350301034651555\n",
      "85 Train Loss 0.13469404 Test MSE 0.02924123153564514 Test RE 0.1235474274211839\n",
      "86 Train Loss 0.12827317 Test MSE 0.02998305458077643 Test RE 0.12510475437486696\n",
      "87 Train Loss 0.12084325 Test MSE 0.03008014588568695 Test RE 0.12530714813738497\n",
      "88 Train Loss 0.1139823 Test MSE 0.02902502978082768 Test RE 0.12308984190965488\n",
      "89 Train Loss 0.10856758 Test MSE 0.027036979196695565 Test RE 0.11879959506506896\n",
      "90 Train Loss 0.1043521 Test MSE 0.024922325412448237 Test RE 0.11405915716465546\n",
      "91 Train Loss 0.098610565 Test MSE 0.019562895860505466 Test RE 0.10105375326883866\n",
      "92 Train Loss 0.093781754 Test MSE 0.01413309199281632 Test RE 0.08589234696821291\n",
      "93 Train Loss 0.0878779 Test MSE 0.008776675737886165 Test RE 0.06768632010891378\n",
      "94 Train Loss 0.083608754 Test MSE 0.00633215520717418 Test RE 0.05749256071704217\n",
      "95 Train Loss 0.07856741 Test MSE 0.005759788268585238 Test RE 0.05483263750151293\n",
      "96 Train Loss 0.073214605 Test MSE 0.0052152388015667545 Test RE 0.05217626371178732\n",
      "97 Train Loss 0.07080859 Test MSE 0.0051895331058600044 Test RE 0.052047517549999735\n",
      "98 Train Loss 0.068087995 Test MSE 0.005128023469436195 Test RE 0.051738148018959165\n",
      "99 Train Loss 0.06503591 Test MSE 0.004215800885868874 Test RE 0.04691113301114329\n",
      "100 Train Loss 0.0634751 Test MSE 0.004227234909216159 Test RE 0.046974705723039745\n",
      "101 Train Loss 0.06142605 Test MSE 0.003908625899914559 Test RE 0.04516977524760567\n",
      "102 Train Loss 0.05958543 Test MSE 0.003736712025453037 Test RE 0.04416524985775363\n",
      "103 Train Loss 0.05614939 Test MSE 0.004181508017888743 Test RE 0.04671994725754959\n",
      "104 Train Loss 0.05419456 Test MSE 0.003953654963873835 Test RE 0.04542921785593391\n",
      "105 Train Loss 0.052614365 Test MSE 0.003915636383682023 Test RE 0.045210265194812464\n",
      "106 Train Loss 0.05029634 Test MSE 0.0035971013706869123 Test RE 0.043332347309158435\n",
      "107 Train Loss 0.04712435 Test MSE 0.0032939846298513224 Test RE 0.041466431350004516\n",
      "108 Train Loss 0.045450438 Test MSE 0.003140995506486027 Test RE 0.040492028555094935\n",
      "109 Train Loss 0.04419123 Test MSE 0.002998231743078372 Test RE 0.039561110669180374\n",
      "110 Train Loss 0.042601228 Test MSE 0.0031260105625564865 Test RE 0.04039532415078861\n",
      "111 Train Loss 0.041049514 Test MSE 0.003175642414681002 Test RE 0.040714740754080596\n",
      "112 Train Loss 0.039860897 Test MSE 0.0031209402721477505 Test RE 0.040362550886079214\n",
      "113 Train Loss 0.038907226 Test MSE 0.003131059176580481 Test RE 0.04042793090621648\n",
      "114 Train Loss 0.038276598 Test MSE 0.0029236343822761175 Test RE 0.039065861604371616\n",
      "115 Train Loss 0.037229665 Test MSE 0.0027131222723973687 Test RE 0.03763314901858161\n",
      "116 Train Loss 0.03644 Test MSE 0.0026629351205021703 Test RE 0.03728345660363238\n",
      "117 Train Loss 0.035215907 Test MSE 0.0025557668487030754 Test RE 0.03652552720113424\n",
      "118 Train Loss 0.03375616 Test MSE 0.002521841955097457 Test RE 0.0362822999802457\n",
      "119 Train Loss 0.032889284 Test MSE 0.002584567610509618 Test RE 0.03673075248728786\n",
      "120 Train Loss 0.031689428 Test MSE 0.0024381594477946955 Test RE 0.035675242076790355\n",
      "121 Train Loss 0.030309325 Test MSE 0.0023657514761696425 Test RE 0.03514151145287241\n",
      "122 Train Loss 0.029796027 Test MSE 0.0024670447857743695 Test RE 0.035885945537058435\n",
      "123 Train Loss 0.029252436 Test MSE 0.0024862496194816568 Test RE 0.03602535272771328\n",
      "124 Train Loss 0.028775616 Test MSE 0.0024419437088896044 Test RE 0.03570291706875407\n",
      "125 Train Loss 0.02832413 Test MSE 0.0025568655381401706 Test RE 0.03653337727145838\n",
      "126 Train Loss 0.027884841 Test MSE 0.002625599704184613 Test RE 0.037021169523229876\n",
      "127 Train Loss 0.027227085 Test MSE 0.0024682171265605845 Test RE 0.03589447103303802\n",
      "128 Train Loss 0.026699642 Test MSE 0.0023462373011903077 Test RE 0.03499627692363662\n",
      "129 Train Loss 0.026375404 Test MSE 0.002233010241946371 Test RE 0.0341413928152738\n",
      "130 Train Loss 0.0258359 Test MSE 0.0021959973023271927 Test RE 0.033857257615479946\n",
      "131 Train Loss 0.025429206 Test MSE 0.0021996878744674404 Test RE 0.033885695764533576\n",
      "132 Train Loss 0.025064608 Test MSE 0.0019453934648813373 Test RE 0.03186688427412626\n",
      "133 Train Loss 0.024606716 Test MSE 0.0019404394099732673 Test RE 0.03182628299425961\n",
      "134 Train Loss 0.024240728 Test MSE 0.0018376121375445905 Test RE 0.030971540136617386\n",
      "135 Train Loss 0.023813529 Test MSE 0.0019164276300015469 Test RE 0.031628754385630585\n",
      "136 Train Loss 0.023389725 Test MSE 0.0020481783812561485 Test RE 0.03269789280998636\n",
      "137 Train Loss 0.02288131 Test MSE 0.001990011809528329 Test RE 0.0322302521914547\n",
      "138 Train Loss 0.022627132 Test MSE 0.0019662220789272516 Test RE 0.03203702360060807\n",
      "139 Train Loss 0.022267465 Test MSE 0.0020439013584587556 Test RE 0.0326637349652962\n",
      "140 Train Loss 0.021874148 Test MSE 0.0020800611262991684 Test RE 0.032951404143948225\n",
      "141 Train Loss 0.021405714 Test MSE 0.001989545333374432 Test RE 0.03222647444371076\n",
      "142 Train Loss 0.021110227 Test MSE 0.0020861245512800827 Test RE 0.03299939623710559\n",
      "143 Train Loss 0.020811664 Test MSE 0.0019657621734812253 Test RE 0.03203327660186636\n",
      "144 Train Loss 0.020554317 Test MSE 0.0020507013934880974 Test RE 0.03271802577160625\n",
      "145 Train Loss 0.020173963 Test MSE 0.001965261702053977 Test RE 0.032029198600874394\n",
      "146 Train Loss 0.019668052 Test MSE 0.0018985616451967053 Test RE 0.03148097890884258\n",
      "147 Train Loss 0.019326242 Test MSE 0.001713017779915293 Test RE 0.029903141247007856\n",
      "148 Train Loss 0.019060703 Test MSE 0.0015762975318669072 Test RE 0.028685007955625116\n",
      "149 Train Loss 0.018799098 Test MSE 0.001506726227425496 Test RE 0.0280448454426746\n",
      "150 Train Loss 0.018355202 Test MSE 0.0014115637677632703 Test RE 0.027144767615401487\n",
      "151 Train Loss 0.018088145 Test MSE 0.0013031668855374814 Test RE 0.02608169997163145\n",
      "152 Train Loss 0.017761031 Test MSE 0.0012932405414483516 Test RE 0.025982176715444224\n",
      "153 Train Loss 0.017408276 Test MSE 0.00129255095328421 Test RE 0.02597524861890978\n",
      "154 Train Loss 0.016978798 Test MSE 0.0012813649884111879 Test RE 0.025862607183608957\n",
      "155 Train Loss 0.016479978 Test MSE 0.0013534808170320674 Test RE 0.026580425528789225\n",
      "156 Train Loss 0.016124565 Test MSE 0.0013734583002451032 Test RE 0.026775871555610172\n",
      "157 Train Loss 0.01578623 Test MSE 0.0014076810377405104 Test RE 0.027107408913155766\n",
      "158 Train Loss 0.015485741 Test MSE 0.001353509315959606 Test RE 0.02658070536638428\n",
      "159 Train Loss 0.015164134 Test MSE 0.0013792256901086074 Test RE 0.026832030928386364\n",
      "160 Train Loss 0.014915034 Test MSE 0.0013956524641297729 Test RE 0.026991344621501767\n",
      "161 Train Loss 0.014601362 Test MSE 0.0014147052542326896 Test RE 0.027174956661493423\n",
      "162 Train Loss 0.014275735 Test MSE 0.0013643880245614469 Test RE 0.026687311592207295\n",
      "163 Train Loss 0.014087797 Test MSE 0.0013245247460204434 Test RE 0.0262945604392118\n",
      "164 Train Loss 0.013863923 Test MSE 0.001262009020952735 Test RE 0.02566652696063312\n",
      "165 Train Loss 0.013712152 Test MSE 0.0012736447145149609 Test RE 0.025784577866494133\n",
      "166 Train Loss 0.013546869 Test MSE 0.0012628472952331588 Test RE 0.025675049886135292\n",
      "167 Train Loss 0.01345286 Test MSE 0.0012884380632288924 Test RE 0.02593388914185544\n",
      "168 Train Loss 0.013367133 Test MSE 0.0013214014619585164 Test RE 0.026263540311914205\n",
      "169 Train Loss 0.0132564 Test MSE 0.0012727579501617414 Test RE 0.025775600156500156\n",
      "170 Train Loss 0.013145791 Test MSE 0.0013252483834705511 Test RE 0.026301742309744854\n",
      "171 Train Loss 0.012920785 Test MSE 0.001400033400424333 Test RE 0.027033674182557203\n",
      "172 Train Loss 0.012635485 Test MSE 0.0015405053793178746 Test RE 0.028357470338066973\n",
      "173 Train Loss 0.012407613 Test MSE 0.0016258383296289475 Test RE 0.02913228539481379\n",
      "174 Train Loss 0.012228542 Test MSE 0.0016230538435181372 Test RE 0.02910732805306744\n",
      "175 Train Loss 0.012020089 Test MSE 0.0016462119684248434 Test RE 0.02931424777144608\n",
      "176 Train Loss 0.011855601 Test MSE 0.0016456459320695622 Test RE 0.02930920760746194\n",
      "177 Train Loss 0.011778793 Test MSE 0.0016279433363972679 Test RE 0.029151138382961586\n",
      "178 Train Loss 0.011680391 Test MSE 0.0016249610294771116 Test RE 0.0291244244634414\n",
      "179 Train Loss 0.011516644 Test MSE 0.0016494184180353636 Test RE 0.02934278265473379\n",
      "180 Train Loss 0.011350797 Test MSE 0.0016868650347811602 Test RE 0.02967399676755525\n",
      "181 Train Loss 0.011225244 Test MSE 0.0017186255252693578 Test RE 0.0299520468072537\n",
      "182 Train Loss 0.011134559 Test MSE 0.0017540960696077158 Test RE 0.030259556926934203\n",
      "183 Train Loss 0.010981375 Test MSE 0.0017842399507063834 Test RE 0.030518452396307558\n",
      "184 Train Loss 0.010871386 Test MSE 0.001788926693157963 Test RE 0.030558508197740718\n",
      "185 Train Loss 0.010763361 Test MSE 0.0018024841332524202 Test RE 0.030674083969741067\n",
      "186 Train Loss 0.0106650675 Test MSE 0.0017394091141616154 Test RE 0.030132609787261712\n",
      "187 Train Loss 0.010562702 Test MSE 0.00179316213157159 Test RE 0.030594661764608354\n",
      "188 Train Loss 0.010473006 Test MSE 0.0017860857725686462 Test RE 0.03053423420445927\n",
      "189 Train Loss 0.010385808 Test MSE 0.0017910262085349814 Test RE 0.030576434936966847\n",
      "190 Train Loss 0.010297487 Test MSE 0.001770614959952756 Test RE 0.030401705067458148\n",
      "191 Train Loss 0.010206275 Test MSE 0.001709774556548353 Test RE 0.029874820316868042\n",
      "192 Train Loss 0.010090282 Test MSE 0.0016910856634766254 Test RE 0.029711096558106637\n",
      "193 Train Loss 0.009986537 Test MSE 0.0017770728644327758 Test RE 0.030457096165852512\n",
      "194 Train Loss 0.00991148 Test MSE 0.0017467156887931042 Test RE 0.03019583109526216\n",
      "195 Train Loss 0.009813013 Test MSE 0.0017445423409665683 Test RE 0.030177039694124646\n",
      "196 Train Loss 0.009643901 Test MSE 0.001789197629120839 Test RE 0.030560822178916074\n",
      "197 Train Loss 0.009570721 Test MSE 0.0017920263349326469 Test RE 0.0305849708343448\n",
      "198 Train Loss 0.009481573 Test MSE 0.001770402983722692 Test RE 0.03039988518231501\n",
      "199 Train Loss 0.009407242 Test MSE 0.001749083179502688 Test RE 0.03021628781374791\n",
      "200 Train Loss 0.009308235 Test MSE 0.0017250064839660767 Test RE 0.03000759867061395\n",
      "201 Train Loss 0.009180882 Test MSE 0.001735974197828513 Test RE 0.03010284274120144\n",
      "202 Train Loss 0.009083051 Test MSE 0.001689706201692099 Test RE 0.029698976035542925\n",
      "203 Train Loss 0.008990842 Test MSE 0.0016208718284598232 Test RE 0.029087755692869147\n",
      "204 Train Loss 0.008920334 Test MSE 0.0016778676121798493 Test RE 0.029594753184245648\n",
      "205 Train Loss 0.008834804 Test MSE 0.0017065075070148445 Test RE 0.029846264158132612\n",
      "206 Train Loss 0.008748255 Test MSE 0.0017073984868446223 Test RE 0.02985405461587521\n",
      "207 Train Loss 0.008683787 Test MSE 0.001705644094915732 Test RE 0.02983871280372623\n",
      "208 Train Loss 0.008611523 Test MSE 0.0016941431282562554 Test RE 0.029737943101308208\n",
      "209 Train Loss 0.008530891 Test MSE 0.001646752494269381 Test RE 0.029319059973150523\n",
      "210 Train Loss 0.008457945 Test MSE 0.0016355399296523769 Test RE 0.029219074285855406\n",
      "211 Train Loss 0.008414503 Test MSE 0.0016176731069408607 Test RE 0.029059039794980118\n",
      "212 Train Loss 0.008342299 Test MSE 0.0016441213389561595 Test RE 0.02929562784239417\n",
      "213 Train Loss 0.008241942 Test MSE 0.0016411168122537649 Test RE 0.029268847657952898\n",
      "214 Train Loss 0.008147545 Test MSE 0.0016305003267379802 Test RE 0.029174023065469828\n",
      "215 Train Loss 0.0079904515 Test MSE 0.0016500983541007184 Test RE 0.02934882998641115\n",
      "216 Train Loss 0.007823112 Test MSE 0.0016303360904955965 Test RE 0.029172553715078337\n",
      "217 Train Loss 0.0076484396 Test MSE 0.0015473807425622167 Test RE 0.028420680391647957\n",
      "218 Train Loss 0.0074450457 Test MSE 0.0014962638721961962 Test RE 0.027947307397044156\n",
      "219 Train Loss 0.007289799 Test MSE 0.001506900614842175 Test RE 0.02804646834090138\n",
      "220 Train Loss 0.007141406 Test MSE 0.0015062667747813465 Test RE 0.028040569197727183\n",
      "221 Train Loss 0.007017867 Test MSE 0.001510852995137232 Test RE 0.02808322515049059\n",
      "222 Train Loss 0.0069009885 Test MSE 0.0015279053821169184 Test RE 0.028241262480505732\n",
      "223 Train Loss 0.006804231 Test MSE 0.0015133471926664535 Test RE 0.028106396242014657\n",
      "224 Train Loss 0.006704377 Test MSE 0.0015259285612870366 Test RE 0.028222987138991913\n",
      "225 Train Loss 0.0066267517 Test MSE 0.0015144131891157682 Test RE 0.028116293522836188\n",
      "226 Train Loss 0.0065399115 Test MSE 0.0015125479184847901 Test RE 0.028098973066443055\n",
      "227 Train Loss 0.00648515 Test MSE 0.0015222764650188066 Test RE 0.02818919302330567\n",
      "228 Train Loss 0.006434166 Test MSE 0.0015365113230203348 Test RE 0.028320685383345413\n",
      "229 Train Loss 0.0063764066 Test MSE 0.001545544064685828 Test RE 0.028403808288880845\n",
      "230 Train Loss 0.0062491954 Test MSE 0.0015938194899162996 Test RE 0.028843997119995038\n",
      "231 Train Loss 0.0061656474 Test MSE 0.001632130571840841 Test RE 0.02918860414989285\n",
      "232 Train Loss 0.006111492 Test MSE 0.0016911058671506766 Test RE 0.029711274039215557\n",
      "233 Train Loss 0.006041223 Test MSE 0.0016774170613748371 Test RE 0.029590779439528977\n",
      "234 Train Loss 0.0060026837 Test MSE 0.001694267721572145 Test RE 0.02973903659829704\n",
      "235 Train Loss 0.0059540262 Test MSE 0.0017142849836331206 Test RE 0.02991419961630767\n",
      "236 Train Loss 0.005810305 Test MSE 0.001728152314060691 Test RE 0.030034948077454868\n",
      "237 Train Loss 0.005739792 Test MSE 0.0017481964305195597 Test RE 0.030208627326327404\n",
      "238 Train Loss 0.005694875 Test MSE 0.0017400859233797476 Test RE 0.030138471560793342\n",
      "239 Train Loss 0.0056648236 Test MSE 0.0017464689423195674 Test RE 0.03019369824157784\n",
      "240 Train Loss 0.0055964645 Test MSE 0.0017234504384389653 Test RE 0.029994061410088275\n",
      "241 Train Loss 0.005551545 Test MSE 0.0017062638838064087 Test RE 0.0298441336365452\n",
      "242 Train Loss 0.0055132965 Test MSE 0.0017087180302938353 Test RE 0.02986558857065986\n",
      "243 Train Loss 0.00547964 Test MSE 0.0016705975841725365 Test RE 0.02953056806915438\n",
      "244 Train Loss 0.0054234318 Test MSE 0.0016465533611216918 Test RE 0.029317287219433018\n",
      "245 Train Loss 0.0053692083 Test MSE 0.0016408168850693128 Test RE 0.02926617297808623\n",
      "246 Train Loss 0.005307811 Test MSE 0.0016174884145685182 Test RE 0.029057380888686642\n",
      "247 Train Loss 0.005267189 Test MSE 0.0015939419526996746 Test RE 0.028845105228015935\n",
      "248 Train Loss 0.0052307965 Test MSE 0.0015851090067137304 Test RE 0.028765070563642702\n",
      "249 Train Loss 0.00516977 Test MSE 0.0015669183131734842 Test RE 0.02859954047105908\n",
      "250 Train Loss 0.005130198 Test MSE 0.0015636879960081278 Test RE 0.02857004523515888\n",
      "251 Train Loss 0.005077946 Test MSE 0.0015689763982741373 Test RE 0.028618316489136444\n",
      "252 Train Loss 0.005028134 Test MSE 0.0015419052849190507 Test RE 0.028370352074000727\n",
      "253 Train Loss 0.00498593 Test MSE 0.0015219759997279645 Test RE 0.028186410909721217\n",
      "254 Train Loss 0.0049553015 Test MSE 0.001522897490369558 Test RE 0.0281949424449123\n",
      "255 Train Loss 0.0049069566 Test MSE 0.0015244969953278138 Test RE 0.028209745186101833\n",
      "256 Train Loss 0.004861487 Test MSE 0.0015499210039909145 Test RE 0.02844399926538057\n",
      "257 Train Loss 0.0048399824 Test MSE 0.001530643837509615 Test RE 0.02826655947095007\n",
      "258 Train Loss 0.004809855 Test MSE 0.0015163531341024178 Test RE 0.028134296075462632\n",
      "259 Train Loss 0.004773894 Test MSE 0.0015099888205883562 Test RE 0.02807519250939248\n",
      "260 Train Loss 0.0047339667 Test MSE 0.001511203615625174 Test RE 0.028086483569058077\n",
      "261 Train Loss 0.004705517 Test MSE 0.0015075973359693553 Test RE 0.028052951286326552\n",
      "262 Train Loss 0.004634637 Test MSE 0.001481988625582994 Test RE 0.027813670929088395\n",
      "263 Train Loss 0.0045926576 Test MSE 0.0014579901462151133 Test RE 0.027587552414860297\n",
      "264 Train Loss 0.0045689493 Test MSE 0.0014591317649789303 Test RE 0.027598350946273352\n",
      "265 Train Loss 0.0045299 Test MSE 0.0014690904483978494 Test RE 0.027692371199846067\n",
      "266 Train Loss 0.0045089857 Test MSE 0.001471617460098676 Test RE 0.02771617806583301\n",
      "267 Train Loss 0.0044935145 Test MSE 0.0014754721243527263 Test RE 0.027752453353039195\n",
      "268 Train Loss 0.004468671 Test MSE 0.0014518216635714706 Test RE 0.02752913167953337\n",
      "269 Train Loss 0.0044456036 Test MSE 0.0014446419689503475 Test RE 0.027460977397809904\n",
      "270 Train Loss 0.004395404 Test MSE 0.0014094778966772248 Test RE 0.02712470425739919\n",
      "271 Train Loss 0.0043601627 Test MSE 0.0013901786570771368 Test RE 0.026938362031978937\n",
      "272 Train Loss 0.0043168683 Test MSE 0.0013820653988454736 Test RE 0.026859639163095576\n",
      "273 Train Loss 0.0042839013 Test MSE 0.0013760519233424117 Test RE 0.0268011412577625\n",
      "274 Train Loss 0.00425091 Test MSE 0.0013892269144076665 Test RE 0.026929139196447915\n",
      "275 Train Loss 0.0042170356 Test MSE 0.0014023953938424214 Test RE 0.027056468799972477\n",
      "276 Train Loss 0.0041922545 Test MSE 0.0014027476326041873 Test RE 0.027059866464694087\n",
      "277 Train Loss 0.0041755806 Test MSE 0.0014171166196065945 Test RE 0.02719810666028852\n",
      "278 Train Loss 0.004154953 Test MSE 0.001401485484728593 Test RE 0.027047689919816133\n",
      "279 Train Loss 0.0041390494 Test MSE 0.0013885841748436044 Test RE 0.02692290895952632\n",
      "280 Train Loss 0.0041215285 Test MSE 0.001377126821763618 Test RE 0.026811607025883276\n",
      "281 Train Loss 0.004094713 Test MSE 0.0013571964790281884 Test RE 0.026616885663795272\n",
      "282 Train Loss 0.0040582 Test MSE 0.0013330018535908908 Test RE 0.026378570309770002\n",
      "283 Train Loss 0.0040192897 Test MSE 0.0012874894650302833 Test RE 0.02592434061526478\n",
      "284 Train Loss 0.0039871274 Test MSE 0.0012723028879688166 Test RE 0.02577099183731451\n",
      "285 Train Loss 0.003962968 Test MSE 0.0012758886677831363 Test RE 0.025807281971040825\n",
      "286 Train Loss 0.0039155525 Test MSE 0.0012913421140021348 Test RE 0.025963099292873004\n",
      "287 Train Loss 0.003879813 Test MSE 0.0013089098794050685 Test RE 0.02613910719292079\n",
      "288 Train Loss 0.0038592722 Test MSE 0.0013088794878102317 Test RE 0.02613880372903106\n",
      "289 Train Loss 0.0038270906 Test MSE 0.0012945508360533654 Test RE 0.025995335785987932\n",
      "290 Train Loss 0.0038006164 Test MSE 0.0012882395056641994 Test RE 0.02593189076551823\n",
      "291 Train Loss 0.0037807361 Test MSE 0.0012690907816916234 Test RE 0.025738440045449708\n",
      "292 Train Loss 0.003761921 Test MSE 0.001258727042276494 Test RE 0.02563313106933751\n",
      "293 Train Loss 0.003744807 Test MSE 0.0012546142006913646 Test RE 0.025591219176256935\n",
      "294 Train Loss 0.003717643 Test MSE 0.0012372669588772516 Test RE 0.025413681603040042\n",
      "295 Train Loss 0.0036937767 Test MSE 0.001211765036882753 Test RE 0.025150410950924792\n",
      "296 Train Loss 0.0036599538 Test MSE 0.001191912299736334 Test RE 0.024943536484702582\n",
      "297 Train Loss 0.0036258793 Test MSE 0.0011769918346791397 Test RE 0.024786922099620443\n",
      "298 Train Loss 0.0035916327 Test MSE 0.0011637975988852405 Test RE 0.024647598184249917\n",
      "299 Train Loss 0.00352199 Test MSE 0.0011498186998078602 Test RE 0.02449912426839377\n",
      "Training time: 172.85\n",
      "KG_stan_high\n",
      "7\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "7\n",
      "0 Train Loss 41453.453 Test MSE 5.800532855023997 Test RE 1.7400824321704118\n",
      "1 Train Loss 9692.849 Test MSE 5.141118113760496 Test RE 1.6381914981024914\n",
      "2 Train Loss 1024.5201 Test MSE 3.8485070767604377 Test RE 1.4173660359452351\n",
      "3 Train Loss 228.03925 Test MSE 2.176451333787987 Test RE 1.0658850164433415\n",
      "4 Train Loss 100.32941 Test MSE 1.8137702235025221 Test RE 0.9730317484340384\n",
      "5 Train Loss 51.862587 Test MSE 1.7210165254928012 Test RE 0.9478255185714004\n",
      "6 Train Loss 30.961811 Test MSE 1.379092199047011 Test RE 0.8484622567958109\n",
      "7 Train Loss 19.379742 Test MSE 1.0610481660164437 Test RE 0.7442235805340509\n",
      "8 Train Loss 12.978024 Test MSE 0.9512686811093362 Test RE 0.7046727479197298\n",
      "9 Train Loss 8.238468 Test MSE 0.6791810304140831 Test RE 0.595427173502963\n",
      "10 Train Loss 5.9040594 Test MSE 0.4993620548273418 Test RE 0.5105563077198852\n",
      "11 Train Loss 4.2205267 Test MSE 0.33564859761455396 Test RE 0.41857982818498474\n",
      "12 Train Loss 3.2318754 Test MSE 0.24366006285184708 Test RE 0.35663835901819363\n",
      "13 Train Loss 2.4820778 Test MSE 0.20113454962622782 Test RE 0.324025519500024\n",
      "14 Train Loss 1.8515097 Test MSE 0.19349209346143273 Test RE 0.31780994899419795\n",
      "15 Train Loss 1.4048064 Test MSE 0.17155220943134253 Test RE 0.2992499143390475\n",
      "16 Train Loss 1.1119031 Test MSE 0.15255598197469408 Test RE 0.2821957688218257\n",
      "17 Train Loss 0.8721595 Test MSE 0.13744065621559484 Test RE 0.26785113247951686\n",
      "18 Train Loss 0.7006381 Test MSE 0.11755673225428334 Test RE 0.2477191776378874\n",
      "19 Train Loss 0.5733527 Test MSE 0.11066403262506586 Test RE 0.24034723089889876\n",
      "20 Train Loss 0.49074915 Test MSE 0.1140244995601191 Test RE 0.24396917877661728\n",
      "21 Train Loss 0.42082945 Test MSE 0.11731312054737406 Test RE 0.24746237146754807\n",
      "22 Train Loss 0.36815923 Test MSE 0.10845309634412596 Test RE 0.2379341911920873\n",
      "23 Train Loss 0.3309294 Test MSE 0.08926812031764843 Test RE 0.21586591442382577\n",
      "24 Train Loss 0.2956769 Test MSE 0.0835029362481053 Test RE 0.20877896986634017\n",
      "25 Train Loss 0.2653946 Test MSE 0.07739803282267567 Test RE 0.20100221265539497\n",
      "26 Train Loss 0.23828329 Test MSE 0.0666686377438336 Test RE 0.1865506074254737\n",
      "27 Train Loss 0.21170233 Test MSE 0.06469999687011908 Test RE 0.1837756666022789\n",
      "28 Train Loss 0.19715938 Test MSE 0.06211622523343275 Test RE 0.1800687728518245\n",
      "29 Train Loss 0.17933401 Test MSE 0.06655650480219902 Test RE 0.18639365752809595\n",
      "30 Train Loss 0.1654149 Test MSE 0.060349036366184466 Test RE 0.1774888382713001\n",
      "31 Train Loss 0.15749303 Test MSE 0.056647574051483275 Test RE 0.1719596429919073\n",
      "32 Train Loss 0.14505148 Test MSE 0.053252277369682695 Test RE 0.1667266290835726\n",
      "33 Train Loss 0.1347249 Test MSE 0.04680026229488708 Test RE 0.15630037516485584\n",
      "34 Train Loss 0.12077829 Test MSE 0.0393636586761299 Test RE 0.14334534874775678\n",
      "35 Train Loss 0.11275879 Test MSE 0.031017228451043124 Test RE 0.1272440170783482\n",
      "36 Train Loss 0.10634707 Test MSE 0.027124417631891527 Test RE 0.11899154080122736\n",
      "37 Train Loss 0.09643897 Test MSE 0.022596070956948763 Test RE 0.10860563065554296\n",
      "38 Train Loss 0.08911418 Test MSE 0.020140793885475395 Test RE 0.10253548014007638\n",
      "39 Train Loss 0.082192846 Test MSE 0.019779016329834368 Test RE 0.10161041412975821\n",
      "40 Train Loss 0.07697558 Test MSE 0.016647750532225586 Test RE 0.09322097835667541\n",
      "41 Train Loss 0.073330455 Test MSE 0.015481690074560859 Test RE 0.08989697154987299\n",
      "42 Train Loss 0.06790201 Test MSE 0.014424397566668079 Test RE 0.08677302124048981\n",
      "43 Train Loss 0.064689696 Test MSE 0.01400278489014869 Test RE 0.08549546633719135\n",
      "44 Train Loss 0.06070177 Test MSE 0.012899460151190182 Test RE 0.08205813543919478\n",
      "45 Train Loss 0.056895237 Test MSE 0.0115994814308379 Test RE 0.07781353831671416\n",
      "46 Train Loss 0.05364967 Test MSE 0.009844684190965047 Test RE 0.07168640002134184\n",
      "47 Train Loss 0.050737184 Test MSE 0.009090132013300506 Test RE 0.06888441461533686\n",
      "48 Train Loss 0.04681698 Test MSE 0.008527171908944987 Test RE 0.06671728828481492\n",
      "49 Train Loss 0.044592287 Test MSE 0.008405999239080218 Test RE 0.06624155976606151\n",
      "50 Train Loss 0.042422365 Test MSE 0.008252695024690154 Test RE 0.06563474087595725\n",
      "51 Train Loss 0.040432446 Test MSE 0.007607096090362235 Test RE 0.06301520130533642\n",
      "52 Train Loss 0.038906284 Test MSE 0.007358871236116238 Test RE 0.06197855958683216\n",
      "53 Train Loss 0.03753784 Test MSE 0.006411696551891886 Test RE 0.05785253010306956\n",
      "54 Train Loss 0.035898592 Test MSE 0.006017849586433669 Test RE 0.05604753813731999\n",
      "55 Train Loss 0.0344905 Test MSE 0.0051288975217504695 Test RE 0.05174255711746197\n",
      "56 Train Loss 0.033204034 Test MSE 0.004856443139095694 Test RE 0.050349484800786104\n",
      "57 Train Loss 0.031196924 Test MSE 0.004554245167886754 Test RE 0.04875779757550653\n",
      "58 Train Loss 0.02992162 Test MSE 0.004348846943637758 Test RE 0.04764561514519241\n",
      "59 Train Loss 0.028993934 Test MSE 0.003983542984330176 Test RE 0.04560060774390263\n",
      "60 Train Loss 0.028006652 Test MSE 0.0039867168443708575 Test RE 0.04561877010974799\n",
      "61 Train Loss 0.02723298 Test MSE 0.0036760632710931954 Test RE 0.04380537129215585\n",
      "62 Train Loss 0.025742061 Test MSE 0.003944443313685977 Test RE 0.04537626405683041\n",
      "63 Train Loss 0.02452591 Test MSE 0.00391564292138447 Test RE 0.045210302937226346\n",
      "64 Train Loss 0.023561794 Test MSE 0.0037286988297718783 Test RE 0.04411786933664561\n",
      "65 Train Loss 0.021994215 Test MSE 0.0035316104282926203 Test RE 0.04293606820534115\n",
      "66 Train Loss 0.020870475 Test MSE 0.003563627858285261 Test RE 0.043130257355183284\n",
      "67 Train Loss 0.020111483 Test MSE 0.003497584996317422 Test RE 0.04272873302930217\n",
      "68 Train Loss 0.019413669 Test MSE 0.0036023784882697786 Test RE 0.043364120959997775\n",
      "69 Train Loss 0.018448051 Test MSE 0.003596275863493136 Test RE 0.04332737480306562\n",
      "70 Train Loss 0.017640673 Test MSE 0.0037635392760747453 Test RE 0.0443235057295109\n",
      "71 Train Loss 0.016988765 Test MSE 0.00395444216278067 Test RE 0.045433740260017494\n",
      "72 Train Loss 0.016241964 Test MSE 0.003976137731617705 Test RE 0.04555820314240266\n",
      "73 Train Loss 0.015859894 Test MSE 0.0038950693332017138 Test RE 0.0450913744269831\n",
      "74 Train Loss 0.015238928 Test MSE 0.0036129839128654835 Test RE 0.04342790616891743\n",
      "75 Train Loss 0.014587795 Test MSE 0.003355641135002869 Test RE 0.041852714574888907\n",
      "76 Train Loss 0.014072766 Test MSE 0.003155398177626916 Test RE 0.04058475813029944\n",
      "77 Train Loss 0.013805396 Test MSE 0.003114508298417206 Test RE 0.04032093766362913\n",
      "78 Train Loss 0.013396185 Test MSE 0.0029921022072204855 Test RE 0.03952065093652022\n",
      "79 Train Loss 0.013150957 Test MSE 0.0028665214463116507 Test RE 0.03868240561877994\n",
      "80 Train Loss 0.012892775 Test MSE 0.002735269643374105 Test RE 0.03778643759340934\n",
      "81 Train Loss 0.012660818 Test MSE 0.002627473559914918 Test RE 0.03703437792613867\n",
      "82 Train Loss 0.012288131 Test MSE 0.0024225331177512785 Test RE 0.035560735783481214\n",
      "83 Train Loss 0.01202532 Test MSE 0.0023118382182928114 Test RE 0.03473878272951361\n",
      "84 Train Loss 0.011628413 Test MSE 0.002096063446943821 Test RE 0.033077912124134176\n",
      "85 Train Loss 0.011230535 Test MSE 0.001958416238906475 Test RE 0.03197336736973292\n",
      "86 Train Loss 0.010692741 Test MSE 0.001826445863945781 Test RE 0.030877297272078903\n",
      "87 Train Loss 0.010179775 Test MSE 0.0017840402159067512 Test RE 0.030516744171028547\n",
      "88 Train Loss 0.00962958 Test MSE 0.0017077487977629397 Test RE 0.029857117071707937\n",
      "89 Train Loss 0.009311924 Test MSE 0.0016571587260303905 Test RE 0.02941155123982756\n",
      "90 Train Loss 0.0090017505 Test MSE 0.001703581525744496 Test RE 0.02982066594787979\n",
      "91 Train Loss 0.008772122 Test MSE 0.0015751926197646571 Test RE 0.028674952757341984\n",
      "92 Train Loss 0.008596342 Test MSE 0.0015628598749531245 Test RE 0.02856247895935032\n",
      "93 Train Loss 0.008288864 Test MSE 0.001515813814776535 Test RE 0.02812929238645859\n",
      "94 Train Loss 0.007979812 Test MSE 0.001567651981980677 Test RE 0.028606235183541495\n",
      "95 Train Loss 0.007731117 Test MSE 0.001448593573465422 Test RE 0.027498509471254488\n",
      "96 Train Loss 0.0074703745 Test MSE 0.0014305508396796364 Test RE 0.027326721153101113\n",
      "97 Train Loss 0.0073443386 Test MSE 0.0013824330537364606 Test RE 0.02686321150528207\n",
      "98 Train Loss 0.0072192 Test MSE 0.0014027483231408458 Test RE 0.027059873125132146\n",
      "99 Train Loss 0.0070829564 Test MSE 0.0013500185468154292 Test RE 0.026546406744290364\n",
      "100 Train Loss 0.00689571 Test MSE 0.001226790037796721 Test RE 0.025305853948559574\n",
      "101 Train Loss 0.0067701177 Test MSE 0.001202486445189804 Test RE 0.025053936460911613\n",
      "102 Train Loss 0.0065395134 Test MSE 0.0012677579315403804 Test RE 0.02572492072272478\n",
      "103 Train Loss 0.0064054597 Test MSE 0.0012904327451982312 Test RE 0.02595395601847269\n",
      "104 Train Loss 0.0062469896 Test MSE 0.0012856965466826033 Test RE 0.025906283605784404\n",
      "105 Train Loss 0.006101184 Test MSE 0.0012867938090855675 Test RE 0.025917335952741895\n",
      "106 Train Loss 0.0058725206 Test MSE 0.0012653217787566057 Test RE 0.02570019203770418\n",
      "107 Train Loss 0.005740359 Test MSE 0.0012462750579409453 Test RE 0.025506027794907054\n",
      "108 Train Loss 0.0056325914 Test MSE 0.0011884158948215493 Test RE 0.02490692441353878\n",
      "109 Train Loss 0.00548191 Test MSE 0.0011361446477526425 Test RE 0.024353012425324977\n",
      "110 Train Loss 0.005347483 Test MSE 0.0011505999809464412 Test RE 0.024507446212265884\n",
      "111 Train Loss 0.005260902 Test MSE 0.0011686513672977835 Test RE 0.024698942703295274\n",
      "112 Train Loss 0.005168748 Test MSE 0.0010972820713012537 Test RE 0.023932883045196415\n",
      "113 Train Loss 0.0050727157 Test MSE 0.0010336590278364987 Test RE 0.023228679827243998\n",
      "114 Train Loss 0.004995451 Test MSE 0.0010063859893240333 Test RE 0.022920187595464145\n",
      "115 Train Loss 0.0049187806 Test MSE 0.0009274853365410465 Test RE 0.02200338019579281\n",
      "116 Train Loss 0.004843967 Test MSE 0.0008790935946423155 Test RE 0.021421675425095058\n",
      "117 Train Loss 0.0047935387 Test MSE 0.0008790896014380183 Test RE 0.021421626772014198\n",
      "118 Train Loss 0.0047303354 Test MSE 0.0008208522700171533 Test RE 0.02069990625594084\n",
      "119 Train Loss 0.004671691 Test MSE 0.0008140760415856551 Test RE 0.020614289160100246\n",
      "120 Train Loss 0.0045302715 Test MSE 0.0007852637327369831 Test RE 0.02024620579371031\n",
      "121 Train Loss 0.0044479384 Test MSE 0.0007983122219326113 Test RE 0.020413725285167106\n",
      "122 Train Loss 0.0043861344 Test MSE 0.0008138900868954086 Test RE 0.020611934624104468\n",
      "123 Train Loss 0.0043426133 Test MSE 0.0008227795548732642 Test RE 0.020724192736921672\n",
      "124 Train Loss 0.0043025212 Test MSE 0.0008311373357974405 Test RE 0.020829184784922503\n",
      "125 Train Loss 0.004247341 Test MSE 0.0008395644281556016 Test RE 0.020934514412437637\n",
      "126 Train Loss 0.004189091 Test MSE 0.0008557841218751349 Test RE 0.021135765852946426\n",
      "127 Train Loss 0.0041334205 Test MSE 0.000851071993432878 Test RE 0.02107749653207376\n",
      "128 Train Loss 0.0040992503 Test MSE 0.0008311779288597923 Test RE 0.020829693431349917\n",
      "129 Train Loss 0.004038817 Test MSE 0.000831252748602202 Test RE 0.02083063091848258\n",
      "130 Train Loss 0.0039879414 Test MSE 0.0008472142911838869 Test RE 0.02102967269564608\n",
      "131 Train Loss 0.0038975186 Test MSE 0.0008018182627813884 Test RE 0.0204585028438607\n",
      "132 Train Loss 0.0038263965 Test MSE 0.0007699583960954082 Test RE 0.020047928578897516\n",
      "133 Train Loss 0.0037565676 Test MSE 0.0007325713953082443 Test RE 0.019555136657325486\n",
      "134 Train Loss 0.0036985648 Test MSE 0.0007112076732116916 Test RE 0.019267887134670644\n",
      "135 Train Loss 0.003630027 Test MSE 0.0006746765610599293 Test RE 0.018766517502480696\n",
      "136 Train Loss 0.003585759 Test MSE 0.0006543290098159147 Test RE 0.018481361606531188\n",
      "137 Train Loss 0.0035226035 Test MSE 0.0006359277301555048 Test RE 0.018219638612893795\n",
      "138 Train Loss 0.0034373885 Test MSE 0.0005722663080218628 Test RE 0.0172836302067348\n",
      "139 Train Loss 0.0033894416 Test MSE 0.0005684696227793591 Test RE 0.01722620090788142\n",
      "140 Train Loss 0.003361239 Test MSE 0.0005340454801888459 Test RE 0.016696482968989537\n",
      "141 Train Loss 0.0033345537 Test MSE 0.0005225634811414334 Test RE 0.01651602018553986\n",
      "142 Train Loss 0.003303666 Test MSE 0.0004991503114665115 Test RE 0.01614178469066779\n",
      "143 Train Loss 0.003267861 Test MSE 0.0004922643645834979 Test RE 0.01603005734159192\n",
      "144 Train Loss 0.003242896 Test MSE 0.0004747756015901451 Test RE 0.015742730951136666\n",
      "145 Train Loss 0.0032160634 Test MSE 0.0004404609477950928 Test RE 0.015163155243245838\n",
      "146 Train Loss 0.0031880862 Test MSE 0.0004310504949466734 Test RE 0.015000300210208428\n",
      "147 Train Loss 0.003136869 Test MSE 0.0004078846036896572 Test RE 0.014591654338456524\n",
      "148 Train Loss 0.0030558119 Test MSE 0.0003688736974662091 Test RE 0.013876333256159685\n",
      "149 Train Loss 0.0030105384 Test MSE 0.000359286874215142 Test RE 0.013694827070331119\n",
      "150 Train Loss 0.0029757384 Test MSE 0.00033751606251798536 Test RE 0.013273428044423129\n",
      "151 Train Loss 0.002947323 Test MSE 0.0003428137366348051 Test RE 0.013377192751242483\n",
      "152 Train Loss 0.0029214649 Test MSE 0.0003419721115688172 Test RE 0.013360761817881622\n",
      "153 Train Loss 0.00287253 Test MSE 0.0003390577733334777 Test RE 0.013303708784167971\n",
      "154 Train Loss 0.0028246758 Test MSE 0.00034555304963739675 Test RE 0.013430532804378434\n",
      "155 Train Loss 0.0027863216 Test MSE 0.0003295546287156417 Test RE 0.013115944938759332\n",
      "156 Train Loss 0.0027625586 Test MSE 0.00032734913448051017 Test RE 0.013071983029751998\n",
      "157 Train Loss 0.0027275379 Test MSE 0.00033501138431170336 Test RE 0.013224085838397572\n",
      "158 Train Loss 0.002697708 Test MSE 0.0003201595002985694 Test RE 0.012927634759629214\n",
      "159 Train Loss 0.0026812092 Test MSE 0.0003156884461241657 Test RE 0.012837049640693363\n",
      "160 Train Loss 0.0026573206 Test MSE 0.0003121538020830336 Test RE 0.012764981550093557\n",
      "161 Train Loss 0.0026324298 Test MSE 0.0002964901213486062 Test RE 0.01244059038319075\n",
      "162 Train Loss 0.0025888614 Test MSE 0.0002767689289137979 Test RE 0.012019725328927127\n",
      "163 Train Loss 0.0025506546 Test MSE 0.00026500077266299196 Test RE 0.011761411553375695\n",
      "164 Train Loss 0.0025168478 Test MSE 0.00026699337580716017 Test RE 0.0118055471522832\n",
      "165 Train Loss 0.0024904846 Test MSE 0.00025825254633238704 Test RE 0.011610694098034417\n",
      "166 Train Loss 0.0024481204 Test MSE 0.00025262298180893177 Test RE 0.011483447927059756\n",
      "167 Train Loss 0.0024118489 Test MSE 0.00025862785539425927 Test RE 0.011619127735448218\n",
      "168 Train Loss 0.0023817425 Test MSE 0.00024077697119128925 Test RE 0.011210974129931188\n",
      "169 Train Loss 0.0023494756 Test MSE 0.00021803028202893327 Test RE 0.010668277040002222\n",
      "170 Train Loss 0.002315938 Test MSE 0.00020915514275829004 Test RE 0.010448889843434306\n",
      "171 Train Loss 0.0022887117 Test MSE 0.00021364972813106613 Test RE 0.010560562451020274\n",
      "172 Train Loss 0.0022569909 Test MSE 0.00021704416712847027 Test RE 0.010644124273123085\n",
      "173 Train Loss 0.0022280933 Test MSE 0.0002150693881218567 Test RE 0.010595590777837045\n",
      "174 Train Loss 0.0022070017 Test MSE 0.0002121131800538862 Test RE 0.010522518656461975\n",
      "175 Train Loss 0.002188028 Test MSE 0.0001973999339887963 Test RE 0.010151012871135649\n",
      "176 Train Loss 0.0021651515 Test MSE 0.0001853022994647641 Test RE 0.009835043411242894\n",
      "177 Train Loss 0.0021441465 Test MSE 0.0001802923299471895 Test RE 0.009701178654212725\n",
      "178 Train Loss 0.0021085646 Test MSE 0.00016100898109534939 Test RE 0.009167711284176821\n",
      "179 Train Loss 0.002087382 Test MSE 0.00016393158749917734 Test RE 0.00925054242337278\n",
      "180 Train Loss 0.002072886 Test MSE 0.0001586091281671963 Test RE 0.009099132011001257\n",
      "181 Train Loss 0.0020610117 Test MSE 0.0001494702473914351 Test RE 0.008833102164553377\n",
      "182 Train Loss 0.0020488752 Test MSE 0.0001449674738495683 Test RE 0.008699036687541184\n",
      "183 Train Loss 0.0020272015 Test MSE 0.0001390148797998928 Test RE 0.008518566560650037\n",
      "184 Train Loss 0.0020065804 Test MSE 0.00012969847855918388 Test RE 0.008228171169491478\n",
      "185 Train Loss 0.0019940592 Test MSE 0.0001262027774848218 Test RE 0.008116528788728242\n",
      "186 Train Loss 0.0019670732 Test MSE 0.0001309002864041865 Test RE 0.008266205072239633\n",
      "187 Train Loss 0.0019376798 Test MSE 0.0001288059390421671 Test RE 0.008199810596882027\n",
      "188 Train Loss 0.0019033401 Test MSE 0.0001293053998868853 Test RE 0.008215693101410427\n",
      "189 Train Loss 0.0018725932 Test MSE 0.00012496941899554185 Test RE 0.008076770678472883\n",
      "190 Train Loss 0.0018497024 Test MSE 0.0001286310251932347 Test RE 0.008194241181014474\n",
      "191 Train Loss 0.0018217288 Test MSE 0.00012146736268550872 Test RE 0.007962797619798477\n",
      "192 Train Loss 0.0018034278 Test MSE 0.0001191561061757122 Test RE 0.007886676521897517\n",
      "193 Train Loss 0.001772965 Test MSE 0.00011542720265174652 Test RE 0.007762291756663573\n",
      "194 Train Loss 0.0017524969 Test MSE 0.0001130471929376625 Test RE 0.007681849039570356\n",
      "195 Train Loss 0.0017317624 Test MSE 0.0001080797692028526 Test RE 0.0075111784700694064\n",
      "196 Train Loss 0.0017136544 Test MSE 0.0001057187850740194 Test RE 0.007428685263525344\n",
      "197 Train Loss 0.0017004503 Test MSE 0.00011386333720226704 Test RE 0.007709528727480651\n",
      "198 Train Loss 0.0016867814 Test MSE 0.00011068243465562499 Test RE 0.007601078692421605\n",
      "199 Train Loss 0.001672814 Test MSE 0.00010868996537203503 Test RE 0.007532351912046218\n",
      "200 Train Loss 0.0016627606 Test MSE 0.00011089545260097272 Test RE 0.007608389644077449\n",
      "201 Train Loss 0.0016455754 Test MSE 0.00012052598212816203 Test RE 0.007931881483461365\n",
      "202 Train Loss 0.0016283984 Test MSE 0.00011507702406958396 Test RE 0.007750508342633126\n",
      "203 Train Loss 0.0016024931 Test MSE 0.00010520792560073816 Test RE 0.007410714900159638\n",
      "204 Train Loss 0.0015804354 Test MSE 0.00010471985393587818 Test RE 0.007393505338378559\n",
      "205 Train Loss 0.0015586391 Test MSE 0.00011308684373145369 Test RE 0.007683196108438034\n",
      "206 Train Loss 0.0015437551 Test MSE 0.00010699610733702924 Test RE 0.0074734281883293025\n",
      "207 Train Loss 0.0015280029 Test MSE 0.00010256180091502969 Test RE 0.007316926558833838\n",
      "208 Train Loss 0.0015168445 Test MSE 9.645236924940528e-05 Test RE 0.007095652313430603\n",
      "209 Train Loss 0.0015066427 Test MSE 9.576917993451723e-05 Test RE 0.007070477770534743\n",
      "210 Train Loss 0.0014967575 Test MSE 9.776336948853957e-05 Test RE 0.007143712329654474\n",
      "211 Train Loss 0.001485459 Test MSE 9.2386359730677e-05 Test RE 0.006944481166476382\n",
      "212 Train Loss 0.0014750921 Test MSE 8.820327658159462e-05 Test RE 0.006785443462217178\n",
      "213 Train Loss 0.0014608254 Test MSE 8.475531251217044e-05 Test RE 0.006651496113739677\n",
      "214 Train Loss 0.0014458692 Test MSE 7.903371882525717e-05 Test RE 0.006423061578778112\n",
      "215 Train Loss 0.0014332213 Test MSE 7.420267114637951e-05 Test RE 0.006223656954997111\n",
      "216 Train Loss 0.0014212837 Test MSE 6.655160150766774e-05 Test RE 0.005894067868593328\n",
      "217 Train Loss 0.0014063453 Test MSE 5.778239949092006e-05 Test RE 0.005492039639639184\n",
      "218 Train Loss 0.0013984536 Test MSE 5.697951926785732e-05 Test RE 0.005453750518669921\n",
      "219 Train Loss 0.0013883567 Test MSE 5.7226764690529726e-05 Test RE 0.005465570162593481\n",
      "220 Train Loss 0.0013805933 Test MSE 5.956338516346735e-05 Test RE 0.005576035921866207\n",
      "221 Train Loss 0.0013727698 Test MSE 6.183127305620064e-05 Test RE 0.0056811985963751\n",
      "222 Train Loss 0.0013636679 Test MSE 5.8230148592259655e-05 Test RE 0.005513277165843015\n",
      "223 Train Loss 0.0013536218 Test MSE 5.639033125901008e-05 Test RE 0.005425480411309087\n",
      "224 Train Loss 0.0013450476 Test MSE 5.349917662344184e-05 Test RE 0.005284567212858375\n",
      "225 Train Loss 0.0013377516 Test MSE 5.466894584375967e-05 Test RE 0.005342028820479671\n",
      "226 Train Loss 0.0013289736 Test MSE 5.21543551519224e-05 Test RE 0.005217724772091964\n",
      "227 Train Loss 0.0013210921 Test MSE 5.081073609814313e-05 Test RE 0.0051500757888845285\n",
      "228 Train Loss 0.001312155 Test MSE 5.025037146955442e-05 Test RE 0.005121598329885733\n",
      "229 Train Loss 0.0013015489 Test MSE 4.7954512591764115e-05 Test RE 0.005003231722289642\n",
      "230 Train Loss 0.0012941543 Test MSE 4.605300254781205e-05 Test RE 0.004903033404463354\n",
      "231 Train Loss 0.0012792101 Test MSE 4.5648617116592325e-05 Test RE 0.0048814594909965614\n",
      "232 Train Loss 0.0012688352 Test MSE 4.349691583318145e-05 Test RE 0.0047650241822542365\n",
      "233 Train Loss 0.001256692 Test MSE 4.2279242476191665e-05 Test RE 0.0046978535667354425\n",
      "234 Train Loss 0.0012462041 Test MSE 4.571589560939541e-05 Test RE 0.004885055397498476\n",
      "235 Train Loss 0.001234068 Test MSE 4.810023139924911e-05 Test RE 0.005010827586687033\n",
      "236 Train Loss 0.0012204491 Test MSE 5.068872667794933e-05 Test RE 0.005143888755648442\n",
      "237 Train Loss 0.0012109175 Test MSE 5.2397766825216945e-05 Test RE 0.00522988652426637\n",
      "238 Train Loss 0.001203888 Test MSE 5.939742659882022e-05 Test RE 0.005568262384415547\n",
      "239 Train Loss 0.0011960897 Test MSE 6.335313314943207e-05 Test RE 0.005750689588915454\n",
      "240 Train Loss 0.0011853413 Test MSE 6.726081495652795e-05 Test RE 0.00592538998936856\n",
      "241 Train Loss 0.0011768467 Test MSE 7.070428258700262e-05 Test RE 0.0060751742202236015\n",
      "242 Train Loss 0.0011670834 Test MSE 6.4956534037571e-05 Test RE 0.005823006819693379\n",
      "243 Train Loss 0.0011566608 Test MSE 6.496370715652041e-05 Test RE 0.005823328326745037\n",
      "244 Train Loss 0.001150955 Test MSE 6.808910595705645e-05 Test RE 0.005961762799174757\n",
      "245 Train Loss 0.001146281 Test MSE 6.830071629121309e-05 Test RE 0.005971019727499261\n",
      "246 Train Loss 0.0011382597 Test MSE 6.268776008478876e-05 Test RE 0.0057204112621389285\n",
      "247 Train Loss 0.0011263755 Test MSE 7.330179897588782e-05 Test RE 0.006185761817765932\n",
      "248 Train Loss 0.001118528 Test MSE 6.902840673032787e-05 Test RE 0.006002743713453128\n",
      "249 Train Loss 0.0011118058 Test MSE 6.896011682340531e-05 Test RE 0.005999773717009797\n",
      "250 Train Loss 0.001103527 Test MSE 7.099142562596354e-05 Test RE 0.006087497918200312\n",
      "251 Train Loss 0.0010936081 Test MSE 6.873762557483297e-05 Test RE 0.005990087135349294\n",
      "252 Train Loss 0.0010859368 Test MSE 6.863803074606879e-05 Test RE 0.005985746005197095\n",
      "253 Train Loss 0.0010780237 Test MSE 6.835243115850304e-05 Test RE 0.005973279821392762\n",
      "254 Train Loss 0.0010697732 Test MSE 6.304389718751276e-05 Test RE 0.00573663743939239\n",
      "255 Train Loss 0.0010622476 Test MSE 6.16738285835431e-05 Test RE 0.005673960807057775\n",
      "256 Train Loss 0.0010564125 Test MSE 5.9614020591670014e-05 Test RE 0.005578405540258664\n",
      "257 Train Loss 0.0010511834 Test MSE 5.715303740161269e-05 Test RE 0.005462048283069004\n",
      "258 Train Loss 0.0010437741 Test MSE 6.114260122168426e-05 Test RE 0.005649471635338914\n",
      "259 Train Loss 0.0010387755 Test MSE 6.300609652903228e-05 Test RE 0.005734917358644565\n",
      "260 Train Loss 0.0010336395 Test MSE 6.242151020526431e-05 Test RE 0.005708250359840434\n",
      "261 Train Loss 0.0010299559 Test MSE 6.502157012346862e-05 Test RE 0.005825921159508456\n",
      "262 Train Loss 0.0010228594 Test MSE 6.224390082353258e-05 Test RE 0.005700123665881246\n",
      "263 Train Loss 0.0010157194 Test MSE 5.916430460127414e-05 Test RE 0.005557324531508513\n",
      "264 Train Loss 0.0010088839 Test MSE 5.892191924553568e-05 Test RE 0.005545929176288916\n",
      "265 Train Loss 0.0010048876 Test MSE 5.7464979119523195e-05 Test RE 0.005476933949966383\n",
      "266 Train Loss 0.0009999452 Test MSE 5.8285925121295584e-05 Test RE 0.005515917017089385\n",
      "267 Train Loss 0.0009925202 Test MSE 5.8756135400171386e-05 Test RE 0.005538121614039892\n",
      "268 Train Loss 0.0009870935 Test MSE 5.487362203303935e-05 Test RE 0.005352019543812057\n",
      "269 Train Loss 0.0009854789 Test MSE 5.530337534594137e-05 Test RE 0.005372936354803129\n",
      "270 Train Loss 0.0009766734 Test MSE 5.2621507038515025e-05 Test RE 0.005241040524973256\n",
      "271 Train Loss 0.00096851814 Test MSE 5.504878185458456e-05 Test RE 0.005360554718266126\n",
      "272 Train Loss 0.0009601092 Test MSE 5.648058986725297e-05 Test RE 0.005429820698945289\n",
      "273 Train Loss 0.0009528879 Test MSE 5.633790596239187e-05 Test RE 0.005422957828514675\n",
      "274 Train Loss 0.00094499247 Test MSE 5.4610999305850634e-05 Test RE 0.00533919691891309\n",
      "275 Train Loss 0.00093994057 Test MSE 5.334320992201613e-05 Test RE 0.005276858513793576\n",
      "276 Train Loss 0.00093274034 Test MSE 5.163260625021721e-05 Test RE 0.005191560274736616\n",
      "277 Train Loss 0.00093129295 Test MSE 5.094804452852135e-05 Test RE 0.005157029749607739\n",
      "278 Train Loss 0.0009256731 Test MSE 5.0129851479947233e-05 Test RE 0.005115452847688621\n",
      "279 Train Loss 0.00092036696 Test MSE 5.133338740119571e-05 Test RE 0.0051764954744685536\n",
      "280 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "281 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "282 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "283 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "284 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "285 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "286 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "287 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "288 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "289 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "290 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "291 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "292 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "293 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "294 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "295 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "296 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "297 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "298 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "299 Train Loss 0.0009189757 Test MSE 5.073535089220864e-05 Test RE 0.005146253923041878\n",
      "Training time: 144.98\n",
      "KG_stan_high\n",
      "8\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "8\n",
      "0 Train Loss 38688.75 Test MSE 4.609600013925465 Test RE 1.5511989354257052\n",
      "1 Train Loss 8246.772 Test MSE 7.918758846188296 Test RE 2.0331266617311203\n",
      "2 Train Loss 1295.5521 Test MSE 8.352389933152423 Test RE 2.0880517479102476\n",
      "3 Train Loss 292.09863 Test MSE 6.381143775596294 Test RE 1.8250935987416455\n",
      "4 Train Loss 123.0612 Test MSE 4.199065220538588 Test RE 1.480512869895647\n",
      "5 Train Loss 68.06096 Test MSE 3.3203114511800145 Test RE 1.3165134139907284\n",
      "6 Train Loss 40.582283 Test MSE 2.0818529224172413 Test RE 1.0424635990408488\n",
      "7 Train Loss 19.094938 Test MSE 0.79295939948844 Test RE 0.6433708096075452\n",
      "8 Train Loss 10.469609 Test MSE 0.3737179016265382 Test RE 0.4416800951937859\n",
      "9 Train Loss 6.321853 Test MSE 0.22684628998770295 Test RE 0.34411350512666244\n",
      "10 Train Loss 4.3434973 Test MSE 0.13039026700411402 Test RE 0.26089061961428905\n",
      "11 Train Loss 2.526405 Test MSE 0.09167103298439866 Test RE 0.21875195321317115\n",
      "12 Train Loss 1.8612124 Test MSE 0.07709694415611268 Test RE 0.20061086898711897\n",
      "13 Train Loss 1.3886253 Test MSE 0.05267555626678838 Test RE 0.16582134833255746\n",
      "14 Train Loss 1.0962796 Test MSE 0.043376434241057214 Test RE 0.15047446256839986\n",
      "15 Train Loss 0.84385145 Test MSE 0.03247047223787341 Test RE 0.13019076512465524\n",
      "16 Train Loss 0.6749661 Test MSE 0.027951019015235862 Test RE 0.12079103421634738\n",
      "17 Train Loss 0.53012943 Test MSE 0.020932724053303008 Test RE 0.10453187755769426\n",
      "18 Train Loss 0.43916285 Test MSE 0.01833936726276202 Test RE 0.0978426148580694\n",
      "19 Train Loss 0.36051476 Test MSE 0.020114106785670115 Test RE 0.10246752647222776\n",
      "20 Train Loss 0.29895622 Test MSE 0.02210442179442685 Test RE 0.10741760287827372\n",
      "21 Train Loss 0.2621246 Test MSE 0.021215810912344358 Test RE 0.10523633018945733\n",
      "22 Train Loss 0.22533342 Test MSE 0.018936367751325036 Test RE 0.09942239403079718\n",
      "23 Train Loss 0.19444382 Test MSE 0.013694493136031969 Test RE 0.08454907453712397\n",
      "24 Train Loss 0.17807253 Test MSE 0.009975417334392467 Test RE 0.07216081239447775\n",
      "25 Train Loss 0.16148663 Test MSE 0.006704736718787149 Test RE 0.05915980600878993\n",
      "26 Train Loss 0.14607999 Test MSE 0.005857853650722039 Test RE 0.05529745394028206\n",
      "27 Train Loss 0.13303661 Test MSE 0.005049997667309161 Test RE 0.05134302654128124\n",
      "28 Train Loss 0.12201332 Test MSE 0.004718153965958975 Test RE 0.0496274466744518\n",
      "29 Train Loss 0.11112816 Test MSE 0.0050097729930624136 Test RE 0.051138136786441434\n",
      "30 Train Loss 0.103321105 Test MSE 0.004694838076347041 Test RE 0.04950467184009407\n",
      "31 Train Loss 0.096466996 Test MSE 0.004767276842400874 Test RE 0.04988512482472858\n",
      "32 Train Loss 0.088645205 Test MSE 0.004255379837043452 Test RE 0.047130825076638024\n",
      "33 Train Loss 0.082871914 Test MSE 0.003950645233335531 Test RE 0.045411923006366185\n",
      "34 Train Loss 0.0791644 Test MSE 0.0037031988849297822 Test RE 0.043966753180802016\n",
      "35 Train Loss 0.07385646 Test MSE 0.0040077692751309575 Test RE 0.045739059750203516\n",
      "36 Train Loss 0.069350526 Test MSE 0.0041078206473822935 Test RE 0.046306463410235414\n",
      "37 Train Loss 0.064988166 Test MSE 0.003912025465137696 Test RE 0.0451894144028946\n",
      "38 Train Loss 0.061236665 Test MSE 0.0040308807551483646 Test RE 0.04587075118359401\n",
      "39 Train Loss 0.05772875 Test MSE 0.0036780754004098054 Test RE 0.0438173583020691\n",
      "40 Train Loss 0.054215822 Test MSE 0.0032179138790311974 Test RE 0.04098482502845434\n",
      "41 Train Loss 0.050710037 Test MSE 0.00310481201375415 Test RE 0.04025812388702331\n",
      "42 Train Loss 0.047744557 Test MSE 0.0028084727076333163 Test RE 0.03828873170524469\n",
      "43 Train Loss 0.04441868 Test MSE 0.0022003893051850596 Test RE 0.03389109802493342\n",
      "44 Train Loss 0.042548336 Test MSE 0.001823075838651635 Test RE 0.030848797846242677\n",
      "45 Train Loss 0.040646773 Test MSE 0.0016789708687288101 Test RE 0.029604481377210338\n",
      "46 Train Loss 0.039013308 Test MSE 0.0014693030046549218 Test RE 0.02769437447128585\n",
      "47 Train Loss 0.03606794 Test MSE 0.0013392173910043443 Test RE 0.026439997947459052\n",
      "48 Train Loss 0.033759974 Test MSE 0.0013467321966915712 Test RE 0.02651407609795232\n",
      "49 Train Loss 0.031571858 Test MSE 0.0011102369994761248 Test RE 0.024073748832256235\n",
      "50 Train Loss 0.030017221 Test MSE 0.0011384212159302604 Test RE 0.02437739908602442\n",
      "51 Train Loss 0.028897459 Test MSE 0.0009857101859987645 Test RE 0.022683522631897705\n",
      "52 Train Loss 0.027403876 Test MSE 0.0008392572378699352 Test RE 0.02093068417165613\n",
      "53 Train Loss 0.025727237 Test MSE 0.0007320211191869921 Test RE 0.0195477907888361\n",
      "54 Train Loss 0.02442101 Test MSE 0.0007834530779939879 Test RE 0.020222850554343644\n",
      "55 Train Loss 0.023084838 Test MSE 0.0010216992897166084 Test RE 0.02309390753506119\n",
      "56 Train Loss 0.022198262 Test MSE 0.0010704257974280568 Test RE 0.023638186806901273\n",
      "57 Train Loss 0.021137977 Test MSE 0.0008946287462305827 Test RE 0.021610126110286548\n",
      "58 Train Loss 0.020527914 Test MSE 0.0009894013201503136 Test RE 0.02272595380986494\n",
      "59 Train Loss 0.01968438 Test MSE 0.0009181799908958479 Test RE 0.021892723348736452\n",
      "60 Train Loss 0.01879205 Test MSE 0.0006845967757487897 Test RE 0.018903982282905015\n",
      "61 Train Loss 0.0178961 Test MSE 0.000542257463095552 Test RE 0.016824363612238595\n",
      "62 Train Loss 0.016912334 Test MSE 0.0004473111504363296 Test RE 0.015280611669955533\n",
      "63 Train Loss 0.016177133 Test MSE 0.00038715315259778163 Test RE 0.014215995487327502\n",
      "64 Train Loss 0.01533423 Test MSE 0.00038075406499377514 Test RE 0.014098020937214618\n",
      "65 Train Loss 0.014821669 Test MSE 0.000391673767239782 Test RE 0.014298751530642728\n",
      "66 Train Loss 0.01428349 Test MSE 0.00042660505294262564 Test RE 0.014922750382790088\n",
      "67 Train Loss 0.013758324 Test MSE 0.0004533651962116209 Test RE 0.015383670368421053\n",
      "68 Train Loss 0.013071623 Test MSE 0.0004860224530187887 Test RE 0.015928102559751415\n",
      "69 Train Loss 0.012471357 Test MSE 0.000475099955570832 Test RE 0.015748107539175094\n",
      "70 Train Loss 0.012035428 Test MSE 0.0003679788810870322 Test RE 0.013859492383951897\n",
      "71 Train Loss 0.01145216 Test MSE 0.00032108547473928297 Test RE 0.012946316098741015\n",
      "72 Train Loss 0.011141162 Test MSE 0.0002883065099571003 Test RE 0.012267698709736293\n",
      "73 Train Loss 0.010809124 Test MSE 0.0002963778414388341 Test RE 0.012438234553208801\n",
      "74 Train Loss 0.0105368635 Test MSE 0.00032533143754120145 Test RE 0.013031634567253361\n",
      "75 Train Loss 0.010233098 Test MSE 0.0003196496076535921 Test RE 0.012917336248280105\n",
      "76 Train Loss 0.010023703 Test MSE 0.0002987604293119181 Test RE 0.012488130094306776\n",
      "77 Train Loss 0.009728545 Test MSE 0.0003064144180334192 Test RE 0.01264708610201713\n",
      "78 Train Loss 0.00957146 Test MSE 0.00026662378232737054 Test RE 0.011797373233592761\n",
      "79 Train Loss 0.009400494 Test MSE 0.00026541602312079167 Test RE 0.011770622884585651\n",
      "80 Train Loss 0.009120685 Test MSE 0.0002706541410401614 Test RE 0.011886204967101261\n",
      "81 Train Loss 0.008897784 Test MSE 0.00028466453209238373 Test RE 0.01218996774861172\n",
      "82 Train Loss 0.008726034 Test MSE 0.0002996912547637279 Test RE 0.01250756912983346\n",
      "83 Train Loss 0.008529901 Test MSE 0.00030570856691675515 Test RE 0.012632510895612608\n",
      "84 Train Loss 0.008304284 Test MSE 0.00036734524201819464 Test RE 0.013847554607015814\n",
      "85 Train Loss 0.008135021 Test MSE 0.00038028274959244553 Test RE 0.014089292636540688\n",
      "86 Train Loss 0.007999187 Test MSE 0.0003973898542080414 Test RE 0.014402711596291862\n",
      "87 Train Loss 0.007855458 Test MSE 0.0004169264929769903 Test RE 0.014752499996082441\n",
      "88 Train Loss 0.0076887566 Test MSE 0.00045896927160255733 Test RE 0.015478457603501044\n",
      "89 Train Loss 0.007447953 Test MSE 0.0005664675575544807 Test RE 0.017195840097576985\n",
      "90 Train Loss 0.007294153 Test MSE 0.0005751997275616361 Test RE 0.017327871263746502\n",
      "91 Train Loss 0.0071440027 Test MSE 0.0006227795893992071 Test RE 0.0180303045438219\n",
      "92 Train Loss 0.0069526494 Test MSE 0.0007367541004383814 Test RE 0.01961088340827145\n",
      "93 Train Loss 0.0067792484 Test MSE 0.0007565458328189673 Test RE 0.019872545436104724\n",
      "94 Train Loss 0.0065976474 Test MSE 0.0009516756927698119 Test RE 0.022288475550369207\n",
      "95 Train Loss 0.0064665065 Test MSE 0.0010022081921468528 Test RE 0.022872563979666746\n",
      "96 Train Loss 0.006330075 Test MSE 0.0009824136610074134 Test RE 0.022645560447698998\n",
      "97 Train Loss 0.0062180124 Test MSE 0.0009862460489971046 Test RE 0.02268968753162011\n",
      "98 Train Loss 0.0061228005 Test MSE 0.0009714525316003439 Test RE 0.022518873905262613\n",
      "99 Train Loss 0.006015567 Test MSE 0.0010408657341822774 Test RE 0.02330951475392726\n",
      "100 Train Loss 0.0058898395 Test MSE 0.0010619412121865596 Test RE 0.02354431798261131\n",
      "101 Train Loss 0.005807684 Test MSE 0.001046905150908174 Test RE 0.023377041358436067\n",
      "102 Train Loss 0.00567569 Test MSE 0.0009312053645434861 Test RE 0.022047462444701193\n",
      "103 Train Loss 0.005582142 Test MSE 0.0008808006289974312 Test RE 0.021442463769768147\n",
      "104 Train Loss 0.00550951 Test MSE 0.0008850108184853985 Test RE 0.021493649707764104\n",
      "105 Train Loss 0.0054365653 Test MSE 0.0007975583772991633 Test RE 0.020404084688764975\n",
      "106 Train Loss 0.005332246 Test MSE 0.0007709256005800246 Test RE 0.020060516506302247\n",
      "107 Train Loss 0.005254548 Test MSE 0.0006927153536880995 Test RE 0.019015742321614553\n",
      "108 Train Loss 0.0051825666 Test MSE 0.0006279267980884263 Test RE 0.01810466052200278\n",
      "109 Train Loss 0.0051190653 Test MSE 0.0006435845694765722 Test RE 0.018328996503388116\n",
      "110 Train Loss 0.0050675385 Test MSE 0.0005746274273102001 Test RE 0.017319248856152377\n",
      "111 Train Loss 0.004988545 Test MSE 0.0005069190188286405 Test RE 0.016266913964309737\n",
      "112 Train Loss 0.0048797345 Test MSE 0.00044697158626704647 Test RE 0.01527481063716078\n",
      "113 Train Loss 0.0048142085 Test MSE 0.00043230665107879345 Test RE 0.015022141051988232\n",
      "114 Train Loss 0.004736847 Test MSE 0.00039528295827334566 Test RE 0.01436448044589766\n",
      "115 Train Loss 0.004658947 Test MSE 0.00039668640531292725 Test RE 0.01438995830241204\n",
      "116 Train Loss 0.004584128 Test MSE 0.00037186274876185394 Test RE 0.013932441060561513\n",
      "117 Train Loss 0.004530079 Test MSE 0.0003513661910873465 Test RE 0.0135430306794949\n",
      "118 Train Loss 0.004469988 Test MSE 0.0003076539151931756 Test RE 0.012672640066405548\n",
      "119 Train Loss 0.0043899533 Test MSE 0.00027202887621518055 Test RE 0.011916353567600152\n",
      "120 Train Loss 0.0043256055 Test MSE 0.0002561053541450712 Test RE 0.011562325885750624\n",
      "121 Train Loss 0.00426474 Test MSE 0.00024397006036010982 Test RE 0.01128506704847376\n",
      "122 Train Loss 0.004212934 Test MSE 0.0002499554466935194 Test RE 0.011422658138669798\n",
      "123 Train Loss 0.0041507017 Test MSE 0.00024867559185832154 Test RE 0.011393376707755847\n",
      "124 Train Loss 0.004112855 Test MSE 0.0002536765179486882 Test RE 0.011507368237017304\n",
      "125 Train Loss 0.004060589 Test MSE 0.00023946178921229906 Test RE 0.011180313679487285\n",
      "126 Train Loss 0.0040112287 Test MSE 0.00024172210293789151 Test RE 0.011232956028339475\n",
      "127 Train Loss 0.0039622835 Test MSE 0.00024180845856908297 Test RE 0.011234962345460522\n",
      "128 Train Loss 0.0039075594 Test MSE 0.0002537218442984104 Test RE 0.01150839624643732\n",
      "129 Train Loss 0.0038595602 Test MSE 0.00025971326045961325 Test RE 0.011643483688679984\n",
      "130 Train Loss 0.003799086 Test MSE 0.0002570049245958351 Test RE 0.011582614429220936\n",
      "131 Train Loss 0.0037498563 Test MSE 0.00024281121180338365 Test RE 0.011258233324982362\n",
      "132 Train Loss 0.0037013146 Test MSE 0.0002354130985114341 Test RE 0.011085395407433331\n",
      "133 Train Loss 0.0036567738 Test MSE 0.00023149105158835217 Test RE 0.010992664688279842\n",
      "134 Train Loss 0.0036222385 Test MSE 0.00023363292594510382 Test RE 0.011043402491226947\n",
      "135 Train Loss 0.0035897107 Test MSE 0.00024539197222674445 Test RE 0.011317905213448753\n",
      "136 Train Loss 0.0035533374 Test MSE 0.00025076345193590166 Test RE 0.011441105667905732\n",
      "137 Train Loss 0.0034998877 Test MSE 0.00023715601974609208 Test RE 0.011126356045171062\n",
      "138 Train Loss 0.0034501292 Test MSE 0.00024282979862085818 Test RE 0.011258664216789142\n",
      "139 Train Loss 0.0034108902 Test MSE 0.000239169165922971 Test RE 0.011173480396670332\n",
      "140 Train Loss 0.003356441 Test MSE 0.00024728192472015615 Test RE 0.011361405567248047\n",
      "141 Train Loss 0.0033016491 Test MSE 0.00026846174033830445 Test RE 0.011837965706047395\n",
      "142 Train Loss 0.003251241 Test MSE 0.0002838285421237875 Test RE 0.0121720551137338\n",
      "143 Train Loss 0.0032055944 Test MSE 0.0002447685793259361 Test RE 0.01130352008841449\n",
      "144 Train Loss 0.003161187 Test MSE 0.00023760264793319622 Test RE 0.011136828068576639\n",
      "145 Train Loss 0.0031148654 Test MSE 0.00022849337928566754 Test RE 0.01092125851265787\n",
      "146 Train Loss 0.0030671463 Test MSE 0.00022963021553822177 Test RE 0.010948393385937326\n",
      "147 Train Loss 0.0030190258 Test MSE 0.0002224276061962749 Test RE 0.010775321100944308\n",
      "148 Train Loss 0.0029637383 Test MSE 0.00022410992740760132 Test RE 0.010815993668172244\n",
      "149 Train Loss 0.0029265385 Test MSE 0.00021356771398172437 Test RE 0.010558535304323428\n",
      "150 Train Loss 0.0028936472 Test MSE 0.0002149545244007249 Test RE 0.010592760966635207\n",
      "151 Train Loss 0.002855924 Test MSE 0.00021842102527615105 Test RE 0.010677832343913403\n",
      "152 Train Loss 0.00279932 Test MSE 0.00022825917814247172 Test RE 0.010915660041951637\n",
      "153 Train Loss 0.002769757 Test MSE 0.0002310930349231248 Test RE 0.010983210443733387\n",
      "154 Train Loss 0.0027365615 Test MSE 0.00023325697866748577 Test RE 0.011034513742758581\n",
      "155 Train Loss 0.0026985174 Test MSE 0.0002335767812495531 Test RE 0.01104207548279548\n",
      "156 Train Loss 0.002661355 Test MSE 0.000234964282543253 Test RE 0.011074823191772002\n",
      "157 Train Loss 0.0026107065 Test MSE 0.0002355862123612531 Test RE 0.011089470547731574\n",
      "158 Train Loss 0.0025819596 Test MSE 0.00023656671150968118 Test RE 0.011112523523419503\n",
      "159 Train Loss 0.0025428548 Test MSE 0.0002481232196028946 Test RE 0.011380715867513483\n",
      "160 Train Loss 0.002505517 Test MSE 0.0002808548618725676 Test RE 0.012108123724593103\n",
      "161 Train Loss 0.0024856136 Test MSE 0.0002795643866199618 Test RE 0.012080274421887732\n",
      "162 Train Loss 0.0024563165 Test MSE 0.00026171723318532935 Test RE 0.011688318492585673\n",
      "163 Train Loss 0.002427142 Test MSE 0.00024031285607891204 Test RE 0.011200163934317317\n",
      "164 Train Loss 0.0023999196 Test MSE 0.00023391403805475628 Test RE 0.011050044322404114\n",
      "165 Train Loss 0.0023689154 Test MSE 0.00024660412701037714 Test RE 0.011345824123438557\n",
      "166 Train Loss 0.0023474353 Test MSE 0.00026237945266946065 Test RE 0.011703096545376641\n",
      "167 Train Loss 0.0023203662 Test MSE 0.0002667607627697563 Test RE 0.011800403349443208\n",
      "168 Train Loss 0.0022853522 Test MSE 0.0002487892277248776 Test RE 0.011395979593611688\n",
      "169 Train Loss 0.002254537 Test MSE 0.0002331972282836577 Test RE 0.01103310036884202\n",
      "170 Train Loss 0.0022225457 Test MSE 0.00023895907069633687 Test RE 0.01116857171488904\n",
      "171 Train Loss 0.0021889086 Test MSE 0.00024162791957432102 Test RE 0.011230767439370768\n",
      "172 Train Loss 0.0021414312 Test MSE 0.0002410023348230791 Test RE 0.011216219554582041\n",
      "173 Train Loss 0.0021124922 Test MSE 0.0002418196203630867 Test RE 0.01123522164343749\n",
      "174 Train Loss 0.0020759352 Test MSE 0.0001981487723771119 Test RE 0.010170248624023586\n",
      "175 Train Loss 0.0020507327 Test MSE 0.0001818796921195429 Test RE 0.009743791496195685\n",
      "176 Train Loss 0.0020155765 Test MSE 0.00015530952812257417 Test RE 0.009003988403467136\n",
      "177 Train Loss 0.0019799767 Test MSE 0.00014639638337222318 Test RE 0.008741803716065259\n",
      "178 Train Loss 0.0019417529 Test MSE 0.00013339833108538265 Test RE 0.008344706668027575\n",
      "179 Train Loss 0.0019138714 Test MSE 0.00013485769997697352 Test RE 0.008390227775860763\n",
      "180 Train Loss 0.0018898282 Test MSE 0.0001354392366429709 Test RE 0.008408298587987272\n",
      "181 Train Loss 0.0018633598 Test MSE 0.00013772804252010814 Test RE 0.008479047426071366\n",
      "182 Train Loss 0.0018395823 Test MSE 0.00012989705921947648 Test RE 0.008234467815084736\n",
      "183 Train Loss 0.0018071606 Test MSE 0.00011773211110130092 Test RE 0.007839409352202249\n",
      "184 Train Loss 0.001789972 Test MSE 0.00010959548477034111 Test RE 0.007563663650253428\n",
      "185 Train Loss 0.0017705389 Test MSE 0.00010360617516148988 Test RE 0.007354085884330918\n",
      "186 Train Loss 0.0017501224 Test MSE 9.473229989884743e-05 Test RE 0.007032098048674945\n",
      "187 Train Loss 0.0017266226 Test MSE 8.167525069856624e-05 Test RE 0.006529517873003982\n",
      "188 Train Loss 0.0016986517 Test MSE 7.267995864864834e-05 Test RE 0.006159468132919218\n",
      "189 Train Loss 0.0016732686 Test MSE 7.208966909507808e-05 Test RE 0.006134404261707251\n",
      "190 Train Loss 0.0016505347 Test MSE 7.501294409883339e-05 Test RE 0.006257545013247277\n",
      "191 Train Loss 0.0016258347 Test MSE 7.541109974069492e-05 Test RE 0.006274130014308615\n",
      "192 Train Loss 0.0016088533 Test MSE 7.528307784804139e-05 Test RE 0.0062688021037529225\n",
      "193 Train Loss 0.0015844008 Test MSE 6.618307903804807e-05 Test RE 0.005877726325409529\n",
      "194 Train Loss 0.0015606072 Test MSE 6.220728723668493e-05 Test RE 0.0056984469339426795\n",
      "195 Train Loss 0.0015402054 Test MSE 6.106653499810009e-05 Test RE 0.00564595634728354\n",
      "196 Train Loss 0.0015271094 Test MSE 5.799647748519344e-05 Test RE 0.005502203961888374\n",
      "197 Train Loss 0.0015143134 Test MSE 5.8150105985201996e-05 Test RE 0.005509486613668024\n",
      "198 Train Loss 0.0014962753 Test MSE 5.947951100749305e-05 Test RE 0.005572108592483522\n",
      "199 Train Loss 0.001481774 Test MSE 5.825726955605579e-05 Test RE 0.00551456093368101\n",
      "200 Train Loss 0.001467028 Test MSE 5.468398115869947e-05 Test RE 0.0053427633651358586\n",
      "201 Train Loss 0.0014557834 Test MSE 5.2809938487531884e-05 Test RE 0.005250415915342657\n",
      "202 Train Loss 0.0014431514 Test MSE 5.040829743310063e-05 Test RE 0.005129640050050564\n",
      "203 Train Loss 0.0014297767 Test MSE 5.3080419730676925e-05 Test RE 0.005263844498049144\n",
      "204 Train Loss 0.0014168569 Test MSE 5.8814467072652435e-05 Test RE 0.005540869988785677\n",
      "205 Train Loss 0.0014074816 Test MSE 6.444471764764373e-05 Test RE 0.005800020646273362\n",
      "206 Train Loss 0.0013967779 Test MSE 6.91026893453427e-05 Test RE 0.00600597267110949\n",
      "207 Train Loss 0.0013818727 Test MSE 7.309491063972925e-05 Test RE 0.006177026245987919\n",
      "208 Train Loss 0.001366881 Test MSE 7.714232259514876e-05 Test RE 0.0063457393871136115\n",
      "209 Train Loss 0.0013532994 Test MSE 9.637726356582845e-05 Test RE 0.007092889148531316\n",
      "210 Train Loss 0.0013434537 Test MSE 0.00010086461251164392 Test RE 0.007256133913405645\n",
      "211 Train Loss 0.0013311992 Test MSE 0.00010802236409141865 Test RE 0.007509183474570574\n",
      "212 Train Loss 0.0013170746 Test MSE 0.00012149497122698395 Test RE 0.00796370250788065\n",
      "213 Train Loss 0.001302844 Test MSE 0.00012157415078789111 Test RE 0.007966297099898757\n",
      "214 Train Loss 0.0012899188 Test MSE 0.00011119094012130274 Test RE 0.007618519403791544\n",
      "215 Train Loss 0.0012752279 Test MSE 0.00010751397647470715 Test RE 0.007491492331607822\n",
      "216 Train Loss 0.0012645113 Test MSE 0.0001066400238504731 Test RE 0.007460982024559678\n",
      "217 Train Loss 0.0012553233 Test MSE 0.00010621866088987304 Test RE 0.007446227277749401\n",
      "218 Train Loss 0.001244734 Test MSE 0.00010986060206993013 Test RE 0.007572806576370712\n",
      "219 Train Loss 0.0012328632 Test MSE 9.716225866308759e-05 Test RE 0.007121716442984185\n",
      "220 Train Loss 0.0012237203 Test MSE 8.962448019899275e-05 Test RE 0.006839891329826943\n",
      "221 Train Loss 0.001210646 Test MSE 8.598486328235552e-05 Test RE 0.006699569232541523\n",
      "222 Train Loss 0.0011977194 Test MSE 7.683978309908947e-05 Test RE 0.006333283689950197\n",
      "223 Train Loss 0.0011829188 Test MSE 6.210599680113137e-05 Test RE 0.0056938057307326\n",
      "224 Train Loss 0.0011727985 Test MSE 5.5649564259709366e-05 Test RE 0.005389726913880401\n",
      "225 Train Loss 0.0011646277 Test MSE 5.1580128387757976e-05 Test RE 0.005188921329440759\n",
      "226 Train Loss 0.0011531743 Test MSE 4.9783655906513335e-05 Test RE 0.005097758647398717\n",
      "227 Train Loss 0.0011433345 Test MSE 4.960790720127684e-05 Test RE 0.0050887525130209705\n",
      "228 Train Loss 0.0011291932 Test MSE 4.491271587116447e-05 Test RE 0.0048419526232487305\n",
      "229 Train Loss 0.0011147021 Test MSE 4.342802239929114e-05 Test RE 0.004761249098860893\n",
      "230 Train Loss 0.0011030503 Test MSE 4.162384146638141e-05 Test RE 0.004661298941502131\n",
      "231 Train Loss 0.0010939236 Test MSE 3.990997839118972e-05 Test RE 0.004564325658868493\n",
      "232 Train Loss 0.0010884543 Test MSE 3.97302445815884e-05 Test RE 0.004554036385601741\n",
      "233 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "234 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "235 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "236 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "237 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "238 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "239 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "240 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "241 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "242 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "243 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "244 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "245 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "246 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "247 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "248 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "249 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "250 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "251 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "252 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "253 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "254 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "255 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "256 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "257 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "258 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "259 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "260 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "261 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "262 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "263 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "264 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "265 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "266 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "267 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "268 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "269 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "270 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "271 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "272 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "273 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "274 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "275 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "276 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "277 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "278 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "279 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "280 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "281 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "282 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "283 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "284 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "285 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "286 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "287 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "288 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "289 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "290 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "291 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "292 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "293 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "294 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "295 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "296 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "297 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "298 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "299 Train Loss 0.0010834311 Test MSE 4.126853055676465e-05 Test RE 0.004641361329724326\n",
      "Training time: 141.16\n",
      "KG_stan_high\n",
      "9\n",
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "9\n",
      "0 Train Loss 17206.441 Test MSE 10.812651694945448 Test RE 2.3757568142223686\n",
      "1 Train Loss 2444.6685 Test MSE 11.872200722543727 Test RE 2.4894390182607156\n",
      "2 Train Loss 785.702 Test MSE 11.150498222729068 Test RE 2.412587166454297\n",
      "3 Train Loss 330.61948 Test MSE 14.261739055686695 Test RE 2.7284884511267564\n",
      "4 Train Loss 171.67317 Test MSE 15.257134097980238 Test RE 2.822099738930187\n",
      "5 Train Loss 96.20522 Test MSE 14.979756191574214 Test RE 2.79632888843936\n",
      "6 Train Loss 66.07945 Test MSE 14.52184490523147 Test RE 2.753257138814555\n",
      "7 Train Loss 48.559395 Test MSE 13.758478824587725 Test RE 2.6799154148415356\n",
      "8 Train Loss 36.136864 Test MSE 12.937778211473352 Test RE 2.5987573331944236\n",
      "9 Train Loss 26.301737 Test MSE 12.290238991663417 Test RE 2.5328883178283257\n",
      "10 Train Loss 20.158676 Test MSE 11.397794987568098 Test RE 2.4391937435898425\n",
      "11 Train Loss 16.32846 Test MSE 10.732259692187062 Test RE 2.3669084676058185\n",
      "12 Train Loss 14.156671 Test MSE 10.268178431194512 Test RE 2.3151683692755243\n",
      "13 Train Loss 12.386108 Test MSE 9.866290263759456 Test RE 2.269409251435434\n",
      "14 Train Loss 11.677937 Test MSE 9.765225359206777 Test RE 2.257756036064333\n",
      "15 Train Loss 10.921134 Test MSE 9.699093719791863 Test RE 2.2500981096808026\n",
      "16 Train Loss 10.521558 Test MSE 9.631643113537606 Test RE 2.2422605079072033\n",
      "17 Train Loss 10.066303 Test MSE 9.594652550144207 Test RE 2.2379506374399574\n",
      "18 Train Loss 9.594109 Test MSE 9.434386518506942 Test RE 2.2191809178527895\n",
      "19 Train Loss 9.198887 Test MSE 9.22817229978086 Test RE 2.1947937975964567\n",
      "20 Train Loss 8.750692 Test MSE 8.965232439187112 Test RE 2.1632995195854128\n",
      "21 Train Loss 8.218713 Test MSE 8.735531266822512 Test RE 2.135406390862217\n",
      "22 Train Loss 7.8217974 Test MSE 8.512689907307573 Test RE 2.107993579082339\n",
      "23 Train Loss 7.5017176 Test MSE 8.38262277016406 Test RE 2.0918273562420646\n",
      "24 Train Loss 7.0665135 Test MSE 8.32116299856959 Test RE 2.0841448114641032\n",
      "25 Train Loss 6.7332115 Test MSE 8.23670843795303 Test RE 2.0735414602904134\n",
      "26 Train Loss 6.4793215 Test MSE 8.081248093928554 Test RE 2.0538801460275145\n",
      "27 Train Loss 6.2515984 Test MSE 7.969075833008689 Test RE 2.039575829776355\n",
      "28 Train Loss 6.066152 Test MSE 7.946361008912308 Test RE 2.036666981389079\n",
      "29 Train Loss 5.81477 Test MSE 7.83472267218101 Test RE 2.0223098213358726\n",
      "30 Train Loss 5.57343 Test MSE 7.726539814668835 Test RE 2.0082991309090006\n",
      "31 Train Loss 5.3326607 Test MSE 7.648217718883496 Test RE 1.9980943790176053\n",
      "32 Train Loss 5.168268 Test MSE 7.61568968571179 Test RE 1.9938408826293061\n",
      "33 Train Loss 5.0268793 Test MSE 7.579922383779226 Test RE 1.9891533072800698\n",
      "34 Train Loss 4.89754 Test MSE 7.541109093380439 Test RE 1.9840540022700515\n",
      "35 Train Loss 4.769374 Test MSE 7.456251372326303 Test RE 1.972859454183154\n",
      "36 Train Loss 4.6091194 Test MSE 7.361921257340483 Test RE 1.9603402674339254\n",
      "37 Train Loss 4.5038123 Test MSE 7.180300291964973 Test RE 1.9360081474908435\n",
      "38 Train Loss 4.3821716 Test MSE 7.062315325195218 Test RE 1.9200362541161713\n",
      "39 Train Loss 4.271568 Test MSE 6.993939432770241 Test RE 1.9107189480610254\n",
      "40 Train Loss 4.1807213 Test MSE 6.811704905145552 Test RE 1.8856617408991876\n",
      "41 Train Loss 4.116427 Test MSE 6.75388813210585 Test RE 1.8776420741566924\n",
      "42 Train Loss 4.034962 Test MSE 6.625724210464302 Test RE 1.8597413795651885\n",
      "43 Train Loss 3.9254613 Test MSE 6.551795417684435 Test RE 1.8493369238439517\n",
      "44 Train Loss 3.8100748 Test MSE 6.351593376282669 Test RE 1.820862787609334\n",
      "45 Train Loss 3.6826859 Test MSE 6.211889265127641 Test RE 1.8007263910013234\n",
      "46 Train Loss 3.5803075 Test MSE 5.983000138863347 Test RE 1.767239391602209\n",
      "47 Train Loss 3.489355 Test MSE 5.898165688825806 Test RE 1.7546655968509308\n",
      "48 Train Loss 3.3916287 Test MSE 5.823094461387403 Test RE 1.7434632382670252\n",
      "49 Train Loss 3.3060129 Test MSE 5.714758067875097 Test RE 1.7271688692493186\n",
      "50 Train Loss 3.2153268 Test MSE 5.494567994071862 Test RE 1.6935680539466218\n",
      "51 Train Loss 3.1291082 Test MSE 5.230379730867396 Test RE 1.652351682535995\n",
      "52 Train Loss 2.9843504 Test MSE 4.8056660735590215 Test RE 1.5838449782592496\n",
      "53 Train Loss 2.864306 Test MSE 4.494921906074429 Test RE 1.5317819663915688\n",
      "54 Train Loss 2.7008362 Test MSE 4.088967432549716 Test RE 1.460974724996039\n",
      "55 Train Loss 2.5185947 Test MSE 3.6014050307405223 Test RE 1.3711086172654472\n",
      "56 Train Loss 2.3483877 Test MSE 3.2302942472267877 Test RE 1.2985447444826677\n",
      "57 Train Loss 2.205366 Test MSE 2.9428910930801773 Test RE 1.2394327633566324\n",
      "58 Train Loss 2.00674 Test MSE 2.4340272855458274 Test RE 1.1271938175537777\n",
      "59 Train Loss 1.8539734 Test MSE 2.0863513100660342 Test RE 1.0435892489100638\n",
      "60 Train Loss 1.6685596 Test MSE 1.7602192990448697 Test RE 0.958559920081227\n",
      "61 Train Loss 1.4396296 Test MSE 1.4459854325289958 Test RE 0.868796046060767\n",
      "62 Train Loss 1.2568259 Test MSE 1.158884474537502 Test RE 0.7777785275747913\n",
      "63 Train Loss 1.1424354 Test MSE 1.0338994805709112 Test RE 0.7346407851497684\n",
      "64 Train Loss 0.9846184 Test MSE 0.8653122809346562 Test RE 0.6720820720299893\n",
      "65 Train Loss 0.8348106 Test MSE 0.749378143623158 Test RE 0.6254410584332056\n",
      "66 Train Loss 0.76624703 Test MSE 0.6526706694830146 Test RE 0.5836909033764957\n",
      "67 Train Loss 0.66386795 Test MSE 0.5180601639257758 Test RE 0.5200270996903659\n",
      "68 Train Loss 0.57866454 Test MSE 0.4013927174637447 Test RE 0.45774185078849405\n",
      "69 Train Loss 0.5102245 Test MSE 0.31595091399118225 Test RE 0.4061118714083573\n",
      "70 Train Loss 0.46194908 Test MSE 0.23774626224252102 Test RE 0.3522838433911089\n",
      "71 Train Loss 0.3953957 Test MSE 0.18078761452841707 Test RE 0.3071992945580379\n",
      "72 Train Loss 0.34523547 Test MSE 0.13978670597223672 Test RE 0.27012750817075126\n",
      "73 Train Loss 0.30033728 Test MSE 0.10236328283058588 Test RE 0.2311574950738987\n",
      "74 Train Loss 0.26165476 Test MSE 0.0781158728782736 Test RE 0.20193217445611703\n",
      "75 Train Loss 0.23289773 Test MSE 0.06269540513505378 Test RE 0.18090631756723607\n",
      "76 Train Loss 0.21180812 Test MSE 0.061363056056331404 Test RE 0.1789737620815211\n",
      "77 Train Loss 0.18807524 Test MSE 0.06596306652829734 Test RE 0.18556082532571125\n",
      "78 Train Loss 0.1737872 Test MSE 0.05639517603798742 Test RE 0.17157612501571526\n",
      "79 Train Loss 0.15668884 Test MSE 0.058078430277220525 Test RE 0.17411785640440428\n",
      "80 Train Loss 0.14331089 Test MSE 0.05574918531560943 Test RE 0.17059061682037274\n",
      "81 Train Loss 0.1349389 Test MSE 0.04931429402475031 Test RE 0.16044355898326734\n",
      "82 Train Loss 0.12447141 Test MSE 0.04561746232011348 Test RE 0.1543126174738827\n",
      "83 Train Loss 0.113212384 Test MSE 0.039099503106525255 Test RE 0.14286356919507248\n",
      "84 Train Loss 0.10674629 Test MSE 0.02937268947427889 Test RE 0.12382482814036617\n",
      "85 Train Loss 0.10020684 Test MSE 0.027190656960012605 Test RE 0.11913674416867565\n",
      "86 Train Loss 0.09165553 Test MSE 0.029289609164668683 Test RE 0.12364958559361662\n",
      "87 Train Loss 0.08458146 Test MSE 0.02961266145300014 Test RE 0.12432961754004404\n",
      "88 Train Loss 0.079668276 Test MSE 0.025019772220746393 Test RE 0.11428192645183725\n",
      "89 Train Loss 0.07559641 Test MSE 0.024266428176510643 Test RE 0.1125482651571629\n",
      "90 Train Loss 0.07092079 Test MSE 0.019138055580494043 Test RE 0.0999504566515605\n",
      "91 Train Loss 0.06751245 Test MSE 0.016238551893284364 Test RE 0.09206817311680478\n",
      "92 Train Loss 0.06460006 Test MSE 0.012242794216419894 Test RE 0.07994221029335125\n",
      "93 Train Loss 0.062024146 Test MSE 0.011190473992641666 Test RE 0.07642934153669823\n",
      "94 Train Loss 0.059243117 Test MSE 0.012731212079619775 Test RE 0.0815212355491261\n",
      "95 Train Loss 0.055971183 Test MSE 0.01353777540708173 Test RE 0.0840638989993045\n",
      "96 Train Loss 0.053665116 Test MSE 0.013120289266238417 Test RE 0.08275754178202292\n",
      "97 Train Loss 0.051697806 Test MSE 0.012392159605097552 Test RE 0.08042839016186756\n",
      "98 Train Loss 0.049056698 Test MSE 0.011050588576473189 Test RE 0.07595014055412859\n",
      "99 Train Loss 0.047349 Test MSE 0.010092644429046322 Test RE 0.07258357641421101\n",
      "100 Train Loss 0.045248486 Test MSE 0.009004224057898445 Test RE 0.06855813952423997\n",
      "101 Train Loss 0.043805607 Test MSE 0.007983873379654838 Test RE 0.0645569044100132\n",
      "102 Train Loss 0.042115733 Test MSE 0.007300142889488489 Test RE 0.06173075054806631\n",
      "103 Train Loss 0.0397764 Test MSE 0.006262418593762486 Test RE 0.05717509878225838\n",
      "104 Train Loss 0.03740637 Test MSE 0.006048889504897491 Test RE 0.05619189812915521\n",
      "105 Train Loss 0.035542842 Test MSE 0.005942842420511799 Test RE 0.05569715143414954\n",
      "106 Train Loss 0.033762436 Test MSE 0.005918815382445646 Test RE 0.05558444501734455\n",
      "107 Train Loss 0.032166384 Test MSE 0.005790842872635519 Test RE 0.054980257232697186\n",
      "108 Train Loss 0.030571932 Test MSE 0.005984617148934126 Test RE 0.055892567922027694\n",
      "109 Train Loss 0.028715948 Test MSE 0.005632874244623118 Test RE 0.05422516781037788\n",
      "110 Train Loss 0.026907975 Test MSE 0.005285886983834442 Test RE 0.052528477536256654\n",
      "111 Train Loss 0.025023077 Test MSE 0.0051916223093222405 Test RE 0.052057993146736765\n",
      "112 Train Loss 0.023459988 Test MSE 0.00523604003796862 Test RE 0.0522802139589729\n",
      "113 Train Loss 0.022595417 Test MSE 0.004764692731402835 Test RE 0.049871602831199104\n",
      "114 Train Loss 0.021488277 Test MSE 0.004562624572732888 Test RE 0.048802631961208924\n",
      "115 Train Loss 0.020855887 Test MSE 0.004440172562679848 Test RE 0.04814329395669962\n",
      "116 Train Loss 0.020222198 Test MSE 0.004584168640485311 Test RE 0.048917715830739415\n",
      "117 Train Loss 0.019395247 Test MSE 0.00489297338884918 Test RE 0.05053849488256339\n",
      "118 Train Loss 0.01904393 Test MSE 0.0047324458739666205 Test RE 0.04970255386689671\n",
      "119 Train Loss 0.018799093 Test MSE 0.004428670090849027 Test RE 0.04808089480669919\n",
      "120 Train Loss 0.018284863 Test MSE 0.004201899301314931 Test RE 0.0468337245193312\n",
      "121 Train Loss 0.017894201 Test MSE 0.004341390958709182 Test RE 0.04760475404013623\n",
      "122 Train Loss 0.017479137 Test MSE 0.004439065837500145 Test RE 0.04813729365880006\n",
      "123 Train Loss 0.01692197 Test MSE 0.0049252668366334745 Test RE 0.05070499672899827\n",
      "124 Train Loss 0.01660574 Test MSE 0.0051267776193034765 Test RE 0.05173186276164293\n",
      "125 Train Loss 0.01629046 Test MSE 0.005076594078866477 Test RE 0.05147805106291648\n",
      "126 Train Loss 0.015810784 Test MSE 0.0049085188877506175 Test RE 0.05061871431390058\n",
      "127 Train Loss 0.015515497 Test MSE 0.00462187560577628 Test RE 0.04911848953975366\n",
      "128 Train Loss 0.015076207 Test MSE 0.004769365958005072 Test RE 0.04989605395484581\n",
      "129 Train Loss 0.01463462 Test MSE 0.004563621755519839 Test RE 0.048807964690766904\n",
      "130 Train Loss 0.014231965 Test MSE 0.004630921743021665 Test RE 0.049166534471211144\n",
      "131 Train Loss 0.013713174 Test MSE 0.004498102912031865 Test RE 0.048456335833969896\n",
      "132 Train Loss 0.013256854 Test MSE 0.004532643249272238 Test RE 0.048642024941621474\n",
      "133 Train Loss 0.012930392 Test MSE 0.004446017637512995 Test RE 0.04817497162273665\n",
      "134 Train Loss 0.012702524 Test MSE 0.004487443895167917 Test RE 0.04839888903298198\n",
      "135 Train Loss 0.012390334 Test MSE 0.004618965734252185 Test RE 0.04910302493081927\n",
      "136 Train Loss 0.012188466 Test MSE 0.004569229883073581 Test RE 0.04883794496361787\n",
      "137 Train Loss 0.011827175 Test MSE 0.004428942024648146 Test RE 0.04808237094055195\n",
      "138 Train Loss 0.011635514 Test MSE 0.004332968980248706 Test RE 0.04755855676746334\n",
      "139 Train Loss 0.011432138 Test MSE 0.004231832920471528 Test RE 0.04700024623929176\n",
      "140 Train Loss 0.011171284 Test MSE 0.004063782007285309 Test RE 0.04605757611105775\n",
      "141 Train Loss 0.010929825 Test MSE 0.003824677366791143 Test RE 0.044682069506928\n",
      "142 Train Loss 0.010632451 Test MSE 0.0034944792255460913 Test RE 0.04270975777591789\n",
      "143 Train Loss 0.010450013 Test MSE 0.0033083577765674545 Test RE 0.04155680128569582\n",
      "144 Train Loss 0.010223126 Test MSE 0.0032140954652418404 Test RE 0.04096050127713811\n",
      "145 Train Loss 0.009997417 Test MSE 0.003306555460971909 Test RE 0.04154548015907823\n",
      "146 Train Loss 0.009715911 Test MSE 0.003154436597942266 Test RE 0.04057857373607279\n",
      "147 Train Loss 0.009449374 Test MSE 0.0031183366110905464 Test RE 0.04034571103655471\n",
      "148 Train Loss 0.009170037 Test MSE 0.0028996388664938883 Test RE 0.03890521620013349\n",
      "149 Train Loss 0.008941305 Test MSE 0.002701970862712223 Test RE 0.037555729954752294\n",
      "150 Train Loss 0.008733505 Test MSE 0.0025132664945511324 Test RE 0.036220558921131386\n",
      "151 Train Loss 0.00853648 Test MSE 0.002472522833501455 Test RE 0.03592576563189529\n",
      "152 Train Loss 0.008417271 Test MSE 0.002468512176799559 Test RE 0.0358966163782873\n",
      "153 Train Loss 0.008241431 Test MSE 0.002527802530801952 Test RE 0.03632515273657242\n",
      "154 Train Loss 0.008078192 Test MSE 0.0024588868390428803 Test RE 0.035826563142874364\n",
      "155 Train Loss 0.007891521 Test MSE 0.0023967310632734564 Test RE 0.035370852664796684\n",
      "156 Train Loss 0.0077471756 Test MSE 0.00233727267333531 Test RE 0.03492935512285158\n",
      "157 Train Loss 0.0076085213 Test MSE 0.0022380833361426797 Test RE 0.034180153103286544\n",
      "158 Train Loss 0.0074731507 Test MSE 0.0019588043264173833 Test RE 0.03197653519729804\n",
      "159 Train Loss 0.007359392 Test MSE 0.001796211149166993 Test RE 0.030620661656133943\n",
      "160 Train Loss 0.007265785 Test MSE 0.001715573490865236 Test RE 0.029925439702644076\n",
      "161 Train Loss 0.007171006 Test MSE 0.001655248177102066 Test RE 0.02939459196723318\n",
      "162 Train Loss 0.007011759 Test MSE 0.0016460397314639167 Test RE 0.029312714211638433\n",
      "163 Train Loss 0.006803321 Test MSE 0.0016624188088443044 Test RE 0.02945819270542215\n",
      "164 Train Loss 0.0067104 Test MSE 0.0016413743243660647 Test RE 0.029271143895212133\n",
      "165 Train Loss 0.006618312 Test MSE 0.0016139692270546189 Test RE 0.029025753443059278\n",
      "166 Train Loss 0.0065199514 Test MSE 0.0014302208928014496 Test RE 0.027323569609640934\n",
      "167 Train Loss 0.006404283 Test MSE 0.0013909216231775443 Test RE 0.026945559530047628\n",
      "168 Train Loss 0.0062571107 Test MSE 0.0014305787836309182 Test RE 0.02732698804778754\n",
      "169 Train Loss 0.0061397217 Test MSE 0.0013658420582188082 Test RE 0.026701528191747283\n",
      "170 Train Loss 0.0060269698 Test MSE 0.0013546291945103748 Test RE 0.02659169938273292\n",
      "171 Train Loss 0.005929198 Test MSE 0.0013225481047705414 Test RE 0.026274932901670045\n",
      "172 Train Loss 0.005866044 Test MSE 0.001327257245925442 Test RE 0.026321669357200095\n",
      "173 Train Loss 0.0057553384 Test MSE 0.0012364301478176923 Test RE 0.0254050860260216\n",
      "174 Train Loss 0.005642163 Test MSE 0.0012318598055464152 Test RE 0.025358088856476817\n",
      "175 Train Loss 0.005532293 Test MSE 0.0012795217256571993 Test RE 0.025843998614861224\n",
      "176 Train Loss 0.005457547 Test MSE 0.0013057026849074731 Test RE 0.02610706349809596\n",
      "177 Train Loss 0.005378464 Test MSE 0.001288365064461924 Test RE 0.025933154465971654\n",
      "178 Train Loss 0.0053217164 Test MSE 0.0012247630223606498 Test RE 0.02528493897482881\n",
      "179 Train Loss 0.0052806963 Test MSE 0.0011547455801731203 Test RE 0.024551556546904673\n",
      "180 Train Loss 0.0052335938 Test MSE 0.001163713760191394 Test RE 0.024646710375382963\n",
      "181 Train Loss 0.005185433 Test MSE 0.0011481090782049473 Test RE 0.024480904086068043\n",
      "182 Train Loss 0.0051240046 Test MSE 0.001084733010678846 Test RE 0.023795635363320352\n",
      "183 Train Loss 0.005056143 Test MSE 0.0010304270910333646 Test RE 0.023192336894899915\n",
      "184 Train Loss 0.0050061643 Test MSE 0.0010209800935385431 Test RE 0.023085777954224944\n",
      "185 Train Loss 0.0049600904 Test MSE 0.0010080988778339397 Test RE 0.022939684605254883\n",
      "186 Train Loss 0.004898453 Test MSE 0.0009760470610800686 Test RE 0.02257206311476365\n",
      "187 Train Loss 0.0048585366 Test MSE 0.0009727046267535265 Test RE 0.022533381404340046\n",
      "188 Train Loss 0.004815898 Test MSE 0.0010059022219764985 Test RE 0.02291467809349647\n",
      "189 Train Loss 0.004787083 Test MSE 0.000972861100372065 Test RE 0.022535193741735945\n",
      "190 Train Loss 0.0047449935 Test MSE 0.0009113522816907978 Test RE 0.02181117285142201\n",
      "191 Train Loss 0.0046846936 Test MSE 0.0009019689638747706 Test RE 0.02169859799959243\n",
      "192 Train Loss 0.0046096365 Test MSE 0.0008595202223894849 Test RE 0.021181851861342495\n",
      "193 Train Loss 0.004548466 Test MSE 0.000881478278274955 Test RE 0.02145071062830912\n",
      "194 Train Loss 0.004476582 Test MSE 0.000872774346775325 Test RE 0.021344543123039655\n",
      "195 Train Loss 0.0044134553 Test MSE 0.0008742736902246147 Test RE 0.021362869204905908\n",
      "196 Train Loss 0.004365713 Test MSE 0.0008825901337316322 Test RE 0.02146423482631944\n",
      "197 Train Loss 0.004319895 Test MSE 0.0008695920557932902 Test RE 0.021305594581106473\n",
      "198 Train Loss 0.0042384113 Test MSE 0.0007859866662655096 Test RE 0.02025552323268906\n",
      "199 Train Loss 0.004180322 Test MSE 0.0007977702449026516 Test RE 0.02040679463300967\n",
      "200 Train Loss 0.0041302755 Test MSE 0.0007881796008186919 Test RE 0.02028376041476504\n",
      "201 Train Loss 0.00403717 Test MSE 0.0007978472598358503 Test RE 0.02040777962211335\n",
      "202 Train Loss 0.0039823256 Test MSE 0.0007791544561767921 Test RE 0.020167295244833\n",
      "203 Train Loss 0.003940225 Test MSE 0.0007653332548055782 Test RE 0.019987623910758465\n",
      "204 Train Loss 0.003915091 Test MSE 0.0007734305153550266 Test RE 0.020093080694060423\n",
      "205 Train Loss 0.0038860936 Test MSE 0.0007702848769973064 Test RE 0.020052178530678224\n",
      "206 Train Loss 0.0038391491 Test MSE 0.0007842747018798396 Test RE 0.02023345184210908\n",
      "207 Train Loss 0.0037996434 Test MSE 0.0007220926785197025 Test RE 0.01941477436823632\n",
      "208 Train Loss 0.0037499093 Test MSE 0.00070539992928288 Test RE 0.01918905478579652\n",
      "209 Train Loss 0.0037137624 Test MSE 0.000718495649286932 Test RE 0.019366357662252996\n",
      "210 Train Loss 0.0036794008 Test MSE 0.0006828706492390406 Test RE 0.018880135209242213\n",
      "211 Train Loss 0.0036193435 Test MSE 0.0006986258370797562 Test RE 0.019096694406577568\n",
      "212 Train Loss 0.0035729408 Test MSE 0.00066061515042337 Test RE 0.018569924654638126\n",
      "213 Train Loss 0.0035215965 Test MSE 0.0006628593201238555 Test RE 0.018601439773212134\n",
      "214 Train Loss 0.0034808596 Test MSE 0.0006705866545855187 Test RE 0.01870954948261913\n",
      "215 Train Loss 0.0034294808 Test MSE 0.0006792824010423979 Test RE 0.01883046559610534\n",
      "216 Train Loss 0.0033985828 Test MSE 0.0006660212974048487 Test RE 0.01864575336452731\n",
      "217 Train Loss 0.0033611297 Test MSE 0.0006741275442745169 Test RE 0.01875888033928321\n",
      "218 Train Loss 0.00331611 Test MSE 0.0006750701779791731 Test RE 0.018771991045025475\n",
      "219 Train Loss 0.0032769237 Test MSE 0.0006636013464044414 Test RE 0.018611848389411895\n",
      "220 Train Loss 0.0032291445 Test MSE 0.0006263699702902735 Test RE 0.018082203023022967\n",
      "221 Train Loss 0.0031766957 Test MSE 0.0006040797896893134 Test RE 0.01775754933490062\n",
      "222 Train Loss 0.0031356793 Test MSE 0.0005842461416922542 Test RE 0.017463601126611446\n",
      "223 Train Loss 0.0030737077 Test MSE 0.0005368759240727755 Test RE 0.016740670222437682\n",
      "224 Train Loss 0.0030086476 Test MSE 0.0005227854118922587 Test RE 0.016519526959169802\n",
      "225 Train Loss 0.0029587985 Test MSE 0.0005190820515734657 Test RE 0.01646091161815642\n",
      "226 Train Loss 0.0029021355 Test MSE 0.00048812363793424414 Test RE 0.015962495821102485\n",
      "227 Train Loss 0.0028602327 Test MSE 0.0004732140237607035 Test RE 0.015716820029040783\n",
      "228 Train Loss 0.0028139981 Test MSE 0.0004546722015664214 Test RE 0.015405829181331727\n",
      "229 Train Loss 0.002771706 Test MSE 0.00041463497555661936 Test RE 0.014711902684423562\n",
      "230 Train Loss 0.0027456249 Test MSE 0.00039800764331533283 Test RE 0.014413902600223861\n",
      "231 Train Loss 0.0027132523 Test MSE 0.00038784765978385405 Test RE 0.014228740685350771\n",
      "232 Train Loss 0.002690696 Test MSE 0.0003670309284385706 Test RE 0.013841629110519735\n",
      "233 Train Loss 0.002657242 Test MSE 0.0003441189174494231 Test RE 0.013402633780392281\n",
      "234 Train Loss 0.0026313986 Test MSE 0.00033152951796778585 Test RE 0.013155185547729906\n",
      "235 Train Loss 0.002609636 Test MSE 0.0003143147118098032 Test RE 0.012809088652214053\n",
      "236 Train Loss 0.00258624 Test MSE 0.00029303399626546184 Test RE 0.012367869120954318\n",
      "237 Train Loss 0.0025657287 Test MSE 0.00027626363190673035 Test RE 0.012008748110669482\n",
      "238 Train Loss 0.0025391348 Test MSE 0.00025701183051102716 Test RE 0.011582770044946485\n",
      "239 Train Loss 0.002518048 Test MSE 0.0002631767121317039 Test RE 0.011720863423326984\n",
      "240 Train Loss 0.0024851395 Test MSE 0.00024961167312240943 Test RE 0.011414800420155247\n",
      "241 Train Loss 0.002438815 Test MSE 0.00024293426671556266 Test RE 0.01126108575799419\n",
      "242 Train Loss 0.002410119 Test MSE 0.00023474563613177995 Test RE 0.011069669144717591\n",
      "243 Train Loss 0.002372288 Test MSE 0.00023037419328477332 Test RE 0.010966114865138883\n",
      "244 Train Loss 0.0023410216 Test MSE 0.00022364137138998434 Test RE 0.010804681026496182\n",
      "245 Train Loss 0.0023236366 Test MSE 0.00021365009232427926 Test RE 0.0105605714519293\n",
      "246 Train Loss 0.002305576 Test MSE 0.00021474651633727782 Test RE 0.010587634503251196\n",
      "247 Train Loss 0.002278964 Test MSE 0.0002016045943108532 Test RE 0.010258552593777176\n",
      "248 Train Loss 0.002249628 Test MSE 0.0002065568112766478 Test RE 0.010383783800740395\n",
      "249 Train Loss 0.0022127773 Test MSE 0.0002095908070762051 Test RE 0.010459766555193612\n",
      "250 Train Loss 0.0021914702 Test MSE 0.0002069997107614967 Test RE 0.010394910303483025\n",
      "251 Train Loss 0.0021670256 Test MSE 0.00021250124151279124 Test RE 0.010532139741787704\n",
      "252 Train Loss 0.0021496953 Test MSE 0.00021061471702778857 Test RE 0.010485284875634174\n",
      "253 Train Loss 0.002131394 Test MSE 0.00020859818160648752 Test RE 0.010434968346940852\n",
      "254 Train Loss 0.0021020432 Test MSE 0.00020807249665074002 Test RE 0.0104218115538735\n",
      "255 Train Loss 0.002068045 Test MSE 0.00020231948595012873 Test RE 0.010276724956412452\n",
      "256 Train Loss 0.0020398358 Test MSE 0.000197763441918779 Test RE 0.010160355013281002\n",
      "257 Train Loss 0.0020173264 Test MSE 0.00019091489242654673 Test RE 0.009982878385764431\n",
      "258 Train Loss 0.0020037831 Test MSE 0.00018201160916938704 Test RE 0.00974732443389856\n",
      "259 Train Loss 0.0019861625 Test MSE 0.0001802887119976111 Test RE 0.009701081316318999\n",
      "260 Train Loss 0.001966724 Test MSE 0.0001696680298321897 Test RE 0.009411002425274631\n",
      "261 Train Loss 0.0019412867 Test MSE 0.0001560627414561699 Test RE 0.009025795569492815\n",
      "262 Train Loss 0.0019216877 Test MSE 0.00015217518450821228 Test RE 0.00891266935833217\n",
      "263 Train Loss 0.0018999455 Test MSE 0.000141756633516158 Test RE 0.008602161112768281\n",
      "264 Train Loss 0.0018817402 Test MSE 0.00013051407874754026 Test RE 0.008254001776043705\n",
      "265 Train Loss 0.0018622164 Test MSE 0.0001238661518427768 Test RE 0.008041039577085933\n",
      "266 Train Loss 0.0018446742 Test MSE 0.00011793076082159171 Test RE 0.00784602029337387\n",
      "267 Train Loss 0.0018271828 Test MSE 0.00012189123765327903 Test RE 0.007976679089965386\n",
      "268 Train Loss 0.0018082932 Test MSE 0.00011822001276651381 Test RE 0.007855636472886236\n",
      "269 Train Loss 0.0017891765 Test MSE 0.0001200801785562082 Test RE 0.007917198603856267\n",
      "270 Train Loss 0.0017780972 Test MSE 0.00012097564262517764 Test RE 0.007946663911550028\n",
      "271 Train Loss 0.0017607977 Test MSE 0.00011665976600330958 Test RE 0.007803625646973248\n",
      "272 Train Loss 0.0017480026 Test MSE 0.00011004872020751953 Test RE 0.007579287393532378\n",
      "273 Train Loss 0.0017249036 Test MSE 0.00010800114448054283 Test RE 0.007508445896854114\n",
      "274 Train Loss 0.0017031624 Test MSE 0.00011250215858009745 Test RE 0.0076633084182162045\n",
      "275 Train Loss 0.0016799691 Test MSE 0.0001134647827249655 Test RE 0.007696024114016131\n",
      "276 Train Loss 0.0016629985 Test MSE 0.00010802046668860777 Test RE 0.007509117525225182\n",
      "277 Train Loss 0.0016513215 Test MSE 0.00010928544184430598 Test RE 0.007552957363884773\n",
      "278 Train Loss 0.0016347298 Test MSE 0.00011509193554926917 Test RE 0.007751010475030921\n",
      "279 Train Loss 0.0016119932 Test MSE 0.00011740379536809463 Test RE 0.007828470967250114\n",
      "280 Train Loss 0.0015951649 Test MSE 0.00011465742676469857 Test RE 0.007736365370460462\n",
      "281 Train Loss 0.0015803224 Test MSE 0.0001104025671179947 Test RE 0.007591462705763265\n",
      "282 Train Loss 0.0015656551 Test MSE 0.00010710142791308951 Test RE 0.007477105481745973\n",
      "283 Train Loss 0.0015439913 Test MSE 9.279297761857652e-05 Test RE 0.006959746677885005\n",
      "284 Train Loss 0.0015304104 Test MSE 9.045081600526803e-05 Test RE 0.006871350808757848\n",
      "285 Train Loss 0.0015123417 Test MSE 8.502992271770873e-05 Test RE 0.006662262940715375\n",
      "286 Train Loss 0.0014945565 Test MSE 7.912113269495572e-05 Test RE 0.0064266126549041985\n",
      "287 Train Loss 0.0014818604 Test MSE 8.004490202648169e-05 Test RE 0.006464020358570272\n",
      "288 Train Loss 0.0014711345 Test MSE 7.97598806420982e-05 Test RE 0.006452501654774396\n",
      "289 Train Loss 0.0014573348 Test MSE 7.89972300949795e-05 Test RE 0.0064215786900663355\n",
      "290 Train Loss 0.0014469586 Test MSE 7.966337400634458e-05 Test RE 0.006448596823799456\n",
      "291 Train Loss 0.0014362725 Test MSE 7.945164751884285e-05 Test RE 0.006440021696480097\n",
      "292 Train Loss 0.0014203208 Test MSE 7.734943041729253e-05 Test RE 0.006354252038099099\n",
      "293 Train Loss 0.0014002346 Test MSE 7.721038748058271e-05 Test RE 0.006348538283864184\n",
      "294 Train Loss 0.0013772227 Test MSE 7.40727666938908e-05 Test RE 0.006218206781218247\n",
      "295 Train Loss 0.001356142 Test MSE 7.223470148292936e-05 Test RE 0.00614057186022196\n",
      "296 Train Loss 0.0013434151 Test MSE 7.10900920961547e-05 Test RE 0.006091726762574507\n",
      "297 Train Loss 0.0013294047 Test MSE 6.938127903269858e-05 Test RE 0.006018067128384409\n",
      "298 Train Loss 0.0013154421 Test MSE 6.767199888551023e-05 Test RE 0.00594347416543599\n",
      "299 Train Loss 0.0013052744 Test MSE 6.574910524449127e-05 Test RE 0.005858424001704427\n",
      "Training time: 166.08\n"
     ]
    }
   ],
   "source": [
    "max_reps = 10 #10\n",
    "max_iter = 300 #200\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "beta_full = []\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "beta_init = 0\n",
    "\n",
    "N_I = 1000  #Total number of data points for 'y'\n",
    "N_B = 5000\n",
    "N_f = 10000 #Total number of collocation points\n",
    "\n",
    "for reps in range(max_reps):\n",
    "    print(label)\n",
    "    print(reps)\n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "    test_re_loss = []\n",
    "    beta_val = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([2,50,50,50,50,1]) #9 hidden layers\n",
    "    # layers = np.array([2,50,50,50,50,50,50,50,1])\n",
    "\n",
    "    PINN = Sequentialmodel(layers,beta_init)\n",
    "\n",
    "    PINN.to(device)\n",
    "\n",
    "    'Neural Network Summary'\n",
    "    print(PINN)\n",
    "\n",
    "    params = list(PINN.parameters())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.LBFGS(PINN.parameters(), lr=1, \n",
    "                            max_iter = 20, \n",
    "                            max_eval = 30, \n",
    "                            tolerance_grad = 1e-8, \n",
    "                            tolerance_change = 1e-8, \n",
    "                            history_size = 100, \n",
    "                            line_search_fn = 'strong_wolfe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nan_flag = train_model(max_iter,reps)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(PINN.state_dict(),label+'_'+str(reps)+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    test_re_full.append(test_re_loss)\n",
    "    #elapsed_time[reps] = time.time() - start_time\n",
    "    beta_full.append(beta_val)\n",
    "\n",
    "\n",
    "  #print('Training time: %.2f' % (elapsed_time[reps]))\n",
    "\n",
    "mdic = {\"train_loss\": train_loss_full,\"test_mse_loss\": test_mse_full,\"test_re_loss\": test_re_full,\"Time\": elapsed_time, \"beta\": beta_full, \"label\": label,\"Thresh Time\": time_threshold,\"Thresh epoch\": epoch_threshold}\n",
    "savemat(label+'.mat', mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe0a0570f50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u_pred = PINN.test()\n",
    "plt.imshow(u_pred.reshape(500,500),cmap = 'jet')\n",
    "plt.figure()\n",
    "plt.imshow(y_true.reshape(500,500),cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1660688534316,
     "user": {
      "displayName": "Raghav Gnanasambandam",
      "userId": "17884362014649498321"
     },
     "user_tz": 240
    },
    "id": "06syezgfv_qO",
    "outputId": "9f4852d5-694a-4977-8893-a6183a2ce493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.007932589241806159\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((10,1))\n",
    "for i in range(10):\n",
    "    a[i] = test_re_full[i][-1]    \n",
    "print(\"a = \",np.nanmean(a))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stan_2D_KG_16Aug2022_tune.ipynb",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
